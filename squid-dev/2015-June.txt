From squid3 at treenet.co.nz  Mon Jun  1 23:21:19 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 02 Jun 2015 11:21:19 +1200
Subject: [squid-dev] [PATCH] Parser-NG: Transfer-Encoding:chunked Parser
Message-ID: <556CE8EF.1050604@treenet.co.nz>

Remove several performance regressions incurred in earlier Parser-NG
updates by refactoring the class ChunkedCodingParser to a class
Http1::TeChunkedParser which parses an SBuf I/O buffer for chunked
encoding data and (for now) copies the chunk payloads into a MemBuf buffer.

The new class is inherited from Http1::Parser and presents the same API.
Chunk Trailers are now available via the Parser API mimeHeader() method
- although none of the rest of Squid makes use of that data yet. It
implements parsing using a ::Parser::Tokenizer for (nearly) compliant
protocol tokenization. With enumerated states instead of a dynamic
function-pointer chain.


Measurements:
 Co-Advisor shows no compliance change.
 Polygraph shows approx 1% speed improvement over trunk.

PS. earlier bugs being investigated turned out to be inherited from
trunk and are now fixed there already.

Amos
-------------- next part --------------
=== modified file 'src/Makefile.am'
--- src/Makefile.am	2015-05-26 09:18:13 +0000
+++ src/Makefile.am	2015-06-01 06:21:35 +0000
@@ -274,42 +274,40 @@
 	AccessLogEntry.h \
 	AsyncEngine.cc \
 	AsyncEngine.h \
 	cache_cf.h \
 	AuthReg.h \
 	YesNoNone.h \
 	YesNoNone.cc \
 	RefreshPattern.h \
 	cache_cf.cc \
 	CacheDigest.h \
 	CacheDigest.cc \
 	cache_manager.cc \
 	NeighborTypeDomainList.h \
 	CachePeer.cc \
 	CachePeer.h \
 	CacheManager.h \
 	carp.h \
 	carp.cc \
 	cbdata.cc \
 	cbdata.h \
-	ChunkedCodingParser.cc \
-	ChunkedCodingParser.h \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
 	client_side.cc \
 	client_side.h \
 	client_side_reply.cc \
 	client_side_reply.h \
 	client_side_request.cc \
 	client_side_request.h \
 	ClientInfo.h \
 	BodyPipe.cc \
 	BodyPipe.h \
 	ClientInfo.h \
 	ClientRequestContext.h \
 	clientStream.cc \
 	clientStream.h \
 	clientStreamForward.h \
 	CollapsedForwarding.cc \
 	CollapsedForwarding.h \
 	CompletionDispatcher.cc \
@@ -1385,41 +1383,40 @@
 	tests/stub_main_cc.cc \
 	tests/stub_ipc_Forwarder.cc \
 	tests/stub_store_stats.cc \
 	tests/stub_EventLoop.cc \
 	time.cc \
 	BodyPipe.cc \
 	cache_manager.cc \
 	cache_cf.h \
 	AuthReg.h \
 	YesNoNone.h \
 	YesNoNone.cc \
 	RefreshPattern.h \
 	cache_cf.cc \
 	CachePeer.cc \
 	CachePeer.h \
 	CacheDigest.h \
 	tests/stub_CacheDigest.cc \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
 	client_side.cc \
 	client_side_reply.cc \
 	client_side_request.cc \
 	ClientInfo.h \
 	clientStream.cc \
 	tests/stub_CollapsedForwarding.cc \
 	ConfigOption.cc \
 	ConfigParser.cc \
 	CpuAffinityMap.cc \
 	CpuAffinityMap.h \
 	CpuAffinitySet.cc \
 	CpuAffinitySet.h \
 	$(DELAY_POOL_SOURCE) \
 	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
 	dlink.h \
@@ -1815,41 +1812,40 @@
 	$(SQUID_CPPUNIT_LIBS)
 tests_testDns_LDFLAGS= $(LIBADD_DL)
 
 tests_testEvent_SOURCES = \
 	AccessLogEntry.cc \
 	BodyPipe.cc \
 	CacheDigest.h \
 	tests/stub_CacheDigest.cc \
 	cache_cf.h \
 	AuthReg.h \
 	YesNoNone.h \
 	YesNoNone.cc \
 	RefreshPattern.h \
 	cache_cf.cc \
 	CachePeer.cc \
 	CachePeer.h \
 	cache_manager.cc \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
 	client_side.cc \
 	client_side_reply.cc \
 	client_side_request.cc \
 	ClientInfo.h \
 	clientStream.cc \
 	tests/stub_CollapsedForwarding.cc \
 	ConfigOption.cc \
 	ConfigParser.cc \
 	CpuAffinityMap.cc \
 	CpuAffinityMap.h \
 	CpuAffinitySet.cc \
 	CpuAffinitySet.h \
 	debug.cc \
 	$(DELAY_POOL_SOURCE) \
 	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
@@ -2061,41 +2057,40 @@
 	$(SQUID_CPPUNIT_LA)
 
 ## Tests of the EventLoop module.
 tests_testEventLoop_SOURCES = \
 	AccessLogEntry.cc \
 	BodyPipe.cc \
 	CacheDigest.h \
 	tests/stub_CacheDigest.cc \
 	cache_manager.cc \
 	cache_cf.h \
 	AuthReg.h \
 	YesNoNone.h \
 	YesNoNone.cc \
 	RefreshPattern.h \
 	cache_cf.cc \
 	CachePeer.cc \
 	CachePeer.h \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
 	client_side.cc \
 	client_side_reply.cc \
 	client_side_request.cc \
 	ClientInfo.h \
 	clientStream.cc \
 	tests/stub_CollapsedForwarding.cc \
 	ConfigOption.cc \
 	ConfigParser.cc \
 	CpuAffinityMap.cc \
 	CpuAffinityMap.h \
 	CpuAffinitySet.cc \
 	CpuAffinitySet.h \
 	debug.cc \
 	$(DELAY_POOL_SOURCE) \
 	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
@@ -2305,41 +2300,40 @@
 	$(REPL_OBJS) \
 	$(SQUID_CPPUNIT_LA)
 
 tests_test_http_range_SOURCES = \
 	AccessLogEntry.cc \
 	BodyPipe.cc \
 	cache_cf.h \
 	AuthReg.h \
 	YesNoNone.h \
 	YesNoNone.cc \
 	RefreshPattern.h \
 	cache_cf.cc \
 	CachePeer.cc \
 	CachePeer.h \
 	cache_manager.cc \
 	CacheDigest.h \
 	tests/stub_CacheDigest.cc \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
 	client_side.cc \
 	client_side_reply.cc \
 	client_side_request.cc \
 	ClientInfo.h \
 	clientStream.cc \
 	tests/stub_CollapsedForwarding.cc \
 	ConfigOption.cc \
 	ConfigParser.cc \
 	CpuAffinityMap.cc \
 	CpuAffinityMap.h \
 	CpuAffinitySet.cc \
 	CpuAffinitySet.h \
 	debug.cc \
 	$(DELAY_POOL_SOURCE) \
 	$(DISKIO_SOURCE) \
 	disk.h \
 	disk.cc \
@@ -2611,41 +2605,40 @@
 	tests/stub_libeui.cc \
 	tests/stub_store_stats.cc \
 	tests/stub_EventLoop.cc \
 	time.cc \
 	BodyPipe.cc \
 	cache_manager.cc \
 	cache_cf.h \
 	AuthReg.h \
 	YesNoNone.h \
 	YesNoNone.cc \
 	RefreshPattern.h \
 	cache_cf.cc \
 	debug.cc \
 	CacheDigest.h \
 	tests/stub_CacheDigest.cc \
 	CachePeer.cc \
 	CachePeer.h \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
 	client_side.cc \
 	client_side_reply.cc \
 	client_side_request.cc \
 	ClientInfo.h \
 	clientStream.cc \
 	tests/stub_CollapsedForwarding.cc \
 	ConfigOption.cc \
 	ConfigParser.cc \
 	CpuAffinityMap.cc \
 	CpuAffinityMap.h \
 	CpuAffinitySet.cc \
 	CpuAffinitySet.h \
 	$(DELAY_POOL_SOURCE) \
 	disk.h \
 	disk.cc \
 	dlink.h \
 	dlink.cc \
@@ -3418,41 +3411,40 @@
 
 ## Tests of the URL module.
 ## TODO: Trim this down once the insanity is over.
 tests_testURL_SOURCES = \
 	AccessLogEntry.cc \
 	BodyPipe.cc \
 	cache_cf.h \
 	AuthReg.h \
 	YesNoNone.h \
 	YesNoNone.cc \
 	RefreshPattern.h \
 	cache_cf.cc \
 	tests/stub_cache_manager.cc \
 	CacheDigest.h \
 	tests/stub_CacheDigest.cc \
 	CachePeer.cc \
 	CachePeer.h \
 	carp.h \
 	tests/stub_carp.cc \
 	cbdata.cc \
-	ChunkedCodingParser.cc \
 	client_db.h \
 	client_db.cc \
 	client_side.h \
 	client_side.cc \
 	client_side_reply.cc \
 	client_side_request.cc \
 	ClientInfo.h \
 	clientStream.cc \
 	tests/stub_CollapsedForwarding.cc \
 	ConfigOption.cc \
 	ConfigParser.cc \
 	CpuAffinityMap.cc \
 	CpuAffinityMap.h \
 	CpuAffinitySet.cc \
 	CpuAffinitySet.h \
 	$(DELAY_POOL_SOURCE) \
 	disk.h \
 	disk.cc \
 	DiskIO/ReadRequest.cc \
 	DiskIO/WriteRequest.cc \

=== modified file 'src/adaptation/icap/ModXact.cc'
--- src/adaptation/icap/ModXact.cc	2015-04-27 09:52:02 +0000
+++ src/adaptation/icap/ModXact.cc	2015-06-01 19:48:35 +0000
@@ -5,44 +5,44 @@
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 /* DEBUG: section 93    ICAP (RFC 3507) Client */
 
 #include "squid.h"
 #include "AccessLogEntry.h"
 #include "adaptation/Answer.h"
 #include "adaptation/History.h"
 #include "adaptation/icap/Client.h"
 #include "adaptation/icap/Config.h"
 #include "adaptation/icap/History.h"
 #include "adaptation/icap/Launcher.h"
 #include "adaptation/icap/ModXact.h"
 #include "adaptation/icap/ServiceRep.h"
 #include "adaptation/Initiator.h"
 #include "auth/UserRequest.h"
 #include "base/TextException.h"
 #include "base64.h"
-#include "ChunkedCodingParser.h"
 #include "comm.h"
 #include "comm/Connection.h"
 #include "err_detail_type.h"
+#include "http/one/TeChunkedParser.h"
 #include "HttpHeaderTools.h"
 #include "HttpMsg.h"
 #include "HttpReply.h"
 #include "HttpRequest.h"
 #include "SquidTime.h"
 #include "URL.h"
 
 // flow and terminology:
 //     HTTP| --> receive --> encode --> write --> |network
 //     end | <-- send    <-- parse  <-- read  <-- |end
 
 // TODO: replace gotEncapsulated() with something faster; we call it often
 
 CBDATA_NAMESPACED_CLASS_INIT(Adaptation::Icap, ModXact);
 CBDATA_NAMESPACED_CLASS_INIT(Adaptation::Icap, ModXactLauncher);
 
 static const size_t TheBackupLimit = BodyPipe::MaxCapacity;
 
 Adaptation::Icap::ModXact::State::State()
 {
@@ -1087,68 +1087,62 @@
     if (!parsed) { // need more data
         debugs(93, 5, HERE << "parse failed, need more data, return false");
         head->reset();
         return false;
     }
 
     if (HttpRequest *r = dynamic_cast<HttpRequest*>(head))
         urlCanonical(r); // parse does not set HttpRequest::canonical
 
     debugs(93, 5, HERE << "parse success, consume " << head->hdr_sz << " bytes, return true");
     readBuf.consume(head->hdr_sz);
     return true;
 }
 
 void Adaptation::Icap::ModXact::decideOnParsingBody()
 {
     if (gotEncapsulated("res-body") || gotEncapsulated("req-body")) {
         debugs(93, 5, HERE << "expecting a body");
         state.parsing = State::psBody;
         replyHttpBodySize = 0;
-        bodyParser = new ChunkedCodingParser;
+        bodyParser = new Http1::TeChunkedParser;
         makeAdaptedBodyPipe("adapted response from the ICAP server");
         Must(state.sending == State::sendingAdapted);
     } else {
         debugs(93, 5, HERE << "not expecting a body");
         stopParsing();
         stopSending(true);
     }
 }
 
 void Adaptation::Icap::ModXact::parseBody()
 {
     Must(state.parsing == State::psBody);
     Must(bodyParser);
 
     debugs(93, 5, "have " << readBuf.length() << " body bytes to parse");
 
     // the parser will throw on errors
     BodyPipeCheckout bpc(*adapted.body_pipe);
-    // XXX: performance regression. SBuf-convert (or Parser-convert?) the chunked decoder.
-    MemBuf encodedData;
-    encodedData.init();
-    // NP: we must do this instead of pointing encodedData at the SBuf::rawContent
-    // because chunked decoder uses MemBuf::consume, which shuffles buffer bytes around.
-    encodedData.append(readBuf.rawContent(), readBuf.length());
-    const bool parsed = bodyParser->parse(&encodedData, &bpc.buf);
-    // XXX: httpChunkDecoder has consumed from MemBuf.
-    readBuf.consume(readBuf.length() - encodedData.contentSize());
+    bodyParser->setPayloadBuffer(&bpc.buf);
+    const bool parsed = bodyParser->parse(readBuf);
+    readBuf = bodyParser->remaining(); // sync buffers after parse
     bpc.checkIn();
 
     debugs(93, 5, "have " << readBuf.length() << " body bytes after parsed all: " << parsed);
     replyHttpBodySize += adapted.body_pipe->buf().contentSize();
 
     // TODO: expose BodyPipe::putSize() to make this check simpler and clearer
     // TODO: do we really need this if we disable when sending headers?
     if (adapted.body_pipe->buf().contentSize() > 0) { // parsed something sometime
         disableRepeats("sent adapted content");
         disableBypass("sent adapted content", true);
     }
 
     if (parsed) {
         if (state.readyForUob && bodyParser->useOriginBody >= 0) {
             prepPartialBodyEchoing(
                 static_cast<uint64_t>(bodyParser->useOriginBody));
             stopParsing();
             return;
         }
 

=== modified file 'src/adaptation/icap/ModXact.h'
--- src/adaptation/icap/ModXact.h	2015-01-13 07:25:36 +0000
+++ src/adaptation/icap/ModXact.h	2015-06-01 19:48:29 +0000
@@ -1,49 +1,48 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_ICAPMODXACT_H
 #define SQUID_ICAPMODXACT_H
 
 #include "AccessLogEntry.h"
 #include "adaptation/icap/InOut.h"
 #include "adaptation/icap/Launcher.h"
 #include "adaptation/icap/Xaction.h"
 #include "BodyPipe.h"
+#include "http/one/forward.h"
 
 /*
  * ICAPModXact implements ICAP REQMOD and RESPMOD transaction using
  * ICAPXaction as the base. The ICAPModXact receives a virgin HTTP message
  * from an ICAP vecoring point, (a.k.a., initiator), communicates with the
  * ICAP server, and sends the adapted HTTP message headers back.
  * Virgin/adapted HTTP message body is reveived/sent using BodyPipe
  * interface. The initiator (or its associate) is expected to send and/or
  * receive the HTTP body.
  */
 
-class ChunkedCodingParser;
-
 namespace Adaptation
 {
 namespace Icap
 {
 
 // estimated future presence and size of something (e.g., HTTP body)
 
 class SizedEstimate
 {
 
 public:
     SizedEstimate(); // not expected by default
     void expect(int64_t aSize); // expect with any, even unknown size
     bool expected() const;
 
     /* other members can be accessed iff expected() */
 
     bool knownSize() const;
     uint64_t size() const; // can be accessed iff knownSize()
 
@@ -233,41 +232,41 @@
     void stopBackup();
 
     virtual void fillPendingStatus(MemBuf &buf) const;
     virtual void fillDoneStatus(MemBuf &buf) const;
     virtual bool fillVirginHttpHeader(MemBuf&) const;
 
 private:
     void packHead(MemBuf &httpBuf, const HttpMsg *head);
     void encapsulateHead(MemBuf &icapBuf, const char *section, MemBuf &httpBuf, const HttpMsg *head);
     bool gotEncapsulated(const char *section) const;
     void checkConsuming();
 
     virtual void finalizeLogInfo();
 
     SizedEstimate virginBody;
     VirginBodyAct virginBodyWriting; // virgin body writing state
     VirginBodyAct virginBodySending;  // virgin body sending state
     uint64_t virginConsumed;        // virgin data consumed so far
     Preview preview; // use for creating (writing) the preview
 
-    ChunkedCodingParser *bodyParser; // ICAP response body parser
+    Http1::TeChunkedParser *bodyParser; // ICAP response body parser
 
     bool canStartBypass; // enables bypass of transaction failures
     bool protectGroupBypass; // protects ServiceGroup-wide bypass of failures
 
     /**
      * size of HTTP header in ICAP reply or -1 if there is not any encapsulated
      * message data
      */
     int64_t replyHttpHeaderSize;
     /**
      * size of dechunked HTTP body in ICAP reply or -1 if there is not any
      * encapsulated message data
      */
     int64_t replyHttpBodySize;
 
     int adaptHistoryId; ///< adaptation history slot reservation
 
     class State
     {
 

=== modified file 'src/client_side.cc'
--- src/client_side.cc	2015-05-26 17:25:04 +0000
+++ src/client_side.cc	2015-06-01 19:48:10 +0000
@@ -46,64 +46,64 @@
  * The request is *immediately* kicked off, and data flows through
  * to clientSocketRecipient.
  *
  \par
  * If the data that arrives at clientSocketRecipient is not for the current
  * request, clientSocketRecipient simply returns, without requesting more
  * data, or sending it.
  *
  \par
  * ClientKeepAliveNextRequest will then detect the presence of data in
  * the next ClientHttpRequest, and will send it, restablishing the
  * data flow.
  */
 
 #include "squid.h"
 #include "acl/FilledChecklist.h"
 #include "anyp/PortCfg.h"
 #include "base/Subscription.h"
 #include "base/TextException.h"
 #include "CachePeer.h"
-#include "ChunkedCodingParser.h"
 #include "client_db.h"
 #include "client_side.h"
 #include "client_side_reply.h"
 #include "client_side_request.h"
 #include "ClientRequestContext.h"
 #include "clientStream.h"
 #include "comm.h"
 #include "comm/Connection.h"
 #include "comm/Loops.h"
 #include "comm/Read.h"
 #include "comm/TcpAcceptor.h"
 #include "comm/Write.h"
 #include "CommCalls.h"
 #include "errorpage.h"
 #include "fd.h"
 #include "fde.h"
 #include "fqdncache.h"
 #include "FwdState.h"
 #include "globals.h"
 #include "helper.h"
 #include "helper/Reply.h"
 #include "http.h"
 #include "http/one/RequestParser.h"
+#include "http/one/TeChunkedParser.h"
 #include "HttpHdrContRange.h"
 #include "HttpHeaderTools.h"
 #include "HttpReply.h"
 #include "HttpRequest.h"
 #include "ident/Config.h"
 #include "ident/Ident.h"
 #include "internal.h"
 #include "ipc/FdNotes.h"
 #include "ipc/StartListening.h"
 #include "log/access_log.h"
 #include "MemBuf.h"
 #include "MemObject.h"
 #include "mime_header.h"
 #include "parser/Tokenizer.h"
 #include "profiler/Profiler.h"
 #include "rfc1738.h"
 #include "servers/forward.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
 #include "StatCounters.h"
@@ -3188,96 +3188,89 @@
 ConnStateData::handleReadData()
 {
     // if we are reading a body, stuff data into the body pipe
     if (bodyPipe != NULL)
         return handleRequestBodyData();
     return true;
 }
 
 /**
  * called when new request body data has been buffered in in.buf
  * may close the connection if we were closing and piped everything out
  *
  * \retval false called comm_close or setReplyToError (the caller should bail)
  * \retval true  we did not call comm_close or setReplyToError
  */
 bool
 ConnStateData::handleRequestBodyData()
 {
     assert(bodyPipe != NULL);
 
-    size_t putSize = 0;
-
     if (in.bodyParser) { // chunked encoding
-        if (const err_type error = handleChunkedRequestBody(putSize)) {
+        if (const err_type error = handleChunkedRequestBody()) {
             abortChunkedRequestBody(error);
             return false;
         }
     } else { // identity encoding
         debugs(33,5, HERE << "handling plain request body for " << clientConnection);
-        putSize = bodyPipe->putMoreData(in.buf.c_str(), in.buf.length());
+        const size_t putSize = bodyPipe->putMoreData(in.buf.c_str(), in.buf.length());
+        if (putSize > 0)
+            consumeInput(putSize);
+
         if (!bodyPipe->mayNeedMoreData()) {
             // BodyPipe will clear us automagically when we produced everything
             bodyPipe = NULL;
         }
     }
 
-    if (putSize > 0)
-        consumeInput(putSize);
-
     if (!bodyPipe) {
         debugs(33,5, HERE << "produced entire request body for " << clientConnection);
 
         if (const char *reason = stoppedSending()) {
             /* we've finished reading like good clients,
              * now do the close that initiateClose initiated.
              */
             debugs(33, 3, HERE << "closing for earlier sending error: " << reason);
             clientConnection->close();
             return false;
         }
     }
 
     return true;
 }
 
 /// parses available chunked encoded body bytes, checks size, returns errors
 err_type
-ConnStateData::handleChunkedRequestBody(size_t &putSize)
+ConnStateData::handleChunkedRequestBody()
 {
     debugs(33, 7, "chunked from " << clientConnection << ": " << in.buf.length());
 
     try { // the parser will throw on errors
 
         if (in.buf.isEmpty()) // nothing to do
             return ERR_NONE;
 
-        MemBuf raw; // ChunkedCodingParser only works with MemBufs
-        // add one because MemBuf will assert if it cannot 0-terminate
-        raw.init(in.buf.length(), in.buf.length()+1);
-        raw.append(in.buf.c_str(), in.buf.length());
-
-        const mb_size_t wasContentSize = raw.contentSize();
         BodyPipeCheckout bpc(*bodyPipe);
-        const bool parsed = in.bodyParser->parse(&raw, &bpc.buf);
+        in.bodyParser->setPayloadBuffer(&bpc.buf);
+        const bool parsed = in.bodyParser->parse(in.buf);
+        in.buf = in.bodyParser->remaining(); // sync buffers
         bpc.checkIn();
-        putSize = wasContentSize - raw.contentSize();
 
         // dechunk then check: the size limit applies to _dechunked_ content
         if (clientIsRequestBodyTooLargeForPolicy(bodyPipe->producedSize()))
             return ERR_TOO_BIG;
 
         if (parsed) {
             finishDechunkingRequest(true);
             Must(!bodyPipe);
             return ERR_NONE; // nil bodyPipe implies body end for the caller
         }
 
         // if chunk parser needs data, then the body pipe must need it too
         Must(!in.bodyParser->needsMoreData() || bodyPipe->mayNeedMoreData());
 
         // if parser needs more space and we can consume nothing, we will stall
         Must(!in.bodyParser->needsMoreSpace() || bodyPipe->buf().hasContent());
     } catch (...) { // TODO: be more specific
         debugs(33, 3, HERE << "malformed chunks" << bodyPipe->status());
         return ERR_INVALID_REQ;
     }
@@ -4692,41 +4685,41 @@
         clientConnection->close();
     }
 }
 
 void
 ConnStateData::expectNoForwarding()
 {
     if (bodyPipe != NULL) {
         debugs(33, 4, HERE << "no consumer for virgin body " << bodyPipe->status());
         bodyPipe->expectNoConsumption();
     }
 }
 
 /// initialize dechunking state
 void
 ConnStateData::startDechunkingRequest()
 {
     Must(bodyPipe != NULL);
     debugs(33, 5, HERE << "start dechunking" << bodyPipe->status());
     assert(!in.bodyParser);
-    in.bodyParser = new ChunkedCodingParser;
+    in.bodyParser = new Http1::TeChunkedParser;
 }
 
 /// put parsed content into input buffer and clean up
 void
 ConnStateData::finishDechunkingRequest(bool withSuccess)
 {
     debugs(33, 5, HERE << "finish dechunking: " << withSuccess);
 
     if (bodyPipe != NULL) {
         debugs(33, 7, HERE << "dechunked tail: " << bodyPipe->status());
         BodyPipe::Pointer myPipe = bodyPipe;
         stopProducingFor(bodyPipe, withSuccess); // sets bodyPipe->bodySize()
         Must(!bodyPipe); // we rely on it being nil after we are done with body
         if (withSuccess) {
             Must(myPipe->bodySizeKnown());
             ClientSocketContext::Pointer context = getCurrentContext();
             if (context != NULL && context->http && context->http->request)
                 context->http->request->setContentLength(myPipe->bodySize());
         }
     }

=== modified file 'src/client_side.h'
--- src/client_side.h	2015-04-10 08:54:13 +0000
+++ src/client_side.h	2015-06-01 19:48:21 +0000
@@ -11,41 +11,40 @@
 #ifndef SQUID_CLIENTSIDE_H
 #define SQUID_CLIENTSIDE_H
 
 #include "clientStreamForward.h"
 #include "comm.h"
 #include "helper/forward.h"
 #include "http/forward.h"
 #include "HttpControlMsg.h"
 #include "ipc/FdNotes.h"
 #include "SBuf.h"
 #if USE_AUTH
 #include "auth/UserRequest.h"
 #endif
 #if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
 class ConnStateData;
 class ClientHttpRequest;
 class clientStreamNode;
-class ChunkedCodingParser;
 namespace AnyP
 {
 class PortCfg;
 } // namespace Anyp
 
 /**
  * Badly named.
  * This is in fact the processing context for a single HTTP request.
  *
  * Managing what has been done, and what happens next to the data buffer
  * holding what we hope is an HTTP request.
  *
  * Parsing is still a mess of global functions done in conjunction with the
  * real socket controller which generated ClientHttpRequest.
  * It also generates one of us and passes us control from there based on
  * the results of the parse.
  *
  * After that all the request interpretation and adaptation is in our scope.
  * Then finally the reply fetcher is created by this and we get the result
  * back. Which we then have to manage writing of it to the ConnStateData.
@@ -191,41 +190,41 @@
     void receivedFirstByte();
 
     // HttpControlMsgSink API
     virtual void sendControlMsg(HttpControlMsg msg);
 
     // Client TCP connection details from comm layer.
     Comm::ConnectionPointer clientConnection;
 
     /**
      * The transfer protocol currently being spoken on this connection.
      * HTTP/1 CONNECT and HTTP/2 SETTINGS offers the ability to change
      * protocols on the fly.
      */
     AnyP::ProtocolVersion transferProtocol;
 
     struct In {
         In();
         ~In();
         bool maybeMakeSpaceAvailable();
 
-        ChunkedCodingParser *bodyParser; ///< parses chunked request body
+        Http1::TeChunkedParser *bodyParser; ///< parses chunked request body
         SBuf buf;
     } in;
 
     /** number of body bytes we need to comm_read for the "current" request
      *
      * \retval 0         We do not need to read any [more] body bytes
      * \retval negative  May need more but do not know how many; could be zero!
      * \retval positive  Need to read exactly that many more body bytes
      */
     int64_t mayNeedToReadMoreBody() const;
 
 #if USE_AUTH
     /**
      * Fetch the user details for connection based authentication
      * NOTE: this is ONLY connection based because NTLM and Negotiate is against HTTP spec.
      */
     const Auth::UserRequest::Pointer &getAuth() const { return auth_; }
 
     /**
      * Set the user details for connection-based authentication to use from now until connection closure.
@@ -406,41 +405,41 @@
 
     /// ClientStream calls this to supply response header (once) and data
     /// for the current ClientSocketContext.
     virtual void handleReply(HttpReply *header, StoreIOBuffer receivedData) = 0;
 
     /// remove no longer needed leading bytes from the input buffer
     void consumeInput(const size_t byteCount);
 
     /* TODO: Make the methods below (at least) non-public when possible. */
 
     /// stop parsing the request and create context for relaying error info
     ClientSocketContext *abortRequestParsing(const char *const errUri);
 
     /// client data which may need to forward as-is to server after an
     /// on_unsupported_protocol tunnel decision.
     SBuf preservedClientData;
 protected:
     void startDechunkingRequest();
     void finishDechunkingRequest(bool withSuccess);
     void abortChunkedRequestBody(const err_type error);
-    err_type handleChunkedRequestBody(size_t &putSize);
+    err_type handleChunkedRequestBody();
 
     void startPinnedConnectionMonitoring();
     void clientPinnedConnectionRead(const CommIoCbParams &io);
 
     /// parse input buffer prefix into a single transfer protocol request
     /// return NULL to request more header bytes (after checking any limits)
     /// use abortRequestParsing() to handle parsing errors w/o creating request
     virtual ClientSocketContext *parseOneRequest() = 0;
 
     /// start processing a freshly parsed request
     virtual void processParsedRequest(ClientSocketContext *context) = 0;
 
     /// returning N allows a pipeline of 1+N requests (see pipeline_prefetch)
     virtual int pipelinePrefetchMax() const;
 
     /// timeout to use when waiting for the next request
     virtual time_t idleTimeout() const = 0;
 
     BodyPipe::Pointer bodyPipe; ///< set when we are reading request body
 

=== modified file 'src/http.cc'
--- src/http.cc	2015-04-27 09:52:02 +0000
+++ src/http.cc	2015-06-01 19:47:47 +0000
@@ -2,53 +2,53 @@
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 /* DEBUG: section 11    Hypertext Transfer Protocol (HTTP) */
 
 /*
  * Anonymizing patch by lutz at as-node.jena.thur.de
  * have a look into http-anon.c to get more informations.
  */
 
 #include "squid.h"
 #include "acl/FilledChecklist.h"
 #include "base/AsyncJobCalls.h"
 #include "base/TextException.h"
 #include "base64.h"
 #include "CachePeer.h"
-#include "ChunkedCodingParser.h"
 #include "client_side.h"
 #include "comm/Connection.h"
 #include "comm/Read.h"
 #include "comm/Write.h"
 #include "CommRead.h"
 #include "err_detail_type.h"
 #include "errorpage.h"
 #include "fd.h"
 #include "fde.h"
 #include "globals.h"
 #include "http.h"
 #include "http/one/ResponseParser.h"
+#include "http/one/TeChunkedParser.h"
 #include "HttpControlMsg.h"
 #include "HttpHdrCc.h"
 #include "HttpHdrContRange.h"
 #include "HttpHdrSc.h"
 #include "HttpHdrScTarget.h"
 #include "HttpHeaderTools.h"
 #include "HttpReply.h"
 #include "HttpRequest.h"
 #include "HttpStateFlags.h"
 #include "log/access_log.h"
 #include "MemBuf.h"
 #include "MemObject.h"
 #include "neighbors.h"
 #include "peer_proxy_negotiate_auth.h"
 #include "profiler/Profiler.h"
 #include "refresh.h"
 #include "RefreshPattern.h"
 #include "rfc1738.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
@@ -771,41 +771,41 @@
         newrep->sline.version.protocol = hp->messageProtocol().protocol;
         newrep->sline.version.major = hp->messageProtocol().major;
         newrep->sline.version.minor = hp->messageProtocol().minor;
         debugs(11, 2, "error parsing response headers mime block");
     }
 
     // done with Parser, now process using the HttpReply
     hp = NULL;
 
     newrep->removeStaleWarnings();
 
     if (newrep->sline.protocol == AnyP::PROTO_HTTP && newrep->sline.status() >= 100 && newrep->sline.status() < 200) {
         handle1xx(newrep);
         ctx_exit(ctx);
         return;
     }
 
     flags.chunked = false;
     if (newrep->sline.protocol == AnyP::PROTO_HTTP && newrep->header.chunked()) {
         flags.chunked = true;
-        httpChunkDecoder = new ChunkedCodingParser;
+        httpChunkDecoder = new Http1::TeChunkedParser;
     }
 
     if (!peerSupportsConnectionPinning())
         request->flags.connectionAuthDisabled = true;
 
     HttpReply *vrep = setVirginReply(newrep);
     flags.headers_parsed = true;
 
     keepaliveAccounting(vrep);
 
     checkDateSkew(vrep);
 
     processSurrogateControl (vrep);
 
     request->hier.peer_reply_status = newrep->sline.status();
 
     ctx_exit(ctx);
 }
 
 /// ignore or start forwarding the 1xx response (a.k.a., control message)
@@ -1376,49 +1376,43 @@
 HttpStateData::writeReplyBody()
 {
     truncateVirginBody(); // if needed
     const char *data = inBuf.rawContent();
     int len = inBuf.length();
     addVirginReplyBody(data, len);
     inBuf.consume(len);
 }
 
 bool
 HttpStateData::decodeAndWriteReplyBody()
 {
     const char *data = NULL;
     int len;
     bool wasThereAnException = false;
     assert(flags.chunked);
     assert(httpChunkDecoder);
     SQUID_ENTER_THROWING_CODE();
     MemBuf decodedData;
     decodedData.init();
-    // XXX: performance regression. SBuf-convert (or Parser-convert?) the chunked decoder.
-    MemBuf encodedData;
-    encodedData.init();
-    // NP: we must do this instead of pointing encodedData at the SBuf::rawContent
-    // because chunked decoder uses MemBuf::consume, which shuffles buffer bytes around.
-    encodedData.append(inBuf.rawContent(), inBuf.length());
-    const bool doneParsing = httpChunkDecoder->parse(&encodedData,&decodedData);
-    // XXX: httpChunkDecoder has consumed from MemBuf.
-    inBuf.consume(inBuf.length() - encodedData.contentSize());
+    httpChunkDecoder->setPayloadBuffer(&decodedData);
+    const bool doneParsing = httpChunkDecoder->parse(inBuf);
+    inBuf = httpChunkDecoder->remaining(); // sync buffers after parse
     len = decodedData.contentSize();
     data=decodedData.content();
     addVirginReplyBody(data, len);
     if (doneParsing) {
         lastChunk = 1;
         flags.do_next_read = false;
     }
     SQUID_EXIT_THROWING_CODE(wasThereAnException);
     return wasThereAnException;
 }
 
 /**
  * processReplyBody has two purposes:
  *  1 - take the reply body data, if any, and put it into either
  *      the StoreEntry, or give it over to ICAP.
  *  2 - see if we made it to the end of the response (persistent
  *      connections and such)
  */
 void
 HttpStateData::processReplyBody()

=== modified file 'src/http.h'
--- src/http.h	2015-03-17 02:53:05 +0000
+++ src/http.h	2015-06-01 19:47:33 +0000
@@ -1,36 +1,36 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_HTTP_H
 #define SQUID_HTTP_H
 
 #include "clients/Client.h"
 #include "comm.h"
+#include "http/forward.h"
 #include "HttpStateFlags.h"
 
-class ChunkedCodingParser;
 class FwdState;
 class HttpHeader;
 
 class HttpStateData : public Client
 {
     CBDATA_CLASS(HttpStateData);
 
 public:
     HttpStateData(FwdState *);
     ~HttpStateData();
 
     static void httpBuildRequestHeader(HttpRequest * request,
                                        StoreEntry * entry,
                                        const AccessLogEntryPointer &al,
                                        HttpHeader * hdr_out,
                                        const HttpStateFlags &flags);
 
     virtual const Comm::ConnectionPointer & dataConnection() const;
     /* should be private */
     bool sendRequest();
@@ -103,34 +103,34 @@
     virtual void handleRequestBodyProducerAborted();
 
     void writeReplyBody();
     bool decodeAndWriteReplyBody();
     bool finishingBrokenPost();
     bool finishingChunkedRequest();
     void doneSendingRequestBody();
     void requestBodyHandler(MemBuf &);
     virtual void sentRequestBody(const CommIoCbParams &io);
     void wroteLast(const CommIoCbParams &io);
     void sendComplete();
     void httpStateConnClosed(const CommCloseCbParams &params);
     void httpTimeout(const CommTimeoutCbParams &params);
 
     mb_size_t buildRequestPrefix(MemBuf * mb);
     static bool decideIfWeDoRanges (HttpRequest * orig_request);
     bool peerSupportsConnectionPinning() const;
 
     /// Parser being used at present to parse the HTTP/ICY server response.
     Http1::ResponseParserPointer hp;
-    ChunkedCodingParser *httpChunkDecoder;
+    Http1::TeChunkedParser *httpChunkDecoder;
 
     /// amount of message payload/body received so far.
     int64_t payloadSeen;
     /// positive when we read more than we wanted
     int64_t payloadTruncated;
 };
 
 int httpCachable(const HttpRequestMethod&);
 void httpStart(FwdState *);
 const char *httpMakeVaryMark(HttpRequest * request, HttpReply const * reply);
 
 #endif /* SQUID_HTTP_H */
 

=== modified file 'src/http/one/Makefile.am'
--- src/http/one/Makefile.am	2015-01-20 12:33:23 +0000
+++ src/http/one/Makefile.am	2015-06-01 19:43:57 +0000
@@ -1,20 +1,22 @@
 ## Copyright (C) 1996-2015 The Squid Software Foundation and contributors
 ##
 ## Squid software is distributed under GPLv2+ license and includes
 ## contributions from numerous individuals and organizations.
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
 include $(top_srcdir)/src/Common.am
 include $(top_srcdir)/src/TestHeaders.am
 
 noinst_LTLIBRARIES = libhttp1.la
 
 libhttp1_la_SOURCES = \
 	forward.h \
 	Parser.cc \
 	Parser.h \
 	RequestParser.cc \
 	RequestParser.h \
 	ResponseParser.cc \
-	ResponseParser.h
+	ResponseParser.h \
+	TeChunkedParser.cc \
+	TeChunkedParser.h

=== modified file 'src/http/one/Parser.h'
--- src/http/one/Parser.h	2015-02-20 03:25:12 +0000
+++ src/http/one/Parser.h	2015-04-12 11:05:50 +0000
@@ -6,44 +6,47 @@
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef _SQUID_SRC_HTTP_ONE_PARSER_H
 #define _SQUID_SRC_HTTP_ONE_PARSER_H
 
 #include "anyp/ProtocolVersion.h"
 #include "http/one/forward.h"
 #include "http/StatusCode.h"
 #include "SBuf.h"
 
 namespace Parser {
 class Tokenizer;
 }
 
 namespace Http {
 namespace One {
 
 // Parser states
 enum ParseState {
-    HTTP_PARSE_NONE,     ///< initialized, but nothing usefully parsed yet
-    HTTP_PARSE_FIRST,    ///< HTTP/1 message first-line
-    HTTP_PARSE_MIME,     ///< HTTP/1 mime-header block
-    HTTP_PARSE_DONE      ///< parsed a message header, or reached a terminal syntax error
+    HTTP_PARSE_NONE,      ///< initialized, but nothing usefully parsed yet
+    HTTP_PARSE_FIRST,     ///< HTTP/1 message first-line
+    HTTP_PARSE_CHUNK_SZ,  ///< HTTP/1.1 chunked encoding chunk-size
+    HTTP_PARSE_CHUNK_EXT, ///< HTTP/1.1 chunked encoding chunk-ext
+    HTTP_PARSE_CHUNK,     ///< HTTP/1.1 chunked encoding chunk-data
+    HTTP_PARSE_MIME,      ///< HTTP/1 mime-header block
+    HTTP_PARSE_DONE       ///< parsed a message header, or reached a terminal syntax error
 };
 
 /** HTTP/1.x protocol parser
  *
  * Works on a raw character I/O buffer and tokenizes the content into
  * the major CRLF delimited segments of an HTTP/1 procotol message:
  *
  * \item first-line (request-line / simple-request / status-line)
  * \item mime-header 0*( header-name ':' SP field-value CRLF)
  */
 class Parser : public RefCountable
 {
 public:
     typedef SBuf::size_type size_type;
 
     Parser() : parseStatusCode(Http::scNone), parsingStage_(HTTP_PARSE_NONE) {}
     virtual ~Parser() {}
 
     /// Set this parser back to a default state.
     /// Will DROP any reference to a buffer (does not free).

=== renamed file 'src/ChunkedCodingParser.cc' => 'src/http/one/TeChunkedParser.cc'
--- src/ChunkedCodingParser.cc	2015-01-13 07:25:36 +0000
+++ src/http/one/TeChunkedParser.cc	2015-06-01 19:45:00 +0000
@@ -1,311 +1,214 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #include "squid.h"
 #include "base/TextException.h"
-#include "ChunkedCodingParser.h"
 #include "Debug.h"
+#include "http/one/TeChunkedParser.h"
+#include "http/ProtocolVersion.h"
 #include "MemBuf.h"
+#include "parser/Tokenizer.h"
 #include "Parsing.h"
 
-ChunkedCodingParser::Step ChunkedCodingParser::psChunkSize = &ChunkedCodingParser::parseChunkSize;
-ChunkedCodingParser::Step ChunkedCodingParser::psUnusedChunkExtension = &ChunkedCodingParser::parseUnusedChunkExtension;
-ChunkedCodingParser::Step ChunkedCodingParser::psLastChunkExtension = &ChunkedCodingParser::parseLastChunkExtension;
-ChunkedCodingParser::Step ChunkedCodingParser::psChunkBody = &ChunkedCodingParser::parseChunkBody;
-ChunkedCodingParser::Step ChunkedCodingParser::psChunkEnd = &ChunkedCodingParser::parseChunkEnd;
-ChunkedCodingParser::Step ChunkedCodingParser::psTrailer = &ChunkedCodingParser::parseTrailer;
-ChunkedCodingParser::Step ChunkedCodingParser::psMessageEnd = &ChunkedCodingParser::parseMessageEnd;
-
-ChunkedCodingParser::ChunkedCodingParser()
+Http::One::TeChunkedParser::TeChunkedParser()
 {
-    reset();
+    // chunked encoding only exists in HTTP/1.1
+    Http1::Parser::msgProtocol_ = Http::ProtocolVersion(1,1);
+
+    clear();
 }
 
-void ChunkedCodingParser::reset()
+void
+Http::One::TeChunkedParser::clear()
 {
-    theStep = psChunkSize;
+    parsingStage_ = Http1::HTTP_PARSE_NONE;
+    buf_.clear();
     theChunkSize = theLeftBodySize = 0;
-    doNeedMoreData = false;
-    theIn = theOut = NULL;
+    theOut = NULL;
     useOriginBody = -1;
-    inQuoted = inSlashed = false;
 }
 
-bool ChunkedCodingParser::parse(MemBuf *rawData, MemBuf *parsedContent)
+bool
+Http::One::TeChunkedParser::parse(const SBuf &aBuf)
 {
-    Must(rawData && parsedContent);
-    theIn = rawData;
-    theOut = parsedContent;
-
-    // we must reset this all the time so that mayContinue() lets us
-    // output more content if we stopped due to needsMoreSpace() before
-    doNeedMoreData = !theIn->hasContent();
+    buf_ = aBuf; // sync buffers first so calls to remaining() work properly if nothing done.
 
-    while (mayContinue()) {
-        (this->*theStep)();
-    }
+    if (buf_.isEmpty()) // nothing to do (yet)
+        return false;
 
-    return theStep == psMessageEnd;
-}
+    debugs(74, DBG_DATA, "Parse buf={length=" << aBuf.length() << ", data='" << aBuf << "'}");
 
-bool ChunkedCodingParser::needsMoreData() const
-{
-    return doNeedMoreData;
-}
+    Must(!buf_.isEmpty() && theOut);
 
-bool ChunkedCodingParser::needsMoreSpace() const
-{
-    assert(theOut);
-    return theStep == psChunkBody && !theOut->hasPotentialSpace();
+    if (parsingStage_ == Http1::HTTP_PARSE_NONE)
+        parsingStage_ = Http1::HTTP_PARSE_CHUNK_SZ;
+
+    ::Parser::Tokenizer tok(buf_);
+
+    // loop for as many chunks as we can
+    // use do-while instead of while so that we can incrementally
+    // restart in the middle of a chunk/frame
+    do {
+
+        if (parsingStage_ == Http1::HTTP_PARSE_CHUNK_EXT && !parseChunkExtension(tok, theChunkSize))
+            return false;
+
+        if (parsingStage_ == Http1::HTTP_PARSE_CHUNK && !parseChunkBody(tok))
+            return false;
+
+        if (parsingStage_ == Http1::HTTP_PARSE_MIME && !grabMimeBlock("Trailers", 64*1024 /* 64KB max */))
+            return false;
+
+        // loop for as many chunks as we can
+    } while (parsingStage_ == Http1::HTTP_PARSE_CHUNK_SZ && parseChunkSize(tok));
+
+    return !needsMoreData() && !needsMoreSpace();
 }
 
-bool ChunkedCodingParser::mayContinue() const
+bool
+Http::One::TeChunkedParser::needsMoreSpace() const
 {
-    return !needsMoreData() && !needsMoreSpace() && theStep != psMessageEnd;
+    assert(theOut);
+    return parsingStage_ == Http1::HTTP_PARSE_CHUNK && !theOut->hasPotentialSpace();
 }
 
-void ChunkedCodingParser::parseChunkSize()
+/// RFC 7230 section 4.1 chunk-size
+bool
+Http::One::TeChunkedParser::parseChunkSize(::Parser::Tokenizer &tok)
 {
     Must(theChunkSize <= 0); // Should(), really
 
-    const char *p = theIn->content();
-    while (p < theIn->space() && xisxdigit(*p)) ++p;
-    if (p >= theIn->space()) {
-        doNeedMoreData = true;
-        return;
-    }
-
     int64_t size = -1;
-    if (StringToInt64(theIn->content(), size, &p, 16)) {
+    if (tok.int64(size, 16, false) && !tok.atEnd()) {
         if (size < 0)
             throw TexcHere("negative chunk size");
 
         theChunkSize = theLeftBodySize = size;
         debugs(94,7, "found chunk: " << theChunkSize);
-        // parse chunk extensions only in the last-chunk
-        if (theChunkSize)
-            theStep = psUnusedChunkExtension;
-        else {
-            theIn->consume(p - theIn->content());
-            theStep = psLastChunkExtension;
-        }
-    } else
-        throw TexcHere("corrupted chunk size");
-}
+        buf_ = tok.remaining(); // parse checkpoint
+        parsingStage_ = Http1::HTTP_PARSE_CHUNK_EXT;
+        return true;
 
-void ChunkedCodingParser::parseUnusedChunkExtension()
-{
-    size_t crlfBeg = 0;
-    size_t crlfEnd = 0;
-    if (findCrlf(crlfBeg, crlfEnd, inQuoted, inSlashed)) {
-        inQuoted = inSlashed = false;
-        theIn->consume(crlfEnd);
-        theStep = theChunkSize ? psChunkBody : psTrailer;
-    } else {
-        theIn->consume(theIn->contentSize());
-        doNeedMoreData = true;
+    } else if (tok.atEnd()) {
+        return false; // need more data
     }
+
+    // else error
+    throw TexcHere("corrupted chunk size");
+    return false; // should not be reachable
 }
 
-void ChunkedCodingParser::parseChunkBody()
+/**
+ * Parses a set of RFC 7230 section 4.1.1 chunk-ext
+ * http://tools.ietf.org/html/rfc7230#section-4.1.1
+ *
+ *   chunk-ext      = *( ";" chunk-ext-name [ "=" chunk-ext-val ] )
+ *   chunk-ext-name = token
+ *   chunk-ext-val  = token / quoted-string
+ *
+ * ICAP 'use-original-body=N' extension is supported.
+ */
+bool
+Http::One::TeChunkedParser::parseChunkExtension(::Parser::Tokenizer &tok, bool skipKnown)
 {
-    Must(theLeftBodySize > 0); // Should, really
+    // TODO implement a proper quoted-string Tokenizer method
+    static const CharacterSet qString = CharacterSet("qString","\"\r\n").add('\0').complement();
 
-    const size_t availSize = min(theLeftBodySize, (uint64_t)theIn->contentSize());
-    const size_t safeSize = min(availSize, (size_t)theOut->potentialSpaceSize());
+    SBuf ext;
+    while (tok.skip(';') && tok.prefix(ext, CharacterSet::TCHAR)) {
 
-    doNeedMoreData = availSize < theLeftBodySize;
-    // and we may also need more space
+        // whole value part is optional. if no '=' expect next chunk-ext
+        if (tok.skip('=')) {
+
+            if (!skipKnown) {
+                if (ext.cmp("use-original-body",17) == 0 && tok.int64(useOriginBody, 10)) {
+                    debugs(94, 3, "Found chunk extension " << ext << "=" << useOriginBody);
+                    buf_ = tok.remaining(); // parse checkpoint
+                    continue;
+                }
+            }
 
-    theOut->append(theIn->content(), safeSize);
-    theIn->consume(safeSize);
-    theLeftBodySize -= safeSize;
+            debugs(94, 5, "skipping unknown chunk extension " << ext);
 
-    if (theLeftBodySize == 0)
-        theStep = psChunkEnd;
-    else
-        Must(needsMoreData() || needsMoreSpace());
-}
-
-void ChunkedCodingParser::parseChunkEnd()
-{
-    Must(theLeftBodySize == 0); // Should(), really
+            // unknown might have a value token ...
+            if (tok.skipAll(CharacterSet::TCHAR) && !tok.atEnd()) {
+                buf_ = tok.remaining(); // parse checkpoint
+                continue;
+            }
 
-    size_t crlfBeg = 0;
-    size_t crlfEnd = 0;
+            // ... or a quoted-string
+            if (tok.skipOne(CharacterSet::DQUOTE) && tok.skipAll(qString) && tok.skipOne(CharacterSet::DQUOTE)) {
+                buf_ = tok.remaining(); // parse checkpoint
+                continue;
+            }
 
-    if (findCrlf(crlfBeg, crlfEnd)) {
-        if (crlfBeg != 0) {
-            throw TexcHere("found data between chunk end and CRLF");
-            return;
+            // otherwise need more data OR corrupt syntax
+            break;
         }
 
-        theIn->consume(crlfEnd);
-        theChunkSize = 0; // done with the current chunk
-        theStep = psChunkSize;
-        return;
+        if (!tok.atEnd())
+            buf_ = tok.remaining(); // parse checkpoint (unless there might be more token name)
     }
 
-    doNeedMoreData = true;
-}
-
-void ChunkedCodingParser::parseTrailer()
-{
-    Must(theChunkSize == 0); // Should(), really
-
-    while (mayContinue())
-        parseTrailerHeader();
-}
-
-void ChunkedCodingParser::parseTrailerHeader()
-{
-    size_t crlfBeg = 0;
-    size_t crlfEnd = 0;
-
-    if (findCrlf(crlfBeg, crlfEnd)) {
+    if (tok.atEnd())
+        return false;
 
-#if TRAILERS_ARE_SUPPORTED
-        if (crlfBeg > 0)
-            theTrailer.append(theIn->content(), crlfEnd);
-#endif
-
-        theIn->consume(crlfEnd);
-
-        if (crlfBeg == 0)
-            theStep = psMessageEnd;
-
-        return;
+    if (skipLineTerminator(tok)) {
+        buf_ = tok.remaining(); // checkpoint
+        // non-0 chunk means data, 0-size means optional Trailer follows
+        parsingStage_ = theChunkSize ? Http1::HTTP_PARSE_CHUNK : Http1::HTTP_PARSE_MIME;
+        return true;
     }
 
-    doNeedMoreData = true;
-}
-
-void ChunkedCodingParser::parseMessageEnd()
-{
-    // termination step, should not be called
-    Must(false); // Should(), really
-}
-
-/// Finds next CRLF. Does not store parsing state.
-bool ChunkedCodingParser::findCrlf(size_t &crlfBeg, size_t &crlfEnd)
-{
-    bool quoted = false;
-    bool slashed = false;
-    return findCrlf(crlfBeg, crlfEnd, quoted, slashed);
+    throw TexcHere("corrupted chunk extension value");
+    return false;
 }
 
-/// Finds next CRLF. Parsing state stored in quoted and slashed
-/// parameters. Incremental: can resume when more data is available.
-bool ChunkedCodingParser::findCrlf(size_t &crlfBeg, size_t &crlfEnd, bool &quoted, bool &slashed)
+bool
+Http::One::TeChunkedParser::parseChunkBody(::Parser::Tokenizer &tok)
 {
-    // XXX: This code was copied, with permission, from another software.
-    // There is a similar and probably better code inside httpHeaderParse
-    // but it seems difficult to isolate due to parsing-unrelated bloat.
-    // Such isolation should probably be done before this class is used
-    // for handling of traffic "more external" than ICAP.
-
-    const char *buf = theIn->content();
-    size_t size = theIn->contentSize();
-
-    ssize_t crOff = -1;
-
-    for (size_t i = 0; i < size; ++i) {
-        if (slashed) {
-            slashed = false;
-            continue;
-        }
+    Must(theLeftBodySize > 0); // Should, really
 
-        const char c = buf[i];
+    buf_ = tok.remaining(); // sync buffers before buf_ use
 
-        // handle quoted strings
-        if (quoted) {
-            if (c == '\\')
-                slashed = true;
-            else if (c == '"')
-                quoted = false;
-
-            continue;
-        } else if (c == '"') {
-            quoted = true;
-            crOff = -1;
-            continue;
-        }
-
-        if (crOff < 0) { // looking for the first CR or LF
+    // TODO fix type mismatches and casting for these
+    const size_t availSize = min(theLeftBodySize, (uint64_t)buf_.length());
+    const size_t safeSize = min(availSize, (size_t)theOut->potentialSpaceSize());
 
-            if (c == '\n') {
-                crlfBeg = i;
-                crlfEnd = ++i;
-                return true;
-            }
+    theOut->append(buf_.rawContent(), safeSize);
+    buf_.consume(safeSize);
+    theLeftBodySize -= safeSize;
 
-            if (c == '\r')
-                crOff = i;
-        } else { // skipping CRs, looking for the first LF
-
-            if (c == '\n') {
-                crlfBeg = crOff;
-                crlfEnd = ++i;
-                return true;
-            }
+    tok.reset(buf_); // sync buffers after consume()
 
-            if (c != '\r')
-                crOff = -1;
-        }
-    }
+    if (theLeftBodySize == 0)
+        return parseChunkEnd(tok);
+    else
+        Must(needsMoreData() || needsMoreSpace());
 
-    return false;
+    return true;
 }
 
-// chunk-extension= *( ";" chunk-ext-name [ "=" chunk-ext-val ] )
-void ChunkedCodingParser::parseLastChunkExtension()
+bool
+Http::One::TeChunkedParser::parseChunkEnd(::Parser::Tokenizer &tok)
 {
-    size_t crlfBeg = 0;
-    size_t crlfEnd = 0;
-
-    if (!findCrlf(crlfBeg, crlfEnd)) {
-        doNeedMoreData = true;
-        return;
-    }
-
-    const char *const startExt = theIn->content();
-    const char *const endExt = theIn->content() + crlfBeg;
-
-    // chunk-extension starts at startExt and ends with LF at endEx
-    for (const char *p = startExt; p < endExt;) {
-
-        while (*p == ' ' || *p == '\t') ++p; // skip spaces before ';'
-
-        if (*p++ != ';') // each ext name=value pair is preceded with ';'
-            break;
-
-        while (*p == ' ' || *p == '\t') ++p; // skip spaces before name
+    Must(theLeftBodySize == 0); // Should(), really
 
-        if (p >= endExt)
-            break; // malformed extension: ';' without ext name=value pair
+    if (skipLineTerminator(tok)) {
+        buf_ = tok.remaining(); // parse checkpoint
+        theChunkSize = 0; // done with the current chunk
+        parsingStage_ = Http1::HTTP_PARSE_CHUNK_SZ;
+        return true;
 
-        const int extSize = endExt - p;
-        // TODO: we need debugData() stream manipulator to dump data
-        debugs(94,7, "Found chunk extension; size=" << extSize);
-
-        // TODO: support implied *LWS around '='
-        if (extSize > 18 && strncmp(p, "use-original-body=", 18) == 0) {
-            (void)StringToInt64(p+18, useOriginBody, &p, 10);
-            debugs(94, 3, HERE << "use-original-body=" << useOriginBody);
-            break; // remove to support more than just use-original-body
-        } else {
-            debugs(94, 5, HERE << "skipping unknown chunk extension");
-            // TODO: support quoted-string chunk-ext-val
-            while (p < endExt && *p != ';') ++p; // skip until the next ';'
-        }
+    } else if (!tok.atEnd()) {
+        throw TexcHere("found data between chunk end and CRLF");
     }
 
-    theIn->consume(crlfEnd);
-    theStep = theChunkSize ? psChunkBody : psTrailer;
+    return false;
 }
 

=== renamed file 'src/ChunkedCodingParser.h' => 'src/http/one/TeChunkedParser.h'
--- src/ChunkedCodingParser.h	2015-01-13 07:25:36 +0000
+++ src/http/one/TeChunkedParser.h	2015-06-01 19:46:19 +0000
@@ -1,84 +1,65 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
-#ifndef SQUID_CHUNKEDCODINGPARSER_H
-#define SQUID_CHUNKEDCODINGPARSER_H
+#ifndef SQUID_SRC_HTTP_ONE_TeChunkedParser_H
+#define SQUID_SRC_HTTP_ONE_TeChunkedParser_H
+
+#include "http/one/Parser.h"
 
 class MemBuf;
 
+namespace Http
+{
+namespace One
+{
+
 /**
- \ingroup ChunkEncodingAPI Chunked Encoding API
- \par
- * ChunkedCodingParser is an incremental parser for chunked transfer coding
- * used by HTTP and ICAP. The parser shovels content bytes from the raw
+ * An incremental parser for chunked transfer coding
+ * defined in RFC 7230 section 4.1.
+ * http://tools.ietf.org/html/rfc7230#section-4.1
+ *
+ * The parser shovels content bytes from the raw
  * input buffer into the content output buffer, both caller-supplied.
  * Ignores chunk extensions except for ICAP's ieof.
- * Has a trailer-handling placeholder.
+ * Trailers are available via mimeHeader() if wanted.
  */
-class ChunkedCodingParser
+class TeChunkedParser : public Http1::Parser
 {
-
 public:
-    ChunkedCodingParser();
-
-    void reset();
+    TeChunkedParser();
+    virtual ~TeChunkedParser() {theOut=NULL;/* we dont own this object */}
 
-    /**
-     \retval true    complete success
-     \retval false   needs more data
-     \throws ??      error.
-     */
-    bool parse(MemBuf *rawData, MemBuf *parsedContent);
+    /// set the buffer to be used to store decoded chunk data
+    void setPayloadBuffer(MemBuf *parsedContent) {theOut = parsedContent;}
 
-    bool needsMoreData() const;
     bool needsMoreSpace() const;
 
-private:
-    typedef void (ChunkedCodingParser::*Step)();
+    /* Http1::Parser API */
+    virtual void clear();
+    virtual bool parse(const SBuf &);
+    virtual Parser::size_type firstLineSize() const {return 0;} // has no meaning with multiple chunks
 
 private:
-    bool mayContinue() const;
-
-    void parseChunkSize();
-    void parseUnusedChunkExtension();
-    void parseLastChunkExtension();
-    void parseChunkBeg();
-    void parseChunkBody();
-    void parseChunkEnd();
-    void parseTrailer();
-    void parseTrailerHeader();
-    void parseMessageEnd();
+    bool parseChunkSize(::Parser::Tokenizer &tok);
+    bool parseChunkExtension(::Parser::Tokenizer &tok, bool skipKnown);
+    bool parseChunkBody(::Parser::Tokenizer &tok);
+    bool parseChunkEnd(::Parser::Tokenizer &tok);
 
-    bool findCrlf(size_t &crlfBeg, size_t &crlfEnd);
-    bool findCrlf(size_t &crlfBeg, size_t &crlfEnd, bool &quoted, bool &slashed);
-
-private:
-    static Step psChunkSize;
-    static Step psUnusedChunkExtension;
-    static Step psLastChunkExtension;
-    static Step psChunkBody;
-    static Step psChunkEnd;
-    static Step psTrailer;
-    static Step psMessageEnd;
-
-    MemBuf *theIn;
     MemBuf *theOut;
-
-    Step theStep;
     uint64_t theChunkSize;
     uint64_t theLeftBodySize;
-    bool doNeedMoreData;
-    bool inQuoted; ///< stores parsing state for incremental findCrlf
-    bool inSlashed; ///< stores parsing state for incremental findCrlf
 
 public:
     int64_t useOriginBody;
 };
 
-#endif /* SQUID_CHUNKEDCODINGPARSER_H */
+} // namespace One
+} // namespace Http
+
+#endif /* SQUID_SRC_HTTP_ONE_TeChunkedParser_H */
 

=== modified file 'src/http/one/forward.h'
--- src/http/one/forward.h	2015-01-20 12:33:23 +0000
+++ src/http/one/forward.h	2015-06-01 19:44:26 +0000
@@ -1,32 +1,34 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_SRC_HTTP_ONE_FORWARD_H
 #define SQUID_SRC_HTTP_ONE_FORWARD_H
 
 #include "base/RefCount.h"
 
 namespace Http {
 namespace One {
 
 class Parser;
 typedef RefCount<Http::One::Parser> ParserPointer;
 
+class TeChunkedParser;
+
 class RequestParser;
 typedef RefCount<Http::One::RequestParser> RequestParserPointer;
 
 class ResponseParser;
 typedef RefCount<Http::One::ResponseParser> ResponseParserPointer;
 
 } // namespace One
 } // namespace Http
 
 namespace Http1 = Http::One;
 
 #endif /* SQUID_SRC_HTTP_ONE_FORWARD_H */
 


From squid3 at treenet.co.nz  Mon Jun  1 23:33:03 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 02 Jun 2015 11:33:03 +1200
Subject: [squid-dev] [PATCH] Bug 3875 MimeIcon error handling
In-Reply-To: <555CA6C5.9080505@treenet.co.nz>
References: <555CA6C5.9080505@treenet.co.nz>
Message-ID: <556CEBAF.4060308@treenet.co.nz>

On 21/05/2015 3:22 a.m., Amos Jeffries wrote:
> This is an attempt to improve the MimeIcon reliability when filesystem
> I/O errors or others cause the icon data to not be loadable.
> 
> The loading process is re-worked to guarantee that once the
> MimeIon::created callback occurs it will result in a valid StoreEntry in
> the cache representing the wanted icon.
>  * If the image can be loaded without any issues it will be placed in
> the cache as a 200 response.
>  * If errors prevent the image being loaded or necessary parameters
> (size and mtime) being known a 204 object will be placed into the cache.
> 
> I have selected 204 as the representation of errors since the bug is not
> in the clients request (eliminating 400, 404, etc), a 500 would be
> revealing details about server internals unnecessarily often and incur
> extra complexity creating the error page. 204 also avoids needing to set
> and emit Content-Length header, and just enough different from 200 to
> use as a special-case test.
> 
> 
> 
> NP: It started with just correcting the errno usage, but other bugs
> promptly started appearing once I got to seriously testing this load
> process. So far it fixes:
> * several assertions resulting from StoreEntry being left invalid in
> cache limbo beween created hash entries and valid mem_obj data.
> * on startup 6+ repeated attempts to load absent icons files which dont
> exist in the filesystem.
> * buffer overfow on misconfigured or corrupt mime.conf file entries
> * incorrect debugs messages about file I/O errors
> * large error pages delivered when icons not installed (when it doesnt
> assert from the StoreEntry)
> 
> Amos
> 

If there are no objections I will appy this tomorrow.

Amos


From rousskov at measurement-factory.com  Tue Jun  2 00:23:30 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 01 Jun 2015 18:23:30 -0600
Subject: [squid-dev] [PATCH] Bug 3875 MimeIcon error handling
In-Reply-To: <556CEBAF.4060308@treenet.co.nz>
References: <555CA6C5.9080505@treenet.co.nz> <556CEBAF.4060308@treenet.co.nz>
Message-ID: <556CF782.2000109@measurement-factory.com>

On 06/01/2015 05:33 PM, Amos Jeffries wrote:
> On 21/05/2015 3:22 a.m., Amos Jeffries wrote:
>> This is an attempt to improve the MimeIcon reliability when filesystem
>> I/O errors or others cause the icon data to not be loadable.
>>
>> The loading process is re-worked to guarantee that once the
>> MimeIon::created callback occurs it will result in a valid StoreEntry in
>> the cache representing the wanted icon.
>>  * If the image can be loaded without any issues it will be placed in
>> the cache as a 200 response.
>>  * If errors prevent the image being loaded or necessary parameters
>> (size and mtime) being known a 204 object will be placed into the cache.
>>
>> I have selected 204 as the representation of errors since the bug is not
>> in the clients request (eliminating 400, 404, etc), a 500 would be
>> revealing details about server internals unnecessarily often and incur
>> extra complexity creating the error page. 204 also avoids needing to set
>> and emit Content-Length header, and just enough different from 200 to
>> use as a special-case test.
>>
>>
>>
>> NP: It started with just correcting the errno usage, but other bugs
>> promptly started appearing once I got to seriously testing this load
>> process. So far it fixes:
>> * several assertions resulting from StoreEntry being left invalid in
>> cache limbo beween created hash entries and valid mem_obj data.
>> * on startup 6+ repeated attempts to load absent icons files which dont
>> exist in the filesystem.
>> * buffer overfow on misconfigured or corrupt mime.conf file entries
>> * incorrect debugs messages about file I/O errors
>> * large error pages delivered when icons not installed (when it doesnt
>> assert from the StoreEntry)


> If there are no objections I will appy this tomorrow.

Using a successful 2xx code to indicate an error sounds like a mistake
to me. Moreover, 204 responses have special framing rules that increase
the chance of them being misinterpreted by poorly written clients.

If there are no better error codes, I suggest using a 503 Service
Unavailable response. If it is difficult to adjust the code to serve an
existing error message in this context, then just set Content-Length to
zero or close connection, whichever is easier.

You have mentioned that 204 "avoids needing to set [...] Content-Length
header", but AFAICT, the content length is just a setHeaders() parameter
which can be zero. In fact, your patch uses it! It looks like that part
of the argument against a true error response is invalid.

If you are sure your solution is better than doing nothing, please do
not interpret the above as an objection.


If you decide to commit this, please do include your NP paragraph to
document what kind of "reliability" problems this patch fixes.


Thank you,

Alex.


From squid3 at treenet.co.nz  Tue Jun  2 01:08:34 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 02 Jun 2015 13:08:34 +1200
Subject: [squid-dev] [PATCH] Bug 3875 MimeIcon error handling
In-Reply-To: <556CF782.2000109@measurement-factory.com>
References: <555CA6C5.9080505@treenet.co.nz> <556CEBAF.4060308@treenet.co.nz>
 <556CF782.2000109@measurement-factory.com>
Message-ID: <556D0212.4060406@treenet.co.nz>

On 2/06/2015 12:23 p.m., Alex Rousskov wrote:
> On 06/01/2015 05:33 PM, Amos Jeffries wrote:
>> On 21/05/2015 3:22 a.m., Amos Jeffries wrote:
>>> This is an attempt to improve the MimeIcon reliability when filesystem
>>> I/O errors or others cause the icon data to not be loadable.
>>>
>>> The loading process is re-worked to guarantee that once the
>>> MimeIon::created callback occurs it will result in a valid StoreEntry in
>>> the cache representing the wanted icon.
>>>  * If the image can be loaded without any issues it will be placed in
>>> the cache as a 200 response.
>>>  * If errors prevent the image being loaded or necessary parameters
>>> (size and mtime) being known a 204 object will be placed into the cache.
>>>
>>> I have selected 204 as the representation of errors since the bug is not
>>> in the clients request (eliminating 400, 404, etc), a 500 would be
>>> revealing details about server internals unnecessarily often and incur
>>> extra complexity creating the error page. 204 also avoids needing to set
>>> and emit Content-Length header, and just enough different from 200 to
>>> use as a special-case test.
>>>
>>>
>>>
>>> NP: It started with just correcting the errno usage, but other bugs
>>> promptly started appearing once I got to seriously testing this load
>>> process. So far it fixes:
>>> * several assertions resulting from StoreEntry being left invalid in
>>> cache limbo beween created hash entries and valid mem_obj data.
>>> * on startup 6+ repeated attempts to load absent icons files which dont
>>> exist in the filesystem.
>>> * buffer overfow on misconfigured or corrupt mime.conf file entries
>>> * incorrect debugs messages about file I/O errors
>>> * large error pages delivered when icons not installed (when it doesnt
>>> assert from the StoreEntry)
> 
> 
>> If there are no objections I will appy this tomorrow.
> 
> Using a successful 2xx code to indicate an error sounds like a mistake
> to me. Moreover, 204 responses have special framing rules that increase
> the chance of them being misinterpreted by poorly written clients.

Its not a protocol error. It may or not be a configuration error on the
part of the sysadmin though.

The proxy has been explicitly configured to "know" this icon URL and has
no content loaded from disk to deliver for it. As far as the client and
any downstream intermediaries are concerned that is the relevant info.

> 
> If there are no better error codes, I suggest using a 503 Service
> Unavailable response. If it is difficult to adjust the code to serve an
> existing error message in this context, then just set Content-Length to
> zero or close connection, whichever is easier.

503 is not appropriate. That implies Connection:close and client being
diverted to another server/proxy (if using PAC or reverse-proxy). The
issue here has nothing to do with the connection or future usability of
the proxy producing this response.


If we are going to advertise these at all to the client, then 500 is the
only applicable registered 5xx status. Since it is also technically an
"Internal Error" while loading the icon.

I dont believe there is anything worth informing the client about
though. If the admin cares about the icons and notices them absent the
errors are logged at the time they actually occur, the cached icon object.

> 
> You have mentioned that 204 "avoids needing to set [...] Content-Length
> header", but AFAICT, the content length is just a setHeaders() parameter
> which can be zero. In fact, your patch uses it! It looks like that part
> of the argument against a true error response is invalid.

FWIW, "set and emit". Saving a few bytes in the headers and allows the
response to be cacheable by default. Both being incidental to the
problems I'm fixing, but potentially useful in general if the URL gets
hit a lot.


> 
> If you are sure your solution is better than doing nothing, please do
> not interpret the above as an objection.
> 
> 
> If you decide to commit this, please do include your NP paragraph to
> document what kind of "reliability" problems this patch fixes.
> 

Okay.

Amos


From squid3 at treenet.co.nz  Tue Jun  2 03:44:15 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 02 Jun 2015 15:44:15 +1200
Subject: [squid-dev] [PATCH] Bug3329
In-Reply-To: <5566C699.5000508@users.sourceforge.net>
References: <5562F5BB.2010904@users.sourceforge.net>
 <55630964.3020202@treenet.co.nz> <556318EF.90600@users.sourceforge.net>
 <556427DE.1010106@treenet.co.nz> <5566C699.5000508@users.sourceforge.net>
Message-ID: <556D268F.8070505@treenet.co.nz>

On 28/05/2015 7:41 p.m., Tsantilas Christos wrote:
> I am attaching a new patch for trunk which renames the  noteClsure() to
> noteClosureXXX().
> 
> If it is OK, I will post the squid-3.5 patch to.

It seems I mistook what Alex has been using the XXX() for.

What I'm thinking of for a long term fix can happen with either version.
So I will leave it up to you which of the patches you apply.

Amos


From chtsanti at users.sourceforge.net  Tue Jun  2 10:47:09 2015
From: chtsanti at users.sourceforge.net (Tsantilas Christos)
Date: Tue, 02 Jun 2015 13:47:09 +0300
Subject: [squid-dev] [PATCH] Bug3329
In-Reply-To: <556D268F.8070505@treenet.co.nz>
References: <5562F5BB.2010904@users.sourceforge.net>
 <55630964.3020202@treenet.co.nz> <556318EF.90600@users.sourceforge.net>
 <556427DE.1010106@treenet.co.nz> <5566C699.5000508@users.sourceforge.net>
 <556D268F.8070505@treenet.co.nz>
Message-ID: <556D89AD.1000300@users.sourceforge.net>

Hi Amos,

I applied the t5 patch to trunk.
In my  first mail I included t5 patch for squid-3.5 to save you time 
from porting it to 3.5.

I will attach the patches to bug report too and I will close the bug.

Regards,
   Christos


On 06/02/2015 06:44 AM, Amos Jeffries wrote:
> On 28/05/2015 7:41 p.m., Tsantilas Christos wrote:
>> I am attaching a new patch for trunk which renames the  noteClsure() to
>> noteClosureXXX().
>>
>> If it is OK, I will post the squid-3.5 patch to.
>
> It seems I mistook what Alex has been using the XXX() for.
>
> What I'm thinking of for a long term fix can happen with either version.
> So I will leave it up to you which of the patches you apply.
>
> Amos
>
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev
>


From chtsanti at users.sourceforge.net  Tue Jun  2 12:04:56 2015
From: chtsanti at users.sourceforge.net (Tsantilas Christos)
Date: Tue, 02 Jun 2015 15:04:56 +0300
Subject: [squid-dev] [PATCH] support custom OIDs in *_cert ACLs
In-Reply-To: <5566C6BB.4070304@users.sourceforge.net>
References: <55643638.3070006@users.sourceforge.net>
 <5566C6BB.4070304@users.sourceforge.net>
Message-ID: <556D9BE8.20400@users.sourceforge.net>

Patch applied to trunk as  r14098.


On 05/28/2015 10:41 AM, Tsantilas Christos wrote:
> If there is not any objection I will apply this patch to trunk.
>
> On 05/26/2015 12:00 PM, Tsantilas Christos wrote:
>> Hi all,
>>
>> This patch allow user_cert and ca_cert ACLs to match arbitrary
>> stand-alone OIDs (not DN/C/O/CN/L/ST objects or their substrings). For
>> example, should be able to match certificates that have
>> 1.3.6.1.4.1.1814.3.1.14 OID in the certificate Subject or Issuer field.
>> Squid configuration would look like this:
>>
>>   acl User_Cert-TrustedCustomerNum user_cert 1.3.6.1.4.1.1814.3.1.14 1001
>>
>> This is a Measurement Factory project
>>
>>
>> _______________________________________________
>> squid-dev mailing list
>> squid-dev at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-dev
>>
>
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev


From squid3 at treenet.co.nz  Tue Jun  2 23:32:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 03 Jun 2015 11:32:38 +1200
Subject: [squid-dev] [PATCH] Bug 3875 MimeIcon error handling
In-Reply-To: <556D0212.4060406@treenet.co.nz>
References: <555CA6C5.9080505@treenet.co.nz> <556CEBAF.4060308@treenet.co.nz>
 <556CF782.2000109@measurement-factory.com> <556D0212.4060406@treenet.co.nz>
Message-ID: <556E3D16.3030707@treenet.co.nz>

On 2/06/2015 1:08 p.m., Amos Jeffries wrote:
> On 2/06/2015 12:23 p.m., Alex Rousskov wrote:
>> On 06/01/2015 05:33 PM, Amos Jeffries wrote:
>>> On 21/05/2015 3:22 a.m., Amos Jeffries wrote:
>>>> This is an attempt to improve the MimeIcon reliability when filesystem
>>>> I/O errors or others cause the icon data to not be loadable.
>>>>

Applied as trunk rev.14100

I've left it as 204 status. If anyone has stronger reasons to use 500 we
can go with that later.

Amos


From matias at ufscar.br  Thu Jun  4 18:51:39 2015
From: matias at ufscar.br (Paulo Matias)
Date: Thu, 04 Jun 2015 15:51:39 -0300
Subject: [squid-dev] [PATCH] TLS: Disable client-initiated renegotiation
Message-ID: <55709E3B.7050609@ufscar.br>

Hi all,

This patch disables client-initiated renegotiation, mitigating a DoS attack
which might be possible with some builds of the OpenSSL library.  We have been
warned about this when testing our service with the Qualys SSL Test
(https://www.ssllabs.com/ssltest) back when it was running in a Debian wheezy
system. Further information is available at:
https://community.qualys.com/blogs/securitylabs/2011/10/31/tls-renegotiation-and-denial-of-service-attacks
Our solution is similar to the one adopted in pureftpd:
https://github.com/jedisct1/pure-ftpd/blob/549e94aaa093a48622efd6d91fdfb3a4236c13f4/src/tls.c#L106

This was previously posted to squid-users, but modified since then to implement
Amos's suggestions:

> * please avoid #ifdef and #ifndef in new code.
> - use #if defined() style instead.
> * please wrap the entire ssl_info_cb() definition in the #if
> conditionals and the appropriate calling lines.

We welcome any additional suggestions or comments.

Best regards,
Paulo Matias


-------------- next part --------------
=== modified file 'src/ssl/support.cc'
--- src/ssl/support.cc	2015-06-03 10:42:08 +0000
+++ src/ssl/support.cc	2015-06-04 12:59:30 +0000
@@ -823,12 +823,28 @@
     return dh;
 }
 
+#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
+static void
+ssl_info_cb(const SSL *ssl, int where, int ret)
+{
+    (void)ret;
+    if ((where & SSL_CB_HANDSHAKE_DONE) != 0) {
+        // disable renegotiation (CVE-2009-3555)
+        ssl->s3->flags |= SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS;
+    }
+}
+#endif
+
 static bool
 configureSslContext(SSL_CTX *sslContext, AnyP::PortCfg &port)
 {
     int ssl_error;
     SSL_CTX_set_options(sslContext, port.sslOptions);
 
+#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
+    SSL_CTX_set_info_callback(sslContext, ssl_info_cb);
+#endif
+
     if (port.sslContextSessionId)
         SSL_CTX_set_session_id_context(sslContext, (const unsigned char *)port.sslContextSessionId, strlen(port.sslContextSessionId));
 
@@ -1045,6 +1061,10 @@
 
     SSL_CTX_set_options(sslContext, Ssl::parse_options(options));
 
+#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
+    SSL_CTX_set_info_callback(sslContext, ssl_info_cb);
+#endif
+
     if (*cipher) {
         debugs(83, 5, "Using chiper suite " << cipher << ".");
 



From matias at ufscar.br  Thu Jun  4 18:51:43 2015
From: matias at ufscar.br (Paulo Matias)
Date: Thu, 04 Jun 2015 15:51:43 -0300
Subject: [squid-dev] [PATCH] TLS: Add support for EECDH
Message-ID: <55709E3F.3070502@ufscar.br>

Hi all,

This patch adds support for Ephemeral Elliptic Curve Diffie-Hellman (EECDH)
key exchange, which allows for forward secrecy with better performance than
traditional ephemeral DH.

This was previously posted to squid-users, but modified since then to implement
Amos's suggestions:

> * the DH parameters I think would be better added as a new option
> "tls-dh=curve:/path/to/params" where the 'curve' part is optional and
> implies EC when present - non-EC when absent.

OK, I have left the "dhparams=" option working as before, but emitting a
deprecation warning message. There is a new "tls-dh=" option which should
replace "dhparams=", and supports the suggested syntax. The following
are also accepted:

 * "tls-dh=:/path/to/params" -> equivalent to "tls-dh=/path/to/params"
 * "tls-dh=curve:" -> allows for enabling only EECDH (no EDH)

> * SINGLE_ECDH_USE needs to be documented in release-4.sgml
>  "New <em>options=SINGLE_ECDH_USE</em> parameter to ..."

OK.

> * The ECDH changes affect both https_port and http_port. They need
> separate listings for each under changed directives, duplicate text on
> the line items is fine.

OK.

> * please implement (duplicate) all this UI parse change using the
> Security::PeerOptions object (src/security/PeerOptions.*)
>  - the src/ssl/* code for UI parsing and config storage is 'legacy' only
> use by http(s)_port directives.
>  - this may require some small changes suitable for use on client contexts
>  - UI options added to Security::PeerOptions get documented in
> release-4.sgml as changes for both cache_peer and tls_outgoing_options.
>  - also in cf.data.pre for those directives

If I understood correctly, Security::PeerOptions is currently only used
for client TLS contexts. Currently, it does not implement e.g. the "dhparams="
option, which is only supposed to be present when configuring a server
TLS context. According to
http://openssl.6102.n7.nabble.com/question-about-ecdh-functions-tp38239p38242.html,
the curve should also be configured only in the server context. Also,
https://github.com/openssl/openssl/blob/e481f9b90b164fd1053015d1c4e0a0d92076d7a8/ssl/ssl_conf.c#L450
shows that the "named_curve" parameter is only allowed in the s_server
OpenSSL tool, therefore not allowed in s_client.

Therefore this is not included in the patch below. Please correct me if I
misunderstood anything.

> * configureSslEECDH() return true in the event that the chosen
> configuration options are not even available.
>  - please make an #else condition that displays an ERROR message at
> level DBG_CRITICAL about the option(s) not being available, then return
> false.
>  - variable 'ok' can then become const (define on assignment) and move
> fully inside the #if case.

OK.

We welcome any additional suggestions or comments.

Best regards,
Paulo Matias


-------------- next part --------------
=== modified file 'doc/release-notes/release-4.sgml'
--- doc/release-notes/release-4.sgml	2015-05-22 09:42:55 +0000
+++ doc/release-notes/release-4.sgml	2015-06-04 14:59:38 +0000
@@ -137,6 +137,12 @@
 	<p>All <em>options=</em> values for SSLv2
 	   configuration or disabling have been removed.
 	<p>Removed <em>version=</em> option. Use <em>options=</em> instead.
+	<p>New <em>options=SINGLE_ECDH_USE</em> parameter to enable ephemeral
+	   ECDH key exchange.
+	<p>Deprecated <em>dhparams=</em> option. Use <em>tls-dh=</em> instead.
+	   The new option allows to optionally specify an elliptic curve for
+	   ephemeral ECDH by adding <em>curve-name:</em> in front of the
+	   parameter file name.
 	<p>Manual squid.conf update may be required on upgrade.
 
 	<tag>sslcrtd_children</tag>

=== modified file 'src/anyp/PortCfg.cc'
--- src/anyp/PortCfg.cc	2015-05-22 09:42:55 +0000
+++ src/anyp/PortCfg.cc	2015-06-04 13:36:42 +0000
@@ -54,6 +54,7 @@
     capath(NULL),
     crlfile(NULL),
     dhfile(NULL),
+    tls_dh(NULL),
     sslflags(NULL),
     sslContextSessionId(NULL),
     generateHostCertificates(false),
@@ -67,6 +68,7 @@
     clientVerifyCrls(),
     clientCA(),
     dhParams(),
+    eecdhCurve(NULL),
     contextMethod(),
     sslContextFlags(0),
     sslOptions(0)
@@ -95,8 +97,10 @@
     safe_free(capath);
     safe_free(crlfile);
     safe_free(dhfile);
+    safe_free(tls_dh);
     safe_free(sslflags);
     safe_free(sslContextSessionId);
+    safe_free(eecdhCurve);
 #endif
 }
 
@@ -140,6 +144,8 @@
         b->crlfile = xstrdup(crlfile);
     if (dhfile)
         b->dhfile = xstrdup(dhfile);
+    if (tls_dh)
+        b->tls_dh = xstrdup(tls_dh);
     if (sslflags)
         b->sslflags = xstrdup(sslflags);
     if (sslContextSessionId)
@@ -227,8 +233,27 @@
     contextMethod = SSLv23_server_method();
 #endif
 
-    if (dhfile)
-        dhParams.reset(Ssl::readDHParams(dhfile));
+    const char *dhFile = dhfile; // backward compatibility for dhparams= configuration
+
+    if (tls_dh && tls_dh[0]) {
+        safe_free(eecdhCurve);
+        eecdhCurve = xstrdup(tls_dh);
+        char *p = strchr(eecdhCurve, ':');
+        if (p) {  // tls-dh=eecdhCurve:dhfile
+            *p = '\0';
+            dhFile = p+1;
+        } else {  // tls-dh=dhfile is equivalent to tls-dh=:dhfile
+            dhFile = tls_dh;
+            eecdhCurve[0] = '\0';
+        }
+    }
+
+    if (dhFile && dhFile[0])
+        dhParams.reset(Ssl::readDHParams(dhFile));
+
+    // an empty eecdhCurve means "do not use EECDH"
+    if (eecdhCurve && !eecdhCurve[0])
+        safe_free(eecdhCurve);
 
     if (sslflags)
         sslContextFlags = Ssl::parse_flags(sslflags);

=== modified file 'src/anyp/PortCfg.h'
--- src/anyp/PortCfg.h	2015-01-13 07:25:36 +0000
+++ src/anyp/PortCfg.h	2015-06-03 19:36:39 +0000
@@ -78,6 +78,7 @@
     char *capath;
     char *crlfile;
     char *dhfile;
+    char *tls_dh;
     char *sslflags;
     char *sslContextSessionId; ///< "session id context" for staticSslContext
     bool generateHostCertificates; ///< dynamically make host cert for sslBump
@@ -93,6 +94,7 @@
     Ssl::X509_CRL_STACK_Pointer clientVerifyCrls; ///< additional CRL lists to use when verifying the client certificate
     Ssl::X509_NAME_STACK_Pointer clientCA; ///< CA certificates to use when verifying client certificates
     Ssl::DH_Pointer dhParams; ///< DH parameters for temporary/ephemeral DH key exchanges
+    char *eecdhCurve; ///< Elliptic curve for ephemeral EC-based DH key exchanges
     Ssl::ContextMethod contextMethod; ///< The context method (SSL_METHOD) to use when creating certificates
     long sslContextFlags; ///< flags modifying the use of SSL
     long sslOptions; ///< SSL engine options

=== modified file 'src/cache_cf.cc'
--- src/cache_cf.cc	2015-05-22 09:42:55 +0000
+++ src/cache_cf.cc	2015-06-03 19:13:55 +0000
@@ -3612,8 +3612,13 @@
         safe_free(s->crlfile);
         s->crlfile = xstrdup(token + 8);
     } else if (strncmp(token, "dhparams=", 9) == 0) {
+        debugs(3, DBG_PARSE_NOTE(DBG_IMPORTANT), "WARNING: '" << token << "' is deprecated " <<
+               "in " << cfg_directive << ". Use 'tls-dh=' instead.");
         safe_free(s->dhfile);
         s->dhfile = xstrdup(token + 9);
+    } else if (strncmp(token, "tls-dh=", 7) == 0) {
+        safe_free(s->tls_dh);
+        s->tls_dh = xstrdup(token + 7);
     } else if (strncmp(token, "sslflags=", 9) == 0) {
         safe_free(s->sslflags);
         s->sslflags = xstrdup(token + 9);
@@ -3834,6 +3839,9 @@
     if (s->dhfile)
         storeAppendPrintf(e, " dhparams=%s", s->dhfile);
 
+    if (s->tls_dh)
+        storeAppendPrintf(e, " tls-dh=%s", s->tls_dh);
+
     if (s->sslflags)
         storeAppendPrintf(e, " sslflags=%s", s->sslflags);
 

=== modified file 'src/cf.data.pre'
--- src/cf.data.pre	2015-06-02 12:04:00 +0000
+++ src/cf.data.pre	2015-06-03 21:14:04 +0000
@@ -1935,6 +1935,11 @@
 				      Always create a new key when using
 				      temporary/ephemeral DH key exchanges
 
+			    SINGLE_ECDH_USE
+				      Enable ephemeral ECDH key exchange.
+				      The adopted curve should be specified
+				      using the tls-dh option.
+
 			    NO_TICKET
 				      Disable use of RFC5077 session tickets.
 				      Some servers may have problems
@@ -1963,11 +1968,15 @@
 			the client certificate, in addition to CRLs stored in
 			the capath. Implies VERIFY_CRL flag below.
 
-	   dhparams=	File containing DH parameters for temporary/ephemeral
-			DH key exchanges. See OpenSSL documentation for details
-			on how to create this file.
-			WARNING: EDH ciphers will be silently disabled if this
-				 option is not set.
+	   tls-dh=[curve:]file
+			File containing DH parameters for temporary/ephemeral DH key
+			exchanges, optionally prefixed by a curve for ephemeral ECDH
+			key exchanges.
+			See OpenSSL documentation for details on how to create the
+			DH parameter file. Supported curves for ECDH can be listed
+			using the "openssl ecparam -list_curves" command.
+			WARNING: EDH and EECDH ciphers will be silently disabled if
+				 this option is not set.
 
 	   sslflags=	Various flags modifying the use of SSL:
 			    DELAYED_AUTH
@@ -2110,6 +2119,11 @@
 				      Always create a new key when using
 				      temporary/ephemeral DH key exchanges
 
+			    SINGLE_ECDH_USE
+				      Enable ephemeral ECDH key exchange.
+				      The adopted curve should be specified
+				      using the tls-dh option.
+
 			    SSL_OP_NO_TICKET
 				      Disable use of RFC5077 session tickets.
 				      Some servers may have problems
@@ -2138,8 +2152,10 @@
 			the client certificate, in addition to CRLs stored in
 			the capath. Implies VERIFY_CRL flag below.
 
-	   dhparams=	File containing DH parameters for temporary/ephemeral
-			DH key exchanges.
+	   tls-dh=[curve:]file
+			File containing DH parameters for temporary/ephemeral DH key
+			exchanges, optionally prefixed by a curve for ephemeral ECDH
+			key exchanges.
 
 	   sslflags=	Various flags modifying the use of SSL:
 			    DELAYED_AUTH

=== modified file 'src/ssl/support.cc'
--- src/ssl/support.cc	2015-06-03 10:42:08 +0000
+++ src/ssl/support.cc	2015-06-04 14:53:55 +0000
@@ -472,6 +472,11 @@
         "NO_TICKET", SSL_OP_NO_TICKET
     },
 #endif
+#if SSL_OP_SINGLE_ECDH_USE
+    {
+        "SINGLE_ECDH_USE", SSL_OP_SINGLE_ECDH_USE
+    },
+#endif
     {
         "", 0
     },
@@ -824,6 +829,29 @@
 }
 
 static bool
+configureSslEECDH(SSL_CTX *sslContext, const char *curve)
+{
+#if OPENSSL_VERSION_NUMBER >= 0x0090800fL && !defined(OPENSSL_NO_ECDH)
+    int nid = OBJ_sn2nid(curve);
+    if (!nid) {
+        debugs(83, DBG_CRITICAL, "ERROR: Unknown EECDH curve '" << curve << "'");
+        return false;
+    }
+
+    EC_KEY *ecdh = EC_KEY_new_by_curve_name(nid);
+    if (ecdh == NULL)
+        return false;
+
+    const bool ok = SSL_CTX_set_tmp_ecdh(sslContext, ecdh) != 0;
+    EC_KEY_free(ecdh);
+    return ok;
+#else
+    debugs(83, DBG_CRITICAL, "ERROR: EECDH is not available in this build");
+    return false;
+#endif
+}
+
+static bool
 configureSslContext(SSL_CTX *sslContext, AnyP::PortCfg &port)
 {
     int ssl_error;
@@ -855,6 +883,16 @@
     debugs(83, 9, "Setting RSA key generation callback.");
     SSL_CTX_set_tmp_rsa_callback(sslContext, ssl_temp_rsa_cb);
 
+    if (port.eecdhCurve) {
+        debugs(83, 9, "Setting Ephemeral ECDH curve to " << port.eecdhCurve << ".");
+
+        if (!configureSslEECDH(sslContext, port.eecdhCurve)) {
+            ssl_error = ERR_get_error();
+            debugs(83, DBG_CRITICAL, "ERROR: Unable to configure Ephemeral ECDH: " << ERR_error_string(ssl_error, NULL));
+            return false;
+        }
+    }
+
     debugs(83, 9, "Setting CA certificate locations.");
 
     const char *cafile = port.cafile ? port.cafile : port.clientca;



From squid3 at treenet.co.nz  Thu Jun  4 22:59:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 05 Jun 2015 10:59:54 +1200
Subject: [squid-dev] [PATCH] TLS: Disable client-initiated renegotiation
In-Reply-To: <55709E3B.7050609@ufscar.br>
References: <55709E3B.7050609@ufscar.br>
Message-ID: <5570D86A.3090009@treenet.co.nz>

This gets a +1 from me.

NP: It seems a little bit odd to be setting a flag this way rather than
with flags= like all the others. However it needs to be at a default to
begin with and then set definitively OFF only after the first handshake
completes.

Christos, do you agree?

Amos


On 5/06/2015 6:51 a.m., Paulo Matias wrote:
> Hi all,
> 
> This patch disables client-initiated renegotiation, mitigating a DoS attack
> which might be possible with some builds of the OpenSSL library.  We have been
> warned about this when testing our service with the Qualys SSL Test
> (https://www.ssllabs.com/ssltest) back when it was running in a Debian wheezy
> system. Further information is available at:
> https://community.qualys.com/blogs/securitylabs/2011/10/31/tls-renegotiation-and-denial-of-service-attacks
> Our solution is similar to the one adopted in pureftpd:
> https://github.com/jedisct1/pure-ftpd/blob/549e94aaa093a48622efd6d91fdfb3a4236c13f4/src/tls.c#L106
> 
> This was previously posted to squid-users, but modified since then to implement
> Amos's suggestions:
> 
>> * please avoid #ifdef and #ifndef in new code.
>> - use #if defined() style instead.
>> * please wrap the entire ssl_info_cb() definition in the #if
>> conditionals and the appropriate calling lines.
> 
> We welcome any additional suggestions or comments.
> 
> Best regards,
> Paulo Matias
> 
> 
> -------------- next part --------------
> === modified file 'src/ssl/support.cc'
> --- src/ssl/support.cc	2015-06-03 10:42:08 +0000
> +++ src/ssl/support.cc	2015-06-04 12:59:30 +0000
> @@ -823,12 +823,28 @@
>      return dh;
>  }
>  
> +#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
> +static void
> +ssl_info_cb(const SSL *ssl, int where, int ret)
> +{
> +    (void)ret;
> +    if ((where & SSL_CB_HANDSHAKE_DONE) != 0) {
> +        // disable renegotiation (CVE-2009-3555)
> +        ssl->s3->flags |= SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS;
> +    }
> +}
> +#endif
> +
>  static bool
>  configureSslContext(SSL_CTX *sslContext, AnyP::PortCfg &port)
>  {
>      int ssl_error;
>      SSL_CTX_set_options(sslContext, port.sslOptions);
>  
> +#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
> +    SSL_CTX_set_info_callback(sslContext, ssl_info_cb);
> +#endif
> +
>      if (port.sslContextSessionId)
>          SSL_CTX_set_session_id_context(sslContext, (const unsigned char *)port.sslContextSessionId, strlen(port.sslContextSessionId));
>  
> @@ -1045,6 +1061,10 @@
>  
>      SSL_CTX_set_options(sslContext, Ssl::parse_options(options));
>  
> +#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
> +    SSL_CTX_set_info_callback(sslContext, ssl_info_cb);
> +#endif
> +
>      if (*cipher) {
>          debugs(83, 5, "Using chiper suite " << cipher << ".");
>  
> 
> 
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev
> 


From squid3 at treenet.co.nz  Thu Jun  4 23:20:52 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 05 Jun 2015 11:20:52 +1200
Subject: [squid-dev] [PATCH] TLS: Add support for EECDH
In-Reply-To: <55709E3F.3070502@ufscar.br>
References: <55709E3F.3070502@ufscar.br>
Message-ID: <5570DD54.6060302@treenet.co.nz>

On 5/06/2015 6:51 a.m., Paulo Matias wrote:
> Hi all,
> 
> This patch adds support for Ephemeral Elliptic Curve Diffie-Hellman (EECDH)
> key exchange, which allows for forward secrecy with better performance than
> traditional ephemeral DH.
> 
> This was previously posted to squid-users, but modified since then to implement
> Amos's suggestions:
> 
>> * the DH parameters I think would be better added as a new option
>> "tls-dh=curve:/path/to/params" where the 'curve' part is optional and
>> implies EC when present - non-EC when absent.
> 
> OK, I have left the "dhparams=" option working as before, but emitting a
> deprecation warning message. There is a new "tls-dh=" option which should
> replace "dhparams=", and supports the suggested syntax. The following
> are also accepted:
> 
>  * "tls-dh=:/path/to/params" -> equivalent to "tls-dh=/path/to/params"
>  * "tls-dh=curve:" -> allows for enabling only EECDH (no EDH)
> 
>> * SINGLE_ECDH_USE needs to be documented in release-4.sgml
>>  "New <em>options=SINGLE_ECDH_USE</em> parameter to ..."
> 
> OK.
> 
>> * The ECDH changes affect both https_port and http_port. They need
>> separate listings for each under changed directives, duplicate text on
>> the line items is fine.
> 
> OK.
> 
>> * please implement (duplicate) all this UI parse change using the
>> Security::PeerOptions object (src/security/PeerOptions.*)
>>  - the src/ssl/* code for UI parsing and config storage is 'legacy' only
>> use by http(s)_port directives.
>>  - this may require some small changes suitable for use on client contexts
>>  - UI options added to Security::PeerOptions get documented in
>> release-4.sgml as changes for both cache_peer and tls_outgoing_options.
>>  - also in cf.data.pre for those directives
> 
> If I understood correctly, Security::PeerOptions is currently only used
> for client TLS contexts. Currently, it does not implement e.g. the "dhparams="
> option, which is only supposed to be present when configuring a server
> TLS context. According to
> http://openssl.6102.n7.nabble.com/question-about-ecdh-functions-tp38239p38242.html,
> the curve should also be configured only in the server context. Also,
> https://github.com/openssl/openssl/blob/e481f9b90b164fd1053015d1c4e0a0d92076d7a8/ssl/ssl_conf.c#L450
> shows that the "named_curve" parameter is only allowed in the s_server
> OpenSSL tool, therefore not allowed in s_client.
> 
> Therefore this is not included in the patch below. Please correct me if I
> misunderstood anything.

Okay, thats reasonable. I was hoping to be able to avoid porting it
later, but that not a problem.



> 
>> * configureSslEECDH() return true in the event that the chosen
>> configuration options are not even available.
>>  - please make an #else condition that displays an ERROR message at
>> level DBG_CRITICAL about the option(s) not being available, then return
>> false.
>>  - variable 'ok' can then become const (define on assignment) and move
>> fully inside the #if case.
> 
> OK.
> 
> We welcome any additional suggestions or comments.


Just a few minor nit-pick bits:

 * the uses of "eecdhCurve[0]" look like thay can all become
"*eecdhCurve" for slightly better compiler optimization.
 (yeah its weird that the compilers are not smart enough to do it
themselves, but we tested and its faster with *X=0 than X[0] = '\0').


* this sequence:

> +        safe_free(eecdhCurve);
> +        eecdhCurve = xstrdup(tls_dh);

can become xfree() instead of safe_free(). They do the same pre-checks,
but xfree() works slightly faster if its guaranteed to be assigned
before next use.


* The debugs output "EECDH is not available in this build" would be a
little more useful if it could suggest a minimum OpenSSL library version
to build against. So its clear the problem comes from OpenSSL imposed
restrictions, not just Squid.


Otherwise +1.

Amos


From squid3 at treenet.co.nz  Thu Jun  4 23:39:33 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 05 Jun 2015 11:39:33 +1200
Subject: [squid-dev] [PATCH] TLS: Add support for EECDH
In-Reply-To: <55709E3F.3070502@ufscar.br>
References: <55709E3F.3070502@ufscar.br>
Message-ID: <5570E1B5.1060802@treenet.co.nz>

Actually two more and you may want to test these after changing.


1) The 'dhfile' pointer must now never be freed. Since it is either a
pointer into tls_dh or eecdhCurve allocated memory.
 - It should simply be set to dhfile=NULL where it was free()'d, and now
also when the tls_dh and/or eecdhCurve memory is released.
 - I spotted the destructor safe_free(dhfile), maybe elsewhere as well.


2) In src/anyp/PortCfg.cc:
> @@ -227,8 +233,27 @@
>      contextMethod = SSLv23_server_method();
>  #endif
>  
> -    if (dhfile)
> -        dhParams.reset(Ssl::readDHParams(dhfile));
> +    const char *dhFile = dhfile; // backward compatibility for dhparams= configuration
> +
> +    if (tls_dh && tls_dh[0]) {
> +        safe_free(eecdhCurve);
> +        eecdhCurve = xstrdup(tls_dh);
> +        char *p = strchr(eecdhCurve, ':');
> +        if (p) {  // tls-dh=eecdhCurve:dhfile
> +            *p = '\0';
> +            dhFile = p+1;
> +        } else {  // tls-dh=dhfile is equivalent to tls-dh=:dhfile
> +            dhFile = tls_dh;
> +            eecdhCurve[0] = '\0';
> +        }
> +    }
> +
> +    if (dhFile && dhFile[0])
> +        dhParams.reset(Ssl::readDHParams(dhFile));
> +
> +    // an empty eecdhCurve means "do not use EECDH"
> +    if (eecdhCurve && !eecdhCurve[0])
> +        safe_free(eecdhCurve);
>  

The eecdhCurve is always left a nil-pointer unless its assigned, which
only happens inside that if() block.

So it seems that could be better written as just:

> +    const char *dhFile = dhfile; // backward compatibility for
dhparams= configuration
> +    safe_free(eecdhCurve); // clear any previous EECDH configuration
> +    if (tls_dh && *tls_dh) {
> +        eecdhCurve = xstrdup(tls_dh);
> +        char *p = strchr(eecdhCurve, ':');
> +        if (p) {  // tls-dh=eecdhCurve:dhfile
> +            *p = '\0';
> +            dhFile = p+1;
> +        } else {  // tls-dh=dhfile is equivalent to tls-dh=:dhfile
> +            dhFile = tls_dh;
> +            // an empty eecdhCurve means "do not use EECDH"
> +            safe_free(eecdhCurve);
> +        }
> +    }
> +
> +    if (dhFile && *dhFile)
> +        dhParams.reset(Ssl::readDHParams(dhFile));



Amos

From chtsanti at users.sourceforge.net  Fri Jun  5 11:16:02 2015
From: chtsanti at users.sourceforge.net (Tsantilas Christos)
Date: Fri, 05 Jun 2015 14:16:02 +0300
Subject: [squid-dev] [PATCH] TLS: Disable client-initiated renegotiation
In-Reply-To: <55709E3B.7050609@ufscar.br>
References: <55709E3B.7050609@ufscar.br>
Message-ID: <557184F2.5000403@users.sourceforge.net>

Hi Paulo,

  Which is the openSSL version in a Debian wheezy system?

My understanding is that openSSL-0.9.8m and later, by default provides 
protection against this bug.

The openSSL provides the following flags to control the  renegotiation:
   - SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION flag for an openSSL server
   -  SSL_OP_LEGACY_SERVER_CONNECT and 
SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION for an openSSL client.

This is what OpenSSL manual says for the behaviour of an openSSL server 
on renegotiation:

"The initial connection succeeds but client renegotiation is denied by 
the server with a no_renegotiation warning alert if TLS v1.0 is used or 
a fatal handshake_failure alert in SSL v3.0.

If the patched OpenSSL server attempts to renegotiate a fatal 
handshake_failure alert is sent. This is because the server code may be 
unaware of the unpatched nature of the client.

If the option SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION is set then 
renegotiation always succeeds."

Reference:
    https://www.openssl.org/docs/ssl/SSL_CTX_set_options.html


We may have problem in squid openSSL client.
But we can add support for these flags and allow users set them in squid 
configuration file. Is n't it better?



On 06/04/2015 09:51 PM, Paulo Matias wrote:
> Hi all,
>
> This patch disables client-initiated renegotiation, mitigating a DoS attack
> which might be possible with some builds of the OpenSSL library.  We have been
> warned about this when testing our service with the Qualys SSL Test
> (https://www.ssllabs.com/ssltest) back when it was running in a Debian wheezy
> system. Further information is available at:
> https://community.qualys.com/blogs/securitylabs/2011/10/31/tls-renegotiation-and-denial-of-service-attacks
> Our solution is similar to the one adopted in pureftpd:
> https://github.com/jedisct1/pure-ftpd/blob/549e94aaa093a48622efd6d91fdfb3a4236c13f4/src/tls.c#L106
>
> This was previously posted to squid-users, but modified since then to implement
> Amos's suggestions:
>
>> * please avoid #ifdef and #ifndef in new code.
>> - use #if defined() style instead.
>> * please wrap the entire ssl_info_cb() definition in the #if
>> conditionals and the appropriate calling lines.
>
> We welcome any additional suggestions or comments.
>
> Best regards,
> Paulo Matias
>
>
> -------------- next part --------------
> === modified file 'src/ssl/support.cc'
> --- src/ssl/support.cc	2015-06-03 10:42:08 +0000
> +++ src/ssl/support.cc	2015-06-04 12:59:30 +0000
> @@ -823,12 +823,28 @@
>       return dh;
>   }
>
> +#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
> +static void
> +ssl_info_cb(const SSL *ssl, int where, int ret)
> +{
> +    (void)ret;
> +    if ((where & SSL_CB_HANDSHAKE_DONE) != 0) {
> +        // disable renegotiation (CVE-2009-3555)
> +        ssl->s3->flags |= SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS;
> +    }
> +}
> +#endif
> +
>   static bool
>   configureSslContext(SSL_CTX *sslContext, AnyP::PortCfg &port)
>   {
>       int ssl_error;
>       SSL_CTX_set_options(sslContext, port.sslOptions);
>
> +#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
> +    SSL_CTX_set_info_callback(sslContext, ssl_info_cb);
> +#endif
> +
>       if (port.sslContextSessionId)
>           SSL_CTX_set_session_id_context(sslContext, (const unsigned char *)port.sslContextSessionId, strlen(port.sslContextSessionId));
>
> @@ -1045,6 +1061,10 @@
>
>       SSL_CTX_set_options(sslContext, Ssl::parse_options(options));
>
> +#if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
> +    SSL_CTX_set_info_callback(sslContext, ssl_info_cb);
> +#endif
> +
>       if (*cipher) {
>           debugs(83, 5, "Using chiper suite " << cipher << ".");
>
>
>
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev
>


-- 
Tsantilas Christos
Network and Systems Engineer
email:christos at chtsanti.net
   web:http://www.chtsanti.net
Phone:+30 6977678842

From matias at ufscar.br  Fri Jun  5 18:02:17 2015
From: matias at ufscar.br (Paulo Matias)
Date: Fri, 05 Jun 2015 15:02:17 -0300
Subject: [squid-dev] [PATCH] TLS: Disable client-initiated renegotiation
In-Reply-To: <557184F2.5000403@users.sourceforge.net>
References: <55709E3B.7050609@ufscar.br>
 <557184F2.5000403@users.sourceforge.net>
Message-ID: <5571E429.8040008@ufscar.br>

Hi Christos,

On 05-06-2015 08:16, Tsantilas Christos wrote:
>  Which is the openSSL version in a Debian wheezy system?

libssl package reports version 1.0.1e-2+deb7u16

> My understanding is that openSSL-0.9.8m and later, by default provides protection against this bug.

Yes, OpenSSL >0.9.8m seems to provide protection against the insecure
renegotiation bug. However my patch is for a different (although much less
severe) issue.

The issue consists on the fact that enabling client-initiated
renegotiation, although cryptographically secure, eases mounting DoS
attacks against the server, because it reduces the number of connections
to the server needed to conduct such an attack:
https://community.qualys.com/blogs/securitylabs/2011/10/31/tls-renegotiation-and-denial-of-service-attacks

This is a screenshot of the Qualys SSL test running against unpatched
Squid trunk in Debian wheezy:
https://web.archive.org/web/20150605172653/http://i.imgur.com/uDCNm8s.png

For the record, it displays:
"Secure Client-Initiated Renegotiation: Supported - DoS DANGER (more
info)", where the "more info" link points to the blog post referenced
above.

Debian jessie passes the test without issues even without applying the
patch. However we did not investigate if the reason is the OpenSSL
version or if Debian applied some new patch in jessie's package. Just
for the record, the Debian jessie's libssl package version is 1.0.1k-3.

Best regards,
Paulo Matias


From matias at ufscar.br  Fri Jun  5 19:21:13 2015
From: matias at ufscar.br (Paulo Matias)
Date: Fri, 05 Jun 2015 16:21:13 -0300
Subject: [squid-dev] [PATCH] TLS: Add support for EECDH
In-Reply-To: <5570E1B5.1060802@treenet.co.nz>
References: <55709E3F.3070502@ufscar.br> <5570E1B5.1060802@treenet.co.nz>
Message-ID: <5571F6A9.3020503@ufscar.br>

Hi Amos,

I have implemented your suggestions. The updated patch follows at the
end of this message. Please tell me if I forgot anything.

On 04-06-2015 20:39, Amos Jeffries wrote:
> 1) The 'dhfile' pointer must now never be freed. Since it is either a
> pointer into tls_dh or eecdhCurve allocated memory.
>  - It should simply be set to dhfile=NULL where it was free()'d, and now
> also when the tls_dh and/or eecdhCurve memory is released.
>  - I spotted the destructor safe_free(dhfile), maybe elsewhere as well.

The 'dhfile' pointer is still only set by the (deprecated) "dhparams="
option. The pointer to tls_dh or eecdhCurve is instead copied to the local
'dhFile' pointer, which can be discarded without issues after the call
to Ssl::readDHParams. However I should not have named the local pointer
'dhFile', as it causes confusion. I have now renamed it to
'dhParamsFile'. Please tell me if I overlooked anything.

Best regards,
Paulo Matias

-------------- next part --------------
=== modified file 'doc/release-notes/release-4.sgml'
--- doc/release-notes/release-4.sgml	2015-05-22 09:42:55 +0000
+++ doc/release-notes/release-4.sgml	2015-06-04 14:59:38 +0000
@@ -137,6 +137,12 @@
 	<p>All <em>options=</em> values for SSLv2
 	   configuration or disabling have been removed.
 	<p>Removed <em>version=</em> option. Use <em>options=</em> instead.
+	<p>New <em>options=SINGLE_ECDH_USE</em> parameter to enable ephemeral
+	   ECDH key exchange.
+	<p>Deprecated <em>dhparams=</em> option. Use <em>tls-dh=</em> instead.
+	   The new option allows to optionally specify an elliptic curve for
+	   ephemeral ECDH by adding <em>curve-name:</em> in front of the
+	   parameter file name.
 	<p>Manual squid.conf update may be required on upgrade.
 
 	<tag>sslcrtd_children</tag>

=== modified file 'src/anyp/PortCfg.cc'
--- src/anyp/PortCfg.cc	2015-05-22 09:42:55 +0000
+++ src/anyp/PortCfg.cc	2015-06-05 18:31:38 +0000
@@ -54,6 +54,7 @@
     capath(NULL),
     crlfile(NULL),
     dhfile(NULL),
+    tls_dh(NULL),
     sslflags(NULL),
     sslContextSessionId(NULL),
     generateHostCertificates(false),
@@ -67,6 +68,7 @@
     clientVerifyCrls(),
     clientCA(),
     dhParams(),
+    eecdhCurve(NULL),
     contextMethod(),
     sslContextFlags(0),
     sslOptions(0)
@@ -95,8 +97,10 @@
     safe_free(capath);
     safe_free(crlfile);
     safe_free(dhfile);
+    safe_free(tls_dh);
     safe_free(sslflags);
     safe_free(sslContextSessionId);
+    safe_free(eecdhCurve);
 #endif
 }
 
@@ -140,6 +144,8 @@
         b->crlfile = xstrdup(crlfile);
     if (dhfile)
         b->dhfile = xstrdup(dhfile);
+    if (tls_dh)
+        b->tls_dh = xstrdup(tls_dh);
     if (sslflags)
         b->sslflags = xstrdup(sslflags);
     if (sslContextSessionId)
@@ -227,8 +233,23 @@
     contextMethod = SSLv23_server_method();
 #endif
 
-    if (dhfile)
-        dhParams.reset(Ssl::readDHParams(dhfile));
+    const char *dhParamsFile = dhfile; // backward compatibility for dhparams= configuration
+    safe_free(eecdhCurve); // clear any previous EECDH configuration
+    if (tls_dh && *tls_dh) {
+        eecdhCurve = xstrdup(tls_dh);
+        char *p = strchr(eecdhCurve, ':');
+        if (p) {  // tls-dh=eecdhCurve:dhParamsFile
+            *p = '\0';
+            dhParamsFile = p+1;
+        } else {  // tls-dh=dhParamsFile
+            dhParamsFile = tls_dh;
+            // a NULL eecdhCurve means "do not use EECDH"
+            safe_free(eecdhCurve);
+        }
+    }
+
+    if (dhParamsFile && *dhParamsFile)
+        dhParams.reset(Ssl::readDHParams(dhParamsFile));
 
     if (sslflags)
         sslContextFlags = Ssl::parse_flags(sslflags);

=== modified file 'src/anyp/PortCfg.h'
--- src/anyp/PortCfg.h	2015-01-13 07:25:36 +0000
+++ src/anyp/PortCfg.h	2015-06-03 19:36:39 +0000
@@ -78,6 +78,7 @@
     char *capath;
     char *crlfile;
     char *dhfile;
+    char *tls_dh;
     char *sslflags;
     char *sslContextSessionId; ///< "session id context" for staticSslContext
     bool generateHostCertificates; ///< dynamically make host cert for sslBump
@@ -93,6 +94,7 @@
     Ssl::X509_CRL_STACK_Pointer clientVerifyCrls; ///< additional CRL lists to use when verifying the client certificate
     Ssl::X509_NAME_STACK_Pointer clientCA; ///< CA certificates to use when verifying client certificates
     Ssl::DH_Pointer dhParams; ///< DH parameters for temporary/ephemeral DH key exchanges
+    char *eecdhCurve; ///< Elliptic curve for ephemeral EC-based DH key exchanges
     Ssl::ContextMethod contextMethod; ///< The context method (SSL_METHOD) to use when creating certificates
     long sslContextFlags; ///< flags modifying the use of SSL
     long sslOptions; ///< SSL engine options

=== modified file 'src/cache_cf.cc'
--- src/cache_cf.cc	2015-05-22 09:42:55 +0000
+++ src/cache_cf.cc	2015-06-03 19:13:55 +0000
@@ -3612,8 +3612,13 @@
         safe_free(s->crlfile);
         s->crlfile = xstrdup(token + 8);
     } else if (strncmp(token, "dhparams=", 9) == 0) {
+        debugs(3, DBG_PARSE_NOTE(DBG_IMPORTANT), "WARNING: '" << token << "' is deprecated " <<
+               "in " << cfg_directive << ". Use 'tls-dh=' instead.");
         safe_free(s->dhfile);
         s->dhfile = xstrdup(token + 9);
+    } else if (strncmp(token, "tls-dh=", 7) == 0) {
+        safe_free(s->tls_dh);
+        s->tls_dh = xstrdup(token + 7);
     } else if (strncmp(token, "sslflags=", 9) == 0) {
         safe_free(s->sslflags);
         s->sslflags = xstrdup(token + 9);
@@ -3834,6 +3839,9 @@
     if (s->dhfile)
         storeAppendPrintf(e, " dhparams=%s", s->dhfile);
 
+    if (s->tls_dh)
+        storeAppendPrintf(e, " tls-dh=%s", s->tls_dh);
+
     if (s->sslflags)
         storeAppendPrintf(e, " sslflags=%s", s->sslflags);
 

=== modified file 'src/cf.data.pre'
--- src/cf.data.pre	2015-06-02 12:04:00 +0000
+++ src/cf.data.pre	2015-06-03 21:14:04 +0000
@@ -1935,6 +1935,11 @@
 				      Always create a new key when using
 				      temporary/ephemeral DH key exchanges
 
+			    SINGLE_ECDH_USE
+				      Enable ephemeral ECDH key exchange.
+				      The adopted curve should be specified
+				      using the tls-dh option.
+
 			    NO_TICKET
 				      Disable use of RFC5077 session tickets.
 				      Some servers may have problems
@@ -1963,11 +1968,15 @@
 			the client certificate, in addition to CRLs stored in
 			the capath. Implies VERIFY_CRL flag below.
 
-	   dhparams=	File containing DH parameters for temporary/ephemeral
-			DH key exchanges. See OpenSSL documentation for details
-			on how to create this file.
-			WARNING: EDH ciphers will be silently disabled if this
-				 option is not set.
+	   tls-dh=[curve:]file
+			File containing DH parameters for temporary/ephemeral DH key
+			exchanges, optionally prefixed by a curve for ephemeral ECDH
+			key exchanges.
+			See OpenSSL documentation for details on how to create the
+			DH parameter file. Supported curves for ECDH can be listed
+			using the "openssl ecparam -list_curves" command.
+			WARNING: EDH and EECDH ciphers will be silently disabled if
+				 this option is not set.
 
 	   sslflags=	Various flags modifying the use of SSL:
 			    DELAYED_AUTH
@@ -2110,6 +2119,11 @@
 				      Always create a new key when using
 				      temporary/ephemeral DH key exchanges
 
+			    SINGLE_ECDH_USE
+				      Enable ephemeral ECDH key exchange.
+				      The adopted curve should be specified
+				      using the tls-dh option.
+
 			    SSL_OP_NO_TICKET
 				      Disable use of RFC5077 session tickets.
 				      Some servers may have problems
@@ -2138,8 +2152,10 @@
 			the client certificate, in addition to CRLs stored in
 			the capath. Implies VERIFY_CRL flag below.
 
-	   dhparams=	File containing DH parameters for temporary/ephemeral
-			DH key exchanges.
+	   tls-dh=[curve:]file
+			File containing DH parameters for temporary/ephemeral DH key
+			exchanges, optionally prefixed by a curve for ephemeral ECDH
+			key exchanges.
 
 	   sslflags=	Various flags modifying the use of SSL:
 			    DELAYED_AUTH

=== modified file 'src/ssl/support.cc'
--- src/ssl/support.cc	2015-06-03 10:42:08 +0000
+++ src/ssl/support.cc	2015-06-05 18:23:11 +0000
@@ -472,6 +472,11 @@
         "NO_TICKET", SSL_OP_NO_TICKET
     },
 #endif
+#if SSL_OP_SINGLE_ECDH_USE
+    {
+        "SINGLE_ECDH_USE", SSL_OP_SINGLE_ECDH_USE
+    },
+#endif
     {
         "", 0
     },
@@ -824,6 +829,29 @@
 }
 
 static bool
+configureSslEECDH(SSL_CTX *sslContext, const char *curve)
+{
+#if OPENSSL_VERSION_NUMBER >= 0x0090800fL && !defined(OPENSSL_NO_ECDH)
+    int nid = OBJ_sn2nid(curve);
+    if (!nid) {
+        debugs(83, DBG_CRITICAL, "ERROR: Unknown EECDH curve '" << curve << "'");
+        return false;
+    }
+
+    EC_KEY *ecdh = EC_KEY_new_by_curve_name(nid);
+    if (ecdh == NULL)
+        return false;
+
+    const bool ok = SSL_CTX_set_tmp_ecdh(sslContext, ecdh) != 0;
+    EC_KEY_free(ecdh);
+    return ok;
+#else
+    debugs(83, DBG_CRITICAL, "ERROR: EECDH is not available in this build. Please link against OpenSSL>=0.9.8 and ensure OPENSSL_NO_ECDH is not set.");
+    return false;
+#endif
+}
+
+static bool
 configureSslContext(SSL_CTX *sslContext, AnyP::PortCfg &port)
 {
     int ssl_error;
@@ -855,6 +883,16 @@
     debugs(83, 9, "Setting RSA key generation callback.");
     SSL_CTX_set_tmp_rsa_callback(sslContext, ssl_temp_rsa_cb);
 
+    if (port.eecdhCurve) {
+        debugs(83, 9, "Setting Ephemeral ECDH curve to " << port.eecdhCurve << ".");
+
+        if (!configureSslEECDH(sslContext, port.eecdhCurve)) {
+            ssl_error = ERR_get_error();
+            debugs(83, DBG_CRITICAL, "ERROR: Unable to configure Ephemeral ECDH: " << ERR_error_string(ssl_error, NULL));
+            return false;
+        }
+    }
+
     debugs(83, 9, "Setting CA certificate locations.");
 
     const char *cafile = port.cafile ? port.cafile : port.clientca;




From squid3 at treenet.co.nz  Fri Jun  5 19:34:30 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 06 Jun 2015 07:34:30 +1200
Subject: [squid-dev] [PATCH] TLS: Add support for EECDH
In-Reply-To: <5571F6A9.3020503@ufscar.br>
References: <55709E3F.3070502@ufscar.br> <5570E1B5.1060802@treenet.co.nz>
 <5571F6A9.3020503@ufscar.br>
Message-ID: <5571F9C6.4010501@treenet.co.nz>

On 6/06/2015 7:21 a.m., Paulo Matias wrote:
> Hi Amos,
> 
> I have implemented your suggestions. The updated patch follows at the
> end of this message. Please tell me if I forgot anything.
> 
> On 04-06-2015 20:39, Amos Jeffries wrote:
>> 1) The 'dhfile' pointer must now never be freed. Since it is either a
>> pointer into tls_dh or eecdhCurve allocated memory.
>>  - It should simply be set to dhfile=NULL where it was free()'d, and now
>> also when the tls_dh and/or eecdhCurve memory is released.
>>  - I spotted the destructor safe_free(dhfile), maybe elsewhere as well.
> 
> The 'dhfile' pointer is still only set by the (deprecated) "dhparams="
> option. The pointer to tls_dh or eecdhCurve is instead copied to the local
> 'dhFile' pointer, which can be discarded without issues after the call
> to Ssl::readDHParams. However I should not have named the local pointer
> 'dhFile', as it causes confusion. I have now renamed it to
> 'dhParamsFile'. Please tell me if I overlooked anything.
> 

Doh. Much better now. :-)


Amos

From squid3 at treenet.co.nz  Fri Jun  5 22:47:09 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 06 Jun 2015 10:47:09 +1200
Subject: [squid-dev] [RFC] TLS peek by default
Message-ID: <557226ED.7010204@treenet.co.nz>

In order to support PROXY protocol on HTTPS inbound traffic we will be
needing Squid to "peek" at the initial client connection bytes and
process the PROXY header.

There is no need for the decryption to enter into the picture and in
current trunk Squid the bytes can be relayed in the BIO buffer to
whatever processing is appropriate.

Along these lines, I am wondering why we need to have "ssl_bump peek"
checked for in relation to client peeking. Can we make Squid simply do
that first 'peek' step always for all potential HTTPS connections ?


This would also give SNI and the like up front and make Squid able to
act lot more like what people in squid-users seem to be starting off
assuming it does.

Amos

From nathan at getoffmalawn.com  Sat Jun  6 14:41:18 2015
From: nathan at getoffmalawn.com (Nathan Hoad)
Date: Sun, 7 Jun 2015 00:41:18 +1000
Subject: [squid-dev] [PATCH] Add chained certificates and signing
 certificate to bumpAndSpliced connections
In-Reply-To: <556044DD.2080601@users.sourceforge.net>
References: <CAGUJm7bBkot1Ae0njnDmESj-XGJ07pZv6iYa+uvh0kzJ8Mf7=Q@mail.gmail.com>
 <556044DD.2080601@users.sourceforge.net>
Message-ID: <CAGUJm7bnpCyM6NPxnrkMnCydsF2HxNgjDdnV4bJTBsjBPjhDCA@mail.gmail.com>

Hello,

Attached is a patch making the changes recommended by Christos. I've
done as described, creating a Ssl::configureUnconfiguredSslContext
function, rather than making the changes to Ssl::configureSSL.

Thank you,

Nathan.

On 23 May 2015 at 19:14, Tsantilas Christos
<chtsanti at users.sourceforge.net> wrote:
> Hi Nathan,
>
>  The patch works.
>
> However I believe It is not good idea to configure SSL_CTX objects while we
> are setting parameters to an SSL object.
> A SSL_CTX object is common to many SSL objects.
>
> Instead of setting SSL_CTX object from
> configureSSLUsingPkeyAndCertFromMemory I am suggesting a new method
> "configureUnconfigureCTX()" which does the job:
>
> Then inside client_side use:
>
>  bool ret = Ssl::configureSSLUsingPkeyAndCertFromMemory(...);
>   if (!ret)
>         debugs(33, 5, "mpla mpla");
>  SSL_CTX *sslContext = SSL_get_SSL_CTX(ssl);
>  ret = configureUnconfigureCTX(sslContext,..., signAlgorithm)
>
>
> OR
>
>   Ssl::configureSSL(ssl, certProperties, *port))
>   SSL_CTX *sslContext = SSL_get_SSL_CTX(ssl);
>   ret = configureUnconfigureCTX(sslContext,..., signAlgorithm)
>
>
> Probably the above should be wrapped to a new method.
> Or  maybe a new function which its name says that both CTX and SSL objects
> are modified.
>
>
>
> On 04/30/2015 08:11 AM, Nathan Hoad wrote:
>>
>> Hello,
>>
>> I am running Squid with SSL bump in bump and splice mode, and I've
>> observed that this mode does not append the signing certificate or any
>> chained certificates to the certificate chain presented to the client.
>>
>> With old bump mode, Squid adds the signing certificate and any other
>> chained certificates to the SSL context. With bump and splice mode,
>> these certificates are not added. Attached is a patch that adds these
>> certificates for bump and spliced connections.
>>
>> Thank you,
>>
>> Nathan.
>>
>>
>>
>> _______________________________________________
>> squid-dev mailing list
>> squid-dev at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-dev
>>
>
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev
-------------- next part --------------
A non-text attachment was scrubbed...
Name: bumpnsplice-chained-certificates-v2.patch
Type: text/x-diff
Size: 4656 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150607/e78db81e/attachment.patch>

From squid3 at treenet.co.nz  Mon Jun  8 08:34:50 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 08 Jun 2015 20:34:50 +1200
Subject: [squid-dev] [PATCH] Parser-NG: Transfer-Encoding:chunked Parser
In-Reply-To: <556CE8EF.1050604@treenet.co.nz>
References: <556CE8EF.1050604@treenet.co.nz>
Message-ID: <557553AA.8060401@treenet.co.nz>

On 2/06/2015 11:21 a.m., Amos Jeffries wrote:
> Remove several performance regressions incurred in earlier Parser-NG
> updates by refactoring the class ChunkedCodingParser to a class
> Http1::TeChunkedParser which parses an SBuf I/O buffer for chunked
> encoding data and (for now) copies the chunk payloads into a MemBuf buffer.
> 
> The new class is inherited from Http1::Parser and presents the same API.
> Chunk Trailers are now available via the Parser API mimeHeader() method
> - although none of the rest of Squid makes use of that data yet. It
> implements parsing using a ::Parser::Tokenizer for (nearly) compliant
> protocol tokenization. With enumerated states instead of a dynamic
> function-pointer chain.
> 
> 
> Measurements:
>  Co-Advisor shows no compliance change.
>  Polygraph shows approx 1% speed improvement over trunk.
> 
> PS. earlier bugs being investigated turned out to be inherited from
> trunk and are now fixed there already.
> 
> Amos
> 

If there are no objections I would like to fast-track this and apply it
in the next day or so.

Amos


From squid3 at treenet.co.nz  Tue Jun  9 01:59:48 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 09 Jun 2015 13:59:48 +1200
Subject: [squid-dev] [PATCH] Parser-NG: Transfer-Encoding:chunked Parser
In-Reply-To: <557553AA.8060401@treenet.co.nz>
References: <556CE8EF.1050604@treenet.co.nz> <557553AA.8060401@treenet.co.nz>
Message-ID: <55764894.5060904@treenet.co.nz>

On 8/06/2015 8:34 p.m., Amos Jeffries wrote:
> On 2/06/2015 11:21 a.m., Amos Jeffries wrote:
>> Remove several performance regressions incurred in earlier Parser-NG
>> updates by refactoring the class ChunkedCodingParser to a class
>> Http1::TeChunkedParser which parses an SBuf I/O buffer for chunked
>> encoding data and (for now) copies the chunk payloads into a MemBuf buffer.
>>
>> The new class is inherited from Http1::Parser and presents the same API.
>> Chunk Trailers are now available via the Parser API mimeHeader() method
>> - although none of the rest of Squid makes use of that data yet. It
>> implements parsing using a ::Parser::Tokenizer for (nearly) compliant
>> protocol tokenization. With enumerated states instead of a dynamic
>> function-pointer chain.
>>
>>
>> Measurements:
>>  Co-Advisor shows no compliance change.
>>  Polygraph shows approx 1% speed improvement over trunk.
>>
>> PS. earlier bugs being investigated turned out to be inherited from
>> trunk and are now fixed there already.
>>
>> Amos
>>
> 
> If there are no objections I would like to fast-track this and apply it
> in the next day or so.
> 


Applied as trunk rev.14108

Amos


From squid3 at treenet.co.nz  Tue Jun  9 14:50:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Jun 2015 02:50:38 +1200
Subject: [squid-dev] [PATCH] Parser-NG: Http1::Tokenizer
Message-ID: <5576FD3E.2030001@treenet.co.nz>

This adds a class Http1::Tokenizer, which inherits from
::Parser::Tokenizer and presents additional HTTP-specific token parsing
methods.

At present it extends for the quoted-string, 1#( token/ quoted-string ),
and qdtext constructs from RFC 7230 and RFC 1945.

It can also cope with charset and quoted-pair escaping differences in
qdtext between RFC 1945 and RFC 7230. The un-escaped form of token is
returned.

Amos
-------------- next part --------------
=== modified file 'src/http/one/Makefile.am'
--- src/http/one/Makefile.am	2015-06-01 21:41:37 +0000
+++ src/http/one/Makefile.am	2015-06-09 01:57:52 +0000
@@ -2,21 +2,23 @@
 ##
 ## Squid software is distributed under GPLv2+ license and includes
 ## contributions from numerous individuals and organizations.
 ## Please see the COPYING and CONTRIBUTORS files for details.
 ##
 
 include $(top_srcdir)/src/Common.am
 include $(top_srcdir)/src/TestHeaders.am
 
 noinst_LTLIBRARIES = libhttp1.la
 
 libhttp1_la_SOURCES = \
 	forward.h \
 	Parser.cc \
 	Parser.h \
 	RequestParser.cc \
 	RequestParser.h \
 	ResponseParser.cc \
 	ResponseParser.h \
 	TeChunkedParser.cc \
-	TeChunkedParser.h
+	TeChunkedParser.h \
+	Tokenizer.cc \
+	Tokenizer.h

=== modified file 'src/http/one/Parser.cc'
--- src/http/one/Parser.cc	2015-03-05 10:19:47 +0000
+++ src/http/one/Parser.cc	2015-04-10 09:05:02 +0000
@@ -1,49 +1,49 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #include "squid.h"
 #include "Debug.h"
 #include "http/one/Parser.h"
+#include "http/one/Tokenizer.h"
 #include "mime_header.h"
-#include "parser/Tokenizer.h"
 #include "SquidConfig.h"
 
 /// RFC 7230 section 2.6 - 7 magic octets
 const SBuf Http::One::Parser::Http1magic("HTTP/1.");
 
 void
 Http::One::Parser::clear()
 {
     parsingStage_ = HTTP_PARSE_NONE;
     buf_ = NULL;
     msgProtocol_ = AnyP::ProtocolVersion();
     mimeHeaderBlock_.clear();
 }
 
 bool
-Http::One::Parser::skipLineTerminator(::Parser::Tokenizer &tok) const
+Http::One::Parser::skipLineTerminator(Http1::Tokenizer &tok) const
 {
     static const SBuf crlf("\r\n");
     if (tok.skip(crlf))
         return true;
 
     if (Config.onoff.relaxed_header_parser && tok.skipOne(CharacterSet::LF))
         return true;
 
     return false;
 }
 
 bool
 Http::One::Parser::grabMimeBlock(const char *which, const size_t limit)
 {
     // MIME headers block exist in (only) HTTP/1.x and ICY
     const bool expectMime = (msgProtocol_.protocol == AnyP::PROTO_HTTP && msgProtocol_.major == 1) ||
                             msgProtocol_.protocol == AnyP::PROTO_ICY;
 
     if (expectMime) {
         /* NOTE: HTTP/0.9 messages do not have a mime header block.
@@ -85,59 +85,59 @@
 }
 
 // arbitrary maximum-length for headers which can be found by Http1Parser::getHeaderField()
 #define GET_HDR_SZ  1024
 
 // BUG: returns only the first header line with given name,
 //      ignores multi-line headers and obs-fold headers
 char *
 Http::One::Parser::getHeaderField(const char *name)
 {
     if (!headerBlockSize() || !name)
         return NULL;
 
     LOCAL_ARRAY(char, header, GET_HDR_SZ);
     const int namelen = strlen(name);
 
     debugs(25, 5, "looking for " << name);
 
     // while we can find more LF in the SBuf
     static CharacterSet iso8859Line = CharacterSet("non-LF",'\0','\n'-1) + CharacterSet(NULL, '\n'+1, (unsigned char)0xFF);
-    ::Parser::Tokenizer tok(mimeHeaderBlock_);
+    Http1::Tokenizer tok(mimeHeaderBlock_);
     SBuf p;
     static const SBuf crlf("\r\n");
 
     while (tok.prefix(p, iso8859Line)) {
         if (!tok.skipOne(CharacterSet::LF)) // move tokenizer past the LF
             break; // error. reached invalid octet or end of buffer insted of an LF ??
 
         // header lines must start with the name (case insensitive)
         if (p.substr(0, namelen).caseCmp(name, namelen))
             continue;
 
         // then a COLON
         if (p[namelen] != ':')
             continue;
 
         // drop any trailing *CR sequence
         p.trim(crlf, false, true);
 
         debugs(25, 5, "checking " << p);
         p.consume(namelen + 1);
 
         // TODO: optimize SBuf::trim to take CharacterSet directly
-        ::Parser::Tokenizer t(p);
+        Http1::Tokenizer t(p);
         t.skipAll(CharacterSet::WSP);
         p = t.remaining();
 
         // prevent buffer overrun on char header[];
         p.chop(0, sizeof(header)-1);
 
         // return the header field-value
         xstrncpy(header, p.rawContent(), p.length()+1);
         debugs(25, 5, "returning " << header);
         return header;
     }
 
     return NULL;
 }
 

=== modified file 'src/http/one/Parser.h'
--- src/http/one/Parser.h	2015-03-29 14:11:36 +0000
+++ src/http/one/Parser.h	2015-06-09 01:57:21 +0000
@@ -1,40 +1,36 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef _SQUID_SRC_HTTP_ONE_PARSER_H
 #define _SQUID_SRC_HTTP_ONE_PARSER_H
 
 #include "anyp/ProtocolVersion.h"
 #include "http/one/forward.h"
 #include "http/StatusCode.h"
 #include "SBuf.h"
 
-namespace Parser {
-class Tokenizer;
-}
-
 namespace Http {
 namespace One {
 
 // Parser states
 enum ParseState {
     HTTP_PARSE_NONE,      ///< initialized, but nothing usefully parsed yet
     HTTP_PARSE_FIRST,     ///< HTTP/1 message first-line
     HTTP_PARSE_CHUNK_SZ,  ///< HTTP/1.1 chunked encoding chunk-size
     HTTP_PARSE_CHUNK_EXT, ///< HTTP/1.1 chunked encoding chunk-ext
     HTTP_PARSE_CHUNK,     ///< HTTP/1.1 chunked encoding chunk-data
     HTTP_PARSE_MIME,      ///< HTTP/1 mime-header block
     HTTP_PARSE_DONE       ///< parsed a message header, or reached a terminal syntax error
 };
 
 /** HTTP/1.x protocol parser
  *
  * Works on a raw character I/O buffer and tokenizes the content into
  * the major CRLF delimited segments of an HTTP/1 procotol message:
  *
  * \item first-line (request-line / simple-request / status-line)
@@ -91,41 +87,41 @@
      * \return A pointer to a field-value of the first matching field-name, or NULL.
      */
     char *getHeaderField(const char *name);
 
     /// the remaining unprocessed section of buffer
     const SBuf &remaining() const {return buf_;}
 
     /**
      * HTTP status code resulting from the parse process.
      * to be used on the invalid message handling.
      *
      * Http::scNone indicates incomplete parse,
      * Http::scOkay indicates no error,
      * other codes represent a parse error.
      */
     Http::StatusCode parseStatusCode;
 
 protected:
     /// detect and skip the CRLF or (if tolerant) LF line terminator
     /// consume from the tokenizer and return true only if found
-    bool skipLineTerminator(::Parser::Tokenizer &tok) const;
+    bool skipLineTerminator(Http1::Tokenizer &tok) const;
 
     /**
      * Scan to find the mime headers block for current message.
      *
      * \retval true   If mime block (or a blocks non-existence) has been
      *                identified accurately within limit characters.
      *                mimeHeaderBlock_ has been updated and buf_ consumed.
      *
      * \retval false  An error occured, or no mime terminator found within limit.
      */
     bool grabMimeBlock(const char *which, const size_t limit);
 
     /// RFC 7230 section 2.6 - 7 magic octets
     static const SBuf Http1magic;
 
     /// bytes remaining to be parsed
     SBuf buf_;
 
     /// what stage the parser is currently up to
     ParseState parsingStage_;

=== modified file 'src/http/one/RequestParser.cc'
--- src/http/one/RequestParser.cc	2015-02-20 03:25:12 +0000
+++ src/http/one/RequestParser.cc	2015-04-10 09:05:05 +0000
@@ -1,33 +1,33 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #include "squid.h"
 #include "Debug.h"
 #include "http/one/RequestParser.h"
+#include "http/one/Tokenizer.h"
 #include "http/ProtocolVersion.h"
-#include "parser/Tokenizer.h"
 #include "profiler/Profiler.h"
 #include "SquidConfig.h"
 
 Http::One::RequestParser::RequestParser() :
     Parser(),
     firstLineGarbage_(0)
 {}
 
 Http1::Parser::size_type
 Http::One::RequestParser::firstLineSize() const
 {
     // RFC 7230 section 2.6
     /* method SP request-target SP "HTTP/" DIGIT "." DIGIT CRLF */
     return method_.image().length() + uri_.length() + 12;
 }
 
 /**
  * Attempt to parse the first line of a new request message.
  *
  * Governed by RFC 7230 section 3.5
@@ -55,41 +55,41 @@
         }
     }
 }
 
 /**
  * Attempt to parse the method field out of an HTTP message request-line.
  *
  * Governed by:
  *  RFC 1945 section 5.1
  *  RFC 7230 section 2.6, 3.1 and 3.5
  *
  * Parsing state is stored between calls. The current implementation uses
  * checkpoints after each successful request-line field.
  * The return value tells you whether the parsing is completed or not.
  *
  * \retval -1  an error occurred. parseStatusCode indicates HTTP status result.
  * \retval  1  successful parse. method_ is filled and buffer consumed including first delimiter.
  * \retval  0  more data is needed to complete the parse
  */
 int
-Http::One::RequestParser::parseMethodField(::Parser::Tokenizer &tok, const CharacterSet &WspDelim)
+Http::One::RequestParser::parseMethodField(Http1::Tokenizer &tok, const CharacterSet &WspDelim)
 {
     // scan for up to 16 valid method characters.
     static const size_t maxMethodLength = 16; // TODO: make this configurable?
 
     // method field is a sequence of TCHAR.
     SBuf methodFound;
     if (tok.prefix(methodFound, CharacterSet::TCHAR, maxMethodLength) && tok.skipOne(WspDelim)) {
 
         method_ = HttpRequestMethod(methodFound);
         buf_ = tok.remaining(); // incremental parse checkpoint
         return 1;
 
     } else if (tok.atEnd()) {
         debugs(74, 5, "Parser needs more data to find method");
         return 0;
 
     } // else error(s)
 
     // non-delimiter found after accepted method bytes means ...
     if (methodFound.length() == maxMethodLength) {
@@ -115,41 +115,41 @@
      * "
      *   A URI is composed from a limited set of characters consisting of
      *   digits, letters, and a few graphic symbols.
      * "
      */
     // RFC 3986 section 2.1 - percent encoding "%" HEXDIG
     UriChars.add('%');
     UriChars += CharacterSet::HEXDIG;
     // RFC 3986 section 2.2 - reserved characters
     UriChars += CharacterSet("gen-delims", ":/?#[]@");
     UriChars += CharacterSet("sub-delims", "!$&'()*+,;=");
     // RFC 3986 section 2.3 - unreserved characters
     UriChars += CharacterSet::ALPHA;
     UriChars += CharacterSet::DIGIT;
     UriChars += CharacterSet("unreserved", "-._~");
 
     return UriChars;
 }
 
 int
-Http::One::RequestParser::parseUriField(::Parser::Tokenizer &tok)
+Http::One::RequestParser::parseUriField(Http1::Tokenizer &tok)
 {
     // URI field is a sequence of ... what? segments all have different valid charset
     // go with non-whitespace non-binary characters for now
     static CharacterSet UriChars = uriValidCharacters();
 
     /* Arbitrary 64KB URI upper length limit.
      *
      * Not quite as arbitrary as it seems though. Old SquidString objects
      * cannot store strings larger than 64KB, so we must limit until they
      * have all been replaced with SBuf.
      *
      * Not that it matters but RFC 7230 section 3.1.1 requires (RECOMMENDED)
      * at least 8000 octets for the whole line, including method and version.
      */
     const size_t maxUriLength = min(static_cast<size_t>(Config.maxRequestHeaderSize) - firstLineSize(),
                                     static_cast<size_t>((64*1024)-1));
 
     SBuf uriFound;
 
     // RFC 7230 HTTP/1.x URI are followed by at least one whitespace delimiter
@@ -170,41 +170,41 @@
     } else if (tok.atEnd()) {
         debugs(74, 5, "Parser needs more data to find URI");
         return 0;
     }
 
     // else errors...
 
     if (uriFound.length() == maxUriLength) {
         // RFC 7230 section 3.1.1 mandatory (MUST) 414 response
         parseStatusCode = Http::scUriTooLong;
         debugs(33, 5, "invalid request-line. URI longer than " << maxUriLength << " bytes");
     } else {
         // RFC 7230 section 3.1.1 required (SHOULD) 400 response
         parseStatusCode = Http::scBadRequest;
         debugs(33, 5, "invalid request-line. missing URI delimiter");
     }
     return -1;
 }
 
 int
-Http::One::RequestParser::parseHttpVersionField(::Parser::Tokenizer &tok)
+Http::One::RequestParser::parseHttpVersionField(Http1::Tokenizer &tok)
 {
     // partial match of HTTP/1 magic prefix
     if (tok.remaining().length() < Http1magic.length() && Http1magic.startsWith(tok.remaining())) {
         debugs(74, 5, "Parser needs more data to find version");
         return 0;
     }
 
     if (!tok.skip(Http1magic)) {
         debugs(74, 5, "invalid request-line. not HTTP/1 protocol");
         parseStatusCode = Http::scHttpVersionNotSupported;
         return -1;
     }
 
     if (tok.atEnd()) {
         debugs(74, 5, "Parser needs more data to find version");
         return 0;
     }
 
     // get the version minor DIGIT
     SBuf digit;
@@ -229,41 +229,41 @@
 }
 
 /**
  * Attempt to parse the first line of a new request message.
  *
  * Governed by:
  *  RFC 1945 section 5.1
  *  RFC 7230 section 2.6, 3.1 and 3.5
  *
  * Parsing state is stored between calls. The current implementation uses
  * checkpoints after each successful request-line field.
  * The return value tells you whether the parsing is completed or not.
  *
  * \retval -1  an error occurred. parseStatusCode indicates HTTP status result.
  * \retval  1  successful parse. member fields contain the request-line items
  * \retval  0  more data is needed to complete the parse
  */
 int
 Http::One::RequestParser::parseRequestFirstLine()
 {
-    ::Parser::Tokenizer tok(buf_);
+    Http1::Tokenizer tok(buf_);
 
     debugs(74, 5, "parsing possible request: buf.length=" << buf_.length());
     debugs(74, DBG_DATA, buf_);
 
     // NP: would be static, except it need to change with reconfigure
     CharacterSet WspDelim = CharacterSet::SP; // strict parse only accepts SP
 
     if (Config.onoff.relaxed_header_parser) {
         // RFC 7230 section 3.5
         // tolerant parser MAY accept any of SP, HTAB, VT (%x0B), FF (%x0C), or bare CR
         // as whitespace between request-line fields
         WspDelim += CharacterSet::HTAB
                     + CharacterSet("VT,FF","\x0B\x0C")
                     + CharacterSet::CR;
     }
 
     // only search for method if we have not yet found one
     if (method_ == Http::METHOD_NONE) {
         const int res = parseMethodField(tok, WspDelim);
         if (res < 1)
@@ -280,41 +280,41 @@
         }
     }
     if (tok.atEnd()) {
         debugs(74, 5, "Parser needs more data");
         return 0;
     }
 
     // from here on, we have two possible parse paths: whitespace tolerant, and strict
     if (Config.onoff.relaxed_header_parser) {
         // whitespace tolerant
 
         // NOTES:
         // * this would be static, except WspDelim changes with reconfigure
         // * HTTP-version charset is included by uriValidCharacters()
         // * terminal CR is included by WspDelim here in relaxed parsing
         CharacterSet LfDelim = uriValidCharacters() + WspDelim;
 
         // seek the LF character, then tokenize the line in reverse
         SBuf line;
         if (tok.prefix(line, LfDelim) && tok.skip('\n')) {
-            ::Parser::Tokenizer rTok(line);
+            Http1::Tokenizer rTok(line);
             SBuf nil;
             (void)rTok.suffix(nil,CharacterSet::CR); // optional CR in terminator
             SBuf digit;
             if (rTok.suffix(digit,CharacterSet::DIGIT) && rTok.skipSuffix(Http1magic) && rTok.suffix(nil,WspDelim)) {
                 uri_ = rTok.remaining();
                 msgProtocol_ = Http::ProtocolVersion(1, (*digit.rawContent() - '0'));
                 if (uri_.isEmpty()) {
                     debugs(33, 5, "invalid request-line. missing URL");
                     parseStatusCode = Http::scBadRequest;
                     return -1;
                 }
 
                 parseStatusCode = Http::scOkay;
                 buf_ = tok.remaining(); // incremental parse checkpoint
                 return 1;
 
             } else if (method_ == Http::METHOD_GET) {
                 // RFC 1945 - for GET the line terminator may follow URL instead of a delimiter
                 debugs(33, 5, "HTTP/0.9 syntax request-line detected");
                 msgProtocol_ = Http::ProtocolVersion(0,9);

=== modified file 'src/http/one/RequestParser.h'
--- src/http/one/RequestParser.h	2015-02-20 03:25:12 +0000
+++ src/http/one/RequestParser.h	2015-04-10 09:05:06 +0000
@@ -30,40 +30,40 @@
 class RequestParser : public Http1::Parser
 {
 public:
     RequestParser();
     virtual ~RequestParser() {}
 
     /* Http::One::Parser API */
     virtual void clear() {*this = RequestParser();}
     virtual Http1::Parser::size_type firstLineSize() const;
     virtual bool parse(const SBuf &aBuf);
 
     /// the HTTP method if this is a request message
     const HttpRequestMethod & method() const {return method_;}
 
     /// the request-line URI if this is a request message, or an empty string.
     const SBuf &requestUri() const {return uri_;}
 
 private:
     void skipGarbageLines();
     int parseRequestFirstLine();
-    int parseMethodField(::Parser::Tokenizer &, const CharacterSet &);
-    int parseUriField(::Parser::Tokenizer &);
-    int parseHttpVersionField(::Parser::Tokenizer &);
+    int parseMethodField(Http1::Tokenizer &, const CharacterSet &);
+    int parseUriField(Http1::Tokenizer &);
+    int parseHttpVersionField(Http1::Tokenizer &);
 
     /// what request method has been found on the first line
     HttpRequestMethod method_;
 
     /// raw copy of the original client request-line URI field
     SBuf uri_;
 
     /// amount of garbage bytes tolerantly skipped inside the request-line
     /// may be -1 if sender only omitted CR on terminator
     int64_t firstLineGarbage_;
 };
 
 } // namespace One
 } // namespace Http
 
 #endif /*  _SQUID_SRC_HTTP_ONE_REQUESTPARSER_H */
 

=== modified file 'src/http/one/ResponseParser.cc'
--- src/http/one/ResponseParser.cc	2015-03-01 08:37:07 +0000
+++ src/http/one/ResponseParser.cc	2015-04-10 09:05:08 +0000
@@ -1,70 +1,70 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #include "squid.h"
 #include "Debug.h"
 #include "http/one/ResponseParser.h"
+#include "http/one/Tokenizer.h"
 #include "http/ProtocolVersion.h"
-#include "parser/Tokenizer.h"
 #include "profiler/Profiler.h"
 #include "SquidConfig.h"
 
 const SBuf Http::One::ResponseParser::IcyMagic("ICY ");
 
 Http1::Parser::size_type
 Http::One::ResponseParser::firstLineSize() const
 {
     Http1::Parser::size_type result = 0;
 
     switch (msgProtocol_.protocol)
     {
     case AnyP::PROTO_HTTP:
         result += Http1magic.length();
         break;
     case AnyP::PROTO_ICY:
         result += IcyMagic.length();
         break;
     default: // no other protocols supported
         return result;
     }
     // NP: the parser does not accept >2 DIGIT for version numbers
     if (msgProtocol_.minor > 9)
         result += 2;
     else
         result += 1;
 
     result += 5; /* 5 octets in: SP status SP */
     result += reasonPhrase_.length();
     result += 2; /* CRLF terminator */
     return result;
 }
 
 // NP: we found the protocol version and consumed it already.
 // just need the status code and reason phrase
 int
-Http::One::ResponseParser::parseResponseStatusAndReason(::Parser::Tokenizer &tok, const CharacterSet &WspDelim)
+Http::One::ResponseParser::parseResponseStatusAndReason(Http1::Tokenizer &tok, const CharacterSet &WspDelim)
 {
     if (!completedStatus_) {
         debugs(74, 9, "seek status-code in: " << tok.remaining().substr(0,10) << "...");
         /* RFC 7230 section 3.1.2 - status code is 3 DIGIT octets.
          * There is no limit on what those octets may be.
          * 000 through 999 are all valid.
          */
         int64_t statusValue;
         if (tok.int64(statusValue, 10, false, 3) && tok.skipOne(WspDelim)) {
 
             debugs(74, 6, "found int64 status-code=" << statusValue);
             statusCode_ = static_cast<Http::StatusCode>(statusValue);
 
             buf_ = tok.remaining(); // resume checkpoint
             completedStatus_ = true;
 
         } else if (tok.atEnd()) {
             debugs(74, 6, "Parser needs more data");
             return 0; // need more to be sure we have it all
 
@@ -104,41 +104,41 @@
 }
 
 /**
  * Attempt to parse the method field out of an HTTP message status-line.
  *
  * Governed by:
  *  RFC 1945 section 6.1
  *  RFC 7230 section 2.6, 3.1 and 3.5
  *
  * Parsing state is stored between calls. The current implementation uses
  * checkpoints after each successful status-line field.
  * The return value tells you whether the parsing is completed or not.
  *
  * \retval -1  an error occurred.
  * \retval  1  successful parse. statusCode_ and maybe reasonPhrase_ are filled and buffer consumed including first delimiter.
  * \retval  0  more data is needed to complete the parse
  */
 int
 Http::One::ResponseParser::parseResponseFirstLine()
 {
-    ::Parser::Tokenizer tok(buf_);
+    Http1::Tokenizer tok(buf_);
 
     CharacterSet WspDelim = CharacterSet::SP; // strict parse only accepts SP
 
     if (Config.onoff.relaxed_header_parser) {
         // RFC 7230 section 3.5
         // tolerant parser MAY accept any of SP, HTAB, VT (%x0B), FF (%x0C), or bare CR
         // as whitespace between status-line fields
         WspDelim += CharacterSet::HTAB
                     + CharacterSet("VT,FF","\x0B\x0C")
                     + CharacterSet::CR;
     }
 
     if (msgProtocol_.protocol != AnyP::PROTO_NONE) {
         debugs(74, 6, "continue incremental parse for " << msgProtocol_);
         debugs(74, DBG_DATA, "parse remaining buf={length=" << tok.remaining().length() << ", data='" << tok.remaining() << "'}");
         // we already found the magic, but not the full line. keep going.
         return parseResponseStatusAndReason(tok, WspDelim);
 
     } else if (tok.skip(Http1magic)) {
         debugs(74, 6, "found prefix magic " << Http1magic);

=== modified file 'src/http/one/ResponseParser.h'
--- src/http/one/ResponseParser.h	2015-03-05 10:00:37 +0000
+++ src/http/one/ResponseParser.h	2015-04-10 09:05:09 +0000
@@ -26,41 +26,41 @@
  * \item status-line (version SP status SP reash-phrase)
  * \item mime-header (set of RFC2616 syntax header fields)
  */
 class ResponseParser : public Http1::Parser
 {
 public:
     ResponseParser() : Parser(), completedStatus_(false), statusCode_(Http::scNone) {}
     virtual ~ResponseParser() {}
 
     /* Http::One::Parser API */
     virtual void clear() {*this=ResponseParser();}
     virtual Http1::Parser::size_type firstLineSize() const;
     virtual bool parse(const SBuf &aBuf);
 
     /* respone specific fields, read-only */
     Http::StatusCode messageStatus() const { return statusCode_;}
     SBuf reasonPhrase() const { return reasonPhrase_;}
 
 private:
     int parseResponseFirstLine();
-    int parseResponseStatusAndReason(::Parser::Tokenizer&, const CharacterSet &);
+    int parseResponseStatusAndReason(Http1::Tokenizer&, const CharacterSet &);
 
     /// magic prefix for identifying ICY response messages
     static const SBuf IcyMagic;
 
     /// Whether we found the status code yet.
     /// We cannot rely on status value because server may send "000".
     bool completedStatus_;
 
     /// HTTP/1 status-line status code
     Http::StatusCode statusCode_;
 
     /// HTTP/1 status-line reason phrase
     SBuf reasonPhrase_;
 };
 
 } // namespace One
 } // namespace Http
 
 #endif /* _SQUID_SRC_HTTP_ONE_RESPONSEPARSER_H */
 

=== modified file 'src/http/one/TeChunkedParser.cc'
--- src/http/one/TeChunkedParser.cc	2015-06-01 21:41:37 +0000
+++ src/http/one/TeChunkedParser.cc	2015-06-09 02:08:47 +0000
@@ -1,214 +1,206 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #include "squid.h"
 #include "base/TextException.h"
 #include "Debug.h"
 #include "http/one/TeChunkedParser.h"
+#include "http/one/Tokenizer.h"
 #include "http/ProtocolVersion.h"
 #include "MemBuf.h"
-#include "parser/Tokenizer.h"
 #include "Parsing.h"
 
 Http::One::TeChunkedParser::TeChunkedParser()
 {
     // chunked encoding only exists in HTTP/1.1
     Http1::Parser::msgProtocol_ = Http::ProtocolVersion(1,1);
 
     clear();
 }
 
 void
 Http::One::TeChunkedParser::clear()
 {
     parsingStage_ = Http1::HTTP_PARSE_NONE;
     buf_.clear();
     theChunkSize = theLeftBodySize = 0;
     theOut = NULL;
     useOriginBody = -1;
 }
 
 bool
 Http::One::TeChunkedParser::parse(const SBuf &aBuf)
 {
     buf_ = aBuf; // sync buffers first so calls to remaining() work properly if nothing done.
 
     if (buf_.isEmpty()) // nothing to do (yet)
         return false;
 
     debugs(74, DBG_DATA, "Parse buf={length=" << aBuf.length() << ", data='" << aBuf << "'}");
 
     Must(!buf_.isEmpty() && theOut);
 
     if (parsingStage_ == Http1::HTTP_PARSE_NONE)
         parsingStage_ = Http1::HTTP_PARSE_CHUNK_SZ;
 
-    ::Parser::Tokenizer tok(buf_);
+    Http1::Tokenizer tok(buf_);
 
     // loop for as many chunks as we can
     // use do-while instead of while so that we can incrementally
     // restart in the middle of a chunk/frame
     do {
 
         if (parsingStage_ == Http1::HTTP_PARSE_CHUNK_EXT && !parseChunkExtension(tok, theChunkSize))
             return false;
 
         if (parsingStage_ == Http1::HTTP_PARSE_CHUNK && !parseChunkBody(tok))
             return false;
 
         if (parsingStage_ == Http1::HTTP_PARSE_MIME && !grabMimeBlock("Trailers", 64*1024 /* 64KB max */))
             return false;
 
         // loop for as many chunks as we can
     } while (parsingStage_ == Http1::HTTP_PARSE_CHUNK_SZ && parseChunkSize(tok));
 
     return !needsMoreData() && !needsMoreSpace();
 }
 
 bool
 Http::One::TeChunkedParser::needsMoreSpace() const
 {
     assert(theOut);
     return parsingStage_ == Http1::HTTP_PARSE_CHUNK && !theOut->hasPotentialSpace();
 }
 
 /// RFC 7230 section 4.1 chunk-size
 bool
-Http::One::TeChunkedParser::parseChunkSize(::Parser::Tokenizer &tok)
+Http::One::TeChunkedParser::parseChunkSize(Http1::Tokenizer &tok)
 {
     Must(theChunkSize <= 0); // Should(), really
 
     int64_t size = -1;
     if (tok.int64(size, 16, false) && !tok.atEnd()) {
         if (size < 0)
             throw TexcHere("negative chunk size");
 
         theChunkSize = theLeftBodySize = size;
         debugs(94,7, "found chunk: " << theChunkSize);
         buf_ = tok.remaining(); // parse checkpoint
         parsingStage_ = Http1::HTTP_PARSE_CHUNK_EXT;
         return true;
 
     } else if (tok.atEnd()) {
         return false; // need more data
     }
 
     // else error
     throw TexcHere("corrupted chunk size");
     return false; // should not be reachable
 }
 
 /**
  * Parses a set of RFC 7230 section 4.1.1 chunk-ext
  * http://tools.ietf.org/html/rfc7230#section-4.1.1
  *
  *   chunk-ext      = *( ";" chunk-ext-name [ "=" chunk-ext-val ] )
  *   chunk-ext-name = token
  *   chunk-ext-val  = token / quoted-string
  *
  * ICAP 'use-original-body=N' extension is supported.
  */
 bool
-Http::One::TeChunkedParser::parseChunkExtension(::Parser::Tokenizer &tok, bool skipKnown)
+Http::One::TeChunkedParser::parseChunkExtension(Http1::Tokenizer &tok, bool skipKnown)
 {
-    // TODO implement a proper quoted-string Tokenizer method
-    static const CharacterSet qString = CharacterSet("qString","\"\r\n").add('\0').complement();
-
     SBuf ext;
+    SBuf value;
     while (tok.skip(';') && tok.prefix(ext, CharacterSet::TCHAR)) {
 
         // whole value part is optional. if no '=' expect next chunk-ext
         if (tok.skip('=')) {
 
             if (!skipKnown) {
                 if (ext.cmp("use-original-body",17) == 0 && tok.int64(useOriginBody, 10)) {
                     debugs(94, 3, "Found chunk extension " << ext << "=" << useOriginBody);
                     buf_ = tok.remaining(); // parse checkpoint
                     continue;
                 }
             }
 
             debugs(94, 5, "skipping unknown chunk extension " << ext);
 
-            // unknown might have a value token ...
-            if (tok.skipAll(CharacterSet::TCHAR) && !tok.atEnd()) {
-                buf_ = tok.remaining(); // parse checkpoint
-                continue;
-            }
-
-            // ... or a quoted-string
-            if (tok.skipOne(CharacterSet::DQUOTE) && tok.skipAll(qString) && tok.skipOne(CharacterSet::DQUOTE)) {
+            // unknown might have a value token or quoted-string
+            if (tok.quotedStringOrToken(value) && !tok.atEnd()) {
                 buf_ = tok.remaining(); // parse checkpoint
                 continue;
             }
 
             // otherwise need more data OR corrupt syntax
             break;
         }
 
         if (!tok.atEnd())
             buf_ = tok.remaining(); // parse checkpoint (unless there might be more token name)
     }
 
     if (tok.atEnd())
         return false;
 
     if (skipLineTerminator(tok)) {
         buf_ = tok.remaining(); // checkpoint
         // non-0 chunk means data, 0-size means optional Trailer follows
         parsingStage_ = theChunkSize ? Http1::HTTP_PARSE_CHUNK : Http1::HTTP_PARSE_MIME;
         return true;
     }
 
     throw TexcHere("corrupted chunk extension value");
     return false;
 }
 
 bool
-Http::One::TeChunkedParser::parseChunkBody(::Parser::Tokenizer &tok)
+Http::One::TeChunkedParser::parseChunkBody(Http1::Tokenizer &tok)
 {
     Must(theLeftBodySize > 0); // Should, really
 
     buf_ = tok.remaining(); // sync buffers before buf_ use
 
     // TODO fix type mismatches and casting for these
     const size_t availSize = min(theLeftBodySize, (uint64_t)buf_.length());
     const size_t safeSize = min(availSize, (size_t)theOut->potentialSpaceSize());
 
     theOut->append(buf_.rawContent(), safeSize);
     buf_.consume(safeSize);
     theLeftBodySize -= safeSize;
 
     tok.reset(buf_); // sync buffers after consume()
 
     if (theLeftBodySize == 0)
         return parseChunkEnd(tok);
     else
         Must(needsMoreData() || needsMoreSpace());
 
     return true;
 }
 
 bool
-Http::One::TeChunkedParser::parseChunkEnd(::Parser::Tokenizer &tok)
+Http::One::TeChunkedParser::parseChunkEnd(Http1::Tokenizer &tok)
 {
     Must(theLeftBodySize == 0); // Should(), really
 
     if (skipLineTerminator(tok)) {
         buf_ = tok.remaining(); // parse checkpoint
         theChunkSize = 0; // done with the current chunk
         parsingStage_ = Http1::HTTP_PARSE_CHUNK_SZ;
         return true;
 
     } else if (!tok.atEnd()) {
         throw TexcHere("found data between chunk end and CRLF");
     }
 
     return false;
 }
 

=== modified file 'src/http/one/TeChunkedParser.h'
--- src/http/one/TeChunkedParser.h	2015-06-01 21:41:37 +0000
+++ src/http/one/TeChunkedParser.h	2015-06-09 02:06:49 +0000
@@ -28,38 +28,38 @@
  * Ignores chunk extensions except for ICAP's ieof.
  * Trailers are available via mimeHeader() if wanted.
  */
 class TeChunkedParser : public Http1::Parser
 {
 public:
     TeChunkedParser();
     virtual ~TeChunkedParser() {theOut=NULL;/* we dont own this object */}
 
     /// set the buffer to be used to store decoded chunk data
     void setPayloadBuffer(MemBuf *parsedContent) {theOut = parsedContent;}
 
     bool needsMoreSpace() const;
 
     /* Http1::Parser API */
     virtual void clear();
     virtual bool parse(const SBuf &);
     virtual Parser::size_type firstLineSize() const {return 0;} // has no meaning with multiple chunks
 
 private:
-    bool parseChunkSize(::Parser::Tokenizer &tok);
-    bool parseChunkExtension(::Parser::Tokenizer &tok, bool skipKnown);
-    bool parseChunkBody(::Parser::Tokenizer &tok);
-    bool parseChunkEnd(::Parser::Tokenizer &tok);
+    bool parseChunkSize(Http1::Tokenizer &tok);
+    bool parseChunkExtension(Http1::Tokenizer &tok, bool skipKnown);
+    bool parseChunkBody(Http1::Tokenizer &tok);
+    bool parseChunkEnd(Http1::Tokenizer &tok);
 
     MemBuf *theOut;
     uint64_t theChunkSize;
     uint64_t theLeftBodySize;
 
 public:
     int64_t useOriginBody;
 };
 
 } // namespace One
 } // namespace Http
 
 #endif /* SQUID_SRC_HTTP_ONE_TeChunkedParser_H */
 

=== added file 'src/http/one/Tokenizer.cc'
--- src/http/one/Tokenizer.cc	1970-01-01 00:00:00 +0000
+++ src/http/one/Tokenizer.cc	2015-06-09 14:45:44 +0000
@@ -0,0 +1,109 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#include "squid.h"
+#include "Debug.h"
+#include "http/one/Tokenizer.h"
+
+bool
+Http::One::Tokenizer::quotedString(SBuf &returnedToken, const bool http1p0)
+{
+    checkpoint();
+
+    if (!skip('"'))
+        return false;
+
+    return qdText(returnedToken, http1p0);
+}
+
+bool
+Http::One::Tokenizer::quotedStringOrToken(SBuf &returnedToken, const bool http1p0)
+{
+    checkpoint();
+
+    if (!skip('"'))
+        return prefix(returnedToken, CharacterSet::TCHAR);
+
+    return qdText(returnedToken, http1p0);
+}
+
+bool
+Http::One::Tokenizer::qdText(SBuf &returnedToken, const bool http1p0)
+{
+    // the initial DQUOTE has been skipped by the caller
+
+    /*
+     * RFC 1945 - defines qdtext:
+     *   inclusive of LWS (which includes CR and LF)
+     *   exclusive of 0x80-0xFF
+     *   includes 0x5C ('\') as just a regular character
+     */
+    static const CharacterSet qdtext1p0 = CharacterSet("qdtext (HTTP/1.0)", 0x23, 0x7E) +
+                                          CharacterSet("", "!") +
+                                          CharacterSet::CR + CharacterSet::LF + CharacterSet::HTAB + CharacterSet::SP;
+    /*
+     * RFC 7230 - defines qdtext:
+     *   exclusive of CR and LF
+     *   inclusive of 0x80-0xFF
+     *   includes 0x5C ('\') but only when part of quoted-pair
+     */
+    static const CharacterSet qdtext1p1 = CharacterSet("qdtext (HTTP/1.1)", 0x23, 0x5B) +
+                                          CharacterSet("", "!") +
+                                          CharacterSet("", 0x5D, 0x7E) +
+                                          CharacterSet::HTAB + CharacterSet::SP +
+                                          CharacterSet::OBSTEXT;
+
+    // best we can do is a conditional reference since http1p0 value may change per-client
+    const CharacterSet &tokenChars = (http1p0 ? qdtext1p0 : qdtext1p1);
+
+    for (;;) {
+        SBuf::size_type prefixLen = buf().findFirstNotOf(tokenChars);
+        returnedToken.append(consume(prefixLen));
+
+        // HTTP/1.1 allows quoted-pair, HTTP/1.0 does not
+        if (!http1p0 && skip('\\')) {
+            /* RFC 7230 section 3.2.6
+             *
+             * The backslash octet ("\") can be used as a single-octet quoting
+             * mechanism within quoted-string and comment constructs.  Recipients
+             * that process the value of a quoted-string MUST handle a quoted-pair
+             * as if it were replaced by the octet following the backslash.
+             *
+             *   quoted-pair    = "\" ( HTAB / SP / VCHAR / obs-text )
+             */
+            static const CharacterSet qPairChars = CharacterSet::HTAB + CharacterSet::SP + CharacterSet::VCHAR + CharacterSet::OBSTEXT;
+            SBuf escaped;
+            if (!prefix(escaped, qPairChars, 1)) {
+                returnedToken.clear();
+                restoreLastCheckpoint();
+                return false;
+            }
+            returnedToken.append(escaped);
+            continue;
+
+        } else if (skip('"')) {
+            break; // done
+
+        } else if (atEnd()) {
+            // need more data
+            returnedToken.clear();
+            restoreLastCheckpoint();
+            return false;
+        }
+
+        // else, we have an error
+        debugs(24, 8, "invalid bytes for set " << tokenChars.name);
+        returnedToken.clear();
+        restoreLastCheckpoint();
+        return false;
+    }
+
+    // found the whole string
+    return true;
+}
+

=== added file 'src/http/one/Tokenizer.h'
--- src/http/one/Tokenizer.h	1970-01-01 00:00:00 +0000
+++ src/http/one/Tokenizer.h	2015-04-10 10:58:57 +0000
@@ -0,0 +1,79 @@
+/*
+ * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
+ *
+ * Squid software is distributed under GPLv2+ license and includes
+ * contributions from numerous individuals and organizations.
+ * Please see the COPYING and CONTRIBUTORS files for details.
+ */
+
+#ifndef SQUID_SRC_HTTP_ONE_TOKENIZER_H
+#define SQUID_SRC_HTTP_ONE_TOKENIZER_H
+
+#include "parser/Tokenizer.h"
+
+namespace Http {
+namespace One {
+
+/**
+ * Lexical processor extended to tokenize HTTP/1.x syntax.
+ *
+ * \see ::Parser::Tokenizer for more detail
+ */
+class Tokenizer : public ::Parser::Tokenizer
+{
+public:
+    Tokenizer(SBuf &s) : ::Parser::Tokenizer(s) {}
+
+    /**
+     * Attempt to parse a quoted-string lexical construct.
+     *
+     * Governed by:
+     *  - RFC 1945 section 2.1
+     *  "
+     *    A string of text is parsed as a single word if it is quoted using
+     *    double-quote marks.
+     *
+     *        quoted-string  = ( <"> *(qdtext) <"> )
+     *
+     *        qdtext         = <any CHAR except <"> and CTLs,
+     *                         but including LWS>
+     *
+     *    Single-character quoting using the backslash ("\") character is not
+     *    permitted in HTTP/1.0.
+     *  "
+     *
+     *  - RFC 7230 section 3.2.6
+     *  "
+     *    A string of text is parsed as a single value if it is quoted using
+     *    double-quote marks.
+     *
+     *    quoted-string  = DQUOTE *( qdtext / quoted-pair ) DQUOTE
+     *    qdtext         = HTAB / SP /%x21 / %x23-5B / %x5D-7E / obs-text
+     *    obs-text       = %x80-FF
+     *  "
+     *
+     * \param escaped HTTP/1.0 does not permit \-escaped characters
+     */
+    bool quotedString(SBuf &value, const bool http1p0 = false);
+
+    /**
+     * Attempt to parse a (token / quoted-string ) lexical construct.
+     */
+    bool quotedStringOrToken(SBuf &value, const bool http1p0 = false);
+
+private:
+    /// parse the internal component of a quote-string, and terminal DQUOTE
+    bool qdText(SBuf &value, const bool http1p0);
+
+    void checkpoint() { savedCheckpoint_ = buf(); savedStats_ = parsedSize(); }
+    void restoreLastCheckpoint() { undoParse(savedCheckpoint_, savedStats_); }
+
+    SBuf savedCheckpoint_;
+    SBuf::size_type savedStats_;
+};
+
+} // namespace One
+} // namespace Http
+
+#endif /* SQUID_SRC_HTTP_ONE_TOKENIZER_H */
+

=== modified file 'src/http/one/forward.h'
--- src/http/one/forward.h	2015-06-01 21:41:37 +0000
+++ src/http/one/forward.h	2015-06-09 01:57:21 +0000
@@ -1,34 +1,36 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_SRC_HTTP_ONE_FORWARD_H
 #define SQUID_SRC_HTTP_ONE_FORWARD_H
 
 #include "base/RefCount.h"
 
 namespace Http {
 namespace One {
 
+class Tokenizer;
+
 class Parser;
 typedef RefCount<Http::One::Parser> ParserPointer;
 
 class TeChunkedParser;
 
 class RequestParser;
 typedef RefCount<Http::One::RequestParser> RequestParserPointer;
 
 class ResponseParser;
 typedef RefCount<Http::One::ResponseParser> ResponseParserPointer;
 
 } // namespace One
 } // namespace Http
 
 namespace Http1 = Http::One;
 
 #endif /* SQUID_SRC_HTTP_ONE_FORWARD_H */
 

=== modified file 'src/parser/Tokenizer.h'
--- src/parser/Tokenizer.h	2015-02-20 03:25:12 +0000
+++ src/parser/Tokenizer.h	2015-04-10 09:09:30 +0000
@@ -27,41 +27,41 @@
  * Methods returning false have no side-effects.
  */
 class Tokenizer
 {
 public:
     explicit Tokenizer(const SBuf &inBuf) : buf_(inBuf), parsed_(0) {}
 
     /// yet unparsed data
     SBuf buf() const { return buf_; }
 
     /// number of parsed bytes, including skipped ones
     SBuf::size_type parsedSize() const { return parsed_; }
 
     /// whether the end of the buffer has been reached
     bool atEnd() const { return buf_.isEmpty(); }
 
     /// the remaining unprocessed section of buffer
     const SBuf& remaining() const { return buf_; }
 
     /// reinitialize processing for a new buffer
-    void reset(const SBuf &newBuf) { buf_ = newBuf; parsed_ = 0; }
+    void reset(const SBuf &newBuf) { undoParse(newBuf, 0); }
 
     /** Basic strtok(3):
      *  Skips all leading delimiters (if any),
      *  extracts all characters up to the next delimiter (a token), and
      *  skips all trailing delimiters (at least one must be present).
      *
      *  Want to extract delimiters? Use prefix() instead.
      *
      *  Note that Tokenizer cannot tell whether the trailing delimiters will
      *  continue when/if more input data becomes available later.
      *
      * \return true if found a non-empty token followed by a delimiter
      */
     bool token(SBuf &returnedToken, const CharacterSet &delimiters);
 
     /** Extracts all sequential permitted characters up to an optional length limit.
      *
      *  Note that Tokenizer cannot tell whether the prefix will
      *  continue when/if more input data becomes available later.
      *
@@ -118,29 +118,32 @@
     /** Extracts an unsigned int64_t at the beginning of the buffer.
      *
      * strtoll(3)-alike function: tries to parse unsigned 64-bit integer
      * at the beginning of the parse buffer, in the base specified by the user
      * or guesstimated; consumes the parsed characters.
      *
      * \param result Output value. Not touched if parsing is unsuccessful.
      * \param base   Specify base to do the parsing in, with the same restrictions
      *               as strtoll. Defaults to 0 (meaning guess)
      * \param allowSign Whether to accept a '+' or '-' sign prefix.
      * \param limit  Maximum count of characters to convert.
      *
      * \return whether the parsing was successful
      */
     bool int64(int64_t &result, int base = 0, bool allowSign = true, SBuf::size_type limit = SBuf::npos);
 
 protected:
     SBuf consume(const SBuf::size_type n);
     SBuf::size_type success(const SBuf::size_type n);
 
+    /// reset the buffer and parsed stats to a saved checkpoint
+    void undoParse(const SBuf &newBuf, SBuf::size_type cParsed) { buf_ = newBuf; parsed_ = cParsed; }
+
 private:
     SBuf buf_; ///< yet unparsed input
     SBuf::size_type parsed_; ///< bytes successfully parsed, including skipped
 };
 
 } /* namespace Parser */
 
 #endif /* SQUID_PARSER_TOKENIZER_H_ */
 


From rousskov at measurement-factory.com  Fri Jun 12 04:52:57 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Jun 2015 22:52:57 -0600
Subject: [squid-dev] [RFC] TLS peek by default
In-Reply-To: <557226ED.7010204@treenet.co.nz>
References: <557226ED.7010204@treenet.co.nz>
Message-ID: <557A65A9.6040105@measurement-factory.com>

On 06/05/2015 04:47 PM, Amos Jeffries wrote:

> Along these lines, I am wondering why we need to have "ssl_bump peek"
> checked for in relation to client peeking. Can we make Squid simply do
> that first 'peek' step always for all potential HTTPS connections ?


IIRC, the reasons we did not want to peek by default included:

1. Worries about non-SSL protocols that expect the server to talk first.
If we require Squid to always peek, the transaction will get stuck. We
will need to add timeouts and such, further complicating the code and
configuration. The server-talks-first protocols are real, especially in
interception setups.

2. Worries about buggy code (ours, OpenSSL, and the combination of the
two) breaking stuff for folks that do not need to peek at all. In
retrospect, these worries were well founded -- IIRC, there were quite a
few problems with peeking at certain traffic that could be temporary
worked around by disabling peeking using ACLs.

Christos, did I forget any other reasons?


> This would also give SNI and the like up front and make Squid able to
> act lot more like what people in squid-users seem to be starting off
> assuming it does.

True. I think we could change how Squid does this, but I doubt simply
hard-coding peeking is a good idea for the reasons mentioned above. A
more flexible/elegant solution is probably needed (which may not exist
at all or may be more complex than your PROXY-specific project wants to
deal with).


HTH,

Alex.


From rousskov at measurement-factory.com  Fri Jun 12 04:56:50 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Jun 2015 22:56:50 -0600
Subject: [squid-dev] [PATCH] Segfault when freeing https_port clientca on
 reconfigure or exit
Message-ID: <557A6692.3030809@measurement-factory.com>

Fixed segmentation fault when freeing https_port clientca on reconfigure
or exit.

AnyP::PortCfg::clientCA list was double-freed, because the SSL context
takes ownership of the STACK_OF(X509_NAME) supplied via
SSL_CTX_set_client_CA_list(), but Squid was not aware of that. Squid now
supplies a clone of clientCA.

Alex.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SQUID-87-port-clientca-double-free-t4.patch
Type: text/x-diff
Size: 3604 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150611/524d7239/attachment.patch>

From eraya at a21an.org  Fri Jun 12 13:54:03 2015
From: eraya at a21an.org (Eray Aslan)
Date: Fri, 12 Jun 2015 13:54:03 +0000
Subject: [squid-dev] libltdl in squid
Message-ID: <20150612135403.GA32339@angelfall>

Is there any particular reason we are shipping and building libltdl in
squid tarballs?  Problem I am facing is when I run autoreconf,
libtoolize blindly copies over am__api_version -which has the automake
version libtool was compiled with and not the version currently running
on the system- to aclocal.m4 which later errors out.

While libtoolize behaviour is certainly not ideal, why is squid not
using the system libltdl?  That seems to be the correct course of
action.  Is there a downside to getting rid of libltdl that I am
missing?

Gory details at:
https://bugs.gentoo.org/show_bug.cgi?id=536420

Thank you.
-- 
Eray

From squid3 at treenet.co.nz  Fri Jun 12 20:38:57 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Jun 2015 08:38:57 +1200
Subject: [squid-dev] libltdl in squid
In-Reply-To: <20150612135403.GA32339@angelfall>
References: <20150612135403.GA32339@angelfall>
Message-ID: <557B4361.5040000@treenet.co.nz>

On 13/06/2015 1:54 a.m., Eray Aslan wrote:
> Is there any particular reason we are shipping and building libltdl in
> squid tarballs?  Problem I am facing is when I run autoreconf,
> libtoolize blindly copies over am__api_version -which has the automake
> version libtool was compiled with and not the version currently running
> on the system- to aclocal.m4 which later errors out.
> 
> While libtoolize behaviour is certainly not ideal, why is squid not
> using the system libltdl?  That seems to be the correct course of
> action.  Is there a downside to getting rid of libltdl that I am
> missing?
> 
> Gory details at:
> https://bugs.gentoo.org/show_bug.cgi?id=536420
> 
> Thank you.
> 

Hi Eray,
 Squid should be using the system libltdl.

IIUIC, the ./libltdl/ bits are in two parts:
- the headers and bits for building an lib*.a to link with. Which are
used as if libltdl was installed in the system includes/ directory.
Run-time it dynamicaly loads the system libltdl.

- also a sub-dir with bits to build a static libltdl. This requires the
--use-included-ltdl option to build and overrides the above run-time load.


I am wondering how you can have libtoolize run and not have the contents
of the libltdl directory entirely replaced to be compatible with the
current OS version. Because, thats exactly what we do to generate it in
the first place.
 Is there possibly multiple libltdl installed on the build system and
libtoolize embedding info from the non-dominant system libltdl version
into Squid?
 There was a hint in the bug that automake was embedding code files
indicating bogus version details.


NP: It is bundled for the old OS or ones that dont supply any
libtool/ltdl compatible with the autoconf version we generate Squid with.


Amos

From squid3 at treenet.co.nz  Sat Jun 13 07:16:05 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Jun 2015 19:16:05 +1200
Subject: [squid-dev] [squid-bugs] Squid 3.4.10 with moments CPU 100%
In-Reply-To: <557B9AD2.80008@outcenter.com.br>
References: <557B9AD2.80008@outcenter.com.br>
Message-ID: <557BD8B5.7070108@treenet.co.nz>

On 13/06/2015 2:52 p.m., Ulisses_Trolez wrote:
> Hi , Staff !
> 
> I am using squid 3.4.10_2 in a pfsense 2.2.2 and have in some crashes
> moments in acess.log the squid logs because of the squid process be 100%
> At that moment freezes customer navigation, returning in minutes later.
> 
> Hardware that is running the squid is a serveru L100 for about just over
> 100 users authenticated proxy.
> 
> Intel (R) Atom (TM) CPU @ 1.80GHz D525
> 4 CPUs: 1 package (s) x 2 core (s) x 2 HTT threads
> Memory RAM 4G
> HD SATA3 500G
> 
> Something we should check?


If you are using NTLM or Negotiate auth it could be
<http://bugs.squid-cache.org/show_bug.cgi?id=3997> which was fixed in 3.4.12

If you are using delay pools it could be
<http://bugs.squid-cache.org/show_bug.cgi?id=2907> which was fixed in 3.5.3.

Otherwise you will need to get an strace of the running proxy when its
cycling like this to see what exactly its trying to do.

Amos



From james.hunter at jartechnologies.com  Thu Jun 18 11:42:51 2015
From: james.hunter at jartechnologies.com (James Hunter)
Date: Thu, 18 Jun 2015 12:42:51 +0100
Subject: [squid-dev] Injecting custom JavaScript
Message-ID: <5582AEBB.90909@jartechnologies.com>

Hi,

I've been looking to inject special JavaScript code into every HTML page 
my squid proxy receives via HTTPS connections, this is for an 
application where the users will be fully aware of the injection.

I've correctly configured Squid to do the SSL Bump, having verified in 
WireShark that the two sides are communicating via separate connections.

Can someone point out where the plain HTTP / TCP request flows through 
squid, after it's deciphered by one side - but before it's encrypted for 
the other? I want to scan the buffer's to find any <BODY> tags and 
ensure that the script is inserted.

Many thanks,

James

From gkinkie at gmail.com  Thu Jun 18 12:04:48 2015
From: gkinkie at gmail.com (Kinkie)
Date: Thu, 18 Jun 2015 14:04:48 +0200
Subject: [squid-dev] Injecting custom JavaScript
In-Reply-To: <5582AEBB.90909@jartechnologies.com>
References: <5582AEBB.90909@jartechnologies.com>
Message-ID: <CA+Y8hcNTrKZiqX_kNouuRy=55=BctcAK4=AkHVfCANRr1zPnMg@mail.gmail.com>

Hi,
  in order to do what you aim for you can either use an (externa) ICAP
service or an eCap adaptor (http://www.e-cap.org/).

On Thu, Jun 18, 2015 at 1:42 PM, James Hunter
<james.hunter at jartechnologies.com> wrote:
> Hi,
>
> I've been looking to inject special JavaScript code into every HTML page my
> squid proxy receives via HTTPS connections, this is for an application where
> the users will be fully aware of the injection.
>
> I've correctly configured Squid to do the SSL Bump, having verified in
> WireShark that the two sides are communicating via separate connections.
>
> Can someone point out where the plain HTTP / TCP request flows through
> squid, after it's deciphered by one side - but before it's encrypted for the
> other? I want to scan the buffer's to find any <BODY> tags and ensure that
> the script is inserted.
>
> Many thanks,
>
> James
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev



-- 
    Francesco

From squid3 at treenet.co.nz  Thu Jun 18 12:11:19 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Jun 2015 00:11:19 +1200
Subject: [squid-dev] Injecting custom JavaScript
In-Reply-To: <5582AEBB.90909@jartechnologies.com>
References: <5582AEBB.90909@jartechnologies.com>
Message-ID: <5582B567.1080207@treenet.co.nz>

On 18/06/2015 11:42 p.m., James Hunter wrote:
> Hi,
> 
> I've been looking to inject special JavaScript code into every HTML page
> my squid proxy receives via HTTPS connections, this is for an
> application where the users will be fully aware of the injection.

Lets start with how this is a truly terrible idea.

The content you are seeking to change is:
a) somebody elses property,
b) copyrighted as such,
c) potentially subject to external checksum and digital protections,
d) HTTP relies on it being unchanged from origin server copies for
correct revalidation operations.

> 
> I've correctly configured Squid to do the SSL Bump, having verified in
> WireShark that the two sides are communicating via separate connections.

That means little these days. Splice works via two connections and Squid
does not participate in the TLS layer inside those connections.

You have to also confirm that Squid has access to the decrypted data,
that shows up in wireshark as different sets of crypto operating on each
connection.

> 
> Can someone point out where the plain HTTP / TCP request flows through
> squid, after it's deciphered by one side - but before it's encrypted for
> the other? I want to scan the buffer's to find any <BODY> tags and
> ensure that the script is inserted.

The "page" is not plaintext HTTP. Its binary payload. Squid is designed
explicitly NOT to touch them.

It is also relayed as given, spread over many smaller buffer segments
and very likely compressed. There is 0 guarantee that you will be able
to see a whole sequence of "<BODY>" characters as a string even if one
existed bare in the payload.

If you want to do payload adaptation use an ICAP service or eCAP module.
The above guarantee is still not provided, but the *CAP APIs provide
easier ways to access the transaction data.
NP: Dont forget to skip altering any and all messages with
"Cache-Control:no-transform" header - that is critical.

Amos


From squid3 at treenet.co.nz  Thu Jun 18 12:15:33 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Jun 2015 00:15:33 +1200
Subject: [squid-dev] [squid-bugs] Squid 3.4.10 with moments CPU 100%
In-Reply-To: <557C180A.9060008@outcenter.com.br>
References: <557B9AD2.80008@outcenter.com.br> <557BD8B5.7070108@treenet.co.nz>
 <557C180A.9060008@outcenter.com.br>
Message-ID: <5582B665.2020500@treenet.co.nz>

On 13/06/2015 11:46 p.m., Ulisses_Trolez wrote:
> I'm using the users own the same squid not use NTLM.
> Then it would be a bug you? I'll have to wait for the pfsense carry the
> version 3.5 or can downgrade to an earlier version?

If it is bug 2907 then it affects all unpatched Squid versions. It has
just not been visible previously because of the low usage of HTTPS. Now
that HTTPS traffic is becoming popular on most networks it is having
larger effects and much more noticed.

Please pester pfsense about when they will have a fixed release
available :-) all their users could benefit.

Amos


From james.hunter at jartechnologies.com  Thu Jun 18 12:41:18 2015
From: james.hunter at jartechnologies.com (James Hunter)
Date: Thu, 18 Jun 2015 13:41:18 +0100
Subject: [squid-dev] Injecting custom JavaScript
In-Reply-To: <5582B567.1080207@treenet.co.nz>
References: <5582AEBB.90909@jartechnologies.com>
 <5582B567.1080207@treenet.co.nz>
Message-ID: <5582BC6E.5010800@jartechnologies.com>

Hi Amos,

> On 18/06/2015 11:42 p.m., James Hunter wrote:
>> Hi,
>>
>> I've been looking to inject special JavaScript code into every HTML page
>> my squid proxy receives via HTTPS connections, this is for an
>> application where the users will be fully aware of the injection.
> Lets start with how this is a truly terrible idea.
>
> The content you are seeking to change is:
> a) somebody elses property,
> b) copyrighted as such,
> c) potentially subject to external checksum and digital protections,
> d) HTTP relies on it being unchanged from origin server copies for
> correct revalidation operations.
This is for stress testing tool that requires the knowledge of what the 
user is doing to record (at a browser event level) the keyboard and 
mouse activities, this occurs on just a single authorized domain that 
they must have signed consent for. If they use the proxy for a domain 
that that is not authorized it redirects them to our web app to seek 
authorization. There is no way to do this without injecting our own 
Javascript library to push those events to a recording application.

Hopefully that's not a truly terrible one :) just a necessity for us

>
>> I've correctly configured Squid to do the SSL Bump, having verified in
>> WireShark that the two sides are communicating via separate connections.
> That means little these days. Splice works via two connections and Squid
> does not participate in the TLS layer inside those connections.
>
> You have to also confirm that Squid has access to the decrypted data,
> that shows up in wireshark as different sets of crypto operating on each
> connection.
I will verify this, I was wondering where (from a C++ level) I can gain 
access to the segments of each request - I couldn't see in the source 
where the "data segment" is available, could anyone point me to the file 
where the data is available in it's raw format (as a void* or similar)

>
>> Can someone point out where the plain HTTP / TCP request flows through
>> squid, after it's deciphered by one side - but before it's encrypted for
>> the other? I want to scan the buffer's to find any <BODY> tags and
>> ensure that the script is inserted.
> The "page" is not plaintext HTTP. Its binary payload. Squid is designed
> explicitly NOT to touch them.
>
> It is also relayed as given, spread over many smaller buffer segments
> and very likely compressed. There is 0 guarantee that you will be able
> to see a whole sequence of "<BODY>" characters as a string even if one
> existed bare in the payload.
>
> If you want to do payload adaptation use an ICAP service or eCAP module.
> The above guarantee is still not provided, but the *CAP APIs provide
> easier ways to access the transaction data.
> NP: Dont forget to skip altering any and all messages with
> "Cache-Control:no-transform" header - that is critical.
Understood, we will have to create some sort of bitstream analyzer that 
can handle separate segments of binary data (for the same URL).

I will investigate the ICAP and eCAP facilities if I can't get direct 
access to the data from within the code.

James

From squid3 at treenet.co.nz  Fri Jun 19 01:24:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Jun 2015 13:24:28 +1200
Subject: [squid-dev] [PATCH] Parser-NG: Http1::Tokenizer
In-Reply-To: <5576FD3E.2030001@treenet.co.nz>
References: <5576FD3E.2030001@treenet.co.nz>
Message-ID: <55836F4C.7060507@treenet.co.nz>

On 10/06/2015 2:50 a.m., Amos Jeffries wrote:
> This adds a class Http1::Tokenizer, which inherits from
> ::Parser::Tokenizer and presents additional HTTP-specific token parsing
> methods.
> 
> At present it extends for the quoted-string, 1#( token/ quoted-string ),
> and qdtext constructs from RFC 7230 and RFC 1945.
> 
> It can also cope with charset and quoted-pair escaping differences in
> qdtext between RFC 1945 and RFC 7230. The un-escaped form of token is
> returned.

Absent any objections I have applied this to trunk as rev.14113

Amos


From squid3 at treenet.co.nz  Fri Jun 19 01:25:16 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Jun 2015 13:25:16 +1200
Subject: [squid-dev] [PATCH] Segfault when freeing https_port clientca
 on reconfigure or exit
In-Reply-To: <557A6692.3030809@measurement-factory.com>
References: <557A6692.3030809@measurement-factory.com>
Message-ID: <55836F7C.9070203@treenet.co.nz>

On 12/06/2015 4:56 p.m., Alex Rousskov wrote:
> Fixed segmentation fault when freeing https_port clientca on reconfigure
> or exit.
> 
> AnyP::PortCfg::clientCA list was double-freed, because the SSL context
> takes ownership of the STACK_OF(X509_NAME) supplied via
> SSL_CTX_set_client_CA_list(), but Squid was not aware of that. Squid now
> supplies a clone of clientCA.

+1. Please apply.

Amos


From squid3 at treenet.co.nz  Fri Jun 19 01:26:25 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Jun 2015 13:26:25 +1200
Subject: [squid-dev] [PATCH] Add chained certificates and signing
 certificate to bumpAndSpliced connections
In-Reply-To: <CAGUJm7bnpCyM6NPxnrkMnCydsF2HxNgjDdnV4bJTBsjBPjhDCA@mail.gmail.com>
References: <CAGUJm7bBkot1Ae0njnDmESj-XGJ07pZv6iYa+uvh0kzJ8Mf7=Q@mail.gmail.com>
 <556044DD.2080601@users.sourceforge.net>
 <CAGUJm7bnpCyM6NPxnrkMnCydsF2HxNgjDdnV4bJTBsjBPjhDCA@mail.gmail.com>
Message-ID: <55836FC1.8080100@treenet.co.nz>

On 7/06/2015 2:41 a.m., Nathan Hoad wrote:
> Hello,
> 
> Attached is a patch making the changes recommended by Christos. I've
> done as described, creating a Ssl::configureUnconfiguredSslContext
> function, rather than making the changes to Ssl::configureSSL.

Christos, can you please review and apply if it is acceptible to you?

Cheers
Amos


From squid3 at treenet.co.nz  Fri Jun 19 03:39:59 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Jun 2015 15:39:59 +1200
Subject: [squid-dev] [PATCH] TLS: Disable client-initiated renegotiation
In-Reply-To: <55709E3B.7050609@ufscar.br>
References: <55709E3B.7050609@ufscar.br>
Message-ID: <55838F0F.2040003@treenet.co.nz>

Absent objections I have applied this to trunk as rev.14114

Amos

From squid3 at treenet.co.nz  Fri Jun 19 05:01:08 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Jun 2015 17:01:08 +1200
Subject: [squid-dev] [PATCH] TLS: Add support for EECDH
In-Reply-To: <55709E3F.3070502@ufscar.br>
References: <55709E3F.3070502@ufscar.br>
Message-ID: <5583A214.6040104@treenet.co.nz>

On 5/06/2015 6:51 a.m., Paulo Matias wrote:
> adds support for Ephemeral Elliptic Curve Diffie-Hellman (EECDH)
> key exchange, which allows for forward secrecy with better performance than
> traditional ephemeral DH.

Applied to trunk (Squid-4) as rev.14115.

Amos

From chtsanti at users.sourceforge.net  Fri Jun 19 08:26:52 2015
From: chtsanti at users.sourceforge.net (Tsantilas Christos)
Date: Fri, 19 Jun 2015 11:26:52 +0300
Subject: [squid-dev] [PATCH] Add chained certificates and signing
 certificate to bumpAndSpliced connections
In-Reply-To: <55836FC1.8080100@treenet.co.nz>
References: <CAGUJm7bBkot1Ae0njnDmESj-XGJ07pZv6iYa+uvh0kzJ8Mf7=Q@mail.gmail.com>
 <556044DD.2080601@users.sourceforge.net>
 <CAGUJm7bnpCyM6NPxnrkMnCydsF2HxNgjDdnV4bJTBsjBPjhDCA@mail.gmail.com>
 <55836FC1.8080100@treenet.co.nz>
Message-ID: <5583D24C.5080606@users.sourceforge.net>

The patch should applied to trunk.

On 06/19/2015 04:26 AM, Amos Jeffries wrote:
> On 7/06/2015 2:41 a.m., Nathan Hoad wrote:
>> Hello,
>>
>> Attached is a patch making the changes recommended by Christos. I've
>> done as described, creating a Ssl::configureUnconfiguredSslContext
>> function, rather than making the changes to Ssl::configureSSL.
>
> Christos, can you please review and apply if it is acceptible to you?
>
> Cheers
> Amos
>
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev
>


From chtsanti at users.sourceforge.net  Fri Jun 19 08:35:16 2015
From: chtsanti at users.sourceforge.net (Tsantilas Christos)
Date: Fri, 19 Jun 2015 11:35:16 +0300
Subject: [squid-dev] [PATCH] TLS: Disable client-initiated renegotiation
In-Reply-To: <55838F0F.2040003@treenet.co.nz>
References: <55709E3B.7050609@ufscar.br> <55838F0F.2040003@treenet.co.nz>
Message-ID: <5583D444.6010709@users.sourceforge.net>

This patch, probably is ok as workarround, but my sense is that it is 
not the best method to fix it.  We should spent some hours of work to 
check openSSL versions has the problem, and apply a better solution.



On 06/19/2015 06:39 AM, Amos Jeffries wrote:
> Absent objections I have applied this to trunk as rev.14114
>
> Amos

From rousskov at measurement-factory.com  Fri Jun 19 16:39:13 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 19 Jun 2015 10:39:13 -0600
Subject: [squid-dev] Injecting custom JavaScript
In-Reply-To: <5582B567.1080207@treenet.co.nz>
References: <5582AEBB.90909@jartechnologies.com>
 <5582B567.1080207@treenet.co.nz>
Message-ID: <558445B1.8000402@measurement-factory.com>

On 06/18/2015 06:11 AM, Amos Jeffries wrote:
> On 18/06/2015 11:42 p.m., James Hunter wrote:
>> I've been looking to inject special JavaScript code into every HTML page
>> my squid proxy receives via HTTPS connections, this is for an
>> application where the users will be fully aware of the injection.

> Lets start with how this is a truly terrible idea.


Hi Amos,

    You may also point folks at
https://answers.launchpad.net/ecap/+faq/1793 which covers content
injection problems pretty well in my biased opinion. There is probably a
Squid wiki page that covers SslBump complications.


HTH,

Alex.


From rousskov at measurement-factory.com  Fri Jun 19 16:47:24 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 19 Jun 2015 10:47:24 -0600
Subject: [squid-dev] Injecting custom JavaScript
In-Reply-To: <5582BC6E.5010800@jartechnologies.com>
References: <5582AEBB.90909@jartechnologies.com>
 <5582B567.1080207@treenet.co.nz> <5582BC6E.5010800@jartechnologies.com>
Message-ID: <5584479C.8070101@measurement-factory.com>

On 06/18/2015 06:41 AM, James Hunter wrote:

> I will investigate the ICAP and eCAP facilities if I can't get direct
> access to the data from within the code.

If you are creating a temporary hack, look for places where Squid passes
data to the adaptation layer, such as calls to adaptVirginReplyBody().

If you are creating more than a temporary hack, you should investigate
eCAP even if you can get direct access to the data from within the code.


HTH,

Alex.


From rousskov at measurement-factory.com  Fri Jun 19 16:54:39 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 19 Jun 2015 10:54:39 -0600
Subject: [squid-dev] [PATCH] Do not blindly forward cache peer CONNECT
	responses
Message-ID: <5584494F.1010405@measurement-factory.com>

Hello,

    The attached trunk patch fixes a rare but nasty problem by removing
a very old hack which shielded Squid from parsing most CONNECT responses.

Currently, Squid blindly forwards cache peer CONNECT responses to
clients when possible. This may break things if the peer responds with
something like HTTP 403 (Forbidden) and keeps the connection with Squid
open:

  -  The client application issues a CONNECT request.
  -  Squid forwards this request to a cache peer.
  -  Cache peer correctly responds back with a "403 Forbidden".
  -  Squid does not parse cache peer response and
     just forwards it as if it was a Squid response to the client.
  -  The TCP connections are not closed.

At this stage, Squid is unaware that the CONNECT request has failed. All
subsequent requests on the user agent TCP connection are treated as
tunnelled traffic. Squid is forwarding these requests to the peer on the
TCP connection previously used for the 403-ed CONNECT request, without
proper processing. The additional headers which should have been applied
by Squid to these requests are not applied, and the requests are being
forwarded to the cache peer even though the Squid configuration may
state that these requests must go directly to the origin server.

This patch fixes Squid to parse cache peer responses, and if an error
response found, respond with "502 Bad Gateway" to the client and close
the connections.


HTH,

Alex.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SQUID-53-blind-connect-response-t8.patch
Type: text/x-diff
Size: 29781 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150619/27f08c05/attachment-0001.patch>

From rousskov at measurement-factory.com  Fri Jun 19 17:04:21 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 19 Jun 2015 11:04:21 -0600
Subject: [squid-dev] [PATCH] Segfault when freeing https_port clientca
 on reconfigure or exit
In-Reply-To: <55836F7C.9070203@treenet.co.nz>
References: <557A6692.3030809@measurement-factory.com>
 <55836F7C.9070203@treenet.co.nz>
Message-ID: <55844B95.6030106@measurement-factory.com>

On 06/18/2015 07:25 PM, Amos Jeffries wrote:
> On 12/06/2015 4:56 p.m., Alex Rousskov wrote:
>> Fixed segmentation fault when freeing https_port clientca on reconfigure
>> or exit.
>>
>> AnyP::PortCfg::clientCA list was double-freed, because the SSL context
>> takes ownership of the STACK_OF(X509_NAME) supplied via
>> SSL_CTX_set_client_CA_list(), but Squid was not aware of that. Squid now
>> supplies a clone of clientCA.
> 
> +1. Please apply.


Committed to trunk (r14118).


Thank you,

Alex.


From squid3 at treenet.co.nz  Sat Jun 20 00:46:15 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Jun 2015 12:46:15 +1200
Subject: [squid-dev] [PATCH] Do not blindly forward cache peer CONNECT
 responses
In-Reply-To: <5584494F.1010405@measurement-factory.com>
References: <5584494F.1010405@measurement-factory.com>
Message-ID: <5584B7D7.1020802@treenet.co.nz>

On 20/06/2015 4:54 a.m., Alex Rousskov wrote:
> Hello,
> 
>     The attached trunk patch fixes a rare but nasty problem by removing
> a very old hack which shielded Squid from parsing most CONNECT responses.
> 
> Currently, Squid blindly forwards cache peer CONNECT responses to
> clients when possible. This may break things if the peer responds with
> something like HTTP 403 (Forbidden) and keeps the connection with Squid
> open:
> 
>   -  The client application issues a CONNECT request.
>   -  Squid forwards this request to a cache peer.
>   -  Cache peer correctly responds back with a "403 Forbidden".
>   -  Squid does not parse cache peer response and
>      just forwards it as if it was a Squid response to the client.
>   -  The TCP connections are not closed.
> 
> At this stage, Squid is unaware that the CONNECT request has failed. All
> subsequent requests on the user agent TCP connection are treated as
> tunnelled traffic. Squid is forwarding these requests to the peer on the
> TCP connection previously used for the 403-ed CONNECT request, without
> proper processing. The additional headers which should have been applied
> by Squid to these requests are not applied, and the requests are being
> forwarded to the cache peer even though the Squid configuration may
> state that these requests must go directly to the origin server.
> 
> This patch fixes Squid to parse cache peer responses, and if an error
> response found, respond with "502 Bad Gateway" to the client and close
> the connections.
> 

Thank you. I've had this on my todo list for a long time.

One problem though...

The parse operations documented as being copied from http.cc
processReplyHeader() do not match what trunk currently does for HTTP
replies in that function.

Specifically HttpReply::parse is deprecated and not to be used in new
code. We now have an Http1::ReplyParser instead that processes the
status-line and grabs the mime headers into a SBuf blob for writing out
if necessary. That is all tunnel.cc needs right now for this patches
parse step.

Amos

From chtsanti at users.sourceforge.net  Tue Jun 23 14:54:42 2015
From: chtsanti at users.sourceforge.net (Tsantilas Christos)
Date: Tue, 23 Jun 2015 17:54:42 +0300
Subject: [squid-dev] [PATCH] Splice to origin cache_peer
Message-ID: <55897332.4060101@users.sourceforge.net>

Currently, Squid cannot redirect intercepted connections that are 
subject to SslBump rules to _originserver_ cache_peer. For example, 
consider Squid that enforces "safe search" by redirecting clients to 
forcesafesearch.example.com. Consider a TLS client that tries to connect 
to www.example.com. Squid needs to send that client to 
forcesafesearch.example.com (without changing the host header and SNI 
information; those would still point to www.example.com for safe search 
to work as intended!).

The admin may configure Squid to send intercepted clients to an 
originserver cache_peer with the forcesafesearch.example.com address. 
Such a configuration does not currently work together with ssl_bump 
peek/splice rules.

This patch:

* Fixes src/neighbors.cc bug which prevented CONNECT requests from going 
to originserver cache peers. This bug affects both true CONNECT requests 
and intercepted SSL/TLS connections (with fake CONNECT requests). Squid 
use the CachePeer::in_addr.port which is not meant to be used for the 
HTTP port, apparently. HTTP checks should use CachePeer::http_port instead.

* Changes Squid to not initiate SSL/TLS connection to cache_peer for 
true CONNECT requests.

* Allows forwarding being-peeked (or stared) at connections to 
originserver cache_peers.


This is a Measurement Factory project.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: splice-to-cache-peer-trunk-t6.patch
Type: text/x-patch
Size: 7530 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150623/bdc670f3/attachment.bin>

From rousskov at measurement-factory.com  Tue Jun 23 15:26:54 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 23 Jun 2015 09:26:54 -0600
Subject: [squid-dev] [PATCH] Do not blindly forward cache peer CONNECT
 responses
In-Reply-To: <5584B7D7.1020802@treenet.co.nz>
References: <5584494F.1010405@measurement-factory.com>
 <5584B7D7.1020802@treenet.co.nz>
Message-ID: <55897ABE.2090409@measurement-factory.com>

On 06/19/2015 06:46 PM, Amos Jeffries wrote:
> On 20/06/2015 4:54 a.m., Alex Rousskov wrote:
>> Hello,
>>
>>     The attached trunk patch fixes a rare but nasty problem by removing
>> a very old hack which shielded Squid from parsing most CONNECT responses.
>>
>> Currently, Squid blindly forwards cache peer CONNECT responses to
>> clients when possible. This may break things if the peer responds with
>> something like HTTP 403 (Forbidden) and keeps the connection with Squid
>> open:
>>
>>   -  The client application issues a CONNECT request.
>>   -  Squid forwards this request to a cache peer.
>>   -  Cache peer correctly responds back with a "403 Forbidden".
>>   -  Squid does not parse cache peer response and
>>      just forwards it as if it was a Squid response to the client.
>>   -  The TCP connections are not closed.
>>
>> At this stage, Squid is unaware that the CONNECT request has failed. All
>> subsequent requests on the user agent TCP connection are treated as
>> tunnelled traffic. Squid is forwarding these requests to the peer on the
>> TCP connection previously used for the 403-ed CONNECT request, without
>> proper processing. The additional headers which should have been applied
>> by Squid to these requests are not applied, and the requests are being
>> forwarded to the cache peer even though the Squid configuration may
>> state that these requests must go directly to the origin server.
>>
>> This patch fixes Squid to parse cache peer responses, and if an error
>> response found, respond with "502 Bad Gateway" to the client and close
>> the connections.
>>
> 
> Thank you. I've had this on my todo list for a long time.
> 
> One problem though...
> 
> The parse operations documented as being copied from http.cc
> processReplyHeader() do not match what trunk currently does for HTTP
> replies in that function.


How is that problem related to the proposed fix?

The posted patch does not change or add new parsing code AFAICT. Whoever
deprecated HttpReply::parse() could update tunnel.cc but had apparently
chosen not to do it. The patch does not change that old tunnel.cc
parsing code. Does the patch add some new parsing code that I missed?


Thank you,

Alex.


From chtsanti at users.sourceforge.net  Tue Jun 23 15:30:24 2015
From: chtsanti at users.sourceforge.net (Tsantilas Christos)
Date: Tue, 23 Jun 2015 18:30:24 +0300
Subject: [squid-dev] [PATCH] Avoid SSL certificate db corruption with empty
 index.txt as a symptom.
Message-ID: <55897B90.3020708@users.sourceforge.net>


* Detect cases where the size file is corrupted or has a clearly wrong 
value. Automatically rebuild the database in such cases.

* Teach ssl_crtd to keep running if it is unable to store the generated 
certificate in the database. Return the generated certificate to Squid 
and log an error message in such cases.

Background:

There are cases where ssl_crtd may corrupt its certificate database. The 
known cases manifest themselves with an empty db index file.  When that 
happens, ssl_crtd helpers quit, SSL bumping does not work any more, and 
the certificate DB has to be deleted and re-initialized.

We do not know exactly what causes corruption in deployments, but one 
known trigger that is easy to reproduce in a lab is the block size 
change in the ssl_crtd configuration. That change has the following 
side-effects:

1. When ssl_crtd removes certificates, it computes their size using a 
different block size than the one used to store the certificates. This 
is may result in negative database sizes.

2. Signed/unsigned conversion results in a huge number near LONG_MAX, 
which is then written to the "size" file.

3. The ssl_crtd helper refuses to store new certificates because the 
database size (as described by the "size" file) exceeds the configured 
limit.

4. The ssl_crtd helper exits because it cannot store a new certificates 
to the database. No helper response is sent to Squid in this case.

Most likely, there are other corruption triggers -- the database 
management code is of an overall poor quality. This change resolves some 
of the underlying problems in hope to address at least some of the 
unknown triggers as well as the known one.

This is a Measurement Factory project.

From rousskov at measurement-factory.com  Wed Jun 24 05:55:58 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 23 Jun 2015 23:55:58 -0600
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
	Amazon
Message-ID: <558A466E.1060303@measurement-factory.com>

Hello,

    This temporary trunk fix adds support for request URIs containing
'|' characters. Such URIs are used by popular Amazon product (and
probably other) sites: /images/I/ID1._RC|ID2.js,ID3.js,ID4.js_.js

Without this fix, all requests for affected URIs timeout while Squid
waits for the end of request headers it has already received(*).


The proper long-term fix is to allow any character in URI as long as we
can reliably parse the request line (and, later, URI components). There
is no point in hurting users by rejecting requests while slowly
accumulating the list of benign characters used by web sites but
prohibited by some RFC.


HTH,

Alex.
P.S. (*) which is probably another parsing regression bug (not addressed
by this temporary patch or the long-term fix discussed above), but I
have not tested whether the very latest trunk still suffers from this
other bug.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: amazon-urls-t0.patch
Type: text/x-diff
Size: 2438 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150623/5ad419a0/attachment.patch>

From squid3 at treenet.co.nz  Wed Jun 24 11:26:18 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 24 Jun 2015 23:26:18 +1200
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <558A466E.1060303@measurement-factory.com>
References: <558A466E.1060303@measurement-factory.com>
Message-ID: <558A93DA.9080506@treenet.co.nz>

On 24/06/2015 5:55 p.m., Alex Rousskov wrote:
> Hello,
> 
>     This temporary trunk fix adds support for request URIs containing
> '|' characters. Such URIs are used by popular Amazon product (and
> probably other) sites: /images/I/ID1._RC|ID2.js,ID3.js,ID4.js_.js
> 
> Without this fix, all requests for affected URIs timeout while Squid
> waits for the end of request headers it has already received(*).

This is not right. Squid should be identifying the message as
non-HTTP/1.x (which it isn't due to the URI syntax violation) and
treating it as such.

There is no reason for HTTP/0.9 traffic to hang (thus the bug
agreement). Squid should read in the first line, find a reply for the
URI and close the connection once that reply is delivered. Note how
thare are no mime headers involved to be waited on. I agree there is a
bug there if its hanging.

NP: it means "broken" syntax does work - but gets a slow response with
no HTTP feature benefits. That slow vs fast is the designed incentive
for such softwares authors to fix things.

> 
> The proper long-term fix is to allow any character in URI as long as we
> can reliably parse the request line (and, later, URI components). There
> is no point in hurting users by rejecting requests while slowly
> accumulating the list of benign characters used by web sites but
> prohibited by some RFC.

The *proper* long term fix is to obey the standards in regard to message
syntax so applications stop using these invalid (when un-encoded)
characters and claiming HTTP/1.1 support.

Amos


From rousskov at measurement-factory.com  Wed Jun 24 20:12:10 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 24 Jun 2015 14:12:10 -0600
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <558A93DA.9080506@treenet.co.nz>
References: <558A466E.1060303@measurement-factory.com>
 <558A93DA.9080506@treenet.co.nz>
Message-ID: <558B0F1A.90301@measurement-factory.com>

On 06/24/2015 05:26 AM, Amos Jeffries wrote:

> On 24/06/2015 5:55 p.m., Alex Rousskov wrote:
>>     This temporary trunk fix adds support for request URIs containing
>> '|' characters. Such URIs are used by popular Amazon product (and
>> probably other) sites: /images/I/ID1._RC|ID2.js,ID3.js,ID4.js_.js
>>
>> Without this fix, all requests for affected URIs timeout while Squid
>> waits for the end of request headers it has already received(*).


> This is not right. Squid should be identifying the message as
> non-HTTP/1.x (which it isn't due to the URI syntax violation) and
> treating it as such.

I agree that Amazon violates URI syntax. On the other hand, the message
can be interpreted as HTTP/1.x for all practical purposes AFAICT. If you
want to implement a different fix, please do so. Meanwhile, folks
suffering from this serious regression can try the temporary fix I posted.


>> The proper long-term fix is to allow any character in URI as long as we
>> can reliably parse the request line (and, later, URI components). There
>> is no point in hurting users by rejecting requests while slowly
>> accumulating the list of benign characters used by web sites but
>> prohibited by some RFC.

> The *proper* long term fix is to obey the standards in regard to message
> syntax so applications stop using these invalid (when un-encoded)
> characters and claiming HTTP/1.1 support.

We had "standards vs reality" and "policing traffic" discussions several
times in the past, with no signs of convergence towards a single
approach, so I am not going to revisit that discussion now. We continue
to disagree [while Squid users continue to suffer].


Thank you,

Alex.


From gkinkie at gmail.com  Wed Jun 24 20:24:51 2015
From: gkinkie at gmail.com (Kinkie)
Date: Wed, 24 Jun 2015 22:24:51 +0200
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
	Amazon
In-Reply-To: <558B0F1A.90301@measurement-factory.com>
References: <558A466E.1060303@measurement-factory.com>
 <558A93DA.9080506@treenet.co.nz>
 <558B0F1A.90301@measurement-factory.com>
Message-ID: <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>

My 2c: I vote for reality; possibly with a shaming announce message; I
wouldn't even recommend logging the violation: there is nothing the
average admin can do about it. I would consider adding a shaming
comment in the release notes.

On Wed, Jun 24, 2015 at 10:12 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 06/24/2015 05:26 AM, Amos Jeffries wrote:
>
>> On 24/06/2015 5:55 p.m., Alex Rousskov wrote:
>>>     This temporary trunk fix adds support for request URIs containing
>>> '|' characters. Such URIs are used by popular Amazon product (and
>>> probably other) sites: /images/I/ID1._RC|ID2.js,ID3.js,ID4.js_.js
>>>
>>> Without this fix, all requests for affected URIs timeout while Squid
>>> waits for the end of request headers it has already received(*).
>
>
>> This is not right. Squid should be identifying the message as
>> non-HTTP/1.x (which it isn't due to the URI syntax violation) and
>> treating it as such.
>
> I agree that Amazon violates URI syntax. On the other hand, the message
> can be interpreted as HTTP/1.x for all practical purposes AFAICT. If you
> want to implement a different fix, please do so. Meanwhile, folks
> suffering from this serious regression can try the temporary fix I posted.
>
>
>>> The proper long-term fix is to allow any character in URI as long as we
>>> can reliably parse the request line (and, later, URI components). There
>>> is no point in hurting users by rejecting requests while slowly
>>> accumulating the list of benign characters used by web sites but
>>> prohibited by some RFC.
>
>> The *proper* long term fix is to obey the standards in regard to message
>> syntax so applications stop using these invalid (when un-encoded)
>> characters and claiming HTTP/1.1 support.
>
> We had "standards vs reality" and "policing traffic" discussions several
> times in the past, with no signs of convergence towards a single
> approach, so I am not going to revisit that discussion now. We continue
> to disagree [while Squid users continue to suffer].
>
>
> Thank you,
>
> Alex.
>
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev



-- 
    Francesco

From marcus.kool at urlfilterdb.com  Wed Jun 24 21:38:47 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 24 Jun 2015 18:38:47 -0300
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>
References: <558A466E.1060303@measurement-factory.com>
 <558A93DA.9080506@treenet.co.nz> <558B0F1A.90301@measurement-factory.com>
 <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>
Message-ID: <558B2367.5010806@urlfilterdb.com>



On 06/24/2015 05:24 PM, Kinkie wrote:
> My 2c: I vote for reality; possibly with a shaming announce message; I
> wouldn't even recommend logging the violation: there is nothing the
> average admin can do about it. I would consider adding a shaming
> comment in the release notes.

more cents:

correct.

A standard can be considered a strong guideline but if important sites
violate the standard (i.e. users/admins complain) then Squid
should be able to cope with it or it risks getting abandoned because
Squid cannot cope with traffic of sites that otherwise work without Squid.

For an admin it is irrelevant if the problem is caused by Squid or by
a website.  And the admin who dares to say to its users "only visit
sites that comply with the standards" probably gets fired.


> On Wed, Jun 24, 2015 at 10:12 PM, Alex Rousskov
> <rousskov at measurement-factory.com> wrote:
>> On 06/24/2015 05:26 AM, Amos Jeffries wrote:
>>
>>> On 24/06/2015 5:55 p.m., Alex Rousskov wrote:
>>>>      This temporary trunk fix adds support for request URIs containing
>>>> '|' characters. Such URIs are used by popular Amazon product (and
>>>> probably other) sites: /images/I/ID1._RC|ID2.js,ID3.js,ID4.js_.js
>>>>
>>>> Without this fix, all requests for affected URIs timeout while Squid
>>>> waits for the end of request headers it has already received(*).
>>
>>
>>> This is not right. Squid should be identifying the message as
>>> non-HTTP/1.x (which it isn't due to the URI syntax violation) and
>>> treating it as such.
>>
>> I agree that Amazon violates URI syntax. On the other hand, the message
>> can be interpreted as HTTP/1.x for all practical purposes AFAICT. If you
>> want to implement a different fix, please do so. Meanwhile, folks
>> suffering from this serious regression can try the temporary fix I posted.
>>
>>
>>>> The proper long-term fix is to allow any character in URI as long as we
>>>> can reliably parse the request line (and, later, URI components). There
>>>> is no point in hurting users by rejecting requests while slowly
>>>> accumulating the list of benign characters used by web sites but
>>>> prohibited by some RFC.
>>
>>> The *proper* long term fix is to obey the standards in regard to message
>>> syntax so applications stop using these invalid (when un-encoded)
>>> characters and claiming HTTP/1.1 support.
>>
>> We had "standards vs reality" and "policing traffic" discussions several
>> times in the past, with no signs of convergence towards a single
>> approach, so I am not going to revisit that discussion now. We continue
>> to disagree [while Squid users continue to suffer].
>>
>>
>> Thank you,
>>
>> Alex.
>>
>> _______________________________________________
>> squid-dev mailing list
>> squid-dev at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-dev
>
>
>

From noc at squid-cache.org  Wed Jun 24 22:29:54 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Wed, 24 Jun 2015 22:29:54 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Build_failed_in_Jenkins=3A_trunk-matrix_?=
 =?utf-8?q?=C2=BB_gcc=2Cd-centos-7_=23222?=
Message-ID: <926718221.2.1435184994649.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/222/>

------------------------------------------
[...truncated 47791 lines...]
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I../.. -I../../include -I../../lib -I../../src -I../include -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -MT util.lo -MD -MP -MF .deps/util.Tpo -c ../../lib/util.c  -fPIC -DPIC -o .libs/util.o
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I../.. -I../../include -I../../lib -I../../src -I../include -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -MT stub_memaccount.lo -MD -MP -MF .deps/stub_memaccount.Tpo -c ../../lib/stub_memaccount.c  -fPIC -DPIC -o stub_memaccount.o >/dev/null 2>&1
depbase=`echo xusleep.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H   -I../.. -I../../include -I../../lib -I../../src -I../include    -I/usr/include/libxml2  -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT  -MT xusleep.lo -MD -MP -MF $depbase.Tpo -c -o xusleep.lo ../../lib/xusleep.c &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I../.. -I../../include -I../../lib -I../../src -I../include -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -MT xusleep.lo -MD -MP -MF .deps/xusleep.Tpo -c ../../lib/xusleep.c  -fPIC -DPIC -o .libs/xusleep.o
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I../.. -I../../include -I../../lib -I../../src -I../include -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -MT util.lo -MD -MP -MF .deps/util.Tpo -c ../../lib/util.c  -fPIC -DPIC -o util.o >/dev/null 2>&1
/bin/sh ../libtool  --tag=CC   --mode=link ccache gcc -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT   -g -o libmiscencoding.la  base64.lo charset.lo html_quote.lo md5.lo rfc1738.lo rfc2617.lo uudecode.lo  
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I../.. -I../../include -I../../lib -I../../src -I../include -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -MT xusleep.lo -MD -MP -MF .deps/xusleep.Tpo -c ../../lib/xusleep.c  -fPIC -DPIC -o xusleep.o >/dev/null 2>&1
libtool: link: /usr/bin/ar cru .libs/libmiscencoding.a .libs/base64.o .libs/charset.o .libs/html_quote.o .libs/md5.o .libs/rfc1738.o .libs/rfc2617.o .libs/uudecode.o 
libtool: link: ranlib .libs/libmiscencoding.a
libtool: link: ( cd ".libs" && rm -f "libmiscencoding.la" && ln -s "../libmiscencoding.la" "libmiscencoding.la" )
libtool: compile:  ccache g++ -DHAVE_CONFIG_H -I../.. -I../../include -I../../lib -I../../src -I../include -I/usr/include/libxml2 -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT Splay.lo -MD -MP -MF .deps/Splay.Tpo -c ../../lib/Splay.cc  -fPIC -DPIC -o Splay.o >/dev/null 2>&1
/bin/sh ../libtool  --tag=CXX   --mode=link ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11  -g -o libmiscutil.la  getfullhostname.lo heap.lo iso3307.lo radix.lo rfc1123.lo Splay.lo stub_memaccount.lo util.lo xusleep.lo  
libtool: compile:  ccache g++ -DHAVE_CONFIG_H -I../.. -I../../include -I../../lib -I../../src -I../include -I/usr/include/libxml2 -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT hash.lo -MD -MP -MF .deps/hash.Tpo -c ../../lib/hash.cc  -fPIC -DPIC -o hash.o >/dev/null 2>&1
/bin/sh ../libtool  --tag=CXX   --mode=link ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11  -g -o libmisccontainers.la  hash.lo  
libtool: link: /usr/bin/ar cru .libs/libmiscutil.a .libs/getfullhostname.o .libs/heap.o .libs/iso3307.o .libs/radix.o .libs/rfc1123.o .libs/Splay.o .libs/stub_memaccount.o .libs/util.o .libs/xusleep.o 
libtool: link: ranlib .libs/libmiscutil.a
libtool: link: /usr/bin/ar cru .libs/libmisccontainers.a .libs/hash.o 
libtool: link: ranlib .libs/libmisccontainers.a
libtool: link: ( cd ".libs" && rm -f "libmiscutil.la" && ln -s "../libmiscutil.la" "libmiscutil.la" )
libtool: link: ( cd ".libs" && rm -f "libmisccontainers.la" && ln -s "../libmisccontainers.la" "libmisccontainers.la" )
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/lib'>
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/lib'>
Making all in libltdl
make[2]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/libltdl'>
make  all-am
make[3]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/libltdl'>
/bin/sh ./libtool  --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl  -DLT_CONFIG_H='<config.h>' -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl   -g -O2 -MT dlopen.lo -MD -MP -MF .deps/dlopen.Tpo -c -o dlopen.lo `test -f 'loaders/dlopen.c' || echo '../../libltdl/'`loaders/dlopen.c
/bin/sh ./libtool  --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl  -DLTDLOPEN=libltdlc -DLT_CONFIG_H='<config.h>' -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl   -g -O2 -MT libltdlc_la-preopen.lo -MD -MP -MF .deps/libltdlc_la-preopen.Tpo -c -o libltdlc_la-preopen.lo `test -f 'loaders/preopen.c' || echo '../../libltdl/'`loaders/preopen.c
/bin/sh ./libtool  --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl  -DLTDLOPEN=libltdlc -DLT_CONFIG_H='<config.h>' -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl   -g -O2 -MT libltdlc_la-lt__alloc.lo -MD -MP -MF .deps/libltdlc_la-lt__alloc.Tpo -c -o libltdlc_la-lt__alloc.lo `test -f 'lt__alloc.c' || echo '../../libltdl/'`lt__alloc.c
/bin/sh ./libtool  --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl  -DLTDLOPEN=libltdlc -DLT_CONFIG_H='<config.h>' -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl   -g -O2 -MT libltdlc_la-lt_dlloader.lo -MD -MP -MF .deps/libltdlc_la-lt_dlloader.Tpo -c -o libltdlc_la-lt_dlloader.lo `test -f 'lt_dlloader.c' || echo '../../libltdl/'`lt_dlloader.c
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT dlopen.lo -MD -MP -MF .deps/dlopen.Tpo -c ../../libltdl/loaders/dlopen.c  -fPIC -DPIC -o .libs/dlopen.o
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-lt__alloc.lo -MD -MP -MF .deps/libltdlc_la-lt__alloc.Tpo -c ../../libltdl/lt__alloc.c  -fPIC -DPIC -o .libs/libltdlc_la-lt__alloc.o
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-preopen.lo -MD -MP -MF .deps/libltdlc_la-preopen.Tpo -c ../../libltdl/loaders/preopen.c  -fPIC -DPIC -o .libs/libltdlc_la-preopen.o
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-lt_dlloader.lo -MD -MP -MF .deps/libltdlc_la-lt_dlloader.Tpo -c ../../libltdl/lt_dlloader.c  -fPIC -DPIC -o .libs/libltdlc_la-lt_dlloader.o
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT dlopen.lo -MD -MP -MF .deps/dlopen.Tpo -c ../../libltdl/loaders/dlopen.c  -fPIC -DPIC -o dlopen.o >/dev/null 2>&1
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-preopen.lo -MD -MP -MF .deps/libltdlc_la-preopen.Tpo -c ../../libltdl/loaders/preopen.c  -fPIC -DPIC -o libltdlc_la-preopen.o >/dev/null 2>&1
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-lt__alloc.lo -MD -MP -MF .deps/libltdlc_la-lt__alloc.Tpo -c ../../libltdl/lt__alloc.c  -fPIC -DPIC -o libltdlc_la-lt__alloc.o >/dev/null 2>&1
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-lt_dlloader.lo -MD -MP -MF .deps/libltdlc_la-lt_dlloader.Tpo -c ../../libltdl/lt_dlloader.c  -fPIC -DPIC -o libltdlc_la-lt_dlloader.o >/dev/null 2>&1
mv -f .deps/libltdlc_la-preopen.Tpo .deps/libltdlc_la-preopen.Plo
/bin/sh ./libtool  --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl  -DLTDLOPEN=libltdlc -DLT_CONFIG_H='<config.h>' -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl   -g -O2 -MT libltdlc_la-lt_error.lo -MD -MP -MF .deps/libltdlc_la-lt_error.Tpo -c -o libltdlc_la-lt_error.lo `test -f 'lt_error.c' || echo '../../libltdl/'`lt_error.c
mv -f .deps/dlopen.Tpo .deps/dlopen.Plo
mv -f .deps/libltdlc_la-lt__alloc.Tpo .deps/libltdlc_la-lt__alloc.Plo
mv -f .deps/libltdlc_la-lt_dlloader.Tpo .deps/libltdlc_la-lt_dlloader.Plo
/bin/sh ./libtool  --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl  -DLTDLOPEN=libltdlc -DLT_CONFIG_H='<config.h>' -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl   -g -O2 -MT libltdlc_la-ltdl.lo -MD -MP -MF .deps/libltdlc_la-ltdl.Tpo -c -o libltdlc_la-ltdl.lo `test -f 'ltdl.c' || echo '../../libltdl/'`ltdl.c
/bin/sh ./libtool  --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl  -DLTDLOPEN=libltdlc -DLT_CONFIG_H='<config.h>' -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl   -g -O2 -MT libltdlc_la-slist.lo -MD -MP -MF .deps/libltdlc_la-slist.Tpo -c -o libltdlc_la-slist.lo `test -f 'slist.c' || echo '../../libltdl/'`slist.c
/bin/sh ./libtool --tag=CC   --mode=compile ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl  -DLT_CONFIG_H='<config.h>' -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl   -g -O2 -MT lt__strl.lo -MD -MP -MF .deps/lt__strl.Tpo -c -o lt__strl.lo ../../libltdl/lt__strl.c
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-lt_error.lo -MD -MP -MF .deps/libltdlc_la-lt_error.Tpo -c ../../libltdl/lt_error.c  -fPIC -DPIC -o .libs/libltdlc_la-lt_error.o
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-lt_error.lo -MD -MP -MF .deps/libltdlc_la-lt_error.Tpo -c ../../libltdl/lt_error.c  -fPIC -DPIC -o libltdlc_la-lt_error.o >/dev/null 2>&1
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-ltdl.lo -MD -MP -MF .deps/libltdlc_la-ltdl.Tpo -c ../../libltdl/ltdl.c  -fPIC -DPIC -o .libs/libltdlc_la-ltdl.o
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-slist.lo -MD -MP -MF .deps/libltdlc_la-slist.Tpo -c ../../libltdl/slist.c  -fPIC -DPIC -o .libs/libltdlc_la-slist.o
mv -f .deps/libltdlc_la-lt_error.Tpo .deps/libltdlc_la-lt_error.Plo
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT lt__strl.lo -MD -MP -MF .deps/lt__strl.Tpo -c ../../libltdl/lt__strl.c  -fPIC -DPIC -o .libs/lt__strl.o
/bin/sh ./libtool --tag=CC   --mode=link ccache gcc  -g -O2 -module -avoid-version  -o dlopen.la  dlopen.lo -ldl -ldl 
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-slist.lo -MD -MP -MF .deps/libltdlc_la-slist.Tpo -c ../../libltdl/slist.c  -fPIC -DPIC -o libltdlc_la-slist.o >/dev/null 2>&1
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl -DLTDLOPEN=libltdlc "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT libltdlc_la-ltdl.lo -MD -MP -MF .deps/libltdlc_la-ltdl.Tpo -c ../../libltdl/ltdl.c  -fPIC -DPIC -o libltdlc_la-ltdl.o >/dev/null 2>&1
libtool: compile:  ccache gcc -DHAVE_CONFIG_H -I. -I../../libltdl "-DLT_CONFIG_H=<config.h>" -DLTDL -I. -I../../libltdl -Ilibltdl -I../../libltdl/libltdl -I../../libltdl/libltdl -g -O2 -MT lt__strl.lo -MD -MP -MF .deps/lt__strl.Tpo -c ../../libltdl/lt__strl.c  -fPIC -DPIC -o lt__strl.o >/dev/null 2>&1
mv -f .deps/libltdlc_la-slist.Tpo .deps/libltdlc_la-slist.Plo
mv -f .deps/lt__strl.Tpo .deps/lt__strl.Plo
mv -f .deps/libltdlc_la-ltdl.Tpo .deps/libltdlc_la-ltdl.Plo
libtool: link: ar cru .libs/dlopen.a .libs/dlopen.o 
libtool: link: ranlib .libs/dlopen.a
libtool: link: ( cd ".libs" && rm -f "dlopen.la" && ln -s "../dlopen.la" "dlopen.la" )
/bin/sh ./libtool --tag=CC   --mode=link ccache gcc  -g -O2 -no-undefined -dlpreopen dlopen.la   -o libltdlc.la  libltdlc_la-preopen.lo libltdlc_la-lt__alloc.lo libltdlc_la-lt_dlloader.lo libltdlc_la-lt_error.lo libltdlc_la-ltdl.lo libltdlc_la-slist.lo lt__strl.lo -ldl 
libtool: link: rm -f .libs/libltdlc.nm .libs/libltdlc.nmS .libs/libltdlc.nmT
libtool: link: (cd .libs && ccache gcc -g -O2 -c -fno-builtin  -fPIC -DPIC "libltdlcS.c")
libtool: link: rm -f ".libs/libltdlcS.c" ".libs/libltdlc.nm" ".libs/libltdlc.nmS" ".libs/libltdlc.nmT"
libtool: link: (cd .libs/libltdlc.lax/dlopen.a && ar x "<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/libltdl/./.libs/dlopen.a")>
libtool: link: ar cru .libs/libltdlc.a .libs/libltdlc_la-preopen.o .libs/libltdlc_la-lt__alloc.o .libs/libltdlc_la-lt_dlloader.o .libs/libltdlc_la-lt_error.o .libs/libltdlc_la-ltdl.o .libs/libltdlc_la-slist.o .libs/lt__strl.o .libs/libltdlcS.o  .libs/libltdlc.lax/dlopen.a/dlopen.o 
libtool: link: ranlib .libs/libltdlc.a
libtool: link: rm -fr .libs/libltdlc.lax
libtool: link: ( cd ".libs" && rm -f "libltdlc.la" && ln -s "../libltdlc.la" "libltdlc.la" )
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/libltdl'>
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/libltdl'>
Making all in scripts
make[2]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/scripts'>
make[2]: Nothing to be done for `all'.
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/scripts'>
Making all in icons
make[2]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/icons'>
make[2]: Nothing to be done for `all'.
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/icons'>
Making all in errors
make[2]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/errors'>
case "off" in \
off) \
    echo "WARNING: Translation is disabled."; \
    ;; \
""|no) \
    echo "WARNING: Translation toolkit was not detected."; \
    ;; \
esac; \
touch translate-warn
WARNING: Translation is disabled.
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/errors'>
Making all in doc
make[2]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/doc'>
Making all in manuals
make[3]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/doc/manuals'>
make[3]: Nothing to be done for `all'.
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/doc/manuals'>
make[3]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/doc'>
make[3]: Nothing to be done for `all-am'.
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/doc'>
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/doc'>
Making all in helpers
make[2]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers'>
Making all in basic_auth
make[3]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/basic_auth'>
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/basic_auth'>
make[4]: Nothing to be done for `all-am'.
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/basic_auth'>
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/basic_auth'>
Making all in digest_auth
make[3]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/digest_auth'>
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/digest_auth'>
make[4]: Nothing to be done for `all-am'.
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/digest_auth'>
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/digest_auth'>
Making all in external_acl
make[3]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl'>
Making all in LDAP_group
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/LDAP_group'>
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT ext_ldap_group_acl.o -MD -MP -MF .deps/ext_ldap_group_acl.Tpo -c -o ext_ldap_group_acl.o ../../../../helpers/external_acl/LDAP_group/ext_ldap_group_acl.cc
mv -f .deps/ext_ldap_group_acl.Tpo .deps/ext_ldap_group_acl.Po
/bin/sh ../../../libtool  --tag=CXX   --mode=link ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11  -g -o ext_ldap_group_acl ext_ldap_group_acl.o ../../../lib/libmiscencoding.la ../../../compat/libcompat-squid.la  -lldap -llber -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl 
libtool: link: ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -g -o ext_ldap_group_acl ext_ldap_group_acl.o  ../../../lib/.libs/libmiscencoding.a ../../../compat/.libs/libcompat-squid.a -lldap -llber -lm -lnsl -lresolv -lcap -lrt -ldl
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/LDAP_group'>
Making all in SQL_session
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/SQL_session'>
sed -e 's,[@]PERL[@],/usr/bin/perl,g' <../../../../helpers/external_acl/SQL_session/ext_sql_session_acl.pl.in >ext_sql_session_acl || (/usr/bin/rm -f -f ext_sql_session_acl ; exit 1)
pod2man --section=8 ext_sql_session_acl ext_sql_session_acl.8
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/SQL_session'>
Making all in delayer
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/delayer'>
sed -e 's,[@]PERL[@],/usr/bin/perl,g' <../../../../helpers/external_acl/delayer/ext_delayer_acl.pl.in >ext_delayer_acl || (/usr/bin/rm -f -f ext_delayer_acl ; exit 1)
pod2man --section=8 ext_delayer_acl ext_delayer_acl.8
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/delayer'>
Making all in eDirectory_userip
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/eDirectory_userip'>
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT ext_edirectory_userip_acl.o -MD -MP -MF .deps/ext_edirectory_userip_acl.Tpo -c -o ext_edirectory_userip_acl.o ../../../../helpers/external_acl/eDirectory_userip/ext_edirectory_userip_acl.cc
mv -f .deps/ext_edirectory_userip_acl.Tpo .deps/ext_edirectory_userip_acl.Po
/bin/sh ../../../libtool  --tag=CXX   --mode=link ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11  -g -o ext_edirectory_userip_acl ext_edirectory_userip_acl.o ../../../compat/libcompat-squid.la  -lldap -llber -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl 
libtool: link: ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -g -o ext_edirectory_userip_acl ext_edirectory_userip_acl.o  ../../../compat/.libs/libcompat-squid.a -lldap -llber -lm -lnsl -lresolv -lcap -lrt -ldl
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/eDirectory_userip'>
Making all in file_userip
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/file_userip'>
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT ext_file_userip_acl.o -MD -MP -MF .deps/ext_file_userip_acl.Tpo -c -o ext_file_userip_acl.o ../../../../helpers/external_acl/file_userip/ext_file_userip_acl.cc
mv -f .deps/ext_file_userip_acl.Tpo .deps/ext_file_userip_acl.Po
/bin/sh ../../../libtool  --tag=CXX   --mode=link ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11  -g -o ext_file_userip_acl ext_file_userip_acl.o ../../../lib/libmiscencoding.la ../../../compat/libcompat-squid.la  -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl 
libtool: link: ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -g -o ext_file_userip_acl ext_file_userip_acl.o  ../../../lib/.libs/libmiscencoding.a ../../../compat/.libs/libcompat-squid.a -lm -lnsl -lresolv -lcap -lrt -ldl
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/file_userip'>
Making all in kerberos_ldap_group
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/kerberos_ldap_group'>
make[5]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/kerberos_ldap_group'>
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT kerberos_ldap_group.o -MD -MP -MF .deps/kerberos_ldap_group.Tpo -c -o kerberos_ldap_group.o ../../../../helpers/external_acl/kerberos_ldap_group/kerberos_ldap_group.cc
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_group.o -MD -MP -MF .deps/support_group.Tpo -c -o support_group.o ../../../../helpers/external_acl/kerberos_ldap_group/support_group.cc
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_netbios.o -MD -MP -MF .deps/support_netbios.Tpo -c -o support_netbios.o ../../../../helpers/external_acl/kerberos_ldap_group/support_netbios.cc
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_member.o -MD -MP -MF .deps/support_member.Tpo -c -o support_member.o ../../../../helpers/external_acl/kerberos_ldap_group/support_member.cc
mv -f .deps/support_member.Tpo .deps/support_member.Po
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_krb5.o -MD -MP -MF .deps/support_krb5.Tpo -c -o support_krb5.o ../../../../helpers/external_acl/kerberos_ldap_group/support_krb5.cc
mv -f .deps/kerberos_ldap_group.Tpo .deps/kerberos_ldap_group.Po
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_ldap.o -MD -MP -MF .deps/support_ldap.Tpo -c -o support_ldap.o ../../../../helpers/external_acl/kerberos_ldap_group/support_ldap.cc
mv -f .deps/support_netbios.Tpo .deps/support_netbios.Po
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_sasl.o -MD -MP -MF .deps/support_sasl.Tpo -c -o support_sasl.o ../../../../helpers/external_acl/kerberos_ldap_group/support_sasl.cc
mv -f .deps/support_group.Tpo .deps/support_group.Po
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_resolv.o -MD -MP -MF .deps/support_resolv.Tpo -c -o support_resolv.o ../../../../helpers/external_acl/kerberos_ldap_group/support_resolv.cc
mv -f .deps/support_krb5.Tpo .deps/support_krb5.Po
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_lserver.o -MD -MP -MF .deps/support_lserver.Tpo -c -o support_lserver.o ../../../../helpers/external_acl/kerberos_ldap_group/support_lserver.cc
mv -f .deps/support_sasl.Tpo .deps/support_sasl.Po
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I../../../../helpers/external_acl/kerberos_ldap_group -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT support_log.o -MD -MP -MF .deps/support_log.Tpo -c -o support_log.o ../../../../helpers/external_acl/kerberos_ldap_group/support_log.cc
mv -f .deps/support_resolv.Tpo .deps/support_resolv.Po
mv -f .deps/support_ldap.Tpo .deps/support_ldap.Po
mv -f .deps/support_log.Tpo .deps/support_log.Po
mv -f .deps/support_lserver.Tpo .deps/support_lserver.Po
/bin/sh ../../../libtool  --tag=CXX   --mode=link ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11  -g -o ext_kerberos_ldap_group_acl kerberos_ldap_group.o support_group.o support_netbios.o support_member.o support_krb5.o support_ldap.o support_sasl.o support_resolv.o support_lserver.o support_log.o ../../../lib/libmiscencoding.la ../../../compat/libcompat-squid.la  -lldap -llber -lsasl2 -lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err -lkrb5 -lk5crypto -lcom_err  -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl 
libtool: link: ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -g -o ext_kerberos_ldap_group_acl kerberos_ldap_group.o support_group.o support_netbios.o support_member.o support_krb5.o support_ldap.o support_sasl.o support_resolv.o support_lserver.o support_log.o  ../../../lib/.libs/libmiscencoding.a ../../../compat/.libs/libcompat-squid.a -lldap -llber -lsasl2 -lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err -lm -lnsl -lresolv -lcap -lrt -ldl
make[5]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/kerberos_ldap_group'>
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/kerberos_ldap_group'>
Making all in unix_group
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/unix_group'>
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT check_group.o -MD -MP -MF .deps/check_group.Tpo -c -o check_group.o ../../../../helpers/external_acl/unix_group/check_group.cc
mv -f .deps/check_group.Tpo .deps/check_group.Po
/bin/sh ../../../libtool  --tag=CXX   --mode=link ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11  -g -o ext_unix_group_acl check_group.o ../../../lib/libmiscencoding.la ../../../compat/libcompat-squid.la  -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl 
libtool: link: ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -g -o ext_unix_group_acl check_group.o  ../../../lib/.libs/libmiscencoding.a ../../../compat/.libs/libcompat-squid.a -lm -lnsl -lresolv -lcap -lrt -ldl
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/unix_group'>
Making all in wbinfo_group
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/wbinfo_group'>
sed -e 's,[@]PERL[@],/usr/bin/perl,g' <../../../../helpers/external_acl/wbinfo_group/ext_wbinfo_group_acl.pl.in >ext_wbinfo_group_acl || (/usr/bin/rm -f -f ext_wbinfo_group_acl ; exit 1)
pod2man --section=8 ext_wbinfo_group_acl ext_wbinfo_group_acl.8
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl/wbinfo_group'>
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl'>
make[4]: Nothing to be done for `all-am'.
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl'>
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/external_acl'>
Making all in log_daemon
make[3]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/log_daemon'>
Making all in DB
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/log_daemon/DB'>
sed -e 's,[@]PERL[@],/usr/bin/perl,g' <../../../../helpers/log_daemon/DB/log_db_daemon.pl.in >log_db_daemon || (/usr/bin/rm -f -f log_db_daemon ; exit 1)
pod2man --section=8 log_db_daemon log_db_daemon.8
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/log_daemon/DB'>
Making all in file
make[4]: Entering directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/log_daemon/file'>
ccache g++ -DHAVE_CONFIG_H   -I../../../.. -I../../../../include -I../../../../lib -I../../../../src -I../../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT log_file_daemon.o -MD -MP -MF .deps/log_file_daemon.Tpo -c -o log_file_daemon.o ../../../../helpers/log_daemon/file/log_file_daemon.cc
mv -f .deps/log_file_daemon.Tpo .deps/log_file_daemon.Po
/bin/sh ../../../libtool  --tag=CXX   --mode=link ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11  -g -o log_file_daemon log_file_daemon.o -L../../../lib ../../../compat/libcompat-squid.la  -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl 
libtool: link: ccache g++ -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -g -o log_file_daemon log_file_daemon.o  -L../../../lib ../../../compat/.libs/libcompat-squid.a -lm -lnsl -lresolv -lcap -lrt -ldl
g++: error: ../../../compat/.libs/libcompat-squid.a: No such file or directory
make[4]: *** [log_file_daemon] Error 1
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/log_daemon/file'>
make[3]: *** [all-recursive] Error 1
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers/log_daemon'>
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/helpers'>
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build'>
make: *** [distcheck] Error 1
buildtest.sh result is 2
BUILD: .././test-suite/buildtests/layer-04-noauth-everything.opts
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: -Wall -g -O2
configure: BUILD EXTRA C FLAGS: -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS: -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS: -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS: -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
g++: error: ../../../compat/.libs/libcompat-squid.a: No such file or directory
make[4]: *** [log_file_daemon] Error 1
make[3]: *** [all-recursive] Error 1
make[2]: *** [all-recursive] Error 1
make[1]: *** [all-recursive] Error 1
make: *** [distcheck] Error 1
Build FAILED.
Build step 'Execute shell' marked build as failure
[description-setter] Description set: 

From noc at squid-cache.org  Wed Jun 24 22:29:57 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Wed, 24 Jun 2015 22:29:57 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Build_failed_in_Jenkins=3A_trunk-matrix_?=
 =?utf-8?q?=C2=BB_gcc=2Cd-ubuntu-utopic_=23222?=
Message-ID: <400685458.4.1435184997343.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/222/>

------------------------------------------
[...truncated 51125 lines...]
Testing ../../src/DiskIO/IpcIo/IpcIoFile.h ...Ok.
Testing ../../src/DiskIO/IpcIo/IpcIoDiskIOModule.h ...Ok.
Testing ../../src/DiskIO/IpcIo/IpcIoIOStrategy.h ...Ok.
Testing ../../src/DiskIO/DiskDaemon/DiskdFile.h ...Ok.
Testing ../../src/DiskIO/DiskDaemon/DiskdAction.h ...Ok.
Testing ../../src/DiskIO/DiskDaemon/diomsg.h ...Ok.
Testing ../../src/DiskIO/DiskDaemon/DiskdIOStrategy.h ...Ok.
Testing ../../src/DiskIO/DiskDaemon/DiskDaemonDiskIOModule.h ...Ok.
Testing ../../src/DiskIO/Blocking/BlockingIOStrategy.h ...Ok.
Testing ../../src/DiskIO/Blocking/BlockingFile.h ...Ok.
Testing ../../src/DiskIO/Blocking/BlockingDiskIOModule.h ...Ok.
PASS: testHeaders
make[7]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
make  all-recursive
make[8]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
Making all in mem
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/mem'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/mem'>
Making all in base
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/base'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/base'>
Making all in anyp
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/anyp'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/anyp'>
Making all in helper
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/helper'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/helper'>
Making all in dns
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/dns'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/dns'>
Making all in ftp
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/ftp'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/ftp'>
Making all in parser
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/parser'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/parser'>
Making all in comm
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/comm'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/comm'>
Making all in eui
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/eui'>
make[9]: Nothing to be done for 'all'.
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/eui'>
Making all in acl
make[9]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/acl'>
/bin/bash ../../libtool  --tag=CXX   --mode=compile ccache g++ -DHAVE_CONFIG_H   -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT Acl.lo -MD -MP -MF .deps/Acl.Tpo -c -o Acl.lo ../../../src/acl/Acl.cc
/bin/bash ../../libtool  --tag=CXX   --mode=compile ccache g++ -DHAVE_CONFIG_H   -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT BoolOps.lo -MD -MP -MF .deps/BoolOps.Tpo -c -o BoolOps.lo ../../../src/acl/BoolOps.cc
/bin/bash ../../libtool  --tag=CXX   --mode=compile ccache g++ -DHAVE_CONFIG_H   -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT Checklist.lo -MD -MP -MF .deps/Checklist.Tpo -c -o Checklist.lo ../../../src/acl/Checklist.cc
/bin/bash ../../libtool  --tag=CXX   --mode=compile ccache g++ -DHAVE_CONFIG_H   -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include    -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT InnerNode.lo -MD -MP -MF .deps/InnerNode.Tpo -c -o InnerNode.lo ../../../src/acl/InnerNode.cc
libtool: compile:  ccache g++ -DHAVE_CONFIG_H -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include -I/usr/include/libxml2 -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT Acl.lo -MD -MP -MF .deps/Acl.Tpo -c ../../../src/acl/Acl.cc  -fPIC -DPIC -o .libs/Acl.o
libtool: compile:  ccache g++ -DHAVE_CONFIG_H -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include -I/usr/include/libxml2 -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT BoolOps.lo -MD -MP -MF .deps/BoolOps.Tpo -c ../../../src/acl/BoolOps.cc  -fPIC -DPIC -o .libs/BoolOps.o
libtool: compile:  ccache g++ -DHAVE_CONFIG_H -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include -I/usr/include/libxml2 -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT InnerNode.lo -MD -MP -MF .deps/InnerNode.Tpo -c ../../../src/acl/InnerNode.cc  -fPIC -DPIC -o .libs/InnerNode.o
g++: error: ../../../src/acl/BoolOps.cc: No such file or directory
g++: fatal error: no input files
compilation terminated.
libtool: compile:  ccache g++ -DHAVE_CONFIG_H -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include -I/usr/include/libxml2 -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT Checklist.lo -MD -MP -MF .deps/Checklist.Tpo -c ../../../src/acl/Checklist.cc  -fPIC -DPIC -o .libs/Checklist.o
Makefile:969: recipe for target 'BoolOps.lo' failed
make[9]: *** [BoolOps.lo] Error 1
make[9]: *** Waiting for unfinished jobs....
g++: error: ../../../src/acl/Checklist.cc: No such file or directory
g++: fatal error: no input files
compilation terminated.
Makefile:969: recipe for target 'Checklist.lo' failed
make[9]: *** [Checklist.lo] Error 1
g++: error: ../../../src/acl/InnerNode.cc: No such file or directory
g++: fatal error: no input files
compilation terminated.
Makefile:969: recipe for target 'InnerNode.lo' failed
make[9]: *** [InnerNode.lo] Error 1
g++: error: ../../../src/acl/Acl.cc: No such file or directory
g++: fatal error: no input files
compilation terminated.
Makefile:969: recipe for target 'Acl.lo' failed
make[9]: *** [Acl.lo] Error 1
make[9]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src/acl'>
Makefile:7080: recipe for target 'all-recursive' failed
make[8]: *** [all-recursive] Error 1
make[8]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
Makefile:5960: recipe for target 'all' failed
make[7]: *** [all] Error 2
make[7]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
============================================================================
Testsuite summary for Squid Web Proxy 4.0.0-BZR
============================================================================
# TOTAL: 21
# PASS:  21
# SKIP:  0
# XFAIL: 0
# FAIL:  0
# XPASS: 0
# ERROR: 0
============================================================================
make[6]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
make[5]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
make[4]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
make[3]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
make[2]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/src'>
Making check in tools
make[2]: Entering directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/tools'>
 cd ../.. && /bin/bash <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/cfgaux/missing> automake-1.14 --foreign tools/Makefile
/bin/bash: <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/cfgaux/missing>: No such file or directory
Makefile:763: recipe for target '../../tools/Makefile.in' failed
make[2]: *** [../../tools/Makefile.in] Error 127
make[2]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build/tools'>
Makefile:567: recipe for target 'check-recursive' failed
make[1]: *** [check-recursive] Error 1
make[1]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/_build'>
Makefile:775: recipe for target 'distcheck' failed
make: *** [distcheck] Error 1
buildtest.sh result is 2
BUILD: .././test-suite/buildtests/layer-04-noauth-everything.opts
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: -Wall -g -O2
configure: BUILD EXTRA C FLAGS: -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS: -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -ldl -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS: -Wall -Wpointer-arith -Wwrite-strings -Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror -pipe -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS: -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
cat: ../../src/DiskIO/../../scripts/boilerplate.h: No such file or directory
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
# XFAIL: 0
# FAIL:  0
g++: error: ../../../src/acl/BoolOps.cc: No such file or directory
g++: fatal error: no input files
make[9]: *** [BoolOps.lo] Error 1
g++: error: ../../../src/acl/Checklist.cc: No such file or directory
g++: fatal error: no input files
make[9]: *** [Checklist.lo] Error 1
g++: error: ../../../src/acl/InnerNode.cc: No such file or directory
g++: fatal error: no input files
make[9]: *** [InnerNode.lo] Error 1
g++: error: ../../../src/acl/Acl.cc: No such file or directory
g++: fatal error: no input files
make[9]: *** [Acl.lo] Error 1
make[8]: *** [all-recursive] Error 1
make[7]: *** [all] Error 2
# XFAIL: 0
# FAIL:  0
/bin/bash: <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/ws/btlayer-04-noauth-everything/squid-4.0.0-BZR/cfgaux/missing>: No such file or directory
make[2]: *** [../../tools/Makefile.in] Error 127
make[1]: *** [check-recursive] Error 1
make: *** [distcheck] Error 1
Build FAILED.
Build step 'Execute shell' marked build as failure
[description-setter] Description set: 

From noc at squid-cache.org  Wed Jun 24 22:29:56 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Wed, 24 Jun 2015 22:29:56 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Build_failed_in_Jenkins=3A_trunk-matrix_?=
 =?utf-8?q?=C2=BB_gcc=2Cd-fedora-21_=23222?=
Message-ID: <693857794.3.1435184996614.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/222/>

------------------------------------------
[...truncated 9197 lines...]
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testStoreController.o -MD -MP -MF $depbase.Tpo -c -o tests/testStoreController.o ../../src/tests/testStoreController.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testStoreHashIndex.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testStoreHashIndex.o -MD -MP -MF $depbase.Tpo -c -o tests/testStoreHashIndex.o ../../src/tests/testStoreHashIndex.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/TestSwapDir.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/TestSwapDir.o -MD -MP -MF $depbase.Tpo -c -o tests/TestSwapDir.o ../../src/tests/TestSwapDir.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testString.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testString.o -MD -MP -MF $depbase.Tpo -c -o tests/testString.o ../../src/tests/testString.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testURL.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testURL.o -MD -MP -MF $depbase.Tpo -c -o tests/testURL.o ../../src/tests/testURL.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testUriScheme.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testUriScheme.o -MD -MP -MF $depbase.Tpo -c -o tests/testUriScheme.o ../../src/tests/testUriScheme.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testSBuf.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testSBuf.o -MD -MP -MF $depbase.Tpo -c -o tests/testSBuf.o ../../src/tests/testSBuf.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/SBufFindTest.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/SBufFindTest.o -MD -MP -MF $depbase.Tpo -c -o tests/SBufFindTest.o ../../src/tests/SBufFindTest.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_wordlist.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_wordlist.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_wordlist.o ../../src/tests/stub_wordlist.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testSBufList.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testSBufList.o -MD -MP -MF $depbase.Tpo -c -o tests/testSBufList.o ../../src/tests/testSBufList.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo SBufList.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT SBufList.o -MD -MP -MF $depbase.Tpo -c -o SBufList.o ../../src/SBufList.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testConfigParser.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testConfigParser.o -MD -MP -MF $depbase.Tpo -c -o tests/testConfigParser.o ../../src/tests/testConfigParser.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testStatHist.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testStatHist.o -MD -MP -MF $depbase.Tpo -c -o tests/testStatHist.o ../../src/tests/testStatHist.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testRock.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testRock.o -MD -MP -MF $depbase.Tpo -c -o tests/testRock.o ../../src/tests/testRock.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testUfs.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testUfs.o -MD -MP -MF $depbase.Tpo -c -o tests/testUfs.o ../../src/tests/testUfs.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testRefCount.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testRefCount.o -MD -MP -MF $depbase.Tpo -c -o tests/testRefCount.o ../../src/tests/testRefCount.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_CollapsedForwarding.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_CollapsedForwarding.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_CollapsedForwarding.o ../../src/tests/stub_CollapsedForwarding.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_ETag.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_ETag.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_ETag.o ../../src/tests/stub_ETag.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_fatal.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_fatal.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_fatal.o ../../src/tests/stub_fatal.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_StatHist.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_StatHist.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_StatHist.o ../../src/tests/stub_StatHist.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_SBufDetailedStats.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_SBufDetailedStats.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_SBufDetailedStats.o ../../src/tests/stub_SBufDetailedStats.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_StoreMeta.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_StoreMeta.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_StoreMeta.o ../../src/tests/stub_StoreMeta.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_SwapDir.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_SwapDir.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_SwapDir.o ../../src/tests/stub_SwapDir.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_access_log.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_access_log.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_access_log.o ../../src/tests/stub_access_log.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_cache_cf.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_cache_cf.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_cache_cf.o ../../src/tests/stub_cache_cf.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_client_side.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_client_side.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_client_side.o ../../src/tests/stub_client_side.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_debug.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_debug.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_debug.o ../../src/tests/stub_debug.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_DelayId.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_DelayId.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_DelayId.o ../../src/tests/stub_DelayId.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_DiskIOModule.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_DiskIOModule.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_DiskIOModule.o ../../src/tests/stub_DiskIOModule.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_errorpage.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_errorpage.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_errorpage.o ../../src/tests/stub_errorpage.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_fd.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_fd.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_fd.o ../../src/tests/stub_fd.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_HttpRequest.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_HttpRequest.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_HttpRequest.o ../../src/tests/stub_HttpRequest.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_HttpReply.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_HttpReply.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_HttpReply.o ../../src/tests/stub_HttpReply.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_ipc_TypedMsgHdr.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_ipc_TypedMsgHdr.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_ipc_TypedMsgHdr.o ../../src/tests/stub_ipc_TypedMsgHdr.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_libauth.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_libauth.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_libauth.o ../../src/tests/stub_libauth.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_libcomm.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_libcomm.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_libcomm.o ../../src/tests/stub_libcomm.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_libformat.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_libformat.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_libformat.o ../../src/tests/stub_libformat.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_libsslsquid.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_libsslsquid.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_libsslsquid.o ../../src/tests/stub_libsslsquid.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_MemObject.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_MemObject.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_MemObject.o ../../src/tests/stub_MemObject.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_MemStore.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_MemStore.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_MemStore.o ../../src/tests/stub_MemStore.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_mime.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_mime.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_mime.o ../../src/tests/stub_mime.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_pconn.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_pconn.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_pconn.o ../../src/tests/stub_pconn.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_Port.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_Port.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_Port.o ../../src/tests/stub_Port.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_store.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_store.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_store.o ../../src/tests/stub_store.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_store_client.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_store_client.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_store_client.o ../../src/tests/stub_store_client.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_store_rebuild.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_store_rebuild.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_store_rebuild.o ../../src/tests/stub_store_rebuild.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_store_stats.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_store_stats.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_store_stats.o ../../src/tests/stub_store_stats.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_store_swapout.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_store_swapout.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_store_swapout.o ../../src/tests/stub_store_swapout.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_tools.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_tools.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_tools.o ../../src/tests/stub_tools.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_cache_manager.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_cache_manager.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_cache_manager.o ../../src/tests/stub_cache_manager.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_UdsOp.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_UdsOp.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_UdsOp.o ../../src/tests/stub_UdsOp.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testACLMaxUserIP.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testACLMaxUserIP.o -MD -MP -MF $depbase.Tpo -c -o tests/testACLMaxUserIP.o ../../src/tests/testACLMaxUserIP.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_time.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_time.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_time.o ../../src/tests/stub_time.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_libmem.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_libmem.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_libmem.o ../../src/tests/stub_libmem.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo test_tools.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT test_tools.o -MD -MP -MF $depbase.Tpo -c -o test_tools.o test_tools.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testBoilerplate.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testBoilerplate.o -MD -MP -MF $depbase.Tpo -c -o tests/testBoilerplate.o ../../src/tests/testBoilerplate.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_cbdata.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_cbdata.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_cbdata.o ../../src/tests/stub_cbdata.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_MemBuf.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_MemBuf.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_MemBuf.o ../../src/tests/stub_MemBuf.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/testCacheManager.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/testCacheManager.o -MD -MP -MF $depbase.Tpo -c -o tests/testCacheManager.o ../../src/tests/testCacheManager.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_main_cc.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_main_cc.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_main_cc.o ../../src/tests/stub_main_cc.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_ipc_Forwarder.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_ipc_Forwarder.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_ipc_Forwarder.o ../../src/tests/stub_ipc_Forwarder.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_EventLoop.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_EventLoop.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_EventLoop.o ../../src/tests/stub_EventLoop.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_CacheDigest.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_CacheDigest.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_CacheDigest.o ../../src/tests/stub_CacheDigest.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_carp.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_carp.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_carp.o ../../src/tests/stub_carp.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_libsecurity.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_libsecurity.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_libsecurity.o ../../src/tests/stub_libsecurity.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_redirect.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_redirect.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_redirect.o ../../src/tests/stub_redirect.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_libauth_acls.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_libauth_acls.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_libauth_acls.o ../../src/tests/stub_libauth_acls.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_store_digest.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_store_digest.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_store_digest.o ../../src/tests/stub_store_digest.cc &&\
mv -f $depbase.Tpo $depbase.Po
depbase=`echo tests/stub_tunnel.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
ccache g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc/squid.conf\"> -DDEFAULT_SQUID_DATA_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/share\"> -DDEFAULT_SQUID_CONFIG_DIR=\"<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_inst/etc\">   -I../.. -I../../include -I../../lib -I../../src -I../include    -I../src    -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -std=c++11 -MT tests/stub_tunnel.o -MD -MP -MF $depbase.Tpo -c -o tests/stub_tunnel.o ../../src/tests/stub_tunnel.cc &&\
mv -f $depbase.Tpo $depbase.Po
g++: error: ../../src/tests/stub_tunnel.cc: No such file or directory
g++: fatal error: no input files
compilation terminated.
Makefile:6957: recipe for target 'tests/stub_tunnel.o' failed
make[5]: *** [tests/stub_tunnel.o] Error 4
make[5]: *** Waiting for unfinished jobs....
g++: error: ../../src/tests/stub_redirect.cc: No such file or directory
g++: fatal error: no input files
compilation terminated.
Makefile:6957: recipe for target 'tests/stub_redirect.o' failed
make[5]: *** [tests/stub_redirect.o] Error 4
g++: error: ../../src/tests/stub_store_digest.cc: No such file or directory
g++: fatal error: no input files
compilation terminated.
Makefile:6957: recipe for target 'tests/stub_store_digest.o' failed
make[5]: *** [tests/stub_store_digest.o] Error 4
g++: error: ../../src/tests/stub_libauth_acls.cc: No such file or directory
g++: fatal error: no input files
compilation terminated.
Makefile:6957: recipe for target 'tests/stub_libauth_acls.o' failed
make[5]: *** [tests/stub_libauth_acls.o] Error 4
make[5]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
Makefile:7538: recipe for target 'check-am' failed
make[4]: *** [check-am] Error 2
make[4]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
Makefile:7080: recipe for target 'check-recursive' failed
make[3]: *** [check-recursive] Error 1
make[3]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
Makefile:7541: recipe for target 'check' failed
make[2]: *** [check] Error 2
make[2]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
Makefile:567: recipe for target 'check-recursive' failed
make[1]: *** [check-recursive] Error 1
make[1]: Leaving directory '<http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/ws/btlayer-00-default/squid-4.0.0-BZR/_build'>
Makefile:775: recipe for target 'distcheck' failed
make: *** [distcheck] Error 1
buildtest.sh result is 2
grep: btlayer-00-default.log: No such file or directory
grep: btlayer-00-default.log: No such file or directory
grep: btlayer-00-default.log: No such file or directory
Build FAILED.
Build step 'Execute shell' marked build as failure
[description-setter] Description set: 

From noc at squid-cache.org  Wed Jun 24 22:29:59 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Wed, 24 Jun 2015 22:29:59 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Build_failed_in_Jenkins=3A_trunk-matrix_?=
 =?utf-8?q?=C2=BB_clang=2Cd-fedora-20_=23222?=
Message-ID: <2143713266.5.1435184999616.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-fedora-20/222/>

------------------------------------------
[...truncated 3998 lines...]
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for syslog... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for timegm... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for vsnprintf... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for initgroups... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for psignal... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for strerror... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for strtoll... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for tempnam... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking whether getaddrinfo is declared... ../configure: line 2631: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 38275: confdefs.h: No such file or directory
checking whether getnameinfo is declared... ../configure: line 2631: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 38313: confdefs.h: No such file or directory
checking whether inet_ntop is declared... ../configure: line 2631: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 38351: confdefs.h: No such file or directory
checking whether inet_pton is declared... ../configure: line 2631: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 38389: confdefs.h: No such file or directory
checking whether InetNtopA is declared... ../configure: line 2631: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 38427: confdefs.h: No such file or directory
checking whether InetPtonA is declared... ../configure: line 2631: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 38465: confdefs.h: No such file or directory
configure: Using epoll for the IO loop.
../configure: line 38551: confdefs.h: No such file or directory
checking if setresuid is actually implemented... ../configure: line 38585: conftest.cpp: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking mswsock.h usability... ../configure: line 2293: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking mswsock.h presence... ../configure: line 2310: conftest.cpp: No such file or directory
../configure: line 2239: conftest.i: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for mswsock.h... no
checking for constant CMSG_SPACE... ../configure: line 38643: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for struct cmsghdr... ../configure: line 2722: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for struct iovec... ../configure: line 2722: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for struct msghdr... ../configure: line 2722: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for struct sockaddr_un... ../configure: line 2722: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking if strnstr is well implemented... ../configure: line 38762: conftest.cpp: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking if va_copy is implemented... ../configure: line 38812: conftest.cpp: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking if __va_copy is implemented... ../configure: line 38859: conftest.cpp: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
configure: IPF-based transparent proxying enabled: no
../configure: line 39069: confdefs.h: No such file or directory
../configure: line 39097: confdefs.h: No such file or directory
../configure: line 39111: confdefs.h: No such file or directory
../configure: line 39139: confdefs.h: No such file or directory
configure: Support for Netfilter-based interception proxy requested: no
configure: Linux Netfilter Conntrack support enabled: no 
../configure: line 39191: confdefs.h: No such file or directory
configure: ZPH QOS enabled: yes
configure: QOS netfilter mark preservation enabled: no
../configure: line 39210: confdefs.h: No such file or directory
checking for regexec in -lregex... ../configure: line 39226: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking if the system-supplied regex lib actually works... ../configure: line 39293: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking if GNUregex needs to be compiled... yes
../configure: line 39349: confdefs.h: No such file or directory
checking Default UDP send buffer size... ../configure: line 39363: conftest.cpp: No such file or directory
sed: can't read conftest.cpp: No such file or directory
16384
../configure: line 39417: confdefs.h: No such file or directory
checking Default UDP receive buffer size... ../configure: line 39428: conftest.cpp: No such file or directory
sed: can't read conftest.cpp: No such file or directory
16384
../configure: line 39482: confdefs.h: No such file or directory
checking Default TCP send buffer size... ../configure: line 39493: conftest.cpp: No such file or directory
sed: can't read conftest.cpp: No such file or directory
16384
../configure: line 39552: confdefs.h: No such file or directory
checking Default TCP receive buffer size... ../configure: line 39563: conftest.cpp: No such file or directory
sed: can't read conftest.cpp: No such file or directory
16384
../configure: line 39622: confdefs.h: No such file or directory
checking whether recv takes a pointer to void or char as second argument... ../configure: line 39635: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
char*
char
../configure: line 39673: confdefs.h: No such file or directory
checking if sys_errlist is already defined... ../configure: line 39684: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
yes
../configure: line 39713: confdefs.h: No such file or directory
checking for system-provided MAXPATHLEN... ../configure: line 39723: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 39746: confdefs.h: No such file or directory
checking for libresolv _dns_ttl_ hack... ../configure: line 39760: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 39789: confdefs.h: No such file or directory
checking for _res_ext.nsaddr_list... ../configure: line 39802: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for _res._u._ext.nsaddrs... ../configure: line 39855: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for _res.nsaddr_list... ../configure: line 39907: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for _res.ns_list... ../configure: line 39959: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking sys/statvfs.h usability... ../configure: line 2293: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking sys/statvfs.h presence... ../configure: line 2310: conftest.cpp: No such file or directory
../configure: line 2239: conftest.i: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for sys/statvfs.h... no
checking for sys/param.h... (cached) yes
../configure: line 40079: confdefs.h: No such file or directory
checking for sys/mount.h... (cached) no
checking for sys/vfs.h... (cached) no
checking sys/statfs.h usability... ../configure: line 2293: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking sys/statfs.h presence... ../configure: line 2310: conftest.cpp: No such file or directory
../configure: line 2239: conftest.i: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for sys/statfs.h... no
checking for statfs... ../configure: line 2774: conftest.cpp: No such file or directory
../configure: line 2193: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
checking for f_frsize field in struct statfs... ../configure: line 40105: conftest.cpp: No such file or directory
../configure: line 2155: conftest.err: No such file or directory
sed: can't read conftest.cpp: No such file or directory
no
../configure: line 40145: confdefs.h: No such file or directory
configure: Multi-Language support enabled: yes
../configure: line 40378: confdefs.h: No such file or directory
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
../configure: line 40446: confcache: No such file or directory
../configure: line 40507: confcache: No such file or directory
checking that generated files are newer than configure... done
configure: creating ./config.status
../configure: line 40777: ./config.status: No such file or directory
../configure: line 40791: ./config.status: No such file or directory
../configure: line 41161: ./config.status: No such file or directory
../configure: line 41189: ./config.status: No such file or directory
../configure: line 41197: ./config.status: No such file or directory
../configure: line 41229: ./config.status: No such file or directory
../configure: line 41248: ./config.status: No such file or directory
../configure: line 41325: ./config.status: No such file or directory
../configure: line 41336: ./config.status: No such file or directory
../configure: line 41347: ./config.status: No such file or directory
../configure: line 41730: ./config.status: No such file or directory
../configure: line 41919: conf23166subs.sh: No such file or directory
configure: error: could not make ./config.status
make: *** [distcheck] Error 1
buildtest.sh result is 2
grep: btlayer-00-default.log: No such file or directory
grep: btlayer-00-default.log: No such file or directory
grep: btlayer-00-default.log: No such file or directory
Build FAILED.
Build step 'Execute shell' marked build as failure
[description-setter] Description set: 

From noc at squid-cache.org  Thu Jun 25 00:29:34 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Thu, 25 Jun 2015 00:29:34 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Build_failed_in_Jenkins=3A_trunk-matrix_?=
 =?utf-8?q?=C2=BB_clang=2Cd-ubuntu-precise_=23222?=
Message-ID: <1492988014.6.1435192174664.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/222/>

------------------------------------------
[...truncated 4969 lines...]
            ^
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char> atomic_char;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<signed char> atomic_schar;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned char> atomic_uchar;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<short> atomic_short;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned short> atomic_ushort;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int> atomic_int;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned int> atomic_uint;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<long> atomic_long;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned long> atomic_ulong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<long long> atomic_llong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned long long> atomic_ullong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<wchar_t> atomic_wchar_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char16_t> atomic_char16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char32_t> atomic_char32_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char32_t> atomic_char32_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least8_t> atomic_int_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<uint_least8_t> atomic_uint_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least16_t> atomic_int_least16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
make[4]: *** [rock/RockRebuild.lo] Error 1
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src/fs'>
make[3]: *** [all-recursive] Error 1
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
make[2]: *** [all] Error 2
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/ws/btlayer-00-default/squid-4.0.0-BZR/_build'>
make: *** [distcheck] Error 1
buildtest.sh result is 2
BUILD: .././test-suite/buildtests/layer-00-default.opts
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockStoreFileSystem.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockIoRequests.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockIoState.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockRebuild.lo] Error 1
make[3]: *** [all-recursive] Error 1
make[2]: *** [all] Error 2
make[1]: *** [all-recursive] Error 1
make: *** [distcheck] Error 1
Build FAILED.
Build step 'Execute shell' marked build as failure
[description-setter] Description set: 

From noc at squid-cache.org  Thu Jun 25 01:30:52 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Thu, 25 Jun 2015 01:30:52 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Build_failed_in_Jenkins=3A_trunk-matrix_?=
 =?utf-8?q?=C2=BB_clang=2Cd-debian-wheezy_=23222?=
Message-ID: <753519673.7.1435195852291.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/222/>

------------------------------------------
[...truncated 4972 lines...]
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char> atomic_char;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<signed char> atomic_schar;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned char> atomic_uchar;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<short> atomic_short;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned short> atomic_ushort;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int> atomic_int;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned int> atomic_uint;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<long> atomic_long;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned long> atomic_ulong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<long long> atomic_llong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned long long> atomic_ullong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<wchar_t> atomic_wchar_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char16_t> atomic_char16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char32_t> atomic_char32_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char32_t> atomic_char32_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least8_t> atomic_int_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<uint_least8_t> atomic_uint_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least16_t> atomic_int_least16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
make[4]: *** [rock/RockStoreFileSystem.lo] Error 1
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src/fs'>
make[3]: *** [all-recursive] Error 1
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
make[2]: *** [all] Error 2
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/ws/btlayer-00-default/squid-4.0.0-BZR/_build'>
make: *** [distcheck] Error 1
buildtest.sh result is 2
BUILD: .././test-suite/buildtests/layer-00-default.opts
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
checking for egrep... ../configure: line 7071: echo: write error: Broken pipe
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockIoRequests.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockIoState.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockRebuild.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockStoreFileSystem.lo] Error 1
make[3]: *** [all-recursive] Error 1
make[2]: *** [all] Error 2
make[1]: *** [all-recursive] Error 1
make: *** [distcheck] Error 1
Build FAILED.
Build step 'Execute shell' marked build as failure
[description-setter] Description set: 

From rousskov at measurement-factory.com  Thu Jun 25 04:05:21 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 24 Jun 2015 22:05:21 -0600
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>
References: <558A466E.1060303@measurement-factory.com>
 <558A93DA.9080506@treenet.co.nz> <558B0F1A.90301@measurement-factory.com>
 <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>
Message-ID: <558B7E01.6020905@measurement-factory.com>

On 06/24/2015 02:24 PM, Kinkie wrote:
> My 2c: I vote for reality; possibly with a shaming announce message;

I would recommend against shaming any particular company unless somebody
can personally vouch that that specific company is the one to blame. I
cannot (without a lot more triage work which I have no time for).

The benefits of shaming in this case are tiny, but the danger of hurting
an innocent person (or even company) is always there.


> I wouldn't even recommend logging the violation: there is nothing the
> average admin can do about it.


An admin has reminded me privately that Squid already has a mechanism
that can be used here if somebody wants to enforce strict parsing [and
wants to see violations]:


> NAME: relaxed_header_parser
>     In the default "on" setting Squid accepts certain forms
>     of non-compliant HTTP messages where it is unambiguous
>     what the sending application intended

>     If set to "warn" then a warning will be emitted in cache.log
>     each time such HTTP error is encountered.

>     If set to "off" then such HTTP errors will cause the request
>     or response to be rejected.

The temporary fix can be enhanced to include all "unwise" URI characters
if (and only if) relaxed_header_parser is "on", and also to warn about
those characters when relaxed_header_parser is "warn".


HTH,

Alex.



> On Wed, Jun 24, 2015 at 10:12 PM, Alex Rousskov
> <rousskov at measurement-factory.com> wrote:
>> On 06/24/2015 05:26 AM, Amos Jeffries wrote:
>>
>>> On 24/06/2015 5:55 p.m., Alex Rousskov wrote:
>>>>     This temporary trunk fix adds support for request URIs containing
>>>> '|' characters. Such URIs are used by popular Amazon product (and
>>>> probably other) sites: /images/I/ID1._RC|ID2.js,ID3.js,ID4.js_.js
>>>>
>>>> Without this fix, all requests for affected URIs timeout while Squid
>>>> waits for the end of request headers it has already received(*).
>>
>>
>>> This is not right. Squid should be identifying the message as
>>> non-HTTP/1.x (which it isn't due to the URI syntax violation) and
>>> treating it as such.
>>
>> I agree that Amazon violates URI syntax. On the other hand, the message
>> can be interpreted as HTTP/1.x for all practical purposes AFAICT. If you
>> want to implement a different fix, please do so. Meanwhile, folks
>> suffering from this serious regression can try the temporary fix I posted.
>>
>>
>>>> The proper long-term fix is to allow any character in URI as long as we
>>>> can reliably parse the request line (and, later, URI components). There
>>>> is no point in hurting users by rejecting requests while slowly
>>>> accumulating the list of benign characters used by web sites but
>>>> prohibited by some RFC.
>>
>>> The *proper* long term fix is to obey the standards in regard to message
>>> syntax so applications stop using these invalid (when un-encoded)
>>> characters and claiming HTTP/1.1 support.
>>
>> We had "standards vs reality" and "policing traffic" discussions several
>> times in the past, with no signs of convergence towards a single
>> approach, so I am not going to revisit that discussion now. We continue
>> to disagree [while Squid users continue to suffer].
>>
>>
>> Thank you,
>>
>> Alex.
>>
>> _______________________________________________
>> squid-dev mailing list
>> squid-dev at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-dev
> 
> 
> 


From noc at squid-cache.org  Thu Jun 25 12:53:03 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Thu, 25 Jun 2015 12:53:03 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Jenkins_build_is_back_to_normal_=3A_trunk-m?=
 =?utf-8?q?atrix_=C2=BB_clang=2Cd-fedora-20_=23223?=
In-Reply-To: <2143713266.5.1435184999616.JavaMail.jenkins@buildmaster>
References: <2143713266.5.1435184999616.JavaMail.jenkins@buildmaster>
Message-ID: <732965105.9.1435236783320.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-fedora-20/223/>


From noc at squid-cache.org  Thu Jun 25 13:01:16 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Thu, 25 Jun 2015 13:01:16 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Jenkins_build_is_back_to_normal_=3A_trunk-m?=
 =?utf-8?q?atrix_=C2=BB_gcc=2Cd-centos-7_=23223?=
In-Reply-To: <926718221.2.1435184994649.JavaMail.jenkins@buildmaster>
References: <926718221.2.1435184994649.JavaMail.jenkins@buildmaster>
Message-ID: <1712579660.10.1435237276531.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-centos-7/223/>


From noc at squid-cache.org  Thu Jun 25 13:41:32 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Thu, 25 Jun 2015 13:41:32 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Build_failed_in_Jenkins=3A_trunk-matrix_?=
 =?utf-8?q?=C2=BB_clang=2Cd-debian-wheezy_=23223?=
In-Reply-To: <753519673.7.1435195852291.JavaMail.jenkins@buildmaster>
References: <753519673.7.1435195852291.JavaMail.jenkins@buildmaster>
Message-ID: <1052099521.11.1435239692738.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/223/>

------------------------------------------
[...truncated 4970 lines...]
            ^
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char> atomic_char;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<signed char> atomic_schar;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned char> atomic_uchar;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<short> atomic_short;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned short> atomic_ushort;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int> atomic_int;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned int> atomic_uint;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<long> atomic_long;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned long> atomic_ulong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<long long> atomic_llong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned long long> atomic_ullong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<wchar_t> atomic_wchar_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char16_t> atomic_char16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char32_t> atomic_char32_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char32_t> atomic_char32_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least8_t> atomic_int_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<uint_least8_t> atomic_uint_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least16_t> atomic_int_least16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
make[4]: *** [rock/RockRebuild.lo] Error 1
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src/fs'>
make[3]: *** [all-recursive] Error 1
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
make[2]: *** [all] Error 2
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-debian-wheezy/ws/btlayer-00-default/squid-4.0.0-BZR/_build'>
make: *** [distcheck] Error 1
buildtest.sh result is 2
BUILD: .././test-suite/buildtests/layer-00-default.opts
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockStoreFileSystem.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockIoRequests.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockIoState.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockRebuild.lo] Error 1
make[3]: *** [all-recursive] Error 1
make[2]: *** [all] Error 2
make[1]: *** [all-recursive] Error 1
make: *** [distcheck] Error 1
Build FAILED.
Build step 'Execute shell' marked build as failure
[description-setter] Description set: 

From noc at squid-cache.org  Thu Jun 25 13:45:21 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Thu, 25 Jun 2015 13:45:21 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Build_failed_in_Jenkins=3A_trunk-matrix_?=
 =?utf-8?q?=C2=BB_clang=2Cd-ubuntu-precise_=23223?=
In-Reply-To: <1492988014.6.1435192174664.JavaMail.jenkins@buildmaster>
References: <1492988014.6.1435192174664.JavaMail.jenkins@buildmaster>
Message-ID: <1123776463.12.1435239921628.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/223/>

------------------------------------------
[...truncated 4641 lines...]
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least8_t> atomic_int_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<uint_least8_t> atomic_uint_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least16_t> atomic_int_least16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
make[4]: *** [rock/RockIoState.lo] Error 1
make[4]: *** Waiting for unfinished jobs....
libtool: compile:  ccache clang++ -DHAVE_CONFIG_H -I../../.. -I../../../include -I../../../lib -I../../../src -I../../include -I../../../src/fs -Werror -Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2 -std=c++11 -MT rock/RockIoRequests.lo -MD -MP -MF rock/.deps/RockIoRequests.Tpo -c ../../../src/fs/rock/RockIoRequests.cc  -fPIC -DPIC -o rock/.libs/RockIoRequests.o
In file included from ../../../src/fs/rock/RockIoRequests.cc:1:
In file included from ../../../src/fs/rock/RockIoRequests.cc:12:
In file included from ../../../src/fs/rock/RockIoRequests.h:14:
In file included from ../../../src/fs/rock/RockIoState.h:12:
In file included from ../../../src/fs/rock/RockSwapDir.h:17:
In file included from ../../../src/ipc/mem/PageStack.h:14:
In file included from /usr/include/c++/4.6/atomic:40:
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
  inline namespace __atomic2 { }
                   ^
/usr/include/c++/4.6/bits/atomic_base.h:127:13: note: previous definition is here
  namespace __atomic2
            ^
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char> atomic_char;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<signed char> atomic_schar;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned char> atomic_uchar;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<short> atomic_short;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned short> atomic_ushort;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int> atomic_int;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned int> atomic_uint;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<long> atomic_long;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned long> atomic_ulong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<long long> atomic_llong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<unsigned long long> atomic_ullong;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<wchar_t> atomic_wchar_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char16_t> atomic_char16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char32_t> atomic_char32_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<char32_t> atomic_char32_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least8_t> atomic_int_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<uint_least8_t> atomic_uint_least8_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
  typedef __atomic_base<int_least16_t> atomic_int_least16_t;
          ^~~~~~~~~~~~~
          __atomic0::__atomic_base
/usr/include/c++/4.6/bits/atomic_base.h:124:14: note: '__atomic0::__atomic_base' declared here
      struct __atomic_base;
             ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
make[4]: *** [rock/RockIoRequests.lo] Error 1
make[4]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src/fs'>
make[3]: *** [all-recursive] Error 1
make[3]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
make[2]: *** [all] Error 2
make[2]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/ws/btlayer-00-default/squid-4.0.0-BZR/_build/src'>
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `<http://build.squid-cache.org/job/trunk-matrix/compiler=clang,label=d-ubuntu-precise/ws/btlayer-00-default/squid-4.0.0-BZR/_build'>
make: *** [distcheck] Error 1
buildtest.sh result is 2
BUILD: .././test-suite/buildtests/layer-00-default.opts
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm -lnsl -lresolv -lcap -lrt -ldl -ldl
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS: 
configure: BUILD EXTRA C FLAGS:  -Werror -Qunused-arguments  -D_REENTRANT
configure: BUILD C++ FLAGS: -g -O2 -std=c++11
configure: BUILD EXTRA C++ FLAGS:  -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
configure: BUILD Tools C++ FLAGS:  -g -O2 -std=c++11
checking for egrep... ../configure: line 7046: echo: write error: Broken pipe
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockIoState.lo] Error 1
/usr/include/c++/4.6/bits/atomic_base.h:163:20: error: non-inline namespace cannot be reopened as inline
/usr/include/c++/4.6/bits/atomic_base.h:167:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:170:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:173:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:176:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:179:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:182:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:185:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:188:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:191:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:194:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:197:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:200:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:203:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:206:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:209:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:213:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:216:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
/usr/include/c++/4.6/bits/atomic_base.h:219:11: error: no template named '__atomic_base'; did you mean '__atomic0::__atomic_base'?
fatal error: too many errors emitted, stopping now [-ferror-limit=]
make[4]: *** [rock/RockIoRequests.lo] Error 1
make[3]: *** [all-recursive] Error 1
make[2]: *** [all] Error 2
make[1]: *** [all-recursive] Error 1
make: *** [distcheck] Error 1
Build FAILED.
Build step 'Execute shell' marked build as failure
[description-setter] Description set: 

From squid3 at treenet.co.nz  Thu Jun 25 14:13:21 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 26 Jun 2015 02:13:21 +1200
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <558B7E01.6020905@measurement-factory.com>
References: <558A466E.1060303@measurement-factory.com>
 <558A93DA.9080506@treenet.co.nz> <558B0F1A.90301@measurement-factory.com>
 <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>
 <558B7E01.6020905@measurement-factory.com>
Message-ID: <558C0C81.6070509@treenet.co.nz>

On 25/06/2015 4:05 p.m., Alex Rousskov wrote:
> On 06/24/2015 02:24 PM, Kinkie wrote:
>> My 2c: I vote for reality; possibly with a shaming announce message;
> 
> I would recommend against shaming any particular company unless somebody
> can personally vouch that that specific company is the one to blame. I
> cannot (without a lot more triage work which I have no time for).
> 
> The benefits of shaming in this case are tiny, but the danger of hurting
> an innocent person (or even company) is always there.
> 

Indeed. Which is why I want to go the route of HTTP/0.9 handling. Its
clear when products encounter it and cause themselves problems. But we
dont need to name and shame any particular source.

pPS. in my testing the URIs you presented as reason for the patch were
accepted by Squid and handled as HTTP/0.9.


> 
>> I wouldn't even recommend logging the violation: there is nothing the
>> average admin can do about it.
> 
> 
> An admin has reminded me privately that Squid already has a mechanism
> that can be used here if somebody wants to enforce strict parsing [and
> wants to see violations]:
> 
> 
>> NAME: relaxed_header_parser
>>     In the default "on" setting Squid accepts certain forms
>>     of non-compliant HTTP messages where it is unambiguous
>>     what the sending application intended
> 
>>     If set to "warn" then a warning will be emitted in cache.log
>>     each time such HTTP error is encountered.
> 
>>     If set to "off" then such HTTP errors will cause the request
>>     or response to be rejected.
> 
> The temporary fix can be enhanced to include all "unwise" URI characters
> if (and only if) relaxed_header_parser is "on", and also to warn about
> those characters when relaxed_header_parser is "warn".
> 

That would be better than always doing it in the strict parsing pathway.
And is a useful temporary workaround for people having this issue you
found since related parse should be on by default IIRC.


>> On Wed, Jun 24, 2015 at 10:12 PM, Alex Rousskov wrote:
>>> On 06/24/2015 05:26 AM, Amos Jeffries wrote:
>>>
>>>> On 24/06/2015 5:55 p.m., Alex Rousskov wrote:
>>>>>     This temporary trunk fix adds support for request URIs containing
>>>>> '|' characters. Such URIs are used by popular Amazon product (and
>>>>> probably other) sites: /images/I/ID1._RC|ID2.js,ID3.js,ID4.js_.js
>>>>>
>>>>> Without this fix, all requests for affected URIs timeout while Squid
>>>>> waits for the end of request headers it has already received(*).
>>>
>>>
>>>> This is not right. Squid should be identifying the message as
>>>> non-HTTP/1.x (which it isn't due to the URI syntax violation) and
>>>> treating it as such.
>>>
>>> I agree that Amazon violates URI syntax. On the other hand, the message
>>> can be interpreted as HTTP/1.x for all practical purposes AFAICT. If you
>>> want to implement a different fix, please do so. Meanwhile, folks
>>> suffering from this serious regression can try the temporary fix I posted.

SMTP messages can be interpreted as HTTP/1.1 for all intents and
purposes as well. That does not make it a good idea to do so.

I don't care who it is sending the broken messages (AIUI, its not the
company anyway, its the particular UA software you found). They need to
stop getting away with it and the best incentive is bad behaviour
leading to bad performance. Loosing the benefits of HTTP/1.1 does that
cleanly.


NP: We have a track record of several vendors who fixed their products
after this type of bug was reported to them.  Was the '|' character
non-compliance bug reported against the product? They are probably able
to roll out the proper fix faster than we can anyway.


Anyhow. I've thrown the URI you mentioned through my test copy of trunk
and its not hanging looking for the end of mime headers like you said.
Its waiting for the end of the URI:
"
RequestParser.cc(390) parse: request-line: method: GET
RequestParser.cc(391) parse: request-line: url:
RequestParser.cc(392) parse: request-line: proto: NONE/0.0
RequestParser.cc(393) parse: Parser: bytes processed=4
SBuf.cc(149) assign: assigning SBuf1845 from SBuf1850
parseHttpRequest: Incomplete request, waiting for end of request line
"

Attached is a patch that replaces the hang behaviour with an
invalid-request error page on standards compliant builds. But, when
--enable-http-violations is used it accepts the invalid characters we
know are in use and passes the request through as HTTP/0.9.


>>>
>>>>> The proper long-term fix is to allow any character in URI as long as we
>>>>> can reliably parse the request line (and, later, URI components). There
>>>>> is no point in hurting users by rejecting requests while slowly
>>>>> accumulating the list of benign characters used by web sites but
>>>>> prohibited by some RFC.
>>>
>>>> The *proper* long term fix is to obey the standards in regard to message
>>>> syntax so applications stop using these invalid (when un-encoded)
>>>> characters and claiming HTTP/1.1 support.
>>>
>>> We had "standards vs reality" and "policing traffic" discussions several
>>> times in the past, with no signs of convergence towards a single
>>> approach, so I am not going to revisit that discussion now. We continue
>>> to disagree [while Squid users continue to suffer].

Yes. And things like <http://bugs.squid-cache.org/show_bug.cgi?id=4222>
are what happens if we accept that particular "reality". (We get screwed
both ways.)

Amos

-------------- next part --------------
=== modified file 'src/http/one/RequestParser.cc'
--- src/http/one/RequestParser.cc	2015-04-10 11:02:44 +0000
+++ src/http/one/RequestParser.cc	2015-06-25 13:01:39 +0000
@@ -244,40 +244,41 @@
  * \retval  0  more data is needed to complete the parse
  */
 int
 Http::One::RequestParser::parseRequestFirstLine()
 {
     Http1::Tokenizer tok(buf_);
 
     debugs(74, 5, "parsing possible request: buf.length=" << buf_.length());
     debugs(74, DBG_DATA, buf_);
 
     // NP: would be static, except it need to change with reconfigure
     CharacterSet WspDelim = CharacterSet::SP; // strict parse only accepts SP
 
     if (Config.onoff.relaxed_header_parser) {
         // RFC 7230 section 3.5
         // tolerant parser MAY accept any of SP, HTAB, VT (%x0B), FF (%x0C), or bare CR
         // as whitespace between request-line fields
         WspDelim += CharacterSet::HTAB
                     + CharacterSet("VT,FF","\x0B\x0C")
                     + CharacterSet::CR;
+        debugs(74, 5, "using Parser relaxed WSP characters");
     }
 
     // only search for method if we have not yet found one
     if (method_ == Http::METHOD_NONE) {
         const int res = parseMethodField(tok, WspDelim);
         if (res < 1)
             return res;
         // else keep going...
     }
 
     // tolerant parser allows multiple whitespace characters between request-line fields
     if (Config.onoff.relaxed_header_parser) {
         const size_t garbage = tok.skipAll(WspDelim);
         if (garbage > 0) {
             firstLineGarbage_ += garbage;
             buf_ = tok.remaining(); // re-checkpoint after garbage
         }
     }
     if (tok.atEnd()) {
         debugs(74, 5, "Parser needs more data");
@@ -313,40 +314,72 @@
                 parseStatusCode = Http::scOkay;
                 buf_ = tok.remaining(); // incremental parse checkpoint
                 return 1;
 
             } else if (method_ == Http::METHOD_GET) {
                 // RFC 1945 - for GET the line terminator may follow URL instead of a delimiter
                 debugs(33, 5, "HTTP/0.9 syntax request-line detected");
                 msgProtocol_ = Http::ProtocolVersion(0,9);
                 static const SBuf cr("\r",1);
                 uri_ = line.trim(cr,false,true);
                 parseStatusCode = Http::scOkay;
                 buf_ = tok.remaining(); // incremental parse checkpoint
                 return 1;
             }
 
             debugs(33, 5, "invalid request-line. not HTTP");
             parseStatusCode = Http::scBadRequest;
             return -1;
         }
 
+        if (!tok.atEnd()) {
+#if USE_HTTP_VIOLATIONS
+            // invalid character somewhere in the line.
+            // As long as we can find the LF, accept the characters
+            // which we know are invalid in any URI, but actively used
+            LfDelim.add('\0'); // Java
+            LfDelim.add(' ');  // IIS
+            LfDelim.add('\"'); // Bing
+            LfDelim.add('\\'); // MSIE, Firefox
+            LfDelim.add('|');  // Amazon
+
+            // reset the tokenizer from anything the above did, then seek the LF character.
+            tok.reset(buf_);
+            if (tok.prefix(line, LfDelim) && tok.skip('\n')) {
+                msgProtocol_ = Http::ProtocolVersion(0,9);
+                static const SBuf cr("\r",1);
+                uri_ = line.trim(cr,false,true);
+                parseStatusCode = Http::scOkay;
+                buf_ = tok.remaining(); // incremental parse checkpoint
+                return 1;
+
+            } else if (tok.atEnd()) {
+                debugs(74, 5, "Parser needs more data");
+                return 0;
+            }
+            // else, drop back to invalid request-line handling
+#endif
+            const SBuf t = tok.remaining();
+            debugs(33, 5, "invalid request-line characters." << Raw("data", t.rawContent(), t.length()));
+            parseStatusCode = Http::scBadRequest;
+            return -1;
+        }
         debugs(74, 5, "Parser needs more data");
         return 0;
     }
     // else strict non-whitespace tolerant parse
 
     // only search for request-target (URL) if we have not yet found one
     if (uri_.isEmpty()) {
         const int res = parseUriField(tok);
         if (res < 1 || msgProtocol_.protocol == AnyP::PROTO_HTTP)
             return res;
         // else keep going...
     }
 
     if (tok.atEnd()) {
         debugs(74, 5, "Parser needs more data");
         return 0;
     }
 
     // HTTP/1 version suffix (protocol magic) followed by CR*LF
     if (msgProtocol_.protocol == AnyP::PROTO_NONE) {


From noc at squid-cache.org  Thu Jun 25 14:54:20 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Thu, 25 Jun 2015 14:54:20 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Jenkins_build_is_back_to_normal_=3A_trunk-m?=
 =?utf-8?q?atrix_=C2=BB_gcc=2Cd-fedora-21_=23223?=
In-Reply-To: <693857794.3.1435184996614.JavaMail.jenkins@buildmaster>
References: <693857794.3.1435184996614.JavaMail.jenkins@buildmaster>
Message-ID: <61582488.13.1435244060233.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-fedora-21/223/>


From noc at squid-cache.org  Thu Jun 25 14:57:41 2015
From: noc at squid-cache.org (noc at squid-cache.org)
Date: Thu, 25 Jun 2015 14:57:41 +0000 (UTC)
Subject: [squid-dev] =?utf-8?q?Jenkins_build_is_back_to_normal_=3A_trunk-m?=
 =?utf-8?q?atrix_=C2=BB_gcc=2Cd-ubuntu-utopic_=23223?=
In-Reply-To: <400685458.4.1435184997343.JavaMail.jenkins@buildmaster>
References: <400685458.4.1435184997343.JavaMail.jenkins@buildmaster>
Message-ID: <555415864.14.1435244261362.JavaMail.jenkins@buildmaster>

See <http://build.squid-cache.org/job/trunk-matrix/compiler=gcc,label=d-ubuntu-utopic/223/>


From eliezer at ngtech.co.il  Thu Jun 25 15:33:15 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 25 Jun 2015 18:33:15 +0300
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <558A466E.1060303@measurement-factory.com>
References: <558A466E.1060303@measurement-factory.com>
Message-ID: <558C1F3B.9050105@ngtech.co.il>

About the shaming idea:
I do not like in any way and time to write bad things on anyone.
To make sure there is a bug and to make sure where the bug is from I 
would try to first understand the bug and maybe someone would be able to 
make this world a better place for programs and programmeres.

I will not run to triage this issue for now but the last idea of amos 
seems to me pretty reasonable(reading the description and not the code).

Eliezer

On 24/06/2015 08:55, Alex Rousskov wrote:
> Hello,
>
>      This temporary trunk fix adds support for request URIs containing
> '|' characters. Such URIs are used by popular Amazon product (and
> probably other) sites: /images/I/ID1._RC|ID2.js,ID3.js,ID4.js_.js
>
> Without this fix, all requests for affected URIs timeout while Squid
> waits for the end of request headers it has already received(*).
>
>
> The proper long-term fix is to allow any character in URI as long as we
> can reliably parse the request line (and, later, URI components). There
> is no point in hurting users by rejecting requests while slowly
> accumulating the list of benign characters used by web sites but
> prohibited by some RFC.
>
>
> HTH,
>
> Alex.
> P.S. (*) which is probably another parsing regression bug (not addressed
> by this temporary patch or the long-term fix discussed above), but I
> have not tested whether the very latest trunk still suffers from this
> other bug.
>
>
>
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev
>



From gkinkie at gmail.com  Thu Jun 25 17:36:43 2015
From: gkinkie at gmail.com (Kinkie)
Date: Thu, 25 Jun 2015 19:36:43 +0200
Subject: [squid-dev] Deprecating debian wheezy and ubuntu precise for trunk?
Message-ID: <CA+Y8hcNMTEqQS1rB0rjWfG0yD_U9uV5iZao2FFzscX-Uv8EJcA@mail.gmail.com>

Hi,
  judging from the latest builds (jenkins was stuck for a while) it seems
that there's serious issues with std::atomic in libc++-6.4 with clang.

Any objections to deprecating these OS/compiler combinations for trunk? gcc
works fine.

-- 
    Kinkie
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150625/873386a7/attachment.html>

From rousskov at measurement-factory.com  Thu Jun 25 19:55:53 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 25 Jun 2015 13:55:53 -0600
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <558C0C81.6070509@treenet.co.nz>
References: <558A466E.1060303@measurement-factory.com>
 <558A93DA.9080506@treenet.co.nz> <558B0F1A.90301@measurement-factory.com>
 <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>
 <558B7E01.6020905@measurement-factory.com> <558C0C81.6070509@treenet.co.nz>
Message-ID: <558C5CC9.2070306@measurement-factory.com>

On 06/25/2015 08:13 AM, Amos Jeffries wrote:
> Which is why I want to go the route of HTTP/0.9 handling. Its
> clear when products encounter it and cause themselves problems.

Sigh. You are repeating essentially the same argument as before. Any
"let's create problems for something that appears to work without Squid"
approach often results in *us* wasting time on workarounds for those
problems.

You may be convinced that creating short-term problems for others will
make the world a better place long-term, but there is no way to prove or
disprove that assumption, and there is no objective way to even compare
the possible long-term gain with the likely short-term pain (especially
when it is somebody else who is hurting).

The history is full of examples where the "future happiness justifies
short-term suffering" approach either works great or fails miserably. I
doubt we can come up with a formula that predicts the outcome.


> Was the '|' character
> non-compliance bug reported against the product?

Unknown to me, but I suspect folks suffering from this do not report
bugs to companies they have no relationship with (and may not even know
what the "product" is!).


> Anyhow. I've thrown the URI you mentioned through my test copy of trunk
> and its not hanging looking for the end of mime headers like you said.
> Its waiting for the end of the URI:

> parseHttpRequest: Incomplete request, waiting for end of request line

Please forgive me for misinterpreting the Squid log line that lies about
an "Incomplete request" and "waiting for end of request line".

If you prefer the "waiting for the end of the URI" description of the
broken state (where the complete URI, the complete request line, and the
complete request are all available), I am not going to argue that it is
also inaccurate.


> Attached is a patch that replaces the hang behaviour with an
> invalid-request error page on standards compliant builds. But, when
> --enable-http-violations is used it accepts the invalid characters we
> know are in use and passes the request through as HTTP/0.9.


... which does not work because the request does not actually use the
HTTP/0.9 format. You end up with:


> Forwarding client request ... url=http://localhost:8080/path|with|unwise|charactersHTTP/1.1

> GET /path|with|unwise|charactersHTTP/1.1 HTTP/1.1
> Via: 0.9 protofroot (squid/4.0.0-BZR)


The trailing " HTTP/1.1" part of the request line is not a part of the
URI but your changes make it so.

Tokenizer cannot handle URIs with whitespaces directly, like your patch
attempts to do: Tokenizer alone cannot handle ambiguous grammars. To
handle such URIs well, you have two options IMO:

A. The old "do it by hand" way:

  0. Trim request line to remove trailing whitespace and CR*LF.
  1. Find the *last* whitespace on the trimmed request line.
  2. To get the request method and URI, apply the tokenizer to the
     request line prefix before that last whitespace.
  3. To get the protocol parts, apply the tokenizer to the
     request line suffix after that last whitespace.
  4. Make the code even messier to handle HTTP/0.9 cases if needed.


B. The new optimized and simplified "optimistic Tokenizer" way:

Here is a sketch:

    SBuf uri; // accumulates request URI characters
    if (!tok.prefix(uri, StrictUriChars))
        return false; // URI does not start with a valid character

    // in the order of correctness (and popularity!):
    const bool parsedSuffix =
        // canonical HTTP/1 format
        parseCanonicalReqLineTail(uri, tok) ||
        // HTTP/1 format but with bad characters in URI
        parseBadUriReqLineTail(uri, tok) ||
        // HTTP/1 format but with bad characters and spaces in URI
        parseSpacedReqLineTail(uri, tok) ||
        // HTTP/0 format (without the protocol part at all)
        parseHttpZeroReqLineTail(uri, tok);

    Assert(parsedSuffix); // parseHttpZeroReqLineTail() cannot fail
    ...

where, for example, parseCanonicalReqLineTail() expects whitespace
followed by protocol info while parseBadUriReqLineTail() expects a URI
suffix (using RelaxedUriChars which do not include whitepsace) followed
by a call to parseCanonicalReqLineTail().

If any of the helper functions returns false, it should not change its
uri and tok parameters, of course.


HTH,

Alex.


From squid3 at treenet.co.nz  Fri Jun 26 05:31:07 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 26 Jun 2015 17:31:07 +1200
Subject: [squid-dev] Deprecating debian wheezy and ubuntu precise for
 trunk?
In-Reply-To: <CA+Y8hcNMTEqQS1rB0rjWfG0yD_U9uV5iZao2FFzscX-Uv8EJcA@mail.gmail.com>
References: <CA+Y8hcNMTEqQS1rB0rjWfG0yD_U9uV5iZao2FFzscX-Uv8EJcA@mail.gmail.com>
Message-ID: <558CE39B.9050107@treenet.co.nz>

On 26/06/2015 5:36 a.m., Kinkie wrote:
> Hi,
>   judging from the latest builds (jenkins was stuck for a while) it seems
> that there's serious issues with std::atomic in libc++-6.4 with clang.
> 
> Any objections to deprecating these OS/compiler combinations for trunk? gcc
> works fine.
> 

None, here. Though we need to keep GCC going for a while longer for them.

Amos

From squid3 at treenet.co.nz  Fri Jun 26 12:44:49 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 Jun 2015 00:44:49 +1200
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <558C5CC9.2070306@measurement-factory.com>
References: <558A466E.1060303@measurement-factory.com>
 <558A93DA.9080506@treenet.co.nz> <558B0F1A.90301@measurement-factory.com>
 <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>
 <558B7E01.6020905@measurement-factory.com> <558C0C81.6070509@treenet.co.nz>
 <558C5CC9.2070306@measurement-factory.com>
Message-ID: <558D4941.7060604@treenet.co.nz>

On 26/06/2015 7:55 a.m., Alex Rousskov wrote:
> On 06/25/2015 08:13 AM, Amos Jeffries wrote:
>> Which is why I want to go the route of HTTP/0.9 handling. Its
>> clear when products encounter it and cause themselves problems.
> 
> Sigh. You are repeating essentially the same argument as before. Any
> "let's create problems for something that appears to work without Squid"
> approach often results in *us* wasting time on workarounds for those
> problems.
> 
> You may be convinced that creating short-term problems for others will
> make the world a better place long-term, but there is no way to prove or
> disprove that assumption, and there is no objective way to even compare
> the possible long-term gain with the likely short-term pain (especially
> when it is somebody else who is hurting).
> 
> The history is full of examples where the "future happiness justifies
> short-term suffering" approach either works great or fails miserably. I
> doubt we can come up with a formula that predicts the outcome.
> 
> 
>> Was the '|' character
>> non-compliance bug reported against the product?
> 
> Unknown to me, but I suspect folks suffering from this do not report
> bugs to companies they have no relationship with (and may not even know
> what the "product" is!).
> 
> 
>> Anyhow. I've thrown the URI you mentioned through my test copy of trunk
>> and its not hanging looking for the end of mime headers like you said.
>> Its waiting for the end of the URI:
> 
>> parseHttpRequest: Incomplete request, waiting for end of request line
> 
> Please forgive me for misinterpreting the Squid log line that lies about
> an "Incomplete request" and "waiting for end of request line".

No lie there. It hasn't got near starting to search for URL yet. When
relaxed parser is enabled (ie by default) it has to find the end of the
request-line first and work backwards. It found characters that are
invalid anywhere in the HTTP first-line / request-line before it found
the LF. It just happens that they are in the URI portion of the
request-line.
 It would report the same thing on receiving "GET / HTTP/1.0|\r\n"

> 
> If you prefer the "waiting for the end of the URI" description of the
> broken state (where the complete URI, the complete request line, and the
> complete request are all available), I am not going to argue that it is
> also inaccurate.
> 
> 
>> Attached is a patch that replaces the hang behaviour with an
>> invalid-request error page on standards compliant builds. But, when
>> --enable-http-violations is used it accepts the invalid characters we
>> know are in use and passes the request through as HTTP/0.9.
> 
> 
> ... which does not work because the request does not actually use the
> HTTP/0.9 format. You end up with:
> 
> 
>> Forwarding client request ... url=http://localhost:8080/path|with|unwise|charactersHTTP/1.1
> 
>> GET /path|with|unwise|charactersHTTP/1.1 HTTP/1.1
>> Via: 0.9 protofroot (squid/4.0.0-BZR)
> 
> 
> The trailing " HTTP/1.1" part of the request line is not a part of the
> URI but your changes make it so.

Sorry. Attached is a patch which fixes that and resolves accel/intercept
issues with the mime block as well.



> 
> Tokenizer cannot handle URIs with whitespaces directly, like your patch
> attempts to do: Tokenizer alone cannot handle ambiguous grammars. To
> handle such URIs well, you have two options IMO:
> 
> A. The old "do it by hand" way:
> 
>   0. Trim request line to remove trailing whitespace and CR*LF.
>   1. Find the *last* whitespace on the trimmed request line.
>   2. To get the request method and URI, apply the tokenizer to the
>      request line prefix before that last whitespace.
>   3. To get the protocol parts, apply the tokenizer to the
>      request line suffix after that last whitespace.
>   4. Make the code even messier to handle HTTP/0.9 cases if needed.
> 
> 
> B. The new optimized and simplified "optimistic Tokenizer" way:
> 
> Here is a sketch:
> 
>     SBuf uri; // accumulates request URI characters
>     if (!tok.prefix(uri, StrictUriChars))
>         return false; // URI does not start with a valid character
> 
>     // in the order of correctness (and popularity!):
>     const bool parsedSuffix =
>         // canonical HTTP/1 format
>         parseCanonicalReqLineTail(uri, tok) ||
>         // HTTP/1 format but with bad characters in URI
>         parseBadUriReqLineTail(uri, tok) ||
>         // HTTP/1 format but with bad characters and spaces in URI
>         parseSpacedReqLineTail(uri, tok) ||
>         // HTTP/0 format (without the protocol part at all)
>         parseHttpZeroReqLineTail(uri, tok);
> 
>     Assert(parsedSuffix); // parseHttpZeroReqLineTail() cannot fail
>     ...

C. locate LF character and parse in reverse. HTTP-Version label, WSP
then remainder is URI.


(B) is Interesting alternative to what we have now (C). Although you are
missing the relaxed vs strict characters which the RFC mandates (for
both URI and whitspace separately permutating). That complicates things
a bit.

If I can find some time I'll give this (B) style a bit of testing and
see how it matches up against the current code. Could prove faster on
very long URIs.

Amos
-------------- next part --------------
=== modified file 'src/http/one/Parser.cc'
--- src/http/one/Parser.cc	2015-04-10 11:02:44 +0000
+++ src/http/one/Parser.cc	2015-06-26 12:15:52 +0000
@@ -26,41 +26,42 @@
 }
 
 bool
 Http::One::Parser::skipLineTerminator(Http1::Tokenizer &tok) const
 {
     static const SBuf crlf("\r\n");
     if (tok.skip(crlf))
         return true;
 
     if (Config.onoff.relaxed_header_parser && tok.skipOne(CharacterSet::LF))
         return true;
 
     return false;
 }
 
 bool
 Http::One::Parser::grabMimeBlock(const char *which, const size_t limit)
 {
     // MIME headers block exist in (only) HTTP/1.x and ICY
     const bool expectMime = (msgProtocol_.protocol == AnyP::PROTO_HTTP && msgProtocol_.major == 1) ||
-                            msgProtocol_.protocol == AnyP::PROTO_ICY;
+                            msgProtocol_.protocol == AnyP::PROTO_ICY ||
+                            hackExpectsMime_;
 
     if (expectMime) {
         /* NOTE: HTTP/0.9 messages do not have a mime header block.
          *       So the rest of the code will need to deal with '0'-byte headers
          *       (ie, none, so don't try parsing em)
          */
         // XXX: c_str() reallocates. performance regression.
         if (SBuf::size_type mimeHeaderBytes = headersEnd(buf_.c_str(), buf_.length())) {
 
             // Squid could handle these headers, but admin does not want to
             if (firstLineSize() + mimeHeaderBytes >= limit) {
                 debugs(33, 5, "Too large " << which);
                 parseStatusCode = Http::scHeaderTooLarge;
                 buf_.consume(mimeHeaderBytes);
                 parsingStage_ = HTTP_PARSE_DONE;
                 return false;
             }
 
             mimeHeaderBlock_ = buf_.consume(mimeHeaderBytes);
             debugs(74, 5, "mime header (0-" << mimeHeaderBytes << ") {" << mimeHeaderBlock_ << "}");

=== modified file 'src/http/one/Parser.h'
--- src/http/one/Parser.h	2015-06-09 01:59:58 +0000
+++ src/http/one/Parser.h	2015-06-26 12:02:35 +0000
@@ -24,41 +24,41 @@
     HTTP_PARSE_CHUNK_SZ,  ///< HTTP/1.1 chunked encoding chunk-size
     HTTP_PARSE_CHUNK_EXT, ///< HTTP/1.1 chunked encoding chunk-ext
     HTTP_PARSE_CHUNK,     ///< HTTP/1.1 chunked encoding chunk-data
     HTTP_PARSE_MIME,      ///< HTTP/1 mime-header block
     HTTP_PARSE_DONE       ///< parsed a message header, or reached a terminal syntax error
 };
 
 /** HTTP/1.x protocol parser
  *
  * Works on a raw character I/O buffer and tokenizes the content into
  * the major CRLF delimited segments of an HTTP/1 procotol message:
  *
  * \item first-line (request-line / simple-request / status-line)
  * \item mime-header 0*( header-name ':' SP field-value CRLF)
  */
 class Parser : public RefCountable
 {
 public:
     typedef SBuf::size_type size_type;
 
-    Parser() : parseStatusCode(Http::scNone), parsingStage_(HTTP_PARSE_NONE) {}
+    Parser() : parseStatusCode(Http::scNone), parsingStage_(HTTP_PARSE_NONE), hackExpectsMime_(false) {}
     virtual ~Parser() {}
 
     /// Set this parser back to a default state.
     /// Will DROP any reference to a buffer (does not free).
     virtual void clear() = 0;
 
     /// attempt to parse a message from the buffer
     /// \retval true if a full message was found and parsed
     /// \retval false if incomplete, invalid or no message was found
     virtual bool parse(const SBuf &aBuf) = 0;
 
     /** Whether the parser is waiting on more data to complete parsing a message.
      * Use to distinguish between incomplete data and error results
      * when parse() returns false.
      */
     bool needsMoreData() const {return parsingStage_!=HTTP_PARSE_DONE;}
 
     /// size in bytes of the first line including CRLF terminator
     virtual size_type firstLineSize() const = 0;
 
@@ -114,27 +114,30 @@
      *                mimeHeaderBlock_ has been updated and buf_ consumed.
      *
      * \retval false  An error occured, or no mime terminator found within limit.
      */
     bool grabMimeBlock(const char *which, const size_t limit);
 
     /// RFC 7230 section 2.6 - 7 magic octets
     static const SBuf Http1magic;
 
     /// bytes remaining to be parsed
     SBuf buf_;
 
     /// what stage the parser is currently up to
     ParseState parsingStage_;
 
     /// what protocol label has been found in the first line (if any)
     AnyP::ProtocolVersion msgProtocol_;
 
     /// buffer holding the mime headers (if any)
     SBuf mimeHeaderBlock_;
+
+    /// Whether the invalid HTTP as HTTP/0.9 hack expects a mime header block
+    bool hackExpectsMime_;
 };
 
 } // namespace One
 } // namespace Http
 
 #endif /*  _SQUID_SRC_HTTP_ONE_PARSER_H */
 

=== modified file 'src/http/one/RequestParser.cc'
--- src/http/one/RequestParser.cc	2015-04-10 11:02:44 +0000
+++ src/http/one/RequestParser.cc	2015-06-26 12:02:28 +0000
@@ -244,109 +244,166 @@
  * \retval  0  more data is needed to complete the parse
  */
 int
 Http::One::RequestParser::parseRequestFirstLine()
 {
     Http1::Tokenizer tok(buf_);
 
     debugs(74, 5, "parsing possible request: buf.length=" << buf_.length());
     debugs(74, DBG_DATA, buf_);
 
     // NP: would be static, except it need to change with reconfigure
     CharacterSet WspDelim = CharacterSet::SP; // strict parse only accepts SP
 
     if (Config.onoff.relaxed_header_parser) {
         // RFC 7230 section 3.5
         // tolerant parser MAY accept any of SP, HTAB, VT (%x0B), FF (%x0C), or bare CR
         // as whitespace between request-line fields
         WspDelim += CharacterSet::HTAB
                     + CharacterSet("VT,FF","\x0B\x0C")
                     + CharacterSet::CR;
+        debugs(74, 5, "using Parser relaxed WSP characters");
     }
 
     // only search for method if we have not yet found one
     if (method_ == Http::METHOD_NONE) {
         const int res = parseMethodField(tok, WspDelim);
         if (res < 1)
             return res;
         // else keep going...
     }
 
     // tolerant parser allows multiple whitespace characters between request-line fields
     if (Config.onoff.relaxed_header_parser) {
         const size_t garbage = tok.skipAll(WspDelim);
         if (garbage > 0) {
             firstLineGarbage_ += garbage;
             buf_ = tok.remaining(); // re-checkpoint after garbage
         }
     }
     if (tok.atEnd()) {
         debugs(74, 5, "Parser needs more data");
         return 0;
     }
 
     // from here on, we have two possible parse paths: whitespace tolerant, and strict
     if (Config.onoff.relaxed_header_parser) {
         // whitespace tolerant
 
+        int warnOnError = (Config.onoff.relaxed_header_parser <= 0 ? DBG_IMPORTANT : 2);
+
         // NOTES:
         // * this would be static, except WspDelim changes with reconfigure
         // * HTTP-version charset is included by uriValidCharacters()
         // * terminal CR is included by WspDelim here in relaxed parsing
         CharacterSet LfDelim = uriValidCharacters() + WspDelim;
 
         // seek the LF character, then tokenize the line in reverse
         SBuf line;
         if (tok.prefix(line, LfDelim) && tok.skip('\n')) {
             Http1::Tokenizer rTok(line);
             SBuf nil;
             (void)rTok.suffix(nil,CharacterSet::CR); // optional CR in terminator
             SBuf digit;
             if (rTok.suffix(digit,CharacterSet::DIGIT) && rTok.skipSuffix(Http1magic) && rTok.suffix(nil,WspDelim)) {
                 uri_ = rTok.remaining();
                 msgProtocol_ = Http::ProtocolVersion(1, (*digit.rawContent() - '0'));
                 if (uri_.isEmpty()) {
-                    debugs(33, 5, "invalid request-line. missing URL");
+                    debugs(33, warnOnError, "invalid request-line. missing URL");
                     parseStatusCode = Http::scBadRequest;
                     return -1;
                 }
 
                 parseStatusCode = Http::scOkay;
                 buf_ = tok.remaining(); // incremental parse checkpoint
                 return 1;
 
             } else if (method_ == Http::METHOD_GET) {
                 // RFC 1945 - for GET the line terminator may follow URL instead of a delimiter
                 debugs(33, 5, "HTTP/0.9 syntax request-line detected");
                 msgProtocol_ = Http::ProtocolVersion(0,9);
                 static const SBuf cr("\r",1);
                 uri_ = line.trim(cr,false,true);
                 parseStatusCode = Http::scOkay;
                 buf_ = tok.remaining(); // incremental parse checkpoint
                 return 1;
             }
 
-            debugs(33, 5, "invalid request-line. not HTTP");
+            debugs(33, warnOnError, "invalid request-line. not HTTP");
             parseStatusCode = Http::scBadRequest;
             return -1;
         }
 
+        if (!tok.atEnd()) {
+
+#if USE_HTTP_VIOLATIONS
+            // invalid character somewhere in the line.
+            // As long as we can find the LF, accept the characters
+            // which we know are invalid in any URI, but actively used
+            LfDelim.add('\0'); // Java
+            LfDelim.add(' ');  // IIS
+            LfDelim.add('\"'); // Bing
+            LfDelim.add('\\'); // MSIE, Firefox
+            LfDelim.add('|');  // Amazon
+
+            // reset the tokenizer from anything the above did, then seek the LF character.
+            tok.reset(buf_);
+
+            if (tok.prefix(line, LfDelim) && tok.skip('\n')) {
+
+                Http1::Tokenizer rTok(line);
+
+                // strip terminating CR (if any)
+                SBuf nil;
+                (void)rTok.suffix(nil,CharacterSet::CR); // optional CR in terminator
+                line = rTok.remaining();
+
+                // strip terminating 'WSP HTTP-version' (if any)
+                if (rTok.suffix(nil,CharacterSet::DIGIT) && rTok.skipSuffix(Http1magic) && rTok.suffix(nil,WspDelim)) {
+                    hackExpectsMime_ = true; // client thinks its speaking HTTP, probably sent a mime block.
+                    uri_ = rTok.remaining();
+                } else
+                    uri_ = line; // no HTTP/1.x label found. Use the whole line.
+
+                if (uri_.isEmpty()) {
+                    debugs(33, warnOnError, "invalid request-line. missing URL");
+                    parseStatusCode = Http::scBadRequest;
+                    return -1;
+                }
+
+                debugs(33, warnOnError, "invalid request-line. treating as HTTP/0.9" << (hackExpectsMime_?" (with mime)":""));
+                msgProtocol_ = Http::ProtocolVersion(0,9);
+                parseStatusCode = Http::scOkay;
+                buf_ = tok.remaining(); // incremental parse checkpoint
+                return 1;
+
+            } else if (tok.atEnd()) {
+                debugs(74, 5, "Parser needs more data");
+                return 0;
+            }
+            // else, drop back to invalid request-line handling
+#endif
+            const SBuf t = tok.remaining();
+            debugs(33, warnOnError, "invalid request-line characters." << Raw("data", t.rawContent(), t.length()));
+            parseStatusCode = Http::scBadRequest;
+            return -1;
+        }
         debugs(74, 5, "Parser needs more data");
         return 0;
     }
     // else strict non-whitespace tolerant parse
 
     // only search for request-target (URL) if we have not yet found one
     if (uri_.isEmpty()) {
         const int res = parseUriField(tok);
         if (res < 1 || msgProtocol_.protocol == AnyP::PROTO_HTTP)
             return res;
         // else keep going...
     }
 
     if (tok.atEnd()) {
         debugs(74, 5, "Parser needs more data");
         return 0;
     }
 
     // HTTP/1 version suffix (protocol magic) followed by CR*LF
     if (msgProtocol_.protocol == AnyP::PROTO_NONE) {


From gkinkie at gmail.com  Fri Jun 26 13:15:00 2015
From: gkinkie at gmail.com (Kinkie)
Date: Fri, 26 Jun 2015 15:15:00 +0200
Subject: [squid-dev] Deprecating debian wheezy and ubuntu precise for
	trunk?
In-Reply-To: <558CE39B.9050107@treenet.co.nz>
References: <CA+Y8hcNMTEqQS1rB0rjWfG0yD_U9uV5iZao2FFzscX-Uv8EJcA@mail.gmail.com>
 <558CE39B.9050107@treenet.co.nz>
Message-ID: <CA+Y8hcNZ0wKvzxEo1L_yiC6dvNSqbj-GTfE0WhW=EYCF1Pv1SQ@mail.gmail.com>

Sure.
Changed the trunk matrix build to match.
I've also changed the website-tarballs-latest and website-tarballs-head
jobs so that they are triggered by a successful matrix build instead of
autonomously polling (and possibly failing the build). Please let me know
if you wish me to revert this.

On Fri, Jun 26, 2015 at 7:31 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 26/06/2015 5:36 a.m., Kinkie wrote:
> > Hi,
> >   judging from the latest builds (jenkins was stuck for a while) it seems
> > that there's serious issues with std::atomic in libc++-6.4 with clang.
> >
> > Any objections to deprecating these OS/compiler combinations for trunk?
> gcc
> > works fine.
> >
>
> None, here. Though we need to keep GCC going for a while longer for them.
>
> Amos
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev
>



-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150626/06eb7a47/attachment.html>

From rousskov at measurement-factory.com  Fri Jun 26 15:40:48 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 Jun 2015 09:40:48 -0600
Subject: [squid-dev] [PATCH] Temporary fix to restore compatibility with
 Amazon
In-Reply-To: <558D4941.7060604@treenet.co.nz>
References: <558A466E.1060303@measurement-factory.com>
 <558A93DA.9080506@treenet.co.nz> <558B0F1A.90301@measurement-factory.com>
 <CA+Y8hcPt4q0EC4a+mqG1u+id=ncB7oihDZ9iLjs=r9_G=eVFgg@mail.gmail.com>
 <558B7E01.6020905@measurement-factory.com> <558C0C81.6070509@treenet.co.nz>
 <558C5CC9.2070306@measurement-factory.com> <558D4941.7060604@treenet.co.nz>
Message-ID: <558D7280.1080707@measurement-factory.com>

On 06/26/2015 06:44 AM, Amos Jeffries wrote:
> On 26/06/2015 7:55 a.m., Alex Rousskov wrote:
>> Tokenizer cannot handle URIs with whitespaces directly, like your patch
>> attempts to do: Tokenizer alone cannot handle ambiguous grammars. To
>> handle such URIs well, you have two options IMO:
>>
>> A. The old "do it by hand" way:
>>
>>   0. Trim request line to remove trailing whitespace and CR*LF.
>>   1. Find the *last* whitespace on the trimmed request line.
>>   2. To get the request method and URI, apply the tokenizer to the
>>      request line prefix before that last whitespace.
>>   3. To get the protocol parts, apply the tokenizer to the
>>      request line suffix after that last whitespace.
>>   4. Make the code even messier to handle HTTP/0.9 cases if needed.
>>
>>
>> B. The new optimized and simplified "optimistic Tokenizer" way:
>>
>> Here is a sketch:
>>
>>     SBuf uri; // accumulates request URI characters
>>     if (!tok.prefix(uri, StrictUriChars))
>>         return false; // URI does not start with a valid character
>>
>>     // in the order of correctness (and popularity!):
>>     const bool parsedSuffix =
>>         // canonical HTTP/1 format
>>         parseCanonicalReqLineTail(uri, tok) ||
>>         // HTTP/1 format but with bad characters in URI
>>         parseBadUriReqLineTail(uri, tok) ||
>>         // HTTP/1 format but with bad characters and spaces in URI
>>         parseSpacedReqLineTail(uri, tok) ||
>>         // HTTP/0 format (without the protocol part at all)
>>         parseHttpZeroReqLineTail(uri, tok);
>>
>>     Assert(parsedSuffix); // parseHttpZeroReqLineTail() cannot fail
>>     ...


> C. locate LF character and parse in reverse. HTTP-Version label, WSP
> then remainder is URI.

Yes, this is a better variant of option A, using Tokenizer::suffix(); I
missed that method. It is still manual labor to accommodate rare special
cases while complicating and slowing down parsing of the common case.



> (B) is Interesting alternative to what we have now (C). Although you are
> missing the relaxed vs strict characters which the RFC mandates (for
> both URI and whitspace separately permutating). That complicates things
> a bit.

I do not see where design B is missing something. Obviously(?), if there
are more special cases than the sketch shows, they should be added. I
was just illustrating the approach. The actual implementation should be
different.


> If I can find some time I'll give this (B) style a bit of testing and
> see how it matches up against the current code. Could prove faster on
> very long URIs.

Given correct implementations of A and B, B should be a tiny bit faster
for an average URI because it does less work in common cases.


In your patch, please add support for all URI characters that we can
support (or at least all the "unwise" ones from RFC 2396), not just the
characters that recent deployments have already confirmed "as necessary
to accommodate". We do not want to come back to this every time some app
starts sending slightly malformed URIs.

I would also recommend accommodating whitespace after HTTP-version.

Ideally, parseRequestFirstLine(), or at least the new code, should be
split into several methods. It is too long, convoluted, and is getting
worse.


I remain opposed to downgrading HTTP/1 requests with slightly malformed
URIs to HTTP/0.


HTH,

Alex.


From gkinkie at gmail.com  Sat Jun 27 18:56:55 2015
From: gkinkie at gmail.com (Kinkie)
Date: Sat, 27 Jun 2015 20:56:55 +0200
Subject: [squid-dev] [PATCH] SBuf case-change operations are safe against
	OutOfBoundsEception
Message-ID: <CA+Y8hcPa_uX1CuZJkkeoUOS4QHA=a_D5PgY-5QOXi9FFEew9VA@mail.gmail.com>

Hi,
  I'd like some feedback on this patch. Coverity detects an uncaught
exception code path for OutOfBoundsException which eventually leads to
SBuf.toUpper. However in single-threaded mode the exception cannot be
thrown by the loop calling that code.
Is it reasonable to explicitly catch that exception as I do in the attached
patch or should we rather triage and mark as false positives in coverity
all uses of this method? Or is there a more effective way to obtain the
same result?

Thanks

-- 
    kinkie
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150627/ae2d61aa/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sbuf-changecase-exceptionsafe.patch
Type: text/x-patch
Size: 1167 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20150627/ae2d61aa/attachment.bin>

From rousskov at measurement-factory.com  Sat Jun 27 21:53:51 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 27 Jun 2015 15:53:51 -0600
Subject: [squid-dev] [PATCH] SBuf case-change operations are safe
 against OutOfBoundsEception
In-Reply-To: <CA+Y8hcPa_uX1CuZJkkeoUOS4QHA=a_D5PgY-5QOXi9FFEew9VA@mail.gmail.com>
References: <CA+Y8hcPa_uX1CuZJkkeoUOS4QHA=a_D5PgY-5QOXi9FFEew9VA@mail.gmail.com>
Message-ID: <558F1B6F.5030805@measurement-factory.com>

On 06/27/2015 12:56 PM, Kinkie wrote:

>   I'd like some feedback on this patch. Coverity detects an uncaught
> exception code path for OutOfBoundsException which eventually leads to
> SBuf.toUpper. However in single-threaded mode the exception cannot be
> thrown by the loop calling that code.


> Is it reasonable to explicitly catch that exception as I do in the
> attached patch 

Catching an exception that [the reason tells you] cannot be thrown is
not reasonable.


> or should we rather triage and mark as false positives in
> coverity all uses of this method?

It is a false positive AFAICT. If you agree, then marking it as such
would be the second best option IMHO.


> Or is there a more effective way to obtain the same result?

I hope so: SBuf::toUpper() and toLower() methods should use a [private]
character setting method that does not check/throw anything. If there is
no such method, add it. You may call it riskySetAt(), justSetAt(), or
setAtUnchecked().

Moreover, calling cow() on every update operation also adds a little
overhead, even though only the first call can actually do something
useful. There are several ways to optimize that. Here is a sketch that
also eliminates code duplication between toUpper() and toLower() while
exposing an optimized method potentially useful to others:

template <class UnaryOperation>
void SBuf::transform(UnaryOperation op) {
    size_type updates = 0;
    for (size_type pos = 0; pos < length(); ++pos) {
        const int original = (*this)[pos];
        const int updated = op(original);
        if (original != updated) {
            if (!updates++)
                cow();
            setAtUnchecked(pos, updated);
        }
    }
}

You may use lambdas to implement SBuf::toUpper() and toLower() via
transform(). The standard toupper(3) and tolower(3) are locale-dependent
so we probably should not be using them for protocol work (for overhead
reasons; even if we force the locale to "C"). BTW, should not we use our
xtoupper() and xtolower() instead of toupper(3) and tolower(3)?


Alternatively, you may add a similar cow-avoiding trick directly to
SBuf::toUpper() and toLower() code, continuing to duplicate it.


HTH,

Alex.


From squid3 at treenet.co.nz  Sun Jun 28 11:21:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 28 Jun 2015 23:21:54 +1200
Subject: [squid-dev] [PATCH] Refactor path strings into class URL
Message-ID: <558FD8D2.4020405@treenet.co.nz>

This takes another step towards bug 1961 closure by shuffling the
HttpRequest::urlpath member into class URL.

These changes appear to work nicely. But I have not been able to test
all code paths that have logic change so a second pair of eyes on it
would be appreciated.

Amos
-------------- next part --------------
=== modified file 'src/HttpRequest.cc'
--- src/HttpRequest.cc	2015-06-09 06:14:43 +0000
+++ src/HttpRequest.cc	2015-06-28 06:32:00 +0000
@@ -44,49 +44,48 @@
 HttpRequest::HttpRequest(const HttpRequestMethod& aMethod, AnyP::ProtocolType aProtocol, const char *aUrlpath) :
     HttpMsg(hoRequest)
 {
     static unsigned int id = 1;
     debugs(93,7, HERE << "constructed, this=" << this << " id=" << ++id);
     init();
     initHTTP(aMethod, aProtocol, aUrlpath);
 }
 
 HttpRequest::~HttpRequest()
 {
     clean();
     debugs(93,7, HERE << "destructed, this=" << this);
 }
 
 void
 HttpRequest::initHTTP(const HttpRequestMethod& aMethod, AnyP::ProtocolType aProtocol, const char *aUrlpath)
 {
     method = aMethod;
     url.setScheme(aProtocol);
-    urlpath = aUrlpath;
+    url.path(aUrlpath);
 }
 
 void
 HttpRequest::init()
 {
     method = Http::METHOD_NONE;
     url.clear();
-    urlpath = NULL;
 #if USE_AUTH
     auth_user_request = NULL;
 #endif
     canonical = NULL;
     memset(&flags, '\0', sizeof(flags));
     range = NULL;
     ims = -1;
     imslen = 0;
     lastmod = -1;
     client_addr.setEmpty();
     my_addr.setEmpty();
     body_pipe = NULL;
     // hier
     dnsWait = -1;
     errType = ERR_NONE;
     errDetail = ERR_DETAIL_NONE;
     peer_login = NULL;      // not allocated/deallocated by this class
     peer_domain = NULL;     // not allocated/deallocated by this class
     peer_host = NULL;
     vary_headers = NULL;
@@ -109,41 +108,40 @@
     icapHistory_ = NULL;
 #endif
     rangeOffsetLimit = -2; //a value of -2 means not checked yet
     forcedBodyContinuation = false;
 }
 
 void
 HttpRequest::clean()
 {
     // we used to assert that the pipe is NULL, but now the request only
     // points to a pipe that is owned and initiated by another object.
     body_pipe = NULL;
 #if USE_AUTH
     auth_user_request = NULL;
 #endif
     safe_free(canonical);
 
     safe_free(vary_headers);
 
     url.clear();
-    urlpath.clean();
 
     header.clean();
 
     if (cache_control) {
         delete cache_control;
         cache_control = NULL;
     }
 
     if (range) {
         delete range;
         range = NULL;
     }
 
     myportname.clean();
 
     notes = NULL;
 
     tag.clean();
 #if USE_AUTH
     extacl_user.clean();
@@ -156,52 +154,55 @@
     etag.clean();
 
 #if USE_ADAPTATION
     adaptHistory_ = NULL;
 #endif
 #if ICAP_CLIENT
     icapHistory_ = NULL;
 #endif
 }
 
 void
 HttpRequest::reset()
 {
     clean();
     init();
 }
 
 HttpRequest *
 HttpRequest::clone() const
 {
-    HttpRequest *copy = new HttpRequest(method, url.getScheme(), urlpath.termedBuf());
+    HttpRequest *copy = new HttpRequest();
+    copy->method = method;
     // TODO: move common cloning clone to Msg::copyTo() or copy ctor
     copy->header.append(&header);
     copy->hdrCacheInit();
     copy->hdr_sz = hdr_sz;
     copy->http_ver = http_ver;
     copy->pstate = pstate; // TODO: should we assert a specific state here?
     copy->body_pipe = body_pipe;
 
+    copy->url.setScheme(url.getScheme());
     copy->url.userInfo(url.userInfo());
     copy->url.host(url.host());
     copy->url.port(url.port());
+    copy->url.path(url.path());
 
     // urlPath handled in ctor
     copy->canonical = canonical ? xstrdup(canonical) : NULL;
 
     // range handled in hdrCacheInit()
     copy->ims = ims;
     copy->imslen = imslen;
     copy->hier = hier; // Is it safe to copy? Should we?
 
     copy->errType = errType;
 
     // XXX: what to do with copy->peer_login?
 
     copy->lastmod = lastmod;
     copy->etag = etag;
     copy->vary_headers = vary_headers ? xstrdup(vary_headers) : NULL;
     // XXX: what to do with copy->peer_domain?
 
     copy->tag = tag;
     copy->extacl_log = extacl_log;
@@ -355,65 +356,65 @@
         hdrCacheInit();
 
     return result;
 }
 
 /* swaps out request using httpRequestPack */
 void
 HttpRequest::swapOut(StoreEntry * e)
 {
     assert(e);
     e->buffer();
     pack(e);
 }
 
 /* packs request-line and headers, appends <crlf> terminator */
 void
 HttpRequest::pack(Packable * p)
 {
     assert(p);
     /* pack request-line */
-    p->appendf(SQUIDSBUFPH " " SQUIDSTRINGPH " HTTP/%d.%d\r\n",
-               SQUIDSBUFPRINT(method.image()), SQUIDSTRINGPRINT(urlpath),
+    p->appendf(SQUIDSBUFPH " " SQUIDSBUFPH " HTTP/%d.%d\r\n",
+               SQUIDSBUFPRINT(method.image()), SQUIDSBUFPRINT(url.path()),
                http_ver.major, http_ver.minor);
     /* headers */
     header.packInto(p);
     /* trailer */
     p->append("\r\n", 2);
 }
 
 /*
  * A wrapper for debugObj()
  */
 void
 httpRequestPack(void *obj, Packable *p)
 {
     HttpRequest *request = static_cast<HttpRequest*>(obj);
     request->pack(p);
 }
 
 /* returns the length of request line + headers + crlf */
 int
-HttpRequest::prefixLen()
+HttpRequest::prefixLen() const
 {
     return method.image().length() + 1 +
-           urlpath.size() + 1 +
+           url.path().length() + 1 +
            4 + 1 + 3 + 2 +
            header.len + 2;
 }
 
 /* sync this routine when you update HttpRequest struct */
 void
 HttpRequest::hdrCacheInit()
 {
     HttpMsg::hdrCacheInit();
 
     assert(!range);
     range = header.getRange();
 }
 
 #if ICAP_CLIENT
 Adaptation::Icap::History::Pointer
 HttpRequest::icapHistory() const
 {
     if (!icapHistory_) {
         if (Log::TheConfig.hasIcapToken || IcapLogfileStatus == LOG_ENABLE) {
@@ -474,57 +475,53 @@
 {
     if (errType || errDetail)
         debugs(11, 5, HERE << "old error details: " << errType << '/' << errDetail);
     debugs(11, 5, HERE << "current error details: " << aType << '/' << aDetail);
     // checking type and detail separately may cause inconsistency, but
     // may result in more details available if they only become available later
     if (!errType)
         errType = aType;
     if (!errDetail)
         errDetail = aDetail;
 }
 
 void
 HttpRequest::clearError()
 {
     debugs(11, 7, HERE << "old error details: " << errType << '/' << errDetail);
     errType = ERR_NONE;
     errDetail = ERR_DETAIL_NONE;
 }
 
-const char *HttpRequest::packableURI(bool full_uri) const
+void
+HttpRequest::packFirstLineInto(Packable * p, bool full_uri) const
 {
+    SBuf tmp;
     if (full_uri)
-        return urlCanonical((HttpRequest*)this);
-
-    if (urlpath.size())
-        return urlpath.termedBuf();
+        tmp = urlCanonical((HttpRequest*)this);
+    else
+        tmp = url.path();
 
-    return "/";
-}
-
-void HttpRequest::packFirstLineInto(Packable * p, bool full_uri) const
-{
     // form HTTP request-line
-    p->appendf(SQUIDSBUFPH " %s HTTP/%d.%d\r\n",
+    p->appendf(SQUIDSBUFPH " " SQUIDSBUFPH " HTTP/%d.%d\r\n",
                SQUIDSBUFPRINT(method.image()),
-               packableURI(full_uri),
+               SQUIDSBUFPRINT(tmp),
                http_ver.major, http_ver.minor);
 }
 
 /*
  * Indicate whether or not we would expect an entity-body
  * along with this request
  */
 bool
 HttpRequest::expectingBody(const HttpRequestMethod &, int64_t &theSize) const
 {
     bool expectBody = false;
 
     /*
      * Note: Checks for message validity is in clientIsContentLengthValid().
      * this just checks if a entity-body is expected based on HTTP message syntax
      */
     if (header.chunked()) {
         expectBody = true;
         theSize = -1;
     } else if (content_length >= 0) {

=== modified file 'src/HttpRequest.h'
--- src/HttpRequest.h	2015-06-09 06:14:43 +0000
+++ src/HttpRequest.h	2015-06-15 03:50:46 +0000
@@ -99,42 +99,40 @@
 
     void init();
 
 public:
     HttpRequestMethod method;
     URL url; ///< the request URI
 
 private:
 #if USE_ADAPTATION
     mutable Adaptation::History::Pointer adaptHistory_; ///< per-HTTP transaction info
 #endif
 #if ICAP_CLIENT
     mutable Adaptation::Icap::History::Pointer icapHistory_; ///< per-HTTP transaction info
 #endif
 
 public:
 #if USE_AUTH
     Auth::UserRequest::Pointer auth_user_request;
 #endif
 
-    String urlpath;
-
     char *canonical;
 
     /**
      * If defined, store_id_program mapped the request URL to this ID.
      * Store uses this ID (and not the URL) to find and store entries,
      * avoiding caching duplicate entries when different URLs point to
      * "essentially the same" cachable resource.
      */
     String store_id;
 
     RequestFlags flags;
 
     HttpHdrRange *range;
 
     time_t ims;
 
     int imslen;
 
     Ip::Address client_addr;
 
@@ -179,70 +177,68 @@
     String x_forwarded_for_iterator; /* XXX a list of IP addresses */
 #endif /* FOLLOW_X_FORWARDED_FOR */
 
     /// A strong etag of the cached entry. Used for refreshing that entry.
     String etag;
 
     /// whether we have responded with HTTP 100 or FTP 150 already
     bool forcedBodyContinuation;
 
 public:
     bool multipartRangeRequest() const;
 
     bool parseFirstLine(const char *start, const char *end);
 
     bool parseHeader(Http1::RequestParser &hp); // TODO move this function to the parser
 
     virtual bool expectingBody(const HttpRequestMethod& unused, int64_t&) const;
 
     bool bodyNibbled() const; // the request has a [partially] consumed body
 
-    int prefixLen();
+    int prefixLen() const;
 
     void swapOut(StoreEntry * e);
 
     void pack(Packable * p);
 
     static void httpRequestPack(void *obj, Packable *p);
 
     static HttpRequest * CreateFromUrlAndMethod(char * url, const HttpRequestMethod& method);
 
     static HttpRequest * CreateFromUrl(char * url);
 
     ConnStateData *pinnedConnection();
 
     /**
      * Returns the current StoreID for the request as a nul-terminated char*.
      * Always returns the current id for the request
      * (either the request canonical url or modified ID by the helper).
      * Does not return NULL.
      */
     const char *storeId();
 
     /**
      * The client connection manager, if known;
      * Used for any response actions needed directly to the client.
      * ie 1xx forwarding or connection pinning state changes
      */
     CbcPointer<ConnStateData> clientConnectionManager;
 
     /// forgets about the cached Range header (for a reason)
     void ignoreRange(const char *reason);
     int64_t getRangeOffsetLimit(); /* the result of this function gets cached in rangeOffsetLimit */
 
 private:
-    const char *packableURI(bool full_uri) const;
-
     mutable int64_t rangeOffsetLimit;  /* caches the result of getRangeOffsetLimit */
 
 protected:
     virtual void packFirstLineInto(Packable * p, bool full_uri) const;
 
     virtual bool sanityCheckStartLine(const char *buf, const size_t hdr_len, Http::StatusCode *error);
 
     virtual void hdrCacheInit();
 
     virtual bool inheritProperties(const HttpMsg *aMsg);
 };
 
 #endif /* SQUID_HTTPREQUEST_H */
 

=== modified file 'src/URL.h'
--- src/URL.h	2015-06-09 06:14:43 +0000
+++ src/URL.h	2015-06-28 06:35:45 +0000
@@ -1,75 +1,84 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_SRC_URL_H
 #define SQUID_SRC_URL_H
 
 #include "anyp/UriScheme.h"
 #include "ip/Address.h"
 #include "rfc2181.h"
 #include "SBuf.h"
 
+#include <iosfwd>
+
 /**
  * The URL class represents a Uniform Resource Location
  *
  * Governed by RFC 3986
  */
 class URL
 {
     MEMPROXY_CLASS(URL);
 
 public:
     URL() : scheme_(), hostIsNumeric_(false), port_(0) {*host_=0;}
     URL(AnyP::UriScheme const &aScheme) : scheme_(aScheme), hostIsNumeric_(false), port_(0) {*host_=0;}
 
     void clear() {
         scheme_=AnyP::PROTO_NONE;
         hostIsNumeric_ = false;
         *host_ = 0;
         hostAddr_.setEmpty();
         port_ = 0;
         touch();
     }
     void touch(); ///< clear the cached URI display forms
 
     AnyP::UriScheme const & getScheme() const {return scheme_;}
 
     /// convert the URL scheme to that given
     void setScheme(const AnyP::ProtocolType &p) {scheme_=p; touch();}
 
     void userInfo(const SBuf &s) {userInfo_=s; touch();}
     const SBuf &userInfo() const {return userInfo_;}
 
     void host(const char *src);
     const char *host(void) const {return host_;}
     int hostIsNumeric(void) const {return hostIsNumeric_;}
     Ip::Address const & hostIP(void) const {return hostAddr_;}
 
     void port(unsigned short p) {port_=p; touch();}
     unsigned short port() const {return port_;}
 
+    void path(const char *p) {path_=p; touch();}
+    void path(const SBuf &p) {path_=p; touch();}
+    const SBuf &path() const;
+
+    /// the static '/' default URL-path
+    static const SBuf &SlashPath();
+
     /// the static '*' pseudo-URL
     static const SBuf &Asterisk();
 
     /**
      * The authority-form URI for currently stored values.
      *
      * As defined by RFC 7230 section 5.3.3 this form omits the
      * userinfo@ field from RFC 3986 defined authority segment.
      *
      * \param requirePort when true the port will be included, otherwise
      *                    port will be elided when it is the default for
      *                    the current scheme.
      */
     SBuf &authority(bool requirePort = false) const;
 
 private:
     /**
      \par
      * The scheme of this URL. This has the 'type code' smell about it.
      * In future we may want to make the methods that dispatch based on
@@ -84,45 +93,58 @@
      * class for each manner of treating the scheme : a Hierarchical URL, a
      * non-hierarchical URL etc.
      \par
      * Deferring the decision, its a type code for now. RBC 20060507.
      \par
      * In order to make taking any of these routes easy, scheme is private
      * and immutable, only settable at construction time,
      */
     AnyP::UriScheme scheme_;
 
     SBuf userInfo_; // aka 'URL-login'
 
     // XXX: uses char[] instead of SBUf to reduce performance regressions
     //      from c_str() since most code using this is not yet using SBuf
     char host_[SQUIDHOSTNAMELEN];   ///< string representation of the URI authority name or IP
     bool hostIsNumeric_;            ///< whether the authority 'host' is a raw-IP
     Ip::Address hostAddr_;          ///< binary representation of the URI authority if it is a raw-IP
 
     unsigned short port_;   ///< URL port
 
+    // XXX: for now includes query-string.
+    SBuf path_;     ///< URL path segment
+
     // pre-assembled URL forms
     mutable SBuf authorityHttp_;     ///< RFC 7230 section 5.3.3 authority, maybe without default-port
     mutable SBuf authorityWithPort_; ///< RFC 7230 section 5.3.3 authority with explicit port
+    mutable SBuf canonical_;         ///< full absolute-URI
 };
 
+inline std::ostream &
+operator <<(std::ostream &os, const URL &url)
+{
+    if (const char *sc = url.getScheme().c_str())
+        os << sc << ":";
+    os << "//" << url.authority() << url.path();
+    return os;
+}
+
 class HttpRequest;
 class HttpRequestMethod;
 
 AnyP::ProtocolType urlParseProtocol(const char *, const char *e = NULL);
 void urlInitialize(void);
 HttpRequest *urlParse(const HttpRequestMethod&, char *, HttpRequest *request = NULL);
 const char *urlCanonical(HttpRequest *);
 char *urlCanonicalClean(const HttpRequest *);
 const char *urlCanonicalFakeHttps(const HttpRequest * request);
 bool urlIsRelative(const char *);
 char *urlMakeAbsolute(const HttpRequest *, const char *);
 char *urlRInternal(const char *host, unsigned short port, const char *dir, const char *name);
 char *urlInternal(const char *dir, const char *name);
 
 /**
  * matchDomainName() compares a hostname (usually extracted from traffic)
  * with a domainname (usually from an ACL) according to the following rules:
  *
  *    HOST      |   DOMAIN    |   MATCH?
  * -------------|-------------|------

=== modified file 'src/acl/UrlPath.cc'
--- src/acl/UrlPath.cc	2015-01-13 07:25:36 +0000
+++ src/acl/UrlPath.cc	2015-06-09 11:52:48 +0000
@@ -1,38 +1,39 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 /* DEBUG: section 28    Access Control */
 
 #include "squid.h"
 #include "acl/Checklist.h"
 #include "acl/RegexData.h"
 #include "acl/UrlPath.h"
 #include "HttpRequest.h"
 #include "rfc1738.h"
 
 int
 ACLUrlPathStrategy::match (ACLData<char const *> * &data, ACLFilledChecklist *checklist, ACLFlags &)
 {
-    if (!checklist->request->urlpath.size())
+    if (checklist->request->url.path().isEmpty())
         return -1;
 
-    char *esc_buf = xstrdup(checklist->request->urlpath.termedBuf());
+    SBuf tmp = checklist->request->url.path();
+    char *esc_buf = xstrndup(tmp.rawContent(), tmp.length());
     rfc1738_unescape(esc_buf);
     int result = data->match(esc_buf);
-    safe_free(esc_buf);
+    xfree(esc_buf);
     return result;
 }
 
 ACLUrlPathStrategy *
 ACLUrlPathStrategy::Instance()
 {
     return &Instance_;
 }
 
 ACLUrlPathStrategy ACLUrlPathStrategy::Instance_;
 

=== modified file 'src/adaptation/Service.cc'
--- src/adaptation/Service.cc	2015-01-13 07:25:36 +0000
+++ src/adaptation/Service.cc	2015-06-14 19:02:01 +0000
@@ -32,41 +32,41 @@
     return probed() && !up();
 }
 
 bool
 Adaptation::Service::wants(const ServiceFilter &filter) const
 {
     if (cfg().method != filter.method)
         return false;
 
     if (cfg().point != filter.point)
         return false;
 
     // sending a message to a broken service is likely to cause errors
     if (cfg().bypass && broken())
         return false;
 
     if (up()) {
         // Sending a message to a service that does not want it is useless.
         // note that we cannot check wantsUrl for service that is not "up"
         // note that even essential services are skipped on unwanted URLs!
-        return wantsUrl(filter.request->urlpath);
+        return wantsUrl(filter.request->url.path());
     }
 
     // The service is down and is either not bypassable or not probed due
     // to the bypass && broken() test above. Thus, we want to use it!
     return true;
 }
 
 Adaptation::Services &
 Adaptation::AllServices()
 {
     static Services *TheServices = new Services;
     return *TheServices;
 }
 
 Adaptation::ServicePointer
 Adaptation::FindService(const Service::Id& key)
 {
     typedef Services::iterator SI;
     for (SI i = AllServices().begin(); i != AllServices().end(); ++i) {
         if ((*i)->cfg().key == key)

=== modified file 'src/adaptation/Service.h'
--- src/adaptation/Service.h	2015-01-13 07:25:36 +0000
+++ src/adaptation/Service.h	2015-06-14 19:14:27 +0000
@@ -28,41 +28,41 @@
 // specific adaptation mechanisms extend this class
 class Service: public RefCountable
 {
 public:
     typedef RefCount<Service> Pointer;
     typedef String Id;
 
 public:
     explicit Service(const ServiceConfigPointer &aConfig);
     virtual ~Service();
 
     virtual bool probed() const = 0; // see comments above
     virtual bool broken() const;
     virtual bool up() const = 0; // see comments above
 
     virtual Initiate *makeXactLauncher(HttpMsg *virginHeader, HttpRequest *virginCause, AccessLogEntry::Pointer &alp) = 0;
 
     bool wants(const ServiceFilter &filter) const;
 
     // the methods below can only be called on an up() service
-    virtual bool wantsUrl(const String &urlPath) const = 0;
+    virtual bool wantsUrl(const SBuf &urlPath) const = 0;
 
     // called by transactions to report service failure
     virtual void noteFailure() = 0;
 
     const ServiceConfig &cfg() const { return *theConfig; }
 
     virtual void finalize(); // called after creation
 
     /// called when removed from the config; the service will be
     /// auto-destroyed when the last refcounting user leaves
     virtual void detach() = 0;
     /// whether detached() was called
     virtual bool detached() const = 0;
 
 protected:
     ServiceConfig &writeableCfg() { return *theConfig; }
 
 private:
     ServiceConfigPointer theConfig;
 };

=== modified file 'src/adaptation/ecap/ServiceRep.cc'
--- src/adaptation/ecap/ServiceRep.cc	2015-01-13 07:25:36 +0000
+++ src/adaptation/ecap/ServiceRep.cc	2015-06-14 19:24:48 +0000
@@ -220,44 +220,46 @@
         return false; // we cannot handle the problem; the caller may escalate
 
     // make up() false, preventing new adaptation requests and enabling bypass
     theService.reset();
     debugs(93, level, "WARNING: " << kind << " eCAP service is " <<
            "down after initialization failure: " << cfg().uri);
 
     return true; // tell the caller to ignore the problem because we handled it
 }
 
 bool Adaptation::Ecap::ServiceRep::probed() const
 {
     return true; // we "probe" the adapter in finalize().
 }
 
 bool Adaptation::Ecap::ServiceRep::up() const
 {
     return theService != NULL;
 }
 
-bool Adaptation::Ecap::ServiceRep::wantsUrl(const String &urlPath) const
+bool Adaptation::Ecap::ServiceRep::wantsUrl(const SBuf &urlPath) const
 {
     Must(up());
-    return theService->wantsUrl(urlPath.termedBuf());
+    SBuf nonConstUrlPath = urlPath;
+    // c_str() reallocates and terminates for libecap API
+    return theService->wantsUrl(nonConstUrlPath.c_str());
 }
 
 Adaptation::Initiate *
 Adaptation::Ecap::ServiceRep::makeXactLauncher(HttpMsg *virgin,
         HttpRequest *cause, AccessLogEntry::Pointer &alp)
 {
     Must(up());
 
     // register now because (a) we need EventLoop::Running and (b) we do not
     // want to add more main loop overheads unless an async service is used.
     static AsyncEngine *TheEngine = NULL;
     if (AsyncServices.size() && !TheEngine && EventLoop::Running) {
         TheEngine = new Engine;
         EventLoop::Running->registerEngine(TheEngine);
         debugs(93, 3, "asyncs: " << AsyncServices.size() << ' ' << TheEngine);
     }
 
     XactionRep *rep = new XactionRep(virgin, cause, alp, Pointer(this));
     XactionRep::AdapterXaction x(theService->makeXaction(rep));
     rep->master(x);

=== modified file 'src/adaptation/ecap/ServiceRep.h'
--- src/adaptation/ecap/ServiceRep.h	2015-01-13 07:25:36 +0000
+++ src/adaptation/ecap/ServiceRep.h	2015-06-14 19:07:28 +0000
@@ -21,41 +21,41 @@
 namespace Ecap
 {
 
 /* The eCAP service representative maintains information about a single eCAP
    service that Squid communicates with. One eCAP module may register many
    eCAP services. */
 
 class ServiceRep : public Adaptation::Service
 {
 public:
     explicit ServiceRep(const ServiceConfigPointer &aConfig);
     virtual ~ServiceRep();
 
     typedef libecap::shared_ptr<libecap::adapter::Service> AdapterService;
 
     /* Adaptation::Service API */
     virtual void finalize();
     virtual bool probed() const;
     virtual bool up() const;
     virtual Adaptation::Initiate *makeXactLauncher(HttpMsg *virginHeader, HttpRequest *virginCause, AccessLogEntry::Pointer &alp);
-    virtual bool wantsUrl(const String &urlPath) const;
+    virtual bool wantsUrl(const SBuf &urlPath) const;
     virtual void noteFailure();
     virtual const char *status() const;
     virtual void detach();
     virtual bool detached() const;
 
 protected:
     void tryConfigureAndStart();
     bool handleFinalizeFailure(const char *error);
 
 private:
     AdapterService theService; // the actual adaptation service we represent
     bool           isDetached;
 };
 
 /// register loaded eCAP module service
 void RegisterAdapterService(const ServiceRep::AdapterService& adapterService);
 /// unregister loaded eCAP module service by service uri
 void UnregisterAdapterService(const String& serviceUri);
 
 /// returns loaded eCAP module service by service uri

=== modified file 'src/adaptation/icap/ModXact.cc'
--- src/adaptation/icap/ModXact.cc	2015-06-01 21:41:37 +0000
+++ src/adaptation/icap/ModXact.cc	2015-06-28 06:37:43 +0000
@@ -1372,43 +1372,41 @@
         Adaptation::History::Pointer ah = request->adaptHistory(false);
         if (ah != NULL) {
             String name, value;
             if (ah->getXxRecord(name, value)) {
                 buf.appendf(SQUIDSTRINGPH ": " SQUIDSTRINGPH "\r\n", SQUIDSTRINGPRINT(name), SQUIDSTRINGPRINT(value));
             }
         }
     }
 
     buf.append("Encapsulated: ", 14);
 
     MemBuf httpBuf;
 
     httpBuf.init();
 
     // build HTTP request header, if any
     ICAP::Method m = s.method;
 
     // to simplify, we could assume that request is always available
 
-    String urlPath;
     if (request) {
-        urlPath = request->urlpath;
         if (ICAP::methodRespmod == m)
             encapsulateHead(buf, "req-hdr", httpBuf, request);
         else if (ICAP::methodReqmod == m)
             encapsulateHead(buf, "req-hdr", httpBuf, virgin.header);
     }
 
     if (ICAP::methodRespmod == m)
         if (const HttpMsg *prime = virgin.header)
             encapsulateHead(buf, "res-hdr", httpBuf, prime);
 
     if (!virginBody.expected())
         buf.appendf("null-body=%d", (int) httpBuf.contentSize());
     else if (ICAP::methodReqmod == m)
         buf.appendf("req-body=%d", (int) httpBuf.contentSize());
     else
         buf.appendf("res-body=%d", (int) httpBuf.contentSize());
 
     buf.append(ICAP::crlf, 2); // terminate Encapsulated line
 
     if (preview.enabled()) {
@@ -1566,44 +1564,44 @@
 
     // pack polished HTTP header
     packHead(httpBuf, headClone.getRaw());
 
     // headClone unlocks and, hence, deletes the message we packed
 }
 
 void Adaptation::Icap::ModXact::packHead(MemBuf &httpBuf, const HttpMsg *head)
 {
     head->packInto(&httpBuf, true);
 }
 
 // decides whether to offer a preview and calculates its size
 void Adaptation::Icap::ModXact::decideOnPreview()
 {
     if (!TheConfig.preview_enable) {
         debugs(93, 5, HERE << "preview disabled by squid.conf");
         return;
     }
 
-    const String urlPath = virginRequest().urlpath;
+    const SBuf urlPath(virginRequest().url.path());
     size_t wantedSize;
     if (!service().wantsPreview(urlPath, wantedSize)) {
-        debugs(93, 5, HERE << "should not offer preview for " << urlPath);
+        debugs(93, 5, "should not offer preview for " << urlPath);
         return;
     }
 
     // we decided to do preview, now compute its size
 
     // cannot preview more than we can backup
     size_t ad = min(wantedSize, TheBackupLimit);
 
     if (!virginBody.expected())
         ad = 0;
     else if (virginBody.knownSize())
         ad = min(static_cast<uint64_t>(ad), virginBody.size()); // not more than we have
 
     debugs(93, 5, HERE << "should offer " << ad << "-byte preview " <<
            "(service wanted " << wantedSize << ")");
 
     preview.enable(ad);
     Must(preview.enabled());
 }
 

=== modified file 'src/adaptation/icap/Options.cc'
--- src/adaptation/icap/Options.cc	2015-01-13 07:25:36 +0000
+++ src/adaptation/icap/Options.cc	2015-06-14 19:06:59 +0000
@@ -26,52 +26,53 @@
 {
     theTransfers.preview.name = "Transfer-Preview";
     theTransfers.preview.kind = xferPreview;
     theTransfers.ignore.name = "Transfer-Ignore";
     theTransfers.ignore.kind = xferIgnore;
     theTransfers.complete.name = "Transfer-Complete";
     theTransfers.complete.kind = xferComplete;
 
     // Section 4.10.2 of RFC 3507 says that default is no Preview
     // TODO: provide a squid.conf option to overwrite the default
     theTransfers.byDefault = &theTransfers.complete;
 }
 
 Adaptation::Icap::Options::~Options()
 {
 }
 
 // future optimization note: this method is called by ICAP ACL code at least
 // twice for each HTTP message to see if the message should be ignored. For any
 // non-ignored HTTP message, ICAP calls to check whether a preview is needed.
-Adaptation::Icap::Options::TransferKind Adaptation::Icap::Options::transferKind(const String &urlPath) const
+Adaptation::Icap::Options::TransferKind
+Adaptation::Icap::Options::transferKind(const SBuf &urlPath) const
 {
     if (theTransfers.preview.matches(urlPath))
         return xferPreview;
 
     if (theTransfers.complete.matches(urlPath))
         return xferComplete;
 
     if (theTransfers.ignore.matches(urlPath))
         return xferIgnore;
 
-    debugs(93,7, HERE << "url " << urlPath << " matches no extensions; " <<
+    debugs(93,7, "url " << urlPath << " matches no extensions; " <<
            "using default: " << theTransfers.byDefault->name);
     return theTransfers.byDefault->kind;
 }
 
 bool Adaptation::Icap::Options::valid() const
 {
     return !error;
 }
 
 bool Adaptation::Icap::Options::fresh() const
 {
     return squid_curtime <= expire();
 }
 
 int Adaptation::Icap::Options::ttl() const
 {
     Must(valid());
     return theTTL >= 0 ? theTTL : TheConfig.default_options_ttl;
 }
 
@@ -167,60 +168,58 @@
     list.report(5, "Adaptation::Icap::Options::cfgTransferList: ");
 }
 
 /* Adaptation::Icap::Options::TransferList */
 
 Adaptation::Icap::Options::TransferList::TransferList(): extensions(NULL), name(NULL),
     kind(xferNone)
 {
 };
 
 Adaptation::Icap::Options::TransferList::~TransferList()
 {
     wordlistDestroy(&extensions);
 };
 
 void Adaptation::Icap::Options::TransferList::add(const char *extension)
 {
     wordlistAdd(&extensions, extension);
 };
 
-bool Adaptation::Icap::Options::TransferList::matches(const String &urlPath) const
+bool Adaptation::Icap::Options::TransferList::matches(const SBuf &urlPath) const
 {
-    const int urlLen = urlPath.size();
+    const SBuf::size_type urlLen = urlPath.length();
     for (wordlist *e = extensions; e; e = e->next) {
         // optimize: store extension lengths
-        const int eLen = strlen(e->key);
+        const size_t eLen = strlen(e->key);
 
         // assume URL contains at least '/' before the extension
         if (eLen < urlLen) {
-            const int eOff = urlLen - eLen;
+            const size_t eOff = urlLen - eLen;
             // RFC 3507 examples imply that extensions come without leading '.'
-            if (urlPath[eOff-1] == '.' &&
-                    strcmp(urlPath.termedBuf() + eOff, e->key) == 0) {
-                debugs(93,7, HERE << "url " << urlPath << " matches " <<
-                       name << " extension " << e->key);
+            if (urlPath[eOff-1] == '.' && urlPath.substr(eOff).cmp(e->key, eLen) == 0) {
+                debugs(93,7, "url " << urlPath << " matches " << name << " extension " << e->key);
                 return true;
             }
         }
     }
-    debugs(93,8, HERE << "url " << urlPath << " matches no " << name << " extensions");
+    debugs(93,8, "url " << urlPath << " matches no " << name << " extensions");
     return false;
 }
 
 void Adaptation::Icap::Options::TransferList::parse(const String &buf, bool &foundStar)
 {
     foundStar = false;
 
     const char *item;
     const char *pos = NULL;
     int ilen;
     while (strListGetItem(&buf, ',', &item, &ilen, &pos)) {
         if (ilen == 1 && *item == '*')
             foundStar = true;
         else {
             const char *tmp = xstrndup(item, ilen+1);
             add(tmp);
             xfree(tmp);
         }
     }
 }

=== modified file 'src/adaptation/icap/Options.h'
--- src/adaptation/icap/Options.h	2015-01-13 07:25:36 +0000
+++ src/adaptation/icap/Options.h	2015-06-14 19:16:30 +0000
@@ -25,67 +25,67 @@
 class Options
 {
 
 public:
     typedef void GetCallback(void *data, Options *options);
     static void Get(ServiceRep::Pointer &service, GetCallback *cb, void *data);
 
 public:
     Options();
     ~Options();
 
     void configure(const HttpReply *reply);
 
     bool valid() const;
     bool fresh() const;
     int ttl() const;
     time_t expire() const;
     time_t timestamp() const { return theTimestamp; };
 
     typedef enum { xferNone, xferPreview, xferIgnore, xferComplete } TransferKind;
-    TransferKind transferKind(const String &urlPath) const;
+    TransferKind transferKind(const SBuf &urlPath) const;
 
 public:
     const char *error; // human-readable information; set iff !valid()
 
     // ICAP server MUST supply this info
     std::vector<ICAP::Method> methods;
     String istag;
 
     // ICAP server MAY supply this info. If not, Squid supplies defaults.
     String service;
     String serviceId;
     int max_connections;
     bool allow204;
     bool allow206;
     int preview;
 
 protected:
     // Transfer-* extension list representation
     // maintains wordlist and does parsing/matching
     class TransferList
     {
     public:
         TransferList();
         ~TransferList();
 
-        bool matches(const String &urlPath) const;
+        bool matches(const SBuf &urlPath) const;
 
         void parse(const String &buf, bool &foundStar);
         void add(const char *extension);
         void report(int level, const char *prefix) const;
 
     public:
         wordlist *extensions; // TODO: optimize with a hash of some sort
         const char *name;  // header name, mostly for debugging
         TransferKind kind; // to simplify caller's life
     };
 
     // varios Transfer-* lists
     struct Transfers {
         TransferList preview;
         TransferList ignore;
         TransferList complete;
         TransferList *byDefault;  // Transfer-X that has '*'
     } theTransfers;
 
     int theTTL;

=== modified file 'src/adaptation/icap/ServiceRep.cc'
--- src/adaptation/icap/ServiceRep.cc	2015-05-26 17:25:04 +0000
+++ src/adaptation/icap/ServiceRep.cc	2015-06-14 19:10:43 +0000
@@ -304,47 +304,47 @@
 }
 
 bool Adaptation::Icap::ServiceRep::availableForNew() const
 {
     Must(up());
     int available = availableConnections();
     if (available < 0)
         return true;
     else
         return (available - theAllWaiters > 0);
 }
 
 bool Adaptation::Icap::ServiceRep::availableForOld() const
 {
     Must(up());
 
     int available = availableConnections();
     return (available != 0); // it is -1 (no limit) or has available slots
 }
 
-bool Adaptation::Icap::ServiceRep::wantsUrl(const String &urlPath) const
+bool Adaptation::Icap::ServiceRep::wantsUrl(const SBuf &urlPath) const
 {
     Must(hasOptions());
     return theOptions->transferKind(urlPath) != Adaptation::Icap::Options::xferIgnore;
 }
 
-bool Adaptation::Icap::ServiceRep::wantsPreview(const String &urlPath, size_t &wantedSize) const
+bool Adaptation::Icap::ServiceRep::wantsPreview(const SBuf &urlPath, size_t &wantedSize) const
 {
     Must(hasOptions());
 
     if (theOptions->preview < 0)
         return false;
 
     if (theOptions->transferKind(urlPath) != Adaptation::Icap::Options::xferPreview)
         return false;
 
     wantedSize = theOptions->preview;
 
     return true;
 }
 
 bool Adaptation::Icap::ServiceRep::allows204() const
 {
     Must(hasOptions());
     return true; // in the future, we may have ACLs to prevent 204s
 }
 

=== modified file 'src/adaptation/icap/ServiceRep.h'
--- src/adaptation/icap/ServiceRep.h	2015-05-05 09:09:27 +0000
+++ src/adaptation/icap/ServiceRep.h	2015-06-14 19:10:55 +0000
@@ -64,42 +64,42 @@
 public:
     typedef RefCount<ServiceRep> Pointer;
 
 public:
     explicit ServiceRep(const ServiceConfigPointer &aConfig);
     virtual ~ServiceRep();
 
     virtual void finalize();
 
     virtual bool probed() const; // see comments above
     virtual bool up() const; // see comments above
     bool availableForNew() const; ///< a new transaction may start communicating with the service
     bool availableForOld() const; ///< a transaction notified about connection slot availability may start communicating with the service
 
     virtual Initiate *makeXactLauncher(HttpMsg *virginHeader, HttpRequest *virginCause, AccessLogEntry::Pointer &alp);
 
     void callWhenAvailable(AsyncCall::Pointer &cb, bool priority = false);
     void callWhenReady(AsyncCall::Pointer &cb);
 
     // the methods below can only be called on an up() service
-    bool wantsUrl(const String &urlPath) const;
-    bool wantsPreview(const String &urlPath, size_t &wantedSize) const;
+    bool wantsUrl(const SBuf &urlPath) const;
+    bool wantsPreview(const SBuf &urlPath, size_t &wantedSize) const;
     bool allows204() const;
     bool allows206() const;
     Comm::ConnectionPointer getConnection(bool isRetriable, bool &isReused);
     void putConnection(const Comm::ConnectionPointer &conn, bool isReusable, bool sendReset, const char *comment);
     void noteConnectionUse(const Comm::ConnectionPointer &conn);
     void noteConnectionFailed(const char *comment);
 
     void noteFailure(); // called by transactions to report service failure
 
     void noteNewWaiter() {theAllWaiters++;} ///< New xaction waiting for service to be up or available
     void noteGoneWaiter(); ///< An xaction is not waiting any more for service to be available
     bool existWaiters() const {return (theAllWaiters > 0);} ///< if there are xactions waiting for the service to be available
 
     //AsyncJob virtual methods
     virtual bool doneAll() const { return Adaptation::Initiator::doneAll() && false;}
     virtual void callException(const std::exception &e);
 
     virtual void detach();
     virtual bool detached() const;
 

=== modified file 'src/carp.cc'
--- src/carp.cc	2015-06-09 06:14:43 +0000
+++ src/carp.cc	2015-06-28 06:43:45 +0000
@@ -161,50 +161,48 @@
 
     /* select CachePeer */
     for (k = 0; k < n_carp_peers; ++k) {
         SBuf key;
         tp = carp_peers[k];
         if (tp->options.carp_key.set) {
             //this code follows urlCanonical's pattern.
             //   corner cases should use the canonical URL
             if (tp->options.carp_key.scheme) {
                 key.append(request->url.getScheme().c_str());
                 if (key.length()) //if the scheme is not empty
                     key.append("://");
             }
             if (tp->options.carp_key.host) {
                 key.append(request->url.host());
             }
             if (tp->options.carp_key.port) {
                 key.appendf(":%u", request->url.port());
             }
             if (tp->options.carp_key.path) {
-                String::size_type pos;
-                if ((pos=request->urlpath.find('?'))!=String::npos)
-                    key.append(SBuf(request->urlpath.substr(0,pos)));
-                else
-                    key.append(SBuf(request->urlpath));
+                // XXX: fix when path and query are separate
+                key.append(request->url.path().substr(0,request->url.path().find('?'))); // 0..N
             }
             if (tp->options.carp_key.params) {
-                String::size_type pos;
-                if ((pos=request->urlpath.find('?'))!=String::npos)
-                    key.append(SBuf(request->urlpath.substr(pos,request->urlpath.size())));
+                // XXX: fix when path and query are separate
+                SBuf::size_type pos;
+                if ((pos=request->url.path().find('?')) != SBuf::npos)
+                    key.append(request->url.path().substr(pos)); // N..npos
             }
         }
         // if the url-based key is empty, e.g. because the user is
         // asking to balance on the path but the request doesn't supply any,
         // then fall back to canonical URL
 
         if (key.isEmpty())
             key=SBuf(urlCanonical(request));
 
         for (const char *c = key.rawContent(), *e=key.rawContent()+key.length(); c < e; ++c)
             user_hash += ROTATE_LEFT(user_hash, 19) + *c;
         combined_hash = (user_hash ^ tp->carp.hash);
         combined_hash += combined_hash * 0x62531965;
         combined_hash = ROTATE_LEFT(combined_hash, 21);
         score = combined_hash * tp->carp.load_multiplier;
         debugs(39, 3, "carpSelectParent: key=" << key << " name=" << tp->name << " combined_hash=" << combined_hash  <<
                " score=" << std::setprecision(0) << score);
 
         if ((score > high_score) && peerHTTPOkay(tp, request)) {
             p = tp;

=== modified file 'src/client_side.cc'
--- src/client_side.cc	2015-06-09 06:14:43 +0000
+++ src/client_side.cc	2015-06-18 09:50:39 +0000
@@ -2186,83 +2186,80 @@
            ", mime-header-size=" << hp->headerBlockSize() <<
            ", mime header block:\n" << hp->mimeHeader() << "\n----------");
 
     /* Ok, all headers are received */
     ClientHttpRequest *http = new ClientHttpRequest(csd);
 
     http->req_sz = hp->messageHeaderSize();
     ClientSocketContext *result = new ClientSocketContext(csd->clientConnection, http);
 
     StoreIOBuffer tempBuffer;
     tempBuffer.data = result->reqbuf;
     tempBuffer.length = HTTP_REQBUF_SZ;
 
     ClientStreamData newServer = new clientReplyContext(http);
     ClientStreamData newClient = result;
     clientStreamInit(&http->client_stream, clientGetMoreData, clientReplyDetach,
                      clientReplyStatus, newServer, clientSocketRecipient,
                      clientSocketDetach, newClient, tempBuffer);
 
     /* set url */
-    // XXX: c_str() does re-allocate but here replaces explicit malloc/free.
-    // when internalCheck() accepts SBuf removing this will be a net gain for performance.
-    SBuf tmp(hp->requestUri());
-    const char *url = tmp.c_str();
-
     debugs(33,5, "Prepare absolute URL from " <<
            (csd->transparent()?"intercept":(csd->port->flags.accelSurrogate ? "accel":"")));
     /* Rewrite the URL in transparent or accelerator mode */
     /* NP: there are several cases to traverse here:
      *  - standard mode (forward proxy)
      *  - transparent mode (TPROXY)
      *  - transparent mode with failures
      *  - intercept mode (NAT)
      *  - intercept mode with failures
      *  - accelerator mode (reverse proxy)
-     *  - internal URL
+     *  - internal relative-URL
      *  - mixed combos of the above with internal URL
      *  - remote interception with PROXY protocol
      *  - remote reverse-proxy with PROXY protocol
      */
     if (csd->transparent()) {
         /* intercept or transparent mode, properly working with no failures */
         prepareTransparentURL(csd, http, hp);
 
-    } else if (internalCheck(url)) {
+    } else if (internalCheck(hp->requestUri())) { // NP: only matches relative-URI
         /* internal URL mode */
         /* prepend our name & port */
-        http->uri = xstrdup(internalLocalUri(NULL, url));
+        http->uri = xstrdup(internalLocalUri(NULL, hp->requestUri()));
         // We just re-wrote the URL. Must replace the Host: header.
         //  But have not parsed there yet!! flag for local-only handling.
         http->flags.internal = true;
 
     } else if (csd->port->flags.accelSurrogate || csd->switchedToHttps()) {
         /* accelerator mode */
         prepareAcceleratedURL(csd, http, hp);
     }
 
     if (!http->uri) {
         /* No special rewrites have been applied above, use the
          * requested url. may be rewritten later, so make extra room */
         int url_sz = hp->requestUri().length() + Config.appendDomainLen + 5;
         http->uri = (char *)xcalloc(url_sz, 1);
-        strcpy(http->uri, url);
+        // XXX: c_str() does re-allocate but here replaces explicit malloc/free.
+        SBuf tmp(hp->requestUri());
+        strcpy(http->uri, tmp.c_str());
     }
 
     result->flags.parsed_ok = 1;
     return result;
 }
 
 bool
 ConnStateData::In::maybeMakeSpaceAvailable()
 {
     if (buf.spaceSize() < 2) {
         const SBuf::size_type haveCapacity = buf.length() + buf.spaceSize();
         if (haveCapacity >= Config.maxRequestBufferSize) {
             debugs(33, 4, "request buffer full: client_request_buffer_max_size=" << Config.maxRequestBufferSize);
             return false;
         }
         if (haveCapacity == 0) {
             // haveCapacity is based on the SBuf visible window of the MemBlob buffer, which may fill up.
             // at which point bump the buffer back to default. This allocates a new MemBlob with any un-parsed bytes.
             buf.reserveCapacity(CLIENT_REQ_BUF_SZ);
         } else {
@@ -2546,45 +2543,45 @@
 
     /** \par
      * If transparent or interception mode is working clone the transparent and interception flags
      * from the port settings to the request.
      */
     if (http->clientConnection != NULL) {
         request->flags.intercepted = ((http->clientConnection->flags & COMM_INTERCEPTION) != 0);
         request->flags.interceptTproxy = ((http->clientConnection->flags & COMM_TRANSPARENT) != 0 ) ;
         static const bool proxyProtocolPort = (conn->port != NULL) ? conn->port->flags.proxySurrogate : false;
         if (request->flags.interceptTproxy && !proxyProtocolPort) {
             if (Config.accessList.spoof_client_ip) {
                 ACLFilledChecklist *checklist = clientAclChecklistCreate(Config.accessList.spoof_client_ip, http);
                 request->flags.spoofClientIp = (checklist->fastCheck() == ACCESS_ALLOWED);
                 delete checklist;
             } else
                 request->flags.spoofClientIp = true;
         } else
             request->flags.spoofClientIp = false;
     }
 
-    if (internalCheck(request->urlpath.termedBuf())) {
+    if (internalCheck(request->url.path())) {
         if (internalHostnameIs(request->url.host()) && request->url.port() == getMyPort()) {
             debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->url.authority(true));
             http->flags.internal = true;
-        } else if (Config.onoff.global_internal_static && internalStaticCheck(request->urlpath.termedBuf())) {
+        } else if (Config.onoff.global_internal_static && internalStaticCheck(request->url.path())) {
             debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->url.authority(true) << " (global_internal_static on)");
             request->url.setScheme(AnyP::PROTO_HTTP);
             request->SetHost(internalHostname());
             request->url.port(getMyPort());
             http->flags.internal = true;
         } else
             debugs(33, 2, "internal URL found: " << request->url.getScheme() << "://" << request->url.authority(true) << " (not this proxy)");
     }
 
     request->flags.internal = http->flags.internal;
     setLogUri (http, urlCanonicalClean(request.getRaw()));
     request->client_addr = conn->clientConnection->remote; // XXX: remove reuest->client_addr member.
 #if FOLLOW_X_FORWARDED_FOR
     // indirect client gets stored here because it is an HTTP header result (from X-Forwarded-For:)
     // not a details about teh TCP connection itself
     request->indirect_client_addr = conn->clientConnection->remote;
 #endif /* FOLLOW_X_FORWARDED_FOR */
     request->my_addr = conn->clientConnection->local;
     request->myportname = conn->port->name;
 

=== modified file 'src/clients/FtpGateway.cc'
--- src/clients/FtpGateway.cc	2015-06-22 11:52:31 +0000
+++ src/clients/FtpGateway.cc	2015-06-28 06:51:22 +0000
@@ -1064,127 +1064,125 @@
     if (password[0])
         return 1;
 
     /* Setup default FTP password settings */
     /* this has to be done last so that we can have a no-password case above. */
     if (!password[0]) {
         if (strcmp(user, "anonymous") == 0 && !flags.tried_auth_anonymous) {
             xstrncpy(password, Config.Ftp.anon_user, MAX_URL);
             flags.tried_auth_anonymous=1;
             return 1;
         } else if (!flags.tried_auth_nopass) {
             xstrncpy(password, null_string, MAX_URL);
             flags.tried_auth_nopass=1;
             return 1;
         }
     }
 
     return 0;           /* different username */
 }
 
-static String str_type_eq;
 void
 Ftp::Gateway::checkUrlpath()
 {
-    int l;
-    size_t t;
+    static SBuf str_type_eq("type=");
+    auto t = request->url.path().rfind(';');
 
-    if (str_type_eq.size()==0) //hack. String doesn't support global-static
-        str_type_eq="type=";
-
-    if ((t = request->urlpath.rfind(';')) != String::npos) {
-        if (request->urlpath.substr(t+1,t+1+str_type_eq.size())==str_type_eq) {
-            typecode = (char)xtoupper(request->urlpath[t+str_type_eq.size()+1]);
-            request->urlpath.cut(t);
+    if (t != SBuf::npos) {
+        auto filenameEnd = t-1;
+        if (request->url.path().substr(++t).cmp(str_type_eq, str_type_eq.length()) == 0) {
+            t += str_type_eq.length();
+            typecode = (char)xtoupper(request->url.path()[t]);
+            request->url.path(request->url.path().substr(0,filenameEnd));
         }
     }
 
-    l = request->urlpath.size();
+    int l = request->url.path().length();
     /* check for null path */
 
     if (!l) {
         flags.isdir = 1;
         flags.root_dir = 1;
         flags.need_base_href = 1;   /* Work around broken browsers */
-    } else if (!request->urlpath.cmp("/%2f/")) {
+    } else if (!request->url.path().cmp("/%2f/")) {
         /* UNIX root directory */
         flags.isdir = 1;
         flags.root_dir = 1;
-    } else if ((l >= 1) && (request->urlpath[l - 1] == '/')) {
+    } else if ((l >= 1) && (request->url.path()[l-1] == '/')) {
         /* Directory URL, ending in / */
         flags.isdir = 1;
 
         if (l == 1)
             flags.root_dir = 1;
     } else {
         flags.dir_slash = 1;
     }
 }
 
 void
 Ftp::Gateway::buildTitleUrl()
 {
     title_url = "ftp://";
 
     if (strcmp(user, "anonymous")) {
         title_url.append(user);
         title_url.append("@");
     }
 
     SBuf authority = request->url.authority(request->url.getScheme() != AnyP::PROTO_FTP);
 
     title_url.append(authority.rawContent(), authority.length());
-    title_url.append(request->urlpath);
+    title_url.append(request->url.path().rawContent(), request->url.path().length());
 
     base_href = "ftp://";
 
     if (strcmp(user, "anonymous") != 0) {
         base_href.append(rfc1738_escape_part(user));
 
         if (password_url) {
             base_href.append(":");
             base_href.append(rfc1738_escape_part(password));
         }
 
         base_href.append("@");
     }
 
     base_href.append(authority.rawContent(), authority.length());
-    base_href.append(request->urlpath);
+    base_href.append(request->url.path().rawContent(), request->url.path().length());
     base_href.append("/");
 }
 
 void
 Ftp::Gateway::start()
 {
     if (!checkAuth(&request->header)) {
         /* create appropriate reply */
         HttpReply *reply = ftpAuthRequired(request, ftpRealm());
         entry->replaceHttpReply(reply);
         serverComplete();
         return;
     }
 
     checkUrlpath();
     buildTitleUrl();
-    debugs(9, 5, HERE << "FD " << ctrl.conn->fd << " : host=" << request->url.host() <<
-           ", path=" << request->urlpath << ", user=" << user << ", passwd=" << password);
+    debugs(9, 5, "FD " << ctrl.conn->fd << " : host=" << request->url.host() <<
+           ", path=" << request->url.path() << ", user=" << user << ", passwd=" << password);
     state = BEGIN;
     Ftp::Client::start();
 }
 
 /* ====================================================================== */
 
 void
 Ftp::Gateway::handleControlReply()
 {
     Ftp::Client::handleControlReply();
     if (ctrl.message == NULL)
         return; // didn't get complete reply yet
 
     /* Copy the message except for the last line to cwd_message to be
      * printed in error messages.
      */
     for (wordlist *w = ctrl.message; w && w->next; w = w->next) {
         cwd_message.append('\n');
         cwd_message.append(w->key);
     }
@@ -1348,99 +1346,98 @@
     ftpState->writeCommand(cbuf);
     ftpState->state = Ftp::Client::SENT_PASS;
 }
 
 static void
 ftpReadPass(Ftp::Gateway * ftpState)
 {
     int code = ftpState->ctrl.replycode;
     debugs(9, 3, HERE << "code=" << code);
 
     if (code == 230) {
         ftpSendType(ftpState);
     } else {
         ftpState->loginFailed();
     }
 }
 
 static void
 ftpSendType(Ftp::Gateway * ftpState)
 {
-    const char *t;
-    const char *filename;
-    char mode;
-
     /* check the server control channel is still available */
     if (!ftpState || !ftpState->haveControlChannel("ftpSendType"))
         return;
 
     /*
      * Ref section 3.2.2 of RFC 1738
      */
-    mode = ftpState->typecode;
+    char mode = ftpState->typecode;
 
     switch (mode) {
 
     case 'D':
         mode = 'A';
         break;
 
     case 'A':
 
     case 'I':
         break;
 
     default:
 
         if (ftpState->flags.isdir) {
             mode = 'A';
         } else {
-            t = ftpState->request->urlpath.rpos('/');
-            filename = t ? t + 1 : ftpState->request->urlpath.termedBuf();
-            mode = mimeGetTransferMode(filename);
+            auto t = ftpState->request->url.path().rfind('/');
+            // XXX: performance regression, c_str() may reallocate
+            SBuf filename = ftpState->request->url.path().substr(t != SBuf::npos ? t + 1 : 0);
+            mode = mimeGetTransferMode(filename.c_str());
         }
 
         break;
     }
 
     if (mode == 'I')
         ftpState->flags.binary = 1;
     else
         ftpState->flags.binary = 0;
 
     snprintf(cbuf, CTRL_BUFLEN, "TYPE %c\r\n", mode);
 
     ftpState->writeCommand(cbuf);
 
     ftpState->state = Ftp::Client::SENT_TYPE;
 }
 
 static void
 ftpReadType(Ftp::Gateway * ftpState)
 {
     int code = ftpState->ctrl.replycode;
     char *path;
     char *d, *p;
     debugs(9, 3, HERE << "code=" << code);
 
     if (code == 200) {
-        p = path = xstrdup(ftpState->request->urlpath.termedBuf());
+        // XXX: performance regression, c_str() may reallocate
+        SBuf tmp = ftpState->request->url.path();
+        p = path = xstrndup(tmp.c_str(),tmp.length());
 
         if (*p == '/')
             ++p;
 
         while (*p) {
             d = p;
             p += strcspn(p, "/");
 
             if (*p) {
                 *p = '\0';
                 ++p;
             }
 
             rfc1738_unescape(d);
 
             if (*d)
                 wordlistAdd(&ftpState->pathcomps, d);
         }
 
         xfree(path);
@@ -2351,41 +2348,43 @@
 ftpReadQuit(Ftp::Gateway * ftpState)
 {
     ftpState->serverComplete();
 }
 
 static void
 ftpTrySlashHack(Ftp::Gateway * ftpState)
 {
     char *path;
     ftpState->flags.try_slash_hack = 1;
     /* Free old paths */
 
     debugs(9, 3, HERE);
 
     if (ftpState->pathcomps)
         wordlistDestroy(&ftpState->pathcomps);
 
     safe_free(ftpState->filepath);
 
     /* Build the new path (urlpath begins with /) */
-    path = xstrdup(ftpState->request->urlpath.termedBuf());
+    // XXX: performance regression. c_str() may reallocate, then xstrdup repeats.
+    SBuf tmp = ftpState->request->url.path();
+    path = xstrdup(tmp.c_str());
 
     rfc1738_unescape(path);
 
     ftpState->filepath = path;
 
     /* And off we go */
     ftpGetFile(ftpState);
 }
 
 /**
  * Forget hack status. Next error is shown to the user
  */
 void
 Ftp::Gateway::unhack()
 {
     debugs(9, 3, HERE);
 
     if (old_request != NULL) {
         safe_free(old_request);
         safe_free(old_reply);
@@ -2402,51 +2401,51 @@
 
     debugs(9, 3, HERE);
 
     if (old_request == NULL) {
         old_request = ctrl.last_command;
         ctrl.last_command = NULL;
         old_reply = ctrl.last_reply;
         ctrl.last_reply = NULL;
 
         if (pathcomps == NULL && filepath != NULL)
             old_filepath = xstrdup(filepath);
     }
 
     /* Jump to the "hack" state */
     nextState(this);
 }
 
 static void
 ftpFail(Ftp::Gateway *ftpState)
 {
-    debugs(9, 6, HERE << "flags(" <<
+    const bool slashHack = ftpState->request->url.path().caseCmp("/%2f", 4)==0;
+    debugs(9, 6, "flags(" <<
            (ftpState->flags.isdir?"IS_DIR,":"") <<
            (ftpState->flags.try_slash_hack?"TRY_SLASH_HACK":"") << "), " <<
            "mdtm=" << ftpState->mdtm << ", size=" << ftpState->theSize <<
-           "slashhack=" << (ftpState->request->urlpath.caseCmp("/%2f", 4)==0? "T":"F") );
+           "slashhack=" << (slashHack? "T":"F") );
 
     /* Try the / hack to support "Netscape" FTP URL's for retreiving files */
     if (!ftpState->flags.isdir &&   /* Not a directory */
-            !ftpState->flags.try_slash_hack &&  /* Not in slash hack */
-            ftpState->mdtm <= 0 && ftpState->theSize < 0 && /* Not known as a file */
-            ftpState->request->urlpath.caseCmp("/%2f", 4) != 0) {   /* No slash encoded */
+            !ftpState->flags.try_slash_hack && !slashHack && /* Not doing slash hack */
+            ftpState->mdtm <= 0 && ftpState->theSize < 0) { /* Not known as a file */
 
         switch (ftpState->state) {
 
         case Ftp::Client::SENT_CWD:
 
         case Ftp::Client::SENT_RETR:
             /* Try the / hack */
             ftpState->hackShortcut(ftpTrySlashHack);
             return;
 
         default:
             break;
         }
     }
 
     ftpState->failed(ERR_NONE, 0);
     /* failed() closes ctrl.conn and frees this */
 }
 
 Http::StatusCode
@@ -2515,80 +2514,81 @@
         err.ftp.request = xstrdup(ftpState->ctrl.last_command);
 
     if (ftpState->old_reply)
         err.ftp.reply = xstrdup(ftpState->old_reply);
     else if (ftpState->ctrl.last_reply)
         err.ftp.reply = xstrdup(ftpState->ctrl.last_reply);
     else
         err.ftp.reply = xstrdup("");
 
     // TODO: interpret as FTP-specific error code
     err.detailError(code);
 
     ftpState->entry->replaceHttpReply( err.BuildHttpReply() );
 
     ftpSendQuit(ftpState);
 }
 
 void
 Ftp::Gateway::appendSuccessHeader()
 {
-    const char *mime_type = NULL;
-    const char *mime_enc = NULL;
-    String urlpath = request->urlpath;
-    const char *filename = NULL;
-    const char *t = NULL;
-
     debugs(9, 3, HERE);
 
     if (flags.http_header_sent)
         return;
 
     HttpReply *reply = new HttpReply;
 
     flags.http_header_sent = 1;
 
     assert(entry->isEmpty());
 
     EBIT_CLR(entry->flags, ENTRY_FWD_HDR_WAIT);
 
     entry->buffer();    /* released when done processing current data payload */
 
-    filename = (t = urlpath.rpos('/')) ? t + 1 : urlpath.termedBuf();
+    SBuf urlPath = request->url.path();
+    auto t = urlPath.rfind('/');
+    SBuf filename = urlPath.substr(t != SBuf::npos ? t : 0);
+
+    const char *mime_type = NULL;
+    const char *mime_enc = NULL;
 
     if (flags.isdir) {
         mime_type = "text/html";
     } else {
         switch (typecode) {
 
         case 'I':
             mime_type = "application/octet-stream";
-            mime_enc = mimeGetContentEncoding(filename);
+            // XXX: performance regression, c_str() may reallocate
+            mime_enc = mimeGetContentEncoding(filename.c_str());
             break;
 
         case 'A':
             mime_type = "text/plain";
             break;
 
         default:
-            mime_type = mimeGetContentType(filename);
-            mime_enc = mimeGetContentEncoding(filename);
+            // XXX: performance regression, c_str() may reallocate
+            mime_type = mimeGetContentType(filename.c_str());
+            mime_enc = mimeGetContentEncoding(filename.c_str());
             break;
         }
     }
 
     /* set standard stuff */
 
     if (0 == getCurrentOffset()) {
         /* Full reply */
         reply->setHeaders(Http::scOkay, "Gatewaying", mime_type, theSize, mdtm, -2);
     } else if (theSize < getCurrentOffset()) {
         /*
          * DPW 2007-05-04
          * offset should not be larger than theSize.  We should
          * not be seeing this condition any more because we'll only
          * send REST if we know the theSize and if it is less than theSize.
          */
         debugs(0,DBG_CRITICAL,HERE << "Whoops! " <<
                " current offset=" << getCurrentOffset() <<
                ", but theSize=" << theSize <<
                ".  assuming full content response");
@@ -2629,52 +2629,52 @@
     } else {
         e->release();
     }
 }
 
 HttpReply *
 Ftp::Gateway::ftpAuthRequired(HttpRequest * request, const char *realm)
 {
     ErrorState err(ERR_CACHE_ACCESS_DENIED, Http::scUnauthorized, request);
     HttpReply *newrep = err.BuildHttpReply();
 #if HAVE_AUTH_MODULE_BASIC
     /* add Authenticate header */
     newrep->header.putAuth("Basic", realm);
 #endif
     return newrep;
 }
 
 const char *
 Ftp::UrlWith2f(HttpRequest * request)
 {
-    String newbuf = "%2f";
+    SBuf newbuf("%2f");
 
     if (request->url.getScheme() != AnyP::PROTO_FTP)
         return NULL;
 
-    if ( request->urlpath[0]=='/' ) {
-        newbuf.append(request->urlpath);
-        request->urlpath.absorb(newbuf);
+    if (request->url.path()[0] == '/') {
+        newbuf.append(request->url.path());
+        request->url.path(newbuf);
         safe_free(request->canonical);
-    } else if ( !strncmp(request->urlpath.termedBuf(), "%2f", 3) ) {
-        newbuf.append(request->urlpath.substr(1,request->urlpath.size()));
-        request->urlpath.absorb(newbuf);
+    } else if (!request->url.path().cmp(newbuf, 3)) {
+        newbuf.append(request->url.path().substr(1));
+        request->url.path(newbuf);
         safe_free(request->canonical);
     }
 
     return urlCanonical(request);
 }
 
 void
 Ftp::Gateway::printfReplyBody(const char *fmt, ...)
 {
     va_list args;
     va_start (args, fmt);
     static char buf[4096];
     buf[0] = '\0';
     vsnprintf(buf, 4096, fmt, args);
     writeReplyBody(buf, strlen(buf));
     va_end(args);
 }
 
 /**
  * Call this when there is data from the origin server

=== modified file 'src/errorpage.cc'
--- src/errorpage.cc	2015-06-09 06:14:43 +0000
+++ src/errorpage.cc	2015-06-28 07:04:07 +0000
@@ -718,52 +718,44 @@
 #if USE_AUTH
     if (auth_user_request.getRaw() && auth_user_request->denyMessage())
         str.appendf("Auth ErrMsg: %s\r\n", auth_user_request->denyMessage());
 #endif
     if (dnsError.size() > 0)
         str.appendf("DNS ErrMsg: %s\r\n", dnsError.termedBuf());
 
     /* - TimeStamp */
     str.appendf("TimeStamp: %s\r\n\r\n", mkrfc1123(squid_curtime));
 
     /* - IP stuff */
     str.appendf("ClientIP: %s\r\n", src_addr.toStr(ntoabuf,MAX_IPSTRLEN));
 
     if (request && request->hier.host[0] != '\0') {
         str.appendf("ServerIP: %s\r\n", request->hier.host);
     }
 
     str.append("\r\n", 2);
     /* - HTTP stuff */
     str.append("HTTP Request:\r\n", 15);
-
-    if (NULL != request) {
-        String urlpath_or_slash;
-
-        if (request->urlpath.size() != 0)
-            urlpath_or_slash = request->urlpath;
-        else
-            urlpath_or_slash = "/";
-
-        str.appendf(SQUIDSBUFPH " " SQUIDSTRINGPH " %s/%d.%d\n",
+    if (request) {
+        str.appendf(SQUIDSBUFPH " " SQUIDSBUFPH " %s/%d.%d\n",
                     SQUIDSBUFPRINT(request->method.image()),
-                    SQUIDSTRINGPRINT(urlpath_or_slash),
+                    SQUIDSBUFPRINT(request->url.path()),
                     AnyP::ProtocolType_str[request->http_ver.protocol],
                     request->http_ver.major, request->http_ver.minor);
         request->header.packInto(&str);
     }
 
     str.append("\r\n", 2);
     /* - FTP stuff */
 
     if (ftp.request) {
         str.appendf("FTP Request: %s\r\n", ftp.request);
         str.appendf("FTP Reply: %s\r\n", (ftp.reply? ftp.reply:"[none]"));
         str.append("FTP Msg: ", 9);
         wordlistCat(ftp.server_msg, &str);
         str.append("\r\n", 2);
     }
 
     str.append("\r\n", 2);
     mb->appendf("&body=%s", rfc1738_escape_part(str.buf));
     str.clean();
     return 0;
@@ -936,57 +928,51 @@
 
     case 'p':
         if (request) {
             mb.appendf("%u", request->url.port());
         } else if (!building_deny_info_url) {
             p = "[unknown port]";
         }
         break;
 
     case 'P':
         if (request) {
             p = request->url.getScheme().c_str();
         } else if (!building_deny_info_url) {
             p = "[unknown protocol]";
         }
         break;
 
     case 'R':
         if (building_deny_info_url) {
             if (request != NULL) {
-                p = (request->urlpath.size() != 0 ? request->urlpath.termedBuf() : "/");
+                SBuf tmp = request->url.path();
+                p = tmp.c_str();
                 no_urlescape = 1;
             } else
                 p = "[no request]";
             break;
         }
-        if (NULL != request) {
-            String urlpath_or_slash;
-
-            if (request->urlpath.size() != 0)
-                urlpath_or_slash = request->urlpath;
-            else
-                urlpath_or_slash = "/";
-
-            mb.appendf(SQUIDSBUFPH " " SQUIDSTRINGPH " %s/%d.%d\n",
+        if (request != NULL) {
+            mb.appendf(SQUIDSBUFPH " " SQUIDSBUFPH " %s/%d.%d\n",
                        SQUIDSBUFPRINT(request->method.image()),
-                       SQUIDSTRINGPRINT(urlpath_or_slash),
+                       SQUIDSBUFPRINT(request->url.path()),
                        AnyP::ProtocolType_str[request->http_ver.protocol],
                        request->http_ver.major, request->http_ver.minor);
             request->header.packInto(&mb, true); //hide authorization data
         } else if (request_hdrs) {
             p = request_hdrs;
         } else {
             p = "[no request]";
         }
         break;
 
     case 's':
         /* for backward compat we make %s show the full URL. Drop this in some future release. */
         if (building_deny_info_url) {
             p = request ? urlCanonical(request) : url;
             debugs(0, DBG_CRITICAL, "WARNING: deny_info now accepts coded tags. Use %u to get the full URL instead of %s");
         } else
             p = visible_appname_string;
         break;
 
     case 'S':

=== modified file 'src/external_acl.cc'
--- src/external_acl.cc	2015-06-09 06:14:43 +0000
+++ src/external_acl.cc	2015-06-28 07:03:42 +0000
@@ -961,42 +961,44 @@
             str = buf;
             break;
 
         case Format::LFT_CLIENT_REQ_URI:
             str = urlCanonical(request);
             break;
 
         case Format::LFT_CLIENT_REQ_URLDOMAIN:
             str = request->url.host();
             break;
 
         case Format::LFT_CLIENT_REQ_URLSCHEME:
             str = request->url.getScheme().c_str();
             break;
 
         case Format::LFT_CLIENT_REQ_URLPORT:
             snprintf(buf, sizeof(buf), "%u", request->url.port());
             str = buf;
             break;
 
-        case Format::LFT_CLIENT_REQ_URLPATH:
-            str = request->urlpath.termedBuf();
+        case Format::LFT_CLIENT_REQ_URLPATH: {
+                SBuf tmp = request->url.path();
+                str = tmp.c_str();
+            }
             break;
 
         case Format::LFT_CLIENT_REQ_METHOD: {
             const SBuf &s = request->method.image();
             sb.append(s.rawContent(), s.length());
         }
         str = sb.termedBuf();
         break;
 
         case Format::LFT_ADAPTED_REQUEST_HEADER:
             if (format->header_id == -1)
                 sb = request->header.getByName(format->header);
             else
                 sb = request->header.getStrOrList(format->header_id);
             str = sb.termedBuf();
             break;
 
         case Format::LFT_ADAPTED_REQUEST_HEADER_ELEM:
             if (format->header_id == -1)
                 sb = request->header.getByNameListMember(format->header, format->member, format->separator);

=== modified file 'src/format/Format.cc'
--- src/format/Format.cc	2015-06-09 06:14:43 +0000
+++ src/format/Format.cc	2015-06-09 12:13:49 +0000
@@ -954,41 +954,42 @@
             }
             break;
 
         case LFT_CLIENT_REQ_URLDOMAIN:
             if (al->request) {
                 out = al->request->url.host();
                 quote = 1;
             }
             break;
 
         case LFT_CLIENT_REQ_URLPORT:
             if (al->request) {
                 outint = al->request->url.port();
                 doint = 1;
             }
             break;
 
         case LFT_REQUEST_URLPATH_OLD_31:
         case LFT_CLIENT_REQ_URLPATH:
             if (al->request) {
-                out = al->request->urlpath.termedBuf();
+                SBuf s = al->request->url.path();
+                out = s.c_str();
                 quote = 1;
             }
             break;
 
         case LFT_CLIENT_REQ_VERSION:
             if (al->request) {
                 snprintf(tmp, sizeof(tmp), "%d.%d", (int) al->request->http_ver.major, (int) al->request->http_ver.minor);
                 out = tmp;
             }
             break;
 
         case LFT_REQUEST_METHOD:
             if (al->_private.method_str) // ICP, HTCP method code
                 out = al->_private.method_str;
             else {
                 const SBuf &s = al->http.method.image();
                 sb.append(s.rawContent(), s.length());
                 out = sb.termedBuf();
                 quote = 1;
             }
@@ -1027,41 +1028,42 @@
                 quote = 1;
             }
             break;
 
         case LFT_SERVER_REQ_URLDOMAIN:
             if (al->adapted_request) {
                 out = al->adapted_request->url.host();
                 quote = 1;
             }
             break;
 
         case LFT_SERVER_REQ_URLPORT:
             if (al->adapted_request) {
                 outint = al->adapted_request->url.port();
                 doint = 1;
             }
             break;
 
         case LFT_SERVER_REQ_URLPATH:
             if (al->adapted_request) {
-                out = al->adapted_request->urlpath.termedBuf();
+                SBuf s = al->adapted_request->url.path();
+                out = s.c_str();
                 quote = 1;
             }
             break;
 
         case LFT_SERVER_REQ_VERSION:
             if (al->adapted_request) {
                 snprintf(tmp, sizeof(tmp), "%d.%d",
                          (int) al->adapted_request->http_ver.major,
                          (int) al->adapted_request->http_ver.minor);
                 out = tmp;
             }
             break;
 
         case LFT_CLIENT_REQUEST_SIZE_TOTAL:
             outoff = al->http.clientRequestSz.messageTotal();
             dooff = 1;
             break;
 
         case LFT_CLIENT_REQUEST_SIZE_HEADERS:
             outoff = al->http.clientRequestSz.header;

=== modified file 'src/gopher.cc'
--- src/gopher.cc	2015-06-09 06:14:43 +0000
+++ src/gopher.cc	2015-06-14 22:04:38 +0000
@@ -4,40 +4,41 @@
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 /* DEBUG: section 10    Gopher */
 
 #include "squid.h"
 #include "comm.h"
 #include "comm/Read.h"
 #include "comm/Write.h"
 #include "errorpage.h"
 #include "fd.h"
 #include "FwdState.h"
 #include "globals.h"
 #include "html_quote.h"
 #include "HttpReply.h"
 #include "HttpRequest.h"
 #include "MemBuf.h"
 #include "mime.h"
+#include "parser/Tokenizer.h"
 #include "rfc1738.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
 #include "StatCounters.h"
 #include "Store.h"
 #include "tools.h"
 
 #if USE_DELAY_POOLS
 #include "DelayPools.h"
 #include "MemObject.h"
 #endif
 
 /* gopher type code from rfc. Anawat. */
 #define GOPHER_FILE         '0'
 #define GOPHER_DIRECTORY    '1'
 #define GOPHER_CSO          '2'
 #define GOPHER_ERROR        '3'
 #define GOPHER_MACBINHEX    '4'
 #define GOPHER_DOSBIN       '5'
 #define GOPHER_UUENCODED    '6'
@@ -236,57 +237,61 @@
     }
 
     assert(entry->isEmpty());
     EBIT_CLR(entry->flags, ENTRY_FWD_HDR_WAIT);
 
     HttpReply *reply = new HttpReply;
     entry->buffer();
     reply->setHeaders(Http::scOkay, "Gatewaying", mime_type, -1, -1, -2);
     if (mime_enc)
         reply->header.putStr(HDR_CONTENT_ENCODING, mime_enc);
 
     entry->replaceHttpReply(reply);
 }
 
 /**
  * Parse a gopher request into components.  By Anawat.
  */
 static void
 gopher_request_parse(const HttpRequest * req, char *type_id, char *request)
 {
-    const char *path = req->urlpath.termedBuf();
+    ::Parser::Tokenizer tok(req->url.path());
 
     if (request)
-        request[0] = '\0';
+        *request = 0;
 
-    if (path && (*path == '/'))
-        ++path;
+    tok.skip('/'); // ignore failures? path could be ab-empty
 
-    if (!path || !*path) {
+    if (tok.atEnd()) {
         *type_id = GOPHER_DIRECTORY;
         return;
     }
 
-    *type_id = path[0];
+    static const CharacterSet anyByte("UTF-8",0x00, 0xFF);
+
+    SBuf typeId;
+    (void)tok.prefix(typeId, anyByte, 1); // never fails since !atEnd()
+    *type_id = typeId[0];
 
     if (request) {
-        xstrncpy(request, path + 1, MAX_URL);
+        SBuf path = tok.remaining();
+        xstrncpy(request, path.c_str(), MAX_URL);
         /* convert %xx to char */
         rfc1738_unescape(request);
     }
 }
 
 /**
  * Parse the request to determine whether it is cachable.
  *
  * \param req   Request data.
  * \retval 0    Not cachable.
  * \retval 1    Cachable.
  */
 int
 gopherCachable(const HttpRequest * req)
 {
     int cachable = 1;
     char type_id;
     /* parse to see type */
     gopher_request_parse(req,
                          &type_id,

=== modified file 'src/http.cc'
--- src/http.cc	2015-06-19 07:13:57 +0000
+++ src/http.cc	2015-06-19 07:20:11 +0000
@@ -1292,62 +1292,61 @@
     if (!flags.headers_parsed && !eof) {
         debugs(11, 9, "needs more at " << inBuf.length());
         flags.do_next_read = true;
         /** \retval false If we have not finished parsing the headers and may get more data.
          *                Schedules more reads to retrieve the missing data.
          */
         maybeReadVirginBody(); // schedules all kinds of reads; TODO: rename
         return false;
     }
 
     /** If we are done with parsing, check for errors */
 
     err_type error = ERR_NONE;
 
     if (flags.headers_parsed) { // parsed headers, possibly with errors
         // check for header parsing errors
         if (HttpReply *vrep = virginReply()) {
             const Http::StatusCode s = vrep->sline.status();
             const AnyP::ProtocolVersion &v = vrep->sline.version;
             if (s == Http::scInvalidHeader && v != Http::ProtocolVersion(0,9)) {
-                debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: Bad header encountered from " << entry->url() << " AKA " << request->url.host() << request->urlpath.termedBuf());
+                debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: Bad header encountered from " << entry->url() << " AKA " << request->url);
                 error = ERR_INVALID_RESP;
             } else if (s == Http::scHeaderTooLarge) {
                 fwd->dontRetry(true);
                 error = ERR_TOO_BIG;
             } else {
                 return true; // done parsing, got reply, and no error
             }
         } else {
             // parsed headers but got no reply
-            debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: No reply at all for " << entry->url() << " AKA " << request->url.host() << request->urlpath.termedBuf());
+            debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: No reply at all for " << entry->url() << " AKA " << request->url);
             error = ERR_INVALID_RESP;
         }
     } else {
         assert(eof);
         if (inBuf.length()) {
             error = ERR_INVALID_RESP;
-            debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: Headers did not parse at all for " << entry->url() << " AKA " << request->url.host() << request->urlpath.termedBuf());
+            debugs(11, DBG_IMPORTANT, "WARNING: HTTP: Invalid Response: Headers did not parse at all for " << entry->url() << " AKA " << request->url);
         } else {
             error = ERR_ZERO_SIZE_OBJECT;
-            debugs(11, (request->flags.accelerated?DBG_IMPORTANT:2), "WARNING: HTTP: Invalid Response: No object data received for " <<
-                   entry->url() << " AKA " << request->url.host() << request->urlpath.termedBuf());
+            debugs(11, (request->flags.accelerated?DBG_IMPORTANT:2), "WARNING: HTTP: Invalid Response: No object data received for " << entry->url() << " AKA " << request->url);
         }
     }
 
     assert(error != ERR_NONE);
     entry->reset();
     fwd->fail(new ErrorState(error, Http::scBadGateway, fwd->request));
     flags.do_next_read = false;
     serverConnection->close();
     return false; // quit on error
 }
 
 /** truncate what we read if we read too much so that writeReplyBody()
     writes no more than what we should have read */
 void
 HttpStateData::truncateVirginBody()
 {
     assert(flags.headers_parsed);
 
     HttpReply *vrep = virginReply();
     int64_t clen = -1;
@@ -2150,45 +2149,48 @@
 
     return result;
 }
 
 /* build request prefix and append it to a given MemBuf;
  * return the length of the prefix */
 mb_size_t
 HttpStateData::buildRequestPrefix(MemBuf * mb)
 {
     const int offset = mb->size;
     /* Uses a local httpver variable to print the HTTP label
      * since the HttpRequest may have an older version label.
      * XXX: This could create protocol bugs as the headers sent and
      * flow control should all be based on the HttpRequest version
      * not the one we are sending. Needs checking.
      */
     const AnyP::ProtocolVersion httpver = Http::ProtocolVersion();
     const char * url;
     if (_peer && !_peer->options.originserver)
         url = urlCanonical(request);
-    else
-        url = request->urlpath.termedBuf();
+    else {
+        // XXX: performance regression, c_str() reallocates
+        SBuf tmp = request->url.path();
+        url = tmp.c_str();
+    }
     mb->appendf(SQUIDSBUFPH " %s %s/%d.%d\r\n",
                 SQUIDSBUFPRINT(request->method.image()),
-                url && *url ? url : "/",
+                url,
                 AnyP::ProtocolType_str[httpver.protocol],
                 httpver.major,httpver.minor);
     /* build and pack headers */
     {
         HttpHeader hdr(hoRequest);
         httpBuildRequestHeader(request, entry, fwd->al, &hdr, flags);
 
         if (request->flags.pinned && request->flags.connectionAuth)
             request->flags.authSent = true;
         else if (hdr.has(HDR_AUTHORIZATION))
             request->flags.authSent = true;
 
         hdr.packInto(mb);
         hdr.clean();
     }
     /* append header terminator */
     mb->append(crlf, 2);
     return mb->size - offset;
 }
 

=== modified file 'src/icmp/net_db.cc'
--- src/icmp/net_db.cc	2015-06-09 06:14:43 +0000
+++ src/icmp/net_db.cc	2015-06-19 11:45:11 +0000
@@ -1272,41 +1272,42 @@
     }
 
     assert(0 == i);
     s->flush();
     memFree(buf, MEM_4K_BUF);
 #else
 
     reply->setHeaders(Http::scBadRequest, "Bad Request", NULL, -1, squid_curtime, -2);
     s->replaceHttpReply(reply);
     storeAppendPrintf(s, "NETDB support not compiled into this Squid cache.\n");
 #endif
 
     s->complete();
 }
 
 void
 netdbExchangeStart(void *data)
 {
 #if USE_ICMP
     CachePeer *p = (CachePeer *)data;
-    char *uri = internalRemoteUri(p->host, p->http_port, "/squid-internal-dynamic/", "netdb");
+    static const SBuf netDB("netdb");
+    char *uri = internalRemoteUri(p->host, p->http_port, "/squid-internal-dynamic/", netDB);
     debugs(38, 3, "netdbExchangeStart: Requesting '" << uri << "'");
     assert(NULL != uri);
     HttpRequest *req = HttpRequest::CreateFromUrl(uri);
 
     if (req == NULL) {
         debugs(38, DBG_IMPORTANT, "netdbExchangeStart: Bad URI " << uri);
         return;
     }
 
     netdbExchangeState *ex = new netdbExchangeState(p, req);
     ex->e = storeCreateEntry(uri, uri, RequestFlags(), Http::METHOD_GET);
     assert(NULL != ex->e);
 
     StoreIOBuffer tempBuffer;
     tempBuffer.length = ex->buf_sz;
     tempBuffer.data = ex->buf;
 
     ex->sc = storeClientListAdd(ex->e, ex);
 
     storeClientCopy(ex->sc, ex->e, tempBuffer,

=== modified file 'src/internal.cc'
--- src/internal.cc	2015-06-09 06:14:43 +0000
+++ src/internal.cc	2015-06-28 07:19:47 +0000
@@ -15,134 +15,140 @@
 #include "HttpReply.h"
 #include "HttpRequest.h"
 #include "icmp/net_db.h"
 #include "MemBuf.h"
 #include "SquidConfig.h"
 #include "SquidTime.h"
 #include "Store.h"
 #include "tools.h"
 #include "URL.h"
 #include "util.h"
 #include "wordlist.h"
 
 /* called when we "miss" on an internal object;
  * generate known dynamic objects,
  * return Http::scNotFound for others
  */
 void
 internalStart(const Comm::ConnectionPointer &clientConn, HttpRequest * request, StoreEntry * entry)
 {
     ErrorState *err;
-    const char *upath = request->urlpath.termedBuf();
-    debugs(76, 3, HERE << clientConn << " requesting '" << upath << "'");
+    const SBuf upath = request->url.path();
+    debugs(76, 3, clientConn << " requesting '" << upath << "'");
 
-    if (0 == strcmp(upath, "/squid-internal-dynamic/netdb")) {
+    static const SBuf netdbUri("/squid-internal-dynamic/netdb");
+    static const SBuf storeDigestUri("/squid-internal-periodic/store_digest");
+    static const SBuf mgrPfx("/squid-internal-mgr/");
+
+    if (upath.cmp(netdbUri) == 0) {
         netdbBinaryExchange(entry);
-    } else if (0 == strcmp(upath, "/squid-internal-periodic/store_digest")) {
+    } else if (upath.cmp(storeDigestUri) == 0) {
 #if USE_CACHE_DIGESTS
         const char *msgbuf = "This cache is currently building its digest.\n";
 #else
 
         const char *msgbuf = "This cache does not support Cache Digests.\n";
 #endif
 
         HttpReply *reply = new HttpReply;
         reply->setHeaders(Http::scNotFound, "Not Found", "text/plain", strlen(msgbuf), squid_curtime, -2);
         entry->replaceHttpReply(reply);
         entry->append(msgbuf, strlen(msgbuf));
         entry->complete();
-    } else if (0 == strncmp(upath, "/squid-internal-mgr/", 20)) {
-        debugs(17, 2, "calling CacheManager due to URL-path /squid-internal-mgr/");
+    } else if (upath.cmp(mgrPfx, mgrPfx.length()) == 0) {
+        debugs(17, 2, "calling CacheManager due to URL-path " << mgrPfx);
         CacheManager::GetInstance()->Start(clientConn, request, entry);
     } else {
         debugObj(76, 1, "internalStart: unknown request:\n",
                  request, (ObjPackMethod) & httpRequestPack);
         err = new ErrorState(ERR_INVALID_REQ, Http::scNotFound, request);
         errorAppendEntry(entry, err);
     }
 }
 
-int
-internalCheck(const char *urlpath)
+bool
+internalCheck(const SBuf &urlPath)
 {
-    return (0 == strncmp(urlpath, "/squid-internal-", 16));
+    static const SBuf InternalPfx("/squid-internal-");
+    return urlPath.cmp(InternalPfx, InternalPfx.length()) == 0;
 }
 
-int
-internalStaticCheck(const char *urlpath)
+bool
+internalStaticCheck(const SBuf &urlPath)
 {
-    return (0 == strncmp(urlpath, "/squid-internal-static", 22));
+    static const SBuf InternalStaticPfx("/squid-internal-static");
+    return urlPath.cmp(InternalStaticPfx, InternalStaticPfx.length()) == 0;
 }
 
 /*
  * makes internal url with a given host and port (remote internal url)
  */
 char *
-internalRemoteUri(const char *host, unsigned short port, const char *dir, const char *name)
+internalRemoteUri(const char *host, unsigned short port, const char *dir, const SBuf &name)
 {
     static char lc_host[SQUIDHOSTNAMELEN];
-    assert(host && name);
+    assert(host && !name.isEmpty());
     /* convert host name to lower case */
     xstrncpy(lc_host, host, SQUIDHOSTNAMELEN);
     Tolower(lc_host);
 
     /* check for an IP address and format appropriately if found */
     Ip::Address test = lc_host;
     if ( !test.isAnyAddr() ) {
         test.toHostStr(lc_host,SQUIDHOSTNAMELEN);
     }
 
     /*
      * append the domain in order to mirror the requests with appended
      * domains
      */
 
     /* For IPv6 addresses also check for a colon */
     if (Config.appendDomain && !strchr(lc_host, '.') && !strchr(lc_host, ':'))
         strncat(lc_host, Config.appendDomain, SQUIDHOSTNAMELEN -
                 strlen(lc_host) - 1);
 
     /* build URI */
     URL tmp(AnyP::PROTO_HTTP);
     tmp.host(lc_host);
     if (port)
         tmp.port(port);
 
     static MemBuf mb;
 
     mb.reset();
     mb.appendf("http://" SQUIDSBUFPH, SQUIDSBUFPRINT(tmp.authority()));
 
     if (dir)
         mb.append(dir, strlen(dir));
 
-    mb.append(name, strlen(name));
+    mb.append(name.rawContent(), name.length());
 
     /* return a pointer to a local static buffer */
     return mb.buf;
 }
 
 /*
  * makes internal url with local host and port
  */
 char *
-internalLocalUri(const char *dir, const char *name)
+internalLocalUri(const char *dir, const SBuf &name)
 {
     return internalRemoteUri(getMyHostname(),
                              getMyPort(), dir, name);
 }
 
 const char *
 internalHostname(void)
 {
     LOCAL_ARRAY(char, host, SQUIDHOSTNAMELEN + 1);
     xstrncpy(host, getMyHostname(), SQUIDHOSTNAMELEN);
 
     /* For IPv6 addresses also check for a colon */
     if (Config.appendDomain && !strchr(host, '.') && !strchr(host, ':'))
         strncat(host, Config.appendDomain, SQUIDHOSTNAMELEN -
                 strlen(host) - 1);
 
     Tolower(host);
 
     return host;
 }

=== modified file 'src/internal.h'
--- src/internal.h	2015-01-13 07:25:36 +0000
+++ src/internal.h	2015-06-19 11:44:31 +0000
@@ -1,30 +1,32 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 /*
  * DEBUG: section 76    Internal Squid Object handling
  * AUTHOR: Duane, Alex, Henrik
  */
 
 #ifndef SQUID_INTERNAL_H_
 #define SQUID_INTERNAL_H_
 
 #include "comm/forward.h"
+
 class HttpRequest;
+class SBuf;
 class StoreEntry;
 
 void internalStart(const Comm::ConnectionPointer &clientConn, HttpRequest *, StoreEntry *);
-int internalCheck(const char *urlpath);
-int internalStaticCheck(const char *urlpath);
-char *internalLocalUri(const char *dir, const char *name);
-char *internalRemoteUri(const char *, unsigned short, const char *, const char *);
+bool internalCheck(const SBuf &urlPath);
+bool internalStaticCheck(const SBuf &urlPath);
+char *internalLocalUri(const char *dir, const SBuf &name);
+char *internalRemoteUri(const char *, unsigned short, const char *, const SBuf &);
 const char *internalHostname(void);
 int internalHostnameIs(const char *);
 
 #endif /* SQUID_INTERNAL_H_ */
 

=== modified file 'src/mime.cc'
--- src/mime.cc	2015-06-18 15:11:24 +0000
+++ src/mime.cc	2015-06-18 16:36:22 +0000
@@ -101,89 +101,89 @@
         else if (!strcmp(m->content_encoding, dash_str))
             (void) 0;
         else {
             /* Assume we matched /\.\w$/ and cut off the last extension */
             if ((t = strrchr(name, '.'))) {
                 *t = '\0';
             } else {
                 /* What? A encoding without a extension? */
                 m = NULL;
             }
         }
     } while (t);
 
     xfree(name);
     return m;
 }
 
 MimeIcon::MimeIcon(const char *aName) :
     icon_(aName)
 {
-    url_ = xstrdup(internalLocalUri("/squid-internal-static/icons/", icon_.c_str()));
+    url_ = xstrdup(internalLocalUri("/squid-internal-static/icons/", icon_));
 }
 
 MimeIcon::~MimeIcon()
 {
     xfree(url_);
 }
 
 void
 MimeIcon::setName(char const *aString)
 {
     xfree(url_);
     icon_ = aString;
-    url_ = xstrdup(internalLocalUri("/squid-internal-static/icons/", icon_.c_str()));
+    url_ = xstrdup(internalLocalUri("/squid-internal-static/icons/", icon_));
 }
 
 SBuf
 MimeIcon::getName() const
 {
     return icon_;
 }
 
 const SBuf
 mimeGetIcon(const char *fn)
 {
     MimeEntry *m = mimeGetEntry(fn, 1);
 
     if (!m || !m->theIcon.getName().cmp(dash_str))
         return SBuf();
 
     return m->theIcon.getName();
 }
 
 const char *
 mimeGetIconURL(const char *fn)
 {
     SBuf icon(mimeGetIcon(fn));
 
     if (icon.isEmpty())
         return null_string;
 
     if (Config.icons.use_short_names) {
         static SBuf mb;
         mb.clear();
         mb.append("/squid-internal-static/icons/");
         mb.append(icon);
         return mb.c_str();
     } else {
-        return internalLocalUri("/squid-internal-static/icons/", icon.c_str());
+        return internalLocalUri("/squid-internal-static/icons/", icon);
     }
 }
 
 const char *
 mimeGetContentType(const char *fn)
 {
     MimeEntry *m = mimeGetEntry(fn, 1);
 
     if (m == NULL)
         return NULL;
 
     if (!strcmp(m->content_type, dash_str))
         return NULL;
 
     return m->content_type;
 }
 
 const char *
 mimeGetContentEncoding(const char *fn)
 {

=== modified file 'src/peer_digest.cc'
--- src/peer_digest.cc	2015-02-04 03:22:38 +0000
+++ src/peer_digest.cc	2015-06-19 11:45:55 +0000
@@ -313,41 +313,41 @@
 
 /* ask store for a digest */
 static void
 peerDigestRequest(PeerDigest * pd)
 {
     CachePeer *p = pd->peer;
     StoreEntry *e, *old_e;
     char *url = NULL;
     const cache_key *key;
     HttpRequest *req;
     StoreIOBuffer tempBuffer;
 
     pd->req_result = NULL;
     pd->flags.requested = true;
 
     /* compute future request components */
 
     if (p->digest_url)
         url = xstrdup(p->digest_url);
     else
-        url = xstrdup(internalRemoteUri(p->host, p->http_port, "/squid-internal-periodic/", StoreDigestFileName));
+        url = xstrdup(internalRemoteUri(p->host, p->http_port, "/squid-internal-periodic/", SBuf(StoreDigestFileName)));
 
     req = HttpRequest::CreateFromUrl(url);
 
     assert(req);
 
     key = storeKeyPublicByRequest(req);
 
     debugs(72, 2, "peerDigestRequest: " << url << " key: " << storeKeyText(key));
 
     /* add custom headers */
     assert(!req->header.len);
 
     req->header.putStr(HDR_ACCEPT, StoreDigestMimeStr);
 
     req->header.putStr(HDR_ACCEPT, "text/html");
 
     if (p->login &&
             p->login[0] != '*' &&
             strcmp(p->login, "PASS") != 0 &&
             strcmp(p->login, "PASSTHRU") != 0 &&

=== modified file 'src/tests/testHttpRequest.cc'
--- src/tests/testHttpRequest.cc	2015-06-09 06:14:43 +0000
+++ src/tests/testHttpRequest.cc	2015-06-23 11:16:56 +0000
@@ -32,138 +32,138 @@
 {
     Mem::Init();
     httpHeaderInitModule();
 }
 
 /*
  * Test creating an HttpRequest object from a Url and method
  */
 void
 testHttpRequest::testCreateFromUrlAndMethod()
 {
     /* vanilla url */
     unsigned short expected_port;
     char * url = xstrdup("http://foo:90/bar");
     HttpRequest *aRequest = HttpRequest::CreateFromUrlAndMethod(url, Http::METHOD_GET);
     expected_port = 90;
     HttpRequest *nullRequest = NULL;
     CPPUNIT_ASSERT_EQUAL(expected_port, aRequest->url.port());
     CPPUNIT_ASSERT(aRequest->method == Http::METHOD_GET);
     CPPUNIT_ASSERT_EQUAL(String("foo"), String(aRequest->url.host()));
-    CPPUNIT_ASSERT_EQUAL(String("/bar"), aRequest->urlpath);
+    CPPUNIT_ASSERT_EQUAL(SBuf("/bar"), aRequest->url.path());
     CPPUNIT_ASSERT_EQUAL(AnyP::PROTO_HTTP, static_cast<AnyP::ProtocolType>(aRequest->url.getScheme()));
     CPPUNIT_ASSERT_EQUAL(String("http://foo:90/bar"), String(url));
     xfree(url);
 
     /* vanilla url, different method */
     url = xstrdup("http://foo/bar");
     aRequest = HttpRequest::CreateFromUrlAndMethod(url, Http::METHOD_PUT);
     expected_port = 80;
     CPPUNIT_ASSERT_EQUAL(expected_port, aRequest->url.port());
     CPPUNIT_ASSERT(aRequest->method == Http::METHOD_PUT);
     CPPUNIT_ASSERT_EQUAL(String("foo"), String(aRequest->url.host()));
-    CPPUNIT_ASSERT_EQUAL(String("/bar"), aRequest->urlpath);
+    CPPUNIT_ASSERT_EQUAL(SBuf("/bar"), aRequest->url.path());
     CPPUNIT_ASSERT_EQUAL(AnyP::PROTO_HTTP, static_cast<AnyP::ProtocolType>(aRequest->url.getScheme()));
     CPPUNIT_ASSERT_EQUAL(String("http://foo/bar"), String(url));
     xfree(url);
 
     /* a connect url with non-CONNECT data */
     url = xstrdup(":foo/bar");
     aRequest = HttpRequest::CreateFromUrlAndMethod(url, Http::METHOD_CONNECT);
     xfree(url);
     CPPUNIT_ASSERT_EQUAL(nullRequest, aRequest);
 
     /* a CONNECT url with CONNECT data */
     url = xstrdup("foo:45");
     aRequest = HttpRequest::CreateFromUrlAndMethod(url, Http::METHOD_CONNECT);
     expected_port = 45;
     CPPUNIT_ASSERT_EQUAL(expected_port, aRequest->url.port());
     CPPUNIT_ASSERT(aRequest->method == Http::METHOD_CONNECT);
     CPPUNIT_ASSERT_EQUAL(String("foo"), String(aRequest->url.host()));
-    CPPUNIT_ASSERT_EQUAL(String(""), aRequest->urlpath);
+    CPPUNIT_ASSERT_EQUAL(SBuf(), aRequest->url.path());
     CPPUNIT_ASSERT_EQUAL(AnyP::PROTO_NONE, static_cast<AnyP::ProtocolType>(aRequest->url.getScheme()));
     CPPUNIT_ASSERT_EQUAL(String("foo:45"), String(url));
     xfree(url);
 }
 
 /*
  * Test creating an HttpRequest object from a Url alone.
  */
 void
 testHttpRequest::testCreateFromUrl()
 {
     /* vanilla url */
     unsigned short expected_port;
     char * url = xstrdup("http://foo:90/bar");
     HttpRequest *aRequest = HttpRequest::CreateFromUrl(url);
     expected_port = 90;
     CPPUNIT_ASSERT_EQUAL(expected_port, aRequest->url.port());
     CPPUNIT_ASSERT(aRequest->method == Http::METHOD_GET);
     CPPUNIT_ASSERT_EQUAL(String("foo"), String(aRequest->url.host()));
-    CPPUNIT_ASSERT_EQUAL(String("/bar"), aRequest->urlpath);
+    CPPUNIT_ASSERT_EQUAL(SBuf("/bar"), aRequest->url.path());
     CPPUNIT_ASSERT_EQUAL(AnyP::PROTO_HTTP, static_cast<AnyP::ProtocolType>(aRequest->url.getScheme()));
     CPPUNIT_ASSERT_EQUAL(String("http://foo:90/bar"), String(url));
     xfree(url);
 }
 
 /*
  * Test BUG: URL '2000:800:45' opens host 2000 port 800 !!
  */
 void
 testHttpRequest::testIPv6HostColonBug()
 {
     unsigned short expected_port;
     char * url = NULL;
     HttpRequest *aRequest = NULL;
 
     /* valid IPv6 address without port */
     url = xstrdup("http://[2000:800::45]/foo");
     aRequest = HttpRequest::CreateFromUrlAndMethod(url, Http::METHOD_GET);
     expected_port = 80;
     CPPUNIT_ASSERT_EQUAL(expected_port, aRequest->url.port());
     CPPUNIT_ASSERT(aRequest->method == Http::METHOD_GET);
     CPPUNIT_ASSERT_EQUAL(String("[2000:800::45]"), String(aRequest->url.host()));
-    CPPUNIT_ASSERT_EQUAL(String("/foo"), aRequest->urlpath);
+    CPPUNIT_ASSERT_EQUAL(SBuf("/foo"), aRequest->url.path());
     CPPUNIT_ASSERT_EQUAL(AnyP::PROTO_HTTP, static_cast<AnyP::ProtocolType>(aRequest->url.getScheme()));
     CPPUNIT_ASSERT_EQUAL(String("http://[2000:800::45]/foo"), String(url));
     xfree(url);
 
     /* valid IPv6 address with port */
     url = xstrdup("http://[2000:800::45]:90/foo");
     aRequest = HttpRequest::CreateFromUrlAndMethod(url, Http::METHOD_GET);
     expected_port = 90;
     CPPUNIT_ASSERT_EQUAL(expected_port, aRequest->url.port());
     CPPUNIT_ASSERT(aRequest->method == Http::METHOD_GET);
     CPPUNIT_ASSERT_EQUAL(String("[2000:800::45]"), String(aRequest->url.host()));
-    CPPUNIT_ASSERT_EQUAL(String("/foo"), aRequest->urlpath);
+    CPPUNIT_ASSERT_EQUAL(SBuf("/foo"), aRequest->url.path());
     CPPUNIT_ASSERT_EQUAL(AnyP::PROTO_HTTP, static_cast<AnyP::ProtocolType>(aRequest->url.getScheme()));
     CPPUNIT_ASSERT_EQUAL(String("http://[2000:800::45]:90/foo"), String(url));
     xfree(url);
 
     /* IPv6 address as invalid (bug trigger) */
     url = xstrdup("http://2000:800::45/foo");
     aRequest = HttpRequest::CreateFromUrlAndMethod(url, Http::METHOD_GET);
     expected_port = 80;
     CPPUNIT_ASSERT_EQUAL(expected_port, aRequest->url.port());
     CPPUNIT_ASSERT(aRequest->method == Http::METHOD_GET);
     CPPUNIT_ASSERT_EQUAL(String("[2000:800::45]"), String(aRequest->url.host()));
-    CPPUNIT_ASSERT_EQUAL(String("/foo"), aRequest->urlpath);
+    CPPUNIT_ASSERT_EQUAL(SBuf("/foo"), aRequest->url.path());
     CPPUNIT_ASSERT_EQUAL(AnyP::PROTO_HTTP, static_cast<AnyP::ProtocolType>(aRequest->url.getScheme()));
     CPPUNIT_ASSERT_EQUAL(String("http://2000:800::45/foo"), String(url));
     xfree(url);
 }
 
 void
 testHttpRequest::testSanityCheckStartLine()
 {
     MemBuf input;
     PrivateHttpRequest engine;
     Http::StatusCode error = Http::scNone;
     size_t hdr_len;
     input.init();
 
     // a valid request line
     input.append("GET / HTTP/1.1\n\n", 16);
     hdr_len = headersEnd(input.content(), input.contentSize());
     CPPUNIT_ASSERT(engine.doSanityCheckStartLine(input.content(), hdr_len, &error) );
     CPPUNIT_ASSERT_EQUAL(error, Http::scNone);
     input.reset();

=== modified file 'src/url.cc'
--- src/url.cc	2015-06-09 06:14:43 +0000
+++ src/url.cc	2015-06-15 10:46:18 +0000
@@ -27,56 +27,75 @@
 static const char valid_hostname_chars_u[] =
     "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
     "abcdefghijklmnopqrstuvwxyz"
     "0123456789-._"
     "[:]"
     ;
 static const char valid_hostname_chars[] =
     "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
     "abcdefghijklmnopqrstuvwxyz"
     "0123456789-."
     "[:]"
     ;
 
 const SBuf &
 URL::Asterisk()
 {
     static SBuf star("*");
     return star;
 }
 
+const SBuf &
+URL::SlashPath()
+{
+    static SBuf slash("/");
+    return slash;
+}
+
 void
 URL::host(const char *src)
 {
     hostAddr_.setEmpty();
     hostAddr_ = src;
     if (hostAddr_.isAnyAddr()) {
         xstrncpy(host_, src, sizeof(host_));
         hostIsNumeric_ = false;
     } else {
         hostAddr_.toHostStr(host_, sizeof(host_));
         debugs(23, 3, "given IP: " << hostAddr_);
         hostIsNumeric_ = 1;
     }
     touch();
 }
 
+const SBuf &
+URL::path() const
+{
+    // RFC 3986 section 3.3 says path can be empty (path-abempty).
+    // RFC 7230 sections 2.7.3, 5.3.1, 5.7.2 - says path cannot be empty, default to "/"
+    // at least when sending and using. We must still accept path-abempty as input.
+    if (path_.isEmpty() && (scheme_ == AnyP::PROTO_HTTP || scheme_ == AnyP::PROTO_HTTPS))
+        return SlashPath();
+
+    return path_;
+}
+
 void
 urlInitialize(void)
 {
     debugs(23, 5, "urlInitialize: Initializing...");
     /* this ensures that the number of protocol strings is the same as
      * the enum slots allocated because the last enum is always 'MAX'.
      */
     assert(strcmp(AnyP::ProtocolType_str[AnyP::PROTO_MAX], "MAX") == 0);
     /*
      * These test that our matchDomainName() function works the
      * way we expect it to.
      */
     assert(0 == matchDomainName("foo.com", "foo.com"));
     assert(0 == matchDomainName(".foo.com", "foo.com"));
     assert(0 == matchDomainName("foo.com", ".foo.com"));
     assert(0 == matchDomainName(".foo.com", ".foo.com"));
     assert(0 == matchDomainName("x.foo.com", ".foo.com"));
     assert(0 != matchDomainName("x.foo.com", "foo.com"));
     assert(0 != matchDomainName("foo.com", "x.foo.com"));
     assert(0 != matchDomainName("bar.com", "foo.com"));
@@ -469,96 +488,96 @@
         authorityHttp_ = authorityWithPort_;
 
         // authorityForm_ only has :port if it is non-default
         authorityWithPort_.appendf(":%u",port());
         if (port() != getScheme().defaultPort())
             authorityHttp_ = authorityWithPort_;
     }
 
     return requirePort ? authorityWithPort_ : authorityHttp_;
 }
 
 const char *
 urlCanonical(HttpRequest * request)
 {
     LOCAL_ARRAY(char, urlbuf, MAX_URL);
 
     if (request->canonical)
         return request->canonical;
 
     if (request->url.getScheme() == AnyP::PROTO_URN) {
-        snprintf(urlbuf, MAX_URL, "urn:" SQUIDSTRINGPH,
-                 SQUIDSTRINGPRINT(request->urlpath));
+        snprintf(urlbuf, MAX_URL, "urn:" SQUIDSBUFPH,
+                 SQUIDSBUFPRINT(request->url.path()));
     } else {
         SBuf authorityForm;
         switch (request->method.id()) {
 
         case Http::METHOD_CONNECT:
             authorityForm = request->url.authority(true); // host:port
             snprintf(urlbuf, MAX_URL, SQUIDSBUFPH, SQUIDSBUFPRINT(authorityForm));
             break;
 
         default: {
             authorityForm = request->url.authority(); // host[:port]
-            snprintf(urlbuf, MAX_URL, "%s://" SQUIDSBUFPH "%s" SQUIDSBUFPH SQUIDSTRINGPH,
+            snprintf(urlbuf, MAX_URL, "%s://" SQUIDSBUFPH "%s" SQUIDSBUFPH SQUIDSBUFPH,
                      request->url.getScheme().c_str(),
                      SQUIDSBUFPRINT(request->url.userInfo()),
                      !request->url.userInfo().isEmpty() ? "@" : "",
                      SQUIDSBUFPRINT(authorityForm),
-                     SQUIDSTRINGPRINT(request->urlpath));
+                     SQUIDSBUFPRINT(request->url.path()));
         }
         }
     }
 
     return (request->canonical = xstrdup(urlbuf));
 }
 
 /** \todo AYJ: Performance: This is an *almost* duplicate of urlCanonical. But elides the query-string.
  *        After copying it on in the first place! Would be less code to merge the two with a flag parameter.
  *        and never copy the query-string part in the first place
  */
 char *
 urlCanonicalClean(const HttpRequest * request)
 {
     LOCAL_ARRAY(char, buf, MAX_URL);
     char *t;
 
     if (request->url.getScheme() == AnyP::PROTO_URN) {
-        snprintf(buf, MAX_URL, "urn:" SQUIDSTRINGPH,
-                 SQUIDSTRINGPRINT(request->urlpath));
+        snprintf(buf, MAX_URL, "urn:" SQUIDSBUFPH,
+                 SQUIDSBUFPRINT(request->url.path()));
     } else {
         SBuf authorityForm;
         switch (request->method.id()) {
 
         case Http::METHOD_CONNECT:
             authorityForm = request->url.authority(true); // host:port
             snprintf(buf, MAX_URL, SQUIDSBUFPH, SQUIDSBUFPRINT(authorityForm));
             break;
 
         default: {
             authorityForm = request->url.authority(); // host[:port]
-            snprintf(buf, MAX_URL, "%s://" SQUIDSBUFPH "%s" SQUIDSBUFPH SQUIDSTRINGPH,
+            snprintf(buf, MAX_URL, "%s://" SQUIDSBUFPH "%s" SQUIDSBUFPH SQUIDSBUFPH,
                      request->url.getScheme().c_str(),
                      SQUIDSBUFPRINT(request->url.userInfo()),
                      !request->url.userInfo().isEmpty() ? "@" : "",
                      SQUIDSBUFPRINT(authorityForm),
-                     SQUIDSTRINGPRINT(request->urlpath));
+                     SQUIDSBUFPRINT(request->url.path()));
 
             // strip arguments AFTER a question-mark
             if (Config.onoff.strip_query_terms)
                 if ((t = strchr(buf, '?')))
                     *(++t) = '\0';
         }
         } // switch
     }
 
     if (stringHasCntl(buf))
         xstrncpy(buf, rfc1738_escape_unescaped(buf), MAX_URL);
 
     return buf;
 }
 
 /**
  * Yet another alternative to urlCanonical.
  * This one adds the https:// parts to Http::METHOD_CONNECT URL
  * for use in error page outputs.
  * Luckily we can leverage the others instead of duplicating.
@@ -611,70 +630,75 @@
  * It is assumed that you have already ensured that the URL is relative.
  *
  * If NULL is returned it is an indication that the method in use in the
  * request does not distinguish between relative and absolute and you should
  * use the url unchanged.
  *
  * If non-NULL is returned, it is up to the caller to free the resulting
  * memory using safe_free().
  */
 char *
 urlMakeAbsolute(const HttpRequest * req, const char *relUrl)
 {
 
     if (req->method.id() == Http::METHOD_CONNECT) {
         return (NULL);
     }
 
     char *urlbuf = (char *)xmalloc(MAX_URL * sizeof(char));
 
     if (req->url.getScheme() == AnyP::PROTO_URN) {
-        snprintf(urlbuf, MAX_URL, "urn:" SQUIDSTRINGPH,
-                 SQUIDSTRINGPRINT(req->urlpath));
+        snprintf(urlbuf, MAX_URL, "urn:" SQUIDSBUFPH,
+                 SQUIDSBUFPRINT(req->url.path()));
         return (urlbuf);
     }
 
     SBuf authorityForm = req->url.authority(); // host[:port]
     size_t urllen = snprintf(urlbuf, MAX_URL, "%s://" SQUIDSBUFPH "%s" SQUIDSBUFPH,
                              req->url.getScheme().c_str(),
                              SQUIDSBUFPRINT(req->url.userInfo()),
                              !req->url.userInfo().isEmpty() ? "@" : "",
                              SQUIDSBUFPRINT(authorityForm));
 
+    // if the first char is '/' assume its a relative path
+    // XXX: this breaks on scheme-relative URLs,
+    // but we should not see those outside ESI, and rarely there.
     if (relUrl[0] == '/') {
         strncpy(&urlbuf[urllen], relUrl, MAX_URL - urllen - 1);
     } else {
-        const char *path = req->urlpath.termedBuf();
-        const char *last_slash = strrchr(path, '/');
+        SBuf path = req->url.path();
+        SBuf::size_type lastSlashPos = path.rfind('/');
 
-        if (last_slash == NULL) {
+        if (lastSlashPos == SBuf::npos) {
+            // replace the whole path with the given bit(s)
             urlbuf[urllen] = '/';
             ++urllen;
             strncpy(&urlbuf[urllen], relUrl, MAX_URL - urllen - 1);
         } else {
-            ++last_slash;
-            size_t pathlen = last_slash - path;
-            if (pathlen > MAX_URL - urllen - 1) {
-                pathlen = MAX_URL - urllen - 1;
+            // replace only the last (file?) segment with the given bit(s)
+            ++lastSlashPos;
+            if (lastSlashPos > MAX_URL - urllen - 1) {
+                // XXX: crops bits in the middle of the combined URL.
+                lastSlashPos = MAX_URL - urllen - 1;
             }
-            strncpy(&urlbuf[urllen], path, pathlen);
-            urllen += pathlen;
+            strncpy(&urlbuf[urllen], path.rawContent(), lastSlashPos);
+            urllen += lastSlashPos;
             if (urllen + 1 < MAX_URL) {
                 strncpy(&urlbuf[urllen], relUrl, MAX_URL - urllen - 1);
             }
         }
     }
 
     return (urlbuf);
 }
 
 int
 matchDomainName(const char *h, const char *d, bool honorWildcards)
 {
     int dl;
     int hl;
 
     while ('.' == *h)
         ++h;
 
     hl = strlen(h);
 
@@ -753,41 +777,41 @@
 urlCheckRequest(const HttpRequest * r)
 {
     int rc = 0;
     /* protocol "independent" methods
      *
      * actually these methods are specific to HTTP:
      * they are methods we recieve on our HTTP port,
      * and if we had a FTP listener would not be relevant
      * there.
      *
      * So, we should delegate them to HTTP. The problem is that we
      * do not have a default protocol from the client side of HTTP.
      */
 
     if (r->method == Http::METHOD_CONNECT)
         return 1;
 
     // we support OPTIONS and TRACE directed at us (with a 501 reply, for now)
     // we also support forwarding OPTIONS and TRACE, except for the *-URI ones
     if (r->method == Http::METHOD_OPTIONS || r->method == Http::METHOD_TRACE)
-        return (r->header.getInt64(HDR_MAX_FORWARDS) == 0 || URL::Asterisk().cmp(r->urlpath.rawBuf(), r->urlpath.size()) != 0);
+        return (r->header.getInt64(HDR_MAX_FORWARDS) == 0 || URL::Asterisk().cmp(r->url.path()) != 0);
 
     if (r->method == Http::METHOD_PURGE)
         return 1;
 
     /* does method match the protocol? */
     switch (r->url.getScheme()) {
 
     case AnyP::PROTO_URN:
 
     case AnyP::PROTO_HTTP:
 
     case AnyP::PROTO_CACHE_OBJECT:
         rc = 1;
         break;
 
     case AnyP::PROTO_FTP:
 
         if (r->method == Http::METHOD_PUT)
             rc = 1;
 

=== modified file 'src/urn.cc'
--- src/urn.cc	2015-05-26 18:12:08 +0000
+++ src/urn.cc	2015-06-15 11:06:49 +0000
@@ -18,45 +18,43 @@
 #include "icmp/net_db.h"
 #include "MemBuf.h"
 #include "mime_header.h"
 #include "RequestFlags.h"
 #include "SquidTime.h"
 #include "Store.h"
 #include "StoreClient.h"
 #include "tools.h"
 #include "URL.h"
 #include "urn.h"
 
 #define URN_REQBUF_SZ   4096
 
 class UrnState : public StoreClient
 {
     CBDATA_CLASS(UrnState);
 
 public:
     void created (StoreEntry *newEntry);
     void start (HttpRequest *, StoreEntry *);
-    char *getHost (String &urlpath);
+    char *getHost(SBuf &urlpath);
     void setUriResFromRequest(HttpRequest *);
     bool RequestNeedsMenu(HttpRequest *r);
-    void updateRequestURL(HttpRequest *r, char const *newPath, const size_t newPath_len);
-    void createUriResRequest (String &uri);
 
     virtual ~UrnState();
 
     StoreEntry *entry;
     store_client *sc;
     StoreEntry *urlres_e;
     HttpRequest::Pointer request;
     HttpRequest::Pointer urlres_r;
 
     struct {
         bool force_menu;
     } flags;
     char reqbuf[URN_REQBUF_SZ];
     int reqofs;
 
 private:
     char *urlres;
 };
 
 typedef struct {
@@ -111,94 +109,80 @@
 
         if (u->rtt > min_rtt && min_rtt != 0)
             continue;
 
         min_rtt = u->rtt;
 
         min_u = u;
     }
 
     if (rtt_ret)
         *rtt_ret = min_rtt;
 
     debugs(52, DBG_IMPORTANT, "urnFindMinRtt: Returning '" <<
            (min_u ? min_u->url : "NONE") << "' RTT " <<
            min_rtt  );
 
     return min_u;
 }
 
 char *
-UrnState::getHost (String &urlpath)
+UrnState::getHost(SBuf &urlpath)
 {
     char * result;
     size_t p;
 
     /** FIXME: this appears to be parsing the URL. *very* badly. */
     /*   a proper encapsulated URI/URL type needs to clear this up. */
-    if ((p=urlpath.find(':')) != String::npos) {
-        result=xstrndup(urlpath.rawBuf(),p-1);
+    if ((p=urlpath.find(':')) != SBuf::npos) {
+        result=xstrndup(urlpath.rawContent(),p-1);
     } else {
-        result = xstrndup(urlpath.rawBuf(),urlpath.size());
+        result = xstrndup(urlpath.rawContent(),urlpath.length());
     }
     return result;
 }
 
 bool
 UrnState::RequestNeedsMenu(HttpRequest *r)
 {
-    if (r->urlpath.size() < 5)
+    if (r->url.path().length() < 5)
         return false;
     //now we're sure it's long enough
-    return strncasecmp(r->urlpath.rawBuf(), "menu.", 5) == 0;
+    return r->url.path().caseCmp("menu.", 5) == 0;
 }
 
 void
-UrnState::updateRequestURL(HttpRequest *r, char const *newPath, const size_t newPath_len)
+UrnState::setUriResFromRequest(HttpRequest *r)
 {
-    char *new_path = xstrndup (newPath, newPath_len);
-    r->urlpath = new_path;
-    xfree(new_path);
-}
+    if (RequestNeedsMenu(r)) {
+        r->url.path(r->url.path().substr(5)); // strip prefix "menu."
+        flags.force_menu = true;
+    }
 
-void
-UrnState::createUriResRequest (String &uri)
-{
+    SBuf uri = r->url.path();
     LOCAL_ARRAY(char, local_urlres, 4096);
-    char *host = getHost (uri);
-    snprintf(local_urlres, 4096, "http://%s/uri-res/N2L?urn:" SQUIDSTRINGPH,
-             host, SQUIDSTRINGPRINT(uri));
+    char *host = getHost(uri);
+    snprintf(local_urlres, 4096, "http://%s/uri-res/N2L?urn:" SQUIDSBUFPH, host, SQUIDSBUFPRINT(uri));
     safe_free(host);
     safe_free(urlres);
     urlres = xstrdup(local_urlres);
     urlres_r = HttpRequest::CreateFromUrl(urlres);
-}
-
-void
-UrnState::setUriResFromRequest(HttpRequest *r)
-{
-    if (RequestNeedsMenu(r)) {
-        updateRequestURL(r, r->urlpath.rawBuf() + 5, r->urlpath.size() - 5 );
-        flags.force_menu = true;
-    }
-
-    createUriResRequest (r->urlpath);
 
     if (urlres_r == NULL) {
         debugs(52, 3, "urnStart: Bad uri-res URL " << urlres);
         ErrorState *err = new ErrorState(ERR_URN_RESOLVE, Http::scNotFound, r);
         err->url = urlres;
         urlres = NULL;
         errorAppendEntry(entry, err);
         return;
     }
 
     urlres_r->header.putStr(HDR_ACCEPT, "text/plain");
 }
 
 void
 UrnState::start(HttpRequest * r, StoreEntry * e)
 {
     debugs(52, 3, "urnStart: '" << e->url() << "'" );
     entry = e;
     request = r;
 

=== modified file 'src/whois.cc'
--- src/whois.cc	2015-01-13 07:25:36 +0000
+++ src/whois.cc	2015-06-15 11:09:45 +0000
@@ -39,57 +39,54 @@
     bool dataWritten;
 };
 
 CBDATA_CLASS_INIT(WhoisState);
 
 static CLCB whoisClose;
 static CTCB whoisTimeout;
 static IOCB whoisReadReply;
 
 /* PUBLIC */
 
 static void
 whoisWriteComplete(const Comm::ConnectionPointer &, char *buf, size_t, Comm::Flag, int, void *)
 {
     xfree(buf);
 }
 
 void
 whoisStart(FwdState * fwd)
 {
-    char *buf;
-    size_t l;
     WhoisState *p = new WhoisState;
     p->request = fwd->request;
     p->entry = fwd->entry;
     p->fwd = fwd;
     p->dataWritten = false;
 
     p->entry->lock("whoisStart");
     comm_add_close_handler(fwd->serverConnection()->fd, whoisClose, p);
 
-    l = p->request->urlpath.size() + 3;
+    size_t l = p->request->url.path().length() + 3;
+    char *buf = (char *)xmalloc(l);
 
-    buf = (char *)xmalloc(l);
-
-    String str_print=p->request->urlpath.substr(1,p->request->urlpath.size());
-    snprintf(buf, l, SQUIDSTRINGPH"\r\n", SQUIDSTRINGPRINT(str_print));
+    SBuf str_print = p->request->url.path().substr(1);
+    snprintf(buf, l, SQUIDSBUFPH "\r\n", SQUIDSBUFPRINT(str_print));
 
     AsyncCall::Pointer writeCall = commCbCall(5,5, "whoisWriteComplete",
                                    CommIoCbPtrFun(whoisWriteComplete, p));
     Comm::Write(fwd->serverConnection(), buf, strlen(buf), writeCall, NULL);
     AsyncCall::Pointer readCall = commCbCall(5,4, "whoisReadReply",
                                   CommIoCbPtrFun(whoisReadReply, p));
     comm_read(fwd->serverConnection(), p->buf, BUFSIZ, readCall);
     AsyncCall::Pointer timeoutCall = commCbCall(5, 4, "whoisTimeout",
                                      CommTimeoutCbPtrFun(whoisTimeout, p));
     commSetConnTimeout(fwd->serverConnection(), Config.Timeout.read, timeoutCall);
 }
 
 /* PRIVATE */
 
 static void
 whoisTimeout(const CommTimeoutCbParams &io)
 {
     WhoisState *p = static_cast<WhoisState *>(io.data);
     debugs(75, 3, HERE << io.conn << ", URL " << p->entry->url());
     io.conn->close();


From squid3 at treenet.co.nz  Sun Jun 28 11:36:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 28 Jun 2015 23:36:46 +1200
Subject: [squid-dev] [PATCH] TLS: Disable client-initiated renegotiation
In-Reply-To: <5583D444.6010709@users.sourceforge.net>
References: <55709E3B.7050609@ufscar.br> <55838F0F.2040003@treenet.co.nz>
 <5583D444.6010709@users.sourceforge.net>
Message-ID: <558FDC4E.1060205@treenet.co.nz>

On 19/06/2015 8:35 p.m., Tsantilas Christos wrote:
> This patch, probably is ok as workarround, but my sense is that it is
> not the best method to fix it.  We should spent some hours of work to
> check openSSL versions has the problem, and apply a better solution.
> 

Up to you. Though I'm not sure there is a better one.

The nature of the renegotiation is that its fine to do before the first
handshake, but not afterwards. Which implies a callback on handshake
completion is the best way to set the flag.

The #if protection I requested ensures the whole mechanism is not even
built if OpenSSL does not support the flag. Which should eliminate the
libraries that dont need it without us having to identify them
individually (including LibreSSL etc.).

Amos


From squid3 at treenet.co.nz  Sun Jun 28 12:12:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 Jun 2015 00:12:28 +1200
Subject: [squid-dev] [PATCH] Do not blindly forward cache peer CONNECT
 responses
In-Reply-To: <55897ABE.2090409@measurement-factory.com>
References: <5584494F.1010405@measurement-factory.com>
 <5584B7D7.1020802@treenet.co.nz> <55897ABE.2090409@measurement-factory.com>
Message-ID: <558FE4AC.9000200@treenet.co.nz>

On 24/06/2015 3:26 a.m., Alex Rousskov wrote:
> On 06/19/2015 06:46 PM, Amos Jeffries wrote:
>> On 20/06/2015 4:54 a.m., Alex Rousskov wrote:
>>> Hello,
>>>
>>>     The attached trunk patch fixes a rare but nasty problem by removing
>>> a very old hack which shielded Squid from parsing most CONNECT responses.
>>>
>>> Currently, Squid blindly forwards cache peer CONNECT responses to
>>> clients when possible. This may break things if the peer responds with
>>> something like HTTP 403 (Forbidden) and keeps the connection with Squid
>>> open:
>>>
>>>   -  The client application issues a CONNECT request.
>>>   -  Squid forwards this request to a cache peer.
>>>   -  Cache peer correctly responds back with a "403 Forbidden".
>>>   -  Squid does not parse cache peer response and
>>>      just forwards it as if it was a Squid response to the client.
>>>   -  The TCP connections are not closed.
>>>
>>> At this stage, Squid is unaware that the CONNECT request has failed. All
>>> subsequent requests on the user agent TCP connection are treated as
>>> tunnelled traffic. Squid is forwarding these requests to the peer on the
>>> TCP connection previously used for the 403-ed CONNECT request, without
>>> proper processing. The additional headers which should have been applied
>>> by Squid to these requests are not applied, and the requests are being
>>> forwarded to the cache peer even though the Squid configuration may
>>> state that these requests must go directly to the origin server.
>>>
>>> This patch fixes Squid to parse cache peer responses, and if an error
>>> response found, respond with "502 Bad Gateway" to the client and close
>>> the connections.
>>>
>>
>> Thank you. I've had this on my todo list for a long time.
>>
>> One problem though...
>>
>> The parse operations documented as being copied from http.cc
>> processReplyHeader() do not match what trunk currently does for HTTP
>> replies in that function.
> 
> 
> How is that problem related to the proposed fix?

Ah. Sorry, You are right.

+1 from me. Please apply.

Amos

From squid3 at treenet.co.nz  Sun Jun 28 12:17:52 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 Jun 2015 00:17:52 +1200
Subject: [squid-dev] [PATCH] Splice to origin cache_peer
In-Reply-To: <55897332.4060101@users.sourceforge.net>
References: <55897332.4060101@users.sourceforge.net>
Message-ID: <558FE5F0.5010503@treenet.co.nz>

On 24/06/2015 2:54 a.m., Tsantilas Christos wrote:
> Currently, Squid cannot redirect intercepted connections that are
> subject to SslBump rules to _originserver_ cache_peer. For example,
> consider Squid that enforces "safe search" by redirecting clients to
> forcesafesearch.example.com. Consider a TLS client that tries to connect
> to www.example.com. Squid needs to send that client to
> forcesafesearch.example.com (without changing the host header and SNI
> information; those would still point to www.example.com for safe search
> to work as intended!).
> 
> The admin may configure Squid to send intercepted clients to an
> originserver cache_peer with the forcesafesearch.example.com address.
> Such a configuration does not currently work together with ssl_bump
> peek/splice rules.
> 
> This patch:
> 
> * Fixes src/neighbors.cc bug which prevented CONNECT requests from going
> to originserver cache peers. This bug affects both true CONNECT requests
> and intercepted SSL/TLS connections (with fake CONNECT requests). Squid
> use the CachePeer::in_addr.port which is not meant to be used for the
> HTTP port, apparently. HTTP checks should use CachePeer::http_port instead.
> 
> * Changes Squid to not initiate SSL/TLS connection to cache_peer for
> true CONNECT requests.
> 
> * Allows forwarding being-peeked (or stared) at connections to
> originserver cache_peers.
> 
> 
> This is a Measurement Factory project.
> 

General comment: remember that SSL (all versions) are now deprecated and
target is to kill all use of SSL (and references if we can). Please use
"TLS" for naming and documenting new things that are generic TLS/SSL and
not explicitly part of SSLv2 or SSLv3 protocols.


in src/FwdState.cc:

* Took me ages to figure out why sslToPeer contains
!userWillSslToPeerForUs. Please either rename sslToPeer  as
needTlsToPeer OR add code comments to document those logics more clearly.
 - please add comment that userWillSslToPeerForUs assumes CONNECT ==
HTTPS (which is not always true in reality).


+1. Other than that bit of polish this looks fine. The updated patch can
go in without another review.

Amos

From squid3 at treenet.co.nz  Sun Jun 28 12:30:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 Jun 2015 00:30:46 +1200
Subject: [squid-dev] [PATCH] Do not blindly forward cache peer CONNECT
 responses
In-Reply-To: <558FE4AC.9000200@treenet.co.nz>
References: <5584494F.1010405@measurement-factory.com>
 <5584B7D7.1020802@treenet.co.nz> <55897ABE.2090409@measurement-factory.com>
 <558FE4AC.9000200@treenet.co.nz>
Message-ID: <558FE8F6.90504@treenet.co.nz>

On 29/06/2015 12:12 a.m., Amos Jeffries wrote:
> On 24/06/2015 3:26 a.m., Alex Rousskov wrote:
>> On 06/19/2015 06:46 PM, Amos Jeffries wrote:
>>> On 20/06/2015 4:54 a.m., Alex Rousskov wrote:
>>>> Hello,
>>>>
>>>>     The attached trunk patch fixes a rare but nasty problem by removing
>>>> a very old hack which shielded Squid from parsing most CONNECT responses.
>>>>
>>>> Currently, Squid blindly forwards cache peer CONNECT responses to
>>>> clients when possible. This may break things if the peer responds with
>>>> something like HTTP 403 (Forbidden) and keeps the connection with Squid
>>>> open:
>>>>
>>>>   -  The client application issues a CONNECT request.
>>>>   -  Squid forwards this request to a cache peer.
>>>>   -  Cache peer correctly responds back with a "403 Forbidden".
>>>>   -  Squid does not parse cache peer response and
>>>>      just forwards it as if it was a Squid response to the client.
>>>>   -  The TCP connections are not closed.
>>>>
>>>> At this stage, Squid is unaware that the CONNECT request has failed. All
>>>> subsequent requests on the user agent TCP connection are treated as
>>>> tunnelled traffic. Squid is forwarding these requests to the peer on the
>>>> TCP connection previously used for the 403-ed CONNECT request, without
>>>> proper processing. The additional headers which should have been applied
>>>> by Squid to these requests are not applied, and the requests are being
>>>> forwarded to the cache peer even though the Squid configuration may
>>>> state that these requests must go directly to the origin server.
>>>>
>>>> This patch fixes Squid to parse cache peer responses, and if an error
>>>> response found, respond with "502 Bad Gateway" to the client and close
>>>> the connections.
>>>>
>>>
>>> Thank you. I've had this on my todo list for a long time.
>>>
>>> One problem though...
>>>
>>> The parse operations documented as being copied from http.cc
>>> processReplyHeader() do not match what trunk currently does for HTTP
>>> replies in that function.
>>
>>
>> How is that problem related to the proposed fix?
> 
> Ah. Sorry, You are right.
> 
> +1 from me. Please apply.

On second thoughts that traffic behaviour after errors is extremely
nasty. Applying immediately so I can backport into 3.5.6 without
incurring extra delays.

Amos

From squid3 at treenet.co.nz  Tue Jun 30 15:27:29 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 01 Jul 2015 03:27:29 +1200
Subject: [squid-dev] [PATCH] Crypto-NG: Use Security::PeerOptions for
 listening port TLS settings
Message-ID: <5592B561.3000405@treenet.co.nz>

Sorry for the size of this one. The bulk of this patch is symbol
shuffling to de-duplicate the TLS settings storage and parsing code.

The actual changes are relatively small:

* Shuffle relevant AnyP::PortCfg settings into a Security::PeerOptions
member object.
 - removes a lot of duplicate config parsing code.

* Shuffle flags= and options= parsing code from Ssl:: to
Security::PeerOptions and update to use Tokenizer,
 - fixes performance regression using c_str() on the stored SBuf,
 - fixes performance issue with xstrdup() for option tokens,
 - removes several calls to c-string manipulation.

* Add cachemgr 'config' report dumper of Security::PeerOptions for use
by all directives using it to dump tls-* parameter names. The old
parameter names are still accepted, and deprecation will follow in a
separate patch.
 - fixes bug where cache_peer was not dumping out its SSL/TLS config
settings at all.

* Remove the now obsolete and unused Ssl::OpenSSLtoSquidSSLVersion()

* Change the tls_outgoing_options default value from "disable" which did
not parse previously (now does). To setting TLS/1.0 minimum version with
SSLv3 disabled.

* Fix tls-min-version=1.N handling not to alter stored options= config
string. Now updates the binary representation in parsedOptions directly.

* Expose the TLS context creation and configuration to non-OpenSSL builds.
 - fixes bug where context creation by OpenSSL failed silently.


Amos
-------------- next part --------------
=== modified file 'doc/release-notes/release-4.sgml'
--- doc/release-notes/release-4.sgml	2015-06-19 07:13:57 +0000
+++ doc/release-notes/release-4.sgml	2015-06-29 12:56:55 +0000
@@ -23,74 +23,80 @@
 <p>We welcome feedback and bug reports. If you find a bug, please see <url url="http://wiki.squid-cache.org/SquidFaq/BugReporting">
    for how to submit a report with a stack trace.
 
 <sect1>Known issues
 <p>
 Although this release is deemed good enough for use in many setups, please note the existence of 
 <url url="http://bugs.squid-cache.org/buglist.cgi?query_format=advanced&amp;product=Squid&amp;bug_status=UNCONFIRMED&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=REOPENED&amp;version=4" name="open bugs against Squid-4">.
 
 <sect1>Changes since earlier releases of Squid-4
 <p>
 The Squid-4 change history can be <url url="http://www.squid-cache.org/Versions/v4/changesets/" name="viewed here">.
 
 
 <sect>Major new features since Squid-3.5
 <p>Squid 4 represents a new feature release above 3.5.
 
 <p>The most important of these new features are:
 <itemize>
 	<item>Helper concurrency channels changes
 	<item>Configurable helper queue size
-	<item>SSLv2 support removal
+	<item>SSL support removal
 	<item>MSNT-multi-domain helper removal
 </itemize>
 
 Most user-facing changes are reflected in squid.conf (see below).
 
 
 <sect1>Configurable helper queue size
 <p>The new queue-size=N option to helpers configuration, allows users 
 to configure the maximum number of queued requests to busy helpers.
 
 <sect1>Helper concurrency channels changes
 <p> helper-mux.pl we have been distributing for the past few years to
     encourage use of concurrency is no longer compatible with Squid. If
     used it will spawn up to 2^64 helpers and DoS the Squid server.
 
 <p> Helpers utilizing arrays to handle fixed amounts of concurrency
     channels MUST be re-written to use queues and capable of handling a
     64-bit int as index or they will be vulnerable to buffer overrun and
     arbitrary memory accesses.
 
 <p> 32-bit helpers need re-writing to handle the concurrency channel ID
     as a 64-bit integer value. If not updated they will cause proxies to
     return unexpected results or timeout once crossing the 32-bit wrap
     boundary. Leading to undefined behaviour in the client HTTP traffic.
 
-<sect1>SSLv2 support removal
+<sect1>SSL support removal
 <p>Details in <url url="https://tools.ietf.org/html/rfc6176" name="RFC 6176">
+   and <url url="https://tools.ietf.org/html/rfc7568" name="RFC 7568">
 
 <p>SSLv2 is not fit for purpose. Squid no longer supports being configured with
 any settings regarding this protocol. That includes settings manually disabling
 its use since it is now forced to disable by default. Also settings enabling
 various client/server workarounds specific to SSLv2 are removed.
 
+<p>SSLv3 is not fit for purpose. Squid still accepts configuration, but use
+is deprecated and will be removed entirely in a future version.
+Squid default behavour is to follow the TLS built in negotiation mechanism
+which prefers the latest TLS version.
+
 
 <sect1>MSNT-multi-domain helper removal
 
 <p>The <em>basic_msnt_multi_domain_auth</em> helper has been removed. The
    <em>basic_smb_lm_auth</em> helper performs the same actions without extra
    Perl and Samba dependencies.
 
 
 <sect>Changes to squid.conf since Squid-3.5
 <p>
 There have been changes to Squid's configuration file since Squid-3.5.
 
 This section gives a thorough account of those changes in three categories:
 
 <itemize>
 	<item><ref id="newtags" name="New tags">
 	<item><ref id="modifiedtags" name="Changes to existing tags">
 	<item><ref id="removedtags" name="Removed tags">
 </itemize>
 <p>
@@ -101,59 +107,61 @@
 	<tag>tls_outgoing_options</tag>
 	<p>New tag to define TLS security context options for outgoing
 	   connections. For example to HTTPS servers.
 
 	<tag>url_rewrite_timeout</tag>
 	<p>Squid times active requests to redirector. This option sets
 	   the timeout value and the Squid reaction to a timed out
 	   request.
 
 </descrip>
 
 <sect1>Changes to existing tags<label id="modifiedtags">
 <p>
 <descrip>
 	<tag>auth_param</tag>
 	<p>New parameter <em>queue-size=</em> to set the maximum number
 	   of queued requests.
 
 	<tag>cache_peer</tag>
 	<p>New option <em>tls-min-version=1.N</em> to set minimum TLS version allowed.
-	<p>All <em>ssloptions=</em> values for
-	   SSLv2 configuration or disabling have been removed.
-	<p>Removed <em>sslversion=</em> option. Use <em>ssloptions=</em> instead.
+	<p>All <em>ssloptions=</em> values for SSLv2 configuration or disabling
+	   have been removed.
+	<p>Removed <em>sslversion=</em> option. Use <em>tls-options=</em> instead.
 	<p>Manual squid.conf update may be required on upgrade.
 
 	<tag>external_acl_type</tag>
 	<p>New parameter <em>queue-size=</em> to set the maximum number
 	   of queued requests.
 
 	<tag>http_port</tag>
-	<p>All <em>option=</em> values for SSLv2
-	   configuration or disabling have been removed.
-	<p>Removed <em>version=</em> option. Use <em>options=</em> instead.
+	<p>New option <em>tls-min-version=1.N</em> to set minimum TLS version allowed.
+	<p>All <em>option=</em> values for SSLv2 configuration or disabling
+	   have been removed.
+	<p>Removed <em>version=</em> option. Use <em>tls-options=</em> instead.
 	<p>Manual squid.conf update may be required on upgrade.
 
 	<tag>https_port</tag>
+	<p>New option <em>tls-min-version=1.N</em> to set minimum TLS version allowed.
 	<p>All <em>options=</em> values for SSLv2
 	   configuration or disabling have been removed.
-	<p>Removed <em>version=</em> option. Use <em>options=</em> instead.
+	<p>Removed <em>version=</em> option. Use <em>tls-options=</em> instead.
 	<p>New <em>options=SINGLE_ECDH_USE</em> parameter to enable ephemeral
 	   ECDH key exchange.
 	<p>Deprecated <em>dhparams=</em> option. Use <em>tls-dh=</em> instead.
 	   The new option allows to optionally specify an elliptic curve for
 	   ephemeral ECDH by adding <em>curve-name:</em> in front of the
 	   parameter file name.
 	<p>Manual squid.conf update may be required on upgrade.
 
 	<tag>refresh_pattern</tag>
 	<p>Removed <em>ignore-auth</em>. Its commonly desired behaviour is
 	   performed by default with correct HTTP/1.1 revalidation.
 	<p>Removed <em>ignore-must-revalidate</em>. Other more HTTP compliant
 	   directives can be used to prevent objects from caching.
 
 	<tag>sslcrtd_children</tag>
 	<p>New parameter <em>queue-size=</em> to set the maximum number
 	   of queued requests.
 
 	<tag>sslcrtvalidator_children</tag>
 	<p>New parameter <em>queue-size=</em> to set the maximum number

=== modified file 'src/CachePeer.h'
--- src/CachePeer.h	2015-02-26 10:25:12 +0000
+++ src/CachePeer.h	2015-03-23 08:56:03 +0000
@@ -165,32 +165,31 @@
     struct {
         unsigned int hash;
         double load_multiplier;
         double load_factor; /* normalized weight value */
     } sourcehash;
 
     char *login;        /* Proxy authorization */
     time_t connect_timeout;
     int connect_fail_limit;
     int max_conn;
     struct {
         PconnPool *pool; ///< idle connection pool for this peer
         CbcPointer<PeerPoolMgr> mgr; ///< pool manager
         int limit; ///< the limit itself
         bool waitingForClose; ///< a conn must close before we open a standby conn
     } standby; ///< optional "cache_peer standby=limit" feature
     char *domain;       /* Forced domain */
 
     /// security settings for peer connection
     Security::PeerOptions secure;
-
+    Security::ContextPointer sslContext;
 #if USE_OPENSSL
-    SSL_CTX *sslContext;
     SSL_SESSION *sslSession;
 #endif
 
     int front_end_https;
     int connection_auth;
 };
 
 #endif /* SQUID_CACHEPEER_H_ */
 

=== modified file 'src/Makefile.am'
--- src/Makefile.am	2015-06-01 06:21:54 +0000
+++ src/Makefile.am	2015-06-28 14:15:53 +0000
@@ -590,49 +590,49 @@
 
 nodist_squid_SOURCES = \
 	$(DISKIO_GEN_SOURCE) \
 	$(BUILT_SOURCES)
 
 squid_LDADD = \
 	$(AUTH_ACL_LIBS) \
 	ident/libident.la \
 	acl/libacls.la \
 	acl/libstate.la \
 	$(AUTH_LIBS) \
 	$(DISK_LIBS) \
 	acl/libapi.la \
 	clients/libclients.la \
 	servers/libservers.la \
 	ftp/libftp.la \
 	helper/libhelper.la \
 	http/libsquid-http.la \
 	parser/libsquid-parser.la \
 	dns/libdns.la \
-	security/libsecurity.la \
 	base/libbase.la \
 	libsquid.la \
 	ip/libip.la \
 	fs/libfs.la \
 	$(SSL_LIBS) \
 	ipc/libipc.la \
 	mgr/libmgr.la \
 	anyp/libanyp.la \
+	security/libsecurity.la \
 	comm/libcomm.la \
 	eui/libeui.la \
 	icmp/libicmp.la icmp/libicmp-core.la \
 	log/liblog.la \
 	format/libformat.la \
 	$(XTRA_OBJS) \
 	$(DISK_LINKOBJS) \
 	$(REPL_OBJS) \
 	$(DISK_OS_LIBS) \
 	$(NETTLELIB) \
 	$(CRYPTLIB) \
 	$(REGEXLIB) \
 	$(ADAPTATION_LIBS) \
 	$(ESI_LIBS) \
 	$(SNMP_LIBS) \
 	mem/libmem.la \
 	$(top_builddir)/lib/libmisccontainers.la \
 	$(top_builddir)/lib/libmiscencoding.la \
 	$(top_builddir)/lib/libmiscutil.la \
 	$(SSLLIB) \
@@ -1149,40 +1149,41 @@
 	tests/stub_SBufDetailedStats.cc \
 	String.cc \
 	StrList.h \
 	StrList.cc \
 	log/access_log.h \
 	tests/stub_access_log.cc \
 	cache_cf.h \
 	YesNoNone.h \
 	tests/stub_cache_cf.cc \
 	tests/stub_cache_manager.cc \
 	tests/stub_comm.cc \
 	tests/stub_debug.cc \
 	tests/stub_errorpage.cc \
 	tests/stub_event.cc \
 	tests/stub_fd.cc \
 	tests/stub_HelperChildConfig.cc \
 	tests/stub_libformat.cc \
 	tests/stub_libauth.cc \
 	tests/stub_libcomm.cc \
 	tests/stub_libmgr.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_libsslsquid.cc \
 	StatCounters.h \
 	StatCounters.cc \
 	StatHist.h \
 	tests/stub_StatHist.cc \
 	repl_modules.h \
 	tests/stub_store.cc \
 	tests/stub_store_stats.cc \
 	tools.h \
 	tests/stub_tools.cc \
 	tests/stub_HttpRequest.cc \
 	tests/testHttpReply.cc \
 	tests/testHttpReply.h \
 	tests/stub_time.cc \
 	url.cc \
 	wordlist.h \
 	wordlist.cc
 nodist_tests_testHttpReply_SOURCES=\
 	$(TESTSOURCES)
 tests_testHttpReply_LDFLAGS = $(LIBADD_DL)
@@ -1231,40 +1232,41 @@
 	HttpHeaderTools.cc \
 	HttpHdrContRange.cc \
 	HttpHdrRange.cc \
 	HttpHeaderFieldStat.h \
 	HttpHdrCc.h \
 	HttpHdrCc.cc \
 	HttpHdrCc.cci \
 	HttpHdrSc.cc \
 	HttpHdrScTarget.cc \
 	HttpMsg.cc \
 	int.h \
 	int.cc \
 	MasterXaction.cc \
 	MasterXaction.h \
 	Notes.cc \
 	Notes.h \
 	SquidList.h \
 	SquidList.cc \
 	mem_node.cc \
 	Parsing.cc \
+	tests/stub_libsecurity.cc \
 	SquidMath.cc \
 	StatCounters.cc \
 	StatCounters.h \
 	StatHist.h \
 	StrList.h \
 	StrList.cc \
 	tests/stub_StatHist.cc \
 	stmem.cc \
 	$(SBUF_SOURCE) \
 	SBufDetailedStats.h \
 	tests/stub_SBufDetailedStats.cc \
 	String.cc \
 	store_dir.cc \
 	StoreIOState.cc \
 	tests/stub_StoreMeta.cc \
 	StoreMetaUnpacker.cc \
 	StoreSwapLogData.cc \
 	store_key_md5.h \
 	store_key_md5.cc \
 	swap_log_op.cc \
@@ -1656,40 +1658,41 @@
 	HttpHeader.cc \
 	HttpMsg.cc \
 	HttpReply.cc \
 	int.h \
 	int.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
 	MasterXaction.h \
 	MemBuf.cc \
 	MemObject.cc \
 	mem_node.cc \
 	Notes.h \
 	Notes.cc \
 	Parsing.cc \
 	refresh.h \
 	refresh.cc \
 	RemovalPolicy.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
+	tests/stub_libsecurity.cc \
 	StatCounters.h \
 	StatCounters.cc \
 	StatHist.h \
 	tests/stub_StatHist.cc \
 	stmem.cc \
 	$(SBUF_SOURCE) \
 	SBufDetailedStats.h \
 	tests/stub_SBufDetailedStats.cc \
 	StoreFileSystem.cc \
 	StoreIOState.cc \
 	tests/stub_StoreMeta.cc \
 	StoreMetaUnpacker.cc \
 	StoreSwapLogData.cc \
 	store_dir.cc \
 	store_io.cc \
 	store_key_md5.h \
 	store_key_md5.cc \
 	store_swapout.cc \
 	store_swapmeta.cc \
 	repl_modules.h \
@@ -2135,41 +2138,40 @@
 	HttpHdrCc.cci \
 	HttpHdrContRange.cc \
 	HttpHdrRange.cc \
 	HttpHdrSc.cc \
 	HttpHdrScTarget.cc \
 	HttpMsg.cc \
 	HttpReply.cc \
 	PeerPoolMgr.h \
 	PeerPoolMgr.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
 	HttpRequest.cc \
 	icp_v2.cc \
 	icp_v3.cc \
 	$(IPC_SOURCE) \
 	ipcache.cc \
 	int.h \
 	int.cc \
 	internal.h \
 	internal.cc \
-	tests/stub_libsecurity.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
 	MasterXaction.h \
 	MemBuf.cc \
 	MemObject.cc \
 	tests/stub_libmem.cc \
 	mem_node.cc \
 	mime.h \
 	mime.cc \
 	mime_header.h \
 	mime_header.cc \
 	multicast.h \
 	multicast.cc \
 	neighbors.h \
 	neighbors.cc \
 	Notes.cc \
 	Notes.h \
 	Parsing.cc \
 	pconn.cc \
@@ -2216,40 +2218,41 @@
 	store_swapin.h \
 	store_swapin.cc \
 	store_swapmeta.cc \
 	store_swapout.cc \
 	StoreFileSystem.cc \
 	StoreIOState.cc \
 	tests/stub_StoreMeta.cc \
 	StoreMetaUnpacker.cc \
 	StoreSwapLogData.cc \
 	String.cc \
 	StrList.h \
 	StrList.cc \
 	tests/stub_SwapDir.cc \
 	tests/testEventLoop.cc \
 	tests/testEventLoop.h \
 	tests/stub_main_cc.cc \
 	tests/stub_ipc_Forwarder.cc \
 	tests/stub_libauth_acls.cc \
 	tests/stub_libauth.cc \
 	tests/stub_libeui.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_store_stats.cc \
 	time.cc \
 	tools.h \
 	tools.cc \
 	Transients.cc \
 	tests/stub_tunnel.cc \
 	MemStore.cc \
 	$(UNLINKDSOURCE) \
 	url.cc \
 	urn.h \
 	urn.cc \
 	wccp2.h \
 	tests/stub_wccp2.cc \
 	whois.h \
 	tests/stub_whois.cc \
 	$(WIN32_SOURCE) \
 	wordlist.h \
 	wordlist.cc
 nodist_tests_testEventLoop_SOURCES = \
 	$(BUILT_SOURCES) \
@@ -2375,41 +2378,40 @@
 	HttpHeader.h \
 	HttpHeader.cc \
 	HttpHeaderFieldInfo.h \
 	HttpHeaderTools.h \
 	HttpHeaderTools.cc \
 	HttpMsg.cc \
 	HttpReply.cc \
 	PeerPoolMgr.h \
 	PeerPoolMgr.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
 	HttpRequest.cc \
 	icp_v2.cc \
 	icp_v3.cc \
 	int.h \
 	int.cc \
 	internal.h \
 	internal.cc \
 	$(IPC_SOURCE) \
 	ipcache.cc \
-	tests/stub_libsecurity.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
 	MasterXaction.h \
 	MemBuf.cc \
 	MemObject.cc \
 	tests/stub_libmem.cc \
 	mem_node.cc \
 	mime.h \
 	mime.cc \
 	mime_header.h \
 	mime_header.cc \
 	multicast.h \
 	multicast.cc \
 	neighbors.h \
 	neighbors.cc \
 	Notes.cc \
 	Notes.h \
 	Parsing.cc \
 	peer_digest.cc \
@@ -2454,40 +2456,41 @@
 	store_rebuild.h \
 	store_rebuild.cc \
 	store_swapin.h \
 	store_swapin.cc \
 	store_swapmeta.cc \
 	store_swapout.cc \
 	StoreFileSystem.cc \
 	StoreIOState.cc \
 	tests/stub_StoreMeta.cc \
 	StoreMetaUnpacker.cc \
 	StoreSwapLogData.cc \
 	String.cc \
 	StrList.h \
 	StrList.cc \
 	tests/stub_SwapDir.cc \
 	Transients.cc \
 	tests/test_http_range.cc \
 	tests/stub_external_acl.cc \
 	tests/stub_ipc_Forwarder.cc \
 	tests/stub_libeui.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_main_cc.cc \
 	tests/stub_MemStore.cc \
 	tests/stub_store_stats.cc \
 	tests/stub_EventLoop.cc \
 	time.cc \
 	tools.h \
 	tools.cc \
 	tests/stub_tunnel.cc \
 	$(UNLINKDSOURCE) \
 	url.cc \
 	urn.h \
 	urn.cc \
 	wccp2.h \
 	tests/stub_wccp2.cc \
 	whois.h \
 	tests/stub_whois.cc \
 	$(WIN32_SOURCE) \
 	wordlist.h \
 	wordlist.cc
 nodist_tests_test_http_range_SOURCES = \
@@ -2542,40 +2545,41 @@
 tests_testHttp1Parser_SOURCES = \
 	Debug.h \
 	MemBuf.cc \
 	MemBuf.h \
 	tests/stub_MemObject.cc \
 	tests/stub_libmem.cc \
 	mime_header.cc \
 	mime_header.h \
 	String.cc \
 	cache_cf.h \
 	YesNoNone.h \
 	$(SBUF_SOURCE) \
 	tests/stub_SBufDetailedStats.cc \
 	tests/stub_cache_cf.cc \
 	tests/stub_cache_manager.cc \
 	tests/stub_comm.cc \
 	tests/stub_cbdata.cc \
 	tests/stub_debug.cc \
 	tests/stub_event.cc \
 	tests/stub_HelperChildConfig.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_stmem.cc \
 	tests/stub_store.cc \
 	tests/stub_store_stats.cc \
 	tools.h \
 	tests/stub_tools.cc \
 	tests/testHttp1Parser.cc \
 	tests/testHttp1Parser.h \
 	tests/stub_time.cc \
 	wordlist.h \
 	wordlist.cc
 nodist_tests_testHttp1Parser_SOURCES = \
 	$(TESTSOURCES)
 tests_testHttp1Parser_LDADD= \
 	http/libsquid-http.la \
 	parser/libsquid-parser.la \
 	anyp/libanyp.la \
 	SquidConfig.o \
 	base/libbase.la \
 	ip/libip.la \
 	$(top_builddir)/lib/libmiscutil.la \
@@ -2908,40 +2912,41 @@
 	tests/stub_access_log.cc \
 	tests/stub_acl.cc \
 	cache_cf.h \
 	YesNoNone.h \
 	tests/stub_cache_cf.cc \
 	tests/stub_cache_manager.cc \
 	tests/stub_client_side_request.cc \
 	tests/stub_comm.cc \
 	tests/stub_debug.cc \
 	tests/stub_DiskIOModule.cc \
 	tests/stub_errorpage.cc \
 	fd.h \
 	fde.h \
 	tests/stub_fd.cc \
 	tests/stub_helper.cc \
 	tests/stub_HelperChildConfig.cc \
 	tests/stub_http.cc \
 	tests/stub_libauth.cc \
 	tests/stub_libeui.cc \
 	tests/stub_libformat.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_libsslsquid.cc \
 	HttpBody.h \
 	HttpBody.cc \
 	tests/stub_HttpReply.cc \
 	tests/stub_HttpRequest.cc \
 	tests/stub_libcomm.cc \
 	tests/stub_MemStore.cc \
 	mime.h \
 	tests/stub_mime.cc \
 	tests/stub_Port.cc \
 	tests/stub_stat.cc \
 	tests/stub_store_client.cc \
 	tests/stub_store_stats.cc \
 	store_rebuild.h \
 	tests/stub_store_rebuild.cc \
 	tests/stub_store_swapout.cc \
 	tools.h \
 	Transients.cc \
 	tests/stub_tools.cc \
 	tests/stub_UdsOp.cc \
@@ -3058,40 +3063,41 @@
 tests_testUfs_SOURCES = \
 	tests/testUfs.cc \
 	tests/testUfs.h \
 	tests/stub_cache_manager.cc \
 	tests/stub_client_db.cc \
 	tests/stub_CollapsedForwarding.cc \
 	tests/stub_HelperChildConfig.cc \
 	tests/stub_icp.cc \
 	tests/stub_ipc.cc \
 	tests/stub_ipcache.cc \
 	tests/stub_libeui.cc \
 	tests/stub_libicmp.cc \
 	tests/stub_MemStore.cc \
 	tests/stub_neighbors.cc \
 	tests/stub_pconn.cc \
 	tests/stub_Port.cc \
 	tests/stub_UdsOp.cc \
 	internal.h \
 	tests/stub_internal.cc \
 	tests/stub_libformat.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_stat.cc \
 	store_rebuild.h \
 	tests/stub_store_rebuild.cc \
 	tests/stub_store_stats.cc \
 	fatal.h \
 	tests/stub_fatal.cc \
 	fd.h \
 	fd.cc \
 	fde.h \
 	fde.cc \
 	client_db.h \
 	disk.h \
 	disk.cc \
 	FileMap.h \
 	filemap.cc \
 	HttpBody.h \
 	HttpBody.cc \
 	HttpReply.cc \
 	int.h \
 	int.cc \
@@ -3334,40 +3340,41 @@
 	cache_cf.h \
 	YesNoNone.h \
 	tests/stub_cache_cf.cc \
 	client_db.h \
 	tests/stub_cache_manager.cc \
 	tests/stub_client_db.cc \
 	tests/stub_client_side_request.cc \
 	tests/stub_debug.cc \
 	tests/stub_errorpage.cc \
 	tests/stub_HelperChildConfig.cc \
 	tests/stub_http.cc \
 	tests/stub_HttpRequest.cc \
 	tests/stub_libauth.cc \
 	tests/stub_icp.cc \
 	tests/stub_ipc.cc \
 	tests/stub_ipcache.cc \
 	tests/stub_libeui.cc \
 	tests/stub_libformat.cc \
 	tests/stub_libicmp.cc \
 	tests/stub_libmgr.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_MemStore.cc \
 	mime.h \
 	tests/stub_mime.cc \
 	tests/stub_neighbors.cc \
 	tests/stub_Port.cc \
 	tests/stub_pconn.cc \
 	tests/stub_store_client.cc \
 	store_rebuild.h \
 	tests/stub_store_rebuild.cc \
 	tests/stub_store_stats.cc \
 	tools.h \
 	tests/stub_tools.cc \
 	time.cc \
 	url.cc \
 	wordlist.h \
 	wordlist.cc \
 	$(DELAY_POOL_SOURCE) \
 	$(DISKIO_SOURCE) \
 	$(UNLINKDSOURCE)
 nodist_tests_testRock_SOURCES = \
@@ -3486,41 +3493,40 @@
 	HttpHeader.h \
 	HttpHeader.cc \
 	HttpHeaderFieldInfo.h \
 	HttpHeaderTools.h \
 	HttpHeaderTools.cc \
 	HttpMsg.cc \
 	HttpReply.cc \
 	PeerPoolMgr.h \
 	PeerPoolMgr.cc \
 	RequestFlags.h \
 	RequestFlags.cc \
 	HttpRequest.cc \
 	icp_v2.cc \
 	icp_v3.cc \
 	$(IPC_SOURCE) \
 	ipcache.cc \
 	int.h \
 	int.cc \
 	internal.h \
 	internal.cc \
-	tests/stub_libsecurity.cc \
 	SquidList.h \
 	SquidList.cc \
 	MasterXaction.cc \
 	MasterXaction.h \
 	multicast.h \
 	multicast.cc \
 	tests/stub_libmem.cc \
 	mem_node.cc \
 	MemBuf.cc \
 	MemObject.cc \
 	mime.h \
 	mime.cc \
 	mime_header.h \
 	mime_header.cc \
 	neighbors.h \
 	neighbors.cc \
 	Notes.h \
 	Notes.cc \
 	Parsing.cc \
 	pconn.cc \
@@ -3566,40 +3572,41 @@
 	store_rebuild.cc \
 	store_swapin.h \
 	store_swapin.cc \
 	store_swapmeta.cc \
 	store_swapout.cc \
 	StoreFileSystem.cc \
 	StoreIOState.cc \
 	tests/stub_StoreMeta.cc \
 	StoreMetaUnpacker.cc \
 	StoreSwapLogData.cc \
 	String.cc \
 	StrList.h \
 	StrList.cc \
 	Transients.cc \
 	tests/stub_SwapDir.cc \
 	MemStore.cc \
 	tests/stub_debug.cc \
 	tests/stub_DiskIOModule.cc \
 	tests/stub_libauth_acls.cc \
 	tests/stub_libauth.cc \
+	tests/stub_libsecurity.cc \
 	tests/stub_main_cc.cc \
 	tests/stub_ipc_Forwarder.cc \
 	tests/stub_store_stats.cc \
 	tests/testURL.cc \
 	tests/testURL.h \
 	tests/testUriScheme.cc \
 	tests/testUriScheme.h \
 	tests/stub_time.cc \
 	tests/stub_EventLoop.cc \
 	tools.h \
 	tools.cc \
 	tests/stub_tunnel.cc \
 	url.cc \
 	urn.h \
 	urn.cc \
 	wccp2.h \
 	tests/stub_wccp2.cc \
 	whois.h \
 	tests/stub_whois.cc \
 	FadingCounter.cc \

=== modified file 'src/SquidConfig.h'
--- src/SquidConfig.h	2015-05-15 12:50:09 +0000
+++ src/SquidConfig.h	2015-06-13 07:27:11 +0000
@@ -1,46 +1,43 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_SQUIDCONFIG_H_
 #define SQUID_SQUIDCONFIG_H_
 
 #include "acl/forward.h"
 #include "base/RefCount.h"
 #include "ClientDelayConfig.h"
 #include "DelayConfig.h"
 #include "helper/ChildConfig.h"
 #include "HttpHeaderTools.h"
 #include "ip/Address.h"
 #include "Notes.h"
+#include "security/forward.h"
 #include "YesNoNone.h"
 
 #if USE_OPENSSL
-#if HAVE_OPENSSL_SSL_H
-#include <openssl/ssl.h>
-#endif
-
 class sslproxy_cert_sign;
 class sslproxy_cert_adapt;
 #endif
 
 namespace Mgr
 {
 class ActionPasswordList;
 } // namespace Mgr
 class CustomLog;
 class CpuAffinityMap;
 class external_acl;
 class HeaderManglers;
 class RefreshPattern;
 class RemovalPolicySettings;
 class SwapDir;
 
 namespace AnyP
 {
 class PortCfg;
 }
@@ -475,48 +472,48 @@
         int unclean_shutdown;
         char *ssl_engine;
         int session_ttl;
         size_t sessionCacheSize;
         char *certSignHash;
     } SSL;
 #endif
 
     wordlist *ext_methods;
 
     struct {
         int high_rptm;
         int high_pf;
         size_t high_memory;
     } warnings;
     char *store_dir_select_algorithm;
     int sleep_after_fork;   /* microseconds */
     time_t minimum_expiry_time; /* seconds */
     external_acl *externalAclHelperList;
 
-#if USE_OPENSSL
     struct {
+        Security::ContextPointer sslContext;
+#if USE_OPENSSL
         acl_access *cert_error;
-        SSL_CTX *sslContext;
         sslproxy_cert_sign *cert_sign;
         sslproxy_cert_adapt *cert_adapt;
-    } ssl_client;
 #endif
+    } ssl_client;
 
     char *accept_filter;
     int umask;
     int max_filedescriptors;
     int workers;
     CpuAffinityMap *cpuAffinityMap;
 
 #if USE_LOADABLE_MODULES
     wordlist *loadable_module_names;
 #endif
 
     int client_ip_max_connections;
 
     char *redirector_extras;
 
     struct UrlHelperTimeout {
         int action;
         char *response;
     } onUrlRewriteTimeout;
 

=== modified file 'src/adaptation/icap/ServiceRep.cc'
--- src/adaptation/icap/ServiceRep.cc	2015-05-26 17:25:04 +0000
+++ src/adaptation/icap/ServiceRep.cc	2015-06-13 12:06:24 +0000
@@ -67,41 +67,41 @@
     const bool have_port = cfg().port >= 0;
     if (!have_port) {
         struct servent *serv;
         if (cfg().protocol.caseCmp("icaps") == 0)
             serv = getservbyname("icaps", "tcp");
         else
             serv = getservbyname("icap", "tcp");
 
         if (serv) {
             writeableCfg().port = htons(serv->s_port);
         } else {
             writeableCfg().port = cfg().protocol.caseCmp("icaps") == 0 ? DEFAULT_ICAPS_PORT : DEFAULT_ICAP_PORT;
         }
     }
 
     if (cfg().protocol.caseCmp("icaps") == 0)
         writeableCfg().secure.encryptTransport = true;
 
     if (cfg().secure.encryptTransport) {
         debugs(3, DBG_IMPORTANT, "Initializing service " << cfg().resource << " SSL context");
-        sslContext = writeableCfg().secure.createContext(true);
+        sslContext = writeableCfg().secure.createClientContext(true);
     }
 
     theSessionFailures.configure(TheConfig.oldest_service_failure > 0 ?
                                  TheConfig.oldest_service_failure : -1);
 }
 
 void Adaptation::Icap::ServiceRep::noteFailure()
 {
     const int failures = theSessionFailures.count(1);
     debugs(93,4, HERE << " failure " << failures << " out of " <<
            TheConfig.service_failure_limit << " allowed in " <<
            TheConfig.oldest_service_failure << "sec " << status());
 
     if (isSuspended)
         return;
 
     if (TheConfig.service_failure_limit >= 0 &&
             failures > TheConfig.service_failure_limit)
         suspend("too many failures");
 

=== modified file 'src/anyp/PortCfg.cc'
--- src/anyp/PortCfg.cc	2015-06-29 12:46:17 +0000
+++ src/anyp/PortCfg.cc	2015-06-29 13:01:14 +0000
@@ -1,260 +1,191 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #include "squid.h"
 #include "anyp/PortCfg.h"
 #include "comm.h"
 #include "fatal.h"
-#include "SBuf.h"
+#include "security/PeerOptions.h"
 #if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
 #include <cstring>
 #include <limits>
 
 AnyP::PortCfgPointer HttpPortList;
 #if USE_OPENSSL
 AnyP::PortCfgPointer HttpsPortList;
 #endif
 AnyP::PortCfgPointer FtpPortList;
 
 int NHttpSockets = 0;
 int HttpSockets[MAXTCPLISTENPORTS];
 
 AnyP::PortCfg::PortCfg() :
     next(),
     s(),
     transport(AnyP::PROTO_HTTP,1,1), // "Squid is an HTTP proxy", etc.
     name(NULL),
     defaultsite(NULL),
     flags(),
     allow_direct(false),
     vhost(false),
     actAsOrigin(false),
     ignore_cc(false),
     connection_auth_disabled(false),
     ftp_track_dirs(false),
     vport(0),
     disable_pmtu_discovery(0),
     listenConn()
 #if USE_OPENSSL
-    ,cert(NULL),
-    key(NULL),
-    version(0),
-    cipher(NULL),
-    options(NULL),
+    ,
     clientca(NULL),
-    cafile(NULL),
-    capath(NULL),
-    crlfile(NULL),
     dhfile(NULL),
     tls_dh(NULL),
-    sslflags(NULL),
     sslContextSessionId(NULL),
     generateHostCertificates(false),
     dynamicCertMemCacheSize(std::numeric_limits<size_t>::max()),
     staticSslContext(),
     signingCert(),
     signPkey(),
     certsToChain(),
     untrustedSigningCert(),
     untrustedSignPkey(),
     clientVerifyCrls(),
     clientCA(),
     dhParams(),
-    eecdhCurve(NULL),
-    sslContextFlags(0),
-    sslOptions(0)
+    eecdhCurve(NULL)
 #endif
 {
     memset(&tcp_keepalive, 0, sizeof(tcp_keepalive));
 }
 
 AnyP::PortCfg::~PortCfg()
 {
     if (Comm::IsConnOpen(listenConn)) {
         listenConn->close();
         listenConn = NULL;
     }
 
     safe_free(name);
     safe_free(defaultsite);
 
 #if USE_OPENSSL
-    safe_free(cert);
-    safe_free(key);
-    safe_free(cipher);
-    safe_free(options);
     safe_free(clientca);
-    safe_free(cafile);
-    safe_free(capath);
-    safe_free(crlfile);
     safe_free(dhfile);
     safe_free(tls_dh);
-    safe_free(sslflags);
     safe_free(sslContextSessionId);
     safe_free(eecdhCurve);
 #endif
 }
 
 AnyP::PortCfgPointer
 AnyP::PortCfg::clone() const
 {
     AnyP::PortCfgPointer b = new AnyP::PortCfg();
     b->s = s;
     if (name)
         b->name = xstrdup(name);
     if (defaultsite)
         b->defaultsite = xstrdup(defaultsite);
 
     b->transport = transport;
     b->flags = flags;
     b->allow_direct = allow_direct;
     b->vhost = vhost;
     b->vport = vport;
     b->connection_auth_disabled = connection_auth_disabled;
     b->ftp_track_dirs = ftp_track_dirs;
     b->disable_pmtu_discovery = disable_pmtu_discovery;
     b->tcp_keepalive = tcp_keepalive;
+    b->secure = secure;
 
 #if USE_OPENSSL
-    if (cert)
-        b->cert = xstrdup(cert);
-    if (key)
-        b->key = xstrdup(key);
-    b->version = version;
-    if (cipher)
-        b->cipher = xstrdup(cipher);
-    if (options)
-        b->options = xstrdup(options);
     if (clientca)
         b->clientca = xstrdup(clientca);
-    if (cafile)
-        b->cafile = xstrdup(cafile);
-    if (capath)
-        b->capath = xstrdup(capath);
-    if (crlfile)
-        b->crlfile = xstrdup(crlfile);
     if (dhfile)
         b->dhfile = xstrdup(dhfile);
     if (tls_dh)
         b->tls_dh = xstrdup(tls_dh);
-    if (sslflags)
-        b->sslflags = xstrdup(sslflags);
     if (sslContextSessionId)
         b->sslContextSessionId = xstrdup(sslContextSessionId);
 
 #if 0
     // TODO: AYJ: 2015-01-15: for now SSL does not clone the context object.
     // cloning should only be done before the PortCfg is post-configure initialized and opened
     SSL_CTX *sslContext;
 #endif
 
 #endif /*0*/
 
     return b;
 }
 
 #if USE_OPENSSL
 void
 AnyP::PortCfg::configureSslServerContext()
 {
-    if (cert)
-        Ssl::readCertChainAndPrivateKeyFromFiles(signingCert, signPkey, certsToChain, cert, key);
+    if (!secure.certFile.isEmpty())
+        Ssl::readCertChainAndPrivateKeyFromFiles(signingCert, signPkey, certsToChain, secure.certFile.c_str(), secure.privateKeyFile.c_str());
 
     if (!signingCert) {
         char buf[128];
         fatalf("No valid signing SSL certificate configured for %s_port %s", AnyP::ProtocolType_str[transport.protocol],  s.toUrl(buf, sizeof(buf)));
     }
 
     if (!signPkey)
         debugs(3, DBG_IMPORTANT, "No SSL private key configured for  " << AnyP::ProtocolType_str[transport.protocol] << "_port " << s);
 
     Ssl::generateUntrustedCert(untrustedSigningCert, untrustedSignPkey,
                                signingCert, signPkey);
 
     if (!untrustedSigningCert) {
         char buf[128];
         fatalf("Unable to generate signing SSL certificate for untrusted sites for %s_port %s", AnyP::ProtocolType_str[transport.protocol], s.toUrl(buf, sizeof(buf)));
     }
 
-    if (crlfile)
-        clientVerifyCrls.reset(Ssl::loadCrl(crlfile, sslContextFlags));
+    if (!secure.crlFile.isEmpty())
+        clientVerifyCrls.reset(Ssl::loadCrl(secure.crlFile.c_str(), secure.parsedFlags));
 
     if (clientca) {
         clientCA.reset(SSL_load_client_CA_file(clientca));
         if (clientCA.get() == NULL) {
             fatalf("Unable to read client CAs! from %s", clientca);
         }
     }
 
-    // backward compatibility hack for sslversion= configuration
-    if (version > 2) {
-        const char *add = NULL;
-        switch (version) {
-        case 3:
-            add = "NO_TLSv1,NO_TLSv1_1,NO_TLSv1_2";
-            break;
-        case 4:
-            add = "NO_SSLv3,NO_TLSv1_1,NO_TLSv1_2";
-            break;
-        case 5:
-            add = "NO_SSLv3,NO_TLSv1,NO_TLSv1_2";
-            break;
-        case 6:
-            add = "NO_SSLv3,NO_TLSv1,NO_TLSv1_1";
-            break;
-        default: // nothing
-            break;
-        }
-        if (add) {
-            SBuf tmpOpts;
-            if (options) {
-                tmpOpts.append(options, strlen(options));
-                tmpOpts.append(",",1);
-            }
-            tmpOpts.append(add, strlen(add));
-            xfree(options);
-            options = xstrdup(tmpOpts.c_str());
-        }
-        version = 0; // prevent options being repeatedly appended
-    }
+    secure.updateTlsVersionLimits();
 
     const char *dhParamsFile = dhfile; // backward compatibility for dhparams= configuration
     safe_free(eecdhCurve); // clear any previous EECDH configuration
     if (tls_dh && *tls_dh) {
         eecdhCurve = xstrdup(tls_dh);
         char *p = strchr(eecdhCurve, ':');
         if (p) {  // tls-dh=eecdhCurve:dhParamsFile
             *p = '\0';
             dhParamsFile = p+1;
         } else {  // tls-dh=dhParamsFile
             dhParamsFile = tls_dh;
             // a NULL eecdhCurve means "do not use EECDH"
             safe_free(eecdhCurve);
         }
     }
 
     if (dhParamsFile && *dhParamsFile)
         dhParams.reset(Ssl::readDHParams(dhParamsFile));
 
-    if (sslflags)
-        sslContextFlags = Ssl::parse_flags(sslflags);
-
-    sslOptions = Ssl::parse_options(options);
-
     staticSslContext.reset(sslCreateServerContext(*this));
 
     if (!staticSslContext) {
         char buf[128];
         fatalf("%s_port %s initialization error", AnyP::ProtocolType_str[transport.protocol],  s.toUrl(buf, sizeof(buf)));
     }
 }
 #endif
 

=== modified file 'src/anyp/PortCfg.h'
--- src/anyp/PortCfg.h	2015-06-29 12:46:17 +0000
+++ src/anyp/PortCfg.h	2015-06-29 12:59:14 +0000
@@ -1,35 +1,37 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_ANYP_PORTCFG_H
 #define SQUID_ANYP_PORTCFG_H
 
 #include "anyp/forward.h"
 #include "anyp/ProtocolVersion.h"
 #include "anyp/TrafficMode.h"
 #include "comm/Connection.h"
+#include "SBuf.h"
+#include "security/PeerOptions.h"
 
 #if USE_OPENSSL
 #include "ssl/gadgets.h"
 #endif
 
 namespace AnyP
 {
 
 class PortCfg : public RefCountable
 {
 public:
     PortCfg();
     ~PortCfg();
     AnyP::PortCfgPointer clone() const;
 #if USE_OPENSSL
     /// creates, configures, and validates SSL context and related port options
     void configureSslServerContext();
 #endif
 
     PortCfgPointer next;
@@ -50,70 +52,62 @@
 
     bool ftp_track_dirs; ///< whether transactions should track FTP directories
 
     int vport;               ///< virtual port support. -1 if dynamic, >0 static
     int disable_pmtu_discovery;
 
     struct {
         unsigned int idle;
         unsigned int interval;
         unsigned int timeout;
         bool enabled;
     } tcp_keepalive;
 
     /**
      * The listening socket details.
      * If Comm::ConnIsOpen() we are actively listening for client requests.
      * use listenConn->close() to stop.
      */
     Comm::ConnectionPointer listenConn;
 
+    /// TLS configuration options for this listening port
+    Security::PeerOptions secure;
+
 #if USE_OPENSSL
-    char *cert;
-    char *key;
-    int version;
-    char *cipher;
-    char *options;
     char *clientca;
-    char *cafile;
-    char *capath;
-    char *crlfile;
     char *dhfile;
     char *tls_dh;
-    char *sslflags;
     char *sslContextSessionId; ///< "session id context" for staticSslContext
     bool generateHostCertificates; ///< dynamically make host cert for sslBump
     size_t dynamicCertMemCacheSize; ///< max size of generated certificates memory cache
 
     Ssl::SSL_CTX_Pointer staticSslContext; ///< for HTTPS accelerator or static sslBump
     Ssl::X509_Pointer signingCert; ///< x509 certificate for signing generated certificates
     Ssl::EVP_PKEY_Pointer signPkey; ///< private key for sighing generated certificates
     Ssl::X509_STACK_Pointer certsToChain; ///<  x509 certificates to send with the generated cert
     Ssl::X509_Pointer untrustedSigningCert; ///< x509 certificate for signing untrusted generated certificates
     Ssl::EVP_PKEY_Pointer untrustedSignPkey; ///< private key for signing untrusted generated certificates
 
     Ssl::X509_CRL_STACK_Pointer clientVerifyCrls; ///< additional CRL lists to use when verifying the client certificate
     Ssl::X509_NAME_STACK_Pointer clientCA; ///< CA certificates to use when verifying client certificates
     Ssl::DH_Pointer dhParams; ///< DH parameters for temporary/ephemeral DH key exchanges
     char *eecdhCurve; ///< Elliptic curve for ephemeral EC-based DH key exchanges
-    long sslContextFlags; ///< flags modifying the use of SSL
-    long sslOptions; ///< SSL engine options
 #endif
 };
 
 } // namespace AnyP
 
 /// list of Squid http_port configured
 extern AnyP::PortCfgPointer HttpPortList;
 
 #if USE_OPENSSL
 /// list of Squid https_port configured
 extern AnyP::PortCfgPointer HttpsPortList;
 #endif
 
 /// list of Squid ftp_port configured
 extern AnyP::PortCfgPointer FtpPortList;
 
 #if !defined(MAXTCPLISTENPORTS)
 // Max number of TCP listening ports
 #define MAXTCPLISTENPORTS 128
 #endif

=== modified file 'src/cache_cf.cc'
--- src/cache_cf.cc	2015-06-19 12:12:10 +0000
+++ src/cache_cf.cc	2015-06-30 15:13:41 +0000
@@ -848,58 +848,66 @@
 #endif
         }
     } else {
         Config2.effectiveUserID = geteuid();
         Config2.effectiveGroupID = getegid();
     }
 
     if (NULL != Config.effectiveGroup) {
 
         struct group *grp = getgrnam(Config.effectiveGroup);
 
         if (NULL == grp) {
             fatalf("getgrnam failed to find groupid for effective group '%s'",
                    Config.effectiveGroup);
             return;
         }
 
         Config2.effectiveGroupID = grp->gr_gid;
     }
 
-#if USE_OPENSSL
-
-    debugs(3, DBG_IMPORTANT, "Initializing https proxy context");
-
-    Config.ssl_client.sslContext = Security::ProxyOutgoingConfig.createContext(false);
+    if (Security::ProxyOutgoingConfig.encryptTransport) {
+        debugs(3, DBG_IMPORTANT, "Initializing https:// proxy context");
+        Config.ssl_client.sslContext = Security::ProxyOutgoingConfig.createClientContext(false);
+        if (!Config.ssl_client.sslContext) {
+            debugs(3, DBG_CRITICAL, "ERROR: Could not initialize https:// proxy context");
+            self_destruct();
+        }
+    }
 
     for (CachePeer *p = Config.peers; p != NULL; p = p->next) {
 
         // default value for ssldomain= is the peer host/IP
         if (p->secure.sslDomain.isEmpty())
             p->secure.sslDomain = p->host;
 
         if (p->secure.encryptTransport) {
-            debugs(3, DBG_IMPORTANT, "Initializing cache_peer " << p->name << " SSL context");
-            p->sslContext = p->secure.createContext(true);
+            debugs(3, DBG_IMPORTANT, "Initializing cache_peer " << p->name << " TLS context");
+            p->sslContext = p->secure.createClientContext(true);
+            if (!p->sslContext) {
+                debugs(3, DBG_CRITICAL, "ERROR: Could not initialize cache_peer " << p->name << " TLS context");
+                self_destruct();
+            }
         }
     }
 
+#if USE_OPENSSL
     for (AnyP::PortCfgPointer s = HttpPortList; s != NULL; s = s->next) {
         if (!s->flags.tunnelSslBumping)
             continue;
 
         debugs(3, DBG_IMPORTANT, "Initializing http_port " << s->s << " SSL context");
         s->configureSslServerContext();
     }
 
     for (AnyP::PortCfgPointer s = HttpsPortList; s != NULL; s = s->next) {
         debugs(3, DBG_IMPORTANT, "Initializing https_port " << s->s << " SSL context");
         s->configureSslServerContext();
     }
 
 #endif
 
     // prevent infinite fetch loops in the request parser
     // due to buffer full but not enough data recived to finish parse
     if (Config.maxRequestBufferSize <= Config.maxRequestHeaderSize) {
         fatalf("Client request buffer of %u bytes cannot hold a request with %u bytes of headers." \
                " Change client_request_buffer_max or request_header_max_size limits.",
@@ -2172,46 +2180,42 @@
         } else if (!strcmp(token, "originserver")) {
             p->options.originserver = true;
         } else if (!strncmp(token, "name=", 5)) {
             safe_free(p->name);
 
             if (token[5])
                 p->name = xstrdup(token + 5);
         } else if (!strncmp(token, "forceddomain=", 13)) {
             safe_free(p->domain);
             if (token[13])
                 p->domain = xstrdup(token + 13);
 
         } else if (strncmp(token, "ssl", 3) == 0) {
 #if !USE_OPENSSL
             debugs(0, DBG_CRITICAL, "WARNING: cache_peer option '" << token << "' requires --with-openssl");
 #else
             p->secure.encryptTransport = true;
             p->secure.parse(token+3);
 #endif
         } else if (strncmp(token, "tls-", 4) == 0) {
-#if !USE_OPENSSL
-            debugs(0, DBG_CRITICAL, "WARNING: cache_peer option '" << token << "' requires --with-openssl");
-#else
             p->secure.encryptTransport = true;
             p->secure.parse(token+4);
-#endif
         } else if (strcmp(token, "front-end-https") == 0) {
             p->front_end_https = 1;
         } else if (strcmp(token, "front-end-https=on") == 0) {
             p->front_end_https = 1;
         } else if (strcmp(token, "front-end-https=auto") == 0) {
             p->front_end_https = 2;
         } else if (strcmp(token, "connection-auth=off") == 0) {
             p->connection_auth = 0;
         } else if (strcmp(token, "connection-auth") == 0) {
             p->connection_auth = 1;
         } else if (strcmp(token, "connection-auth=on") == 0) {
             p->connection_auth = 1;
         } else if (strcmp(token, "connection-auth=auto") == 0) {
             p->connection_auth = 2;
         } else if (token[0] == '#') {
             // start of a text comment. stop reading this line.
             break;
         } else {
             debugs(3, DBG_PARSE_NOTE(DBG_IMPORTANT), "ERROR: Ignoring unknown cache_peer option '" << token << "'");
         }
@@ -3545,98 +3549,90 @@
             self_destruct();
         }
     } else if (strcmp(token, "tcpkeepalive") == 0) {
         s->tcp_keepalive.enabled = true;
     } else if (strncmp(token, "tcpkeepalive=", 13) == 0) {
         char *t = token + 13;
         s->tcp_keepalive.enabled = true;
         s->tcp_keepalive.idle = xatoui(t,',');
         t = strchr(t, ',');
         if (t) {
             ++t;
             s->tcp_keepalive.interval = xatoui(t,',');
             t = strchr(t, ',');
         }
         if (t) {
             ++t;
             s->tcp_keepalive.timeout = xatoui(t);
         }
 #if USE_OPENSSL
     } else if (strcmp(token, "sslBump") == 0) {
-        debugs(3, DBG_CRITICAL, "WARNING: '" << token << "' is deprecated " <<
+        debugs(3, DBG_PARSE_NOTE(1), "WARNING: '" << token << "' is deprecated " <<
                "in " << cfg_directive << ". Use 'ssl-bump' instead.");
         s->flags.tunnelSslBumping = true;
     } else if (strcmp(token, "ssl-bump") == 0) {
         s->flags.tunnelSslBumping = true;
     } else if (strncmp(token, "cert=", 5) == 0) {
-        safe_free(s->cert);
-        s->cert = xstrdup(token + 5);
+        s->secure.parse(token);
     } else if (strncmp(token, "key=", 4) == 0) {
-        safe_free(s->key);
-        s->key = xstrdup(token + 4);
+        s->secure.parse(token);
     } else if (strncmp(token, "version=", 8) == 0) {
         debugs(3, DBG_PARSE_NOTE(1), "UPGRADE WARNING: '" << token << "' is deprecated " <<
                "in " << cfg_directive << ". Use 'options=' instead.");
-        s->version = xatoi(token + 8);
-        if (s->version < 1 || s->version > 6)
-            self_destruct();
+        s->secure.parse(token);
     } else if (strncmp(token, "options=", 8) == 0) {
-        safe_free(s->options);
-        s->options = xstrdup(token + 8);
+        s->secure.parse(token);
     } else if (strncmp(token, "cipher=", 7) == 0) {
-        safe_free(s->cipher);
-        s->cipher = xstrdup(token + 7);
+        s->secure.parse(token);
     } else if (strncmp(token, "clientca=", 9) == 0) {
         safe_free(s->clientca);
         s->clientca = xstrdup(token + 9);
     } else if (strncmp(token, "cafile=", 7) == 0) {
-        safe_free(s->cafile);
-        s->cafile = xstrdup(token + 7);
+        s->secure.parse(token);
     } else if (strncmp(token, "capath=", 7) == 0) {
-        safe_free(s->capath);
-        s->capath = xstrdup(token + 7);
+        s->secure.parse(token);
     } else if (strncmp(token, "crlfile=", 8) == 0) {
-        safe_free(s->crlfile);
-        s->crlfile = xstrdup(token + 8);
+        s->secure.parse(token);
     } else if (strncmp(token, "dhparams=", 9) == 0) {
         debugs(3, DBG_PARSE_NOTE(DBG_IMPORTANT), "WARNING: '" << token << "' is deprecated " <<
                "in " << cfg_directive << ". Use 'tls-dh=' instead.");
         safe_free(s->dhfile);
         s->dhfile = xstrdup(token + 9);
     } else if (strncmp(token, "tls-dh=", 7) == 0) {
         safe_free(s->tls_dh);
         s->tls_dh = xstrdup(token + 7);
     } else if (strncmp(token, "sslflags=", 9) == 0) {
-        safe_free(s->sslflags);
-        s->sslflags = xstrdup(token + 9);
+        s->secure.parse(token+3);
     } else if (strncmp(token, "sslcontext=", 11) == 0) {
         safe_free(s->sslContextSessionId);
         s->sslContextSessionId = xstrdup(token + 11);
     } else if (strcmp(token, "generate-host-certificates") == 0) {
         s->generateHostCertificates = true;
     } else if (strcmp(token, "generate-host-certificates=on") == 0) {
         s->generateHostCertificates = true;
     } else if (strcmp(token, "generate-host-certificates=off") == 0) {
         s->generateHostCertificates = false;
     } else if (strncmp(token, "dynamic_cert_mem_cache_size=", 28) == 0) {
         parseBytesOptionValue(&s->dynamicCertMemCacheSize, B_BYTES_STR, token + 28);
 #endif
+    } else if (strncmp(token, "tls-", 4) == 0) {
+        s->secure.parse(token+4);
     } else if (strcmp(token, "ftp-track-dirs") == 0) {
         s->ftp_track_dirs = true;
     } else {
         debugs(3, DBG_CRITICAL, "FATAL: Unknown " << cfg_directive << " option '" << token << "'.");
         self_destruct();
     }
 }
 
 void
 add_http_port(char *portspec)
 {
     AnyP::PortCfgPointer s = new AnyP::PortCfg();
     s->transport = parsePortProtocol(SBuf("HTTP"));
     parsePortSpecification(s, portspec);
     // we may need to merge better if the above returns a list with clones
     assert(s->next == NULL);
     s->next = HttpPortList;
     HttpPortList = s;
 }
 
@@ -3783,71 +3779,51 @@
         else
             pmtu = "transparent";
 
         storeAppendPrintf(e, " disable-pmtu-discovery=%s", pmtu);
     }
 
     if (s->s.isAnyAddr() && !s->s.isIPv6())
         storeAppendPrintf(e, " ipv4");
 
     if (s->tcp_keepalive.enabled) {
         if (s->tcp_keepalive.idle || s->tcp_keepalive.interval || s->tcp_keepalive.timeout) {
             storeAppendPrintf(e, " tcpkeepalive=%d,%d,%d", s->tcp_keepalive.idle, s->tcp_keepalive.interval, s->tcp_keepalive.timeout);
         } else {
             storeAppendPrintf(e, " tcpkeepalive");
         }
     }
 
 #if USE_OPENSSL
     if (s->flags.tunnelSslBumping)
         storeAppendPrintf(e, " ssl-bump");
+#endif
 
-    if (s->cert)
-        storeAppendPrintf(e, " cert=%s", s->cert);
-
-    if (s->key)
-        storeAppendPrintf(e, " key=%s", s->key);
-
-    if (s->options)
-        storeAppendPrintf(e, " options=%s", s->options);
-
-    if (s->cipher)
-        storeAppendPrintf(e, " cipher=%s", s->cipher);
-
-    if (s->cafile)
-        storeAppendPrintf(e, " cafile=%s", s->cafile);
-
-    if (s->capath)
-        storeAppendPrintf(e, " capath=%s", s->capath);
-
-    if (s->crlfile)
-        storeAppendPrintf(e, " crlfile=%s", s->crlfile);
+    s->secure.dumpCfg(e, "tls-");
 
+#if USE_OPENSSL
     if (s->dhfile)
         storeAppendPrintf(e, " dhparams=%s", s->dhfile);
 
     if (s->tls_dh)
         storeAppendPrintf(e, " tls-dh=%s", s->tls_dh);
 
-    if (s->sslflags)
-        storeAppendPrintf(e, " sslflags=%s", s->sslflags);
-
     if (s->sslContextSessionId)
         storeAppendPrintf(e, " sslcontext=%s", s->sslContextSessionId);
 
     if (s->generateHostCertificates)
         storeAppendPrintf(e, " generate-host-certificates");
 
     if (s->dynamicCertMemCacheSize != std::numeric_limits<size_t>::max())
         storeAppendPrintf(e, "dynamic_cert_mem_cache_size=%lu%s\n", (unsigned long)s->dynamicCertMemCacheSize, B_BYTES_STR);
 #endif
 }
 
 static void
 dump_PortCfg(StoreEntry * e, const char *n, const AnyP::PortCfgPointer &s)
 {
     for (AnyP::PortCfgPointer p = s; p != NULL; p = p->next) {
         dump_generic_port(e, n, p);
         storeAppendPrintf(e, "\n");
     }
 }
 

=== modified file 'src/cf.data.pre'
--- src/cf.data.pre	2015-06-19 07:13:57 +0000
+++ src/cf.data.pre	2015-06-29 04:55:53 +0000
@@ -2574,41 +2574,41 @@
 	
 	This option (on by default) prevents alternative DNS entries being
 	located to send intercepted traffic DIRECT to an origin server.
 	The clients original destination IP and port will be used instead.
 	
 	Regardless of this option setting, when dealing with intercepted
 	traffic Squid will verify the Host: header and any traffic which
 	fails Host verification will be treated as if this option were ON.
 	
 	see host_verify_strict for details on the verification process.
 DOC_END
 
 COMMENT_START
  TLS OPTIONS
  -----------------------------------------------------------------------------
 COMMENT_END
 
 NAME: tls_outgoing_options
 IFDEF: USE_GNUTLS||USE_OPENSSL
 TYPE: securePeerOptions
-DEFAULT: disable
+DEFAULT: min-version=1.0 options=NO_SSLv3
 LOC: Security::ProxyOutgoingConfig
 DOC_START
 	disable		Do not support https:// URLs.
 	
 	cert=/path/to/client/certificate
 			A client TLS certificate to use when connecting.
 	
 	key=/path/to/client/private_key
 			The private TLS key corresponding to the cert= above.
 			If key= is not specified cert= is assumed to reference
 			a PEM file containing both the certificate and the key.
 	
 	cipher=...	The list of valid TLS ciphers to use.
 
 	min-version=1.N
 			The minimum TLS protocol version to permit. To control
 			SSLv3 use the options= parameter.
 			Supported Values: 1.0 (default), 1.1, 1.2
 
 	options=... 	Specify various TLS/SSL implementation options:

=== modified file 'src/neighbors.cc'
--- src/neighbors.cc	2015-06-09 06:14:43 +0000
+++ src/neighbors.cc	2015-06-30 06:29:58 +0000
@@ -1539,40 +1539,41 @@
         storeAppendPrintf(sentry, " no-tproxy");
 
     if (p->max_conn > 0)
         storeAppendPrintf(sentry, " max-conn=%d", p->max_conn);
     if (p->standby.limit > 0)
         storeAppendPrintf(sentry, " standby=%d", p->standby.limit);
 
     if (p->options.originserver)
         storeAppendPrintf(sentry, " originserver");
 
     if (p->domain)
         storeAppendPrintf(sentry, " forceddomain=%s", p->domain);
 
     if (p->connection_auth == 0)
         storeAppendPrintf(sentry, " connection-auth=off");
     else if (p->connection_auth == 1)
         storeAppendPrintf(sentry, " connection-auth=on");
     else if (p->connection_auth == 2)
         storeAppendPrintf(sentry, " connection-auth=auto");
 
+    p->secure.dumpCfg(sentry,"tls-");
     storeAppendPrintf(sentry, "\n");
 }
 
 static void
 dump_peers(StoreEntry * sentry, CachePeer * peers)
 {
     char ntoabuf[MAX_IPSTRLEN];
     icp_opcode op;
     int i;
 
     if (peers == NULL)
         storeAppendPrintf(sentry, "There are no neighbors installed.\n");
 
     for (CachePeer *e = peers; e; e = e->next) {
         assert(e->host != NULL);
         storeAppendPrintf(sentry, "\n%-11.11s: %s\n",
                           neighborTypeStr(e),
                           e->name);
         storeAppendPrintf(sentry, "Host       : %s/%d/%d\n",
                           e->host,

=== modified file 'src/security/Context.h'
--- src/security/Context.h	2015-02-26 12:12:11 +0000
+++ src/security/Context.h	2015-03-21 10:41:16 +0000
@@ -1,30 +1,40 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_SRC_SECURITY_CONTEXT_H
 #define SQUID_SRC_SECURITY_CONTEXT_H
 
 #if USE_OPENSSL
-#include "ssl/gadgets.h"
+#if HAVE_OPENSSL_SSL_H
+#include <openssl/ssl.h>
+#endif
+#endif
+
+#if USE_GNUTLS
+#if HAVE_GNUTLS_GNUTLS_H
+#include <gnutls/gnutls.h>
+#endif
 #endif
 
 namespace Security {
 
 #if USE_OPENSSL
-// XXX: make this a SSL_CTX_Pointer
 typedef SSL_CTX* ContextPointer;
 
+#elif USE_GNUTLS
+typedef gnutls_certificate_credentials_t* ContextPointer;
+
 #else
 // use void* so we can check against NULL
 typedef void* ContextPointer;
 #endif
 
 } // namespace Security
 
 #endif /* SQUID_SRC_SECURITY_CONTEXT_H */
 

=== modified file 'src/security/PeerOptions.cc'
--- src/security/PeerOptions.cc	2015-05-22 09:42:55 +0000
+++ src/security/PeerOptions.cc	2015-06-30 12:09:14 +0000
@@ -1,130 +1,445 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #include "squid.h"
+#include "base/Packable.h"
 #include "Debug.h"
+#include "fatal.h"
 #include "globals.h"
 #include "parser/Tokenizer.h"
 #include "Parsing.h"
+#include "parser/Tokenizer.h"
 #include "security/PeerOptions.h"
 
 #if USE_OPENSSL
 #include "ssl/support.h"
 #endif
 
 Security::PeerOptions Security::ProxyOutgoingConfig;
 
+Security::PeerOptions::PeerOptions(const Security::PeerOptions &p) :
+    certFile(p.certFile),
+    privateKeyFile(p.privateKeyFile),
+    sslOptions(p.sslOptions),
+    caFile(p.caFile),
+    caDir(p.caDir),
+    crlFile(p.crlFile),
+    sslCipher(p.sslCipher),
+    sslFlags(p.sslFlags),
+    sslDomain(p.sslDomain),
+    parsedOptions(p.parsedOptions),
+    parsedFlags(p.parsedFlags),
+    sslVersion(p.sslVersion),
+    encryptTransport(p.encryptTransport)
+{
+}
+
 void
 Security::PeerOptions::parse(const char *token)
 {
-    if (strncmp(token, "cert=", 5) == 0) {
+    if (strncmp(token, "disable", 7) == 0) {
+        clear();
+    } else if (strncmp(token, "cert=", 5) == 0) {
         certFile = SBuf(token + 5);
         if (privateKeyFile.isEmpty())
             privateKeyFile = certFile;
     } else if (strncmp(token, "key=", 4) == 0) {
         privateKeyFile = SBuf(token + 4);
         if (certFile.isEmpty()) {
-            debugs(0, DBG_PARSE_NOTE(1), "WARNING: cert= option needs to be set before key= is used.");
+            debugs(3, DBG_PARSE_NOTE(1), "WARNING: cert= option needs to be set before key= is used.");
             certFile = privateKeyFile;
         }
     } else if (strncmp(token, "version=", 8) == 0) {
         debugs(0, DBG_PARSE_NOTE(1), "UPGRADE WARNING: SSL version= is deprecated. Use options= to limit protocols instead.");
         sslVersion = xatoi(token + 8);
     } else if (strncmp(token, "min-version=", 12) == 0) {
         tlsMinVersion = SBuf(token + 12);
     } else if (strncmp(token, "options=", 8) == 0) {
         sslOptions = SBuf(token + 8);
-#if USE_OPENSSL
-        // Pre-parse SSL client options to be applied when the client SSL objects created.
-        // Options must not used in the case of peek or stare bump mode.
-        // XXX: performance regression. c_str() can reallocate
-        parsedOptions = Ssl::parse_options(sslOptions.c_str());
-#endif
+        parsedOptions = parseOptions();
     } else if (strncmp(token, "cipher=", 7) == 0) {
         sslCipher = SBuf(token + 7);
     } else if (strncmp(token, "cafile=", 7) == 0) {
         caFile = SBuf(token + 7);
     } else if (strncmp(token, "capath=", 7) == 0) {
         caDir = SBuf(token + 7);
     } else if (strncmp(token, "crlfile=", 8) == 0) {
         crlFile = SBuf(token + 8);
     } else if (strncmp(token, "flags=", 6) == 0) {
+        if (parsedFlags != 0) {
+            debugs(3, DBG_PARSE_NOTE(1), "WARNING: Overwriting flags=" << sslFlags << " with " << SBuf(token + 6));
+        }
         sslFlags = SBuf(token + 6);
+        parsedFlags = parseFlags();
     } else if (strncmp(token, "domain=", 7) == 0) {
         sslDomain = SBuf(token + 7);
+    } else {
+        debugs(3, DBG_CRITICAL, "ERROR: Unknown TLS option '" << token << "'");
     }
 }
 
-// XXX: make a GnuTLS variant
-Security::ContextPointer
-Security::PeerOptions::createContext(bool setOptions)
+void
+Security::PeerOptions::dumpCfg(Packable *p, const char *pfx) const
 {
-    Security::ContextPointer t = NULL;
+    if (!encryptTransport) {
+        p->appendf(" %sdisable", pfx);
+        return; // no other settings are relevant
+    }
 
+    if (!certFile.isEmpty())
+        p->appendf(" %scert=" SQUIDSBUFPH, pfx, SQUIDSBUFPRINT(certFile));
+
+    if (!privateKeyFile.isEmpty() && privateKeyFile != certFile)
+        p->appendf(" %skey=" SQUIDSBUFPH, pfx, SQUIDSBUFPRINT(privateKeyFile));
+
+    if (!sslOptions.isEmpty())
+        p->appendf(" %soptions=" SQUIDSBUFPH, pfx, SQUIDSBUFPRINT(sslOptions));
+
+    if (!sslCipher.isEmpty())
+        p->appendf(" %scipher=" SQUIDSBUFPH, pfx, SQUIDSBUFPRINT(sslCipher));
+
+    if (!caFile.isEmpty())
+        p->appendf(" %scafile=" SQUIDSBUFPH, pfx, SQUIDSBUFPRINT(caFile));
+
+    if (!caDir.isEmpty())
+        p->appendf(" %scapath=" SQUIDSBUFPH, pfx, SQUIDSBUFPRINT(caDir));
+
+    if (!crlFile.isEmpty())
+        p->appendf(" %scrlfile=" SQUIDSBUFPH, pfx, SQUIDSBUFPRINT(crlFile));
+
+    if (!sslFlags.isEmpty())
+        p->appendf(" %sflags=" SQUIDSBUFPH, pfx, SQUIDSBUFPRINT(sslFlags));
+}
+
+void
+Security::PeerOptions::updateTlsVersionLimits()
+{
     if (!tlsMinVersion.isEmpty()) {
         ::Parser::Tokenizer tok(tlsMinVersion);
         int64_t v = 0;
         if (tok.skip('1') && tok.skip('.') && tok.int64(v, 10, false, 1) && v <= 2) {
             // only account for TLS here - SSL versions are handled by options= parameter
+            // avoid affectign options= parameter in cachemgr config report
+#if SSL_OP_NO_TLSv1
             if (v > 0)
-                sslOptions.append(",NO_TLSv1",9);
+                parsedOptions |= SSL_OP_NO_TLSv1;
+#endif
+#if SSL_OP_NO_TLSv1_1
             if (v > 1)
-                sslOptions.append(",NO_TLSv1_1",11);
+                parsedOptions |= SSL_OP_NO_TLSv1_1;
+#endif
+#if SSL_OP_NO_TLSv1_2
             if (v > 2)
-                sslOptions.append(",NO_TLSv1_2",11);
+                parsedOptions |= SSL_OP_NO_TLSv1_2;
+#endif
 
         } else {
             debugs(0, DBG_PARSE_NOTE(1), "WARNING: Unknown TLS minimum version: " << tlsMinVersion);
         }
 
     } else if (sslVersion > 2) {
         // backward compatibility hack for sslversion= configuration
         // only use if tls-min-version=N.N is not present
-
+        // values 0-2 for auto and SSLv2 are not supported any longer.
+        // Do it this way so we DO cause changes to options= in cachemgr config report
         const char *add = NULL;
         switch (sslVersion) {
         case 3:
             add = "NO_TLSv1,NO_TLSv1_1,NO_TLSv1_2";
             break;
         case 4:
             add = "NO_SSLv3,NO_TLSv1_1,NO_TLSv1_2";
             break;
         case 5:
             add = "NO_SSLv3,NO_TLSv1,NO_TLSv1_2";
             break;
         case 6:
             add = "NO_SSLv3,NO_TLSv1,NO_TLSv1_1";
             break;
         default: // nothing
             break;
         }
         if (add) {
             if (!sslOptions.isEmpty())
                 sslOptions.append(",",1);
             sslOptions.append(add, strlen(add));
         }
         sslVersion = 0; // prevent sslOptions being repeatedly appended
     }
+}
+
+// XXX: make a GnuTLS variant
+Security::ContextPointer
+Security::PeerOptions::createClientContext(bool setOptions)
+{
+    Security::ContextPointer t = NULL;
 
+    updateTlsVersionLimits();
 #if USE_OPENSSL
     // XXX: temporary performance regression. c_str() data copies and prevents this being a const method
     t = sslCreateClientContext(certFile.c_str(), privateKeyFile.c_str(), sslCipher.c_str(),
-                               (setOptions ? sslOptions.c_str() : NULL), sslFlags.c_str(),
+                               (setOptions ? parsedOptions : 0), parsedFlags,
                                caFile.c_str(), caDir.c_str(), crlFile.c_str());
 #endif
 
     return t;
 }
 
+/// set of options we can parse and what they map to
+static struct ssl_option {
+    const char *name;
+    long value;
+
+} ssl_options[] = {
+
+#if SSL_OP_NETSCAPE_REUSE_CIPHER_CHANGE_BUG
+    {
+        "NETSCAPE_REUSE_CIPHER_CHANGE_BUG", SSL_OP_NETSCAPE_REUSE_CIPHER_CHANGE_BUG
+    },
+#endif
+#if SSL_OP_SSLREF2_REUSE_CERT_TYPE_BUG
+    {
+        "SSLREF2_REUSE_CERT_TYPE_BUG", SSL_OP_SSLREF2_REUSE_CERT_TYPE_BUG
+    },
+#endif
+#if SSL_OP_MICROSOFT_BIG_SSLV3_BUFFER
+    {
+        "MICROSOFT_BIG_SSLV3_BUFFER", SSL_OP_MICROSOFT_BIG_SSLV3_BUFFER
+    },
+#endif
+#if SSL_OP_SSLEAY_080_CLIENT_DH_BUG
+    {
+        "SSLEAY_080_CLIENT_DH_BUG", SSL_OP_SSLEAY_080_CLIENT_DH_BUG
+    },
+#endif
+#if SSL_OP_TLS_D5_BUG
+    {
+        "TLS_D5_BUG", SSL_OP_TLS_D5_BUG
+    },
+#endif
+#if SSL_OP_TLS_BLOCK_PADDING_BUG
+    {
+        "TLS_BLOCK_PADDING_BUG", SSL_OP_TLS_BLOCK_PADDING_BUG
+    },
+#endif
+#if SSL_OP_TLS_ROLLBACK_BUG
+    {
+        "TLS_ROLLBACK_BUG", SSL_OP_TLS_ROLLBACK_BUG
+    },
+#endif
+#if SSL_OP_ALL
+    {
+        "ALL", (long)SSL_OP_ALL
+    },
+#endif
+#if SSL_OP_SINGLE_DH_USE
+    {
+        "SINGLE_DH_USE", SSL_OP_SINGLE_DH_USE
+    },
+#endif
+#if SSL_OP_EPHEMERAL_RSA
+    {
+        "EPHEMERAL_RSA", SSL_OP_EPHEMERAL_RSA
+    },
+#endif
+#if SSL_OP_PKCS1_CHECK_1
+    {
+        "PKCS1_CHECK_1", SSL_OP_PKCS1_CHECK_1
+    },
+#endif
+#if SSL_OP_PKCS1_CHECK_2
+    {
+        "PKCS1_CHECK_2", SSL_OP_PKCS1_CHECK_2
+    },
+#endif
+#if SSL_OP_NETSCAPE_CA_DN_BUG
+    {
+        "NETSCAPE_CA_DN_BUG", SSL_OP_NETSCAPE_CA_DN_BUG
+    },
+#endif
+#if SSL_OP_NON_EXPORT_FIRST
+    {
+        "NON_EXPORT_FIRST", SSL_OP_NON_EXPORT_FIRST
+    },
+#endif
+#if SSL_OP_CIPHER_SERVER_PREFERENCE
+    {
+        "CIPHER_SERVER_PREFERENCE", SSL_OP_CIPHER_SERVER_PREFERENCE
+    },
+#endif
+#if SSL_OP_NETSCAPE_DEMO_CIPHER_CHANGE_BUG
+    {
+        "NETSCAPE_DEMO_CIPHER_CHANGE_BUG", SSL_OP_NETSCAPE_DEMO_CIPHER_CHANGE_BUG
+    },
+#endif
+#if SSL_OP_NO_SSLv3
+    {
+        "NO_SSLv3", SSL_OP_NO_SSLv3
+    },
+#endif
+#if SSL_OP_NO_TLSv1
+    {
+        "NO_TLSv1", SSL_OP_NO_TLSv1
+    },
+#endif
+#if SSL_OP_NO_TLSv1_1
+    {
+        "NO_TLSv1_1", SSL_OP_NO_TLSv1_1
+    },
+#endif
+#if SSL_OP_NO_TLSv1_2
+    {
+        "NO_TLSv1_2", SSL_OP_NO_TLSv1_2
+    },
+#endif
+#if SSL_OP_NO_COMPRESSION
+    {
+        "No_Compression", SSL_OP_NO_COMPRESSION
+    },
+#endif
+#if SSL_OP_NO_TICKET
+    {
+        "NO_TICKET", SSL_OP_NO_TICKET
+    },
+#endif
+#if SSL_OP_SINGLE_ECDH_USE
+    {
+        "SINGLE_ECDH_USE", SSL_OP_SINGLE_ECDH_USE
+    },
+#endif
+    {
+        "", 0
+    },
+    {
+        NULL, 0
+    }
+};
+
+/**
+ * Pre-parse TLS options= parameter to be applied when the TLS objects created.
+ * Options must not used in the case of peek or stare bump mode.
+ */
+long
+Security::PeerOptions::parseOptions()
+{
+    long op = 0;
+    ::Parser::Tokenizer tok(sslOptions);
+
+    do {
+        enum {
+            MODE_ADD, MODE_REMOVE
+        } mode;
+
+        if (tok.skip('-') || tok.skip('!'))
+            mode = MODE_REMOVE;
+        else {
+            (void)tok.skip('+'); // default action is add. ignore if missing operator
+            mode = MODE_ADD;
+        }
+
+        static const CharacterSet optChars = CharacterSet("TLS-option", "_") + CharacterSet::ALPHA + CharacterSet::DIGIT;
+        int64_t hex = 0;
+        SBuf option;
+        long value = 0;
+
+        if (tok.int64(hex, 16, false)) {
+            /* Special case.. hex specification */
+            value = hex;
+        }
+
+        else if (tok.prefix(option, optChars)) {
+            // find the named option in our supported set
+            for (struct ssl_option *opttmp = ssl_options; opttmp->name; ++opttmp) {
+                if (option.cmp(opttmp->name) == 0) {
+                    value = opttmp->value;
+                    break;
+                }
+            }
+        }
+
+        if (!value) {
+            fatalf("Unknown TLS option '" SQUIDSBUFPH "'", SQUIDSBUFPRINT(option));
+        }
+
+        switch (mode) {
+
+        case MODE_ADD:
+            op |= value;
+            break;
+
+        case MODE_REMOVE:
+            op &= ~value;
+            break;
+        }
+
+        static const CharacterSet delims("TLS-option-delim",":,");
+        if (!tok.skipAll(delims) && !tok.atEnd()) {
+            fatalf("Unknown TLS option '" SQUIDSBUFPH "'", SQUIDSBUFPRINT(tok.remaining()));
+        }
+
+    } while (!tok.atEnd());
+
+#if SSL_OP_NO_SSLv2
+    // compliance with RFC 6176: Prohibiting Secure Sockets Layer (SSL) Version 2.0
+    op = op | SSL_OP_NO_SSLv2;
+#endif
+    return op;
+}
+
+/**
+ * Parses the TLS flags squid.conf parameter
+ */
+long
+Security::PeerOptions::parseFlags()
+{
+    if (sslFlags.isEmpty())
+        return 0;
+
+    static struct {
+        SBuf label;
+        long mask;
+    } flagTokens[] = {
+        { SBuf("NO_DEFAULT_CA"), SSL_FLAG_NO_DEFAULT_CA },
+        { SBuf("DELAYED_AUTH"), SSL_FLAG_DELAYED_AUTH },
+        { SBuf("DONT_VERIFY_PEER"), SSL_FLAG_DONT_VERIFY_PEER },
+        { SBuf("DONT_VERIFY_DOMAIN"), SSL_FLAG_DONT_VERIFY_DOMAIN },
+        { SBuf("NO_SESSION_REUSE"), SSL_FLAG_NO_SESSION_REUSE },
+#if X509_V_FLAG_CRL_CHECK
+        { SBuf("VERIFY_CRL"), SSL_FLAG_VERIFY_CRL },
+        { SBuf("VERIFY_CRL_ALL"), SSL_FLAG_VERIFY_CRL_ALL },
+#endif
+        { SBuf(), 0 }
+    };
+
+    ::Parser::Tokenizer tok(sslFlags);
+    static const CharacterSet delims("Flag-delimiter", ":,");
+
+    long fl = 0;
+    do {
+        long found = 0;
+        for (size_t i = 0; flagTokens[i].mask; ++i) {
+            if (tok.skip(flagTokens[i].label) == 0) {
+                found = flagTokens[i].mask;
+                break;
+            }
+        }
+        if (!found)
+            fatalf("Unknown TLS flag '" SQUIDSBUFPH "'", SQUIDSBUFPRINT(tok.remaining()));
+        fl |= found;
+    } while (tok.skipOne(delims));
+
+    return fl;
+}
+
 void
 parse_securePeerOptions(Security::PeerOptions *opt)
 {
     while(const char *token = ConfigParser::NextToken())
         opt->parse(token);
 }
 

=== modified file 'src/security/PeerOptions.h'
--- src/security/PeerOptions.h	2015-05-22 09:42:55 +0000
+++ src/security/PeerOptions.h	2015-06-30 12:08:12 +0000
@@ -1,68 +1,83 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_SRC_SECURITY_PEEROPTIONS_H
 #define SQUID_SRC_SECURITY_PEEROPTIONS_H
 
 #include "ConfigParser.h"
 #include "SBuf.h"
 #include "security/forward.h"
 
+class Packable;
+
 namespace Security
 {
 
 /// TLS squid.conf settings for a remote server peer
 class PeerOptions
 {
 public:
-    PeerOptions() : parsedOptions(0), sslVersion(0), encryptTransport(false) {}
+    PeerOptions() : parsedOptions(0), parsedFlags(0), sslVersion(0), encryptTransport(false) {}
+    PeerOptions(const PeerOptions &);
 
     /// parse a TLS squid.conf option
     void parse(const char *);
 
     /// reset the configuration details to default
     void clear() {*this = PeerOptions();}
 
-    /// generate a security context from these configured options
-    Security::ContextPointer createContext(bool setOptions);
+    /// generate a security client-context from these configured options
+    Security::ContextPointer createClientContext(bool setOptions);
+
+    /// sync the context options with tls-min-version=N configuration
+    void updateTlsVersionLimits();
+
+    /// output squid.conf syntax with 'pfx' prefix on parameters for the stored settings
+    void dumpCfg(Packable *, const char *pfx) const;
 
+private:
+    long parseOptions();
+    long parseFlags();
+
+public:
     SBuf certFile;       ///< path of file containing PEM format X509 certificate
     SBuf privateKeyFile; ///< path of file containing private key in PEM format
     SBuf sslOptions;     ///< library-specific options string
     SBuf caFile;         ///< path of file containing trusted Certificate Authority
     SBuf caDir;          ///< path of directory containing a set of trusted Certificate Authorities
     SBuf crlFile;        ///< path of file containing Certificate Revoke List
 
     SBuf sslCipher;
-    SBuf sslFlags;
+    SBuf sslFlags;       ///< flags defining what TLS operations Squid performs
     SBuf sslDomain;
 
     SBuf tlsMinVersion;  ///< version label for minimum TLS version to permit
 
     long parsedOptions; ///< parsed value of sslOptions
+    long parsedFlags;   ///< parsed value of sslFlags
 
 private:
     int sslVersion;
 
 public:
     /// whether transport encryption (TLS/SSL) is to be used on connections to the peer
     bool encryptTransport;
 };
 
 /// configuration options for DIRECT server access
 extern PeerOptions ProxyOutgoingConfig;
 
 } // namespace Security
 
 // parse the tls_outgoing_options directive
 void parse_securePeerOptions(Security::PeerOptions *);
 #define free_securePeerOptions(x) Security::ProxyOutgoingConfig.clear()
-#define dump_securePeerOptions(e,n,x) // not supported yet
+#define dump_securePeerOptions(e,n,x) do { (e)->appendf(n); (x).dumpCfg((e),""); (e)->append("\n",1); } while(false)
 
 #endif /* SQUID_SRC_SECURITY_PEEROPTIONS_H */
 

=== modified file 'src/security/forward.h'
--- src/security/forward.h	2015-03-20 15:10:07 +0000
+++ src/security/forward.h	2015-03-25 09:39:15 +0000
@@ -1,24 +1,33 @@
 /*
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #ifndef SQUID_SRC_SECURITY_FORWARD_H
 #define SQUID_SRC_SECURITY_FORWARD_H
 
 #include "security/Context.h"
 
+/* flags a SSL connection can be configured with */
+#define SSL_FLAG_NO_DEFAULT_CA      (1<<0)
+#define SSL_FLAG_DELAYED_AUTH       (1<<1)
+#define SSL_FLAG_DONT_VERIFY_PEER   (1<<2)
+#define SSL_FLAG_DONT_VERIFY_DOMAIN (1<<3)
+#define SSL_FLAG_NO_SESSION_REUSE   (1<<4)
+#define SSL_FLAG_VERIFY_CRL         (1<<5)
+#define SSL_FLAG_VERIFY_CRL_ALL     (1<<6)
+
 /// Network/connection security abstraction layer
 namespace Security
 {
 
 class EncryptorAnswer;
 class PeerOptions;
 
 } // namespace Security
 
 #endif /* SQUID_SRC_SECURITY_FORWARD_H */
 

=== modified file 'src/ssl/support.cc'
--- src/ssl/support.cc	2015-06-29 12:46:17 +0000
+++ src/ssl/support.cc	2015-06-30 10:45:09 +0000
@@ -337,315 +337,40 @@
         // Find the broken certificate. It may be intermediate.
         X509 *broken_cert = peer_cert; // reasonable default if search fails
         // Our SQUID_X509_V_ERR_DOMAIN_MISMATCH implies peer_cert is at fault.
         if (error_no != SQUID_X509_V_ERR_DOMAIN_MISMATCH) {
             if (X509 *last_used_cert = X509_STORE_CTX_get_current_cert(ctx))
                 broken_cert = last_used_cert;
         }
 
         Ssl::ErrorDetail *errDetail =
             new Ssl::ErrorDetail(error_no, peer_cert, broken_cert);
 
         if (!SSL_set_ex_data(ssl, ssl_ex_index_ssl_error_detail,  errDetail)) {
             debugs(83, 2, "Failed to set Ssl::ErrorDetail in ssl_verify_cb: Certificate " << buffer);
             delete errDetail;
         }
     }
 
     return ok;
 }
 
-/// \ingroup ServerProtocolSSLInternal
-static struct ssl_option {
-    const char *name;
-    long value;
-}
-
-ssl_options[] = {
-
-#if SSL_OP_NETSCAPE_REUSE_CIPHER_CHANGE_BUG
-    {
-        "NETSCAPE_REUSE_CIPHER_CHANGE_BUG", SSL_OP_NETSCAPE_REUSE_CIPHER_CHANGE_BUG
-    },
-#endif
-#if SSL_OP_SSLREF2_REUSE_CERT_TYPE_BUG
-    {
-        "SSLREF2_REUSE_CERT_TYPE_BUG", SSL_OP_SSLREF2_REUSE_CERT_TYPE_BUG
-    },
-#endif
-#if SSL_OP_MICROSOFT_BIG_SSLV3_BUFFER
-    {
-        "MICROSOFT_BIG_SSLV3_BUFFER", SSL_OP_MICROSOFT_BIG_SSLV3_BUFFER
-    },
-#endif
-#if SSL_OP_SSLEAY_080_CLIENT_DH_BUG
-    {
-        "SSLEAY_080_CLIENT_DH_BUG", SSL_OP_SSLEAY_080_CLIENT_DH_BUG
-    },
-#endif
-#if SSL_OP_TLS_D5_BUG
-    {
-        "TLS_D5_BUG", SSL_OP_TLS_D5_BUG
-    },
-#endif
-#if SSL_OP_TLS_BLOCK_PADDING_BUG
-    {
-        "TLS_BLOCK_PADDING_BUG", SSL_OP_TLS_BLOCK_PADDING_BUG
-    },
-#endif
-#if SSL_OP_TLS_ROLLBACK_BUG
-    {
-        "TLS_ROLLBACK_BUG", SSL_OP_TLS_ROLLBACK_BUG
-    },
-#endif
-#if SSL_OP_ALL
-    {
-        "ALL", (long)SSL_OP_ALL
-    },
-#endif
-#if SSL_OP_SINGLE_DH_USE
-    {
-        "SINGLE_DH_USE", SSL_OP_SINGLE_DH_USE
-    },
-#endif
-#if SSL_OP_EPHEMERAL_RSA
-    {
-        "EPHEMERAL_RSA", SSL_OP_EPHEMERAL_RSA
-    },
-#endif
-#if SSL_OP_PKCS1_CHECK_1
-    {
-        "PKCS1_CHECK_1", SSL_OP_PKCS1_CHECK_1
-    },
-#endif
-#if SSL_OP_PKCS1_CHECK_2
-    {
-        "PKCS1_CHECK_2", SSL_OP_PKCS1_CHECK_2
-    },
-#endif
-#if SSL_OP_NETSCAPE_CA_DN_BUG
-    {
-        "NETSCAPE_CA_DN_BUG", SSL_OP_NETSCAPE_CA_DN_BUG
-    },
-#endif
-#if SSL_OP_NON_EXPORT_FIRST
-    {
-        "NON_EXPORT_FIRST", SSL_OP_NON_EXPORT_FIRST
-    },
-#endif
-#if SSL_OP_CIPHER_SERVER_PREFERENCE
-    {
-        "CIPHER_SERVER_PREFERENCE", SSL_OP_CIPHER_SERVER_PREFERENCE
-    },
-#endif
-#if SSL_OP_NETSCAPE_DEMO_CIPHER_CHANGE_BUG
-    {
-        "NETSCAPE_DEMO_CIPHER_CHANGE_BUG", SSL_OP_NETSCAPE_DEMO_CIPHER_CHANGE_BUG
-    },
-#endif
-#if SSL_OP_NO_SSLv3
-    {
-        "NO_SSLv3", SSL_OP_NO_SSLv3
-    },
-#endif
-#if SSL_OP_NO_TLSv1
-    {
-        "NO_TLSv1", SSL_OP_NO_TLSv1
-    },
-#endif
-#if SSL_OP_NO_TLSv1_1
-    {
-        "NO_TLSv1_1", SSL_OP_NO_TLSv1_1
-    },
-#endif
-#if SSL_OP_NO_TLSv1_2
-    {
-        "NO_TLSv1_2", SSL_OP_NO_TLSv1_2
-    },
-#endif
-#if SSL_OP_NO_COMPRESSION
-    {
-        "No_Compression", SSL_OP_NO_COMPRESSION
-    },
-#endif
-#if SSL_OP_NO_TICKET
-    {
-        "NO_TICKET", SSL_OP_NO_TICKET
-    },
-#endif
-#if SSL_OP_SINGLE_ECDH_USE
-    {
-        "SINGLE_ECDH_USE", SSL_OP_SINGLE_ECDH_USE
-    },
-#endif
-    {
-        "", 0
-    },
-    {
-        NULL, 0
-    }
-};
-
-/// \ingroup ServerProtocolSSLInternal
-long
-Ssl::parse_options(const char *options)
-{
-    long op = 0;
-    char *tmp;
-    char *option;
-
-    if (!options)
-        goto no_options;
-
-    tmp = xstrdup(options);
-
-    option = strtok(tmp, ":,");
-
-    while (option) {
-
-        struct ssl_option *opt = NULL, *opttmp;
-        long value = 0;
-        enum {
-            MODE_ADD, MODE_REMOVE
-        } mode;
-
-        switch (*option) {
-
-        case '!':
-
-        case '-':
-            mode = MODE_REMOVE;
-            ++option;
-            break;
-
-        case '+':
-            mode = MODE_ADD;
-            ++option;
-            break;
-
-        default:
-            mode = MODE_ADD;
-            break;
-        }
-
-        for (opttmp = ssl_options; opttmp->name; ++opttmp) {
-            if (strcmp(opttmp->name, option) == 0) {
-                opt = opttmp;
-                break;
-            }
-        }
-
-        if (opt)
-            value = opt->value;
-        else if (strncmp(option, "0x", 2) == 0) {
-            /* Special case.. hex specification */
-            value = strtol(option + 2, NULL, 16);
-        } else {
-            fatalf("Unknown SSL option '%s'", option);
-            value = 0;      /* Keep GCC happy */
-        }
-
-        switch (mode) {
-
-        case MODE_ADD:
-            op |= value;
-            break;
-
-        case MODE_REMOVE:
-            op &= ~value;
-            break;
-        }
-
-        option = strtok(NULL, ":,");
-    }
-
-    safe_free(tmp);
-
-no_options:
-#if SSL_OP_NO_SSLv2
-    // compliance with RFC 6176: Prohibiting Secure Sockets Layer (SSL) Version 2.0
-    op = op | SSL_OP_NO_SSLv2;
-#endif
-    return op;
-}
-
-/// \ingroup ServerProtocolSSLInternal
-#define SSL_FLAG_NO_DEFAULT_CA      (1<<0)
-/// \ingroup ServerProtocolSSLInternal
-#define SSL_FLAG_DELAYED_AUTH       (1<<1)
-/// \ingroup ServerProtocolSSLInternal
-#define SSL_FLAG_DONT_VERIFY_PEER   (1<<2)
-/// \ingroup ServerProtocolSSLInternal
-#define SSL_FLAG_DONT_VERIFY_DOMAIN (1<<3)
-/// \ingroup ServerProtocolSSLInternal
-#define SSL_FLAG_NO_SESSION_REUSE   (1<<4)
-/// \ingroup ServerProtocolSSLInternal
-#define SSL_FLAG_VERIFY_CRL     (1<<5)
-/// \ingroup ServerProtocolSSLInternal
-#define SSL_FLAG_VERIFY_CRL_ALL     (1<<6)
-
-/// \ingroup ServerProtocolSSLInternal
-long
-Ssl::parse_flags(const char *flags)
-{
-    long fl = 0;
-    char *tmp;
-    char *flag;
-
-    if (!flags)
-        return 0;
-
-    tmp = xstrdup(flags);
-
-    flag = strtok(tmp, ":,");
-
-    while (flag) {
-        if (strcmp(flag, "NO_DEFAULT_CA") == 0)
-            fl |= SSL_FLAG_NO_DEFAULT_CA;
-        else if (strcmp(flag, "DELAYED_AUTH") == 0)
-            fl |= SSL_FLAG_DELAYED_AUTH;
-        else if (strcmp(flag, "DONT_VERIFY_PEER") == 0)
-            fl |= SSL_FLAG_DONT_VERIFY_PEER;
-        else if (strcmp(flag, "DONT_VERIFY_DOMAIN") == 0)
-            fl |= SSL_FLAG_DONT_VERIFY_DOMAIN;
-        else if (strcmp(flag, "NO_SESSION_REUSE") == 0)
-            fl |= SSL_FLAG_NO_SESSION_REUSE;
-
-#if X509_V_FLAG_CRL_CHECK
-
-        else if (strcmp(flag, "VERIFY_CRL") == 0)
-            fl |= SSL_FLAG_VERIFY_CRL;
-        else if (strcmp(flag, "VERIFY_CRL_ALL") == 0)
-            fl |= SSL_FLAG_VERIFY_CRL_ALL;
-
-#endif
-
-        else
-            fatalf("Unknown ssl flag '%s'", flag);
-
-        flag = strtok(NULL, ":,");
-    }
-
-    safe_free(tmp);
-    return fl;
-}
-
 // "dup" function for SSL_get_ex_new_index("cert_err_check")
 static int
 ssl_dupAclChecklist(CRYPTO_EX_DATA *, CRYPTO_EX_DATA *, void *,
                     int, long, void *)
 {
     // We do not support duplication of ACLCheckLists.
     // If duplication is needed, we can count copies with cbdata.
     assert(false);
     return 0;
 }
 
 // "free" function for SSL_get_ex_new_index("cert_err_check")
 static void
 ssl_freeAclChecklist(void *, void *ptr, CRYPTO_EX_DATA *,
                      int, long, void *)
 {
     delete static_cast<ACLChecklist *>(ptr); // may be NULL
 }
 
 // "free" function for SSL_get_ex_new_index("ssl_error_detail")
@@ -850,185 +575,174 @@
         return false;
     }
 
     EC_KEY *ecdh = EC_KEY_new_by_curve_name(nid);
     if (ecdh == NULL)
         return false;
 
     const bool ok = SSL_CTX_set_tmp_ecdh(sslContext, ecdh) != 0;
     EC_KEY_free(ecdh);
     return ok;
 #else
     debugs(83, DBG_CRITICAL, "ERROR: EECDH is not available in this build. Please link against OpenSSL>=0.9.8 and ensure OPENSSL_NO_ECDH is not set.");
     return false;
 #endif
 }
 
 static bool
 configureSslContext(SSL_CTX *sslContext, AnyP::PortCfg &port)
 {
     int ssl_error;
-    SSL_CTX_set_options(sslContext, port.sslOptions);
+    SSL_CTX_set_options(sslContext, port.secure.parsedOptions);
 
 #if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
     SSL_CTX_set_info_callback(sslContext, ssl_info_cb);
 #endif
 
     if (port.sslContextSessionId)
         SSL_CTX_set_session_id_context(sslContext, (const unsigned char *)port.sslContextSessionId, strlen(port.sslContextSessionId));
 
-    if (port.sslContextFlags & SSL_FLAG_NO_SESSION_REUSE) {
+    if (port.secure.parsedFlags & SSL_FLAG_NO_SESSION_REUSE) {
         SSL_CTX_set_session_cache_mode(sslContext, SSL_SESS_CACHE_OFF);
     }
 
     if (Config.SSL.unclean_shutdown) {
         debugs(83, 5, "Enabling quiet SSL shutdowns (RFC violation).");
 
         SSL_CTX_set_quiet_shutdown(sslContext, 1);
     }
 
-    if (port.cipher) {
-        debugs(83, 5, "Using chiper suite " << port.cipher << ".");
+    if (!port.secure.sslCipher.isEmpty()) {
+        debugs(83, 5, "Using chiper suite " << port.secure.sslCipher << ".");
 
-        if (!SSL_CTX_set_cipher_list(sslContext, port.cipher)) {
+        if (!SSL_CTX_set_cipher_list(sslContext, port.secure.sslCipher.c_str())) {
             ssl_error = ERR_get_error();
-            debugs(83, DBG_CRITICAL, "ERROR: Failed to set SSL cipher suite '" << port.cipher << "': " << ERR_error_string(ssl_error, NULL));
+            debugs(83, DBG_CRITICAL, "ERROR: Failed to set SSL cipher suite '" << port.secure.sslCipher << "': " << ERR_error_string(ssl_error, NULL));
             return false;
         }
     }
 
     debugs(83, 9, "Setting RSA key generation callback.");
     SSL_CTX_set_tmp_rsa_callback(sslContext, ssl_temp_rsa_cb);
 
     if (port.eecdhCurve) {
         debugs(83, 9, "Setting Ephemeral ECDH curve to " << port.eecdhCurve << ".");
 
         if (!configureSslEECDH(sslContext, port.eecdhCurve)) {
             ssl_error = ERR_get_error();
             debugs(83, DBG_CRITICAL, "ERROR: Unable to configure Ephemeral ECDH: " << ERR_error_string(ssl_error, NULL));
             return false;
         }
     }
 
     debugs(83, 9, "Setting CA certificate locations.");
 
-    const char *cafile = port.cafile ? port.cafile : port.clientca;
-    if ((cafile || port.capath) && !SSL_CTX_load_verify_locations(sslContext, cafile, port.capath)) {
+    const char *cafile = port.secure.caFile.isEmpty() ? port.clientca : port.secure.caFile.c_str();
+    if ((cafile || !port.secure.caDir.isEmpty()) && !SSL_CTX_load_verify_locations(sslContext, cafile, port.secure.caDir.c_str())) {
         ssl_error = ERR_get_error();
         debugs(83, DBG_IMPORTANT, "WARNING: Ignoring error setting CA certificate locations: " << ERR_error_string(ssl_error, NULL));
     }
 
-    if (!(port.sslContextFlags & SSL_FLAG_NO_DEFAULT_CA) &&
+    if (!(port.secure.parsedFlags & SSL_FLAG_NO_DEFAULT_CA) &&
             !SSL_CTX_set_default_verify_paths(sslContext)) {
         ssl_error = ERR_get_error();
         debugs(83, DBG_IMPORTANT, "WARNING: Ignoring error setting default CA certificate location: " << ERR_error_string(ssl_error, NULL));
     }
 
     if (port.clientCA.get()) {
         ERR_clear_error();
         if (STACK_OF(X509_NAME) *clientca = SSL_dup_CA_list(port.clientCA.get())) {
             SSL_CTX_set_client_CA_list(sslContext, clientca);
         } else {
             ssl_error = ERR_get_error();
             debugs(83, DBG_CRITICAL, "ERROR: Failed to dupe the client CA list: " << ERR_error_string(ssl_error, NULL));
             return false;
         }
 
-        if (port.sslContextFlags & SSL_FLAG_DELAYED_AUTH) {
+        if (port.secure.parsedFlags & SSL_FLAG_DELAYED_AUTH) {
             debugs(83, 9, "Not requesting client certificates until acl processing requires one");
             SSL_CTX_set_verify(sslContext, SSL_VERIFY_NONE, NULL);
         } else {
             debugs(83, 9, "Requiring client certificates.");
             SSL_CTX_set_verify(sslContext, SSL_VERIFY_PEER | SSL_VERIFY_FAIL_IF_NO_PEER_CERT, ssl_verify_cb);
         }
 
         if (port.clientVerifyCrls.get()) {
             X509_STORE *st = SSL_CTX_get_cert_store(sslContext);
             for (int i = 0; i < sk_X509_CRL_num(port.clientVerifyCrls.get()); ++i) {
                 X509_CRL *crl = sk_X509_CRL_value(port.clientVerifyCrls.get(), i);
                 if (!X509_STORE_add_crl(st, crl))
                     debugs(83, 2, "WARNING: Failed to add CRL");
             }
         }
 
 #if X509_V_FLAG_CRL_CHECK
-        if (port.sslContextFlags & SSL_FLAG_VERIFY_CRL_ALL)
+        if (port.secure.parsedFlags & SSL_FLAG_VERIFY_CRL_ALL)
             X509_STORE_set_flags(SSL_CTX_get_cert_store(sslContext), X509_V_FLAG_CRL_CHECK|X509_V_FLAG_CRL_CHECK_ALL);
-        else if (port.sslContextFlags & SSL_FLAG_VERIFY_CRL)
+        else if (port.secure.parsedFlags & SSL_FLAG_VERIFY_CRL)
             X509_STORE_set_flags(SSL_CTX_get_cert_store(sslContext), X509_V_FLAG_CRL_CHECK);
 #endif
 
     } else {
         debugs(83, 9, "Not requiring any client certificates");
         SSL_CTX_set_verify(sslContext, SSL_VERIFY_NONE, NULL);
     }
 
     if (port.dhParams.get()) {
         SSL_CTX_set_tmp_dh(sslContext, port.dhParams.get());
     }
 
-    if (port.sslContextFlags & SSL_FLAG_DONT_VERIFY_DOMAIN)
+    if (port.secure.parsedFlags & SSL_FLAG_DONT_VERIFY_DOMAIN)
         SSL_CTX_set_ex_data(sslContext, ssl_ctx_ex_index_dont_verify_domain, (void *) -1);
 
     setSessionCallbacks(sslContext);
 
     return true;
 }
 
 SSL_CTX *
 sslCreateServerContext(AnyP::PortCfg &port)
 {
-    int ssl_error;
-    const char *keyfile, *certfile;
-    certfile = port.cert;
-    keyfile = port.key;
-
     ssl_initialize();
 
-    if (!keyfile)
-        keyfile = certfile;
-
-    if (!certfile)
-        certfile = keyfile;
-
 #if (OPENSSL_VERSION_NUMBER >= 0x10100000L)
     SSL_CTX *sslContext = SSL_CTX_new(TLS_server_method());
 #else
     SSL_CTX *sslContext = SSL_CTX_new(SSLv23_server_method());
 #endif
 
     if (sslContext == NULL) {
-        ssl_error = ERR_get_error();
+        int ssl_error = ERR_get_error();
         debugs(83, DBG_CRITICAL, "ERROR: Failed to allocate SSL context: " << ERR_error_string(ssl_error, NULL));
         return NULL;
     }
 
     if (!SSL_CTX_use_certificate(sslContext, port.signingCert.get())) {
-        ssl_error = ERR_get_error();
-        debugs(83, DBG_CRITICAL, "ERROR: Failed to acquire SSL certificate '" << certfile << "': " << ERR_error_string(ssl_error, NULL));
+        int ssl_error = ERR_get_error();
+        debugs(83, DBG_CRITICAL, "ERROR: Failed to acquire SSL certificate '" << port.secure.certFile << "': " << ERR_error_string(ssl_error, NULL));
         SSL_CTX_free(sslContext);
         return NULL;
     }
 
     if (!SSL_CTX_use_PrivateKey(sslContext, port.signPkey.get())) {
-        ssl_error = ERR_get_error();
-        debugs(83, DBG_CRITICAL, "ERROR: Failed to acquire SSL private key '" << keyfile << "': " << ERR_error_string(ssl_error, NULL));
+        int ssl_error = ERR_get_error();
+        debugs(83, DBG_CRITICAL, "ERROR: Failed to acquire SSL private key '" << port.secure.privateKeyFile << "': " << ERR_error_string(ssl_error, NULL));
         SSL_CTX_free(sslContext);
         return NULL;
     }
 
     Ssl::addChainToSslContext(sslContext, port.certsToChain.get());
 
     /* Alternate code;
         debugs(83, DBG_IMPORTANT, "Using certificate in " << certfile);
 
         if (!SSL_CTX_use_certificate_chain_file(sslContext, certfile)) {
             ssl_error = ERR_get_error();
             debugs(83, DBG_CRITICAL, "ERROR: Failed to acquire SSL certificate '" << certfile << "': " << ERR_error_string(ssl_error, NULL));
             SSL_CTX_free(sslContext);
             return NULL;
         }
 
         debugs(83, DBG_IMPORTANT, "Using private key in " << keyfile);
         ssl_ask_password(sslContext, keyfile);
 
         if (!SSL_CTX_use_PrivateKey_file(sslContext, keyfile, SSL_FILETYPE_PEM)) {
@@ -1041,166 +755,145 @@
         debugs(83, 5, "Comparing private and public SSL keys.");
 
         if (!SSL_CTX_check_private_key(sslContext)) {
             ssl_error = ERR_get_error();
             debugs(83, DBG_CRITICAL, "ERROR: SSL private key '" << certfile << "' does not match public key '" <<
                    keyfile << "': " << ERR_error_string(ssl_error, NULL));
             SSL_CTX_free(sslContext);
             return NULL;
         }
     */
 
     if (!configureSslContext(sslContext, port)) {
         debugs(83, DBG_CRITICAL, "ERROR: Configuring static SSL context");
         SSL_CTX_free(sslContext);
         return NULL;
     }
 
     return sslContext;
 }
 
-int Ssl::OpenSSLtoSquidSSLVersion(int sslVersion)
-{
-    if (sslVersion == SSL2_VERSION)
-        return 2;
-    else if (sslVersion == SSL3_VERSION)
-        return 3;
-    else if (sslVersion == TLS1_VERSION)
-        return 4;
-#if OPENSSL_VERSION_NUMBER >= 0x10001000L
-    else if (sslVersion == TLS1_1_VERSION)
-        return 5;
-    else if (sslVersion == TLS1_2_VERSION)
-        return 6;
-#endif
-    else
-        return 1;
-}
-
 #if defined(TLSEXT_TYPE_next_proto_neg)
 //Dummy next_proto_neg callback
 static int
 ssl_next_proto_cb(SSL *s, unsigned char **out, unsigned char *outlen, const unsigned char *in, unsigned int inlen, void *arg)
 {
     static const unsigned char supported_protos[] = {8, 'h','t','t', 'p', '/', '1', '.', '1'};
     (void)SSL_select_next_proto(out, outlen, in, inlen, supported_protos, sizeof(supported_protos));
     return SSL_TLSEXT_ERR_OK;
 }
 #endif
 
 SSL_CTX *
-sslCreateClientContext(const char *certfile, const char *keyfile, const char *cipher, const char *options, const char *flags, const char *CAfile, const char *CApath, const char *CRLfile)
+sslCreateClientContext(const char *certfile, const char *keyfile, const char *cipher, long options, long fl, const char *CAfile, const char *CApath, const char *CRLfile)
 {
-    int ssl_error;
-    long fl = Ssl::parse_flags(flags);
-
     ssl_initialize();
 
 #if (OPENSSL_VERSION_NUMBER >= 0x10100000L)
     SSL_CTX *sslContext = SSL_CTX_new(TLS_client_method());
 #else
     SSL_CTX *sslContext = SSL_CTX_new(SSLv23_client_method());
 #endif
 
     if (sslContext == NULL) {
-        ssl_error = ERR_get_error();
+        int ssl_error = ERR_get_error();
         fatalf("Failed to allocate SSL context: %s\n",
                ERR_error_string(ssl_error, NULL));
     }
 
-    SSL_CTX_set_options(sslContext, Ssl::parse_options(options));
+    SSL_CTX_set_options(sslContext, options);
 
 #if defined(SSL3_FLAGS_NO_RENEGOTIATE_CIPHERS)
     SSL_CTX_set_info_callback(sslContext, ssl_info_cb);
 #endif
 
     if (*cipher) {
         debugs(83, 5, "Using chiper suite " << cipher << ".");
 
         if (!SSL_CTX_set_cipher_list(sslContext, cipher)) {
-            ssl_error = ERR_get_error();
+            int ssl_error = ERR_get_error();
             fatalf("Failed to set SSL cipher suite '%s': %s\n",
                    cipher, ERR_error_string(ssl_error, NULL));
         }
     }
 
     if (*certfile) {
         debugs(83, DBG_IMPORTANT, "Using certificate in " << certfile);
 
         if (!SSL_CTX_use_certificate_chain_file(sslContext, certfile)) {
-            ssl_error = ERR_get_error();
+            int ssl_error = ERR_get_error();
             fatalf("Failed to acquire SSL certificate '%s': %s\n",
                    certfile, ERR_error_string(ssl_error, NULL));
         }
 
         debugs(83, DBG_IMPORTANT, "Using private key in " << keyfile);
         ssl_ask_password(sslContext, keyfile);
 
         if (!SSL_CTX_use_PrivateKey_file(sslContext, keyfile, SSL_FILETYPE_PEM)) {
-            ssl_error = ERR_get_error();
+            int ssl_error = ERR_get_error();
             fatalf("Failed to acquire SSL private key '%s': %s\n",
                    keyfile, ERR_error_string(ssl_error, NULL));
         }
 
         debugs(83, 5, "Comparing private and public SSL keys.");
 
         if (!SSL_CTX_check_private_key(sslContext)) {
-            ssl_error = ERR_get_error();
+            int ssl_error = ERR_get_error();
             fatalf("SSL private key '%s' does not match public key '%s': %s\n",
                    certfile, keyfile, ERR_error_string(ssl_error, NULL));
         }
     }
 
     debugs(83, 9, "Setting RSA key generation callback.");
     SSL_CTX_set_tmp_rsa_callback(sslContext, ssl_temp_rsa_cb);
 
     if (fl & SSL_FLAG_DONT_VERIFY_PEER) {
         debugs(83, 2, "NOTICE: Peer certificates are not verified for validity!");
         SSL_CTX_set_verify(sslContext, SSL_VERIFY_NONE, NULL);
     } else {
         debugs(83, 9, "Setting certificate verification callback.");
         SSL_CTX_set_verify(sslContext, SSL_VERIFY_PEER | SSL_VERIFY_FAIL_IF_NO_PEER_CERT, ssl_verify_cb);
     }
 
     debugs(83, 9, "Setting CA certificate locations.");
 
     if ((*CAfile || *CApath) && !SSL_CTX_load_verify_locations(sslContext, CAfile, CApath)) {
-        ssl_error = ERR_get_error();
+        int ssl_error = ERR_get_error();
         debugs(83, DBG_IMPORTANT, "WARNING: Ignoring error setting CA certificate locations: " << ERR_error_string(ssl_error, NULL));
     }
 
     if (*CRLfile) {
         ssl_load_crl(sslContext, CRLfile);
         fl |= SSL_FLAG_VERIFY_CRL;
     }
 
 #if X509_V_FLAG_CRL_CHECK
     if (fl & SSL_FLAG_VERIFY_CRL_ALL)
         X509_STORE_set_flags(SSL_CTX_get_cert_store(sslContext), X509_V_FLAG_CRL_CHECK|X509_V_FLAG_CRL_CHECK_ALL);
     else if (fl & SSL_FLAG_VERIFY_CRL)
         X509_STORE_set_flags(SSL_CTX_get_cert_store(sslContext), X509_V_FLAG_CRL_CHECK);
 
 #endif
 
     if (!(fl & SSL_FLAG_NO_DEFAULT_CA) &&
             !SSL_CTX_set_default_verify_paths(sslContext)) {
-        ssl_error = ERR_get_error();
+        int ssl_error = ERR_get_error();
         debugs(83, DBG_IMPORTANT, "WARNING: Ignoring error setting default CA certificate location: " << ERR_error_string(ssl_error, NULL));
     }
 
 #if defined(TLSEXT_TYPE_next_proto_neg)
     SSL_CTX_set_next_proto_select_cb(sslContext, &ssl_next_proto_cb, NULL);
 #endif
     return sslContext;
 }
 
 /// \ingroup ServerProtocolSSLInternal
 int
 ssl_read_method(int fd, char *buf, int len)
 {
     SSL *ssl = fd_table[fd].ssl;
     int i;
 
 #if DONT_DO_THIS
 
     if (!SSL_is_init_finished(ssl)) {
         errno = ENOTCONN;

=== modified file 'src/ssl/support.h'
--- src/ssl/support.h	2015-05-22 09:42:55 +0000
+++ src/ssl/support.h	2015-06-30 10:45:03 +0000
@@ -75,41 +75,41 @@
 {
 public:
     ssl_error_t code; ///< certificate error code
     X509_Pointer cert; ///< certificate with the above error code
     CertError(ssl_error_t anErr, X509 *aCert);
     CertError(CertError const &err);
     CertError & operator = (const CertError &old);
     bool operator == (const CertError &ce) const;
     bool operator != (const CertError &ce) const;
 };
 
 /// Holds a list of certificate SSL errors
 typedef CbDataList<Ssl::CertError> CertErrors;
 
 } //namespace Ssl
 
 /// \ingroup ServerProtocolSSLAPI
 SSL_CTX *sslCreateServerContext(AnyP::PortCfg &port);
 
 /// \ingroup ServerProtocolSSLAPI
-SSL_CTX *sslCreateClientContext(const char *certfile, const char *keyfile, const char *cipher, const char *options, const char *flags, const char *CAfile, const char *CApath, const char *CRLfile);
+SSL_CTX *sslCreateClientContext(const char *certfile, const char *keyfile, const char *cipher, long options, long flags, const char *CAfile, const char *CApath, const char *CRLfile);
 
 /// \ingroup ServerProtocolSSLAPI
 int ssl_read_method(int, char *, int);
 
 /// \ingroup ServerProtocolSSLAPI
 int ssl_write_method(int, const char *, int);
 
 /// \ingroup ServerProtocolSSLAPI
 void ssl_shutdown_method(SSL *ssl);
 
 /// \ingroup ServerProtocolSSLAPI
 const char *sslGetUserEmail(SSL *ssl);
 
 /// \ingroup ServerProtocolSSLAPI
 const char *sslGetUserAttribute(SSL *ssl, const char *attribute_name);
 
 /// \ingroup ServerProtocolSSLAPI
 const char *sslGetCAAttribute(SSL *ssl, const char *attribute_name);
 
 /// \ingroup ServerProtocolSSLAPI
@@ -148,46 +148,40 @@
  */
 extern const char *BumpModeStr[];
 
 /**
  \ingroup ServerProtocolSSLAPI
  * Return the short name of the ssl-bump mode "bm"
  */
 inline const char *bumpMode(int bm)
 {
     return (0 <= bm && bm < Ssl::bumpEnd) ? Ssl::BumpModeStr[bm] : NULL;
 }
 
 /**
  \ingroup ServerProtocolSSLAPI
  * Parses the SSL flags.
  */
 long parse_flags(const char *flags);
 
 /**
  \ingroup ServerProtocolSSLAPI
- * Parses the SSL options.
- */
-long parse_options(const char *options);
-
-/**
- \ingroup ServerProtocolSSLAPI
  * Load a CRLs list stored in a file
  */
 STACK_OF(X509_CRL) *loadCrl(const char *CRLFile, long &flags);
 
 /**
  \ingroup ServerProtocolSSLAPI
  * Load DH params from file
  */
 DH *readDHParams(const char *dhfile);
 
 /**
   \ingroup ServerProtocolSSLAPI
   * Generate a certificate to be used as untrusted signing certificate, based on a trusted CA
 */
 bool generateUntrustedCert(X509_Pointer & untrustedCert, EVP_PKEY_Pointer & untrustedPkey, X509_Pointer const & cert, EVP_PKEY_Pointer const & pkey);
 
 /**
   \ingroup ServerProtocolSSLAPI
   * Decide on the kind of certificate and generate a CA- or self-signed one
 */
@@ -265,42 +259,40 @@
 bool checkX509ServerValidity(X509 *cert, const char *server);
 
 /**
    \ingroup ServerProtocolSSLAPI
    * Convert a given ASN1_TIME to a string form.
    \param tm the time in ASN1_TIME form
    \param buf the buffer to write the output
    \param len write at most len bytes
    \return The number of bytes written
  */
 int asn1timeToString(ASN1_TIME *tm, char *buf, int len);
 
 /**
    \ingroup ServerProtocolSSLAPI
    * Sets the hostname for the Server Name Indication (SNI) TLS extension
    * if supported by the used openssl toolkit.
    \return true if SNI set false otherwise
 */
 bool setClientSNI(SSL *ssl, const char *fqdn);
 
-int OpenSSLtoSquidSSLVersion(int sslVersion);
-
 /**
    \ingroup ServerProtocolSSLAPI
    * Initializes the shared session cache if configured
 */
 void initialize_session_cache();
 
 /**
    \ingroup ServerProtocolSSLAPI
    * Destroy the shared session cache if configured
 */
 void destruct_session_cache();
 } //namespace Ssl
 
 #if _SQUID_WINDOWS_
 
 #if defined(__cplusplus)
 
 /** \cond AUTODOCS-IGNORE */
 namespace Squid
 {

=== modified file 'src/tests/stub_libsecurity.cc'
--- src/tests/stub_libsecurity.cc	2015-03-20 15:10:07 +0000
+++ src/tests/stub_libsecurity.cc	2015-06-30 12:09:41 +0000
@@ -2,23 +2,27 @@
  * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
  *
  * Squid software is distributed under GPLv2+ license and includes
  * contributions from numerous individuals and organizations.
  * Please see the COPYING and CONTRIBUTORS files for details.
  */
 
 #include "squid.h"
 #include "comm/Connection.h"
 
 #define STUB_API "security/libsecurity.la"
 #include "tests/STUB.h"
 
 #include "security/EncryptorAnswer.h"
 Security::EncryptorAnswer::~EncryptorAnswer() {}
 std::ostream &Security::operator <<(std::ostream &os, const Security::EncryptorAnswer &) STUB_RETVAL(os)
 
 #include "security/PeerOptions.h"
 Security::PeerOptions Security::ProxyOutgoingConfig;
 void Security::PeerOptions::parse(char const*) STUB
-Security::ContextPointer Security::PeerOptions::createContext(bool) STUB_RETVAL(NULL)
+Security::ContextPointer Security::PeerOptions::createClientContext(bool) STUB_RETVAL(NULL)
+void Security::PeerOptions::updateTlsVersionLimits() STUB
+void Security::PeerOptions::dumpCfg(Packable*, char const*) const STUB
+long Security::PeerOptions::parseOptions() STUB_RETVAL(0)
+long Security::PeerOptions::parseFlags() STUB_RETVAL(0)
 void parse_securePeerOptions(Security::PeerOptions *) STUB
 

=== modified file 'src/tests/stub_libsslsquid.cc'
--- src/tests/stub_libsslsquid.cc	2015-05-22 09:42:55 +0000
+++ src/tests/stub_libsslsquid.cc	2015-06-13 07:33:01 +0000
@@ -40,55 +40,54 @@
 void Ssl::GlobalContextStorage::reconfigureStart() STUB
 //Ssl::GlobalContextStorage Ssl::TheGlobalContextStorage;
 
 #include "ssl/ErrorDetail.h"
 Ssl::ssl_error_t parseErrorString(const char *name) STUB_RETVAL(0)
 //const char *Ssl::getErrorName(ssl_error_t value) STUB_RETVAL(NULL)
 Ssl::ErrorDetail::ErrorDetail(ssl_error_t err_no, X509 *, X509 *, const char *) STUB
 Ssl::ErrorDetail::ErrorDetail(ErrorDetail const &) STUB
 const String & Ssl::ErrorDetail::toString() const STUB_RETSTATREF(String)
 
 #include "ssl/support.h"
 namespace Ssl
 {
 //CertError::CertError(ssl_error_t anErr, X509 *aCert) STUB
 //CertError::CertError(CertError const &err) STUB
 CertError & CertError::operator = (const CertError &old) STUB_RETVAL(*this)
 bool CertError::operator == (const CertError &ce) const STUB_RETVAL(false)
 bool CertError::operator != (const CertError &ce) const STUB_RETVAL(false)
 } // namespace Ssl
 SSL_CTX *sslCreateServerContext(AnyP::PortCfg &port) STUB_RETVAL(NULL)
-SSL_CTX *sslCreateClientContext(const char *certfile, const char *keyfile, const char *cipher, const char *options, const char *flags, const char *CAfile, const char *CApath, const char *CRLfile) STUB_RETVAL(NULL)
+SSL_CTX *sslCreateClientContext(const char *certfile, const char *keyfile, const char *cipher, long options, const char *flags, const char *CAfile, const char *CApath, const char *CRLfile) STUB_RETVAL(NULL)
 int ssl_read_method(int, char *, int) STUB_RETVAL(0)
 int ssl_write_method(int, const char *, int) STUB_RETVAL(0)
 void ssl_shutdown_method(SSL *ssl) STUB
 const char *sslGetUserEmail(SSL *ssl) STUB_RETVAL(NULL)
 const char *sslGetUserAttribute(SSL *ssl, const char *attribute_name) STUB_RETVAL(NULL)
 const char *sslGetCAAttribute(SSL *ssl, const char *attribute_name) STUB_RETVAL(NULL)
 const char *sslGetUserCertificatePEM(SSL *ssl) STUB_RETVAL(NULL)
 const char *sslGetUserCertificateChainPEM(SSL *ssl) STUB_RETVAL(NULL)
 namespace Ssl
 {
 //GETX509ATTRIBUTE GetX509UserAttribute;
 //GETX509ATTRIBUTE GetX509CAAttribute;
 //GETX509ATTRIBUTE GetX509Fingerprint;
 const char *BumpModeStr[] = {""};
 long parse_flags(const char *flags) STUB_RETVAL(0)
-long parse_options(const char *options) STUB_RETVAL(0)
 STACK_OF(X509_CRL) *loadCrl(const char *CRLFile, long &flags) STUB_RETVAL(NULL)
 DH *readDHParams(const char *dhfile) STUB_RETVAL(NULL)
 bool generateUntrustedCert(X509_Pointer & untrustedCert, EVP_PKEY_Pointer & untrustedPkey, X509_Pointer const & cert, EVP_PKEY_Pointer const & pkey) STUB_RETVAL(false)
 SSL_CTX * generateSslContext(CertificateProperties const &properties, AnyP::PortCfg &port) STUB_RETVAL(NULL)
 bool verifySslCertificate(SSL_CTX * sslContext,  CertificateProperties const &properties) STUB_RETVAL(false)
 SSL_CTX * generateSslContextUsingPkeyAndCertFromMemory(const char * data, AnyP::PortCfg &port) STUB_RETVAL(NULL)
 void addChainToSslContext(SSL_CTX *sslContext, STACK_OF(X509) *certList) STUB
 void readCertChainAndPrivateKeyFromFiles(X509_Pointer & cert, EVP_PKEY_Pointer & pkey, X509_STACK_Pointer & chain, char const * certFilename, char const * keyFilename) STUB
 int matchX509CommonNames(X509 *peer_cert, void *check_data, int (*check_func)(void *check_data,  ASN1_STRING *cn_data)) STUB_RETVAL(0)
 bool checkX509ServerValidity(X509 *cert, const char *server) STUB_RETVAL(false)
 int asn1timeToString(ASN1_TIME *tm, char *buf, int len) STUB_RETVAL(0)
 bool setClientSNI(SSL *ssl, const char *fqdn) STUB_RETVAL(false)
 void initialize_session_cache() STUB
 void destruct_session_cache() STUB
 } //namespace Ssl
 
 #endif
 


From rousskov at measurement-factory.com  Tue Jun 30 22:11:08 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 30 Jun 2015 16:11:08 -0600
Subject: [squid-dev] [PATCH] Crypto-NG: Use Security::PeerOptions for
 listening port TLS settings
In-Reply-To: <5592B561.3000405@treenet.co.nz>
References: <5592B561.3000405@treenet.co.nz>
Message-ID: <559313FC.7080403@measurement-factory.com>

On 06/30/2015 09:27 AM, Amos Jeffries wrote:

> * Change the tls_outgoing_options default value from "disable" which did
> not parse previously (now does). To setting TLS/1.0 minimum version with
> SSLv3 disabled.

>  NAME: tls_outgoing_options
...
> -DEFAULT: disable
> +DEFAULT: min-version=1.0 options=NO_SSLv3


Does this change mean that Squid can no longer talk to SSLv3-only sites
unless the admin manually adjusts tls_outgoing_options to include SSLv3
support?


> * Fix tls-min-version=1.N handling not to alter stored options= config
> string. Now updates the binary representation in parsedOptions directly.

Can you describe this bug from the admin point of view? That is, what
Squid trunk behavior was broken that this patch fixes?


> -        ssl_error = ERR_get_error();
> +        int ssl_error = ERR_get_error();

Minor: You can make all(?) of the redeclared ssl_error variables
constant. Just something I accidentally noticed -- I did not review the
whole patch.


Thank you,

Alex.


