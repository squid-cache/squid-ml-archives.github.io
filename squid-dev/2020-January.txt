From rousskov at measurement-factory.com  Mon Jan  6 15:28:37 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 6 Jan 2020 10:28:37 -0500
Subject: [squid-dev] Efficient FD annotations
In-Reply-To: <a2117aa5-7413-415f-6370-e221ffae9082@measurement-factory.com>
References: <a2117aa5-7413-415f-6370-e221ffae9082@measurement-factory.com>
Message-ID: <488434a9-d602-8a56-d775-f7e31208deb9@measurement-factory.com>

For the record: The ideas below are superseded by the concept of the
code context introduced in commit ccfbe8f, including the
fde::codeContext field. --Alex


On 2/22/19 12:08 PM, Alex Rousskov wrote:
> In https://github.com/squid-cache/squid/pull/270#discussion_r259316609
> 
> 
>> In src/comm.cc:
>>
>>> @@ -424,7 +424,7 @@ comm_init_opened(const Comm::ConnectionPointer &conn,
>>      debugs(5, 5, HERE << conn << " is a new socket");
>>  
>>      assert(!isOpen(conn->fd));
>> -    fd_open(conn->fd, FD_SOCKET, note);
>> +    fd_open(conn->fd, FD_SOCKET, SBuf(note));
> 
> 
>> Alex: I do not think we should introduce this performance regression
>> on a common code path. Better debugging/reporting is just not worth
>> it. I have ideas on how this regression can be avoided (and debugging
>> improved), but I do not want to waste time detailing and discussing
>> them if you do not want to spend a lot more time on this PR.
> 
> 
>> Amos: Since this PR is about fixing the compile error I don't want to
>> complicate it any further. But do want to hear these ideas. Can you
>> post them to squid-dev so we can go over it separately please.
> 
> 
> IMO, the best way to annotate file descriptors (and other objects) for
> debugging/reporting purposes is to store pointers to their current
> owners and/or objects currently responsible for FD processing. Very
> roughly speaking:
> 
> class fde
> {
>   ...
> 
>   /* current FD handling context */
> 
>   /// Comm::Connection this FD belongs to
>   WeakConnectionPointer connection;
> 
>   /// Client that created this FD
>   WeakClientPointer creator;
> 
>   /// Server that accepted this FD
>   WeakServerPointer acceptor;
> 
>   /// generic FD owner/handler
>   /// (to cover exceptional contexts missed above?)
>   WeakFdOwnerPointer owner;
> 
>   /// poor man's generic FD owner/handler/operation description
>   /// (to cover performance-ignorant contexts missed above)
>   SBuf note;
> };
> 
> 
> Copying a pointer is a cheap operation; its performance expense is worth
> providing that extra information to developers and sysadmins. The heavy
> price of interpreting/reporting owner details is only paid when that
> extra information is actually requested/used, allowing us to provide a
> lot more useful details (than a short summary which we can compute and
> stuff into an SBuf every time we manipulate an FD).
> 
> Designing the right set of context pointers requires making difficult
> decisions such as whether the fde class should point to acceptor/creator
> (as shown in the above oversimplified sketch) or the Comm::Connection
> class should do that instead. FWIW, the latter makes more sense to me
> now, but I have not given it enough thought.
> 
> Implementing weak pointers correctly (including efficiently) OR
> convincing ourselves that certain strong pointers are acceptable in this
> context is also a serious challenge.
> 
> 
> IMO, we should be moving towards this design while continuing to provide
> sketchy/stale/truncated/limited FD info without performance regressions.
> 
> Fortunately, the two approaches can co-exist nicely: Want more/better
> details? Invest in the right approach for the context you are interested
> in. Just want to continue to provide the bare minimum? Continue to use
> expensive fixed annotation buffers (without slowing things down further)
> and/or cheap constant SBuf annotations.
> 
> 
> HTH,
> 
> Alex.
> 


From squid3 at treenet.co.nz  Tue Jan  7 06:39:21 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jan 2020 19:39:21 +1300
Subject: [squid-dev] Efficient FD annotations
In-Reply-To: <488434a9-d602-8a56-d775-f7e31208deb9@measurement-factory.com>
References: <a2117aa5-7413-415f-6370-e221ffae9082@measurement-factory.com>
 <488434a9-d602-8a56-d775-f7e31208deb9@measurement-factory.com>
Message-ID: <124619a7-7401-5619-3c83-c8dd7b6d7767@treenet.co.nz>

On 7/01/20 4:28 am, Alex Rousskov wrote:
> For the record: The ideas below are superseded by the concept of the
> code context introduced in commit ccfbe8f, including the
> fde::codeContext field. --Alex
> 

If you want to go that way (replace fde:note with fde:codeContext) we
are going to have to do a security audit on the values displayed by the
CodeContext objects. That is due to how the fde::note are sent over the
public network in clear-text transactions for mgr:filedescriptors report.


In regards to PR 70;
  Most of the notes which are dynamically created are coming from the
URL field of HttpRequest which has become an SBuf while this PR was on hold.
 So the performance hit is much reduced from what worried you in the
earlier review. In fact we are about to gain the removal of a c_str() in
the common path and a xstrndup() on all SMP worker shared FDs.


Amos

From rousskov at measurement-factory.com  Tue Jan  7 14:39:20 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 7 Jan 2020 09:39:20 -0500
Subject: [squid-dev] Efficient FD annotations
In-Reply-To: <124619a7-7401-5619-3c83-c8dd7b6d7767@treenet.co.nz>
References: <a2117aa5-7413-415f-6370-e221ffae9082@measurement-factory.com>
 <488434a9-d602-8a56-d775-f7e31208deb9@measurement-factory.com>
 <124619a7-7401-5619-3c83-c8dd7b6d7767@treenet.co.nz>
Message-ID: <651fb68b-fd93-3bb3-70f1-dfb0eba9924e@measurement-factory.com>

On 1/7/20 1:39 AM, Amos Jeffries wrote:
> On 7/01/20 4:28 am, Alex Rousskov wrote:
>> For the record: The ideas below are superseded by the concept of the
>> code context introduced in commit ccfbe8f, including the
>> fde::codeContext field. --Alex

> If you want to go that way (replace fde:note with fde:codeContext)

I would not replace fde::note with fde::codeContext. I would keep
fde::note as a basic indication of the current FD purpose/scope. This
can be done cheaply using string literals or constant SBufs.


> we are going to have to do a security audit on the values displayed
> by the CodeContext objects. That is due to how the fde::note are sent
> over the public network in clear-text transactions for
> mgr:filedescriptors report.

Overall, I doubt such an audit is a good idea -- only the Squid admin
can correctly decide whether it is OK to expose transaction information
in cache manager responses[1,2]. If there is demand for limiting that
exposure, I would rather add a configuration directive that would allow
the admin to control whether Squid is allowed to report context in cache
manager responses, error pages, etc.

Alex.

[1] Some of the transaction context is already exposed in the current
cache manager responses. We may want to add more details or report fewer
details, but there is no paradigm shift here.

[2] In some deployment environments, cache manager responses are
delivered over secure channels.

From rousskov at measurement-factory.com  Wed Jan  8 22:20:36 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 8 Jan 2020 17:20:36 -0500
Subject: [squid-dev] Timeouts for abandoned negative reviews
Message-ID: <ccad0a3f-7b07-7c27-3f77-4acef22b5497@measurement-factory.com>

Hello,

    Squid GitHub pull requests have the following problem: A core
developer can stall PR progress by submitting a negative review and then
ignoring the PR (despite others reminding them that the reviewer action
is required). Such stalled PRs cannot be merged because our policies
strictly prohibit merging of vetoed PRs.

This problem has affected many PRs. Collection of meaningful stats is
prohibitively expensive, but there are ~50 PRs that were open for 100+
days and many of them are not abandoned/irrelevant. Here are some of the
worst examples (the stalled day counts below are approximate):

* PR 369: stalled for 310 days (and counting)
  https://github.com/squid-cache/squid/pull/369

* PR 59: 120-480 days, depending on when you think the PR was stalled
  https://github.com/squid-cache/squid/pull/59

* PR 443: stalled for 100+ days (and counting)
  https://github.com/squid-cache/squid/pull/443

Stalled PRs may significantly increase development overheads and badly
reflect on the Squid Project as a whole. I have heard many complains
from contributors frustrated with the lack of Project responsiveness and
accountability. Stalled PRs have also been used in attempts to block
features from being added to the next numbered release.

While 100-day stalling is unheard of in other open source projects I
know about, the problem with unresponsive reviewers is not unique to
Squid. The best (applicable to the Squid Project) solution that I know
of is a timeout:

If the reviewer remains unresponsive for N days, their negative review
can be dismissed. The counting starts from a well-defined event S, and
there are at least two reminder comments addressed at the reviewer (R1
days after S and R2 days before the dismissal).

Do you think timeouts can solve the problem with stalled PRs if Project
contributors do not attempt to game the system? Can you think of a
better solution?


We can discuss specific parameter values and minor technical details
separately, but I would post the following rough suggestions for
illustrative purposes:

* N (stalling days after which the veto is dismissed): 30. N should be
small enough to prevent long stalls (keeping in mind that an
irresponsible reviewer can stall the same PR many times) but large
enough to accommodate vacations, sickness, overload, and similar
temporary conditions.

* R1 (days between S and the first "you are stalling!" reminder): 20. R1
should be small enough to avoid rushing re-review but large enough to
indicate a likely problem and avoid noise.

* R2 (days between the second reminder and vote dismissal): 5. R2 should
be small enough to reduce "Oh, I will do it later!" failures to
re-review and to clearly indicate a stalling problem (the PR was stalled
for N-R2 days already) but large enough to be sufficient for a thorough
re-review.

* S (the event that resets the timeout counter): The last time the PR is
assigned to the reviewer. GitHub already logs assignments and generates
a notification email. I do not like to abuse the "PR Assignment" feature
to pass the "who is responsible for the next step" baton, but I cannot
think of a _simpler_ way to implement this. Assignment also makes it
easy to search for PRs that await your action. The reviewer would be
responsible for assigning the PR back to the author (if there are
unaddressed change requests) or to Anubis (if a commit is required).


Thank you,

Alex.
P.S. A similar timeout approach can be applied to PRs stalled by
authors, but those PRs represent a smaller problem and their incorrect
handling results in little harm. We can consider that problem and argue
about appropriate parameters for it later.

From squid3 at treenet.co.nz  Fri Jan 10 06:59:08 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jan 2020 19:59:08 +1300
Subject: [squid-dev] Timeouts for abandoned negative reviews
In-Reply-To: <ccad0a3f-7b07-7c27-3f77-4acef22b5497@measurement-factory.com>
References: <ccad0a3f-7b07-7c27-3f77-4acef22b5497@measurement-factory.com>
Message-ID: <acc2c64f-021b-4bfc-e4d3-1636cf48a934@treenet.co.nz>

On 9/01/20 11:20 am, Alex Rousskov wrote:
> Hello,
> 
>     Squid GitHub pull requests have the following problem: A core
> developer can stall PR progress by submitting a negative review and then
> ignoring the PR (despite others reminding them that the reviewer action
> is required). Such stalled PRs cannot be merged because our policies
> strictly prohibit merging of vetoed PRs.

The "problem" you are describing is what I see as a core principle of
the review process.

Consider the case of Joe blogs coming along tomorrow to submits a PR
deleting all of ICAP support from Squid.
 day 1: one reviewer gives it a no-go vote.
 day N: Auto-Merge? oops.


> 
> This problem has affected many PRs.

This situation is not new. I have 400-800 patch submissions from before
the github days that got blocked for various reasons and need polishing
up to re-submit.

One of the oldest is a still-active patch that was submitted in Oct 2010
for improved talloc support. It is being used by some clients from that
period and blocked by reviewer who did not like how the author could not
definitively prove that it would work with all compilers on every
operating system.


> Collection of meaningful stats is
> prohibitively expensive, but there are ~50 PRs that were open for 100+
> days and many of them are not abandoned/irrelevant. Here are some of the
> worst examples (the stalled day counts below are approximate):
> 
> * PR 369: stalled for 310 days (and counting)
>   https://github.com/squid-cache/squid/pull/369
> 
> * PR 59: 120-480 days, depending on when you think the PR was stalled
>   https://github.com/squid-cache/squid/pull/59
> 
> * PR 443: stalled for 100+ days (and counting)
>   https://github.com/squid-cache/squid/pull/443
> 

* PR 30 blocked because the reviewer wants author to fix bugs in
pre-existing code.

(IMO the 'days' metric is less indicative than the PR number itself.)


Also, at a fundamental level I object to the categorization of any open
PRs as "abandoned".

There is a lot of maintainer work in the background which nobody ever sees.

Particular to this proposal I regularly review *all* PRs in a quick scan
to see where progress can happen, as I did for the patches queue under
pre-github systems. What gets omitted is a post to every PR saying "I
looked at this today - decided it was too much work for the next {1,2,3}
hours I have available".

 [ By regular I mean at least once a week. I have two regular days with
usually 3-4 hrs free (you will see most larger audits happen these
days). And 3-4 whole days in a month (you might see _one_ of the larger
PRs worked on each of those days, or it may be worked on but not pushed
yet). ]



> Stalled PRs may significantly increase development overheads and badly
> reflect on the Squid Project as a whole. I have heard many complains
> from contributors frustrated with the lack of Project responsiveness and
> accountability. Stalled PRs have also been used in attempts to block
> features from being added to the next numbered release.

Interesting statement there. Particularly since you and I are
essentially the only reviewers.

Are you admitting reason for PR 358 not being approved yet?

I certainly have not done such underhanded politics. When I want to
block a feature for next release I state so clearly in the PR. Though
there is scant reason to block anything from merging to master when the
code is good - no numbered releases come from there.



> 
> While 100-day stalling is unheard of in other open source projects I
> know about, the problem with unresponsive reviewers is not unique to
> Squid. The best (applicable to the Squid Project) solution that I know
> of is a timeout:
> 
> If the reviewer remains unresponsive for N days, their negative review
> can be dismissed. The counting starts from a well-defined event S, and
> there are at least two reminder comments addressed at the reviewer (R1
> days after S and R2 days before the dismissal).
> 
> Do you think timeouts can solve the problem with stalled PRs if Project
> contributors do not attempt to game the system? Can you think of a
> better solution?
> 

I do not think this will solve stalled PRs.

It may lead to better communication when reviewers are forced to post
regularly about why no progress. But do we really prefer PRs littered
with a long history of that? or a clean history with the 'stalled' state
easily found?
 As the reviewer most likely to be hit by these notices, I much prefer
the PR to end with the thing needing action  than to have to read its
old history to figure out whether I can work on it immediately (see
above about the weekly scan through).
 We could use a tag set by the party suspecting a stall and unset by the
reviewer when they next pay attention to the PR.


Also, IMO it will just change to a different type of stall, add the risk
of Joe Blogs above, and revert Squid to the bygone situation where core
developers were regularly commiting code that broke trunk/master because
they personally thought it less broken than it was. We have this
negative as a veto to protect against those nasties - and for the most
part it is working.


I have outlined below what I think the real problem actually is.
Perhapse a re-focus on that can help come up with something that works
without the QA regressions.



> 
> Thank you,
> 
> Alex.
> P.S. A similar timeout approach can be applied to PRs stalled by
> authors, but those PRs represent a smaller problem and their incorrect
> handling results in little harm. We can consider that problem and argue
> about appropriate parameters for it later.



As I see the situation, the root cause is:

With multiple Factory personnel working paid (full time?) hours on Squid
code there are a lot of large and complicated Factory PRs to review and
only one non-Factory reviewer. When a non-Factory reviewer has an issue
with any one PR it is quickly responded to (usually not fixed,
apparently due to their commercial situation and sunken-costs?) and
bumped back into waiting-for-reviewer status.

Non-Factory patches come along relatively rarely and quickly handled by
the paid (almost-full time?) Factory reviewer with requests that require
a lot of author work.

So IMO these two reviewer vs author stalls are not distinct, but
directly linked to the originator of the PR.


[ In the spirit of being open, Alex is that Factory reviewer and I that
Non-Factory one. We both have quite a lot of overhead work like this
discussion to spread our Squid time over, so maybe hours:minutes instead
of days:hours depicted - I think the relative bias in time is the
important factor there rather than absolute units. ]


FYI: Github has some interesting stats in our records of PR approvals.
We essentially match up in number of PRs reviewed. Though there are some
bumps at the periods of the year my employment takes me away from Squid
where you process 1-2 more that month and those match up against the
times IIRC when the PR queue total grew and the mentioned stall PRs started.


Amos

From squid3 at treenet.co.nz  Fri Jan 10 07:37:32 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jan 2020 20:37:32 +1300
Subject: [squid-dev] Efficient FD annotations
In-Reply-To: <651fb68b-fd93-3bb3-70f1-dfb0eba9924e@measurement-factory.com>
References: <a2117aa5-7413-415f-6370-e221ffae9082@measurement-factory.com>
 <488434a9-d602-8a56-d775-f7e31208deb9@measurement-factory.com>
 <124619a7-7401-5619-3c83-c8dd7b6d7767@treenet.co.nz>
 <651fb68b-fd93-3bb3-70f1-dfb0eba9924e@measurement-factory.com>
Message-ID: <18ae915e-1490-497a-e79e-1c7c71569a98@treenet.co.nz>

On 8/01/20 3:39 am, Alex Rousskov wrote:
> On 1/7/20 1:39 AM, Amos Jeffries wrote:
>> On 7/01/20 4:28 am, Alex Rousskov wrote:
>>> For the record: The ideas below are superseded by the concept of the
>>> code context introduced in commit ccfbe8f, including the
>>> fde::codeContext field. --Alex
> 
>> If you want to go that way (replace fde:note with fde:codeContext)
> 
> I would not replace fde::note with fde::codeContext. I would keep
> fde::note as a basic indication of the current FD purpose/scope. This
> can be done cheaply using string literals or constant SBufs.
> 

In that case, why is this thread being revived?
AIUI your proposals were alternatives to PR 270 - ways to replace the
fde::note field instead of just updating it to SBuf.


> 
>> we are going to have to do a security audit on the values displayed
>> by the CodeContext objects. That is due to how the fde::note are sent
>> over the public network in clear-text transactions for
>> mgr:filedescriptors report.
> 
> Overall, I doubt such an audit is a good idea -- only the Squid admin
> can correctly decide whether it is OK to expose transaction information
> in cache manager responses[1,2].

see responses below to [1] and [2]. Since you are apparently not seeking
to replace the mgr:filedescriptors report fde::note field with
fde::codeContext display - then please take it as a general security
approach policy for handling that type of change.



> If there is demand for limiting that
> exposure, I would rather add a configuration directive that would allow
> the admin to control whether Squid is allowed to report context in cache
> manager responses, error pages, etc.

We do not have to default such an option to publish everything on the
off chance it is safe. Our objective here is to prevent CVEs occuring.
To achieve that we should be defaulting to elide sensitive details from
public view unless configured to show them.

The details I am thinking of most prominently here are things like
credentials and tokens in the auth processing contexts. URL history and
keys in the SSL-Bump context. Access to Squid internal memory spaces on
the server. There are probably others we will uncover later. Anything
that could be reported as a sensitive information leak and assigned a CVE.


> 
> Alex.
> 
> [1] Some of the transaction context is already exposed in the current
> cache manager responses. We may want to add more details or report fewer
> details, but there is no paradigm shift here.

"some" renders this argument irrelevant. The leak issues will be
cropping up about the *new* data if we let that contain anything sensitive.

The purpose of audit is to retrospectively check the those not-yet
published details are safe for publishing. It will either find
everything is OK as-is, or that we need to add a censoring print
operator for publicly visible displays to use.


> 
> [2] In some deployment environments, cache manager responses are
> delivered over secure channels.
> 

"some" renders this argument irrelevant. The leak issues will be
cropping up where they are *not* secured.


Amos

From rousskov at measurement-factory.com  Sat Jan 11 00:20:50 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 10 Jan 2020 19:20:50 -0500
Subject: [squid-dev] Timeouts for abandoned negative reviews
In-Reply-To: <acc2c64f-021b-4bfc-e4d3-1636cf48a934@treenet.co.nz>
References: <ccad0a3f-7b07-7c27-3f77-4acef22b5497@measurement-factory.com>
 <acc2c64f-021b-4bfc-e4d3-1636cf48a934@treenet.co.nz>
Message-ID: <7c6ca887-a42f-4826-ace5-1bd85ce8a1a8@measurement-factory.com>

On 1/10/20 1:59 AM, Amos Jeffries wrote:
> On 9/01/20 11:20 am, Alex Rousskov wrote:
>>     Squid GitHub pull requests have the following problem: A core
>> developer can stall PR progress by submitting a negative review and then
>> ignoring the PR (despite others reminding them that the reviewer action
>> is required). Such stalled PRs cannot be merged because our policies
>> strictly prohibit merging of vetoed PRs.

> The "problem" you are describing is what I see as a core principle of
> the review process.

You may have missed the critical "and then..." part of my description. I
did not describe the ability to block a PR. I described the ability to
block and then ignore the PR. I called that "stalling". The ability to
block a PR (a fundamental feature) is very different from stalling (a
dereliction of duty).

[I am omitting the part of your response that discusses basic PR
blocking because this is not what I am talking about.]


>> Collection of meaningful stats is
>> prohibitively expensive, but there are ~50 PRs that were open for 100+
>> days and many of them are not abandoned/irrelevant. Here are some of the
>> worst examples (the stalled day counts below are approximate):
>>
>> * PR 369: stalled for 310 days (and counting)
>>   https://github.com/squid-cache/squid/pull/369
>>
>> * PR 59: 120-480 days, depending on when you think the PR was stalled
>>   https://github.com/squid-cache/squid/pull/59
>>
>> * PR 443: stalled for 100+ days (and counting)
>>   https://github.com/squid-cache/squid/pull/443


> Also, at a fundamental level I object to the categorization of any open
> PRs as "abandoned".

This term does not change the proposal AFAICT, but what term would you
prefer?


> Particular to this proposal I regularly review *all* PRs in a quick scan
> to see where progress can happen

It is good that you know when a PR needs your attention, but please note
that your scans have not solved the problem I am writing about. We need
to solve that problem.

The timeout might solve (or reduce) the problem not because of new
notifications, but because it sheds reviewer load. A reviewer who for
months sees authors pleading to explain what needs to be done but does
not respond is probably overloaded.


>> Stalled PRs may significantly increase development overheads and badly
>> reflect on the Squid Project as a whole. I have heard many complains
>> from contributors frustrated with the lack of Project responsiveness and
>> accountability. Stalled PRs have also been used in attempts to block
>> features from being added to the next numbered release.


> Interesting statement there. Particularly since you and I are
> essentially the only reviewers.
> 
> Are you admitting reason for PR 358 not being approved yet?

You seem to imply something nefarious on my part. Sorry, I do not know
what you are implying exactly, so I will just stick to the facts:

* PR 358 was approved a year ago and was open for about a day. I do not
think it is relevant here.

* If you meant PR 538, then I reviewed it within ~6 days of opening
(before seeing your squid-dev message), and Eduard helped you make
progress with this PR a few days earlier. And the PR is not even
blocked! Clearly, this is not a stalled PR by any stretch of the
imagination.


> I certainly have not done such underhanded politics. When I want to
> block a feature for next release I state so clearly in the PR. Though
> there is scant reason to block anything from merging to master when the
> code is good - no numbered releases come from there.

I am not sure why you are saying the above. You seem to be trying to
prove that you have not done something bad that I have done, but I do
not know what that something is, so I cannot respond in a meaningful way.


>> While 100-day stalling is unheard of in other open source projects I
>> know about, the problem with unresponsive reviewers is not unique to
>> Squid. The best (applicable to the Squid Project) solution that I know
>> of is a timeout:
>>
>> If the reviewer remains unresponsive for N days, their negative review
>> can be dismissed. The counting starts from a well-defined event S, and
>> there are at least two reminder comments addressed at the reviewer (R1
>> days after S and R2 days before the dismissal).
>>
>> Do you think timeouts can solve the problem with stalled PRs if Project
>> contributors do not attempt to game the system? Can you think of a
>> better solution?


> I do not think this will solve stalled PRs.

Why do you think timeouts will not solve stalled PRs? What do you think
will happen if we agree to enable timeouts (other than better
communication you have mentioned)?

Can you think of a solution that would work?


> It may lead to better communication when reviewers are forced to post
> regularly about why no progress. But do we really prefer PRs littered
> with a long history of that? or a clean history with the 'stalled' state
> easily found?

Sounds like a false dichotomy. I "prefer" that each blocked PR has a
clear, legitimate reason for remaining blocked and a clear way towards a
block removal (where such a removal is possible). IMO, a blocking
reviewer has a duty to engage with the PR author to get the PR into that
state. I hope we agree on this.

We could discuss whether hypothetical blocking reasons such as "I need
three months to review your changes" or "I need four months to find a
vulnerability in your changes" are legitimate (if clearly stated). I
think the correct outcome of such a discussion would be that they are
legitimate when there are no other core developers willing to carefully
approve the PR with a full understanding of the blocking reviewer
concerns (if any).


>  As the reviewer most likely to be hit by these notices, I much prefer
> the PR to end with the thing needing action  than to have to read its
> old history to figure out whether I can work on it immediately

Yes, I agree that increased notification noise is a possible negative
side effect of the timeout solution, but if we cannot find a better
solution, then I think that price is acceptable. Authors essentially
have to generate similar notifications already!


> We could use a tag set by the party suspecting a stall and unset by the
> reviewer when they next pay attention to the PR.

Sure, that procedure can work.

And just to avoid misunderstanding, please note that "paying attention"
is not what resets the timeout. A stalled PR remains stalled until the
reviewer provides sufficient information for the PR author to make progress.


> Also, IMO it will just change to a different type of stall, add the risk
> of Joe Blogs above, and revert Squid to the bygone situation where core
> developers were regularly commiting code that broke trunk/master because
> they personally thought it less broken than it was. We have this
> negative as a veto to protect against those nasties - and for the most
> part it is working.

The usefulness of a veto itself is undisputed. The "old way" did not
work well because committing without a second review was the norm. With
the timeout proposal, it is an _exceptional_ (and recognized as
unfortunate) situation with several safeguards preventing abuse.


> As I see the situation, the root cause is:
> 
> With multiple Factory personnel working paid (full time?) hours on Squid
> code there are a lot of large and complicated Factory PRs to review and
> only one non-Factory reviewer. When a non-Factory reviewer has an issue
> with any one PR it is quickly responded to (usually not fixed,
> apparently due to their commercial situation and sunken-costs?) and
> bumped back into waiting-for-reviewer status.

There is a lot of FUD here!

I will try to clarify what the "usually not fixed" part means:

* If the author knows what the reviewer wants and agrees that there is a
legitimate/in-scope/etc. problem, then the author fixes that problem, of
course.

* Otherwise, the author should ask for clarification or retraction. This
is a natural open source development process rather than a nefarious
scheme driven by "commercial situation and sunken-costs" (whatever that
means!).

Does that match your understanding of that "usually not fixed" statement?


> As I see the situation, the root cause is:
> 
> With multiple Factory personnel working paid (full time?) hours on Squid
> code there are a lot of large and complicated Factory PRs to review and
> only one non-Factory reviewer. When a non-Factory reviewer has an issue
> with any one PR it is quickly responded to (usually not fixed,
> apparently due to their commercial situation and sunken-costs?) and
> bumped back into waiting-for-reviewer status.
> 
> Non-Factory patches come along relatively rarely and quickly handled by
> the paid (almost-full time?) Factory reviewer with requests that require
> a lot of author work.
> 
> So IMO these two reviewer vs author stalls are not distinct, but
> directly linked to the originator of the PR.


I am doing my best to ignore the FUD parts to focus on understanding
what you see as the "root cause". I am having a hard time distilling the
above text into a root cause description. Is it that I request so many
modifications in your PRs that you do not have sufficient time left to
finish PR reviews?


> [ In the spirit of being open, Alex is that Factory reviewer and I that
> Non-Factory one. We both have quite a lot of overhead work like this
> discussion to spread our Squid time over, so maybe hours:minutes instead
> of days:hours depicted - I think the relative bias in time is the
> important factor there rather than absolute units. ]

I do not know what you mean by "days:hours depicted". If you mean that
absolute/calendar delays are not important, then I disagree: For my team
and for the folks waiting for the features to be merged, the absolute
wait time is very important (as well as overheads), especially when that
absolute time is measured not in days or weeks, but months and,
arguably, years.

Alex.

From rousskov at measurement-factory.com  Mon Jan 13 15:01:28 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 13 Jan 2020 10:01:28 -0500
Subject: [squid-dev] Efficient FD annotations
In-Reply-To: <18ae915e-1490-497a-e79e-1c7c71569a98@treenet.co.nz>
References: <a2117aa5-7413-415f-6370-e221ffae9082@measurement-factory.com>
 <488434a9-d602-8a56-d775-f7e31208deb9@measurement-factory.com>
 <124619a7-7401-5619-3c83-c8dd7b6d7767@treenet.co.nz>
 <651fb68b-fd93-3bb3-70f1-dfb0eba9924e@measurement-factory.com>
 <18ae915e-1490-497a-e79e-1c7c71569a98@treenet.co.nz>
Message-ID: <37d56005-7a31-d804-12fe-70d50d276973@measurement-factory.com>

On 1/10/20 2:37 AM, Amos Jeffries wrote:
> On 8/01/20 3:39 am, Alex Rousskov wrote:
>> On 1/7/20 1:39 AM, Amos Jeffries wrote:
>>> On 7/01/20 4:28 am, Alex Rousskov wrote:
>>>> For the record: The ideas below are superseded by the concept of the
>>>> code context introduced in commit ccfbe8f, including the
>>>> fde::codeContext field. --Alex
>>
>>> If you want to go that way (replace fde:note with fde:codeContext)
>>
>> I would not replace fde::note with fde::codeContext. I would keep
>> fde::note as a basic indication of the current FD purpose/scope. This
>> can be done cheaply using string literals or constant SBufs.

> In that case, why is this thread being revived?

FWIW, I was not trying to revive this thread. I simply added a reference
to the (official) next generation of the ideas expressed on that old
thread. IIRC, I posted this "closure" in part because PR 270 is open,
and one of my old comments there refers to this thread.


> AIUI your proposals were alternatives to PR 270 - ways to replace the
> fde::note field instead of just updating it to SBuf.

This thread kept the fde::note field and its SBuf conversion introduced
in PR 270. The thread focused on adding transaction information without
the performance sacrifices. Please see the original message for details:
http://lists.squid-cache.org/pipermail/squid-dev/2019-February/009503.html


>>> we are going to have to do a security audit on the values displayed
>>> by the CodeContext objects. That is due to how the fde::note are sent
>>> over the public network in clear-text transactions for
>>> mgr:filedescriptors report.
>>
>> Overall, I doubt such an audit is a good idea -- only the Squid admin
>> can correctly decide whether it is OK to expose transaction information
>> in cache manager responses[1,2].
> 
> see responses below to [1] and [2]. Since you are apparently not seeking
> to replace the mgr:filedescriptors report fde::note field with
> fde::codeContext display - then please take it as a general security
> approach policy for handling that type of change.

Sorry, I do not understand what "it" and "that type of change" refers to
in your last sentence, especially since those references follow a text
that describes what is _not_ going to happen (i.e. "you are apparently
not ..."). My argument was (and is) that an audit without a
configuration option (or an equivalent shared definition of "sensitive"
and "exposure") would be largely impractical or meaningless because the
auditor would not be able to properly identify problems with exposure of
sensitive info.


>> If there is demand for limiting that
>> exposure, I would rather add a configuration directive that would allow
>> the admin to control whether Squid is allowed to report context in cache
>> manager responses, error pages, etc.

> We do not have to default such an option to publish everything on the
> off chance it is safe. Our objective here is to prevent CVEs occuring.
> To achieve that we should be defaulting to elide sensitive details from
> public view unless configured to show them.

I have no problems with the "do not publish" default for areas where the
information may go to a 3rd party unexpectedly (for a reasonable admin).
You started your paragraph with "we do not have to X". I hope I did not
imply anywhere that we have to X.


> The details I am thinking of most prominently here are things like
> credentials and tokens in the auth processing contexts. URL history and
> keys in the SSL-Bump context. Access to Squid internal memory spaces on
> the server. There are probably others we will uncover later. Anything
> that could be reported as a sensitive information leak and assigned a CVE.

I think we are on the same page here although, IIRC, we already report
URLs in fde::notes.


>> [1] Some of the transaction context is already exposed in the current
>> cache manager responses. We may want to add more details or report fewer
>> details, but there is no paradigm shift here.

> "some" renders this argument irrelevant. The leak issues will be
> cropping up about the *new* data if we let that contain anything sensitive.

I do not follow. If we already expose sensitive data in interface X,
then a reasonable admin would be expected to protect that interface and,
hence, we can add similarly sensitive details there with little risk.
The only other reasonable action that I can see is to file a CVE for
what we are already doing, admitting that we have exposed too much (even
though nobody complained [loudly enough] about that old exposure).


>> [2] In some deployment environments, cache manager responses are
>> delivered over secure channels.

> "some" renders this argument irrelevant. The leak issues will be
> cropping up where they are *not* secured.

I think the context got lost here. The argument was that, in general,
the admin has to decide: In some environments, any exposure is safe,
even new exposure, because the admin has already protected (or disabled)
the affected interface (e.g., [2]). In other environments, any exposure
is undesirable, especially new exposure. Squid cannot distinguish one
environment from another without a new configuration option.

Alex.

From justinmschw at gmail.com  Mon Jan 20 23:52:18 2020
From: justinmschw at gmail.com (agent_js03)
Date: Mon, 20 Jan 2020 17:52:18 -0600 (CST)
Subject: [squid-dev] Want to integrate squid github to Jenkins CI
Message-ID: <1579564338491-0.post@n4.nabble.com>

Hi all,

I am putting together a squid + content filter solution using docker and
kubernetes.
Right now I am setting up a CI system in Jenkins so that when there is a new
release of squid, it will pull the code, build a new container,and then
publish the image to docker hub. So basically I am wanting to know how the
github works. I only want this for new release versions. For example, the
current latest release is 4.10:

http://www.squid-cache.org/Versions/

So when latest updates again, i.e. to 4.11, what happens on github? Is there
a latest tag that gets moved? Or does a certain branch get updated or
something? Looking for a way to trigger.

Thanks a bunch,
-Justin



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Development-f1042840.html

From squid3 at treenet.co.nz  Tue Jan 21 01:22:10 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 21 Jan 2020 14:22:10 +1300
Subject: [squid-dev] Want to integrate squid github to Jenkins CI
In-Reply-To: <1579564338491-0.post@n4.nabble.com>
References: <1579564338491-0.post@n4.nabble.com>
Message-ID: <14b57b4c-86ad-1823-a1b5-9bbf2aad856d@treenet.co.nz>

On 21/01/20 12:52 pm, agent_js03 wrote:
> Hi all,
> 
> I am putting together a squid + content filter solution using docker and
> kubernetes.
> Right now I am setting up a CI system in Jenkins so that when there is a new
> release of squid, it will pull the code, build a new container,and then
> publish the image to docker hub. So basically I am wanting to know how the
> github works. I only want this for new release versions. For example, the
> current latest release is 4.10:
> 
> http://www.squid-cache.org/Versions/
> 
> So when latest updates again, i.e. to 4.11, what happens on github? Is there
> a latest tag that gets moved? Or does a certain branch get updated or
> something? Looking for a way to trigger.


Releases happen in a separate repository, the changes on the main
repository appear as regular PRs to the vNN branches. So I do not think
there is any specific trigger to use unless you are also happy
rebuilding when backports happen (might be good, but YMMV).

We do tag the release commit with a SQUID_* tag some time shortly after
the release has actually bundled. So you could do a check for those
every so often. Releases are intended to take place first weekend of
each month - though as with this month there can be some delays caused
by external situations.


Amos

From justinmschw at gmail.com  Wed Jan 22 04:30:33 2020
From: justinmschw at gmail.com (Justin Michael Schwartzbeck)
Date: Tue, 21 Jan 2020 22:30:33 -0600
Subject: [squid-dev] Want to integrate squid github to Jenkins CI
In-Reply-To: <14b57b4c-86ad-1823-a1b5-9bbf2aad856d@treenet.co.nz>
References: <1579564338491-0.post@n4.nabble.com>
 <14b57b4c-86ad-1823-a1b5-9bbf2aad856d@treenet.co.nz>
Message-ID: <CAGEc96nHdhaWRYwO=+Qj6rA0zbXETpFL4bUmn1qqPQAhBA+jrg@mail.gmail.com>

Hi Amos, thanks for replying.

So I guess maybe I need to narrow this down a little bit more. Is there
some programmatic way that I can get the *latest stable release* *version*
and *source download link*?
Right now I can do this by navigating to the downloads page:
http://www.squid-cache.org/Versions/

Scroll to "Stable Versions" under source code packages, and see that 4.10
is the latest, along with a link.
I guess I could write a script to parse the HTML on that page and find this
information, but that is rather clunky, and if the page format ever changes
then my script will be broken. Is there another way that you are aware of?

Thank you for your patience.
-Justin

On Mon, Jan 20, 2020 at 7:22 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 21/01/20 12:52 pm, agent_js03 wrote:
> > Hi all,
> >
> > I am putting together a squid + content filter solution using docker and
> > kubernetes.
> > Right now I am setting up a CI system in Jenkins so that when there is a
> new
> > release of squid, it will pull the code, build a new container,and then
> > publish the image to docker hub. So basically I am wanting to know how
> the
> > github works. I only want this for new release versions. For example, the
> > current latest release is 4.10:
> >
> > http://www.squid-cache.org/Versions/
> >
> > So when latest updates again, i.e. to 4.11, what happens on github? Is
> there
> > a latest tag that gets moved? Or does a certain branch get updated or
> > something? Looking for a way to trigger.
>
>
> Releases happen in a separate repository, the changes on the main
> repository appear as regular PRs to the vNN branches. So I do not think
> there is any specific trigger to use unless you are also happy
> rebuilding when backports happen (might be good, but YMMV).
>
> We do tag the release commit with a SQUID_* tag some time shortly after
> the release has actually bundled. So you could do a check for those
> every so often. Releases are intended to take place first weekend of
> each month - though as with this month there can be some delays caused
> by external situations.
>
>
> Amos
> _______________________________________________
> squid-dev mailing list
> squid-dev at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20200121/ec8cb766/attachment.html>

From squid3 at treenet.co.nz  Wed Jan 22 10:50:24 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 22 Jan 2020 23:50:24 +1300
Subject: [squid-dev] Want to integrate squid github to Jenkins CI
In-Reply-To: <CAGEc96nHdhaWRYwO=+Qj6rA0zbXETpFL4bUmn1qqPQAhBA+jrg@mail.gmail.com>
References: <1579564338491-0.post@n4.nabble.com>
 <14b57b4c-86ad-1823-a1b5-9bbf2aad856d@treenet.co.nz>
 <CAGEc96nHdhaWRYwO=+Qj6rA0zbXETpFL4bUmn1qqPQAhBA+jrg@mail.gmail.com>
Message-ID: <84f61464-ff12-a430-c77c-2e26aeadfb70@treenet.co.nz>

On 22/01/20 5:30 pm, Justin Michael Schwartzbeck wrote:
> Hi Amos, thanks for replying.
> 
> So I guess maybe I need to narrow this down a little bit more. Is there
> some programmatic way that I can get the *latest stable release*
> *version* and *source download link*?
> Right now I can do this by navigating to the downloads page:
> http://www.squid-cache.org/Versions/
> 
> Scroll to "Stable Versions" under source code packages, and see that
> 4.10 is the latest, along with a link.
> I guess I could write a script to parse the HTML on that page and find
> this information, but that is rather clunky, and if the page format ever
> changes then my script will be broken. Is there another way that you are
> aware of?

There are several ways.

1) You can fetch the FTP directory listing from
<ftp://ftp.squid-cache.org/pub/squid/>


2) You can fetch the checksums file from that directory
<ftp://ftp.squid-cache.org/pub/squid/sha1s.txt> and process it rather
than the directory listing. This is sometimes easier for HTTP mirrors of
the FTP service.


Those contain only the latest 2 releases from each series. This way you
can track when we change stable series - though manual review is advised
at the changeover, so you may want to make that part just a notice for
attention rather than an auto-build.


Any permanent URLs you need linking back to the website for HTTP
download, docs, or FTP archive (all released tarballs) can be
synthesized from the version number.


Amos

From justinmschw at gmail.com  Wed Jan 22 13:45:49 2020
From: justinmschw at gmail.com (Justin Michael Schwartzbeck)
Date: Wed, 22 Jan 2020 07:45:49 -0600
Subject: [squid-dev] Want to integrate squid github to Jenkins CI
In-Reply-To: <84f61464-ff12-a430-c77c-2e26aeadfb70@treenet.co.nz>
References: <1579564338491-0.post@n4.nabble.com>
 <14b57b4c-86ad-1823-a1b5-9bbf2aad856d@treenet.co.nz>
 <CAGEc96nHdhaWRYwO=+Qj6rA0zbXETpFL4bUmn1qqPQAhBA+jrg@mail.gmail.com>
 <84f61464-ff12-a430-c77c-2e26aeadfb70@treenet.co.nz>
Message-ID: <CAGEc96=z2FTCbpR08ew0wZ2YkL+ef4-JPEhmP9uK7ey17cvvwA@mail.gmail.com>

The SHA list sounds great. Thanks for that. I notice that 4.10 is not
there? Is it not considered "stable" officially?

On Wed, Jan 22, 2020 at 4:50 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 22/01/20 5:30 pm, Justin Michael Schwartzbeck wrote:
> > Hi Amos, thanks for replying.
> >
> > So I guess maybe I need to narrow this down a little bit more. Is there
> > some programmatic way that I can get the *latest stable release*
> > *version* and *source download link*?
> > Right now I can do this by navigating to the downloads page:
> > http://www.squid-cache.org/Versions/
> >
> > Scroll to "Stable Versions" under source code packages, and see that
> > 4.10 is the latest, along with a link.
> > I guess I could write a script to parse the HTML on that page and find
> > this information, but that is rather clunky, and if the page format ever
> > changes then my script will be broken. Is there another way that you are
> > aware of?
>
> There are several ways.
>
> 1) You can fetch the FTP directory listing from
> <ftp://ftp.squid-cache.org/pub/squid/>
>
>
> 2) You can fetch the checksums file from that directory
> <ftp://ftp.squid-cache.org/pub/squid/sha1s.txt> and process it rather
> than the directory listing. This is sometimes easier for HTTP mirrors of
> the FTP service.
>
>
> Those contain only the latest 2 releases from each series. This way you
> can track when we change stable series - though manual review is advised
> at the changeover, so you may want to make that part just a notice for
> attention rather than an auto-build.
>
>
> Any permanent URLs you need linking back to the website for HTTP
> download, docs, or FTP archive (all released tarballs) can be
> synthesized from the version number.
>
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20200122/060563c3/attachment.html>

From rousskov at measurement-factory.com  Wed Jan 22 14:21:17 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 22 Jan 2020 09:21:17 -0500
Subject: [squid-dev] Want to integrate squid github to Jenkins CI
In-Reply-To: <CAGEc96nHdhaWRYwO=+Qj6rA0zbXETpFL4bUmn1qqPQAhBA+jrg@mail.gmail.com>
References: <1579564338491-0.post@n4.nabble.com>
 <14b57b4c-86ad-1823-a1b5-9bbf2aad856d@treenet.co.nz>
 <CAGEc96nHdhaWRYwO=+Qj6rA0zbXETpFL4bUmn1qqPQAhBA+jrg@mail.gmail.com>
Message-ID: <e6797404-01cc-bf88-437d-717b455dbeaf@measurement-factory.com>

On 1/21/20 11:30 PM, Justin Michael Schwartzbeck wrote:
> 
> So I guess maybe I need to narrow this down a little bit more. Is there
> some programmatic way that I can get the *latest stable release*
> *version* and *source download link*?

If you want GitHub integration, then you should get all git tags from
the official Squid repository, filter/sort SQUID_X_Y release tags, find
the last tag, and checkout git sources using that tag.

Until the Squid Project starts using GitHub releases, your trigger will
probably have to be any repository modification. Such modifications are
infrequent so the amount of extra tag manipulation work (when the tag of
interest has not changes) will be small.


HTH,

Alex.

From squid3 at treenet.co.nz  Wed Jan 22 14:50:36 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jan 2020 03:50:36 +1300
Subject: [squid-dev] Want to integrate squid github to Jenkins CI
In-Reply-To: <CAGEc96=z2FTCbpR08ew0wZ2YkL+ef4-JPEhmP9uK7ey17cvvwA@mail.gmail.com>
References: <1579564338491-0.post@n4.nabble.com>
 <14b57b4c-86ad-1823-a1b5-9bbf2aad856d@treenet.co.nz>
 <CAGEc96nHdhaWRYwO=+Qj6rA0zbXETpFL4bUmn1qqPQAhBA+jrg@mail.gmail.com>
 <84f61464-ff12-a430-c77c-2e26aeadfb70@treenet.co.nz>
 <CAGEc96=z2FTCbpR08ew0wZ2YkL+ef4-JPEhmP9uK7ey17cvvwA@mail.gmail.com>
Message-ID: <434d55b8-e747-9aed-38a5-cbac5fe4f848@treenet.co.nz>

On 23/01/20 2:45 am, Justin Michael Schwartzbeck wrote:
> The SHA list sounds great. Thanks for that. I notice that 4.10 is not
> there? Is it not considered "stable" officially?
> 

Ah, seems a small bug in our server scripts. Fixed now.

Amos

From mrumph68 at gmail.com  Mon Jan 27 19:11:15 2020
From: mrumph68 at gmail.com (Mike Rumph)
Date: Mon, 27 Jan 2020 11:11:15 -0800
Subject: [squid-dev] Interested in helping with Squid development
Message-ID: <CAKkihnznsHMANKzcXSP_xET+pS4iKep4ZvqnN9RDEjeSWYOMTA@mail.gmail.com>

Hello Squid developers,

I am interested in helping with Squid development.
I've participated as committer on the Apache HTTP Server project since 2012.
And I have over 20 years experience with C/C++.

First of all as I get to know the project, I would help with the
documentation.
For example, I have already found several grammar errors in the following
link that I would like to contribute fixes for:
- https://wiki.squid-cache.org/SquidFaq/ConfiguringSquid

Later, I will be interested in contributing source fixes as well.

Thanks,

Mike Rumph
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20200127/7c11f2eb/attachment.html>

From rousskov at measurement-factory.com  Tue Jan 28 21:23:44 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 28 Jan 2020 16:23:44 -0500
Subject: [squid-dev] Interested in helping with Squid development
In-Reply-To: <CAKkihnznsHMANKzcXSP_xET+pS4iKep4ZvqnN9RDEjeSWYOMTA@mail.gmail.com>
References: <CAKkihnznsHMANKzcXSP_xET+pS4iKep4ZvqnN9RDEjeSWYOMTA@mail.gmail.com>
Message-ID: <86ae4b18-3841-abbd-38c7-0188132f4f34@measurement-factory.com>

On 1/27/20 2:11 PM, Mike Rumph wrote:

> I am interested in helping with Squid development.
> I've participated as committer on the Apache HTTP Server project since 2012.
> And I have over 20 years experience with C/C++.


Hello Mike,

    Welcome to the Squid Project! Squid does need good C++ developers.
We have a lot more work than the current handful of regulars can carry.
The Apache committer status should qualify you for challenging
development projects, but please note that many areas of Squid code are
a lot less polished than httpd.


> First of all as I get to know the project, I would help with the
> documentation.
> For example, I have already found several grammar errors in the
> following link that I would like to contribute fixes for:
> - https://wiki.squid-cache.org/SquidFaq/ConfiguringSquid 
> 
> Later, I will be interested in contributing source fixes as well.

For wiki fixes, please see the following first step instructions if you
have not already: https://wiki.squid-cache.org/WikiAccountCreation

Another, somewhat similar project would be addressing bug 5021:
http://bugs.squid-cache.org/show_bug.cgi?id=5021


Cheers,

Alex.

