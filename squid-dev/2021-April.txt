From jrogers at opera.com  Sun Apr  4 21:31:15 2021
From: jrogers at opera.com (Joshua Rogers)
Date: Sun, 4 Apr 2021 23:31:15 +0200
Subject: [squid-dev] Forcing interception(transparent) mode,
 disabling NS lookups, and 'secretly' forwarding connections
Message-ID: <CAOCwWhGywGKMVqugaEn2rsYOV-g03ieb1d0JUVUhuvpYw6uSkQ@mail.gmail.com>

Hi all,

I have an extremely specific question about manipulating Squid to run to in
a very specific way.
Due to the complexity, I will gladly accept a "not possible" answer.

I need to make the following changes to Squid, or somehow manipulate Squid
to:

1) Always consider a client intercepted. This would mean
that COMM_INTERCEPTION is set for every client no matter what.

2) NS lookups for domains needs to be disabled or simply return localhost.
I have considered setting AI_NUMERICHOST flag for every getaddrinfo() call,
but I don't think this function is used for making connections to a website
(gethostbyname seems to be used in some places).

3) Every outward connection Squid makes needs to be forwarded to localhost
on a specific port.


Why do I need to do this?
I have a large set of files which contain HTTP requests (headers included).
I have a large set of files which contain HTTP responses (headers included).

I would like to loop the HTTP requests, sending each request to Squid, and
then I would like to run a loop, responding with each of the HTTP responses
I have stored. The idea is to get a nice code coverage report which I can
use for research later on.

Like I said, this is a bit complicated, but I thought I would act, perhaps
somebody has an interesting idea how to do this :-). It will most certainly
require me to somehow defile the source code, but this is just temporary
and is nothing to do with a production service.

Happy to hear any ideas.

Cheers,
Josh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20210404/fa5f6d8b/attachment.htm>

From jrogers at opera.com  Sun Apr  4 23:06:29 2021
From: jrogers at opera.com (Joshua Rogers)
Date: Mon, 5 Apr 2021 01:06:29 +0200
Subject: [squid-dev] Forcing interception(transparent) mode,
 disabling NS lookups, and 'secretly' forwarding connections
In-Reply-To: <CAOCwWhGywGKMVqugaEn2rsYOV-g03ieb1d0JUVUhuvpYw6uSkQ@mail.gmail.com>
References: <CAOCwWhGywGKMVqugaEn2rsYOV-g03ieb1d0JUVUhuvpYw6uSkQ@mail.gmail.com>
Message-ID: <CAOCwWhHb8U3GAQbC97L4BtCaVuV+7ZVDdeXaVjQ6Yxu1jecZvQ@mail.gmail.com>

I ended up finding a solution.

http->uri in the ConnStateData::parseHttpRequest function can simply be
rewritten to be http://localhost:80/. You can also manually set
COMM_INTERCEPTION a little bit before that.



On Sun, Apr 4, 2021 at 11:31 PM Joshua Rogers <jrogers at opera.com> wrote:

> Hi all,
>
> I have an extremely specific question about manipulating Squid to run to
> in a very specific way.
> Due to the complexity, I will gladly accept a "not possible" answer.
>
> I need to make the following changes to Squid, or somehow manipulate Squid
> to:
>
> 1) Always consider a client intercepted. This would mean
> that COMM_INTERCEPTION is set for every client no matter what.
>
> 2) NS lookups for domains needs to be disabled or simply return localhost.
> I have considered setting AI_NUMERICHOST flag for every getaddrinfo() call,
> but I don't think this function is used for making connections to a website
> (gethostbyname seems to be used in some places).
>
> 3) Every outward connection Squid makes needs to be forwarded to localhost
> on a specific port.
>
>
> Why do I need to do this?
> I have a large set of files which contain HTTP requests (headers included).
> I have a large set of files which contain HTTP responses (headers
> included).
>
> I would like to loop the HTTP requests, sending each request to Squid, and
> then I would like to run a loop, responding with each of the HTTP responses
> I have stored. The idea is to get a nice code coverage report which I can
> use for research later on.
>
> Like I said, this is a bit complicated, but I thought I would act, perhaps
> somebody has an interesting idea how to do this :-). It will most certainly
> require me to somehow defile the source code, but this is just temporary
> and is nothing to do with a production service.
>
> Happy to hear any ideas.
>
> Cheers,
> Josh
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20210405/879068ed/attachment.htm>

From rousskov at measurement-factory.com  Mon Apr  5 01:51:13 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 4 Apr 2021 21:51:13 -0400
Subject: [squid-dev] Forcing interception(transparent) mode,
 disabling NS lookups, and 'secretly' forwarding connections
In-Reply-To: <CAOCwWhHb8U3GAQbC97L4BtCaVuV+7ZVDdeXaVjQ6Yxu1jecZvQ@mail.gmail.com>
References: <CAOCwWhGywGKMVqugaEn2rsYOV-g03ieb1d0JUVUhuvpYw6uSkQ@mail.gmail.com>
 <CAOCwWhHb8U3GAQbC97L4BtCaVuV+7ZVDdeXaVjQ6Yxu1jecZvQ@mail.gmail.com>
Message-ID: <a1f73f2d-9323-d39b-508d-050c82c64317@measurement-factory.com>

On 4/4/21 7:06 PM, Joshua Rogers wrote:
> I ended up finding a solution.
> 
> http->uri in the ConnStateData::parseHttpRequest function can simply be
> rewritten to be http://localhost:80/ <http://localhost:80/>. You can
> also manually set COMM_INTERCEPTION a little bit before that.

You may also be able to use a cache_peer or URL rewriter for this.

Alex.


> On Sun, Apr 4, 2021 at 11:31 PM Joshua Rogers wrote:
> 
>     Hi all,
> 
>     I have an extremely specific question about manipulating Squid to
>     run to in a very specific way.
>     Due to the complexity, I will gladly accept a "not possible" answer.
> 
>     I need to make the following changes to Squid, or somehow manipulate
>     Squid to:
> 
>     1) Always consider a client intercepted. This would mean
>     that COMM_INTERCEPTION is set for every client no matter what.
> 
>     2) NS lookups for domains needs to be disabled or simply return
>     localhost. I have considered setting AI_NUMERICHOST flag for every
>     getaddrinfo() call, but I don't think this function is used for
>     making connections to a website (gethostbyname seems to be used in
>     some places).
> 
>     3) Every outward connection Squid makes needs to be forwarded to
>     localhost on a specific port.
> 
> 
>     Why do I need to do this?
>     I have a large set of files which contain HTTP requests (headers
>     included).
>     I have a large set of files which contain HTTP responses (headers
>     included).
> 
>     I would like to loop the HTTP requests, sending each request to
>     Squid, and then I would like to run a loop, responding with each of
>     the HTTP responses I have stored. The idea is to get a nice code
>     coverage report which I can use for research later on.
> 
>     Like I said, this is a bit complicated, but I thought I would act,
>     perhaps somebody has an interesting idea how to do this :-). It will
>     most certainly require me to somehow defile the source code, but
>     this is just temporary and is nothing to do with a production service.
> 
>     Happy to hear any ideas.
> 
>     Cheers,
>     Josh


From subchell at gmail.com  Thu Apr 22 12:25:19 2021
From: subchell at gmail.com (sub chell)
Date: Thu, 22 Apr 2021 17:55:19 +0530
Subject: [squid-dev] Query: Debs to be picked for attached patch on top of
 squid 4.6-1
Message-ID: <CAOupnftn2eeFHC+NiA_Qe0wiOTLO9pgeFCGNd-g91ocTBpuXqA@mail.gmail.com>

Hi Team,

I am trying to customize squid 4.6-1 with an attached patch and building
the same.
Please let me know what are all the debs it might affect with this change,
means what are all the debs i need to take it from my customized build
other than buster squid(https://packages.debian.org/buster/squid)

diff -Naur '--exclude=.pc' squid-4.6/debian/rules squid-4.6_new/debian/rules
--- squid-4.6/debian/rules      2021-04-12 00:47:35.071871989 -0500
+++ squid-4.6_new/debian/rules  2021-04-12 01:03:19.630856334 -0500
@@ -28,7 +28,7 @@
 DEB_CONFIGURE_EXTRA_FLAGS := BUILDCXXFLAGS="$(CXXFLAGS) $(CPPFLAGS)
$(LDFLAGS)" \
                BUILDCXX=$(CXX_FOR_BUILD) \
                --with-build-environment=default \
-               --enable-build-info="$(BUILDINFO) $(DEB_HOST_ARCH_OS)" \
+               --enable-build-info="Debian $(DEB_HOST_ARCH_OS)" \
                --datadir=/usr/share/squid \
                --sysconfdir=/etc/squid \
                --libexecdir=/usr/lib/squid \
@@ -54,7 +54,8 @@
                --enable-esi \
                --enable-icmp \
                --enable-zph-qos \
-               --enable-ecap \
+               --disable-ecap \
+                --disable-ipv6 \
                --disable-translation \
                --with-swapdir=/var/spool/squid \
                --with-logdir=/var/log/squid \

Thanks & Regards,
Subramanian.C
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20210422/77028e04/attachment.htm>

From squid3 at treenet.co.nz  Mon Apr 26 06:44:07 2021
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Mon, 26 Apr 2021 18:44:07 +1200
Subject: [squid-dev] Query: Debs to be picked for attached patch on top
 of squid 4.6-1
In-Reply-To: <CAOupnftn2eeFHC+NiA_Qe0wiOTLO9pgeFCGNd-g91ocTBpuXqA@mail.gmail.com>
References: <CAOupnftn2eeFHC+NiA_Qe0wiOTLO9pgeFCGNd-g91ocTBpuXqA@mail.gmail.com>
Message-ID: <502b58f7c27d0d08c09621c2d3fe60df@treenet.co.nz>

On 2021-04-23 00:25, sub chell wrote:
> Hi Team,
> 
> I am trying to customize squid 4.6-1 with an attached patch and
> building the same.

OK.

> Please let me know what are all the debs it might affect with this
> change, means what are all the debs i need to take it from my
> customized build other than buster
> squid(https://packages.debian.org/buster/squid)

Sorry, what are you trying to ask here?

> 
> diff -Naur '--exclude=.pc' squid-4.6/debian/rules
> squid-4.6_new/debian/rules
> --- squid-4.6/debian/rules      2021-04-12 00:47:35.071871989 -0500
> +++ squid-4.6_new/debian/rules  2021-04-12 01:03:19.630856334 -0500
> @@ -28,7 +28,7 @@
>  DEB_CONFIGURE_EXTRA_FLAGS := BUILDCXXFLAGS="$(CXXFLAGS) $(CPPFLAGS)
> $(LDFLAGS)" \
>                 BUILDCXX=$(CXX_FOR_BUILD) \
>                 --with-build-environment=default \
> -               --enable-build-info="$(BUILDINFO) $(DEB_HOST_ARCH_OS)"
> \
> +               --enable-build-info="Debian $(DEB_HOST_ARCH_OS)" \
>                 --datadir=/usr/share/squid \
>                 --sysconfdir=/etc/squid \
>                 --libexecdir=/usr/lib/squid \
> @@ -54,7 +54,8 @@
>                 --enable-esi \
>                 --enable-icmp \
>                 --enable-zph-qos \
> -               --enable-ecap \
> +               --disable-ecap \
> +                --disable-ipv6 \


Why disable these?

eCAP is a feature not used unless configured.

IPv6 is not optional in modern traffic. Removing it can lead to crashes 
etc.


Amos

From gkinkie at gmail.com  Wed Apr 28 05:45:45 2021
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 28 Apr 2021 07:45:45 +0200
Subject: [squid-dev] Strategy about build farm nodes
Message-ID: <CA+Y8hcPL8bQfwfnUyAMhuZ8gwKK-ETZJPYw3WhApC1qBMCWMcA@mail.gmail.com>

Hi all,
  I'm moving here the discussion from PR #806 about what strategy to have
for CI tests, looking for an agreement.

We have 3 classes of tests ni our CI farm (https://build.squid-cache.org/)
- PR staging tests, triggered by commit hooks on GitHub (possibly with
human approval)
   the job is 5-pr-auto (misnamed, it tests trunk with the PR applied).
   To be successful, it needs to successfully compile and unit-test all
combinations of clang and gcc on the latest stable version of the most
popular linux distros, at this time centos-8, debian-testing,
fedora-33, opensuse-leap, ubuntu-focal
- PR build tests run , after a PR is approved, also triggered by GitHub
  the job is 5-pr-test
  To be successful, it needs to compile and unit-test all combinations of
clang and gcc on LTS and most recent versions of most popular linux
distros, at this time: centos-7,
debian-stable, debian-unstable, fedora-32, fedora-34, ubuntu-bionic,
ubuntu-hirsute
- full-scale build tests (jobs: trunk-matrix, trunk-arm32-matrix,
trunk-arm64-matrix, trunk-freebsd13-clang-matrix, trunk-openbsd-matrix)
  these test everything we can test, including bleeding edge distros such
as getntoo, rawhide, tumbleweed, and the latest compilers. Failing these
will not block a PR from mergeing, but there is an expectation that build
regressions will be fixed

The change in policy since last week is that the PR-blocking builds used to
depend on unstabledistros (fedora-rawhide and opensuse-tumbleweed), I've
removed that today as part of the discussion on PR #806
This policy would allow keeping stable distros uptodate and matching
expected user experience, while not introducing instability that would come
in from the unstable distros
One distro that's notably missing is centos-stream, this is due to
technical issues with getting a good docker image for it, when available
I'll add it

Would this work as a general policy? If there is agreement, I'll support
it moving forward

Thanks

-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20210428/3e3e3195/attachment.htm>

From rousskov at measurement-factory.com  Wed Apr 28 15:47:41 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 28 Apr 2021 11:47:41 -0400
Subject: [squid-dev] Strategy about build farm nodes
In-Reply-To: <CA+Y8hcPL8bQfwfnUyAMhuZ8gwKK-ETZJPYw3WhApC1qBMCWMcA@mail.gmail.com>
References: <CA+Y8hcPL8bQfwfnUyAMhuZ8gwKK-ETZJPYw3WhApC1qBMCWMcA@mail.gmail.com>
Message-ID: <4ad7be77-2903-61b5-f9da-1e35528f48eb@measurement-factory.com>

On 4/28/21 1:45 AM, Francesco Chemolli wrote:

>   I'm moving here the discussion from PR #806 about what strategy to
> have for CI tests, looking for an agreement.

> We have 3 classes of tests ni our CI farm
> (https://build.squid-cache.org/)

> - PR staging tests, triggered by commit hooks on GitHub (possibly with
> human approval)

>    the job is 5-pr-auto (misnamed, it tests trunk with the PR applied).

FYI: The "auto" branch is "master branch + PR". When PR is merged,
master becomes identical to the auto branch. The name "auto" is fairly
common in CI AFAICT. In Anubis (and relatively widespread/common)
terminology[1], the words "staged" and "staging" mean what you describe
as "trunk with the PR applied" below.

[1]
https://github.com/measurement-factory/anubis/blob/master/README.md#pull-request-merging-algorithm

AFAICT, this class should _follow_ the 5-pr-test class (described below)
because a PR is not staged until it is approved and passes 5-pr-test checks.


>    To be successful, it needs to successfully compile and unit-test all
> combinations of clang and gcc on the latest stable version of the most
> popular linux distros, at this time centos-8, debian-testing,
> fedora-33, opensuse-leap, ubuntu-focal


> - PR build tests run , after a PR is approved, also triggered by GitHub
>   the job is 5-pr-test

AFAICT, this job tests the "GitHub-generated merge commit for the PR
branch". That commit may become stale if master advances while there
were no PR branch commits. Unlike the GitHub-generated merge commit, the
"auto" branch (mentioned above) is kept in sync with master by Anubis.

We do not merge the GitHub-generated merge commit into master.

If 5-pr-test requires a PR approval, then something probably went wrong
somewhere. Testing PR branch or the GitHub-generated merge commit should
not require a PR approval. Perhaps you meant the "OK to test" _testing_
approval. That testing approval is indeed required and expected for
testing GitHub-generated merge commits on vulnerable Jenkins.


>   To be successful, it needs to compile and unit-test all combinations
> of clang and gcc on LTS and most recent versions of most popular linux
> distros, at this time: centos-7,
> debian-stable, debian-unstable, fedora-32, fedora-34, ubuntu-bionic, ubuntu-hirsute

> - full-scale build tests (jobs: trunk-matrix, trunk-arm32-matrix,
> trunk-arm64-matrix, trunk-freebsd13-clang-matrix, trunk-openbsd-matrix)
>   these test everything we can test, including bleeding edge distros
> such as getntoo, rawhide, tumbleweed, and the latest compilers. 

Please clarify what branches/commits these "full-scale build tests" test.

Ideally, all this should be documented somewhere on Squid wiki!


> Failing
> these will not block a PR from mergeing, but there is an expectation
> that build regressions will be fixed

If we expect a fix, then the failure has to block something important,
like the responsible PR (ideally), the next numbered release, or all
PRs. What does this failure block today, if anything?


> The change in policy since last week

There was no change in any Project policies AFAIK. You have changed
Jenkins setup, but that is not a change in policy. It is likely that
there is no policy at all right now -- just ad hoc decisions by
sysadmins. It would be a stretch to call that current approach a
"policy", but even if we do call it that, then that "policy" has not
"changed" :-).

Alternatively, Jenkins configuration changes have violated a Project
policy (one cannot _change_ a Project policy unilaterally; one can only
violate it). I prefer the "no policy" version above though :-).


> is that the PR-blocking builds used
> to depend on unstabledistros (fedora-rawhide and opensuse-tumbleweed),
> I've removed that today as part of the discussion on PR #806
> This policy would allow keeping stable distros uptodate and matching
> expected user experience, while not introducing instability that would
> come in from the unstable distros
> One distro that's notably missing is centos-stream, this is due to
> technical issues with getting a good docker image for it, when available
> I'll add it

> Would this work as a general policy?

I am not sure what exact general policy you are proposing -- please
extract it from the lengthy prose above (removing the ever-changing
low-level specifics to the extent possible, to arrive at something truly
"general"). FWIW, if the fleshed out proposal violates the existing "do
not break master" principle below, then I do not think it will work
well. I suspect that a focus on vague optimization targets like
"expected user experience" will not allow us to formulate a usable
policy we can all agree on, but I would be happy to be proven wrong.


I can propose the following. Perhaps knowing my state of mind will help
you finalize your proposal.

We already have a "do not break master" principle:

* Master always passes all current development-related tests.


I propose to add the following principle:

* A test failure blocks the change responsible for that failure.


Direct consequences of that principle are:

* If the breaking change is a CI change (e.g., an OS upgrade on a
Jenkins test node), then the change must be reverted (until it becomes
non-blocking).

* If the breaking change is a code change, then the corresponding pull
request must be fixed before it is merged. We already apply this
principle (or are very close to faithfully applying it).


The above applies to what I called, for the lack of a better term,
"development-related" tests. These are the tests applied to staged
commits[1] today. Until Squid releases are automated and "always ready",
we should have "release-related" tests as well. It is not clear to me
whether such automated release-related tests exist today in our CI, but,
if they do exist, then the same principles can be applied to releases:

* A new release passes all contemporary release-related tests.
* A test failure blocks the change responsible for that failure.

Just like for development-related tests, a release-related test failure
would imply that either the tests have to be fixed or the release
candidate has to be rejected.

N.B. I am talking about releases separately from PRs primarily because I
suspect that some of the Jenkins tests may not be applicable to PRs but
are currently considered applicable to releases. For example, we are OK
with master build failures on OS Foo, but we still want all official
releases to build on that OS. If that is not the case today, then we do
not have to complicate things by separating development concerns from
release concerns!


HTH,

Alex.

From squid3 at treenet.co.nz  Wed Apr 28 21:12:33 2021
From: squid3 at treenet.co.nz (=?UTF-8?B?4oCqQW1vcyBKZWZmcmllc+KArA==?=)
Date: Thu, 29 Apr 2021 09:12:33 +1200
Subject: [squid-dev] Strategy about build farm nodes
References: <CA+Y8hcPL8bQfwfnUyAMhuZ8gwKK-ETZJPYw3WhApC1qBMCWMcA@mail.gmail.com>
 <4ad7be77-2903-61b5-f9da-1e35528f48eb@measurement-factory.com>
Message-ID: <skbb4h-uyjkyaq2eh9e-cobkd3wscnh4-immygnraz6742804ck-q6a3ttagbfe9v5pbqc159bg8-v28t3ahg46rm-rh7jqfus9643gsz6fm-a1iuwpuu45ja2wj7su-s2y08l-su112h-ezpmst-tdvuc4.1619642950774@email.android.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20210429/bbd61d9e/attachment.htm>

From rousskov at measurement-factory.com  Wed Apr 28 21:34:43 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 28 Apr 2021 17:34:43 -0400
Subject: [squid-dev] Strategy about build farm nodes
In-Reply-To: <skbb4h-uyjkyaq2eh9e-cobkd3wscnh4-immygnraz6742804ck-q6a3ttagbfe9v5pbqc159bg8-v28t3ahg46rm-rh7jqfus9643gsz6fm-a1iuwpuu45ja2wj7su-s2y08l-su112h-ezpmst-tdvuc4.1619642950774@email.android.com>
References: <CA+Y8hcPL8bQfwfnUyAMhuZ8gwKK-ETZJPYw3WhApC1qBMCWMcA@mail.gmail.com>
 <4ad7be77-2903-61b5-f9da-1e35528f48eb@measurement-factory.com>
 <skbb4h-uyjkyaq2eh9e-cobkd3wscnh4-immygnraz6742804ck-q6a3ttagbfe9v5pbqc159bg8-v28t3ahg46rm-rh7jqfus9643gsz6fm-a1iuwpuu45ja2wj7su-s2y08l-su112h-ezpmst-tdvuc4.1619642950774@email.android.com>
Message-ID: <baedd943-1a24-bc0e-2cbc-50e6cd34397b@measurement-factory.com>

On 4/28/21 5:12 PM, Amos Jeffries wrote:
> I'm not sure why this is so controversial still. We have already been
> over these and have a policy from last time:

Apparently, the recollections of what was agreed upon, if anything,
during that "last time" differ. If you can provide a pointer to that
"last time" agreement, please do so.


> * dev PR submissions use the volatile 5-pr-test, after test approval by
> anyone in QA. Check against unstable OS nodes, as many as possible.
> Kinkie adds/removes from that set as upgrades fix or break at CI end of
> things.

I do not know how to interpret the last sentence correctly, but, IMO, we
should not add or change nodes if doing so breaks master tests. AFAICT
from PR 806 discussion[1], Francesco thinks that it is not a big deal to
do so. The current discussion is meant to resolve that disagreement.

[1] https://github.com/squid-cache/squid/pull/806#issuecomment-827937563


> * anubis auto branch tested by curated set of LTS stable nodes only.

FWIW, the above list and the original list by Francesco appears to focus
on distro stability, popularity, and other factors that are largely
irrelevant to the disagreement at hand. The disagreement is whether it
is OK to break master (and, hence, all PR) tests by changing CI. It does
not matter whether that CI change comes from an upgrade of an "LTS
stable node", "unstable node", or some other source IMO. Breaking
changes should not be allowed (in the CI environments under our
control). If they slip through despite careful monitoring for change
effects, the breaking CI changes should be reverted.

Alex.

From dsuhpublic at gmail.com  Thu Apr 29 06:09:57 2021
From: dsuhpublic at gmail.com (dsuh)
Date: Wed, 28 Apr 2021 23:09:57 -0700
Subject: [squid-dev] Any code pointers to get sending certificate chain from
 squid reverse proxy with gnutls?
Message-ID: <CABWAcDuVUKkxkUGZUmvRhWANtWZ0nvScHYjPCOoG1vYe5s+WbA@mail.gmail.com>

I have hit a wall as I want to listen on one https_port for 3 different
server key/cert chains.
Previous message about 2 years ago says this has not been implemented yet.
http://squid-web-proxy-cache.1019090.n4.nabble.com/sending-certificate-chain-from-squid-reverse-proxy-td4687986.html

I am looking at what it would take to get cert chains working.
I think the credentials are set for gnutls TLS handshake
with gnutls_credentials_set() call in CreateSession() in Session.cc
So, I think that ctx is used for session data for gnutls and also for
context data for openssl?
I think I kind of got lost on how I can make sure a cert chain (instead of
just the server cert) is set in ctx.
Any direction on where the server cert chain should be set for gnutls TLS
handshake would be appreciated.

David Suh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-dev/attachments/20210428/a27f50af/attachment.htm>

