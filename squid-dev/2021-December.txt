From gkinkie at gmail.com  Sun Dec  5 09:44:46 2021
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Sun, 5 Dec 2021 09:44:46 +0000
Subject: [squid-dev] What os/cpu platforms do we want to target as a project?
Message-ID: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>

Hi all,
  continuing the conversation from
https://github.com/squid-cache/squid/pull/942#issuecomment-986055422
to a bigger forum

The discussion started out of a number of PRs meant to remove explicit
support for obsolete platforms such as OSF/1, NeXT or old versions of
Solaris.

I that thread I move forward a list of platforms that in my opinion we
should as a project target, and while of course we should not
explicitly prevent other platforms from being built on, we should also
not disperse our time supporting complexity for the sake of other
os/cpu combos .

The rationale is that we should focus our attention as a project where
the majority of our userbase is, where users mean "people who build
and run squid".

We have no way of knowing who is installing squid, we don't have
telemetry, so we will need to do a bit of guesswork, based on the
assumption that people who deploy squid are rational; as a consequence
of that, we can assume that they will go for the solution that gives
them most bang for buck ("buck" being money and time).

What are the main use cases for squid users? (again, guesswork, please
feel free to add more)
1. forward proxy in enterprise or ISP
2. reverse proxy in datacenter
3. forward proxy in small or embedded environments

What are the Os/CPU combos that we can expect to find in these environments?
x64 is likely to be found in all of them, and the OSes most likely to
be used are all sorts of Linux, FreeBSD, OpenBSD, Windows.
For the third use case (and possibly more and more of the second in
upcoming years), we can consider arm64, arm32 and possibly MIPS with
Linux. There might be a niche of NetBSD users here, hard to tell.

By now it makes no economic sense to run Squid on large Unix boxen.
Maybe some corporate can convince some captive account to run a
reverse proxy on AIX/POWER, but I don't see anyone willing to pay tens
of thousands of dollars in maintenance contracts on expensive UNIX
iron to run a service that can run as well if not better on Linux/x64

Given these reasonings, I would recommend that we support as main targets:
- Linux on x64, arm64, arm32 and, if we can, MIPS
- FreeBSD, OpenBSD on x64
As best-effort:
- Windows on x64, with the aim of eventually promoting to primary target
- Darwin on x64 and maybe eventually arm64
- NetBSD on x64

If anyone in the community wants to support/maintain extra OSes or
architectures, they're very welcome to do so; I expect that the target
audience is of enthusiasts who have the technical skills to do so,
largely independently.

What do we get as a project out of this?
- Mainly code simplification. Fewer portability subcases makes for
easier to understand and modify code
- More clarity about our target use cases
- better coverage in our testing for our explicit target use cases


Let's discuss

-- 
    Francesco

From squid3 at treenet.co.nz  Sun Dec  5 12:00:03 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 6 Dec 2021 01:00:03 +1300
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
Message-ID: <abc50ecc-b54d-db33-a0bc-8cceafb2c8d9@treenet.co.nz>

On 5/12/21 22:44, Francesco Chemolli wrote:
> Hi all,
>    continuing the conversation from
> https://github.com/squid-cache/squid/pull/942#issuecomment-986055422
> to a bigger forum
> 
> The discussion started out of a number of PRs meant to remove explicit
> support for obsolete platforms such as OSF/1, NeXT or old versions of
> Solaris.
> 
> I that thread I move forward a list of platforms that in my opinion we
> should as a project target, and while of course we should not
> explicitly prevent other platforms from being built on, we should also
> not disperse our time supporting complexity for the sake of other
> os/cpu combos .
> 
> The rationale is that we should focus our attention as a project where
> the majority of our userbase is, where users mean "people who build
> and run squid".
> 

I do not accept that a few hacks for old OS are causing pain to core 
developers simply by bitrotting in untouched code.

Removing things because the majority of users are not using it would 
mean we become a Linux-only project and thus actively push people out of 
the community unnecessarily. There are active benefits gained in the 
form of better code, bug detection, and community inclusiveness from 
maintaining portable code.


FTR; The criteria informing my OS removal decisions so far have been:

  a) Squid-3 has support for any OS which has a chance at providing C++ 
tools. Inheriting from the Squid-2 support for any ancient OS that had 
someone willing to provide patches.

  b) Squid-4+ require C++11 toolchain. This eliminates a lot of very old 
OS code. Especially those which have no vendor/distro have little chance 
at providing a modern toolchain.

  - At times the vendor/distro supporting that OS provides 
toolchains/support in ways that no longer need our hacks (eg PR 944 m88k 
supported as normal NetBSD/OpenBSD builds, PR 943 likewise as QNX or 
MacOS builds).

  -  At times our hack is for a version of OS which the vendor(s) 
provide (and/or require) admin to use a newer version of Squid for. Our 
usual distro hack removals.

  c) OS which are outdated (newer version supported by the vendors) need 
a reasonable ability for any admin wanting to manually build their Squid 
able to do so. If we know of any admin wanting the code to remain it can 
stay unless we have a clear reason to remove. (eg PR 942)


NP: now that Squid has formally dated releases I have a timeline for 
support forcasts. (eg PR 942 vendor LTS schedule vs Squid-6 release)



> We have no way of knowing who is installing squid, we don't have
> telemetry, so we will need to do a bit of guesswork, based on the
> assumption that people who deploy squid are rational; as a consequence
> of that, we can assume that they will go for the solution that gives
> them most bang for buck ("buck" being money and time).
> 
> What are the main use cases for squid users? (again, guesswork, please
> feel free to add more)
> 1. forward proxy in enterprise or ISP
> 2. reverse proxy in datacenter
> 3. forward proxy in small or embedded environments
> 


IME, (1) and (2) have switched places in the past 5 years for actual 
usage. Though (1) people are more vocal with SSL-Bump problems.


  4. protocol translation gateways

Historically FTP and Gopher to HTTP. Recent years IPv6/v4 conversion. 
Plus latest Browsers dropping FTP support has brought back FTP gateway 
translation popularity.


We should be in the thick of HTTP 1/2/3 conversion, but blockers on that 
work have completely eliminated Squid from that section of the market. 
People wanting that go to Haproxy instead.



> What are the Os/CPU combos that we can expect to find in these environments?

Ubuntu is a large chunk of user base and that alone requires a large 
range of architectures (see https://buildd.debian.org/) to get through 
Debian. That includes BSD and microkernel builds, not just Linux.

So, IMO specific machine architectures are not much concern to "us". The 
toolchains and vendors take care of that part so long as we provide 
half-decent code.


> x64 is likely to be found in all of them, and the OSes most likely to
> be used are all sorts of Linux, FreeBSD, OpenBSD, Windows.
> For the third use case (and possibly more and more of the second in
> upcoming years), we can consider arm64, arm32 and possibly MIPS with
> Linux. There might be a niche of NetBSD users here, hard to tell.
> 
> By now it makes no economic sense to run Squid on large Unix boxen.

Worse decisions have been sighted from management levels and not every 
admin has a choice. I don't think this is a strong enough argument for 
it to be relevant to this discussion.



> 
> What do we get as a project out of this?
> - Mainly code simplification. Fewer portability subcases makes for
> easier to understand and modify code

When it comes to portability the outcome is more ironic. The lack of 
special-cases means less pressure to have clear concept design, 
abstraction/boundaries between actions (modularity). So large code like 
Squid can become more complex than simple.

It is more work in total to design simple than complex/ad-hoc. 
Portability gives a clear justification for that design work, does not 
add/remove from the amount of it necessary to output simple code.


> - More clarity about our target use cases

That is a matter of features/protocols not portability.


> - better coverage in our testing for our explicit target use cases
> 

Agreed.

Amos

From squid3 at treenet.co.nz  Sun Dec  5 13:06:46 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 6 Dec 2021 02:06:46 +1300
Subject: [squid-dev] RFC: Categorize level-0/1 messages
In-Reply-To: <c917fc15-bd3e-429a-e059-9bb7d8db0b20@measurement-factory.com>
References: <200b6139-1941-cd30-7a49-b5262823094e@measurement-factory.com>
 <9497b99d-8a2e-3941-0c99-1606270bd2bc@treenet.co.nz>
 <c917fc15-bd3e-429a-e059-9bb7d8db0b20@measurement-factory.com>
Message-ID: <2df2236d-959f-4672-68a4-3807d4e2cfd1@treenet.co.nz>

On 21/10/21 16:16, Alex Rousskov wrote:
> On 10/20/21 3:14 PM, Amos Jeffries wrote:
>> On 21/10/21 4:22 am, Alex Rousskov wrote:
>>> To facilitate automatic monitoring of Squid cache.logs, I suggest to
>>> adjust Squid code to divide all level-0/1 messages into two major
>>> categories -- "problem messages" and "status messages"[0]:
> 
> 
>> We already have a published categorization design which (when/if used)
>> solves the problem(s) you are describing. Unfortunately that design has
>> not been followed by all authors and conversion of old code to it has
>> not been done.
> 
>> Please focus your project on making Squid actually use the system of
>> debugs line labels. The labels are documented at:
>>  ? https://wiki.squid-cache.org/SquidFaq/SquidLogs#Squid_Error_Messages
> 
> AFAICT, the partial classification in that wiki table is an opinion on
> how things could be designed, and that opinion does not reflect Project
> consensus.

The wiki was written from observation of how the message labels are/were 
being used in the code. As such it reflects the defacto consensus of 
everyone ever authoring code that used one of the labels.


NP: The "core team" or "dev team" are not "The Project". There are a 
large number of developers contributing to each version of Squid whose 
only voice in any of the style/design decisions is the existing Squid code.


> FWIW, I cannot use that wiki table for labeling messages, but
> I do not want to hijack this RFC thread for that table review.
> 

You our text below contradicts the "cannot" statement by describing how 
the two definitions fit together and offer to use the wiki table labels 
for problem category.

I assume the below text is your definition of "cannot"? if not them 
please explain why not.


> Fortunately, there are many similarities between the wiki table and this
> RFC that we can and should capitalize on instead:
> 
> * While the wiki table is silent about the majority of existing
> cache.log messages, most of the messages it is silent about probably
> belong to the "status messages" category proposed by this RFC.

Exactly so.

> This
> assumption gives a usable match between the wiki table and the RFC for
> about half of the existing level-0/1 cache.log messages. Great!
> 
> * The wiki table talks about FATAL, ERROR, and WARNING messages. These
> labels match the RFC "problem messages" category. This match covers all
> of the remaining cache.log messages except for 10 debugs() detailed
> below. Thus, so far, there is a usable match on nearly all current
> level-0/1 messages. Excellent!

Thus my request that you use the wiki definitions to categorize the 
unlabeled and fix any detected labeling mistakes.


> * The wiki table also uses three "SECURITY ..." labels. The RFC does not
> recognize those labels as special. I find their definitions in the wiki
> table unusable/impractical, and you naturally think otherwise, but the
> situation is not as bad as it may seem at the first glance:
> 
> - "SECURITY ERROR" is used once to report a coding _bug_. That single
> use case does not match the wiki table SECURITY ERROR description. We
> should be able to rephrase that single message so that does it not
> contradict the wiki table and the RFC.
> 
> - "SECURITY ALERT" is used 6 times. Most or all of those cases are a
> poor match for the SECURITY ALERT description in the wiki table IMHO. I
> hope we can find a way to rephrase those 6 cases to avoid conflicts.
> 
> - "SECURITY NOTICE" is used 3 times. Two of those use cases can be
> simply removed by removing the long-deprecated and increasingly poorly
> supported SslBump features. I do not see why we should keep the third
> message/feature, but if it must be kept, we may be able to rephrase it.
> 
> If we cannot reach an agreement regarding these 10 special messages, we
> can leave them as is for now, and come back to them when we find a way
> to agree on how/whether to assign additional labels to some messages.
> 

AFAICT, they were added as equivalent to ERROR/WARNING in CVE fixes, or 
to highlight a known security vulnerability being opened by admin settings.

I am okay with them remaining untouched by a PR submission cleaning 
level 0/1 messages. Though they are there to use if any author finds a 
message that suitably meets their definition.


> 
> Thus, there are no significant conflicts between the RFC and the table!
> We strongly disagree how labels should be defined,

Recall that the wiki is describing the observed pattern of label usage 
by all Squid contributors. That means any significant conflict is 
between your choice of definition and "The Project" as a whole. Minor 
conflicts may be just differences in my wording and yours on the 
observed pattern.


> but I do not think we
> have to agree on those details to make progress here.

The options for any author are to comply with the existing 
consensus/pattern or to get agreement on changing the definitions.

Options like changing the labeling scheme are off the table because we 
already have significant amounts of community using those labels with 
third-party tools etc. i.e. the "automatic monitoring" cited as target 
use-case for this proposal are already using the wiki labels as their 
category types.


> We only need to
> agree that (those 10 SECURITY messages aside) the RFC-driven message
> categorization projects should adjust (the easily adjustable) messages
> about Squid problems to use three standard labels: FATAL, ERROR, and
> WARNING. Can we do just that and set aside the other disagreements for
> another time?
> 

Agreed.


> If there are serious disagreements whether a specific debugs() is an
> ERROR or WARNING, we can leave those specific messages intact until we
> find a way to reach consensus. I hope there will be very few such
> messages if we use the three labels from the RFC and do our best to
> avoid controversial changes.
> 


You may have misunderstood the intention behind my request.

IMO you should not need a formal definition of "status message" and 
"problem message".

  All it needs to do is go straight to determine whether the message 
meets one of the wiki labels and apply it or the debugs to level2+. 
"status" vs "problem messages" are an emergent property of the correctly 
used labels.


> 
>> What we do not have in that design is clarity on which labels are shown
>> at what level.
> 
> In hope to make progress, I strongly suggest to _ignore_ the difference
> between level 0 and level 1 for now. We are just too far apart on that
> topic to reach consensus AFAICT. The vast majority of messages that
> RFC-driven projects should touch (and, if really needed, _all_ such
> messages!) can be left at their current level, avoiding this problem.
> 

Okay. IIRC there are a large number that will need to change verbosity, 
but fine to do that later.


Amos

From rousskov at measurement-factory.com  Sun Dec  5 17:43:39 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 5 Dec 2021 12:43:39 -0500
Subject: [squid-dev] RFC: Categorize level-0/1 messages
In-Reply-To: <2df2236d-959f-4672-68a4-3807d4e2cfd1@treenet.co.nz>
References: <200b6139-1941-cd30-7a49-b5262823094e@measurement-factory.com>
 <9497b99d-8a2e-3941-0c99-1606270bd2bc@treenet.co.nz>
 <c917fc15-bd3e-429a-e059-9bb7d8db0b20@measurement-factory.com>
 <2df2236d-959f-4672-68a4-3807d4e2cfd1@treenet.co.nz>
Message-ID: <d8b47c13-a095-0bd0-dbd3-7bfae931ccc3@measurement-factory.com>

On 12/5/21 8:06 AM, Amos Jeffries wrote:
> On 21/10/21 16:16, Alex Rousskov wrote:
>> On 10/20/21 3:14 PM, Amos Jeffries wrote:
>>> On 21/10/21 4:22 am, Alex Rousskov wrote:
>>>> To facilitate automatic monitoring of Squid cache.logs, I suggest to
>>>> adjust Squid code to divide all level-0/1 messages into two major
>>>> categories -- "problem messages" and "status messages"[0]:
>>
>>> We already have a published categorization design which (when/if used)
>>> solves the problem(s) you are describing. Unfortunately that design has
>>> not been followed by all authors and conversion of old code to it has
>>> not been done.
>>
>>> Please focus your project on making Squid actually use the system of
>>> debugs line labels. The labels are documented at:
>>> ?? https://wiki.squid-cache.org/SquidFaq/SquidLogs#Squid_Error_Messages
>>
>> AFAICT, the partial classification in that wiki table is an opinion on
>> how things could be designed, and that opinion does not reflect Project
>> consensus.

> The wiki was written from observation of how the message labels are/were
> being used in the code. As such it reflects the defacto consensus of
> everyone ever authoring code that used one of the labels.

[ N.B. I am worried that this (mostly irrelevant IMO) part of the
discussion risks ruining the shaky agreement we have reached on the
important parts of the RFC, but I am also worried about
misrepresentation of the wiki table status. I will respond here, but
please move any future discussion about that table status (if you decide
to continue them) to a different email thread. ]

AFAICT, the wiki table in question does not accurately reflect Squid
code and does not constitute Project consensus on how things could be
designed, regardless of what observations led to that table creation.
The creative process of writing a classification table (based on code
observations) naturally allows for misinterpretations, mistakes, and
other problems. One cannot claim consensus on the _result_ on the
grounds that they have started with code observations.


>> FWIW, I cannot use that wiki table for labeling messages, but
>> I do not want to hijack this RFC thread for that table review.

> You our text below contradicts the "cannot" statement by describing how
> the two definitions fit together and offer to use the wiki table labels
> for problem category.

I cannot use the wiki table for deciding how to label a given message
(because of the problems with the table definitions that I would rather
not review here), but the primary labels we use (and should continue to
use!) are naturally found in that table. There is no contradiction here.


>> * The wiki table talks about FATAL, ERROR, and WARNING messages. These
>> labels match the RFC "problem messages" category. This match covers all
>> of the remaining cache.log messages except for 10 debugs() detailed
>> below. Thus, so far, there is a usable match on nearly all current
>> level-0/1 messages. Excellent!

> Thus my request that you use the wiki definitions to categorize the
> unlabeled and fix any detected labeling mistakes.

While I cannot use those wiki definitions (because of the problems with
the table that I would rather not review here), it is not a big deal as
far as this RFC is concerned because I do not have to use or violate
those definitions to implement the vast majority of the proposed changes
-- those changes are orthogonal to the wiki table and its definitions.

If somebody finds a table violation introduced by the RFC PR, then we
will either undo the corresponding PR change, change the label used by
the PR, or fix the table, but my goal is to minimize the number of such
cases because they are likely to waste a lot of time on difficult
discussions about poorly defined concepts.



>> * The wiki table also uses three "SECURITY ..." labels. The RFC does not
>> recognize those labels as special. I find their definitions in the wiki
>> table unusable/impractical, and you naturally think otherwise, but the
>> situation is not as bad as it may seem at the first glance:
>>
>> - "SECURITY ERROR" is used once to report a coding _bug_. That single
>> use case does not match the wiki table SECURITY ERROR description. We
>> should be able to rephrase that single message so that does it not
>> contradict the wiki table and the RFC.
>>
>> - "SECURITY ALERT" is used 6 times. Most or all of those cases are a
>> poor match for the SECURITY ALERT description in the wiki table IMHO. I
>> hope we can find a way to rephrase those 6 cases to avoid conflicts.
>>
>> - "SECURITY NOTICE" is used 3 times. Two of those use cases can be
>> simply removed by removing the long-deprecated and increasingly poorly
>> supported SslBump features. I do not see why we should keep the third
>> message/feature, but if it must be kept, we may be able to rephrase it.
>>
>> If we cannot reach an agreement regarding these 10 special messages, we
>> can leave them as is for now, and come back to them when we find a way
>> to agree on how/whether to assign additional labels to some messages.

> AFAICT, they were added as equivalent to ERROR/WARNING in CVE fixes,

Sorry, I do not understand the relationship between a CVE fix (i.e. a
code change) and a debugs() label that you are referring to above.
Clearly, CVE fixes may or may not alter or add debugs() statements, but
those statements very rarely get (or should get) a special label. I hope
this detail is not important for the RFC though.


> or to highlight a known security vulnerability being opened by admin settings.

We can and, IMO, should highlight those while still using just three
top-level labels.


>> Thus, there are no significant conflicts between the RFC and the table!
>> We strongly disagree how labels should be defined,

> Recall that the wiki is describing the observed pattern of label usage
> by all Squid contributors.

IMO, it does not.


> The options for any author are to comply with the existing
> consensus/pattern or to get agreement on changing the definitions.

Yes, of course. We only disagree on whether the wiki table represents
any existing agreement/consensus or Project definitions, but, again, I
hope we can avoid fighting about that as far as this RFC is concerned.


> Options like changing the labeling scheme are off the table because we
> already have significant amounts of community using those labels with
> third-party tools etc. i.e. the "automatic monitoring" cited as target
> use-case for this proposal are already using the wiki labels as their
> category types.

There is pretty much no official labeling scheme right now, so this RFC
does not _change_ it. The RFC proposes parts of such a scheme for future
use.

The RFC is compatible with what the community is doing/using already and
greatly reduces long-term admin overheads. Any "we cannot change
anything because admins are using these labels" assertion is false
because it is _admins_ that rightfully complain about existing labeling
(and lack of thereof) and ask for these changes! Admins really want us
to change/improve things in this area. I would not post this RFC otherwise.


>> We only need to
>> agree that (those 10 SECURITY messages aside) the RFC-driven message
>> categorization projects should adjust (the easily adjustable) messages
>> about Squid problems to use three standard labels: FATAL, ERROR, and
>> WARNING. Can we do just that and set aside the other disagreements for
>> another time?

> Agreed.

Great! I will proceed with that agreement in mind.


> IMO you should not need a formal definition of "status message" and
> "problem message".

Hm... Perhaps there is a misunderstanding of how "problem messages" and
"status messages" categories are defined in the RFC.

For obvious convenience in discussions, documentation, and code, we need
a term that describes

* level-0/1 messages with such well-known prefixes as WARNING:, ERROR:,
and FATAL:.

The RFC calls these messages "problem messages".

All other level-0/1 messages are called "status messages":

* level-0/1 messages without well-known prefixes

That is it! These "definitions" are so
factual/trivial/pragmatic/convenient that (the choice of the words
"problem" and "status" aside) we should not be arguing about (the need
for) them IMO! If you think these categories are not needed, you do not
need to use them, of course, but I see no reason to argue about it. They
contradict/prevent/block nothing.


> All it needs to do is go straight to determine whether the message
> meets one of the wiki labels and apply it or the debugs to level2+.
> "status" vs "problem messages" are an emergent property of the correctly
> used labels.

Lots of of existing level-0/1 messages satisfy both of these conditions:

a) They are not ERRORs/WARNINGs/FATALs/SECURITY*s by _any_ definition.
b) They should be logged at level 0 or 1.

In RFC terminology, these are "status messages", but you do not have to
call them that. If you are suggesting that their debugs() level should
be changed to 2+, then I disagree because they are useful for
understanding Squid state and triaging basic problems at the _default_
debugging level. Perhaps you are suggesting something else with regard
to the status messages?


> IIRC there are a large number that will need to change verbosity,
> but fine to do that later.

Agreed on all counts.


Thank you,

Alex.

From rousskov at measurement-factory.com  Sun Dec  5 18:20:53 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 5 Dec 2021 13:20:53 -0500
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <abc50ecc-b54d-db33-a0bc-8cceafb2c8d9@treenet.co.nz>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
 <abc50ecc-b54d-db33-a0bc-8cceafb2c8d9@treenet.co.nz>
Message-ID: <02dbcaca-bbf7-89be-c2b9-d51d37d3fb2d@measurement-factory.com>

On 12/5/21 7:00 AM, Amos Jeffries wrote:
> On 5/12/21 22:44, Francesco Chemolli wrote:
>> The rationale is that we should focus our attention as a project where
>> the majority of our userbase is, where users mean "people who build
>> and run squid".

> I do not accept that a few hacks for old OS are causing pain to core
> developers simply by bitrotting in untouched code.

Squid code that should be removed (from any reasonable person point of
view) may cause significant pain. I (and, I bet, others) have wasted a
lot of time dealing with such code. Old OSes and platforms are not be
the _biggest_ contributor here, but they are a contributor, and I hope
that this thread will result in a scheme that is applicable to a much
wider set of code snippets than those OS hacks alone.


> Removing things because the majority of users are not using it would
> mean we become a Linux-only project and thus actively push people out of
> the community unnecessarily. There are active benefits gained in the
> form of better code, bug detection, and community inclusiveness from
> maintaining portable code.

Nobody questions the real benefits of supporting non-Linux platforms
AFAICT. The questions usually revolve around the benefits of a given
OS-specific code snippet -- do they outweigh the drawbacks associated
with it? It is impossible to correctly answer such questions in general,
especially in the context of a starving Project. We may have to paint
with a much broader pragmatic brush to arrive at imperfect but
reusable/generic solutions that we can afford.


> IMO specific machine architectures are not much concern to "us". The
> toolchains and vendors take care of that part so long as we provide
> half-decent code.

I would go one step further and claim that any OS-specific Squid code
that exists to accomodate OS Foo idiosyncrasies is the responsibility of
the folks working on OS Foo-based distributions. It should not be the
responsibility of the Squid project. Ideally, we should not have such
code in Squid. This is what distro patches/adjustments are for.

Alex.

From rousskov at measurement-factory.com  Sun Dec  5 21:05:40 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 5 Dec 2021 16:05:40 -0500
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
Message-ID: <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>

On 12/5/21 4:44 AM, Francesco Chemolli wrote:

> I would recommend that we support as main targets:
> - Linux on x64, arm64, arm32 and, if we can, MIPS
> - FreeBSD, OpenBSD on x64

> As best-effort:
> - Windows on x64, with the aim of eventually promoting to primary target
> - Darwin on x64 and maybe eventually arm64
> - NetBSD on x64

What does "support as main targets" and "support as best-effort" mean?

Without defining/detailing these two terms, it is impossible to properly
evaluate this proposal IMO...


> If anyone in the community wants to support/maintain extra OSes or
> architectures, they're very welcome to do so

By "welcome", do you mean something like "we will accept high-quality
PRs adding such extra support to Squid"? Or "we will consider sharing
references to your work, but please do not ask us to merge your
OS-specific changes into the official Squid code"? Something else? This
bit is critical for understanding the real effect of this proposal IMO.

----

If we manage to and agree on what platforms to "support" and on removing
code dedicated to unsupported platforms, great! If we fail, I would like
to propose an alternative scheme for the removal of platform-specific
(or any other) code from the official master branch:

A PR dedicated to code removal can be merged if it satisfies the
following criteria:

1. Two positive votes from core developers.
2. No negative votes.
3. Voting lasted for 30+ calendar days.
4. The removal PR is announced in a PR-dedicated squid-users post.
   This announcement resets the 30+ day timer.

The author and reviewers do not have to justify the removal and the
votes if the PR author elects to use this special code removal
procedure. We simply trust they have good reasons to remove, support
removal, or block it.

A PR that does not satisfy the above criteria may still be merged under
the existing/regular PR merging rules. This special procedure does not
change those primary rules. It simply grants us the ability to avoid
difficult justifications and associated policy discussions in exchange
for longer wait times and more votes/exposure, under the assumption that
when it comes to simple removal, we just want to avoid (to the extent
possible) removing something that is still in significant use.

I am not sure we need rule #4, but it is not very difficult to post a
GitHub link and a PR description to squid-users, so the extra protection
that rule offers may be worth the posting overheads.

I am OK with increasing the 30 day waiting period if others think we
should wait longer for possible objections.


Thank you,

Alex.

From a-squid at mikus.sk  Sun Dec  5 23:11:35 2021
From: a-squid at mikus.sk (Andrej Mikus)
Date: Mon, 6 Dec 2021 00:11:35 +0100
Subject: [squid-dev] Squid does not accept WCCP of Cisco router since CVE
 2021-28116
Message-ID: <20211205231135.GE500194@mikus.sk>

Hi,

I would like to find some information about wccp servers (routers,
firewalls, etc) that are officially supported and therefore tested for
compatibility. I thought there would be this kind of page published in
squid wiki but failed to locate one.

Since the recent update squid does not accept wccp packets sent by Cisco
IOS 15.8(3)M2 claiming there is duplicate security definition.

Is there any way to get in touch with the developper responsible for the
security patch and request his comments? I do not have access to other
Cisco hardware, and I would like to know if the update was confirmed
working for example against a CSR1000v.

I have first reported the issue to Ubuntu since I am running 18.04, but
today confirmed that recent versions of squid fail as well. Prior
creating a new entry at https://bugs.squid-cache.org/ I would appreciate
your guidance.

Regards
Andrej Mikus


----- Forwarded message from amk <1952158 at bugs.launchpad.net> -----

Date: Sun, 05 Dec 2021 22:21:51 -0000
From: amk <1952158 at bugs.launchpad.net>
To: launchpad at mikus.sk
Subject: [Bug 1952158] Re: squid does not accept WCCP of Cisco router since 3.5.27-1ubuntu1.12

4.13-10ubuntu5 in 21.10 and 5.2-1ubuntu1 in jammy are failing as well,
with debug log different when compared to version 3 involved here:

2021/12/05 19:58:41.705 kid1| 80,6| wccp2.cc(1580) wccp2HereIam: wccp2HereIam: Called
2021/12/05 19:58:41.705 kid1| 80,5| wccp2.cc(1599) wccp2HereIam: wccp2HereIam: sending to service id 0
2021/12/05 19:58:41.705 kid1| 80,3| wccp2.cc(1630) wccp2HereIam: Sending HereIam packet size 144
2021/12/05 19:58:41.707 kid1| 80,6| wccp2.cc(1202) wccp2HandleUdp: wccp2HandleUdp: Called.
2021/12/05 19:58:41.707 kid1| 80,3| wccp2.cc(1226) wccp2HandleUdp: Incoming WCCPv2 I_SEE_YOU length 128.
2021/12/05 19:58:41.707 kid1| ERROR: Ignoring WCCPv2 message: duplicate security definition
    exception location: wccp2.cc(1249) wccp2HandleUdp

This looks like a problem with squid itself, the packet does not have
duplicate security definition. In the code at http://www.squid-
cache.org/Doc/code/wccp2_8cc_source.html I miss some debug output in the
loop processing the packet /* Go through the data structure */ so would
need to rebuild the package or to involve debugger.

I was not able to find any documentation of squid listing
supported/tested wccp servers but at this point this looks like an issue
to be reported upstream. There is no reason to consider wccp packets
from IOS 15.8(3)M2 invalid.

-- 
You received this bug notification because you are subscribed to the bug
report.
https://bugs.launchpad.net/bugs/1952158


Bug description:
  WCCP peering between squid and CIsco IOS 15.8(3)M2 stopped as of

  Start-Date: 2021-10-07  06:27:37
  Commandline: /usr/bin/unattended-upgrade
  Upgrade: squid-common:amd64 (3.5.27-1ubuntu1.11, 3.5.27-1ubuntu1.12)

  1) The release of Ubuntu you are using: 18.04
  2) The version of the package you are using: 3.5.27-1ubuntu1.12
  3) What you expected to happen:

  Unattended upgrade will not break working setup. Valid wccp packets
  from the router continue to get accepted and processed by squid.

  4) What happened instead

  The squid cache.log is logging a loop of ERROR messages:

  ERROR: Ignoring WCCPv2 message: ntohl(wccp2_i_see_you.type) == WCCP2_I_SEE_YOU
  ERROR: Ignoring WCCPv2 message: !security_info
  ERROR: Ignoring WCCPv2 message: !security_info
  ERROR: Ignoring WCCPv2 message: !security_info

  Router logged Oct  7 04:28:45.918: %WCCP-1-SERVICELOST: Service web-cache lost on WCCP client x.x.x.x
  Since then debug wccp logs periodically WCCP-EVNT:IPv4:S0: HIA from x.x.x.x with bad rcv_id 0 (expected yy)

  wccp service detail shows: WCCP Client information: State: NOT Usable
  (initializing)

----- End forwarded message -----

From rousskov at measurement-factory.com  Mon Dec  6 20:34:58 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 6 Dec 2021 15:34:58 -0500
Subject: [squid-dev] Squid does not accept WCCP of Cisco router since
 CVE 2021-28116
In-Reply-To: <20211205231135.GE500194@mikus.sk>
References: <20211205231135.GE500194@mikus.sk>
Message-ID: <7cd07c6b-18d4-23f1-5c96-8b907b304660@measurement-factory.com>

On 12/5/21 6:11 PM, Andrej Mikus wrote:

> I would like to find some information about wccp servers (routers,
> firewalls, etc) that are officially supported and therefore tested for
> compatibility.

IIRC, there are no such servers/etc. WCCP code quality is low, the code
has been neglected for a long time, and the changes we recently had to
do for CVE 2021-28116 took a very long time, were unfinished and
essentially untested because, in part, those looking for testers could
not get anybody to test the changes and report the results back to us.


> Is there any way to get in touch with the developper responsible for the
> security patch and request his comments?

You are using the right channel for that. I was one of the developers
that were forced to work on code changes for CVE 2021-28116, but I am
not sure I would consider myself "responsible for the patch" (it depends
on your definition of "responsible"). The advisory says the bug was
fixed by Amos; Amos is on this mailing list.


> I do not have access to other
> Cisco hardware, and I would like to know if the update was confirmed
> working for example against a CSR1000v.

I do not think that update was confirmed as working against any WCCP
server. If you are using WCCP, you are relying on a long-neglected
feature. There is no proper support for WCCP code in Squid today IMO.


Alex.
P.S. Squid side of CVE 2021-28116 is at
https://github.com/squid-cache/squid/security/advisories/GHSA-rgf3-9v3p-qp82



> ----- Forwarded message from amk <1952158 at bugs.launchpad.net> -----
> 
> Date: Sun, 05 Dec 2021 22:21:51 -0000
> From: amk <1952158 at bugs.launchpad.net>
> To: launchpad at mikus.sk
> Subject: [Bug 1952158] Re: squid does not accept WCCP of Cisco router since 3.5.27-1ubuntu1.12
> 
> 4.13-10ubuntu5 in 21.10 and 5.2-1ubuntu1 in jammy are failing as well,
> with debug log different when compared to version 3 involved here:
> 
> 2021/12/05 19:58:41.705 kid1| 80,6| wccp2.cc(1580) wccp2HereIam: wccp2HereIam: Called
> 2021/12/05 19:58:41.705 kid1| 80,5| wccp2.cc(1599) wccp2HereIam: wccp2HereIam: sending to service id 0
> 2021/12/05 19:58:41.705 kid1| 80,3| wccp2.cc(1630) wccp2HereIam: Sending HereIam packet size 144
> 2021/12/05 19:58:41.707 kid1| 80,6| wccp2.cc(1202) wccp2HandleUdp: wccp2HandleUdp: Called.
> 2021/12/05 19:58:41.707 kid1| 80,3| wccp2.cc(1226) wccp2HandleUdp: Incoming WCCPv2 I_SEE_YOU length 128.
> 2021/12/05 19:58:41.707 kid1| ERROR: Ignoring WCCPv2 message: duplicate security definition
>     exception location: wccp2.cc(1249) wccp2HandleUdp
> 
> This looks like a problem with squid itself, the packet does not have
> duplicate security definition. In the code at http://www.squid-
> cache.org/Doc/code/wccp2_8cc_source.html I miss some debug output in the
> loop processing the packet /* Go through the data structure */ so would
> need to rebuild the package or to involve debugger.
> 
> I was not able to find any documentation of squid listing
> supported/tested wccp servers but at this point this looks like an issue
> to be reported upstream. There is no reason to consider wccp packets
> from IOS 15.8(3)M2 invalid.
> 


From squid3 at treenet.co.nz  Tue Dec  7 01:37:09 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Dec 2021 14:37:09 +1300
Subject: [squid-dev] Squid does not accept WCCP of Cisco router since
 CVE 2021-28116
In-Reply-To: <20211205231135.GE500194@mikus.sk>
References: <20211205231135.GE500194@mikus.sk>
Message-ID: <d8e1b104-2ffe-c203-d423-31fd38830604@treenet.co.nz>

On 6/12/21 12:11, Andrej Mikus wrote:
> Hi,
> 
> I would like to find some information about wccp servers (routers,
> firewalls, etc) that are officially supported and therefore tested for
> compatibility. I thought there would be this kind of page published in
> squid wiki but failed to locate one.
> 
> Since the recent update squid does not accept wccp packets sent by Cisco
> IOS 15.8(3)M2 claiming there is duplicate security definition.
> 
> Is there any way to get in touch with the developper responsible for the
> security patch and request his comments? I do not have access to other
> Cisco hardware, and I would like to know if the update was confirmed
> working for example against a CSR1000v.
> 
> I have first reported the issue to Ubuntu since I am running 18.04, but
> today confirmed that recent versions of squid fail as well. Prior
> creating a new entry at https://bugs.squid-cache.org/ I would appreciate
> your guidance.
> 
> Regards
> Andrej Mikus
> 

Hi Andrej,

  Alex has summarized the state of things pretty accurately. Since CVE 
is already public please feel free to open a bug report on our Bugzilla. 
That will help with getting the fix backported to official releases.

If you are able to do the testing I am happy to try and fix it for you.

Amos

From a-squid at mikus.sk  Tue Dec  7 23:25:04 2021
From: a-squid at mikus.sk (Andrej Mikus)
Date: Wed, 8 Dec 2021 00:25:04 +0100
Subject: [squid-dev] Squid does not accept WCCP of Cisco router since
 CVE 2021-28116
In-Reply-To: <d8e1b104-2ffe-c203-d423-31fd38830604@treenet.co.nz>
 <7cd07c6b-18d4-23f1-5c96-8b907b304660@measurement-factory.com>
Message-ID: <20211207232504.GI500194@mikus.sk>

Hi,

It is sad to hear that the code was released without confirmed test, and the
lack of a feedback it can mean that I am apparently a single user of the
component.

In this situation it would be perhaps feasible to abandon it entirely instead
of maintaining a neglected feature? At the other hand I can imagine that the
test suite could boot a virtual router and to try peering with it.

By adding a single debug line I was able to confirm an issue in the function
CheckFieldDataLength. It is using sizeof(header) while header is a pointer,
with no relevance to the wccp packet. This is my diff:


diff --git a/src/wccp2.cc b/src/wccp2.cc
index a0629b2b7..c63245f6b 100644
--- a/src/wccp2.cc
+++ b/src/wccp2.cc
@@ -1142,9 +1142,9 @@ static size_t
 CheckFieldDataLength(const FieldHeader *header, const size_t dataLength, const void *areaStart, const size_t areaSize, const char *error)
 {
     assert(header);
-    const auto dataStart = reinterpret_cast<const char*>(header) + sizeof(header);
+    const auto dataStart = reinterpret_cast<const char*>(header) + sizeof(FieldHeader);
     CheckSectionLength(dataStart, dataLength, areaStart, areaSize, error);
-    return sizeof(header) + dataLength; // no overflow after CheckSectionLength()
+    return sizeof(FieldHeader) + dataLength; // no overflow after CheckSectionLength()
 }
 
 /// Positions the given field at a given start within a given packet area.
@@ -1245,6 +1245,7 @@ wccp2HandleUdp(int sock, void *)
         const auto itemHeader = reinterpret_cast<const wccp2_item_header_t*>(&data[offset]);
         const auto itemSize = CheckFieldDataLength(itemHeader, ntohs(itemHeader->length),
                               data, data_length, "truncated record");
+       debugs(80, 7, "Offset: " << offset << " Item type: " << ntohs(itemHeader->type) << " size: " << itemSize << ".");
         // XXX: Check "The specified length must be a multiple of 4 octets"
         // requirement to avoid unaligned memory reads after the first item.


It moved me a bit further, router returned the cache in its view, but there is
likely a similar issue in parsing of capability element:


2021/12/08 00:06:18.686| Initialising all WCCPv2 lists
2021/12/08 00:06:19.687| 80,6| wccp2.cc(1586) wccp2HereIam: wccp2HereIam: Called
2021/12/08 00:06:19.687| 80,5| wccp2.cc(1605) wccp2HereIam: wccp2HereIam: sending to service id 0
2021/12/08 00:06:19.687| 80,3| wccp2.cc(1636) wccp2HereIam: Sending HereIam packet size 144
2021/12/08 00:06:19.689| 80,6| wccp2.cc(1207) wccp2HandleUdp: wccp2HandleUdp: Called.
2021/12/08 00:06:19.690| 80,3| wccp2.cc(1231) wccp2HandleUdp: Incoming WCCPv2 I_SEE_YOU length 176.
2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 0 Item type: 0 size: 8.
2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 8 Item type: 1 size: 28.
2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 36 Item type: 2 size: 24.
2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 60 Item type: 4 size: 72.
2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 132 Item type: 8 size: 44.
2021/12/08 00:06:19.690| 80,5| wccp2.cc(1309) wccp2HandleUdp: Complete packet received
2021/12/08 00:06:19.690| 80,3| wccp2.cc(1350) wccp2HandleUdp: Incoming WCCP2_I_SEE_YOU Received ID old=0 new=112418.
2021/12/08 00:06:19.690| Unknown capability type in WCCPv2 Packet (0).
2021/12/08 00:06:19.690| ERROR: Ignoring WCCPv2 message: capability element truncated
    exception location: wccp2.cc(1134) CheckSectionLength
2021/12/08 00:06:29.688| 80,6| wccp2.cc(1586) wccp2HereIam: wccp2HereIam: Called
2021/12/08 00:06:29.688| 80,5| wccp2.cc(1605) wccp2HereIam: wccp2HereIam: sending to service id 0
2021/12/08 00:06:29.688| 80,3| wccp2.cc(1636) wccp2HereIam: Sending HereIam packet size 144
2021/12/08 00:06:29.691| 80,6| wccp2.cc(1207) wccp2HandleUdp: wccp2HandleUdp: Called.
2021/12/08 00:06:29.691| 80,3| wccp2.cc(1231) wccp2HandleUdp: Incoming WCCPv2 I_SEE_YOU length 220.
2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 0 Item type: 0 size: 8.
2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 8 Item type: 1 size: 28.
2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 36 Item type: 2 size: 24.
2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 60 Item type: 4 size: 116.
2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 176 Item type: 8 size: 44.
2021/12/08 00:06:29.691| 80,5| wccp2.cc(1309) wccp2HandleUdp: Complete packet received
2021/12/08 00:06:29.691| 80,3| wccp2.cc(1350) wccp2HandleUdp: Incoming WCCP2_I_SEE_YOU Received ID old=112418 new=112420.
2021/12/08 00:06:29.691| Unknown capability type in WCCPv2 Packet (0).
2021/12/08 00:06:29.691| ERROR: Ignoring WCCPv2 message: capability element truncated
    exception location: wccp2.cc(1134) CheckSectionLength


Will have to leave it for you, or to continue another time...
Opened bug at https://bugs.squid-cache.org/show_bug.cgi?id=5179

Regards
Andrej Mikus



On Mon, 06.Dec.21 15:34:58 -0500, Alex Rousskov wrote:
> 
> > I do not have access to other
> > Cisco hardware, and I would like to know if the update was confirmed
> > working for example against a CSR1000v.
> 
> I do not think that update was confirmed as working against any WCCP
> server. If you are using WCCP, you are relying on a long-neglected
> feature. There is no proper support for WCCP code in Squid today IMO.
> 
> 
> Alex.
> P.S. Squid side of CVE 2021-28116 is at
> https://github.com/squid-cache/squid/security/advisories/GHSA-rgf3-9v3p-qp82
> 

On Tue, 07.Dec.21 14:37:09 +1300, Amos Jeffries wrote:
> 
> Hi Andrej,
> 
>  Alex has summarized the state of things pretty accurately. Since CVE is
> already public please feel free to open a bug report on our Bugzilla. That
> will help with getting the fix backported to official releases.
> 
> If you are able to do the testing I am happy to try and fix it for you.
> 
> Amos


From a-squid at mikus.sk  Mon Dec 20 04:06:20 2021
From: a-squid at mikus.sk (Andrej Mikus)
Date: Mon, 20 Dec 2021 05:06:20 +0100
Subject: [squid-dev] Squid does not accept WCCP of Cisco router since
 CVE 2021-28116
In-Reply-To: <20211207232504.GI500194@mikus.sk>
References: <d8e1b104-2ffe-c203-d423-31fd38830604@treenet.co.nz>
 <7cd07c6b-18d4-23f1-5c96-8b907b304660@measurement-factory.com>
 <20211207232504.GI500194@mikus.sk>
Message-ID: <20211220040620.GA557699@mikus.sk>

Hi team,

I spent some time playing with the code and made the wccp part
operational again, to the extent it was working before.

Checking the code I can see many possible improvements, from
configurable mask parameters, up to implementing variable timers or
preserving connections when caches are added into farm.

I could eventually invest effort into this part, but considering the
situation you explained before, there is likely no perspective user
base.

The changes are submitted as PR
https://github.com/squid-cache/squid/pull/953

I have tested standard service in hash and mask modes as well as
a dynamic service, in a combo of one cache and one router.

Regards
Andrej

On Wed, 08.Dec.21 00:25:04 +0100, Andrej Mikus wrote:
> Hi,
> 
> It is sad to hear that the code was released without confirmed test, and the
> lack of a feedback it can mean that I am apparently a single user of the
> component.
> 
> In this situation it would be perhaps feasible to abandon it entirely instead
> of maintaining a neglected feature? At the other hand I can imagine that the
> test suite could boot a virtual router and to try peering with it.
> 
> By adding a single debug line I was able to confirm an issue in the function
> CheckFieldDataLength. It is using sizeof(header) while header is a pointer,
> with no relevance to the wccp packet. This is my diff:
> 
> 
> diff --git a/src/wccp2.cc b/src/wccp2.cc
> index a0629b2b7..c63245f6b 100644
> --- a/src/wccp2.cc
> +++ b/src/wccp2.cc
> @@ -1142,9 +1142,9 @@ static size_t
>  CheckFieldDataLength(const FieldHeader *header, const size_t dataLength, const void *areaStart, const size_t areaSize, const char *error)
>  {
>      assert(header);
> -    const auto dataStart = reinterpret_cast<const char*>(header) + sizeof(header);
> +    const auto dataStart = reinterpret_cast<const char*>(header) + sizeof(FieldHeader);
>      CheckSectionLength(dataStart, dataLength, areaStart, areaSize, error);
> -    return sizeof(header) + dataLength; // no overflow after CheckSectionLength()
> +    return sizeof(FieldHeader) + dataLength; // no overflow after CheckSectionLength()
>  }
>  
>  /// Positions the given field at a given start within a given packet area.
> @@ -1245,6 +1245,7 @@ wccp2HandleUdp(int sock, void *)
>          const auto itemHeader = reinterpret_cast<const wccp2_item_header_t*>(&data[offset]);
>          const auto itemSize = CheckFieldDataLength(itemHeader, ntohs(itemHeader->length),
>                                data, data_length, "truncated record");
> +       debugs(80, 7, "Offset: " << offset << " Item type: " << ntohs(itemHeader->type) << " size: " << itemSize << ".");
>          // XXX: Check "The specified length must be a multiple of 4 octets"
>          // requirement to avoid unaligned memory reads after the first item.
> 
> 
> It moved me a bit further, router returned the cache in its view, but there is
> likely a similar issue in parsing of capability element:
> 
> 
> 2021/12/08 00:06:18.686| Initialising all WCCPv2 lists
> 2021/12/08 00:06:19.687| 80,6| wccp2.cc(1586) wccp2HereIam: wccp2HereIam: Called
> 2021/12/08 00:06:19.687| 80,5| wccp2.cc(1605) wccp2HereIam: wccp2HereIam: sending to service id 0
> 2021/12/08 00:06:19.687| 80,3| wccp2.cc(1636) wccp2HereIam: Sending HereIam packet size 144
> 2021/12/08 00:06:19.689| 80,6| wccp2.cc(1207) wccp2HandleUdp: wccp2HandleUdp: Called.
> 2021/12/08 00:06:19.690| 80,3| wccp2.cc(1231) wccp2HandleUdp: Incoming WCCPv2 I_SEE_YOU length 176.
> 2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 0 Item type: 0 size: 8.
> 2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 8 Item type: 1 size: 28.
> 2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 36 Item type: 2 size: 24.
> 2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 60 Item type: 4 size: 72.
> 2021/12/08 00:06:19.690| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 132 Item type: 8 size: 44.
> 2021/12/08 00:06:19.690| 80,5| wccp2.cc(1309) wccp2HandleUdp: Complete packet received
> 2021/12/08 00:06:19.690| 80,3| wccp2.cc(1350) wccp2HandleUdp: Incoming WCCP2_I_SEE_YOU Received ID old=0 new=112418.
> 2021/12/08 00:06:19.690| Unknown capability type in WCCPv2 Packet (0).
> 2021/12/08 00:06:19.690| ERROR: Ignoring WCCPv2 message: capability element truncated
>     exception location: wccp2.cc(1134) CheckSectionLength
> 2021/12/08 00:06:29.688| 80,6| wccp2.cc(1586) wccp2HereIam: wccp2HereIam: Called
> 2021/12/08 00:06:29.688| 80,5| wccp2.cc(1605) wccp2HereIam: wccp2HereIam: sending to service id 0
> 2021/12/08 00:06:29.688| 80,3| wccp2.cc(1636) wccp2HereIam: Sending HereIam packet size 144
> 2021/12/08 00:06:29.691| 80,6| wccp2.cc(1207) wccp2HandleUdp: wccp2HandleUdp: Called.
> 2021/12/08 00:06:29.691| 80,3| wccp2.cc(1231) wccp2HandleUdp: Incoming WCCPv2 I_SEE_YOU length 220.
> 2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 0 Item type: 0 size: 8.
> 2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 8 Item type: 1 size: 28.
> 2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 36 Item type: 2 size: 24.
> 2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 60 Item type: 4 size: 116.
> 2021/12/08 00:06:29.691| 80,7| wccp2.cc(1248) wccp2HandleUdp: Offset: 176 Item type: 8 size: 44.
> 2021/12/08 00:06:29.691| 80,5| wccp2.cc(1309) wccp2HandleUdp: Complete packet received
> 2021/12/08 00:06:29.691| 80,3| wccp2.cc(1350) wccp2HandleUdp: Incoming WCCP2_I_SEE_YOU Received ID old=112418 new=112420.
> 2021/12/08 00:06:29.691| Unknown capability type in WCCPv2 Packet (0).
> 2021/12/08 00:06:29.691| ERROR: Ignoring WCCPv2 message: capability element truncated
>     exception location: wccp2.cc(1134) CheckSectionLength
> 
> 
> Will have to leave it for you, or to continue another time...
> Opened bug at https://bugs.squid-cache.org/show_bug.cgi?id=5179
> 
> Regards
> Andrej Mikus
> 
> 
> 
> On Mon, 06.Dec.21 15:34:58 -0500, Alex Rousskov wrote:
> > 
> > > I do not have access to other
> > > Cisco hardware, and I would like to know if the update was confirmed
> > > working for example against a CSR1000v.
> > 
> > I do not think that update was confirmed as working against any WCCP
> > server. If you are using WCCP, you are relying on a long-neglected
> > feature. There is no proper support for WCCP code in Squid today IMO.
> > 
> > 
> > Alex.
> > P.S. Squid side of CVE 2021-28116 is at
> > https://github.com/squid-cache/squid/security/advisories/GHSA-rgf3-9v3p-qp82
> > 
> 
> On Tue, 07.Dec.21 14:37:09 +1300, Amos Jeffries wrote:
> > 
> > Hi Andrej,
> > 
> >  Alex has summarized the state of things pretty accurately. Since CVE is
> > already public please feel free to open a bug report on our Bugzilla. That
> > will help with getting the fix backported to official releases.
> > 
> > If you are able to do the testing I am happy to try and fix it for you.
> > 
> > Amos
> 

From gkinkie at gmail.com  Sun Dec 26 15:30:27 2021
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Sun, 26 Dec 2021 16:30:27 +0100
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
 <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>
Message-ID: <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>

On Sun, Dec 5, 2021 at 10:05 PM Alex Rousskov
<rousskov at measurement-factory.com> wrote:
>
> On 12/5/21 4:44 AM, Francesco Chemolli wrote:
>
> > I would recommend that we support as main targets:
> > - Linux on x64, arm64, arm32 and, if we can, MIPS
> > - FreeBSD, OpenBSD on x64
>
> > As best-effort:
> > - Windows on x64, with the aim of eventually promoting to primary target
> > - Darwin on x64 and maybe eventually arm64
> > - NetBSD on x64
>
> What does "support as main targets" and "support as best-effort" mean?
>
> Without defining/detailing these two terms, it is impossible to properly
> evaluate this proposal IMO...

That's a very fair point.
"main targets" to me means that any regression in build or unit tests
on these platforms is PR-blocking. We aim to deliver a working build
out of the box on these environments, with no need of maintainer
patches. Once achieved this status on any of these platforms,
regressions on it are release blockers.
"support as best effort" means that we keep these environment as build
options, and test builds on them. Regressions on build or unit tests
on these environments are not PR-blocking but we strongly encourage
the PR owner to fix these platforms with followup PRs. We aim to
deliver an out-of-the-box build on these platforms but failure to do
so or regressions are not a release blocker


> > If anyone in the community wants to support/maintain extra OSes or
> > architectures, they're very welcome to do so
>
> By "welcome", do you mean something like "we will accept high-quality
> PRs adding such extra support to Squid"? Or "we will consider sharing
> references to your work, but please do not ask us to merge your
> OS-specific changes into the official Squid code"? Something else? This
> bit is critical for understanding the real effect of this proposal IMO.

Fair point. I'd go for the former. If someone has an environment they
want to support and do so without adding complexity to the code base,
it's a good policy to enable that. The question is "how much
complexity is it healthy to impose on other platforms to support
niche/obsolete ones?"
While setting an objective bar is hard to impossible, this is my
attempt to set one for the most active group of developers

> If we manage to and agree on what platforms to "support" and on removing
> code dedicated to unsupported platforms, great! If we fail, I would like
> to propose an alternative scheme for the removal of platform-specific
> (or any other) code from the official master branch:
>
> A PR dedicated to code removal can be merged if it satisfies the
> following criteria:
>
> 1. Two positive votes from core developers.
> 2. No negative votes.
> 3. Voting lasted for 30+ calendar days.
> 4. The removal PR is announced in a PR-dedicated squid-users post.
>    This announcement resets the 30+ day timer.

How about instead something along the lines of:
1. announce on squid-users about intent to remove support for a platform
2. wait for objections for 15 days
3. PR following standard merge procedure

> The author and reviewers do not have to justify the removal and the
> votes if the PR author elects to use this special code removal
> procedure. We simply trust they have good reasons to remove, support
> removal, or block it.

My proposal doesn't change the merge process at all, it mostly gives
any active users in the candidate for removal a chance to speak up. I
think 15 days are a good window to not stall development too long, but
it can be extended if others feel we should


-- 
    Francesco

From rousskov at measurement-factory.com  Sun Dec 26 21:11:34 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 26 Dec 2021 16:11:34 -0500
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
 <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>
 <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>
Message-ID: <1f57f91c-6756-426c-4209-a40e8a6c1417@measurement-factory.com>

On 12/26/21 10:30 AM, Francesco Chemolli wrote:
> On Sun, Dec 5, 2021 at 10:05 PM Alex Rousskov wrote:
>> If we manage to and agree on what platforms to "support" and on removing
>> code dedicated to unsupported platforms, great! If we fail, I would like
>> to propose an alternative scheme for the removal of platform-specific
>> (or any other) code from the official master branch:
>>
>> A PR dedicated to code removal can be merged if it satisfies the
>> following criteria:
>>
>> 1. Two positive votes from core developers.
>> 2. No negative votes.
>> 3. Voting lasted for 30+ calendar days.
>> 4. The removal PR is announced in a PR-dedicated squid-users post.
>>    This announcement resets the 30+ day timer.

> How about instead something along the lines of:
> 1. announce on squid-users about intent to remove support for a platform
> 2. wait for objections for 15 days
> 3. PR following standard merge procedure


My proposal is trying to solve the specific problem that recent PRs
(attempting to remove some code) have faced: The reviewer asked _why_ we
are removing code, and the author closed the PR instead of developing
consensus regarding the correct answer to that question[1]. My proposal
establishes a special track for code removal PRs so that they do not
have to answer the (otherwise standard) "why" question.

Your proposal changes nothing as far as that problem is concerned. Thus,
unless that past experience has altered our understanding of the
problem, we are likely to face the same problem again!

Needless to say, getting squid-users feedback is nice -- both proposals
share that feature. However, even an enthusiastic squid-users support
for X removal cannot replace the answer to the "why" question. This is
why I am proposing to change the rules to remove that question for some PRs.


Hope this clarifies,

Alex.

[1] https://github.com/squid-cache/squid/pull/942#issuecomment-986208860

From rousskov at measurement-factory.com  Sun Dec 26 21:58:40 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 26 Dec 2021 16:58:40 -0500
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
 <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>
 <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>
Message-ID: <bd66c4f1-7685-7e58-eda3-21ad02510c7b@measurement-factory.com>

On 12/26/21 10:30 AM, Francesco Chemolli wrote:
> On Sun, Dec 5, 2021 at 10:05 PM Alex Rousskov wrote:
>> On 12/5/21 4:44 AM, Francesco Chemolli wrote:
>>> I would recommend that we support as main targets:
>>> - Linux on x64, arm64, arm32 and, if we can, MIPS
>>> - FreeBSD, OpenBSD on x64
>>
>>> As best-effort:
>>> - Windows on x64, with the aim of eventually promoting to primary target
>>> - Darwin on x64 and maybe eventually arm64
>>> - NetBSD on x64
>>
>> What does "support as main targets" and "support as best-effort" mean?

> "main targets" to me means that any regression in build or unit tests
> on these platforms is PR-blocking. We aim to deliver a working build
> out of the box on these environments, with no need of maintainer
> patches.

I am OK with that definition if you remove "in build or unit tests". Any
known Squid regression affecting the "main" environment should block the
PR introducing that regression IMO. I see no need to limit this to
"build and unit tests" regressions. Are you OK with that definition
simplification?

I do not think MIPS, FreeBSD, and OpenBSD should be on the "main" list:
There are just too few users and contributors on those platforms right
now to grant them primary status AFAICT. I may be missing some important
signals, of course, but I would downgrade them to best-effort.

I am not sure about arm32, for similar reasons, but perhaps there is a
strong demand for "embedded" Squid that I do not know about (and that
does not materialize in a stream of PRs because Squid already works well
in those environments??)? How can we tell?


> Once achieved this status on any of these platforms,
> regressions on it are release blockers.

I do not know what you mean by "release" exactly, but we should not add
rules that block schedule-based branching points and major releases[1].
As for other/minor releases, I am not against this rule if the
maintainer is happy about it.

[1] https://wiki.squid-cache.org/ReleaseSchedule



> "support as best effort" means that we keep these environment as build
> options, and test builds on them. Regressions on build or unit tests
> on these environments are not PR-blocking but we strongly encourage
> the PR owner to fix these platforms with followup PRs. We aim to
> deliver an out-of-the-box build on these platforms but failure to do
> so or regressions are not a release blocker

OK. If we drop the vague parts, "best effort" simply means that CI
covers these platforms (but they are not "main" environments and, hence,
the corresponding CI failures alone are not sufficient to block PRs).

AFAICT, the primary costs of keeping a platform on a best-effort list
are CI testing time and CI maintenance overheads. I suggest capping that
best-effort list to keep the total CI test time for one PR commit under,
say, 4 hours and granting CI maintenance team a veto on adding (but not
removing) platforms. IIRC, we have discussed PR commit testing time a
few months ago; if we agreed on another number of hours there, let's
take that as a cap.


>>> If anyone in the community wants to support/maintain extra OSes or
>>> architectures, they're very welcome to do so
>>
>> By "welcome", do you mean something like "we will accept high-quality
>> PRs adding such extra support to Squid"? Or "we will consider sharing
>> references to your work, but please do not ask us to merge your
>> OS-specific changes into the official Squid code"? Something else? This
>> bit is critical for understanding the real effect of this proposal IMO.
> 
> Fair point. I'd go for the former. If someone has an environment they
> want to support and do so without adding complexity to the code base,
> it's a good policy to enable that. The question is "how much
> complexity is it healthy to impose on other platforms to support
> niche/obsolete ones?"
> While setting an objective bar is hard to impossible, this is my
> attempt to set one for the most active group of developers

I agree regarding the level of difficulty in defining that bar.

Unfortunately, I do not think "we will accept high-quality PRs adding
such extra support to Squid" is something we should run with. We simply
do not have the resources to support some new environments, even if PRs
introducing them are perfect in every respect. For example, a perfect PR
introducing (explicit) LibreSSL support should be blocked IMO because we
do not have enough resources to properly handle the two already
(unfortunately) accepted TLS libraries (OpenSSL and GnuTLS).

However, we can drop this part of your proposal in hope to get to the
consensus on the other, arguably more important parts: The definitions
of three support levels (main, best-effort, and other). We can come back
to this part of the discussion later/separately, armed with established
and tested support levels.


Cheers,

Alex.

From squid3 at treenet.co.nz  Mon Dec 27 01:36:45 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 27 Dec 2021 14:36:45 +1300
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <1f57f91c-6756-426c-4209-a40e8a6c1417@measurement-factory.com>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
 <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>
 <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>
 <1f57f91c-6756-426c-4209-a40e8a6c1417@measurement-factory.com>
Message-ID: <1851760b-81f7-75fe-6cc8-9d914a61a695@treenet.co.nz>

On 27/12/21 10:11, Alex Rousskov wrote:
> On 12/26/21 10:30 AM, Francesco Chemolli wrote:
>> On Sun, Dec 5, 2021 at 10:05 PM Alex Rousskov wrote:
>>> If we manage to and agree on what platforms to "support" and on removing
>>> code dedicated to unsupported platforms, great! If we fail, I would like
>>> to propose an alternative scheme for the removal of platform-specific
>>> (or any other) code from the official master branch:
>>>
>>> A PR dedicated to code removal can be merged if it satisfies the
>>> following criteria:
>>>
>>> 1. Two positive votes from core developers.
>>> 2. No negative votes.
>>> 3. Voting lasted for 30+ calendar days.
>>> 4. The removal PR is announced in a PR-dedicated squid-users post.
>>>     This announcement resets the 30+ day timer.
> 
>> How about instead something along the lines of:
>> 1. announce on squid-users about intent to remove support for a platform
>> 2. wait for objections for 15 days
>> 3. PR following standard merge procedure
> 
> 
> My proposal is trying to solve the specific problem that recent PRs
> (attempting to remove some code) have faced: The reviewer asked _why_ we
> are removing code, and the author closed the PR instead of developing
> consensus regarding the correct answer to that question[1]. My proposal
> establishes a special track for code removal PRs so that they do not
> have to answer the (otherwise standard) "why" question.
> 

[1] is about removal of a trivial piece of code that has no harm leaving 
in place.

As I stated in followup what I regard as reasonable justification *was* 
given up front. If that was not enough for agreement to merge it was not 
worth the jumping through hoops in the first place. Let alone creating a 
whole new bureaucratic policy and management process.

As I said in other discussions, we already have a deprecation+removal 
process that works fine and matches the industry standard practices when 
a code change is even suspected to matter to anyone at all. That process 
gives far more than just 30 days to inform any interested community 
members and does not limit the notification channels.

If anyone picks up the code removal in [1] again they should follow that 
process since that code is now obviously of some importance to reviewer 
Alex.


Amos

From gkinkie at gmail.com  Mon Dec 27 09:41:16 2021
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Mon, 27 Dec 2021 10:41:16 +0100
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <bd66c4f1-7685-7e58-eda3-21ad02510c7b@measurement-factory.com>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
 <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>
 <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>
 <bd66c4f1-7685-7e58-eda3-21ad02510c7b@measurement-factory.com>
Message-ID: <CA+Y8hcOVbXwwdaGp2zixTDvPHr1+xCQzQFvantVG+tq7Fm3u0Q@mail.gmail.com>

On Sun, Dec 26, 2021 at 10:58 PM Alex Rousskov
<rousskov at measurement-factory.com> wrote:
>
> On 12/26/21 10:30 AM, Francesco Chemolli wrote:
> > On Sun, Dec 5, 2021 at 10:05 PM Alex Rousskov wrote:
> >> On 12/5/21 4:44 AM, Francesco Chemolli wrote:
> >>> I would recommend that we support as main targets:
> >>> - Linux on x64, arm64, arm32 and, if we can, MIPS
> >>> - FreeBSD, OpenBSD on x64
> >>
> >>> As best-effort:
> >>> - Windows on x64, with the aim of eventually promoting to primary target
> >>> - Darwin on x64 and maybe eventually arm64
> >>> - NetBSD on x64
> >>
> >> What does "support as main targets" and "support as best-effort" mean?
>
> > "main targets" to me means that any regression in build or unit tests
> > on these platforms is PR-blocking. We aim to deliver a working build
> > out of the box on these environments, with no need of maintainer
> > patches.
>
> I am OK with that definition if you remove "in build or unit tests". Any
> known Squid regression affecting the "main" environment should block the
> PR introducing that regression IMO. I see no need to limit this to
> "build and unit tests" regressions. Are you OK with that definition
> simplification?

Yes

> I do not think MIPS, FreeBSD, and OpenBSD should be on the "main" list:
> There are just too few users and contributors on those platforms right
> now to grant them primary status AFAICT. I may be missing some important
> signals, of course, but I would downgrade them to best-effort.

I'm okay with downgrading MIPS - it is present in the embedded space
but testing poses some challenges.
I'm a bit more reluctant with downgrading FreeBSD and (once stable)
OpenBSD. They ship Squid as part of their ports, and while the
developer community may not be very large, I'd expect the user
community to be a bit more prevalent. This would also prevent the risk
of the project becoming a Linux monoculture.

> I am not sure about arm32, for similar reasons, but perhaps there is a
> strong demand for "embedded" Squid that I do not know about (and that
> does not materialize in a stream of PRs because Squid already works well
> in those environments??)? How can we tell?

We can't, we have to guess. My angle on that is that having arm32 will
help us not become a 64-bit monoculture, which could bring in
regressions in low-level data structures. At this stage in the
embedded world, as far as I'm aware, there are x86-32, arm32, MIPS and
RISC-V. Of these arm32 is the most prevalent and therefore my
preferred choice. It also helps that we have a test environment for it
already, courtesy of a couple of raspberry pi 3.

> > Once achieved this status on any of these platforms,
> > regressions on it are release blockers.
>
> I do not know what you mean by "release" exactly, but we should not add
> rules that block schedule-based branching points and major releases[1].
> As for other/minor releases, I am not against this rule if the
> maintainer is happy about it.

Amos, what do you think?

>
> [1] https://wiki.squid-cache.org/ReleaseSchedule
>
>
>
> > "support as best effort" means that we keep these environment as build
> > options, and test builds on them. Regressions on build or unit tests
> > on these environments are not PR-blocking but we strongly encourage
> > the PR owner to fix these platforms with followup PRs. We aim to
> > deliver an out-of-the-box build on these platforms but failure to do
> > so or regressions are not a release blocker
>
> OK. If we drop the vague parts, "best effort" simply means that CI
> covers these platforms (but they are not "main" environments and, hence,
> the corresponding CI failures alone are not sufficient to block PRs).

Sounds good

> AFAICT, the primary costs of keeping a platform on a best-effort list
> are CI testing time and CI maintenance overheads. I suggest capping that
> best-effort list to keep the total CI test time for one PR commit under,
> say, 4 hours and granting CI maintenance team a veto on adding (but not
> removing) platforms. IIRC, we have discussed PR commit testing time a
> few months ago; if we agreed on another number of hours there, let's
> take that as a cap.

The best-effort model supports testing best-effort platforms
asynchronously, no need to cap there. Regressions would be noted and
hopefully dealt with in followup PRs. We are already using this
practice.

> >>> If anyone in the community wants to support/maintain extra OSes or
> >>> architectures, they're very welcome to do so
> >>
> >> By "welcome", do you mean something like "we will accept high-quality
> >> PRs adding such extra support to Squid"? Or "we will consider sharing
> >> references to your work, but please do not ask us to merge your
> >> OS-specific changes into the official Squid code"? Something else? This
> >> bit is critical for understanding the real effect of this proposal IMO.
> >
> > Fair point. I'd go for the former. If someone has an environment they
> > want to support and do so without adding complexity to the code base,
> > it's a good policy to enable that. The question is "how much
> > complexity is it healthy to impose on other platforms to support
> > niche/obsolete ones?"
> > While setting an objective bar is hard to impossible, this is my
> > attempt to set one for the most active group of developers
>
> I agree regarding the level of difficulty in defining that bar.
>
> Unfortunately, I do not think "we will accept high-quality PRs adding
> such extra support to Squid" is something we should run with. We simply
> do not have the resources to support some new environments, even if PRs
> introducing them are perfect in every respect. For example, a perfect PR
> introducing (explicit) LibreSSL support should be blocked IMO because we
> do not have enough resources to properly handle the two already
> (unfortunately) accepted TLS libraries (OpenSSL and GnuTLS).
>
> However, we can drop this part of your proposal in hope to get to the
> consensus on the other, arguably more important parts: The definitions
> of three support levels (main, best-effort, and other). We can come back
> to this part of the discussion later/separately, armed with established
> and tested support levels.

Sounds like a good plan to me


-- 
    Francesco

From rousskov at measurement-factory.com  Mon Dec 27 17:04:09 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 27 Dec 2021 12:04:09 -0500
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <CA+Y8hcOVbXwwdaGp2zixTDvPHr1+xCQzQFvantVG+tq7Fm3u0Q@mail.gmail.com>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
 <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>
 <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>
 <bd66c4f1-7685-7e58-eda3-21ad02510c7b@measurement-factory.com>
 <CA+Y8hcOVbXwwdaGp2zixTDvPHr1+xCQzQFvantVG+tq7Fm3u0Q@mail.gmail.com>
Message-ID: <ffa556c9-8caf-6d84-c8a8-e15d19b2eb03@measurement-factory.com>

On 12/27/21 4:41 AM, Francesco Chemolli wrote:
> On Sun, Dec 26, 2021 at 10:58 PM Alex Rousskov wrote:
>>
>> On 12/26/21 10:30 AM, Francesco Chemolli wrote:
>>> On Sun, Dec 5, 2021 at 10:05 PM Alex Rousskov wrote:
>>>> On 12/5/21 4:44 AM, Francesco Chemolli wrote:
>>>>> I would recommend that we support as main targets:
>>>>> - Linux on x64, arm64, arm32 and, if we can, MIPS
>>>>> - FreeBSD, OpenBSD on x64
>>>>
>>>>> As best-effort:
>>>>> - Windows on x64, with the aim of eventually promoting to primary target
>>>>> - Darwin on x64 and maybe eventually arm64
>>>>> - NetBSD on x64

First of all, thank you for making good progress on this important thread.


> I'm a bit more reluctant with downgrading FreeBSD and (once stable) 
> OpenBSD. They ship Squid as part of their ports, and while the 
> developer community may not be very large, I'd expect the user 
> community to be a bit more prevalent. This would also prevent the
> risk of the project becoming a Linux monoculture.

I share the overall sentiment, but I think all of the above concerns can
continue to be adequately addressed with FreeBSD/OpenBSD being assigned
to the second tier (i.e. the "best-effort" tier you have proposed). IMO,
it makes little sense to name two tiers and then essentially treat the
second named tier as "all other".

The second tier, as proposed, will bring our attention to any
FreeBSD/OpenBSD regressions and, in most cases, we will address them
(because they are usually easy to address). IMO, this level of support
is more than adequate given our lack of resources and relative
unpopularity of those platforms.

Perhaps this difference in approaches is rooted in our current (and
newly discovered!) disagreement on when best-effort/tier-2 results must
be reported (as discussed further below).


> My angle on that is that having arm32 will help us not become a
> 64-bit monoculture, which could bring in regressions in low-level
> data structures. At this stage in the embedded world, as far as I'm
> aware, there are x86-32, arm32, MIPS and RISC-V. Of these arm32 is
> the most prevalent and therefore my preferred choice. It also helps
> that we have a test environment for it already, courtesy of a couple
> of raspberry pi 3.

Same here: I share the sentiment but consider all these arguments
appropriate for tier-2; they are an overkill for tier-1. Squid can
survive without x86-32, arm32, MIPS, and RISC-V support. Yes, we do not
want to accidentally abandon support for those environments, without a
compelling reason, but that is exactly why we are adding tier-2 -- to
eliminate such accidents: Thanks to tier-2 presence, the decision to
regress support for those platforms (in some specific PR scope) will be
deliberate, _not_ accidental.



>>> Once achieved this status on any of these platforms,
>>> regressions on it are release blockers.
>>
>> I do not know what you mean by "release" exactly, but we should not add
>> rules that block schedule-based branching points and major releases[1].
>> [1] https://wiki.squid-cache.org/ReleaseSchedule

Just to avoid misunderstanding, my comments/opinions about minor
releases below apply to the text below. My sentence quoted above is not
about minor releases; it is about major releases; major releases occur
on a fixed schedule; they are not governed by release maintenance rules
that are largely in Amos hands today. Moreover, since no PR can be
merged if it breaks tier-1 support, it is impossible to have a tier-1
regression unless we change the test environment without fixing Squid
first (which we should not do, especially for tier-1 platforms!).


>> As for other/minor releases, I am not against this rule if the
>> maintainer is happy about it.

> Amos, what do you think?

I would like to adjust my comment: I think this additional formal rule
is not needed because we should just let the maintainer decide what
maintenance rules work best (and adjust them as needed), but I am not
against adding that formal rule if Amos wants to add it to his current
set of rules.


>> AFAICT, the primary costs of keeping a platform on a best-effort list
>> are CI testing time and CI maintenance overheads. I suggest capping that
>> best-effort list to keep the total CI test time for one PR commit under,
>> say, 4 hours and granting CI maintenance team a veto on adding (but not
>> removing) platforms. IIRC, we have discussed PR commit testing time a
>> few months ago; if we agreed on another number of hours there, let's
>> take that as a cap.
> 
> The best-effort model supports testing best-effort platforms
> asynchronously, no need to cap there. Regressions would be noted and
> hopefully dealt with in followup PRs. We are already using this
> practice.

The "I will eventually let you know if your old PR broke OpenBSD support
and let you decide whether to revert that PR commit or fix the problem
sometime in the future" approach does not work (and has never worked)
well IMO. We should know about tier-2 regressions _before_ PR is merged
(and excuse them explicitly). For that, tier-2 regressions should be
reported _before_ a PR is merged.

I understand that we may not have the technical capability to achieve
the timely regression reporting goal today, but that should be the goal,
and the tier design/rules should be based on that goal. Otherwise, there
will be little practical difference between best-effort teir-2 and
other/tier-3. Both will occasionally receive post-PR regression reports.
We should eliminate named tier-2 in that case and just let you test
whatever you want, whenever you can, reporting the results whenever you
have the time to do so.

In summary, if we want to define named tiers based, in part, on the PR
reaction to their test results, then those results must be reported
before the reacting PR is merged. Moreover, all other tiers (i.e. tiers
that are not defined in terms of PRs), do not really matter much in
terms of keeping Squid regressions-free. Can we agree to that principle?


Cheers,

Alex.

From rousskov at measurement-factory.com  Mon Dec 27 20:11:42 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 27 Dec 2021 15:11:42 -0500
Subject: [squid-dev] What os/cpu platforms do we want to target as a
 project?
In-Reply-To: <1851760b-81f7-75fe-6cc8-9d914a61a695@treenet.co.nz>
References: <CA+Y8hcMVyXDRx2HRvJjg90wBm6eK-HSAe90VAoHFi7P=pZm14A@mail.gmail.com>
 <81bd3f81-0c54-f71f-b158-47400f24f094@measurement-factory.com>
 <CA+Y8hcNSutg6j42g6jFVmWVFJAdQkN2Q=qD5r9duudYPZUwtKg@mail.gmail.com>
 <1f57f91c-6756-426c-4209-a40e8a6c1417@measurement-factory.com>
 <1851760b-81f7-75fe-6cc8-9d914a61a695@treenet.co.nz>
Message-ID: <84fdfdc8-5ccb-e0ef-e660-c3b0dc854dd8@measurement-factory.com>

On 12/26/21 8:36 PM, Amos Jeffries wrote:
> On 27/12/21 10:11, Alex Rousskov wrote:
>> On 12/26/21 10:30 AM, Francesco Chemolli wrote:
>>> On Sun, Dec 5, 2021 at 10:05 PM Alex Rousskov wrote:
>>>> If we manage to and agree on what platforms to "support" and
>>>> on removing code dedicated to unsupported platforms, great! If
>>>> we fail, I would like to propose an alternative scheme for the
>>>> removal of platform-specific (or any other) code from the
>>>> official master branch:
>>>> 
>>>> A PR dedicated to code removal can be merged if it satisfies
>>>> the following criteria:
>>>> 
>>>> 1. Two positive votes from core developers. 2. No negative
>>>> votes. 3. Voting lasted for 30+ calendar days. 4. The removal
>>>> PR is announced in a PR-dedicated squid-users post. This
>>>> announcement resets the 30+ day timer.

>>> How about instead something along the lines of:
>>> 1. announce on squid-users about intent to remove support for a platform
>>> 2. wait for objections for 15 days
>>> 3. PR following standard merge procedure

>> My proposal is trying to solve the specific problem that recent PRs
>> (attempting to remove some code) have faced: The reviewer asked _why_ we
>> are removing code, and the author closed the PR instead of developing
>> consensus regarding the correct answer to that question[1]. My proposal
>> establishes a special track for code removal PRs so that they do not
>> have to answer the (otherwise standard) "why" question.


> [1] is about removal of a trivial piece of code that has no harm leaving
> in place.
> 
> As I stated in followup what I regard as reasonable justification *was*
> given up front. If that was not enough for agreement to merge it was not
> worth the jumping through hoops in the first place. Let alone creating a
> whole new bureaucratic policy and management process.
> 
> As I said in other discussions, we already have a deprecation+removal
> process that works fine and matches the industry standard practices when
> a code change is even suspected to matter to anyone at all. That process
> gives far more than just 30 days to inform any interested community
> members and does not limit the notification channels.
> 
> If anyone picks up the code removal in [1] again they should follow that
> process 


I do not think they should. IMO, that (poorly working)
deprecation+removal process should not be used for explicit OSF/1
support removal (among other things). They should use the regular PR
review process (if we do not come up with something better by then).


> since that code is now obviously of some importance to reviewer Alex.

FWIW, I still[2] support removal of explicit OSF/1 support. The reason
we had this discussion is not some special importance of that explicit
OSF/1 support code. The goal is to lower the overhead of future PRs
similar to the one you closed _because_ that overhead was too high.


Hope this clarifies,

Alex.

[1] https://github.com/squid-cache/squid/pull/942#issuecomment-986208860
[2] https://github.com/squid-cache/squid/pull/942#issuecomment-986055422

From dm at belkam.com  Tue Dec 28 06:17:00 2021
From: dm at belkam.com (Dmitry Melekhov)
Date: Tue, 28 Dec 2021 10:17:00 +0400
Subject: [squid-dev] squid 5.3 crash
Message-ID: <585427c4-ba6d-f6f8-a341-99ce0f0ff02e@belkam.com>

Hello!


Testing squid 5.3 on Ubuntu 20.04.

Looks good for several weeks , but just got this:


2021/12/28 09:58:01 kid1| assertion failed: Read.cc:61: 
"Comm::IsConnOpen(conn)"
 ??? current master transaction: master28713185


After this squid ate almost 100% of cpu, then crashed, unfortunately gdb 
says core dump is truncated:

/var/crash/squid-dump/CoreDump is truncated: expected core file size >= 
303022080, found: 177070080


Is this assertion fail known problem?


Thank you!



From rousskov at measurement-factory.com  Wed Dec 29 14:23:37 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 29 Dec 2021 09:23:37 -0500
Subject: [squid-dev] squid 5.3 crash
In-Reply-To: <585427c4-ba6d-f6f8-a341-99ce0f0ff02e@belkam.com>
References: <585427c4-ba6d-f6f8-a341-99ce0f0ff02e@belkam.com>
Message-ID: <541a66bb-17d6-09b5-e7d8-4f09d2b4f079@measurement-factory.com>

On 12/28/21 1:17 AM, Dmitry Melekhov wrote:

> Testing squid 5.3 on Ubuntu 20.04.

> 2021/12/28 09:58:01 kid1| assertion failed: Read.cc:61:
> "Comm::IsConnOpen(conn)"

> Is this assertion fail known problem?

Impossible to say for sure without a stack trace, unfortunately -- many
different code paths lead to that low level assertion -- but this could
be bug #5056 or a related problem, as triaged at:

https://bugs.squid-cache.org/show_bug.cgi?id=5056#c1


HTH,

Alex.

From dm at belkam.com  Wed Dec 29 15:46:26 2021
From: dm at belkam.com (Dmitry Melekhov)
Date: Wed, 29 Dec 2021 19:46:26 +0400
Subject: [squid-dev] squid 5.3 crash
In-Reply-To: <541a66bb-17d6-09b5-e7d8-4f09d2b4f079@measurement-factory.com>
References: <585427c4-ba6d-f6f8-a341-99ce0f0ff02e@belkam.com>
 <541a66bb-17d6-09b5-e7d8-4f09d2b4f079@measurement-factory.com>
Message-ID: <e47200af-3920-4324-aee9-21978869f027@belkam.com>


29.12.2021 18:23, Alex Rousskov ?????:
> On 12/28/21 1:17 AM, Dmitry Melekhov wrote:
>
>> Testing squid 5.3 on Ubuntu 20.04.
>> 2021/12/28 09:58:01 kid1| assertion failed: Read.cc:61:
>> "Comm::IsConnOpen(conn)"
>> Is this assertion fail known problem?
> Impossible to say for sure without a stack trace, unfortunately -- many
> different code paths lead to that low level assertion -- but this could
> be bug #5056 or a related problem, as triaged at:
>
> https://bugs.squid-cache.org/show_bug.cgi?id=5056#c1
>
>
Thank you!

I got e-mail from another user that they hit the same problem with delay 
pools enabled in configuration...

We use delay pools.



