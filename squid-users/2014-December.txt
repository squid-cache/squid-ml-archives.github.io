From dan at getbusi.com  Mon Dec  1 05:49:43 2014
From: dan at getbusi.com (dan at getbusi.com)
Date: Sun, 30 Nov 2014 21:49:43 -0800 (PST)
Subject: [squid-users] long standing bug about aufs on freebsd 10
In-Reply-To: <547AC48B.8040800@gmail.com>
References: <547AC48B.8040800@gmail.com>
Message-ID: <1417412983452.10bd4da3@Nodemailer>

FWIW I have this bug in CentOS 6.

On Mon, Dec 1, 2014 at 4:48 PM, k simon <chio1990 at gmail.com> wrote:

> Hi, Lists,
>    AUFS can not run stable one day and report:
> 2014/11/30 07:10:15 kid1| WARNING: swapfile header inconsistent with 
> available data
> 2014/11/30 07:10:15 kid1| Could not parse headers from on disk object
> 2014/11/30 07:10:15 kid1| BUG 3279: HTTP reply without Date:
> 2014/11/30 07:10:15 kid1| StoreEntry->key: 553ABDC02632452B7204639E5DDA66D8
> 2014/11/30 07:10:15 kid1| StoreEntry->next: 0
> 2014/11/30 07:10:15 kid1| StoreEntry->mem_obj: 0x82178ed00
> 2014/11/30 07:10:15 kid1| StoreEntry->timestamp: -1
> 2014/11/30 07:10:15 kid1| StoreEntry->lastref: 1417302615
> 2014/11/30 07:10:15 kid1| StoreEntry->expires: -1
> 2014/11/30 07:10:15 kid1| StoreEntry->lastmod: -1
> 2014/11/30 07:10:15 kid1| StoreEntry->swap_file_sz: 0
> 2014/11/30 07:10:15 kid1| StoreEntry->refcount: 1
> 2014/11/30 07:10:15 kid1| StoreEntry->flags: 
> CACHABLE,PRIVATE,FWD_HDR_WAIT,VALIDATED
> 2014/11/30 07:10:15 kid1| StoreEntry->swap_dirn: -1
> 2014/11/30 07:10:15 kid1| StoreEntry->swap_filen: -1
> 2014/11/30 07:10:15 kid1| StoreEntry->lock_count: 2
> 2014/11/30 07:10:15 kid1| StoreEntry->mem_status: 0
> 2014/11/30 07:10:15 kid1| StoreEntry->ping_status: 2
> 2014/11/30 07:10:15 kid1| StoreEntry->store_status: 1
> 2014/11/30 07:10:15 kid1| StoreEntry->swap_status: 0
> 2014/11/30 07:10:15 kid1| assertion failed: store.cc:1876: "isEmpty()"
>    How can I workaround it ?
> Simon
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141130/b6748a9c/attachment.htm>

From hno at squid-cache.org  Mon Dec  1 07:59:31 2014
From: hno at squid-cache.org (Henrik Nordstrom)
Date: Mon, 01 Dec 2014 08:59:31 +0100
Subject: [squid-users] Multiple SSL Domains on Reverse Proxy
In-Reply-To: <CAJbW+rn6-7XnZnSXWevSoTPmCZ4VJF89SMK6SEiXz0gv-0QO1Q@mail.gmail.com>
References: <CAJbW+rn6-7XnZnSXWevSoTPmCZ4VJF89SMK6SEiXz0gv-0QO1Q@mail.gmail.com>
Message-ID: <1417420771.14299.10.camel@localhost>


l?r 2014-11-29 klockan 20:39 -0500 skrev Roman Gelfand:
> Is it possible to listen on port 443 for requests for multiple domains
> ie... www.xyz.com, www.mno.com, etc...?

If you have one IP address per domain then it's just one https_port with
explicit ip:port per domain, with vhost or defaultdomain= telling Squid
what hostname to use as requested host in HTTP(S).

Supporting more than one domain on the same ip:port is currently only
possible if you use a multi-domain certificate.

We really should support SNI negotiation to select certificate based on
client requested domain. SNI is a TLS extension to indicate requested
host during TLS negotiation and is quite well supported in todays
browsers.  Patches implemententing this are very welcome.

Regards
Henrik




From hno at squid-cache.org  Mon Dec  1 08:38:24 2014
From: hno at squid-cache.org (Henrik Nordstrom)
Date: Mon, 01 Dec 2014 09:38:24 +0100
Subject: [squid-users] Squid WCCP with multiple workers
In-Reply-To: <CABrJVozUY6m0yF0E=yBX7u51Te5qNqPnOKXwdGC7oZbYfD=+7g@mail.gmail.com>
References: <CABrJVozUY6m0yF0E=yBX7u51Te5qNqPnOKXwdGC7oZbYfD=+7g@mail.gmail.com>
Message-ID: <1417423104.14299.13.camel@localhost>

fre 2014-11-28 klockan 10:28 +0000 skrev Stephen Baynes:
> Is WCCP supposed to work with Squid multiple workers?

In theory it should work.. but not sure it has been adapted for
multi-worker.

> It works with 1 worker. If we change the number of workers from 1 to 2
> we see it fail. The router no longer is aware of Squid and does not
> reroute the data to the Squid box.

Try making the wccp configuration conditional on worker id 1. If this
makes a difference then Squid needs to be extended to add a internal
wccp worker.

Regards
Henrik




From squid3 at treenet.co.nz  Mon Dec  1 08:42:57 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 01 Dec 2014 21:42:57 +1300
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
In-Reply-To: <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
References: <E6B2517F8D6DBF4CABB8F38ACA367E783431AF29@Draco.dawnsign.com>
 <5473E101.4010907@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
Message-ID: <547C2A11.6030403@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 26/11/2014 8:59 a.m., Doug Sampson wrote:
> 
> Thanks, Amos, for your pointers.
> 
> I've commented out all the fresh_patterns lines appearing above
> the last two lines.
> 
> I also have dropped diskd in favor of using aufs exclusively,
> taking out the min-size parameter. I've commented out the
> diskd_program support option. In the previous version of squid
> (2.7) I had split the cache_dir into two types with great success
> using coss and aufs. Previously I had only aufs and performance
> wasn't where I wanted it. Apparently coss is no longer supported in
> the 3.x version of squid atop FreeBSD.

COSS has been replaced with Rock storage type in Squid-3. They should
be used in roughly similar ways in terms of traffic optimization.

> 
> The pathname for the cache swap logs have been fixed. Apparently
> this came from a squid.conf example that I copied in parts. Would
> this be the reason why we are seeing the error messages in
> /var/log/messages regarding swapping mentioned in my original
> post?

No. I think that is coming out of the OS kernel memory management. It
uses the term "swap" as well in regards to disk backed virtual memory.

If your system is "swapping" (using that disk backed "swap memory")
while running Squid then you will get terrible performance as a matter
of course since the Squid cache index and cache_meme is often very
large in RAM and accessed often.


> 
> The hierarchy_stoplist line has been stripped out as you say it is 
> deprecated.
> 
> The mem .TSV file is attached herewith.
> 
> Currently I have the cache_dir located on the OS disk and all of
> the cache logging files on a second drive. Is this the optimal
> setup of cache-dir and logs?

I would do it the other way around. Logs are appended with a small
amount of data each transaction, whereas the main cache_dir has a
relativey large % of the bandwidth throughput being written out to it
constantly (less % in recent Squid, but still a lot). The dik most
likely to die early is the one holding cache_dir.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfCoRAAoJELJo5wb/XPRjvtsIAJskATDCJDf4IZdapvHXeJAn
Ug8KkCrV4/HU5ajeG/Z0G7czvzU34LNXCDtblLWp2JD9LDBK9NRTlOO6q5IoTtAY
qqw5YXFrKbDt16A6bNHuVDn1Mxh+vHG64KG6cPabcG4lR3EnAlS8/WoBebAZDHCq
1Ds0LfPJJKNg6CEKiaXavwv+zv5rEsZBCZtQmq8+8hymn7ytCBOo/IN5+UKUkhZg
cEo3RgZYhVjo5msATRTjR83Ow+4MCEKaejFuRsFVlI6tapJlZ6u2M/0XgxGRbQyv
NqXJoxLunXlOMEftpyPWY52EOhH7XkQzTLLky+mzHQK4P9/jPMv8NuwUxZhS6Bk=
=Etqf
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Mon Dec  1 08:57:39 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 01 Dec 2014 21:57:39 +1300
Subject: [squid-users] WARNING: there are more than 100 regular
	expressions
In-Reply-To: <1417166614113-4668542.post@n4.nabble.com>
References: <1417078626013-4668529.post@n4.nabble.com>
 <D5dthyFPCXB@helmut.hullen.de> <1417082346062-4668531.post@n4.nabble.com>
 <547715EF.5050703@solutti.com.br> <1417166614113-4668542.post@n4.nabble.com>
Message-ID: <547C2D83.80908@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 28/11/2014 10:23 p.m., navari.lorenzo at gmail.com wrote:
> I saw that the error does not preclude the use of the lines over
> the 100. I have no problem with the CPU ( 7 % ) . Only I do not
> like to see " Warning"
> 

The RE engine can scan for individual patterns easily enough but
copying patterns into libregex memory and scanning the entire URI 100+
times per transaction is quite an excessive amount of work for the
simple task being attempted.

Like Marcus said lists of domains are best matched using dstdomain ACL
type which does an optimized single scan of just the domain name
portion no matter how many entries there are.

If you do have no choice but to use RE, then manually combining
patterns is best. This warning is just an indication that you need to
pay some attention to reducing the count.

For example the list containing:
 facebook\.com
 fbcdn\.com

Can be reduced to:
  f(acebook|bcdn)\.com


If you are importing a public list of domains to block please
investigate whether your list source supports squid dstdomain ACL
formats. The best lists provide files with Squid dstdomain format
(which is also almost identical to the rbldnsd 'RHSBL' data format).

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfC2DAAoJELJo5wb/XPRjQuoH/31JMC52DYzvZqp1xycEIlwU
BTmdZCXZNsnYNklKW0MmN+Li3C3K87d5O07og7EsovG0syFxXlJc5HSvEBgqwQ9v
iAqTLkrg23EMKmqU7cM+A6MhMcuCGK7r//JAQiCqG6JD0iDXS5V8GFTOv2FYLr5e
yHhJ3p5vbmh/K8Qx6JrThTwNq8h41g9ek1PRG+BQj9iem80ujK8m616dXqhJGB4g
3BvgSHbuhkSD9MfOcz1lkftR1+baBK8XtIn/Ue/MkEmveTzbOre+mXEOryZX9ny+
a9nL6ioOzzAIBVqzaLz00xhZkp7Lm2iifycn8p3p6tPi+zIxcp70TemruOON1uE=
=JLTR
-----END PGP SIGNATURE-----


From chio1990 at gmail.com  Mon Dec  1 09:02:33 2014
From: chio1990 at gmail.com (k simon)
Date: Mon, 01 Dec 2014 17:02:33 +0800
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
In-Reply-To: <547C2A11.6030403@treenet.co.nz>
References: <E6B2517F8D6DBF4CABB8F38ACA367E783431AF29@Draco.dawnsign.com>
 <5473E101.4010907@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
 <547C2A11.6030403@treenet.co.nz>
Message-ID: <547C2EA9.9090900@gmail.com>

   Maybe your problem is related to sysctl mib tuning about 
swap/overcommit etc. I did not observed memory leak with squid 3.4.4, 
but FB 10 do swap frequently than old version.


Simon


From chio1990 at gmail.com  Mon Dec  1 09:08:02 2014
From: chio1990 at gmail.com (k simon)
Date: Mon, 01 Dec 2014 17:08:02 +0800
Subject: [squid-users] long standing bug about aufs on freebsd 10
In-Reply-To: <1417412983452.10bd4da3@Nodemailer>
References: <547AC48B.8040800@gmail.com> <1417412983452.10bd4da3@Nodemailer>
Message-ID: <547C2FF2.8070104@gmail.com>

   I did not observed this bug with diskd, but diskd have less performance.

Simon


? 14/12/1 13:49, dan at getbusi.com ??:
> FWIW I have this bug in CentOS 6.
>
>
>
>
> On Mon, Dec 1, 2014 at 4:48 PM, k simon <chio1990 at gmail.com
> <mailto:chio1990 at gmail.com>> wrote:
>
>     Hi, Lists,
>     AUFS can not run stable one day and report:
>
>     2014/11/30 07:10:15 kid1| WARNING: swapfile header inconsistent with
>     available data
>     2014/11/30 07:10:15 kid1| Could not parse headers from on disk object
>     2014/11/30 07:10:15 kid1| BUG 3279: HTTP reply without Date:
>     2014/11/30 07:10:15 kid1| StoreEntry->key:
>     553ABDC02632452B7204639E5DDA66D8
>     2014/11/30 07:10:15 kid1| StoreEntry->next: 0
>     2014/11/30 07:10:15 kid1| StoreEntry->mem_obj: 0x82178ed00
>     2014/11/30 07:10:15 kid1| StoreEntry->timestamp: -1
>     2014/11/30 07:10:15 kid1| StoreEntry->lastref: 1417302615
>     2014/11/30 07:10:15 kid1| StoreEntry->expires: -1
>     2014/11/30 07:10:15 kid1| StoreEntry->lastmod: -1
>     2014/11/30 07:10:15 kid1| StoreEntry->swap_file_sz: 0
>     2014/11/30 07:10:15 kid1| StoreEntry->refcount: 1
>     2014/11/30 07:10:15 kid1| StoreEntry->flags:
>     CACHABLE,PRIVATE,FWD_HDR_WAIT,VALIDATED
>     2014/11/30 07:10:15 kid1| StoreEntry->swap_dirn: -1
>     2014/11/30 07:10:15 kid1| StoreEntry->swap_filen: -1
>     2014/11/30 07:10:15 kid1| StoreEntry->lock_count: 2
>     2014/11/30 07:10:15 kid1| StoreEntry->mem_status: 0
>     2014/11/30 07:10:15 kid1| StoreEntry->ping_status: 2
>     2014/11/30 07:10:15 kid1| StoreEntry->store_status: 1
>     2014/11/30 07:10:15 kid1| StoreEntry->swap_status: 0
>     2014/11/30 07:10:15 kid1| assertion failed: store.cc:1876: "isEmpty()"
>
>     How can I workaround it ?
>
>
>
>
>     Simon
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     http://lists.squid-cache.org/listinfo/squid-users
>
>


From omidkosari at yahoo.com  Mon Dec  1 09:11:38 2014
From: omidkosari at yahoo.com (Omid Kosari)
Date: Mon, 1 Dec 2014 01:11:38 -0800 (PST)
Subject: [squid-users] Squid 3.4.9 RPM release
In-Reply-To: <546BC47C.9010008@ngtech.co.il>
References: <5458596C.8060203@treenet.co.nz> <546A7222.90001@ngtech.co.il>
 <546BC47C.9010008@ngtech.co.il>
Message-ID: <1417425098891-4668576.post@n4.nabble.com>

Any news about ubuntu version ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-4-9-is-available-tp4668181p4668576.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon Dec  1 09:32:10 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 01 Dec 2014 22:32:10 +1300
Subject: [squid-users] 2.7.STABLE9 & Error with option deny_info from
 local requests
In-Reply-To: <166D4EE577088449BA7DD4367005D8642E1BF4AA@s015011.office.babiel.com>
References: <166D4EE577088449BA7DD4367005D8642E1BF4AA@s015011.office.babiel.com>
Message-ID: <547C359A.604@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 29/11/2014 2:40 a.m., Mark Riede wrote:
> Hello,
> 
> I have a strange behavior with Squid 2.7.STABLE9 and local
> requests which should be intercept by the option deny_info.
> 

1) *Please* upgrade your Squid. 2.7 has been unsupported for more than 5
years now and is seriously out of date with modern web traffic needs.

2) "intercept" and how deny_info works are completely unrelated concepts.


> I am using Squid as a reverse proxy. I have configured a list of 
> subdomains (i.e. subdomain.domain.tld) in a file via the option 
> dstdomain, which will be forwarded to the defined cache peer.
> There is an additional list of domains (i.e. *.domain.tld) which
> match via wildcard to all other domains, which are not absolutely
> defined yet and will be forwarded to a custom error page via the
> option deny_info.
> 
> The problem is that requests forwarded to the ip of the server,
> i.e. 192.168.0.1, will be catched up by the option deny_info. But,
> when the request is forwarded to the ip of the localhost
> (127.0.0.1), the option deny_info will not match.

?? *all* traffic to the cache_peer is "forwarded to the ip 127.0.0.1"
since that IP *is* the cache_peer's IP.


127.0.0.1 (and ::1) are special purpose IP addresses. Traffic is not
permitted to go to/from it from a global-scope IP address. When you
send to/from a localhost IP then it is mandatory for the TCP system to
use the localhost IP as source.


> Now the strange behaviour is that requests to the ip of the
> localhost but with the destination domain subdomain.domain.tld will
> be answered successfully. I need a fix because clients get the
> custom error page for requests via http (NAT to 192.168.0.1) but
> not the same response via https (nginx to 127.0.0.1). I don?t know
> where or how I can fix this problem or do more debugging.


Why is nginx not forwarding proper HTTP messages with the relevant
Host: header contents to Squid? the HTTP message syntax is no
different when sent over TLS port 443 as when sent over TCP port 80.

- From your description it sounds like nginx is sending to Squid
messages with URL https://127.0.0.1/* which cannot be expected to
exist in your list of acceptible domains.


Also, why are you not using Squid to receive and direct both HTTP and
HTTPS traffic to the relevant servers?
 Squid accepts port 443 traffic with an https_port directive just fine.


> 
> # Config http_access allow localhost

The above rule permits all traffic from 127.0.0.1 to go through this
proxy *no matter what*. From your description that would be all
traffic arriving from nginx **AND** any traffic you direct at
127.0.0.1 IP from any other software.

It is a very bad thing to do, particularly for a reverse-proxy. Remove
it and traffic from nginx (and yoru 127.0.0.1 tests) will start to
obey the other rules. Not a complete fix, but required for Squid to
work as you expect.

> acl foo dstdomain "/file" acl foo_deny dstdom_regex "/ file _deny" 
> http_access allow foo

When testing this ACL with a raw-IP Squid will lookup reverse-DNS of
the IPand compare the result with contents of /file.
Meaning 127.0.0.1 == "localhost" --> is "localhost" one of the peer
hosted domain names? should not be.

> cache_peer 127.0.0.1 parent 8080 0 no-query originserver name=srv1
login=PASS
> cache_peer_access srv1 allow foo cache_peer_access srv1 deny all 
> deny_info ERR_FOO foo_deny http_access deny foo_deny http_access
> deny all
<snip>

The rest of these rules match your intended behaviour of Squid.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfDWaAAoJELJo5wb/XPRjfEYH/1KMTu400wRO0wmz6RURlUwB
6jVEqWGc+rYV1hvtjZe5PtvJW8nMxF6idP0SU2aj/GWoGmcusrq413sAsoQhwEYT
lGAlDhU08c6aQ5r7ZyNY9TMNip8OJS6NPYEWV07Nw34QuJcQXbHUEC9VTAjboQqa
VYfnrBZIbMXFY3wkdhGkyNm4m/Uz5scOZ2lKAVabhZ4wHEu/NVMYISD3mEIHNiT7
rLT9/dqZaj/KHn1Vb5Z31k3szija9ZMh2Gu6A5tg3TfpelBVrbCXFOzoHIJMN7es
eRScL64c2KZ1PMpTMrTUzq1ILcOIuXcVDSdcj610Tcp524u0ssQ1vteJqj8kFak=
=8Dhf
-----END PGP SIGNATURE-----


From rafael.akchurin at diladele.com  Mon Dec  1 09:46:02 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 1 Dec 2014 09:46:02 +0000
Subject: [squid-users] Best way to deny access to URLs in Squid 3.3.x?
In-Reply-To: <BAY181-W520DB81776ED7F829DE327F0AD0@phx.gbl>
References: <BAY181-W74A0085867394B1608E8A2F0AD0@phx.gbl>,
 <D0632D4C.7F86%rafael.akchurin@diladele.com>,
 <BAY181-W520DB81776ED7F829DE327F0AD0@phx.gbl>
Message-ID: <1417427172668.6352@diladele.com>

Hello Mirza,


We are building MSI installer for the Squid you are using (see sources at https://github.com/diladele/squid3-windows and http://squid.diladele.com/) - it is now very early Alpha and MSI for the qlproxyd will follow in a week or so. I will try to post the update when it is ready.


Fighting with latest Squid build with Cygwin and/or MinGW takes all the time and I am loosing the battle :(


Best regards,

Rafael


________________________________
From: Mirza Dedic <mirza.dedic at outlook.com>
Sent: Tuesday, October 14, 2014 8:17 PM
To: Rafael Akchurin
Subject: RE: [squid-users] Best way to deny access to URLs in Squid 3.3.x?

I will be happy to test the native windows ICAP build. We are running SQUID 3.3.3 on Windows via Cygwin.

Is there a source we can try to build from? I see you have them listed for various distributions, however cygwin is not on there.

________________________________
From: rafael.akchurin at diladele.com
To: mirza.dedic at outlook.com; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Best way to deny access to URLs in Squid 3.3.x?
Date: Tue, 14 Oct 2014 17:46:11 +0000

Hello Mirza,

I would humbly propose taking a look at any of the ICAP servers listed on http://www.squid-cache.org/Misc/icap.html.
BTW we are now preparing a native Windows ICAP build of qlproxy and would be glad if you could take a look.

Best regards,
Raf

From: Mirza Dedic <mirza.dedic at outlook.com<mailto:mirza.dedic at outlook.com>>
Date: Tuesday 14 October 2014 19:37
To: "squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>" <squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
Subject: [squid-users] Best way to deny access to URLs in Squid 3.3.x?

Just curious, what are some of you doing in your Squid environment as far as URL filtering goes? It seems there are a few options out there.. squidguard... dansguardian.. plain block lists.

What is the best practice to implement some sort of block list into squid? I've found urlblacklist.com that has a pretty good broken down URL block list by category, what would be the best way to go.. use dansguardian with this list or set it up in squid.conf as an "acl dstdomain" and feed in the block list file without calling an external helper application?

Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141201/0bb6fac4/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec  1 09:54:43 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 01 Dec 2014 22:54:43 +1300
Subject: [squid-users] Squid WCCP with multiple workers
In-Reply-To: <1417423104.14299.13.camel@localhost>
References: <CABrJVozUY6m0yF0E=yBX7u51Te5qNqPnOKXwdGC7oZbYfD=+7g@mail.gmail.com>
 <1417423104.14299.13.camel@localhost>
Message-ID: <547C3AE3.7030505@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 1/12/2014 9:38 p.m., Henrik Nordstrom wrote:
> fre 2014-11-28 klockan 10:28 +0000 skrev Stephen Baynes:
>> Is WCCP supposed to work with Squid multiple workers?
> 
> In theory it should work.. but not sure it has been adapted for 
> multi-worker.

Not that I am aware of.

I think each worker will be emitting separate WCCP packts to the
router. If they are all sharing http_port entries then there should be
no problem, as long as one worker is running the router will see the
proxy as alive. With differet http_port between workers they can
confuse the router and cause it to reset its traffic mappings up to
every 10 seconds.

There may also be problems with receiving back the WCCP reply from
router as no guarantee it goes to the right worker. Some may receive
multiple packets and some workers might think their router has gone
away as it dont reply often enough. This should only affect Squid
workers which have never received any router reply before receiving
HTTP, once they get one packet they cache the details until updated.

> 
>> It works with 1 worker. If we change the number of workers from 1
>> to 2 we see it fail. The router no longer is aware of Squid and
>> does not reroute the data to the Squid box.
> 
> Try making the wccp configuration conditional on worker id 1. If
> this makes a difference then Squid needs to be extended to add a
> internal wccp worker.
> 

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfDrjAAoJELJo5wb/XPRjaE8H/2tSAA/9Yz2RDSgm/xjAqphB
Zz3jlGRSUDIlMDeVfH7p+2hhEGZ41yPQ9x0viWMDvd4NNHOY8/c+DoA5OkzjYT+9
Kl+2HyFGWy1EqY3oC3mREVxab4i/5NvXveZQg9Pf4imMPkQxzqD+hXp8RCmVsFms
RW+0RvqeW7Jb8uDZjTOGjLI+pXlTehpQOoLQmRUxy0WTT75m9xlnnTPtTo4zb1by
qxB0+PrC7Z/G7A8LYw9tFgEVF7KKHNLIkUJGibP/ojSs5PZ+Y+AS9HdphldfLEoG
EUSxafYcVyqDavm/nhMAWG//JPfcpY4ZyLsfRV2L9kbI01RaiHAep7Gf0GqUlGw=
=mO6b
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Mon Dec  1 09:59:10 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 01 Dec 2014 22:59:10 +1300
Subject: [squid-users] Squid 3.4.9 RPM release
In-Reply-To: <1417425098891-4668576.post@n4.nabble.com>
References: <5458596C.8060203@treenet.co.nz> <546A7222.90001@ngtech.co.il>
 <546BC47C.9010008@ngtech.co.il> <1417425098891-4668576.post@n4.nabble.com>
Message-ID: <547C3BEE.7020406@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 1/12/2014 10:11 p.m., Omid Kosari wrote:
> Any news about ubuntu version ?

Feel free to grab the 3.4.8-2 packages from Debian official
repositories. It contains all the useful parts of Ubuntu packages
except upstart integration and should work fine on recent Ubuntu versions.

For older Debian/Ubuntu it is being worked on getting into the
"wheezy-backports" repository as well.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfDvuAAoJELJo5wb/XPRjBOsIAMLLsGQJ57miiTFN5OKBhF+w
ckd6MHfM9r8G3oXSSu4rg/ogBJtSj1/3hwsrGf3YAtCauGK0TIWvGwPdRAmrJgWh
dTr5AbRyADNp5SY9xf057OdIi9DqIuYROoC68OVirD6UtYGzzsNR/zUyt6puwbxA
+Sa7JYUW6Wg04kAc0HCBCe8qbdPFWSbBUlnbz0G4nulhWTGCOSIZ7jrIGvP5NIVi
c2nsWaqctPelr0IQXcx/Tbps1hWmFOotSFJ1rPWrzGt+Ope4OvcD+fzupncN62Tl
ZuWfFnjMD1CHj4R+y55nv0u95PU2RwfZVuyWIA7wPKquIx3EojDLJL72cx5H4lk=
=+gqY
-----END PGP SIGNATURE-----


From stephen.baynes at smoothwall.net  Mon Dec  1 10:08:41 2014
From: stephen.baynes at smoothwall.net (Stephen Baynes)
Date: Mon, 1 Dec 2014 10:08:41 +0000
Subject: [squid-users] Squid WCCP with multiple workers
In-Reply-To: <1417423104.14299.13.camel@localhost>
References: <CABrJVozUY6m0yF0E=yBX7u51Te5qNqPnOKXwdGC7oZbYfD=+7g@mail.gmail.com>
 <1417423104.14299.13.camel@localhost>
Message-ID: <CABrJVoyzNLhPei3Zr6V-1aLrukqRf9oaT9apr-6ZL3VJ6RNKGQ@mail.gmail.com>

Thanks for the suggestion of making wccp conditional on worker 1.
Unfortunately it does not work.

Stephen

On 1 December 2014 at 08:38, Henrik Nordstrom <hno at squid-cache.org> wrote:
> fre 2014-11-28 klockan 10:28 +0000 skrev Stephen Baynes:
>> Is WCCP supposed to work with Squid multiple workers?
>
> In theory it should work.. but not sure it has been adapted for
> multi-worker.
>
>> It works with 1 worker. If we change the number of workers from 1 to 2
>> we see it fail. The router no longer is aware of Squid and does not
>> reroute the data to the Squid box.
>
> Try making the wccp configuration conditional on worker id 1. If this
> makes a difference then Squid needs to be extended to add a internal
> wccp worker.
>
> Regards
> Henrik
>
>



-- 
Stephen Baynes CEng MBCS CITP


From squid3 at treenet.co.nz  Mon Dec  1 10:39:01 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 01 Dec 2014 23:39:01 +1300
Subject: [squid-users] squid-3.5.0.2-20141031-r13657 crashes
In-Reply-To: <HKNPR04MB193FD4B698E424FC11690E5E87C0@HKNPR04MB193.apcprd04.prod.outlook.com>
References: <HKNPR04MB193FD4B698E424FC11690E5E87C0@HKNPR04MB193.apcprd04.prod.outlook.com>
Message-ID: <547C4545.7090606@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 1/12/2014 9:44 a.m., James Harper wrote:
> I've been getting squid crashes with squid-3.5.0.2-20141031-r13657.
> Basically I think my cache got corrupt - started seeing
> TCP_SWAPFAIL_MISS and md5 mismatches. Config is cache_dir ufs
> /usr/local/squid/var/cache/squid 102400 16 256
> 
> It's possible that at one point I might have started 2 instances of
> squid running at once... could that cause corruption?

Yes, very likely. More so the longer they were both running.

I see you mention segfaults below, that can also cause it for any
objects in use at the time of the crash.

> 
> And if it happens again, what sort of things should I collect to
> better diagnose the problem?

Firstly, Squid is expected to cope with cache corruption by cleaning
up entries as it identifies them. The SWAPFAIL and MD5 details you
mention above are signs that the detection at least is occuring.

After any type of corruption these messages can be expected for a
while with an exponential drop-off in frequency as the cache gets
fixed. Only if it starts occuring with unknown cause or does not
decrease in frequency is there a serious problem to attend to (usually
a disk dying, Squid crashing a lot, or second Squid process started
wrongly).


The basic things required for bug reports
(http://wiki.squid-cache.org/SquidFaq/BugReporting). That also
includes investigation of the segfauls mentioned below.

Plus if you can the URL, HTTP request headers in full, any access.log
entry you can match up with the issue.

> As I see it there are two problems: 1. that the cache got corrupt
> in the first place 2. that a corrupt cache can crash squid

These may in fact be the reverse with cause (2) and effect (1). When a
segfault happens the details are not logged at all because the process
doing the logging is the Squid which has died.

Only in an assertion failure or exception error is Squid running well
enough and able to log why before exiting.


> 
> Unfortunately I did the stupid thing and deleted the cache without
> taking a copy for post-mortem... the best I can do is:
> 
> [31072.428922] squid[6317]: segfault at 58 ip 000000000061a6f9 sp
> 00007fff8b9e2d40 error 4 in squid[400000+4e9000] [31654.707792]
> squid[6329]: segfault at 58 ip 000000000061a6f9 sp 00007fff54358fe0
> error 4 in squid[400000+4e9000] [31783.399832] squid[6465]:
> segfault at 58 ip 000000000061a6f9 sp 00007fff82af0aa0 error 4 in
> squid[400000+4e9000] [31984.470507] squid[6509]: segfault at 58 ip
> 000000000061a6f9 sp 00007fff028a6640 error 4 in
> squid[400000+4e9000] [32178.270298] squid[6576]: segfault at 58 ip
> 000000000061a6f9 sp 00007fffe64a07e0 error 4 in
> squid[400000+4e9000] [32789.635935] squid[6626]: segfault at 58 ip
> 000000000061a6f9 sp 00007ffff6932960 error 4 in
> squid[400000+4e9000]
> 
> addr2line -e /usr/local/squid/sbin/squid 000000000061a6f9 
> /usr/local/src/squid-3.5.0.2-20141031-r13657/src/store.cc:962
> 

This looks like http://bugs.squid-cache.org/show_bug.cgi?id=4131. The
two patched posted there seem to be getting good results.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfEVFAAoJELJo5wb/XPRjgVkH/1gj4utqZanu9jtLFEaBuV9Q
c4K+pw7grL8s1CH8vKvyNZnhSiDi7FsPPaG1RQTkJplhsqswZ2rUcLkVwAEHb2Ug
cS4uH9y5nN/M+O7yqmx/29JS1ITaXnR2ooy8PctKZoYqizEIz6UhDDd2vFuKiPFJ
rlhP+gvd8fDACtZgWLnojl6OmrFXmD0RyxZE0r8Y5wQyzIkbqveJfHzRcl7hkZJh
xJLPfiakK0RBHQSEDRJg/Jui8hv2UeaqGd/YJcF+XJZW6USY6tB8sVnwd8zir6Aw
q2VVbofu2YRn7RJmUrwwppvbmQ+j9ykRS5VMFkJrDVGrf0RohIqn1d7OO3pNJu0=
=DOp+
-----END PGP SIGNATURE-----


From gkinkie at gmail.com  Mon Dec  1 10:41:02 2014
From: gkinkie at gmail.com (Kinkie)
Date: Mon, 1 Dec 2014 11:41:02 +0100
Subject: [squid-users] Multiple SSL Domains on Reverse Proxy
In-Reply-To: <1417420771.14299.10.camel@localhost>
References: <CAJbW+rn6-7XnZnSXWevSoTPmCZ4VJF89SMK6SEiXz0gv-0QO1Q@mail.gmail.com>
 <1417420771.14299.10.camel@localhost>
Message-ID: <CA+Y8hcNthAHu7vxJfE_4ZRFa9HWRq8gsUo5c1VoXB7t37o6amA@mail.gmail.com>

Hi all,
  I've created bug 4153 to track progress.


On Mon, Dec 1, 2014 at 8:59 AM, Henrik Nordstrom <hno at squid-cache.org> wrote:
>
> l?r 2014-11-29 klockan 20:39 -0500 skrev Roman Gelfand:
>> Is it possible to listen on port 443 for requests for multiple domains
>> ie... www.xyz.com, www.mno.com, etc...?
>
> If you have one IP address per domain then it's just one https_port with
> explicit ip:port per domain, with vhost or defaultdomain= telling Squid
> what hostname to use as requested host in HTTP(S).
>
> Supporting more than one domain on the same ip:port is currently only
> possible if you use a multi-domain certificate.
>
> We really should support SNI negotiation to select certificate based on
> client requested domain. SNI is a TLS extension to indicate requested
> host during TLS negotiation and is quite well supported in todays
> browsers.  Patches implemententing this are very welcome.
>
> Regards
> Henrik
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From mromani at ottotecnica.com  Mon Dec  1 13:32:54 2014
From: mromani at ottotecnica.com (Marcello Romani)
Date: Mon, 01 Dec 2014 14:32:54 +0100
Subject: [squid-users] WARNING: there are more than 100 regular
	expressions
In-Reply-To: <547C2D83.80908@treenet.co.nz>
References: <1417078626013-4668529.post@n4.nabble.com>
 <D5dthyFPCXB@helmut.hullen.de> <1417082346062-4668531.post@n4.nabble.com>
 <547715EF.5050703@solutti.com.br> <1417166614113-4668542.post@n4.nabble.com>
 <547C2D83.80908@treenet.co.nz>
Message-ID: <547C6E06.8040301@ottotecnica.com>

Il 01/12/2014 09:57, Amos Jeffries ha scritto:

[...]

> If you are importing a public list of domains to block please
> investigate whether your list source supports squid dstdomain ACL
> formats. The best lists provide files with Squid dstdomain format
> (which is also almost identical to the rbldnsd 'RHSBL' data format).
>
> Amos
>

May I suggest: http://www.squidblacklist.org/

I have been using it for almost a year now and it has done a good job 
for me. Over time I've just had to add a dozen entries and allow some 
specific URLs to tailor it to my specific company.

-- 
Marcello Romani


From dougs at dawnsign.com  Mon Dec  1 15:16:23 2014
From: dougs at dawnsign.com (Doug Sampson)
Date: Mon, 1 Dec 2014 15:16:23 +0000
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
In-Reply-To: <547C2EA9.9090900@gmail.com>
References: <E6B2517F8D6DBF4CABB8F38ACA367E783431AF29@Draco.dawnsign.com>
 <5473E101.4010907@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
 <547C2A11.6030403@treenet.co.nz> <547C2EA9.9090900@gmail.com>
Message-ID: <E6B2517F8D6DBF4CABB8F38ACA367E7834350F9E@Draco.dawnsign.com>

>    Maybe your problem is related to sysctl mib tuning about
> swap/overcommit etc. I did not observed memory leak with squid 3.4.4,
> but FB 10 do swap frequently than old version.

Could you elaborate a bit more? That went over my head. What could I do in terms of tuning the system?

~Doug

From fredbmail at free.fr  Mon Dec  1 15:52:54 2014
From: fredbmail at free.fr (FredB)
Date: Mon, 1 Dec 2014 16:52:54 +0100 (CET)
Subject: [squid-users] WARNING: there are more than 100
	regular	expressions
In-Reply-To: <1925984921.185080466.1417160539596.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1569444166.193225561.1417449174331.JavaMail.root@zimbra4-e1.priv.proxad.net>

Maybe you should use a tool that has been created for the only purpose of filtering web sites. 
Like, e2guardian, squidguard, etc

Fred


From fredbmail at free.fr  Mon Dec  1 15:53:46 2014
From: fredbmail at free.fr (FredB)
Date: Mon, 1 Dec 2014 16:53:46 +0100 (CET)
Subject: [squid-users] Problem with digest authentification and
 credential backend
In-Reply-To: <545187135.185068537.1417160237843.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <990004087.193226555.1417449226399.JavaMail.root@zimbra4-e1.priv.proxad.net>

> 
> Ok, thanks,
> 
> Tested with both nonce_count and nonce_max_duration, no problem. Do
> you known if it works with squid 3.5 ?
> 
> 

No sorry I don't know, but if the patch can be applied I guess that yes it can works.
Except if there are some changes in DIGEST between 3.4 and 3.5.


From chio1990 at gmail.com  Mon Dec  1 16:28:14 2014
From: chio1990 at gmail.com (k simon)
Date: Tue, 02 Dec 2014 00:28:14 +0800
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
In-Reply-To: <E6B2517F8D6DBF4CABB8F38ACA367E7834350F9E@Draco.dawnsign.com>
References: <E6B2517F8D6DBF4CABB8F38ACA367E783431AF29@Draco.dawnsign.com>
 <5473E101.4010907@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
 <547C2A11.6030403@treenet.co.nz> <547C2EA9.9090900@gmail.com>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834350F9E@Draco.dawnsign.com>
Message-ID: <547C971E.4@gmail.com>

   I used the ugly tuning: set vm.defer_swapspace_pageouts to 1.  But it 
is may caused some issue when the physic memory is really exhausted. I 
have no much time to investigate the right way, but I think maybe 
vm.swap_idle_threshold1/vm.swap_idle_threshold2 or vm.overcommit etc. 
maybe harmful.

Simon

? 14/12/1 23:16, Doug Sampson ??:
>>     Maybe your problem is related to sysctl mib tuning about
>> swap/overcommit etc. I did not observed memory leak with squid 3.4.4,
>> but FB 10 do swap frequently than old version.
>
> Could you elaborate a bit more? That went over my head. What could I do in terms of tuning the system?
>
> ~Doug
>


From david at articatech.com  Mon Dec  1 17:28:52 2014
From: david at articatech.com (David Touzeau)
Date: Mon, 01 Dec 2014 18:28:52 +0100
Subject: [squid-users] squid 3.5x: Active Directory accounts with space
 issue
In-Reply-To: <547AD06A.5000301@treenet.co.nz>
References: <5471BE7D.6030206@articatech.com> <5475AB0D.4030608@treenet.co.nz>
 <5479B368.4070908@articatech.com> <547AD06A.5000301@treenet.co.nz>
Message-ID: <547CA554.1000203@articatech.com>


Le 30/11/2014 09:08, Amos Jeffries a ?crit :
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 30/11/2014 12:52 a.m., David Touzeau wrote:
>> Le 26/11/2014 11:27, Amos Jeffries a ?crit : On 24/11/2014 12:01
>> a.m., David Touzeau wrote:
>>>>> Hi
>>>>>
>>>>> We have connected 3.5.0.2-20141121-r13666 with Active
>>>>> Directory. It seems where there are spaces in login account
>>>>> squid use only the last argument.
>>>>>
>>>>> For example for an account "Jhon smith" squid use "smith"
>>>>> only For example for an account "Dr Jhon smith" squid use
>>>>> "smith" only
>>>>>
>>>>> In 3.3.13 there is no such issue, a "Jhon smith" account is
>>>>> logged as "Jhon smith" and sended as Jhon%20smith to helpers
>> Any information about the auth Scheme being performed? the helpers
>> being used? and what is being sent to/from the helpers in 3.5
>> different from the 3.3 version?
>>
>> Amos
>>
>>> _______________________________________________ squid-users
>>> mailing list squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> Hi
>>
>> I'm using this method
>>
>> auth_param ntlm program /usr/bin/ntlm_auth --domain=TOUZEAU.BIZ
>> --helper-protocol=squid-2.5-ntlmssp auth_param ntlm children 25
>> startup=5 idle=1 auth_param ntlm keep_alive off #Dynamic ACLs
>> groups Enabled: [1] external_acl_type ads_group ttl=3600
>> children-max=5 children-startup=1 children-idle=1 %LOGIN
>> /usr/share/artica-postfix/external_acl_squid_ldap.php #Other
>> settings authenticate_ttl 1 hour
>> authenticate_cache_garbage_interval 10 seconds authenticate_ip_ttl
>> 60 seconds # END NTLM Parameters --------------------------------
>> #Basic authentication for other browser that did not supports
>> NTLM: (KerbAuthMethod =  ) auth_param basic program
>> /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic auth_param
>> basic children 3 startup=1 idle=1 auth_param basic realm Basic
>> Identification auth_param basic credentialsttl 2 hours
>>
>>
>> On 3.3.13, everything works as expected. On 3.5x LOGIN are
>> truncated where there is space on account.
> By "LOGIN" are you meaning the log entries for user name labels?
>   the %LOGIN format code delivered to the external ACL helper?
>   the user=X labels delivered by the NTLM helper to Squid?
>   or the generic "login" concept?
>
> The 'old' helper protocol was whitespace delimited set of fields with
> fixed meaning for each column/field. If the helper is delivering an
> un-encoded SP character inside an old-style response to Squid it will
> be parsed as two values.
>   The 3.4+ helpers are parsing that protocol and upgrading it to the
> new kv-pair protocol automatically. Garbage fields are discarded from
> the input.
>
> It looks like the 2-column AF (NTLM) response being confused for a
> 3-column AF (Kerberos) response. Since the only difference between the
> two helpers outputs is the presence of a "token" column before the
> username field.
>
> You can workaround it with a script to convert the protocol explicitly
> before delivering to Squid.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUetBqAAoJELJo5wb/XPRja6YH/1PpeTPb+BcfvWTKnsxDcy1O
> deM+KEBK3nPz2IjTj6In73cH/UIkoFZaKIOViSR8MyjFtg517mz54tQcWWMkLIUQ
> CId00veZcSlbpI1oJlg/eds6o0UXj+TZ4KpFGzLCnxLrAzwW93bneRuj6VeGUlpY
> wlWwutZKFFlY1mHfIzlOkCE0f3AJZ/bK6XKP0x6UOfCzXjX4V/MW8KyhwCJXE0rz
> Vr04GoJbMxSKR5JhMVZJV2uPteW9qFvX2efEkZA4coyV/E78YEp800et07eE+hRO
> 3O5Wswq7Lh+aZ0cMrjbdV/l4jcC/1UQnd9lM9rkiqoA3aXn63i5aUjxpbJJ9PWk=
> =uEUQ
> -----END PGP SIGNATURE-----
Thanks Amos.

I'm agree but helper answer just to OK if the user is a member of a 
group it doesn't send user=something
After removing the helper, Squid still write the truncated login
So i'm talking about the generic login concept.


From florent1818 at hotmail.com  Mon Dec  1 19:28:43 2014
From: florent1818 at hotmail.com (fzab_)
Date: Mon, 1 Dec 2014 11:28:43 -0800 (PST)
Subject: [squid-users] Forward proxy with BASIC authentication
Message-ID: <1417462123236-4668592.post@n4.nabble.com>

Hi,
I want to use Squid locally on my computer to forward all traffic to a
parent Squid proxy which uses BASIC authentication. The aim is to not store
my password on every configuration file that needs internet access.

So here's the only lines I added to Squid default conf file :

/cache_peer x.x.x.x   parent  3128 0 no-query default  login=login:password 
no-digest 
never_direct allow all/

It seems to work for a few minutes, but it doesn't seem to authenticate
again when needed to. The access log shows 407 errors when it breaks. :

/297 127.0.0.1 TCP_MISS/407 2071 GET http://...../

Am I missing something, when I take a look at the sent requests, none have
an authentication header?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Forward-proxy-with-BASIC-authentication-tp4668592.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Mon Dec  1 20:20:56 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 01 Dec 2014 22:20:56 +0200
Subject: [squid-users] WARNING: there are more than 100 regular
	expressions
In-Reply-To: <1417078626013-4668529.post@n4.nabble.com>
References: <1417078626013-4668529.post@n4.nabble.com>
Message-ID: <547CCDA8.3080706@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey,

As the warning suggests you better use less REGEX and specifically
dstdom_regex is not recommends.
If you have more then 100 of them you should just verify that these
are really a good solution.
You can use an external_acl helper with long ttl cache and it would
let you to update the regex or checks outside of squid.

If you have these regex and you know you will not update them fast use
some external_acl helper based only on domain name.

If you can share these urls maybe there is a chance that I or others
can suggest to you the right path.

All The Bests,
Eliezer

On 11/27/2014 10:57 AM, navari.lorenzo at gmail.com wrote:
> Good day, i have these Warnings
> 
> squid -k parse
> 
> .......... 2014/11/27 09:36:22| Processing: acl direct_urls
> dstdom_regex "/etc/squid/direct_urls.txt" 2014/11/27 09:36:22|
> /etc/squid/squid.conf line 86: acl direct_urls dstdom_regex
> "/etc/squid/direct_urls.txt" 2014/11/27 09:36:22| WARNING: there
> are more than 100 regular expressions. Consider using less REs or
> use rules without expressions like 'dstdomain'. 
> .................... 2014/11/27 09:36:22| Processing: acl
> allowed_sitesmime dstdom_regex "/etc/squid/allowed_sitesmime.txt" 
> 2014/11/27 09:36:22| /etc/squid/squid.conf line 94: acl
> allowed_sitesmime dstdom_regex 	"/etc/squid/allowed_sitesmime.txt" 
> 2014/11/27 09:36:22| WARNING: there are more than 100 regular
> expressions. Consider using less REs or use rules without
> expressions like 'dstdomain'.
> 
> 
> What can i do ?
> 
> Thank to everybody.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUfM2oAAoJENxnfXtQ8ZQUNWQIAJrdvqA1xauwZg4PLsHmVVp6
MXVqsO63YTkaM84TlOcdLYmsX0CUky2j7APGUJT6xt4P3fgDLmJOaXHXqapWcm/9
rAgAj7qewzlx6HRH34sbKUj9ho8xsVEnuSu6tJQ7LV0pw/VVe1BuD3u5xup+iTxF
AcPx86Y4mVShcHq6pFSp40QVJ+olBCq4vhgRxjkyvLWVNOmx1EiiWRqRwsMZDb/Q
AvWxu2h0J4ffm3m8AneJlkqcJ6qfpn5ORVDr9qvMP1mKmAS0w/1Rl+S/AAWqeSbO
qLFqb8HO6tBTRFgPJm2VmzNGLTx04rGly6VL5lkdzbf18FaCy1Vgsj8XU/KRbUA=
=b070
-----END PGP SIGNATURE-----


From signup_mail2002 at yahoo.com  Mon Dec  1 21:48:46 2014
From: signup_mail2002 at yahoo.com (WorkingMan)
Date: Mon, 1 Dec 2014 21:48:46 +0000 (UTC)
Subject: [squid-users] =?utf-8?q?sslcrtvalidator=5Fprogram?=
Message-ID: <loom.20141201T224144-430@post.gmane.org>

Spam detection software, running on the system "master.squid-cache.org",
has identified this incoming email as possible spam.  The original
message has been attached to this so you can view it or label
similar future email.  If you have any questions, see
@@CONTACT_ADDRESS@@ for details.

Content preview:  I am using sample validator script called cert_valid.pl. Everything
   is working as is (I can see stuff in the log in debug mode) but I could not
   change the behavior when there is an error. For example when I receive an
   error (X509_V_ERR_UNABLE_TO_VERIFY_LEAF_SIGNATURE) that I want to return
  OK instead of ERR but SQUID still shows the error page in the browser. [...]
   

Content analysis details:   (5.6 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
 1.0 FORGED_YAHOO_RCVD      'From' yahoo.com does not match 'Received' headers
 0.0 FREEMAIL_FROM          Sender email is commonly abused enduser mail provider
                            (signup_mail2002[at]yahoo.com)
 0.0 URIBL_BLOCKED          ADMINISTRATOR NOTICE: The query to URIBL was blocked.
                            See
                            http://wiki.apache.org/spamassassin/DnsBlocklists#dnsbl-block
                             for more information.
                            [URIs: cert_valid.pl]
 0.9 SPF_FAIL               SPF: sender does not match SPF record (fail)
[SPF failed: Please see http://www.openspf.org/Why?s=mfrom;id=gcwsg-squid-users%40m.gmane.org;ip=192.0.186.121;r=master.squid-cache.org]
 0.9 RCVD_NUMERIC_HELO      Received: contains an IP address used for HELO
 0.0 T_HEADER_FROM_DIFFERENT_DOMAINS From and EnvelopeFrom 2nd level mail
                            domains are different
 0.0 UNPARSEABLE_RELAY      Informational: message has unparseable relay lines
 0.0 T_FREEMAIL_FORGED_FROMDOMAIN 2nd level domains in From and
                            EnvelopeFrom freemail headers are different
 1.3 RDNS_NONE              Delivered to internal network by a host with no rDNS
 1.5 FSL_HELO_BARE_IP_2     No description available.


-------------- next part --------------
An embedded message was scrubbed...
From: WorkingMan <signup_mail2002 at yahoo.com>
Subject: sslcrtvalidator_program
Date: Mon, 1 Dec 2014 21:48:46 +0000 (UTC)
Size: 2336
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141201/c64bd8d9/attachment.eml>

From vdoctor at neuf.fr  Tue Dec  2 15:09:47 2014
From: vdoctor at neuf.fr (Stakres)
Date: Tue, 2 Dec 2014 07:09:47 -0800 (PST)
Subject: [squid-users] Squid 3.4.x Videos/Music Booster
In-Reply-To: <1415701988960-4668310.post@n4.nabble.com>
References: <1401445017211-4666154.post@n4.nabble.com>
 <1402342920545-4666272.post@n4.nabble.com>
 <CAOoxthOFdUyjpPcyNYx6maQ=8EJuX8LCm6EjFRQ6ySt4fUaRXQ@mail.gmail.com>
 <CAOoxthNhLP26KUWVy+OpPobQgb6oeU-Y7cQ+dMvghXXWfNrz=w@mail.gmail.com>
 <1402470426333-4666302.post@n4.nabble.com>
 <1402558228027-4666310.post@n4.nabble.com>
 <1412234862102-4667630.post@n4.nabble.com>
 <1415701988960-4668310.post@n4.nabble.com>
Message-ID: <1417532987530-4668595.post@n4.nabble.com>

Hi All,

Here we go with the new  version 2.00
<https://sourceforge.net/projects/squidvideosbooster/>  

What's news:
- *Independent Squid plugin* that does not need the Cloud API anymore
- Compatible Debian/Ubuntu 32/64bits and CentOS 64bits
- "porn=0/1" option removed
- Taking care 500+ web sites: http://www.unveiltech.com/videosboost.php

Enjoy 

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-4-x-Videos-Music-Booster-tp4666154p4668595.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From steve at opendium.com  Tue Dec  2 15:40:53 2014
From: steve at opendium.com (Steve Hill)
Date: Tue, 02 Dec 2014 15:40:53 +0000
Subject: [squid-users] RFC2616 headers in bumped requests
In-Reply-To: <547AC9EC.6010800@treenet.co.nz>
References: <5458A7D6.3090502@opendium.com> <5458DBD0.2050306@treenet.co.nz>
 <5469CD2B.8080802@opendium.com> <546A7111.70605@treenet.co.nz>
 <546DC79F.5040300@opendium.com> <547AC9EC.6010800@treenet.co.nz>
Message-ID: <547DDD85.3010504@opendium.com>

On 30.11.14 07:40, Amos Jeffries wrote:

> Just to followup, there will not be a permanent change made to Squid
> because:

That's fair enough - my initial diagnosis was basically "the server's 
broken", but I thought it was worth having a debate about the merits of 
modifying the contents of a bumped connection, in light of the fact that 
at least one such broken server exists and that it probably isn't 
completely unreasonable for the endpoints to assume they have a 
transparent tunnel.

(Another perennial problem that comes from the assumption of a 
transparent tunnel is clients making websockets connections over https, 
which of course won't work through a bumped connection since Squid 
doesn't support HTTP upgrade requests)

Many thanks.

-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Direct contacts:
    Instant messager: xmpp:steve at opendium.com
    Email:            steve at opendium.com
    Phone:            sip:steve at opendium.com

Sales / enquiries contacts:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support contacts:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From giorgi at mia.gov.ge  Wed Dec  3 06:09:15 2014
From: giorgi at mia.gov.ge (Giorgi Tepnadze)
Date: Wed, 03 Dec 2014 10:09:15 +0400
Subject: [squid-users] Problem with access.log and when using SMP
In-Reply-To: <547AB72F.9030303@treenet.co.nz>
References: <5475C6BA.5000008@mia.gov.ge> <547AB72F.9030303@treenet.co.nz>
Message-ID: <547EA90B.3080709@mia.gov.ge>

 From squid config:

access_log daemon:/var/log/squid3/access.log squid
logfile_daemon /usr/lib/squid3/log_file_daemon

So I am using daemon. At this moment it would take some time to develop 
new daemon, but I have other question, is it possible to give each 
running squid kid different access.log file to write?

George Tepnadze

On 11/30/2014 10:20 AM, Amos Jeffries wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 27/11/2014 1:25 a.m., Giorgi Tepnadze wrote:
>> Hello,
>>
>> I have own squid log parsing software which worked flawlessly
>> before we moved to squid 3.3.8 (old was 2.7). Log parser stopped
>> working. This is the problem I found.
>>
>> Problem lines: 1416971036.802 184393 10.xx.xx.xx TCP_MISS/200 10963
>> CONNECT pixel.facebook.com:1416971036.390      0 10.yy.yy.yy
>> TCP_DENIED/407 3751 CONNECT clients4.google.com:443 - HIER_NONE/-
>> text/html 1416971036.645   7164 10.zz.zz.zz TCP_MISS/200 55438 GET
>> http://s40.radikal.ru/i089/1107/9b/2fbf1779ead9.jpg
>> user at domain.com HIER_DIRECT/81.176.238.141 image/jpeg 443
>> user2 at domainc.com HIER_DIRECT/31.13.93.3 -
>>
>> As it should be: 1416971036.390      0 10.yy.yy.yy TCP_DENIED/407
>> 3751 CONNECT clients4.google.com:443 - HIER_NONE/- text/html
>> 1416971036.802 184393 10.xx.xx.xx TCP_MISS/200 10963 CONNECT
>> pixel.facebook.com:443 user2 at domainc.com HIER_DIRECT/31.13.93.3 -
>> 1416971036.645   7164 10.zz.zz.zz TCP_MISS/200 55438 GET
>> http://s40.radikal.ru/i089/1107/9b/2fbf1779ead9.jpg
>> user at domain.com HIER_DIRECT/81.176.238.141 image/jpeg
>>
>> I think that's because of SMP as I have 4 squid kids running and
>> they all write to same access.log file and there is concurrency
>> problem. Sometimes one is writing log line when previous log line
>> is not finished yet or something like this. Such errors are rare
>> but enough to stop my parser with  error.
>>
>> Is it a bug? Is there any workaround or solution?
> What logging module are you using to write?
>
> Squid log lines are generated into a buffer and emitted in what should
> be close to atomic (but not exactly locking) per-line write() actions.
>
> You could write a custom daemon to receive the log lines and send them
> directly through your parser system as units. This has the added
> benefit of being a lot closer to real-time log processing.
>
> Amos
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUercvAAoJELJo5wb/XPRjZVEH/RtrMBTH5XfPi6MmIVf2/Yzb
> DZg+ObG64J/SmWMc99YvTL8Bg5SrB4GNKZEt5JM3jKYOkjS1lg7G90JUfwmHi8xI
> xnX/+iayr19QVmdRb5LNZdpgn1spCoodq9RXQKVLKQnxvYVrV5SCnPx51xeevG2g
> X7gBa+l/nltEQy1cc2Dc5UScvMHdXh8tShG8CINX/oyXr6XM0qa8jCe3Tczq966K
> GsEnicp017lwSDVSiXPU866Gf/3xexXGUzPIxlWe3OIbEwp/LP0U63jaF2lUz6cu
> xY10bAUbOTGE76UmhHRSmePlhZcWwsHHwbXy7Z5OQCe2UX/MRIZYzN7GkqSVgf4=
> =iKx3
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Dec  3 12:15:02 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 04 Dec 2014 01:15:02 +1300
Subject: [squid-users] Problem with access.log and when using SMP
In-Reply-To: <547EA90B.3080709@mia.gov.ge>
References: <5475C6BA.5000008@mia.gov.ge> <547AB72F.9030303@treenet.co.nz>
 <547EA90B.3080709@mia.gov.ge>
Message-ID: <547EFEC6.5060003@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 3/12/2014 7:09 p.m., Giorgi Tepnadze wrote:
> From squid config:
> 
> access_log daemon:/var/log/squid3/access.log squid logfile_daemon
> /usr/lib/squid3/log_file_daemon
> 
> So I am using daemon. At this moment it would take some time to
> develop new daemon, but I have other question, is it possible to
> give each running squid kid different access.log file to write?

Yes.

 access_log daemon:/var/log/squid3/access_${process_name}.log squid

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfv7FAAoJELJo5wb/XPRj090IALNcrIcf1GT0h05sflD1l4p7
QMIVfkjAlF0twSAExnjnVMsE84rq+WqHgNh962uUW5ANdMHd2vDfGiKlWrWXSzR+
YZ2pZh+mCVov4xE7gUWZvppfWe5ZJDLT7EVcxD0CgF+sNFENotpuyxltWIUCFkXn
lGUan/HrsawhAphtK0h5qp3gvpq/wDXUUwuSVLpzzxoROfFCCrqRMrcqMiBBQ13f
+Jz6QsYIAeEgfHsYP8s2uc3Gyf+2rGUvT8PV0zG76dpFob6m+1iDh2J8VxeS+W/r
W9pmKSxC+DiAV0aBb6X1R9uYUOXswW3PTd/HkCqfHEjNQ2gGu5FTSHCcnXmOjhE=
=5yxa
-----END PGP SIGNATURE-----


From m.riede at babiel.com  Wed Dec  3 14:49:34 2014
From: m.riede at babiel.com (Mark Riede)
Date: Wed, 3 Dec 2014 14:49:34 +0000
Subject: [squid-users] 2.7.STABLE9 & Error with option deny_info from
 local requests
In-Reply-To: <547C359A.604@treenet.co.nz>
References: <166D4EE577088449BA7DD4367005D8642E1BF4AA@s015011.office.babiel.com>
 <547C359A.604@treenet.co.nz>
Message-ID: <166D4EE577088449BA7DD4367005D8642E1D10E1@s015011.office.babiel.com>

> On 29/11/2014 2:40 a.m., Mark Riede wrote:
> > Hello,
> > 
> > I have a strange behavior with Squid 2.7.STABLE9 and local requests 
> > which should be intercept by the option deny_info.
> > 

> 1) *Please* upgrade your Squid. 2.7 has been unsupported for more than 5 years now and is seriously out of date with modern web traffic needs.
That is not an option. We are already migrating to an other software.

> 2) "intercept" and how deny_info works are completely unrelated concepts.
"intercept" was the wrong word. The word "match" ist more appropiate.

> > I am using Squid as a reverse proxy. I have configured a list of 
> > subdomains (i.e. subdomain.domain.tld) in a file via the option 
> > dstdomain, which will be forwarded to the defined cache peer.
> > There is an additional list of domains (i.e. *.domain.tld) which match 
> > via wildcard to all other domains, which are not absolutely defined 
> > yet and will be forwarded to a custom error page via the option 
> > deny_info.
> > 
> > The problem is that requests forwarded to the ip of the server, i.e. 
> > 192.168.0.1, will be catched up by the option deny_info. But, when the 
> > request is forwarded to the ip of the localhost (127.0.0.1), the 
> > option deny_info will not match.

> ?? *all* traffic to the cache_peer is "forwarded to the ip 127.0.0.1"
> since that IP *is* the cache_peer's IP.
Ok, I think it needs a little bit more explanation.
External requests will be forwarded via nat to internal IP 192.168.0.1 and the option deny_info works well.
But when the nginx sends a request to the squid with the destination IP 127.0.0.1 the option deny_info does not work.

> 127.0.0.1 (and ::1) are special purpose IP addresses. Traffic is not permitted to go to/from it from a global-scope IP address. When you send to/from a localhost IP then it is mandatory for the TCP system to use the localhost IP as source.


> > Now the strange behaviour is that requests to the ip of the localhost 
> > but with the destination domain subdomain.domain.tld will be answered 
> > successfully. I need a fix because clients get the custom error page 
> > for requests via http (NAT to 192.168.0.1) but not the same response 
> > via https (nginx to 127.0.0.1). I don?t know where or how I can fix 
> > this problem or do more debugging.


> Why is nginx not forwarding proper HTTP messages with the relevant
> Host: header contents to Squid? the HTTP message syntax is no different when sent over TLS port 443 as when sent over TCP port 80.
Nginx is forwarding the request with a proper HTTP-Header because the option cache_peer is working well. We are able to cache HTTPS-Requests so far.
It seems that the option deny_info does not work well. 

> - From your description it sounds like nginx is sending to Squid messages with URL https://127.0.0.1/* which cannot be expected to exist in your list of acceptible domains.

> Also, why are you not using Squid to receive and direct both HTTP and HTTPS traffic to the relevant servers?
>  Squid accepts port 443 traffic with an https_port directive just fine.
Because we are using the Squid for multiple clients and Squid in our version ist not able to handle multiple certificates.

> > 
> > # Config http_access allow localhost

> The above rule permits all traffic from 127.0.0.1 to go through this proxy *no matter what*. From your description that would be all traffic arriving from nginx **AND** any traffic you direct at
> 127.0.0.1 IP from any other software.
Thank you for your consideration. I will consider it.

> It is a very bad thing to do, particularly for a reverse-proxy. Remove it and traffic from nginx (and yoru 127.0.0.1 tests) will start to obey the other rules. Not a complete fix, but required for Squid to work as you expect.

> > acl foo dstdomain "/file" acl foo_deny dstdom_regex "/ file _deny" 
> > http_access allow foo

> When testing this ACL with a raw-IP Squid will lookup reverse-DNS of the IPand compare the result with contents of /file.
> Meaning 127.0.0.1 == "localhost" --> is "localhost" one of the peer hosted domain names? should not be.
Which version was in use?
Is it possible to override this behaviour?
I don?t think it is the right location of the problem. Everything works well except the option deny_info.

> > cache_peer 127.0.0.1 parent 8080 0 no-query originserver name=srv1
> login=PASS
> > cache_peer_access srv1 allow foo cache_peer_access srv1 deny all 
> > deny_info ERR_FOO foo_deny http_access deny foo_deny http_access deny 
> > all
> <snip>

> The rest of these rules match your intended behaviour of Squid.

> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)

> iQEcBAEBAgAGBQJUfDWaAAoJELJo5wb/XPRjfEYH/1KMTu400wRO0wmz6RURlUwB
> 6jVEqWGc+rYV1hvtjZe5PtvJW8nMxF6idP0SU2aj/GWoGmcusrq413sAsoQhwEYT
> lGAlDhU08c6aQ5r7ZyNY9TMNip8OJS6NPYEWV07Nw34QuJcQXbHUEC9VTAjboQqa
> VYfnrBZIbMXFY3wkdhGkyNm4m/Uz5scOZ2lKAVabhZ4wHEu/NVMYISD3mEIHNiT7
> rLT9/dqZaj/KHn1Vb5Z31k3szija9ZMh2Gu6A5tg3TfpelBVrbCXFOzoHIJMN7es
> eRScL64c2KZ1PMpTMrTUzq1ILcOIuXcVDSdcj610Tcp524u0ssQ1vteJqj8kFak=
> =8Dhf
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Wed Dec  3 14:58:35 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 04 Dec 2014 03:58:35 +1300
Subject: [squid-users] Forward proxy with BASIC authentication
In-Reply-To: <1417462123236-4668592.post@n4.nabble.com>
References: <1417462123236-4668592.post@n4.nabble.com>
Message-ID: <547F251B.2000501@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 2/12/2014 8:28 a.m., fzab_ wrote:
> Hi, I want to use Squid locally on my computer to forward all
> traffic to a parent Squid proxy which uses BASIC authentication.
> The aim is to not store my password on every configuration file
> that needs internet access.
> 
> So here's the only lines I added to Squid default conf file :
> 
> /cache_peer x.x.x.x   parent  3128 0 no-query default
> login=login:password no-digest never_direct allow all/
> 
> It seems to work for a few minutes, but it doesn't seem to
> authenticate again when needed to. The access log shows 407 errors
> when it breaks. :
> 
> /297 127.0.0.1 TCP_MISS/407 2071 GET http://...../
> 
> Am I missing something, when I take a look at the sent requests,
> none have an authentication header?

All requests from Squid to its cache_peer should have the header:
 Proxy-Authorization: Basic bG9naW46cGFzc3dvcmQg

(bG9naW46cGFzc3dvcmQg being base64 encoded string "login:password").

If you are getting a 407 *from the peer*, that means either it does
not want Basic auth or the login:password details are incorrect. Squid
supports only Kerberos or Basic auth to peers, not Digest or NTLM.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfyUbAAoJELJo5wb/XPRjhIgH/0EIPR2SJIPZpVGzzs6C1Bj9
EEWJ1w/oIp2fYKm7raB2kLp8xLLSIxc4a6s8od5UD4R9OyiQECqjCWO/sub9lsK4
GqX/anIxct8vDJb82jIe4qjFVi4SLA0YvBavgMV71yH4j7pSZRRdM/EKqdYMeq4F
Rrm2Xdfec/LXYP2EYFcPssT7XjjuH2qne2RgPAhtcfnEFnYMjmOHy56lGuiMkjTd
ftN0LuoTmIPR8zBzV+DXaaPHmajpLgtr8Onh89pYNULqsOqWgKXeXIm3UQtTu01e
O7Ni8fWLV8kDMKYbdCfWxPKb8OUU3INoUzgi0S9LjluoDD3E4wnnzoX/jIzJ1X0=
=fx/l
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Wed Dec  3 15:38:37 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 04 Dec 2014 04:38:37 +1300
Subject: [squid-users] 2.7.STABLE9 & Error with option deny_info from
 local requests
In-Reply-To: <166D4EE577088449BA7DD4367005D8642E1D10E1@s015011.office.babiel.com>
References: <166D4EE577088449BA7DD4367005D8642E1BF4AA@s015011.office.babiel.com>
 <547C359A.604@treenet.co.nz>
 <166D4EE577088449BA7DD4367005D8642E1D10E1@s015011.office.babiel.com>
Message-ID: <547F2E7D.2030902@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 4/12/2014 3:49 a.m., Mark Riede wrote:
>>> 
>>> # Config http_access allow localhost
> 
>> The above rule permits all traffic from 127.0.0.1 to go through
>> this proxy *no matter what*. From your description that would be
>> all traffic arriving from nginx **AND** any traffic you direct
>> at 127.0.0.1 IP from any other software.
> Thank you for your consideration. I will consider it.
> 
>> It is a very bad thing to do, particularly for a reverse-proxy.
>> Remove it and traffic from nginx (and yoru 127.0.0.1 tests) will
>> start to obey the other rules. Not a complete fix, but required
>> for Squid to work as you expect.
> 
>>> acl foo dstdomain "/file" acl foo_deny dstdom_regex "/ file
>>> _deny" http_access allow foo
> 
>> When testing this ACL with a raw-IP Squid will lookup reverse-DNS
>> of the IPand compare the result with contents of /file. Meaning
>> 127.0.0.1 == "localhost" --> is "localhost" one of the peer
>> hosted domain names? should not be.
> Which version was in use? Is it possible to override this
> behaviour?

Only after an upgrade to a current Squid-3 version for the DNS
no-lookup feature.

You do not actually need the "http_access allow localhost" line at all
though. All it seems to be doing is causing this problem.

If you were perhapse relying on it for access to the Squid cachemgr
reports, then replace it with this:
  acl mgr url_regex -i ^cache_object://
  http_access allow localhost mgr


> I don?t think it is the right location of the problem. Everything
> works well except the option deny_info.

The "deny_info ... foo_deny" is just an instruction/directive on the
"foo_deny" ACL to what will happen IF (and only IF) foo_deny is used
in http_access to deny a request.

If the either of the previous http_access allow lines are being acted
on then it will not happen.

"allow localhost" will act on 127.0.0.1/localhost nginx requests in
your config. Causing the foo_deny never to be enacted. Causing the
deny_info to not happen. See?


Assuming Nginx is presenting Squid with correct Host headers then
removing the "http_access allow localhost" is all you need to fix the
deny_info problem.

After changing that you may still see some *other* errors with traffic
from Nginx. For those you will need to investigate the Host header in
those requests and decide what is the right thing to be done to fix
that other problem.

HTH
Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfy59AAoJELJo5wb/XPRjGzwIANhBfDa56/sjgMvx2mlvUasV
Oet0PGyFfdCkaY+cKcFIxERWUnAripXhK0JdasQ7795uOZRMIKbTVYy6mKF8/EoN
HsIkW6VaKJ3x15E1kebKSIqANcpcWl0nX6SrswODJGRG561QcXdSZ+k1NwOOPWpv
YbBKRcVs5WhW+AaRh+e9bLU/K152PVyY44A6/sY7MavhmMc91EIxgrw77v3tUIus
HIm4Lidr6D868iRqnimVu7TRCZnHwCWInYv0sy7gFQU5/EEh6nOrWRceJ9MYHU2k
bFjh4t+ixGBcYv0NwnXVOaC1mise/VoCitjWmZ9zbooQby/d7B3mooIpDJXF8uE=
=RwXb
-----END PGP SIGNATURE-----


From vdoctor at neuf.fr  Wed Dec  3 17:32:45 2014
From: vdoctor at neuf.fr (Stakres)
Date: Wed, 3 Dec 2014 09:32:45 -0800 (PST)
Subject: [squid-users] Squid 3.4.x Videos/Music Booster
In-Reply-To: <1417532987530-4668595.post@n4.nabble.com>
References: <1401445017211-4666154.post@n4.nabble.com>
 <1402342920545-4666272.post@n4.nabble.com>
 <CAOoxthOFdUyjpPcyNYx6maQ=8EJuX8LCm6EjFRQ6ySt4fUaRXQ@mail.gmail.com>
 <CAOoxthNhLP26KUWVy+OpPobQgb6oeU-Y7cQ+dMvghXXWfNrz=w@mail.gmail.com>
 <1402470426333-4666302.post@n4.nabble.com>
 <1402558228027-4666310.post@n4.nabble.com>
 <1412234862102-4667630.post@n4.nabble.com>
 <1415701988960-4668310.post@n4.nabble.com>
 <1417532987530-4668595.post@n4.nabble.com>
Message-ID: <1417627965623-4668602.post@n4.nabble.com>

Hi All,

New  build 2.01 <https://sourceforge.net/projects/squidvideosbooster/>  
avilable.

Version 2.01 - December 4th 2014
- Standalone program with no addtional library needed (no external libraries
anymore)
- Independent Squid plugin that does not need the Cloud API anymore
- Compatible All Linux distri., (tested under Debian/Ubuntu/CentOS 64bits
and Debian 32bits)
- "porn=0/1" option removed
- New option "-v" to display the version of the plugin
- Taking care 500+ web sites: http://www.unveiltech.com/videosboost.php

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-4-x-Videos-Music-Booster-tp4666154p4668602.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From james at ejbdigital.com.au  Thu Dec  4 09:09:52 2014
From: james at ejbdigital.com.au (James Harper)
Date: Thu, 4 Dec 2014 09:09:52 +0000
Subject: [squid-users] squid-3.5.0.2-20141031-r13657 crashes
In-Reply-To: <547C4545.7090606@treenet.co.nz>
References: <HKNPR04MB193FD4B698E424FC11690E5E87C0@HKNPR04MB193.apcprd04.prod.outlook.com>
 <547C4545.7090606@treenet.co.nz>
Message-ID: <HKNPR04MB1932E24A11635FF58B92C26E8780@HKNPR04MB193.apcprd04.prod.outlook.com>

> > It's possible that at one point I might have started 2 instances of
> > squid running at once... could that cause corruption?
> 
> Yes, very likely. More so the longer they were both running.
> 
> I see you mention segfaults below, that can also cause it for any
> objects in use at the time of the crash.

The latter is more likely. This had happened several times before I patched it so I doubt I managed to run multiple squid instances on more than one occasion.

> >
> > addr2line -e /usr/local/squid/sbin/squid 000000000061a6f9
> > /usr/local/src/squid-3.5.0.2-20141031-r13657/src/store.cc:962
> >
> 
> This looks like http://bugs.squid-cache.org/show_bug.cgi?id=4131. The
> two patched posted there seem to be getting good results.
> 

I applied the patch a few days ago and haven't seen the problem since. I'm still unsure which problem was causing the other though.

Thanks

James

From m.riede at babiel.com  Thu Dec  4 12:55:42 2014
From: m.riede at babiel.com (Mark Riede)
Date: Thu, 4 Dec 2014 12:55:42 +0000
Subject: [squid-users] 2.7.STABLE9 & Error with option deny_info from
 local requests
In-Reply-To: <547F2E7D.2030902@treenet.co.nz>
References: <166D4EE577088449BA7DD4367005D8642E1BF4AA@s015011.office.babiel.com>
 <547C359A.604@treenet.co.nz>
 <166D4EE577088449BA7DD4367005D8642E1D10E1@s015011.office.babiel.com>
 <547F2E7D.2030902@treenet.co.nz>
Message-ID: <166D4EE577088449BA7DD4367005D8642E1D39A2@s015011.office.babiel.com>

That was the fix. I?ve removed the line ' http_access allow localhost'.
Thank you.

-----Urspr?ngliche Nachricht-----
Von: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Gesendet: Mittwoch, 3. Dezember 2014 16:39
An: Mark Riede; 'squid-users at lists.squid-cache.org'
Betreff: Re: AW: [squid-users] 2.7.STABLE9 & Error with option deny_info from local requests

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 4/12/2014 3:49 a.m., Mark Riede wrote:
>>> 
>>> # Config http_access allow localhost
> 
>> The above rule permits all traffic from 127.0.0.1 to go through this 
>> proxy *no matter what*. From your description that would be all 
>> traffic arriving from nginx **AND** any traffic you direct at 
>> 127.0.0.1 IP from any other software.
> Thank you for your consideration. I will consider it.
> 
>> It is a very bad thing to do, particularly for a reverse-proxy.
>> Remove it and traffic from nginx (and yoru 127.0.0.1 tests) will 
>> start to obey the other rules. Not a complete fix, but required for 
>> Squid to work as you expect.
> 
>>> acl foo dstdomain "/file" acl foo_deny dstdom_regex "/ file _deny" 
>>> http_access allow foo
> 
>> When testing this ACL with a raw-IP Squid will lookup reverse-DNS of 
>> the IPand compare the result with contents of /file. Meaning
>> 127.0.0.1 == "localhost" --> is "localhost" one of the peer hosted 
>> domain names? should not be.
> Which version was in use? Is it possible to override this behaviour?

Only after an upgrade to a current Squid-3 version for the DNS no-lookup feature.

You do not actually need the "http_access allow localhost" line at all though. All it seems to be doing is causing this problem.

If you were perhapse relying on it for access to the Squid cachemgr reports, then replace it with this:
  acl mgr url_regex -i ^cache_object://
  http_access allow localhost mgr


> I don?t think it is the right location of the problem. Everything 
> works well except the option deny_info.

The "deny_info ... foo_deny" is just an instruction/directive on the "foo_deny" ACL to what will happen IF (and only IF) foo_deny is used in http_access to deny a request.

If the either of the previous http_access allow lines are being acted on then it will not happen.

"allow localhost" will act on 127.0.0.1/localhost nginx requests in your config. Causing the foo_deny never to be enacted. Causing the deny_info to not happen. See?


Assuming Nginx is presenting Squid with correct Host headers then removing the "http_access allow localhost" is all you need to fix the deny_info problem.

After changing that you may still see some *other* errors with traffic from Nginx. For those you will need to investigate the Host header in those requests and decide what is the right thing to be done to fix that other problem.

HTH
Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUfy59AAoJELJo5wb/XPRjGzwIANhBfDa56/sjgMvx2mlvUasV
Oet0PGyFfdCkaY+cKcFIxERWUnAripXhK0JdasQ7795uOZRMIKbTVYy6mKF8/EoN
HsIkW6VaKJ3x15E1kebKSIqANcpcWl0nX6SrswODJGRG561QcXdSZ+k1NwOOPWpv
YbBKRcVs5WhW+AaRh+e9bLU/K152PVyY44A6/sY7MavhmMc91EIxgrw77v3tUIus
HIm4Lidr6D868iRqnimVu7TRCZnHwCWInYv0sy7gFQU5/EEh6nOrWRceJ9MYHU2k
bFjh4t+ixGBcYv0NwnXVOaC1mise/VoCitjWmZ9zbooQby/d7B3mooIpDJXF8uE=
=RwXb
-----END PGP SIGNATURE-----

From nicolas.langlois at rouen.archi.fr  Thu Dec  4 14:19:10 2014
From: nicolas.langlois at rouen.archi.fr (LANGLOIS Nicolas)
Date: Thu, 4 Dec 2014 14:19:10 +0000
Subject: [squid-users] SQUID 3.1.20 TunnelStateData::Connection::error
 read/write failure: (32) Broken pipe
Message-ID: <E5B6AD485ECDEC469A7AA6CFF504EF66095D4B95@EXCH1.admin.rouen.archi.fr>

Hi, im using squid On a debian server as simple proxy/cache  and  sometimes some clients get a connection error, i can't reproduce the problem and don' t really know where it can come from

Here is a Squid cache.log  output :

2014/12/04 14:46:14| TunnelStateData::Connection::error: FD 232: read/write failure: (32) Broken pipe
2014/12/04 15:09:13| TunnelStateData::Connection::error: FD 285: read/write failure: (32) Broken pipe

Anyone has an idea or at least know what it mean ?


Nicolas
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141204/c540b171/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec  4 14:56:06 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 05 Dec 2014 03:56:06 +1300
Subject: [squid-users] SQUID 3.1.20 TunnelStateData::Connection::error
 read/write failure: (32) Broken pipe
In-Reply-To: <E5B6AD485ECDEC469A7AA6CFF504EF66095D4B95@EXCH1.admin.rouen.archi.fr>
References: <E5B6AD485ECDEC469A7AA6CFF504EF66095D4B95@EXCH1.admin.rouen.archi.fr>
Message-ID: <54807606.9000007@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 5/12/2014 3:19 a.m., LANGLOIS Nicolas wrote:
> Hi, im using squid On a debian server as simple proxy/cache  and
> sometimes some clients get a connection error, i can't reproduce
> the problem and don' t really know where it can come from
> 
> Here is a Squid cache.log  output :
> 
> 2014/12/04 14:46:14| TunnelStateData::Connection::error: FD 232:
> read/write failure: (32) Broken pipe 2014/12/04 15:09:13|
> TunnelStateData::Connection::error: FD 285: read/write failure:
> (32) Broken pipe
> 
> Anyone has an idea or at least know what it mean ?

It means either the client or server attached to that tunnel
disconnected while there was still traffic flowing. Nothing Squid can
do about it.

PS. You should try to upgrade your Squid. Debian is currently shipping
3.3.8 (in Wheezy/stable) and 3.4.8 (in Jesse/testing) versions. The
latest will give you IP:port to further investigate if its not
resolved by the upgrade.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUgHYEAAoJELJo5wb/XPRjSnsH/Awlzz3Uy2nydneUgxI56qVr
xRe0w8t2LY9WHos7hZyt2Spx/jgb5gjMe1liv6A7ca2vJWKNpgNw2kj9ciwy5LQq
nTC97LUlxcyvKjHFhcYqswnlMKUi0P/B+vWr7ijqYAuoQaG/eMYJ5itg4SmsvoBR
lCtwfhm4EBDpAcd8Y39vr1Qx2jhj+As3EKXLVhXNMiqfuc86lCzdA5TudmxUjxNd
41a91esieGw7Nbgi62/au5e/+FZPlE7Lbx6HhdgAZqd08EdggaRO8qfAKW6X+oQO
U8kDhmHXQGEXUtNa4IZZJoDqXdV15/MA0T4u6gq9H6oEAnWm8k8tb8WT1hfBr8Q=
=PgwO
-----END PGP SIGNATURE-----


From signup_mail2002 at yahoo.com  Thu Dec  4 15:32:41 2014
From: signup_mail2002 at yahoo.com (WorkingMan)
Date: Thu, 4 Dec 2014 15:32:41 +0000 (UTC)
Subject: [squid-users] =?utf-8?q?sslcrtvalidator=5Fprogram?=
Message-ID: <loom.20141204T162921-494@post.gmane.org>

Spam detection software, running on the system "master.squid-cache.org",
has identified this incoming email as possible spam.  The original
message has been attached to this so you can view it or label
similar future email.  If you have any questions, see
@@CONTACT_ADDRESS@@ for details.

Content preview:  I hope it's not a duplicate post since my last post was marked
   as spam for some reason. I am using sample validator script called cert_valid.pl.
   Everything is working as is (I can see stuff in the log in debug mode) but
   I could not change the behavior when there is an error. [...] 

Content analysis details:   (9.6 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
 0.0 CK_HELO_DYNAMIC_SPLIT_IP Relay HELO'd using suspicious hostname
                            (Split IP)
 1.0 FORGED_YAHOO_RCVD      'From' yahoo.com does not match 'Received' headers
 0.0 FREEMAIL_FROM          Sender email is commonly abused enduser mail provider
                            (signup_mail2002[at]yahoo.com)
 0.0 URIBL_BLOCKED          ADMINISTRATOR NOTICE: The query to URIBL was blocked.
                            See
                            http://wiki.apache.org/spamassassin/DnsBlocklists#dnsbl-block
                             for more information.
                            [URIs: cert_valid.pl]
 0.0 RCVD_IN_DNSWL_BLOCKED  RBL: ADMINISTRATOR NOTICE: The query to DNSWL
                            was blocked.  See
                            http://wiki.apache.org/spamassassin/DnsBlocklists#dnsbl-block
                             for more information.
                            [192.0.186.121 listed in list.dnswl.org]
 0.9 SPF_FAIL               SPF: sender does not match SPF record (fail)
[SPF failed: Please see http://www.openspf.org/Why?s=mfrom;id=gcwsg-squid-users%40m.gmane.org;ip=192.0.186.121;r=master.squid-cache.org]
 0.0 T_HEADER_FROM_DIFFERENT_DOMAINS From and EnvelopeFrom 2nd level mail
                            domains are different
 0.0 UNPARSEABLE_RELAY      Informational: message has unparseable relay lines
 3.9 HELO_DYNAMIC_IPADDR2   Relay HELO'd using suspicious hostname (IP addr
                            2)
 0.0 T_FREEMAIL_FORGED_FROMDOMAIN 2nd level domains in From and
                            EnvelopeFrom freemail headers are different
 1.3 RDNS_NONE              Delivered to internal network by a host with no rDNS
 2.5 HELO_DYNAMIC_HCC       Relay HELO'd using suspicious hostname (HCC)


-------------- next part --------------
An embedded message was scrubbed...
From: WorkingMan <signup_mail2002 at yahoo.com>
Subject: sslcrtvalidator_program
Date: Thu, 4 Dec 2014 15:32:41 +0000 (UTC)
Size: 2690
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141204/b50f106d/attachment.eml>

From ivanbrazza27 at gmail.com  Thu Dec  4 16:17:34 2014
From: ivanbrazza27 at gmail.com (Ivan Brazza)
Date: Thu, 4 Dec 2014 16:17:34 +0000
Subject: [squid-users] Parent proxy login details
Message-ID: <CAM9SHURtqqXL19+BRWn9G9_hBcFkBVeAw5z+mpLMkBf69nJX-A@mail.gmail.com>

Hi everybody,

Currently using squid 2.7 on Windows Server 2008 to forward all requests
that come in through our corporate proxy to allow applications that don't
support this to access the outside world (essentially doing what cntlm
does). Now I was able to get this to work by using cache_peer's
login=user:pass with my regular windows account. However, I need to use an
account that has hyphens in the name to authenticate with the parent proxy.
It seems that this doesn't work in squid, I tried using URL encoding for
hyphens (%2D) so that -tsk-rst-nexus becomes %2Dtsk%2Drst%2Dnexus but that
didn't work (I also tried with 2 %'s i.e. %%2D). Would anybody be able to
help me with this?

Thanks loads,
Ivan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141204/8b28f7d0/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec  4 16:32:38 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 05 Dec 2014 05:32:38 +1300
Subject: [squid-users] Parent proxy login details
In-Reply-To: <CAM9SHURtqqXL19+BRWn9G9_hBcFkBVeAw5z+mpLMkBf69nJX-A@mail.gmail.com>
References: <CAM9SHURtqqXL19+BRWn9G9_hBcFkBVeAw5z+mpLMkBf69nJX-A@mail.gmail.com>
Message-ID: <54808CA6.9070805@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 5/12/2014 5:17 a.m., Ivan Brazza wrote:
> Hi everybody,
> 
> Currently using squid 2.7 on Windows Server 2008 to forward all
> requests that come in through our corporate proxy to allow
> applications that don't support this to access the outside world
> (essentially doing what cntlm does). Now I was able to get this to
> work by using cache_peer's login=user:pass with my regular windows
> account. However, I need to use an account that has hyphens in the
> name to authenticate with the parent proxy. It seems that this
> doesn't work in squid, I tried using URL encoding for hyphens (%2D)
> so that -tsk-rst-nexus becomes %2Dtsk%2Drst%2Dnexus but that didn't
> work (I also tried with 2 %'s i.e. %%2D). Would anybody be able to 
> help me with this?
> 

When you are using login=user:pass in that form Squid just takes the
characters following "login=" and base-64 encodes them to become the
token for delivery to the peer. The hyphens are nothing special to
Squid, although they may be to the peer.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUgIymAAoJELJo5wb/XPRjDmkH/0z+xM1fzDmErPeryzQ5Uxt0
/WLgyZ+MlJ+jYEOSlYoO1t9DV2PDfg7L0hEM5Alqm8mLLVSCE9VvfO3ykOZPAAiO
u/J0msqdfEKyVjclQvDdljczBEn0rYQJLOlwPa3Ptb53tFjfcu+2vxn9oJ4q7FWU
bjYZZw4Nl2bl065Onod7ReLbdYxuzYZyc9Fdm2oU3AwBfpCPrbMfgviW4N08JRWl
yr99yc2+yipaVqRIsGwUcb5xKydfQMM72id5swDozr+y7REpI6GHJ2we2zswcJGN
s2Y9YZsG6DdVMvCP9ecsLz+VJUHY+UslVZWwc8gxAWi+CjJKWmKbKWvrBEnrFZw=
=UWu4
-----END PGP SIGNATURE-----


From Jason_Haar at trimble.com  Thu Dec  4 17:58:28 2014
From: Jason_Haar at trimble.com (Jason Haar)
Date: Fri, 5 Dec 2014 06:58:28 +1300
Subject: [squid-users] odd wccp issue affecting only some web servers
Message-ID: <5480A0C4.90604@trimble.com>

Hi there

We have CentOS-6 squid-3.1.10-29 servers that are configured for WCCP.
They are working - for some web sites. eg "www.slashdot.org" works
(216.34.181.48), but "slashdot.org" doesn't (216.34.181.45). Those are
both on the same Class-C subnet.

What I see is the SYN packet being forwarded for both from our Cisco kit
to the Linux "wccp0" interface, but only the "www.slashdot.org" one
leads to squid connecting to that website. The other just stops. I can't
tell if this is a fault in iptables forwarding one and not the other to
squid, or a problem with squid - but iptables has the easier job so it
shouldn't be in there. (obviously we don't do any kind of weird,
"partial" transparent proxy - the iptables rule is to pass all port 80
traffic to squid). Also both websites work fine through squid if you use
it as a normal proxy

Any ideas how to diagnose this, or is this a "that was fixed in a newer
version that your OS vendor doesn't support" kind of problem ;-)

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From jddig2000 at yahoo.com  Thu Dec  4 21:17:19 2014
From: jddig2000 at yahoo.com (JeffDK)
Date: Thu, 4 Dec 2014 13:17:19 -0800 (PST)
Subject: [squid-users] Squid config question
Message-ID: <1417727839784-4668611.post@n4.nabble.com>

Hi,

I have domain with about 20 servers.  Server A and B need full internet
access and ssh access to one offsite server and the rest of the servers
(domainX) have internet access limited to about 10 sites.  I've added these
lines and I beleive the rest is default.

acl ServerA src ?Server A IP?
acl ServerB src ?Server B IP?
acl AllowedSites securezone ?/usr/local/etc/allowed-sites.squid

http_access allow ServerA
http_access allow ServerB
http_access allow ?domainX? AllowedSites
http_access deny all

It seems that this config still restricts all servers to the allowed sites
and does not allow ssh.  I'm a beginner and curious if anyone has any ideas?

Thanks,
Jeff 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-config-question-tp4668611.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Dec  5 01:06:47 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 05 Dec 2014 14:06:47 +1300
Subject: [squid-users] Squid config question
In-Reply-To: <1417727839784-4668611.post@n4.nabble.com>
References: <1417727839784-4668611.post@n4.nabble.com>
Message-ID: <54810527.8020602@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 5/12/2014 10:17 a.m., JeffDK wrote:
> Hi,
> 
> I have domain with about 20 servers.  Server A and B need full
> internet access and ssh access to one offsite server and the rest
> of the servers (domainX) have internet access limited to about 10
> sites.  I've added these lines and I beleive the rest is default.
> 
> acl ServerA src ?Server A IP? acl ServerB src ?Server B IP?

I assume the above "" details are actual IP addresses rather than
quoted strings. Otherwise that is your problem.

You can also list multiple IP addresses in one ACL. So you dont need
separate serverA and serverB definitions.

I suggest naming the ACL for what meaning your policy assigns to them.
ie
 acl unlimitedServers src ?Server A IP? ?Server B IP?
 http_access allow unlimitedServers

> acl AllowedSites securezone ?/usr/local/etc/allowed-sites.squid
> 
> http_access allow ServerA http_access allow ServerB http_access
> allow ?domainX? AllowedSites http_access deny all
> 
> It seems that this config still restricts all servers to the
> allowed sites and does not allow ssh.  I'm a beginner and curious
> if anyone has any ideas?

SSH uses TLS protocol, not HTTP protocol. Squid will only let it
through if the tool used sends HTTP messages. For non-HTTP protocols
use your system firewall to permit/deny.


Without details on how you are identifying the problem "restricts all
servers to the allowed sites" its hard to suggest any other
possibilities for what might be wrong.
 If the problem persists after you make the above changes then we are
going to need access.log records showing the problem, and exact
details of what those elided IPs are.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUgQUnAAoJELJo5wb/XPRjm8YH+QF1IRQMTvLxkDjH9EJk2xKC
REXtNmdsibKPyA25ruv7pj+VhO+s8pGOYYsaFQROip7KapzvvoftFy5QvdjMrdsY
N3GKKGwvGc9tXAFsg7Un5aRJ2nt6uY8+cgIk4BhuLrfmKvNrXA8nRZ0Muco/IN2I
z0R4MeinMMpm/c+jZDGVNs1VI2sg49LGJUSwTWrue7Rf7hjFtid3B2jIp32mqfQT
A5R9g3WyOZOJgADbYbqvEQ3Jta3Dq2s8Q2lCjl99UEw4W/SpXl0evbKWziH/2k1T
SYrW5js+fVxzepmRnukN1BLsRMqzIrzVeFi2V5wEFLZutnGiu/iPOmKikfnFVMU=
=jbuW
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Dec  5 01:22:18 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 05 Dec 2014 14:22:18 +1300
Subject: [squid-users] odd wccp issue affecting only some web servers
In-Reply-To: <5480A0C4.90604@trimble.com>
References: <5480A0C4.90604@trimble.com>
Message-ID: <548108CA.9080805@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 5/12/2014 6:58 a.m., Jason Haar wrote:
> Hi there
> 
> We have CentOS-6 squid-3.1.10-29 servers that are configured for
> WCCP. They are working - for some web sites. eg "www.slashdot.org"
> works (216.34.181.48), but "slashdot.org" doesn't (216.34.181.45).
> Those are both on the same Class-C subnet.

"Class-C" ? ... oh right, that netmask thing they used to have before
1996. ;-P

> 
> What I see is the SYN packet being forwarded for both from our
> Cisco kit to the Linux "wccp0" interface, but only the
> "www.slashdot.org" one leads to squid connecting to that website.
> The other just stops. I can't tell if this is a fault in iptables
> forwarding one and not the other to squid, or a problem with squid
> - but iptables has the easier job so it shouldn't be in there.
> (obviously we don't do any kind of weird, "partial" transparent
> proxy - the iptables rule is to pass all port 80 traffic to squid).
> Also both websites work fine through squid if you use it as a
> normal proxy
> 
> Any ideas how to diagnose this, or is this a "that was fixed in a
> newer version that your OS vendor doesn't support" kind of problem
> ;-)
> 

One is a HIT the other a MISS?
 Squid ACLs?
 TCP connection issue?

I suggest finding out what happens to the TCP DATA packets that follow
the SYN. There might be some clues in there, particularly if its a TCP
issue like path-MTU, ECN or Window scaling.

Whether its fixed in a new version is a "maybe". Upgrade and see?


Squid might be trying IPv6 to contact slashdot.org (thus bypassing
your viewing), but it has no AAAA records when I resolve it. So that
is unlikely.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUgQjKAAoJELJo5wb/XPRjckgH/Am25yCkoC6hGF/ghVdwDi7C
ZkvoEmBSHBVSHt7SheScKwuymQxgghtj02veX6y6oEkHSycyhNJfTPW4XXTpYmqf
eMWo+Wqz10U3rc/fcpdz9OuCk76rq/fmnozGcKuG5F5g0oue+SPsPFOzPBt8D1GB
KIwkZKl9aKKfO0BatTMdGnnpP+NH3WB92SgNVW8G21QXvIRh4r5LSDzRa8VF5oTG
dEoFAS/aYMOyLOOZDYMx0LXCuMIJ865+Wle912N9vN6vugK5g1h89RAPtLJ2vPFt
yxP/IH3+zJQLtWj1gV+xgKWpDc3k0+sGzaQcs0j85izm8b93XCWF1SU774c455k=
=QsO6
-----END PGP SIGNATURE-----


From Richard.Aspley at hammonds-uk.com  Fri Dec  5 11:55:15 2014
From: Richard.Aspley at hammonds-uk.com (Rich549)
Date: Fri, 5 Dec 2014 03:55:15 -0800 (PST)
Subject: [squid-users] Squid 3.3.8 NTLM Group Authentication
Message-ID: <1417780515744-4668615.post@n4.nabble.com>

Hi,

I'm having problems getting NTLM authentication to work.  I need it to only
allow members of the Internet_Users AD group to be able to access the
internet.  Instead it is only allowing the websites that I've marked as OK
for all users (a lot of this config came from my SquidNT installation).

My config is as follows:

##	WELCOME TO SQUID 3.3.8
#	----------------------------

#-----------------------------------------------------------------------------
#DEFAULTS
#-----------------------------------------------------------------------------
http_port 3128
hierarchy_stoplist cgi-bin ?
acl QUERY urlpath_regex cgi-bin \?
cache deny QUERY
acl apache rep_header Server ^Apache
cache_mem 1024 MB

#-----------------------------------------------------------------------------
# AUTHENTICATION
#-----------------------------------------------------------------------------
#
#
### negotiate kerberos and ntlm authentication
#auth_param negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm
/usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp
--domain=DOMAIN --kerberos /usr/lib/squid3/negotiate_kerberos_auth -d -s
GSS_C_NO_NAME domain=HAMMONDS --kerberos
/usr/lib/squid3/negotiate_kerberos_auth srvham09.domain.com
#auth_param negotiate children 10
#auth_param negotiate keep_alive off

### pure ntlm authentication
auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
--helper-protocol=squid-2.5-ntlmssp --domain=HAMMONDS
auth_param ntlm children 10
auth_param ntlm keep_alive off

### provide basic authentication via ldap for clients not authenticated via
kerberos/ntlm
#auth_param basic program /usr/lib/squid3/basic_ldap_auth -b
"dc=domain,dc=com" -D squid at domain.com -W /etc/squid3/ldappass.txt -f
sAMAccountName=%s -h srvham09.domain.com 
#auth_param basic children 10
#auth_param basic realm Internet Proxy
#auth_param basic credentialsttl 1 minute

### acl for proxy auth and ldap authorizations
acl auth proxy_auth REQUIRED
#acl localnet src 172.31.0.0/16

### set helper processes
external_acl_type internet_domain_group %LOGIN
/usr/lib/squid3/ext_ldap_group_acl -b "ou=Service_Accounts,dc=domain,dc=com"
-D squid at domain.com -W /etc/squid3/ldappass.txt -f
"cn=Internet_Users,ou=Domain_Groups,dn=domain,dn=com" srvham09.domain.com



#-------------------------------------------------------------------------------------------------
### Allow authenticated users
#-------------------------------------------------------------------------------------------------
acl InetAllow external internet_domain_group Internet_Users 

#-------------------------------------------------------------------------------------------------
### Bypass Authentication
#-------------------------------------------------------------------------------------------------

# These domains will be reachable without authentication
acl OK_Unauthenticated dstdomain .domain.com .force24.co.uk .trakit.uk.net
194.73.60.21 .stanford.edu 171.65.103.68 212.100.232.212
acl OK_Unauthenticated dstdomain .canonical.com .sophos.com .ubuntu.com
.oracle.com .bt.com .refreshthis.com
acl OK_Unauthenticated dstdomain .oanda.com .dell.com .launchpad.net
acl OK_Unauthenticated dstdomain .dashboards.my-tmac.co.uk

#Squid Access Denied Screen
acl OK_Unauthenticated dstdomain .squid-cache.org

# ------------------------------------------------
# ------ Permit/Deny access as appropriate -------
# ------------------------------------------------

http_access allow OK_Unauthenticated
http_access allow InetAllow
    
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern .		0	20%	4320
shutdown_lifetime 10 seconds
acl all src 0.0.0.0/0.0.0.0
acl localhost src 127.0.0.1/255.255.255.255
acl to_localhost dst 127.0.0.0/8
acl SSL_ports port 443 563
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443 563	# https, snews
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl Safe_ports port 4004	# Radii website download site uses this port
acl Safe_ports port 10000	# Webmin
acl Safe_ports port 900		# Swat
acl Safe_ports port 82		# Pacejet request - test site hosted on HTTP 82
acl Safe_ports port 81		# Image plus test server (hepplewhite)
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all
http_reply_access allow all
icp_access allow all
cache_mgr otrs at domain.com
forwarded_for off

When I try to browse to any of the whitelisted websites the cache.log shows
an NTLM process starting so it looks like it's making sure that I'm an
authenticated user but isn't controlling my access correctly.

Any help would be appreciated as I'm totally stumped.

Thanks,

Rich



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-3-8-NTLM-Group-Authentication-tp4668615.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Richard.Aspley at hammonds-uk.com  Fri Dec  5 12:51:04 2014
From: Richard.Aspley at hammonds-uk.com (Rich549)
Date: Fri, 5 Dec 2014 04:51:04 -0800 (PST)
Subject: [squid-users] Squid 3.3.8 NTLM Group Authentication
In-Reply-To: <1417780515744-4668615.post@n4.nabble.com>
References: <1417780515744-4668615.post@n4.nabble.com>
Message-ID: <1417783864137-4668616.post@n4.nabble.com>

Ok, so I realised that my query was wrong so I've updated it to this:

external_acl_type internet_domain_group %LOGIN
/usr/lib/squid3/ext_ldap_group_acl -R -P -b "dc=domain,dc=com" -D
squid at domain.com -W /etc/squid3/ldappass.txt -f
"(&(objectclass=person)(sAMAccountName=%u)(memberof=cn=%g,dc=domain,dc=com))"
-h srvham09.domain.com

Still not working though :-(




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-3-8-NTLM-Group-Authentication-tp4668615p4668616.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Dec  5 13:26:07 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 06 Dec 2014 02:26:07 +1300
Subject: [squid-users] Squid 3.3.8 NTLM Group Authentication
In-Reply-To: <1417780515744-4668615.post@n4.nabble.com>
References: <1417780515744-4668615.post@n4.nabble.com>
Message-ID: <5481B26F.1090204@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 6/12/2014 12:55 a.m., Rich549 wrote:
> Hi,
> 
> I'm having problems getting NTLM authentication to work.  I need it
> to only allow members of the Internet_Users AD group to be able to
> access the internet.  Instead it is only allowing the websites that
> I've marked as OK for all users (a lot of this config came from my
> SquidNT installation).
> 
> My config is as follows:
> 
> ##	WELCOME TO SQUID 3.3.8 #	----------------------------
> 
> #-----------------------------------------------------------------------------
>
> 
#DEFAULTS
> #-----------------------------------------------------------------------------
>
> 
http_port 3128

> hierarchy_stoplist cgi-bin ? acl QUERY urlpath_regex cgi-bin \? 
> cache deny QUERY

The above QUERY and hierarchy_stoplist actions are not much use in
recent Squid versions. There is a refresh_pattern (mentioned below)
that replaces them.

> acl apache rep_header Server ^Apache cache_mem 1024 MB
> 
> #-----------------------------------------------------------------------------
>
> 
# AUTHENTICATION
> #-----------------------------------------------------------------------------
>
> 
#
> # ### negotiate kerberos and ntlm authentication #auth_param
> negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm 
> /usr/bin/ntlm_auth --diagnostics
> --helper-protocol=squid-2.5-ntlmssp --domain=DOMAIN --kerberos
> /usr/lib/squid3/negotiate_kerberos_auth -d -s GSS_C_NO_NAME
> domain=HAMMONDS --kerberos /usr/lib/squid3/negotiate_kerberos_auth
> srvham09.domain.com #auth_param negotiate children 10 #auth_param
> negotiate keep_alive off
> 
> ### pure ntlm authentication auth_param ntlm program
> /usr/bin/ntlm_auth --diagnostics 
> --helper-protocol=squid-2.5-ntlmssp --domain=HAMMONDS auth_param
> ntlm children 10 auth_param ntlm keep_alive off
> 
> ### provide basic authentication via ldap for clients not
> authenticated via kerberos/ntlm #auth_param basic program
> /usr/lib/squid3/basic_ldap_auth -b "dc=domain,dc=com" -D
> squid at domain.com -W /etc/squid3/ldappass.txt -f sAMAccountName=%s
> -h srvham09.domain.com #auth_param basic children 10 #auth_param
> basic realm Internet Proxy #auth_param basic credentialsttl 1
> minute
> 
> ### acl for proxy auth and ldap authorizations acl auth proxy_auth
> REQUIRED #acl localnet src 172.31.0.0/16
> 
> ### set helper processes external_acl_type internet_domain_group
> %LOGIN /usr/lib/squid3/ext_ldap_group_acl -b
> "ou=Service_Accounts,dc=domain,dc=com" -D squid at domain.com -W
> /etc/squid3/ldappass.txt -f 
> "cn=Internet_Users,ou=Domain_Groups,dn=domain,dn=com"
> srvham09.domain.com
> 
> 
> 
> #-------------------------------------------------------------------------------------------------
>
> 
### Allow authenticated users
> #-------------------------------------------------------------------------------------------------
>
> 
acl InetAllow external internet_domain_group Internet_Users
> 
> #-------------------------------------------------------------------------------------------------
>
> 
### Bypass Authentication
> #-------------------------------------------------------------------------------------------------
>
>  # These domains will be reachable without authentication acl
> OK_Unauthenticated dstdomain .domain.com .force24.co.uk
> .trakit.uk.net 194.73.60.21 .stanford.edu 171.65.103.68
> 212.100.232.212 acl OK_Unauthenticated dstdomain .canonical.com
> .sophos.com .ubuntu.com .oracle.com .bt.com .refreshthis.com acl
> OK_Unauthenticated dstdomain .oanda.com .dell.com .launchpad.net 
> acl OK_Unauthenticated dstdomain .dashboards.my-tmac.co.uk
> 
> #Squid Access Denied Screen acl OK_Unauthenticated dstdomain
> .squid-cache.org
> 
> # ------------------------------------------------ # ------
> Permit/Deny access as appropriate ------- #
> ------------------------------------------------
> 
> http_access allow OK_Unauthenticated http_access allow InetAllow
> 
> refresh_pattern ^ftp:		1440	20%	10080 refresh_pattern ^gopher:	1440
> 0%	1440

Missing pattern:
  refresh_pattern -i (/cgi-bin/|\?) 0 0% 0

> refresh_pattern .		0	20%	4320 shutdown_lifetime 10 seconds acl all
> src 0.0.0.0/0.0.0.0 acl localhost src 127.0.0.1/255.255.255.255 acl
> to_localhost dst 127.0.0.0/8

You are likely getting startup warnings about the above ACL
definitions. ACLs all, manager, localhost, and to_localhost are
predefined in your Squid version. Remove the above lines from your config.


> acl SSL_ports port 443 563 acl Safe_ports port 80		# http acl
> Safe_ports port 21		# ftp acl Safe_ports port 443 563	# https,
> snews acl Safe_ports port 70		# gopher acl Safe_ports port 210		#
> wais acl Safe_ports port 1025-65535	# unregistered ports acl
> Safe_ports port 280		# http-mgmt acl Safe_ports port 488		#
> gss-http acl Safe_ports port 591		# filemaker acl Safe_ports port
> 777		# multiling http acl Safe_ports port 4004	# Radii website
> download site uses this port acl Safe_ports port 10000	# Webmin

The above two ports are included in the range 1024-65535 (unregistered
ports). No need to add them specially.

> acl Safe_ports port 900		# Swat acl Safe_ports port 82		# Pacejet
> request - test site hosted on HTTP 82 acl Safe_ports port 81		#
> Image plus test server (hepplewhite) acl CONNECT method CONNECT 
> http_access allow manager localhost http_access deny manager 
> http_access deny !Safe_ports http_access deny CONNECT !SSL_ports 
> http_access deny all http_reply_access allow all icp_access allow
> all cache_mgr otrs at domain.com forwarded_for off
> 
> When I try to browse to any of the whitelisted websites the
> cache.log shows an NTLM process starting so it looks like it's
> making sure that I'm an authenticated user but isn't controlling my
> access correctly.

It should not be doing anything with NTLM  when you request the
whitelisted domains or raw-IP addresses.

* With your config it should start the helper processes right at teh
beginning when you start Squid, or if some of them die unexpectedly
early they should be restarted on a following login.

* Squid should do some lookups via the already running helpers only
when non-whiteisted domains are requested.


IIRC there was an issue with login when external ACL was the first ACL
to be tested. Try using a "http_access deny !auth" after the whitelist
and before the group check.
Like so:

  http_access allow OK_Unauthenticated
  http_access deny !auth
  http_access allow InetAllow


HTH
Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUgbJvAAoJELJo5wb/XPRjNRAIAMp1eqekS+RxJrl0+ewg9jEH
CXONklru2cAvTA5pKkZtUE/NDLgRVyZAPE0P4/UYQumgXFPyeIfHnTOxUYaPiMVt
yD/ITGs8p8/BnsE9DGEbUJ0AS4Dex+PjLxfuCwoEFc2SVX3EqxfyWJIuwNJJFo3E
pDhqoa8+LpsbJvJNeV21IWB6D51fq4RW0rsLQW+mA/xLFD2bFdYdAO/hknTXSq/w
wTdLACc3+gDoyfEDd48p8Bi1tO+bAu8xsWVGtDPNKIz0KOCp81mexweqtYHuKINC
EVrVXb2lLdtc/QqM+XCUC5coB8n1FT26+npd3QJRHZuisNRyspA3g3ibeARl2+w=
=lPSb
-----END PGP SIGNATURE-----


From ogoderich at gmail.com  Fri Dec  5 15:15:30 2014
From: ogoderich at gmail.com (Osmany Goderich)
Date: Fri, 5 Dec 2014 10:15:30 -0500
Subject: [squid-users] Packet Marking for Traffic Shaping
Message-ID: <CAPHknWNrQBgSXwoUrPZ=qt3aDaPPnHrS7UHvG8X+j3enWXvrzg@mail.gmail.com>

Hi everyone,

I was googling and I couldn't find anything clear about the subject, but I
am trying to make Squid mark the packets in order to differentiate traffic
so that I can do Traffic Shaping on my hardware firewalls. This should help
me do the job easier in my firewalls since the requests that go to internet
come from only one IP (the proxy-cache) and I really need to identify
different clients so that I can apply different traffic shaping rules. My
firewall supports DSCP or ToS. I was looking up ToS but I am having a hard
time to understand how can I apply different values of ToS to all my
clients(I'm talking about more that 50 clients with different bandwidth to
be assigned).
Can anyone please help me with this?

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141205/2c297c27/attachment.htm>

From dougs at dawnsign.com  Fri Dec  5 22:17:08 2014
From: dougs at dawnsign.com (Doug Sampson)
Date: Fri, 5 Dec 2014 22:17:08 +0000
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
In-Reply-To: <547C2A11.6030403@treenet.co.nz>
References: <E6B2517F8D6DBF4CABB8F38ACA367E783431AF29@Draco.dawnsign.com>
 <5473E101.4010907@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
 <547C2A11.6030403@treenet.co.nz>
Message-ID: <E6B2517F8D6DBF4CABB8F38ACA367E783435DD36@Draco.dawnsign.com>

> On 26/11/2014 8:59 a.m., Doug Sampson wrote:
> >
> > Thanks, Amos, for your pointers.
> >
> > I've commented out all the fresh_patterns lines appearing above
> > the last two lines.
> >
> > I also have dropped diskd in favor of using aufs exclusively,
> > taking out the min-size parameter. I've commented out the
> > diskd_program support option. In the previous version of squid
> > (2.7) I had split the cache_dir into two types with great success
> > using coss and aufs. Previously I had only aufs and performance
> > wasn't where I wanted it. Apparently coss is no longer supported in
> > the 3.x version of squid atop FreeBSD.
> 
> COSS has been replaced with Rock storage type in Squid-3. They should
> be used in roughly similar ways in terms of traffic optimization.
> 
> >
> > The pathname for the cache swap logs have been fixed. Apparently
> > this came from a squid.conf example that I copied in parts. Would
> > this be the reason why we are seeing the error messages in
> > /var/log/messages regarding swapping mentioned in my original
> > post?
> 
> No. I think that is coming out of the OS kernel memory management. It
> uses the term "swap" as well in regards to disk backed virtual memory.
> 
> If your system is "swapping" (using that disk backed "swap memory")
> while running Squid then you will get terrible performance as a matter
> of course since the Squid cache index and cache_meme is often very
> large in RAM and accessed often.
> 
> >
> > The hierarchy_stoplist line has been stripped out as you say it is
> > deprecated.
> >
> > The mem .TSV file is attached herewith.
> >
> > Currently I have the cache_dir located on the OS disk and all of
> > the cache logging files on a second drive. Is this the optimal
> > setup of cache-dir and logs?
> 
> I would do it the other way around. Logs are appended with a small
> amount of data each transaction, whereas the main cache_dir has a
> relativey large % of the bandwidth throughput being written out to it
> constantly (less % in recent Squid, but still a lot). The dik most
> likely to die early is the one holding cache_dir.
> 
I'm still running into the issue of being out of available space in the swapfile on my system. I've attached another TSV file indicating the various type of memory being in use and whatnot. Is there anything in there that screams out?

Amos, you said earlier that it was the OS system that needed to be tuned. Are there any references to where I can fine-tune it for Squid usage? I looked here http://oss.org.cn/man/newsoft/squid/Squid_FAQ/FAQ-8.html#how-much-ram and I'm unable to figure out a way to decrease the amount of memory that I could use. I tried limiting cache_mem to 1344 MB from some higher value but that didn't work. What are some of the methods that FreeBSD 10.0 users using to limit the use of memory that Squid uses?

Sort of fixing the memory leaks, it looks like I need to consider the possibility of restarting the Squid service on a regular basis (i.e. at least once a week) in order to enable Squid to perform at an acceptable level and to avoid clogging /var/log/messages with such messages as follows:

<...>
+swap_pager_getswapspace(15): failed
+swap_pager_getswapspace(2): failed
+swap_pager_getswapspace(16): failed
+swap_pager_getswapspace(16): failed
<...>

Is this a common practice among squid admins to restart squid periodically?

Thank you!

~Doug
 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid-internal-mgr_MEM_20141205.tsv
Type: text/tab-separated-values
Size: 15791 bytes
Desc: squid-internal-mgr_MEM_20141205.tsv
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141205/89b5c3ee/attachment.tsv>

From sven.falempin at gmail.com  Fri Dec  5 22:19:09 2014
From: sven.falempin at gmail.com (sven falempin)
Date: Fri, 5 Dec 2014 17:19:09 -0500
Subject: [squid-users] Configuring the sslbump
Message-ID: <CA++fYEiTvtuwhGuxpkC+rt=22OiFS=7GA_vOMzhzx4Rb_beH8w@mail.gmail.com>

Hello Squid,

I am trying the sslBump and just following the doc, i tried to also some
random tutorial on the web that mostly looks like copy pasta of the wiki.
All i got is a FATAL. .. . .

2014/12/05 17:07:24.472| src/ssl/support.cc(1584)
readSslX509CertificatesChain: Certificate is self-signed, will not
 be chained
2014/12/05 17:07:24.500| src/ssl/support.cc(1446) contextMethod: Using
SSLv2/SSLv3.
2014/12/05 17:07:24.500| src/ssl/support.cc(857) configureSslContext:
Setting RSA key generation callback.
2014/12/05 17:07:24.500| src/ssl/support.cc(860) configureSslContext:
Setting CA certificate locations.
2014/12/05 17:07:24.505| src/ssl/support.cc(903) configureSslContext: Not
requiring any client certificates
2014/12/05 17:07:24.505| Initializing https_port 0.0.0.0:3129 SSL context
2014/12/05 17:07:24.505| src/tools.cc(564) leave_suid: leave_suid: PID
10872 called
2014/12/05 17:07:24.505| src/tools.cc(586) leave_suid: leave_suid: PID
10872 giving up root, becoming '_squid'
FATAL: No valid signing SSL certificate configured for HTTPS_port
0.0.0.0:3129
Squid Cache (Version 3.HEAD-20140626-r13480): Terminated abnormally.

my certificates are all right
2014/12/05 17:07:24.505| Initializing https_port 0.0.0.0:3129 SSL context
but sundenly they are i dont recheck or something ?

the only non logged code i see is this one :

    if (!pkey || !cert || !X509_check_private_key(cert.get(), pkey.get())) {
        pkey.reset(NULL);
        cert.reset(NULL);
    }

But i swear i follow the doc and create the certificate normally.

Is there a particular CN to use ?
Shall i emit a self signed root and then another certificate for the proxy
??? is this error not related at all ? with the certificate on the sslbump
lines ?

Conf:
# Squid normally listens to port 3128
http_port 3128
https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=2MB  cert=/etc/squid/sq
uid-proxy.crt  key=/etc/squid/squid-proxy.key

# dont forget ssl_crtd -c -s /var/db/squid/ssl when setup
always_direct allow all
ssl_bump client-first  all
sslproxy_cert_error allow all
# Or may be deny all according to your company policy
# sslproxy_cert_error deny all
sslproxy_flags DONT_VERIFY_PEER
sslcrtd_program /usr/local/bin/ssl_crtd -s /var/db/squid/ssl -M 2MB
sslcrtd_children 5


Info:
 # ls /var/db/squid/ssl
certs     index.txt size


-- 
---------------------------------------------------------------------------------------------------------------------
() ascii ribbon campaign - against html e-mail
/\
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141205/2b631384/attachment.htm>

From squid3 at treenet.co.nz  Sat Dec  6 06:00:16 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 06 Dec 2014 19:00:16 +1300
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
In-Reply-To: <E6B2517F8D6DBF4CABB8F38ACA367E783435DD36@Draco.dawnsign.com>
References: <E6B2517F8D6DBF4CABB8F38ACA367E783431AF29@Draco.dawnsign.com>
 <5473E101.4010907@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
 <547C2A11.6030403@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E783435DD36@Draco.dawnsign.com>
Message-ID: <54829B70.9080000@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 6/12/2014 11:17 a.m., Doug Sampson wrote:
>> On 26/11/2014 8:59 a.m., Doug Sampson wrote:
>>> 
>>> Thanks, Amos, for your pointers.
>>> 
>>> I've commented out all the fresh_patterns lines appearing
>>> above the last two lines.
>>> 
>>> I also have dropped diskd in favor of using aufs exclusively, 
>>> taking out the min-size parameter. I've commented out the 
>>> diskd_program support option. In the previous version of squid 
>>> (2.7) I had split the cache_dir into two types with great
>>> success using coss and aufs. Previously I had only aufs and
>>> performance wasn't where I wanted it. Apparently coss is no
>>> longer supported in the 3.x version of squid atop FreeBSD.
>> 
>> COSS has been replaced with Rock storage type in Squid-3. They
>> should be used in roughly similar ways in terms of traffic
>> optimization.
>> 
>>> 
>>> The pathname for the cache swap logs have been fixed.
>>> Apparently this came from a squid.conf example that I copied in
>>> parts. Would this be the reason why we are seeing the error
>>> messages in /var/log/messages regarding swapping mentioned in
>>> my original post?
>> 
>> No. I think that is coming out of the OS kernel memory
>> management. It uses the term "swap" as well in regards to disk
>> backed virtual memory.
>> 
>> If your system is "swapping" (using that disk backed "swap
>> memory") while running Squid then you will get terrible
>> performance as a matter of course since the Squid cache index and
>> cache_meme is often very large in RAM and accessed often.
>> 
>>> 
>>> The hierarchy_stoplist line has been stripped out as you say it
>>> is deprecated.
>>> 
>>> The mem .TSV file is attached herewith.
>>> 
>>> Currently I have the cache_dir located on the OS disk and all
>>> of the cache logging files on a second drive. Is this the
>>> optimal setup of cache-dir and logs?
>> 
>> I would do it the other way around. Logs are appended with a
>> small amount of data each transaction, whereas the main cache_dir
>> has a relativey large % of the bandwidth throughput being written
>> out to it constantly (less % in recent Squid, but still a lot).
>> The dik most likely to die early is the one holding cache_dir.
>> 
> I'm still running into the issue of being out of available space in
> the swapfile on my system. I've attached another TSV file
> indicating the various type of memory being in use and whatnot. Is
> there anything in there that screams out?
> 

Nothing particularly stands out as leaking. Although the cache memory
pages (mem_node) in-use size is suspiciously close to half what you
say the OS is reporting.

That makes me suspect that your OS is rounding up its allocations to
8KB of memory for each node. If that is the case the simplest
workaround is to reduce cache_mem size down to below the point where
the box will swap.


If you are game for it I have been wondering if we need to enable
chunking for 64-bit systems. To test that run squid with environment
variable MEMPOOLS=1.
 Memory should then be allocated in larger blocks, but utilized much
more compactly within those blocks for an overall saving on objects
like mem_node. It is currently a rarely used feature though, so I'm
not sure if there are any issues hiding.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUgptwAAoJELJo5wb/XPRjLbUIAJjORv/denfKNTA53cxrN7CU
Cbyc3m6yqiM4Mi0J0VNS2qPUJYd69sSGkz4Q4XtpoKLPjO8i8glcVDg8ncoKMokj
E3rJbpj4tcdukPmvJ8XlQRqlAfYANTQK6wGvfhmQOlNqPjtKi6eB7HZR75LWNFlM
aj/6Ij15cfM0OI9KQW5PyKwxLwTmZhDn3g0RTHdbzho9GZOjfZEYA0Wn2eMDNqOM
JIwsamBp6KFCN7w/6Mw2I0+guVOpFALDd35M39HdapEuzwauuNrt5F1DvD+rSIa+
8iBKRcDtB3tsaFWyIilFoxCbTTdtdggDhiN0FfT/KEebtZb+A5PI+IQIFWszNzc=
=5tf8
-----END PGP SIGNATURE-----


From gkinkie at gmail.com  Sat Dec  6 18:49:48 2014
From: gkinkie at gmail.com (Kinkie)
Date: Sat, 6 Dec 2014 19:49:48 +0100
Subject: [squid-users] Packet Marking for Traffic Shaping
In-Reply-To: <CAPHknWNrQBgSXwoUrPZ=qt3aDaPPnHrS7UHvG8X+j3enWXvrzg@mail.gmail.com>
References: <CAPHknWNrQBgSXwoUrPZ=qt3aDaPPnHrS7UHvG8X+j3enWXvrzg@mail.gmail.com>
Message-ID: <CA+Y8hcOF26oWAOPYoXfnRUn1ER=LQ7k7SaypGiBJSzS=w5uhcQ@mail.gmail.com>

Hello Osmany,
  have you tried http://wiki.squid-cache.org/Features/QualityOfService ?


Kinkie

On Fri, Dec 5, 2014 at 4:15 PM, Osmany Goderich <ogoderich at gmail.com> wrote:
> Hi everyone,
>
> I was googling and I couldn't find anything clear about the subject, but I
> am trying to make Squid mark the packets in order to differentiate traffic
> so that I can do Traffic Shaping on my hardware firewalls. This should help
> me do the job easier in my firewalls since the requests that go to internet
> come from only one IP (the proxy-cache) and I really need to identify
> different clients so that I can apply different traffic shaping rules. My
> firewall supports DSCP or ToS. I was looking up ToS but I am having a hard
> time to understand how can I apply different values of ToS to all my
> clients(I'm talking about more that 50 clients with different bandwidth to
> be assigned).
> Can anyone please help me with this?
>
> Thanks
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
    Francesco


From glenn.groves at bradnams.com.au  Sun Dec  7 08:48:11 2014
From: glenn.groves at bradnams.com.au (glenn.groves at bradnams.com.au)
Date: Sun, 7 Dec 2014 18:48:11 +1000
Subject: [squid-users] https issues for google
In-Reply-To: <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
Message-ID: <2329B68B3D676246BA0D1149E22F509F01A6FBA2@bneseqs20.bradnams.com.au>

Hi All,

I have finally been able to spend time upgrading a server to a later squid version, I have tried 3.4.9.

I could not get authentication to work for this test, but proceeded to test without (also dismisses auth as the problem).

I am getting the following in the logs with secure sites now the squid is 3.4.9:

192.168.9.69 TCP_MISS/200 295 CONNECT www.google.com:443 - HIER_DIRECT/216.58.220.1
192.168.9.69 TCP_MISS/200 0 CONNECT www.google.com:443 - HIER_DIRECT/216.58.220.132

Upgrading to 3.4.9 on Centos as been a pain so far, no point in proceeding with the problem persisting. Can someone advise why I am getting TCP_MISS/200 when going to secure google sites?

Or more importantly, how to fix my squid 3.1 on centos 6.5 with this problem.

Thanks,

Glenn

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of glenn.groves at bradnams.com.au
Sent: Thursday, 9 October 2014 9:04 AM
To: eliezer at ngtech.co.il; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] https issues for google

Hi Eliezer,

The DNS we are using is the ISP default for external, our internal domain DNS for internal. Nslookup works for all tests.

I would like to update to the latest stable, but I am concerned of breaking the current setup. It took a little work to get it working correctly particularity on the multiple authentication methods working with our domain and trust.

I support what has been said - to check the logs. This will likely take time as I cannot reproduce this issue on demand - and I think users are starting to not report the issue and just living with it (or it is not getting all the way to me at least). I will have to get lucky at some point on my computer and look into it then.

Could squid be getting mixed up when mulipule https requests are to the same address (e.g. https://google.com.au)?

Thanks,

Glenn 

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Wednesday, 8 October 2014 7:39 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] https issues for google

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Glenn,

Since you are not using intercept or tproxy the basic place to look at is the access.log.
You can see there if the proxy is trying for example to reach an IPV6 address (by mistake).

Also to make sure there is an issue you can use specific exception like the cacheadmin acl you are using to allow the cacheadmin access without authentication for the basic test.

Also you are indeed using the latest CentOS 6.5 squid but since the current stable version is 3.4.8 you should try to upgrade(to something else then 3.1) due to other issues.

The issue can be a network or dns related issue which was not detected until now.

Please first make sure that the access.log and cache.log files are clean for errors or issues.

What dns servers are you using?

Eliezer

On 10/07/2014 06:51 AM, glenn.groves at bradnams.com.au wrote:
> Hi All,
> 
> We have a weird issue where https sites apparently don't respond (get 
> message "this page can't be displayed"). This mainly affects google 
> websites and to a lesser affect youtube. It has been reported it may 
> have affected some banking sites but this is unconfirmed. We are 
> running centos 6.5 with up to date squid from the centos repositories.
> 
> Here is the version of squid: yum list installed | grep squid 
> squid.x86_64                         7:3.1.10-20.el6_5.3
> 
> The https sites work fine if I put a direct hole in the firewall to 
> allow internet traffic directly out - but this is not a solution.
> 
> Thanks, Glenn

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUNF1uAAoJENxnfXtQ8ZQUlfYH/i0o9MQDTt8g5aINRljVSMZc
btC8mcYn/JYn4WUPIoOc4/MhvuYg0JO6hXsSoPxjI1khMrq9fTV2c8eaLItWqYCf
hjioWPJs2hPwfw6WDi0I6kF0Is+hD/MGsJci7s+jg593lHnm+ZjoDIHj0aCpcdgy
u95961yZWXINbYsjTirFftnX5UC5MWbwZjaah6zW84RKZl/pa1vJM/tdgqiLdE5V
GDNhS01mbKPfin8oc/RQk4nYAK39vncSebvSHJwkvPJIKlb54Yti64j6qUfPsav3
uUvIVKSpxZjFFJoLtw1zjn1MwyynoHNGT1lP+HptsGkDoeGJ6YWU/IwB1sFKcVk=
=GKmE
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
 
This message (including any attachments) is confidential and may be legally privileged. If you are not the intended recipient, you should not disclose, copy or use any part of it - please delete all copies immediately and notify the Bradnam Group Helpdesk at helpdesk at bradnams.com.au 

Any information, statements or opinions contained in this message (including any attachments) are given by the author. They are not given on behalf of the Bradnam Group unless subsequently confirmed by an individual other than the author who is duly authorised to represent the Bradnam Group (or any of its subsidiary and associate companies).

All sent and received email from/to the Bradnam Group (or any of its subsidiary and associate companies) is automatically scanned for the presence of computer viruses, security issues and inappropriate content.

For further information on the services which the Bradnam Group provides visit our web
site(s) at www.bradnams.com.au or www.nationalglass.com.au _______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Sun Dec  7 09:34:26 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 07 Dec 2014 22:34:26 +1300
Subject: [squid-users] https issues for google
In-Reply-To: <2329B68B3D676246BA0D1149E22F509F01A6FBA2@bneseqs20.bradnams.com.au>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
 <2329B68B3D676246BA0D1149E22F509F01A6FBA2@bneseqs20.bradnams.com.au>
Message-ID: <54841F22.90206@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 7/12/2014 9:48 p.m., glenn.groves wrote:
> Hi All,
> 
> I have finally been able to spend time upgrading a server to a
> later squid version, I have tried 3.4.9.
> 
> I could not get authentication to work for this test, but proceeded
> to test without (also dismisses auth as the problem).
> 
> I am getting the following in the logs with secure sites now the
> squid is 3.4.9:
> 
> 192.168.9.69 TCP_MISS/200 295 CONNECT www.google.com:443 -
> HIER_DIRECT/216.58.220.1 192.168.9.69 TCP_MISS/200 0 CONNECT
> www.google.com:443 - HIER_DIRECT/216.58.220.132
> 
> Upgrading to 3.4.9 on Centos as been a pain so far, no point in
> proceeding with the problem persisting. Can someone advise why I am
> getting TCP_MISS/200 when going to secure google sites?
> 

"200" because the tunnel was setup successfully.

"TCP_MISS" because a connection being opened does not use an existing
cache object. Old Squid versions do not use the TCP_TUNNEL label.

The above appear to be successful tunnels setup through the proxy.


> Or more importantly, how to fix my squid 3.1 on centos 6.5 with
> this problem.
> 

What browser(s) are showing the problem? and what does a tcpdump trace
of the packets content show happening?

A) It could be they are trying to use SPDY or HTTP/2 inside the
tunnel. CONNECT technically could be followed immediately with traffic
bytes even though the tunnel/Upgrade process was not confirmed
successful by the proxy. Squid does not support that behaviour until
version 3.4.5 (bug 3371) but browsers using SPDY and HTTP/2 rely on it.

You may be able to backport the bug fix
(http://www.squid-cache.org/Versions/v3/3.4/changesets/squid-3.4-13126.patch),
but this is one unlikely to be easy across so many versions. There
have been numerous tunneling code updates in between.


B) It could be happy-eyeballs algorithm being used by the browser.
Settign up a connection in advance and having it timeout in the proxy
before an attempt to actually use it is made. Although Squid should
append _TIMEOUT to the MISS tag in those cases its not certain if that
happens on tunnels.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUhB8iAAoJELJo5wb/XPRjfsIH/jFvpT7a/lHZfM8uaMxoUVu4
oGLoyjx6m1ZEg/W5Ta+TjlnfJjcyqfZdkHeIJzY9athcAWaxcT/By2sFEhuPqdtJ
hbps9UWbcae3Uu8sL71oABPnNvfH23HpU6q3PBrNRv82K8jrFjS56oEFwCQrKavP
pxfirbNk0MZg9/bLDAGnD05ItKAxo+uQ2xQU0AE/z6z3LE23WaMS4axTNLBS2icP
V9y2D90mH35nMlaFkhSPl1oL8HfQ1yOuKoNJz2YSgIsgiEmGBsF9aRQ+FS1CgiSh
HFFDyY+dAQUOFL9Qv/gJjddWhQAqH3X6kjqUCqgzqp+eHCOfrQGWzG6Wv42X7/k=
=P6Ev
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Sun Dec  7 10:44:36 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 07 Dec 2014 23:44:36 +1300
Subject: [squid-users] Packet Marking for Traffic Shaping
In-Reply-To: <CA+Y8hcOF26oWAOPYoXfnRUn1ER=LQ7k7SaypGiBJSzS=w5uhcQ@mail.gmail.com>
References: <CAPHknWNrQBgSXwoUrPZ=qt3aDaPPnHrS7UHvG8X+j3enWXvrzg@mail.gmail.com>
 <CA+Y8hcOF26oWAOPYoXfnRUn1ER=LQ7k7SaypGiBJSzS=w5uhcQ@mail.gmail.com>
Message-ID: <54842F94.4080504@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 7/12/2014 7:49 a.m., Kinkie wrote:
> Hello Osmany, have you tried
> http://wiki.squid-cache.org/Features/QualityOfService ?
> 

http://www.squid-cache.org/Doc/config/tcp_outgoing_tos/ is likey to be
more relevant since it is for the server traffic, not the client traffic.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUhC+TAAoJELJo5wb/XPRj8tsH/3udS8qCru/6pv3Q+CrJJpyp
mjwVnSado55xF4ADQad7uo92cmLBHZfQFNArPkRJ7eImiUqK0cwj8Ofs2nqHSSiw
scgGnD94xmMZ9LLFBaJ+vc4fzvwCh9+75jLEKN59iuvZz9IQm8N84Hcde/EraRYC
6ZL23Su8HvESQLCbguNym0iIZ/uHO2Ho/0apxBOJU6BF/F144HM9Q8HCsEIqT2so
aOkJDCesbycHkQoOvzzqaakMaLaxUJZcJPXApIRtfoAR+mYzjV0e0ywkT3RFviFe
nse9IfHsbyFk/MvVbupYoi9cOmppmsrckWYEr4NPLBoosxOaZlE015xrg/P5lZo=
=dyoJ
-----END PGP SIGNATURE-----


From jeg1972 at gmail.com  Sun Dec  7 19:32:25 2014
From: jeg1972 at gmail.com (John Gardner)
Date: Sun, 7 Dec 2014 19:32:25 +0000
Subject: [squid-users] Running SCCM through Squid
Message-ID: <CAFFsz+LLWkU6U15Liydc+a68LrUt+po4AJCsqohWHRfzOXR6iQ@mail.gmail.com>

Hi everyone, I'm posting this in the hope that someone will have some
experience in connecting Microsoft System Center Configuration Manager
(SCCM) through a Squid Reverse Proxy in Internet-Based Client
Management mode.  Basically, at the moment we use SCCM through an MS
TMG server in Reverse Proxy configuration and this works (probably
because Microsoft have lots documentation on this on their site), but
due to the fact that MS are phasing out TMG, we want another solution
for patching our laptops when they are off the network but on the
Internet.

What should happen is that when a laptop is off the LAN but on the
Internet, it communicates back to the SCCM server via HTTPS through
port 443. The authentication happens as there is a certificate on the
laptop which has a organisational CA in common and once authenticated,
all of the patches should roll out.

When we try to connect through Squid, the traffic does get through
from the laptop to the SCCM server, but we do have issues.

The configuration in Squid is as follows (running on Squid 3.4);


https_port xx.xx.xx.44:443 accel
cert=/usr/newrprgate/CertAuth/ibcm.ourdomain.com/ibcm.crt
key=/usr/newrprgate/CertAuth/ibcm.ourdomain.com/ibcm_key.pem
cipher=ALL:!aNULL:!ADH:!eNULL:!LOW:!EXP:RC4+RSA:+HIGH:+MEDIUM
options=NO_SSLv2,NO_SSLv3 defaultsite=server_4.btstl.co.uk
cache_peer xx.xx.xx.60 parent 443 0 no-query originserver login=PASS
connection-auth=on ssl
sslcert=/usr/newrprgate/CertAuth/ibcm.ourdomain.com/peer_keys/IBCM.pem
sslversion=1 sslflags=DONT_VERIFY_PEER front-end-https
name=server_4_https
acl sites_server_4 dstdomain ibcm.ourdomain.com
cache_peer_access server_4_https allow sites_server_4
cache_peer_access server_4_https deny all

And the log looks like this;

81.XX.XX.XX - - [05/Dec/2014:11:43:33 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:11:51:16 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:11:54:44 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:11:57:44 +0000] "CCM_POST
https://ibcm.ourdomain.com/bgb/handler.ashx? HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:02:55 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:02:55 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:02:55 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:22:13 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:22:13 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:22:13 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:22:14 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:31:27 +0000] "CCM_POST
https://ibcm.ourdomain.com/bgb/handler.ashx? HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:39:37 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:39:38 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:39:38 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:40:48 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:42:28 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:45:39 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT
81.XX.XX.XX - - [05/Dec/2014:12:51:19 +0000] "CCM_POST
https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560
TCP_MISS:FIRSTUP_PARENT

So obviously, we are connecting, but getting a 403 error back.  The
configuration on the SCCM server does appear to be correct, so we are
examining whether we have configured the Squid part correctly... Does
anyone have any experience of doing this?

Thanks in advance

John


From Jason_Haar at trimble.com  Sun Dec  7 20:04:50 2014
From: Jason_Haar at trimble.com (Jason Haar)
Date: Mon, 8 Dec 2014 09:04:50 +1300
Subject: [squid-users] Running SCCM through Squid
In-Reply-To: <CAFFsz+LLWkU6U15Liydc+a68LrUt+po4AJCsqohWHRfzOXR6iQ@mail.gmail.com>
References: <CAFFsz+LLWkU6U15Liydc+a68LrUt+po4AJCsqohWHRfzOXR6iQ@mail.gmail.com>
Message-ID: <5484B2E2.9040601@trimble.com>

I don't think you can do it. The "SCCM protocol" is *NOT* HTTP - the
geniuses at Microsoft created this faux-HTTP that runs on standard HTTP
ports - I think you'll find only IIS supports it.

Unless you can make squid proxy non-HTTP traffic, I think you're out of
luck. We're looking at doing the same thing using client certs and will
probably use stunnel (instead of laying the SCCM server bare-assed on
the Internet)

Jason

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From glenn.groves at bradnams.com.au  Sun Dec  7 20:46:35 2014
From: glenn.groves at bradnams.com.au (glenn.groves at bradnams.com.au)
Date: Mon, 8 Dec 2014 06:46:35 +1000
Subject: [squid-users] https issues for google
In-Reply-To: <54841F22.90206@treenet.co.nz>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
 <2329B68B3D676246BA0D1149E22F509F01A6FBA2@bneseqs20.bradnams.com.au>
 <54841F22.90206@treenet.co.nz>
Message-ID: <2329B68B3D676246BA0D1149E22F509F01A6FBA4@bneseqs20.bradnams.com.au>

Hi All and Amos,

Thanks for correcting me on thinking that was an error.

Even though squid is logging TCP_200, the browser states the proxy server is not responding. This is again only with secure sites, mainly google sites. It is fairly reproducible now with google mail.

On IE, the error is :the proxy server is not responding"
On Chrome: "ERR_SSL_PROTOCOL_ERROR"
On Firefox "ssl_error_rx_record_too_long"

If I bypass the proxy and go direct to the internet through our firewall, it works fine.

This suggests to me, without having any errors in squid to go by, that squid is doing something to the SSL record. What can I do to try and fix or diagnose? 

Thanks,

Glenn

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Sunday, 7 December 2014 7:34 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] https issues for google

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 7/12/2014 9:48 p.m., glenn.groves wrote:
> Hi All,
> 
> I have finally been able to spend time upgrading a server to a later 
> squid version, I have tried 3.4.9.
> 
> I could not get authentication to work for this test, but proceeded to 
> test without (also dismisses auth as the problem).
> 
> I am getting the following in the logs with secure sites now the squid 
> is 3.4.9:
> 
> 192.168.9.69 TCP_MISS/200 295 CONNECT www.google.com:443 -
> HIER_DIRECT/216.58.220.1 192.168.9.69 TCP_MISS/200 0 CONNECT
> www.google.com:443 - HIER_DIRECT/216.58.220.132
> 
> Upgrading to 3.4.9 on Centos as been a pain so far, no point in 
> proceeding with the problem persisting. Can someone advise why I am 
> getting TCP_MISS/200 when going to secure google sites?
> 

"200" because the tunnel was setup successfully.

"TCP_MISS" because a connection being opened does not use an existing cache object. Old Squid versions do not use the TCP_TUNNEL label.

The above appear to be successful tunnels setup through the proxy.


> Or more importantly, how to fix my squid 3.1 on centos 6.5 with this 
> problem.
> 

What browser(s) are showing the problem? and what does a tcpdump trace of the packets content show happening?

A) It could be they are trying to use SPDY or HTTP/2 inside the tunnel. CONNECT technically could be followed immediately with traffic bytes even though the tunnel/Upgrade process was not confirmed successful by the proxy. Squid does not support that behaviour until version 3.4.5 (bug 3371) but browsers using SPDY and HTTP/2 rely on it.

You may be able to backport the bug fix
(http://www.squid-cache.org/Versions/v3/3.4/changesets/squid-3.4-13126.patch),
but this is one unlikely to be easy across so many versions. There have been numerous tunneling code updates in between.


B) It could be happy-eyeballs algorithm being used by the browser.
Settign up a connection in advance and having it timeout in the proxy before an attempt to actually use it is made. Although Squid should append _TIMEOUT to the MISS tag in those cases its not certain if that happens on tunnels.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUhB8iAAoJELJo5wb/XPRjfsIH/jFvpT7a/lHZfM8uaMxoUVu4
oGLoyjx6m1ZEg/W5Ta+TjlnfJjcyqfZdkHeIJzY9athcAWaxcT/By2sFEhuPqdtJ
hbps9UWbcae3Uu8sL71oABPnNvfH23HpU6q3PBrNRv82K8jrFjS56oEFwCQrKavP
pxfirbNk0MZg9/bLDAGnD05ItKAxo+uQ2xQU0AE/z6z3LE23WaMS4axTNLBS2icP
V9y2D90mH35nMlaFkhSPl1oL8HfQ1yOuKoNJz2YSgIsgiEmGBsF9aRQ+FS1CgiSh
HFFDyY+dAQUOFL9Qv/gJjddWhQAqH3X6kjqUCqgzqp+eHCOfrQGWzG6Wv42X7/k=
=P6Ev
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
 
This message (including any attachments) is confidential and may be legally privileged. If you are not the intended recipient, you should not disclose, copy or use any part of it - please delete all copies immediately and notify the Bradnam Group Helpdesk at helpdesk at bradnams.com.au 

Any information, statements or opinions contained in this message (including any attachments) are given by the author. They are not given on behalf of the Bradnam Group unless subsequently confirmed by an individual other than the author who is duly authorised to represent the Bradnam Group (or any of its subsidiary and associate companies).

All sent and received email from/to the Bradnam Group (or any of its subsidiary and associate companies) is automatically scanned for the presence of computer viruses, security issues and inappropriate content.

For further information on the services which the Bradnam Group provides visit our web 
site(s) at www.bradnams.com.au or www.nationalglass.com.au


From eliezer at ngtech.co.il  Sun Dec  7 22:33:08 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 08 Dec 2014 00:33:08 +0200
Subject: [squid-users] https issues for google
In-Reply-To: <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
Message-ID: <5484D5A4.3050708@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Glenn,

I noticed that in the mean while you have upgraded the system to
latest 3.4.9 stable.
As Amos mentioned there are couple options about the tunneling issues.
I am unsure about the issue since in my environment squid seems to not
have any issues.
I would suggest a testing path for the issue before applying patches
blindly.
My suggestion is:
- - use one and only one client
- - run a tracepath from the client to the relevant sites.
- - test using wget\curl\script a tunnel request to
https:/www.gmail.com/ or https://mail.google.com/ throw the proxy from
the mentioned client.(there is a wget binary for windows)
- - if the issue accrues to this client try to remove the authentication
only for this client ip and try again.

The above test will isolate the issue from multiple clients and
unknown source to only one.
If you are familiar with PMTU or iptables clamping it will help to
test it more in depth.
I assume that you are using a Linux OS and I would prefer to get some
details about it as a starter.

Thanks,
Eliezer

On 10/09/2014 02:04 AM, glenn.groves at bradnams.com.au wrote:
> Could squid be getting mixed up when mulipule https requests are to
> the same address (e.g. https://google.com.au)?
> 
> Thanks,
> 
> Glenn

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUhNWkAAoJENxnfXtQ8ZQUhjkIAIt13ZuSaMx7HyLYExUmAxPW
djzEj9DK6YBEUexeSA5hfIqRFwA0wRXK1a4fAni8J5v7iVqqdLj4Cwnx1C3Jf9Gc
fl9pRBbDNl8SMHWUPvxv0PELRgGzjGN76CXHB7aARbAKaOd6raajlbdl0ltro2D6
UyTaAjG2lc2yH/kJAGHsnjpEztkxWezdBWO3SC8Ej4bEdctfRfSEXeZDI0fQsSsg
D3vVG/ppGOSnivMfeQiaUSmexhaFI6XO0wrrj4uyeJ/ptVC0ZkikkCDCp3xRWEAt
BK0fgRJtUbc7jroqPx7ec+2l3gtZCbK8fMDwPMt2ut5IXevPFO8B4a16dPk40uM=
=6hKW
-----END PGP SIGNATURE-----


From glenn.groves at bradnams.com.au  Mon Dec  8 00:25:17 2014
From: glenn.groves at bradnams.com.au (glenn.groves at bradnams.com.au)
Date: Mon, 8 Dec 2014 10:25:17 +1000
Subject: [squid-users] https issues for google
In-Reply-To: <5484D5A4.3050708@ngtech.co.il>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
 <5484D5A4.3050708@ngtech.co.il>
Message-ID: <2329B68B3D676246BA0D1149E22F509F01A6FBBA@bneseqs20.bradnams.com.au>

Hi Eliezer,

Thanks for the response,

-- I am doing this on a clone of the original proxy with the issue, this frees me up to test, largely I am testing from one client - but try others every now and again to check, it is windows.
-- I am not sure as to the idea of the tracepath  from the client, it is a windows client so I did try mturoute, but it fails as it is trying to go direct, not through the proxy. If I enable direct in our firewall, the SSL sites work fine.
-- In the web browser I found if I go to secure google.com sites I get the errors, if I go to secure google.com.au site I do not.
-- I decided to do a tracepath from the proxy itself. Both google.com and google.com.au return the same output:
tracepath www.google.com.au
 1:  Proxy Ext IP (Proxy Ext IP)                      0.059ms pmtu 1500
 1:  firewall gateway (firewall gateway)                      0.513ms asymm  2
 1:  firewall gateway (firewall gateway)                      0.384ms asymm  2
 2:  Internet IP (Internet IP)                        1.105ms
 3:  woo6.brisbane.telstra.net (165.228.143.1)   2.540ms
 4:  tengige0-8-0-2.woo-core1.brisbane.telstra.net (203.50.51.129)   4.136ms
 5:  bundle-ether11.chw-core10.sydney.telstra.net (203.50.11.70)  15.819ms
 6:  bundle-ether1.chw48.sydney.telstra.net (203.50.6.154)  23.194ms
 7:  no reply
 8:  no reply

-- I used wget and test this out:

https://www.google.com.au

wget -e https_proxy= proxyserver:port https://www.google.com.au
converted 'https://www.google.com.au' (ASCII) -> 'https://www.google.com.au' (UTF-8)
--2014-12-08 09:58:18--  https://www.google.com.au/
Resolving proxyserver (proxyserver)... IP ADDRESS

Connecting to proxyserver(proxyserver)| IP ADDRESS |:port... connected.
ERROR: cannot verify www.google.com.au's certificate, issued by '/C=US/O=Google
Inc/CN=Google Internet Authority G2':
  Unable to locally verify the issuer's authority.
To connect to www.google.com.au insecurely, use `--no-check-certificate'.

https://www.google.com

wget -e https_proxy=proxyserver:port https://www.google.com
converted 'https://www.google.com' (ASCII) -> 'https://www.google.com' (UTF-8)
--2014-12-08 09:55:29--  https://www.google.com/
Resolving proxyserver (proxyserver)... IP ADDRESS

Connecting to proxyserver (proxyserver)|IP ADDRESS|:PORT... connected.
Unable to establish SSL connection.

-- So this shows that SSL to google.com is a problem through the proxy, but google.com.au is not.

I am using linux, it is Centos 6.5, standard install, iptables, 2 interfaces - one for internal traffic to get out, the other on DMZ for the out traffic.

--Iptables is enabled, I suspect this should not be a problem there as some SSL sites work.
-- We do not use IPV6, I have tried disabling IPV6 in Centos and leaving as is, no difference there.


I do not have great experience in iptables of PMTU.


On a last note, I did wget on the proxy itself, I did not specify to go through squid so should have gone direct, the problem exists there too, seems squid may not be the issue but I would appreciate if I could have help on the issue:

#  wget https://www.google.com
--2014-12-08 10:14:39--  https://www.google.com/
Resolving www.google.com... 216.58.220.132, 2404:6800:4006:800::2004
Connecting to www.google.com|216.58.220.132|:443... connected.
OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol
Unable to establish SSL connection.

#wget https://www.google.com.au
--2014-12-08 10:15:04--  https://www.google.com.au/
Resolving www.google.com.au... 216.58.220.131, 2404:6800:4006:800::2003
Connecting to www.google.com.au|216.58.220.131|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified [text/html]
Saving to: ?index.html?

    [ <=>                                                                                                                                                                                                ] 19,467      --.-K/s   in 0s

2014-12-08 10:15:04 (38.8 MB/s) - ?index.html?



-----Original Message-----
From: Eliezer Croitoru [mailto:eliezer at ngtech.co.il] 
Sent: Monday, 8 December 2014 8:33 AM
To: squid-users at lists.squid-cache.org
Cc: Glenn Groves
Subject: Re: [squid-users] https issues for google

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Glenn,

I noticed that in the mean while you have upgraded the system to latest 3.4.9 stable.
As Amos mentioned there are couple options about the tunneling issues.
I am unsure about the issue since in my environment squid seems to not have any issues.
I would suggest a testing path for the issue before applying patches blindly.
My suggestion is:
- - use one and only one client
- - run a tracepath from the client to the relevant sites.
- - test using wget\curl\script a tunnel request to https:/www.gmail.com/ or https://mail.google.com/ throw the proxy from the mentioned client.(there is a wget binary for windows)
- - if the issue accrues to this client try to remove the authentication only for this client ip and try again.

The above test will isolate the issue from multiple clients and unknown source to only one.
If you are familiar with PMTU or iptables clamping it will help to test it more in depth.
I assume that you are using a Linux OS and I would prefer to get some details about it as a starter.

Thanks,
Eliezer

On 10/09/2014 02:04 AM, glenn.groves at bradnams.com.au wrote:
> Could squid be getting mixed up when mulipule https requests are to 
> the same address (e.g. https://google.com.au)?
> 
> Thanks,
> 
> Glenn

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUhNWkAAoJENxnfXtQ8ZQUhjkIAIt13ZuSaMx7HyLYExUmAxPW
djzEj9DK6YBEUexeSA5hfIqRFwA0wRXK1a4fAni8J5v7iVqqdLj4Cwnx1C3Jf9Gc
fl9pRBbDNl8SMHWUPvxv0PELRgGzjGN76CXHB7aARbAKaOd6raajlbdl0ltro2D6
UyTaAjG2lc2yH/kJAGHsnjpEztkxWezdBWO3SC8Ej4bEdctfRfSEXeZDI0fQsSsg
D3vVG/ppGOSnivMfeQiaUSmexhaFI6XO0wrrj4uyeJ/ptVC0ZkikkCDCp3xRWEAt
BK0fgRJtUbc7jroqPx7ec+2l3gtZCbK8fMDwPMt2ut5IXevPFO8B4a16dPk40uM=
=6hKW
-----END PGP SIGNATURE-----
 
This message (including any attachments) is confidential and may be legally privileged. If you are not the intended recipient, you should not disclose, copy or use any part of it - please delete all copies immediately and notify the Bradnam Group Helpdesk at helpdesk at bradnams.com.au 

Any information, statements or opinions contained in this message (including any attachments) are given by the author. They are not given on behalf of the Bradnam Group unless subsequently confirmed by an individual other than the author who is duly authorised to represent the Bradnam Group (or any of its subsidiary and associate companies).

All sent and received email from/to the Bradnam Group (or any of its subsidiary and associate companies) is automatically scanned for the presence of computer viruses, security issues and inappropriate content.

For further information on the services which the Bradnam Group provides visit our web 
site(s) at www.bradnams.com.au or www.nationalglass.com.au


From james at ejbdigital.com.au  Mon Dec  8 02:13:55 2014
From: james at ejbdigital.com.au (James Harper)
Date: Mon, 8 Dec 2014 02:13:55 +0000
Subject: [squid-users] https issues for google
In-Reply-To: <2329B68B3D676246BA0D1149E22F509F01A6FBA4@bneseqs20.bradnams.com.au>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
 <2329B68B3D676246BA0D1149E22F509F01A6FBA2@bneseqs20.bradnams.com.au>
 <54841F22.90206@treenet.co.nz>
 <2329B68B3D676246BA0D1149E22F509F01A6FBA4@bneseqs20.bradnams.com.au>
Message-ID: <HKXPR04MB200F5A9B8D1AEF40A7AA94FE8640@HKXPR04MB200.apcprd04.prod.outlook.com>

> 
> On IE, the error is :the proxy server is not responding"
> On Chrome: "ERR_SSL_PROTOCOL_ERROR"
> On Firefox "ssl_error_rx_record_too_long"
> 
> If I bypass the proxy and go direct to the internet through our firewall, it
> works fine.
> 
> This suggests to me, without having any errors in squid to go by, that squid is
> doing something to the SSL record. What can I do to try and fix or diagnose?
> 

I've seen that when squid is returning a HTML page (error, denied, not found, etc). Seems strange that a 200 is being logged if that's the case though...

Can you do a tcpdump on the traffic and see what is happening, and if the response looks like SSL, or more like plaintext HTML?

James


From squid3 at treenet.co.nz  Mon Dec  8 02:14:32 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 08 Dec 2014 15:14:32 +1300
Subject: [squid-users] Running SCCM through Squid
In-Reply-To: <CAFFsz+LLWkU6U15Liydc+a68LrUt+po4AJCsqohWHRfzOXR6iQ@mail.gmail.com>
References: <CAFFsz+LLWkU6U15Liydc+a68LrUt+po4AJCsqohWHRfzOXR6iQ@mail.gmail.com>
Message-ID: <54850988.3010709@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 8/12/2014 8:32 a.m., John Gardner wrote:
> Hi everyone, I'm posting this in the hope that someone will have
> some experience in connecting Microsoft System Center Configuration
> Manager (SCCM) through a Squid Reverse Proxy in Internet-Based
> Client Management mode.  Basically, at the moment we use SCCM
> through an MS TMG server in Reverse Proxy configuration and this
> works (probably because Microsoft have lots documentation on this
> on their site), but due to the fact that MS are phasing out TMG, we
> want another solution for patching our laptops when they are off
> the network but on the Internet.
> 
> What should happen is that when a laptop is off the LAN but on the 
> Internet, it communicates back to the SCCM server via HTTPS
> through port 443. The authentication happens as there is a
> certificate on the laptop which has a organisational CA in common
> and once authenticated, all of the patches should roll out.
> 
> When we try to connect through Squid, the traffic does get through 
> from the laptop to the SCCM server, but we do have issues.
> 
> The configuration in Squid is as follows (running on Squid 3.4);
> 
> 
> https_port xx.xx.xx.44:443 accel 
> cert=/usr/newrprgate/CertAuth/ibcm.ourdomain.com/ibcm.crt 
> key=/usr/newrprgate/CertAuth/ibcm.ourdomain.com/ibcm_key.pem 
> cipher=ALL:!aNULL:!ADH:!eNULL:!LOW:!EXP:RC4+RSA:+HIGH:+MEDIUM 
> options=NO_SSLv2,NO_SSLv3 defaultsite=server_4.btstl.co.uk 
> cache_peer xx.xx.xx.60 parent 443 0 no-query originserver
> login=PASS connection-auth=on ssl 
> sslcert=/usr/newrprgate/CertAuth/ibcm.ourdomain.com/peer_keys/IBCM.pem
>
> 
sslversion=1 sslflags=DONT_VERIFY_PEER front-end-https
> name=server_4_https acl sites_server_4 dstdomain
> ibcm.ourdomain.com cache_peer_access server_4_https allow
> sites_server_4 cache_peer_access server_4_https deny all
> 
> And the log looks like this;
> 
> 81.XX.XX.XX - - [05/Dec/2014:11:43:33 +0000] "CCM_POST 
> https://ibcm.ourdomain.com/ccm_system/request HTTP/1.1" 403 1560 
> TCP_MISS:FIRSTUP_PARENT
<snip>

> 
> So obviously, we are connecting, but getting a 403 error back.
> The configuration on the SCCM server does appear to be correct, so
> we are examining whether we have configured the Squid part
> correctly... Does anyone have any experience of doing this?
> 

Assuming Jason is right about it being a not-quite-HTTP protocol can
you please enable debug_options 11,2 to see what messages SCCM is
sending to Squid. I might be able to do something about it.

Also check that you have this at or near the top of your http_access
rules:
  http_access allow sites_server_4

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUhQmHAAoJELJo5wb/XPRj8cAIAIk3BMDvxfCpn+8b0MzIVN8E
61lyU1KesNrvS9irv07LN6iro7Wj79TXqDPRcZ95OHnnHUyvjoBtBUvHJoADQvWQ
2sU0ZU37UjBRP5xLvaoA4uDT2JH/UJbxVdY5k55yiKqzlPw9ma7IF71Tw0xSzcnz
P5f2Mai+w4agkXo1s2p6aVHqf0G0ZkHryYZcE7tT8/ee2gDPelhbB3wShcpcuvOS
Qt5x9MS7pdU3SC6bpam01kf1pOxMaRLVdyk9u3t5pXcKAmPZR8FDAS1K5kpmJuXH
r+277c90PPFQzUIwJrki1T7nn+dGFtYVvs8IntCUUIrfjO+iC1+iKkz1KvelCUM=
=LHwZ
-----END PGP SIGNATURE-----


From vrogoziansky.squid at gmail.com  Tue Dec  2 18:32:36 2014
From: vrogoziansky.squid at gmail.com (Vadim Rogoziansky)
Date: Tue, 02 Dec 2014 20:32:36 +0200
Subject: [squid-users] Transparent proxy with Peek and Splice feature.
In-Reply-To: <547948CF.5040408@treenet.co.nz>
References: <5474C8CF.6030404@gmail.com> <54759E6C.5080404@treenet.co.nz>
 <54772BB5.5010101@gmail.com> <547948CF.5040408@treenet.co.nz>
Message-ID: <547E05C4.9070705@gmail.com>

Yeap, squid perfectly "splice" the destination domain after step1 or 
step2 or step3 when the browser is set to use proxy directly.
But, it does not work in case of transparent proxy. Squid uses client IP 
address instead of SNI details.

I've attached squid debug log.
The example of using client IP address is below:
2014/11/27 01:15:22.851| DomainData.cc(110) match: aclMatchDomainList: 
'212.42.77.232' NOT found

Thank you guys.

11/29/2014 6:17 AM, Amos Jeffries ???????(??):
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 28/11/2014 2:48 a.m., Vadim Rogoziansky wrote:
>> Hello Amos.
>>
>> Thank you for answer.
>>
>> There was made an investigation related to squid's peek and splice
>> issues in transparent mode. One-line explanation is as follows - in
>> intercept mode squid can't get a server host name from the request
>> header and uses clent IP address instead for both fake cert
>> generation and as a SNI record in server bump SSL handshaking. This
>> is the root of the problem. However this can be fixed if squid uses
>> SNI field taken from client TLS Hello message for that purposes.
>> Can you hack squid in this way? What do you think?
> I think peek-n-splice is supposed to already be doing that.
>
> However it does depend on whether you are bumping the connection at
> step 1 (before ClientHello), step 2 (after ClientHello, before
> ServerHello), or step 3 (after both ClientHello and ServerHello) of
> the TLS handshake whether the SNI details are present.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUeUjPAAoJELJo5wb/XPRj6QEIAOHrR8wmDcjkfgUh2UtPwpHP
> vVkPMEuIrUq9Gxx3uSojCZjlFJPuCQ2UafS1p8LuxcEQ+TRmUFbAu4AkKoO2RoZ5
> 7fCGoiXTwn4TzFf0pLh9SPBq9j12OJ3uT28EEqbILrT0sbKP02xK/qiJfCLR61Ev
> vprAdggapbKg/ns1l1H3BBgZR2A4W/abQPIq6/Eu/r+7nYK6L2oOdqPDWTJjudMV
> 8D9sdOD9mYYryrdptU0GLh9Q/V5QEhipSkuA936iZ0Dfa2ZSr4gphJyaRAFWSMf3
> q502lZy+ASkDa2vAbjALRBgn3VwYWl8KBQcypUKF4UXtaLtF0EIrLMun+p4QxUM=
> =44aG
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
2014/11/27 01:15:22.431| debug.cc(403) parseOptions: command-line -X overrides: ALL,7
2014/11/27 01:15:22.431| cache_manager.cc(80) registerProfile: registering legacy mem
2014/11/27 01:15:22.431| cache_manager.cc(114) findAction: CacheManager::findAction: looking for action mem
2014/11/27 01:15:22.431| cache_manager.cc(122) findAction: Action not found.
2014/11/27 01:15:22.431| cache_manager.cc(65) registerProfile: registered profile: mem
2014/11/27 01:15:22.431| cache_manager.cc(80) registerProfile: registering legacy squidaio_counts
2014/11/27 01:15:22.431| cache_manager.cc(114) findAction: CacheManager::findAction: looking for action squidaio_counts
2014/11/27 01:15:22.431| cache_manager.cc(122) findAction: Action not found.
2014/11/27 01:15:22.431| cache_manager.cc(65) registerProfile: registered profile: squidaio_counts
2014/11/27 01:15:22.431| cache_manager.cc(114) findAction: CacheManager::findAction: looking for action diskd
2014/11/27 01:15:22.432| cache_manager.cc(122) findAction: Action not found.
2014/11/27 01:15:22.432| cache_manager.cc(65) registerProfile: registered profile: diskd
2014/11/27 01:15:22.432| rock/RockStoreFileSystem.cc(50) setup: Will use Rock FS
2014/11/27 01:15:22.432| Startup: Initializing Authentication Schemes ...
2014/11/27 01:15:22.432| Startup: Initialized Authentication Scheme 'basic'
2014/11/27 01:15:22.432| Startup: Initialized Authentication Scheme 'digest'
2014/11/27 01:15:22.432| Startup: Initialized Authentication Scheme 'negotiate'
2014/11/27 01:15:22.432| Startup: Initialized Authentication.
2014/11/27 01:15:22.432| tools.cc(63) ProbeTransport: IPv6 transport forced OFF by build parameters.
2014/11/27 01:15:22.432| Config.cc(48) registerTokens:  register format tokens for 'adapt'
2014/11/27 01:15:22.432| Config.cc(48) registerTokens:  register format tokens for 'icap'
2014/11/27 01:15:22.432| Config.cc(48) registerTokens:  register format tokens for 'ssl'
2014/11/27 01:15:22.432| cache_cf.cc(570) parseConfigFile: 
2014/11/27 01:15:22.432| cf_parser.cci(4094) free_all: 
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type ssl_error
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.432| Acl.cc(97) FindByName: ACL::FindByName 'ssl::certHasExpired'
2014/11/27 01:15:22.432| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.432| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'ssl::certHasExpired'
2014/11/27 01:15:22.432| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'ssl_error'
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5cc98
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type ssl_error
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.432| Acl.cc(97) FindByName: ACL::FindByName 'ssl::certNotYetValid'
2014/11/27 01:15:22.432| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.432| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'ssl::certNotYetValid'
2014/11/27 01:15:22.432| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'ssl_error'
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5b398
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type ssl_error
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.432| Acl.cc(97) FindByName: ACL::FindByName 'ssl::certDomainMismatch'
2014/11/27 01:15:22.432| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.432| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'ssl::certDomainMismatch'
2014/11/27 01:15:22.432| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'ssl_error'
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5bf98
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type ssl_error
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.432| Acl.cc(97) FindByName: ACL::FindByName 'ssl::certUntrusted'
2014/11/27 01:15:22.432| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.432| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'ssl::certUntrusted'
2014/11/27 01:15:22.432| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'ssl_error'
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5afc8
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5c448
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5bff8
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5d028
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5d098
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5d308
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type ssl_error
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.432| Acl.cc(97) FindByName: ACL::FindByName 'ssl::certSelfSigned'
2014/11/27 01:15:22.432| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.432| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'ssl::certSelfSigned'
2014/11/27 01:15:22.432| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'ssl_error'
2014/11/27 01:15:22.432| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c5b7e8
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type src
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.432| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/11/27 01:15:22.432| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.432| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'all'
2014/11/27 01:15:22.432| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'src'
2014/11/27 01:15:22.432| Ip.cc(233) FactoryParse: aclIpParseIpData: all
2014/11/27 01:15:22.432| Ip.cc(237) FactoryParse: aclIpParseIpData: magic 'all' found.
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type url_regex
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.432| Acl.cc(97) FindByName: ACL::FindByName 'manager'
2014/11/27 01:15:22.432| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.432| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'manager'
2014/11/27 01:15:22.432| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'url_regex'
2014/11/27 01:15:22.432| RegexData.cc(303) aclParseRegexList: aclParseRegexList: new Regex line or file
2014/11/27 01:15:22.432| RegexData.cc(311) aclParseRegexList: aclParseRegexList: buffering RE '-i'
2014/11/27 01:15:22.432| RegexData.cc(311) aclParseRegexList: aclParseRegexList: buffering RE '^cache_object://'
2014/11/27 01:15:22.432| RegexData.cc(311) aclParseRegexList: aclParseRegexList: buffering RE '+i'
2014/11/27 01:15:22.432| RegexData.cc(311) aclParseRegexList: aclParseRegexList: buffering RE '^https?://[^/]+/squid-internal-mgr/'
2014/11/27 01:15:22.432| RegexData.cc(194) compileOptimisedREs: compileOptimisedREs: -i
2014/11/27 01:15:22.432| RegexData.cc(218) compileOptimisedREs: compileOptimisedREs: adding RE '^cache_object://'
2014/11/27 01:15:22.432| RegexData.cc(208) compileOptimisedREs: compileOptimisedREs: +i
2014/11/27 01:15:22.432| RegexData.cc(153) compileRE: compileRE: compiled '(^cache_object://)' with flags 11
2014/11/27 01:15:22.432| RegexData.cc(218) compileOptimisedREs: compileOptimisedREs: adding RE '^https?://[^/]+/squid-internal-mgr/'
2014/11/27 01:15:22.432| RegexData.cc(153) compileRE: compileRE: compiled '(^https?://[^/]+/squid-internal-mgr/)' with flags 9
2014/11/27 01:15:22.432| RegexData.cc(261) compileOptimisedREs: compileOptimisedREs: 2 REs are optimised into one RE.
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type src
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.432| Acl.cc(97) FindByName: ACL::FindByName 'localhost'
2014/11/27 01:15:22.432| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.432| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'localhost'
2014/11/27 01:15:22.432| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'src'
2014/11/27 01:15:22.432| Ip.cc(233) FactoryParse: aclIpParseIpData: 127.0.0.1/32
2014/11/27 01:15:22.432| Ip.cc(341) FactoryParse: aclIpParseIpData: '127.0.0.1/32' matched: SCAN3-v4: %[0123456789.]/%[0123456789.]
2014/11/27 01:15:22.432| Ip.cc(478) FactoryParse: Parsed: 127.0.0.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff](/128)
2014/11/27 01:15:22.432| Ip.cc(233) FactoryParse: aclIpParseIpData: ::1
2014/11/27 01:15:22.432| Ip.cc(378) FactoryParse: aclIpParseIpData: Lookup Host/IP ::1
2014/11/27 01:15:22.432| Ip.cc(417) FactoryParse: aclIpParseIpData: Located host/IP: '[::1]'
2014/11/27 01:15:22.432| Ip.cc(424) FactoryParse: ::1 --> [::1]
2014/11/27 01:15:22.432| Ip.cc(410) FactoryParse: aclIpParseIpData: Duplicate host/IP: '[::1]' dropped.
2014/11/27 01:15:22.432| Ip.cc(410) FactoryParse: aclIpParseIpData: Duplicate host/IP: '[::1]' dropped.
2014/11/27 01:15:22.432| Ip.cc(107) aclIpAddrNetworkCompare: aclIpAddrNetworkCompare: compare: 127.0.0.1/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff] (127.0.0.1)  vs [::1]-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
2014/11/27 01:15:22.432| Ip.cc(107) aclIpAddrNetworkCompare: aclIpAddrNetworkCompare: compare: [::1]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff] ([::1])  vs 127.0.0.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
2014/11/27 01:15:22.432| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type dst
2014/11/27 01:15:22.432| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.433| Acl.cc(97) FindByName: ACL::FindByName 'to_localhost'
2014/11/27 01:15:22.433| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.433| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'to_localhost'
2014/11/27 01:15:22.433| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'dst'
2014/11/27 01:15:22.433| Ip.cc(233) FactoryParse: aclIpParseIpData: 127.0.0.0/8
2014/11/27 01:15:22.433| Ip.cc(341) FactoryParse: aclIpParseIpData: '127.0.0.0/8' matched: SCAN3-v4: %[0123456789.]/%[0123456789.]
2014/11/27 01:15:22.433| Ip.cc(478) FactoryParse: Parsed: 127.0.0.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ff00:0](/104)
2014/11/27 01:15:22.433| Ip.cc(233) FactoryParse: aclIpParseIpData: 0.0.0.0/32
2014/11/27 01:15:22.433| Ip.cc(341) FactoryParse: aclIpParseIpData: '0.0.0.0/32' matched: SCAN3-v4: %[0123456789.]/%[0123456789.]
2014/11/27 01:15:22.433| Ip.cc(478) FactoryParse: Parsed: 0.0.0.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff](/128)
2014/11/27 01:15:22.433| Ip.cc(107) aclIpAddrNetworkCompare: aclIpAddrNetworkCompare: compare: 127.0.0.0/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff] (127.0.0.0)  vs 0.0.0.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
2014/11/27 01:15:22.433| Ip.cc(107) aclIpAddrNetworkCompare: aclIpAddrNetworkCompare: compare: 0.0.0.0/[ffff:ffff:ffff:ffff:ffff:ffff:ff00:0] (0.0.0.0)  vs 127.0.0.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ff00:0]
2014/11/27 01:15:22.433| Ip.cc(233) FactoryParse: aclIpParseIpData: ::1
2014/11/27 01:15:22.433| Ip.cc(378) FactoryParse: aclIpParseIpData: Lookup Host/IP ::1
2014/11/27 01:15:22.433| Ip.cc(417) FactoryParse: aclIpParseIpData: Located host/IP: '[::1]'
2014/11/27 01:15:22.433| Ip.cc(424) FactoryParse: ::1 --> [::1]
2014/11/27 01:15:22.433| Ip.cc(410) FactoryParse: aclIpParseIpData: Duplicate host/IP: '[::1]' dropped.
2014/11/27 01:15:22.433| Ip.cc(410) FactoryParse: aclIpParseIpData: Duplicate host/IP: '[::1]' dropped.
2014/11/27 01:15:22.433| Ip.cc(107) aclIpAddrNetworkCompare: aclIpAddrNetworkCompare: compare: 0.0.0.0/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff] (0.0.0.0)  vs [::1]-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
2014/11/27 01:15:22.433| Ip.cc(107) aclIpAddrNetworkCompare: aclIpAddrNetworkCompare: compare: [::1]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff] ([::1])  vs 0.0.0.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
2014/11/27 01:15:22.433| Processing Configuration File: /opt/squid/etc/squid.conf (depth 0)
2014/11/27 01:15:22.433| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.433| SBuf.cc(175) rawSpace: not growing
2014/11/27 01:15:22.433| cache_cf.cc(518) parseOneConfigFile: Processing: visible_hostname local.local
2014/11/27 01:15:22.433| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.433| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.433| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.433| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob37 reserveSize=6
2014/11/27 01:15:22.433| MemBlob.cc(102) memAlloc: blob37 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob32 capacity=16388 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: always_direct allow all
2014/11/27 01:15:22.434| InnerNode.cc(57) lineParse: looking for ACL all
2014/11/27 01:15:22.434| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/11/27 01:15:22.434| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c3b258
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob38 reserveSize=6
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob38 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob37 capacity=40 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: dns_nameservers 8.8.8.8
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob39 reserveSize=6
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob39 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob38 capacity=40 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: acl step2 at_step SslBump2
2014/11/27 01:15:22.434| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type at_step
2014/11/27 01:15:22.434| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.434| Acl.cc(97) FindByName: ACL::FindByName 'step2'
2014/11/27 01:15:22.434| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.434| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'step2'
2014/11/27 01:15:22.434| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'at_step'
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob40 reserveSize=6
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob40 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob39 capacity=40 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: ssl_bump stare step2 all
2014/11/27 01:15:22.434| InnerNode.cc(57) lineParse: looking for ACL step2
2014/11/27 01:15:22.434| Acl.cc(97) FindByName: ACL::FindByName 'step2'
2014/11/27 01:15:22.434| InnerNode.cc(57) lineParse: looking for ACL all
2014/11/27 01:15:22.434| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/11/27 01:15:22.434| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c3bac8
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob41 reserveSize=6
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob41 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob40 capacity=40 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: acl sslBumpDeniedDstDomain dstdomain ukr.net www.ukr.net
2014/11/27 01:15:22.434| Acl.cc(396) Registered: ACL::Prototype::Registered: invoked for type dstdomain
2014/11/27 01:15:22.434| Acl.cc(400) Registered: ACL::Prototype::Registered:    yes
2014/11/27 01:15:22.434| Acl.cc(97) FindByName: ACL::FindByName 'sslBumpDeniedDstDomain'
2014/11/27 01:15:22.434| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/11/27 01:15:22.434| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL 'sslBumpDeniedDstDomain'
2014/11/27 01:15:22.434| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning an object for type 'dstdomain'
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob42 reserveSize=6
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob42 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob41 capacity=40 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: ssl_bump splice sslBumpDeniedDstDomain
2014/11/27 01:15:22.434| InnerNode.cc(57) lineParse: looking for ACL sslBumpDeniedDstDomain
2014/11/27 01:15:22.434| Acl.cc(97) FindByName: ACL::FindByName 'sslBumpDeniedDstDomain'
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob43 reserveSize=6
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob43 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob42 capacity=40 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: ssl_bump bump all
2014/11/27 01:15:22.434| InnerNode.cc(57) lineParse: looking for ACL all
2014/11/27 01:15:22.434| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob44 reserveSize=6
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob44 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob43 capacity=40 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/opt/squid/var/ssl_cert/cert.pem
2014/11/27 01:15:22.434| SBuf.cc(79) SBuf: SBuf38 created
2014/11/27 01:15:22.434| SBuf.cc(152) assign: SBuf38 from c-string, n=4294967295)
2014/11/27 01:15:22.434| SBuf.cc(215) append: from c-string to id SBuf38
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 4 for SBuf38
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:4
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 4
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob45 reserveSize=4
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob45 memAlloc: requested=4, received=40
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(3513) parsePortSpecification: http_port: found Listen on Port: 3128
2014/11/27 01:15:22.434| cache_cf.cc(3529) parsePortSpecification: http_port: found Listen on wildcard address: *:3128
2014/11/27 01:15:22.434| SBuf.cc(124) ~SBuf: SBuf38 destructed
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob45 capacity=40 size=4
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob46 reserveSize=6
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob46 memAlloc: requested=6, received=40
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob44 capacity=40 size=6
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(518) parseOneConfigFile: Processing: http_port 3131 transparent
2014/11/27 01:15:22.434| SBuf.cc(79) SBuf: SBuf39 created
2014/11/27 01:15:22.434| SBuf.cc(152) assign: SBuf39 from c-string, n=4294967295)
2014/11/27 01:15:22.434| SBuf.cc(215) append: from c-string to id SBuf39
2014/11/27 01:15:22.434| SBuf.cc(168) rawSpace: reserving 4 for SBuf39
2014/11/27 01:15:22.434| SBuf.cc(910) cow: new size:4
2014/11/27 01:15:22.434| SBuf.cc(880) reAlloc: new size: 4
2014/11/27 01:15:22.434| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob47 reserveSize=4
2014/11/27 01:15:22.434| MemBlob.cc(102) memAlloc: blob47 memAlloc: requested=4, received=40
2014/11/27 01:15:22.434| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.434| cache_cf.cc(3513) parsePortSpecification: http_port: found Listen on Port: 3131
2014/11/27 01:15:22.434| cache_cf.cc(3529) parsePortSpecification: http_port: found Listen on wildcard address: *:3131
2014/11/27 01:15:22.434| Starting Authentication on port 0.0.0.0:3131
2014/11/27 01:15:22.434| Disabling Authentication on port 0.0.0.0:3131 (interception enabled)
2014/11/27 01:15:22.434| SBuf.cc(124) ~SBuf: SBuf39 destructed
2014/11/27 01:15:22.434| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob47 capacity=40 size=4
2014/11/27 01:15:22.435| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.435| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.435| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.435| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob48 reserveSize=6
2014/11/27 01:15:22.435| MemBlob.cc(102) memAlloc: blob48 memAlloc: requested=6, received=40
2014/11/27 01:15:22.435| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob46 capacity=40 size=6
2014/11/27 01:15:22.435| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.435| cache_cf.cc(518) parseOneConfigFile: Processing: https_port 3132 transparent ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/opt/squid/var/ssl_cert/cert.pem
2014/11/27 01:15:22.435| SBuf.cc(79) SBuf: SBuf40 created
2014/11/27 01:15:22.435| SBuf.cc(152) assign: SBuf40 from c-string, n=4294967295)
2014/11/27 01:15:22.435| SBuf.cc(215) append: from c-string to id SBuf40
2014/11/27 01:15:22.435| SBuf.cc(168) rawSpace: reserving 5 for SBuf40
2014/11/27 01:15:22.435| SBuf.cc(910) cow: new size:5
2014/11/27 01:15:22.435| SBuf.cc(880) reAlloc: new size: 5
2014/11/27 01:15:22.435| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob49 reserveSize=5
2014/11/27 01:15:22.435| MemBlob.cc(102) memAlloc: blob49 memAlloc: requested=5, received=40
2014/11/27 01:15:22.435| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.435| cache_cf.cc(3513) parsePortSpecification: https_port: found Listen on Port: 3132
2014/11/27 01:15:22.435| cache_cf.cc(3529) parsePortSpecification: https_port: found Listen on wildcard address: *:3132
2014/11/27 01:15:22.435| Starting Authentication on port 0.0.0.0:3132
2014/11/27 01:15:22.435| Disabling Authentication on port 0.0.0.0:3132 (interception enabled)
2014/11/27 01:15:22.435| SBuf.cc(124) ~SBuf: SBuf40 destructed
2014/11/27 01:15:22.435| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob49 capacity=40 size=5
2014/11/27 01:15:22.435| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.435| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.435| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.435| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob50 reserveSize=6
2014/11/27 01:15:22.435| MemBlob.cc(102) memAlloc: blob50 memAlloc: requested=6, received=40
2014/11/27 01:15:22.435| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob48 capacity=40 size=6
2014/11/27 01:15:22.435| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.435| cache_cf.cc(518) parseOneConfigFile: Processing: http_access allow all
2014/11/27 01:15:22.435| InnerNode.cc(57) lineParse: looking for ACL all
2014/11/27 01:15:22.435| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/11/27 01:15:22.435| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c3c8a8
2014/11/27 01:15:22.435| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.435| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.435| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.435| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob51 reserveSize=6
2014/11/27 01:15:22.435| MemBlob.cc(102) memAlloc: blob51 memAlloc: requested=6, received=40
2014/11/27 01:15:22.435| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob50 capacity=40 size=6
2014/11/27 01:15:22.435| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.435| cache_cf.cc(518) parseOneConfigFile: Processing: sslcrtd_program /opt/squid/libexec/ssl_crtd -s /opt/squid/var/ssl_db -M 4MB
2014/11/27 01:15:22.435| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.435| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.435| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.435| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob52 reserveSize=6
2014/11/27 01:15:22.435| MemBlob.cc(102) memAlloc: blob52 memAlloc: requested=6, received=40
2014/11/27 01:15:22.435| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob51 capacity=40 size=6
2014/11/27 01:15:22.435| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.435| cache_cf.cc(518) parseOneConfigFile: Processing: sslcrtd_children 15
2014/11/27 01:15:22.435| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.435| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.435| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.435| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob53 reserveSize=6
2014/11/27 01:15:22.435| MemBlob.cc(102) memAlloc: blob53 memAlloc: requested=6, received=40
2014/11/27 01:15:22.435| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c60450 id=blob52 capacity=40 size=6
2014/11/27 01:15:22.435| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.435| cache_cf.cc(518) parseOneConfigFile: Processing: logformat logaccess  [%{%d/%b/%Y  %H:%M:%S}tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
2014/11/27 01:15:22.435| Config.cc(34) parseFormats: Log Format for 'logaccess' is '[%{%d/%b/%Y  %H:%M:%S}tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Format.cc(64) parse: got definition '[%{%d/%b/%Y  %H:%M:%S}tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.435| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.435| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.435| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.435| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>eui' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>qos' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<qos' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>nfmark' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<nfmark' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'err_code' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'err_detail' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'note' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'credentials' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>la' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'la' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>lp' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'lp' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<la' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'oa' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<lp' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'ts' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'tu' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'tl' with 'tl] %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(228) scanForToken: Found token 'tl'
2014/11/27 01:15:22.435| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.435| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.435| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.435| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.435| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>eui' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>qos' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<qos' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>nfmark' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<nfmark' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'err_code' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'err_detail' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'note' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'credentials' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>la' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'la' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>lp' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'lp' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<la' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'oa' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<lp' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'ts' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'tu' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'tl' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'tg' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'tS' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'tr' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<pt' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<tt' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'dt' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>ha' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>ha' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'un' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'ul' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'ui' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'ue' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'Hs' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>Hs' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<Hs' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '<bs' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'Ss' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'Sh' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens 'mt' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>rm' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.435| Token.cc(224) scanForToken: compare tokens '>ru' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>rs' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>rd' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>rP' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>rp' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>rv' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'rm' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ru' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'rp' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'rv' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'rG' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<rm' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<ru' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<rs' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<rd' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<rP' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<rp' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<rv' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>st' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>sh' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<st' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<sH' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<sS' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<sh' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'st' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'et' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ea' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'sn' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(389) parse: scan for possible 1C token
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>a' with '>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(228) scanForToken: Found token '>a'
2014/11/27 01:15:22.436| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.436| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>eui' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>qos' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<qos' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>nfmark' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<nfmark' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'err_code' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'err_detail' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'note' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'credentials' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>la' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'la' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>lp' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'lp' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<la' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'oa' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<lp' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ts' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tu' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tl' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tg' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tS' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tr' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<pt' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<tt' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'dt' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>ha' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>ha' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'un' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ul' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ui' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ue' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'Hs' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>Hs' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<Hs' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<bs' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'Ss' with 'Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(228) scanForToken: Found token 'Ss'
2014/11/27 01:15:22.436| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.436| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>eui' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>qos' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<qos' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>nfmark' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<nfmark' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'err_code' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'err_detail' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'note' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'credentials' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>la' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'la' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>lp' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'lp' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<la' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'oa' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<lp' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ts' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tu' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tl' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tg' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tS' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tr' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<pt' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<tt' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'dt' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>ha' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>ha' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'un' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ul' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ui' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ue' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'Hs' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>Hs' with '>Hs %<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(228) scanForToken: Found token '>Hs'
2014/11/27 01:15:22.436| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.436| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.436| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>eui' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>qos' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<qos' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>nfmark' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<nfmark' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'err_code' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'err_detail' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'note' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'credentials' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>la' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'la' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '>lp' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'lp' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<la' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'oa' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens '<lp' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'ts' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tu' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tl' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tg' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tS' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.436| Token.cc(224) scanForToken: compare tokens 'tr' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<pt' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<tt' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'dt' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ha' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ha' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'un' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ul' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ui' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ue' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Hs' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>Hs' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<Hs' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<bs' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Ss' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Sh' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'mt' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rm' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ru' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rs' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rd' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rP' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rp' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rv' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'rm' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ru' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'rp' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'rv' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'rG' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<rm' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<ru' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<rs' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<rd' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<rP' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<rp' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<rv' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>st' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>sh' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<st' with '<st %rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(228) scanForToken: Found token '<st'
2014/11/27 01:15:22.437| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.437| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.437| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.437| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.437| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>eui' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>qos' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<qos' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>nfmark' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<nfmark' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'err_code' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'err_detail' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'note' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'credentials' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>la' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'la' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>lp' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'lp' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<la' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'oa' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<lp' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ts' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tu' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tl' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tg' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tS' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tr' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<pt' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<tt' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'dt' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ha' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ha' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'un' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ul' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ui' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ue' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Hs' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>Hs' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<Hs' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<bs' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Ss' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Sh' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'mt' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rm' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ru' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rs' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rd' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rP' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rp' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rv' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'rm' with 'rm %ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(228) scanForToken: Found token 'rm'
2014/11/27 01:15:22.437| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.437| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.437| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.437| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.437| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>eui' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>qos' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<qos' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>nfmark' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<nfmark' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'err_code' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'err_detail' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'note' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'credentials' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>la' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'la' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>lp' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'lp' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<la' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'oa' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<lp' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ts' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tu' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tl' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tg' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tS' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'tr' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<pt' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<tt' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'dt' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ha' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ha' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'un' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ul' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ui' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'ue' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Hs' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>Hs' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<Hs' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '<bs' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Ss' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'Sh' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens 'mt' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rm' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>ru' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rs' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rd' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rP' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.437| Token.cc(224) scanForToken: compare tokens '>rp' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>rv' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'rm' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ru' with 'ru %un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(228) scanForToken: Found token 'ru'
2014/11/27 01:15:22.438| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.438| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>eui' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>qos' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<qos' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>nfmark' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<nfmark' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'err_code' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'err_detail' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'note' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'credentials' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>la' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'la' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>lp' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'lp' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<la' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'oa' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<lp' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ts' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tu' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tl' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tg' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tS' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tr' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<pt' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<tt' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'dt' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>ha' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>ha' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'un' with 'un %Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(228) scanForToken: Found token 'un'
2014/11/27 01:15:22.438| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.438| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>eui' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>qos' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<qos' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>nfmark' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<nfmark' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'err_code' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'err_detail' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'note' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'credentials' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>la' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'la' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>lp' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'lp' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<la' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'oa' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<lp' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ts' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tu' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tl' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tg' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tS' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tr' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<pt' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<tt' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'dt' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>ha' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>ha' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'un' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ul' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ui' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ue' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'Hs' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>Hs' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<Hs' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<bs' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'Ss' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'Sh' with 'Sh/%<A %mt'
2014/11/27 01:15:22.438| Token.cc(228) scanForToken: Found token 'Sh'
2014/11/27 01:15:22.438| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.438| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.438| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>eui' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>qos' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<qos' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>nfmark' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<nfmark' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'err_code' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'err_detail' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'note' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'credentials' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>la' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'la' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>lp' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'lp' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<la' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'oa' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<lp' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ts' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tu' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tl' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tg' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tS' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'tr' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<pt' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<tt' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'dt' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>ha' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>ha' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'un' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ul' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ui' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ue' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'Hs' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>Hs' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<Hs' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<bs' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'Ss' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'Sh' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'mt' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>rm' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>ru' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>rs' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>rd' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>rP' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>rp' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '>rv' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'rm' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'ru' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'rp' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'rv' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens 'rG' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<rm' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<ru' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<rs' with '<A %mt'
2014/11/27 01:15:22.438| Token.cc(224) scanForToken: compare tokens '<rd' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<rP' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<rp' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<rv' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>st' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>sh' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<st' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<sH' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<sS' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<sh' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'st' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'et' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'ea' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'sn' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(389) parse: scan for possible 1C token
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>a' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>p' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>A' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<a' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<p' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<A' with '<A %mt'
2014/11/27 01:15:22.439| Token.cc(228) scanForToken: Found token '<A'
2014/11/27 01:15:22.439| Token.cc(354) parse: check for token in 3 namespaces.
2014/11/27 01:15:22.439| Token.cc(356) parse: check for possible adapt:: token
2014/11/27 01:15:22.439| Token.cc(356) parse: check for possible icap:: token
2014/11/27 01:15:22.439| Token.cc(356) parse: check for possible ssl:: token
2014/11/27 01:15:22.439| Token.cc(380) parse: scan for possible Misc token
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>eui' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>qos' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<qos' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>nfmark' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<nfmark' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'err_code' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'err_detail' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'note' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'credentials' with 'mt'
2014/11/27 01:15:22.439| Token.cc(384) parse: scan for possible 2C token
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>la' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'la' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>lp' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'lp' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<la' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'oa' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<lp' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'ts' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'tu' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'tl' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'tg' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'tS' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'tr' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<pt' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<tt' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'dt' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>ha' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>ha' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'un' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'ul' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'ui' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'ue' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'Hs' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '>Hs' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<Hs' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens '<bs' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'Ss' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'Sh' with 'mt'
2014/11/27 01:15:22.439| Token.cc(224) scanForToken: compare tokens 'mt' with 'mt'
2014/11/27 01:15:22.439| Token.cc(228) scanForToken: Found token 'mt'
2014/11/27 01:15:22.439| SBuf.cc(168) rawSpace: reserving 1 for SBuf33
2014/11/27 01:15:22.439| SBuf.cc(910) cow: new size:6
2014/11/27 01:15:22.439| SBuf.cc(880) reAlloc: new size: 6
2014/11/27 01:15:22.439| MemBlob.cc(57) MemBlob: constructed, this=0x2c60450 id=blob54 reserveSize=6
2014/11/27 01:15:22.439| MemBlob.cc(102) memAlloc: blob54 memAlloc: requested=6, received=40
2014/11/27 01:15:22.439| MemBlob.cc(83) ~MemBlob: destructed, this=0x2c3a0d0 id=blob53 capacity=40 size=6
2014/11/27 01:15:22.439| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.439| cache_cf.cc(518) parseOneConfigFile: Processing: access_log daemon:/opt/squid/var/logs/access.log logaccess
2014/11/27 01:15:22.439| cache_cf.cc(4145) setLogformat: possible daemon:/opt/squid/var/logs/access.log logformat: logaccess
2014/11/27 01:15:22.439| cache_cf.cc(4158) setLogformat: Comparing against 'logaccess'
2014/11/27 01:15:22.439| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c3d468
2014/11/27 01:15:22.439| InnerNode.cc(57) lineParse: looking for ACL all
2014/11/27 01:15:22.439| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/11/27 01:15:22.439| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c3d008
2014/11/27 01:15:22.439| wccp2.cc(511) wccp2_add_service_list: wccp2_add_service_list: added service id 0
2014/11/27 01:15:22.439| InnerNode.cc(57) lineParse: looking for ACL all
2014/11/27 01:15:22.439| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/11/27 01:15:22.439| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c61008
2014/11/27 01:15:22.439| InnerNode.cc(57) lineParse: looking for ACL ssl::certUntrusted
2014/11/27 01:15:22.439| Acl.cc(97) FindByName: ACL::FindByName 'ssl::certUntrusted'
2014/11/27 01:15:22.439| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c3e0b8
2014/11/27 01:15:22.439| InnerNode.cc(57) lineParse: looking for ACL ssl::certSelfSigned
2014/11/27 01:15:22.439| Acl.cc(97) FindByName: ACL::FindByName 'ssl::certSelfSigned'
2014/11/27 01:15:22.439| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c3de68
2014/11/27 01:15:22.439| InnerNode.cc(57) lineParse: looking for ACL all
2014/11/27 01:15:22.439| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/11/27 01:15:22.439| cbdata.cc(299) cbdataInternalAlloc: Allocating 0x2c3e528
2014/11/27 01:15:22.439| tools.cc(531) uniqueHostname:  Config: '
2014/11/27 01:15:22.439| tools.cc(531) uniqueHostname:  Config: '
2014/11/27 01:15:22.439| SBuf.cc(79) SBuf: SBuf41 created
2014/11/27 01:15:22.439| SBuf.cc(152) assign: SBuf41 from c-string, n=4294967295)
2014/11/27 01:15:22.439| SBuf.cc(215) append: from c-string to id SBuf41
2014/11/27 01:15:22.439| SBuf.cc(168) rawSpace: reserving 1 for SBuf41
2014/11/27 01:15:22.439| SBuf.cc(910) cow: new size:1
2014/11/27 01:15:22.439| SBuf.cc(880) reAlloc: new size: 1
2014/11/27 01:15:22.439| MemBlob.cc(57) MemBlob: constructed, this=0x2c3a0d0 id=blob55 reserveSize=1
2014/11/27 01:15:22.439| MemBlob.cc(102) memAlloc: blob55 memAlloc: requested=1, received=40
2014/11/27 01:15:22.439| SBuf.cc(889) reAlloc: new store capacity: 40
2014/11/27 01:15:22.439| Initializing https proxy context
2014/11/27 01:15:22.441| support.cc(1062) method: Using SSLv2/SSLv3.
2014/11/27 01:15:22.441| support.cc(1194) sslCreateClientContext: Setting RSA key generation callback.
2014/11/27 01:15:22.441| support.cc(1201) sslCreateClientContext: Setting certificate verification callback.
2014/11/27 01:15:22.441| support.cc(1205) sslCreateClientContext: Setting CA certificate locations.
2014/11/27 01:15:22.441| Initializing http_port 0.0.0.0:3128 SSL context
2014/11/27 01:15:22.441| Using certificate in /opt/squid/var/ssl_cert/cert.pem
2014/11/27 01:15:22.448| support.cc(1708) readSslX509CertificatesChain: Certificate is self-signed, will not be chained
2014/11/27 01:15:22.449| support.cc(1527) contextMethod: Using SSLv2/SSLv3.
2014/11/27 01:15:22.449| support.cc(849) configureSslContext: Setting RSA key generation callback.
2014/11/27 01:15:22.449| support.cc(852) configureSslContext: Setting CA certificate locations.
2014/11/27 01:15:22.456| support.cc(895) configureSslContext: Not requiring any client certificates
2014/11/27 01:15:22.456| Initializing https_port 0.0.0.0:3132 SSL context
2014/11/27 01:15:22.456| Using certificate in /opt/squid/var/ssl_cert/cert.pem
2014/11/27 01:15:22.456| support.cc(1708) readSslX509CertificatesChain: Certificate is self-signed, will not be chained
2014/11/27 01:15:22.457| support.cc(1527) contextMethod: Using SSLv2/SSLv3.
2014/11/27 01:15:22.457| support.cc(849) configureSslContext: Setting RSA key generation callback.
2014/11/27 01:15:22.457| support.cc(852) configureSslContext: Setting CA certificate locations.
2014/11/27 01:15:22.464| support.cc(895) configureSslContext: Not requiring any client certificates
2014/11/27 01:15:22.464| tools.cc(543) leave_suid: leave_suid: PID 16232 called
2014/11/27 01:15:22.464| tools.cc(565) leave_suid: leave_suid: PID 16232 giving up root, becoming 'nobody'
2014/11/27 01:15:22.464| debug.cc(403) parseOptions: command-line -X overrides: ALL,1
2014/11/27 01:15:22.464| tools.cc(610) enter_suid: enter_suid: PID 16232 taking root privileges
2014/11/27 01:15:22.464| cache_manager.cc(80) registerProfile: registering legacy config
2014/11/27 01:15:22.464| cache_manager.cc(65) registerProfile: registered profile: config
2014/11/27 01:15:22.465| mem.cc(473) Report: Memory pools are 'on'; limit: 5.000 MB
2014/11/27 01:15:22.465| main.cc(1424) SquidMain: Doing post-config initialization

2014/11/27 01:15:22.465| tools.cc(543) leave_suid: leave_suid: PID 16232 called
2014/11/27 01:15:22.465| tools.cc(565) leave_suid: leave_suid: PID 16232 giving up root, becoming 'nobody'
2014/11/27 01:15:22.465| main.cc(1426) SquidMain: running RegisteredRunner::finalizeConfig
2014/11/27 01:15:22.465| main.cc(1427) SquidMain: running RegisteredRunner::claimMemoryNeeds
2014/11/27 01:15:22.465| main.cc(1428) SquidMain: running RegisteredRunner::useConfig
2014/11/27 01:15:22.465| mem/Segment.cc(111) create: created /squid-ssl_session_cache.shm segment: 2103672
2014/11/27 01:15:22.465| mem/Segment.cc(111) create: created /squid-cf__metadata.shm segment: 8
2014/11/27 01:15:22.465| mem/Segment.cc(111) create: created /squid-cf__queues.shm segment: 8216
2014/11/27 01:15:22.466| mem/Segment.cc(111) create: created /squid-cf__readers.shm segment: 44
2014/11/27 01:15:22.466| cache_manager.cc(80) registerProfile: registering legacy client_list
2014/11/27 01:15:22.466| cache_manager.cc(65) registerProfile: registered profile: client_list
2014/11/27 01:15:22.466| tools.cc(610) enter_suid: enter_suid: PID 16232 taking root privileges
2014/11/27 01:15:22.466| cache_manager.cc(80) registerProfile: registering legacy comm_epoll_incoming
2014/11/27 01:15:22.466| cache_manager.cc(65) registerProfile: registered profile: comm_epoll_incoming
2014/11/27 01:15:22.466| fd.cc(198) fd_open: fd_open() FD 0 stdin
2014/11/27 01:15:22.466| fd.cc(198) fd_open: fd_open() FD 1 stdout
2014/11/27 01:15:22.466| fd.cc(198) fd_open: fd_open() FD 2 stderr
2014/11/27 01:15:22.466| Current Directory is /opt/squid/etc
2014/11/27 01:15:22.466| tools.cc(543) leave_suid: leave_suid: PID 16232 called
2014/11/27 01:15:22.466| tools.cc(565) leave_suid: leave_suid: PID 16232 giving up root, becoming 'nobody'
2014/11/27 01:15:22.466| fd.cc(198) fd_open: fd_open() FD 3 /opt/squid/var/logs/cache.log
2014/11/27 01:15:22.466| Starting Squid Cache version 3.5.0.2 for x86_64-unknown-linux-gnu...
2014/11/27 01:15:22.466| Service Name: squid
2014/11/27 01:15:22.466| Process ID 16232
2014/11/27 01:15:22.466| Process Roles: master worker
2014/11/27 01:15:22.466| With 4096 file descriptors available
2014/11/27 01:15:22.466| Initializing IP Cache...
2014/11/27 01:15:22.466| cache_manager.cc(80) registerProfile: registering legacy ipcache
2014/11/27 01:15:22.466| cache_manager.cc(65) registerProfile: registered profile: ipcache
2014/11/27 01:15:22.466| cache_manager.cc(80) registerProfile: registering legacy fqdncache
2014/11/27 01:15:22.466| cache_manager.cc(65) registerProfile: registered profile: fqdncache
2014/11/27 01:15:22.466| fqdncache.cc(720) fqdncache_init: Initializing FQDN Cache...
2014/11/27 01:15:22.466| ipcache.cc(174) ipcacheRelease: ipcacheRelease: Releasing entry for 'test-local'
2014/11/27 01:15:22.466| dns_internal.cc(1538) dnsInit: idnsInit: attempt open DNS socket to: 0.0.0.0
2014/11/27 01:15:22.466| comm.cc(342) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0
2014/11/27 01:15:22.466| comm.cc(383) comm_openex: comm_openex: Opened socket local=0.0.0.0 remote=[::] FD 10 flags=1 : family=2, type=2, protocol=17
2014/11/27 01:15:22.466| fd.cc(198) fd_open: fd_open() FD 10 DNS Socket IPv4
2014/11/27 01:15:22.466| DNS Socket created at 0.0.0.0, FD 10
2014/11/27 01:15:22.467| Adding nameserver 8.8.8.8 from squid.conf
2014/11/27 01:15:22.467| dns_internal.cc(321) idnsAddNameserver: idnsAddNameserver: Added nameserver #0 (8.8.8.8:53)
2014/11/27 01:15:22.467| cache_manager.cc(80) registerProfile: registering legacy idns
2014/11/27 01:15:22.467| cache_manager.cc(65) registerProfile: registered profile: idns
2014/11/27 01:15:22.467| helperOpenServers: Starting 5/15 'ssl_crtd' processes
2014/11/27 01:15:22.467| fd.cc(198) fd_open: fd_open() FD 11 IPC UNIX STREAM Parent
2014/11/27 01:15:22.467| fd.cc(198) fd_open: fd_open() FD 12 IPC UNIX STREAM Parent
2014/11/27 01:15:22.467| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 11
2014/11/27 01:15:22.467| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 11
2014/11/27 01:15:22.467| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 12
2014/11/27 01:15:22.467| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 12
2014/11/27 01:15:22.467| comm.cc(860) _comm_close: comm_close: start closing FD 12
2014/11/27 01:15:22.467| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 12
2014/11/27 01:15:22.467| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2f237c0 [call1]
2014/11/27 01:15:22.467| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 12) [call1]
2014/11/27 01:15:22.467| tools.cc(543) leave_suid: leave_suid: PID 16233 called
2014/11/27 01:15:22.467| tools.cc(636) no_suid: no_suid: PID 16233 giving up root priveleges forever
2014/11/27 01:15:22.467| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 11
2014/11/27 01:15:22.467| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x2f70ca0 [call2]
2014/11/27 01:15:22.467| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x2f71c40 [call3]
2014/11/27 01:15:22.467| fd.cc(198) fd_open: fd_open() FD 13 IPC UNIX STREAM Parent
2014/11/27 01:15:22.467| fd.cc(198) fd_open: fd_open() FD 14 IPC UNIX STREAM Parent
2014/11/27 01:15:22.467| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 13
2014/11/27 01:15:22.467| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 13
2014/11/27 01:15:22.467| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 14
2014/11/27 01:15:22.467| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 14
2014/11/27 01:15:22.468| comm.cc(860) _comm_close: comm_close: start closing FD 14
2014/11/27 01:15:22.468| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 14
2014/11/27 01:15:22.468| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2f734d0 [call4]
2014/11/27 01:15:22.468| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 14) [call4]
2014/11/27 01:15:22.468| tools.cc(543) leave_suid: leave_suid: PID 16234 called
2014/11/27 01:15:22.468| tools.cc(636) no_suid: no_suid: PID 16234 giving up root priveleges forever
2014/11/27 01:15:22.468| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 13
2014/11/27 01:15:22.468| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x2f73460 [call5]
2014/11/27 01:15:22.468| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x2f74930 [call6]
2014/11/27 01:15:22.468| fd.cc(198) fd_open: fd_open() FD 15 IPC UNIX STREAM Parent
2014/11/27 01:15:22.468| fd.cc(198) fd_open: fd_open() FD 16 IPC UNIX STREAM Parent
2014/11/27 01:15:22.468| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 15
2014/11/27 01:15:22.468| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 15
2014/11/27 01:15:22.468| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 16
2014/11/27 01:15:22.468| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 16
2014/11/27 01:15:22.468| comm.cc(860) _comm_close: comm_close: start closing FD 16
2014/11/27 01:15:22.468| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 16
2014/11/27 01:15:22.468| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2f74cd0 [call7]
2014/11/27 01:15:22.468| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 16) [call7]
2014/11/27 01:15:22.468| tools.cc(543) leave_suid: leave_suid: PID 16235 called
2014/11/27 01:15:22.468| tools.cc(636) no_suid: no_suid: PID 16235 giving up root priveleges forever
2014/11/27 01:15:22.468| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 15
2014/11/27 01:15:22.468| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x2f74ac0 [call8]
2014/11/27 01:15:22.468| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x2f74b30 [call9]
2014/11/27 01:15:22.468| fd.cc(198) fd_open: fd_open() FD 17 IPC UNIX STREAM Parent
2014/11/27 01:15:22.469| fd.cc(198) fd_open: fd_open() FD 18 IPC UNIX STREAM Parent
2014/11/27 01:15:22.469| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 17
2014/11/27 01:15:22.469| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 17
2014/11/27 01:15:22.469| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 18
2014/11/27 01:15:22.469| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 18
2014/11/27 01:15:22.469| comm.cc(860) _comm_close: comm_close: start closing FD 18
2014/11/27 01:15:22.469| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 18
2014/11/27 01:15:22.469| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2f76130 [call10]
2014/11/27 01:15:22.469| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 18) [call10]
2014/11/27 01:15:22.469| tools.cc(543) leave_suid: leave_suid: PID 16236 called
2014/11/27 01:15:22.469| tools.cc(636) no_suid: no_suid: PID 16236 giving up root priveleges forever
2014/11/27 01:15:22.469| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 17
2014/11/27 01:15:22.469| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x2f74bc0 [call11]
2014/11/27 01:15:22.469| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x2f76000 [call12]
2014/11/27 01:15:22.469| fd.cc(198) fd_open: fd_open() FD 19 IPC UNIX STREAM Parent
2014/11/27 01:15:22.469| fd.cc(198) fd_open: fd_open() FD 20 IPC UNIX STREAM Parent
2014/11/27 01:15:22.469| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 19
2014/11/27 01:15:22.469| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 19
2014/11/27 01:15:22.469| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 20
2014/11/27 01:15:22.469| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 20
2014/11/27 01:15:22.469| comm.cc(860) _comm_close: comm_close: start closing FD 20
2014/11/27 01:15:22.469| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 20
2014/11/27 01:15:22.469| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2f74c30 [call13]
2014/11/27 01:15:22.470| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 20) [call13]
2014/11/27 01:15:22.471| tools.cc(543) leave_suid: leave_suid: PID 16237 called
2014/11/27 01:15:22.471| tools.cc(636) no_suid: no_suid: PID 16237 giving up root priveleges forever
2014/11/27 01:15:22.471| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 19
2014/11/27 01:15:22.471| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x2f76090 [call14]
2014/11/27 01:15:22.471| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x2f78610 [call15]
2014/11/27 01:15:22.471| mem/Segment.cc(130) open: opened /squid-ssl_session_cache.shm segment: 2103672
2014/11/27 01:15:22.471| cache_manager.cc(80) registerProfile: registering legacy redirector
2014/11/27 01:15:22.471| cache_manager.cc(65) registerProfile: registered profile: redirector
2014/11/27 01:15:22.471| cache_manager.cc(80) registerProfile: registering legacy store_id
2014/11/27 01:15:22.471| cache_manager.cc(65) registerProfile: registered profile: store_id
2014/11/27 01:15:22.471| Format.cc(64) parse: got definition '%>a/%>A %un %>rm myip=%la myport=%lp'
2014/11/27 01:15:22.473| Format.cc(64) parse: got definition '%>a/%>A %un %>rm myip=%la myport=%lp'
2014/11/27 01:15:22.475| cache_manager.cc(80) registerProfile: registering legacy external_acl
2014/11/27 01:15:22.475| cache_manager.cc(65) registerProfile: registered profile: external_acl
2014/11/27 01:15:22.477| cache_manager.cc(80) registerProfile: registering legacy http_headers
2014/11/27 01:15:22.477| cache_manager.cc(65) registerProfile: registered profile: http_headers
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_ACCESS_DENIED
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_ACCESS_DENIED
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_CACHE_ACCESS_DENIED
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_CACHE_ACCESS_DENIED
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_CACHE_MGR_ACCESS_DENIED
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_CACHE_MGR_ACCESS_DENIED
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FORWARDING_DENIED
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FORWARDING_DENIED
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_NO_RELAY
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_NO_RELAY
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_CANNOT_FORWARD
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_CANNOT_FORWARD
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_READ_TIMEOUT
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_READ_TIMEOUT
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_LIFETIME_EXP
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_LIFETIME_EXP
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_READ_ERROR
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_READ_ERROR
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_WRITE_ERROR
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_WRITE_ERROR
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_CONNECT_FAIL
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_CONNECT_FAIL
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_SECURE_CONNECT_FAIL
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_SECURE_CONNECT_FAIL
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_SOCKET_FAILURE
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_SOCKET_FAILURE
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_DNS_FAIL
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_DNS_FAIL
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_URN_RESOLVE
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_URN_RESOLVE
2014/11/27 01:15:22.477| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_ONLY_IF_CACHED_MISS
2014/11/27 01:15:22.477| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_ONLY_IF_CACHED_MISS
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_TOO_BIG
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_TOO_BIG
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_INVALID_RESP
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_INVALID_RESP
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_UNSUP_HTTPVERSION
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_UNSUP_HTTPVERSION
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_INVALID_REQ
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_INVALID_REQ
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_UNSUP_REQ
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_UNSUP_REQ
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_INVALID_URL
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_INVALID_URL
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_ZERO_SIZE_OBJECT
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_ZERO_SIZE_OBJECT
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_PRECONDITION_FAILED
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_PRECONDITION_FAILED
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_CONFLICT_HOST
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_CONFLICT_HOST
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FTP_DISABLED
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FTP_DISABLED
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FTP_UNAVAILABLE
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FTP_UNAVAILABLE
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FTP_FAILURE
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FTP_FAILURE
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FTP_PUT_ERROR
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FTP_PUT_ERROR
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FTP_NOT_FOUND
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FTP_NOT_FOUND
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FTP_FORBIDDEN
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FTP_FORBIDDEN
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FTP_PUT_CREATED
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FTP_PUT_CREATED
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_FTP_PUT_MODIFIED
2014/11/27 01:15:22.478| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_FTP_PUT_MODIFIED
2014/11/27 01:15:22.478| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_ESI
2014/11/27 01:15:22.479| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_ESI
2014/11/27 01:15:22.479| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_ICAP_FAILURE
2014/11/27 01:15:22.479| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_ICAP_FAILURE
2014/11/27 01:15:22.479| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_GATEWAY_FAILURE
2014/11/27 01:15:22.479| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_GATEWAY_FAILURE
2014/11/27 01:15:22.479| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_DIR_LISTING
2014/11/27 01:15:22.479| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_DIR_LISTING
2014/11/27 01:15:22.479| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/ERR_SHUTTING_DOWN
2014/11/27 01:15:22.479| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/ERR_SHUTTING_DOWN
2014/11/27 01:15:22.479| disk.cc(68) file_open: file_open: error opening file /opt/squid/share/errors/templates/MGR_INDEX: (2) No such file or directory
2014/11/27 01:15:22.479| errorpage.cc(286) loadDefault: WARNING: failed to find or read error text file MGR_INDEX
2014/11/27 01:15:22.479| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/etc/errorpage.css
2014/11/27 01:15:22.479| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/etc/errorpage.css
2014/11/27 01:15:22.479| fd.cc(198) fd_open: fd_open() FD 22 /opt/squid/share/errors/templates/error-details.txt
2014/11/27 01:15:22.488| fd.cc(93) fd_close: fd_close FD 22 /opt/squid/share/errors/templates/error-details.txt
2014/11/27 01:15:22.488| Logfile: opening log daemon:/opt/squid/var/logs/access.log
2014/11/27 01:15:22.488| Logfile Daemon: opening log /opt/squid/var/logs/access.log
2014/11/27 01:15:22.488| fd.cc(198) fd_open: fd_open() FD 22 IPC UNIX STREAM Parent
2014/11/27 01:15:22.488| fd.cc(198) fd_open: fd_open() FD 23 IPC UNIX STREAM Parent
2014/11/27 01:15:22.488| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 22
2014/11/27 01:15:22.488| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 22
2014/11/27 01:15:22.488| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 23
2014/11/27 01:15:22.488| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 23
2014/11/27 01:15:22.488| comm.cc(860) _comm_close: comm_close: start closing FD 23
2014/11/27 01:15:22.488| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 23
2014/11/27 01:15:22.488| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2f9d8d0 [call16]
2014/11/27 01:15:22.488| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 23) [call16]
2014/11/27 01:15:22.488| tools.cc(636) no_suid: no_suid: PID 16238 giving up root priveleges forever
2014/11/27 01:15:22.488| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 22
2014/11/27 01:15:22.488| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/opt/squid/var/logs/access.log: appending 7 bytes
2014/11/27 01:15:22.488| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 0 of 32768 bytes before append
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: info
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: service_times
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy filedescriptors
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: filedescriptors
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy objects
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: objects
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy vm_objects
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: vm_objects
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: io
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: counters
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy peer_select
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: peer_select
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy digest_stats
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: digest_stats
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: 5min
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: 60min
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy utilization
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: utilization
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy histograms
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: histograms
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy active_requests
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: active_requests
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy username_cache
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: username_cache
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy openfd_objects
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: openfd_objects
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy store_digest
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: store_digest
2014/11/27 01:15:22.493| store_digest.cc(117) storeDigestInit: Local cache digest is 'off'
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy store_log_tags
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: store_log_tags
2014/11/27 01:15:22.493| Store logging disabled
2014/11/27 01:15:22.493| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2014/11/27 01:15:22.493| Target number of buckets: 1008
2014/11/27 01:15:22.493| Using 8192 Store buckets
2014/11/27 01:15:22.493| Max Mem  size: 262144 KB
2014/11/27 01:15:22.493| Max Swap size: 0 KB
2014/11/27 01:15:22.493| Using Least Load store dir selection
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy storedir
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: storedir
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: store_io
2014/11/27 01:15:22.493| cache_manager.cc(80) registerProfile: registering legacy store_check_cachable_stats
2014/11/27 01:15:22.493| cache_manager.cc(65) registerProfile: registered profile: store_check_cachable_stats
2014/11/27 01:15:22.493| Current Directory is /opt/squid/etc
2014/11/27 01:15:22.493| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.494| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.495| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.496| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.497| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.498| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.499| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.500| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.500| store_dir.cc(744) find: none of 0 cache_dirs have 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.500| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/image.png
2014/11/27 01:15:22.500| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/image.png'
2014/11/27 01:15:22.500| MemObject.cc(97) MemObject: new MemObject 0x33696c0
2014/11/27 01:15:22.501| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33693c0*1
2014/11/27 01:15:22.501| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33693c0*1 key '91525E905C3E2496DD9A7C19EE2E78F5'
2014/11/27 01:15:22.501| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33693c0*1 key '9C0CC615AF155C43AECEA90B7D4E5B7F'
2014/11/27 01:15:22.501| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/image.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/image.png'
2014/11/27 01:15:22.501| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.501| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/image.png
2014/11/27 01:15:22.502| store_client.cc(731) invokeHandlers: InvokeHandlers: 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.503| store_client.cc(731) invokeHandlers: InvokeHandlers: 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.503| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/image.png
2014/11/27 01:15:22.503| store.cc(1028) complete: storeComplete: '9C0CC615AF155C43AECEA90B7D4E5B7F'
2014/11/27 01:15:22.503| store.cc(1319) validLength: storeEntryValidLength: Checking '9C0CC615AF155C43AECEA90B7D4E5B7F'
2014/11/27 01:15:22.503| store_client.cc(731) invokeHandlers: InvokeHandlers: 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.503| store.cc(523) unlock: MimeIcon::created unlocking key 9C0CC615AF155C43AECEA90B7D4E5B7F e:=sSV/0x33693c0*1
2014/11/27 01:15:22.503| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.503| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33693c0*0 into policy
2014/11/27 01:15:22.503| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/image.png
2014/11/27 01:15:22.503| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.503| store_dir.cc(744) find: none of 0 cache_dirs have D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.503| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_text.png
2014/11/27 01:15:22.503| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_text.png'
2014/11/27 01:15:22.503| MemObject.cc(97) MemObject: new MemObject 0x336bc50
2014/11/27 01:15:22.503| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x336be20*1
2014/11/27 01:15:22.503| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_text.png
2014/11/27 01:15:22.503| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x336be20*1 key 'D7EB66F40301CFBF04917718E7DA6C54'
2014/11/27 01:15:22.503| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x336be20*1 key 'D81E5CFD84EA27DB6A94514C03E68DB8'
2014/11/27 01:15:22.503| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_text.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_text.png'
2014/11/27 01:15:22.503| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.503| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_text.png
2014/11/27 01:15:22.505| store_client.cc(731) invokeHandlers: InvokeHandlers: D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.505| store_client.cc(731) invokeHandlers: InvokeHandlers: D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.505| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_text.png
2014/11/27 01:15:22.505| store.cc(1028) complete: storeComplete: 'D81E5CFD84EA27DB6A94514C03E68DB8'
2014/11/27 01:15:22.505| store.cc(1319) validLength: storeEntryValidLength: Checking 'D81E5CFD84EA27DB6A94514C03E68DB8'
2014/11/27 01:15:22.505| store_client.cc(731) invokeHandlers: InvokeHandlers: D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.505| store.cc(523) unlock: MimeIcon::created unlocking key D81E5CFD84EA27DB6A94514C03E68DB8 e:=sSV/0x336be20*1
2014/11/27 01:15:22.505| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.505| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x336be20*0 into policy
2014/11/27 01:15:22.505| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_text.png
2014/11/27 01:15:22.505| store_dir.cc(1073) get: storeGet: looking up 39A0FAE869902A69EA6754B557D317C1
2014/11/27 01:15:22.505| store_dir.cc(744) find: none of 0 cache_dirs have 39A0FAE869902A69EA6754B557D317C1
2014/11/27 01:15:22.505| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/arrow_up.png
2014/11/27 01:15:22.505| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/arrow_up.png'
2014/11/27 01:15:22.505| MemObject.cc(97) MemObject: new MemObject 0x3370960
2014/11/27 01:15:22.505| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33708f0*1
2014/11/27 01:15:22.505| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/arrow_up.png
2014/11/27 01:15:22.505| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33708f0*1 key '291BA1D2C98B9A9F1D4E2D744BBE56F2'
2014/11/27 01:15:22.505| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33708f0*1 key '39A0FAE869902A69EA6754B557D317C1'
2014/11/27 01:15:22.505| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/arrow_up.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/arrow_up.png'
2014/11/27 01:15:22.505| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.506| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/arrow_up.png
2014/11/27 01:15:22.507| store_client.cc(731) invokeHandlers: InvokeHandlers: 39A0FAE869902A69EA6754B557D317C1
2014/11/27 01:15:22.507| store_client.cc(731) invokeHandlers: InvokeHandlers: 39A0FAE869902A69EA6754B557D317C1
2014/11/27 01:15:22.507| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/arrow_up.png
2014/11/27 01:15:22.507| store.cc(1028) complete: storeComplete: '39A0FAE869902A69EA6754B557D317C1'
2014/11/27 01:15:22.507| store.cc(1319) validLength: storeEntryValidLength: Checking '39A0FAE869902A69EA6754B557D317C1'
2014/11/27 01:15:22.507| store_client.cc(731) invokeHandlers: InvokeHandlers: 39A0FAE869902A69EA6754B557D317C1
2014/11/27 01:15:22.507| store.cc(523) unlock: MimeIcon::created unlocking key 39A0FAE869902A69EA6754B557D317C1 e:=sSV/0x33708f0*1
2014/11/27 01:15:22.507| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.507| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33708f0*0 into policy
2014/11/27 01:15:22.507| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/arrow_up.png
2014/11/27 01:15:22.507| store_dir.cc(1073) get: storeGet: looking up 1D22C36D3450F39B1CE86481F97BEB2F
2014/11/27 01:15:22.507| store_dir.cc(744) find: none of 0 cache_dirs have 1D22C36D3450F39B1CE86481F97BEB2F
2014/11/27 01:15:22.507| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/folder.png
2014/11/27 01:15:22.507| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/folder.png'
2014/11/27 01:15:22.507| MemObject.cc(97) MemObject: new MemObject 0x3372210
2014/11/27 01:15:22.508| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33721a0*1
2014/11/27 01:15:22.508| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/folder.png
2014/11/27 01:15:22.508| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33721a0*1 key '93AAA821A2A8858032D5E43C31192991'
2014/11/27 01:15:22.508| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33721a0*1 key '1D22C36D3450F39B1CE86481F97BEB2F'
2014/11/27 01:15:22.508| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/folder.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/folder.png'
2014/11/27 01:15:22.508| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.508| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/folder.png
2014/11/27 01:15:22.509| store_client.cc(731) invokeHandlers: InvokeHandlers: 1D22C36D3450F39B1CE86481F97BEB2F
2014/11/27 01:15:22.509| store_client.cc(731) invokeHandlers: InvokeHandlers: 1D22C36D3450F39B1CE86481F97BEB2F
2014/11/27 01:15:22.509| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/folder.png
2014/11/27 01:15:22.509| store.cc(1028) complete: storeComplete: '1D22C36D3450F39B1CE86481F97BEB2F'
2014/11/27 01:15:22.509| store.cc(1319) validLength: storeEntryValidLength: Checking '1D22C36D3450F39B1CE86481F97BEB2F'
2014/11/27 01:15:22.510| store_client.cc(731) invokeHandlers: InvokeHandlers: 1D22C36D3450F39B1CE86481F97BEB2F
2014/11/27 01:15:22.510| store.cc(523) unlock: MimeIcon::created unlocking key 1D22C36D3450F39B1CE86481F97BEB2F e:=sSV/0x33721a0*1
2014/11/27 01:15:22.510| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.510| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33721a0*0 into policy
2014/11/27 01:15:22.510| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/folder.png
2014/11/27 01:15:22.510| store_dir.cc(1073) get: storeGet: looking up 74879194D826534455B3394D45AA61D1
2014/11/27 01:15:22.510| store_dir.cc(744) find: none of 0 cache_dirs have 74879194D826534455B3394D45AA61D1
2014/11/27 01:15:22.510| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/link.png
2014/11/27 01:15:22.510| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/link.png'
2014/11/27 01:15:22.510| MemObject.cc(97) MemObject: new MemObject 0x3373bc0
2014/11/27 01:15:22.510| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3373b50*1
2014/11/27 01:15:22.510| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/link.png
2014/11/27 01:15:22.510| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3373b50*1 key 'AD712B448C3F2139FF2846DE9273F4A8'
2014/11/27 01:15:22.510| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3373b50*1 key '74879194D826534455B3394D45AA61D1'
2014/11/27 01:15:22.510| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/link.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/link.png'
2014/11/27 01:15:22.510| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.510| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/link.png
2014/11/27 01:15:22.512| store_client.cc(731) invokeHandlers: InvokeHandlers: 74879194D826534455B3394D45AA61D1
2014/11/27 01:15:22.512| store_client.cc(731) invokeHandlers: InvokeHandlers: 74879194D826534455B3394D45AA61D1
2014/11/27 01:15:22.512| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/link.png
2014/11/27 01:15:22.512| store.cc(1028) complete: storeComplete: '74879194D826534455B3394D45AA61D1'
2014/11/27 01:15:22.512| store.cc(1319) validLength: storeEntryValidLength: Checking '74879194D826534455B3394D45AA61D1'
2014/11/27 01:15:22.512| store_client.cc(731) invokeHandlers: InvokeHandlers: 74879194D826534455B3394D45AA61D1
2014/11/27 01:15:22.512| store.cc(523) unlock: MimeIcon::created unlocking key 74879194D826534455B3394D45AA61D1 e:=sSV/0x3373b50*1
2014/11/27 01:15:22.512| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.512| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3373b50*0 into policy
2014/11/27 01:15:22.512| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/link.png
2014/11/27 01:15:22.512| store_dir.cc(1073) get: storeGet: looking up E6CADECED8B3D8625BF9E6D02023E5C2
2014/11/27 01:15:22.512| store_dir.cc(744) find: none of 0 cache_dirs have E6CADECED8B3D8625BF9E6D02023E5C2
2014/11/27 01:15:22.512| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/SN.png
2014/11/27 01:15:22.512| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/SN.png'
2014/11/27 01:15:22.512| MemObject.cc(97) MemObject: new MemObject 0x3375570
2014/11/27 01:15:22.512| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3375500*1
2014/11/27 01:15:22.512| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/SN.png
2014/11/27 01:15:22.512| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3375500*1 key 'E88579692EEACC810BA50500C669CA07'
2014/11/27 01:15:22.512| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3375500*1 key 'E6CADECED8B3D8625BF9E6D02023E5C2'
2014/11/27 01:15:22.512| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/SN.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/SN.png'
2014/11/27 01:15:22.512| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.512| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/SN.png
2014/11/27 01:15:22.514| store_client.cc(731) invokeHandlers: InvokeHandlers: E6CADECED8B3D8625BF9E6D02023E5C2
2014/11/27 01:15:22.514| store_client.cc(731) invokeHandlers: InvokeHandlers: E6CADECED8B3D8625BF9E6D02023E5C2
2014/11/27 01:15:22.514| store_client.cc(731) invokeHandlers: InvokeHandlers: E6CADECED8B3D8625BF9E6D02023E5C2
2014/11/27 01:15:22.514| store_client.cc(731) invokeHandlers: InvokeHandlers: E6CADECED8B3D8625BF9E6D02023E5C2
2014/11/27 01:15:22.514| store_client.cc(731) invokeHandlers: InvokeHandlers: E6CADECED8B3D8625BF9E6D02023E5C2
2014/11/27 01:15:22.514| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/SN.png
2014/11/27 01:15:22.514| store.cc(1028) complete: storeComplete: 'E6CADECED8B3D8625BF9E6D02023E5C2'
2014/11/27 01:15:22.514| store.cc(1319) validLength: storeEntryValidLength: Checking 'E6CADECED8B3D8625BF9E6D02023E5C2'
2014/11/27 01:15:22.514| store_client.cc(731) invokeHandlers: InvokeHandlers: E6CADECED8B3D8625BF9E6D02023E5C2
2014/11/27 01:15:22.514| store.cc(523) unlock: MimeIcon::created unlocking key E6CADECED8B3D8625BF9E6D02023E5C2 e:=sSV/0x3375500*1
2014/11/27 01:15:22.514| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.514| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3375500*0 into policy
2014/11/27 01:15:22.515| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/SN.png
2014/11/27 01:15:22.515| store_dir.cc(1073) get: storeGet: looking up BC86BD9D96A6F884B62FE6BBF50BB53A
2014/11/27 01:15:22.515| store_dir.cc(744) find: none of 0 cache_dirs have BC86BD9D96A6F884B62FE6BBF50BB53A
2014/11/27 01:15:22.515| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/folder_table.png
2014/11/27 01:15:22.515| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/folder_table.png'
2014/11/27 01:15:22.515| MemObject.cc(97) MemObject: new MemObject 0x3379fb0
2014/11/27 01:15:22.515| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3379f40*1
2014/11/27 01:15:22.515| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/folder_table.png
2014/11/27 01:15:22.515| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3379f40*1 key 'FBA89B2A08A72092929C0967076E0570'
2014/11/27 01:15:22.515| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3379f40*1 key 'BC86BD9D96A6F884B62FE6BBF50BB53A'
2014/11/27 01:15:22.515| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/folder_table.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/folder_table.png'
2014/11/27 01:15:22.515| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.515| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/folder_table.png
2014/11/27 01:15:22.517| store_client.cc(731) invokeHandlers: InvokeHandlers: BC86BD9D96A6F884B62FE6BBF50BB53A
2014/11/27 01:15:22.517| store_client.cc(731) invokeHandlers: InvokeHandlers: BC86BD9D96A6F884B62FE6BBF50BB53A
2014/11/27 01:15:22.517| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/folder_table.png
2014/11/27 01:15:22.517| store.cc(1028) complete: storeComplete: 'BC86BD9D96A6F884B62FE6BBF50BB53A'
2014/11/27 01:15:22.517| store.cc(1319) validLength: storeEntryValidLength: Checking 'BC86BD9D96A6F884B62FE6BBF50BB53A'
2014/11/27 01:15:22.517| store_client.cc(731) invokeHandlers: InvokeHandlers: BC86BD9D96A6F884B62FE6BBF50BB53A
2014/11/27 01:15:22.517| store.cc(523) unlock: MimeIcon::created unlocking key BC86BD9D96A6F884B62FE6BBF50BB53A e:=sSV/0x3379f40*1
2014/11/27 01:15:22.517| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.517| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3379f40*0 into policy
2014/11/27 01:15:22.517| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/folder_table.png
2014/11/27 01:15:22.517| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.517| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.517| store_dir.cc(1073) get: storeGet: looking up BC86BD9D96A6F884B62FE6BBF50BB53A
2014/11/27 01:15:22.517| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3379f40*0
2014/11/27 01:15:22.517| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.517| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.517| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.517| store_dir.cc(744) find: none of 0 cache_dirs have 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.517| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/music.png
2014/11/27 01:15:22.517| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/music.png'
2014/11/27 01:15:22.517| MemObject.cc(97) MemObject: new MemObject 0x337b9c0
2014/11/27 01:15:22.517| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x337b950*1
2014/11/27 01:15:22.517| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/music.png
2014/11/27 01:15:22.517| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x337b950*1 key '64E6A6A1A27DB88606A4013353538897'
2014/11/27 01:15:22.517| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x337b950*1 key '51B121AB09873161B8AA3027B291757A'
2014/11/27 01:15:22.517| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/music.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/music.png'
2014/11/27 01:15:22.517| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.518| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/music.png
2014/11/27 01:15:22.519| store_client.cc(731) invokeHandlers: InvokeHandlers: 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.519| store_client.cc(731) invokeHandlers: InvokeHandlers: 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.519| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/music.png
2014/11/27 01:15:22.519| store.cc(1028) complete: storeComplete: '51B121AB09873161B8AA3027B291757A'
2014/11/27 01:15:22.519| store.cc(1319) validLength: storeEntryValidLength: Checking '51B121AB09873161B8AA3027B291757A'
2014/11/27 01:15:22.519| store_client.cc(731) invokeHandlers: InvokeHandlers: 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.519| store.cc(523) unlock: MimeIcon::created unlocking key 51B121AB09873161B8AA3027B291757A e:=sSV/0x337b950*1
2014/11/27 01:15:22.519| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.519| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x337b950*0 into policy
2014/11/27 01:15:22.519| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/music.png
2014/11/27 01:15:22.519| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.519| store_dir.cc(744) find: none of 0 cache_dirs have F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.519| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/film.png
2014/11/27 01:15:22.519| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/film.png'
2014/11/27 01:15:22.519| MemObject.cc(97) MemObject: new MemObject 0x337d370
2014/11/27 01:15:22.519| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x337d300*1
2014/11/27 01:15:22.519| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/film.png
2014/11/27 01:15:22.519| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x337d300*1 key 'AACBA8125C6F85042A17094627AD283F'
2014/11/27 01:15:22.520| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x337d300*1 key 'F16CA0A0B0F9E5727914AD2B62B4FB74'
2014/11/27 01:15:22.520| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/film.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/film.png'
2014/11/27 01:15:22.520| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.520| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/film.png
2014/11/27 01:15:22.521| store_client.cc(731) invokeHandlers: InvokeHandlers: F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.521| store_client.cc(731) invokeHandlers: InvokeHandlers: F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.521| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/film.png
2014/11/27 01:15:22.521| store.cc(1028) complete: storeComplete: 'F16CA0A0B0F9E5727914AD2B62B4FB74'
2014/11/27 01:15:22.521| store.cc(1319) validLength: storeEntryValidLength: Checking 'F16CA0A0B0F9E5727914AD2B62B4FB74'
2014/11/27 01:15:22.521| store_client.cc(731) invokeHandlers: InvokeHandlers: F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.522| store.cc(523) unlock: MimeIcon::created unlocking key F16CA0A0B0F9E5727914AD2B62B4FB74 e:=sSV/0x337d300*1
2014/11/27 01:15:22.522| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.522| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x337d300*0 into policy
2014/11/27 01:15:22.522| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/film.png
2014/11/27 01:15:22.522| store_dir.cc(1073) get: storeGet: looking up C99950CF83DA8D1E5C8BD4C9D9D32794
2014/11/27 01:15:22.522| store_dir.cc(744) find: none of 0 cache_dirs have C99950CF83DA8D1E5C8BD4C9D9D32794
2014/11/27 01:15:22.522| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/computer_link.png
2014/11/27 01:15:22.522| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/computer_link.png'
2014/11/27 01:15:22.522| MemObject.cc(97) MemObject: new MemObject 0x337ed20
2014/11/27 01:15:22.522| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x337ecb0*1
2014/11/27 01:15:22.522| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/computer_link.png
2014/11/27 01:15:22.522| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x337ecb0*1 key 'A46A89E2434BE701DB4F508DAC11929D'
2014/11/27 01:15:22.522| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x337ecb0*1 key 'C99950CF83DA8D1E5C8BD4C9D9D32794'
2014/11/27 01:15:22.522| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/computer_link.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/computer_link.png'
2014/11/27 01:15:22.522| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.522| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/computer_link.png
2014/11/27 01:15:22.524| store_client.cc(731) invokeHandlers: InvokeHandlers: C99950CF83DA8D1E5C8BD4C9D9D32794
2014/11/27 01:15:22.524| store_client.cc(731) invokeHandlers: InvokeHandlers: C99950CF83DA8D1E5C8BD4C9D9D32794
2014/11/27 01:15:22.524| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/computer_link.png
2014/11/27 01:15:22.524| store.cc(1028) complete: storeComplete: 'C99950CF83DA8D1E5C8BD4C9D9D32794'
2014/11/27 01:15:22.524| store.cc(1319) validLength: storeEntryValidLength: Checking 'C99950CF83DA8D1E5C8BD4C9D9D32794'
2014/11/27 01:15:22.524| store_client.cc(731) invokeHandlers: InvokeHandlers: C99950CF83DA8D1E5C8BD4C9D9D32794
2014/11/27 01:15:22.524| store.cc(523) unlock: MimeIcon::created unlocking key C99950CF83DA8D1E5C8BD4C9D9D32794 e:=sSV/0x337ecb0*1
2014/11/27 01:15:22.524| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.524| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x337ecb0*0 into policy
2014/11/27 01:15:22.524| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/computer_link.png
2014/11/27 01:15:22.524| store_dir.cc(1073) get: storeGet: looking up 288A7626FFE57C1B2DBA69C15FB9A411
2014/11/27 01:15:22.524| store_dir.cc(744) find: none of 0 cache_dirs have 288A7626FFE57C1B2DBA69C15FB9A411
2014/11/27 01:15:22.524| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/application.png
2014/11/27 01:15:22.524| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/application.png'
2014/11/27 01:15:22.524| MemObject.cc(97) MemObject: new MemObject 0x33806d0
2014/11/27 01:15:22.524| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3380660*1
2014/11/27 01:15:22.524| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/application.png
2014/11/27 01:15:22.524| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3380660*1 key 'D0DF014C8A0159858D00EE67DFB9C528'
2014/11/27 01:15:22.524| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3380660*1 key '288A7626FFE57C1B2DBA69C15FB9A411'
2014/11/27 01:15:22.524| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/application.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/application.png'
2014/11/27 01:15:22.524| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.524| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/application.png
2014/11/27 01:15:22.526| store_client.cc(731) invokeHandlers: InvokeHandlers: 288A7626FFE57C1B2DBA69C15FB9A411
2014/11/27 01:15:22.526| store_client.cc(731) invokeHandlers: InvokeHandlers: 288A7626FFE57C1B2DBA69C15FB9A411
2014/11/27 01:15:22.526| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/application.png
2014/11/27 01:15:22.526| store.cc(1028) complete: storeComplete: '288A7626FFE57C1B2DBA69C15FB9A411'
2014/11/27 01:15:22.526| store.cc(1319) validLength: storeEntryValidLength: Checking '288A7626FFE57C1B2DBA69C15FB9A411'
2014/11/27 01:15:22.526| store_client.cc(731) invokeHandlers: InvokeHandlers: 288A7626FFE57C1B2DBA69C15FB9A411
2014/11/27 01:15:22.526| store.cc(523) unlock: MimeIcon::created unlocking key 288A7626FFE57C1B2DBA69C15FB9A411 e:=sSV/0x3380660*1
2014/11/27 01:15:22.526| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.526| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3380660*0 into policy
2014/11/27 01:15:22.526| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/application.png
2014/11/27 01:15:22.526| store_dir.cc(1073) get: storeGet: looking up 4226A0233E563AAFAECC8B1C7F522696
2014/11/27 01:15:22.526| store_dir.cc(744) find: none of 0 cache_dirs have 4226A0233E563AAFAECC8B1C7F522696
2014/11/27 01:15:22.526| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/bullet_red.png
2014/11/27 01:15:22.526| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/bullet_red.png'
2014/11/27 01:15:22.526| MemObject.cc(97) MemObject: new MemObject 0x33822a0
2014/11/27 01:15:22.526| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33820e0*1
2014/11/27 01:15:22.526| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/bullet_red.png
2014/11/27 01:15:22.526| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33820e0*1 key '7F28AB9458D0607C552095C76913EEAC'
2014/11/27 01:15:22.526| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33820e0*1 key '4226A0233E563AAFAECC8B1C7F522696'
2014/11/27 01:15:22.526| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/bullet_red.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/bullet_red.png'
2014/11/27 01:15:22.526| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.527| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/bullet_red.png
2014/11/27 01:15:22.528| store_client.cc(731) invokeHandlers: InvokeHandlers: 4226A0233E563AAFAECC8B1C7F522696
2014/11/27 01:15:22.528| store_client.cc(731) invokeHandlers: InvokeHandlers: 4226A0233E563AAFAECC8B1C7F522696
2014/11/27 01:15:22.528| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/bullet_red.png
2014/11/27 01:15:22.528| store.cc(1028) complete: storeComplete: '4226A0233E563AAFAECC8B1C7F522696'
2014/11/27 01:15:22.528| store.cc(1319) validLength: storeEntryValidLength: Checking '4226A0233E563AAFAECC8B1C7F522696'
2014/11/27 01:15:22.528| store_client.cc(731) invokeHandlers: InvokeHandlers: 4226A0233E563AAFAECC8B1C7F522696
2014/11/27 01:15:22.528| store.cc(523) unlock: MimeIcon::created unlocking key 4226A0233E563AAFAECC8B1C7F522696 e:=sSV/0x33820e0*1
2014/11/27 01:15:22.528| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.528| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33820e0*0 into policy
2014/11/27 01:15:22.528| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/bullet_red.png
2014/11/27 01:15:22.528| store_dir.cc(1073) get: storeGet: looking up 014EE52BD4C4571E5F15AB6231A62DBB
2014/11/27 01:15:22.529| store_dir.cc(744) find: none of 0 cache_dirs have 014EE52BD4C4571E5F15AB6231A62DBB
2014/11/27 01:15:22.529| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white.png
2014/11/27 01:15:22.529| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white.png'
2014/11/27 01:15:22.529| MemObject.cc(97) MemObject: new MemObject 0x3384420
2014/11/27 01:15:22.529| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33847c0*1
2014/11/27 01:15:22.529| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white.png
2014/11/27 01:15:22.529| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33847c0*1 key 'F4AC3EB020FDD56794FDCFD074C26130'
2014/11/27 01:15:22.529| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33847c0*1 key '014EE52BD4C4571E5F15AB6231A62DBB'
2014/11/27 01:15:22.529| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white.png'
2014/11/27 01:15:22.529| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.529| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white.png
2014/11/27 01:15:22.530| store_client.cc(731) invokeHandlers: InvokeHandlers: 014EE52BD4C4571E5F15AB6231A62DBB
2014/11/27 01:15:22.531| store_client.cc(731) invokeHandlers: InvokeHandlers: 014EE52BD4C4571E5F15AB6231A62DBB
2014/11/27 01:15:22.531| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white.png
2014/11/27 01:15:22.531| store.cc(1028) complete: storeComplete: '014EE52BD4C4571E5F15AB6231A62DBB'
2014/11/27 01:15:22.531| store.cc(1319) validLength: storeEntryValidLength: Checking '014EE52BD4C4571E5F15AB6231A62DBB'
2014/11/27 01:15:22.531| store_client.cc(731) invokeHandlers: InvokeHandlers: 014EE52BD4C4571E5F15AB6231A62DBB
2014/11/27 01:15:22.531| store.cc(523) unlock: MimeIcon::created unlocking key 014EE52BD4C4571E5F15AB6231A62DBB e:=sSV/0x33847c0*1
2014/11/27 01:15:22.531| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.531| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33847c0*0 into policy
2014/11/27 01:15:22.531| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white.png
2014/11/27 01:15:22.531| store_dir.cc(1073) get: storeGet: looking up 93FB840D0C379219DEC9E5D6C4618EB8
2014/11/27 01:15:22.531| store_dir.cc(744) find: none of 0 cache_dirs have 93FB840D0C379219DEC9E5D6C4618EB8
2014/11/27 01:15:22.531| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/package_go.png
2014/11/27 01:15:22.531| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/package_go.png'
2014/11/27 01:15:22.531| MemObject.cc(97) MemObject: new MemObject 0x3385d40
2014/11/27 01:15:22.531| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3386160*1
2014/11/27 01:15:22.531| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/package_go.png
2014/11/27 01:15:22.531| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3386160*1 key '9FC26D0669985FE4403775F03E4F31E7'
2014/11/27 01:15:22.531| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3386160*1 key '93FB840D0C379219DEC9E5D6C4618EB8'
2014/11/27 01:15:22.531| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/package_go.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/package_go.png'
2014/11/27 01:15:22.531| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.531| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/package_go.png
2014/11/27 01:15:22.533| store_client.cc(731) invokeHandlers: InvokeHandlers: 93FB840D0C379219DEC9E5D6C4618EB8
2014/11/27 01:15:22.533| store_client.cc(731) invokeHandlers: InvokeHandlers: 93FB840D0C379219DEC9E5D6C4618EB8
2014/11/27 01:15:22.533| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/package_go.png
2014/11/27 01:15:22.533| store.cc(1028) complete: storeComplete: '93FB840D0C379219DEC9E5D6C4618EB8'
2014/11/27 01:15:22.533| store.cc(1319) validLength: storeEntryValidLength: Checking '93FB840D0C379219DEC9E5D6C4618EB8'
2014/11/27 01:15:22.533| store_client.cc(731) invokeHandlers: InvokeHandlers: 93FB840D0C379219DEC9E5D6C4618EB8
2014/11/27 01:15:22.533| store.cc(523) unlock: MimeIcon::created unlocking key 93FB840D0C379219DEC9E5D6C4618EB8 e:=sSV/0x3386160*1
2014/11/27 01:15:22.533| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.533| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3386160*0 into policy
2014/11/27 01:15:22.533| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/package_go.png
2014/11/27 01:15:22.533| store_dir.cc(1073) get: storeGet: looking up 288A7626FFE57C1B2DBA69C15FB9A411
2014/11/27 01:15:22.533| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3380660*0
2014/11/27 01:15:22.533| store_dir.cc(1073) get: storeGet: looking up 288A7626FFE57C1B2DBA69C15FB9A411
2014/11/27 01:15:22.533| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3380660*0
2014/11/27 01:15:22.533| store_dir.cc(1073) get: storeGet: looking up 288A7626FFE57C1B2DBA69C15FB9A411
2014/11/27 01:15:22.533| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3380660*0
2014/11/27 01:15:22.533| store_dir.cc(1073) get: storeGet: looking up 36006D47FACB2755F26D2A9D577500AE
2014/11/27 01:15:22.533| store_dir.cc(744) find: none of 0 cache_dirs have 36006D47FACB2755F26D2A9D577500AE
2014/11/27 01:15:22.533| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_acrobat.png
2014/11/27 01:15:22.533| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_acrobat.png'
2014/11/27 01:15:22.533| MemObject.cc(97) MemObject: new MemObject 0x33876e0
2014/11/27 01:15:22.533| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3387b00*1
2014/11/27 01:15:22.533| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_acrobat.png
2014/11/27 01:15:22.533| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3387b00*1 key 'A117DAC28CCF06AA7527A1F8860F1809'
2014/11/27 01:15:22.533| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3387b00*1 key '36006D47FACB2755F26D2A9D577500AE'
2014/11/27 01:15:22.533| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_acrobat.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_acrobat.png'
2014/11/27 01:15:22.534| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.534| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_acrobat.png
2014/11/27 01:15:22.535| store_client.cc(731) invokeHandlers: InvokeHandlers: 36006D47FACB2755F26D2A9D577500AE
2014/11/27 01:15:22.535| store_client.cc(731) invokeHandlers: InvokeHandlers: 36006D47FACB2755F26D2A9D577500AE
2014/11/27 01:15:22.535| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_acrobat.png
2014/11/27 01:15:22.535| store.cc(1028) complete: storeComplete: '36006D47FACB2755F26D2A9D577500AE'
2014/11/27 01:15:22.535| store.cc(1319) validLength: storeEntryValidLength: Checking '36006D47FACB2755F26D2A9D577500AE'
2014/11/27 01:15:22.535| store_client.cc(731) invokeHandlers: InvokeHandlers: 36006D47FACB2755F26D2A9D577500AE
2014/11/27 01:15:22.535| store.cc(523) unlock: MimeIcon::created unlocking key 36006D47FACB2755F26D2A9D577500AE e:=sSV/0x3387b00*1
2014/11/27 01:15:22.535| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.535| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3387b00*0 into policy
2014/11/27 01:15:22.535| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_acrobat.png
2014/11/27 01:15:22.536| store_dir.cc(1073) get: storeGet: looking up 71CA7720BB68023561B1DC835F86221D
2014/11/27 01:15:22.536| store_dir.cc(744) find: none of 0 cache_dirs have 71CA7720BB68023561B1DC835F86221D
2014/11/27 01:15:22.536| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_green.png
2014/11/27 01:15:22.536| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_green.png'
2014/11/27 01:15:22.536| MemObject.cc(97) MemObject: new MemObject 0x3389090
2014/11/27 01:15:22.536| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3389490*1
2014/11/27 01:15:22.536| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_green.png
2014/11/27 01:15:22.536| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3389490*1 key '4D91C809DA2BEDEC192B1FA7F7C002A7'
2014/11/27 01:15:22.536| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3389490*1 key '71CA7720BB68023561B1DC835F86221D'
2014/11/27 01:15:22.536| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_green.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_green.png'
2014/11/27 01:15:22.536| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.536| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_green.png
2014/11/27 01:15:22.538| store_client.cc(731) invokeHandlers: InvokeHandlers: 71CA7720BB68023561B1DC835F86221D
2014/11/27 01:15:22.538| store_client.cc(731) invokeHandlers: InvokeHandlers: 71CA7720BB68023561B1DC835F86221D
2014/11/27 01:15:22.538| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_green.png
2014/11/27 01:15:22.538| store.cc(1028) complete: storeComplete: '71CA7720BB68023561B1DC835F86221D'
2014/11/27 01:15:22.538| store.cc(1319) validLength: storeEntryValidLength: Checking '71CA7720BB68023561B1DC835F86221D'
2014/11/27 01:15:22.538| store_client.cc(731) invokeHandlers: InvokeHandlers: 71CA7720BB68023561B1DC835F86221D
2014/11/27 01:15:22.538| store.cc(523) unlock: MimeIcon::created unlocking key 71CA7720BB68023561B1DC835F86221D e:=sSV/0x3389490*1
2014/11/27 01:15:22.538| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.538| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3389490*0 into policy
2014/11/27 01:15:22.538| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_green.png
2014/11/27 01:15:22.538| store_dir.cc(1073) get: storeGet: looking up 71CA7720BB68023561B1DC835F86221D
2014/11/27 01:15:22.538| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3389490*0
2014/11/27 01:15:22.538| store_dir.cc(1073) get: storeGet: looking up 71CA7720BB68023561B1DC835F86221D
2014/11/27 01:15:22.538| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3389490*0
2014/11/27 01:15:22.538| store_dir.cc(1073) get: storeGet: looking up 11E51DB30434453AD0C7A0185D2CD597
2014/11/27 01:15:22.538| store_dir.cc(744) find: none of 0 cache_dirs have 11E51DB30434453AD0C7A0185D2CD597
2014/11/27 01:15:22.538| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_picture.png
2014/11/27 01:15:22.538| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_picture.png'
2014/11/27 01:15:22.538| MemObject.cc(97) MemObject: new MemObject 0x338aa40
2014/11/27 01:15:22.538| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x338ae40*1
2014/11/27 01:15:22.538| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_picture.png
2014/11/27 01:15:22.538| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x338ae40*1 key '1E9CE778F66A498A040D1858D781E0B6'
2014/11/27 01:15:22.538| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x338ae40*1 key '11E51DB30434453AD0C7A0185D2CD597'
2014/11/27 01:15:22.538| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_picture.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_picture.png'
2014/11/27 01:15:22.538| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.538| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_picture.png
2014/11/27 01:15:22.540| store_client.cc(731) invokeHandlers: InvokeHandlers: 11E51DB30434453AD0C7A0185D2CD597
2014/11/27 01:15:22.540| store_client.cc(731) invokeHandlers: InvokeHandlers: 11E51DB30434453AD0C7A0185D2CD597
2014/11/27 01:15:22.540| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_picture.png
2014/11/27 01:15:22.540| store.cc(1028) complete: storeComplete: '11E51DB30434453AD0C7A0185D2CD597'
2014/11/27 01:15:22.540| store.cc(1319) validLength: storeEntryValidLength: Checking '11E51DB30434453AD0C7A0185D2CD597'
2014/11/27 01:15:22.540| store_client.cc(731) invokeHandlers: InvokeHandlers: 11E51DB30434453AD0C7A0185D2CD597
2014/11/27 01:15:22.540| store.cc(523) unlock: MimeIcon::created unlocking key 11E51DB30434453AD0C7A0185D2CD597 e:=sSV/0x338ae40*1
2014/11/27 01:15:22.540| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.540| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x338ae40*0 into policy
2014/11/27 01:15:22.540| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_picture.png
2014/11/27 01:15:22.540| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.540| store_dir.cc(744) find: none of 0 cache_dirs have 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.540| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/compress.png
2014/11/27 01:15:22.540| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/compress.png'
2014/11/27 01:15:22.540| MemObject.cc(97) MemObject: new MemObject 0x338c3e0
2014/11/27 01:15:22.540| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x338c7e0*1
2014/11/27 01:15:22.540| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/compress.png
2014/11/27 01:15:22.540| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x338c7e0*1 key 'DFD831AB88F098DA3F495C3098E90042'
2014/11/27 01:15:22.540| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x338c7e0*1 key '859639B2D98C5D1EECA638A885752553'
2014/11/27 01:15:22.540| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/compress.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/compress.png'
2014/11/27 01:15:22.540| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.541| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/compress.png
2014/11/27 01:15:22.542| store_client.cc(731) invokeHandlers: InvokeHandlers: 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.542| store_client.cc(731) invokeHandlers: InvokeHandlers: 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.542| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/compress.png
2014/11/27 01:15:22.542| store.cc(1028) complete: storeComplete: '859639B2D98C5D1EECA638A885752553'
2014/11/27 01:15:22.542| store.cc(1319) validLength: storeEntryValidLength: Checking '859639B2D98C5D1EECA638A885752553'
2014/11/27 01:15:22.542| store_client.cc(731) invokeHandlers: InvokeHandlers: 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.542| store.cc(523) unlock: MimeIcon::created unlocking key 859639B2D98C5D1EECA638A885752553 e:=sSV/0x338c7e0*1
2014/11/27 01:15:22.542| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.542| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x338c7e0*0 into policy
2014/11/27 01:15:22.542| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/compress.png
2014/11/27 01:15:22.543| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.543| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.543| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.543| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.543| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.543| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.543| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.543| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.543| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.543| store_dir.cc(744) find: none of 0 cache_dirs have 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.543| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/script.png
2014/11/27 01:15:22.543| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/script.png'
2014/11/27 01:15:22.543| MemObject.cc(97) MemObject: new MemObject 0x338dd90
2014/11/27 01:15:22.543| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x338e190*1
2014/11/27 01:15:22.543| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/script.png
2014/11/27 01:15:22.543| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x338e190*1 key '144DB87249EAAB83CEBC10265BB8A937'
2014/11/27 01:15:22.543| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x338e190*1 key '93A5D936ED6A19E50691CD1B2FF11519'
2014/11/27 01:15:22.543| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/script.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/script.png'
2014/11/27 01:15:22.543| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.543| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/script.png
2014/11/27 01:15:22.545| store_client.cc(731) invokeHandlers: InvokeHandlers: 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.545| store_client.cc(731) invokeHandlers: InvokeHandlers: 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.545| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/script.png
2014/11/27 01:15:22.545| store.cc(1028) complete: storeComplete: '93A5D936ED6A19E50691CD1B2FF11519'
2014/11/27 01:15:22.545| store.cc(1319) validLength: storeEntryValidLength: Checking '93A5D936ED6A19E50691CD1B2FF11519'
2014/11/27 01:15:22.545| store_client.cc(731) invokeHandlers: InvokeHandlers: 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.545| store.cc(523) unlock: MimeIcon::created unlocking key 93A5D936ED6A19E50691CD1B2FF11519 e:=sSV/0x338e190*1
2014/11/27 01:15:22.545| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.545| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x338e190*0 into policy
2014/11/27 01:15:22.545| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/script.png
2014/11/27 01:15:22.545| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.545| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.545| store_dir.cc(1073) get: storeGet: looking up 8C0F252779516ECED33C19BEAC975C7E
2014/11/27 01:15:22.545| store_dir.cc(744) find: none of 0 cache_dirs have 8C0F252779516ECED33C19BEAC975C7E
2014/11/27 01:15:22.545| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/database.png
2014/11/27 01:15:22.545| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/database.png'
2014/11/27 01:15:22.545| MemObject.cc(97) MemObject: new MemObject 0x338f740
2014/11/27 01:15:22.545| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x338fb40*1
2014/11/27 01:15:22.545| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/database.png
2014/11/27 01:15:22.545| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x338fb40*1 key 'D5D1C5D159A1E1D6A94B05AC38C005F9'
2014/11/27 01:15:22.545| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x338fb40*1 key '8C0F252779516ECED33C19BEAC975C7E'
2014/11/27 01:15:22.545| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/database.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/database.png'
2014/11/27 01:15:22.545| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.546| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/database.png
2014/11/27 01:15:22.547| store_client.cc(731) invokeHandlers: InvokeHandlers: 8C0F252779516ECED33C19BEAC975C7E
2014/11/27 01:15:22.547| store_client.cc(731) invokeHandlers: InvokeHandlers: 8C0F252779516ECED33C19BEAC975C7E
2014/11/27 01:15:22.547| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/database.png
2014/11/27 01:15:22.547| store.cc(1028) complete: storeComplete: '8C0F252779516ECED33C19BEAC975C7E'
2014/11/27 01:15:22.547| store.cc(1319) validLength: storeEntryValidLength: Checking '8C0F252779516ECED33C19BEAC975C7E'
2014/11/27 01:15:22.547| store_client.cc(731) invokeHandlers: InvokeHandlers: 8C0F252779516ECED33C19BEAC975C7E
2014/11/27 01:15:22.547| store.cc(523) unlock: MimeIcon::created unlocking key 8C0F252779516ECED33C19BEAC975C7E e:=sSV/0x338fb40*1
2014/11/27 01:15:22.547| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.547| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x338fb40*0 into policy
2014/11/27 01:15:22.547| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/database.png
2014/11/27 01:15:22.547| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.547| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.547| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.547| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.548| store_dir.cc(1073) get: storeGet: looking up 9CCBB9E3BABFE9FBB70719DBC551A187
2014/11/27 01:15:22.548| store_dir.cc(744) find: none of 0 cache_dirs have 9CCBB9E3BABFE9FBB70719DBC551A187
2014/11/27 01:15:22.548| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/cd.png
2014/11/27 01:15:22.548| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/cd.png'
2014/11/27 01:15:22.548| MemObject.cc(97) MemObject: new MemObject 0x33910d0
2014/11/27 01:15:22.548| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x338fac0*1
2014/11/27 01:15:22.548| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/cd.png
2014/11/27 01:15:22.548| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x338fac0*1 key 'C47C7344BFD2F82A115E50B4AFD57C73'
2014/11/27 01:15:22.548| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x338fac0*1 key '9CCBB9E3BABFE9FBB70719DBC551A187'
2014/11/27 01:15:22.548| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/cd.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/cd.png'
2014/11/27 01:15:22.548| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.548| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/cd.png
2014/11/27 01:15:22.550| store_client.cc(731) invokeHandlers: InvokeHandlers: 9CCBB9E3BABFE9FBB70719DBC551A187
2014/11/27 01:15:22.550| store_client.cc(731) invokeHandlers: InvokeHandlers: 9CCBB9E3BABFE9FBB70719DBC551A187
2014/11/27 01:15:22.550| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/cd.png
2014/11/27 01:15:22.550| store.cc(1028) complete: storeComplete: '9CCBB9E3BABFE9FBB70719DBC551A187'
2014/11/27 01:15:22.550| store.cc(1319) validLength: storeEntryValidLength: Checking '9CCBB9E3BABFE9FBB70719DBC551A187'
2014/11/27 01:15:22.550| store_client.cc(731) invokeHandlers: InvokeHandlers: 9CCBB9E3BABFE9FBB70719DBC551A187
2014/11/27 01:15:22.550| store.cc(523) unlock: MimeIcon::created unlocking key 9CCBB9E3BABFE9FBB70719DBC551A187 e:=sSV/0x338fac0*1
2014/11/27 01:15:22.550| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.550| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x338fac0*0 into policy
2014/11/27 01:15:22.550| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/cd.png
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up 9CCBB9E3BABFE9FBB70719DBC551A187
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338fac0*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.550| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.550| store_dir.cc(1073) get: storeGet: looking up C6C255C752F7F20A55182B9AB3B288BF
2014/11/27 01:15:22.550| store_dir.cc(744) find: none of 0 cache_dirs have C6C255C752F7F20A55182B9AB3B288BF
2014/11/27 01:15:22.550| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_magnify.png
2014/11/27 01:15:22.550| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_magnify.png'
2014/11/27 01:15:22.550| MemObject.cc(97) MemObject: new MemObject 0x3392a10
2014/11/27 01:15:22.551| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33929a0*1
2014/11/27 01:15:22.551| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_magnify.png
2014/11/27 01:15:22.551| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33929a0*1 key 'CA19C91B956D12778DDD47A1F133BA2F'
2014/11/27 01:15:22.551| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33929a0*1 key 'C6C255C752F7F20A55182B9AB3B288BF'
2014/11/27 01:15:22.551| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_magnify.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_magnify.png'
2014/11/27 01:15:22.551| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.551| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_magnify.png
2014/11/27 01:15:22.552| store_client.cc(731) invokeHandlers: InvokeHandlers: C6C255C752F7F20A55182B9AB3B288BF
2014/11/27 01:15:22.552| store_client.cc(731) invokeHandlers: InvokeHandlers: C6C255C752F7F20A55182B9AB3B288BF
2014/11/27 01:15:22.552| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_magnify.png
2014/11/27 01:15:22.552| store.cc(1028) complete: storeComplete: 'C6C255C752F7F20A55182B9AB3B288BF'
2014/11/27 01:15:22.552| store.cc(1319) validLength: storeEntryValidLength: Checking 'C6C255C752F7F20A55182B9AB3B288BF'
2014/11/27 01:15:22.553| store_client.cc(731) invokeHandlers: InvokeHandlers: C6C255C752F7F20A55182B9AB3B288BF
2014/11/27 01:15:22.553| store.cc(523) unlock: MimeIcon::created unlocking key C6C255C752F7F20A55182B9AB3B288BF e:=sSV/0x33929a0*1
2014/11/27 01:15:22.553| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.553| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33929a0*0 into policy
2014/11/27 01:15:22.553| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_magnify.png
2014/11/27 01:15:22.553| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.553| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.553| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.553| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.553| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.553| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.553| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.553| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.553| store_dir.cc(1073) get: storeGet: looking up 683CA4FE0957F25DF94EC23B89C376C8
2014/11/27 01:15:22.553| store_dir.cc(744) find: none of 0 cache_dirs have 683CA4FE0957F25DF94EC23B89C376C8
2014/11/27 01:15:22.553| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/box.png
2014/11/27 01:15:22.553| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/box.png'
2014/11/27 01:15:22.553| MemObject.cc(97) MemObject: new MemObject 0x33943d0
2014/11/27 01:15:22.553| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3394360*1
2014/11/27 01:15:22.553| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/box.png
2014/11/27 01:15:22.553| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3394360*1 key '0D79614CE9E3237F4018BCB59A6C0FF1'
2014/11/27 01:15:22.553| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3394360*1 key '683CA4FE0957F25DF94EC23B89C376C8'
2014/11/27 01:15:22.553| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/box.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/box.png'
2014/11/27 01:15:22.553| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.553| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/box.png
2014/11/27 01:15:22.555| store_client.cc(731) invokeHandlers: InvokeHandlers: 683CA4FE0957F25DF94EC23B89C376C8
2014/11/27 01:15:22.555| store_client.cc(731) invokeHandlers: InvokeHandlers: 683CA4FE0957F25DF94EC23B89C376C8
2014/11/27 01:15:22.555| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/box.png
2014/11/27 01:15:22.555| store.cc(1028) complete: storeComplete: '683CA4FE0957F25DF94EC23B89C376C8'
2014/11/27 01:15:22.555| store.cc(1319) validLength: storeEntryValidLength: Checking '683CA4FE0957F25DF94EC23B89C376C8'
2014/11/27 01:15:22.555| store_client.cc(731) invokeHandlers: InvokeHandlers: 683CA4FE0957F25DF94EC23B89C376C8
2014/11/27 01:15:22.555| store.cc(523) unlock: MimeIcon::created unlocking key 683CA4FE0957F25DF94EC23B89C376C8 e:=sSV/0x3394360*1
2014/11/27 01:15:22.555| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.555| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3394360*0 into policy
2014/11/27 01:15:22.555| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/box.png
2014/11/27 01:15:22.555| store_dir.cc(1073) get: storeGet: looking up 683CA4FE0957F25DF94EC23B89C376C8
2014/11/27 01:15:22.555| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3394360*0
2014/11/27 01:15:22.555| store_dir.cc(1073) get: storeGet: looking up 7C26723F666ED2415A2989B56DD64037
2014/11/27 01:15:22.555| store_dir.cc(744) find: none of 0 cache_dirs have 7C26723F666ED2415A2989B56DD64037
2014/11/27 01:15:22.555| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_stack.png
2014/11/27 01:15:22.555| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_stack.png'
2014/11/27 01:15:22.555| MemObject.cc(97) MemObject: new MemObject 0x3395d60
2014/11/27 01:15:22.555| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3395cf0*1
2014/11/27 01:15:22.555| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_stack.png
2014/11/27 01:15:22.555| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3395cf0*1 key 'ED35F94EF9DAD091F625C3DE8E5DC915'
2014/11/27 01:15:22.555| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3395cf0*1 key '7C26723F666ED2415A2989B56DD64037'
2014/11/27 01:15:22.555| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_stack.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_stack.png'
2014/11/27 01:15:22.556| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.556| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_stack.png
2014/11/27 01:15:22.557| store_client.cc(731) invokeHandlers: InvokeHandlers: 7C26723F666ED2415A2989B56DD64037
2014/11/27 01:15:22.557| store_client.cc(731) invokeHandlers: InvokeHandlers: 7C26723F666ED2415A2989B56DD64037
2014/11/27 01:15:22.557| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_stack.png
2014/11/27 01:15:22.557| store.cc(1028) complete: storeComplete: '7C26723F666ED2415A2989B56DD64037'
2014/11/27 01:15:22.557| store.cc(1319) validLength: storeEntryValidLength: Checking '7C26723F666ED2415A2989B56DD64037'
2014/11/27 01:15:22.557| store_client.cc(731) invokeHandlers: InvokeHandlers: 7C26723F666ED2415A2989B56DD64037
2014/11/27 01:15:22.557| store.cc(523) unlock: MimeIcon::created unlocking key 7C26723F666ED2415A2989B56DD64037 e:=sSV/0x3395cf0*1
2014/11/27 01:15:22.557| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.557| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3395cf0*0 into policy
2014/11/27 01:15:22.557| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_stack.png
2014/11/27 01:15:22.558| store_dir.cc(1073) get: storeGet: looking up D6BF2395672A3EAF823DE0731B02D0FD
2014/11/27 01:15:22.558| store_dir.cc(744) find: none of 0 cache_dirs have D6BF2395672A3EAF823DE0731B02D0FD
2014/11/27 01:15:22.558| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/package.png
2014/11/27 01:15:22.558| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/package.png'
2014/11/27 01:15:22.558| MemObject.cc(97) MemObject: new MemObject 0x3397720
2014/11/27 01:15:22.558| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33976b0*1
2014/11/27 01:15:22.558| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/package.png
2014/11/27 01:15:22.558| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33976b0*1 key '9A95B8F33D045CEB4B1CBA040BA33515'
2014/11/27 01:15:22.558| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33976b0*1 key 'D6BF2395672A3EAF823DE0731B02D0FD'
2014/11/27 01:15:22.558| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/package.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/package.png'
2014/11/27 01:15:22.558| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.558| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/package.png
2014/11/27 01:15:22.560| store_client.cc(731) invokeHandlers: InvokeHandlers: D6BF2395672A3EAF823DE0731B02D0FD
2014/11/27 01:15:22.560| store_client.cc(731) invokeHandlers: InvokeHandlers: D6BF2395672A3EAF823DE0731B02D0FD
2014/11/27 01:15:22.560| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/package.png
2014/11/27 01:15:22.560| store.cc(1028) complete: storeComplete: 'D6BF2395672A3EAF823DE0731B02D0FD'
2014/11/27 01:15:22.560| store.cc(1319) validLength: storeEntryValidLength: Checking 'D6BF2395672A3EAF823DE0731B02D0FD'
2014/11/27 01:15:22.560| store_client.cc(731) invokeHandlers: InvokeHandlers: D6BF2395672A3EAF823DE0731B02D0FD
2014/11/27 01:15:22.560| store.cc(523) unlock: MimeIcon::created unlocking key D6BF2395672A3EAF823DE0731B02D0FD e:=sSV/0x33976b0*1
2014/11/27 01:15:22.560| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.560| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33976b0*0 into policy
2014/11/27 01:15:22.560| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/package.png
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 683CA4FE0957F25DF94EC23B89C376C8
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3394360*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 683CA4FE0957F25DF94EC23B89C376C8
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3394360*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 7C26723F666ED2415A2989B56DD64037
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3395cf0*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 7C26723F666ED2415A2989B56DD64037
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3395cf0*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.560| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.560| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.561| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.561| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.561| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.561| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.561| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.561| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.561| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.561| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.561| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.561| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.561| store_dir.cc(1073) get: storeGet: looking up 540CB777FCAD6BE09A9DD78CBB41A526
2014/11/27 01:15:22.561| store_dir.cc(744) find: none of 0 cache_dirs have 540CB777FCAD6BE09A9DD78CBB41A526
2014/11/27 01:15:22.561| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/photo.png
2014/11/27 01:15:22.561| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/photo.png'
2014/11/27 01:15:22.561| MemObject.cc(97) MemObject: new MemObject 0x33990b0
2014/11/27 01:15:22.561| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x3399040*1
2014/11/27 01:15:22.561| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/photo.png
2014/11/27 01:15:22.561| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x3399040*1 key '900B29FFCA40C1A506CC064092C72ED3'
2014/11/27 01:15:22.561| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x3399040*1 key '540CB777FCAD6BE09A9DD78CBB41A526'
2014/11/27 01:15:22.561| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/photo.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/photo.png'
2014/11/27 01:15:22.561| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.561| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/photo.png
2014/11/27 01:15:22.563| store_client.cc(731) invokeHandlers: InvokeHandlers: 540CB777FCAD6BE09A9DD78CBB41A526
2014/11/27 01:15:22.563| store_client.cc(731) invokeHandlers: InvokeHandlers: 540CB777FCAD6BE09A9DD78CBB41A526
2014/11/27 01:15:22.563| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/photo.png
2014/11/27 01:15:22.563| store.cc(1028) complete: storeComplete: '540CB777FCAD6BE09A9DD78CBB41A526'
2014/11/27 01:15:22.563| store.cc(1319) validLength: storeEntryValidLength: Checking '540CB777FCAD6BE09A9DD78CBB41A526'
2014/11/27 01:15:22.563| store_client.cc(731) invokeHandlers: InvokeHandlers: 540CB777FCAD6BE09A9DD78CBB41A526
2014/11/27 01:15:22.563| store.cc(523) unlock: MimeIcon::created unlocking key 540CB777FCAD6BE09A9DD78CBB41A526 e:=sSV/0x3399040*1
2014/11/27 01:15:22.563| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.563| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x3399040*0 into policy
2014/11/27 01:15:22.563| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/photo.png
2014/11/27 01:15:22.563| store_dir.cc(1073) get: storeGet: looking up 540CB777FCAD6BE09A9DD78CBB41A526
2014/11/27 01:15:22.563| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3399040*0
2014/11/27 01:15:22.563| store_dir.cc(1073) get: storeGet: looking up 540CB777FCAD6BE09A9DD78CBB41A526
2014/11/27 01:15:22.563| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3399040*0
2014/11/27 01:15:22.563| store_dir.cc(1073) get: storeGet: looking up 540CB777FCAD6BE09A9DD78CBB41A526
2014/11/27 01:15:22.563| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x3399040*0
2014/11/27 01:15:22.563| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.563| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.563| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.563| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.563| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.563| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.563| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.563| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.564| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.564| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.564| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.564| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.564| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.564| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.564| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.564| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.564| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.564| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.564| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.564| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.564| store_dir.cc(1073) get: storeGet: looking up 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.564| store_dir.cc(744) find: none of 0 cache_dirs have 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.564| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_world.png
2014/11/27 01:15:22.564| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_world.png'
2014/11/27 01:15:22.564| MemObject.cc(97) MemObject: new MemObject 0x339aa60
2014/11/27 01:15:22.564| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x339a9f0*1
2014/11/27 01:15:22.564| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_world.png
2014/11/27 01:15:22.564| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x339a9f0*1 key 'CA8DE5F1643D5FF46FDF5041E1016907'
2014/11/27 01:15:22.564| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x339a9f0*1 key '19C41E4F777D19FFA38C31FC3FE11777'
2014/11/27 01:15:22.564| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_world.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_world.png'
2014/11/27 01:15:22.564| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.564| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_world.png
2014/11/27 01:15:22.566| store_client.cc(731) invokeHandlers: InvokeHandlers: 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.566| store_client.cc(731) invokeHandlers: InvokeHandlers: 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.566| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_world.png
2014/11/27 01:15:22.566| store.cc(1028) complete: storeComplete: '19C41E4F777D19FFA38C31FC3FE11777'
2014/11/27 01:15:22.566| store.cc(1319) validLength: storeEntryValidLength: Checking '19C41E4F777D19FFA38C31FC3FE11777'
2014/11/27 01:15:22.566| store_client.cc(731) invokeHandlers: InvokeHandlers: 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.566| store.cc(523) unlock: MimeIcon::created unlocking key 19C41E4F777D19FFA38C31FC3FE11777 e:=sSV/0x339a9f0*1
2014/11/27 01:15:22.566| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.566| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x339a9f0*0 into policy
2014/11/27 01:15:22.566| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_world.png
2014/11/27 01:15:22.566| store_dir.cc(1073) get: storeGet: looking up 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.566| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x339a9f0*0
2014/11/27 01:15:22.566| store_dir.cc(1073) get: storeGet: looking up 8F6795E3ACAD40C3F1A13097CAE4B3D5
2014/11/27 01:15:22.566| store_dir.cc(744) find: none of 0 cache_dirs have 8F6795E3ACAD40C3F1A13097CAE4B3D5
2014/11/27 01:15:22.566| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/css.png
2014/11/27 01:15:22.566| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/css.png'
2014/11/27 01:15:22.566| MemObject.cc(97) MemObject: new MemObject 0x339c410
2014/11/27 01:15:22.566| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x339c3a0*1
2014/11/27 01:15:22.566| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/css.png
2014/11/27 01:15:22.566| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x339c3a0*1 key '5350AFDE32328A7462D458E31188CD90'
2014/11/27 01:15:22.566| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x339c3a0*1 key '8F6795E3ACAD40C3F1A13097CAE4B3D5'
2014/11/27 01:15:22.566| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/css.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/css.png'
2014/11/27 01:15:22.566| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.567| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/css.png
2014/11/27 01:15:22.568| store_client.cc(731) invokeHandlers: InvokeHandlers: 8F6795E3ACAD40C3F1A13097CAE4B3D5
2014/11/27 01:15:22.568| store_client.cc(731) invokeHandlers: InvokeHandlers: 8F6795E3ACAD40C3F1A13097CAE4B3D5
2014/11/27 01:15:22.568| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/css.png
2014/11/27 01:15:22.568| store.cc(1028) complete: storeComplete: '8F6795E3ACAD40C3F1A13097CAE4B3D5'
2014/11/27 01:15:22.568| store.cc(1319) validLength: storeEntryValidLength: Checking '8F6795E3ACAD40C3F1A13097CAE4B3D5'
2014/11/27 01:15:22.568| store_client.cc(731) invokeHandlers: InvokeHandlers: 8F6795E3ACAD40C3F1A13097CAE4B3D5
2014/11/27 01:15:22.568| store.cc(523) unlock: MimeIcon::created unlocking key 8F6795E3ACAD40C3F1A13097CAE4B3D5 e:=sSV/0x339c3a0*1
2014/11/27 01:15:22.568| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.568| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x339c3a0*0 into policy
2014/11/27 01:15:22.568| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/css.png
2014/11/27 01:15:22.568| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.569| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.569| store_dir.cc(1073) get: storeGet: looking up C1C15A2DF4443D42B1A2ABE3F3AD3374
2014/11/27 01:15:22.569| store_dir.cc(744) find: none of 0 cache_dirs have C1C15A2DF4443D42B1A2ABE3F3AD3374
2014/11/27 01:15:22.569| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_c.png
2014/11/27 01:15:22.569| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_c.png'
2014/11/27 01:15:22.569| MemObject.cc(97) MemObject: new MemObject 0x339ddc0
2014/11/27 01:15:22.569| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x339dd50*1
2014/11/27 01:15:22.569| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_c.png
2014/11/27 01:15:22.569| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x339dd50*1 key 'B0E2611C5F025DA889D2A255D5CC47CB'
2014/11/27 01:15:22.569| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x339dd50*1 key 'C1C15A2DF4443D42B1A2ABE3F3AD3374'
2014/11/27 01:15:22.569| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_c.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_c.png'
2014/11/27 01:15:22.569| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.569| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_c.png
2014/11/27 01:15:22.571| store_client.cc(731) invokeHandlers: InvokeHandlers: C1C15A2DF4443D42B1A2ABE3F3AD3374
2014/11/27 01:15:22.571| store_client.cc(731) invokeHandlers: InvokeHandlers: C1C15A2DF4443D42B1A2ABE3F3AD3374
2014/11/27 01:15:22.571| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_c.png
2014/11/27 01:15:22.571| store.cc(1028) complete: storeComplete: 'C1C15A2DF4443D42B1A2ABE3F3AD3374'
2014/11/27 01:15:22.571| store.cc(1319) validLength: storeEntryValidLength: Checking 'C1C15A2DF4443D42B1A2ABE3F3AD3374'
2014/11/27 01:15:22.571| store_client.cc(731) invokeHandlers: InvokeHandlers: C1C15A2DF4443D42B1A2ABE3F3AD3374
2014/11/27 01:15:22.571| store.cc(523) unlock: MimeIcon::created unlocking key C1C15A2DF4443D42B1A2ABE3F3AD3374 e:=sSV/0x339dd50*1
2014/11/27 01:15:22.571| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.571| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x339dd50*0 into policy
2014/11/27 01:15:22.571| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_c.png
2014/11/27 01:15:22.571| store_dir.cc(1073) get: storeGet: looking up C1C15A2DF4443D42B1A2ABE3F3AD3374
2014/11/27 01:15:22.571| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x339dd50*0
2014/11/27 01:15:22.571| store_dir.cc(1073) get: storeGet: looking up CDA8DD64F38FDABBEF83E7F48FF0EC55
2014/11/27 01:15:22.571| store_dir.cc(744) find: none of 0 cache_dirs have CDA8DD64F38FDABBEF83E7F48FF0EC55
2014/11/27 01:15:22.571| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_cplusplus.png
2014/11/27 01:15:22.571| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_cplusplus.png'
2014/11/27 01:15:22.571| MemObject.cc(97) MemObject: new MemObject 0x339f770
2014/11/27 01:15:22.571| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x339f700*1
2014/11/27 01:15:22.571| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_cplusplus.png
2014/11/27 01:15:22.571| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x339f700*1 key 'F613F3C956FAD91790B430C355153793'
2014/11/27 01:15:22.571| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x339f700*1 key 'CDA8DD64F38FDABBEF83E7F48FF0EC55'
2014/11/27 01:15:22.571| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_cplusplus.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_cplusplus.png'
2014/11/27 01:15:22.571| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.571| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_cplusplus.png
2014/11/27 01:15:22.573| store_client.cc(731) invokeHandlers: InvokeHandlers: CDA8DD64F38FDABBEF83E7F48FF0EC55
2014/11/27 01:15:22.573| store_client.cc(731) invokeHandlers: InvokeHandlers: CDA8DD64F38FDABBEF83E7F48FF0EC55
2014/11/27 01:15:22.573| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_cplusplus.png
2014/11/27 01:15:22.573| store.cc(1028) complete: storeComplete: 'CDA8DD64F38FDABBEF83E7F48FF0EC55'
2014/11/27 01:15:22.573| store.cc(1319) validLength: storeEntryValidLength: Checking 'CDA8DD64F38FDABBEF83E7F48FF0EC55'
2014/11/27 01:15:22.573| store_client.cc(731) invokeHandlers: InvokeHandlers: CDA8DD64F38FDABBEF83E7F48FF0EC55
2014/11/27 01:15:22.573| store.cc(523) unlock: MimeIcon::created unlocking key CDA8DD64F38FDABBEF83E7F48FF0EC55 e:=sSV/0x339f700*1
2014/11/27 01:15:22.573| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.573| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x339f700*0 into policy
2014/11/27 01:15:22.573| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_cplusplus.png
2014/11/27 01:15:22.573| store_dir.cc(1073) get: storeGet: looking up CDA8DD64F38FDABBEF83E7F48FF0EC55
2014/11/27 01:15:22.573| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x339f700*0
2014/11/27 01:15:22.573| store_dir.cc(1073) get: storeGet: looking up C1C15A2DF4443D42B1A2ABE3F3AD3374
2014/11/27 01:15:22.573| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x339dd50*0
2014/11/27 01:15:22.573| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.573| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.573| store_dir.cc(1073) get: storeGet: looking up 86F8329951E4E8F4F27D8D36E8FE5A42
2014/11/27 01:15:22.573| store_dir.cc(744) find: none of 0 cache_dirs have 86F8329951E4E8F4F27D8D36E8FE5A42
2014/11/27 01:15:22.573| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_code.png
2014/11/27 01:15:22.573| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_code.png'
2014/11/27 01:15:22.573| MemObject.cc(97) MemObject: new MemObject 0x33a1130
2014/11/27 01:15:22.574| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33a10c0*1
2014/11/27 01:15:22.574| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_code.png
2014/11/27 01:15:22.574| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33a10c0*1 key 'EAD835601CFCD5C49429C9421D43E8C4'
2014/11/27 01:15:22.574| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33a10c0*1 key '86F8329951E4E8F4F27D8D36E8FE5A42'
2014/11/27 01:15:22.574| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_code.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_code.png'
2014/11/27 01:15:22.574| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.574| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_code.png
2014/11/27 01:15:22.575| store_client.cc(731) invokeHandlers: InvokeHandlers: 86F8329951E4E8F4F27D8D36E8FE5A42
2014/11/27 01:15:22.575| store_client.cc(731) invokeHandlers: InvokeHandlers: 86F8329951E4E8F4F27D8D36E8FE5A42
2014/11/27 01:15:22.575| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_code.png
2014/11/27 01:15:22.575| store.cc(1028) complete: storeComplete: '86F8329951E4E8F4F27D8D36E8FE5A42'
2014/11/27 01:15:22.575| store.cc(1319) validLength: storeEntryValidLength: Checking '86F8329951E4E8F4F27D8D36E8FE5A42'
2014/11/27 01:15:22.576| store_client.cc(731) invokeHandlers: InvokeHandlers: 86F8329951E4E8F4F27D8D36E8FE5A42
2014/11/27 01:15:22.576| store.cc(523) unlock: MimeIcon::created unlocking key 86F8329951E4E8F4F27D8D36E8FE5A42 e:=sSV/0x33a10c0*1
2014/11/27 01:15:22.576| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.576| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33a10c0*0 into policy
2014/11/27 01:15:22.576| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_code.png
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up 11E51DB30434453AD0C7A0185D2CD597
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338ae40*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.576| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.576| store_dir.cc(1073) get: storeGet: looking up 14070246FEADB0E4627376D79F796056
2014/11/27 01:15:22.576| store_dir.cc(744) find: none of 0 cache_dirs have 14070246FEADB0E4627376D79F796056
2014/11/27 01:15:22.576| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_zip.png
2014/11/27 01:15:22.576| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_zip.png'
2014/11/27 01:15:22.577| MemObject.cc(97) MemObject: new MemObject 0x33a2ca0
2014/11/27 01:15:22.577| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33a2f20*1
2014/11/27 01:15:22.577| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_zip.png
2014/11/27 01:15:22.577| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33a2f20*1 key '7481D3531522DA0CA4AA4D16D0E156D0'
2014/11/27 01:15:22.577| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33a2f20*1 key '14070246FEADB0E4627376D79F796056'
2014/11/27 01:15:22.577| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_zip.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_zip.png'
2014/11/27 01:15:22.577| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.577| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_zip.png
2014/11/27 01:15:22.578| store_client.cc(731) invokeHandlers: InvokeHandlers: 14070246FEADB0E4627376D79F796056
2014/11/27 01:15:22.578| store_client.cc(731) invokeHandlers: InvokeHandlers: 14070246FEADB0E4627376D79F796056
2014/11/27 01:15:22.578| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_zip.png
2014/11/27 01:15:22.579| store.cc(1028) complete: storeComplete: '14070246FEADB0E4627376D79F796056'
2014/11/27 01:15:22.579| store.cc(1319) validLength: storeEntryValidLength: Checking '14070246FEADB0E4627376D79F796056'
2014/11/27 01:15:22.579| store_client.cc(731) invokeHandlers: InvokeHandlers: 14070246FEADB0E4627376D79F796056
2014/11/27 01:15:22.579| store.cc(523) unlock: MimeIcon::created unlocking key 14070246FEADB0E4627376D79F796056 e:=sSV/0x33a2f20*1
2014/11/27 01:15:22.579| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.579| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33a2f20*0 into policy
2014/11/27 01:15:22.579| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_zip.png
2014/11/27 01:15:22.579| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.579| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.579| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.579| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.579| store_dir.cc(1073) get: storeGet: looking up A568488BE56A3D33CEF3AC5A07A3E3B6
2014/11/27 01:15:22.579| store_dir.cc(744) find: none of 0 cache_dirs have A568488BE56A3D33CEF3AC5A07A3E3B6
2014/11/27 01:15:22.579| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_word.png
2014/11/27 01:15:22.579| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_word.png'
2014/11/27 01:15:22.579| MemObject.cc(97) MemObject: new MemObject 0x33a4520
2014/11/27 01:15:22.579| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33a4940*1
2014/11/27 01:15:22.579| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_word.png
2014/11/27 01:15:22.579| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33a4940*1 key 'CAEAB3AF8FC8EF2E3AA02182B39CFA2B'
2014/11/27 01:15:22.579| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33a4940*1 key 'A568488BE56A3D33CEF3AC5A07A3E3B6'
2014/11/27 01:15:22.579| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_word.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_word.png'
2014/11/27 01:15:22.579| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.579| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_word.png
2014/11/27 01:15:22.581| store_client.cc(731) invokeHandlers: InvokeHandlers: A568488BE56A3D33CEF3AC5A07A3E3B6
2014/11/27 01:15:22.581| store_client.cc(731) invokeHandlers: InvokeHandlers: A568488BE56A3D33CEF3AC5A07A3E3B6
2014/11/27 01:15:22.581| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_word.png
2014/11/27 01:15:22.581| store.cc(1028) complete: storeComplete: 'A568488BE56A3D33CEF3AC5A07A3E3B6'
2014/11/27 01:15:22.581| store.cc(1319) validLength: storeEntryValidLength: Checking 'A568488BE56A3D33CEF3AC5A07A3E3B6'
2014/11/27 01:15:22.581| store_client.cc(731) invokeHandlers: InvokeHandlers: A568488BE56A3D33CEF3AC5A07A3E3B6
2014/11/27 01:15:22.581| store.cc(523) unlock: MimeIcon::created unlocking key A568488BE56A3D33CEF3AC5A07A3E3B6 e:=sSV/0x33a4940*1
2014/11/27 01:15:22.581| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.581| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33a4940*0 into policy
2014/11/27 01:15:22.581| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_word.png
2014/11/27 01:15:22.581| store_dir.cc(1073) get: storeGet: looking up 6E286E2CF3E2D470E1AD1E5139C22180
2014/11/27 01:15:22.581| store_dir.cc(744) find: none of 0 cache_dirs have 6E286E2CF3E2D470E1AD1E5139C22180
2014/11/27 01:15:22.581| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_excel.png
2014/11/27 01:15:22.581| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_excel.png'
2014/11/27 01:15:22.581| MemObject.cc(97) MemObject: new MemObject 0x33a5ed0
2014/11/27 01:15:22.581| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33a62d0*1
2014/11/27 01:15:22.581| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_excel.png
2014/11/27 01:15:22.581| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33a62d0*1 key '579FF2DAE232880B5FE52E05EBBFB3F5'
2014/11/27 01:15:22.581| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33a62d0*1 key '6E286E2CF3E2D470E1AD1E5139C22180'
2014/11/27 01:15:22.581| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_excel.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_excel.png'
2014/11/27 01:15:22.581| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.582| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_excel.png
2014/11/27 01:15:22.583| store_client.cc(731) invokeHandlers: InvokeHandlers: 6E286E2CF3E2D470E1AD1E5139C22180
2014/11/27 01:15:22.583| store_client.cc(731) invokeHandlers: InvokeHandlers: 6E286E2CF3E2D470E1AD1E5139C22180
2014/11/27 01:15:22.583| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_excel.png
2014/11/27 01:15:22.583| store.cc(1028) complete: storeComplete: '6E286E2CF3E2D470E1AD1E5139C22180'
2014/11/27 01:15:22.583| store.cc(1319) validLength: storeEntryValidLength: Checking '6E286E2CF3E2D470E1AD1E5139C22180'
2014/11/27 01:15:22.583| store_client.cc(731) invokeHandlers: InvokeHandlers: 6E286E2CF3E2D470E1AD1E5139C22180
2014/11/27 01:15:22.583| store.cc(523) unlock: MimeIcon::created unlocking key 6E286E2CF3E2D470E1AD1E5139C22180 e:=sSV/0x33a62d0*1
2014/11/27 01:15:22.583| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.583| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33a62d0*0 into policy
2014/11/27 01:15:22.583| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_excel.png
2014/11/27 01:15:22.583| store_dir.cc(1073) get: storeGet: looking up 14319A81D237CF23E8AB2799D1416D01
2014/11/27 01:15:22.583| store_dir.cc(744) find: none of 0 cache_dirs have 14319A81D237CF23E8AB2799D1416D01
2014/11/27 01:15:22.583| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_powerpoint.png
2014/11/27 01:15:22.583| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_powerpoint.png'
2014/11/27 01:15:22.583| MemObject.cc(97) MemObject: new MemObject 0x33a7860
2014/11/27 01:15:22.584| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33a7c80*1
2014/11/27 01:15:22.584| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_powerpoint.png
2014/11/27 01:15:22.584| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33a7c80*1 key '0C05055EF7A966A57B6F8D2837936F7E'
2014/11/27 01:15:22.584| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33a7c80*1 key '14319A81D237CF23E8AB2799D1416D01'
2014/11/27 01:15:22.584| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_powerpoint.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_powerpoint.png'
2014/11/27 01:15:22.584| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.584| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_powerpoint.png
2014/11/27 01:15:22.585| store_client.cc(731) invokeHandlers: InvokeHandlers: 14319A81D237CF23E8AB2799D1416D01
2014/11/27 01:15:22.585| store_client.cc(731) invokeHandlers: InvokeHandlers: 14319A81D237CF23E8AB2799D1416D01
2014/11/27 01:15:22.585| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_powerpoint.png
2014/11/27 01:15:22.585| store.cc(1028) complete: storeComplete: '14319A81D237CF23E8AB2799D1416D01'
2014/11/27 01:15:22.585| store.cc(1319) validLength: storeEntryValidLength: Checking '14319A81D237CF23E8AB2799D1416D01'
2014/11/27 01:15:22.586| store_client.cc(731) invokeHandlers: InvokeHandlers: 14319A81D237CF23E8AB2799D1416D01
2014/11/27 01:15:22.586| store.cc(523) unlock: MimeIcon::created unlocking key 14319A81D237CF23E8AB2799D1416D01 e:=sSV/0x33a7c80*1
2014/11/27 01:15:22.586| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.586| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33a7c80*0 into policy
2014/11/27 01:15:22.586| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_powerpoint.png
2014/11/27 01:15:22.586| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.586| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.586| store_dir.cc(1073) get: storeGet: looking up D81E5CFD84EA27DB6A94514C03E68DB8
2014/11/27 01:15:22.586| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x336be20*0
2014/11/27 01:15:22.586| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.586| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.586| store_dir.cc(1073) get: storeGet: looking up 181E07A355FEE58A3D6A23964FFF3D14
2014/11/27 01:15:22.586| store_dir.cc(744) find: none of 0 cache_dirs have 181E07A355FEE58A3D6A23964FFF3D14
2014/11/27 01:15:22.586| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/picture.png
2014/11/27 01:15:22.586| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/picture.png'
2014/11/27 01:15:22.586| MemObject.cc(97) MemObject: new MemObject 0x33a9220
2014/11/27 01:15:22.586| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33a9620*1
2014/11/27 01:15:22.586| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/picture.png
2014/11/27 01:15:22.586| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33a9620*1 key '54D34B49E061D09204D9659AF090B853'
2014/11/27 01:15:22.586| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33a9620*1 key '181E07A355FEE58A3D6A23964FFF3D14'
2014/11/27 01:15:22.586| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/picture.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/picture.png'
2014/11/27 01:15:22.586| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.586| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/picture.png
2014/11/27 01:15:22.588| store_client.cc(731) invokeHandlers: InvokeHandlers: 181E07A355FEE58A3D6A23964FFF3D14
2014/11/27 01:15:22.588| store_client.cc(731) invokeHandlers: InvokeHandlers: 181E07A355FEE58A3D6A23964FFF3D14
2014/11/27 01:15:22.588| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/picture.png
2014/11/27 01:15:22.588| store.cc(1028) complete: storeComplete: '181E07A355FEE58A3D6A23964FFF3D14'
2014/11/27 01:15:22.588| store.cc(1319) validLength: storeEntryValidLength: Checking '181E07A355FEE58A3D6A23964FFF3D14'
2014/11/27 01:15:22.588| store_client.cc(731) invokeHandlers: InvokeHandlers: 181E07A355FEE58A3D6A23964FFF3D14
2014/11/27 01:15:22.588| store.cc(523) unlock: MimeIcon::created unlocking key 181E07A355FEE58A3D6A23964FFF3D14 e:=sSV/0x33a9620*1
2014/11/27 01:15:22.588| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.588| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33a9620*0 into policy
2014/11/27 01:15:22.588| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/picture.png
2014/11/27 01:15:22.588| store_dir.cc(1073) get: storeGet: looking up 181E07A355FEE58A3D6A23964FFF3D14
2014/11/27 01:15:22.588| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33a9620*0
2014/11/27 01:15:22.588| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.588| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.588| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.588| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.588| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.588| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.588| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.588| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.588| store_dir.cc(1073) get: storeGet: looking up 0C263D9D51E102332B649589484F918A
2014/11/27 01:15:22.588| store_dir.cc(744) find: none of 0 cache_dirs have 0C263D9D51E102332B649589484F918A
2014/11/27 01:15:22.588| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/information.png
2014/11/27 01:15:22.588| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/information.png'
2014/11/27 01:15:22.589| MemObject.cc(97) MemObject: new MemObject 0x33aabd0
2014/11/27 01:15:22.589| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33aafd0*1
2014/11/27 01:15:22.589| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/information.png
2014/11/27 01:15:22.589| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33aafd0*1 key 'F1867DADEB492713B8E28A43F5F426D9'
2014/11/27 01:15:22.589| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33aafd0*1 key '0C263D9D51E102332B649589484F918A'
2014/11/27 01:15:22.589| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/information.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/information.png'
2014/11/27 01:15:22.589| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.589| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/information.png
2014/11/27 01:15:22.590| store_client.cc(731) invokeHandlers: InvokeHandlers: 0C263D9D51E102332B649589484F918A
2014/11/27 01:15:22.590| store_client.cc(731) invokeHandlers: InvokeHandlers: 0C263D9D51E102332B649589484F918A
2014/11/27 01:15:22.590| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/information.png
2014/11/27 01:15:22.591| store.cc(1028) complete: storeComplete: '0C263D9D51E102332B649589484F918A'
2014/11/27 01:15:22.591| store.cc(1319) validLength: storeEntryValidLength: Checking '0C263D9D51E102332B649589484F918A'
2014/11/27 01:15:22.591| store_client.cc(731) invokeHandlers: InvokeHandlers: 0C263D9D51E102332B649589484F918A
2014/11/27 01:15:22.591| store.cc(523) unlock: MimeIcon::created unlocking key 0C263D9D51E102332B649589484F918A e:=sSV/0x33aafd0*1
2014/11/27 01:15:22.591| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.591| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33aafd0*0 into policy
2014/11/27 01:15:22.591| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/information.png
2014/11/27 01:15:22.591| store_dir.cc(1073) get: storeGet: looking up E085B4C54CD735AB8D8313A505402612
2014/11/27 01:15:22.591| store_dir.cc(744) find: none of 0 cache_dirs have E085B4C54CD735AB8D8313A505402612
2014/11/27 01:15:22.591| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/bomb.png
2014/11/27 01:15:22.591| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/bomb.png'
2014/11/27 01:15:22.591| MemObject.cc(97) MemObject: new MemObject 0x33ac580
2014/11/27 01:15:22.591| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33ac980*1
2014/11/27 01:15:22.591| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/bomb.png
2014/11/27 01:15:22.591| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33ac980*1 key '1F3ECD560831D9A23E71C8A89BEBCE94'
2014/11/27 01:15:22.591| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33ac980*1 key 'E085B4C54CD735AB8D8313A505402612'
2014/11/27 01:15:22.591| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/bomb.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/bomb.png'
2014/11/27 01:15:22.591| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.591| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/bomb.png
2014/11/27 01:15:22.593| store_client.cc(731) invokeHandlers: InvokeHandlers: E085B4C54CD735AB8D8313A505402612
2014/11/27 01:15:22.593| store_client.cc(731) invokeHandlers: InvokeHandlers: E085B4C54CD735AB8D8313A505402612
2014/11/27 01:15:22.593| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/bomb.png
2014/11/27 01:15:22.593| store.cc(1028) complete: storeComplete: 'E085B4C54CD735AB8D8313A505402612'
2014/11/27 01:15:22.593| store.cc(1319) validLength: storeEntryValidLength: Checking 'E085B4C54CD735AB8D8313A505402612'
2014/11/27 01:15:22.593| store_client.cc(731) invokeHandlers: InvokeHandlers: E085B4C54CD735AB8D8313A505402612
2014/11/27 01:15:22.593| store.cc(523) unlock: MimeIcon::created unlocking key E085B4C54CD735AB8D8313A505402612 e:=sSV/0x33ac980*1
2014/11/27 01:15:22.593| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.593| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33ac980*0 into policy
2014/11/27 01:15:22.593| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/bomb.png
2014/11/27 01:15:22.593| store_dir.cc(1073) get: storeGet: looking up E085B4C54CD735AB8D8313A505402612
2014/11/27 01:15:22.593| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33ac980*0
2014/11/27 01:15:22.593| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.593| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.593| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.593| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.593| store_dir.cc(1073) get: storeGet: looking up E14619C265204454F63168D76F32E64A
2014/11/27 01:15:22.593| store_dir.cc(744) find: none of 0 cache_dirs have E14619C265204454F63168D76F32E64A
2014/11/27 01:15:22.593| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/plugin_add.png
2014/11/27 01:15:22.593| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/plugin_add.png'
2014/11/27 01:15:22.593| MemObject.cc(97) MemObject: new MemObject 0x33adf30
2014/11/27 01:15:22.593| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33ae330*1
2014/11/27 01:15:22.593| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/plugin_add.png
2014/11/27 01:15:22.593| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33ae330*1 key '4364BA05B60B04ABFAD44BF3AEFC5D9C'
2014/11/27 01:15:22.593| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33ae330*1 key 'E14619C265204454F63168D76F32E64A'
2014/11/27 01:15:22.593| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/plugin_add.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/plugin_add.png'
2014/11/27 01:15:22.593| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.594| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/plugin_add.png
2014/11/27 01:15:22.595| store_client.cc(731) invokeHandlers: InvokeHandlers: E14619C265204454F63168D76F32E64A
2014/11/27 01:15:22.595| store_client.cc(731) invokeHandlers: InvokeHandlers: E14619C265204454F63168D76F32E64A
2014/11/27 01:15:22.595| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/plugin_add.png
2014/11/27 01:15:22.595| store.cc(1028) complete: storeComplete: 'E14619C265204454F63168D76F32E64A'
2014/11/27 01:15:22.595| store.cc(1319) validLength: storeEntryValidLength: Checking 'E14619C265204454F63168D76F32E64A'
2014/11/27 01:15:22.595| store_client.cc(731) invokeHandlers: InvokeHandlers: E14619C265204454F63168D76F32E64A
2014/11/27 01:15:22.595| store.cc(523) unlock: MimeIcon::created unlocking key E14619C265204454F63168D76F32E64A e:=sSV/0x33ae330*1
2014/11/27 01:15:22.595| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.595| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33ae330*0 into policy
2014/11/27 01:15:22.595| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/plugin_add.png
2014/11/27 01:15:22.595| store_dir.cc(1073) get: storeGet: looking up 46F7356332479A3C71647BA7EFF331BD
2014/11/27 01:15:22.595| store_dir.cc(744) find: none of 0 cache_dirs have 46F7356332479A3C71647BA7EFF331BD
2014/11/27 01:15:22.595| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/script_gear.png
2014/11/27 01:15:22.595| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/script_gear.png'
2014/11/27 01:15:22.595| MemObject.cc(97) MemObject: new MemObject 0x33af8e0
2014/11/27 01:15:22.596| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33afce0*1
2014/11/27 01:15:22.596| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/script_gear.png
2014/11/27 01:15:22.596| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33afce0*1 key 'A7ABF435286750BB4690D907F192AAAD'
2014/11/27 01:15:22.596| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33afce0*1 key '46F7356332479A3C71647BA7EFF331BD'
2014/11/27 01:15:22.596| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/script_gear.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/script_gear.png'
2014/11/27 01:15:22.596| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.596| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/script_gear.png
2014/11/27 01:15:22.597| store_client.cc(731) invokeHandlers: InvokeHandlers: 46F7356332479A3C71647BA7EFF331BD
2014/11/27 01:15:22.597| store_client.cc(731) invokeHandlers: InvokeHandlers: 46F7356332479A3C71647BA7EFF331BD
2014/11/27 01:15:22.597| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/script_gear.png
2014/11/27 01:15:22.598| store.cc(1028) complete: storeComplete: '46F7356332479A3C71647BA7EFF331BD'
2014/11/27 01:15:22.598| store.cc(1319) validLength: storeEntryValidLength: Checking '46F7356332479A3C71647BA7EFF331BD'
2014/11/27 01:15:22.598| store_client.cc(731) invokeHandlers: InvokeHandlers: 46F7356332479A3C71647BA7EFF331BD
2014/11/27 01:15:22.598| store.cc(523) unlock: MimeIcon::created unlocking key 46F7356332479A3C71647BA7EFF331BD e:=sSV/0x33afce0*1
2014/11/27 01:15:22.598| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.598| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33afce0*0 into policy
2014/11/27 01:15:22.598| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/script_gear.png
2014/11/27 01:15:22.598| store_dir.cc(1073) get: storeGet: looking up 9BA6814019AAC525B92A2BCC2E44A68D
2014/11/27 01:15:22.598| store_dir.cc(744) find: none of 0 cache_dirs have 9BA6814019AAC525B92A2BCC2E44A68D
2014/11/27 01:15:22.598| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/cup.png
2014/11/27 01:15:22.598| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/cup.png'
2014/11/27 01:15:22.598| MemObject.cc(97) MemObject: new MemObject 0x33b1290
2014/11/27 01:15:22.598| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33b1690*1
2014/11/27 01:15:22.598| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/cup.png
2014/11/27 01:15:22.598| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33b1690*1 key '2E5A180C3A8B8DC83AFB0DEAF557F305'
2014/11/27 01:15:22.598| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33b1690*1 key '9BA6814019AAC525B92A2BCC2E44A68D'
2014/11/27 01:15:22.598| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/cup.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/cup.png'
2014/11/27 01:15:22.598| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.598| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/cup.png
2014/11/27 01:15:22.600| store_client.cc(731) invokeHandlers: InvokeHandlers: 9BA6814019AAC525B92A2BCC2E44A68D
2014/11/27 01:15:22.600| store_client.cc(731) invokeHandlers: InvokeHandlers: 9BA6814019AAC525B92A2BCC2E44A68D
2014/11/27 01:15:22.600| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/cup.png
2014/11/27 01:15:22.600| store.cc(1028) complete: storeComplete: '9BA6814019AAC525B92A2BCC2E44A68D'
2014/11/27 01:15:22.600| store.cc(1319) validLength: storeEntryValidLength: Checking '9BA6814019AAC525B92A2BCC2E44A68D'
2014/11/27 01:15:22.600| store_client.cc(731) invokeHandlers: InvokeHandlers: 9BA6814019AAC525B92A2BCC2E44A68D
2014/11/27 01:15:22.600| store.cc(523) unlock: MimeIcon::created unlocking key 9BA6814019AAC525B92A2BCC2E44A68D e:=sSV/0x33b1690*1
2014/11/27 01:15:22.600| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.600| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33b1690*0 into policy
2014/11/27 01:15:22.600| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/cup.png
2014/11/27 01:15:22.600| store_dir.cc(1073) get: storeGet: looking up BBA08A4540C9F8EBC054A042A14F0E5F
2014/11/27 01:15:22.600| store_dir.cc(744) find: none of 0 cache_dirs have BBA08A4540C9F8EBC054A042A14F0E5F
2014/11/27 01:15:22.600| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/script_palette.png
2014/11/27 01:15:22.600| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/script_palette.png'
2014/11/27 01:15:22.600| MemObject.cc(97) MemObject: new MemObject 0x33b2c20
2014/11/27 01:15:22.600| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33b1610*1
2014/11/27 01:15:22.600| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/script_palette.png
2014/11/27 01:15:22.600| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33b1610*1 key '27F2E1B045B67083C77AEBF250484399'
2014/11/27 01:15:22.600| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33b1610*1 key 'BBA08A4540C9F8EBC054A042A14F0E5F'
2014/11/27 01:15:22.600| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/script_palette.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/script_palette.png'
2014/11/27 01:15:22.600| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.600| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/script_palette.png
2014/11/27 01:15:22.602| store_client.cc(731) invokeHandlers: InvokeHandlers: BBA08A4540C9F8EBC054A042A14F0E5F
2014/11/27 01:15:22.602| store_client.cc(731) invokeHandlers: InvokeHandlers: BBA08A4540C9F8EBC054A042A14F0E5F
2014/11/27 01:15:22.602| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/script_palette.png
2014/11/27 01:15:22.602| store.cc(1028) complete: storeComplete: 'BBA08A4540C9F8EBC054A042A14F0E5F'
2014/11/27 01:15:22.602| store.cc(1319) validLength: storeEntryValidLength: Checking 'BBA08A4540C9F8EBC054A042A14F0E5F'
2014/11/27 01:15:22.602| store_client.cc(731) invokeHandlers: InvokeHandlers: BBA08A4540C9F8EBC054A042A14F0E5F
2014/11/27 01:15:22.602| store.cc(523) unlock: MimeIcon::created unlocking key BBA08A4540C9F8EBC054A042A14F0E5F e:=sSV/0x33b1610*1
2014/11/27 01:15:22.602| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.602| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33b1610*0 into policy
2014/11/27 01:15:22.602| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/script_palette.png
2014/11/27 01:15:22.602| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.602| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.602| store_dir.cc(1073) get: storeGet: looking up E46D85BB192C32787C610C43C7B6B54C
2014/11/27 01:15:22.602| store_dir.cc(744) find: none of 0 cache_dirs have E46D85BB192C32787C610C43C7B6B54C
2014/11/27 01:15:22.602| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/film_key.png
2014/11/27 01:15:22.602| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/film_key.png'
2014/11/27 01:15:22.602| MemObject.cc(97) MemObject: new MemObject 0x33b4560
2014/11/27 01:15:22.602| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33b44f0*1
2014/11/27 01:15:22.602| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/film_key.png
2014/11/27 01:15:22.602| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33b44f0*1 key 'E8AB748B4EE97F2F0FD3F9DF18FD2E9F'
2014/11/27 01:15:22.603| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33b44f0*1 key 'E46D85BB192C32787C610C43C7B6B54C'
2014/11/27 01:15:22.603| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/film_key.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/film_key.png'
2014/11/27 01:15:22.603| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.603| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/film_key.png
2014/11/27 01:15:22.604| store_client.cc(731) invokeHandlers: InvokeHandlers: E46D85BB192C32787C610C43C7B6B54C
2014/11/27 01:15:22.604| store_client.cc(731) invokeHandlers: InvokeHandlers: E46D85BB192C32787C610C43C7B6B54C
2014/11/27 01:15:22.604| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/film_key.png
2014/11/27 01:15:22.604| store.cc(1028) complete: storeComplete: 'E46D85BB192C32787C610C43C7B6B54C'
2014/11/27 01:15:22.604| store.cc(1319) validLength: storeEntryValidLength: Checking 'E46D85BB192C32787C610C43C7B6B54C'
2014/11/27 01:15:22.604| store_client.cc(731) invokeHandlers: InvokeHandlers: E46D85BB192C32787C610C43C7B6B54C
2014/11/27 01:15:22.604| store.cc(523) unlock: MimeIcon::created unlocking key E46D85BB192C32787C610C43C7B6B54C e:=sSV/0x33b44f0*1
2014/11/27 01:15:22.605| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.605| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33b44f0*0 into policy
2014/11/27 01:15:22.605| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/film_key.png
2014/11/27 01:15:22.605| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.605| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.605| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.605| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.605| store_dir.cc(1073) get: storeGet: looking up 5F513ACCB4BEA8B9F17162FB2BACBBDA
2014/11/27 01:15:22.605| store_dir.cc(744) find: none of 0 cache_dirs have 5F513ACCB4BEA8B9F17162FB2BACBBDA
2014/11/27 01:15:22.605| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/plugin.png
2014/11/27 01:15:22.605| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/plugin.png'
2014/11/27 01:15:22.605| MemObject.cc(97) MemObject: new MemObject 0x33b5f10
2014/11/27 01:15:22.605| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33b5ea0*1
2014/11/27 01:15:22.605| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/plugin.png
2014/11/27 01:15:22.605| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33b5ea0*1 key '06955E7B8B0A4235B32D4D20FDC460FA'
2014/11/27 01:15:22.605| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33b5ea0*1 key '5F513ACCB4BEA8B9F17162FB2BACBBDA'
2014/11/27 01:15:22.605| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/plugin.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/plugin.png'
2014/11/27 01:15:22.605| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.605| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/plugin.png
2014/11/27 01:15:22.607| store_client.cc(731) invokeHandlers: InvokeHandlers: 5F513ACCB4BEA8B9F17162FB2BACBBDA
2014/11/27 01:15:22.607| store_client.cc(731) invokeHandlers: InvokeHandlers: 5F513ACCB4BEA8B9F17162FB2BACBBDA
2014/11/27 01:15:22.607| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/plugin.png
2014/11/27 01:15:22.607| store.cc(1028) complete: storeComplete: '5F513ACCB4BEA8B9F17162FB2BACBBDA'
2014/11/27 01:15:22.607| store.cc(1319) validLength: storeEntryValidLength: Checking '5F513ACCB4BEA8B9F17162FB2BACBBDA'
2014/11/27 01:15:22.607| store_client.cc(731) invokeHandlers: InvokeHandlers: 5F513ACCB4BEA8B9F17162FB2BACBBDA
2014/11/27 01:15:22.607| store.cc(523) unlock: MimeIcon::created unlocking key 5F513ACCB4BEA8B9F17162FB2BACBBDA e:=sSV/0x33b5ea0*1
2014/11/27 01:15:22.607| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.607| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33b5ea0*0 into policy
2014/11/27 01:15:22.607| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/plugin.png
2014/11/27 01:15:22.607| store_dir.cc(1073) get: storeGet: looking up 40C6FD4B550872FFB26C3A474B46CE06
2014/11/27 01:15:22.607| store_dir.cc(744) find: none of 0 cache_dirs have 40C6FD4B550872FFB26C3A474B46CE06
2014/11/27 01:15:22.607| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/drive_disk.png
2014/11/27 01:15:22.607| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/drive_disk.png'
2014/11/27 01:15:22.607| MemObject.cc(97) MemObject: new MemObject 0x33b78c0
2014/11/27 01:15:22.607| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33b7850*1
2014/11/27 01:15:22.607| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/drive_disk.png
2014/11/27 01:15:22.607| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33b7850*1 key '2C2FBB3219D3B40943A1F3DB84782A4E'
2014/11/27 01:15:22.607| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33b7850*1 key '40C6FD4B550872FFB26C3A474B46CE06'
2014/11/27 01:15:22.607| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/drive_disk.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/drive_disk.png'
2014/11/27 01:15:22.607| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.607| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/drive_disk.png
2014/11/27 01:15:22.609| store_client.cc(731) invokeHandlers: InvokeHandlers: 40C6FD4B550872FFB26C3A474B46CE06
2014/11/27 01:15:22.609| store_client.cc(731) invokeHandlers: InvokeHandlers: 40C6FD4B550872FFB26C3A474B46CE06
2014/11/27 01:15:22.609| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/drive_disk.png
2014/11/27 01:15:22.609| store.cc(1028) complete: storeComplete: '40C6FD4B550872FFB26C3A474B46CE06'
2014/11/27 01:15:22.609| store.cc(1319) validLength: storeEntryValidLength: Checking '40C6FD4B550872FFB26C3A474B46CE06'
2014/11/27 01:15:22.609| store_client.cc(731) invokeHandlers: InvokeHandlers: 40C6FD4B550872FFB26C3A474B46CE06
2014/11/27 01:15:22.609| store.cc(523) unlock: MimeIcon::created unlocking key 40C6FD4B550872FFB26C3A474B46CE06 e:=sSV/0x33b7850*1
2014/11/27 01:15:22.609| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.609| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33b7850*0 into policy
2014/11/27 01:15:22.609| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/drive_disk.png
2014/11/27 01:15:22.609| store_dir.cc(1073) get: storeGet: looking up 4226A0233E563AAFAECC8B1C7F522696
2014/11/27 01:15:22.609| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33820e0*0
2014/11/27 01:15:22.609| store_dir.cc(1073) get: storeGet: looking up 859639B2D98C5D1EECA638A885752553
2014/11/27 01:15:22.609| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338c7e0*0
2014/11/27 01:15:22.609| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.609| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.609| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.609| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.610| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.610| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.610| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.610| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.610| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.610| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.610| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.610| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.610| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.610| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.610| store_dir.cc(1073) get: storeGet: looking up F16CA0A0B0F9E5727914AD2B62B4FB74
2014/11/27 01:15:22.610| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337d300*0
2014/11/27 01:15:22.610| store_dir.cc(1073) get: storeGet: looking up FF3B1B5F182673F33B578D9B9C9E75C4
2014/11/27 01:15:22.610| store_dir.cc(744) find: none of 0 cache_dirs have FF3B1B5F182673F33B578D9B9C9E75C4
2014/11/27 01:15:22.610| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/chart_line.png
2014/11/27 01:15:22.610| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/chart_line.png'
2014/11/27 01:15:22.610| MemObject.cc(97) MemObject: new MemObject 0x33b9270
2014/11/27 01:15:22.610| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33b9200*1
2014/11/27 01:15:22.610| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/chart_line.png
2014/11/27 01:15:22.610| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33b9200*1 key '6E8FF943B9A2D54BD7A4DEEF5FAE0FC7'
2014/11/27 01:15:22.610| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33b9200*1 key 'FF3B1B5F182673F33B578D9B9C9E75C4'
2014/11/27 01:15:22.610| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/chart_line.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/chart_line.png'
2014/11/27 01:15:22.610| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.610| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/chart_line.png
2014/11/27 01:15:22.612| store_client.cc(731) invokeHandlers: InvokeHandlers: FF3B1B5F182673F33B578D9B9C9E75C4
2014/11/27 01:15:22.612| store_client.cc(731) invokeHandlers: InvokeHandlers: FF3B1B5F182673F33B578D9B9C9E75C4
2014/11/27 01:15:22.612| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/chart_line.png
2014/11/27 01:15:22.612| store.cc(1028) complete: storeComplete: 'FF3B1B5F182673F33B578D9B9C9E75C4'
2014/11/27 01:15:22.612| store.cc(1319) validLength: storeEntryValidLength: Checking 'FF3B1B5F182673F33B578D9B9C9E75C4'
2014/11/27 01:15:22.612| store_client.cc(731) invokeHandlers: InvokeHandlers: FF3B1B5F182673F33B578D9B9C9E75C4
2014/11/27 01:15:22.612| store.cc(523) unlock: MimeIcon::created unlocking key FF3B1B5F182673F33B578D9B9C9E75C4 e:=sSV/0x33b9200*1
2014/11/27 01:15:22.612| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.612| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33b9200*0 into policy
2014/11/27 01:15:22.612| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/chart_line.png
2014/11/27 01:15:22.612| store_dir.cc(1073) get: storeGet: looking up EBB6D2EE86B206086B7AD8914B18865C
2014/11/27 01:15:22.612| store_dir.cc(744) find: none of 0 cache_dirs have EBB6D2EE86B206086B7AD8914B18865C
2014/11/27 01:15:22.612| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/bricks.png
2014/11/27 01:15:22.612| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/bricks.png'
2014/11/27 01:15:22.612| MemObject.cc(97) MemObject: new MemObject 0x33bac20
2014/11/27 01:15:22.612| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33babb0*1
2014/11/27 01:15:22.612| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/bricks.png
2014/11/27 01:15:22.612| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33babb0*1 key '876D70528CCB2BC0B0EF8D60607A410D'
2014/11/27 01:15:22.612| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33babb0*1 key 'EBB6D2EE86B206086B7AD8914B18865C'
2014/11/27 01:15:22.612| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/bricks.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/bricks.png'
2014/11/27 01:15:22.612| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.613| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/bricks.png
2014/11/27 01:15:22.614| store_client.cc(731) invokeHandlers: InvokeHandlers: EBB6D2EE86B206086B7AD8914B18865C
2014/11/27 01:15:22.614| store_client.cc(731) invokeHandlers: InvokeHandlers: EBB6D2EE86B206086B7AD8914B18865C
2014/11/27 01:15:22.614| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/bricks.png
2014/11/27 01:15:22.614| store.cc(1028) complete: storeComplete: 'EBB6D2EE86B206086B7AD8914B18865C'
2014/11/27 01:15:22.614| store.cc(1319) validLength: storeEntryValidLength: Checking 'EBB6D2EE86B206086B7AD8914B18865C'
2014/11/27 01:15:22.614| store_client.cc(731) invokeHandlers: InvokeHandlers: EBB6D2EE86B206086B7AD8914B18865C
2014/11/27 01:15:22.614| store.cc(523) unlock: MimeIcon::created unlocking key EBB6D2EE86B206086B7AD8914B18865C e:=sSV/0x33babb0*1
2014/11/27 01:15:22.614| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.614| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33babb0*0 into policy
2014/11/27 01:15:22.614| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/bricks.png
2014/11/27 01:15:22.614| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.614| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.615| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.615| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 86F8329951E4E8F4F27D8D36E8FE5A42
2014/11/27 01:15:22.615| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33a10c0*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 86F8329951E4E8F4F27D8D36E8FE5A42
2014/11/27 01:15:22.615| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33a10c0*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.615| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.615| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.615| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 51B121AB09873161B8AA3027B291757A
2014/11/27 01:15:22.615| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x337b950*0
2014/11/27 01:15:22.615| store_dir.cc(1073) get: storeGet: looking up 2CAE304264CED8A999F7EDDAD80D9DB3
2014/11/27 01:15:22.615| store_dir.cc(744) find: none of 0 cache_dirs have 2CAE304264CED8A999F7EDDAD80D9DB3
2014/11/27 01:15:22.615| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/layers.png
2014/11/27 01:15:22.615| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/layers.png'
2014/11/27 01:15:22.615| MemObject.cc(97) MemObject: new MemObject 0x33bc5d0
2014/11/27 01:15:22.615| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33bc560*1
2014/11/27 01:15:22.615| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/layers.png
2014/11/27 01:15:22.615| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33bc560*1 key '0D2110D18F33B0BD52AB551A7757FBC6'
2014/11/27 01:15:22.615| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33bc560*1 key '2CAE304264CED8A999F7EDDAD80D9DB3'
2014/11/27 01:15:22.615| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/layers.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/layers.png'
2014/11/27 01:15:22.615| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.615| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/layers.png
2014/11/27 01:15:22.617| store_client.cc(731) invokeHandlers: InvokeHandlers: 2CAE304264CED8A999F7EDDAD80D9DB3
2014/11/27 01:15:22.617| store_client.cc(731) invokeHandlers: InvokeHandlers: 2CAE304264CED8A999F7EDDAD80D9DB3
2014/11/27 01:15:22.617| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/layers.png
2014/11/27 01:15:22.617| store.cc(1028) complete: storeComplete: '2CAE304264CED8A999F7EDDAD80D9DB3'
2014/11/27 01:15:22.617| store.cc(1319) validLength: storeEntryValidLength: Checking '2CAE304264CED8A999F7EDDAD80D9DB3'
2014/11/27 01:15:22.617| store_client.cc(731) invokeHandlers: InvokeHandlers: 2CAE304264CED8A999F7EDDAD80D9DB3
2014/11/27 01:15:22.617| store.cc(523) unlock: MimeIcon::created unlocking key 2CAE304264CED8A999F7EDDAD80D9DB3 e:=sSV/0x33bc560*1
2014/11/27 01:15:22.617| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.617| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33bc560*0 into policy
2014/11/27 01:15:22.617| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/layers.png
2014/11/27 01:15:22.617| store_dir.cc(1073) get: storeGet: looking up 2CAE304264CED8A999F7EDDAD80D9DB3
2014/11/27 01:15:22.617| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33bc560*0
2014/11/27 01:15:22.617| store_dir.cc(1073) get: storeGet: looking up 5F513ACCB4BEA8B9F17162FB2BACBBDA
2014/11/27 01:15:22.617| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33b5ea0*0
2014/11/27 01:15:22.617| store_dir.cc(1073) get: storeGet: looking up 9558A0E9BC84DF0EA31B96050B31244B
2014/11/27 01:15:22.617| store_dir.cc(744) find: none of 0 cache_dirs have 9558A0E9BC84DF0EA31B96050B31244B
2014/11/27 01:15:22.617| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/page_white_flash.png
2014/11/27 01:15:22.617| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/page_white_flash.png'
2014/11/27 01:15:22.618| MemObject.cc(97) MemObject: new MemObject 0x33bdf80
2014/11/27 01:15:22.618| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33bdf10*1
2014/11/27 01:15:22.618| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/page_white_flash.png
2014/11/27 01:15:22.618| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33bdf10*1 key '019DC4E46E93735C333410BF172AD112'
2014/11/27 01:15:22.618| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33bdf10*1 key '9558A0E9BC84DF0EA31B96050B31244B'
2014/11/27 01:15:22.618| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/page_white_flash.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/page_white_flash.png'
2014/11/27 01:15:22.618| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.618| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/page_white_flash.png
2014/11/27 01:15:22.619| store_client.cc(731) invokeHandlers: InvokeHandlers: 9558A0E9BC84DF0EA31B96050B31244B
2014/11/27 01:15:22.619| store_client.cc(731) invokeHandlers: InvokeHandlers: 9558A0E9BC84DF0EA31B96050B31244B
2014/11/27 01:15:22.619| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/page_white_flash.png
2014/11/27 01:15:22.620| store.cc(1028) complete: storeComplete: '9558A0E9BC84DF0EA31B96050B31244B'
2014/11/27 01:15:22.620| store.cc(1319) validLength: storeEntryValidLength: Checking '9558A0E9BC84DF0EA31B96050B31244B'
2014/11/27 01:15:22.620| store_client.cc(731) invokeHandlers: InvokeHandlers: 9558A0E9BC84DF0EA31B96050B31244B
2014/11/27 01:15:22.620| store.cc(523) unlock: MimeIcon::created unlocking key 9558A0E9BC84DF0EA31B96050B31244B e:=sSV/0x33bdf10*1
2014/11/27 01:15:22.620| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.620| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33bdf10*0 into policy
2014/11/27 01:15:22.620| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/page_white_flash.png
2014/11/27 01:15:22.620| store_dir.cc(1073) get: storeGet: looking up 9558A0E9BC84DF0EA31B96050B31244B
2014/11/27 01:15:22.620| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33bdf10*0
2014/11/27 01:15:22.620| store_dir.cc(1073) get: storeGet: looking up 9CCBB9E3BABFE9FBB70719DBC551A187
2014/11/27 01:15:22.620| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338fac0*0
2014/11/27 01:15:22.620| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.620| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.620| store_dir.cc(1073) get: storeGet: looking up 9C0CC615AF155C43AECEA90B7D4E5B7F
2014/11/27 01:15:22.620| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33693c0*0
2014/11/27 01:15:22.620| store_dir.cc(1073) get: storeGet: looking up 60F84834B2AD28662096CA73C771FD43
2014/11/27 01:15:22.620| store_dir.cc(744) find: none of 0 cache_dirs have 60F84834B2AD28662096CA73C771FD43
2014/11/27 01:15:22.620| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/database_table.png
2014/11/27 01:15:22.620| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/database_table.png'
2014/11/27 01:15:22.620| MemObject.cc(97) MemObject: new MemObject 0x33bf940
2014/11/27 01:15:22.620| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33bf8d0*1
2014/11/27 01:15:22.620| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/database_table.png
2014/11/27 01:15:22.620| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33bf8d0*1 key 'F2F6B63A0A85000F5848C1A70FDF4BB4'
2014/11/27 01:15:22.620| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33bf8d0*1 key '60F84834B2AD28662096CA73C771FD43'
2014/11/27 01:15:22.620| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/database_table.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/database_table.png'
2014/11/27 01:15:22.620| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.620| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/database_table.png
2014/11/27 01:15:22.622| store_client.cc(731) invokeHandlers: InvokeHandlers: 60F84834B2AD28662096CA73C771FD43
2014/11/27 01:15:22.622| store_client.cc(731) invokeHandlers: InvokeHandlers: 60F84834B2AD28662096CA73C771FD43
2014/11/27 01:15:22.622| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/database_table.png
2014/11/27 01:15:22.622| store.cc(1028) complete: storeComplete: '60F84834B2AD28662096CA73C771FD43'
2014/11/27 01:15:22.622| store.cc(1319) validLength: storeEntryValidLength: Checking '60F84834B2AD28662096CA73C771FD43'
2014/11/27 01:15:22.622| store_client.cc(731) invokeHandlers: InvokeHandlers: 60F84834B2AD28662096CA73C771FD43
2014/11/27 01:15:22.622| store.cc(523) unlock: MimeIcon::created unlocking key 60F84834B2AD28662096CA73C771FD43 e:=sSV/0x33bf8d0*1
2014/11/27 01:15:22.622| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.622| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33bf8d0*0 into policy
2014/11/27 01:15:22.622| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/database_table.png
2014/11/27 01:15:22.622| store_dir.cc(1073) get: storeGet: looking up 60F84834B2AD28662096CA73C771FD43
2014/11/27 01:15:22.622| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33bf8d0*0
2014/11/27 01:15:22.622| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.622| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.622| store_dir.cc(1073) get: storeGet: looking up 93A5D936ED6A19E50691CD1B2FF11519
2014/11/27 01:15:22.622| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x338e190*0
2014/11/27 01:15:22.622| store_dir.cc(1073) get: storeGet: looking up 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.622| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x339a9f0*0
2014/11/27 01:15:22.622| store_dir.cc(1073) get: storeGet: looking up 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.622| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x339a9f0*0
2014/11/27 01:15:22.623| store_dir.cc(1073) get: storeGet: looking up 19C41E4F777D19FFA38C31FC3FE11777
2014/11/27 01:15:22.623| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x339a9f0*0
2014/11/27 01:15:22.623| store_dir.cc(1073) get: storeGet: looking up CD30DD801AB5085E83CBF794C2F3F419
2014/11/27 01:15:22.623| store_dir.cc(744) find: none of 0 cache_dirs have CD30DD801AB5085E83CBF794C2F3F419
2014/11/27 01:15:22.623| fd.cc(198) fd_open: fd_open() FD 24 /opt/squid/share/icons/silk/layout.png
2014/11/27 01:15:22.623| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://local.local:3128/squid-internal-static/icons/silk/layout.png'
2014/11/27 01:15:22.623| MemObject.cc(97) MemObject: new MemObject 0x33c12d0
2014/11/27 01:15:22.623| store.cc(485) lock: storeCreateEntry locked key [null_store_key] e:=V/0x33c1260*1
2014/11/27 01:15:22.623| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://local.local:3128/squid-internal-static/icons/silk/layout.png
2014/11/27 01:15:22.623| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x33c1260*1 key '5DFD93303E6B4C4B6D4B71832026D82C'
2014/11/27 01:15:22.623| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=SV/0x33c1260*1 key 'CD30DD801AB5085E83CBF794C2F3F419'
2014/11/27 01:15:22.623| url.cc(357) urlParse: urlParse: Split URL 'http://local.local:3128/squid-internal-static/icons/silk/layout.png' into proto='http', host='local.local', port='3128', path='/squid-internal-static/icons/silk/layout.png'
2014/11/27 01:15:22.623| Address.cc(379) lookupHostIP: Given Non-IP 'local.local': Name or service not known
2014/11/27 01:15:22.623| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://local.local:3128/squid-internal-static/icons/silk/layout.png
2014/11/27 01:15:22.625| store_client.cc(731) invokeHandlers: InvokeHandlers: CD30DD801AB5085E83CBF794C2F3F419
2014/11/27 01:15:22.625| store_client.cc(731) invokeHandlers: InvokeHandlers: CD30DD801AB5085E83CBF794C2F3F419
2014/11/27 01:15:22.625| fd.cc(93) fd_close: fd_close FD 24 /opt/squid/share/icons/silk/layout.png
2014/11/27 01:15:22.625| store.cc(1028) complete: storeComplete: 'CD30DD801AB5085E83CBF794C2F3F419'
2014/11/27 01:15:22.625| store.cc(1319) validLength: storeEntryValidLength: Checking 'CD30DD801AB5085E83CBF794C2F3F419'
2014/11/27 01:15:22.625| store_client.cc(731) invokeHandlers: InvokeHandlers: CD30DD801AB5085E83CBF794C2F3F419
2014/11/27 01:15:22.625| store.cc(523) unlock: MimeIcon::created unlocking key CD30DD801AB5085E83CBF794C2F3F419 e:=sSV/0x33c1260*1
2014/11/27 01:15:22.625| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:22.625| store.cc(1647) setMemStatus: not inserting special e:=sSV/0x33c1260*0 into policy
2014/11/27 01:15:22.625| mime.cc(423) created: Loaded icon http://local.local:3128/squid-internal-static/icons/silk/layout.png
2014/11/27 01:15:22.625| store_dir.cc(1073) get: storeGet: looking up FF3B1B5F182673F33B578D9B9C9E75C4
2014/11/27 01:15:22.625| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33b9200*0
2014/11/27 01:15:22.625| store_dir.cc(1073) get: storeGet: looking up 4226A0233E563AAFAECC8B1C7F522696
2014/11/27 01:15:22.625| store_dir.cc(697) find: got in-transit entry: e:=msSV/0x33820e0*0
2014/11/27 01:15:22.625| Finished loading MIME types and icons.
2014/11/27 01:15:22.625| cache_manager.cc(80) registerProfile: registering legacy refresh
2014/11/27 01:15:22.625| cache_manager.cc(65) registerProfile: registered profile: refresh
2014/11/27 01:15:22.625| cache_manager.cc(80) registerProfile: registering legacy forward
2014/11/27 01:15:22.625| cache_manager.cc(65) registerProfile: registered profile: forward
2014/11/27 01:15:22.625| cache_manager.cc(80) registerProfile: registering legacy cbdata
2014/11/27 01:15:22.625| cache_manager.cc(65) registerProfile: registered profile: cbdata
2014/11/27 01:15:22.625| cache_manager.cc(80) registerProfile: registering legacy events
2014/11/27 01:15:22.625| cache_manager.cc(65) registerProfile: registered profile: events
2014/11/27 01:15:22.625| wccp.cc(112) wccpConnectionOpen: WCCPv1 disabled.
2014/11/27 01:15:22.625| wccp2.cc(960) wccp2ConnectionOpen: WCCPv2 Disabled. No IPv4 Router(s) configured.
2014/11/27 01:15:22.625| AsyncCall.cc(26) AsyncCall: The AsyncCall clientListenerConnectionOpened constructed, this=0x33c3150 [call18]
2014/11/27 01:15:22.625| tools.cc(610) enter_suid: enter_suid: PID 16232 taking root privileges
2014/11/27 01:15:22.625| comm.cc(342) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0:3128
2014/11/27 01:15:22.625| comm.cc(383) comm_openex: comm_openex: Opened socket local=0.0.0.0:3128 remote=[::] FD 24 flags=1 : family=2, type=1, protocol=6
2014/11/27 01:15:22.625| fd.cc(198) fd_open: fd_open() FD 24 HTTP Socket
2014/11/27 01:15:22.625| tools.cc(543) leave_suid: leave_suid: PID 16232 called
2014/11/27 01:15:22.625| tools.cc(565) leave_suid: leave_suid: PID 16232 giving up root, becoming 'nobody'
2014/11/27 01:15:22.625| StartListening.cc(58) StartListening: opened listen local=0.0.0.0:3128 remote=[::] FD 24 flags=9
2014/11/27 01:15:22.625| AsyncCall.cc(93) ScheduleCall: StartListening.cc(59) will call clientListenerConnectionOpened(local=0.0.0.0:3128 remote=[::] FD 24 flags=9, err=0, HTTP Socket port=0x33c31b0) [call18]
2014/11/27 01:15:22.625| AsyncCall.cc(26) AsyncCall: The AsyncCall clientListenerConnectionOpened constructed, this=0x33c3320 [call20]
2014/11/27 01:15:22.625| tools.cc(610) enter_suid: enter_suid: PID 16232 taking root privileges
2014/11/27 01:15:22.625| comm.cc(342) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0:3131
2014/11/27 01:15:22.625| comm.cc(383) comm_openex: comm_openex: Opened socket local=0.0.0.0:3131 remote=[::] FD 25 flags=1 : family=2, type=1, protocol=6
2014/11/27 01:15:22.625| fd.cc(198) fd_open: fd_open() FD 25 HTTP Socket
2014/11/27 01:15:22.625| tools.cc(543) leave_suid: leave_suid: PID 16232 called
2014/11/27 01:15:22.625| tools.cc(565) leave_suid: leave_suid: PID 16232 giving up root, becoming 'nobody'
2014/11/27 01:15:22.626| StartListening.cc(58) StartListening: opened listen local=0.0.0.0:3131 remote=[::] FD 25 flags=41
2014/11/27 01:15:22.626| AsyncCall.cc(93) ScheduleCall: StartListening.cc(59) will call clientListenerConnectionOpened(local=0.0.0.0:3131 remote=[::] FD 25 flags=41, err=0, HTTP Socket port=0x33c3380) [call20]
2014/11/27 01:15:22.626| AsyncCall.cc(26) AsyncCall: The AsyncCall clientListenerConnectionOpened constructed, this=0x33c35c0 [call22]
2014/11/27 01:15:22.626| tools.cc(610) enter_suid: enter_suid: PID 16232 taking root privileges
2014/11/27 01:15:22.626| comm.cc(342) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0:3132
2014/11/27 01:15:22.626| comm.cc(383) comm_openex: comm_openex: Opened socket local=0.0.0.0:3132 remote=[::] FD 26 flags=1 : family=2, type=1, protocol=6
2014/11/27 01:15:22.626| fd.cc(198) fd_open: fd_open() FD 26 HTTPS Socket
2014/11/27 01:15:22.626| tools.cc(543) leave_suid: leave_suid: PID 16232 called
2014/11/27 01:15:22.626| tools.cc(565) leave_suid: leave_suid: PID 16232 giving up root, becoming 'nobody'
2014/11/27 01:15:22.626| StartListening.cc(58) StartListening: opened listen local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:22.626| AsyncCall.cc(93) ScheduleCall: StartListening.cc(59) will call clientListenerConnectionOpened(local=0.0.0.0:3132 remote=[::] FD 26 flags=41, err=0, HTTPS Socket port=0x33c3620) [call22]
2014/11/27 01:15:22.626| HTCP Disabled.
2014/11/27 01:15:22.626| cache_manager.cc(80) registerProfile: registering legacy asndb
2014/11/27 01:15:22.626| cache_manager.cc(65) registerProfile: registered profile: asndb
2014/11/27 01:15:22.626| Acl.cc(450) Initialize: ACL::Initialize
2014/11/27 01:15:22.626| cache_manager.cc(80) registerProfile: registering legacy carp
2014/11/27 01:15:22.626| cache_manager.cc(65) registerProfile: registered profile: carp
2014/11/27 01:15:22.626| cache_manager.cc(80) registerProfile: registering legacy userhash
2014/11/27 01:15:22.626| cache_manager.cc(65) registerProfile: registered profile: userhash
2014/11/27 01:15:22.626| cache_manager.cc(80) registerProfile: registering legacy sourcehash
2014/11/27 01:15:22.626| cache_manager.cc(65) registerProfile: registered profile: sourcehash
2014/11/27 01:15:22.626| cache_manager.cc(80) registerProfile: registering legacy server_list
2014/11/27 01:15:22.626| cache_manager.cc(65) registerProfile: registered profile: server_list
2014/11/27 01:15:22.626| tools.cc(610) enter_suid: enter_suid: PID 16232 taking root privileges
2014/11/27 01:15:22.626| fd.cc(198) fd_open: fd_open() FD 27 /opt/squid/var/run/squid.pid
2014/11/27 01:15:22.626| tools.cc(543) leave_suid: leave_suid: PID 16232 called
2014/11/27 01:15:22.626| tools.cc(565) leave_suid: leave_suid: PID 16232 giving up root, becoming 'nobody'
2014/11/27 01:15:22.626| fd.cc(93) fd_close: fd_close FD 27 /opt/squid/var/run/squid.pid
2014/11/27 01:15:22.626| Squid plugin modules loaded: 0
2014/11/27 01:15:22.626| Config.cc(122) clear: rules: 0, groups: 0, services: 0
2014/11/27 01:15:22.626| Config.cc(129) clear: rules: 0, groups: 0, services: 0
2014/11/27 01:15:22.626| Adaptation support is off.
2014/11/27 01:15:22.626| Config.cc(211) FinalizeEach: Initialized 0 message adaptation services
2014/11/27 01:15:22.626| Config.cc(211) FinalizeEach: Initialized 0 message adaptation service groups
2014/11/27 01:15:22.626| Config.cc(211) FinalizeEach: Initialized 0 message adaptation access rules
2014/11/27 01:15:22.626| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 12)
2014/11/27 01:15:22.626| AsyncCall.cc(38) make: make call comm_close_complete [call1]
2014/11/27 01:15:22.626| fd.cc(93) fd_close: fd_close FD 12 IPC UNIX STREAM Parent
2014/11/27 01:15:22.626| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 12)
2014/11/27 01:15:22.626| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 14)
2014/11/27 01:15:22.626| AsyncCall.cc(38) make: make call comm_close_complete [call4]
2014/11/27 01:15:22.626| fd.cc(93) fd_close: fd_close FD 14 IPC UNIX STREAM Parent
2014/11/27 01:15:22.626| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 14)
2014/11/27 01:15:22.626| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 16)
2014/11/27 01:15:22.626| AsyncCall.cc(38) make: make call comm_close_complete [call7]
2014/11/27 01:15:22.626| fd.cc(93) fd_close: fd_close FD 16 IPC UNIX STREAM Parent
2014/11/27 01:15:22.626| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 16)
2014/11/27 01:15:22.626| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 18)
2014/11/27 01:15:22.626| AsyncCall.cc(38) make: make call comm_close_complete [call10]
2014/11/27 01:15:22.626| fd.cc(93) fd_close: fd_close FD 18 IPC UNIX STREAM Parent
2014/11/27 01:15:22.626| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 18)
2014/11/27 01:15:22.627| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 20)
2014/11/27 01:15:22.627| AsyncCall.cc(38) make: make call comm_close_complete [call13]
2014/11/27 01:15:22.627| fd.cc(93) fd_close: fd_close FD 20 IPC UNIX STREAM Parent
2014/11/27 01:15:22.627| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 20)
2014/11/27 01:15:22.627| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 23)
2014/11/27 01:15:22.627| AsyncCall.cc(38) make: make call comm_close_complete [call16]
2014/11/27 01:15:22.627| fd.cc(93) fd_close: fd_close FD 23 IPC UNIX STREAM Parent
2014/11/27 01:15:22.627| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 23)
2014/11/27 01:15:22.627| AsyncCallQueue.cc(55) fireNext: entering clientListenerConnectionOpened(local=0.0.0.0:3128 remote=[::] FD 24 flags=9, err=0, HTTP Socket port=0x33c31b0)
2014/11/27 01:15:22.627| AsyncCall.cc(38) make: make call clientListenerConnectionOpened [call18]
2014/11/27 01:15:22.627| Accepting SSL bumped HTTP Socket connections at local=0.0.0.0:3128 remote=[::] FD 24 flags=9
2014/11/27 01:15:22.627| AsyncCallQueue.cc(57) fireNext: leaving clientListenerConnectionOpened(local=0.0.0.0:3128 remote=[::] FD 24 flags=9, err=0, HTTP Socket port=0x33c31b0)
2014/11/27 01:15:22.627| AsyncCallQueue.cc(55) fireNext: entering clientListenerConnectionOpened(local=0.0.0.0:3131 remote=[::] FD 25 flags=41, err=0, HTTP Socket port=0x33c3380)
2014/11/27 01:15:22.627| AsyncCall.cc(38) make: make call clientListenerConnectionOpened [call20]
2014/11/27 01:15:22.627| Accepting NAT intercepted HTTP Socket connections at local=0.0.0.0:3131 remote=[::] FD 25 flags=41
2014/11/27 01:15:22.627| AsyncCallQueue.cc(57) fireNext: leaving clientListenerConnectionOpened(local=0.0.0.0:3131 remote=[::] FD 25 flags=41, err=0, HTTP Socket port=0x33c3380)
2014/11/27 01:15:22.627| AsyncCallQueue.cc(55) fireNext: entering clientListenerConnectionOpened(local=0.0.0.0:3132 remote=[::] FD 26 flags=41, err=0, HTTPS Socket port=0x33c3620)
2014/11/27 01:15:22.627| AsyncCall.cc(38) make: make call clientListenerConnectionOpened [call22]
2014/11/27 01:15:22.627| Accepting NAT intercepted SSL bumped HTTPS Socket connections at local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:22.627| AsyncCallQueue.cc(57) fireNext: leaving clientListenerConnectionOpened(local=0.0.0.0:3132 remote=[::] FD 26 flags=41, err=0, HTTPS Socket port=0x33c3620)
2014/11/27 01:15:22.627| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::TcpAcceptor::handleClosure constructed, this=0x33c35c0 [call26]
2014/11/27 01:15:22.627| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::TcpAcceptor::handleClosure constructed, this=0x33c4810 [call27]
2014/11/27 01:15:22.628| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::TcpAcceptor::handleClosure constructed, this=0x33c48a0 [call28]
2014/11/27 01:15:22.850| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:22.850| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:22.850| fd.cc(198) fd_open: fd_open() FD 12 HTTP Request
2014/11/27 01:15:22.850| Eui48.cc(178) lookup: id=0x33c3774 query ARP table
2014/11/27 01:15:22.850| Eui48.cc(221) lookup: id=0x33c3774 query ARP on each interface (80 found)
2014/11/27 01:15:22.850| Eui48.cc(227) lookup: id=0x33c3774 found interface lo
2014/11/27 01:15:22.850| Eui48.cc(227) lookup: id=0x33c3774 found interface br0
2014/11/27 01:15:22.850| Eui48.cc(236) lookup: id=0x33c3774 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:22.850| Eui48.cc(279) lookup: id=0x33c3774 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:22.851| client_side.cc(3889) httpsAccept: local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:22.851| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '192.168.0.122'.
2014/11/27 01:15:22.851| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 192.168.0.122, id = 0x97a
2014/11/27 01:15:22.851| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:22.851| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.77.232
2014/11/27 01:15:22.851| Checklist.cc(68) preCheck: 0x33c85a8 checking slow rules
2014/11/27 01:15:22.851| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:22.851| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:22.851| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.77.232'
2014/11/27 01:15:22.851| DomainData.cc(110) match: aclMatchDomainList: '212.42.77.232' NOT found
2014/11/27 01:15:22.851| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.77.232' == 212.42.77.232
2014/11/27 01:15:22.851| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.77.232'.
2014/11/27 01:15:22.851| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.77.232, id = 0x69ba
2014/11/27 01:15:22.851| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:22.851| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.77.232'
2014/11/27 01:15:22.851| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.77.232'.
2014/11/27 01:15:22.851| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.77.232, id = 0x9362
2014/11/27 01:15:22.851| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:22.851| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:22.851| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:22.851| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:22.914| dns_internal.cc(1281) idnsRead: idnsRead: starting with FD 10
2014/11/27 01:15:22.914| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:22.914| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x9362, 1 answers
2014/11/27 01:15:22.914| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.77.232'
2014/11/27 01:15:22.914| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.77.232'
2014/11/27 01:15:22.914| DomainData.cc(110) match: aclMatchDomainList: '212.42.77.232' NOT found
2014/11/27 01:15:22.914| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.77.232' == 212.42.77.232
2014/11/27 01:15:22.914| DomainData.cc(106) match: aclMatchDomainList: checking 'frv232.fwdcdn.com'
2014/11/27 01:15:22.914| DomainData.cc(110) match: aclMatchDomainList: 'frv232.fwdcdn.com' NOT found
2014/11/27 01:15:22.914| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:22.914| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:22.914| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62948' found
2014/11/27 01:15:22.914| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:22.914| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:22.914| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:22.914| Checklist.cc(61) markFinished: 0x33c85a8 answer ALLOWED for match
2014/11/27 01:15:22.914| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x33c85a8 answer=ALLOWED
2014/11/27 01:15:22.914| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33 method 5
2014/11/27 01:15:22.915| comm.cc(548) commSetConnTimeout: local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33 timeout 300
2014/11/27 01:15:22.915| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.77.232
2014/11/27 01:15:22.915| client_side.cc(3827) httpsEstablish: local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:22.915| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x33c85a8
2014/11/27 01:15:22.915| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x33c85a8
2014/11/27 01:15:22.915| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 44 bytes from 8.8.8.8:53
2014/11/27 01:15:22.915| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x97a, -3 answers
2014/11/27 01:15:22.915| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:22.915| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '192.168.0.122' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:22.915| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:22.915| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x69ba, 1 answers
2014/11/27 01:15:22.915| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.77.232'
2014/11/27 01:15:22.915| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 11 flags=1 (0, 0)
2014/11/27 01:15:22.918| Read.cc(143) HandleRead: FD 11, size 4095, retval 1690, errno 0
2014/11/27 01:15:22.918| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 11 flags=1 (0, 0)
2014/11/27 01:15:22.918| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350) [call3]
2014/11/27 01:15:22.918| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350)
2014/11/27 01:15:22.918| AsyncCall.cc(38) make: make call helperHandleRead [call3]
2014/11/27 01:15:22.918| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:22.918| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:22.918| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:22.918| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:22.925| comm.cc(548) commSetConnTimeout: local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33 timeout 300
2014/11/27 01:15:22.925| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x33c5b20 [call35]
2014/11/27 01:15:22.925| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350)
2014/11/27 01:15:22.930| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x33d0510 on FD 12 (192.168.0.122:62948)
2014/11/27 01:15:22.930| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 12 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:22.930| client_side.cc(234) readSomeData: local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33: reading request...
2014/11/27 01:15:22.932| IoCallback.cc(116) finish: called for local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33 (0, 0)
2014/11/27 01:15:22.932| Read.cc(91) ReadNow: local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:22.932| client_side.cc(2372) connFinishedWithConn: local=212.42.77.232:443 remote=192.168.0.122:62948 FD 12 flags=33 closed
2014/11/27 01:15:22.932| comm.cc(860) _comm_close: comm_close: start closing FD 12
2014/11/27 01:15:22.932| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x34d0e10 [call37]
2014/11/27 01:15:22.932| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 12) [call37]
2014/11/27 01:15:22.932| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 12
2014/11/27 01:15:22.932| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2f71c40 [call38]
2014/11/27 01:15:22.932| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 12) [call38]
2014/11/27 01:15:22.933| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 12)
2014/11/27 01:15:22.933| AsyncCall.cc(38) make: make call commStartSslClose [call37]
2014/11/27 01:15:22.933| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 12)
2014/11/27 01:15:22.933| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:22.933| client_side.cc(817) swanSong: local=212.42.77.232:443 remote=192.168.0.122:62948 flags=33
2014/11/27 01:15:22.933| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:22.933| client_side.cc(848) ~ConnStateData: local=212.42.77.232:443 remote=192.168.0.122:62948 flags=33
2014/11/27 01:15:22.933| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 12)
2014/11/27 01:15:22.933| AsyncCall.cc(38) make: make call comm_close_complete [call38]
2014/11/27 01:15:22.933| fd.cc(93) fd_close: fd_close FD 12 client https start
2014/11/27 01:15:22.933| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 12)
2014/11/27 01:15:23.100| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.100| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.100| fd.cc(198) fd_open: fd_open() FD 12 HTTP Request
2014/11/27 01:15:23.100| Eui48.cc(178) lookup: id=0x33c3774 query ARP table
2014/11/27 01:15:23.100| Eui48.cc(221) lookup: id=0x33c3774 query ARP on each interface (80 found)
2014/11/27 01:15:23.100| Eui48.cc(227) lookup: id=0x33c3774 found interface lo
2014/11/27 01:15:23.100| Eui48.cc(227) lookup: id=0x33c3774 found interface br0
2014/11/27 01:15:23.100| Eui48.cc(236) lookup: id=0x33c3774 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.100| Eui48.cc(279) lookup: id=0x33c3774 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.100| client_side.cc(3889) httpsAccept: local=212.42.77.232:443 remote=192.168.0.122:62949 FD 12 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.100| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.77.232
2014/11/27 01:15:23.100| Checklist.cc(68) preCheck: 0x33c85a8 checking slow rules
2014/11/27 01:15:23.100| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.100| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.100| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.77.232'
2014/11/27 01:15:23.100| DomainData.cc(110) match: aclMatchDomainList: '212.42.77.232' NOT found
2014/11/27 01:15:23.100| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.77.232' == 212.42.77.232
2014/11/27 01:15:23.100| DomainData.cc(106) match: aclMatchDomainList: checking 'frv232.fwdcdn.com'
2014/11/27 01:15:23.100| DomainData.cc(110) match: aclMatchDomainList: 'frv232.fwdcdn.com' NOT found
2014/11/27 01:15:23.100| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.100| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.100| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62949' found
2014/11/27 01:15:23.100| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.100| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.100| Acl.cc(156) matches: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.100| Checklist.cc(61) markFinished: 0x33c85a8 answer ALLOWED for match
2014/11/27 01:15:23.100| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x33c85a8 answer=ALLOWED
2014/11/27 01:15:23.100| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.77.232:443 remote=192.168.0.122:62949 FD 12 flags=33 method 5
2014/11/27 01:15:23.101| comm.cc(548) commSetConnTimeout: local=212.42.77.232:443 remote=192.168.0.122:62949 FD 12 flags=33 timeout 300
2014/11/27 01:15:23.101| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.77.232
2014/11/27 01:15:23.101| client_side.cc(3827) httpsEstablish: local=212.42.77.232:443 remote=192.168.0.122:62949 FD 12 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.101| comm.cc(548) commSetConnTimeout: local=212.42.77.232:443 remote=192.168.0.122:62949 FD 12 flags=33 timeout 300
2014/11/27 01:15:23.101| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x33c85a8
2014/11/27 01:15:23.101| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x33c85a8
2014/11/27 01:15:23.490| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/opt/squid/var/logs/access.log: appending 2 bytes
2014/11/27 01:15:23.490| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 7 of 32768 bytes before append
2014/11/27 01:15:23.490| ModDaemon.cc(108) logfileHandleWrite: daemon:/opt/squid/var/logs/access.log: write returned 9
2014/11/27 01:15:23.490| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.490| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.491| fd.cc(198) fd_open: fd_open() FD 14 HTTP Request
2014/11/27 01:15:23.491| Eui48.cc(178) lookup: id=0x33d0844 query ARP table
2014/11/27 01:15:23.491| Eui48.cc(221) lookup: id=0x33d0844 query ARP on each interface (80 found)
2014/11/27 01:15:23.491| Eui48.cc(227) lookup: id=0x33d0844 found interface lo
2014/11/27 01:15:23.491| Eui48.cc(227) lookup: id=0x33d0844 found interface br0
2014/11/27 01:15:23.491| Eui48.cc(236) lookup: id=0x33d0844 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.491| Eui48.cc(279) lookup: id=0x33d0844 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.491| client_side.cc(3889) httpsAccept: local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.491| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:23.491| Checklist.cc(68) preCheck: 0x33c85a8 checking slow rules
2014/11/27 01:15:23.491| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.491| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.491| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:23.491| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:23.491| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:23.491| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.253'.
2014/11/27 01:15:23.491| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.253, id = 0x2631
2014/11/27 01:15:23.491| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.491| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.253'
2014/11/27 01:15:23.491| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.253'.
2014/11/27 01:15:23.491| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.253, id = 0x38b8
2014/11/27 01:15:23.491| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.491| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.491| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.491| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.492| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.492| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.492| fd.cc(198) fd_open: fd_open() FD 16 HTTP Request
2014/11/27 01:15:23.492| Eui48.cc(178) lookup: id=0x33d1b54 query ARP table
2014/11/27 01:15:23.492| Eui48.cc(221) lookup: id=0x33d1b54 query ARP on each interface (80 found)
2014/11/27 01:15:23.492| Eui48.cc(227) lookup: id=0x33d1b54 found interface lo
2014/11/27 01:15:23.492| Eui48.cc(227) lookup: id=0x33d1b54 found interface br0
2014/11/27 01:15:23.492| Eui48.cc(236) lookup: id=0x33d1b54 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.492| Eui48.cc(279) lookup: id=0x33d1b54 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.492| client_side.cc(3889) httpsAccept: local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.492| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:23.492| Checklist.cc(68) preCheck: 0x3498f18 checking slow rules
2014/11/27 01:15:23.492| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.492| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.492| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:23.492| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:23.492| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:23.492| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.253'.
2014/11/27 01:15:23.492| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.253, id = 0xbe07
2014/11/27 01:15:23.492| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.492| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.253'
2014/11/27 01:15:23.492| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.253'.
2014/11/27 01:15:23.492| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.253, id = 0x9242
2014/11/27 01:15:23.493| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.493| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.493| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.493| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.493| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.493| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.493| fd.cc(198) fd_open: fd_open() FD 18 HTTP Request
2014/11/27 01:15:23.493| Eui48.cc(178) lookup: id=0x34d0384 query ARP table
2014/11/27 01:15:23.493| Eui48.cc(221) lookup: id=0x34d0384 query ARP on each interface (80 found)
2014/11/27 01:15:23.493| Eui48.cc(227) lookup: id=0x34d0384 found interface lo
2014/11/27 01:15:23.493| Eui48.cc(227) lookup: id=0x34d0384 found interface br0
2014/11/27 01:15:23.493| Eui48.cc(236) lookup: id=0x34d0384 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.493| Eui48.cc(279) lookup: id=0x34d0384 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.493| client_side.cc(3889) httpsAccept: local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.493| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:23.493| Checklist.cc(68) preCheck: 0x34d0c78 checking slow rules
2014/11/27 01:15:23.493| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.493| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.493| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:23.493| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:23.493| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:23.493| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.253'.
2014/11/27 01:15:23.493| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.253, id = 0xfa45
2014/11/27 01:15:23.493| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.494| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.253'
2014/11/27 01:15:23.494| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.253'.
2014/11/27 01:15:23.494| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.253, id = 0xf90a
2014/11/27 01:15:23.494| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.494| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.494| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.494| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.494| storeLateRelease: released 0 objects
2014/11/27 01:15:23.494| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.494| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.494| fd.cc(198) fd_open: fd_open() FD 20 HTTP Request
2014/11/27 01:15:23.494| Eui48.cc(178) lookup: id=0x34d1024 query ARP table
2014/11/27 01:15:23.494| Eui48.cc(221) lookup: id=0x34d1024 query ARP on each interface (80 found)
2014/11/27 01:15:23.494| Eui48.cc(227) lookup: id=0x34d1024 found interface lo
2014/11/27 01:15:23.494| Eui48.cc(227) lookup: id=0x34d1024 found interface br0
2014/11/27 01:15:23.494| Eui48.cc(236) lookup: id=0x34d1024 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.494| Eui48.cc(279) lookup: id=0x34d1024 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.494| client_side.cc(3889) httpsAccept: local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.494| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:23.494| Checklist.cc(68) preCheck: 0x33ced08 checking slow rules
2014/11/27 01:15:23.494| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.494| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.495| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:23.495| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:23.495| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:23.495| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.253'.
2014/11/27 01:15:23.495| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.253, id = 0xf845
2014/11/27 01:15:23.495| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.495| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.253'
2014/11/27 01:15:23.495| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.253'.
2014/11/27 01:15:23.495| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.253, id = 0x112c
2014/11/27 01:15:23.495| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.495| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.495| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.495| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.495| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.495| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.495| fd.cc(198) fd_open: fd_open() FD 23 HTTP Request
2014/11/27 01:15:23.495| Eui48.cc(178) lookup: id=0x33cf004 query ARP table
2014/11/27 01:15:23.495| Eui48.cc(221) lookup: id=0x33cf004 query ARP on each interface (80 found)
2014/11/27 01:15:23.495| Eui48.cc(227) lookup: id=0x33cf004 found interface lo
2014/11/27 01:15:23.495| Eui48.cc(227) lookup: id=0x33cf004 found interface br0
2014/11/27 01:15:23.495| Eui48.cc(236) lookup: id=0x33cf004 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.495| Eui48.cc(279) lookup: id=0x33cf004 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.495| client_side.cc(3889) httpsAccept: local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.495| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.191.234.34
2014/11/27 01:15:23.495| Checklist.cc(68) preCheck: 0x33cf598 checking slow rules
2014/11/27 01:15:23.496| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.496| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.496| DomainData.cc(106) match: aclMatchDomainList: checking '195.191.234.34'
2014/11/27 01:15:23.496| DomainData.cc(110) match: aclMatchDomainList: '195.191.234.34' NOT found
2014/11/27 01:15:23.496| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.191.234.34' == 195.191.234.34
2014/11/27 01:15:23.496| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.191.234.34'.
2014/11/27 01:15:23.496| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.191.234.34, id = 0xfd91
2014/11/27 01:15:23.496| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.496| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '195.191.234.34'
2014/11/27 01:15:23.496| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.191.234.34'.
2014/11/27 01:15:23.496| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.191.234.34, id = 0xec7d
2014/11/27 01:15:23.496| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.496| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.496| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.496| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.496| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.496| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.496| fd.cc(198) fd_open: fd_open() FD 27 HTTP Request
2014/11/27 01:15:23.496| Eui48.cc(178) lookup: id=0x33cf974 query ARP table
2014/11/27 01:15:23.496| Eui48.cc(221) lookup: id=0x33cf974 query ARP on each interface (80 found)
2014/11/27 01:15:23.496| Eui48.cc(227) lookup: id=0x33cf974 found interface lo
2014/11/27 01:15:23.496| Eui48.cc(227) lookup: id=0x33cf974 found interface br0
2014/11/27 01:15:23.496| Eui48.cc(236) lookup: id=0x33cf974 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.496| Eui48.cc(279) lookup: id=0x33cf974 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.496| client_side.cc(3889) httpsAccept: local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.497| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.191.234.34
2014/11/27 01:15:23.497| Checklist.cc(68) preCheck: 0x2fa8998 checking slow rules
2014/11/27 01:15:23.497| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.497| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.497| DomainData.cc(106) match: aclMatchDomainList: checking '195.191.234.34'
2014/11/27 01:15:23.497| DomainData.cc(110) match: aclMatchDomainList: '195.191.234.34' NOT found
2014/11/27 01:15:23.497| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.191.234.34' == 195.191.234.34
2014/11/27 01:15:23.497| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.191.234.34'.
2014/11/27 01:15:23.497| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.191.234.34, id = 0x3062
2014/11/27 01:15:23.497| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.497| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '195.191.234.34'
2014/11/27 01:15:23.497| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.191.234.34'.
2014/11/27 01:15:23.497| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.191.234.34, id = 0xc2f0
2014/11/27 01:15:23.497| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.497| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.497| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.497| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.497| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.497| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.497| fd.cc(198) fd_open: fd_open() FD 28 HTTP Request
2014/11/27 01:15:23.497| Eui48.cc(178) lookup: id=0x2fa8c94 query ARP table
2014/11/27 01:15:23.497| Eui48.cc(221) lookup: id=0x2fa8c94 query ARP on each interface (80 found)
2014/11/27 01:15:23.497| Eui48.cc(227) lookup: id=0x2fa8c94 found interface lo
2014/11/27 01:15:23.497| Eui48.cc(227) lookup: id=0x2fa8c94 found interface br0
2014/11/27 01:15:23.497| Eui48.cc(236) lookup: id=0x2fa8c94 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.497| Eui48.cc(279) lookup: id=0x2fa8c94 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.497| client_side.cc(3889) httpsAccept: local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.498| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.193.51
2014/11/27 01:15:23.498| Checklist.cc(68) preCheck: 0x34ce718 checking slow rules
2014/11/27 01:15:23.498| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.498| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.498| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.193.51'
2014/11/27 01:15:23.498| DomainData.cc(110) match: aclMatchDomainList: '195.214.193.51' NOT found
2014/11/27 01:15:23.498| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.193.51' == 195.214.193.51
2014/11/27 01:15:23.498| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.193.51'.
2014/11/27 01:15:23.498| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.214.193.51, id = 0x4b0
2014/11/27 01:15:23.498| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.498| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '195.214.193.51'
2014/11/27 01:15:23.498| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.193.51'.
2014/11/27 01:15:23.498| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.214.193.51, id = 0xc68b
2014/11/27 01:15:23.498| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.498| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.498| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.498| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.498| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.498| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.498| fd.cc(198) fd_open: fd_open() FD 29 HTTP Request
2014/11/27 01:15:23.498| Eui48.cc(178) lookup: id=0x34ced84 query ARP table
2014/11/27 01:15:23.498| Eui48.cc(221) lookup: id=0x34ced84 query ARP on each interface (80 found)
2014/11/27 01:15:23.498| Eui48.cc(227) lookup: id=0x34ced84 found interface lo
2014/11/27 01:15:23.498| Eui48.cc(227) lookup: id=0x34ced84 found interface br0
2014/11/27 01:15:23.498| Eui48.cc(236) lookup: id=0x34ced84 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.498| Eui48.cc(279) lookup: id=0x34ced84 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.498| client_side.cc(3889) httpsAccept: local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.499| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.193.51
2014/11/27 01:15:23.499| Checklist.cc(68) preCheck: 0x34cf718 checking slow rules
2014/11/27 01:15:23.499| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.499| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.499| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.193.51'
2014/11/27 01:15:23.499| DomainData.cc(110) match: aclMatchDomainList: '195.214.193.51' NOT found
2014/11/27 01:15:23.499| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.193.51' == 195.214.193.51
2014/11/27 01:15:23.499| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.193.51'.
2014/11/27 01:15:23.499| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.214.193.51, id = 0xe3bd
2014/11/27 01:15:23.499| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.499| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '195.214.193.51'
2014/11/27 01:15:23.499| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.193.51'.
2014/11/27 01:15:23.499| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.214.193.51, id = 0xf8a
2014/11/27 01:15:23.499| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.499| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.499| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.499| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.499| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.499| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.499| fd.cc(198) fd_open: fd_open() FD 30 HTTP Request
2014/11/27 01:15:23.499| Eui48.cc(178) lookup: id=0x34cfd84 query ARP table
2014/11/27 01:15:23.499| Eui48.cc(221) lookup: id=0x34cfd84 query ARP on each interface (80 found)
2014/11/27 01:15:23.499| Eui48.cc(227) lookup: id=0x34cfd84 found interface lo
2014/11/27 01:15:23.499| Eui48.cc(227) lookup: id=0x34cfd84 found interface br0
2014/11/27 01:15:23.499| Eui48.cc(236) lookup: id=0x34cfd84 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.499| Eui48.cc(279) lookup: id=0x34cfd84 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.499| client_side.cc(3889) httpsAccept: local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.500| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.77.249
2014/11/27 01:15:23.500| Checklist.cc(68) preCheck: 0x34e6e08 checking slow rules
2014/11/27 01:15:23.500| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.500| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.500| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.77.249'
2014/11/27 01:15:23.500| DomainData.cc(110) match: aclMatchDomainList: '212.42.77.249' NOT found
2014/11/27 01:15:23.500| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.77.249' == 212.42.77.249
2014/11/27 01:15:23.500| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.77.249'.
2014/11/27 01:15:23.500| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.77.249, id = 0x7676
2014/11/27 01:15:23.500| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.500| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.77.249'
2014/11/27 01:15:23.500| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.77.249'.
2014/11/27 01:15:23.500| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.77.249, id = 0x3f80
2014/11/27 01:15:23.500| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.500| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.500| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.500| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.500| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.500| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.500| fd.cc(198) fd_open: fd_open() FD 31 HTTP Request
2014/11/27 01:15:23.500| Eui48.cc(178) lookup: id=0x34e7104 query ARP table
2014/11/27 01:15:23.500| Eui48.cc(221) lookup: id=0x34e7104 query ARP on each interface (80 found)
2014/11/27 01:15:23.500| Eui48.cc(227) lookup: id=0x34e7104 found interface lo
2014/11/27 01:15:23.500| Eui48.cc(227) lookup: id=0x34e7104 found interface br0
2014/11/27 01:15:23.500| Eui48.cc(236) lookup: id=0x34e7104 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.500| Eui48.cc(279) lookup: id=0x34e7104 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.500| client_side.cc(3889) httpsAccept: local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.501| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.77.249
2014/11/27 01:15:23.501| Checklist.cc(68) preCheck: 0x34ec188 checking slow rules
2014/11/27 01:15:23.501| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.501| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.501| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.77.249'
2014/11/27 01:15:23.501| DomainData.cc(110) match: aclMatchDomainList: '212.42.77.249' NOT found
2014/11/27 01:15:23.501| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.77.249' == 212.42.77.249
2014/11/27 01:15:23.501| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.77.249'.
2014/11/27 01:15:23.501| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.77.249, id = 0x4711
2014/11/27 01:15:23.501| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.501| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.77.249'
2014/11/27 01:15:23.501| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.77.249'.
2014/11/27 01:15:23.501| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.77.249, id = 0xde5d
2014/11/27 01:15:23.501| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.501| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.501| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.501| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.501| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.501| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.501| fd.cc(198) fd_open: fd_open() FD 32 HTTP Request
2014/11/27 01:15:23.501| Eui48.cc(178) lookup: id=0x34f0bf4 query ARP table
2014/11/27 01:15:23.501| Eui48.cc(221) lookup: id=0x34f0bf4 query ARP on each interface (80 found)
2014/11/27 01:15:23.501| Eui48.cc(227) lookup: id=0x34f0bf4 found interface lo
2014/11/27 01:15:23.501| Eui48.cc(227) lookup: id=0x34f0bf4 found interface br0
2014/11/27 01:15:23.501| Eui48.cc(236) lookup: id=0x34f0bf4 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.501| Eui48.cc(279) lookup: id=0x34f0bf4 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.501| client_side.cc(3889) httpsAccept: local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.502| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.195.101
2014/11/27 01:15:23.502| Checklist.cc(68) preCheck: 0x34f1548 checking slow rules
2014/11/27 01:15:23.502| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.502| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.502| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.195.101'
2014/11/27 01:15:23.502| DomainData.cc(110) match: aclMatchDomainList: '195.214.195.101' NOT found
2014/11/27 01:15:23.502| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.195.101' == 195.214.195.101
2014/11/27 01:15:23.502| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.195.101'.
2014/11/27 01:15:23.502| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 46 bytes for 195.214.195.101, id = 0x3203
2014/11/27 01:15:23.502| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.502| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '195.214.195.101'
2014/11/27 01:15:23.502| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.195.101'.
2014/11/27 01:15:23.502| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 46 bytes for 195.214.195.101, id = 0x40fd
2014/11/27 01:15:23.502| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.502| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.502| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.502| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.502| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.502| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.502| fd.cc(198) fd_open: fd_open() FD 33 HTTP Request
2014/11/27 01:15:23.502| Eui48.cc(178) lookup: id=0x34f5fb4 query ARP table
2014/11/27 01:15:23.502| Eui48.cc(221) lookup: id=0x34f5fb4 query ARP on each interface (80 found)
2014/11/27 01:15:23.502| Eui48.cc(227) lookup: id=0x34f5fb4 found interface lo
2014/11/27 01:15:23.502| Eui48.cc(227) lookup: id=0x34f5fb4 found interface br0
2014/11/27 01:15:23.502| Eui48.cc(236) lookup: id=0x34f5fb4 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.502| Eui48.cc(279) lookup: id=0x34f5fb4 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.502| client_side.cc(3889) httpsAccept: local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.503| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.195.101
2014/11/27 01:15:23.503| Checklist.cc(68) preCheck: 0x34f6998 checking slow rules
2014/11/27 01:15:23.503| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.503| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.503| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.195.101'
2014/11/27 01:15:23.503| DomainData.cc(110) match: aclMatchDomainList: '195.214.195.101' NOT found
2014/11/27 01:15:23.503| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.195.101' == 195.214.195.101
2014/11/27 01:15:23.503| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.195.101'.
2014/11/27 01:15:23.503| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 46 bytes for 195.214.195.101, id = 0x9a34
2014/11/27 01:15:23.503| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.503| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '195.214.195.101'
2014/11/27 01:15:23.503| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.195.101'.
2014/11/27 01:15:23.503| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 46 bytes for 195.214.195.101, id = 0x4d16
2014/11/27 01:15:23.503| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.503| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.503| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.503| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.503| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.503| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.503| fd.cc(198) fd_open: fd_open() FD 34 HTTP Request
2014/11/27 01:15:23.503| Eui48.cc(178) lookup: id=0x34fb404 query ARP table
2014/11/27 01:15:23.503| Eui48.cc(221) lookup: id=0x34fb404 query ARP on each interface (80 found)
2014/11/27 01:15:23.503| Eui48.cc(227) lookup: id=0x34fb404 found interface lo
2014/11/27 01:15:23.503| Eui48.cc(227) lookup: id=0x34fb404 found interface br0
2014/11/27 01:15:23.503| Eui48.cc(236) lookup: id=0x34fb404 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.503| Eui48.cc(279) lookup: id=0x34fb404 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.503| client_side.cc(3889) httpsAccept: local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.504| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 173.194.113.94
2014/11/27 01:15:23.504| Checklist.cc(68) preCheck: 0x34fbd58 checking slow rules
2014/11/27 01:15:23.504| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.504| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.504| DomainData.cc(106) match: aclMatchDomainList: checking '173.194.113.94'
2014/11/27 01:15:23.504| DomainData.cc(110) match: aclMatchDomainList: '173.194.113.94' NOT found
2014/11/27 01:15:23.504| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '173.194.113.94' == 173.194.113.94
2014/11/27 01:15:23.504| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '173.194.113.94'.
2014/11/27 01:15:23.504| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 173.194.113.94, id = 0x8bb7
2014/11/27 01:15:23.504| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.504| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '173.194.113.94'
2014/11/27 01:15:23.504| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '173.194.113.94'.
2014/11/27 01:15:23.504| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 173.194.113.94, id = 0x9791
2014/11/27 01:15:23.504| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.504| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.504| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.504| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.504| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.504| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.504| fd.cc(198) fd_open: fd_open() FD 35 HTTP Request
2014/11/27 01:15:23.504| Eui48.cc(178) lookup: id=0x35007c4 query ARP table
2014/11/27 01:15:23.504| Eui48.cc(221) lookup: id=0x35007c4 query ARP on each interface (80 found)
2014/11/27 01:15:23.504| Eui48.cc(227) lookup: id=0x35007c4 found interface lo
2014/11/27 01:15:23.504| Eui48.cc(227) lookup: id=0x35007c4 found interface br0
2014/11/27 01:15:23.504| Eui48.cc(236) lookup: id=0x35007c4 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.504| Eui48.cc(279) lookup: id=0x35007c4 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.504| client_side.cc(3889) httpsAccept: local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.505| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.194.27
2014/11/27 01:15:23.505| Checklist.cc(68) preCheck: 0x35011a8 checking slow rules
2014/11/27 01:15:23.505| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.505| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.505| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.194.27'
2014/11/27 01:15:23.505| DomainData.cc(110) match: aclMatchDomainList: '195.214.194.27' NOT found
2014/11/27 01:15:23.505| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.194.27' == 195.214.194.27
2014/11/27 01:15:23.505| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.194.27'.
2014/11/27 01:15:23.505| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.214.194.27, id = 0x1a5f
2014/11/27 01:15:23.505| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.505| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '195.214.194.27'
2014/11/27 01:15:23.505| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.194.27'.
2014/11/27 01:15:23.505| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.214.194.27, id = 0x1308
2014/11/27 01:15:23.505| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.505| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.505| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.505| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.505| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.505| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.505| fd.cc(198) fd_open: fd_open() FD 36 HTTP Request
2014/11/27 01:15:23.505| Eui48.cc(178) lookup: id=0x3505c14 query ARP table
2014/11/27 01:15:23.505| Eui48.cc(221) lookup: id=0x3505c14 query ARP on each interface (80 found)
2014/11/27 01:15:23.505| Eui48.cc(227) lookup: id=0x3505c14 found interface lo
2014/11/27 01:15:23.505| Eui48.cc(227) lookup: id=0x3505c14 found interface br0
2014/11/27 01:15:23.505| Eui48.cc(236) lookup: id=0x3505c14 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.505| Eui48.cc(279) lookup: id=0x3505c14 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.505| client_side.cc(3889) httpsAccept: local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.506| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.194.27
2014/11/27 01:15:23.506| Checklist.cc(68) preCheck: 0x3506568 checking slow rules
2014/11/27 01:15:23.506| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.506| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.506| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.194.27'
2014/11/27 01:15:23.506| DomainData.cc(110) match: aclMatchDomainList: '195.214.194.27' NOT found
2014/11/27 01:15:23.506| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.194.27' == 195.214.194.27
2014/11/27 01:15:23.506| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.194.27'.
2014/11/27 01:15:23.506| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.214.194.27, id = 0xa10b
2014/11/27 01:15:23.506| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.506| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '195.214.194.27'
2014/11/27 01:15:23.506| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '195.214.194.27'.
2014/11/27 01:15:23.506| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 45 bytes for 195.214.194.27, id = 0x8419
2014/11/27 01:15:23.506| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.506| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.506| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.506| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.506| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.506| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.506| fd.cc(198) fd_open: fd_open() FD 37 HTTP Request
2014/11/27 01:15:23.506| Eui48.cc(178) lookup: id=0x350afd4 query ARP table
2014/11/27 01:15:23.506| Eui48.cc(221) lookup: id=0x350afd4 query ARP on each interface (80 found)
2014/11/27 01:15:23.506| Eui48.cc(227) lookup: id=0x350afd4 found interface lo
2014/11/27 01:15:23.506| Eui48.cc(227) lookup: id=0x350afd4 found interface br0
2014/11/27 01:15:23.506| Eui48.cc(236) lookup: id=0x350afd4 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.506| Eui48.cc(279) lookup: id=0x350afd4 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.506| client_side.cc(3889) httpsAccept: local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.506| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 185.26.97.139
2014/11/27 01:15:23.507| Checklist.cc(68) preCheck: 0x350b928 checking slow rules
2014/11/27 01:15:23.507| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.507| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.507| DomainData.cc(106) match: aclMatchDomainList: checking '185.26.97.139'
2014/11/27 01:15:23.507| DomainData.cc(110) match: aclMatchDomainList: '185.26.97.139' NOT found
2014/11/27 01:15:23.507| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '185.26.97.139' == 185.26.97.139
2014/11/27 01:15:23.507| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '185.26.97.139'.
2014/11/27 01:15:23.507| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 185.26.97.139, id = 0xa66a
2014/11/27 01:15:23.507| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.507| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '185.26.97.139'
2014/11/27 01:15:23.507| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '185.26.97.139'.
2014/11/27 01:15:23.507| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 185.26.97.139, id = 0xc73c
2014/11/27 01:15:23.507| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.507| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.507| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.507| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.507| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.507| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.507| fd.cc(198) fd_open: fd_open() FD 38 HTTP Request
2014/11/27 01:15:23.507| Eui48.cc(178) lookup: id=0x3510394 query ARP table
2014/11/27 01:15:23.507| Eui48.cc(221) lookup: id=0x3510394 query ARP on each interface (80 found)
2014/11/27 01:15:23.507| Eui48.cc(227) lookup: id=0x3510394 found interface lo
2014/11/27 01:15:23.507| Eui48.cc(227) lookup: id=0x3510394 found interface br0
2014/11/27 01:15:23.507| Eui48.cc(236) lookup: id=0x3510394 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.507| Eui48.cc(279) lookup: id=0x3510394 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.507| client_side.cc(3889) httpsAccept: local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.507| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 185.26.97.139
2014/11/27 01:15:23.507| Checklist.cc(68) preCheck: 0x3510ce8 checking slow rules
2014/11/27 01:15:23.508| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.508| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.508| DomainData.cc(106) match: aclMatchDomainList: checking '185.26.97.139'
2014/11/27 01:15:23.508| DomainData.cc(110) match: aclMatchDomainList: '185.26.97.139' NOT found
2014/11/27 01:15:23.508| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '185.26.97.139' == 185.26.97.139
2014/11/27 01:15:23.508| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '185.26.97.139'.
2014/11/27 01:15:23.508| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 185.26.97.139, id = 0xbcd1
2014/11/27 01:15:23.508| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.508| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '185.26.97.139'
2014/11/27 01:15:23.508| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '185.26.97.139'.
2014/11/27 01:15:23.508| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 185.26.97.139, id = 0x6471
2014/11/27 01:15:23.508| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.508| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.508| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.508| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.508| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.508| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.508| fd.cc(198) fd_open: fd_open() FD 39 HTTP Request
2014/11/27 01:15:23.508| Eui48.cc(178) lookup: id=0x3515754 query ARP table
2014/11/27 01:15:23.508| Eui48.cc(221) lookup: id=0x3515754 query ARP on each interface (80 found)
2014/11/27 01:15:23.508| Eui48.cc(227) lookup: id=0x3515754 found interface lo
2014/11/27 01:15:23.508| Eui48.cc(227) lookup: id=0x3515754 found interface br0
2014/11/27 01:15:23.508| Eui48.cc(236) lookup: id=0x3515754 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.508| Eui48.cc(279) lookup: id=0x3515754 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.508| client_side.cc(3889) httpsAccept: local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.508| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.508| Checklist.cc(68) preCheck: 0x35160a8 checking slow rules
2014/11/27 01:15:23.508| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.508| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.508| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.508| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.509| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.509| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.509| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0x597e
2014/11/27 01:15:23.509| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.509| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.246'
2014/11/27 01:15:23.509| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.509| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0xb716
2014/11/27 01:15:23.509| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.509| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.509| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.509| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.509| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.509| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.509| fd.cc(198) fd_open: fd_open() FD 40 HTTP Request
2014/11/27 01:15:23.509| Eui48.cc(178) lookup: id=0x351ab14 query ARP table
2014/11/27 01:15:23.509| Eui48.cc(221) lookup: id=0x351ab14 query ARP on each interface (80 found)
2014/11/27 01:15:23.509| Eui48.cc(227) lookup: id=0x351ab14 found interface lo
2014/11/27 01:15:23.509| Eui48.cc(227) lookup: id=0x351ab14 found interface br0
2014/11/27 01:15:23.509| Eui48.cc(236) lookup: id=0x351ab14 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.509| Eui48.cc(279) lookup: id=0x351ab14 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.509| client_side.cc(3889) httpsAccept: local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.509| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.509| Checklist.cc(68) preCheck: 0x351b468 checking slow rules
2014/11/27 01:15:23.509| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.509| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.509| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.509| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.509| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.509| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.510| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0x5d7b
2014/11/27 01:15:23.510| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.510| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.246'
2014/11/27 01:15:23.510| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.510| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0x51c3
2014/11/27 01:15:23.510| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.510| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.510| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.510| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.510| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.510| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.510| fd.cc(198) fd_open: fd_open() FD 41 HTTP Request
2014/11/27 01:15:23.510| Eui48.cc(178) lookup: id=0x351fed4 query ARP table
2014/11/27 01:15:23.510| Eui48.cc(221) lookup: id=0x351fed4 query ARP on each interface (80 found)
2014/11/27 01:15:23.510| Eui48.cc(227) lookup: id=0x351fed4 found interface lo
2014/11/27 01:15:23.510| Eui48.cc(227) lookup: id=0x351fed4 found interface br0
2014/11/27 01:15:23.510| Eui48.cc(236) lookup: id=0x351fed4 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.510| Eui48.cc(279) lookup: id=0x351fed4 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.510| client_side.cc(3889) httpsAccept: local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.510| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.510| Checklist.cc(68) preCheck: 0x3520828 checking slow rules
2014/11/27 01:15:23.510| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.510| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.510| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.510| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.510| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.510| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.510| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0xc842
2014/11/27 01:15:23.510| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.510| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.246'
2014/11/27 01:15:23.510| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.511| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0x5b0c
2014/11/27 01:15:23.511| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.511| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.511| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.511| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.511| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.511| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.511| fd.cc(198) fd_open: fd_open() FD 42 HTTP Request
2014/11/27 01:15:23.511| Eui48.cc(178) lookup: id=0x3525294 query ARP table
2014/11/27 01:15:23.511| Eui48.cc(221) lookup: id=0x3525294 query ARP on each interface (80 found)
2014/11/27 01:15:23.511| Eui48.cc(227) lookup: id=0x3525294 found interface lo
2014/11/27 01:15:23.511| Eui48.cc(227) lookup: id=0x3525294 found interface br0
2014/11/27 01:15:23.511| Eui48.cc(236) lookup: id=0x3525294 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.511| Eui48.cc(279) lookup: id=0x3525294 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.511| client_side.cc(3889) httpsAccept: local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.511| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.511| Checklist.cc(68) preCheck: 0x3525be8 checking slow rules
2014/11/27 01:15:23.511| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.511| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.511| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.511| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.511| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.511| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.511| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0x3e40
2014/11/27 01:15:23.511| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.511| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.246'
2014/11/27 01:15:23.511| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.511| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0xf8a4
2014/11/27 01:15:23.512| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.512| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.512| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.512| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.512| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.512| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.512| fd.cc(198) fd_open: fd_open() FD 43 HTTP Request
2014/11/27 01:15:23.512| Eui48.cc(178) lookup: id=0x352a654 query ARP table
2014/11/27 01:15:23.512| Eui48.cc(221) lookup: id=0x352a654 query ARP on each interface (80 found)
2014/11/27 01:15:23.512| Eui48.cc(227) lookup: id=0x352a654 found interface lo
2014/11/27 01:15:23.512| Eui48.cc(227) lookup: id=0x352a654 found interface br0
2014/11/27 01:15:23.512| Eui48.cc(236) lookup: id=0x352a654 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.512| Eui48.cc(279) lookup: id=0x352a654 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.512| client_side.cc(3889) httpsAccept: local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.512| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.512| Checklist.cc(68) preCheck: 0x352afa8 checking slow rules
2014/11/27 01:15:23.512| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.512| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.512| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.512| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.512| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.512| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.512| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0x1dfd
2014/11/27 01:15:23.512| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.512| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '212.42.76.246'
2014/11/27 01:15:23.512| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '212.42.76.246'.
2014/11/27 01:15:23.512| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 212.42.76.246, id = 0x42f1
2014/11/27 01:15:23.512| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.512| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.512| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.512| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.521| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.521| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.521| fd.cc(198) fd_open: fd_open() FD 44 HTTP Request
2014/11/27 01:15:23.521| Eui48.cc(178) lookup: id=0x352fa14 query ARP table
2014/11/27 01:15:23.521| Eui48.cc(221) lookup: id=0x352fa14 query ARP on each interface (80 found)
2014/11/27 01:15:23.521| Eui48.cc(227) lookup: id=0x352fa14 found interface lo
2014/11/27 01:15:23.521| Eui48.cc(227) lookup: id=0x352fa14 found interface br0
2014/11/27 01:15:23.521| Eui48.cc(236) lookup: id=0x352fa14 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.521| Eui48.cc(279) lookup: id=0x352fa14 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.521| client_side.cc(3889) httpsAccept: local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.521| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 81.222.128.22
2014/11/27 01:15:23.521| Checklist.cc(68) preCheck: 0x3530368 checking slow rules
2014/11/27 01:15:23.521| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.521| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.521| DomainData.cc(106) match: aclMatchDomainList: checking '81.222.128.22'
2014/11/27 01:15:23.521| DomainData.cc(110) match: aclMatchDomainList: '81.222.128.22' NOT found
2014/11/27 01:15:23.521| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '81.222.128.22' == 81.222.128.22
2014/11/27 01:15:23.521| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '81.222.128.22'.
2014/11/27 01:15:23.521| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 81.222.128.22, id = 0xbf30
2014/11/27 01:15:23.521| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.521| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '81.222.128.22'
2014/11/27 01:15:23.521| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '81.222.128.22'.
2014/11/27 01:15:23.522| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 81.222.128.22, id = 0x1ba
2014/11/27 01:15:23.522| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.522| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.522| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.522| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.522| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:23.522| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:23.522| fd.cc(198) fd_open: fd_open() FD 45 HTTP Request
2014/11/27 01:15:23.522| Eui48.cc(178) lookup: id=0x3534dd4 query ARP table
2014/11/27 01:15:23.522| Eui48.cc(221) lookup: id=0x3534dd4 query ARP on each interface (80 found)
2014/11/27 01:15:23.522| Eui48.cc(227) lookup: id=0x3534dd4 found interface lo
2014/11/27 01:15:23.522| Eui48.cc(227) lookup: id=0x3534dd4 found interface br0
2014/11/27 01:15:23.522| Eui48.cc(236) lookup: id=0x3534dd4 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:23.522| Eui48.cc(279) lookup: id=0x3534dd4 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:23.522| client_side.cc(3889) httpsAccept: local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:23.522| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 81.222.128.22
2014/11/27 01:15:23.522| Checklist.cc(68) preCheck: 0x3535728 checking slow rules
2014/11/27 01:15:23.522| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:23.522| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.522| DomainData.cc(106) match: aclMatchDomainList: checking '81.222.128.22'
2014/11/27 01:15:23.522| DomainData.cc(110) match: aclMatchDomainList: '81.222.128.22' NOT found
2014/11/27 01:15:23.522| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '81.222.128.22' == 81.222.128.22
2014/11/27 01:15:23.522| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '81.222.128.22'.
2014/11/27 01:15:23.522| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 81.222.128.22, id = 0x527b
2014/11/27 01:15:23.522| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.522| DestinationDomain.cc(85) match: aclMatchAcl: Can't yet compare 'sslBumpDeniedDstDomain' ACL for '81.222.128.22'
2014/11/27 01:15:23.522| fqdncache.cc(425) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '81.222.128.22'.
2014/11/27 01:15:23.523| dns_internal.cc(1798) idnsPTRLookup: idnsPTRLookup: buf is 44 bytes for 81.222.128.22, id = 0x35a6
2014/11/27 01:15:23.523| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:23.523| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = -1 async
2014/11/27 01:15:23.523| Acl.cc(156) matches: checked: (ssl_bump rule) = -1 async
2014/11/27 01:15:23.523| Acl.cc(156) matches: checked: (ssl_bump rules) = -1 async
2014/11/27 01:15:23.554| dns_internal.cc(1281) idnsRead: idnsRead: starting with FD 10
2014/11/27 01:15:23.554| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.554| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x2631, 1 answers
2014/11/27 01:15:23.554| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.253'
2014/11/27 01:15:23.555| dns_internal.cc(1281) idnsRead: idnsRead: starting with FD 10
2014/11/27 01:15:23.555| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.555| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x38b8, 1 answers
2014/11/27 01:15:23.555| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.253'
2014/11/27 01:15:23.555| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:23.555| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:23.555| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:23.555| DomainData.cc(106) match: aclMatchDomainList: checking 'srv253.fwdcdn.com'
2014/11/27 01:15:23.555| DomainData.cc(110) match: aclMatchDomainList: 'srv253.fwdcdn.com' NOT found
2014/11/27 01:15:23.555| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.555| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.555| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62950' found
2014/11/27 01:15:23.555| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.555| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.555| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.555| Checklist.cc(61) markFinished: 0x33c85a8 answer ALLOWED for match
2014/11/27 01:15:23.555| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x33c85a8 answer=ALLOWED
2014/11/27 01:15:23.555| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33 method 5
2014/11/27 01:15:23.555| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33 timeout 300
2014/11/27 01:15:23.555| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:23.555| client_side.cc(3827) httpsEstablish: local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.556| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x33c85a8
2014/11/27 01:15:23.556| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x33c85a8
2014/11/27 01:15:23.556| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.556| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xbe07, 1 answers
2014/11/27 01:15:23.556| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.253'
2014/11/27 01:15:23.556| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.556| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x9242, 1 answers
2014/11/27 01:15:23.556| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.253'
2014/11/27 01:15:23.556| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:23.556| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:23.556| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:23.556| DomainData.cc(106) match: aclMatchDomainList: checking 'srv253.fwdcdn.com'
2014/11/27 01:15:23.556| DomainData.cc(110) match: aclMatchDomainList: 'srv253.fwdcdn.com' NOT found
2014/11/27 01:15:23.556| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.556| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.556| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62951' found
2014/11/27 01:15:23.556| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.556| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.556| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.556| Checklist.cc(61) markFinished: 0x3498f18 answer ALLOWED for match
2014/11/27 01:15:23.556| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3498f18 answer=ALLOWED
2014/11/27 01:15:23.556| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33 method 5
2014/11/27 01:15:23.556| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33 timeout 300
2014/11/27 01:15:23.557| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:23.557| client_side.cc(3827) httpsEstablish: local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.557| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3498f18
2014/11/27 01:15:23.557| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3498f18
2014/11/27 01:15:23.557| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.557| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xfa45, 1 answers
2014/11/27 01:15:23.557| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.253'
2014/11/27 01:15:23.557| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.557| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xf90a, 1 answers
2014/11/27 01:15:23.557| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.253'
2014/11/27 01:15:23.557| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:23.557| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:23.557| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:23.557| DomainData.cc(106) match: aclMatchDomainList: checking 'srv253.fwdcdn.com'
2014/11/27 01:15:23.557| DomainData.cc(110) match: aclMatchDomainList: 'srv253.fwdcdn.com' NOT found
2014/11/27 01:15:23.557| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.557| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.557| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62952' found
2014/11/27 01:15:23.557| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.557| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.557| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.557| Checklist.cc(61) markFinished: 0x34d0c78 answer ALLOWED for match
2014/11/27 01:15:23.557| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x34d0c78 answer=ALLOWED
2014/11/27 01:15:23.557| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33 method 5
2014/11/27 01:15:23.557| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33 timeout 300
2014/11/27 01:15:23.558| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:23.558| client_side.cc(3827) httpsEstablish: local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.558| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x34d0c78
2014/11/27 01:15:23.558| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x34d0c78
2014/11/27 01:15:23.558| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.558| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xf845, 1 answers
2014/11/27 01:15:23.558| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.253'
2014/11/27 01:15:23.558| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.558| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x112c, 1 answers
2014/11/27 01:15:23.558| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.253'
2014/11/27 01:15:23.558| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:23.558| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:23.558| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:23.558| DomainData.cc(106) match: aclMatchDomainList: checking 'srv253.fwdcdn.com'
2014/11/27 01:15:23.558| DomainData.cc(110) match: aclMatchDomainList: 'srv253.fwdcdn.com' NOT found
2014/11/27 01:15:23.558| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.558| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.558| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62953' found
2014/11/27 01:15:23.558| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.558| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.558| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.558| Checklist.cc(61) markFinished: 0x33ced08 answer ALLOWED for match
2014/11/27 01:15:23.558| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x33ced08 answer=ALLOWED
2014/11/27 01:15:23.558| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33 method 5
2014/11/27 01:15:23.558| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33 timeout 300
2014/11/27 01:15:23.559| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:23.559| client_side.cc(3827) httpsEstablish: local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.559| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x33ced08
2014/11/27 01:15:23.559| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x33ced08
2014/11/27 01:15:23.559| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 122 bytes from 8.8.8.8:53
2014/11/27 01:15:23.559| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xec7d, -3 answers
2014/11/27 01:15:23.559| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.559| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.191.234.34' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.559| DomainData.cc(106) match: aclMatchDomainList: checking '195.191.234.34'
2014/11/27 01:15:23.559| DomainData.cc(110) match: aclMatchDomainList: '195.191.234.34' NOT found
2014/11/27 01:15:23.559| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.191.234.34' == 195.191.234.34
2014/11/27 01:15:23.559| DomainData.cc(106) match: aclMatchDomainList: checking 'none'
2014/11/27 01:15:23.559| DomainData.cc(110) match: aclMatchDomainList: 'none' NOT found
2014/11/27 01:15:23.559| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.559| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.559| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62954' found
2014/11/27 01:15:23.559| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.559| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.559| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.559| Checklist.cc(61) markFinished: 0x33cf598 answer ALLOWED for match
2014/11/27 01:15:23.559| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x33cf598 answer=ALLOWED
2014/11/27 01:15:23.559| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33 method 5
2014/11/27 01:15:23.559| comm.cc(548) commSetConnTimeout: local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33 timeout 300
2014/11/27 01:15:23.559| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.191.234.34
2014/11/27 01:15:23.559| client_side.cc(3827) httpsEstablish: local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.560| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x33cf598
2014/11/27 01:15:23.560| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x33cf598
2014/11/27 01:15:23.560| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 122 bytes from 8.8.8.8:53
2014/11/27 01:15:23.560| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xfd91, -3 answers
2014/11/27 01:15:23.560| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.560| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.191.234.34' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.560| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 122 bytes from 8.8.8.8:53
2014/11/27 01:15:23.560| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x3062, -3 answers
2014/11/27 01:15:23.560| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.560| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.191.234.34' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.560| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 122 bytes from 8.8.8.8:53
2014/11/27 01:15:23.560| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xc2f0, -3 answers
2014/11/27 01:15:23.560| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.560| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.191.234.34' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.560| DomainData.cc(106) match: aclMatchDomainList: checking '195.191.234.34'
2014/11/27 01:15:23.560| DomainData.cc(110) match: aclMatchDomainList: '195.191.234.34' NOT found
2014/11/27 01:15:23.560| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.191.234.34' == 195.191.234.34
2014/11/27 01:15:23.560| DomainData.cc(106) match: aclMatchDomainList: checking 'none'
2014/11/27 01:15:23.560| DomainData.cc(110) match: aclMatchDomainList: 'none' NOT found
2014/11/27 01:15:23.560| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.560| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.560| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62955' found
2014/11/27 01:15:23.560| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.560| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.560| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.560| Checklist.cc(61) markFinished: 0x2fa8998 answer ALLOWED for match
2014/11/27 01:15:23.560| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x2fa8998 answer=ALLOWED
2014/11/27 01:15:23.560| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33 method 5
2014/11/27 01:15:23.561| comm.cc(548) commSetConnTimeout: local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33 timeout 300
2014/11/27 01:15:23.561| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.191.234.34
2014/11/27 01:15:23.561| client_side.cc(3827) httpsEstablish: local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.561| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.561| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.561| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.561| fd.cc(198) fd_open: fd_open() FD 46 IPC UNIX STREAM Parent
2014/11/27 01:15:23.561| fd.cc(198) fd_open: fd_open() FD 47 IPC UNIX STREAM Parent
2014/11/27 01:15:23.561| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 46
2014/11/27 01:15:23.561| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 46
2014/11/27 01:15:23.561| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 47
2014/11/27 01:15:23.561| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 47
2014/11/27 01:15:23.561| comm.cc(860) _comm_close: comm_close: start closing FD 47
2014/11/27 01:15:23.561| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 47
2014/11/27 01:15:23.561| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3499230 [call129]
2014/11/27 01:15:23.561| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 47) [call129]
2014/11/27 01:15:23.561| tools.cc(543) leave_suid: leave_suid: PID 16239 called
2014/11/27 01:15:23.561| tools.cc(636) no_suid: no_suid: PID 16239 giving up root priveleges forever
2014/11/27 01:15:23.561| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 46
2014/11/27 01:15:23.561| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x33d0690 [call130]
2014/11/27 01:15:23.561| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x33cf0d0 [call131]
2014/11/27 01:15:23.562| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.562| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x2fa8998
2014/11/27 01:15:23.562| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x2fa8998
2014/11/27 01:15:23.562| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.562| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xc68b, 1 answers
2014/11/27 01:15:23.562| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '195.214.193.51'
2014/11/27 01:15:23.562| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.193.51'
2014/11/27 01:15:23.562| DomainData.cc(110) match: aclMatchDomainList: '195.214.193.51' NOT found
2014/11/27 01:15:23.562| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.193.51' == 195.214.193.51
2014/11/27 01:15:23.562| DomainData.cc(106) match: aclMatchDomainList: checking 'safe-fe1.ukr.net'
2014/11/27 01:15:23.562| DomainData.cc(110) match: aclMatchDomainList: 'safe-fe1.ukr.net' NOT found
2014/11/27 01:15:23.562| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.562| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.562| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62956' found
2014/11/27 01:15:23.562| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.562| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.562| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.562| Checklist.cc(61) markFinished: 0x34ce718 answer ALLOWED for match
2014/11/27 01:15:23.562| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x34ce718 answer=ALLOWED
2014/11/27 01:15:23.562| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33 method 5
2014/11/27 01:15:23.562| comm.cc(548) commSetConnTimeout: local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33 timeout 300
2014/11/27 01:15:23.562| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.193.51
2014/11/27 01:15:23.562| client_side.cc(3827) httpsEstablish: local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.563| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.563| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.563| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.563| fd.cc(198) fd_open: fd_open() FD 48 IPC UNIX STREAM Parent
2014/11/27 01:15:23.563| fd.cc(198) fd_open: fd_open() FD 49 IPC UNIX STREAM Parent
2014/11/27 01:15:23.563| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 48
2014/11/27 01:15:23.563| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 48
2014/11/27 01:15:23.563| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 49
2014/11/27 01:15:23.563| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 49
2014/11/27 01:15:23.563| comm.cc(860) _comm_close: comm_close: start closing FD 49
2014/11/27 01:15:23.563| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 49
2014/11/27 01:15:23.563| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x353a3c0 [call134]
2014/11/27 01:15:23.563| tools.cc(543) leave_suid: leave_suid: PID 16240 called
2014/11/27 01:15:23.563| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 49) [call134]
2014/11/27 01:15:23.563| tools.cc(636) no_suid: no_suid: PID 16240 giving up root priveleges forever
2014/11/27 01:15:23.563| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 48
2014/11/27 01:15:23.563| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x34d03c0 [call135]
2014/11/27 01:15:23.563| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3546610 [call136]
2014/11/27 01:15:23.563| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.563| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x34ce718
2014/11/27 01:15:23.563| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x34ce718
2014/11/27 01:15:23.564| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.564| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x4b0, 1 answers
2014/11/27 01:15:23.564| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '195.214.193.51'
2014/11/27 01:15:23.564| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.564| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xf8a, 1 answers
2014/11/27 01:15:23.564| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '195.214.193.51'
2014/11/27 01:15:23.564| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.193.51'
2014/11/27 01:15:23.564| DomainData.cc(110) match: aclMatchDomainList: '195.214.193.51' NOT found
2014/11/27 01:15:23.564| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.193.51' == 195.214.193.51
2014/11/27 01:15:23.564| DomainData.cc(106) match: aclMatchDomainList: checking 'safe-fe1.ukr.net'
2014/11/27 01:15:23.564| DomainData.cc(110) match: aclMatchDomainList: 'safe-fe1.ukr.net' NOT found
2014/11/27 01:15:23.564| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.564| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.564| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62957' found
2014/11/27 01:15:23.564| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.564| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.564| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.564| Checklist.cc(61) markFinished: 0x34cf718 answer ALLOWED for match
2014/11/27 01:15:23.564| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x34cf718 answer=ALLOWED
2014/11/27 01:15:23.564| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33 method 5
2014/11/27 01:15:23.564| comm.cc(548) commSetConnTimeout: local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33 timeout 300
2014/11/27 01:15:23.564| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.193.51
2014/11/27 01:15:23.564| client_side.cc(3827) httpsEstablish: local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.564| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.564| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.564| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.564| fd.cc(198) fd_open: fd_open() FD 50 IPC UNIX STREAM Parent
2014/11/27 01:15:23.564| fd.cc(198) fd_open: fd_open() FD 51 IPC UNIX STREAM Parent
2014/11/27 01:15:23.564| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 50
2014/11/27 01:15:23.564| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 50
2014/11/27 01:15:23.564| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 51
2014/11/27 01:15:23.564| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 51
2014/11/27 01:15:23.565| comm.cc(860) _comm_close: comm_close: start closing FD 51
2014/11/27 01:15:23.565| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 51
2014/11/27 01:15:23.565| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34cfa60 [call139]
2014/11/27 01:15:23.565| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 51) [call139]
2014/11/27 01:15:23.565| tools.cc(636) no_suid: no_suid: PID 16241 giving up root priveleges forever
2014/11/27 01:15:23.565| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 50
2014/11/27 01:15:23.565| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x353a190 [call140]
2014/11/27 01:15:23.565| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3546bc0 [call141]
2014/11/27 01:15:23.565| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.565| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x34cf718
2014/11/27 01:15:23.565| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x34cf718
2014/11/27 01:15:23.565| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.565| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xe3bd, 1 answers
2014/11/27 01:15:23.565| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '195.214.193.51'
2014/11/27 01:15:23.565| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 47)
2014/11/27 01:15:23.565| AsyncCall.cc(38) make: make call comm_close_complete [call129]
2014/11/27 01:15:23.565| fd.cc(93) fd_close: fd_close FD 47 IPC UNIX STREAM Parent
2014/11/27 01:15:23.566| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 47)
2014/11/27 01:15:23.566| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 49)
2014/11/27 01:15:23.566| AsyncCall.cc(38) make: make call comm_close_complete [call134]
2014/11/27 01:15:23.566| fd.cc(93) fd_close: fd_close FD 49 IPC UNIX STREAM Parent
2014/11/27 01:15:23.566| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 49)
2014/11/27 01:15:23.566| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 51)
2014/11/27 01:15:23.566| AsyncCall.cc(38) make: make call comm_close_complete [call139]
2014/11/27 01:15:23.566| fd.cc(93) fd_close: fd_close FD 51 IPC UNIX STREAM Parent
2014/11/27 01:15:23.566| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 51)
2014/11/27 01:15:23.566| dns_internal.cc(1281) idnsRead: idnsRead: starting with FD 10
2014/11/27 01:15:23.566| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.566| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x7676, 1 answers
2014/11/27 01:15:23.566| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.77.249'
2014/11/27 01:15:23.566| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.566| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x3f80, 1 answers
2014/11/27 01:15:23.566| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.77.249'
2014/11/27 01:15:23.566| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.77.249'
2014/11/27 01:15:23.566| DomainData.cc(110) match: aclMatchDomainList: '212.42.77.249' NOT found
2014/11/27 01:15:23.566| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.77.249' == 212.42.77.249
2014/11/27 01:15:23.566| DomainData.cc(106) match: aclMatchDomainList: checking 'frv249.fwdcdn.com'
2014/11/27 01:15:23.566| DomainData.cc(110) match: aclMatchDomainList: 'frv249.fwdcdn.com' NOT found
2014/11/27 01:15:23.566| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.566| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.566| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62958' found
2014/11/27 01:15:23.566| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.566| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.566| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.566| Checklist.cc(61) markFinished: 0x34e6e08 answer ALLOWED for match
2014/11/27 01:15:23.566| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x34e6e08 answer=ALLOWED
2014/11/27 01:15:23.566| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33 method 5
2014/11/27 01:15:23.566| comm.cc(548) commSetConnTimeout: local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33 timeout 300
2014/11/27 01:15:23.566| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.77.249
2014/11/27 01:15:23.566| client_side.cc(3827) httpsEstablish: local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.567| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.567| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.567| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.567| fd.cc(198) fd_open: fd_open() FD 47 IPC UNIX STREAM Parent
2014/11/27 01:15:23.567| fd.cc(198) fd_open: fd_open() FD 49 IPC UNIX STREAM Parent
2014/11/27 01:15:23.567| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 47
2014/11/27 01:15:23.567| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 47
2014/11/27 01:15:23.567| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 49
2014/11/27 01:15:23.567| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 49
2014/11/27 01:15:23.567| comm.cc(860) _comm_close: comm_close: start closing FD 49
2014/11/27 01:15:23.567| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 49
2014/11/27 01:15:23.567| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34ec4d0 [call144]
2014/11/27 01:15:23.567| tools.cc(543) leave_suid: leave_suid: PID 16242 called
2014/11/27 01:15:23.567| tools.cc(636) no_suid: no_suid: PID 16242 giving up root priveleges forever
2014/11/27 01:15:23.567| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 47
2014/11/27 01:15:23.567| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x34fc0a0 [call145]
2014/11/27 01:15:23.567| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x34cec00 [call146]
2014/11/27 01:15:23.567| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.567| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x34e6e08
2014/11/27 01:15:23.567| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x34e6e08
2014/11/27 01:15:23.568| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.568| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x4711, 1 answers
2014/11/27 01:15:23.568| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.77.249'
2014/11/27 01:15:23.568| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.568| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xde5d, 1 answers
2014/11/27 01:15:23.568| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.77.249'
2014/11/27 01:15:23.568| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.77.249'
2014/11/27 01:15:23.568| DomainData.cc(110) match: aclMatchDomainList: '212.42.77.249' NOT found
2014/11/27 01:15:23.568| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.77.249' == 212.42.77.249
2014/11/27 01:15:23.568| DomainData.cc(106) match: aclMatchDomainList: checking 'frv249.fwdcdn.com'
2014/11/27 01:15:23.568| DomainData.cc(110) match: aclMatchDomainList: 'frv249.fwdcdn.com' NOT found
2014/11/27 01:15:23.568| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.568| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.568| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62959' found
2014/11/27 01:15:23.568| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.568| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.568| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.568| Checklist.cc(61) markFinished: 0x34ec188 answer ALLOWED for match
2014/11/27 01:15:23.568| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x34ec188 answer=ALLOWED
2014/11/27 01:15:23.568| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33 method 5
2014/11/27 01:15:23.568| comm.cc(548) commSetConnTimeout: local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33 timeout 300
2014/11/27 01:15:23.568| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.77.249
2014/11/27 01:15:23.568| client_side.cc(3827) httpsEstablish: local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.568| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.568| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.568| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.568| fd.cc(198) fd_open: fd_open() FD 51 IPC UNIX STREAM Parent
2014/11/27 01:15:23.568| fd.cc(198) fd_open: fd_open() FD 52 IPC UNIX STREAM Parent
2014/11/27 01:15:23.568| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 51
2014/11/27 01:15:23.568| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 51
2014/11/27 01:15:23.568| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 52
2014/11/27 01:15:23.568| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 52
2014/11/27 01:15:23.569| comm.cc(860) _comm_close: comm_close: start closing FD 52
2014/11/27 01:15:23.569| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 52
2014/11/27 01:15:23.569| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3499230 [call149]
2014/11/27 01:15:23.569| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 52) [call149]
2014/11/27 01:15:23.569| tools.cc(543) leave_suid: leave_suid: PID 16243 called
2014/11/27 01:15:23.569| tools.cc(636) no_suid: no_suid: PID 16243 giving up root priveleges forever
2014/11/27 01:15:23.569| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 51
2014/11/27 01:15:23.569| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x353f250 [call150]
2014/11/27 01:15:23.569| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x353eff0 [call151]
2014/11/27 01:15:23.569| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.569| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x34ec188
2014/11/27 01:15:23.569| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x34ec188
2014/11/27 01:15:23.569| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 117 bytes from 8.8.8.8:53
2014/11/27 01:15:23.569| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x40fd, -3 answers
2014/11/27 01:15:23.569| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.569| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.214.195.101' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.570| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.195.101'
2014/11/27 01:15:23.570| DomainData.cc(110) match: aclMatchDomainList: '195.214.195.101' NOT found
2014/11/27 01:15:23.570| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.195.101' == 195.214.195.101
2014/11/27 01:15:23.570| DomainData.cc(106) match: aclMatchDomainList: checking 'none'
2014/11/27 01:15:23.570| DomainData.cc(110) match: aclMatchDomainList: 'none' NOT found
2014/11/27 01:15:23.570| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.570| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.570| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62960' found
2014/11/27 01:15:23.570| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.570| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.570| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.570| Checklist.cc(61) markFinished: 0x34f1548 answer ALLOWED for match
2014/11/27 01:15:23.570| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x34f1548 answer=ALLOWED
2014/11/27 01:15:23.570| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33 method 5
2014/11/27 01:15:23.570| comm.cc(548) commSetConnTimeout: local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33 timeout 300
2014/11/27 01:15:23.570| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.195.101
2014/11/27 01:15:23.570| client_side.cc(3827) httpsEstablish: local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.570| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.570| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.570| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.570| fd.cc(198) fd_open: fd_open() FD 53 IPC UNIX STREAM Parent
2014/11/27 01:15:23.570| fd.cc(198) fd_open: fd_open() FD 54 IPC UNIX STREAM Parent
2014/11/27 01:15:23.570| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 53
2014/11/27 01:15:23.570| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 53
2014/11/27 01:15:23.570| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 54
2014/11/27 01:15:23.570| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 54
2014/11/27 01:15:23.570| comm.cc(860) _comm_close: comm_close: start closing FD 54
2014/11/27 01:15:23.570| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 54
2014/11/27 01:15:23.570| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x354bd30 [call154]
2014/11/27 01:15:23.570| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 54) [call154]
2014/11/27 01:15:23.570| tools.cc(543) leave_suid: leave_suid: PID 16244 called
2014/11/27 01:15:23.570| tools.cc(636) no_suid: no_suid: PID 16244 giving up root priveleges forever
2014/11/27 01:15:23.571| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 53
2014/11/27 01:15:23.571| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x34cfc70 [call155]
2014/11/27 01:15:23.571| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x34ec620 [call156]
2014/11/27 01:15:23.571| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.571| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x34f1548
2014/11/27 01:15:23.571| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x34f1548
2014/11/27 01:15:23.571| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 117 bytes from 8.8.8.8:53
2014/11/27 01:15:23.571| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x3203, -3 answers
2014/11/27 01:15:23.571| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.571| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.214.195.101' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.571| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 117 bytes from 8.8.8.8:53
2014/11/27 01:15:23.571| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x9a34, -3 answers
2014/11/27 01:15:23.571| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.571| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.214.195.101' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.571| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 117 bytes from 8.8.8.8:53
2014/11/27 01:15:23.571| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x4d16, -3 answers
2014/11/27 01:15:23.571| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.571| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.214.195.101' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.571| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.195.101'
2014/11/27 01:15:23.571| DomainData.cc(110) match: aclMatchDomainList: '195.214.195.101' NOT found
2014/11/27 01:15:23.572| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.195.101' == 195.214.195.101
2014/11/27 01:15:23.572| DomainData.cc(106) match: aclMatchDomainList: checking 'none'
2014/11/27 01:15:23.572| DomainData.cc(110) match: aclMatchDomainList: 'none' NOT found
2014/11/27 01:15:23.572| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.572| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.572| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62961' found
2014/11/27 01:15:23.572| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.572| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.572| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.572| Checklist.cc(61) markFinished: 0x34f6998 answer ALLOWED for match
2014/11/27 01:15:23.572| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x34f6998 answer=ALLOWED
2014/11/27 01:15:23.572| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33 method 5
2014/11/27 01:15:23.572| comm.cc(548) commSetConnTimeout: local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33 timeout 300
2014/11/27 01:15:23.572| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.195.101
2014/11/27 01:15:23.572| client_side.cc(3827) httpsEstablish: local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.572| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.572| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.572| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.572| fd.cc(198) fd_open: fd_open() FD 55 IPC UNIX STREAM Parent
2014/11/27 01:15:23.572| fd.cc(198) fd_open: fd_open() FD 56 IPC UNIX STREAM Parent
2014/11/27 01:15:23.572| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 55
2014/11/27 01:15:23.572| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 55
2014/11/27 01:15:23.572| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 56
2014/11/27 01:15:23.572| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 56
2014/11/27 01:15:23.572| comm.cc(860) _comm_close: comm_close: start closing FD 56
2014/11/27 01:15:23.572| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 56
2014/11/27 01:15:23.572| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x33d0580 [call159]
2014/11/27 01:15:23.572| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 56) [call159]
2014/11/27 01:15:23.572| tools.cc(543) leave_suid: leave_suid: PID 16245 called
2014/11/27 01:15:23.572| tools.cc(636) no_suid: no_suid: PID 16245 giving up root priveleges forever
2014/11/27 01:15:23.573| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 55
2014/11/27 01:15:23.573| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x3545d30 [call160]
2014/11/27 01:15:23.573| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x34f1a60 [call161]
2014/11/27 01:15:23.573| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.573| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x34f6998
2014/11/27 01:15:23.573| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x34f6998
2014/11/27 01:15:23.573| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 84 bytes from 8.8.8.8:53
2014/11/27 01:15:23.573| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x9791, 1 answers
2014/11/27 01:15:23.573| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '173.194.113.94'
2014/11/27 01:15:23.573| DomainData.cc(106) match: aclMatchDomainList: checking '173.194.113.94'
2014/11/27 01:15:23.573| DomainData.cc(110) match: aclMatchDomainList: '173.194.113.94' NOT found
2014/11/27 01:15:23.573| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '173.194.113.94' == 173.194.113.94
2014/11/27 01:15:23.573| DomainData.cc(106) match: aclMatchDomainList: checking 'fra02s21-in-f30.1e100.net'
2014/11/27 01:15:23.573| DomainData.cc(110) match: aclMatchDomainList: 'fra02s21-in-f30.1e100.net' NOT found
2014/11/27 01:15:23.573| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.573| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.573| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62962' found
2014/11/27 01:15:23.573| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.573| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.573| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.573| Checklist.cc(61) markFinished: 0x34fbd58 answer ALLOWED for match
2014/11/27 01:15:23.573| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x34fbd58 answer=ALLOWED
2014/11/27 01:15:23.573| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33 method 5
2014/11/27 01:15:23.574| comm.cc(548) commSetConnTimeout: local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33 timeout 300
2014/11/27 01:15:23.574| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 173.194.113.94
2014/11/27 01:15:23.574| client_side.cc(3827) httpsEstablish: local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.574| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.574| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.574| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.574| fd.cc(198) fd_open: fd_open() FD 57 IPC UNIX STREAM Parent
2014/11/27 01:15:23.574| fd.cc(198) fd_open: fd_open() FD 58 IPC UNIX STREAM Parent
2014/11/27 01:15:23.574| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 57
2014/11/27 01:15:23.574| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 57
2014/11/27 01:15:23.574| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 58
2014/11/27 01:15:23.574| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 58
2014/11/27 01:15:23.574| comm.cc(860) _comm_close: comm_close: start closing FD 58
2014/11/27 01:15:23.574| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 58
2014/11/27 01:15:23.574| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3551d30 [call164]
2014/11/27 01:15:23.574| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 58) [call164]
2014/11/27 01:15:23.574| tools.cc(543) leave_suid: leave_suid: PID 16246 called
2014/11/27 01:15:23.574| tools.cc(636) no_suid: no_suid: PID 16246 giving up root priveleges forever
2014/11/27 01:15:23.574| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 57
2014/11/27 01:15:23.574| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x354f820 [call165]
2014/11/27 01:15:23.574| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x34f6ee0 [call166]
2014/11/27 01:15:23.575| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.575| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x34fbd58
2014/11/27 01:15:23.575| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x34fbd58
2014/11/27 01:15:23.575| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 84 bytes from 8.8.8.8:53
2014/11/27 01:15:23.575| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x8bb7, 1 answers
2014/11/27 01:15:23.575| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '173.194.113.94'
2014/11/27 01:15:23.575| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 116 bytes from 8.8.8.8:53
2014/11/27 01:15:23.575| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xa10b, -3 answers
2014/11/27 01:15:23.575| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.575| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.214.194.27' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.575| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 116 bytes from 8.8.8.8:53
2014/11/27 01:15:23.575| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x1a5f, -3 answers
2014/11/27 01:15:23.575| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.575| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.214.194.27' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.575| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 116 bytes from 8.8.8.8:53
2014/11/27 01:15:23.575| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x8419, -3 answers
2014/11/27 01:15:23.575| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.575| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.214.194.27' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.575| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.194.27'
2014/11/27 01:15:23.575| DomainData.cc(110) match: aclMatchDomainList: '195.214.194.27' NOT found
2014/11/27 01:15:23.575| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.194.27' == 195.214.194.27
2014/11/27 01:15:23.575| DomainData.cc(106) match: aclMatchDomainList: checking 'none'
2014/11/27 01:15:23.575| DomainData.cc(110) match: aclMatchDomainList: 'none' NOT found
2014/11/27 01:15:23.575| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.575| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.575| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62964' found
2014/11/27 01:15:23.575| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.575| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.575| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.575| Checklist.cc(61) markFinished: 0x3506568 answer ALLOWED for match
2014/11/27 01:15:23.575| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3506568 answer=ALLOWED
2014/11/27 01:15:23.575| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33 method 5
2014/11/27 01:15:23.576| comm.cc(548) commSetConnTimeout: local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33 timeout 300
2014/11/27 01:15:23.576| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.194.27
2014/11/27 01:15:23.576| client_side.cc(3827) httpsEstablish: local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.576| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.576| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.576| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.576| fd.cc(198) fd_open: fd_open() FD 59 IPC UNIX STREAM Parent
2014/11/27 01:15:23.576| fd.cc(198) fd_open: fd_open() FD 60 IPC UNIX STREAM Parent
2014/11/27 01:15:23.576| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 59
2014/11/27 01:15:23.576| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 59
2014/11/27 01:15:23.576| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 60
2014/11/27 01:15:23.576| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 60
2014/11/27 01:15:23.576| comm.cc(860) _comm_close: comm_close: start closing FD 60
2014/11/27 01:15:23.576| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 60
2014/11/27 01:15:23.576| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x353f3c0 [call169]
2014/11/27 01:15:23.576| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 60) [call169]
2014/11/27 01:15:23.576| tools.cc(543) leave_suid: leave_suid: PID 16247 called
2014/11/27 01:15:23.576| tools.cc(636) no_suid: no_suid: PID 16247 giving up root priveleges forever
2014/11/27 01:15:23.576| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 59
2014/11/27 01:15:23.576| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x3554d30 [call170]
2014/11/27 01:15:23.576| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x34fc1f0 [call171]
2014/11/27 01:15:23.577| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.577| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3506568
2014/11/27 01:15:23.577| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3506568
2014/11/27 01:15:23.577| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 116 bytes from 8.8.8.8:53
2014/11/27 01:15:23.577| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x1308, -3 answers
2014/11/27 01:15:23.577| dns_internal.cc(1199) idnsGrokReply: idnsGrokReply: error Name Error: The domain name does not exist. (3)
2014/11/27 01:15:23.577| fqdncache.cc(331) fqdncacheParse: fqdncacheParse: Lookup of '195.214.194.27' failed (Name Error: The domain name does not exist.)
2014/11/27 01:15:23.577| DomainData.cc(106) match: aclMatchDomainList: checking '195.214.194.27'
2014/11/27 01:15:23.577| DomainData.cc(110) match: aclMatchDomainList: '195.214.194.27' NOT found
2014/11/27 01:15:23.577| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '195.214.194.27' == 195.214.194.27
2014/11/27 01:15:23.577| DomainData.cc(106) match: aclMatchDomainList: checking 'none'
2014/11/27 01:15:23.577| DomainData.cc(110) match: aclMatchDomainList: 'none' NOT found
2014/11/27 01:15:23.577| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.577| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.577| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62963' found
2014/11/27 01:15:23.577| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.577| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.577| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.577| Checklist.cc(61) markFinished: 0x35011a8 answer ALLOWED for match
2014/11/27 01:15:23.577| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x35011a8 answer=ALLOWED
2014/11/27 01:15:23.577| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33 method 5
2014/11/27 01:15:23.577| comm.cc(548) commSetConnTimeout: local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33 timeout 300
2014/11/27 01:15:23.577| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 195.214.194.27
2014/11/27 01:15:23.577| client_side.cc(3827) httpsEstablish: local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.577| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.577| Starting new ssl_crtd helpers...
2014/11/27 01:15:23.577| helperOpenServers: Starting 1/15 'ssl_crtd' processes
2014/11/27 01:15:23.577| fd.cc(198) fd_open: fd_open() FD 61 IPC UNIX STREAM Parent
2014/11/27 01:15:23.577| fd.cc(198) fd_open: fd_open() FD 62 IPC UNIX STREAM Parent
2014/11/27 01:15:23.577| ipc.cc(180) ipcCreate: ipcCreate: prfd FD 61
2014/11/27 01:15:23.578| ipc.cc(181) ipcCreate: ipcCreate: pwfd FD 61
2014/11/27 01:15:23.578| ipc.cc(182) ipcCreate: ipcCreate: crfd FD 62
2014/11/27 01:15:23.578| ipc.cc(183) ipcCreate: ipcCreate: cwfd FD 62
2014/11/27 01:15:23.578| comm.cc(860) _comm_close: comm_close: start closing FD 62
2014/11/27 01:15:23.578| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 62
2014/11/27 01:15:23.578| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3557d30 [call174]
2014/11/27 01:15:23.578| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 62) [call174]
2014/11/27 01:15:23.578| tools.cc(543) leave_suid: leave_suid: PID 16248 called
2014/11/27 01:15:23.578| tools.cc(636) no_suid: no_suid: PID 16248 giving up root priveleges forever
2014/11/27 01:15:23.578| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 61
2014/11/27 01:15:23.578| AsyncCall.cc(26) AsyncCall: The AsyncCall helperServerFree constructed, this=0x355ad30 [call175]
2014/11/27 01:15:23.578| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x35069e0 [call176]
2014/11/27 01:15:23.578| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.578| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x35011a8
2014/11/27 01:15:23.578| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x35011a8
2014/11/27 01:15:23.578| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 69 bytes from 8.8.8.8:53
2014/11/27 01:15:23.578| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xa66a, 1 answers
2014/11/27 01:15:23.578| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '185.26.97.139'
2014/11/27 01:15:23.579| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 11 flags=1 (0, 0)
2014/11/27 01:15:23.579| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 13 flags=1 (0, 0)
2014/11/27 01:15:23.579| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 15 flags=1 (0, 0)
2014/11/27 01:15:23.580| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 17 flags=1 (0, 0)
2014/11/27 01:15:23.580| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 19 flags=1 (0, 0)
2014/11/27 01:15:23.580| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 46 flags=1 (0, 0)
2014/11/27 01:15:23.580| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 48 flags=1 (0, 0)
2014/11/27 01:15:23.580| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 50 flags=1 (0, 0)
2014/11/27 01:15:23.580| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 49)
2014/11/27 01:15:23.580| AsyncCall.cc(38) make: make call comm_close_complete [call144]
2014/11/27 01:15:23.580| fd.cc(93) fd_close: fd_close FD 49 IPC UNIX STREAM Parent
2014/11/27 01:15:23.581| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 49)
2014/11/27 01:15:23.581| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 52)
2014/11/27 01:15:23.581| AsyncCall.cc(38) make: make call comm_close_complete [call149]
2014/11/27 01:15:23.581| fd.cc(93) fd_close: fd_close FD 52 IPC UNIX STREAM Parent
2014/11/27 01:15:23.581| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 52)
2014/11/27 01:15:23.581| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 54)
2014/11/27 01:15:23.581| AsyncCall.cc(38) make: make call comm_close_complete [call154]
2014/11/27 01:15:23.581| fd.cc(93) fd_close: fd_close FD 54 IPC UNIX STREAM Parent
2014/11/27 01:15:23.581| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 54)
2014/11/27 01:15:23.581| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 56)
2014/11/27 01:15:23.581| AsyncCall.cc(38) make: make call comm_close_complete [call159]
2014/11/27 01:15:23.581| fd.cc(93) fd_close: fd_close FD 56 IPC UNIX STREAM Parent
2014/11/27 01:15:23.581| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 56)
2014/11/27 01:15:23.581| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 58)
2014/11/27 01:15:23.581| AsyncCall.cc(38) make: make call comm_close_complete [call164]
2014/11/27 01:15:23.581| fd.cc(93) fd_close: fd_close FD 58 IPC UNIX STREAM Parent
2014/11/27 01:15:23.581| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 58)
2014/11/27 01:15:23.581| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 60)
2014/11/27 01:15:23.581| AsyncCall.cc(38) make: make call comm_close_complete [call169]
2014/11/27 01:15:23.581| fd.cc(93) fd_close: fd_close FD 60 IPC UNIX STREAM Parent
2014/11/27 01:15:23.581| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 60)
2014/11/27 01:15:23.581| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 62)
2014/11/27 01:15:23.581| AsyncCall.cc(38) make: make call comm_close_complete [call174]
2014/11/27 01:15:23.581| fd.cc(93) fd_close: fd_close FD 62 IPC UNIX STREAM Parent
2014/11/27 01:15:23.581| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 62)
2014/11/27 01:15:23.581| dns_internal.cc(1281) idnsRead: idnsRead: starting with FD 10
2014/11/27 01:15:23.581| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 69 bytes from 8.8.8.8:53
2014/11/27 01:15:23.581| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xc73c, 1 answers
2014/11/27 01:15:23.581| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '185.26.97.139'
2014/11/27 01:15:23.582| DomainData.cc(106) match: aclMatchDomainList: checking '185.26.97.139'
2014/11/27 01:15:23.582| DomainData.cc(110) match: aclMatchDomainList: '185.26.97.139' NOT found
2014/11/27 01:15:23.582| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '185.26.97.139' == 185.26.97.139
2014/11/27 01:15:23.582| DomainData.cc(106) match: aclMatchDomainList: checking 'trafmag.com'
2014/11/27 01:15:23.582| DomainData.cc(110) match: aclMatchDomainList: 'trafmag.com' NOT found
2014/11/27 01:15:23.582| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.582| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.582| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62965' found
2014/11/27 01:15:23.582| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.582| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.582| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.582| Checklist.cc(61) markFinished: 0x350b928 answer ALLOWED for match
2014/11/27 01:15:23.582| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x350b928 answer=ALLOWED
2014/11/27 01:15:23.582| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33 method 5
2014/11/27 01:15:23.582| comm.cc(548) commSetConnTimeout: local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33 timeout 300
2014/11/27 01:15:23.582| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 185.26.97.139
2014/11/27 01:15:23.582| client_side.cc(3827) httpsEstablish: local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.582| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.582| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x350b928
2014/11/27 01:15:23.582| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x350b928
2014/11/27 01:15:23.582| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 69 bytes from 8.8.8.8:53
2014/11/27 01:15:23.582| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x6471, 1 answers
2014/11/27 01:15:23.582| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '185.26.97.139'
2014/11/27 01:15:23.582| DomainData.cc(106) match: aclMatchDomainList: checking '185.26.97.139'
2014/11/27 01:15:23.582| DomainData.cc(110) match: aclMatchDomainList: '185.26.97.139' NOT found
2014/11/27 01:15:23.582| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '185.26.97.139' == 185.26.97.139
2014/11/27 01:15:23.583| DomainData.cc(106) match: aclMatchDomainList: checking 'trafmag.com'
2014/11/27 01:15:23.583| DomainData.cc(110) match: aclMatchDomainList: 'trafmag.com' NOT found
2014/11/27 01:15:23.583| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.583| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.583| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62966' found
2014/11/27 01:15:23.583| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.583| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.583| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.583| Checklist.cc(61) markFinished: 0x3510ce8 answer ALLOWED for match
2014/11/27 01:15:23.583| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3510ce8 answer=ALLOWED
2014/11/27 01:15:23.583| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33 method 5
2014/11/27 01:15:23.583| comm.cc(548) commSetConnTimeout: local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33 timeout 300
2014/11/27 01:15:23.583| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 185.26.97.139
2014/11/27 01:15:23.583| client_side.cc(3827) httpsEstablish: local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.583| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.583| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3510ce8
2014/11/27 01:15:23.583| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3510ce8
2014/11/27 01:15:23.583| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 69 bytes from 8.8.8.8:53
2014/11/27 01:15:23.583| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xbcd1, 1 answers
2014/11/27 01:15:23.583| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '185.26.97.139'
2014/11/27 01:15:23.583| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.583| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x597e, 1 answers
2014/11/27 01:15:23.583| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.583| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.583| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xb716, 1 answers
2014/11/27 01:15:23.583| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.583| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.584| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.584| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.584| DomainData.cc(106) match: aclMatchDomainList: checking 'srv246.fwdcdn.com'
2014/11/27 01:15:23.584| DomainData.cc(110) match: aclMatchDomainList: 'srv246.fwdcdn.com' NOT found
2014/11/27 01:15:23.584| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.584| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.584| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62967' found
2014/11/27 01:15:23.584| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.584| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.584| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.584| Checklist.cc(61) markFinished: 0x35160a8 answer ALLOWED for match
2014/11/27 01:15:23.584| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x35160a8 answer=ALLOWED
2014/11/27 01:15:23.584| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33 method 5
2014/11/27 01:15:23.584| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33 timeout 300
2014/11/27 01:15:23.584| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.584| client_side.cc(3827) httpsEstablish: local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.584| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.584| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x35160a8
2014/11/27 01:15:23.584| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x35160a8
2014/11/27 01:15:23.584| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.584| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x5d7b, 1 answers
2014/11/27 01:15:23.584| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.584| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.584| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x51c3, 1 answers
2014/11/27 01:15:23.584| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.584| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.584| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.584| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.584| DomainData.cc(106) match: aclMatchDomainList: checking 'srv246.fwdcdn.com'
2014/11/27 01:15:23.585| DomainData.cc(110) match: aclMatchDomainList: 'srv246.fwdcdn.com' NOT found
2014/11/27 01:15:23.585| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.585| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.585| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62968' found
2014/11/27 01:15:23.585| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.585| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.585| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.585| Checklist.cc(61) markFinished: 0x351b468 answer ALLOWED for match
2014/11/27 01:15:23.585| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x351b468 answer=ALLOWED
2014/11/27 01:15:23.585| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33 method 5
2014/11/27 01:15:23.585| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33 timeout 300
2014/11/27 01:15:23.585| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.585| client_side.cc(3827) httpsEstablish: local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.585| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.585| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x351b468
2014/11/27 01:15:23.585| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x351b468
2014/11/27 01:15:23.585| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.585| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xc842, 1 answers
2014/11/27 01:15:23.585| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.585| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.585| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x5b0c, 1 answers
2014/11/27 01:15:23.585| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.585| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.585| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.585| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.585| DomainData.cc(106) match: aclMatchDomainList: checking 'srv246.fwdcdn.com'
2014/11/27 01:15:23.585| DomainData.cc(110) match: aclMatchDomainList: 'srv246.fwdcdn.com' NOT found
2014/11/27 01:15:23.585| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.585| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.586| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62969' found
2014/11/27 01:15:23.586| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.586| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.586| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.586| Checklist.cc(61) markFinished: 0x3520828 answer ALLOWED for match
2014/11/27 01:15:23.586| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3520828 answer=ALLOWED
2014/11/27 01:15:23.586| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33 method 5
2014/11/27 01:15:23.586| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33 timeout 300
2014/11/27 01:15:23.586| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.586| client_side.cc(3827) httpsEstablish: local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.586| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.586| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3520828
2014/11/27 01:15:23.586| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3520828
2014/11/27 01:15:23.586| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.586| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x3e40, 1 answers
2014/11/27 01:15:23.586| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.586| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.586| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xf8a4, 1 answers
2014/11/27 01:15:23.586| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.586| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.586| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.586| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.586| DomainData.cc(106) match: aclMatchDomainList: checking 'srv246.fwdcdn.com'
2014/11/27 01:15:23.586| DomainData.cc(110) match: aclMatchDomainList: 'srv246.fwdcdn.com' NOT found
2014/11/27 01:15:23.586| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.586| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.586| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62970' found
2014/11/27 01:15:23.586| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.586| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.586| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.586| Checklist.cc(61) markFinished: 0x3525be8 answer ALLOWED for match
2014/11/27 01:15:23.586| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3525be8 answer=ALLOWED
2014/11/27 01:15:23.587| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33 method 5
2014/11/27 01:15:23.587| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33 timeout 300
2014/11/27 01:15:23.587| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.587| client_side.cc(3827) httpsEstablish: local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.587| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.587| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3525be8
2014/11/27 01:15:23.587| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3525be8
2014/11/27 01:15:23.587| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.587| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x42f1, 1 answers
2014/11/27 01:15:23.587| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.587| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.246'
2014/11/27 01:15:23.587| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.246' NOT found
2014/11/27 01:15:23.587| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.246' == 212.42.76.246
2014/11/27 01:15:23.587| DomainData.cc(106) match: aclMatchDomainList: checking 'srv246.fwdcdn.com'
2014/11/27 01:15:23.587| DomainData.cc(110) match: aclMatchDomainList: 'srv246.fwdcdn.com' NOT found
2014/11/27 01:15:23.587| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.587| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.587| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62971' found
2014/11/27 01:15:23.587| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.587| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.587| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.587| Checklist.cc(61) markFinished: 0x352afa8 answer ALLOWED for match
2014/11/27 01:15:23.587| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x352afa8 answer=ALLOWED
2014/11/27 01:15:23.587| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33 method 5
2014/11/27 01:15:23.587| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33 timeout 300
2014/11/27 01:15:23.587| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.246
2014/11/27 01:15:23.588| client_side.cc(3827) httpsEstablish: local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.588| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.588| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x352afa8
2014/11/27 01:15:23.588| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x352afa8
2014/11/27 01:15:23.588| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 75 bytes from 8.8.8.8:53
2014/11/27 01:15:23.588| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x1dfd, 1 answers
2014/11/27 01:15:23.588| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '212.42.76.246'
2014/11/27 01:15:23.588| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 72 bytes from 8.8.8.8:53
2014/11/27 01:15:23.588| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x1ba, 1 answers
2014/11/27 01:15:23.588| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '81.222.128.22'
2014/11/27 01:15:23.588| DomainData.cc(106) match: aclMatchDomainList: checking '81.222.128.22'
2014/11/27 01:15:23.588| DomainData.cc(110) match: aclMatchDomainList: '81.222.128.22' NOT found
2014/11/27 01:15:23.588| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '81.222.128.22' == 81.222.128.22
2014/11/27 01:15:23.588| DomainData.cc(106) match: aclMatchDomainList: checking 'lb1.adriver.ru'
2014/11/27 01:15:23.588| DomainData.cc(110) match: aclMatchDomainList: 'lb1.adriver.ru' NOT found
2014/11/27 01:15:23.588| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.588| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.588| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62972' found
2014/11/27 01:15:23.588| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.588| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.588| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.588| Checklist.cc(61) markFinished: 0x3530368 answer ALLOWED for match
2014/11/27 01:15:23.588| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3530368 answer=ALLOWED
2014/11/27 01:15:23.588| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33 method 5
2014/11/27 01:15:23.588| comm.cc(548) commSetConnTimeout: local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33 timeout 300
2014/11/27 01:15:23.588| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 81.222.128.22
2014/11/27 01:15:23.588| client_side.cc(3827) httpsEstablish: local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.589| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.589| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3530368
2014/11/27 01:15:23.589| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3530368
2014/11/27 01:15:23.589| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 72 bytes from 8.8.8.8:53
2014/11/27 01:15:23.589| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0xbf30, 1 answers
2014/11/27 01:15:23.589| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '81.222.128.22'
2014/11/27 01:15:23.589| Read.cc(143) HandleRead: FD 11, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 11 flags=1 (0, 0)
2014/11/27 01:15:23.589| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350) [call35]
2014/11/27 01:15:23.589| Read.cc(143) HandleRead: FD 13, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 13 flags=1 (0, 0)
2014/11/27 01:15:23.589| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 13 flags=1, data=0x2f73378, size=1690, buf=0x2f73920) [call6]
2014/11/27 01:15:23.589| Read.cc(143) HandleRead: FD 15, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 15 flags=1 (0, 0)
2014/11/27 01:15:23.589| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 15 flags=1, data=0x2f749d8, size=1690, buf=0x2f74ef0) [call9]
2014/11/27 01:15:23.589| Read.cc(143) HandleRead: FD 17, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 17 flags=1 (0, 0)
2014/11/27 01:15:23.589| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 17 flags=1, data=0x2f75f18, size=1690, buf=0x2f76350) [call12]
2014/11/27 01:15:23.589| Read.cc(143) HandleRead: FD 48, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 48 flags=1 (0, 0)
2014/11/27 01:15:23.589| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 48 flags=1, data=0x353f2d8, size=1694, buf=0x3541510) [call136]
2014/11/27 01:15:23.589| Read.cc(143) HandleRead: FD 50, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 50 flags=1 (0, 0)
2014/11/27 01:15:23.589| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 50 flags=1, data=0x3546ad8, size=1694, buf=0x3544d20) [call141]
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 47 flags=1 (0, 0)
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 51 flags=1 (0, 0)
2014/11/27 01:15:23.589| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 53 flags=1 (0, 0)
2014/11/27 01:15:23.590| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 55 flags=1 (0, 0)
2014/11/27 01:15:23.590| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 57 flags=1 (0, 0)
2014/11/27 01:15:23.590| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 59 flags=1 (0, 0)
2014/11/27 01:15:23.590| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 61 flags=1 (0, 0)
2014/11/27 01:15:23.590| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350)
2014/11/27 01:15:23.590| AsyncCall.cc(38) make: make call helperHandleRead [call35]
2014/11/27 01:15:23.590| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.590| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.590| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.590| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.597| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33 timeout 300
2014/11/27 01:15:23.598| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.598| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3627bf0 [call188]
2014/11/27 01:15:23.598| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350)
2014/11/27 01:15:23.598| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 13 flags=1, data=0x2f73378, size=1690, buf=0x2f73920)
2014/11/27 01:15:23.598| AsyncCall.cc(38) make: make call helperHandleRead [call6]
2014/11/27 01:15:23.598| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.598| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.598| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.598| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.605| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33 timeout 300
2014/11/27 01:15:23.605| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.605| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3713400 [call191]
2014/11/27 01:15:23.605| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 13 flags=1, data=0x2f73378, size=1690, buf=0x2f73920)
2014/11/27 01:15:23.605| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 15 flags=1, data=0x2f749d8, size=1690, buf=0x2f74ef0)
2014/11/27 01:15:23.605| AsyncCall.cc(38) make: make call helperHandleRead [call9]
2014/11/27 01:15:23.605| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.605| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.605| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.605| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.613| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33 timeout 300
2014/11/27 01:15:23.613| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.613| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x37fe950 [call194]
2014/11/27 01:15:23.613| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 15 flags=1, data=0x2f749d8, size=1690, buf=0x2f74ef0)
2014/11/27 01:15:23.613| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 17 flags=1, data=0x2f75f18, size=1690, buf=0x2f76350)
2014/11/27 01:15:23.613| AsyncCall.cc(38) make: make call helperHandleRead [call12]
2014/11/27 01:15:23.613| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.613| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.613| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.613| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.621| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33 timeout 300
2014/11/27 01:15:23.621| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.621| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x38ea150 [call197]
2014/11/27 01:15:23.621| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 17 flags=1, data=0x2f75f18, size=1690, buf=0x2f76350)
2014/11/27 01:15:23.621| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 48 flags=1, data=0x353f2d8, size=1694, buf=0x3541510)
2014/11/27 01:15:23.621| AsyncCall.cc(38) make: make call helperHandleRead [call136]
2014/11/27 01:15:23.621| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.621| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.621| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.621| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.628| comm.cc(548) commSetConnTimeout: local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33 timeout 300
2014/11/27 01:15:23.628| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.628| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x353e560 [call200]
2014/11/27 01:15:23.628| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 48 flags=1, data=0x353f2d8, size=1694, buf=0x3541510)
2014/11/27 01:15:23.628| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 50 flags=1, data=0x3546ad8, size=1694, buf=0x3544d20)
2014/11/27 01:15:23.628| AsyncCall.cc(38) make: make call helperHandleRead [call141]
2014/11/27 01:15:23.629| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.629| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.629| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.629| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.636| comm.cc(548) commSetConnTimeout: local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33 timeout 300
2014/11/27 01:15:23.636| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.636| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3ac1080 [call203]
2014/11/27 01:15:23.636| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 50 flags=1, data=0x3546ad8, size=1694, buf=0x3544d20)
2014/11/27 01:15:23.637| dns_internal.cc(1281) idnsRead: idnsRead: starting with FD 10
2014/11/27 01:15:23.637| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 72 bytes from 8.8.8.8:53
2014/11/27 01:15:23.637| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x35a6, 1 answers
2014/11/27 01:15:23.637| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '81.222.128.22'
2014/11/27 01:15:23.637| DomainData.cc(106) match: aclMatchDomainList: checking '81.222.128.22'
2014/11/27 01:15:23.637| DomainData.cc(110) match: aclMatchDomainList: '81.222.128.22' NOT found
2014/11/27 01:15:23.637| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '81.222.128.22' == 81.222.128.22
2014/11/27 01:15:23.637| DomainData.cc(106) match: aclMatchDomainList: checking 'lb1.adriver.ru'
2014/11/27 01:15:23.637| DomainData.cc(110) match: aclMatchDomainList: 'lb1.adriver.ru' NOT found
2014/11/27 01:15:23.637| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:23.637| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rule) = 0
2014/11/27 01:15:23.637| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62973' found
2014/11/27 01:15:23.637| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:23.637| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:23.637| InnerNode.cc(97) resumeMatchingAt: checked: (ssl_bump rules) = 1
2014/11/27 01:15:23.637| Checklist.cc(61) markFinished: 0x3535728 answer ALLOWED for match
2014/11/27 01:15:23.637| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3535728 answer=ALLOWED
2014/11/27 01:15:23.637| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33 method 5
2014/11/27 01:15:23.637| comm.cc(548) commSetConnTimeout: local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33 timeout 300
2014/11/27 01:15:23.637| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 81.222.128.22
2014/11/27 01:15:23.637| client_side.cc(3827) httpsEstablish: local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:23.637| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.638| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3535728
2014/11/27 01:15:23.638| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3535728
2014/11/27 01:15:23.638| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 72 bytes from 8.8.8.8:53
2014/11/27 01:15:23.638| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x527b, 1 answers
2014/11/27 01:15:23.638| fqdncache.cc(342) fqdncacheParse: fqdncacheParse: 1 answers for '81.222.128.22'
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 11 flags=1 (0, 0)
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 13 flags=1 (0, 0)
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 15 flags=1 (0, 0)
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 17 flags=1 (0, 0)
2014/11/27 01:15:23.638| Read.cc(143) HandleRead: FD 19, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 19 flags=1 (0, 0)
2014/11/27 01:15:23.638| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 19 flags=1, data=0x2f77378, size=1694, buf=0x2f77600) [call15]
2014/11/27 01:15:23.638| Read.cc(143) HandleRead: FD 46, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 46 flags=1 (0, 0)
2014/11/27 01:15:23.638| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 46 flags=1, data=0x2fa7e88, size=1694, buf=0x3542580) [call131]
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 48 flags=1 (0, 0)
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 50 flags=1 (0, 0)
2014/11/27 01:15:23.638| Read.cc(143) HandleRead: FD 47, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.638| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 47 flags=1 (0, 0)
2014/11/27 01:15:23.638| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 47 flags=1, data=0x34cfb88, size=1690, buf=0x3547d20) [call146]
2014/11/27 01:15:23.638| Read.cc(143) HandleRead: FD 51, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.639| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 51 flags=1 (0, 0)
2014/11/27 01:15:23.639| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 51 flags=1, data=0x34e71e8, size=1690, buf=0x354ad20) [call151]
2014/11/27 01:15:23.639| Read.cc(143) HandleRead: FD 53, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.639| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 53 flags=1 (0, 0)
2014/11/27 01:15:23.639| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 53 flags=1, data=0x2fa8d78, size=1694, buf=0x354dd20) [call156]
2014/11/27 01:15:23.639| Read.cc(143) HandleRead: FD 55, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.639| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 55 flags=1 (0, 0)
2014/11/27 01:15:23.639| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 55 flags=1, data=0x34f18a8, size=1694, buf=0x3550d20) [call161]
2014/11/27 01:15:23.639| Read.cc(143) HandleRead: FD 57, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.639| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 57 flags=1 (0, 0)
2014/11/27 01:15:23.639| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 57 flags=1, data=0x354f738, size=1694, buf=0x3553d20) [call166]
2014/11/27 01:15:23.639| Read.cc(143) HandleRead: FD 59, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.639| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 59 flags=1 (0, 0)
2014/11/27 01:15:23.639| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 59 flags=1, data=0x354f9c8, size=1694, buf=0x3556d20) [call171]
2014/11/27 01:15:23.639| Read.cc(143) HandleRead: FD 61, size 4095, retval 1694, errno 0
2014/11/27 01:15:23.639| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 61 flags=1 (0, 0)
2014/11/27 01:15:23.639| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 61 flags=1, data=0x3549788, size=1694, buf=0x3559d20) [call176]
2014/11/27 01:15:23.640| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 19 flags=1, data=0x2f77378, size=1694, buf=0x2f77600)
2014/11/27 01:15:23.640| AsyncCall.cc(38) make: make call helperHandleRead [call15]
2014/11/27 01:15:23.640| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.640| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.640| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.640| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.647| comm.cc(548) commSetConnTimeout: local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33 timeout 300
2014/11/27 01:15:23.647| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.647| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3b3e920 [call208]
2014/11/27 01:15:23.647| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 19 flags=1, data=0x2f77378, size=1694, buf=0x2f77600)
2014/11/27 01:15:23.648| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 46 flags=1, data=0x2fa7e88, size=1694, buf=0x3542580)
2014/11/27 01:15:23.648| AsyncCall.cc(38) make: make call helperHandleRead [call131]
2014/11/27 01:15:23.648| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.648| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.648| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.648| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.655| comm.cc(548) commSetConnTimeout: local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33 timeout 300
2014/11/27 01:15:23.655| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.655| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3cef0e0 [call211]
2014/11/27 01:15:23.655| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 46 flags=1, data=0x2fa7e88, size=1694, buf=0x3542580)
2014/11/27 01:15:23.655| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 47 flags=1, data=0x34cfb88, size=1690, buf=0x3547d20)
2014/11/27 01:15:23.655| AsyncCall.cc(38) make: make call helperHandleRead [call146]
2014/11/27 01:15:23.655| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.655| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.655| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.655| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.663| comm.cc(548) commSetConnTimeout: local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33 timeout 300
2014/11/27 01:15:23.663| helper.cc(1200) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is overloaded!
2014/11/27 01:15:23.663| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3540f60 [call214]
2014/11/27 01:15:23.663| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 47 flags=1, data=0x34cfb88, size=1690, buf=0x3547d20)
2014/11/27 01:15:23.663| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 51 flags=1, data=0x34e71e8, size=1690, buf=0x354ad20)
2014/11/27 01:15:23.663| AsyncCall.cc(38) make: make call helperHandleRead [call151]
2014/11/27 01:15:23.663| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.663| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.663| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.663| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.671| comm.cc(548) commSetConnTimeout: local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33 timeout 300
2014/11/27 01:15:23.671| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x353f1c0 [call216]
2014/11/27 01:15:23.671| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 51 flags=1, data=0x34e71e8, size=1690, buf=0x354ad20)
2014/11/27 01:15:23.671| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 53 flags=1, data=0x2fa8d78, size=1694, buf=0x354dd20)
2014/11/27 01:15:23.671| AsyncCall.cc(38) make: make call helperHandleRead [call156]
2014/11/27 01:15:23.671| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.671| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.671| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.671| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.678| comm.cc(548) commSetConnTimeout: local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33 timeout 300
2014/11/27 01:15:23.678| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x33d04f0 [call218]
2014/11/27 01:15:23.678| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 53 flags=1, data=0x2fa8d78, size=1694, buf=0x354dd20)
2014/11/27 01:15:23.678| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 55 flags=1, data=0x34f18a8, size=1694, buf=0x3550d20)
2014/11/27 01:15:23.678| AsyncCall.cc(38) make: make call helperHandleRead [call161]
2014/11/27 01:15:23.678| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.678| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.678| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.678| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.686| comm.cc(548) commSetConnTimeout: local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33 timeout 300
2014/11/27 01:15:23.686| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x354fbb0 [call220]
2014/11/27 01:15:23.686| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 55 flags=1, data=0x34f18a8, size=1694, buf=0x3550d20)
2014/11/27 01:15:23.686| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 57 flags=1, data=0x354f738, size=1694, buf=0x3553d20)
2014/11/27 01:15:23.686| AsyncCall.cc(38) make: make call helperHandleRead [call166]
2014/11/27 01:15:23.686| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.686| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.686| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.686| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.693| comm.cc(548) commSetConnTimeout: local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33 timeout 300
2014/11/27 01:15:23.693| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x4187e40 [call222]
2014/11/27 01:15:23.693| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 57 flags=1, data=0x354f738, size=1694, buf=0x3553d20)
2014/11/27 01:15:23.693| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 59 flags=1, data=0x354f9c8, size=1694, buf=0x3556d20)
2014/11/27 01:15:23.693| AsyncCall.cc(38) make: make call helperHandleRead [call171]
2014/11/27 01:15:23.693| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.693| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.694| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.694| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.701| comm.cc(548) commSetConnTimeout: local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33 timeout 300
2014/11/27 01:15:23.701| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x42735f0 [call224]
2014/11/27 01:15:23.701| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 59 flags=1, data=0x354f9c8, size=1694, buf=0x3556d20)
2014/11/27 01:15:23.701| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 61 flags=1, data=0x3549788, size=1694, buf=0x3559d20)
2014/11/27 01:15:23.701| AsyncCall.cc(38) make: make call helperHandleRead [call176]
2014/11/27 01:15:23.701| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.701| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.701| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.701| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.708| comm.cc(548) commSetConnTimeout: local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33 timeout 300
2014/11/27 01:15:23.708| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x35496e0 [call226]
2014/11/27 01:15:23.709| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 61 flags=1, data=0x3549788, size=1694, buf=0x3559d20)
2014/11/27 01:15:23.709| Read.cc(143) HandleRead: FD 11, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 11 flags=1 (0, 0)
2014/11/27 01:15:23.709| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350) [call188]
2014/11/27 01:15:23.709| Read.cc(143) HandleRead: FD 13, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 13 flags=1 (0, 0)
2014/11/27 01:15:23.709| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 13 flags=1, data=0x2f73378, size=1690, buf=0x2f73920) [call191]
2014/11/27 01:15:23.709| Read.cc(143) HandleRead: FD 15, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 15 flags=1 (0, 0)
2014/11/27 01:15:23.709| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 15 flags=1, data=0x2f749d8, size=1690, buf=0x2f74ef0) [call194]
2014/11/27 01:15:23.709| Read.cc(143) HandleRead: FD 17, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 17 flags=1 (0, 0)
2014/11/27 01:15:23.709| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 17 flags=1, data=0x2f75f18, size=1690, buf=0x2f76350) [call197]
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 19 flags=1 (0, 0)
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 46 flags=1 (0, 0)
2014/11/27 01:15:23.709| Read.cc(143) HandleRead: FD 48, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 48 flags=1 (0, 0)
2014/11/27 01:15:23.709| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 48 flags=1, data=0x353f2d8, size=1690, buf=0x3541510) [call200]
2014/11/27 01:15:23.709| Read.cc(143) HandleRead: FD 50, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 50 flags=1 (0, 0)
2014/11/27 01:15:23.709| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 50 flags=1, data=0x3546ad8, size=1690, buf=0x3544d20) [call203]
2014/11/27 01:15:23.709| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 47 flags=1 (0, 0)
2014/11/27 01:15:23.711| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350)
2014/11/27 01:15:23.711| AsyncCall.cc(38) make: make call helperHandleRead [call188]
2014/11/27 01:15:23.711| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.711| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.711| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.711| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.718| comm.cc(548) commSetConnTimeout: local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33 timeout 300
2014/11/27 01:15:23.718| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x33ce1e0 [call228]
2014/11/27 01:15:23.718| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 11 flags=1, data=0x2f70348, size=1690, buf=0x2f72350)
2014/11/27 01:15:23.718| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 13 flags=1, data=0x2f73378, size=1690, buf=0x2f73920)
2014/11/27 01:15:23.718| AsyncCall.cc(38) make: make call helperHandleRead [call191]
2014/11/27 01:15:23.718| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.718| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.718| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.718| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.726| comm.cc(548) commSetConnTimeout: local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33 timeout 300
2014/11/27 01:15:23.726| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x3499370 [call230]
2014/11/27 01:15:23.726| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 13 flags=1, data=0x2f73378, size=1690, buf=0x2f73920)
2014/11/27 01:15:23.726| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 15 flags=1, data=0x2f749d8, size=1690, buf=0x2f74ef0)
2014/11/27 01:15:23.726| AsyncCall.cc(38) make: make call helperHandleRead [call194]
2014/11/27 01:15:23.726| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.726| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.726| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.726| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.733| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33 timeout 300
2014/11/27 01:15:23.733| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x353a210 [call232]
2014/11/27 01:15:23.733| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 15 flags=1, data=0x2f749d8, size=1690, buf=0x2f74ef0)
2014/11/27 01:15:23.733| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 17 flags=1, data=0x2f75f18, size=1690, buf=0x2f76350)
2014/11/27 01:15:23.733| AsyncCall.cc(38) make: make call helperHandleRead [call197]
2014/11/27 01:15:23.733| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.733| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.733| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.733| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.741| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33 timeout 300
2014/11/27 01:15:23.741| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x35466a0 [call234]
2014/11/27 01:15:23.741| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 17 flags=1, data=0x2f75f18, size=1690, buf=0x2f76350)
2014/11/27 01:15:23.741| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 48 flags=1, data=0x353f2d8, size=1690, buf=0x3541510)
2014/11/27 01:15:23.741| AsyncCall.cc(38) make: make call helperHandleRead [call200]
2014/11/27 01:15:23.741| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.741| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.741| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.741| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.748| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33 timeout 300
2014/11/27 01:15:23.749| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x33cf160 [call236]
2014/11/27 01:15:23.749| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 48 flags=1, data=0x353f2d8, size=1690, buf=0x3541510)
2014/11/27 01:15:23.749| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 50 flags=1, data=0x3546ad8, size=1690, buf=0x3544d20)
2014/11/27 01:15:23.749| AsyncCall.cc(38) make: make call helperHandleRead [call203]
2014/11/27 01:15:23.749| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.749| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.749| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.749| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.756| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33 timeout 300
2014/11/27 01:15:23.756| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x353a330 [call238]
2014/11/27 01:15:23.756| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 50 flags=1, data=0x3546ad8, size=1690, buf=0x3544d20)
2014/11/27 01:15:23.756| Read.cc(143) HandleRead: FD 19, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.756| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 19 flags=1 (0, 0)
2014/11/27 01:15:23.756| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 19 flags=1, data=0x2f77378, size=1690, buf=0x2f77600) [call208]
2014/11/27 01:15:23.756| Read.cc(143) HandleRead: FD 46, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.756| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 46 flags=1 (0, 0)
2014/11/27 01:15:23.756| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 46 flags=1, data=0x2fa7e88, size=1690, buf=0x3542580) [call211]
2014/11/27 01:15:23.756| Read.cc(143) HandleRead: FD 47, size 4095, retval 1690, errno 0
2014/11/27 01:15:23.756| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 47 flags=1 (0, 0)
2014/11/27 01:15:23.756| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 47 flags=1, data=0x34cfb88, size=1690, buf=0x3547d20) [call214]
2014/11/27 01:15:23.758| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 19 flags=1, data=0x2f77378, size=1690, buf=0x2f77600)
2014/11/27 01:15:23.758| AsyncCall.cc(38) make: make call helperHandleRead [call208]
2014/11/27 01:15:23.758| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.758| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.758| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.758| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.766| comm.cc(548) commSetConnTimeout: local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33 timeout 300
2014/11/27 01:15:23.766| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x353b390 [call240]
2014/11/27 01:15:23.766| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 19 flags=1, data=0x2f77378, size=1690, buf=0x2f77600)
2014/11/27 01:15:23.766| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 46 flags=1, data=0x2fa7e88, size=1690, buf=0x3542580)
2014/11/27 01:15:23.766| AsyncCall.cc(38) make: make call helperHandleRead [call211]
2014/11/27 01:15:23.766| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.766| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.766| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.766| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.773| comm.cc(548) commSetConnTimeout: local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33 timeout 300
2014/11/27 01:15:23.773| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x4b93d20 [call242]
2014/11/27 01:15:23.773| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 46 flags=1, data=0x2fa7e88, size=1690, buf=0x3542580)
2014/11/27 01:15:23.773| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 47 flags=1, data=0x34cfb88, size=1690, buf=0x3547d20)
2014/11/27 01:15:23.773| AsyncCall.cc(38) make: make call helperHandleRead [call214]
2014/11/27 01:15:23.773| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2014/11/27 01:15:23.773| Reply.cc(29) parse: Parsing helper buffer
2014/11/27 01:15:23.773| Reply.cc(48) parse: Buff length is larger than 2
2014/11/27 01:15:23.773| Reply.cc(52) parse: helper Result = OK
2014/11/27 01:15:23.781| comm.cc(548) commSetConnTimeout: local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33 timeout 300
2014/11/27 01:15:23.781| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x34ec6b0 [call244]
2014/11/27 01:15:23.781| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 47 flags=1, data=0x34cfb88, size=1690, buf=0x3547d20)
2014/11/27 01:15:23.813| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x35662a0 on FD 28 (192.168.0.122:62956)
2014/11/27 01:15:23.813| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 28 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.813| client_side.cc(234) readSomeData: local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33: reading request...
2014/11/27 01:15:23.816| IoCallback.cc(116) finish: called for local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33 (0, 0)
2014/11/27 01:15:23.820| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x4cd5160 on FD 29 (192.168.0.122:62957)
2014/11/27 01:15:23.820| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 29 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.820| client_side.cc(234) readSomeData: local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33: reading request...
2014/11/27 01:15:23.820| Read.cc(91) ReadNow: local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.820| client_side.cc(2372) connFinishedWithConn: local=195.214.193.51:443 remote=192.168.0.122:62956 FD 28 flags=33 closed
2014/11/27 01:15:23.820| comm.cc(860) _comm_close: comm_close: start closing FD 28
2014/11/27 01:15:23.820| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x4ce1480 [call247]
2014/11/27 01:15:23.820| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 28) [call247]
2014/11/27 01:15:23.820| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 28
2014/11/27 01:15:23.821| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x4ce0e60 [call248]
2014/11/27 01:15:23.821| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 28) [call248]
2014/11/27 01:15:23.821| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 28)
2014/11/27 01:15:23.821| AsyncCall.cc(38) make: make call commStartSslClose [call247]
2014/11/27 01:15:23.821| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 28)
2014/11/27 01:15:23.821| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.821| client_side.cc(817) swanSong: local=195.214.193.51:443 remote=192.168.0.122:62956 flags=33
2014/11/27 01:15:23.821| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.821| client_side.cc(848) ~ConnStateData: local=195.214.193.51:443 remote=192.168.0.122:62956 flags=33
2014/11/27 01:15:23.821| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 28)
2014/11/27 01:15:23.821| AsyncCall.cc(38) make: make call comm_close_complete [call248]
2014/11/27 01:15:23.822| fd.cc(93) fd_close: fd_close FD 28 client https start
2014/11/27 01:15:23.822| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 28)
2014/11/27 01:15:23.823| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x4cd1e60 on FD 14 (192.168.0.122:62950)
2014/11/27 01:15:23.823| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 14 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.823| client_side.cc(234) readSomeData: local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33: reading request...
2014/11/27 01:15:23.824| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x3b24240 on FD 16 (192.168.0.122:62951)
2014/11/27 01:15:23.824| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 16 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.824| client_side.cc(234) readSomeData: local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33: reading request...
2014/11/27 01:15:23.825| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x3b25860 on FD 18 (192.168.0.122:62952)
2014/11/27 01:15:23.825| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 18 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.825| client_side.cc(234) readSomeData: local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33: reading request...
2014/11/27 01:15:23.825| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x3b26040 on FD 20 (192.168.0.122:62953)
2014/11/27 01:15:23.825| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 20 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.826| client_side.cc(234) readSomeData: local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33: reading request...
2014/11/27 01:15:23.828| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x4cdb880 on FD 34 (192.168.0.122:62962)
2014/11/27 01:15:23.828| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 34 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.828| client_side.cc(234) readSomeData: local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33: reading request...
2014/11/27 01:15:23.830| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x4cddf10 on FD 37 (192.168.0.122:62965)
2014/11/27 01:15:23.830| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 37 negotiated cipher AES128-SHA
2014/11/27 01:15:23.830| client_side.cc(234) readSomeData: local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33: reading request...
2014/11/27 01:15:23.831| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x4ce05a0 on FD 38 (192.168.0.122:62966)
2014/11/27 01:15:23.831| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 38 negotiated cipher AES128-SHA
2014/11/27 01:15:23.831| client_side.cc(234) readSomeData: local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33: reading request...
2014/11/27 01:15:23.833| IoCallback.cc(116) finish: called for local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33 (0, 0)
2014/11/27 01:15:23.833| Read.cc(91) ReadNow: local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.833| client_side.cc(2372) connFinishedWithConn: local=195.214.193.51:443 remote=192.168.0.122:62957 FD 29 flags=33 closed
2014/11/27 01:15:23.833| comm.cc(860) _comm_close: comm_close: start closing FD 29
2014/11/27 01:15:23.833| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x4c7f7f0 [call256]
2014/11/27 01:15:23.833| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 29) [call256]
2014/11/27 01:15:23.833| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 29
2014/11/27 01:15:23.833| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x355b030 [call257]
2014/11/27 01:15:23.833| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 29) [call257]
2014/11/27 01:15:23.833| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 29)
2014/11/27 01:15:23.833| AsyncCall.cc(38) make: make call commStartSslClose [call256]
2014/11/27 01:15:23.833| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 29)
2014/11/27 01:15:23.833| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.833| client_side.cc(817) swanSong: local=195.214.193.51:443 remote=192.168.0.122:62957 flags=33
2014/11/27 01:15:23.833| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.833| client_side.cc(848) ~ConnStateData: local=195.214.193.51:443 remote=192.168.0.122:62957 flags=33
2014/11/27 01:15:23.833| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 29)
2014/11/27 01:15:23.833| AsyncCall.cc(38) make: make call comm_close_complete [call257]
2014/11/27 01:15:23.833| fd.cc(93) fd_close: fd_close FD 29 client https start
2014/11/27 01:15:23.833| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 29)
2014/11/27 01:15:23.833| IoCallback.cc(116) finish: called for local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33 (0, 0)
2014/11/27 01:15:23.834| IoCallback.cc(116) finish: called for local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33 (0, 0)
2014/11/27 01:15:23.834| IoCallback.cc(116) finish: called for local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33 (0, 0)
2014/11/27 01:15:23.834| IoCallback.cc(116) finish: called for local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33 (0, 0)
2014/11/27 01:15:23.835| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x35662a0 on FD 30 (192.168.0.122:62958)
2014/11/27 01:15:23.835| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 30 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.836| client_side.cc(234) readSomeData: local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33: reading request...
2014/11/27 01:15:23.836| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x39a4780 on FD 31 (192.168.0.122:62959)
2014/11/27 01:15:23.836| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 31 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.836| client_side.cc(234) readSomeData: local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33: reading request...
2014/11/27 01:15:23.838| IoCallback.cc(116) finish: called for local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33 (0, 0)
2014/11/27 01:15:23.838| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x3966a70 on FD 36 (192.168.0.122:62964)
2014/11/27 01:15:23.839| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 36 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.839| client_side.cc(234) readSomeData: local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33: reading request...
2014/11/27 01:15:23.839| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x39ad090 on FD 35 (192.168.0.122:62963)
2014/11/27 01:15:23.839| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 35 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.839| client_side.cc(234) readSomeData: local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33: reading request...
2014/11/27 01:15:23.840| IoCallback.cc(116) finish: called for local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33 (0, 0)
2014/11/27 01:15:23.840| IoCallback.cc(116) finish: called for local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33 (0, 0)
2014/11/27 01:15:23.841| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x39ad990 on FD 44 (192.168.0.122:62972)
2014/11/27 01:15:23.841| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 44 negotiated cipher AES128-SHA
2014/11/27 01:15:23.841| client_side.cc(234) readSomeData: local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33: reading request...
2014/11/27 01:15:23.841| Read.cc(91) ReadNow: local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.841| client_side.cc(2372) connFinishedWithConn: local=212.42.76.253:443 remote=192.168.0.122:62950 FD 14 flags=33 closed
2014/11/27 01:15:23.841| comm.cc(860) _comm_close: comm_close: start closing FD 14
2014/11/27 01:15:23.841| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x4ce08e0 [call263]
2014/11/27 01:15:23.841| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 14) [call263]
2014/11/27 01:15:23.841| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 14
2014/11/27 01:15:23.841| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x39c7b60 [call264]
2014/11/27 01:15:23.841| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 14) [call264]
2014/11/27 01:15:23.842| Read.cc(91) ReadNow: local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.842| client_side.cc(2372) connFinishedWithConn: local=212.42.76.253:443 remote=192.168.0.122:62951 FD 16 flags=33 closed
2014/11/27 01:15:23.842| comm.cc(860) _comm_close: comm_close: start closing FD 16
2014/11/27 01:15:23.842| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x39d50b0 [call265]
2014/11/27 01:15:23.842| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 16) [call265]
2014/11/27 01:15:23.842| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 16
2014/11/27 01:15:23.842| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x39c7ae0 [call266]
2014/11/27 01:15:23.842| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 16) [call266]
2014/11/27 01:15:23.842| Read.cc(91) ReadNow: local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.842| client_side.cc(2372) connFinishedWithConn: local=212.42.76.253:443 remote=192.168.0.122:62952 FD 18 flags=33 closed
2014/11/27 01:15:23.842| comm.cc(860) _comm_close: comm_close: start closing FD 18
2014/11/27 01:15:23.842| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x39c75d0 [call267]
2014/11/27 01:15:23.842| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 18) [call267]
2014/11/27 01:15:23.842| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 18
2014/11/27 01:15:23.842| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x39e9330 [call268]
2014/11/27 01:15:23.842| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 18) [call268]
2014/11/27 01:15:23.842| Read.cc(91) ReadNow: local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.842| client_side.cc(2372) connFinishedWithConn: local=212.42.76.253:443 remote=192.168.0.122:62953 FD 20 flags=33 closed
2014/11/27 01:15:23.842| comm.cc(860) _comm_close: comm_close: start closing FD 20
2014/11/27 01:15:23.842| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x39260c0 [call269]
2014/11/27 01:15:23.842| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 20) [call269]
2014/11/27 01:15:23.842| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 20
2014/11/27 01:15:23.842| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x39a4af0 [call270]
2014/11/27 01:15:23.842| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 20) [call270]
2014/11/27 01:15:23.843| Read.cc(91) ReadNow: local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.843| client_side.cc(2372) connFinishedWithConn: local=173.194.113.94:443 remote=192.168.0.122:62962 FD 34 flags=33 closed
2014/11/27 01:15:23.843| comm.cc(860) _comm_close: comm_close: start closing FD 34
2014/11/27 01:15:23.843| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x3713370 [call271]
2014/11/27 01:15:23.843| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 34) [call271]
2014/11/27 01:15:23.843| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 34
2014/11/27 01:15:23.843| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x38ea0c0 [call272]
2014/11/27 01:15:23.843| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 34) [call272]
2014/11/27 01:15:23.843| Read.cc(91) ReadNow: local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.843| client_side.cc(2372) connFinishedWithConn: local=185.26.97.139:443 remote=192.168.0.122:62965 FD 37 flags=33 closed
2014/11/27 01:15:23.843| comm.cc(860) _comm_close: comm_close: start closing FD 37
2014/11/27 01:15:23.843| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x3627840 [call273]
2014/11/27 01:15:23.843| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 37) [call273]
2014/11/27 01:15:23.843| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 37
2014/11/27 01:15:23.843| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x37fe8c0 [call274]
2014/11/27 01:15:23.843| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 37) [call274]
2014/11/27 01:15:23.843| Read.cc(91) ReadNow: local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.843| client_side.cc(2372) connFinishedWithConn: local=185.26.97.139:443 remote=192.168.0.122:62966 FD 38 flags=33 closed
2014/11/27 01:15:23.843| comm.cc(860) _comm_close: comm_close: start closing FD 38
2014/11/27 01:15:23.843| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x44ccf80 [call275]
2014/11/27 01:15:23.843| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 38) [call275]
2014/11/27 01:15:23.843| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 38
2014/11/27 01:15:23.843| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x4187d30 [call276]
2014/11/27 01:15:23.843| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 38) [call276]
2014/11/27 01:15:23.843| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 14)
2014/11/27 01:15:23.843| AsyncCall.cc(38) make: make call commStartSslClose [call263]
2014/11/27 01:15:23.843| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 14)
2014/11/27 01:15:23.844| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.844| client_side.cc(817) swanSong: local=212.42.76.253:443 remote=192.168.0.122:62950 flags=33
2014/11/27 01:15:23.844| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.844| client_side.cc(848) ~ConnStateData: local=212.42.76.253:443 remote=192.168.0.122:62950 flags=33
2014/11/27 01:15:23.844| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 14)
2014/11/27 01:15:23.844| AsyncCall.cc(38) make: make call comm_close_complete [call264]
2014/11/27 01:15:23.844| fd.cc(93) fd_close: fd_close FD 14 client https start
2014/11/27 01:15:23.844| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 14)
2014/11/27 01:15:23.844| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 16)
2014/11/27 01:15:23.844| AsyncCall.cc(38) make: make call commStartSslClose [call265]
2014/11/27 01:15:23.845| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 16)
2014/11/27 01:15:23.845| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.845| client_side.cc(817) swanSong: local=212.42.76.253:443 remote=192.168.0.122:62951 flags=33
2014/11/27 01:15:23.845| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.845| client_side.cc(848) ~ConnStateData: local=212.42.76.253:443 remote=192.168.0.122:62951 flags=33
2014/11/27 01:15:23.845| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 16)
2014/11/27 01:15:23.845| AsyncCall.cc(38) make: make call comm_close_complete [call266]
2014/11/27 01:15:23.845| fd.cc(93) fd_close: fd_close FD 16 client https start
2014/11/27 01:15:23.846| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 16)
2014/11/27 01:15:23.846| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 18)
2014/11/27 01:15:23.846| AsyncCall.cc(38) make: make call commStartSslClose [call267]
2014/11/27 01:15:23.846| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 18)
2014/11/27 01:15:23.846| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.846| client_side.cc(817) swanSong: local=212.42.76.253:443 remote=192.168.0.122:62952 flags=33
2014/11/27 01:15:23.846| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.846| client_side.cc(848) ~ConnStateData: local=212.42.76.253:443 remote=192.168.0.122:62952 flags=33
2014/11/27 01:15:23.846| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 18)
2014/11/27 01:15:23.846| AsyncCall.cc(38) make: make call comm_close_complete [call268]
2014/11/27 01:15:23.847| fd.cc(93) fd_close: fd_close FD 18 client https start
2014/11/27 01:15:23.847| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 18)
2014/11/27 01:15:23.847| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 20)
2014/11/27 01:15:23.847| AsyncCall.cc(38) make: make call commStartSslClose [call269]
2014/11/27 01:15:23.847| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 20)
2014/11/27 01:15:23.847| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.847| client_side.cc(817) swanSong: local=212.42.76.253:443 remote=192.168.0.122:62953 flags=33
2014/11/27 01:15:23.847| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.847| client_side.cc(848) ~ConnStateData: local=212.42.76.253:443 remote=192.168.0.122:62953 flags=33
2014/11/27 01:15:23.847| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 20)
2014/11/27 01:15:23.847| AsyncCall.cc(38) make: make call comm_close_complete [call270]
2014/11/27 01:15:23.847| fd.cc(93) fd_close: fd_close FD 20 client https start
2014/11/27 01:15:23.847| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 20)
2014/11/27 01:15:23.847| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 34)
2014/11/27 01:15:23.847| AsyncCall.cc(38) make: make call commStartSslClose [call271]
2014/11/27 01:15:23.847| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 34)
2014/11/27 01:15:23.847| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.847| client_side.cc(817) swanSong: local=173.194.113.94:443 remote=192.168.0.122:62962 flags=33
2014/11/27 01:15:23.847| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.847| client_side.cc(848) ~ConnStateData: local=173.194.113.94:443 remote=192.168.0.122:62962 flags=33
2014/11/27 01:15:23.847| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 34)
2014/11/27 01:15:23.847| AsyncCall.cc(38) make: make call comm_close_complete [call272]
2014/11/27 01:15:23.847| fd.cc(93) fd_close: fd_close FD 34 client https start
2014/11/27 01:15:23.847| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 34)
2014/11/27 01:15:23.847| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 37)
2014/11/27 01:15:23.847| AsyncCall.cc(38) make: make call commStartSslClose [call273]
2014/11/27 01:15:23.847| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 37)
2014/11/27 01:15:23.848| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.848| client_side.cc(817) swanSong: local=185.26.97.139:443 remote=192.168.0.122:62965 flags=33
2014/11/27 01:15:23.848| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.848| client_side.cc(848) ~ConnStateData: local=185.26.97.139:443 remote=192.168.0.122:62965 flags=33
2014/11/27 01:15:23.848| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 37)
2014/11/27 01:15:23.848| AsyncCall.cc(38) make: make call comm_close_complete [call274]
2014/11/27 01:15:23.849| fd.cc(93) fd_close: fd_close FD 37 client https start
2014/11/27 01:15:23.849| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 37)
2014/11/27 01:15:23.849| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 38)
2014/11/27 01:15:23.849| AsyncCall.cc(38) make: make call commStartSslClose [call275]
2014/11/27 01:15:23.849| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 38)
2014/11/27 01:15:23.850| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.850| client_side.cc(817) swanSong: local=185.26.97.139:443 remote=192.168.0.122:62966 flags=33
2014/11/27 01:15:23.850| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.850| client_side.cc(848) ~ConnStateData: local=185.26.97.139:443 remote=192.168.0.122:62966 flags=33
2014/11/27 01:15:23.850| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 38)
2014/11/27 01:15:23.850| AsyncCall.cc(38) make: make call comm_close_complete [call276]
2014/11/27 01:15:23.850| fd.cc(93) fd_close: fd_close FD 38 client https start
2014/11/27 01:15:23.850| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 38)
2014/11/27 01:15:23.851| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x4ce1580 on FD 23 (192.168.0.122:62954)
2014/11/27 01:15:23.851| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 23 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.851| client_side.cc(234) readSomeData: local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33: reading request...
2014/11/27 01:15:23.852| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x3ac0a20 on FD 27 (192.168.0.122:62955)
2014/11/27 01:15:23.852| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 27 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.852| client_side.cc(234) readSomeData: local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33: reading request...
2014/11/27 01:15:23.852| IoCallback.cc(116) finish: called for local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33 (0, 0)
2014/11/27 01:15:23.852| IoCallback.cc(116) finish: called for local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33 (0, 0)
2014/11/27 01:15:23.853| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x3910db0 on FD 32 (192.168.0.122:62960)
2014/11/27 01:15:23.853| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 32 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.853| client_side.cc(234) readSomeData: local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33: reading request...
2014/11/27 01:15:23.853| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x39744d0 on FD 33 (192.168.0.122:62961)
2014/11/27 01:15:23.854| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 33 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.854| client_side.cc(234) readSomeData: local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33: reading request...
2014/11/27 01:15:23.854| IoCallback.cc(116) finish: called for local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33 (0, 0)
2014/11/27 01:15:23.854| IoCallback.cc(116) finish: called for local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33 (0, 0)
2014/11/27 01:15:23.856| IoCallback.cc(116) finish: called for local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33 (0, 0)
2014/11/27 01:15:23.857| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x39f6ab0 on FD 45 (192.168.0.122:62973)
2014/11/27 01:15:23.857| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 45 negotiated cipher AES128-SHA
2014/11/27 01:15:23.857| client_side.cc(234) readSomeData: local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33: reading request...
2014/11/27 01:15:23.857| Read.cc(91) ReadNow: local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.857| client_side.cc(2372) connFinishedWithConn: local=212.42.77.249:443 remote=192.168.0.122:62958 FD 30 flags=33 closed
2014/11/27 01:15:23.857| comm.cc(860) _comm_close: comm_close: start closing FD 30
2014/11/27 01:15:23.857| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x4ce0960 [call282]
2014/11/27 01:15:23.857| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 30) [call282]
2014/11/27 01:15:23.857| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 30
2014/11/27 01:15:23.857| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x38ea1e0 [call283]
2014/11/27 01:15:23.857| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 30) [call283]
2014/11/27 01:15:23.858| Read.cc(91) ReadNow: local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.858| client_side.cc(2372) connFinishedWithConn: local=212.42.77.249:443 remote=192.168.0.122:62959 FD 31 flags=33 closed
2014/11/27 01:15:23.858| comm.cc(860) _comm_close: comm_close: start closing FD 31
2014/11/27 01:15:23.858| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x39ad4e0 [call284]
2014/11/27 01:15:23.858| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 31) [call284]
2014/11/27 01:15:23.858| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 31
2014/11/27 01:15:23.858| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3499230 [call285]
2014/11/27 01:15:23.858| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 31) [call285]
2014/11/27 01:15:23.858| Read.cc(91) ReadNow: local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.858| client_side.cc(2372) connFinishedWithConn: local=195.214.194.27:443 remote=192.168.0.122:62964 FD 36 flags=33 closed
2014/11/27 01:15:23.858| comm.cc(860) _comm_close: comm_close: start closing FD 36
2014/11/27 01:15:23.858| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x34ec4d0 [call286]
2014/11/27 01:15:23.858| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 36) [call286]
2014/11/27 01:15:23.858| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 36
2014/11/27 01:15:23.858| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3506ac0 [call287]
2014/11/27 01:15:23.858| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 36) [call287]
2014/11/27 01:15:23.858| Read.cc(91) ReadNow: local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.858| client_side.cc(2372) connFinishedWithConn: local=195.214.194.27:443 remote=192.168.0.122:62963 FD 35 flags=33 closed
2014/11/27 01:15:23.858| comm.cc(860) _comm_close: comm_close: start closing FD 35
2014/11/27 01:15:23.858| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x4ce0e60 [call288]
2014/11/27 01:15:23.858| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 35) [call288]
2014/11/27 01:15:23.858| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 35
2014/11/27 01:15:23.858| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x42734e0 [call289]
2014/11/27 01:15:23.858| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 35) [call289]
2014/11/27 01:15:23.859| Read.cc(91) ReadNow: local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.859| client_side.cc(2372) connFinishedWithConn: local=81.222.128.22:443 remote=192.168.0.122:62972 FD 44 flags=33 closed
2014/11/27 01:15:23.859| comm.cc(860) _comm_close: comm_close: start closing FD 44
2014/11/27 01:15:23.859| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x39a4b80 [call290]
2014/11/27 01:15:23.859| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 44) [call290]
2014/11/27 01:15:23.859| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 44
2014/11/27 01:15:23.859| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34d10a0 [call291]
2014/11/27 01:15:23.859| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 44) [call291]
2014/11/27 01:15:23.859| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 30)
2014/11/27 01:15:23.859| AsyncCall.cc(38) make: make call commStartSslClose [call282]
2014/11/27 01:15:23.859| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 30)
2014/11/27 01:15:23.859| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.859| client_side.cc(817) swanSong: local=212.42.77.249:443 remote=192.168.0.122:62958 flags=33
2014/11/27 01:15:23.859| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.859| client_side.cc(848) ~ConnStateData: local=212.42.77.249:443 remote=192.168.0.122:62958 flags=33
2014/11/27 01:15:23.859| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 30)
2014/11/27 01:15:23.859| AsyncCall.cc(38) make: make call comm_close_complete [call283]
2014/11/27 01:15:23.860| fd.cc(93) fd_close: fd_close FD 30 client https start
2014/11/27 01:15:23.860| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 30)
2014/11/27 01:15:23.860| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 31)
2014/11/27 01:15:23.860| AsyncCall.cc(38) make: make call commStartSslClose [call284]
2014/11/27 01:15:23.860| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 31)
2014/11/27 01:15:23.860| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.860| client_side.cc(817) swanSong: local=212.42.77.249:443 remote=192.168.0.122:62959 flags=33
2014/11/27 01:15:23.860| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.860| client_side.cc(848) ~ConnStateData: local=212.42.77.249:443 remote=192.168.0.122:62959 flags=33
2014/11/27 01:15:23.860| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 31)
2014/11/27 01:15:23.860| AsyncCall.cc(38) make: make call comm_close_complete [call285]
2014/11/27 01:15:23.860| fd.cc(93) fd_close: fd_close FD 31 client https start
2014/11/27 01:15:23.860| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 31)
2014/11/27 01:15:23.860| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 36)
2014/11/27 01:15:23.860| AsyncCall.cc(38) make: make call commStartSslClose [call286]
2014/11/27 01:15:23.860| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 36)
2014/11/27 01:15:23.860| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.860| client_side.cc(817) swanSong: local=195.214.194.27:443 remote=192.168.0.122:62964 flags=33
2014/11/27 01:15:23.860| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.860| client_side.cc(848) ~ConnStateData: local=195.214.194.27:443 remote=192.168.0.122:62964 flags=33
2014/11/27 01:15:23.861| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 36)
2014/11/27 01:15:23.861| AsyncCall.cc(38) make: make call comm_close_complete [call287]
2014/11/27 01:15:23.861| fd.cc(93) fd_close: fd_close FD 36 client https start
2014/11/27 01:15:23.861| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 36)
2014/11/27 01:15:23.861| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 35)
2014/11/27 01:15:23.861| AsyncCall.cc(38) make: make call commStartSslClose [call288]
2014/11/27 01:15:23.861| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 35)
2014/11/27 01:15:23.861| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.861| client_side.cc(817) swanSong: local=195.214.194.27:443 remote=192.168.0.122:62963 flags=33
2014/11/27 01:15:23.861| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.861| client_side.cc(848) ~ConnStateData: local=195.214.194.27:443 remote=192.168.0.122:62963 flags=33
2014/11/27 01:15:23.862| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 35)
2014/11/27 01:15:23.862| AsyncCall.cc(38) make: make call comm_close_complete [call289]
2014/11/27 01:15:23.862| fd.cc(93) fd_close: fd_close FD 35 client https start
2014/11/27 01:15:23.862| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 35)
2014/11/27 01:15:23.862| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 44)
2014/11/27 01:15:23.862| AsyncCall.cc(38) make: make call commStartSslClose [call290]
2014/11/27 01:15:23.862| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 44)
2014/11/27 01:15:23.862| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.862| client_side.cc(817) swanSong: local=81.222.128.22:443 remote=192.168.0.122:62972 flags=33
2014/11/27 01:15:23.862| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.862| client_side.cc(848) ~ConnStateData: local=81.222.128.22:443 remote=192.168.0.122:62972 flags=33
2014/11/27 01:15:23.862| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 44)
2014/11/27 01:15:23.862| AsyncCall.cc(38) make: make call comm_close_complete [call291]
2014/11/27 01:15:23.863| fd.cc(93) fd_close: fd_close FD 44 client https start
2014/11/27 01:15:23.864| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 44)
2014/11/27 01:15:23.864| IoCallback.cc(116) finish: called for local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33 (0, 0)
2014/11/27 01:15:23.864| IoCallback.cc(116) finish: called for local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33 (0, 0)
2014/11/27 01:15:23.864| IoCallback.cc(116) finish: called for local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33 (0, 0)
2014/11/27 01:15:23.864| IoCallback.cc(116) finish: called for local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33 (0, 0)
2014/11/27 01:15:23.864| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x44540e0 on FD 39 (192.168.0.122:62967)
2014/11/27 01:15:23.864| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 39 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.864| client_side.cc(234) readSomeData: local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33: reading request...
2014/11/27 01:15:23.865| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x3785880 on FD 40 (192.168.0.122:62968)
2014/11/27 01:15:23.865| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 40 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.865| client_side.cc(234) readSomeData: local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33: reading request...
2014/11/27 01:15:23.866| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x44cc8e0 on FD 41 (192.168.0.122:62969)
2014/11/27 01:15:23.866| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 41 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.866| client_side.cc(234) readSomeData: local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33: reading request...
2014/11/27 01:15:23.867| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x37fe030 on FD 42 (192.168.0.122:62970)
2014/11/27 01:15:23.867| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 42 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.867| client_side.cc(234) readSomeData: local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33: reading request...
2014/11/27 01:15:23.868| IoCallback.cc(116) finish: called for local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33 (0, 0)
2014/11/27 01:15:23.868| Read.cc(91) ReadNow: local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.868| client_side.cc(2372) connFinishedWithConn: local=195.191.234.34:443 remote=192.168.0.122:62954 FD 23 flags=33 closed
2014/11/27 01:15:23.868| comm.cc(860) _comm_close: comm_close: start closing FD 23
2014/11/27 01:15:23.868| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x4bc06f0 [call296]
2014/11/27 01:15:23.868| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 23) [call296]
2014/11/27 01:15:23.868| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 23
2014/11/27 01:15:23.868| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3566090 [call297]
2014/11/27 01:15:23.868| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 23) [call297]
2014/11/27 01:15:23.868| Read.cc(91) ReadNow: local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.868| client_side.cc(2372) connFinishedWithConn: local=195.191.234.34:443 remote=192.168.0.122:62955 FD 27 flags=33 closed
2014/11/27 01:15:23.868| comm.cc(860) _comm_close: comm_close: start closing FD 27
2014/11/27 01:15:23.868| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x429ff50 [call298]
2014/11/27 01:15:23.869| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 27) [call298]
2014/11/27 01:15:23.869| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 27
2014/11/27 01:15:23.869| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x382af60 [call299]
2014/11/27 01:15:23.869| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 27) [call299]
2014/11/27 01:15:23.869| Read.cc(91) ReadNow: local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.869| client_side.cc(2372) connFinishedWithConn: local=195.214.195.101:443 remote=192.168.0.122:62960 FD 32 flags=33 closed
2014/11/27 01:15:23.869| comm.cc(860) _comm_close: comm_close: start closing FD 32
2014/11/27 01:15:23.869| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x4187dc0 [call300]
2014/11/27 01:15:23.869| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 32) [call300]
2014/11/27 01:15:23.869| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 32
2014/11/27 01:15:23.869| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3c2fff0 [call301]
2014/11/27 01:15:23.869| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 32) [call301]
2014/11/27 01:15:23.869| Read.cc(91) ReadNow: local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.869| client_side.cc(2372) connFinishedWithConn: local=195.214.195.101:443 remote=192.168.0.122:62961 FD 33 flags=33 closed
2014/11/27 01:15:23.869| comm.cc(860) _comm_close: comm_close: start closing FD 33
2014/11/27 01:15:23.869| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x354bd30 [call302]
2014/11/27 01:15:23.869| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 33) [call302]
2014/11/27 01:15:23.869| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 33
2014/11/27 01:15:23.869| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3fb1190 [call303]
2014/11/27 01:15:23.869| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 33) [call303]
2014/11/27 01:15:23.869| Read.cc(91) ReadNow: local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.869| client_side.cc(2372) connFinishedWithConn: local=81.222.128.22:443 remote=192.168.0.122:62973 FD 45 flags=33 closed
2014/11/27 01:15:23.869| comm.cc(860) _comm_close: comm_close: start closing FD 45
2014/11/27 01:15:23.869| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x409cb10 [call304]
2014/11/27 01:15:23.870| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 45) [call304]
2014/11/27 01:15:23.870| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 45
2014/11/27 01:15:23.870| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3c03430 [call305]
2014/11/27 01:15:23.870| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 45) [call305]
2014/11/27 01:15:23.870| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 23)
2014/11/27 01:15:23.870| AsyncCall.cc(38) make: make call commStartSslClose [call296]
2014/11/27 01:15:23.870| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 23)
2014/11/27 01:15:23.870| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.870| client_side.cc(817) swanSong: local=195.191.234.34:443 remote=192.168.0.122:62954 flags=33
2014/11/27 01:15:23.870| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.870| client_side.cc(848) ~ConnStateData: local=195.191.234.34:443 remote=192.168.0.122:62954 flags=33
2014/11/27 01:15:23.870| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 23)
2014/11/27 01:15:23.870| AsyncCall.cc(38) make: make call comm_close_complete [call297]
2014/11/27 01:15:23.871| fd.cc(93) fd_close: fd_close FD 23 client https start
2014/11/27 01:15:23.871| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 23)
2014/11/27 01:15:23.871| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 27)
2014/11/27 01:15:23.871| AsyncCall.cc(38) make: make call commStartSslClose [call298]
2014/11/27 01:15:23.871| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 27)
2014/11/27 01:15:23.871| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.871| client_side.cc(817) swanSong: local=195.191.234.34:443 remote=192.168.0.122:62955 flags=33
2014/11/27 01:15:23.871| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.871| client_side.cc(848) ~ConnStateData: local=195.191.234.34:443 remote=192.168.0.122:62955 flags=33
2014/11/27 01:15:23.871| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 27)
2014/11/27 01:15:23.871| AsyncCall.cc(38) make: make call comm_close_complete [call299]
2014/11/27 01:15:23.871| fd.cc(93) fd_close: fd_close FD 27 client https start
2014/11/27 01:15:23.871| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 27)
2014/11/27 01:15:23.871| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 32)
2014/11/27 01:15:23.871| AsyncCall.cc(38) make: make call commStartSslClose [call300]
2014/11/27 01:15:23.871| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 32)
2014/11/27 01:15:23.871| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.872| client_side.cc(817) swanSong: local=195.214.195.101:443 remote=192.168.0.122:62960 flags=33
2014/11/27 01:15:23.872| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.872| client_side.cc(848) ~ConnStateData: local=195.214.195.101:443 remote=192.168.0.122:62960 flags=33
2014/11/27 01:15:23.872| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 32)
2014/11/27 01:15:23.872| AsyncCall.cc(38) make: make call comm_close_complete [call301]
2014/11/27 01:15:23.872| fd.cc(93) fd_close: fd_close FD 32 client https start
2014/11/27 01:15:23.872| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 32)
2014/11/27 01:15:23.872| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 33)
2014/11/27 01:15:23.872| AsyncCall.cc(38) make: make call commStartSslClose [call302]
2014/11/27 01:15:23.872| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 33)
2014/11/27 01:15:23.873| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.873| client_side.cc(817) swanSong: local=195.214.195.101:443 remote=192.168.0.122:62961 flags=33
2014/11/27 01:15:23.873| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.873| client_side.cc(848) ~ConnStateData: local=195.214.195.101:443 remote=192.168.0.122:62961 flags=33
2014/11/27 01:15:23.873| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 33)
2014/11/27 01:15:23.873| AsyncCall.cc(38) make: make call comm_close_complete [call303]
2014/11/27 01:15:23.873| fd.cc(93) fd_close: fd_close FD 33 client https start
2014/11/27 01:15:23.873| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 33)
2014/11/27 01:15:23.873| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 45)
2014/11/27 01:15:23.873| AsyncCall.cc(38) make: make call commStartSslClose [call304]
2014/11/27 01:15:23.873| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 45)
2014/11/27 01:15:23.873| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.873| client_side.cc(817) swanSong: local=81.222.128.22:443 remote=192.168.0.122:62973 flags=33
2014/11/27 01:15:23.873| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.873| client_side.cc(848) ~ConnStateData: local=81.222.128.22:443 remote=192.168.0.122:62973 flags=33
2014/11/27 01:15:23.873| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 45)
2014/11/27 01:15:23.873| AsyncCall.cc(38) make: make call comm_close_complete [call305]
2014/11/27 01:15:23.873| fd.cc(93) fd_close: fd_close FD 45 client https start
2014/11/27 01:15:23.873| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 45)
2014/11/27 01:15:23.873| IoCallback.cc(116) finish: called for local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33 (0, 0)
2014/11/27 01:15:23.873| IoCallback.cc(116) finish: called for local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33 (0, 0)
2014/11/27 01:15:23.873| IoCallback.cc(116) finish: called for local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33 (0, 0)
2014/11/27 01:15:23.873| IoCallback.cc(116) finish: called for local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33 (0, 0)
2014/11/27 01:15:23.874| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x3dd9c50 on FD 43 (192.168.0.122:62971)
2014/11/27 01:15:23.874| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 43 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:23.874| client_side.cc(234) readSomeData: local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33: reading request...
2014/11/27 01:15:23.875| Read.cc(91) ReadNow: local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.875| client_side.cc(2372) connFinishedWithConn: local=212.42.76.246:443 remote=192.168.0.122:62967 FD 39 flags=33 closed
2014/11/27 01:15:23.875| comm.cc(860) _comm_close: comm_close: start closing FD 39
2014/11/27 01:15:23.875| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x3499230 [call307]
2014/11/27 01:15:23.875| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 39) [call307]
2014/11/27 01:15:23.875| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 39
2014/11/27 01:15:23.875| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3fdda20 [call308]
2014/11/27 01:15:23.875| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 39) [call308]
2014/11/27 01:15:23.875| Read.cc(91) ReadNow: local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.875| client_side.cc(2372) connFinishedWithConn: local=212.42.76.246:443 remote=192.168.0.122:62968 FD 40 flags=33 closed
2014/11/27 01:15:23.875| comm.cc(860) _comm_close: comm_close: start closing FD 40
2014/11/27 01:15:23.875| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x354bd30 [call309]
2014/11/27 01:15:23.875| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 40) [call309]
2014/11/27 01:15:23.875| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 40
2014/11/27 01:15:23.875| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x355adb0 [call310]
2014/11/27 01:15:23.875| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 40) [call310]
2014/11/27 01:15:23.875| Read.cc(91) ReadNow: local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.875| client_side.cc(2372) connFinishedWithConn: local=212.42.76.246:443 remote=192.168.0.122:62969 FD 41 flags=33 closed
2014/11/27 01:15:23.875| comm.cc(860) _comm_close: comm_close: start closing FD 41
2014/11/27 01:15:23.875| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x4187dc0 [call311]
2014/11/27 01:15:23.875| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 41) [call311]
2014/11/27 01:15:23.875| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 41
2014/11/27 01:15:23.876| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x382af60 [call312]
2014/11/27 01:15:23.876| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 41) [call312]
2014/11/27 01:15:23.876| Read.cc(91) ReadNow: local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.876| client_side.cc(2372) connFinishedWithConn: local=212.42.76.246:443 remote=192.168.0.122:62970 FD 42 flags=33 closed
2014/11/27 01:15:23.876| comm.cc(860) _comm_close: comm_close: start closing FD 42
2014/11/27 01:15:23.876| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x429ff50 [call313]
2014/11/27 01:15:23.876| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 42) [call313]
2014/11/27 01:15:23.876| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 42
2014/11/27 01:15:23.876| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3498e70 [call314]
2014/11/27 01:15:23.876| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 42) [call314]
2014/11/27 01:15:23.876| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 39)
2014/11/27 01:15:23.876| AsyncCall.cc(38) make: make call commStartSslClose [call307]
2014/11/27 01:15:23.876| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 39)
2014/11/27 01:15:23.876| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.876| client_side.cc(817) swanSong: local=212.42.76.246:443 remote=192.168.0.122:62967 flags=33
2014/11/27 01:15:23.876| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.876| client_side.cc(848) ~ConnStateData: local=212.42.76.246:443 remote=192.168.0.122:62967 flags=33
2014/11/27 01:15:23.876| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 39)
2014/11/27 01:15:23.876| AsyncCall.cc(38) make: make call comm_close_complete [call308]
2014/11/27 01:15:23.877| fd.cc(93) fd_close: fd_close FD 39 client https start
2014/11/27 01:15:23.877| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 39)
2014/11/27 01:15:23.877| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 40)
2014/11/27 01:15:23.877| AsyncCall.cc(38) make: make call commStartSslClose [call309]
2014/11/27 01:15:23.877| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 40)
2014/11/27 01:15:23.877| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.877| client_side.cc(817) swanSong: local=212.42.76.246:443 remote=192.168.0.122:62968 flags=33
2014/11/27 01:15:23.877| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.877| client_side.cc(848) ~ConnStateData: local=212.42.76.246:443 remote=192.168.0.122:62968 flags=33
2014/11/27 01:15:23.877| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 40)
2014/11/27 01:15:23.878| AsyncCall.cc(38) make: make call comm_close_complete [call310]
2014/11/27 01:15:23.878| fd.cc(93) fd_close: fd_close FD 40 client https start
2014/11/27 01:15:23.878| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 40)
2014/11/27 01:15:23.878| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 41)
2014/11/27 01:15:23.878| AsyncCall.cc(38) make: make call commStartSslClose [call311]
2014/11/27 01:15:23.878| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 41)
2014/11/27 01:15:23.878| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.878| client_side.cc(817) swanSong: local=212.42.76.246:443 remote=192.168.0.122:62969 flags=33
2014/11/27 01:15:23.878| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.878| client_side.cc(848) ~ConnStateData: local=212.42.76.246:443 remote=192.168.0.122:62969 flags=33
2014/11/27 01:15:23.879| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 41)
2014/11/27 01:15:23.879| AsyncCall.cc(38) make: make call comm_close_complete [call312]
2014/11/27 01:15:23.879| fd.cc(93) fd_close: fd_close FD 41 client https start
2014/11/27 01:15:23.879| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 41)
2014/11/27 01:15:23.879| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 42)
2014/11/27 01:15:23.879| AsyncCall.cc(38) make: make call commStartSslClose [call313]
2014/11/27 01:15:23.879| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 42)
2014/11/27 01:15:23.879| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.879| client_side.cc(817) swanSong: local=212.42.76.246:443 remote=192.168.0.122:62970 flags=33
2014/11/27 01:15:23.879| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.879| client_side.cc(848) ~ConnStateData: local=212.42.76.246:443 remote=192.168.0.122:62970 flags=33
2014/11/27 01:15:23.880| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 42)
2014/11/27 01:15:23.880| AsyncCall.cc(38) make: make call comm_close_complete [call314]
2014/11/27 01:15:23.881| fd.cc(93) fd_close: fd_close FD 42 client https start
2014/11/27 01:15:23.881| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 42)
2014/11/27 01:15:23.881| IoCallback.cc(116) finish: called for local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33 (0, 0)
2014/11/27 01:15:23.881| Read.cc(91) ReadNow: local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:23.881| client_side.cc(2372) connFinishedWithConn: local=212.42.76.246:443 remote=192.168.0.122:62971 FD 43 flags=33 closed
2014/11/27 01:15:23.881| comm.cc(860) _comm_close: comm_close: start closing FD 43
2014/11/27 01:15:23.881| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x44f9890 [call315]
2014/11/27 01:15:23.881| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 43) [call315]
2014/11/27 01:15:23.881| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 43
2014/11/27 01:15:23.881| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x38ea1e0 [call316]
2014/11/27 01:15:23.881| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 43) [call316]
2014/11/27 01:15:23.881| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 43)
2014/11/27 01:15:23.881| AsyncCall.cc(38) make: make call commStartSslClose [call315]
2014/11/27 01:15:23.881| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 43)
2014/11/27 01:15:23.882| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:23.882| client_side.cc(817) swanSong: local=212.42.76.246:443 remote=192.168.0.122:62971 flags=33
2014/11/27 01:15:23.882| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:23.882| client_side.cc(848) ~ConnStateData: local=212.42.76.246:443 remote=192.168.0.122:62971 flags=33
2014/11/27 01:15:23.882| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 43)
2014/11/27 01:15:23.882| AsyncCall.cc(38) make: make call comm_close_complete [call316]
2014/11/27 01:15:23.882| fd.cc(93) fd_close: fd_close FD 43 client https start
2014/11/27 01:15:23.882| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 43)
2014/11/27 01:15:24.533| TcpAcceptor.cc(222) doAccept: New connection on FD 26
2014/11/27 01:15:24.533| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3132 remote=[::] FD 26 flags=41
2014/11/27 01:15:24.533| fd.cc(198) fd_open: fd_open() FD 14 HTTP Request
2014/11/27 01:15:24.533| Eui48.cc(178) lookup: id=0x352a654 query ARP table
2014/11/27 01:15:24.533| Eui48.cc(221) lookup: id=0x352a654 query ARP on each interface (80 found)
2014/11/27 01:15:24.533| Eui48.cc(227) lookup: id=0x352a654 found interface lo
2014/11/27 01:15:24.533| Eui48.cc(227) lookup: id=0x352a654 found interface br0
2014/11/27 01:15:24.533| Eui48.cc(236) lookup: id=0x352a654 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:24.533| Eui48.cc(279) lookup: id=0x352a654 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:24.533| client_side.cc(3889) httpsAccept: local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33 accepted, starting SSL negotiation.
2014/11/27 01:15:24.534| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:24.534| Checklist.cc(68) preCheck: 0x3535728 checking slow rules
2014/11/27 01:15:24.534| Acl.cc(156) matches: checked: step2 = 0
2014/11/27 01:15:24.534| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:24.534| DomainData.cc(106) match: aclMatchDomainList: checking '212.42.76.253'
2014/11/27 01:15:24.534| DomainData.cc(110) match: aclMatchDomainList: '212.42.76.253' NOT found
2014/11/27 01:15:24.534| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '212.42.76.253' == 212.42.76.253
2014/11/27 01:15:24.534| DomainData.cc(106) match: aclMatchDomainList: checking 'srv253.fwdcdn.com'
2014/11/27 01:15:24.534| DomainData.cc(110) match: aclMatchDomainList: 'srv253.fwdcdn.com' NOT found
2014/11/27 01:15:24.534| Acl.cc(156) matches: checked: sslBumpDeniedDstDomain = 0
2014/11/27 01:15:24.534| Acl.cc(156) matches: checked: (ssl_bump rule) = 0
2014/11/27 01:15:24.534| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62974' found
2014/11/27 01:15:24.534| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:24.534| Acl.cc(156) matches: checked: (ssl_bump rule) = 1
2014/11/27 01:15:24.534| Acl.cc(156) matches: checked: (ssl_bump rules) = 1
2014/11/27 01:15:24.534| Checklist.cc(61) markFinished: 0x3535728 answer ALLOWED for match
2014/11/27 01:15:24.534| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3535728 answer=ALLOWED
2014/11/27 01:15:24.534| client_side.cc(3849) httpsSslBumpAccessCheckDone: sslBump needed for local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33 method 5
2014/11/27 01:15:24.534| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33 timeout 300
2014/11/27 01:15:24.534| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 212.42.76.253
2014/11/27 01:15:24.534| client_side.cc(3827) httpsEstablish: local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33 try to generate a Dynamic SSL CTX
2014/11/27 01:15:24.534| comm.cc(548) commSetConnTimeout: local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33 timeout 300
2014/11/27 01:15:24.535| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3535728
2014/11/27 01:15:24.535| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3535728
2014/11/27 01:15:24.539| client_side.cc(3757) clientNegotiateSSL: clientNegotiateSSL: New session 0x4b1aeb0 on FD 14 (192.168.0.122:62974)
2014/11/27 01:15:24.539| client_side.cc(3761) clientNegotiateSSL: clientNegotiateSSL: FD 14 negotiated cipher AES128-GCM-SHA256
2014/11/27 01:15:24.539| client_side.cc(234) readSomeData: local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33: reading request...
2014/11/27 01:15:24.539| IoCallback.cc(116) finish: called for local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33 (0, 0)
2014/11/27 01:15:24.539| Read.cc(91) ReadNow: local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33, size 16384, retval 0, errno 0
2014/11/27 01:15:24.539| client_side.cc(2372) connFinishedWithConn: local=212.42.76.253:443 remote=192.168.0.122:62974 FD 14 flags=33 closed
2014/11/27 01:15:24.539| comm.cc(860) _comm_close: comm_close: start closing FD 14
2014/11/27 01:15:24.539| AsyncCall.cc(26) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x3506ac0 [call324]
2014/11/27 01:15:24.539| AsyncCall.cc(93) ScheduleCall: comm.cc(894) will call commStartSslClose(FD 14) [call324]
2014/11/27 01:15:24.539| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 14
2014/11/27 01:15:24.539| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3fdda20 [call325]
2014/11/27 01:15:24.539| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 14) [call325]
2014/11/27 01:15:24.539| AsyncCallQueue.cc(55) fireNext: entering commStartSslClose(FD 14)
2014/11/27 01:15:24.539| AsyncCall.cc(38) make: make call commStartSslClose [call324]
2014/11/27 01:15:24.539| AsyncCallQueue.cc(57) fireNext: leaving commStartSslClose(FD 14)
2014/11/27 01:15:24.539| AsyncJob.cc(55) deleteThis: Http::Server will NOT delete in-call job, reason: ConnStateData::connStateClosed
2014/11/27 01:15:24.539| client_side.cc(817) swanSong: local=212.42.76.253:443 remote=192.168.0.122:62974 flags=33
2014/11/27 01:15:24.539| client_side.cc(5014) unpinConnection: 
2014/11/27 01:15:24.539| client_side.cc(848) ~ConnStateData: local=212.42.76.253:443 remote=192.168.0.122:62974 flags=33
2014/11/27 01:15:24.540| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 14)
2014/11/27 01:15:24.540| AsyncCall.cc(38) make: make call comm_close_complete [call325]
2014/11/27 01:15:24.540| fd.cc(93) fd_close: fd_close FD 14 client https start
2014/11/27 01:15:24.540| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 14)
2014/11/27 01:15:24.546| TcpAcceptor.cc(222) doAccept: New connection on FD 25
2014/11/27 01:15:24.546| TcpAcceptor.cc(297) acceptNext: connection on local=0.0.0.0:3131 remote=[::] FD 25 flags=41
2014/11/27 01:15:24.546| fd.cc(198) fd_open: fd_open() FD 14 HTTP Request
2014/11/27 01:15:24.546| Eui48.cc(178) lookup: id=0x352a654 query ARP table
2014/11/27 01:15:24.546| Eui48.cc(221) lookup: id=0x352a654 query ARP on each interface (80 found)
2014/11/27 01:15:24.546| Eui48.cc(227) lookup: id=0x352a654 found interface lo
2014/11/27 01:15:24.546| Eui48.cc(227) lookup: id=0x352a654 found interface br0
2014/11/27 01:15:24.546| Eui48.cc(236) lookup: id=0x352a654 looking up ARP address for 192.168.0.122 on br0
2014/11/27 01:15:24.546| Eui48.cc(279) lookup: id=0x352a654 got address 30:85:a9:40:a4:19 on br0
2014/11/27 01:15:24.547| client_side.cc(3626) httpAccept: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33: accepted
2014/11/27 01:15:24.547| comm.cc(548) commSetConnTimeout: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33 timeout 300
2014/11/27 01:15:24.547| client_side.cc(234) readSomeData: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33: reading request...
2014/11/27 01:15:24.565| IoCallback.cc(116) finish: called for local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33 (0, 0)
2014/11/27 01:15:24.565| Read.cc(91) ReadNow: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33, size 16384, retval 331, errno 0
2014/11/27 01:15:24.565| client_side.cc(2226) parseHttpRequest: parseHttpRequest: req_hdr = {Host: www.gstatic.com
Connection: keep-alive
Pragma: no-cache
Cache-Control: no-cache
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 Safari/537.36
Accept-Encoding: gzip, deflate, sdch
Accept-Language: en-US,en;q=0.8,uk;q=0.6,ru;q=0.4

}
2014/11/27 01:15:24.565| client_side.cc(2230) parseHttpRequest: parseHttpRequest: end = {
}
2014/11/27 01:15:24.565| client_side.cc(2234) parseHttpRequest: parseHttpRequest: prefix_sz = 331, req_line_sz = 28
2014/11/27 01:15:24.565| clientStream.cc(144) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x34cffe8 with data 0x493e110 after head
2014/11/27 01:15:24.565| client_side.cc(2313) parseHttpRequest: HTTP Client local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33
2014/11/27 01:15:24.565| client_side.cc(2314) parseHttpRequest: HTTP Client REQUEST:
---------
GET /generate_204 HTTP/1.1
Host: www.gstatic.com
Connection: keep-alive
Pragma: no-cache
Cache-Control: no-cache
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 Safari/537.36
Accept-Encoding: gzip, deflate, sdch
Accept-Language: en-US,en;q=0.8,uk;q=0.6,ru;q=0.4


----------
2014/11/27 01:15:24.565| AsyncCall.cc(26) AsyncCall: The AsyncCall clientLifetimeTimeout constructed, this=0x34ec4d0 [call331]
2014/11/27 01:15:24.565| comm.cc(548) commSetConnTimeout: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33 timeout 86400
2014/11/27 01:15:24.565| url.cc(357) urlParse: urlParse: Split URL 'http://www.gstatic.com/generate_204' into proto='http', host='www.gstatic.com', port='80', path='/generate_204'
2014/11/27 01:15:24.566| Address.cc(379) lookupHostIP: Given Non-IP 'www.gstatic.com': Name or service not known
2014/11/27 01:15:24.566| client_side.cc(875) clientSetKeepaliveFlag: http_ver = HTTP/1.1
2014/11/27 01:15:24.566| client_side.cc(876) clientSetKeepaliveFlag: method = GET
2014/11/27 01:15:24.566| client_side_request.cc(130) ClientRequestContext: 0x3506ad8 ClientRequestContext constructed
2014/11/27 01:15:24.566| client_side_request.cc(1673) doCallouts: Doing calloutContext->hostHeaderVerify()
2014/11/27 01:15:24.566| client_side_request.cc(631) hostHeaderVerify: validate host=www.gstatic.com, port=0, portStr=NULL
2014/11/27 01:15:24.566| ipcache.cc(501) ipcache_nbgethostbyname: ipcache_nbgethostbyname: Name 'www.gstatic.com'.
2014/11/27 01:15:24.566| Address.cc(379) lookupHostIP: Given Non-IP 'www.gstatic.com': Name or service not known
2014/11/27 01:15:24.566| dns_internal.cc(1749) idnsALookup: idnsALookup: buf is 33 bytes for www.gstatic.com, id = 0x413a
2014/11/27 01:15:24.566| comm.cc(949) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 10 using Port 15059
2014/11/27 01:15:24.566| client_side.cc(234) readSomeData: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33: reading request...
2014/11/27 01:15:24.633| dns_internal.cc(1281) idnsRead: idnsRead: starting with FD 10
2014/11/27 01:15:24.633| dns_internal.cc(1327) idnsRead: idnsRead: FD 10: received 97 bytes from 8.8.8.8:53
2014/11/27 01:15:24.633| dns_internal.cc(1134) idnsGrokReply: idnsGrokReply: QID 0x413a, 4 answers
2014/11/27 01:15:24.633| ipcache.cc(364) ipcacheParse: ipcacheParse: 4 answers for 'www.gstatic.com'
2014/11/27 01:15:24.633| ipcache.cc(422) ipcacheParse: ipcacheParse: www.gstatic.com #0 173.194.112.31
2014/11/27 01:15:24.633| ipcache.cc(422) ipcacheParse: ipcacheParse: www.gstatic.com #1 173.194.112.15
2014/11/27 01:15:24.633| ipcache.cc(422) ipcacheParse: ipcacheParse: www.gstatic.com #2 173.194.112.24
2014/11/27 01:15:24.633| ipcache.cc(422) ipcacheParse: ipcacheParse: www.gstatic.com #3 173.194.112.23
2014/11/27 01:15:24.633| client_side_request.cc(529) hostHeaderIpVerify: validate IP 173.194.113.23:80 non-match from Host: IP 173.194.112.31
2014/11/27 01:15:24.633| client_side_request.cc(529) hostHeaderIpVerify: validate IP 173.194.113.23:80 non-match from Host: IP 173.194.112.15
2014/11/27 01:15:24.633| client_side_request.cc(529) hostHeaderIpVerify: validate IP 173.194.113.23:80 non-match from Host: IP 173.194.112.24
2014/11/27 01:15:24.633| client_side_request.cc(529) hostHeaderIpVerify: validate IP 173.194.113.23:80 non-match from Host: IP 173.194.112.23
2014/11/27 01:15:24.633| client_side_request.cc(532) hostHeaderIpVerify: FAIL: validate IP 173.194.113.23:80 possible from Host:
2014/11/27 01:15:24.633| client_side_request.cc(1680) doCallouts: Doing calloutContext->clientAccessCheck()
2014/11/27 01:15:24.633| Checklist.cc(68) preCheck: 0x3535728 checking slow rules
2014/11/27 01:15:24.633| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62975' found
2014/11/27 01:15:24.633| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:24.633| Acl.cc(156) matches: checked: http_access#1 = 1
2014/11/27 01:15:24.633| Acl.cc(156) matches: checked: http_access = 1
2014/11/27 01:15:24.633| Checklist.cc(61) markFinished: 0x3535728 answer ALLOWED for match
2014/11/27 01:15:24.633| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3535728 answer=ALLOWED
2014/11/27 01:15:24.633| client_side_request.cc(741) clientAccessCheckDone: The request GET http://www.gstatic.com/generate_204 is ALLOWED; last ACL checked: all
2014/11/27 01:15:24.633| AccessCheck.cc(42) Start: adaptation off, skipping
2014/11/27 01:15:24.634| client_side_request.cc(1709) doCallouts: Doing calloutContext->clientAccessCheck2()
2014/11/27 01:15:24.634| client_side_request.cc(717) clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2014/11/27 01:15:24.634| client_side_request.cc(741) clientAccessCheckDone: The request GET http://www.gstatic.com/generate_204 is ALLOWED; last ACL checked: all
2014/11/27 01:15:24.634| client_side_request.cc(1728) doCallouts: Doing clientInterpretRequestHeaders()
2014/11/27 01:15:24.634| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff3a654bc0
2014/11/27 01:15:24.634| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff3a654bc0
2014/11/27 01:15:24.634| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff3a654a10
2014/11/27 01:15:24.634| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff3a654a10
2014/11/27 01:15:24.634| client_side_request.cc(115) ~ClientRequestContext: 0x3506ad8 ClientRequestContext destructed
2014/11/27 01:15:24.634| client_side_request.cc(1817) doCallouts: calling processRequest()
2014/11/27 01:15:24.634| client_side_request.cc(1489) processRequest: GET http://www.gstatic.com/generate_204
2014/11/27 01:15:24.634| client_side_request.cc(1511) httpStart: TAG_NONE for 'http://www.gstatic.com/generate_204'
2014/11/27 01:15:24.634| clientStream.cc(184) clientStreamRead: clientStreamRead: Calling 1 with cbdata 0x48b3f18 from node 0x34cffe8
2014/11/27 01:15:24.634| client_side_reply.cc(1634) identifyFoundObject: StoreEntry is NULL -  MISS
2014/11/27 01:15:24.634| client_side_reply.cc(631) processMiss: GET http://www.gstatic.com/generate_204
2014/11/27 01:15:24.634| store.cc(780) storeCreatePureEntry: storeCreateEntry: 'http://www.gstatic.com/generate_204'
2014/11/27 01:15:24.634| MemObject.cc(97) MemObject: new MemObject 0x3d2ef20
2014/11/27 01:15:24.634| store.cc(501) setReleaseFlag: StoreEntry::setReleaseFlag: '[null_store_key]'
2014/11/27 01:15:24.634| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: GET http://www.gstatic.com/generate_204
2014/11/27 01:15:24.634| store.cc(449) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=XI/0x3540f60*0 key '5A1FB6665A738F63A93D8E42ECC6FB76'
2014/11/27 01:15:24.634| store.cc(485) lock: storeCreateEntry locked key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=XIV/0x3540f60*1
2014/11/27 01:15:24.634| store_client.cc(200) copy: store_client::copy: 5A1FB6665A738F63A93D8E42ECC6FB76, from 0, for length 4096, cb 1, cbdata 0x48b2e68
2014/11/27 01:15:24.634| store.cc(485) lock: store_client::copy locked key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=XIV/0x3540f60*2
2014/11/27 01:15:24.634| store_client.cc(297) storeClientCopy2: storeClientCopy2: 5A1FB6665A738F63A93D8E42ECC6FB76
2014/11/27 01:15:24.634| store_client.cc(341) doCopy: store_client::doCopy: Waiting for more
2014/11/27 01:15:24.634| store.cc(523) unlock: store_client::copy unlocking key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=XIV/0x3540f60*2
2014/11/27 01:15:24.634| FwdState.cc(328) Start: 'http://www.gstatic.com/generate_204'
2014/11/27 01:15:24.634| FwdState.cc(132) FwdState: Forwarding client request local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33, url=http://www.gstatic.com/generate_204
2014/11/27 01:15:24.634| store.cc(485) lock: FwdState locked key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=XIV/0x3540f60*2
2014/11/27 01:15:24.634| peer_select.cc(137) peerSelect: e:=XIWV/0x3540f60*2 http://www.gstatic.com/generate_204
2014/11/27 01:15:24.634| store.cc(485) lock: peerSelect locked key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=XIWV/0x3540f60*3
2014/11/27 01:15:24.634| peer_select.cc(440) peerSelectFoo: GET www.gstatic.com
2014/11/27 01:15:24.634| peer_select.cc(445) peerSelectFoo: peerSelectFoo: direct = DIRECT_UNKNOWN (always_direct to be checked)
2014/11/27 01:15:24.634| Checklist.cc(68) preCheck: 0x3530368 checking slow rules
2014/11/27 01:15:24.634| Ip.cc(538) match: aclIpMatchIp: '192.168.0.122:62975' found
2014/11/27 01:15:24.634| Acl.cc(156) matches: checked: all = 1
2014/11/27 01:15:24.634| Acl.cc(156) matches: checked: always_direct#1 = 1
2014/11/27 01:15:24.634| Acl.cc(156) matches: checked: always_direct = 1
2014/11/27 01:15:24.634| Checklist.cc(61) markFinished: 0x3530368 answer ALLOWED for match
2014/11/27 01:15:24.634| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x3530368 answer=ALLOWED
2014/11/27 01:15:24.634| peer_select.cc(194) peerCheckAlwaysDirectDone: peerCheckAlwaysDirectDone: ALLOWED
2014/11/27 01:15:24.634| peer_select.cc(200) peerCheckAlwaysDirectDone: direct = DIRECT_YES (always_direct allow)
2014/11/27 01:15:24.634| peer_select.cc(440) peerSelectFoo: GET www.gstatic.com
2014/11/27 01:15:24.635| peer_select.cc(279) peerSelectDnsPaths: Found sources for 'http://www.gstatic.com/generate_204'
2014/11/27 01:15:24.635| peer_select.cc(280) peerSelectDnsPaths:   always_direct = ALLOWED
2014/11/27 01:15:24.635| peer_select.cc(281) peerSelectDnsPaths:    never_direct = DENIED
2014/11/27 01:15:24.635| peer_select.cc(287) peerSelectDnsPaths:    ORIGINAL_DST = local=0.0.0.0 remote=173.194.113.23:80 flags=1
2014/11/27 01:15:24.635| peer_select.cc(294) peerSelectDnsPaths:        timedout = 0
2014/11/27 01:15:24.635| FwdState.cc(383) startConnectionOrFail: http://www.gstatic.com/generate_204
2014/11/27 01:15:24.635| FwdState.cc(781) connectStart: fwdConnectStart: http://www.gstatic.com/generate_204
2014/11/27 01:15:24.635| pconn.cc(439) pop: lookup for key {173.194.113.23:80/www.gstatic.com} failed.
2014/11/27 01:15:24.635| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff3a653fc0
2014/11/27 01:15:24.635| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff3a653fc0
2014/11/27 01:15:24.635| FwdState.cc(1301) GetMarkingsToServer: from 0.0.0.0 netfilter mark 0
2014/11/27 01:15:24.635| AsyncCall.cc(26) AsyncCall: The AsyncCall fwdConnectDoneWrapper constructed, this=0x354bd30 [call333]
2014/11/27 01:15:24.635| peer_select.cc(79) ~ps_state: http://www.gstatic.com/generate_204
2014/11/27 01:15:24.635| store.cc(523) unlock: peerSelect unlocking key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=p2XIWV/0x3540f60*3
2014/11/27 01:15:24.635| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3530368
2014/11/27 01:15:24.635| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3530368
2014/11/27 01:15:24.635| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x3535728
2014/11/27 01:15:24.635| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x3535728
2014/11/27 01:15:24.635| comm.cc(342) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0
2014/11/27 01:15:24.635| comm.cc(383) comm_openex: comm_openex: Opened socket local=0.0.0.0 remote=[::] FD 16 flags=1 : family=2, type=1, protocol=6
2014/11/27 01:15:24.635| fd.cc(198) fd_open: fd_open() FD 16 www.gstatic.com
2014/11/27 01:15:24.635| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::ConnOpener::earlyAbort constructed, this=0x3511000 [call335]
2014/11/27 01:15:24.635| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::ConnOpener::timeout constructed, this=0x4cd6080 [call336]
2014/11/27 01:15:24.635| ConnOpener.cc(289) createFd: local=0.0.0.0 remote=173.194.113.23:80 flags=1 will timeout in 60
2014/11/27 01:15:24.666| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::ConnOpener::doConnect constructed, this=0x353a2a0 [call338]
2014/11/27 01:15:24.666| AsyncCall.cc(93) ScheduleCall: ConnOpener.cc(460) will call Comm::ConnOpener::doConnect() [call338]
2014/11/27 01:15:24.666| AsyncCallQueue.cc(55) fireNext: entering Comm::ConnOpener::doConnect()
2014/11/27 01:15:24.666| AsyncCall.cc(38) make: make call Comm::ConnOpener::doConnect [call338]
2014/11/27 01:15:24.666| AsyncJob.cc(123) callStart: Comm::ConnOpener status in: [ job33]
2014/11/27 01:15:24.666| ConnOpener.cc(153) cleanFd: local=0.0.0.0 remote=173.194.113.23:80 flags=1 closing temp FD 16
2014/11/27 01:15:24.666| AsyncCall.cc(56) cancel: will not call Comm::ConnOpener::timeout [call336] because Comm::ConnOpener::cleanFd
2014/11/27 01:15:24.666| AsyncCall.cc(56) cancel: will not call Comm::ConnOpener::earlyAbort [call335] because comm_remove_close_handler
2014/11/27 01:15:24.666| AsyncCall.cc(93) ScheduleCall: ConnOpener.cc(137) will call fwdConnectDoneWrapper(local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1, data=0x4273238) [call333]
2014/11/27 01:15:24.666| AsyncCallQueue.cc(57) fireNext: leaving Comm::ConnOpener::doConnect()
2014/11/27 01:15:24.666| AsyncCallQueue.cc(55) fireNext: entering fwdConnectDoneWrapper(local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1, data=0x4273238)
2014/11/27 01:15:24.666| AsyncCall.cc(38) make: make call fwdConnectDoneWrapper [call333]
2014/11/27 01:15:24.666| FwdState.cc(677) connectDone: local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1: 'http://www.gstatic.com/generate_204'
2014/11/27 01:15:24.666| AsyncCall.cc(26) AsyncCall: The AsyncCall SomeCloseHandler constructed, this=0x3fdda20 [call339]
2014/11/27 01:15:24.666| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::ConnStateData::notePeerConnection constructed, this=0x3499230 [call340]
2014/11/27 01:15:24.666| AsyncCall.cc(93) ScheduleCall: FwdState.cc(706) will call ConnStateData::ConnStateData::notePeerConnection(local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1) [call340]
2014/11/27 01:15:24.666| FwdState.cc(902) dispatch: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33: Fetching GET http://www.gstatic.com/generate_204
2014/11/27 01:15:24.666| http.cc(2259) httpStart: GET http://www.gstatic.com/generate_204
2014/11/27 01:15:24.666| store.cc(485) lock: Client locked key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=p2XDIWV/0x3540f60*3
2014/11/27 01:15:24.667| AsyncCallQueue.cc(57) fireNext: leaving fwdConnectDoneWrapper(local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1, data=0x4273238)
2014/11/27 01:15:24.667| AsyncCallQueue.cc(55) fireNext: entering ConnStateData::ConnStateData::notePeerConnection(local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1)
2014/11/27 01:15:24.667| AsyncCall.cc(38) make: make call ConnStateData::ConnStateData::notePeerConnection [call340]
2014/11/27 01:15:24.667| AsyncJob.cc(123) callStart: Http::Server status in: [ job31]
2014/11/27 01:15:24.667| AsyncJob.cc(152) callEnd: Http::Server status out: [ job31]
2014/11/27 01:15:24.667| AsyncCallQueue.cc(57) fireNext: leaving ConnStateData::ConnStateData::notePeerConnection(local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1)
2014/11/27 01:15:24.667| comm.cc(548) commSetConnTimeout: local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1 timeout 86400
2014/11/27 01:15:24.667| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff3a6555f0
2014/11/27 01:15:24.667| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff3a6555f0
2014/11/27 01:15:24.668| http.cc(2215) sendRequest: HTTP Server local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1
2014/11/27 01:15:24.668| http.cc(2216) sendRequest: HTTP Server REQUEST:
---------
GET /generate_204 HTTP/1.1
Host: www.gstatic.com
Pragma: no-cache
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 Safari/537.36
Accept-Encoding: gzip, deflate, sdch
Accept-Language: en-US,en;q=0.8,uk;q=0.6,ru;q=0.4
Via: 1.1 local.local (squid/3.5.0.2)
X-Forwarded-For: 192.168.0.122
Cache-Control: no-cache
Connection: keep-alive


----------
2014/11/27 01:15:24.668| IoCallback.cc(116) finish: called for local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1 (0, 0)
2014/11/27 01:15:24.668| comm.cc(548) commSetConnTimeout: local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1 timeout 900
2014/11/27 01:15:24.698| Read.cc(143) HandleRead: FD 16, size 16383, retval 140, errno 0
2014/11/27 01:15:24.698| IoCallback.cc(116) finish: called for local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1 (0, 0)
2014/11/27 01:15:24.698| ctx: enter level  0: 'http://www.gstatic.com/generate_204'
2014/11/27 01:15:24.698| http.cc(693) processReplyHeader: processReplyHeader: key '5A1FB6665A738F63A93D8E42ECC6FB76'
2014/11/27 01:15:24.699| http.cc(737) processReplyHeader: HTTP Server local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1
2014/11/27 01:15:24.699| http.cc(738) processReplyHeader: HTTP Server REPLY:
---------
HTTP/1.1 204 No Content
Content-Length: 0
Content-Type: text/html; charset=UTF-8
Date: Wed, 26 Nov 2014 14:15:24 GMT
Server: GFE/2.0


----------
2014/11/27 01:15:24.699| ctx: exit level  0
2014/11/27 01:15:24.699| AccessCheck.cc(42) Start: adaptation off, skipping
2014/11/27 01:15:24.699| store.cc(1846) replaceHttpReply: StoreEntry::replaceHttpReply: http://www.gstatic.com/generate_204
2014/11/27 01:15:24.699| ctx: enter level  0: 'http://www.gstatic.com/generate_204'
2014/11/27 01:15:24.699| http.cc(907) haveParsedReplyHeaders: HTTP CODE: 204
2014/11/27 01:15:24.699| http.cc(328) cacheableReply: NO because e:=p2XDIV/0x3540f60*3 has been released.
2014/11/27 01:15:24.699| store.cc(819) expireNow: StoreEntry::expireNow: '5A1FB6665A738F63A93D8E42ECC6FB76'
2014/11/27 01:15:24.700| store.cc(942) checkCachable: StoreEntry::checkCachable: NO: not cachable
2014/11/27 01:15:24.700| store_client.cc(731) invokeHandlers: InvokeHandlers: 5A1FB6665A738F63A93D8E42ECC6FB76
2014/11/27 01:15:24.700| store_client.cc(737) invokeHandlers: StoreEntry::InvokeHandlers: checking client #0
2014/11/27 01:15:24.700| store_client.cc(297) storeClientCopy2: storeClientCopy2: 5A1FB6665A738F63A93D8E42ECC6FB76
2014/11/27 01:15:24.700| store_client.cc(433) scheduleMemRead: store_client::doCopy: Copying normal from memory
2014/11/27 01:15:24.700| client_side_reply.cc(1996) processReplyAccessResult: The reply for GET http://www.gstatic.com/generate_204 is ALLOWED, because it matched all
2014/11/27 01:15:24.700| store.cc(485) lock: ClientHttpRequest::loggingEntry locked key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=p2XDIV/0x3540f60*4
2014/11/27 01:15:24.700| client_side_reply.cc(2034) processReplyAccessResult: clientReplyContext::sendMoreData: Appending 0 bytes after 140 bytes of headers
2014/11/27 01:15:24.700| clientStream.cc(162) clientStreamCallback: clientStreamCallback: Calling 1 with cbdata 0x493e110 from node 0x34f6ef8
2014/11/27 01:15:24.700| client_side.cc(1399) sendStartOfMessage: HTTP Client local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33
2014/11/27 01:15:24.700| client_side.cc(1400) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 204 No Content
Content-Length: 0
Content-Type: text/html; charset=UTF-8
Date: Wed, 26 Nov 2014 14:15:24 GMT
Server: GFE/2.0
X-Cache: MISS from local.local
Via: 1.1 local.local (squid/3.5.0.2)
Connection: keep-alive


----------
2014/11/27 01:15:24.700| store.cc(942) checkCachable: StoreEntry::checkCachable: NO: not cachable
2014/11/27 01:15:24.700| store_client.cc(731) invokeHandlers: InvokeHandlers: 5A1FB6665A738F63A93D8E42ECC6FB76
2014/11/27 01:15:24.700| store_client.cc(737) invokeHandlers: StoreEntry::InvokeHandlers: checking client #0
2014/11/27 01:15:24.700| http.cc(1052) persistentConnStatus: local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1 eof=0
2014/11/27 01:15:24.701| comm.cc(574) commUnsetConnTimeout: Remove timeout for local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1
2014/11/27 01:15:24.701| comm.cc(548) commSetConnTimeout: local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1 timeout -1
2014/11/27 01:15:24.701| FwdState.cc(443) unregister: http://www.gstatic.com/generate_204
2014/11/27 01:15:24.701| AsyncCall.cc(56) cancel: will not call SomeCloseHandler [call339] because comm_remove_close_handler
2014/11/27 01:15:24.701| pconn.cc(413) push: new IdleConnList for {173.194.113.23:80/www.gstatic.com}
2014/11/27 01:15:24.701| AsyncCall.cc(26) AsyncCall: The AsyncCall IdleConnList::Read constructed, this=0x34e7140 [call348]
2014/11/27 01:15:24.701| AsyncCall.cc(26) AsyncCall: The AsyncCall IdleConnList::Timeout constructed, this=0x3fdda20 [call349]
2014/11/27 01:15:24.701| comm.cc(548) commSetConnTimeout: local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1 timeout 60
2014/11/27 01:15:24.701| pconn.cc(425) push: pushed local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1 for 173.194.113.23:80/www.gstatic.com
2014/11/27 01:15:24.701| FwdState.cc(468) complete: http://www.gstatic.com/generate_204
	status 204
2014/11/27 01:15:24.701| FwdState.cc(1040) reforward: http://www.gstatic.com/generate_204?
2014/11/27 01:15:24.701| FwdState.cc(1043) reforward: No, ENTRY_FWD_HDR_WAIT isn't set
2014/11/27 01:15:24.701| FwdState.cc(492) complete: server (FD closed) not re-forwarding status 204
2014/11/27 01:15:24.701| store.cc(1028) complete: storeComplete: '5A1FB6665A738F63A93D8E42ECC6FB76'
2014/11/27 01:15:24.701| store.cc(1319) validLength: storeEntryValidLength: Checking '5A1FB6665A738F63A93D8E42ECC6FB76'
2014/11/27 01:15:24.701| store.cc(942) checkCachable: StoreEntry::checkCachable: NO: not cachable
2014/11/27 01:15:24.701| store_client.cc(731) invokeHandlers: InvokeHandlers: 5A1FB6665A738F63A93D8E42ECC6FB76
2014/11/27 01:15:24.701| store_client.cc(737) invokeHandlers: StoreEntry::InvokeHandlers: checking client #0
2014/11/27 01:15:24.701| store_client.cc(757) storePendingNClients: storePendingNClients: returning 1
2014/11/27 01:15:24.701| store.cc(523) unlock: Client unlocking key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=sp2XDIV/0x3540f60*4
2014/11/27 01:15:24.701| FwdState.cc(262) ~FwdState: FwdState destructor starting
2014/11/27 01:15:24.701| store.cc(523) unlock: FwdState unlocking key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=sp2XDIV/0x3540f60*3
2014/11/27 01:15:24.701| AsyncCall.cc(56) cancel: will not call fwdConnectDoneWrapper [call333] because FwdState destructed
2014/11/27 01:15:24.701| FwdState.cc(289) ~FwdState: FwdState destructor done
2014/11/27 01:15:24.701| IoCallback.cc(116) finish: called for local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33 (0, 0)
2014/11/27 01:15:24.701| client_side_reply.cc(1098) storeOKTransferDone: storeOKTransferDone  out.offset=0 objectLen()=140 headers_sz=140
2014/11/27 01:15:24.701| client_side.cc(1546) keepaliveNextRequest: ConnnStateData(local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33), Context(local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33)
2014/11/27 01:15:24.701| clientStream.cc(202) clientStreamDetach: clientStreamDetach: Detaching node 0x34cffe8
2014/11/27 01:15:24.702| clientStream.cc(287) clientStreamFree: Freeing clientStreamNode 0x34cffe8
2014/11/27 01:15:24.702| client_side_request.cc(246) ~ClientHttpRequest: httpRequestFree: http://www.gstatic.com/generate_204
2014/11/27 01:15:24.702| Checklist.cc(68) preCheck: 0x7fff3a655890 checking fast ACLs
2014/11/27 01:15:24.702| Acl.cc(156) matches: checked: (access_log daemon:/opt/squid/var/logs/access.log line) = 1
2014/11/27 01:15:24.702| Acl.cc(156) matches: checked: access_log daemon:/opt/squid/var/logs/access.log = 1
2014/11/27 01:15:24.702| Checklist.cc(61) markFinished: 0x7fff3a655890 answer ALLOWED for match
2014/11/27 01:15:24.702| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/opt/squid/var/logs/access.log: appending 1 bytes
2014/11/27 01:15:24.702| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 0 of 32768 bytes before append
2014/11/27 01:15:24.702| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/opt/squid/var/logs/access.log: appending 136 bytes
2014/11/27 01:15:24.702| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 1 of 32768 bytes before append
2014/11/27 01:15:24.702| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/opt/squid/var/logs/access.log: appending 2 bytes
2014/11/27 01:15:24.702| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 137 of 32768 bytes before append
2014/11/27 01:15:24.702| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff3a655890
2014/11/27 01:15:24.702| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff3a655890
2014/11/27 01:15:24.702| store.cc(523) unlock: ClientHttpRequest::loggingEntry unlocking key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=sp2XDIV/0x3540f60*2
2014/11/27 01:15:24.702| clientStream.cc(247) clientStreamAbort: clientStreamAbort: Aborting stream with tail 0x34f6ef8
2014/11/27 01:15:24.702| clientStream.cc(202) clientStreamDetach: clientStreamDetach: Detaching node 0x34f6ef8
2014/11/27 01:15:24.702| clientStream.cc(223) clientStreamDetach: clientStreamDetach: Calling 1 with cbdata 0x48b3f18
2014/11/27 01:15:24.702| clientStream.cc(287) clientStreamFree: Freeing clientStreamNode 0x34f6ef8
2014/11/27 01:15:24.702| store_client.cc(663) storeUnregister: storeUnregister: called for '5A1FB6665A738F63A93D8E42ECC6FB76'
2014/11/27 01:15:24.702| store.cc(942) checkCachable: StoreEntry::checkCachable: NO: not cachable
2014/11/27 01:15:24.702| store.cc(485) lock: storeUnregister locked key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=sp2XDIV/0x3540f60*2
2014/11/27 01:15:24.702| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:24.702| store.cc(523) unlock: storeUnregister unlocking key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=sp2XDIV/0x3540f60*2
2014/11/27 01:15:24.702| store.cc(523) unlock: clientReplyContext::removeStoreReference unlocking key 5A1FB6665A738F63A93D8E42ECC6FB76 e:=sp2XDIV/0x3540f60*1
2014/11/27 01:15:24.702| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2014/11/27 01:15:24.702| store.cc(1221) release: releasing e:=sp2XDIV/0x3540f60*0 5A1FB6665A738F63A93D8E42ECC6FB76
2014/11/27 01:15:24.702| store.cc(404) destroyMemObject: destroyMemObject 0x3d2ef20
2014/11/27 01:15:24.702| MemObject.cc(110) ~MemObject: del MemObject 0x3d2ef20
2014/11/27 01:15:24.702| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3540f68
2014/11/27 01:15:24.702| store.cc(404) destroyMemObject: destroyMemObject 0
2014/11/27 01:15:24.702| client_side.cc(1616) keepaliveNextRequest: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33: calling conn->readNextRequest()
2014/11/27 01:15:24.703| comm.cc(548) commSetConnTimeout: local=173.194.113.23:80 remote=192.168.0.122:62975 FD 14 flags=33 timeout 120
2014/11/27 01:15:24.703| ModDaemon.cc(108) logfileHandleWrite: daemon:/opt/squid/var/logs/access.log: write returned 139
2014/11/27 01:15:27| Preparing for shutdown after 1 requests
2014/11/27 01:15:27| Waiting 0 seconds for active connections to finish
2014/11/27 01:15:27| Closing HTTP port 0.0.0.0:3128
2014/11/27 01:15:27.230| comm.cc(860) _comm_close: comm_close: start closing FD 24
2014/11/27 01:15:27.230| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 24
2014/11/27 01:15:27.230| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c30f8) [call26]
2014/11/27 01:15:27.230| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34ec4d0 [call357]
2014/11/27 01:15:27.230| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 24) [call357]
2014/11/27 01:15:27.230| Closing HTTP port 0.0.0.0:3131
2014/11/27 01:15:27.230| comm.cc(860) _comm_close: comm_close: start closing FD 25
2014/11/27 01:15:27.230| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 25
2014/11/27 01:15:27.230| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c3168) [call27]
2014/11/27 01:15:27.230| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x382af60 [call358]
2014/11/27 01:15:27.230| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 25) [call358]
2014/11/27 01:15:27.230| Closing HTTPS port 0.0.0.0:3132
2014/11/27 01:15:27.230| comm.cc(860) _comm_close: comm_close: start closing FD 26
2014/11/27 01:15:27.230| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 26
2014/11/27 01:15:27.230| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c3338) [call28]
2014/11/27 01:15:27.230| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3499230 [call359]
2014/11/27 01:15:27.230| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 26) [call359]
2014/11/27 01:15:27.230| Shutdown: Negotiate authentication.
2014/11/27 01:15:27.230| Scheme.cc(59) PurgeCredentialsCache: Erasing Digest authentication credentials from username cache.
2014/11/27 01:15:27.230| Config.cc(236) authenticateDigestNonceShutdown: Nonce cache shutdown
2014/11/27 01:15:27.230| Shutdown: Digest authentication.
2014/11/27 01:15:27.230| Shutdown: Basic authentication.
2014/11/27 01:15:27.230| main.cc(251) doShutdown: running RegisteredRunner::startShutdown
2014/11/27 01:15:27.230| AsyncCallQueue.cc(55) fireNext: entering Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c30f8)
2014/11/27 01:15:27.230| AsyncCall.cc(38) make: make call Comm::TcpAcceptor::handleClosure [call26]
2014/11/27 01:15:27.230| AsyncJob.cc(123) callStart: Comm::TcpAcceptor status in: FD -1, 0.0.0.0 [ job1]
2014/11/27 01:15:27.230| AsyncCallQueue.cc(57) fireNext: leaving Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c30f8)
2014/11/27 01:15:27.230| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 24)
2014/11/27 01:15:27.230| AsyncCall.cc(38) make: make call comm_close_complete [call357]
2014/11/27 01:15:27.230| fd.cc(93) fd_close: fd_close FD 24 HTTP Socket
2014/11/27 01:15:27.230| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 24)
2014/11/27 01:15:27.230| AsyncCallQueue.cc(55) fireNext: entering Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c3168)
2014/11/27 01:15:27.230| AsyncCall.cc(38) make: make call Comm::TcpAcceptor::handleClosure [call27]
2014/11/27 01:15:27.230| AsyncJob.cc(123) callStart: Comm::TcpAcceptor status in: FD -1, 0.0.0.0 [ job2]
2014/11/27 01:15:27.230| AsyncCallQueue.cc(57) fireNext: leaving Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c3168)
2014/11/27 01:15:27.231| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 25)
2014/11/27 01:15:27.231| AsyncCall.cc(38) make: make call comm_close_complete [call358]
2014/11/27 01:15:27.231| fd.cc(93) fd_close: fd_close FD 25 HTTP Socket
2014/11/27 01:15:27.231| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 25)
2014/11/27 01:15:27.231| AsyncCallQueue.cc(55) fireNext: entering Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c3338)
2014/11/27 01:15:27.231| AsyncCall.cc(38) make: make call Comm::TcpAcceptor::handleClosure [call28]
2014/11/27 01:15:27.231| AsyncJob.cc(123) callStart: Comm::TcpAcceptor status in: FD -1, 0.0.0.0 [ job3]
2014/11/27 01:15:27.231| AsyncCallQueue.cc(57) fireNext: leaving Comm::TcpAcceptor::handleClosure(FD -1, data=0x33c3338)
2014/11/27 01:15:27.231| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 26)
2014/11/27 01:15:27.231| AsyncCall.cc(38) make: make call comm_close_complete [call359]
2014/11/27 01:15:27.231| fd.cc(93) fd_close: fd_close FD 26 HTTPS Socket
2014/11/27 01:15:27.231| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 26)
2014/11/27 01:15:28.231| Shutting down...
2014/11/27 01:15:28.526| comm.cc(860) _comm_close: comm_close: start closing FD 10
2014/11/27 01:15:28.526| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 10
2014/11/27 01:15:28.526| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3499230 [call364]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 10) [call364]
2014/11/27 01:15:28.526| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr1 shutting down.
2014/11/27 01:15:28.526| comm.cc(860) _comm_close: comm_close: start closing FD 11
2014/11/27 01:15:28.526| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 11
2014/11/27 01:15:28.526| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x2f70348, size=0, buf=0x2f72350) [call228]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x2f70348/0x2f70348) [call2]
2014/11/27 01:15:28.526| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x33c3490 [call365]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 11) [call365]
2014/11/27 01:15:28.526| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr2 shutting down.
2014/11/27 01:15:28.526| comm.cc(860) _comm_close: comm_close: start closing FD 13
2014/11/27 01:15:28.526| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 13
2014/11/27 01:15:28.526| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x2f73378, size=0, buf=0x2f73920) [call230]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x2f73378/0x2f73378) [call5]
2014/11/27 01:15:28.526| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x382af60 [call366]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 13) [call366]
2014/11/27 01:15:28.526| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr3 shutting down.
2014/11/27 01:15:28.526| comm.cc(860) _comm_close: comm_close: start closing FD 15
2014/11/27 01:15:28.526| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 15
2014/11/27 01:15:28.526| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x2f749d8, size=0, buf=0x2f74ef0) [call232]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x2f749d8/0x2f749d8) [call8]
2014/11/27 01:15:28.526| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x33c2ee0 [call367]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 15) [call367]
2014/11/27 01:15:28.526| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr4 shutting down.
2014/11/27 01:15:28.526| comm.cc(860) _comm_close: comm_close: start closing FD 17
2014/11/27 01:15:28.526| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 17
2014/11/27 01:15:28.526| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x2f75f18, size=0, buf=0x2f76350) [call234]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x2f75f18/0x2f75f18) [call11]
2014/11/27 01:15:28.526| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34ec4d0 [call368]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 17) [call368]
2014/11/27 01:15:28.526| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr5 shutting down.
2014/11/27 01:15:28.526| comm.cc(860) _comm_close: comm_close: start closing FD 19
2014/11/27 01:15:28.526| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 19
2014/11/27 01:15:28.526| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x2f77378, size=0, buf=0x2f77600) [call240]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x2f77378/0x2f77378) [call14]
2014/11/27 01:15:28.526| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x33c3060 [call369]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 19) [call369]
2014/11/27 01:15:28.526| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr6 shutting down.
2014/11/27 01:15:28.526| comm.cc(860) _comm_close: comm_close: start closing FD 46
2014/11/27 01:15:28.526| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 46
2014/11/27 01:15:28.526| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x2fa7e88, size=0, buf=0x3542580) [call242]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x2fa7e88/0x2fa7e88) [call130]
2014/11/27 01:15:28.526| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x354bd30 [call370]
2014/11/27 01:15:28.526| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 46) [call370]
2014/11/27 01:15:28.526| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr7 shutting down.
2014/11/27 01:15:28.526| comm.cc(860) _comm_close: comm_close: start closing FD 48
2014/11/27 01:15:28.526| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 48
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x353f2d8, size=0, buf=0x3541510) [call236]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x353f2d8/0x353f2d8) [call135]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34f6200 [call371]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 48) [call371]
2014/11/27 01:15:28.527| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr8 shutting down.
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 50
2014/11/27 01:15:28.527| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 50
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x3546ad8, size=0, buf=0x3544d20) [call238]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x3546ad8/0x3546ad8) [call140]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3511000 [call372]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 50) [call372]
2014/11/27 01:15:28.527| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr9 shutting down.
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 47
2014/11/27 01:15:28.527| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 47
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x34cfb88, size=0, buf=0x3547d20) [call244]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x34cfb88/0x34cfb88) [call145]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3506880 [call373]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 47) [call373]
2014/11/27 01:15:28.527| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr10 shutting down.
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 51
2014/11/27 01:15:28.527| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 51
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x34e71e8, size=0, buf=0x354ad20) [call216]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x34e71e8/0x34e71e8) [call150]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34d10a0 [call374]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 51) [call374]
2014/11/27 01:15:28.527| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr11 shutting down.
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 53
2014/11/27 01:15:28.527| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 53
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x2fa8d78, size=0, buf=0x354dd20) [call218]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x2fa8d78/0x2fa8d78) [call155]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34eb9f0 [call375]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 53) [call375]
2014/11/27 01:15:28.527| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr12 shutting down.
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 55
2014/11/27 01:15:28.527| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 55
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x34f18a8, size=0, buf=0x3550d20) [call220]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x34f18a8/0x34f18a8) [call160]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x34f6cb0 [call376]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 55) [call376]
2014/11/27 01:15:28.527| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr13 shutting down.
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 57
2014/11/27 01:15:28.527| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 57
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x354f738, size=0, buf=0x3553d20) [call222]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x354f738/0x354f738) [call165]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3498e70 [call377]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 57) [call377]
2014/11/27 01:15:28.527| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr14 shutting down.
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 59
2014/11/27 01:15:28.527| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 59
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x354f9c8, size=0, buf=0x3556d20) [call224]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x354f9c8/0x354f9c8) [call170]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x33c35c0 [call378]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 59) [call378]
2014/11/27 01:15:28.527| helper.cc(594) helperShutdown: helperShutdown: ssl_crtd #Hlpr15 shutting down.
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 61
2014/11/27 01:15:28.527| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 61
2014/11/27 01:15:28.527| IoCallback.cc(116) finish: called for local=[::] remote=[::] flags=1 (-10, 0)
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] flags=1, errno=11, flag=-10, data=0x3549788, size=0, buf=0x3559d20) [call226]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(722) will call helperServerFree(0x3549788/0x3549788) [call175]
2014/11/27 01:15:28.527| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x3b3e920 [call379]
2014/11/27 01:15:28.527| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 61) [call379]
2014/11/27 01:15:28.527| comm.cc(860) _comm_close: comm_close: start closing FD 10
2014/11/27 01:15:28.528| AsyncCall.cc(93) ScheduleCall: comm.cc(1526) will call IdleConnList::Timeout(local=192.168.0.121:19291 remote=173.194.113.23:80 FD 16 flags=1, data=0x49322d8) [call349]
2014/11/27 01:15:28.528| Gadgets.cc(99) authenticateReset: Reset authentication State.
2014/11/27 01:15:28.528| storeDirWriteCleanLogs: Starting...
2014/11/27 01:15:28.528|   Finished.  Wrote 0 entries.
2014/11/27 01:15:28.528|   Took 0.00 seconds (  0.00 entries/sec).
2014/11/27 01:15:28.528| Logfile: closing log daemon:/opt/squid/var/logs/access.log
2014/11/27 01:15:28.528| Logfile Daemon: closing log daemon:/opt/squid/var/logs/access.log
2014/11/27 01:15:28.528| comm.cc(860) _comm_close: comm_close: start closing FD 22
2014/11/27 01:15:28.528| comm.cc(535) commUnsetFdTimeout: Remove timeout for FD 22
2014/11/27 01:15:28.528| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2f74930 [call380]
2014/11/27 01:15:28.528| AsyncCall.cc(93) ScheduleCall: comm.cc(933) will call comm_close_complete(FD 22) [call380]
2014/11/27 01:15:28.528| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3387b08
2014/11/27 01:15:28.528| store.cc(404) destroyMemObject: destroyMemObject 0x33876e0
2014/11/27 01:15:28.528| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3387b00*0 from policy
2014/11/27 01:15:28.528| MemObject.cc(110) ~MemObject: del MemObject 0x33876e0
2014/11/27 01:15:28.528| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33708f8
2014/11/27 01:15:28.528| store.cc(404) destroyMemObject: destroyMemObject 0x3370960
2014/11/27 01:15:28.528| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33708f0*0 from policy
2014/11/27 01:15:28.528| MemObject.cc(110) ~MemObject: del MemObject 0x3370960
2014/11/27 01:15:28.528| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33b1618
2014/11/27 01:15:28.528| store.cc(404) destroyMemObject: destroyMemObject 0x33b2c20
2014/11/27 01:15:28.528| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33b1610*0 from policy
2014/11/27 01:15:28.528| MemObject.cc(110) ~MemObject: del MemObject 0x33b2c20
2014/11/27 01:15:28.528| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x339dd58
2014/11/27 01:15:28.528| store.cc(404) destroyMemObject: destroyMemObject 0x339ddc0
2014/11/27 01:15:28.528| store.cc(1656) setMemStatus: not removing special e:=msSV/0x339dd50*0 from policy
2014/11/27 01:15:28.528| MemObject.cc(110) ~MemObject: del MemObject 0x339ddc0
2014/11/27 01:15:28.528| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33721a8
2014/11/27 01:15:28.528| store.cc(404) destroyMemObject: destroyMemObject 0x3372210
2014/11/27 01:15:28.528| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33721a0*0 from policy
2014/11/27 01:15:28.528| MemObject.cc(110) ~MemObject: del MemObject 0x3372210
2014/11/27 01:15:28.529| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33929a8
2014/11/27 01:15:28.529| store.cc(404) destroyMemObject: destroyMemObject 0x3392a10
2014/11/27 01:15:28.529| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33929a0*0 from policy
2014/11/27 01:15:28.529| MemObject.cc(110) ~MemObject: del MemObject 0x3392a10
2014/11/27 01:15:28.529| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x339a9f8
2014/11/27 01:15:28.529| store.cc(404) destroyMemObject: destroyMemObject 0x339aa60
2014/11/27 01:15:28.529| store.cc(1656) setMemStatus: not removing special e:=msSV/0x339a9f0*0 from policy
2014/11/27 01:15:28.529| MemObject.cc(110) ~MemObject: del MemObject 0x339aa60
2014/11/27 01:15:28.529| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x338ae48
2014/11/27 01:15:28.529| store.cc(404) destroyMemObject: destroyMemObject 0x338aa40
2014/11/27 01:15:28.529| store.cc(1656) setMemStatus: not removing special e:=msSV/0x338ae40*0 from policy
2014/11/27 01:15:28.529| MemObject.cc(110) ~MemObject: del MemObject 0x338aa40
2014/11/27 01:15:28.529| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x338e198
2014/11/27 01:15:28.529| store.cc(404) destroyMemObject: destroyMemObject 0x338dd90
2014/11/27 01:15:28.529| store.cc(1656) setMemStatus: not removing special e:=msSV/0x338e190*0 from policy
2014/11/27 01:15:28.529| MemObject.cc(110) ~MemObject: del MemObject 0x338dd90
2014/11/27 01:15:28.529| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33ac988
2014/11/27 01:15:28.529| store.cc(404) destroyMemObject: destroyMemObject 0x33ac580
2014/11/27 01:15:28.529| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33ac980*0 from policy
2014/11/27 01:15:28.529| MemObject.cc(110) ~MemObject: del MemObject 0x33ac580
2014/11/27 01:15:28.529| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33aafd8
2014/11/27 01:15:28.529| store.cc(404) destroyMemObject: destroyMemObject 0x33aabd0
2014/11/27 01:15:28.530| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33aafd0*0 from policy
2014/11/27 01:15:28.530| MemObject.cc(110) ~MemObject: del MemObject 0x33aabd0
2014/11/27 01:15:28.530| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33b7858
2014/11/27 01:15:28.530| store.cc(404) destroyMemObject: destroyMemObject 0x33b78c0
2014/11/27 01:15:28.530| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33b7850*0 from policy
2014/11/27 01:15:28.530| MemObject.cc(110) ~MemObject: del MemObject 0x33b78c0
2014/11/27 01:15:28.530| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33820e8
2014/11/27 01:15:28.530| store.cc(404) destroyMemObject: destroyMemObject 0x33822a0
2014/11/27 01:15:28.530| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33820e0*0 from policy
2014/11/27 01:15:28.530| MemObject.cc(110) ~MemObject: del MemObject 0x33822a0
2014/11/27 01:15:28.530| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3395cf8
2014/11/27 01:15:28.530| store.cc(404) destroyMemObject: destroyMemObject 0x3395d60
2014/11/27 01:15:28.530| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3395cf0*0 from policy
2014/11/27 01:15:28.530| MemObject.cc(110) ~MemObject: del MemObject 0x3395d60
2014/11/27 01:15:28.530| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33b1698
2014/11/27 01:15:28.530| store.cc(404) destroyMemObject: destroyMemObject 0x33b1290
2014/11/27 01:15:28.530| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33b1690*0 from policy
2014/11/27 01:15:28.530| MemObject.cc(110) ~MemObject: del MemObject 0x33b1290
2014/11/27 01:15:28.530| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3379f48
2014/11/27 01:15:28.530| store.cc(404) destroyMemObject: destroyMemObject 0x3379fb0
2014/11/27 01:15:28.530| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3379f40*0 from policy
2014/11/27 01:15:28.530| MemObject.cc(110) ~MemObject: del MemObject 0x3379fb0
2014/11/27 01:15:28.531| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33ae338
2014/11/27 01:15:28.531| store.cc(404) destroyMemObject: destroyMemObject 0x33adf30
2014/11/27 01:15:28.531| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33ae330*0 from policy
2014/11/27 01:15:28.531| MemObject.cc(110) ~MemObject: del MemObject 0x33adf30
2014/11/27 01:15:28.531| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33a2f28
2014/11/27 01:15:28.531| store.cc(404) destroyMemObject: destroyMemObject 0x33a2ca0
2014/11/27 01:15:28.531| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33a2f20*0 from policy
2014/11/27 01:15:28.531| MemObject.cc(110) ~MemObject: del MemObject 0x33a2ca0
2014/11/27 01:15:28.531| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3373b58
2014/11/27 01:15:28.531| store.cc(404) destroyMemObject: destroyMemObject 0x3373bc0
2014/11/27 01:15:28.531| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3373b50*0 from policy
2014/11/27 01:15:28.531| MemObject.cc(110) ~MemObject: del MemObject 0x3373bc0
2014/11/27 01:15:28.531| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x339c3a8
2014/11/27 01:15:28.531| store.cc(404) destroyMemObject: destroyMemObject 0x339c410
2014/11/27 01:15:28.531| store.cc(1656) setMemStatus: not removing special e:=msSV/0x339c3a0*0 from policy
2014/11/27 01:15:28.531| MemObject.cc(110) ~MemObject: del MemObject 0x339c410
2014/11/27 01:15:28.531| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33a62d8
2014/11/27 01:15:28.531| store.cc(404) destroyMemObject: destroyMemObject 0x33a5ed0
2014/11/27 01:15:28.531| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33a62d0*0 from policy
2014/11/27 01:15:28.531| MemObject.cc(110) ~MemObject: del MemObject 0x33a5ed0
2014/11/27 01:15:28.531| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33a4948
2014/11/27 01:15:28.531| store.cc(404) destroyMemObject: destroyMemObject 0x33a4520
2014/11/27 01:15:28.531| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33a4940*0 from policy
2014/11/27 01:15:28.531| MemObject.cc(110) ~MemObject: del MemObject 0x33a4520
2014/11/27 01:15:28.532| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x339f708
2014/11/27 01:15:28.532| store.cc(404) destroyMemObject: destroyMemObject 0x339f770
2014/11/27 01:15:28.532| store.cc(1656) setMemStatus: not removing special e:=msSV/0x339f700*0 from policy
2014/11/27 01:15:28.532| MemObject.cc(110) ~MemObject: del MemObject 0x339f770
2014/11/27 01:15:28.532| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3380668
2014/11/27 01:15:28.532| store.cc(404) destroyMemObject: destroyMemObject 0x33806d0
2014/11/27 01:15:28.532| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3380660*0 from policy
2014/11/27 01:15:28.532| MemObject.cc(110) ~MemObject: del MemObject 0x33806d0
2014/11/27 01:15:28.532| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3389498
2014/11/27 01:15:28.532| store.cc(404) destroyMemObject: destroyMemObject 0x3389090
2014/11/27 01:15:28.532| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3389490*0 from policy
2014/11/27 01:15:28.532| MemObject.cc(110) ~MemObject: del MemObject 0x3389090
2014/11/27 01:15:28.532| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3375508
2014/11/27 01:15:28.532| store.cc(404) destroyMemObject: destroyMemObject 0x3375570
2014/11/27 01:15:28.532| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3375500*0 from policy
2014/11/27 01:15:28.532| MemObject.cc(110) ~MemObject: del MemObject 0x3375570
2014/11/27 01:15:28.532| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x338fac8
2014/11/27 01:15:28.532| store.cc(404) destroyMemObject: destroyMemObject 0x33910d0
2014/11/27 01:15:28.532| store.cc(1656) setMemStatus: not removing special e:=msSV/0x338fac0*0 from policy
2014/11/27 01:15:28.532| MemObject.cc(110) ~MemObject: del MemObject 0x33910d0
2014/11/27 01:15:28.532| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3399048
2014/11/27 01:15:28.532| store.cc(404) destroyMemObject: destroyMemObject 0x33990b0
2014/11/27 01:15:28.532| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3399040*0 from policy
2014/11/27 01:15:28.532| MemObject.cc(110) ~MemObject: del MemObject 0x33990b0
2014/11/27 01:15:28.533| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33693c8
2014/11/27 01:15:28.533| store.cc(404) destroyMemObject: destroyMemObject 0x33696c0
2014/11/27 01:15:28.533| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33693c0*0 from policy
2014/11/27 01:15:28.533| MemObject.cc(110) ~MemObject: del MemObject 0x33696c0
2014/11/27 01:15:28.533| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x337d308
2014/11/27 01:15:28.533| store.cc(404) destroyMemObject: destroyMemObject 0x337d370
2014/11/27 01:15:28.533| store.cc(1656) setMemStatus: not removing special e:=msSV/0x337d300*0 from policy
2014/11/27 01:15:28.533| MemObject.cc(110) ~MemObject: del MemObject 0x337d370
2014/11/27 01:15:28.533| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33b44f8
2014/11/27 01:15:28.533| store.cc(404) destroyMemObject: destroyMemObject 0x33b4560
2014/11/27 01:15:28.533| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33b44f0*0 from policy
2014/11/27 01:15:28.533| MemObject.cc(110) ~MemObject: del MemObject 0x33b4560
2014/11/27 01:15:28.533| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33847c8
2014/11/27 01:15:28.533| store.cc(404) destroyMemObject: destroyMemObject 0x3384420
2014/11/27 01:15:28.533| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33847c0*0 from policy
2014/11/27 01:15:28.533| MemObject.cc(110) ~MemObject: del MemObject 0x3384420
2014/11/27 01:15:28.533| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33bc568
2014/11/27 01:15:28.533| store.cc(404) destroyMemObject: destroyMemObject 0x33bc5d0
2014/11/27 01:15:28.533| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33bc560*0 from policy
2014/11/27 01:15:28.533| MemObject.cc(110) ~MemObject: del MemObject 0x33bc5d0
2014/11/27 01:15:28.533| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x338fb48
2014/11/27 01:15:28.533| store.cc(404) destroyMemObject: destroyMemObject 0x338f740
2014/11/27 01:15:28.533| store.cc(1656) setMemStatus: not removing special e:=msSV/0x338fb40*0 from policy
2014/11/27 01:15:28.533| MemObject.cc(110) ~MemObject: del MemObject 0x338f740
2014/11/27 01:15:28.534| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33c1268
2014/11/27 01:15:28.534| store.cc(404) destroyMemObject: destroyMemObject 0x33c12d0
2014/11/27 01:15:28.534| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33c1260*0 from policy
2014/11/27 01:15:28.534| MemObject.cc(110) ~MemObject: del MemObject 0x33c12d0
2014/11/27 01:15:28.534| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33a7c88
2014/11/27 01:15:28.534| store.cc(404) destroyMemObject: destroyMemObject 0x33a7860
2014/11/27 01:15:28.534| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33a7c80*0 from policy
2014/11/27 01:15:28.534| MemObject.cc(110) ~MemObject: del MemObject 0x33a7860
2014/11/27 01:15:28.534| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x337b958
2014/11/27 01:15:28.534| store.cc(404) destroyMemObject: destroyMemObject 0x337b9c0
2014/11/27 01:15:28.534| store.cc(1656) setMemStatus: not removing special e:=msSV/0x337b950*0 from policy
2014/11/27 01:15:28.534| MemObject.cc(110) ~MemObject: del MemObject 0x337b9c0
2014/11/27 01:15:28.534| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33b5ea8
2014/11/27 01:15:28.534| store.cc(404) destroyMemObject: destroyMemObject 0x33b5f10
2014/11/27 01:15:28.534| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33b5ea0*0 from policy
2014/11/27 01:15:28.534| MemObject.cc(110) ~MemObject: del MemObject 0x33b5f10
2014/11/27 01:15:28.534| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x338c7e8
2014/11/27 01:15:28.534| store.cc(404) destroyMemObject: destroyMemObject 0x338c3e0
2014/11/27 01:15:28.534| store.cc(1656) setMemStatus: not removing special e:=msSV/0x338c7e0*0 from policy
2014/11/27 01:15:28.534| MemObject.cc(110) ~MemObject: del MemObject 0x338c3e0
2014/11/27 01:15:28.534| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33babb8
2014/11/27 01:15:28.534| store.cc(404) destroyMemObject: destroyMemObject 0x33bac20
2014/11/27 01:15:28.534| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33babb0*0 from policy
2014/11/27 01:15:28.534| MemObject.cc(110) ~MemObject: del MemObject 0x33bac20
2014/11/27 01:15:28.535| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33afce8
2014/11/27 01:15:28.535| store.cc(404) destroyMemObject: destroyMemObject 0x33af8e0
2014/11/27 01:15:28.535| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33afce0*0 from policy
2014/11/27 01:15:28.535| MemObject.cc(110) ~MemObject: del MemObject 0x33af8e0
2014/11/27 01:15:28.535| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33bf8d8
2014/11/27 01:15:28.535| store.cc(404) destroyMemObject: destroyMemObject 0x33bf940
2014/11/27 01:15:28.535| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33bf8d0*0 from policy
2014/11/27 01:15:28.535| MemObject.cc(110) ~MemObject: del MemObject 0x33bf940
2014/11/27 01:15:28.535| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33a10c8
2014/11/27 01:15:28.535| store.cc(404) destroyMemObject: destroyMemObject 0x33a1130
2014/11/27 01:15:28.535| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33a10c0*0 from policy
2014/11/27 01:15:28.535| MemObject.cc(110) ~MemObject: del MemObject 0x33a1130
2014/11/27 01:15:28.535| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33bdf18
2014/11/27 01:15:28.535| store.cc(404) destroyMemObject: destroyMemObject 0x33bdf80
2014/11/27 01:15:28.535| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33bdf10*0 from policy
2014/11/27 01:15:28.535| MemObject.cc(110) ~MemObject: del MemObject 0x33bdf80
2014/11/27 01:15:28.535| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x337ecb8
2014/11/27 01:15:28.535| store.cc(404) destroyMemObject: destroyMemObject 0x337ed20
2014/11/27 01:15:28.535| store.cc(1656) setMemStatus: not removing special e:=msSV/0x337ecb0*0 from policy
2014/11/27 01:15:28.535| MemObject.cc(110) ~MemObject: del MemObject 0x337ed20
2014/11/27 01:15:28.535| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3386168
2014/11/27 01:15:28.535| store.cc(404) destroyMemObject: destroyMemObject 0x3385d40
2014/11/27 01:15:28.535| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3386160*0 from policy
2014/11/27 01:15:28.536| MemObject.cc(110) ~MemObject: del MemObject 0x3385d40
2014/11/27 01:15:28.536| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33b9208
2014/11/27 01:15:28.536| store.cc(404) destroyMemObject: destroyMemObject 0x33b9270
2014/11/27 01:15:28.536| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33b9200*0 from policy
2014/11/27 01:15:28.536| MemObject.cc(110) ~MemObject: del MemObject 0x33b9270
2014/11/27 01:15:28.536| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x3394368
2014/11/27 01:15:28.536| store.cc(404) destroyMemObject: destroyMemObject 0x33943d0
2014/11/27 01:15:28.536| store.cc(1656) setMemStatus: not removing special e:=msSV/0x3394360*0 from policy
2014/11/27 01:15:28.536| MemObject.cc(110) ~MemObject: del MemObject 0x33943d0
2014/11/27 01:15:28.536| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33a9628
2014/11/27 01:15:28.536| store.cc(404) destroyMemObject: destroyMemObject 0x33a9220
2014/11/27 01:15:28.536| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33a9620*0 from policy
2014/11/27 01:15:28.536| MemObject.cc(110) ~MemObject: del MemObject 0x33a9220
2014/11/27 01:15:28.536| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x336be28
2014/11/27 01:15:28.536| store.cc(404) destroyMemObject: destroyMemObject 0x336bc50
2014/11/27 01:15:28.536| store.cc(1656) setMemStatus: not removing special e:=msSV/0x336be20*0 from policy
2014/11/27 01:15:28.536| MemObject.cc(110) ~MemObject: del MemObject 0x336bc50
2014/11/27 01:15:28.536| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x33976b8
2014/11/27 01:15:28.536| store.cc(404) destroyMemObject: destroyMemObject 0x3397720
2014/11/27 01:15:28.536| store.cc(1656) setMemStatus: not removing special e:=msSV/0x33976b0*0 from policy
2014/11/27 01:15:28.536| MemObject.cc(110) ~MemObject: del MemObject 0x3397720
2014/11/27 01:15:28.536| Open FD UNSTARTED     0 stdin
2014/11/27 01:15:28.536| Open FD UNSTARTED     1 stdout
2014/11/27 01:15:28.536| Open FD UNSTARTED     2 stderr
2014/11/27 01:15:28.536| Open FD READ/WRITE   10 DNS Socket IPv4
2014/11/27 01:15:28.536| Open FD READ/WRITE   11 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD UNSTARTED    12 client https start
2014/11/27 01:15:28.536| Open FD READ/WRITE   13 ssl_crtd #2
2014/11/27 01:15:28.536| Open FD READ/WRITE   14 Idle client: Waiting for next request
2014/11/27 01:15:28.536| Open FD READ/WRITE   15 ssl_crtd #3
2014/11/27 01:15:28.536| Open FD READ/WRITE   16 Idle server: 173.194.113.23:80/www.gstatic.com
2014/11/27 01:15:28.536| Open FD READ/WRITE   17 ssl_crtd #4
2014/11/27 01:15:28.536| Open FD READ/WRITE   19 ssl_crtd #5
2014/11/27 01:15:28.536| Open FD UNSTARTED    22 IPC UNIX STREAM Parent
2014/11/27 01:15:28.536| Open FD READ/WRITE   46 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   47 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   48 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   50 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   51 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   53 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   55 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   57 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   59 ssl_crtd #1
2014/11/27 01:15:28.536| Open FD READ/WRITE   61 ssl_crtd #1
2014/11/27 01:15:28.537| main.cc(1908) SquidShutdown: running RegisteredRunner::finishShutdown
2014/11/27 01:15:28.537| mem/Segment.cc(177) unlink: unlinked /squid-ssl_session_cache.shm segment
2014/11/27 01:15:28.537| mem/Segment.cc(177) unlink: unlinked /squid-cf__metadata.shm segment
2014/11/27 01:15:28.537| mem/Segment.cc(177) unlink: unlinked /squid-cf__queues.shm segment
2014/11/27 01:15:28.537| mem/Segment.cc(177) unlink: unlinked /squid-cf__readers.shm segment
2014/11/27 01:15:28.537| mem.cc(519) memClean: memCleanModule: 731 items in 0 chunks and 43 pools are left dirty
2014/11/27 01:15:28.537| tools.cc(610) enter_suid: enter_suid: PID 16232 taking root privileges
2014/11/27 01:15:28.537| tools.cc(543) leave_suid: leave_suid: PID 16232 called
2014/11/27 01:15:28.537| tools.cc(565) leave_suid: leave_suid: PID 16232 giving up root, becoming 'nobody'
2014/11/27 01:15:28.537| Squid Cache (Version 3.5.0.2): Exiting normally.
2014/11/27 01:15:28.537| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.537| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.538| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.539| Acl.cc(378) ~ACL: ACL::~ACL: '
2014/11/27 01:15:28.539| Acl.cc(378) ~ACL: ACL::~ACL: '

From eliezer at ngtech.co.il  Mon Dec  8 03:21:01 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 08 Dec 2014 05:21:01 +0200
Subject: [squid-users] https issues for google
In-Reply-To: <2329B68B3D676246BA0D1149E22F509F01A6FBBA@bneseqs20.bradnams.com.au>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
 <5484D5A4.3050708@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A6FBBA@bneseqs20.bradnams.com.au>
Message-ID: <5485191D.3000708@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

OK Glenn,

It's unclear on what side the SSL error is.
There are issues and the next step would be to try to run some openssl
s_client test towards these hosts.
An example throw a proxy and directly can be found in the next link:
http://stackoverflow.com/questions/3220419/openssl-s-client-using-a-proxy

We will see together the results of the basic test of direct
connection vs a tunneled connection from the proxy itself and
understand better the issue.

Eliezer

On 12/08/2014 02:25 AM, glenn.groves at bradnams.com.au wrote:
> --Iptables is enabled, I suspect this should not be a problem there
> as some SSL sites work. -- We do not use IPV6, I have tried
> disabling IPV6 in Centos and leaving as is, no difference there.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUhRkdAAoJENxnfXtQ8ZQUcgoIAIee9Ce5JCNYRt+zIZXdrtEE
OzHA9YO1xucI5/xEJlPXvV0x5O4g75HINOyE+K/KII+z/T92Lvfoa4rYmo4D7jxf
0fqjwfP9D3D2Xb58lhlhfdoXD69L36orVKROahCt/xVx5b+lOlQ2NJI3NXDG2GnX
UG7nJENWeKW+u2AY9934ydP223cd08q471tmXCZba6bUGCWdC3/IFS7w2XVwbTsU
ffiv7dZc1V4q45XgHpeGbqhUKZpFlyJ2zxpqYbW9y+OKpNgfGnn/4GqAheCqeDco
t+VE21aiJux0xy7uWVnNj7VVsn3cV3EUBei3UiHZ0AKCoGsRERCt8c2OOmJgcvM=
=5R6z
-----END PGP SIGNATURE-----


From hoangnatc at gmail.com  Mon Dec  8 05:03:13 2014
From: hoangnatc at gmail.com (Hoang Nguyen)
Date: Mon, 8 Dec 2014 12:03:13 +0700
Subject: [squid-users] Help for Squid buiding up
Message-ID: <CA+tDn=CDMtfSLS1e7QASJgsSdRpf7JZ=m5twnqfh_Xf68CPgkQ@mail.gmail.com>

Dear Squid Support

I'm newbie about Squid, could you help me to point out the error I get
while I installing the Squid

OS: Ubuntu LTS 12.04

I follow the guide on this link: http://www.e-cap.org/Documentation

$ tar -xzf squid-3.4.9.tar.gz
$ cd squid-3.4.9/
$ ./configure --enable-ecap && make && sudo make install

I do this step but I get these error for *#make* command



Your help is highly appreciated

Steve
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141208/497ff77a/attachment.htm>

From hoangnatc at gmail.com  Mon Dec  8 06:19:36 2014
From: hoangnatc at gmail.com (Hoang Nguyen)
Date: Mon, 8 Dec 2014 13:19:36 +0700
Subject: [squid-users] Help for Squid buiding up
In-Reply-To: <CA+tDn=Ar6WEEv2frs4be=RzEv1kMryU34DMcesohRJRVP90W1Q@mail.gmail.com>
References: <CA+tDn=Ar6WEEv2frs4be=RzEv1kMryU34DMcesohRJRVP90W1Q@mail.gmail.com>
Message-ID: <CA+tDn=CFNC2zsOu+Q3XxC_5R-QBw6oFKjBK_0MHRmtKWwASmcg@mail.gmail.com>

Hi,

I attached the capture of the error that I gets

Anyone can help?

Steve

2014-12-08 11:57 GMT+07:00 Hoang Nguyen <hoangnatc at gmail.com>:

> Dear Squid
>
> I'm newbie about Squid, could you help me to point out the error I get
> while I installing the Squid
>
> OS: Ubuntu LTS 12.04
>
> I follow the guide on this link: http://www.e-cap.org/Documentation
>
> $ tar -xzf squid-3.4.9.tar.gz
> $ cd squid-3.4.9/
> $ ./configure --enable-ecap && make && sudo make install
>
> I do this step but I get these error for *#make* command
>
>
>
>
> Your help is highly appreciated
>
> Steve
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141208/8e4323f4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Error Squid building up.png
Type: image/png
Size: 9957 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141208/8e4323f4/attachment.png>

From squid3 at treenet.co.nz  Mon Dec  8 07:57:21 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 08 Dec 2014 20:57:21 +1300
Subject: [squid-users] Help for Squid buiding up
In-Reply-To: <CA+tDn=CFNC2zsOu+Q3XxC_5R-QBw6oFKjBK_0MHRmtKWwASmcg@mail.gmail.com>
References: <CA+tDn=Ar6WEEv2frs4be=RzEv1kMryU34DMcesohRJRVP90W1Q@mail.gmail.com>
 <CA+tDn=CFNC2zsOu+Q3XxC_5R-QBw6oFKjBK_0MHRmtKWwASmcg@mail.gmail.com>
Message-ID: <548559E1.2050208@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 8/12/2014 7:19 p.m., Hoang Nguyen wrote:
> Hi,
> 
> I attached the capture of the error that I gets
> 
> Anyone can help?
> 

That looks like an error inside your compiler tools. Probably the
compielr is not the correct build for your CPU architecture.
Nothing we can do about that.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUhVnhAAoJELJo5wb/XPRj8lgIANAzgRuBmCBb6In+AzVN9PNy
DuAlKrikQz5geUPtzvPtQhze6KfcJzbIQSH0FgYIaQa5Bgj3w6nq0fgM0hq8rE0W
7EzxRWEUqN/3aNaKt+GmUkxOmI4Y7VqTi838kyFTed0B2FLch3euG7pmPrLAy5y2
i4lkrgXgQElHwLrnhzblXEwntCBViUsjR9gw5webVsj5sF1ny4tVTlqLGAOJNqwX
gU8XsjB2g41sLCnxCMRhR802rZnd8FmeItuwoyoL2rP3rP79Rq6xmgHIzlyqxn8G
E8vQHD5hwcVPGntgPYHZeNfvMYkzFo6k2MpUtdsO3tbfONk29bUGByyPuuwQRZk=
=LVcG
-----END PGP SIGNATURE-----


From hoangnatc at gmail.com  Mon Dec  8 08:23:02 2014
From: hoangnatc at gmail.com (Hoang Nguyen)
Date: Mon, 8 Dec 2014 15:23:02 +0700
Subject: [squid-users] Help for Squid buiding up
In-Reply-To: <548559E1.2050208@treenet.co.nz>
References: <CA+tDn=Ar6WEEv2frs4be=RzEv1kMryU34DMcesohRJRVP90W1Q@mail.gmail.com>
 <CA+tDn=CFNC2zsOu+Q3XxC_5R-QBw6oFKjBK_0MHRmtKWwASmcg@mail.gmail.com>
 <548559E1.2050208@treenet.co.nz>
Message-ID: <CA+tDn=BDXXMt-wsTXBQHuDoURDkAVGhe16RbS-X=dxUYi=utJw@mail.gmail.com>

Thanks Amos,

Do you have any recommendation for the CPU for squid?

2014-12-08 14:57 GMT+07:00 Amos Jeffries <squid3 at treenet.co.nz>:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 8/12/2014 7:19 p.m., Hoang Nguyen wrote:
> > Hi,
> >
> > I attached the capture of the error that I gets
> >
> > Anyone can help?
> >
>
> That looks like an error inside your compiler tools. Probably the
> compielr is not the correct build for your CPU architecture.
> Nothing we can do about that.
>
> Amos
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUhVnhAAoJELJo5wb/XPRj8lgIANAzgRuBmCBb6In+AzVN9PNy
> DuAlKrikQz5geUPtzvPtQhze6KfcJzbIQSH0FgYIaQa5Bgj3w6nq0fgM0hq8rE0W
> 7EzxRWEUqN/3aNaKt+GmUkxOmI4Y7VqTi838kyFTed0B2FLch3euG7pmPrLAy5y2
> i4lkrgXgQElHwLrnhzblXEwntCBViUsjR9gw5webVsj5sF1ny4tVTlqLGAOJNqwX
> gU8XsjB2g41sLCnxCMRhR802rZnd8FmeItuwoyoL2rP3rP79Rq6xmgHIzlyqxn8G
> E8vQHD5hwcVPGntgPYHZeNfvMYkzFo6k2MpUtdsO3tbfONk29bUGByyPuuwQRZk=
> =LVcG
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141208/56b2be6a/attachment.htm>

From smkkannan at gmail.com  Mon Dec  8 08:28:37 2014
From: smkkannan at gmail.com (kamal kannan)
Date: Mon, 8 Dec 2014 13:58:37 +0530
Subject: [squid-users] Need to disable IPv6 / AAAA lookup in squid
Message-ID: <CA+nNoHmnpA53gOG7e=1jnmjeC0XBjctDPjkR9DNTfh5Lx1PKiA@mail.gmail.com>

Hi,

    I'm currently running squid 3.4.

Somtime facing below error/

""Connection to 2620:0:861:ed1a::1 failed."

"The system returned: (101) Network is unreachable""


Tried tcp_outgoing_address and dns_v4_first on.

But nothing fixes this issue.

Is there an option to disable AAAA lookup from squid.


Regards,
Kamal


From squid3 at treenet.co.nz  Mon Dec  8 09:00:25 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 08 Dec 2014 22:00:25 +1300
Subject: [squid-users] Need to disable IPv6 / AAAA lookup in squid
In-Reply-To: <CA+nNoHmnpA53gOG7e=1jnmjeC0XBjctDPjkR9DNTfh5Lx1PKiA@mail.gmail.com>
References: <CA+nNoHmnpA53gOG7e=1jnmjeC0XBjctDPjkR9DNTfh5Lx1PKiA@mail.gmail.com>
Message-ID: <548568A9.7010501@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 8/12/2014 9:28 p.m., kamal kannan wrote:
> Hi,
> 
> I'm currently running squid 3.4.
> 
> Somtime facing below error/
> 
> ""Connection to 2620:0:861:ed1a::1 failed."
> 
> "The system returned: (101) Network is unreachable""
> 
> 
> Tried tcp_outgoing_address and dns_v4_first on.
> 
> But nothing fixes this issue.
> 
> Is there an option to disable AAAA lookup from squid.
> 

No. IPv6 support has been mandatory in all networking software since
2012. (RFC 6540, also known as BCP 177).


The option available to make Squid prefer IPv4 over IPv6 is
"dns_v4_first on" which you found. With that Squid is already trying
all available IPv4 connections to the destination domain before its
tries any IPv6 ones. The reported "failed" IP was simply the last to
be tried out of the full set.

Possibly Squid was instructed to connect to exactly that IPv6 address
and no DNS is taking place at all.

Either way the entire domain/network is unreachable with the
information in the URL given.

If you get IPv6 working you may be able to access those URLs. That can
be as simple as installing miredo software, or setting up a 6to4
tunnel to 192.88.99.1, or both on the Squid machine.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUhWipAAoJELJo5wb/XPRjLyoH/jQ78etEn01kzq5DTZczmqnv
C0FgQfHv5re+csKeIQDESBHrB51HhqrG2xLXEp04//hfxDOUptwCH1b+gq1WGsL3
WuYegalOljjeQMFomfups+2nGgls99VbRLWboybunKJ420kIJ6lDF6BePk0PPmHR
Pm9SFvc3atF3K2DRQlv33zqFQJYsH8i7cXJ9Qa6wOtSCr7epCzC03RjN65/JRIHF
UHcB96e1NMD1FTRlljIyYTNXWa5dudECadzGqPbROraAkAXnQ4LGhDQSFM5j0gJt
pAKYW8HsOMkxBLRtiZTULBgyff++4DESOrg5wgTEI5zr7TbjeakQ2SnCp6RUckY=
=RRxZ
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Mon Dec  8 09:01:25 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 08 Dec 2014 22:01:25 +1300
Subject: [squid-users] Help for Squid buiding up
In-Reply-To: <CA+tDn=BDXXMt-wsTXBQHuDoURDkAVGhe16RbS-X=dxUYi=utJw@mail.gmail.com>
References: <CA+tDn=Ar6WEEv2frs4be=RzEv1kMryU34DMcesohRJRVP90W1Q@mail.gmail.com>	<CA+tDn=CFNC2zsOu+Q3XxC_5R-QBw6oFKjBK_0MHRmtKWwASmcg@mail.gmail.com>	<548559E1.2050208@treenet.co.nz>
 <CA+tDn=BDXXMt-wsTXBQHuDoURDkAVGhe16RbS-X=dxUYi=utJw@mail.gmail.com>
Message-ID: <548568E5.6080406@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 8/12/2014 9:23 p.m., Hoang Nguyen wrote:
> Thanks Amos,
> 
> Do you have any recommendation for the CPU for squid?

Squid does not require any particular CPU(s). Any will do.

What you do need though is a working compiler.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUhWjlAAoJELJo5wb/XPRjZcwH/jaGQfV8fZ4i0PDMRrFswbm0
WI01UVYw5k8i5Mb8tgO7zfTCNB41TvENjIwT77WUD9yTN7LFERoaiJPVepI9tsAv
0zUxKmtuR+VTkvivYrv2r4o8Z4+u0qwN4d+/aP+VmanPN94WM9u/UlRBQHQHFSjn
HiwMdb29IPuT9Gl/vOMuLSGVB3W+P0G91ej2s1DJNnjSKxwTzkToVqSS+4tbX9M8
JLhI4wj8zMpEmrWd+3IqWCW38yIheNmfmifpuTRnACJanpDGspBEWsRKSs6XnceK
TUf0P/TdjnvJGWW2TbfuJJvzukgDLiN2BU6VTujGcmoNQPY8VGMDE5Pqmr6Urdg=
=CBkp
-----END PGP SIGNATURE-----


From vdoctor at neuf.fr  Mon Dec  8 11:30:23 2014
From: vdoctor at neuf.fr (Stakres)
Date: Mon, 8 Dec 2014 03:30:23 -0800 (PST)
Subject: [squid-users] Squid 3.4.x Videos/Music Booster
In-Reply-To: <1417627965623-4668602.post@n4.nabble.com>
References: <1401445017211-4666154.post@n4.nabble.com>
 <1402342920545-4666272.post@n4.nabble.com>
 <CAOoxthOFdUyjpPcyNYx6maQ=8EJuX8LCm6EjFRQ6ySt4fUaRXQ@mail.gmail.com>
 <CAOoxthNhLP26KUWVy+OpPobQgb6oeU-Y7cQ+dMvghXXWfNrz=w@mail.gmail.com>
 <1402470426333-4666302.post@n4.nabble.com>
 <1402558228027-4666310.post@n4.nabble.com>
 <1412234862102-4667630.post@n4.nabble.com>
 <1415701988960-4668310.post@n4.nabble.com>
 <1417532987530-4668595.post@n4.nabble.com>
 <1417627965623-4668602.post@n4.nabble.com>
Message-ID: <1418038223871-4668643.post@n4.nabble.com>

Hi All,

New  build 2.05 <https://sourceforge.net/projects/squidvideosbooster>  

- New option "-g" to enable the Global Generic Patterns acting with
"not-yet" identified websites.
	This option will do its best to de-duplicate all websites.
- Bugs fix
- New websites added (600+)

Dedicated website about  SquidVideBooster and licensing
<http://www.unveiltech.com/indexsquidvideobooster.php>  :

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-4-x-Videos-Music-Booster-tp4666154p4668643.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Mon Dec  8 11:56:30 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 08 Dec 2014 13:56:30 +0200
Subject: [squid-users] Squid 3.4.x Videos/Music Booster
In-Reply-To: <1418038223871-4668643.post@n4.nabble.com>
References: <1401445017211-4666154.post@n4.nabble.com>
 <1402342920545-4666272.post@n4.nabble.com>
 <CAOoxthOFdUyjpPcyNYx6maQ=8EJuX8LCm6EjFRQ6ySt4fUaRXQ@mail.gmail.com>
 <CAOoxthNhLP26KUWVy+OpPobQgb6oeU-Y7cQ+dMvghXXWfNrz=w@mail.gmail.com>
 <1402470426333-4666302.post@n4.nabble.com>
 <1402558228027-4666310.post@n4.nabble.com>
 <1412234862102-4667630.post@n4.nabble.com>
 <1415701988960-4668310.post@n4.nabble.com>
 <1417532987530-4668595.post@n4.nabble.com>
 <1417627965623-4668602.post@n4.nabble.com>
 <1418038223871-4668643.post@n4.nabble.com>
Message-ID: <548591EE.3060706@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Thanks Fred for the great product!!
I have not tested it yet but it seems to be of a very high quality.

A tiny question:
Would squid debug_options relevant to StoreID feature be enough for
debugging?
If so notify me and I will collect them for the public list.

Eliezer Croitoru

On 12/08/2014 01:30 PM, Stakres wrote:
> Hi All,
> 
> New  build 2.05
> <https://sourceforge.net/projects/squidvideosbooster>
> 
> - New option "-g" to enable the Global Generic Patterns acting
> with "not-yet" identified websites. This option will do its best to
> de-duplicate all websites. - Bugs fix - New websites added (600+)
> 
> Dedicated website about  SquidVideBooster and licensing 
> <http://www.unveiltech.com/indexsquidvideobooster.php>  :
> 
> Bye Fred
> 
> 
> 
> -- View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-4-x-Videos-Music-Booster-tp4666154p4668643.html
>
> 
Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUhZHuAAoJENxnfXtQ8ZQU0hAH/A8e7fkHovJ7kNcZiF0viw/a
wNU0rp/s5nNAoWkDEfDZ/Uw2CUGqKBjlgDKWT4jGNTZXLIC2bcJjzfPA3QRExm3a
B8bS5IkNWDODqlYkSOJi0QG+R+ekMdifT6cvoJxF6WbggVyzUf+yLQ9SIqWRD69E
mqoEAEMwsyZm/biLSudQQjy55PTHrHyKF6nWVD6zptkTM/FmzP6E24hrFIsVRQt+
Qa3HIt39ptnksTDpwSKF28gM0mNGOfgN6+w7+PtdoIstqJf9Agv6gSyyFTd0VRdi
So7eiSuP0KP0Q71r3u0ACq0DHJGvGWq+KXjVQDuAKpDJjE2gMJ1p58GjyQonyD8=
=3FBA
-----END PGP SIGNATURE-----


From vdoctor at neuf.fr  Mon Dec  8 11:55:41 2014
From: vdoctor at neuf.fr (Stakres)
Date: Mon, 8 Dec 2014 03:55:41 -0800 (PST)
Subject: [squid-users] Squid 3.4.x Videos/Music Booster
In-Reply-To: <548591EE.3060706@ngtech.co.il>
References: <CAOoxthOFdUyjpPcyNYx6maQ=8EJuX8LCm6EjFRQ6ySt4fUaRXQ@mail.gmail.com>
 <CAOoxthNhLP26KUWVy+OpPobQgb6oeU-Y7cQ+dMvghXXWfNrz=w@mail.gmail.com>
 <1402470426333-4666302.post@n4.nabble.com>
 <1402558228027-4666310.post@n4.nabble.com>
 <1412234862102-4667630.post@n4.nabble.com>
 <1415701988960-4668310.post@n4.nabble.com>
 <1417532987530-4668595.post@n4.nabble.com>
 <1417627965623-4668602.post@n4.nabble.com>
 <1418038223871-4668643.post@n4.nabble.com> <548591EE.3060706@ngtech.co.il>
Message-ID: <1418039741740-4668645.post@n4.nabble.com>

Hi Eliezer,

"/Would squid debug_options relevant to StoreID feature be enough for
debugging?/"

Honestly ?
We don't know because we did not need Squid debug options to build this
plugin 
This is now developed in C++, the main issue is to be sure it'll work with
all Linux distri. without any additional linux tools/libraries...

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-4-x-Videos-Music-Booster-tp4666154p4668645.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Mon Dec  8 12:08:11 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 08 Dec 2014 14:08:11 +0200
Subject: [squid-users] Squid 3.4.x Videos/Music Booster
In-Reply-To: <1418039741740-4668645.post@n4.nabble.com>
References: <CAOoxthOFdUyjpPcyNYx6maQ=8EJuX8LCm6EjFRQ6ySt4fUaRXQ@mail.gmail.com>
 <CAOoxthNhLP26KUWVy+OpPobQgb6oeU-Y7cQ+dMvghXXWfNrz=w@mail.gmail.com>
 <1402470426333-4666302.post@n4.nabble.com>
 <1402558228027-4666310.post@n4.nabble.com>
 <1412234862102-4667630.post@n4.nabble.com>
 <1415701988960-4668310.post@n4.nabble.com>
 <1417532987530-4668595.post@n4.nabble.com>
 <1417627965623-4668602.post@n4.nabble.com>
 <1418038223871-4668643.post@n4.nabble.com> <548591EE.3060706@ngtech.co.il>
 <1418039741740-4668645.post@n4.nabble.com>
Message-ID: <548594AB.2090108@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

The answer to your question can be answered by "ldd"
##START
$ ldd ut-squidbooster
	linux-vdso.so.1 =>  (0x00007fffc5e00000)
	libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f176d3f0000)
	libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f176d0e8000)
	libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1
(0x00007f176ced8000)
	libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f176ccc0000)
	libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0
(0x00007f176caa0000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f176c6d8000)
	/lib64/ld-linux-x86-64.so.2 (0x00007f176d620000)
	librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f176c4d0000)
##END
Shows that these libs are used by the binary and from my knowledge it
should work on each and every normal linux distribution.
I can tell you that it works on ubuntu and others can test it on
CentOS and many others.

I wish you All The Bests and good luck with the product!
Eliezer

On 12/08/2014 01:55 PM, Stakres wrote:
> Hi Eliezer,
> 
> "/Would squid debug_options relevant to StoreID feature be enough
> for debugging?/"
> 
> Honestly ? We don't know because we did not need Squid debug
> options to build this plugin This is now developed in C++, the main
> issue is to be sure it'll work with all Linux distri. without any
> additional linux tools/libraries...
> 
> Bye Fred

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUhZSqAAoJENxnfXtQ8ZQUacsH/A34GMfH9SwrTy6oep6cfo72
1hslPyMiWLxhJ+6cQQfHqB8rTrSnvHwQ5bzqpMEvFIjC9zO0RQkRj5FF7uYLo3Ig
js6gNGfQlm05FBM/skiCIjLlF8KUSRjZZPJXdUWh00q4J0N4Pq9t7kGdBpaCZK9b
XgWf6azR1Rqy+2lGF/opm//g9gCZOoXDHc8BlnkHblF75iyfWP7Kq/eIHigu7P5C
QAj1ivkCeUwbIT9U7wQl6ACkjiejrBQtORi5+r7M893P94h1BYqfeSBcSaUXJj1c
MYX7zN6eBrtIdh8k3h1zD6Nie0aYa5HveTOXYGRNyIKSkWmTrwVOH/m1ghWYg6c=
=AXhh
-----END PGP SIGNATURE-----


From vdoctor at neuf.fr  Mon Dec  8 12:04:32 2014
From: vdoctor at neuf.fr (Stakres)
Date: Mon, 8 Dec 2014 04:04:32 -0800 (PST)
Subject: [squid-users] Squid 3.4.x Videos/Music Booster
In-Reply-To: <548594AB.2090108@ngtech.co.il>
References: <1402470426333-4666302.post@n4.nabble.com>
 <1402558228027-4666310.post@n4.nabble.com>
 <1412234862102-4667630.post@n4.nabble.com>
 <1415701988960-4668310.post@n4.nabble.com>
 <1417532987530-4668595.post@n4.nabble.com>
 <1417627965623-4668602.post@n4.nabble.com>
 <1418038223871-4668643.post@n4.nabble.com> <548591EE.3060706@ngtech.co.il>
 <1418039741740-4668645.post@n4.nabble.com> <548594AB.2090108@ngtech.co.il>
Message-ID: <1418040272135-4668647.post@n4.nabble.com>

Eliezer,

Good to know 

We indicate in the readme.txt the distri. we hve tested:
*Note: Currently SquidVideoBooster is available for Linux Debian, Ubuntu,
CentOS, Suse, etc...
Secific Linux distribution can be provided on demand.
*


Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-4-x-Videos-Music-Booster-tp4666154p4668647.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Jason_Haar at trimble.com  Mon Dec  8 12:35:03 2014
From: Jason_Haar at trimble.com (Jason Haar)
Date: Tue, 9 Dec 2014 01:35:03 +1300
Subject: [squid-users] anyone transparently proxying ipv6?
Message-ID: <54859AF7.6090302@trimble.com>

Hi there

We're not even running ipv6 yet so this is a curiosity question for me
:-) We're using transparent proxy for ipv4 (via WCCP); ipv6 will show up
at some stage - so forewarned is forearmed and all that

I see from the squid documentation that the normal transparent proxy
options disable ipv6 - except if it's TPROXY - in which case it's
"disables authentication and maybe IPv6 on the port"

It does look like TPROXY (via iptables) does support transparently
modifying packets in non-NAT mode, but the "maybe" makes me think it
isn't tested? Is anyone successfully transparently proxying ipv6
traffic? Can TPROXY be used over WCCP?

Thanks!

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From Jason_Haar at trimble.com  Wed Dec 10 15:15:57 2014
From: Jason_Haar at trimble.com (Jason Haar)
Date: Thu, 11 Dec 2014 04:15:57 +1300
Subject: [squid-users] odd wccp issue affecting only some web servers
In-Reply-To: <548108CA.9080805@treenet.co.nz>
References: <5480A0C4.90604@trimble.com> <548108CA.9080805@treenet.co.nz>
Message-ID: <548863AD.2020307@trimble.com>

On 05/12/14 14:22, Amos Jeffries wrote:
>
> One is a HIT the other a MISS?
>  Squid ACLs?
>  TCP connection issue?
>
Found the problem. We had three proxies and the Cisco ASA was load
balancing between them. Ended up the 2nd proxy had "INPUT DROP" instead
of "INPUT ALLOW" in iptables (everything else being correct and
eyeballed as "good") and simply didn't work as a transparent proxy! As
it was only 1 of 3, we had "some sites worked, some didn't". :-)

Fixed ;-)

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From ulises at vianetcon.com.ar  Tue Dec  9 17:04:25 2014
From: ulises at vianetcon.com.ar (Ulises Nicolini)
Date: Tue, 09 Dec 2014 14:04:25 -0300
Subject: [squid-users] Check if object is already cached
Message-ID: <54872B99.2010900@vianetcon.com.ar>

Hello,

I'm working with some scripts to prefetch content but having some 
trouble, what I can't work out is a way to check if a given object is 
already cached, in other words, I want to check if the object I'm going 
to download is going to hit, in which case I can ignore it.
I've read squidclient man page but could not find something like it

Thanks

Ulises
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141209/14449f5e/attachment.htm>

From dougs at dawnsign.com  Wed Dec 10 15:22:37 2014
From: dougs at dawnsign.com (Doug Sampson)
Date: Wed, 10 Dec 2014 15:22:37 +0000
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
In-Reply-To: <54829B70.9080000@treenet.co.nz>
References: <E6B2517F8D6DBF4CABB8F38ACA367E783431AF29@Draco.dawnsign.com>
 <5473E101.4010907@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
 <547C2A11.6030403@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E783435DD36@Draco.dawnsign.com>
 <54829B70.9080000@treenet.co.nz>
Message-ID: <E6B2517F8D6DBF4CABB8F38ACA367E7834363160@Draco.dawnsign.com>

> Nothing particularly stands out as leaking. Although the cache memory
> pages (mem_node) in-use size is suspiciously close to half what you
> say the OS is reporting.
> 
> That makes me suspect that your OS is rounding up its allocations to
> 8KB of memory for each node. If that is the case the simplest
> workaround is to reduce cache_mem size down to below the point where
> the box will swap.

Okay, I'll keep dropping the cache_mem down until the system stops swapping. Hopefully not too much.

Would it make sense to add additional memory in order to reduce the possibility of swapping? Say, 1GB more?

> If you are game for it I have been wondering if we need to enable
> chunking for 64-bit systems. To test that run squid with environment
> variable MEMPOOLS=1.
>  Memory should then be allocated in larger blocks, but utilized much
> more compactly within those blocks for an overall saving on objects
> like mem_node. It is currently a rarely used feature though, so I'm
> not sure if there are any issues hiding.
> 

I'm reluctant to do this on a production server. Interfacing with our customers via social media et al is an important part of our business.

Nevertheless, I looked into how the MEMPOOLS parameter could be implemented in a FreeBSD machine. I couldn't find a post that clearly indicates how to implement it. The nearest reference I could find was that FreeBSD implements UMA which apparently with my limited knowledge is a parallel memory implementation of MEMPOOLS. Correct me if I'm terribly mistaken.

~Doug

From glenn.groves at bradnams.com.au  Mon Dec  8 23:57:55 2014
From: glenn.groves at bradnams.com.au (glenn.groves at bradnams.com.au)
Date: Tue, 9 Dec 2014 09:57:55 +1000
Subject: [squid-users] https issues for google
In-Reply-To: <5485191D.3000708@ngtech.co.il>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
 <5484D5A4.3050708@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A6FBBA@bneseqs20.bradnams.com.au>
 <5485191D.3000708@ngtech.co.il>
Message-ID: <2329B68B3D676246BA0D1149E22F509F01A6FC17@bneseqs20.bradnams.com.au>

Hi Eliezer,

The command for www.google.com failed to complete the connection with a unknown protocol error: 

openssl s_client -connect www.google.com:443 -showcerts
CONNECTED(00000003)
140623996839752:error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol:s23_clnt.c:766:
---
no peer certificate available
---
No client certificate CA names sent
---
SSL handshake has read 7 bytes and written 263 bytes
---
New, (NONE), Cipher is (NONE)
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
---

The command for www.google.com.au, google.com.au AND google.com all got the certificate fine, for example a snipt:

openssl s_client -connect www.google.com.au:443 -showcerts
CONNECTED(00000003)
depth=3 C = US, O = Equifax, OU = Equifax Secure Certificate Authority
verify return:1
depth=2 C = US, O = GeoTrust Inc., CN = GeoTrust Global CA
verify return:1
depth=1 C = US, O = Google Inc, CN = Google Internet Authority G2
verify return:1
depth=0 C = US, ST = California, L = Mountain View, O = Google Inc, CN = google.com
verify return:1
---
Certificate chain
 0 s:/C=US/ST=California/L=Mountain View/O=Google Inc/CN=google.com
   i:/C=US/O=Google Inc/CN=Google Internet Authority G2
------------------------------------
Server certificate
subject=/C=US/ST=California/L=Mountain View/O=Google Inc/CN=google.com
issuer=/C=US/O=Google Inc/CN=Google Internet Authority G2
---
No client certificate CA names sent
---
SSL handshake has read 10548 bytes and written 389 bytes
---
New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES128-GCM-SHA256
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : ECDHE-RSA-AES128-GCM-SHA256
    Session-ID: 363AA9E6E5446296B11FC1763C24C0C23D6D4D67E4E0D858CEAA9C3B8172CE9A
    Session-ID-ctx:
    Master-Key: 30AC2CE9E8447130F9A4664CEF9399075C5C97602F4908D532540CE3694558AF66D54A5390FAF137BB8121785D0B7BB3
    Key-Arg   : None
    Krb5 Principal: None
    PSK identity: None
    PSK identity hint: None
    TLS session ticket lifetime hint: 100800 (seconds)
    TLS session ticket:
    0000 - 58 90 ee 84 cd 6d 26 5f-13 10 64 4c df 9a 1d a2   X....m&_..dL....
    0010 - 61 fe 82 ea b8 28 c2 51-6d f4 d9 ac 4c a1 45 be   a....(.Qm...L.E.
    0020 - b4 e0 d0 2e 83 3b 08 f4-e1 20 0f 8d 7a fa 77 9f   .....;... ..z.w.
    0030 - 0b 15 5c a3 6f 36 a7 79-4a 8f 70 af ee 81 0e 34   ..\.o6.yJ.p....4
    0040 - 78 a0 ba 22 84 62 56 7f-19 37 19 d3 66 bd 9a e2   x..".bV..7..f...
    0050 - 5b a4 47 29 3d 73 32 a8-f8 2a 29 29 b6 81 1f 9b   [.G)=s2..*))....
    0060 - 74 bb a9 9a 6f 3a 70 5d-31 7c 5b ba 6c 06 2c 59   t...o:p]1|[.l.,Y
    0070 - 14 b9 c8 af d5 3e 05 15-48 52 2e c6 0e c6 31 15   .....>..HR....1.
    0080 - 26 2e a6 5f d7 e4 09 dd-24 f7 74 ac 5e bb 00 ea   &.._....$.t.^...
    0090 - 39 d8 70 0e ba 87 99 fe-ff 9c 02 cd bf f2 d4 8b   9.p.............
    00a0 - 2a c2 90 b2                                       *...

    Start Time: 1418082857
    Timeout   : 300 (sec)
    Verify return code: 0 (ok)




-----Original Message-----
From: Eliezer Croitoru [mailto:eliezer at ngtech.co.il] 
Sent: Monday, 8 December 2014 1:21 PM
To: squid-users at lists.squid-cache.org
Cc: Glenn Groves
Subject: Re: [squid-users] https issues for google

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

OK Glenn,

It's unclear on what side the SSL error is.
There are issues and the next step would be to try to run some openssl s_client test towards these hosts.
An example throw a proxy and directly can be found in the next link:
http://stackoverflow.com/questions/3220419/openssl-s-client-using-a-proxy

We will see together the results of the basic test of direct connection vs a tunneled connection from the proxy itself and understand better the issue.

Eliezer

On 12/08/2014 02:25 AM, glenn.groves at bradnams.com.au wrote:
> --Iptables is enabled, I suspect this should not be a problem there as 
> some SSL sites work. -- We do not use IPV6, I have tried disabling 
> IPV6 in Centos and leaving as is, no difference there.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUhRkdAAoJENxnfXtQ8ZQUcgoIAIee9Ce5JCNYRt+zIZXdrtEE
OzHA9YO1xucI5/xEJlPXvV0x5O4g75HINOyE+K/KII+z/T92Lvfoa4rYmo4D7jxf
0fqjwfP9D3D2Xb58lhlhfdoXD69L36orVKROahCt/xVx5b+lOlQ2NJI3NXDG2GnX
UG7nJENWeKW+u2AY9934ydP223cd08q471tmXCZba6bUGCWdC3/IFS7w2XVwbTsU
ffiv7dZc1V4q45XgHpeGbqhUKZpFlyJ2zxpqYbW9y+OKpNgfGnn/4GqAheCqeDco
t+VE21aiJux0xy7uWVnNj7VVsn3cV3EUBei3UiHZ0AKCoGsRERCt8c2OOmJgcvM=
=5R6z
-----END PGP SIGNATURE-----
 
This message (including any attachments) is confidential and may be legally privileged. If you are not the intended recipient, you should not disclose, copy or use any part of it - please delete all copies immediately and notify the Bradnam Group Helpdesk at helpdesk at bradnams.com.au 

Any information, statements or opinions contained in this message (including any attachments) are given by the author. They are not given on behalf of the Bradnam Group unless subsequently confirmed by an individual other than the author who is duly authorised to represent the Bradnam Group (or any of its subsidiary and associate companies).

All sent and received email from/to the Bradnam Group (or any of its subsidiary and associate companies) is automatically scanned for the presence of computer viruses, security issues and inappropriate content.

For further information on the services which the Bradnam Group provides visit our web 
site(s) at www.bradnams.com.au or www.nationalglass.com.au


From ahmed.zaeem at netstream.ps  Wed Dec 10 23:42:42 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Wed, 10 Dec 2014 15:42:42 -0800
Subject: [squid-users] squid with kerberos
Message-ID: <001201d014d3$037fda70$0a7f8f50$@netstream.ps>

Hi ,

I have a Kerberos protected website. I am making a Kerberos enabled browser.

I need to test my browser for proxy support. 
At least, I must do these 2 tests:

1. make some of my servers only accessible via a proxy (to test my
software's proxy support)

2. have the proxy require authentication via Kerberos

I want you to prepare my environment, so I can do these 2 tests.

 

How can squid help me ???

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141210/8f1bb96c/attachment.htm>

From squid3 at treenet.co.nz  Wed Dec 10 15:40:14 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 11 Dec 2014 04:40:14 +1300
Subject: [squid-users] Check if object is already cached
In-Reply-To: <54872B99.2010900@vianetcon.com.ar>
References: <54872B99.2010900@vianetcon.com.ar>
Message-ID: <5488695E.7060105@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10/12/2014 6:04 a.m., Ulises Nicolini wrote:
> Hello,
> 
> I'm working with some scripts to prefetch content but having some 
> trouble, what I can't work out is a way to check if a given object
> is already cached, in other words, I want to check if the object
> I'm going to download is going to hit, in which case I can ignore
> it. I've read squidclient man page but could not find something
> like it
> 

While HIT means cached object was used, an object being in cache does
not mean it will HIT.

An object in cache can be stale, or could be a variant different from
what will be needed in future.

Pre-caching in HTTP has not been of much use since HTTP/1.1 started
getting popular. The HTTP/1.0 concept of HIT/MISS got extended and
expanded to include near-HIT or near-MISS or shared-HIT.

Back to your question... The way to check if an object is in cache is
to fetch it. If it was already there it will be refreshed, and if it
was missing it may now be cached (if cacheable).
 If you want to do the test without risking upstream bandwidth use the
squidclient parameter -H 'Cache-Control:only-if-cached\n' which will
return 200 status only if the cache does contain the object matching
the request.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUiGldAAoJELJo5wb/XPRjfdgIANEiy8Zbo3Yfo64hco//khUI
wf9GHxViAGEH2LmDopDrjxfmHsOjeZoZoeepCGh3NgHgGOaFo0wQAw1uYUd0QBxY
15YzLEyb5WFo/L6BmQM344RolFOrqygY+tNVQabyUWRZ9h0iMahStpOm7TZY44Ih
pPYyByNJLRTiixCtPDtqfCPgc+1dL0ZHjvc+//iw48HIocx9dmv8UEfFPMOsyGO4
+0LBXPvdYG3ccBpXJjJ9fYURR5G7EuTi3lnOvwR4Cf7vJyd8v06qjCK+yT20o6O4
A4MgAvbRN6eLTY9RZ6nnlbzqDmBnS8g19bjedhOkPx8mPWi4xeZWfUF8U8MBIMQ=
=FRb2
-----END PGP SIGNATURE-----


From squid at bloms.de  Mon Dec  8 15:48:25 2014
From: squid at bloms.de (Dieter Bloms)
Date: Mon, 8 Dec 2014 16:48:25 +0100
Subject: [squid-users] Squid doesn't do a fallback from ipv6 to ipv4,
 if the ipv6 connect fails
Message-ID: <20141208154825.GB9584@bloms.de>

Hello,

we use squid 3.4.9 as proxy for our company with ipv4 and ipv6 dual
stack.
It works good, but if a destination has an A and AAAA record and the
webserver isn't reachable via ipv6, squid generates an error page
instead of trying a connection via ipv4.

One example is the url:

https://ssl.ratsinfo-online.net/pirna-ri/logon.asp

where squid tries to reach the webside via the ip
2001:8d8:87c:5f00::6e:72d6, but without success, because it isn't
reachable.

Now I want, that squid does a fallback to ipv4 after connect_timeout,
but squid returns an error page (ERR_CONNECT_FAIL) to the client.


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From vrogoziansky.squid at gmail.com  Tue Dec  9 11:52:38 2014
From: vrogoziansky.squid at gmail.com (Vadim Rogoziansky)
Date: Tue, 09 Dec 2014 13:52:38 +0200
Subject: [squid-users] Transparent proxy with Peek and Splice feature.
In-Reply-To: <547948CF.5040408@treenet.co.nz>
References: <5474C8CF.6030404@gmail.com> <54759E6C.5080404@treenet.co.nz>
 <54772BB5.5010101@gmail.com> <547948CF.5040408@treenet.co.nz>
Message-ID: <5486E286.7020201@gmail.com>

Yeap, squid perfectly "splice" the destination domain after step1 or 
step2 or step3 when the browser is set to use proxy directly.
But, it does not work in case of transparent proxy. Squid uses the 
destination IP address instead of SNI details.

The example of using client IP address is below:
2014/11/27 01:15:22.851| DomainData.cc(110) match: aclMatchDomainList: 
'212.42.77.232' NOT found

Thank you guys.


11/29/2014 6:17 AM, Amos Jeffries ???????(??):
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 28/11/2014 2:48 a.m., Vadim Rogoziansky wrote:
>> Hello Amos.
>>
>> Thank you for answer.
>>
>> There was made an investigation related to squid's peek and splice
>> issues in transparent mode. One-line explanation is as follows - in
>> intercept mode squid can't get a server host name from the request
>> header and uses clent IP address instead for both fake cert
>> generation and as a SNI record in server bump SSL handshaking. This
>> is the root of the problem. However this can be fixed if squid uses
>> SNI field taken from client TLS Hello message for that purposes.
>> Can you hack squid in this way? What do you think?
> I think peek-n-splice is supposed to already be doing that.
>
> However it does depend on whether you are bumping the connection at
> step 1 (before ClientHello), step 2 (after ClientHello, before
> ServerHello), or step 3 (after both ClientHello and ServerHello) of
> the TLS handshake whether the SNI details are present.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUeUjPAAoJELJo5wb/XPRj6QEIAOHrR8wmDcjkfgUh2UtPwpHP
> vVkPMEuIrUq9Gxx3uSojCZjlFJPuCQ2UafS1p8LuxcEQ+TRmUFbAu4AkKoO2RoZ5
> 7fCGoiXTwn4TzFf0pLh9SPBq9j12OJ3uT28EEqbILrT0sbKP02xK/qiJfCLR61Ev
> vprAdggapbKg/ns1l1H3BBgZR2A4W/abQPIq6/Eu/r+7nYK6L2oOdqPDWTJjudMV
> 8D9sdOD9mYYryrdptU0GLh9Q/V5QEhipSkuA936iZ0Dfa2ZSr4gphJyaRAFWSMf3
> q502lZy+ASkDa2vAbjALRBgn3VwYWl8KBQcypUKF4UXtaLtF0EIrLMun+p4QxUM=
> =44aG
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Dec 10 11:31:35 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 10 Dec 2014 13:31:35 +0200
Subject: [squid-users] https issues for google
In-Reply-To: <2329B68B3D676246BA0D1149E22F509F01A6FC17@bneseqs20.bradnams.com.au>
References: <2329B68B3D676246BA0D1149E22F509F01A02886@bneseqs20.bradnams.com.au>
 <54345D6E.3090403@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A028F4@bneseqs20.bradnams.com.au>
 <5484D5A4.3050708@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A6FBBA@bneseqs20.bradnams.com.au>
 <5485191D.3000708@ngtech.co.il>
 <2329B68B3D676246BA0D1149E22F509F01A6FC17@bneseqs20.bradnams.com.au>
Message-ID: <54882F17.8040506@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Glen,

Since openssls_client is showing you this error I assume squid
received the same response.
We do need to verify why the connection is being hangs.
For now it seems like not 100% squid related issue.

Eliezer

On 12/09/2014 01:57 AM, glenn.groves at bradnams.com.au wrote:
> Hi Eliezer,
> 
> The command for www.google.com failed to complete the connection
> with a unknown protocol error:
> 
> openssl s_client -connect www.google.com:443 -showcerts 
> CONNECTED(00000003) 140623996839752:error:140770FC:SSL
> routines:SSL23_GET_SERVER_HELLO:unknown protocol:s23_clnt.c:766: 
> --- no peer certificate available --- No client certificate CA
> names sent --- SSL handshake has read 7 bytes and written 263
> bytes --- New, (NONE), Cipher is (NONE) Secure Renegotiation IS NOT
> supported Compression: NONE Expansion: NONE ---

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUiC8XAAoJENxnfXtQ8ZQUTsoH/39dKxH0hacCfys0J1zIy+wi
hsgWSsgGUAwAwKwa8uEp8XgAqIEACrpig9MUDXWAqaQYwuufu8HqP6bBUC4PG3mx
MGbXrbMc8gEs1+K1pxGEmwph9GruTJKxSlBavxWDcozj6x7x2N7SEXRHvcqoq9SE
rqZo16eO5vG3cOLa+rsAA/ouEDVHm55G/MC+647nrztQneW1iKFoDzdTqPKl40kF
9RQZwwbbP7cSCF8RZh5AfJwBNpPQKt0eUisJqcWp4w9Kx7Mz4j0Qk7dVQiQ9vTMD
rM8z+8SJfdUdWBnWdUU1Pl5qG0T2BUQHtnkM/lyz4OdRNQnGzXdlaY4KSpybKsA=
=tePH
-----END PGP SIGNATURE-----


From steve at opendium.com  Wed Dec 10 16:18:19 2014
From: steve at opendium.com (Steve Hill)
Date: Wed, 10 Dec 2014 16:18:19 +0000
Subject: [squid-users] Debugging slow access
Message-ID: <5488724B.9080304@opendium.com>


I'm looking for advice on figuring out what is causing intermittent high 
CPU usage.

I'm seeing this on multiple servers - most of the time everything is 
fine and I see the Squid workers using maybe 20% CPU each, but every so 
often all the workers sit at the top of the process list in "top", using 
 > 97% CPU each and users report very sluggish web access.

Using squidclient during "sluggish" periods is also very slow, with 
Squid taking several seconds to respond to the http requests.  The 
number of requests being handled by squid during the slow periods isn't 
especially high (maybe ~20 / second) and is certainly lower than the 
number of requests at other times - probably because it is taking so 
long to answer requests, but this seems to indicate that it isn't simply 
overloaded and having to deal with too many requests at once.

The during the "slow" periods, squid's servicing of requests seems very 
bursty in nature - I see a whole bunch of requests over a few hundred 
milliseconds and then nothing for maybe half a second.  There are no log 
entries that seem to coincide with these problems.

If I firewall off the clients, the load drops back to zero, so it seems 
this is something a client is doing that is causing Squid to expend a 
huge amount of CPU handling the request, rather than Squid getting stuck 
in a loop or similar.

Restarting squid seems to temporarily fix the problem, but it invariably 
comes back again at some point.

Notably the median service time go up:
	HTTP Requests (All):   0.30178  0.40454
	Cache Misses:          0.70906  0.65348
	Cache Hits:            0.00000  0.00000
	Near Hits:             0.00000  0.00000
	Not-Modified Replies:  0.00000  0.00000
	DNS Lookups:           0.02893  0.03092
	ICP Queries:           0.00000  0.00000

	UP Time:	11657.399 seconds
	CPU Time:	8843.268 seconds
	CPU Usage:	111.23%
	CPU Usage, 5 minute avg:	144.81%
	CPU Usage, 60 minute avg:	153.58%
	Maximum Resident Size: 2937536 KB
	Page faults with physical i/o: 3


Compared to (recently restarted):
	HTTP Requests (All):   0.09477  0.09477
	Cache Misses:          0.11465  0.11465
	Cache Hits:            0.00000  0.00000
	Near Hits:             0.00000  0.00000
	Not-Modified Replies:  0.00000  0.00000
	DNS Lookups:           0.00953  0.00953
	ICP Queries:           0.00000  0.00000

	UP Time:	293.336 seconds
	CPU Time:	127.775 seconds
	CPU Usage:	43.56%
	CPU Usage, 5 minute avg:	47.40%
	CPU Usage, 60 minute avg:	47.40%
	Maximum Resident Size: 799808 KB
	Page faults with physical i/o: 0


Is there any advice on how to track down what the problem is?

This Squid is doing:
  - No caching
  - ICAP
  - External ACLs
  - Auth (Negotiate and Basic)
  - SSL bump
  - Both TPROXY and non-transparent (majority of the traffic is 
non-transparent)
  - Uses an upstream proxy for most HTTP (not HTTPS)

-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Direct contacts:
    Instant messager: xmpp:steve at opendium.com
    Email:            steve at opendium.com
    Phone:            sip:steve at opendium.com

Sales / enquiries contacts:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support contacts:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From margaretofscotland at younghouse.info  Wed Dec 10 16:19:57 2014
From: margaretofscotland at younghouse.info (Stephen Young-Work)
Date: Wed, 10 Dec 2014 16:19:57 +0000
Subject: [squid-users] Parent Proxy Cache Problem
Message-ID: <CAA8G5W3pH=z_UXxocjuQ7A5rB=+OFgzvSXXPV5SQb2=sQcJchA@mail.gmail.com>

Hi, We have an upstream (parent) proxy that we have no control over and I
am trying to get squid to cache .ipa files and other large updates.

I have tested this offsite where there is no proxy and i get TCP_HIT on all
of the content when I download it for the second time (downloaded from
cache). However when i'm behind the parent proxy my squid doesn't seem able
to cache any data that is coming from upstream resulting in TCP_MISS every
time we download the file. This is resulting in our internet slowing to a
crawl.

If anyone has a way to enable this that would be great or additonally if i
can request a change to the parent proxy to allow this. I can post my
config if necessary.

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141210/b49cf3de/attachment.htm>

From squid3 at treenet.co.nz  Wed Dec 10 16:21:54 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 11 Dec 2014 05:21:54 +1300
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
In-Reply-To: <E6B2517F8D6DBF4CABB8F38ACA367E7834363160@Draco.dawnsign.com>
References: <E6B2517F8D6DBF4CABB8F38ACA367E783431AF29@Draco.dawnsign.com>
 <5473E101.4010907@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834342AF7@Draco.dawnsign.com>
 <547C2A11.6030403@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E783435DD36@Draco.dawnsign.com>
 <54829B70.9080000@treenet.co.nz>
 <E6B2517F8D6DBF4CABB8F38ACA367E7834363160@Draco.dawnsign.com>
Message-ID: <54887322.70309@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/12/2014 4:22 a.m., Doug Sampson wrote:
>> Nothing particularly stands out as leaking. Although the cache
>> memory pages (mem_node) in-use size is suspiciously close to half
>> what you say the OS is reporting.
>> 
>> That makes me suspect that your OS is rounding up its allocations
>> to 8KB of memory for each node. If that is the case the simplest 
>> workaround is to reduce cache_mem size down to below the point
>> where the box will swap.
> 
> Okay, I'll keep dropping the cache_mem down until the system stops
> swapping. Hopefully not too much.
> 
> Would it make sense to add additional memory in order to reduce the
> possibility of swapping? Say, 1GB more?

If you can afford that option, then yes.

> 
>> If you are game for it I have been wondering if we need to
>> enable chunking for 64-bit systems. To test that run squid with
>> environment variable MEMPOOLS=1. Memory should then be allocated
>> in larger blocks, but utilized much more compactly within those
>> blocks for an overall saving on objects like mem_node. It is
>> currently a rarely used feature though, so I'm not sure if there
>> are any issues hiding.
>> 
> 
> I'm reluctant to do this on a production server. Interfacing with
> our customers via social media et al is an important part of our
> business.
> 

Sure. No problem.

> Nevertheless, I looked into how the MEMPOOLS parameter could be
> implemented in a FreeBSD machine. I couldn't find a post that
> clearly indicates how to implement it. The nearest reference I
> could find was that FreeBSD implements UMA which apparently with my
> limited knowledge is a parallel memory implementation of MEMPOOLS.
> Correct me if I'm terribly mistaken.
> 

It is a shell environment variable Squid checks for when starting up.

Add the line:
  export MEMPOOLS=1

to the Squid init script, then run the script to restart the proxy.
likewise, remove the line and restart to stop using it.

NP: you may or may not need the "export" keyword depending on your shell.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUiHMhAAoJELJo5wb/XPRjx7wIAIkcEUEvdQ+vN5QbtEhBxERK
7iofy58y5BgPkoargu2BkLJXmLd+mAuanJOslL45RAyp1BlBJuDVi+rGX/rGvIBj
OOFbnIx99qbyysG4gkZcqu8S3TESzfJyQ8QTFGB39GK69fNXTymcK2+S+3GVLW/P
9u95j9EwMCYw5BZQcd5QJhaoLQqrkQeJ7/7jNXcB/7AEs5Ho4xT07tV66RS9c0BK
SUQrYEbYHOx+Xm4dOf2e1oF8JD8ilZ+Hyn+/7+pRMVkbvMN3fq/nG6Ibrhoo2CU+
JcwfK0a7/pgbEiJPb7TDCiaPjIHnkXnyI4d8eBRvEDbLytww3gXuETuqD/1OBFg=
=v4R3
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Wed Dec 10 16:35:26 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 11 Dec 2014 05:35:26 +1300
Subject: [squid-users] Squid doesn't do a fallback from ipv6 to ipv4,
 if the ipv6 connect fails
In-Reply-To: <20141208154825.GB9584@bloms.de>
References: <20141208154825.GB9584@bloms.de>
Message-ID: <5488764E.4020506@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 9/12/2014 4:48 a.m., Dieter Bloms wrote:
> Hello,
> 
> we use squid 3.4.9 as proxy for our company with ipv4 and ipv6
> dual stack. It works good, but if a destination has an A and AAAA
> record and the webserver isn't reachable via ipv6, squid generates
> an error page instead of trying a connection via ipv4.
> 
> One example is the url:
> 
> https://ssl.ratsinfo-online.net/pirna-ri/logon.asp
> 
> where squid tries to reach the webside via the ip 
> 2001:8d8:87c:5f00::6e:72d6, but without success, because it isn't 
> reachable.
> 
> Now I want, that squid does a fallback to ipv4 after
> connect_timeout, but squid returns an error page (ERR_CONNECT_FAIL)
> to the client.
> 

Squid rarely sees https:// URLs like that. Check if it is being given
the server name in a way that it can lookup all IPs, or just the one
IP address.

It also depends on how long the connection attempt(s) take.
 If it takes longer to lookup the DNS (dns_timeout) and try that one
IP (connect_timeout * connect_retries) than the entire transaction is
permitted to use (forward_timeout), then there is of course no time to
try anything else.

Note also that the message in the ERR_CONNECT_FAIL page is the result
of the final attempt made. Squid may have made several connection
attempts to other IP which also failed.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUiHZOAAoJELJo5wb/XPRj1TYH/Aid+TxcHzQNK4Q1Lw12Bwl6
QUx0vlpBKfmvzAq+9ucvavWePBSkKkLqmjsSasqqDebi26PuKvoTaJB02lZUdbKe
tDFlL9+1QWLfUCyqJDhZuUsnbD/rjVolvpk+Zu1RD6PvK2TSRG0YcaM68mefw7Wn
LFj4aKpo+pUaRJhdZHu3cKmG3SMREhq6z5rgHASyxnQhGUWugSg5NjCnHGzB0Qt1
5U79b3nmRO9bZ2st15iJG3B000v01NLojthSDZaTjYNR9LJ0eNIqVwa4ppEf399q
j/H6JyC5hNFXpX4LOtuGTY7sptAXCK4ItNJcAupV6TOkCJsesaQqk5SreOlxA/M=
=n1dE
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Wed Dec 10 16:39:15 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 11 Dec 2014 05:39:15 +1300
Subject: [squid-users] Parent Proxy Cache Problem
In-Reply-To: <CAA8G5W3pH=z_UXxocjuQ7A5rB=+OFgzvSXXPV5SQb2=sQcJchA@mail.gmail.com>
References: <CAA8G5W3pH=z_UXxocjuQ7A5rB=+OFgzvSXXPV5SQb2=sQcJchA@mail.gmail.com>
Message-ID: <54887733.6020907@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/12/2014 5:19 a.m., Stephen Young-Work wrote:
> Hi, We have an upstream (parent) proxy that we have no control over
> and I am trying to get squid to cache .ipa files and other large
> updates.
> 
> I have tested this offsite where there is no proxy and i get
> TCP_HIT on all of the content when I download it for the second
> time (downloaded from cache). However when i'm behind the parent
> proxy my squid doesn't seem able to cache any data that is coming
> from upstream resulting in TCP_MISS every time we download the
> file. This is resulting in our internet slowing to a crawl.
> 
> If anyone has a way to enable this that would be great or
> additonally if i can request a change to the parent proxy to allow
> this. I can post my config if necessary.

Please check your config for "proxy-only" option on the link to parent
proxy. That alone will prevent caching.

If that option is not there, please post your config.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUiHczAAoJELJo5wb/XPRjJ0UH/j+dHXhzrajdZygW/dcpykQU
hk+YtIxSORVPp3iU3VAOC8zLdGbvKFvuI0RQGQNH80wPHnvMcucbKHxQNRRoyhAB
rcv4UgfW//fD7Tpvv704NI4+Jp+e+8JoI5Sqq0qP9LryeRJCou1mgmCVg1zAsNwA
mnu/TTBH18kpzi3fHy1rAGPYh34+FvVEm1NlPI3B4YXYARPzfLPmpxFAgMwwYR5X
mvkDcwrXDoQ6lzPAFBJLPTFeQ+WgKqJCo1Zg7U/T9gf9mIzgg9YlNqwYX4p54OV3
hq13NZXacTJhiam6tDGCy+Rb6n1WphnPLAxUNqw17o21DAro9yHLcj9upfA0Aw4=
=7hA9
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Wed Dec 10 14:37:31 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 11 Dec 2014 03:37:31 +1300
Subject: [squid-users] [squid-announce] Squid 3.4.10 is available
Message-ID: <54885AAB.2000504@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.4.10 release!


This release is a bug fix release resolving several issues found in
the prior Squid releases.


The major changes to be aware of:


* Bug 4033: Rebuild corrupted ssl_db/size file

The certificate DB size file may become empty (for reasons beyond Squid
control such as server reboots, and possibly some unknown Squid bugs).
When it becomes empty, all ssl_crtd helpers (and then Squid) quit.


* Fixes Segmentation Fault in ACLUrlPathStrategy::match

This segmentation fault would occur when urlpath_regex ACL was used in
access controls to test transactions where no URL path is available.
 eg CONNECT or OPTIONS requests, some WebDAV requests, etc.


* Fixes Alternate-Protocol header behaviour

Certain servers emit the non-standard Alternate-Protocol header
without listing it as Connection header and popular client software
will attempt to follow its instructions regardless of the presence of
a proxy. This may result in loss of administrative information about
client traffic, increased network bandwidth, unpredictable client
failures, loss of connectivity for the client, information leakage
and/or other security vulnerabilities in experimental protocols.

Squid now handles this non-standard header on the clients behalf and
will cause it to only have any effect if the protocol it instructs to
be used is supported by Squid.


 All users of Squid are encouraged to upgrade to this release as
time permits.



 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.4/RELEASENOTES.html
when you are ready to make the switch to Squid-3.4

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUiFqrAAoJELJo5wb/XPRj+aMIAIDo6Mc/vtpkhN5XNwfOmwAD
xyaCv3f/b3CN4VyLjCGvbJ8us+nicuRGlg7IsCxBcICtID4Km1UvZEr6ouOpH6U1
7b/NIm5ftjO2HlcrxO14qLMGNCslkk60ByVCVk6vPA1aqnC5L+kujCyC9azqJS8a
w5nAtU/pSHdKrOzy9b+Cv83PqXwMXby1KuKALnDAx6o4qMFQVAC/mUQncd9JweCT
Y3PrMA2gC/iqSy1ZhXPeY3eUU6fHjRGh9s6B1nfgj7Okc4vmeL3lMnOINA24FNW4
TVriWwrrNMzNw5yEBLdH4q/wqpVXEZi47ihgk4lOiSEA8phAvC+c2MIA1I7uK1Y=
=eyPH
-----END PGP SIGNATURE-----
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From eliezer at ngtech.co.il  Wed Dec 10 18:42:54 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 10 Dec 2014 20:42:54 +0200
Subject: [squid-users] Check if object is already cached
In-Reply-To: <54872B99.2010900@vianetcon.com.ar>
References: <54872B99.2010900@vianetcon.com.ar>
Message-ID: <5488942E.4010004@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Ulises,

I am unsure about what exactly you have asked.
There are constrains and there is a current interface to squid
internal DB of objects.
The basic way is to use whats already there but since there is too
much unknown about the script you are working on I would try to think
about:
- - HTCP
- - ICP

squidclient man pages may or may not help you.
I remember that there was a tool that pre-fetch content into squid.

Since squid caching algorithm became much more complex, there are
always some cases which you as a cache admin cannot predict unless you
have knowledge on how the system(you want to cache) works.

The complexity of HTCP and ICP is that they are built in a binary
format which for some might not be that simple to work with.

Eliezer

On 12/09/2014 07:04 PM, Ulises Nicolini wrote:
> Hello,
> 
> I'm working with some scripts to prefetch content but having some 
> trouble, what I can't work out is a way to check if a given object
>  is already cached, in other words, I want to check if the object 
> I'm going to download is going to hit, in which case I can ignore 
> it. I've read squidclient man page but could not find something 
> like it
> 
> Thanks
> 
> Ulises


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUiJQuAAoJENxnfXtQ8ZQU1cQH/jOhlog+jRtBK8LkI6MyN16Q
gC5wptWJeakwUdiCsQ5MCByqbhuuye5K0BJSijWQbpqy87uSmcT+sTc9FlvgkemH
lz4IRySgjiHQqosIgKh6vYl987bykJFeyBqHAVxfEmC+zOx0r3cIYmzhahdqM7rV
1wKPDchvT1RqkCiDjcJ16yz7fyMDIaHADAG2qiWvtkVYxGP/SQum0LImbf4qu3be
1FaiSEazUqSei4saUlT4vPGEB3akEUiEJdL/jXCOp5pMb6qClNvHd/tOe2yv4i0V
6P6Pc5G6qP0Oh4FJ9d5CBpg4wkEYwyrCpxptnJO7dhKPsnRaQvOWFs2w/I0Xhs8=
=M6fd
-----END PGP SIGNATURE-----


From nobody at hushmail.com  Wed Dec 10 19:04:17 2014
From: nobody at hushmail.com (HaxNobody)
Date: Wed, 10 Dec 2014 11:04:17 -0800 (PST)
Subject: [squid-users] Existing root certificate not working with SSL
 Bump (squid 3.3.10)
In-Reply-To: <547AB5A1.3030702@treenet.co.nz>
References: <1416933493483-4668515.post@n4.nabble.com>
 <5475A124.4050208@treenet.co.nz> <1417021381827-4668526.post@n4.nabble.com>
 <1417023920196-4668527.post@n4.nabble.com> <547AB5A1.3030702@treenet.co.nz>
Message-ID: <1418238257941-4668666.post@n4.nabble.com>

Hello,

I found another possible cause. I have a certificate that works properly
with this proxy, and it has a signature algorithm of SHA256. The
certificates that I have that do not work properly are SHA1. Is this a
possible reason it's not working the way I want it to? If so, what options
do I have, other than regenerating my certificates?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Existing-root-certificate-not-working-with-SSL-Bump-squid-3-3-10-tp4668515p4668666.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Dec 10 19:27:43 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 10 Dec 2014 21:27:43 +0200
Subject: [squid-users] Existing root certificate not working with SSL
 Bump (squid 3.3.10)
In-Reply-To: <1418238257941-4668666.post@n4.nabble.com>
References: <1416933493483-4668515.post@n4.nabble.com>
 <5475A124.4050208@treenet.co.nz> <1417021381827-4668526.post@n4.nabble.com>
 <1417023920196-4668527.post@n4.nabble.com> <547AB5A1.3030702@treenet.co.nz>
 <1418238257941-4668666.post@n4.nabble.com>
Message-ID: <54889EAF.7030309@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/10/2014 09:04 PM, HaxNobody wrote:
> Hello,
> 
> I found another possible cause. I have a certificate that works
> properly with this proxy, and it has a signature algorithm of
> SHA256. The certificates that I have that do not work properly are
> SHA1. Is this a possible reason it's not working the way I want it
> to? If so, what options do I have, other than regenerating my
> certificates?
> 
What is your testing environment?
What OS?
What Browser?
Have you tried with openssl s_client?

Eliezer

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUiJ6vAAoJENxnfXtQ8ZQUQgEH/1HeNc0mHHFWVwahRC6FvKYf
kTysAdeuVAKoA+qDHWnIN0EFgBXmXeWasdXOeXZSoV/w5VWbt6ot1xECLPdmFGf9
1UNmMdzNMrqkygijT2XJs00qpOhKY8pxk3CmZKkTr5KPi0s31rWfKa2Zx1axTqNz
Qxsxw1TeVydfNM7iC7e6hr/M4D3mJVPqf2o3EcuINYLyzOkl2QO199HsibDPoT88
qoCKOhDBopxlFKW+SGEgPuYt1l2z202XinBY0xmMFwpGjje4aK3Yz8wqY4g5/UG0
z/CKdcLcQ+7Di48pjAA84Pz264zCml9gwKZJJ0Wgktytn7Eut7ZPcP/YKYeXQpk=
=QEsm
-----END PGP SIGNATURE-----


From nobody at hushmail.com  Wed Dec 10 19:25:04 2014
From: nobody at hushmail.com (HaxNobody)
Date: Wed, 10 Dec 2014 11:25:04 -0800 (PST)
Subject: [squid-users] Existing root certificate not working with SSL
 Bump (squid 3.3.10)
In-Reply-To: <54889EAF.7030309@ngtech.co.il>
References: <1416933493483-4668515.post@n4.nabble.com>
 <5475A124.4050208@treenet.co.nz> <1417021381827-4668526.post@n4.nabble.com>
 <1417023920196-4668527.post@n4.nabble.com> <547AB5A1.3030702@treenet.co.nz>
 <1418238257941-4668666.post@n4.nabble.com> <54889EAF.7030309@ngtech.co.il>
Message-ID: <1418239504656-4668668.post@n4.nabble.com>

>What is your testing environment?
>What OS?
>What Browser?
>Have you tried with openssl s_client?
>
>Eliezer

The proxy runs on Linux (Ubuntu, I believe), and I'm doing my testing from
multiple browsers on Windows 8.1.
I have been unable to find a way to use openssl s_client via a proxy,
although I was able to run it from the server itself, which gave me "Verify
return code: 20 (unable to get local issuer certificate)".





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Existing-root-certificate-not-working-with-SSL-Bump-squid-3-3-10-tp4668515p4668668.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Dec 10 21:13:53 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 10 Dec 2014 23:13:53 +0200
Subject: [squid-users] Existing root certificate not working with SSL
 Bump (squid 3.3.10)
In-Reply-To: <1418239504656-4668668.post@n4.nabble.com>
References: <1416933493483-4668515.post@n4.nabble.com>
 <5475A124.4050208@treenet.co.nz> <1417021381827-4668526.post@n4.nabble.com>
 <1417023920196-4668527.post@n4.nabble.com> <547AB5A1.3030702@treenet.co.nz>
 <1418238257941-4668666.post@n4.nabble.com> <54889EAF.7030309@ngtech.co.il>
 <1418239504656-4668668.post@n4.nabble.com>
Message-ID: <5488B791.606@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/10/2014 09:25 PM, HaxNobody wrote:
> The proxy runs on Linux (Ubuntu, I believe), and I'm doing my
> testing from multiple browsers on Windows 8.1. I have been unable
> to find a way to use openssl s_client via a proxy, although I was
> able to run it from the server itself, which gave me "Verify return
> code: 20 (unable to get local issuer certificate)".
Can you give me more details about the build environment?
squid -v
apparmor_status
ip addr

What are the steps you have taken while creating the private key for
the rootCA?

I have a lab here and I can test settings if needed.

Eliezer

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUiLeRAAoJENxnfXtQ8ZQUtq0H/Aox2HOHCE3LEwG905aEJrzd
dWdMU4iiW1SSccytj+dyFmBLd9b81XrhMaEL1AO0+GLDA3vhz6PvYS3waarcRYKw
VxHIDpWfku1ulB9Z1J+1rOtt+nYFDBRgLhg8daC2bugx8UXjAtHsjzV+sDuwaxbe
ip5snjTYN0+ct0Hmi4tBJAgPqEWX2cR+maSjTGlmMfO5akz4kun0Mgh4kDXS/V+F
7dUUPrYb1jBxpfN6+eQoznNoojzaxiWcZPQRPhUB2G/gmwNOWmS063b4f21xGONf
9kIizqwQAADA1x4sBOeRCJ8zyL6AXNxuCBhTVsZZZI1qb9bLE4my6WN2jG4Gj3g=
=4L6M
-----END PGP SIGNATURE-----


From nobody at hushmail.com  Wed Dec 10 21:23:46 2014
From: nobody at hushmail.com (HaxNobody)
Date: Wed, 10 Dec 2014 13:23:46 -0800 (PST)
Subject: [squid-users] Existing root certificate not working with SSL
 Bump (squid 3.3.10)
In-Reply-To: <5488B791.606@ngtech.co.il>
References: <1416933493483-4668515.post@n4.nabble.com>
 <5475A124.4050208@treenet.co.nz> <1417021381827-4668526.post@n4.nabble.com>
 <1417023920196-4668527.post@n4.nabble.com> <547AB5A1.3030702@treenet.co.nz>
 <1418238257941-4668666.post@n4.nabble.com> <54889EAF.7030309@ngtech.co.il>
 <1418239504656-4668668.post@n4.nabble.com> <5488B791.606@ngtech.co.il>
Message-ID: <1418246626371-4668670.post@n4.nabble.com>

squid -v:

Squid Cache: Version 3.3.10
configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr'
'--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
'--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var'
'--libexecdir=${prefix}/lib/bloxx-squid3' '--srcdir=.'
'--disable-maintainer-mode' '--disable-dependency-tracking'
'--disable-silent-rules' '--datadir=/usr/share/squid3'
'--sysconfdir=/etc/squid3' '--mandir=/usr/share/man'
'--with-cppunit-basedir=/usr' '--with-logdir=/var/log/squid3'
'--with-swapdir=/var/spool/squid3' '--with-pidfile=/var/run/squid3.pid'
'--enable-dependency-tracking' '--enable-wccp' '--enable-wccp2'
'--disable-icmp' '--disable-htcp' '--disable-ident-lookups' '--disable-poll'
'--enable-ssl' '--enable-epoll' '--enable-delay-pools'
'--enable-default-languages=English' '--enable-err-languages=English'
'--enable-storeio=diskd,ufs,aufs' '--enable-async-io' '--enable-auth'
'--enable-basic-auth-helpers=LDAP,NCSA'
'--enable-digest-auth-helpers=password' '--enable-icap-client'
'--enable-underscores' '--with-maxfd=65536' '--with-default-user=proxy'
'--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -Wall' 'LDFLAGS=-Wl,-Bsymbolic-functions
-Wl,-z,relro' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -Wall'

apparmor_status:

apparmor module is loaded.
7 profiles are loaded.
7 profiles are in enforce mode.
   /sbin/dhclient
   /usr/bin/freshclam
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/connman/scripts/dhclient-script
   /usr/sbin/clamd
   /usr/sbin/ntpd
   /usr/sbin/tcpdump
0 profiles are in complain mode.
2 processes have profiles defined.
2 processes are in enforce mode.
   /usr/bin/freshclam (1206)
   /usr/sbin/ntpd (1942)
0 processes are in complain mode.
0 processes are unconfined but have a profile defined.

ip addr:

1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state
UP qlen 1000
    link/ether 00:15:5d:28:60:31 brd ff:ff:ff:ff:ff:ff
    inet 192.168.137.138/24 brd 192.168.137.255 scope global eth0
3: gre0: <NOARP> mtu 1476 qdisc noop state DOWN
    link/gre 0.0.0.0 brd 0.0.0.0

Unfortunately, these CA certificates aren't ones that I have created, and I
don't know what OpenSSL config flags might have been used to create them. We
have had them in use with other proxy software without getting any errors or
browser warnings once the root is installed. It's only with this server that
we get errors and warnings, even with the same cert installed in the
browser/on the machine.

I don't really want to share any other specific info (certs, IP addresses)
publicly, but let me know if you need them for testing and I will email them
to you.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Existing-root-certificate-not-working-with-SSL-Bump-squid-3-3-10-tp4668515p4668670.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From huaraz at moeller.plus.com  Wed Dec 10 22:12:08 2014
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Wed, 10 Dec 2014 22:12:08 -0000
Subject: [squid-users] squid with kerberos
In-Reply-To: <001201d014d3$037fda70$0a7f8f50$@netstream.ps>
References: <001201d014d3$037fda70$0a7f8f50$@netstream.ps>
Message-ID: <m6agfu$4lp$1@ger.gmane.org>

Hi Ahmed,

  squid is a proxy which supports Kerberos authentication.

Markus

"Ahmed Allzaeem" <ahmed.zaeem at netstream.ps> wrote in message news:001201d014d3$037fda70$0a7f8f50$@netstream.ps...
Hi ,

I have a Kerberos protected website. I am making a Kerberos enabled browser. 
I need to test my browser for proxy support. 
At least, I must do these 2 tests:

1. make some of my servers only accessible via a proxy (to test my software's proxy support)

2. have the proxy require authentication via Kerberos

I want you to prepare my environment, so I can do these 2 tests.

 

How can squid help me ???



--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141210/f41577d1/attachment.htm>

From ssivaprakash666 at gmail.com  Thu Dec 11 10:31:14 2014
From: ssivaprakash666 at gmail.com (Siva Prakash)
Date: Thu, 11 Dec 2014 16:01:14 +0530
Subject: [squid-users] Maximum Bandwidth a squid server can Handle
Message-ID: <CAEuU1acL+TJwn9gwEY1TkBPXoNevNaKGPV8bA30bU75LpBOWTA@mail.gmail.com>

Hi All,

I have searched lot but i could not get clear statistics regrading how much
bandwidth a squid can handle.

Consider, I have a server of 4 GB RAM, Multicore processor and centos or
ubuntu operarting system.

Can any one guide me how much amount of bandwidth single squid sever can
handle?

or else help me out with how much request/second can be handled by squid?

Thanks in advance.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141211/95c9f5dc/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 11 11:12:39 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Dec 2014 00:12:39 +1300
Subject: [squid-users] Maximum Bandwidth a squid server can Handle
In-Reply-To: <CAEuU1acL+TJwn9gwEY1TkBPXoNevNaKGPV8bA30bU75LpBOWTA@mail.gmail.com>
References: <CAEuU1acL+TJwn9gwEY1TkBPXoNevNaKGPV8bA30bU75LpBOWTA@mail.gmail.com>
Message-ID: <54897C27.7040101@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/12/2014 11:31 p.m., Siva Prakash wrote:
> Hi All,
> 
> I have searched lot but i could not get clear statistics regrading
> how much bandwidth a squid can handle.
> 
> Consider, I have a server of 4 GB RAM, Multicore processor and
> centos or ubuntu operarting system.
> 
> Can any one guide me how much amount of bandwidth single squid
> sever can handle?

That question is like asking how much bandwidth "a CPU" can handle.
 The answer can only be "it depends".

It depends very much on:
 what Squid version you are talking about,
 what hardware its running on (NIC speed, CPU speed, disk I/O speed),
 what features have been configured for use,
 what ACL tests are being run,
 and finally ... what the input traffic actually contains.


> 
> or else help me out with how much request/second can be handled by
> squid?

Somewhere between 0 and 3000 RPS per-CPU. Still depending on the
things listed above.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUiXwnAAoJELJo5wb/XPRjDBQIAKHPvNslBERtoyBQF6jhLR51
KSai0HFYPXSjHRi9VRQa1id0ZulgOcG/bVos+fGkdptd8GSVcon2Lx5zeAtwYUGB
IRHZpHnP966E0vF5VsunLJ670qX37Zd9xwb8DkySWhDTGTiVYjl0ptMzNEovXoyB
U2X6MxqOcg9kMZ7H0+huQHV+V2+Ld0RGF7pwad5ScJIb5YU6Px75pvVYvAiituBT
8eCBiCgY5oAE4gMQHcZ6PDiPTbRWiXVuAmyCvxYp5b5iyvoS5cddVvm+QSHgx+VV
rYs1BJwxrNyjgBxP0Eumi9oD0nKId2spTR1KsXkILO+GMKokgOb5pK9mw8mRL/U=
=jRfr
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Thu Dec 11 12:39:14 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 11 Dec 2014 14:39:14 +0200
Subject: [squid-users] Maximum Bandwidth a squid server can Handle
In-Reply-To: <54897C27.7040101@treenet.co.nz>
References: <CAEuU1acL+TJwn9gwEY1TkBPXoNevNaKGPV8bA30bU75LpBOWTA@mail.gmail.com>
 <54897C27.7040101@treenet.co.nz>
Message-ID: <54899072.8040304@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

- From my experience it also depends on if you try to cache or not.
If you have a spinning disk and you try to cache into disk and not
only into ram you will have a bottle neck from the HDD.

If you will use only RAM cache a restart will cause to loss the cache.

If you will use squid without access logs it will help the overall speed.

If you will use squid with no access logs and disk cache and only use
it as a simple forward proxy the the server will be only a simple ACL
proxy and will be very fast.

Eliezer

On 12/11/2014 01:12 PM, Amos Jeffries wrote:
> That question is like asking how much bandwidth "a CPU" can
> handle. The answer can only be "it depends".
> 
> It depends very much on: what Squid version you are talking about, 
> what hardware its running on (NIC speed, CPU speed, disk I/O
> speed), what features have been configured for use, what ACL tests
> are being run, and finally ... what the input traffic actually
> contains.
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUiZBxAAoJENxnfXtQ8ZQUVCUIAInvMe07N0ac2HDEkGN6jlma
ib4bBn5S/BFwdyxyAbGvrlP0tbstrZpNCIwa/rKPuik1Mu7OJLqhJ2eNZcteLBDN
n5l1tqpE4yKqCyvxpwVOEVmyAMpXjvIsByQwz2HpSmMsSbHQPIOvZ/6KlotIHadi
AM3qQ1aqFZXfzoYF2Q4YKJNMy9XqVYASGU5L7oA5DGb3KtL9n1DNNqkapfy5MJ0t
KYTII8TqlqMAQ0MdMPKC7fAVrshPSWzHp/jAyc42CzqK6JFq0o1/2hZiieTNKg+7
7q5JLZTbhqC8m5ko+uEg2TjW1841kZNxgO1isCzAa/LwrRRkW3GhJO4Ko8xkW1E=
=WhAq
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Thu Dec 11 14:03:42 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 11 Dec 2014 16:03:42 +0200
Subject: [squid-users] Caching based on header/etag
In-Reply-To: <537B8823.4050705@treenet.co.nz>
References: <CAEwV=CcgdQ4yjDoBagTOvsZofYgTO_-1SHeQ2AaVPFqPe-owxA@mail.gmail.com>
 <537B8823.4050705@treenet.co.nz>
Message-ID: <5489A43E.50301@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

If you have access to the apache server it's very simple to remove the
headers.

I do have a question about the docs:
http://www.squid-cache.org/Versions/v3/3.4/cfgman/reply_header_access.html

Will the reply_header_access will affect the stored cache object?
If so or not what suppose to happen?

Thanks,
Eliezer

On 05/20/2014 07:51 PM, Amos Jeffries wrote:
> On 21/05/2014 3:43 a.m., Tom Holder wrote:
>> Hi all,
>> 
>> I've setup squid to proxy everything to a single server I have.
>> 
>> Based on a header, I might want to serve a different version of a
>> file for example for:
>> 
>> X-MY-HEADER: 1 URL: /css/style.css
>> 
>> Would not be the same as:
>> 
>> X-MY-HEADER: 2 URL: /css/style.css
>> 
>> Ideally though I'd like to be able to cache both.
>> 
>> Can I get squid to somehow differentiate based on an incoming
>> header?
>> 
>> Failing that, I'm generating an etag on the server that's a hash
>> of the content. Will this be enough to distinguish between the
>> different files?
> 
> Not by itself. ETag is used to confirm correct variant is being 
> revalidated or fetched once one is chosen.
> 
> You need the server to emit "Vary: X-MY-HEADER" on all responses
> to enable Squid to perform the initial selection.
> 
> Between them Vary, ETag and Last-Modified permit Squid to target a 
> specific object variant inside the set of possible responses to
> any dynamic resource URL.
> 
> Amos
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUiaQ9AAoJENxnfXtQ8ZQUHqwH/19gKkhG5zKlT7dndqUTZs/7
27Iv1kzzh1XU+nt6sVkhDZIaVztbEMuaG8GjIGWpCnEmBaqqXF6yqvrDBvZeZwfz
kbIiVKR+WTOxHWxURdnYq+wfEtqbIIQt08PrrlDGPJw7qnYc9mBR+d8XwYj+DK3R
ku6gBezLhJG+LDQdTXaIFhScJa+yWi3DqRZrbyG76kbG/1FnYJjVcchy5bjfHRwq
idbAbYHjYn1AFCyYlETRO/Mgs53t7nbsSJ7WXM4gHiwzJ5xvy1KvGZpBuGgM9mKx
KIif5MGexhGm1a5GrV0SOb5FFpSgWX21rrC3EkEG2MKKrCI10U6hig0aAiM4exg=
=6a6c
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Thu Dec 11 14:04:00 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 11 Dec 2014 16:04:00 +0200
Subject: [squid-users] Caching based on header/etag
In-Reply-To: <537B8823.4050705@treenet.co.nz>
References: <CAEwV=CcgdQ4yjDoBagTOvsZofYgTO_-1SHeQ2AaVPFqPe-owxA@mail.gmail.com>
 <537B8823.4050705@treenet.co.nz>
Message-ID: <5489A450.60408@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

If you have access to the apache server it's very simple to remove the
headers.

I do have a question about the docs:
http://www.squid-cache.org/Versions/v3/3.4/cfgman/reply_header_access.html

Will the reply_header_access will affect the stored cache object?
If so or not what suppose to happen?

Thanks,
Eliezer

On 05/20/2014 07:51 PM, Amos Jeffries wrote:
> On 21/05/2014 3:43 a.m., Tom Holder wrote:
>> Hi all,
>> 
>> I've setup squid to proxy everything to a single server I have.
>> 
>> Based on a header, I might want to serve a different version of a
>> file for example for:
>> 
>> X-MY-HEADER: 1 URL: /css/style.css
>> 
>> Would not be the same as:
>> 
>> X-MY-HEADER: 2 URL: /css/style.css
>> 
>> Ideally though I'd like to be able to cache both.
>> 
>> Can I get squid to somehow differentiate based on an incoming
>> header?
>> 
>> Failing that, I'm generating an etag on the server that's a hash
>> of the content. Will this be enough to distinguish between the
>> different files?
> 
> Not by itself. ETag is used to confirm correct variant is being 
> revalidated or fetched once one is chosen.
> 
> You need the server to emit "Vary: X-MY-HEADER" on all responses
> to enable Squid to perform the initial selection.
> 
> Between them Vary, ETag and Last-Modified permit Squid to target a 
> specific object variant inside the set of possible responses to
> any dynamic resource URL.
> 
> Amos
> 


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUiaRQAAoJENxnfXtQ8ZQUMTEH/3eoeTvOjVoa0HpM/HGxcEc/
BMdU0ODhYcxhShPckXK/WJJ7D6ihyI9srKZkAAt1msiDELsTMgLJwKg0er1Uf6fp
pzICv5hmlFviuyQkjzdoM6s1dhHVBUBSLMOI7KutxecC6FoGmGxWz/ModUWdeaGE
Na30IyAMgj3xdt2mtC/COv/SeEp3/n72Yqa9mrHToW3QiwqFhC2jYMXI7pTD88zl
qQHkFWbhHIby/miqHIETF13b4Ec/yLlcR+HwgCz08Lt8pbDktqLuu7TVYmg67XNF
3SeHQhJrv7vag44qz8jfU4BScKN3lEg7cEgd98DH1/Vivapxz55U1LNIFzC1wHc=
=ayHh
-----END PGP SIGNATURE-----


From vdoctor at neuf.fr  Thu Dec 11 14:01:48 2014
From: vdoctor at neuf.fr (Stakres)
Date: Thu, 11 Dec 2014 06:01:48 -0800 (PST)
Subject: [squid-users] Squid 3.4.x Videos/Music Booster
In-Reply-To: <1418040272135-4668647.post@n4.nabble.com>
References: <1402558228027-4666310.post@n4.nabble.com>
 <1412234862102-4667630.post@n4.nabble.com>
 <1415701988960-4668310.post@n4.nabble.com>
 <1417532987530-4668595.post@n4.nabble.com>
 <1417627965623-4668602.post@n4.nabble.com>
 <1418038223871-4668643.post@n4.nabble.com> <548591EE.3060706@ngtech.co.il>
 <1418039741740-4668645.post@n4.nabble.com> <548594AB.2090108@ngtech.co.il>
 <1418040272135-4668647.post@n4.nabble.com>
Message-ID: <1418306508598-4668677.post@n4.nabble.com>

Hi All,

New  build 2.12 <https://sourceforge.net/projects/squidvideosbooster/>  
available.
- New websites added
- New option "-shakir" to boost speedtest.net

Enjoy 

Dedicated website about SquidVideBooster and licensing:
http://www.unveiltech.com/indexsquidvideobooster.php

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-4-x-Videos-Music-Booster-tp4666154p4668677.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ssivaprakash666 at gmail.com  Thu Dec 11 15:41:07 2014
From: ssivaprakash666 at gmail.com (Siva Prakash)
Date: Thu, 11 Dec 2014 21:11:07 +0530
Subject: [squid-users] Maximum Bandwidth a squid server can Handle
In-Reply-To: <54899072.8040304@ngtech.co.il>
References: <CAEuU1acL+TJwn9gwEY1TkBPXoNevNaKGPV8bA30bU75LpBOWTA@mail.gmail.com>
 <54897C27.7040101@treenet.co.nz> <54899072.8040304@ngtech.co.il>
Message-ID: <CAEuU1afizDUUTty+=P1r_-udajdSQ2xQMKsT6OeZs8xiZZSH5g@mail.gmail.com>

Thanks for your valuable input, Eliezer and Amos.

I have added the rough hardware and squid configuration, please guide me
out with how much request squid can handle per second,

CPU Speed - each 3.30GHz( totally 5 processors)

RAM - 4 GB

NIC - one 10 GB Ethernet Adapter

Squid Version - 3.4

Squid configuration - For authentication, it is integrated with AD and lots
of ACLs(1000) to block sites.


On Thu, Dec 11, 2014 at 6:09 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> - From my experience it also depends on if you try to cache or not.
> If you have a spinning disk and you try to cache into disk and not
> only into ram you will have a bottle neck from the HDD.
>
> If you will use only RAM cache a restart will cause to loss the cache.
>
> If you will use squid without access logs it will help the overall speed.
>
> If you will use squid with no access logs and disk cache and only use
> it as a simple forward proxy the the server will be only a simple ACL
> proxy and will be very fast.
>
> Eliezer
>
> On 12/11/2014 01:12 PM, Amos Jeffries wrote:
> > That question is like asking how much bandwidth "a CPU" can
> > handle. The answer can only be "it depends".
> >
> > It depends very much on: what Squid version you are talking about,
> > what hardware its running on (NIC speed, CPU speed, disk I/O
> > speed), what features have been configured for use, what ACL tests
> > are being run, and finally ... what the input traffic actually
> > contains.
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQEcBAEBAgAGBQJUiZBxAAoJENxnfXtQ8ZQUVCUIAInvMe07N0ac2HDEkGN6jlma
> ib4bBn5S/BFwdyxyAbGvrlP0tbstrZpNCIwa/rKPuik1Mu7OJLqhJ2eNZcteLBDN
> n5l1tqpE4yKqCyvxpwVOEVmyAMpXjvIsByQwz2HpSmMsSbHQPIOvZ/6KlotIHadi
> AM3qQ1aqFZXfzoYF2Q4YKJNMy9XqVYASGU5L7oA5DGb3KtL9n1DNNqkapfy5MJ0t
> KYTII8TqlqMAQ0MdMPKC7fAVrshPSWzHp/jAyc42CzqK6JFq0o1/2hZiieTNKg+7
> 7q5JLZTbhqC8m5ko+uEg2TjW1841kZNxgO1isCzAa/LwrRRkW3GhJO4Ko8xkW1E=
> =WhAq
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141211/17560e37/attachment.htm>

From eliezer at ngtech.co.il  Thu Dec 11 18:52:30 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 11 Dec 2014 20:52:30 +0200
Subject: [squid-users] Maximum Bandwidth a squid server can Handle
In-Reply-To: <CAEuU1afizDUUTty+=P1r_-udajdSQ2xQMKsT6OeZs8xiZZSH5g@mail.gmail.com>
References: <CAEuU1acL+TJwn9gwEY1TkBPXoNevNaKGPV8bA30bU75LpBOWTA@mail.gmail.com>
 <54897C27.7040101@treenet.co.nz> <54899072.8040304@ngtech.co.il>
 <CAEuU1afizDUUTty+=P1r_-udajdSQ2xQMKsT6OeZs8xiZZSH5g@mail.gmail.com>
Message-ID: <5489E7EE.4050706@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/11/2014 05:41 PM, Siva Prakash wrote:
> Squid configuration - For authentication, it is integrated with AD
> and lots of ACLs(1000) to block sites.

Hey,

The acls should not be too much of an effect unless they are binded to
an external helper.
Every helper adds overhead and can cause some delay in the initiation
of a connection(needs a micro seconds tests in a lab).
In the squid 3.4 there were reports that clearly states about a bug
somewhere with AD authentication.
I am still not 100% convinced it's squid internals.
In any case it depends on what happens with the AD authentication.

Since you are using 3.4 and the bug do not exists on 3.3 I my first
suggestion is to make sure what are the options to narrow down the
options.

NTLM or kerberous authentication allow a higher level of encryption
which to my knowledge can be replaced with a radius server(in many
environments).
I do not suggest to replace AD or kerberous!!

Depends on your ACLs there might be a way to make it possible to lower
the usage of AD authentication when not needed.
One of the examples is windows updates or antivirus updates web-sites.

The hardware you are talking about without cache and access logs can
take care nicely 3k requests without sweat(unless the CPUs are very old).
So consider my suggestion about AD authentication and in any case
please do not use NTLM if possible.
If you can think of a way to use a radius server in your environment
it will help you lowering the need to rely on a feature which might
contain a bug.

All The Bests,
Eliezer
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUiefuAAoJENxnfXtQ8ZQUnQ8H/jdvuq4C8CnUHwwKRkSBpKnC
CZCigPRw9bJyhxHia2ZF3f+UEXkWLzi6oGzhX9oHV6zm0/sT5bpY35axV77/Fzep
0Sm4cfDlv4yS1IERae68jRXaUMIa0vUO7V3HTF9Y7IeV35CD3Yg8k+OnrlY3Gzn8
CxbddEewvwQYvWE6b30tZsa7HLUi9a18yprwyvfqECUItU4jsxnUNUQaOA1yFYMg
zz5RB3mTolMhqGCdjHwCPqsufw7x0jV7GSea+SSJDb1HHjqwj9lGa6CiTEtzgQzJ
VCad7Nthf5XpNkQQRN4yRNVozobGtf7cpCKr0PO8uEZpTCM+WEZeKZ+ng+UKb9w=
=9apR
-----END PGP SIGNATURE-----


From sven.falempin at gmail.com  Thu Dec 11 19:03:51 2014
From: sven.falempin at gmail.com (sven falempin)
Date: Thu, 11 Dec 2014 14:03:51 -0500
Subject: [squid-users] Configuring the sslbump
In-Reply-To: <CA++fYEiTvtuwhGuxpkC+rt=22OiFS=7GA_vOMzhzx4Rb_beH8w@mail.gmail.com>
References: <CA++fYEiTvtuwhGuxpkC+rt=22OiFS=7GA_vOMzhzx4Rb_beH8w@mail.gmail.com>
Message-ID: <CA++fYEjLGBG3pDiveBiLz0dgwPJWg=x4LhTenGQngwp9nWfkFA@mail.gmail.com>

On Fri, Dec 5, 2014 at 5:19 PM, sven falempin <sven.falempin at gmail.com> wrote:
> Hello Squid,
>
> I am trying the sslBump and just following the doc, i tried to also some
> random tutorial on the web that mostly looks like copy pasta of the wiki.
> All i got is a FATAL. .. . .
>
> 2014/12/05 17:07:24.472| src/ssl/support.cc(1584)
> readSslX509CertificatesChain: Certificate is self-signed, will not
>  be chained
> 2014/12/05 17:07:24.500| src/ssl/support.cc(1446) contextMethod: Using
> SSLv2/SSLv3.
> 2014/12/05 17:07:24.500| src/ssl/support.cc(857) configureSslContext:
> Setting RSA key generation callback.
> 2014/12/05 17:07:24.500| src/ssl/support.cc(860) configureSslContext:
> Setting CA certificate locations.
> 2014/12/05 17:07:24.505| src/ssl/support.cc(903) configureSslContext: Not
> requiring any client certificates
> 2014/12/05 17:07:24.505| Initializing https_port 0.0.0.0:3129 SSL context
> 2014/12/05 17:07:24.505| src/tools.cc(564) leave_suid: leave_suid: PID 10872
> called
> 2014/12/05 17:07:24.505| src/tools.cc(586) leave_suid: leave_suid: PID 10872
> giving up root, becoming '_squid'
> FATAL: No valid signing SSL certificate configured for HTTPS_port
> 0.0.0.0:3129
> Squid Cache (Version 3.HEAD-20140626-r13480): Terminated abnormally.
>
> my certificates are all right
> 2014/12/05 17:07:24.505| Initializing https_port 0.0.0.0:3129 SSL context
> but sundenly they are i dont recheck or something ?
>
> the only non logged code i see is this one :
>
>     if (!pkey || !cert || !X509_check_private_key(cert.get(), pkey.get())) {
>         pkey.reset(NULL);
>         cert.reset(NULL);
>     }
>
> But i swear i follow the doc and create the certificate normally.
>
> Is there a particular CN to use ?
> Shall i emit a self signed root and then another certificate for the proxy
> ??? is this error not related at all ? with the certificate on the sslbump
> lines ?
>
> Conf:
> # Squid normally listens to port 3128
> http_port 3128
> https_port 3129 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=2MB  cert=/etc/squid/sq
> uid-proxy.crt  key=/etc/squid/squid-proxy.key
>
> # dont forget ssl_crtd -c -s /var/db/squid/ssl when setup
> always_direct allow all
> ssl_bump client-first  all
> sslproxy_cert_error allow all
> # Or may be deny all according to your company policy
> # sslproxy_cert_error deny all
> sslproxy_flags DONT_VERIFY_PEER
> sslcrtd_program /usr/local/bin/ssl_crtd -s /var/db/squid/ssl -M 2MB
> sslcrtd_children 5
>
>
> Info:
>  # ls /var/db/squid/ssl
> certs     index.txt size
>
>
> --
> ---------------------------------------------------------------------------------------------------------------------
> () ascii ribbon campaign - against html e-mail
> /\


So looks like the squid guys didnt clone the certificate entry in
their clone method ( you guys are sure you wanna stick to c++ ??)

And this test is done

    if (Ip::EnableIpv6&IPV6_SPECIAL_SPLITSTACK && s->s.isAnyAddr()) {
        // clone the port options from *s to *(s->next)
        s->next = cbdataReference(s->clone());
        s->next->s.setIPv4();

So with the right config the program failed.


Workaround , bind it to an ip.

Well done guys


-- 
---------------------------------------------------------------------------------------------------------------------
() ascii ribbon campaign - against html e-mail
/\


From JP at kerrsolutions.com.au  Thu Dec 11 22:26:38 2014
From: JP at kerrsolutions.com.au (JP Greyling)
Date: Thu, 11 Dec 2014 22:26:38 +0000
Subject: [squid-users] Help with Windows updates
Message-ID: <74669a89ce604698a1ed8b6916d054a9@KSEXC.KERRSOLUTIONS.local>

Good day,

I am trying to configure Squid to cache all windows updates, I have followed the instructions on Squid's recommendations for Windows updates but I downloaded 10GB of updates and only 665MB got cached. My cache dir is 100GB. The Windows 8.1 upgrade did also not cache.

Can anyone please share their squid.conf windows updates settings with me including their referesh_paterns.

Kind Regards
JP
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141211/7120e912/attachment.htm>

From vdoctor at neuf.fr  Fri Dec 12 08:51:00 2014
From: vdoctor at neuf.fr (Stakres)
Date: Fri, 12 Dec 2014 00:51:00 -0800 (PST)
Subject: [squid-users] Squid 2.7,
	3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster
Message-ID: <1418374260739-4668683.post@n4.nabble.com>

Hi All,

Just to let you know the SquidVideoBooster is now compatible with Squid 2.7,
3.4 and 3.5 to speed up your Video, Music, Image files, Libraries (Jquery,
Bootstrap, etc...), Software Updates (Windows Update, Apple, Android,
etc...), Smartphone/Tablet Apps, CDNs.
It'll help you to save more than 50% of your bandwidth...
The plugin is available from
https://sourceforge.net/projects/squidvideosbooster/

The plugin takes into account 600+ web sites
(http://www.unveiltech.com/videosboost.php) including YouTube, DailyMotion,
Vimeo, Vevo, iMDB, Netflix, Windows Update, Anti-Virus updates, etc...

Read the readme.txt for the new compatibility with Squid 2.7.

Enjoy 

Dedicated website about SquidVideBooster and licensing:
http://www.unveiltech.com/indexsquidvideobooster.php

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraris-CDNs-Booster-tp4668683.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From windflower1201 at gmail.com  Fri Dec 12 09:31:02 2014
From: windflower1201 at gmail.com (Yu-Hsuan Liao)
Date: Fri, 12 Dec 2014 17:31:02 +0800
Subject: [squid-users] Skype bypass using ssl_bump peek
Message-ID: <CAGob8wB-U0jHSqKk4ePbXrM15pZWgFOfbrv0Z5pr+SxtH+5x-w@mail.gmail.com>

Hello everyone,

I'm trying to using Squid 3.5's new feature peek-and-splice to bypass
Skype connection
I'm a little confused about ssl_bump steps,
the wiki says that

peek Receive client (step SslBump1) or server (step SslBump2)
certificate while preserving the possibility of splicing the
connection.

My question is: does ssl_bump make decision to bump or splice connection
when Squid gets the ServerHello message?

cos I found that Skype voice connection is first

1. client send Clien tHello
2. server send Server Hello

then began the skype data payload transmit(non-SSL format, not the
rest SSL handshake)

so that I still got the "Error negotiating SSL connection on FD"
message in cache.log

Does peek-and-splice function cover above situation, or I just
misunderstand the usage of ssl_bump peek?

my squid ver. is 3.5.0.3

squid.config setting is

acl skype_list dstdomain "skype_list"
ssl_bump peek skype_list
ssl_bump stare all


Thanks.


From squid3 at treenet.co.nz  Fri Dec 12 09:45:49 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Dec 2014 22:45:49 +1300
Subject: [squid-users] Caching based on header/etag
In-Reply-To: <5489A450.60408@ngtech.co.il>
References: <CAEwV=CcgdQ4yjDoBagTOvsZofYgTO_-1SHeQ2AaVPFqPe-owxA@mail.gmail.com>
 <537B8823.4050705@treenet.co.nz> <5489A450.60408@ngtech.co.il>
Message-ID: <548AB94D.8020104@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/12/2014 3:04 a.m., Eliezer Croitoru wrote:
> If you have access to the apache server it's very simple to remove
> the headers.
> 
> I do have a question about the docs: 
> http://www.squid-cache.org/Versions/v3/3.4/cfgman/reply_header_access.html
>
>  Will the reply_header_access will affect the stored cache object? 
> If so or not what suppose to happen?

The reply_header_* directives should only be affecting the output
replies sent "over the wire" to clients. The cached object should
still have the original headers.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUirlKAAoJELJo5wb/XPRj/4EH/ioQB5i8mybxC/gSUEvi6/Bb
6+FCgUQ6o5SYNi4eUDkiklkha38m0njGLgReCQ8/w2+ffgMoTGVSO+IK+YHtgIbM
dQPSLkvdhgcDVTDu9Jlfpszhlgiy3FXPJCmU8XcG4gV50xGZzI77UVQ+JajH9QPE
Zb8Gob1QcGoz3mfiCVRuUr/ISqO/SRp7dTf/auMa28tI820YScYX6It0w8vYxWc6
De7KAJFzxd+Ca9N3xoWVyAsyHwt3s1jCQ7qmNxlrYbbIURofelG6W27JX1mcO6G7
WyyV8eV0GpCb6Hs7RqOtjFwoAUPcgbDqYZKuGUQpNe2XC2pHzvD9UOlLVziES5A=
=rl+1
-----END PGP SIGNATURE-----


From vdoctor at neuf.fr  Fri Dec 12 09:37:57 2014
From: vdoctor at neuf.fr (Stakres)
Date: Fri, 12 Dec 2014 01:37:57 -0800 (PST)
Subject: [squid-users] Help with Windows updates
In-Reply-To: <74669a89ce604698a1ed8b6916d054a9@KSEXC.KERRSOLUTIONS.local>
References: <74669a89ce604698a1ed8b6916d054a9@KSEXC.KERRSOLUTIONS.local>
Message-ID: <1418377077424-4668685.post@n4.nabble.com>

Hi JP,

Have you tried the SquidVideoBooster ?
It takes care Squid 2.7, 3.4 and 3.5 including Windows Update and hundred of
other websites.
https://sourceforge.net/projects/squidvideosbooster

Link to the  news
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraris-CDNs-Booster-tp4668683.html> 
.

Dedicated website about SquidVideoBooster and licensing:
http://www.unveiltech.com/indexsquidvideobooster.php

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Help-with-Windows-updates-tp4668681p4668685.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Dec 12 10:14:41 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Dec 2014 23:14:41 +1300
Subject: [squid-users] Maximum Bandwidth a squid server can Handle
In-Reply-To: <CAEuU1afizDUUTty+=P1r_-udajdSQ2xQMKsT6OeZs8xiZZSH5g@mail.gmail.com>
References: <CAEuU1acL+TJwn9gwEY1TkBPXoNevNaKGPV8bA30bU75LpBOWTA@mail.gmail.com>
 <54897C27.7040101@treenet.co.nz> <54899072.8040304@ngtech.co.il>
 <CAEuU1afizDUUTty+=P1r_-udajdSQ2xQMKsT6OeZs8xiZZSH5g@mail.gmail.com>
Message-ID: <548AC011.2060203@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/12/2014 4:41 a.m., Siva Prakash wrote:
> Thanks for your valuable input, Eliezer and Amos.
> 
> I have added the rough hardware and squid configuration, please
> guide me out with how much request squid can handle per second,
> 
> CPU Speed - each 3.30GHz( totally 5 processors)
> 
> RAM - 4 GB
> 
> NIC - one 10 GB Ethernet Adapter
> 
> Squid Version - 3.4
> 
> Squid configuration - For authentication, it is integrated with AD
> and lots of ACLs(1000) to block sites.
> 

On a 3.3GHz CPU core I would expect an upper limit of around 3000 RPS.

The bottlneck will be the AD processing delays. Most of HTTP
performance features and mechanisms have to be disabled in order to
get NTLM or Kerberos authentication to work. That reduces Squid
performance by roughly a factor of 3-4. You would be lucky to get 1000
RPS per core out of the auth systems, though not all requests need the
full auth latency so call it 1500 RPS max.

With 4 CPU for Squid and one for OS, thats 6-12K RPS for the machine.
If we assume your traffic has average object size ~40KB that measures
up at around 250 Mbps combined for 4 Squid worker processes.


These are very, very rough guesstimate *upper* limit numbers. The only
way to be at all sure is to actually run the traffic through the proxy
and find out. Squid has a lot of tuning knobs that can affect the
performance.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUir/jAAoJELJo5wb/XPRjzacIAOK9Dft9QpDtact+iKNWAVv1
KqfmZz1wHNyRc8+1do9WnKuyUvoS5WosDSE4NjCk3woc2sLVky5b0ifPsp0Z+qVx
MjDGx8ka74Yl5KUAimxFhn/ZdkNLDx1CHhFkH8am8mARwFR7yA++t16biB3QvDWT
zMB02DAqmJX0xRvyuqJNFUfqjaufQO3ftzFeJXTI1krCtYJxBU/Y5tQMhH/7cHhe
bOfTOTPUvWRnSNmbtZKrQJae+R87a66qyAj7Rr4S+YbkyvW3d0ORW0AfDV+JWF92
hZtsWu+mVzf6n3uObg6ah+610O0T30b1FdKwfjA5ssvQDxNcShChM1MfW5ctP20=
=q4IZ
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Dec 12 10:25:46 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Dec 2014 23:25:46 +1300
Subject: [squid-users] Skype bypass using ssl_bump peek
In-Reply-To: <CAGob8wB-U0jHSqKk4ePbXrM15pZWgFOfbrv0Z5pr+SxtH+5x-w@mail.gmail.com>
References: <CAGob8wB-U0jHSqKk4ePbXrM15pZWgFOfbrv0Z5pr+SxtH+5x-w@mail.gmail.com>
Message-ID: <548AC2AA.3040509@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/12/2014 10:31 p.m., Yu-Hsuan Liao wrote:
> Hello everyone,
> 
> I'm trying to using Squid 3.5's new feature peek-and-splice to
> bypass Skype connection I'm a little confused about ssl_bump
> steps, the wiki says that
> 
> peek Receive client (step SslBump1) or server (step SslBump2) 
> certificate while preserving the possibility of splicing the 
> connection.
> 
> My question is: does ssl_bump make decision to bump or splice
> connection when Squid gets the ServerHello message?
> 
> cos I found that Skype voice connection is first
> 

a) ssl_bump called (step 1) to decide what to do with no info but TCP
packet details available.

> 1. client send Client Hello

b) ssl_bump called again (step 2) to decide what to do with only
client and TCP details available.

> 2. server send Server Hello

c) ssl_bump called again (step 3) to decide what to do with all
client, server and TCP details available.

> 
> then began the skype data payload transmit(non-SSL format, not the 
> rest SSL handshake)
> 
> so that I still got the "Error negotiating SSL connection on FD" 
> message in cache.log
> 
> Does peek-and-splice function cover above situation, or I just 
> misunderstand the usage of ssl_bump peek?
> 

Not if you nee dto wait for the Skype payload before deciding what to
do during the bumping process.
If the TLS hello from either end included ALPN or a useful SNI value
they might be used to determine a step during bumping. Though I dont
think Squid acts on ALPN values yet.


> my squid ver. is 3.5.0.3
> 
> squid.config setting is
> 
> acl skype_list dstdomain "skype_list" ssl_bump peek skype_list 
> ssl_bump stare all
> 

Only if "skype_list" matches the TCP packet IP address (without rDNS
being looked up) will the peek happen.

I think you need to add at_step ACL test to peek always at step1, then
do the other actions at step2 once SNI (domain name) is possibly
available.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUisKqAAoJELJo5wb/XPRjNasIAOKpSpii9cuB1u3khGuADMKF
QQpyWrPYoJ4jG1HZRYz+w4SEkRYyDVqv16FA8o6/Pgbxknie/GRgqAdUAxF8iTAk
t96kDd9O8Futr/67iK/a7ry3ejW+IA4siJuZIpTl1FGx1Ku8W1I1lEOdjcJIJRSe
NfPmVc/ok6v9sKXmoTbbcMoG5YzBLE+g/LM5HQywMmTs0FMzrtgrfd6OTU+phV+Z
dkDGYo2pcKWjYuT+KXP3jw6Z37rENH4GxpKKHWXuzV3tvSpc30ACBxZ3Lk8N5417
1G9IcmDJoPoz7JBQMH+CVgtCMBJaEhtcodZkzCxvSejacMewu5N1oDKbRtaCGaM=
=D4zK
-----END PGP SIGNATURE-----


From alexander.bubnov at bk.ru  Fri Dec 12 13:10:55 2014
From: alexander.bubnov at bk.ru (=?UTF-8?B?QWxleGFuZGVyIEJ1Ym5vdg==?=)
Date: Fri, 12 Dec 2014 16:10:55 +0300
Subject: [squid-users] =?utf-8?q?ICAP=3A_how_to_get_port_of_X-Client-IP?=
Message-ID: <1418389855.19761439@f356.i.mail.ru>

 Hello!
Could you please help me?
There is a possibility to get IP address of squid client through extended ICAP X-Client-IP field. And is there a way to get port of that client who owns IP placed in X-Client-IP field?
I would like to know which application of a desktop computer establish connection to squid. I will happy with anyway of doing this even eICAP or ICAP or other way except modified source code of squid.

--
/BR, Alexander
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141212/a277c5fc/attachment.htm>

From ahmed.zaeem at netstream.ps  Sat Dec 13 01:21:00 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Fri, 12 Dec 2014 17:21:00 -0800
Subject: [squid-users] Squid 2.7,
	3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster
In-Reply-To: <1418374260739-4668683.post@n4.nabble.com>
References: <1418374260739-4668683.post@n4.nabble.com>
Message-ID: <004501d01673$0f445150$2dccf3f0$@netstream.ps>

Hi ,
I want to ask

Does it support working with squid smp ??

As I know smp don?t support more than 32 KB caching

Will it solve that issue ?

Plz reply me if it is.

regards

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Stakres
Sent: Friday, December 12, 2014 12:51 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid 2.7, 3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster

Hi All,

Just to let you know the SquidVideoBooster is now compatible with Squid 2.7,
3.4 and 3.5 to speed up your Video, Music, Image files, Libraries (Jquery, Bootstrap, etc...), Software Updates (Windows Update, Apple, Android, etc...), Smartphone/Tablet Apps, CDNs.
It'll help you to save more than 50% of your bandwidth...
The plugin is available from
https://sourceforge.net/projects/squidvideosbooster/

The plugin takes into account 600+ web sites
(http://www.unveiltech.com/videosboost.php) including YouTube, DailyMotion, Vimeo, Vevo, iMDB, Netflix, Windows Update, Anti-Virus updates, etc...

Read the readme.txt for the new compatibility with Squid 2.7.

Enjoy 

Dedicated website about SquidVideBooster and licensing:
http://www.unveiltech.com/indexsquidvideobooster.php

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraris-CDNs-Booster-tp4668683.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ssivaprakash666 at gmail.com  Fri Dec 12 15:37:51 2014
From: ssivaprakash666 at gmail.com (Siva Prakash)
Date: Fri, 12 Dec 2014 21:07:51 +0530
Subject: [squid-users] Maximum Bandwidth a squid server can Handle
In-Reply-To: <548AC011.2060203@treenet.co.nz>
References: <CAEuU1acL+TJwn9gwEY1TkBPXoNevNaKGPV8bA30bU75LpBOWTA@mail.gmail.com>
 <54897C27.7040101@treenet.co.nz> <54899072.8040304@ngtech.co.il>
 <CAEuU1afizDUUTty+=P1r_-udajdSQ2xQMKsT6OeZs8xiZZSH5g@mail.gmail.com>
 <548AC011.2060203@treenet.co.nz>
Message-ID: <CAEuU1ac1NGC=0N3n6GEVAmekhLREpZQ78ypcwr1wQxd-_fc-xw@mail.gmail.com>

Thanks a lot, Eliezer and Amos.

Your Views are going to help me lot :)


On Fri, Dec 12, 2014 at 3:44 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 12/12/2014 4:41 a.m., Siva Prakash wrote:
> > Thanks for your valuable input, Eliezer and Amos.
> >
> > I have added the rough hardware and squid configuration, please
> > guide me out with how much request squid can handle per second,
> >
> > CPU Speed - each 3.30GHz( totally 5 processors)
> >
> > RAM - 4 GB
> >
> > NIC - one 10 GB Ethernet Adapter
> >
> > Squid Version - 3.4
> >
> > Squid configuration - For authentication, it is integrated with AD
> > and lots of ACLs(1000) to block sites.
> >
>
> On a 3.3GHz CPU core I would expect an upper limit of around 3000 RPS.
>
> The bottlneck will be the AD processing delays. Most of HTTP
> performance features and mechanisms have to be disabled in order to
> get NTLM or Kerberos authentication to work. That reduces Squid
> performance by roughly a factor of 3-4. You would be lucky to get 1000
> RPS per core out of the auth systems, though not all requests need the
> full auth latency so call it 1500 RPS max.
>
> With 4 CPU for Squid and one for OS, thats 6-12K RPS for the machine.
> If we assume your traffic has average object size ~40KB that measures
> up at around 250 Mbps combined for 4 Squid worker processes.
>
>
> These are very, very rough guesstimate *upper* limit numbers. The only
> way to be at all sure is to actually run the traffic through the proxy
> and find out. Squid has a lot of tuning knobs that can affect the
> performance.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUir/jAAoJELJo5wb/XPRjzacIAOK9Dft9QpDtact+iKNWAVv1
> KqfmZz1wHNyRc8+1do9WnKuyUvoS5WosDSE4NjCk3woc2sLVky5b0ifPsp0Z+qVx
> MjDGx8ka74Yl5KUAimxFhn/ZdkNLDx1CHhFkH8am8mARwFR7yA++t16biB3QvDWT
> zMB02DAqmJX0xRvyuqJNFUfqjaufQO3ftzFeJXTI1krCtYJxBU/Y5tQMhH/7cHhe
> bOfTOTPUvWRnSNmbtZKrQJae+R87a66qyAj7Rr4S+YbkyvW3d0ORW0AfDV+JWF92
> hZtsWu+mVzf6n3uObg6ah+610O0T30b1FdKwfjA5ssvQDxNcShChM1MfW5ctP20=
> =q4IZ
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141212/978363e4/attachment.htm>

From alexander.bubnov at bk.ru  Fri Dec 12 20:09:59 2014
From: alexander.bubnov at bk.ru (=?koi8-r?B?4czFy9PBzsTSIOLVws7P1w==?=)
Date: Fri, 12 Dec 2014 23:09:59 +0300
Subject: [squid-users] ICAP: how to get port of X-Client-IP
In-Reply-To: <CAJ3HoZ3QcTScVSFUJCkdBOWg8vSncqCZzT6dUiB_1qiwNyO2Vg@mail.gmail.com>
References: <1418389855.19761439@f356.i.mail.ru>
 <CAJ3HoZ3QcTScVSFUJCkdBOWg8vSncqCZzT6dUiB_1qiwNyO2Vg@mail.gmail.com>
Message-ID: <4149321418414999@web26g.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141212/b4721754/attachment.htm>

From vdoctor at neuf.fr  Fri Dec 12 20:23:57 2014
From: vdoctor at neuf.fr (Stakres)
Date: Fri, 12 Dec 2014 12:23:57 -0800 (PST)
Subject: [squid-users] Squid 2.7,
 3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster
In-Reply-To: <004501d01673$0f445150$2dccf3f0$@netstream.ps>
References: <1418374260739-4668683.post@n4.nabble.com>
 <004501d01673$0f445150$2dccf3f0$@netstream.ps>
Message-ID: <1418415837677-4668693.post@n4.nabble.com>

Hi Ahmed,

I could not answer concerning the SMP 32KB caching limitation, Amos and/or
Eliezer should be the right persons here to answer you.

Regarding the SquidVideoBooster, this is a plugin to Squid. If you Squid
supports the SMP so the SquidVideoBooster will work.

Reminder, the SquidVideoBooster is a plugin to de-duplicate similar URLs
(video, CDNs etc...) with Squid. The SquidVideoBooster will not fix
misconfigurations or issues with Squid...

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraries-CDNs-Booster-tp4668683p4668693.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From alehman at gbateam.com  Fri Dec 12 21:57:57 2014
From: alehman at gbateam.com (Alan Lehman)
Date: Fri, 12 Dec 2014 21:57:57 +0000
Subject: [squid-users] error compiling 3.4.10
Message-ID: <B967FC4A73984244A48E8572B691B31E0C6B5983@EXCH.win.gbutler.com>

Trying to compile on RHEL7, I get the following. I?m sure I have a path error.

libtool: link: g++ -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -g -O2 -march=native -std=c++11 -g -o basic_ncsa_auth basic_ncsa_auth.o crypt_md5.o  ../../../lib/.libs/libmisccontainers.a ../../../lib/.libs/libmiscencoding.a ../../../compat/.libs/libcompat-squid.a -lcrypt -L/usr/lib64/openssl/lib -lssl -lcrypto -lm -lnsl -lresolv -lrt -ldl
/usr/bin/ld: cannot find -lssl
/usr/bin/ld: cannot find -lcrypto
collect2: error: ld returned 1 exit status
make[3]: *** [basic_ncsa_auth] Error 1
make[3]: Leaving directory `/home/alehman/squid-3.4.10/helpers/basic_auth/NCSA'
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory `/home/alehman/squid-3.4.10/helpers/basic_auth'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/home/alehman/squid-3.4.10/helpers'
make: *** [all-recursive] Error 1

config options: --enable-ssl --enable-useragent-log --enable-referer-log --with-filedescriptors=8192 --disable-loadable-modules --prefix=/usr --includedir=/usr/include --datadir=/usr/share --bindir=/usr/sbin --libexecdir=/usr/lib/squid --localstatedir=/var --sysconfdir=/etc/squid --with-openssl=/usr/lib64/openssl



CONFIDENTIALITY NOTICE: This e-mail message including attachments, if any, is intended for the person or entity to which it is addressed and may contain confidential and/or privileged material. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message. Thank you.


From eliezer at ngtech.co.il  Fri Dec 12 23:58:08 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 13 Dec 2014 01:58:08 +0200
Subject: [squid-users] error compiling 3.4.10
In-Reply-To: <B967FC4A73984244A48E8572B691B31E0C6B5983@EXCH.win.gbutler.com>
References: <B967FC4A73984244A48E8572B691B31E0C6B5983@EXCH.win.gbutler.com>
Message-ID: <548B8110.9090405@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Alan,

The main issue is the unknown environment.
Can you run this script:
http://www1.ngtech.co.il/squid/basic_data.sh

The script will give us the basic details about the build system.
When you use the script make sure there are no confidential details.

I did not tested yet this build on CentOS 7 but it builds on 6.6 and
couple others so it should be something solvable.

Eliezer

On 12/12/2014 11:57 PM, Alan Lehman wrote:
> config options: --enable-ssl --enable-useragent-log
> --enable-referer-log --with-filedescriptors=8192
> --disable-loadable-modules --prefix=/usr --includedir=/usr/include
> --datadir=/usr/share --bindir=/usr/sbin --libexecdir=/usr/lib/squid
> --localstatedir=/var --sysconfdir=/etc/squid
> --with-openssl=/usr/lib64/openssl

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUi4EQAAoJENxnfXtQ8ZQUpnwIAJ1ZSDa7OKpl51C6ZTObBTy+
StROk+SlEPX7g6Vg+zL+TL9emoEIbHYXNZ0Pi8jRsiVi2W0VZaMowD8inglZwLqP
WIz6ChROO9jIMy7N2TK8VuoCJC4DwrishAD/K0UH0S1jqArTE6ngzCrCGwWg8bNI
9HxflR6Tc+eOXYhe5bvcEBufKtFv9249dsktr6IJvgT+IZ+RAhVc0SXeZMbIPX18
HYVEtBYZsyzXbiLJAmFcw9tbLteZrKlZe1GhkCmt6wa8/Sm9I+OvlCvjuO/zhfta
qxhVzKjOlOeydH8TMxCZ+P3se3zEbGu11FjzPSP2cmw0kcWS+IHz3YpRETeQjjQ=
=n9Jj
-----END PGP SIGNATURE-----


From hoangnatc at gmail.com  Sat Dec 13 09:16:55 2014
From: hoangnatc at gmail.com (Hoang Nguyen)
Date: Sat, 13 Dec 2014 16:16:55 +0700
Subject: [squid-users]  Help for Squid running
Message-ID: <CA+tDn=CPntQg78785xutQT7nym6-mZKzYLLkr-97kAAz+RgFhg@mail.gmail.com>

Dear Amos,

Could you help me one more time with this error, I installed Squid 3.4.9
already

But when I run it, it appears with this error

2014/12/13 16:12:32| assertion failed: mem.cc:282: "size ==
StrPoolsAttrs[i].obj_size"

ubuntu at ubuntu:/$ squid
Aborted (core dumped)

I attached the log file for your checking

Thank you so much
Hoang
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141213/490eed9e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cache.log
Type: application/octet-stream
Size: 8880 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141213/490eed9e/attachment.obj>

From alex.hha at gmail.com  Sat Dec 13 11:51:37 2014
From: alex.hha at gmail.com (Alex Domoradov)
Date: Sat, 13 Dec 2014 13:51:37 +0200
Subject: [squid-users] error compiling 3.4.10
In-Reply-To: <548B8110.9090405@ngtech.co.il>
References: <B967FC4A73984244A48E8572B691B31E0C6B5983@EXCH.win.gbutler.com>
 <548B8110.9090405@ngtech.co.il>
Message-ID: <CAK90gp6Hmqs9NLJJgsa6e1vZ8WOMpdYbHj7X0iVLGP4VxMk1_A@mail.gmail.com>

According to the following lines

> /usr/bin/ld: cannot find -lssl
> /usr/bin/ld: cannot find -lcrypto

it seems that you forgot to install devel package - openssl-devel

On Sat, Dec 13, 2014 at 1:58 AM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Hey Alan,
>
> The main issue is the unknown environment.
> Can you run this script:
> http://www1.ngtech.co.il/squid/basic_data.sh
>
> The script will give us the basic details about the build system.
> When you use the script make sure there are no confidential details.
>
> I did not tested yet this build on CentOS 7 but it builds on 6.6 and
> couple others so it should be something solvable.
>
> Eliezer
>
> On 12/12/2014 11:57 PM, Alan Lehman wrote:
> > config options: --enable-ssl --enable-useragent-log
> > --enable-referer-log --with-filedescriptors=8192
> > --disable-loadable-modules --prefix=/usr --includedir=/usr/include
> > --datadir=/usr/share --bindir=/usr/sbin --libexecdir=/usr/lib/squid
> > --localstatedir=/var --sysconfdir=/etc/squid
> > --with-openssl=/usr/lib64/openssl
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQEcBAEBAgAGBQJUi4EQAAoJENxnfXtQ8ZQUpnwIAJ1ZSDa7OKpl51C6ZTObBTy+
> StROk+SlEPX7g6Vg+zL+TL9emoEIbHYXNZ0Pi8jRsiVi2W0VZaMowD8inglZwLqP
> WIz6ChROO9jIMy7N2TK8VuoCJC4DwrishAD/K0UH0S1jqArTE6ngzCrCGwWg8bNI
> 9HxflR6Tc+eOXYhe5bvcEBufKtFv9249dsktr6IJvgT+IZ+RAhVc0SXeZMbIPX18
> HYVEtBYZsyzXbiLJAmFcw9tbLteZrKlZe1GhkCmt6wa8/Sm9I+OvlCvjuO/zhfta
> qxhVzKjOlOeydH8TMxCZ+P3se3zEbGu11FjzPSP2cmw0kcWS+IHz3YpRETeQjjQ=
> =n9Jj
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141213/c4bd381a/attachment.htm>

From eliezer at ngtech.co.il  Sat Dec 13 16:31:01 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 13 Dec 2014 18:31:01 +0200
Subject: [squid-users] error compiling 3.4.10
In-Reply-To: <CAK90gp6Hmqs9NLJJgsa6e1vZ8WOMpdYbHj7X0iVLGP4VxMk1_A@mail.gmail.com>
References: <B967FC4A73984244A48E8572B691B31E0C6B5983@EXCH.win.gbutler.com>	<548B8110.9090405@ngtech.co.il>
 <CAK90gp6Hmqs9NLJJgsa6e1vZ8WOMpdYbHj7X0iVLGP4VxMk1_A@mail.gmail.com>
Message-ID: <548C69C5.9060108@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/13/2014 01:51 PM, Alex Domoradov wrote:
> According to the following lines
> 
>>> /usr/bin/ld: cannot find -lssl /usr/bin/ld: cannot find
>>> -lcrypto
> it seems that you forgot to install devel package - openssl-devel
Thanks Alex,

I also verified that my last CentOS 7 build node finished building and
the test node confirms that it runs fine after a nice build.
For comparison attached the output of the basic_data.sh script link:
http://www1.ngtech.co.il/squid/centos7_build_node.txt

Eliezer
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUjGnFAAoJENxnfXtQ8ZQUlggH/i2MRUrCbDf4Xj8RZtKDcp1K
7cUKsUjhxBRZ7p8HzkNJeaxTVa7advVm3DZpVhkygs0exlR1Tf/uNXiIAK/fR343
VtMGOxJWLBrGHCD7TT2MeCZcwFpxBYAmcTe/C0gbExD4yila6e518HyfeKdycbz3
EkkwcGJBKBaZU5sPhSrEQSfc4NJs7U8X7y7o5ovL0B0RfGLF5CxjQnbjF7J+6PfL
g7+B8GaZfT8t23lEi7z6f9VFK0aI1IVuv05jwfX6OGcyFiEeyBRLYlDXlo+E5Fi4
PFPJVewXHIXVPIotMNDB0L82DeW6vQHFbspnmc7IYgOV6bUS2js170rpso2HcMM=
=gkNY
-----END PGP SIGNATURE-----


From danielkovacecic at yahoo.com  Sun Dec 14 04:49:09 2014
From: danielkovacecic at yahoo.com (dkovacevic)
Date: Sat, 13 Dec 2014 20:49:09 -0800 (PST)
Subject: [squid-users] After a Successful PURGE, Still Get TCP-DENIED
Message-ID: <1418532549129-4668699.post@n4.nabble.com>

I have an external_acl_type directive which returns "OK" or "ERR" depending
on a database query.

The problem is this: when the database is updated, which should permit the
site to be accessed, Squid has the previous response cached, the result
being continued "access denied" responses until either Squid is restarted or
the result expires (where?).

I attempted to clear the cache by using PURGE request via squidclient, which
is successful in clearing the cache, but not the result decision
(TCP-DENIED). After running the PURGE, doing a refresh in browser causes
another lookup in Squid- but Squid then returns "access-denied" (no database
query).

What do I need to do to force Squid to check the ACL after a browser
refresh?





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/After-a-Successful-PURGE-Still-Get-TCP-DENIED-tp4668699.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun Dec 14 05:29:48 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 14 Dec 2014 18:29:48 +1300
Subject: [squid-users] After a Successful PURGE, Still Get TCP-DENIED
In-Reply-To: <1418532549129-4668699.post@n4.nabble.com>
References: <1418532549129-4668699.post@n4.nabble.com>
Message-ID: <548D204C.1020002@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14/12/2014 5:49 p.m., dkovacevic wrote:
> I have an external_acl_type directive which returns "OK" or "ERR"
> depending on a database query.

Ok.

> 
> The problem is this: when the database is updated, which should
> permit the site to be accessed,

Ok.

> Squid has the previous response cached,

Irrelevant. ACL managing *access* to an object does not matter where
it comes from, the only thing that matters is whether access is
allowed/denied.

> the result being continued "access denied" responses until either
> Squid is restarted or the result expires (where?).

generated != cached.

"Access denied" object is being generated by Squid. Results
*generated* by Squid are not cached by Squid.

> 
> I attempted to clear the cache by using PURGE request via
> squidclient, which is successful in clearing the cache, but not the
> result decision (TCP-DENIED). After running the PURGE, doing a
> refresh in browser causes another lookup in Squid- but Squid then
> returns "access-denied" (no database query).
> 
> What do I need to do to force Squid to check the ACL after a
> browser refresh?

You seem to be mistaking what is cached.

1) The DB has an internal cache of query/response, the DB lookup
result from the helepr may becoming from there. SQL/relational
databases ACID compliance prevents this cache interferring if the DB
has been updated, but if you are using a NoSQL database or distributed
cluster DB it can affect things quite badly.

2) Some helpers have internal caches to quickly respond to queries.
external ACL helpers not so much becasue of #3, but this is a possibility.

3) Squid has a cache for each helpers responses. Such that if you send
the same query twice the repeats get serviced quickly from the helper
cache. This is controlled by the various ttl=, negative_ttl= and
cache= options of external_acl_type directive.
  http://www.squid-cache.org/Doc/config/external_acl_type/

4) Squid has an HTTP object cache for *external* server produced
objects in the HTTP traffic.
 - PURGE is an HTTP method, it only affects this cache.


I think #3 is what you are having trouble with. The default is 60
minutes caching for helper responses. So there will be a 1 hour delay
between updating the DB and any change visible in Squid HTTP responses.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUjSBKAAoJELJo5wb/XPRj6UAH/2x7iTYM6gx1+kQ0YJmh1vsF
ckebcQVXHpb8ww2G+LmH0D7LVCz4OlsdxXEYM5lVHxoIa6BNBnlvXONGk3Y/8l78
yLBEHdj1lktAigpleU2TI+4tVVKFdRWBEqQF0ICzxFVsmH4GKWgT+I0EJ6b/bsAO
VExbR0bKd1mqXWG08yEpcXlrLug8eVMTo8qsn8eyCVsRpjKhW1fp2g2i+TncwLqy
eg2HqTEQBnCkkjIA2dwzQkSFhRKiEpa1xcwF6+6pDSY82nU/MvCPG+MYLRBaH8FL
BopNwjKQyMiLK5QxOFK5z2FCKIUseFGtvjioctBATESFdX1LYqZWG408mJg248U=
=Me+/
-----END PGP SIGNATURE-----


From danielkovacecic at yahoo.com  Sun Dec 14 08:05:01 2014
From: danielkovacecic at yahoo.com (dkovacevic)
Date: Sun, 14 Dec 2014 00:05:01 -0800 (PST)
Subject: [squid-users] After a Successful PURGE, Still Get TCP-DENIED
In-Reply-To: <548D204C.1020002@treenet.co.nz>
References: <1418532549129-4668699.post@n4.nabble.com>
 <548D204C.1020002@treenet.co.nz>
Message-ID: <1418544301204-4668701.post@n4.nabble.com>

Thank you Amos, setting the TTL worked.

I had no idea that the helpers had a separate cache, and that was creating a
lot of frustration for me.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/After-a-Successful-PURGE-Still-Get-TCP-DENIED-tp4668699p4668701.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From pavel.kazlenka at measurement-factory.com  Sun Dec 14 09:15:42 2014
From: pavel.kazlenka at measurement-factory.com (Pavel Kazlenka)
Date: Sun, 14 Dec 2014 12:15:42 +0300
Subject: [squid-users] Help for Squid running
In-Reply-To: <CA+tDn=CPntQg78785xutQT7nym6-mZKzYLLkr-97kAAz+RgFhg@mail.gmail.com>
References: <CA+tDn=CPntQg78785xutQT7nym6-mZKzYLLkr-97kAAz+RgFhg@mail.gmail.com>
Message-ID: <548D553E.5060905@measurement-factory.com>

Hi Hoang,

This could be a known bug: 
http://bugs.squid-cache.org/show_bug.cgi?id=4057, the fix is attached, 
but still not in main tree. You probably should rebuild squid within the 
fix attached to bugzilla issue for now.

On 12/13/2014 12:16 PM, Hoang Nguyen wrote:
> Dear Amos,
>
> Could you help me one more time with this error, I installed Squid 
> 3.4.9 already
>
> But when I run it, it appears with this error
>
> 2014/12/13 16:12:32| assertion failed: mem.cc:282: "size == 
> StrPoolsAttrs[i].obj_size"
>
> ubuntu at ubuntu:/$ squid
> Aborted (core dumped)
>
> I attached the log file for your checking
>
> Thank you so much
> Hoang
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141214/7dba411d/attachment.htm>

From dannydebont at gmail.com  Sun Dec 14 18:34:04 2014
From: dannydebont at gmail.com (Danny)
Date: Sun, 14 Dec 2014 20:34:04 +0200
Subject: [squid-users] reply_body_max size
Message-ID: <20141214183404.GA11344@fever.havannah.local>

Hi,

If I want to restrict user's download size:

reply_body_max_size 10 MB localnet_finance localnet_engineering
reply_body_max_size 15 MB localnet_manufacturing localnet_stores

Will the above 2 lines do what it is supposed to and allow unrestricted
downloads for all other local networks?

Thank you

Danny


From alex at samad.com.au  Mon Dec 15 03:53:36 2014
From: alex at samad.com.au (Alexander Samad)
Date: Mon, 15 Dec 2014 14:53:36 +1100
Subject: [squid-users] Disable SSLv3 on Squid doesn't seem to work
In-Reply-To: <546F632A.7030601@far-galaxy.de>
References: <546F52D7.9030804@far-galaxy.de> <546F5A56.8010001@treenet.co.nz>
 <546F632A.7030601@far-galaxy.de>
Message-ID: <CAJ+Q1PVmsVG-LF-JvoHk57rtzv4XKGAmQNTFWeq0ySXNAVp3xQ@mail.gmail.com>

does that need to be https_port ?

this is what  I have used

https_port 2.7.3.1:443 accel cert=/etc/httpd/conf.d/a,b,c.crt
key=/etc/httpd/conf.d/a.b.c.key defaultsite=a.b.c
options=NO_SSLv2,NO_SSLv3

The only thing I haven't got working is PFS.

I test with https://www.ssllabs.com/

Alex

On 22 November 2014 at 03:07, Sebastian Fohler <info at far-galaxy.de> wrote:
> Thank you Amos,
>
> I've implemented http_port 80 ssl-bump options=NO_SSLv3:NO_SSLv2
> Yet still the proxy accepts SSLv3 connections in the sniffing protocol.
>
> Something is still wrong.
>
> Best regards
> Sebastian
>
>
> On 21.11.2014 16:29, Amos Jeffries wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 22/11/2014 3:57 a.m., Sebastian Fohler wrote:
>>>
>>> I've disabled SSLv3 with this option set in my squid.conf file:
>>>
>>> sslproxy_options NO_SSLv3 NO_SSLv2
>>>
>>> But despite that fact, the squid proxy accepted the configuration
>>> without any problems, I still get SSLv3 connections working. I've
>>> sniffed the traffice on that interface on the proxy port and if I
>>> do a SSLv3 connection from the browser and do a poodle check, the
>>> sniffing protocol shows an established SSLv3 connection.
>>
>>
>> The connection between browser and Squid is controlled by the *_port
>> settings.
>>
>> sslproxy_* directives are purely for DIRECT or ORIGINAL_DST server
>> connections.
>>
>>>
>>> Can someone tell me if I missed something here?
>>
>>
>> The sslproxy_options setting is an OpenSSL format string. Which is a
>> list of comma (',') or colon (':') separated OpenSSL option names.
>>
>>
>> What you need to configure is something like these:
>>
>>   # to prevent SSL on inbound traffic
>>   https_port ...  options=NO_SSLv3:NO_SSLv2
>>   http_port ... ssl-bump options=NO_SSLv3:NO_SSLv2
>>
>>   # to prevent SSL on direct server traffic
>>   sslproxy_options NO_SSLv3:NO_SSLv2
>>
>>   # to prevent SSL on relayed peer connections
>>   cache_peer ... ssloptions=NO_SSLv3:NO_SSLv2
>>
>>
>>> Is there some option which could override the sslproxy_options
>>> setting?
>>
>>
>> If anything the OpenSSL library configuration may have such options.
>> But AFAIK that is for configuring the defaults and squid.conf settings
>> are overriding them.
>>
>>
>>> How can I check if the sslproxy_options are really being used?
>>
>>
>> Good question. I'm not aware of anything in particular. If there is an
>> SSL/TLS testing website connecting to it through Squid should tell you.
>>
>> Amos
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2.0.22 (MingW32)
>>
>> iQEcBAEBAgAGBQJUb1pVAAoJELJo5wb/XPRjTPAIAJiboRyQ7kwCTW9bByF8yT99
>> oD/u8W23DQ5p6sl1bfvKGeZBwUIkn5qX6pzF8RDZIWFrz/Fu1N0b7KMpdqQYqsFC
>> W/dfyXywucWSmnTj32e47Wa9q1Y4u/r1oa6tDUBCsUM9Dh4iVS2UI6akyy1HkuEk
>> Zpxl7iF9UcPyRBZ7cvTl7iZSFHRgPEokdaXNo+qKLDQUpNg5XlK82wf4JY+EUyt1
>> AvBz32cCIVz9ErQ5RckCTCV3XTLOUFoAXrbOiApGe07Gum746yAnRzuB07LYCwwY
>> 16XL5N+mjw5Gj+70pMGVfaieoQHK7W9L7qJPDLy+JqL7Z2r81GjD4tb6O0txAgo=
>> =NbHW
>> -----END PGP SIGNATURE-----
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Mon Dec 15 04:15:02 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 15 Dec 2014 17:15:02 +1300
Subject: [squid-users] Disable SSLv3 on Squid doesn't seem to work
In-Reply-To: <CAJ+Q1PVmsVG-LF-JvoHk57rtzv4XKGAmQNTFWeq0ySXNAVp3xQ@mail.gmail.com>
References: <546F52D7.9030804@far-galaxy.de> <546F5A56.8010001@treenet.co.nz>
 <546F632A.7030601@far-galaxy.de>
 <CAJ+Q1PVmsVG-LF-JvoHk57rtzv4XKGAmQNTFWeq0ySXNAVp3xQ@mail.gmail.com>
Message-ID: <548E6046.4030400@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15/12/2014 4:53 p.m., Alexander Samad wrote:
> does that need to be https_port ?

Not particularly when using SSL interception ("SSL-bump").

> 
> this is what  I have used
> 
> https_port 2.7.3.1:443 accel cert=/etc/httpd/conf.d/a,b,c.crt 
> key=/etc/httpd/conf.d/a.b.c.key defaultsite=a.b.c 
> options=NO_SSLv2,NO_SSLv3
> 
> The only thing I haven't got working is PFS.
> 
> I test with https://www.ssllabs.com/
> 
> Alex
> 
> On 22 November 2014 at 03:07, Sebastian Fohler wrote:
>> Thank you Amos,
>> 
>> I've implemented http_port 80 ssl-bump options=NO_SSLv3:NO_SSLv2 
>> Yet still the proxy accepts SSLv3 connections in the sniffing
>> protocol.
>> 
>> Something is still wrong.


Is that actually SSLv3 protocol values going across or just TLS 1.x
using "ssl3" format for the handshakes?

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUjmBGAAoJELJo5wb/XPRjoqEIAJUiy/c2NKpMFc11ErupOzU5
1B0zkL8KPxe5AADO8A+6FKTgNkxQXOnjl6DyTs922CgWkd2JJg8nd55aMJeo4Lqc
OH9/HZ9xHni/beA9sAcb8CEBD5i96JLOuZFO/clFF517W4O+5aqjFzNPmJ1Ca3Ny
Z59C3SIzHQnP5ueNVjSRmZ41Ut4SARf4qs/aBhco+bAT9hV4hrTXeSdPdAMjK34V
Z2I4xx3XCf/zSogyQYEkmTR1MuAXPkR6BaAUCaAIqPBfzgtRu/3vAoLQCTshJJaC
+DzqAZ4voLmS2v9N63ysCb4hm65p4M6iRpWyjGzBiGVoU7QFHplnr79WgxfGJ3k=
=lV8u
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Mon Dec 15 04:32:34 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 15 Dec 2014 17:32:34 +1300
Subject: [squid-users] ICAP: how to get port of X-Client-IP
In-Reply-To: <4149321418414999@web26g.yandex.ru>
References: <1418389855.19761439@f356.i.mail.ru>
 <CAJ3HoZ3QcTScVSFUJCkdBOWg8vSncqCZzT6dUiB_1qiwNyO2Vg@mail.gmail.com>
 <4149321418414999@web26g.yandex.ru>
Message-ID: <548E6462.1020909@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 13/12/2014 9:09 a.m., ????????? ?????? wrote:
> I do not need to map it back remotely. I just need to know it. One
> of my applications collects logs about all connections on a desktop
> PC and another (ICAP server) collects what that applications sends
> to the Internet. And to know that traffic belongs to certain
> application I need to know port of the application on a desktop
> PC.

You could try using the adaptation_meta directive to add a custom
header with %>p as the value parameter. I'm not sure if that will send
a port number though.
  http://www.squid-cache.org/Doc/config/adaptation_meta/

There is near zero reliability that the port number outgoing from the
client is the same number incoming to Squid. There are numerous
potential layers of protocol and machinery re-numbering ports
transparently between any two devices.


The name of the client application is supposed to be sent in the
User-Agent: HTTP header which gets delivered to ICAP already. For most
legitimate uses of agent-sniffing UA header + IP is sufficient
information.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUjmRiAAoJELJo5wb/XPRj9skH/i6rlp7XmNptgfn/VgKtgH+v
D22idQBsXyTC00LN2UQssz6Hrpk7nvK96dKObtSppJQ8Xtu1NrrPG1uSq1plRgBT
d5EXRYnAMttTbI5KVDdXW6IsFSjTkL2Hr1m244BEv7SRUBNaa67XPpDjucoIX2kP
8eIKZrB32jaW3/t2VDIl67iRKOZQh3DZfFqFrU6BgZCrLXjZXU/629+KBVnvNg/A
TEnYXDBOSRwRVsWuLK/o0bZFI7y6wp0jtRT1ETliUpmdbGKKPSnMWLym2FX5VI+d
8B1BSzbjEAP+sWex2oKE5Z7+FQ+eSf2tYLvS15fqAHe09hKqpJTMur4cumdkRM0=
=LgMG
-----END PGP SIGNATURE-----


From vdoctor at neuf.fr  Mon Dec 15 07:26:56 2014
From: vdoctor at neuf.fr (Stakres)
Date: Sun, 14 Dec 2014 23:26:56 -0800 (PST)
Subject: [squid-users] Squid 2.7,
 3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster
In-Reply-To: <1418415837677-4668693.post@n4.nabble.com>
References: <1418374260739-4668683.post@n4.nabble.com>
 <004501d01673$0f445150$2dccf3f0$@netstream.ps>
 <1418415837677-4668693.post@n4.nabble.com>
Message-ID: <1418628416193-4668707.post@n4.nabble.com>

Hi All,

New  build 2.16 <https://sourceforge.net/projects/squidvideosbooster/>  
taking care new websites in de-duplication...

Enjoy 

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraries-CDNs-Booster-tp4668683p4668707.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Mon Dec 15 09:58:10 2014
From: fredbmail at free.fr (FredB)
Date: Mon, 15 Dec 2014 10:58:10 +0100 (CET)
Subject: [squid-users] CVS mailing list
In-Reply-To: <752576164.223752294.1418637395885.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <154989364.223755084.1418637490682.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello,

FI, the mailing list CVS seems broken 

http://lists.squid-cache.org/pipermail/squid-cvs/

Fred


From ahmed.zaeem at netstream.ps  Mon Dec 15 23:03:46 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Mon, 15 Dec 2014 15:03:46 -0800
Subject: [squid-users] squid_ldap_auth: WARNING,
	could not bind to binddn 'Invalid credentials'
Message-ID: <000001d018bb$63509200$29f1b600$@netstream.ps>

Hi guys 

Im trying to use squid with active directory  2008 R2 as an external
authentication

On DC called smart.ps

Create user squid and gave it delegation to the dc and put it also in the
group admins in the OU=proxy

 

Also create user with username a and pwd 111111

 

Now on my linux box it don't work with squid ,

So , I try to troubleshoot it and I do the following test :



echo "a 111111" | /usr/lib/squid/squid_ldap_auth -R -b  "dc=smart,dc=ps" -D
"cn=squid,ou=proxy,dc=smart,dc=ps" -w "rocket123" -f saMaccoutName=%s -h
192.168.1.110

 

squid_ldap_auth: WARNING, could not bind to binddn 'Invalid credentials'

ERR Success

 

 

Any help ?

 

Any recommendations about squid and winwod s2008 R2 ??

 

Here is  squid version BTW :

squid -v

Squid Cache: Version 3.1.10

configure options:  '--build=i386-redhat-linux-gnu'
'--host=i386-redhat-linux-gnu' '--target=i686-redhat-linux-gnu'
'--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin'
'--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share'
'--includedir=/usr/include' '--libdir=/usr/lib' '--libexecdir=/usr/libexec'
'--sharedstatedir=/var/lib' '--mandir=/usr/share/man'
'--infodir=/usr/share/info' '--enable-internal-dns'
'--disable-strict-error-checking' '--exec_prefix=/usr'
'--libexecdir=/usr/lib/squid' '--localstatedir=/var'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--with-logdir=$(localstatedir)/log/squid'
'--with-pidfile=$(localstatedir)/run/squid.pid'
'--disable-dependency-tracking' '--enable-arp-acl'
'--enable-follow-x-forwarded-for'
'--enable-auth=basic,digest,ntlm,negotiate'
'--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain
-NTLM,SASL,DB,POP3,squid_radius_auth'
'--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth'
'--enable-digest-auth-helpers=password,ldap,eDirectory'
'--enable-negotiate-auth-helpers=squid_kerb_auth'
'--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_
group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
'--enable-ident-lookups' '--with-large-files' '--enable-linux-netfilter'
'--enable-referer-log' '--enable-removal-policies=heap,lru' '--enable-snmp'
'--enable-ssl' '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log'
'--enable-wccpv2' '--enable-esi' '--with-aio' '--with-default-user=squid'
'--with-filedescriptors=16384' '--with-dl' '--with-openssl'
'--with-pthreads' 'build_alias=i386-redhat-linux-gnu'
'host_alias=i386-redhat-linux-gnu' 'target_alias=i686-redhat-linux-gnu'
'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
-fstack-protector --param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom
-fasynchronous-unwind-tables -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g -pipe
-Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom
-fasynchronous-unwind-tables -fpie'
--with-squid=/builddir/build/BUILD/squid-3.1.10

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141215/fd85c9c7/attachment.htm>

From margaretofscotland at younghouse.info  Mon Dec 15 13:26:37 2014
From: margaretofscotland at younghouse.info (squeeky)
Date: Mon, 15 Dec 2014 05:26:37 -0800 (PST)
Subject: [squid-users] Parent Proxy Cache Problem
In-Reply-To: <54887733.6020907@treenet.co.nz>
References: <CAA8G5W3pH=z_UXxocjuQ7A5rB=+OFgzvSXXPV5SQb2=sQcJchA@mail.gmail.com>
 <54887733.6020907@treenet.co.nz>
Message-ID: <1418649997855-4668710.post@n4.nabble.com>

> Please check your config for "proxy-only" option on the link to parent 
> proxy. That alone will prevent caching. 
>
> If that option is not there, please post your config.

Still having issues with with getting content that is served from parent to
cache locally.
Config below:

http_port 10.77.40.8:8080
icp_port 7
dns_v4_first off
pid_filename /var/run/squid.pid
cache_effective_user proxy
cache_effective_group proxy
error_default_language en
icon_directory /usr/pbi/squid-i386/etc/squid/icons
visible_hostname localhost
cache_mgr admin at localhost
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
sslcrtd_children 0
logfile_rotate 0
shutdown_lifetime 3 seconds
# Allow local network(s) on interface(s)
acl localnet src  10.77.40.0/21
forwarded_for off
via off
httpd_suppress_version_string on
uri_whitespace strip

# Break HTTP standard for flash videos. Keep them in cache even if asked not
to.
refresh_pattern -i \.flv$ 10080 90% 999999 ignore-no-cache override-expire
ignor
e-private

# Let the clients favorite video site through with full caching
acl youtube dstdomain .youtube.com
cache allow youtube

# Windows Update refresh_pattern
range_offset_limit -1
refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f]|asf|wm[v|a]|dat|zip)
432
0 80% 43200 reload-into-ims
refresh_pattern -i
windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|asf|wm[v|a]|dat|zip)
 4320 80% 43200 reload-into-ims
refresh_pattern -i
my.windowsupdate.website.com/.*\.(cab|exe|ms[i|u|f]|asf|wm[v|
a]|dat|zip) 4320 80% 43200 reload-into-ims
cache_mem 100 MB
maximum_object_size_in_memory 32 KB
memory_replacement_policy heap LFUDA

cache_replacement_policy heap LFUDA
cache_dir ufs /var/squid/cache 6000 32 256
minimum_object_size 0 KB
maximum_object_size 5000000 KB
offline_mode oncache_swap_low 90
cache_swap_high 95

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:    1440  20%  10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0  0%  0
refresh_pattern .    0  20%  4320
# No redirector configured

#Remote proxies

# Setup some default acls
acl allsrc src all
acl localhost src 127.0.0.1/32
acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901  3128
1025-65535

acl sslports port 443 563
acl manager proto cache_object
acl purge method PURGE
acl connect method CONNECT

# Define protocols used for redirects
acl HTTP proto HTTP
acl HTTPS proto HTTPS

acl allowed_subnets src IP.REMOVED.FOR.SECURITY
acl blacklist dstdom_regex -i "/var/squid/acl/blacklist.acl"
http_access allow manager localhost

http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !safeports
http_access deny CONNECT !sslports

# Always allow localhost connections
http_access allow localhost

request_body_max_size 0 KB
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
delay_access 1 allow allsrc

# Reverse Proxy settings

# Custom options
refresh_pattern -i .ipa$ 4320 100% 259200 override-expire reload-into-ims
ignore
-reload
refresh_pattern -i .pkg$ 4320 100% 259200 override-expire reload-into-ims
ignore
-reload
refresh_pattern -i .ipsw$ 4320 100% 259200 override-expire reload-into-ims
ignor
e-reload

cache_peer IP.REMOVED.FOR.SECURITY parent 8080 0 default
never_direct allow all

# Block access to blacklist domains
http_access deny blacklist
# Setup allowed acls
# Allow local network(s) on interface(s)
http_access allow allowed_subnets
http_access allow localnet
# Default block all to be sure
http_access deny allsrc











--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Parent-Proxy-Cache-Problem-tp4668661p4668710.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon Dec 15 19:05:14 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 Dec 2014 08:05:14 +1300
Subject: [squid-users] squid_ldap_auth: WARNING,
 could not bind to binddn 'Invalid credentials'
In-Reply-To: <000001d018bb$63509200$29f1b600$@netstream.ps>
References: <000001d018bb$63509200$29f1b600$@netstream.ps>
Message-ID: <548F30EA.1070405@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 16/12/2014 12:03 p.m., Ahmed Allzaeem wrote:
> Hi guys
> 
> Im trying to use squid with active directory  2008 R2 as an
> external authentication
> 
> On DC called smart.ps
> 
> Create user squid and gave it delegation to the dc and put it also
> in the group admins in the OU=proxy
> 
> 
> 
> Also create user with username a and pwd 111111
> 
> 
> 
> Now on my linux box it don't work with squid ,
> 
> So , I try to troubleshoot it and I do the following test :
> 
> 
> 
> echo "a 111111" | /usr/lib/squid/squid_ldap_auth -R -b
> "dc=smart,dc=ps" -D "cn=squid,ou=proxy,dc=smart,dc=ps" -w .... -f
> saMaccoutName=%s -h 192.168.1.110
> 
> 
> 
> squid_ldap_auth: WARNING, could not bind to binddn 'Invalid
> credentials'
> 
> ERR Success
> 
> 
> 
> 
> 
> Any help ?
> 

I think that used to mean the command line parameters -D... and -w...
you have given the helper are not able to be used to login to the
- -h... AD server.

Please note that by using -w (lower case w) parameter you have now
just published your AD password in a public mailing list. It should be
changed immediately.


Although it could mean the client credentials being looked up were not
able to be found within AD when using the -b -f and -R parameters.

Is the "saMaccoutName=%s" parameter spelled correctly ?


> 
> Any recommendations about squid and winwod s2008 R2 ??
> 
> 
> 
> Here is  squid version BTW :
> 
> squid -v
> 
> Squid Cache: Version 3.1.10
> 

Please upgrade if you can. 3.1 is really old. I seem to recall some
changes to these LDAP helpers.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUjzDpAAoJELJo5wb/XPRj0iIIAKhDvp/6bVvr+2byFcQREd/D
jmcMU4r3lAOkWVoHIovgCPkBqupnbfQr03SoLGfnj08z18gtQDkiEkCniUoIN6Tz
2Nkb+itWKa5vlgmMcetC1SIlLj/8hOPULmCIj7/qF9ccGcoYQilm9EYcYpIztyNA
rbiJZLDpjXTneL0O1H2t6IbpYGaCIyvNDFFqvYSziqQd1mBhdJ3CfIafph1w08i9
TSoidRbB3rNttoffAbzXNPdsb7K6uToWjBe++whLJrZ/I2TGAMO9x43EEJ0JpMdV
F8XJEAAcfGe7OymRGzq4IeeAsEGPJNX1ELC89mJMA9GN2LJfNpwCguFiP4V3ZCk=
=BaEO
-----END PGP SIGNATURE-----


From sdreijer at microsoft.com  Mon Dec 15 19:11:08 2014
From: sdreijer at microsoft.com (Soren Madsen (DREIJER))
Date: Mon, 15 Dec 2014 19:11:08 +0000
Subject: [squid-users] Splicing a connection if server cert cannot be
	verified
Message-ID: <BY2PR03MB364691B2198BC6B96D0E597D56F0@BY2PR03MB364.namprd03.prod.outlook.com>

Hi all,

By default, I want to bump all connections through my Squid instance. However, while testing I've discovered lots of sites that use SSLv3 or self-signed certificates, in which case I'd like to fall back to TLS passthrough mode and let the client decide whether it wants to trust the server or not. In other words, if Squid cannot successfully bump a connection, I don't want to fail the connection, but rather step out of the way and let the client decide what to do.

The ideal solution, I think, would be to optimistically attempt to bump the connection, but if it fails due to e.g. a bad server cert, a new connection can be established with the original client hello.

I was hoping the new peek and splice functionality would be able to help me in this regard:
http://wiki.squid-cache.org/Features/SslPeekAndSplice

As far as I can tell, the 'stare' action is what I'm interested in here although it appears it's not a focus of the current implementation, and the 'peek' action has the following limitation note about 'Peeking at the server often precludes bumping':
"We could teach Squid to abandon the current server connection and then bump a newly open one. This is something we do not want to do as it is likely to create an even worse operational problems with Squids being auto-blocked for opening and closing connections in vein."

I'm confused about this. Couldn't Squid just cache the information about whether it has previously refrained from bumping a connection due to a bad server cert (or other errors) and only check with the server once the cache expires? That should avoid triggering any alarms on the server. 

Maybe I'm misreading the document. I was hoping somebody here on the list could explain to me if I can achieve the above behavior.

Thanks!

/ Soren


From leolistas at solutti.com.br  Mon Dec 15 19:13:13 2014
From: leolistas at solutti.com.br (Leonardo Rodrigues)
Date: Mon, 15 Dec 2014 17:13:13 -0200
Subject: [squid-users] squid_ldap_auth: WARNING,
 could not bind to binddn 'Invalid credentials'
In-Reply-To: <000001d018bb$63509200$29f1b600$@netstream.ps>
References: <000001d018bb$63509200$29f1b600$@netstream.ps>
Message-ID: <548F32C9.9060109@solutti.com.br>


     I have several squids authenticating users using ldap_auth and it 
works fine. Users are located on the 'Users' OU and my config lines are:


(single line)
auth_param basic program /usr/lib/squid/squid_ldap_auth -P -R -b 
"dc=myad,dc=domain" -D "cn=ProxyUser,cn=Users,dc=myad,dc=domain"
-w "xxxxxxxxx" -f sAMAccountName=%s -h ad.ip.addr.ess

(single line)
external_acl_type ldap_group children=3 ttl=300 %LOGIN 
/usr/lib/squid/squid_ldap_group -P -R -b "dc=myad,dc=domain" -D 
"cn=ProxyUser,
cn=Users,dc=myad,dc=domain" -w "xxxxxxxxxxx" -f 
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%a,cn=Users,
dc=myad,dc=domain))" -h ad.ip.addr.ess


On 15/12/14 21:03, Ahmed Allzaeem wrote:
>
> Hi guys
>
> Im trying to use squid with active directory  2008 R2 as an external 
> authentication
>
> On DC called smart.ps
>
> Create user squid and gave it delegation to the dc and put it also in 
> the group admins in the OU=proxy
>
>

-- 


	Atenciosamente / Sincerily,
	Leonardo Rodrigues
	Solutti Tecnologia
	http://www.solutti.com.br

	Minha armadilha de SPAM, N?O mandem email
	gertrudes at solutti.com.br
	My SPAMTRAP, do not email it


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141215/06e1054f/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 15 19:39:19 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 Dec 2014 08:39:19 +1300
Subject: [squid-users] Parent Proxy Cache Problem
In-Reply-To: <1418649997855-4668710.post@n4.nabble.com>
References: <CAA8G5W3pH=z_UXxocjuQ7A5rB=+OFgzvSXXPV5SQb2=sQcJchA@mail.gmail.com>
 <54887733.6020907@treenet.co.nz> <1418649997855-4668710.post@n4.nabble.com>
Message-ID: <548F38E7.3030600@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 16/12/2014 2:26 a.m., squeeky wrote:
>> Please check your config for "proxy-only" option on the link to
>> parent proxy. That alone will prevent caching.
>> 
>> If that option is not there, please post your config.
> 
> Still having issues with with getting content that is served from
> parent to cache locally.


You dont say what Squid version. Some of the things below were only
ever relevant in Squid-2 series releases. If you are using anything
older than Squid-3.4 please seriously consider an upgrade.


> Config below:
> 
> http_port 10.77.40.8:8080 icp_port 7

> dns_v4_first off

Above line is a default anyway, you can remove it completely.

> pid_filename /var/run/squid.pid cache_effective_user proxy 
> cache_effective_group proxy error_default_language en

The above 4 lines should all be default values for those directives too.

> icon_directory /usr/pbi/squid-i386/etc/squid/icons visible_hostname
> localhost

NP: how are your clients expected to fetch icons from
http://localhost/... URLs ?
 - *visible* hostname is supposed to be a DNs domain name which your
Squid can be contacted on.

> cache_mgr admin at localhost

Ditto for emailing you probems reoports to admin at localhost.

Note that Squid itself tries to email you crash reports at this
address too.


> access_log /var/squid/logs/access.log cache_log
> /var/squid/logs/cache.log cache_store_log none sslcrtd_children 0 
> logfile_rotate 0 shutdown_lifetime 3 seconds # Allow local
> network(s) on interface(s)


Em. Squid is layer 4-7 software. Has nothing to do with layer-3
interfaces.

"localnet" ACL is supposed to list the valid LAN network range(s)
where Squid can expect traffic to flow in from.

> acl localnet src  10.77.40.0/21 forwarded_for off via off 
> httpd_suppress_version_string on uri_whitespace strip
> 
> # Break HTTP standard for flash videos. Keep them in cache even if
> asked not to. refresh_pattern -i \.flv$ 10080 90% 999999
> ignore-no-cache override-expire ignor e-private
> 
> # Let the clients favorite video site through with full caching acl
> youtube dstdomain .youtube.com cache allow youtube

This might be your problem. Squid ACLs have an implicit default action
which is the opposite of the last explicit action. So what you have
configured above is equivalent to:

   cache allow youtube
   cache deny all

That "deny all" implicit action will block caching for a huge amount
of traffic.


Also, Squid caches everything is can by default. The purpose of the
cache directive is to allow you to *prevent* things caching.

I think you should remove the config lines:
"
 # Let the clients favorite video site through with full caching
 acl youtube dstdomain .youtube.com
 cache allow youtube"
"



> 
> # Windows Update refresh_pattern range_offset_limit -1 
> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|asf|wm[v|a]|dat|zip) 432 0 80%
> 43200 reload-into-ims refresh_pattern -i 
> windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|asf|wm[v|a]|dat|zip) 4320
> 80% 43200 reload-into-ims refresh_pattern -i 
> my.windowsupdate.website.com/.*\.(cab|exe|ms[i|u|f]|asf|wm[v| 
> a]|dat|zip) 4320 80% 43200 reload-into-ims cache_mem 100 MB 
> maximum_object_size_in_memory 32 KB memory_replacement_policy heap
> LFUDA
> 
> cache_replacement_policy heap LFUDA cache_dir ufs /var/squid/cache
> 6000 32 256 minimum_object_size 0 KB maximum_object_size 5000000
> KB


Your biggest cache is only 6GB in size. You truely expect to cache
many up-to-5GB objects there?



> offline_mode oncache_swap_low 90 cache_swap_high 95
> 
> # Add any of your own refresh_pattern entries above these.

Notice the above instruction.

> refresh_pattern ^ftp:    1440  20%  10080 refresh_pattern ^gopher:
> 1440  0%  1440 refresh_pattern -i (/cgi-bin/|\?) 0  0%  0 
> refresh_pattern .    0  20%  4320 # No redirector configured
> 
> #Remote proxies
> 
> # Setup some default acls acl allsrc src all

Why are you defining "allsrc" as a special name?
There is nothing special being done when it matches, just use "all"
instead.


> acl localhost src 127.0.0.1/32 acl safeports port 21 70 80 210 280
> 443 488 563 591 631 777 901  3128 1025-65535

NOTE: 3128 is part of the 1025-65535 number range.

> 
> acl sslports port 443 563 acl manager proto cache_object acl purge
> method PURGE acl connect method CONNECT
> 
> # Define protocols used for redirects acl HTTP proto HTTP acl HTTPS
> proto HTTPS
> 
> acl allowed_subnets src IP.REMOVED.FOR.SECURITY

NOTE: I hope that is not he same IP as the cache_peer below. If it is
you are explicitly allowing traffic to loop infinitely between the
peer and your Squid.

> acl blacklist dstdom_regex -i "/var/squid/acl/blacklist.acl" 
> http_access allow manager localhost
> 
> http_access deny manager http_access allow purge localhost 
> http_access deny purge http_access deny !safeports http_access deny
> CONNECT !sslports
> 
> # Always allow localhost connections http_access allow localhost
> 
> request_body_max_size 0 KB

Another default setting being explicitly configured. You should be
able to remove the above line.

> delay_pools 1 delay_class 1 2 delay_parameters 1 -1/-1 -1/-1 
> delay_initial_bucket_level 100 delay_access 1 allow allsrc

So, you want Squid to do a lot of complicated per-packet byte
accounting/management in order *not* to apply byte-rate limits ?

Erase the above delay_* directives and your Squid will work a bit faster.


> 
> # Reverse Proxy settings
> 
> # Custom options refresh_pattern -i .ipa$ 4320 100% 259200
> override-expire reload-into-ims ignore -reload refresh_pattern -i
> .pkg$ 4320 100% 259200 override-expire reload-into-ims ignore 
> -reload refresh_pattern -i .ipsw$ 4320 100% 259200 override-expire
> reload-into-ims ignor e-reload
> 

None of these refresh_patterns have any effect. They are not above the
default refresh_patterns with that notice about putting your own
patterns above them.


> cache_peer IP.REMOVED.FOR.SECURITY parent 8080 0 default 
> never_direct allow all
> 
> # Block access to blacklist domains http_access deny blacklist #
> Setup allowed acls # Allow local network(s) on interface(s) 
> http_access allow allowed_subnets http_access allow localnet #
> Default block all to be sure http_access deny allsrc
> 


Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUjzjnAAoJELJo5wb/XPRjiN4IAK8dj6AGVorC4olSVPtx1fyg
ZB4HTu7WYtNLHNTfoMxq7oLucvftCHIxwTNP+s2l3MbyvcaM4sceBpeALo0EL6wN
V5zN4Kt+MV0lolZMSuM7bfCqndNdN5eErRxAi99iwZXpbNZN0OEabqEoLL7kGX76
sNTXWCvXl9mvhVL0oWJHRN5tm8Gyv9BezZMJnY/zKdwMtb1zT7QEEZC+WCCH1s+6
2uB+tlf/ZMyFzairhXnYcC2PgjI4T5QbgsZcCPGbmGwIG3EbArbnUDIyPqqsJvaV
u8v/I1E7kQmEY2lrj8pDrfZLGVbQIv56Pa5R/Xof4B472snBLykG+R3wz/KalTI=
=dr00
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Mon Dec 15 20:10:34 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 Dec 2014 09:10:34 +1300
Subject: [squid-users] Splicing a connection if server cert cannot be
 verified
In-Reply-To: <BY2PR03MB364691B2198BC6B96D0E597D56F0@BY2PR03MB364.namprd03.prod.outlook.com>
References: <BY2PR03MB364691B2198BC6B96D0E597D56F0@BY2PR03MB364.namprd03.prod.outlook.com>
Message-ID: <548F403A.9040803@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 16/12/2014 8:11 a.m., Soren Madsen (DREIJER) wrote:
> Hi all,
> 
> By default, I want to bump all connections through my Squid
> instance. However, while testing I've discovered lots of sites that
> use SSLv3


Offering SSLv3 from a server is suicide these days. Those sites should
be on the fast decline, or at very least shunned like plague victims.
Lookup POODLE if you dont know why already.


> or self-signed certificates,

Nothing wrong with self-signed though. Much *more* secure than CA
validated certs when used in DANE protocol.

> in which case I'd like to fall back to TLS passthrough mode and let
> the client decide whether it wants to trust the server or not. In
> other words, if Squid cannot successfully bump a connection, I
> don't want to fail the connection, but rather step out of the way
> and let the client decide what to do.
> 
> The ideal solution, I think, would be to optimistically attempt to 
> bump the connection, but if it fails due to e.g. a bad server cert,
> a new connection can be established with the original client
> hello.
> 
> I was hoping the new peek and splice functionality would be able
> to help me in this regard: 
> http://wiki.squid-cache.org/Features/SslPeekAndSplice
> 
> As far as I can tell, the 'stare' action is what I'm interested in 
> here although it appears it's not a focus of the current 
> implementation, and the 'peek' action has the following limitation 
> note about 'Peeking at the server often precludes bumping': "We
> could teach Squid to abandon the current server connection and then
> bump a newly open one. This is something we do not want to do as it
> is likely to create an even worse operational problems with Squids
> being auto-blocked for opening and closing connections in vein."
> 
> I'm confused about this. Couldn't Squid just cache the information 
> about whether it has previously refrained from bumping a
> connection due to a bad server cert (or other errors) and only
> check with the server once the cache expires? That should avoid
> triggering any alarms on the server.

Happy eyeballs clients open multiple connections in parallel, causing
Squid to be seen opening just as many. Adding the above behaviour
would make the number of connections hammering the server multiply by
*at least* 2.

Also, with modern HTTPS load balancers every since connection is
potentially going to a different real backend server, with different
TLS settings even if the domain, IP, and port details are exactly
identical. Things could also change with no notice as admin fix
transient problems.

If you are going to bypass bumping based on vague-ish criteria then
you might as well just not bump. That gets you away from all those
technical probems, and a host of legal issues as well.


AIUI, the basic problem that "precludes bumping" is that in order to
peek at the serverHello some clientHello has to already have been
sent. Squid is already locked into using the features advertised in
that clientHello or dying - with no middle ground. Most times the
client and Squid do not actually have identical capabilities so
peeking the serverHello then either bump or splice actions will break
depending on which clientHello Squid sent.


> 
> Maybe I'm misreading the document. I was hoping somebody here on
> the list could explain to me if I can achieve the above behavior.
> 

I suspect you actually need the certificate mimic behaviour. Where
Squid generates a server cert as close as possible to the original,
including errors so the client can decide how to handle them.


HTH
Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUj0A6AAoJELJo5wb/XPRjBFgH/3G1mlMG/qMMcPH772Txy53I
iW7vi6is+V015UTKOxYs8cygB4eSFCtL8gXc2+y8ezOsZbSYX9kxCNqChul8clRE
fR8Bo+IldSP7ZcK8lBdoQdPVWz061P+OeyXnvz39ehajXaiXjOrstmT/G4HPWK79
vknA4aznvEnOZN/7qjcF9Arf2BbOQh7JzoO1hLD0XO2jKhS5E+/LbdJgw4i5tH+k
d8ZdxGSmFO/A7J1IZM9tH1bpuXQa3GSGHgEEDnPz7bMKw2mIKCoDV+BxNpqa9gsu
uWjNwEmA4/KAx5JzA/fYOGWDZDh3vsnUXcovRWxlEOB2N24EINz6I4bkTvdqLsY=
=1lCG
-----END PGP SIGNATURE-----


From sdreijer at microsoft.com  Mon Dec 15 21:20:13 2014
From: sdreijer at microsoft.com (Soren Madsen (DREIJER))
Date: Mon, 15 Dec 2014 21:20:13 +0000
Subject: [squid-users] Splicing a connection if server cert cannot be
 verified
In-Reply-To: <548F403A.9040803@treenet.co.nz>
References: <BY2PR03MB364691B2198BC6B96D0E597D56F0@BY2PR03MB364.namprd03.prod.outlook.com>
 <548F403A.9040803@treenet.co.nz>
Message-ID: <BY2PR03MB36452C552811D9EA7A09372D56F0@BY2PR03MB364.namprd03.prod.outlook.com>

Thanks for the quick reply, Amos.

> Offering SSLv3 from a server is suicide these days. Those sites should
> be on the fast decline, or at very least shunned like plague victims.
> Lookup POODLE if you dont know why already.

That's correct. That's why I don't want to bump such connections and instead fall back to splicing. In other words, if I can't trust the server, I want to get out of the way and defer the decision to the client.

> > or self-signed certificates,
> 
> Nothing wrong with self-signed though. Much *more* secure than CA
> validated certs when used in DANE protocol.

Yes, but Squid has no way of trusting a self-signed cert. When Squid mints a server cert on the fly and sends it to the client, the client won't have any idea that the cert was originally self-signed. Like the previous scenario, I'd want to step out of the way and defer the decision to the client.

> > in which case I'd like to fall back to TLS passthrough mode and let
> > the client decide whether it wants to trust the server or not. In
> > other words, if Squid cannot successfully bump a connection, I
> > don't want to fail the connection, but rather step out of the way
> > and let the client decide what to do.
> >
> > The ideal solution, I think, would be to optimistically attempt to
> > bump the connection, but if it fails due to e.g. a bad server cert,
> > a new connection can be established with the original client
> > hello.
> >
> > I was hoping the new peek and splice functionality would be able
> > to help me in this regard:
> > http://wiki.squid-cache.org/Features/SslPeekAndSplice
> >
> > As far as I can tell, the 'stare' action is what I'm interested in
> > here although it appears it's not a focus of the current
> > implementation, and the 'peek' action has the following limitation
> > note about 'Peeking at the server often precludes bumping': "We
> > could teach Squid to abandon the current server connection and then
> > bump a newly open one. This is something we do not want to do as it
> > is likely to create an even worse operational problems with Squids
> > being auto-blocked for opening and closing connections in vein."
> >
> > I'm confused about this. Couldn't Squid just cache the information
> > about whether it has previously refrained from bumping a
> > connection due to a bad server cert (or other errors) and only
> > check with the server once the cache expires? That should avoid
> > triggering any alarms on the server.
> 
> Happy eyeballs clients open multiple connections in parallel, causing
> Squid to be seen opening just as many. Adding the above behaviour
> would make the number of connections hammering the server multiply by
> *at least* 2.

I don't think I see the big problem here. If you hit a web server with 10 connections, but Squid decides to splice the connection after all and therefore closes the connections and create 10 new ones, that's hardly going to cause any alarms to go off. After that point, Squid will cache the fact that connections to that hostname shouldn't be bumped and subsequent attempts at hitting that hostname (based on the SNI, for instance) won't be bumped again until the cache expires.

> 
> Also, with modern HTTPS load balancers every since connection is
> potentially going to a different real backend server, with different
> TLS settings even if the domain, IP, and port details are exactly
> identical. Things could also change with no notice as admin fix
> transient problems.

Sure, and that's the point of the cache I mentioned above. If there happens to be a transient problem with the server, it's okay that Squid doesn't bump the connection for, say, an hour until it checks the host again. I see this as optimistic bumping, i.e. bump if you can but under no circumstances break the connectivity between the user and the server.

> If you are going to bypass bumping based on vague-ish criteria then
> you might as well just not bump. That gets you away from all those
> technical probems, and a host of legal issues as well.

I don't follow what you're saying here. How is looking at a server cert and determining that Squid cannot trust it "vague-ish" criteria? And a host of legal issues?

> AIUI, the basic problem that "precludes bumping" is that in order to
> peek at the serverHello some clientHello has to already have been
> sent. Squid is already locked into using the features advertised in
> that clientHello or dying - with no middle ground. Most times the
> client and Squid do not actually have identical capabilities so
> peeking the serverHello then either bump or splice actions will break
> depending on which clientHello Squid sent.

I don't see why that is a problem if you just recreate the connection to the server. That is, you first try bumping the connection by sending a new clientHello to the server, and if the server cert cannot be verified, a new connection is established and the original clientHello is sent to the server.

> > Maybe I'm misreading the document. I was hoping somebody here on
> > the list could explain to me if I can achieve the above behavior.
> >
> 
> I suspect you actually need the certificate mimic behaviour. Where
> Squid generates a server cert as close as possible to the original,
> including errors so the client can decide how to handle them.

How would you propose supporting self-signed certs in this scenario? 
This also means that in order to allow the client to use SSLv3, I'm going to have to allow Squid to bump SSLv3 connections, which I'm not keen on for the reason you mentioned yourself above.

Thanks,
Soren

From ahmed.zaeem at netstream.ps  Tue Dec 16 08:25:41 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Tue, 16 Dec 2014 00:25:41 -0800
Subject: [squid-users] squid_ldap_auth: WARNING,
	could not bind to binddn 'Invalid credentials'
In-Reply-To: <548F32C9.9060109@solutti.com.br>
References: <000001d018bb$63509200$29f1b600$@netstream.ps>
 <548F32C9.9060109@solutti.com.br>
Message-ID: <002101d01909$e2435d10$a6ca1730$@netstream.ps>

Hi Leonardo

Thanks a lot for reply ,

Let me ask you , do we need to do any delegation on the windows server ?

 

Can u summarize to me wt we need on AD in additional to creating the users ?

 

 

cheers

 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Leonardo Rodrigues
Sent: Monday, December 15, 2014 11:13 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid_ldap_auth: WARNING, could not bind to binddn 'Invalid credentials'

 


    I have several squids authenticating users using ldap_auth and it works fine. Users are located on the 'Users' OU and my config lines are:


(single line)
auth_param basic program /usr/lib/squid/squid_ldap_auth -P -R -b "dc=myad,dc=domain" -D "cn=ProxyUser,cn=Users,dc=myad,dc=domain"
-w "xxxxxxxxx" -f sAMAccountName=%s -h ad.ip.addr.ess

(single line)
external_acl_type ldap_group children=3 ttl=300 %LOGIN /usr/lib/squid/squid_ldap_group -P -R -b "dc=myad,dc=domain" -D "cn=ProxyUser,
cn=Users,dc=myad,dc=domain" -w "xxxxxxxxxxx" -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%a,cn=Users,
dc=myad,dc=domain))" -h ad.ip.addr.ess


On 15/12/14 21:03, Ahmed Allzaeem wrote:

Hi guys 

Im trying to use squid with active directory  2008 R2 as an external authentication

On DC called smart.ps

Create user squid and gave it delegation to the dc and put it also in the group admins in the OU=proxy

 





-- 
 
 
        Atenciosamente / Sincerily,
        Leonardo Rodrigues
        Solutti Tecnologia
        http://www.solutti.com.br
 
        Minha armadilha de SPAM, N?O mandem email
        gertrudes at solutti.com.br <mailto:gertrudes at solutti.com.br> 
        My SPAMTRAP, do not email it
 
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141216/4fd77284/attachment.htm>

From alexander.bubnov at bk.ru  Tue Dec 16 08:49:02 2014
From: alexander.bubnov at bk.ru (=?UTF-8?B?QWxleGFuZGVyIEJ1Ym5vdg==?=)
Date: Tue, 16 Dec 2014 11:49:02 +0300
Subject: [squid-users] =?utf-8?q?ICAP=3A_how_to_get_port_of_X-Client-IP?=
In-Reply-To: <548E6462.1020909@treenet.co.nz>
References: <1418389855.19761439@f356.i.mail.ru>
 <4149321418414999@web26g.yandex.ru>
 <548E6462.1020909@treenet.co.nz>
Message-ID: <1418719742.490807966@f228.i.mail.ru>


Hello Amos!
Glad to get your answer!


1. I have tried to use %>p specifier for adaptation_meta directive. But it seems does not work that way I used it.
I specified it in squid.conf:

adaptation_meta X-CLIENT-SRCPORT %>p

I found that specifier ony in logformat. May be you mixed it up?

2. About mapping port transparently. How does it help to get (at least) mapped port number in ICAP?

3. I would like to track any software. Especially software which use "User Agent" field not? legitimately or event does not fill it at all.


--
/BR, Alexander

Mon, 15 Dec 2014 17:32:34 +1300 ?? Amos Jeffries <squid3 at treenet.co.nz>:
>-----BEGIN PGP SIGNED MESSAGE-----
>Hash: SHA1
>
>On 13/12/2014 9:09 a.m., ????????? ?????? wrote:
>> I do not need to map it back remotely. I just need to know it. One
>> of my applications collects logs about all connections on a desktop
>> PC and another (ICAP server) collects what that applications sends
>> to the Internet. And to know that traffic belongs to certain
>> application I need to know port of the application on a desktop
>> PC.
>
>You could try using the adaptation_meta directive to add a custom
>header with %>p as the value parameter. I'm not sure if that will send
>a port number though.
>?? http://www.squid-cache.org/Doc/config/adaptation_meta/
>
>There is near zero reliability that the port number outgoing from the
>client is the same number incoming to Squid. There are numerous
>potential layers of protocol and machinery re-numbering ports
>transparently between any two devices.
>
>
>The name of the client application is supposed to be sent in the
>User-Agent: HTTP header which gets delivered to ICAP already. For most
>legitimate uses of agent-sniffing UA header + IP is sufficient
>information.
>
>Amos
>
>-----BEGIN PGP SIGNATURE-----
>Version: GnuPG v2.0.22 (MingW32)
>
>iQEcBAEBAgAGBQJUjmRiAAoJELJo5wb/XPRj9skH/i6rlp7XmNptgfn/VgKtgH+v
>D22idQBsXyTC00LN2UQssz6Hrpk7nvK96dKObtSppJQ8Xtu1NrrPG1uSq1plRgBT
>d5EXRYnAMttTbI5KVDdXW6IsFSjTkL2Hr1m244BEv7SRUBNaa67XPpDjucoIX2kP
>8eIKZrB32jaW3/t2VDIl67iRKOZQh3DZfFqFrU6BgZCrLXjZXU/629+KBVnvNg/A
>TEnYXDBOSRwRVsWuLK/o0bZFI7y6wp0jtRT1ETliUpmdbGKKPSnMWLym2FX5VI+d
>8B1BSzbjEAP+sWex2oKE5Z7+FQ+eSf2tYLvS15fqAHe09hKqpJTMur4cumdkRM0=
>=LgMG
>-----END PGP SIGNATURE-----
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141216/0b15bd7f/attachment.htm>

From james at ejbdigital.com.au  Tue Dec 16 10:01:06 2014
From: james at ejbdigital.com.au (James Harper)
Date: Tue, 16 Dec 2014 10:01:06 +0000
Subject: [squid-users] 'cache' config option and rewrite
Message-ID: <HKNPR04MB1935709C271DBDE86DE7BD9E86C0@HKNPR04MB193.apcprd04.prod.outlook.com>

I have a rewrite rule so that any request for a list of apt repositories (acl dstdomain) are rewritten to instead go to my apt-cacher server, and then a "cache deny" rule to make sure squid doesn't cache files from these repositories. This seemed to be working fine but my latest attempt at a debian install kept failing because the gpg signature didn't match. It turns that that squid was actually caching these requests, which is the opposite of what I wanted as it meant that the sig and the file got out of sync (I guess apt-cacher doesn't return a proper indication of what is allowed to be cached and what isn't... so the sig was cached but the file wasn't, or something like that)

It turns out that "cache deny <dstdomain acl>" is processed after the rewrite, and against the rewritten url, so I needed to also exclude requests for my server running apt-cacher.

So for example:

acl apt_repo dstdomain ftp.au.debian.org
acl apt_cacher browser apt-cacher # apt-cacher itself

cache deny apt_repo
cache deny apt_cacher
cache allow all

but I needed to add:

acl apt_repo dstdomain my.apt.cacher.server

This is kind of obvious in retrospect, but is it described anywhere which rules apply against the url before it is rewritten and which are applied to the rewritten url?

Thanks

James


From squid3 at treenet.co.nz  Tue Dec 16 12:41:15 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 Dec 2014 01:41:15 +1300
Subject: [squid-users] 'cache' config option and rewrite
In-Reply-To: <HKNPR04MB1935709C271DBDE86DE7BD9E86C0@HKNPR04MB193.apcprd04.prod.outlook.com>
References: <HKNPR04MB1935709C271DBDE86DE7BD9E86C0@HKNPR04MB193.apcprd04.prod.outlook.com>
Message-ID: <5490286B.9000603@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 16/12/2014 11:01 p.m., James Harper wrote:
> I have a rewrite rule so that any request for a list of apt
> repositories (acl dstdomain) are rewritten to instead go to my
> apt-cacher server, and then a "cache deny" rule to make sure squid
> doesn't cache files from these repositories. This seemed to be
> working fine but my latest attempt at a debian install kept failing
> because the gpg signature didn't match. It turns that that squid
> was actually caching these requests, which is the opposite of what
> I wanted as it meant that the sig and the file got out of sync (I
> guess apt-cacher doesn't return a proper indication of what is
> allowed to be cached and what isn't... so the sig was cached but
> the file wasn't, or something like that)
> 
> It turns out that "cache deny <dstdomain acl>" is processed after
> the rewrite, and against the rewritten url, so I needed to also
> exclude requests for my server running apt-cacher.
> 
> So for example:
> 
> acl apt_repo dstdomain ftp.au.debian.org acl apt_cacher browser
> apt-cacher # apt-cacher itself
> 
> cache deny apt_repo cache deny apt_cacher cache allow all
> 
> but I needed to add:
> 
> acl apt_repo dstdomain my.apt.cacher.server
> 
> This is kind of obvious in retrospect, but is it described anywhere
> which rules apply against the url before it is rewritten and which
> are applied to the rewritten url?
> 

URL re-write is a type of request adaptation.

The operational sequence of HTTP request processing is roughly:
 * parse + header interpretation
 * network traffic security/policy checks (http_access etc)
 * request adaptation (ICAP, eCAP, URL-rewrite/redirect)
 * security policy checks on adapted content (adapted_http_access etc)
 * source type selection (Store-ID rewrite, cache/store_hit directive)
 * client connection QoS setup
 * source-type specific file/worker/server setup
 * fetching the response

I'm not sure if we have it documented anywhere outside the code.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUkChqAAoJELJo5wb/XPRjJVoIAKyyiJY4koPWKXwQy7FBpcCR
Ts0K/glXs2dRDtElp5ijZo7qoxyKPHoE8/H5gJ97f6wb76syctKZNsjYbPjTStNo
G9qSN9prjo18MvYRZupmz6LTGeE+jKAeAcpoNiqprIAsR3H2uQpTAd0lXYIVGZly
EZ8v//IntiGGfEMFP6VP26AD6eG3uTXwUDEa0msv/PcuXTq0uH2monaMQU/aLzhr
rmxAPmLe/x6z0OqY6by/LCk4qFLfFe9lfA3MG2RnJh/ZAy/b6FeApGMQpAX+XfmK
it1U9uZIQUsxKpd6zKP6Ekk7T/j4AD1ImDwK0K03vfj9uKA+Svp/XSlhc9FEam8=
=XGfH
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Dec 16 12:42:37 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 Dec 2014 01:42:37 +1300
Subject: [squid-users] ICAP: how to get port of X-Client-IP
In-Reply-To: <1418719742.490807966@f228.i.mail.ru>
References: <1418389855.19761439@f356.i.mail.ru>
 <4149321418414999@web26g.yandex.ru> <548E6462.1020909@treenet.co.nz>
 <1418719742.490807966@f228.i.mail.ru>
Message-ID: <549028BD.9020308@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 16/12/2014 9:49 p.m., Alexander Bubnov wrote:
> 
> Hello Amos! Glad to get your answer!
> 
> 
> 1. I have tried to use %>p specifier for adaptation_meta directive.
> But it seems does not work that way I used it. I specified it in
> squid.conf:
> 
> adaptation_meta X-CLIENT-SRCPORT %>p
> 
> I found that specifier ony in logformat. May be you mixed it up?

We are generalizing the logformat tokens for use anywhere custom
formats or strings might be configured. I was hoping that header value
parameter had been updated already, but it seems not.

> 
> 2. About mapping port transparently. How does it help to get (at
> least) mapped port number in ICAP?

I dont know. You were pretty adamant that the (ephemeral) port Squid
was receiving from was what you needed passed through, so I figured
you had a use-case for it.

> 
> 3. I would like to track any software. Especially software which
> use "User Agent" field not  legitimately or event does not fill it
> at all.
> 

Thats possibly the answer to your Q#2.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUkCi9AAoJELJo5wb/XPRjlhYIAK40g+UJ2jxSjYCQuDbwzdk/
uamQVRYZr51bmrGbt61XDC88lq1g9b9zCR768VySbwWziMbQng0VXkS+pwY13BHC
SzyTZ/9VHy8SQ7JOr81z6/aufspN1x3Ht8bSIP084ZtXvjAKKqQd0jawNUA+tU7W
VtLq4/LRaNAs+U4mlUL8n/E643Qkx+qGUbIBEtebGN+m9Av+SwjBfxpR43qEaonW
gCcDQU6UQM46CaTlqknW8CgkFfk7QfXQAJM+9Gkc1L/7Z5xIhxB45WcwuF/NEkwZ
zS8fT1gva23JnSyIdm32JNQM2V4PXUs0D15/JcdqubQdn71xyh9RMIjtYThqBeo=
=YKfQ
-----END PGP SIGNATURE-----


From fredbmail at free.fr  Tue Dec 16 14:03:51 2014
From: fredbmail at free.fr (FredB)
Date: Tue, 16 Dec 2014 15:03:51 +0100 (CET)
Subject: [squid-users] Problem with digest authentification and
 credential backend
In-Reply-To: <990004087.193226555.1417449226399.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <307436124.226535781.1418738631357.JavaMail.root@zimbra4-e1.priv.proxad.net>


> > Ok, thanks,
> > 
> > Tested with both nonce_count and nonce_max_duration, no problem. Do
> > you known if it works with squid 3.5 ?
> > 
> > 
> 
> No sorry I don't know, but if the patch can be applied I guess that
> yes it can works.
> Except if there are some changes in DIGEST between 3.4 and 3.5.
> _______________________________________________


Quickly checked in 3.5.0.3, no 
The file auth_digest.cc is missing, I will take a look later.

Fred

 


From ahmed.zaeem at netstream.ps  Wed Dec 17 00:03:42 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Tue, 16 Dec 2014 16:03:42 -0800
Subject: [squid-users] squid rotating between many ips
Message-ID: <000001d0198c$ec779480$c566bd80$@netstream.ps>

Hello Guys , im gonna configure squid with many ips with many outside
outgoing addresses.

 

But my goal this time is .

I need rotating ips.

 

As an example , I connect to ip:port , and then I need my ips be rotated
between many outgoing ips

 

How can squid help me with that ?

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141216/e0455182/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec 16 14:20:55 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 Dec 2014 03:20:55 +1300
Subject: [squid-users] Splicing a connection if server cert cannot be
 verified
In-Reply-To: <BY2PR03MB36452C552811D9EA7A09372D56F0@BY2PR03MB364.namprd03.prod.outlook.com>
References: <BY2PR03MB364691B2198BC6B96D0E597D56F0@BY2PR03MB364.namprd03.prod.outlook.com>
 <548F403A.9040803@treenet.co.nz>
 <BY2PR03MB36452C552811D9EA7A09372D56F0@BY2PR03MB364.namprd03.prod.outlook.com>
Message-ID: <54903FC7.9020905@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 16/12/2014 10:20 a.m., Soren Madsen (DREIJER) wrote:
> Thanks for the quick reply, Amos.
> 
>> Offering SSLv3 from a server is suicide these days. Those sites
>> should be on the fast decline, or at very least shunned like
>> plague victims. Lookup POODLE if you dont know why already.
> 
> That's correct. That's why I don't want to bump such connections
> and instead fall back to splicing. In other words, if I can't trust
> the server, I want to get out of the way and defer the decision to
> the client.
> 
>>> or self-signed certificates,
>> 
>> Nothing wrong with self-signed though. Much *more* secure than
>> CA validated certs when used in DANE protocol.
> 
> Yes, but Squid has no way of trusting a self-signed cert. When
> Squid mints a server cert on the fly and sends it to the client,
> the client won't have any idea that the cert was originally
> self-signed. Like the previous scenario, I'd want to step out of
> the way and defer the decision to the client.
> 

The global list of CAs which non-self-signed certs validate against is
explicitly loaded into the SSL library. It is not a built-in list.

All you have to do to trust a "self-signed" cert is add the CA signing
it to your trusted set.


>>> in which case I'd like to fall back to TLS passthrough mode and
>>> let the client decide whether it wants to trust the server or
>>> not. In other words, if Squid cannot successfully bump a
>>> connection, I don't want to fail the connection, but rather
>>> step out of the way and let the client decide what to do.
>>> 
>>> The ideal solution, I think, would be to optimistically attempt
>>> to bump the connection, but if it fails due to e.g. a bad
>>> server cert, a new connection can be established with the
>>> original client hello.
>>> 
>>> I was hoping the new peek and splice functionality would be
>>> able to help me in this regard: 
>>> http://wiki.squid-cache.org/Features/SslPeekAndSplice
>>> 
>>> As far as I can tell, the 'stare' action is what I'm interested
>>> in here although it appears it's not a focus of the current 
>>> implementation, and the 'peek' action has the following
>>> limitation note about 'Peeking at the server often precludes
>>> bumping': "We could teach Squid to abandon the current server
>>> connection and then bump a newly open one. This is something we
>>> do not want to do as it is likely to create an even worse
>>> operational problems with Squids being auto-blocked for opening
>>> and closing connections in vein."
>>> 
>>> I'm confused about this. Couldn't Squid just cache the
>>> information about whether it has previously refrained from
>>> bumping a connection due to a bad server cert (or other errors)
>>> and only check with the server once the cache expires? That
>>> should avoid triggering any alarms on the server.
>> 
>> Happy eyeballs clients open multiple connections in parallel,
>> causing Squid to be seen opening just as many. Adding the above
>> behaviour would make the number of connections hammering the
>> server multiply by *at least* 2.
> 
> I don't think I see the big problem here. If you hit a web server
> with 10 connections, but Squid decides to splice the connection
> after all and therefore closes the connections and create 10 new
> ones, that's hardly going to cause any alarms to go off. After that
> point, Squid will cache the fact that connections to that hostname
> shouldn't be bumped and subsequent attempts at hitting that
> hostname (based on the SNI, for instance) won't be bumped again
> until the cache expires.
> 
>> 
>> Also, with modern HTTPS load balancers every since connection is 
>> potentially going to a different real backend server, with
>> different TLS settings even if the domain, IP, and port details
>> are exactly identical. Things could also change with no notice as
>> admin fix transient problems.
> 
> Sure, and that's the point of the cache I mentioned above. If there
> happens to be a transient problem with the server, it's okay that
> Squid doesn't bump the connection for, say, an hour until it checks
> the host again. I see this as optimistic bumping, i.e. bump if you
> can but under no circumstances break the connectivity between the
> user and the server.
> 
>> If you are going to bypass bumping based on vague-ish criteria
>> then you might as well just not bump. That gets you away from all
>> those technical probems, and a host of legal issues as well.
> 
> I don't follow what you're saying here. How is looking at a server
> cert and determining that Squid cannot trust it "vague-ish"
> criteria? And a host of legal issues?
> 

The vagueness is in how long the cache will be presenting accurate
representation of the cert state. Given the LB situation and other
intermediaries like Squid generatign certs per-connection there is no
reliability on it being accurate from one use to the next.


>> AIUI, the basic problem that "precludes bumping" is that in order
>> to peek at the serverHello some clientHello has to already have
>> been sent. Squid is already locked into using the features
>> advertised in that clientHello or dying - with no middle ground.
>> Most times the client and Squid do not actually have identical
>> capabilities so peeking the serverHello then either bump or
>> splice actions will break depending on which clientHello Squid
>> sent.
> 
> I don't see why that is a problem if you just recreate the
> connection to the server. That is, you first try bumping the
> connection by sending a new clientHello to the server, and if the
> server cert cannot be verified, a new connection is established and
> the original clientHello is sent to the server.
> 

"just" recreating the connection to the server means discarding the
old one. Which is not anywhere near as nice a proposition once you
look beyond the single proxy.

The details, you can skip if you want to avoid...

* Each aborted connection means 15 minutes TCP TIME_WAIT delay before
that TCP socket can be re-used.

* TCP/IP limits software to 63K sockets per IP address (64K total with
1024 reserved).

Using multiple outbound connections to discover some behaviour is what
the browser "happy eyeballs" algoithm is all about. They are just
looking for connectino handshake speed rather than cert properties.

- - Browsers are operating on rate of 10's to hundreds of single
requests per minute. With all 64K per-IP sockets on that machine
dedicated to the one end user.

- - Proxies are individually dealing with requests on the rate of 10's
or 100's of thousand requests per minute. Sharing socets between
hundreds or thousands of end-users.

At that speed 64K sockets per IP address are consumed very quickly
already. Squid is limited to a very few over 10K new
connections/minute per IP address on the machine. We get away with
higher rates by having HITs, collapsed-forwarding and by multiplexing
requests onto server connections.
 => multiplex is the biggest gainer which is not possible with HTTPS
traffic, despite bumping.

Then you have to consider the Internet-wide scale which all these
things are operating on. Internet is not a simple client->server or
even client->proxy->server connection. The reality is that the general
architecture is more like: users browser, ISP load balancer, ISP
cache, content provider CDN router/load balancer, content provider CDN
cache, origin server load balancer and finally origin server. approx 6
"hops" that each HTTP connnection goes through. Sometimes worse,
sometimes better. But the common situation for users is being on a big
ISP visiting popular so called "Big content" website.

What you are asking is that we effectively do happy-eyeballs for
outbound server connections in proxies. With each of the above hops
the number of TCP sockets consumed doubles, and all but 1 in that hop
will be discarded by the end of the handshake process.


* Browser people love their happy-eyeballs and prefetch algorithms. So
it starts everything by opening 2 sockets to see which connects
fastest and only using that one. (and probably not just 2, but 4 or 8
but I shall simplify).

By the end of the doubling at each proxy, (2^6) -> 64 sockets per
client connection hitting the origin server in worst-case. Thats
limiting it to serving only 1000 end users every 15 minutes. Or
serving just 1 *single* HTTP request per second.

Sites like Facebook load several hundreds of objects per page. Imagine
how badly the site would be if it took a few minutes to load after
each click.

Or how much the hardware they would have to purchase would cost at a
rate of 2-3 whole servers per user (at 100's million of users) for a
half-decent response rate.


I know those last two conclusions are OTT worst-case extreme of the
problem. However, the main point is that all that stands between
worst-case from becoming common-case is how much we *avoid* joining in
on the browser happy-eyeballs behaviour you are suggesting.
 And remember that I got to those nasty numbers quickly despite
conservatively assuming the browser only oppened 2 connections at the
start.


>>> Maybe I'm misreading the document. I was hoping somebody here
>>> on the list could explain to me if I can achieve the above
>>> behavior.
>>> 
>> 
>> I suspect you actually need the certificate mimic behaviour.
>> Where Squid generates a server cert as close as possible to the
>> original, including errors so the client can decide how to handle
>> them.
> 
> How would you propose supporting self-signed certs in this
> scenario?

A truely self-signed cert is a CA cert and must never be used to
encrypt a connection directly. What is seen on the wire and called
"self-signed" is actually a cert signed by some CA (the servers admin)
who is not in your trusted CA set.

So...

... if a lot of your traffic comes from a few sites you can add those
sites CA cert to your proxies trusted CA set.
 - maybe check and see if the CA-certificates set used by your proxy
machines SSL library is up to date. If that is outdated a bunch of
those self-signed claims may be false-nagatives.

... or you can replace the helper program Squid uses to validate the
certs with one that accepts self-signed.

I am interested in getting a helper that does TLSA/DANE validation. A
lot of sites are starting to use TLSA cert instead of the global
corporate CAs.


> This also means that in order to allow the client to use SSLv3, I'm
> going to have to allow Squid to bump SSLv3 connections, which I'm
> not keen on for the reason you mentioned yourself above.
> 

Nod.

It is a little bit safer to allow Squid to use SSLv3 to servers which
are still broken, than to allow clients to SSLv3 to Squid. At least
half of the connectivity you have soemthign to do with becomes
trustworthy even though the overall end-2-end security is no better (yet).

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUkD/HAAoJELJo5wb/XPRj0bEH/jMKe7M/CJPMUgUDlIkdzJyU
zWn8mnv80cpoz2TdFd71vcGFT3wDLLlOleGLu6RyFWI3ikGHcAa1jdeAOJhbBk5v
dQlx7nWYiIV5rkFYHYgkl2lNBFdI9ETX4SakPWrLksf/6XGvascP8mNNDI8987XB
Vk2HXSUnA9dRiWUvmc4bOc4inMSqdjwoFR8uKQmsG6PQftNGrmrtfUcqi3fLXwMU
k8RpIPDiczCf2FzjXMk8VbfnTHEGtodDGKtjmRQk0zrc7NeO5LmyGgCbficqsmWM
PqcSKVi6pI5Rl/CrWAfgZiSlrlKnShItA5uZOIxHroLYo0gslW0BvAwT86xX/fo=
=Gwkq
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Tue Dec 16 14:21:37 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 16 Dec 2014 16:21:37 +0200
Subject: [squid-users] squid rotating between many ips
In-Reply-To: <000001d0198c$ec779480$c566bd80$@netstream.ps>
References: <000001d0198c$ec779480$c566bd80$@netstream.ps>
Message-ID: <54903FF1.6060503@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/17/2014 02:03 AM, Ahmed Allzaeem wrote:
> Hello Guys , im gonna configure squid with many ips with many
> outside outgoing addresses.
> 
> 
> 
> But my goal this time is .
> 
> I need rotating ips.
> 
> 
> 
> As an example , I connect to ip:port , and then I need my ips be
> rotated between many outgoing ips
> 
> 
> 
> How can squid help me with that ?
> 
> 
Hey,

If you want to rotate IP addresses you will better implement it on the
OS level and not squid.

All The Bests,
Eliezer


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUkD/xAAoJENxnfXtQ8ZQUEtwIAIrpGgzoPEfJQ0MJ8Aaxm19p
dd/zWuax/C+yIm3IpiinQWK8DqpoyUUKOp8gJRXVAb9bH+fvpYo0hqxNxj0wW2CW
d2baWnhIbTF6F0J6T0BUQxXpkRBwYbCKlGHazVq98iTxNZMWSuIEfwZr1mICYvMn
6B40nIrrHC7Upzgh3nqb3C51em+9e3qi9Eo8w7RXCcdbF86J+4V2KjMIRSr+kQsU
8/INHD22KKRy3Rn5OiRurbXJBlzhL2K7bc1dlZQejT/4FoJMrAosYVf15YZfCRw6
UX7OYZrGN0IMeeefsf3Mppey6JdhQY934KsZD8GhDzLHaEswWIAGFfanwJZcOIU=
=rUNn
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Dec 16 14:22:21 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 Dec 2014 03:22:21 +1300
Subject: [squid-users] Problem with digest authentification and
 credential backend
In-Reply-To: <307436124.226535781.1418738631357.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <307436124.226535781.1418738631357.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <5490401D.4000208@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 17/12/2014 3:03 a.m., FredB wrote:
> 
>>> Ok, thanks,
>>> 
>>> Tested with both nonce_count and nonce_max_duration, no
>>> problem. Do you known if it works with squid 3.5 ?
>>> 
>>> 
>> 
>> No sorry I don't know, but if the patch can be applied I guess
>> that yes it can works. Except if there are some changes in DIGEST
>> between 3.4 and 3.5. 
>> _______________________________________________
> 
> 
> Quickly checked in 3.5.0.3, no The file auth_digest.cc is missing,
> I will take a look later.

Should be called auth/digest/Config.cc now. Contents should not be
much different, just the filename.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUkEAdAAoJELJo5wb/XPRjJ3gIAI+OpHgIGMTAk6QIpOlCsbEN
e4XCTHNoRllyiaX2huH+Uav2qThHBDVnvI9ouXV/dirmjyFROn7G7fmzDo+SWciP
7+ZjcIqdJhZxT3cUqrbpM/wLuu4QNXrFZovoFR1XUSE25LILtVyxesNO8H3j1WZm
JvtXQwgkH1b2gCUCH0h9hpK4B/yS0kp9qAIG8thM0HbeVo3C2W7CJV/N7vxTQQ/k
Oq/C4YgTA1o4aWRjDlt4zgtkFXRSI7piDbYnT0hOxNxdOX0xBse7wLE55atIYiFf
4Xna8/B5pll7mTTeGD5Xo0IA0cJdFj7J6JP3kwGSEPxVi/izW+3uvhMUWcF7taU=
=mgG6
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Dec 16 14:32:57 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 Dec 2014 03:32:57 +1300
Subject: [squid-users] squid rotating between many ips
In-Reply-To: <000001d0198c$ec779480$c566bd80$@netstream.ps>
References: <000001d0198c$ec779480$c566bd80$@netstream.ps>
Message-ID: <54904299.6020502@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 17/12/2014 1:03 p.m., Ahmed Allzaeem wrote:
> Hello Guys , im gonna configure squid with many ips with many
> outside outgoing addresses.
> 
> 
> 
> But my goal this time is .
> 
> I need rotating ips.
> 
> 
> 
> As an example , I connect to ip:port , and then I need my ips be
> rotated between many outgoing ips
> 
> 
> 
> How can squid help me with that ?
> 

Yes, by combining these:
 http://wiki.squid-cache.org/ConfigExamples/Strange/RotatingIPs
http://wiki.squid-cache.org/Features/AclRandom

... but what are you trying to do it for?

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUkEKZAAoJELJo5wb/XPRjhWEIALATzev+bjI6U/D9NZ00v6Qk
Bv4q4qcSqtd97Zdts92tlffmMcMaC18mjMw7AK8fgECXKG+CsAqbEgl4f/FZXfPp
JySg4Tyrtdbcxo7uqCsPvf7S4IFBavPLkUyhOUS0+UimWzT5JN1nwBomdFqwTzod
PC9ZbveXUKb0PHZf9K5J/NZkhzgQudMq4tRTvcYjrq3Mf6pCUn6cORwYqy71F4Rc
TApxy+Sxl+TT2Ndr5rremy6lpq0d7AzuzCEHr6QCuzD0JwJFXngFJnEiXWOhGUoJ
7L1CihD4AIgtYWesGxX0FAVviOmoMkIzp1+KwXP40T9SY67Sq1d74U7v75qptqs=
=hl+n
-----END PGP SIGNATURE-----


From fredbmail at free.fr  Tue Dec 16 15:42:32 2014
From: fredbmail at free.fr (FredB)
Date: Tue, 16 Dec 2014 16:42:32 +0100 (CET)
Subject: [squid-users] Problem with digest authentification and
 credential backend
In-Reply-To: <5490401D.4000208@treenet.co.nz>
Message-ID: <1236837612.226735321.1418744552567.JavaMail.root@zimbra4-e1.priv.proxad.net>


> Should be called auth/digest/Config.cc now. Contents should not be
> much different, just the filename.
> 
> Amos


Hello,

Thnaks Amos,
Ok, so I will provide a patch in bug report this week  

Fred


From lars at lhanke.de  Tue Dec 16 18:10:53 2014
From: lars at lhanke.de (Dr. Lars Hanke)
Date: Tue, 16 Dec 2014 19:10:53 +0100
Subject: [squid-users] Strange entries in access.log
Message-ID: <549075AD.1060709@lhanke.de>

Hi,

in my access.log I find entries like:

1418752070.702      0 172.16.1.66 NONE/400 3636 
%C0%0E%C0%0F%C0%07%C0%09%C0 - NONE/- text/html
1418752082.987      0 172.16.1.66 NONE/400 3636 
%C0%0E%C0%0F%C0%07%C0%09%C0 - NONE/- text/html
1418752083.490      0 172.16.1.66 NONE/400 3636 
%C0%0E%C0%0F%C0%07%C0%09%C0 - NONE/- text/html
1418752083.526      0 172.16.1.66 NONE/400 3636 
%C0%0E%C0%0F%C0%07%C0%09%C0 - NONE/- text/html

I guess that these come from a mobile phone, which is transparently 
proxied (the IP belongs to the router). The mobile receives "The 
requested URL could not be retrieved" "Invalid URL", which is not 
surprising given the log. However, the phone works when connected to the 
net directly.

The device is a Samsung GT-B5330 running Android 4.0.4 using the 
standard browser. Squid is 3.1.6 as current in Debian 6 (Squeeze).

Is this something known?

Regards,
  - lars.



From natxo.asenjo at gmail.com  Tue Dec 16 18:40:24 2014
From: natxo.asenjo at gmail.com (Natxo Asenjo)
Date: Tue, 16 Dec 2014 19:40:24 +0100
Subject: [squid-users] citrix receiver not authenticating with squid
Message-ID: <CAHBEJzX6ofZrMjcZymVDcb5gdwA6OzJZcxLEfD0+g0Re73tNAw@mail.gmail.com>

hi,

we have 2 centos 6 hosts providing a load-balanced squid service
(behind keepalived and haproxy; haproxy sends requests to both squids)
and authenticating users against an Active Directory environment. This
is working really nice.

Our users log in their desktops and using the negotiate authenticator
squid_kerb_auth they get automatically logged in the proxies. As a
fall back for users using them but not logging in to the kerberos AD
domain, we offer ldap authentication as well. That works fine too.

However, some of our users need to log in to other organizations
desktops using the citrix reciever plugin and Internet Explorer. And
there it fails. The plugin does not use the negotiate authenticator
apparently so it falls back to the ldap authenticator. This works for
a few minutes, but after some time the receiver ldap authentication
pop up re-appears, and then again, and again. Not nice.

Does anyone have squid working to access citrix vpn sites without this
problem? Do you know what setting to tweak?

Could it be that the load-balanced setting is provoking this? Should I
have the haproxy config as a primary/slave instead of both masters?

This is a piece of the log file:

172.20.4.33 - - [16/Dec/2014:14:59:47 +0100] "CONNECT
login.site.com:443 HTTP/1.0" 407 3996 "-" "Mozilla/5.0 (compatible;
MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_DENIED:NONE
172.20.4.33 - - [16/Dec/2014:14:59:48 +0100] "CONNECT
login.site.com:443 HTTP/1.0" 407 3996 "-" "Mozilla/5.0 (compatible;
MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_DENIED:NONE
172.20.4.33 - - [16/Dec/2014:14:59:48 +0100] "CONNECT
login.site.com:443 HTTP/1.0" 407 3996 "-" "Mozilla/5.0 (compatible;
MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_DENIED:NONE
172.20.4.33 - user at DOMAIN [16/Dec/2014:15:00:03 +0100] "CONNECT
login.site.com:443 HTTP/1.0" 200 20472 "-" "Mozilla/5.0 (compatible;
MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_MISS:DIRECT
172.20.4.33 -user at DOMAIN [16/Dec/2014:15:00:03 +0100] "CONNECT
login.site.com:443 HTTP/1.0" 200 41726 "-" "Mozilla/5.0 (compatible;
MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_MISS:DIRECT
172.20.4.33 -user at DOMAIN [16/Dec/2014:15:00:28 +0100] "CONNECT
login.site.com:443 HTTP/1.0" 200 20447 "-" "Mozilla/5.0 (compatible;
MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_MISS:DIRECT
172.20.4.33 - - [16/Dec/2014:15:01:37 +0100] "CONNECT
login.site.com:443 HTTP/1.0" 407 3996 "-" "Mozilla/5.0 (compatible;
MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_DENIED:NONE
172.20.4.33 -user at DOMAIN [16/Dec/2014:15:01:54 +0100] "CONNECT
login.site.com:443 HTTP/1.0" 200 32958 "-" "Mozilla/5.0 (compatible;
MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_MISS:DIRECT

My squid.conf for completeness

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

auth_param negotiate program /usr/lib/squid/squid_kerb_auth -i -s
HTTP/proxy.domain.tld at DOMAIN.TLD
auth_param negotiate children 10
auth_param negotiate keep_alive on
acl auth proxy_auth REQUIRED

auth_param basic program /usr/lib/squid/squid_ldap_auth -b
dc=domain,dc=tld -f "samaccountname=%s" -s sub -D user -W
/etc/squid/squid_ldap_bi
nd -h dc1.domain.tld,dc2.domain.tld,dc3.domain.tld -p 3268 -Z
auth_param basic children 10
auth_param basic realm Proxy LDAP Authentication
auth_param basic credentialsttl 8 hours

acl SSL_ports port 443
acl SSL_ports port 1494
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

http_access allow localhost

http_access deny !auth
http_access allow auth

http_access deny all

# Squid normally listens to port 3128
http_port 3128

# We recommend you to use at least the following line.
hierarchy_stoplist cgi-bin ?

logformat combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
"%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
access_log /var/log/squid/combined.log combined

Thanks in advance.

--
Groeten,
natxo


From bpk678 at gmail.com  Tue Dec 16 19:13:10 2014
From: bpk678 at gmail.com (Brendan Kearney)
Date: Tue, 16 Dec 2014 14:13:10 -0500
Subject: [squid-users] citrix receiver not authenticating with squid
In-Reply-To: <CAHBEJzX6ofZrMjcZymVDcb5gdwA6OzJZcxLEfD0+g0Re73tNAw@mail.gmail.com>
References: <CAHBEJzX6ofZrMjcZymVDcb5gdwA6OzJZcxLEfD0+g0Re73tNAw@mail.gmail.com>
Message-ID: <1418757190.2481.8.camel@desktop.bpk2.com>

On Tue, 2014-12-16 at 19:40 +0100, Natxo Asenjo wrote:
> hi,
> 
> we have 2 centos 6 hosts providing a load-balanced squid service
> (behind keepalived and haproxy; haproxy sends requests to both squids)
> and authenticating users against an Active Directory environment. This
> is working really nice.
> 
> Our users log in their desktops and using the negotiate authenticator
> squid_kerb_auth they get automatically logged in the proxies. As a
> fall back for users using them but not logging in to the kerberos AD
> domain, we offer ldap authentication as well. That works fine too.
> 
> However, some of our users need to log in to other organizations
> desktops using the citrix reciever plugin and Internet Explorer. And
> there it fails. The plugin does not use the negotiate authenticator
> apparently so it falls back to the ldap authenticator. This works for
> a few minutes, but after some time the receiver ldap authentication
> pop up re-appears, and then again, and again. Not nice.
> 
> Does anyone have squid working to access citrix vpn sites without this
> problem? Do you know what setting to tweak?
> 
> Could it be that the load-balanced setting is provoking this? Should I
> have the haproxy config as a primary/slave instead of both masters?
> 
> This is a piece of the log file:
> 
> 172.20.4.33 - - [16/Dec/2014:14:59:47 +0100] "CONNECT
> login.site.com:443 HTTP/1.0" 407 3996 "-" "Mozilla/5.0 (compatible;
> MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_DENIED:NONE
> 172.20.4.33 - - [16/Dec/2014:14:59:48 +0100] "CONNECT
> login.site.com:443 HTTP/1.0" 407 3996 "-" "Mozilla/5.0 (compatible;
> MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_DENIED:NONE
> 172.20.4.33 - - [16/Dec/2014:14:59:48 +0100] "CONNECT
> login.site.com:443 HTTP/1.0" 407 3996 "-" "Mozilla/5.0 (compatible;
> MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_DENIED:NONE
> 172.20.4.33 - user at DOMAIN [16/Dec/2014:15:00:03 +0100] "CONNECT
> login.site.com:443 HTTP/1.0" 200 20472 "-" "Mozilla/5.0 (compatible;
> MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_MISS:DIRECT
> 172.20.4.33 -user at DOMAIN [16/Dec/2014:15:00:03 +0100] "CONNECT
> login.site.com:443 HTTP/1.0" 200 41726 "-" "Mozilla/5.0 (compatible;
> MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_MISS:DIRECT
> 172.20.4.33 -user at DOMAIN [16/Dec/2014:15:00:28 +0100] "CONNECT
> login.site.com:443 HTTP/1.0" 200 20447 "-" "Mozilla/5.0 (compatible;
> MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_MISS:DIRECT
> 172.20.4.33 - - [16/Dec/2014:15:01:37 +0100] "CONNECT
> login.site.com:443 HTTP/1.0" 407 3996 "-" "Mozilla/5.0 (compatible;
> MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_DENIED:NONE
> 172.20.4.33 -user at DOMAIN [16/Dec/2014:15:01:54 +0100] "CONNECT
> login.site.com:443 HTTP/1.0" 200 32958 "-" "Mozilla/5.0 (compatible;
> MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)" TCP_MISS:DIRECT
> 
> My squid.conf for completeness
> 
> acl manager proto cache_object
> acl localhost src 127.0.0.1/32 ::1
> acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
> 
> auth_param negotiate program /usr/lib/squid/squid_kerb_auth -i -s
> HTTP/proxy.domain.tld at DOMAIN.TLD
> auth_param negotiate children 10
> auth_param negotiate keep_alive on
> acl auth proxy_auth REQUIRED
> 
> auth_param basic program /usr/lib/squid/squid_ldap_auth -b
> dc=domain,dc=tld -f "samaccountname=%s" -s sub -D user -W
> /etc/squid/squid_ldap_bi
> nd -h dc1.domain.tld,dc2.domain.tld,dc3.domain.tld -p 3268 -Z
> auth_param basic children 10
> auth_param basic realm Proxy LDAP Authentication
> auth_param basic credentialsttl 8 hours
> 
> acl SSL_ports port 443
> acl SSL_ports port 1494
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Only allow cachemgr access from localhost
> http_access allow manager localhost
> http_access deny manager
> 
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> http_access allow localhost
> 
> http_access deny !auth
> http_access allow auth
> 
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 3128
> 
> # We recommend you to use at least the following line.
> hierarchy_stoplist cgi-bin ?
> 
> logformat combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
> "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
> access_log /var/log/squid/combined.log combined
> 
> Thanks in advance.
> 
> --
> Groeten,
> natxo
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

citrix sessions are not SSL sessions, so any bumping will need to exempt
the traffic from inspection.  citrix uses some encryption that is not
considered HTTPS/SSL

are you able to implement NTLM?  we dont run squid at work, but i do
force kerberos auth and fallback to ntlm when we have to.  none of the
users have issues with proxy auth in those cases.  not sure if kerberos
or ntlm auth is used.

are the raw citrix ports (1434 or whatever) being used, or is it being
tunneled over 443?  maybe you need to look at the SSL_PORTS list and add
the raw ports to the list.



From brett.lymn at baesystems.com  Tue Dec 16 22:54:21 2014
From: brett.lymn at baesystems.com (Brett Lymn)
Date: Wed, 17 Dec 2014 09:24:21 +1030
Subject: [squid-users] squid rotating between many ips
In-Reply-To: <54904299.6020502@treenet.co.nz>
References: <000001d0198c$ec779480$c566bd80$@netstream.ps>
 <54904299.6020502@treenet.co.nz>
Message-ID: <20141216225421.GB15234@baea.com.au>

On Wed, Dec 17, 2014 at 03:32:57AM +1300, Amos Jeffries wrote:
> 
> Yes, by combining these:
>  http://wiki.squid-cache.org/ConfigExamples/Strange/RotatingIPs
> http://wiki.squid-cache.org/Features/AclRandom
> 
> ... but what are you trying to do it for?
> 

Probably so he can enjoy the pain of dealing working around the sites
that build the source IP address into the authentication cookie.
Aggressively rotating through the proxies will cause problems with such
sites because they will see a different source IP and so the auth cookie
will no longer be valid at which point the site will force the user to
log in again.

-- 
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

    BAE Systems Australia Limited - Australian Company Number 008 423 005
    BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846
    BAE Systems Australia Logistics Pty Limited - Australian Company Number 086 228 864

Our registered office is Evans Building, Taranaki Road, Edinburgh Parks,
Edinburgh, South Australia, 5111. If the identity of the sending company is
not clear from the content of this email please contact the sender.

This email and any attachments may contain confidential and legally
privileged information.  If you are not the intended recipient, do not copy or
disclose its content, but please reply to this email immediately and highlight
the error to the sender and then immediately delete the message.



From windflower1201 at gmail.com  Wed Dec 17 09:52:07 2014
From: windflower1201 at gmail.com (Yu-Hsuan Liao)
Date: Wed, 17 Dec 2014 17:52:07 +0800
Subject: [squid-users] Skype bypass using ssl_bump peek
Message-ID: <CAGob8wDOf3aNWZF-Nb=67qLVCW5SaWa7AY=AhbsbXQFDxt3vKA@mail.gmail.com>

> Only if "skype_list" matches the TCP packet IP address (without rDNS
> being looked up) will the peek happen.

> I think you need to add at_step ACL test to peek always at step1, then
> do the other actions at step2 once SNI (domain name) is possibly
> available.

Hello Amos,

What if a non-SSL over 443 or a non-HTTP over SSL connections?
Skype voice connection seems an non standard SSL negotiation(Partial
Handshake),
is it possible revert to tunnel mode at steps to bypass connection?

Thx.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141217/f627b027/attachment.htm>

From squid3 at treenet.co.nz  Wed Dec 17 12:13:26 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Dec 2014 01:13:26 +1300
Subject: [squid-users] Skype bypass using ssl_bump peek
In-Reply-To: <CAGob8wDOf3aNWZF-Nb=67qLVCW5SaWa7AY=AhbsbXQFDxt3vKA@mail.gmail.com>
References: <CAGob8wDOf3aNWZF-Nb=67qLVCW5SaWa7AY=AhbsbXQFDxt3vKA@mail.gmail.com>
Message-ID: <54917366.6010000@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 17/12/2014 10:52 p.m., Yu-Hsuan Liao wrote:


The peek at step1 should be detecting that non-TLS/SSL is occuring.

For the non-HTTP over TLS/SSL... IF you bumped it Squid can still
fallback to tunnel I think, but a slower way than splice normally
would. A few people are indicating problems or weirdness with how
serverHello is handled so YMMV.


NP: this is all brand new complicated functionality and I'm not the
author/designer. So reality may differ a bit from what I understand of
it all.




As long as you are able to determine whether to do splice and Squid
has not yet auto-generated anything that got sent out, then you should
be able to.
 If Squid has sent anything over the wire that was generated by Squid
(bumping) the only choices left are continue with bump or reject/abort.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUkXM9AAoJELJo5wb/XPRjIy0H/A4alyGG/lNif60LcCWWKEI6
7+mCNz28b+q828gCTWfF7i93rd6s5qxkhmXDs5rnluJ+0nbxawpOfCoMeeKnQQU7
+GwmmeZFzrF0yh933Ck+A10aJVP40boC9U62B9BcH1gnKlVKshe8zl+ZIO0EHyRA
Af0yhYE/Lp5A4GKLgwTNnJmbQ2/eUZKfs86rF4bSXHJkc3ecObBnztTMV0b2xm4N
ypZyYDNCyoxm4QoD7qGbXYUxcwCV3U9rA0TZ+6tD8pDqGhqbggahvvtiM7ldSOco
bpO0Ttu0o4AIkLVpIRIfQfEgRGxFBaqgKuYGMHm8WcU719KCc2L7EFtpUxLFWEs=
=pApA
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Wed Dec 17 12:13:22 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Dec 2014 01:13:22 +1300
Subject: [squid-users] Skype bypass using ssl_bump peek
In-Reply-To: <CAGob8wDOf3aNWZF-Nb=67qLVCW5SaWa7AY=AhbsbXQFDxt3vKA@mail.gmail.com>
References: <CAGob8wDOf3aNWZF-Nb=67qLVCW5SaWa7AY=AhbsbXQFDxt3vKA@mail.gmail.com>
Message-ID: <54917362.5080202@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 17/12/2014 10:52 p.m., Yu-Hsuan Liao wrote:
>> Only if "skype_list" matches the TCP packet IP address (without 
>> rDNS being looked up) will the peek happen.
> 
>> I think you need to add at_step ACL test to peek always at
>> step1, then do the other actions at step2 once SNI (domain name)
>> is possibly available.
> 
> Hello Amos,
> 
> What if a non-SSL over 443 or a non-HTTP over SSL connections?

The peek at step1 should be detecting that non-TLS/SSL is occuring.

For the non-HTTP over TLS/SSL... IF you bumped it Squid can still
fallback to tunnel I think, but a slower way than splice normally
would. A few people are indicating problems or weirdness with how
serverHello is handled so YMMV.


NP: this is all brand new complicated functionality and I'm not the
author/designer. So reality may differ a bit from what I understand of
it all.


> Skype voice connection seems an non standard SSL 
> negotiation(Partial Handshake), is it possible revert to tunnel 
> mode at steps to bypass connection?
> 

As long as you are able to determine whether to do splice and Squid
has not yet auto-generated anything that got sent out, then you should
be able to.
 If Squid has sent anything over the wire that was generated by Squid
(bumping) the only choices left are continue with bump or reject/abort.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUkXNaAAoJELJo5wb/XPRj2awH/2o+zdYmKSht6T+4NnlexI4y
fKEY+9v1jP8+ugFzcpuEu9AeOLN8JZZf1lC+uVBeRDyZD7XGRiY4DuAW4dJle9Mk
ythFOp1WIU4JWa9+FjQv4fpR3ua1t5JljVfyHZRxXBOMZTYs9E9cMdE4wsCW5TBa
7P8dGpfHXKFDyJNhtJEZO2rG8w4cUiVn9L33ZBkYcysTeAQdZdc70jRdpJndLOiA
yeR8C7FGMtDyQ207QXIimrVhhas8gRWFn2bhG9i5JbCYzpS4TLb3XHQm1KUR+Kvn
V0aXkS576MuoJOb46LnQEznm7cL8AJeri7GYGo2FxwH2MWeGTmYoPEeIZ+jkikE=
=sRS7
-----END PGP SIGNATURE-----


From alexander.bubnov at bk.ru  Wed Dec 17 12:52:00 2014
From: alexander.bubnov at bk.ru (=?UTF-8?B?QWxleGFuZGVyIEJ1Ym5vdg==?=)
Date: Wed, 17 Dec 2014 15:52:00 +0300
Subject: [squid-users] =?utf-8?q?ICAP=3A_how_to_get_port_of_X-Client-IP?=
In-Reply-To: <549028BD.9020308@treenet.co.nz>
References: <1418389855.19761439@f356.i.mail.ru>
 <1418719742.490807966@f228.i.mail.ru>
 <549028BD.9020308@treenet.co.nz>
Message-ID: <1418820720.462876842@f405.i.mail.ru>




--
/BR, Alexander

Wed, 17 Dec 2014 01:42:37 +1300 ?? Amos Jeffries <squid3 at treenet.co.nz>:
>-----BEGIN PGP SIGNED MESSAGE-----
>Hash: SHA1
>
>On 16/12/2014 9:49 p.m., Alexander Bubnov wrote:
>> 
>> Hello Amos! Glad to get your answer!
>> 
>> 
>> 1. I have tried to use %>p specifier for adaptation_meta directive.
>> But it seems does not work that way I used it. I specified it in
>> squid.conf:
>> 
>> adaptation_meta X-CLIENT-SRCPORT %>p
>> 
>> I found that specifier ony in logformat. May be you mixed it up?
>
>We are generalizing the logformat tokens for use anywhere custom
>formats or strings might be configured. I was hoping that header value
>parameter had been updated already, but it seems not.
Excuse me. Saying updated do you mean implemented i.e. squid does not have that feature yet?

>
>
>> 
>> 2. About mapping port transparently. How does it help to get (at
>> least) mapped port number in ICAP?
>
>I dont know. You were pretty adamant that the (ephemeral) port Squid
>was receiving from was what you needed passed through, so I figured
>you had a use-case for it.
>
>> 
>> 3. I would like to track any software. Especially software which
>> use "User Agent" field not  legitimately or event does not fill it
>> at all.
>> 
>
>Thats possibly the answer to your Q#2.
>
>Amos
>-----BEGIN PGP SIGNATURE-----
>Version: GnuPG v2.0.22 (MingW32)
>
>iQEcBAEBAgAGBQJUkCi9AAoJELJo5wb/XPRjlhYIAK40g+UJ2jxSjYCQuDbwzdk/
>uamQVRYZr51bmrGbt61XDC88lq1g9b9zCR768VySbwWziMbQng0VXkS+pwY13BHC
>SzyTZ/9VHy8SQ7JOr81z6/aufspN1x3Ht8bSIP084ZtXvjAKKqQd0jawNUA+tU7W
>VtLq4/LRaNAs+U4mlUL8n/E643Qkx+qGUbIBEtebGN+m9Av+SwjBfxpR43qEaonW
>gCcDQU6UQM46CaTlqknW8CgkFfk7QfXQAJM+9Gkc1L/7Z5xIhxB45WcwuF/NEkwZ
>zS8fT1gva23JnSyIdm32JNQM2V4PXUs0D15/JcdqubQdn71xyh9RMIjtYThqBeo=
>=YKfQ
>-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141217/168d4c3c/attachment.htm>

From alexander.bubnov at bk.ru  Wed Dec 17 13:44:19 2014
From: alexander.bubnov at bk.ru (=?UTF-8?B?QWxleGFuZGVyIEJ1Ym5vdg==?=)
Date: Wed, 17 Dec 2014 16:44:19 +0300
Subject: [squid-users] =?utf-8?q?ICAP=3A_how_to_get_port_of_X-Client-IP?=
In-Reply-To: <1418820720.462876842@f405.i.mail.ru>
References: <1418389855.19761439@f356.i.mail.ru>
 <549028BD.9020308@treenet.co.nz>
 <1418820720.462876842@f405.i.mail.ru>
Message-ID: <1418823859.200462711@f389.i.mail.ru>

 It works on sqiud 3.5.0.2!!!

adaptation_meta X-Client-Port %>p

Exactly as you said. Many thanks to you Amos!

I am not sure about 3.4 version but it does not matter for me.

--
/BR, Alexander

Wed, 17 Dec 2014 15:52:00 +0300 ?? Alexander Bubnov <alexander.bubnov at bk.ru>:
>
>
>
>--
>/BR, Alexander
>
>Wed, 17 Dec 2014 01:42:37 +1300 ?? Amos Jeffries <squid3 at treenet.co.nz>:
>>-----BEGIN PGP SIGNED MESSAGE-----
>>Hash: SHA1
>>
>>On 16/12/2014 9:49 p.m., Alexander Bubnov wrote:
>>> 
>>> Hello Amos! Glad to get your answer!
>>> 
>>> 
>>> 1. I have tried to use %>p specifier for adaptation_meta directive.
>>> But it seems does not work that way I used it. I specified it in
>>> squid.conf:
>>> 
>>> adaptation_meta X-CLIENT-SRCPORT %>p
>>> 
>>> I found that specifier ony in logformat. May be you mixed it up?
>>
>>We are generalizing the logformat tokens for use anywhere custom
>>formats or strings might be configured. I was hoping that header value
>>parameter had been updated already, but it seems not.
>Excuse me. Saying updated do you mean implemented i.e. squid does not have that feature yet?
>
>>
>>
>>> 
>>> 2. About mapping port transparently. How does it help to get (at
>>> least) mapped port number in ICAP?
>>
>>I dont know. You were pretty adamant that the (ephemeral) port Squid
>>was receiving from was what you needed passed through, so I figured
>>you had a use-case for it.
>>
>>> 
>>> 3. I would like to track any software. Especially software which
>>> use "User Agent" field not  legitimately or event does not fill it
>>> at all.
>>> 
>>
>>Thats possibly the answer to your Q#2.
>>
>>Amos
>>-----BEGIN PGP SIGNATURE-----
>>Version: GnuPG v2.0.22 (MingW32)
>>
>>iQEcBAEBAgAGBQJUkCi9AAoJELJo5wb/XPRjlhYIAK40g+UJ2jxSjYCQuDbwzdk/
>>uamQVRYZr51bmrGbt61XDC88lq1g9b9zCR768VySbwWziMbQng0VXkS+pwY13BHC
>>SzyTZ/9VHy8SQ7JOr81z6/aufspN1x3Ht8bSIP084ZtXvjAKKqQd0jawNUA+tU7W
>>VtLq4/LRaNAs+U4mlUL8n/E643Qkx+qGUbIBEtebGN+m9Av+SwjBfxpR43qEaonW
>>gCcDQU6UQM46CaTlqknW8CgkFfk7QfXQAJM+9Gkc1L/7Z5xIhxB45WcwuF/NEkwZ
>>zS8fT1gva23JnSyIdm32JNQM2V4PXUs0D15/JcdqubQdn71xyh9RMIjtYThqBeo=
>>=YKfQ
>>-----END PGP SIGNATURE-----
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141217/7a9bf07d/attachment.htm>

From vdoctor at neuf.fr  Wed Dec 17 14:03:23 2014
From: vdoctor at neuf.fr (Stakres)
Date: Wed, 17 Dec 2014 06:03:23 -0800 (PST)
Subject: [squid-users] Squid 2.7,
 3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster
In-Reply-To: <1418628416193-4668707.post@n4.nabble.com>
References: <1418374260739-4668683.post@n4.nabble.com>
 <004501d01673$0f445150$2dccf3f0$@netstream.ps>
 <1418415837677-4668693.post@n4.nabble.com>
 <1418628416193-4668707.post@n4.nabble.com>
Message-ID: <1418825003303-4668738.post@n4.nabble.com>

Hi All,

New  build 2.17 <https://sourceforge.net/projects/squidvideosbooster/>  
with additional website...

Enjoy 

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraries-CDNs-Booster-tp4668683p4668738.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From sdreijer at microsoft.com  Wed Dec 17 17:25:39 2014
From: sdreijer at microsoft.com (Soren Madsen (DREIJER))
Date: Wed, 17 Dec 2014 17:25:39 +0000
Subject: [squid-users] Splicing a connection if server cert cannot be
 verified
In-Reply-To: <54903FC7.9020905@treenet.co.nz>
References: <BY2PR03MB364691B2198BC6B96D0E597D56F0@BY2PR03MB364.namprd03.prod.outlook.com>
 <548F403A.9040803@treenet.co.nz>
 <BY2PR03MB36452C552811D9EA7A09372D56F0@BY2PR03MB364.namprd03.prod.outlook.com>
 <54903FC7.9020905@treenet.co.nz>
Message-ID: <BY2PR03MB364CB522A2CDAFB73417400D56D0@BY2PR03MB364.namprd03.prod.outlook.com>

Hi Amos,

> > Yes, but Squid has no way of trusting a self-signed cert. When Squid
> > mints a server cert on the fly and sends it to the client, the client
> > won't have any idea that the cert was originally self-signed. Like the
> > previous scenario, I'd want to step out of the way and defer the
> > decision to the client.
> >
> 
> The global list of CAs which non-self-signed certs validate against is explicitly
> loaded into the SSL library. It is not a built-in list.
> 
> All you have to do to trust a "self-signed" cert is add the CA signing it to your
> trusted set.

I don't think you quite understand what I'm saying here. I can't run around and add new self-signed certs to Squid every time users discover broken sites; even worse, for SSLv3 connections, there's nothing "to add" that will fix future connections apart from permanently exempting the target site from bumping.

I want to bump connections ONLY when I can do so reliably, i.e. when I trust the server's cert and the connection is not SSLv3. In all other cases, I want to bail out and let the client decide what to do. The self-signed cert might be expected and trusted by the client depending on the target site. This way, my proxy isn't degrading connectivity for users and I get extra visibility into most connections by applying bumping opportunistically.
 
> >> AIUI, the basic problem that "precludes bumping" is that in order to
> >> peek at the serverHello some clientHello has to already have been
> >> sent. Squid is already locked into using the features advertised in
> >> that clientHello or dying - with no middle ground.
> >> Most times the client and Squid do not actually have identical
> >> capabilities so peeking the serverHello then either bump or splice
> >> actions will break depending on which clientHello Squid sent.
> >
> > I don't see why that is a problem if you just recreate the connection
> > to the server. That is, you first try bumping the connection by
> > sending a new clientHello to the server, and if the server cert cannot
> > be verified, a new connection is established and the original
> > clientHello is sent to the server.
> >
> 
> "just" recreating the connection to the server means discarding the old one.
> Which is not anywhere near as nice a proposition once you look beyond the
> single proxy.
> 
> The details, you can skip if you want to avoid...
> 
> * Each aborted connection means 15 minutes TCP TIME_WAIT delay before
> that TCP socket can be re-used.
> 
> * TCP/IP limits software to 63K sockets per IP address (64K total with
> 1024 reserved).
> 
> Using multiple outbound connections to discover some behaviour is what the
> browser "happy eyeballs" algoithm is all about. They are just looking for
> connectino handshake speed rather than cert properties.
> 
> - - Browsers are operating on rate of 10's to hundreds of single requests per
> minute. With all 64K per-IP sockets on that machine dedicated to the one
> end user.
> 
> - - Proxies are individually dealing with requests on the rate of 10's or 100's of
> thousand requests per minute. Sharing socets between hundreds or
> thousands of end-users.
> 
> At that speed 64K sockets per IP address are consumed very quickly already.
> Squid is limited to a very few over 10K new connections/minute per IP
> address on the machine. We get away with higher rates by having HITs,
> collapsed-forwarding and by multiplexing requests onto server connections.
>  => multiplex is the biggest gainer which is not possible with HTTPS traffic,
> despite bumping.

Like you just mentioned, Squid's clever socket sharing algorithms cannot be used for HTTPS traffic, so I don't quite understand the argument you're making here. If Squid has to terminate a connection because it doesn't trust the target server due to a bad cert, that connection will be subject to the TCP TIME_WAIT delay anyway. Squid might as well note the fact that the site is broken in a cache somewhere, so that the next time a connection is established to that same host, Squid won't try to bump the connection.

> It is a little bit safer to allow Squid to use SSLv3 to servers which are still
> broken, than to allow clients to SSLv3 to Squid. At least half of the
> connectivity you have soemthign to do with becomes trustworthy even
> though the overall end-2-end security is no better (yet).

Perhaps, but then again, not really. :) It gives the user a false sense of security when it looks like they are connected to a server with TLS 1.2 when half of the connection is in fact done over SSLv3.

Let me try to reset the conversation here a bit: 

Given my goal of opportunistically bumping connections and avoid degrading connectivity for the users of the proxy in cases where I can't successfully bump a connection, what would you do to achieve this?

Thanks,
Soren


From Bert at hubbsplace.org  Wed Dec 17 22:28:32 2014
From: Bert at hubbsplace.org (Bert)
Date: Wed, 17 Dec 2014 22:28:32 +0000
Subject: [squid-users] Debian 7 LDAP auth to 2008r2
Message-ID: <630C125872C12D42BAD1C9A726BA472D2B79FE46@WIN8.hubbsplace.org>

Man I just can't seem to make this work. I followed this guide:

http://wiki.bitbinary.com/index.php/Active_Directory_Integrated_Squid_Proxy

and everything went well but as soon as I get to the squid_ldap_group test I get nothing back, or the second time I hit enter it returns a "invalid entry" error.

/usr/lib/squid3/squid_ldap_group -R -K -S -b "dc=example,dc=local" -D squid at example.local -W /etc/squid3/ldappass.txt -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=Security Groups,ou=MyBusiness,dc=example,dc=local))" -h dc1.example.local EXAMPLE\Username Internet%20Users%20Standard

Can anyone tell me what to look for as far as testing? I have run this test with debug -d but that doesn't seem to return anything.
My understanding of the command above is it's taking the basedn and a user name that I have setup and created a password for and attempting to query the AD server that is listed after the -h option. The part of the line I don't understand is cn=%g. No idea what might be plugged in there as "g" is not initialized anywhere. Based on the options returned after squid_ldap_group I think I get what's going on and the last two entries on the line are the queried username against the security groups I created in AD and the user I have been testing is a member of the internet users group.
This seems pretty straight forward but I get nothing and so this query is basically the same in the squid.conf so if it doesn't work here it's obviously not going to work from a browser.





--
This message has been scanned by E.F.A. Project and is believed to be clean.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141217/765bf2d1/attachment.htm>

From rgelfand2 at gmail.com  Thu Dec 18 04:32:14 2014
From: rgelfand2 at gmail.com (Roman Gelfand)
Date: Wed, 17 Dec 2014 23:32:14 -0500
Subject: [squid-users] SQUID_ERR_SSL_HANDSHAKE
Message-ID: <CAJbW+rn3zt-OmFVuUP+oFw0ka5Gk7eenS_dwKceEYBRf3CrCRw@mail.gmail.com>

*The squid version is 3.4.5.  The server certificate is sslv3 generated by
openssl.  Not quite sure as to what the problem is.*


*Failed to establish a secure connection to 192.168.3.108*

The system returned:

(71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Handshake with SSL server failed: error:140770FC:SSL
routines:SSL23_GET_SERVER_HELLO:unknown protocol

This proxy and the remote host failed to negotiate a mutually acceptable
security settings for handling your request. It is possible that the remote
host does not support secure connections, or the proxy is not satisfied
with the host security credentials.




The ssl configuration is...

https_port 443 cert=/etc/ssl/certs/webfarm.crt
key=/etc/ssl/private/webfarm.key accel vport
options=NO_SSLv2:NO_TLSv1:CIPHER_SERVER_PREFERENCE
cipher=RC4:!MD5:!aNULL:!EDH

cache_peer 192.168.3.108 parent 80 0 no-query originserver login=PASS
front-end-https=on name=cmm2Server

acl cmm2 dstdomain [my domain]
cache_peer_access cmm2Server allow cmm2
never_direct allow cmm2

http_access allow cmm2
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141217/d3a13fb9/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 18 08:25:08 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Dec 2014 21:25:08 +1300
Subject: [squid-users] SQUID_ERR_SSL_HANDSHAKE
In-Reply-To: <CAJbW+rn3zt-OmFVuUP+oFw0ka5Gk7eenS_dwKceEYBRf3CrCRw@mail.gmail.com>
References: <CAJbW+rn3zt-OmFVuUP+oFw0ka5Gk7eenS_dwKceEYBRf3CrCRw@mail.gmail.com>
Message-ID: <54928F64.2080107@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 18/12/2014 5:32 p.m., Roman Gelfand wrote:
> *The squid version is 3.4.5.  The server certificate is sslv3
> generated by openssl.  Not quite sure as to what the problem is.*
> 

Problem 1: "The server certificate is sslv3"

A certficate has two things:
 * a format+data
 * a security key

Neither of these things is particularly attached to use on SSLv3
*protocol*, other than being defined there. The format used by all
protocols SSLv2 and later is self-descriptive, you should be able to
use it for secure TLS.

Did you mean cert format v3?


> 
> *Failed to establish a secure connection to 192.168.3.108*
> 
> The system returned:
> 
> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
> 
> Handshake with SSL server failed: error:140770FC:SSL 
> routines:SSL23_GET_SERVER_HELLO:unknown protocol
> 
> This proxy and the remote host failed to negotiate a mutually
> acceptable security settings for handling your request. It is
> possible that the remote host does not support secure connections,
> or the proxy is not satisfied with the host security credentials.
> 
> 

This seems to be *a* Squid generated error page BUT...

> 
> The ssl configuration is...
> 
> https_port 443 cert=/etc/ssl/certs/webfarm.crt 
> key=/etc/ssl/private/webfarm.key accel vport 
> options=NO_SSLv2:NO_TLSv1:CIPHER_SERVER_PREFERENCE 
> cipher=RC4:!MD5:!aNULL:!EDH
> 

Problem 2:

Squid-3 no longer impicitly enables "options=ALL". What that means is
that if you explicitly configure an options= or cipher= only what you
sepecifically configure there is available for use.
 Omitting those parameters entirely uses the OpenSSL libraries config
settings rather than "ALL".

Your proxy is presenting a very restricted set of ciphers. RC4 only,
with SSLv3, TLSv1.1, TLSv1.2 as protocol.


> cache_peer 192.168.3.108 parent 80 0 no-query originserver
> login=PASS front-end-https=on name=cmm2Server
> 
> acl cmm2 dstdomain [my domain] cache_peer_access cmm2Server allow
> cmm2 never_direct allow cmm2
> 
> http_access allow cmm2
> 

You have no TLS/SSL settings on this cache_peer. So Squid has no
reason to be using SSL/TLS to connect to it.

You don't mention any sslproxy_* settings so I cant be sure. But the
only way for your proxy to generate that page is for somethign like
https://192.168.3.108/ to be requested by the client and allowed
through your proxy.


Far more likely that it comes from some other proxy which does proper
securty checking and complaining about your https_port requirements.


My advice:
* see if your cert can be used over any of the TLS versions. Very
likely it can, especially as you are already offering to use it over
TLSv1.1 or TLSv1.2.

* update the proxy allowed ciphers to include some modern secure ones.
 - may require upgrading your OpenSSL library.

* If the cert really is tying you back see if you can get a
better/newer one.


Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUko9kAAoJELJo5wb/XPRj7QUH/3pFtmKow6VbcIkJ9s/grWhS
0qEAIeHKfrkkqTyCYReFOimj60NIS43ogrFjcVNxlbFx8jqQMKgVJsfont99/D20
h+R3mro7/4EVp8rJYqouKbx3qSWac4leB6wyBWHzKPg2sNTNWWqxfQA38kIAqm6C
+nhUHqrGvVfrdXybtYNj639alHZ7FkoDgw7Xy2CQfaSMMIx6FuJ/0zWH6zYddfWi
L4O7qth0HGpbwtzMwZiwyjEVHoVEKlQVFYSCQx1XjWNOpPSZHcJxO3QrTJ2NZRte
gq3IHXDBJIUBatCW4xMqXGjLTeHDE+L9obEstJdZWeWyXjD1UydfCWoTHKcJFWI=
=MUH8
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Thu Dec 18 09:01:44 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Dec 2014 22:01:44 +1300
Subject: [squid-users] Debian 7 LDAP auth to 2008r2
In-Reply-To: <630C125872C12D42BAD1C9A726BA472D2B79FE46@WIN8.hubbsplace.org>
References: <630C125872C12D42BAD1C9A726BA472D2B79FE46@WIN8.hubbsplace.org>
Message-ID: <549297F8.1030600@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 18/12/2014 11:28 a.m., Bert wrote:
> Man I just can't seem to make this work. I followed this guide:
> 
> http://wiki.bitbinary.com/index.php/Active_Directory_Integrated_Squid_Proxy
>
>
> 
and everything went well but as soon as I get to the
> squid_ldap_group test I get nothing back, or the second time I hit 
> enter it returns a "invalid entry" error.
> 
> /usr/lib/squid3/squid_ldap_group -R -K -S -b "dc=example,dc=local"
> -D squid at example.local -W /etc/squid3/ldappass.txt -f 
> "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=Security
>
> 
Groups,ou=MyBusiness,dc=example,dc=local))" -h dc1.example.local
> EXAMPLE\Username Internet%20Users%20Standard
> 
> Can anyone tell me what to look for as far as testing? I have run 
> this test with debug -d but that doesn't seem to return anything.
> My understanding of the command above is it's taking the basedn and
> a user name that I have setup and created a password for and
> attempting to query the AD server that is listed after the -h
> option. The part of the line I don't understand is cn=%g. No idea
> what might be plugged in there as "g" is not initialized anywhere.

%g is the group name being looked up.

acl .. external groupName1 groupName2 ...

> Based on the options returned after squid_ldap_group I think I get
> what's going on and the last two entries on the line are the
> queried username against the security groups I created in AD and
> the user I have been testing is a member of the internet users
> group. This seems pretty straight forward but I get nothing and so
> this query is basically the same in the squid.conf so if it doesn't
> work here it's obviously not going to work from a browser.
> 

The tutorial is a bit broken.

Firstly, it does not explain the "bug" causing group names to have to
be in files loaded by Squid external ACL is that the squid.conf parser
uses whitespace as reserved characters delimiting words.
The normal ACL syntax is:
  acl foo external memberof Group1Name Group2Name ...

It then recommends that -f parameter which contains whitespace
directly in squid.conf...


You need to replace "Security Groups" with "Security\ Groups" and if
that does not work by itself upgrade to a current Squid version.
Squid-3.4 or later should accept \-escapes in quoted strings.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUkpf3AAoJELJo5wb/XPRjLHAH/RhYmHXjlZFPPGzd02VpILIE
aVTacnsnauzQeLIUNH+EWjU5wCDN9byPE7kjC/h7yo3f1cirV2UIR7vw7s12SkVH
BWBNzdhNGe5uQsJ6al33USYKUeuVxdVhMJs6orJAQWzxgRK8xqktJFcDSivv+opN
5HmKXqBK4S1sXtGDzybu6lJzRC/ycZMAuDjT2Mbs5pF/Pw5eQd0KW9A5RE9DQT6q
HkCQl9B7HDhiYs0hMVVc7ayjcg//r+BVqI1Y5uEl+/AaUqkYjlQqiQG/Y+Ls2HrX
YIq2n6fzvrzSpE0drac7iyIM6RyGQ4Fh7LkCS8ae9mBNFI4nAZXYnldseReKVJA=
=e4Co
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Thu Dec 18 14:01:20 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 18 Dec 2014 20:01:20 +0600
Subject: [squid-users] Squid 3.4.10 incorrectly configured on Solaris 10
Message-ID: <5492DE30.5060209@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Hi there,

yesterday (and during last four day) I've try to build transparent
caching proxy on Solaris 10 (x86_64) testing environment.

Configuration options are:

# Without SSL 64 bit GCC
./configure '--prefix=/usr/local/squid' '--enable-translation'
'--enable-external-acl-helpers=file_userip,unix_group'
'--enable-icap-client' '--enable-ipf-transparent'
'--enable-storeio=diskd' '--enable-removal-policies=lru,heap'
'--enable-devpoll' '--disable-wccp' '--enable-wccpv2'
'--enable-http-violations' '--enable-follow-x-forwarded-for'
'--enable-arp-acl' '--enable-htcp' '--enable-cache-digests' '--with-dl'
'--enable-auth-negotiate=none' '--disable-auth-digest'
'--disable-auth-ntlm' '--disable-auth-basic'
'--enable-storeid-rewrite-helpers=file'
'--enable-log-daemon-helpers=file' '--with-filedescriptors=131072'
'--with-build-environment=POSIX_V6_LP64_OFF64' 'CFLAGS=-O3 -m64 -fPIE
-fstack-protector -mtune=core2 --param=ssp-buffer-size=4 -pipe'
'CXXFLAGS=-O3 -m64 -fPIE -fstack-protector -mtune=core2
--param=ssp-buffer-size=4 -pipe' 'CPPFLAGS=-I/usr/include
-I/opt/csw/include' 'LDFLAGS=-fPIE -pie -Wl,-z,now'

But binaries built without interceptor support.

Some investigation:

Config.log has errors with ip_nat.h compilation:

configure:27435: checking for netinet/ip_nat.h
configure:27435: g++ -c -m64 -O3 -m64 -fPIE -fstack-protector
-mtune=core2 --param=ssp-buffer-size=4 -pipe -march=native -std=c++11
-I/usr/include -I/opt/csw/include -I/usr/include/gssapi
-I/usr/include/kerberosv5 conftest.cpp >&5
In file included from conftest.cpp:266:0:
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:98:2:
error: 'ipfmutex_t' does not name a type
  ipfmutex_t nat_lock;
  ^
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:108:2:
error: 'frentry_t' does not name a type
  frentry_t *nat_fr; /* filter rule ptr if appropriate */
  ^
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:112:2:
error: 'ipftqent_t' does not name a type
  ipftqent_t nat_tqe;
  ^
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:113:2:
error: 'u_32_t' does not name a type
  u_32_t  nat_flags;
  ^
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:114:2:
error: 'u_32_t' does not name a type
  u_32_t  nat_sumd[2]; /* ip checksum delta for data segment */
  ^
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:115:2:
error: 'u_32_t' does not name a type
  u_32_t  nat_ipsumd; /* ip checksum delta for ip header */
  ^
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:116:2:
error: 'u_32_t' does not name a type
  u_32_t  nat_mssclamp; /* if != zero clamp MSS to this */
  ^
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:117:2:
error: 'i6addr_t' does not name a type
  i6addr_t nat_inip6;

and so, configure does not see IP Filter finally, ergo cannot build
interceptor.

Yes, IP Filter installed in system. Yes, I've try to build 32 bit also.
Yes, I've try to build on another system. Yes, I've try to play with
configure option. Yes, I've try also development version 3.5.x - with
the same result.

Amos, need your help.

Thanks in advance,

WBR, Yuri

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUkt4vAAoJENNXIZxhPexGn9EH/3CUqof3f4xHNBuZIhC35Zup
EgTYQGwUck0hq98GP+USC7C186qW3pscafTO82olbb55xb7Bpmw6b0YVgsVK9AJy
u2IFnc6MQe1rhYl8NM5L9B5XC6K5gKb8P4UQYAirYPvu0XDxWJYd0N8HqL+8uI6+
3OtvrGnQZyCOHTuQ8Ubu2y3yDpjdUhjX7sCRER8QiLR/IMTyXAu2pmIpMISLTMK+
wmI1xVfrafpg5TO+RzkwQFbWQhNUq1JqY6kttHb9D/Qg5eTw2ceFLYsrkTiuwpYv
czjRk2J4F7WYmbFJ0sTwRqyAZtM8xC8b9dk4SjkqOEpgIE/wdnqCJp/yQbfo/kk=
=LWVp
-----END PGP SIGNATURE-----




From gkinkie at gmail.com  Thu Dec 18 14:11:13 2014
From: gkinkie at gmail.com (Kinkie)
Date: Thu, 18 Dec 2014 15:11:13 +0100
Subject: [squid-users] Squid 3.4.10 incorrectly configured on Solaris 10
In-Reply-To: <5492DE30.5060209@gmail.com>
References: <5492DE30.5060209@gmail.com>
Message-ID: <CA+Y8hcMRjPL7OSk4Ug4kmGfnqQQtZns7b6mx12a7miDYOwTfZA@mail.gmail.com>

Hello Yuri,
  this is probably a system header dependency.
Could you check if the manuals mention anything about ipfmutex_t ? If
they do, at the beginning of the page they should include a list of
#include <...> lines. Could you copy-paste these lines here?

Thanks

On Thu, Dec 18, 2014 at 3:01 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Hi there,
>
> yesterday (and during last four day) I've try to build transparent
> caching proxy on Solaris 10 (x86_64) testing environment.
>
> Configuration options are:
>
> # Without SSL 64 bit GCC
> ./configure '--prefix=/usr/local/squid' '--enable-translation'
> '--enable-external-acl-helpers=file_userip,unix_group'
> '--enable-icap-client' '--enable-ipf-transparent'
> '--enable-storeio=diskd' '--enable-removal-policies=lru,heap'
> '--enable-devpoll' '--disable-wccp' '--enable-wccpv2'
> '--enable-http-violations' '--enable-follow-x-forwarded-for'
> '--enable-arp-acl' '--enable-htcp' '--enable-cache-digests' '--with-dl'
> '--enable-auth-negotiate=none' '--disable-auth-digest'
> '--disable-auth-ntlm' '--disable-auth-basic'
> '--enable-storeid-rewrite-helpers=file'
> '--enable-log-daemon-helpers=file' '--with-filedescriptors=131072'
> '--with-build-environment=POSIX_V6_LP64_OFF64' 'CFLAGS=-O3 -m64 -fPIE
> -fstack-protector -mtune=core2 --param=ssp-buffer-size=4 -pipe'
> 'CXXFLAGS=-O3 -m64 -fPIE -fstack-protector -mtune=core2
> --param=ssp-buffer-size=4 -pipe' 'CPPFLAGS=-I/usr/include
> -I/opt/csw/include' 'LDFLAGS=-fPIE -pie -Wl,-z,now'
>
> But binaries built without interceptor support.
>
> Some investigation:
>
> Config.log has errors with ip_nat.h compilation:
>
> configure:27435: checking for netinet/ip_nat.h
> configure:27435: g++ -c -m64 -O3 -m64 -fPIE -fstack-protector
> -mtune=core2 --param=ssp-buffer-size=4 -pipe -march=native -std=c++11
> -I/usr/include -I/opt/csw/include -I/usr/include/gssapi
> -I/usr/include/kerberosv5 conftest.cpp >&5
> In file included from conftest.cpp:266:0:
> /opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:98:2:
> error: 'ipfmutex_t' does not name a type
>   ipfmutex_t nat_lock;
>   ^
> /opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:108:2:
> error: 'frentry_t' does not name a type
>   frentry_t *nat_fr; /* filter rule ptr if appropriate */
>   ^
> /opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:112:2:
> error: 'ipftqent_t' does not name a type
>   ipftqent_t nat_tqe;
>   ^
> /opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:113:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_flags;
>   ^
> /opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:114:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_sumd[2]; /* ip checksum delta for data segment */
>   ^
> /opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:115:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_ipsumd; /* ip checksum delta for ip header */
>   ^
> /opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:116:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_mssclamp; /* if != zero clamp MSS to this */
>   ^
> /opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:117:2:
> error: 'i6addr_t' does not name a type
>   i6addr_t nat_inip6;
>
> and so, configure does not see IP Filter finally, ergo cannot build
> interceptor.
>
> Yes, IP Filter installed in system. Yes, I've try to build 32 bit also.
> Yes, I've try to build on another system. Yes, I've try to play with
> configure option. Yes, I've try also development version 3.5.x - with
> the same result.
>
> Amos, need your help.
>
> Thanks in advance,
>
> WBR, Yuri
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJUkt4vAAoJENNXIZxhPexGn9EH/3CUqof3f4xHNBuZIhC35Zup
> EgTYQGwUck0hq98GP+USC7C186qW3pscafTO82olbb55xb7Bpmw6b0YVgsVK9AJy
> u2IFnc6MQe1rhYl8NM5L9B5XC6K5gKb8P4UQYAirYPvu0XDxWJYd0N8HqL+8uI6+
> 3OtvrGnQZyCOHTuQ8Ubu2y3yDpjdUhjX7sCRER8QiLR/IMTyXAu2pmIpMISLTMK+
> wmI1xVfrafpg5TO+RzkwQFbWQhNUq1JqY6kttHb9D/Qg5eTw2ceFLYsrkTiuwpYv
> czjRk2J4F7WYmbFJ0sTwRqyAZtM8xC8b9dk4SjkqOEpgIE/wdnqCJp/yQbfo/kk=
> =LWVp
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From fredbmail at free.fr  Thu Dec 18 14:38:33 2014
From: fredbmail at free.fr (FredB)
Date: Thu, 18 Dec 2014 15:38:33 +0100 (CET)
Subject: [squid-users] Problem with digest authentification and
 credential backend
In-Reply-To: <1236837612.226735321.1418744552567.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <2022973553.230975209.1418913513817.JavaMail.root@zimbra4-e1.priv.proxad.net>

Patch for squid 3.5.0.3

| Tested with both nonce_count and nonce_max_duration, no problem. Do you known if it works with squid 3.5 ? 

Be careful chech_nonce_count is broken, you can see in your log that there are many unexpected 407, my advice is to set the value check_nonce_count to off
It's an old bug but fortunately it's transparent for users.

For me still two problems with digest:

1) chech_nonce_count -> but not annoying for me ...
2) smp aware -> http://bugs.squid-cache.org/show_bug.cgi?id=3517 because we can reduce the cpu load with smp


Amos, I can't post the patch in bugzilla: The function Bugzilla::Attachment->create requires a description argument, and that argument was not set 
I tried some different descriptions without more success (Firefox 34.0)

Regards,

Fred

http://numsys.eu
http://e2guardian.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: patch-3.5.patch
Type: text/x-patch
Size: 1861 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141218/6d4dd6a2/attachment.bin>

From hack.back at hotmail.com  Thu Dec 18 18:20:35 2014
From: hack.back at hotmail.com (HackXBack)
Date: Thu, 18 Dec 2014 10:20:35 -0800 (PST)
Subject: [squid-users] Error negotiating SSL connection
Message-ID: <1418926835993-4668748.post@n4.nabble.com>

2014/12/18 06:16:13 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 86: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:13 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 91: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:13 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 80: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:15 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 82: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:15 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 93: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:15 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 94: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:21 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 86: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:21 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 134: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:21 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 135: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:40 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 86: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:40 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 93: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:42 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 93: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:43 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 97:  error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:48 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 86: error:00000000:lib(0):func(0):reason(0) (5/0/0)
2014/12/18 06:16:48 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 93: error:00000000:lib(0):func(0):reason(0) (5/0/0)


https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
http_port  3129
http_port  3128 intercept

sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/squid/ssl_db/certs/ -M 4MB
sslcrtd_children 32 startup=30 idle=1

ssl_unclean_shutdown on
sslproxy_version 1
always_direct allow all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER



ssl_bump server-first all 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Error-negotiating-SSL-connection-tp4668748.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From redhoodny at gmail.com  Thu Dec 18 19:37:54 2014
From: redhoodny at gmail.com (Red)
Date: Thu, 18 Dec 2014 14:37:54 -0500
Subject: [squid-users] Unable to configure cache_dir with only TCP_MISS/200
Message-ID: <54932D12.6020802@gmail.com>

Using squid 3.3.8 on Ubuntu 14.04.
Copied default configuration file for version from
http://wiki.squid-cache.org/Squid-3.3, modified refresh pattern and acl to:

refresh_pattern .               1440       20%     4320
acl localnet src 129.236.0.0/16 

start squid, execute squidclient http://wiki.squid-cache.org/ twice, get expected responses:
1418930476.244    565 127.0.0.1 TCP_MISS/200 16286 GET http://wiki.squid-cache.org/ - HIER_DIRECT/77.93.254.178 text/html
1418930486.000      0 127.0.0.1 TCP_MEM_HIT/200 16293 GET http://wiki.squid-cache.org/ - HIER_NONE/- text/html

Tried to enable cache_dir, add line to config: 
cache_dir ufs /var/spool/squid3 100 16 256

Create  cache with sudo squid3 -z ; start squid, repeat above squidclient commands and get only TCP_MISS/200:

1418930731.778   5548 127.0.0.1 TCP_MISS/200 16286 GET http://wiki.squid-cache.org/ - HIER_DIRECT/77.93.254.178 text/html
1418930738.044    774 127.0.0.1 TCP_MISS/200 16286 GET http://wiki.squid-cache.org/ - HIER_DIRECT/77.93.254.178 text/html

Check cache dirs to see if any file has been create, and one is there:
$ sudo find /var/spool/squid3/ -type f -exec ls -l {} \;
-rw-r----- 1 proxy proxy 288 Dec 18 14:25 /var/spool/squid3/swap.state
-rw-r----- 1 proxy proxy 16393 Dec 18 14:25 /var/spool/squid3/00/00/00000001

Note: I have tried other pages which for sure do not have do not cache instructions with same result.

I have tried this on three different ubuntu machines, no luck.  BTW, more complex squid config we have with 3.1.19 on ubuntu 12 works fine.  Can not upgrade for now.
Any help is appreciated.


Bob
 




From rgelfand2 at gmail.com  Thu Dec 18 22:02:47 2014
From: rgelfand2 at gmail.com (Roman Gelfand)
Date: Thu, 18 Dec 2014 17:02:47 -0500
Subject: [squid-users] cache_peer configuration
Message-ID: <CAJbW+rnDE=+F2hURCQZtjJci0Gfw=_irasPyhZygFjd6qeMX+w@mail.gmail.com>

My goal is to accept ssl requests/connections from wan, decrypt them and
forward the decrypted requests/connection to apache web server over port
80.  Below, is my configuration to accomplish that.  However, it appears
that the requests/connections from squid to apache web server are
encrypted.  I am not sure why.  How do I make it decrypted?


https_port 443 cert=/etc/ssl/certs/webfarm.crt
key=/etc/ssl/private/webfarm.key accel vport options=ALL

cache_peer 192.168.3.108 parent 80 0 no-query originserver login=PASS
front-end-https=on name=cmm2Server

acl cmm2 dstdomain [my domain]
cache_peer_access cmm2Server allow cmm2
never_direct allow cmm2

http_access allow cmm2


Thanks in advance
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141218/5729cac0/attachment.htm>

From al.akchurin at hotmail.com  Thu Dec 18 23:32:51 2014
From: al.akchurin at hotmail.com (Eldar Akchurin)
Date: Fri, 19 Dec 2014 00:32:51 +0100
Subject: [squid-users] Problem with running squid 3.5 on windows 7
Message-ID: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>




 Hi,
I have cross-compiled squid 3.5 with mingw32-w64 on Ubuntu. The properties are:
c:\squid\sbin>squid -v
Squid Cache: Version 3.5.0.3-20141209-r13687
Service Name: squid
Test build
configure options:  '--host=i686-w64-mingw32' '--prefix=c:/squid' 'CXXFLAGS=-DWI
NVER=0x601 -D_WIN32_WINNT=0x601 -fpermissive' 'CFLAGS=-DWINVER=0x601 -D_WIN32_WI
NNT=0x601 -fpermissive' 'BUILDCXX=g++' 'BUILDCXXFLAGS=-DFOO' '--enable-build-inf
o=Test build' 'host_alias=i686-w64-mingw32' --enable-ltdl-convenience

When I try to run it on windows 7 64, it gives a critical error at start, below is the debug trace:c:\squid\sbin>squid.exe -X -f squid.conf
2014/12/19 00:17:40.101| debug.cc(403) parseOptions: command-line -X overrides:
ALL,7
2014/12/19 00:17:40.101| signal: sig=31 func=sigusr2_handle: (0) No error.
2014/12/19 00:17:40.101| cache_manager.cc(80) registerProfile: registering legac
y mem
2014/12/19 00:17:40.101| cache_manager.cc(114) findAction: CacheManager::findAct
ion: looking for action mem
2014/12/19 00:17:40.101| cache_manager.cc(122) findAction: Action not found.
2014/12/19 00:17:40.101| cache_manager.cc(65) registerProfile: registered profil
e: mem
2014/12/19 00:17:40.101| cache_manager.cc(80) registerProfile: registering legac
y squidaio_counts
2014/12/19 00:17:40.111| cache_manager.cc(114) findAction: CacheManager::findAct
ion: looking for action squidaio_counts
2014/12/19 00:17:40.111| cache_manager.cc(122) findAction: Action not found.
2014/12/19 00:17:40.121| cache_manager.cc(65) registerProfile: registered profil
e: squidaio_counts
2014/12/19 00:17:40.121| rock/RockStoreFileSystem.cc(50) setup: Will use Rock FS2014/12/19 00:17:40.121| Startup: Initializing Authentication Schemes ...
2014/12/19 00:17:40.121| Startup: Initialized Authentication Scheme 'basic'
2014/12/19 00:17:40.121| Startup: Initialized Authentication Scheme 'digest'
2014/12/19 00:17:40.121| Startup: Initialized Authentication Scheme 'negotiate'
2014/12/19 00:17:40.121| Startup: Initialized Authentication Scheme 'ntlm'
2014/12/19 00:17:40.121| Startup: Initialized Authentication.
2014/12/19 00:17:40.151| tools.cc(47) ProbeTransport: Detected IPv6 hybrid or v4
-mapping stack...
2014/12/19 00:17:40.151| tools.cc(61) ProbeTransport: IPv6 transport Enabled
2014/12/19 00:17:40.151| Config.cc(48) registerTokens:  register format tokens f
or 'adapt'
2014/12/19 00:17:40.151| Config.cc(48) registerTokens:  register format tokens f
or 'icap'
2014/12/19 00:17:40.151| cache_cf.cc(570) parseConfigFile:
2014/12/19 00:17:40.151| cf_parser.cci(4089) free_all:
2014/12/19 00:17:40.151| Acl.cc(396) Registered: ACL::Prototype::Registered: inv
oked for type src
2014/12/19 00:17:40.151| Acl.cc(400) Registered: ACL::Prototype::Registered:
yes
2014/12/19 00:17:40.151| Acl.cc(97) FindByName: ACL::FindByName 'all'
2014/12/19 00:17:40.151| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/12/19 00:17:40.151| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL
 'all'
2014/12/19 00:17:40.151| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning a
n object for type 'src'
2014/12/19 00:17:40.151| Ip.cc(233) FactoryParse: aclIpParseIpData: all
2014/12/19 00:17:40.161| Ip.cc(237) FactoryParse: aclIpParseIpData: magic 'all'
found.
2014/12/19 00:17:40.161| Acl.cc(396) Registered: ACL::Prototype::Registered: inv
oked for type url_regex
2014/12/19 00:17:40.161| Acl.cc(400) Registered: ACL::Prototype::Registered:
yes
2014/12/19 00:17:40.161| Acl.cc(97) FindByName: ACL::FindByName 'manager'
2014/12/19 00:17:40.161| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/12/19 00:17:40.161| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL
 'manager'
2014/12/19 00:17:40.161| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning a
n object for type 'url_regex'
2014/12/19 00:17:40.161| RegexData.cc(303) aclParseRegexList: aclParseRegexList:
 new Regex line or file
2014/12/19 00:17:40.161| RegexData.cc(311) aclParseRegexList: aclParseRegexList:
 buffering RE '-i'
2014/12/19 00:17:40.161| RegexData.cc(311) aclParseRegexList: aclParseRegexList:
 buffering RE '^cache_object://'
2014/12/19 00:17:40.161| RegexData.cc(311) aclParseRegexList: aclParseRegexList:
 buffering RE '+i'
2014/12/19 00:17:40.161| RegexData.cc(311) aclParseRegexList: aclParseRegexList:
 buffering RE '^https?://[^/]+/squid-internal-mgr/'
2014/12/19 00:17:40.161| RegexData.cc(194) compileOptimisedREs: compileOptimised
REs: -i
2014/12/19 00:17:40.161| RegexData.cc(218) compileOptimisedREs: compileOptimised
REs: adding RE '^cache_object://'
2014/12/19 00:17:40.161| RegexData.cc(208) compileOptimisedREs: compileOptimised
REs: +i
2014/12/19 00:17:40.161| RegexData.cc(153) compileRE: compileRE: compiled '(^cac
he_object://)' with flags 11
2014/12/19 00:17:40.171| RegexData.cc(218) compileOptimisedREs: compileOptimised
REs: adding RE '^https?://[^/]+/squid-internal-mgr/'
2014/12/19 00:17:40.171| RegexData.cc(153) compileRE: compileRE: compiled '(^htt
ps?://[^/]+/squid-internal-mgr/)' with flags 9
2014/12/19 00:17:40.171| RegexData.cc(261) compileOptimisedREs: compileOptimised
REs: 2 REs are optimised into one RE.
2014/12/19 00:17:40.171| Acl.cc(396) Registered: ACL::Prototype::Registered: inv
oked for type src
2014/12/19 00:17:40.171| Acl.cc(400) Registered: ACL::Prototype::Registered:
yes
2014/12/19 00:17:40.171| Acl.cc(97) FindByName: ACL::FindByName 'localhost'
2014/12/19 00:17:40.171| Acl.cc(103) FindByName: ACL::FindByName found no match
2014/12/19 00:17:40.171| Acl.cc(238) ParseAclLine: aclParseAclLine: Creating ACL
 'localhost'
2014/12/19 00:17:40.171| Acl.cc(432) Factory: ACL::Prototype::Factory: cloning a
n object for type 'src'
2014/12/19 00:17:40.171| Ip.cc(233) FactoryParse: aclIpParseIpData: 127.0.0.1/322014/12/19 00:17:40.171| Ip.cc(341) FactoryParse: aclIpParseIpData: '127.0.0.1/3
2' matched: SCAN3-v4: %[0123456789.]/%[0123456789.]
2014/12/19 00:17:40.171| Address.cc(379) lookupHostIP: Given Non-IP '127.0.0.1':
 No such host is known.
2014/12/19 00:17:40.171| aclIpParseIpData: unknown first address in '127.0.0.1/3
2'
2014/12/19 00:17:40.171| tools.cc(543) leave_suid: leave_suid: PID 4792 called
FATAL: Bungled Default Configuration line 6: acl localhost src 127.0.0.1/32 ::1
Squid Cache (Version 3.5.0.3-20141209-r13687): Terminated abnormally.
CPU Usage: 0.000 seconds = 0.000 user + 0.000 sys
Maximum Resident Size: 0 KB
Page faults with physical i/o: 0
Could you please advice what I'm doing wrong or whether this is a bug? Thank you!-eAdd to Calendar  
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141219/d2377a80/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec 19 03:08:03 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Dec 2014 16:08:03 +1300
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>
Message-ID: <54939693.3060102@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 19/12/2014 12:32 p.m., Eldar Akchurin wrote:
> 
> 
> 
> Hi, I have cross-compiled squid 3.5 with mingw32-w64 on Ubuntu. The
> properties are: c:\squid\sbin>squid -v Squid Cache: Version
> 3.5.0.3-20141209-r13687 Service Name: squid Test build configure
> options:  '--host=i686-w64-mingw32' '--prefix=c:/squid'
> 'CXXFLAGS=-DWI NVER=0x601 -D_WIN32_WINNT=0x601 -fpermissive'
> 'CFLAGS=-DWINVER=0x601 -D_WIN32_WI NNT=0x601 -fpermissive'
> 'BUILDCXX=g++' 'BUILDCXXFLAGS=-DFOO' '--enable-build-inf o=Test
> build' 'host_alias=i686-w64-mingw32' --enable-ltdl-convenience
> 
> When I try to run it on windows 7 64, it gives a critical error at
> start, below is the debug trace
<snip>


> 2014/12/19 00:17:40.171| Address.cc(379) lookupHostIP: Given Non-IP
> '127.0.0.1': No such host is known. 2014/12/19 00:17:40.171|
> aclIpParseIpData: unknown first address in '127.0.0.1/3 2' 
> 2014/12/19 00:17:40.171| tools.cc(543) leave_suid: leave_suid: PID
> 4792 called FATAL: Bungled Default Configuration line 6: acl
> localhost src 127.0.0.1/32 ::1 Squid Cache (Version
> 3.5.0.3-20141209-r13687): Terminated abnormally. CPU Usage: 0.000
> seconds = 0.000 user + 0.000 sys Maximum Resident Size: 0 KB Page
> faults with physical i/o: 0 Could you please advice what I'm doing
> wrong or whether this is a bug? Thank you!-eAdd to Calendar
> 

Thank you for testing this all out Eldar. It seems you have gotten a
little further than I have with this (I diverted to working on native
MinGW build issues).

This is a bug. Though where it is coming from is still unknown. The
operation being performed is that Squid is passing the IP text string
to the system getaddrinfo() resolver API for conversion to a number.

First thing to check is whether Squid is actually using the native OS
API or the stub replacement bundled in compat/. The config.log file
generated during build will have an entry indicating whether
getaddrinfo() was found or not in the MinGW headers. If the detection
failed there will be some debug info about what broke.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUk5aTAAoJELJo5wb/XPRjiLkIAL0nS83JZLdTV7DfMFsDFqRJ
yU7rFKWwqXp8P64K5Woedwga4JMpUrkxvbQ1t+wqS3mKWX3hJ72+M71juVeyt7pr
pMZYGkoSZNXwhh/i73BxH2hVX7lysI8WKUw0NgBW7cZYe7KleLIODf8GWQhmXhJi
vQh5uAfeYO6W/V+wwiRpY47H49yuU3UpypzsZ4P2i88+QvKZaef0T4ZJN8Wlresg
ldc7vwBTqQ7p810s87dUrYAuCYZJKqYj/cQnUX86dEgkfxZSPwbDHS8qQdUxAvMb
DqIZRp+H7hdO2DK1Sh1FCwyDEEbkuc0O/GurH6Nnw9IVpSAmWr4l8l82WdDXd4o=
=4unG
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Dec 19 03:26:46 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Dec 2014 16:26:46 +1300
Subject: [squid-users] Unable to configure cache_dir with only
	TCP_MISS/200
In-Reply-To: <54932D12.6020802@gmail.com>
References: <54932D12.6020802@gmail.com>
Message-ID: <54939AF6.9060107@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 19/12/2014 8:37 a.m., Red wrote:
> Using squid 3.3.8 on Ubuntu 14.04.

This is probably bug 3806. Which was fixed in 3.3.12 release.

Can you try an upgrade to 3.4 ?
The Debian Jesse/Testing package 3.4.8-* should work fine in Ubuntu 14.*

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUk5r2AAoJELJo5wb/XPRj7iAH/ij3XrL4iy+UClCb+vXhmORj
TnpKonk2pRwOyTh2Vhx0Kh69yRuX298W74dbB5VA93SmtBwpDORZbTWhuUUxlaCz
xFHCVKJ6LluVmqYlqmomq8KG8NwxzhNjMNtKWV4RI3q3rs+wCEwebF7m5DNVcdYY
bw+N+iJJzZEwbwDMa0orlxG18GazLV0/hryg2yFO/0h9SU5dpiyyjeh8bChRxRln
fb5Fg7CRsPX6t1Z8vSKR+Y2/xsQIfqRrKeNOcPGCzDgoq5VhS7CQVavV90nnmfA1
C4DbsyGgXOJAaAJ0tbZ0KuFISR5eudaX2cm9vT1vp/wjO7o14ero7yVX3uIDa/E=
=VKEV
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Fri Dec 19 09:17:36 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 19 Dec 2014 15:17:36 +0600
Subject: [squid-users] Squid 3.4.10 incorrectly configured on Solaris 10
In-Reply-To: <CA+Y8hcMRjPL7OSk4Ug4kmGfnqQQtZns7b6mx12a7miDYOwTfZA@mail.gmail.com>
References: <5492DE30.5060209@gmail.com>
 <CA+Y8hcMRjPL7OSk4Ug4kmGfnqQQtZns7b6mx12a7miDYOwTfZA@mail.gmail.com>
Message-ID: <5493ED30.3040201@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
I found,

from where legs grows.

The problems beguns from ip_compat.h:

configure:27435: checking for netinet/ip_compat.h
configure:27435: g++ -c -m64 -O3 -m64 -fPIE -fstack-protector
-mtune=core2 --param=ssp-buffer-size=4 -pipe -march=native -std=c++11
-I/usr/include -I/opt/csw/include
-I/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/
-I/usr/include/gssapi -I/usr/include/kerberosv5 conftest.cpp >&5
In file included from conftest.cpp:261:0:
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_compat.h:1094:14:
error: conflicting declaration 'typedef int minor_t'
 typedef int  minor_t;
              ^
In file included from conftest.cpp:211:0:
/usr/include/sys/types.h:303:16: note: previous declaration as 'typedef
uint_t minor_t'
 typedef uint_t minor_t; /* minor part of device number */
                ^
configure:27435: $? = 1
configure: failed program was:

Try to find workaround...

18.12.2014 20:11, Kinkie ?????:
> Hello Yuri,
>   this is probably a system header dependency.
> Could you check if the manuals mention anything about ipfmutex_t ? If
> they do, at the beginning of the page they should include a list of
> #include <...> lines. Could you copy-paste these lines here?
>
> Thanks
>
> On Thu, Dec 18, 2014 at 3:01 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>
> Hi there,
>
> yesterday (and during last four day) I've try to build transparent
> caching proxy on Solaris 10 (x86_64) testing environment.
>
> Configuration options are:
>
> # Without SSL 64 bit GCC
> ./configure '--prefix=/usr/local/squid' '--enable-translation'
> '--enable-external-acl-helpers=file_userip,unix_group'
> '--enable-icap-client' '--enable-ipf-transparent'
> '--enable-storeio=diskd' '--enable-removal-policies=lru,heap'
> '--enable-devpoll' '--disable-wccp' '--enable-wccpv2'
> '--enable-http-violations' '--enable-follow-x-forwarded-for'
> '--enable-arp-acl' '--enable-htcp' '--enable-cache-digests' '--with-dl'
> '--enable-auth-negotiate=none' '--disable-auth-digest'
> '--disable-auth-ntlm' '--disable-auth-basic'
> '--enable-storeid-rewrite-helpers=file'
> '--enable-log-daemon-helpers=file' '--with-filedescriptors=131072'
> '--with-build-environment=POSIX_V6_LP64_OFF64' 'CFLAGS=-O3 -m64 -fPIE
> -fstack-protector -mtune=core2 --param=ssp-buffer-size=4 -pipe'
> 'CXXFLAGS=-O3 -m64 -fPIE -fstack-protector -mtune=core2
> --param=ssp-buffer-size=4 -pipe' 'CPPFLAGS=-I/usr/include
> -I/opt/csw/include' 'LDFLAGS=-fPIE -pie -Wl,-z,now'
>
> But binaries built without interceptor support.
>
> Some investigation:
>
> Config.log has errors with ip_nat.h compilation:
>
> configure:27435: checking for netinet/ip_nat.h
> configure:27435: g++ -c -m64 -O3 -m64 -fPIE -fstack-protector
> -mtune=core2 --param=ssp-buffer-size=4 -pipe -march=native -std=c++11
> -I/usr/include -I/opt/csw/include -I/usr/include/gssapi
> -I/usr/include/kerberosv5 conftest.cpp >&5
> In file included from conftest.cpp:266:0:
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:98:2:
> error: 'ipfmutex_t' does not name a type
>   ipfmutex_t nat_lock;
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:108:2:
> error: 'frentry_t' does not name a type
>   frentry_t *nat_fr; /* filter rule ptr if appropriate */
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:112:2:
> error: 'ipftqent_t' does not name a type
>   ipftqent_t nat_tqe;
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:113:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_flags;
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:114:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_sumd[2]; /* ip checksum delta for data segment */
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:115:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_ipsumd; /* ip checksum delta for ip header */
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:116:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_mssclamp; /* if != zero clamp MSS to this */
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:117:2:
> error: 'i6addr_t' does not name a type
>   i6addr_t nat_inip6;
>
> and so, configure does not see IP Filter finally, ergo cannot build
> interceptor.
>
> Yes, IP Filter installed in system. Yes, I've try to build 32 bit also.
> Yes, I've try to build on another system. Yes, I've try to play with
> configure option. Yes, I've try also development version 3.5.x - with
> the same result.
>
> Amos, need your help.
>
> Thanks in advance,
>
> WBR, Yuri
>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUk+0vAAoJENNXIZxhPexGpXYIAJCALmyB6uEyUgiVEoG+Zgrc
rEMOdHeYrZuIQGs+ZNLng/lg7fC6gBTsYohJehFnsdVEwNMXoHPqT3aaxA7GwZc1
jxTBJco8qHPEQhZD/X6oKGL62YnMDb89pPVfsj8hMuF/ss3RVtHpth8UUKmg5slz
S23xJIMFJCnOXOK1UMUnw6+ntzIlX0+/Iho2/zlVADnLPgZs4BLpFbJ8PAhEuMVQ
AQjbqv7z7IVC3l2NzZpLc8QSyxW8subbxyaOXFl3F7Pk6Ky7UkC2M++zRjQLD4cQ
uz2JcAVwTHRpwkkJkNgI1sRTHHN03LZaq8Mk2gl7B39fkmOO1FM5qkPwvb2euBw=
=mbhU
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141219/7f9b31a2/attachment.htm>

From ahmed.zaeem at netstream.ps  Fri Dec 19 22:25:35 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Fri, 19 Dec 2014 14:25:35 -0800
Subject: [squid-users] You MUST specify at least one Domain Controller.You
	can use either \ or / as separator between the domain name
Message-ID: <001701d01bda$b676bdc0$23643940$@netstream.ps>

Hi guys im trygint to use Kerberos authentication between squid & AD.

I have configured ntp  , dns , winbind , samba and also joinf the squid to
the AD domina

 

Now the issue I have is running squid

I added the following helpers below :

 


#Kerberos config for squid

auth_param ntlm program /usr/lib/squid/ntlm_smb_lm_auth
--helper-protocol=squid-2.5-basic

auth_param ntlm children 10

auth_param basic program /usr/lib/squid/ntlm_smb_lm_auth
--helper-protocol=squid-2.5-basic

auth_param basic children 5

auth_param basic realm Domain Proxy Server

auth_param basic credentialsttl 2 hours

auth_param basic casesensitive off

authenticate_cache_garbage_interval 10 seconds

authenticate_ttl 0 seconds

acl lcl src 192.168.1.0/24

acl auth proxy_auth REQUIRED

http_access allow auth

 

 

And I have the errors below :


You MUST specify at least one Domain Controller.

You can use either \ or / as separator between the domain name 

and the controller name

(ntlm_smb_lm_auth): invalid option -- 's'

unknown option: -?. Exiting

(ntlm_smb_lm_auth) usage:

(ntlm_smb_lm_auth) [-b] [-f] [-d] [-l] domain\controller [domain\controller
...]

-b enables load-balancing among controllers

-f enables failover among controllers (DEPRECATED and always active)

-l changes behavior on domain controller failyures to last-ditch.

-d enables debugging statements if DEBUG was defined at build-time.

 

You MUST specify at least one Domain Controller.

You can use either \ or / as separator between the domain name 

and the controller name

(ntlm_smb_lm_auth): invalid option -- 'i'

unknown option: -?. Exiting

(ntlm_smb_lm_auth) usage:

(ntlm_smb_lm_auth) [-b] [-f] [-d] [-l] domain\controller [domain\controller
...]

-b enables load-balancing among controllers

-f enables failover among controllers (DEPRECATED and always active)

-l changes behavior on domain controller failyures to last-ditch.

-d enables debugging statements if DEBUG was defined at build-time.

 

You MUST specify at least one Domain Controller.

You can use either \ or / as separator between the domain name 

and the controller name

(ntlm_smb_lm_auth): invalid option -- 'c'

unknown option: -?. Exiting

(ntlm_smb_lm_auth) usage:

(ntlm_smb_lm_auth) [-b] [-f] [-d] [-l] domain\controller [domain\controller
...]

-b enables load-balancing among controllers

-f enables failover among controllers (DEPRECATED and always active)

-l changes behavior on domain controller failyures to last-ditch.

-d enables debugging statements if DEBUG was defined at build-time.

 

You MUST specify at least one Domain Controller.

You can use either \ or / as separator between the domain name 

and the controller name

2014/12/19 07:22:52| Local cache digest enabled; rebuild/rewrite every
3600/3600 sec

2014/12/19 07:22:52| Store logging disabled

2014/12/19 07:22:52| Swap maxSize 0 + 262144 KB, estimated 20164 objects

2014/12/19 07:22:52| Target number of buckets: 1008

2014/12/19 07:22:52| Using 8192 Store buckets

2014/12/19 07:22:52| Max Mem  size: 262144 KB

2014/12/19 07:22:52| Max Swap size: 0 KB

2014/12/19 07:22:52| Using Least Load store dir selection

2014/12/19 07:22:52| Set Current Directory to /var/spool/squid

2014/12/19 07:22:52| Loaded Icons.

2014/12/19 07:22:52| Accepting  HTTP connections at [::]:3128, FD 45.

2014/12/19 07:22:52| HTCP Disabled.

2014/12/19 07:22:52| Squid plugin modules loaded: 0

2014/12/19 07:22:52| Adaptation support is off.

2014/12/19 07:22:52| Ready to serve requests.

2014/12/19 07:22:52| WARNING: ntlmauthenticator #1 (FD 10) exited

2014/12/19 07:22:52| WARNING: ntlmauthenticator #2 (FD 12) exited

2014/12/19 07:22:52| WARNING: ntlmauthenticator #3 (FD 14) exited

2014/12/19 07:22:52| WARNING: ntlmauthenticator #4 (FD 16) exited

2014/12/19 07:22:52| WARNING: ntlmauthenticator #5 (FD 18) exited

2014/12/19 07:22:52| Too few ntlmauthenticator processes are running

2014/12/19 07:22:52| storeDirWriteCleanLogs: Starting...

2014/12/19 07:22:52|   Finished.  Wrote 0 entries.

2014/12/19 07:22:52|   Took 0.00 seconds (  0.00 entries/sec).

FATAL: The ntlmauthenticator helpers are crashing too rapidly, need help!

 

Squid Cache (Version 3.1.10): Terminated abnormally.

CPU Usage: 0.044 seconds = 0.023 user + 0.021 sys

Maximum Resident Size: 37216 KB

Page faults with physical i/o: 0

Memory usage for squid via mallinfo():

        total space in arena:    3188 KB

        Ordinary blocks:         3068 KB     20 blks

        Small blocks:               0 KB      0 blks

        Holding blocks:          1012 KB      4 blks

        Free Small blocks:          0 KB

        Free Ordinary blocks:     119 KB

        Total in use:            4080 KB 128%

        Total free:               119 KB 4%

 

 

Imusing  centos 6.x wth squid verison as :


[root at drvirus ~]# squid -v

Squid Cache: Version 3.1.10

configure options:  '--build=i386-redhat-linux-gnu'
'--host=i386-redhat-linux-gnu' '--target=i686-redhat-linux-gnu'
'--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin'
'--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share'
'--includedir=/usr/include' '--libdir=/usr/lib' '--libexecdir=/usr/libexec'
'--sharedstatedir=/var/lib' '--mandir=/usr/share/man'
'--infodir=/usr/share/info' '--enable-internal-dns'
'--disable-strict-error-checking' '--exec_prefix=/usr'
'--libexecdir=/usr/lib/squid' '--localstatedir=/var'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--with-logdir=$(localstatedir)/log/squid'
'--with-pidfile=$(localstatedir)/run/squid.pid'
'--disable-dependency-tracking' '--enable-arp-acl'
'--enable-follow-x-forwarded-for'
'--enable-auth=basic,digest,ntlm,negotiate'
'--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain
-NTLM,SASL,DB,POP3,squid_radius_auth'
'--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth'
'--enable-digest-auth-helpers=password,ldap,eDirectory'
'--enable-negotiate-auth-helpers=squid_kerb_auth'
'--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_
group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
'--enable-ident-lookups' '--with-large-files' '--enable-linux-netfilter'
'--enable-referer-log' '--enable-removal-policies=heap,lru' '--enable-snmp'
'--enable-ssl' '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log'
'--enable-wccpv2' '--enable-esi' '--with-aio' '--with-default-user=squid'
'--with-filedescriptors=16384' '--with-dl' '--with-openssl'
'--with-pthreads' 'build_alias=i386-redhat-linux-gnu'
'host_alias=i386-redhat-linux-gnu' 'target_alias=i686-redhat-linux-gnu'
'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
-fstack-protector --param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom
-fasynchronous-unwind-tables -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g -pipe
-Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom
-fasynchronous-unwind-tables -fpie'
--with-squid=/builddir/build/BUILD/squid-3.1.10

[root at drvirus ~]#

 

 

 

 

Any help wts going on ???

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141219/1299ca83/attachment.htm>

From vrogoziansky.squid at gmail.com  Fri Dec 19 12:29:16 2014
From: vrogoziansky.squid at gmail.com (Vadim Rogoziansky)
Date: Fri, 19 Dec 2014 14:29:16 +0200
Subject: [squid-users] Transparent proxy with Peek and Splice feature.
In-Reply-To: <547948CF.5040408@treenet.co.nz>
References: <5474C8CF.6030404@gmail.com> <54759E6C.5080404@treenet.co.nz>
 <54772BB5.5010101@gmail.com> <547948CF.5040408@treenet.co.nz>
Message-ID: <54941A1C.90702@gmail.com>

Any ideas, any thoughts?
Thanks.


11/29/2014 6:17 AM, Amos Jeffries ???????(??):
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 28/11/2014 2:48 a.m., Vadim Rogoziansky wrote:
>> Hello Amos.
>>
>> Thank you for answer.
>>
>> There was made an investigation related to squid's peek and splice
>> issues in transparent mode. One-line explanation is as follows - in
>> intercept mode squid can't get a server host name from the request
>> header and uses clent IP address instead for both fake cert
>> generation and as a SNI record in server bump SSL handshaking. This
>> is the root of the problem. However this can be fixed if squid uses
>> SNI field taken from client TLS Hello message for that purposes.
>> Can you hack squid in this way? What do you think?
> I think peek-n-splice is supposed to already be doing that.
>
> However it does depend on whether you are bumping the connection at
> step 1 (before ClientHello), step 2 (after ClientHello, before
> ServerHello), or step 3 (after both ClientHello and ServerHello) of
> the TLS handshake whether the SNI details are present.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUeUjPAAoJELJo5wb/XPRj6QEIAOHrR8wmDcjkfgUh2UtPwpHP
> vVkPMEuIrUq9Gxx3uSojCZjlFJPuCQ2UafS1p8LuxcEQ+TRmUFbAu4AkKoO2RoZ5
> 7fCGoiXTwn4TzFf0pLh9SPBq9j12OJ3uT28EEqbILrT0sbKP02xK/qiJfCLR61Ev
> vprAdggapbKg/ns1l1H3BBgZR2A4W/abQPIq6/Eu/r+7nYK6L2oOdqPDWTJjudMV
> 8D9sdOD9mYYryrdptU0GLh9Q/V5QEhipSkuA936iZ0Dfa2ZSr4gphJyaRAFWSMf3
> q502lZy+ASkDa2vAbjALRBgn3VwYWl8KBQcypUKF4UXtaLtF0EIrLMun+p4QxUM=
> =44aG
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Dec 19 13:01:15 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 02:01:15 +1300
Subject: [squid-users] You MUST specify at least one Domain
 Controller.You can use either \ or / as separator between the domain name
In-Reply-To: <001701d01bda$b676bdc0$23643940$@netstream.ps>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
Message-ID: <5494219B.2010708@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 11:25 a.m., Ahmed Allzaeem wrote:
> Hi guys im trygint to use Kerberos authentication between squid &
> AD.
> 
> I have configured ntp  , dns , winbind , samba and also joinf the
> squid to the AD domina
> 
> 
> 
> Now the issue I have is running squid
> 
> I added the following helpers below :
> 
> 
> 
> 
> #Kerberos config for squid
> 
> auth_param ntlm program /usr/lib/squid/ntlm_smb_lm_auth

This is *not* the Samba NTLM helper. This helper does not even perform
NTLMv1. It performs LM protocol (used for authenticating against
Windows 3.1 servers) using HTTP "NTLM" auth scheme headers.


> --helper-protocol=squid-2.5-basic

This is a command line parameter for the Samba ntlm_auth helper.

The samba helper still uses the name ntlm_auth. It is probably located
in /usr/bin/ or /usr/local/bin/.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlCGbAAoJELJo5wb/XPRj1awIAI0+646wnDRvjed2bSw7Cote
9tIBA0j7VLF0wcWx1HLpViLhatq2ep7S/isz0pkGwUgcX3w20f1sXfuM3MbdGYH6
Gh3lRCsOaXqRhIQY80pNjfQKs75oGn8Zelqlm3DmJjxCcFLOtj/5Du1CASquajJ5
26T11+HZ9EJ4rwG+LXN3nAXRjcoEGdIt09VmiCLGukHN1FvkFo7Ms0CR0i7urTYD
IQUI4uoObQJVq+vY9gJyzhyEdWJqvK9Q1fM7fUptCcaIGMhkM70Ue8RLu4YUWH82
GzXTf+Hdt7zfnyq0ALusvGOiXyQ3UFcYRfijBuhfEAjPd2Vr2F/7oCoGueieFb8=
=48pC
-----END PGP SIGNATURE-----


From squid at bloms.de  Fri Dec 19 13:08:19 2014
From: squid at bloms.de (Dieter Bloms)
Date: Fri, 19 Dec 2014 14:08:19 +0100
Subject: [squid-users] Squid doesn't do a fallback from ipv6 to ipv4,
 if the ipv6 connect fails
In-Reply-To: <5488764E.4020506@treenet.co.nz>
References: <20141208154825.GB9584@bloms.de> <5488764E.4020506@treenet.co.nz>
Message-ID: <20141219130819.GA20800@bloms.de>

Hello Amos,

thank you for the reply.

On Thu, Dec 11, Amos Jeffries wrote:

> > we use squid 3.4.9 as proxy for our company with ipv4 and ipv6
> > dual stack. It works good, but if a destination has an A and AAAA
> > record and the webserver isn't reachable via ipv6, squid generates
> > an error page instead of trying a connection via ipv4.
> > 
> > One example is the url:
> > 
> > https://ssl.ratsinfo-online.net/pirna-ri/logon.asp
> > 
> > where squid tries to reach the webside via the ip 
> > 2001:8d8:87c:5f00::6e:72d6, but without success, because it isn't 
> > reachable.
> > 
> > Now I want, that squid does a fallback to ipv4 after
> > connect_timeout, but squid returns an error page (ERR_CONNECT_FAIL)
> > to the client.
> > 
> 
> Squid rarely sees https:// URLs like that. Check if it is being given
> the server name in a way that it can lookup all IPs, or just the one
> IP address.

in my squidlogs I see a line like:

Fri Dec 19 13:49:18 2014   4789 10.252.16.100 TCP_MISS/503 0 CONNECT ssl.ratsinfo-online.net:443 - HIER_NONE/- -

So I think squid gets the hostname instead of an ip address.

> It also depends on how long the connection attempt(s) take.
>  If it takes longer to lookup the DNS (dns_timeout) and try that one
> IP (connect_timeout * connect_retries) than the entire transaction is
> permitted to use (forward_timeout), then there is of course no time to
> try anything else.

when I do a "host ssl.ratsinfo-online.net" on the server where squid
runs I get the Ipv4 and the Ipv6 immediately.

I didn't set any of the parameters forward_timeout, connect_timeout,
connect_retries.

> Note also that the message in the ERR_CONNECT_FAIL page is the result
> of the final attempt made. Squid may have made several connection
> attempts to other IP which also failed.

for a http connections, the fallback to ipv4 works, but not for a https connection.

The web server ssl.ratsinfo-online.net listens on port 80 for http and
on port 443 for https.

When I do a http://ssl.ratsinfo-online.net/ the fallback from ipv6 to
ipv4 works fine, but when I do a https://ssl.ratsinfo-online.net/ squid tries
ipv6 only and doesn't do a fallback to ipv4.

I would be nice, if you can try it on your dial stack setup.

Thank you.

-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From ahmed.zaeem at netstream.ps  Fri Dec 19 23:13:28 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Fri, 19 Dec 2014 15:13:28 -0800
Subject: [squid-users] You MUST specify at least one Domain
	Controller.You can use either \ or / as separator between the
	domain name
In-Reply-To: <5494219B.2010708@treenet.co.nz>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
 <5494219B.2010708@treenet.co.nz>
Message-ID: <002101d01be1$677b74c0$36725e40$@netstream.ps>

HI amos , thanks for clarification , 
Actually I modified it with the correct samba path with ==> /usr/bin/ntlm_auth whereas I checked and found that helper !


So , my squid config  file to  :
=======
##Kerberos config for squid
auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic
auth_param ntlm children 10
auth_param basic program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic
auth_param basic children 5
auth_param basic realm Domain Proxy Server
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off
authenticate_cache_garbage_interval 10 seconds
authenticate_ttl 0 seconds
acl lcl src 192.168.1.0/24
acl auth proxy_auth REQUIRED
http_access allow auth
====================



But I have an error below :
=======================
2014/12/19 08:11:00|   Took 0.00 seconds (  0.00 entries/sec).
FATAL: authenticateNTLMHandleReply: *** Unsupported helper response ***, 'ERR'

Squid Cache (Version 3.1.10): Terminated abnormally.
CPU Usage: 0.047 seconds = 0.022 user + 0.025 sys
Maximum Resident Size: 37904 KB
Page faults with physical i/o: 0
Memory usage for squid via mallinfo():
        total space in arena:    3192 KB
        Ordinary blocks:         3105 KB     15 blks
        Small blocks:               0 KB      0 blks
        Holding blocks:          1012 KB      4 blks
        Free Small blocks:          0 KB
        Free Ordinary blocks:      86 KB
        Total in use:            4117 KB 129%
        Total free:                86 KB 3%
2014/12/19 08:11:03| Starting Squid Cache version 3.1.10 for i386-redhat-linux-gnu...
2014/12/19 08:11:03| Process ID 7571
2014/12/19 08:11:03| With 1024 file descriptors available
2014/12/19 08:11:03| Initializing IP Cache...
2014/12/19 08:11:03| DNS Socket created at [::], FD 8
2014/12/19 08:11:03| DNS Socket created at 0.0.0.0, FD 9
2014/12/19 08:11:03| Adding nameserver 192.168.1.242 from /etc/resolv.conf
2014/12/19 08:11:03| Adding nameserver 199.85.126.20 from /etc/resolv.conf
2014/12/19 08:11:03| helperOpenServers: Starting 10/10 'ntlm_auth' processes
2014/12/19 08:11:03| helperOpenServers: Starting 5/5 'ntlm_auth' processes
2014/12/19 08:11:03| User-Agent logging is disabled.
2014/12/19 08:11:03| Referer logging is disabled.
2014/12/19 08:11:04| Unlinkd pipe opened on FD 44
2014/12/19 08:11:04| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2014/12/19 08:11:04| Store logging disabled
2014/12/19 08:11:04| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2014/12/19 08:11:04| Target number of buckets: 1008
2014/12/19 08:11:04| Using 8192 Store buckets
2014/12/19 08:11:04| Max Mem  size: 262144 KB
2014/12/19 08:11:04| Max Mem  size: 262144 KB
2014/12/19 08:11:04| Max Swap size: 0 KB
2014/12/19 08:11:04| Using Least Load store dir selection
2014/12/19 08:11:04| Set Current Directory to /var/spool/squid
2014/12/19 08:11:04| Loaded Icons.
2014/12/19 08:11:04| Accepting  HTTP connections at [::]:3128, FD 45.
2014/12/19 08:11:04| HTCP Disabled.
2014/12/19 08:11:04| Squid plugin modules loaded: 0
2014/12/19 08:11:04| Adaptation support is off.
2014/12/19 08:11:04| Ready to serve requests.
2014/12/19 08:11:04| Adaptation support is off.
2014/12/19 08:11:04| Ready to serve requests.
2014/12/19 08:11:04| storeDirWriteCleanLogs: Starting...
2014/12/19 08:11:04|   Finished.  Wrote 0 entries.
2014/12/19 08:11:04|   Took 0.00 seconds (  0.00 entries/sec).
2014/12/19 08:11:04|   Took 0.00 seconds (  0.00 entries/sec).
FATAL: authenticateNTLMHandleReply: *** Unsupported helper response ***, 'ERR'

Squid Cache (Version 3.1.10): Terminated abnormally.
CPU Usage: 0.040 seconds = 0.027 user + 0.013 sys
Maximum Resident Size: 38976 KB
Page faults with physical i/o: 0
Memory usage for squid via mallinfo():
        total space in arena:    5120 KB
        Ordinary blocks:         4105 KB     13 blks
        Small blocks:               0 KB      0 blks
        Holding blocks:             0 KB      0 blks
        Free Small blocks:          0 KB
        Free Ordinary blocks:    1014 KB
        Total in use:            4105 KB 80%
        Total free:              1014 KB 20%
2014/12/19 08:11:07| Starting Squid Cache version 3.1.10 for i386-redhat-linux-gnu...
2014/12/19 08:11:07| Process ID 7589
2014/12/19 08:11:07| With 1024 file descriptors available
2014/12/19 08:11:07| Initializing IP Cache...
2014/12/19 08:11:07| DNS Socket created at [::], FD 8
2014/12/19 08:11:07| DNS Socket created at 0.0.0.0, FD 9
2014/12/19 08:11:07| Adding nameserver 192.168.1.242 from /etc/resolv.conf
2014/12/19 08:11:07| Adding nameserver 199.85.126.20 from /etc/resolv.conf
2014/12/19 08:11:07| helperOpenServers: Starting 10/10 'ntlm_auth' processes
2014/12/19 08:11:07| helperOpenServers: Starting 5/5 'ntlm_auth' processes
2014/12/19 08:11:07| User-Agent logging is disabled.
2014/12/19 08:11:07| Referer logging is disabled.
2014/12/19 08:11:07| Unlinkd pipe opened on FD 44
2014/12/19 08:11:07| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2014/12/19 08:11:07| Store logging disabled
2014/12/19 08:11:07| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2014/12/19 08:11:07| Target number of buckets: 1008
2014/12/19 08:11:07| Using 8192 Store buckets
2014/12/19 08:11:07| Max Mem  size: 262144 KB
2014/12/19 08:11:07| Max Swap size: 0 KB
2014/12/19 08:11:07| Using Least Load store dir selection
2014/12/19 08:11:07| Set Current Directory to /var/spool/squid
2014/12/19 08:11:07| Loaded Icons.
2014/12/19 08:11:07| Accepting  HTTP connections at [::]:3128, FD 45.
2014/12/19 08:11:07| HTCP Disabled.
2014/12/19 08:11:07| Squid plugin modules loaded: 0
2014/12/19 08:11:07| Adaptation support is off.
2014/12/19 08:11:07| Ready to serve requests.
2014/12/19 08:11:08| storeLateRelease: released 0 objects
^C
==============================================

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, December 19, 2014 5:01 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] You MUST specify at least one Domain Controller.You can use either \ or / as separator between the domain name

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 11:25 a.m., Ahmed Allzaeem wrote:
> Hi guys im trygint to use Kerberos authentication between squid & AD.
> 
> I have configured ntp  , dns , winbind , samba and also joinf the 
> squid to the AD domina
> 
> 
> 
> Now the issue I have is running squid
> 
> I added the following helpers below :
> 
> 
> 
> 
> #Kerberos config for squid
> 
> auth_param ntlm program /usr/lib/squid/ntlm_smb_lm_auth

This is *not* the Samba NTLM helper. This helper does not even perform NTLMv1. It performs LM protocol (used for authenticating against Windows 3.1 servers) using HTTP "NTLM" auth scheme headers.


> --helper-protocol=squid-2.5-basic

This is a command line parameter for the Samba ntlm_auth helper.

The samba helper still uses the name ntlm_auth. It is probably located in /usr/bin/ or /usr/local/bin/.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlCGbAAoJELJo5wb/XPRj1awIAI0+646wnDRvjed2bSw7Cote
9tIBA0j7VLF0wcWx1HLpViLhatq2ep7S/isz0pkGwUgcX3w20f1sXfuM3MbdGYH6
Gh3lRCsOaXqRhIQY80pNjfQKs75oGn8Zelqlm3DmJjxCcFLOtj/5Du1CASquajJ5
26T11+HZ9EJ4rwG+LXN3nAXRjcoEGdIt09VmiCLGukHN1FvkFo7Ms0CR0i7urTYD
IQUI4uoObQJVq+vY9gJyzhyEdWJqvK9Q1fM7fUptCcaIGMhkM70Ue8RLu4YUWH82
GzXTf+Hdt7zfnyq0ALusvGOiXyQ3UFcYRfijBuhfEAjPd2Vr2F/7oCoGueieFb8=
=48pC
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Dec 19 13:37:36 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 02:37:36 +1300
Subject: [squid-users] Squid doesn't do a fallback from ipv6 to ipv4,
 if the ipv6 connect fails
In-Reply-To: <20141219130819.GA20800@bloms.de>
References: <20141208154825.GB9584@bloms.de> <5488764E.4020506@treenet.co.nz>
 <20141219130819.GA20800@bloms.de>
Message-ID: <54942A20.7040209@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 2:08 a.m., Dieter Bloms wrote:
> 
> When I do a http://ssl.ratsinfo-online.net/ the fallback from ipv6
> to ipv4 works fine, but when I do a
> https://ssl.ratsinfo-online.net/ squid tries ipv6 only and doesn't
> do a fallback to ipv4.
> 
> I would be nice, if you can try it on your dial stack setup.
> 
> Thank you.
> 

It takes me 10-20 sec to receive any response on the very first DNS
lookup for that domain. After which all responses are quite fast for a
few minutes. Then repeat with the slow lookup.

Like you say it responds with 1 IPv4 and 1 IPv6. Which is not too
many, and none actually failing to resolve. So DNS is reasonable even
with the occasional delay.

I am seeing approx 40-90% packet loss on several of the NTT.net
transit hops between me and the site in IPv4. Not sure if that is
related in any way related to your access path.

My current colo provider blocks network measurements from end-servers
(but only on v6) so I cant adequately test the v6 connectivity
anymore. But your log entry indicates that probably a TCP SYN
handshake did not finish over either IP version.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlCofAAoJELJo5wb/XPRjtC8H/jza0kveI1sedrGVqAUleGxL
sD0V7gOy7sb6INFcIKKhl9VhTZf43m6zB4qcP/bJ9AtvjAJKc9D4FLNAaicvzTJr
e2IS+glEfg8bXC67DEbH1YpMo6R3iK73LX5T50+E+SqrYbsRv8xXqkEnU6J7d4dL
dFsYFbYFs7zqcOCSkqHFHuWmAKsi86zmmvuLgBxsmOGuHUPMR70J8MtFxSZTL3DJ
zCyDESIuw3L3P+fJw9A0SiKiXLCagj6Gv/XKWpOiBvwUhUSow0D+avsH37J1rAOC
ddZuzOOfNHbPCuQT41X7xN3AWfY42fvJmz3Ihr0sgzkBQph9IBSIqvx21cuxq8s=
=J0by
-----END PGP SIGNATURE-----


From al.akchurin at hotmail.com  Fri Dec 19 13:40:07 2014
From: al.akchurin at hotmail.com (Eldar Akchurin)
Date: Fri, 19 Dec 2014 14:40:07 +0100
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <54939693.3060102@treenet.co.nz>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>,
 <54939693.3060102@treenet.co.nz>
Message-ID: <DUB128-W5785D0EB431A38181AF80ED6B0@phx.gbl>




Hi Amos,
It seems it uses a posix resolver for that, because it cannot find the native implementation.  configure:37657: checking for getaddrinfo
configure:37657: x86_64-w64-mingw32-g++ -o conftest.exe -DWINVER=0x601 -D_WIN32_WINNT=0x601 -fpermissive -L/usr/lib -mthreads -static-libgcc -static-libstdc++  -g conftest.cpp  -lpsapi >&5
/tmp/cckciKLu.o: In function `main':
/usr/src/squid-3.5.0.3-20141209-r13687/conftest.cpp:204: undefined reference to `getaddrinfo'
collect2: error: ld returned 1 exit status
configure:37657: $? = 1  Is this expected? If not, I will look how I can enable the native implementation.Thank you!
 > Date: Fri, 19 Dec 2014 16:08:03 +1300
> From: squid3 at treenet.co.nz
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problem with running squid 3.5 on windows 7
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> On 19/12/2014 12:32 p.m., Eldar Akchurin wrote:
> > 
> > 
> > 
> > Hi, I have cross-compiled squid 3.5 with mingw32-w64 on Ubuntu. The
> > properties are: c:\squid\sbin>squid -v Squid Cache: Version
> > 3.5.0.3-20141209-r13687 Service Name: squid Test build configure
> > options:  '--host=i686-w64-mingw32' '--prefix=c:/squid'
> > 'CXXFLAGS=-DWI NVER=0x601 -D_WIN32_WINNT=0x601 -fpermissive'
> > 'CFLAGS=-DWINVER=0x601 -D_WIN32_WI NNT=0x601 -fpermissive'
> > 'BUILDCXX=g++' 'BUILDCXXFLAGS=-DFOO' '--enable-build-inf o=Test
> > build' 'host_alias=i686-w64-mingw32' --enable-ltdl-convenience
> > 
> > When I try to run it on windows 7 64, it gives a critical error at
> > start, below is the debug trace
> <snip>
> 
> 
> > 2014/12/19 00:17:40.171| Address.cc(379) lookupHostIP: Given Non-IP
> > '127.0.0.1': No such host is known. 2014/12/19 00:17:40.171|
> > aclIpParseIpData: unknown first address in '127.0.0.1/3 2' 
> > 2014/12/19 00:17:40.171| tools.cc(543) leave_suid: leave_suid: PID
> > 4792 called FATAL: Bungled Default Configuration line 6: acl
> > localhost src 127.0.0.1/32 ::1 Squid Cache (Version
> > 3.5.0.3-20141209-r13687): Terminated abnormally. CPU Usage: 0.000
> > seconds = 0.000 user + 0.000 sys Maximum Resident Size: 0 KB Page
> > faults with physical i/o: 0 Could you please advice what I'm doing
> > wrong or whether this is a bug? Thank you!-eAdd to Calendar
> > 
> 
> Thank you for testing this all out Eldar. It seems you have gotten a
> little further than I have with this (I diverted to working on native
> MinGW build issues).
> 
> This is a bug. Though where it is coming from is still unknown. The
> operation being performed is that Squid is passing the IP text string
> to the system getaddrinfo() resolver API for conversion to a number.
> 
> First thing to check is whether Squid is actually using the native OS
> API or the stub replacement bundled in compat/. The config.log file
> generated during build will have an entry indicating whether
> getaddrinfo() was found or not in the MinGW headers. If the detection
> failed there will be some debug info about what broke.
> 
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
> 
> iQEcBAEBAgAGBQJUk5aTAAoJELJo5wb/XPRjiLkIAL0nS83JZLdTV7DfMFsDFqRJ
> yU7rFKWwqXp8P64K5Woedwga4JMpUrkxvbQ1t+wqS3mKWX3hJ72+M71juVeyt7pr
> pMZYGkoSZNXwhh/i73BxH2hVX7lysI8WKUw0NgBW7cZYe7KleLIODf8GWQhmXhJi
> vQh5uAfeYO6W/V+wwiRpY47H49yuU3UpypzsZ4P2i88+QvKZaef0T4ZJN8Wlresg
> ldc7vwBTqQ7p810s87dUrYAuCYZJKqYj/cQnUX86dEgkfxZSPwbDHS8qQdUxAvMb
> DqIZRp+H7hdO2DK1Sh1FCwyDEEbkuc0O/GurH6Nnw9IVpSAmWr4l8l82WdDXd4o=
> =4unG
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141219/d43c845f/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec 19 13:41:35 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 02:41:35 +1300
Subject: [squid-users] You MUST specify at least one Domain
 Controller.You can use either \ or / as separator between the domain name
In-Reply-To: <002101d01be1$677b74c0$36725e40$@netstream.ps>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
 <5494219B.2010708@treenet.co.nz>
 <002101d01be1$677b74c0$36725e40$@netstream.ps>
Message-ID: <54942B0F.3050008@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 12:13 p.m., Ahmed Allzaeem wrote:
> HI amos , thanks for clarification , Actually I modified it with
> the correct samba path with ==> /usr/bin/ntlm_auth whereas I
> checked and found that helper !
> 
> 
> So , my squid config  file to  : ======= ##Kerberos config for
> squid auth_param ntlm program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-basic

That should be:
  --helper-protocol=squid-2.5-ntlmssp

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlCsPAAoJELJo5wb/XPRjbX8IANahhzgeqoXQy9nVPbhfTAAB
53MDu/3ZzMXeK3mw60c/xzA0FV/F5iBQuXh+zydMlRUeqYDTU7WhRJ+Si0AbM0MX
6fsiHSJ++/1mY/4UyG/TlhmFc9ByxuXfYEoDFntUOb7hT3DDSrKZVYvZ6T4QdaCX
fqfDAHsxfaRt8j7gOcZhQOOeWA5khSbWxsTAsO7DKzBf2pZItNi3CLGzAg8OkVqo
6C1XtZ5sFGj3Ij/3tGngKYlNTnv6A3rt3N2+b63TWTbdWVvQLlkZqAfC5GF3tw0j
9wiBSOOuzxCSRTXo2/6r3dvnVK3tqMyBwngeIafOjIl0prmAbcegZVgLzX5hKBY=
=AFDb
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Fri Dec 19 13:45:35 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 19 Dec 2014 19:45:35 +0600
Subject: [squid-users] Squid 3.4.10 incorrectly configured on Solaris 10
In-Reply-To: <CA+Y8hcMRjPL7OSk4Ug4kmGfnqQQtZns7b6mx12a7miDYOwTfZA@mail.gmail.com>
References: <5492DE30.5060209@gmail.com>
 <CA+Y8hcMRjPL7OSk4Ug4kmGfnqQQtZns7b6mx12a7miDYOwTfZA@mail.gmail.com>
Message-ID: <54942BFF.1080608@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
If i do durty hack with editing these includes (ip_compat.h or
ip_nat.h), configuration went ok,
but build interceptor has errors and squid cannot be build.

Also, squid 3.4.8 in OpenCSW repository (built with ipf transparent
option) also cannot work in transparent mode.

So, need help - I need transparent proxy, not forwarding.

2.7 is too obsolete and contains strange bug (sometimes dies with fatal
error when high load).

Change OS is not an option.

WBR, Yuri

18.12.2014 20:11, Kinkie ?????:
> Hello Yuri,
>   this is probably a system header dependency.
> Could you check if the manuals mention anything about ipfmutex_t ? If
> they do, at the beginning of the page they should include a list of
> #include <...> lines. Could you copy-paste these lines here?
>
> Thanks
>
> On Thu, Dec 18, 2014 at 3:01 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>
> Hi there,
>
> yesterday (and during last four day) I've try to build transparent
> caching proxy on Solaris 10 (x86_64) testing environment.
>
> Configuration options are:
>
> # Without SSL 64 bit GCC
> ./configure '--prefix=/usr/local/squid' '--enable-translation'
> '--enable-external-acl-helpers=file_userip,unix_group'
> '--enable-icap-client' '--enable-ipf-transparent'
> '--enable-storeio=diskd' '--enable-removal-policies=lru,heap'
> '--enable-devpoll' '--disable-wccp' '--enable-wccpv2'
> '--enable-http-violations' '--enable-follow-x-forwarded-for'
> '--enable-arp-acl' '--enable-htcp' '--enable-cache-digests' '--with-dl'
> '--enable-auth-negotiate=none' '--disable-auth-digest'
> '--disable-auth-ntlm' '--disable-auth-basic'
> '--enable-storeid-rewrite-helpers=file'
> '--enable-log-daemon-helpers=file' '--with-filedescriptors=131072'
> '--with-build-environment=POSIX_V6_LP64_OFF64' 'CFLAGS=-O3 -m64 -fPIE
> -fstack-protector -mtune=core2 --param=ssp-buffer-size=4 -pipe'
> 'CXXFLAGS=-O3 -m64 -fPIE -fstack-protector -mtune=core2
> --param=ssp-buffer-size=4 -pipe' 'CPPFLAGS=-I/usr/include
> -I/opt/csw/include' 'LDFLAGS=-fPIE -pie -Wl,-z,now'
>
> But binaries built without interceptor support.
>
> Some investigation:
>
> Config.log has errors with ip_nat.h compilation:
>
> configure:27435: checking for netinet/ip_nat.h
> configure:27435: g++ -c -m64 -O3 -m64 -fPIE -fstack-protector
> -mtune=core2 --param=ssp-buffer-size=4 -pipe -march=native -std=c++11
> -I/usr/include -I/opt/csw/include -I/usr/include/gssapi
> -I/usr/include/kerberosv5 conftest.cpp >&5
> In file included from conftest.cpp:266:0:
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:98:2:
> error: 'ipfmutex_t' does not name a type
>   ipfmutex_t nat_lock;
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:108:2:
> error: 'frentry_t' does not name a type
>   frentry_t *nat_fr; /* filter rule ptr if appropriate */
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:112:2:
> error: 'ipftqent_t' does not name a type
>   ipftqent_t nat_tqe;
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:113:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_flags;
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:114:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_sumd[2]; /* ip checksum delta for data segment */
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:115:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_ipsumd; /* ip checksum delta for ip header */
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:116:2:
> error: 'u_32_t' does not name a type
>   u_32_t  nat_mssclamp; /* if != zero clamp MSS to this */
>   ^
>
/opt/csw/lib/gcc/i386-pc-solaris2.10/4.9.2/include-fixed/netinet/ip_nat.h:117:2:
> error: 'i6addr_t' does not name a type
>   i6addr_t nat_inip6;
>
> and so, configure does not see IP Filter finally, ergo cannot build
> interceptor.
>
> Yes, IP Filter installed in system. Yes, I've try to build 32 bit also.
> Yes, I've try to build on another system. Yes, I've try to play with
> configure option. Yes, I've try also development version 3.5.x - with
> the same result.
>
> Amos, need your help.
>
> Thanks in advance,
>
> WBR, Yuri
>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUlCv/AAoJENNXIZxhPexGyYUH/jl6MeJZcF/Krw+nYL/okEO6
YAH0k+zk/p2uhXARenFNXpoTJkUwi1yoOFrmCgo2sgw9wmEk418OGKTii+JgDh2L
ZpI0pvGhmkX84bbFuyU4SkXRi+NZAcR0gJRfCra7itibeDvJ7DlOm2pxuteLXqdz
EduGcMI8l2jmVf6Ib3CVKfYNXPMhJiPmIkXuPCfms+T2CLFuGRvrwoM44SjKra8e
vADuIBJkUF6kg0psz3GmNQLm2NLqusB8yt7kF0/WecK5OkeIGXI5JY+jJrGkrnI1
UtRau1AsxqVz9gWsptArUwWVfBazxYZNk73/4PI5MqQTtVJ8ilOAjn1WxnImTaQ=
=PGXC
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141219/3015aa7f/attachment.htm>

From ahmed.zaeem at netstream.ps  Fri Dec 19 23:50:09 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Fri, 19 Dec 2014 15:50:09 -0800
Subject: [squid-users] You MUST specify at least one Domain
	Controller.You can use either \ or / as separator between the
	domain name
In-Reply-To: <54942B0F.3050008@treenet.co.nz>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
 <5494219B.2010708@treenet.co.nz>
 <002101d01be1$677b74c0$36725e40$@netstream.ps>
 <54942B0F.3050008@treenet.co.nz>
Message-ID: <002701d01be6$871e91e0$955bb5a0$@netstream.ps>

Thank  you Amos , don?t know wt to say , u helped me a lot !

Now it get user/pwd

But still a new issue appeared !!

Now the browsing is so slow !!

I check the logs of squid I found a lot of TCP_denied and some of TCP_MISS


The question is being asked ... why a lot of requests is being deinied ans some is  being accepted ???

Here is a sample :
1418996889.904      1 192.168.1.5 TCP_DENIED/407 3972 GET http://google.com/ - NONE/- text/html
1418996889.925      1 192.168.1.5 TCP_DENIED/407 4189 GET http://google.com/ - NONE/- text/html
1418996889.936      2 192.168.1.5 TCP_DENIED/407 4506 GET http://google.com/ - NONE/- text/html
1418996889.943      2 192.168.1.5 TCP_DENIED/407 4189 GET http://google.com/ - NONE/- text/html
1418996897.774   7830 192.168.1.5 TCP_MISS/302 1258 GET http://google.com/ b DIRECT/74.125.232.228 text/html
1418996905.927   8142 192.168.1.5 TCP_MISS/302 1266 GET http://www.google.ps/? b DIRECT/74.125.232.247 text/html
1418996905.943      3 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
1418996905.946      2 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
1418996905.949      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
1418996905.949      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
1418996905.953      2 192.168.1.5 TCP_DENIED/407 3851 CONNECT www.google.ps:443 - NONE/- text/html
1418996905.955      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
1418996905.969      2 192.168.1.5 TCP_DENIED/407 4068 CONNECT www.google.ps:443 - NONE/- text/html
1418996905.973      1 192.168.1.5 TCP_DENIED/407 4393 CONNECT www.google.ps:443 - NONE/- text/html
1418996905.980      1 192.168.1.5 TCP_DENIED/407 4068 CONNECT www.google.ps:443 - NONE/- text/html
1418996908.011      1 192.168.1.5 TCP_DENIED/407 4103 POST http://clients1.google.com/ocsp - NONE/- text/html
1418996908.015      1 192.168.1.5 TCP_DENIED/407 4320 POST http://clients1.google.com/ocsp - NONE/- text/html
1418996908.019      2 192.168.1.5 TCP_DENIED/407 4661 POST http://clients1.google.com/ocsp - NONE/- text/html
1418996909.041      1 192.168.1.5 TCP_DENIED/407 3859 CONNECT ssl.gstatic.com:443 - NONE/- text/html
1418996909.089      2 192.168.1.5 TCP_DENIED/407 4076 CONNECT ssl.gstatic.com:443 - NONE/- text/html
1418996909.097      2 192.168.1.5 TCP_DENIED/407 4405 CONNECT ssl.gstatic.com:443 - NONE/- text/html
1418996909.104      2 192.168.1.5 TCP_DENIED/407 4076 CONNECT ssl.gstatic.com:443 - NONE/- text/html
1418996910.755      1 192.168.1.5 TCP_DENIED/407 3859 CONNECT www.gstatic.com:443 - NONE/- text/html
1418996910.784      1 192.168.1.5 TCP_DENIED/407 4076 CONNECT www.gstatic.com:443 - NONE/- text/html
1418996910.791      2 192.168.1.5 TCP_DENIED/407 4405 CONNECT www.gstatic.com:443 - NONE/- text/html
1418996910.796      1 192.168.1.5 TCP_DENIED/407 4076 CONNECT www.gstatic.com:443 - NONE/- text/html
1418996917.152      2 192.168.1.5 TCP_DENIED/407 4103 POST http://clients1.google.com/ocsp - NONE/- text/html
1418996917.156      2 192.168.1.5 TCP_DENIED/407 4320 POST http://clients1.google.com/ocsp - NONE/- text/html
1418996917.161      2 192.168.1.5 TCP_DENIED/407 4663 POST http://clients1.google.com/ocsp - NONE/- text/html
1418996920.312      1 192.168.1.5 TCP_DENIED/407 3903 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
1418996920.334      4 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
1418996920.471      2 192.168.1.5 TCP_DENIED/407 4483 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
1418996926.896      1 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
1418996935.623      1 192.168.1.5 TCP_DENIED/407 4079 POST http://ocsp.digicert.com/ - NONE/- text/html
1418996935.630      3 192.168.1.5 TCP_DENIED/407 4296 POST http://ocsp.digicert.com/ - NONE/- text/html
1418996935.633      2 192.168.1.5 TCP_DENIED/407 4635 POST http://ocsp.digicert.com/ - NONE/- text/html
1418996935.640      2 192.168.1.5 TCP_DENIED/407 4296 POST http://ocsp.digicert.com/ - NONE/- text/html
1418996935.810   7242 192.168.1.5 TCP_MISS/200 6448 GET http://whatismyipaddress.com/ b DIRECT/66.171.248.172 text/html
1418996935.852      1 192.168.1.5 TCP_DENIED/407 4349 GET http://maps.google.com/maps/api/js? - NONE/- text/html
1418996935.862      2 192.168.1.5 TCP_DENIED/407 4566 GET http://maps.google.com/maps/api/js? - NONE/- text/html
1418996935.868      4 192.168.1.5 TCP_DENIED/407 4901 GET http://maps.google.com/maps/api/js? - NONE/- text/html
1418996935.876      3 192.168.1.5 TCP_DENIED/407 4566 GET http://maps.google.com/maps/api/js? - NONE/- text/html
1418996935.904      0 192.168.1.5 TCP_DENIED/407 4076 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
1418996935.918      1 192.168.1.5 TCP_DENIED/407 4293 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
1418996935.925      1 192.168.1.5 TCP_DENIED/407 4650 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
1418996935.934      1 192.168.1.5 TCP_DENIED/407 4293 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
1418996937.486      1 192.168.1.5 TCP_DENIED/407 3863 CONNECT aus4.mozilla.org:443 - NONE/- text/html
1418996937.493      1 192.168.1.5 TCP_DENIED/407 4080 CONNECT aus4.mozilla.org:443 - NONE/- text/html
1418996937.498      3 192.168.1.5 TCP_DENIED/407 4413 CONNECT aus4.mozilla.org:443 - NONE/- text/html
1418996937.505      1 192.168.1.5 TCP_DENIED/407 4080 CONNECT aus4.mozilla.org:443 - NONE/- text/html
1418996937.615   1974 192.168.1.5 TCP_MISS/000 0 POST http://ocsp.digicert.com/ b DIRECT/ocsp.digicert.com -
1418996937.621      1 192.168.1.5 TCP_DENIED/407 3903 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
1418996937.628      2 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
1418996937.633      3 192.168.1.5 TCP_DENIED/407 4485 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
1418996937.641      1 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
1418996943.423   7545 192.168.1.5 TCP_MISS/200 1613 GET http://maps.google.com/maps/api/js? b DIRECT/216.58.209.128 text/javascript



regards

-----Original Message-----
From: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Sent: Friday, December 19, 2014 5:42 AM
To: Ahmed Allzaeem; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] You MUST specify at least one Domain Controller.You can use either \ or / as separator between the domain name

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 12:13 p.m., Ahmed Allzaeem wrote:
> HI amos , thanks for clarification , Actually I modified it with the 
> correct samba path with ==> /usr/bin/ntlm_auth whereas I checked and 
> found that helper !
> 
> 
> So , my squid config  file to  : ======= ##Kerberos config for squid 
> auth_param ntlm program /usr/bin/ntlm_auth 
> --helper-protocol=squid-2.5-basic

That should be:
  --helper-protocol=squid-2.5-ntlmssp

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlCsPAAoJELJo5wb/XPRjbX8IANahhzgeqoXQy9nVPbhfTAAB
53MDu/3ZzMXeK3mw60c/xzA0FV/F5iBQuXh+zydMlRUeqYDTU7WhRJ+Si0AbM0MX
6fsiHSJ++/1mY/4UyG/TlhmFc9ByxuXfYEoDFntUOb7hT3DDSrKZVYvZ6T4QdaCX
fqfDAHsxfaRt8j7gOcZhQOOeWA5khSbWxsTAsO7DKzBf2pZItNi3CLGzAg8OkVqo
6C1XtZ5sFGj3Ij/3tGngKYlNTnv6A3rt3N2+b63TWTbdWVvQLlkZqAfC5GF3tw0j
9wiBSOOuzxCSRTXo2/6r3dvnVK3tqMyBwngeIafOjIl0prmAbcegZVgLzX5hKBY=
=AFDb
-----END PGP SIGNATURE-----



From squid3 at treenet.co.nz  Fri Dec 19 13:51:49 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 02:51:49 +1300
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>
Message-ID: <54942D75.3020908@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 2:35 a.m., Eldar Akchurin wrote:
> Hi Amos,
> 
> It seems it uses a posix resolver for that, because cannot find the
> native implementation.
> 
> 
> 
> 
> 
> *configure:37657: checking for getaddrinfoconfigure:37657: 
> x86_64-w64-mingw32-g++ -o conftest.exe -DWINVER=0x601
> -D_WIN32_WINNT=0x601 -fpermissive -L/usr/lib -mthreads
> -static-libgcc -static-libstdc++  -g conftest.cpp  -lpsapi
> >&5/tmp/cckciKLu.o: In function 
> `main':/usr/src/squid-3.5.0.3-**20141209-r13687/conftest.cpp:*
> 
> *204: undefined reference to `getaddrinfo'collect2: error: ld
> returned 1 exit statusconfigure:37657: $? = 1 *
> 
> 
> Is this expected? If not, I will look how I can enable the native 
> implementation.

Well, the targeted Win7 version (0x601) is supposed to supply a native
getaddrinfo() and IIRC the MinGW headers included a definition. So I
expect (more of a hope really) that the MinGW supplied version should
be detected and used with the right autoconf test.

If you are able to figure this one out it would be a great help. I'm
not able to spare any time to Windows for a few weeks at least.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlC10AAoJELJo5wb/XPRjRQsH+gMtH17XrfhnwDicZMS5iRlQ
aYcE7ocsX355703i1QnKi3IXtDdrxnMG8AD8xmlyvnEjvnrZKGc2tSQrl6WZNygW
VP3dt/hTWzI7x4+gYBwPmMMYojQKvLUaDwX3vTX6cpRBJY/U07NdjQF4F2OPoU6Z
DON68zCz3K/b8IABhWYNFuyT/bcAsb5U+XbPiVGSnPxH1ArH1++Uqn0+hnTUWJoD
9A8rNbj4aoJz4JnM/8v89dsQFBVFmSyGBqmPk4CpIUc1oZewyf8+BMvxK6VhwoAo
mH9n7jq+Hy/i9lOGQ1FwjbiL52pnJxszvaxqBb+pED0c8tD/N4wqkM4F331/ZQ0=
=9NMH
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Dec 19 13:58:25 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 02:58:25 +1300
Subject: [squid-users] Squid 3.4.10 incorrectly configured on Solaris 10
In-Reply-To: <54942BFF.1080608@gmail.com>
References: <5492DE30.5060209@gmail.com>
 <CA+Y8hcMRjPL7OSk4Ug4kmGfnqQQtZns7b6mx12a7miDYOwTfZA@mail.gmail.com>
 <54942BFF.1080608@gmail.com>
Message-ID: <54942F01.6000001@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 2:45 a.m., Yuri Voinov wrote:
> 
> If i do durty hack with editing these includes (ip_compat.h or 
> ip_nat.h), configuration went ok, but build interceptor has errors
> and squid cannot be build.
> 
> Also, squid 3.4.8 in OpenCSW repository (built with ipf
> transparent option) also cannot work in transparent mode.
> 
> So, need help - I need transparent proxy, not forwarding.
> 
> 2.7 is too obsolete and contains strange bug (sometimes dies with
> fatal error when high load).
> 
> Change OS is not an option.
> 
> WBR, Yuri

The problem is clearly two Solaris OS headers contradicting each other.

I think you should take this to the Solaris or IP Filter developers
and see if they can provide help. It may require patching the system
headers (best if they produce that) or they might be able to supply a
working #include set for us to patch into Squid.

Either way they will be the people who know what is needed.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlC8BAAoJELJo5wb/XPRjuhoIANsyr9hBzSVP4OrK4unMBVuh
/83vhatRiStNO69xQ2ZmidDZqV7ZSlTiVp7hLXw26j0phIQN+k44arU06Dc+Qegz
qnmESIhPpiZANvJrO4DoahL4TknJ3LP7IF2PZDfKt0JmAgIOkWTGVspr1nUXAE+m
2O8+ssdyA2a11TLg9fY4FLzrZ3a2O4UnV+KTe/eBrPsIfc9B0Lj7f7gKHUj+OSiQ
35huA921tyW91b44ymwD751SDYCZmmupY0JHqJxtntk171TAn0LbmFvJbDJLzuO8
h3GyTfu+2z3G/KL4Vd4bqnoX1uGNGH92vmRCKc7UdmHQXUh5VavlbRQD7EMyGJQ=
=1sWd
-----END PGP SIGNATURE-----


From acrow at integrafin.co.uk  Fri Dec 19 14:01:53 2014
From: acrow at integrafin.co.uk (Alex Crow)
Date: Fri, 19 Dec 2014 14:01:53 +0000
Subject: [squid-users] You MUST specify at least one Domain
 Controller.You can use either \ or / as separator between the domain name
In-Reply-To: <002701d01be6$871e91e0$955bb5a0$@netstream.ps>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
 <5494219B.2010708@treenet.co.nz>
 <002101d01be1$677b74c0$36725e40$@netstream.ps>
 <54942B0F.3050008@treenet.co.nz>
 <002701d01be6$871e91e0$955bb5a0$@netstream.ps>
Message-ID: <54942FD1.2010905@integrafin.co.uk>

Hi,

That is how NTLM works. It doesn't (normally) indicate anything is 
wrong. You do seem to have a /lot/ of DENIED though.

NTLM Auth will slow down browsing somewhat because authentication is 
performed for every object retrieved. Google Maps can be a real nasty 
because it loads lots of small images for the map tiles. However I don't 
know /how/ slow your access is so I can't really say if it's likely to 
be a problem.

Cheers

Alex

On 19/12/14 23:50, Ahmed Allzaeem wrote:
> Thank  you Amos , don?t know wt to say , u helped me a lot !
>
> Now it get user/pwd
>
> But still a new issue appeared !!
>
> Now the browsing is so slow !!
>
> I check the logs of squid I found a lot of TCP_denied and some of TCP_MISS
>
>
> The question is being asked ... why a lot of requests is being deinied ans some is  being accepted ???
>
> Here is a sample :
> 1418996889.904      1 192.168.1.5 TCP_DENIED/407 3972 GET http://google.com/ - NONE/- text/html
> 1418996889.925      1 192.168.1.5 TCP_DENIED/407 4189 GET http://google.com/ - NONE/- text/html
> 1418996889.936      2 192.168.1.5 TCP_DENIED/407 4506 GET http://google.com/ - NONE/- text/html
> 1418996889.943      2 192.168.1.5 TCP_DENIED/407 4189 GET http://google.com/ - NONE/- text/html
> 1418996897.774   7830 192.168.1.5 TCP_MISS/302 1258 GET http://google.com/ b DIRECT/74.125.232.228 text/html
> 1418996905.927   8142 192.168.1.5 TCP_MISS/302 1266 GET http://www.google.ps/? b DIRECT/74.125.232.247 text/html
> 1418996905.943      3 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.946      2 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.949      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.949      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.953      2 192.168.1.5 TCP_DENIED/407 3851 CONNECT www.google.ps:443 - NONE/- text/html
> 1418996905.955      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.969      2 192.168.1.5 TCP_DENIED/407 4068 CONNECT www.google.ps:443 - NONE/- text/html
> 1418996905.973      1 192.168.1.5 TCP_DENIED/407 4393 CONNECT www.google.ps:443 - NONE/- text/html
> 1418996905.980      1 192.168.1.5 TCP_DENIED/407 4068 CONNECT www.google.ps:443 - NONE/- text/html
> 1418996908.011      1 192.168.1.5 TCP_DENIED/407 4103 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996908.015      1 192.168.1.5 TCP_DENIED/407 4320 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996908.019      2 192.168.1.5 TCP_DENIED/407 4661 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996909.041      1 192.168.1.5 TCP_DENIED/407 3859 CONNECT ssl.gstatic.com:443 - NONE/- text/html
> 1418996909.089      2 192.168.1.5 TCP_DENIED/407 4076 CONNECT ssl.gstatic.com:443 - NONE/- text/html
> 1418996909.097      2 192.168.1.5 TCP_DENIED/407 4405 CONNECT ssl.gstatic.com:443 - NONE/- text/html
> 1418996909.104      2 192.168.1.5 TCP_DENIED/407 4076 CONNECT ssl.gstatic.com:443 - NONE/- text/html
> 1418996910.755      1 192.168.1.5 TCP_DENIED/407 3859 CONNECT www.gstatic.com:443 - NONE/- text/html
> 1418996910.784      1 192.168.1.5 TCP_DENIED/407 4076 CONNECT www.gstatic.com:443 - NONE/- text/html
> 1418996910.791      2 192.168.1.5 TCP_DENIED/407 4405 CONNECT www.gstatic.com:443 - NONE/- text/html
> 1418996910.796      1 192.168.1.5 TCP_DENIED/407 4076 CONNECT www.gstatic.com:443 - NONE/- text/html
> 1418996917.152      2 192.168.1.5 TCP_DENIED/407 4103 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996917.156      2 192.168.1.5 TCP_DENIED/407 4320 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996917.161      2 192.168.1.5 TCP_DENIED/407 4663 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996920.312      1 192.168.1.5 TCP_DENIED/407 3903 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996920.334      4 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996920.471      2 192.168.1.5 TCP_DENIED/407 4483 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996926.896      1 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996935.623      1 192.168.1.5 TCP_DENIED/407 4079 POST http://ocsp.digicert.com/ - NONE/- text/html
> 1418996935.630      3 192.168.1.5 TCP_DENIED/407 4296 POST http://ocsp.digicert.com/ - NONE/- text/html
> 1418996935.633      2 192.168.1.5 TCP_DENIED/407 4635 POST http://ocsp.digicert.com/ - NONE/- text/html
> 1418996935.640      2 192.168.1.5 TCP_DENIED/407 4296 POST http://ocsp.digicert.com/ - NONE/- text/html
> 1418996935.810   7242 192.168.1.5 TCP_MISS/200 6448 GET http://whatismyipaddress.com/ b DIRECT/66.171.248.172 text/html
> 1418996935.852      1 192.168.1.5 TCP_DENIED/407 4349 GET http://maps.google.com/maps/api/js? - NONE/- text/html
> 1418996935.862      2 192.168.1.5 TCP_DENIED/407 4566 GET http://maps.google.com/maps/api/js? - NONE/- text/html
> 1418996935.868      4 192.168.1.5 TCP_DENIED/407 4901 GET http://maps.google.com/maps/api/js? - NONE/- text/html
> 1418996935.876      3 192.168.1.5 TCP_DENIED/407 4566 GET http://maps.google.com/maps/api/js? - NONE/- text/html
> 1418996935.904      0 192.168.1.5 TCP_DENIED/407 4076 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
> 1418996935.918      1 192.168.1.5 TCP_DENIED/407 4293 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
> 1418996935.925      1 192.168.1.5 TCP_DENIED/407 4650 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
> 1418996935.934      1 192.168.1.5 TCP_DENIED/407 4293 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
> 1418996937.486      1 192.168.1.5 TCP_DENIED/407 3863 CONNECT aus4.mozilla.org:443 - NONE/- text/html
> 1418996937.493      1 192.168.1.5 TCP_DENIED/407 4080 CONNECT aus4.mozilla.org:443 - NONE/- text/html
> 1418996937.498      3 192.168.1.5 TCP_DENIED/407 4413 CONNECT aus4.mozilla.org:443 - NONE/- text/html
> 1418996937.505      1 192.168.1.5 TCP_DENIED/407 4080 CONNECT aus4.mozilla.org:443 - NONE/- text/html
> 1418996937.615   1974 192.168.1.5 TCP_MISS/000 0 POST http://ocsp.digicert.com/ b DIRECT/ocsp.digicert.com -
> 1418996937.621      1 192.168.1.5 TCP_DENIED/407 3903 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996937.628      2 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996937.633      3 192.168.1.5 TCP_DENIED/407 4485 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996937.641      1 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996943.423   7545 192.168.1.5 TCP_MISS/200 1613 GET http://maps.google.com/maps/api/js? b DIRECT/216.58.209.128 text/javascript
>
>
>
> regards
>
> -----Original Message-----
> From: Amos Jeffries [mailto:squid3 at treenet.co.nz]
> Sent: Friday, December 19, 2014 5:42 AM
> To: Ahmed Allzaeem; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] You MUST specify at least one Domain Controller.You can use either \ or / as separator between the domain name
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 20/12/2014 12:13 p.m., Ahmed Allzaeem wrote:
>> HI amos , thanks for clarification , Actually I modified it with the
>> correct samba path with ==> /usr/bin/ntlm_auth whereas I checked and
>> found that helper !
>>
>>
>> So , my squid config  file to  : ======= ##Kerberos config for squid
>> auth_param ntlm program /usr/bin/ntlm_auth
>> --helper-protocol=squid-2.5-basic
> That should be:
>    --helper-protocol=squid-2.5-ntlmssp
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUlCsPAAoJELJo5wb/XPRjbX8IANahhzgeqoXQy9nVPbhfTAAB
> 53MDu/3ZzMXeK3mw60c/xzA0FV/F5iBQuXh+zydMlRUeqYDTU7WhRJ+Si0AbM0MX
> 6fsiHSJ++/1mY/4UyG/TlhmFc9ByxuXfYEoDFntUOb7hT3DDSrKZVYvZ6T4QdaCX
> fqfDAHsxfaRt8j7gOcZhQOOeWA5khSbWxsTAsO7DKzBf2pZItNi3CLGzAg8OkVqo
> 6C1XtZ5sFGj3Ij/3tGngKYlNTnv6A3rt3N2+b63TWTbdWVvQLlkZqAfC5GF3tw0j
> 9wiBSOOuzxCSRTXo2/6r3dvnVK3tqMyBwngeIafOjIl0prmAbcegZVgLzX5hKBY=
> =AFDb
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
"Transact" is operated by Integrated Financial Arrangements plc. 29
Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608
5300. (Registered office: as above; Registered in England and Wales
under number: 3727592). Authorised and regulated by the Financial
Conduct Authority (entered on the Financial Services Register; no. 190856).



From ahmed.zaeem at netstream.ps  Sat Dec 20 00:08:52 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Fri, 19 Dec 2014 16:08:52 -0800
Subject: [squid-users] You MUST specify at least one Domain
	Controller.You can use either \ or / as separator between the
	domain name
In-Reply-To: <54942FD1.2010905@integrafin.co.uk>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
 <5494219B.2010708@treenet.co.nz>
 <002101d01be1$677b74c0$36725e40$@netstream.ps>
 <54942B0F.3050008@treenet.co.nz>
 <002701d01be6$871e91e0$955bb5a0$@netstream.ps>
 <54942FD1.2010905@integrafin.co.uk>
Message-ID: <002d01d01be9$24a1fc70$6de5f550$@netstream.ps>

If you look @ the logs , it seems it  recognize a username when it allow , but when it deny it don?t recognize a username

Plz look @ logs below :
N username here , but I put the username "b"
> 1418996889.943      2 192.168.1.5 TCP_DENIED/407 4189 GET http://google.com/ - NONE/- text/html


Down  here itc MISS , u will see the username "b" after the google.com
> 1418996897.774   7830 192.168.1.5 TCP_MISS/302 1258 GET http://google.com/ b DIRECT/74.125.232.228 text/html

Compare both of them
U will see that user "b" ibcluded when its allowed

Im not sure why all of that slow in Kerberos ???!!!

cheers

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Alex Crow
Sent: Friday, December 19, 2014 6:02 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] You MUST specify at least one Domain Controller.You can use either \ or / as separator between the domain name

Hi,

That is how NTLM works. It doesn't (normally) indicate anything is wrong. You do seem to have a /lot/ of DENIED though.

NTLM Auth will slow down browsing somewhat because authentication is performed for every object retrieved. Google Maps can be a real nasty because it loads lots of small images for the map tiles. However I don't know /how/ slow your access is so I can't really say if it's likely to be a problem.

Cheers

Alex

On 19/12/14 23:50, Ahmed Allzaeem wrote:
> Thank  you Amos , don?t know wt to say , u helped me a lot !
>
> Now it get user/pwd
>
> But still a new issue appeared !!
>
> Now the browsing is so slow !!
>
> I check the logs of squid I found a lot of TCP_denied and some of 
> TCP_MISS
>
>
> The question is being asked ... why a lot of requests is being deinied ans some is  being accepted ???
>
> Here is a sample :
> 1418996889.904      1 192.168.1.5 TCP_DENIED/407 3972 GET http://google.com/ - NONE/- text/html
> 1418996889.925      1 192.168.1.5 TCP_DENIED/407 4189 GET http://google.com/ - NONE/- text/html
> 1418996889.936      2 192.168.1.5 TCP_DENIED/407 4506 GET http://google.com/ - NONE/- text/html
> 1418996889.943      2 192.168.1.5 TCP_DENIED/407 4189 GET http://google.com/ - NONE/- text/html
> 1418996897.774   7830 192.168.1.5 TCP_MISS/302 1258 GET http://google.com/ b DIRECT/74.125.232.228 text/html
> 1418996905.927   8142 192.168.1.5 TCP_MISS/302 1266 GET http://www.google.ps/? b DIRECT/74.125.232.247 text/html
> 1418996905.943      3 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.946      2 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.949      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.949      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.953      2 192.168.1.5 TCP_DENIED/407 3851 CONNECT www.google.ps:443 - NONE/- text/html
> 1418996905.955      4 192.168.1.5 TCP_DENIED/407 4128 CONNECT dtex4kvbppovt.cloudfront.net:443 - NONE/- text/html
> 1418996905.969      2 192.168.1.5 TCP_DENIED/407 4068 CONNECT www.google.ps:443 - NONE/- text/html
> 1418996905.973      1 192.168.1.5 TCP_DENIED/407 4393 CONNECT www.google.ps:443 - NONE/- text/html
> 1418996905.980      1 192.168.1.5 TCP_DENIED/407 4068 CONNECT www.google.ps:443 - NONE/- text/html
> 1418996908.011      1 192.168.1.5 TCP_DENIED/407 4103 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996908.015      1 192.168.1.5 TCP_DENIED/407 4320 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996908.019      2 192.168.1.5 TCP_DENIED/407 4661 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996909.041      1 192.168.1.5 TCP_DENIED/407 3859 CONNECT ssl.gstatic.com:443 - NONE/- text/html
> 1418996909.089      2 192.168.1.5 TCP_DENIED/407 4076 CONNECT ssl.gstatic.com:443 - NONE/- text/html
> 1418996909.097      2 192.168.1.5 TCP_DENIED/407 4405 CONNECT ssl.gstatic.com:443 - NONE/- text/html
> 1418996909.104      2 192.168.1.5 TCP_DENIED/407 4076 CONNECT ssl.gstatic.com:443 - NONE/- text/html
> 1418996910.755      1 192.168.1.5 TCP_DENIED/407 3859 CONNECT www.gstatic.com:443 - NONE/- text/html
> 1418996910.784      1 192.168.1.5 TCP_DENIED/407 4076 CONNECT www.gstatic.com:443 - NONE/- text/html
> 1418996910.791      2 192.168.1.5 TCP_DENIED/407 4405 CONNECT www.gstatic.com:443 - NONE/- text/html
> 1418996910.796      1 192.168.1.5 TCP_DENIED/407 4076 CONNECT www.gstatic.com:443 - NONE/- text/html
> 1418996917.152      2 192.168.1.5 TCP_DENIED/407 4103 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996917.156      2 192.168.1.5 TCP_DENIED/407 4320 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996917.161      2 192.168.1.5 TCP_DENIED/407 4663 POST http://clients1.google.com/ocsp - NONE/- text/html
> 1418996920.312      1 192.168.1.5 TCP_DENIED/407 3903 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996920.334      4 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996920.471      2 192.168.1.5 TCP_DENIED/407 4483 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996926.896      1 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996935.623      1 192.168.1.5 TCP_DENIED/407 4079 POST http://ocsp.digicert.com/ - NONE/- text/html
> 1418996935.630      3 192.168.1.5 TCP_DENIED/407 4296 POST http://ocsp.digicert.com/ - NONE/- text/html
> 1418996935.633      2 192.168.1.5 TCP_DENIED/407 4635 POST http://ocsp.digicert.com/ - NONE/- text/html
> 1418996935.640      2 192.168.1.5 TCP_DENIED/407 4296 POST http://ocsp.digicert.com/ - NONE/- text/html
> 1418996935.810   7242 192.168.1.5 TCP_MISS/200 6448 GET http://whatismyipaddress.com/ b DIRECT/66.171.248.172 text/html
> 1418996935.852      1 192.168.1.5 TCP_DENIED/407 4349 GET http://maps.google.com/maps/api/js? - NONE/- text/html
> 1418996935.862      2 192.168.1.5 TCP_DENIED/407 4566 GET http://maps.google.com/maps/api/js? - NONE/- text/html
> 1418996935.868      4 192.168.1.5 TCP_DENIED/407 4901 GET http://maps.google.com/maps/api/js? - NONE/- text/html
> 1418996935.876      3 192.168.1.5 TCP_DENIED/407 4566 GET http://maps.google.com/maps/api/js? - NONE/- text/html
> 1418996935.904      0 192.168.1.5 TCP_DENIED/407 4076 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
> 1418996935.918      1 192.168.1.5 TCP_DENIED/407 4293 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
> 1418996935.925      1 192.168.1.5 TCP_DENIED/407 4650 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
> 1418996935.934      1 192.168.1.5 TCP_DENIED/407 4293 GET http://cdn.whatismyipaddress.com/favicon.ico - NONE/- text/html
> 1418996937.486      1 192.168.1.5 TCP_DENIED/407 3863 CONNECT aus4.mozilla.org:443 - NONE/- text/html
> 1418996937.493      1 192.168.1.5 TCP_DENIED/407 4080 CONNECT aus4.mozilla.org:443 - NONE/- text/html
> 1418996937.498      3 192.168.1.5 TCP_DENIED/407 4413 CONNECT aus4.mozilla.org:443 - NONE/- text/html
> 1418996937.505      1 192.168.1.5 TCP_DENIED/407 4080 CONNECT aus4.mozilla.org:443 - NONE/- text/html
> 1418996937.615   1974 192.168.1.5 TCP_MISS/000 0 POST http://ocsp.digicert.com/ b DIRECT/ocsp.digicert.com -
> 1418996937.621      1 192.168.1.5 TCP_DENIED/407 3903 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996937.628      2 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996937.633      3 192.168.1.5 TCP_DENIED/407 4485 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996937.641      1 192.168.1.5 TCP_DENIED/407 4120 CONNECT tiles.services.mozilla.com:443 - NONE/- text/html
> 1418996943.423   7545 192.168.1.5 TCP_MISS/200 1613 GET http://maps.google.com/maps/api/js? b DIRECT/216.58.209.128 text/javascript
>
>
>
> regards
>
> -----Original Message-----
> From: Amos Jeffries [mailto:squid3 at treenet.co.nz]
> Sent: Friday, December 19, 2014 5:42 AM
> To: Ahmed Allzaeem; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] You MUST specify at least one Domain 
> Controller.You can use either \ or / as separator between the domain 
> name
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 20/12/2014 12:13 p.m., Ahmed Allzaeem wrote:
>> HI amos , thanks for clarification , Actually I modified it with the 
>> correct samba path with ==> /usr/bin/ntlm_auth whereas I checked and 
>> found that helper !
>>
>>
>> So , my squid config  file to  : ======= ##Kerberos config for squid 
>> auth_param ntlm program /usr/bin/ntlm_auth 
>> --helper-protocol=squid-2.5-basic
> That should be:
>    --helper-protocol=squid-2.5-ntlmssp
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUlCsPAAoJELJo5wb/XPRjbX8IANahhzgeqoXQy9nVPbhfTAAB
> 53MDu/3ZzMXeK3mw60c/xzA0FV/F5iBQuXh+zydMlRUeqYDTU7WhRJ+Si0AbM0MX
> 6fsiHSJ++/1mY/4UyG/TlhmFc9ByxuXfYEoDFntUOb7hT3DDSrKZVYvZ6T4QdaCX
> fqfDAHsxfaRt8j7gOcZhQOOeWA5khSbWxsTAsO7DKzBf2pZItNi3CLGzAg8OkVqo
> 6C1XtZ5sFGj3Ij/3tGngKYlNTnv6A3rt3N2+b63TWTbdWVvQLlkZqAfC5GF3tw0j
> 9wiBSOOuzxCSRTXo2/6r3dvnVK3tqMyBwngeIafOjIl0prmAbcegZVgLzX5hKBY=
> =AFDb
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

--
This message is intended only for the addressee and may contain confidential information. Unless you are that person, you may not disclose its contents or use it in any way and are requested to delete the message along with any attachments and notify us immediately.
"Transact" is operated by Integrated Financial Arrangements plc. 29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300. (Registered office: as above; Registered in England and Wales under number: 3727592). Authorised and regulated by the Financial Conduct Authority (entered on the Financial Services Register; no. 190856).

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Dec 19 14:28:27 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 03:28:27 +1300
Subject: [squid-users] You MUST specify at least one Domain
 Controller.You can use either \ or / as separator between the domain name
In-Reply-To: <002701d01be6$871e91e0$955bb5a0$@netstream.ps>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
 <5494219B.2010708@treenet.co.nz>
 <002101d01be1$677b74c0$36725e40$@netstream.ps>
 <54942B0F.3050008@treenet.co.nz>
 <002701d01be6$871e91e0$955bb5a0$@netstream.ps>
Message-ID: <5494360B.5000301@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 12:50 p.m., Ahmed Allzaeem wrote:
> Thank  you Amos , don?t know wt to say , u helped me a lot !
> 
> Now it get user/pwd
> 
> But still a new issue appeared !!
> 
> Now the browsing is so slow !!
> 
> I check the logs of squid I found a lot of TCP_denied and some of
> TCP_MISS
> 

Thats DENIED/407. In particular sets of 5 requests.
 Four auth challenges (407) followed by one final/successful request
(non-407).

NTLM handshake normally works in threes. Two 407's then one non-407.

NOTE: The non-407 can appear much later in the log than the two 407's.
A very good example of this is the 5 "POST http://ocsp.digicert.com/"
log lines. You can see the set of 407s occuring, then ~2 seconds later
the non-407 saying it took 1974 ms (~2 sec) to complete.


I suspect what you are seeing in that log is the mess that happens
when browsers (un)Happy Eyeballs algorithm collides with NTLM. The
browser opening connections in pairs to see which will be usable first
needs to authenticate both, but final request only sent on first
connection to complete the auth.
 *If* I am right about this then the slowdown should only happen on
startup when a lot of stuff has to be done by the browser and the
experience will get faster over time. The browser can technically save
the second-opened connections for later use, some do.


Also, ensure that persistent connections are enabled to both server
and clients. This will help minimize the number of handshakes
required. That is about all you can do to optimize NTLM unfortunately,
it is a truely nasty protocol.


Also, if you are seeing some clients looping with many 407 trying the
same credentials over and over try the setting:
 auth_param ntlm keepalive off

However, dont confuse this "keepalive" option with persistent
connections. It is a hack specially crafted to work with NTLM and
Negotiate auth to fix old IE brokenness and has proven useful with
some Java apps and recent Firefox versions. Its not harmful to any
client, but can limit the proxy total traffic capacity somewhat so
best to avoid if you dont need it.

HTH
Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlDYLAAoJELJo5wb/XPRj558H/12+3ARMFEHINczwgrPjzFBx
3la3Vn+mBo8NOaxCgEcJP73F1ZHH58oTlBcUygj1h9ecj7/fikil6IXhDvV87W4s
esS+IIFbOekKKFXxfGiSa0hg4G3NEEepmPfAx8OT8UWLC68fkESOCeOP99LYY3q5
7xZ7bef1ieudgDAUI7zuTCb8tEsV47SRFRQESOJefcXz3YkXhtL5ouNaK56sfp03
iaP33AzkjC9HBVxcfp4h4rInMO3VVbSecKtrHdStmnty5pU7lkXvMgSDtP1Kf71z
5waoPr7+8sf2uyUx/c42/RFpLIH0gfjg++WcIAXfF9gzmALNwhImvtb8JnRfHHk=
=autN
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Dec 19 14:46:04 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 03:46:04 +1300
Subject: [squid-users] You MUST specify at least one Domain
 Controller.You can use either \ or / as separator between the domain name
In-Reply-To: <002d01d01be9$24a1fc70$6de5f550$@netstream.ps>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
 <5494219B.2010708@treenet.co.nz>
 <002101d01be1$677b74c0$36725e40$@netstream.ps>
 <54942B0F.3050008@treenet.co.nz>
 <002701d01be6$871e91e0$955bb5a0$@netstream.ps>
 <54942FD1.2010905@integrafin.co.uk>
 <002d01d01be9$24a1fc70$6de5f550$@netstream.ps>
Message-ID: <54943A2C.9070006@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 1:08 p.m., Ahmed Allzaeem wrote:
> If you look @ the logs , it seems it  recognize a username when it
> allow , but when it deny it don?t recognize a username
> 

The 407 is sent because there is nobody authenticated. Nobody
authenticated means no username.


> Plz look @ logs below : N username here , but I put the username
> "b"
>> 1418996889.943      2 192.168.1.5 TCP_DENIED/407 4189 GET
>> http://google.com/ - NONE/- text/html

One of teh 407 is before you put any username in. The second one is
after you entered username, but before its fully authenticated.

> 
> 
> Down  here itc MISS , u will see the username "b" after the
> google.com
>> 1418996897.774   7830 192.168.1.5 TCP_MISS/302 1258 GET
>> http://google.com/ b DIRECT/74.125.232.228 text/html
> 
> Compare both of them U will see that user "b" ibcluded when its
> allowed
> 
> Im not sure why all of that slow in Kerberos ???!!!

You are not using Kerberos. You are using NTLM.

Kerberos is part of the "Negotiate" auth scheme.


Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlDorAAoJELJo5wb/XPRjBjkIANDA0SQMtglLVBj/6reDISIj
goYqOQzq4Aw5hP60RcDuIazo//mHTHLLFRof95hmIFCRlo3kHt4aF9EFKQ03gih1
+jvbQ4V2MdZq3+oJiULGhME73DjpZOe9mxhz5FZFMGkOazOd+LIVhipXeoJbK7As
BkpCqHnY7N0l4QtvwO85Ea+9jdSC5dws7CIcrN6+J49h7g/J5b7jQRgOdhm+2MoE
jg936RA8dM3i/usW7E/CRfdvAS4N7BUXtRsbk88I/YgRJhXRRhpl2FUOa9dCoJXT
ol1jibwWjyc1Kjsmn/MZLIBiMrhrBnNOSjSZXldGslEvRN60HptPxetQ4WDgpBw=
=L19J
-----END PGP SIGNATURE-----


From redhoodny at gmail.com  Fri Dec 19 14:45:19 2014
From: redhoodny at gmail.com (Red)
Date: Fri, 19 Dec 2014 09:45:19 -0500
Subject: [squid-users] Unable to configure cache_dir with only
	TCP_MISS/200
In-Reply-To: <54939AF6.9060107@treenet.co.nz>
References: <54932D12.6020802@gmail.com> <54939AF6.9060107@treenet.co.nz>
Message-ID: <549439FF.5050002@gmail.com>

Thank You Amos;
I have tried that already, however  I get "Error: Dependancy not
satisfiable: libstdc++6 (>= 4.9)".  I am not sure what forcing upgrade
of libraries will do to OS, so I guess it would be the best for me to
just sit upgrade out until it can be done smoothly.
Thank You again,
Bob

On 12/18/2014 10:26 PM, Amos Jeffries wrote:
> On 19/12/2014 8:37 a.m., Red wrote:
> > Using squid 3.3.8 on Ubuntu 14.04.
>
> This is probably bug 3806. Which was fixed in 3.3.12 release.
>
> Can you try an upgrade to 3.4 ?
> The Debian Jesse/Testing package 3.4.8-* should work fine in Ubuntu 14.*
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141219/f98c0548/attachment.htm>

From ahmed.zaeem at netstream.ps  Sat Dec 20 00:48:36 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Fri, 19 Dec 2014 16:48:36 -0800
Subject: [squid-users] You MUST specify at least one Domain
	Controller.You can use either \ or / as separator between the
	domain name
In-Reply-To: <54943A2C.9070006@treenet.co.nz>
References: <001701d01bda$b676bdc0$23643940$@netstream.ps>
 <5494219B.2010708@treenet.co.nz>
 <002101d01be1$677b74c0$36725e40$@netstream.ps>
 <54942B0F.3050008@treenet.co.nz>
 <002701d01be6$871e91e0$955bb5a0$@netstream.ps>
 <54942FD1.2010905@integrafin.co.uk>
 <002d01d01be9$24a1fc70$6de5f550$@netstream.ps>
 <54943A2C.9070006@treenet.co.nz>
Message-ID: <002f01d01bee$b1328970$13979c50$@netstream.ps>

Thank you a lot a lot a lot .
Great mailing list with people like you. "Amos"

Soon I will jump to Kerberos and if I got hanged I will ask here again :)
 
thanks

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, December 19, 2014 6:46 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] You MUST specify at least one Domain Controller.You can use either \ or / as separator between the domain name

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 1:08 p.m., Ahmed Allzaeem wrote:
> If you look @ the logs , it seems it  recognize a username when it 
> allow , but when it deny it don?t recognize a username
> 

The 407 is sent because there is nobody authenticated. Nobody authenticated means no username.


> Plz look @ logs below : N username here , but I put the username "b"
>> 1418996889.943      2 192.168.1.5 TCP_DENIED/407 4189 GET
>> http://google.com/ - NONE/- text/html

One of teh 407 is before you put any username in. The second one is after you entered username, but before its fully authenticated.

> 
> 
> Down  here itc MISS , u will see the username "b" after the google.com
>> 1418996897.774   7830 192.168.1.5 TCP_MISS/302 1258 GET
>> http://google.com/ b DIRECT/74.125.232.228 text/html
> 
> Compare both of them U will see that user "b" ibcluded when its 
> allowed
> 
> Im not sure why all of that slow in Kerberos ???!!!

You are not using Kerberos. You are using NTLM.

Kerberos is part of the "Negotiate" auth scheme.


Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlDorAAoJELJo5wb/XPRjBjkIANDA0SQMtglLVBj/6reDISIj
goYqOQzq4Aw5hP60RcDuIazo//mHTHLLFRof95hmIFCRlo3kHt4aF9EFKQ03gih1
+jvbQ4V2MdZq3+oJiULGhME73DjpZOe9mxhz5FZFMGkOazOd+LIVhipXeoJbK7As
BkpCqHnY7N0l4QtvwO85Ea+9jdSC5dws7CIcrN6+J49h7g/J5b7jQRgOdhm+2MoE
jg936RA8dM3i/usW7E/CRfdvAS4N7BUXtRsbk88I/YgRJhXRRhpl2FUOa9dCoJXT
ol1jibwWjyc1Kjsmn/MZLIBiMrhrBnNOSjSZXldGslEvRN60HptPxetQ4WDgpBw=
=L19J
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From vkukk at xvidservices.com  Fri Dec 19 14:52:26 2014
From: vkukk at xvidservices.com (Veiko Kukk)
Date: Fri, 19 Dec 2014 16:52:26 +0200
Subject: [squid-users] Determining unique clients in Squid
Message-ID: <54943BAA.5040706@xvidservices.com>

Hi,

I have been trying to understand, how does Squid determine different 
clients, but it is not clear from the documentation. I guess this does 
not depend entirely on IP address, right? Otherwise all clients behind 
NAT would be considered as single client.

Reason behind this is that I'd like to configure a forward proxy for 
(mostly) binary files caching. All requests have Authorization headers 
(API key) and come from single IP address (localhost, python 
application, not generic web browser).

client <https> squid ssl_bump to see inside https <https> remote cloud 
storage

http://wiki.squid-cache.org/SquidFaq/InnerWorkings#What_are_private_and_public_keys.3F
"Private objects are associated with only a single client whereas a 
public object may be sent to multiple clients at the same time."

I wonder if it would be possible to use Squid for effectively cache 
larger objects locally with this type of configuration?

Best regards,
Veiko


From squid at bloms.de  Fri Dec 19 15:03:04 2014
From: squid at bloms.de (Dieter Bloms)
Date: Fri, 19 Dec 2014 16:03:04 +0100
Subject: [squid-users] Squid doesn't do a fallback from ipv6 to ipv4,
 if the ipv6 connect fails
In-Reply-To: <54942A20.7040209@treenet.co.nz>
References: <20141208154825.GB9584@bloms.de> <5488764E.4020506@treenet.co.nz>
 <20141219130819.GA20800@bloms.de> <54942A20.7040209@treenet.co.nz>
Message-ID: <20141219150304.GB20800@bloms.de>

Hello Amos,

On Sat, Dec 20, Amos Jeffries wrote:

> > When I do a http://ssl.ratsinfo-online.net/ the fallback from ipv6
> > to ipv4 works fine, but when I do a
> > https://ssl.ratsinfo-online.net/ squid tries ipv6 only and doesn't
> > do a fallback to ipv4.
> > 
> > I would be nice, if you can try it on your dial stack setup.
> > 
> > Thank you.
> > 
> 
> It takes me 10-20 sec to receive any response on the very first DNS
> lookup for that domain. After which all responses are quite fast for a
> few minutes. Then repeat with the slow lookup.
> 
> Like you say it responds with 1 IPv4 and 1 IPv6. Which is not too
> many, and none actually failing to resolve. So DNS is reasonable even
> with the occasional delay.
> 
> I am seeing approx 40-90% packet loss on several of the NTT.net
> transit hops between me and the site in IPv4. Not sure if that is
> related in any way related to your access path.
> 
> My current colo provider blocks network measurements from end-servers
> (but only on v6) so I cant adequately test the v6 connectivity
> anymore. But your log entry indicates that probably a TCP SYN
> handshake did not finish over either IP version.

with https squid doesn't try to connect the webserver over ipv4 (verfied
with tcpdump).

So I think you can test the missing failover from ipv6 to ipv4, if a
connect over ipv6 isn't possible with https connection.

Again with http the failover from ipv6 to ipv4 occur, only https is a
problem.


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From alehman at gbateam.com  Fri Dec 19 15:12:07 2014
From: alehman at gbateam.com (Alan Lehman)
Date: Fri, 19 Dec 2014 15:12:07 +0000
Subject: [squid-users] error compiling 3.4.10
In-Reply-To: <CAK90gp6Hmqs9NLJJgsa6e1vZ8WOMpdYbHj7X0iVLGP4VxMk1_A@mail.gmail.com>
References: <B967FC4A73984244A48E8572B691B31E0C6B5983@EXCH.win.gbutler.com>
 <548B8110.9090405@ngtech.co.il>
 <CAK90gp6Hmqs9NLJJgsa6e1vZ8WOMpdYbHj7X0iVLGP4VxMk1_A@mail.gmail.com>
Message-ID: <B967FC4A73984244A48E8572B691B31E0C6BE21F@EXCH.win.gbutler.com>

Alex,
This corrected the compile problem. It now compiles and installs without error. Thank you!

Eliezer,
Thanks for sharing the script. I will save that for future reference.

Alan


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Alex Domoradov
Sent: Saturday, December 13, 2014 5:52 AM
To: Eliezer Croitoru
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] error compiling 3.4.10

According to the following lines

> /usr/bin/ld: cannot find -lssl
> /usr/bin/ld: cannot find -lcrypto
it seems that you forgot to install devel package - openssl-devel

On Sat, Dec 13, 2014 at 1:58 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Alan,

The main issue is the unknown environment.
Can you run this script:
http://www1.ngtech.co.il/squid/basic_data.sh

The script will give us the basic details about the build system.
When you use the script make sure there are no confidential details.

I did not tested yet this build on CentOS 7 but it builds on 6.6 and
couple others so it should be something solvable.

Eliezer

On 12/12/2014 11:57 PM, Alan Lehman wrote:
> config options: --enable-ssl --enable-useragent-log
> --enable-referer-log --with-filedescriptors=8192
> --disable-loadable-modules --prefix=/usr --includedir=/usr/include
> --datadir=/usr/share --bindir=/usr/sbin --libexecdir=/usr/lib/squid
> --localstatedir=/var --sysconfdir=/etc/squid
> --with-openssl=/usr/lib64/openssl

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUi4EQAAoJENxnfXtQ8ZQUpnwIAJ1ZSDa7OKpl51C6ZTObBTy+
StROk+SlEPX7g6Vg+zL+TL9emoEIbHYXNZ0Pi8jRsiVi2W0VZaMowD8inglZwLqP
WIz6ChROO9jIMy7N2TK8VuoCJC4DwrishAD/K0UH0S1jqArTE6ngzCrCGwWg8bNI
9HxflR6Tc+eOXYhe5bvcEBufKtFv9249dsktr6IJvgT+IZ+RAhVc0SXeZMbIPX18
HYVEtBYZsyzXbiLJAmFcw9tbLteZrKlZe1GhkCmt6wa8/Sm9I+OvlCvjuO/zhfta
qxhVzKjOlOeydH8TMxCZ+P3se3zEbGu11FjzPSP2cmw0kcWS+IHz3YpRETeQjjQ=
=n9Jj
-----END PGP SIGNATURE-----


Alan Lehman, PE, DCEP, Senior Associate
GBA, 9801 Renner Boulevard, Lenexa, KS 66219-9745
D: (913) 577-8829 | M: (816) 210-8785 | F: (913) 577-8264


CONFIDENTIALITY NOTICE: This e-mail message including attachments, if any, is intended for the person or entity to which it is addressed and may contain confidential and/or privileged material. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message. Thank you.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Fri Dec 19 15:11:06 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 04:11:06 +1300
Subject: [squid-users] Unable to configure cache_dir with only
	TCP_MISS/200
In-Reply-To: <549439FF.5050002@gmail.com>
References: <54932D12.6020802@gmail.com> <54939AF6.9060107@treenet.co.nz>
 <549439FF.5050002@gmail.com>
Message-ID: <5494400A.4060608@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 3:45 a.m., Red wrote:
> Thank You Amos; I have tried that already, however  I get "Error:
> Dependancy not satisfiable: libstdc++6 (>= 4.9)".  I am not sure
> what forcing upgrade of libraries will do to OS, so I guess it
> would be the best for me to just sit upgrade out until it can be
> done smoothly.

Darn. Yeah okay, libstdc++ impacts a lot of things and across-OS is
worse than just a version bump.


You could try the version in backports repository. Otherwise you are
stuck doing a custom build to patch - in which case you may as well
build the latest version anyway.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlEAJAAoJELJo5wb/XPRjOdQH/ivueQ2uKdZ5kytmyNB0WK7s
Zz8Qml0U9c74QPLwj4HUZvShGsm4befACSbSUq3O936g+ZsE/VHLtkJYBEJNlgNW
fMO9x9fcvL9iwSkcwmH/4iodx68gluqMG2qpUw6RNWoQTLOci5OALzE4KZox5fmf
8jYWEHPXosqAeRChkUbrGBqeUEgGtdXpcjzGorpReydOIAqXuYtWXQFhJBS3oTSp
agMkuWkofixazST2zmdjOpI0mZvpAvQXU4OnoT17xmWFMgmHD0Gk4wjNxqcwKIlY
lIRWLWwu6KMwpkeBwFdK4VQufp2RZt24yisEfsSS1mrrCYEN3SCJFqiJaLldlO0=
=ohqA
-----END PGP SIGNATURE-----


From alfredo at fing.uncu.edu.ar  Fri Dec 19 15:21:51 2014
From: alfredo at fing.uncu.edu.ar (Alfredo Rezinovsky)
Date: Fri, 19 Dec 2014 12:21:51 -0300
Subject: [squid-users] ERR_CONNECT_FAIL 110
Message-ID: <5494428F.2040805@fing.uncu.edu.ar>

I have a few TPROXY implementations with squid. In only one of them 
recently I'm getting lots of: "x-squid-error: ERR_CONNECT_FAIL 110" and 
some 504 timeouts.

Squid Cache: Version 3.4.10-20141218-r13197
configure options:  '--prefix=/opt/sepia/squid' 
'--sysconfdir=/var/lib/sepia/' '--disable-auth' '--disable-auto-locale' 
'--disable-cache-digests' '--disable-cpu-profiling' 
'--disable-debug-cbdata' '--disable-delay-pools' '--disable-devpoll' 
'--disable-ecap' '--disable-esi' '--disable-eui' 
'--disable-external-acl-helpers' '--disable-follow-x-forwarded-for' 
'--disable-forw-via-db' '--enable-gnuregex' '--disable-htcp' 
'--disable-icap-client' '--disable-ident-lookups' 
'--enable-internal-dns' '--disable-ipf-transparent' 
'--disable-ipfw-transparent' '--disable-ipv6' '--disable-leakfinder' 
'--disable-pf-transparent' '--disable-poll' '--disable-select' 
'--disable-snmp' '--enable-ssl' '--disable-stacktraces' 
'--disable-translation' '--disable-url-rewrite-helpers' '--disable-wccp' 
'--disable-wccpv2' '--disable-win32-service' 
'--disable-x-accelerator-vary' '--disable-icmp' 
'--disable-storeid-rewrite-helpers' '--enable-async-io' 
'--enable-disk-io' '--enable-epoll' '--enable-http-violations' 
'--enable-inline' '--enable-kill-parent-hack' '--enable-linux-netfilter' 
'--enable-log-daemon-helpers' '--enable-removal-policies' 
'--enable-storeio' '--enable-unlinkd' '--enable-x-accelerator-vary' 
'--enable-zph-qos' '--with-default-user=nobody' 
'--with-logdir=/var/log/sepia' '--with-pthreads' '--with-included-ltdl' 
'--with-pidfile=/var/lib/sepia/squid.pid' '--with-netfilter-conntrack' 
--enable-ltdl-convenience

Is a custom compiled squid with everything I don't need disabled.

Running in Ubuntu with kernel 3.13.0

PMTU from the proxy to both the servers and the clients seems to be 1500.

Any clue?

--
Alfrenovsky



From squid3 at treenet.co.nz  Fri Dec 19 15:45:52 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 04:45:52 +1300
Subject: [squid-users] Determining unique clients in Squid
In-Reply-To: <54943BAA.5040706@xvidservices.com>
References: <54943BAA.5040706@xvidservices.com>
Message-ID: <54944830.1@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 3:52 a.m., Veiko Kukk wrote:
> Hi,
> 
> I have been trying to understand, how does Squid determine
> different clients, but it is not clear from the documentation. I
> guess this does not depend entirely on IP address, right? Otherwise
> all clients behind NAT would be considered as single client.

It depends ...

 ... for Squids' network measurement mechanisms and client_db* do
depend on IP address alone.

 ... security contexts like TLS/SSL or connection pinning depend on
the TCP socket numbers in use.


Other concepts of "client" such as authenticated user or end-user or
remote software agent are not relevant to Squid beyond the ACLs you
configure.


> 
> Reason behind this is that I'd like to configure a forward proxy
> for (mostly) binary files caching. All requests have Authorization
> headers (API key) and come from single IP address (localhost,
> python application, not generic web browser).


*Caching* is not related to the client though. Whether an object can
be cached depends solely on the request/reply message headers.

see below...

> 
> client <https> squid ssl_bump to see inside https <https> remote
> cloud storage
> 
> http://wiki.squid-cache.org/SquidFaq/InnerWorkings#What_are_private_and_public_keys.3F
>
>  "Private objects are associated with only a single client whereas
> a public object may be sent to multiple clients at the same time."
> 
> I wonder if it would be possible to use Squid for effectively
> cache larger objects locally with this type of configuration?
> 

Some points:

0) the document above is referring to the internal hash keys Squid
uses for indexing objects. Its describing the technical mechanism by
which Squid remembders which object is which type. Not much relevance
to your query as such.

1) Squid-3.2 and later are HTTP/1.1 compliant and able to cache
authenticated replies (and many other types of client-specific
objects) in accordance with the HTTP/1.1 rules for them.

2) client proxy-authorization credentials have no effect on
cacheability. Only credentials in www-authorization header affect
that, and only if the reply message does not make the object cacheable
by providing certain cache-control settings.

4) "HTTP" and "HTTPS" are both the same HTTP protocol. The only
difference is that one is inside a TLS channel. A lot of people seem
to think its more secure somehow, but its not really. SSL-Bumped HTTPS
requests are just as cacheable (or not) as they would be if
intercepted on port 80.

5) Size of objects is related only to the size limits you configure
into Squid. Default config is up to 4MB is cached to disks, up to
512KB to memory.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlEgwAAoJELJo5wb/XPRjCawH/1joPQ6E4bBAJglfiyT39JNO
GFZZ21Oo2ew74gyz0K99fXlOXIpz1l9IupHgayHm+R7ezfMLWen3CGfWOK6QukC/
7NpjdkqCDUxwhhJ70XeWdgrw1rMRXwBlMZUGkwrQ4mGTuBA7DsFjneEg6H9PmY7r
zJLTb8NVbQAwzVRKmq9etJHpBbMN1QmZUYHLHV7uFIUirwpD58gfgvWBdPGFKTDF
I5+RwmzDP0Lmri7dPGWJwYTUPVCdyJ848Fjhvj/gVLuaBwEjZI+CxuSANrRa8Rr5
tAQKDMY7Zp5MTO/sYOTEg8I4yavP2UCtXBh3SpT+AzBium5PlQdVIlc45yVlo5k=
=Ik7x
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Dec 19 15:53:22 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 04:53:22 +1300
Subject: [squid-users] ERR_CONNECT_FAIL 110
In-Reply-To: <5494428F.2040805@fing.uncu.edu.ar>
References: <5494428F.2040805@fing.uncu.edu.ar>
Message-ID: <549449F2.6040005@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 4:21 a.m., Alfredo Rezinovsky wrote:
> I have a few TPROXY implementations with squid. In only one of
> them recently I'm getting lots of: "x-squid-error: ERR_CONNECT_FAIL
> 110" and some 504 timeouts.
> 
> Squid Cache: Version 3.4.10-20141218-r13197 configure options:
> '--prefix=/opt/sepia/squid' '--sysconfdir=/var/lib/sepia/'
> '--disable-auth' '--disable-auto-locale' '--disable-cache-digests'
> '--disable-cpu-profiling' '--disable-debug-cbdata'
> '--disable-delay-pools' '--disable-devpoll' '--disable-ecap'
> '--disable-esi' '--disable-eui' '--disable-external-acl-helpers'
> '--disable-follow-x-forwarded-for' '--disable-forw-via-db'
> '--enable-gnuregex' '--disable-htcp' '--disable-icap-client'
> '--disable-ident-lookups' '--enable-internal-dns'
> '--disable-ipf-transparent' '--disable-ipfw-transparent'
> '--disable-ipv6' '--disable-leakfinder' '--disable-pf-transparent'
> '--disable-poll' '--disable-select' '--disable-snmp' '--enable-ssl'
> '--disable-stacktraces' '--disable-translation'
> '--disable-url-rewrite-helpers' '--disable-wccp' '--disable-wccpv2'
> '--disable-win32-service' '--disable-x-accelerator-vary'
> '--disable-icmp' '--disable-storeid-rewrite-helpers'
> '--enable-async-io' '--enable-disk-io' '--enable-epoll'
> '--enable-http-violations' '--enable-inline'
> '--enable-kill-parent-hack' '--enable-linux-netfilter' 
> '--enable-log-daemon-helpers' '--enable-removal-policies' 
> '--enable-storeio' '--enable-unlinkd'
> '--enable-x-accelerator-vary' '--enable-zph-qos'
> '--with-default-user=nobody' '--with-logdir=/var/log/sepia'
> '--with-pthreads' '--with-included-ltdl' 
> '--with-pidfile=/var/lib/sepia/squid.pid'
> '--with-netfilter-conntrack' --enable-ltdl-convenience
> 
> Is a custom compiled squid with everything I don't need disabled.
> 
> Running in Ubuntu with kernel 3.13.0
> 
> PMTU from the proxy to both the servers and the clients seems to be
> 1500.
> 
> Any clue?

Nope you omitted the best clues. :-)

The access.log entries matching those errors would be a good start if
you can identify them.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlEnxAAoJELJo5wb/XPRjZ0IIAIw6hUQdmnVtXEF7UU0o5Zp6
Q3zhRdXfNVuqc7xHgmyakD8UIsLM8lmKb/43qiHqvbU9ZVvg0WslloSS05eDjG6m
FcTzgeVaQJImiSvkZ2Ei6MGlLgiuxDR4BIUxRWxhhuD7UFvsG8Ese45yM55ivq6C
ocEThNWHZYbwTsCbKOIZz5Be6pEHVh8EkNAIAl7+/+cnXG6fc7qUPnG471piOu4a
LNnhJdDqlYhe3vwKcVSN0aIjz+lrtB6tMs4DDT2GpX+LZ6tOIihsCZOHij31M4Z2
qpVWs4i4r7aKmideSYMsr2SSd9s8zzLGel3ReXuPhKvFZsZOiP8uZtBJEm47n/4=
=tGQM
-----END PGP SIGNATURE-----


From vdoctor at neuf.fr  Fri Dec 19 16:46:34 2014
From: vdoctor at neuf.fr (Stakres)
Date: Fri, 19 Dec 2014 08:46:34 -0800 (PST)
Subject: [squid-users] Determining unique clients in Squid
In-Reply-To: <54943BAA.5040706@xvidservices.com>
References: <54943BAA.5040706@xvidservices.com>
Message-ID: <05cd01d01bac$a6c222d0$f4466870$@fr>

Hi Veiko,

 

Correct me if I?m wrong, you need to use Squid in HTTPS decryption and try
to cache maximum of objects (mainly big), am I right ?

Regarding the private/public objects, I could not answer here as I don?t see
what your project is ? then I?m not a member of the Squid team so I?m not
informed about all tricks J

 

So, do you plan to install a Squid for your users for regular internet
traffic or do you have special restrictions for a specific Squid
installation ?

 

Ready to help you but need more details on what you want to do J

 

Bye Fred

 

De : Veiko Kukk [via Squid Web Proxy Cache]
[mailto:ml-node+s1019090n4668773h96 at n4.nabble.com] 
Envoy? : vendredi 19 d?cembre 2014 15:43
? : Stakres
Objet : Determining unique clients in Squid

 

Hi, 

I have been trying to understand, how does Squid determine different 
clients, but it is not clear from the documentation. I guess this does 
not depend entirely on IP address, right? Otherwise all clients behind 
NAT would be considered as single client. 

Reason behind this is that I'd like to configure a forward proxy for 
(mostly) binary files caching. All requests have Authorization headers 
(API key) and come from single IP address (localhost, python 
application, not generic web browser). 

client <https> squid ssl_bump to see inside https <https> remote cloud 
storage 

http://wiki.squid-cache.org/SquidFaq/InnerWorkings#What_are_private_and_publ
ic_keys.3F
"Private objects are associated with only a single client whereas a 
public object may be sent to multiple clients at the same time." 

I wonder if it would be possible to use Squid for effectively cache 
larger objects locally with this type of configuration? 

Best regards, 
Veiko 
_______________________________________________ 
squid-users mailing list 
[hidden email] 
http://lists.squid-cache.org/listinfo/squid-users



  _____  

If you reply to this email, your message will be added to the discussion
below:

http://squid-web-proxy-cache.1019090.n4.nabble.com/Determining-unique-client
s-in-Squid-tp4668773.html 

To start a new topic under Squid - Users, email
ml-node+s1019090n1019091h54 at n4.nabble.com 
To unsubscribe from Squid Web Proxy Cache, click here
<http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp
?macro=unsubscribe_by_code&node=1019090&code=dmRvY3RvckBuZXVmLmZyfDEwMTkwOTB
8OTE5NjEzNjUz> .
 
<http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp
?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.n
amespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.vie
w.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail
.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aema
il.naml> NAML 





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Determining-unique-clients-in-Squid-tp4668773p4668780.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From al.akchurin at hotmail.com  Fri Dec 19 18:05:23 2014
From: al.akchurin at hotmail.com (Eldar Akchurin)
Date: Fri, 19 Dec 2014 19:05:23 +0100
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <54942D75.3020908@treenet.co.nz>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>
 <54939693.3060102@treenet.co.nz>,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>,
 <54942D75.3020908@treenet.co.nz>
Message-ID: <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>

Hi Amos,
 
Thanks a lot for the hint!
Specifying LIBS="-lws2_32" fixes this particular issue. Let's see what comes up next.
 
--e
 
> Date: Sat, 20 Dec 2014 02:51:49 +1300
> From: squid3 at treenet.co.nz
> To: al.akchurin at googlemail.com
> CC: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problem with running squid 3.5 on windows 7
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> On 20/12/2014 2:35 a.m., Eldar Akchurin wrote:
> > Hi Amos,
> > 
> > It seems it uses a posix resolver for that, because cannot find the
> > native implementation.
> > 
> > 
> > 
> > 
> > 
> > *configure:37657: checking for getaddrinfoconfigure:37657: 
> > x86_64-w64-mingw32-g++ -o conftest.exe -DWINVER=0x601
> > -D_WIN32_WINNT=0x601 -fpermissive -L/usr/lib -mthreads
> > -static-libgcc -static-libstdc++  -g conftest.cpp  -lpsapi
> > >&5/tmp/cckciKLu.o: In function 
> > `main':/usr/src/squid-3.5.0.3-**20141209-r13687/conftest.cpp:*
> > 
> > *204: undefined reference to `getaddrinfo'collect2: error: ld
> > returned 1 exit statusconfigure:37657: $? = 1 *
> > 
> > 
> > Is this expected? If not, I will look how I can enable the native 
> > implementation.
> 
> Well, the targeted Win7 version (0x601) is supposed to supply a native
> getaddrinfo() and IIRC the MinGW headers included a definition. So I
> expect (more of a hope really) that the MinGW supplied version should
> be detected and used with the right autoconf test.
> 
> If you are able to figure this one out it would be a great help. I'm
> not able to spare any time to Windows for a few weeks at least.
> 
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
> 
> iQEcBAEBAgAGBQJUlC10AAoJELJo5wb/XPRjRQsH+gMtH17XrfhnwDicZMS5iRlQ
> aYcE7ocsX355703i1QnKi3IXtDdrxnMG8AD8xmlyvnEjvnrZKGc2tSQrl6WZNygW
> VP3dt/hTWzI7x4+gYBwPmMMYojQKvLUaDwX3vTX6cpRBJY/U07NdjQF4F2OPoU6Z
> DON68zCz3K/b8IABhWYNFuyT/bcAsb5U+XbPiVGSnPxH1ArH1++Uqn0+hnTUWJoD
> 9A8rNbj4aoJz4JnM/8v89dsQFBVFmSyGBqmPk4CpIUc1oZewyf8+BMvxK6VhwoAo
> mH9n7jq+Hy/i9lOGQ1FwjbiL52pnJxszvaxqBb+pED0c8tD/N4wqkM4F331/ZQ0=
> =9NMH
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141219/b4e6df8b/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec 19 20:46:57 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Dec 2014 09:46:57 +1300
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>,
 <54942D75.3020908@treenet.co.nz> <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>
Message-ID: <54948EC0.9000406@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 7:05 a.m., Eldar Akchurin wrote:
> Hi Amos,
> 
> Thanks a lot for the hint! Specifying LIBS="-lws2_32" fixes this
> particular issue. Let's see what comes up next.
> 
> --e

Great! thank you. I have added that to Squid-3. For the next release
you should not have to explicitly define it or the 0x601 version options.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlI7AAAoJELJo5wb/XPRjBWgIAJ6G3bJ50M9x1l5lkT8VULXg
TeMQ2F88gOAE2bPfPGr+jZ2vxxmS+I/cRNGaZd5icEsMVtFCVHvtVwgRMyLNB0l/
sJSMqhRT2RZvJZBb13GeQsthUh0e0Resfj44T3YMzntVpEPx4nkEWtRv97iaLgDp
yA8imLIPtieX2GN+m4BXpKVc8Y842nfAcDKbRGbpqZQ0V56QOwHhGNzyuEIgYjad
kzrtfQKs4m4BHvk6kCr4OHJHvE6E+VKQpKc4IBxpv5gwu9atP6ayMKFZEgCC4mdP
BfPgf9SRIy3KQri2RNTCiS0x9xLrCYLGflXuifs1dRz4UIOJQCrPdE6Kz1WPFbw=
=d93Y
-----END PGP SIGNATURE-----


From james at ejbdigital.com.au  Fri Dec 19 22:20:34 2014
From: james at ejbdigital.com.au (James Harper)
Date: Fri, 19 Dec 2014 22:20:34 +0000
Subject: [squid-users] Transparent proxy with Peek and Splice feature.
In-Reply-To: <54941A1C.90702@gmail.com>
References: <5474C8CF.6030404@gmail.com> <54759E6C.5080404@treenet.co.nz>
 <54772BB5.5010101@gmail.com> <547948CF.5040408@treenet.co.nz>
 <54941A1C.90702@gmail.com>
Message-ID: <HKXPR04MB200C296ED856A0B610BDE7EE86B0@HKXPR04MB200.apcprd04.prod.outlook.com>

The following "works" for me:

# intercept for transparent proxy of ssl connections
https_port 3130 name=transproxyssl intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/ca.pem

# just testing with my laptop
acl james_src arp 11:11:11:11:11:11

# name of port used for transparent ssl interception
acl transproxyssl myportname transproxyssl

ssl_bump stare transproxyssl james_src
ssl_bump bump james_src
ssl_bump splice all

But "works" is probably a bit of an exaggeration. I was seeing lots of this sort of thing in the logs:
 
Error negotiating SSL on FD 75: error:1409F07F:SSL routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0)
hold write on SSL connection on FD 65
BUG 3556: FD 112 is not an open socket.
assertion failed: Read.cc:69: "fd_table[conn->fd].halfClosedReader != NULL"

And squid restarting a lot. This was with squid-3.5.0.2-20141121-r13666 and so hopefully I was seeing some bugs that are now fixed, and it's not that I am abusing the configuration or something...

I'm upgrading to the latest snapshot now for further testing.

James


> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Vadim Rogoziansky
> Sent: Friday, 19 December 2014 11:29 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Transparent proxy with Peek and Splice feature.
> 
> Any ideas, any thoughts?
> Thanks.
> 
> 
> 11/29/2014 6:17 AM, Amos Jeffries ???????(??):
> > -----BEGIN PGP SIGNED MESSAGE-----
> > Hash: SHA1
> >
> > On 28/11/2014 2:48 a.m., Vadim Rogoziansky wrote:
> >> Hello Amos.
> >>
> >> Thank you for answer.
> >>
> >> There was made an investigation related to squid's peek and splice
> >> issues in transparent mode. One-line explanation is as follows - in
> >> intercept mode squid can't get a server host name from the request
> >> header and uses clent IP address instead for both fake cert
> >> generation and as a SNI record in server bump SSL handshaking. This
> >> is the root of the problem. However this can be fixed if squid uses
> >> SNI field taken from client TLS Hello message for that purposes.
> >> Can you hack squid in this way? What do you think?
> > I think peek-n-splice is supposed to already be doing that.
> >
> > However it does depend on whether you are bumping the connection at
> > step 1 (before ClientHello), step 2 (after ClientHello, before
> > ServerHello), or step 3 (after both ClientHello and ServerHello) of
> > the TLS handshake whether the SNI details are present.
> >
> > Amos
> > -----BEGIN PGP SIGNATURE-----
> > Version: GnuPG v2.0.22 (MingW32)
> >
> >
> iQEcBAEBAgAGBQJUeUjPAAoJELJo5wb/XPRj6QEIAOHrR8wmDcjkfgUh2UtPw
> pHP
> >
> vVkPMEuIrUq9Gxx3uSojCZjlFJPuCQ2UafS1p8LuxcEQ+TRmUFbAu4AkKoO2Ro
> Z5
> > 7fCGoiXTwn4TzFf0pLh9SPBq9j12OJ3uT28EEqbILrT0sbKP02xK/qiJfCLR61Ev
> >
> vprAdggapbKg/ns1l1H3BBgZR2A4W/abQPIq6/Eu/r+7nYK6L2oOdqPDWTJjud
> MV
> >
> 8D9sdOD9mYYryrdptU0GLh9Q/V5QEhipSkuA936iZ0Dfa2ZSr4gphJyaRAFWSMf
> 3
> >
> q502lZy+ASkDa2vAbjALRBgn3VwYWl8KBQcypUKF4UXtaLtF0EIrLMun+p4QxU
> M=
> > =44aG
> > -----END PGP SIGNATURE-----
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

From ahmed.zaeem at netstream.ps  Sat Dec 20 19:15:40 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Sat, 20 Dec 2014 11:15:40 -0800
Subject: [squid-users] squid with multiple ips is listenting to some ips
	with port and not all of ips ??!!
Message-ID: <000001d01c89$58f08780$0ad19680$@netstream.ps>

Hi

 

Recently I have a squid with 256 ips installed on a proxy server.

 

The issue that we have is I added about 256 .

 

 

The ips are diversie in ranges and I can ping all of them from outside

 

 

Bur the problem is only with squid !!

 

Squid whrn it start .it only listen to sort of ips , not all of the ips.

 

I check that by the command :

Netstat -ant | grep LISTEN

 

I can see only some of ips

 

As can example , in squid.conf there is about 240 ips listening 

But the real that getting listenting is about 130 ips ??!!!

 

 

The port tanges of the ips is from 2400 tcp to 2460 

I mean , ip #  1 listen to port 2400

Ip # 2  listen to port 2401

And so on..

But im wondering why the proxy is not let the other ips up !!!

Why only 130 ips from 240 is up with ip:port and other is not working and
not connecting ??!!!

Im sure it not iptables and I checked by tcpdump , I can see that I can
reach the proxy , but the issue with ssquid that is not letting all ips in
the conf file to be up.

 

Also im sure all ips are pingable from outide !!!

 

Here is sampel of wy I have :

I made abbreviation of  long list of ips :

 

=====================================
[root at localhost ~]# cat /etc/squid/squid.conf

# Recommended minimum configuration:

#

###########Authentication######

auth_param basic children 300

auth_param basic realm "Put your pwd"

auth_param basic program /lib/squid/basic_ncsa_auth   /etc/squid/squid_user

auth_param basic credentialsttl 2 hours

auth_param basic casesensitive off

###

acl classx proxy_auth REQUIRED

http_access allow classx

###

# Example rule allowing access from your local networks.

# Adapt to list your (internal) IP networks from where browsing

# should be allowed

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network

acl localnet src 172.16.0.0/12  # RFC1918 possible internal network

acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

acl localnet src fc00::/7       # RFC 4193 local private network range

acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl localnet src xx0.0/16 xxx0.0/16

acl SSL_ports port 443

acl Safe_ports port 80          # http

acl Safe_ports port 21          # ftp

acl Safe_ports port 443         # https

acl Safe_ports port 70          # gopher

acl Safe_ports port 210         # wais

acl Safe_ports port 1025-65535  # unregistered ports

acl Safe_ports port 280         # http-mgmt

acl Safe_ports port 488         # gss-http

acl Safe_ports port 591         # filemaker

acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

#

# Recommended minimum Access Permission configuration:

#

# Deny requests to certain unsafe ports

http_access deny !Safe_ports

 

# Deny CONNECT to other than secure SSL ports

http_access deny CONNECT !SSL_ports

 

# Only allow cachemgr access from localhost

http_access allow localhost manager

http_access deny manager

 

# We strongly recommend the following be uncommented to protect innocent

# web applications running on the proxy server who think the only

# one who can access services on "localhost" is a local user

#http_access deny to_localhost

 

#

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

#

####################################################################

# Example rule allowing access from your local networks.

# Adapt localnet in the ACL section to list your (internal) IP networks

# from where browsing should be allowed

http_access allow localnet

http_access allow localhost

############################################################

# And finally deny all other access to this proxy

http_access deny all

 

 

#http_port 2400

http_port xxxx:2401
.

.

.

.

.

 

http_port xxxx:2660

# Uncomment and adjust the following to add a disk cache directory.

#cache_dir ufs /var/cache/squid 100 16 256

 

# Leave coredumps in the first cache dir

coredump_dir /var/cache/squid

 

#

# Add any of your own refresh_pattern entries above these.

#

refresh_pattern ^ftp:           1440    20%     10080

refresh_pattern ^gopher:        1440    0%      1440

refresh_pattern -i (/cgi-bin/|\?) 0     0%      0

refresh_pattern .               0       20%     4320

###################################################

cache_effective_user squid

cache_effective_group squid

##############################

################################################

acl ip1 myip 5x.x.x.x

.

.

.

.

..

 

acl ip260 myip xxx

################################################

################################################

tcp_outgoing_address xxx ip1

.

.

.

.

.

.

tcp_outgoing_address xxx ip260

 

#####################################################

 

 

 

 

 

Version 3.4.3

configure options:  '--prefix=/usr' '--includedir=/include'
'--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc'
'--enable-cachemgr-hostname=drx' '--localstatedir=/var'
'--libexecdir=/lib/squid' '--disable-maintainer-mode'
'--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8'
'--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap'
'--enable-delay-pools' '--enable-cache-digests' '--enable-underscores'
'--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth'
'--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam
,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm'
'--enable-digest-auth-helpers=ldap,password'
'--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-arp-acl'
'--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=131072'
'--with-large-files' '--with-default-user=squid' '--enable-linux-netfilter'
'CFLAGS=-g -O2 -g -Wall -O2' 'LDFLAGS=' 'CPPFLAGS=' 'CXXFLAGS=-g -O2 -g
-Wall -O2' '--enable-ltdl-convenience'

 

 

 

 

 

 

 

Any help ???

Could it be a kernel limitations ???

 

cheers

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141220/0ca6cc1a/attachment.htm>

From ahmed.zaeem at netstream.ps  Sat Dec 20 20:43:25 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Sat, 20 Dec 2014 12:43:25 -0800
Subject: [squid-users] squid with multiple ips is listenting to some
	ips	with port and not all of ips ??!!
In-Reply-To: <000001d01c89$58f08780$0ad19680$@netstream.ps>
References: <000001d01c89$58f08780$0ad19680$@netstream.ps>
Message-ID: <000a01d01c95$9afe3440$d0fa9cc0$@netstream.ps>

Hi Guys I thunk I found the reason . but didn't fix it now !!!

 

I ran squid in debug mode and I had :

014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.

2014/12/20 05:38:23|          The limit is 128

2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.

2014/12/20 05:38:23|          The limit is 128

2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.

2014/12/20 05:38:23|          The limit is 128

2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.

 

 

As we see there is limitation to 128 ips ,

How can I increase this value ???

 

 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Ahmed Allzaeem
Sent: Saturday, December 20, 2014 11:16 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid with multiple ips is listenting to some ips
with port and not all of ips ??!!

 

Hi

 

Recently I have a squid with 256 ips installed on a proxy server.

 

The issue that we have is I added about 256 .

 

 

The ips are diversie in ranges and I can ping all of them from outside

 

 

Bur the problem is only with squid !!

 

Squid whrn it start .it only listen to sort of ips , not all of the ips.

 

I check that by the command :

Netstat -ant | grep LISTEN

 

I can see only some of ips

 

As can example , in squid.conf there is about 240 ips listening 

But the real that getting listenting is about 130 ips ??!!!

 

 

The port tanges of the ips is from 2400 tcp to 2460 

I mean , ip #  1 listen to port 2400

Ip # 2  listen to port 2401

And so on..

But im wondering why the proxy is not let the other ips up !!!

Why only 130 ips from 240 is up with ip:port and other is not working and
not connecting ??!!!

Im sure it not iptables and I checked by tcpdump , I can see that I can
reach the proxy , but the issue with ssquid that is not letting all ips in
the conf file to be up.

 

Also im sure all ips are pingable from outide !!!

 

Here is sampel of wy I have :

I made abbreviation of  long list of ips :

 

=====================================
[root at localhost ~]# cat /etc/squid/squid.conf

# Recommended minimum configuration:

#

###########Authentication######

auth_param basic children 300

auth_param basic realm "Put your pwd"

auth_param basic program /lib/squid/basic_ncsa_auth   /etc/squid/squid_user

auth_param basic credentialsttl 2 hours

auth_param basic casesensitive off

###

acl classx proxy_auth REQUIRED

http_access allow classx

###

# Example rule allowing access from your local networks.

# Adapt to list your (internal) IP networks from where browsing

# should be allowed

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network

acl localnet src 172.16.0.0/12  # RFC1918 possible internal network

acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

acl localnet src fc00::/7       # RFC 4193 local private network range

acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl localnet src xx0.0/16 xxx0.0/16

acl SSL_ports port 443

acl Safe_ports port 80          # http

acl Safe_ports port 21          # ftp

acl Safe_ports port 443         # https

acl Safe_ports port 70          # gopher

acl Safe_ports port 210         # wais

acl Safe_ports port 1025-65535  # unregistered ports

acl Safe_ports port 280         # http-mgmt

acl Safe_ports port 488         # gss-http

acl Safe_ports port 591         # filemaker

acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

#

# Recommended minimum Access Permission configuration:

#

# Deny requests to certain unsafe ports

http_access deny !Safe_ports

 

# Deny CONNECT to other than secure SSL ports

http_access deny CONNECT !SSL_ports

 

# Only allow cachemgr access from localhost

http_access allow localhost manager

http_access deny manager

 

# We strongly recommend the following be uncommented to protect innocent

# web applications running on the proxy server who think the only

# one who can access services on "localhost" is a local user

#http_access deny to_localhost

 

#

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

#

####################################################################

# Example rule allowing access from your local networks.

# Adapt localnet in the ACL section to list your (internal) IP networks

# from where browsing should be allowed

http_access allow localnet

http_access allow localhost

############################################################

# And finally deny all other access to this proxy

http_access deny all

 

 

#http_port 2400

http_port xxxx:2401
.

.

.

.

.

 

http_port xxxx:2660

# Uncomment and adjust the following to add a disk cache directory.

#cache_dir ufs /var/cache/squid 100 16 256

 

# Leave coredumps in the first cache dir

coredump_dir /var/cache/squid

 

#

# Add any of your own refresh_pattern entries above these.

#

refresh_pattern ^ftp:           1440    20%     10080

refresh_pattern ^gopher:        1440    0%      1440

refresh_pattern -i (/cgi-bin/|\?) 0     0%      0

refresh_pattern .               0       20%     4320

###################################################

cache_effective_user squid

cache_effective_group squid

##############################

################################################

acl ip1 myip 5x.x.x.x

.

.

.

.

..

 

acl ip260 myip xxx

################################################

################################################

tcp_outgoing_address xxx ip1

.

.

.

.

.

.

tcp_outgoing_address xxx ip260

 

#####################################################

 

 

 

 

 

Version 3.4.3

configure options:  '--prefix=/usr' '--includedir=/include'
'--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc'
'--enable-cachemgr-hostname=drx' '--localstatedir=/var'
'--libexecdir=/lib/squid' '--disable-maintainer-mode'
'--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8'
'--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap'
'--enable-delay-pools' '--enable-cache-digests' '--enable-underscores'
'--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth'
'--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam
,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm'
'--enable-digest-auth-helpers=ldap,password'
'--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-arp-acl'
'--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=131072'
'--with-large-files' '--with-default-user=squid' '--enable-linux-netfilter'
'CFLAGS=-g -O2 -g -Wall -O2' 'LDFLAGS=' 'CPPFLAGS=' 'CXXFLAGS=-g -O2 -g
-Wall -O2' '--enable-ltdl-convenience'

 

 

 

 

 

 

 

Any help ???

Could it be a kernel limitations ???

 

cheers

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141220/d7da22f0/attachment.htm>

From squid3 at treenet.co.nz  Sat Dec 20 13:40:04 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 Dec 2014 02:40:04 +1300
Subject: [squid-users] squid with multiple ips is listenting to some ips
 with port and not all of ips ??!!
In-Reply-To: <000a01d01c95$9afe3440$d0fa9cc0$@netstream.ps>
References: <000001d01c89$58f08780$0ad19680$@netstream.ps>
 <000a01d01c95$9afe3440$d0fa9cc0$@netstream.ps>
Message-ID: <54957C34.60002@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 21/12/2014 9:43 a.m., Ahmed Allzaeem wrote:
> Hi Guys I thunk I found the reason . but didn't fix it now !!!
> 
> 
> 
> I ran squid in debug mode and I had :
> 
> 014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.
> 
> 2014/12/20 05:38:23|          The limit is 128
> 
> 2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.
> 
> 2014/12/20 05:38:23|          The limit is 128
> 
> 2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.
> 
> 2014/12/20 05:38:23|          The limit is 128
> 
> 2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.
> 
> 
> 
> 
> 
> As we see there is limitation to 128 ips ,
> 
> How can I increase this value ???
> 


You can increase it if you really have to by building the latest
version of Squid (3.4.7 or later anyway) using:
  ./configure CXXFLAGS="-DMAXTCPLISTENPORTS=256"

 or whichever number you want to increase it to.

For each packet read Squid has to check the listening port list to see
if it is a read() or accept() operation. Doing even 128 checks per
packet is pushing the boundaries for reasonable performance loss.


Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlXw0AAoJELJo5wb/XPRjru8IAJZ6KfAKIyzMHeC3SFdTdAg+
TjnXR7rSJSU5f53arEPa2vA16F0PxkWXFwjpmG01TuMaDLqg8PROdnWvITYka6+k
D/bqhylRSeE95T9uO8Sdy0gQTHf4Y1To6w77qlNSrpK2j5e32N25dEmQVm2zMa9n
8d044+BWuwMJq9sessLjnYtZEffN1DQCWpjevZx1sa5rvIVBgv1S3RRY2jIrgcMW
XvdMCYlbawGQ997B/BDGttlN8aNf/t1NqAe5ckn9FTKlVYgL/tbRjkC00vtUxzb0
75Yz8b/SONVK5E6BDcfffVvrY0KUvKZrbauhTQ68uFzGpv1Cv/ynTaqyp2NlDQ0=
=HJ+Q
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Sat Dec 20 14:11:40 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 Dec 2014 03:11:40 +1300
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <54948EC0.9000406@treenet.co.nz>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>,
 <54942D75.3020908@treenet.co.nz> <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>
 <54948EC0.9000406@treenet.co.nz>
Message-ID: <5495839C.90503@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 9:46 a.m., Amos Jeffries wrote:
> On 20/12/2014 7:05 a.m., Eldar Akchurin wrote:
>> Hi Amos,
> 
>> Thanks a lot for the hint! Specifying LIBS="-lws2_32" fixes this 
>> particular issue. Let's see what comes up next.
> 
>> --e
> 
> Great! thank you. I have added that to Squid-3. For the next
> release you should not have to explicitly define it or the 0x601
> version options.

Actually, spoke too soon. I have been testing prior to the commit and
it seems this does not work for me.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlYOcAAoJELJo5wb/XPRjPg0H/34HEDJvxJzxmuFIcavcRmCt
3BxwAUeVb07e5gX96wEcVboaKgCqWuYrjtGEnUv11E3Uo3wvmBtw83U8eFxb2DEv
9+FOSy59Q20oFmErmNHlWTEHfdc+I9G5aSIxQxSefvANAV3foTS7cOR8M4RBuLhp
SumXc/p3qtp4HhNYpab/qXwuAxXsEPuQtTzocEOFOiRrQa1HIHvjj5hYcy3/BICE
E4jdqNinpJ9EO2w8hDqwfGqn//mFJMf+/wcg8z9u6NED8xmt/7ihVaYZTy9p8YOk
b21/9AdcvuniiC50YATzhyM8Uk8GdsmN9xUBhVKy6SP8Dd9dGIYThfYE2cg3pf0=
=/ab+
-----END PGP SIGNATURE-----


From ahmed.zaeem at netstream.ps  Sun Dec 21 00:22:57 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Sat, 20 Dec 2014 16:22:57 -0800
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <5495839C.90503@treenet.co.nz>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>,
 <54942D75.3020908@treenet.co.nz> <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>
 <54948EC0.9000406@treenet.co.nz> <5495839C.90503@treenet.co.nz>
Message-ID: <001401d01cb4$465ff850$d31fe8f0$@netstream.ps>

HI Amos , I tried with 3.4.7 but it has same result !!!!

Here is after compilation :
squid -v
Squid Cache: Version 3.4.7
configure options:  'CXXFLAGS=DMAXTCPLISTENPORTS=10000' '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=drx' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-arp-acl' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=131072' '--with-large-files' '--with-default-user=squid' '--enable-linux-netfilter' 'CFLAGS=-g -O2 -g -Wall -O2' 'LDFLAGS=' 'CPPFLAGS=' 'CXXFLAGS=-g -O2 -g -Wall -O2' '--enable-ltdl-convenience'
[root at Proxy squid-3.4.7]#


Here is log logs :
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.




Any Help ?????

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Saturday, December 20, 2014 6:12 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Problem with running squid 3.5 on windows 7

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 9:46 a.m., Amos Jeffries wrote:
> On 20/12/2014 7:05 a.m., Eldar Akchurin wrote:
>> Hi Amos,
> 
>> Thanks a lot for the hint! Specifying LIBS="-lws2_32" fixes this 
>> particular issue. Let's see what comes up next.
> 
>> --e
> 
> Great! thank you. I have added that to Squid-3. For the next release 
> you should not have to explicitly define it or the 0x601 version 
> options.

Actually, spoke too soon. I have been testing prior to the commit and it seems this does not work for me.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlYOcAAoJELJo5wb/XPRjPg0H/34HEDJvxJzxmuFIcavcRmCt
3BxwAUeVb07e5gX96wEcVboaKgCqWuYrjtGEnUv11E3Uo3wvmBtw83U8eFxb2DEv
9+FOSy59Q20oFmErmNHlWTEHfdc+I9G5aSIxQxSefvANAV3foTS7cOR8M4RBuLhp
SumXc/p3qtp4HhNYpab/qXwuAxXsEPuQtTzocEOFOiRrQa1HIHvjj5hYcy3/BICE
E4jdqNinpJ9EO2w8hDqwfGqn//mFJMf+/wcg8z9u6NED8xmt/7ihVaYZTy9p8YOk
b21/9AdcvuniiC50YATzhyM8Uk8GdsmN9xUBhVKy6SP8Dd9dGIYThfYE2cg3pf0=
=/ab+
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Sat Dec 20 14:37:40 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 Dec 2014 03:37:40 +1300
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <001401d01cb4$465ff850$d31fe8f0$@netstream.ps>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>,
 <54942D75.3020908@treenet.co.nz> <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>
 <54948EC0.9000406@treenet.co.nz> <5495839C.90503@treenet.co.nz>
 <001401d01cb4$465ff850$d31fe8f0$@netstream.ps>
Message-ID: <549589B4.1070708@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Wrong thread...

On 21/12/2014 1:22 p.m., Ahmed Allzaeem wrote:
> HI Amos , I tried with 3.4.7 but it has same result !!!!
> 
> Here is after compilation : squid -v Squid Cache: Version 3.4.7 
> configure options:  'CXXFLAGS=DMAXTCPLISTENPORTS=10000'

Missing a '-' sign before the 'D' on this one. And ...

> 'CXXFLAGS=-g -O2 -g -Wall -O2' '--enable-ltdl-convenience'

... you are defining it twice. Removethis secodn one, Squid configure
script figures out the -g/-O-Wall options by itself.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlYm0AAoJELJo5wb/XPRjKBgH/1DumfpZ20xZ31zqrJF4oVmV
391I+cY9mYk5ulcxRS/YkrV5IBsGrjzHEa2Aw/VRfqltqiLe+FzpabNUTppLGnez
k7cfiN/KIKX2mSV2FUCzQBBk0K+sH18Rq09UEoiA1brmAe0iUCAvCw3fgeCLinnB
idSmzOuwbKtlpNl1QsT5Gg5Axh5FDYW4CdPThIy4DFxw47wC15URuT3NmKWudbIJ
Sr3q0GBhTrZPpbsQsWqJ78sroaM+1RB5vRLNbqUbBnyZHod5UV9PR3d/BfGUdBLl
ud/odbG0Wde8/WoQpHoxnjfKkYjA6ttK1UbNugBB4unmI0WlIevGgt0/aLAH5mA=
=zEcR
-----END PGP SIGNATURE-----


From ahmed.zaeem at netstream.ps  Sun Dec 21 00:40:36 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Sat, 20 Dec 2014 16:40:36 -0800
Subject: [squid-users] squid with multiple ips is listenting to some ips
	with port and not all of ips ??!!
In-Reply-To: <54957C34.60002@treenet.co.nz>
References: <000001d01c89$58f08780$0ad19680$@netstream.ps>
 <000a01d01c95$9afe3440$d0fa9cc0$@netstream.ps> <54957C34.60002@treenet.co.nz>
Message-ID: <001501d01cb6$bde6a7a0$39b3f6e0$@netstream.ps>

HI Amos , I tried with 3.4.7 but it has same result !!!!

Here is after compilation :
squid -v
Squid Cache: Version 3.4.7
configure options:  'CXXFLAGS=DMAXTCPLISTENPORTS=10000' '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=drx' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-arp-acl' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=131072' '--with-large-files' '--with-default-user=squid' '--enable-linux-netfilter' 'CFLAGS=-g -O2 -g -Wall -O2' 'LDFLAGS=' 'CPPFLAGS=' 'CXXFLAGS=-g -O2 -g -Wall -O2' '--enable-ltdl-convenience'
[root at Proxy squid-3.4.7]#


Here is log logs :
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.




Any Help ?????


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Saturday, December 20, 2014 5:40 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid with multiple ips is listenting to some ips with port and not all of ips ??!!

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 21/12/2014 9:43 a.m., Ahmed Allzaeem wrote:
> Hi Guys I thunk I found the reason . but didn't fix it now !!!
> 
> 
> 
> I ran squid in debug mode and I had :
> 
> 014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.
> 
> 2014/12/20 05:38:23|          The limit is 128
> 
> 2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.
> 
> 2014/12/20 05:38:23|          The limit is 128
> 
> 2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.
> 
> 2014/12/20 05:38:23|          The limit is 128
> 
> 2014/12/20 05:38:23| WARNING: You have too many 'http_port' lines.
> 
> 
> 
> 
> 
> As we see there is limitation to 128 ips ,
> 
> How can I increase this value ???
> 


You can increase it if you really have to by building the latest version of Squid (3.4.7 or later anyway) using:
  ./configure CXXFLAGS="-DMAXTCPLISTENPORTS=256"

 or whichever number you want to increase it to.

For each packet read Squid has to check the listening port list to see if it is a read() or accept() operation. Doing even 128 checks per packet is pushing the boundaries for reasonable performance loss.


Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlXw0AAoJELJo5wb/XPRjru8IAJZ6KfAKIyzMHeC3SFdTdAg+
TjnXR7rSJSU5f53arEPa2vA16F0PxkWXFwjpmG01TuMaDLqg8PROdnWvITYka6+k
D/bqhylRSeE95T9uO8Sdy0gQTHf4Y1To6w77qlNSrpK2j5e32N25dEmQVm2zMa9n
8d044+BWuwMJq9sessLjnYtZEffN1DQCWpjevZx1sa5rvIVBgv1S3RRY2jIrgcMW
XvdMCYlbawGQ997B/BDGttlN8aNf/t1NqAe5ckn9FTKlVYgL/tbRjkC00vtUxzb0
75Yz8b/SONVK5E6BDcfffVvrY0KUvKZrbauhTQ68uFzGpv1Cv/ynTaqyp2NlDQ0=
=HJ+Q
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ahmed.zaeem at netstream.ps  Sun Dec 21 00:41:08 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Sat, 20 Dec 2014 16:41:08 -0800
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <001401d01cb4$465ff850$d31fe8f0$@netstream.ps>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>,
 <54942D75.3020908@treenet.co.nz> <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>
 <54948EC0.9000406@treenet.co.nz> <5495839C.90503@treenet.co.nz>
 <001401d01cb4$465ff850$d31fe8f0$@netstream.ps>
Message-ID: <001601d01cb6$d0fd9650$72f8c2f0$@netstream.ps>

Sorry guys it was a typo from me , I corrected it in the right discussion thread.
cheers

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Ahmed Allzaeem
Sent: Saturday, December 20, 2014 4:23 PM
To: 'Amos Jeffries'; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Problem with running squid 3.5 on windows 7

HI Amos , I tried with 3.4.7 but it has same result !!!!

Here is after compilation :
squid -v
Squid Cache: Version 3.4.7
configure options:  'CXXFLAGS=DMAXTCPLISTENPORTS=10000' '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=drx' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-arp-acl' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=131072' '--with-large-files' '--with-default-user=squid' '--enable-linux-netfilter' 'CFLAGS=-g -O2 -g -Wall -O2' 'LDFLAGS=' 'CPPFLAGS=' 'CXXFLAGS=-g -O2 -g -Wall -O2' '--enable-ltdl-convenience'
[root at Proxy squid-3.4.7]#


Here is log logs :
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.
2014/12/20 15:22:15|          The limit is 128 HTTP ports.
2014/12/20 15:22:15| WARNING: You have too many 'http_port' lines.




Any Help ?????

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Saturday, December 20, 2014 6:12 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Problem with running squid 3.5 on windows 7

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/12/2014 9:46 a.m., Amos Jeffries wrote:
> On 20/12/2014 7:05 a.m., Eldar Akchurin wrote:
>> Hi Amos,
> 
>> Thanks a lot for the hint! Specifying LIBS="-lws2_32" fixes this 
>> particular issue. Let's see what comes up next.
> 
>> --e
> 
> Great! thank you. I have added that to Squid-3. For the next release 
> you should not have to explicitly define it or the 0x601 version 
> options.

Actually, spoke too soon. I have been testing prior to the commit and it seems this does not work for me.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlYOcAAoJELJo5wb/XPRjPg0H/34HEDJvxJzxmuFIcavcRmCt
3BxwAUeVb07e5gX96wEcVboaKgCqWuYrjtGEnUv11E3Uo3wvmBtw83U8eFxb2DEv
9+FOSy59Q20oFmErmNHlWTEHfdc+I9G5aSIxQxSefvANAV3foTS7cOR8M4RBuLhp
SumXc/p3qtp4HhNYpab/qXwuAxXsEPuQtTzocEOFOiRrQa1HIHvjj5hYcy3/BICE
E4jdqNinpJ9EO2w8hDqwfGqn//mFJMf+/wcg8z9u6NED8xmt/7ihVaYZTy9p8YOk
b21/9AdcvuniiC50YATzhyM8Uk8GdsmN9xUBhVKy6SP8Dd9dGIYThfYE2cg3pf0=
=/ab+
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ahmed.zaeem at netstream.ps  Sun Dec 21 01:14:11 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Sat, 20 Dec 2014 17:14:11 -0800
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <549589B4.1070708@treenet.co.nz>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>,
 <54942D75.3020908@treenet.co.nz> <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>
 <54948EC0.9000406@treenet.co.nz> <5495839C.90503@treenet.co.nz>
 <001401d01cb4$465ff850$d31fe8f0$@netstream.ps>
 <549589B4.1070708@treenet.co.nz>
Message-ID: <001701d01cbb$6f053a20$4d0fae60$@netstream.ps>

Amos,
Thank you .
It worked :)
Great thanks again
cheers

-----Original Message-----
From: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Sent: Saturday, December 20, 2014 6:38 AM
To: Ahmed Allzaeem; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Problem with running squid 3.5 on windows 7

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Wrong thread...

On 21/12/2014 1:22 p.m., Ahmed Allzaeem wrote:
> HI Amos , I tried with 3.4.7 but it has same result !!!!
> 
> Here is after compilation : squid -v Squid Cache: Version 3.4.7 
> configure options:  'CXXFLAGS=DMAXTCPLISTENPORTS=10000'

Missing a '-' sign before the 'D' on this one. And ...

> 'CXXFLAGS=-g -O2 -g -Wall -O2' '--enable-ltdl-convenience'

... you are defining it twice. Removethis secodn one, Squid configure script figures out the -g/-O-Wall options by itself.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlYm0AAoJELJo5wb/XPRjKBgH/1DumfpZ20xZ31zqrJF4oVmV
391I+cY9mYk5ulcxRS/YkrV5IBsGrjzHEa2Aw/VRfqltqiLe+FzpabNUTppLGnez
k7cfiN/KIKX2mSV2FUCzQBBk0K+sH18Rq09UEoiA1brmAe0iUCAvCw3fgeCLinnB
idSmzOuwbKtlpNl1QsT5Gg5Axh5FDYW4CdPThIy4DFxw47wC15URuT3NmKWudbIJ
Sr3q0GBhTrZPpbsQsWqJ78sroaM+1RB5vRLNbqUbBnyZHod5UV9PR3d/BfGUdBLl
ud/odbG0Wde8/WoQpHoxnjfKkYjA6ttK1UbNugBB4unmI0WlIevGgt0/aLAH5mA=
=zEcR
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Sat Dec 20 20:40:43 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 21 Dec 2014 02:40:43 +0600
Subject: [squid-users] Is squid2/3 ufs/diskd cache formats compatible?
Message-ID: <5495DECB.6010006@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Hi gents,

does enybody tell me, please,

is squid2 and squid3 compatible or not by cache formats?

Interested ufs/diskd format and dependency from squid binaries.

I plan to migrate production server and want to keep warmed cache. ;)

WBR,

Yuri
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUld7LAAoJENNXIZxhPexGXHgH/iSl2sY9y24x9nUzxQZmp6pt
g8lPFf1gQmy8dOchVvFS8LePBW+ca0JUODKZ/mP7Y7Vh8Vw5LGuw+U+hb+CXTsGk
lu6jL+N6gFgdME+68S6obR7/AzOoZ0rp0Ylmw3bn962JVam+wlHmNunlk77N7nxc
KOGGx7roKevDpuQUx75VYZJq0tM9dIEd4gM08qzuoQfFZ+fnoqKc1z0nqRnaAZBL
WzyBa1wV2J1s7ENINIhb9Uz49z95xMqBg8YQ81OkFSApz5Q/IljNsXwosCwS3bRK
eAzkplGQFmoIKNJvX7mBMefSItu6cNFkVVz5DEvZcly3h8S3rc8BxP8ikAJ1Jxg=
=Ofiu
-----END PGP SIGNATURE-----



From alfrenovsky at gmail.com  Sat Dec 20 21:12:03 2014
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Sat, 20 Dec 2014 18:12:03 -0300
Subject: [squid-users] ERR_CONNECT_FAIL 110
In-Reply-To: <549449F2.6040005@treenet.co.nz>
References: <5494428F.2040805@fing.uncu.edu.ar>
 <549449F2.6040005@treenet.co.nz>
Message-ID: <5495E623.7070407@gmail.com>

El 19/12/14 a las 12:53, Amos Jeffries escibi?:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 20/12/2014 4:21 a.m., Alfredo Rezinovsky wrote:
>> I have a few TPROXY implementations with squid. In only one of
>> them recently I'm getting lots of: "x-squid-error: ERR_CONNECT_FAIL
>> 110" and some 504 timeouts.
>>
>> Squid Cache: Version 3.4.10-20141218-r13197 configure options:
>> '--prefix=/opt/sepia/squid' '--sysconfdir=/var/lib/sepia/'
>> '--disable-auth' '--disable-auto-locale' '--disable-cache-digests'
>> '--disable-cpu-profiling' '--disable-debug-cbdata'
>> '--disable-delay-pools' '--disable-devpoll' '--disable-ecap'
>> '--disable-esi' '--disable-eui' '--disable-external-acl-helpers'
>> '--disable-follow-x-forwarded-for' '--disable-forw-via-db'
>> '--enable-gnuregex' '--disable-htcp' '--disable-icap-client'
>> '--disable-ident-lookups' '--enable-internal-dns'
>> '--disable-ipf-transparent' '--disable-ipfw-transparent'
>> '--disable-ipv6' '--disable-leakfinder' '--disable-pf-transparent'
>> '--disable-poll' '--disable-select' '--disable-snmp' '--enable-ssl'
>> '--disable-stacktraces' '--disable-translation'
>> '--disable-url-rewrite-helpers' '--disable-wccp' '--disable-wccpv2'
>> '--disable-win32-service' '--disable-x-accelerator-vary'
>> '--disable-icmp' '--disable-storeid-rewrite-helpers'
>> '--enable-async-io' '--enable-disk-io' '--enable-epoll'
>> '--enable-http-violations' '--enable-inline'
>> '--enable-kill-parent-hack' '--enable-linux-netfilter'
>> '--enable-log-daemon-helpers' '--enable-removal-policies'
>> '--enable-storeio' '--enable-unlinkd'
>> '--enable-x-accelerator-vary' '--enable-zph-qos'
>> '--with-default-user=nobody' '--with-logdir=/var/log/sepia'
>> '--with-pthreads' '--with-included-ltdl'
>> '--with-pidfile=/var/lib/sepia/squid.pid'
>> '--with-netfilter-conntrack' --enable-ltdl-convenience
>>
>> Is a custom compiled squid with everything I don't need disabled.
>>
>> Running in Ubuntu with kernel 3.13.0
>>
>> PMTU from the proxy to both the servers and the clients seems to be
>> 1500.
>>
>> Any clue?
> Nope you omitted the best clues. :-)
>
> The access.log entries matching those errors would be a good start if
> you can identify them.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUlEnxAAoJELJo5wb/XPRjZ0IIAIw6hUQdmnVtXEF7UU0o5Zp6
> Q3zhRdXfNVuqc7xHgmyakD8UIsLM8lmKb/43qiHqvbU9ZVvg0WslloSS05eDjG6m
> FcTzgeVaQJImiSvkZ2Ei6MGlLgiuxDR4BIUxRWxhhuD7UFvsG8Ese45yM55ivq6C
> ocEThNWHZYbwTsCbKOIZz5Be6pEHVh8EkNAIAl7+/+cnXG6fc7qUPnG471piOu4a
> LNnhJdDqlYhe3vwKcVSN0aIjz+lrtB6tMs4DDT2GpX+LZ6tOIihsCZOHij31M4Z2
> qpVWs4i4r7aKmideSYMsr2SSd9s8zzLGel3ReXuPhKvFZsZOiP8uZtBJEm47n/4=
> =tGQM
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
Shame on me

1419108172.470  29936 172.16.1.2 TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ - ORIGINAL_DST/172.233.13.247 -
1419108202.446  29971 172.16.1.2 TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ - ORIGINAL_DST/172.233.13.247 -
1419108212.325  30029 172.16.1.2 TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ - ORIGINAL_DST/172.233.13.247 -
1419108232.487  30029 172.16.1.2 TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ - ORIGINAL_DST/172.233.13.247 -
1419108262.453  29814 172.16.1.2 TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ - ORIGINAL_DST/172.233.13.247 -
1419108294.101  59408 172.16.1.2 TCP_MISS/503 469 GET http://xml.weather.yahoo.com/forecastrss? - ORIGINAL_DST/206.190.43.214 text/html
1419108295.670  60800 172.16.1.2 TCP_MISS/503 469 GET http://download.finance.yahoo.com/d/333.txt? - ORIGINAL_DST/209.191.96.200 text/html

All 503 errors are around 60 seconds.
The same requests works whe the tproxy is not enabled.




From al.akchurin at hotmail.com  Sat Dec 20 22:58:27 2014
From: al.akchurin at hotmail.com (Eldar Akchurin)
Date: Sat, 20 Dec 2014 23:58:27 +0100
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <5495839C.90503@treenet.co.nz>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>
 <54939693.3060102@treenet.co.nz>, ,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>, ,
 <54942D75.3020908@treenet.co.nz>
 <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>, <54948EC0.9000406@treenet.co.nz>,
 <5495839C.90503@treenet.co.nz>
Message-ID: <DUB128-W78DFD91541BE4FF2230E56ED680@phx.gbl>

Hi Amos,
 
Hmm, after checking I found out that this fix works only for 64 bit. 
When I try this on 32, both mingw on Cygwin and Ubuntu cannot identify presence of getaddrinfo.
 
It seems the 32 bit version of libws2_32 is compiled with "stdcall", i.e. the following works:
 
#ifdef __cplusplus
extern "C"
#endif
char __attribute__((__stdcall__)) getaddrinfo(int, int, int, int); // 
 
// AUTOCONF tries out the below one (which does not mingle @16)
// char getaddrinfo();
// return getaddrinfo();
 
int
main ()
{
    return getaddrinfo(0,0,0,0);
  ;
  return 0;
} 
 
I also found the following report, which kind of confirms what I see (https://patches.libav.org/patch/545/):
This moves network_extralibs setup before use so that the link test
works correctly on mingw-w64.  mingw32 still fails to detect it due
to calling convention differences; getaddrinfo() is STDCALL, so it
is mangled as getaddrinfo at 16 on x86.

Unfortunately, my background is windows, so I'm new to autoconf and all unix business. What do you think will be the right approach here? Maybe AC_CECK_DECL instead of AC_REPLACE_FUNC for getaddrinfo (and maybe some other funcs declared in the same lib)?
 
Thank you very much for all your help, really appreciate it!
 
--e
 
> Date: Sun, 21 Dec 2014 03:11:40 +1300
> From: squid3 at treenet.co.nz
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problem with running squid 3.5 on windows 7
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> On 20/12/2014 9:46 a.m., Amos Jeffries wrote:
> > On 20/12/2014 7:05 a.m., Eldar Akchurin wrote:
> >> Hi Amos,
> > 
> >> Thanks a lot for the hint! Specifying LIBS="-lws2_32" fixes this 
> >> particular issue. Let's see what comes up next.
> > 
> >> --e
> > 
> > Great! thank you. I have added that to Squid-3. For the next
> > release you should not have to explicitly define it or the 0x601
> > version options.
> 
> Actually, spoke too soon. I have been testing prior to the commit and
> it seems this does not work for me.
> 
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
> 
> iQEcBAEBAgAGBQJUlYOcAAoJELJo5wb/XPRjPg0H/34HEDJvxJzxmuFIcavcRmCt
> 3BxwAUeVb07e5gX96wEcVboaKgCqWuYrjtGEnUv11E3Uo3wvmBtw83U8eFxb2DEv
> 9+FOSy59Q20oFmErmNHlWTEHfdc+I9G5aSIxQxSefvANAV3foTS7cOR8M4RBuLhp
> SumXc/p3qtp4HhNYpab/qXwuAxXsEPuQtTzocEOFOiRrQa1HIHvjj5hYcy3/BICE
> E4jdqNinpJ9EO2w8hDqwfGqn//mFJMf+/wcg8z9u6NED8xmt/7ihVaYZTy9p8YOk
> b21/9AdcvuniiC50YATzhyM8Uk8GdsmN9xUBhVKy6SP8Dd9dGIYThfYE2cg3pf0=
> =/ab+
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141220/8720755e/attachment.htm>

From squid3 at treenet.co.nz  Sun Dec 21 03:17:16 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 Dec 2014 16:17:16 +1300
Subject: [squid-users] Is squid2/3 ufs/diskd cache formats compatible?
In-Reply-To: <5495DECB.6010006@gmail.com>
References: <5495DECB.6010006@gmail.com>
Message-ID: <54963BBC.8060100@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 21/12/2014 9:40 a.m., Yuri Voinov wrote:
> 
> Hi gents,
> 
> does enybody tell me, please,
> 
> is squid2 and squid3 compatible or not by cache formats?

Yes and no.

UFS/diskd/AUFS:
 The Squid-3 swap.state format includes a few extra checksum details
and better 32-bit 64-bit protection. There is enough compatibility
that Squid will detect which format the objects on disk are and
upgrade the mautomatically. Unfortunately this also means each current
item in your cache will likely need a network refresh when its first
used after the update. And the cache will not be compatible with
Squid-2 once its been touched by Squid-3.

For larger caches (10's of GB or more ) the best thing to do is just
erase and start clean as the DIRTY scan can take hours. Squid will
begin with slow-ish service times for some minutes but things will
improve exponentially as the cache fills up.

For smallish (few GB or less) you can erase the old cache_dir's
swap.state and let Squid do a full disk-based ("DIRTY") rebuild. If
you can do that before putting traffic through it even better.


COSS / Rock:
 COSS has been replaced by Rock in Squid-3. But the two are not binary
compatible. So an empty Rock cache is required.

If you really are desperate to preserve the data (**) you can run
Squid-2 for a few weeks with the COSS cache set to read-only and a
temporary UFS cache that can store the objects currently in COSS.
Eventually the COSS cache contents will be useless and the UFS will
contain all the useful ones. Then reserve the process after moving to
Squid-3 with Rock.


** Key thing to remember is that a cache is just a cache. *Short* term
storage for objects which are served and constantly being updated
elsewhere within the network. The data in it is always subject to erasure.


Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlju7AAoJELJo5wb/XPRjvMMIAIsma0rw9Zp9WV/loLqDKo6Q
RUoomsqMSv6aJmVQh6swn/vWlM1JFuWdDsXQKMMlnWYvebWI4llU+zErLWu/gWMx
YsG+iZaTvvl2TJutZdmRhcw/TwVGf+YoEyBNe8NowHzTbQy0TYj+5k1vK/yWl4YB
4ccQmD548F1syj8UmFhyIp9g2jzDhb3Alg8xy7VnP3ix662KSU1R5olelK34fYdJ
UMwzBxOjyOSrK9xcoKejBrdSYyLseTtjJ1EreJBYbUT5DxlilmSnzkHpwQech0uM
IvIr6h1uhXe5Rq1ASjO+VsP6GCVDqo4bTGqYi+LU0F1cy9yRHXTeEG/Y5KpLVZE=
=Upc+
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Sun Dec 21 03:31:39 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 Dec 2014 16:31:39 +1300
Subject: [squid-users] ERR_CONNECT_FAIL 110
In-Reply-To: <5495E623.7070407@gmail.com>
References: <5494428F.2040805@fing.uncu.edu.ar>
 <549449F2.6040005@treenet.co.nz> <5495E623.7070407@gmail.com>
Message-ID: <54963F1B.1000709@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 21/12/2014 10:12 a.m., Alfredo Rezinovsky wrote:
> El 19/12/14 a las 12:53, Amos Jeffries escibi?: On 20/12/2014 4:21
> a.m., Alfredo Rezinovsky wrote:
>>>> I have a few TPROXY implementations with squid. In only one
>>>> of them recently I'm getting lots of: "x-squid-error:
>>>> ERR_CONNECT_FAIL 110" and some 504 timeouts.
>>>> 
>>>> Squid Cache: Version 3.4.10-20141218-r13197 configure
>>>> options: '--prefix=/opt/sepia/squid'
>>>> '--sysconfdir=/var/lib/sepia/' '--disable-auth'
>>>> '--disable-auto-locale' '--disable-cache-digests' 
>>>> '--disable-cpu-profiling' '--disable-debug-cbdata' 
>>>> '--disable-delay-pools' '--disable-devpoll' '--disable-ecap' 
>>>> '--disable-esi' '--disable-eui'
>>>> '--disable-external-acl-helpers' 
>>>> '--disable-follow-x-forwarded-for' '--disable-forw-via-db' 
>>>> '--enable-gnuregex' '--disable-htcp' '--disable-icap-client' 
>>>> '--disable-ident-lookups' '--enable-internal-dns' 
>>>> '--disable-ipf-transparent' '--disable-ipfw-transparent' 
>>>> '--disable-ipv6' '--disable-leakfinder'
>>>> '--disable-pf-transparent' '--disable-poll'
>>>> '--disable-select' '--disable-snmp' '--enable-ssl' 
>>>> '--disable-stacktraces' '--disable-translation' 
>>>> '--disable-url-rewrite-helpers' '--disable-wccp'
>>>> '--disable-wccpv2' '--disable-win32-service'
>>>> '--disable-x-accelerator-vary' '--disable-icmp'
>>>> '--disable-storeid-rewrite-helpers' '--enable-async-io'
>>>> '--enable-disk-io' '--enable-epoll' 
>>>> '--enable-http-violations' '--enable-inline' 
>>>> '--enable-kill-parent-hack' '--enable-linux-netfilter' 
>>>> '--enable-log-daemon-helpers' '--enable-removal-policies' 
>>>> '--enable-storeio' '--enable-unlinkd' 
>>>> '--enable-x-accelerator-vary' '--enable-zph-qos' 
>>>> '--with-default-user=nobody' '--with-logdir=/var/log/sepia' 
>>>> '--with-pthreads' '--with-included-ltdl' 
>>>> '--with-pidfile=/var/lib/sepia/squid.pid' 
>>>> '--with-netfilter-conntrack' --enable-ltdl-convenience
>>>> 
>>>> Is a custom compiled squid with everything I don't need
>>>> disabled.
>>>> 
>>>> Running in Ubuntu with kernel 3.13.0
>>>> 
>>>> PMTU from the proxy to both the servers and the clients seems
>>>> to be 1500.
>>>> 
>>>> Any clue?
> Nope you omitted the best clues. :-)
> 
> The access.log entries matching those errors would be a good start
> if you can identify them.
> 
> Amos
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
> Shame on me
> 
> 1419108172.470  29936 172.16.1.2 TCP_MISS_ABORTED/000 0 GET 
> http://www.ibm.com/ - ORIGINAL_DST/172.233.13.247 - 1419108202.446
> 29971 172.16.1.2 TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ -
> ORIGINAL_DST/172.233.13.247 - 1419108212.325  30029 172.16.1.2
> TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ -
> ORIGINAL_DST/172.233.13.247 - 1419108232.487  30029 172.16.1.2
> TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ -
> ORIGINAL_DST/172.233.13.247 - 1419108262.453  29814 172.16.1.2
> TCP_MISS_ABORTED/000 0 GET http://www.ibm.com/ -
> ORIGINAL_DST/172.233.13.247 - 1419108294.101  59408 172.16.1.2
> TCP_MISS/503 469 GET http://xml.weather.yahoo.com/forecastrss? -
> ORIGINAL_DST/206.190.43.214 text/html 1419108295.670  60800
> 172.16.1.2 TCP_MISS/503 469 GET 
> http://download.finance.yahoo.com/d/333.txt? - 
> ORIGINAL_DST/209.191.96.200 text/html
> 
> All 503 errors are around 60 seconds. The same requests works whe
> the tproxy is not enabled.
> 

Okay, this says that you are intercepting the traffic. Squid tried
opening a connection to the same IP the client was connecting to.
(should work right?). But the TCP SYN packets sent out by Squid never
got any response.

Sometimes (ABORTED/000) the client gave up waiting and disconnected
after ~30sec.

Sometimes (MISS/503) Squid was the one to give up after ~60sec.

Since it is the outbound TCP connections from Squid that are dying.
Check the usual suspects:

 ICMP blocking  - only a very small sub-set of a few codes are
dangerous and need blocking, the rest are useful or mandatory for
reliable connectivity.

 path-MTU discovery - can be broken by ICMP packets being dropped or
bad MSS values on a tunnel/VPN interface,

 ECN and TCP Window Scaling - can be corrupted by old broken software
on the transit path,

 NAT on the outbound connections - can send packets to weird places.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlj8bAAoJELJo5wb/XPRjGx8H/2uyWG+PKh06b/aS1Mv5xbV8
M1p09RTLJ1gD4F4aasAQuHQyCqPI3VpyoURskr8hJWtpQjpE7dxvEMCP9fIlp7rX
ButRCUGtEOoZ1rvqNkSQKvTaWk2tO7kPg0/GDFO5k0f8s6zVDTfGbHFefSakjXm6
vPHamIBHcgVqlgC3JCqcRMgrLyZoBEyMhgCP9O4P7677TPyKKn7YeJVFquSwJ0do
8xJOsWnWd15W1waRyaHJLzn6wcv+DSJLl8NBDJF3WZqlt2Itnu/flQ2OJIdmEbXS
eB7b2oT53hf9QHeC3FpfozFuLvnj8WmsorQtvmO1rQSCY7kONH94Sk407+j+Wes=
=0UIE
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Sun Dec 21 03:43:35 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 Dec 2014 16:43:35 +1300
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <DUB128-W78DFD91541BE4FF2230E56ED680@phx.gbl>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>,
 , <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>, ,
 <54942D75.3020908@treenet.co.nz> <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>,
 <54948EC0.9000406@treenet.co.nz>,
 <5495839C.90503@treenet.co.nz> <DUB128-W78DFD91541BE4FF2230E56ED680@phx.gbl>
Message-ID: <549641E7.2000700@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 21/12/2014 11:58 a.m., Eldar Akchurin wrote:
> Hi Amos,
> 
> Hmm, after checking I found out that this fix works only for 64
> bit. When I try this on 32, both mingw on Cygwin and Ubuntu cannot
> identify presence of getaddrinfo.
> 
> It seems the 32 bit version of libws2_32 is compiled with
> "stdcall", i.e. the following works:
> 
> #ifdef __cplusplus extern "C" #endif char
> __attribute__((__stdcall__)) getaddrinfo(int, int, int, int); //
> 
> // AUTOCONF tries out the below one (which does not mingle @16) //
> char getaddrinfo(); // return getaddrinfo();
> 
> int main () { return getaddrinfo(0,0,0,0); ; return 0; }
> 
> I also found the following report, which kind of confirms what I
> see (https://patches.libav.org/patch/545/): This moves
> network_extralibs setup before use so that the link test works
> correctly on mingw-w64.  mingw32 still fails to detect it due to
> calling convention differences; getaddrinfo() is STDCALL, so it is
> mangled as getaddrinfo at 16 on x86.
> 
> Unfortunately, my background is windows, so I'm new to autoconf and
> all unix business. What do you think will be the right approach
> here? Maybe AC_CECK_DECL instead of AC_REPLACE_FUNC for getaddrinfo
> (and maybe some other funcs declared in the same lib)?
> 


Aha. That explains it, my build VM is an old 32-bit.

AC_CECK_DECL might work. getaddrinfo/getnameinfo/inet_ntop/inet_pton
are the key ones for IP parsing. If not a full replacement lookup macro.

I am going to be delving into the configure.ac logics to add some new
definitions for Solaris IP-Filter after the holidays. Might as well
write a new one for Windows getaddrinfo() while I'm doing that.


> Thank you very much for all your help, really appreciate it!
> 
> --e

No, thank you for yours. I have been procrastinating a bit much on
this project.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlkHnAAoJELJo5wb/XPRjYoMH/RmApzGhNDemo6x+MXmVzUsf
a8M+JY2OFminwNAJ3SNoz7SBmO6Kmi0fvh6f7LeJfmG6utr0M0/lqCFL9MZ8RDUs
a9COhruK0Mwrs25z0kgzXSaZ6c4qV0mbCEeuUMGTnNKIkSkCflkljt1PMJ3O1+ou
A+8EKWaMlXLXGOpVSqctwzkJex0B+cDOnaQ1j6cpioW7TZK+OyRGqj+BYB/GmVt4
sxZX0UmsTmcTgFvKx1TbbUJPHpYy3PdJcIWlKRiMbL3FJQh4VmAc64g96qiOSXYF
72N9jQ8NTYVc/Gns0c8vse2kN/BSJk8uSFfvS9FXeFjtCvzjvBEFEQ7TUKhXaxs=
=Hs2Z
-----END PGP SIGNATURE-----


From hack.back at hotmail.com  Sun Dec 21 07:44:07 2014
From: hack.back at hotmail.com (HackXBack)
Date: Sat, 20 Dec 2014 23:44:07 -0800 (PST)
Subject: [squid-users] Error negotiating SSL connection
In-Reply-To: <1418926835993-4668748.post@n4.nabble.com>
References: <1418926835993-4668748.post@n4.nabble.com>
Message-ID: <1419147847957-4668801.post@n4.nabble.com>

with this error https pages some times open and some times no 
maybe there is any solution ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Error-negotiating-SSL-connection-tp4668748p4668801.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Sun Dec 21 18:47:18 2014
From: ahmed.zaeem at netstream.ps (Ahmed Allzaeem)
Date: Sun, 21 Dec 2014 10:47:18 -0800
Subject: [squid-users] squid with ldp authentication and with squidguard
	based on ldp group
Message-ID: <001d01d01d4e$8caa9af0$a5ffd0d0$@netstream.ps>

The problem is that squidguard is not filtering anything!!!

 

The ldp work for suthentication , I mean I can login from users in the DC ,
but all users has full permsions !!

 

I created group called "level2" and gave it to some users , but that users
still has full permission and not being filtered from anything !!

This is os is pfsense on freebsd

 

 

I will post config below :

===========================

 

Here is config

# This file is automatically generated by pfSense

# Do not edit manually !

http_port 10.0.0.1:3128

icp_port 7

dns_v4_first off

pid_filename /var/run/squid.pid

cache_effective_user proxy

cache_effective_group proxy

error_default_language en

icon_directory /usr/pbi/squid-i386/etc/squid/icons

visible_hostname pfsense

cache_mgr admin at localhost

access_log /var/squid/logs/access.log

cache_log /var/squid/logs/cache.log

cache_store_log none

sslcrtd_children 0

logfile_rotate 0

shutdown_lifetime 3 seconds

# Allow local network(s) on interface(s)

acl localnet src  10.0.0.0/24

forwarded_for off

uri_whitespace strip

 

acl dynamic urlpath_regex cgi-bin ?

cache deny dynamic

cache_mem 8 MB

maximum_object_size_in_memory 32 KB

memory_replacement_policy heap GDSF

cache_replacement_policy heap LFUDA

 

minimum_object_size 0 KB

maximum_object_size 10 KB

offline_mode off

# No redirector configured

 

 

#Remote proxies

 

 

# Setup some default acls

acl allsrc src all

acl localhost src 127.0.0.1/32

acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901  3128
1025-65535 

acl sslports port 443 563  

acl manager proto cache_object

acl purge method PURGE

acl connect method CONNECT

 

# Define protocols used for redirects

acl HTTP proto HTTP

acl HTTPS proto HTTPS

 

http_access allow manager localhost

  

http_access deny manager

http_access allow purge localhost

http_access deny purge

http_access deny !safeports

http_access deny CONNECT !sslports

 

# Always allow localhost connections

http_access allow localhost

 

request_body_max_size 0 KB

delay_pools 1

delay_class 1 2

delay_parameters 1 -1/-1 -1/-1

delay_initial_bucket_level 100

delay_access 1 allow allsrc

 

# Reverse Proxy settings

 

 

# Package Integration

auth_param basic program /usr/pbi/squid-i386/libexec/squid/squid_ldap_auth
-P -R -b 'dc=smart,dc=ps' -D 'cn=administrator,cn=Users,dc=smart,dc=ps' -w
'admin at 123' -f sAMAccountName=%s -h 192.168.1.242

auth_param basic children 100

auth_param basic realm heyyyyy

auth_param basic credentialsttl 1 hour

acl password proxy_auth REQUIRED

redirect_program /usr/pbi/squidguard-i386/bin/squidGuard -c
/usr/pbi/squidguard-i386/etc/squidGuard/squidGuard.conf

redirector_bypass off

url_rewrite_children 5

 

# Custom options

http_access allow password

 

# Setup allowed acls

# Allow local network(s) on interface(s)

http_access allow localnet

# Default block all to be sure

http_access deny allsrc

 

 

 

 

# ============================================================

# SquidGuard configuration file

# This file generated automaticly with SquidGuard configurator

# (C)2006 Serg Dvoriancev

# email: dv_serg at mail.ru

# ============================================================

 

logdir /var/squidGuard/log

dbhome /var/db/squidGuard

ldapbinddn cn=administrator,cn=Users,dc=smart,dc=ps

ldapbindpass admin at 123

ldapprotover 2

stripntdomain true

 

# 

src zozo {

                ldapusersearch
ldap://192.168.1.242/DC=smart,DC=ps?sAMAccountName?sub?(&(sAMAccountName=%s)
(memberOf=CN=level2%2cCN=Users%2cDC=smart%2cDC=ps))

                log block.log

}

 

 

# 

rew safesearch {

                s@(google..*/search?.*q=.*)@&safe=active at i

                s@(google..*/images.*q=.*)@&safe=active at i

                s@(google..*/groups.*q=.*)@&safe=active at i

                s@(google..*/news.*q=.*)@&safe=active at i

                s@(yandex..*/yandsearch?.*text=.*)@&fyandex=1 at i

                s@(search.yahoo..*/search.*p=.*)@&vm=r&v=1 at i

                s@(search.live..*/.*q=.*)@&adlt=strict at i

                s@(search.msn..*/.*q=.*)@&adlt=strict at i

                s@(.bing..*/.*q=.*)@&adlt=strict at i

                log block.log

}

 

# 

acl  {

                # 

                zozo  {

                                pass !in-addr !blk_BL_adv !blk_BL_aggressive
!blk_BL_alcohol !blk_BL_anonvpn !blk_BL_automobile_bikes
!blk_BL_automobile_boats !blk_BL_automobile_cars !blk_BL_downloads
!blk_BL_movies !blk_BL_porn !blk_BL_sex_education !blk_BL_sex_lingerie none

                                redirect
http://10.0.0.1:80/sgerror.php?url=403%20&a=%a&n=%n&i=%i&s=%s&t=%t&u=%u

                                log block.log

                }

                # 

                default  {

                                pass !blk_BL_porn !blk_BL_searchengines
!blk_BL_sex_education !blk_BL_sex_lingerie !blk_BL_shopping none

                                redirect
http://10.0.0.1:80/sgerror.php?url=403%20KKKK&a=%a&n=%n&i=%i&s=%s&t=%t&u=%u

                                rewrite safesearch

                                log block.log

                }

}

 

 

 

 

 

Any idea why suqidguard is not blocking anything ??? 

 

cheers

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141221/dd9fe918/attachment.htm>

From vdoctor at neuf.fr  Sun Dec 21 09:46:38 2014
From: vdoctor at neuf.fr (Stakres)
Date: Sun, 21 Dec 2014 01:46:38 -0800 (PST)
Subject: [squid-users] Squid 2.7,
 3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster
In-Reply-To: <1418825003303-4668738.post@n4.nabble.com>
References: <1418374260739-4668683.post@n4.nabble.com>
 <004501d01673$0f445150$2dccf3f0$@netstream.ps>
 <1418415837677-4668693.post@n4.nabble.com>
 <1418628416193-4668707.post@n4.nabble.com>
 <1418825003303-4668738.post@n4.nabble.com>
Message-ID: <1419155198462-4668803.post@n4.nabble.com>

Hi All,

New  build version 2.20
<https://sourceforge.net/projects/squidvideosbooster/>   - December 21th
2014
- New option "*-ytd*" to enable the caching function with YouTube Downloader
tools
- New websites added

More details on https://svb.unveiltech.com

Enjoy...

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraries-CDNs-Booster-tp4668683p4668803.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun Dec 21 07:52:54 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 Dec 2014 20:52:54 +1300
Subject: [squid-users] [squid-announce] Squid 3.5.0.4 beta is available
Message-ID: <54967C56.3050709@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

The Squid Software Foundation is very pleased to announce the
availability of the Squid-3.5.0.4 beta release!


This release is a bug fix and documentation update release resolving
some major issues found in the prior Squid releases.


The major changes to be aware of:

* Support http_access denials of SslBump "peeked" connections.

This bug shows up with "peek" SSL-Bump operation preventing Squid from
rejecting client connections, and "splice" connections not being
governed by the general access controls.

Starting with this release ssl_bump has the following behaviours:

- - During transparent SSL bumping, if we decide to splice at step1, do
not splice the connection immediately, but create a fake CONNECT
request first and send it through the callout code (http_access check,
ICAP/ECAP, etc.). If that fake CONNECT is denied, the code path
described below kicks in. Otherwise the connection is spliced.

- - When an error page is generated during CONNECT or transparent
bumping (e.g. because an http_access check has failed), we switch to
the "client-first" bumping mode and then serve the error page to the
client (upon receiving the first regular request on the bumped
connection).


* negotiate_kerberos_auth: MEMORY keytab and replay cache support

The Negotiate/Kerberos authentication helper has been updated to
support a MEMORY: keytab. This provides better performance over
previous versions with constant disk access.

Also, the token replay cache is now more configurable. It may be moved
from the default location as needed, or disabled entirely.



* Bug 3826: pt 2: Provide a systemd .service file for Squid

Squid is designed with a built-in daemon manager which clashes in
annoying ways with third-party daemon managers like OpenRC, Upstart,
and systemd. In particular Squid SMP support is not fully operational
under these systems.

This release provides a squid.service file under tools/ for anyone
wishing to package Squid for the systemd environment. It contains
basic signalling rules and command line arguments suitable for
managing this version of Squid via systemd (without SMP support).


* Code style reformatting

Our code style enforcement was not working properly since the Sept
2014 server outage. That has been fixed and along with it several old
bugs in the enforcement code. As a result this release includes a
large amount of style/polishing changes. It is very likely that
patches written for older releases 3.5 will need adjusting.


* Bug fixes shared with 3.4 series

This release also includes several bug fixes shared with the 3.4 stable
series in future 3.4.11 release.


All users of previous 3.5 releases are urged to upgrade to this releas
as soon as possible.

All users of 3.4 and older versions are encouraged to give this Squid
release a test run as soon as time permits. All feedback welcome.


Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
if and when you are ready to make the switch to Squid-3.5

This new release can be downloaded from our HTTP or FTP servers

http://www.squid-cache.org/Versions/v3/3.5/
ftp://ftp.squid-cache.org/pub/squid/
ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

http://www.squid-cache.org/Download/http-mirrors.html
http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/

Amos Jeffries
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlnxVAAoJELJo5wb/XPRjbXwH/0K+dbdvPW/iztgkouzQEgMY
J/ZkFZSMJBhUvcC8euL2EcnzqKoBNLJZ/8C/7k7aQRBQeilwJj++JYIRCrAd6Jlv
LlxYbqQgqOvyltwljuJTnLuZ4f84vBAtB5sPm+jWFDsNpADsKpFJwX5CVkGoA6I7
tVx9J7nE3f/uvyKgeUEbSPIO2uFtJnL0Cf+c1o3cFpwKkyc+ielVIhwJ1VHxB+o0
16F4RIhWl2bqY7w32S/9WUYfJttXMRciQp/Vsgu0IJexOAUMQRQi9zTBWW8Ius67
ce1XvGWak5OlNDSLhpauFc4z8SN8tVqKSEr6alvb5qq0ymX2a1koZZnC+v6qzBc=
=V1Xg
-----END PGP SIGNATURE-----
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From al.akchurin at hotmail.com  Sun Dec 21 14:43:46 2014
From: al.akchurin at hotmail.com (Eldar Akchurin)
Date: Sun, 21 Dec 2014 15:43:46 +0100
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <549641E7.2000700@treenet.co.nz>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>
 <54939693.3060102@treenet.co.nz>, ,
 <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>, ,
 <54942D75.3020908@treenet.co.nz>
 <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>, <54948EC0.9000406@treenet.co.nz>,
 <5495839C.90503@treenet.co.nz>
 <DUB128-W78DFD91541BE4FF2230E56ED680@phx.gbl>, <549641E7.2000700@treenet.co.nz>
Message-ID: <DUB128-W846880FC1B7B967BA72838ED690@phx.gbl>

Hi Amos,
 
I'm continuing trying to make it run on 64 bit windows.
I bumped into the following compilation error:
 
ipc_win32.cc:720:38: error: call of overloaded ?write(int&, char*&, ssize_t&)? is ambiguous

             x = write(c2p[1], buf1, x);

                                      ^

ipc_win32.cc:720:38: note: candidates are:

In file included from /usr/x86_64-w64-mingw32/sys-root/mingw/include/direct.h:10:0,

                 from ../compat/os/mswindows.h:38,

                 from ../compat/compat.h:73,

                 from ../include/squid.h:43,

                 from ipc_win32.cc:11:

/usr/x86_64-w64-mingw32/sys-root/mingw/include/io.h:329:15: note: int write(int, const void*, unsigned int)

   int __cdecl write(int _Filehandle,const void *_Buf,unsigned int _MaxCharCount) __MINGW_ATTRIB_DEPRECATED_MSVC2005;

               ^

In file included from ../compat/compat.h:73:0,

                 from ../include/squid.h:43,

                 from ipc_win32.cc:11:

../compat/os/mswindows.h:486:1: note: int write(int, const void*, size_t)

write(int fd, const void * buf, size_t siz)

 ^

Makefile:7011: recipe for target 'ipc_win32.o' failed
 
 
I suppose I need to use the second one, right (the first one seems deprecated)? 
As soon as I make it run, I will send you a patch.
 
Thank you!
 
--e
 
> Date: Sun, 21 Dec 2014 16:43:35 +1300
> From: squid3 at treenet.co.nz
> To: al.akchurin at hotmail.com; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problem with running squid 3.5 on windows 7
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> On 21/12/2014 11:58 a.m., Eldar Akchurin wrote:
> > Hi Amos,
> > 
> > Hmm, after checking I found out that this fix works only for 64
> > bit. When I try this on 32, both mingw on Cygwin and Ubuntu cannot
> > identify presence of getaddrinfo.
> > 
> > It seems the 32 bit version of libws2_32 is compiled with
> > "stdcall", i.e. the following works:
> > 
> > #ifdef __cplusplus extern "C" #endif char
> > __attribute__((__stdcall__)) getaddrinfo(int, int, int, int); //
> > 
> > // AUTOCONF tries out the below one (which does not mingle @16) //
> > char getaddrinfo(); // return getaddrinfo();
> > 
> > int main () { return getaddrinfo(0,0,0,0); ; return 0; }
> > 
> > I also found the following report, which kind of confirms what I
> > see (https://patches.libav.org/patch/545/): This moves
> > network_extralibs setup before use so that the link test works
> > correctly on mingw-w64.  mingw32 still fails to detect it due to
> > calling convention differences; getaddrinfo() is STDCALL, so it is
> > mangled as getaddrinfo at 16 on x86.
> > 
> > Unfortunately, my background is windows, so I'm new to autoconf and
> > all unix business. What do you think will be the right approach
> > here? Maybe AC_CECK_DECL instead of AC_REPLACE_FUNC for getaddrinfo
> > (and maybe some other funcs declared in the same lib)?
> > 
> 
> 
> Aha. That explains it, my build VM is an old 32-bit.
> 
> AC_CECK_DECL might work. getaddrinfo/getnameinfo/inet_ntop/inet_pton
> are the key ones for IP parsing. If not a full replacement lookup macro.
> 
> I am going to be delving into the configure.ac logics to add some new
> definitions for Solaris IP-Filter after the holidays. Might as well
> write a new one for Windows getaddrinfo() while I'm doing that.
> 
> 
> > Thank you very much for all your help, really appreciate it!
> > 
> > --e
> 
> No, thank you for yours. I have been procrastinating a bit much on
> this project.
> 
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
> 
> iQEcBAEBAgAGBQJUlkHnAAoJELJo5wb/XPRjYoMH/RmApzGhNDemo6x+MXmVzUsf
> a8M+JY2OFminwNAJ3SNoz7SBmO6Kmi0fvh6f7LeJfmG6utr0M0/lqCFL9MZ8RDUs
> a9COhruK0Mwrs25z0kgzXSaZ6c4qV0mbCEeuUMGTnNKIkSkCflkljt1PMJ3O1+ou
> A+8EKWaMlXLXGOpVSqctwzkJex0B+cDOnaQ1j6cpioW7TZK+OyRGqj+BYB/GmVt4
> sxZX0UmsTmcTgFvKx1TbbUJPHpYy3PdJcIWlKRiMbL3FJQh4VmAc64g96qiOSXYF
> 72N9jQ8NTYVc/Gns0c8vse2kN/BSJk8uSFfvS9FXeFjtCvzjvBEFEQ7TUKhXaxs=
> =Hs2Z
> -----END PGP SIGNATURE-----
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141221/37b0f626/attachment.htm>

From squid3 at treenet.co.nz  Sun Dec 21 14:57:19 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 22 Dec 2014 03:57:19 +1300
Subject: [squid-users] Problem with running squid 3.5 on windows 7
In-Reply-To: <DUB128-W846880FC1B7B967BA72838ED690@phx.gbl>
References: <DUB128-W55525A3B23BC7997B586EDED6A0@phx.gbl>	<54939693.3060102@treenet.co.nz>,
 , <CAD5EgYppKH2dEaCyV5+UEWxsrVEOwhuLoHx7R5+1KeAsrpcAJA@mail.gmail.com>, ,
 <54942D75.3020908@treenet.co.nz> <DUB128-W386F0087439E955D2D0817ED6B0@phx.gbl>,
 <54948EC0.9000406@treenet.co.nz>,
 <5495839C.90503@treenet.co.nz> <DUB128-W78DFD91541BE4FF2230E56ED680@phx.gbl>,
 <549641E7.2000700@treenet.co.nz> <DUB128-W846880FC1B7B967BA72838ED690@phx.gbl>
Message-ID: <5496DFCF.9040808@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 22/12/2014 3:43 a.m., Eldar Akchurin wrote:
> Hi Amos,
> 
> I'm continuing trying to make it run on 64 bit windows. I bumped
> into the following compilation error:
> 
> ipc_win32.cc:720:38: error: call of overloaded ?write(int&, char*&,
> ssize_t&)? is ambiguous
> 
> x = write(c2p[1], buf1, x);
> 
> ^
> 
> ipc_win32.cc:720:38: note: candidates are:
> 
> In file included from
> /usr/x86_64-w64-mingw32/sys-root/mingw/include/direct.h:10:0,
> 
> from ../compat/os/mswindows.h:38,
> 
> from ../compat/compat.h:73,
> 
> from ../include/squid.h:43,
> 
> from ipc_win32.cc:11:
> 
> /usr/x86_64-w64-mingw32/sys-root/mingw/include/io.h:329:15: note:
> int write(int, const void*, unsigned int)
> 
> int __cdecl write(int _Filehandle,const void *_Buf,unsigned int
> _MaxCharCount) __MINGW_ATTRIB_DEPRECATED_MSVC2005;
> 
> ^
> 
> In file included from ../compat/compat.h:73:0,
> 
> from ../include/squid.h:43,
> 
> from ipc_win32.cc:11:
> 
> ../compat/os/mswindows.h:486:1: note: int write(int, const void*,
> size_t)
> 
> write(int fd, const void * buf, size_t siz)
> 
> ^
> 
> Makefile:7011: recipe for target 'ipc_win32.o' failed
> 
> 
> I suppose I need to use the second one, right (the first one seems
> deprecated)? As soon as I make it run, I will send you a patch.

Yes it is supposed to use the one defined in compat/os/mswindows.h
which in turn does the parameter conversions to call whatever the
Windows API call is.

You may need to make the read/write replacements be Scoped in Squid::
with a #define to do the mapping. Like the other I/O functions just below.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUlt/PAAoJELJo5wb/XPRjYkcIAI2H11HhVSmyUu81MB5ZVbNb
u3b1LHwF7sOaO7ayIWhtm4sh8/fwJ4Axyt2TVtDZrn4dyezuwaAPjIvL6Di56TZq
KWJpX/9KWtIu0LYNxfhBFoA+nOD3mHnqrA9D6ZH+C55nCWqVnEasKgr8JcclI3v8
HhvznNyLp/pjL++T68qjCAXgq2Vl5drhDUmvuqyzTfcTXjuy5nvD4wr9016MEob/
nBQndVVEhlmaNWPgr6EaSfVFuZuLg6noxgyUudFSlJYMn/TnWf/KMIoMNlysYF7y
uwQhYUr3k+D5rIgxSbJwHtdyBczvdVBSBghiZcwLoesI1BaaRmV7iscVZ6Zfqx8=
=Tmbu
-----END PGP SIGNATURE-----


From bpk678 at gmail.com  Sun Dec 21 21:23:58 2014
From: bpk678 at gmail.com (Brendan Kearney)
Date: Sun, 21 Dec 2014 16:23:58 -0500
Subject: [squid-users] what are people using nowadays (icap, a/v, etc)?
Message-ID: <1419197038.30825.30.camel@desktop.bpk2.com>

i have been running Squid with DansGuardian, ClamAV and Privoxy for
quite some time, and have been successful and moderately pleased with
functionality and performance.

while DG has been a means for me to perform A/V scanning at the
infrastructure layer via ClamAV, the penalty has been losing HTTP/1.1
compression and cache controls.  because DG downgrades everything to
HTTP/1.0, i feel i am not getting the most out of my squid instance
(through no fault of the software, or those who write/support it).

i am looking to move with the times, and find out what people are using
these days.  c-icap seems to use libclamav for scanning, which would
suffice, but it is not available on fedora as an rpm in repos, it seems.
i would much prefer to have rpms from repos that are updated then have
to install packages that i rolled myself.

libecap is available, but i dont know if i need more than just that to
do a/v scanning.  squidguard, also is available, but that does not look
like it interfaces with clamav.

what are people using these days, and what feedback do you have on the
setup you have?



From rafael.akchurin at diladele.com  Sun Dec 21 22:44:18 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sun, 21 Dec 2014 22:44:18 +0000
Subject: [squid-users] what are people using nowadays (icap, a/v, etc)?
In-Reply-To: <1419197038.30825.30.camel@desktop.bpk2.com>
References: <1419197038.30825.30.camel@desktop.bpk2.com>
Message-ID: <AM3PR04MB450C74E959867B9FF967BFA8F690@AM3PR04MB450.eurprd04.prod.outlook.com>

Hello Brendan,

I would suggest looking at any ICAP server(s) to perform web filtering and AV; some docs how to build a chain of ICAP servers together to achieve at least some of your goals are at http://docs.diladele.com/faq/squid.html#is-it-possible-to-add-anti-virus-scanning-to-diladele-web-safety.

The list of available ICAP servers is http://www.squid-cache.org/Misc/icap.html.

But I am biased so these are just my two very personal cents.

Best regards,
Rafael Akchurin
Diladele B.V.

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Brendan Kearney
Sent: Sunday, December 21, 2014 10:24 PM
To: squid-users
Subject: [squid-users] what are people using nowadays (icap, a/v, etc)?

i have been running Squid with DansGuardian, ClamAV and Privoxy for quite some time, and have been successful and moderately pleased with functionality and performance.

while DG has been a means for me to perform A/V scanning at the infrastructure layer via ClamAV, the penalty has been losing HTTP/1.1 compression and cache controls.  because DG downgrades everything to HTTP/1.0, i feel i am not getting the most out of my squid instance (through no fault of the software, or those who write/support it).

i am looking to move with the times, and find out what people are using these days.  c-icap seems to use libclamav for scanning, which would suffice, but it is not available on fedora as an rpm in repos, it seems.
i would much prefer to have rpms from repos that are updated then have to install packages that i rolled myself.

libecap is available, but i dont know if i need more than just that to do a/v scanning.  squidguard, also is available, but that does not look like it interfaces with clamav.

what are people using these days, and what feedback do you have on the setup you have?

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From monahbaki at gmail.com  Mon Dec 22 10:25:21 2014
From: monahbaki at gmail.com (Monah Baki)
Date: Mon, 22 Dec 2014 05:25:21 -0500
Subject: [squid-users] Question
Message-ID: <CALP3=x_bueve3aatko=qEkTYPWhQOqjGbpgkwHmubFVzVHM4=g@mail.gmail.com>

Hi All,
How can I have 2 servers (parent/sibling) separated geographically, where
the parent does not cache requests, but the sibling does.

Certain sites will block the sibling due to its origin country, but I do
not want the server in the U.S (parent) to cache anything.



Thanks
Monah
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141222/9493bae9/attachment.htm>

From yvoinov at gmail.com  Mon Dec 22 14:34:18 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 22 Dec 2014 20:34:18 +0600
Subject: [squid-users] Squid 3.4.10 startup/shutdown core dumps
Message-ID: <54982BEA.4080703@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Hi gents,

I run subj on testing environment in transparent mode under Solaris 10
and have a bit questions. ;)

1. Squid 3 must absolutely run from root (and drops privilegies to user
squid createrd first) under Solaris 10. It absolutely can't work in
transparent when run from squid with NAT permission denied error. That
is ok, no problem.

2. When it run as root, all works like charm, but:

when startup/shutdown it write in system log (/var/adm/messages):

ec 22 20:22:24 fhtagn genunix: [ID 603404 kern.notice] NOTICE: core_log:
squid[53415] core dumped: /var/core/core.squid.53415
Dec 22 20:22:31 fhtagn genunix: [ID 603404 kern.notice] NOTICE:
core_log: squid[53377] core dumped: /var/core/core.squid.53377
Dec 22 20:22:33 fhtagn genunix: [ID 603404 kern.notice] NOTICE:
core_log: squid[53375] core dumped: /var/core/core.squid.53375
Dec 22 20:22:35 fhtagn genunix: [ID 603404 kern.notice] NOTICE:
core_log: squid[53450] core dumped: /var/core/core.squid.53450

four times on every startup/shutdown (counted by my cache_dir's - I have
four).

In core dump I see next stack:

mdb core.squid.53450
Loading modules: [ ld.so.1 libc.so.1 libuutil.so.1 ]
> ::stack
_ZN10Adaptation10AccessRuleD1Ev+0x15()
_ZN10Adaptation6Config10FreeAccessEv+0x52()
_ZN10Adaptation6Config11freeServiceEv+0x11()
_ZN10Adaptation6ConfigD1Ev+0x1f()
0x7e9280()
0x517327()
_fini+9()
libc.so.1`_exithandle+0x3b()
libc.so.1`exit+0x11()
_Z9SquidMainiPPc+0x991()
main+0xc()
_start+0x6c()
>

This dump is produced when Squid runs by own user. I don't know, what
thie means ;)

When runs as root, the dump is not produced with next messages in system
log:

Dec 22 20:16:07 fhtagn genunix: [ID 603404 kern.notice] NOTICE:
core_log: squid[52387] setid process, core not dumped:
/var/core/core.squid.52387
Dec 22 20:16:13 fhtagn genunix: [ID 603404 kern.notice] NOTICE:
core_log: squid[48867] setid process, core not dumped:
/var/core/core.squid.48867
Dec 22 20:16:13 fhtagn genunix: [ID 603404 kern.notice] NOTICE:
core_log: squid[48865] setid process, core not dumped:
/var/core/core.squid.48865
Dec 22 20:16:14 fhtagn genunix: [ID 603404 kern.notice] NOTICE:
core_log: squid[52419] setid process, core not dumped:
/var/core/core.squid.52419

In cache.log the same time I've got fatal error AFTER shutdown:

2014/12/22 20:22:28 kid1| Open FD UNSTARTED     6 devpoll ctl
2014/12/22 20:22:28 kid1| Open FD UNSTARTED     7 DNS Socket IPv6
2014/12/22 20:22:28 kid1| Open FD UNSTARTED     8 DNS Socket IPv4
2014/12/22 20:22:28 kid1| Open FD UNSTARTED    11 IPC UNIX STREAM Parent
2014/12/22 20:22:28 kid1| Open FD UNSTARTED    17 squid -> diskd
2014/12/22 20:22:28 kid1| Open FD UNSTARTED    21 squid -> diskd
2014/12/22 20:22:28 kid1| Open FD UNSTARTED    25 squid -> diskd
2014/12/22 20:22:28 kid1| Open FD UNSTARTED    29 squid -> diskd
2014/12/22 20:22:28 kid1| Squid Cache (Version 3.4.10): Exiting normally.
FATAL: Received Segment Violation...dying.
2014/12/22 20:22:28 kid1| storeDirWriteCleanLogs: Starting...
2014/12/22 20:22:33 kid1| Set Current Directory to /var/core
2014/12/22 20:22:33 kid1| Starting Squid Cache version 3.4.10 for
i386-pc-solaris2.10...

BTW, squid works itself. All ok, interception working, helpers works
like charm.

But this errors in system log are annoying and badly looking on server
console. :)

What I'm doing wrong?

WBR, Yuri
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEbBAEBAgAGBQJUmCvqAAoJENNXIZxhPexGpR0H90AhbqPFbwS+++QC4MNRilEl
vGE+6rL2LHe8fvlutdlKKmovcocg8ODpb6eBCpWCk+KAmSTuJIii8LcORYpIVppa
wy1LIrz3kwL8p3vFV+DvxpYtOLQjU2D0pmiJE2b3UHlm3jHsbAhcjAn9KbdDhjOr
uDtsesej0NUzN2LXBFeo20uD5GDYTsZSipwE0/DFYEy+uJ08quJQk9IQTcfs1vFr
Mkx+ooBko/CA2Yy0s/4jS/W6s1tF3C/79VnKK88JOalXlm6M39T7DDQHD667diit
Qd8Cmv7ceEmWky2wfxJWeLpCJdHK7HGL4tYFXEzCAy3Oj1u/mjJjW123Oe+kBg==
=xwzb
-----END PGP SIGNATURE-----




From squid3 at treenet.co.nz  Mon Dec 22 20:57:28 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 Dec 2014 09:57:28 +1300
Subject: [squid-users] Squid 3.4.10 startup/shutdown core dumps
In-Reply-To: <54982BEA.4080703@gmail.com>
References: <54982BEA.4080703@gmail.com>
Message-ID: <549885B8.2030500@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

This is bug 4057.

It is fixed in the latest daily snapshot for 3.4 series. Or the patch
can be downloaded from here:
http://www.squid-cache.org/Versions/v3/3.4/changesets/

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUmIW4AAoJELJo5wb/XPRjNs4IANok2rF0Cwq01bweUl9b6/Nx
qVHh+/Rliwa6E8CjP0SwXvhDoHTYOa3ovht7kA4kKuUgMI+sSbWBzqc6t7FC6Pcd
0SLej8Ti5GvCbym1zRvwOmLPRDJAmavAG2OdCJ037Py8xpJmQeGxR2pHEThWITjh
1Am4LYAZ0aQbsKPmO6xr0bT/h7/bAqcVBg8oNvU5hi27YX7XUuP0Vfuwx2avD+DM
WvUAJM3+cmF69kcbNYuQFnxuaRA5pAAy7fxT5NZWxHX/rESg/C9IxdJg5Bizj9Ms
eyWJexNXDlPlhN9q/nccn+VE5wDsFey3p+JQJjXLRWULewoIn8WhNoNfQ8yu5J0=
=HbO0
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Mon Dec 22 21:26:04 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 Dec 2014 10:26:04 +1300
Subject: [squid-users] Question
In-Reply-To: <CALP3=x_bueve3aatko=qEkTYPWhQOqjGbpgkwHmubFVzVHM4=g@mail.gmail.com>
References: <CALP3=x_bueve3aatko=qEkTYPWhQOqjGbpgkwHmubFVzVHM4=g@mail.gmail.com>
Message-ID: <54988C6C.5020709@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 22/12/2014 11:25 p.m., Monah Baki wrote:
> Hi All, How can I have 2 servers (parent/sibling) separated
> geographically, where the parent does not cache requests, but the
> sibling does.
> 

In the proxy that you do not want to cache anything add to squid.conf:
 cache deny all

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUmIxsAAoJELJo5wb/XPRjUQYH/03tVdPNCL5Y9kC2gZ9Rxg61
YJ3iCEWakncRywlIZAXJKYPwVL+pllMstUr4f1DPqFAHDrk9oCABodzFdmBty5Q6
Sk0AVF/wC6UOIflUExl2NA/Dd1/roXOs0nktuIcbov9fSjv4Kz6Fz6uChr1t84Gl
Z8w4olYfTGTCUVueistHbgUU2B+kMYBwBBFEVCz9FyWBTjFKoibMke7JMXNlfgB6
WT8Fafl+enxY5rAjLsf7Nz2LGOvmeujh2aQYzGRul9zLBLVDu47YlLFM28IYX/mK
9/0vprQUj7yib0ixygAswgOSZXWlMa+zhH6f7X5Vac1sEd0tNdbyiCWCdCmu2T0=
=zsK8
-----END PGP SIGNATURE-----


From derek.cole at gmail.com  Mon Dec 22 21:35:02 2014
From: derek.cole at gmail.com (Derek Cole)
Date: Mon, 22 Dec 2014 16:35:02 -0500
Subject: [squid-users] squid unable to start on CentOS 6.5
Message-ID: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>

Hello,

I have a succesful version of squid installed on a CentOS 6.5 box, and
another Centos65 box where it is not working when I type "service squid
start" Both boxes have the identical squid configuration, and i ensured
that they were both running the same version, 3.4.8

>From the cache.log file:

2014/12/22 16:22:22| Set Current Directory to /var/spool/squid
2014/12/22 16:23:25| Set Current Directory to /var/spool/squid
2014/12/22 16:29:32 kid1| Set Current Directory to /var/spool/squid
2014/12/22 16:29:32 kid1| Starting Squid Cache version 3.4.8 for
x86_64-redhat-linux-gnu...
2014/12/22 16:29:32 kid1| Process ID 1555
2014/12/22 16:29:32 kid1| Process Roles: worker
2014/12/22 16:29:32 kid1| With 1024 file descriptors available
2014/12/22 16:29:32 kid1| Initializing IP Cache...
2014/12/22 16:29:32 kid1| DNS Socket created at [::], FD 7
2014/12/22 16:29:32 kid1| DNS Socket created at 0.0.0.0, FD 8
2014/12/22 16:29:32 kid1| Adding nameserver 8.8.8.8 from /etc/resolv.conf
2014/12/22 16:29:32 kid1| Logfile: opening log
daemon:/var/log/squid/access.log
2014/12/22 16:29:32 kid1| Logfile Daemon: opening log
/var/log/squid/access.log
2014/12/22 16:29:32 kid1| Local cache digest enabled; rebuild/rewrite every
3600/3600 sec
2014/12/22 16:29:32 kid1| Store logging disabled
2014/12/22 16:29:32 kid1| Swap maxSize 0 + 262144 KB, estimated 20164
objects
2014/12/22 16:29:32 kid1| Target number of buckets: 1008
2014/12/22 16:29:32 kid1| Using 8192 Store buckets
2014/12/22 16:29:32 kid1| Max Mem  size: 262144 KB
2014/12/22 16:29:32 kid1| Max Swap size: 0 KB
2014/12/22 16:29:32 kid1| Using Least Load store dir selection
2014/12/22 16:29:32 kid1| Set Current Directory to /var/spool/squid
2014/12/22 16:29:32 kid1| Finished loading MIME types and icons.
2014/12/22 16:29:32 kid1| HTCP Disabled.
2014/12/22 16:29:32 kid1| sendto FD 12: (1) Operation not permitted
2014/12/22 16:29:32 kid1| ipcCreate: CHILD: hello write test failed

from squid.out:

squid: ERROR: No running copy
2014/12/22 16:29:32| WARNING: Netmasks are deprecated. Please use CIDR
masks instead.
2014/12/22 16:29:32| WARNING: IPv4 netmasks are particularly nasty when
used to compare IPv6 to IPv4 ranges.
2014/12/22 16:29:32| WARNING: For now we will assume you meant to write /32
2014/12/22 16:29:32| WARNING: (A) '0.0.0.0' is a subnetwork of (B) '::/0'
2014/12/22 16:29:32| WARNING: because of this '0.0.0.0' is ignored to keep
splay tree searching predictable
2014/12/22 16:29:32| WARNING: You should probably remove '0.0.0.0' from the
ACL named 'all'


and from /var/log/messages:

Dec 22 16:28:06 triad02 yum[1384]: Installed: 7:squid-3.4.8-1.el6.x86_64
Dec 22 16:29:32 triad02 squid[1552]: Squid Parent: will start 1 kids
Dec 22 16:29:32 triad02 squid[1552]: Squid Parent: (squid-1) process 1555
started
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141222/0c39b04c/attachment.htm>

From eliezer at ngtech.co.il  Mon Dec 22 22:14:51 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 23 Dec 2014 00:14:51 +0200
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
Message-ID: <549897DB.6020002@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Derek,

To verify that these boxes has the same settings I would start running
the basic_data.sh script at:
http://www1.ngtech.co.il/squid/basic_data.sh

This script will might find the culprit with the issue pretty fast.
I assume you have used the RPM from my repository?

Eliezer

On 12/22/2014 11:35 PM, Derek Cole wrote:
> Hello,
> 
> I have a succesful version of squid installed on a CentOS 6.5 box,
> and another Centos65 box where it is not working when I type
> "service squid start" Both boxes have the identical squid
> configuration, and i ensured that they were both running the same
> version, 3.4.8

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmJfbAAoJENxnfXtQ8ZQUdHMIAIjStSiZ9X2knUTnlVSwE5/3
qT/G86tFgcDQXxeucbn4Vj7SK2GXQoMKrMKVDWaSykJLsl5yiS8NT17RYqi8Pdor
Vy1TCqB+ifHfSUFwrK2zMqADbD9HkN7sLB5IzBlDP8j997LMy+3MHkXH3u2VjPJZ
FD3OyOROg4SQERZlT20KA+nV5759uVgoOEXBXkMmT7jDF7ktW4AnZ6bkKhQYt46Q
hjeAFbPwTRn7Mk6fZ+wHi47ytAhRBKE3ODrVaS0+2WoRyQT3pVhprzMewz37Ef/q
21HbZp5CwPR5rdgmtHwPsAsMETgPGJPpo02xF5j2fFFFUB1FeuRv2Hhr3x4j+eo=
=xP2t
-----END PGP SIGNATURE-----


From derek.cole at gmail.com  Mon Dec 22 22:26:19 2014
From: derek.cole at gmail.com (Derek Cole)
Date: Mon, 22 Dec 2014 17:26:19 -0500
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <549897DB.6020002@ngtech.co.il>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
 <549897DB.6020002@ngtech.co.il>
Message-ID: <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>

Hello,

Yes it is true I am using the RPM repository to do the install. I have
downloaded your script and I will see if I can find any differences that
may be the culprit. In the meantime I thought I may be on to something -
but I am not sure. Is that error message one that you may get if the
iptables rules are not set up properly? I have these two boxes on different
networks, so the rules are going to be slightly different.

On Mon, Dec 22, 2014 at 5:14 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Hey Derek,
>
> To verify that these boxes has the same settings I would start running
> the basic_data.sh script at:
> http://www1.ngtech.co.il/squid/basic_data.sh
>
> This script will might find the culprit with the issue pretty fast.
> I assume you have used the RPM from my repository?
>
> Eliezer
>
> On 12/22/2014 11:35 PM, Derek Cole wrote:
> > Hello,
> >
> > I have a succesful version of squid installed on a CentOS 6.5 box,
> > and another Centos65 box where it is not working when I type
> > "service squid start" Both boxes have the identical squid
> > configuration, and i ensured that they were both running the same
> > version, 3.4.8
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQEcBAEBAgAGBQJUmJfbAAoJENxnfXtQ8ZQUdHMIAIjStSiZ9X2knUTnlVSwE5/3
> qT/G86tFgcDQXxeucbn4Vj7SK2GXQoMKrMKVDWaSykJLsl5yiS8NT17RYqi8Pdor
> Vy1TCqB+ifHfSUFwrK2zMqADbD9HkN7sLB5IzBlDP8j997LMy+3MHkXH3u2VjPJZ
> FD3OyOROg4SQERZlT20KA+nV5759uVgoOEXBXkMmT7jDF7ktW4AnZ6bkKhQYt46Q
> hjeAFbPwTRn7Mk6fZ+wHi47ytAhRBKE3ODrVaS0+2WoRyQT3pVhprzMewz37Ef/q
> 21HbZp5CwPR5rdgmtHwPsAsMETgPGJPpo02xF5j2fFFFUB1FeuRv2Hhr3x4j+eo=
> =xP2t
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141222/4db9b231/attachment.htm>

From eliezer at ngtech.co.il  Mon Dec 22 22:37:56 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 23 Dec 2014 00:37:56 +0200
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>	<549897DB.6020002@ngtech.co.il>
 <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>
Message-ID: <54989D44.4060501@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/23/2014 12:26 AM, Derek Cole wrote:
> Hello,
> 
> Yes it is true I am using the RPM repository to do the install. I
> have downloaded your script and I will see if I can find any
> differences that may be the culprit. In the meantime I thought I
> may be on to something - but I am not sure. Is that error message
> one that you may get if the iptables rules are not set up properly?
> I have these two boxes on different networks, so the rules are
> going to be slightly different.

Hey Derek,

No this is not an iptables level issue.
It can be one of couple from my experience:
- - basic permissions issue
- - selinux enforcement
- - a missing directory

Are you using SMP features in your configuration?

Eliezer

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmJ1EAAoJENxnfXtQ8ZQUlWwIAIuJhLOekHKMdp1/AyGpkFh0
bOb1Msurt7+vLkOiEhUmiu8d3WaH5tYoPCD/aYleQxQm3Kf5S8jEZfWU30Wrj4Mq
9qrTUuI2KoQx/X/gkUuvyzbm4sE9ePWjkqYH2ulpw9nAMw5pTbFhyd8cLGEYiUpS
AS5HQclq9VquDvJccY5htKwQjoF5LR9sc8WPIjvHPC1O5TkAFlqTnESBJkoGQBqE
C3M3K2nI5LyZo+xiDNNO8YNXzEnU8uVDWj/h3gfotOp1FXMEX7E/t4NPLuAJJ4/d
/mznTJdX8hupcyIV7omkSnSWPdyOan61IEWJTTME+bcZufuR8PU8wdDWTHKYTB4=
=HNGr
-----END PGP SIGNATURE-----


From derek.cole at gmail.com  Mon Dec 22 22:49:13 2014
From: derek.cole at gmail.com (Derek Cole)
Date: Mon, 22 Dec 2014 17:49:13 -0500
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <54989D44.4060501@ngtech.co.il>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
 <549897DB.6020002@ngtech.co.il>
 <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>
 <54989D44.4060501@ngtech.co.il>
Message-ID: <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>

Ok - thanks for saving me from chasing that issue down.

I am not currently using selinux:


On Mon, Dec 22, 2014 at 5:37 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 12/23/2014 12:26 AM, Derek Cole wrote:
> > Hello,
> >
> > Yes it is true I am using the RPM repository to do the install. I
> > have downloaded your script and I will see if I can find any
> > differences that may be the culprit. In the meantime I thought I
> > may be on to something - but I am not sure. Is that error message
> > one that you may get if the iptables rules are not set up properly?
> > I have these two boxes on different networks, so the rules are
> > going to be slightly different.
>
> Hey Derek,
>
> No this is not an iptables level issue.
> It can be one of couple from my experience:
> - - basic permissions issue
> - - selinux enforcement
> - - a missing directory
>
> Are you using SMP features in your configuration?
>
> Eliezer
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQEcBAEBAgAGBQJUmJ1EAAoJENxnfXtQ8ZQUlWwIAIuJhLOekHKMdp1/AyGpkFh0
> bOb1Msurt7+vLkOiEhUmiu8d3WaH5tYoPCD/aYleQxQm3Kf5S8jEZfWU30Wrj4Mq
> 9qrTUuI2KoQx/X/gkUuvyzbm4sE9ePWjkqYH2ulpw9nAMw5pTbFhyd8cLGEYiUpS
> AS5HQclq9VquDvJccY5htKwQjoF5LR9sc8WPIjvHPC1O5TkAFlqTnESBJkoGQBqE
> C3M3K2nI5LyZo+xiDNNO8YNXzEnU8uVDWj/h3gfotOp1FXMEX7E/t4NPLuAJJ4/d
> /mznTJdX8hupcyIV7omkSnSWPdyOan61IEWJTTME+bcZufuR8PU8wdDWTHKYTB4=
> =HNGr
> -----END PGP SIGNATURE-----
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141222/2c541f3b/attachment.htm>

From eliezer at ngtech.co.il  Mon Dec 22 22:52:49 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 23 Dec 2014 00:52:49 +0200
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>	<549897DB.6020002@ngtech.co.il>	<CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>	<54989D44.4060501@ngtech.co.il>
 <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>
Message-ID: <5498A0C1.9080203@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/23/2014 12:49 AM, Derek Cole wrote:
> Ok - thanks for saving me from chasing that issue down.
> 
> I am not currently using selinux:

Then make sure that selinux is on not on enforced mode and if so the
issue might be because of a missing directory in the OS.
If you can share the squid.conf file I can test it here on a test node
and see the results.

Eliezer
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmKDBAAoJENxnfXtQ8ZQUNPYH/j6OPryCIlqqhnRKxuoyv26h
jbTbM2FQKLWkM6hw3AS6eTizJnJdpBhiOWIr2MIi9fZnXi5gIQwKaoP85qaTa5Ju
Ik0KRU5Y68gprdY9aYnhRwKrTBk9XwBHxewwM2hkUMd/y/ATPODwJusW/ElcuDkH
QLj9F7opys319169p7ay0recLYPN1h/CORSYvkMQgc7ZeVAWLIIRCDfX1hIOxSPc
tKwRsHwyl995F92fSdbUd96/nPq69QZqxZF+GuNFZYU3CVBYX1E6p51SyXWBnF+i
1hTjWTo6TK0uJyuSf96NO5XhxYCcGyarA/AyTxq3sqrZWLoQmh8AbmN1HoJ184I=
=BhEX
-----END PGP SIGNATURE-----


From derek.cole at gmail.com  Mon Dec 22 22:52:47 2014
From: derek.cole at gmail.com (Derek Cole)
Date: Mon, 22 Dec 2014 17:52:47 -0500
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
 <549897DB.6020002@ngtech.co.il>
 <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>
 <54989D44.4060501@ngtech.co.il>
 <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>
Message-ID: <CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>

Sorry, my previous message got sent prematurely.

As I was saying, I am not currently using selinux

SELINUX=disabled
SELINUXTYPE=targeted

is the configuration on both machines. As for the basic permissions issue,
I thought I read somewhere about a missing pid file, but I don't know when
that gets made/deleted. It is not currently there on the broken box, but it
is ont he good one, which squid is running on.

-rw-r--r-- 1 root squid 6 Dec 22 16:23 /var/run/squid.pid



On Mon, Dec 22, 2014 at 5:49 PM, Derek Cole <derek.cole at gmail.com> wrote:

> Ok - thanks for saving me from chasing that issue down.
>
> I am not currently using selinux:
>
>
> On Mon, Dec 22, 2014 at 5:37 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
> wrote:
>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 12/23/2014 12:26 AM, Derek Cole wrote:
>> > Hello,
>> >
>> > Yes it is true I am using the RPM repository to do the install. I
>> > have downloaded your script and I will see if I can find any
>> > differences that may be the culprit. In the meantime I thought I
>> > may be on to something - but I am not sure. Is that error message
>> > one that you may get if the iptables rules are not set up properly?
>> > I have these two boxes on different networks, so the rules are
>> > going to be slightly different.
>>
>> Hey Derek,
>>
>> No this is not an iptables level issue.
>> It can be one of couple from my experience:
>> - - basic permissions issue
>> - - selinux enforcement
>> - - a missing directory
>>
>> Are you using SMP features in your configuration?
>>
>> Eliezer
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1
>>
>> iQEcBAEBAgAGBQJUmJ1EAAoJENxnfXtQ8ZQUlWwIAIuJhLOekHKMdp1/AyGpkFh0
>> bOb1Msurt7+vLkOiEhUmiu8d3WaH5tYoPCD/aYleQxQm3Kf5S8jEZfWU30Wrj4Mq
>> 9qrTUuI2KoQx/X/gkUuvyzbm4sE9ePWjkqYH2ulpw9nAMw5pTbFhyd8cLGEYiUpS
>> AS5HQclq9VquDvJccY5htKwQjoF5LR9sc8WPIjvHPC1O5TkAFlqTnESBJkoGQBqE
>> C3M3K2nI5LyZo+xiDNNO8YNXzEnU8uVDWj/h3gfotOp1FXMEX7E/t4NPLuAJJ4/d
>> /mznTJdX8hupcyIV7omkSnSWPdyOan61IEWJTTME+bcZufuR8PU8wdDWTHKYTB4=
>> =HNGr
>> -----END PGP SIGNATURE-----
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141222/3eac4443/attachment.htm>

From derek.cole at gmail.com  Mon Dec 22 22:57:11 2014
From: derek.cole at gmail.com (Derek Cole)
Date: Mon, 22 Dec 2014 17:57:11 -0500
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
 <549897DB.6020002@ngtech.co.il>
 <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>
 <54989D44.4060501@ngtech.co.il>
 <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>
 <CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>
Message-ID: <CAHrteQVNB1ESFVhKGftu4mrmyh9CcxdkVTCHgCViLsAyz0aKFQ@mail.gmail.com>

Here is the squid configuration file, on both boxes:

visible_hostname BrowserAccess
#acl localnet src 10.1.1.0/24 # RFC1918 possible internal network
#acl localnet src 10.22.0.0/23
acl all src 0.0.0.0/255.255.255.255
acl SSL_ports port 443
acl Safe_ports port 80      # http
acl Safe_ports port 21      # ftp
acl Safe_ports port 443     # https
acl Safe_ports port 70      # gopher
acl Safe_ports port 210     # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280     # http-mgmt
acl Safe_ports port 488     # gss-http
acl Safe_ports port 591     # filemaker
acl Safe_ports port 777     # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
#http_access allow localnet
http_access allow localhost
http_access allow all
http_access deny all
http_port 3128 accel vhost allow-direct
coredump_dir /var/spool/squid
refresh_pattern ^ftp:       1440    20% 10080
refresh_pattern ^gopher:    1440    0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
refresh_pattern .       0   20% 4320


On Mon, Dec 22, 2014 at 5:52 PM, Derek Cole <derek.cole at gmail.com> wrote:

> Sorry, my previous message got sent prematurely.
>
> As I was saying, I am not currently using selinux
>
> SELINUX=disabled
> SELINUXTYPE=targeted
>
> is the configuration on both machines. As for the basic permissions issue,
> I thought I read somewhere about a missing pid file, but I don't know when
> that gets made/deleted. It is not currently there on the broken box, but it
> is ont he good one, which squid is running on.
>
> -rw-r--r-- 1 root squid 6 Dec 22 16:23 /var/run/squid.pid
>
>
>
> On Mon, Dec 22, 2014 at 5:49 PM, Derek Cole <derek.cole at gmail.com> wrote:
>
>> Ok - thanks for saving me from chasing that issue down.
>>
>> I am not currently using selinux:
>>
>>
>> On Mon, Dec 22, 2014 at 5:37 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
>> wrote:
>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>> On 12/23/2014 12:26 AM, Derek Cole wrote:
>>> > Hello,
>>> >
>>> > Yes it is true I am using the RPM repository to do the install. I
>>> > have downloaded your script and I will see if I can find any
>>> > differences that may be the culprit. In the meantime I thought I
>>> > may be on to something - but I am not sure. Is that error message
>>> > one that you may get if the iptables rules are not set up properly?
>>> > I have these two boxes on different networks, so the rules are
>>> > going to be slightly different.
>>>
>>> Hey Derek,
>>>
>>> No this is not an iptables level issue.
>>> It can be one of couple from my experience:
>>> - - basic permissions issue
>>> - - selinux enforcement
>>> - - a missing directory
>>>
>>> Are you using SMP features in your configuration?
>>>
>>> Eliezer
>>>
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v1
>>>
>>> iQEcBAEBAgAGBQJUmJ1EAAoJENxnfXtQ8ZQUlWwIAIuJhLOekHKMdp1/AyGpkFh0
>>> bOb1Msurt7+vLkOiEhUmiu8d3WaH5tYoPCD/aYleQxQm3Kf5S8jEZfWU30Wrj4Mq
>>> 9qrTUuI2KoQx/X/gkUuvyzbm4sE9ePWjkqYH2ulpw9nAMw5pTbFhyd8cLGEYiUpS
>>> AS5HQclq9VquDvJccY5htKwQjoF5LR9sc8WPIjvHPC1O5TkAFlqTnESBJkoGQBqE
>>> C3M3K2nI5LyZo+xiDNNO8YNXzEnU8uVDWj/h3gfotOp1FXMEX7E/t4NPLuAJJ4/d
>>> /mznTJdX8hupcyIV7omkSnSWPdyOan61IEWJTTME+bcZufuR8PU8wdDWTHKYTB4=
>>> =HNGr
>>> -----END PGP SIGNATURE-----
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141222/f0456106/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 22 23:07:29 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 Dec 2014 12:07:29 +1300
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
Message-ID: <5498A431.90402@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 23/12/2014 10:35 a.m., Derek Cole wrote:
> Hello,
> 
> I have a succesful version of squid installed on a CentOS 6.5 box,
> and another Centos65 box where it is not working when I type
> "service squid start" Both boxes have the identical squid
> configuration, and i ensured that they were both running the same
> version, 3.4.8
> 
> From the cache.log file:
> 
> 2014/12/22 16:22:22| Set Current Directory to /var/spool/squid 
> 2014/12/22 16:23:25| Set Current Directory to /var/spool/squid 
> 2014/12/22 16:29:32 kid1| Set Current Directory to
> /var/spool/squid 2014/12/22 16:29:32 kid1| Starting Squid Cache
> version 3.4.8 for x86_64-redhat-linux-gnu... 2014/12/22 16:29:32
> kid1| Process ID 1555 2014/12/22 16:29:32 kid1| Process Roles:
> worker 2014/12/22 16:29:32 kid1| With 1024 file descriptors
> available 2014/12/22 16:29:32 kid1| Initializing IP Cache... 
> 2014/12/22 16:29:32 kid1| DNS Socket created at [::], FD 7 
> 2014/12/22 16:29:32 kid1| DNS Socket created at 0.0.0.0, FD 8 
> 2014/12/22 16:29:32 kid1| Adding nameserver 8.8.8.8 from
> /etc/resolv.conf 2014/12/22 16:29:32 kid1| Logfile: opening log 
> daemon:/var/log/squid/access.log 2014/12/22 16:29:32 kid1| Logfile
> Daemon: opening log /var/log/squid/access.log 2014/12/22 16:29:32
> kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600
> sec 2014/12/22 16:29:32 kid1| Store logging disabled 2014/12/22
> 16:29:32 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects 
> 2014/12/22 16:29:32 kid1| Target number of buckets: 1008 2014/12/22
> 16:29:32 kid1| Using 8192 Store buckets 2014/12/22 16:29:32 kid1|
> Max Mem  size: 262144 KB 2014/12/22 16:29:32 kid1| Max Swap size: 0
> KB 2014/12/22 16:29:32 kid1| Using Least Load store dir selection 
> 2014/12/22 16:29:32 kid1| Set Current Directory to
> /var/spool/squid 2014/12/22 16:29:32 kid1| Finished loading MIME
> types and icons. 2014/12/22 16:29:32 kid1| HTCP Disabled. 
> 2014/12/22 16:29:32 kid1| sendto FD 12: (1) Operation not
> permitted 2014/12/22 16:29:32 kid1| ipcCreate: CHILD: hello write
> test failed
> 

Broken helper program or something like apparmor/selinux blocking I/O
sockets use.

> from squid.out:
> 
> squid: ERROR: No running copy 2014/12/22 16:29:32| WARNING:
> Netmasks are deprecated. Please use CIDR masks instead. 2014/12/22
> 16:29:32| WARNING: IPv4 netmasks are particularly nasty when used
> to compare IPv6 to IPv4 ranges. 2014/12/22 16:29:32| WARNING: For
> now we will assume you meant to write /32 2014/12/22 16:29:32|
> WARNING: (A) '0.0.0.0' is a subnetwork of (B) '::/0' 2014/12/22
> 16:29:32| WARNING: because of this '0.0.0.0' is ignored to keep 
> splay tree searching predictable 2014/12/22 16:29:32| WARNING: You
> should probably remove '0.0.0.0' from the ACL named 'all'

Those "WARNING" are about Squid-2 configuration settings being used in
a Squid-3 config file. They are not stopping Squid from starting.

The last few are about your config file containing an "acl all "
definition. In Squid-3 that is a built-in ACL that covers more than
just IPv4. The rest of the warnings may be side effects of that
re-definition.

Please run "squid -k parse", it will show you the config line which is
being processed when the issue(s) are found.


Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUmKQxAAoJELJo5wb/XPRjH3QH/1Ruur9o4bi2uk1ABhTajQGV
H1ud1lFRYexUHAbAhV2aHQozZuHaXrx73OPObg7wRPltZqwoPSbtQuq/TmM61uDW
oOXlYrcKoFPtmNOn+UJMz/kUoKn9//vdWH3nDBGLtmE1oY++3sfKcHsHYsj6jn22
X/2LctH2Z5+qRJ8pREXfY02VINvDyctaABNDgNr651UpTX//fGaEoMi9ou+whtot
TqhtfFPIywni1XBstxW8bobTRjJqqBRsXBexukHyzXRVBZ/Av2tl+ABgWL+R0ci7
3f3BFCKbaHh5BDThV05VR2FIkDxy3mADm8l87TO1UWxhHFQdOK2d9TXkj13DKv4=
=sEGT
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Mon Dec 22 23:18:29 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 23 Dec 2014 01:18:29 +0200
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQVNB1ESFVhKGftu4mrmyh9CcxdkVTCHgCViLsAyz0aKFQ@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>	<549897DB.6020002@ngtech.co.il>	<CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>	<54989D44.4060501@ngtech.co.il>	<CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>	<CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>
 <CAHrteQVNB1ESFVhKGftu4mrmyh9CcxdkVTCHgCViLsAyz0aKFQ@mail.gmail.com>
Message-ID: <5498A6C5.80704@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

OK Amos gave you a suggestion which will cover everything but from
reading the squid.conf I would first try to understand:
What do you want squid to do for you?

You need to remove the "all" acl line and change the http_port from
what it is to the defaults "http_port 3128".
Did you tried to remove squid.conf and run it using the default
squid.conf?

Eliezer


On 12/23/2014 12:57 AM, Derek Cole wrote:
> visible_hostname BrowserAccess #acl localnet src 10.1.1.0/24 #
> RFC1918 possible internal network #acl localnet src 10.22.0.0/23 
> acl all src 0.0.0.0/255.255.255.255 acl SSL_ports port 443 acl
> Safe_ports port 80      # http acl Safe_ports port 21      # ftp 
> acl Safe_ports port 443     # https acl Safe_ports port 70      #
> gopher acl Safe_ports port 210     # wais acl Safe_ports port
> 1025-65535  # unregistered ports acl Safe_ports port 280     #
> http-mgmt acl Safe_ports port 488     # gss-http acl Safe_ports
> port 591     # filemaker acl Safe_ports port 777     # multiling
> http acl CONNECT method CONNECT http_access deny !Safe_ports 
> http_access deny CONNECT !SSL_ports http_access allow localhost
> manager http_access deny manager #http_access allow localnet 
> http_access allow localhost http_access allow all http_access deny
> all http_port 3128 accel vhost allow-direct coredump_dir
> /var/spool/squid refresh_pattern ^ftp:       1440    20% 10080 
> refresh_pattern ^gopher:    1440    0%  1440 refresh_pattern -i
> (/cgi-bin/|\?) 0 0%  0 refresh_pattern .       0   20% 4320

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmKbFAAoJENxnfXtQ8ZQUd6AH/jkZV2m6wpiaSyRrhAnQ1OmK
Yc7EJt9BiyrPKi5AhiCTG1LfySYVWM1J1krdH4xoXVQB543Xnz0TLA5ul7YZrkSt
s+EGMO9GJbPnzA1gjwurBz1sRDOnmd30Yc6f8sT51hJ++csVWld5PTbfCbluun95
UZwUgPl+CfUKDhot/JuobRiPd90UayuEprYcIpH4I5dbPCZlSRliXNZKzVAqE9Ht
9iIeOPuvPXKw1nWawmKxj4sytX79iNxeJ8PrXxPyCYxf8zeFHSMetA3pe2rcYQgK
y2V3aNRCdVY+VSolTkUcE+GmItbM3B//XV4CRb3CNRNsdl2cHFOglvPc8mWmodI=
=DX3j
-----END PGP SIGNATURE-----


From derek.cole at gmail.com  Mon Dec 22 23:25:40 2014
From: derek.cole at gmail.com (Derek Cole)
Date: Mon, 22 Dec 2014 18:25:40 -0500
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <5498A6C5.80704@ngtech.co.il>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
 <549897DB.6020002@ngtech.co.il>
 <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>
 <54989D44.4060501@ngtech.co.il>
 <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>
 <CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>
 <CAHrteQVNB1ESFVhKGftu4mrmyh9CcxdkVTCHgCViLsAyz0aKFQ@mail.gmail.com>
 <5498A6C5.80704@ngtech.co.il>
Message-ID: <CAHrteQWQ+du9VhPkeKES-tDOiqB_+tfWWkOnsv_GZ8q-41XQ9A@mail.gmail.com>

Thanks for taking a look.

I did try what you suggested, change the "http_port 3128" line back to
default, and also I tried to launch squid with the default squid.conf from
the RPM install. Both cases still result in a failed launch.

sharadchhetri.com/2014/03/15/install-configure-transparent-squid-proxy-server-rhelcentos-6-x/

This link is the link I was using when I initially set this up, and got it
working on the first machine. I am essentially using iptables to route
traffic to squid, and then squid is routing to the internet.

Is there anything else I can check, with respect to selinux, etc that would
determine if it's actually running or something?

Thanks

On Mon, Dec 22, 2014 at 6:18 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> OK Amos gave you a suggestion which will cover everything but from
> reading the squid.conf I would first try to understand:
> What do you want squid to do for you?
>
> You need to remove the "all" acl line and change the http_port from
> what it is to the defaults "http_port 3128".
> Did you tried to remove squid.conf and run it using the default
> squid.conf?
>
> Eliezer
>
>
> On 12/23/2014 12:57 AM, Derek Cole wrote:
> > visible_hostname BrowserAccess #acl localnet src 10.1.1.0/24 #
> > RFC1918 possible internal network #acl localnet src 10.22.0.0/23
> > acl all src 0.0.0.0/255.255.255.255 acl SSL_ports port 443 acl
> > Safe_ports port 80      # http acl Safe_ports port 21      # ftp
> > acl Safe_ports port 443     # https acl Safe_ports port 70      #
> > gopher acl Safe_ports port 210     # wais acl Safe_ports port
> > 1025-65535  # unregistered ports acl Safe_ports port 280     #
> > http-mgmt acl Safe_ports port 488     # gss-http acl Safe_ports
> > port 591     # filemaker acl Safe_ports port 777     # multiling
> > http acl CONNECT method CONNECT http_access deny !Safe_ports
> > http_access deny CONNECT !SSL_ports http_access allow localhost
> > manager http_access deny manager #http_access allow localnet
> > http_access allow localhost http_access allow all http_access deny
> > all http_port 3128 accel vhost allow-direct coredump_dir
> > /var/spool/squid refresh_pattern ^ftp:       1440    20% 10080
> > refresh_pattern ^gopher:    1440    0%  1440 refresh_pattern -i
> > (/cgi-bin/|\?) 0 0%  0 refresh_pattern .       0   20% 4320
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQEcBAEBAgAGBQJUmKbFAAoJENxnfXtQ8ZQUd6AH/jkZV2m6wpiaSyRrhAnQ1OmK
> Yc7EJt9BiyrPKi5AhiCTG1LfySYVWM1J1krdH4xoXVQB543Xnz0TLA5ul7YZrkSt
> s+EGMO9GJbPnzA1gjwurBz1sRDOnmd30Yc6f8sT51hJ++csVWld5PTbfCbluun95
> UZwUgPl+CfUKDhot/JuobRiPd90UayuEprYcIpH4I5dbPCZlSRliXNZKzVAqE9Ht
> 9iIeOPuvPXKw1nWawmKxj4sytX79iNxeJ8PrXxPyCYxf8zeFHSMetA3pe2rcYQgK
> y2V3aNRCdVY+VSolTkUcE+GmItbM3B//XV4CRb3CNRNsdl2cHFOglvPc8mWmodI=
> =DX3j
> -----END PGP SIGNATURE-----
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141222/a7cf1aff/attachment.htm>

From derek.cole at gmail.com  Mon Dec 22 23:35:15 2014
From: derek.cole at gmail.com (Derek Cole)
Date: Mon, 22 Dec 2014 18:35:15 -0500
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQWQ+du9VhPkeKES-tDOiqB_+tfWWkOnsv_GZ8q-41XQ9A@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
 <549897DB.6020002@ngtech.co.il>
 <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>
 <54989D44.4060501@ngtech.co.il>
 <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>
 <CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>
 <CAHrteQVNB1ESFVhKGftu4mrmyh9CcxdkVTCHgCViLsAyz0aKFQ@mail.gmail.com>
 <5498A6C5.80704@ngtech.co.il>
 <CAHrteQWQ+du9VhPkeKES-tDOiqB_+tfWWkOnsv_GZ8q-41XQ9A@mail.gmail.com>
Message-ID: <CAHrteQVryq8yXH==RmxPjdQyQLY9BSWj6cgGw-YHCnpFj_ACcQ@mail.gmail.com>

Here is the output of the "squid -k parse" command, AFTER making the
changes suggested by  Eliezer

2014/12/22 18:34:40| Startup: Initializing Authentication Schemes ...
2014/12/22 18:34:40| Startup: Initialized Authentication Scheme 'basic'
2014/12/22 18:34:40| Startup: Initialized Authentication Scheme 'digest'
2014/12/22 18:34:40| Startup: Initialized Authentication Scheme 'negotiate'
2014/12/22 18:34:40| Startup: Initialized Authentication Scheme 'ntlm'
2014/12/22 18:34:40| Startup: Initialized Authentication.
2014/12/22 18:34:40| Processing Configuration File: /etc/squid/squid.conf
(depth 0)
2014/12/22 18:34:40| Processing: visible_hostname BrowserAccess
2014/12/22 18:34:40| Processing: acl SSL_ports port 443
2014/12/22 18:34:40| Processing: acl Safe_ports port 80      # http
2014/12/22 18:34:40| Processing: acl Safe_ports port 21      # ftp
2014/12/22 18:34:40| Processing: acl Safe_ports port 443     # https
2014/12/22 18:34:40| Processing: acl Safe_ports port 70      # gopher
2014/12/22 18:34:40| Processing: acl Safe_ports port 210     # wais
2014/12/22 18:34:40| Processing: acl Safe_ports port 1025-65535  #
unregistered ports
2014/12/22 18:34:40| Processing: acl Safe_ports port 280     # http-mgmt
2014/12/22 18:34:40| Processing: acl Safe_ports port 488     # gss-http
2014/12/22 18:34:40| Processing: acl Safe_ports port 591     # filemaker
2014/12/22 18:34:40| Processing: acl Safe_ports port 777     # multiling
http
2014/12/22 18:34:40| Processing: acl CONNECT method CONNECT
2014/12/22 18:34:40| Processing: http_access deny !Safe_ports
2014/12/22 18:34:40| Processing: http_access deny CONNECT !SSL_ports
2014/12/22 18:34:40| Processing: http_access allow localhost manager
2014/12/22 18:34:40| Processing: http_access deny manager
2014/12/22 18:34:40| Processing: http_access allow localhost
2014/12/22 18:34:40| Processing: http_access allow all
2014/12/22 18:34:40| Processing: http_access deny all
2014/12/22 18:34:40| Processing: http_port 3128
2014/12/22 18:34:40| Processing: coredump_dir /var/spool/squid
2014/12/22 18:34:40| Processing: refresh_pattern ^ftp:       1440    20%
10080
2014/12/22 18:34:40| Processing: refresh_pattern ^gopher:    1440    0%
1440
2014/12/22 18:34:40| Processing: refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
2014/12/22 18:34:40| Processing: refresh_pattern .       0   20% 4320
2014/12/22 18:34:40| Initializing https proxy context


On Mon, Dec 22, 2014 at 6:25 PM, Derek Cole <derek.cole at gmail.com> wrote:

> Thanks for taking a look.
>
> I did try what you suggested, change the "http_port 3128" line back to
> default, and also I tried to launch squid with the default squid.conf from
> the RPM install. Both cases still result in a failed launch.
>
>
> sharadchhetri.com/2014/03/15/install-configure-transparent-squid-proxy-server-rhelcentos-6-x/
>
> This link is the link I was using when I initially set this up, and got it
> working on the first machine. I am essentially using iptables to route
> traffic to squid, and then squid is routing to the internet.
>
> Is there anything else I can check, with respect to selinux, etc that
> would determine if it's actually running or something?
>
> Thanks
>
> On Mon, Dec 22, 2014 at 6:18 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
> wrote:
>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> OK Amos gave you a suggestion which will cover everything but from
>> reading the squid.conf I would first try to understand:
>> What do you want squid to do for you?
>>
>> You need to remove the "all" acl line and change the http_port from
>> what it is to the defaults "http_port 3128".
>> Did you tried to remove squid.conf and run it using the default
>> squid.conf?
>>
>> Eliezer
>>
>>
>> On 12/23/2014 12:57 AM, Derek Cole wrote:
>> > visible_hostname BrowserAccess #acl localnet src 10.1.1.0/24 #
>> > RFC1918 possible internal network #acl localnet src 10.22.0.0/23
>> > acl all src 0.0.0.0/255.255.255.255 acl SSL_ports port 443 acl
>> > Safe_ports port 80      # http acl Safe_ports port 21      # ftp
>> > acl Safe_ports port 443     # https acl Safe_ports port 70      #
>> > gopher acl Safe_ports port 210     # wais acl Safe_ports port
>> > 1025-65535  # unregistered ports acl Safe_ports port 280     #
>> > http-mgmt acl Safe_ports port 488     # gss-http acl Safe_ports
>> > port 591     # filemaker acl Safe_ports port 777     # multiling
>> > http acl CONNECT method CONNECT http_access deny !Safe_ports
>> > http_access deny CONNECT !SSL_ports http_access allow localhost
>> > manager http_access deny manager #http_access allow localnet
>> > http_access allow localhost http_access allow all http_access deny
>> > all http_port 3128 accel vhost allow-direct coredump_dir
>> > /var/spool/squid refresh_pattern ^ftp:       1440    20% 10080
>> > refresh_pattern ^gopher:    1440    0%  1440 refresh_pattern -i
>> > (/cgi-bin/|\?) 0 0%  0 refresh_pattern .       0   20% 4320
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1
>>
>> iQEcBAEBAgAGBQJUmKbFAAoJENxnfXtQ8ZQUd6AH/jkZV2m6wpiaSyRrhAnQ1OmK
>> Yc7EJt9BiyrPKi5AhiCTG1LfySYVWM1J1krdH4xoXVQB543Xnz0TLA5ul7YZrkSt
>> s+EGMO9GJbPnzA1gjwurBz1sRDOnmd30Yc6f8sT51hJ++csVWld5PTbfCbluun95
>> UZwUgPl+CfUKDhot/JuobRiPd90UayuEprYcIpH4I5dbPCZlSRliXNZKzVAqE9Ht
>> 9iIeOPuvPXKw1nWawmKxj4sytX79iNxeJ8PrXxPyCYxf8zeFHSMetA3pe2rcYQgK
>> y2V3aNRCdVY+VSolTkUcE+GmItbM3B//XV4CRb3CNRNsdl2cHFOglvPc8mWmodI=
>> =DX3j
>> -----END PGP SIGNATURE-----
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141222/504b4641/attachment.htm>

From eliezer at ngtech.co.il  Mon Dec 22 23:42:31 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 23 Dec 2014 01:42:31 +0200
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <CAHrteQWQ+du9VhPkeKES-tDOiqB_+tfWWkOnsv_GZ8q-41XQ9A@mail.gmail.com>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>	<549897DB.6020002@ngtech.co.il>	<CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>	<54989D44.4060501@ngtech.co.il>	<CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>	<CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>	<CAHrteQVNB1ESFVhKGftu4mrmyh9CcxdkVTCHgCViLsAyz0aKFQ@mail.gmail.com>	<5498A6C5.80704@ngtech.co.il>
 <CAHrteQWQ+du9VhPkeKES-tDOiqB_+tfWWkOnsv_GZ8q-41XQ9A@mail.gmail.com>
Message-ID: <5498AC67.9050802@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Well Derek,

I must write something "I am amazed!!!"
In Step 7 there is a little confusion.
The "accel vhost allow-direct" options are not for transparent and\or
interception proxy and I am unsure why it works.
you should use something like:
http_port 127.0.0.1:3128
http_port 13128 intercept

Instead of what mentioned in the tutorial.
I would try to use another tutorial or guide to install squid in
transparent mode.
Have you tried our wiki? I have found this for you:
http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect

Else then couple little mistakes(which I will gladly be open to help
with) the tutorial looks very good.

Try my suggestion and lets see if squid starts up or not.

Eliezer

On 12/23/2014 01:25 AM, Derek Cole wrote:
> Thanks for taking a look.
> 
> I did try what you suggested, change the "http_port 3128" line back
> to default, and also I tried to launch squid with the default
> squid.conf from the RPM install. Both cases still result in a
> failed launch.
> 
> sharadchhetri.com/2014/03/15/install-configure-transparent-squid-proxy-server-rhelcentos-6-x/
>
>  This link is the link I was using when I initially set this up,
> and got it working on the first machine. I am essentially using
> iptables to route traffic to squid, and then squid is routing to
> the internet.
> 
> Is there anything else I can check, with respect to selinux, etc
> that would determine if it's actually running or something?
> 
> Thanks

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmKxmAAoJENxnfXtQ8ZQUhhwH/i5JshI9ufD8JPv7B/uLBK89
FivZdHgY25gYo4gks2bmcONCsOyBd9GoBG5IzPiTW2a7dzq232w92dsfLGUsTq5A
8uPHnAs2KU2Yr81e3I+lKfpj0BnRhieLz1wsKqYZCQuBiPN+Ik5i3TH8T6M5+2+r
HhTsT+GYkhY1xUQlV4gaU41GEBN4r+Xhup76LhNo+znO7kqg2lTkO4Wq1Jks19rk
Timfsf7m7LY5jyck3/hY6I19E3nCSpISeewga5mAT0Mg/uf5Pfi74/im9wQp72xm
MJVH47FV8BZyYtsul7kH+2pemrDkufr0qv3wc++OhPx7//t+sQrBZQU7ywfmBy8=
=2yI5
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Dec 23 00:31:55 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 Dec 2014 13:31:55 +1300
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <5498AC67.9050802@ngtech.co.il>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>	<549897DB.6020002@ngtech.co.il>	<CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>	<54989D44.4060501@ngtech.co.il>	<CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>	<CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>	<CAHrteQVNB1ESFVhKGftu4mrmyh9CcxdkVTCHgCViLsAyz0aKFQ@mail.gmail.com>	<5498A6C5.80704@ngtech.co.il>
 <CAHrteQWQ+du9VhPkeKES-tDOiqB_+tfWWkOnsv_GZ8q-41XQ9A@mail.gmail.com>
 <5498AC67.9050802@ngtech.co.il>
Message-ID: <5498B7FB.9000909@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 23/12/2014 12:42 p.m., Eliezer Croitoru wrote:
> Well Derek,
> 
> I must write something "I am amazed!!!" In Step 7 there is a little
> confusion. The "accel vhost allow-direct" options are not for
> transparent and\or interception proxy and I am unsure why it
> works.

It "works" because the traffic syntax for port 80 is accepted by both
intercept (transparent intercept-proxy) and accel (web server
reverse-proxy) modes. The "allow-direct" settings then converts the
reverse-proxy into a highly vulnerable Open Proxy. Plus firewall NAT
settings diverting all traffic (from both LAN and WAN!)



Derek, If you got to step 9 then *immediately* go to your firewall
setup and erase that line containing:
 -i $ETHERNET_INTERNET -p tcp --dport 80 -j REDIRECT

It is completely needless on WAN interface and should never be used in
the form shown there. The tutorial Eliezer linked below contains all
you need for transparent interception.



> you should use something like: http_port 127.0.0.1:3128 http_port
> 13128 intercept

nod.

> 
> Instead of what mentioned in the tutorial. I would try to use
> another tutorial or guide to install squid in transparent mode. 
> Have you tried our wiki? I have found this for you: 
> http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect
> 
> Else then couple little mistakes(which I will gladly be open to
> help with) the tutorial looks very good.
> 
> Try my suggestion and lets see if squid starts up or not.
> 
> Eliezer
> 

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUmLf7AAoJELJo5wb/XPRjd8QIANnGYjuGGzJ1WPvV1oF6BZzO
4fxqnJOLDH/M4b6gB+vgRYIkMY1qZTCptC1eE66YvkKGgYYjZEGvbIxyZ3Ql9IEg
bvm2t3ouJxts4I576275XIj9Tvh7u77ObcD51vPFrOCzjt66UoNBnXlHE2Hm7jfz
WYTK/oa7AgdYxfsZPZuVLb6m9ClfIzdB+ta3vVBUkfgsgCPkPZdk3O6NRmhnzA56
sSlCOS43UfXwDsg6F/RwREs5/SruAYa2PTIwhLcHsPmKJiUToH9v/UnGRzGaKiwp
LsuktdGfkDYl4bsd8FVAwTzev1Lzs97+IokVUGogE20LxWT08DwZEMd7M2SvmtE=
=UfqC
-----END PGP SIGNATURE-----


From alex at samad.com.au  Tue Dec 23 03:54:04 2014
From: alex at samad.com.au (Alexander Samad)
Date: Tue, 23 Dec 2014 14:54:04 +1100
Subject: [squid-users] centos 6.x repo
Message-ID: <CAJ+Q1PVNMqY0CnbycSwfMdQJL-FM0wWn1bk7J_gE5LMRdSdcmw@mail.gmail.com>

Hi

Just found this repo from the wiki
http://www1.ngtech.co.il/rpm/centos/6/$basearch

Wondering what if any downsides there are to using the lastest on 6.x ?

Alex


From eliezer at ngtech.co.il  Tue Dec 23 05:35:44 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 23 Dec 2014 07:35:44 +0200
Subject: [squid-users] centos 6.x repo
In-Reply-To: <CAJ+Q1PVNMqY0CnbycSwfMdQJL-FM0wWn1bk7J_gE5LMRdSdcmw@mail.gmail.com>
References: <CAJ+Q1PVNMqY0CnbycSwfMdQJL-FM0wWn1bk7J_gE5LMRdSdcmw@mail.gmail.com>
Message-ID: <5498FF30.8080000@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Alex,

I am not sure what you mean by your question.
I am using latest 6.6 as a build node and am trying to use the most
up-to-date CentOS version and libs.
Downsides? If someone has a 6.5 or older 6 branch system without
enough updates to work with the RPMs.

Eliezer

On 12/23/2014 05:54 AM, Alexander Samad wrote:
> Hi
> 
> Just found this repo from the wiki 
> http://www1.ngtech.co.il/rpm/centos/6/$basearch
> 
> Wondering what if any downsides there are to using the lastest on
> 6.x ?
> 
> Alex

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmP8wAAoJENxnfXtQ8ZQUaQIH/24I7rf729AluCHDIcV7KgUd
tf104aptDw03RTeKqHgGonwZn3kcuq6nADhSOnszqSn0Tlp62E+w+rT4OkV0yClt
5ULiNTRHq58RoSX5pAYfHJAsu8I0HEDKYJAjif4c2mWjQusgJsp4FNLqvrrvpxX0
hq2j7RwOUQ5iBTFGiFsrCge6sO8TC5Uw3O/iqN2P2MFtV+0zwIpcIsPKDsjkmX72
hY4JDPUnaoxTlgUYwqGn5PLW9KY8cGe2sYbUekoiBXRoLyl5VW45DZf2KnmhKeqi
9k2Fn1UDtzChFRseKSzXMSEby2X5MR0gphhhLLdmGDQGKS2mG083cHquFBoOuEU=
=G/SU
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Tue Dec 23 09:22:01 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 23 Dec 2014 15:22:01 +0600
Subject: [squid-users] Squid 3.4.10 startup/shutdown core dumps
Message-ID: <54993439.9050308@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Amos,

this patch works partially. On startup cores gone, but on shutdown
remains one:

Dec 23 15:19:28 fhtagn genunix: [ID 603404 kern.notice] NOTICE:
core_log: squid[58817] setid process, core not dumped:
/var/core/core.squid.58817

Is patch not complete?

WBR, Yuri
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUmTQ4AAoJENNXIZxhPexGOG8IAKqEdCXIj/NVKSNYFjF4VOX1
dtIjG6IICkQKQO8dWuObQwOgTSwnszFdvLIuXERhe+a/M9VmD8L895Knxs9Gf5v1
cwowFBeAsNgjiZQKI+yajI1s2xJ3U/es+yz98xpCyjdBmW+Wgss7/7+K/E4o6McY
O/UImIGL1sBC5WeAoBI2QfhsT9Y2XKChyjA8QkaoMg6nfoIthKIpWyOBbMJghYqr
jBrR3KdpIcqro28iEW9m8oOKkuUq4LQUQx9dgPxkcige4fWEq9w++N33W3YI0KOh
TnWmqD6ZYqMbThjOMgoD9wbU7blMLu91Le1J3xGa4Qyvf/X/zddzSdIXOOSf/8U=
=iuzt
-----END PGP SIGNATURE-----



From alex at samad.com.au  Tue Dec 23 22:32:50 2014
From: alex at samad.com.au (Alexander Samad)
Date: Wed, 24 Dec 2014 09:32:50 +1100
Subject: [squid-users] centos 6.x repo
In-Reply-To: <5498FF30.8080000@ngtech.co.il>
References: <CAJ+Q1PVNMqY0CnbycSwfMdQJL-FM0wWn1bk7J_gE5LMRdSdcmw@mail.gmail.com>
 <5498FF30.8080000@ngtech.co.il>
Message-ID: <CAJ+Q1PVDUhV9AzT4Nqx07OpbHmWAQeiMnLAo=dhkjhXAVpH=Ug@mail.gmail.com>

Hi

Some new version of software are based on centos 7.x... I believe the
differences are glib and kernel ...

for example http 2.4 I need a backport to get it to work on centos 6.x.

Just wondering if there is any thing special I need for centos 6.x for
latest squid

But it sounds like I am good to go

Alex

On 23 December 2014 at 16:35, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Hey Alex,
>
> I am not sure what you mean by your question.
> I am using latest 6.6 as a build node and am trying to use the most
> up-to-date CentOS version and libs.
> Downsides? If someone has a 6.5 or older 6 branch system without
> enough updates to work with the RPMs.
>
> Eliezer
>
> On 12/23/2014 05:54 AM, Alexander Samad wrote:
>> Hi
>>
>> Just found this repo from the wiki
>> http://www1.ngtech.co.il/rpm/centos/6/$basearch
>>
>> Wondering what if any downsides there are to using the lastest on
>> 6.x ?
>>
>> Alex
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQEcBAEBAgAGBQJUmP8wAAoJENxnfXtQ8ZQUaQIH/24I7rf729AluCHDIcV7KgUd
> tf104aptDw03RTeKqHgGonwZn3kcuq6nADhSOnszqSn0Tlp62E+w+rT4OkV0yClt
> 5ULiNTRHq58RoSX5pAYfHJAsu8I0HEDKYJAjif4c2mWjQusgJsp4FNLqvrrvpxX0
> hq2j7RwOUQ5iBTFGiFsrCge6sO8TC5Uw3O/iqN2P2MFtV+0zwIpcIsPKDsjkmX72
> hY4JDPUnaoxTlgUYwqGn5PLW9KY8cGe2sYbUekoiBXRoLyl5VW45DZf2KnmhKeqi
> 9k2Fn1UDtzChFRseKSzXMSEby2X5MR0gphhhLLdmGDQGKS2mG083cHquFBoOuEU=
> =G/SU
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From hack.back at hotmail.com  Wed Dec 24 00:42:54 2014
From: hack.back at hotmail.com (HackXBack)
Date: Tue, 23 Dec 2014 16:42:54 -0800 (PST)
Subject: [squid-users] https bug slow browsing
Message-ID: <1419381774083-4668830.post@n4.nabble.com>

hello amos,
I used 3.4.x for http cache
when used https then https sites open slow
I upgrade from 3.4.x to 3.5.0.4 then squid crash and always restart
automatically, and this is bug.
now I format the system and install squid 3.5.0.4 in fresh system knowing
that i lost 4 terra data on my HDD's.
then i face the same problem at 3.4.x version that https sites is openning
slowly and its like the packets drop and stop loading . !!
my cache work in intercept mode with mikrotik
and i see many errors like this

2014/12/23 19:32:43 kid1| Error negotiating SSL connection on FD 193:
Success (0)
2014/12/23 19:32:43 kid1| Error negotiating SSL connection on FD 193:
Success (0)
2014/12/23 19:32:44 kid1| Error negotiating SSL connection on FD 193:
Success (0)
2014/12/23 19:32:47 kid1| hold write on SSL connection on FD 196
2014/12/23 19:32:50 kid1| hold write on SSL connection on FD 93
2014/12/23 19:33:10 kid1| Error negotiating SSL on FD 317:
error:1409F07F:SSL routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0)
2014/12/23 19:33:10 kid1| Error negotiating SSL on FD 317:
error:1409F07F:SSL routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0)


what I discover that when packets drop and the page stop loading one of this
tow error appear in cache.log

either 
2014/12/23 19:32:44 kid1| Error negotiating SSL connection on FD 193:
Success (0)
or
2014/12/23 19:36:08 kid1| Error negotiating SSL on FD 95: error:1409F07F:SSL
routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0)

and that is in squid 3.5.0.4

but in version 3.4.x
the error when packet dropped is

Error negotiating SSL connection on FD 36:
error:00000000:lib(0):func(0):reason(0)


so now we have 2 bug
1st one : when upgrading from 3.4.x to 3.5.0.4 squid crash and always
restart automatically
2nd one : browsing on https slow = packet dropped and stop loading until
refresh in 3.4.x and 3.5.0.4

Good Luck Guys and wish this bugs will solved as soon as possible and thanks
for you response and interest



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Dec 24 01:30:39 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 24 Dec 2014 03:30:39 +0200
Subject: [squid-users] centos 6.x repo
In-Reply-To: <CAJ+Q1PVDUhV9AzT4Nqx07OpbHmWAQeiMnLAo=dhkjhXAVpH=Ug@mail.gmail.com>
References: <CAJ+Q1PVNMqY0CnbycSwfMdQJL-FM0wWn1bk7J_gE5LMRdSdcmw@mail.gmail.com>	<5498FF30.8080000@ngtech.co.il>
 <CAJ+Q1PVDUhV9AzT4Nqx07OpbHmWAQeiMnLAo=dhkjhXAVpH=Ug@mail.gmail.com>
Message-ID: <549A173F.6070500@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Alex,

The answer to your question is: no you don't.
I am building squid on the latest CentOS 6.x and it should work on any
new 6.x system.
There is however a lib which doesn't exist in CentOS 6.x and being
embedded inside squid src code: "ltdl".
Squid requires a ltdl tools which are not included on CentOS 6.x and
therefor being embedded inside the src code.

Notice that I separated squid and squid helpers into two different
packages in order to allow an admin to install squid core on a
"vanilla" CentOS with no EPEL repositories installed.

Eliezer

On 12/24/2014 12:32 AM, Alexander Samad wrote:
> Hi
> 
> Some new version of software are based on centos 7.x... I believe
> the differences are glib and kernel ...
> 
> for example http 2.4 I need a backport to get it to work on centos
> 6.x.
> 
> Just wondering if there is any thing special I need for centos 6.x
> for latest squid
> 
> But it sounds like I am good to go
> 
> Alex

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmhc/AAoJENxnfXtQ8ZQUCNQH/0A/Sjb8NrZUowdLbMcpwBlW
PLwbpTbbDfVLKtHReHKerPvBCon2iMpcDbEcZfnRmgWiWhzItAqEOSRdTPffMnrx
cWLhGhxGOyeUMTiZdGcf7yg3R1XAOEf8PRgjidwJPxnCybFiihNUzKSxQHpxb7ot
4tcgvLQUSGOPIgBULtD1HMBHmirg59lD5P9AOdHpghbYJFXpIyumNzF3hS1OGuzr
SVmjHe28uzNL778X4qEYugDf+XFa6NUMjo27oF8/1eURQbtW0dlf+wdRMak6ChXu
R3y2+ocgX2LYnzZCytsuGs/7grJ89dGzxbpCy7zwYJV5sJHCviNoz6mu/cRJlWA=
=U+py
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Wed Dec 24 01:32:12 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 24 Dec 2014 03:32:12 +0200
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419381774083-4668830.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
Message-ID: <549A179C.4050606@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/24/2014 02:42 AM, HackXBack wrote:
> so now we have 2 bug 1st one : when upgrading from 3.4.x to 3.5.0.4
> squid crash and always restart automatically 2nd one : browsing on
> https slow = packet dropped and stop loading until refresh in 3.4.x
> and 3.5.0.4
> 
> Good Luck Guys and wish this bugs will solved as soon as possible
> and thanks for you response and interest

Can you share your squid.conf?

Eliezer
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmhecAAoJENxnfXtQ8ZQUwNoH/0hSIsz+akzVxysN3gSjoy/G
qEeyiKt1EOI5KK4kaeX8SUNngqf1S+Y8Nuk37dz9dwrghYt5mxCrLij5WCcNj1H3
I67fmKbluqE0GCX1Jn+73G7MKoLyT9+HirlcM6cWhbL7uwa139jE9kmKohQKPWFF
gGj5hN1pRaySHDGqnADtGYvLS6Vycp9gcxUxJ6d97toq09alqt1E/YHHgmKnXW//
+JYA/Tc2uwdQF1IVOneTJmT1rN9DmsQQ9zFWK4H4L+U2VNMKQKSIGnlG7hdK7fPM
ujDj+J5ZVV2sgCpf5RAQtDz0Chmff9ernHbmFi6N8NAOkDSjMBVR/dVGFYZUWxw=
=qWSb
-----END PGP SIGNATURE-----


From alex at samad.com.au  Wed Dec 24 02:22:55 2014
From: alex at samad.com.au (Alexander Samad)
Date: Wed, 24 Dec 2014 13:22:55 +1100
Subject: [squid-users] centos 6.x repo
In-Reply-To: <549A173F.6070500@ngtech.co.il>
References: <CAJ+Q1PVNMqY0CnbycSwfMdQJL-FM0wWn1bk7J_gE5LMRdSdcmw@mail.gmail.com>
 <5498FF30.8080000@ngtech.co.il>
 <CAJ+Q1PVDUhV9AzT4Nqx07OpbHmWAQeiMnLAo=dhkjhXAVpH=Ug@mail.gmail.com>
 <549A173F.6070500@ngtech.co.il>
Message-ID: <CAJ+Q1PU4Zzv-7g_3DM58+L8t2PVwxHeGqM1=z7SLc9FJmDzw1g@mail.gmail.com>

Great thanks

Nice work

On 24 December 2014 at 12:30, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Hey Alex,
>
> The answer to your question is: no you don't.
> I am building squid on the latest CentOS 6.x and it should work on any
> new 6.x system.
> There is however a lib which doesn't exist in CentOS 6.x and being
> embedded inside squid src code: "ltdl".
> Squid requires a ltdl tools which are not included on CentOS 6.x and
> therefor being embedded inside the src code.
>
> Notice that I separated squid and squid helpers into two different
> packages in order to allow an admin to install squid core on a
> "vanilla" CentOS with no EPEL repositories installed.
>
> Eliezer
>
> On 12/24/2014 12:32 AM, Alexander Samad wrote:
>> Hi
>>
>> Some new version of software are based on centos 7.x... I believe
>> the differences are glib and kernel ...
>>
>> for example http 2.4 I need a backport to get it to work on centos
>> 6.x.
>>
>> Just wondering if there is any thing special I need for centos 6.x
>> for latest squid
>>
>> But it sounds like I am good to go
>>
>> Alex
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQEcBAEBAgAGBQJUmhc/AAoJENxnfXtQ8ZQUCNQH/0A/Sjb8NrZUowdLbMcpwBlW
> PLwbpTbbDfVLKtHReHKerPvBCon2iMpcDbEcZfnRmgWiWhzItAqEOSRdTPffMnrx
> cWLhGhxGOyeUMTiZdGcf7yg3R1XAOEf8PRgjidwJPxnCybFiihNUzKSxQHpxb7ot
> 4tcgvLQUSGOPIgBULtD1HMBHmirg59lD5P9AOdHpghbYJFXpIyumNzF3hS1OGuzr
> SVmjHe28uzNL778X4qEYugDf+XFa6NUMjo27oF8/1eURQbtW0dlf+wdRMak6ChXu
> R3y2+ocgX2LYnzZCytsuGs/7grJ89dGzxbpCy7zwYJV5sJHCviNoz6mu/cRJlWA=
> =U+py
> -----END PGP SIGNATURE-----


From hack.back at hotmail.com  Wed Dec 24 11:51:53 2014
From: hack.back at hotmail.com (HackXBack)
Date: Wed, 24 Dec 2014 03:51:53 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419381774083-4668830.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
Message-ID: <1419421913328-4668834.post@n4.nabble.com>

# REVISI 19/10/2014 12:24 By Mc Leod
#INFO
#PORT HTTP
#http_port 3128 transparent
#http_port 3127


https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
http_port  3129
http_port  3128 intercept

#####HDD
#cache_dir aufs /cache 1000 32 256 min-size=0 max-size=33554432

cache_dir aufs /cache01/1 400000 961 256
cache_dir aufs /cache01/2 400000 961 256
cache_dir aufs /cache01/3 400000 961 256
cache_dir aufs /cache01/4 400000 961 256
cache_dir aufs /cache01/5 400000 961 256
cache_dir aufs /cache01/6 400000 961 256

cache_dir aufs /cache02/1 400000 961 256
cache_dir aufs /cache02/2 400000 961 256
cache_dir aufs /cache02/3 400000 961 256
cache_dir aufs /cache02/4 400000 961 256
cache_dir aufs /cache02/5 400000 961 256
cache_dir aufs /cache02/6 400000 961 256

cache_dir aufs /cache03/1 400000 961 256
cache_dir aufs /cache03/2 400000 961 256
cache_dir aufs /cache03/3 400000 961 256
cache_dir aufs /cache03/4 400000 961 256
cache_dir aufs /cache03/5 400000 961 256
cache_dir aufs /cache03/6 400000 961 256


cache_dir aufs /cache04/1 400000 961 256
cache_dir aufs /cache04/2 400000 961 256
cache_dir aufs /cache04/3 400000 961 256
cache_dir aufs /cache04/4 400000 961 256
cache_dir aufs /cache04/5 400000 961 256
cache_dir aufs /cache04/6 400000 961 256


cache_dir aufs /cache05/1 400000 961 256
cache_dir aufs /cache05/2 400000 961 256
cache_dir aufs /cache05/3 400000 961 256
cache_dir aufs /cache05/4 400000 961 256
cache_dir aufs /cache05/5 400000 961 256
cache_dir aufs /cache05/6 400000 961 256






cache_mgr ipbobos.com +9613006553
visible_hostname Internet
unique_hostname Internet
cachemgr_passwd none all

acl banned_methods method OPTIONS POST PURGE CONNECT PUT DELETE TRACE
acl http_code_ignored http_status 200-299

#ACLs#
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src 172.192.111.0/24

##redirect Porn
#include /etc/squid/porn.conf



http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
http_access allow localnet
http_access allow localhost
http_access deny all

acl partial_content  url_regex -i ^http:\/\/122\.102\.49.*
acl partial_content  url_regex -i ^http:\/\/202\.93\.20.*
acl partial_content  url_regex -i ^http:\/\/armdl\.adobe\.com/pub.*
acl partial_content  url_regex -i ^http:\/\/download\.cdn\.mozilla\.net.*
acl partial_content  url_regex -i ^http.*netmarble\.co\.id.*
acl partial_content  url_regex -i ^http.*gemscool\.com.*
acl partial_content  url_regex -i ^http.*crossfire\.web\.id.*
acl partial_content  url_regex -i ^http.*garenanow\.com.*
acl partial_content  url_regex -i ^http.*winnerinter\.co\.id.*
acl partial_content  url_regex -i ^http.*starhub\.com.*
acl partial_content  url_regex -i ^http.*lytogame\.com.*
acl partial_content  url_regex -i ^http.*megaxus\.com
acl partial_content  url_regex -i ^http.*images\.offensive-security\.com.*
acl partial_content  url_regex -i ^http.*download\.windowsupdate\.com
acl partial_content  url_regex -i ^http.*ws\.microsoft\.com
acl partial_content  url_regex -i ^http.*fs41\.idup\.in.*
acl partial_content  url_regex -i ^http.*tusfiles\.net.*
acl partial_content  url_regex -i ^http.*files\.jalantikus\.com.*
acl partial_content  url_regex -i ^http.*cdn.files.bagas31.com.*
acl partial_content  url_regex -i ^http\/\/dl\.google\.com.*
acl partial_content  url_regex -i ^http.*\.c\.pack\.google\.com.*
acl partial_content  url_regex -i ^http.*\.(exe|psf|msi|msp|msu|dmg|cab)$
range_offset_limit 1 KB partial_content

acl querypath urlpath_regex -i cgi-bin localhost
acl queryreg url_regex -i gemscool\.com\/registration\/.*
acl queryreg url_regex -i gemscool\.com\/isiGcash\/.*
acl queryreg url_regex -i ^http.*(youtube|google).*yt_live_broadcast.*
acl queryreg url_regex -i ^http.*live\.mytrans\.com.*
acl queryreg url_regex -i ^http.*socialpointgames\.com\/dragoncity.*USERID.*
acl queryreg url_regex -i ^http.*fb_source=bookmark_apps.*
acl queryreg url_regex -i ^http.*gvoucher.*
acl queryreg url_regex -i ^http.*\.(asp|aspx|php|xml)(\?.*|)$

cache deny banned_methods
cache deny querypath
cache deny queryreg

acl speedtest urlpath_regex -i speedtest\/.*\.(jpg|php|txt).*$
#acl speedtest urlpath_regex -i results.php\?.*$
store_id_access allow speedtest

acl playstoreandroid url_regex -i
c.android.clients.google.com.market.GetBinary.GetBinary.*
store_id_access allow playstoreandroid

acl DENYCACHE urlpath_regex
\.(ini|ui|lst|inf|pak|ver|patch|md5|cfg|lst|list|rsc|log|conf|dbd|db|aspx|js|m3u8|ts)$
acl DENYCACHE urlpath_regex
(notice.html|notice.swf|afs.dat|dat.asp|patchinfo.xml|version.list|iepngfix.htc|updates.txt|patchlist.txt|update.ver)
acl DENYCACHE urlpath_regex (pointblank.css|login_form.css|form.css)$
cache deny DENYCACHE






#redirect youtube agent
acl youtube url_regex -i \.(youtube|googlevideo)\.com.*
#acl youtube url_regex -i ^http://.*\.googlevideo\.com.*
request_header_access User-Agent deny youtube
request_header_replace User-Agent Mozilla/5.0 (Windows NT 6.1; WOW64;
rv:33.0) Gecko/20100101 Firefox/33.0

#redirect all agents
#request_header_access User-Agent deny all
#request_header_replace User-Agent Mozilla/5.0 (Windows NT 6.1; WOW64;
rv:33.0) Gecko/20100101 Firefox/33.0


cache_effective_user proxy
cache_effective_group proxy

#LOGS
coredump_dir /var/spool/squid/cache/squid
error_directory /usr/share/squid/errors/templates
mime_table /etc/squid/mime.conf

cache_log /var/log/squid/cache.log
access_log /var/log/squid/access.log
cache_store_log /var/log/squid/store.log

logfile_daemon /usr/lib/squid/log_file_daemon
logfile_rotate 12

#debug helper
#debug_options ALL,1 84,9

#debug refresh_pattern
#debug_options ALL,1 22,3

#debug ACL
#debug_options ALL,1 33,2 28,9

#debug squid.conf
#debug_options ALL,1 33,2


#YANG ANE RUBAH
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i \.(asp|aspx|htm|html|php)(\?.*)?$ 0 0% 0


#REFRESH PATTERN
# apple updates
refresh_pattern -i ^http://swscan\.apple\.com 86400 100% 86400 
override-lastmod override-expire ignore-reload ignore-must-revalidate
ignore-private store-stale ignore-no-store
refresh_pattern -i ^http://swcdn\.apple\.com 86400 100% 86400 
override-lastmod override-expire ignore-reload ignore-must-revalidate
ignore-private store-stale ignore-no-store



#Windows Update
refresh_pattern -i
microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
reload-into-ims
refresh_pattern -i
windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims
refresh_pattern -i
windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
reload-into-ims

#sensitive site
refresh_pattern -i \.(sc-|dl-|ex-|mh-|dll|da-) 0 2% 50 reload-into-ims
refresh_pattern -i \.(mst|Xtp|iop)$ 0 50% 1440 reload-into-ims
refresh_pattern -i
(index.php|autoup.exe|main.exe|xtrap.xt|autoupgrade.exe|update.exe|grandchase.exe|FSLauncher.exe|FreeStyle_Setup.exe|grandchase.exe|filelist.zip)$
0 50% 1440
refresh_pattern -i
(wks_avira-win32-en-pecl.info.gz|wks_avira10-win32-en-pecl.info.gz|servers.def.vpx)$
0 50% 1440
refresh_pattern -i
(setup.exe.gz|avscan.exe.gz|avguard.exe.gz|filelist.zip|AvaClient.exe) 0 50%
1440
refresh_pattern -i (livescore.com|goal.com|bobet|betbetty) 0 50% 60



# refresh pattern
----------------------------------------------------------------------------------#
refresh_pattern -i (cgi-bin|mrtg|graph) 0 0% 0
refresh_pattern -i (xtrap|login|sources) 0 0% 0
refresh_pattern .*(begin|start)\=[1-9][0-9].* 0 0% 0
refresh_pattern -i
\.(html|htm|ini|ver|patch|lst|inf|htc|jsp|asx|asp|aspx|cfg|md5|key|pub|list|db|log|cgi)$
0 0% 0
refresh_pattern
(update.ini|Update.ini|version.list|Version.list|update.1st|update.exe|autoup.exe)
0 0% 0
refresh_pattern
(hackshield|HackShield|HSUpdate|HShield|hsupdate|nprotect|update3) 0 50% 420
override-expire override-lastmod reload-into-ims



#FB
refresh_pattern
\.facebook\.com.*\.(jp(e?g|e|2)|gif|png|tiff?|bmp|swf|mp|api|php(4|3)) 1440
99% 43200 override-expire override-lastmod reload-into-ims ignore-reload
ignore-no-store ignore-private store-stale
refresh_pattern -i facebook\.com.* 1440 99% 43200 override-expire
override-lastmod ignore-reload ignore-private ignore-no-store
reload-into-ims store-stale
refresh_pattern -i (fbcdn|akamaihd)\.net.* 14400 99% 43200 override-expire
override-lastmod ignore-reload ignore-private ignore-no-store
reload-into-ims store-stale
refresh_pattern \.gstatic\.com/images\? 14400 99% 43200 override-expire
override-lastmod ignore-reload ignore-private ignore-no-store
reload-into-ims store-stale
refresh_pattern
\.(edgecastcdn|spilcdn|zgncdn|(tw|y|yt)img)\.com.*\.(jp(e?g|e|2)|gif|png|swf|mp(3|4))
1440 99% 43200 override-expire override-lastmod ignore-reload ignore-private
ignore-no-store reload-into-ims store-stale
refresh_pattern (gstatic|diggstatic)\.com/.* 1440 99% 43200 override-expire
override-lastmod ignore-reload ignore-private ignore-no-store
reload-into-ims store-stale
refresh_pattern
(photobucket|pbsrc|flickr|yimg|ytimg|twimg|gravatar)\.com.*\.(jp(e?g|e|2)|gif|png|tiff?|bmp|swf|mp(4|3))
1440 99% 43200 override-expire ignore-reload ignore-private
refresh_pattern ^http:\/\/images|image|img|pics|openx|thumbs[0-9]\. 1440 99%
43200 override-expire override-lastmod ignore-reload ignore-private
ignore-no-store reload-into-ims store-stale
refresh_pattern ^.*safebrowsing.*google 1440 90% 43200 override-expire
override-lastmod ignore-reload ignore-private ignore-no-store
reload-into-ims store-stale
#refresh_pattern ^http://.*\.squid\.internal\/.* 10080 99% 79900
override-expire override-lastmod ignore-reload ignore-no-store
ignore-must-revalidate reload-into-ims ignore-private ignore-auth
store-stale
refresh_pattern http://gtssl-ocsp.geotrust.com/ 1440 99% 43200
override-expire override-lastmod ignore-reload ignore-private
ignore-no-store reload-into-ims store-stale
refresh_pattern http://ocsp.godaddy.com/ 1440 99% 43200 override-expire
override-lastmod ignore-reload ignore-private ignore-no-store
reload-into-ims store-stale
refresh_pattern http://ocsp.digicert.com/ 1440 99% 43200 override-expire
override-lastmod ignore-reload ignore-private ignore-no-store
reload-into-ims store-stale



#All File with ?
refresh_pattern -i
\.(npk|ipa|sis|apk|ipsw|pak|kom|dds|thor|nar|gpf|nzp|xpi|cdo|3gp|avi|ac4|ram|mp(e?g|a|e|1|2|3|4)|m4(a|v)|3g(p?2|p)|mk(a|v)|og(x|v|a|g|m)|wm(a|v)|wmx|wpl|rm|snd|vob|wav|asx|avi|qt|divx|flv|f4v|x-flv|dvr-ms|m(1|2)(v|p)|mov|mid)\?
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern -i
\.(ogg|m1v|m2(v|p)|txt|dll|mo(d|v)|7z|ace|rar|jar|gz|tgz|bz2|iso|mod|arj|lha|lzh|zip|tar|cab|dat)\?
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern -i \.(jp(e?g|e|2)|bmp|gif|pn[pg]|bm?|tiff?|ico|swf|ad)\?
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern -i \.(exe|ms(i|u|p)|deb|bin|ax|r(a|p)m|app|pkg|apk)\? 86400
100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern -i
\.(pp(t?x|t)|epub|pdf|rtf|wax|cb(r|z|t)|xl(s?x|s)|do(c?x|c)|inc|x-flv)\?
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern -i
\.(z(ip|[0-9]{2})|r(ar|[0-9]{2})|tar.gz|tar.bz2|rpm|vpu)\? 86400 100% 86400 
override-lastmod override-expire ignore-reload ignore-must-revalidate
ignore-private store-stale ignore-no-store
refresh_pattern -i
\.(raw|pnm|png|webp|m4v|rmvb|mkv|webm|doc|docx|pptx?|xlsx?|lit|pdb|prc|djvu|psd|mar|crx|dcr|uha|dmg|zipx|msi|msu|msp|aac|amr|amf|au|wma|rma|nup|vdf|idx|gem|mcs|avc|vpx|ipa)\?
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store

#All File without ?
refresh_pattern
\.(npk|ipa|sis|apk|ipsw|pak|kom|dds|thor|nar|gpf|nzp|xpi|cdo|3gp|avi|ac4|ram|mp(e?g|a|e|1|2|3|4)|m4(a|v)|3g(p?2|p)|mk(a|v)|og(x|v|a|g|m)|wm(a|v)|wmx|wpl|rm|snd|vob|wav|asx|avi|qt|divx|flv|f4v|x-flv|dvr-ms|m(1|2)(v|p)|mov|mid)
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern
\.(ogg|m1v|m2(v|p)|txt|dll|mo(d|v)|7z|ace|rar|jar|gz|tgz|bz2|iso|mod|arj|lha|lzh|zip|tar|cab|dat)
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern \.(jp(e?g|e|2)|bmp|gif|pn[pg]|bm?|tiff?|ico|swf|ad) 86400
100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern \.(exe|ms(i|u|p)|deb|bin|ax|r(a|p)m|app|pkg|apk) 86400 100%
86400  override-lastmod override-expire ignore-reload ignore-must-revalidate
ignore-private store-stale ignore-no-store
refresh_pattern
\.(pp(t?x|t)|epub|pdf|rtf|wax|cb(r|z|t)|xl(s?x|s)|do(c?x|c)|inc|x-flv) 86400
100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern \.(z(ip|[0-9]{2})|r(ar|[0-9]{2})|tar.gz|tar.bz2|rpm|vpu)
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store
refresh_pattern
\.(raw|pnm|png|webp|m4v|rmvb|mkv|webm|doc|docx|pptx?|xlsx?|lit|pdb|prc|djvu|psd|mar|crx|dcr|uha|dmg|zipx|msi|msu|msp|aac|amr|amf|au|wma|rma|nup|vdf|idx|gem|mcs|avc|vpx|ipa)
86400 100% 86400  override-lastmod override-expire ignore-reload
ignore-must-revalidate ignore-private store-stale ignore-no-store



#REFRESH PATTERN
#refresh_pattern -i \.(js|css)$ 0 20% 4320 ignore-reload ignore-no-store
ignore-must-revalidate ignore-private ignore-auth store-stale
#refresh_pattern -i \.(nup|vdf|idx|gem|mcs|avc|vpx)$ 0 20% 4320
ignore-reload ignore-must-revalidate ignore-private store-stale
ignore-no-store
#refresh_pattern -i ^http:\/\/safebrowsing-cache\.google\.com\/.* 525600
100% 525600 override-expire override-lastmod reload-into-ims ignore-reload
ignore-no-cache ignore-no-store ignore-private ignore-auth
ignore-must-revalidate
#refresh_pattern -i ^http.*\/hackshield\/.* 0 20% 1440 ignore-no-store
ignore-must-revalidate ignore-private ignore-auth store-stale
#refresh_pattern -i \.(iop)$ 0 50% 1440 ignore-reload ignore-no-store
ignore-must-revalidate ignore-private ignore-auth store-stale
refresh_pattern -i
^http.*(netmarble\.co\.id|gemscool\.com|crossfire\.web\.id|garenanow\.com|winnerinter\.co\.id|starhub\.com|lytogame\.com|megaxus\.com).*
0 20% 4320 ignore-no-store ignore-private ignore-auth store-stale
refresh_pattern -i ^http:\/\/(storeid\.cdn|cdn\.porno).* 525600 100% 525600
override-expire override-lastmod reload-into-ims ignore-reload
ignore-no-cache ignore-no-store ignore-private ignore-auth
ignore-must-revalidate
#refresh_pattern -i \.(jpg|jpeg|raw|pnm|gif|bmp|tiff|swf|png|webp)(\?.*|)$
525600 100% 525600 override-expire override-lastmod reload-into-ims
ignore-reload ignore-no-cache ignore-no-store ignore-private ignore-auth
ignore-must-revalidate
#refresh_pattern -i
\.(web|avi|f4v|m4v|mpg|3gp|wmv|mov|rmvb|mkv|swf|dat|flv|fla|mp4|webm|00[1-9])
525600 100% 525600 override-expire override-lastmod reload-into-ims
ignore-reload ignore-no-cache ignore-no-store ignore-private ignore-auth
ignore-must-revalidate
#refresh_pattern -i \.(docx?|pptx?|xlsx?|pdf|lit|rtf|pdb|epub|prc|djvu)
525600 100% 525600 override-expire override-lastmod reload-into-ims
ignore-reload ignore-no-cache ignore-no-store ignore-private ignore-auth
ignore-must-revalidate
#refresh_pattern -i
\.(exe|rar|zip|tar|mar|iso|dcr|bz2|gz|7z|uha|bin|dmg|zipx|msi|msu|msp|cab|diff)
525600 100% 525600 override-expire override-lastmod reload-into-ims
ignore-reload ignore-no-cache ignore-no-store ignore-private ignore-auth
ignore-must-revalidate
#refresh_pattern -i \.(mid|mp3|wav|mka|aac|ogg|amr|amf|au|wma|rma) 525600
100% 525600 override-expire override-lastmod reload-into-ims ignore-reload
ignore-no-cache ignore-no-store ignore-private ignore-auth
ignore-must-revalidate
refresh_pattern  . 0 20% 4320 ignore-no-store ignore-must-revalidate
ignore-private ignore-auth store-stale reload-into-ims ignore-reload




#OTHER
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA

#acl fakespeed urlpath_regex -i speedtest\/.*\.(jpg|php).*$
#acl fakespeed urlpath_regex -i results.php\?.*$
#url_rewrite_access allow fakespeed
#url_rewrite_program /etc/squid/rewriter.pl
#url_rewrite_children 10 startup=5 concurrency=10
#redirector_bypass on

cache_mem 512 MB
cache_swap_low 98
cache_swap_high 99

##ZPH
qos_flows local-hit=0x30

## DNS
dns_nameservers 127.0.0.1
ftp_user anonymous@
ftp_passive on
ftp_sanitycheck on

#============================================================$
# SNMP , if you want to generate graphs for SQUID via MRTG
#============================================================$
#acl snmppublic snmp_community public
#snmp_port 3401
#snmp_access allow snmppublic all
#snmp_access allow all


#To prevent caching of a domain:
#acl example dstdomain .example.com
#cache deny example

#acl mix dstdom_regex -i "/etc/squid/block.txt"
#http_access deny mix



sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/squid/ssl_db/certs/ -M 4MB
sslcrtd_children 32 startup=30 idle=1

ssl_unclean_shutdown on
sslproxy_version 1
always_direct allow all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER



ssl_bump server-first all


acl norewrite url_regex -i redirector\.c\.android\.clients\.google\.com
acl norewrite url_regex -i ^http.*(youtube|google).*yt_live_broadcast.*
acl norewrite url_regex -i ^http://redirector\.(googlevideo|c\.youtube)\.com

store_id_program /etc/squid/storeid.pl
store_id_children 40 startup=10 idle=5 concurrency=10
store_id_access deny norewrite
store_id_access deny banned_methods
store_miss deny !banned_methods !http_code_ignored
send_hit deny banned_methods http_code_ignored



pid_filename	/var/run/squid.pid





maximum_object_size 4096 MB
maximum_object_size_in_memory 10 KB
minimum_object_size 512 bytes

icap_206_enable on
httpd_suppress_version_string	on
ipcache_low 98
ipcache_high 99
offline_mode off
#range_offset_limit 1 KB
client_persistent_connections off
server_persistent_connections off
ipcache_size 85120
shutdown_lifetime 10 seconds
log_icp_queries off
icp_hit_stale on
query_icmp on
#high_page_fault_warning 2
nonhierarchical_direct on
prefer_direct off
half_closed_clients off
quick_abort_min 16 KB
quick_abort_max 16 KB
quick_abort_pct 95
range_offset_limit 0

vary_ignore_expire on
#reload_into_ims on
memory_pools off
max_filedescriptors 100000
fqdncache_size 85120
read_timeout 1 minutes
client_lifetime 24 hours
positive_dns_ttl 6 hours
negative_ttl 0 second
negative_dns_ttl 1 second
request_timeout 15 seconds
store_avg_object_size 13 KB
#client_db on
pipeline_prefetch off
forwarded_for off
# If you want to hide your proxy machine from being detected at various site
use following
#via off

global_internal_static off
retry_on_error on
read_ahead_gap 1 KB

minimum_expiry_time 3600 seconds
#accept_filter data=2
relaxed_header_parser on
check_hostnames off
allow_underscore on
request_header_max_size 64 KB
reply_header_max_size 64 KB


#persistent_request_timeout 150 seconds
uri_whitespace allow
ignore_unknown_nameservers off
strip_query_terms off
detect_broken_pconn on
pconn_timeout 150 seconds
store_dir_select_algorithm round-robin



ie_refresh on

#range_offset_limit 64 KB
buffered_logs on
dns_v4_first on




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668834.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Wed Dec 24 11:52:45 2014
From: hack.back at hotmail.com (HackXBack)
Date: Wed, 24 Dec 2014 03:52:45 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419381774083-4668830.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
Message-ID: <1419421965333-4668835.post@n4.nabble.com>

the problem is not from my squid.conf because i try minimal squid.conf with
https and the same problems



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668835.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Dec 24 14:55:46 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 24 Dec 2014 16:55:46 +0200
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419421965333-4668835.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419421965333-4668835.post@n4.nabble.com>
Message-ID: <549AD3F2.80303@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/24/2014 01:52 PM, HackXBack wrote:
> the problem is not from my squid.conf because i try minimal
> squid.conf with https and the same problems

Hey,

A minimal squid and https interception or bumping doesn't stand in the
same place.
A minimal squid is a basic squid.conf after compilation without any
changes.
https_port is a more complex setup.
To understand the complexity of the feature you can start here:
http://wiki.squid-cache.org/Features/SslBump

Eliezer
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUmtPxAAoJENxnfXtQ8ZQU0AYIAI6yI9Hq+vev9mqrRuijRKGF
yDZatXqAUPJssEwR/47lo/uGNvZnOBCOKbwbUcUD0CfvLgW+kFgqivYGKrJv2T0f
2cIfYY949duPeSDX/MJeqESBKi61nN2SQ0MtxL+KCSyQ+ckxsJ9PLS5GDukQnq7K
o3JmU9JAY/v9qxetaEoOt9u/vhlzQ+J+LA88lePWoVCyWl/P0+sk7CAQO9BI0SGc
CTO9HaMfVucuFF8xGdjpTs3UZzqhHdg/aEIRqjk5N5pDQvce8817hw4wJ9ycI7g+
VfnNdydJul1nyLaCFtnyDdejHz8PH1IQ/hVbA/tSgXkt9y9FJsYni7DpWtopEpA=
=H7hw
-----END PGP SIGNATURE-----


From hack.back at hotmail.com  Wed Dec 24 19:08:07 2014
From: hack.back at hotmail.com (HackXBack)
Date: Wed, 24 Dec 2014 11:08:07 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419381774083-4668830.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
Message-ID: <1419448087152-4668837.post@n4.nabble.com>

i dont use minimal squid its just an idea , i put my squid.conf here where is
the problem in it ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668837.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Thu Dec 25 10:04:18 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 25 Dec 2014 12:04:18 +0200
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419448087152-4668837.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com>
Message-ID: <549BE122.7000603@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/24/2014 09:08 PM, HackXBack wrote:
> i dont use minimal squid its just an idea , i put my squid.conf
> here where is the problem in it ?
> 
Well you can say that the issue is too much cache.
What are the machine specs?HDDs?CPUs?RAM?etc..

Eliezer
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUm+EiAAoJENxnfXtQ8ZQUjMAIAJPdjLvztwWYmq6Dg+tr42J2
GvN/iTK3HVpPJOT9igAOAotPSvBpp1ggz5/Dc4viFcXVspzubO8gqUewxv53LK6z
rGfnyWUxVT5hjAQDaG6tcfWSo0NxJaFrCeycuL5v39GKo7+MxQQsfk+FJYyLIIZ0
3VgQmjGU4aDa1PUunuW6KXO/m1I67Pedlega1a+662cm/RkjuTqICh2eOaBSUHVD
QyUQkLhZryoHGsb1x0HhwQIyMnHuUAsTMF1pmx9NJL3B0WRb6RCFURj3LUuG5EFd
8wOTEWhfMqzvfsWTah9wzxYu/yxGzNZhsyn3S5PmVyOU/tZIQqVH2MSzYwgysXo=
=A98s
-----END PGP SIGNATURE-----


From hack.back at hotmail.com  Fri Dec 26 11:38:15 2014
From: hack.back at hotmail.com (HackXBack)
Date: Fri, 26 Dec 2014 03:38:15 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <549BE122.7000603@ngtech.co.il>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
Message-ID: <1419593895219-4668839.post@n4.nabble.com>



5 hdd = 3 terra western digital red edition
1 hdd = 250 ssd ( system )
cpu = core i7 extreme
ram = 32 GB



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668839.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Fri Dec 26 12:22:29 2014
From: hack.back at hotmail.com (HackXBack)
Date: Fri, 26 Dec 2014 04:22:29 -0800 (PST)
Subject: [squid-users] DiskThreadsDiskFile::openDone  squid 3.5.0.4
Message-ID: <1419596549288-4668840.post@n4.nabble.com>

Hello squid ,
after using 3.5.0.4 on fresh debian system
i see many errors in cache.log

2014/12/26 07:21:39 kid1|       /cache03/2/00/31/00003123
2014/12/26 07:21:39 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:21:39 kid1|       /cache04/1/00/5F/00005F16
2014/12/26 07:21:39 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:21:39 kid1|       /cache03/3/00/29/0000291F
2014/12/26 07:21:39 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:21:39 kid1|       /cache05/1/00/11/000011F6
2014/12/26 07:21:45 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:21:45 kid1|       /cache03/3/00/17/0000176C
2014/12/26 07:21:46 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:21:46 kid1|       /cache02/6/00/15/000015CE
2014/12/26 07:21:47 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:21:47 kid1|       /cache02/6/00/0B/00000B07
2014/12/26 07:21:47 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:21:47 kid1|       /cache02/2/00/02/000002B4
2014/12/26 07:22:09 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:09 kid1|       /cache03/4/00/03/00000365
2014/12/26 07:22:12 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:12 kid1|       /cache03/2/00/1F/00001F26
2014/12/26 07:22:12 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:12 kid1|       /cache03/6/00/1F/00001F25
2014/12/26 07:22:13 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:13 kid1|       /cache04/6/00/1F/00001F21
2014/12/26 07:22:15 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:15 kid1|       /cache05/2/00/1F/00001F30
2014/12/26 07:22:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:21 kid1|       /cache02/6/00/1D/00001D5A
2014/12/26 07:22:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:21 kid1|       /cache02/2/00/0C/00000CB5
2014/12/26 07:22:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:21 kid1|       /cache03/5/00/01/00000144
2014/12/26 07:22:31 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:31 kid1|       /cache02/2/00/25/00002504
2014/12/26 07:22:31 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/26 07:22:31 kid1|       /cache04/5/00/24/0000244D
2014/12/26 07:22:31 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/DiskThreadsDiskFile-openDone-squid-3-5-0-4-tp4668840.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From gkinkie at gmail.com  Fri Dec 26 14:49:39 2014
From: gkinkie at gmail.com (Kinkie)
Date: Fri, 26 Dec 2014 15:49:39 +0100
Subject: [squid-users] DiskThreadsDiskFile::openDone squid 3.5.0.4
In-Reply-To: <1419596549288-4668840.post@n4.nabble.com>
References: <1419596549288-4668840.post@n4.nabble.com>
Message-ID: <CA+Y8hcOyfyYQ24R7AysJ13-TmOnsnoURp9jq0OnscE_gpmj1Hg@mail.gmail.com>

Nothing to worry about. The files were removed by some outside
software and were not found. Squid will manage the error and carry on.

On Fri, Dec 26, 2014 at 1:22 PM, HackXBack <hack.back at hotmail.com> wrote:
> Hello squid ,
> after using 3.5.0.4 on fresh debian system
> i see many errors in cache.log
>
> 2014/12/26 07:21:39 kid1|       /cache03/2/00/31/00003123
> 2014/12/26 07:21:39 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:21:39 kid1|       /cache04/1/00/5F/00005F16
> 2014/12/26 07:21:39 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:21:39 kid1|       /cache03/3/00/29/0000291F
> 2014/12/26 07:21:39 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:21:39 kid1|       /cache05/1/00/11/000011F6
> 2014/12/26 07:21:45 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:21:45 kid1|       /cache03/3/00/17/0000176C
> 2014/12/26 07:21:46 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:21:46 kid1|       /cache02/6/00/15/000015CE
> 2014/12/26 07:21:47 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:21:47 kid1|       /cache02/6/00/0B/00000B07
> 2014/12/26 07:21:47 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:21:47 kid1|       /cache02/2/00/02/000002B4
> 2014/12/26 07:22:09 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:09 kid1|       /cache03/4/00/03/00000365
> 2014/12/26 07:22:12 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:12 kid1|       /cache03/2/00/1F/00001F26
> 2014/12/26 07:22:12 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:12 kid1|       /cache03/6/00/1F/00001F25
> 2014/12/26 07:22:13 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:13 kid1|       /cache04/6/00/1F/00001F21
> 2014/12/26 07:22:15 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:15 kid1|       /cache05/2/00/1F/00001F30
> 2014/12/26 07:22:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:21 kid1|       /cache02/6/00/1D/00001D5A
> 2014/12/26 07:22:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:21 kid1|       /cache02/2/00/0C/00000CB5
> 2014/12/26 07:22:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:21 kid1|       /cache03/5/00/01/00000144
> 2014/12/26 07:22:31 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:31 kid1|       /cache02/2/00/25/00002504
> 2014/12/26 07:22:31 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2014/12/26 07:22:31 kid1|       /cache04/5/00/24/0000244D
> 2014/12/26 07:22:31 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/DiskThreadsDiskFile-openDone-squid-3-5-0-4-tp4668840.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From yvoinov at gmail.com  Fri Dec 26 21:33:00 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 27 Dec 2014 03:33:00 +0600
Subject: [squid-users] Squid 3.4.10 cachemgr.cgi permission denied
Message-ID: <549DD40C.1030708@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Hi, gents.

Now I have another problem. Cachemgr.cgi with password does not access
to Squid when password specified.

Look at squid.conf frag (this configuration ffragments derived from
working Squid2 installation):

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# Cache manager
cache_mgr yvoinov at gmail.com

# Cache manager password
cachemgr_passwd secret all

and when I login through local Apache - I've got Squid access denied
page and message in cache.log:

2014/12/24 17:44:17 kid1| CacheManager: unknown at local=127.0.0.1:3127
remote=127.0.0.1:35146 FD 40 flags=1: password needed for 'menu'

Also, Munin plugins cannot work too - they use authenticated cachemgr login.

AFAIK, this means unknown user.

Ok,

now - what username I must use in cachemgr login form?

PS. I found temporary workaround - with disabling password protection
(and disabling dangerous actions in cachemgr), but want to find better
solution.

WBR, Yuri
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUndQMAAoJENNXIZxhPexG008IALoNvSVKavqSTuExfgnx4zNh
Jr3IclALs3xubDyyKXfVB/dHDu+0cccJqPXkERPZuNZ1/FeuZQlRVwvD3BqwDYEa
wTqbn9tzu+spH+YD2KL3SjBu6JzzK0/DDlpzJ1ch0ynRbiOrNhso21Ft3NnMLNhl
VkoZzsI5OJqXe6rD8nO7bdc17npnaZc8Pnn7lwVUsY/fsJkFOObvnQjBHxaJYEdW
swFTbFUJjs977cGPCAHaKVLyuuhCMSzOv0AUgSoqG/PZBNk5VvbsTTan4+U5aKcV
1WFBmpEcdo8aeNUft/TWp1JVMrwMSNZ1/8N3eFwN1nmtwCpqG67HeL/r54PeUW0=
=lOFb
-----END PGP SIGNATURE-----



From squid3 at treenet.co.nz  Sat Dec 27 00:53:05 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 Dec 2014 13:53:05 +1300
Subject: [squid-users] Squid 3.4.10 cachemgr.cgi permission denied
In-Reply-To: <549DD40C.1030708@gmail.com>
References: <549DD40C.1030708@gmail.com>
Message-ID: <549E02F1.7020907@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 27/12/2014 10:33 a.m., Yuri Voinov wrote:
> 
> Hi, gents.
> 
> Now I have another problem. Cachemgr.cgi with password does not
> access to Squid when password specified.
> 
> Look at squid.conf frag (this configuration ffragments derived
> from working Squid2 installation):
> 
> # Only allow cachemgr access from localhost http_access allow
> localhost manager http_access deny manager
> 
> # Cache manager cache_mgr yvoinov at gmail.com
> 
> # Cache manager password cachemgr_passwd secret all
> 
> and when I login through local Apache - I've got Squid access
> denied page and message in cache.log:
> 
> 2014/12/24 17:44:17 kid1| CacheManager:
> unknown at local=127.0.0.1:3127 remote=127.0.0.1:35146 FD 40 flags=1:
> password needed for 'menu'
> 
> Also, Munin plugins cannot work too - they use authenticated
> cachemgr login.
> 
> AFAIK, this means unknown user.
> 
> Ok,
> 
> now - what username I must use in cachemgr login form?

You should get the administrators to use their normal username and the
mgr password. The cachemgr itself only checks the password matches the
one in squid.conf for that manager action. Username is used if some
other security checks are in place such as proxy_auth ACLs, and for
logging.

The cachemgr now has three methods of access. Direct http:// and
https:// URLs from the browser to Squid, and the old cache_object://
URLs sent by cachemgr and existing tools (Munin?). Though HTTPS only
works properly in reverse-proxy at the moment and it is all a bit
picky about the URL matching Squids public domain name (visible_hostname).

All of those methods can have user:password in a Basic www-auth header
(not proxy-auth), or the @password tacked on the end of the URL. Squid
should be generating a 401 auth challenge to get that Basic header,
not a full 403 Forbidden access denied.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUngLxAAoJELJo5wb/XPRjpUQIAId3lEcO8aIxMeP3wuW2//fg
2z4klihTpTcSD1ZxMrLMfDyS0JAAaZr967MQc9+txPThwZ9GL13uFiBhrfbvJmoT
7MS35K5aLHTP0CpbbxYwIv9Frah7GtFGiyslV8+m0l67428JIgDYIxm9wOcW5LLL
LiyK8taI4bBa5SmALD7gM1kP2hUERCRqq8rxelz/fVHN4eqjFSie2ELZu090R/Fc
riQut3W4r6LT30S3vS2+koFFce+cYNFyCYMn1NxAtOmnejkIAh/SkHFphNLT1/wy
6yh6iRMl43pi84/UzQK4Jq5ZGjbRcsgGSxMO31W4PEgCMD9U2R8Uw+qyRA82pnU=
=UgC2
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Sat Dec 27 02:29:01 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 Dec 2014 15:29:01 +1300
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419593895219-4668839.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com>
Message-ID: <549E196D.1070104@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 27/12/2014 12:38 a.m., HackXBack wrote:
> 
> 
> 5 hdd = 3 terra western digital red edition

These 5 HDD is what we refer to as "spindles" when planning and
calculating cache arrangement.

* You have 5 disk "spindles".
* UFS/AUFS/diskd can only handle one cache_dir per spindle.
 - doing more will make their I/O operations collide and drastically
reduce disk speeds.

Therefor you can have 5x AUFS cache_dir on this machine.

BUT that does not exactly mean only 5 cache_dir. You can have a COSS
or Rock cache_dir alongside the UFS based on on the same spindle.
Making a total of 10 cache_dir for these disks.


> 1 hdd = 250 ssd ( system )

SSD can technically handle more than one of each type of cache_dir.
But Rock/COSS align much better with the drives internal design. So
IMO, you can have up to 5 AUFS cache_dir, and up to 6 Rock cache_dir
on this machine...


> cpu = core i7 extreme ram = 32 GB
> 

In your squid.conf you have 30 cache_dir of size 400000 MB.

At an average memory requirement of 15MB per GB of cache that means
your machine requires approx. 171 GB of RAM for fast performance when
its caches are full.

That is also just for the HTTP object cache index, no room for any
active transactions or traffic, or other caches Squid needs to operate.


With 32GB your machine is probably able to comfortably use around 2000
GB of disk cache. In otherwords only 5 of those 400GB cache_dir
directories you have given it. (Co-incidence that matches the HDD count.)


In your place I would assign a 50GB Rock cache_dir to each of the 5
HDD (for objects up to 31KB), and a 400 GB or so UFS/AUFS cache_dir on
each as well (for objects over 31KB).

Using the SSD for system swap space, so in case things get overloaded
in memory the swap is at least fast you could probably expand the
UFS/AUFS cache_dir sizes. But that requires experimentation to find
the right balance, and using the swap for reagular traffic is not a
good idea, just emergency peak loads.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUnhltAAoJELJo5wb/XPRjtLAH/AkBDPwLuTJmimvbujuX70FW
8KlqKanXXRIYiawoORNGqIQ7g2vxcW4l5vmpdO2gAQ/RZeedEoyojbhtx87JKXL2
zqnV+irtLkIxOrt6uBHqT4W3UB/8G7DAsA1A/HL5c4Ce7LTXxV2uNG31/EvEMRKG
GLlmyFMkEC8vVF2PwkWT0RUpi7sIA1ywHrlWxA3JlyNLVXs1UlXP5xs2b8mJeM0Z
bymuQYi5qdlqVOqrRDF+gappGJsXoSFbZcKud7G9bNFTvi+VVsTe9lYc5jxBmaIp
8dtMCMK5n6WFYqK+cLw4Dz7ux+5Eqgiu7qRNnm5507v6lk63aUjzeHODAMY7EtY=
=Bh1L
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Sat Dec 27 12:27:48 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 27 Dec 2014 18:27:48 +0600
Subject: [squid-users] Squid 3.4.10 cachemgr.cgi permission denied
Message-ID: <549EA5C4.20009@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Hm,

I don't think so.

proxy_auth cannot be use on transparent interceptor.

Does it mean, that cachemgr authentification impossible in my case?

Or, may be, we have bug there?

WBR, Yuri
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUnqXEAAoJENNXIZxhPexG+k8IAMSjiiRs9GLcuigXdVtWW9uX
P1A8Kj6/yscQcJeHceaZ9eZsH1R/2TYRuMk8H4k0Ct7fnt8las/mIJYshN+FxBiP
ZqQx+ZXEwmaMyYvvHzPZtCGA8Jdd4LpBnkTP37nj3Z30bWMR9y6i9neiyvJ7+f6B
ETOSUXyD0iMoA60Wzg+j0UBiLHNmj1q1klZ0JIQv5/oTp5kK4j2fB3ENdEI6d8jm
qNopO65ipeooAd5O32P1KeUziKeEsZiPBjQ9EBBkuoggTAB7kGGC+8WYkxrjuIGf
r8c2+BvKEdIfVsTCyGzPZCRWDrJ30cd+rVWLJvxDE5W1aAGoOMnP1gFBk/QDG5I=
=0oZb
-----END PGP SIGNATURE-----



From eliezer at ngtech.co.il  Sat Dec 27 19:13:34 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 27 Dec 2014 21:13:34 +0200
Subject: [squid-users] Squid 3.4.10 cachemgr.cgi permission denied
In-Reply-To: <549EA5C4.20009@gmail.com>
References: <549EA5C4.20009@gmail.com>
Message-ID: <549F04DE.6020906@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Yuri,

I am not sure yet how you have tried to access the cachemgr?
The basic settings of squid allow any request throw 127.0.0.1 and the
basic forward proxy port access to cache mgr interface.
If you are using Munin and it cannot access put this aside and lets
try to make sure the basic access to the cachemgr interface works or
do not.
If you can describe each step(not related to munin) it will help to
find the issue.
A 403 access denied might come from the apache server.

Eliezer

On 12/27/2014 02:27 PM, Yuri Voinov wrote:
> Hm,
> 
> I don't think so.
> 
> proxy_auth cannot be use on transparent interceptor.
> 
> Does it mean, that cachemgr authentification impossible in my
> case?
> 
> Or, may be, we have bug there?
> 
> WBR, Yuri

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUnwTeAAoJENxnfXtQ8ZQUe78IAJ/STkCBm1qKwVxfm58mRhgL
Ha0Rs5WZfP4hvLpswxTW5/eZCB9iGLDCFvVDOliPQ/KDlfAO1BjeRSMjM8OvaHSn
y4/IdUAIwg7fB2aJ9pKq5vwq+/6TxGA/faDKUxYqg7EgiFT7IwJonS04p8u4YHjZ
4sKuUB/Ys3qFqby5DXiE/59YWL7qjQC+yk7dNIPhd+BLKM9BIj9DrhjeaE9d2YZC
JuYE3ZiECJ5CZW6V5FzbluOO3QuX66m/hFxDcPBzfYgiY+Z11TXt0/o5lfBdwsNK
IgIyiE5RKijen9pHjHwh0848riImNj91iSETUmvDFVDVwL5eBHae4efZ/DbPINw=
=/hU8
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Sat Dec 27 19:16:05 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 27 Dec 2014 21:16:05 +0200
Subject: [squid-users] DiskThreadsDiskFile::openDone  squid 3.5.0.4
In-Reply-To: <1419596549288-4668840.post@n4.nabble.com>
References: <1419596549288-4668840.post@n4.nabble.com>
Message-ID: <549F0575.2000801@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 12/26/2014 02:22 PM, HackXBack wrote:
> Hello squid , after using 3.5.0.4 on fresh debian system i see many
> errors in cache.log

Hey There,

(leaving aside these errors)
As a part of a cache proxy integration I am generally recommending to
do it in steps by first using a proxy with ram only cache while later
adding the disk cache to make sure the machine can hold the basic
environment loads.

Eliezer
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUnwV1AAoJENxnfXtQ8ZQU7+kIAJoKcCbkRdgndSTsZiHyYMY8
oTJWAafR094ThJp6LFurkDaAZqaZhpa8ncBFlKaB9MQOUt5ylDGnFfGm9CNcdHOx
dtNIJl/FHxEylw4YABp89A8DuoepRRMDa6ACrtW74JV1UB7t6kYJzZIkZYYymn39
cTS5HeJlTc1aG/UJXtXDwkZnQ2ZQLIGhshfgCuuI7PN6hgljY2nrsmgbWsL1Jc3j
EjejRi4KdJQujlGyQJ0fvQYAxqWYKHYPJFnFYApT2Glqb+KHdMhKwBbsBpuqhUQM
loPc05vgcxqvR/RwiyYWcQDL7X4wLMEDn+NFu3MPnJ4O9jQLcqD8l9X2TMjOco8=
=KGXb
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Sat Dec 27 21:03:59 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 28 Dec 2014 03:03:59 +0600
Subject: [squid-users] Squid 3.4.10 cachemgr.cgi permission denied
Message-ID: <549F1EBF.4010700@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Smear in my hand... :))))))

I have forgotten to enable basic auth when build....

My stupid head.... :))))))))

All ok now.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUnx6/AAoJENNXIZxhPexGxIgH/AqTEHdtM2QJdhhGIHLFVsqc
E/AzxoL+aWaJD6dH86e7splJj4kw6+GMKvhwZwxWJkHcCZtLMEqNnKuGKlHr7mB7
Mz5nm6p3Sli69yOKwUM5Gk6nJMap8iA7fAdTnCQxs509CZov0GYQ/nTUmZYD/b71
ZwzVU+GnEwVvURE22S5dpk9BwS+XAjZbwbZSkwvObQLSJsjjILnX/ALHR1JtEzz1
G90945GqvTnt0JIJTJ7ESmX/DBIl6lbKuyw0avAMdA8rTs0tu+jRyQwEG+7wrwoQ
BVNgckTIMyZLIOMIY5a1pZ6HHTQm8rynIe1SKKVAqDD95qQ7ZouMwQ1r7Tx5R+A=
=sXAp
-----END PGP SIGNATURE-----



From squid3 at treenet.co.nz  Sun Dec 28 02:17:25 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 28 Dec 2014 15:17:25 +1300
Subject: [squid-users] Squid 3.4.10 cachemgr.cgi permission denied
In-Reply-To: <549EA5C4.20009@gmail.com>
References: <549EA5C4.20009@gmail.com>
Message-ID: <549F6835.5090202@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 28/12/2014 1:27 a.m., Yuri Voinov wrote:
> 
> Hm,
> 
> I don't think so.
> 
> proxy_auth cannot be use on transparent interceptor.
> 
> Does it mean, that cachemgr authentification impossible in my
> case?
> 
> Or, may be, we have bug there?

You should be using port 3128 without intercept flags on it for this
management access. That is what port 3128 is registered for.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUn2gzAAoJELJo5wb/XPRjhFsIAIahg1nejK70RQDuoHtopd+k
WJPPUPKwJHSveiLDlyZWSRhZ2wqwaizNb7HNVqFlRldSMRkFw0u4202UvSomV1Bj
4XalGGD5HMZdfp0dJCEYbZSFBDa6FkS98e0bgWxs9Z3MZ/daxKFo9gdgaoG6S3tq
gqajysPlmiXJVIEERznhDMsgztBFMaI/WhkEbcBOwqu7m5qiXW2rI59DovsNkj0d
gxqEH5BR0bX7zJj1MgIYOGUqNtkjyCqkAL7tqXuWWjYSKjiLH5P86sAhRJvkhKWj
EwtsFye9GC0UKv8DyFI9y8J3+CTV/q3JizlSzXHNnocTKCxTh3t67SNT+QVBapU=
=0fek
-----END PGP SIGNATURE-----


From hack.back at hotmail.com  Sun Dec 28 22:21:16 2014
From: hack.back at hotmail.com (HackXBack)
Date: Sun, 28 Dec 2014 14:21:16 -0800 (PST)
Subject: [squid-users] another squid 3.5.0.4 bug [restart automatically]
Message-ID: <1419805276984-4668851.post@n4.nabble.com>


2014/12/29 00:20:16 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2014/12/29 00:20:16 kid1|       /cache03/4/00/04/000004AB
2014/12/29 00:20:22 kid1| Could not parse headers from on disk object
2014/12/29 00:20:22 kid1| BUG 3279: HTTP reply without Date:
2014/12/29 00:20:22 kid1| StoreEntry->key: DA29B0A1E9099BB8CE0C0CE80D41F6B7
2014/12/29 00:20:22 kid1| StoreEntry->next: 0
2014/12/29 00:20:22 kid1| StoreEntry->mem_obj: 0x15d87f20
2014/12/29 00:20:22 kid1| StoreEntry->timestamp: -1
2014/12/29 00:20:22 kid1| StoreEntry->lastref: 1419830422
2014/12/29 00:20:22 kid1| StoreEntry->expires: -1
2014/12/29 00:20:22 kid1| StoreEntry->lastmod: -1
2014/12/29 00:20:22 kid1| StoreEntry->swap_file_sz: 0
2014/12/29 00:20:22 kid1| StoreEntry->refcount: 1
2014/12/29 00:20:22 kid1| StoreEntry->flags: PRIVATE,FWD_HDR_WAIT,VALIDATED
2014/12/29 00:20:22 kid1| StoreEntry->swap_dirn: -1
2014/12/29 00:20:22 kid1| StoreEntry->swap_filen: -1
2014/12/29 00:20:22 kid1| StoreEntry->lock_count: 2
2014/12/29 00:20:22 kid1| StoreEntry->mem_status: 0
2014/12/29 00:20:22 kid1| StoreEntry->ping_status: 2
2014/12/29 00:20:22 kid1| StoreEntry->store_status: 1
2014/12/29 00:20:22 kid1| StoreEntry->swap_status: 0
2014/12/29 00:20:22 kid1| assertion failed: store.cc:1887: "isEmpty()"




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/another-squid-3-5-0-4-bug-restart-automatically-tp4668851.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Sun Dec 28 22:46:28 2014
From: hack.back at hotmail.com (HackXBack)
Date: Sun, 28 Dec 2014 14:46:28 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <549E196D.1070104@treenet.co.nz>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
Message-ID: <1419806788826-4668852.post@n4.nabble.com>

you're explain is complicated for me and sorry for that
but i want to understand more if that not bother you.
at first lets talk about cache_dir
what you are telling me is to do rock and aufs for each HDD
what you mean is like this :
cache_dir rock /cache01/rk 50000 120 256 max-size=31744
cache_dir aufs/cache01/au 400000 961 256 min-size=31745

for each HDD
but in this way i will consume only 450 GB from 3TerraByte
and this is not enough for me and will be full very fast especially for
caching videos and large files and this is a problem while i cant add more
rams for this hardware, so what is the solution for this ?

also you said that is for only http objects , so what about caching https
files like youtube videos ? why i cant take these traffic also ?

Thank you dear Amos .



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668852.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Sun Dec 28 23:19:35 2014
From: hack.back at hotmail.com (HackXBack)
Date: Sun, 28 Dec 2014 15:19:35 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <549E196D.1070104@treenet.co.nz>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
Message-ID: <1419808775284-4668853.post@n4.nabble.com>

also what if i use all my free space of my ssd to swap then this will solve
the requirements 1gb per 15mb ??



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668853.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Sun Dec 28 23:47:37 2014
From: hack.back at hotmail.com (HackXBack)
Date: Sun, 28 Dec 2014 15:47:37 -0800 (PST)
Subject: [squid-users] another squid 3.5.0.4 bug [restart automatically]
In-Reply-To: <1419805276984-4668851.post@n4.nabble.com>
References: <1419805276984-4668851.post@n4.nabble.com>
Message-ID: <1419810457908-4668854.post@n4.nabble.com>

2014/12/28 18:47:35 kid1| StoreEntry->swap_dirn: -1
2014/12/28 18:47:35 kid1| StoreEntry->swap_filen: -1
2014/12/28 18:47:35 kid1| StoreEntry->lock_count: 2
2014/12/28 18:47:35 kid1| StoreEntry->mem_status: 0
2014/12/28 18:47:35 kid1| StoreEntry->ping_status: 2
2014/12/28 18:47:35 kid1| StoreEntry->store_status: 1
2014/12/28 18:47:35 kid1| StoreEntry->swap_status: 0
2014/12/28 18:47:35 kid1| Could not parse headers from on disk object
2014/12/28 18:47:35 kid1| BUG 3279: HTTP reply without Date:
2014/12/28 18:47:35 kid1| StoreEntry->key: F893798EF9815BFEE4B3254CCE88EDDE
2014/12/28 18:47:35 kid1| StoreEntry->next: 0x895bc78
2014/12/28 18:47:35 kid1| StoreEntry->mem_obj: 0x1bb2e670
2014/12/28 18:47:35 kid1| StoreEntry->timestamp: -1
2014/12/28 18:47:35 kid1| StoreEntry->lastref: 1419810455
2014/12/28 18:47:35 kid1| StoreEntry->expires: -1
2014/12/28 18:47:35 kid1| StoreEntry->lastmod: -1
2014/12/28 18:47:35 kid1| StoreEntry->swap_file_sz: 0
2014/12/28 18:47:35 kid1| StoreEntry->refcount: 1
2014/12/28 18:47:35 kid1| StoreEntry->flags: PRIVATE,FWD_HDR_WAIT,VALIDATED
2014/12/28 18:47:35 kid1| StoreEntry->swap_dirn: -1
2014/12/28 18:47:35 kid1| StoreEntry->swap_filen: -1
2014/12/28 18:47:35 kid1| StoreEntry->lock_count: 2
2014/12/28 18:47:35 kid1| StoreEntry->mem_status: 0
2014/12/28 18:47:35 kid1| StoreEntry->ping_status: 2
2014/12/28 18:47:35 kid1| StoreEntry->store_status: 1
2014/12/28 18:47:35 kid1| StoreEntry->swap_status: 0
2014/12/28 18:47:35 kid1| Could not parse headers from on disk object
2014/12/28 18:47:35 kid1| BUG 3279: HTTP reply without Date:
2014/12/28 18:47:35 kid1| StoreEntry->key: BFD1385AD593FD5A1A4EA26DBE010AB0
2014/12/28 18:47:35 kid1| StoreEntry->next: 0
2014/12/28 18:47:35 kid1| StoreEntry->mem_obj: 0x1bcedb40
2014/12/28 18:47:35 kid1| StoreEntry->timestamp: -1
2014/12/28 18:47:35 kid1| StoreEntry->lastref: 1419810455
2014/12/28 18:47:35 kid1| StoreEntry->expires: -1
2014/12/28 18:47:35 kid1| StoreEntry->lastmod: -1
2014/12/28 18:47:35 kid1| StoreEntry->swap_file_sz: 0
2014/12/28 18:47:35 kid1| StoreEntry->refcount: 1
2014/12/28 18:47:35 kid1| StoreEntry->flags: PRIVATE,FWD_HDR_WAIT,VALIDATED
2014/12/28 18:47:35 kid1| StoreEntry->swap_dirn: -1
2014/12/28 18:47:35 kid1| StoreEntry->swap_filen: -1
2014/12/28 18:47:35 kid1| StoreEntry->lock_count: 2
2014/12/28 18:47:35 kid1| StoreEntry->mem_status: 0
2014/12/28 18:47:35 kid1| StoreEntry->ping_status: 2
2014/12/28 18:47:35 kid1| StoreEntry->store_status: 1
2014/12/28 18:47:35 kid1| StoreEntry->swap_status: 0




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/another-squid-3-5-0-4-bug-restart-automatically-tp4668851p4668854.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon Dec 29 04:46:10 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 Dec 2014 17:46:10 +1300
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419806788826-4668852.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
 <1419806788826-4668852.post@n4.nabble.com>
Message-ID: <54A0DC92.6040404@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 29/12/2014 11:46 a.m., HackXBack wrote:
> you're explain is complicated for me and sorry for that but i want
>  to understand more if that not bother you. at first lets talk
> about cache_dir what you are telling me is to do rock and aufs for
> each HDD what you mean is like this : cache_dir rock /cache01/rk
> 50000 120 256 max-size=31744 cache_dir aufs/cache01/au 400000 961
> 256 min-size=31745
> 
> for each HDD but in this way i will consume only 450 GB from 
> 3TerraByte and this is not enough for me and will be full very fast
> especially for caching videos and large files and this is a problem
> while i cant add more rams for this hardware, so what is the
> solution for this ?

It is a starting point. The size parameter on the AUFS cache_dir can
be increased as needed later with only a "squid -k reconfigure" and no
data loss. Just set the L1/L2 cache parameters suitable for a large
cache size, they cannot be changed easily.
NP: I also notice your L1 parameter is 961 ... both numbers need to
be even (multiples of 2, or better powers of 2).


15 TB cache (5x 3TB) may be too much and never filled if our traffic
is mostly small objects. Only if your users request a lot of video
will it be used.

If you are expecting a large number of under-32KB objects you can
double the rock cache to 100GB. But it gets slow to manage the Rock DB
if it gets too big (rock is a singe database file containing DB
records/slots with an object in each).

The key problem(s) currently is that you have/had too many cache_dir
on each HDD. The memory required to handle them is bigger than the
machine contains and they are competing for disk I/O bandwidth. Both
of which slow Squid down - sometimes a lot.




> 
> also you said that is for only http objects , so what about caching
> https files like youtube videos ? why i cant take these traffic
> also ?

HTTPS is HTTP. Just using a TLS transport instead of TCP transport.
When it comes to caching there is no difference.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUoNySAAoJELJo5wb/XPRjxIYH/Rc8yzu4tZ1MKwg5dfJYWINl
GKeIESk1bZWGBqRYWGHjRihy4NlwYqWB9qD0TYdskbGW0VgpcRH97OBmroSD6BZn
EPVGwLhINpqJo7PEb9TIg7FIXCoI8ADH5rKUmq/5/SCoSuF4cOIq9tFZuQaBOjT0
PH2OYFuVd+uJ3AA5uWtulzBDMAPyDW5V7RraZYokBPws+kRoIE0r60oqGbFUuwLo
VXd+d97E1HRL4uPsaLbZuVG/VenbGzm1/ppn2zn5pSm5/cmqFYJWjg5686Qcp+1x
wY/xxMyxrAO4FNcMtB8VVSd+EnLGFbHvc6dc3F3bOK+EUNZJCc/TPoVY7DhwcJw=
=zzIG
-----END PGP SIGNATURE-----


From hack.back at hotmail.com  Mon Dec 29 12:20:00 2014
From: hack.back at hotmail.com (HackXBack)
Date: Mon, 29 Dec 2014 04:20:00 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <54A0DC92.6040404@treenet.co.nz>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
 <1419806788826-4668852.post@n4.nabble.com> <54A0DC92.6040404@treenet.co.nz>
Message-ID: <1419855600388-4668856.post@n4.nabble.com>

Mr Amos thanks for replaying ,
for L1/L2 numbers i am using this calculation , but i dont know if it is
right ?

Then using this formula from a friend ((( x / y ) / 256 ) / 256 ) * 2 = L1
x is the size of the partition, in KB unit.
y is the size of object that 13KB average
L1 is the option in cache_dir means how many directory exist in the
partition
L2 is the option in cache_dir means how many folder inside the L1 folder.
Usually 256
So my calculation is this ((( 2960000 KB / 13 KB) / 256 ) / 256 ) * 2 = 6.9


15 TB cache (5x 3TB) is not too much because this 15 TB can be full in about
6 month's.

what i didnt understand in this replay is what you mean in using TLS instead
of TCP transport, where i can find the manual conf for this ?

Thank you Dear Amos .



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668856.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Mon Dec 29 12:37:52 2014
From: hack.back at hotmail.com (HackXBack)
Date: Mon, 29 Dec 2014 04:37:52 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419855600388-4668856.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
 <1419806788826-4668852.post@n4.nabble.com> <54A0DC92.6040404@treenet.co.nz>
 <1419855600388-4668856.post@n4.nabble.com>
Message-ID: <1419856672924-4668857.post@n4.nabble.com>

HTTPS is HTTP when it is decrypted by openssl and using certificate , i
already did that,
but the problem exist , https browsing is still slow and drops the packet
when redirect the traffic to squid



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668857.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Mon Dec 29 18:12:51 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 29 Dec 2014 20:12:51 +0200
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419856672924-4668857.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
 <1419806788826-4668852.post@n4.nabble.com> <54A0DC92.6040404@treenet.co.nz>
 <1419855600388-4668856.post@n4.nabble.com>
 <1419856672924-4668857.post@n4.nabble.com>
Message-ID: <54A199A3.2040102@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Hack,

As I suggested you before you add disk cache to the machine let the
machine run only on memory cache with default settings and then and
only then change the settings.
Start with the default and change it to intercept only http traffic.
Then you can see the proxy handling your http traffic.
When you see that http traffic interception is not slowing down the
clients speed and *only* then try to add ssl interception and only
then try to see with default settings with addition the needed lines
for http interception and https interception see how the proxy play
for you.

There are couple options to your issue and if you will rush to just
"cache http and https" the results might not be as you need or want.

If you are willing to take the slow path in order to find out if this
machine is good enough to take your load first help can be considered
an option.
If not then you might see the server lumping and runs *slow* without
understanding the issue in hands.

All The Bests,
Eliezer

On 12/29/2014 02:37 PM, HackXBack wrote:
> HTTPS is HTTP when it is decrypted by openssl and using certificate
> , i already did that, but the problem exist , https browsing is
> still slow and drops the packet when redirect the traffic to squid

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUoZmjAAoJENxnfXtQ8ZQUFj8H/jCV5E9KgIvGNeEz//lZUGlt
xjBI3l+GP/fCG1dP9fswuQbX78iGmL3IMCgcZlk845RGvKHhnfP1M87bx8GYrJGu
25a84VdGH3srMY7iE09TXP+w+oJ/g04GU6QgzgPOqVsbSWGR/9vB257jm/FQ33kT
TwDfW2h/N8RR+vNABhNpDOh8emeNKFV38lmn8z7LTE2tXqn44XSne9Dzzcm2u2sO
EZYj1h7FiVAMsdkEhuFrtUpJK9FZkm8gZ8G5kL7BhBWdXXP9ecuZ3wLOEXpFYi1p
WohDJ2xnaPna6NGZ06PY1yTIxVXhBvIYDIlDRcQyp9OMiFTbDDgM+A24qr+nCjg=
=3hCq
-----END PGP SIGNATURE-----


From hack.back at hotmail.com  Mon Dec 29 18:39:01 2014
From: hack.back at hotmail.com (HackXBack)
Date: Mon, 29 Dec 2014 10:39:01 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <54A199A3.2040102@ngtech.co.il>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
 <1419806788826-4668852.post@n4.nabble.com> <54A0DC92.6040404@treenet.co.nz>
 <1419855600388-4668856.post@n4.nabble.com>
 <1419856672924-4668857.post@n4.nabble.com> <54A199A3.2040102@ngtech.co.il>
Message-ID: <1419878341964-4668859.post@n4.nabble.com>

Dear Eliezer Croitoru,
what you suggest for me already done , http not slow and http work like a
charm but the slow in https traffic also there is drop on https packets
also i mentioned the log when the packet https roped :

with 3.5.0.4 
2014/12/23 19:33:10 kid1| Error negotiating SSL on FD 317:
error:1409F07F:SSL routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0) 

with 3.4.x
Error negotiating SSL connection on FD 36:
error:00000000:lib(0):func(0):reason(0) 

now i will downgrade for 3.4.10 and i will see a lot of logs while browsing
https 
Error negotiating SSL connection on FD 36:
error:00000000:lib(0):func(0):reason(0) 


Another helpful question , i want to buy trusted certificate to use it with
squid , the question is which type of certificate i need , i bought one from
X and its type for apache , but when i used it with squid , https error in
browser says that invalid type, so what type of certificate i need for that 
?

Thanks Very Much
Best Regards.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668859.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Mon Dec 29 19:34:53 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 29 Dec 2014 21:34:53 +0200
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419878341964-4668859.post@n4.nabble.com>
References: <1419381774083-4668830.post@n4.nabble.com>
 <1419448087152-4668837.post@n4.nabble.com> <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
 <1419806788826-4668852.post@n4.nabble.com> <54A0DC92.6040404@treenet.co.nz>
 <1419855600388-4668856.post@n4.nabble.com>
 <1419856672924-4668857.post@n4.nabble.com> <54A199A3.2040102@ngtech.co.il>
 <1419878341964-4668859.post@n4.nabble.com>
Message-ID: <54A1ACDD.1080601@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Hack,

So now the image is much clear.
I would assume that the ssl DB is stored in the SSD and not on sniping
disks.
Since the issue is with SSL only the issue still should be tested with
no disk cache at all.
This is to test the SSL issue and minimize the relevant data.
I do not know the exact reasons for all errors but couple pointers.

* for squid ssl-bump you will need a rootCA certificate which cannot
be bought by just anyone and there for the assumption to buy one is
not an option.
* All over the world many work places use a local rootCA for internal
usage and ssl content inspection and it's not a new thing that you
cannot buy a rootCA certificate(or in this case private key) and it
will be published to just anyone.


Specifically for the FD and\or ssl negotiation issue, it is possible
that such an issue will arise since there are more then couple cases
which sslctrd helper might was not immunized against.
The source for the issue can be (from my eyes) in the network level or
the disk level or others.
In any case if the issue came up and exists and the reason for the
issue is squid internals that causes crashes(can be seen in the
cache.log) the approach will be one.
While if the issue is not causing crashes and the service continues to
work properly but slow you maybe need to go one step back into the
load testing.
It's not the only option so a bug is an option but from my eyes squid
is just being honest with the admin about an issue.

I have seen your squid.conf and it's far from defaults.....
You can try to run "diff your_squid.conf default_squid.conf" and see
what I am talking about.

If you want to solve the issue I would recommend you like before to
start from 0 squid.conf and adding only the basics so at-least my head
can contain the picture about your server.

All The Bests,
Eliezer

On 12/29/2014 08:39 PM, HackXBack wrote:
> Dear Eliezer Croitoru, what you suggest for me already done , http
> not slow and http work like a charm but the slow in https traffic
> also there is drop on https packets also i mentioned the log when
> the packet https roped :
> 
> with 3.5.0.4 2014/12/23 19:33:10 kid1| Error negotiating SSL on FD
> 317: error:1409F07F:SSL routines:SSL3_WRITE_PENDING:bad write retry
> (1/-1/0)
> 
> with 3.4.x Error negotiating SSL connection on FD 36: 
> error:00000000:lib(0):func(0):reason(0)
> 
> now i will downgrade for 3.4.10 and i will see a lot of logs while
> browsing https Error negotiating SSL connection on FD 36: 
> error:00000000:lib(0):func(0):reason(0)
> 
> 
> Another helpful question , i want to buy trusted certificate to use
> it with squid , the question is which type of certificate i need ,
> i bought one from X and its type for apache , but when i used it
> with squid , https error in browser says that invalid type, so what
> type of certificate i need for that ?
> 
> Thanks Very Much Best Regards.
> 
> 
> 
> -- View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668859.html
>
> 
Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUoazdAAoJENxnfXtQ8ZQUv0IH/RUpy8hbyTy09ZJBv7UeLtn+
BwaDM6z2pKrTesW7ooxYfys3vfR11Fw1BZSzCLa0pzkHs8TUT3bNQYrh7RiXJbiy
KfNVGu22XUmlmo1+uVIc1FfJgu1j71wzxsY/rz6gD9Lgi2yOkdDZBr6A/qrW1ZTo
I0E8UaKAGLgiijHTCu91VY0g19ydP9yzs3e1MG10e0IQ4dwi/RuT86pI9mbVYfW4
rGaLakytyuoJ2Isq2naR5YkPjFG9prgDedO62gxE1UGftOJQ8Axotbglb+HJAcUO
0wCdapvRU86n+Uihqg8XVM7rZ8G7oM49D3o+Zefteu10n8jerJrXzAB3249VhKM=
=2x8x
-----END PGP SIGNATURE-----


From derek.cole at gmail.com  Mon Dec 29 23:02:32 2014
From: derek.cole at gmail.com (Derek Cole)
Date: Mon, 29 Dec 2014 18:02:32 -0500
Subject: [squid-users] squid unable to start on CentOS 6.5
In-Reply-To: <5498B7FB.9000909@treenet.co.nz>
References: <CAHrteQUVuOqRO5LcYEjwSovf9jymtxxL4Fh62U1RRtJ86aihsw@mail.gmail.com>
 <549897DB.6020002@ngtech.co.il>
 <CAHrteQVJzDufMdHGTD8rG+N-FuXMLnUwx1kbwku02kSn12v-eA@mail.gmail.com>
 <54989D44.4060501@ngtech.co.il>
 <CAHrteQU0JQSUwbxi8aB+6pZa=EE-bj0vW4fLetVuQVM9KSj68Q@mail.gmail.com>
 <CAHrteQX2geEWLEg2r-2sra1g0-Z7O2iKbrNfWzMjtu1i5Vog3A@mail.gmail.com>
 <CAHrteQVNB1ESFVhKGftu4mrmyh9CcxdkVTCHgCViLsAyz0aKFQ@mail.gmail.com>
 <5498A6C5.80704@ngtech.co.il>
 <CAHrteQWQ+du9VhPkeKES-tDOiqB_+tfWWkOnsv_GZ8q-41XQ9A@mail.gmail.com>
 <5498AC67.9050802@ngtech.co.il> <5498B7FB.9000909@treenet.co.nz>
Message-ID: <CAHrteQUC+VvviXS18vY7qJKUsR0LOwnmXtPhQy7hRMvETMouHw@mail.gmail.com>

I just wanted to let you know that I got back to look at this problem. I
have tried to uninstall and re-install squid with just default RPM's
squid.conf, and it still will not launch. Tomorrow I am going to try to
install on a fresh VM with the exact same kernel version and see what kind
of results I have.

-Derek

On Mon, Dec 22, 2014 at 7:31 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 23/12/2014 12:42 p.m., Eliezer Croitoru wrote:
> > Well Derek,
> >
> > I must write something "I am amazed!!!" In Step 7 there is a little
> > confusion. The "accel vhost allow-direct" options are not for
> > transparent and\or interception proxy and I am unsure why it
> > works.
>
> It "works" because the traffic syntax for port 80 is accepted by both
> intercept (transparent intercept-proxy) and accel (web server
> reverse-proxy) modes. The "allow-direct" settings then converts the
> reverse-proxy into a highly vulnerable Open Proxy. Plus firewall NAT
> settings diverting all traffic (from both LAN and WAN!)
>
>
>
> Derek, If you got to step 9 then *immediately* go to your firewall
> setup and erase that line containing:
>  -i $ETHERNET_INTERNET -p tcp --dport 80 -j REDIRECT
>
> It is completely needless on WAN interface and should never be used in
> the form shown there. The tutorial Eliezer linked below contains all
> you need for transparent interception.
>
>
>
> > you should use something like: http_port 127.0.0.1:3128 http_port
> > 13128 intercept
>
> nod.
>
> >
> > Instead of what mentioned in the tutorial. I would try to use
> > another tutorial or guide to install squid in transparent mode.
> > Have you tried our wiki? I have found this for you:
> > http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect
> >
> > Else then couple little mistakes(which I will gladly be open to
> > help with) the tutorial looks very good.
> >
> > Try my suggestion and lets see if squid starts up or not.
> >
> > Eliezer
> >
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJUmLf7AAoJELJo5wb/XPRjd8QIANnGYjuGGzJ1WPvV1oF6BZzO
> 4fxqnJOLDH/M4b6gB+vgRYIkMY1qZTCptC1eE66YvkKGgYYjZEGvbIxyZ3Ql9IEg
> bvm2t3ouJxts4I576275XIj9Tvh7u77ObcD51vPFrOCzjt66UoNBnXlHE2Hm7jfz
> WYTK/oa7AgdYxfsZPZuVLb6m9ClfIzdB+ta3vVBUkfgsgCPkPZdk3O6NRmhnzA56
> sSlCOS43UfXwDsg6F/RwREs5/SruAYa2PTIwhLcHsPmKJiUToH9v/UnGRzGaKiwp
> LsuktdGfkDYl4bsd8FVAwTzev1Lzs97+IokVUGogE20LxWT08DwZEMd7M2SvmtE=
> =UfqC
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141229/19ac74e2/attachment.htm>

From huaraz at moeller.plus.com  Tue Dec 30 02:31:21 2014
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Tue, 30 Dec 2014 02:31:21 -0000
Subject: [squid-users] Proxy to proxy authentication
Message-ID: <m7t2pq$2rk$1@ger.gmane.org>

Spam detection software, running on the system "master.squid-cache.org",
has identified this incoming email as possible spam.  The original
message has been attached to this so you can view it or label
similar future email.  If you have any questions, see
@@CONTACT_ADDRESS@@ for details.

Content preview:  Hi, Can squid authenticate to an upstream proxy using digest
   ? If I saw it right cache_peer allows basic and negotiate only (or passthrough)
   Thank you Markus [...] 

Content analysis details:   (7.8 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
 0.2 STOX_REPLY_TYPE        No description available.
 0.9 SPF_FAIL               SPF: sender does not match SPF record (fail)
[SPF failed: Please see http://www.openspf.org/Why?s=mfrom;id=gcwsg-squid-users%40m.gmane.org;ip=81.174.172.105;r=master.squid-cache.org]
 0.0 T_HEADER_FROM_DIFFERENT_DOMAINS From and EnvelopeFrom 2nd level mail
                            domains are different
 0.0 UNPARSEABLE_RELAY      Informational: message has unparseable relay lines
 1.9 STOX_REPLY_TYPE_WITHOUT_QUOTES No description available.
 1.3 RDNS_NONE              Delivered to internal network by a host with no rDNS
 3.5 TO_NO_BRKTS_MSFT       To: misformatted and supposed Microsoft tool


-------------- next part --------------
An embedded message was scrubbed...
From: "Markus Moeller" <huaraz at moeller.plus.com>
Subject: Proxy to proxy authentication
Date: Tue, 30 Dec 2014 02:31:21 -0000
Size: 1666
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/36323cdb/attachment.eml>

From james at ejbdigital.com.au  Tue Dec 30 06:08:48 2014
From: james at ejbdigital.com.au (James Harper)
Date: Tue, 30 Dec 2014 06:08:48 +0000
Subject: [squid-users] cache behaviour when hostname is the same but ip
	address is different
Message-ID: <HKNPR04MB193E7AA22192EA4EA6198CBE85E0@HKNPR04MB193.apcprd04.prod.outlook.com>

Suppose hostname hostsite.com resolves to 2 different IP addresses. If a client in transparent mode retrieves a page (which is then cached by squid), and another client in transparent mode retrieves the same page but from the other IP address, is the page served from the cache?

If not, is there a way I can get this behaviour? I note that the site in question does provide an ETag.

Thanks

James


From squid3 at treenet.co.nz  Tue Dec 30 06:39:24 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 30 Dec 2014 19:39:24 +1300
Subject: [squid-users] cache behaviour when hostname is the same but ip
 address is different
In-Reply-To: <HKNPR04MB193E7AA22192EA4EA6198CBE85E0@HKNPR04MB193.apcprd04.prod.outlook.com>
References: <HKNPR04MB193E7AA22192EA4EA6198CBE85E0@HKNPR04MB193.apcprd04.prod.outlook.com>
Message-ID: <54A2489C.8000604@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 30/12/2014 7:08 p.m., James Harper wrote:
> Suppose hostname hostsite.com resolves to 2 different IP
> addresses. If a client in transparent mode retrieves a page (which
> is then cached by squid), and another client in transparent mode
> retrieves the same page but from the other IP address, is the page
> served from the cache?
> 

Provided the requested object (not "page") is cached by Squid the
second client should be served a HIT.

If the second client TCP connection is going to some other IP address
entirely, then no it wont be cached - it may or may not HIT depending
on whether the client encounters a bug we have not yet resolved.


> If not, is there a way I can get this behaviour? I note that the
> site in question does provide an ETag.

ETag will only help if it is presented the same by all origin servers
of the domain, and only in the cases of revalidation.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUokibAAoJELJo5wb/XPRjMVkH/RlcCSZaxFE3nA+QFHoBqoRa
6LE7hlAs6xs/wHcgJdSIjqc9MlJ6rn2RX+kTQJ1RnA36Rn/Aok6N+jAVmQFU88z9
LFp4FROnkBJVMuccnS102W4l8UpeT0kv+RvG/O9Y6HJZzoKHoliiSq50r1GNm+yU
sMUPxLEbIQerhViDl63mBAwQfkdkgGm0Uo7aX/piu36mD7eptF1Hf9GKSoD/0ndr
x+oFTRku7T0YMrLxGv7K8uOxmsl69EJfAC8geFOBYA7SS3LjSu6oRZwwMKBYNyuE
E/Ovw+cQ+/wNsclTPazHW72PI7eWqceG+3an02EHQ40EKTwue0mt/VP/aaM36Oc=
=y9rx
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Tue Dec 30 13:12:11 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 30 Dec 2014 19:12:11 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could not
	connect
Message-ID: <54A2A4AB.1000003@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Hi gents,

I found strange issue.

Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs correct.

Whenever all web https sites works perfectly - especially in Chrome,
most cloud clients works like charm (SpiderOak is!), Google Drive client
application (PC) could not work.
Note: Web Google Docs works. Web Google drive works.

Note: Google support info - even I if pass dozen Google URL's without
bump - cannot help. It doesn't work when server-first bumping is on and
works othervise.

So, the Serious Question is: Why? :)

Any idea?


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUoqSqAAoJENNXIZxhPexGMlsH/iEoVUCBOdF174Kj8I9mBbI3
RFdsouwnd6IMT0HTBt+MtjHK00NU/8yKVwgmUy4IyqVK1k6j+96ipGR6SeRsVzu1
RC7eym7ZLlRBWKUx+evQ5VhYXv7c1sX6UzD8irAUAp1019mZCVm5LfM4JJ/Vadw+
3mlOj4ASQGjDnA3BU+YKUhITFFdOY8vGrZKrJvY8JtkpOZ6i+GKW4V8UB+uGXicL
cYpx+LEbIV6UCL+lA4O3vOiQPBEVymu+TCeQ2gp6sxwNE+927TNrJEh8hp6IXha1
KAgareSZK3lp+/NXQwJTRsUw1YF768iPWP+RcB1Ao+2CGDjGk49b6WigvvHKlL0=
=Vbof
-----END PGP SIGNATURE-----




From squid3 at treenet.co.nz  Tue Dec 30 13:57:36 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Dec 2014 02:57:36 +1300
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
In-Reply-To: <54A2A4AB.1000003@gmail.com>
References: <54A2A4AB.1000003@gmail.com>
Message-ID: <54A2AF50.2070103@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 31/12/2014 2:12 a.m., Yuri Voinov wrote:
> 
> Hi gents,
> 
> I found strange issue.
> 
> Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs
> correct.
> 
> Whenever all web https sites works perfectly - especially in
> Chrome, most cloud clients works like charm (SpiderOak is!), Google
> Drive client application (PC) could not work. Note: Web Google Docs
> works. Web Google drive works.
> 
> Note: Google support info - even I if pass dozen Google URL's
> without bump - cannot help. It doesn't work when server-first
> bumping is on and works othervise.
> 
> So, the Serious Question is: Why? :)
> 
> Any idea?
> 

Probably non-HTTPS protocol being used.

As bumping gets more popular we are hearing about a number of services
abusing port 443 for non-HTTPS protocols on the false assumption that
the TLS layer goes all the way to the origin server without
inspection. That has never been a true assumption, CDN frontends have
always decrypted.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUoq9PAAoJELJo5wb/XPRjcSQIAJk349r6X95aJbaTTueFWfgP
RkAOwmDF7M6kiir8XgJ0D4+LXXL4mTxwkuGlIDe1au1jrhMAY8S1aIoU1Dc0BN5x
z4j9m1OeSeTrMAVvDCSFdf+pvAWOpLclY+f6b5HY773vus0kqT8PWhb4wVaIHP3m
9JtgpKOD9ElWdZosGVtdIl3uaExrmFGFbNLeVVo6VdeSE/D21YcH2HtEo3b+dopx
9T1SCMHItT83lr0LLFTlgTlKBrjREuKMNHN1L6FWkyJSe9OSu1efPvm23MG33G8a
ShbFMrWh9Zo50fVXZRidAyXlvjBcX7aHM/ZSb8+3ID5O7Ao484aPvbSSck9Hq/g=
=IeYG
-----END PGP SIGNATURE-----


From ludovit.koren at gmail.com  Tue Dec 30 13:59:43 2014
From: ludovit.koren at gmail.com (Ludovit Koren)
Date: Tue, 30 Dec 2014 14:59:43 +0100
Subject: [squid-users] Memory Leak Squid 3.4.9 on FreeBSD 10.0 x64
Message-ID: <86iogtp7ao.fsf@gmail.com>


Hi,

I have the similar problem on FreeBSD 10.1-STABLE #1 r275861 with 
squid-3.4.10. I also applied MEMPOOLS=1 when starting squid. I
experience the process slowing down and unacceptable performance.

Squid is configured to use kerberos and ntlm authentication and lap
group authentication. other settings:

cache_replacement_policy heap LFUDA
cache_mem 4096 MB
maximum_object_size 32 MB
cache_dir diskd /usr/local/squid/cache 32768 32 256

I have seen the following errors in cache.log:

FATAL: Received Segment Violation...dying.
FATAL: Received Bus Error...dying.

after this the squid restarts. The system has 10GB of memory and is
working as internal cache for ~600 users.

Please point me in the right direction. I have no problem running
squid33-3.3.13 on FreeBSD 9.3-STABLE #0 r270210.

Thank you very much.

Regards,

lk


From rafael.akchurin at diladele.com  Tue Dec 30 14:09:25 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 30 Dec 2014 14:09:25 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <54A2A4AB.1000003@gmail.com>
References: <54A2A4AB.1000003@gmail.com>
Message-ID: <1419948567529.54486@diladele.com>

SSL Pinning? (I know Dropbox does this)

my two cents only :)

Raf

________________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Yuri Voinov <yvoinov at gmail.com>
Sent: Tuesday, December 30, 2014 2:12 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid 3 SSL bump: Google drive application could not     connect

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi gents,

I found strange issue.

Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs correct.

Whenever all web https sites works perfectly - especially in Chrome,
most cloud clients works like charm (SpiderOak is!), Google Drive client
application (PC) could not work.
Note: Web Google Docs works. Web Google drive works.

Note: Google support info - even I if pass dozen Google URL's without
bump - cannot help. It doesn't work when server-first bumping is on and
works othervise.

So, the Serious Question is: Why? :)

Any idea?


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJUoqSqAAoJENNXIZxhPexGMlsH/iEoVUCBOdF174Kj8I9mBbI3
RFdsouwnd6IMT0HTBt+MtjHK00NU/8yKVwgmUy4IyqVK1k6j+96ipGR6SeRsVzu1
RC7eym7ZLlRBWKUx+evQ5VhYXv7c1sX6UzD8irAUAp1019mZCVm5LfM4JJ/Vadw+
3mlOj4ASQGjDnA3BU+YKUhITFFdOY8vGrZKrJvY8JtkpOZ6i+GKW4V8UB+uGXicL
cYpx+LEbIV6UCL+lA4O3vOiQPBEVymu+TCeQ2gp6sxwNE+927TNrJEh8hp6IXha1
KAgareSZK3lp+/NXQwJTRsUw1YF768iPWP+RcB1Ao+2CGDjGk49b6WigvvHKlL0=
=Vbof
-----END PGP SIGNATURE-----


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Tue Dec 30 14:19:26 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 30 Dec 2014 20:19:26 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <1419948567529.54486@diladele.com>
References: <54A2A4AB.1000003@gmail.com> <1419948567529.54486@diladele.com>
Message-ID: <54A2B46E.5090506@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
May be.

Does workaround exists?

30.12.2014 20:09, Rafael Akchurin ?????:
> SSL Pinning? (I know Dropbox does this)
>
> my two cents only :)
>
> Raf
>
> ________________________________________
> From: squid-users <squid-users-bounces at lists.squid-cache.org> on
behalf of Yuri Voinov <yvoinov at gmail.com>
> Sent: Tuesday, December 30, 2014 2:12 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Squid 3 SSL bump: Google drive application
could not     connect
>
> Hi gents,
>
> I found strange issue.
>
> Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs
correct.
>
> Whenever all web https sites works perfectly - especially in Chrome,
> most cloud clients works like charm (SpiderOak is!), Google Drive client
> application (PC) could not work.
> Note: Web Google Docs works. Web Google drive works.
>
> Note: Google support info - even I if pass dozen Google URL's without
> bump - cannot help. It doesn't work when server-first bumping is on and
> works othervise.
>
> So, the Serious Question is: Why? :)
>
> Any idea?
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUorRuAAoJENNXIZxhPexGRPEH/0Vlh/kZINRlo3IaDe/9UYSW
M0oaXQemB2Wg/wvNMdZ8SA3F4dUJUuHgS/y7FXcCgP/KgWnudsoJ7oPiHEVNPzt3
L8K7rNPy3d/c/+baXilh4/xErp/mAOKU/mLBqd0GQYQ2N7bAsWpsWqt7/dTGxWkU
kLVgFJr9JblxVdABAZ7JTooye3bLskdrAB/865vZOyQcveozW6d4TKZwaEGFrq/d
b/3Mki4T6YLMG248jVN+43W2us6Z598geDLn8aJN+zb/s6TBEzxy1d5tUROM4a2A
1rE7B92o+9leZi+JdQAGX4l7Um1WVmrnih52w+Pxz/PR/k7Hz+fCcQBlUtsqvMk=
=Lf+I
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/20b204aa/attachment.htm>

From rafael.akchurin at diladele.com  Tue Dec 30 15:22:32 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 30 Dec 2014 15:22:32 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <54A2B46E.5090506@gmail.com>
References: <54A2A4AB.1000003@gmail.com>
 <1419948567529.54486@diladele.com>,<54A2B46E.5090506@gmail.com>
Message-ID: <1419952954086.69012@diladele.com>

?Only exclusion from SSL Bump as far as I know.


raf

________________________________
From: Yuri Voinov <yvoinov at gmail.com>
Sent: Tuesday, December 30, 2014 3:19 PM
To: Rafael Akchurin; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

May be.

Does workaround exists?

30.12.2014 20:09, Rafael Akchurin ?????:
> SSL Pinning? (I know Dropbox does this)
>
> my two cents only :)
>
> Raf
>
> ________________________________________
> From: squid-users <squid-users-bounces at lists.squid-cache.org><mailto:squid-users-bounces at lists.squid-cache.org> on behalf of Yuri Voinov <yvoinov at gmail.com><mailto:yvoinov at gmail.com>
> Sent: Tuesday, December 30, 2014 2:12 PM
> To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
> Subject: [squid-users] Squid 3 SSL bump: Google drive application could not     connect
>
> Hi gents,
>
> I found strange issue.
>
> Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs correct.
>
> Whenever all web https sites works perfectly - especially in Chrome,
> most cloud clients works like charm (SpiderOak is!), Google Drive client
> application (PC) could not work.
> Note: Web Google Docs works. Web Google drive works.
>
> Note: Google support info - even I if pass dozen Google URL's without
> bump - cannot help. It doesn't work when server-first bumping is on and
> works othervise.
>
> So, the Serious Question is: Why? :)
>
> Any idea?
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJUorRuAAoJENNXIZxhPexGRPEH/0Vlh/kZINRlo3IaDe/9UYSW
M0oaXQemB2Wg/wvNMdZ8SA3F4dUJUuHgS/y7FXcCgP/KgWnudsoJ7oPiHEVNPzt3
L8K7rNPy3d/c/+baXilh4/xErp/mAOKU/mLBqd0GQYQ2N7bAsWpsWqt7/dTGxWkU
kLVgFJr9JblxVdABAZ7JTooye3bLskdrAB/865vZOyQcveozW6d4TKZwaEGFrq/d
b/3Mki4T6YLMG248jVN+43W2us6Z598geDLn8aJN+zb/s6TBEzxy1d5tUROM4a2A
1rE7B92o+9leZi+JdQAGX4l7Um1WVmrnih52w+Pxz/PR/k7Hz+fCcQBlUtsqvMk=
=Lf+I
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/5f343c89/attachment.htm>

From yvoinov at gmail.com  Tue Dec 30 16:00:35 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 30 Dec 2014 22:00:35 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <1419952954086.69012@diladele.com>
References: <54A2A4AB.1000003@gmail.com> <1419948567529.54486@diladele.com>,
 <54A2B46E.5090506@gmail.com> <1419952954086.69012@diladele.com>
Message-ID: <54A2CC23.9060302@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Captain Obvious. :)

Say me something I don't know.

The question 2 is - WHAT exactly I must exclude?

Google Support's list could not help.

30.12.2014 21:22, Rafael Akchurin ?????:
>
> ?Only exclusion from SSL Bump as far as I know.
>
>
> raf
>
> -------------------------
> *From:* Yuri Voinov <yvoinov at gmail.com>
> *Sent:* Tuesday, December 30, 2014 3:19 PM
> *To:* Rafael Akchurin; squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
application could not connect
> 
>
> May be.
>
> Does workaround exists?
>
> 30.12.2014 20:09, Rafael Akchurin ?????:
> > SSL Pinning? (I know Dropbox does this)
>
> > my two cents only :)
>
> > Raf
>
> > ________________________________________
> > From: squid-users <squid-users-bounces at lists.squid-cache.org> on
behalf of Yuri Voinov <yvoinov at gmail.com>
> > Sent: Tuesday, December 30, 2014 2:12 PM
> > To: squid-users at lists.squid-cache.org
> > Subject: [squid-users] Squid 3 SSL bump: Google drive application
could not     connect
>
> > Hi gents,
>
> > I found strange issue.
>
> > Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs
correct.
>
> > Whenever all web https sites works perfectly - especially in Chrome,
> > most cloud clients works like charm (SpiderOak is!), Google Drive client
> > application (PC) could not work.
> > Note: Web Google Docs works. Web Google drive works.
>
> > Note: Google support info - even I if pass dozen Google URL's without
> > bump - cannot help. It doesn't work when server-first bumping is on and
> > works othervise.
>
> > So, the Serious Question is: Why? :)
>
> > Any idea?
>
>
>
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUoswjAAoJENNXIZxhPexGA2IIAJTCqznLh7dPzZyMgqGB8xYp
zm2KW26B8MynhgIBXVHTKorY7YbJY2dg3JM4pRHjzN+BtItdEUCXa+oES86IMnCh
qAFvVDWmn0SXVrVK5yRVk5SrPG6Pm83P8++qo2uPP8XShbHKjuVIusMbnZUo0Hxr
n9CiwvHaL9xVuyhQkSD9TZ/yRdUP5YrGDXfQtZOkWTtlRnqVtn115UsQwD5/njNJ
axr15U+8OOt+oDfY5TQ8KYd3nQTYmQrgAWdADUPcHxAa1Fu+/SevU0xj6oKH16NJ
pb0KcIY6Ngj9SQEk//F1a36YkcTjPyh8F0UlKaigLa3wZXahmxBHyrZd+wpKxB8=
=6yaP
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/781c00cc/attachment.htm>

From rafael.akchurin at diladele.com  Tue Dec 30 17:12:02 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 30 Dec 2014 17:12:02 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
In-Reply-To: <54A2CC23.9060302@gmail.com>
Message-ID: <D0C89B65.9C68%rafael.akchurin@diladele.com>

Ask wireshark not me :)

From: Yuri Voinov <yvoinov at gmail.com<mailto:yvoinov at gmail.com>>
Date: Tuesday 30 December 2014 17:00
To: R <rafael.akchurin at diladele.com<mailto:rafael.akchurin at diladele.com>>, "squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>" <squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Captain Obvious. :)

Say me something I don't know.

The question 2 is - WHAT exactly I must exclude?

Google Support's list could not help.

30.12.2014 21:22, Rafael Akchurin ?????:
>
> ?Only exclusion from SSL Bump as far as I know.
>
>
> raf
>
> -------------------------
> *From:* Yuri Voinov <yvoinov at gmail.com><mailto:yvoinov at gmail.com>
> *Sent:* Tuesday, December 30, 2014 3:19 PM
> *To:* Rafael Akchurin; squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
> *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect
>
>
> May be.
>
> Does workaround exists?
>
> 30.12.2014 20:09, Rafael Akchurin ?????:
> > SSL Pinning? (I know Dropbox does this)
>
> > my two cents only :)
>
> > Raf
>
> > ________________________________________
> > From: squid-users <squid-users-bounces at lists.squid-cache.org><mailto:squid-users-bounces at lists.squid-cache.org> on behalf of Yuri Voinov <yvoinov at gmail.com><mailto:yvoinov at gmail.com>
> > Sent: Tuesday, December 30, 2014 2:12 PM
> > To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
> > Subject: [squid-users] Squid 3 SSL bump: Google drive application could not     connect
>
> > Hi gents,
>
> > I found strange issue.
>
> > Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs correct.
>
> > Whenever all web https sites works perfectly - especially in Chrome,
> > most cloud clients works like charm (SpiderOak is!), Google Drive client
> > application (PC) could not work.
> > Note: Web Google Docs works. Web Google drive works.
>
> > Note: Google support info - even I if pass dozen Google URL's without
> > bump - cannot help. It doesn't work when server-first bumping is on and
> > works othervise.
>
> > So, the Serious Question is: Why? :)
>
> > Any idea?
>
>
>
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJUoswjAAoJENNXIZxhPexGA2IIAJTCqznLh7dPzZyMgqGB8xYp
zm2KW26B8MynhgIBXVHTKorY7YbJY2dg3JM4pRHjzN+BtItdEUCXa+oES86IMnCh
qAFvVDWmn0SXVrVK5yRVk5SrPG6Pm83P8++qo2uPP8XShbHKjuVIusMbnZUo0Hxr
n9CiwvHaL9xVuyhQkSD9TZ/yRdUP5YrGDXfQtZOkWTtlRnqVtn115UsQwD5/njNJ
axr15U+8OOt+oDfY5TQ8KYd3nQTYmQrgAWdADUPcHxAa1Fu+/SevU0xj6oKH16NJ
pb0KcIY6Ngj9SQEk//F1a36YkcTjPyh8F0UlKaigLa3wZXahmxBHyrZd+wpKxB8=
=6yaP
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/10604f37/attachment.htm>

From rousskov at measurement-factory.com  Tue Dec 30 17:16:24 2014
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 30 Dec 2014 10:16:24 -0700
Subject: [squid-users] Skype bypass using ssl_bump peek
In-Reply-To: <CAGob8wB-U0jHSqKk4ePbXrM15pZWgFOfbrv0Z5pr+SxtH+5x-w@mail.gmail.com>
References: <CAGob8wB-U0jHSqKk4ePbXrM15pZWgFOfbrv0Z5pr+SxtH+5x-w@mail.gmail.com>
Message-ID: <54A2DDE8.8050704@measurement-factory.com>

On 12/12/2014 02:31 AM, Yu-Hsuan Liao wrote:

> I'm trying to using Squid 3.5's new feature peek-and-splice to bypass
> Skype connection
> I'm a little confused about ssl_bump steps,
> the wiki says that
> 
> peek Receive client (step SslBump1) or server (step SslBump2)
> certificate while preserving the possibility of splicing the
> connection.


> My question is: does ssl_bump make decision to bump or splice connection
> when Squid gets the ServerHello message?

Squid makes the final decision to bump (or splice) the connection when
the first ssl_bump bump (or ssl_bump splice) rule matches. Whether that
final rule matches during step1, step2, or step3 depends on how you
write your ssl_bump configuration (and on traffic).


The peek/stare actions are for receiving information from client and
server. Due to how SSL is designed, these actions usually have side
effects as detailed on the wiki page: peeking usually implies eventual
splicing and staring usually implies eventual bumping. Thus, you have to
be careful how you get the information you need.


> cos I found that Skype voice connection is first
> 
> 1. client send Clien tHello
> 2. server send Server Hello
> 
> then began the skype data payload transmit(non-SSL format, not the
> rest SSL handshake)
> 
> so that I still got the "Error negotiating SSL connection on FD"
> message in cache.log
> 
> Does peek-and-splice function cover above situation, or I just
> misunderstand the usage of ssl_bump peek?

If Skype client and server Hello information is standard (supported by
OpenSSL), then splicing connection should work at step1 or step2. For
example, the following configurations should work:

  ssl_bump splice isSkype
  ...

or

  ssl_bump peek all
  ssl_bump splice isSkype
  ...

where "isSkype" is your custom ACL that matches Skype traffic. It is
difficult to write such an ACL, as discussed below.


If those Hello exchanges are not supported by OpenSSL, then you must
splice at step1 without peeking:

  ssl_bump splice isSkype
  ...



> acl skype_list dstdomain "skype_list"
> ssl_bump peek skype_list
> ssl_bump stare all

This configuration will most likely not work because you are staring
(which usually implies eventual bumping) at step2. You cannot bump a
non-SSL connection. Moreover, I would be concerned about dstdomain
matching at step1 where Squid has access to CONNECT (forward proxy) or
TCP-level (intercepting proxy) information only and may be forced to do
a reverse DNS lookup.


The proper way to handle all this complexity is via automatic
non-HTTP/non-SSL traffic bypass rather than hand-written rules that try
to identify such traffic on a case-by-case basis. Unfortunately, the
corresponding Squid feature got stuck in Squid Project review for a few
months now. We have not given up on it though.


HTH,

Alex.



From ag4ve.us at gmail.com  Tue Dec 30 17:30:54 2014
From: ag4ve.us at gmail.com (shawn wilson)
Date: Tue, 30 Dec 2014 12:30:54 -0500
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
In-Reply-To: <54A2AF50.2070103@treenet.co.nz>
References: <54A2A4AB.1000003@gmail.com>
	<54A2AF50.2070103@treenet.co.nz>
Message-ID: <CAH_OBid-E2NeENMR_c-PYe8jPfnN5VaF1b6dOFKdpk8Hi0Fpgg@mail.gmail.com>

On Dec 30, 2014 8:57 AM, "Amos Jeffries" <squid3 at treenet.co.nz> wrote:
>

>
> As bumping gets more popular we are hearing about a number of services
> abusing port 443 for non-HTTPS protocols on the false assumption that
> the TLS layer goes all the way to the origin server without
> inspection. That has never been a true assumption, CDN frontends have
> always decrypted.
>

OT but you use 443 because people expect it to be encrypted web data and
don't block it. And DPI doesn't tell you anything more.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/a125fcbc/attachment.htm>

From rafael.akchurin at diladele.com  Tue Dec 30 17:39:32 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 30 Dec 2014 17:39:32 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <1419952954086.69012@diladele.com>
References: <54A2A4AB.1000003@gmail.com>
 <1419948567529.54486@diladele.com>,<54A2B46E.5090506@gmail.com>
 <1419952954086.69012@diladele.com>
Message-ID: <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>

Hello Yuri,

Luckily the same topic was just discussed on our forum ? please see if this can help https://groups.google.com/d/msg/quintolabs-content-security-for-squid-proxy/GKIV3FpYSBE/9IET-4hg_tEJ

It describes the iptables settings for successful SSL bump exclusions for Dropbox clients / Google Drive / iTunes (bypassing SSL Bump because of SSL Pinning).

Best regards,
Raf

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Rafael Akchurin
Sent: Tuesday, December 30, 2014 4:23 PM
To: Yuri Voinov; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect


?Only exclusion from SSL Bump as far as I know.



raf

________________________________
From: Yuri Voinov <yvoinov at gmail.com<mailto:yvoinov at gmail.com>>
Sent: Tuesday, December 30, 2014 3:19 PM
To: Rafael Akchurin; squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

May be.

Does workaround exists?

30.12.2014 20:09, Rafael Akchurin ?????:
> SSL Pinning? (I know Dropbox does this)

>

> my two cents only :)

>

> Raf

>

> ________________________________________

> From: squid-users <mailto:squid-users-bounces at lists.squid-cache.org>
<squid-users-bounces at lists.squid-cache.org><mailto:squid-users-bounces at lists.squid-cache.org> on behalf of Yuri Voinov <mailto:yvoinov at gmail.com>
<yvoinov at gmail.com><mailto:yvoinov at gmail.com>

> Sent: Tuesday, December 30, 2014 2:12 PM

> To: <mailto:squid-users at lists.squid-cache.org>
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

> Subject: [squid-users] Squid 3 SSL bump: Google drive application could not     connect

>

> Hi gents,

>

> I found strange issue.

>

> Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs correct.

>

> Whenever all web https sites works perfectly - especially in Chrome,

> most cloud clients works like charm (SpiderOak is!), Google Drive client

> application (PC) could not work.

> Note: Web Google Docs works. Web Google drive works.

>

> Note: Google support info - even I if pass dozen Google URL's without

> bump - cannot help. It doesn't work when server-first bumping is on and

> works othervise.

>

> So, the Serious Question is: Why? :)

>

> Any idea?

>

>

>

>

> _______________________________________________

> squid-users mailing list

> <mailto:squid-users at lists.squid-cache.org>
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

> <http://lists.squid-cache.org/listinfo/squid-users>
http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJUorRuAAoJENNXIZxhPexGRPEH/0Vlh/kZINRlo3IaDe/9UYSW
M0oaXQemB2Wg/wvNMdZ8SA3F4dUJUuHgS/y7FXcCgP/KgWnudsoJ7oPiHEVNPzt3
L8K7rNPy3d/c/+baXilh4/xErp/mAOKU/mLBqd0GQYQ2N7bAsWpsWqt7/dTGxWkU
kLVgFJr9JblxVdABAZ7JTooye3bLskdrAB/865vZOyQcveozW6d4TKZwaEGFrq/d
b/3Mki4T6YLMG248jVN+43W2us6Z598geDLn8aJN+zb/s6TBEzxy1d5tUROM4a2A
1rE7B92o+9leZi+JdQAGX4l7Um1WVmrnih52w+Pxz/PR/k7Hz+fCcQBlUtsqvMk=
=Lf+I
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/465e94a2/attachment.htm>

From huaraz at moeller.plus.com  Tue Dec 30 18:59:28 2014
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Tue, 30 Dec 2014 18:59:28 -0000
Subject: [squid-users] Proxy to proxy authentication
In-Reply-To: <m7t2pq$2rk$1@ger.gmane.org>
References: <m7t2pq$2rk$1@ger.gmane.org>
Message-ID: <m7usmj$iu9$1@ger.gmane.org>

Hi Amos,

>On 30/12/2014 3:31 p.m., Markus Moeller wrote:
>> Hi,
>>
>>   Can squid authenticate to an upstream proxy using digest ?  If I saw
>> it right cache_peer allows basic and negotiate only (or passthrough)
>>
>> Thank you
>> Markus
>>
>
>Not yet.
>
>Amos

Is it planned to add or no real interest in it ?

Thank you
Markus



From yvoinov at gmail.com  Tue Dec 30 19:47:44 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Dec 2014 01:47:44 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
References: <54A2A4AB.1000003@gmail.com> <1419948567529.54486@diladele.com>,
 <54A2B46E.5090506@gmail.com> <1419952954086.69012@diladele.com>
 <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
Message-ID: <54A30160.1000809@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Already found this lonely right post ;) I have Google-Fu too :) And it
longer than you :)

Anyway,

all of these issues solved.

I have snoop (not Windoze wireshark - all great things makes in console,
ya!) and take a look on single client traffic during bumping.

As I haven't iptables (no penguins, please!), but I have Cisco 2911, I
pass some Windows Update, Symantec Update (which is not work too)
bypassing Squid.

Cisco is greatest. All others are probably suxx :)

The complete solution looks like:

access-list 121 remark ACL for HTTPS WCCP
access-list 121 remark Squid proxies bypass
access-list 121 deny   ip host 192.168.200.3 any
access-list 121 remark WU bypass
access-list 121 deny tcp any 191.232.0.0 0.7.255.255
access-list 121 deny tcp any 65.52.0.0 0.3.255.255
access-list 121 remark Symantec bypass
access-list 121 deny tcp any host 195.215.221.99
access-list 121 deny tcp any host 195.215.221.104
access-list 121 deny tcp any host 213.248.114.172
access-list 121 deny tcp any host 213.248.114.173
access-list 121 deny tcp any host 213.248.114.174
access-list 121 deny tcp any host 213.248.114.175
access-list 121 deny tcp any host 77.67.22.168
access-list 121 deny tcp any host 77.67.22.171
access-list 121 deny tcp any host 77.67.22.173
access-list 121 deny tcp any host 213.248.114.171
access-list 121 remark LAN clients proxy port 443
access-list 121 permit tcp 192.168.0.0 0.0.255.255 any eq 443
access-list 121 remark all others bypass WCCP
access-list 121 deny   ip any any

So, all others issue solves similar.

Want to do something good - do it yourself!

That's the way. :)

30.12.2014 23:39, Rafael Akchurin ?????:
>
> Hello Yuri,
>
> 
>
> Luckily the same topic was just discussed on our forum ? please see if
this can help
https://groups.google.com/d/msg/quintolabs-content-security-for-squid-proxy/GKIV3FpYSBE/9IET-4hg_tEJ
>
> 
>
> It describes the iptables settings for successful SSL bump exclusions
for Dropbox clients / Google Drive / iTunes (bypassing SSL Bump because
of SSL Pinning).
>
> 
>
> Best regards,
>
> Raf
>
> 
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
*On Behalf Of *Rafael Akchurin
> *Sent:* Tuesday, December 30, 2014 4:23 PM
> *To:* Yuri Voinov; squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
application could not connect
>
> 
>
> ?Only exclusion from SSL Bump as far as I know.
>
> 
>
> raf
>
> -------------------------
>
> *From:*Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com>>
> *Sent:* Tuesday, December 30, 2014 3:19 PM
> *To:* Rafael Akchurin; squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
application could not connect
>
> 
>
>
> May be.
>
> Does workaround exists?
>
> 30.12.2014 20:09, Rafael Akchurin ?????:
> > SSL Pinning? (I know Dropbox does this)
>
>
>
> > my two cents only :)
>
>
>
> > Raf
>
>
>
> > ________________________________________
>
> > From: squid-users <mailto:squid-users-bounces at lists.squid-cache.org>
>
> <squid-users-bounces at lists.squid-cache.org>
<mailto:squid-users-bounces at lists.squid-cache.org>on behalf of Yuri
Voinov <mailto:yvoinov at gmail.com>
>
> <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>
> > Sent: Tuesday, December 30, 2014 2:12 PM
>
> > To: <mailto:squid-users at lists.squid-cache.org>
>
> squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
> > Subject: [squid-users] Squid 3 SSL bump: Google drive application
could not     connect
>
>
>
> > Hi gents,
>
>
>
> > I found strange issue.
>
>
>
> > Squid 3.4.10. Intercept. HTTPS bumping. All works fine. All configs
correct.
>
>
>
> > Whenever all web https sites works perfectly - especially in Chrome,
>
> > most cloud clients works like charm (SpiderOak is!), Google Drive client
>
> > application (PC) could not work.
>
> > Note: Web Google Docs works. Web Google drive works.
>
>
>
> > Note: Google support info - even I if pass dozen Google URL's without
>
> > bump - cannot help. It doesn't work when server-first bumping is on and
>
> > works othervise.
>
>
>
> > So, the Serious Question is: Why? :)
>
>
>
> > Any idea?
>
>
>
>
>
>
>
>
>
> > _______________________________________________
>
> > squid-users mailing list
>
> > <mailto:squid-users at lists.squid-cache.org>
>
> squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
> > <http://lists.squid-cache.org/listinfo/squid-users>
>
> http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUowFgAAoJENNXIZxhPexGHxkIAM2mb+OjhevZWpgdwiKHP2E0
D+8UM6/c7OZcJ2uSjIWN7DG0h+b86/ATul+9S+mZHl1DLBYpGUKW9J5I3iIQb+sr
5xR2ReFkuFeSpZASXex2yq5lfmACPdiUzI9iVhe7DPJqKJNiIzvHLq4ZRnjJN4Ih
0u0NGuPKfkkWFJ/SmXAceEdS7sT/lT0cVm1JgpurVzipelBUNbLQUd0yKrpbIz2x
ia7gwu3ZFi2aY2DvrfP7ntkoZpLl+SyDI/PkFIEaAr2+KaMcTbUXVQcVTZ7S6eLu
pgCNil0x8AFApWSIg+P68DcFcIS/nUIvNqXjuvr0ikqGwLEAqvueM6LPKifsdSg=
=J+Cs
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141231/091f2fff/attachment.htm>

From rafael.akchurin at diladele.com  Tue Dec 30 20:10:12 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 30 Dec 2014 20:10:12 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <54A30160.1000809@gmail.com>
References: <54A2A4AB.1000003@gmail.com>
 <1419948567529.54486@diladele.com>,<54A2B46E.5090506@gmail.com>
 <1419952954086.69012@diladele.com>
 <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
 <54A30160.1000809@gmail.com>
Message-ID: <AM3PR04MB45093D2771C683722C3B16B8F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>

Glad that it worked.
May be useful to dump here your squid.conf to better understand how to configure squid to transparently work with wccp traffic coming from your Cisco router?
Raf

From: Yuri Voinov [mailto:yvoinov at gmail.com]
Sent: Tuesday, December 30, 2014 8:48 PM
To: Rafael Akchurin; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Already found this lonely right post ;) I have Google-Fu too :) And it longer than you :)

Anyway,

all of these issues solved.

I have snoop (not Windoze wireshark - all great things makes in console, ya!) and take a look on single client traffic during bumping.

As I haven't iptables (no penguins, please!), but I have Cisco 2911, I pass some Windows Update, Symantec Update (which is not work too) bypassing Squid.

Cisco is greatest. All others are probably suxx :)

The complete solution looks like:

access-list 121 remark ACL for HTTPS WCCP
access-list 121 remark Squid proxies bypass
access-list 121 deny   ip host 192.168.200.3 any
access-list 121 remark WU bypass
access-list 121 deny tcp any 191.232.0.0 0.7.255.255
access-list 121 deny tcp any 65.52.0.0 0.3.255.255
access-list 121 remark Symantec bypass
access-list 121 deny tcp any host 195.215.221.99
access-list 121 deny tcp any host 195.215.221.104
access-list 121 deny tcp any host 213.248.114.172
access-list 121 deny tcp any host 213.248.114.173
access-list 121 deny tcp any host 213.248.114.174
access-list 121 deny tcp any host 213.248.114.175
access-list 121 deny tcp any host 77.67.22.168
access-list 121 deny tcp any host 77.67.22.171
access-list 121 deny tcp any host 77.67.22.173
access-list 121 deny tcp any host 213.248.114.171
access-list 121 remark LAN clients proxy port 443
access-list 121 permit tcp 192.168.0.0 0.0.255.255 any eq 443
access-list 121 remark all others bypass WCCP
access-list 121 deny   ip any any

So, all others issue solves similar.

Want to do something good - do it yourself!

That's the way. :)

30.12.2014 23:39, Rafael Akchurin ?????:
>

      > Hello Yuri,

      >

      >

      >

      > Luckily the same topic was just discussed on our forum ?
      please see if this can help
https://groups.google.com/d/msg/quintolabs-content-security-for-squid-proxy/GKIV3FpYSBE/9IET-4hg_tEJ

      >

      >

      >

      > It describes the iptables settings for successful SSL bump
      exclusions for Dropbox clients / Google Drive / iTunes (bypassing
      SSL Bump because of SSL Pinning).

      >

      >

      >

      > Best regards,

      >

      > Raf

      >

      >

      >

      > *From:*squid-users
      [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of
     *Rafael Akchurin

      > *Sent:* Tuesday, December 30, 2014 4:23 PM

      > *To:* Yuri Voinov; squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
      application could not connect

      >

      >

      >

      > ?Only exclusion from SSL Bump as far as I know.

      >

      >

      >

      > raf

      >

      > -------------------------

      >

      > *From:*Yuri Voinov <yvoinov at gmail.com<mailto:yvoinov at gmail.com>
      <mailto:yvoinov at gmail.com><mailto:yvoinov at gmail.com>>

      > *Sent:* Tuesday, December 30, 2014 3:19 PM

      > *To:* Rafael Akchurin; squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
      <mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org>

      > *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
      application could not connect

      >

      >

      >

      >

      > May be.

      >

      > Does workaround exists?

      >

      > 30.12.2014 20:09, Rafael Akchurin ?????:

      > > SSL Pinning? (I know Dropbox does this)

      >

      >

      >

      > > my two cents only :)

      >

      >

      >

      > > Raf

      >

      >

      >

      > > ________________________________________

      >

      > > From: squid-users
      <mailto:squid-users-bounces at lists.squid-cache.org><mailto:squid-users-bounces at lists.squid-cache.org>

      >

      > <squid-users-bounces at lists.squid-cache.org><mailto:squid-users-bounces at lists.squid-cache.org>
      <mailto:squid-users-bounces at lists.squid-cache.org><mailto:squid-users-bounces at lists.squid-cache.org>on behalf
      of Yuri Voinov <mailto:yvoinov at gmail.com><mailto:yvoinov at gmail.com>

      >

      > <yvoinov at gmail.com><mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com><mailto:yvoinov at gmail.com>

      >

      > > Sent: Tuesday, December 30, 2014 2:12 PM

      >

      > > To: <mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org>

      >

      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
      <mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org>

      >

      > > Subject: [squid-users] Squid 3 SSL bump: Google drive
      application could not     connect

      >

      >

      >

      > > Hi gents,

      >

      >

      >

      > > I found strange issue.

      >

      >

      >

      > > Squid 3.4.10. Intercept. HTTPS bumping. All works fine.
      All configs correct.

      >

      >

      >

      > > Whenever all web https sites works perfectly -
      especially in Chrome,

      >

      > > most cloud clients works like charm (SpiderOak is!),
      Google Drive client

      >

      > > application (PC) could not work.

      >

      > > Note: Web Google Docs works. Web Google drive works.

      >

      >

      >

      > > Note: Google support info - even I if pass dozen Google
      URL's without

      >

      > > bump - cannot help. It doesn't work when server-first
      bumping is on and

      >

      > > works othervise.

      >

      >

      >

      > > So, the Serious Question is: Why? :)

      >

      >

      >

      > > Any idea?

      >

      >

      >

      >

      >

      >

      >

      >

      >

      > > _______________________________________________

      >

      > > squid-users mailing list

      >

      > > <mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org>

      >

      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
      <mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org>

      >

      > >
      <http://lists.squid-cache.org/listinfo/squid-users><http://lists.squid-cache.org/listinfo/squid-users>

      >

      > http://lists.squid-cache.org/listinfo/squid-users

      >

      >

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJUowFgAAoJENNXIZxhPexGHxkIAM2mb+OjhevZWpgdwiKHP2E0
D+8UM6/c7OZcJ2uSjIWN7DG0h+b86/ATul+9S+mZHl1DLBYpGUKW9J5I3iIQb+sr
5xR2ReFkuFeSpZASXex2yq5lfmACPdiUzI9iVhe7DPJqKJNiIzvHLq4ZRnjJN4Ih
0u0NGuPKfkkWFJ/SmXAceEdS7sT/lT0cVm1JgpurVzipelBUNbLQUd0yKrpbIz2x
ia7gwu3ZFi2aY2DvrfP7ntkoZpLl+SyDI/PkFIEaAr2+KaMcTbUXVQcVTZ7S6eLu
pgCNil0x8AFApWSIg+P68DcFcIS/nUIvNqXjuvr0ikqGwLEAqvueM6LPKifsdSg=
=J+Cs
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/753d81a4/attachment.htm>

From yvoinov at gmail.com  Tue Dec 30 20:15:47 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Dec 2014 02:15:47 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
References: <54A2A4AB.1000003@gmail.com> <1419948567529.54486@diladele.com>,
 <54A2B46E.5090506@gmail.com> <1419952954086.69012@diladele.com>
 <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
Message-ID: <54A307F3.1020902@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
To finalize a solution,

see the our favorite:

http://www.squid-cache.org/mail-archive/squid-users/201406/0369.html

Why use iptables, ipfilter,Cisco, etc?!

Only Squid, only hardcore!

Revert cisco config back:

R2911(config)#no access-list 121
R2911(config)#access-list 121 remark ACL for HTTPS WCCP
R2911(config)#access-list 121 remark Squid proxies bypass
R2911(config)#access-list 121 deny   ip host 192.168.200.3 any
R2911(config)#access-list 121 deny   ip host 192.168.100.251 any
R2911(config)#access-list 121 remark Videoserver
R2911(config)#access-list 121 deny   ip host 192.168.200.5 any
R2911(config)#access-list 121 remark LAN clients proxy port 443
R2911(config)#access-list 121 permit tcp 192.168.0.0 0.0.255.255 any eq 443
R2911(config)#access-list 121 remark all others bypass WCCP
R2911(config)#access-list 121 deny   ip any any
R2911(config)#^Z
R2911#wr
Building configuration...
[OK]

Write acl file with IP/net with SSL Pinning:

root @ ktulhu /usr/local/squid/etc # cat dst.nobump
# BCC bypass
91.198.63.0/24
# Salyk bypass
212.154.165.148/32
# WU bypass
191.232.0.0/13
65.52.0.0/14
# Symantec bypass
195.215.221.99/32
195.215.221.104/32
213.248.114.172/32
213.248.114.173/32
213.248.114.174/32
213.248.114.175/32
77.67.22.168/32
77.67.22.171/32
77.67.22.173/32
213.248.114.171/32

Add needful nets/apps to acl by your taste.

Add to squid config:

# SSL bump acl
acl net_bump src "/usr/local/squid/etc/net.bump"
# HTTP-use 443 port apps
acl url_nobump dstdom_regex \.icq\.*
# SSL Pinning servers. Only ip-based dst acl!
acl dst_nobump dst "/usr/local/squid/etc/dst.nobump"

# SSL bump rules
sslproxy_cert_error allow all
ssl_bump none localhost
ssl_bump none url_nobump
ssl_bump none dst_nobump
ssl_bump server-first net_bump

Yahooo! The same result with Squid only!

30.12.2014 23:39, Rafael Akchurin ?????:
> SSL Pinning

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUowfzAAoJENNXIZxhPexGQjgH/2a6Ec4VMKgwKdgR+HPJYRj3
eOmmO8E3LAwkQpDnUNfBl057tKSdPTq5Y1Fo0SJrs0yczvc7w2nt7G01adCajxgT
Zj91d77aNxXoE730I6rnL8vAg4gvWVYdJufJstTQuToJW31SYMlEkzZfY38suRTs
GQRAaQ+hYY4trqE7f5BlQHdChMwIb6pxQoE2PJ+8SzkuBr4E68fJlqECz8zXxs8Z
Mb+R3OCA18YKpr+6nU3dM58B3FDvWTj/NuIib2PgvIGR2Xsrrrr2GPms2x6QKg5v
ivlmYD5cYWz3F+8htv7mFovSxp32cKb6+Vfxk45yGEA2+z9VziGE1G7KF4WgKGM=
=1ux+
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141231/a0f35df5/attachment.htm>

From rafael.akchurin at diladele.com  Tue Dec 30 20:21:42 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 30 Dec 2014 20:21:42 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <54A307F3.1020902@gmail.com>
References: <54A2A4AB.1000003@gmail.com>
 <1419948567529.54486@diladele.com>,<54A2B46E.5090506@gmail.com>
 <1419952954086.69012@diladele.com>
 <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
 <54A307F3.1020902@gmail.com>
Message-ID: <AM3PR04MB4506D47F5B279AB6D0A04958F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>

Just for me to completely clarify:

- how exactly your Squid gets the traffic from your clients? (explicit proxy or cisco WCCP?)

raf
From: Yuri Voinov [mailto:yvoinov at gmail.com]
Sent: Tuesday, December 30, 2014 9:16 PM
To: Rafael Akchurin; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

To finalize a solution,

see the our favorite:

http://www.squid-cache.org/mail-archive/squid-users/201406/0369.html

Why use iptables, ipfilter,Cisco, etc?!

Only Squid, only hardcore!

Revert cisco config back:

R2911(config)#no access-list 121
R2911(config)#access-list 121 remark ACL for HTTPS WCCP
R2911(config)#access-list 121 remark Squid proxies bypass
R2911(config)#access-list 121 deny   ip host 192.168.200.3 any
R2911(config)#access-list 121 deny   ip host 192.168.100.251 any
R2911(config)#access-list 121 remark Videoserver
R2911(config)#access-list 121 deny   ip host 192.168.200.5 any
R2911(config)#access-list 121 remark LAN clients proxy port 443
R2911(config)#access-list 121 permit tcp 192.168.0.0 0.0.255.255 any eq 443
R2911(config)#access-list 121 remark all others bypass WCCP
R2911(config)#access-list 121 deny   ip any any
R2911(config)#^Z
R2911#wr
Building configuration...
[OK]

Write acl file with IP/net with SSL Pinning:

root @ ktulhu /usr/local/squid/etc # cat dst.nobump
# BCC bypass
91.198.63.0/24
# Salyk bypass
212.154.165.148/32
# WU bypass
191.232.0.0/13
65.52.0.0/14
# Symantec bypass
195.215.221.99/32
195.215.221.104/32
213.248.114.172/32
213.248.114.173/32
213.248.114.174/32
213.248.114.175/32
77.67.22.168/32
77.67.22.171/32
77.67.22.173/32
213.248.114.171/32

Add needful nets/apps to acl by your taste.

Add to squid config:

# SSL bump acl
acl net_bump src "/usr/local/squid/etc/net.bump"
# HTTP-use 443 port apps
acl url_nobump dstdom_regex \.icq\.*
# SSL Pinning servers. Only ip-based dst acl!
acl dst_nobump dst "/usr/local/squid/etc/dst.nobump"

# SSL bump rules
sslproxy_cert_error allow all
ssl_bump none localhost
ssl_bump none url_nobump
ssl_bump none dst_nobump
ssl_bump server-first net_bump

Yahooo! The same result with Squid only!

30.12.2014 23:39, Rafael Akchurin ?????:
> SSL Pinning

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJUowfzAAoJENNXIZxhPexGQjgH/2a6Ec4VMKgwKdgR+HPJYRj3
eOmmO8E3LAwkQpDnUNfBl057tKSdPTq5Y1Fo0SJrs0yczvc7w2nt7G01adCajxgT
Zj91d77aNxXoE730I6rnL8vAg4gvWVYdJufJstTQuToJW31SYMlEkzZfY38suRTs
GQRAaQ+hYY4trqE7f5BlQHdChMwIb6pxQoE2PJ+8SzkuBr4E68fJlqECz8zXxs8Z
Mb+R3OCA18YKpr+6nU3dM58B3FDvWTj/NuIib2PgvIGR2Xsrrrr2GPms2x6QKg5v
ivlmYD5cYWz3F+8htv7mFovSxp32cKb6+Vfxk45yGEA2+z9VziGE1G7KF4WgKGM=
=1ux+
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/4986f0f8/attachment.htm>

From yvoinov at gmail.com  Tue Dec 30 20:21:59 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Dec 2014 02:21:59 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <AM3PR04MB45093D2771C683722C3B16B8F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
References: <54A2A4AB.1000003@gmail.com> <1419948567529.54486@diladele.com>,
 <54A2B46E.5090506@gmail.com> <1419952954086.69012@diladele.com>
 <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
 <54A30160.1000809@gmail.com>
 <AM3PR04MB45093D2771C683722C3B16B8F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
Message-ID: <54A30967.80504@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Sure.

Squid 3 WCCP key config part:

# WCCPv2 parameters
wccp2_router 192.168.200.2
wccp2_forwarding_method l2
wccp2_return_method l2
wccp2_service standard 0
wccp2_rebuild_wait off
wccp2_service standard 0
wccp2_service dynamic 70
wccp2_service_info 70 protocol=tcp
flags=dst_ip_hash,src_ip_alt_hash,src_port_alt_hash priority=240 ports=443

Cisco config key parts:

!
ip wccp web-cache redirect-list 120
ip wccp 70 redirect-list 121
!
!
! This interface look to Squid proxy (internal networks on another
interface)
interface GigabitEthernet0/1
 ip address 192.168.200.2 255.255.255.0
 ip wccp web-cache redirect out
 ip wccp 70 redirect out
 ip nbar protocol-discovery
 ip virtual-reassembly in
 duplex auto
 speed auto
!
access-list 120 remark ACL for HTTP WCCP
access-list 120 remark Squid proxies bypass WCCP
access-list 120 deny   ip host 192.168.200.3 any
access-list 120 remark LAN clients proxy port 80
access-list 120 permit tcp 192.168.0.0 0.0.255.255 any eq www
access-list 120 remark all others bypass WCCP
access-list 120 deny   ip any any
!
access-list 121 remark ACL for HTTPS WCCP
access-list 121 remark Squid proxies bypass
access-list 121 deny   ip host 192.168.200.3 any
access-list 121 remark LAN clients proxy port 443
access-list 121 permit tcp 192.168.0.0 0.0.255.255 any eq 443
access-list 121 remark all others bypass WCCP
access-list 121 deny   ip any any
!

That's all. :)

31.12.2014 2:10, Rafael Akchurin ?????:
>
> Glad that it worked.
>
> May be useful to dump here your squid.conf to better understand how to
configure squid to transparently work with wccp traffic coming from your
Cisco router?
>
> Raf
>
> 
>
> *From:*Yuri Voinov [mailto:yvoinov at gmail.com]
> *Sent:* Tuesday, December 30, 2014 8:48 PM
> *To:* Rafael Akchurin; squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
application could not connect
>
> 
>
>
> Already found this lonely right post ;) I have Google-Fu too :) And it
longer than you :)
>
> Anyway,
>
> all of these issues solved.
>
> I have snoop (not Windoze wireshark - all great things makes in
console, ya!) and take a look on single client traffic during bumping.
>
> As I haven't iptables (no penguins, please!), but I have Cisco 2911, I
pass some Windows Update, Symantec Update (which is not work too)
bypassing Squid.
>
> Cisco is greatest. All others are probably suxx :)
>
> The complete solution looks like:
>
> access-list 121 remark ACL for HTTPS WCCP
> access-list 121 remark Squid proxies bypass
> access-list 121 deny   ip host 192.168.200.3 any
> access-list 121 remark WU bypass
> access-list 121 deny tcp any 191.232.0.0 0.7.255.255
> access-list 121 deny tcp any 65.52.0.0 0.3.255.255
> access-list 121 remark Symantec bypass
> access-list 121 deny tcp any host 195.215.221.99
> access-list 121 deny tcp any host 195.215.221.104
> access-list 121 deny tcp any host 213.248.114.172
> access-list 121 deny tcp any host 213.248.114.173
> access-list 121 deny tcp any host 213.248.114.174
> access-list 121 deny tcp any host 213.248.114.175
> access-list 121 deny tcp any host 77.67.22.168
> access-list 121 deny tcp any host 77.67.22.171
> access-list 121 deny tcp any host 77.67.22.173
> access-list 121 deny tcp any host 213.248.114.171
> access-list 121 remark LAN clients proxy port 443
> access-list 121 permit tcp 192.168.0.0 0.0.255.255 any eq 443
> access-list 121 remark all others bypass WCCP
> access-list 121 deny   ip any any
>
> So, all others issue solves similar.
>
> Want to do something good - do it yourself!
>
> That's the way. :)
>
> 30.12.2014 23:39, Rafael Akchurin ?????:
>
>
>       > Hello Yuri,
>
>
>
>
>
>
>
>       > Luckily the same topic was just discussed on our forum ?
>
>       please see if this can help
>
>
https://groups.google.com/d/msg/quintolabs-content-security-for-squid-proxy/GKIV3FpYSBE/9IET-4hg_tEJ
>
>
>
>
>
>
>
>       > It describes the iptables settings for successful SSL bump
>
>       exclusions for Dropbox clients / Google Drive / iTunes (bypassing
>
>       SSL Bump because of SSL Pinning).
>
>
>
>
>
>
>
>       > Best regards,
>
>
>
>       > Raf
>
>
>
>
>
>
>
>       > *From:*squid-users
>
>       [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of
>
>      *Rafael Akchurin
>
>       > *Sent:* Tuesday, December 30, 2014 4:23 PM
>
>       > *To:* Yuri Voinov; squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
>
>       application could not connect
>
>
>
>
>
>
>
>       > ?Only exclusion from SSL Bump as far as I know.
>
>
>
>
>
>
>
>       > raf
>
>
>
>       > -------------------------
>
>
>
>       > *From:*Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com>
>
>       <mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>>
>
>       > *Sent:* Tuesday, December 30, 2014 3:19 PM
>
>       > *To:* Rafael Akchurin; squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>       > *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
>
>       application could not connect
>
>
>
>
>
>
>
>
>
>       > May be.
>
>
>
>       > Does workaround exists?
>
>
>
>       > 30.12.2014 20:09, Rafael Akchurin ?????:
>
>       > > SSL Pinning? (I know Dropbox does this)
>
>
>
>
>
>
>
>       > > my two cents only :)
>
>
>
>
>
>
>
>       > > Raf
>
>
>
>
>
>
>
>       > > ________________________________________
>
>
>
>       > > From: squid-users
>
>       <mailto:squid-users-bounces at lists.squid-cache.org>
<mailto:squid-users-bounces at lists.squid-cache.org>
>
>
>
>       > <squid-users-bounces at lists.squid-cache.org>
<mailto:squid-users-bounces at lists.squid-cache.org>
>
>       <mailto:squid-users-bounces at lists.squid-cache.org>
<mailto:squid-users-bounces at lists.squid-cache.org>on behalf
>
>       of Yuri Voinov <mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>
>
>
>       > <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
<mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>
>
>
>       > > Sent: Tuesday, December 30, 2014 2:12 PM
>
>
>
>       > > To: <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       > > Subject: [squid-users] Squid 3 SSL bump: Google drive
>
>       application could not     connect
>
>
>
>
>
>
>
>       > > Hi gents,
>
>
>
>
>
>
>
>       > > I found strange issue.
>
>
>
>
>
>
>
>       > > Squid 3.4.10. Intercept. HTTPS bumping. All works fine.
>
>       All configs correct.
>
>
>
>
>
>
>
>       > > Whenever all web https sites works perfectly -
>
>       especially in Chrome,
>
>
>
>       > > most cloud clients works like charm (SpiderOak is!),
>
>       Google Drive client
>
>
>
>       > > application (PC) could not work.
>
>
>
>       > > Note: Web Google Docs works. Web Google drive works.
>
>
>
>
>
>
>
>       > > Note: Google support info - even I if pass dozen Google
>
>       URL's without
>
>
>
>       > > bump - cannot help. It doesn't work when server-first
>
>       bumping is on and
>
>
>
>       > > works othervise.
>
>
>
>
>
>
>
>       > > So, the Serious Question is: Why? :)
>
>
>
>
>
>
>
>       > > Any idea?
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       > > _______________________________________________
>
>
>
>       > > squid-users mailing list
>
>
>
>       > > <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       > >
>
>       <http://lists.squid-cache.org/listinfo/squid-users>
<http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUowlmAAoJENNXIZxhPexG1ygH/RWXJIeFp4G/B39Ba/4yQ5XS
R/JmIkMaafDabBe5sPYVdwH7u25cIS7nKvVssme5TVmzcFAZuancr3ZV/ue9OtsH
jYwWSz/uHz76T6hKHmYB9uq3ESHQrasZ9WC2vfhYd0XR0mHxsn+zjPz34cKqlN5P
daeTbZGcrw/WyzJxMPRqjBX4nHNnvwb0mpo1htm3KS//yVdZMrNYMwqRR9DcBilE
rX5bkEjegnqmc7DM73XHu1Lz5SSeKCXttkcz2UAkP6aqRzAazjNBlObHASO9wYgq
RCsH/GvbNjJWyw7ZrvqxOnwOiMyJhV6L9h3uVM02NxsLzhnNutVl4dymzZHZf3Y=
=Ls1G
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141231/0219ac60/attachment.htm>

From yvoinov at gmail.com  Tue Dec 30 20:23:03 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Dec 2014 02:23:03 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <AM3PR04MB4506D47F5B279AB6D0A04958F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
References: <54A2A4AB.1000003@gmail.com> <1419948567529.54486@diladele.com>,
 <54A2B46E.5090506@gmail.com> <1419952954086.69012@diladele.com>
 <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
 <54A307F3.1020902@gmail.com>
 <AM3PR04MB4506D47F5B279AB6D0A04958F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
Message-ID: <54A309A7.4000505@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
WCCP only, of course. To reduce Cisco CPU usage.

Also, iOS version 15.4 with SECURITYK9 techno pack activated.

31.12.2014 2:21, Rafael Akchurin ?????:
>
> Just for me to completely clarify:
>
> 
>
> - how exactly your Squid gets the traffic from your clients? (explicit
proxy or cisco WCCP?)
>
> 
>
> raf
>
> *From:*Yuri Voinov [mailto:yvoinov at gmail.com]
> *Sent:* Tuesday, December 30, 2014 9:16 PM
> *To:* Rafael Akchurin; squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
application could not connect
>
> 
>
>
> To finalize a solution,
>
> see the our favorite:
>
> http://www.squid-cache.org/mail-archive/squid-users/201406/0369.html
>
> Why use iptables, ipfilter,Cisco, etc?!
>
> Only Squid, only hardcore!
>
> Revert cisco config back:
>
> R2911(config)#no access-list 121
> R2911(config)#access-list 121 remark ACL for HTTPS WCCP
> R2911(config)#access-list 121 remark Squid proxies bypass
> R2911(config)#access-list 121 deny   ip host 192.168.200.3 any
> R2911(config)#access-list 121 deny   ip host 192.168.100.251 any
> R2911(config)#access-list 121 remark Videoserver
> R2911(config)#access-list 121 deny   ip host 192.168.200.5 any
> R2911(config)#access-list 121 remark LAN clients proxy port 443
> R2911(config)#access-list 121 permit tcp 192.168.0.0 0.0.255.255 any
eq 443
> R2911(config)#access-list 121 remark all others bypass WCCP
> R2911(config)#access-list 121 deny   ip any any
> R2911(config)#^Z
> R2911#wr
> Building configuration...
> [OK]
>
> Write acl file with IP/net with SSL Pinning:
>
> root @ ktulhu /usr/local/squid/etc # cat dst.nobump
> # BCC bypass
> 91.198.63.0/24
> # Salyk bypass
> 212.154.165.148/32
> # WU bypass
> 191.232.0.0/13
> 65.52.0.0/14
> # Symantec bypass
> 195.215.221.99/32
> 195.215.221.104/32
> 213.248.114.172/32
> 213.248.114.173/32
> 213.248.114.174/32
> 213.248.114.175/32
> 77.67.22.168/32
> 77.67.22.171/32
> 77.67.22.173/32
> 213.248.114.171/32
>
> Add needful nets/apps to acl by your taste.
>
> Add to squid config:
>
> # SSL bump acl
> acl net_bump src "/usr/local/squid/etc/net.bump"
> # HTTP-use 443 port apps
> acl url_nobump dstdom_regex \.icq\.*
> # SSL Pinning servers. Only ip-based dst acl!
> acl dst_nobump dst "/usr/local/squid/etc/dst.nobump"
>
> # SSL bump rules
> sslproxy_cert_error allow all
> ssl_bump none localhost
> ssl_bump none url_nobump
> ssl_bump none dst_nobump
> ssl_bump server-first net_bump
>
> Yahooo! The same result with Squid only!
>
> 30.12.2014 23:39, Rafael Akchurin ?????:
> > SSL Pinning
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUowmnAAoJENNXIZxhPexGEtwH/10nuDG9+Z7AG2W+nh64X7JV
5JmvvaC778yUYnMUaPJTLPK3hxVuQshVMaE2x4jhuxBEkhtKPWBJZg8JFLFinzf5
nDINk8zz0j4fLCXmDAJaXz2NMacUviCiKFY8k63SumxKeTIBU20DuLk9glggTpfY
3RgdNWfvmma9iv8QW/s2UJFbRdJS0cLjra4XFFQBZLyGEJPTOcft3slWX3QgHVCD
SB3CZWy2gwbLVphiCiG91HxBtUUUzSLqPc60RdSwOCoSOaBMHZgy8yjZ8VRgQkyi
uz41hhp1mCMfssNjoLdCvr/AxJG990yQ24MiCDuzN9fYVNzUPdXF+q4E5G/avtk=
=FkuL
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141231/db379ad3/attachment.htm>

From rafael.akchurin at diladele.com  Tue Dec 30 20:30:50 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 30 Dec 2014 20:30:50 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <54A309A7.4000505@gmail.com>
References: <54A2A4AB.1000003@gmail.com>
 <1419948567529.54486@diladele.com>,<54A2B46E.5090506@gmail.com>
 <1419952954086.69012@diladele.com>
 <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
 <54A307F3.1020902@gmail.com>
 <AM3PR04MB4506D47F5B279AB6D0A04958F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
 <54A309A7.4000505@gmail.com>
Message-ID: <AM3PR04MB450D7F8D87C2F98BFB176F88F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>

Perfect thanks a lot!!!
Raf :)

From: Yuri Voinov [mailto:yvoinov at gmail.com]
Sent: Tuesday, December 30, 2014 9:23 PM
To: Rafael Akchurin; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

WCCP only, of course. To reduce Cisco CPU usage.

Also, iOS version 15.4 with SECURITYK9 techno pack activated.

31.12.2014 2:21, Rafael Akchurin ?????:
>

      > Just for me to completely clarify:

      >

      >

      >

      > - how exactly your Squid gets the traffic from your clients?
      (explicit proxy or cisco WCCP?)

      >

      >

      >

      > raf

      >

      > *From:*Yuri Voinov [mailto:yvoinov at gmail.com]

      > *Sent:* Tuesday, December 30, 2014 9:16 PM

      > *To:* Rafael Akchurin; squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
      application could not connect

      >

      >

      >

      >

      > To finalize a solution,

      >

      > see the our favorite:

      >

      >
      http://www.squid-cache.org/mail-archive/squid-users/201406/0369.html

      >

      > Why use iptables, ipfilter,Cisco, etc?!

      >

      > Only Squid, only hardcore!

      >

      > Revert cisco config back:

      >

      > R2911(config)#no access-list 121

      > R2911(config)#access-list 121 remark ACL for HTTPS WCCP

      > R2911(config)#access-list 121 remark Squid proxies bypass

      > R2911(config)#access-list 121 deny   ip host 192.168.200.3
      any

      > R2911(config)#access-list 121 deny   ip host 192.168.100.251
      any

      > R2911(config)#access-list 121 remark Videoserver

      > R2911(config)#access-list 121 deny   ip host 192.168.200.5
      any

      > R2911(config)#access-list 121 remark LAN clients proxy port
      443

      > R2911(config)#access-list 121 permit tcp 192.168.0.0
      0.0.255.255 any eq 443

      > R2911(config)#access-list 121 remark all others bypass WCCP

      > R2911(config)#access-list 121 deny   ip any any

      > R2911(config)#^Z

      > R2911#wr

      > Building configuration...

      > [OK]

      >

      > Write acl file with IP/net with SSL Pinning:

      >

      > root @ ktulhu /usr/local/squid/etc # cat dst.nobump

      > # BCC bypass

      > 91.198.63.0/24

      > # Salyk bypass

      > 212.154.165.148/32

      > # WU bypass

      > 191.232.0.0/13

      > 65.52.0.0/14

      > # Symantec bypass

      > 195.215.221.99/32

      > 195.215.221.104/32

      > 213.248.114.172/32

      > 213.248.114.173/32

      > 213.248.114.174/32

      > 213.248.114.175/32

      > 77.67.22.168/32

      > 77.67.22.171/32

      > 77.67.22.173/32

      > 213.248.114.171/32

      >

      > Add needful nets/apps to acl by your taste.

      >

      > Add to squid config:

      >

      > # SSL bump acl

      > acl net_bump src "/usr/local/squid/etc/net.bump"

      > # HTTP-use 443 port apps

      > acl url_nobump dstdom_regex \.icq\.*

      > # SSL Pinning servers. Only ip-based dst acl!

      > acl dst_nobump dst "/usr/local/squid/etc/dst.nobump"

      >

      > # SSL bump rules

      > sslproxy_cert_error allow all

      > ssl_bump none localhost

      > ssl_bump none url_nobump

      > ssl_bump none dst_nobump

      > ssl_bump server-first net_bump

      >

      > Yahooo! The same result with Squid only!

      >

      > 30.12.2014 23:39, Rafael Akchurin ?????:

      > > SSL Pinning

      >

      >

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJUowmnAAoJENNXIZxhPexGEtwH/10nuDG9+Z7AG2W+nh64X7JV
5JmvvaC778yUYnMUaPJTLPK3hxVuQshVMaE2x4jhuxBEkhtKPWBJZg8JFLFinzf5
nDINk8zz0j4fLCXmDAJaXz2NMacUviCiKFY8k63SumxKeTIBU20DuLk9glggTpfY
3RgdNWfvmma9iv8QW/s2UJFbRdJS0cLjra4XFFQBZLyGEJPTOcft3slWX3QgHVCD
SB3CZWy2gwbLVphiCiG91HxBtUUUzSLqPc60RdSwOCoSOaBMHZgy8yjZ8VRgQkyi
uz41hhp1mCMfssNjoLdCvr/AxJG990yQ24MiCDuzN9fYVNzUPdXF+q4E5G/avtk=
=FkuL
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/82d71488/attachment.htm>

From yvoinov at gmail.com  Tue Dec 30 20:32:07 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Dec 2014 02:32:07 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not	connect
In-Reply-To: <AM3PR04MB450D7F8D87C2F98BFB176F88F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
References: <54A2A4AB.1000003@gmail.com> <1419948567529.54486@diladele.com>,
 <54A2B46E.5090506@gmail.com> <1419952954086.69012@diladele.com>
 <AM3PR04MB450E65CAECE78456C53A2458F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
 <54A307F3.1020902@gmail.com>
 <AM3PR04MB4506D47F5B279AB6D0A04958F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
 <54A309A7.4000505@gmail.com>
 <AM3PR04MB450D7F8D87C2F98BFB176F88F5E0@AM3PR04MB450.eurprd04.prod.outlook.com>
Message-ID: <54A30BC7.4070504@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
No problem. ;)

31.12.2014 2:30, Rafael Akchurin ?????:
>
> Perfect thanks a lot!!!
>
> Raf :)
>
> 
>
> *From:*Yuri Voinov [mailto:yvoinov at gmail.com]
> *Sent:* Tuesday, December 30, 2014 9:23 PM
> *To:* Rafael Akchurin; squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
application could not connect
>
> 
>
>
> WCCP only, of course. To reduce Cisco CPU usage.
>
> Also, iOS version 15.4 with SECURITYK9 techno pack activated.
>
> 31.12.2014 2:21, Rafael Akchurin ?????:
>
>
>       > Just for me to completely clarify:
>
>
>
>
>
>
>
>       > - how exactly your Squid gets the traffic from your clients?
>
>       (explicit proxy or cisco WCCP?)
>
>
>
>
>
>
>
>       > raf
>
>
>
>       > *From:*Yuri Voinov [mailto:yvoinov at gmail.com]
>
>       > *Sent:* Tuesday, December 30, 2014 9:16 PM
>
>       > *To:* Rafael Akchurin; squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > *Subject:* Re: [squid-users] Squid 3 SSL bump: Google drive
>
>       application could not connect
>
>
>
>
>
>
>
>
>
>       > To finalize a solution,
>
>
>
>       > see the our favorite:
>
>
>
>
>
>       http://www.squid-cache.org/mail-archive/squid-users/201406/0369.html
>
>
>
>       > Why use iptables, ipfilter,Cisco, etc?!
>
>
>
>       > Only Squid, only hardcore!
>
>
>
>       > Revert cisco config back:
>
>
>
>       > R2911(config)#no access-list 121
>
>       > R2911(config)#access-list 121 remark ACL for HTTPS WCCP
>
>       > R2911(config)#access-list 121 remark Squid proxies bypass
>
>       > R2911(config)#access-list 121 deny   ip host 192.168.200.3
>
>       any
>
>       > R2911(config)#access-list 121 deny   ip host 192.168.100.251
>
>       any
>
>       > R2911(config)#access-list 121 remark Videoserver
>
>       > R2911(config)#access-list 121 deny   ip host 192.168.200.5
>
>       any
>
>       > R2911(config)#access-list 121 remark LAN clients proxy port
>
>       443
>
>       > R2911(config)#access-list 121 permit tcp 192.168.0.0
>
>       0.0.255.255 any eq 443
>
>       > R2911(config)#access-list 121 remark all others bypass WCCP
>
>       > R2911(config)#access-list 121 deny   ip any any
>
>       > R2911(config)#^Z
>
>       > R2911#wr
>
>       > Building configuration...
>
>       > [OK]
>
>
>
>       > Write acl file with IP/net with SSL Pinning:
>
>
>
>       > root @ ktulhu /usr/local/squid/etc # cat dst.nobump
>
>       > # BCC bypass
>
>       > 91.198.63.0/24
>
>       > # Salyk bypass
>
>       > 212.154.165.148/32
>
>       > # WU bypass
>
>       > 191.232.0.0/13
>
>       > 65.52.0.0/14
>
>       > # Symantec bypass
>
>       > 195.215.221.99/32
>
>       > 195.215.221.104/32
>
>       > 213.248.114.172/32
>
>       > 213.248.114.173/32
>
>       > 213.248.114.174/32
>
>       > 213.248.114.175/32
>
>       > 77.67.22.168/32
>
>       > 77.67.22.171/32
>
>       > 77.67.22.173/32
>
>       > 213.248.114.171/32
>
>
>
>       > Add needful nets/apps to acl by your taste.
>
>
>
>       > Add to squid config:
>
>
>
>       > # SSL bump acl
>
>       > acl net_bump src "/usr/local/squid/etc/net.bump"
>
>       > # HTTP-use 443 port apps
>
>       > acl url_nobump dstdom_regex \.icq\.*
>
>       > # SSL Pinning servers. Only ip-based dst acl!
>
>       > acl dst_nobump dst "/usr/local/squid/etc/dst.nobump"
>
>
>
>       > # SSL bump rules
>
>       > sslproxy_cert_error allow all
>
>       > ssl_bump none localhost
>
>       > ssl_bump none url_nobump
>
>       > ssl_bump none dst_nobump
>
>       > ssl_bump server-first net_bump
>
>
>
>       > Yahooo! The same result with Squid only!
>
>
>
>       > 30.12.2014 23:39, Rafael Akchurin ?????:
>
>       > > SSL Pinning
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUowvHAAoJENNXIZxhPexGdMwH/28FtXnzlefKyuPNgvvLBJ2B
dd/slXF1TbXhBi60S6jfXe/Vlbd9iAeTc4zP6WaR7XJEty3jXDCKQ/TISNDhXyRg
3tB/Ycg1ondWuAqPZsLTlrmttGDSkOgPOamL+kkGbbfyim6xdv/y9ZcH1QEz2Ibr
ToRRXENsbuFWgpZchrNtDrDtOpAUwBkNKLyOkdE1t1dX4g9BKq0PLq054oqx/vmG
G4ErEoUSqKWgWG2aOCk3l6GIJQwbcj13qLDKcKFRQEyCYRZ07sf5PcSk1A2J1jTt
vJzTMse05mOt/fZdhp0Sf+w5rw8kg0oMv7szyVZjXqnuiwKgOYabjwFje42NkOQ=
=TYok
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141231/aa7b0697/attachment.htm>

From hack.back at hotmail.com  Tue Dec 30 20:56:55 2014
From: hack.back at hotmail.com (HackXBack)
Date: Tue, 30 Dec 2014 12:56:55 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <54A1ACDD.1080601@ngtech.co.il>
References: <549BE122.7000603@ngtech.co.il>
 <1419593895219-4668839.post@n4.nabble.com> <549E196D.1070104@treenet.co.nz>
 <1419806788826-4668852.post@n4.nabble.com> <54A0DC92.6040404@treenet.co.nz>
 <1419855600388-4668856.post@n4.nabble.com>
 <1419856672924-4668857.post@n4.nabble.com> <54A199A3.2040102@ngtech.co.il>
 <1419878341964-4668859.post@n4.nabble.com> <54A1ACDD.1080601@ngtech.co.il>
Message-ID: <1419973015802-4668885.post@n4.nabble.com>

hello ,
just one more question for this installation like what Amos told me to do ,
is this cache_dir formula right :

cache_dir rock /cache01/rock 50000 120 256 max-size=31744
cache_dir aufs/cache01/aufs 2000000 4808 256 min-size=31745

cache_dir rock /cache01/rock 50000 120 256 max-size=31744
cache_dir aufs/cache01/aufs 2000000 4808 256 min-size=31745

cache_dir rock /cache01/rock 50000 120 256 max-size=31744
cache_dir aufs/cache01/aufs 2000000 4808 256 min-size=31745

cache_dir rock /cache01/rock 50000 120 256 max-size=31744
cache_dir aufs/cache01/aufs 2000000 4808 256 min-size=31745

cache_dir rock /cache01/rock 50000 120 256 max-size=31744
cache_dir aufs/cache01/aufs 2000000 4808 256 min-size=31745



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668885.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Tue Dec 30 21:02:48 2014
From: hack.back at hotmail.com (HackXBack)
Date: Tue, 30 Dec 2014 13:02:48 -0800 (PST)
Subject: [squid-users] https bug slow browsing
In-Reply-To: <1419973015802-4668885.post@n4.nabble.com>
References: <1419593895219-4668839.post@n4.nabble.com>
 <549E196D.1070104@treenet.co.nz> <1419806788826-4668852.post@n4.nabble.com>
 <54A0DC92.6040404@treenet.co.nz> <1419855600388-4668856.post@n4.nabble.com>
 <1419856672924-4668857.post@n4.nabble.com> <54A199A3.2040102@ngtech.co.il>
 <1419878341964-4668859.post@n4.nabble.com> <54A1ACDD.1080601@ngtech.co.il>
 <1419973015802-4668885.post@n4.nabble.com>
Message-ID: <1419973368470-4668886.post@n4.nabble.com>

Correction:

cache_dir rock /cache01/rock 50000 120 256 max-size=31744
cache_dir aufs/cache01/aufs 2000000 4808 256 min-size=31745

cache_dir rock /cache02/rock 50000 120 256 max-size=31744
cache_dir aufs/cache02/aufs 2000000 4808 256 min-size=31745

cache_dir rock /cache03/rock 50000 120 256 max-size=31744
cache_dir aufs/cache03/aufs 2000000 4808 256 min-size=31745

cache_dir rock /cache04/rock 50000 120 256 max-size=31744
cache_dir aufs/cache04/aufs 2000000 4808 256 min-size=31745

cache_dir rock /cache05/rock 50000 120 256 max-size=31744
cache_dir aufs/cache05/aufs 2000000 4808 256 min-size=31745 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-bug-slow-browsing-tp4668830p4668886.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Dec 31 00:03:35 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Dec 2014 13:03:35 +1300
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
In-Reply-To: <CAH_OBid-E2NeENMR_c-PYe8jPfnN5VaF1b6dOFKdpk8Hi0Fpgg@mail.gmail.com>
References: <54A2A4AB.1000003@gmail.com>	<54A2AF50.2070103@treenet.co.nz>
 <CAH_OBid-E2NeENMR_c-PYe8jPfnN5VaF1b6dOFKdpk8Hi0Fpgg@mail.gmail.com>
Message-ID: <54A33D57.8030500@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 31/12/2014 6:30 a.m., shawn wilson wrote:
> On Dec 30, 2014 8:57 AM, "Amos Jeffries" wrote:
>> 
> 
>> 
>> As bumping gets more popular we are hearing about a number of
>> services abusing port 443 for non-HTTPS protocols on the false
>> assumption that the TLS layer goes all the way to the origin
>> server without inspection. That has never been a true assumption,
>> CDN frontends have always decrypted.
>> 
> 
> OT but you use 443 because people expect it to be encrypted web
> data and don't block it. And DPI doesn't tell you anything more.
> 

"web" is no longer just HTTP and that is part of the problem. People
treating port 443 as if any of the "web" protocols can use it just by
being wrapped in TLS.

Port 443 is specifically registered for "HTTP over TLS" (aka HTTPS).
"Web" includes HTTP, but also includes protocols like RSS, WebSockets,
SPDY, QUIC, COAP, even IRC and Jabber at times.

The other non-HTTP protocols have other non-443 ports registered or
available for their use. Some like SMTP even switch their main port
between encrypted and non-encrypted as needed.

I know it can be hard to get unusual ports opened past firewalls, but
that is not being helped by everything using only a handful of ports.
[I have a long rant at this point about lazy corporates, but its 2015
in a few hrs so I'll drop it for now].

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUoz1SAAoJELJo5wb/XPRjjysH/0qwbyyOk8gIqziA5gU2h5FX
ztcvM6gMxNSUWkZ68Duc7MSP+5D5LfWpGUuGoIvsqV2ovMY5CT1hFKNsk/JyvAsH
NORSS1EYwns0z8ftlJi0h5//YdzFIVX5BAbGmDuUQuIsGcm3Yxjofn91YU4wlkM1
QfnPfBXRJKeXUkDaAsC+OiK1SgMpFb7WwGnbkqaTZZYM1qjETbWlujJGQK0Ipz+v
NIKATGdksa1cYxkb91J6G8Y9hJBAYkxMIQi1n+cvQ1ntDqBUn5bHK9LTS8/7Ledm
yzc27NNqHSgGY3FwfjNaHjIoNaJTukcH6WA/qBlJF4wz/uSZ/ZD4QMsGidmmNaE=
=JXLa
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Wed Dec 31 00:21:03 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Dec 2014 13:21:03 +1300
Subject: [squid-users] Proxy to proxy authentication
In-Reply-To: <m7usmj$iu9$1@ger.gmane.org>
References: <m7t2pq$2rk$1@ger.gmane.org> <m7usmj$iu9$1@ger.gmane.org>
Message-ID: <54A3416F.9060501@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 31/12/2014 7:59 a.m., Markus Moeller wrote:
> Hi Amos,
> 
>> On 30/12/2014 3:31 p.m., Markus Moeller wrote:
>>> Hi,
>>> 
>>> Can squid authenticate to an upstream proxy using digest ?  If
>>> I saw it right cache_peer allows basic and negotiate only (or
>>> passthrough)
>>> 
>>> Thank you Markus
>>> 
>> 
>> Not yet.
>> 
>> Amos
> 
> Is it planned to add or no real interest in it ?

Mostly lack of interest. As usual if you are interested please feel
free to code. :-)

The biggest issue is that Digest like NTLM does not permit the initial
challenge step to be avoided. So Squid has to be made to handle
request retry when fetching the first nonce. The peer is supposed to
supply a next-nonce before the old one expires so further retries
*should* not be necessary, but may also happen on persistent connections.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUo0FvAAoJELJo5wb/XPRjyjIIAMLwnM/JkZAvRjClivoJUIXC
vZ9a3Z/r69pBMNM1snZ1ep4C+hg7jNYsBjennl03u8Fr+kQ4BhhoaAsqjuOAVeWb
boR1MtOpmkt2dhf+U2js9Y3tSd/tY6QSNoCboVDNEUoZDyowHBovdqL9Ei3gFr1t
lqRNoW39K/vvbWRwB6/WflH4xHiX595Wywshh9Hec7a6nhjwdGvZzeeBvDhG1eVj
ECHcIkBICfTydazIFulyCiDTvUgspC1YpcIV2+P//PKGQEDJ/ds6KwxjKqYix9JU
8pnAnm423O11RzUh7qq8NixACPkOjkP7IDXbvJPG2YrKGVFQj8Fi2gEeEcJ/sgU=
=rq6Y
-----END PGP SIGNATURE-----


From huaraz at moeller.plus.com  Wed Dec 31 00:51:27 2014
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Wed, 31 Dec 2014 00:51:27 -0000
Subject: [squid-users] Proxy to proxy authentication
In-Reply-To: <54A3416F.9060501@treenet.co.nz>
References: <m7t2pq$2rk$1@ger.gmane.org> <m7usmj$iu9$1@ger.gmane.org>
 <54A3416F.9060501@treenet.co.nz>
Message-ID: <m7vhak$25q$1@ger.gmane.org>

I thought it wasn't trivial, otherwise it would have been already done.  ;-)

Thank you
Markus

"Amos Jeffries"  wrote in message news:54A3416F.9060501 at treenet.co.nz... 

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 31/12/2014 7:59 a.m., Markus Moeller wrote:
> Hi Amos,
> 
>> On 30/12/2014 3:31 p.m., Markus Moeller wrote:
>>> Hi,
>>> 
>>> Can squid authenticate to an upstream proxy using digest ?  If
>>> I saw it right cache_peer allows basic and negotiate only (or
>>> passthrough)
>>> 
>>> Thank you Markus
>>> 
>> 
>> Not yet.
>> 
>> Amos
> 
> Is it planned to add or no real interest in it ?

Mostly lack of interest. As usual if you are interested please feel
free to code. :-)

The biggest issue is that Digest like NTLM does not permit the initial
challenge step to be avoided. So Squid has to be made to handle
request retry when fetching the first nonce. The peer is supposed to
supply a next-nonce before the old one expires so further retries
*should* not be necessary, but may also happen on persistent connections.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUo0FvAAoJELJo5wb/XPRjyjIIAMLwnM/JkZAvRjClivoJUIXC
vZ9a3Z/r69pBMNM1snZ1ep4C+hg7jNYsBjennl03u8Fr+kQ4BhhoaAsqjuOAVeWb
boR1MtOpmkt2dhf+U2js9Y3tSd/tY6QSNoCboVDNEUoZDyowHBovdqL9Ei3gFr1t
lqRNoW39K/vvbWRwB6/WflH4xHiX595Wywshh9Hec7a6nhjwdGvZzeeBvDhG1eVj
ECHcIkBICfTydazIFulyCiDTvUgspC1YpcIV2+P//PKGQEDJ/ds6KwxjKqYix9JU
8pnAnm423O11RzUh7qq8NixACPkOjkP7IDXbvJPG2YrKGVFQj8Fi2gEeEcJ/sgU=
=rq6Y
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ag4ve.us at gmail.com  Wed Dec 31 04:13:34 2014
From: ag4ve.us at gmail.com (shawn wilson)
Date: Tue, 30 Dec 2014 23:13:34 -0500
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
In-Reply-To: <54A33D57.8030500@treenet.co.nz>
References: <54A2A4AB.1000003@gmail.com> <54A2AF50.2070103@treenet.co.nz>
 <CAH_OBid-E2NeENMR_c-PYe8jPfnN5VaF1b6dOFKdpk8Hi0Fpgg@mail.gmail.com>
 <54A33D57.8030500@treenet.co.nz>
Message-ID: <CAH_OBiejmg4GAm-2PYxuFVhrs+s+VaZsNXNL_ypvTeS6XjLc4g@mail.gmail.com>

On Dec 30, 2014 7:04 PM, "Amos Jeffries" <squid3 at treenet.co.nz> wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 31/12/2014 6:30 a.m., shawn wilson wrote:
> > On Dec 30, 2014 8:57 AM, "Amos Jeffries" wrote:
> >>
> >
> >>
> >> As bumping gets more popular we are hearing about a number of
> >> services abusing port 443 for non-HTTPS protocols on the false
> >> assumption that the TLS layer goes all the way to the origin
> >> server without inspection. That has never been a true assumption,
> >> CDN frontends have always decrypted.
> >>
> >
> > OT but you use 443 because people expect it to be encrypted web
> > data and don't block it. And DPI doesn't tell you anything more.
> >
>
> "web" is no longer just HTTP and that is part of the problem. People
> treating port 443 as if any of the "web" protocols can use it just by
> being wrapped in TLS.
>

Worse than that - I'm mainly thinking ssh (which won't survive DPI).

> Port 443 is specifically registered for "HTTP over TLS" (aka HTTPS).
> "Web" includes HTTP, but also includes protocols like RSS, WebSockets,
> SPDY, QUIC, COAP, even IRC and Jabber at times.
>
> The other non-HTTP protocols have other non-443 ports registered or
> available for their use. Some like SMTP even switch their main port
> between encrypted and non-encrypted as needed.
>
> I know it can be hard to get unusual ports opened past firewalls, but
> that is not being helped by everything using only a handful of ports.
> [I have a long rant at this point about lazy corporates, but its 2015
> in a few hrs so I'll drop it for now].
>

My point isn't even about "lazy corporates"  but this: how many airlines
will block ssh over port 22 and how many will block it over 443? (And if
that doesn't work OpenVPN on 443 and ssh through that) I assume Google
thought along similar lines when they talked about which port to put their
binary Drive data on.

You want people to stop using 443 for non-https traffic, get people to stop
blocking the other ssl ports.

This is OT but here's the topical point -  if you're going to bump http+ssl
traffic, you need to know that due to some people blocking alternative
ports for secure services, you'll always see non-http traffic here. The
IETF might give you a port but only smart long term business decisions will
allow you to keep it - that's far past over for 443/tcp at this point I
think :/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/291f7fa9/attachment.htm>

From smashingzero33 at gmail.com  Wed Dec 31 05:59:57 2014
From: smashingzero33 at gmail.com (Evan Blackstone)
Date: Tue, 30 Dec 2014 23:59:57 -0600
Subject: [squid-users] Squid Deployment Questions
Message-ID: <CAAbi1EuPc9qPTavqw_tJJUh=T-cJwdTHcMrNtu0oMDeoqtKC7Q@mail.gmail.com>

Hey all,
Wondering if I could get some advice on potentially setting up a Squid
forward proxy on my network. I'm not a Linux novice by any means, but I'm
not experienced in server administration, log review, etc.

We're needing to deploy a simple non-caching, non-peering forward proxy to
integrate with an ICAP server for web filtering. My plan is pretty
basic...here's my network config:

Internet --> Cisco ASA --> DMZ --> Internal LAN

I've received conflicting advice on whether or not there's any advantage to
putting a forward proxy on the DMZ vs. internal LAN. In any case, 'm
wanting to deploy an explicit proxy with a single NIC. Workstations will
use a PAC file, etc. to point to the proxy.

If the server is on the DMZ, I'd allow 80/443 from the internal LAN to the
DMZ, then allow 80/443 from the proxy to outside. I'd also be allowing the
proxy to internal LAN for ICAP, syslog, and possibly NTP. The proxy would
have a single interface...although it would NAT to outside for internet
access, there would be no ports open on the outside interface.

Based on some testing I've done, my squid.conf would be pretty basic...

http_access allow internalnetwork
cache deny internalnetwork
always_direct allow internalnetwork
http_access deny all
etc.

My questions are:

Does it sound like I'm on the right track here? Would the above described
configuration be safe? I've read that Squid should listen only on an
internal interface? What about when the server only has one?

What level of risk would I be assuming (regular patching included)? Given
that I'm relatively new to monitoring Linux servers for security, etc., is
this a bad idea? I'm not really sure what to be looking for log-wise in
terms of compromise. I have edge devices and monitoring on the perimeter,
but I don't really know what to look for on the server itself...

Am I approaching this the wrong way? Should I be looking at putting it on
the inside LAN? Would such an approach leave my network vulnerable should
the Squid box get owned?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141230/677e42e0/attachment.htm>

From eliezer at ngtech.co.il  Wed Dec 31 06:20:17 2014
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 31 Dec 2014 08:20:17 +0200
Subject: [squid-users] Squid Deployment Questions
In-Reply-To: <CAAbi1EuPc9qPTavqw_tJJUh=T-cJwdTHcMrNtu0oMDeoqtKC7Q@mail.gmail.com>
References: <CAAbi1EuPc9qPTavqw_tJJUh=T-cJwdTHcMrNtu0oMDeoqtKC7Q@mail.gmail.com>
Message-ID: <54A395A1.1010802@ngtech.co.il>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hey Evan,

I am missing couple things in my head to get the picture:
How big is the lan? how many clients?
Allowing port 80 and 443 from then lan to the dmz depends on the
services that will be or are there.
Squid default port is 3128.
If the ICAP, NTP, SYSLOG are in the lan segment I am almost sure that
putting the proxy inside the lan is a better idea.
You will just need to block all port 80\443 and maybe other traffic
from passing the firewall unless it comes from the proxy IP address.
Risk? It is unclear to me what are you talking about.
Basically as long you are using a Linux from a maintained distribution
you should be ok about getting critical updates.
I am using ubuntu LTS for couple years and I think it's a good choice
since you always can try their support for a price.
Since it's a linux server most of the access to the server would
probably be throw ssh so install fail2ban to prevent password
attacks(from the internal LAN).
In the case you want to restrict the access a bit more you can use
iptables which is the linux firewall to prevent unwanted probes to
touch your machine.

If you do have some more questions you got into the right place.

All The Bests,
Eliezer

On 12/31/2014 07:59 AM, Evan Blackstone wrote:
> What level of risk would I be assuming (regular patching included)?
> Given that I'm relatively new to monitoring Linux servers for
> security, etc., is this a bad idea? I'm not really sure what to be
> looking for log-wise in terms of compromise. I have edge devices
> and monitoring on the perimeter, but I don't really know what to
> look for on the server itself...
> 
> Am I approaching this the wrong way? Should I be looking at putting
> it on the inside LAN? Would such an approach leave my network
> vulnerable should the Squid box get owned?

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJUo5WgAAoJENxnfXtQ8ZQUmtEH/190ktYLzjxxS9Llv/RiWaBJ
rXvbgUjPNe8usK04vesx0SVqmQBl3vdHqlKxCKd/rSzs/2/SBDW+nxxqB2aGX+op
HohS7gbyWvME6EaY7WzpnIJjQ3Gthbw2KElm56WrHo3FFRMAXUPyK6JHC8DVJe7f
3wOqW80YiKy5dezYKJCGFirP7YJRJMQOpa0U/tHKpUlvBJ9wdsGM0B/oWR/jmoBO
ToKpluk6lnJdJ5F8j/GFZQ4/OQxbp7NJV/dMER5tfkpfcR6yOzuo2CGbfdmkcp//
9Mefp+EwJT6Z/uca7UmMDeSBVajOpkR2bZ2bcy2klzqlj1j3bm+dIrz2T5td5BU=
=PzLI
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Wed Dec 31 09:55:18 2014
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Dec 2014 22:55:18 +1300
Subject: [squid-users] Squid Deployment Questions
In-Reply-To: <CAAbi1EuPc9qPTavqw_tJJUh=T-cJwdTHcMrNtu0oMDeoqtKC7Q@mail.gmail.com>
References: <CAAbi1EuPc9qPTavqw_tJJUh=T-cJwdTHcMrNtu0oMDeoqtKC7Q@mail.gmail.com>
Message-ID: <54A3C806.4010405@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 31/12/2014 6:59 p.m., Evan Blackstone wrote:
> Hey all, Wondering if I could get some advice on potentially
> setting up a Squid forward proxy on my network. I'm not a Linux
> novice by any means, but I'm not experienced in server
> administration, log review, etc.
> 
> We're needing to deploy a simple non-caching, non-peering forward
> proxy to integrate with an ICAP server for web filtering. My plan
> is pretty basic...here's my network config:
> 
> Internet --> Cisco ASA --> DMZ --> Internal LAN
> 
> I've received conflicting advice on whether or not there's any
> advantage to putting a forward proxy on the DMZ vs. internal LAN.
> In any case, 'm wanting to deploy an explicit proxy with a single
> NIC. Workstations will use a PAC file, etc. to point to the proxy.
> 
> If the server is on the DMZ, I'd allow 80/443 from the internal LAN
> to the DMZ, then allow 80/443 from the proxy to outside. I'd also
> be allowing the proxy to internal LAN for ICAP, syslog, and
> possibly NTP. The proxy would have a single interface...although it
> would NAT to outside for internet access, there would be no ports
> open on the outside interface.

Like Eliezer mentioned if ICAP services are in the LAN place the proxy
there. Placing the proxy in the DMZ if ICAP services are in the LAN
means the traffic has to flow across the DMZ<->LAN pathways three
times - limiting your traffic to 1/3 of line speed on the slowest NIC
along the way.

Similarly using a single NIC machine means the HTTP traffic through
the proxy is already limited to 1.2 the speed of that NIC. If it's not
a Gbit NIC then using two NIC (for separate inbound and outbound
flows) will allow Squid to run at capacity - which is somewhat over
50Mbps these days and increasing a little each release.


> 
> Based on some testing I've done, my squid.conf would be pretty
> basic...
> 
> http_access allow internalnetwork cache deny internalnetwork 
> always_direct allow internalnetwork http_access deny all etc.
> 

No need for always_direct. Nor for "cache deny internalnetwork".

You could use "cache deny all" to prevent all HTTP caching but a small
amount of memory-only cache is good for improving responses to the
topmost popular URLs. Squid has a default 256MB of memory cache to
store approx 10K objects (cache_mem directive).


> My questions are:
> 
> Does it sound like I'm on the right track here? Would the above
> described configuration be safe? I've read that Squid should listen
> only on an internal interface? What about when the server only has
> one?

Use the default squid.conf as a basis and extend as necessary. It has
the basic security measures that are important. For a quick start you
only need to ensure *localnet* ACL is defined with your LAN IP ranges
and you are good to go as a forward proxy.


Internal/external interface makes no difference when there is only one
NIC.

The default config is safe enough to reject traffic from external
sources (non-localnet), but you can be extra sure with either a
firewall block in the routers preventing non-LAN connections inbound
to the proxy machine.


> 
> What level of risk would I be assuming (regular patching included)?
> Given that I'm relatively new to monitoring Linux servers for
> security, etc., is this a bad idea? I'm not really sure what to be
> looking for log-wise in terms of compromise. I have edge devices
> and monitoring on the perimeter, but I don't really know what to
> look for on the server itself...

Squid is one of (if not The) most hardened proxies available. It can
basically only be compromised in two ways:
1) corruption of cached objects - you dont have any on disk, and
avoiding the refresh_pattern override/ignores removes the risk of
memory objects corruption.

2) infection of the binaries that make up Squid - this is not
detectable from within Squid anyway. A system AV scanner (or regular
update schedule) is required for that.

Squid does crash in a numer of ways, but that is a fail-closed DoS
type event rather than compromise.

* You should monitor cache.log for anything that mentions "assertion"
or "FATAL". These are Squid bugs and self-DoS vulnerability. We are
always interested in finding out how these happen and fixing.

* access.log monitoring is a possibility. One can usually find web
exploits being attempted on *other* services in a Squid access.log, so
monitoring it like one woud la web server log for suspicious URL
requests can be useful to proactively identify compromised clients.


The Safe_ports and SSL_ports ACLs in the default config map out blocks
on the ports with known security issues.

You may have clients with web apps needing special ports accessible
via CONNECT. Take the usual due-diligence there as if you were opening
a firewall port for unrestricted use, then if you wish add the port
number to SSL_ports ACL (Safe_ports should already be open for 1024 or
larger port numbers).


You can enable the to_localhost rules which are commented out by
default to protect against clients accessing services on the Squid
machine itself (if any exist accessible over localhost interface).
Though on a dedicated proxy the SSL_Ports rule should already be
taking care of that.


> 
> Am I approaching this the wrong way? Should I be looking at putting
> it on the inside LAN? Would such an approach leave my network
> vulnerable should the Squid box get owned?
> 

Since the purpose of a proxy is to be reachable from LAN clients the
security impact on Squid itself is no different in either position.

The security balance is betweeen whether the rest of the machine
access methods (including the ICAP servers security "footprint") are
more/worse secure in either position vs the traffic costs mentioned above.

NP: ICAP servers and particularly the unencrypted TCP connections to
them are the weakest point, since they have the ability to alter the
HTTP traffic contents in arbitrary ways. Explicitly not touching the
traffic content is one of the security hardening aspects of Squid.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJUo8gFAAoJELJo5wb/XPRjtX8H+wRNpqWFQ5+Q/elGQcVJVMtO
z4U1SrMG3fk1Mbda/i2J/1gds/bdkOSqRtc6E8Qi35qTBDARxNCLixT60zcEla4m
r/kqBqPXwl0ZpheaS+st9n5Pmc2LoQxwZTJzUT4CjzVZ4+dWPVHhBZoIbizo1EGO
hpZLLGf7Xxoy975119av/NTY+as5moXvG94qoOVne+qOzMuJjUhw1Yk9N6drZ7K8
4TKLdi6ePFF6esHe2XERjPVEdx9L5YtAhV8TeJH2V4RENdZkbwzOe6Bcf/RIa3Do
/9FL03OfI36F7XepjsQzMgf57wpB6T5Kh27geqmWuhkP7AuU13U8vRrAZIYHzNw=
=xmjG
-----END PGP SIGNATURE-----


From james at ejbdigital.com.au  Wed Dec 31 11:11:36 2014
From: james at ejbdigital.com.au (James Harper)
Date: Wed, 31 Dec 2014 11:11:36 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
In-Reply-To: <54A2AF50.2070103@treenet.co.nz>
References: <54A2A4AB.1000003@gmail.com> <54A2AF50.2070103@treenet.co.nz>
Message-ID: <HKNPR04MB1933D74D5F5A53D56ED20C8E85F0@HKNPR04MB193.apcprd04.prod.outlook.com>

> 
> Probably non-HTTPS protocol being used.
> 
> As bumping gets more popular we are hearing about a number of services
> abusing port 443 for non-HTTPS protocols on the false assumption that
> the TLS layer goes all the way to the origin server without
> inspection. That has never been a true assumption, CDN frontends have
> always decrypted.
> 

I've mentioned it before, and it's been pointed out that it probably doesn't scale, but I wrote a callout helper for this reason and for better logging.

Basically:

external_acl_type cert_callout concurrency=20 %DST %PORT /usr/local/squid/libexec/ext_cert_callout_acl
acl is_ssl external cert_callout IS_SSL
ssl_bump bump is_ssl
ssl_bump splice all

The helper connects to the IP:port and tries to obtain the certificate, and then caches the result (in an sqlite database). If it can't do so within a fairly short time it returns failure (but keeps trying a bit longer and caches it for next time). Alternatively if the IP used to be SSL but is now timing out it returns the previously cached value. Negative results are cached for an increasing amount of time each time it fails, on the basis that it probably isn't SSL.

So it's somewhat optimistic - on a slow link or for a slow server a given IP:port might be spliced the first time when it should be bumped, but it will learn fairly quickly. And for non-SSL connections that appear to just hang in response to the request there will be an additional delay the first time. But otherwise it learns about the target without requiring admin intervention.

It also returns the name of the cert so it can be logged instead of the IP (for transparent connections), although that isn't ideal as the same IP might be used for many services (google/youtube/etc)

I can post it if anyone is interested, although it would require a bit of work to be completely useful.

James


From yvoinov at gmail.com  Wed Dec 31 12:07:14 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Dec 2014 18:07:14 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
Message-ID: <54A3E6F2.1050603@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
James,

where I can take a look on your helper? I'm interested in this things,
as exists services uses 443 port but without HTTPS. I.e., ICQ, etc.

WBR, Yuri
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUo+byAAoJENNXIZxhPexGQ9YH/2E1q0AklYtA0L1V4qXnQ5wX
NtrW/9hqZYo6JNiRdTyOq0FyhPJkHqslg7cs+OyF+W3uY1PZSVXzttHcc20+Gogl
tqaQ8z/i/gp1kjLfEXSDGivNCoGeAwMeNZhwqBc2s1PdW1xxhD6vhfmR2G4Xo8qJ
o3U8akB/qROqsYVxFlAuqaOHZf7W7y3VQeMx++ReouayYZrVVWMsk0RQT3MEsGJw
jfjUeC83qV+PKeH9ShxnJfh9oQ4If5jMMi5hD64UC+dBslVBoEiTtfXx70PFIFHd
sxxEhiGVpSwCYz5GzlktVgpRSDsX8Ym7P1Af8zLQO7RtusU1sNOiMGboL0RUNUA=
=PNeb
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Wed Dec 31 12:09:07 2014
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Dec 2014 18:09:07 +0600
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
In-Reply-To: <mailman.3.1420027201.23065.squid-users@lists.squid-cache.org>
References: <mailman.3.1420027201.23065.squid-users@lists.squid-cache.org>
Message-ID: <54A3E763.7080909@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Also, finally, gents.

Google Drive application uses network:

# Google Drive
74.125.201.0/24

in my region. ;)

So to bypass bump you must specify this network as dst with no bumping.

WBR, Yuri

31.12.2014 18:00, squid-users-request at lists.squid-cache.org ?????:
> Send squid-users mailing list submissions to
>     squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>     http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>     squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>     squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Re: Squid Deployment Questions (Amos Jeffries)
>    2. Re: Squid 3 SSL bump: Google drive application could not
>       connect (James Harper)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Wed, 31 Dec 2014 22:55:18 +1300
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid Deployment Questions
> Message-ID: <54A3C806.4010405 at treenet.co.nz>
> Content-Type: text/plain; charset=utf-8
>
> On 31/12/2014 6:59 p.m., Evan Blackstone wrote:
> > Hey all, Wondering if I could get some advice on potentially
> > setting up a Squid forward proxy on my network. I'm not a Linux
> > novice by any means, but I'm not experienced in server
> > administration, log review, etc.
>
> > We're needing to deploy a simple non-caching, non-peering forward
> > proxy to integrate with an ICAP server for web filtering. My plan
> > is pretty basic...here's my network config:
>
> > Internet --> Cisco ASA --> DMZ --> Internal LAN
>
> > I've received conflicting advice on whether or not there's any
> > advantage to putting a forward proxy on the DMZ vs. internal LAN.
> > In any case, 'm wanting to deploy an explicit proxy with a single
> > NIC. Workstations will use a PAC file, etc. to point to the proxy.
>
> > If the server is on the DMZ, I'd allow 80/443 from the internal LAN
> > to the DMZ, then allow 80/443 from the proxy to outside. I'd also
> > be allowing the proxy to internal LAN for ICAP, syslog, and
> > possibly NTP. The proxy would have a single interface...although it
> > would NAT to outside for internet access, there would be no ports
> > open on the outside interface.
>
> Like Eliezer mentioned if ICAP services are in the LAN place the proxy
> there. Placing the proxy in the DMZ if ICAP services are in the LAN
> means the traffic has to flow across the DMZ<->LAN pathways three
> times - limiting your traffic to 1/3 of line speed on the slowest NIC
> along the way.
>
> Similarly using a single NIC machine means the HTTP traffic through
> the proxy is already limited to 1.2 the speed of that NIC. If it's not
> a Gbit NIC then using two NIC (for separate inbound and outbound
> flows) will allow Squid to run at capacity - which is somewhat over
> 50Mbps these days and increasing a little each release.
>
>
>
> > Based on some testing I've done, my squid.conf would be pretty
> > basic...
>
> > http_access allow internalnetwork cache deny internalnetwork
> > always_direct allow internalnetwork http_access deny all etc.
>
>
> No need for always_direct. Nor for "cache deny internalnetwork".
>
> You could use "cache deny all" to prevent all HTTP caching but a small
> amount of memory-only cache is good for improving responses to the
> topmost popular URLs. Squid has a default 256MB of memory cache to
> store approx 10K objects (cache_mem directive).
>
>
> > My questions are:
>
> > Does it sound like I'm on the right track here? Would the above
> > described configuration be safe? I've read that Squid should listen
> > only on an internal interface? What about when the server only has
> > one?
>
> Use the default squid.conf as a basis and extend as necessary. It has
> the basic security measures that are important. For a quick start you
> only need to ensure *localnet* ACL is defined with your LAN IP ranges
> and you are good to go as a forward proxy.
>
>
> Internal/external interface makes no difference when there is only one
> NIC.
>
> The default config is safe enough to reject traffic from external
> sources (non-localnet), but you can be extra sure with either a
> firewall block in the routers preventing non-LAN connections inbound
> to the proxy machine.
>
>
>
> > What level of risk would I be assuming (regular patching included)?
> > Given that I'm relatively new to monitoring Linux servers for
> > security, etc., is this a bad idea? I'm not really sure what to be
> > looking for log-wise in terms of compromise. I have edge devices
> > and monitoring on the perimeter, but I don't really know what to
> > look for on the server itself...
>
> Squid is one of (if not The) most hardened proxies available. It can
> basically only be compromised in two ways:
> 1) corruption of cached objects - you dont have any on disk, and
> avoiding the refresh_pattern override/ignores removes the risk of
> memory objects corruption.
>
> 2) infection of the binaries that make up Squid - this is not
> detectable from within Squid anyway. A system AV scanner (or regular
> update schedule) is required for that.
>
> Squid does crash in a numer of ways, but that is a fail-closed DoS
> type event rather than compromise.
>
> * You should monitor cache.log for anything that mentions "assertion"
> or "FATAL". These are Squid bugs and self-DoS vulnerability. We are
> always interested in finding out how these happen and fixing.
>
> * access.log monitoring is a possibility. One can usually find web
> exploits being attempted on *other* services in a Squid access.log, so
> monitoring it like one woud la web server log for suspicious URL
> requests can be useful to proactively identify compromised clients.
>
>
> The Safe_ports and SSL_ports ACLs in the default config map out blocks
> on the ports with known security issues.
>
> You may have clients with web apps needing special ports accessible
> via CONNECT. Take the usual due-diligence there as if you were opening
> a firewall port for unrestricted use, then if you wish add the port
> number to SSL_ports ACL (Safe_ports should already be open for 1024 or
> larger port numbers).
>
>
> You can enable the to_localhost rules which are commented out by
> default to protect against clients accessing services on the Squid
> machine itself (if any exist accessible over localhost interface).
> Though on a dedicated proxy the SSL_Ports rule should already be
> taking care of that.
>
>
>
> > Am I approaching this the wrong way? Should I be looking at putting
> > it on the inside LAN? Would such an approach leave my network
> > vulnerable should the Squid box get owned?
>
>
> Since the purpose of a proxy is to be reachable from LAN clients the
> security impact on Squid itself is no different in either position.
>
> The security balance is betweeen whether the rest of the machine
> access methods (including the ICAP servers security "footprint") are
> more/worse secure in either position vs the traffic costs mentioned above.
>
> NP: ICAP servers and particularly the unencrypted TCP connections to
> them are the weakest point, since they have the ability to alter the
> HTTP traffic contents in arbitrary ways. Explicitly not touching the
> traffic content is one of the security hardening aspects of Squid.
>
> Amos
>
>
>
> ------------------------------
>
> Message: 2
> Date: Wed, 31 Dec 2014 11:11:36 +0000
> From: James Harper <james at ejbdigital.com.au>
> To: "squid-users at lists.squid-cache.org"
>     <squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application
>     could not connect
> Message-ID:
>    
<HKNPR04MB1933D74D5F5A53D56ED20C8E85F0 at HKNPR04MB193.apcprd04.prod.outlook.com>
>    
> Content-Type: text/plain; charset="utf-8"
>
>>
>> Probably non-HTTPS protocol being used.
>>
>> As bumping gets more popular we are hearing about a number of services
>> abusing port 443 for non-HTTPS protocols on the false assumption that
>> the TLS layer goes all the way to the origin server without
>> inspection. That has never been a true assumption, CDN frontends have
>> always decrypted.
>>
>
> I've mentioned it before, and it's been pointed out that it probably
doesn't scale, but I wrote a callout helper for this reason and for
better logging.
>
> Basically:
>
> external_acl_type cert_callout concurrency=20 %DST %PORT
/usr/local/squid/libexec/ext_cert_callout_acl
> acl is_ssl external cert_callout IS_SSL
> ssl_bump bump is_ssl
> ssl_bump splice all
>
> The helper connects to the IP:port and tries to obtain the
certificate, and then caches the result (in an sqlite database). If it
can't do so within a fairly short time it returns failure (but keeps
trying a bit longer and caches it for next time). Alternatively if the
IP used to be SSL but is now timing out it returns the previously cached
value. Negative results are cached for an increasing amount of time each
time it fails, on the basis that it probably isn't SSL.
>
> So it's somewhat optimistic - on a slow link or for a slow server a
given IP:port might be spliced the first time when it should be bumped,
but it will learn fairly quickly. And for non-SSL connections that
appear to just hang in response to the request there will be an
additional delay the first time. But otherwise it learns about the
target without requiring admin intervention.
>
> It also returns the name of the cert so it can be logged instead of
the IP (for transparent connections), although that isn't ideal as the
same IP might be used for many services (google/youtube/etc)
>
> I can post it if anyone is interested, although it would require a bit
of work to be completely useful.
>
> James
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 4, Issue 75
> ******************************************

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUo+djAAoJENNXIZxhPexGcEAH/Ap3Vx/czpznQaAAtKoeHK/k
6NXQTJVYxC5FkSV9S4UXGjp+DcWd4bIsIPC0oZ0ZJ7W67d98qC0lP3ciC6rBwPnB
cV9pzA2ewL73dWQJOwd1rtX44ZVvAgA9uDlg0zW7ZDrrefw1ACxgPvD2Ta2EHNsI
QD8FwMSA7I5IGc2jgYeL0uILnWX64BuTUw/r1zIbm6uMaRERjxWOujNGNgu6ToRL
GKOwdxbZIDGBKYo8LmYG1gv5urvVVtZ2ghpZN9iyFrdSmpBNU9wyPc/OssowY0jX
5Qy9qQD5xWlYpsslivS90WzXdgMpd+n0livRpfIXUStTu6r3juTt34awAG9MzF4=
=QCIn
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141231/c9de397b/attachment.htm>

From rafael.akchurin at diladele.com  Wed Dec 31 13:09:44 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 31 Dec 2014 13:09:44 +0000
Subject: [squid-users] Squid Deployment Questions
In-Reply-To: <CAAbi1EuPc9qPTavqw_tJJUh=T-cJwdTHcMrNtu0oMDeoqtKC7Q@mail.gmail.com>
References: <CAAbi1EuPc9qPTavqw_tJJUh=T-cJwdTHcMrNtu0oMDeoqtKC7Q@mail.gmail.com>
Message-ID: <AM3PR04MB450AC03EBD44CE295A456AA8F5F0@AM3PR04MB450.eurprd04.prod.outlook.com>

And if your ICAP server allows it run it on the same host as Squid to minimize connection delays from squid <-> icap. E.g. ours (qlproxy) by default is run on 127.0.0.1.

Best regards,
Rafael

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Evan Blackstone
Sent: Wednesday, December 31, 2014 7:00 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid Deployment Questions

Hey all,
Wondering if I could get some advice on potentially setting up a Squid forward proxy on my network. I'm not a Linux novice by any means, but I'm not experienced in server administration, log review, etc.

We're needing to deploy a simple non-caching, non-peering forward proxy to integrate with an ICAP server for web filtering. My plan is pretty basic...here's my network config:

Internet --> Cisco ASA --> DMZ --> Internal LAN

I've received conflicting advice on whether or not there's any advantage to putting a forward proxy on the DMZ vs. internal LAN. In any case, 'm wanting to deploy an explicit proxy with a single NIC. Workstations will use a PAC file, etc. to point to the proxy.

If the server is on the DMZ, I'd allow 80/443 from the internal LAN to the DMZ, then allow 80/443 from the proxy to outside. I'd also be allowing the proxy to internal LAN for ICAP, syslog, and possibly NTP. The proxy would have a single interface...although it would NAT to outside for internet access, there would be no ports open on the outside interface.

Based on some testing I've done, my squid.conf would be pretty basic...

http_access allow internalnetwork
cache deny internalnetwork
always_direct allow internalnetwork
http_access deny all
etc.

My questions are:

Does it sound like I'm on the right track here? Would the above described configuration be safe? I've read that Squid should listen only on an internal interface? What about when the server only has one?

What level of risk would I be assuming (regular patching included)? Given that I'm relatively new to monitoring Linux servers for security, etc., is this a bad idea? I'm not really sure what to be looking for log-wise in terms of compromise. I have edge devices and monitoring on the perimeter, but I don't really know what to look for on the server itself...

Am I approaching this the wrong way? Should I be looking at putting it on the inside LAN? Would such an approach leave my network vulnerable should the Squid box get owned?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20141231/12e72c95/attachment.htm>

From rafael.akchurin at diladele.com  Wed Dec 31 13:11:08 2014
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 31 Dec 2014 13:11:08 +0000
Subject: [squid-users] Squid 3 SSL bump: Google drive application could
 not connect
In-Reply-To: <HKNPR04MB1933D74D5F5A53D56ED20C8E85F0@HKNPR04MB193.apcprd04.prod.outlook.com>
References: <54A2A4AB.1000003@gmail.com> <54A2AF50.2070103@treenet.co.nz>
 <HKNPR04MB1933D74D5F5A53D56ED20C8E85F0@HKNPR04MB193.apcprd04.prod.outlook.com>
Message-ID: <AM3PR04MB450807CF39B164A9ABB1E7F8F5F0@AM3PR04MB450.eurprd04.prod.outlook.com>

Please James do if it is possible.

Best regards,
Rafael

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of James Harper
Sent: Wednesday, December 31, 2014 12:12 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 3 SSL bump: Google drive application could not connect

> 
> Probably non-HTTPS protocol being used.
> 
> As bumping gets more popular we are hearing about a number of services 
> abusing port 443 for non-HTTPS protocols on the false assumption that 
> the TLS layer goes all the way to the origin server without 
> inspection. That has never been a true assumption, CDN frontends have 
> always decrypted.
> 

I've mentioned it before, and it's been pointed out that it probably doesn't scale, but I wrote a callout helper for this reason and for better logging.

Basically:

external_acl_type cert_callout concurrency=20 %DST %PORT /usr/local/squid/libexec/ext_cert_callout_acl
acl is_ssl external cert_callout IS_SSL
ssl_bump bump is_ssl
ssl_bump splice all

The helper connects to the IP:port and tries to obtain the certificate, and then caches the result (in an sqlite database). If it can't do so within a fairly short time it returns failure (but keeps trying a bit longer and caches it for next time). Alternatively if the IP used to be SSL but is now timing out it returns the previously cached value. Negative results are cached for an increasing amount of time each time it fails, on the basis that it probably isn't SSL.

So it's somewhat optimistic - on a slow link or for a slow server a given IP:port might be spliced the first time when it should be bumped, but it will learn fairly quickly. And for non-SSL connections that appear to just hang in response to the request there will be an additional delay the first time. But otherwise it learns about the target without requiring admin intervention.

It also returns the name of the cert so it can be logged instead of the IP (for transparent connections), although that isn't ideal as the same IP might be used for many services (google/youtube/etc)

I can post it if anyone is interested, although it would require a bit of work to be completely useful.

James

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

