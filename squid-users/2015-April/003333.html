<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] Happy Eyeballs and &quot;connect_timeout&quot; in squid	3.4.12
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Happy%20Eyeballs%20and%20%22connect_timeout%22%20in%20squid%0A%093.4.12&In-Reply-To=%3C55421FD8.3050307%40treenet.co.nz%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003328.html">
   <LINK REL="Next"  HREF="003320.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] Happy Eyeballs and &quot;connect_timeout&quot; in squid	3.4.12</H1>
    <B>Amos Jeffries</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Happy%20Eyeballs%20and%20%22connect_timeout%22%20in%20squid%0A%093.4.12&In-Reply-To=%3C55421FD8.3050307%40treenet.co.nz%3E"
       TITLE="[squid-users] Happy Eyeballs and &quot;connect_timeout&quot; in squid	3.4.12">squid3 at treenet.co.nz
       </A><BR>
    <I>Thu Apr 30 12:28:08 UTC 2015</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="003328.html">[squid-users] Happy Eyeballs and &quot;connect_timeout&quot; in squid	3.4.12
</A></li>
        <LI>Next message (by thread): <A HREF="003320.html">[squid-users] NTLM AUTH: All redirector processes are busy
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3333">[ date ]</a>
              <a href="thread.html#3333">[ thread ]</a>
              <a href="subject.html#3333">[ subject ]</a>
              <a href="author.html#3333">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 30/04/2015 7:05 a.m., Tom Tom wrote:
&gt;<i> Thank you Amos, for this explanation.
</I>&gt;<i> 
</I>&gt;<i> 
</I>&gt;<i> On Wed, Apr 29, 2015 at 3:02 PM, Amos Jeffries wrote:
</I>&gt;&gt;<i> On 29/04/2015 7:38 p.m., Tom Tom wrote:
</I>&gt;&gt;&gt;<i> Hi
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I'm running squid (3.4.12) on a IPv6/IPv4-dual-stack system.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> While accessing the test-site &quot;<A HREF="http://test.rx.td.h.labs.apnic.net">http://test.rx.td.h.labs.apnic.net</A>&quot;, I
</I>&gt;&gt;&gt;<i> encountered a 60s connection-timeout (configurable with
</I>&gt;&gt;&gt;<i> connect_timeout) while squid is making 5 IPv6-connection-attempts
</I>&gt;&gt;&gt;<i> (SYN), before it tries to connect with IPv4 (which is working on the
</I>&gt;&gt;&gt;<i> test-site). I can decrease the &quot;connect_timeout&quot;-value to 1 second.
</I>&gt;&gt;&gt;<i> This behaves in a better &quot;surf&quot;-experience and results in a 1s-timeout
</I>&gt;&gt;&gt;<i> (also only 1 IPv6-SYN) instead of the default 60s timeout.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Why does squid not tries to connect first IPv6 (based on the host's
</I>&gt;&gt;&gt;<i> address preference-policy) and then - in case of a failure - switch to
</I>&gt;&gt;&gt;<i> IPv4 during a 300ms timeout (like current Browsers are doing)?
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Several reasons:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> 1) The default builds and installs do try IPv6 first in accordance with
</I>&gt;&gt;<i> RFC 6540. Check your config for a &quot;dns_v4_first&quot; directive which forces
</I>&gt;&gt;<i> IPv4 to be tried first.
</I>&gt;<i> 
</I>&gt;<i> According to RFC 6555:  &quot;Over time, as most content is available via
</I>&gt;<i> IPv6, the amount of IPv4 traffic will decrease.&quot;. With forcing this
</I>&gt;<i> directive, I reduce the chance for connecting with IPv6 and my
</I>&gt;<i> outbound connections are probably a long time with IPv4. This is maybe
</I>&gt;<i> not the behaviour we want?
</I>
If you want to encourage IPv6 usage let Squid operate at its default
behaviour and fix the issues in the network which make any given request
go particularly worse than in IPv4. Sadly many of these are caused by
external sysadmins choices nowdays either to run with outdated machinery
or to explicitly break IPv6 in the name of disabling it.

As a proponent of IPv6 adoption myself I have written the IPv6
behaviours into Squid to prefer IPv6 over IPv4 whenever possible. Long
before RFC 6540 required it.


&gt;&gt;<i>
</I>&gt;&gt;<i> 2) Squid is not the OS built-in resolver. Any obeying of that policy by
</I>&gt;&gt;<i> Squid is purely arbitrary. The host systems DNS resolver policy does not
</I>&gt;&gt;<i> supposed to affect standalone resolvers such as Squids internal one.
</I>&gt;&gt;<i> Particularly when there are squid.conf directives overriding the
</I>&gt;&gt;<i> resolv.conf behaviour (eg. dns_nameservers).
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> dns_v4_first was a partial implementation added for
</I>&gt;&gt;<i> &lt;<A HREF="http://bugs.squid-cache.org/show_bug.cgi?id=3086">http://bugs.squid-cache.org/show_bug.cgi?id=3086</A>&gt;.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> 3) when performed by middleware such as Squid the &quot;Happy Eyeballs&quot;
</I>&gt;&gt;<i> algorithm is heavily destructive.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> A browser is consuming at minimum 2 network sockets to perform &quot;Happy
</I>&gt;&gt;<i> Eyeballs&quot;.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> At the middlware each of those translates to potentially 3 sockets
</I>&gt;&gt;<i> (total 6 proxy sockets, 2 outgoing server sockets). If the middleware
</I>&gt;&gt;<i> were to perform &quot;Happy Eyeballs&quot; itself that would increase to 4 sockets
</I>&gt;&gt;<i> (total 8 proxy sockets, 4 outgoing server sockets).
</I>&gt;<i> 
</I>&gt;<i> But only in the parallel way (1 x IPv6 and 1 x IPv4)?
</I>
No, multiplexed. Each hop has both IPv4 and IPv6 outbound possibilities
for each individual packet regardless of the inbound type. &quot;Happy
Eyeballs&quot; worst-case is a straight exponential 2^N socket usage at the
server where N is proxy hop distance from client. Best-case occurs when
an admin chooses to disable IPv4 or IPv6 and cuts the exponential growth
from their hop in half.

So the algorithm happening in middleware would actively encourage bad
network practices by sysadmin. Grr :-(

&gt;<i> 
</I>&gt;<i> Tests with the current curl (I know, curl != squid) behaves not in
</I>&gt;<i> doing two similar (parallel) TCP-Connections (1x SYN for IPv6 and 1x
</I>&gt;<i> SYN for IPv4). Instead, curl tries IPv6 first and in case of an
</I>&gt;<i> connection-error, it tries after a few milliseconds with IPv4. This
</I>&gt;<i> way, not a lot of sockets should be consumed. Does this not behave
</I>&gt;<i> like a native IPv4-Stack? Squid would behave like curl, if I would be
</I>&gt;<i> able to change the connect_timeout to milliseconds.
</I>
That sequential operation is already the current behaviour of Squid.
Just with resolution of seconds on the timeout and configurable choice
between ordering of {IPv6,IPv4} or {IPv4,IPv6} as to what gets tried first.

The browser &quot;Happy Eyeballs&quot; algorithm you were talking about /
proposing works quite differenty. All A and AAAA record have DNS queries
generated at once - as those replies happen all listed IPs have TCP SYN
packets generated at once and all of them are sent. It ends when one TCP
SYN packet gets a success response. End of spec.

That performance numbers that come out of it are great ... for a single
point-to-point connection.
It looks less wonderful and more like a DoS attack in all other cases,
especially when taking server resource side-effects into account.

&gt;<i> 
</I>&gt;<i> Is there a well-known restriction (which I don't now, actually), by
</I>&gt;<i> setting the connect_timeout to 1 second for all those IPv6-Adresses,
</I>&gt;<i> which aren't connectable and for which the IPv4-Stack should be used
</I>&gt;<i> after 1s timeout? Is this a practicable way?
</I>
There are two restrictions:

 1) the OS unix time (time_t) has a minimum resolution of 1 second.
Anything using more detailed time resolution is paying (in mutiple ms of
extra latency) for expensive syscalls to find out what the nanosecond
clocks in the system are.

 2) the event loop checking for what timeouts have occured cycles once
per second. The guarantee provided by Squid is that a timeout action
will have *at least* the requested N seconds before it triggers.

Also, to a lesser degree translating between timescales for this
directive with all the other timouts it interacts with would be a
performance drag and annoying to code.

Amos


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="003328.html">[squid-users] Happy Eyeballs and &quot;connect_timeout&quot; in squid	3.4.12
</A></li>
	<LI>Next message (by thread): <A HREF="003320.html">[squid-users] NTLM AUTH: All redirector processes are busy
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3333">[ date ]</a>
              <a href="thread.html#3333">[ thread ]</a>
              <a href="subject.html#3333">[ subject ]</a>
              <a href="author.html#3333">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
