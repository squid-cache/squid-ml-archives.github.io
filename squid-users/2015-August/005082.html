<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] How to have squid as safe as (e.g.) firefox?
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20How%20to%20have%20squid%20as%20safe%20as%20%28e.g.%29%20firefox%3F&In-Reply-To=%3C830832878.7684678.1439998999365.JavaMail.yahoo%40mail.yahoo.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="005001.html">
   <LINK REL="Next"  HREF="005086.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] How to have squid as safe as (e.g.) firefox?</H1>
    <B>Jeremie Rafin</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20How%20to%20have%20squid%20as%20safe%20as%20%28e.g.%29%20firefox%3F&In-Reply-To=%3C830832878.7684678.1439998999365.JavaMail.yahoo%40mail.yahoo.com%3E"
       TITLE="[squid-users] How to have squid as safe as (e.g.) firefox?">rafinjer-squid at yahoo.fr
       </A><BR>
    <I>Wed Aug 19 15:43:19 UTC 2015</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="005001.html">[squid-users] How to have squid as safe as (e.g.) firefox?
</A></li>
        <LI>Next message (by thread): <A HREF="005086.html">[squid-users] How to have squid as safe as (e.g.) firefox?
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#5082">[ date ]</a>
              <a href="thread.html#5082">[ thread ]</a>
              <a href="subject.html#5082">[ subject ]</a>
              <a href="author.html#5082">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Amos and Alex,

Thanks a lot for all your advises. I appreciate your helpful comments! :))

Nevertheless, all is not cristal clear for me. I have setup a sandbox (virtual box with squid 3.5.7 on debian 7.6; for transparent proxy, I have setup NAT iptables and IP route to run client through squid; my client browser is configured with squid certificate) and have tried many configurations. I am still a little bit lost...

Let me sum-up my needs, first. In a family context, I would like:
-a) to black/white list accesses (with e.g. squidguard);
-b) to check for content (with e.g. diladele or e2guardian);
-c) to do that for https (because more and more sites cipher links, like google);
-d) not to check for content for a given (spliced) sites (like banks);
-e) not to degrade security; for instance, revoked CA must not succeed in access, even if bumped;
-f) [nice to have]: to do this in a transparent proxy way; but explicit proxy would also be ok, if required.

Second, as per your advises, and some searches, I have setup this configuration (from the default one, unchanged; no third party, yet):

#

# Black list: meteofrance (http) and google (https)
acl blacklist dstdomain .meteofrance.com
acl sslblacklist ssl::server_name .google.fr
http_access deny blacklist
http_access deny sslblacklist

# Non bumped list (only spliced): wellsfargo
acl splicelist ssl::server_name .wellsfargo.com

# SSL configuration
acl step1 at_step SslBump1
acl step2 at_step SslBump2
ssl_bump peek step1 all
ssl_bump splice step2 splicelist
ssl_bump bump all

# Web access
http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
http_port 3126 intercept
https_port 3127 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
sslcrtd_program /usr/local/squid-3.5/lib/squid/ssl_crtd -s /var/spool/squid3_ssldb -M 4MB

#

With this config file, I am able to satisfy my requirements a, b (ready for), c, d and f (I mean a, b, c and d are ok in transparent and explicit modes). But e fails: <A HREF="https://revoked.grc.com/">https://revoked.grc.com/</A> is not rejected.

So, even if I think my configuration is much cleaner thanks to you (you will probably comment), I have still the same feeling of degrading the security when bumping. Hence, my main question remains (title of the thread): how to get (at least) revocation working (requirement &quot;e&quot;)?



During my investigation, I have met some other difficulties (these points are less important than above main question, but are still obscur for me):

-&quot;peek&quot;/&quot;splice&quot;/&quot;bump&quot;: nothing is logged in access.log (I tried a &quot;debug_options ALL,9&quot;; no success); I have read in some post that nothing is logged yet, but I double check: is it planed (or done) to get log for SSL decision?

-with this SSL configuration:
#
...

# SSL configuration
ssl_bump splice splicelist
ssl_bump bump all

...
#
 -all works but **only in explicit proxy**; in transparent, the HTTPS are failing (no certification???); if I add a &quot;ssl_bump peek all&quot; before the &quot;bump&quot; rule, all https accesses are peeked (poken?) or spliced; nothing is bumped (in explicit and transparent); is it normal?
 -furthermore, google is not blacklisted **only** in transparent mode! Why?
 -the wiki (<A HREF="http://wiki.squid-cache.org/Features/SslPeekAndSplice">http://wiki.squid-cache.org/Features/SslPeekAndSplice</A>) does not mention this need of step1/step2 (like first configuration) for having splice/bump decision working well in transparent mode, does it?

-I noticed a quite similar unexpected behavior for &quot;ssl_bump terminate&quot; without &quot;step1/step2&quot;; for instance, a simple &quot;ssl_bump terminate all&quot; gives:
 -in transparent mode: no effet (no bump, no black list), all is spliced (or poken);
 -in explicit mode: google is rejected but every other https works (in a non bumped way);
Why?
Note that &quot;terminate&quot; behaves logically (i.e. as I would expect) with a preceeding &quot;acl step1 at_step SslBump1/acl step2 at_step SslBump2/ssl_bump peek step1 all&quot;. With &quot;all&quot; or, for instance, with &quot;sslblacklist&quot;.



Thanks for any answer/help!
J&#233;r&#233;mie





P.S.: my comments for your answers below.
&gt;<i>
</I>&gt;<i>Technically a clean install of Squid with default options is more secure
</I>&gt;<i>than any browser you will be able to find.
</I>&gt;<i>
</I>&gt;<i>Because it comes configured for forward-proxy. Which does not touch the
</I>&gt;<i>TLS traffic in any way but relays CONNECT tunnels. Inside the tunnel the
</I>&gt;<i>browser&lt;-&gt;server security is in operating control, which makes the Squid
</I>&gt;<i>relay equally secure as whatever the browser and server would agree to
</I>&gt;<i>without Squid.
</I>&gt;<i>
</I>&gt;<i>Additionally, Squid enforces that HTTPS tunnels only go to port 443.
</I>&gt;<i>Which is something the browsers do not do. Making Squid better in this
</I>&gt;<i>one way on top of all the things the browsers do inside their tunnel.
</I>&gt;<i>
</I>

For &quot;splicing&quot;, OK; but I still have a doubt with bumping since I fail in revoking the test page.


&gt;<i>
</I>&gt;<i>Secondly;
</I>&gt;<i>
</I>&gt;<i>the feeling of security you have with browser is a lie. Pure &quot;security
</I>&gt;<i>theatre&quot;, done so well that you and billions of others can't even see it.
</I>&gt;<i>
</I>&gt;<i>What you are doing is trusting a very large set of nearly a thousand CA
</I>&gt;<i>entities. Including most of those governments with bad reputations now
</I>&gt;<i>for surveillance, and a lot of corporations with agendas of their own.
</I>&gt;<i>For all sorts of reasons which you have no knowledge or control over.
</I>&gt;<i>Yes, someone has vetted that their published intentions were good to get
</I>&gt;<i>them into the list, but it was not you. For you and everyone else it is
</I>&gt;<i>almost blind trust.
</I>&gt;<i>
</I>

This is my next goal: be able to manage the CA by myself in order to increase security for my clients surfing on internet. But this is another story: in a first time, I would like to reach same level of security as without squid. No more, no less. Even if I agree this is not perfect, this is a must, as I can not give better, so far.


&gt;<i>
</I>&gt;<i>At any time *one*, just one, of them could sign a faked certificate.
</I>&gt;<i>When that happens no user will be able to tell the difference without
</I>&gt;<i>detailed digging down into the browser cert information.
</I>&gt;<i>
</I>&gt;<i>The only reason these things come to light at all is when the ability is
</I>&gt;<i>abused in obvious user-visible ways for dictatorial censorship or
</I>&gt;<i>malware attacks. Or the few vigilant an knowledgable people actively
</I>&gt;<i>seeking it out catch it in the act. Its not the CA action that was seen
</I>&gt;<i>first, but the abuse of power it allowed.
</I>&gt;<i>
</I>&gt;<i>Thankfully the repercussions of being wiped from the global CA list are
</I>&gt;<i>severe enough to prevent power abuse in amost cases. But there have been
</I>&gt;<i>some exceptions even so.
</I>&gt;<i>
</I>&gt;<i>So security threatre. Its been working so far, but only just.
</I>&gt;<i>
</I>

I may have the same feeling than you; but maybe this discussion is out of scope (even if I would appreciate to discuss longer)? Again, before improving my (our) condition of simple browser people, I would like not to degrade it...


&gt;<i>You have also configured &quot;sslproxy_cert_error deny all&quot; which forces
</I>&gt;<i>Squid to accept and ignore all possible origin server certificate
</I>&gt;<i>errors. Including revocation.
</I>&gt;<i>
</I>&gt;<i>I hope you can see/understand the result.
</I>&gt;<i>
</I>

According to Alex, I am not wrong. Anyway, with or without, with deny or allow, the revoked test page still fails, as soon as it is bumped...


&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> -do you know any implementation of NSS library (the security library
</I>&gt;<i>of firefox, probably safer than openssl) for certificate checking helper
</I>&gt;<i>(cf. sslcrtvalidator_program)?
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i>No. Just the OpenSSL one we provide so far.
</I>&gt;<i>
</I>&gt;<i>I'm still working on getting library-agnostic TLS support rolled into
</I>&gt;<i>Squid. But the main effort has been on the squid binary, not the helpers
</I>&gt;<i>yet.
</I>&gt;<i>
</I>

OK. As Alex says it, and I definitly agree with him, maintening such a tool is out of my capability and/or time availability. I have not been able to find any project on that topic, so I give this idea up.


&gt;&gt;<i> # SSL Options - to mimic firefox; some of keys are weaks but some of my favorite websites need them :(
</I>&gt;&gt;<i> sslproxy_options NO_SSLv2,No_Compression
</I>&gt;&gt;<i> sslproxy_cipher ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:ECDHE-RSA-RC4-SHA:ECDHE-ECDSA-AES256-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-ECDSA-RC4-SHA:DHE-RSA-AES256-SHA:AES256-SHA:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA:AES128-SHA:DES-CBC3-SHA:RC4-SHA:RC4-MD5:!aNULL:!eNULL:!EXPORT:!DSS:!DES:!3DES:!PSK
</I>&gt;<i>
</I>&gt;<i>Careful. Squid will do what you tell it to.
</I>&gt;<i>
</I>&gt;<i>In order for this to be more secure than the browser, you will have to
</I>&gt;<i>ensure that each of these things you are allowing actually are more
</I>&gt;<i>secure than what it does. And that you are not allowing anything that
</I>&gt;<i>the browser decides is bad.
</I>&gt;<i>
</I>&gt;<i>
</I>

Thanks for the advise. Improving this is another next step for me.


&gt;&gt;<i> sslproxy_cert_error deny all
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> # Splice access lists
</I>&gt;&gt;<i> acl splice_client src 192.168.2.30
</I>&gt;&gt;<i> acl splice_domain dstdomain .paypal.com
</I>&gt;&gt;<i> acl splice_dst dst 66.211.169.66 66.211.169.3
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> # HTTPS access
</I>&gt;<i>
</I>&gt;<i>Nope, &quot;TLS access&quot; is better description.
</I>&gt;<i>
</I>&gt;<i>HTTPS is two protocol layers; a HTTP layer over a TLS layer (like
</I>&gt;<i>&quot;TCP/IP&quot; is actually TCP over IP layer).
</I>&gt;<i>
</I>&gt;<i>ssl_bump directive controls only the TLS later actions. The http_access
</I>&gt;<i>rules later deal with the decrypted HTTP layer - but only if it was
</I>&gt;<i>allowed to be decrypted (&quot;bump&quot; action) by these rules.
</I>&gt;<i>
</I>

Thanks for this reminder :)


&gt;<i>
</I>&gt;&gt;<i> ssl_bump splice splice_client
</I>&gt;<i>
</I>&gt;<i>Splice is equivalent to blind tunnelling, but can be done after Squid
</I>&gt;<i>has played with the certififcates a bit (using read-only accesses).
</I>&gt;<i>
</I>&gt;<i>Since splice_client is based only on src-IP and nothing TLS layer
</I>&gt;<i>related it is better to use &quot;none&quot; instead of splice action on the above
</I>&gt;<i>rule. The true secure blind-tunnel will then be done.
</I>&gt;<i>
</I>

This makes sens; thanks.


&gt;<i>
</I>&gt;&gt;<i> ssl_bump splice splice_domain
</I>&gt;<i>
</I>&gt;<i>This is a good example of how dstdomain fails. You are deciding whether
</I>&gt;<i>to splice instead of interpret the HTTP message. Based on details inside
</I>&gt;<i>that HTTP message which has not yet been interpreted.
</I>&gt;<i>
</I>&gt;<i>Make sure you are using the latest 3.5 release, and use the
</I>&gt;<i>&quot;ssl::server_name&quot; insted of dstdomain in the ACL definition.
</I>&gt;<i>
</I>

Your comment is really helpful! Maybe the wiki (<A HREF="http://wiki.squid-cache.org/Features/SslPeekAndSplice">http://wiki.squid-cache.org/Features/SslPeekAndSplice</A>) should insist on this basis. I am not the only one doing this mistake...


&gt;<i>
</I>&gt;&gt;<i> ssl_bump splice splice_dst
</I>&gt;<i>
</I>&gt;&gt;<i> ssl_bump server-first all
</I>&gt;<i>
</I>&gt;<i>DO NOT mix the old and new config styles together. server-first requires
</I>&gt;<i>doing things like emitting a fake server cert to the client before
</I>&gt;<i>reading soem of the client handshake details the splicing needs. But you
</I>&gt;<i>have already spliced a bunch of transactions from the earlier rules.
</I>&gt;<i>
</I>

Once again, maybe this basis should be explained in the wiki.
If I remember correclty, I was motivated by the effect in log (cache). I have not checked, but I remember that &quot;server-first&quot; gives more logs than &quot;bump&quot;, hence I was more confident. Definitly, ssl decisions should be logged.


&gt;&gt;<i>
</I>&gt;&gt;<i> # Hide PROXY
</I>&gt;&gt;<i> via off
</I>&gt;&gt;<i> forwarded_for delete
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i>Does *not* hide the proxy.
</I>&gt;<i>
</I>&gt;<i>Hides the *client* by actively &quot;shouting&quot; the proxy details out to the
</I>&gt;<i>world in protocol places where the client details would normally go.
</I>&gt;<i>
</I>

This is another interesting topic -maybe not the right place here.
The goal is to get video streaming: some web sites refuse to provide video if a proxy is detected (because of broadcast laws); to debug I use these sites (streaming web site is very slow): 
 <A HREF="http://whatismyipaddress.com/proxy-check">http://whatismyipaddress.com/proxy-check</A>
 <A HREF="http://proxydetect.com/">http://proxydetect.com/</A>


The only configuration I have found to hide the proxy (and to get the video streaming) was the above one. If you have a better configuration, I would be curious to know it: all of the configurations I found on internet was failing (and I was not able to find something else that works).
Thanks :)

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="005001.html">[squid-users] How to have squid as safe as (e.g.) firefox?
</A></li>
	<LI>Next message (by thread): <A HREF="005086.html">[squid-users] How to have squid as safe as (e.g.) firefox?
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#5082">[ date ]</a>
              <a href="thread.html#5082">[ thread ]</a>
              <a href="subject.html#5082">[ subject ]</a>
              <a href="author.html#5082">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
