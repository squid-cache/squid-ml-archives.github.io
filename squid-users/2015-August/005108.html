<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] refresh_pattern and same objects
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20refresh_pattern%20and%20same%20objects&In-Reply-To=%3C1440146203116-4672802.post%40n4.nabble.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="005101.html">
   <LINK REL="Next"  HREF="005110.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] refresh_pattern and same objects</H1>
    <B>Stakres</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20refresh_pattern%20and%20same%20objects&In-Reply-To=%3C1440146203116-4672802.post%40n4.nabble.com%3E"
       TITLE="[squid-users] refresh_pattern and same objects">vdoctor at neuf.fr
       </A><BR>
    <I>Fri Aug 21 08:36:43 UTC 2015</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="005101.html">[squid-users] refresh_pattern and same objects
</A></li>
        <LI>Next message (by thread): <A HREF="005110.html">[squid-users] refresh_pattern and same objects
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#5108">[ date ]</a>
              <a href="thread.html#5108">[ thread ]</a>
              <a href="subject.html#5108">[ subject ]</a>
              <a href="author.html#5108">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi Amos,
Is that possible to have a dedicated option with the Squid to keep objects
in the cache if they're regulary used even if the time is expired ?
Cleaning small expired files (&lt;16kb) is not a problem but we must keep big
files into the cache if often used.
There are many &quot;small&quot; ISPs with 2, 4 or 8Mbps bandwidth and big files are a
problem if they've to download a fresh copy every month (if max-day 1
month).
Doing a local copy is not a right way here because too many possible big
objects and issues to manage them, we should have Squid able to do that.

I'm thinking something like that:
save_big_file on/off
save_big_file_min_size 128 MB
save_big_file_max_time 1 years

Would it be something you could implement with Squid ?
I'm sure it would work so fine 

bye Fred



--
View this message in context: <A HREF="http://squid-web-proxy-cache.1019090.n4.nabble.com/refresh-pattern-and-same-objects-tp4672792p4672802.html">http://squid-web-proxy-cache.1019090.n4.nabble.com/refresh-pattern-and-same-objects-tp4672792p4672802.html</A>
Sent from the Squid - Users mailing list archive at Nabble.com.

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="005101.html">[squid-users] refresh_pattern and same objects
</A></li>
	<LI>Next message (by thread): <A HREF="005110.html">[squid-users] refresh_pattern and same objects
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#5108">[ date ]</a>
              <a href="thread.html#5108">[ thread ]</a>
              <a href="subject.html#5108">[ subject ]</a>
              <a href="author.html#5108">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
