From bart.spedden at 3sharecorp.com  Tue Dec  1 00:01:44 2015
From: bart.spedden at 3sharecorp.com (Bart Spedden)
Date: Mon, 30 Nov 2015 17:01:44 -0700
Subject: [squid-users] 2 way SSL on a non standard SSL Port
In-Reply-To: <CAMxDymf8xXhm1p7TXy6XhZ98--XmtmuqhQvaFY9RX2NFmfJOWw@mail.gmail.com>
References: <CAMxDymdY6ohJ+V-x=Cfh=h3daHOYVK+y4=QzUvwF2Umb6a0Oow@mail.gmail.com>
 <565C8AF4.9040207@ngtech.co.il>
 <CAMxDymd5OQyqSTsYB2qCUqf04kTWpnEV4mve5NjnPrzXy8P4sw@mail.gmail.com>
 <201511301859.24482.Antony.Stone@squid.open.source.it>
 <CAMxDymf8xXhm1p7TXy6XhZ98--XmtmuqhQvaFY9RX2NFmfJOWw@mail.gmail.com>
Message-ID: <CAMxDymc-0ntnAqUfJXjdbGYjn80AN1L14dRLA=fKmYWWKp7Fhw@mail.gmail.com>

In the cache.log I have found the following:

CONNECT tv1var.merchantlink-lab.com:8184 HTTP/1.1^M

User-Agent: Java/1.8.0_05^M

Host: tv1var.merchantlink-lab.com:8184^M

Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2^M

Proxy-Connection: keep-alive^M

^M


----------

2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(741)
clientAccessCheckDone: The request CONNECT tv1var.merchantlink-lab.com:8184
is ALLOWED; last ACL checked: localnet

2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(717)
clientAccessCheck2: No adapted_http_access configuration. default: ALLOW

2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(741)
clientAccessCheckDone: The request CONNECT tv1var.merchantlink-lab.com:8184
is ALLOWED; last ACL checked: localnet

2015/11/30 17:18:47.517 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
Find IP destination for: tv1var.merchantlink-lab.com:8184' via
tv1var.merchantlink-lab.com

2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for 'tv1var.merchantlink-lab.com:8184'

2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(281) peerSelectDnsPaths:
  always_direct = DENIED

2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(282)
peerSelectDnsPaths:    never_direct = DENIED

2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=
104.153.8.184:8184 flags=1

2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(295)
peerSelectDnsPaths:        timedout = 0

2015/11/30 17:18:47.534 kid1| 4,2| errorpage.cc(1262) BuildContent: No
existing error page language negotiated for ERR_CONNECT_FAIL. Using default
error file.

2015/11/30 17:18:47.534 kid1| 33,2| client_side.cc(815) swanSong: local=
10.1.0.57:3128 remote=192.168.55.103:56395 flags=1

2015/11/30 17:18:47.689 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New
connection on FD 11

2015/11/30 17:18:47.689 kid1| 5,2| TcpAcceptor.cc(295) acceptNext:
connection on local=[::]:3128 remote=[::] FD 11 flags=9

2015/11/30 17:18:47.695 kid1| 11,2| client_side.cc(2345) parseHttpRequest:
HTTP Client local=10.1.0.57:3128 remote=192.168.55.103:56396 FD 10 flags=1

2015/11/30 17:18:47.695 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client REQUEST:

versus

a successful call to google:

User-Agent: Java/1.8.0_05^M

Host: www.google.com^M

Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2^M

Proxy-Connection: keep-alive^M

^M


----------

2015/11/30 17:18:47.849 kid1| 85,2| client_side_request.cc(741)
clientAccessCheckDone: The request CONNECT www.google.com:443 is ALLOWED;
last ACL checked: localnet

2015/11/30 17:18:47.849 kid1| 85,2| client_side_request.cc(717)
clientAccessCheck2: No adapted_http_access configuration. default: ALLOW

2015/11/30 17:18:47.849 kid1| 85,2| client_side_request.cc(741)
clientAccessCheckDone: The request CONNECT www.google.com:443 is ALLOWED;
last ACL checked: localnet

2015/11/30 17:18:47.849 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
Find IP destination for: www.google.com:443' via www.google.com

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for 'www.google.com:443'

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(281) peerSelectDnsPaths:
  always_direct = DENIED

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(282)
peerSelectDnsPaths:    never_direct = DENIED

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=[::]
remote=[2607:f8b0:400d:c06::63]:443 flags=1

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=74.125.22.99:443
flags=1

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=74.125.22.105:443
flags=1

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=74.125.22.106:443
flags=1

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=74.125.22.103:443
flags=1

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=74.125.22.104:443
flags=1

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=74.125.22.147:443
flags=1

2015/11/30 17:18:47.853 kid1| 44,2| peer_select.cc(295)
peerSelectDnsPaths:        timedout = 0

2015/11/30 17:18:48.008 kid1| 33,2| client_side.cc(815) swanSong: local=
10.1.0.57:3128 remote=192.168.55.103:56396 flags=1

2015/11/30 17:18:48.196 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New
connection on FD 11

2015/11/30 17:18:48.196 kid1| 5,2| TcpAcceptor.cc(295) acceptNext:
connection on local=[::]:3128 remote=[::] FD 11 flags=9

2015/11/30 17:18:48.196 kid1| 11,2| client_side.cc(2345) parseHttpRequest:
HTTP Client local=10.1.0.57:3128 remote=10.1.0.43:42281 FD 10 flags=1

2015/11/30 17:18:48.196 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client REQUEST:




On Mon, Nov 30, 2015 at 4:37 PM, Bart Spedden <bart.spedden at 3sharecorp.com>
wrote:

> Good idea Anthony.
>
> Here's what I found.
>
> On the squid server when I use the following command to monitor a call to
> https://www.google.com
>
> tcpdump -i eth0 -vv 'port 443'
>
> I get the following:
>
> 17:32:56.373772 IP (tos 0x0, ttl 64, id 33502, offset 0, flags [DF], proto
> TCP (6), length 60)
>
>     d6uxpci.lq.com.46591 > qh-in-f104.1e100.net.https: Flags [S], cksum
> 0x62f0 (correct), seq 3198653455, win 14600, options [mss 1460,sackOK,TS
> val 530978513 ecr 0,nop,wscale 7], length 0
>
> 17:32:56.390214 IP (tos 0x0, ttl 42, id 42485, offset 0, flags [none],
> proto TCP (6), length 60)
>
>     qh-in-f104.1e100.net.https > d6uxpci.lq.com.46591: Flags [S.], cksum
> 0x40d0 (correct), seq 558417168, ack 3198653456, win 42540, options [mss
> 1380,nop,nop,TS val 953915655 ecr 530978513,nop,wscale 7], length 0
>
> 17:32:56.390423 IP (tos 0x0, ttl 64, id 33503, offset 0, flags [DF], proto
> TCP (6), length 52)
>
>     d6uxpci.lq.com.46591 > qh-in-f104.1e100.net.https: Flags [.], cksum
> 0x11f5 (correct), seq 1, ack 1, win 115, options [nop,nop,TS val 530978529
> ecr 953915655], length 0
>
> 17:32:56.605977 IP (tos 0x0, ttl 64, id 33504, offset 0, flags [DF], proto
> TCP (6), length 329)
>
>     d6uxpci.lq.com.46591 > qh-in-f104.1e100.net.https: Flags [P.], cksum
> 0x6c5a (incorrect -> 0xc57a), seq 1:278, ack 1, win 115, options
> [nop,nop,TS val 530978745 ecr 953915655], length 277
>
> 17:32:56.622191 IP (tos 0x0, ttl 42, id 42578, offset 0, flags [none],
> proto TCP (6), length 52)
>
>     qh-in-f104.1e100.net.https > d6uxpci.lq.com.46591: Flags [.], cksum
> 0x0e3e (correct), seq 1, ack 278, win 341, options [nop,nop,TS val
> 953915887 ecr 530978745], length 0
>
> but when I monitor on the non-stand https port (8184) that I'm trying to
> connect to I do not see any traffic at all.  So this leads me to believe
> that squid is not actually trying to make the call on the client's behalf.
>
> So I'm feeling a bit lost.
>
> I've upgraded to 3.5.11.
>
> The only change I made to the default /etc/squid/squid.conf is to add the
> two non stand https ports that I need to connect to via:
>
> acl SSL_ports port 443 8184 8185
>
> Is there anyway to get more logging out of squid?  I tried adding
> debug_option ALL to the squid.conf but didn't see any more logging.
>
> On Mon, Nov 30, 2015 at 10:59 AM, Antony Stone <
> Antony.Stone at squid.open.source.it> wrote:
>
>> On Monday 30 November 2015 at 18:53:54, Bart Spedden wrote:
>>
>> > I can successfully connect as long as I don't use squid for either 1
>> way or
>> > 2 way TLS connections. I've also successfully connect via curl. So, I
>> feel
>> > like the site's certs are working well. I could be totally off base here
>> > but my interpretation of the the 503 (service unavailable) is that
>> squid is
>> > timing out on tls handshake? But what is weird is that when using squid
>> I
>> > can successfully connect to google using https. So, that is what makes
>> me
>> > wonder if it has something to do with the non-standard https port?
>>
>> If it's a timeout, you should be able to see this with a standard
>> wireshark /
>> tcpdump packet capture (no SSL inspection necessary) on your
>> external-facing
>> router (or anywhere else which is a common path both when going direct
>> from
>> the client, and via Squid).
>>
>> Comparing the two (even though you can't decode the content of the
>> packets)
>> may well give a clue as to what's going on differently between the two
>> types of
>> connection.
>>
>>
>> Antony.
>>
>> --
>> Users don't know what they want until they see what they get.
>>
>>                                                    Please reply to the
>> list;
>>                                                          please *don't*
>> CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
>
> --
> Bart Spedden  |  Senior Developer
> +1.720.210.7041  |
> *bart.spedden at 3sharecorp.com <bart.spedden at 3sharecorp.com>*
> 3 | S H A R E  |  Adobe Digital Marketing Experts  |  An Adobe?  Business
> Plus Level Solution PartnerConsulting  |  Training  |  Remote Operations
> Management
> <http://www.3sharecorp.com/en/services/rom.html>
> <http://www.3sharecorp.com/en/services/rom.html>
> <http://www.3sharecorp.com/en/services/rom.html>
>



-- 
Bart Spedden  |  Senior Developer
+1.720.210.7041  |
*bart.spedden at 3sharecorp.com <bart.spedden at 3sharecorp.com>*
3 | S H A R E  |  Adobe Digital Marketing Experts  |  An Adobe?  Business
Plus Level Solution PartnerConsulting  |  Training  |  Remote Operations
Management
<http://www.3sharecorp.com/en/services/rom.html>
<http://www.3sharecorp.com/en/services/rom.html>
<http://www.3sharecorp.com/en/services/rom.html>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151130/75013a9d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rom-email-sig4_600x100.png
Type: image/png
Size: 16361 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151130/75013a9d/attachment.png>

From fengsheng.10 at gmail.com  Tue Dec  1 01:01:09 2015
From: fengsheng.10 at gmail.com (=?UTF-8?B?6aOO5aOw?=)
Date: Tue, 1 Dec 2015 09:01:09 +0800
Subject: [squid-users] Squid memory leak on ubuntu 14.04
In-Reply-To: <565C0EFE.40904@treenet.co.nz>
References: <CAJGZ0h4bmkcMF7V6WGsfh4uLB-by27t8esB0SnRjudFPVCTt9g@mail.gmail.com>
 <5658838F.7050707@urlfilterdb.com>
 <CAJGZ0h5s9k7txGMTN1tP4wdhKvkb=z_kuK8E5t5jwBpgKj8pUg@mail.gmail.com>
 <565BC47E.6070408@treenet.co.nz>
 <CAJGZ0h4AWgyHbwkujCiUpRPf8AbhegpdxaHzRVNuOCasd-Ho0w@mail.gmail.com>
 <565C0EFE.40904@treenet.co.nz>
Message-ID: <CAJGZ0h6oTCu2OJqk8u-+X4eaeDiHyawg76xJPskjG=tfv-CESA@mail.gmail.com>

Hi

Finally, we found the root cause, it is kernel issue with specific version
on ubuntu 14.04.

We prepared new environment for testing, 3.3.8?3.5.11?2.7 on ubuntu 12.04
and 14.04.

3.3.8?3.5.11 on ubuntu 12.04 is ok
2.7 on ubuntu 14.04 is ok

3.3.8?3.5.11 on ubuntu 14.04 is abnormal.


I found this
https://bugs.launchpad.net/ubuntu/+source/linux-meta-lts-trusty/+bug/1516738

and I downgrade kernel version to 3.13.0-57 on ubuntu 14.04, memory usage
is normal now.

I don't know how was it introduced into kernel on ubuntu 14.04, but it is
really works for me.

Thanks for you help .





2015-11-30 16:55 GMT+08:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 30/11/2015 9:31 p.m., ?? wrote:
> > We did not enable squid cache, so I think memory is ok for our case, and
> we
> > run squid servers (without cache, without cache cluster, just as forward
> > proxy) more than 100 servers more than 1 years in AWS serveral regions
> with
> > EC2 c3.xlarge on ubuntu 12.04. It was always running well.
> >
> > Just after upgrade ubuntu 14.04, we found the memory usage increased.
> >
> > Server Spec: AWS EC2 c3.xlarge (4 Cores, 7.5GB Memory, 2 x 40 GB SSD)
> >
> > Before upgrade:
> >
> > 12.04:
> > Memory usage is always less than 50% (3.5GB), will increase or decrease
> > because traffic changes
> > CPU is very low, same as Disk IO, B/W (In or Out) is 500Mb/s at most, is
> > around 200Mb/s most of time.
> >
> > 14:04
> > Memory usage is about 80-90 % (nearly 7GB), will increase , but it
> decrease
> > very slow, and always keeping more than 50% (3.5GB),
> > CPU is very low, same as Disk IO, B/W (In or Out) is 500Mb/s at most, is
> > around 200Mb/s most of time.
> >
> > I tested with squid-3.3.8 (ubuntu offical packages), and squid-3.5.11 on
> > 12.04 and 14.04, I think it is most likely ubuntu related issue ? because
> > same version, same configs, but different OS versions.
>
> Most likely. Though a whole OS of difference has many moving parts. By
> keeping Squid the same you have eliminated it specifically as the cause.
> But all the libraries it uses will be different in each OS.
>
> If there was a 32-bit to 64-bit change in the hardware or memory
> allocation system you could also see this same change.
>
> Amos
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151201/c3589236/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec  1 02:08:31 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Dec 2015 15:08:31 +1300
Subject: [squid-users] 2 way SSL on a non standard SSL Port
In-Reply-To: <CAMxDymc-0ntnAqUfJXjdbGYjn80AN1L14dRLA=fKmYWWKp7Fhw@mail.gmail.com>
References: <CAMxDymdY6ohJ+V-x=Cfh=h3daHOYVK+y4=QzUvwF2Umb6a0Oow@mail.gmail.com>
 <565C8AF4.9040207@ngtech.co.il>
 <CAMxDymd5OQyqSTsYB2qCUqf04kTWpnEV4mve5NjnPrzXy8P4sw@mail.gmail.com>
 <201511301859.24482.Antony.Stone@squid.open.source.it>
 <CAMxDymf8xXhm1p7TXy6XhZ98--XmtmuqhQvaFY9RX2NFmfJOWw@mail.gmail.com>
 <CAMxDymc-0ntnAqUfJXjdbGYjn80AN1L14dRLA=fKmYWWKp7Fhw@mail.gmail.com>
Message-ID: <565D011F.9040402@treenet.co.nz>

On 1/12/2015 1:01 p.m., Bart Spedden wrote:
> In the cache.log I have found the following:
> 
> CONNECT tv1var.merchantlink-lab.com:8184 HTTP/1.1^M
> 
> User-Agent: Java/1.8.0_05^M
> 
> Host: tv1var.merchantlink-lab.com:8184^M
> 
> Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2^M
> 
> Proxy-Connection: keep-alive^M
> 
> ^M
> 
> 
> ----------
> 
> 2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(741)
> clientAccessCheckDone: The request CONNECT tv1var.merchantlink-lab.com:8184
> is ALLOWED; last ACL checked: localnet
> 
> 2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(717)
> clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
> 
> 2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(741)
> clientAccessCheckDone: The request CONNECT tv1var.merchantlink-lab.com:8184
> is ALLOWED; last ACL checked: localnet
> 
> 2015/11/30 17:18:47.517 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
> Find IP destination for: tv1var.merchantlink-lab.com:8184' via
> tv1var.merchantlink-lab.com
> 
> 2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
> Found sources for 'tv1var.merchantlink-lab.com:8184'
>
<snip>
> 
> 2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(286)
> peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=
> 104.153.8.184:8184 flags=1

So this one server destination has been found, and will be tried.

> 
> 2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(295)
> peerSelectDnsPaths:        timedout = 0
> 

But the TCP connect failed:

> 2015/11/30 17:18:47.534 kid1| 4,2| errorpage.cc(1262) BuildContent: No
> existing error page language negotiated for ERR_CONNECT_FAIL. Using default
> error file.
> 


At this point I suspect some external access crontol, such as a firewall
is also blocking that unusual port.

Amos



From squid3 at treenet.co.nz  Tue Dec  1 02:14:17 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Dec 2015 15:14:17 +1300
Subject: [squid-users] Squid 3.4.8 Authenticacion Ldap AD windows server
 2003
In-Reply-To: <565CC3A5.9040005@centis.edu.cu>
References: <565CC3A5.9040005@centis.edu.cu>
Message-ID: <565D0279.7000103@treenet.co.nz>

On 1/12/2015 10:46 a.m., Rafael Maleta Fdez wrote:
> Hello everyone
> I need to authenticate my squid against a Windows 2003 Active Directory,
> but queiro done through LDAP not have to put the machine of squid within
> the domain, please as you would, I made queries to Active Directory but
> give me credentials error .

To check credentials Squid needs access to the authentication system.

AFAIK that usually means the Squid machine should be on-domain even if
the clients are using Basic auth from off-domain. LDAP might be a bit
different though.

> Always I look forward to your help in the squid 3.4.8 squid_ldap_auth
> basic_ldap_auth parameter change.

IIRC there is no parameter change. Only the helper named changed in 3.2.


You will need to share your configuration and details of what the
redentials aerror you are talking about is exactly to get more help.

Amos



From squid3 at treenet.co.nz  Tue Dec  1 04:11:30 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Dec 2015 17:11:30 +1300
Subject: [squid-users] deny_info / url_rewrite_program
In-Reply-To: <565CBB36.1030005@web.de>
References: <565CBB36.1030005@web.de>
Message-ID: <565D1DF2.8030405@treenet.co.nz>

On 1/12/2015 10:10 a.m., Jens Kallup wrote:
> Hi,
> 
> next, the output, followed by the config snippet, the perl script is fixed,
> but don't work - squid shows only Error - Access Denied ...
> 
<snip>

> # squid config:
> auth_param basic program /usr/local/squid/libexec/basic_ncsa_auth
> /sap/squid/passwd
> auth_param basic utf8 on
> auth_param basic children 5 startup=1 idle=1 concurrency=0
> auth_param basic realm Bitte geben Sie Ihren Benutzernamen und Ihr
> Passwort zur Internet-Authentifizierung ein!
> auth_param basic credentialsttl 60 minutes
> auth_param basic casesensitive on
> 
> external_acl_type blocker concurrency=100 ttl=60 negative_ttl=0
> children-max=1 %LOGIN %DST /sap/squid/block.sh
> acl mysql_blocker external blocker
> 
> url_rewrite_program /sap/squid/rewrite.pl  # inserted \__ these 2 lines
> have no effect, always, the same behavour
> url_rewrite_access deny mysql_blocker      # inserted /
> 

In url_rewrite_access "deny" means "dont use the re-writer".


> #deny_info http://www.freenet.de blocker
> 

The above deny_info is the line changing the "Access denied" action to a
"redirect to http://..." action, done when a "http_access deny blocker"
line is matched.

Amos



From fengsheng.10 at gmail.com  Tue Dec  1 04:44:37 2015
From: fengsheng.10 at gmail.com (=?UTF-8?B?6aOO5aOw?=)
Date: Tue, 1 Dec 2015 12:44:37 +0800
Subject: [squid-users] How to use the different Store ID with same url and
 different proxy port ?
Message-ID: <CAJGZ0h7bLtm3yhYSJtnd0R3NunKYwDw56bae6=YnkT_UzNPBGg@mail.gmail.com>

Hi,

We want to Squid-3 to listen serveral ports (like 3128/3129/3120/...), but
we want reply different cached objects for different ports with same
request (same url), because we want to cache compressed objects for some
ports.

How can we do that ? we try to use store id configs in squid.conf, but
looks like it does not work.


squid --> ziproxy --------> websites
          \----------------------> websites

or we just only can do is setup multiple squid instances in same servers
 to listen different ports ?

Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151201/c7026b87/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec  1 10:15:34 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Dec 2015 23:15:34 +1300
Subject: [squid-users] Time-Based Download Restrictions
In-Reply-To: <CAMQtd8jrL2k-8bS-Eq-2MN-=9_YyO=cMY8W9HVno7Y4sEAodhQ@mail.gmail.com>
References: <CAMQtd8jrL2k-8bS-Eq-2MN-=9_YyO=cMY8W9HVno7Y4sEAodhQ@mail.gmail.com>
Message-ID: <565D7346.3050403@treenet.co.nz>

On 1/12/2015 3:56 a.m., Edmonds Namasenda wrote:
> Greetings.
> 
> I want to deny access to certain downloads (in str-med.txt) during "WorkHrs"
> This is failing miserably as this is not achieved.
> 
> Please look through my files (squid.conf and str-med.txt) below for
> pointers to rectify this. Thanks in advance

Apart from being placed above the access controls on CONNECT (it should
be below). The config looks like it should work and block all HTTP
downloads for URLs that look like filename downloads.

I suspect that you are probably confusing HTTPS and HTTP though. HTTPS
does not have a URL path exposed for the ACL to work with. So these
controls will have no effect on HTTPS traffic.

Or perhapse you are confusing URL paths for file paths. While they do
look alike sometimes, the overlap is purely historical design
coincidence. There is not necessarily any correlation in reality.


> 
> ### Start squid.conf ###
> acl office-net src 10.10.2.0/24
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> acl WorkHrs time MTWHF 08:29-12:59
> acl WorkHrs time MTWHFA 14:00-16:59
> 
> ## Wrong Files and URLS
> acl malice dstdomain -i "/etc/squid/malware.acl"
> acl porn dstdomain -i "/etc/squid/xxx.acl"
> acl ads dstdomain -i "/etc/squid/ads.acl"
> acl proxies dstdomain -i "/etc/squid/proxies.acl"
> 
> acl nostr urlpath_regex -i "/etc/squid/str-med.txt"
> 
> http_access deny nostr WorkHrs
> http_reply_access deny nostr WorkHrs

If the "nostr WorkHrs" check matches anything it would do so on
http_access, the reply version is not useful.

> 
> http_access deny !Safe_ports
> http_access deny ads
> http_access deny porn
> http_access deny malice
> http_access deny proxies


The ACLs ads, porn  malice, and proxies are all dstdomain. You should be
able to load all their entries into one AC name and just test once,
instead of checking each requests domain x4 times.
combine them into one ACL name.

Also, all your custom ACLs should be placed after the "deny CONNECT
!SSL_ports" line.

> 
> http_access deny CONNECT !SSL_ports
> 
> http_access allow localhost manager
> http_access deny manager
> 
> http_access allow office-net all
> 
> # Allow localhost always proxy functionality
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> error_directory /usr/share/squid/errors/en
> 
> icp_access allow office-net
> icp_access deny all
> 
> htcp_access allow office-net
> htcp_access deny all
> 
> http_port 10.10.2.10:3128 intercept
> http_port 127.0.0.1:3127
> 
> hierarchy_stoplist cgi-bin ?
> 

You don't have peers, so the above is not useful. You can remove it.

<snip>
> 
> acl youtube dstdomain .youtube.com
> cache allow youtube

The above may not be doing what you think it does...

With ACL processing the implicit default action is the inverse of the
previous action. So what the above does is tell Squid to cache
youtube.com objects, *but nothing else*.

If that is intentional it is best to say so with an explicit "cache deny
all" line at the end.

If you want youtube.com objects to be cached, a) the above does not
work, and b) you dont have to specify "cache allow" lines. The default
action by Squid is to cache everything that is cacheable.

Amos


From squid3 at treenet.co.nz  Tue Dec  1 10:46:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Dec 2015 23:46:10 +1300
Subject: [squid-users] How to use the different Store ID with same url
 and different proxy port ?
In-Reply-To: <CAJGZ0h7bLtm3yhYSJtnd0R3NunKYwDw56bae6=YnkT_UzNPBGg@mail.gmail.com>
References: <CAJGZ0h7bLtm3yhYSJtnd0R3NunKYwDw56bae6=YnkT_UzNPBGg@mail.gmail.com>
Message-ID: <565D7A72.9010104@treenet.co.nz>

On 1/12/2015 5:44 p.m., ?? wrote:
> Hi,
> 
> We want to Squid-3 to listen serveral ports (like 3128/3129/3120/...), but
> we want reply different cached objects for different ports with same
> request (same url),

Don't. URL do not work that way.

RFC 3986 section 1.1.3:
" The term "Uniform Resource Locator" (URL) refers to the subset of URIs
that, in addition to identifying a resource, provide a means of locating
the resource by describing its primary access mechanism "

The URL tells Squid both what object to return, but also *how* it had to
have been fetched (if already cached) or to fetch (if not cached yet).


Neither of which has anything to do with what proxy port Squid is
receiving HTTP messages through.



> because we want to cache compressed objects for some
> ports.

Whether Squid stores a compressed or non-compressed or both objects
depends on what forms are actively negotiated between client and server.
Independent of the URL.


> 
> How can we do that ? we try to use store id configs in squid.conf, but
> looks like it does not work.
> 

Store-ID does not work that way either. All it says is what ID Squid is
to use internally for the URL. It has nothing to do with either the type
of object, nor with what listening port was involved.


> 
> squid --> ziproxy --------> websites
>           \----------------------> websites
> 
> or we just only can do is setup multiple squid instances in same servers
>  to listen different ports ?
> 

What are you *really* trying to do? I mean the end product goal, not
just the "serve compressed and non-compressed on different ports"
halfway step. That is just a halfway step towards a badly designed end
product.

If you place ziproxy between Squid and web servers you will get
compressed objects.

You can achieve the same by having Squid emit headers stating that only
compressed objects are acceptible. The web servers themselves then do
the compression, no need for ziproxy AFAICS.

Amos



From squid3 at treenet.co.nz  Tue Dec  1 10:47:23 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Dec 2015 23:47:23 +1300
Subject: [squid-users] 32bit (i386) squid 3.5 cache dir size
In-Reply-To: <F8298236-20EF-4438-9B98-E9C9F5C201C0@yahoo.com>
References: <011b01d12b92$4e41cdd0$eac56970$@verizon.net>
 <F8298236-20EF-4438-9B98-E9C9F5C201C0@yahoo.com>
Message-ID: <565D7ABB.8060809@treenet.co.nz>

On 1/12/2015 8:48 a.m., TarotApprentice wrote:
> From the Debian repo. Stretch has 3.5.10 at the moment. Jessie has 3.4.8.
> 

Then it should have large-file support IIRC.

Amos



From squid3 at treenet.co.nz  Tue Dec  1 10:57:40 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Dec 2015 23:57:40 +1300
Subject: [squid-users] Looking for ideas on how to use squid in order to
 protect against a DOS\DDOS.
In-Reply-To: <565CA12C.4000509@ngtech.co.il>
References: <565CA12C.4000509@ngtech.co.il>
Message-ID: <565D7D24.3050809@treenet.co.nz>

On 1/12/2015 8:19 a.m., Eliezer Croitoru wrote:
> I was wondering if someone have a nice idea on how to use squid to
> protect against DOS\DDOS http\https attacks.
> 
> The basic way I was thinking is rate limiting by counting the client IP
> page HITs but I am unsure about it since it can actually catch the good
> guys and bite my squid setup.
> 
> The other way I was thinking was some kind of a challenge like a captcha
> page.
> 
> Also I have seen something like JavaScript browser challenge being used.
> 
> What do you think would be the right choice?

Fast automated detection. Absolute minimal response to identified
requests. Push the cost as far back up the traffic path towards the
attacker as possible. Those are the answers to DDoS.

> 
> If you have another idea please send me or the list an email.
> 

Squid already does pretty well against many of the common (old'ish) DDoS
types. Though there are some countermeasures that could still be
improved, and some DDoS types that are not protected against at all.

There are many forms of DoS to begin with, and *how* the DoS is turned
into DDoS is one of the important considerations. There are many
possible forms that could take. So the big question to start with is
what type of DDoS are you trying to protect against?

Amos



From nicolas.langlois at rouen.archi.fr  Tue Dec  1 11:40:06 2015
From: nicolas.langlois at rouen.archi.fr (LANGLOIS Nicolas)
Date: Tue, 1 Dec 2015 11:40:06 +0000
Subject: [squid-users] squid 3.4.8  ssl-bump resolve ip in access.log
Message-ID: <E5B6AD485ECDEC469A7AA6CFF504EF660979B7A7@EXCH1.admin.rouen.archi.fr>

Hi,  i'm trying to set up squid 3.4.8 on debian , i want a full transparent proxy, no conf on client side .
it's working actually but i 'm ask to report websites access but for https actually i just get  this kind of line in my access.log :
< TCP_MISS/200 288 CONNECT 64.233.184.106:443 - ORIGINAL_DST/64.233.184.106 <

Is there a way to have dns resolution  and log the website visited  for https ?

Here is a part of my squid.conf :

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.pem
http_port 192.168.1.1:3129 intercept
https_port 192.168.1.1:3130 intercept ssl-bump  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.pem

ssl_bump none all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
always_direct allow all

or is there a magical solution for transparent proxy  with no client-side (certs or proxy conf) config working actually with https ?

Regards

Nicolas

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151201/17ec3b76/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec  1 12:18:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 2 Dec 2015 01:18:24 +1300
Subject: [squid-users] squid 3.4.8 ssl-bump resolve ip in access.log
In-Reply-To: <E5B6AD485ECDEC469A7AA6CFF504EF660979B7A7@EXCH1.admin.rouen.archi.fr>
References: <E5B6AD485ECDEC469A7AA6CFF504EF660979B7A7@EXCH1.admin.rouen.archi.fr>
Message-ID: <565D9010.2070602@treenet.co.nz>

On 2/12/2015 12:40 a.m., LANGLOIS Nicolas wrote:
> Hi,  i'm trying to set up squid 3.4.8 on debian , i want a full transparent proxy, no conf on client side .

That is not what "fully transparent" means.

The best form of transparent proxy is when clients are auto-configured
with explicit-proxy settings.


Also be aware that the Debian versions which are shipping Squid-3.4.8
have some mystery issue in their kernels that nobody has yet been able
to track down that prevents the TPROXY feature from operating properly.
You will have to stick with NAT or upgrade to one of the Debian versions
shipping Squid-3.5, their kernels seem to work better.


> it's working actually but i 'm ask to report websites access but for https actually i just get  this kind of line in my access.log :
> < TCP_MISS/200 288 CONNECT 64.233.184.106:443 - ORIGINAL_DST/64.233.184.106 <
> 
> Is there a way to have dns resolution  and log the website visited  for https ?

What for? all it does is reduce accuracy of the log.
You can end up with situations where the log says:
 "CONNECT 64.233.184.106:443 - ORIGINAL_DST/example.com"

But when log analysis runs example.com has moved its IP, or just DNS has
cycled on to another one of the set. So analysis then reports the client
requested URL "64.233.184.106:443" when connecting to a server whose IP
is now 192.0.2.1. Which is plain wrong.


> 
> Here is a part of my squid.conf :
> 
> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.pem
> http_port 192.168.1.1:3129 intercept
> https_port 192.168.1.1:3130 intercept ssl-bump  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.pem
> 
> ssl_bump none all
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> always_direct allow all

So basically; Intercept TLS (supposed to be secure). Ignore all possible
errors, malicious attacks, diversions or hijacking that might be done by
anyone else on the way to the real server. BUT tell the client
everything is safe to send or fetch that sensitive data they needed TLS for?

You are SO lucky you started that "ssl_bump none all" actually means
dont perform SSL-bump interception. It is preventing a world of FAIL
from landing on your head.

The other three lines should be erased immediately.

> 
> or is there a magical solution for transparent proxy  with no client-side (certs or proxy conf) config working actually with https ?

Firstly, Be aware that SSL-Bump is involved in an arms race. If you are
doing bumping always use the latest Squid. The 3.4 series is outdated by
a year. Things have already moved on well past its capabilities.


Secondly, after upgrade to Squid-3.5 use "splice all" where you have
placed "none all" right now and what you request will 'just work'. You
can then peek/stare at unencrypted the SNI and cert details to log where
clients are going and/or block certain servers being contacted.

The assumption with SSL-Bump is that you are doing so in order to
actually bump at least some of the traffic. There is very little point
in diverting port 443 to Squid only to do nothing at all with it. All
that does is slow the already heavyweight HTTPS protocol down. It is the
bumping action that requires the client setup.

Amos



From jkallup at web.de  Tue Dec  1 14:17:23 2015
From: jkallup at web.de (Jens Kallup)
Date: Tue, 1 Dec 2015 15:17:23 +0100
Subject: [squid-users] deny_info / url_rewrite_program
Message-ID: <565DABF3.7090209@web.de>

Hello,

bellow, a Perl script that works for me - it redirect the
URL in browser; when i type in "web.de" the result is
"www.freenet.de".
But the browser don't connect to www.freenet.de,
he shows me a Error: redirect-error - this problem can
be, when Cookies deactivated or denied.
(iceweasel - firefox)
Is that a browser mistake or my logic?

#!/usr/bin/perl -l

$|=1;                   # don't buffer stdout

while (<>) {            # read line from STDIN (squid input)
   $url = m/^([^ ]*)/;
   if ($url !~ /^http:\/\/web\.de/) {
     print "301:http://www.freenet.de/index.html\n";
   } else {
     print "$url\n";
   }
}


From nicolas.langlois at rouen.archi.fr  Tue Dec  1 15:01:12 2015
From: nicolas.langlois at rouen.archi.fr (LANGLOIS Nicolas)
Date: Tue, 1 Dec 2015 15:01:12 +0000
Subject: [squid-users] squid 3.4.8 ssl-bump resolve ip in access.log
In-Reply-To: <565D9010.2070602@treenet.co.nz>
References: <E5B6AD485ECDEC469A7AA6CFF504EF660979B7A7@EXCH1.admin.rouen.archi.fr>
 <565D9010.2070602@treenet.co.nz>
Message-ID: <E5B6AD485ECDEC469A7AA6CFF504EF660979BAA5@EXCH1.admin.rouen.archi.fr>

Thanks Amos for the quick reply,  
I 'm making lot of mistake around  ssl with squid, i 'm following your advice and try to setup with with last squid 3.5 version using tproxy  will let you know . 

Have a good day 

Nicolas

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Amos Jeffries
Envoy??: mardi 1 d?cembre 2015 13:18
??: squid-users at lists.squid-cache.org
Objet?: Re: [squid-users] squid 3.4.8 ssl-bump resolve ip in access.log

On 2/12/2015 12:40 a.m., LANGLOIS Nicolas wrote:
> Hi,  i'm trying to set up squid 3.4.8 on debian , i want a full transparent proxy, no conf on client side .

That is not what "fully transparent" means.

The best form of transparent proxy is when clients are auto-configured with explicit-proxy settings.


Also be aware that the Debian versions which are shipping Squid-3.4.8 have some mystery issue in their kernels that nobody has yet been able to track down that prevents the TPROXY feature from operating properly.
You will have to stick with NAT or upgrade to one of the Debian versions shipping Squid-3.5, their kernels seem to work better.


> it's working actually but i 'm ask to report websites access but for https actually i just get  this kind of line in my access.log :
> < TCP_MISS/200 288 CONNECT 64.233.184.106:443 - 
> ORIGINAL_DST/64.233.184.106 <
> 
> Is there a way to have dns resolution  and log the website visited  for https ?

What for? all it does is reduce accuracy of the log.
You can end up with situations where the log says:
 "CONNECT 64.233.184.106:443 - ORIGINAL_DST/example.com"

But when log analysis runs example.com has moved its IP, or just DNS has cycled on to another one of the set. So analysis then reports the client requested URL "64.233.184.106:443" when connecting to a server whose IP is now 192.0.2.1. Which is plain wrong.


> 
> Here is a part of my squid.conf :
> 
> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on 
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.pem
> http_port 192.168.1.1:3129 intercept
> https_port 192.168.1.1:3130 intercept ssl-bump  
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> cert=/etc/squid3/ssl_cert/squid.pem
> 
> ssl_bump none all
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> always_direct allow all

So basically; Intercept TLS (supposed to be secure). Ignore all possible errors, malicious attacks, diversions or hijacking that might be done by anyone else on the way to the real server. BUT tell the client everything is safe to send or fetch that sensitive data they needed TLS for?

You are SO lucky you started that "ssl_bump none all" actually means dont perform SSL-bump interception. It is preventing a world of FAIL from landing on your head.

The other three lines should be erased immediately.

> 
> or is there a magical solution for transparent proxy  with no client-side (certs or proxy conf) config working actually with https ?

Firstly, Be aware that SSL-Bump is involved in an arms race. If you are doing bumping always use the latest Squid. The 3.4 series is outdated by a year. Things have already moved on well past its capabilities.


Secondly, after upgrade to Squid-3.5 use "splice all" where you have placed "none all" right now and what you request will 'just work'. You can then peek/stare at unencrypted the SNI and cert details to log where clients are going and/or block certain servers being contacted.

The assumption with SSL-Bump is that you are doing so in order to actually bump at least some of the traffic. There is very little point in diverting port 443 to Squid only to do nothing at all with it. All that does is slow the already heavyweight HTTPS protocol down. It is the bumping action that requires the client setup.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From eliezer at ngtech.co.il  Tue Dec  1 15:27:33 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 1 Dec 2015 17:27:33 +0200
Subject: [squid-users] Looking for ideas on how to use squid in order to
 protect against a DOS\DDOS.
In-Reply-To: <565D7D24.3050809@treenet.co.nz>
References: <565CA12C.4000509@ngtech.co.il> <565D7D24.3050809@treenet.co.nz>
Message-ID: <565DBC65.70709@ngtech.co.il>

On 01/12/2015 12:57, Amos Jeffries wrote:
> On 1/12/2015 8:19 a.m., Eliezer Croitoru wrote:
>> I was wondering if someone have a nice idea on how to use squid to
>> protect against DOS\DDOS http\https attacks.
>>
>> The basic way I was thinking is rate limiting by counting the client IP
>> page HITs but I am unsure about it since it can actually catch the good
>> guys and bite my squid setup.
>>
>> The other way I was thinking was some kind of a challenge like a captcha
>> page.
>>
>> Also I have seen something like JavaScript browser challenge being used.
>>
>> What do you think would be the right choice?
>
> Fast automated detection. Absolute minimal response to identified
> requests. Push the cost as far back up the traffic path towards the
> attacker as possible. Those are the answers to DDoS.
>
>>
>> If you have another idea please send me or the list an email.
>>
>
> Squid already does pretty well against many of the common (old'ish) DDoS
> types. Though there are some countermeasures that could still be
> improved, and some DDoS types that are not protected against at all.

Squid can only "catch" with default settings basic objects fetch from 
the origin which in most cases can also be forced by adding couple 
arguments to the request such as a timestamp.

> There are many forms of DoS to begin with, and *how* the DoS is turned
> into DDoS is one of the important considerations. There are many
> possible forms that could take. So the big question to start with is
> what type of DDoS are you trying to protect against?

I do not have one in mind yet since I'm not really a Dos or DDoS master.
I have seen couple attacks in the past which was coming from a single or 
more AS while spreading the attack from lots of origins.
The basic attack would be an application level one which in this case a 
captcha gives in many cases really good results.
The second case would be traffic BW exhaustion and for that a basic BW 
throttling would be good enough.(delay pools can be used for that..)

I have used fail2ban more then once to block origins and to identify 
them but I think an ICAP service might be able to identify more then 
what is in the access.logs.

What you wrote about "Push the cost as far back up the traffic path.." I 
can think about one way which would be a redirection towards their own 
source IP or GW.
And the above is nice for small attacks but not for very big ones. But 
in the other hand an ICAP service can give better details\debug on the 
details of the attack. It can be turned on for specific traffic and help 
understand the nature of it.
Also an ICAP service can be used as a honey pot.

I will research more and see what can be done in the ICAP level.

Thanks,
Eliezer


From giray_simsek at hotmail.com  Tue Dec  1 15:34:40 2015
From: giray_simsek at hotmail.com (Giray Simsek)
Date: Tue, 1 Dec 2015 07:34:40 -0800
Subject: [squid-users] missing icap respmod request when the web object
 is found in the cache?
In-Reply-To: <565CE103.9040908@measurement-factory.com>
References: <BLU184-W645A0925C834673288D738FE000@phx.gbl>,
 <565CE103.9040908@measurement-factory.com>
Message-ID: <BLU184-W6848D381220C822321837DFE0F0@phx.gbl>

Thanks Alex, this was helpful.

----------------------------------------
> Subject: Re: [squid-users] missing icap respmod request when the web object is found in the cache?
> To: squid-users at lists.squid-cache.org
> From: rousskov at measurement-factory.com
> CC: giray_simsek at hotmail.com
> Date: Mon, 30 Nov 2015 16:51:31 -0700
>
> On 11/30/2015 09:59 AM, Giray Simsek wrote:
>
>> Is there a way to tell squid to send the Respmod request to the icap
>> server in the case when the requested html page is found in the
>> cache?
>
> Squid supports two common ICAP "vectoring points": pre-cache REQMOD and
> pre-cache RESPMOD. To do what you want, you need post-cache RESPMOD.
> Squid (and most popular proxies AFAICT) does not support that vectoring
> point.
>
> There is a steady but small trickle of post-cache RESPMOD (and
> post-cache REQMOD!) support requests, so this feature may eventually be
> added, but it is quite a difficult project so I doubt it will happen any
> time soon.
>
>
> Cheers,
>
> Alex.
>
 		 	   		  

From giray_simsek at hotmail.com  Tue Dec  1 15:49:48 2015
From: giray_simsek at hotmail.com (Giray Simsek)
Date: Tue, 1 Dec 2015 07:49:48 -0800
Subject: [squid-users] Question about c-icap and setting X-Next-Services
 header to empty string
Message-ID: <BLU184-W379DCDE12E07C803AD7273FE0F0@phx.gbl>

Hi,
I have 2 icap response modification services. I have integrated them to squid as in the below config. 
I am trying to update the adaptation plan dynamically in the first service (service_a_resp)Basically, if a certain condition is met, then I don't want the second service (service_b_resp) to be called by Squid.

icap_enable onicap_send_client_ip onicap_send_client_username onicap_client_username_header X-Client-Username
icap_service service_a_resp respmod_precache bypass=on routing=on icap://127.0.0.1:1344/virus_scan icap_service service_b_resp respmod_precache bypass=on routing=on icap://127.0.0.1:1344/content_filter
adaptation_service_chain response_chain service_a_resp service_b_respadaptation_access response_chain allow all
After reading the documentation about the icap_service option and its routing parameter, I got the impression that I can achieve this by setting X-Next-Services header to empty string in my first service (service_a_resp) in the adaptation chain as below:
ci_headers_add(req->response_header, "X-Next-Services: ");
However, when I test this I see that the second service is still getting called by Squid.
How can I dynamically prevent the second service in the adaptation chain from getting called? Any ideas what I am missing?
Thanks,Giray 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151201/7ca51f3f/attachment.htm>

From giray_simsek at hotmail.com  Tue Dec  1 15:58:36 2015
From: giray_simsek at hotmail.com (Giray Simsek)
Date: Tue, 1 Dec 2015 07:58:36 -0800
Subject: [squid-users] Question about c-icap and setting X-Next-Services
 header to empty string
In-Reply-To: <BLU184-W379DCDE12E07C803AD7273FE0F0@phx.gbl>
References: <BLU184-W379DCDE12E07C803AD7273FE0F0@phx.gbl>
Message-ID: <BLU184-W697BE01A0926B1148435BAFE0F0@phx.gbl>

Hi,

[Sorry for the dupe mail but I forgot to format the previous one as "Plain Text" and it looks bad.]

I have 2 icap response modification services. I have integrated them to squid as in the below config.?

I am trying to update the adaptation plan dynamically in the first service (service_a_resp)
Basically, if a certain condition is met, then I don't want the second service (service_b_resp) to be called by Squid.


icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Client-Username

icap_service service_a_resp respmod_precache bypass=on routing=on icap://127.0.0.1:1344/virus_scan?
icap_service service_b_resp respmod_precache bypass=on routing=on icap://127.0.0.1:1344/content_filter

adaptation_service_chain response_chain service_a_resp service_b_resp
adaptation_access response_chain allow all

After reading the documentation about the icap_service option and its routing parameter, I got the impression that I can achieve this by setting X-Next-Services header to empty string in my first service (service_a_resp) in the adaptation chain as below:

ci_headers_add(req->response_header, "X-Next-Services: ");

However, when I test this I see that the second service is still getting called by Squid.

How can I dynamically prevent the second service in the adaptation chain from getting called? Any ideas what I am missing?

Thanks,
Giray

________________________________
> From: giray_simsek at hotmail.com 
> To: squid-users at lists.squid-cache.org 
> Subject: Question about c-icap and setting X-Next-Services header to 
> empty string 
> Date: Tue, 1 Dec 2015 07:49:48 -0800 
> 
> Hi, 
> 
> I have 2 icap response modification services. I have integrated them to 
> squid as in the below config. 
> 
> I am trying to update the adaptation plan dynamically in the first 
> service (service_a_resp) 
> Basically, if a certain condition is met, then I don't want the second 
> service (service_b_resp) to be called by Squid. 
> 
> 
> icap_enable on 
> icap_send_client_ip on 
> icap_send_client_username on 
> icap_client_username_header X-Client-Username 
> 
> icap_service service_a_resp respmod_precache bypass=on routing=on 
> icap://127.0.0.1:1344/virus_scan 
> icap_service service_b_resp respmod_precache bypass=on routing=on 
> icap://127.0.0.1:1344/content_filter 
> 
> adaptation_service_chain response_chain service_a_resp service_b_resp 
> adaptation_access response_chain allow all 
> 
> After reading the documentation about the icap_service option and its 
> routing parameter, I got the impression that I can achieve this by 
> setting X-Next-Services header to empty string in my first service 
> (service_a_resp) in the adaptation chain as below: 
> 
> ci_headers_add(req->response_header, "X-Next-Services: "); 
> 
> However, when I test this I see that the second service is still 
> getting called by Squid. 
> 
> How can I dynamically prevent the second service in the adaptation 
> chain from getting called? Any ideas what I am missing? 
> 
> Thanks, 
> Giray 
 		 	   		  

From bart.spedden at 3sharecorp.com  Tue Dec  1 16:06:34 2015
From: bart.spedden at 3sharecorp.com (Bart Spedden)
Date: Tue, 1 Dec 2015 09:06:34 -0700
Subject: [squid-users] 2 way SSL on a non standard SSL Port
In-Reply-To: <565D011F.9040402@treenet.co.nz>
References: <CAMxDymdY6ohJ+V-x=Cfh=h3daHOYVK+y4=QzUvwF2Umb6a0Oow@mail.gmail.com>
 <565C8AF4.9040207@ngtech.co.il>
 <CAMxDymd5OQyqSTsYB2qCUqf04kTWpnEV4mve5NjnPrzXy8P4sw@mail.gmail.com>
 <201511301859.24482.Antony.Stone@squid.open.source.it>
 <CAMxDymf8xXhm1p7TXy6XhZ98--XmtmuqhQvaFY9RX2NFmfJOWw@mail.gmail.com>
 <CAMxDymc-0ntnAqUfJXjdbGYjn80AN1L14dRLA=fKmYWWKp7Fhw@mail.gmail.com>
 <565D011F.9040402@treenet.co.nz>
Message-ID: <CAMxDymfWLw-RVK3F=BgtbMQxmd7=SiygBrnSN7oH7h1UmqEafA@mail.gmail.com>

Thank you so much Amos! You figured it out!

I was able to telnet to those ports from my localhost, but not from the
server where squid is installed. I'm working to get those ports opened now.

Thanks again!

On Mon, Nov 30, 2015 at 7:08 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 1/12/2015 1:01 p.m., Bart Spedden wrote:
> > In the cache.log I have found the following:
> >
> > CONNECT tv1var.merchantlink-lab.com:8184 HTTP/1.1^M
> >
> > User-Agent: Java/1.8.0_05^M
> >
> > Host: tv1var.merchantlink-lab.com:8184^M
> >
> > Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2^M
> >
> > Proxy-Connection: keep-alive^M
> >
> > ^M
> >
> >
> > ----------
> >
> > 2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(741)
> > clientAccessCheckDone: The request CONNECT
> tv1var.merchantlink-lab.com:8184
> > is ALLOWED; last ACL checked: localnet
> >
> > 2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(717)
> > clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
> >
> > 2015/11/30 17:18:47.517 kid1| 85,2| client_side_request.cc(741)
> > clientAccessCheckDone: The request CONNECT
> tv1var.merchantlink-lab.com:8184
> > is ALLOWED; last ACL checked: localnet
> >
> > 2015/11/30 17:18:47.517 kid1| 44,2| peer_select.cc(258)
> peerSelectDnsPaths:
> > Find IP destination for: tv1var.merchantlink-lab.com:8184' via
> > tv1var.merchantlink-lab.com
> >
> > 2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(280)
> peerSelectDnsPaths:
> > Found sources for 'tv1var.merchantlink-lab.com:8184'
> >
> <snip>
> >
> > 2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(286)
> > peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=
> > 104.153.8.184:8184 flags=1
>
> So this one server destination has been found, and will be tried.
>
> >
> > 2015/11/30 17:18:47.533 kid1| 44,2| peer_select.cc(295)
> > peerSelectDnsPaths:        timedout = 0
> >
>
> But the TCP connect failed:
>
> > 2015/11/30 17:18:47.534 kid1| 4,2| errorpage.cc(1262) BuildContent: No
> > existing error page language negotiated for ERR_CONNECT_FAIL. Using
> default
> > error file.
> >
>
>
> At this point I suspect some external access crontol, such as a firewall
> is also blocking that unusual port.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Bart Spedden  |  Senior Developer
+1.720.210.7041  |
*bart.spedden at 3sharecorp.com <bart.spedden at 3sharecorp.com>*
3 | S H A R E  |  Adobe Digital Marketing Experts  |  An Adobe?  Business
Plus Level Solution PartnerConsulting  |  Training  |  Remote Operations
Management
<http://www.3sharecorp.com/en/services/rom.html>
<http://www.3sharecorp.com/en/services/rom.html>
<http://www.3sharecorp.com/en/services/rom.html>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151201/df7bf8a0/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rom-email-sig4_600x100.png
Type: image/png
Size: 16361 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151201/df7bf8a0/attachment.png>

From rousskov at measurement-factory.com  Tue Dec  1 16:18:07 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 1 Dec 2015 09:18:07 -0700
Subject: [squid-users] Question about c-icap and setting X-Next-Services
 header to empty string
In-Reply-To: <BLU184-W697BE01A0926B1148435BAFE0F0@phx.gbl>
References: <BLU184-W379DCDE12E07C803AD7273FE0F0@phx.gbl>
 <BLU184-W697BE01A0926B1148435BAFE0F0@phx.gbl>
Message-ID: <565DC83F.1050601@measurement-factory.com>

On 12/01/2015 08:58 AM, Giray Simsek wrote:

> I am trying to update the adaptation plan dynamically in the first
> service (service_a_resp) Basically, if a certain condition is met,
> then I don't want the second service (service_b_resp) to be called by
> Squid.


> icap_enable on
> icap_send_client_ip on
> icap_send_client_username on
> icap_client_username_header X-Client-Username
> 
> icap_service service_a_resp respmod_precache bypass=on routing=on icap://127.0.0.1:1344/virus_scan 
> icap_service service_b_resp respmod_precache bypass=on routing=on icap://127.0.0.1:1344/content_filter

This is probably not important, but only the first service needs
routing=on. Your other ICAP service does not route requests.


> adaptation_service_chain response_chain service_a_resp service_b_resp
> adaptation_access response_chain allow all

OK.


> After reading the documentation about the icap_service option and its
> routing parameter, I got the impression that I can achieve this by
> setting X-Next-Services header to empty string in my first service
> (service_a_resp) in the adaptation chain 

That sounds correct although you are omitting a critical detail:
X-Next-Services is an ICAP response header, not an HTTP header.
Naturally, ICAP routing does not modify the HTTP message being routed.


> as below:
> ci_headers_add(req->response_header, "X-Next-Services: ");

Googling suggests that the above c-icap method is for adding HTTP
headers. You need to add an ICAP response header instead. I do not know
c-icap API, so I cannot recommend a specific method. If you do not know
how to do that either, consider asking on c-icap support forums.


HTH,

Alex.



From chip_pop at hotmail.com  Tue Dec  1 16:23:21 2015
From: chip_pop at hotmail.com (joe)
Date: Tue, 1 Dec 2015 08:23:21 -0800 (PST)
Subject: [squid-users] Looking for ideas on how to use squid in order to
 protect against a DOS\DDOS.
In-Reply-To: <565CA12C.4000509@ngtech.co.il>
References: <565CA12C.4000509@ngtech.co.il>
Message-ID: <1448987001552-4674939.post@n4.nabble.com>

put your server behind mikrotik
mikrotik has advance firewall and use tarpit instead of drop 
tarpit it freeze the attacker then drop his connection so making his attack
slow 

dig in mikrotik forum you find lots of working sample depend on Ddos attack



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Looking-for-ideas-on-how-to-use-squid-in-order-to-protect-against-a-DOS-DDOS-tp4674910p4674939.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue Dec  1 16:41:27 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 1 Dec 2015 22:41:27 +0600
Subject: [squid-users] Looking for ideas on how to use squid in order to
 protect against a DOS\DDOS.
In-Reply-To: <1448987001552-4674939.post@n4.nabble.com>
References: <565CA12C.4000509@ngtech.co.il>
 <1448987001552-4674939.post@n4.nabble.com>
Message-ID: <565DCDB7.4000703@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
mikrotik is SOHO-class network equipment. AFAIK we are not talking about
SOHO.

01.12.15 22:23, joe ?????:
> put your server behind mikrotik
> mikrotik has advance firewall and use tarpit instead of drop
> tarpit it freeze the attacker then drop his connection so making his
attack
> slow
>
> dig in mikrotik forum you find lots of working sample depend on Ddos
attack
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Looking-for-ideas-on-how-to-use-squid-in-order-to-protect-against-a-DOS-DDOS-tp4674910p4674939.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWXc23AAoJENNXIZxhPexGEy8H/Rwsaftz49qlHjdCgpGbbrfe
D0gEzftooEtP/crBx4K7yIrh++zOGmJciNwimScwiT5W2+KX5yAWpkurMLnn05o5
CND5QhLQrcL/jFXwC9JwqmwwPGg32Q+5gSOf9FyKBFpfWJ1uOc7myj7yl6yl5tXj
Xz8lKp7odiQErofTPYzKy/GSMDpre5W2BQNTJcm+imkx4xrgogV/1HDWCqXUw3qc
/nrcEV6gBkb0u4JT/ynTYD8d0egBzPZPCy/jw9x985/QhnLHeLMopkIGnnJVgL0N
NVQnNBrQhbsc3n5BGIadoMfXvAh3ci2wmBr8pEJr1o0eyX1PRT8ZmV9USsTpLqc=
=Ja8u
-----END PGP SIGNATURE-----



From eliezer at ngtech.co.il  Tue Dec  1 16:45:00 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 1 Dec 2015 18:45:00 +0200
Subject: [squid-users] Looking for ideas on how to use squid in order to
 protect against a DOS\DDOS.
In-Reply-To: <1448987001552-4674939.post@n4.nabble.com>
References: <565CA12C.4000509@ngtech.co.il>
 <1448987001552-4674939.post@n4.nabble.com>
Message-ID: <565DCE8C.9060205@ngtech.co.il>

On 01/12/2015 18:23, joe wrote:
> put your server behind mikrotik
> mikrotik has advance firewall and use tarpit instead of drop
> tarpit it freeze the attacker then drop his connection so making his attack
> slow
>
> dig in mikrotik forum you find lots of working sample depend on Ddos attack
>
I will look into it.
I am using a Linux based router in many places so I can use a black-hole 
route which is faster then itpables.
But I have had couple cases in the past so I have used two methods.
For a DoS I redirected the traffic towards a block page while for a DDoS 
I have used black-hope route for an AS or even more.

Eliezer



From eliezer at ngtech.co.il  Tue Dec  1 16:51:13 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 1 Dec 2015 18:51:13 +0200
Subject: [squid-users] Looking for ideas on how to use squid in order to
 protect against a DOS\DDOS.
In-Reply-To: <565DCDB7.4000703@gmail.com>
References: <565CA12C.4000509@ngtech.co.il>
 <1448987001552-4674939.post@n4.nabble.com> <565DCDB7.4000703@gmail.com>
Message-ID: <565DD001.9000500@ngtech.co.il>

Hey Yuri,

Even if mikrotik is SOHO-class in some places of the world it is still a 
nice product which in many cases is being used as a edge on non SOHO 
networks.
For amazon it won't do the trick but we are talking about 1Gbps+ WAN 
connections which are not SOHO.

Eliezer

On 01/12/2015 18:41, Yuri Voinov wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> mikrotik is SOHO-class network equipment. AFAIK we are not talking about
> SOHO.
>
> 01.12.15 22:23, joe ?????:
>> put your server behind mikrotik
>> mikrotik has advance firewall and use tarpit instead of drop
>> tarpit it freeze the attacker then drop his connection so making his
> attack
>> slow
>>
>> dig in mikrotik forum you find lots of working sample depend on Ddos
> attack
>>
>>
>>
>> --
>> View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Looking-for-ideas-on-how-to-use-squid-in-order-to-protect-against-a-DOS-DDOS-tp4674910p4674939.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJWXc23AAoJENNXIZxhPexGEy8H/Rwsaftz49qlHjdCgpGbbrfe
> D0gEzftooEtP/crBx4K7yIrh++zOGmJciNwimScwiT5W2+KX5yAWpkurMLnn05o5
> CND5QhLQrcL/jFXwC9JwqmwwPGg32Q+5gSOf9FyKBFpfWJ1uOc7myj7yl6yl5tXj
> Xz8lKp7odiQErofTPYzKy/GSMDpre5W2BQNTJcm+imkx4xrgogV/1HDWCqXUw3qc
> /nrcEV6gBkb0u4JT/ynTYD8d0egBzPZPCy/jw9x985/QhnLHeLMopkIGnnJVgL0N
> NVQnNBrQhbsc3n5BGIadoMfXvAh3ci2wmBr8pEJr1o0eyX1PRT8ZmV9USsTpLqc=
> =Ja8u
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From yvoinov at gmail.com  Tue Dec  1 16:59:32 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 1 Dec 2015 22:59:32 +0600
Subject: [squid-users] Looking for ideas on how to use squid in order to
 protect against a DOS\DDOS.
In-Reply-To: <565DD001.9000500@ngtech.co.il>
References: <565CA12C.4000509@ngtech.co.il>
 <1448987001552-4674939.post@n4.nabble.com> <565DCDB7.4000703@gmail.com>
 <565DD001.9000500@ngtech.co.il>
Message-ID: <565DD1F4.2000200@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
:) May be, may be not.

01.12.15 22:51, Eliezer Croitoru ?????:
> Hey Yuri,
>
> Even if mikrotik is SOHO-class in some places of the world it is still
a nice product which in many cases is being used as a edge on non SOHO
networks.
> For amazon it won't do the trick but we are talking about 1Gbps+ WAN
connections which are not SOHO.
Sure, agreed. This is not SOHO already.
>
> Eliezer
>
> On 01/12/2015 18:41, Yuri Voinov wrote:
>>
> mikrotik is SOHO-class network equipment. AFAIK we are not talking about
> SOHO.
>
> 01.12.15 22:23, joe ?????:
> >>> put your server behind mikrotik
> >>> mikrotik has advance firewall and use tarpit instead of drop
> >>> tarpit it freeze the attacker then drop his connection so making his
> attack
> >>> slow
> >>>
> >>> dig in mikrotik forum you find lots of working sample depend on Ddos
> attack
> >>>
> >>>
> >>>
> >>> --
> >>> View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Looking-for-ideas-on-how-to-use-squid-in-order-to-protect-against-a-DOS-DDOS-tp4674910p4674939.html
> >>> Sent from the Squid - Users mailing list archive at Nabble.com.
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWXdH0AAoJENNXIZxhPexGszAIALhA1DgJApQEHEdesvHkiVVg
OT+QynvgYKpngeRI6Ib0XhqciBqou+ui2hTrPLCLCfLTXrwqI2+jmmWFSLfJK5dm
g8qOuWrzhjKSQ+PUqphSscxW78xeX3yidD6wUxXy19vuaoc/H6OC2RUzjwfPr8AI
1u7d4+eusjvOsnjjWk4ASB3TECPgGQemsP5hDUvHSD1LaD0QLBq2q4iR4E8n4Crn
sooTIsOVr6kj1jg6PRl7zFOIr0cIvpjW6PnGCU1qo4inaJemvySkEsnTK41OfDGa
43LKsNvzV4GvOO3CWI0yh6HamvmqJ0vKiGv2a9YgJEA8NO9snEyDP+8YDBrp2P4=
=S0+o
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151201/fbf92f66/attachment.htm>

From chip_pop at hotmail.com  Tue Dec  1 23:11:03 2015
From: chip_pop at hotmail.com (joe)
Date: Tue, 1 Dec 2015 15:11:03 -0800 (PST)
Subject: [squid-users] TCP_SWAPFAIL_MISS
Message-ID: <1449011463169-4674944.post@n4.nabble.com>

TCP_MEM_HIT/200       469 GET
http://engine.adzerk.net/i.gif?e=eyJhdiI6NDE0LCJhdCI6NCwiYnQiOjAsImNtIjoxODc5NTQsImNoIjoxMTc4LCJjayI6e30sImNyIjo2NjQ0MjQsImRpIjoiZTc4OWZlNmQ4ZjUwNGZhOGI0ZWM4NDMxY2MyZWViOTkiLCJkbSI6MSwiZmMiOjY4NjI4MywiZmwiOjQxNTQ4NSwiaXAiOiJ1bmtub3duIiwibnciOjIyLCJwYyI6MCwiZWMiOjAsInByIjoxNjA0LCJydCI6MSwicmYiOiJodHRwczovL3d3dy5nb29nbGUuY29tIiwic3QiOjgyNzcsInVrIjoidWUxLTNjMWY4NjY1ZDNhZTQwZTI5OTFlNDNjNWIxNjM2NTFkIiwiem4iOjQzLCJ0cyI6MTQ0ODk4OTAwNDMyNiwiYmYiOnRydWUsInBuIjoiY2FyZWVyczEifQ&s=i2PYZxi83kOP-QjipXQNgpY1fSU
TCP_SWAPFAIL_MISS/200 560 GET
http://engine.adzerk.net/i.gif?e=eyJhdiI6NDE0LCJhdCI6NCwiYnQiOjAsImNtIjoxODc5NTQsImNoIjoxMTc4LCJjayI6e30sImNyIjo2NjQ0MjQsImRpIjoiZTc4OWZlNmQ4ZjUwNGZhOGI0ZWM4NDMxY2MyZWViOTkiLCJkbSI6MSwiZmMiOjY4NjI4MywiZmwiOjQxNTQ4NSwiaXAiOiJ1bmtub3duIiwibnciOjIyLCJwYyI6MCwiZWMiOjAsInByIjoxNjA0LCJydCI6MSwicmYiOiJodHRwczovL3d3dy5nb29nbGUuY29tIiwic3QiOjgyNzcsInVrIjoidWUxLTNjMWY4NjY1ZDNhZTQwZTI5OTFlNDNjNWIxNjM2NTFkIiwiem4iOjQzLCJ0cyI6MTQ0ODk4OTAwNDMyNiwiYmYiOnRydWUsInBuIjoiY2FyZWVyczEifQ&s=i2PYZxi83kOP-QjipXQNgpY1fSU

TCP_SWAPFAIL_MISS/200 1246 GET
http://pix04.revsci.net/J14015/b3/0/3/noscript.gif?D=DM_LOC%3Dhttp%253A%252F%252Frevsci.net%253F117702656%253D1%2526117440512%253D1%2526134283264%253D1%2526134217728%253D1%26DM_EOM%3D1&C=J14015&L=0
TCP_MISS/200          1244 GET
http://pix04.revsci.net/J14015/b3/0/3/noscript.gif?D=DM_LOC%3Dhttp%253A%252F%252Frevsci.net%253F117702656%253D1%2526117440512%253D1%2526134283264%253D1%2526134217728%253D1%26DM_EOM%3D1&C=J14015&L=0

TCP_SWAPFAIL_MISS/200 84773 GET
http://pagead2.googlesyndication.com/pagead/show_companion_ad.js
TCP_MISS/200          84701 GET
http://pagead2.googlesyndication.com/pagead/show_companion_ad.js

TCP_SWAPFAIL_MISS/200 624 GET
http://rtd.tubemogul.com/upi/?sid=y6Q0bLoY9W90bLo82l0X 
TCP_MISS/200          576 GET
http://rtd.tubemogul.com/upi/?sid=y6Q0bLoY9W90bLo82l0X

The native format for Squid 
time elapsed remotehost code/status bytes method URL rfc931
peerstatus/peerhost type

after lots of digging guessing wondering and i get tiered of this to find
the cause of the swapfail
i change HD  and the file-system from resiserfs to other even i tried btrfs 
all same 
daily i get TCP_SWAPFAIL_MISS  
only Squid Version 3.4.14 never seen TCP_SWAPFAIL_MISS in about cpl weeks
until now
so i notice the bytes ar diferent size wen it happen larger a bit 

so pls guys wen you have swapfail re send that link and verify if bytes size
ar different and post the result tks

mr.. amos if bytes size ar different that will fire error flag and  get
TCP_SWAPFAIL_MISS or ??



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-SWAPFAIL-MISS-tp4674944.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From alex at samad.com.au  Wed Dec  2 05:50:45 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 2 Dec 2015 16:50:45 +1100
Subject: [squid-users] setting up cache peering
Message-ID: <CAJ+Q1PV_LCzDDHcPdLkpZue7_OKNFoVZY5dbUo3mM2rXbHhg=w@mail.gmail.com>

Hi

I recently moved to squid-3.5.11-1.el6.x86_64 on centos 6.7.

from the centos 3.1 i think ?

This what I had originall
#cache_peer gsdmz1.xy.com sibling 3128 3130 proxy-only
#cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only

I had a shared config between the 2 server gsdmz1 and alcdmz1. I would
uncomment 1 or the other depending.

during my upgrade I coped the gsdmz1 squid config over to alcdmz1 but
forgot to uncomment the
cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only

so alcdmz1 was talking to itself at times.

using this as my test
wget -d   http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
-O /dev/null

and setting http_proxy to either alc or gsdmz1 I would get a 504 error.


wget -d  http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
-O /dev/null
Setting --output-document (outputdocument) to /dev/null
DEBUG output created by Wget 1.12 on linux-gnu.

--2015-12-02 16:35:34--
http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
Resolving alcdmz1... 10.3.2.111
Caching alcdmz1 => 10.3.2.111
Connecting to alcdmz1|10.3.2.111|:3128... connected.
Created socket 4.
Releasing 0x0000000001ea5db0 (new refcount 1).

---request begin---
GET http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
HTTP/1.0
User-Agent: Wget/1.12 (linux-gnu)
Accept: */*
Host: www.smh.com.au

---request end---
Proxy request sent, awaiting response...
---response begin---
HTTP/1.1 504 Gateway Timeout
Server: squid
Mime-Version: 1.0
Date: Wed, 02 Dec 2015 05:35:34 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 4063
X-Squid-Error: ERR_ONLY_IF_CACHED_MISS 0
Vary: Accept-Language
Content-Language: en
X-Cache: MISS from gsdmz1
X-Cache-Lookup: MISS from gsdmz1:3128
X-Cache: MISS from alcdmz1
X-Cache-Lookup: MISS from alcdmz1:3128
Via: 1.1 gsdmz1 (squid), 1.1 alcdmz1 (squid)
Connection: close

---response end---
504 Gateway Timeout
Closed fd 4
2015-12-02 16:35:34 ERROR 504: Gateway Timeout.


I changed the line to be
cache_peer gsdmz1.xy.com sibling 3128 3130 proxy-only standby=50
on the alcdmz1 box
and
cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only standby=50
on the gsdmz1 box

but this still gave me 504 errors ?
I tried to force a new version through both proxies by using wget with
no-cache option.  But that didn't help.


So what went wrong, how can I flush out the stale 504.
What is the best way to setup the 2 proxies to talk to each other
before going out to the internet.

the proxies run on a pacemaker cluster. I have 2 vip's setup as the
proxy addresses, in normal conditions these address are setup 1 on
each server. whilst working on a server I can move the vip and not
affect any one.


But I would like to take benefit of each others cache, whats the best
setup for cache_peer in this setup.

Neither server is closer to the internet.

thanks
A


From itpc.vivek at gmail.com  Wed Dec  2 06:07:09 2015
From: itpc.vivek at gmail.com (vivek singh)
Date: Wed, 2 Dec 2015 11:37:09 +0530
Subject: [squid-users] mail upload problem
Message-ID: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>

     we are facing problem while users trying to upload some attachments it
fails using linux proxy, while at the same time if they switch to windows
proxy attachment uploaded succesfully.
     I am using squid 3.5 version onboth linux and windows proxy servers,
any help would be appreciation.




*Thanks and RegardsVivek Kumar SinghMobile   08902000538*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151202/2957bcd1/attachment.htm>

From alex at samad.com.au  Wed Dec  2 06:24:18 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 2 Dec 2015 17:24:18 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
Message-ID: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>

Hi

recently upgraded to squid-3.5.11-1.el6.x86_64 from the centos 6.7  squid 3.1


I am now having problems with people who use active sync via this
connection . seems like emails with attachments aren't making it
through .

cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
originserver login=PASS front-end-https=on ssl
sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.yx.com.crt
sslkey=/etc/httpd/conf.d/office.yx.com.key name=exchangeServer


cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
sslcert=/etc/httpd/conf.d/office.yx.com.crt
sslkey=/etc/httpd/conf.d/office.yx.com.key name=webServer
c

# List of acceptable URLs to send to the Exchange server
acl exch_url url_regex -i office.yieldbroker.com/exchange
acl exch_url url_regex -i office.yieldbroker.com/exchweb
acl exch_url url_regex -i office.yieldbroker.com/public
acl exch_url url_regex -i office.yieldbroker.com/owa
acl exch_url url_regex -i office.yieldbroker.com/ecp
acl exch_url url_regex -i office.yieldbroker.com/microsoft-server-activesync
acl exch_url url_regex -i office.yieldbroker.com/rpc
acl exch_url url_regex -i office.yieldbroker.com/rpcwithcert
acl exch_url url_regex -i office.yieldbroker.com/exadmin
acl exch_url url_regex -i office.yieldbroker.com/oab
# added after
acl exch_url url_regex -i office.yieldbroker.com/ews
# Not configured on exchange 2010
#acl exch_url url_regex -i office.yieldbroker.com/autodiscover

# Send the Exchange URLs to the Exchange server
cache_peer_access exchangeServer allow exch_url

# Send everything else to the Apache
cache_peer_access webServer deny exch_url

# This is to protect Squid
never_direct allow exch_url

# Logging Configuration
redirect_rewrites_host_header off
cache_mem 32 MB
maximum_object_size_in_memory 128 KB
cache_log none
cache_store_log none

access_log stdio:/var/log/squid/office-access.log squid
#access_log none
cache_log /var/log/squid/office-cache.log
#cache_log none
pid_filename /var/run/squid-office.pid


# Set the hostname so that we can see Squid in the path (Optional)
visible_hostname yieldbroker.com
deny_info TCP_RESET all

# ACL - required to allow
#acl all src ALL

# Allow everyone through, internal and external connections
http_access allow all
miss_access allow all

icp_port 0
snmp_port 0

via off


The previous setup had worked for at least 18 months.

Alex


From giray_simsek at hotmail.com  Wed Dec  2 08:56:09 2015
From: giray_simsek at hotmail.com (Giray Simsek)
Date: Wed, 2 Dec 2015 00:56:09 -0800
Subject: [squid-users] Question about c-icap and setting X-Next-Services
 header to empty string
In-Reply-To: <565DC83F.1050601@measurement-factory.com>
References: <BLU184-W379DCDE12E07C803AD7273FE0F0@phx.gbl>,
 <BLU184-W697BE01A0926B1148435BAFE0F0@phx.gbl>,
 <565DC83F.1050601@measurement-factory.com>
Message-ID: <BLU184-W82A749A0A181095EA6FB9FE0E0@phx.gbl>

Thanks Alex. You're right. Using?

ci_icap_add_xheader(req, "X-Next-Services: ");

instead solved the problem.

Regards,
Giray

----------------------------------------
> Subject: Re: [squid-users] Question about c-icap and setting X-Next-Services header to empty string
> To: squid-users at lists.squid-cache.org
> From: rousskov at measurement-factory.com
> CC: giray_simsek at hotmail.com
> Date: Tue, 1 Dec 2015 09:18:07 -0700
>
> On 12/01/2015 08:58 AM, Giray Simsek wrote:
>
>> I am trying to update the adaptation plan dynamically in the first
>> service (service_a_resp) Basically, if a certain condition is met,
>> then I don't want the second service (service_b_resp) to be called by
>> Squid.
>
>
>> icap_enable on
>> icap_send_client_ip on
>> icap_send_client_username on
>> icap_client_username_header X-Client-Username
>>
>> icap_service service_a_resp respmod_precache bypass=on routing=on icap://127.0.0.1:1344/virus_scan
>> icap_service service_b_resp respmod_precache bypass=on routing=on icap://127.0.0.1:1344/content_filter
>
> This is probably not important, but only the first service needs
> routing=on. Your other ICAP service does not route requests.
>
>
>> adaptation_service_chain response_chain service_a_resp service_b_resp
>> adaptation_access response_chain allow all
>
> OK.
>
>
>> After reading the documentation about the icap_service option and its
>> routing parameter, I got the impression that I can achieve this by
>> setting X-Next-Services header to empty string in my first service
>> (service_a_resp) in the adaptation chain
>
> That sounds correct although you are omitting a critical detail:
> X-Next-Services is an ICAP response header, not an HTTP header.
> Naturally, ICAP routing does not modify the HTTP message being routed.
>
>
>> as below:
>> ci_headers_add(req->response_header, "X-Next-Services: ");
>
> Googling suggests that the above c-icap method is for adding HTTP
> headers. You need to add an ICAP response header instead. I do not know
> c-icap API, so I cannot recommend a specific method. If you do not know
> how to do that either, consider asking on c-icap support forums.
>
>
> HTH,
>
> Alex.
>
 		 	   		  

From Antony.Stone at squid.open.source.it  Wed Dec  2 08:58:48 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 2 Dec 2015 09:58:48 +0100
Subject: [squid-users] mail upload problem
In-Reply-To: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
Message-ID: <201512020958.48412.Antony.Stone@squid.open.source.it>

On Wednesday 02 December 2015 at 07:07:09, vivek singh wrote:

>      we are facing problem while users trying to upload some attachments it
> fails using linux proxy, while at the same time if they switch to windows
> proxy attachment uploaded succesfully.
>      I am using squid 3.5 version onboth linux and windows proxy servers,
> any help would be appreciation.

Please consider telling us:

1. What specific problem (eg: error message?) are the users getting?

2. Which browser/s are the users using?

3. Which web mail service are they accessing?

4. Are the browsers explicitly configured to use the Squid proxy, or are you 
using intercept mode?

5. What is your squid.conf (without comments or blank lines)?

6. What entries do you get in Squid's access.log when the problem occurs?

7. You say "some attachments" - does this mean that some can be successfully 
uploaded through Squid, but others can't?  If so, is there any noticeable 
difference (eg: size) between the ones whihc work and the ones which don't?


Regards,


Antony.

-- 
If you were ploughing a field, which would you rather use - two strong oxen or 
1024 chickens?

 - Seymour Cray, pioneer of supercomputing

                                                   Please reply to the list;
                                                         please *don't* CC me.


From alex at samad.com.au  Wed Dec  2 09:39:49 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 2 Dec 2015 20:39:49 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
Message-ID: <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>

Just to add to this I have a lot of these in the log file

TCP_MISS_ABORTED/000 0 RPC_IN_DATA
TCP_MISS_ABORTED/200 4322 RPC_OUT_DATA
TCP_MISS_ABORTED/000 0 RPC_IN_DATA https:






On 2 December 2015 at 17:24, Alex Samad <alex at samad.com.au> wrote:
> Hi
>
> recently upgraded to squid-3.5.11-1.el6.x86_64 from the centos 6.7  squid 3.1
>
>
> I am now having problems with people who use active sync via this
> connection . seems like emails with attachments aren't making it
> through .
>
> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
> originserver login=PASS front-end-https=on ssl
> sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.yx.com.crt
> sslkey=/etc/httpd/conf.d/office.yx.com.key name=exchangeServer
>
>
> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
> sslcert=/etc/httpd/conf.d/office.yx.com.crt
> sslkey=/etc/httpd/conf.d/office.yx.com.key name=webServer
> c
>
> # List of acceptable URLs to send to the Exchange server
> acl exch_url url_regex -i office.yieldbroker.com/exchange
> acl exch_url url_regex -i office.yieldbroker.com/exchweb
> acl exch_url url_regex -i office.yieldbroker.com/public
> acl exch_url url_regex -i office.yieldbroker.com/owa
> acl exch_url url_regex -i office.yieldbroker.com/ecp
> acl exch_url url_regex -i office.yieldbroker.com/microsoft-server-activesync
> acl exch_url url_regex -i office.yieldbroker.com/rpc
> acl exch_url url_regex -i office.yieldbroker.com/rpcwithcert
> acl exch_url url_regex -i office.yieldbroker.com/exadmin
> acl exch_url url_regex -i office.yieldbroker.com/oab
> # added after
> acl exch_url url_regex -i office.yieldbroker.com/ews
> # Not configured on exchange 2010
> #acl exch_url url_regex -i office.yieldbroker.com/autodiscover
>
> # Send the Exchange URLs to the Exchange server
> cache_peer_access exchangeServer allow exch_url
>
> # Send everything else to the Apache
> cache_peer_access webServer deny exch_url
>
> # This is to protect Squid
> never_direct allow exch_url
>
> # Logging Configuration
> redirect_rewrites_host_header off
> cache_mem 32 MB
> maximum_object_size_in_memory 128 KB
> cache_log none
> cache_store_log none
>
> access_log stdio:/var/log/squid/office-access.log squid
> #access_log none
> cache_log /var/log/squid/office-cache.log
> #cache_log none
> pid_filename /var/run/squid-office.pid
>
>
> # Set the hostname so that we can see Squid in the path (Optional)
> visible_hostname yieldbroker.com
> deny_info TCP_RESET all
>
> # ACL - required to allow
> #acl all src ALL
>
> # Allow everyone through, internal and external connections
> http_access allow all
> miss_access allow all
>
> icp_port 0
> snmp_port 0
>
> via off
>
>
> The previous setup had worked for at least 18 months.
>
> Alex


From fengsheng.10 at gmail.com  Wed Dec  2 10:54:11 2015
From: fengsheng.10 at gmail.com (=?UTF-8?B?6aOO5aOw?=)
Date: Wed, 2 Dec 2015 18:54:11 +0800
Subject: [squid-users] Squid memory leak on ubuntu 14.04
In-Reply-To: <CAJGZ0h6oTCu2OJqk8u-+X4eaeDiHyawg76xJPskjG=tfv-CESA@mail.gmail.com>
References: <CAJGZ0h4bmkcMF7V6WGsfh4uLB-by27t8esB0SnRjudFPVCTt9g@mail.gmail.com>
 <5658838F.7050707@urlfilterdb.com>
 <CAJGZ0h5s9k7txGMTN1tP4wdhKvkb=z_kuK8E5t5jwBpgKj8pUg@mail.gmail.com>
 <565BC47E.6070408@treenet.co.nz>
 <CAJGZ0h4AWgyHbwkujCiUpRPf8AbhegpdxaHzRVNuOCasd-Ho0w@mail.gmail.com>
 <565C0EFE.40904@treenet.co.nz>
 <CAJGZ0h6oTCu2OJqk8u-+X4eaeDiHyawg76xJPskjG=tfv-CESA@mail.gmail.com>
Message-ID: <CAJGZ0h5Cf0936+5i17UCVN7vm+Y=KPg_+bM0uK1fz1+kM0sv4Q@mail.gmail.com>

I think not only the kernel/malloc, also the libs (libmnl and libnetfilter)
squid depends on with ubuntu 14.04, we try to rebuild it, keep watching the
status.

2015-12-01 9:01 GMT+08:00 ?? <fengsheng.10 at gmail.com>:

> Hi
>
> Finally, we found the root cause, it is kernel issue with specific version
> on ubuntu 14.04.
>
> We prepared new environment for testing, 3.3.8?3.5.11?2.7 on ubuntu 12.04
> and 14.04.
>
> 3.3.8?3.5.11 on ubuntu 12.04 is ok
> 2.7 on ubuntu 14.04 is ok
>
> 3.3.8?3.5.11 on ubuntu 14.04 is abnormal.
>
>
> I found this
> https://bugs.launchpad.net/ubuntu/+source/linux-meta-lts-trusty/+bug/1516738
>
> and I downgrade kernel version to 3.13.0-57 on ubuntu 14.04, memory usage
> is normal now.
>
> I don't know how was it introduced into kernel on ubuntu 14.04, but it is
> really works for me.
>
> Thanks for you help .
>
>
>
>
>
> 2015-11-30 16:55 GMT+08:00 Amos Jeffries <squid3 at treenet.co.nz>:
>
>> On 30/11/2015 9:31 p.m., ?? wrote:
>> > We did not enable squid cache, so I think memory is ok for our case,
>> and we
>> > run squid servers (without cache, without cache cluster, just as forward
>> > proxy) more than 100 servers more than 1 years in AWS serveral regions
>> with
>> > EC2 c3.xlarge on ubuntu 12.04. It was always running well.
>> >
>> > Just after upgrade ubuntu 14.04, we found the memory usage increased.
>> >
>> > Server Spec: AWS EC2 c3.xlarge (4 Cores, 7.5GB Memory, 2 x 40 GB SSD)
>> >
>> > Before upgrade:
>> >
>> > 12.04:
>> > Memory usage is always less than 50% (3.5GB), will increase or decrease
>> > because traffic changes
>> > CPU is very low, same as Disk IO, B/W (In or Out) is 500Mb/s at most, is
>> > around 200Mb/s most of time.
>> >
>> > 14:04
>> > Memory usage is about 80-90 % (nearly 7GB), will increase , but it
>> decrease
>> > very slow, and always keeping more than 50% (3.5GB),
>> > CPU is very low, same as Disk IO, B/W (In or Out) is 500Mb/s at most, is
>> > around 200Mb/s most of time.
>> >
>> > I tested with squid-3.3.8 (ubuntu offical packages), and squid-3.5.11 on
>> > 12.04 and 14.04, I think it is most likely ubuntu related issue ?
>> because
>> > same version, same configs, but different OS versions.
>>
>> Most likely. Though a whole OS of difference has many moving parts. By
>> keeping Squid the same you have eliminated it specifically as the cause.
>> But all the libraries it uses will be different in each OS.
>>
>> If there was a 32-bit to 64-bit change in the hardware or memory
>> allocation system you could also see this same change.
>>
>> Amos
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151202/587c3983/attachment.htm>

From alex at samad.com.au  Wed Dec  2 11:30:15 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 2 Dec 2015 22:30:15 +1100
Subject: [squid-users] rollback squid
Message-ID: <CAJ+Q1PVVorWcOXnp1QeEhSbhoftKTzAZv1DCja71JB1w4v80GQ@mail.gmail.com>

Hi

I am rolling back from 3.5 to 3.1

my cache directory was updated for the 3.1 to 3.5.

Is there going to be an issue when i roll back ?


thanks
Alex


From supergeorge1234 at gmail.com  Wed Dec  2 14:27:24 2015
From: supergeorge1234 at gmail.com (supergeorge)
Date: Wed, 2 Dec 2015 06:27:24 -0800 (PST)
Subject: [squid-users] logformat in normal GMT time?
Message-ID: <1449066444877-4674954.post@n4.nabble.com>

is their a logformat i can use that displays time logs in actual time?  it's
such a pain to look thru log files and i would think there's an easy way to
switch the logging.  I hope i'm right. Thanx



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/logformat-in-normal-GMT-time-tp4674954.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Wed Dec  2 14:53:11 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 2 Dec 2015 15:53:11 +0100
Subject: [squid-users] logformat in normal GMT time?
In-Reply-To: <1449066444877-4674954.post@n4.nabble.com>
References: <1449066444877-4674954.post@n4.nabble.com>
Message-ID: <201512021553.11989.Antony.Stone@squid.open.source.it>

On Wednesday 02 December 2015 at 15:27:24, supergeorge wrote:

> is their a logformat i can use that displays time logs in actual time? 

http://www.squid-cache.org/Doc/config/logformat/ - see the section "Time 
related format codes".


Antony.

-- 
This sentence contains exacly three erors.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Wed Dec  2 16:03:35 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 05:03:35 +1300
Subject: [squid-users] rollback squid
In-Reply-To: <CAJ+Q1PVVorWcOXnp1QeEhSbhoftKTzAZv1DCja71JB1w4v80GQ@mail.gmail.com>
References: <CAJ+Q1PVVorWcOXnp1QeEhSbhoftKTzAZv1DCja71JB1w4v80GQ@mail.gmail.com>
Message-ID: <565F1657.5070407@treenet.co.nz>

On 3/12/2015 12:30 a.m., Alex Samad wrote:
> Hi
> 
> I am rolling back from 3.5 to 3.1
> 
> my cache directory was updated for the 3.1 to 3.5.
> 
> Is there going to be an issue when i roll back ?

Yes, you will have to discard the current cache and start with it empty.
The old Squid cannot cope with the new format.

Amos



From squid3 at treenet.co.nz  Wed Dec  2 16:22:43 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 05:22:43 +1300
Subject: [squid-users] setting up cache peering
In-Reply-To: <CAJ+Q1PV_LCzDDHcPdLkpZue7_OKNFoVZY5dbUo3mM2rXbHhg=w@mail.gmail.com>
References: <CAJ+Q1PV_LCzDDHcPdLkpZue7_OKNFoVZY5dbUo3mM2rXbHhg=w@mail.gmail.com>
Message-ID: <565F1AD3.3060601@treenet.co.nz>

On 2/12/2015 6:50 p.m., Alex Samad wrote:
> Hi
> 
> I recently moved to squid-3.5.11-1.el6.x86_64 on centos 6.7.
> 
> from the centos 3.1 i think ?
> 
> This what I had originall
> #cache_peer gsdmz1.xy.com sibling 3128 3130 proxy-only
> #cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only
> 
> I had a shared config between the 2 server gsdmz1 and alcdmz1. I would
> uncomment 1 or the other depending.
> 
> during my upgrade I coped the gsdmz1 squid config over to alcdmz1 but
> forgot to uncomment the
> cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only
> 
> so alcdmz1 was talking to itself at times.
> 
> using this as my test
> wget -d   http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
> -O /dev/null
> 
> and setting http_proxy to either alc or gsdmz1 I would get a 504 error.
> 
> 
> wget -d  http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
> -O /dev/null
> Setting --output-document (outputdocument) to /dev/null
> DEBUG output created by Wget 1.12 on linux-gnu.
> 
> --2015-12-02 16:35:34--
> http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
> Resolving alcdmz1... 10.3.2.111
> Caching alcdmz1 => 10.3.2.111
> Connecting to alcdmz1|10.3.2.111|:3128... connected.
> Created socket 4.
> Releasing 0x0000000001ea5db0 (new refcount 1).
> 
> ---request begin---
> GET http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
> HTTP/1.0
> User-Agent: Wget/1.12 (linux-gnu)
> Accept: */*
> Host: www.smh.com.au
> 
> ---request end---
> Proxy request sent, awaiting response...
> ---response begin---
> HTTP/1.1 504 Gateway Timeout
> Server: squid
> Mime-Version: 1.0
> Date: Wed, 02 Dec 2015 05:35:34 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 4063
> X-Squid-Error: ERR_ONLY_IF_CACHED_MISS 0
> Vary: Accept-Language
> Content-Language: en
> X-Cache: MISS from gsdmz1
> X-Cache-Lookup: MISS from gsdmz1:3128
> X-Cache: MISS from alcdmz1
> X-Cache-Lookup: MISS from alcdmz1:3128
> Via: 1.1 gsdmz1 (squid), 1.1 alcdmz1 (squid)
> Connection: close
> 
> ---response end---
> 504 Gateway Timeout
> Closed fd 4
> 2015-12-02 16:35:34 ERROR 504: Gateway Timeout.
> 

*timeout* is terribly bad. Turn the Via header back on. Its sole purpose
is to let the peers reject messages that are looping like that one.

> 
> I changed the line to be
> cache_peer gsdmz1.xy.com sibling 3128 3130 proxy-only standby=50
> on the alcdmz1 box
> and
> cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only standby=50
> on the gsdmz1 box
> 
> but this still gave me 504 errors ?

Notice how the difference in configurations is that you added
standby=50. It should not be having any effect that we know of, but does
mean that connections are pre-opened to the sibling and thus have a much
lower latency than any normal TCP connection. If your Squid is searching
for fastest-route using the netdb latency tables that could be the
opposite of what you need.

> I tried to force a new version through both proxies by using wget with
> no-cache option.  But that didn't help.

Sending "no-cache" from the client makes it worse, since that prevents
HIT from happening on either peer.

When combined with "cache_peer ... proxy-only" configuration it prevents
any traffic that goes through a peer from being cached.

> 
> So what went wrong, how can I flush out the stale 504.

It is not cached. There is nothing to flush (except perhapse the standby
connections, see above).

> What is the best way to setup the 2 proxies to talk to each other
> before going out to the internet.

That depends on the proxies, version, and what you want them to do.

> 
> the proxies run on a pacemaker cluster. I have 2 vip's setup as the
> proxy addresses, in normal conditions these address are setup 1 on
> each server. whilst working on a server I can move the vip and not
> affect any one.

What you have appears to be almost correct. Since you are dealing with
3.1 vs 3.5, you need to keep in mind the differences in behaviour
between HTTP/1.0 (3.1) and HTTP/1.1 (3.5).

One of the side effects is that the default peer query messaging is ICP
which does not work at all well with HTTP/1.1 Vary caching. HTCP was
designed to avoid those problems, but needs turning on explcicitly.

> 
> 
> But I would like to take benefit of each others cache, whats the best
> setup for cache_peer in this setup.
> 
> Neither server is closer to the internet.
> 


I suggest you:

1) add the "htcp" option to the cache_peer lines. So the peer selection
can use the full HTTP/1.1 headers to decide if the peer cached object is
actually usable.

2) Remove the "via off" from your config file.

3) remove the standby= parameter from cache_peer until you have at least
got the original setup working.


There might be other things involved, but we cant know that without the
details about those things existence or absence from your config.

Amos



From squid3 at treenet.co.nz  Wed Dec  2 16:30:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 05:30:10 +1300
Subject: [squid-users] deny_info / url_rewrite_program
In-Reply-To: <565DABF3.7090209@web.de>
References: <565DABF3.7090209@web.de>
Message-ID: <565F1C92.1080608@treenet.co.nz>

On 2/12/2015 3:17 a.m., Jens Kallup wrote:
> Hello,
> 
> bellow, a Perl script that works for me - it redirect the
> URL in browser; when i type in "web.de" the result is
> "www.freenet.de".
> But the browser don't connect to www.freenet.de,
> he shows me a Error: redirect-error - this problem can
> be, when Cookies deactivated or denied.
> (iceweasel - firefox)
> Is that a browser mistake or my logic?

Maybe both. If you are trying to redirect a CONNECT request or such.

HTTP is not the only protocol Browsers do these days, and the others
generally use CONNECT when going through a HTTP-only proxy like Squid.

Alternatively the browser message might be meaning to say that 301 is an
invalid status response for whatever application process it was
performing before starting to go to that URL. CONNECT is the usual one
due to HTTPS popularity these days, but the CORS and HSTS security
systems can also have sequences of HTTP messages that are expecting
specific non-3xx responses.

> 
> #!/usr/bin/perl -l
> 
> $|=1;                   # don't buffer stdout
> 
> while (<>) {            # read line from STDIN (squid input)
>   $url = m/^([^ ]*)/;
>   if ($url !~ /^http:\/\/web\.de/) {
>     print "301:http://www.freenet.de/index.html\n";
>   } else {
>     print "$url\n";
>   }
> }

That helper is using Squid-2 protocol syntax.

Squid is translating it to its own current syntax. But the helper should
really output the protocol its Squid is wanting to use.

Amos



From squid at bloms.de  Wed Dec  2 17:14:24 2015
From: squid at bloms.de (Dieter Bloms)
Date: Wed, 2 Dec 2015 18:14:24 +0100
Subject: [squid-users] assertion failed: client_side.cc:819:
 "areAllContextsForThisConnection()" after upgrade from 3.5.8 to 3.5.11
Message-ID: <20151202171424.GA15255@bloms.de>

Hello,

I did an upgrade from 3.5.8 to 3.5.11 and now sometimes I get the
message:

assertion failed: client_side.cc:819: "areAllContextsForThisConnection()"

in cache.log and squid dies.

Is this a known problem or shall I create a bugreport ?


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From yvoinov at gmail.com  Wed Dec  2 18:38:33 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 3 Dec 2015 00:38:33 +0600
Subject: [squid-users] logformat in normal GMT time?
In-Reply-To: <201512021553.11989.Antony.Stone@squid.open.source.it>
References: <1449066444877-4674954.post@n4.nabble.com>
 <201512021553.11989.Antony.Stone@squid.open.source.it>
Message-ID: <565F3AA9.4010100@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Just remember - some tools will not be able to recognize such a log
format. For example, squidview.

Those which originally designed the format of "epoch".

02.12.15 20:53, Antony Stone ?????:
> On Wednesday 02 December 2015 at 15:27:24, supergeorge wrote:
>
>> is their a logformat i can use that displays time logs in actual time?
>
> http://www.squid-cache.org/Doc/config/logformat/ - see the section "Time
> related format codes".
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWXzqpAAoJENNXIZxhPexG1GYH/0V+OqCLbPztVJaANu+iLTgb
574t/uNYm/ZvXh0qU/ljaKnJ5GD6eVmYB482CRuSZLr/meU4wwyXPHkZyDLUM1XF
2Tei0IwKxCCDeloXWXVEmRV3e+bunxbhHX5MEe0bFX6XNwOB6Wo4soMDzNME5Fme
stfhi6cJ3E1u4f8FDksmzFAFszPmdUp0CIgfucIy8IOVLiHP1x6O1pmx1Ve9pFOo
dFPYpQ/Qfft6JfRv8Bt/rAzvPL+7hYt5gwK7rk/Yk8PvtX4QG+nhUVpEZ3k6JJP9
3IjQRh+SNJYJxSbwziqr5lXzISmK1zgPeUmIVyk9Hh4UDqZNPz0t6rWiqBZHInE=
=LGLJ
-----END PGP SIGNATURE-----



From eliezer at ngtech.co.il  Wed Dec  2 18:42:19 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 2 Dec 2015 20:42:19 +0200
Subject: [squid-users] logformat in normal GMT time?
In-Reply-To: <565F3AA9.4010100@gmail.com>
References: <1449066444877-4674954.post@n4.nabble.com>
 <201512021553.11989.Antony.Stone@squid.open.source.it>
 <565F3AA9.4010100@gmail.com>
Message-ID: <565F3B8B.1000108@ngtech.co.il>

On 02/12/2015 20:38, Yuri Voinov wrote:
> Just remember - some tools will not be able to recognize such a log
> format. For example, squidview.
>
> Those which originally designed the format of "epoch".

But in the other hand it will be human readable.

Eliezer


From yvoinov at gmail.com  Wed Dec  2 18:43:15 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 3 Dec 2015 00:43:15 +0600
Subject: [squid-users] logformat in normal GMT time?
In-Reply-To: <565F3B8B.1000108@ngtech.co.il>
References: <1449066444877-4674954.post@n4.nabble.com>
 <201512021553.11989.Antony.Stone@squid.open.source.it>
 <565F3AA9.4010100@gmail.com> <565F3B8B.1000108@ngtech.co.il>
Message-ID: <565F3BC3.8010606@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Of course, but usually do not read logs eyes.

03.12.15 0:42, Eliezer Croitoru ?????:
> On 02/12/2015 20:38, Yuri Voinov wrote:
>> Just remember - some tools will not be able to recognize such a log
>> format. For example, squidview.
>>
>> Those which originally designed the format of "epoch".
>
> But in the other hand it will be human readable.
>
> Eliezer
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWXzvDAAoJENNXIZxhPexGMOEH/04GklsQjoLgqRxnuJIIV7Zy
q12EoVrk1Od4l1oKG55qvOm/QUr4uo4kQ5vqqYKziGmhROaxOQYhzpahlZqF54WG
Eu/QXzOs06Tfm2/PhTd7JuE7g7fdNegn/dR4QHPdh0xl8fV5kao9vEW7Gk2Tkv7g
4/VzpwxIanJfHrmA+5Oq1eXKUJGoYtqeThd73SiPXTDgaMtk2BETZG//NIUvkoTd
GroZXxniNuOx/QwdzOVNVBBSI+xLuuGEpszjvhahOjQreAvWHPT/H7KtCL0hm6RI
OdKm7Vn+qPflWT9UYySR7+PcMXfnTo7bfUE8hi/h4Ln/5XVPQK9caU43X4qCCyg=
=ju9J
-----END PGP SIGNATURE-----



From RBackes at bond.de  Wed Dec  2 19:12:51 2015
From: RBackes at bond.de (Rainer Backes)
Date: Wed, 02 Dec 2015 20:12:51 +0100
Subject: [squid-users] Kerberos-Authentication to AD 2012
Message-ID: <565F50C3020000AF0001EFE4@smtp-out.bond.de>

Hi,

I'm trying to build a Squid-Proxy that integrates with an Active
Directory - and I think I'm only one step from succeeding, but I still
get one error from negotiate_kerberos_auth.

Here is my config: (everything is hosted inside my VMware Workstation)
- Passwords here are only experimental.

Basic Installation

- Windows Server 2012R2 with default Active Directory, only one User:
me
- Windows 8.1/64 with IE and Firefox
- SLES 11 SP 4 as the Proxy

Squid Version: First I used the DBA Package available from OpenSuse
Build Service, this is 3.5.11. Then I downloaded the newest stable
source 3.5.12 and compliled it by myself (with configure options
--prefix=/usr/local/squid --with-included-ltdl ), OpenLdap and Kerberos
devel packages also installed from SLES11SP4 SDK. Error is the same on
both versions.

Preparation on Windows side: 

- Created user bsquid for the proxy, added SPN.
- with ktpass -princ HTTP/bsquid.bond.local at BOND.LOCAL -pass Sq1dcache
-mapuser bsquid -pType KRB5_NT_PRINCIPAL -crypto All -out bsquid.keytab
I build a keytab file that includes ALL available Crypto algorithms
(After I found out that 2012 uses AES256.... on default). Result from
command:
Targeting domain controller: W2K12-Squid.bond.local
Using legacy password setting method
Successfully mapped HTTP/bsquid.bond.local to bsquid.
Key created.
Key created.
Key created.
Key created.
Key created.
Output keytab to bsquid.keytab:
Keytab version: 0x502
keysize 60 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x1 (DES-CBC-CRC) keylength 8 (0x0
7cbdf6d7c8f0b75)
keysize 60 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x3 (DES-CBC-MD5) keylength 8 (0x0
7cbdf6d7c8f0b75)
keysize 68 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x17 (RC4-HMAC) keylength 16 (0xdc
2fdd6643b8e3e18184d38b989b6f87)
keysize 84 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x12 (AES256-SHA1) keylength 32 (0
x3cfb4221e4f8ce0c8ce6a2a4b231872b1fe979c013ee965be8469bac4fd0e9ec)
keysize 68 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x11 (AES128-SHA1) keylength 16 (0
xc32c8f7a8a039a7921148d863a5d6f78)

with this keytab a kinit from the SLES box works without errors.

The negotiate line from squid.conf is as follows:
auth_param negotiate program
/usr/local/squid/libexec/negotiate_kerberos_auth -d -s
HTTP/bsquid.bond.local	 

I also tried to add the Kerberos realm - that did not make any
difference.

My krb5.conf:

[libdefaults]
	    ticket_lifetime = 24000
	    default_realm = BOND.LOCAL
	    default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac
des-cbc-crc des-cbc-md5
	    default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac
des-cbc-crc des-cbc-md5
	    permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac
des-cbc-crc des-cbc-md5

;	    default_tkt_enctypes = rc4-hmac arcfour-hmac-md5 des-cbc-crc
des-cbc-md5
;	    default_tgs_enctypes = rc4-hmac arcfour-hmac-md5 des-cbc-crc
des-cbc-md5

[domain_realm]
	    .bond.local = BOND.LOCAL
	    bond.local = BOND.LOCAL

[realms]
	    BOND.LOCAL = {
			    kdc = w2k12-squid.bond.local
			    admin_server = w2k12-squid.bond.local
			    default_domain = bond.local
	    }

[logging]
    kdc = FILE:/var/log/krb5/krb5kdc.log
    admin_server = FILE:/var/log/krb5/kadmind.log
    default = FILE:/var/log/krb5/krb5libs.log
;    default = SYSLOG:NOTICE:DAEMON


Set the environment variable for the keytab and starting squid -N
inside a GUI-Window
bsquid:/usr/local/squid/sbin # export
KRB5_KTNAME=/usr/local/squid/etc/bsquid.keytab
bsquid:/usr/local/squid/sbin # ./squid -N



On the workstation tried to open a Website, get the following error:
negotiate_kerberos_auth.cc(487): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: INFO: Starting version 3.0.4sq
negotiate_kerberos_auth.cc(546): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: INFO: Setting keytab to
/usr/local/squid/etc/bsquid.keytab
negotiate_kerberos_auth.cc(610): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: DEBUG: Got 'YR
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'
from squid (length: 2155).
negotiate_kerberos_auth.cc(663): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: DEBUG: Decode
'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'
(decoded length: 1614).
negotiate_kerberos_auth.cc(180): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: ERROR: gss_acquire_cred() failed: Unspecified
GSS failure.  Minor code may provide more information. Permission
denied
2015/12/02 20:00:41| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: gss_acquire_cred() failed:
Unspecified GSS failure.  Minor code may provide more information.
Permission denied; }}

In the same GUI window, negotiate_kerberos_auth_test works:

bsquid:/usr/local/squid/sbin #
/usr/local/squid/libexec/negotiate_kerberos_auth_test bsquid.bond.local
| awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' |
/usr/local/squid/libexec/negotiate_kerberos_auth -d  -s
HTTP/bsquid.bond.local
negotiate_kerberos_auth.cc(487): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: INFO: Starting version 3.0.4sq
negotiate_kerberos_auth.cc(546): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: INFO: Setting keytab to
/usr/local/squid/etc/bsquid.keytab
negotiate_kerberos_auth.cc(610): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: DEBUG: Got 'YR
YIIFOQYGKwYBBQUCoIIFLTCCBSmgHzAdBgkqhkiG9xIBAgIGBSsFAQUCBgkqhkiC9xIBAgKiggUEBIIFAGCCBPwGCSqGSIb3EgECAgEAboIE6zCCBOegAwIBBaEDAgEOogcDBQAAAAAAo4ID/mGCA/owggP2oAMCAQWhDBsKQk9ORC5MT0NBTKIkMCKgAwIBA6EbMBkbBEhUVFAbEWJzcXVpZC5ib25kLmxvY2Fso4IDuTCCA7WgAwIBEqEDAgEKooIDpwSCA6Mf94bC+59KaQjsnQcWkXVcQknzpZjaEaz7bbGPyUlvR+ac8Y+z7vp0807CtBysvSMTgRCU+ghgUculGmncFwXSHoIpjCAg1faW/+COorCBjnBsOGzy3/sHUstVgnT/+cbqVBk/8f2v5b7k/VmejnADQyP/8T2yphyA9xBRaPOnjQiqtVFeheVnDA3+6X8bR+IlHCC7c/KJJBFUO/nRbM7lnb2yzW/nLVHaYlzw3+o5MiKu1FYdSLGil5jFIxjhqUzOpf87Z1ax/Ojzco3gVZxSDvRNp6EJ5Nea7LVESNQGto24Cru2ae4lO0oXe7An8VFHm4tVikvZQzHprNgUQITQlVzQ0CjztGuFpIrw/xt/ie5K5XziH76YaAxpzaiVfXG02V5pdY2ntSvVN/+IqSwQ8iRxkB+ZUQdLy0gR5dPXgjW/lU2NNWcAvfJWszf8y7hzu85GCy+fQXfRMY0g6CgsUncFmQy+x6E74Ft5XD/qOnW+66+HAxA6pmzBRvos9+drul3RQvVaGwaDo5Z86bKERZFKz02tmQUXFt+fEtqAqYXfsiXKq/HmxpZF3XklrQhoolGS41JTfhDmKeN4NtQYBM/pDMCo0HYWNMKthHvKXDhhLuu+WlT41vw5fl+uDiBOEOkVMhVsxe4M+Qsdj1z/DDqBgrVpYOcSF/rTC+8wETuciuUpZKecZkhLeT3VdIYMzNnhwSBG00bktICxPTuRXZC+Qfp+E+gsGk37r7bArYxtbjHjhj3WRkRTqfk11/6j6Bq0EDZV/o1OYOSulcuXulPTKCpQ209sJJmKEqjVgdFq697HIdC1eB7m9jETJH8YzqVLx500DEDipj8VeDLyxWPcM5P4HKeLTyMxjW72nZwlSBfbpIO2ogh6j5X0+f4/nuGW43/kX7LG9K+7NoRWofmasE2fUjq2NgbL+Qg5r4nfL3byE+LR5tg5xz9tUe+WYq+FpS4HSqfcxxUhDadXW2RgKsohNR3+cqBI0jDS/IcHu8LnicRuIVIJes2Bpf3KnThA9JqlUI5GcySWKvA4S7SOvSRvqipoA412/OMiUA4JSkV98BAFZaYt5+x6TswIMAz+xngrr39oWSrnnuem7A7vOwaG2pAa4rnQlBMKWZCztO7GLjQDeJyjNFDdyhT5tM31t0gvfH1seulRlAMXR8SJrraj320For2iVZK9d9+Op2xgsfb1VfPNBoIw+LuCpAIvwdL+PgtLcXUUxdklXkhTpIHPMIHMoAMCARKigcQEgcFbbiCFd2nHRDkZiUP7oFMEf3xmoeg7/fTpZT/VUpyFeVqzKZyBt3g6WLlFa++rlZm8aRxh65oKYk6ptRZcqje02XmhQpfRkZG4+NRiu175DgGvk4pNsZfPQSKxAP1WDZ2jVRy4U5+R49NbLodhRh0KFV9R4fug30x8uxQAJVTYu952i1mrx+PD/yS6UT2KLeDpVqfFtpnlVxeYjgK7hJoLb0qgN0fJbQDEqM9vrZ396z27pNOZXI7wa06I7roQFSlZ'
from squid (length: 1791).
negotiate_kerberos_auth.cc(663): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: DEBUG: Decode
'YIIFOQYGKwYBBQUCoIIFLTCCBSmgHzAdBgkqhkiG9xIBAgIGBSsFAQUCBgkqhkiC9xIBAgKiggUEBIIFAGCCBPwGCSqGSIb3EgECAgEAboIE6zCCBOegAwIBBaEDAgEOogcDBQAAAAAAo4ID/mGCA/owggP2oAMCAQWhDBsKQk9ORC5MT0NBTKIkMCKgAwIBA6EbMBkbBEhUVFAbEWJzcXVpZC5ib25kLmxvY2Fso4IDuTCCA7WgAwIBEqEDAgEKooIDpwSCA6Mf94bC+59KaQjsnQcWkXVcQknzpZjaEaz7bbGPyUlvR+ac8Y+z7vp0807CtBysvSMTgRCU+ghgUculGmncFwXSHoIpjCAg1faW/+COorCBjnBsOGzy3/sHUstVgnT/+cbqVBk/8f2v5b7k/VmejnADQyP/8T2yphyA9xBRaPOnjQiqtVFeheVnDA3+6X8bR+IlHCC7c/KJJBFUO/nRbM7lnb2yzW/nLVHaYlzw3+o5MiKu1FYdSLGil5jFIxjhqUzOpf87Z1ax/Ojzco3gVZxSDvRNp6EJ5Nea7LVESNQGto24Cru2ae4lO0oXe7An8VFHm4tVikvZQzHprNgUQITQlVzQ0CjztGuFpIrw/xt/ie5K5XziH76YaAxpzaiVfXG02V5pdY2ntSvVN/+IqSwQ8iRxkB+ZUQdLy0gR5dPXgjW/lU2NNWcAvfJWszf8y7hzu85GCy+fQXfRMY0g6CgsUncFmQy+x6E74Ft5XD/qOnW+66+HAxA6pmzBRvos9+drul3RQvVaGwaDo5Z86bKERZFKz02tmQUXFt+fEtqAqYXfsiXKq/HmxpZF3XklrQhoolGS41JTfhDmKeN4NtQYBM/pDMCo0HYWNMKthHvKXDhhLuu+WlT41vw5fl+uDiBOEOkVMhVsxe4M+Qsdj1z/DDqBgrVpYOcSF/rTC+8wETuciuUpZKecZkhLeT3VdIYMzNnhwSBG00bktICxPTuRXZC+Qfp+E+gsGk37r7bArYxtbjHjhj3WRkRTqfk11/6j6Bq0EDZV/o1OYOSulcuXulPTKCpQ209sJJmKEqjVgdFq697HIdC1eB7m9jETJH8YzqVLx500DEDipj8VeDLyxWPcM5P4HKeLTyMxjW72nZwlSBfbpIO2ogh6j5X0+f4/nuGW43/kX7LG9K+7NoRWofmasE2fUjq2NgbL+Qg5r4nfL3byE+LR5tg5xz9tUe+WYq+FpS4HSqfcxxUhDadXW2RgKsohNR3+cqBI0jDS/IcHu8LnicRuIVIJes2Bpf3KnThA9JqlUI5GcySWKvA4S7SOvSRvqipoA412/OMiUA4JSkV98BAFZaYt5+x6TswIMAz+xngrr39oWSrnnuem7A7vOwaG2pAa4rnQlBMKWZCztO7GLjQDeJyjNFDdyhT5tM31t0gvfH1seulRlAMXR8SJrraj320For2iVZK9d9+Op2xgsfb1VfPNBoIw+LuCpAIvwdL+PgtLcXUUxdklXkhTpIHPMIHMoAMCARKigcQEgcFbbiCFd2nHRDkZiUP7oFMEf3xmoeg7/fTpZT/VUpyFeVqzKZyBt3g6WLlFa++rlZm8aRxh65oKYk6ptRZcqje02XmhQpfRkZG4+NRiu175DgGvk4pNsZfPQSKxAP1WDZ2jVRy4U5+R49NbLodhRh0KFV9R4fug30x8uxQAJVTYu952i1mrx+PD/yS6UT2KLeDpVqfFtpnlVxeYjgK7hJoLb0qgN0fJbQDEqM9vrZ396z27pNOZXI7wa06I7roQFSlZ'
(decoded length: 1341).
AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== rbackes at BOND.LOCAL
negotiate_kerberos_auth.cc(783): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: DEBUG: AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg==
rbackes at BOND.LOCAL
negotiate_kerberos_auth.cc(610): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: DEBUG: Got 'QQ' from squid (length: 2).
BH quit command
bsquid:/usr/local/squid/sbin # 

The Windows client has some kerberos tickets avail:
C:\Windows\system32>klist

Aktuelle Anmelde-ID ist 0:0x37b196

Zwischengespeicherte Tickets: (4)

#0>	 Client: RBackes @ BOND.LOCAL
	    Server: krbtgt/BOND.LOCAL @ BOND.LOCAL
	    KerbTicket (Verschl?sselungstyp): AES-256-CTS-HMAC-SHA1-96
	    Ticketkennzeichen 0x40e10000 -> forwardable renewable
initial pre_authent name_canonicalize
	    Startzeit: 12/2/2015 18:39:42 (lokal)
	    Endzeit:   12/3/2015 4:39:42 (lokal)
	    Erneuerungszeit: 12/9/2015 18:39:42 (lokal)
	    Sitzungsschl?sseltyp: AES-256-CTS-HMAC-SHA1-96
	    Cachekennzeichen: 0x1 -> PRIMARY
	    KDC aufgerufen: W2K12-SQUID

#1>	 Client: RBackes @ BOND.LOCAL
	    Server: HTTP/bsquid.bond.local @ BOND.LOCAL
	    KerbTicket (Verschl?sselungstyp): AES-256-CTS-HMAC-SHA1-96
	    Ticketkennzeichen 0x40a10000 -> forwardable renewable
pre_authent name_canonicalize
	    Startzeit: 12/2/2015 18:39:46 (lokal)
	    Endzeit:   12/3/2015 4:39:42 (lokal)
	    Erneuerungszeit: 12/9/2015 18:39:42 (lokal)
	    Sitzungsschl?sseltyp: AES-256-CTS-HMAC-SHA1-96
	    Cachekennzeichen: 0
	    KDC aufgerufen: W2K12-Squid.bond.local

#2>	 Client: RBackes @ BOND.LOCAL
	    Server: ldap/W2K12-Squid.bond.local @ BOND.LOCAL
	    KerbTicket (Verschl?sselungstyp): AES-256-CTS-HMAC-SHA1-96
	    Ticketkennzeichen 0x40a50000 -> forwardable renewable
pre_authent ok_as_delegate name_canonicalize
	    Startzeit: 12/2/2015 18:39:44 (lokal)
	    Endzeit:   12/3/2015 4:39:42 (lokal)
	    Erneuerungszeit: 12/9/2015 18:39:42 (lokal)
	    Sitzungsschl?sseltyp: AES-256-CTS-HMAC-SHA1-96
	    Cachekennzeichen: 0
	    KDC aufgerufen: W2K12-Squid.bond.local

#3>	 Client: RBackes @ BOND.LOCAL
	    Server: LDAP/W2K12-Squid.bond.local/bond.local @ BOND.LOCAL
	    KerbTicket (Verschl?sselungstyp): AES-256-CTS-HMAC-SHA1-96
	    Ticketkennzeichen 0x40a50000 -> forwardable renewable
pre_authent ok_as_delegate name_canonicalize
	    Startzeit: 12/2/2015 18:39:44 (lokal)
	    Endzeit:   12/3/2015 4:39:42 (lokal)
	    Erneuerungszeit: 12/9/2015 18:39:42 (lokal)
	    Sitzungsschl?sseltyp: AES-256-CTS-HMAC-SHA1-96
	    Cachekennzeichen: 0
	    KDC aufgerufen: W2K12-Squid.bond.local

C:\Windows\system32>


Anyone an idea ?

Thanks, Rainer



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151202/83136cdd/attachment.htm>

From alex at samad.com.au  Wed Dec  2 20:18:38 2015
From: alex at samad.com.au (Alex Samad)
Date: Thu, 3 Dec 2015 07:18:38 +1100
Subject: [squid-users] rollback squid
In-Reply-To: <565F1657.5070407@treenet.co.nz>
References: <CAJ+Q1PVVorWcOXnp1QeEhSbhoftKTzAZv1DCja71JB1w4v80GQ@mail.gmail.com>
 <565F1657.5070407@treenet.co.nz>
Message-ID: <CAJ+Q1PWegD4VEx9MFqqy4THKVE4rUA0r_3_i_VJS3-H6VuOuNw@mail.gmail.com>

Discard you mean delete .. the cache directories

if so

I currently have 3 directories, is this an opportunity to consolidate
down to 1 directory is that better ?

On 3 December 2015 at 03:03, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 3/12/2015 12:30 a.m., Alex Samad wrote:
>> Hi
>>
>> I am rolling back from 3.5 to 3.1
>>
>> my cache directory was updated for the 3.1 to 3.5.
>>
>> Is there going to be an issue when i roll back ?
>
> Yes, you will have to discard the current cache and start with it empty.
> The old Squid cannot cope with the new format.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From alex at samad.com.au  Wed Dec  2 20:20:49 2015
From: alex at samad.com.au (Alex Samad)
Date: Thu, 3 Dec 2015 07:20:49 +1100
Subject: [squid-users] setting up cache peering
In-Reply-To: <565F1AD3.3060601@treenet.co.nz>
References: <CAJ+Q1PV_LCzDDHcPdLkpZue7_OKNFoVZY5dbUo3mM2rXbHhg=w@mail.gmail.com>
 <565F1AD3.3060601@treenet.co.nz>
Message-ID: <CAJ+Q1PXk84C+CjULsicq_9XP3OQnm2qfWSOM8JR=UCCHHostAQ@mail.gmail.com>

Hi

Thanks I will do when I get back to 3.5. Had to roll back because of
my issues with 3.5 and reverse proxy and outlook.

Are these suggestions still valid with 3.1 ?

Thanks

On 3 December 2015 at 03:22, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 2/12/2015 6:50 p.m., Alex Samad wrote:
>> Hi
>>
>> I recently moved to squid-3.5.11-1.el6.x86_64 on centos 6.7.
>>
>> from the centos 3.1 i think ?
>>
>> This what I had originall
>> #cache_peer gsdmz1.xy.com sibling 3128 3130 proxy-only
>> #cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only
>>
>> I had a shared config between the 2 server gsdmz1 and alcdmz1. I would
>> uncomment 1 or the other depending.
>>
>> during my upgrade I coped the gsdmz1 squid config over to alcdmz1 but
>> forgot to uncomment the
>> cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only
>>
>> so alcdmz1 was talking to itself at times.
>>
>> using this as my test
>> wget -d   http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
>> -O /dev/null
>>
>> and setting http_proxy to either alc or gsdmz1 I would get a 504 error.
>>
>>
>> wget -d  http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
>> -O /dev/null
>> Setting --output-document (outputdocument) to /dev/null
>> DEBUG output created by Wget 1.12 on linux-gnu.
>>
>> --2015-12-02 16:35:34--
>> http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
>> Resolving alcdmz1... 10.3.2.111
>> Caching alcdmz1 => 10.3.2.111
>> Connecting to alcdmz1|10.3.2.111|:3128... connected.
>> Created socket 4.
>> Releasing 0x0000000001ea5db0 (new refcount 1).
>>
>> ---request begin---
>> GET http://www.smh.com.au/business/markets-live/markets-live-investors-take-stock-20151201-gld1lu.html
>> HTTP/1.0
>> User-Agent: Wget/1.12 (linux-gnu)
>> Accept: */*
>> Host: www.smh.com.au
>>
>> ---request end---
>> Proxy request sent, awaiting response...
>> ---response begin---
>> HTTP/1.1 504 Gateway Timeout
>> Server: squid
>> Mime-Version: 1.0
>> Date: Wed, 02 Dec 2015 05:35:34 GMT
>> Content-Type: text/html;charset=utf-8
>> Content-Length: 4063
>> X-Squid-Error: ERR_ONLY_IF_CACHED_MISS 0
>> Vary: Accept-Language
>> Content-Language: en
>> X-Cache: MISS from gsdmz1
>> X-Cache-Lookup: MISS from gsdmz1:3128
>> X-Cache: MISS from alcdmz1
>> X-Cache-Lookup: MISS from alcdmz1:3128
>> Via: 1.1 gsdmz1 (squid), 1.1 alcdmz1 (squid)
>> Connection: close
>>
>> ---response end---
>> 504 Gateway Timeout
>> Closed fd 4
>> 2015-12-02 16:35:34 ERROR 504: Gateway Timeout.
>>
>
> *timeout* is terribly bad. Turn the Via header back on. Its sole purpose
> is to let the peers reject messages that are looping like that one.
>
>>
>> I changed the line to be
>> cache_peer gsdmz1.xy.com sibling 3128 3130 proxy-only standby=50
>> on the alcdmz1 box
>> and
>> cache_peer alcdmz1.xy.com sibling 3128 3130 proxy-only standby=50
>> on the gsdmz1 box
>>
>> but this still gave me 504 errors ?
>
> Notice how the difference in configurations is that you added
> standby=50. It should not be having any effect that we know of, but does
> mean that connections are pre-opened to the sibling and thus have a much
> lower latency than any normal TCP connection. If your Squid is searching
> for fastest-route using the netdb latency tables that could be the
> opposite of what you need.
>
>> I tried to force a new version through both proxies by using wget with
>> no-cache option.  But that didn't help.
>
> Sending "no-cache" from the client makes it worse, since that prevents
> HIT from happening on either peer.
>
> When combined with "cache_peer ... proxy-only" configuration it prevents
> any traffic that goes through a peer from being cached.
>
>>
>> So what went wrong, how can I flush out the stale 504.
>
> It is not cached. There is nothing to flush (except perhapse the standby
> connections, see above).
>
>> What is the best way to setup the 2 proxies to talk to each other
>> before going out to the internet.
>
> That depends on the proxies, version, and what you want them to do.
>
>>
>> the proxies run on a pacemaker cluster. I have 2 vip's setup as the
>> proxy addresses, in normal conditions these address are setup 1 on
>> each server. whilst working on a server I can move the vip and not
>> affect any one.
>
> What you have appears to be almost correct. Since you are dealing with
> 3.1 vs 3.5, you need to keep in mind the differences in behaviour
> between HTTP/1.0 (3.1) and HTTP/1.1 (3.5).
>
> One of the side effects is that the default peer query messaging is ICP
> which does not work at all well with HTTP/1.1 Vary caching. HTCP was
> designed to avoid those problems, but needs turning on explcicitly.
>
>>
>>
>> But I would like to take benefit of each others cache, whats the best
>> setup for cache_peer in this setup.
>>
>> Neither server is closer to the internet.
>>
>
>
> I suggest you:
>
> 1) add the "htcp" option to the cache_peer lines. So the peer selection
> can use the full HTTP/1.1 headers to decide if the peer cached object is
> actually usable.
>
> 2) Remove the "via off" from your config file.
>
> 3) remove the standby= parameter from cache_peer until you have at least
> got the original setup working.
>
>
> There might be other things involved, but we cant know that without the
> details about those things existence or absence from your config.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From nkelly at citrusnetworks.net  Wed Dec  2 21:10:52 2015
From: nkelly at citrusnetworks.net (Noel Kelly)
Date: Wed, 2 Dec 2015 21:10:52 +0000
Subject: [squid-users] ntlm_auth defaulting to succeed
Message-ID: <565F5E5C.1000103@citrusnetworks.net>

Hello All

We have been using Squid and ntlm_auth for many years with mainly 
success.  However we have always had a few annoyances like continual 
authentication pop-ups if a user has changed their password and not 
restarted their session or, as now, persistent popups which seem related 
to a browser update (Google Chrome is the suspect currently).

It occurred to me that thee days we don't use ntlm_auth to block 
Internet access per se but rather to capture the username to manage 
access using ACLs  and the username.

So I was wondering if anyone had any ideas for a Squid config where the 
ntlm_auth helper always succeeded regardless of the password  so they 
user gets waived through and Squid has the username needed to process 
the ACLs?

Thanks
Noel



From vze2k3sa at verizon.net  Wed Dec  2 22:28:58 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Wed, 02 Dec 2015 17:28:58 -0500
Subject: [squid-users] Windows Uninstall to Update
Message-ID: <019b01d12d50$d6a1da20$83e58e60$@verizon.net>

Hi,

 

When I uninstalled Squid 3.5.10, my squid.conf file got deleted by the
uninstall. Is this a bug or by design? I guess this question is for Rafael
of Diladele who very generously creates Windows binaries for people like me.
Thank you Rafael, very much appreciated.

 

-Patrick

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151202/b1111934/attachment.htm>

From rafael.akchurin at diladele.com  Wed Dec  2 22:42:17 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 2 Dec 2015 22:42:17 +0000
Subject: [squid-users] Windows Uninstall to Update
In-Reply-To: <019b01d12d50$d6a1da20$83e58e60$@verizon.net>
References: <019b01d12d50$d6a1da20$83e58e60$@verizon.net>
Message-ID: <VI1PR04MB135930C089065B10C8A176AC8F0E0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hi Patrick,

Currently the MSI installer removes everything it installs. It is the default behavior of Wix.
I have created a bug, see here https://github.com/diladele/squid3-windows/issues/52

This should be fixed in the next release of the installer (containing 3.5.12)

Thank you for reporting this!

Best regards,
Rafael Akchurin
Diladele B.V.

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy
http://www.diladele.com
http://www.quintolabs.com




From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Patrick Flaherty
Sent: Wednesday, December 2, 2015 11:29 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Windows Uninstall to Update

Hi,

When I uninstalled Squid 3.5.10, my squid.conf file got deleted by the uninstall. Is this a bug or by design? I guess this question is for Rafael of Diladele who very generously creates Windows binaries for people like me. Thank you Rafael, very much appreciated.

-Patrick

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151202/287a2afe/attachment.htm>

From vze2k3sa at verizon.net  Wed Dec  2 23:42:21 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Wed, 02 Dec 2015 18:42:21 -0500
Subject: [squid-users] DNS Socket Created
Message-ID: <01a601d12d5b$1707b530$45171f90$@verizon.net>

Hello,

 

What does Squid open Sockets for? (As shown below)

 

2015/12/02 17:20:53 kid1| DNS Socket created at [::], FD 5

2015/12/02 17:20:53 kid1| DNS Socket created at 0.0.0.0, FD 6

 

Thanks,

Patrick

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151202/64f4f744/attachment.htm>

From vze2k3sa at verizon.net  Wed Dec  2 23:43:35 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Wed, 02 Dec 2015 18:43:35 -0500
Subject: [squid-users] Disabling IP6 in 3.5.x
Message-ID: <01ab01d12d5b$434e8bf0$c9eba3d0$@verizon.net>

Hello,

 

Is there a way to disable IP6 in the 3.5.x Squid builds?

 

Thanks

Patrick

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151202/1a81871c/attachment.htm>

From vze2k3sa at verizon.net  Wed Dec  2 23:54:26 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Wed, 02 Dec 2015 18:54:26 -0500
Subject: [squid-users] SQUID_ERR_SSL_HANDSHAKE
Message-ID: <01b101d12d5c$c725a7f0$5570f7d0$@verizon.net>

Hi,

 

Doing some debugging (ALL,9) and looking at the cache log just after
starting the Squid Windows Service and I see the following error. Can anyone
help with what this means? Is it a misconfiguration?

 

Thanks

Patrick

 

name: SQUID_ERR_SSL_HANDSHAKE

detail: "%ssl_error_descr: %ssl_lib_error"

descr: "Handshake with SSL server failed"

 

 

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1656) parse: parsing
HttpHeaderEntry: near 'name: SQUID_ERR_SSL_HANDSHAKE'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1698) parse: parsed
HttpHeaderEntry: 'name: SQUID_ERR_SSL_HANDSHAKE'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1599) HttpHeaderEntry:
created HttpHeaderEntry 0x600259920: 'name : SQUID_ERR_SSL_HANDSHAKE

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(981) addEntry: 0x2390e0
adding entry: 85 at 0

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1656) parse: parsing
HttpHeaderEntry: near 'detail: "%ssl_error_descr: %ssl_lib_error"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1698) parse: parsed
HttpHeaderEntry: 'detail: "%ssl_error_descr: %ssl_lib_error"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1599) HttpHeaderEntry:
created HttpHeaderEntry 0x6002599c0: 'detail : "%ssl_error_descr:
%ssl_lib_error"

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(981) addEntry: 0x2390e0
adding entry: 85 at 1

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1656) parse: parsing
HttpHeaderEntry: near 'descr: "Handshake with SSL server failed"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1698) parse: parsed
HttpHeaderEntry: 'descr: "Handshake with SSL server failed"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1599) HttpHeaderEntry:
created HttpHeaderEntry 0x600259a60: 'descr : "Handshake with SSL server
failed"

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(981) addEntry: 0x2390e0
adding entry: 85 at 2

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1201) has: 0x2390e0 lookup
for 62

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(480) clean: cleaning hdr:
0x2390e0 owner: 4

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1605) ~HttpHeaderEntry:
destroying entry 0x600259920: 'name: SQUID_ERR_SSL_HANDSHAKE'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1605) ~HttpHeaderEntry:
destroying entry 0x6002599c0: 'detail: "%ssl_error_descr: %ssl_lib_error"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1605) ~HttpHeaderEntry:
destroying entry 0x600259a60: 'descr: "Handshake with SSL server failed"'

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(446) HttpHeader: init-ing
hdr: 0x2390e0 owner: 4

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(597) parse: parsing hdr:
(0x2390e0)

name: SQUID_X509_V_ERR_DOMAIN_MISMATCH

detail: "%ssl_error_descr: %ssl_subject"

descr: "Certificate does not match domainname"

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151202/1c902506/attachment.htm>

From marciobacci at gmail.com  Thu Dec  3 03:15:59 2015
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Thu, 3 Dec 2015 01:15:59 -0200
Subject: [squid-users] doubts about the squid3
Message-ID: <CA+0TdyqipgBeMAscVKGeMvTkY1L_Di-3Or3f=LZJcW2y65jjhw@mail.gmail.com>

My Linux Stations are in Domain, but when a user open your bowser, the user
and password are asked. Sometimes, during the navegation, the user and
password are asked again.

This way, I wish that the user session to be valid per 4 hours. How do I
set it?

Follow the authentication portion of the  my squid.conf:

# NTLM
auth_param ntlm program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp  --domain=DOMAIN
auth_param ntlm children 30
auth_param ntlm keep_alive off

 #BASIC
auth_param basic program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-basic
auth_param basic children 5
auth_param basic realm "Web Proxy"
external_acl_type ad_group %LOGIN /usr/lib/squid3/wbinfo_group.pl -d

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151203/e983760c/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec  3 03:27:55 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 16:27:55 +1300
Subject: [squid-users] rollback squid
In-Reply-To: <CAJ+Q1PWegD4VEx9MFqqy4THKVE4rUA0r_3_i_VJS3-H6VuOuNw@mail.gmail.com>
References: <CAJ+Q1PVVorWcOXnp1QeEhSbhoftKTzAZv1DCja71JB1w4v80GQ@mail.gmail.com>
 <565F1657.5070407@treenet.co.nz>
 <CAJ+Q1PWegD4VEx9MFqqy4THKVE4rUA0r_3_i_VJS3-H6VuOuNw@mail.gmail.com>
Message-ID: <565FB6BB.50406@treenet.co.nz>

On 3/12/2015 9:18 a.m., Alex Samad wrote:
> Discard you mean delete .. the cache directories
> 

Yes, and redo the squid -z process to partition new one(s).

> if so
> 
> I currently have 3 directories, is this an opportunity to consolidate
> down to 1 directory is that better ?

Another tricky question with "it depends" as the answer.

If you have a fast (Gbit) network and want lowest latency possible,
removing cache_dir entirely is best. But you will pay for latency gains
in bandwidth from the lower HIT ratio.

If the cache_dir are of UFS/AUFS/diskd type and on the same HDD. Then
there will definitely be speed gains from removing 2 of them. If they
are on different HDD disk/spindles then you only gain if the removed
ones have slow RPM speeds, commonly have errors, or are in use a lot by
other processes.

Amos




From alex at samad.com.au  Thu Dec  3 03:44:25 2015
From: alex at samad.com.au (Alex Samad)
Date: Thu, 3 Dec 2015 14:44:25 +1100
Subject: [squid-users] rollback squid
In-Reply-To: <565FB6BB.50406@treenet.co.nz>
References: <CAJ+Q1PVVorWcOXnp1QeEhSbhoftKTzAZv1DCja71JB1w4v80GQ@mail.gmail.com>
 <565F1657.5070407@treenet.co.nz>
 <CAJ+Q1PWegD4VEx9MFqqy4THKVE4rUA0r_3_i_VJS3-H6VuOuNw@mail.gmail.com>
 <565FB6BB.50406@treenet.co.nz>
Message-ID: <CAJ+Q1PUkPsKTr6tVRXNDqmNMnK_kT8F0g2A7iYZBTwt75HO8RA@mail.gmail.com>

:)

Okay done

is a VM on a single VMDK..
10G nics (virtual and physical)



On 3 December 2015 at 14:27, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 3/12/2015 9:18 a.m., Alex Samad wrote:
>> Discard you mean delete .. the cache directories
>>
>
> Yes, and redo the squid -z process to partition new one(s).
>
>> if so
>>
>> I currently have 3 directories, is this an opportunity to consolidate
>> down to 1 directory is that better ?
>
> Another tricky question with "it depends" as the answer.
>
> If you have a fast (Gbit) network and want lowest latency possible,
> removing cache_dir entirely is best. But you will pay for latency gains
> in bandwidth from the lower HIT ratio.
>
> If the cache_dir are of UFS/AUFS/diskd type and on the same HDD. Then
> there will definitely be speed gains from removing 2 of them. If they
> are on different HDD disk/spindles then you only gain if the removed
> ones have slow RPM speeds, commonly have errors, or are in use a lot by
> other processes.
>
> Amos
>
>


From gkinkie at gmail.com  Thu Dec  3 05:19:53 2015
From: gkinkie at gmail.com (Kinkie)
Date: Thu, 3 Dec 2015 06:19:53 +0100
Subject: [squid-users] ntlm_auth defaulting to succeed
In-Reply-To: <565F5E5C.1000103@citrusnetworks.net>
References: <565F5E5C.1000103@citrusnetworks.net>
Message-ID: <CA+Y8hcMYgdkMLN0dYVdh4wCSgSqWAM=fHySb21KgmTRYFpjWhQ@mail.gmail.com>

Hi,
  you can check the ntlm_fake_auth helper; it'll blandly trust
anything the user says.

On Wed, Dec 2, 2015 at 10:10 PM, Noel Kelly <nkelly at citrusnetworks.net> wrote:
> Hello All
>
> We have been using Squid and ntlm_auth for many years with mainly success.
> However we have always had a few annoyances like continual authentication
> pop-ups if a user has changed their password and not restarted their session
> or, as now, persistent popups which seem related to a browser update (Google
> Chrome is the suspect currently).
>
> It occurred to me that thee days we don't use ntlm_auth to block Internet
> access per se but rather to capture the username to manage access using ACLs
> and the username.
>
> So I was wondering if anyone had any ideas for a Squid config where the
> ntlm_auth helper always succeeded regardless of the password  so they user
> gets waived through and Squid has the username needed to process the ACLs?
>
> Thanks
> Noel
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From gkinkie at gmail.com  Thu Dec  3 05:22:54 2015
From: gkinkie at gmail.com (Kinkie)
Date: Thu, 3 Dec 2015 06:22:54 +0100
Subject: [squid-users] Disabling IP6 in 3.5.x
In-Reply-To: <01ab01d12d5b$434e8bf0$c9eba3d0$@verizon.net>
References: <01ab01d12d5b$434e8bf0$c9eba3d0$@verizon.net>
Message-ID: <CA+Y8hcM9NyKhFVGXEZLC4Bb=9E+Bm-7twSokH5gLoSnY99y1zg@mail.gmail.com>

Hi Patrick,
   ./configure --disable-ipv6 <other arguments>

will do the trick.

On Thu, Dec 3, 2015 at 12:43 AM, Patrick Flaherty <vze2k3sa at verizon.net> wrote:
> Hello,
>
>
>
> Is there a way to disable IP6 in the 3.5.x Squid builds?
>
>
>
> Thanks
>
> Patrick
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
    Francesco


From itpc.vivek at gmail.com  Thu Dec  3 06:17:40 2015
From: itpc.vivek at gmail.com (vivek singh)
Date: Thu, 3 Dec 2015 11:47:40 +0530
Subject: [squid-users] mail upload problem
In-Reply-To: <201512020958.48412.Antony.Stone@squid.open.source.it>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
Message-ID: <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>

Thanks for the quick reply. please find the answers below
1. while uploading attachments,it stays idle without any advancement in
attachment progress bar.
2. we have tested on IE,Crome and Firefox with the same result.
3. Major mail services used are i. gmail, 2. mail.bsnl.co.in
4. yes, clients can access internet through proxy servers only, no other
way.
5. squid.conf (all the access lists are separate text files)
acl SSL_ports port 443
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow all exceptionlist
http_access allow sysadmin_ip sysadmin_time sysadmin_url
http_access deny all blacklist
http_access allow tv_ip
http_access allow sysadmin_ip whitelist
http_access allow workstation_ip whitelist
http_access allow localhost
http_access deny all
http_port 8080
cache deny all
coredump_dir /var/spool/squid
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320
dns_nameservers ip1 ip2 ip3 8.8.8.8
visible_hostname proxyserver
cache_mgr emailid
max_filedescriptors 4096
6. can be informed later
7. I meant to state that this problem occurs in some machines only, that is
on those machines attachment is not uploaded at all.








*Thanks and RegardsVivek Kumar SinghJ.T.O./ITPC-KolkataMobile
 08902000538Landline 033-23211548*


On Wed, Dec 2, 2015 at 2:28 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Wednesday 02 December 2015 at 07:07:09, vivek singh wrote:
>
> >      we are facing problem while users trying to upload some attachments
> it
> > fails using linux proxy, while at the same time if they switch to windows
> > proxy attachment uploaded succesfully.
> >      I am using squid 3.5 version onboth linux and windows proxy servers,
> > any help would be appreciation.
>
> Please consider telling us:
>
> 1. What specific problem (eg: error message?) are the users getting?
>
> 2. Which browser/s are the users using?
>
> 3. Which web mail service are they accessing?
>
> 4. Are the browsers explicitly configured to use the Squid proxy, or are
> you
> using intercept mode?
>
> 5. What is your squid.conf (without comments or blank lines)?
>
> 6. What entries do you get in Squid's access.log when the problem occurs?
>
> 7. You say "some attachments" - does this mean that some can be
> successfully
> uploaded through Squid, but others can't?  If so, is there any noticeable
> difference (eg: size) between the ones whihc work and the ones which don't?
>
>
> Regards,
>
>
> Antony.
>
> --
> If you were ploughing a field, which would you rather use - two strong
> oxen or
> 1024 chickens?
>
>  - Seymour Cray, pioneer of supercomputing
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151203/b77c643f/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec  3 09:42:21 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 22:42:21 +1300
Subject: [squid-users] doubts about the squid3
In-Reply-To: <CA+0TdyqipgBeMAscVKGeMvTkY1L_Di-3Or3f=LZJcW2y65jjhw@mail.gmail.com>
References: <CA+0TdyqipgBeMAscVKGeMvTkY1L_Di-3Or3f=LZJcW2y65jjhw@mail.gmail.com>
Message-ID: <56600E7D.1020203@treenet.co.nz>

On 3/12/2015 4:15 p.m., Marcio Demetrio Bacci wrote:
> My Linux Stations are in Domain, but when a user open your bowser, the user
> and password are asked. Sometimes, during the navegation, the user and
> password are asked again.

Be aware the popup has nothing to do with Squid. It is a mechanism the
browser uses to get credentials when it discovers that the ones it has
are invalid, not usable any longer, not acceptible, or otherwise
rejected by the authentication systems it is trying to uses them with.

Basically it is a last-resort method to find some way to login to an
authenticated service.

So for the popup to happen you either have misconfigured Squid or
running into a bug in the authentication. It has been a while since we
had any bugs that only occured later (the current bunch are immediately
visible).

> 
> This way, I wish that the user session to be valid per 4 hours. How do I
> set it?

Firstly, there is no such thing as "session" in HTTP.

For authentication "sessions"

> 
> Follow the authentication portion of the  my squid.conf:
> 
> # NTLM
> auth_param ntlm program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp  --domain=DOMAIN
> auth_param ntlm children 30
> auth_param ntlm keep_alive off
> 
>  #BASIC
> auth_param basic program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-basic
> auth_param basic children 5
> auth_param basic realm "Web Proxy"
> external_acl_type ad_group %LOGIN /usr/lib/squid3/wbinfo_group.pl -d
> 

There is also all the part(s) where authentication gets used, and the
non-authentication ACLs around those which determine under what
conditinos authentication gets used.

Please post your whole squid.conf (without the comments or empty lines)
so we can do a proper analysis.

Amos



From squid3 at treenet.co.nz  Thu Dec  3 09:44:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 22:44:54 +1300
Subject: [squid-users] Disabling IP6 in 3.5.x
In-Reply-To: <CA+Y8hcM9NyKhFVGXEZLC4Bb=9E+Bm-7twSokH5gLoSnY99y1zg@mail.gmail.com>
References: <01ab01d12d5b$434e8bf0$c9eba3d0$@verizon.net>
 <CA+Y8hcM9NyKhFVGXEZLC4Bb=9E+Bm-7twSokH5gLoSnY99y1zg@mail.gmail.com>
Message-ID: <56600F16.1010303@treenet.co.nz>

On 3/12/2015 6:22 p.m., Kinkie wrote:
> Hi Patrick,
>    ./configure --disable-ipv6 <other arguments>
> 
> will do the trick.

But please, *why* do you want to go to such drastic measures?

Amos



From squid3 at treenet.co.nz  Thu Dec  3 10:02:12 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 23:02:12 +1300
Subject: [squid-users] mail upload problem
In-Reply-To: <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
Message-ID: <56601324.3030508@treenet.co.nz>

On 3/12/2015 7:17 p.m., vivek singh wrote:
> Thanks for the quick reply. please find the answers below
> 1. while uploading attachments,it stays idle without any advancement in
> attachment progress bar.
> 2. we have tested on IE,Crome and Firefox with the same result.
> 3. Major mail services used are i. gmail, 2. mail.bsnl.co.in
> 4. yes, clients can access internet through proxy servers only, no other
> way.
> 5. squid.conf (all the access lists are separate text files)
> acl SSL_ports port 443
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow all exceptionlist

The "all" on the above line is doing nothing. You can remove it to
clarify what this config does.

> http_access allow sysadmin_ip sysadmin_time sysadmin_url
> http_access deny all blacklist

 ... same for the "all" on the above line.

> http_access allow tv_ip
> http_access allow sysadmin_ip whitelist
> http_access allow workstation_ip whitelist
> http_access allow localhost
> http_access deny all
> http_port 8080
> cache deny all
> coredump_dir /var/spool/squid
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
> dns_nameservers ip1 ip2 ip3 8.8.8.8
> visible_hostname proxyserver
> cache_mgr emailid
> max_filedescriptors 4096
> 6. can be informed later
> 7. I meant to state that this problem occurs in some machines only, that is
> on those machines attachment is not uploaded at all.

Which ones? ie. How does the IP correlate to the tv_ip, sysadmin_ip,
workstation_ip ACLs above?

Any difference with attachment size?

Any difference with how those machines are configured to use the proxy
vs ones that work? (Manual setting? WPAD/PAC auto-configuration?)

Any pattern with the client OS type and version?
 or the browser versions?


Exactly what version of squid-3.5.x is being used?
 Running on what operating system?
 Self-built or a packaged Squid from .. where?


If the above questions do not lead you towards an answer, are you able
to get a packet trace to see where the pause is happening
(client<->squid, or squid<->server), and whether the upload is actually
hung, or just not being reported right by the browser.

Amos


From yvoinov at gmail.com  Thu Dec  3 10:04:03 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 3 Dec 2015 16:04:03 +0600
Subject: [squid-users] mail upload problem
In-Reply-To: <56601324.3030508@treenet.co.nz>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz>
Message-ID: <56601393.8090004@gmail.com>

I suggest the problem just required to allow POST method from LAN and/or 
to mail servers. Often this can help.

03.12.15 16:02, Amos Jeffries ?????:
> On 3/12/2015 7:17 p.m., vivek singh wrote:
>> Thanks for the quick reply. please find the answers below
>> 1. while uploading attachments,it stays idle without any advancement in
>> attachment progress bar.
>> 2. we have tested on IE,Crome and Firefox with the same result.
>> 3. Major mail services used are i. gmail, 2. mail.bsnl.co.in
>> 4. yes, clients can access internet through proxy servers only, no other
>> way.
>> 5. squid.conf (all the access lists are separate text files)
>> acl SSL_ports port 443
>> acl CONNECT method CONNECT
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>> http_access allow all exceptionlist
> The "all" on the above line is doing nothing. You can remove it to
> clarify what this config does.
>
>> http_access allow sysadmin_ip sysadmin_time sysadmin_url
>> http_access deny all blacklist
>   ... same for the "all" on the above line.
>
>> http_access allow tv_ip
>> http_access allow sysadmin_ip whitelist
>> http_access allow workstation_ip whitelist
>> http_access allow localhost
>> http_access deny all
>> http_port 8080
>> cache deny all
>> coredump_dir /var/spool/squid
>> refresh_pattern ^ftp: 1440 20% 10080
>> refresh_pattern ^gopher: 1440 0% 1440
>> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
>> refresh_pattern . 0 20% 4320
>> dns_nameservers ip1 ip2 ip3 8.8.8.8
>> visible_hostname proxyserver
>> cache_mgr emailid
>> max_filedescriptors 4096
>> 6. can be informed later
>> 7. I meant to state that this problem occurs in some machines only, that is
>> on those machines attachment is not uploaded at all.
> Which ones? ie. How does the IP correlate to the tv_ip, sysadmin_ip,
> workstation_ip ACLs above?
>
> Any difference with attachment size?
>
> Any difference with how those machines are configured to use the proxy
> vs ones that work? (Manual setting? WPAD/PAC auto-configuration?)
>
> Any pattern with the client OS type and version?
>   or the browser versions?
>
>
> Exactly what version of squid-3.5.x is being used?
>   Running on what operating system?
>   Self-built or a packaged Squid from .. where?
>
>
> If the above questions do not lead you towards an answer, are you able
> to get a packet trace to see where the pause is happening
> (client<->squid, or squid<->server), and whether the upload is actually
> hung, or just not being reported right by the browser.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Dec  3 10:13:04 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 23:13:04 +1300
Subject: [squid-users] DNS Socket Created
In-Reply-To: <01a601d12d5b$1707b530$45171f90$@verizon.net>
References: <01a601d12d5b$1707b530$45171f90$@verizon.net>
Message-ID: <566015B0.7060708@treenet.co.nz>

On 3/12/2015 12:42 p.m., Patrick Flaherty wrote:
> Hello,
> 
> What does Squid open Sockets for? (As shown below)
> 
> 2015/12/02 17:20:53 kid1| DNS Socket created at [::], FD 5
> 
> 2015/12/02 17:20:53 kid1| DNS Socket created at 0.0.0.0, FD 6
> 

For sending and receiving DNS messages.

Amos



From focusnetgogo at gmail.com  Thu Dec  3 10:21:04 2015
From: focusnetgogo at gmail.com (GoGo net)
Date: Thu, 3 Dec 2015 18:21:04 +0800
Subject: [squid-users] How to enable OCSP stapling for squid 3.5
Message-ID: <5E53F746-38C7-482C-B5DC-162704EC47D8@gmail.com>

Hi, cool guys,

I am running a squid 3.5 on Ubuntu 14.04 as proxy server through https_port 443 (not http_port):

> client ?> (https_prot:443) squid  ?> Internet

Basically speaking, it works well. But TLS brings in some performance overhead. 
Currently, I am planning to enable OCSP stapling to speed up handshake. I have searched squid configuration doc, did NOT find anything helpful. So my question is:

** Does squid 3.5 support OCSP stapling (between client and squid)? If yes, can anyone provide an example? **

Best wishes,

Daniel




From squid3 at treenet.co.nz  Thu Dec  3 10:22:15 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 23:22:15 +1300
Subject: [squid-users] SQUID_ERR_SSL_HANDSHAKE
In-Reply-To: <01b101d12d5c$c725a7f0$5570f7d0$@verizon.net>
References: <01b101d12d5c$c725a7f0$5570f7d0$@verizon.net>
Message-ID: <566017D7.4000405@treenet.co.nz>

On 3/12/2015 12:54 p.m., Patrick Flaherty wrote:
> Hi,
> 
>  
> 
> Doing some debugging (ALL,9) and looking at the cache log just after
> starting the Squid Windows Service and I see the following error. Can anyone
> help with what this means? Is it a misconfiguration?


This is not an error.

"ALL,9" is for logging the highest most verbose *debug* information
Squid can produce.

The lines you are seeing are Squid loading the text strings to be
displayed in HTTP error pages IF those errors ever occur.


PS. when Squid is producing an HTML error page for the client to explain
some problem it negotiates with the browser to find a language the
client can read. When the langpack is installed Squid can produce any
one of 45 languages, or using one of 119 national dialects.
 <http://www.squid-cache.org/Versions/langpack/>

Amos



From squid3 at treenet.co.nz  Thu Dec  3 10:24:50 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 23:24:50 +1300
Subject: [squid-users] mail upload problem
In-Reply-To: <56601393.8090004@gmail.com>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
Message-ID: <56601872.20906@treenet.co.nz>

On 3/12/2015 11:04 p.m., Yuri Voinov wrote:
> I suggest the problem just required to allow POST method from LAN and/or
> to mail servers. Often this can help.
> 

His squid.conf does not contain anything that obviously restricts that.
So I am suspecting the problems some old-ish browsers and OS have with
POST messages and Expect headers.

Or that some of the machines have been configured in a way that only
partially configures the applictinos on it, leaving some occasionally to
not even find the proxy.

Amos



From squid3 at treenet.co.nz  Thu Dec  3 10:39:03 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Dec 2015 23:39:03 +1300
Subject: [squid-users] How to enable OCSP stapling for squid 3.5
In-Reply-To: <5E53F746-38C7-482C-B5DC-162704EC47D8@gmail.com>
References: <5E53F746-38C7-482C-B5DC-162704EC47D8@gmail.com>
Message-ID: <56601BC7.7050404@treenet.co.nz>

On 3/12/2015 11:21 p.m., GoGo net wrote:
> Hi, cool guys,
> 
> I am running a squid 3.5 on Ubuntu 14.04 as proxy server through https_port 443 (not http_port):
> 
>> client ?> (https_prot:443) squid  ?> Internet
> 
> Basically speaking, it works well. But TLS brings in some performance overhead. 
> Currently, I am planning to enable OCSP stapling to speed up handshake. I have searched squid configuration doc, did NOT find anything helpful. So my question is:
> 
> ** Does squid 3.5 support OCSP stapling (between client and squid)? If yes, can anyone provide an example? **
> 

Squid does not currently support OCSP in any way. Sorry.

There is some work towards checking revocation better, but that is
focusing on the outgoing Squid->server connections.

Since the TLS infrastructure within Squid is undergoing a stabilization
currently we are a little distracted with solving the existing issues
with SSL-Bump functionality. OCSP and similar extension features are not
really on the roadmap.

If this is an important fature for you I suggest finding/funding someone
to do the development - a list of Support Services can be found on the
Squid website and you are free to post a RFI to the squid-dev mailing
list to see if anyone already familiar with the code wants to pick up a
contract.

Amos



From Massimo.Sala at asl.bergamo.it  Thu Dec  3 11:34:00 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 3 Dec 2015 12:34:00 +0100
Subject: [squid-users] squid 3.4, Zero-Sized Replies from Windows Server
Message-ID: <OF3B8D5E22.D5A6172C-ONC1257F10.003F8242-C1257F10.003F896B@asl.bergamo.it>

We have a server with squid 3.4.8 as forward proxy ( clients have the 
proxy configured in the browsers ).


Sometimes we have  Zero-Sized Replies from Windows Servers as discussed 
here :

        https://squidproxy.wordpress.com/category/squid-3/

The proxy server is in the internal LAN. We want to adopt this work-around 
:

        disable BEAST mitigation by ssloptions=ALL in squid.conf 
(insecure)


Does it work  in forwarding mode ?

        http_port 3128 ssloptions=ALL


best regards, Sala




From Massimo.Sala at asl.bergamo.it  Thu Dec  3 11:40:54 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 3 Dec 2015 12:40:54 +0100
Subject: [squid-users] delay_pools from 3.1 to 3.4
Message-ID: <OF2A28D84E.F3FB44B0-ONC1257F10.003F9178-C1257F10.00402B3D@asl.bergamo.it>

Squid 3 as forwarding proxy, intranet LAN.

We want to limit the bandwidth only for multimedia content.

On 3.1.20 we have these lines into squid.conf :

acl localnet src 10.0.0.0/8

acl acl_flussi_media rep_mime_type -i ^audio/
acl acl_flussi_media rep_mime_type -i ^video/

delay_pools 1
delay_class 1 1
delay_parameters 1 320000/320000
delay_access 1 allow acl_flussi_media
delay_access 1 deny all

http_access allow localnet
http_access deny all


Using the same lines on the new server, with squid 3.4.8, we got these 
warnings in cache.log :

        2015/12/03 12:38:45 kid1| WARNING: acl_flussi_media ACL is used in 
context without an HTTP response. Assuming mismatch.


What does it mean ? How to fix it ?

best regards, Sala



From squid3 at treenet.co.nz  Thu Dec  3 11:58:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 4 Dec 2015 00:58:24 +1300
Subject: [squid-users] delay_pools from 3.1 to 3.4
In-Reply-To: <OF2A28D84E.F3FB44B0-ONC1257F10.003F9178-C1257F10.00402B3D@asl.bergamo.it>
References: <OF2A28D84E.F3FB44B0-ONC1257F10.003F9178-C1257F10.00402B3D@asl.bergamo.it>
Message-ID: <56602E60.7040204@treenet.co.nz>

On 4/12/2015 12:40 a.m., Massimo.Sala at asl.bergamo.it wrote:
> Squid 3 as forwarding proxy, intranet LAN.
> 
> We want to limit the bandwidth only for multimedia content.
> 
> On 3.1.20 we have these lines into squid.conf :
> 
> acl localnet src 10.0.0.0/8
> 
> acl acl_flussi_media rep_mime_type -i ^audio/
> acl acl_flussi_media rep_mime_type -i ^video/
> 
> delay_pools 1
> delay_class 1 1
> delay_parameters 1 320000/320000
> delay_access 1 allow acl_flussi_media
> delay_access 1 deny all
> 
> http_access allow localnet
> http_access deny all
> 
> 
> Using the same lines on the new server, with squid 3.4.8, we got these 
> warnings in cache.log :
> 
>         2015/12/03 12:38:45 kid1| WARNING: acl_flussi_media ACL is used in 
> context without an HTTP response. Assuming mismatch.
> 
> 
> What does it mean ? How to fix it ?

It means that *reply* header do not work when using *request* to decide
what delay pool the transaction will use.

It has never worked. The older Squid just did not tell you about the
config problem.

If you want traffic to be re-assigned to pools when the reply happens
you need to upgrade to at least the Squid-4.0.3 (beta) release.

Amos



From focusnetgogo at gmail.com  Thu Dec  3 12:01:47 2015
From: focusnetgogo at gmail.com (GoGo net)
Date: Thu, 3 Dec 2015 20:01:47 +0800
Subject: [squid-users] How to enable OCSP stapling for squid 3.5
In-Reply-To: <56601BC7.7050404@treenet.co.nz>
References: <5E53F746-38C7-482C-B5DC-162704EC47D8@gmail.com>
 <56601BC7.7050404@treenet.co.nz>
Message-ID: <8711F9E2-ACB0-4910-9863-142F55ED3B3E@gmail.com>

Hi, Amos,

I am really appreciated for you quick reply.

Many thanks for your information. I will consider if I will post a RFI.


> On Dec 3, 2015, at 6:39 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 3/12/2015 11:21 p.m., GoGo net wrote:
>> Hi, cool guys,
>> 
>> I am running a squid 3.5 on Ubuntu 14.04 as proxy server through https_port 443 (not http_port):
>> 
>>> client ?> (https_prot:443) squid  ?> Internet
>> 
>> Basically speaking, it works well. But TLS brings in some performance overhead. 
>> Currently, I am planning to enable OCSP stapling to speed up handshake. I have searched squid configuration doc, did NOT find anything helpful. So my question is:
>> 
>> ** Does squid 3.5 support OCSP stapling (between client and squid)? If yes, can anyone provide an example? **
>> 
> 
> Squid does not currently support OCSP in any way. Sorry.
> 
> There is some work towards checking revocation better, but that is
> focusing on the outgoing Squid->server connections.
> 
> Since the TLS infrastructure within Squid is undergoing a stabilization
> currently we are a little distracted with solving the existing issues
> with SSL-Bump functionality. OCSP and similar extension features are not
> really on the roadmap.
> 
> If this is an important fature for you I suggest finding/funding someone
> to do the development - a list of Support Services can be found on the
> Squid website and you are free to post a RFI to the squid-dev mailing
> list to see if anyone already familiar with the code wants to pick up a
> contract.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Dec  3 12:04:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 4 Dec 2015 01:04:46 +1300
Subject: [squid-users] squid 3.4, Zero-Sized Replies from Windows Server
In-Reply-To: <OF3B8D5E22.D5A6172C-ONC1257F10.003F8242-C1257F10.003F896B@asl.bergamo.it>
References: <OF3B8D5E22.D5A6172C-ONC1257F10.003F8242-C1257F10.003F896B@asl.bergamo.it>
Message-ID: <56602FDE.8000704@treenet.co.nz>

On 4/12/2015 12:34 a.m., Massimo.Sala wrote:
> We have a server with squid 3.4.8 as forward proxy ( clients have the 
> proxy configured in the browsers ).
> 
> 
> Sometimes we have  Zero-Sized Replies from Windows Servers as discussed 
> here :
> 
>         https://squidproxy.wordpress.com/category/squid-3/
> 
> The proxy server is in the internal LAN. We want to adopt this work-around 
> :
> 
>         disable BEAST mitigation by ssloptions=ALL in squid.conf 
> (insecure)
> 
> 
> Does it work  in forwarding mode ?
> 
>         http_port 3128 ssloptions=ALL
> 

No. SSL options are not relevant to plain-text HTTP traffic.

>From the hints you have given about your configuration so far I believe
the HTTPS traffic is being tunnelled blindly through your proxy. All
TLS/SSL details are being negotiated between the client UA and the
server they are tunneled to.
Under such conditions there is *nothing* you can do to influence or
affect TLS/SSL behaviour short of blocking it outright on a per-server
basis.

Amos



From focusnetgogo at gmail.com  Thu Dec  3 12:14:06 2015
From: focusnetgogo at gmail.com (GoGo net)
Date: Thu, 3 Dec 2015 20:14:06 +0800
Subject: [squid-users] How to limit user traffic quota?
Message-ID: <02C693F6-3766-49EA-9475-EFC6F68CCBCA@gmail.com>

I am running squid 3.5 in my LAN as a proxy for surfing internet.

The proxy is shared by all users in the LAN, and every user has a username/password configured in their web browser.

Now, I want to limit user traffic quota, say every user 100GB/month. How can achieve this?

Currently, I use a script to monitor **access.log** of squid, and aggregate the traffic from log to calculate user traffic. But I am wondering what is the best practise to limit user quota? Is there a better way to limit user traffic quota?

Best wishes,

Daniel

From Massimo.Sala at asl.bergamo.it  Thu Dec  3 12:17:24 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 3 Dec 2015 13:17:24 +0100
Subject: [squid-users] squid docs, http_access manager : mismatch
Message-ID: <OFA67CDFB2.1D018AD4-ONC1257F10.00432A74-C1257F10.004382AE@asl.bergamo.it>

I am reviewing our squid.conf about  http_access manager


http://www.squid-cache.org/Doc/config/http_access/

        http_access allow localhost manager


http://wiki.squid-cache.org/Features/CacheManager

        Cache manager Access Control in squid.conf
        http_access allow manager localhost



Which is the correct syntax ?

best regards, Sala



From Antony.Stone at squid.open.source.it  Thu Dec  3 12:26:50 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 3 Dec 2015 13:26:50 +0100
Subject: [squid-users] squid docs, http_access manager : mismatch
In-Reply-To: <OFA67CDFB2.1D018AD4-ONC1257F10.00432A74-C1257F10.004382AE@asl.bergamo.it>
References: <OFA67CDFB2.1D018AD4-ONC1257F10.00432A74-C1257F10.004382AE@asl.bergamo.it>
Message-ID: <201512031326.50849.Antony.Stone@squid.open.source.it>

On Thursday 03 December 2015 at 13:17:24, Massimo.Sala at asl.bergamo.it wrote:

> http://www.squid-cache.org/Doc/config/http_access/
> 
>         http_access allow localhost manager
> 
> http://wiki.squid-cache.org/Features/CacheManager
> 
>         Cache manager Access Control in squid.conf
>         http_access allow manager localhost
> 
> Which is the correct syntax ?

Both.

The ACLs in an http_access statement are ANDed together, so it makes no 
difference what order they appear in.


Regards,


Antony.

-- 
"The future is already here.   It's just not evenly distributed yet."

 - William Gibson

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Thu Dec  3 12:27:19 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 4 Dec 2015 01:27:19 +1300
Subject: [squid-users] How to limit user traffic quota?
In-Reply-To: <02C693F6-3766-49EA-9475-EFC6F68CCBCA@gmail.com>
References: <02C693F6-3766-49EA-9475-EFC6F68CCBCA@gmail.com>
Message-ID: <56603527.1020209@treenet.co.nz>

On 4/12/2015 1:14 a.m., GoGo net wrote:
> I am running squid 3.5 in my LAN as a proxy for surfing internet.
> 
> The proxy is shared by all users in the LAN, and every user has a username/password configured in their web browser.
> 
> Now, I want to limit user traffic quota, say every user 100GB/month. How can achieve this?
> 
> Currently, I use a script to monitor **access.log** of squid, and aggregate the traffic from log to calculate user traffic. But I am wondering what is the best practise to limit user quota? Is there a better way to limit user traffic quota?
> 

Nope. Squid is designed to optimize traffic not to de-optimize it. So
does not do quota limitations.

However the OS QoS controls often do support quotas and do so far better
than Squid could even get close to. Squid can integrate with those using
tcp_outgoing_tos/mark and qos_flows to deliver per-request
classification tags to the OS QoS system.


If you stay wit a helper script you maybe could still optimize it a
little. Your log monitoring Script could be run as a log daemon helper
in order to get the log lines as soon as they are written. That also
lets you send a custom log format separate from the access.log to the
helper so it can work better.


Amos



From focusnetgogo at gmail.com  Thu Dec  3 12:34:32 2015
From: focusnetgogo at gmail.com (GoGo net)
Date: Thu, 3 Dec 2015 20:34:32 +0800
Subject: [squid-users] How to limit user traffic quota?
In-Reply-To: <56603527.1020209@treenet.co.nz>
References: <02C693F6-3766-49EA-9475-EFC6F68CCBCA@gmail.com>
 <56603527.1020209@treenet.co.nz>
Message-ID: <190FC863-543B-4B98-8830-6C8EBB15E287@gmail.com>

As I do NOT want to add extra cost to squid, I will stay with the script and try to optimise it.

Thanks, Amos.

> On Dec 3, 2015, at 8:27 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 4/12/2015 1:14 a.m., GoGo net wrote:
>> I am running squid 3.5 in my LAN as a proxy for surfing internet.
>> 
>> The proxy is shared by all users in the LAN, and every user has a username/password configured in their web browser.
>> 
>> Now, I want to limit user traffic quota, say every user 100GB/month. How can achieve this?
>> 
>> Currently, I use a script to monitor **access.log** of squid, and aggregate the traffic from log to calculate user traffic. But I am wondering what is the best practise to limit user quota? Is there a better way to limit user traffic quota?
>> 
> 
> Nope. Squid is designed to optimize traffic not to de-optimize it. So
> does not do quota limitations.
> 
> However the OS QoS controls often do support quotas and do so far better
> than Squid could even get close to. Squid can integrate with those using
> tcp_outgoing_tos/mark and qos_flows to deliver per-request
> classification tags to the OS QoS system.
> 
> 
> If you stay wit a helper script you maybe could still optimize it a
> little. Your log monitoring Script could be run as a log daemon helper
> in order to get the log lines as soon as they are written. That also
> lets you send a custom log format separate from the access.log to the
> helper so it can work better.
> 
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Dec  3 12:43:51 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 4 Dec 2015 01:43:51 +1300
Subject: [squid-users] squid docs, http_access manager : mismatch
In-Reply-To: <OFA67CDFB2.1D018AD4-ONC1257F10.00432A74-C1257F10.004382AE@asl.bergamo.it>
References: <OFA67CDFB2.1D018AD4-ONC1257F10.00432A74-C1257F10.004382AE@asl.bergamo.it>
Message-ID: <56603907.6040203@treenet.co.nz>

On 4/12/2015 1:17 a.m., Massimo.Sala at asl.bergamo.it wrote:
> I am reviewing our squid.conf about  http_access manager
> 
> 
> http://www.squid-cache.org/Doc/config/http_access/
> 
>         http_access allow localhost manager
> 
> 
> http://wiki.squid-cache.org/Features/CacheManager
> 
>         Cache manager Access Control in squid.conf
>         http_access allow manager localhost
> 
> 
> 
> Which is the correct syntax ?

Either is fine. The first is better.

The conditions on the line are AND'd together to decide if the action
(allow) is to be enacted. Best Practice is to place the fastest ACL
tests earlier, so if they mis-match its fast and raises overall
performance. There are a few exceptions, but this is not one of those
odd cases.

The manager ACL was changed in Squid-3.2 from a super-fast proto ACL
type to a slow(er) regex type. Old Squid have slightly faster
performance with "manager localhost" and current Squid have faster
performance with "localhost manager". The difference is very marginal
though so it would not be noticed except under extremely heavy load
conditions.

Thank you for spotting this. I'm updating the wiki page now to align
with current recommendations.

Amos



From Antony.Stone at squid.open.source.it  Thu Dec  3 12:45:31 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 3 Dec 2015 13:45:31 +0100
Subject: [squid-users] How to limit user traffic quota?
In-Reply-To: <190FC863-543B-4B98-8830-6C8EBB15E287@gmail.com>
References: <02C693F6-3766-49EA-9475-EFC6F68CCBCA@gmail.com>
 <56603527.1020209@treenet.co.nz>
 <190FC863-543B-4B98-8830-6C8EBB15E287@gmail.com>
Message-ID: <201512031345.31577.Antony.Stone@squid.open.source.it>

On Thursday 03 December 2015 at 13:34:32, GoGo net wrote:

> As I do NOT want to add extra cost to squid, I will stay with the script
> and try to optimise it.

What do you mean by "cost"?


Antony.

> > On Dec 3, 2015, at 8:27 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> > 
> > On 4/12/2015 1:14 a.m., GoGo net wrote:
> >> I am running squid 3.5 in my LAN as a proxy for surfing internet.
> >> 
> >> The proxy is shared by all users in the LAN, and every user has a
> >> username/password configured in their web browser.
> >> 
> >> Now, I want to limit user traffic quota, say every user 100GB/month. How
> >> can achieve this?
> >> 
> >> Currently, I use a script to monitor **access.log** of squid, and
> >> aggregate the traffic from log to calculate user traffic. But I am
> >> wondering what is the best practise to limit user quota? Is there a
> >> better way to limit user traffic quota?
> > 
> > Nope. Squid is designed to optimize traffic not to de-optimize it. So
> > does not do quota limitations.
> > 
> > However the OS QoS controls often do support quotas and do so far better
> > than Squid could even get close to. Squid can integrate with those using
> > tcp_outgoing_tos/mark and qos_flows to deliver per-request
> > classification tags to the OS QoS system.
> > 
> > If you stay wit a helper script you maybe could still optimize it a
> > little. Your log monitoring Script could be run as a log daemon helper
> > in order to get the log lines as soon as they are written. That also
> > lets you send a custom log format separate from the access.log to the
> > helper so it can work better.

-- 
All generalisations are inaccurate.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From focusnetgogo at gmail.com  Thu Dec  3 12:48:18 2015
From: focusnetgogo at gmail.com (GoGo net)
Date: Thu, 3 Dec 2015 20:48:18 +0800
Subject: [squid-users] How to limit user traffic quota?
In-Reply-To: <201512031345.31577.Antony.Stone@squid.open.source.it>
References: <02C693F6-3766-49EA-9475-EFC6F68CCBCA@gmail.com>
 <56603527.1020209@treenet.co.nz>
 <190FC863-543B-4B98-8830-6C8EBB15E287@gmail.com>
 <201512031345.31577.Antony.Stone@squid.open.source.it>
Message-ID: <62DE7735-6ED1-4797-8B49-66C01919306D@gmail.com>

The cost means "integrate with those using tcp_outgoing_tos/mark and qos_flows to deliver per-request classification tags to the OS QoS system".

> On Dec 3, 2015, at 8:45 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Thursday 03 December 2015 at 13:34:32, GoGo net wrote:
> 
>> As I do NOT want to add extra cost to squid, I will stay with the script
>> and try to optimise it.
> 
> What do you mean by "cost"?
> 
> 
> Antony.
> 
>>> On Dec 3, 2015, at 8:27 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> On 4/12/2015 1:14 a.m., GoGo net wrote:
>>>> I am running squid 3.5 in my LAN as a proxy for surfing internet.
>>>> 
>>>> The proxy is shared by all users in the LAN, and every user has a
>>>> username/password configured in their web browser.
>>>> 
>>>> Now, I want to limit user traffic quota, say every user 100GB/month. How
>>>> can achieve this?
>>>> 
>>>> Currently, I use a script to monitor **access.log** of squid, and
>>>> aggregate the traffic from log to calculate user traffic. But I am
>>>> wondering what is the best practise to limit user quota? Is there a
>>>> better way to limit user traffic quota?
>>> 
>>> Nope. Squid is designed to optimize traffic not to de-optimize it. So
>>> does not do quota limitations.
>>> 
>>> However the OS QoS controls often do support quotas and do so far better
>>> than Squid could even get close to. Squid can integrate with those using
>>> tcp_outgoing_tos/mark and qos_flows to deliver per-request
>>> classification tags to the OS QoS system.
>>> 
>>> If you stay wit a helper script you maybe could still optimize it a
>>> little. Your log monitoring Script could be run as a log daemon helper
>>> in order to get the log lines as soon as they are written. That also
>>> lets you send a custom log format separate from the access.log to the
>>> helper so it can work better.
> 
> -- 
> All generalisations are inaccurate.
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From robert at plamondon.com  Thu Dec  3 16:23:07 2015
From: robert at plamondon.com (Robert Plamondon)
Date: Thu, 3 Dec 2015 08:23:07 -0800
Subject: [squid-users] How to limit user traffic quota? (GoGo net)
Message-ID: <CAH8HCTT1bAcFGxPa5cq7NLPts4Tc_SWF8gu0aXy7SvG9mLrQEQ@mail.gmail.com>

I haven't used delay pools in a while, but I would think that the updated
Squid 3 delay pools (with 64-bit counters and per-authenticated-user
buckets) would allow such quotas.

I'd take the monthly quota and turn it into a per-second rate. If my math
isn't failing me, 100 GB/month = 38,500 bytes per second. That would be the
refill rate on the delay pool. Users will be guaranteed this rate. Their BW
would never be cut off, just throttled to the rate they're paying for.

Then pick a max value to taste. I like to populate delay pools to support
an enormous burst size (the "maximum" parameter in the pool), so the
bandwidth limitations will rarely if ever be encountered by the average
user. 10% of the monthly allotment, or 10 GB, (3 days' worth of bandwidth)
strikes me as a good starting point, but I wouldn't have much resistance to
even higher numbers, like 25%.

Robert
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151203/453344a8/attachment.htm>

From eliezer at ngtech.co.il  Thu Dec  3 16:31:27 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 3 Dec 2015 18:31:27 +0200
Subject: [squid-users] mail upload problem
In-Reply-To: <56601872.20906@treenet.co.nz>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
 <56601872.20906@treenet.co.nz>
Message-ID: <56606E5F.30103@ngtech.co.il>

Or it could be the slow uploads but in 3.5.X which I am almost sure was 
not fixed yet.

Eliezer

On 03/12/2015 12:24, Amos Jeffries wrote:
> His squid.conf does not contain anything that obviously restricts that.
> So I am suspecting the problems some old-ish browsers and OS have with
> POST messages and Expect headers.
>
> Or that some of the machines have been configured in a way that only
> partially configures the applictinos on it, leaving some occasionally to
> not even find the proxy.
>
> Amos



From demonihin at gmail.com  Thu Dec  3 20:46:54 2015
From: demonihin at gmail.com (Dima Ermakov)
Date: Thu, 3 Dec 2015 23:46:54 +0300
Subject: [squid-users] Authentication Problem
Message-ID: <CAOpdYysqg4B0ybwj3MGbC0-37AsnJRhpddSt1+c8w=4mkDOY9w@mail.gmail.com>

Hi!
I have a problem with authentiation.

I use samba ntlm authentication in my network.

Some users ( not all ) have problems with http traffic.

They see basic authentication request.
If they enter correct domain login and password, they have auth error.
If this users try to open https sites: all works good, they have not any
type of errors.


So we have errors only with unencrypted connections.

I have this error on two servers:
debian8, squid3.4 (from repository)
CentOS7, squid3.3.8 (from repository).

squid servers are domain joined.

System Time on client PC is correct.

Sorry for my bad English.
Thank you, for your help.

Configuration files are in attachment.

-- 
? ?????????, ??????? ???????.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151203/3c8c7fe9/attachment.htm>
-------------- next part --------------
# Uncomment and adjust the following to add a disk cache directory.
cache_dir aufs /var/spool/squid3/ 10000 32 256

http_port 127.0.0.1:4001
cache_mem 1024 MB
visible_hostname it-gw-b.vod.local
http_access allow localhost

access_log /var/log/squid3/access.backend.log
cache_log /var/log/squid3/cache.backend.log

-------------- next part --------------
#Memoty Cache size
cache_mem 256 MB

maximum_object_size_in_memory 1024 KB

cache_peer 127.0.0.1 parent 4001 0 default name=it-squid-b.vod.local
never_direct allow all

visible_hostname it-gw-f.vod.local

######AUTHENTICATION BLOCK#############
#Authentication Programs
auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 100 startup=5 idle=5
auth_param ntlm keep_alive on

#authenticate_ttl 1 hour
#authenticate_cache_garbage_interval 1 hour


auth_param basic program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic
auth_param basic credentialsttl 600 second
auth_param basic children 60 startup=5 idle=5



#Need Auth
acl AuthorizedUsers proxy_auth REQUIRED

#Unlim speed users
acl unlim_group src "/etc/squid/acl/unlim_group"

#Check group membership
external_acl_type testforGroup   children-max=30 children-startup=5  %LOGIN /usr/lib/squid3/ext_wbinfo_group_acl
acl internet_G external testforGroup Internet_group
acl internet_SG external testforGroup Internet_super_group

########## END AUTHENTICATION BLOCK #########


####### Speed Limits Block ###########
delay_pools 3

#Limit for internet super group
delay_class 1 4

#Limit for internet group
delay_class 2 4

# No Speed Limit - unlim
delay_class 3 4

delay_parameters 1 -1/-1 -1/-1 -1/-1 -1/-1
delay_parameters 2 -1/-1 -1/-1 -1/-1 125000/125000
delay_parameters 3 -1/-1 -1/-1 -1/-1 64000/64000


delay_access 1 allow unlim_group
#delay_access 1 allow unlim_domains
delay_access 1 deny all

delay_access 2 allow internet_SG
delay_access 2 deny all

delay_access 3 allow internet_G
delay_access 3 deny all

############ End Speed Limits Block ###########3


#################### ACL Control Block ##################

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
####http_access allow localnet

http_access allow unlim_group
http_access allow internet_SG
http_access allow internet_G

#http_access allow unlim_group


# And finally deny all other access to this proxy
http_access allow localhost

http_access deny all

#####################3 End ACL Control Block ##############

# Squid normally listens to port 3128
http_port 8080
##https_port 8080

access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log
-------------- next part --------------
A non-text attachment was scrubbed...
Name: http-site.png
Type: image/png
Size: 13518 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151203/3c8c7fe9/attachment.png>
-------------- next part --------------
#
# Recommended minimum configuration:
#

####SNMP
#if ${process_number} = 2
##   snmp_port 3401
#endif
acl zabbix src 192.168.4.19/32
acl snmppublic snmp_community public
snmp_access allow snmppublic zabbix
snmp_access allow snmppublic localhost
snmp_access deny all

####### END SNMP



pid_filename /var/run/squid3/squid.pid

### Set local DNS as DNS for squid
dns_nameservers 127.0.0.1 192.168.4.23 192.168.4.1 192.168.4.2

#DNS V4
dns_v4_first on

#### SMP support
###workers 4

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
#acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 172.16.0.0/18 # RFC1918 possible internal network
acl localnet src 192.168.4.0/23 # RFC1918 possible internal network
#acl localnet src fc00::/7       # RFC 4193 local private network range
#acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443 #https
acl SSL_ports port 8445 #it-smtp.vod.local
acl SSL_ports port 8443 #it-ubiquiti.vod.local

acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl Safe_ports port 93 # Teh-Ekspert
acl CONNECT method CONNECT



#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports

# Deny CONNECT to other than secure SSL ports

# Only allow cachemgr access from localhost

acl manager url_regex -i ^cache_object:// /squid-internal-mgr/
####acl localhost src 127.0.0.1/32 ::1/128
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
###http_access allow localhost manager
acl sqstat src 192.168.4.19/32


http_access allow manager localhost
http_access allow manager sqstat
http_access deny manager

#cachemgr_passwd dm3ZcN7kDI12 all

#snmp_port 3401
cpu_affinity_map process_numbers=1,2,3,4,5,6 cores=1,2,3,4,5,6
workers 5
if ${process_number} = 1
   	include /etc/squid3/backend.conf
	snmp_port 3401
else
	include /etc/squid3/frontend.conf
endif


# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid3


#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320


From vze2k3sa at verizon.net  Thu Dec  3 21:57:52 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Thu, 03 Dec 2015 16:57:52 -0500
Subject: [squid-users] SQUID_ERR_SSL_HANDSHAKE
Message-ID: <003701d12e15$a8bbdcd0$fa339670$@verizon.net>

Hi,

 

Doing some debugging (ALL,9) and looking at the cache log just after
starting the Squid Windows Service and I see the following error. Can anyone
help with what this means? Is it a misconfiguration?

 

Thanks

Patrick

 

name: SQUID_ERR_SSL_HANDSHAKE

detail: "%ssl_error_descr: %ssl_lib_error"

descr: "Handshake with SSL server failed"

 

 

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1656) parse: parsing
HttpHeaderEntry: near 'name: SQUID_ERR_SSL_HANDSHAKE'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1698) parse: parsed
HttpHeaderEntry: 'name: SQUID_ERR_SSL_HANDSHAKE'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1599) HttpHeaderEntry:
created HttpHeaderEntry 0x600259920: 'name : SQUID_ERR_SSL_HANDSHAKE

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(981) addEntry: 0x2390e0
adding entry: 85 at 0

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1656) parse: parsing
HttpHeaderEntry: near 'detail: "%ssl_error_descr: %ssl_lib_error"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1698) parse: parsed
HttpHeaderEntry: 'detail: "%ssl_error_descr: %ssl_lib_error"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1599) HttpHeaderEntry:
created HttpHeaderEntry 0x6002599c0: 'detail : "%ssl_error_descr:
%ssl_lib_error"

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(981) addEntry: 0x2390e0
adding entry: 85 at 1

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1656) parse: parsing
HttpHeaderEntry: near 'descr: "Handshake with SSL server failed"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1698) parse: parsed
HttpHeaderEntry: 'descr: "Handshake with SSL server failed"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1599) HttpHeaderEntry:
created HttpHeaderEntry 0x600259a60: 'descr : "Handshake with SSL server
failed"

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(981) addEntry: 0x2390e0
adding entry: 85 at 2

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1201) has: 0x2390e0 lookup
for 62

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(480) clean: cleaning hdr:
0x2390e0 owner: 4

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1605) ~HttpHeaderEntry:
destroying entry 0x600259920: 'name: SQUID_ERR_SSL_HANDSHAKE'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1605) ~HttpHeaderEntry:
destroying entry 0x6002599c0: 'detail: "%ssl_error_descr: %ssl_lib_error"'

2015/12/02 18:49:41.713 kid1| 55,9| HttpHeader.cc(1605) ~HttpHeaderEntry:
destroying entry 0x600259a60: 'descr: "Handshake with SSL server failed"'

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(446) HttpHeader: init-ing
hdr: 0x2390e0 owner: 4

2015/12/02 18:49:41.713 kid1| 55,7| HttpHeader.cc(597) parse: parsing hdr:
(0x2390e0)

name: SQUID_X509_V_ERR_DOMAIN_MISMATCH

detail: "%ssl_error_descr: %ssl_subject"

descr: "Certificate does not match domainname"

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151203/fec38c5f/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec  4 01:55:07 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 4 Dec 2015 14:55:07 +1300
Subject: [squid-users] Authentication Problem
In-Reply-To: <CAOpdYysqg4B0ybwj3MGbC0-37AsnJRhpddSt1+c8w=4mkDOY9w@mail.gmail.com>
References: <CAOpdYysqg4B0ybwj3MGbC0-37AsnJRhpddSt1+c8w=4mkDOY9w@mail.gmail.com>
Message-ID: <5660F27B.6000907@treenet.co.nz>

On 4/12/2015 9:46 a.m., Dima Ermakov wrote:
> Hi!
> I have a problem with authentiation.
> 
> I use samba ntlm authentication in my network.
> 
> Some users ( not all ) have problems with http traffic.
> 
> They see basic authentication request.

Meaning you *dont* have NTLM authentication on your network.

Or you are making the mistake of thinking a popup means Basic
authentication.

> If they enter correct domain login and password, they have auth error.
> If this users try to open https sites: all works good, they have not any
> type of errors.

So,
 a) they are probably not going through this proxy, or
 b) the browser is suppressing the proxy-auth popups, or
 c) the authentication request is not coming from *your* proxy.

> 
> So we have errors only with unencrypted connections.
> 
> I have this error on two servers:
> debian8, squid3.4 (from repository)
> CentOS7, squid3.3.8 (from repository).
> 

Two things to try:

1) Adding a line like this before the group access controls in
frntend.conf. This will ensure that authentiation credentials are valid
before doing group lookups:
 http_access deny !AuthorizedUsers


2) checking up on the Debian winbind issue mentioned in
<http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm#winbind_privileged_pipe_permissions>

Im not sure about this it is likely to be involved on Debian, but CentOS
is not known to have that issue.


Oh and:
 3) remove the "acl manager" line from squid.conf.

 4) change your cachemgr_passwd. Commenting it out does not hide it from
view when you post it on this public mailing list.

You should remove all the commented out directives as well, some of them
may be leading to misunderstanding of what the config is actually doing.


Amos


From Jason_Haar at trimble.com  Fri Dec  4 03:35:55 2015
From: Jason_Haar at trimble.com (Jason Haar)
Date: Fri, 4 Dec 2015 16:35:55 +1300
Subject: [squid-users] using splice just to improve TLS SNI logging
Message-ID: <56610A1B.7010709@trimble.com>

Hi there

We just had an incident where I would really have liked to have had
transparent TLS intercept in place. Currently I'm still in
"experimental" phase and don't want to go full "bump", but some quick
testing of just activating "splice" with TLS intercept seems to me to be
zero risk

ie instead of allowing direct port 443 Internet access, redirect it back
onto squid-3.5 set to splice all port 443 traffic. End result is squid
logfiles containing the following

.. CONNECT 1.2.3.4:443 blah
.. CONNECT real.SNI.name:443 blah

Then at least I can see what HTTPS sites have been visited when I need to.

Does going "splice" mode avoid all the potential SSL/TLS issues
surrounding bump? ie it won't care about client certs, weird TLS
extensions, etc? (ie other than availability, it shouldn't introduce a
new way of failing?)

Thanks!

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From dan at getbusi.com  Fri Dec  4 03:47:46 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Fri, 4 Dec 2015 14:47:46 +1100
Subject: [squid-users] using splice just to improve TLS SNI logging
In-Reply-To: <56610A1B.7010709@trimble.com>
References: <56610A1B.7010709@trimble.com>
Message-ID: <04751552-F3EA-49A6-8FBC-449EF2542209@getbusi.com>

It?s been a far superior client experience to bumping on the deployments I?ve seen. Obviously MITM-ing a connection is always going to be a less amenable situation for clients; technically and ethically.

The only problem I?ve had with splicing is this Host Header Forgery error squid has when it resolves a different IP for an HTTPS host than the client does. It?s pretty well minimised by making sure the client and squid box are using the same DNS server, but I still have the occasional timeouts on github.com and missing images/media on twitter.com because of it.

> On 4 Dec 2015, at 2:35 PM, Jason Haar <Jason_Haar at trimble.com> wrote:
> 
> Hi there
> 
> We just had an incident where I would really have liked to have had
> transparent TLS intercept in place. Currently I'm still in
> "experimental" phase and don't want to go full "bump", but some quick
> testing of just activating "splice" with TLS intercept seems to me to be
> zero risk
> 
> ie instead of allowing direct port 443 Internet access, redirect it back
> onto squid-3.5 set to splice all port 443 traffic. End result is squid
> logfiles containing the following
> 
> .. CONNECT 1.2.3.4:443 blah
> .. CONNECT real.SNI.name:443 blah
> 
> Then at least I can see what HTTPS sites have been visited when I need to.
> 
> Does going "splice" mode avoid all the potential SSL/TLS issues
> surrounding bump? ie it won't care about client certs, weird TLS
> extensions, etc? (ie other than availability, it shouldn't introduce a
> new way of failing?)
> 
> Thanks!
> 
> -- 
> Cheers
> 
> Jason Haar
> Corporate Information Security Manager, Trimble Navigation Ltd.
> Phone: +1 408 481 8171
> PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From itpc.vivek at gmail.com  Fri Dec  4 06:59:47 2015
From: itpc.vivek at gmail.com (vivek singh)
Date: Fri, 4 Dec 2015 12:29:47 +0530
Subject: [squid-users] mail upload problem
In-Reply-To: <56606E5F.30103@ngtech.co.il>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
 <56601872.20906@treenet.co.nz> <56606E5F.30103@ngtech.co.il>
Message-ID: <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>

Thanks a lot for you responses.
I will update after doing  more analysis.

*@Amos Jeffries :*
Q . How does the IP correlate to the tv_ip, sysadmin_ip,
workstation_ip ACLs above?
A. these are separate text files in the same directory, containing ip lists.
Q. Any difference with how those machines are configured to use the proxy
A. all the machines are in the same domain and network.
Q. what version of squid-3.5.x is being used
A. Squid 3.5.0.2 on Redhat Linux , packaged rpm is used.
Q. His squid.conf does not contain anything that obviously restricts
that.So I am suspecting the problems some old-ish browsers and OS have with
POST messages and Expect headers
A. On the same machine if i change it to use another windows proxy server,
it works fine.

*@ Eliezer Croitoru*
Q. slow uploads but in 3.5.X which I am almost sure was not fixed yet
A. while on other machines it is working fine.

*@Yuri Voinov*
Q. I suggest the problem just required to allow POST method from LAN and/or
to mail servers. Often this can help
A. Do i explicitly need to do so, if yes please tell me how.



*Thanks and RegardsVivek Kumar Singh*


On Thu, Dec 3, 2015 at 10:01 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> Or it could be the slow uploads but in 3.5.X which I am almost sure was
> not fixed yet.
>
> Eliezer
>
>
> On 03/12/2015 12:24, Amos Jeffries wrote:
>
>> His squid.conf does not contain anything that obviously restricts that.
>> So I am suspecting the problems some old-ish browsers and OS have with
>> POST messages and Expect headers.
>>
>> Or that some of the machines have been configured in a way that only
>> partially configures the applictinos on it, leaving some occasionally to
>> not even find the proxy.
>>
>> Amos
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151204/30e8cb8d/attachment.htm>

From yvoinov at gmail.com  Fri Dec  4 07:02:09 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 4 Dec 2015 13:02:09 +0600
Subject: [squid-users] mail upload problem
In-Reply-To: <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
 <56601872.20906@treenet.co.nz> <56606E5F.30103@ngtech.co.il>
 <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>
Message-ID: <56613A71.8090705@gmail.com>



04.12.15 12:59, vivek singh ?????:
> Thanks a lot for you responses.
> I will update after doing  more analysis.
>
> *@Amos Jeffries :*
> Q . How does the IP correlate to the tv_ip, sysadmin_ip,
> workstation_ip ACLs above?
> A. these are separate text files in the same directory, containing ip 
> lists.
> Q. Any difference with how those machines are configured to use the proxy
> A. all the machines are in the same domain and network.
> Q. what version of squid-3.5.x is being used
> A. Squid 3.5.0.2 on Redhat Linux , packaged rpm is used.
> Q. His squid.conf does not contain anything that obviously restricts 
> that.So I am suspecting the problems some old-ish browsers and OS have 
> with POST messages and Expect headers
> A. On the same machine if i change it to use another windows proxy 
> server, it works fine.
>
> *@ Eliezer Croitoru*
> Q. slow uploads but in 3.5.X which I am almost sure was not fixed yet
> A. while on other machines it is working fine.
>
> *@Yuri Voinov*
> Q. I suggest the problem just required to allow POST method from LAN 
> and/or to mail servers. Often this can help
> A. Do i explicitly need to do so, if yes please tell me how.
Example:

# Adjust network as you need
acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
acl POST method POST
# Allow POST for localnet
http_access allow POST localnet

>
> *Thanks and Regards
> Vivek Kumar Singh
> *
>
>
> On Thu, Dec 3, 2015 at 10:01 PM, Eliezer Croitoru 
> <eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>> wrote:
>
>     Or it could be the slow uploads but in 3.5.X which I am almost
>     sure was not fixed yet.
>
>     Eliezer
>
>
>     On 03/12/2015 12:24, Amos Jeffries wrote:
>
>         His squid.conf does not contain anything that obviously
>         restricts that.
>         So I am suspecting the problems some old-ish browsers and OS
>         have with
>         POST messages and Expect headers.
>
>         Or that some of the machines have been configured in a way
>         that only
>         partially configures the applictinos on it, leaving some
>         occasionally to
>         not even find the proxy.
>
>         Amos
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151204/59437049/attachment.htm>

From tomtux007 at gmail.com  Fri Dec  4 08:34:10 2015
From: tomtux007 at gmail.com (Tom Tom)
Date: Fri, 4 Dec 2015 09:34:10 +0100
Subject: [squid-users] Deny Access based on SSL-Blacklists
	(SHA1-Fingerprint) with ssl_bump
Message-ID: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>

Hi list,

I'm trying to implement SSL-Blacklists based on SHA1-Fingerprints
(squid 3.5.11). As I know, certificate-fingerprints are one of the
parts of a certificate, which are visible in a uncrypted traffic.

It seems, that blocking https-sites based on fingerprints is only
working with a ssl_bump-enabled configuration. The directive, which
denies the access based on the fingerprint is "ssl_bump bump all" in
my case.

The necessary parts of my config:
acl DENY_SSL_BUMP ssl::server_name_regex -i "/etc/squid/DENY_SSL_BUMP"
acl tls_s1_connect at_step SslBump1
acl SSL_BL server_cert_fingerprint "/etc/squid/SSL_BLACKLIST"
http_access deny SSL_BL

http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/certs/myCA.pem
ssl_bump peek tls_s1_connect all
ssl_bump splice DENY_SSL_BUMP
ssl_bump bump all



Question:
Why do I need a "full" ssl_bump-configuration to prevent access based
on fingerprints? Why is it not enough with just "peeking" the
certificate/connection?

Thanks a lot.
Kind regards,
Tom


From nkelly at citrusnetworks.net  Fri Dec  4 10:02:26 2015
From: nkelly at citrusnetworks.net (Noel Kelly)
Date: Fri, 4 Dec 2015 10:02:26 +0000
Subject: [squid-users] Google Chrome v47.0.2526.73M Broken NTLM
	Authentication
Message-ID: <566164B2.6000604@citrusnetworks.net>

Hi

For information, the latest version of Google Chrome (v47.0.2526.73M) 
has broken NTLM authentication:

https://code.google.com/p/chromium/issues/detail?id=544255
https://productforums.google.com/forum/#!topic/chrome/G_9eXH9c_ns;context-place=forum/chrome

Cheers


From fabietto82 at gmail.com  Fri Dec  4 10:14:46 2015
From: fabietto82 at gmail.com (Fabio Bucci)
Date: Fri, 4 Dec 2015 11:14:46 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
Message-ID: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>

Hi All,
my task is implementing a squid proxy that allow all my authenticated
(windows AD) internal users to surf internet without any credential request
(pop-up).

Plus, i created two squid nodes and put them behind a citrix netscaler in
order to perform a load balance service.

I configured squid with samba and ntlm helper in order to perform a
transparent authentication but sometimes some user report me their browsers
require authentication via pop-up.

I'm not a deep expert about squid and i'd like to receive your help in
order to understand if my configuration is correct or not and if there is a
way to prevent popup.

Thanks all!

Fabio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151204/072937c8/attachment.htm>

From demonihin at gmail.com  Fri Dec  4 10:22:34 2015
From: demonihin at gmail.com (Dima Ermakov)
Date: Fri, 4 Dec 2015 13:22:34 +0300
Subject: [squid-users] Authentication Problem
In-Reply-To: <5660F27B.6000907@treenet.co.nz>
References: <CAOpdYysqg4B0ybwj3MGbC0-37AsnJRhpddSt1+c8w=4mkDOY9w@mail.gmail.com>
 <5660F27B.6000907@treenet.co.nz>
Message-ID: <CAOpdYysr9-abvae=F20kZTzgq29bPw5h=Z8Bi82=iZvwBwA=6w@mail.gmail.com>

Thank you, Amos.

I checked all, that you wrote.
It didn't help me.

I have this problem only on google chrome browser.
Before 2015-12-03 all was good.
I didn't change my configuration more than one month.

Ten minutes ago "Noel Kelly nkelly at citrusnetworks.net" wrote in this list,
that google chrome v47 has broken NTLM authentication.
My clients with problems has google chrome v47 (((

Mozilla Firefox clients work good.

Thank you!

This is message from Noel Kelly:
"

Hi

For information, the latest version of Google Chrome (v47.0.2526.73M) has
broken NTLM authentication:

https://code.google.com/p/chromium/issues/detail?id=544255
https://productforums.google.com/forum/#!topic/chrome/G_9eXH9c_ns;context-place=forum/chrome

Cheers
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

"

On 4 December 2015 at 04:55, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 4/12/2015 9:46 a.m., Dima Ermakov wrote:
> > Hi!
> > I have a problem with authentiation.
> >
> > I use samba ntlm authentication in my network.
> >
> > Some users ( not all ) have problems with http traffic.
> >
> > They see basic authentication request.
>
> Meaning you *dont* have NTLM authentication on your network.
>
> Or you are making the mistake of thinking a popup means Basic
> authentication.
>
> > If they enter correct domain login and password, they have auth error.
> > If this users try to open https sites: all works good, they have not any
> > type of errors.
>
> So,
>  a) they are probably not going through this proxy, or
>  b) the browser is suppressing the proxy-auth popups, or
>  c) the authentication request is not coming from *your* proxy.
>
> >
> > So we have errors only with unencrypted connections.
> >
> > I have this error on two servers:
> > debian8, squid3.4 (from repository)
> > CentOS7, squid3.3.8 (from repository).
> >
>
> Two things to try:
>
> 1) Adding a line like this before the group access controls in
> frntend.conf. This will ensure that authentiation credentials are valid
> before doing group lookups:
>  http_access deny !AuthorizedUsers
>
>
> 2) checking up on the Debian winbind issue mentioned in
> <
> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm#winbind_privileged_pipe_permissions
> >
>
> Im not sure about this it is likely to be involved on Debian, but CentOS
> is not known to have that issue.
>
>
> Oh and:
>  3) remove the "acl manager" line from squid.conf.
>
>  4) change your cachemgr_passwd. Commenting it out does not hide it from
> view when you post it on this public mailing list.
>
> You should remove all the commented out directives as well, some of them
> may be leading to misunderstanding of what the config is actually doing.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
? ?????????, ??????? ???????.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151204/402c62b2/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec  4 12:40:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 01:40:28 +1300
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
Message-ID: <566189BC.7010602@treenet.co.nz>

On 4/12/2015 9:34 p.m., Tom Tom wrote:
> Hi list,
> 
> I'm trying to implement SSL-Blacklists based on SHA1-Fingerprints
> (squid 3.5.11). As I know, certificate-fingerprints are one of the
> parts of a certificate, which are visible in a uncrypted traffic.
> 
> It seems, that blocking https-sites based on fingerprints is only
> working with a ssl_bump-enabled configuration. The directive, which
> denies the access based on the fingerprint is "ssl_bump bump all" in
> my case.
> 
> The necessary parts of my config:
> acl DENY_SSL_BUMP ssl::server_name_regex -i "/etc/squid/DENY_SSL_BUMP"
> acl tls_s1_connect at_step SslBump1
> acl SSL_BL server_cert_fingerprint "/etc/squid/SSL_BLACKLIST"
> http_access deny SSL_BL
> 
> http_port 3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/usr/local/certs/myCA.pem
> ssl_bump peek tls_s1_connect all
> ssl_bump splice DENY_SSL_BUMP
> ssl_bump bump all
> 
> 
> 
> Question:
> Why do I need a "full" ssl_bump-configuration to prevent access based
> on fingerprints?

Because "deny" in the form you are trying to do it is an HTTP message.
In order to perform HTTP over a TLS connection you have to decrypt it first.


> Why is it not enough with just "peeking" the
> certificate/connection?

Because peeking is an action done to the TLS layer.


What you actually want to be doing is:

  acl step1 at_step SslBump1
  acl whitelist ssl::server_name_regex -i "/etc/squid/DENY_SSL_BUMP"
  acl blacklist server_cert_fingerprint "/etc/squid/SSL_BLACKLIST"

  ssl_bump splice whitelist
  ssl_bump peek step1
  ssl_bump stare all
  ssl_bump terminate blacklist
  ssl_bump bump all


Notice how http_access is not part of the TLS ssl_bump processing.

Amos


From itpc.vivek at gmail.com  Fri Dec  4 13:41:18 2015
From: itpc.vivek at gmail.com (vivek singh)
Date: Fri, 4 Dec 2015 19:11:18 +0530
Subject: [squid-users] mail upload problem
In-Reply-To: <56613A71.8090705@gmail.com>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
 <56601872.20906@treenet.co.nz> <56606E5F.30103@ngtech.co.il>
 <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>
 <56613A71.8090705@gmail.com>
Message-ID: <CACeaudmVbUGwhu_UJddsLQ-eKtJybCD2s5V8Ap=YS1ddtLgAVQ@mail.gmail.com>

please find below the access log while problem occur
1449226819.307: 0: TCP_DENIED/403: 4089: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226828.671: 249222: TCP_TUNNEL/200: 6610: CONNECT:
clients2.google.com:443: -: HIER_DIRECT/216.58.196.110
1449226829.308: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226839.323: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226849.216: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226859.119: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226868.917: 0: TCP_DENIED/403: 4088: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226878.635: 0: TCP_DENIED/403: 4089: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226888.391: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226898.104: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226907.951: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226917.685: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226927.463: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226937.162: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226947.042: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226956.901: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226966.745: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226976.559: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226986.260: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449226996.214: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227006.198: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227016.198: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227026.184: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227036.072: 0: TCP_DENIED/403: 4089: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227042.281: 791782: TCP_TUNNEL/200: 5014: CONNECT: mtalk.google.com:443:
-: HIER_DIRECT/74.125.130.188
1449227042.537: 714649: TCP_TUNNEL/200: 7775: CONNECT: play.google.com:443:
-: HIER_DIRECT/216.58.196.110
1449227042.537: 68131: TCP_TUNNEL/200: 5813: CONNECT:
lh3.googleusercontent.com:443: -: HIER_DIRECT/216.58.196.97
1449227042.538: 70423: TCP_TUNNEL/200: 2303: CONNECT: apis.google.com:443:
-: HIER_DIRECT/216.58.196.110
1449227042.538: 184079: TCP_TUNNEL/200: 698: CONNECT: csi.gstatic.com:443:
-: HIER_DIRECT/216.58.211.3
1449227042.539: 190277: TCP_TUNNEL/200: 3353: CONNECT: ssl.gstatic.com:443:
-: HIER_DIRECT/216.58.196.99
1449227042.539: 143474: TCP_TUNNEL/200: 723: CONNECT:
clients5.google.com:443: -: HIER_DIRECT/216.58.196.110
1449227042.539: 142248: TCP_TUNNEL/200: 5317: CONNECT:
clients5.google.com:443: -: HIER_DIRECT/216.58.196.110
1449227042.540: 165512: TCP_TUNNEL/200: 1107: CONNECT:
clients1.google.com:443: -: HIER_DIRECT/216.58.196.110
1449227042.540: 188929: TCP_TUNNEL/200: 7668: CONNECT: plus.google.com:443:
-: HIER_DIRECT/216.58.196.110
1449227042.540: 388342: TCP_TUNNEL/200: 4996: CONNECT:
clients6.google.com:443: -: HIER_DIRECT/216.58.196.110
1449227042.540: 396197: TCP_TUNNEL/200: 2101: CONNECT: www.google.com:443:
-: HIER_DIRECT/216.58.196.100
1449227042.542: 106590: TCP_TUNNEL/200: 575: CONNECT:
clients2.google.com:443: -: HIER_DIRECT/216.58.196.110
1449227042.542: 88135: TCP_TUNNEL/200: 963: CONNECT: play.google.com:443:
-: HIER_DIRECT/216.58.196.110
1449227042.543: 6778: TCP_TUNNEL/200: 60202: CONNECT: www.google.co.in:443:
-: HIER_DIRECT/216.58.196.99
1449227042.543: 786962: TCP_TUNNEL/200: 16071: CONNECT:
0.client-channel.google.com:443: -: HIER_DIRECT/74.125.200.189
1449227042.544: 6709: TCP_TUNNEL/200: 234: CONNECT: www.google.co.in:443:
-: HIER_DIRECT/216.58.196.99
1449227042.544: 6630: TCP_TUNNEL/200: 234: CONNECT: www.google.co.in:443:
-: HIER_DIRECT/216.58.196.99
1449227042.544: 6399: TCP_TUNNEL/200: 234: CONNECT: www.google.co.in:443:
-: HIER_DIRECT/216.58.196.99
1449227045.855: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227055.855: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227065.855: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227075.855: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227085.855: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227095.855: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227105.855: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227115.855: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227125.855: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227135.855: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227145.855: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227155.855: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227165.855: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227175.855: 0: TCP_DENIED/403: 4091: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227185.855: 0: TCP_DENIED/403: 4089: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227195.855: 0: TCP_DENIED/403: 4089: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227196.494: 0: TCP_DENIED/403: 3964: CONNECT: mtalk.google.com:5228: -:
HIER_NONE/-
1449227196.503: 0: TCP_DENIED/403: 3964: CONNECT: mtalk.google.com:5228: -:
HIER_NONE/-
1449227205.589: 0: TCP_DENIED/403: 4089: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227207.642: 10969: TCP_TUNNEL/200: 4053: CONNECT: www.googleapis.com:443:
-: HIER_DIRECT/216.58.197.42
1449227207.643: 10970: TCP_TUNNEL/200: 4053: CONNECT: www.googleapis.com:443:
-: HIER_DIRECT/216.58.197.42
1449227215.671: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/-
1449227215.935: 504: TCP_TUNNEL/200: 0: CONNECT: hangouts.google.com:443:
-: HIER_DIRECT/216.58.196.110
1449227216.850: 10806: TCP_TUNNEL/200: 4045: CONNECT: ssl.gstatic.com:443:
-: HIER_DIRECT/216.58.196.99
1449227217.642: 11363: TCP_TUNNEL/200: 4770: CONNECT: plus.google.com:443:
-: HIER_DIRECT/216.58.196.110
1449227217.642: 13636: TCP_TUNNEL/200: 3993: CONNECT: ssl.gstatic.com:443:
-: HIER_DIRECT/216.58.196.99





*Thanks and RegardsVivek Kumar SinghMobile   ?+918902000538*

On Fri, Dec 4, 2015 at 12:32 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
>
> 04.12.15 12:59, vivek singh ?????:
>
> Thanks a lot for you responses.
> I will update after doing  more analysis.
>
> *@Amos Jeffries :*
> Q . How does the IP correlate to the tv_ip, sysadmin_ip,
> workstation_ip ACLs above?
> A. these are separate text files in the same directory, containing ip
> lists.
> Q. Any difference with how those machines are configured to use the proxy
> A. all the machines are in the same domain and network.
> Q. what version of squid-3.5.x is being used
> A. Squid 3.5.0.2 on Redhat Linux , packaged rpm is used.
> Q. His squid.conf does not contain anything that obviously restricts
> that.So I am suspecting the problems some old-ish browsers and OS have with
> POST messages and Expect headers
> A. On the same machine if i change it to use another windows proxy server,
> it works fine.
>
> *@ Eliezer Croitoru*
> Q. slow uploads but in 3.5.X which I am almost sure was not fixed yet
> A. while on other machines it is working fine.
>
> *@Yuri Voinov*
> Q. I suggest the problem just required to allow POST method from LAN
> and/or to mail servers. Often this can help
> A. Do i explicitly need to do so, if yes please tell me how.
>
> Example:
>
> # Adjust network as you need
> acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
> acl POST method POST
> # Allow POST for localnet
> http_access allow POST localnet
>
>
>
>
> *Thanks and Regards Vivek Kumar Singh *
>
>
> On Thu, Dec 3, 2015 at 10:01 PM, Eliezer Croitoru < <eliezer at ngtech.co.il>
> eliezer at ngtech.co.il> wrote:
>
>> Or it could be the slow uploads but in 3.5.X which I am almost sure was
>> not fixed yet.
>>
>> Eliezer
>>
>>
>> On 03/12/2015 12:24, Amos Jeffries wrote:
>>
>>> His squid.conf does not contain anything that obviously restricts that.
>>> So I am suspecting the problems some old-ish browsers and OS have with
>>> POST messages and Expect headers.
>>>
>>> Or that some of the machines have been configured in a way that only
>>> partially configures the applictinos on it, leaving some occasionally to
>>> not even find the proxy.
>>>
>>> Amos
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151204/5e538b42/attachment.htm>

From itpc.vivek at gmail.com  Fri Dec  4 14:07:55 2015
From: itpc.vivek at gmail.com (vivek singh)
Date: Fri, 4 Dec 2015 19:37:55 +0530
Subject: [squid-users] mail upload problem
In-Reply-To: <CACeaudmVbUGwhu_UJddsLQ-eKtJybCD2s5V8Ap=YS1ddtLgAVQ@mail.gmail.com>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
 <56601872.20906@treenet.co.nz> <56606E5F.30103@ngtech.co.il>
 <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>
 <56613A71.8090705@gmail.com>
 <CACeaudmVbUGwhu_UJddsLQ-eKtJybCD2s5V8Ap=YS1ddtLgAVQ@mail.gmail.com>
Message-ID: <CACeaudkXr=muJVfcWPO-8e5L-du_Lb=b-fTQOKtM4=iu+d2kTg@mail.gmail.com>

I accept http://download.newnext.me/spark.bin to be a virus redirection,
but not sure, and dint understand how it is so, i have checked the computer
for any unwanted third party  and were not found.




*Thanks and RegardsVivek Kumar SinghMobile   ?+918902000538*

On Fri, Dec 4, 2015 at 7:11 PM, vivek singh <itpc.vivek at gmail.com> wrote:

> please find below the access log while problem occur
> 1449226819.307: 0: TCP_DENIED/403: 4089: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226828.671: 249222: TCP_TUNNEL/200: 6610: CONNECT:
> clients2.google.com:443: -: HIER_DIRECT/216.58.196.110
> 1449226829.308: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226839.323: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226849.216: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226859.119: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226868.917: 0: TCP_DENIED/403: 4088: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226878.635: 0: TCP_DENIED/403: 4089: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226888.391: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226898.104: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226907.951: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226917.685: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226927.463: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226937.162: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226947.042: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226956.901: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226966.745: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226976.559: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226986.260: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449226996.214: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227006.198: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227016.198: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227026.184: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227036.072: 0: TCP_DENIED/403: 4089: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227042.281: 791782: TCP_TUNNEL/200: 5014: CONNECT:
> mtalk.google.com:443: -: HIER_DIRECT/74.125.130.188
> 1449227042.537: 714649: TCP_TUNNEL/200: 7775: CONNECT: play.google.com:443:
> -: HIER_DIRECT/216.58.196.110
> 1449227042.537: 68131: TCP_TUNNEL/200: 5813: CONNECT:
> lh3.googleusercontent.com:443: -: HIER_DIRECT/216.58.196.97
> 1449227042.538: 70423: TCP_TUNNEL/200: 2303: CONNECT: apis.google.com:443:
> -: HIER_DIRECT/216.58.196.110
> 1449227042.538: 184079: TCP_TUNNEL/200: 698: CONNECT: csi.gstatic.com:443:
> -: HIER_DIRECT/216.58.211.3
> 1449227042.539: 190277: TCP_TUNNEL/200: 3353: CONNECT: ssl.gstatic.com:443:
> -: HIER_DIRECT/216.58.196.99
> 1449227042.539: 143474: TCP_TUNNEL/200: 723: CONNECT:
> clients5.google.com:443: -: HIER_DIRECT/216.58.196.110
> 1449227042.539: 142248: TCP_TUNNEL/200: 5317: CONNECT:
> clients5.google.com:443: -: HIER_DIRECT/216.58.196.110
> 1449227042.540: 165512: TCP_TUNNEL/200: 1107: CONNECT:
> clients1.google.com:443: -: HIER_DIRECT/216.58.196.110
> 1449227042.540: 188929: TCP_TUNNEL/200: 7668: CONNECT: plus.google.com:443:
> -: HIER_DIRECT/216.58.196.110
> 1449227042.540: 388342: TCP_TUNNEL/200: 4996: CONNECT:
> clients6.google.com:443: -: HIER_DIRECT/216.58.196.110
> 1449227042.540: 396197: TCP_TUNNEL/200: 2101: CONNECT: www.google.com:443:
> -: HIER_DIRECT/216.58.196.100
> 1449227042.542: 106590: TCP_TUNNEL/200: 575: CONNECT:
> clients2.google.com:443: -: HIER_DIRECT/216.58.196.110
> 1449227042.542: 88135: TCP_TUNNEL/200: 963: CONNECT: play.google.com:443:
> -: HIER_DIRECT/216.58.196.110
> 1449227042.543: 6778: TCP_TUNNEL/200: 60202: CONNECT: www.google.co.in:443:
> -: HIER_DIRECT/216.58.196.99
> 1449227042.543: 786962: TCP_TUNNEL/200: 16071: CONNECT:
> 0.client-channel.google.com:443: -: HIER_DIRECT/74.125.200.189
> 1449227042.544: 6709: TCP_TUNNEL/200: 234: CONNECT: www.google.co.in:443:
> -: HIER_DIRECT/216.58.196.99
> 1449227042.544: 6630: TCP_TUNNEL/200: 234: CONNECT: www.google.co.in:443:
> -: HIER_DIRECT/216.58.196.99
> 1449227042.544: 6399: TCP_TUNNEL/200: 234: CONNECT: www.google.co.in:443:
> -: HIER_DIRECT/216.58.196.99
> 1449227045.855: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227055.855: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227065.855: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227075.855: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227085.855: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227095.855: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227105.855: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227115.855: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227125.855: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227135.855: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227145.855: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227155.855: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227165.855: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227175.855: 0: TCP_DENIED/403: 4091: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227185.855: 0: TCP_DENIED/403: 4089: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227195.855: 0: TCP_DENIED/403: 4089: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227196.494: 0: TCP_DENIED/403: 3964: CONNECT: mtalk.google.com:5228:
> -: HIER_NONE/-
> 1449227196.503: 0: TCP_DENIED/403: 3964: CONNECT: mtalk.google.com:5228:
> -: HIER_NONE/-
> 1449227205.589: 0: TCP_DENIED/403: 4089: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227207.642: 10969: TCP_TUNNEL/200: 4053: CONNECT:
> www.googleapis.com:443: -: HIER_DIRECT/216.58.197.42
> 1449227207.643: 10970: TCP_TUNNEL/200: 4053: CONNECT:
> www.googleapis.com:443: -: HIER_DIRECT/216.58.197.42
> 1449227215.671: 0: TCP_DENIED/403: 4090: GET:
> http://download.newnext.me/spark.bin?: -: HIER_NONE/-
> 1449227215.935: 504: TCP_TUNNEL/200: 0: CONNECT: hangouts.google.com:443:
> -: HIER_DIRECT/216.58.196.110
> 1449227216.850: 10806: TCP_TUNNEL/200: 4045: CONNECT: ssl.gstatic.com:443:
> -: HIER_DIRECT/216.58.196.99
> 1449227217.642: 11363: TCP_TUNNEL/200: 4770: CONNECT: plus.google.com:443:
> -: HIER_DIRECT/216.58.196.110
> 1449227217.642: 13636: TCP_TUNNEL/200: 3993: CONNECT: ssl.gstatic.com:443:
> -: HIER_DIRECT/216.58.196.99
>
>
>
>
>
> *Thanks and RegardsVivek Kumar SinghMobile   ?+918902000538*
>
> On Fri, Dec 4, 2015 at 12:32 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>
>>
>>
>> 04.12.15 12:59, vivek singh ?????:
>>
>> Thanks a lot for you responses.
>> I will update after doing  more analysis.
>>
>> *@Amos Jeffries :*
>> Q . How does the IP correlate to the tv_ip, sysadmin_ip,
>> workstation_ip ACLs above?
>> A. these are separate text files in the same directory, containing ip
>> lists.
>> Q. Any difference with how those machines are configured to use the proxy
>> A. all the machines are in the same domain and network.
>> Q. what version of squid-3.5.x is being used
>> A. Squid 3.5.0.2 on Redhat Linux , packaged rpm is used.
>> Q. His squid.conf does not contain anything that obviously restricts
>> that.So I am suspecting the problems some old-ish browsers and OS have with
>> POST messages and Expect headers
>> A. On the same machine if i change it to use another windows proxy
>> server, it works fine.
>>
>> *@ Eliezer Croitoru*
>> Q. slow uploads but in 3.5.X which I am almost sure was not fixed yet
>> A. while on other machines it is working fine.
>>
>> *@Yuri Voinov*
>> Q. I suggest the problem just required to allow POST method from LAN
>> and/or to mail servers. Often this can help
>> A. Do i explicitly need to do so, if yes please tell me how.
>>
>> Example:
>>
>> # Adjust network as you need
>> acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
>> acl POST method POST
>> # Allow POST for localnet
>> http_access allow POST localnet
>>
>>
>>
>>
>> *Thanks and Regards Vivek Kumar Singh *
>>
>>
>> On Thu, Dec 3, 2015 at 10:01 PM, Eliezer Croitoru <
>> <eliezer at ngtech.co.il>eliezer at ngtech.co.il> wrote:
>>
>>> Or it could be the slow uploads but in 3.5.X which I am almost sure was
>>> not fixed yet.
>>>
>>> Eliezer
>>>
>>>
>>> On 03/12/2015 12:24, Amos Jeffries wrote:
>>>
>>>> His squid.conf does not contain anything that obviously restricts that.
>>>> So I am suspecting the problems some old-ish browsers and OS have with
>>>> POST messages and Expect headers.
>>>>
>>>> Or that some of the machines have been configured in a way that only
>>>> partially configures the applictinos on it, leaving some occasionally to
>>>> not even find the proxy.
>>>>
>>>> Amos
>>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151204/5bac7e8d/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec  4 14:28:01 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 03:28:01 +1300
Subject: [squid-users] mail upload problem
In-Reply-To: <CACeaudkXr=muJVfcWPO-8e5L-du_Lb=b-fTQOKtM4=iu+d2kTg@mail.gmail.com>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
 <56601872.20906@treenet.co.nz> <56606E5F.30103@ngtech.co.il>
 <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>
 <56613A71.8090705@gmail.com>
 <CACeaudmVbUGwhu_UJddsLQ-eKtJybCD2s5V8Ap=YS1ddtLgAVQ@mail.gmail.com>
 <CACeaudkXr=muJVfcWPO-8e5L-du_Lb=b-fTQOKtM4=iu+d2kTg@mail.gmail.com>
Message-ID: <5661A2F1.8080707@treenet.co.nz>

On 5/12/2015 3:07 a.m., vivek singh wrote:
> I accept http://download.newnext.me/spark.bin to be a virus redirection,
> but not sure, and dint understand how it is so, i have checked the computer
> for any unwanted third party  and were not found.
> 

Well, it is not an upload, and does not visibly have anything to do with
mail. So your earlier report and teh subject of this thread was confusing.

These are explicit Access Control denied responses send by Squid, your
http_access rules are doing "deny".

You are not logging the client IP or the full URL so there is no way to
see if the client is correctly matched with the necessary whitelist, or
if the blacklist is having its desired effect.

Amos



From tomtux007 at gmail.com  Fri Dec  4 14:32:53 2015
From: tomtux007 at gmail.com (Tom Tom)
Date: Fri, 4 Dec 2015 15:32:53 +0100
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <566189BC.7010602@treenet.co.nz>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz>
Message-ID: <CACLJR+MF5HrpTE3Dw2kx8mqhq5zB1f1J4o17wo23SECNAzxuzA@mail.gmail.com>

Hi Amos

The configuration you provided above works also fine. Thank you. Which
configuration is generally proposed or "the way to go"?: The one,
which terminates SSL-Blacklists with "ssl_bump terminate" or the other
which denies https-Blacklist with "http_access deny"? Are there some
speed-/security...-considerations?

Kind regards,
Tom

On Fri, Dec 4, 2015 at 1:40 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 4/12/2015 9:34 p.m., Tom Tom wrote:
>> Hi list,
>>
>> I'm trying to implement SSL-Blacklists based on SHA1-Fingerprints
>> (squid 3.5.11). As I know, certificate-fingerprints are one of the
>> parts of a certificate, which are visible in a uncrypted traffic.
>>
>> It seems, that blocking https-sites based on fingerprints is only
>> working with a ssl_bump-enabled configuration. The directive, which
>> denies the access based on the fingerprint is "ssl_bump bump all" in
>> my case.
>>
>> The necessary parts of my config:
>> acl DENY_SSL_BUMP ssl::server_name_regex -i "/etc/squid/DENY_SSL_BUMP"
>> acl tls_s1_connect at_step SslBump1
>> acl SSL_BL server_cert_fingerprint "/etc/squid/SSL_BLACKLIST"
>> http_access deny SSL_BL
>>
>> http_port 3128 ssl-bump generate-host-certificates=on
>> dynamic_cert_mem_cache_size=4MB cert=/usr/local/certs/myCA.pem
>> ssl_bump peek tls_s1_connect all
>> ssl_bump splice DENY_SSL_BUMP
>> ssl_bump bump all
>>
>>
>>
>> Question:
>> Why do I need a "full" ssl_bump-configuration to prevent access based
>> on fingerprints?
>
> Because "deny" in the form you are trying to do it is an HTTP message.
> In order to perform HTTP over a TLS connection you have to decrypt it first.
>
>
>> Why is it not enough with just "peeking" the
>> certificate/connection?
>
> Because peeking is an action done to the TLS layer.
>
>
> What you actually want to be doing is:
>
>   acl step1 at_step SslBump1
>   acl whitelist ssl::server_name_regex -i "/etc/squid/DENY_SSL_BUMP"
>   acl blacklist server_cert_fingerprint "/etc/squid/SSL_BLACKLIST"
>
>   ssl_bump splice whitelist
>   ssl_bump peek step1
>   ssl_bump stare all
>   ssl_bump terminate blacklist
>   ssl_bump bump all
>
>
> Notice how http_access is not part of the TLS ssl_bump processing.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Fri Dec  4 14:47:55 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 03:47:55 +1300
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <CACLJR+MF5HrpTE3Dw2kx8mqhq5zB1f1J4o17wo23SECNAzxuzA@mail.gmail.com>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz>
 <CACLJR+MF5HrpTE3Dw2kx8mqhq5zB1f1J4o17wo23SECNAzxuzA@mail.gmail.com>
Message-ID: <5661A79B.5060608@treenet.co.nz>

On 5/12/2015 3:32 a.m., Tom Tom wrote:
> Hi Amos
> 
> The configuration you provided above works also fine. Thank you. Which
> configuration is generally proposed or "the way to go"?: The one,
> which terminates SSL-Blacklists with "ssl_bump terminate" or the other
> which denies https-Blacklist with "http_access deny"? Are there some
> speed-/security...-considerations?

terminate is the correct way to go if you are rejecting based on just
the TLS details. Squid may decrypt, but will only do the absolute
minimum necessary to get the error back to the client. Not getting
involved with the clients HTTPS data is a good idea.

Amos



From squid3 at treenet.co.nz  Fri Dec  4 14:59:33 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 03:59:33 +1300
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
Message-ID: <5661AA55.4090407@treenet.co.nz>

On 4/12/2015 11:14 p.m., Fabio Bucci wrote:
> Hi All,
> my task is implementing a squid proxy that allow all my authenticated
> (windows AD) internal users to surf internet without any credential request
> (pop-up).
> 
> Plus, i created two squid nodes and put them behind a citrix netscaler in
> order to perform a load balance service.
> 

How does this LB device work exactly? when dealing with NTLM the
specifics matter *a lot*.

Some LB sniff the HTTP traffic then route them on a per-message basis.
This is incompatible with both NTLM and Negotiate authentication, and
can cause bad confusion between the browser and proxy randomly.

Note that HTTP is a stateless protocol. So none of the browser, LB or
proxy are broken when this is going on. It is those to auth schemes that
are broken and incompatible with the designed statelessness feature of
HTTP being used by the LB.


> I configured squid with samba and ntlm helper in order to perform a
> transparent authentication but sometimes some user report me their browsers
> require authentication via pop-up.
> 
> I'm not a deep expert about squid and i'd like to receive your help in
> order to understand if my configuration is correct or not and if there is a
> way to prevent popup.

With HTTP authentication there should only ever be one popup no matter
what type of authentication scheme is used. HTTP being stateless,
requires that every single message has credentials attached (NTLM
violates that and some browsers dont always re-send while the connection
is alive; Squid accepts that, the LB may not). It is the browsers
responsibility to remember the credentials that work and continue using
them without annoying the user.


There are some proxy configurations that allow for the proxy to force
the Browser to change credentials. These can result in popups as that
change happens. We will need to see your squid.conf to provide any
specific help on that.

Amos



From rousskov at measurement-factory.com  Fri Dec  4 15:03:19 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 4 Dec 2015 08:03:19 -0700
Subject: [squid-users] using splice just to improve TLS SNI logging
In-Reply-To: <56610A1B.7010709@trimble.com>
References: <56610A1B.7010709@trimble.com>
Message-ID: <5661AB37.1050008@measurement-factory.com>

On 12/03/2015 08:35 PM, Jason Haar wrote:

> Does going "splice" mode avoid all the potential SSL/TLS issues
> surrounding bump? ie it won't care about client certs, weird TLS
> extensions, etc? (ie other than availability, it shouldn't introduce a
> new way of failing?)

Obtaining SNI information requires parsing TLS handshake, so you will be
partially exposed to the dangers of that experimental and changing code.
Splicing at step1 is safer but does not give you SNI.

Alex.



From me at hussam.eu.org  Fri Dec  4 15:37:47 2015
From: me at hussam.eu.org (Hussam Al-Tayeb)
Date: Fri, 04 Dec 2015 17:37:47 +0200
Subject: [squid-users] rock storage integrity
Message-ID: <1449243467.1017.5.camel@hussam.eu.org>

Hi. I am using squid with rock storage right now to cache computer
updates for my Linux computers. It works well.
Since this is a database, it is possible for part of the database to
get corrupted through a crash or incorrect poweroff?
I know from sql database that incorrect shutdowns can cause binary
corruption.

I had an incorrect poweroff yesterday but cache.log did not list
anything weird.

2015/12/03 01:00:11| Store rebuilding is 0.31% complete
2015/12/03 01:01:00| Finished rebuilding storage from disk.
2015/12/03 01:01:00|????319999 Entries scanned
2015/12/03 01:01:00|?????????0 Invalid entries.
2015/12/03 01:01:00|?????????0 With invalid flags.
2015/12/03 01:01:00|?????55523 Objects loaded.
2015/12/03 01:01:00|?????????0 Objects expired.
2015/12/03 01:01:00|?????????0 Objects cancelled.
2015/12/03 01:01:00|?????????0 Duplicate URLs purged.
2015/12/03 01:01:00|?????????0 Swapfile clashes avoided.
2015/12/03 01:01:00|???Took 49.94 seconds (1111.79 objects/sec).
2015/12/03 01:01:00| Beginning Validation Procedure
2015/12/03 01:01:00|???Completed Validation Procedure
2015/12/03 01:01:00|???Validated 0 Entries
2015/12/03 01:01:00|???store_swap_size = 3187216.00 KB

Nevertheless, what would be the best way to check if there was some
damage to the database (unusable slots/cells/whatever)?


From focusnetgogo at gmail.com  Fri Dec  4 15:57:36 2015
From: focusnetgogo at gmail.com (GoGo net)
Date: Fri, 4 Dec 2015 23:57:36 +0800
Subject: [squid-users] How to limit user traffic quota? (GoGo net)
In-Reply-To: <CAH8HCTT1bAcFGxPa5cq7NLPts4Tc_SWF8gu0aXy7SvG9mLrQEQ@mail.gmail.com>
References: <CAH8HCTT1bAcFGxPa5cq7NLPts4Tc_SWF8gu0aXy7SvG9mLrQEQ@mail.gmail.com>
Message-ID: <D02FE375-0B47-4C23-ADF7-C746E4805995@gmail.com>

Limit rate is another direction to limit traffic, I will think about it.

Currently, I prefer to use the script to monitor access.log, and I find a problem today:

From [squid wiki](http://wiki.squid-cache.org/Features/LogFormat):

> bytes The size is the amount of data delivered to the client. Mind that this does not constitute the net object size, as headers are also counted.

It seems that **bytes** only includes response size (including http header). What I really want is counting both http-request and http-response. Is there any way to enable http-request **bytes** being logged in access.log?


> On Dec 4, 2015, at 12:23 AM, Robert Plamondon <robert at plamondon.com> wrote:
> 
> I haven't used delay pools in a while, but I would think that the updated Squid 3 delay pools (with 64-bit counters and per-authenticated-user buckets) would allow such quotas. 
> 
> I'd take the monthly quota and turn it into a per-second rate. If my math isn't failing me, 100 GB/month = 38,500 bytes per second. That would be the refill rate on the delay pool. Users will be guaranteed this rate. Their BW would never be cut off, just throttled to the rate they're paying for.
> 
> Then pick a max value to taste. I like to populate delay pools to support an enormous burst size (the "maximum" parameter in the pool), so the bandwidth limitations will rarely if ever be encountered by the average user. 10% of the monthly allotment, or 10 GB, (3 days' worth of bandwidth) strikes me as a good starting point, but I wouldn't have much resistance to even higher numbers, like 25%.
> 
> Robert
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Dec  4 16:01:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 05:01:38 +1300
Subject: [squid-users] rock storage integrity
In-Reply-To: <1449243467.1017.5.camel@hussam.eu.org>
References: <1449243467.1017.5.camel@hussam.eu.org>
Message-ID: <5661B8E2.3020308@treenet.co.nz>

On 5/12/2015 4:37 a.m., Hussam Al-Tayeb wrote:
> Hi. I am using squid with rock storage right now to cache computer
> updates for my Linux computers. It works well.
> Since this is a database, it is possible for part of the database to
> get corrupted through a crash or incorrect poweroff?
> I know from sql database that incorrect shutdowns can cause binary
> corruption.
> 
> I had an incorrect poweroff yesterday but cache.log did not list
> anything weird.

Such types of corruption only happen if files were actively in the
process of writing data when the power went out (read does not count).

The way Squid uses a separate memory cache as the front-line I/O area
and Diskers cache as a secondary the risks of that happening are a bit
lower than with DB services that process directly to disk.


Also, unless you tuned them to a different size the rock slots/cells are
sized to match the OS natural page sizes. So there is almost no delay in
the wrote(2) within which the corruption can happen.

Your underlying FS can also play a part in preventing the corruption.

> 
> 2015/12/03 01:00:11| Store rebuilding is 0.31% complete
> 2015/12/03 01:01:00| Finished rebuilding storage from disk.
> 2015/12/03 01:01:00|    319999 Entries scanned
> 2015/12/03 01:01:00|         0 Invalid entries.
> 2015/12/03 01:01:00|         0 With invalid flags.
> 2015/12/03 01:01:00|     55523 Objects loaded.
> 2015/12/03 01:01:00|         0 Objects expired.
> 2015/12/03 01:01:00|         0 Objects cancelled.
> 2015/12/03 01:01:00|         0 Duplicate URLs purged.
> 2015/12/03 01:01:00|         0 Swapfile clashes avoided.
> 2015/12/03 01:01:00|   Took 49.94 seconds (1111.79 objects/sec).
> 2015/12/03 01:01:00| Beginning Validation Procedure
> 2015/12/03 01:01:00|   Completed Validation Procedure
> 2015/12/03 01:01:00|   Validated 0 Entries
> 2015/12/03 01:01:00|   store_swap_size = 3187216.00 KB
> 
> Nevertheless, what would be the best way to check if there was some
> damage to the database (unusable slots/cells/whatever)?

Squid does that automatically on (every) startup. The log lines you
quote above are the scan happening and its results.

If Squid had found any corruption there would have been a non-0 value on
the lines:

> 2015/12/03 01:01:00|         0 Invalid entries.
> 2015/12/03 01:01:00|         0 With invalid flags.

and possibly some WARNING notices above the "Finished rebuilding" line
if important problems were found.

Amos



From squid3 at treenet.co.nz  Fri Dec  4 16:08:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 05:08:10 +1300
Subject: [squid-users] How to limit user traffic quota? (GoGo net)
In-Reply-To: <D02FE375-0B47-4C23-ADF7-C746E4805995@gmail.com>
References: <CAH8HCTT1bAcFGxPa5cq7NLPts4Tc_SWF8gu0aXy7SvG9mLrQEQ@mail.gmail.com>
 <D02FE375-0B47-4C23-ADF7-C746E4805995@gmail.com>
Message-ID: <5661BA6A.90009@treenet.co.nz>

On 5/12/2015 4:57 a.m., GoGo net wrote:
> Limit rate is another direction to limit traffic, I will think about
> it.
> 
> Currently, I prefer to use the script to monitor access.log, and I
> find a problem today:
> 
> From [squid wiki](http://wiki.squid-cache.org/Features/LogFormat):
> 
>> bytes The size is the amount of data delivered to the client. Mind
>> that this does not constitute the net object size, as headers are
>> also counted.
> 
> It seems that **bytes** only includes response size (including http
> header). What I really want is counting both http-request and
> http-response. Is there any way to enable http-request **bytes**
> being logged in access.log?

You need to use the %st code in a custom log format.


PS. there is another problem you may not have noticed yet. The log
entries are only recorded at the *end* of each transaction. Which means
that all transactions started before the user hits their limit will be
allowed to continue consuming bandwidth until they exit naturally. At
which time the counted quota-spent value continues to go up past the
limit you set. CONNECT tunnels have indefinite lifetimes, some have been
seen lasting for weeks.

This is one of the reasons I recommend QoS controls external to Squid.
The OS can measure as each packet happens and terminate the over-quota
transactions at the TCP level.

Amos


From rousskov at measurement-factory.com  Fri Dec  4 16:15:31 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 4 Dec 2015 09:15:31 -0700
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <566189BC.7010602@treenet.co.nz>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz>
Message-ID: <5661BC23.7040109@measurement-factory.com>

On 12/04/2015 05:40 AM, Amos Jeffries wrote:
> On 4/12/2015 9:34 p.m., Tom Tom wrote:
>> Why do I need a "full" ssl_bump-configuration to prevent access based
>> on fingerprints?


> Because "deny" in the form you are trying to do it is an HTTP message.
> In order to perform HTTP over a TLS connection you have to decrypt it first.


> What you actually want to be doing is:
> 
>   acl step1 at_step SslBump1
>   acl whitelist ssl::server_name_regex -i "/etc/squid/DENY_SSL_BUMP"
>   acl blacklist server_cert_fingerprint "/etc/squid/SSL_BLACKLIST"
> 
>   ssl_bump splice whitelist
>   ssl_bump peek step1
>   ssl_bump stare all
>   ssl_bump terminate blacklist
>   ssl_bump bump all


Please consider adding this fine example to the SslPeekAndSplice wiki
page at http://wiki.squid-cache.org/Features/SslPeekAndSplice


Please note that if you do not want to bump anything, then the following
should also work (bugs notwithstanding):

    ssl_bump splice whitelist
    ssl_bump peek all
    ssl_bump terminate blacklist
    ssl_bump splice all


Thank you,

Alex.



From vze2k3sa at verizon.net  Fri Dec  4 16:53:47 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Fri, 04 Dec 2015 11:53:47 -0500
Subject: [squid-users] Understand debug Logs
Message-ID: <007001d12eb4$58752c00$095f8400$@verizon.net>

Hi,

 

I have debug level set to 2 (ALL,2) and was wondering if ANY of the
following messages in the logs below were of concern. I'm new to Squid and
loving it. Particularly where it says always_direct = DENIED & never_direct
= DENIED.

 

Thanks

Patrick

 

CONNECT mydomain.com:443 HTTP/1.1

Host: mydomain.com

Proxy-Connection: keep-alive

User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.19 (KHTML,
like Gecko) Chrome/18.0.1003.1 Safari/535.19 Awesomium/1.7.1

 

 

----------

2015/12/04 11:44:59.322 kid1| 85,2| client_side_request.cc(741)
clientAccessCheckDone: The request CONNECT mydomain.com:443 is ALLOWED; last
ACL checked: whitelist

2015/12/04 11:44:59.322 kid1| 85,2| client_side_request.cc(717)
clientAccessCheck2: No adapted_http_access configuration. default: ALLOW

2015/12/04 11:44:59.322 kid1| 85,2| client_side_request.cc(741)
clientAccessCheckDone: The request CONNECT mydomain.com:443 is ALLOWED; last
ACL checked: whitelist

2015/12/04 11:44:59.322 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
Find IP destination for: mydomain.com:443' via smart911.rave411.com

2015/12/04 11:44:59.322 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for 'mydomain.com:443'

2015/12/04 11:44:59.322 kid1| 44,2| peer_select.cc(281) peerSelectDnsPaths:
always_direct = DENIED

2015/12/04 11:44:59.322 kid1| 44,2| peer_select.cc(282) peerSelectDnsPaths:
never_direct = DENIED

2015/12/04 11:44:59.322 kid1| 44,2| peer_select.cc(286) peerSelectDnsPaths:
DIRECT = local=0.0.0.0 remote=205.126.126.230:443 flags=1

2015/12/04 11:44:59.322 kid1| 44,2| peer_select.cc(295) peerSelectDnsPaths:
timedout = 0

2015/12/04 11:44:59.457 kid1| 33,2| client_side.cc(815) swanSong:
local=192.168.1.1:3128 remote=192.168.1.233:49352 flags=1

2015/12/04 11:45:09.429 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New
connection on FD 10

2015/12/04 11:45:09.429 kid1| 5,2| TcpAcceptor.cc(295) acceptNext:
connection on local=[::]:3128 remote=[::] FD 10 flags=9

2015/12/04 11:45:09.430 kid1| 11,2| client_side.cc(2345) parseHttpRequest:
HTTP Client local=192.168.1.1:3128 remote=192.168.1.233:49353 FD 58 flags=1

2015/12/04 11:45:09.430 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client REQUEST:

---------

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151204/9b8ab9b0/attachment.htm>

From rousskov at measurement-factory.com  Fri Dec  4 16:55:17 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 4 Dec 2015 09:55:17 -0700
Subject: [squid-users] rock storage integrity
In-Reply-To: <1449243467.1017.5.camel@hussam.eu.org>
References: <1449243467.1017.5.camel@hussam.eu.org>
Message-ID: <5661C575.2090008@measurement-factory.com>

On 12/04/2015 08:37 AM, Hussam Al-Tayeb wrote:
> Since this is a database, it is possible for part of the database to
> get corrupted through a crash or incorrect poweroff?

It depends on your definition of "corruption". Yes, it is possible that
some database updates will be incomplete because of a poweroff. Bugs
notwithstanding, after a restart,

* Squid will not notice that an entry that was supposed to be deleted
was not. Squid will continue to serve such an entry from the cache.

* Assuming atomic single-write disk I/Os, Squid should notice an entry
that was only partially saved and not serve it from the cache. Its slots
will be considered free space.

* In the event a single-write disk I/O was only partially completed,
Squid may or may not notice a partial save, depending on what was
actually written to disk. There is currently no Squid code that detects
non-atomic single-write disk I/Os. AFAICT, this might corrupt up to two
cache entries per cache_dir in such a way that Squid will not notice the
corruption unless there are some OS-level protections against that.
Squid uses regular file system calls for writing entries...

* There should be no effect on entries already fully stored at the time
of the power outage.


> I had an incorrect poweroff yesterday but cache.log did not list
> anything weird.

> Nevertheless, what would be the best way to check if there was some
> damage to the database (unusable slots/cells/whatever)?

IIRC, for Rock, all validation is currently done automagically upon startup.


HTH,

Alex.



From squid3 at treenet.co.nz  Fri Dec  4 17:21:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 06:21:46 +1300
Subject: [squid-users] Understand debug Logs
In-Reply-To: <007001d12eb4$58752c00$095f8400$@verizon.net>
References: <007001d12eb4$58752c00$095f8400$@verizon.net>
Message-ID: <5661CBAA.6080408@treenet.co.nz>

On 5/12/2015 5:53 a.m., Patrick Flaherty wrote:
> Hi,
> 
> I have debug level set to 2 (ALL,2) and was wondering if ANY of the
> following messages in the logs below were of concern.

level "ALL,0" displays only critical issues.

level ALL,1 displays the above plus other important issues that should
be attended to, but are not serious enough to panic about.

Everything else is informational. Squid has a long history of people
randomly selecting what level to display things at, so there is not much
coherency.


> I'm new to Squid and
> loving it. Particularly where it says always_direct = DENIED & never_direct
> = DENIED.
> 

The first means the message was not forced to go DIRECT to a DNS listed
server.

The second means the message was not forced to go to a cache_peer.

Amos



From itpc.vivek at gmail.com  Fri Dec  4 18:02:12 2015
From: itpc.vivek at gmail.com (vivek singh)
Date: Fri, 4 Dec 2015 23:32:12 +0530
Subject: [squid-users] mail upload problem
In-Reply-To: <5661A2F1.8080707@treenet.co.nz>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
 <56601872.20906@treenet.co.nz> <56606E5F.30103@ngtech.co.il>
 <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>
 <56613A71.8090705@gmail.com>
 <CACeaudmVbUGwhu_UJddsLQ-eKtJybCD2s5V8Ap=YS1ddtLgAVQ@mail.gmail.com>
 <CACeaudkXr=muJVfcWPO-8e5L-du_Lb=b-fTQOKtM4=iu+d2kTg@mail.gmail.com>
 <5661A2F1.8080707@treenet.co.nz>
Message-ID: <CACeaudkkCamyid-i929dDjXW9HcPrpiYnhEPVbJbDS9vjzJZXQ@mail.gmail.com>

Thanks a lot
1. These logs are of the moment when when an gmail attachment was
initiated on the user machine.
2. Logs have been filtered for that particular user, and hence have
not been shown in the previous post.
3. I am worried that, while initiating the mail attachment in the user
machine, no other task was being performed on that machine, so how
come the line
1449226966.745: 0: TCP_DENIED/403: 4090: GET:
http://download.newnext.me/spark.bin?: -: HIER_NONE/
come into picture,
of cource access to http://download.newnext.me/spark.bin is not
allowed in proxy server, but even we dont think to allow that,
4. if http://download.newnext.me/spark.bin have nothing to do with
mail attachement problem, then what could be the cause,

   I really appreciate your replies, Again I am thankful to you


-- 




*Thanks and RegardsVivek Kumar SinghJ.T.O./ITPC-KolkataMobile
 08902000538Landline 033-23211548*


From sam at idsdoc.com  Fri Dec  4 18:04:35 2015
From: sam at idsdoc.com (Samuel Anderson)
Date: Fri, 4 Dec 2015 13:04:35 -0500
Subject: [squid-users] Authentication Problem
In-Reply-To: <CAOpdYysr9-abvae=F20kZTzgq29bPw5h=Z8Bi82=iZvwBwA=6w@mail.gmail.com>
References: <CAOpdYysqg4B0ybwj3MGbC0-37AsnJRhpddSt1+c8w=4mkDOY9w@mail.gmail.com>
 <5660F27B.6000907@treenet.co.nz>
 <CAOpdYysr9-abvae=F20kZTzgq29bPw5h=Z8Bi82=iZvwBwA=6w@mail.gmail.com>
Message-ID: <CAP6yRXj5oeW5WSFwu4NrEfoe1yJWg80w4eKrmZtno2hqRzijNQ@mail.gmail.com>

Hi Amos and Dima,

I'm having the exact same problem. After updating Chrome to version
(47.0.2526.73
m) I'm no longer able to authenticate. IE and Firefox still seem to work
fine. I haven't changed anything in my config file for months.

On Fri, Dec 4, 2015 at 5:22 AM, Dima Ermakov <demonihin at gmail.com> wrote:

> Thank you, Amos.
>
> I checked all, that you wrote.
> It didn't help me.
>
> I have this problem only on google chrome browser.
> Before 2015-12-03 all was good.
> I didn't change my configuration more than one month.
>
> Ten minutes ago "Noel Kelly nkelly at citrusnetworks.net" wrote in this
> list, that google chrome v47 has broken NTLM authentication.
> My clients with problems has google chrome v47 (((
>
> Mozilla Firefox clients work good.
>
> Thank you!
>
> This is message from Noel Kelly:
> "
>
> Hi
>
> For information, the latest version of Google Chrome (v47.0.2526.73M) has
> broken NTLM authentication:
>
> https://code.google.com/p/chromium/issues/detail?id=544255
>
> https://productforums.google.com/forum/#!topic/chrome/G_9eXH9c_ns;context-place=forum/chrome
>
> Cheers
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> "
>
> On 4 December 2015 at 04:55, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>> On 4/12/2015 9:46 a.m., Dima Ermakov wrote:
>> > Hi!
>> > I have a problem with authentiation.
>> >
>> > I use samba ntlm authentication in my network.
>> >
>> > Some users ( not all ) have problems with http traffic.
>> >
>> > They see basic authentication request.
>>
>> Meaning you *dont* have NTLM authentication on your network.
>>
>> Or you are making the mistake of thinking a popup means Basic
>> authentication.
>>
>> > If they enter correct domain login and password, they have auth error.
>> > If this users try to open https sites: all works good, they have not any
>> > type of errors.
>>
>> So,
>>  a) they are probably not going through this proxy, or
>>  b) the browser is suppressing the proxy-auth popups, or
>>  c) the authentication request is not coming from *your* proxy.
>>
>> >
>> > So we have errors only with unencrypted connections.
>> >
>> > I have this error on two servers:
>> > debian8, squid3.4 (from repository)
>> > CentOS7, squid3.3.8 (from repository).
>> >
>>
>> Two things to try:
>>
>> 1) Adding a line like this before the group access controls in
>> frntend.conf. This will ensure that authentiation credentials are valid
>> before doing group lookups:
>>  http_access deny !AuthorizedUsers
>>
>>
>> 2) checking up on the Debian winbind issue mentioned in
>> <
>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm#winbind_privileged_pipe_permissions
>> >
>>
>> Im not sure about this it is likely to be involved on Debian, but CentOS
>> is not known to have that issue.
>>
>>
>> Oh and:
>>  3) remove the "acl manager" line from squid.conf.
>>
>>  4) change your cachemgr_passwd. Commenting it out does not hide it from
>> view when you post it on this public mailing list.
>>
>> You should remove all the commented out directives as well, some of them
>> may be leading to misunderstanding of what the config is actually doing.
>>
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
>
> --
> ? ?????????, ??????? ???????.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


-- 
Samuel Anderson  |  System Administrator  |  International Document Services

IDS  |  11629 South 700 East, Suite 200  |  Draper, UT 84020-4607

-- 
CONFIDENTIALITY NOTICE:
This e-mail and any attachments are confidential. If you are not an 
intended recipient, please contact the sender to report the error and 
delete all copies of this message from your system.  Any unauthorized 
review, use, disclosure or distribution is prohibited.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151204/724060ed/attachment.htm>

From squid3 at treenet.co.nz  Sat Dec  5 05:36:23 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 18:36:23 +1300
Subject: [squid-users] doubts about the squid3
In-Reply-To: <CA+0TdypzvZ3RGvG_v3=eWKe7FFM26c1B4VQp3sZZShJuxrsosA@mail.gmail.com>
References: <CA+0TdyqipgBeMAscVKGeMvTkY1L_Di-3Or3f=LZJcW2y65jjhw@mail.gmail.com>
 <56600E7D.1020203@treenet.co.nz>
 <CA+0TdypzvZ3RGvG_v3=eWKe7FFM26c1B4VQp3sZZShJuxrsosA@mail.gmail.com>
Message-ID: <566277D7.6010308@treenet.co.nz>

On 5/12/2015 11:20 a.m., Marcio Demetrio Bacci wrote:
> Hi Amos,
> 
> Thanks for help me.
> 
> Follow my whole squid.conf

<snip>
> acl manager proto cache_object


I see you still have the old Squid-2 definition for "manager" ACL. If
your Squid is not complaining about that, it means you are using a very
old version and need to upgrade.
 The config should work, so I think you are hitting bugs in Squid. With
Squid older than 3.4 it could be bug 2305 and the related nest of
horrible auth code that used to exist in Squid.

Please ensure you are using a Squid-3.4 or later. If the problem
remains, you will have to try to isolate some situatino that always
causes it. With that a ALL,9 debug log from Squid could help.


Also, be aware that there is always the possibility of browser bugs
being involved. Firefx 25-40 did not do NTLM properly, and Chrome 47
just had a major regression where it broke all NTLM to a proxy - similar
but less high profile things have happened before with both of them, and
old IE 0-8 can be randomly problems as they do their own undocumented
things.


<snip>
> acl Safe_ports port 80 8080 21 443 563 70 210 280 488 591 777 3001
> 1025-65535

You don't have to add port 8080 or 3001 to that list. They are included
in the 1025-65535 set.

<snip>
> acl connect_abertas maxconn 8

connect_abertas is unused. You should remove it.

> acl grupo_admins external ad_group gg_admins
> acl grupo_users external ad_group gg_users
> acl extensoes_bloqueadas url_regex -i "/etc/squid3/acls/extensoes-proibidas"
> acl sites_liberados url_regex -i "/etc/squid3/acls/sites-permitidos"
> acl sites_bloqueados url_regex -i "/etc/squid3/acls/sites-proibidos"
> acl palavras_bloqueadas url_regex -i "/etc/squid3/acls/palavras-proibidas"
> acl autenticados proxy_auth REQUIRED
> http_access deny !autenticados
> http_access allow grupo_admins
> http_access deny extensoes_bloqueadas
> http_access allow sites_liberados
> http_access deny sites_bloqueados
> http_access deny palavras_bloqueadas
> http_access allow grupo_users
> http_access allow autenticados

Only autenticados can get past the "deny !autenticados" at the top. So
this "allow autenticados" will always match. The below lines do nothing
useful.

So you could replace the above "allow autenticados" with "allow all" and
save some extra auth checking.


> acl network_servers src 192.168.0.0/25
> acl Lan1 src 192.168.1.0/24
> acl lan2 src 192.168.2.0/23
> http_access allow  network_servers
> http_access allow lan1
> http_access allow lan2
> http_access deny all
> error_directory /usr/share/squid3/errors/pt-br

I hear Brazil is a multi-cultural country. You might want to seriously
consider removing that line which forces all users and clients to read
Portuguese (Brazi) language messages from the proxy.

Amos



From squid3 at treenet.co.nz  Sat Dec  5 06:22:07 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Dec 2015 19:22:07 +1300
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
Message-ID: <5662828F.5090007@treenet.co.nz>

On 5/12/2015 5:39 a.m., Fabio Bucci wrote:
> Thanks Amos.
> Actually my load balancing is configured to perform round robin balancing
> between the two nodes. I added a session persistance by source ip in order
> to avoid to login again with some sites.
> 
> my squid.conf is very simple:
> auth_param ntlm program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 100
> auth_param ntlm keep_alive off
> 
> acl auth proxy_auth REQUIRED
> 
> http_access allow auth
> 

Okay. That *should* work. With some NTLM-specific caveats.


> forwarded_for on
> follow_x_forwarded_for allow netscaler
> 

If the LB is touching the traffic enough to add headers then it is a
proxy. NTLM does not work at all well through proxies. NTLM as a whole
is based on the assumption that there is one (and only one) TCP
connection between it and the proxy - the credentials are tied to the
TCP connection state.

There is one VERY slim hack that lets NTLM pass straight through a
frontend proxy/LB. That is by pinning the LB's inbound and outbound TCP
connections together. This is not just session persistence, but absolute
prohibition on any other traffic (even from other connections by the
same client) being sent to that outbound LB->proxy connection. Some LB
can do it, some can't.


I recommend advertising both/all proxy IPs to the clients and letting
each select the one(s) it wants to contact. That way the client can
perform NTLM directly to the Squid.


On the other hand NTLM was deprecated back in 2006, you should try
migrating to Negotiate/Kerberos. Kerberos is a bit of a learning curve
and can be tricky working with older client software. But is *way* more
efficient and friendlier to HTTP (but still not fully).


Amos



From eliezer at ngtech.co.il  Sat Dec  5 20:25:24 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 5 Dec 2015 22:25:24 +0200
Subject: [squid-users] mail upload problem
In-Reply-To: <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>
References: <CACeaudmBj=_=LCmAGpkxjEC-zRt-S8SQmdLnY1P-pxtV1hm3yA@mail.gmail.com>
 <201512020958.48412.Antony.Stone@squid.open.source.it>
 <CACeaudmM04oUg670dYWAyaicPuzAMi-UzNsdbdhwLCroKWk9ZQ@mail.gmail.com>
 <56601324.3030508@treenet.co.nz> <56601393.8090004@gmail.com>
 <56601872.20906@treenet.co.nz> <56606E5F.30103@ngtech.co.il>
 <CACeaudkar3eXRgUb90Wm56snWg-U+feKB+Y8sAOJMb=hp4hdKQ@mail.gmail.com>
Message-ID: <56634834.5050106@ngtech.co.il>

On 04/12/2015 08:59, vivek singh wrote:
> Thanks a lot for you responses.
> I will update after doing  more analysis.
>
> *@Amos Jeffries :*
> Q . How does the IP correlate to the tv_ip, sysadmin_ip,
> workstation_ip ACLs above?
> A. these are separate text files in the same directory, containing ip lists.
> Q. Any difference with how those machines are configured to use the proxy
> A. all the machines are in the same domain and network.
> Q. what version of squid-3.5.x is being used
> A. Squid 3.5.0.2 on Redhat Linux , packaged rpm is used.
> Q. His squid.conf does not contain anything that obviously restricts
> that.So I am suspecting the problems some old-ish browsers and OS have with
> POST messages and Expect headers
> A. On the same machine if i change it to use another windows proxy server,
> it works fine.
>
> *@ Eliezer Croitoru*
> Q. slow uploads but in 3.5.X which I am almost sure was not fixed yet
> A. while on other machines it is working fine.
The same squid version? other machines you mean other OS or other VM\box?
The reason I asked is due to some tcp level bug which causes POST 
requests and maybe couple other cases to be sent in chunks of 39 
bytes...converting 1500bytes which might fit into 1 or 2 tcp writes into 
a sequence of about 38 chunks.. which in some if not all cases causes 
slow uploads for many sites.

Eliezer

>
> *@Yuri Voinov*
> Q. I suggest the problem just required to allow POST method from LAN and/or
> to mail servers. Often this can help
> A. Do i explicitly need to do so, if yes please tell me how.
>
>
>
> *Thanks and RegardsVivek Kumar Singh*
>
>
> On Thu, Dec 3, 2015 at 10:01 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
> wrote:
>
>> Or it could be the slow uploads but in 3.5.X which I am almost sure was
>> not fixed yet.
>>
>> Eliezer
>>
>>
>> On 03/12/2015 12:24, Amos Jeffries wrote:
>>
>>> His squid.conf does not contain anything that obviously restricts that.
>>> So I am suspecting the problems some old-ish browsers and OS have with
>>> POST messages and Expect headers.
>>>
>>> Or that some of the machines have been configured in a way that only
>>> partially configures the applictinos on it, leaving some occasionally to
>>> not even find the proxy.
>>>
>>> Amos
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>



From xxiao8 at fosiao.com  Sun Dec  6 02:45:15 2015
From: xxiao8 at fosiao.com (xxiao8)
Date: Sat, 5 Dec 2015 20:45:15 -0600
Subject: [squid-users] http request header must use hostname
Message-ID: <5663A13B.3030306@fosiao.com>

is it possible to enforce all http requests must use non-IP for the 
destination, i.e. dns/hostname.

for example: http://www.google.com will be fine, but http://some-IP will 
not.

Thanks,
xxiao



From yvoinov at gmail.com  Sun Dec  6 10:07:48 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 6 Dec 2015 16:07:48 +0600
Subject: [squid-users] http request header must use hostname
In-Reply-To: <5663A13B.3030306@fosiao.com>
References: <5663A13B.3030306@fosiao.com>
Message-ID: <566408F4.3080902@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
# Numeric IP's acl
acl numeric_IPs dstdom_regex [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+

# Deny access to numeric IP's
http_access deny CONNECT numeric_IPs
deny_info TCP_RESET numeric_IPs


06.12.15 8:45, xxiao8 ?????:
> is it possible to enforce all http requests must use non-IP for the destination, i.e. dns/hostname.
>
> for example: http://www.google.com will be fine, but http://some-IP
will not.
>
> Thanks,
> xxiao
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWZAj0AAoJENNXIZxhPexGQTsH/jRjgc6Eo+zSDFnCKybq/wvw
w7p17tjH15OIMg0K2KeHci2JP+EVh6oi6SmBw/F6tl3siD1kuat01aCMFtATCLwu
OTTXrPUZXyUp/m7hv2VSLyeIrK+pQEkY9v4Co5KRRdXcDhNb/4WiyCqcTAcd5m57
vB5EU48HB/nJdMkZi+QnTDtpboXvsu+t2r1w/YPEj5Mz4Ah5MRkmjmjtTlggPr/H
7LsZSfttNP3cq5jVLkRQqJEiPdO5BGqeqAH4i/dxV7PNIX//v2SwBHf/qS+bU3VN
4ITGxarFz0hdVMCgZBEZa+3yQwF8D9yE+3cqPyV569doH0dljU+/szdrWdRr1nU=
=32ma
-----END PGP SIGNATURE-----



From eliezer at ngtech.co.il  Sun Dec  6 18:19:10 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 6 Dec 2015 20:19:10 +0200
Subject: [squid-users] http request header must use hostname
In-Reply-To: <566408F4.3080902@gmail.com>
References: <5663A13B.3030306@fosiao.com> <566408F4.3080902@gmail.com>
Message-ID: <56647C1E.3010704@ngtech.co.il>

I would make it a more accurate regex which requires start and end line 
matching and max size of the number like:
acl numeric_IPs dstdom_regex 
^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$

It will match more the exact real IP addresses but it will work.

Eliezer

On 06/12/2015 12:07, Yuri Voinov wrote:
> # Numeric IP's acl
> acl numeric_IPs dstdom_regex [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
>
> # Deny access to numeric IP's
> http_access deny CONNECT numeric_IPs
> deny_info TCP_RESET numeric_IPs



From Walter.H at mathemainzel.info  Sun Dec  6 18:38:30 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Sun, 06 Dec 2015 19:38:30 +0100
Subject: [squid-users] http request header must use hostname
In-Reply-To: <566408F4.3080902@gmail.com>
References: <5663A13B.3030306@fosiao.com> <566408F4.3080902@gmail.com>
Message-ID: <566480A6.5070809@mathemainzel.info>

On 06.12.2015 11:07, Yuri Voinov wrote:
> # Numeric IP's acl
> acl numeric_IPs dstdom_regex [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
>
> # Deny access to numeric IP's
> http_access deny CONNECT numeric_IPs
> deny_info TCP_RESET numeric_IPs
>
and not to forget IPv6 ...

acl numeric_IPs_ipv4 dstdom_regex [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+

acl numeric_IPs_ipv6 dstdom_regex ([0-9A-Fa-f]+|\:)+[0-9A-Fa-f]+

http_access deny CONNECT numeric_IPs_ipv4
deny_info TCP_RESET numeric_IPs_ipv4

http_access deny CONNECT numeric_IPs_ipv6
deny_info TCP_RESET numeric_IPs_ipv6

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151206/42d7f1ff/attachment.bin>

From nkelly at citrusnetworks.net  Sun Dec  6 20:54:59 2015
From: nkelly at citrusnetworks.net (Noel Kelly)
Date: Sun, 6 Dec 2015 20:54:59 +0000
Subject: [squid-users] ntlm_auth defaulting to succeed
In-Reply-To: <CA+Y8hcMYgdkMLN0dYVdh4wCSgSqWAM=fHySb21KgmTRYFpjWhQ@mail.gmail.com>
References: <565F5E5C.1000103@citrusnetworks.net>
 <CA+Y8hcMYgdkMLN0dYVdh4wCSgSqWAM=fHySb21KgmTRYFpjWhQ@mail.gmail.com>
Message-ID: <5664A0A3.2060008@citrusnetworks.net>

Thanks for this Francesco.  I have been experimenting with the various 
authenticators without much success.

I have compiled squid-3.5.11 from source and ntlm_fake_auth doesn't 
appear to work.  I have scoured the docs and the forums but I can't find 
anyone saying it doesn't work.

I have it set up like this in my squid.conf:

auth_param ntlm program /usr/local/squid/libexec/ntlm_fake_auth -d -v -S

but I just get denied access whilst sending ADS 2008R2 domain 
authentication via Firefox:

==> /usr/local/squid/var/logs/access.log <==
1449434911.652      0 192.168.5.35 TCP_DENIED/407 4473 GET 
http://www.bbc.co.uk/ - HIER_NONE/- text/html

==> /usr/local/squid/var/logs/cache.log <==
ntlm_fake_auth.cc(163): pid=30933 :Got 'YR' from Squid with data:
[0000]   4E 54 4C 4D 53 53 50 00   01 00 00 00 07 82 08 A2 NTLMSSP. ........
[0010]   00 00 00 00 00 00 00 00   00 00 00 00 00 00 00 00 ........ ........
[0020]   06 01 B1 1D 00 00 00 0F   00 00 ........ ..
ntlm_fake_auth.cc(185): pid=30933 :sending 'TT' to squid with data:
[0000]   4E 54 4C 4D 53 53 50 00   02 00 00 00 09 00 09 00 NTLMSSP. ........
[0010]   AE AA AA AA 07 82 08 A2   E4 9D FA 04 45 14 D1 A5 ........ ....E...
[0020]   00 00 00 00 00 00 3A 00   57 4F 52 4B 47 52 4F 55 ........ WORKGROU
[0030]   50                                                  P

==> /usr/local/squid/var/logs/access.log <==
1449434911.660      0 192.168.5.35 TCP_DENIED/407 4640 GET 
http://www.bbc.co.uk/ - HIER_NONE/- text/html
1449434911.706      0 192.168.5.35 TCP_IMS_HIT/304 249 GET 
http://tex.uk.plc:8080/squid-internal-static/icons/SN.png - HIER_NONE/- 
image/png
1449434913.266      0 192.168.5.35 TCP_DENIED/407 4473 GET 
http://www.bbc.co.uk/ - HIER_NONE/- text/html

==> /usr/local/squid/var/logs/cache.log <==
ntlm_fake_auth.cc(163): pid=30933 :Got 'YR' from Squid with data:
[0000]   4E 54 4C 4D 53 53 50 00   01 00 00 00 07 82 08 A2 NTLMSSP. ........
[0010]   00 00 00 00 00 00 00 00   00 00 00 00 00 00 00 00 ........ ........
[0020]   06 01 B1 1D 00 00 00 0F   00 00 ........ ..
ntlm_fake_auth.cc(185): pid=30933 :sending 'TT' to squid with data:
[0000]   4E 54 4C 4D 53 53 50 00   02 00 00 00 09 00 09 00 NTLMSSP. ........
[0010]   AE AA AA AA 07 82 08 A2   CE 7D A2 0A 08 8A 68 B2 ........ ......h.
[0020]   00 00 00 00 00 00 3A 00   57 4F 52 4B 47 52 4F 55 ........ WORKGROU
[0030]   50                                                  P

==> /usr/local/squid/var/logs/access.log <==
1449434913.272      0 192.168.5.35 TCP_DENIED/407 4640 GET 
http://www.bbc.co.uk/ - HIER_NONE/- text/html
1449434913.319      0 192.168.5.35 TCP_IMS_HIT/304 249 GET 
http://tex.uk.plc:8080/squid-internal-static/icons/SN.png - HIER_NONE/- 
image/png


I have tried ntlm_fake_auth.pl.in and ntlm_smb_lm_auth without success 
too.  We have used ntlm_auth for years but have issues with the process 
sometimes failing due to ADS password changes etc so hence the desire 
for a dummy/fake authentication.

Does anyone know if ntlm_fake_auth should work with squid v3.5.11 ?

Many thanks
Noel

On 03/12/15 05:19, Kinkie wrote:
> Hi,
>    you can check the ntlm_fake_auth helper; it'll blandly trust
> anything the user says.
>
> On Wed, Dec 2, 2015 at 10:10 PM, Noel Kelly<nkelly at citrusnetworks.net>  wrote:
>> Hello All
>>
>> We have been using Squid and ntlm_auth for many years with mainly success.
>> However we have always had a few annoyances like continual authentication
>> pop-ups if a user has changed their password and not restarted their session
>> or, as now, persistent popups which seem related to a browser update (Google
>> Chrome is the suspect currently).
>>
>> It occurred to me that thee days we don't use ntlm_auth to block Internet
>> access per se but rather to capture the username to manage access using ACLs
>> and the username.
>>
>> So I was wondering if anyone had any ideas for a Squid config where the
>> ntlm_auth helper always succeeded regardless of the password  so they user
>> gets waived through and Squid has the username needed to process the ACLs?
>>
>> Thanks
>> Noel
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>

-- 
=======================
Noel Kelly
Citrus Networks
m: 07939 528 478
t: 0207 100 2410
e:nkelly at citrusnetworks.net
=======================
Citrus Networks UK Ltd is registered
in England and Wales with company
number 3927941. Registered Office:
Gladstone House, 77-79 High St,
Egham, Surrey TW20 9HY.
VAT Reg. 748716690
=======================



From squid3 at treenet.co.nz  Sun Dec  6 23:21:33 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 7 Dec 2015 12:21:33 +1300
Subject: [squid-users] http request header must use hostname
In-Reply-To: <566480A6.5070809@mathemainzel.info>
References: <5663A13B.3030306@fosiao.com> <566408F4.3080902@gmail.com>
 <566480A6.5070809@mathemainzel.info>
Message-ID: <5664C2FD.1090907@treenet.co.nz>

On 7/12/2015 7:38 a.m., Walter H. wrote:
> On 06.12.2015 11:07, Yuri Voinov wrote:
>> # Numeric IP's acl
>> acl numeric_IPs dstdom_regex [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
>>
>> # Deny access to numeric IP's
>> http_access deny CONNECT numeric_IPs
>> deny_info TCP_RESET numeric_IPs
>>
> and not to forget IPv6 ...
> 
> acl numeric_IPs_ipv4 dstdom_regex [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
> 
> acl numeric_IPs_ipv6 dstdom_regex ([0-9A-Fa-f]+|\:)+[0-9A-Fa-f]+
> 
> http_access deny CONNECT numeric_IPs_ipv4
> deny_info TCP_RESET numeric_IPs_ipv4
> 
> http_access deny CONNECT numeric_IPs_ipv6
> deny_info TCP_RESET numeric_IPs_ipv6

OR IPv4-mapped address format,
OR that port can be included,
OR the fact that raw-IP can be used on any request..


  acl ips
^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|[0-9\.]+)?\]))(:[0-9])?$

 http_access deny CONNECT ips
 deny_info TCP_RESET ips


Getting complicated...

So xxiao8, why does one want to censor these requests anyway?

Amos



From squid3 at treenet.co.nz  Sun Dec  6 23:37:41 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 7 Dec 2015 12:37:41 +1300
Subject: [squid-users] ntlm_auth defaulting to succeed
In-Reply-To: <5664A0A3.2060008@citrusnetworks.net>
References: <565F5E5C.1000103@citrusnetworks.net>
 <CA+Y8hcMYgdkMLN0dYVdh4wCSgSqWAM=fHySb21KgmTRYFpjWhQ@mail.gmail.com>
 <5664A0A3.2060008@citrusnetworks.net>
Message-ID: <5664C6C5.3080907@treenet.co.nz>

On 7/12/2015 9:54 a.m., Noel Kelly wrote:
> Thanks for this Francesco.  I have been experimenting with the various
> authenticators without much success.
> 
> I have compiled squid-3.5.11 from source and ntlm_fake_auth doesn't
> appear to work.  I have scoured the docs and the forums but I can't find
> anyone saying it doesn't work.

It works if your clients accept a downgrade attack to NTLMv1.


> 
> I have it set up like this in my squid.conf:
> 
> auth_param ntlm program /usr/local/squid/libexec/ntlm_fake_auth -d -v -S
> 
> but I just get denied access whilst sending ADS 2008R2 domain
> authentication via Firefox:
> 
> ==> /usr/local/squid/var/logs/access.log <==
> 1449434911.652      0 192.168.5.35 TCP_DENIED/407 4473 GET
> http://www.bbc.co.uk/ - HIER_NONE/- text/html
> 
> ==> /usr/local/squid/var/logs/cache.log <==
> ntlm_fake_auth.cc(163): pid=30933 :Got 'YR' from Squid with data:
> [0000]   4E 54 4C 4D 53 53 50 00   01 00 00 00 07 82 08 A2 NTLMSSP.
> ........
> [0010]   00 00 00 00 00 00 00 00   00 00 00 00 00 00 00 00 ........
> ........
> [0020]   06 01 B1 1D 00 00 00 0F   00 00 ........ ..
> ntlm_fake_auth.cc(185): pid=30933 :sending 'TT' to squid with data:
> [0000]   4E 54 4C 4D 53 53 50 00   02 00 00 00 09 00 09 00 NTLMSSP.
> ........
> [0010]   AE AA AA AA 07 82 08 A2   E4 9D FA 04 45 14 D1 A5 ........
> ....E...
> [0020]   00 00 00 00 00 00 3A 00   57 4F 52 4B 47 52 4F 55 ........
> WORKGROU
> [0030]   50                                                  P
> 

That shows the first 407 out of the NTLM handshake being prepared by the
helper. Where is the second?


> ==> /usr/local/squid/var/logs/access.log <==
> 1449434911.660      0 192.168.5.35 TCP_DENIED/407 4640 GET
> http://www.bbc.co.uk/ - HIER_NONE/- text/html
> 1449434911.706      0 192.168.5.35 TCP_IMS_HIT/304 249 GET
> http://tex.uk.plc:8080/squid-internal-static/icons/SN.png - HIER_NONE/-
> image/png
> 1449434913.266      0 192.168.5.35 TCP_DENIED/407 4473 GET
> http://www.bbc.co.uk/ - HIER_NONE/- text/html

Either the client is not working correctly, or there are some missing
log lines earlier from the client. Note that NTLM auth may take many
seconds.

NTLM requires two 407 messages to perform its handshake. That cache.log
section is showing only the first step where the type-1 token (YR) is
being processed and type-2 (TT) generated for delivery to the UA.

The access.log is showing what appears to be only the final step, where
Squid is rejecting type-3 (KK) token and the UA is displaying the
auth-required error page message to the user.
 If that UA is displaying errors based on the TT token, then it is flat
out broken.

> 
> I have tried ntlm_fake_auth.pl.in and ntlm_smb_lm_auth without success
> too.


SMB LM helper requires a NTLM downgrade attack all the way to plain-text
LM auth so Squids' simple helper can decrypt on the fly. It is
thankfully getting kind of rare to encounter software which supports LM.

Amos



From alex at samad.com.au  Sun Dec  6 23:46:07 2015
From: alex at samad.com.au (Alex Samad)
Date: Mon, 7 Dec 2015 10:46:07 +1100
Subject: [squid-users] chrome proxy issue
Message-ID: <CAJ+Q1PVCtCAe9rmCCRH1+zLKrhc2xQmEeKoEZ7mEjQkXQZd7xg@mail.gmail.com>

Hi

https://code.google.com/p/chromium/issues/detail?id=544255
Not a squid issue, but might stop people wasting time debugging squid

A


From xxiao8 at fosiao.com  Mon Dec  7 00:13:28 2015
From: xxiao8 at fosiao.com (xxiao8)
Date: Sun, 6 Dec 2015 18:13:28 -0600
Subject: [squid-users] http request header must use hostname
In-Reply-To: <mailman.6437.1449445576.2892.squid-users@lists.squid-cache.org>
References: <mailman.6437.1449445576.2892.squid-users@lists.squid-cache.org>
Message-ID: <5664CF28.9080809@fosiao.com>


On 7/12/2015 7:38 a.m., Walter H. wrote:
 > On 06.12.2015 11:07, Yuri Voinov wrote:
 >> # Numeric IP's acl
 >> acl numeric_IPs dstdom_regex [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
 >>
 >> # Deny access to numeric IP's
 >> http_access deny CONNECT numeric_IPs
 >> deny_info TCP_RESET numeric_IPs
 >>
 > and not to forget IPv6 ...
 >
 > acl numeric_IPs_ipv4 dstdom_regex [0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
 >
 > acl numeric_IPs_ipv6 dstdom_regex ([0-9A-Fa-f]+|\:)+[0-9A-Fa-f]+
 >
 > http_access deny CONNECT numeric_IPs_ipv4
 > deny_info TCP_RESET numeric_IPs_ipv4
 >
 > http_access deny CONNECT numeric_IPs_ipv6
 > deny_info TCP_RESET numeric_IPs_ipv6

OR IPv4-mapped address format,
OR that port can be included,
OR the fact that raw-IP can be used on any request..


   acl ips
^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|[0-9\.]+)?\]))(:[0-9])?$

  http_access deny CONNECT ips
  deny_info TCP_RESET ips


Getting complicated...

So xxiao8, why does one want to censor these requests anyway?

Amos

---

Thanks for all the replies. The reason is to enforce dns-based filtering 
so you can't type in IP to bypass it easily.

xxiao



From squid3 at treenet.co.nz  Mon Dec  7 01:25:31 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 7 Dec 2015 14:25:31 +1300
Subject: [squid-users] doubts about the squid3
In-Reply-To: <CA+0TdyrOjjo+wb7HHkWNPwyJEpZsLmCimuGWi2Nc=SXwSVxYQA@mail.gmail.com>
References: <CA+0TdyqipgBeMAscVKGeMvTkY1L_Di-3Or3f=LZJcW2y65jjhw@mail.gmail.com>
 <56600E7D.1020203@treenet.co.nz>
 <CA+0TdypzvZ3RGvG_v3=eWKe7FFM26c1B4VQp3sZZShJuxrsosA@mail.gmail.com>
 <566277D7.6010308@treenet.co.nz>
 <CA+0TdyowP_g8N9BRe8cprfQrHwzkKyV+4bKDYSH2r5esOcyhNA@mail.gmail.com>
 <5664C9B5.5050308@treenet.co.nz>
 <CA+0TdyrOjjo+wb7HHkWNPwyJEpZsLmCimuGWi2Nc=SXwSVxYQA@mail.gmail.com>
Message-ID: <5664E00B.9010805@treenet.co.nz>

Can you please reply to the mailing list.

On 7/12/2015 1:56 p.m., Marcio Demetrio Bacci wrote:
> Hi Amos,
> 
> What is the best way to authenticate Squid3 in the Samba 4?
> 

That kind of depends on your network environment and definition of "best".

Kerberos is most secure and Negotiate/Kerberos solves a fair chunk of
the NTLM problems. So it is usually the Best Current Practice, but...

It can be a learning curve to get it going, and can add problems if
there are software on the network that insists on using the
Negotiate/NTLM auth variant. So sometimes it turns out other forms of
Proxy-Auth is best.

Amos



From Walter.H at mathemainzel.info  Mon Dec  7 04:41:24 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Mon, 07 Dec 2015 05:41:24 +0100
Subject: [squid-users] http request header must use hostname
In-Reply-To: <5664C2FD.1090907@treenet.co.nz>
References: <5663A13B.3030306@fosiao.com> <566408F4.3080902@gmail.com>
 <566480A6.5070809@mathemainzel.info> <5664C2FD.1090907@treenet.co.nz>
Message-ID: <56650DF4.6070704@mathemainzel.info>

On 07.12.2015 00:21, Amos Jeffries wrote:
> Getting complicated...
>
> So xxiao8, why does one want to censor these requests anyway?
>
> Amos
try to connect natively with the IP-Address instead of the hostname ...
the SSL certificate of the host itself prevents the connection without 
message in the user agent ...

TLS code: SQUID_X509_V_ERR_DOMAIN_MISMATCH

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151207/cc778251/attachment.bin>

From squid3 at treenet.co.nz  Mon Dec  7 07:49:22 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 7 Dec 2015 20:49:22 +1300
Subject: [squid-users] http request header must use hostname
In-Reply-To: <56650DF4.6070704@mathemainzel.info>
References: <5663A13B.3030306@fosiao.com> <566408F4.3080902@gmail.com>
 <566480A6.5070809@mathemainzel.info> <5664C2FD.1090907@treenet.co.nz>
 <56650DF4.6070704@mathemainzel.info>
Message-ID: <56653A02.7040902@treenet.co.nz>

On 7/12/2015 5:41 p.m., Walter H. wrote:
> On 07.12.2015 00:21, Amos Jeffries wrote:
>> Getting complicated...
>>
>> So xxiao8, why does one want to censor these requests anyway?
>>
>> Amos
> try to connect natively with the IP-Address instead of the hostname ...
> the SSL certificate of the host itself prevents the connection without
> message in the user agent ...
> 
> TLS code: SQUID_X509_V_ERR_DOMAIN_MISMATCH

xxiao was asking about http:// plain-text scope. TLS bugs in client UA
(sending SNI with raw-IP values) are irrelevant there.

Amos



From Ralf.Hildebrandt at charite.de  Mon Dec  7 11:37:47 2015
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Mon, 7 Dec 2015 12:37:47 +0100
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <5661BC23.7040109@measurement-factory.com>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz>
 <5661BC23.7040109@measurement-factory.com>
Message-ID: <20151207113746.GK12890@charite.de>

* Alex Rousskov <rousskov at measurement-factory.com>:

> Please consider adding this fine example to the SslPeekAndSplice wiki
> page at http://wiki.squid-cache.org/Features/SslPeekAndSplice
> 
> 
> Please note that if you do not want to bump anything, then the following
> should also work (bugs notwithstanding):
> 
>     ssl_bump splice whitelist
>     ssl_bump peek all
>     ssl_bump terminate blacklist
>     ssl_bump splice all

That doesn't seem to work for me (squid 3.5.2) - at the very bottom of
my config I have:

*** snip ***
acl whitelist ssl::server_name_regex -i "/etc/squid3/DENY_SSL_BUMP"
acl blacklist server_cert_fingerprint "/etc/squid3/SSL_BLACKLIST"

ssl_bump splice whitelist
ssl_bump peek all
ssl_bump terminate blacklist
ssl_bump splice all
*** snap ***

I put "9ec8153f27c9b5bab91749c80ad7df21d38c8050" into
/etc/squid3/SSL_BLACKLIST -- which is the SHA-1 Fingerprint of
https://www.arschkrebs.de/

Yet I still can connect. What am I doing wrong?

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From fabietto82 at gmail.com  Mon Dec  7 13:57:54 2015
From: fabietto82 at gmail.com (Fabio Bucci)
Date: Mon, 7 Dec 2015 14:57:54 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <5662828F.5090007@treenet.co.nz>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
Message-ID: <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>

Thanks Amos.
So, what do you suggest? Implement kerberos authetication instead NTLM one?

I have to check if netscaler is able to perform that kind hack you wrote
before.

Thanks again,
Fabio

2015-12-05 7:22 GMT+01:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 5/12/2015 5:39 a.m., Fabio Bucci wrote:
> > Thanks Amos.
> > Actually my load balancing is configured to perform round robin balancing
> > between the two nodes. I added a session persistance by source ip in
> order
> > to avoid to login again with some sites.
> >
> > my squid.conf is very simple:
> > auth_param ntlm program /usr/bin/ntlm_auth
> > --helper-protocol=squid-2.5-ntlmssp
> > auth_param ntlm children 100
> > auth_param ntlm keep_alive off
> >
> > acl auth proxy_auth REQUIRED
> >
> > http_access allow auth
> >
>
> Okay. That *should* work. With some NTLM-specific caveats.
>
>
> > forwarded_for on
> > follow_x_forwarded_for allow netscaler
> >
>
> If the LB is touching the traffic enough to add headers then it is a
> proxy. NTLM does not work at all well through proxies. NTLM as a whole
> is based on the assumption that there is one (and only one) TCP
> connection between it and the proxy - the credentials are tied to the
> TCP connection state.
>
> There is one VERY slim hack that lets NTLM pass straight through a
> frontend proxy/LB. That is by pinning the LB's inbound and outbound TCP
> connections together. This is not just session persistence, but absolute
> prohibition on any other traffic (even from other connections by the
> same client) being sent to that outbound LB->proxy connection. Some LB
> can do it, some can't.
>
>
> I recommend advertising both/all proxy IPs to the clients and letting
> each select the one(s) it wants to contact. That way the client can
> perform NTLM directly to the Squid.
>
>
> On the other hand NTLM was deprecated back in 2006, you should try
> migrating to Negotiate/Kerberos. Kerberos is a bit of a learning curve
> and can be tricky working with older client software. But is *way* more
> efficient and friendlier to HTTP (but still not fully).
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151207/ff994722/attachment.htm>

From rousskov at measurement-factory.com  Mon Dec  7 15:02:59 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 7 Dec 2015 08:02:59 -0700
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <20151207113746.GK12890@charite.de>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz> <5661BC23.7040109@measurement-factory.com>
 <20151207113746.GK12890@charite.de>
Message-ID: <56659FA3.9000404@measurement-factory.com>

On 12/07/2015 04:37 AM, Ralf Hildebrandt wrote:
> * Alex Rousskov <rousskov at measurement-factory.com>:
>> Please note that if you do not want to bump anything, then the following
>> should also work (bugs notwithstanding):
>>
>>     ssl_bump splice whitelist
>>     ssl_bump peek all
>>     ssl_bump terminate blacklist
>>     ssl_bump splice all
> 
> That doesn't seem to work for me (squid 3.5.2)

> Yet I still can connect. What am I doing wrong?

If you are indeed using v3.5.2, then that is a big red flag.

If you are using the latest v3.5 release, then you should open a bug
report, preferably with an ALL,9 log depicting a single failing
transaction. AFAICT, the above is meant to work. If it does not, there
is either a Squid bug or misconfiguration [that I cannot detect by
reading email].


Thank you,

Alex.



From marciobacci at gmail.com  Mon Dec  7 18:47:57 2015
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Mon, 7 Dec 2015 16:47:57 -0200
Subject: [squid-users] Problems with ldap authentication
Message-ID: <CA+0TdyrzqjD+nytOapbmNNcqox8__YGaTH31E8HJfg=2PLJuqg@mail.gmail.com>

My LDAP Authentication do not work in Squid. I have already saw many
tutorials, but nothing solve this problem.
I have installed Squid 3.4 on Debian 8. My DC is a* Samba 4.2.*
In /var/log/squid3/cache.log appear the message:
*squid_ldap_auth: WARNING, could not bind to binddn 'Invalid credentials'*

Follows my squid.conf


http_port 3128
cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90
maximum_object_size 512 MB
minimum_object_size 0 KB
maximum_object_size_in_memory 4096 KB
cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA
quick_abort_min -1 KB
detect_broken_pconn on
fqdncache_size 1024
refresh_pattern ^ftp:    1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%     0
refresh_pattern .        0    20%    4320
access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log
cache_dir aufs /var/spool/squid3 600 16 256

auth_param basic program /usr/lib/squid3/squid_ldap_auth -R -b
?dc=empresa,dc=com,dc=br? -D ?cn=Administrator,dc=empresa,dc=com,dc=br? -w
"1234" -f sAMAccountName=%s -h 192.168.0.25
auth_param basic children 50
auth_param basic realm Web-Proxy
auth_param basic credentialsttl 1 minute

visible_hostname proxy.empresa.com.br
acl localhost src 192.168.0.54/32
acl SSL_ports port 22 443 563
acl Safe_ports port 80 8080
acl Safe_ports port 21
acl Safe_ports port 443 563
acl Safe_ports port 70
acl Safe_ports port 210
acl Safe_ports port 280
acl Safe_ports port 488
acl Safe_ports port 591
acl Safe_ports port 777
acl Safe_ports port 1025-65535
acl purge method PURGE
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow manager localhost
http_access deny manager
http_access allow purge localhost
http_access deny purge
acl users proxy_auth REQUIRED
http_access allow users
acl lan src 192.168.0.0/22
http_access allow lan
http_access deny all
error_directory /usr/share/squid3/errors/en
coredump_dir /var/spool/squid3

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151207/1bf96a6e/attachment.htm>

From tomtux007 at gmail.com  Mon Dec  7 21:05:05 2015
From: tomtux007 at gmail.com (Tom Tom)
Date: Mon, 7 Dec 2015 22:05:05 +0100
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <56659FA3.9000404@measurement-factory.com>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz>
 <5661BC23.7040109@measurement-factory.com>
 <20151207113746.GK12890@charite.de>
 <56659FA3.9000404@measurement-factory.com>
Message-ID: <CACLJR+PNpWzh=uU-qBNsbk7xVsvcq1Ve9cpb_tu1gUsFGH1qZA@mail.gmail.com>

The configuration provided by Alex works for me (squid 3.5.11) if:
* the http_port-directive is configured with ssl-bump and a
certificate (ex. http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/certs/myCA.pem)
* the SHA1-fingerprint in the file SSL_BLACKLISTS is delimited after
two characters with a colon
(9E:C8:15:3F:27:C9:B5:BA:B9:17:49:C8:0A:D7:DF:21:D3:8C:80:50 for
ar***krebs.de)

Kind regards,
Tom

On Mon, Dec 7, 2015 at 4:02 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 12/07/2015 04:37 AM, Ralf Hildebrandt wrote:
>> * Alex Rousskov <rousskov at measurement-factory.com>:
>>> Please note that if you do not want to bump anything, then the following
>>> should also work (bugs notwithstanding):
>>>
>>>     ssl_bump splice whitelist
>>>     ssl_bump peek all
>>>     ssl_bump terminate blacklist
>>>     ssl_bump splice all
>>
>> That doesn't seem to work for me (squid 3.5.2)
>
>> Yet I still can connect. What am I doing wrong?
>
> If you are indeed using v3.5.2, then that is a big red flag.
>
> If you are using the latest v3.5 release, then you should open a bug
> report, preferably with an ALL,9 log depicting a single failing
> transaction. AFAICT, the above is meant to work. If it does not, there
> is either a Squid bug or misconfiguration [that I cannot detect by
> reading email].
>
>
> Thank you,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Mon Dec  7 21:30:01 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 7 Dec 2015 14:30:01 -0700
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <CACLJR+PNpWzh=uU-qBNsbk7xVsvcq1Ve9cpb_tu1gUsFGH1qZA@mail.gmail.com>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz> <5661BC23.7040109@measurement-factory.com>
 <20151207113746.GK12890@charite.de>
 <56659FA3.9000404@measurement-factory.com>
 <CACLJR+PNpWzh=uU-qBNsbk7xVsvcq1Ve9cpb_tu1gUsFGH1qZA@mail.gmail.com>
Message-ID: <5665FA59.5010506@measurement-factory.com>

On 12/07/2015 02:05 PM, Tom Tom wrote:
> The configuration provided by Alex works for me (squid 3.5.11) 

Thank you for testing and helping expose problems.


> if:
> * the http_port-directive is configured with ssl-bump and a
> certificate (ex. http_port 3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/usr/local/certs/myCA.pem)

ssl-bump is required to access SSL/TLS peeking code. Now way around that
today although future Squid versions may provide something like an
ssl-peek port option that tells Squid that no bumping, for any reason
(including error serving) is permitted on that port.

Specifying root CA is required to serve certificate validation (and
other) errors, but we probably should be more flexible and allow no-CA
splice-or-terminate configurations as well.

Related enhancement requests in bugzilla are welcomed, especially if
they are followed by quality patches.


> * the SHA1-fingerprint in the file SSL_BLACKLISTS is delimited after
> two characters with a colon
> (9E:C8:15:3F:27:C9:B5:BA:B9:17:49:C8:0A:D7:DF:21:D3:8C:80:50 for
> ar***krebs.de)

If Squid silently misinterprets colon-less fingerprints, it is a bug
that should be reported and fixed. Squid should either interpret them
correctly or exit with a configuration error.


Thank you,

Alex.



> On Mon, Dec 7, 2015 at 4:02 PM, Alex Rousskov
> <rousskov at measurement-factory.com> wrote:
>> On 12/07/2015 04:37 AM, Ralf Hildebrandt wrote:
>>> * Alex Rousskov <rousskov at measurement-factory.com>:
>>>> Please note that if you do not want to bump anything, then the following
>>>> should also work (bugs notwithstanding):
>>>>
>>>>     ssl_bump splice whitelist
>>>>     ssl_bump peek all
>>>>     ssl_bump terminate blacklist
>>>>     ssl_bump splice all
>>>
>>> That doesn't seem to work for me (squid 3.5.2)
>>
>>> Yet I still can connect. What am I doing wrong?
>>
>> If you are indeed using v3.5.2, then that is a big red flag.
>>
>> If you are using the latest v3.5 release, then you should open a bug
>> report, preferably with an ALL,9 log depicting a single failing
>> transaction. AFAICT, the above is meant to work. If it does not, there
>> is either a Squid bug or misconfiguration [that I cannot detect by
>> reading email].
>>
>>
>> Thank you,
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From Walter.H at mathemainzel.info  Mon Dec  7 22:04:25 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Mon, 07 Dec 2015 23:04:25 +0100
Subject: [squid-users] http request header must use hostname
In-Reply-To: <56653A02.7040902@treenet.co.nz>
References: <5663A13B.3030306@fosiao.com> <566408F4.3080902@gmail.com>
 <566480A6.5070809@mathemainzel.info> <5664C2FD.1090907@treenet.co.nz>
 <56650DF4.6070704@mathemainzel.info> <56653A02.7040902@treenet.co.nz>
Message-ID: <56660269.1070300@mathemainzel.info>

On 07.12.2015 08:49, Amos Jeffries wrote:
> On 7/12/2015 5:41 p.m., Walter H. wrote:
>> On 07.12.2015 00:21, Amos Jeffries wrote:
>>> Getting complicated...
>>>
>>> So xxiao8, why does one want to censor these requests anyway?
>>>
>>> Amos
>> try to connect natively with the IP-Address instead of the hostname ...
>> the SSL certificate of the host itself prevents the connection without
>> message in the user agent ...
>>
>> TLS code: SQUID_X509_V_ERR_DOMAIN_MISMATCH
> xxiao was asking about http:// plain-text scope. TLS bugs in client UA
> (sending SNI with raw-IP values) are irrelevant there.
>
> Amos
then this

"http_access deny CONNECT numeric_IPs"

is wrong, because CONNECT and has nothing to do with http://, isn't it?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151207/c3a4f045/attachment.bin>

From squid3 at treenet.co.nz  Tue Dec  8 00:10:58 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 8 Dec 2015 13:10:58 +1300
Subject: [squid-users] Problems with ldap authentication
In-Reply-To: <CA+0TdyrzqjD+nytOapbmNNcqox8__YGaTH31E8HJfg=2PLJuqg@mail.gmail.com>
References: <CA+0TdyrzqjD+nytOapbmNNcqox8__YGaTH31E8HJfg=2PLJuqg@mail.gmail.com>
Message-ID: <56662012.6080203@treenet.co.nz>

On 8/12/2015 7:47 a.m., Marcio Demetrio Bacci wrote:
> My LDAP Authentication do not work in Squid. I have already saw many
> tutorials, but nothing solve this problem.
> I have installed Squid 3.4 on Debian 8. My DC is a* Samba 4.2.*
> In /var/log/squid3/cache.log appear the message:
> *squid_ldap_auth: WARNING, could not bind to binddn 'Invalid credentials'*
> 

That is your Squid helper being unable to access the LDAP server at
192.168.0.25. The credentials you have configured it to use to access
the LDAP (-D -w) are not working.


Also, squid_ldap_auth is not part of the Squid-3.4 package on Debian.
That might be part of the problem. Squid-3.4 provides basic_ldap_auth.

Amos



From marciobacci at gmail.com  Tue Dec  8 03:00:01 2015
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Tue, 8 Dec 2015 01:00:01 -0200
Subject: [squid-users] Problems with ldap authentication
In-Reply-To: <56662012.6080203@treenet.co.nz>
References: <CA+0TdyrzqjD+nytOapbmNNcqox8__YGaTH31E8HJfg=2PLJuqg@mail.gmail.com>
 <56662012.6080203@treenet.co.nz>
Message-ID: <CA+0TdypAnD-E8aRqoThKqaJuYmjv03_5PLbdnr3fYqNjZApXiA@mail.gmail.com>

I have changed my authentication block as below, but is not working.

The proxy user is a Read Only Domain Controller member. The password is
correct.

Samba4, krb5-user and winbindd are installed and work perfectly. Do I need
install any other package?

How can I test in command line?

Have anything wrong in my authentication block ?

auth_param basic program /usr/lib/squid3/basic_ldap_auth -b
cn=users,dc=empresa,dc=com,dc=br -D
cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 -h 192.168.0.25 -p
389 -s sub -v 3 -f "sAMAccountName=%s"
auth_param basic children 50
auth_param basic realm Proxy Server Squid
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off

With the command "ldbsearch -H /opt/samba/private/sam.ldb
'(objectclass=user)' uidNumber gidNumber ", my result is:
# record 881
dn: CN=proxy,CN=Users,DC=empresa,DC=com,DC=br
uidNumber: 10558
gidNumber: 30037

Regards,

M?rcio


2015-12-07 22:10 GMT-02:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 8/12/2015 7:47 a.m., Marcio Demetrio Bacci wrote:
> > My LDAP Authentication do not work in Squid. I have already saw many
> > tutorials, but nothing solve this problem.
> > I have installed Squid 3.4 on Debian 8. My DC is a* Samba 4.2.*
> > In /var/log/squid3/cache.log appear the message:
> > *squid_ldap_auth: WARNING, could not bind to binddn 'Invalid
> credentials'*
> >
>
> That is your Squid helper being unable to access the LDAP server at
> 192.168.0.25. The credentials you have configured it to use to access
> the LDAP (-D -w) are not working.
>
>
> Also, squid_ldap_auth is not part of the Squid-3.4 package on Debian.
> That might be part of the problem. Squid-3.4 provides basic_ldap_auth.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151208/c4691657/attachment.htm>

From alex at samad.com.au  Tue Dec  8 06:35:45 2015
From: alex at samad.com.au (Alex Samad)
Date: Tue, 8 Dec 2015 17:35:45 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
Message-ID: <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>

Hi

Any suggestions on how to debug this... I wouldn't mind rolling
forward to 3.5 again

On 2 December 2015 at 20:39, Alex Samad <alex at samad.com.au> wrote:
> Just to add to this I have a lot of these in the log file
>
> TCP_MISS_ABORTED/000 0 RPC_IN_DATA
> TCP_MISS_ABORTED/200 4322 RPC_OUT_DATA
> TCP_MISS_ABORTED/000 0 RPC_IN_DATA https:
>
>
>
>
>
>
> On 2 December 2015 at 17:24, Alex Samad <alex at samad.com.au> wrote:
>> Hi
>>
>> recently upgraded to squid-3.5.11-1.el6.x86_64 from the centos 6.7  squid 3.1
>>
>>
>> I am now having problems with people who use active sync via this
>> connection . seems like emails with attachments aren't making it
>> through .
>>
>> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
>> originserver login=PASS front-end-https=on ssl
>> sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.yx.com.crt
>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=exchangeServer
>>
>>
>> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
>> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
>> sslcert=/etc/httpd/conf.d/office.yx.com.crt
>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=webServer
>> c
>>
>> # List of acceptable URLs to send to the Exchange server
>> acl exch_url url_regex -i office.yieldbroker.com/exchange
>> acl exch_url url_regex -i office.yieldbroker.com/exchweb
>> acl exch_url url_regex -i office.yieldbroker.com/public
>> acl exch_url url_regex -i office.yieldbroker.com/owa
>> acl exch_url url_regex -i office.yieldbroker.com/ecp
>> acl exch_url url_regex -i office.yieldbroker.com/microsoft-server-activesync
>> acl exch_url url_regex -i office.yieldbroker.com/rpc
>> acl exch_url url_regex -i office.yieldbroker.com/rpcwithcert
>> acl exch_url url_regex -i office.yieldbroker.com/exadmin
>> acl exch_url url_regex -i office.yieldbroker.com/oab
>> # added after
>> acl exch_url url_regex -i office.yieldbroker.com/ews
>> # Not configured on exchange 2010
>> #acl exch_url url_regex -i office.yieldbroker.com/autodiscover
>>
>> # Send the Exchange URLs to the Exchange server
>> cache_peer_access exchangeServer allow exch_url
>>
>> # Send everything else to the Apache
>> cache_peer_access webServer deny exch_url
>>
>> # This is to protect Squid
>> never_direct allow exch_url
>>
>> # Logging Configuration
>> redirect_rewrites_host_header off
>> cache_mem 32 MB
>> maximum_object_size_in_memory 128 KB
>> cache_log none
>> cache_store_log none
>>
>> access_log stdio:/var/log/squid/office-access.log squid
>> #access_log none
>> cache_log /var/log/squid/office-cache.log
>> #cache_log none
>> pid_filename /var/run/squid-office.pid
>>
>>
>> # Set the hostname so that we can see Squid in the path (Optional)
>> visible_hostname yieldbroker.com
>> deny_info TCP_RESET all
>>
>> # ACL - required to allow
>> #acl all src ALL
>>
>> # Allow everyone through, internal and external connections
>> http_access allow all
>> miss_access allow all
>>
>> icp_port 0
>> snmp_port 0
>>
>> via off
>>
>>
>> The previous setup had worked for at least 18 months.
>>
>> Alex


From alex at samad.com.au  Tue Dec  8 06:44:43 2015
From: alex at samad.com.au (Alex Samad)
Date: Tue, 8 Dec 2015 17:44:43 +1100
Subject: [squid-users] squid auth
Message-ID: <CAJ+Q1PWh1SL8VzvLy9Vj+CNNaXthY-g+rezMJG2KJ0wMNVeQfA@mail.gmail.com>

Hi

Currently using 3.1 (from centos 6)
I have setup squid to auth against MS AD

I have
# #######
# Negotiate
# #######

# http://wiki.squid-cache.org/Features/Authentication
# http://wiki.squid-cache.org/Features/NegotiateAuthentication
auth_param negotiate program /usr/bin/ntlm_auth
--helper-protocol=gss-spnego --configfile /etc/samba/smb.conf-squid
auth_param negotiate children 10 startup=0 idle=3
auth_param negotiate keep_alive on

# #######
# NTLM AUTH
# #######

# ntlm auth
auth_param ntlm program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp --configfile
/etc/samba/smb.conf-squid
auth_param ntlm children 10
#auth_param ntlm children 10 startup=0 idle=3
#auth_param ntlm keep_alive


# #######
# NTLM over basic
# #######

# warning: basic authentication sends passwords plaintext
# a network sniffer can and will discover passwords
auth_param basic program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-basic --configfile
/etc/samba/smb.conf-squid
auth_param basic children 5
auth_param basic realm Squid proxy-caching web server
auth_param basic credentialsttl 2 hours


I want to move towards using kerberos come to this page
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos

worked through that, but i saw this

Do not use this method if you run winbindd or other samba services as
samba will reset the machine password every x days and thereby makes
the keytab invalid !!

I have winbindd running for my users list in linux

is there a way around this and if not how

then found this one
http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory

but I am not using msktutil, i do have samba and the krb-workstation installed

Now I'm a bit lost..


From squid3 at treenet.co.nz  Tue Dec  8 08:23:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 8 Dec 2015 21:23:38 +1300
Subject: [squid-users] Problems with ldap authentication
In-Reply-To: <CA+0TdypAnD-E8aRqoThKqaJuYmjv03_5PLbdnr3fYqNjZApXiA@mail.gmail.com>
References: <CA+0TdyrzqjD+nytOapbmNNcqox8__YGaTH31E8HJfg=2PLJuqg@mail.gmail.com>
 <56662012.6080203@treenet.co.nz>
 <CA+0TdypAnD-E8aRqoThKqaJuYmjv03_5PLbdnr3fYqNjZApXiA@mail.gmail.com>
Message-ID: <5666938A.8080202@treenet.co.nz>

On 8/12/2015 4:00 p.m., Marcio Demetrio Bacci wrote:
> I have changed my authentication block as below, but is not working.
> 
> The proxy user is a Read Only Domain Controller member. The password is
> correct.
> 
> Samba4, krb5-user and winbindd are installed and work perfectly. Do I need
> install any other package?

What authentication system do you think you are using? Basic or
Kerberos? because you configured Basic.

> 
> How can I test in command line?
> 

Everthign in squid.conf after the "auth_param basic program " is the
command line for the helper.
* Run that command line:
  /usr/lib/squid3/basic_ldap_auth \
   -b cn=users,dc=empresa,dc=com,dc=br \
   -D cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 \
   -h 192.168.0.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"

* If nothing happens and it just waits for input, it has started properly.

* Enter two words on each line, username and password for a user account
which might be using Squid. Try both valid and invalid combos.

* The helper will reply OK (valid) or ERR (invalid) if it has been a
successful check. BH if there was a failure.


> Have anything wrong in my authentication block ?
> 
> auth_param basic program /usr/lib/squid3/basic_ldap_auth -b
> cn=users,dc=empresa,dc=com,dc=br -D
> cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 -h 192.168.0.25 -p
> 389 -s sub -v 3 -f "sAMAccountName=%s"
> auth_param basic children 50
> auth_param basic realm Proxy Server Squid
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off


Nothing particularly visible to me. But that said I'm not a regular user
of LDAP, so there could be something subtle hiding in the LDAP query
strings or ither parameters that deos not match what your LDAP service
needs.


> 
> With the command "ldbsearch -H /opt/samba/private/sam.ldb
> '(objectclass=user)' uidNumber gidNumber ", my result is:
> # record 881
> dn: CN=proxy,CN=Users,DC=empresa,DC=com,DC=br
> uidNumber: 10558
> gidNumber: 30037
> 

The U on Users is upper case in this test. It is lower case in your
config file.

The DC/dc CN/cn values are also different case. That might matter to
your LDAP system.

If either of those turn out to be the problem, then you will need to fix
the -b parameter as well.


Amos


From squid3 at treenet.co.nz  Tue Dec  8 08:34:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 8 Dec 2015 21:34:10 +1300
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
Message-ID: <56669602.9020407@treenet.co.nz>

On 8/12/2015 7:35 p.m., Alex Samad wrote:
> Hi
> 
> Any suggestions on how to debug this... I wouldn't mind rolling
> forward to 3.5 again
> 

Some ideas inline. The main ones are:

* re-enable cache.log. It is not optional.

* try an upgrade to 3.5.12. There were some regressions in the .10/.11
releases that can lead to really weird behaviour.


> On 2 December 2015 at 20:39, Alex Samad wrote:
>> Just to add to this I have a lot of these in the log file
>>
>> TCP_MISS_ABORTED/000 0 RPC_IN_DATA
>> TCP_MISS_ABORTED/200 4322 RPC_OUT_DATA
>> TCP_MISS_ABORTED/000 0 RPC_IN_DATA https:
>>
>>
>>
>> On 2 December 2015 at 17:24, Alex Samad wrote:
>>> Hi
>>>
>>> recently upgraded to squid-3.5.11-1.el6.x86_64 from the centos 6.7  squid 3.1
>>>
>>>
>>> I am now having problems with people who use active sync via this
>>> connection . seems like emails with attachments aren't making it
>>> through .
>>>
>>> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
>>> originserver login=PASS front-end-https=on ssl
>>> sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.yx.com.crt
>>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=exchangeServer

You could try changing these from login=PASS to login=PASSTHRU

>>>
>>>
>>> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
>>> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
>>> sslcert=/etc/httpd/conf.d/office.yx.com.crt
>>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=webServer
>>> c
>>>
>>> # List of acceptable URLs to send to the Exchange server
>>> acl exch_url url_regex -i office.yieldbroker.com/exchange
>>> acl exch_url url_regex -i office.yieldbroker.com/exchweb
>>> acl exch_url url_regex -i office.yieldbroker.com/public
>>> acl exch_url url_regex -i office.yieldbroker.com/owa
>>> acl exch_url url_regex -i office.yieldbroker.com/ecp
>>> acl exch_url url_regex -i office.yieldbroker.com/microsoft-server-activesync
>>> acl exch_url url_regex -i office.yieldbroker.com/rpc
>>> acl exch_url url_regex -i office.yieldbroker.com/rpcwithcert
>>> acl exch_url url_regex -i office.yieldbroker.com/exadmin
>>> acl exch_url url_regex -i office.yieldbroker.com/oab
>>> # added after
>>> acl exch_url url_regex -i office.yieldbroker.com/ews
>>> # Not configured on exchange 2010
>>> #acl exch_url url_regex -i office.yieldbroker.com/autodiscover
>>>
>>> # Send the Exchange URLs to the Exchange server
>>> cache_peer_access exchangeServer allow exch_url
>>>
>>> # Send everything else to the Apache
>>> cache_peer_access webServer deny exch_url
>>>
>>> # This is to protect Squid
>>> never_direct allow exch_url
>>>
>>> # Logging Configuration
>>> redirect_rewrites_host_header off
>>> cache_mem 32 MB
>>> maximum_object_size_in_memory 128 KB
>>> cache_log none

You should re-enable cache.log and fix any of the issues that are logged
there.


>>> cache_store_log none
>>>
>>> access_log stdio:/var/log/squid/office-access.log squid
>>> #access_log none
>>> cache_log /var/log/squid/office-cache.log
>>> #cache_log none
>>> pid_filename /var/run/squid-office.pid
>>>
>>>
>>> # Set the hostname so that we can see Squid in the path (Optional)
>>> visible_hostname yieldbroker.com
>>> deny_info TCP_RESET all

This could lead to strange behaviour. Particularly since "deny all" is
not being used in your http_access rules ...


>>>
>>> # Allow everyone through, internal and external connections
>>> http_access allow all
>>> miss_access allow all
>>>
>>> icp_port 0
>>> snmp_port 0
>>>
>>> via off
>>>
>>>
>>> The previous setup had worked for at least 18 months.
>>>
>>> Alex
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From squid3 at treenet.co.nz  Tue Dec  8 09:03:12 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 8 Dec 2015 22:03:12 +1300
Subject: [squid-users] squid auth
In-Reply-To: <CAJ+Q1PWh1SL8VzvLy9Vj+CNNaXthY-g+rezMJG2KJ0wMNVeQfA@mail.gmail.com>
References: <CAJ+Q1PWh1SL8VzvLy9Vj+CNNaXthY-g+rezMJG2KJ0wMNVeQfA@mail.gmail.com>
Message-ID: <56669CD0.4070805@treenet.co.nz>

On 8/12/2015 7:44 p.m., Alex Samad wrote:
> Hi
> 
> Currently using 3.1 (from centos 6)
> I have setup squid to auth against MS AD
> 
> I have
> # #######
> # Negotiate
> # #######
> 
> # http://wiki.squid-cache.org/Features/Authentication
> # http://wiki.squid-cache.org/Features/NegotiateAuthentication
> auth_param negotiate program /usr/bin/ntlm_auth
> --helper-protocol=gss-spnego --configfile /etc/samba/smb.conf-squid
> auth_param negotiate children 10 startup=0 idle=3
> auth_param negotiate keep_alive on
> 
> # #######
> # NTLM AUTH
> # #######
> 
> # ntlm auth
> auth_param ntlm program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp --configfile
> /etc/samba/smb.conf-squid
> auth_param ntlm children 10
> #auth_param ntlm children 10 startup=0 idle=3
> #auth_param ntlm keep_alive
> 
> 
> # #######
> # NTLM over basic
> # #######
> 
> # warning: basic authentication sends passwords plaintext
> # a network sniffer can and will discover passwords
> auth_param basic program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-basic --configfile
> /etc/samba/smb.conf-squid
> auth_param basic children 5
> auth_param basic realm Squid proxy-caching web server
> auth_param basic credentialsttl 2 hours
> 
> 
> I want to move towards using kerberos come to this page
> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
> 
> worked through that, but i saw this
> 
> Do not use this method if you run winbindd or other samba services as
> samba will reset the machine password every x days and thereby makes
> the keytab invalid !!


As I understand it that disclaimer applies only to the "OR with Samba"
instructions for keytab creation directly above it. The other two
methods should work.

Also, it is just a disclaimer about a known problem. There is always the
option to setup a script that re-builds the keytab and reloads Squid
every X days when it changes.

> 
> I have winbindd running for my users list in linux
> 
> is there a way around this and if not how
> 

The initial mskutil method of keytab creation is both a way around it
and the preferred method of keytab creation.

As you found elsewhere ...

> then found this one
> http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory
> 
> but I am not using msktutil, i do have samba and the krb-workstation installed
> 

mskutil is just a tool to generate keytabs and link the machine to
domain. I *think* it should still be usable even if you have Sambe, the
probem is just that if you let Samba know about the keytab and account
it will do the periodic updates.

Amos



From marciobacci at gmail.com  Tue Dec  8 17:14:45 2015
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Tue, 8 Dec 2015 15:14:45 -0200
Subject: [squid-users] Problems with ldap authentication
In-Reply-To: <5666938A.8080202@treenet.co.nz>
References: <CA+0TdyrzqjD+nytOapbmNNcqox8__YGaTH31E8HJfg=2PLJuqg@mail.gmail.com>
 <56662012.6080203@treenet.co.nz>
 <CA+0TdypAnD-E8aRqoThKqaJuYmjv03_5PLbdnr3fYqNjZApXiA@mail.gmail.com>
 <5666938A.8080202@treenet.co.nz>
Message-ID: <CA+0TdyoEgtAv5NqgNLXVJjOxYQ381FHVerT1A+L9TbmQbK+ssA@mail.gmail.com>

Hi

In the Squid Server, I want only basic authentication.

The command:

/usr/lib/squid3/basic_ldap_auth \
   -b cn=users,dc=empresa,dc=com,dc=br \
   -D cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 \
   -h 192.168.0.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"

shows "Success" to authenticate only the users in Organization Unity  (OU)
"Users", but in my domain I have many OU that has users as TI, Financial,
Sales..

How I get authenticate the users in others OU?

Thanks,

M?rcio

2015-12-08 6:23 GMT-02:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 8/12/2015 4:00 p.m., Marcio Demetrio Bacci wrote:
> > I have changed my authentication block as below, but is not working.
> >
> > The proxy user is a Read Only Domain Controller member. The password is
> > correct.
> >
> > Samba4, krb5-user and winbindd are installed and work perfectly. Do I
> need
> > install any other package?
>
> What authentication system do you think you are using? Basic or
> Kerberos? because you configured Basic.
>
> >
> > How can I test in command line?
> >
>
> Everthign in squid.conf after the "auth_param basic program " is the
> command line for the helper.
> * Run that command line:
>   /usr/lib/squid3/basic_ldap_auth \
>    -b cn=users,dc=empresa,dc=com,dc=br \
>    -D cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 \
>    -h 192.168.0.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"
>
> * If nothing happens and it just waits for input, it has started properly.
>
> * Enter two words on each line, username and password for a user account
> which might be using Squid. Try both valid and invalid combos.
>
> * The helper will reply OK (valid) or ERR (invalid) if it has been a
> successful check. BH if there was a failure.
>
>
> > Have anything wrong in my authentication block ?
> >
> > auth_param basic program /usr/lib/squid3/basic_ldap_auth -b
> > cn=users,dc=empresa,dc=com,dc=br -D
> > cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 -h 192.168.0.25
> -p
> > 389 -s sub -v 3 -f "sAMAccountName=%s"
> > auth_param basic children 50
> > auth_param basic realm Proxy Server Squid
> > auth_param basic credentialsttl 2 hours
> > auth_param basic casesensitive off
>
>
> Nothing particularly visible to me. But that said I'm not a regular user
> of LDAP, so there could be something subtle hiding in the LDAP query
> strings or ither parameters that deos not match what your LDAP service
> needs.
>
>
> >
> > With the command "ldbsearch -H /opt/samba/private/sam.ldb
> > '(objectclass=user)' uidNumber gidNumber ", my result is:
> > # record 881
> > dn: CN=proxy,CN=Users,DC=empresa,DC=com,DC=br
> > uidNumber: 10558
> > gidNumber: 30037
> >
>
> The U on Users is upper case in this test. It is lower case in your
> config file.
>
> The DC/dc CN/cn values are also different case. That might matter to
> your LDAP system.
>
> If either of those turn out to be the problem, then you will need to fix
> the -b parameter as well.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151208/bf7cb22e/attachment.htm>

From gkinkie at gmail.com  Tue Dec  8 18:16:54 2015
From: gkinkie at gmail.com (Kinkie)
Date: Tue, 8 Dec 2015 19:16:54 +0100
Subject: [squid-users] Problems with ldap authentication
In-Reply-To: <CA+0TdyoEgtAv5NqgNLXVJjOxYQ381FHVerT1A+L9TbmQbK+ssA@mail.gmail.com>
References: <CA+0TdyrzqjD+nytOapbmNNcqox8__YGaTH31E8HJfg=2PLJuqg@mail.gmail.com>
 <56662012.6080203@treenet.co.nz>
 <CA+0TdypAnD-E8aRqoThKqaJuYmjv03_5PLbdnr3fYqNjZApXiA@mail.gmail.com>
 <5666938A.8080202@treenet.co.nz>
 <CA+0TdyoEgtAv5NqgNLXVJjOxYQ381FHVerT1A+L9TbmQbK+ssA@mail.gmail.com>
Message-ID: <CA+Y8hcOWZXwTp9_meANY-G95izwBhEk-eye2YZs3-CHY7JCdOg@mail.gmail.com>

On Tue, Dec 8, 2015 at 6:14 PM, Marcio Demetrio Bacci
<marciobacci at gmail.com> wrote:
> Hi
>
> In the Squid Server, I want only basic authentication.
>
> The command:
>
> /usr/lib/squid3/basic_ldap_auth \
>    -b cn=users,dc=empresa,dc=com,dc=br \
>    -D cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 \
>    -h 192.168.0.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"
>
> shows "Success" to authenticate only the users in Organization Unity  (OU)
> "Users", but in my domain I have many OU that has users as TI, Financial,
> Sales..
>
> How I get authenticate the users in others OU?

Since you are using "sub" as search scope, you simply have to move up
one level in the base-DN tree.
Change the parameter
-b cn=users,dc=empresa,dc=com,dc=br
to
-b dc=empresa,dc=com,dc=br

   Francesco Chemolli


From alex at samad.com.au  Tue Dec  8 19:32:53 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 9 Dec 2015 06:32:53 +1100
Subject: [squid-users] squid auth
In-Reply-To: <56669CD0.4070805@treenet.co.nz>
References: <CAJ+Q1PWh1SL8VzvLy9Vj+CNNaXthY-g+rezMJG2KJ0wMNVeQfA@mail.gmail.com>
 <56669CD0.4070805@treenet.co.nz>
Message-ID: <CAJ+Q1PW9Ue4zdT9GCt-4MjW=UjDWyBOPc4AFrcjG=qFNEwMMGA@mail.gmail.com>

Hi

So what your saying is I should install the mskutil and let it manage
the squid krb keytab file.


Could you possible help with the changed to the squid.conf file do I
leave as is and just add kerberos first ?


On 8 December 2015 at 20:03, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 8/12/2015 7:44 p.m., Alex Samad wrote:
>> Hi
>>
>> Currently using 3.1 (from centos 6)
>> I have setup squid to auth against MS AD
>>
>> I have
>> # #######
>> # Negotiate
>> # #######
>>
>> # http://wiki.squid-cache.org/Features/Authentication
>> # http://wiki.squid-cache.org/Features/NegotiateAuthentication
>> auth_param negotiate program /usr/bin/ntlm_auth
>> --helper-protocol=gss-spnego --configfile /etc/samba/smb.conf-squid
>> auth_param negotiate children 10 startup=0 idle=3
>> auth_param negotiate keep_alive on
>>
>> # #######
>> # NTLM AUTH
>> # #######
>>
>> # ntlm auth
>> auth_param ntlm program /usr/bin/ntlm_auth
>> --helper-protocol=squid-2.5-ntlmssp --configfile
>> /etc/samba/smb.conf-squid
>> auth_param ntlm children 10
>> #auth_param ntlm children 10 startup=0 idle=3
>> #auth_param ntlm keep_alive
>>
>>
>> # #######
>> # NTLM over basic
>> # #######
>>
>> # warning: basic authentication sends passwords plaintext
>> # a network sniffer can and will discover passwords
>> auth_param basic program /usr/bin/ntlm_auth
>> --helper-protocol=squid-2.5-basic --configfile
>> /etc/samba/smb.conf-squid
>> auth_param basic children 5
>> auth_param basic realm Squid proxy-caching web server
>> auth_param basic credentialsttl 2 hours
>>
>>
>> I want to move towards using kerberos come to this page
>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
>>
>> worked through that, but i saw this
>>
>> Do not use this method if you run winbindd or other samba services as
>> samba will reset the machine password every x days and thereby makes
>> the keytab invalid !!
>
>
> As I understand it that disclaimer applies only to the "OR with Samba"
> instructions for keytab creation directly above it. The other two
> methods should work.
>
> Also, it is just a disclaimer about a known problem. There is always the
> option to setup a script that re-builds the keytab and reloads Squid
> every X days when it changes.
>
>>
>> I have winbindd running for my users list in linux
>>
>> is there a way around this and if not how
>>
>
> The initial mskutil method of keytab creation is both a way around it
> and the preferred method of keytab creation.
>
> As you found elsewhere ...
>
>> then found this one
>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory
>>
>> but I am not using msktutil, i do have samba and the krb-workstation installed
>>
>
> mskutil is just a tool to generate keytabs and link the machine to
> domain. I *think* it should still be usable even if you have Sambe, the
> probem is just that if you let Samba know about the keytab and account
> it will do the periodic updates.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From huaraz at moeller.plus.com  Tue Dec  8 20:20:51 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Tue, 8 Dec 2015 20:20:51 -0000
Subject: [squid-users] squid auth
In-Reply-To: <CAJ+Q1PW9Ue4zdT9GCt-4MjW=UjDWyBOPc4AFrcjG=qFNEwMMGA@mail.gmail.com>
References: <CAJ+Q1PWh1SL8VzvLy9Vj+CNNaXthY-g+rezMJG2KJ0wMNVeQfA@mail.gmail.com>
 <56669CD0.4070805@treenet.co.nz>
 <CAJ+Q1PW9Ue4zdT9GCt-4MjW=UjDWyBOPc4AFrcjG=qFNEwMMGA@mail.gmail.com>
Message-ID: <n47e38$9b7$1@ger.gmane.org>

Hi,

   The issue appears if you use the same AD account for samba and the 
kerberos keytab creation.  As samba will reset the password of the AD 
account and thereby invalidate the extracted keytab.

Markus


"Alex Samad"  wrote in message 
news:CAJ+Q1PW9Ue4zdT9GCt-4MjW=UjDWyBOPc4AFrcjG=qFNEwMMGA at mail.gmail.com...

Hi

So what your saying is I should install the mskutil and let it manage
the squid krb keytab file.


Could you possible help with the changed to the squid.conf file do I
leave as is and just add kerberos first ?


On 8 December 2015 at 20:03, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 8/12/2015 7:44 p.m., Alex Samad wrote:
>> Hi
>>
>> Currently using 3.1 (from centos 6)
>> I have setup squid to auth against MS AD
>>
>> I have
>> # #######
>> # Negotiate
>> # #######
>>
>> # http://wiki.squid-cache.org/Features/Authentication
>> # http://wiki.squid-cache.org/Features/NegotiateAuthentication
>> auth_param negotiate program /usr/bin/ntlm_auth
>> --helper-protocol=gss-spnego --configfile /etc/samba/smb.conf-squid
>> auth_param negotiate children 10 startup=0 idle=3
>> auth_param negotiate keep_alive on
>>
>> # #######
>> # NTLM AUTH
>> # #######
>>
>> # ntlm auth
>> auth_param ntlm program /usr/bin/ntlm_auth
>> --helper-protocol=squid-2.5-ntlmssp --configfile
>> /etc/samba/smb.conf-squid
>> auth_param ntlm children 10
>> #auth_param ntlm children 10 startup=0 idle=3
>> #auth_param ntlm keep_alive
>>
>>
>> # #######
>> # NTLM over basic
>> # #######
>>
>> # warning: basic authentication sends passwords plaintext
>> # a network sniffer can and will discover passwords
>> auth_param basic program /usr/bin/ntlm_auth
>> --helper-protocol=squid-2.5-basic --configfile
>> /etc/samba/smb.conf-squid
>> auth_param basic children 5
>> auth_param basic realm Squid proxy-caching web server
>> auth_param basic credentialsttl 2 hours
>>
>>
>> I want to move towards using kerberos come to this page
>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
>>
>> worked through that, but i saw this
>>
>> Do not use this method if you run winbindd or other samba services as
>> samba will reset the machine password every x days and thereby makes
>> the keytab invalid !!
>
>
> As I understand it that disclaimer applies only to the "OR with Samba"
> instructions for keytab creation directly above it. The other two
> methods should work.
>
> Also, it is just a disclaimer about a known problem. There is always the
> option to setup a script that re-builds the keytab and reloads Squid
> every X days when it changes.
>
>>
>> I have winbindd running for my users list in linux
>>
>> is there a way around this and if not how
>>
>
> The initial mskutil method of keytab creation is both a way around it
> and the preferred method of keytab creation.
>
> As you found elsewhere ...
>
>> then found this one
>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory
>>
>> but I am not using msktutil, i do have samba and the krb-workstation 
>> installed
>>
>
> mskutil is just a tool to generate keytabs and link the machine to
> domain. I *think* it should still be usable even if you have Sambe, the
> probem is just that if you let Samba know about the keytab and account
> it will do the periodic updates.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From alex at samad.com.au  Tue Dec  8 23:21:25 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 9 Dec 2015 10:21:25 +1100
Subject: [squid-users] squid auth
In-Reply-To: <n47e38$9b7$1@ger.gmane.org>
References: <CAJ+Q1PWh1SL8VzvLy9Vj+CNNaXthY-g+rezMJG2KJ0wMNVeQfA@mail.gmail.com>
 <56669CD0.4070805@treenet.co.nz>
 <CAJ+Q1PW9Ue4zdT9GCt-4MjW=UjDWyBOPc4AFrcjG=qFNEwMMGA@mail.gmail.com>
 <n47e38$9b7$1@ger.gmane.org>
Message-ID: <CAJ+Q1PVw1rrSvMUjzqbp_QNUAVwN=r7rqRg0Lt94hv3V3o9ekA@mail.gmail.com>

so when I do kinit I should use a different account to the samba one.

I'm lost sorry.

when I attach with winbind, I kinit with my personal admin account and
also do a net ads join -U <admin account>.

the password on the <admin account> doesn't / hasn't changed.

are you talking about the computer account password ?

if so, then I setup a different computer account for the squid
kerberos application !


On 9 December 2015 at 07:20, Markus Moeller <huaraz at moeller.plus.com> wrote:
> Hi,
>
>   The issue appears if you use the same AD account for samba and the
> kerberos keytab creation.  As samba will reset the password of the AD
> account and thereby invalidate the extracted keytab.
>
> Markus
>
>
> "Alex Samad"  wrote in message
> news:CAJ+Q1PW9Ue4zdT9GCt-4MjW=UjDWyBOPc4AFrcjG=qFNEwMMGA at mail.gmail.com...
>
>
> Hi
>
> So what your saying is I should install the mskutil and let it manage
> the squid krb keytab file.
>
>
> Could you possible help with the changed to the squid.conf file do I
> leave as is and just add kerberos first ?
>
>
> On 8 December 2015 at 20:03, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>
>> On 8/12/2015 7:44 p.m., Alex Samad wrote:
>>>
>>> Hi
>>>
>>> Currently using 3.1 (from centos 6)
>>> I have setup squid to auth against MS AD
>>>
>>> I have
>>> # #######
>>> # Negotiate
>>> # #######
>>>
>>> # http://wiki.squid-cache.org/Features/Authentication
>>> # http://wiki.squid-cache.org/Features/NegotiateAuthentication
>>> auth_param negotiate program /usr/bin/ntlm_auth
>>> --helper-protocol=gss-spnego --configfile /etc/samba/smb.conf-squid
>>> auth_param negotiate children 10 startup=0 idle=3
>>> auth_param negotiate keep_alive on
>>>
>>> # #######
>>> # NTLM AUTH
>>> # #######
>>>
>>> # ntlm auth
>>> auth_param ntlm program /usr/bin/ntlm_auth
>>> --helper-protocol=squid-2.5-ntlmssp --configfile
>>> /etc/samba/smb.conf-squid
>>> auth_param ntlm children 10
>>> #auth_param ntlm children 10 startup=0 idle=3
>>> #auth_param ntlm keep_alive
>>>
>>>
>>> # #######
>>> # NTLM over basic
>>> # #######
>>>
>>> # warning: basic authentication sends passwords plaintext
>>> # a network sniffer can and will discover passwords
>>> auth_param basic program /usr/bin/ntlm_auth
>>> --helper-protocol=squid-2.5-basic --configfile
>>> /etc/samba/smb.conf-squid
>>> auth_param basic children 5
>>> auth_param basic realm Squid proxy-caching web server
>>> auth_param basic credentialsttl 2 hours
>>>
>>>
>>> I want to move towards using kerberos come to this page
>>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
>>>
>>> worked through that, but i saw this
>>>
>>> Do not use this method if you run winbindd or other samba services as
>>> samba will reset the machine password every x days and thereby makes
>>> the keytab invalid !!
>>
>>
>>
>> As I understand it that disclaimer applies only to the "OR with Samba"
>> instructions for keytab creation directly above it. The other two
>> methods should work.
>>
>> Also, it is just a disclaimer about a known problem. There is always the
>> option to setup a script that re-builds the keytab and reloads Squid
>> every X days when it changes.
>>
>>>
>>> I have winbindd running for my users list in linux
>>>
>>> is there a way around this and if not how
>>>
>>
>> The initial mskutil method of keytab creation is both a way around it
>> and the preferred method of keytab creation.
>>
>> As you found elsewhere ...
>>
>>> then found this one
>>>
>>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory
>>>
>>> but I am not using msktutil, i do have samba and the krb-workstation
>>> installed
>>>
>>
>> mskutil is just a tool to generate keytabs and link the machine to
>> domain. I *think* it should still be usable even if you have Sambe, the
>> probem is just that if you let Samba know about the keytab and account
>> it will do the periodic updates.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From huaraz at moeller.plus.com  Tue Dec  8 23:35:00 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Tue, 8 Dec 2015 23:35:00 -0000
Subject: [squid-users] squid auth
In-Reply-To: <CAJ+Q1PVw1rrSvMUjzqbp_QNUAVwN=r7rqRg0Lt94hv3V3o9ekA@mail.gmail.com>
References: <CAJ+Q1PWh1SL8VzvLy9Vj+CNNaXthY-g+rezMJG2KJ0wMNVeQfA@mail.gmail.com>
 <56669CD0.4070805@treenet.co.nz>
 <CAJ+Q1PW9Ue4zdT9GCt-4MjW=UjDWyBOPc4AFrcjG=qFNEwMMGA@mail.gmail.com>
 <n47e38$9b7$1@ger.gmane.org>
 <CAJ+Q1PVw1rrSvMUjzqbp_QNUAVwN=r7rqRg0Lt94hv3V3o9ekA@mail.gmail.com>
Message-ID: <n47pf9$t7a$1@ger.gmane.org>

Hi Alex,

   Yes I talk about the AD computer account password.

Markus


"Alex Samad"  wrote in message 
news:CAJ+Q1PVw1rrSvMUjzqbp_QNUAVwN=r7rqRg0Lt94hv3V3o9ekA at mail.gmail.com...

so when I do kinit I should use a different account to the samba one.

I'm lost sorry.

when I attach with winbind, I kinit with my personal admin account and
also do a net ads join -U <admin account>.

the password on the <admin account> doesn't / hasn't changed.

are you talking about the computer account password ?

if so, then I setup a different computer account for the squid
kerberos application !


On 9 December 2015 at 07:20, Markus Moeller <huaraz at moeller.plus.com> wrote:
> Hi,
>
>   The issue appears if you use the same AD account for samba and the
> kerberos keytab creation.  As samba will reset the password of the AD
> account and thereby invalidate the extracted keytab.
>
> Markus
>
>
> "Alex Samad"  wrote in message
> news:CAJ+Q1PW9Ue4zdT9GCt-4MjW=UjDWyBOPc4AFrcjG=qFNEwMMGA at mail.gmail.com...
>
>
> Hi
>
> So what your saying is I should install the mskutil and let it manage
> the squid krb keytab file.
>
>
> Could you possible help with the changed to the squid.conf file do I
> leave as is and just add kerberos first ?
>
>
> On 8 December 2015 at 20:03, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>
>> On 8/12/2015 7:44 p.m., Alex Samad wrote:
>>>
>>> Hi
>>>
>>> Currently using 3.1 (from centos 6)
>>> I have setup squid to auth against MS AD
>>>
>>> I have
>>> # #######
>>> # Negotiate
>>> # #######
>>>
>>> # http://wiki.squid-cache.org/Features/Authentication
>>> # http://wiki.squid-cache.org/Features/NegotiateAuthentication
>>> auth_param negotiate program /usr/bin/ntlm_auth
>>> --helper-protocol=gss-spnego --configfile /etc/samba/smb.conf-squid
>>> auth_param negotiate children 10 startup=0 idle=3
>>> auth_param negotiate keep_alive on
>>>
>>> # #######
>>> # NTLM AUTH
>>> # #######
>>>
>>> # ntlm auth
>>> auth_param ntlm program /usr/bin/ntlm_auth
>>> --helper-protocol=squid-2.5-ntlmssp --configfile
>>> /etc/samba/smb.conf-squid
>>> auth_param ntlm children 10
>>> #auth_param ntlm children 10 startup=0 idle=3
>>> #auth_param ntlm keep_alive
>>>
>>>
>>> # #######
>>> # NTLM over basic
>>> # #######
>>>
>>> # warning: basic authentication sends passwords plaintext
>>> # a network sniffer can and will discover passwords
>>> auth_param basic program /usr/bin/ntlm_auth
>>> --helper-protocol=squid-2.5-basic --configfile
>>> /etc/samba/smb.conf-squid
>>> auth_param basic children 5
>>> auth_param basic realm Squid proxy-caching web server
>>> auth_param basic credentialsttl 2 hours
>>>
>>>
>>> I want to move towards using kerberos come to this page
>>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
>>>
>>> worked through that, but i saw this
>>>
>>> Do not use this method if you run winbindd or other samba services as
>>> samba will reset the machine password every x days and thereby makes
>>> the keytab invalid !!
>>
>>
>>
>> As I understand it that disclaimer applies only to the "OR with Samba"
>> instructions for keytab creation directly above it. The other two
>> methods should work.
>>
>> Also, it is just a disclaimer about a known problem. There is always the
>> option to setup a script that re-builds the keytab and reloads Squid
>> every X days when it changes.
>>
>>>
>>> I have winbindd running for my users list in linux
>>>
>>> is there a way around this and if not how
>>>
>>
>> The initial mskutil method of keytab creation is both a way around it
>> and the preferred method of keytab creation.
>>
>> As you found elsewhere ...
>>
>>> then found this one
>>>
>>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory
>>>
>>> but I am not using msktutil, i do have samba and the krb-workstation
>>> installed
>>>
>>
>> mskutil is just a tool to generate keytabs and link the machine to
>> domain. I *think* it should still be usable even if you have Sambe, the
>> probem is just that if you let Samba know about the keytab and account
>> it will do the periodic updates.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From marciobacci at gmail.com  Tue Dec  8 23:57:38 2015
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Tue, 8 Dec 2015 21:57:38 -0200
Subject: [squid-users] Problems with ldap authentication
In-Reply-To: <CA+Y8hcOWZXwTp9_meANY-G95izwBhEk-eye2YZs3-CHY7JCdOg@mail.gmail.com>
References: <CA+0TdyrzqjD+nytOapbmNNcqox8__YGaTH31E8HJfg=2PLJuqg@mail.gmail.com>
 <56662012.6080203@treenet.co.nz>
 <CA+0TdypAnD-E8aRqoThKqaJuYmjv03_5PLbdnr3fYqNjZApXiA@mail.gmail.com>
 <5666938A.8080202@treenet.co.nz>
 <CA+0TdyoEgtAv5NqgNLXVJjOxYQ381FHVerT1A+L9TbmQbK+ssA@mail.gmail.com>
 <CA+Y8hcOWZXwTp9_meANY-G95izwBhEk-eye2YZs3-CHY7JCdOg@mail.gmail.com>
Message-ID: <CA+0TdypDW1-WmLCo-iTevHvZTkJY1uSNZUkLXp+eAz8BktGHjA@mail.gmail.com>

Hi,

I changed the parameter, but I received the following error:

basic_ldap_auth: WARNING, LDAP search error 'Operations error'
ERR Success

The command line used:

/usr/lib/squid3/basic_ldap_auth \
    -b dc=empresa,dc=com,dc=br \
    -D cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 \
    -h 192.168.0.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"

My Samba4 Structure is:

empresa.com.br
    Users
    Computers
    Builtin
    Domain Controllers
    ForeignSecurityPrincipals
    EMPRESA
        IT
            Users
        Sales
            Users
...

2015-12-08 16:16 GMT-02:00 Kinkie <gkinkie at gmail.com>:

> On Tue, Dec 8, 2015 at 6:14 PM, Marcio Demetrio Bacci
> <marciobacci at gmail.com> wrote:
> > Hi
> >
> > In the Squid Server, I want only basic authentication.
> >
> > The command:
> >
> > /usr/lib/squid3/basic_ldap_auth \
> >    -b cn=users,dc=empresa,dc=com,dc=br \
> >    -D cn=proxy,cn=users,dc=empresa,dc=com,dc=br -w test_12345 \
> >    -h 192.168.0.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"
> >
> > shows "Success" to authenticate only the users in Organization Unity
> (OU)
> > "Users", but in my domain I have many OU that has users as TI, Financial,
> > Sales..
> >
> > How I get authenticate the users in others OU?
>
> Since you are using "sub" as search scope, you simply have to move up
> one level in the base-DN tree.
> Change the parameter
> -b cn=users,dc=empresa,dc=com,dc=br
> to
> -b dc=empresa,dc=com,dc=br
>
>    Francesco Chemolli
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151208/533acc60/attachment.htm>

From vze2k3sa at verizon.net  Wed Dec  9 00:50:38 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Tue, 08 Dec 2015 19:50:38 -0500
Subject: [squid-users] Slow Squid
Message-ID: <006501d1321b$9fb01d40$df1057c0$@verizon.net>

Hi,

 

My Squid Server is much slower to go through than direct access to the
internet. I would expect it to be slower but not dramatically slower. Any
tips to speed it up? It's only used to access 8 whitelisted domains. I am
not using the disk based cache as it's only 8 sites total we hit. See my
squid config below and please offer any suggestions.

 

Thank You,

Patrick

 

# Proxy Configuration

 

http_port     3128

 

# acl and http_access to ("whitelist.txt")

acl whitelist dstdomain  "c:/squid/etc/squid/whitelist.txt"

http_access        allow     whitelist

 

# network source of proxy traffic

acl localnet  src        all

 

# debug (Used by Rave Support Only)

#debug_options              ALL,2

 

# acl directives for ports and protocols

acl http      proto      http

acl https     proto      https

acl port_80   port       80

acl sslports  port       443

acl CONNECT   method     CONNECT

 

# localhost proxy access

acl localhost src 127.0.0.1/32

http_access allow localhost

 

# rules allowing proxy access

http_access allow http    port_80  whitelist localnet

http_access allow https   sslports whitelist localnet

 

# dns servers (Change dns_nameservers to client dns servers for consistency
and better performance)

dns_nameservers 172.16.50.1 172.16.50.9

 

# cache web pages directory

#cache_dir ufs C:/Squid/var/cache/squid 100 16 256

cache_mem 64 MB

 

# log file roll weekly

logfile_rotate 7

 

# access log rules

logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt

 

# catch-all rule

http_access deny all

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151208/5c5c0504/attachment.htm>

From michael at hendrie.id.au  Wed Dec  9 00:59:11 2015
From: michael at hendrie.id.au (Michael Hendrie)
Date: Wed, 9 Dec 2015 11:29:11 +1030
Subject: [squid-users] ssl-bump splice on unsupported ciphers
Message-ID: <F683BAA1-082D-4110-931B-2C6890C4E569@hendrie.id.au>

Hi All,

I've read a few articles that indicate squid-3.5 and below doesn't support ssl-bump'ing ECDHE ciphers.

Is this correct? If so, is it possible to create/structure acl and ssl-bump rules to splice on unsupported ciphers?  

I've looked through the available ACL options and doesn't seem to be possible unless I'm missing something.

Thanks,

Michael

From eliezer at ngtech.co.il  Wed Dec  9 01:23:15 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 9 Dec 2015 03:23:15 +0200
Subject: [squid-users] Slow Squid
In-Reply-To: <006501d1321b$9fb01d40$df1057c0$@verizon.net>
References: <006501d1321b$9fb01d40$df1057c0$@verizon.net>
Message-ID: <56678283.60309@ngtech.co.il>

Hey Patrick,

Can you use some paste for the conf?(maybe http://fpaste.org/) it is 
really unclear.
I am almost sure you are using the windows version so what version are 
you using? where did you got it from?

Basically in some cases it is expected from the proxy to slow down the 
connection but in many cases it is due to some other reasons such as 
network issues or slow host machine or a bug.

Eliezer

On 09/12/2015 02:50, Patrick Flaherty wrote:
> Hi,
>
>
>
> My Squid Server is much slower to go through than direct access to the
> internet. I would expect it to be slower but not dramatically slower. Any
> tips to speed it up? It's only used to access 8 whitelisted domains. I am
> not using the disk based cache as it's only 8 sites total we hit. See my
> squid config below and please offer any suggestions.
>
>
>
> Thank You,
>
> Patrick
>
>
>
> # Proxy Configuration
>
>
>
> http_port     3128
>
>
>
> # acl and http_access to ("whitelist.txt")
>
> acl whitelist dstdomain  "c:/squid/etc/squid/whitelist.txt"
>
> http_access        allow     whitelist
>
>
>
> # network source of proxy traffic
>
> acl localnet  src        all
>
>
>
> # debug (Used by Rave Support Only)
>
> #debug_options              ALL,2
>
>
>
> # acl directives for ports and protocols
>
> acl http      proto      http
>
> acl https     proto      https
>
> acl port_80   port       80
>
> acl sslports  port       443
>
> acl CONNECT   method     CONNECT
>
>
>
> # localhost proxy access
>
> acl localhost src 127.0.0.1/32
>
> http_access allow localhost
>
>
>
> # rules allowing proxy access
>
> http_access allow http    port_80  whitelist localnet
>
> http_access allow https   sslports whitelist localnet
>
>
>
> # dns servers (Change dns_nameservers to client dns servers for consistency
> and better performance)
>
> dns_nameservers 172.16.50.1 172.16.50.9
>
>
>
> # cache web pages directory
>
> #cache_dir ufs C:/Squid/var/cache/squid 100 16 256
>
> cache_mem 64 MB
>
>
>
> # log file roll weekly
>
> logfile_rotate 7
>
>
>
> # access log rules
>
> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
>
>
>
> # catch-all rule
>
> http_access deny all
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From squid3 at treenet.co.nz  Wed Dec  9 01:23:01 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 9 Dec 2015 14:23:01 +1300
Subject: [squid-users] ssl-bump splice on unsupported ciphers
In-Reply-To: <F683BAA1-082D-4110-931B-2C6890C4E569@hendrie.id.au>
References: <F683BAA1-082D-4110-931B-2C6890C4E569@hendrie.id.au>
Message-ID: <56678275.5000308@treenet.co.nz>

On 9/12/2015 1:59 p.m., Michael Hendrie wrote:
> Hi All,
> 
> I've read a few articles that indicate squid-3.5 and below doesn't support ssl-bump'ing ECDHE ciphers.
> 
> Is this correct?

That is correct.

> If so, is it possible to create/structure acl and ssl-bump rules to splice on unsupported ciphers? 
> 
> I've looked through the available ACL options and doesn't seem to be possible unless I'm missing something.
> 

Good question. The workaround that comes to mind is using the user_cert
type ACL to match values in the certificate.

But doing so by custom OID is also only available in Squid-4 and later.
So if ciphers is not one of the specific fields listed that 3.5 and
older can match, then AFAIK you are out of luck.


FYI: Squid-4 is available, all that "beta" means is that the new code
has not yet had much testing. It works fine for some of us in
production. You may be able to use it also but some extra care is
recommended to check it works well enough before rolling it out.

... or in short: YMMV.

Amos



From squid3 at treenet.co.nz  Wed Dec  9 01:56:23 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 9 Dec 2015 14:56:23 +1300
Subject: [squid-users] Slow Squid
In-Reply-To: <006501d1321b$9fb01d40$df1057c0$@verizon.net>
References: <006501d1321b$9fb01d40$df1057c0$@verizon.net>
Message-ID: <56678A47.8000600@treenet.co.nz>

On 9/12/2015 1:50 p.m., Patrick Flaherty wrote:
> Hi,
> 
>  
> 
> My Squid Server is much slower to go through than direct access to the
> internet. I would expect it to be slower but not dramatically slower. Any
> tips to speed it up? It's only used to access 8 whitelisted domains. I am
> not using the disk based cache as it's only 8 sites total we hit. See my
> squid config below and please offer any suggestions.
> 


What Squid version are you using?
 And what are the values for "slower" ?


> 
> # acl and http_access to ("whitelist.txt")
> 
> acl whitelist dstdomain  "c:/squid/etc/squid/whitelist.txt"

[ I'm not sure if this following applies to the Cygwin builds. It may
not, but since the FD limit is actually coming from the Windows kernel
itself it might anyway. ]

On Windows the proxy faces an absolute OS limit of 2048 FD that are
available per-process group.

Since each transaction/request uses 2-3 FD that means Squid on Windows
can service no more than ~1,000 RPS regardless of CPU capacity. Keeping
in mind modern browsers open 6 connections to a proxy, that means
160-200 concurrent visitors.

By comparison non-Windows proxies can reach ~20,000 RPS with up to 10K
concurrent visitors. So "slow" is par for the course on Windows (if you
have a lot of users).


> 
> http_access        allow     whitelist
> 

At this point, anybody from anywhere (the whole Internet) who can access
the proxy is allowed to fetch anythign from the whitelisted
servers/domains through it. No other limits on those servers.

>  
> 
> # network source of proxy traffic
> 
> acl localnet  src        all
> 

So you are defining the entire Internet as being your LAN.

All the security controls, both those configured in your squid.conf
*and* any default built-in Squid settings that restrict access to the
LAN will now be wide open to any external visitor.


> 
> # acl directives for ports and protocols
> 
> acl http      proto      http
> 
> acl https     proto      https
> 
> acl port_80   port       80
> 
> acl sslports  port       443
> 
> acl CONNECT   method     CONNECT
> 
>  
> 
> # localhost proxy access
> 
> acl localhost src 127.0.0.1/32
> 
> http_access allow localhost
> 

You now have unlimited access to any of the whitelisted domains (from
earlier) *or* to anywhere at all when coming from localhost.

Note that this is *extending* the built-in definition of localhost ACL
(if you have a current Squid) which already includes the entire 127/8
and ::1 network ranges.


> 
> # rules allowing proxy access
> 
> http_access allow http    port_80  whitelist localnet
> 
> http_access allow https   sslports whitelist localnet
> 

These ACLs do nothing but waste CPU. All requests for whitelist domains
are permitted earlier without the protocol and port restrictions.


>  
> 
> # dns servers (Change dns_nameservers to client dns servers for consistency
> and better performance)
> 
> dns_nameservers 172.16.50.1 172.16.50.9
> 
>  
> 
> # cache web pages directory
> 
> #cache_dir ufs C:/Squid/var/cache/squid 100 16 256
> 
> cache_mem 64 MB
> 

There are two implications from this 64MB of RAM cache.

Firstly, memory cache is the primary source of traffic acceleration for
Squid. Having only a small amount limits how much acceleration Squid can
do when the proxy is under load.


If the machine the proxy is running on is an embeded device or minimal
VM so limited that it can only spare 64MB of RAM for caching. Then it is
likely that the available CPU is also constrained and that prpcessor
limit may be the direct cause of the proxy being slow.


>  
> 
> # log file roll weekly
> 
> logfile_rotate 7
> 

NP: most systems default to daily for this AFAIK. If the logs get very
big then the filesystem can cause slowdown appending to them. I'm not
sure if that is relevant for your case, but worth checking.


> 
> # access log rules
> 
> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
> 

Do not redefine a built-in log format. Either use the built-in
definition, or make your custom one have a different name.


Amos



From alex at samad.com.au  Wed Dec  9 10:49:12 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 9 Dec 2015 21:49:12 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <56669602.9020407@treenet.co.nz>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
Message-ID: <CAJ+Q1PUBccbhFZDrg4C8O_rpN6_+tRsK-HVM1UyY_72ZMBzimg@mail.gmail.com>

Hi

Can't seem to find  3.5.12 for centos pre compiled at
http://www1.ngtech.co.il/repo/centos/6/x86_64/


On 8 December 2015 at 19:34, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> * try an upgrade to 3.5.12. There were some regressions in the .10/.11
> releases that can lead to really weird behaviour.


From vero.ovando at live.com  Wed Dec  9 14:25:33 2015
From: vero.ovando at live.com (=?UTF-8?B?VmVyw7NuaWNhIE92YW5kbw==?=)
Date: Wed, 9 Dec 2015 11:25:33 -0300
Subject: [squid-users] Authentication pop-ups. Questions
Message-ID: <BLU436-SMTP1541B6078C9156DBA9F64339EE80@phx.gbl>

Hi. I have Squid 3.5 running over Debian 8.

I am using AD authentication. This is part of my squid.conf:

#auth_param ntlm program /usr/local/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --domain=DOMAIN.com
auth_param ntlm program /usr/local/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 30
auth_param ntlm keep_alive off

auth_param basic program /usr/local/bin/ntlm_auth --helper-protocol=squid-2.5-basic
auth_param basic children 5
auth_param basic realm Servidor proxy-cache de mi Dominio
auth_param basic credentialsttl 2 hours

external_acl_type AD_Grupos ttl=10 children=10 %LOGIN
/usr/lib/squid3/ext_wbinfo_group_acl -d

acl AD_Standard external Grupos_AD Standard
acl AD_Exceptuados external Grupos_AD Exceptuados
acl AD_Bloqueados external Grupos_AD Bloqueados

acl face url_regex -i "/etc/squid3/facebook"
acl gob url_regex -i "/etc/squid3/gubernamentales"

http_access allow AD_Standard
http_access allow AD_Exceptuados face
http_access allow AD_Exceptuados gob
http_access deny AD_Bloqueados
http_access deny all


When  a users that belongs to AD_Bloqueados is asked for the AD user and 
password (of course he/she needs one that belongs to AD_Standard or 
AD_Exceptuados). When I try to use one of those users I cannot 
authenticate correctly. the popup appears many times until I cancel it. 
But sometimes it works. I use all the browsers to do the tests (IE, 
Mozilla and the latest Chrome). With Chrome I get good results, but as I 
said, it works sometimes.

Because sometimes I login with users not in the domain and I need to 
access to internet, I cannot use the 'all' directive in the end of the 
line of 'http_access deny AD_Bloqueados.'

I will appreciate a lot any help you can give me.

Sorry for my English. Thanks.



From magiclink at outlook.com  Wed Dec  9 14:42:02 2015
From: magiclink at outlook.com (Magic Link)
Date: Wed, 9 Dec 2015 15:42:02 +0100
Subject: [squid-users] issue with video
Message-ID: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>

Hi,
i have a problem with this video http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/This video doesn't start with squid (3.4.8) on Debian 8 but does with a direct access to Internet.I don't know how to debug this issue.
Any clues ? Thanks 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151209/397c9664/attachment.htm>

From supergeorge1234 at gmail.com  Wed Dec  9 15:11:42 2015
From: supergeorge1234 at gmail.com (George Hollingshead)
Date: Wed, 9 Dec 2015 10:11:42 -0500
Subject: [squid-users] logging https websites
Message-ID: <CABQqRma0d-D3GvAj5wJLxzKcSnkwF5tg_i0wSr1B4K6f-+JGpg@mail.gmail.com>

is there a simple way to log request made to https sites.  I just want to
see sites visited without having to set up tunneling and all this complex
stuff i'm reading about.

Hoping there's a simple way, and yes, i'm a newb but smart enough to have
your awesome program running; hehe

Thanx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151209/57ce0e70/attachment.htm>

From vze2k3sa at verizon.net  Wed Dec  9 15:29:06 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Wed, 09 Dec 2015 10:29:06 -0500
Subject: [squid-users] Slow Squid
Message-ID: <008701d13296$588528e0$098f7aa0$@verizon.net>

Hi ,

I have changed my 3.5.11 squid.conf based on your excellent feedback Amos.
Please have a look at my edits to see if it is improved.

Thank You,
Patrick

# Squid Proxy Configuration

# listening port
http_port     3128

# max_filedesc
max_filedesc  2048

# debug_options	ALL,2


# acl directives for ports and protocols
acl http      proto      http
acl https     proto      https
acl port_80   port       80
acl sslports  port       443
acl CONNECT   method     CONNECT


# acl and http_access ("rmsc.txt")
acl whitelist dstdomain  "c:/squid/etc/squid/rmsc.txt"
http_access 	allow 	whitelist
http_access 	deny 	whitelist

# network source of proxy traffic (Specific Network Example 192.168.1.0/24)
acl localnet  src        172.16.50.0/24
http_access allow localnet
http_access deny localnet


# localhost proxy access
#acl localhost src 127.0.0.1/32
#http_access allow localhost

# rules allowing proxy access
#http_access allow http    port_80  whitelist localnet
#http_access allow https   sslports whitelist localnet

# dns servers (Change dns_nameservers to client dns servers for consistency
and better performance)
dns_nameservers 172.16.50.9 172.16.9.13

# cache web pages
cache_mem 512 MB

# roll log file daily and keep 30 days
logfile_rotate 30

# access log format         (Having one problem with the Default Squid log
and that is the timestamp being Epoch and not human readable on Windows
platform)
logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt

# catch-all rule
http_access deny all

----------------------------------------------------------------------------
-----------------------------
Message: 2
Date: Wed, 9 Dec 2015 14:56:23 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Slow Squid
Message-ID: <56678A47.8000600 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 9/12/2015 1:50 p.m., Patrick Flaherty wrote:
> Hi,
> 
>  
> 
> My Squid Server is much slower to go through than direct access to the 
> internet. I would expect it to be slower but not dramatically slower. 
> Any tips to speed it up? It's only used to access 8 whitelisted 
> domains. I am not using the disk based cache as it's only 8 sites 
> total we hit. See my squid config below and please offer any suggestions.
> 


What Squid version are you using?
 And what are the values for "slower" ?


> 
> # acl and http_access to ("whitelist.txt")
> 
> acl whitelist dstdomain  "c:/squid/etc/squid/whitelist.txt"

[ I'm not sure if this following applies to the Cygwin builds. It may not,
but since the FD limit is actually coming from the Windows kernel itself it
might anyway. ]

On Windows the proxy faces an absolute OS limit of 2048 FD that are
available per-process group.

Since each transaction/request uses 2-3 FD that means Squid on Windows can
service no more than ~1,000 RPS regardless of CPU capacity. Keeping in mind
modern browsers open 6 connections to a proxy, that means
160-200 concurrent visitors.

By comparison non-Windows proxies can reach ~20,000 RPS with up to 10K
concurrent visitors. So "slow" is par for the course on Windows (if you have
a lot of users).


> 
> http_access        allow     whitelist
> 

At this point, anybody from anywhere (the whole Internet) who can access the
proxy is allowed to fetch anythign from the whitelisted servers/domains
through it. No other limits on those servers.

>  
> 
> # network source of proxy traffic
> 
> acl localnet  src        all
> 

So you are defining the entire Internet as being your LAN.

All the security controls, both those configured in your squid.conf
*and* any default built-in Squid settings that restrict access to the LAN
will now be wide open to any external visitor.


> 
> # acl directives for ports and protocols
> 
> acl http      proto      http
> 
> acl https     proto      https
> 
> acl port_80   port       80
> 
> acl sslports  port       443
> 
> acl CONNECT   method     CONNECT
> 
>  
> 
> # localhost proxy access
> 
> acl localhost src 127.0.0.1/32
> 
> http_access allow localhost
> 

You now have unlimited access to any of the whitelisted domains (from
earlier) *or* to anywhere at all when coming from localhost.

Note that this is *extending* the built-in definition of localhost ACL (if
you have a current Squid) which already includes the entire 127/8 and ::1
network ranges.


> 
> # rules allowing proxy access
> 
> http_access allow http    port_80  whitelist localnet
> 
> http_access allow https   sslports whitelist localnet
> 

These ACLs do nothing but waste CPU. All requests for whitelist domains are
permitted earlier without the protocol and port restrictions.


>  
> 
> # dns servers (Change dns_nameservers to client dns servers for 
> consistency and better performance)
> 
> dns_nameservers 172.16.50.1 172.16.50.9
> 
>  
> 
> # cache web pages directory
> 
> #cache_dir ufs C:/Squid/var/cache/squid 100 16 256
> 
> cache_mem 64 MB
> 

There are two implications from this 64MB of RAM cache.

Firstly, memory cache is the primary source of traffic acceleration for
Squid. Having only a small amount limits how much acceleration Squid can do
when the proxy is under load.


If the machine the proxy is running on is an embeded device or minimal VM so
limited that it can only spare 64MB of RAM for caching. Then it is likely
that the available CPU is also constrained and that prpcessor limit may be
the direct cause of the proxy being slow.


>  
> 
> # log file roll weekly
> 
> logfile_rotate 7
> 

NP: most systems default to daily for this AFAIK. If the logs get very big
then the filesystem can cause slowdown appending to them. I'm not sure if
that is relevant for your case, but worth checking.


> 
> # access log rules
> 
> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
> 

Do not redefine a built-in log format. Either use the built-in definition,
or make your custom one have a different name.


Amos



------------------------------

Message: 3
Date: Wed, 9 Dec 2015 21:49:12 +1100
From: Alex Samad <alex at samad.com.au>
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid reverse proxy infront of exchange
	2010
Message-ID:
	<CAJ+Q1PUBccbhFZDrg4C8O_rpN6_+tRsK-HVM1UyY_72ZMBzimg at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

Hi

Can't seem to find  3.5.12 for centos pre compiled at
http://www1.ngtech.co.il/repo/centos/6/x86_64/


On 8 December 2015 at 19:34, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> * try an upgrade to 3.5.12. There were some regressions in the .10/.11 
> releases that can lead to really weird behaviour.


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 16, Issue 32
*******************************************



From leolistas at solutti.com.br  Wed Dec  9 18:25:58 2015
From: leolistas at solutti.com.br (Leonardo Rodrigues)
Date: Wed, 9 Dec 2015 16:25:58 -0200
Subject: [squid-users] logging https websites
In-Reply-To: <CABQqRma0d-D3GvAj5wJLxzKcSnkwF5tg_i0wSr1B4K6f-+JGpg@mail.gmail.com>
References: <CABQqRma0d-D3GvAj5wJLxzKcSnkwF5tg_i0wSr1B4K6f-+JGpg@mail.gmail.com>
Message-ID: <56687236.1060909@solutti.com.br>

Em 09/12/15 13:11, George Hollingshead escreveu:
> is there a simple way to log request made to https sites.  I just want 
> to see sites visited without having to set up tunneling and all this 
> complex stuff i'm reading about.
>
> Hoping there's a simple way, and yes, i'm a newb but smart enough to 
> have your awesome program running; hehe
>
     If you really want a SIMPLE way, than the answer is NO, that's not 
possible

     With simply configuring the proxy on the users browsers, you'll be 
able to see the hostname, but not the full URL

user acessing https://www.gmail.com/mail/something/INBOX
will appear on the logs just as
CONNECT www.gmail.com

     and that's how it works ... the path is only visible to the 
endpoints, the browser and the server, squid just carries the encripted 
tunnel between them, without knowing what's happening inside.

     is it possible to decript and see the full path on the logs, being 
able to filter on them and everything else ?? YES, that's ssl-bump, but 
that's FAR from being an easy setup ...



-- 


	Atenciosamente / Sincerily,
	Leonardo Rodrigues
	Solutti Tecnologia
	http://www.solutti.com.br

	Minha armadilha de SPAM, N?O mandem email
	gertrudes at solutti.com.br
	My SPAMTRAP, do not email it





From marciobacci at gmail.com  Wed Dec  9 21:40:11 2015
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Wed, 9 Dec 2015 19:40:11 -0200
Subject: [squid-users] Problem with ext_ldap_group_acl
Message-ID: <CA+0TdyrRNceRKHWY6RMK7qT67fhND7_At6zKBOXOq-gsUs7egQ@mail.gmail.com>

I'm trying authenticate Squid (3.4.8) in the Samba 4.

The first block is working perfectly.

auth_param basic program /usr/lib/squid3/basic_ldap_auth -R -b \
DC=empresa,DC=com,DC=br -D CN=proxy,CN=Users,DC=empresa,DC=com,DC=br \
-w 12345 -h 192.168.0.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"
auth_param basic children 50
auth_param basic realm Proxy Server Squid
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off


But when I try to use external_acl_type,

external_acl_type ad_group %LOGIN /usr/lib/squid3/ext_ldap_group_acl -v 3
-R -b \
DC=empresa,DC=com,DC=br -f
?(&(cn=%v)(memberOf=cn=%a,DC=empresa,DC=com,DC=br ))? -D \
CN=proxy,CN=Users,DC=empresa,DC=com,DC=br -w 12345 -P 192.168.0.25:389


I have the following problem:

*ext_ldap_group_acl: WARNING: LDAP search error 'Bad search filter'*

Could anybody help me?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151209/6b31441a/attachment.htm>

From squid3 at treenet.co.nz  Wed Dec  9 21:56:04 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 10 Dec 2015 10:56:04 +1300
Subject: [squid-users] Authentication pop-ups. Questions
In-Reply-To: <BLU436-SMTP1541B6078C9156DBA9F64339EE80@phx.gbl>
References: <BLU436-SMTP1541B6078C9156DBA9F64339EE80@phx.gbl>
Message-ID: <5668A374.9030307@treenet.co.nz>

On 10/12/2015 3:25 a.m., Ver?nica Ovando wrote:
> Hi. I have Squid 3.5 running over Debian 8.
> 
> I am using AD authentication. This is part of my squid.conf:
> 
> #auth_param ntlm program /usr/local/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp --domain=DOMAIN.com
> auth_param ntlm program /usr/local/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 30
> auth_param ntlm keep_alive off
> 
> auth_param basic program /usr/local/bin/ntlm_auth
> --helper-protocol=squid-2.5-basic
> auth_param basic children 5
> auth_param basic realm Servidor proxy-cache de mi Dominio
> auth_param basic credentialsttl 2 hours
> 
> external_acl_type AD_Grupos ttl=10 children=10 %LOGIN
> /usr/lib/squid3/ext_wbinfo_group_acl -d
> 
> acl AD_Standard external Grupos_AD Standard
> acl AD_Exceptuados external Grupos_AD Exceptuados
> acl AD_Bloqueados external Grupos_AD Bloqueados
> 
> acl face url_regex -i "/etc/squid3/facebook"
> acl gob url_regex -i "/etc/squid3/gubernamentales"
> 
> http_access allow AD_Standard
> http_access allow AD_Exceptuados face
> http_access allow AD_Exceptuados gob
> http_access deny AD_Bloqueados
> http_access deny all
> 
> 
> When  a users that belongs to AD_Bloqueados is asked for the AD user and
> password (of course he/she needs one that belongs to AD_Standard or
> AD_Exceptuados). 

The first login check is for "AD_Standard". Users initial login is
checked for that group membership ... then a 407 *re-login* is requested
if they are part of AD_Bloqueados.

All users are logged in, just to check the group. So "deny all" at the
end never actually happens unless the user is part of some 5th or 6th
group (for example "Administrators" or "Domain Servers").

When you are authenticating based on *group* instead of the
user/password things get really weird.


> When I try to use one of those users I cannot
> authenticate correctly. the popup appears many times until I cancel it.
> But sometimes it works. I use all the browsers to do the tests (IE,
> Mozilla and the latest Chrome). With Chrome I get good results, but as I
> said, it works sometimes.
> 
> Because sometimes I login with users not in the domain and I need to
> access to internet, I cannot use the 'all' directive in the end of the
> line of 'http_access deny AD_Bloqueados.'

Which means that whenever that group AD_Bloqueados matches the user will
have to *re-login*. Popups etc are expected in such events, because the
browser has what it thinks are fine credentials to use. But has just
been informed that its known set of credentials were invalid. They
almost all panic at that point and do a popup.

Note that the browser does not get told *why* the rejection (it might be
a random attacker, so that info is privileged). Just that the
credentials are not usable.

> 
> I will appreciate a lot any help you can give me.


I highly recommend that you do it like this:

 acl auth proxy_auth REQUIRED
 http_access deny !auth
 http_access allow AD_Standard
 http_access allow face AD_Exceptuados
 http_access allow gob AD_Exceptuados
 http_access deny all

Why:
* that !auth will ensure that users are only authenticated once and the
407 request lookup cycles all happen predictably at that first line
instead of interleaved within the group checks.

* the line ordering change of face/gob ACLs will greatly reduce the time
and CPU spent on helper lookups for non-face and non-gob traffic. (up to
50% reduction in proxy caused latency).

Note that you dont even need to check group AD_Bloqueados. The "deny
all" at the end rejects that groups access along with all other
undefined groups.

Amos



From squid3 at treenet.co.nz  Wed Dec  9 22:03:04 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 10 Dec 2015 11:03:04 +1300
Subject: [squid-users] logging https websites
In-Reply-To: <56687236.1060909@solutti.com.br>
References: <CABQqRma0d-D3GvAj5wJLxzKcSnkwF5tg_i0wSr1B4K6f-+JGpg@mail.gmail.com>
 <56687236.1060909@solutti.com.br>
Message-ID: <5668A518.8050403@treenet.co.nz>

On 10/12/2015 7:25 a.m., Leonardo Rodrigues wrote:
> Em 09/12/15 13:11, George Hollingshead escreveu:
>> is there a simple way to log request made to https sites.  I just want
>> to see sites visited without having to set up tunneling and all this
>> complex stuff i'm reading about.
>>
>> Hoping there's a simple way, and yes, i'm a newb but smart enough to
>> have your awesome program running; hehe
>>
>     If you really want a SIMPLE way, than the answer is NO, that's not
> possible
> 
>     With simply configuring the proxy on the users browsers, you'll be
> able to see the hostname, but not the full URL
> 
> user acessing https://www.gmail.com/mail/something/INBOX
> will appear on the logs just as
> CONNECT www.gmail.com
> 
>     and that's how it works ... the path is only visible to the
> endpoints, the browser and the server, squid just carries the encripted
> tunnel between them, without knowing what's happening inside.
> 
>     is it possible to decript and see the full path on the logs, being
> able to filter on them and everything else ?? YES, that's ssl-bump, but
> that's FAR from being an easy setup ...
> 

It is also worth noting that clients sending SNI can have their prot 443
traffic intercepted, then logged without actually decrypting.
The setup for that looks like the normal ssl-bump setup. But just peeks
and splices everything.

Amos



From squid3 at treenet.co.nz  Wed Dec  9 23:00:50 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 10 Dec 2015 12:00:50 +1300
Subject: [squid-users] Slow Squid
In-Reply-To: <008701d13296$588528e0$098f7aa0$@verizon.net>
References: <008701d13296$588528e0$098f7aa0$@verizon.net>
Message-ID: <5668B2A2.4000401@treenet.co.nz>

On 10/12/2015 4:29 a.m., Patrick Flaherty wrote:
> Hi ,
> 
> I have changed my 3.5.11 squid.conf based on your excellent feedback Amos.
> Please have a look at my edits to see if it is improved.
> 
> Thank You,
> Patrick
> 
> # Squid Proxy Configuration
> 
> # listening port
> http_port     3128
> 
> # max_filedesc
> max_filedesc  2048
> 

FYI: the directive name is actually "max_filedescriptors". The
"filedesc" thing is a RHEL hack, Squid accepts it but only for backward
compatibility.


> # debug_options	ALL,2
> 
> 
> # acl directives for ports and protocols
> acl http      proto      http
> acl https     proto      https
> acl port_80   port       80
> acl sslports  port       443
> acl CONNECT   method     CONNECT
> 
> 
> # acl and http_access ("rmsc.txt")
> acl whitelist dstdomain  "c:/squid/etc/squid/rmsc.txt"
> http_access 	allow 	whitelist

This is no change from before. Everything matching whitelist is allowed.
No other rules about whitelist are reachable.


FYI:
Squid checks access controls from the top down, left to right.
The first non-matching ACL check on a line wins and no following ACLs
are checked.
The first fully matching line wins and no following lines are checked.


So;
* whenever "allow localnet" matches, the "deny localnet" line will not
be processed.
* whenever "allow localnet" does not match, the "deny localnet" line is
also a non-match.

Understand?


Also, if you are going to let "anyone" access the listed domains, at
least place the basic security protections in at the top. They protect
against abuses like people sending Spam or VPN tunnels through the proxy.

These ones that are set in the default squid.conf:
 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_Ports

 ... then your whitelist rule:

  http_access allow whitelist


> http_access 	deny 	whitelist

> 
> # network source of proxy traffic (Specific Network Example 192.168.1.0/24)
> acl localnet  src        172.16.50.0/24
> http_access allow localnet

Thats better.


> http_access deny localnet
> 

Same as with whitelist rules above. Denying something has no effect if
you already allowed it.


> # dns servers (Change dns_nameservers to client dns servers for consistency
> and better performance)
> dns_nameservers 172.16.50.9 172.16.9.13
> 

Or if your system registry settings are the same ones the clients are
using, remove the dns_nameservers entirely and Squid will use the
networks normal resolver(s).


> # cache web pages
> cache_mem 512 MB
> 
> # roll log file daily and keep 30 days
> logfile_rotate 30
> 
> # access log format         (Having one problem with the Default Squid log
> and that is the timestamp being Epoch and not human readable on Windows
> platform)
> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt

The problem I pointed out was the *name* of the logformat.

 logformat something %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
 access_log stdio:/var/log/squid/access.log something

(or whatever the local path equivalent needs to be).


Amos



From squid3 at treenet.co.nz  Wed Dec  9 23:09:00 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 10 Dec 2015 12:09:00 +1300
Subject: [squid-users] issue with video
In-Reply-To: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>
Message-ID: <5668B48C.703@treenet.co.nz>

On 10/12/2015 3:42 a.m., Magic Link wrote:
> Hi,
> i have a problem with this video http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/ This video doesn't start with squid (3.4.8) on Debian 8 but does with a direct access to Internet.I don't know how to debug this issue.
> Any clues ? Thanks 		 	   		  
> 

Check cache.log to see if any errors are being logged when you request it.

Check access.log to see if the proxy is actually being contacted to
fetch the video.

"debug_options 11,2" to see what the request and reply headers are.

If you can, try an upgrade. Current Squid is 3.5.12. I'm just mentioning
this because its the nromal debugging step. I dont recommend a
cross-install of the 3.5.12 package to Debian 8 - it needs a proper
backport / recompile.

The remaining steps get trickier and depend on the results of the above
checks, or whether


Amos



From alex at samad.com.au  Thu Dec 10 05:29:25 2015
From: alex at samad.com.au (Alex Samad)
Date: Thu, 10 Dec 2015 16:29:25 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <56669602.9020407@treenet.co.nz>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
Message-ID: <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>

Hi

config
https_port 22.4.2.5:443 accel
cert=/etc/httpd/conf.d/office.abc.com.crt
key=/etc/httpd/conf.d/office.abc.com.key defaultsite=office.abc.com
options=NO_SSLv2,NO_SSLv3
dhparams=/etc/squid/squid-office-dhparams.pem
cipher=ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA
cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
sslcert=/etc/httpd/conf.d/office.abc.com.crt
sslkey=/etc/httpd/conf.d/office.abc.com.key name=webServer
cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
originserver login=PASS front-end-https=on ssl
sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.abc.com.crt
sslkey=/etc/httpd/conf.d/office.abc.com.key name=exchangeServer
acl exch_domain dstdomain office.abc.com
acl exch_path urlpath_regex -i /exch(ange|web)
acl exch_path urlpath_regex -i /public
acl exch_path urlpath_regex -i /owa
acl exch_path urlpath_regex -i /ecp
acl exch_path urlpath_regex -i /microsoft-server-activesync
acl exch_path urlpath_regex -i /rpc
acl exch_path urlpath_regex -i /rpcwithcert
acl exch_path urlpath_regex -i /exadmin
acl exch_path urlpath_regex -i /ews
acl exch_path urlpath_regex -i /oab
acl exch_path urlpath_regex -i /autodiscover
cache_peer_access exchangeServer allow exch_domain exch_path
cache_peer_access webServer deny exch_domain exch_path
never_direct allow exch_domain exch_path
cache_mem 32 MB
maximum_object_size_in_memory 128 KB
access_log stdio:/var/log/squid/office-access.log squid
cache_log /var/log/squid/office-cache.log
cache_store_log stdio:/var/log/squid/office-cache_store.log
pid_filename /var/run/squid-office.pid
visible_hostname office.abc.com
deny_info TCP_RESET all
http_access allow all
miss_access allow all
icp_port 0
snmp_port 0



cache.log
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Process ID 5631
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Process Roles: worker
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| With 1024 file descriptors available
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Initializing IP Cache...
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| DNS Socket created at 0.0.0.0, FD 6
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding domain
yieldbroker.com from /etc/resolv.conf
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding nameserver
10.32.20.100 from /etc/resolv.conf
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding nameserver
10.32.20.102 from /etc/resolv.conf
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Logfile: opening log
stdio:/var/log/squid/office-access.log
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Local cache digest enabled;
rebuild/rewrite every 3600/3600 sec
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Logfile: opening log
stdio:/var/log/squid/office-cache_store.log
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Swap maxSize 0 + 32768 KB,
estimated 2520 objects
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Target number of buckets: 126
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Using 8192 Store buckets
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Max Mem  size: 32768 KB
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Max Swap size: 0 KB
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Using Least Load store dir selection
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Current Directory is /etc/squid
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Finished loading MIME types and icons.
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| HTCP Disabled.
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Configuring Parent 127.0.0.1/443/0
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Configuring Parent 10.32.69.11/443/0
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Squid plugin modules loaded: 0
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adaptation support is off.
Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Accepting reverse-proxy
HTTPS Socket connections at local=202.74.32.15:443 remote=[::] FD 11
flags=9
Jan 01 10:33:35 1970/12/10 16:15:43 kid1| storeLateRelease: released 0 objects


cache log
Dec 10 16:16:23 2015.225 RELEASE -1 FFFFFFFF
BE6736C8CD1A74A54575AF9880395D04   ?         ?         ?         ? ?/?
?/? ? ?
Dec 10 16:16:34 2015.287 RELEASE -1 FFFFFFFF
78C390A2D412F8E601035A2C1FD771C8   ?         ?         ?         ? ?/?
?/? ? ?
Dec 10 16:16:34 2015.296 RELEASE -1 FFFFFFFF
A7D8B3751858C54225D29408B56FE42D   ?         ?         ?         ? ?/?
?/? ? ?
Dec 10 16:16:37 2015.863 RELEASE -1 FFFFFFFF
35992070307CD15EE743F71344E1C1AE   ?         ?         ?         ? ?/?
?/? ? ?
Dec 10 16:16:37 2015.873 RELEASE -1 FFFFFFFF
17EFD3BCAF4265B7CF7803AD0289DD7E   ?         ?         ?         ? ?/?
?/? ? ?
Dec 10 16:16:49 2015.228 RELEASE -1 FFFFFFFF
2666EC9714425D57FDC4CD15965D350B   ?         ?         ?         ? ?/?
?/? ? ?



access.logs
Dec 10 16:17:09 2015.706     13 192.168.56.1 TCP_MISS/200 6578 POST
https://office.abc.com/ews/exchange.asmx - FIRSTUP_PARENT/10.32.69.11
text/xml
Dec 10 16:19:36 2015.447 206818 192.168.56.1 TCP_MISS/200 16532
RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
FIRSTUP_PARENT/10.32.69.11 application/rpc
Dec 10 16:19:36 2015.449 206862 192.168.56.1 TCP_MISS_ABORTED/502 4493
RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
FIRSTUP_PARENT/10.32.69.11 text/html
Dec 10 16:19:36 2015.453 207197 192.168.56.1 TCP_MISS_ABORTED/000 0
RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
FIRSTUP_PARENT/10.32.69.11 -
Dec 10 16:19:36 2015.453 207087 192.168.56.1 TCP_MISS_ABORTED/200
48056 RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
FIRSTUP_PARENT/10.32.69.11 application/rpc
Dec 10 16:20:07 2015.305  24688 192.168.56.1 TCP_MISS_ABORTED/000 0
RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
FIRSTUP_PARENT/10.32.69.11 -
Dec 10 16:20:07 2015.306  24654 192.168.56.1 TCP_MISS_ABORTED/200 2004
RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
FIRSTUP_PARENT/10.32.69.11 application/rpc


This is when I try and send an email with an attachment. An email with
no attached goes through no problem...


this config works with 3.1, not with 3.5 ..

still on .11 as I can't find centos 6 compile of .12

I think there is some issue with rpc sending or receiving ..

On 8 December 2015 at 19:34, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 8/12/2015 7:35 p.m., Alex Samad wrote:
>> Hi
>>
>> Any suggestions on how to debug this... I wouldn't mind rolling
>> forward to 3.5 again
>>
>
> Some ideas inline. The main ones are:
>
> * re-enable cache.log. It is not optional.
>
> * try an upgrade to 3.5.12. There were some regressions in the .10/.11
> releases that can lead to really weird behaviour.
>
>
>> On 2 December 2015 at 20:39, Alex Samad wrote:
>>> Just to add to this I have a lot of these in the log file
>>>
>>> TCP_MISS_ABORTED/000 0 RPC_IN_DATA
>>> TCP_MISS_ABORTED/200 4322 RPC_OUT_DATA
>>> TCP_MISS_ABORTED/000 0 RPC_IN_DATA https:
>>>
>>>
>>>
>>> On 2 December 2015 at 17:24, Alex Samad wrote:
>>>> Hi
>>>>
>>>> recently upgraded to squid-3.5.11-1.el6.x86_64 from the centos 6.7  squid 3.1
>>>>
>>>>
>>>> I am now having problems with people who use active sync via this
>>>> connection . seems like emails with attachments aren't making it
>>>> through .
>>>>
>>>> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
>>>> originserver login=PASS front-end-https=on ssl
>>>> sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.yx.com.crt
>>>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=exchangeServer
>
> You could try changing these from login=PASS to login=PASSTHRU
>
>>>>
>>>>
>>>> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
>>>> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
>>>> sslcert=/etc/httpd/conf.d/office.yx.com.crt
>>>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=webServer
>>>> c
>>>>
>>>> # List of acceptable URLs to send to the Exchange server
>>>> acl exch_url url_regex -i office.yieldbroker.com/exchange
>>>> acl exch_url url_regex -i office.yieldbroker.com/exchweb
>>>> acl exch_url url_regex -i office.yieldbroker.com/public
>>>> acl exch_url url_regex -i office.yieldbroker.com/owa
>>>> acl exch_url url_regex -i office.yieldbroker.com/ecp
>>>> acl exch_url url_regex -i office.yieldbroker.com/microsoft-server-activesync
>>>> acl exch_url url_regex -i office.yieldbroker.com/rpc
>>>> acl exch_url url_regex -i office.yieldbroker.com/rpcwithcert
>>>> acl exch_url url_regex -i office.yieldbroker.com/exadmin
>>>> acl exch_url url_regex -i office.yieldbroker.com/oab
>>>> # added after
>>>> acl exch_url url_regex -i office.yieldbroker.com/ews
>>>> # Not configured on exchange 2010
>>>> #acl exch_url url_regex -i office.yieldbroker.com/autodiscover
>>>>
>>>> # Send the Exchange URLs to the Exchange server
>>>> cache_peer_access exchangeServer allow exch_url
>>>>
>>>> # Send everything else to the Apache
>>>> cache_peer_access webServer deny exch_url
>>>>
>>>> # This is to protect Squid
>>>> never_direct allow exch_url
>>>>
>>>> # Logging Configuration
>>>> redirect_rewrites_host_header off
>>>> cache_mem 32 MB
>>>> maximum_object_size_in_memory 128 KB
>>>> cache_log none
>
> You should re-enable cache.log and fix any of the issues that are logged
> there.
>
>
>>>> cache_store_log none
>>>>
>>>> access_log stdio:/var/log/squid/office-access.log squid
>>>> #access_log none
>>>> cache_log /var/log/squid/office-cache.log
>>>> #cache_log none
>>>> pid_filename /var/run/squid-office.pid
>>>>
>>>>
>>>> # Set the hostname so that we can see Squid in the path (Optional)
>>>> visible_hostname yieldbroker.com
>>>> deny_info TCP_RESET all
>
> This could lead to strange behaviour. Particularly since "deny all" is
> not being used in your http_access rules ...
>
>
>>>>
>>>> # Allow everyone through, internal and external connections
>>>> http_access allow all
>>>> miss_access allow all
>>>>
>>>> icp_port 0
>>>> snmp_port 0
>>>>
>>>> via off
>>>>
>>>>
>>>> The previous setup had worked for at least 18 months.
>>>>
>>>> Alex
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rafael.akchurin at diladele.com  Thu Dec 10 08:16:48 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 10 Dec 2015 08:16:48 +0000
Subject: [squid-users] [squid related software] Web Safety ICAP Filter 4.3
 for Squid is available
Message-ID: <VI1PR04MB1359AB7AC86900D156A6C10C8FE90@VI1PR04MB1359.eurprd04.prod.outlook.com>

Greetings everyone,

Version 4.3.0.B716 of Web Safety ICAP Filter for Squid is now available. We have finally added support for working with Squid on FreeBSD 10 and pfSense 2.2. In this version we tried to concentrate on better reporting, SSL bump root certificate management from Web UI and better dashboard exposing some Squid statistics (via squidclient).

More specifically, this version contains the following bug fixes and improvements:

- Monitoring information is now collected and processed by a specific standalone monitoring server wsmgrd. It is responsible for upload of monitoring information into configured database and generation of Surfing Now real time information, Surfing History and reports. Report upload was heavily optimized so hopefully the ever running Python upload scripts are now history. Please take into account the report generation is still being done by Python so it may still be slow on huge traffic. We plan to concentrate on this in version 4.4.

- We now added the Web UI for management of Root CA ssl bump certificates for the Squid proxy. It is now very simple to generate your own trusted root SSL decryption certificate, back up or upload your own pre-generated certificate all from Web UI.

- Web UI has a new and remastered dashboard with charts of CPU activity, RAM and SWAP used by Squid, ICAP server and monitoring daemon, various system information and history of last connections processed by Squid. Surfing Now and Surfing History allow searching for not only incident id as before but also for host, address, user name, etc.

We now have two preconfigured sample virtual appliances for Ubuntu 14 LTS and CentOS 7 (experimental) available at our site. Please if you have issues/bugs with Web UI or ICAP server do not hesitate to report to support at diladele.com. All other issues are better reported to squid Bugzilla.

Best regards,
Diladele B.V. Dev Team.



From squid3 at treenet.co.nz  Thu Dec 10 08:30:41 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 10 Dec 2015 21:30:41 +1300
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
Message-ID: <56693831.9040400@treenet.co.nz>

On 10/12/2015 6:29 p.m., Alex Samad wrote:
> Hi
> 
> config
> https_port 22.4.2.5:443 accel
> cert=/etc/httpd/conf.d/office.abc.com.crt
> key=/etc/httpd/conf.d/office.abc.com.key defaultsite=office.abc.com
> options=NO_SSLv2,NO_SSLv3
> dhparams=/etc/squid/squid-office-dhparams.pem
> cipher=ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA

None of those ECDHE entries will work properlyy. Squid does not have the
additional curve name support needed to configure them.


> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
> sslcert=/etc/httpd/conf.d/office.abc.com.crt
> sslkey=/etc/httpd/conf.d/office.abc.com.key name=webServer
> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
> originserver login=PASS front-end-https=on ssl
> sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.abc.com.crt
> sslkey=/etc/httpd/conf.d/office.abc.com.key name=exchangeServer

Note that these cache_peer cert details are the "client certificate"
used to 2-way TLS authenticate Squid with the Office server.

I doubt the same certificate used on the https_port will work as both
server and client certificate. Perhapse that is why the verification has
to be fully disabled.


> acl exch_domain dstdomain office.abc.com
> acl exch_path urlpath_regex -i /exch(ange|web)
> acl exch_path urlpath_regex -i /public
> acl exch_path urlpath_regex -i /owa
> acl exch_path urlpath_regex -i /ecp
> acl exch_path urlpath_regex -i /microsoft-server-activesync
> acl exch_path urlpath_regex -i /rpc
> acl exch_path urlpath_regex -i /rpcwithcert
> acl exch_path urlpath_regex -i /exadmin
> acl exch_path urlpath_regex -i /ews
> acl exch_path urlpath_regex -i /oab
> acl exch_path urlpath_regex -i /autodiscover
> cache_peer_access exchangeServer allow exch_domain exch_path
> cache_peer_access webServer deny exch_domain exch_path
> never_direct allow exch_domain exch_path
> cache_mem 32 MB
> maximum_object_size_in_memory 128 KB
> access_log stdio:/var/log/squid/office-access.log squid
> cache_log /var/log/squid/office-cache.log
> cache_store_log stdio:/var/log/squid/office-cache_store.log
> pid_filename /var/run/squid-office.pid
> visible_hostname office.abc.com
> deny_info TCP_RESET all
> http_access allow all
> miss_access allow all
> icp_port 0
> snmp_port 0
> 
> 
> 
> cache.log
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Process ID 5631
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Process Roles: worker
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| With 1024 file descriptors available
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Initializing IP Cache...
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| DNS Socket created at 0.0.0.0, FD 6
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding domain
> yieldbroker.com from /etc/resolv.conf
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding nameserver
> 10.32.20.100 from /etc/resolv.conf
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding nameserver
> 10.32.20.102 from /etc/resolv.conf
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Logfile: opening log
> stdio:/var/log/squid/office-access.log
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Local cache digest enabled;
> rebuild/rewrite every 3600/3600 sec
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Logfile: opening log
> stdio:/var/log/squid/office-cache_store.log
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Swap maxSize 0 + 32768 KB,
> estimated 2520 objects
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Target number of buckets: 126
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Using 8192 Store buckets
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Max Mem  size: 32768 KB
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Max Swap size: 0 KB
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Using Least Load store dir selection
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Current Directory is /etc/squid
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Finished loading MIME types and icons.
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| HTCP Disabled.
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Configuring Parent 127.0.0.1/443/0
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Configuring Parent 10.32.69.11/443/0
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Squid plugin modules loaded: 0
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adaptation support is off.
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Accepting reverse-proxy
> HTTPS Socket connections at local=202.74.32.15:443 remote=[::] FD 11
> flags=9
> Jan 01 10:33:35 1970/12/10 16:15:43 kid1| storeLateRelease: released 0 objects
> 
> 
> cache log
> Dec 10 16:16:23 2015.225 RELEASE -1 FFFFFFFF
> BE6736C8CD1A74A54575AF9880395D04   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:34 2015.287 RELEASE -1 FFFFFFFF
> 78C390A2D412F8E601035A2C1FD771C8   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:34 2015.296 RELEASE -1 FFFFFFFF
> A7D8B3751858C54225D29408B56FE42D   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:37 2015.863 RELEASE -1 FFFFFFFF
> 35992070307CD15EE743F71344E1C1AE   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:37 2015.873 RELEASE -1 FFFFFFFF
> 17EFD3BCAF4265B7CF7803AD0289DD7E   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:49 2015.228 RELEASE -1 FFFFFFFF
> 2666EC9714425D57FDC4CD15965D350B   ?         ?         ?         ? ?/?
> ?/? ? ?
> 
> 
> 
> access.logs
> Dec 10 16:17:09 2015.706     13 192.168.56.1 TCP_MISS/200 6578 POST
> https://office.abc.com/ews/exchange.asmx - FIRSTUP_PARENT/10.32.69.11
> text/xml
> Dec 10 16:19:36 2015.447 206818 192.168.56.1 TCP_MISS/200 16532
> RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 application/rpc
> Dec 10 16:19:36 2015.449 206862 192.168.56.1 TCP_MISS_ABORTED/502 4493
> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 text/html
> Dec 10 16:19:36 2015.453 207197 192.168.56.1 TCP_MISS_ABORTED/000 0
> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 -
> Dec 10 16:19:36 2015.453 207087 192.168.56.1 TCP_MISS_ABORTED/200
> 48056 RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 application/rpc
> Dec 10 16:20:07 2015.305  24688 192.168.56.1 TCP_MISS_ABORTED/000 0
> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 -
> Dec 10 16:20:07 2015.306  24654 192.168.56.1 TCP_MISS_ABORTED/200 2004
> RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 application/rpc
> 

Can you enable "debug_options 11,2" and get a trace of the message
headers going through for those requests?


> 
> This is when I try and send an email with an attachment. An email with
> no attached goes through no problem...
> 
> 
> this config works with 3.1, not with 3.5 ..
> 
> still on .11 as I can't find centos 6 compile of .12

Okay. It seem Eliezer is only getting to it in a few days.

> 
> I think there is some issue with rpc sending or receiving ..
> 

I've been doing some work in the SSL/TLS code recently and found that
Squid is always sending "http/1.1" for the TLS NPN extension. I am a
little suspicious about the particular methods that are failing for you
are non-HTTP methods.
 Are you able to try running the latest Squid with a patch?

Amos



From marciobacci at gmail.com  Thu Dec 10 09:24:02 2015
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Thu, 10 Dec 2015 07:24:02 -0200
Subject: [squid-users] Issues with authentication in Squid3
Message-ID: <CA+0TdyoK5WyCYLf8p=78BrwU34f1bgT1hfYRZzJcSSE3MRc0sw@mail.gmail.com>

Hi,

My problem with Squid 3.4.8 is the following :

The ext_ldap_group_acl locates the user group of a user, but even if find
the first group (eg "administrators") in which the user is a member
continue to search for all groups that the user is a member, so
authenticate the user only in his last group, in the my case is the Domain
Users group.

This way, only rules to Domain Users is working in my Squid Server. Rules
to admins users and others do not work.

I have the message in  /var/log/squid3/cache.log:

2015/12/10 06:36:33 kid1| helperOpenServers: Starting 1/50
'basic_ldap_auth' processes
ext_ldap_group_acl.cc(583): pid=24059 :Connected OK
ext_ldap_group_acl.cc(722): pid=24059 :group filter
'(&(objectclass=person)(sAMAccountName=ze)(memberof=cn=webadmins,DC=empresa,DC=com,DC=br
))', searchbase 'DC=empresa,DC=com,DC=br'
2015/12/10 06:36:34 kid1| Starting new redirector helpers...
2015/12/10 06:36:34 kid1| helperOpenServers: Starting 1/20 'squidGuard'
processes
ext_ldap_group_acl.cc(583): pid=24059 :Connected OK
ext_ldap_group_acl.cc(722): pid=24059 :group filter
'(&(objectclass=person)(sAMAccountName=ze)(memberof=cn=webliberados,DC=empresa,DC=com,DC=br
))', searchbase 'DC=empresa,DC=com,DC=br'
ext_ldap_group_acl.cc(583): pid=24060 :Connected OK
ext_ldap_group_acl.cc(722): pid=24060 :group filter
'(&(objectclass=person)(sAMAccountName=ze)(memberof=cn=domain%20users,DC=empresa,DC=com,DC=br))',
searchbase 'DC=empresa,DC=com,DC=br'
2015/12/10 06:38:04 kid1| Starting new redirector helpers...


Here is my squid.conf

http_port 3128
cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90
maximum_object_size 512 MB
minimum_object_size 0 KB
maximum_object_size_in_memory 4096 KB
cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA
quick_abort_min -1 KB
detect_broken_pconn on
fqdncache_size 1024
refresh_pattern ^ftp:    1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%     0
refresh_pattern .        0    20%    4320
access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log
cache_dir aufs /var/spool/squid3 600 16 256

auth_param basic program /usr/lib/squid3/basic_ldap_auth -R -b
DC=empresa,DC=com,DC=br -D CN=proxy,CN=Users,DC=empresa,DC=com,DC=br -w
12345 -h 192.168.0.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"
auth_param basic children 50
auth_param basic realm Proxy Server Squid
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off

external_acl_type ad_group %LOGIN /usr/lib/squid3/ext_ldap_group_acl -d -R
-b DC=empresa,DC=com,DC=br -D proxy at empresa.com.br -w 12345 -f
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%a,DC=empresa,DC=com,DC=br
))" -h 192.168.0.25

visible_hostname proxy.empresa.com.br
acl localhost src 192.168.0.1/32
acl SSL_ports port 22 443 563
acl Safe_ports port 21
acl Safe_ports port 70
acl Safe_ports port 80
acl Safe_ports port 88
acl Safe_ports port 210
acl Safe_ports port 280
acl Safe_ports port 389
acl Safe_ports port 443
acl Safe_ports port 464
acl Safe_ports port 488
acl Safe_ports port 563
acl Safe_ports port 591
acl Safe_ports port 777
acl Safe_ports port 1025-65535
acl purge method PURGE
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow manager localhost
http_access deny manager
http_access allow purge localhost
http_access deny purge
acl grupo_admins external ad_group webadmins
acl grupo_liberado external ad_group webliberados
acl grupo_restrito external ad_group domain%20users
acl autenticados proxy_auth REQUIRED
http_access deny !autenticados
http_access allow grupo_admins
acl extensoes_bloqueadas url_regex -i "/etc/squid3/acls/extensoes-proibidas"
acl sites_liberados url_regex -i "/etc/squid3/acls/sites-permitidos"
acl sites_bloqueados url_regex -i "/etc/squid3/acls/sites-proibidos"
http_access deny extensoes_bloqueadas
http_access allow sites_liberados
http_access deny sites_bloqueados
http_access allow grupo_liberado
redirect_program /usr/bin/squidGuard
redirect_children 20
redirector_bypass on
http_access allow grupo_restrito
acl lan src 192.168.0.0/22
http_access allow lan
http_access deny all
error_directory /usr/share/squid3/errors/en
coredump_dir /var/spool/squid3

Regards,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151210/4a59c1fc/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 10 09:33:22 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 10 Dec 2015 22:33:22 +1300
Subject: [squid-users] Issues with authentication in Squid3
In-Reply-To: <CA+0TdyoK5WyCYLf8p=78BrwU34f1bgT1hfYRZzJcSSE3MRc0sw@mail.gmail.com>
References: <CA+0TdyoK5WyCYLf8p=78BrwU34f1bgT1hfYRZzJcSSE3MRc0sw@mail.gmail.com>
Message-ID: <566946E2.9090708@treenet.co.nz>

On 10/12/2015 10:24 p.m., Marcio Demetrio Bacci wrote:
> Hi,

Hi Marcio,
 You didn't get any response the last three threads you started about
this in the past few days. Around here that means nobody reading it has
an idea how to solve your problem or even any hints about to to go about
fixing it.

For example, I helped when I could, but you have now moved out of my
knowledge area into LDAP syntax problems.

It might help though if you stuck to one thread and updated it with your
changing experiment results. So anyone coming along in future (with a
fix, or the same issues) has it all in one place to work with and
hopefully followup.

HTH
Amos



From Massimo.Sala at asl.bergamo.it  Thu Dec 10 10:02:49 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 10 Dec 2015 11:02:49 +0100
Subject: [squid-users] squid 3.4, dstdomain
Message-ID: <OF6F535AD9.4E5A92CC-ONC1257F17.0036EA39-C1257F17.00372FA2@asl.bergamo.it>

2015/12/10 10:33:49| ERROR: '.addons.mozilla.org' is a subdomain of 
'addons.mozilla.org'


I thought
        addons.mozilla.org              blocks only these hostname

        .addons.mozilla.org             blocks all the sub-domains, like 
www.addons.mozilla.org etc.addons.mozilla.org


Which are the parsing rules of squid 3.4 ?

Does the first case block also the sub-domains ?


best regards, Sala



From Massimo.Sala at asl.bergamo.it  Thu Dec 10 10:21:39 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 10 Dec 2015 11:21:39 +0100
Subject: [squid-users] delay_pools from 3.1 to 3.4, media content
Message-ID: <OF844F3021.F069C357-ONC1257F17.0038487E-C1257F17.0038E8F8@asl.bergamo.it>

Massimo :
>> acl acl_flussi_media rep_mime_type -i ^audio/
>> acl acl_flussi_media rep_mime_type -i ^video/

>> 2015/12/03 12:38:45 kid1| WARNING: acl_flussi_media ACL is used in 
>> context without an HTTP response. Assuming mismatch.



Amos :
> It means that *reply* header do not work when using *request* to decide
> what delay pool the transaction will use.

> It has never worked. The older Squid just did not tell you about the
> config problem.

> If you want traffic to be re-assigned to pools when the reply happens
> you need to upgrade to at least the Squid-4.0.3 (beta) release.



Amos, many thanks for your answer.


An example of ACLs to catch media content, e.g. :

        acl acl_sites_media dstdomain .ask.fm .facebook.com .fbcdn.net 
.googlevideo.com .youtube.com
        acl acl_types_media urlpath_regex -i \.asf$ \.avi$ \.flv$ \.mkv$ 
\.mov$ \.mp3$ \.mp4$ \.mpeg$ \.mpg$ \.qt$ \.swf$ \.vob$ \.wmv$


1) To apply the two ACLs to the same pool, which is the correct syntax ?

        delay_access 1 allow acl_sites_media
        delay_access 1 allow acl_types_media

or

        delay_access 1 allow acl_sites_media acl_types_media


2)  Can you please add all of these stuff to the official docs ?


best regards, Sala
 
massimo.sala at asl.bergamo.it
Tel. 035/385.034
ASL Provincia di Bergamo | Sistemi Informativi Strategici



From gkinkie at gmail.com  Thu Dec 10 10:27:54 2015
From: gkinkie at gmail.com (Kinkie)
Date: Thu, 10 Dec 2015 11:27:54 +0100
Subject: [squid-users] squid 3.4, dstdomain
In-Reply-To: <OF6F535AD9.4E5A92CC-ONC1257F17.0036EA39-C1257F17.00372FA2@asl.bergamo.it>
References: <OF6F535AD9.4E5A92CC-ONC1257F17.0036EA39-C1257F17.00372FA2@asl.bergamo.it>
Message-ID: <CA+Y8hcOS8Py9P84YA4AvHe9qS60Qo33J-FkO2xHxSSWtdZvM8w@mail.gmail.com>

Hi,
  it works exactly as you expect. "dstdomain addons.mozilla.org" does
not block subdomains.

On Thu, Dec 10, 2015 at 11:02 AM,  <Massimo.Sala at asl.bergamo.it> wrote:
> 2015/12/10 10:33:49| ERROR: '.addons.mozilla.org' is a subdomain of
> 'addons.mozilla.org'
>
>
> I thought
>         addons.mozilla.org              blocks only these hostname
>
>         .addons.mozilla.org             blocks all the sub-domains, like
> www.addons.mozilla.org etc.addons.mozilla.org
>
>
> Which are the parsing rules of squid 3.4 ?
>
> Does the first case block also the sub-domains ?
>
>
> best regards, Sala
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From squid3 at treenet.co.nz  Thu Dec 10 10:34:52 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 10 Dec 2015 23:34:52 +1300
Subject: [squid-users] squid 3.4, dstdomain
In-Reply-To: <OF6F535AD9.4E5A92CC-ONC1257F17.0036EA39-C1257F17.00372FA2@asl.bergamo.it>
References: <OF6F535AD9.4E5A92CC-ONC1257F17.0036EA39-C1257F17.00372FA2@asl.bergamo.it>
Message-ID: <5669554C.3000100@treenet.co.nz>

On 10/12/2015 11:02 p.m., Massimo.Sala wrote:
> 2015/12/10 10:33:49| ERROR: '.addons.mozilla.org' is a subdomain of 
> 'addons.mozilla.org'
> 
> 
> I thought
>         addons.mozilla.org              blocks only these hostname


ACLs do not block anything. Access Controls do.

This value tells Squid that addons.mozilla.org is an exact-match. Any
sub-domain is to be a non-match.


> 
>         .addons.mozilla.org             blocks all the sub-domains, like 
> www.addons.mozilla.org etc.addons.mozilla.org


This one tells Squid that "addons.mozilla.org" and *all* sub-domains are
to match true.


> 
> Which are the parsing rules of squid 3.4 ?

Each entry in the dstdomain ACL must be a unique and distinct match. The
two ranges of possible domain names above overlap.


Squid uses splay trees internally. So when there are two overlapping
entries, which one will be found and tested against will change randomly
based on how other things affect the splay. Which will cause random
rejections for the *.addons.mozilla.org sub-domains.

Thus having both is a problem. Which way around you place them in the
list of ACL values determins whether Squid can drop one (and just warn)
or not (the error).

Amos



From Massimo.Sala at asl.bergamo.it  Thu Dec 10 10:38:17 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 10 Dec 2015 11:38:17 +0100
Subject: [squid-users] delay syntax, speed and network
Message-ID: <OF10FAB157.D3E46FE0-ONC1257F17.00391A1B-C1257F17.003A6EA4@asl.bergamo.it>

1) speed syntax

example :

        delay_parameters 1 -1/-1 1280000/1280000 128000/128000


The speed is bytes / sec.

Is it possible to use multipliers like K and M ?

Is it possible to use units, like bps ( bit per sec ) ?


It is wonderfoul to read :

        delay_parameters 1 -1/-1 10Mbps/10Mbps 1Mbps/1Mbps



2) network

We have about 50 subnets, on different locations.

It is a "hub" topology : all the subnets are linked via WANs to our 
central location, where there is the IT centre.

>From the IT centre we have the links to Internet, and the proxy server 
running squid ( forwarding, IT manager decision ).


Our internal IP addressing is 10.0.0.0/8

10.1.0.0 for the first site, 10.2.0.0 the 2nd, etc ...


Goals :

        overall proxy bandwidth limit : none
        each site limit : 10 Mbps
        each pc client limit : 1 Mbps


My work-around is this, using class 3 for /16 networks :

        delay_class 1 3
        delay_parameters 1 -1/-1 1280000/1280000 128000/128000

but it is a "fuzzy" fitting : each remote site is seen by squid as N 
smaller networks, so the overall site limit is N * 10 Mbps ...


Is it possible to match my goals ?

Or I request a new class, where we can specify the netmask.


best regards, Sala 
massimo.sala at asl.bergamo.it
Tel. 035/385.034
ASL Provincia di Bergamo | Sistemi Informativi Strategici



From Massimo.Sala at asl.bergamo.it  Thu Dec 10 10:43:55 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 10 Dec 2015 11:43:55 +0100
Subject: [squid-users] squid 3.4, dstdomain
In-Reply-To: <CA+Y8hcOS8Py9P84YA4AvHe9qS60Qo33J-FkO2xHxSSWtdZvM8w@mail.gmail.com>
Message-ID: <OF5E22BFB1.E2E007BE-ONC1257F17.003ACB73-C1257F17.003AF2F0@asl.bergamo.it>

Massimo
> 2015/12/10 10:33:49| ERROR: '.addons.mozilla.org' is a subdomain of
> 'addons.mozilla.org'


Kinkie :
>  it works exactly as you expect. "dstdomain addons.mozilla.org" does
> not block subdomains.



So why doesn't squid accept both rules ? a parsing bug ?

best regards, Massimo



From squid3 at treenet.co.nz  Thu Dec 10 11:02:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 11 Dec 2015 00:02:46 +1300
Subject: [squid-users] delay_pools from 3.1 to 3.4, media content
In-Reply-To: <OF844F3021.F069C357-ONC1257F17.0038487E-C1257F17.0038E8F8@asl.bergamo.it>
References: <OF844F3021.F069C357-ONC1257F17.0038487E-C1257F17.0038E8F8@asl.bergamo.it>
Message-ID: <56695BD6.8000306@treenet.co.nz>

On 10/12/2015 11:21 p.m., Massimo.Sala at asl.bergamo.it wrote:
> Massimo :
>>> acl acl_flussi_media rep_mime_type -i ^audio/
>>> acl acl_flussi_media rep_mime_type -i ^video/
> 
>>> 2015/12/03 12:38:45 kid1| WARNING: acl_flussi_media ACL is used in 
>>> context without an HTTP response. Assuming mismatch.
> 
> 
> 
> Amos :
>> It means that *reply* header do not work when using *request* to decide
>> what delay pool the transaction will use.
> 
>> It has never worked. The older Squid just did not tell you about the
>> config problem.
> 
>> If you want traffic to be re-assigned to pools when the reply happens
>> you need to upgrade to at least the Squid-4.0.3 (beta) release.
> 
> 
> 
> Amos, many thanks for your answer.
> 
> 
> An example of ACLs to catch media content, e.g. :
> 
>         acl acl_sites_media dstdomain .ask.fm .facebook.com .fbcdn.net 
> .googlevideo.com .youtube.com
>         acl acl_types_media urlpath_regex -i \.asf$ \.avi$ \.flv$ \.mkv$ 
> \.mov$ \.mp3$ \.mp4$ \.mpeg$ \.mpg$ \.qt$ \.swf$ \.vob$ \.wmv$
> 

Both of those match against parts of the request message URL. Which is
fine for delay_access.

Be aware that neither of those matches the real content type.

Your config used to have a rep_mime_type ACL trying to check reply
header value. Which is the correct way to match mime / content type. It
just happens to be data only available after the reply has started
happening.

  acl acl_flussi_media rep_mime_type -i ^audio/
  acl acl_flussi_media rep_mime_type -i ^video/


> 
> 1) To apply the two ACLs to the same pool, which is the correct syntax ?
> 
>         delay_access 1 allow acl_sites_media
>         delay_access 1 allow acl_types_media
> 
> or
> 
>         delay_access 1 allow acl_sites_media acl_types_media
> 

Both and neither. "correct" depends on what your local administrative
policy is.


> 
> 2)  Can you please add all of these stuff to the official docs ?

Where exactly did you look in the documentation? We dont have anything
provided by the Squid Project mentioning how to use delay pools for mime
content delaying. Specifically because it has not been possible to do
until very recently.


<http://www.squid-cache.org/Doc/config/delay_access/>
 "This is used to determine which delay pool a request falls into."

 Note the use of *request*.

<http://ww.squid-cache.org/Doc/config/acl/>
"
	acl aclname rep_mime_type [-i] mime-type ...
	  # regex match against the mime type of the reply received by
	  # squid. Can be used to detect file download or some
	  # types HTTP tunneling requests. [fast]
	  # NOTE: This has no effect in http_access rules. It only has
	  # effect in rules that affect the reply data stream such as
	  # http_reply_access.
"

Note the repeated used of *reply*. And the extra notice about usage only
with reply related rules (unlike delay_access).

It should be obvious at least from the second that the first is not
somewhere it will be useful.

Amos



From dweimer at dweimer.net  Thu Dec 10 12:44:46 2015
From: dweimer at dweimer.net (dweimer)
Date: Thu, 10 Dec 2015 06:44:46 -0600
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
Message-ID: <6ede17791f7541fa080516d4ac0461cf@dweimer.net>

On 2015-12-09 11:29 pm, Alex Samad wrote:
> Hi
> 
> config
> https_port 22.4.2.5:443 accel
> cert=/etc/httpd/conf.d/office.abc.com.crt
> key=/etc/httpd/conf.d/office.abc.com.key defaultsite=office.abc.com
> options=NO_SSLv2,NO_SSLv3
> dhparams=/etc/squid/squid-office-dhparams.pem
> cipher=ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA
> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
> sslcert=/etc/httpd/conf.d/office.abc.com.crt
> sslkey=/etc/httpd/conf.d/office.abc.com.key name=webServer
> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
> originserver login=PASS front-end-https=on ssl
> sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.abc.com.crt
> sslkey=/etc/httpd/conf.d/office.abc.com.key name=exchangeServer
> acl exch_domain dstdomain office.abc.com
> acl exch_path urlpath_regex -i /exch(ange|web)
> acl exch_path urlpath_regex -i /public
> acl exch_path urlpath_regex -i /owa
> acl exch_path urlpath_regex -i /ecp
> acl exch_path urlpath_regex -i /microsoft-server-activesync
> acl exch_path urlpath_regex -i /rpc
> acl exch_path urlpath_regex -i /rpcwithcert
> acl exch_path urlpath_regex -i /exadmin
> acl exch_path urlpath_regex -i /ews
> acl exch_path urlpath_regex -i /oab
> acl exch_path urlpath_regex -i /autodiscover
> cache_peer_access exchangeServer allow exch_domain exch_path
> cache_peer_access webServer deny exch_domain exch_path
> never_direct allow exch_domain exch_path
> cache_mem 32 MB
> maximum_object_size_in_memory 128 KB
> access_log stdio:/var/log/squid/office-access.log squid
> cache_log /var/log/squid/office-cache.log
> cache_store_log stdio:/var/log/squid/office-cache_store.log
> pid_filename /var/run/squid-office.pid
> visible_hostname office.abc.com
> deny_info TCP_RESET all
> http_access allow all
> miss_access allow all
> icp_port 0
> snmp_port 0
> 
> 
> 
> cache.log
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Process ID 5631
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Process Roles: worker
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| With 1024 file descriptors 
> available
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Initializing IP Cache...
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| DNS Socket created at 
> 0.0.0.0, FD 6
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding domain
> yieldbroker.com from /etc/resolv.conf
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding nameserver
> 10.32.20.100 from /etc/resolv.conf
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding nameserver
> 10.32.20.102 from /etc/resolv.conf
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Logfile: opening log
> stdio:/var/log/squid/office-access.log
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Local cache digest enabled;
> rebuild/rewrite every 3600/3600 sec
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Logfile: opening log
> stdio:/var/log/squid/office-cache_store.log
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Swap maxSize 0 + 32768 KB,
> estimated 2520 objects
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Target number of buckets: 126
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Using 8192 Store buckets
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Max Mem  size: 32768 KB
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Max Swap size: 0 KB
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Using Least Load store dir 
> selection
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Current Directory is 
> /etc/squid
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Finished loading MIME types 
> and icons.
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| HTCP Disabled.
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Configuring Parent 
> 127.0.0.1/443/0
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Configuring Parent 
> 10.32.69.11/443/0
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Squid plugin modules loaded: 
> 0
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adaptation support is off.
> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Accepting reverse-proxy
> HTTPS Socket connections at local=202.74.32.15:443 remote=[::] FD 11
> flags=9
> Jan 01 10:33:35 1970/12/10 16:15:43 kid1| storeLateRelease: released 0 
> objects
> 
> 
> cache log
> Dec 10 16:16:23 2015.225 RELEASE -1 FFFFFFFF
> BE6736C8CD1A74A54575AF9880395D04   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:34 2015.287 RELEASE -1 FFFFFFFF
> 78C390A2D412F8E601035A2C1FD771C8   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:34 2015.296 RELEASE -1 FFFFFFFF
> A7D8B3751858C54225D29408B56FE42D   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:37 2015.863 RELEASE -1 FFFFFFFF
> 35992070307CD15EE743F71344E1C1AE   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:37 2015.873 RELEASE -1 FFFFFFFF
> 17EFD3BCAF4265B7CF7803AD0289DD7E   ?         ?         ?         ? ?/?
> ?/? ? ?
> Dec 10 16:16:49 2015.228 RELEASE -1 FFFFFFFF
> 2666EC9714425D57FDC4CD15965D350B   ?         ?         ?         ? ?/?
> ?/? ? ?
> 
> 
> 
> access.logs
> Dec 10 16:17:09 2015.706     13 192.168.56.1 TCP_MISS/200 6578 POST
> https://office.abc.com/ews/exchange.asmx - FIRSTUP_PARENT/10.32.69.11
> text/xml
> Dec 10 16:19:36 2015.447 206818 192.168.56.1 TCP_MISS/200 16532
> RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 application/rpc
> Dec 10 16:19:36 2015.449 206862 192.168.56.1 TCP_MISS_ABORTED/502 4493
> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 text/html
> Dec 10 16:19:36 2015.453 207197 192.168.56.1 TCP_MISS_ABORTED/000 0
> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 -
> Dec 10 16:19:36 2015.453 207087 192.168.56.1 TCP_MISS_ABORTED/200
> 48056 RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 application/rpc
> Dec 10 16:20:07 2015.305  24688 192.168.56.1 TCP_MISS_ABORTED/000 0
> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 -
> Dec 10 16:20:07 2015.306  24654 192.168.56.1 TCP_MISS_ABORTED/200 2004
> RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
> FIRSTUP_PARENT/10.32.69.11 application/rpc
> 
> 
> This is when I try and send an email with an attachment. An email with
> no attached goes through no problem...
> 
> 
> this config works with 3.1, not with 3.5 ..
> 
> still on .11 as I can't find centos 6 compile of .12
> 
> I think there is some issue with rpc sending or receiving ..
> 
> On 8 December 2015 at 19:34, Amos Jeffries <squid3 at treenet.co.nz> 
> wrote:
>> On 8/12/2015 7:35 p.m., Alex Samad wrote:
>>> Hi
>>> 
>>> Any suggestions on how to debug this... I wouldn't mind rolling
>>> forward to 3.5 again
>>> 
>> 
>> Some ideas inline. The main ones are:
>> 
>> * re-enable cache.log. It is not optional.
>> 
>> * try an upgrade to 3.5.12. There were some regressions in the .10/.11
>> releases that can lead to really weird behaviour.
>> 
>> 
>>> On 2 December 2015 at 20:39, Alex Samad wrote:
>>>> Just to add to this I have a lot of these in the log file
>>>> 
>>>> TCP_MISS_ABORTED/000 0 RPC_IN_DATA
>>>> TCP_MISS_ABORTED/200 4322 RPC_OUT_DATA
>>>> TCP_MISS_ABORTED/000 0 RPC_IN_DATA https:
>>>> 
>>>> 
>>>> 
>>>> On 2 December 2015 at 17:24, Alex Samad wrote:
>>>>> Hi
>>>>> 
>>>>> recently upgraded to squid-3.5.11-1.el6.x86_64 from the centos 6.7  
>>>>> squid 3.1
>>>>> 
>>>>> 
>>>>> I am now having problems with people who use active sync via this
>>>>> connection . seems like emails with attachments aren't making it
>>>>> through .
>>>>> 
>>>>> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
>>>>> originserver login=PASS front-end-https=on ssl
>>>>> sslflags=DONT_VERIFY_PEER 
>>>>> sslcert=/etc/httpd/conf.d/office.yx.com.crt
>>>>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=exchangeServer
>> 
>> You could try changing these from login=PASS to login=PASSTHRU
>> 
>>>>> 
>>>>> 
>>>>> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
>>>>> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
>>>>> sslcert=/etc/httpd/conf.d/office.yx.com.crt
>>>>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=webServer
>>>>> c
>>>>> 
>>>>> # List of acceptable URLs to send to the Exchange server
>>>>> acl exch_url url_regex -i office.yieldbroker.com/exchange
>>>>> acl exch_url url_regex -i office.yieldbroker.com/exchweb
>>>>> acl exch_url url_regex -i office.yieldbroker.com/public
>>>>> acl exch_url url_regex -i office.yieldbroker.com/owa
>>>>> acl exch_url url_regex -i office.yieldbroker.com/ecp
>>>>> acl exch_url url_regex -i 
>>>>> office.yieldbroker.com/microsoft-server-activesync
>>>>> acl exch_url url_regex -i office.yieldbroker.com/rpc
>>>>> acl exch_url url_regex -i office.yieldbroker.com/rpcwithcert
>>>>> acl exch_url url_regex -i office.yieldbroker.com/exadmin
>>>>> acl exch_url url_regex -i office.yieldbroker.com/oab
>>>>> # added after
>>>>> acl exch_url url_regex -i office.yieldbroker.com/ews
>>>>> # Not configured on exchange 2010
>>>>> #acl exch_url url_regex -i office.yieldbroker.com/autodiscover
>>>>> 
>>>>> # Send the Exchange URLs to the Exchange server
>>>>> cache_peer_access exchangeServer allow exch_url
>>>>> 
>>>>> # Send everything else to the Apache
>>>>> cache_peer_access webServer deny exch_url
>>>>> 
>>>>> # This is to protect Squid
>>>>> never_direct allow exch_url
>>>>> 
>>>>> # Logging Configuration
>>>>> redirect_rewrites_host_header off
>>>>> cache_mem 32 MB
>>>>> maximum_object_size_in_memory 128 KB
>>>>> cache_log none
>> 
>> You should re-enable cache.log and fix any of the issues that are 
>> logged
>> there.
>> 
>> 
>>>>> cache_store_log none
>>>>> 
>>>>> access_log stdio:/var/log/squid/office-access.log squid
>>>>> #access_log none
>>>>> cache_log /var/log/squid/office-cache.log
>>>>> #cache_log none
>>>>> pid_filename /var/run/squid-office.pid
>>>>> 
>>>>> 
>>>>> # Set the hostname so that we can see Squid in the path (Optional)
>>>>> visible_hostname yieldbroker.com
>>>>> deny_info TCP_RESET all
>> 
>> This could lead to strange behaviour. Particularly since "deny all" is
>> not being used in your http_access rules ...
>> 
>> 
>>>>> 
>>>>> # Allow everyone through, internal and external connections
>>>>> http_access allow all
>>>>> miss_access allow all
>>>>> 
>>>>> icp_port 0
>>>>> snmp_port 0
>>>>> 
>>>>> via off
>>>>> 
>>>>> 
>>>>> The previous setup had worked for at least 18 months.
>>>>> 
>>>>> Alex

On our Reverse proxy I ran into an issue uploading attachments to 
Exchange back end, a while back, turned out the solution was to lock it 
down so that the proxy only used ssl version 3 to connect to the 
Exchange server. This however did recently break after a windows update 
in Novemeber. Further investigation led to the particular cipher that 
was in use. After discovering this I was able to use the same cipher 
with TLSv1.0

Currently I am using TLSv1.0 with RC4-SHA cipher to talk to the Exchange 
server.

cache_peer 10.20.10.161 parent 443 0 ssl no-query proxy-only no-digest 
originserver \
  name=owa2010_parent sslcapath=/usr/local/share/certs 
sslflags=DONT_VERIFY_PEER  \
  login=PASSTHRU front-end-https=on connection-auth=on sslcipher=RC4-SHA 
sslversion=4

I am not however locking down the incoming connections to this setting, 
I am using the following for the https_port setting. This does pass PCI 
scans, in case anyone is wondering about the choice of cipher options, 
and you will notice the RC4 used to send traffic between the Proxy and 
Exchange is disabled as that doesn't meet current requirements.

https_port 10.50.20.12:443 accel defaultsite=mail.mydomain.com \
  cert=/certs/wildcard.certificate.crt \
  key=/certs/wildcard.certificate.key \
  
options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE 
\
  dhparams=/usr/local/etc/squid/dh.param \
  cipher=ALL:!aNULL:!eNULL:!LOW:!EXP:!ADH:+HIGH:+MEDIUM:!SSLv2:!RC4 \
  vhost


-- 
Thanks,
    Dean E. Weimer
    http://www.dweimer.net/


From gkinkie at gmail.com  Thu Dec 10 13:50:38 2015
From: gkinkie at gmail.com (Kinkie)
Date: Thu, 10 Dec 2015 14:50:38 +0100
Subject: [squid-users] squid 3.4, dstdomain
In-Reply-To: <OF5E22BFB1.E2E007BE-ONC1257F17.003ACB73-C1257F17.003AF2F0@asl.bergamo.it>
References: <CA+Y8hcOS8Py9P84YA4AvHe9qS60Qo33J-FkO2xHxSSWtdZvM8w@mail.gmail.com>
 <OF5E22BFB1.E2E007BE-ONC1257F17.003ACB73-C1257F17.003AF2F0@asl.bergamo.it>
Message-ID: <CA+Y8hcOyO6L7ex8ipVkGZ-Qi7+gjm4s3s6SHTLyhNjeeYtvpFA@mail.gmail.com>

On Thu, Dec 10, 2015 at 11:43 AM,  <Massimo.Sala at asl.bergamo.it> wrote:
> Massimo
>> 2015/12/10 10:33:49| ERROR: '.addons.mozilla.org' is a subdomain of
>> 'addons.mozilla.org'
>
>
> Kinkie :
>>  it works exactly as you expect. "dstdomain addons.mozilla.org" does
>> not block subdomains.
>
>
>
> So why doesn't squid accept both rules ? a parsing bug ?


No bug, it is really intentional: ".addons.mozilla.org" also matches
"addons.mozilla.org" (without the dot). Therefore the latter is
rejected to keep the internal data structures consistent.


-- 
    Francesco


From magiclink at outlook.com  Thu Dec 10 13:56:58 2015
From: magiclink at outlook.com (Magic Link)
Date: Thu, 10 Dec 2015 14:56:58 +0100
Subject: [squid-users] issue with video
In-Reply-To: <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>,
 <5668B48C.703@treenet.co.nz>, <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>
Message-ID: <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl>

Where can i upload my logs ? It's too big for the mail.

From: magiclink at outlook.com
To: squid3 at treenet.co.nz; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] issue with video
Date: Thu, 10 Dec 2015 11:29:42 +0100




I activated the debug_option. I don't see anything particular in access.log, but i don't know what to do with the content of cache.logI 'v never compiled squid, is there a tutorial ? I used to use the debian stable repository, but get only the 3.4.8 version for debian 8 (i can try with testing repository or another one if so)

Thanks
> To: squid-users at lists.squid-cache.org
> From: squid3 at treenet.co.nz
> Date: Thu, 10 Dec 2015 12:09:00 +1300
> Subject: Re: [squid-users] issue with video
> 
> On 10/12/2015 3:42 a.m., Magic Link wrote:
> > Hi,
> > i have a problem with this video http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/ This video doesn't start with squid (3.4.8) on Debian 8 but does with a direct access to Internet.I don't know how to debug this issue.
> > Any clues ? Thanks 		 	   		  
> > 
> 
> Check cache.log to see if any errors are being logged when you request it.
> 
> Check access.log to see if the proxy is actually being contacted to
> fetch the video.
> 
> "debug_options 11,2" to see what the request and reply headers are.
> 
> If you can, try an upgrade. Current Squid is 3.5.12. I'm just mentioning
> this because its the nromal debugging step. I dont recommend a
> cross-install of the 3.5.12 package to Debian 8 - it needs a proper
> backport / recompile.
> 
> The remaining steps get trickier and depend on the results of the above
> checks, or whether
> 
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
 		 	   		   		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151210/98951293/attachment.htm>

From yvoinov at gmail.com  Thu Dec 10 15:25:46 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 10 Dec 2015 21:25:46 +0600
Subject: [squid-users] issue with video
In-Reply-To: <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>
 <5668B48C.703@treenet.co.nz> <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>
 <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl>
Message-ID: <5669997A.70209@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
tar -cvf logs.tar access.log cache.log; gzip -9 logs.tar ->
http://drive.google.com -> sahre+post URL's

10.12.15 19:56, Magic Link ?????:
> Where can i upload my logs ? It's too big for the mail.
>
> From: magiclink at outlook.com
> To: squid3 at treenet.co.nz; squid-users at lists.squid-cache.org
> Subject: RE: [squid-users] issue with video
> Date: Thu, 10 Dec 2015 11:29:42 +0100
>
>
>
>
> I activated the debug_option. I don't see anything particular in
access.log, but i don't know what to do with the content of cache.logI
'v never compiled squid, is there a tutorial ? I used to use the debian
stable repository, but get only the 3.4.8 version for debian 8 (i can
try with testing repository or another one if so)
>
> Thanks
>> To: squid-users at lists.squid-cache.org
>> From: squid3 at treenet.co.nz
>> Date: Thu, 10 Dec 2015 12:09:00 +1300
>> Subject: Re: [squid-users] issue with video
>>
>> On 10/12/2015 3:42 a.m., Magic Link wrote:
>>> Hi,
>>> i have a problem with this video
http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/ This
video doesn't start with squid (3.4.8) on Debian 8 but does with a
direct access to Internet.I don't know how to debug this issue.
>>> Any clues ? Thanks                          
>>>
>>
>> Check cache.log to see if any errors are being logged when you
request it.
>>
>> Check access.log to see if the proxy is actually being contacted to
>> fetch the video.
>>
>> "debug_options 11,2" to see what the request and reply headers are.
>>
>> If you can, try an upgrade. Current Squid is 3.5.12. I'm just mentioning
>> this because its the nromal debugging step. I dont recommend a
>> cross-install of the 3.5.12 package to Debian 8 - it needs a proper
>> backport / recompile.
>>
>> The remaining steps get trickier and depend on the results of the above
>> checks, or whether
>>
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>                                                      
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWaZl6AAoJENNXIZxhPexGGe4IAILsG3rcB+8WN0bn5++RHUie
ts4SNFYvOgmDt48xfy1uOzpjUbDmdE7mWlYKsyJ7rVQq44KmsnxJXQVVC3xYaERl
huvisfIIgIn+eGmdMmyQ07Vr0mN6f5bX1n7FiKI63/l0/7mD7EKgWmuiw1ISRuQ3
FhUkpxNAowJ9uC3Rf03sborivigriR+WzjKyBlQWbqI9rHSoEZm/6JTmyTXmGX7y
LjPejC1uaAK2VLyzGGCZPtABGZEpKP2XYnd0m6NWonhGhG2cFaA0zHQLE0BMMWRv
sVoiqL/X3GqB5Zf8fYBx+Ulhk+gBff+gpRvkv4GT7J3bB/ploGPdtiJL9hhPQBM=
=E3Ow
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151210/6d4f7afe/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 10 15:26:27 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 11 Dec 2015 04:26:27 +1300
Subject: [squid-users] delay syntax, speed and network
In-Reply-To: <OF10FAB157.D3E46FE0-ONC1257F17.00391A1B-C1257F17.003A6EA4@asl.bergamo.it>
References: <OF10FAB157.D3E46FE0-ONC1257F17.00391A1B-C1257F17.003A6EA4@asl.bergamo.it>
Message-ID: <566999A3.5000402@treenet.co.nz>

On 10/12/2015 11:38 p.m., Massimo.Sala wrote:
> 1) speed syntax
> 
> example :
> 
>         delay_parameters 1 -1/-1 1280000/1280000 128000/128000
> 
> 
> The speed is bytes / sec.
> 
> Is it possible to use multipliers like K and M ?
> 

No.

> Is it possible to use units, like bps ( bit per sec ) ?
> 

No.

> 
> It is wonderfoul to read :
> 
>         delay_parameters 1 -1/-1 10Mbps/10Mbps 1Mbps/1Mbps
> 

That does look nice. If only that had any relation to what the delay
pool values mean.


Taking the 10MB one for an example. Translating it to the units as
defined would be: 10Mbps/10Mb


BUT, that the "bps" part is *not* the speed limit the client will go. It
is the speed the client gains more traffic capacity.

The correct units to represent this as a speed in metric is:
   10MBpsps/10MBps

If one were to write 1Mbps/10Mb for example, that client would be able
to go up to 10Mbps. Quite non-intuitive to what you would expect a
number saying "1Mbps" would do.

However that is the burst limit, so on *average* you would see them
going 1Mbps. Emphasis on average. For every second they go under 1Mbps
they are permitted an equal amount *over* 1Mbps, with an peak (burst)
speed of 10Mbps.




> 
> 2) network
> 
> We have about 50 subnets, on different locations.
> 
> It is a "hub" topology : all the subnets are linked via WANs to our 
> central location, where there is the IT centre.
> 
> From the IT centre we have the links to Internet, and the proxy server 
> running squid ( forwarding, IT manager decision ).
> 
> 
> Our internal IP addressing is 10.0.0.0/8
> 
> 10.1.0.0 for the first site, 10.2.0.0 the 2nd, etc ...
> 
> 
> Goals :
> 
>         overall proxy bandwidth limit : none
>         each site limit : 10 Mbps
>         each pc client limit : 1 Mbps
> 
> 
> My work-around is this, using class 3 for /16 networks :
> 
>         delay_class 1 3
>         delay_parameters 1 -1/-1 1280000/1280000 128000/128000
> 
> but it is a "fuzzy" fitting : each remote site is seen by squid as N 
> smaller networks, so the overall site limit is N * 10 Mbps ...
> 
> 
> Is it possible to match my goals ?

Using a class 5 pool and an externl_acl_type helper to classify each
request as to what site it is coming from and assign a unique tag=site
to each request.

However, you might as well use the tag= site classification to determine
a tcp_outgoing_tos/mark value to send to the underlying system QoS
functionality.

Delay pools is 1980's technology (as you might see from the fact that a
/16 is considered big enough to represent an entire network, lol).
Modern QoS can do a lot of things far better than Squid delay pools. Not
least of which is to add in all the non-HTTP traffic that goes nowhere
near Squid to the sites traffic speed accounting.


> 
> Or I request a new class, where we can specify the netmask.
> 

If you wish to supply a patch it will be considered. However, be aware
that delay pools is a very ancient and broken feature. I am wanting to
deprecate and remove it as soon as people will stop using it.

Amos


From eliezer at ngtech.co.il  Thu Dec 10 17:32:21 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 10 Dec 2015 19:32:21 +0200
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PUBccbhFZDrg4C8O_rpN6_+tRsK-HVM1UyY_72ZMBzimg@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PUBccbhFZDrg4C8O_rpN6_+tRsK-HVM1UyY_72ZMBzimg@mail.gmail.com>
Message-ID: <5669B725.1080504@ngtech.co.il>

On 09/12/2015 12:49, Alex Samad wrote:
> Hi
>
> Can't seem to find  3.5.12 for centos pre compiled at
> http://www1.ngtech.co.il/repo/centos/6/x86_64/
Since it's in testing....
I have built and tested for CentOS 7 but yet to publish them.
It will take a week or more.

Eliezer


From tomtux007 at gmail.com  Thu Dec 10 20:10:48 2015
From: tomtux007 at gmail.com (Tom Tom)
Date: Thu, 10 Dec 2015 21:10:48 +0100
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <5665FA59.5010506@measurement-factory.com>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz>
 <5661BC23.7040109@measurement-factory.com>
 <20151207113746.GK12890@charite.de>
 <56659FA3.9000404@measurement-factory.com>
 <CACLJR+PNpWzh=uU-qBNsbk7xVsvcq1Ve9cpb_tu1gUsFGH1qZA@mail.gmail.com>
 <5665FA59.5010506@measurement-factory.com>
Message-ID: <CACLJR+NE-T1SkFMhoUFj8xJb9iDOrR_xooOY44J2b1+zgNxjmQ@mail.gmail.com>

Hi Alex

I've tested again. Squid (3.5.11) only terminates the connection
(based on SHA1-Fingerprint), *if* the fingerprint is delimited with
colons. If not, squid GET's the https-request as usual. I'll report a
bug.

With SHA1-FP (delimited):
41:30:72:F8:03:CE:96:12:10:E9:A4:5D:10:DA:14:B0:D2:D4:85:32 in the
config-file, Squid terminates the connection as expected:
$ curl -x proxy:3128 -I -k -L https://www.yahoo.com
HTTP/1.1 200 Connection established
curl: (35) Unknown SSL protocol error in connection to www.yahoo.com:443


With SHA1-FP (not delimited): 413072F803CE961210E9A45D10DA14B0D2D48532
in the config-file, squid GET's the site:
$ curl -x proxy:3128 -I -k -L https://www.yahoo.com
HTTP/1.1 200 Connection established

HTTP/1.1 200 OK
Date: Thu, 10 Dec 2015 20:06:11 GMT
P3P: policyref="http://info.yahoo.com/w3c/p3p.xml", CP="CAO DSP COR
CUR ADM DEV TAI PSA PSD IVAi IVDi CONi TELo OTPi OUR DELi SAMi OTRi
UNRi PUBi IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE
LOC GOV"
X-Frame-Options: DENY
Strict-Transport-Security: max-age=2592000
...
....

Kind regards,
Tom

On Mon, Dec 7, 2015 at 10:30 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 12/07/2015 02:05 PM, Tom Tom wrote:
>> The configuration provided by Alex works for me (squid 3.5.11)
>
> Thank you for testing and helping expose problems.
>
>
>> if:
>> * the http_port-directive is configured with ssl-bump and a
>> certificate (ex. http_port 3128 ssl-bump generate-host-certificates=on
>> dynamic_cert_mem_cache_size=4MB cert=/usr/local/certs/myCA.pem)
>
> ssl-bump is required to access SSL/TLS peeking code. Now way around that
> today although future Squid versions may provide something like an
> ssl-peek port option that tells Squid that no bumping, for any reason
> (including error serving) is permitted on that port.
>
> Specifying root CA is required to serve certificate validation (and
> other) errors, but we probably should be more flexible and allow no-CA
> splice-or-terminate configurations as well.
>
> Related enhancement requests in bugzilla are welcomed, especially if
> they are followed by quality patches.
>
>
>> * the SHA1-fingerprint in the file SSL_BLACKLISTS is delimited after
>> two characters with a colon
>> (9E:C8:15:3F:27:C9:B5:BA:B9:17:49:C8:0A:D7:DF:21:D3:8C:80:50 for
>> ar***krebs.de)
>
> If Squid silently misinterprets colon-less fingerprints, it is a bug
> that should be reported and fixed. Squid should either interpret them
> correctly or exit with a configuration error.
>
>
> Thank you,
>
> Alex.
>
>
>
>> On Mon, Dec 7, 2015 at 4:02 PM, Alex Rousskov
>> <rousskov at measurement-factory.com> wrote:
>>> On 12/07/2015 04:37 AM, Ralf Hildebrandt wrote:
>>>> * Alex Rousskov <rousskov at measurement-factory.com>:
>>>>> Please note that if you do not want to bump anything, then the following
>>>>> should also work (bugs notwithstanding):
>>>>>
>>>>>     ssl_bump splice whitelist
>>>>>     ssl_bump peek all
>>>>>     ssl_bump terminate blacklist
>>>>>     ssl_bump splice all
>>>>
>>>> That doesn't seem to work for me (squid 3.5.2)
>>>
>>>> Yet I still can connect. What am I doing wrong?
>>>
>>> If you are indeed using v3.5.2, then that is a big red flag.
>>>
>>> If you are using the latest v3.5 release, then you should open a bug
>>> report, preferably with an ALL,9 log depicting a single failing
>>> transaction. AFAICT, the above is meant to work. If it does not, there
>>> is either a Squid bug or misconfiguration [that I cannot detect by
>>> reading email].
>>>
>>>
>>> Thank you,
>>>
>>> Alex.
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>


From alex at samad.com.au  Thu Dec 10 20:11:12 2015
From: alex at samad.com.au (Alex Samad)
Date: Fri, 11 Dec 2015 07:11:12 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <5669B725.1080504@ngtech.co.il>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PUBccbhFZDrg4C8O_rpN6_+tRsK-HVM1UyY_72ZMBzimg@mail.gmail.com>
 <5669B725.1080504@ngtech.co.il>
Message-ID: <CAJ+Q1PUzMi7mORqv76zubuNexD65cE3s_xfmLpojDTP4P9eYhg@mail.gmail.com>

Thanxs everyone i will try the changes and try with the debug options

Tls1 might be an issue. Might have to look at the ssl offloading config  so
squid  to exchange can be http instead of ssl....

Eliezer hopefuly you'll do a centos 6. Any chance you can let me have a non
released .12  save me trying to build one.
A
On 11/12/2015 4:32 AM, "Eliezer Croitoru" <eliezer at ngtech.co.il> wrote:

> On 09/12/2015 12:49, Alex Samad wrote:
>
>> Hi
>>
>> Can't seem to find  3.5.12 for centos pre compiled at
>> http://www1.ngtech.co.il/repo/centos/6/x86_64/
>>
> Since it's in testing....
> I have built and tested for CentOS 7 but yet to publish them.
> It will take a week or more.
>
> Eliezer
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/1846d75e/attachment.htm>

From juanchorevolution at hotmail.com  Thu Dec 10 20:27:58 2015
From: juanchorevolution at hotmail.com (juancho Alfonso)
Date: Thu, 10 Dec 2015 15:27:58 -0500
Subject: [squid-users] help change cache dir
Message-ID: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>

Hey thereI have installed CentOS squid in 7I want to change the cache directory
appears when I try to initialize
Creating Swap Directories
FATAL: Failed to make directory swap mydirectory / cache / 00:
     (13) Permission denied
directory is an external drive or a folder on the same partitionand I granted permissions
chmod 777 cacheorchmod cache squid.squid
no worksI need help to put more capacity more directories



the squid.conf
## Recommended minimum configuration:#
# Example rule allowing access from your local networks.# Adapt to list your (internal) IP networks from where browsing# should be allowedacl localnet src 10.0.0.0/8 # RFC1918 possible internal networkacl localnet src 172.16.0.0/12 # RFC1918 possible internal networkacl localnet src 192.168.0.0/16 # RFC1918 possible internal networkacl localnet src fc00::/7 # RFC 4193 local private network rangeacl localnet src fe80::/10 # RFC 4291 link-local (directly plugged) machines
acl SSL_ports port 443acl Safe_ports port 80 # httpacl Safe_ports port 21 # ftpacl Safe_ports port 443 # httpsacl Safe_ports port 70 # gopheracl Safe_ports port 210 # waisacl Safe_ports port 1025-65535 # unregistered portsacl Safe_ports port 280 # http-mgmtacl Safe_ports port 488 # gss-httpacl Safe_ports port 591 # filemakeracl Safe_ports port 777 # multiling httpacl CONNECT method CONNECTacl PAGINASBLOQUEADAS url_regex -i porno abcde
## Recommended minimum Access Permission configuration:## Deny requests to certain unsafe portshttp_access deny PAGINASBLOQUEADAS
# Deny CONNECT to other than secure SSL portshttp_access deny !Safe_ports
# Only allow cachemgr access from localhosthttp_access deny CONNECT !SSL_portshttp_access allow localhost manager
# We strongly recommend the following be uncommented to protect innocent# web applications running on the proxy server who think the only# one who can access services on "localhost" is a local user#http_access deny to_localhost
## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS#
# Example rule allowing access from your local networks.# Adapt localnet in the ACL section to list your (internal) IP networks# from where browsing should be allowedhttp_access allow managerhttp_access allow localnet
# And finally deny all other access to this proxyhttp_access allow localhosthttp_access allow all
# Squid normally listens to port 3128http_port 3128 transparent
# Uncomment and adjust the following to add a disk cache directory.
# Leave coredumps in the first cache dircoredump_dir /var/spool/squid
## Add any of your own refresh_pattern entries above these.#refresh_pattern ^ftp:		1440	20%	10080refresh_pattern ^gopher:	1440	0%	1440refresh_pattern -i (/cgi-bin/|\?) 0	0%	0refresh_pattern .		0	20%	4320


#juancache_mem 16384 MB#cache_replacement_policy heap LFUDA #El par?metro maximum_object_size define el tama?o m?ximo de los objetos que ser?n almacenados en el cache de discomaximum_object_size 200 MBcache_swap_low 90cache_swap_high 95#correo del administrador del cachecache_mgr ingenieria at conexiondigital.cocachemgr_passwd cache all
#this workcache_dir aufs /var/spool/squid 40000 16 256 #this no workcache_dir aufs /var/spool/squid2 40000 16 256 
cache_effective_user squidcache_effective_group squid



Juan Ernesto Alfonsoestudiante ingenier?a electr?nicauniversidad distrital Francisco Jos? de Caldas
JUANCHO
 NEMESIS 
KRAVEN

" si un d?a tienes que elegir entre el mundo y el amor...
recuerda: 

si eliges el mundo quedar?s sin amor, 

pero si eliges el amor, con ?l conquistar?s al mundo" 

albert einstein 



  		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151210/8408a84c/attachment.htm>

From yvoinov at gmail.com  Thu Dec 10 20:36:23 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 11 Dec 2015 02:36:23 +0600
Subject: [squid-users] help change cache dir
In-Reply-To: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>
References: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>
Message-ID: <5669E247.8000503@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
chmod is about nothing. Who's the owner of cache dir?

11.12.15 2:27, juancho Alfonso ?????:
> Hey thereI have installed CentOS squid in 7I want to change the cache directory
> appears when I try to initialize
> Creating Swap Directories
> FATAL: Failed to make directory swap mydirectory / cache / 00:
>      (13) Permission denied
> directory is an external drive or a folder on the same partitionand I
granted permissions
> chmod 777 cacheorchmod cache squid.squid
> no worksI need help to put more capacity more directories
>
>
>
> the squid.conf
> ## Recommended minimum configuration:#
> # Example rule allowing access from your local networks.# Adapt to
list your (internal) IP networks from where browsing# should be
allowedacl localnet src 10.0.0.0/8 # RFC1918 possible internal
networkacl localnet src 172.16.0.0/12 # RFC1918 possible internal
networkacl localnet src 192.168.0.0/16 # RFC1918 possible internal
networkacl localnet src fc00::/7 # RFC 4193 local private network
rangeacl localnet src fe80::/10 # RFC 4291 link-local (directly plugged)
machines
> acl SSL_ports port 443acl Safe_ports port 80 # httpacl Safe_ports port
21 # ftpacl Safe_ports port 443 # httpsacl Safe_ports port 70 #
gopheracl Safe_ports port 210 # waisacl Safe_ports port 1025-65535 #
unregistered portsacl Safe_ports port 280 # http-mgmtacl Safe_ports port
488 # gss-httpacl Safe_ports port 591 # filemakeracl Safe_ports port 777
# multiling httpacl CONNECT method CONNECTacl PAGINASBLOQUEADAS
url_regex -i porno abcde
> ## Recommended minimum Access Permission configuration:## Deny
requests to certain unsafe portshttp_access deny PAGINASBLOQUEADAS
> # Deny CONNECT to other than secure SSL portshttp_access deny !Safe_ports
> # Only allow cachemgr access from localhosthttp_access deny CONNECT
!SSL_portshttp_access allow localhost manager
> # We strongly recommend the following be uncommented to protect
innocent# web applications running on the proxy server who think the
only# one who can access services on "localhost" is a local
user#http_access deny to_localhost
> ## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS#
> # Example rule allowing access from your local networks.# Adapt
localnet in the ACL section to list your (internal) IP networks# from
where browsing should be allowedhttp_access allow managerhttp_access
allow localnet
> # And finally deny all other access to this proxyhttp_access allow
localhosthttp_access allow all
> # Squid normally listens to port 3128http_port 3128 transparent
> # Uncomment and adjust the following to add a disk cache directory.
> # Leave coredumps in the first cache dircoredump_dir /var/spool/squid
> ## Add any of your own refresh_pattern entries above
these.#refresh_pattern ^ftp:        1440    20%    10080refresh_pattern
^gopher:    1440    0%    1440refresh_pattern -i (/cgi-bin/|\?) 0   
0%    0refresh_pattern .        0    20%    4320
>
>
> #juancache_mem 16384 MB#cache_replacement_policy heap LFUDA #El
par?metro maximum_object_size define el tama?o m?ximo de los objetos que
ser?n almacenados en el cache de discomaximum_object_size 200
MBcache_swap_low 90cache_swap_high 95#correo del administrador del
cachecache_mgr ingenieria at conexiondigital.cocachemgr_passwd cache all
> #this workcache_dir aufs /var/spool/squid 40000 16 256 #this no
workcache_dir aufs /var/spool/squid2 40000 16 256
> cache_effective_user squidcache_effective_group squid
>
>
>
> Juan Ernesto Alfonsoestudiante ingenier?a electr?nicauniversidad
distrital Francisco Jos? de Caldas
> JUANCHO
>  NEMESIS
> KRAVEN
>
> " si un d?a tienes que elegir entre el mundo y el amor...
> recuerda:
>
> si eliges el mundo quedar?s sin amor,
>
> pero si eliges el amor, con ?l conquistar?s al mundo"
>
> albert einstein
>
>
>
>                            
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWaeJHAAoJENNXIZxhPexG2u8H+gM/L1RdvwGHP6UiKbWPM3Fr
mU5Lt3V0iD6vLP7Wupn/oHyNNIhji39nkBLWPMs9SApodE0nOeirSD/M04TMfWMr
94HSDqnez+hOzlAZnCRxeI86eAu7w1ndY1SCfSJdXWHDkyY4sf7rvBczJigCP2Sm
+qX/4SHap32X5EoAwVWPk+lmyQ7MSma3x8OtzNUEqXfpX9EXMretXQ0yQ+B+egy+
9jvN5w+E8tKm1fV05rgT7B+QRNEG5jqnTI2hULX+xnJAbTcJZI/XR8AG2VmOvqjA
GErvrH6qqGpqW49IVEBY4Jm2qenThUbA2AOXq5d7bvybJP0oAJC1ap9pcc6gvyE=
=d1y4
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/a9b42e69/attachment.htm>

From yvoinov at gmail.com  Thu Dec 10 20:38:56 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 11 Dec 2015 02:38:56 +0600
Subject: [squid-users] help change cache dir
In-Reply-To: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>
References: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>
Message-ID: <5669E2E0.6040405@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Cache dir owner must be user which is specified in squid.conf:

http://i.imgur.com/AbYkE8M.png



11.12.15 2:27, juancho Alfonso ?????:
> Hey thereI have installed CentOS squid in 7I want to change the cache directory
> appears when I try to initialize
> Creating Swap Directories
> FATAL: Failed to make directory swap mydirectory / cache / 00:
>      (13) Permission denied
> directory is an external drive or a folder on the same partitionand I
granted permissions
> chmod 777 cacheorchmod cache squid.squid
> no worksI need help to put more capacity more directories
>
>
>
> the squid.conf
> ## Recommended minimum configuration:#
> # Example rule allowing access from your local networks.# Adapt to
list your (internal) IP networks from where browsing# should be
allowedacl localnet src 10.0.0.0/8 # RFC1918 possible internal
networkacl localnet src 172.16.0.0/12 # RFC1918 possible internal
networkacl localnet src 192.168.0.0/16 # RFC1918 possible internal
networkacl localnet src fc00::/7 # RFC 4193 local private network
rangeacl localnet src fe80::/10 # RFC 4291 link-local (directly plugged)
machines
> acl SSL_ports port 443acl Safe_ports port 80 # httpacl Safe_ports port
21 # ftpacl Safe_ports port 443 # httpsacl Safe_ports port 70 #
gopheracl Safe_ports port 210 # waisacl Safe_ports port 1025-65535 #
unregistered portsacl Safe_ports port 280 # http-mgmtacl Safe_ports port
488 # gss-httpacl Safe_ports port 591 # filemakeracl Safe_ports port 777
# multiling httpacl CONNECT method CONNECTacl PAGINASBLOQUEADAS
url_regex -i porno abcde
> ## Recommended minimum Access Permission configuration:## Deny
requests to certain unsafe portshttp_access deny PAGINASBLOQUEADAS
> # Deny CONNECT to other than secure SSL portshttp_access deny !Safe_ports
> # Only allow cachemgr access from localhosthttp_access deny CONNECT
!SSL_portshttp_access allow localhost manager
> # We strongly recommend the following be uncommented to protect
innocent# web applications running on the proxy server who think the
only# one who can access services on "localhost" is a local
user#http_access deny to_localhost
> ## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS#
> # Example rule allowing access from your local networks.# Adapt
localnet in the ACL section to list your (internal) IP networks# from
where browsing should be allowedhttp_access allow managerhttp_access
allow localnet
> # And finally deny all other access to this proxyhttp_access allow
localhosthttp_access allow all
> # Squid normally listens to port 3128http_port 3128 transparent
> # Uncomment and adjust the following to add a disk cache directory.
> # Leave coredumps in the first cache dircoredump_dir /var/spool/squid
> ## Add any of your own refresh_pattern entries above
these.#refresh_pattern ^ftp:        1440    20%    10080refresh_pattern
^gopher:    1440    0%    1440refresh_pattern -i (/cgi-bin/|\?) 0   
0%    0refresh_pattern .        0    20%    4320
>
>
> #juancache_mem 16384 MB#cache_replacement_policy heap LFUDA #El
par?metro maximum_object_size define el tama?o m?ximo de los objetos que
ser?n almacenados en el cache de discomaximum_object_size 200
MBcache_swap_low 90cache_swap_high 95#correo del administrador del
cachecache_mgr ingenieria at conexiondigital.cocachemgr_passwd cache all
> #this workcache_dir aufs /var/spool/squid 40000 16 256 #this no
workcache_dir aufs /var/spool/squid2 40000 16 256
> cache_effective_user squidcache_effective_group squid
>
>
>
> Juan Ernesto Alfonsoestudiante ingenier?a electr?nicauniversidad
distrital Francisco Jos? de Caldas
> JUANCHO
>  NEMESIS
> KRAVEN
>
> " si un d?a tienes que elegir entre el mundo y el amor...
> recuerda:
>
> si eliges el mundo quedar?s sin amor,
>
> pero si eliges el amor, con ?l conquistar?s al mundo"
>
> albert einstein
>
>
>
>                            
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWaeLfAAoJENNXIZxhPexGV6wH/0dy5nyvKJBsB8cWnXpyU661
98aA96FF+8QlQW+dkAKyNJ/dNtjv/VyGbglqyDDoaqwq2+Uef3dZauwyIQcwoRxZ
TVhUu47v+cX1F6Ka+JWxvw7hsIumoEvrXQQxdBoZUAqdXDRyvdK/VeraGyV1y2LD
qYQB/vIV7u/PGgiyzE5vtZ/aHYnAsiLQxMD4a3SSvDnSNx9fklhRGyTljcNuVH5n
NAXeXE3JD9+NW9rFY3/49TWNGJMNzH9v9RyQPG5uWkov/hAR1fXiRW7a/TD6pZ6V
/gb54gbAQcdCMXwsly7XQTswoG6OKGLuLl6+mLbLz3hgBpDfZDNAQMpKM4npiSU=
=ayi0
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/a7a741a3/attachment.htm>

From rafael.akchurin at diladele.com  Thu Dec 10 20:40:37 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 10 Dec 2015 20:40:37 +0000
Subject: [squid-users] help change cache dir
In-Reply-To: <5669E247.8000503@gmail.com>
References: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>
 <5669E247.8000503@gmail.com>
Message-ID: <VI1PR04MB1359AED451DEF7B7F745C9F88FE90@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Juancho,

Also check the SeLinux permissions.

Best regards,
Rafael Akchurin
Diladele B.V.

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.



From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Thursday, December 10, 2015 9:36 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] help change cache dir


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

chmod is about nothing. Who's the owner of cache dir?

11.12.15 2:27, juancho Alfonso ?????:
> Hey thereI have installed
      CentOS squid in 7I want to change the cache directory

      > appears when I try to initialize

      > Creating Swap Directories

      > FATAL: Failed to make directory swap mydirectory / cache /
      00:

      >      (13) Permission denied

     > directory is an external drive or a folder on the same
      partitionand I granted permissions

      > chmod 777 cacheorchmod cache squid.squid

      > no worksI need help to put more capacity more directories

      >

      >

      >

      > the squid.conf

      > ## Recommended minimum configuration:#

      > # Example rule allowing access from your local networks.#
      Adapt to list your (internal) IP networks from where browsing#
      should be allowedacl localnet src 10.0.0.0/8 # RFC1918 possible
      internal networkacl localnet src 172.16.0.0/12 # RFC1918 possible
      internal networkacl localnet src 192.168.0.0/16 # RFC1918 possible
      internal networkacl localnet src fc00::/7 # RFC 4193 local private
      network rangeacl localnet src fe80::/10 # RFC 4291 link-local
      (directly plugged) machines

      > acl SSL_ports port 443acl Safe_ports port 80 # httpacl
      Safe_ports port 21 # ftpacl Safe_ports port 443 # httpsacl
      Safe_ports port 70 # gopheracl Safe_ports port 210 # waisacl
      Safe_ports port 1025-65535 # unregistered portsacl Safe_ports port
      280 # http-mgmtacl Safe_ports port 488 # gss-httpacl Safe_ports
      port 591 # filemakeracl Safe_ports port 777 # multiling httpacl
      CONNECT method CONNECTacl PAGINASBLOQUEADAS url_regex -i porno
      abcde

      > ## Recommended minimum Access Permission configuration:##
      Deny requests to certain unsafe portshttp_access deny
      PAGINASBLOQUEADAS

      > # Deny CONNECT to other than secure SSL portshttp_access deny
      !Safe_ports

      > # Only allow cachemgr access from localhosthttp_access deny
      CONNECT !SSL_portshttp_access allow localhost manager

      > # We strongly recommend the following be uncommented to
      protect innocent# web applications running on the proxy server who
      think the only# one who can access services on "localhost" is a
      local user#http_access deny to_localhost

      > ## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR
      CLIENTS#

      > # Example rule allowing access from your local networks.#
      Adapt localnet in the ACL section to list your (internal) IP
      networks# from where browsing should be allowedhttp_access allow
      managerhttp_access allow localnet

      > # And finally deny all other access to this proxyhttp_access
      allow localhosthttp_access allow all

      > # Squid normally listens to port 3128http_port 3128
      transparent

      > # Uncomment and adjust the following to add a disk cache
      directory.

      > # Leave coredumps in the first cache dircoredump_dir
     /var/spool/squid

      > ## Add any of your own refresh_pattern entries above
      these.#refresh_pattern ^ftp:        1440    20%
      10080refresh_pattern ^gopher:    1440    0%    1440refresh_pattern
      -i (/cgi-bin/|\?) 0    0%    0refresh_pattern .        0    20%
      4320

      >

      >

      > #juancache_mem 16384 MB#cache_replacement_policy heap LFUDA
      #El par?metro maximum_object_size define el tama?o m?ximo de los
      objetos que ser?n almacenados en el cache de
      discomaximum_object_size 200 MBcache_swap_low 90cache_swap_high
      95#correo del administrador del cachecache_mgr
      ingenieria at conexiondigital.cocachemgr_passwd<mailto:ingenieria at conexiondigital.cocachemgr_passwd> cache all

     > #this workcache_dir aufs /var/spool/squid 40000 16 256 #this
      no workcache_dir aufs /var/spool/squid2 40000 16 256

      > cache_effective_user squidcache_effective_group squid

      >

      >

      >

      > Juan Ernesto Alfonsoestudiante ingenier?a
      electr?nicauniversidad distrital Francisco Jos? de Caldas

      > JUANCHO

      >  NEMESIS

      > KRAVEN

      >

      > " si un d?a tienes que elegir entre el mundo y el amor...

      > recuerda:

      >

      > si eliges el mundo quedar?s sin amor,

      >

      > pero si eliges el amor, con ?l conquistar?s al mundo"

      >

      > albert einstein

      >

      >

      >

      >

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJWaeJHAAoJENNXIZxhPexG2u8H+gM/L1RdvwGHP6UiKbWPM3Fr
mU5Lt3V0iD6vLP7Wupn/oHyNNIhji39nkBLWPMs9SApodE0nOeirSD/M04TMfWMr
94HSDqnez+hOzlAZnCRxeI86eAu7w1ndY1SCfSJdXWHDkyY4sf7rvBczJigCP2Sm
+qX/4SHap32X5EoAwVWPk+lmyQ7MSma3x8OtzNUEqXfpX9EXMretXQ0yQ+B+egy+
9jvN5w+E8tKm1fV05rgT7B+QRNEG5jqnTI2hULX+xnJAbTcJZI/XR8AG2VmOvqjA
GErvrH6qqGpqW49IVEBY4Jm2qenThUbA2AOXq5d7bvybJP0oAJC1ap9pcc6gvyE=
=d1y4
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151210/e321ac43/attachment.htm>

From alex at samad.com.au  Thu Dec 10 22:23:22 2015
From: alex at samad.com.au (Alex Samad)
Date: Fri, 11 Dec 2015 09:23:22 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <6ede17791f7541fa080516d4ac0461cf@dweimer.net>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
 <6ede17791f7541fa080516d4ac0461cf@dweimer.net>
Message-ID: <CAJ+Q1PUfhUWMQQ7yMyvNJPZuF52xDxyvnv_v2Nem3MzB0h5ouQ@mail.gmail.com>

Hi


On 10 December 2015 at 23:44, dweimer <dweimer at dweimer.net> wrote:
> https_port 10.50.20.12:443 accel defaultsite=mail.mydomain.com \
>  cert=/certs/wildcard.certificate.crt \
>  key=/certs/wildcard.certificate.key \
>  options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE \
>  dhparams=/usr/local/etc/squid/dh.param \
>  cipher=ALL:!aNULL:!eNULL:!LOW:!EXP:!ADH:+HIGH:+MEDIUM:!SSLv2:!RC4 \
>  vhost

what is the vhost option can't find it on the doco page
http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html


From alex at samad.com.au  Thu Dec 10 22:24:51 2015
From: alex at samad.com.au (Alex Samad)
Date: Fri, 11 Dec 2015 09:24:51 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PUfhUWMQQ7yMyvNJPZuF52xDxyvnv_v2Nem3MzB0h5ouQ@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
 <6ede17791f7541fa080516d4ac0461cf@dweimer.net>
 <CAJ+Q1PUfhUWMQQ7yMyvNJPZuF52xDxyvnv_v2Nem3MzB0h5ouQ@mail.gmail.com>
Message-ID: <CAJ+Q1PUR2XSRvKT=A9sYb6SPFLcjTbLXEKaH454h_poNCg7Ebw@mail.gmail.com>

Hi

Answer my own question
http://www.squid-cache.org/Versions/v3/3.5/cfgman/http_port.html

seems like there is a no-vhost, I presume vhost turns it on


On 11 December 2015 at 09:23, Alex Samad <alex at samad.com.au> wrote:
> Hi
>
>
> On 10 December 2015 at 23:44, dweimer <dweimer at dweimer.net> wrote:
>> https_port 10.50.20.12:443 accel defaultsite=mail.mydomain.com \
>>  cert=/certs/wildcard.certificate.crt \
>>  key=/certs/wildcard.certificate.key \
>>  options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE \
>>  dhparams=/usr/local/etc/squid/dh.param \
>>  cipher=ALL:!aNULL:!eNULL:!LOW:!EXP:!ADH:+HIGH:+MEDIUM:!SSLv2:!RC4 \
>>  vhost
>
> what is the vhost option can't find it on the doco page
> http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html


From alex at samad.com.au  Fri Dec 11 00:06:21 2015
From: alex at samad.com.au (Alex Samad)
Date: Fri, 11 Dec 2015 11:06:21 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <6ede17791f7541fa080516d4ac0461cf@dweimer.net>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
 <6ede17791f7541fa080516d4ac0461cf@dweimer.net>
Message-ID: <CAJ+Q1PU2-wz5DbMEdTO8UACrL--uOP-R8N+3CKLkRQ=g3Xuxwg@mail.gmail.com>

Hi

So I have taken this config done some slight customization for my site
and it appears to be working

Thanks for this ..

On 10 December 2015 at 23:44, dweimer <dweimer at dweimer.net> wrote:
> On 2015-12-09 11:29 pm, Alex Samad wrote:
>>
>> Hi
>>
>> config
>> https_port 22.4.2.5:443 accel
>> cert=/etc/httpd/conf.d/office.abc.com.crt
>> key=/etc/httpd/conf.d/office.abc.com.key defaultsite=office.abc.com
>> options=NO_SSLv2,NO_SSLv3
>> dhparams=/etc/squid/squid-office-dhparams.pem
>>
>> cipher=ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA
>> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
>> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
>> sslcert=/etc/httpd/conf.d/office.abc.com.crt
>> sslkey=/etc/httpd/conf.d/office.abc.com.key name=webServer
>> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
>> originserver login=PASS front-end-https=on ssl
>> sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.abc.com.crt
>> sslkey=/etc/httpd/conf.d/office.abc.com.key name=exchangeServer
>> acl exch_domain dstdomain office.abc.com
>> acl exch_path urlpath_regex -i /exch(ange|web)
>> acl exch_path urlpath_regex -i /public
>> acl exch_path urlpath_regex -i /owa
>> acl exch_path urlpath_regex -i /ecp
>> acl exch_path urlpath_regex -i /microsoft-server-activesync
>> acl exch_path urlpath_regex -i /rpc
>> acl exch_path urlpath_regex -i /rpcwithcert
>> acl exch_path urlpath_regex -i /exadmin
>> acl exch_path urlpath_regex -i /ews
>> acl exch_path urlpath_regex -i /oab
>> acl exch_path urlpath_regex -i /autodiscover
>> cache_peer_access exchangeServer allow exch_domain exch_path
>> cache_peer_access webServer deny exch_domain exch_path
>> never_direct allow exch_domain exch_path
>> cache_mem 32 MB
>> maximum_object_size_in_memory 128 KB
>> access_log stdio:/var/log/squid/office-access.log squid
>> cache_log /var/log/squid/office-cache.log
>> cache_store_log stdio:/var/log/squid/office-cache_store.log
>> pid_filename /var/run/squid-office.pid
>> visible_hostname office.abc.com
>> deny_info TCP_RESET all
>> http_access allow all
>> miss_access allow all
>> icp_port 0
>> snmp_port 0
>>
>>
>>
>> cache.log
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Process ID 5631
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Process Roles: worker
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| With 1024 file descriptors
>> available
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Initializing IP Cache...
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| DNS Socket created at 0.0.0.0,
>> FD 6
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding domain
>> yieldbroker.com from /etc/resolv.conf
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding nameserver
>> 10.32.20.100 from /etc/resolv.conf
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adding nameserver
>> 10.32.20.102 from /etc/resolv.conf
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Logfile: opening log
>> stdio:/var/log/squid/office-access.log
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Local cache digest enabled;
>> rebuild/rewrite every 3600/3600 sec
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Logfile: opening log
>> stdio:/var/log/squid/office-cache_store.log
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Swap maxSize 0 + 32768 KB,
>> estimated 2520 objects
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Target number of buckets: 126
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Using 8192 Store buckets
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Max Mem  size: 32768 KB
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Max Swap size: 0 KB
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Using Least Load store dir
>> selection
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Current Directory is /etc/squid
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Finished loading MIME types and
>> icons.
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| HTCP Disabled.
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Configuring Parent
>> 127.0.0.1/443/0
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Configuring Parent
>> 10.32.69.11/443/0
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Squid plugin modules loaded: 0
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Adaptation support is off.
>> Jan 01 10:33:35 1970/12/10 16:15:42 kid1| Accepting reverse-proxy
>> HTTPS Socket connections at local=202.74.32.15:443 remote=[::] FD 11
>> flags=9
>> Jan 01 10:33:35 1970/12/10 16:15:43 kid1| storeLateRelease: released 0
>> objects
>>
>>
>> cache log
>> Dec 10 16:16:23 2015.225 RELEASE -1 FFFFFFFF
>> BE6736C8CD1A74A54575AF9880395D04   ?         ?         ?         ? ?/?
>> ?/? ? ?
>> Dec 10 16:16:34 2015.287 RELEASE -1 FFFFFFFF
>> 78C390A2D412F8E601035A2C1FD771C8   ?         ?         ?         ? ?/?
>> ?/? ? ?
>> Dec 10 16:16:34 2015.296 RELEASE -1 FFFFFFFF
>> A7D8B3751858C54225D29408B56FE42D   ?         ?         ?         ? ?/?
>> ?/? ? ?
>> Dec 10 16:16:37 2015.863 RELEASE -1 FFFFFFFF
>> 35992070307CD15EE743F71344E1C1AE   ?         ?         ?         ? ?/?
>> ?/? ? ?
>> Dec 10 16:16:37 2015.873 RELEASE -1 FFFFFFFF
>> 17EFD3BCAF4265B7CF7803AD0289DD7E   ?         ?         ?         ? ?/?
>> ?/? ? ?
>> Dec 10 16:16:49 2015.228 RELEASE -1 FFFFFFFF
>> 2666EC9714425D57FDC4CD15965D350B   ?         ?         ?         ? ?/?
>> ?/? ? ?
>>
>>
>>
>> access.logs
>> Dec 10 16:17:09 2015.706     13 192.168.56.1 TCP_MISS/200 6578 POST
>> https://office.abc.com/ews/exchange.asmx - FIRSTUP_PARENT/10.32.69.11
>> text/xml
>> Dec 10 16:19:36 2015.447 206818 192.168.56.1 TCP_MISS/200 16532
>> RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
>> FIRSTUP_PARENT/10.32.69.11 application/rpc
>> Dec 10 16:19:36 2015.449 206862 192.168.56.1 TCP_MISS_ABORTED/502 4493
>> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
>> FIRSTUP_PARENT/10.32.69.11 text/html
>> Dec 10 16:19:36 2015.453 207197 192.168.56.1 TCP_MISS_ABORTED/000 0
>> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
>> FIRSTUP_PARENT/10.32.69.11 -
>> Dec 10 16:19:36 2015.453 207087 192.168.56.1 TCP_MISS_ABORTED/200
>> 48056 RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
>> FIRSTUP_PARENT/10.32.69.11 application/rpc
>> Dec 10 16:20:07 2015.305  24688 192.168.56.1 TCP_MISS_ABORTED/000 0
>> RPC_IN_DATA https://office.abc.com/rpc/rpcproxy.dll? -
>> FIRSTUP_PARENT/10.32.69.11 -
>> Dec 10 16:20:07 2015.306  24654 192.168.56.1 TCP_MISS_ABORTED/200 2004
>> RPC_OUT_DATA https://office.abc.com/rpc/rpcproxy.dll? -
>> FIRSTUP_PARENT/10.32.69.11 application/rpc
>>
>>
>> This is when I try and send an email with an attachment. An email with
>> no attached goes through no problem...
>>
>>
>> this config works with 3.1, not with 3.5 ..
>>
>> still on .11 as I can't find centos 6 compile of .12
>>
>> I think there is some issue with rpc sending or receiving ..
>>
>> On 8 December 2015 at 19:34, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>
>>> On 8/12/2015 7:35 p.m., Alex Samad wrote:
>>>>
>>>> Hi
>>>>
>>>> Any suggestions on how to debug this... I wouldn't mind rolling
>>>> forward to 3.5 again
>>>>
>>>
>>> Some ideas inline. The main ones are:
>>>
>>> * re-enable cache.log. It is not optional.
>>>
>>> * try an upgrade to 3.5.12. There were some regressions in the .10/.11
>>> releases that can lead to really weird behaviour.
>>>
>>>
>>>> On 2 December 2015 at 20:39, Alex Samad wrote:
>>>>>
>>>>> Just to add to this I have a lot of these in the log file
>>>>>
>>>>> TCP_MISS_ABORTED/000 0 RPC_IN_DATA
>>>>> TCP_MISS_ABORTED/200 4322 RPC_OUT_DATA
>>>>> TCP_MISS_ABORTED/000 0 RPC_IN_DATA https:
>>>>>
>>>>>
>>>>>
>>>>> On 2 December 2015 at 17:24, Alex Samad wrote:
>>>>>>
>>>>>> Hi
>>>>>>
>>>>>> recently upgraded to squid-3.5.11-1.el6.x86_64 from the centos 6.7
>>>>>> squid 3.1
>>>>>>
>>>>>>
>>>>>> I am now having problems with people who use active sync via this
>>>>>> connection . seems like emails with attachments aren't making it
>>>>>> through .
>>>>>>
>>>>>> cache_peer 10.32.69.11 parent 443 0 proxy-only no-query no-digest
>>>>>> originserver login=PASS front-end-https=on ssl
>>>>>> sslflags=DONT_VERIFY_PEER sslcert=/etc/httpd/conf.d/office.yx.com.crt
>>>>>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=exchangeServer
>>>
>>>
>>> You could try changing these from login=PASS to login=PASSTHRU
>>>
>>>>>>
>>>>>>
>>>>>> cache_peer 127.0.0.1 parent 443 0 proxy-only no-query no-digest
>>>>>> originserver login=PASS ssl sslflags=DONT_VERIFY_PEER
>>>>>> sslcert=/etc/httpd/conf.d/office.yx.com.crt
>>>>>> sslkey=/etc/httpd/conf.d/office.yx.com.key name=webServer
>>>>>> c
>>>>>>
>>>>>> # List of acceptable URLs to send to the Exchange server
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/exchange
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/exchweb
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/public
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/owa
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/ecp
>>>>>> acl exch_url url_regex -i
>>>>>> office.yieldbroker.com/microsoft-server-activesync
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/rpc
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/rpcwithcert
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/exadmin
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/oab
>>>>>> # added after
>>>>>> acl exch_url url_regex -i office.yieldbroker.com/ews
>>>>>> # Not configured on exchange 2010
>>>>>> #acl exch_url url_regex -i office.yieldbroker.com/autodiscover
>>>>>>
>>>>>> # Send the Exchange URLs to the Exchange server
>>>>>> cache_peer_access exchangeServer allow exch_url
>>>>>>
>>>>>> # Send everything else to the Apache
>>>>>> cache_peer_access webServer deny exch_url
>>>>>>
>>>>>> # This is to protect Squid
>>>>>> never_direct allow exch_url
>>>>>>
>>>>>> # Logging Configuration
>>>>>> redirect_rewrites_host_header off
>>>>>> cache_mem 32 MB
>>>>>> maximum_object_size_in_memory 128 KB
>>>>>> cache_log none
>>>
>>>
>>> You should re-enable cache.log and fix any of the issues that are logged
>>> there.
>>>
>>>
>>>>>> cache_store_log none
>>>>>>
>>>>>> access_log stdio:/var/log/squid/office-access.log squid
>>>>>> #access_log none
>>>>>> cache_log /var/log/squid/office-cache.log
>>>>>> #cache_log none
>>>>>> pid_filename /var/run/squid-office.pid
>>>>>>
>>>>>>
>>>>>> # Set the hostname so that we can see Squid in the path (Optional)
>>>>>> visible_hostname yieldbroker.com
>>>>>> deny_info TCP_RESET all
>>>
>>>
>>> This could lead to strange behaviour. Particularly since "deny all" is
>>> not being used in your http_access rules ...
>>>
>>>
>>>>>>
>>>>>> # Allow everyone through, internal and external connections
>>>>>> http_access allow all
>>>>>> miss_access allow all
>>>>>>
>>>>>> icp_port 0
>>>>>> snmp_port 0
>>>>>>
>>>>>> via off
>>>>>>
>>>>>>
>>>>>> The previous setup had worked for at least 18 months.
>>>>>>
>>>>>> Alex
>
>
> On our Reverse proxy I ran into an issue uploading attachments to Exchange
> back end, a while back, turned out the solution was to lock it down so that
> the proxy only used ssl version 3 to connect to the Exchange server. This
> however did recently break after a windows update in Novemeber. Further
> investigation led to the particular cipher that was in use. After
> discovering this I was able to use the same cipher with TLSv1.0
>
> Currently I am using TLSv1.0 with RC4-SHA cipher to talk to the Exchange
> server.
>
> cache_peer 10.20.10.161 parent 443 0 ssl no-query proxy-only no-digest
> originserver \
>  name=owa2010_parent sslcapath=/usr/local/share/certs
> sslflags=DONT_VERIFY_PEER  \
>  login=PASSTHRU front-end-https=on connection-auth=on sslcipher=RC4-SHA
> sslversion=4
>
> I am not however locking down the incoming connections to this setting, I am
> using the following for the https_port setting. This does pass PCI scans, in
> case anyone is wondering about the choice of cipher options, and you will
> notice the RC4 used to send traffic between the Proxy and Exchange is
> disabled as that doesn't meet current requirements.
>
> https_port 10.50.20.12:443 accel defaultsite=mail.mydomain.com \
>  cert=/certs/wildcard.certificate.crt \
>  key=/certs/wildcard.certificate.key \
>  options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE \
>  dhparams=/usr/local/etc/squid/dh.param \
>  cipher=ALL:!aNULL:!eNULL:!LOW:!EXP:!ADH:+HIGH:+MEDIUM:!SSLv2:!RC4 \
>  vhost
>
>
> --
> Thanks,
>    Dean E. Weimer
>    http://www.dweimer.net/


From dweimer at dweimer.net  Fri Dec 11 00:09:34 2015
From: dweimer at dweimer.net (dweimer)
Date: Thu, 10 Dec 2015 18:09:34 -0600
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PUR2XSRvKT=A9sYb6SPFLcjTbLXEKaH454h_poNCg7Ebw@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
 <6ede17791f7541fa080516d4ac0461cf@dweimer.net>
 <CAJ+Q1PUfhUWMQQ7yMyvNJPZuF52xDxyvnv_v2Nem3MzB0h5ouQ@mail.gmail.com>
 <CAJ+Q1PUR2XSRvKT=A9sYb6SPFLcjTbLXEKaH454h_poNCg7Ebw@mail.gmail.com>
Message-ID: <991f0fbb2c0b831db4973e5895369ce8@dweimer.net>

On 2015-12-10 4:24 pm, Alex Samad wrote:
> Hi
> 
> Answer my own question
> http://www.squid-cache.org/Versions/v3/3.5/cfgman/http_port.html
> 
> seems like there is a no-vhost, I presume vhost turns it on
> 
> 
> On 11 December 2015 at 09:23, Alex Samad <alex at samad.com.au> wrote:
>> Hi
>> 
>> 
>> On 10 December 2015 at 23:44, dweimer <dweimer at dweimer.net> wrote:
>>> https_port 10.50.20.12:443 accel defaultsite=mail.mydomain.com \
>>>  cert=/certs/wildcard.certificate.crt \
>>>  key=/certs/wildcard.certificate.key \
>>>  
>>> options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE 
>>> \
>>>  dhparams=/usr/local/etc/squid/dh.param \
>>>  cipher=ALL:!aNULL:!eNULL:!LOW:!EXP:!ADH:+HIGH:+MEDIUM:!SSLv2:!RC4 \
>>>  vhost
>> 
>> what is the vhost option can't find it on the doco page
>> http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html

It maybe on by default now, unless you are doing multiple host names, 
its not necessary. The setup on mine is using a wildcard certificate and 
is proxying multiple domains names.

-- 
Thanks,
    Dean E. Weimer
    http://www.dweimer.net/


From vze2k3sa at verizon.net  Fri Dec 11 01:16:18 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Thu, 10 Dec 2015 20:16:18 -0500
Subject: [squid-users] Squid 32-bit (2.7.2) much faster than Squid 64-bit
	(3.5.11)
Message-ID: <004e01d133b1$8a9a48d0$9fceda70$@verizon.net>

Hello,

 

Just following up on my slow 3.5.11 Squid server.  I loaded the 32-bit 2.7.2
version on the same box and it's so much faster for me. Its 4 to 5 times
faster for me on the same machine. Please any help appreciated. Amos, I
think I cleaned up my 3.5.11 squid.conf properly. I think my 2.7.2
squid.conf needs work.

See below Startup Cache logs from both 3.5.11 and 2.7.2 and also the
squid.conf files from 3.5.11 and 2.7.2.

 

Thank You,

Patrick

 

Squid 3.5.11 Startup Cache Log:

2015/12/10 19:50:09 kid1| Current Directory is /cygdrive/c/Windows/system32

2015/12/10 19:50:09 kid1| Starting Squid Cache version 3.5.11 for
x86_64-unknown-cygwin...

2015/12/10 19:50:09 kid1| Service Name: squid

2015/12/10 19:50:09 kid1| Process ID 1968

2015/12/10 19:50:09 kid1| Process Roles: worker

2015/12/10 19:50:09 kid1| With 3200 file descriptors available

2015/12/10 19:50:09 kid1| Initializing IP Cache...

2015/12/10 19:50:09 kid1| parseEtcHosts: /etc/hosts: (2) No such file or
directory

2015/12/10 19:50:09 kid1| DNS Socket created at [::], FD 5

2015/12/10 19:50:09 kid1| DNS Socket created at 0.0.0.0, FD 6

2015/12/10 19:50:09 kid1| Adding nameserver 172.16.50.9 from squid.conf

2015/12/10 19:50:09 kid1| Adding nameserver 172.16.50.13 from squid.conf

2015/12/10 19:50:09 kid1| Logfile: opening log
daemon:/var/log/squid/access.log

2015/12/10 19:50:09 kid1| Logfile Daemon: opening log
/var/log/squid/access.log

2015/12/10 19:50:09 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument

2015/12/10 19:50:09 kid1| Store logging disabled

2015/12/10 19:50:09 kid1| Swap maxSize 0 + 262144 KB, estimated 20164
objects

2015/12/10 19:50:09 kid1| Target number of buckets: 1008

2015/12/10 19:50:09 kid1| Using 8192 Store buckets

2015/12/10 19:50:09 kid1| Max Mem  size: 262144 KB

2015/12/10 19:50:09 kid1| Max Swap size: 0 KB

2015/12/10 19:50:09 kid1| Using Least Load store dir selection

2015/12/10 19:50:09 kid1| Current Directory is /cygdrive/c/Windows/system32

2015/12/10 19:50:09 kid1| Finished loading MIME types and icons.

2015/12/10 19:50:09 kid1| HTCP Disabled.

2015/12/10 19:50:09 kid1| Squid plugin modules loaded: 0

2015/12/10 19:50:09 kid1| Adaptation support is off.

2015/12/10 19:50:09 kid1| Accepting HTTP Socket connections at
local=[::]:3130 remote=[::] FD 10 flags=9

2015/12/10 19:50:11 kid1| storeLateRelease: released 0 objects 

----------------------------------------------------------------------------
-------------------------------

Squid 2.7.2 Startup Cache Log:

2015/12/10 19:50:38| Starting Squid Cache version 2.7.STABLE8 for
i686-pc-winnt...

2015/12/10 19:50:38| Running as Squid-Proxy-2.7.2 Windows System Service on
Windows Server 2008

2015/12/10 19:50:38| Service command line is: 

2015/12/10 19:50:38| Process ID 2644

2015/12/10 19:50:38| With 2048 file descriptors available

2015/12/10 19:50:38| With 2048 CRT stdio descriptors available

2015/12/10 19:50:38| Windows sockets initialized

2015/12/10 19:50:38| Using select for the IO loop

2015/12/10 19:50:38| Performing DNS Tests...

2015/12/10 19:50:38| Successful DNS name lookup tests...

2015/12/10 19:50:38| DNS Socket created at 0.0.0.0, port 50961, FD 5

2015/12/10 19:50:38| Adding DHCP nameserver 172.16.50.9 from Registry

2015/12/10 19:50:38| Adding DHCP nameserver 172.16.50.13 from Registry

2015/12/10 19:50:38| Adding DHCP nameserver 4.2.2.3 from Registry

2015/12/10 19:50:38| Adding domain  from Registry

2015/12/10 19:50:38| User-Agent logging is disabled.

2015/12/10 19:50:38| Referer logging is disabled.

2015/12/10 19:50:38| logfileOpen: opening log C:/squid/var/logs/access.log

2015/12/10 19:50:38| Unlinkd pipe opened on FD 8

2015/12/10 19:50:38| Swap maxSize 102400 + 65536 KB, estimated 12918 objects

2015/12/10 19:50:38| Target number of buckets: 645

2015/12/10 19:50:38| Using 8192 Store buckets

2015/12/10 19:50:38| Max Mem  size: 65536 KB

2015/12/10 19:50:38| Max Swap size: 102400 KB

2015/12/10 19:50:38| Local cache digest enabled; rebuild/rewrite every
3600/3600 sec

2015/12/10 19:50:38| logfileOpen: opening log c:/squid/var/logs/store.log

2015/12/10 19:50:38| Rebuilding storage in C:/Squid/var/cache/squid (DIRTY)

2015/12/10 19:50:38| Using Least Load store dir selection

2015/12/10 19:50:38| Current Directory is C:\squid\sbin

2015/12/10 19:50:38| Loaded Icons.

2015/12/10 19:50:38| Accepting proxy HTTP connections at 0.0.0.0, port 3128,
FD 14.

2015/12/10 19:50:38| HTCP Disabled.

2015/12/10 19:50:38| Ready to serve requests.

2015/12/10 19:50:38| Done reading C:/Squid/var/cache/squid swaplog (0
entries)

2015/12/10 19:50:38| Finished rebuilding storage from disk.

2015/12/10 19:50:38|         0 Entries scanned

2015/12/10 19:50:38|         0 Invalid entries.

2015/12/10 19:50:38|         0 With invalid flags.

2015/12/10 19:50:38|         0 Objects loaded.

2015/12/10 19:50:38|         0 Objects expired.

2015/12/10 19:50:38|         0 Objects cancelled.

2015/12/10 19:50:38|         0 Duplicate URLs purged.

2015/12/10 19:50:38|         0 Swapfile clashes avoided.

2015/12/10 19:50:38|   Took 0.0 seconds (   0.0 objects/sec).

2015/12/10 19:50:38| Beginning Validation Procedure

2015/12/10 19:50:38|   Completed Validation Procedure

2015/12/10 19:50:38|   Validated 0 Entries

2015/12/10 19:50:38|   store_swap_size = 0k

2015/12/10 19:50:39| storeLateRelease: released 0 objects

----------------------------------------------------------------------------
----------------------

Squid 3.5.11 Squid.conf:

# Squid Proxy Configuration

 

acl localnet src all

#acl localnet src 172.16.50.0/24  # RFC1918 possible internal network

 

 

acl SSL_ports port 443

acl Safe_ports port 80                    # http

acl Safe_ports port 443                  # https

acl CONNECT method CONNECT

 

# Deny requests to certain unsafe ports

http_access deny !Safe_ports

 

# Deny CONNECT to other than secure SSL ports

http_access deny CONNECT !SSL_ports

 

http_access allow localnet

http_access allow localhost

 

# Lastly deny all other access to this proxy

http_access deny all

 

# Listens to port 3128

http_port 3130

 

dns_nameservers 172.16.50.9 172.16.50.13

 

max_filedescriptors 3200

 

# roll log file daily and keep 30 days

logfile_rotate 30

 

# access log format

logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt

 

# debug_options             ALL,2

----------------------------------------------------------------------------
-----------

Squid 2.7.2 Squid.conf:

 

# Squid Proxy Configuration

 

http_port    3128

 

# acl and http_access to ("whitelist.txt")

acl whitelist dstdomain  "c:/squid/etc/whitelist.txt"

http_access        allow     whitelist

 

# subnet source of proxy traffic

acl all src 0.0.0.0/0.0.0.0

acl localnet  src  0.0.0.0/0.0.0.0

 

# acl directives for ports and protocols

acl http      proto      http

acl https     proto      https

acl port_80   port       80

acl sslports  port       443-444

acl CONNECT   method     CONNECT

 

icp_port 0

htcp_port 0

snmp_port 0

 

# rules allowing whitelist domains

http_access allow http    port_80  whitelist localnet

http_access allow https   sslports whitelist localnet

 

# cache web pages directory

cache_dir ufs C:/Squid/var/cache/squid 100 16 256

cache_mem 64 MB

 

# log file roll weekly

access_log C:/squid/var/logs/access.log common

logfile_rotate 7

 

# catch-all rule

http_access deny all

 

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151210/fd94037c/attachment.htm>

From alex at samad.com.au  Fri Dec 11 03:52:21 2015
From: alex at samad.com.au (Alex Samad)
Date: Fri, 11 Dec 2015 14:52:21 +1100
Subject: [squid-users] reverse proxy setup
Message-ID: <CAJ+Q1PXWn7M=1NCia1Zqi4DJT3niNJBjADbYss0Ri0i2=szPRg@mail.gmail.com>

Hi


Is there any way to remove these from the log

kid1| Error negotiating SSL connection on FD 38: error:140760FC:SSL
routines:SSL23_GET_CLIENT_HELLO:unknown protocol (1/-1)

this is the corrosponding squid config
options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE

Not I don't get this when I re enable tlsv1..

I am presuming I can ignore these.


From alex at samad.com.au  Fri Dec 11 04:29:48 2015
From: alex at samad.com.au (Alex Samad)
Date: Fri, 11 Dec 2015 15:29:48 +1100
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <991f0fbb2c0b831db4973e5895369ce8@dweimer.net>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
 <6ede17791f7541fa080516d4ac0461cf@dweimer.net>
 <CAJ+Q1PUfhUWMQQ7yMyvNJPZuF52xDxyvnv_v2Nem3MzB0h5ouQ@mail.gmail.com>
 <CAJ+Q1PUR2XSRvKT=A9sYb6SPFLcjTbLXEKaH454h_poNCg7Ebw@mail.gmail.com>
 <991f0fbb2c0b831db4973e5895369ce8@dweimer.net>
Message-ID: <CAJ+Q1PUEuzgBuQNKAyg0nVbBRuExYmik0w0abBZAHe_=QcRo_g@mail.gmail.com>

Hi

I did the change over today.
Tested with Window 7 + exchange 2010 and it wouldn't connect whilst
there was no tls1 !

interesting IE worked against the web site .... so ..

Did you come across this issues ?


On 11 December 2015 at 11:09, dweimer <dweimer at dweimer.net> wrote:
> On 2015-12-10 4:24 pm, Alex Samad wrote:
>>
>> Hi
>>
>> Answer my own question
>> http://www.squid-cache.org/Versions/v3/3.5/cfgman/http_port.html
>>
>> seems like there is a no-vhost, I presume vhost turns it on
>>
>>
>> On 11 December 2015 at 09:23, Alex Samad <alex at samad.com.au> wrote:
>>>
>>> Hi
>>>
>>>
>>> On 10 December 2015 at 23:44, dweimer <dweimer at dweimer.net> wrote:
>>>>
>>>> https_port 10.50.20.12:443 accel defaultsite=mail.mydomain.com \
>>>>  cert=/certs/wildcard.certificate.crt \
>>>>  key=/certs/wildcard.certificate.key \
>>>>
>>>> options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE \
>>>>  dhparams=/usr/local/etc/squid/dh.param \
>>>>  cipher=ALL:!aNULL:!eNULL:!LOW:!EXP:!ADH:+HIGH:+MEDIUM:!SSLv2:!RC4 \
>>>>  vhost
>>>
>>>
>>> what is the vhost option can't find it on the doco page
>>> http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html
>
>
> It maybe on by default now, unless you are doing multiple host names, its
> not necessary. The setup on mine is using a wildcard certificate and is
> proxying multiple domains names.
>
>
> --
> Thanks,
>    Dean E. Weimer
>    http://www.dweimer.net/


From squid3 at treenet.co.nz  Fri Dec 11 04:50:50 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 11 Dec 2015 17:50:50 +1300
Subject: [squid-users] reverse proxy setup
In-Reply-To: <CAJ+Q1PXWn7M=1NCia1Zqi4DJT3niNJBjADbYss0Ri0i2=szPRg@mail.gmail.com>
References: <CAJ+Q1PXWn7M=1NCia1Zqi4DJT3niNJBjADbYss0Ri0i2=szPRg@mail.gmail.com>
Message-ID: <566A562A.1020909@treenet.co.nz>

On 11/12/2015 4:52 p.m., Alex Samad wrote:
> Hi
> 
> 
> Is there any way to remove these from the log
> 
> kid1| Error negotiating SSL connection on FD 38: error:140760FC:SSL
> routines:SSL23_GET_CLIENT_HELLO:unknown protocol (1/-1)
> 
> this is the corrosponding squid config
> options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE
> 
> Not I don't get this when I re enable tlsv1..

Strange. Usually that means non-TLS traffic being passed to the HTTPS
port. For example, clients opening plain-text HTTP connections to it.

> 
> I am presuming I can ignore these.

That is always up to you. In this case somebody is getting broken
traffic, and your logs are filling with the messages saying so.

Amos



From tomtux007 at gmail.com  Fri Dec 11 05:33:11 2015
From: tomtux007 at gmail.com (Tom Tom)
Date: Fri, 11 Dec 2015 06:33:11 +0100
Subject: [squid-users] Deny Access based on SSL-Blacklists
 (SHA1-Fingerprint) with ssl_bump
In-Reply-To: <CACLJR+NE-T1SkFMhoUFj8xJb9iDOrR_xooOY44J2b1+zgNxjmQ@mail.gmail.com>
References: <CACLJR+Ot7baE-5fPoXt4iNmzStp_0GL9w-qHG3MPRd0v_Nvv9g@mail.gmail.com>
 <566189BC.7010602@treenet.co.nz>
 <5661BC23.7040109@measurement-factory.com>
 <20151207113746.GK12890@charite.de>
 <56659FA3.9000404@measurement-factory.com>
 <CACLJR+PNpWzh=uU-qBNsbk7xVsvcq1Ve9cpb_tu1gUsFGH1qZA@mail.gmail.com>
 <5665FA59.5010506@measurement-factory.com>
 <CACLJR+NE-T1SkFMhoUFj8xJb9iDOrR_xooOY44J2b1+zgNxjmQ@mail.gmail.com>
Message-ID: <CACLJR+MzWT6-721zFNxa04OS3-FYxW3zRb1We6AkBcow1YnRpQ@mail.gmail.com>

Bug created: http://bugs.squid-cache.org/show_bug.cgi?id=4394

On Thu, Dec 10, 2015 at 9:10 PM, Tom Tom <tomtux007 at gmail.com> wrote:
> Hi Alex
>
> I've tested again. Squid (3.5.11) only terminates the connection
> (based on SHA1-Fingerprint), *if* the fingerprint is delimited with
> colons. If not, squid GET's the https-request as usual. I'll report a
> bug.
>
> With SHA1-FP (delimited):
> 41:30:72:F8:03:CE:96:12:10:E9:A4:5D:10:DA:14:B0:D2:D4:85:32 in the
> config-file, Squid terminates the connection as expected:
> $ curl -x proxy:3128 -I -k -L https://www.yahoo.com
> HTTP/1.1 200 Connection established
> curl: (35) Unknown SSL protocol error in connection to www.yahoo.com:443
>
>
> With SHA1-FP (not delimited): 413072F803CE961210E9A45D10DA14B0D2D48532
> in the config-file, squid GET's the site:
> $ curl -x proxy:3128 -I -k -L https://www.yahoo.com
> HTTP/1.1 200 Connection established
>
> HTTP/1.1 200 OK
> Date: Thu, 10 Dec 2015 20:06:11 GMT
> P3P: policyref="http://info.yahoo.com/w3c/p3p.xml", CP="CAO DSP COR
> CUR ADM DEV TAI PSA PSD IVAi IVDi CONi TELo OTPi OUR DELi SAMi OTRi
> UNRi PUBi IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE
> LOC GOV"
> X-Frame-Options: DENY
> Strict-Transport-Security: max-age=2592000
> ...
> ....
>
> Kind regards,
> Tom
>
> On Mon, Dec 7, 2015 at 10:30 PM, Alex Rousskov
> <rousskov at measurement-factory.com> wrote:
>> On 12/07/2015 02:05 PM, Tom Tom wrote:
>>> The configuration provided by Alex works for me (squid 3.5.11)
>>
>> Thank you for testing and helping expose problems.
>>
>>
>>> if:
>>> * the http_port-directive is configured with ssl-bump and a
>>> certificate (ex. http_port 3128 ssl-bump generate-host-certificates=on
>>> dynamic_cert_mem_cache_size=4MB cert=/usr/local/certs/myCA.pem)
>>
>> ssl-bump is required to access SSL/TLS peeking code. Now way around that
>> today although future Squid versions may provide something like an
>> ssl-peek port option that tells Squid that no bumping, for any reason
>> (including error serving) is permitted on that port.
>>
>> Specifying root CA is required to serve certificate validation (and
>> other) errors, but we probably should be more flexible and allow no-CA
>> splice-or-terminate configurations as well.
>>
>> Related enhancement requests in bugzilla are welcomed, especially if
>> they are followed by quality patches.
>>
>>
>>> * the SHA1-fingerprint in the file SSL_BLACKLISTS is delimited after
>>> two characters with a colon
>>> (9E:C8:15:3F:27:C9:B5:BA:B9:17:49:C8:0A:D7:DF:21:D3:8C:80:50 for
>>> ar***krebs.de)
>>
>> If Squid silently misinterprets colon-less fingerprints, it is a bug
>> that should be reported and fixed. Squid should either interpret them
>> correctly or exit with a configuration error.
>>
>>
>> Thank you,
>>
>> Alex.
>>
>>
>>
>>> On Mon, Dec 7, 2015 at 4:02 PM, Alex Rousskov
>>> <rousskov at measurement-factory.com> wrote:
>>>> On 12/07/2015 04:37 AM, Ralf Hildebrandt wrote:
>>>>> * Alex Rousskov <rousskov at measurement-factory.com>:
>>>>>> Please note that if you do not want to bump anything, then the following
>>>>>> should also work (bugs notwithstanding):
>>>>>>
>>>>>>     ssl_bump splice whitelist
>>>>>>     ssl_bump peek all
>>>>>>     ssl_bump terminate blacklist
>>>>>>     ssl_bump splice all
>>>>>
>>>>> That doesn't seem to work for me (squid 3.5.2)
>>>>
>>>>> Yet I still can connect. What am I doing wrong?
>>>>
>>>> If you are indeed using v3.5.2, then that is a big red flag.
>>>>
>>>> If you are using the latest v3.5 release, then you should open a bug
>>>> report, preferably with an ALL,9 log depicting a single failing
>>>> transaction. AFAICT, the above is meant to work. If it does not, there
>>>> is either a Squid bug or misconfiguration [that I cannot detect by
>>>> reading email].
>>>>
>>>>
>>>> Thank you,
>>>>
>>>> Alex.
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>


From Massimo.Sala at asl.bergamo.it  Fri Dec 11 09:00:03 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Fri, 11 Dec 2015 10:00:03 +0100
Subject: [squid-users] squid 3.4, dstdomain
Message-ID: <OF270E7043.34772203-ONC1257F18.002F0382-C1257F18.00317014@asl.bergamo.it>

> Massimo

>> 2015/12/10 10:33:49| ERROR: '.addons.mozilla.org' is a subdomain of
>> 'addons.mozilla.org'



Francesco aka Kinkie

> No bug, it is really intentional: ".addons.mozilla.org" also matches
> "addons.mozilla.org" (without the dot).


Francesco, thank you for the explanation.

Is it possible to add it to the official docs ?

ciao, Massimo 
massimo.sala at asl.bergamo.it
Tel. 035/385.034
ASL Provincia di Bergamo | Sistemi Informativi Strategici



From tarotapprentice at yahoo.com  Fri Dec 11 09:16:31 2015
From: tarotapprentice at yahoo.com (TarotApprentice)
Date: Fri, 11 Dec 2015 09:16:31 +0000 (UTC)
Subject: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than Squid
 64-bit (3.5.11)
In-Reply-To: <65A6F958-E262-46D7-A05E-08C4C34E4061@yahoo.com>
References: <65A6F958-E262-46D7-A05E-08C4C34E4061@yahoo.com>
Message-ID: <81537556.619395.1449825391887.JavaMail.yahoo@mail.yahoo.com>

Sorry should have replied to the list.

MarkJ
 
----- Forwarded Message -----
>From: Tarot Apprentice <tarotapprentice at yahoo.com>
>To: Patrick Flaherty <vze2k3sa at verizon.net> 
>Sent: Friday, 11 December 2015, 14:10
>Subject: Re: [squid-users] Squid 32-bit (2.7.2) much faster than Squid 64-bit (3.5.11)
> 
>Looking at the startup logs the 3.4.11 says "store logging disabled" (it had an error) so would account for some of the difference.
>
>MarkJ
>
>
>
>
>On 11 Dec 2015, at 12:16 PM, Patrick Flaherty <vze2k3sa at verizon.net> wrote:
>
>
>Hello,
> 
>Just following up on my slow 3.5.11 Squid server.  I loaded the 32-bit 2.7.2 version on the same box and it?s so much faster for me. Its 4 to 5 times faster for me on the same machine. Please any help appreciated. Amos, I think I cleaned up my 3.5.11 squid.conf properly. I think my 2.7.2 squid.conf needs work.
>See below Startup Cache logs from both 3.5.11 and 2.7.2 and also the squid.conf files from 3.5.11 and 2.7.2.
> 
>Thank You,
>Patrick
> 
>Squid 3.5.11 Startup Cache Log:
>2015/12/10 19:50:09 kid1| Current Directory is /cygdrive/c/Windows/system32
>2015/12/10 19:50:09 kid1| Starting Squid Cache version 3.5.11 for x86_64-unknown-cygwin...
>2015/12/10 19:50:09 kid1| Service Name: squid
>2015/12/10 19:50:09 kid1| Process ID 1968
>2015/12/10 19:50:09 kid1| Process Roles: worker
>2015/12/10 19:50:09 kid1| With 3200 file descriptors available
>2015/12/10 19:50:09 kid1| Initializing IP Cache...
>2015/12/10 19:50:09 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
>2015/12/10 19:50:09 kid1| DNS Socket created at [::], FD 5
>2015/12/10 19:50:09 kid1| DNS Socket created at 0.0.0.0, FD 6
>2015/12/10 19:50:09 kid1| Adding nameserver 172.16.50.9 from squid.conf
>2015/12/10 19:50:09 kid1| Adding nameserver 172.16.50.13 from squid.conf
>2015/12/10 19:50:09 kid1| Logfile: opening log daemon:/var/log/squid/access.log
>2015/12/10 19:50:09 kid1| Logfile Daemon: opening log /var/log/squid/access.log
>2015/12/10 19:50:09 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
>2015/12/10 19:50:09 kid1| Store logging disabled
>2015/12/10 19:50:09 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects
>2015/12/10 19:50:09 kid1| Target number of buckets: 1008
>2015/12/10 19:50:09 kid1| Using 8192 Store buckets
>2015/12/10 19:50:09 kid1| Max Mem  size: 262144 KB
>2015/12/10 19:50:09 kid1| Max Swap size: 0 KB
>2015/12/10 19:50:09 kid1| Using Least Load store dir selection
>2015/12/10 19:50:09 kid1| Current Directory is /cygdrive/c/Windows/system32
>2015/12/10 19:50:09 kid1| Finished loading MIME types and icons.
>2015/12/10 19:50:09 kid1| HTCP Disabled.
>2015/12/10 19:50:09 kid1| Squid plugin modules loaded: 0
>2015/12/10 19:50:09 kid1| Adaptation support is off.
>2015/12/10 19:50:09 kid1| Accepting HTTP Socket connections at local=[::]:3130 remote=[::] FD 10 flags=9
>2015/12/10 19:50:11 kid1| storeLateRelease: released 0 objects 
>-----------------------------------------------------------------------------------------------------------
>Squid 2.7.2 Startup Cache Log:
>2015/12/10 19:50:38| Starting Squid Cache version 2.7.STABLE8 for i686-pc-winnt...
>2015/12/10 19:50:38| Running as Squid-Proxy-2.7.2 Windows System Service on Windows Server 2008
>2015/12/10 19:50:38| Service command line is: 
>2015/12/10 19:50:38| Process ID 2644
>2015/12/10 19:50:38| With 2048 file descriptors available
>2015/12/10 19:50:38| With 2048 CRT stdio descriptors available
>2015/12/10 19:50:38| Windows sockets initialized
>2015/12/10 19:50:38| Using select for the IO loop
>2015/12/10 19:50:38| Performing DNS Tests...
>2015/12/10 19:50:38| Successful DNS name lookup tests...
>2015/12/10 19:50:38| DNS Socket created at 0.0.0.0, port 50961, FD 5
>2015/12/10 19:50:38| Adding DHCP nameserver 172.16.50.9 from Registry
>2015/12/10 19:50:38| Adding DHCP nameserver 172.16.50.13 from Registry
>2015/12/10 19:50:38| Adding DHCP nameserver 4.2.2.3 from Registry
>2015/12/10 19:50:38| Adding domain  from Registry
>2015/12/10 19:50:38| User-Agent logging is disabled.
>2015/12/10 19:50:38| Referer logging is disabled.
>2015/12/10 19:50:38| logfileOpen: opening log C:/squid/var/logs/access.log
>2015/12/10 19:50:38| Unlinkd pipe opened on FD 8
>2015/12/10 19:50:38| Swap maxSize 102400 + 65536 KB, estimated 12918 objects
>2015/12/10 19:50:38| Target number of buckets: 645
>2015/12/10 19:50:38| Using 8192 Store buckets
>2015/12/10 19:50:38| Max Mem  size: 65536 KB
>2015/12/10 19:50:38| Max Swap size: 102400 KB
>2015/12/10 19:50:38| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
>2015/12/10 19:50:38| logfileOpen: opening log c:/squid/var/logs/store.log
>2015/12/10 19:50:38| Rebuilding storage in C:/Squid/var/cache/squid (DIRTY)
>2015/12/10 19:50:38| Using Least Load store dir selection
>2015/12/10 19:50:38| Current Directory is C:\squid\sbin
>2015/12/10 19:50:38| Loaded Icons.
>2015/12/10 19:50:38| Accepting proxy HTTP connections at 0.0.0.0, port 3128, FD 14.
>2015/12/10 19:50:38| HTCP Disabled.
>2015/12/10 19:50:38| Ready to serve requests.
>2015/12/10 19:50:38| Done reading C:/Squid/var/cache/squid swaplog (0 entries)
>2015/12/10 19:50:38| Finished rebuilding storage from disk.
>2015/12/10 19:50:38|         0 Entries scanned
>2015/12/10 19:50:38|         0 Invalid entries.
>2015/12/10 19:50:38|         0 With invalid flags.
>2015/12/10 19:50:38|         0 Objects loaded.
>2015/12/10 19:50:38|         0 Objects expired.
>2015/12/10 19:50:38|         0 Objects cancelled.
>2015/12/10 19:50:38|         0 Duplicate URLs purged.
>2015/12/10 19:50:38|         0 Swapfile clashes avoided.
>2015/12/10 19:50:38|   Took 0.0 seconds (   0.0 objects/sec).
>2015/12/10 19:50:38| Beginning Validation Procedure
>2015/12/10 19:50:38|   Completed Validation Procedure
>2015/12/10 19:50:38|   Validated 0 Entries
>2015/12/10 19:50:38|   store_swap_size = 0k
>2015/12/10 19:50:39| storeLateRelease: released 0 objects
>--------------------------------------------------------------------------------------------------
>Squid 3.5.11 Squid.conf:
># Squid Proxy Configuration
> 
>acl localnet src all
>#acl localnet src 172.16.50.0/24  # RFC1918 possible internal network
> 
> 
>acl SSL_ports port 443
>acl Safe_ports port 80                    # http
>acl Safe_ports port 443                  # https
>acl CONNECT method CONNECT
> 
># Deny requests to certain unsafe ports
>http_access deny !Safe_ports
> 
># Deny CONNECT to other than secure SSL ports
>http_access deny CONNECT !SSL_ports
> 
>http_access allow localnet
>http_access allow localhost
> 
># Lastly deny all other access to this proxy
>http_access deny all
> 
># Listens to port 3128
>http_port 3130
> 
>dns_nameservers 172.16.50.9 172.16.50.13
> 
>max_filedescriptors 3200
> 
># roll log file daily and keep 30 days
>logfile_rotate 30
> 
># access log format
>logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
> 
># debug_options             ALL,2
>---------------------------------------------------------------------------------------
>Squid 2.7.2 Squid.conf:
> 
># Squid Proxy Configuration
> 
>http_port    3128
> 
># acl and http_access to ("whitelist.txt")
>acl whitelist dstdomain  "c:/squid/etc/whitelist.txt"
>http_access        allow     whitelist
> 
># subnet source of proxy traffic
>acl all src 0.0.0.0/0.0.0.0
>acl localnet  src  0.0.0.0/0.0.0.0
> 
># acl directives for ports and protocols
>acl http      proto      http
>acl https     proto      https
>acl port_80   port       80
>acl sslports  port       443-444
>acl CONNECT   method     CONNECT
> 
>icp_port 0
>htcp_port 0
>snmp_port 0
> 
># rules allowing whitelist domains
>http_access allow http    port_80  whitelist localnet
>http_access allow https   sslports whitelist localnet
> 
># cache web pages directory
>cache_dir ufs C:/Squid/var/cache/squid 100 16 256
>cache_mem 64 MB
> 
># log file roll weekly
>access_log C:/squid/var/logs/access.log common
>logfile_rotate 7
> 
># catch-all rule
>http_access deny all
> 
> 
> 
> 
>_______________________________________________
>>squid-users mailing list
>>squid-users at lists.squid-cache.org
>>http://lists.squid-cache.org/listinfo/squid-users
>>
>
>


From emz at norma.perm.ru  Fri Dec 11 09:30:52 2015
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Fri, 11 Dec 2015 14:30:52 +0500
Subject: [squid-users] https and URL rewriting
Message-ID: <566A97CC.2090307@norma.perm.ru>

Hi.

I'm using URL rewriting to display instant messages to users. I'm doing
it using traffic interception and squid in transparent mode, so far I'm
intercepting http only. But I wonder, how it will behave with https,
since it's a tunneled connection ? I suppose, unless using ssl-Bum
technique, squid will never see the URL in such request ? But how would
url rewrite sequence behave itself in these conditions ?

Thanks.
Eugene.


From magiclink at outlook.com  Fri Dec 11 10:40:01 2015
From: magiclink at outlook.com (Magic Link)
Date: Fri, 11 Dec 2015 11:40:01 +0100
Subject: [squid-users] issue with video
In-Reply-To: <5669997A.70209@gmail.com>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>,
 <5668B48C.703@treenet.co.nz>
 <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>,
 <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl>, <5669997A.70209@gmail.com>
Message-ID: <DUB130-W4883D1369E0FC96B14F00ABDEA0@phx.gbl>

https://drive.google.com/file/d/0B5u1WrFLUfPiNWhXLVRJZnJETzA/view?usp=sharing
I test with squid 3.5.10 (from debian testing repository) et no luck :( it doesn't work too

To: squid-users at lists.squid-cache.org
From: yvoinov at gmail.com
Date: Thu, 10 Dec 2015 21:25:46 +0600
Subject: Re: [squid-users] issue with video


  
    
  
  
    

    -----BEGIN PGP SIGNED MESSAGE----- 

    Hash: SHA256 

     

    tar -cvf logs.tar access.log cache.log; gzip -9 logs.tar ->
    http://drive.google.com -> sahre+post URL's

    

    10.12.15 19:56, Magic Link ?????:

    > Where can i upload my logs ?
      It's too big for the mail.

      >

      > From: magiclink at outlook.com

      > To: squid3 at treenet.co.nz; squid-users at lists.squid-cache.org

      > Subject: RE: [squid-users] issue with video

      > Date: Thu, 10 Dec 2015 11:29:42 +0100

      >

      >

      >

      >

      > I activated the debug_option. I don't see anything particular
      in access.log, but i don't know what to do with the content of
      cache.logI 'v never compiled squid, is there a tutorial ? I used
      to use the debian stable repository, but get only the 3.4.8
      version for debian 8 (i can try with testing repository or another
      one if so)

      >

      > Thanks

      >> To: squid-users at lists.squid-cache.org

      >> From: squid3 at treenet.co.nz

      >> Date: Thu, 10 Dec 2015 12:09:00 +1300

      >> Subject: Re: [squid-users] issue with video

      >>

      >> On 10/12/2015 3:42 a.m., Magic Link wrote:

      >>> Hi,

      >>> i have a problem with this video
      http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/
      This video doesn't start with squid (3.4.8) on Debian 8 but does
      with a direct access to Internet.I don't know how to debug this
      issue.

      >>> Any clues ? Thanks                           

      >>>

      >>

      >> Check cache.log to see if any errors are being logged
      when you request it.

      >>

      >> Check access.log to see if the proxy is actually being
      contacted to

      >> fetch the video.

      >>

      >> "debug_options 11,2" to see what the request and reply
      headers are.

      >>

      >> If you can, try an upgrade. Current Squid is 3.5.12. I'm
      just mentioning

      >> this because its the nromal debugging step. I dont
      recommend a

      >> cross-install of the 3.5.12 package to Debian 8 - it
      needs a proper

      >> backport / recompile.

      >>

      >> The remaining steps get trickier and depend on the
      results of the above

      >> checks, or whether

      >>

      >>

      >> Amos

      >>

      >> _______________________________________________

      >> squid-users mailing list

      >> squid-users at lists.squid-cache.org

      >> http://lists.squid-cache.org/listinfo/squid-users

      >                                                       

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org

      > http://lists.squid-cache.org/listinfo/squid-users

    

    -----BEGIN PGP SIGNATURE-----


    Version: GnuPG v2


     

    iQEcBAEBCAAGBQJWaZl6AAoJENNXIZxhPexGGe4IAILsG3rcB+8WN0bn5++RHUie


    ts4SNFYvOgmDt48xfy1uOzpjUbDmdE7mWlYKsyJ7rVQq44KmsnxJXQVVC3xYaERl


    huvisfIIgIn+eGmdMmyQ07Vr0mN6f5bX1n7FiKI63/l0/7mD7EKgWmuiw1ISRuQ3


    FhUkpxNAowJ9uC3Rf03sborivigriR+WzjKyBlQWbqI9rHSoEZm/6JTmyTXmGX7y


    LjPejC1uaAK2VLyzGGCZPtABGZEpKP2XYnd0m6NWonhGhG2cFaA0zHQLE0BMMWRv


    sVoiqL/X3GqB5Zf8fYBx+Ulhk+gBff+gpRvkv4GT7J3bB/ploGPdtiJL9hhPQBM=


    =E3Ow


    -----END PGP SIGNATURE-----


    

  


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/aa9575a3/attachment.htm>

From RBackes at bond.de  Fri Dec 11 12:36:17 2015
From: RBackes at bond.de (Rainer Backes)
Date: Fri, 11 Dec 2015 13:36:17 +0100
Subject: [squid-users] Antw:  Kerberos-Authentication to AD 2012
In-Reply-To: <565F50C3020000AF0001EFE4@smtp-out.bond.de>
References: <565F50C3020000AF0001EFE4@smtp-out.bond.de>
Message-ID: <566AD151020000AF0001F172@smtp-out.bond.de>

Is there no one who could help me ?
>>> "Rainer Backes" <RBackes at bond.de> 02.12.2015 20:12 >>>
Hi,

I'm trying to build a Squid-Proxy that integrates with an Active
Directory - and I think I'm only one step from succeeding, but I still
get one error from negotiate_kerberos_auth.

Here is my config: (everything is hosted inside my VMware Workstation)
- Passwords here are only experimental.

Basic Installation

- Windows Server 2012R2 with default Active Directory, only one User:
me
- Windows 8.1/64 with IE and Firefox
- SLES 11 SP 4 as the Proxy

Squid Version: First I used the DBA Package available from OpenSuse
Build Service, this is 3.5.11. Then I downloaded the newest stable
source 3.5.12 and compliled it by myself (with configure options
--prefix=/usr/local/squid --with-included-ltdl ), OpenLdap and Kerberos
devel packages also installed from SLES11SP4 SDK. Error is the same on
both versions.

Preparation on Windows side: 

- Created user bsquid for the proxy, added SPN.
- with ktpass -princ HTTP/bsquid.bond.local at BOND.LOCAL -pass Sq1dcache
-mapuser bsquid -pType KRB5_NT_PRINCIPAL -crypto All -out bsquid.keytab
I build a keytab file that includes ALL available Crypto algorithms
(After I found out that 2012 uses AES256.... on default). Result from
command:
Targeting domain controller: W2K12-Squid.bond.local
Using legacy password setting method
Successfully mapped HTTP/bsquid.bond.local to bsquid.
Key created.
Key created.
Key created.
Key created.
Key created.
Output keytab to bsquid.keytab:
Keytab version: 0x502
keysize 60 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x1 (DES-CBC-CRC) keylength 8 (0x0
7cbdf6d7c8f0b75)
keysize 60 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x3 (DES-CBC-MD5) keylength 8 (0x0
7cbdf6d7c8f0b75)
keysize 68 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x17 (RC4-HMAC) keylength 16 (0xdc
2fdd6643b8e3e18184d38b989b6f87)
keysize 84 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x12 (AES256-SHA1) keylength 32 (0
x3cfb4221e4f8ce0c8ce6a2a4b231872b1fe979c013ee965be8469bac4fd0e9ec)
keysize 68 HTTP/bsquid.bond.local at BOND.LOCAL ptype 1
(KRB5_NT_PRINCIPAL) vno 10 etype 0x11 (AES128-SHA1) keylength 16 (0
xc32c8f7a8a039a7921148d863a5d6f78)

with this keytab a kinit from the SLES box works without errors.

The negotiate line from squid.conf is as follows:
auth_param negotiate program
/usr/local/squid/libexec/negotiate_kerberos_auth -d -s
HTTP/bsquid.bond.local	 

I also tried to add the Kerberos realm - that did not make any
difference.

My krb5.conf:

[libdefaults]
	    ticket_lifetime = 24000
	    default_realm = BOND.LOCAL
	    default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac
des-cbc-crc des-cbc-md5
	    default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac
des-cbc-crc des-cbc-md5
	    permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac
des-cbc-crc des-cbc-md5

;	    default_tkt_enctypes = rc4-hmac arcfour-hmac-md5 des-cbc-crc
des-cbc-md5
;	    default_tgs_enctypes = rc4-hmac arcfour-hmac-md5 des-cbc-crc
des-cbc-md5

[domain_realm]
	    .bond.local = BOND.LOCAL
	    bond.local = BOND.LOCAL

[realms]
	    BOND.LOCAL = {
			    kdc = w2k12-squid.bond.local
			    admin_server = w2k12-squid.bond.local
			    default_domain = bond.local
	    }

[logging]
    kdc = FILE:/var/log/krb5/krb5kdc.log
    admin_server = FILE:/var/log/krb5/kadmind.log
    default = FILE:/var/log/krb5/krb5libs.log
;    default = SYSLOG:NOTICE:DAEMON


Set the environment variable for the keytab and starting squid -N
inside a GUI-Window
bsquid:/usr/local/squid/sbin # export
KRB5_KTNAME=/usr/local/squid/etc/bsquid.keytab
bsquid:/usr/local/squid/sbin # ./squid -N



On the workstation tried to open a Website, get the following error:
negotiate_kerberos_auth.cc(487): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: INFO: Starting version 3.0.4sq
negotiate_kerberos_auth.cc(546): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: INFO: Setting keytab to
/usr/local/squid/etc/bsquid.keytab
negotiate_kerberos_auth.cc(610): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: DEBUG: Got 'YR
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'
from squid (length: 2155).
negotiate_kerberos_auth.cc(663): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: DEBUG: Decode
'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'
(decoded length: 1614).
negotiate_kerberos_auth.cc(180): pid=122356 :2015/12/02 20:00:41|
negotiate_kerberos_auth: ERROR: gss_acquire_cred() failed: Unspecified
GSS failure.  Minor code may provide more information. Permission
denied
2015/12/02 20:00:41| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: gss_acquire_cred() failed:
Unspecified GSS failure.  Minor code may provide more information.
Permission denied; }}

In the same GUI window, negotiate_kerberos_auth_test works:

bsquid:/usr/local/squid/sbin #
/usr/local/squid/libexec/negotiate_kerberos_auth_test bsquid.bond.local
| awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' |
/usr/local/squid/libexec/negotiate_kerberos_auth -d  -s
HTTP/bsquid.bond.local
negotiate_kerberos_auth.cc(487): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: INFO: Starting version 3.0.4sq
negotiate_kerberos_auth.cc(546): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: INFO: Setting keytab to
/usr/local/squid/etc/bsquid.keytab
negotiate_kerberos_auth.cc(610): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: DEBUG: Got 'YR
YIIFOQYGKwYBBQUCoIIFLTCCBSmgHzAdBgkqhkiG9xIBAgIGBSsFAQUCBgkqhkiC9xIBAgKiggUEBIIFAGCCBPwGCSqGSIb3EgECAgEAboIE6zCCBOegAwIBBaEDAgEOogcDBQAAAAAAo4ID/mGCA/owggP2oAMCAQWhDBsKQk9ORC5MT0NBTKIkMCKgAwIBA6EbMBkbBEhUVFAbEWJzcXVpZC5ib25kLmxvY2Fso4IDuTCCA7WgAwIBEqEDAgEKooIDpwSCA6Mf94bC+59KaQjsnQcWkXVcQknzpZjaEaz7bbGPyUlvR+ac8Y+z7vp0807CtBysvSMTgRCU+ghgUculGmncFwXSHoIpjCAg1faW/+COorCBjnBsOGzy3/sHUstVgnT/+cbqVBk/8f2v5b7k/VmejnADQyP/8T2yphyA9xBRaPOnjQiqtVFeheVnDA3+6X8bR+IlHCC7c/KJJBFUO/nRbM7lnb2yzW/nLVHaYlzw3+o5MiKu1FYdSLGil5jFIxjhqUzOpf87Z1ax/Ojzco3gVZxSDvRNp6EJ5Nea7LVESNQGto24Cru2ae4lO0oXe7An8VFHm4tVikvZQzHprNgUQITQlVzQ0CjztGuFpIrw/xt/ie5K5XziH76YaAxpzaiVfXG02V5pdY2ntSvVN/+IqSwQ8iRxkB+ZUQdLy0gR5dPXgjW/lU2NNWcAvfJWszf8y7hzu85GCy+fQXfRMY0g6CgsUncFmQy+x6E74Ft5XD/qOnW+66+HAxA6pmzBRvos9+drul3RQvVaGwaDo5Z86bKERZFKz02tmQUXFt+fEtqAqYXfsiXKq/HmxpZF3XklrQhoolGS41JTfhDmKeN4NtQYBM/pDMCo0HYWNMKthHvKXDhhLuu+WlT41vw5fl+uDiBOEOkVMhVsxe4M+Qsdj1z/DDqBgrVpYOcSF/rTC+8wETuciuUpZKecZkhLeT3VdIYMzNnhwSBG00bktICxPTuRXZC+Qfp+E+gsGk37r7bArYxtbjHjhj3WRkRTqfk11/6j6Bq0EDZV/o1OYOSulcuXulPTKCpQ209sJJmKEqjVgdFq697HIdC1eB7m9jETJH8YzqVLx500DEDipj8VeDLyxWPcM5P4HKeLTyMxjW72nZwlSBfbpIO2ogh6j5X0+f4/nuGW43/kX7LG9K+7NoRWofmasE2fUjq2NgbL+Qg5r4nfL3byE+LR5tg5xz9tUe+WYq+FpS4HSqfcxxUhDadXW2RgKsohNR3+cqBI0jDS/IcHu8LnicRuIVIJes2Bpf3KnThA9JqlUI5GcySWKvA4S7SOvSRvqipoA412/OMiUA4JSkV98BAFZaYt5+x6TswIMAz+xngrr39oWSrnnuem7A7vOwaG2pAa4rnQlBMKWZCztO7GLjQDeJyjNFDdyhT5tM31t0gvfH1seulRlAMXR8SJrraj320For2iVZK9d9+Op2xgsfb1VfPNBoIw+LuCpAIvwdL+PgtLcXUUxdklXkhTpIHPMIHMoAMCARKigcQEgcFbbiCFd2nHRDkZiUP7oFMEf3xmoeg7/fTpZT/VUpyFeVqzKZyBt3g6WLlFa++rlZm8aRxh65oKYk6ptRZcqje02XmhQpfRkZG4+NRiu175DgGvk4pNsZfPQSKxAP1WDZ2jVRy4U5+R49NbLodhRh0KFV9R4fug30x8uxQAJVTYu952i1mrx+PD/yS6UT2KLeDpVqfFtpnlVxeYjgK7hJoLb0qgN0fJbQDEqM9vrZ396z27pNOZXI7wa06I7roQFSlZ'
from squid (length: 1791).
negotiate_kerberos_auth.cc(663): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: DEBUG: Decode
'YIIFOQYGKwYBBQUCoIIFLTCCBSmgHzAdBgkqhkiG9xIBAgIGBSsFAQUCBgkqhkiC9xIBAgKiggUEBIIFAGCCBPwGCSqGSIb3EgECAgEAboIE6zCCBOegAwIBBaEDAgEOogcDBQAAAAAAo4ID/mGCA/owggP2oAMCAQWhDBsKQk9ORC5MT0NBTKIkMCKgAwIBA6EbMBkbBEhUVFAbEWJzcXVpZC5ib25kLmxvY2Fso4IDuTCCA7WgAwIBEqEDAgEKooIDpwSCA6Mf94bC+59KaQjsnQcWkXVcQknzpZjaEaz7bbGPyUlvR+ac8Y+z7vp0807CtBysvSMTgRCU+ghgUculGmncFwXSHoIpjCAg1faW/+COorCBjnBsOGzy3/sHUstVgnT/+cbqVBk/8f2v5b7k/VmejnADQyP/8T2yphyA9xBRaPOnjQiqtVFeheVnDA3+6X8bR+IlHCC7c/KJJBFUO/nRbM7lnb2yzW/nLVHaYlzw3+o5MiKu1FYdSLGil5jFIxjhqUzOpf87Z1ax/Ojzco3gVZxSDvRNp6EJ5Nea7LVESNQGto24Cru2ae4lO0oXe7An8VFHm4tVikvZQzHprNgUQITQlVzQ0CjztGuFpIrw/xt/ie5K5XziH76YaAxpzaiVfXG02V5pdY2ntSvVN/+IqSwQ8iRxkB+ZUQdLy0gR5dPXgjW/lU2NNWcAvfJWszf8y7hzu85GCy+fQXfRMY0g6CgsUncFmQy+x6E74Ft5XD/qOnW+66+HAxA6pmzBRvos9+drul3RQvVaGwaDo5Z86bKERZFKz02tmQUXFt+fEtqAqYXfsiXKq/HmxpZF3XklrQhoolGS41JTfhDmKeN4NtQYBM/pDMCo0HYWNMKthHvKXDhhLuu+WlT41vw5fl+uDiBOEOkVMhVsxe4M+Qsdj1z/DDqBgrVpYOcSF/rTC+8wETuciuUpZKecZkhLeT3VdIYMzNnhwSBG00bktICxPTuRXZC+Qfp+E+gsGk37r7bArYxtbjHjhj3WRkRTqfk11/6j6Bq0EDZV/o1OYOSulcuXulPTKCpQ209sJJmKEqjVgdFq697HIdC1eB7m9jETJH8YzqVLx500DEDipj8VeDLyxWPcM5P4HKeLTyMxjW72nZwlSBfbpIO2ogh6j5X0+f4/nuGW43/kX7LG9K+7NoRWofmasE2fUjq2NgbL+Qg5r4nfL3byE+LR5tg5xz9tUe+WYq+FpS4HSqfcxxUhDadXW2RgKsohNR3+cqBI0jDS/IcHu8LnicRuIVIJes2Bpf3KnThA9JqlUI5GcySWKvA4S7SOvSRvqipoA412/OMiUA4JSkV98BAFZaYt5+x6TswIMAz+xngrr39oWSrnnuem7A7vOwaG2pAa4rnQlBMKWZCztO7GLjQDeJyjNFDdyhT5tM31t0gvfH1seulRlAMXR8SJrraj320For2iVZK9d9+Op2xgsfb1VfPNBoIw+LuCpAIvwdL+PgtLcXUUxdklXkhTpIHPMIHMoAMCARKigcQEgcFbbiCFd2nHRDkZiUP7oFMEf3xmoeg7/fTpZT/VUpyFeVqzKZyBt3g6WLlFa++rlZm8aRxh65oKYk6ptRZcqje02XmhQpfRkZG4+NRiu175DgGvk4pNsZfPQSKxAP1WDZ2jVRy4U5+R49NbLodhRh0KFV9R4fug30x8uxQAJVTYu952i1mrx+PD/yS6UT2KLeDpVqfFtpnlVxeYjgK7hJoLb0qgN0fJbQDEqM9vrZ396z27pNOZXI7wa06I7roQFSlZ'
(decoded length: 1341).
AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== rbackes at BOND.LOCAL
negotiate_kerberos_auth.cc(783): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: DEBUG: AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg==
rbackes at BOND.LOCAL
negotiate_kerberos_auth.cc(610): pid=122362 :2015/12/02 20:04:17|
negotiate_kerberos_auth: DEBUG: Got 'QQ' from squid (length: 2).
BH quit command
bsquid:/usr/local/squid/sbin # 

The Windows client has some kerberos tickets avail:
C:\Windows\system32>klist

Aktuelle Anmelde-ID ist 0:0x37b196

Zwischengespeicherte Tickets: (4)

#0>	 Client: RBackes @ BOND.LOCAL
	    Server: krbtgt/BOND.LOCAL @ BOND.LOCAL
	    KerbTicket (Verschl?sselungstyp): AES-256-CTS-HMAC-SHA1-96
	    Ticketkennzeichen 0x40e10000 -> forwardable renewable
initial pre_authent name_canonicalize
	    Startzeit: 12/2/2015 18:39:42 (lokal)
	    Endzeit:   12/3/2015 4:39:42 (lokal)
	    Erneuerungszeit: 12/9/2015 18:39:42 (lokal)
	    Sitzungsschl?sseltyp: AES-256-CTS-HMAC-SHA1-96
	    Cachekennzeichen: 0x1 -> PRIMARY
	    KDC aufgerufen: W2K12-SQUID

#1>	 Client: RBackes @ BOND.LOCAL
	    Server: HTTP/bsquid.bond.local @ BOND.LOCAL
	    KerbTicket (Verschl?sselungstyp): AES-256-CTS-HMAC-SHA1-96
	    Ticketkennzeichen 0x40a10000 -> forwardable renewable
pre_authent name_canonicalize
	    Startzeit: 12/2/2015 18:39:46 (lokal)
	    Endzeit:   12/3/2015 4:39:42 (lokal)
	    Erneuerungszeit: 12/9/2015 18:39:42 (lokal)
	    Sitzungsschl?sseltyp: AES-256-CTS-HMAC-SHA1-96
	    Cachekennzeichen: 0
	    KDC aufgerufen: W2K12-Squid.bond.local

#2>	 Client: RBackes @ BOND.LOCAL
	    Server: ldap/W2K12-Squid.bond.local @ BOND.LOCAL
	    KerbTicket (Verschl?sselungstyp): AES-256-CTS-HMAC-SHA1-96
	    Ticketkennzeichen 0x40a50000 -> forwardable renewable
pre_authent ok_as_delegate name_canonicalize
	    Startzeit: 12/2/2015 18:39:44 (lokal)
	    Endzeit:   12/3/2015 4:39:42 (lokal)
	    Erneuerungszeit: 12/9/2015 18:39:42 (lokal)
	    Sitzungsschl?sseltyp: AES-256-CTS-HMAC-SHA1-96
	    Cachekennzeichen: 0
	    KDC aufgerufen: W2K12-Squid.bond.local

#3>	 Client: RBackes @ BOND.LOCAL
	    Server: LDAP/W2K12-Squid.bond.local/bond.local @ BOND.LOCAL
	    KerbTicket (Verschl?sselungstyp): AES-256-CTS-HMAC-SHA1-96
	    Ticketkennzeichen 0x40a50000 -> forwardable renewable
pre_authent ok_as_delegate name_canonicalize
	    Startzeit: 12/2/2015 18:39:44 (lokal)
	    Endzeit:   12/3/2015 4:39:42 (lokal)
	    Erneuerungszeit: 12/9/2015 18:39:42 (lokal)
	    Sitzungsschl?sseltyp: AES-256-CTS-HMAC-SHA1-96
	    Cachekennzeichen: 0
	    KDC aufgerufen: W2K12-Squid.bond.local

C:\Windows\system32>


Anyone an idea ?

Thanks, Rainer



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/8c131fba/attachment.htm>

From dweimer at dweimer.net  Fri Dec 11 12:38:34 2015
From: dweimer at dweimer.net (dweimer)
Date: Fri, 11 Dec 2015 06:38:34 -0600
Subject: [squid-users] squid reverse proxy infront of exchange 2010
In-Reply-To: <CAJ+Q1PUEuzgBuQNKAyg0nVbBRuExYmik0w0abBZAHe_=QcRo_g@mail.gmail.com>
References: <CAJ+Q1PWi8JcURS02LHc=Qj--YcKNT=7J7SkOV5ycqGx7jHCung@mail.gmail.com>
 <CAJ+Q1PUxd5GxMMZoA3B_COU1SLj6w-B=Sg4hNPbHaL3Om83Zuw@mail.gmail.com>
 <CAJ+Q1PXL73L96TBmRpc2x06XRDvqVd3Y7BwzHyn4YgqAtn17-A@mail.gmail.com>
 <56669602.9020407@treenet.co.nz>
 <CAJ+Q1PXO1cAshLxC2Tk+uBXTaPPZaNJZgArguMpyYxr7hRfgzA@mail.gmail.com>
 <6ede17791f7541fa080516d4ac0461cf@dweimer.net>
 <CAJ+Q1PUfhUWMQQ7yMyvNJPZuF52xDxyvnv_v2Nem3MzB0h5ouQ@mail.gmail.com>
 <CAJ+Q1PUR2XSRvKT=A9sYb6SPFLcjTbLXEKaH454h_poNCg7Ebw@mail.gmail.com>
 <991f0fbb2c0b831db4973e5895369ce8@dweimer.net>
 <CAJ+Q1PUEuzgBuQNKAyg0nVbBRuExYmik0w0abBZAHe_=QcRo_g@mail.gmail.com>
Message-ID: <2a1a049d3df10912700ab8bf1137cf5e@dweimer.net>

On 2015-12-10 10:29 pm, Alex Samad wrote:
> Hi
> 
> I did the change over today.
> Tested with Window 7 + exchange 2010 and it wouldn't connect whilst
> there was no tls1 !
> 
> interesting IE worked against the web site .... so ..
> 
> Did you come across this issues ?
> 
> 
> On 11 December 2015 at 11:09, dweimer <dweimer at dweimer.net> wrote:
>> On 2015-12-10 4:24 pm, Alex Samad wrote:
>>> 
>>> Hi
>>> 
>>> Answer my own question
>>> http://www.squid-cache.org/Versions/v3/3.5/cfgman/http_port.html
>>> 
>>> seems like there is a no-vhost, I presume vhost turns it on
>>> 
>>> 
>>> On 11 December 2015 at 09:23, Alex Samad <alex at samad.com.au> wrote:
>>>> 
>>>> Hi
>>>> 
>>>> 
>>>> On 10 December 2015 at 23:44, dweimer <dweimer at dweimer.net> wrote:
>>>>> 
>>>>> https_port 10.50.20.12:443 accel defaultsite=mail.mydomain.com \
>>>>>  cert=/certs/wildcard.certificate.crt \
>>>>>  key=/certs/wildcard.certificate.key \
>>>>> 
>>>>> options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE 
>>>>> \
>>>>>  dhparams=/usr/local/etc/squid/dh.param \
>>>>>  cipher=ALL:!aNULL:!eNULL:!LOW:!EXP:!ADH:+HIGH:+MEDIUM:!SSLv2:!RC4 
>>>>> \
>>>>>  vhost
>>>> 
>>>> 
>>>> what is the vhost option can't find it on the doco page
>>>> http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html
>> 
>> 
>> It maybe on by default now, unless you are doing multiple host names, 
>> its
>> not necessary. The setup on mine is using a wildcard certificate and 
>> is
>> proxying multiple domains names.
>> 

So Outlook wouldn't connect using the Exchange Proxy method with RPC 
over HTTPS?

Which version of office? Did you make sure all the windows and office 
updates are installed?

-- 
Thanks,
    Dean E. Weimer
    http://www.dweimer.net/


From squid3 at treenet.co.nz  Fri Dec 11 13:20:17 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 02:20:17 +1300
Subject: [squid-users] squid 3.4, dstdomain
In-Reply-To: <OF270E7043.34772203-ONC1257F18.002F0382-C1257F18.00317014@asl.bergamo.it>
References: <OF270E7043.34772203-ONC1257F18.002F0382-C1257F18.00317014@asl.bergamo.it>
Message-ID: <566ACD91.4080904@treenet.co.nz>

On 11/12/2015 10:00 p.m., Massimo.Sala wrote:
>> Massimo
> 
>>> 2015/12/10 10:33:49| ERROR: '.addons.mozilla.org' is a subdomain of
>>> 'addons.mozilla.org'
> 
> 
> 
> Francesco aka Kinkie
> 
>> No bug, it is really intentional: ".addons.mozilla.org" also matches
>> "addons.mozilla.org" (without the dot).
> 
> 
> Francesco, thank you for the explanation.
> 
> Is it possible to add it to the official docs ?

You mean like the FAQ entry on how to use dstdomain?

<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Squid_doesn.27t_match_my_subdomains>

Amos



From squid3 at treenet.co.nz  Fri Dec 11 13:47:05 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 02:47:05 +1300
Subject: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than Squid
 64-bit (3.5.11)
In-Reply-To: <81537556.619395.1449825391887.JavaMail.yahoo@mail.yahoo.com>
References: <65A6F958-E262-46D7-A05E-08C4C34E4061@yahoo.com>
 <81537556.619395.1449825391887.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <566AD3D9.4020609@treenet.co.nz>

On 11/12/2015 10:16 p.m., TarotApprentice wrote:
> Sorry should have replied to the list.
> 
> MarkJ
>  
> ----- Forwarded Message -----
>> From: Tarot Apprentice
>>
>> Looking at the startup logs the 3.4.11 says "store logging disabled" (it had an error) so would account for some of the difference.
>>


So the builds are different:

* OS integration:
Squid-2 builds from Acme being made with Visual Studio. So they have
native Windows API integration.
Squid-3 builds by Diladele are using Cgwin. So a whole OS abstraction
layer between Squid and Windows.

* HTTP 1.x:
Squid-2 is HTTP/1.0-only.
Squid-3 does HTTP/1.1 and does a whole lot more protocol processing to
detect whether 1.1 features are being used.

* X-bit:
As you already said 32-bit vs 64-bit. I read some research recently that
showed 64-bit is only faster in benchmarks when there is hardware layer
retardation being applied to emulating the 32-bit operations on the same
hardware. So YMMV.

* Features:
Squid-2 has less features than Squid-3.5. It also has less of them
enabled by default. YMMV.
 - This includes IPv6 support. Squid-3 waits for both IPv4 and IPv6
responses from DNS. Squid-2 will not be doing that.


The configs are different:

* DNS:
Squid-2 is configured to use the Windows Registry DNS servers (default).
Squid-3 is explicitly configured with dns_nameservers to override that
to use only a sub-set of the Registry listed NS.
 - if that one DNS server is running much faster than the others it can
account for a lot of speed variance.

* Cache:
Squid-2 is using a 100MB disk cache + 64MB RAM cache.
Squid-3 is using only a 256MB RAM cache.
 - Usually this should count against Squid-2 in most traffic. But if
your Squid are processing objects over 4MB size, then Squid-2 has the
advantage of storing them to HDD and fast-ish HITs later. Where Squid-3
has to MISS.


>>
>> On 11 Dec 2015, at 12:16 PM, Patrick Flaherty wrote:
>>
>>
>> Hello,
>>
>> Just following up on my slow 3.5.11 Squid server.  I loaded the 32-bit 2.7.2 version on the same box and it?s so much faster for me. Its 4 to 5 times faster for me on the same machine. Please any help appreciated. Amos, I think I cleaned up my 3.5.11 squid.conf properly. I think my 2.7.2 squid.conf needs work.
>> See below Startup Cache logs from both 3.5.11 and 2.7.2 and also the squid.conf files from 3.5.11 and 2.7.2.
>>

Both configs look roughly equivalent to me. Except the Squid-3 config
defines localnet as being "all" then does an "allow localnet". Making it
an open proxy. The Squid-2 is at least restricted to the whitelist domains.

Though I dont think that is affecting your results. Uunless someone
figured out how to open a tunnel through it already and is using up the
bandwidth with an not-yet-logged huge transaction.

Amos



From squid3 at treenet.co.nz  Fri Dec 11 13:50:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 02:50:24 +1300
Subject: [squid-users] https and URL rewriting
In-Reply-To: <566A97CC.2090307@norma.perm.ru>
References: <566A97CC.2090307@norma.perm.ru>
Message-ID: <566AD4A0.3010906@treenet.co.nz>

On 11/12/2015 10:30 p.m., Eugene M. Zheganin wrote:
> Hi.
> 
> I'm using URL rewriting to display instant messages to users. I'm doing
> it using traffic interception and squid in transparent mode, so far I'm
> intercepting http only. But I wonder, how it will behave with https,
> since it's a tunneled connection ?

Depends.

> I suppose, unless using ssl-Bum
> technique, squid will never see the URL in such request ?

Correct.

> But how would
> url rewrite sequence behave itself in these conditions ?
> 

That Depends. Some well written re-writers know how to handle
authority-URI (skip the rewrite). Most don't (try to rewite and mangle
the URI). So the answer is usually "badly".

Amos



From fabietto82 at gmail.com  Fri Dec 11 14:08:44 2015
From: fabietto82 at gmail.com (Fabio Bucci)
Date: Fri, 11 Dec 2015 15:08:44 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
Message-ID: <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>

No suggestions?

2015-12-07 14:57 GMT+01:00 Fabio Bucci <fabietto82 at gmail.com>:

> Thanks Amos.
> So, what do you suggest? Implement kerberos authetication instead NTLM one?
>
> I have to check if netscaler is able to perform that kind hack you wrote
> before.
>
> Thanks again,
> Fabio
>
> 2015-12-05 7:22 GMT+01:00 Amos Jeffries <squid3 at treenet.co.nz>:
>
>> On 5/12/2015 5:39 a.m., Fabio Bucci wrote:
>> > Thanks Amos.
>> > Actually my load balancing is configured to perform round robin
>> balancing
>> > between the two nodes. I added a session persistance by source ip in
>> order
>> > to avoid to login again with some sites.
>> >
>> > my squid.conf is very simple:
>> > auth_param ntlm program /usr/bin/ntlm_auth
>> > --helper-protocol=squid-2.5-ntlmssp
>> > auth_param ntlm children 100
>> > auth_param ntlm keep_alive off
>> >
>> > acl auth proxy_auth REQUIRED
>> >
>> > http_access allow auth
>> >
>>
>> Okay. That *should* work. With some NTLM-specific caveats.
>>
>>
>> > forwarded_for on
>> > follow_x_forwarded_for allow netscaler
>> >
>>
>> If the LB is touching the traffic enough to add headers then it is a
>> proxy. NTLM does not work at all well through proxies. NTLM as a whole
>> is based on the assumption that there is one (and only one) TCP
>> connection between it and the proxy - the credentials are tied to the
>> TCP connection state.
>>
>> There is one VERY slim hack that lets NTLM pass straight through a
>> frontend proxy/LB. That is by pinning the LB's inbound and outbound TCP
>> connections together. This is not just session persistence, but absolute
>> prohibition on any other traffic (even from other connections by the
>> same client) being sent to that outbound LB->proxy connection. Some LB
>> can do it, some can't.
>>
>>
>> I recommend advertising both/all proxy IPs to the clients and letting
>> each select the one(s) it wants to contact. That way the client can
>> perform NTLM directly to the Squid.
>>
>>
>> On the other hand NTLM was deprecated back in 2006, you should try
>> migrating to Negotiate/Kerberos. Kerberos is a bit of a learning curve
>> and can be tricky working with older client software. But is *way* more
>> efficient and friendlier to HTTP (but still not fully).
>>
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/02b663ed/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec 11 14:39:02 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 03:39:02 +1300
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
 <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
Message-ID: <566AE006.80609@treenet.co.nz>

On 12/12/2015 3:08 a.m., Fabio Bucci wrote:
> No suggestions?
> 

I've already suggested several times to use Kerberos. But the choice is
yours.

Amos



From fabietto82 at gmail.com  Fri Dec 11 14:42:37 2015
From: fabietto82 at gmail.com (Fabio Bucci)
Date: Fri, 11 Dec 2015 15:42:37 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <566AE006.80609@treenet.co.nz>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
 <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
 <566AE006.80609@treenet.co.nz>
Message-ID: <CAJrMMC_BPiU49yd6w8dHyqbUbeujTsq41fjjdULvk9L9Eu5dSA@mail.gmail.com>

Thank Amos i know you suggested kerberos. How can i implement it instead of
LDAP?

2015-12-11 15:39 GMT+01:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 12/12/2015 3:08 a.m., Fabio Bucci wrote:
> > No suggestions?
> >
>
> I've already suggested several times to use Kerberos. But the choice is
> yours.
>
> Amos
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/2ec00e04/attachment.htm>

From mcsnv96 at afo.net  Fri Dec 11 15:48:08 2015
From: mcsnv96 at afo.net (Mike)
Date: Fri, 11 Dec 2015 09:48:08 -0600
Subject: [squid-users] Squid 32-bit (2.7.2) much faster than Squid
 64-bit (3.5.11)
In-Reply-To: <004e01d133b1$8a9a48d0$9fceda70$@verizon.net>
References: <004e01d133b1$8a9a48d0$9fceda70$@verizon.net>
Message-ID: <566AF038.9030502@afo.net>

I believe one possible issue is here:
max_filedescriptors 3200
Need to have squid and the OS working together, adding it to squid 
without the proper setting in the OS causes delays and slow performance. 
I would suggest commenting this out and restarting the squid service to 
see if that helps.

I've found that entry does not work well in Windows, but it should in 
linux. Also with my company we moved away from Win Server because of 
similar and other unrelated issues, so now are linux only (except for 
one out of hundreds of servers).

Mike



On 12/10/2015 19:16 PM, Patrick Flaherty wrote:
>
> Hello,
>
> Just following up on my slow 3.5.11 Squid server.  I loaded the 32-bit 
> 2.7.2 version on the same box and it?s so much faster for me. Its 4 to 
> 5 times faster for me on the same machine. Please any help 
> appreciated. Amos, I think I cleaned up my 3.5.11 squid.conf properly. 
> I think my 2.7.2 squid.conf needs work.
>
> See below Startup Cache logs from both 3.5.11 and 2.7.2 and also the 
> squid.conf files from 3.5.11 and 2.7.2.
>
> Thank You,
>
> Patrick
>
> Squid 3.5.11 Startup Cache Log:
>
> 2015/12/10 19:50:09 kid1| Current Directory is 
> /cygdrive/c/Windows/system32
>
> 2015/12/10 19:50:09 kid1| Starting Squid Cache version 3.5.11 for 
> x86_64-unknown-cygwin...
>
> 2015/12/10 19:50:09 kid1| Service Name: squid
>
> 2015/12/10 19:50:09 kid1| Process ID 1968
>
> 2015/12/10 19:50:09 kid1| Process Roles: worker
>
> 2015/12/10 19:50:09 kid1| With 3200 file descriptors available
>
> 2015/12/10 19:50:09 kid1| Initializing IP Cache...
>
> 2015/12/10 19:50:09 kid1| parseEtcHosts: /etc/hosts: (2) No such file 
> or directory
>
> 2015/12/10 19:50:09 kid1| DNS Socket created at [::], FD 5
>
> 2015/12/10 19:50:09 kid1| DNS Socket created at 0.0.0.0, FD 6
>
> 2015/12/10 19:50:09 kid1| Adding nameserver 172.16.50.9 from squid.conf
>
> 2015/12/10 19:50:09 kid1| Adding nameserver 172.16.50.13 from squid.conf
>
> 2015/12/10 19:50:09 kid1| Logfile: opening log 
> daemon:/var/log/squid/access.log
>
> 2015/12/10 19:50:09 kid1| Logfile Daemon: opening log 
> /var/log/squid/access.log
>
> 2015/12/10 19:50:09 kid1| WARNING: no_suid: setuid(0): (22) Invalid 
> argument
>
> 2015/12/10 19:50:09 kid1| Store logging disabled
>
> 2015/12/10 19:50:09 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 
> objects
>
> 2015/12/10 19:50:09 kid1| Target number of buckets: 1008
>
> 2015/12/10 19:50:09 kid1| Using 8192 Store buckets
>
> 2015/12/10 19:50:09 kid1| Max Mem  size: 262144 KB
>
> 2015/12/10 19:50:09 kid1| Max Swap size: 0 KB
>
> 2015/12/10 19:50:09 kid1| Using Least Load store dir selection
>
> 2015/12/10 19:50:09 kid1| Current Directory is 
> /cygdrive/c/Windows/system32
>
> 2015/12/10 19:50:09 kid1| Finished loading MIME types and icons.
>
> 2015/12/10 19:50:09 kid1| HTCP Disabled.
>
> 2015/12/10 19:50:09 kid1| Squid plugin modules loaded: 0
>
> 2015/12/10 19:50:09 kid1| Adaptation support is off.
>
> 2015/12/10 19:50:09 kid1| Accepting HTTP Socket connections at 
> local=[::]:3130 remote=[::] FD 10 flags=9
>
> 2015/12/10 19:50:11 kid1| storeLateRelease: released 0 objects
>
> -----------------------------------------------------------------------------------------------------------
>
> Squid 2.7.2 Startup Cache Log:
>
> 2015/12/10 19:50:38| Starting Squid Cache version 2.7.STABLE8 for 
> i686-pc-winnt...
>
> 2015/12/10 19:50:38| Running as Squid-Proxy-2.7.2 Windows System 
> Service on Windows Server 2008
>
> 2015/12/10 19:50:38| Service command line is:
>
> 2015/12/10 19:50:38| Process ID 2644
>
> 2015/12/10 19:50:38| With 2048 file descriptors available
>
> 2015/12/10 19:50:38| With 2048 CRT stdio descriptors available
>
> 2015/12/10 19:50:38| Windows sockets initialized
>
> 2015/12/10 19:50:38| Using select for the IO loop
>
> 2015/12/10 19:50:38| Performing DNS Tests...
>
> 2015/12/10 19:50:38| Successful DNS name lookup tests...
>
> 2015/12/10 19:50:38| DNS Socket created at 0.0.0.0, port 50961, FD 5
>
> 2015/12/10 19:50:38| Adding DHCP nameserver 172.16.50.9 from Registry
>
> 2015/12/10 19:50:38| Adding DHCP nameserver 172.16.50.13 from Registry
>
> 2015/12/10 19:50:38| Adding DHCP nameserver 4.2.2.3 from Registry
>
> 2015/12/10 19:50:38| Adding domain  from Registry
>
> 2015/12/10 19:50:38| User-Agent logging is disabled.
>
> 2015/12/10 19:50:38| Referer logging is disabled.
>
> 2015/12/10 19:50:38| logfileOpen: opening log C:/squid/var/logs/access.log
>
> 2015/12/10 19:50:38| Unlinkd pipe opened on FD 8
>
> 2015/12/10 19:50:38| Swap maxSize 102400 + 65536 KB, estimated 12918 
> objects
>
> 2015/12/10 19:50:38| Target number of buckets: 645
>
> 2015/12/10 19:50:38| Using 8192 Store buckets
>
> 2015/12/10 19:50:38| Max Mem  size: 65536 KB
>
> 2015/12/10 19:50:38| Max Swap size: 102400 KB
>
> 2015/12/10 19:50:38| Local cache digest enabled; rebuild/rewrite every 
> 3600/3600 sec
>
> 2015/12/10 19:50:38| logfileOpen: opening log c:/squid/var/logs/store.log
>
> 2015/12/10 19:50:38| Rebuilding storage in C:/Squid/var/cache/squid 
> (DIRTY)
>
> 2015/12/10 19:50:38| Using Least Load store dir selection
>
> 2015/12/10 19:50:38| Current Directory is C:\squid\sbin
>
> 2015/12/10 19:50:38| Loaded Icons.
>
> 2015/12/10 19:50:38| Accepting proxy HTTP connections at 0.0.0.0, port 
> 3128, FD 14.
>
> 2015/12/10 19:50:38| HTCP Disabled.
>
> 2015/12/10 19:50:38| Ready to serve requests.
>
> 2015/12/10 19:50:38| Done reading C:/Squid/var/cache/squid swaplog (0 
> entries)
>
> 2015/12/10 19:50:38| Finished rebuilding storage from disk.
>
> 2015/12/10 19:50:38|         0 Entries scanned
>
> 2015/12/10 19:50:38|         0 Invalid entries.
>
> 2015/12/10 19:50:38|         0 With invalid flags.
>
> 2015/12/10 19:50:38|         0 Objects loaded.
>
> 2015/12/10 19:50:38|         0 Objects expired.
>
> 2015/12/10 19:50:38|         0 Objects cancelled.
>
> 2015/12/10 19:50:38|         0 Duplicate URLs purged.
>
> 2015/12/10 19:50:38|         0 Swapfile clashes avoided.
>
> 2015/12/10 19:50:38|   Took 0.0 seconds ( 0.0 objects/sec).
>
> 2015/12/10 19:50:38| Beginning Validation Procedure
>
> 2015/12/10 19:50:38|   Completed Validation Procedure
>
> 2015/12/10 19:50:38|   Validated 0 Entries
>
> 2015/12/10 19:50:38|   store_swap_size = 0k
>
> 2015/12/10 19:50:39| storeLateRelease: released 0 objects
>
> --------------------------------------------------------------------------------------------------
>
> Squid 3.5.11 Squid.conf:
>
> # Squid Proxy Configuration
>
> acl localnet src all
>
> #acl localnet src 172.16.50.0/24  # RFC1918 possible internal network
>
> acl SSL_ports port 443
>
> acl Safe_ports port 80                    # http
>
> acl Safe_ports port 443                  # https
>
> acl CONNECT method CONNECT
>
> # Deny requests to certain unsafe ports
>
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
>
> http_access deny CONNECT !SSL_ports
>
> http_access allow localnet
>
> http_access allow localhost
>
> # Lastly deny all other access to this proxy
>
> http_access deny all
>
> # Listens to port 3128
>
> http_port 3130
>
> dns_nameservers 172.16.50.9 172.16.50.13
>
> max_filedescriptors 3200
>
> # roll log file daily and keep 30 days
>
> logfile_rotate 30
>
> # access log format
>
> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
>
> # debug_options             ALL,2
>
> ---------------------------------------------------------------------------------------
>
> Squid 2.7.2 Squid.conf:
>
> # Squid Proxy Configuration
>
> http_port    3128
>
> # acl and http_access to ("whitelist.txt")
>
> acl whitelist dstdomain "c:/squid/etc/whitelist.txt"
>
> http_access        allow     whitelist
>
> # subnet source of proxy traffic
>
> acl all src 0.0.0.0/0.0.0.0
>
> acl localnet  src  0.0.0.0/0.0.0.0
>
> # acl directives for ports and protocols
>
> acl http      proto      http
>
> acl https     proto      https
>
> acl port_80   port       80
>
> acl sslports  port       443-444
>
> acl CONNECT   method     CONNECT
>
> icp_port 0
>
> htcp_port 0
>
> snmp_port 0
>
> # rules allowing whitelist domains
>
> http_access allow http    port_80 whitelist localnet
>
> http_access allow https   sslports whitelist localnet
>
> # cache web pages directory
>
> cache_dir ufs C:/Squid/var/cache/squid 100 16 256
>
> cache_mem 64 MB
>
> # log file roll weekly
>
> access_log C:/squid/var/logs/access.log common
>
> logfile_rotate 7
>
> # catch-all rule
>
> http_access deny all
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/ed9d96ce/attachment.htm>

From vze2k3sa at verizon.net  Fri Dec 11 18:42:24 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Fri, 11 Dec 2015 13:42:24 -0500
Subject: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than
Message-ID: <000601d13443$ad8d5930$08a80b90$@verizon.net>

Hello,

I added the following line to my squid.conf and now Squid 3.5.11 is as fast as 2.7.2 and feels like direct internet access.

dns_v4_first on 

Thank You,
Patrick


Message: 3
Date: Sat, 12 Dec 2015 02:47:05 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than
	Squid 64-bit (3.5.11)
Message-ID: <566AD3D9.4020609 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 11/12/2015 10:16 p.m., TarotApprentice wrote:
> Sorry should have replied to the list.
> 
> MarkJ
>  
> ----- Forwarded Message -----
>> From: Tarot Apprentice
>>
>> Looking at the startup logs the 3.4.11 says "store logging disabled" (it had an error) so would account for some of the difference.
>>


So the builds are different:

* OS integration:
Squid-2 builds from Acme being made with Visual Studio. So they have
native Windows API integration.
Squid-3 builds by Diladele are using Cgwin. So a whole OS abstraction
layer between Squid and Windows.

* HTTP 1.x:
Squid-2 is HTTP/1.0-only.
Squid-3 does HTTP/1.1 and does a whole lot more protocol processing to
detect whether 1.1 features are being used.

* X-bit:
As you already said 32-bit vs 64-bit. I read some research recently that
showed 64-bit is only faster in benchmarks when there is hardware layer
retardation being applied to emulating the 32-bit operations on the same
hardware. So YMMV.

* Features:
Squid-2 has less features than Squid-3.5. It also has less of them
enabled by default. YMMV.
 - This includes IPv6 support. Squid-3 waits for both IPv4 and IPv6
responses from DNS. Squid-2 will not be doing that.


The configs are different:

* DNS:
Squid-2 is configured to use the Windows Registry DNS servers (default).
Squid-3 is explicitly configured with dns_nameservers to override that
to use only a sub-set of the Registry listed NS.
 - if that one DNS server is running much faster than the others it can
account for a lot of speed variance.

* Cache:
Squid-2 is using a 100MB disk cache + 64MB RAM cache.
Squid-3 is using only a 256MB RAM cache.
 - Usually this should count against Squid-2 in most traffic. But if
your Squid are processing objects over 4MB size, then Squid-2 has the
advantage of storing them to HDD and fast-ish HITs later. Where Squid-3
has to MISS.


>>
>> On 11 Dec 2015, at 12:16 PM, Patrick Flaherty wrote:
>>
>>
>> Hello,
>>
>> Just following up on my slow 3.5.11 Squid server.  I loaded the 32-bit 2.7.2 version on the same box and it?s so much faster for me. Its 4 to 5 times faster for me on the same machine. Please any help appreciated. Amos, I think I cleaned up my 3.5.11 squid.conf properly. I think my 2.7.2 squid.conf needs work.
>> See below Startup Cache logs from both 3.5.11 and 2.7.2 and also the squid.conf files from 3.5.11 and 2.7.2.
>>

Both configs look roughly equivalent to me. Except the Squid-3 config
defines localnet as being "all" then does an "allow localnet". Making it
an open proxy. The Squid-2 is at least restricted to the whitelist domains.

Though I dont think that is affecting your results. Uunless someone
figured out how to open a tunnel through it already and is using up the
bandwidth with an not-yet-logged huge transaction.

Amos




From supergeorge1234 at gmail.com  Fri Dec 11 18:46:24 2015
From: supergeorge1234 at gmail.com (George Hollingshead)
Date: Fri, 11 Dec 2015 13:46:24 -0500
Subject: [squid-users] Help with basic config for ssl bump
Message-ID: <CABQqRmbLu0_3Q1mzL7+25H_A841uWihs1b5nc3XXWYwQ7Df+dw@mail.gmail.com>

Can any of you help a newb out here.  I'm upgradihng from 3.0 to 3.5 so i
can see https connects and  i'm a little confused as to what i need to add
to my working config for SSL bump

i have certificates generated just a basic squid.conf of what i need to add
to get SSL bump so i can log https connects.

Thanx a lot
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/2f78b942/attachment.htm>

From yvoinov at gmail.com  Fri Dec 11 18:48:14 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 12 Dec 2015 00:48:14 +0600
Subject: [squid-users] Help with basic config for ssl bump
In-Reply-To: <CABQqRmbLu0_3Q1mzL7+25H_A841uWihs1b5nc3XXWYwQ7Df+dw@mail.gmail.com>
References: <CABQqRmbLu0_3Q1mzL7+25H_A841uWihs1b5nc3XXWYwQ7Df+dw@mail.gmail.com>
Message-ID: <566B1A6E.1090006@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

Feel free to read our good Wiki.

12.12.15 0:46, George Hollingshead ?????:
> Can any of you help a newb out here.  I'm upgradihng from 3.0 to 3.5 so i
> can see https connects and  i'm a little confused as to what i need to add
> to my working config for SSL bump
>
> i have certificates generated just a basic squid.conf of what i need
to add
> to get SSL bump so i can log https connects.
>
> Thanx a lot
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWaxptAAoJENNXIZxhPexGZdMH/iPzoN1Twm8XffmB0oNUnMi7
OjgeNRlPlq6OirUDfuWaNy6HgGnmVQFv85CGp64U4NPnkq4u58af9GVemvEabs1q
zrcgtNvCuqAztzGM11lPE8tKob4LejR8ZrQzoUpY+xaL1h5BE5fSHhL5UknE8EzZ
HgIh1pCaAvAvax9PHXrNmNuW273fFvK3iSsldf1d13Bp1SQuQtRuxTVEUUp9RgmL
+4n0LCDcsBNSjbYiw4xk8RcatruJahl/81wi1tsQ4AG0rDXVxZMZ2PxmpJH1rlwn
S2mMgnSnSn+N6WKs+mt7THy1zjMRqlIPUMSZtL4ypuzAVJwidHHLTuubwvZSRvs=
=81hm
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151212/c80da0b2/attachment.htm>

From supergeorge1234 at gmail.com  Fri Dec 11 21:55:22 2015
From: supergeorge1234 at gmail.com (George Hollingshead)
Date: Fri, 11 Dec 2015 16:55:22 -0500
Subject: [squid-users] Sha 256?
Message-ID: <CABQqRmYdWXXRnG6tAadR81oK=H9OGz+qjifcn=FnpiWe7rqYfw@mail.gmail.com>

i am getting this message when trying to run my newly compiled squid
3.5.11.  i think it's related to openssl but i'm really lost.

Any incite on what's needed to correct this?  i'm really determined to bump
ssl so i can log them but it's becoming a pain for my skill level; lol

Thanx

FATAL: sign hash 'sha256' is not supported squid 3.5
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151211/19f01f48/attachment.htm>

From alex at samad.com.au  Sat Dec 12 03:07:49 2015
From: alex at samad.com.au (Alex Samad)
Date: Sat, 12 Dec 2015 14:07:49 +1100
Subject: [squid-users] reverse proxy setup
In-Reply-To: <566A562A.1020909@treenet.co.nz>
References: <CAJ+Q1PXWn7M=1NCia1Zqi4DJT3niNJBjADbYss0Ri0i2=szPRg@mail.gmail.com>
 <566A562A.1020909@treenet.co.nz>
Message-ID: <CAJ+Q1PXp7uhqq6X8=Ov8fuHt5U6V-FLX5NwvXJgW6FagHNiK8g@mail.gmail.com>

Hi

I'm thinking it is outlook not being able to talk tls1.1 and/or tls
1.2 to squid. I am in the process of patching up my test box.

By ignoring that, I mean the reason its there is that outlook tried to
talk tls1 to it whilst I had tls1 turned off

A

On 11 December 2015 at 15:50, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 11/12/2015 4:52 p.m., Alex Samad wrote:
>> Hi
>>
>>
>> Is there any way to remove these from the log
>>
>> kid1| Error negotiating SSL connection on FD 38: error:140760FC:SSL
>> routines:SSL23_GET_CLIENT_HELLO:unknown protocol (1/-1)
>>
>> this is the corrosponding squid config
>> options=NO_SSLv2:NO_SSLv3:NO_TLSv1:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE
>>
>> Not I don't get this when I re enable tlsv1..
>
> Strange. Usually that means non-TLS traffic being passed to the HTTPS
> port. For example, clients opening plain-text HTTP connections to it.
>
>>
>> I am presuming I can ignore these.
>
> That is always up to you. In this case somebody is getting broken
> traffic, and your logs are filling with the messages saying so.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Sat Dec 12 04:00:39 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 17:00:39 +1300
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC_BPiU49yd6w8dHyqbUbeujTsq41fjjdULvk9L9Eu5dSA@mail.gmail.com>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
 <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
 <566AE006.80609@treenet.co.nz>
 <CAJrMMC_BPiU49yd6w8dHyqbUbeujTsq41fjjdULvk9L9Eu5dSA@mail.gmail.com>
Message-ID: <566B9BE7.8050907@treenet.co.nz>

On 12/12/2015 3:42 a.m., Fabio Bucci wrote:
> Thank Amos i know you suggested kerberos. How can i implement it instead of
> LDAP?

<http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos>

Amos




From squid3 at treenet.co.nz  Sat Dec 12 04:03:25 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 17:03:25 +1300
Subject: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than
In-Reply-To: <000601d13443$ad8d5930$08a80b90$@verizon.net>
References: <000601d13443$ad8d5930$08a80b90$@verizon.net>
Message-ID: <566B9C8D.9000803@treenet.co.nz>

On 12/12/2015 7:42 a.m., Patrick Flaherty wrote:
> Hello,
> 
> I added the following line to my squid.conf and now Squid 3.5.11 is as fast as 2.7.2 and feels like direct internet access.
> 
> dns_v4_first on 
> 

That plus the huge difference in speed tells me that you have very
broken IPv6 connectivity. Most likely ICMP is not working on your
network, or one of your upstreams.

ICMP is not an optional protocol. It is mandatory for efficient
congestion control, even in IPv4 networks.

Amos



From squid3 at treenet.co.nz  Sat Dec 12 04:08:16 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 17:08:16 +1300
Subject: [squid-users] reverse proxy setup
In-Reply-To: <CAJ+Q1PXp7uhqq6X8=Ov8fuHt5U6V-FLX5NwvXJgW6FagHNiK8g@mail.gmail.com>
References: <CAJ+Q1PXWn7M=1NCia1Zqi4DJT3niNJBjADbYss0Ri0i2=szPRg@mail.gmail.com>
 <566A562A.1020909@treenet.co.nz>
 <CAJ+Q1PXp7uhqq6X8=Ov8fuHt5U6V-FLX5NwvXJgW6FagHNiK8g@mail.gmail.com>
Message-ID: <566B9DB0.4060404@treenet.co.nz>

On 12/12/2015 4:07 p.m., Alex Samad wrote:
> Hi
> 
> I'm thinking it is outlook not being able to talk tls1.1 and/or tls
> 1.2 to squid. I am in the process of patching up my test box.
> 
> By ignoring that, I mean the reason its there is that outlook tried to
> talk tls1 to it whilst I had tls1 turned off
> 

Nod. I meant it strange to get that particular error. I would have
expected another one about unsupported features. Still, its OpenSSL so
who knows whats broken or if I'm just reading it wrong.

Amos



From squid3 at treenet.co.nz  Sat Dec 12 04:47:19 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 17:47:19 +1300
Subject: [squid-users] Help with basic config for ssl bump
In-Reply-To: <566B1A6E.1090006@gmail.com>
References: <CABQqRmbLu0_3Q1mzL7+25H_A841uWihs1b5nc3XXWYwQ7Df+dw@mail.gmail.com>
 <566B1A6E.1090006@gmail.com>
Message-ID: <566BA6D7.708@treenet.co.nz>

On 12/12/2015 7:48 a.m., Yuri Voinov wrote:
> 
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> 
> Feel free to read our good Wiki.
> 
> 12.12.15 0:46, George Hollingshead ?????:
>> Can any of you help a newb out here.  I'm upgradihng from 3.0 to 3.5 so i
>> can see https connects and  i'm a little confused as to what i need to add
>> to my working config for SSL bump

Upgrade first. Only when that is confirmed working attempt to go on to
adding new features to the configuration.

Amos


From squid3 at treenet.co.nz  Sat Dec 12 05:05:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 18:05:38 +1300
Subject: [squid-users] Sha 256?
In-Reply-To: <CABQqRmYdWXXRnG6tAadR81oK=H9OGz+qjifcn=FnpiWe7rqYfw@mail.gmail.com>
References: <CABQqRmYdWXXRnG6tAadR81oK=H9OGz+qjifcn=FnpiWe7rqYfw@mail.gmail.com>
Message-ID: <566BAB22.4050902@treenet.co.nz>

On 12/12/2015 10:55 a.m., George Hollingshead wrote:
> i am getting this message when trying to run my newly compiled squid
> 3.5.11.  i think it's related to openssl but i'm really lost.
> 
> Any incite on what's needed to correct this?  i'm really determined to bump
> ssl so i can log them but it's becoming a pain for my skill level; lol
> 
> Thanx
> 
> FATAL: sign hash 'sha256' is not supported squid 3.5
> 

There is no such error produced by Squid, and it looks nothing like an
OpenSSL message. Particularly saying "squid 3.5".

For anyone to help you will need to provide the full and exact error
message. Squid -v output, OS details, OpenSSL version details,
squid.conf, etc.

Amos



From squid3 at treenet.co.nz  Sat Dec 12 05:37:40 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Dec 2015 18:37:40 +1300
Subject: [squid-users] Sha 256?
In-Reply-To: <566BAB22.4050902@treenet.co.nz>
References: <CABQqRmYdWXXRnG6tAadR81oK=H9OGz+qjifcn=FnpiWe7rqYfw@mail.gmail.com>
 <566BAB22.4050902@treenet.co.nz>
Message-ID: <566BB2A4.4040207@treenet.co.nz>

On 12/12/2015 6:05 p.m., Amos Jeffries wrote:
> On 12/12/2015 10:55 a.m., George Hollingshead wrote:
>> i am getting this message when trying to run my newly compiled squid
>> 3.5.11.  i think it's related to openssl but i'm really lost.
>>
>> Any incite on what's needed to correct this?  i'm really determined to bump
>> ssl so i can log them but it's becoming a pain for my skill level; lol
>>
>> Thanx
>>
>> FATAL: sign hash 'sha256' is not supported squid 3.5
>>
> 
> There is no such error produced by Squid, and it looks nothing like an
> OpenSSL message. Particularly saying "squid 3.5".

Found it. There is one in Squid similar, but not quite the same wording
you posted. It happens when OpenSSL is asked to translate the text hash
name into it ID code for use, and OpenSSL returns an error.

So yes, OpenSSL realeted. Either it needs an upgrade, or you rconfigured
it not to understand SHA256.

> 
> For anyone to help you will need to provide the full and exact error
> message. Squid -v output, OS details, OpenSSL version details,
> squid.conf, etc.

That still applies.

Amos



From juanchorevolution at hotmail.com  Sat Dec 12 13:39:32 2015
From: juanchorevolution at hotmail.com (juancho Alfonso)
Date: Sat, 12 Dec 2015 08:39:32 -0500
Subject: [squid-users] FW:  help change cache dir
In-Reply-To: <COL131-W56159B00FFCCFFB2BC8F99B0EA0@phx.gbl>
References: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>,
 <5669E2E0.6040405@gmail.com>, <COL131-W633C280854D4FDA65685BCB0E90@phx.gbl>,
 <COL131-W56159B00FFCCFFB2BC8F99B0EA0@phx.gbl>
Message-ID: <COL131-W3061BB144436CFF64C7941B0EB0@phx.gbl>





the user issquidif i initialite by defaul it worksin var/spool/squidand works user squid squidbut i want add dir var/spool/squidor XDISKEXTERNAL/something/squid
but dont work permission denied(13)

try chmod -R squid.squid cacheorchmod -R 777 cache

image show config http://es.zimagez.com/zimage/captura398.php


To: squid-users at lists.squid-cache.org
From: yvoinov at gmail.com
Date: Fri, 11 Dec 2015 02:38:56 +0600
Subject: Re: [squid-users] help change cache dir


  
    
  
  
    

    -----BEGIN PGP SIGNED MESSAGE----- 

    Hash: SHA256 

     

    Cache dir owner must be user which is specified in squid.conf:

    

    http://i.imgur.com/AbYkE8M.png

    

    

    

    11.12.15 2:27, juancho Alfonso ?????:

    > Hey thereI have installed
      CentOS squid in 7I want to change the cache directory

      > appears when I try to initialize

      > Creating Swap Directories

      > FATAL: Failed to make directory swap mydirectory / cache /
      00:

      >      (13) Permission denied

      > directory is an external drive or a folder on the same
      partitionand I granted permissions

      > chmod 777 cacheorchmod cache squid.squid

      > no worksI need help to put more capacity more directories

      >

      >

      >

      > the squid.conf

      > ## Recommended minimum configuration:#

      > # Example rule allowing access from your local networks.#
      Adapt to list your (internal) IP networks from where browsing#
      should be allowedacl localnet src 10.0.0.0/8 # RFC1918 possible
      internal networkacl localnet src 172.16.0.0/12 # RFC1918 possible
      internal networkacl localnet src 192.168.0.0/16 # RFC1918 possible
      internal networkacl localnet src fc00::/7 # RFC 4193 local private
      network rangeacl localnet src fe80::/10 # RFC 4291 link-local
      (directly plugged) machines

      > acl SSL_ports port 443acl Safe_ports port 80 # httpacl
      Safe_ports port 21 # ftpacl Safe_ports port 443 # httpsacl
      Safe_ports port 70 # gopheracl Safe_ports port 210 # waisacl
      Safe_ports port 1025-65535 # unregistered portsacl Safe_ports port
      280 # http-mgmtacl Safe_ports port 488 # gss-httpacl Safe_ports
      port 591 # filemakeracl Safe_ports port 777 # multiling httpacl
      CONNECT method CONNECTacl PAGINASBLOQUEADAS url_regex -i porno
      abcde

      > ## Recommended minimum Access Permission configuration:##
      Deny requests to certain unsafe portshttp_access deny
      PAGINASBLOQUEADAS

      > # Deny CONNECT to other than secure SSL portshttp_access deny
      !Safe_ports

      > # Only allow cachemgr access from localhosthttp_access deny
      CONNECT !SSL_portshttp_access allow localhost manager

      > # We strongly recommend the following be uncommented to
      protect innocent# web applications running on the proxy server who
      think the only# one who can access services on "localhost" is a
      local user#http_access deny to_localhost

      > ## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR
      CLIENTS#

      > # Example rule allowing access from your local networks.#
      Adapt localnet in the ACL section to list your (internal) IP
      networks# from where browsing should be allowedhttp_access allow
      managerhttp_access allow localnet

      > # And finally deny all other access to this proxyhttp_access
      allow localhosthttp_access allow all

      > # Squid normally listens to port 3128http_port 3128
      transparent

      > # Uncomment and adjust the following to add a disk cache
      directory.

      > # Leave coredumps in the first cache dircoredump_dir
      /var/spool/squid

      > ## Add any of your own refresh_pattern entries above
      these.#refresh_pattern ^ftp:        1440    20%   
      10080refresh_pattern ^gopher:    1440    0%    1440refresh_pattern
      -i (/cgi-bin/|\?) 0    0%    0refresh_pattern .        0    20%   
      4320

      >

      >

      > #juancache_mem 16384 MB#cache_replacement_policy heap LFUDA
      #El par?metro maximum_object_size define el tama?o m?ximo de los
      objetos que ser?n almacenados en el cache de
      discomaximum_object_size 200 MBcache_swap_low 90cache_swap_high
      95#correo del administrador del cachecache_mgr
      ingenieria at conexiondigital.cocachemgr_passwd cache all

      > #this workcache_dir aufs /var/spool/squid 40000 16 256 #this
      no workcache_dir aufs /var/spool/squid2 40000 16 256 

      > cache_effective_user squidcache_effective_group squid

      >

      >

      >

      > Juan Ernesto Alfonsoestudiante ingenier?a
      electr?nicauniversidad distrital Francisco Jos? de Caldas

      > JUANCHO

      >  NEMESIS 

      > KRAVEN

      >

      > " si un d?a tienes que elegir entre el mundo y el amor...

      > recuerda: 

      >

      > si eliges el mundo quedar?s sin amor, 

      >

      > pero si eliges el amor, con ?l conquistar?s al mundo" 

      >

      > albert einstein 

      >

      >

      >

      >                             

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org

      > http://lists.squid-cache.org/listinfo/squid-users

    

    -----BEGIN PGP SIGNATURE-----


    Version: GnuPG v2


     

    iQEcBAEBCAAGBQJWaeLfAAoJENNXIZxhPexGV6wH/0dy5nyvKJBsB8cWnXpyU661


    98aA96FF+8QlQW+dkAKyNJ/dNtjv/VyGbglqyDDoaqwq2+Uef3dZauwyIQcwoRxZ


    TVhUu47v+cX1F6Ka+JWxvw7hsIumoEvrXQQxdBoZUAqdXDRyvdK/VeraGyV1y2LD


    qYQB/vIV7u/PGgiyzE5vtZ/aHYnAsiLQxMD4a3SSvDnSNx9fklhRGyTljcNuVH5n


    NAXeXE3JD9+NW9rFY3/49TWNGJMNzH9v9RyQPG5uWkov/hAR1fXiRW7a/TD6pZ6V


    /gb54gbAQcdCMXwsly7XQTswoG6OKGLuLl6+mLbLz3hgBpDfZDNAQMpKM4npiSU=


    =ayi0


    -----END PGP SIGNATURE-----


    

  


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 		 	   		   		 	   		   		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151212/1c503ff3/attachment.htm>

From leeb at ratnaling.org  Sat Dec 12 17:59:35 2015
From: leeb at ratnaling.org (Lee Brown)
Date: Sat, 12 Dec 2015 09:59:35 -0800
Subject: [squid-users] FW: help change cache dir
In-Reply-To: <COL131-W3061BB144436CFF64C7941B0EB0@phx.gbl>
References: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>
 <5669E2E0.6040405@gmail.com>
 <COL131-W633C280854D4FDA65685BCB0E90@phx.gbl>
 <COL131-W56159B00FFCCFFB2BC8F99B0EA0@phx.gbl>
 <COL131-W3061BB144436CFF64C7941B0EB0@phx.gbl>
Message-ID: <CAFPNf5-S_w-C=3F-EdYXH6tNCYYOMFqb5UTB23SNvzOrbOj9TA@mail.gmail.com>

On Sat, Dec 12, 2015 at 5:39 AM, juancho Alfonso <
juanchorevolution at hotmail.com> wrote:

>
> the user is
> squid
> if i initialite by defaul it works
> in var/spool/squid
> and works
> user squid squid
> but i want add dir
> var/spool/squid
> or
> XDISKEXTERNAL/something/squid
>
> but dont work
> permission denied(13)
>
>
> try chmod -R squid.squid cache
> or
> chmod -R 777 cache
>
>
> image show config
> http://es.zimagez.com/zimage/captura398.php
>
>
>
> ------------------------------
> To: squid-users at lists.squid-cache.org
> From: yvoinov at gmail.com
> Date: Fri, 11 Dec 2015 02:38:56 +0600
> Subject: Re: [squid-users] help change cache dir
>
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Cache dir owner must be user which is specified in squid.conf:
>
> http://i.imgur.com/AbYkE8M.png
>
>
>
> 11.12.15 2:27, juancho Alfonso ?????:
> > Hey thereI have installed CentOS squid in 7I want to change the cache
> directory
> > appears when I try to initialize
> > Creating Swap Directories
> > FATAL: Failed to make directory swap mydirectory / cache / 00:
> >      (13) Permission denied
> > directory is an external drive or a folder on the same partitionand I
> granted permissions
> > chmod 777 cacheorchmod cache squid.squid
> > no worksI need help to put more capacity more directories
> >
> >
> >
> > the squid.conf
> > ## Recommended minimum configuration:#
> > # Example rule allowing access from your local networks.# Adapt to list
> your (internal) IP networks from where browsing# should be allowedacl
> localnet src 10.0.0.0/8 # RFC1918 possible internal networkacl localnet
> src 172.16.0.0/12 # RFC1918 possible internal networkacl localnet src
> 192.168.0.0/16 # RFC1918 possible internal networkacl localnet src
> fc00::/7 # RFC 4193 local private network rangeacl localnet src fe80::/10 #
> RFC 4291 link-local (directly plugged) machines
> > acl SSL_ports port 443acl Safe_ports port 80 # httpacl Safe_ports port
> 21 # ftpacl Safe_ports port 443 # httpsacl Safe_ports port 70 # gopheracl
> Safe_ports port 210 # waisacl Safe_ports port 1025-65535 # unregistered
> portsacl Safe_ports port 280 # http-mgmtacl Safe_ports port 488 #
> gss-httpacl Safe_ports port 591 # filemakeracl Safe_ports port 777 #
> multiling httpacl CONNECT method CONNECTacl PAGINASBLOQUEADAS url_regex -i
> porno abcde
> > ## Recommended minimum Access Permission configuration:## Deny requests
> to certain unsafe portshttp_access deny PAGINASBLOQUEADAS
> > # Deny CONNECT to other than secure SSL portshttp_access deny !Safe_ports
> > # Only allow cachemgr access from localhosthttp_access deny CONNECT
> !SSL_portshttp_access allow localhost manager
> > # We strongly recommend the following be uncommented to protect
> innocent# web applications running on the proxy server who think the only#
> one who can access services on "localhost" is a local user#http_access deny
> to_localhost
> > ## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS#
> > # Example rule allowing access from your local networks.# Adapt localnet
> in the ACL section to list your (internal) IP networks# from where browsing
> should be allowedhttp_access allow managerhttp_access allow localnet
> > # And finally deny all other access to this proxyhttp_access allow
> localhosthttp_access allow all
> > # Squid normally listens to port 3128http_port 3128 transparent
> > # Uncomment and adjust the following to add a disk cache directory.
> > # Leave coredumps in the first cache dircoredump_dir /var/spool/squid
> > ## Add any of your own refresh_pattern entries above
> these.#refresh_pattern ^ftp:        1440    20%    10080refresh_pattern
> ^gopher:    1440    0%    1440refresh_pattern -i (/cgi-bin/|\?) 0    0%
> 0refresh_pattern .        0    20%    4320
> >
> >
> > #juancache_mem 16384 MB#cache_replacement_policy heap LFUDA #El
> par?metro maximum_object_size define el tama?o m?ximo de los objetos que
> ser?n almacenados en el cache de discomaximum_object_size 200
> MBcache_swap_low 90cache_swap_high 95#correo del administrador del
> cachecache_mgr ingenieria at conexiondigital.cocachemgr_passwd cache all
> > #this workcache_dir aufs /var/spool/squid 40000 16 256 #this no
> workcache_dir aufs /var/spool/squid2 40000 16 256
> > cache_effective_user squidcache_effective_group squid
> >
> >
> >
> > Juan Ernesto Alfonsoestudiante ingenier?a electr?nicauniversidad
> distrital Francisco Jos? de Caldas
> > JUANCHO
> >  NEMESIS
> > KRAVEN
> >
> > " si un d?a tienes que elegir entre el mundo y el amor...
> > recuerda:
> >
> > si eliges el mundo quedar?s sin amor,
> >
> > pero si eliges el amor, con ?l conquistar?s al mundo"
> >
> > albert einstein
> >
> >
> >
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJWaeLfAAoJENNXIZxhPexGV6wH/0dy5nyvKJBsB8cWnXpyU661
> 98aA96FF+8QlQW+dkAKyNJ/dNtjv/VyGbglqyDDoaqwq2+Uef3dZauwyIQcwoRxZ
> TVhUu47v+cX1F6Ka+JWxvw7hsIumoEvrXQQxdBoZUAqdXDRyvdK/VeraGyV1y2LD
> qYQB/vIV7u/PGgiyzE5vtZ/aHYnAsiLQxMD4a3SSvDnSNx9fklhRGyTljcNuVH5n
> NAXeXE3JD9+NW9rFY3/49TWNGJMNzH9v9RyQPG5uWkov/hAR1fXiRW7a/TD6pZ6V
> /gb54gbAQcdCMXwsly7XQTswoG6OKGLuLl6+mLbLz3hgBpDfZDNAQMpKM4npiSU=
> =ayi0
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________ squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>

As Rafael said,

Check your SELinux settings.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151212/b0fbcf0a/attachment.htm>

From jkallup at web.de  Sat Dec 12 19:44:36 2015
From: jkallup at web.de (Jens Kallup)
Date: Sat, 12 Dec 2015 20:44:36 +0100
Subject: [squid-users] ffserver on remote server and ffmpeg on local
Message-ID: <566C7924.5010408@web.de>

Hello,

I have running a ffserver on remote machine without parameters - except

#File: /etc/ffserver.conf

Port 8090
# bind to all IPs aliased or not
BindAddress 0.0.0.0
# max number of simultaneous clients
MaxClients 1000
# max bandwidth per-client (kb/s)
MaxBandwidth 10000
# Suppress that if you want to launch ffserver as a daemon.
NoDaemon

<Feed feed1.ffm>
File /tmp/feed1.ffm
FileMaxSize 5M
</Feed>

<Stream test.swf>
Feed feed1.ffm
Format swf
VideoCodec flv
VideoFrameRate 15
VideoBufferSize 80000
VideoBitRate 100
VideoQMin 1
VideoQMax 5
VideoSize 352x288
PreRoll 0
Noaudio
</Stream>

And on local machine:

# ffmpeg -f x11grab -i :0.0+100,200 -flags +global_header -c:v libx264 
-b:v 500k -r 10 -s 352x288 -x264opts keyint=50 -g 10 -pix_fmt yuv420p -f 
flv http://server.tld:8090/feed1.ffm
ffmpeg version 2.7.2 Copyright (c) 2000-2015 the FFmpeg developers
   built with gcc 4.9.2 (Debian 4.9.2-10)
   configuration: --enable-gpl --enable-version3 --enable-nonfree 
--enable-postproc --enable-libaacplus --enable-libfaac 
--enable-libfdk-aac --enable-libfreetype --enable-libmp3lame 
--enable-libopencore-amrnb --enable-libopencore-amrwb 
--enable-libopenjpeg --enable-openssl --enable-libopus 
--enable-libschroedinger --enable-libspeex --enable-libtheora 
--enable-libvo-aacenc --enable-libvorbis --enable-libvpx 
--enable-libx264 --enable-libxvid --prefix=/usr/local --enable-librtmp
   WARNING: library configuration mismatch
   avutil      configuration: --enable-gpl --enable-postproc 
--enable-swscale --enable-avfilter --enable-libmp3lame 
--enable-libvorbis --enable-libtheora --enable-libx264 --enable-libspeex 
--enable-shared --enable-pthreads --enable-libopenjpeg --enable-libfaac 
--enable-nonfree
   avcodec     configuration: --enable-gpl --enable-postproc 
--enable-swscale --enable-avfilter --enable-libmp3lame 
--enable-libvorbis --enable-libtheora --enable-libx264 --enable-libspeex 
--enable-shared --enable-pthreads --enable-libopenjpeg --enable-libfaac 
--enable-nonfree
   avformat    configuration: --enable-gpl --enable-postproc 
--enable-swscale --enable-avfilter --enable-libmp3lame 
--enable-libvorbis --enable-libtheora --enable-libx264 --enable-libspeex 
--enable-shared --enable-pthreads --enable-libopenjpeg --enable-libfaac 
--enable-nonfree
   avdevice    configuration: --enable-gpl --enable-postproc 
--enable-swscale --enable-avfilter --enable-libmp3lame 
--enable-libvorbis --enable-libtheora --enable-libx264 --enable-libspeex 
--enable-shared --enable-pthreads --enable-libopenjpeg --enable-libfaac 
--enable-nonfree
   avfilter    configuration: --enable-gpl --enable-postproc 
--enable-swscale --enable-avfilter --enable-libmp3lame 
--enable-libvorbis --enable-libtheora --enable-libx264 --enable-libspeex 
--enable-shared --enable-pthreads --enable-libopenjpeg --enable-libfaac 
--enable-nonfree
   swscale     configuration: --enable-gpl --enable-postproc 
--enable-swscale --enable-avfilter --enable-libmp3lame 
--enable-libvorbis --enable-libtheora --enable-libx264 --enable-libspeex 
--enable-shared --enable-pthreads --enable-libopenjpeg --enable-libfaac 
--enable-nonfree
   swresample  configuration: --enable-gpl --enable-postproc 
--enable-swscale --enable-avfilter --enable-libmp3lame 
--enable-libvorbis --enable-libtheora --enable-libx264 --enable-libspeex 
--enable-shared --enable-pthreads --enable-libopenjpeg --enable-libfaac 
--enable-nonfree
   postproc    configuration: --enable-gpl --enable-postproc 
--enable-swscale --enable-avfilter --enable-libmp3lame 
--enable-libvorbis --enable-libtheora --enable-libx264 --enable-libspeex 
--enable-shared --enable-pthreads --enable-libopenjpeg --enable-libfaac 
--enable-nonfree
   libavutil      54. 27.100 / 54. 27.100
   libavcodec     56. 41.100 / 56. 41.100
   libavformat    56. 36.100 / 56. 36.100
   libavdevice    56.  4.100 / 56.  4.100
   libavfilter     5. 16.101 /  5. 16.101
   libswscale      3.  1.101 /  3.  1.101
   libswresample   1.  2.100 /  1.  2.100
   libpostproc    53.  3.100 / 53.  3.100
Input #0, x11grab, from ':0.0+100,200':
   Duration: N/A, start: 1449948966.255341, bitrate: N/A
     Stream #0:0: Video: rawvideo (BGR[0] / 0x524742), bgr0, 640x480, 
29.97 fps, 29.97 tbr, 1000k tbn, 29.97 tbc
[libx264 @ 0x1e5be20] using cpu capabilities: MMX2 SSE2Fast SSSE3 Cache64
[libx264 @ 0x1e5be20] profile High, level 2.0
[libx264 @ 0x1e5be20] 264 - core 146 - H.264/MPEG-4 AVC codec - Copyleft 
2003-2015 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 
deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 
mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 
deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 
lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 
bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 
b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=50 keyint_min=5 
scenecut=40 intra_refresh=0 rc_lookahead=40 rc=abr mbtree=1 bitrate=500 
ratetol=1.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00
Output #0, flv, to 'http://kallup.net:8090/feed1.ffm':
   Metadata:
     encoder         : Lavf56.36.100
     Stream #0:0: Video: h264 (libx264) ([7][0][0][0] / 0x0007), 
yuv420p, 352x288, q=-1--1, 500 kb/s, 10 fps, 1k tbn, 10 tbc
     Metadata:
       encoder         : Lavc56.41.100 libx264
Stream mapping:
   Stream #0:0 -> #0:0 (rawvideo (native) -> h264 (libx264))
Press [q] to stop, [?] for help
av_interleaved_write_frame(): Connection reset by peer:00.10 bitrate=N/A 
dup=0 drop=92
[flv @ 0x1e5ac20] Failed to update header with correct duration.
[flv @ 0x1e5ac20] Failed to update header with correct filesize.
frame=   49 fps= 10 q=-1.0 Lsize=      41kB time=00:00:00.00 bitrate=N/A 
dup=0 drop=94
video:41kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB 
muxing overhead: 0.793859%
[libx264 @ 0x1e5be20] frame I:1     Avg QP:18.63  size: 37296
[libx264 @ 0x1e5be20] frame P:14    Avg QP:12.64  size:  4936
[libx264 @ 0x1e5be20] frame B:34    Avg QP:19.91  size:    23
[libx264 @ 0x1e5be20] consecutive B-frames:  6.1%  4.1%  0.0% 89.8%
[libx264 @ 0x1e5be20] mb I  I16..4:  8.3%  2.3% 89.4%
[libx264 @ 0x1e5be20] mb P  I16..4:  1.0%  0.2%  4.5%  P16..4: 25.6%  
1.4%  1.1%  0.0%  0.0%    skip:66.3%
[libx264 @ 0x1e5be20] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 2.3%  
0.0%  0.0%  direct: 0.0%  skip:97.7%  L0: 2.6% L1:97.4% BI: 0.0%
[libx264 @ 0x1e5be20] final ratefactor: 6.87
[libx264 @ 0x1e5be20] 8x8 transform intra:2.8% inter:40.2%
[libx264 @ 0x1e5be20] coded y,uvDC,uvAC intra: 74.4% 5.9% 5.5% inter: 
5.8% 1.0% 0.9%
[libx264 @ 0x1e5be20] i16 v,h,dc,p: 46% 51%  3%  0%
[libx264 @ 0x1e5be20] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 55%  0% 45% 0%  0%  
0%  0%  0%  0%
[libx264 @ 0x1e5be20] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 27% 12% 4%  6%  
5%  7%  5%  9%
[libx264 @ 0x1e5be20] i8c dc,h,v,p: 86% 12%  2%  0%
[libx264 @ 0x1e5be20] Weighted P-Frames: Y:0.0% UV:0.0%
[libx264 @ 0x1e5be20] ref P L0: 98.0%  0.6%  1.2%  0.2%
[libx264 @ 0x1e5be20] kb/s:174.96
Conversion failed!


The stream break always after 3-5 seconds.
Any help and ideas are welcome
Thanks

Jens


From tarotapprentice at yahoo.com  Sat Dec 12 21:57:17 2015
From: tarotapprentice at yahoo.com (TarotApprentice)
Date: Sun, 13 Dec 2015 08:57:17 +1100
Subject: [squid-users] FW: help change cache dir
In-Reply-To: <CAFPNf5-S_w-C=3F-EdYXH6tNCYYOMFqb5UTB23SNvzOrbOj9TA@mail.gmail.com>
References: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>
 <5669E2E0.6040405@gmail.com> <COL131-W633C280854D4FDA65685BCB0E90@phx.gbl>
 <COL131-W56159B00FFCCFFB2BC8F99B0EA0@phx.gbl>
 <COL131-W3061BB144436CFF64C7941B0EB0@phx.gbl>
 <CAFPNf5-S_w-C=3F-EdYXH6tNCYYOMFqb5UTB23SNvzOrbOj9TA@mail.gmail.com>
Message-ID: <1E65640A-DDA2-41F1-B55E-93E6DC57A702@yahoo.com>

The last time I setup my cache dir I did the following (in Debian):

cd /var/spool
sudo mkdir squid
sudo chown proxy:proxy squid
/usr/sbin/squid -z

Where proxy is the username for squid.

> On 13 Dec 2015, at 4:59 AM, Lee Brown <leeb at ratnaling.org> wrote:
> 
> 
>> On Sat, Dec 12, 2015 at 5:39 AM, juancho Alfonso <juanchorevolution at hotmail.com> wrote:
>> 
>> the user is
>> squid
>> if i initialite by defaul it works
>> in var/spool/squid
>> and works 
>> user squid squid
>> but i want add dir 
>> var/spool/squid
>> or 
>> XDISKEXTERNAL/something/squid
>> 
>> but dont work 
>> permission denied(13)
>> 
>> 
>> try chmod -R squid.squid cache
>> or
>> chmod -R 777 cache
>> 
>> 
>> image show config 
>> http://es.zimagez.com/zimage/captura398.php
>> 
>> 
>> 
>> To: squid-users at lists.squid-cache.org
>> From: yvoinov at gmail.com
>> Date: Fri, 11 Dec 2015 02:38:56 +0600
>> Subject: Re: [squid-users] help change cache dir
>> 
>> 
>> -----BEGIN PGP SIGNED MESSAGE----- 
>> Hash: SHA256 
>>  
>> Cache dir owner must be user which is specified in squid.conf:
>> 
>> http://i.imgur.com/AbYkE8M.png
>> 
>> 
>> 
>> 11.12.15 2:27, juancho Alfonso ?????:
>> > Hey thereI have installed
>>       CentOS squid in 7I want to change the cache directory
>> 
>>       > appears when I try to initialize
>> 
>>       > Creating Swap Directories
>> 
>>       > FATAL: Failed to make directory swap mydirectory / cache /
>>       00:
>> 
>>       >      (13) Permission denied
>> 
>>       > directory is an external drive or a folder on the same
>>       partitionand I granted permissions
>> 
>>       > chmod 777 cacheorchmod cache squid.squid
>> 
>>       > no worksI need help to put more capacity more directories
>> 
>>       >
>> 
>>       >
>> 
>>       >
>> 
>>       > the squid.conf
>> 
>>       > ## Recommended minimum configuration:#
>> 
>>       > # Example rule allowing access from your local networks.#
>>       Adapt to list your (internal) IP networks from where browsing#
>>       should be allowedacl localnet src 10.0.0.0/8 # RFC1918 possible
>>       internal networkacl localnet src 172.16.0.0/12 # RFC1918 possible
>>       internal networkacl localnet src 192.168.0.0/16 # RFC1918 possible
>>       internal networkacl localnet src fc00::/7 # RFC 4193 local private
>>       network rangeacl localnet src fe80::/10 # RFC 4291 link-local
>>       (directly plugged) machines
>> 
>>       > acl SSL_ports port 443acl Safe_ports port 80 # httpacl
>>       Safe_ports port 21 # ftpacl Safe_ports port 443 # httpsacl
>>       Safe_ports port 70 # gopheracl Safe_ports port 210 # waisacl
>>       Safe_ports port 1025-65535 # unregistered portsacl Safe_ports port
>>       280 # http-mgmtacl Safe_ports port 488 # gss-httpacl Safe_ports
>>       port 591 # filemakeracl Safe_ports port 777 # multiling httpacl
>>       CONNECT method CONNECTacl PAGINASBLOQUEADAS url_regex -i porno
>>       abcde
>> 
>>       > ## Recommended minimum Access Permission configuration:##
>>       Deny requests to certain unsafe portshttp_access deny
>>       PAGINASBLOQUEADAS
>> 
>>       > # Deny CONNECT to other than secure SSL portshttp_access deny
>>       !Safe_ports
>> 
>>       > # Only allow cachemgr access from localhosthttp_access deny
>>       CONNECT !SSL_portshttp_access allow localhost manager
>> 
>>       > # We strongly recommend the following be uncommented to
>>       protect innocent# web applications running on the proxy server who
>>       think the only# one who can access services on "localhost" is a
>>       local user#http_access deny to_localhost
>> 
>>       > ## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR
>>       CLIENTS#
>> 
>>       > # Example rule allowing access from your local networks.#
>>       Adapt localnet in the ACL section to list your (internal) IP
>>       networks# from where browsing should be allowedhttp_access allow
>>       managerhttp_access allow localnet
>> 
>>       > # And finally deny all other access to this proxyhttp_access
>>       allow localhosthttp_access allow all
>> 
>>       > # Squid normally listens to port 3128http_port 3128
>>       transparent
>> 
>>       > # Uncomment and adjust the following to add a disk cache
>>       directory.
>> 
>>       > # Leave coredumps in the first cache dircoredump_dir
>>       /var/spool/squid
>> 
>>       > ## Add any of your own refresh_pattern entries above
>>       these.#refresh_pattern ^ftp:        1440    20%   
>>       10080refresh_pattern ^gopher:    1440    0%    1440refresh_pattern
>>       -i (/cgi-bin/|\?) 0    0%    0refresh_pattern .        0    20%   
>>       4320
>> 
>>       >
>> 
>>       >
>> 
>>       > #juancache_mem 16384 MB#cache_replacement_policy heap LFUDA
>>       #El par?metro maximum_object_size define el tama?o m?ximo de los
>>       objetos que ser?n almacenados en el cache de
>>       discomaximum_object_size 200 MBcache_swap_low 90cache_swap_high
>>       95#correo del administrador del cachecache_mgr
>>       ingenieria at conexiondigital.cocachemgr_passwd cache all
>> 
>>       > #this workcache_dir aufs /var/spool/squid 40000 16 256 #this
>>       no workcache_dir aufs /var/spool/squid2 40000 16 256 
>> 
>>       > cache_effective_user squidcache_effective_group squid
>> 
>>       >
>> 
>>       >
>> 
>>       >
>> 
>>       > Juan Ernesto Alfonsoestudiante ingenier?a
>>       electr?nicauniversidad distrital Francisco Jos? de Caldas
>> 
>>       > JUANCHO
>> 
>>       >  NEMESIS 
>> 
>>       > KRAVEN
>> 
>>       >
>> 
>>       > " si un d?a tienes que elegir entre el mundo y el amor...
>> 
>>       > recuerda: 
>> 
>>       >
>> 
>>       > si eliges el mundo quedar?s sin amor, 
>> 
>>       >
>> 
>>       > pero si eliges el amor, con ?l conquistar?s al mundo" 
>> 
>>       >
>> 
>>       > albert einstein 
>> 
>>       >
>> 
>>       >
>> 
>>       >
>> 
>>       >                             
>> 
>>       >
>> 
>>       >
>> 
>>       > _______________________________________________
>> 
>>       > squid-users mailing list
>> 
>>       > squid-users at lists.squid-cache.org
>> 
>>       > http://lists.squid-cache.org/listinfo/squid-users
>> 
>> -----BEGIN PGP SIGNATURE----- 
>> Version: GnuPG v2 
>>  
>> iQEcBAEBCAAGBQJWaeLfAAoJENNXIZxhPexGV6wH/0dy5nyvKJBsB8cWnXpyU661 
>> 98aA96FF+8QlQW+dkAKyNJ/dNtjv/VyGbglqyDDoaqwq2+Uef3dZauwyIQcwoRxZ 
>> TVhUu47v+cX1F6Ka+JWxvw7hsIumoEvrXQQxdBoZUAqdXDRyvdK/VeraGyV1y2LD 
>> qYQB/vIV7u/PGgiyzE5vtZ/aHYnAsiLQxMD4a3SSvDnSNx9fklhRGyTljcNuVH5n 
>> NAXeXE3JD9+NW9rFY3/49TWNGJMNzH9v9RyQPG5uWkov/hAR1fXiRW7a/TD6pZ6V
>> /gb54gbAQcdCMXwsly7XQTswoG6OKGLuLl6+mLbLz3hgBpDfZDNAQMpKM4npiSU= 
>> =ayi0 
>> -----END PGP SIGNATURE----- 
>> 
>> 
>> _______________________________________________ squid-users mailing list squid-users at lists.squid-cache.org http://lists.squid-cache.org/listinfo/squid-users
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> As Rafael said,
> 
> Check your SELinux settings.
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151213/c2e8b8f1/attachment.htm>

From vze2k3sa at verizon.net  Sat Dec 12 22:44:12 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Sat, 12 Dec 2015 17:44:12 -0500
Subject: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than 64-bit
	(3.5.11)
Message-ID: <004701d1352e$9fba9cf0$df2fd6d0$@verizon.net>

I agree, though it would be nice if there were some *warning* in the CACHE.LOG about slow DNS transactions.
------------------------------

Message: 6
Date: Sat, 12 Dec 2015 17:03:25 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than
Message-ID: <566B9C8D.9000803 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 12/12/2015 7:42 a.m., Patrick Flaherty wrote:
> Hello,
> 
> I added the following line to my squid.conf and now Squid 3.5.11 is as fast as 2.7.2 and feels like direct internet access.
> 
> dns_v4_first on
> 

That plus the huge difference in speed tells me that you have very
broken IPv6 connectivity. Most likely ICMP is not working on your
network, or one of your upstreams.

ICMP is not an optional protocol. It is mandatory for efficient
congestion control, even in IPv4 networks.

Amos

*****



From squid3 at treenet.co.nz  Sun Dec 13 06:12:14 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 13 Dec 2015 19:12:14 +1300
Subject: [squid-users] ffserver on remote server and ffmpeg on local
In-Reply-To: <566C7924.5010408@web.de>
References: <566C7924.5010408@web.de>
Message-ID: <566D0C3E.3040708@treenet.co.nz>

On 13/12/2015 8:44 a.m., Jens Kallup wrote:
> Hello,
> 
> I have running a ffserver on remote machine without parameters - except
> 
<snip>

This is a Squid mailing list. Not ffserver.

If you are streaming via a Squid, then we can try to assist with the
HTTP portion. There are no visible details indicating any Squid problem
though.

Errors within the ffserver software should be taken to the ffserver
support channels.

Amos



From squid3 at treenet.co.nz  Sun Dec 13 06:20:35 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 13 Dec 2015 19:20:35 +1300
Subject: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than 64-bit
 (3.5.11)
In-Reply-To: <004701d1352e$9fba9cf0$df2fd6d0$@verizon.net>
References: <004701d1352e$9fba9cf0$df2fd6d0$@verizon.net>
Message-ID: <566D0E33.2060002@treenet.co.nz>

On 13/12/2015 11:44 a.m., Patrick Flaherty wrote:
> I agree, though it would be nice if there were some *warning* in the CACHE.LOG about slow DNS transactions.

It's not the DNS itslf. That appears to be working fine.

dns_v4_first having a good effect means that the DNS for A and AAAA are
both happening fast. The TCP connection opening to IPv6 servers is
timing out (dns_v4_first sorts the A to be tried first at the TCP
stage). That kind of thing happens a lot.

If you have your timeouts set to be short Squid will log transactions as
TIMEOUT. Otherwise they are just like any other broken server IP
address. Retried, but slow in getting around to the IPv4 which works.

Amos



From markus.bytom.pl at gmail.com  Sun Dec 13 12:31:39 2015
From: markus.bytom.pl at gmail.com (Markus)
Date: Sun, 13 Dec 2015 13:31:39 +0100
Subject: [squid-users] blocking certain file types by content
Message-ID: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>

I'm wondering if it is possible to detect (and block) certain files by
its header/content  like 'MZ' (0d 0a 0d 0a 4d 5a) which is a beginning
of any EXE/DLL file.

Purpose:

I'm trying to protect my internal network against unconsciously
downloading executable files (like malware). All users traffic pass
through our Squid proxy.

What I've already done is:

1. Blocking by URL (url contains \.exe \.dll and other banned extensions)
2. Blocking by server's response header (MIME-type ,
Content-Disposition and so on.)

But there is still a way to download an executable file when somebody
put it on server as e.g. readme.txt. Server's response header would be
in this case 'Content-Type: text/html;'.

So none of above mentioned rules would block this file. Of course, a
regular Web browser would show this EXE as text, which isn't
dangerous. But we can imagine a dedicated downloader (e.g. a part of
the malware) which can download binary code this way.

So, tell me guys, if there is any solution for this?

I could also use "Snort", but it would be very inflexible (I would
like to have a whitelist of domains).

even if it's possible, what about performance in real environment?
maybe there's a way to analyze only the first bytes of the incoming
stream?

greetings
Markus

PS
----
if the string 'MZ' is too short, we can also use 'This program cannot
be run in DOS mode' (this string is also part of EXE header). But
probably a majority of exe packers can compress it.


From Antony.Stone at squid.open.source.it  Sun Dec 13 12:41:00 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 13 Dec 2015 12:41:00 +0000
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
Message-ID: <201512131241.00218.Antony.Stone@squid.open.source.it>

On Sunday 13 Dec 2015 at 12:31, Markus wrote:

> I'm trying to protect my internal network against unconsciously
> downloading executable files (like malware). All users traffic pass
> through our Squid proxy.

> So, tell me guys, if there is any solution for this?

http://www.techrepublic.com/blog/linux-and-open-source/how-to-set-up-web-
filtering-solution-on-squid-proxy/ (sorry about the line split) gives not only 
a specific solution to this (albeit based on a commercial product with a free 
trial licence), but also the general concept - you want to be using an ICAP 
server.

Hope this helps,


Antony.

-- 
"It is easy to be blinded to the essential uselessness of them by the sense of 
achievement you get from getting them to work at all. In other words - and 
this is the rock solid principle on which the whole of the Corporation's 
Galaxy-wide success is founded - their fundamental design flaws are completely 
hidden by their superficial design flaws."

 - Douglas Noel Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From vze2k3sa at verizon.net  Sun Dec 13 14:37:01 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Sun, 13 Dec 2015 09:37:01 -0500
Subject: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than 64-bit
 (3.5.11)
Message-ID: <005701d135b3$bac1b490$30451db0$@verizon.net>

Without 'dns_v4_first', what is sitting on top of the IPv6 connection
timeout? Is it a DNS lookup? Regardless of it being IPv6 timing out or IPv6
timing out falling back on IPv4 and having success of a long process to
maybe should be logged as a warning?

Second question, without 'dns_v4_first', was I experiencing a IPv6 timeout
and it falling back on IPv4? Because it does ultimately work... just slow.

Third question if the answer to question 2 is yes, should the DNS IPv4
lookup (successful) be cached so that next time it is fast?

Thanks Amos,
Patrick

Message: 3
Date: Sun, 13 Dec 2015 19:20:35 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than
	64-bit (3.5.11)
Message-ID: <566D0E33.2060002 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 13/12/2015 11:44 a.m., Patrick Flaherty wrote:
> I agree, though it would be nice if there were some *warning* in the
CACHE.LOG about slow DNS transactions.

It's not the DNS itslf. That appears to be working fine.

dns_v4_first having a good effect means that the DNS for A and AAAA are both
happening fast. The TCP connection opening to IPv6 servers is timing out
(dns_v4_first sorts the A to be tried first at the TCP stage). That kind of
thing happens a lot.

If you have your timeouts set to be short Squid will log transactions as
TIMEOUT. Otherwise they are just like any other broken server IP address.
Retried, but slow in getting around to the IPv4 which works.

Amos



------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 16, Issue 50
*******************************************



From marciobacci at gmail.com  Sun Dec 13 15:25:20 2015
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Sun, 13 Dec 2015 13:25:20 -0200
Subject: [squid-users] Direct Access without Proxy
Message-ID: <CA+0TdyqPxLUf-SaH7CB-uxNTRNZVZ-ZVPXP9-4fxpCbRG4meaw@mail.gmail.com>

Hi,

What is the best way to free access to a site without going through of the
Squid Proxy?

There is a bank site that has problem when accessed through a proxy.

Could anyone give me an example?

Thanks,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151213/69a54a0d/attachment.htm>

From Antony.Stone at squid.open.source.it  Sun Dec 13 16:04:58 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 13 Dec 2015 16:04:58 +0000
Subject: [squid-users] Direct Access without Proxy
In-Reply-To: <CA+0TdyqPxLUf-SaH7CB-uxNTRNZVZ-ZVPXP9-4fxpCbRG4meaw@mail.gmail.com>
References: <CA+0TdyqPxLUf-SaH7CB-uxNTRNZVZ-ZVPXP9-4fxpCbRG4meaw@mail.gmail.com>
Message-ID: <201512131604.58753.Antony.Stone@squid.open.source.it>

On Sunday 13 Dec 2015 at 15:25, Marcio Demetrio Bacci wrote:

> Hi,
> 
> What is the best way to free access to a site without going through of the
> Squid Proxy?

Add an exception to the browser proxy configuration - generally most easily 
done using a PAC file:

if (dnsDomainIs(host, ".my.bank.com")) return "DIRECT";

> Could anyone give me an example?

http://findproxyforurl.com/example-pac-file/

Regards,


Antony.

-- 
"The future is already here.   It's just not evenly distributed yet."

 - William Gibson

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rafael.akchurin at diladele.com  Sun Dec 13 17:09:42 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sun, 13 Dec 2015 17:09:42 +0000
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
Message-ID: <VI1PR04MB135925AF9D9300201BA5EDBD8FEC0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Markus,

Indeed you need to have an ICAP server for example. The one I represent can "look into first 256 bytes" of the stream to block by real contents as indicated on http://docs.diladele.com/administrator_guide_4_3/web_filter/policies/blocking_file_downloads.html.

Of course any other ICAP server will do the same job too.
One possible is "greasy spoon icap" server.

Best regards,
Rafael Akchurin
Diladele B.V.



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Markus
Sent: Sunday, December 13, 2015 1:32 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] blocking certain file types by content

I'm wondering if it is possible to detect (and block) certain files by its header/content  like 'MZ' (0d 0a 0d 0a 4d 5a) which is a beginning of any EXE/DLL file.

Purpose:

I'm trying to protect my internal network against unconsciously downloading executable files (like malware). All users traffic pass through our Squid proxy.

What I've already done is:

1. Blocking by URL (url contains \.exe \.dll and other banned extensions) 2. Blocking by server's response header (MIME-type , Content-Disposition and so on.)

But there is still a way to download an executable file when somebody put it on server as e.g. readme.txt. Server's response header would be in this case 'Content-Type: text/html;'.

So none of above mentioned rules would block this file. Of course, a regular Web browser would show this EXE as text, which isn't dangerous. But we can imagine a dedicated downloader (e.g. a part of the malware) which can download binary code this way.

So, tell me guys, if there is any solution for this?

I could also use "Snort", but it would be very inflexible (I would like to have a whitelist of domains).

even if it's possible, what about performance in real environment?
maybe there's a way to analyze only the first bytes of the incoming stream?

greetings
Markus

PS
----
if the string 'MZ' is too short, we can also use 'This program cannot be run in DOS mode' (this string is also part of EXE header). But probably a majority of exe packers can compress it.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From rousskov at measurement-factory.com  Sun Dec 13 17:50:55 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 13 Dec 2015 10:50:55 -0700
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <201512131241.00218.Antony.Stone@squid.open.source.it>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
 <201512131241.00218.Antony.Stone@squid.open.source.it>
Message-ID: <566DAFFF.8030406@measurement-factory.com>

On 12/13/2015 05:41 AM, Antony Stone wrote:
> On Sunday 13 Dec 2015 at 12:31, Markus wrote:
> 
>> I'm trying to protect my internal network against unconsciously
>> downloading executable files (like malware). All users traffic pass
>> through our Squid proxy.

> http://www.techrepublic.com/blog/linux-and-open-source/how-to-set-up-web-
> filtering-solution-on-squid-proxy/ (sorry about the line split) gives not only 
> a specific solution to this (albeit based on a commercial product with a free 
> trial licence), but also the general concept - you want to be using an ICAP 
> server.


Or an eCAP service. There is a free eCAP adapter that integrates with
ClamAV, for example: http://www.e-cap.org/Market


HTH,

Alex.



From yvoinov at gmail.com  Sun Dec 13 18:32:55 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 14 Dec 2015 00:32:55 +0600
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
Message-ID: <566DB9D7.8080603@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
For malware checking we have two working (and performance) solutions:

http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP

No need to block any and all executables in the world. Just enough to
check it with AV-engine. ;)

13.12.15 18:31, Markus ?????:
> I'm wondering if it is possible to detect (and block) certain files by
> its header/content  like 'MZ' (0d 0a 0d 0a 4d 5a) which is a beginning
> of any EXE/DLL file.
>
> Purpose:
>
> I'm trying to protect my internal network against unconsciously
> downloading executable files (like malware). All users traffic pass
> through our Squid proxy.
>
> What I've already done is:
>
> 1. Blocking by URL (url contains \.exe \.dll and other banned extensions)
> 2. Blocking by server's response header (MIME-type ,
> Content-Disposition and so on.)
>
> But there is still a way to download an executable file when somebody
> put it on server as e.g. readme.txt. Server's response header would be
> in this case 'Content-Type: text/html;'.
>
> So none of above mentioned rules would block this file. Of course, a
> regular Web browser would show this EXE as text, which isn't
> dangerous. But we can imagine a dedicated downloader (e.g. a part of
> the malware) which can download binary code this way.
>
> So, tell me guys, if there is any solution for this?
>
> I could also use "Snort", but it would be very inflexible (I would
> like to have a whitelist of domains).
>
> even if it's possible, what about performance in real environment?
> maybe there's a way to analyze only the first bytes of the incoming
> stream?
>
> greetings
> Markus
>
> PS
> ----
> if the string 'MZ' is too short, we can also use 'This program cannot
> be run in DOS mode' (this string is also part of EXE header). But
> probably a majority of exe packers can compress it.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWbbnXAAoJENNXIZxhPexGUeYIAJuUrT1HI7kTu2yh/yqyJT6D
r7DXoOmoNOXjLUqNNZDC/wXBQVVXzfDFAYGXCSeUr/EHAhl+UKeNyISEK0LAbb+h
x3QUJkBytBt+b5UaUNLjf4lod2DlgT2npSXAZGoSynJkbPgKsPGfoRbKYtu88y4R
cZSoltP9T2NIZ+IXQVx1ZCz+HF0LKjFRjGt+lHPf26HnpF8CHGelMDL+QBgeA+B6
0PYx2OKlZjJu6fA2P6vX8CjfTTm4ZsSf960KjptWCdUEVFsVHGBEQZ5zTg5qcnmW
MKIdSWbuDUfgFerQyLHbdsWcLL+fBicas87iYidSInFOZ+keFYmf+MsEb1LNalI=
=nvsX
-----END PGP SIGNATURE-----



From markus.bytom.pl at gmail.com  Sun Dec 13 20:22:20 2015
From: markus.bytom.pl at gmail.com (Markus)
Date: Sun, 13 Dec 2015 21:22:20 +0100
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <566DB9D7.8080603@gmail.com>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
 <566DB9D7.8080603@gmail.com>
Message-ID: <CAFp+3KcVscRexYWMEyt3tiEeMRG5_LBWFDvnk2uEAfyEcS3GSA@mail.gmail.com>

hi,
thanks for your help guys. I suspected that ICAP will be necessary.
but I thought that even ICAP checks it only by the file extension or
by server response (mime-type). Surprisingly Diladele is able to check
the first bytes of file content, which is exactly what I wanted.
On the other hand I don't want to check exe files by external AV for 2 reasons
1. I don't believe in its effectiveness :)
2. each user has an comercial AV on his PC
As I said in the first post - I already block exe files by squid ACL.
Now I'm afraid that some malware software can get through web/http by
omitting this ACL (will be downloaded as jpg).

thanks. Now I have to read more about available ICAP servers :)

On Sun, Dec 13, 2015 at 7:32 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> For malware checking we have two working (and performance) solutions:
>
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP
>
> No need to block any and all executables in the world. Just enough to
> check it with AV-engine. ;)
>
> 13.12.15 18:31, Markus ?????:
>> I'm wondering if it is possible to detect (and block) certain files by
>> its header/content  like 'MZ' (0d 0a 0d 0a 4d 5a) which is a beginning
>> of any EXE/DLL file.
>>
>> Purpose:
>>
>> I'm trying to protect my internal network against unconsciously
>> downloading executable files (like malware). All users traffic pass
>> through our Squid proxy.
>>
>> What I've already done is:
>>
>> 1. Blocking by URL (url contains \.exe \.dll and other banned extensions)
>> 2. Blocking by server's response header (MIME-type ,
>> Content-Disposition and so on.)
>>
>> But there is still a way to download an executable file when somebody
>> put it on server as e.g. readme.txt. Server's response header would be
>> in this case 'Content-Type: text/html;'.
>>
>> So none of above mentioned rules would block this file. Of course, a
>> regular Web browser would show this EXE as text, which isn't
>> dangerous. But we can imagine a dedicated downloader (e.g. a part of
>> the malware) which can download binary code this way.
>>
>> So, tell me guys, if there is any solution for this?
>>
>> I could also use "Snort", but it would be very inflexible (I would
>> like to have a whitelist of domains).
>>
>> even if it's possible, what about performance in real environment?
>> maybe there's a way to analyze only the first bytes of the incoming
>> stream?
>>
>> greetings
>> Markus
>>
>> PS
>> ----
>> if the string 'MZ' is too short, we can also use 'This program cannot
>> be run in DOS mode' (this string is also part of EXE header). But
>> probably a majority of exe packers can compress it.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJWbbnXAAoJENNXIZxhPexGUeYIAJuUrT1HI7kTu2yh/yqyJT6D
> r7DXoOmoNOXjLUqNNZDC/wXBQVVXzfDFAYGXCSeUr/EHAhl+UKeNyISEK0LAbb+h
> x3QUJkBytBt+b5UaUNLjf4lod2DlgT2npSXAZGoSynJkbPgKsPGfoRbKYtu88y4R
> cZSoltP9T2NIZ+IXQVx1ZCz+HF0LKjFRjGt+lHPf26HnpF8CHGelMDL+QBgeA+B6
> 0PYx2OKlZjJu6fA2P6vX8CjfTTm4ZsSf960KjptWCdUEVFsVHGBEQZ5zTg5qcnmW
> MKIdSWbuDUfgFerQyLHbdsWcLL+fBicas87iYidSInFOZ+keFYmf+MsEb1LNalI=
> =nvsX
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Sun Dec 13 20:39:42 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 14 Dec 2015 02:39:42 +0600
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <CAFp+3KcVscRexYWMEyt3tiEeMRG5_LBWFDvnk2uEAfyEcS3GSA@mail.gmail.com>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
 <566DB9D7.8080603@gmail.com>
 <CAFp+3KcVscRexYWMEyt3tiEeMRG5_LBWFDvnk2uEAfyEcS3GSA@mail.gmail.com>
Message-ID: <566DD78E.6040706@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


14.12.15 2:22, Markus ?????:
> hi,
> thanks for your help guys. I suspected that ICAP will be necessary.
> but I thought that even ICAP checks it only by the file extension or
> by server response (mime-type). Surprisingly Diladele is able to check
> the first bytes of file content, which is exactly what I wanted.

ICAP-Clamav solution does the same. You can adjust it as you wish.

> On the other hand I don't want to check exe files by external AV for 2 reasons
> 1. I don't believe in its effectiveness :)
Faith is not an option. Practical applications for several years proved
their effectiveness. Of course, a matter of personal faith can deny a
personal experience.

> 2. each user has an comercial AV on his PC

So what?  This does not preclude the need to filter Internet content.
Practice shows that one does not exclude the other.

> As I said in the first post - I already block exe files by squid ACL.
> Now I'm afraid that some malware software can get through web/http by
> omitting this ACL (will be downloaded as jpg).

With this purpose and is used ICAP/eCAP solution(s).

>
> thanks. Now I have to read more about available ICAP servers :)
>
> On Sun, Dec 13, 2015 at 7:32 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>
> For malware checking we have two working (and performance) solutions:
>
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP
>
> No need to block any and all executables in the world. Just enough to
> check it with AV-engine. ;)
>
> 13.12.15 18:31, Markus ?????:
> >>> I'm wondering if it is possible to detect (and block) certain files by
> >>> its header/content  like 'MZ' (0d 0a 0d 0a 4d 5a) which is a beginning
> >>> of any EXE/DLL file.
> >>>
> >>> Purpose:
> >>>
> >>> I'm trying to protect my internal network against unconsciously
> >>> downloading executable files (like malware). All users traffic pass
> >>> through our Squid proxy.
> >>>
> >>> What I've already done is:
> >>>
> >>> 1. Blocking by URL (url contains \.exe \.dll and other banned
extensions)
> >>> 2. Blocking by server's response header (MIME-type ,
> >>> Content-Disposition and so on.)
> >>>
> >>> But there is still a way to download an executable file when somebody
> >>> put it on server as e.g. readme.txt. Server's response header would be
> >>> in this case 'Content-Type: text/html;'.
> >>>
> >>> So none of above mentioned rules would block this file. Of course, a
> >>> regular Web browser would show this EXE as text, which isn't
> >>> dangerous. But we can imagine a dedicated downloader (e.g. a part of
> >>> the malware) which can download binary code this way.
> >>>
> >>> So, tell me guys, if there is any solution for this?
> >>>
> >>> I could also use "Snort", but it would be very inflexible (I would
> >>> like to have a whitelist of domains).
> >>>
> >>> even if it's possible, what about performance in real environment?
> >>> maybe there's a way to analyze only the first bytes of the incoming
> >>> stream?
> >>>
> >>> greetings
> >>> Markus
> >>>
> >>> PS
> >>> ----
> >>> if the string 'MZ' is too short, we can also use 'This program cannot
> >>> be run in DOS mode' (this string is also part of EXE header). But
> >>> probably a majority of exe packers can compress it.
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWbdeOAAoJENNXIZxhPexGV2gIAM0nXZAMeD2QNuGaU3i5outm
rDWOhVbSglJwZU+2TX+Wr/mg23zyTEMZDvWGWmnatwgOeFF6VRiZBhkAwfxSZxd0
c2CSIXLEU+XtSswy02FONzBakjXsuPlR+WwwvadlextCTeMejS0uTDiAEKhtaS3+
S8pjlVl1bbGYDvhNoDp0E1Koq8/r69dzxs0mZE1p23gRPcQ2skadyjwpxn8Om88x
gF1J2Vy2JjcTM15ZmM8VkDxwXb9XVmxCCdunOMHm5yxWyLkAd6jlzqVX8IYDJdMX
8jr+B3mNkd4ZkU8Cp6rJ37jJsuowplYO/DGHWzgAS3csUp6occBu6VizGIjZn+0=
=6vxB
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151214/9bc523a8/attachment.htm>

From yvoinov at gmail.com  Sun Dec 13 20:47:12 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 14 Dec 2015 02:47:12 +0600
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <CAFp+3KcVscRexYWMEyt3tiEeMRG5_LBWFDvnk2uEAfyEcS3GSA@mail.gmail.com>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
 <566DB9D7.8080603@gmail.com>
 <CAFp+3KcVscRexYWMEyt3tiEeMRG5_LBWFDvnk2uEAfyEcS3GSA@mail.gmail.com>
Message-ID: <566DD950.5020904@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Finally,

14.12.15 2:22, Markus ?????:
> hi,
> thanks for your help guys. I suspected that ICAP will be necessary.
> but I thought that even ICAP checks it only by the file extension or
> by server response (mime-type). Surprisingly Diladele is able to check

Think more. ALL ICAP solutions checks content. Diladele is not only
solution which checks content.

> the first bytes of file content, which is exactly what I wanted.
> On the other hand I don't want to check exe files by external AV for 2
reasons
> 1. I don't believe in its effectiveness :)
> 2. each user has an comercial AV on his PC

You need to learn - not all commercial anti-virus software detects all.
And vice versa. Therefore, even if an external antivirus control reduces
the probability of malware  penetration just twice - it should be used.

Also, remember one thing. Caching Proxy can be infected - and then you
get a large-scale epidemic, regardless used on the client computer
antivirus software or not.

I have encountered similar situations in the past and they usually lead
to large-scale network failures.

> As I said in the first post - I already block exe files by squid ACL.

You really think executable files can have only known extension?

> Now I'm afraid that some malware software can get through web/http by
> omitting this ACL (will be downloaded as jpg).

Sure. That is why you will be forced to use only one really existing
solution.

>
> thanks. Now I have to read more about available ICAP servers :)
>
> On Sun, Dec 13, 2015 at 7:32 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>
> For malware checking we have two working (and performance) solutions:
>
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP
>
> No need to block any and all executables in the world. Just enough to
> check it with AV-engine. ;)
>
> 13.12.15 18:31, Markus ?????:
> >>> I'm wondering if it is possible to detect (and block) certain files by
> >>> its header/content  like 'MZ' (0d 0a 0d 0a 4d 5a) which is a beginning
> >>> of any EXE/DLL file.
> >>>
> >>> Purpose:
> >>>
> >>> I'm trying to protect my internal network against unconsciously
> >>> downloading executable files (like malware). All users traffic pass
> >>> through our Squid proxy.
> >>>
> >>> What I've already done is:
> >>>
> >>> 1. Blocking by URL (url contains \.exe \.dll and other banned
extensions)
> >>> 2. Blocking by server's response header (MIME-type ,
> >>> Content-Disposition and so on.)
> >>>
> >>> But there is still a way to download an executable file when somebody
> >>> put it on server as e.g. readme.txt. Server's response header would be
> >>> in this case 'Content-Type: text/html;'.
> >>>
> >>> So none of above mentioned rules would block this file. Of course, a
> >>> regular Web browser would show this EXE as text, which isn't
> >>> dangerous. But we can imagine a dedicated downloader (e.g. a part of
> >>> the malware) which can download binary code this way.
> >>>
> >>> So, tell me guys, if there is any solution for this?
> >>>
> >>> I could also use "Snort", but it would be very inflexible (I would
> >>> like to have a whitelist of domains).
> >>>
> >>> even if it's possible, what about performance in real environment?
> >>> maybe there's a way to analyze only the first bytes of the incoming
> >>> stream?
> >>>
> >>> greetings
> >>> Markus
> >>>
> >>> PS
> >>> ----
> >>> if the string 'MZ' is too short, we can also use 'This program cannot
> >>> be run in DOS mode' (this string is also part of EXE header). But
> >>> probably a majority of exe packers can compress it.
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWbdlQAAoJENNXIZxhPexGJTUH/2DC/xG9EsI5oR0VHJsKuoid
2gYed3/wEq1uA2VJCZVe2Cbnr9mEkA25Kg6xEUoMUVNGI8zRGimt1BSiXk5HK+7G
P0B588oY3R5TpgwwREmF6ZKnqgX6X0weORM2QzEwS0K/FiWOY05LJ4XoX32lqIfq
fYokJ2MCtgvRFtXA7vKxokHA5IyG5xgKf4fYfDnXY2wN+yCaYj2GqACpzfNzn9xn
Zbiqf1DH0S5hIEac5n1Z5oPmEjcEUgVlkeJ8i8nCCIdsinBAhYVC9TCK9ZDJymuF
1IkBHHJAyj5UoJHOB2k1Nkihx4faRfdLc2rTcNkzXvT34kXjUbXFfvEkz0UYUkU=
=fk/o
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151214/1174d5b5/attachment.htm>

From markus.bytom.pl at gmail.com  Sun Dec 13 21:39:19 2015
From: markus.bytom.pl at gmail.com (Markus)
Date: Sun, 13 Dec 2015 22:39:19 +0100
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <566DD950.5020904@gmail.com>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
 <566DB9D7.8080603@gmail.com>
 <CAFp+3KcVscRexYWMEyt3tiEeMRG5_LBWFDvnk2uEAfyEcS3GSA@mail.gmail.com>
 <566DD950.5020904@gmail.com>
Message-ID: <CAFp+3Kd+ckzSfoya7wMV4Sh4A72NaJYSQiiQWC3-1ytCxkRDWQ@mail.gmail.com>

Yuri Voinov wrote:

> Think more. ALL ICAP solutions checks content. Diladele is not only solution which checks content.
[...]

> You really think executable files can have only known extension?


My way of thinking was like that:
instead of testing with AV each .exe or .zip file better block it out
(except for whitelist domains). Because testing with AV needs CPU/RAM.
But as we already established - executables can be downloaded as JPG
/TXT or whatever. If so - AV makes only sense if we test every kind of
extensions/streams. Right?

let's consider such possible case:

here we have putty.exe (without virus ;-) , but saved as txt file:

http://6web.pl/~mserafin/putty.txt

now we can just download it and change extension for exe. My question is -
can ICAP-Clamav detect that it's windows executable and block it?
(even without testing against viruses)?

and here more complicated case:

http://6web.pl/~mserafin/putty_zip.txt   (it's a regular ZIP file with
putty.exe inside)


Can ICAP-Clamav deal with it?

thx!

On Sun, Dec 13, 2015 at 9:47 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Finally,
>
> 14.12.15 2:22, Markus ?????:
>> hi,
>> thanks for your help guys. I suspected that ICAP will be necessary.
>> but I thought that even ICAP checks it only by the file extension or
>> by server response (mime-type). Surprisingly Diladele is able to check
>
> Think more. ALL ICAP solutions checks content. Diladele is not only solution
> which checks content.
>
>> the first bytes of file content, which is exactly what I wanted.
>> On the other hand I don't want to check exe files by external AV for 2
>> reasons
>> 1. I don't believe in its effectiveness :)
>> 2. each user has an comercial AV on his PC
>
> You need to learn - not all commercial anti-virus software detects all. And
> vice versa. Therefore, even if an external antivirus control reduces the
> probability of malware  penetration just twice - it should be used.
>
> Also, remember one thing. Caching Proxy can be infected - and then you get a
> large-scale epidemic, regardless used on the client computer antivirus
> software or not.
>
> I have encountered similar situations in the past and they usually lead to
> large-scale network failures.
>
>> As I said in the first post - I already block exe files by squid ACL.
>
> You really think executable files can have only known extension?
>
>> Now I'm afraid that some malware software can get through web/http by
>> omitting this ACL (will be downloaded as jpg).
>
> Sure. That is why you will be forced to use only one really existing
> solution.
>
>>
>> thanks. Now I have to read more about available ICAP servers :)
>>
>> On Sun, Dec 13, 2015 at 7:32 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>>
>> For malware checking we have two working (and performance) solutions:
>>
>> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
>> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP
>>
>> No need to block any and all executables in the world. Just enough to
>> check it with AV-engine. ;)
>>
>> 13.12.15 18:31, Markus ?????:
>> >>> I'm wondering if it is possible to detect (and block) certain files by
>> >>> its header/content  like 'MZ' (0d 0a 0d 0a 4d 5a) which is a beginning
>> >>> of any EXE/DLL file.
>> >>>
>> >>> Purpose:
>> >>>
>> >>> I'm trying to protect my internal network against unconsciously
>> >>> downloading executable files (like malware). All users traffic pass
>> >>> through our Squid proxy.
>> >>>
>> >>> What I've already done is:
>> >>>
>> >>> 1. Blocking by URL (url contains \.exe \.dll and other banned
>> >>> extensions)
>> >>> 2. Blocking by server's response header (MIME-type ,
>> >>> Content-Disposition and so on.)
>> >>>
>> >>> But there is still a way to download an executable file when somebody
>> >>> put it on server as e.g. readme.txt. Server's response header would be
>> >>> in this case 'Content-Type: text/html;'.
>> >>>
>> >>> So none of above mentioned rules would block this file. Of course, a
>> >>> regular Web browser would show this EXE as text, which isn't
>> >>> dangerous. But we can imagine a dedicated downloader (e.g. a part of
>> >>> the malware) which can download binary code this way.
>> >>>
>> >>> So, tell me guys, if there is any solution for this?
>> >>>
>> >>> I could also use "Snort", but it would be very inflexible (I would
>> >>> like to have a whitelist of domains).
>> >>>
>> >>> even if it's possible, what about performance in real environment?
>> >>> maybe there's a way to analyze only the first bytes of the incoming
>> >>> stream?
>> >>>
>> >>> greetings
>> >>> Markus
>> >>>
>> >>> PS
>> >>> ----
>> >>> if the string 'MZ' is too short, we can also use 'This program cannot
>> >>> be run in DOS mode' (this string is also part of EXE header). But
>> >>> probably a majority of exe packers can compress it.
>> >>> _______________________________________________
>> >>> squid-users mailing list
>> >>> squid-users at lists.squid-cache.org
>> >>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJWbdlQAAoJENNXIZxhPexGJTUH/2DC/xG9EsI5oR0VHJsKuoid
> 2gYed3/wEq1uA2VJCZVe2Cbnr9mEkA25Kg6xEUoMUVNGI8zRGimt1BSiXk5HK+7G
> P0B588oY3R5TpgwwREmF6ZKnqgX6X0weORM2QzEwS0K/FiWOY05LJ4XoX32lqIfq
> fYokJ2MCtgvRFtXA7vKxokHA5IyG5xgKf4fYfDnXY2wN+yCaYj2GqACpzfNzn9xn
> Zbiqf1DH0S5hIEac5n1Z5oPmEjcEUgVlkeJ8i8nCCIdsinBAhYVC9TCK9ZDJymuF
> 1IkBHHJAyj5UoJHOB2k1Nkihx4faRfdLc2rTcNkzXvT34kXjUbXFfvEkz0UYUkU=
> =fk/o
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From squid3 at treenet.co.nz  Mon Dec 14 05:13:27 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 14 Dec 2015 18:13:27 +1300
Subject: [squid-users] Fw: Squid 32-bit (2.7.2) much faster than 64-bit
 (3.5.11)
In-Reply-To: <005701d135b3$bac1b490$30451db0$@verizon.net>
References: <005701d135b3$bac1b490$30451db0$@verizon.net>
Message-ID: <566E4FF7.5050900@treenet.co.nz>

On 14/12/2015 3:37 a.m., Patrick Flaherty wrote:
> Without 'dns_v4_first', what is sitting on top of the IPv6 connection
> timeout?

The processing order is:
  Select set of potential servers to contact,
  DNS lookups [ both A and AAAA in parallel],
  IP sorting order [v6 first],
  TCP connect(2) [which times out],
  ... repeat until TCP succeeds or runs out of possible server IPs.
  do HTTP stuff...


> Is it a DNS lookup? Regardless of it being IPv6 timing out or IPv6
> timing out falling back on IPv4 and having success of a long process to
> maybe should be logged as a warning?
> 
> Second question, without 'dns_v4_first', was I experiencing a IPv6 timeout
> and it falling back on IPv4? Because it does ultimately work... just slow.

Yes. All the evidence suggests that you are/were.

When IPv4 is tried first (dns_v4_first on), then IPv6 is rarely tried at
all. So rarely affects the connections even though v6 connectivity
remains broken for your network, and when clients *do* try to connect to
v6-only services they have the same breakage.

It is quite common to have no route to some networks, broken links,
broken tunnels, or devices which are v4-only somewhere along the
Internet paths. Those events are signalled with ICMP (v4 or v6) packets.
So ICMP is *not* optional.

It is great that you have working v4, and a temporary workaround in
Squid for reducing the impact of the v6 breakage. Now please try to fix
the v6. Because a) the workaround really is temporary - it will
gradually stop working as more and more services need v6-only access,
and b) it will be affecting a lot of other v6 traffic attempts outside
of Squid.


> 
> Third question if the answer to question 2 is yes, should the DNS IPv4
> lookup (successful) be cached so that next time it is fast?

DNS results are always cached. And before you get to it - yes the cache
is also updated with good/bad flags of which IPs are connecting
successfully and which are failing, in order to skip the fail ones on
later attempts.

I think DNS is a red-herring, those processes seem to be working just
fine. dns_v4_first just happens to be an option that makes the next
stages of Squid (after DNS) use IPv4 instead of IPv6, which reveals or
hides the network layer problems at the later TCP connect stage.

Amos



From squid3 at treenet.co.nz  Mon Dec 14 05:57:16 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 14 Dec 2015 18:57:16 +1300
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <CAFp+3Kd+ckzSfoya7wMV4Sh4A72NaJYSQiiQWC3-1ytCxkRDWQ@mail.gmail.com>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
 <566DB9D7.8080603@gmail.com>
 <CAFp+3KcVscRexYWMEyt3tiEeMRG5_LBWFDvnk2uEAfyEcS3GSA@mail.gmail.com>
 <566DD950.5020904@gmail.com>
 <CAFp+3Kd+ckzSfoya7wMV4Sh4A72NaJYSQiiQWC3-1ytCxkRDWQ@mail.gmail.com>
Message-ID: <566E5A3C.2070001@treenet.co.nz>

On 14/12/2015 10:39 a.m., Markus wrote:
> Yuri Voinov wrote:
> 
>> Think more. ALL ICAP solutions checks content. Diladele is not only solution which checks content.
> [...]
> 
>> You really think executable files can have only known extension?
> 
> 
> My way of thinking was like that:
> instead of testing with AV each .exe or .zip file better block it out
> (except for whitelist domains). Because testing with AV needs CPU/RAM.
> But as we already established - executables can be downloaded as JPG
> /TXT or whatever. If so - AV makes only sense if we test every kind of
> extensions/streams. Right?

Correct.

> 
> let's consider such possible case:
> 
> here we have putty.exe (without virus ;-) , but saved as txt file:
> 
> http://6web.pl/~mserafin/putty.txt
> 
> now we can just download it and change extension for exe. My question is -
> can ICAP-Clamav detect that it's windows executable and block it?
> (even without testing against viruses)?


You are making the mistake of thinking of
"http://6web.pl/~mserafin/putty.txt" as a file. There is no concept of
"file" in HTTP and thus also no "file extension".
It might be one for this case, but while it is in HTTP it ceases acting
like one.

The reality is that "http://6web.pl/~mserafin/putty.txt" is just a
resource locator;
 * It has no guaranteed relationship to the actual delivered content
type, and
 * there may be a file involved - or not, and
 * any file which is involved may exist at that location on the server -
or somewhere else (even another server), and
 * the response to that URL may be a singular object, multi-part
response with multiple objects, a 206 partial object or network
generated 3xx-5xx objects.


> 
> and here more complicated case:
> 
> http://6web.pl/~mserafin/putty_zip.txt   (it's a regular ZIP file with
> putty.exe inside)
> 
> 
> Can ICAP-Clamav deal with it?

Good question. For the two simplistic cases you describe the answer is
probably yes - if we assume the responses are whole files.

Clamav insists on saving objects to disk to scan them fully, or at least
the initial bytes of the object. It is a little restricted in that way.

Other AV might do better with the more complicated HTTP response cases,
or they might not. I'm not familiar with how each works. I just know
that clamav is designed as a file-based scanner. Other AV have
designed-in ICAP services, so may work better (but costly).

Amos


From 79501810059 at yandex.ru  Mon Dec 14 08:43:16 2015
From: 79501810059 at yandex.ru (=?koi8-r?B?8MHSxsXOz9fJ3iDuLuEu?=)
Date: Mon, 14 Dec 2015 13:43:16 +0500
Subject: [squid-users] Peek and splice without replacing the certificates
Message-ID: <343421450082596@web5h.yandex.ru>

Hello! Show you how to use Squid in transparent mode for tracking HTTPS without replacing the certificates?
My squid.conf: http://pastebin.ru/AWU8LXvK. If such a configuration file
to use version 3.5.8 squid compiled using Libressl, everything works
fine. But if you use version 3.5.9 and above, Squid begins to "terminated" in
the number of clients above 20. Moreover, interrupted for no apparent reason and messages in the logs. Also tested versions> = 4.0, the effect is the same - Squid "terminated". How to overcome the problem? Correct any
configuration I have? Thank you in advance. PS .: Sorry for my english 


From yvoinov at gmail.com  Mon Dec 14 09:19:08 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 14 Dec 2015 15:19:08 +0600
Subject: [squid-users] blocking certain file types by content
In-Reply-To: <566E5A3C.2070001@treenet.co.nz>
References: <CAFp+3KcbHyx7_VcMffk8Pcw-7f0Rpk=ZsGaOypR9NzfsUZNnkw@mail.gmail.com>
 <566DB9D7.8080603@gmail.com>
 <CAFp+3KcVscRexYWMEyt3tiEeMRG5_LBWFDvnk2uEAfyEcS3GSA@mail.gmail.com>
 <566DD950.5020904@gmail.com>
 <CAFp+3Kd+ckzSfoya7wMV4Sh4A72NaJYSQiiQWC3-1ytCxkRDWQ@mail.gmail.com>
 <566E5A3C.2070001@treenet.co.nz>
Message-ID: <566E898C.3080405@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


14.12.15 11:57, Amos Jeffries ?????:
> On 14/12/2015 10:39 a.m., Markus wrote:
>> Yuri Voinov wrote:
>>
>>> Think more. ALL ICAP solutions checks content. Diladele is not only
solution which checks content.
>> [...]
>>
>>> You really think executable files can have only known extension?
>>
>>
>> My way of thinking was like that:
>> instead of testing with AV each .exe or .zip file better block it out
>> (except for whitelist domains). Because testing with AV needs CPU/RAM.
>> But as we already established - executables can be downloaded as JPG
>> /TXT or whatever. If so - AV makes only sense if we test every kind of
>> extensions/streams. Right?
>
> Correct.
>
>>
>> let's consider such possible case:
>>
>> here we have putty.exe (without virus ;-) , but saved as txt file:
>>
>> http://6web.pl/~mserafin/putty.txt
>>
>> now we can just download it and change extension for exe. My question
is -
>> can ICAP-Clamav detect that it's windows executable and block it?
>> (even without testing against viruses)?
>
>
> You are making the mistake of thinking of
> "http://6web.pl/~mserafin/putty.txt" as a file. There is no concept of
> "file" in HTTP and thus also no "file extension".
> It might be one for this case, but while it is in HTTP it ceases acting
> like one.
>
> The reality is that "http://6web.pl/~mserafin/putty.txt" is just a
> resource locator;
>  * It has no guaranteed relationship to the actual delivered content
> type, and
>  * there may be a file involved - or not, and
>  * any file which is involved may exist at that location on the server -
> or somewhere else (even another server), and
>  * the response to that URL may be a singular object, multi-part
> response with multiple objects, a 206 partial object or network
> generated 3xx-5xx objects.
>
>
>>
>> and here more complicated case:
>>
>> http://6web.pl/~mserafin/putty_zip.txt   (it's a regular ZIP file with
>> putty.exe inside)
>>
>>
>> Can ICAP-Clamav deal with it?
>
> Good question. For the two simplistic cases you describe the answer is
> probably yes - if we assume the responses are whole files.
>
> Clamav insists on saving objects to disk to scan them fully, or at least
> the initial bytes of the object. It is a little restricted in that way.
>
> Other AV might do better with the more complicated HTTP response cases,
> or they might not. I'm not familiar with how each works. I just know
> that clamav is designed as a file-based scanner. Other AV have
No. Clamav use INSTREAM API for scanning. I-CAP based squidclamav
utilizes it for years.
>
> designed-in ICAP services, so may work better (but costly).
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWbomMAAoJENNXIZxhPexGdEAH/ixLaaqMjogpgd0cnVqQELTs
GCQAbHKb0IEujv7ZNGRr00DeUiPMA7AlZ4FzC7G/MZmV8hI4RU7m6f3negJUpeIf
w20gcq6MCc1lorHB5emvaYw2RLbDAiiLdVzcNBDWbntqjRyd3FiOPcf+w27ch47R
8gaDIyViqs/ndJOp85AtjTMifWR7KCE61utKS4+VBO44KHdPbiZXa6PnzsLUdeYq
+iXrxWzjTduf8iq1QkL8z6Ms1Gk0ApwtSemJD8sJCR7drOfj5azepOFhQNIvwS1Z
YUMH/AyBpsPTpy+TG3vEJfloppztm6l1gT4nppFN4HaJHFmMXoj0Wn0MB5AYNeQ=
=AnSo
-----END PGP SIGNATURE-----



From igor.dzombic at fela.ch  Mon Dec 14 10:07:06 2015
From: igor.dzombic at fela.ch (Igor Dzombic)
Date: Mon, 14 Dec 2015 11:07:06 +0100 (CET)
Subject: [squid-users] URL Cacheing Question
Message-ID: <00cb01d13657$2fa9b200$8efd1600$@fela.ch>

Hallo Squid Team,

i have one Question, i?m trying to Configure Squid-Proxy-Server and i need
your help. It should work like this:

-          i should cache one URL (like
http://backend.my-server.net/servlets/fgi/onepage.php) and refrashe it
every 5 min. on a Squid-Proxy Server

-          My Clients should access ONLY this page and in a case that this
page ist not reachable (no Internet-Connection), clients should load the
Page from Proxy Cache

-          Proxy Server (Squid) have Static LAN IP Adress ? 172.27.11.1
255.255.0.0

-          Clients have Static LAN IP Adresses ? 172.27.72.x 255.255.0.0,
Web Browser Client is Mizilla FireFox

I hope you can help me.

Thanks in advance

Igor Dzombic







Freundliche Gr?sse

Igor Dzombic



FELA Management AG      Phone : +41 52 646 46 14

Basadingerstrasse 18    Fax   : +41 52 646 46 96

CH-8253 Diessenhofen    Mail  :  <mailto:igor.dzombic at fela.ch>
igor.dzombic at fela.ch

 <http://www.fela.ch/> http://www.fela.ch/



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151214/99a5d101/attachment.htm>

From magiclink at outlook.com  Mon Dec 14 14:01:06 2015
From: magiclink at outlook.com (Magic Link)
Date: Mon, 14 Dec 2015 15:01:06 +0100
Subject: [squid-users] issue with video
In-Reply-To: <DUB130-W4883D1369E0FC96B14F00ABDEA0@phx.gbl>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>, ,
 <5668B48C.703@treenet.co.nz>, <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>, ,
 <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl>, 
 <5669997A.70209@gmail.com>,<DUB130-W4883D1369E0FC96B14F00ABDEA0@phx.gbl>
Message-ID: <DUB130-W6B91C01FA9412AB19D44CBDED0@phx.gbl>

Any ideas ?
Thanks !

From: magiclink at outlook.com
To: yvoinov at gmail.com; squid-users at lists.squid-cache.org
Date: Fri, 11 Dec 2015 11:40:01 +0100
Subject: Re: [squid-users] issue with video




https://drive.google.com/file/d/0B5u1WrFLUfPiNWhXLVRJZnJETzA/view?usp=sharing
I test with squid 3.5.10 (from debian testing repository) et no luck :( it doesn't work too

To: squid-users at lists.squid-cache.org
From: yvoinov at gmail.com
Date: Thu, 10 Dec 2015 21:25:46 +0600
Subject: Re: [squid-users] issue with video


  
    
  
  
    

    -----BEGIN PGP SIGNED MESSAGE----- 

    Hash: SHA256 

     

    tar -cvf logs.tar access.log cache.log; gzip -9 logs.tar ->
    http://drive.google.com -> sahre+post URL's

    

    10.12.15 19:56, Magic Link ?????:

    > Where can i upload my logs ?
      It's too big for the mail.

      >

      > From: magiclink at outlook.com

      > To: squid3 at treenet.co.nz; squid-users at lists.squid-cache.org

      > Subject: RE: [squid-users] issue with video

      > Date: Thu, 10 Dec 2015 11:29:42 +0100

      >

      >

      >

      >

      > I activated the debug_option. I don't see anything particular
      in access.log, but i don't know what to do with the content of
      cache.logI 'v never compiled squid, is there a tutorial ? I used
      to use the debian stable repository, but get only the 3.4.8
      version for debian 8 (i can try with testing repository or another
      one if so)

      >

      > Thanks

      >> To: squid-users at lists.squid-cache.org

      >> From: squid3 at treenet.co.nz

      >> Date: Thu, 10 Dec 2015 12:09:00 +1300

      >> Subject: Re: [squid-users] issue with video

      >>

      >> On 10/12/2015 3:42 a.m., Magic Link wrote:

      >>> Hi,

      >>> i have a problem with this video
      http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/
      This video doesn't start with squid (3.4.8) on Debian 8 but does
      with a direct access to Internet.I don't know how to debug this
      issue.

      >>> Any clues ? Thanks                           

      >>>

      >>

      >> Check cache.log to see if any errors are being logged
      when you request it.

      >>

      >> Check access.log to see if the proxy is actually being
      contacted to

      >> fetch the video.

      >>

      >> "debug_options 11,2" to see what the request and reply
      headers are.

      >>

      >> If you can, try an upgrade. Current Squid is 3.5.12. I'm
      just mentioning

      >> this because its the nromal debugging step. I dont
      recommend a

      >> cross-install of the 3.5.12 package to Debian 8 - it
      needs a proper

      >> backport / recompile.

      >>

      >> The remaining steps get trickier and depend on the
      results of the above

      >> checks, or whether

      >>

      >>

      >> Amos

      >>

      >> _______________________________________________

      >> squid-users mailing list

      >> squid-users at lists.squid-cache.org

      >> http://lists.squid-cache.org/listinfo/squid-users

      >                                                       

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org

      > http://lists.squid-cache.org/listinfo/squid-users

    

    -----BEGIN PGP SIGNATURE-----


    Version: GnuPG v2


     

    iQEcBAEBCAAGBQJWaZl6AAoJENNXIZxhPexGGe4IAILsG3rcB+8WN0bn5++RHUie


    ts4SNFYvOgmDt48xfy1uOzpjUbDmdE7mWlYKsyJ7rVQq44KmsnxJXQVVC3xYaERl


    huvisfIIgIn+eGmdMmyQ07Vr0mN6f5bX1n7FiKI63/l0/7mD7EKgWmuiw1ISRuQ3


    FhUkpxNAowJ9uC3Rf03sborivigriR+WzjKyBlQWbqI9rHSoEZm/6JTmyTXmGX7y


    LjPejC1uaAK2VLyzGGCZPtABGZEpKP2XYnd0m6NWonhGhG2cFaA0zHQLE0BMMWRv


    sVoiqL/X3GqB5Zf8fYBx+Ulhk+gBff+gpRvkv4GT7J3bB/ploGPdtiJL9hhPQBM=


    =E3Ow


    -----END PGP SIGNATURE-----


    

  


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 		 	   		  

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151214/13a1355b/attachment.htm>

From uhlar at fantomas.sk  Mon Dec 14 14:20:05 2015
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 14 Dec 2015 15:20:05 +0100
Subject: [squid-users] Peek and splice without replacing the certificates
In-Reply-To: <343421450082596@web5h.yandex.ru>
References: <343421450082596@web5h.yandex.ru>
Message-ID: <20151214142005.GA3091@fantomas.sk>

On 14.12.15 13:43, ?????????? ?.?. wrote:
>Hello! Show you how to use Squid in transparent mode for tracking HTTPS without replacing the certificates?

Not possible. Either you replace the certificates, or you CAN NOT track trhe
session.

the "s" part in https means that proxy can not see the encrypted connect,
thus it can not track it (=see what's inside).
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
BSE = Mad Cow Desease ... BSA = Mad Software Producents Desease


From giray_simsek at hotmail.com  Mon Dec 14 15:33:38 2015
From: giray_simsek at hotmail.com (Giray Simsek)
Date: Mon, 14 Dec 2015 07:33:38 -0800
Subject: [squid-users] Transfer-Encoding tag not delivered to c-icap server
Message-ID: <BLU184-W23009AB86AF5852A8AA753FEED0@phx.gbl>

Hi,

I?am?using?squid?+?c-icap?for?content?adaptation.
On a client machine, I am trying to download a pdf file from docs.google.com. Looks like the google servers are sending the response as chunked as the http headers look like below:

Access-Control-Allow-Credentials:false
Access-Control-Allow-Headers:Accept, Accept-Language, Authorization, Cache-Control, Content-Disposition, Content-Encoding, Content-Language, Content-Length, Content-MD5, Content-Range, Content-Type, Date, GData-Version, Host, If-Match, If-Modified-Since, If-None-Match, If-Unmodified-Since, Origin, OriginToken, Pragma, Range, Slug, Transfer-Encoding, Want-Digest, X-ClientDetails, X-GData-Client, X-GData-Key, X-Goog-AuthUser, X-Goog-PageId, X-Goog-Encode-Response-If-Executable, X-Goog-Correlation-Id, X-Goog-Request-Info, X-Goog-Experiments, x-goog-iam-authority-selector, x-goog-iam-authorization-token, X-Goog-Spatula, X-Goog-Upload-Command, X-Goog-Upload-Content-Disposition, X-Goog-Upload-Content-Length, X-Goog-Upload-Content-Type, X-Goog-Upload-File-Name, X-Goog-Upload-Offset, X-Goog-Upload-Protocol, X-Goog-Visitor-Id, X-HTTP-Method-Override, X-JavaScript-User-Agent, X-Pan-Versionid, X-Origin, X-Referer, X-Upload-Content-Length, X-Upload-Content-Type, X-Use-HTTP-Status-Code-Override, X-YouTube-VVT, X-YouTube-Page-CL, X-YouTube-Page-Timestamp
Access-Control-Allow-Methods:GET,OPTIONS
Access-Control-Allow-Origin:*
Alt-Svc:clear
Cache-Control:private, max-age=0
Connection:keep-alive
Content-Disposition:attachment;filename="obama ve abd d__ poltikas_ her k_tada.pdf";filename*=UTF-8''obama%20ve%20abd%20d%C4%B1%C5%9F%20poltikas%C4%B1%20her%20k%C4%B1tada.pdf
Content-Type:application/pdf
Date:Mon, 14 Dec 2015 14:54:38 GMT
Expires:Mon, 14 Dec 2015 14:54:38 GMT
Server:UploadServer
Transfer-Encoding:chunked
Via:ICAP/1.0 localhost.localdomain (C-ICAP/0.3.5 Antivirus service )
X-Cache:MISS from yssyk-1
X-Cache-Lookup:MISS from yssyk-1:3127
X-Goog-Hash:crc32c=fd1pYw==
X-GUploader-UploadID:AEnB2Ur_sVGeDq9pSrx5PWhUk5OcucS4Eh3hsy6sddLOCAZwjniCCgCCbtFGptms0svl89fX24bj4hktdI9tN-QY95hvJ5n74Q


The problem is when the response comes through squid+icap, the file can not be downloaded. The file appears on the file system with file size = 0.

I listened to the packets that are delivered to icap server from squid and verified that "Transfer-Encoding" header is not delivered to icap server.

So I can't find out at what point the file download is being blocked. File is downloaded successfully when the icap server is stopped. But I guess the problem might be
about squid's way of passing the file content (or headers) to icap server. Is there anything I can do on the icap server side to make the download succeed?


Thanks in advance,
Giray 		 	   		  

From marcus.kool at urlfilterdb.com  Mon Dec 14 16:52:10 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 14 Dec 2015 14:52:10 -0200
Subject: [squid-users] Peek and splice without replacing the certificates
In-Reply-To: <343421450082596@web5h.yandex.ru>
References: <343421450082596@web5h.yandex.ru>
Message-ID: <566EF3BA.4030900@urlfilterdb.com>



On 12/14/2015 06:43 AM, ?????????? ?.?. wrote:
> Hello! Show you how to use Squid in transparent mode for tracking HTTPS without replacing the certificates?
> My squid.conf: http://pastebin.ru/AWU8LXvK. If such a configuration file
> to use version 3.5.8 squid compiled using Libressl, everything works
> fine. But if you use version 3.5.9 and above, Squid begins to "terminated" in
> the number of clients above 20. Moreover, interrupted for no apparent reason and messages in the logs. Also tested versions> = 4.0, the effect is the same - Squid "terminated". How to overcome the problem? Correct any
> configuration I have? Thank you in advance. PS .: Sorry for my english

Depending on how you define "tracking" ...

Your squid config has:

acl blocked ssl::server_name  "/etc/squid/blocked_https.txt"
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump terminate blocked
ssl_bump splice all

So it seems that you want to peek and block a few sites based on the SNI and splice all other allowed sites.
When you splice, the TLS/SSL connection is untouched so the original certificates of the webservers are used.
I am not 100% sure, but it seems that to configure sslbump, one must define a fake CA certificate to tell Squid to do sslbumping.
But since you never bump (only terminate or splice) the fake CA certificate is never used.

To debug the sslbump feature you need to set
debug_options ALL,1 33,9 83,9
and carefully look at cache.log to see what is going wrong.

Marcus


From rousskov at measurement-factory.com  Mon Dec 14 17:02:24 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 14 Dec 2015 10:02:24 -0700
Subject: [squid-users] Transfer-Encoding tag not delivered to c-icap
 server
In-Reply-To: <BLU184-W23009AB86AF5852A8AA753FEED0@phx.gbl>
References: <BLU184-W23009AB86AF5852A8AA753FEED0@phx.gbl>
Message-ID: <566EF620.6060502@measurement-factory.com>

On 12/14/2015 08:33 AM, Giray Simsek wrote:

> I am using squid + c-icap for content adaptation.
> On a client machine, I am trying to download a pdf file from docs.google.com. Looks like the google servers are sending the response as chunked as the http headers look like below:

> Transfer-Encoding:chunked


> I listened to the packets that are delivered to icap server from
> squid and verified that "Transfer-Encoding" header is not delivered
> to icap server.


This is normal. Squid decodes chunked transfer encoding before sending
the message to the ICAP (or eCAP) service, as it should.


> So I can't find out at what point the file download is being blocked.
> File is downloaded successfully when the icap server is stopped. But
> I guess the problem might be about squid's way of passing the file
> content (or headers) to icap server. Is there anything I can do on
> the icap server side to make the download succeed?

You may want start by finding the ICAP request and response headers and
posting them here. IIRC, Squid reports them with debug_options ALL,2


HTH,

Alex.






From squid3 at treenet.co.nz  Mon Dec 14 19:05:49 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Dec 2015 08:05:49 +1300
Subject: [squid-users] URL Cacheing Question
In-Reply-To: <00cb01d13657$2fa9b200$8efd1600$@fela.ch>
References: <00cb01d13657$2fa9b200$8efd1600$@fela.ch>
Message-ID: <566F130D.2030808@treenet.co.nz>

On 14/12/2015 11:07 p.m., Igor Dzombic wrote:
> Hallo Squid Team,
> 
> i have one Question, i?m trying to Configure Squid-Proxy-Server and i need
> your help. It should work like this:
> 
> -          i should cache one URL (like
> http://backend.my-server.net/servlets/fgi/onepage.php) and refrashe it
> every 5 min. on a Squid-Proxy Server
> 
> -          My Clients should access ONLY this page and in a case that this
> page ist not reachable (no Internet-Connection), clients should load the
> Page from Proxy Cache

Firstly, cache != backup.

HTTP cache works by taking client requests and storing the responses
that have to be fetcehd rom a remote server. If the clients are not
using the proxy constantly when the server is working then the proxy and
its cache will not know what response object that URL is supposed to be
supplying when that server goes down. By then it will be too late.

=> This means you have to make the proxy be the place the clients go. Or
at least a large portion of them. Squid is the CDN frontend for the
origin server.


The other thing about caches is that they have a very strong purpose on
delivering *accurate* content. That means that sometimes when the server
is down they will generate error page instead of delivering outdated
content, even if it is cached.

It is up to the origin server to explicitly specify how long cached
content is to be stored without even checking back to the origin
(Cache-Control s-maxage=N, max-age=N or Expires: header) and how long
after that expiry time happens it is allowed to be served even if the
origin it comes from has broken (Cache-Control:stale-if-error=N).

=> This means you have to make the origin deliver the required cache
control headers to make the cache store things for your 5min period, and
with N seconds failure hiding.


Amos



From squid3 at treenet.co.nz  Mon Dec 14 19:14:39 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Dec 2015 08:14:39 +1300
Subject: [squid-users] Peek and splice without replacing the certificates
In-Reply-To: <566EF3BA.4030900@urlfilterdb.com>
References: <343421450082596@web5h.yandex.ru>
 <566EF3BA.4030900@urlfilterdb.com>
Message-ID: <566F151F.908@treenet.co.nz>

On 15/12/2015 5:52 a.m., Marcus Kool wrote:
> 
> 
> On 12/14/2015 06:43 AM, ?????????? ?.?. wrote:
>> Hello! Show you how to use Squid in transparent mode for tracking
>> HTTPS without replacing the certificates?
>> My squid.conf: http://pastebin.ru/AWU8LXvK. If such a configuration file
>> to use version 3.5.8 squid compiled using Libressl, everything works
>> fine. But if you use version 3.5.9 and above, Squid begins to
>> "terminated" in
>> the number of clients above 20. Moreover, interrupted for no apparent
>> reason and messages in the logs. Also tested versions> = 4.0, the
>> effect is the same - Squid "terminated". How to overcome the problem?
>> Correct any
>> configuration I have? Thank you in advance. PS .: Sorry for my english
> 
> Depending on how you define "tracking" ...
> 
> Your squid config has:
> 
> acl blocked ssl::server_name  "/etc/squid/blocked_https.txt"
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump terminate blocked
> ssl_bump splice all
> 
> So it seems that you want to peek and block a few sites based on the SNI
> and splice all other allowed sites.
> When you splice, the TLS/SSL connection is untouched so the original
> certificates of the webservers are used.
> I am not 100% sure, but it seems that to configure sslbump, one must
> define a fake CA certificate to tell Squid to do sslbumping.
> But since you never bump (only terminate or splice) the fake CA
> certificate is never used.

Sort of. The terminate action does need to do a full bump with what used
to be called client-first style of bumping. Otherwise for splice-only
they are unused, but still need to be properly configured just to enable
ssl_bump processing in current Squid.

> 
> To debug the sslbump feature you need to set
> debug_options ALL,1 33,9 83,9
> and carefully look at cache.log to see what is going wrong.
> 
> Marcus

Amos




From yvoinov at gmail.com  Mon Dec 14 21:26:42 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 15 Dec 2015 03:26:42 +0600
Subject: [squid-users] Using subordinate CA for SSL Bump
Message-ID: <566F3412.6060504@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hi all.

Does anybody can tell me - is it possible to use subordinate secondary
CA in squid for SSL Bumping purpose?

I.e., we have self-signed primary CA for issue subordinate CA,

subordinate CA we install in squid's setup,

primary CA certificate install to clients.

For example.

For mimicking we'll using subordinate CA, and, in case of subordinate
key forgery, we can use primary CA to revoke subordinate CA and re-issue
them without total replacement primary CA on clients.

This will seriously increase bumping security procedure, hm?

I've tried this scheme with 3.5.11, but without success.

WBR, Yuri

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWbzQSAAoJENNXIZxhPexGR60IAJ/Q50kpDd9JDnaWP+CSk2k5
4l/cqbWjk+z3jJLHunvPfeURuq7l/7+cOBOvc5WTx0f05IOsg2M/+wv2IXocpjc7
FvtB5i6ZlBIGOVBPRbwoh/ipd8aR7W+zv+RvqzjDiO7NZ4PAWzN5ADW6+lIb4WfA
Mjxk/zhpngrlMoVu1zc82OUhu5b3/FUKqSMeuodP9lMFzQWN/y15HUtxBErj0TD6
mLvAv627rlOGRd96ZpKNB4Cpgl1Nqx7nx+U74eE2bNdV+1zABSUMeHHNVFizKH5A
g5c7Tds9nHumH+8HafWEmOFEsTLq+HLWlFp0vA/pq6Wo8GlCYo1UiDLNWn1OWi8=
=l917
-----END PGP SIGNATURE-----



From michael.pelletier at palmbeachschools.org  Mon Dec 14 21:59:15 2015
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Mon, 14 Dec 2015 16:59:15 -0500
Subject: [squid-users] Problems filtering specific plus.google.com
	(application/x-www-form-urlencoded)
Message-ID: <CAEnCSG7YcYs-PpyRmFRP9aB6nNFE45YcMnk1fg5+H6u143DUpA@mail.gmail.com>

Hello,
Today we found a site that needed to be blocked while allowing the rest at
plus.google.com. I went to block the URL but it did not block. I looked
deeper into the problem and it seems application/x-www-form-urlencoded
never sends the url so I can't block it.

Can someone help?

Michael

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151214/a6534e04/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 14 22:29:53 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Dec 2015 11:29:53 +1300
Subject: [squid-users] Problems filtering specific plus.google.com
 (application/x-www-form-urlencoded)
In-Reply-To: <CAEnCSG7YcYs-PpyRmFRP9aB6nNFE45YcMnk1fg5+H6u143DUpA@mail.gmail.com>
References: <CAEnCSG7YcYs-PpyRmFRP9aB6nNFE45YcMnk1fg5+H6u143DUpA@mail.gmail.com>
Message-ID: <566F42E1.7050604@treenet.co.nz>

On 15/12/2015 10:59 a.m., Michael Pelletier wrote:
> Hello,
> Today we found a site that needed to be blocked while allowing the rest at
> plus.google.com. I went to block the URL but it did not block. I looked
> deeper into the problem and it seems application/x-www-form-urlencoded
> never sends the url so I can't block it.

What do you mean? and what exactly are you seeing in the traffic?

"application/x-www-form-urlencoded" is a mime type (payload or content
data). Not a message or action.

Amos



From squid3 at treenet.co.nz  Mon Dec 14 23:16:22 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Dec 2015 12:16:22 +1300
Subject: [squid-users] Using subordinate CA for SSL Bump
In-Reply-To: <566F3412.6060504@gmail.com>
References: <566F3412.6060504@gmail.com>
Message-ID: <566F4DC6.6080408@treenet.co.nz>

On 15/12/2015 10:26 a.m., Yuri Voinov wrote:
> 
> Hi all.
> 
> Does anybody can tell me - is it possible to use subordinate secondary
> CA in squid for SSL Bumping purpose?
> 
> I.e., we have self-signed primary CA for issue subordinate CA,
> 
> subordinate CA we install in squid's setup,
> 
> primary CA certificate install to clients.
> 
> For example.
> 
> For mimicking we'll using subordinate CA, and, in case of subordinate
> key forgery, we can use primary CA to revoke subordinate CA and re-issue
> them without total replacement primary CA on clients.
> 
> This will seriously increase bumping security procedure, hm?
> 
> I've tried this scheme with 3.5.11, but without success.

I suspect its not going to work in the current releases. The more I look
at this part of the SSL code the more twisted it appears to be.

There are multiple code paths loading certs in different orders for
different features and traffic types. I have been trying to clean up
those code paths recently, but it is all still a bit tangled to even see
which one is handling what type of traffic.

AFAICT (so far) both the bumping and reverse-proxy code loads
Intermediary certs if they are listed in the cert= PEM file after the
cert Squid is using for either signing-cert or as server-cert. Some
other code path is loading them from cafile=, it looks like its the main
SSL code but I've not yet found how that code path actually happens (grr).

With all that looking hopeful, and the certs identified as the secondary
chain being attached (everything except the firstprimary/signing cert).
I'm not actually finding anywhere sending the actual signing certificate
itself during the bumping steps. So Squid may be horribly sending
all-but-one of the certs needed, on the assumption that the signing cert
is itself installed on the client.

Amos


From marcus.kool at urlfilterdb.com  Mon Dec 14 23:48:04 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 14 Dec 2015 21:48:04 -0200
Subject: [squid-users] Using subordinate CA for SSL Bump
In-Reply-To: <566F4DC6.6080408@treenet.co.nz>
References: <566F3412.6060504@gmail.com> <566F4DC6.6080408@treenet.co.nz>
Message-ID: <566F5534.6090801@urlfilterdb.com>



On 12/14/2015 09:16 PM, Amos Jeffries wrote:

> With all that looking hopeful, and the certs identified as the secondary
> chain being attached (everything except the firstprimary/signing cert).
> I'm not actually finding anywhere sending the actual signing certificate
> itself during the bumping steps. So Squid may be horribly sending
> all-but-one of the certs needed, on the assumption that the signing cert
> is itself installed on the client.

The RFC says that it is not necessary to send the signing CA certificate.

Marcus

> Amos


From eliezer at ngtech.co.il  Tue Dec 15 01:09:33 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 15 Dec 2015 03:09:33 +0200
Subject: [squid-users] issue with video
In-Reply-To: <DUB130-W6B91C01FA9412AB19D44CBDED0@phx.gbl>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>
 <5668B48C.703@treenet.co.nz> <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>
 <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl> <5669997A.70209@gmail.com>
 <DUB130-W4883D1369E0FC96B14F00ABDEA0@phx.gbl>
 <DUB130-W6B91C01FA9412AB19D44CBDED0@phx.gbl>
Message-ID: <566F684D.4060602@ngtech.co.il>

I am not sure it's any squid issue since it is unclear what you are 
referring to as "not working".
The logs can show couple things but cannot record what is the issue in 
the client level.
I have tried to read them but have not seen the video request.
It could be a client issue rather then squid..

What browser are you using? What version? Do you have the latest flash 
player instlaled?

Do you know if the requested video file\stream is an http one?
If so what is the url which doesn't work?
In any case you can use firefox\chrome\explorer\safri\opera developers 
tools to identify the url which doesn't work.
For firefox take a look at:
https://www.youtube.com/watch?v=w4zSG53Qlbk
https://developer.mozilla.org/en-US/docs/Tools/Network_Monitor

For Chrome take a look at:
https://www.youtube.com/watch?v=PwoT18tp6Hs

For Internet Explorer at:
https://youtu.be/GbbjL_Uir24?t=713

Since the url you presented at your first post doesn't work I have tried 
the official video one at:
http://www.cbsnews.com/videos/

The videos works for me using squid 3.5.12 so it doesn't seem to be any 
squid related issue in my eyes.

The video urls are at the domain\origin\server:
http://cbsnews-vh.akamaihd.net/

You can post images of screenshot using either google drive or one of these:
http://snag.gy/
http://pasteboard.co/

Eliezer

On 14/12/2015 16:01, Magic Link wrote:
> Any ideas ?
> Thanks !
>
> From: magiclink at outlook.com
> To: yvoinov at gmail.com; squid-users at lists.squid-cache.org
> Date: Fri, 11 Dec 2015 11:40:01 +0100
> Subject: Re: [squid-users] issue with video
>
>
>
>
> https://drive.google.com/file/d/0B5u1WrFLUfPiNWhXLVRJZnJETzA/view?usp=sharing
> I test with squid 3.5.10 (from debian testing repository) et no luck :( it doesn't work too
>
> To: squid-users at lists.squid-cache.org
> From: yvoinov at gmail.com
> Date: Thu, 10 Dec 2015 21:25:46 +0600
> Subject: Re: [squid-users] issue with video
>
>
>
>
>
>
>
>
>      -----BEGIN PGP SIGNED MESSAGE-----
>
>      Hash: SHA256
>
>
>
>      tar -cvf logs.tar access.log cache.log; gzip -9 logs.tar ->
>      http://drive.google.com -> sahre+post URL's
>
>
>
>      10.12.15 19:56, Magic Link ?????:
>
>      > Where can i upload my logs ?
>        It's too big for the mail.
>
>        >
>
>        > From: magiclink at outlook.com
>
>        > To: squid3 at treenet.co.nz; squid-users at lists.squid-cache.org
>
>        > Subject: RE: [squid-users] issue with video
>
>        > Date: Thu, 10 Dec 2015 11:29:42 +0100
>
>        >
>
>        >
>
>        >
>
>        >
>
>        > I activated the debug_option. I don't see anything particular
>        in access.log, but i don't know what to do with the content of
>        cache.logI 'v never compiled squid, is there a tutorial ? I used
>        to use the debian stable repository, but get only the 3.4.8
>        version for debian 8 (i can try with testing repository or another
>        one if so)
>
>        >
>
>        > Thanks
>
>        >> To: squid-users at lists.squid-cache.org
>
>        >> From: squid3 at treenet.co.nz
>
>        >> Date: Thu, 10 Dec 2015 12:09:00 +1300
>
>        >> Subject: Re: [squid-users] issue with video
>
>        >>
>
>        >> On 10/12/2015 3:42 a.m., Magic Link wrote:
>
>        >>> Hi,
>
>        >>> i have a problem with this video
>        http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/
>        This video doesn't start with squid (3.4.8) on Debian 8 but does
>        with a direct access to Internet.I don't know how to debug this
>        issue.
>
>        >>> Any clues ? Thanks
>
>        >>>
>
>        >>
>
>        >> Check cache.log to see if any errors are being logged
>        when you request it.
>
>        >>
>
>        >> Check access.log to see if the proxy is actually being
>        contacted to
>
>        >> fetch the video.
>
>        >>
>
>        >> "debug_options 11,2" to see what the request and reply
>        headers are.
>
>        >>
>
>        >> If you can, try an upgrade. Current Squid is 3.5.12. I'm
>        just mentioning
>
>        >> this because its the nromal debugging step. I dont
>        recommend a
>
>        >> cross-install of the 3.5.12 package to Debian 8 - it
>        needs a proper
>
>        >> backport / recompile.
>
>        >>
>
>        >> The remaining steps get trickier and depend on the
>        results of the above
>
>        >> checks, or whether
>
>        >>
>
>        >>
>
>        >> Amos
>
>        >>
>
>        >> _______________________________________________
>
>        >> squid-users mailing list
>
>        >> squid-users at lists.squid-cache.org
>
>        >> http://lists.squid-cache.org/listinfo/squid-users
>
>        >
>
>        >
>
>        >
>
>        > _______________________________________________
>
>        > squid-users mailing list
>
>        > squid-users at lists.squid-cache.org
>
>        > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>      -----BEGIN PGP SIGNATURE-----
>
>
>      Version: GnuPG v2
>
>
>
>
>      iQEcBAEBCAAGBQJWaZl6AAoJENNXIZxhPexGGe4IAILsG3rcB+8WN0bn5++RHUie
>
>
>      ts4SNFYvOgmDt48xfy1uOzpjUbDmdE7mWlYKsyJ7rVQq44KmsnxJXQVVC3xYaERl
>
>
>      huvisfIIgIn+eGmdMmyQ07Vr0mN6f5bX1n7FiKI63/l0/7mD7EKgWmuiw1ISRuQ3
>
>
>      FhUkpxNAowJ9uC3Rf03sborivigriR+WzjKyBlQWbqI9rHSoEZm/6JTmyTXmGX7y
>
>
>      LjPejC1uaAK2VLyzGGCZPtABGZEpKP2XYnd0m6NWonhGhG2cFaA0zHQLE0BMMWRv
>
>
>      sVoiqL/X3GqB5Zf8fYBx+Ulhk+gBff+gpRvkv4GT7J3bB/ploGPdtiJL9hhPQBM=
>
>
>      =E3Ow
>
>
>      -----END PGP SIGNATURE-----
>
>
>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users 		 	   		
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users 		 	   		
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From squid3 at treenet.co.nz  Tue Dec 15 02:50:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Dec 2015 15:50:54 +1300
Subject: [squid-users] issue with video
In-Reply-To: <566F684D.4060602@ngtech.co.il>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>
 <5668B48C.703@treenet.co.nz> <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>
 <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl> <5669997A.70209@gmail.com>
 <DUB130-W4883D1369E0FC96B14F00ABDEA0@phx.gbl>
 <DUB130-W6B91C01FA9412AB19D44CBDED0@phx.gbl> <566F684D.4060602@ngtech.co.il>
Message-ID: <566F800E.106@treenet.co.nz>

On 15/12/2015 2:09 p.m., Eliezer Croitoru wrote:
> I am not sure it's any squid issue since it is unclear what you are
> referring to as "not working".
> The logs can show couple things but cannot record what is the issue in
> the client level.
> I have tried to read them but have not seen the video request.
> It could be a client issue rather then squid..
> 

The closest thing to a video stream in those logs seems to be:

cache.log:

2015/12/10 09:56:12.400 kid1| client_side.cc(2407) parseHttpRequest:
HTTP Client local=10.2.10.251:3128 remote=10.2.100.32:53031 FD 21 flags=1
2015/12/10 09:56:12.401 kid1| client_side.cc(2408) parseHttpRequest:
HTTP Client REQUEST:
---------
CONNECT www.youtube.com:443 HTTP/1.0
User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0)
like Gecko
Host: www.youtube.com:443
Content-Length: 0
Proxy-Connection: Keep-Alive
Pragma: no-cache
---------

access.log:

1449737803.472  31071 10.2.100.32 TCP_MISS/200 4435 CONNECT
www.youtube.com:443 - HIER_DIRECT/216.58.211.78 -


If we assume that the HTTPS request was a video fetch from YouTube, then
it was a succesful tunnel as far as Squid is concerned. It had 4.4KB
sent in 31 seconds. Which does seem a bit odd for a video, but could be
if its broken internally.

The rest of what Eliezer pointed out is relevant to further debugging
non your part...

> What browser are you using? What version? Do you have the latest flash
> player instlaled?
> 
> Do you know if the requested video file\stream is an http one?
> If so what is the url which doesn't work?
> In any case you can use firefox\chrome\explorer\safri\opera developers
> tools to identify the url which doesn't work.
> For firefox take a look at:
> https://www.youtube.com/watch?v=w4zSG53Qlbk
> https://developer.mozilla.org/en-US/docs/Tools/Network_Monitor
> 
> For Chrome take a look at:
> https://www.youtube.com/watch?v=PwoT18tp6Hs
> 
> For Internet Explorer at:
> https://youtu.be/GbbjL_Uir24?t=713
> 
> Since the url you presented at your first post doesn't work I have tried
> the official video one at:
> http://www.cbsnews.com/videos/
> 
> The videos works for me using squid 3.5.12 so it doesn't seem to be any
> squid related issue in my eyes.
> 
> The video urls are at the domain\origin\server:
> http://cbsnews-vh.akamaihd.net/
> 
> You can post images of screenshot using either google drive or one of
> these:
> http://snag.gy/
> http://pasteboard.co/
> 
> Eliezer
> 

Amos


From michael.pelletier at palmbeachschools.org  Tue Dec 15 04:54:55 2015
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Mon, 14 Dec 2015 23:54:55 -0500
Subject: [squid-users] Problems filtering specific plus.google.com
	(application/x-www-form-urlencoded)
In-Reply-To: <566F42E1.7050604@treenet.co.nz>
References: <CAEnCSG7YcYs-PpyRmFRP9aB6nNFE45YcMnk1fg5+H6u143DUpA@mail.gmail.com>
 <566F42E1.7050604@treenet.co.nz>
Message-ID: <CAEnCSG7DFU8M2W5Ow4f5hUuJb4RW3+HJrzWkgsat8LPF_VZp-w@mail.gmail.com>

When trying to filter a sepcific site in plus.google.com (for example
https://plus.google.com/111111222233334/), I see the request header going
out to plus.google.com without any reference to the url. So it does not
match the black list rule I have.



On Mon, Dec 14, 2015 at 5:29 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 15/12/2015 10:59 a.m., Michael Pelletier wrote:
> > Hello,
> > Today we found a site that needed to be blocked while allowing the rest
> at
> > plus.google.com. I went to block the URL but it did not block. I looked
> > deeper into the problem and it seems application/x-www-form-urlencoded
> > never sends the url so I can't block it.
>
> What do you mean? and what exactly are you seeing in the traffic?
>
> "application/x-www-form-urlencoded" is a mime type (payload or content
> data). Not a message or action.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151214/2b821251/attachment.htm>

From wayne.gillan at jurox.com.au  Tue Dec 15 05:20:06 2015
From: wayne.gillan at jurox.com.au (Wayne Gillan)
Date: Tue, 15 Dec 2015 05:20:06 +0000
Subject: [squid-users] SSTP_DUPLEX_POST method
Message-ID: <241CD68BD7EF6D4D8CE0A53F4166F57E3A784842@exchange.jurox>

Hi all,

I am trying to configure squid as a reverse proxy in front of a Microsoft SSTP VPN server but squid does not appear to be forwarding the requests. I think it may have something to do with this custom verb/method that Microsoft use. See https://msdn.microsoft.com/en-us/library/cc247364.aspx. Should it work ok? I am running 3.1.19.

Thank you,
Wayne

______________________________________________________________________
This email is confidential.  If you are not the intended recipient, you must not disclose  or  use the  information  contained in it.
If you have received this email in error,  please notify us immediately by return email and delete the email and any attachments.
Any personal views/ opinions expressed by the writer may not necessarily reflect the views/ opinions of the company.
______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________


From eliezer at ngtech.co.il  Tue Dec 15 07:22:34 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 15 Dec 2015 09:22:34 +0200
Subject: [squid-users] SSTP_DUPLEX_POST method
In-Reply-To: <241CD68BD7EF6D4D8CE0A53F4166F57E3A784842@exchange.jurox>
References: <241CD68BD7EF6D4D8CE0A53F4166F57E3A784842@exchange.jurox>
Message-ID: <566FBFBA.3080500@ngtech.co.il>

Isn't SSTP is some kind of secure VPN service? which is based on SSL?
Why would you want to put a reverse proxy in front of a VPN service? 
There are many things to do in the IP level but not much to do in the 
HTTP level.

Eliezer

On 15/12/2015 07:20, Wayne Gillan wrote:
> Hi all,
>
> I am trying to configure squid as a reverse proxy in front of a Microsoft SSTP VPN server but squid does not appear to be forwarding the requests. I think it may have something to do with this custom verb/method that Microsoft use. Seehttps://msdn.microsoft.com/en-us/library/cc247364.aspx. Should it work ok? I am running 3.1.19.
>
> Thank you,
> Wayne



From flavius_nopcea at netex.ro  Tue Dec 15 09:58:55 2015
From: flavius_nopcea at netex.ro (Flavius Nopcea)
Date: Tue, 15 Dec 2015 11:58:55 +0200
Subject: [squid-users] squid url_rewrite_program for urls with parametes
Message-ID: <566FE45F.9010007@netex.ro>

Hi,

i try to rewrite a URL based on its parametes..... for example the url: 
www.google.com?param1=value1&param2=value2

the problem is that I do not get the parameters as input in the url 
rewrite program.

do you know a way how I can do this?

thanks a lot


From robertocarna36 at gmail.com  Tue Dec 15 11:39:14 2015
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Tue, 15 Dec 2015 08:39:14 -0300
Subject: [squid-users] Reverse proxy: session expired in 15 minutes
Message-ID: <CAG2Qp6sR-hCNTGHc+QADV1ZmT+mQYim_KwxA33cAFi9ZuB2sjQ@mail.gmail.com>

Dear, we have a Squid3 as reverse proxy with default configuration.

We have a domain pointed to a web server. In this server the user
session expiration is setup in 3 hs, but each 15 minutes the session
expires.

At this time, we are not sure about the origin of the session
expiration. Taking into account the Squid 3 server, which parameter
can I adjust in order to increment the session timeout ???

Thanks a lot,

Roberto


From andre61 at brazcubas.br  Tue Dec 15 11:42:24 2015
From: andre61 at brazcubas.br (=?UTF-8?Q?Andr=c3=a9_Janna?=)
Date: Tue, 15 Dec 2015 09:42:24 -0200
Subject: [squid-users] file descriptors leak
In-Reply-To: <20151128224640.Horde.pKUQ_9MBwdZSp6PUe3fx3I7@webmail.brazcubas.br>
References: <20151122011022.Horde.yNO89VXlhLk9DdWU9nfO8LK@webmail.brazcubas.br>
 <56515624.109@treenet.co.nz>
 <20151122120121.Horde.9rSzFRvRMzh2xQ-uxHeNaff@webmail.brazcubas.br>
 <20151122151837.Horde.MzEU4g781Kl2iN4L_ns5wTe@webmail.brazcubas.br>
 <565208A2.5020709@ngtech.co.il> <56535EE1.6040809@brazcubas.br>
 <5653D182.70009@treenet.co.nz> <56575116.1020302@brazcubas.br>
 <565788A1.4010501@treenet.co.nz>
 <20151128224640.Horde.pKUQ_9MBwdZSp6PUe3fx3I7@webmail.brazcubas.br>
Message-ID: <566FFCA0.8010901@brazcubas.br>

Em 28/11/2015 22:46, Andr? Janna escreveu:
> I took another network trace this time both at Squid and Windows 
> client ends.
>
> cache.log:
> 2015/11/27 11:30:55.610 kid1| SECURITY ALERT: Host header forgery 
> detected on local=177.43.198.106:443 remote=192.168.64.4:61802 FD 5465 
> flags=33 (local IP does not match any domain IP)
>
> ------------------------------
> network trace at Squid side
>
> client connects
> 11:30:55.604870 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [S], 
> seq 1701554341, win 8192, options [mss 1460,nop,wscale 
> 8,nop,nop,sackOK], length 0
> 11:30:55.604992 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags 
> [S.], seq 3125704417, ack 1701554342, win 29200, options [mss 
> 1460,nop,nop,sackOK,nop,wscale 7], length 0
> 11:30:55.605766 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> ack 1, win 256, length 0
>
> client sends SSL hello
> 11:30:55.606242 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags 
> [P.], seq 1:198, ack 1, win 256, length 197
> 11:30:55.606306 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 198, win 237, length 0
>
> client OS sends TCP keep-alive packets
> 11:31:05.607191 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 197:198, ack 1, win 256, length 1
> 11:31:05.607231 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 198, win 237, options [nop,nop,sack 1 {197:198}], length 0
> 11:31:15.608966 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 197:198, ack 1, win 256, length 1
> 11:31:15.609005 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 198, win 237, options [nop,nop,sack 1 {197:198}], length 0
> 11:31:25.614527 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 197:198, ack 1, win 256, length 1
> 11:31:25.614589 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 198, win 237, options [nop,nop,sack 1 {197:198}], length 0
>
> client sends FIN
> 11:31:29.384280 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags 
> [F.], seq 198, ack 1, win 256, length 0
> 11:31:29.421787 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 199, win 237, length 0
>
> client OS sends TCP keep-alive packets
> 11:31:39.417426 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 198:199, ack 1, win 256, length 1
> 11:31:39.417489 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 199, win 237, options [nop,nop,sack 1 {198:199}], length 0
> 11:31:49.425366 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 198:199, ack 1, win 256, length 1
> 11:31:49.425443 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 199, win 237, options [nop,nop,sack 1 {198:199}], length 0
> 11:31:59.426153 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 198:199, ack 1, win 256, length 1
> 11:31:59.426233 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 199, win 237, options [nop,nop,sack 1 {198:199}], length 0
> .... it continues this way until I powered off Windows client after 
> three hours ...
>
>
> ------------------------------
> network trace at Windows client side
>
> client connects
> 11:30:34.894242 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [S], 
> seq 1701554341, win 8192, options [mss 1460,nop,wscale 
> 8,nop,nop,sackOK], length 0
> 11:30:34.898234 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags 
> [S.], seq 3125704417, ack 1701554342, win 29200, options [mss 
> 1460,nop,nop,sackOK,nop,wscale 7], length 0
> 11:30:34.898298 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> ack 1, win 256, length 0
>
> client sends SSL hello
> 11:30:34.898712 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags 
> [P.], seq 1:198, ack 1, win 256, length 197
> 11:30:34.899479 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 198, win 237, length 0
>
> client OS sends TCP keep-alive packets
> 11:30:44.899271 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 197:198, ack 1, win 256, length 1
> 11:30:44.899986 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 198, win 237, options [nop,nop,sack 1 {197:198}], length 0
> 11:30:54.900495 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 197:198, ack 1, win 256, length 1
> 11:30:54.901323 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 198, win 237, options [nop,nop,sack 1 {197:198}], length 0
> 11:31:04.905731 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 197:198, ack 1, win 256, length 1
> 11:31:04.906560 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 198, win 237, options [nop,nop,sack 1 {197:198}], length 0
>
> client sends FIN
> 11:31:08.675299 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags 
> [F.], seq 198, ack 1, win 256, length 0
> 11:31:08.713746 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 199, win 237, length 0
>
> client OS sends TCP keep-alive packets
> 11:31:18.708086 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 198:199, ack 1, win 256, length 1
> 11:31:18.708917 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 199, win 237, options [nop,nop,sack 1 {198:199}], length 0
> 11:31:28.715600 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 198:199, ack 1, win 256, length 1
> 11:31:28.716516 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 199, win 237, options [nop,nop,sack 1 {198:199}], length 0
> 11:31:38.714887 IP 192.168.64.4.61802 > 177.43.198.106.443: Flags [.], 
> seq 198:199, ack 1, win 256, length 1
> 11:31:38.716911 IP 177.43.198.106.443 > 192.168.64.4.61802: Flags [.], 
> ack 199, win 237, options [nop,nop,sack 1 {198:199}], length 0
> ...
>
>
> So after less then one minute after connection Windows client sent a 
> FIN and Linux server acknowledged.
> Windows netstat showed that connection changed to FIN_WAIT_2 state 
> while Linux netstat showed that connection at Squid endpoint changed 
> to CLOSE_WAIT state.
>   # date; netstat -tno | grep 192.168.64.4
>   Fri Nov 27 11:32:13 BRST 2015
>   tcp6       1      0 172.16.10.22:3126 192.168.64.4:61802      
> CLOSE_WAIT  off (0.00/0/0)
>
> According to 
> http://www.tcpipguide.com/free/t_TCPConnectionTermination-2.htm in 
> this state the server IP stack is waiting for Squid to be ready to 
> close the connection.
>
> After 3 hours from initial connection netstat state on client was 
> still FIN_WAIT_2 and on server was still CLOSE_WAIT.
> So I powered off Windows laptop and waited 3 hours more but nothing 
> changed, connection remained in CLOSE_WAIT state and Squid didn't 
> release the file descriptor.
>   Fri Nov 27 18:22:25 BRST 2015
>   squid      2708           proxy 5465u     IPv6 620209      
> 0t0        TCP 172.16.10.22:3126->192.168.64.4:61802 (CLOSE_WAIT)
>
>
> Regards,
> Andr?


I installed Squid 3.5.12 on another machine and got the same problem as 
before.
Squid keeps using file descriptors for connections that have been in 
CLOSE_WAIT state for hours.
My guess is that Squid doesn't release the file descriptor when 
intercepts an https connection that triggers "local IP does not match 
any domain IP" warning in cache.log.


Regards,
Andr?



From behrad_es at yahoo.com  Tue Dec 15 11:53:55 2015
From: behrad_es at yahoo.com (behrad eslami)
Date: Tue, 15 Dec 2015 11:53:55 +0000 (UTC)
Subject: [squid-users] squid 3.5.12 and ecap
References: <1482652592.1446755.1450180435187.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1482652592.1446755.1450180435187.JavaMail.yahoo@mail.yahoo.com>

Hi
I add simple rule to ecap module and deny some url. I forground (squid -N -d10) all things work well. when i run service wtih mutiple workers, after a while some url not filter and user can open them in browsers.
I compile Squid 3.5.12 and libecpa 1.0.0. squid compiled with below options:'--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=${prefix}/lib/squid3' '--srcdir=.' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--datadir=/usr/share/squid3' '--sysconfdir=/etc/squid3' '--mandir=/usr/share/man' '--enable-inline' '--disable-arch-native' '--enable-async-io=8' '--enable-storeio=aufs,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-follow-x-forwarded-for' '--enable-eui' '--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-auto-locale' '--disable-translation' '--with-swapdir=/var/spool/squid3' '--with-logdir=/var/log/squid3' '--with-pidfile=/var/run/squid3.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-build-info= linux' '--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security' '--disable-ipv6' '--disable-wccp' '--disable-auth-basic' '--disable-auth-digest' '--disable-auth-negotiate' '--disable-auth-ntlm' '--disable-external-acl-helpers' '--disable-url-rewrite-helpers' '--disable-storeid-rewrite-helpers' '--without-mit-krb5' '--without-heimdal-krb5' '--without-gnugss' '--disable-unlinkd' '--disable-ident-lookups' '--disable-esi' '--disable-select' '--disable-poll' '--disable-kqueue' '--disable-devpoll' '--enable-epoll'

and my ecap config is:icap_enable onicap_send_client_ip onicap_client_username_encode on
loadable_modules /usr/local/lib/ecap_adapter_MY_processing.soecap_enable onecap_service ecapModifier respmod_precache \? ? ? uri=ecap://www.deltaglobal.net/adapter_My_processing ?\? ? ? ?victim=sadeghsalehi\? ? ? ? replacement=***adaptation_access ecapModifier allow all
loadable_modules /usr/local/lib/ecap_adapter_My_request.so
ecap_enable onecap_service eReqmod reqmod_precache bypass=1 ?ecap://e-cap.org/ecap/services/My/requestadaptation_access ? eReqmod ?allow all
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/41edb1a5/attachment.htm>

From robertocarna36 at gmail.com  Tue Dec 15 12:02:45 2015
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Tue, 15 Dec 2015 09:02:45 -0300
Subject: [squid-users] Reverse proxy: session expired in 15 minutes
In-Reply-To: <CAG2Qp6sR-hCNTGHc+QADV1ZmT+mQYim_KwxA33cAFi9ZuB2sjQ@mail.gmail.com>
References: <CAG2Qp6sR-hCNTGHc+QADV1ZmT+mQYim_KwxA33cAFi9ZuB2sjQ@mail.gmail.com>
Message-ID: <CAG2Qp6u6tcC7k-oBMzh_wjVHJAJ04uoAxzx_PHiPjeesLur-pw@mail.gmail.com>

I add that the main line in squid3.conf is:

cache_peer 10.10.1.10 parent 80 0 no-query originserver login=PASS name=SiteXXX

Thanks again.

2015-12-15 8:39 GMT-03:00 Roberto Carna <robertocarna36 at gmail.com>:
> Dear, we have a Squid3 as reverse proxy with default configuration.
>
> We have a domain pointed to a web server. In this server the user
> session expiration is setup in 3 hs, but each 15 minutes the session
> expires.
>
> At this time, we are not sure about the origin of the session
> expiration. Taking into account the Squid 3 server, which parameter
> can I adjust in order to increment the session timeout ???
>
> Thanks a lot,
>
> Roberto


From Antony.Stone at squid.open.source.it  Tue Dec 15 12:32:05 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 15 Dec 2015 12:32:05 +0000
Subject: [squid-users] Reverse proxy: session expired in 15 minutes
In-Reply-To: <CAG2Qp6sR-hCNTGHc+QADV1ZmT+mQYim_KwxA33cAFi9ZuB2sjQ@mail.gmail.com>
References: <CAG2Qp6sR-hCNTGHc+QADV1ZmT+mQYim_KwxA33cAFi9ZuB2sjQ@mail.gmail.com>
Message-ID: <201512151232.05386.Antony.Stone@squid.open.source.it>

On Tuesday 15 Dec 2015 at 11:39, Roberto Carna wrote:

> Dear, we have a Squid3 as reverse proxy with default configuration.
> 
> We have a domain pointed to a web server. In this server the user
> session expiration is setup in 3 hs, but each 15 minutes the session
> expires.

What is your definition of "session"?


Antony.

-- 
The words "e pluribus unum" on the Great Seal of the United States are from a 
poem by Virgil entitled "Moretum", which is about cheese and garlic salad 
dressing.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From robertocarna36 at gmail.com  Tue Dec 15 13:02:41 2015
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Tue, 15 Dec 2015 10:02:41 -0300
Subject: [squid-users] Reverse proxy: session expired in 15 minutes
In-Reply-To: <201512151232.05386.Antony.Stone@squid.open.source.it>
References: <CAG2Qp6sR-hCNTGHc+QADV1ZmT+mQYim_KwxA33cAFi9ZuB2sjQ@mail.gmail.com>
 <201512151232.05386.Antony.Stone@squid.open.source.it>
Message-ID: <CAG2Qp6uScOGoy5bBkQGnOGnpMQ0wLiVUNxip-x5511V3mHNssw@mail.gmail.com>

Development team say that a session is conformed by cookies, and the
expiration time defined is 3 hours.

2015-12-15 9:32 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:
> On Tuesday 15 Dec 2015 at 11:39, Roberto Carna wrote:
>
>> Dear, we have a Squid3 as reverse proxy with default configuration.
>>
>> We have a domain pointed to a web server. In this server the user
>> session expiration is setup in 3 hs, but each 15 minutes the session
>> expires.
>
> What is your definition of "session"?
>
>
> Antony.
>
> --
> The words "e pluribus unum" on the Great Seal of the United States are from a
> poem by Virgil entitled "Moretum", which is about cheese and garlic salad
> dressing.
>
>                                                    Please reply to the list;
>                                                          please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Tue Dec 15 13:06:41 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 02:06:41 +1300
Subject: [squid-users] Reverse proxy: session expired in 15 minutes
In-Reply-To: <CAG2Qp6uScOGoy5bBkQGnOGnpMQ0wLiVUNxip-x5511V3mHNssw@mail.gmail.com>
References: <CAG2Qp6sR-hCNTGHc+QADV1ZmT+mQYim_KwxA33cAFi9ZuB2sjQ@mail.gmail.com>
 <201512151232.05386.Antony.Stone@squid.open.source.it>
 <CAG2Qp6uScOGoy5bBkQGnOGnpMQ0wLiVUNxip-x5511V3mHNssw@mail.gmail.com>
Message-ID: <56701061.1020400@treenet.co.nz>

On 16/12/2015 2:02 a.m., Roberto Carna wrote:
> Development team say that a session is conformed by cookies, and the
> expiration time defined is 3 hours.

Squid has nothing to do with Cookie headers. Except to ensure that they
are erased from cached responses as per the Cookie requirements.

Amos



From Antony.Stone at squid.open.source.it  Tue Dec 15 13:08:30 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 15 Dec 2015 13:08:30 +0000
Subject: [squid-users] Reverse proxy: session expired in 15 minutes
In-Reply-To: <CAG2Qp6uScOGoy5bBkQGnOGnpMQ0wLiVUNxip-x5511V3mHNssw@mail.gmail.com>
References: <CAG2Qp6sR-hCNTGHc+QADV1ZmT+mQYim_KwxA33cAFi9ZuB2sjQ@mail.gmail.com>
 <201512151232.05386.Antony.Stone@squid.open.source.it>
 <CAG2Qp6uScOGoy5bBkQGnOGnpMQ0wLiVUNxip-x5511V3mHNssw@mail.gmail.com>
Message-ID: <201512151308.30865.Antony.Stone@squid.open.source.it>

On Tuesday 15 Dec 2015 at 13:02, Roberto Carna wrote:

> Development team say that a session is conformed by cookies, and the
> expiration time defined is 3 hours.

Squid will not change the content of the cookies (although it's possible it 
could remove them, depending on the configuration).

Does the server perhaps set a default session expiry time of 15 minutes in the 
absence of a cookie, and 180 minutes when the cookie is present?

Have you tried performing a packet capture, on either the client-facing or 
server-facing side of the Squid proxy, to see whether the cookies are getting 
passed through?

> > On Tuesday 15 Dec 2015 at 11:39, Roberto Carna wrote:
> >> Dear, we have a Squid3 as reverse proxy with default configuration.
> >> 
> >> We have a domain pointed to a web server. In this server the user
> >> session expiration is setup in 3 hs, but each 15 minutes the session
> >> expires.
> > 
> > What is your definition of "session"?
> > 
> > 
> > Antony.

-- 
Never automate fully anything that does not have a manual override capability. 
Never design anything that cannot work under degraded conditions in emergency.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From giray_simsek at hotmail.com  Tue Dec 15 13:11:17 2015
From: giray_simsek at hotmail.com (Giray Simsek)
Date: Tue, 15 Dec 2015 05:11:17 -0800
Subject: [squid-users] Transfer-Encoding tag not delivered to c-icap
 server
In-Reply-To: <566EF620.6060502@measurement-factory.com>
References: <BLU184-W23009AB86AF5852A8AA753FEED0@phx.gbl>,
 <566EF620.6060502@measurement-factory.com>
Message-ID: <BLU184-W304DFB5AD23B264C862DEFFEEE0@phx.gbl>

That was helpful. I looked at the ICAP request/response headers as well as the squid log.?

After seeing the following line in the log file:

2015/12/15 11:52:58.104 kid1| 93,3| Xaction.cc(512) setOutcome: Warning: reseting outcome: from ICAP_MOD to ICAP_ERR_OTHER

I thought it must be caused by something on the icap side. And I verified that download problem occurs only for files larger than 5 MB.?

Then I noticed that the icap av service's MaxObjectSize has a default value of 5MB.

Upping this number in the conf file solved my issue.

Thanks a lot.

Giray


----------------------------------------
> Subject: Re: [squid-users] Transfer-Encoding tag not delivered to c-icap server
> To: squid-users at lists.squid-cache.org
> CC: giray_simsek at hotmail.com
> From: rousskov at measurement-factory.com
> Date: Mon, 14 Dec 2015 10:02:24 -0700
>
> On 12/14/2015 08:33 AM, Giray Simsek wrote:
>
>> I am using squid + c-icap for content adaptation.
>> On a client machine, I am trying to download a pdf file from docs.google.com. Looks like the google servers are sending the response as chunked as the http headers look like below:
>
>> Transfer-Encoding:chunked
>
>
>> I listened to the packets that are delivered to icap server from
>> squid and verified that "Transfer-Encoding" header is not delivered
>> to icap server.
>
>
> This is normal. Squid decodes chunked transfer encoding before sending
> the message to the ICAP (or eCAP) service, as it should.
>
>
>> So I can't find out at what point the file download is being blocked.
>> File is downloaded successfully when the icap server is stopped. But
>> I guess the problem might be about squid's way of passing the file
>> content (or headers) to icap server. Is there anything I can do on
>> the icap server side to make the download succeed?
>
> You may want start by finding the ICAP request and response headers and
> posting them here. IIRC, Squid reports them with debug_options ALL,2
>
>
> HTH,
>
> Alex.
>
>
>
>
 		 	   		  

From magiclink at outlook.com  Tue Dec 15 14:02:34 2015
From: magiclink at outlook.com (Magic Link)
Date: Tue, 15 Dec 2015 15:02:34 +0100
Subject: [squid-users] issue with video
In-Reply-To: <566F800E.106@treenet.co.nz>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>,
 <5668B48C.703@treenet.co.nz>, <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>,
 <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl>, <5669997A.70209@gmail.com>,
 <DUB130-W4883D1369E0FC96B14F00ABDEA0@phx.gbl>,
 <DUB130-W6B91C01FA9412AB19D44CBDED0@phx.gbl>, <566F684D.4060602@ngtech.co.il>,
 <566F800E.106@treenet.co.nz>
Message-ID: <DUB130-W51B0FFFACA318CF71E92BDBDEE0@phx.gbl>







Hi,
the preview video here doesn't start, only the ads starts, then black screen appears. Then i don't have the choice, the play button appears and itplays the ads again and again : http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/. Tested with squid 3.4.8 and 3.5.10If i use a direct access without the proxy with the same computer, the preview video begins (length 45 sec)
The videos listed here works very well with squid : http://www.cbsnews.com/videos/

> To: squid-users at lists.squid-cache.org
> From: squid3 at treenet.co.nz
> Date: Tue, 15 Dec 2015 15:50:54 +1300
> Subject: Re: [squid-users] issue with video
> 
> On 15/12/2015 2:09 p.m., Eliezer Croitoru wrote:
> > I am not sure it's any squid issue since it is unclear what you are
> > referring to as "not working".
> > The logs can show couple things but cannot record what is the issue in
> > the client level.
> > I have tried to read them but have not seen the video request.
> > It could be a client issue rather then squid..
> > 
> 
> The closest thing to a video stream in those logs seems to be:
> 
> cache.log:
> 
> 2015/12/10 09:56:12.400 kid1| client_side.cc(2407) parseHttpRequest:
> HTTP Client local=10.2.10.251:3128 remote=10.2.100.32:53031 FD 21 flags=1
> 2015/12/10 09:56:12.401 kid1| client_side.cc(2408) parseHttpRequest:
> HTTP Client REQUEST:
> ---------
> CONNECT www.youtube.com:443 HTTP/1.0
> User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0)
> like Gecko
> Host: www.youtube.com:443
> Content-Length: 0
> Proxy-Connection: Keep-Alive
> Pragma: no-cache
> ---------
> 
> access.log:
> 
> 1449737803.472  31071 10.2.100.32 TCP_MISS/200 4435 CONNECT
> www.youtube.com:443 - HIER_DIRECT/216.58.211.78 -
> 
> 
> If we assume that the HTTPS request was a video fetch from YouTube, then
> it was a succesful tunnel as far as Squid is concerned. It had 4.4KB
> sent in 31 seconds. Which does seem a bit odd for a video, but could be
> if its broken internally.
> 
> The rest of what Eliezer pointed out is relevant to further debugging
> non your part...
> 
> > What browser are you using? What version? Do you have the latest flash
> > player instlaled?
> > 
> > Do you know if the requested video file\stream is an http one?
> > If so what is the url which doesn't work?
> > In any case you can use firefox\chrome\explorer\safri\opera developers
> > tools to identify the url which doesn't work.
> > For firefox take a look at:
> > https://www.youtube.com/watch?v=w4zSG53Qlbk
> > https://developer.mozilla.org/en-US/docs/Tools/Network_Monitor
> > 
> > For Chrome take a look at:
> > https://www.youtube.com/watch?v=PwoT18tp6Hs
> > 
> > For Internet Explorer at:
> > https://youtu.be/GbbjL_Uir24?t=713
> > 
> > Since the url you presented at your first post doesn't work I have tried
> > the official video one at:
> > http://www.cbsnews.com/videos/
> > 
> > The videos works for me using squid 3.5.12 so it doesn't seem to be any
> > squid related issue in my eyes.
> > 
> > The video urls are at the domain\origin\server:
> > http://cbsnews-vh.akamaihd.net/
> > 
> > You can post images of screenshot using either google drive or one of
> > these:
> > http://snag.gy/
> > http://pasteboard.co/
> > 
> > Eliezer
> > 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/19691bf2/attachment.htm>

From Sebastien.Boulianne at cpu.ca  Tue Dec 15 15:15:17 2015
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Tue, 15 Dec 2015 10:15:17 -0500
Subject: [squid-users] Installing Squid as a service on Oracle Linux 7.2
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>

Hi,

I hope all is going perfectly for you.

Im trying to install Squid-3.5.12 from source.
I followed the doc to compile it properly.

When I ran squid -z, all is perfect.

[root at squid /]# squid -z
[root at squid /]# 2015/12/15 10:06:20 kid1| Set Current Directory to /var/spool/squid
2015/12/15 10:06:20 kid1| Creating missing swap directories
2015/12/15 10:06:20 kid1| /var/spool/squid exists
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/00
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/01
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/02
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/03
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/04
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/05
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/06
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/07
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/08
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/09
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0A
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0B
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0C
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0D
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0E
2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0F

But when I try to ? service squid start ?, it fails... There is no squid.service.

[root at squid /]# service squid start
Redirecting to /bin/systemctl start  squid.service
Failed to start squid.service: Unit squid.service failed to load: No such file or directory.

I searched for a doc how to create this file but I can't find it.

Can you help me please ?

S?bastien Boulianne
Administrateur r?seau & syst?me / Network & System Administrator.
Gestion des infrastructures / Infrastructure Management.
CCNA / CompTIA Server+ / Sp?cialiste en monitoring.
sebastien.boulianne at cpu.ca<mailto:sebastien.boulianne at cpu.ca>

[cid:image001.jpg at 01D13720.14E92580]


2323, du Versant Nord, suite 100
Qu?bec (Qu?bec) G1N 4P4
T?l?phone : (418) 681 6974 poste 666
Ligne sans frais : 1 888 681 6974
T?l?copieur : (418) 681 1444

Information confidentielle : Le pr?sent message, ainsi que tout fichier qui y est joint, est envoy? ? l'intention exclusive de son ou de ses destinataires, il est de nature confidentielle et peut constituer une information privil?gi?e. Nous avertissons toute personne autre que le destinataire pr?vu que tout examen, r?acheminement, impression, copie, distribution ou autre utilisation de ce message et de tout fichier qui y est joint est strictement interdit. Si vous n'?tes pas le destinataire pr?vu, veuillez en aviser imm?diatement l'exp?diteur par retour de courriel et supprimer ce message et tout document joint de votre syst?me. Merci.

Confidentiality Warning : This message and any attachments are intended only for the use of the intended recipient(s), are confidential, and may be privileged. If you are not the intended recipient, you are hereby notified that any review, retransmission, conversion to hard copy, copying, circulation or other use of this message and any attachments is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail, and delete this message and any attachments from your system. Thank you.

? G?rer c'est pr?voir (voir avant, avoir une vision de l'avenir) ?
[cid:image002.jpg at 01D13720.14E92580]

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/be2bbd03/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.jpg
Type: image/jpeg
Size: 1648 bytes
Desc: image001.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/be2bbd03/attachment.jpg>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.jpg
Type: image/jpeg
Size: 3146 bytes
Desc: image002.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/be2bbd03/attachment-0001.jpg>

From yvoinov at gmail.com  Tue Dec 15 15:34:55 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 15 Dec 2015 21:34:55 +0600
Subject: [squid-users] Installing Squid as a service on Oracle Linux 7.2
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>
Message-ID: <5670331F.4090207@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Squid's source don't contain automatically installed autostart services
for all possible platforms. You can do it yourself.

15.12.15 21:15, Sebastien.Boulianne at cpu.ca ?????:
> Hi,
>
> I hope all is going perfectly for you.
>
> Im trying to install Squid-3.5.12 from source.
> I followed the doc to compile it properly.
>
> When I ran squid -z, all is perfect.
>
> [root at squid /]# squid -z
> [root at squid /]# 2015/12/15 10:06:20 kid1| Set Current Directory to
/var/spool/squid
> 2015/12/15 10:06:20 kid1| Creating missing swap directories
> 2015/12/15 10:06:20 kid1| /var/spool/squid exists
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/00
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/01
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/02
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/03
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/04
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/05
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/06
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/07
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/08
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/09
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0A
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0B
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0C
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0D
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0E
> 2015/12/15 10:06:20 kid1| Making directories in /var/spool/squid/0F
>
> But when I try to ? service squid start ?, it fails... There is no
squid.service.
>
> [root at squid /]# service squid start
> Redirecting to /bin/systemctl start  squid.service
> Failed to start squid.service: Unit squid.service failed to load: No
such file or directory.
>
> I searched for a doc how to create this file but I can't find it.
>
> Can you help me please ?
>
> S?bastien Boulianne
> Administrateur r?seau & syst?me / Network & System Administrator.
> Gestion des infrastructures / Infrastructure Management.
> CCNA / CompTIA Server+ / Sp?cialiste en monitoring.
> sebastien.boulianne at cpu.ca<mailto:sebastien.boulianne at cpu.ca>
>
> [cid:image001.jpg at 01D13720.14E92580]
>
>
> 2323, du Versant Nord, suite 100
> Qu?bec (Qu?bec) G1N 4P4
> T?l?phone : (418) 681 6974 poste 666
> Ligne sans frais : 1 888 681 6974
> T?l?copieur : (418) 681 1444
>
> Information confidentielle : Le pr?sent message, ainsi que tout
fichier qui y est joint, est envoy? ? l'intention exclusive de son ou de
ses destinataires, il est de nature confidentielle et peut constituer
une information privil?gi?e. Nous avertissons toute personne autre que
le destinataire pr?vu que tout examen, r?acheminement, impression,
copie, distribution ou autre utilisation de ce message et de tout
fichier qui y est joint est strictement interdit. Si vous n'?tes pas le
destinataire pr?vu, veuillez en aviser imm?diatement l'exp?diteur par
retour de courriel et supprimer ce message et tout document joint de
votre syst?me. Merci.
>
> Confidentiality Warning : This message and any attachments are
intended only for the use of the intended recipient(s), are
confidential, and may be privileged. If you are not the intended
recipient, you are hereby notified that any review, retransmission,
conversion to hard copy, copying, circulation or other use of this
message and any attachments is strictly prohibited. If you are not the
intended recipient, please notify the sender immediately by return
e-mail, and delete this message and any attachments from your system.
Thank you.
>
> ? G?rer c'est pr?voir (voir avant, avoir une vision de l'avenir) ?
> [cid:image002.jpg at 01D13720.14E92580]
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWcDMfAAoJENNXIZxhPexG0uMH/jha7PDHI4By6iZGulVXPaXf
kKqv1u9CYM2u6Sp/45i7FFVSYUYW0DnVD6PlkuWXjIxD0L2zouOOkl1JOPBA+J4N
/SKrMYlTDDajRUltL1WGaFzLWjPr6msxLHTAiFu1gyrUKr1VCrUkdQ7mYoJ+Pyrx
ygoH8bcjIsHFVJjBMTtfQsJlJHW0So7TqYMZUuYK3JsjirP81fDGEOonMHt/M3tx
ySWZ7elgLwsbs2eOaovjon6Kz0A7ZMBCRBwD3JQPG20RL+UzUfSaldcq4xpsUpfG
T76uDIN+LJAgIeNsSlCSiIfbQGvT940oqh6OXWCxuL6iP955Iva9+OfjRxlexNI=
=s1CD
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/67200be3/attachment.htm>

From bhsreenath at gmail.com  Tue Dec 15 18:16:19 2015
From: bhsreenath at gmail.com (Sreenath BH)
Date: Tue, 15 Dec 2015 23:46:19 +0530
Subject: [squid-users] Time for cache synchronization between siblings
Message-ID: <CALgKBSnCywpET++mS_UdgYpGpEgJ7Wx4D40Mwg2=yiXRtN-h7g@mail.gmail.com>

Hi,

I have a setup with three squid peers (siblings in squid.conf) and
three upstream servers(peers with parent and originserver in
squid.conf).

I am using htcp for the three squid siblings.
How much time does it take for one squid server to 'know' that another
peer has a particular object cached? I see digests exchanged between
the siblings, as logged in cache.log.

I have been able to make a request to one sibling and it resulted in a
sibling_hit.

How I do this test is this:
1. bring up all siblings
2. issue a request to one server (sibling 1)
3. Make sure it is cached in sibling 1
4. Wait for some time (I don't know how long to wait)
5. Make same request to another sibling, say sibling 2
6. Check if it went to upstream server for the request or it was a sibling hit.

My problem is that the sibling hits seem to be random. I am  not able
to figure out exactly
how log it takes for the cache information to propagate to all siblings.

Any information in this regard is appreciated.

thanks,
Sreenath


From rousskov at measurement-factory.com  Tue Dec 15 19:38:02 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 15 Dec 2015 12:38:02 -0700
Subject: [squid-users] Using subordinate CA for SSL Bump
In-Reply-To: <566F5534.6090801@urlfilterdb.com>
References: <566F3412.6060504@gmail.com> <566F4DC6.6080408@treenet.co.nz>
 <566F5534.6090801@urlfilterdb.com>
Message-ID: <56706C1A.3080300@measurement-factory.com>

On 12/14/2015 04:48 PM, Marcus Kool wrote:
> On 12/14/2015 09:16 PM, Amos Jeffries wrote:
>> Squid may be horribly sending
>> all-but-one of the certs needed, on the assumption that the signing cert
>> is itself installed on the client.


> The RFC says that it is not necessary to send the signing CA certificate.


Sending the CA certificate is usually both unnecessary (because the
clients must have it) and borderline dangerous (because some clients do
not expect this extra information). This is why, I bet, Squid does not
send the signing certificate in some cases.

On the other hand, sending the signing certificate is necessary if that
signing certificate is not the CA certificate expected to be stored by
clients. IIRC, we have fixed at least one Squid bug in this area in
2015, but I do not have a reference handy.

And there are actually situations in-between the two extremes above
because a CA (well-known and not) often has its own CA certificate
hierarchy, and some clients may trust intermediate CA certificates [with
or without storing the root CA certificate].

The above does not answer the OP question. The answer may go something
like this:

If you expect your clients to store your signing certificate, then you
can configure Squid to sign with that certificate and not worry about
any higher-level (closer to root) certificate that may or may not exist.
On the other hand, if your clients are storing a higher-level
certificate, then you need to test whether Squid does the right thing
(i.e., sends the intermediate certificate which also happens to be the
signing certificate). If Squid does not do the right thing, file a bug
report.


HTH,

Alex.



From hack.back at hotmail.com  Tue Dec 15 19:46:56 2015
From: hack.back at hotmail.com (HackXBack)
Date: Tue, 15 Dec 2015 11:46:56 -0800 (PST)
Subject: [squid-users] cant bump ssl
Message-ID: <1450208816089-4675201.post@n4.nabble.com>

hello,
am using squid 3.5
why i cant bump ssl conection with android 
my squid conf is



# SSL_BUMP_WHITE_LIST = 0 [squid_ssl/build/48]
acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3
ssl_bump peek ssl_step1

# SNI Group fbcdn
acl SNIGroup5 ssl::server_name_regex -i fbcdn\.net
acl SNIGroup5 ssl::server_name_regex -i akamaihd\.net
acl SNIGroup5 ssl::server_name_regex -i i\.ytimg\.com
acl SNIGroup5 ssl::server_name_regex -i facebook\.com

# 1 BUMP rules...
ssl_bump bump ssl_step2 SNIGroup5
# 1 Splice rules...
ssl_bump splice all

sslproxy_version 0
sslproxy_options ALL
sslproxy_cert_error allow all

#-------- Wont push the client to use udp 443 or udp 80
reply_header_access alternate-protocol deny all
#--------- Wont push the client to use HSTS sent by the web site
reply_header_access Strict-Transport-Security deny all

# Squid normally listens to port 3128
https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl_cert/myCA.pem
http_port  3129
http_port  3128 intercept

sslcrtd_program /usr/lib/squid/ssl_crtd -s /etc/squid/ssl_db/certs/ -M 16MB
sslcrtd_children 50 startup=40 idle=1





in access.log i see TAG_NONE





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/cant-bump-ssl-tp4675201.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Tue Dec 15 20:17:43 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 15 Dec 2015 13:17:43 -0700
Subject: [squid-users] cant bump ssl
In-Reply-To: <1450208816089-4675201.post@n4.nabble.com>
References: <1450208816089-4675201.post@n4.nabble.com>
Message-ID: <56707567.7080905@measurement-factory.com>

On 12/15/2015 12:46 PM, HackXBack wrote:
> why i cant bump ssl conection with android 
> my squid conf is

> ssl_bump bump ssl_step2 SNIGroup5
> ssl_bump splice all


In modern Squids, your configuration above is equivalent to:

  ssl_bump splice all

because, during the very first SslBump processing step (step1), your
bump rule never matches while your splice rule always does. Once the
final rule (bump, splice, or terminate) matches, Squid performs the
matched action and stops further SslBump rules processing.

I recommend thinking of ssl_bump rules as a single set of instructions,
revisited at each SslBump step, until the final rule matches.


HTH,

Alex.



From hack.back at hotmail.com  Tue Dec 15 20:07:20 2015
From: hack.back at hotmail.com (HackXBack)
Date: Tue, 15 Dec 2015 12:07:20 -0800 (PST)
Subject: [squid-users] cant bump ssl
In-Reply-To: <56707567.7080905@measurement-factory.com>
References: <1450208816089-4675201.post@n4.nabble.com>
 <56707567.7080905@measurement-factory.com>
Message-ID: <1450210040202-4675203.post@n4.nabble.com>

i cant understand ssl_bump rules for version 3.5
what i can do to bump this 3 domains 
fbcdn\.net
akamaihd\.net
i\.ytimg\.com



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/cant-bump-ssl-tp4675201p4675203.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Sebastien.Boulianne at cpu.ca  Tue Dec 15 20:29:09 2015
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Tue, 15 Dec 2015 15:29:09 -0500
Subject: [squid-users] Installing Squid as a service on Oracle Linux 7.2
In-Reply-To: <5670331F.4090207@gmail.com>
References: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>
 <5670331F.4090207@gmail.com>
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>

Hi,

Your answer didn?t help me.
Does it have anyone who create a service file for squid and want to share it.
I tried the squid.service from the yum package (v3.3.8) but it didn?t work.

Thanks

S?bastien
De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Yuri Voinov
Envoy? : 15 d?cembre 2015 10:35
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] Installing Squid as a service on Oracle Linux 7.2


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

Squid's source don't contain automatically installed autostart services for all possible platforms. You can do it yourself.

15.12.15 21:15, Sebastien.Boulianne at cpu.ca<mailto:Sebastien.Boulianne at cpu.ca> ?????:
> Hi,

      >

      > I hope all is going perfectly for you.

      >

      > Im trying to install Squid-3.5.12 from source.

      > I followed the doc to compile it properly.

      >

      > When I ran squid -z, all is perfect.

      >

      > [root at squid /]# squid -z

      > [root at squid /]# 2015/12/15 10:06:20 kid1| Set Current
      Directory to /var/spool/squid

      > 2015/12/15 10:06:20 kid1| Creating missing swap directories

      > 2015/12/15 10:06:20 kid1| /var/spool/squid exists

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/00

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/01

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/02

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/03

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/04

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/05

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/06

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/07

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/08

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/09

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/0A

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/0B

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/0C

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/0D

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/0E

      > 2015/12/15 10:06:20 kid1| Making directories in
      /var/spool/squid/0F

      >

      > But when I try to ? service squid start ?, it fails... There
      is no squid.service.

      >

      > [root at squid /]# service squid start

      > Redirecting to /bin/systemctl start  squid.service

      > Failed to start squid.service: Unit squid.service failed to
      load: No such file or directory.

      >

      > I searched for a doc how to create this file but I can't find
      it.

      >

      > Can you help me please ?

      >

      > S?bastien Boulianne

      > Administrateur r?seau & syst?me / Network & System
      Administrator.

      > Gestion des infrastructures / Infrastructure Management.

      > CCNA / CompTIA Server+ / Sp?cialiste en monitoring.

      >
      sebastien.boulianne at cpu.ca<mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca>

      >

      > [cid:image001.jpg at 01D13720.14E92580]

      >

      >

      > 2323, du Versant Nord, suite 100

      > Qu?bec (Qu?bec) G1N 4P4

      > T?l?phone : (418) 681 6974 poste 666

      > Ligne sans frais : 1 888 681 6974

      > T?l?copieur : (418) 681 1444

      >

      > Information confidentielle : Le pr?sent message, ainsi que
      tout fichier qui y est joint, est envoy? ? l'intention exclusive
      de son ou de ses destinataires, il est de nature confidentielle et
      peut constituer une information privil?gi?e. Nous avertissons
      toute personne autre que le destinataire pr?vu que tout examen,
      r?acheminement, impression, copie, distribution ou autre
      utilisation de ce message et de tout fichier qui y est joint est
      strictement interdit. Si vous n'?tes pas le destinataire pr?vu,
      veuillez en aviser imm?diatement l'exp?diteur par retour de
      courriel et supprimer ce message et tout document joint de votre
      syst?me. Merci.

      >

      > Confidentiality Warning : This message and any attachments
      are intended only for the use of the intended recipient(s), are
      confidential, and may be privileged. If you are not the intended
      recipient, you are hereby notified that any review,
      retransmission, conversion to hard copy, copying, circulation or
      other use of this message and any attachments is strictly
      prohibited. If you are not the intended recipient, please notify
      the sender immediately by return e-mail, and delete this message
      and any attachments from your system. Thank you.

      >

      > ? G?rer c'est pr?voir (voir avant, avoir une vision de
      l'avenir) ?

      > [cid:image002.jpg at 01D13720.14E92580]

      >

      >

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJWcDMfAAoJENNXIZxhPexG0uMH/jha7PDHI4By6iZGulVXPaXf
kKqv1u9CYM2u6Sp/45i7FFVSYUYW0DnVD6PlkuWXjIxD0L2zouOOkl1JOPBA+J4N
/SKrMYlTDDajRUltL1WGaFzLWjPr6msxLHTAiFu1gyrUKr1VCrUkdQ7mYoJ+Pyrx
ygoH8bcjIsHFVJjBMTtfQsJlJHW0So7TqYMZUuYK3JsjirP81fDGEOonMHt/M3tx
ySWZ7elgLwsbs2eOaovjon6Kz0A7ZMBCRBwD3JQPG20RL+UzUfSaldcq4xpsUpfG
T76uDIN+LJAgIeNsSlCSiIfbQGvT940oqh6OXWCxuL6iP955Iva9+OfjRxlexNI=
=s1CD
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/869650ba/attachment.htm>

From juanchorevolution at hotmail.com  Tue Dec 15 20:35:54 2015
From: juanchorevolution at hotmail.com (juancho Alfonso)
Date: Tue, 15 Dec 2015 15:35:54 -0500
Subject: [squid-users] Not work HELP change cache dir
In-Reply-To: <1E65640A-DDA2-41F1-B55E-93E6DC57A702@yahoo.com>
References: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>,
 <5669E2E0.6040405@gmail.com>
 <COL131-W633C280854D4FDA65685BCB0E90@phx.gbl>,
 <COL131-W56159B00FFCCFFB2BC8F99B0EA0@phx.gbl>,
 <COL131-W3061BB144436CFF64C7941B0EB0@phx.gbl>,
 <CAFPNf5-S_w-C=3F-EdYXH6tNCYYOMFqb5UTB23SNvzOrbOj9TA@mail.gmail.com>,
 <1E65640A-DDA2-41F1-B55E-93E6DC57A702@yahoo.com>
Message-ID: <COL131-W7165EADE844BC9CC50F18CB0EE0@phx.gbl>

s.o. centos 7squid version 3.3
in the squid.conf file
cache_dir aufs /var/spool/squid 20480 16 256 
cache_effective_user squid
cache_effective_group squidthis way works
cache_dir aufs /var/spool/squid2 20480 16 256 cache_effective_user squid
cache_effective_group squidorcache_dir aufs PATHEXTERNALDRIVE/squid2 20480 16 256 cache_effective_user squidcache_effective_group squidthis way doesnt
i need change dir to a external drive with more capacity2 TB
the local disk is small 70 GB
i have tried
chmod 777 -R /var/spool/squid2chown -R squid.squid  /var/spool/squid2orchown -R root.root      /var/spool/squid2orchown -R squid.squid  /var/spool/squid2ororchown -R proxy.conexion  /var/spool/squid2

nothing works


















From: tarotapprentice at yahoo.com
Date: Sun, 13 Dec 2015 08:57:17 +1100
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] FW: help change cache dir

The last time I setup my cache dir I did the following (in Debian):
cd /var/spoolsudo mkdir squidsudo chown proxy:proxy squid/usr/sbin/squid -z
Where proxy is the username for squid.
On 13 Dec 2015, at 4:59 AM, Lee Brown <leeb at ratnaling.org> wrote:


On Sat, Dec 12, 2015 at 5:39 AM, juancho Alfonso <juanchorevolution at hotmail.com> wrote:







the user issquidif i initialite by defaul it worksin var/spool/squidand works user squid squidbut i want add dir var/spool/squidor XDISKEXTERNAL/something/squid
but dont work permission denied(13)

try chmod -R squid.squid cacheorchmod -R 777 cache

image show config http://es.zimagez.com/zimage/captura398.php


To: squid-users at lists.squid-cache.org
From: yvoinov at gmail.com
Date: Fri, 11 Dec 2015 02:38:56 +0600
Subject: Re: [squid-users] help change cache dir


  
    
  
  
    

    -----BEGIN PGP SIGNED MESSAGE----- 

    Hash: SHA256 

     

    Cache dir owner must be user which is specified in squid.conf:

    

    http://i.imgur.com/AbYkE8M.png

    

    

    

    11.12.15 2:27, juancho Alfonso ?????:

    > Hey thereI have installed
      CentOS squid in 7I want to change the cache directory

      > appears when I try to initialize

      > Creating Swap Directories

      > FATAL: Failed to make directory swap mydirectory / cache /
      00:

      >      (13) Permission denied

      > directory is an external drive or a folder on the same
      partitionand I granted permissions

      > chmod 777 cacheorchmod cache squid.squid

      > no worksI need help to put more capacity more directories

      >

      >

      >

      > the squid.conf

      > ## Recommended minimum configuration:#

      > # Example rule allowing access from your local networks.#
      Adapt to list your (internal) IP networks from where browsing#
      should be allowedacl localnet src 10.0.0.0/8 # RFC1918 possible
      internal networkacl localnet src 172.16.0.0/12 # RFC1918 possible
      internal networkacl localnet src 192.168.0.0/16 # RFC1918 possible
      internal networkacl localnet src fc00::/7 # RFC 4193 local private
      network rangeacl localnet src fe80::/10 # RFC 4291 link-local
      (directly plugged) machines

      > acl SSL_ports port 443acl Safe_ports port 80 # httpacl
      Safe_ports port 21 # ftpacl Safe_ports port 443 # httpsacl
      Safe_ports port 70 # gopheracl Safe_ports port 210 # waisacl
      Safe_ports port 1025-65535 # unregistered portsacl Safe_ports port
      280 # http-mgmtacl Safe_ports port 488 # gss-httpacl Safe_ports
      port 591 # filemakeracl Safe_ports port 777 # multiling httpacl
      CONNECT method CONNECTacl PAGINASBLOQUEADAS url_regex -i porno
      abcde

      > ## Recommended minimum Access Permission configuration:##
      Deny requests to certain unsafe portshttp_access deny
      PAGINASBLOQUEADAS

      > # Deny CONNECT to other than secure SSL portshttp_access deny
      !Safe_ports

      > # Only allow cachemgr access from localhosthttp_access deny
      CONNECT !SSL_portshttp_access allow localhost manager

      > # We strongly recommend the following be uncommented to
      protect innocent# web applications running on the proxy server who
      think the only# one who can access services on "localhost" is a
      local user#http_access deny to_localhost

      > ## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR
      CLIENTS#

      > # Example rule allowing access from your local networks.#
      Adapt localnet in the ACL section to list your (internal) IP
      networks# from where browsing should be allowedhttp_access allow
      managerhttp_access allow localnet

      > # And finally deny all other access to this proxyhttp_access
      allow localhosthttp_access allow all

      > # Squid normally listens to port 3128http_port 3128
      transparent

      > # Uncomment and adjust the following to add a disk cache
      directory.

      > # Leave coredumps in the first cache dircoredump_dir
      /var/spool/squid

      > ## Add any of your own refresh_pattern entries above
      these.#refresh_pattern ^ftp:        1440    20%   
      10080refresh_pattern ^gopher:    1440    0%    1440refresh_pattern
      -i (/cgi-bin/|\?) 0    0%    0refresh_pattern .        0    20%   
      4320

      >

      >

      > #juancache_mem 16384 MB#cache_replacement_policy heap LFUDA
      #El par?metro maximum_object_size define el tama?o m?ximo de los
      objetos que ser?n almacenados en el cache de
      discomaximum_object_size 200 MBcache_swap_low 90cache_swap_high
      95#correo del administrador del cachecache_mgr
      ingenieria at conexiondigital.cocachemgr_passwd cache all

      > #this workcache_dir aufs /var/spool/squid 40000 16 256 #this
      no workcache_dir aufs /var/spool/squid2 40000 16 256 

      > cache_effective_user squidcache_effective_group squid

      >

      >

      >

      > Juan Ernesto Alfonsoestudiante ingenier?a
      electr?nicauniversidad distrital Francisco Jos? de Caldas

      > JUANCHO

      >  NEMESIS 

      > KRAVEN

      >

      > " si un d?a tienes que elegir entre el mundo y el amor...

      > recuerda: 

      >

      > si eliges el mundo quedar?s sin amor, 

      >

      > pero si eliges el amor, con ?l conquistar?s al mundo" 

      >

      > albert einstein 

      >

      >

      >

      >                             

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org

      > http://lists.squid-cache.org/listinfo/squid-users

    

    -----BEGIN PGP SIGNATURE-----


    Version: GnuPG v2


     

    iQEcBAEBCAAGBQJWaeLfAAoJENNXIZxhPexGV6wH/0dy5nyvKJBsB8cWnXpyU661


    98aA96FF+8QlQW+dkAKyNJ/dNtjv/VyGbglqyDDoaqwq2+Uef3dZauwyIQcwoRxZ


    TVhUu47v+cX1F6Ka+JWxvw7hsIumoEvrXQQxdBoZUAqdXDRyvdK/VeraGyV1y2LD


    qYQB/vIV7u/PGgiyzE5vtZ/aHYnAsiLQxMD4a3SSvDnSNx9fklhRGyTljcNuVH5n


    NAXeXE3JD9+NW9rFY3/49TWNGJMNzH9v9RyQPG5uWkov/hAR1fXiRW7a/TD6pZ6V


    /gb54gbAQcdCMXwsly7XQTswoG6OKGLuLl6+mLbLz3hgBpDfZDNAQMpKM4npiSU=


    =ayi0


    -----END PGP SIGNATURE-----


    

  


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 		 	   		   		 	   		   		 	   		  

_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users




As Rafael said,

Check your SELinux settings.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/054baef2/attachment.htm>

From yvoinov at gmail.com  Tue Dec 15 20:53:54 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 16 Dec 2015 02:53:54 +0600
Subject: [squid-users] Installing Squid as a service on Oracle Linux 7.2
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>
 <5670331F.4090207@gmail.com>
 <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>
Message-ID: <56707DE2.5050507@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I'm in doubt that someone will do the work for you, the system
administrator :)

Especially since there is no big problem to read the manual and write a
dozen lines. :)

Repositories Linux - evil, they weaned experts think :)

16.12.15 2:29, Sebastien.Boulianne at cpu.ca ?????:
> Hi,
>
> Your answer didn?t help me.
> Does it have anyone who create a service file for squid and want to
share it.
> I tried the squid.service from the yum package (v3.3.8) but it didn?t
work.
>
> Thanks
>
> S?bastien
> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De
la part de Yuri Voinov
> Envoy? : 15 d?cembre 2015 10:35
> ? : squid-users at lists.squid-cache.org
> Objet : Re: [squid-users] Installing Squid as a service on Oracle
Linux 7.2
>
>
> Squid's source don't contain automatically installed autostart
services for all possible platforms. You can do it yourself.
>
> 15.12.15 21:15,
Sebastien.Boulianne at cpu.ca<mailto:Sebastien.Boulianne at cpu.ca> ?????:
> > Hi,
>
>
>
>       > I hope all is going perfectly for you.
>
>
>
>       > Im trying to install Squid-3.5.12 from source.
>
>       > I followed the doc to compile it properly.
>
>
>
>       > When I ran squid -z, all is perfect.
>
>
>
>       > [root at squid /]# squid -z
>
>       > [root at squid /]# 2015/12/15 10:06:20 kid1| Set Current
>       Directory to /var/spool/squid
>
>       > 2015/12/15 10:06:20 kid1| Creating missing swap directories
>
>       > 2015/12/15 10:06:20 kid1| /var/spool/squid exists
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/00
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/01
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/02
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/03
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/04
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/05
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/06
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/07
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/08
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/09
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0A
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0B
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0C
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0D
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0E
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0F
>
>
>
>       > But when I try to ? service squid start ?, it fails... There
>       is no squid.service.
>
>
>
>       > [root at squid /]# service squid start
>
>       > Redirecting to /bin/systemctl start  squid.service
>
>       > Failed to start squid.service: Unit squid.service failed to
>       load: No such file or directory.
>
>
>
>       > I searched for a doc how to create this file but I can't find
>       it.
>
>
>
>       > Can you help me please ?
>
>
>
>       > S?bastien Boulianne
>
>       > Administrateur r?seau & syst?me / Network & System
>       Administrator.
>
>       > Gestion des infrastructures / Infrastructure Management.
>
>       > CCNA / CompTIA Server+ / Sp?cialiste en monitoring.
>
>
>      
sebastien.boulianne at cpu.ca<mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca>
>
>
>
>       > [cid:image001.jpg at 01D13720.14E92580]
>
>
>
>
>
>       > 2323, du Versant Nord, suite 100
>
>       > Qu?bec (Qu?bec) G1N 4P4
>
>       > T?l?phone : (418) 681 6974 poste 666
>
>       > Ligne sans frais : 1 888 681 6974
>
>       > T?l?copieur : (418) 681 1444
>
>
>
>       > Information confidentielle : Le pr?sent message, ainsi que
>       tout fichier qui y est joint, est envoy? ? l'intention exclusive
>       de son ou de ses destinataires, il est de nature confidentielle et
>       peut constituer une information privil?gi?e. Nous avertissons
>       toute personne autre que le destinataire pr?vu que tout examen,
>       r?acheminement, impression, copie, distribution ou autre
>       utilisation de ce message et de tout fichier qui y est joint est
>       strictement interdit. Si vous n'?tes pas le destinataire pr?vu,
>       veuillez en aviser imm?diatement l'exp?diteur par retour de
>       courriel et supprimer ce message et tout document joint de votre
>       syst?me. Merci.
>
>
>
>       > Confidentiality Warning : This message and any attachments
>       are intended only for the use of the intended recipient(s), are
>       confidential, and may be privileged. If you are not the intended
>       recipient, you are hereby notified that any review,
>       retransmission, conversion to hard copy, copying, circulation or
>       other use of this message and any attachments is strictly
>       prohibited. If you are not the intended recipient, please notify
>       the sender immediately by return e-mail, and delete this message
>       and any attachments from your system. Thank you.
>
>
>
>       > ? G?rer c'est pr?voir (voir avant, avoir une vision de
>       l'avenir) ?
>
>       > [cid:image002.jpg at 01D13720.14E92580]
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       >
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWcH3hAAoJENNXIZxhPexGKp8H/iAFxGb+H2IMm86h/JON0zTO
rykxN+f5AC6ewtbbQWzN9MGT6amWFcAGHRaGcIsZhyvImnh1dN6PN7RkgnfzgQoi
PilUSCWMYqLh8y3P6gp520hGDvLp7lSbh7vc2/pBd5ONS+xKUe47QUA/6fiJHaGj
uGnrJQj7ibMEI2mLTLGTDvUMH7MCArpY3dJVTmjuxPPN1U3aVWk/lnLH4VPXyfxm
bYnQ7eiVuJzBwT9TkBDIL6xhIh5HRFlLe/wouAQm5majSGuucL8xWMyizbBxsUqO
Y4iMaBh7leK9dTBMxu2IU6J0B6SKNuGtB6QWlaKrK2q4uZlruKC2TzDlVuHA22Q=
=7JZw
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/f1d54e55/attachment.htm>

From yvoinov at gmail.com  Tue Dec 15 20:58:22 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 16 Dec 2015 02:58:22 +0600
Subject: [squid-users] Installing Squid as a service on Oracle Linux 7.2
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>
 <5670331F.4090207@gmail.com>
 <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>
Message-ID: <56707EEE.50003@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Ok,

I'll just done your job.

See attachements. I wrote squid.service, it takes approx. 30 seconds.

PS. But note: you must install both files manually yourself. Read
manuals anyway.

16.12.15 2:29, Sebastien.Boulianne at cpu.ca ?????:
> Hi,
>
> Your answer didn?t help me.
> Does it have anyone who create a service file for squid and want to
share it.
> I tried the squid.service from the yum package (v3.3.8) but it didn?t
work.
>
> Thanks
>
> S?bastien
> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De
la part de Yuri Voinov
> Envoy? : 15 d?cembre 2015 10:35
> ? : squid-users at lists.squid-cache.org
> Objet : Re: [squid-users] Installing Squid as a service on Oracle
Linux 7.2
>
>
> Squid's source don't contain automatically installed autostart
services for all possible platforms. You can do it yourself.
>
> 15.12.15 21:15,
Sebastien.Boulianne at cpu.ca<mailto:Sebastien.Boulianne at cpu.ca> ?????:
> > Hi,
>
>
>
>       > I hope all is going perfectly for you.
>
>
>
>       > Im trying to install Squid-3.5.12 from source.
>
>       > I followed the doc to compile it properly.
>
>
>
>       > When I ran squid -z, all is perfect.
>
>
>
>       > [root at squid /]# squid -z
>
>       > [root at squid /]# 2015/12/15 10:06:20 kid1| Set Current
>       Directory to /var/spool/squid
>
>       > 2015/12/15 10:06:20 kid1| Creating missing swap directories
>
>       > 2015/12/15 10:06:20 kid1| /var/spool/squid exists
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/00
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/01
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/02
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/03
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/04
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/05
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/06
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/07
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/08
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/09
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0A
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0B
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0C
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0D
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0E
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0F
>
>
>
>       > But when I try to ? service squid start ?, it fails... There
>       is no squid.service.
>
>
>
>       > [root at squid /]# service squid start
>
>       > Redirecting to /bin/systemctl start  squid.service
>
>       > Failed to start squid.service: Unit squid.service failed to
>       load: No such file or directory.
>
>
>
>       > I searched for a doc how to create this file but I can't find
>       it.
>
>
>
>       > Can you help me please ?
>
>
>
>       > S?bastien Boulianne
>
>       > Administrateur r?seau & syst?me / Network & System
>       Administrator.
>
>       > Gestion des infrastructures / Infrastructure Management.
>
>       > CCNA / CompTIA Server+ / Sp?cialiste en monitoring.
>
>
>      
sebastien.boulianne at cpu.ca<mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca>
>
>
>
>       > [cid:image001.jpg at 01D13720.14E92580]
>
>
>
>
>
>       > 2323, du Versant Nord, suite 100
>
>       > Qu?bec (Qu?bec) G1N 4P4
>
>       > T?l?phone : (418) 681 6974 poste 666
>
>       > Ligne sans frais : 1 888 681 6974
>
>       > T?l?copieur : (418) 681 1444
>
>
>
>       > Information confidentielle : Le pr?sent message, ainsi que
>       tout fichier qui y est joint, est envoy? ? l'intention exclusive
>       de son ou de ses destinataires, il est de nature confidentielle et
>       peut constituer une information privil?gi?e. Nous avertissons
>       toute personne autre que le destinataire pr?vu que tout examen,
>       r?acheminement, impression, copie, distribution ou autre
>       utilisation de ce message et de tout fichier qui y est joint est
>       strictement interdit. Si vous n'?tes pas le destinataire pr?vu,
>       veuillez en aviser imm?diatement l'exp?diteur par retour de
>       courriel et supprimer ce message et tout document joint de votre
>       syst?me. Merci.
>
>
>
>       > Confidentiality Warning : This message and any attachments
>       are intended only for the use of the intended recipient(s), are
>       confidential, and may be privileged. If you are not the intended
>       recipient, you are hereby notified that any review,
>       retransmission, conversion to hard copy, copying, circulation or
>       other use of this message and any attachments is strictly
>       prohibited. If you are not the intended recipient, please notify
>       the sender immediately by return e-mail, and delete this message
>       and any attachments from your system. Thank you.
>
>
>
>       > ? G?rer c'est pr?voir (voir avant, avoir une vision de
>       l'avenir) ?
>
>       > [cid:image002.jpg at 01D13720.14E92580]
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       >
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWcH7uAAoJENNXIZxhPexGDbQH/RTjH2cN53mXTAzKsN/zCHD9
b5NfyQsqYHxctnWG1fpZScNubbUP2kwGMEZOd+7ZpImHpt73QktJ1irAgW4Zv5NW
sgraQaCYPDzw1nWOHtDGnHaTI6UWa3BYNHQ6KklauBPcF3TRTAXf1n90CdTFpY0R
3OjJUgGc1nSQhDUN+tCK42JGL02+JkOTSiaOiF/DIBm/Yzs9JzW6J0F5HWsRn5GH
mg++cFx6zBkRm/Av7mV493P1wQxdo0IywV/x1lpu9DSDz+VdsmQTFhD6BUO0eDvB
NZCNJIcfLkFmCpEhR0UCf8OUepLrClgClzSIMcpnwJaf9OEb27+vJ6mKywDSCJE=
=wvB9
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/106f29e7/attachment.htm>
-------------- next part --------------
#!/bin/sh

# chkconfig: 345 99 01
# description: Service for autostart Squid processes
# processname: init.squid
#
# Control Method for Squid (/lib/svc/method/init.squid)
# using SMF or init SysV (Linux).
# Written by Yuri Voinov (C) 2007,2015
#
# ident "@(#)squid.sh    2.5    15/12/01 YV"
#

#############
# Variables #
#############

# Base Squid installation directory
BASE_DIR="/usr/local/squid"

# Squid files paths
SQUID_PATH="$BASE_DIR""/sbin"
SQUID_CONF_PATH="$BASE_DIR""/etc"

# Squid files
SQUID_BIN_FILE="squid"
SQUID_CONF_FILE="squid.conf"

# Squid effective user name
SQUID_USER="squid"

# Set file descriptors limit. See --with-maxfd/--with-filedescriptors option with squid configuration
MAXFD=131072

# LD_LIBRARY_PATH additional setting. Change if another bdb version is installed. Bdb uses by squidGuard
LD_ADD="/opt/csw/bdb48/lib/amd64:/opt/csw/lib/amd64"

# Linux lock directory
LOCK_DIR="/var/lock/subsys"
# Script name for Linux up/down workaround
SVC_SHORT_NAME="$SQUID_BIN_FILE"
SCRIPT_NAME="init.$SVC_SHORT_NAME"

# Log cache to syslog
# Set to Y, if your need
TO_SYSLOG="N"

#
# OS Commands location variables
#
CAT=`which cat`
CUT=`which cut`
ECHO=`which echo`
GETENT=`which getent`
GREP=`which grep`
NEWTASK=`which newtask`
PS=`which ps`
TOUCH=`which touch`
ULIMIT=`which ulimit`
UNAME=`which uname`

# OS release
OS_VER=`$UNAME -r|$CUT -f2 -d"."`
OS_NAME=`$UNAME -s|$CUT -f1 -d" "`

###############
# Subroutines #
###############

check_squid ()
{
 # Check Squid installed
 program=$1
 if [ ! -f "$SQUID_PATH/$program" -a ! -x "$SQUID_PATH/$program" ]; then
  $ECHO "ERROR: Squid not found!"
  $ECHO "Exiting..."
  exit 1
 fi
}

check_os ()
{
 if [ "$OS_NAME" = "SunOS" -a "$OS_VER" -lt "10" ]; then
  if [ "$OS_NAME" != "Linux" ]; then
   $ECHO "ERROR: Unsupported $OS_NAME version $OS_VER. Exiting..."
   exit 1
  fi
 fi
}

checkuser ()
{
# Check squid user
 username=$1
 if [ ! -z "`$GETENT passwd $username`" ]; then
  $ECHO "1"
 else
  $ECHO "0"
 fi
}

checkconf ()
{
# Check Squid config file
 config=$1
 if [ -f "$SQUID_CONF_PATH"/"$config" ]; then
  $ECHO "1"
 else
  $ECHO "0"
 fi
}

checkrcapd ()
{
# Check if rcapd running
 if [ ! -z "$PS -ef|$GREP -v grep|$GREP rcapd" ]; then
  $ECHO "1"
 else
  $ECHO "0"
 fi
}

startproc()
{
# Start Squid
 program=$1

 # Set additional cache logging to syslog, if specified
 if [ "$TO_SYSLOG" = "Y" ]; then
  sl="s"
 else
  sl=""
 fi

 if [ "`checkconf $SQUID_CONF_FILE`" = "1" ]; then
  if [ "`checkuser $SQUID_USER`" = "1" ]; then
   LD_LIBRARY_PATH=$LD_ADD:$LD_LIBRARY_PATH
   export LD_LIBRARY_PATH
   $ULIMIT -Sn $MAXFD
   if [ ! -z "`$CAT /etc/project | $GREP "$SQUID_USER"`" -a "`checkrcapd`" -eq "1" ]; then
    $NEWTASK -p `$CAT /etc/project | $GREP "squid" | $CUT -f1 -d":"` $SQUID_PATH/$program -Y$sl
   else
   $SQUID_PATH/$program -Y$sl
   fi
  else
   $ECHO "ERROR: User $SQUID_USER not found."
   $ECHO "Exiting..."
   exit 3
  fi
 else
  $ECHO "ERROR: Config file $SQUID_CONF_PATH/$SQUID_CONF_FILE not found."
  $ECHO "Exiting..."
  exit 2
 fi
 if [ "$OS_NAME" = "Linux" ]; then
  # Linux up/down workaround
  $TOUCH "$LOCK_DIR"/"$SCRIPT_NAME"
 fi
}

stopproc()
{
# Stop Squid
 program=$1
 if [ "`checkconf $SQUID_CONF_FILE`" = "1" ]; then
  if [ "`checkuser $SQUID_USER`" = "1" ]; then
   $SQUID_PATH/$program -k shutdown
  else
   $ECHO "ERROR: User $SQUID_USER not found."
   $ECHO "Exiting..."
   exit 3
  fi
 else
  $ECHO "ERROR: Config file $SQUID_CONF_PATH/$SQUID_CONF_FILE not found."
  $ECHO "Exiting..."
  exit 2
 fi
 if [ "$OS_NAME" = "Linux" ]; then
 # Linux up/down workaround
  $RM -f "$LOCK_DIR"/"$SCRIPT_NAME"
 fi
}

refreshproc()
{
# Refresh Squid
 program=$1
 if [ "`checkconf $SQUID_CONF_FILE`" = "1" ]; then
  if [ "`checkuser $SQUID_USER`" = "1" ]; then
   $SQUID_PATH/$program -k reconfigure
  else
   $ECHO "ERROR: User $SQUID_USER not found."
   $ECHO "Exiting..."
   exit 2
  fi
 else
  $ECHO "ERROR: Config file $SQUID_CONF_PATH/$SQUID_CONF_FILE not found."
  $ECHO "Exiting..."
  exit 2
 fi
}

##############
# Main block #
##############

# Check Squid installed
check_squid $SQUID_BIN_FILE

# Check OS version
check_os

case "$1" in
"start")
  startproc $SQUID_BIN_FILE
  ;;
"stop")
  stopproc $SQUID_BIN_FILE
  ;;
"refresh")
  refreshproc $SQUID_BIN_FILE
  ;;
"restart")
  stopproc $SQUID_BIN_FILE
  startproc $SQUID_BIN_FILE
  ;;
*)
  $ECHO "Usage: $0 { start | stop | refresh | restart }"
  exit 1
esac

exit 0
#
-------------- next part --------------
[Unit]
Description=Squid Cache Service
After=syslog.target

[Service]
ExecStart=/usr/lib/systemd/scripts/init.squid start
ExecStop=/usr/lib/systemd/scripts/init.squid stop
Restart=on-abort

[Install]
WantedBy=multi-user.target

From yvoinov at gmail.com  Tue Dec 15 21:06:20 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 16 Dec 2015 03:06:20 +0600
Subject: [squid-users] Installing Squid as a service on Oracle Linux 7.2
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>
 <5670331F.4090207@gmail.com>
 <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>
Message-ID: <567080CC.9020800@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
On the day when I forget how to write scripts - I kill myself :)

16.12.15 2:29, Sebastien.Boulianne at cpu.ca ?????:
> Hi,
>
> Your answer didn?t help me.
> Does it have anyone who create a service file for squid and want to
share it.
> I tried the squid.service from the yum package (v3.3.8) but it didn?t
work.
>
> Thanks
>
> S?bastien
> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De
la part de Yuri Voinov
> Envoy? : 15 d?cembre 2015 10:35
> ? : squid-users at lists.squid-cache.org
> Objet : Re: [squid-users] Installing Squid as a service on Oracle
Linux 7.2
>
>
> Squid's source don't contain automatically installed autostart
services for all possible platforms. You can do it yourself.
>
> 15.12.15 21:15,
Sebastien.Boulianne at cpu.ca<mailto:Sebastien.Boulianne at cpu.ca> ?????:
> > Hi,
>
>
>
>       > I hope all is going perfectly for you.
>
>
>
>       > Im trying to install Squid-3.5.12 from source.
>
>       > I followed the doc to compile it properly.
>
>
>
>       > When I ran squid -z, all is perfect.
>
>
>
>       > [root at squid /]# squid -z
>
>       > [root at squid /]# 2015/12/15 10:06:20 kid1| Set Current
>       Directory to /var/spool/squid
>
>       > 2015/12/15 10:06:20 kid1| Creating missing swap directories
>
>       > 2015/12/15 10:06:20 kid1| /var/spool/squid exists
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/00
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/01
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/02
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/03
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/04
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/05
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/06
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/07
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/08
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/09
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0A
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0B
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0C
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0D
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0E
>
>       > 2015/12/15 10:06:20 kid1| Making directories in
>       /var/spool/squid/0F
>
>
>
>       > But when I try to ? service squid start ?, it fails... There
>       is no squid.service.
>
>
>
>       > [root at squid /]# service squid start
>
>       > Redirecting to /bin/systemctl start  squid.service
>
>       > Failed to start squid.service: Unit squid.service failed to
>       load: No such file or directory.
>
>
>
>       > I searched for a doc how to create this file but I can't find
>       it.
>
>
>
>       > Can you help me please ?
>
>
>
>       > S?bastien Boulianne
>
>       > Administrateur r?seau & syst?me / Network & System
>       Administrator.
>
>       > Gestion des infrastructures / Infrastructure Management.
>
>       > CCNA / CompTIA Server+ / Sp?cialiste en monitoring.
>
>
>      
sebastien.boulianne at cpu.ca<mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca>
>
>
>
>       > [cid:image001.jpg at 01D13720.14E92580]
>
>
>
>
>
>       > 2323, du Versant Nord, suite 100
>
>       > Qu?bec (Qu?bec) G1N 4P4
>
>       > T?l?phone : (418) 681 6974 poste 666
>
>       > Ligne sans frais : 1 888 681 6974
>
>       > T?l?copieur : (418) 681 1444
>
>
>
>       > Information confidentielle : Le pr?sent message, ainsi que
>       tout fichier qui y est joint, est envoy? ? l'intention exclusive
>       de son ou de ses destinataires, il est de nature confidentielle et
>       peut constituer une information privil?gi?e. Nous avertissons
>       toute personne autre que le destinataire pr?vu que tout examen,
>       r?acheminement, impression, copie, distribution ou autre
>       utilisation de ce message et de tout fichier qui y est joint est
>       strictement interdit. Si vous n'?tes pas le destinataire pr?vu,
>       veuillez en aviser imm?diatement l'exp?diteur par retour de
>       courriel et supprimer ce message et tout document joint de votre
>       syst?me. Merci.
>
>
>
>       > Confidentiality Warning : This message and any attachments
>       are intended only for the use of the intended recipient(s), are
>       confidential, and may be privileged. If you are not the intended
>       recipient, you are hereby notified that any review,
>       retransmission, conversion to hard copy, copying, circulation or
>       other use of this message and any attachments is strictly
>       prohibited. If you are not the intended recipient, please notify
>       the sender immediately by return e-mail, and delete this message
>       and any attachments from your system. Thank you.
>
>
>
>       > ? G?rer c'est pr?voir (voir avant, avoir une vision de
>       l'avenir) ?
>
>       > [cid:image002.jpg at 01D13720.14E92580]
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       >
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWcIDLAAoJENNXIZxhPexGtogH/jXR8FX5QivkQ74QkfjBXQop
4e7BdX8mcrgeEzGx7DlIVic0NYWGrFPSK/zlWqZjXub26gRKf1ZYbFLO/2O0rr18
d2OkSKxoET1cSI1+6L/GYKeC+j1DelHQtUVWu23u8zeIjoHy1nrFml06tZsu0FS7
W+3b3mYbLEZwwXDcT3AoQdC7lF3FuI+EfDdkClloxCcVSCZ5kaoy/NMMV3YxVm/N
maSNmKPLUymNGkHlRr8i/1033T+iU122hKhbopCy/Z3A0UKAIlJ6QpEhQpwuScpJ
sx+1bWmAXTIpYHIh/RwkWVI2oFrqF9cQ9N3nXEp2szLF48v623O05WZ4m/GFRCY=
=eI+k
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/92939927/attachment.htm>

From Sebastien.Boulianne at cpu.ca  Tue Dec 15 21:08:24 2015
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Tue, 15 Dec 2015 16:08:24 -0500
Subject: [squid-users] Installing Squid as a service on Oracle Linux 7.2
In-Reply-To: <56707EEE.50003@gmail.com>
References: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>
 <5670331F.4090207@gmail.com>
 <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>
 <56707EEE.50003@gmail.com>
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5829B1264D@CPUMAIL2.cpu.qc.ca>

Hi,

Thanks you very much for your answer.
It tooks me about 1 min to get it too.

I reach the wiki where Eliezer give his repositery.

I just did a yum ?y install squid-3.5.11 and I got the squid.service?

All is perfect now.

Thanks anyways.

S?bastien


De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Yuri Voinov
Envoy? : 15 d?cembre 2015 15:58
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] Installing Squid as a service on Oracle Linux 7.2


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

Ok,

I'll just done your job.

See attachements. I wrote squid.service, it takes approx. 30 seconds.

PS. But note: you must install both files manually yourself. Read manuals anyway.

16.12.15 2:29, Sebastien.Boulianne at cpu.ca<mailto:Sebastien.Boulianne at cpu.ca> ?????:
> Hi,

      >

      > Your answer didn?t help me.

      > Does it have anyone who create a service file for squid and
      want to share it.

      > I tried the squid.service from the yum package (v3.3.8) but
      it didn?t work.

      >

      > Thanks

      >

      > S?bastien

      > De : squid-users
      [mailto:squid-users-bounces at lists.squid-cache.org] De la part de
      Yuri Voinov

      > Envoy? : 15 d?cembre 2015 10:35

      > ? : squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > Objet : Re: [squid-users] Installing Squid as a service on
      Oracle Linux 7.2

      >

      >

      > Squid's source don't contain automatically installed
      autostart services for all possible platforms. You can do it
      yourself.

      >

      > 15.12.15 21:15,
      Sebastien.Boulianne at cpu.ca<mailto:Sebastien.Boulianne at cpu.ca><mailto:Sebastien.Boulianne at cpu.ca><mailto:Sebastien.Boulianne at cpu.ca>
      ?????:

      > > Hi,

      >

      >

      >

      >       > I hope all is going perfectly for you.

      >

      >

      >

      >       > Im trying to install Squid-3.5.12 from source.

      >

      >       > I followed the doc to compile it properly.

      >

      >

      >

      >       > When I ran squid -z, all is perfect.

      >

      >

      >

      >       > [root at squid /]# squid -z

      >

      >       > [root at squid /]# 2015/12/15 10:06:20 kid1| Set
      Current

      >       Directory to /var/spool/squid

      >

      >       > 2015/12/15 10:06:20 kid1| Creating missing swap
      directories

      >

      >       > 2015/12/15 10:06:20 kid1| /var/spool/squid exists

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/00

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/01

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/02

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/03

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/04

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/05

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/06

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/07

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/08

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/09

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/0A

      >

     >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/0B

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/0C

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/0D

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/0E

      >

      >       > 2015/12/15 10:06:20 kid1| Making directories in

      >       /var/spool/squid/0F

      >

      >

      >

      >       > But when I try to ? service squid start ?, it
      fails... There

      >       is no squid.service.

      >

      >

      >

      >       > [root at squid /]# service squid start

      >

      >       > Redirecting to /bin/systemctl start  squid.service

      >

      >       > Failed to start squid.service: Unit squid.service
      failed to

      >       load: No such file or directory.

      >

      >

      >

      >       > I searched for a doc how to create this file but I
      can't find

      >       it.

      >

      >

      >

      >       > Can you help me please ?

      >

      >

      >

      >       > S?bastien Boulianne

      >

      >       > Administrateur r?seau & syst?me / Network
      & System

      >       Administrator.

      >

      >       > Gestion des infrastructures / Infrastructure
      Management.

      >

      >       > CCNA / CompTIA Server+ / Sp?cialiste en
      monitoring.

      >

      >

      >
sebastien.boulianne at cpu.ca<mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca>

      >

      >

      >

      >       > [cid:image001.jpg at 01D13720.14E92580]

      >

      >

      >

      >

      >

      >       > 2323, du Versant Nord, suite 100

      >

      >       > Qu?bec (Qu?bec) G1N 4P4

      >

      >       > T?l?phone : (418) 681 6974 poste 666

      >

      >       > Ligne sans frais : 1 888 681 6974

      >

     >       > T?l?copieur : (418) 681 1444

      >

      >

      >

      >       > Information confidentielle : Le pr?sent message,
      ainsi que

      >       tout fichier qui y est joint, est envoy? ? l'intention
      exclusive

      >       de son ou de ses destinataires, il est de nature
      confidentielle et

      >       peut constituer une information privil?gi?e. Nous
      avertissons

      >       toute personne autre que le destinataire pr?vu que tout
      examen,

      >       r?acheminement, impression, copie, distribution ou
      autre

      >       utilisation de ce message et de tout fichier qui y est
      joint est

      >       strictement interdit. Si vous n'?tes pas le
      destinataire pr?vu,

      >       veuillez en aviser imm?diatement l'exp?diteur par
      retour de

      >       courriel et supprimer ce message et tout document joint
      de votre

      >       syst?me. Merci.

      >

      >

      >

      >       > Confidentiality Warning : This message and any
      attachments

      >       are intended only for the use of the intended
      recipient(s), are

      >       confidential, and may be privileged. If you are not the
      intended

      >       recipient, you are hereby notified that any review,

      >       retransmission, conversion to hard copy, copying,
      circulation or

      >       other use of this message and any attachments is
      strictly

      >       prohibited. If you are not the intended recipient,
      please notify

      >       the sender immediately by return e-mail, and delete
      this message

      >       and any attachments from your system. Thank you.

      >

      >

      >

      >       > ? G?rer c'est pr?voir (voir avant, avoir une
      vision de

      >       l'avenir) ?

      >

      >       > [cid:image002.jpg at 01D13720.14E92580]

      >

      >

      >

      >

      >

      >

      >

      >

      >

      >       > _______________________________________________

      >

      >       > squid-users mailing list

      >

      >       >
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org>

      >

      >       > http://lists.squid-cache.org/listinfo/squid-users

      >

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJWcH7uAAoJENNXIZxhPexGDbQH/RTjH2cN53mXTAzKsN/zCHD9
b5NfyQsqYHxctnWG1fpZScNubbUP2kwGMEZOd+7ZpImHpt73QktJ1irAgW4Zv5NW
sgraQaCYPDzw1nWOHtDGnHaTI6UWa3BYNHQ6KklauBPcF3TRTAXf1n90CdTFpY0R
3OjJUgGc1nSQhDUN+tCK42JGL02+JkOTSiaOiF/DIBm/Yzs9JzW6J0F5HWsRn5GH
mg++cFx6zBkRm/Av7mV493P1wQxdo0IywV/x1lpu9DSDz+VdsmQTFhD6BUO0eDvB
NZCNJIcfLkFmCpEhR0UCf8OUepLrClgClzSIMcpnwJaf9OEb27+vJ6mKywDSCJE=
=wvB9
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151215/013c0eb9/attachment.htm>

From avhernandez at uci.cu  Tue Dec 15 20:14:21 2015
From: avhernandez at uci.cu (=?UTF-8?Q?Amaury_Viera_Hern=c3=a1ndez?=)
Date: Tue, 15 Dec 2015 15:14:21 -0500
Subject: [squid-users] Authenticate against the squid of my organization
Message-ID: <5670749D.3050907@uci.cu>

Hello everyone:

This is my main doubt:
I'm using an authenticated proxy (squid) in my university but i do not 
have access to change any configuration in that proxy.

I need to install squid in my local machine and specify in some place 
that this squid will use my user and password of the squid of my 
university (Please, note that I can't make configurations in the main proxy)

Regards. Amaury


From yvoinov at gmail.com  Tue Dec 15 21:38:13 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 16 Dec 2015 03:38:13 +0600
Subject: [squid-users] Installing Squid as a service on Oracle Linux 7.2
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5829B1264D@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5829B12638@CPUMAIL2.cpu.qc.ca>
 <5670331F.4090207@gmail.com>
 <5FE0959288C73D448BB44CB7E9CC320F5829B1264C@CPUMAIL2.cpu.qc.ca>
 <56707EEE.50003@gmail.com>
 <5FE0959288C73D448BB44CB7E9CC320F5829B1264D@CPUMAIL2.cpu.qc.ca>
Message-ID: <56708845.4080804@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You are welcome ;)

16.12.15 3:08, Sebastien.Boulianne at cpu.ca ?????:
> Hi,
>
> Thanks you very much for your answer.
> It tooks me about 1 min to get it too.
>
> I reach the wiki where Eliezer give his repositery.
>
> I just did a yum ?y install squid-3.5.11 and I got the squid.service?
>
> All is perfect now.
>
> Thanks anyways.
>
> S?bastien
>
>
> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De
la part de Yuri Voinov
> Envoy? : 15 d?cembre 2015 15:58
> ? : squid-users at lists.squid-cache.org
> Objet : Re: [squid-users] Installing Squid as a service on Oracle
Linux 7.2
>
>
> Ok,
>
> I'll just done your job.
>
> See attachements. I wrote squid.service, it takes approx. 30 seconds.
>
> PS. But note: you must install both files manually yourself. Read
manuals anyway.
>
> 16.12.15 2:29,
Sebastien.Boulianne at cpu.ca<mailto:Sebastien.Boulianne at cpu.ca> ?????:
> > Hi,
>
>
>
>       > Your answer didn?t help me.
>
>       > Does it have anyone who create a service file for squid and
>       want to share it.
>
>       > I tried the squid.service from the yum package (v3.3.8) but
>       it didn?t work.
>
>
>
>       > Thanks
>
>
>
>       > S?bastien
>
>       > De : squid-users
>       [mailto:squid-users-bounces at lists.squid-cache.org] De la part de
>       Yuri Voinov
>
>       > Envoy? : 15 d?cembre 2015 10:35
>
>       > ? :
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
>
>       > Objet : Re: [squid-users] Installing Squid as a service on
>       Oracle Linux 7.2
>
>
>
>
>
>       > Squid's source don't contain automatically installed
>       autostart services for all possible platforms. You can do it
>       yourself.
>
>
>
>       > 15.12.15 21:15,
>      
Sebastien.Boulianne at cpu.ca<mailto:Sebastien.Boulianne at cpu.ca><mailto:Sebastien.Boulianne at cpu.ca><mailto:Sebastien.Boulianne at cpu.ca>
>       ?????:
>
>       > > Hi,
>
>
>
>
>
>
>
>       >       > I hope all is going perfectly for you.
>
>
>
>
>
>
>
>       >       > Im trying to install Squid-3.5.12 from source.
>
>
>
>       >       > I followed the doc to compile it properly.
>
>
>
>
>
>
>
>       >       > When I ran squid -z, all is perfect.
>
>
>
>
>
>
>
>       >       > [root at squid /]# squid -z
>
>
>
>       >       > [root at squid /]# 2015/12/15 10:06:20 kid1| Set
>       Current
>
>       >       Directory to /var/spool/squid
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Creating missing swap
>       directories
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| /var/spool/squid exists
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/00
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/01
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/02
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/03
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/04
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/05
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/06
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/07
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/08
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/09
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/0A
>
>
>
>      >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/0B
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/0C
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/0D
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/0E
>
>
>
>       >       > 2015/12/15 10:06:20 kid1| Making directories in
>
>       >       /var/spool/squid/0F
>
>
>
>
>
>
>
>       >       > But when I try to ? service squid start ?, it
>       fails... There
>
>       >       is no squid.service.
>
>
>
>
>
>
>
>       >       > [root at squid /]# service squid start
>
>
>
>       >       > Redirecting to /bin/systemctl start  squid.service
>
>
>
>       >       > Failed to start squid.service: Unit squid.service
>       failed to
>
>       >       load: No such file or directory.
>
>
>
>
>
>
>
>       >       > I searched for a doc how to create this file but I
>       can't find
>
>       >       it.
>
>
>
>
>
>
>
>       >       > Can you help me please ?
>
>
>
>
>
>
>
>       >       > S?bastien Boulianne
>
>
>
>       >       > Administrateur r?seau & syst?me / Network
>       & System
>
>       >       Administrator.
>
>
>
>       >       > Gestion des infrastructures / Infrastructure
>       Management.
>
>
>
>       >       > CCNA / CompTIA Server+ / Sp?cialiste en
>       monitoring.
>
>
>
>
>
>
>
sebastien.boulianne at cpu.ca<mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca><mailto:sebastien.boulianne at cpu.ca>
>
>
>
>
>
>
>
>       >       > [cid:image001.jpg at 01D13720.14E92580]
>
>
>
>
>
>
>
>
>
>
>
>       >       > 2323, du Versant Nord, suite 100
>
>
>
>       >       > Qu?bec (Qu?bec) G1N 4P4
>
>
>
>       >       > T?l?phone : (418) 681 6974 poste 666
>
>
>
>       >       > Ligne sans frais : 1 888 681 6974
>
>
>
>      >       > T?l?copieur : (418) 681 1444
>
>
>
>
>
>
>
>       >       > Information confidentielle : Le pr?sent message,
>       ainsi que
>
>       >       tout fichier qui y est joint, est envoy? ? l'intention
>       exclusive
>
>       >       de son ou de ses destinataires, il est de nature
>       confidentielle et
>
>       >       peut constituer une information privil?gi?e. Nous
>       avertissons
>
>       >       toute personne autre que le destinataire pr?vu que tout
>       examen,
>
>       >       r?acheminement, impression, copie, distribution ou
>       autre
>
>       >       utilisation de ce message et de tout fichier qui y est
>       joint est
>
>       >       strictement interdit. Si vous n'?tes pas le
>       destinataire pr?vu,
>
>       >       veuillez en aviser imm?diatement l'exp?diteur par
>       retour de
>
>       >       courriel et supprimer ce message et tout document joint
>       de votre
>
>       >       syst?me. Merci.
>
>
>
>
>
>
>
>       >       > Confidentiality Warning : This message and any
>       attachments
>
>       >       are intended only for the use of the intended
>       recipient(s), are
>
>       >       confidential, and may be privileged. If you are not the
>       intended
>
>       >       recipient, you are hereby notified that any review,
>
>       >       retransmission, conversion to hard copy, copying,
>       circulation or
>
>       >       other use of this message and any attachments is
>       strictly
>
>       >       prohibited. If you are not the intended recipient,
>       please notify
>
>       >       the sender immediately by return e-mail, and delete
>       this message
>
>       >       and any attachments from your system. Thank you.
>
>
>
>
>
>
>
>       >       > ? G?rer c'est pr?voir (voir avant, avoir une
>       vision de
>
>       >       l'avenir) ?
>
>
>
>       >       > [cid:image002.jpg at 01D13720.14E92580]
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       >
>
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       >
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWcIhEAAoJENNXIZxhPexGrdMIAJsRaszhRYRS/sIzDq6lcPx3
pZupGA1WtRQVvQOFjSxrI6RmTn0d9ZuLFZsjkUM/hzmMhnuNYCkhdLI2Hl9bCnUq
aETe+de6PBHheWlIoRH+21J3FUneXI94ihpu5wVebpVFfvhRrobyJUOXf6kiitPo
+In86wzt4X9xBJcvYleieDIsQrVOzBjUj5FmDaK4mFbQ29nHKnsc7NuA+Etp5B7V
gaQJDfC9w5nx9Gw5G3i/DuSR3cA5P1i/mb58f86jRx/V/g/0Pj+hEr2iMD/MnLT0
/SEqjPfsuQ/67Qv9xKDlAkEJh2VwTPIoKoBIWW+oRqJo3NRYpPwL22Y46WMnwSk=
=4WoK
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/a4b92425/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec 15 21:40:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 10:40:38 +1300
Subject: [squid-users] Not work HELP change cache dir
In-Reply-To: <COL131-W7165EADE844BC9CC50F18CB0EE0@phx.gbl>
References: <COL131-W200BF62374E6393CCC8194B0E90@phx.gbl>
 <5669E2E0.6040405@gmail.com> <COL131-W633C280854D4FDA65685BCB0E90@phx.gbl>
 <COL131-W56159B00FFCCFFB2BC8F99B0EA0@phx.gbl>
 <COL131-W3061BB144436CFF64C7941B0EB0@phx.gbl>
 <CAFPNf5-S_w-C=3F-EdYXH6tNCYYOMFqb5UTB23SNvzOrbOj9TA@mail.gmail.com>
 <1E65640A-DDA2-41F1-B55E-93E6DC57A702@yahoo.com>
 <COL131-W7165EADE844BC9CC50F18CB0EE0@phx.gbl>
Message-ID: <567088D6.70906@treenet.co.nz>

On 16/12/2015 9:35 a.m., juancho Alfonso wrote:
> s.o. centos 7squid version 3.3
> in the squid.conf file
> cache_dir aufs /var/spool/squid 20480 16 256 
> cache_effective_user squid
> cache_effective_group squidthis way works
> cache_dir aufs /var/spool/squid2 20480 16 256 cache_effective_user squid
> cache_effective_group squidorcache_dir aufs PATHEXTERNALDRIVE/squid2 20480 16 256 cache_effective_user squidcache_effective_group squidthis way doesnt
> i need change dir to a external drive with more capacity2 TB
> the local disk is small 70 GB
> i have tried
> chmod 777 -R /var/spool/squid2chown -R squid.squid  /var/spool/squid2orchown -R root.root      /var/spool/squid2orchown -R squid.squid  /var/spool/squid2ororchown -R proxy.conexion  /var/spool/squid2
> 
> nothing works
> 

If the 777 permission does not work (like you said it dont) then it is
*definitely* something right down in the kernel or driver levels, not a
Squid or chown/chmod problem.

You seem to be still focussing on chown/chmod alone (filesystem level)
and not taking SELinux permissions (kernel level) into account - despite
having been told to check them several times already.


Do this:

* erase cache_effective_group from your squid.conf

* comment out the cache_dir /var/spool/squid2 lines in your squid.conf

* run the command line and fix any ERROR or FATAL that come up:

  squid -k parse


* run command line (dont worry if it fails or says already a member):

  adduser squid squid


* run the command lines:

 chmod -R 777 /var/spool/squid2
 rm -rf /var/spool/squid2/*
 chmod 755 /var/spool/squid2
 chown squid:squid /var/spool/squid2
 test -x /sbin/restorecon && restorecon -R /var/spool/squid2


* un-comment the cache_dir /var/spool/squid2 line in squid.conf

* run these command lines:

 squid -z
 test -x /sbin/restorecon && restorecon -R /var/spool/squid2
 squid -k check


Amos



From squid3 at treenet.co.nz  Tue Dec 15 21:57:44 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 10:57:44 +1300
Subject: [squid-users] cant bump ssl
In-Reply-To: <56707567.7080905@measurement-factory.com>
References: <1450208816089-4675201.post@n4.nabble.com>
 <56707567.7080905@measurement-factory.com>
Message-ID: <56708CD8.5010103@treenet.co.nz>

On 16/12/2015 9:17 a.m., Alex Rousskov wrote:
> On 12/15/2015 12:46 PM, HackXBack wrote:
>> why i cant bump ssl conection with android 
>> my squid conf is
> 
>> ssl_bump bump ssl_step2 SNIGroup5
>> ssl_bump splice all
> 
> 
> In modern Squids, your configuration above is equivalent to:
> 
>   ssl_bump splice all
> 
> because, during the very first SslBump processing step (step1), your
> bump rule never matches while your splice rule always does. Once the
> final rule (bump, splice, or terminate) matches, Squid performs the
> matched action and stops further SslBump rules processing.

Um, I dont think so. There is a "peek step1" hiding a few lines above that.

So it should be peek at step 1, bump or splice at step 2.


HackXBack:
 you mention TAG_NONE. That means bump did start happening. Splice or
nothing at all would be TCP_TUNNEL in the log.

This is sounding just like the Solaris timeout issues Yuri was having
before we fixed /dev/poll in 3.5.11. We continue to find and fix issues
with bumping though, so 3.5.12 is needed.

Amos



From squid3 at treenet.co.nz  Tue Dec 15 21:58:56 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 10:58:56 +1300
Subject: [squid-users] Authenticate against the squid of my organization
In-Reply-To: <5670749D.3050907@uci.cu>
References: <5670749D.3050907@uci.cu>
Message-ID: <56708D20.1010105@treenet.co.nz>

On 16/12/2015 9:14 a.m., Amaury Viera Hern?ndez wrote:
> Hello everyone:
> 
> This is my main doubt:
> I'm using an authenticated proxy (squid) in my university but i do not
> have access to change any configuration in that proxy.
> 
> I need to install squid in my local machine and specify in some place
> that this squid will use my user and password of the squid of my
> university (Please, note that I can't make configurations in the main
> proxy)

Squid can authenticate against another proxy using Basic or
Negotiate/Kerberos authentication.

Or it can be configured to do *nothing* with authentication and
transparently pass Proxy-Auth details headers between the upstream proxy
and the client software.

See the cache_peer login= parameter:
 <http://www.squid-cache.org/Doc/config/cache_peer/>


Amos



From rousskov at measurement-factory.com  Tue Dec 15 22:16:25 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 15 Dec 2015 15:16:25 -0700
Subject: [squid-users] cant bump ssl
In-Reply-To: <56708CD8.5010103@treenet.co.nz>
References: <1450208816089-4675201.post@n4.nabble.com>
 <56707567.7080905@measurement-factory.com> <56708CD8.5010103@treenet.co.nz>
Message-ID: <56709139.4010501@measurement-factory.com>

On 12/15/2015 02:57 PM, Amos Jeffries wrote:
> On 16/12/2015 9:17 a.m., Alex Rousskov wrote:
>> On 12/15/2015 12:46 PM, HackXBack wrote:
>>> why i cant bump ssl conection with android 
>>> my squid conf is
>>
>>> ssl_bump bump ssl_step2 SNIGroup5
>>> ssl_bump splice all
>>
>>
>> In modern Squids, your configuration above is equivalent to:
>>
>>   ssl_bump splice all
>>
>> because, during the very first SslBump processing step (step1), your
>> bump rule never matches while your splice rule always does. Once the
>> final rule (bump, splice, or terminate) matches, Squid performs the
>> matched action and stops further SslBump rules processing.
> 
> Um, I dont think so. There is a "peek step1" hiding a few lines above that.

Sorry I missed that hiding place.

Alex.



From squid3 at treenet.co.nz  Tue Dec 15 22:22:04 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 11:22:04 +1300
Subject: [squid-users] Time for cache synchronization between siblings
In-Reply-To: <CALgKBSnCywpET++mS_UdgYpGpEgJ7Wx4D40Mwg2=yiXRtN-h7g@mail.gmail.com>
References: <CALgKBSnCywpET++mS_UdgYpGpEgJ7Wx4D40Mwg2=yiXRtN-h7g@mail.gmail.com>
Message-ID: <5670928C.8050805@treenet.co.nz>

On 16/12/2015 7:16 a.m., Sreenath BH wrote:
> Hi,
> 
> I have a setup with three squid peers (siblings in squid.conf) and
> three upstream servers(peers with parent and originserver in
> squid.conf).
> 
> I am using htcp for the three squid siblings.
> How much time does it take for one squid server to 'know' that another
> peer has a particular object cached? I see digests exchanged between
> the siblings, as logged in cache.log.

When both HTCP an dDgests are active between siblings the maximum time
is however long it takes for the HTCP packet to reach the sibling, be
parsed, looked up in the cache and response to get back.

Digests are used to short-circuit the ICP or HTCP process. If the digest
contains an entry for the URL the peer will be selected as a possible
destination server. Regardless of whether the object stored for that URL
is the same one the client is fetching.

Digests are updated every digest_rebuild_period (default 1 hr). You can
disable digests with either "digest_generation off" or per-peer with the
cache_peer no-digest option.


> 
> I have been able to make a request to one sibling and it resulted in a
> sibling_hit.
> 
> How I do this test is this:
> 1. bring up all siblings
> 2. issue a request to one server (sibling 1)
> 3. Make sure it is cached in sibling 1
> 4. Wait for some time (I don't know how long to wait)

Until the log of sibling1 contains a digest fetch from sibling2. A
restart of sibling2 will make that happen faster.

> 5. Make same request to another sibling, say sibling 2
> 6. Check if it went to upstream server for the request or it was a sibling hit.
> 
> My problem is that the sibling hits seem to be random. I am  not able
> to figure out exactly
> how log it takes for the cache information to propagate to all siblings.

Digest is a old algorithm designed as an optimization of ICP, and
likewise is based on URL alone - which is great for HTTP/1.0 traffic. In
modern HTTP/1.1 traffic the Vary headers have a big part to play and
HTCP with full-header lookups works much better.

I suggest trying with only HTCP (digests disabled) and see if your
performance improves at all. YMMV though.

Be aware that there is no guarantee that any object is still in cache,
even with the more reliable HTCP on-demand lookups. Any object could be
dropped from sibling1 cache picoseconds after the "i have it" reply
started being formed for delivery to sibling2 (before it even hits the
wire on its way back).

Amos



From squid3 at treenet.co.nz  Tue Dec 15 22:40:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 11:40:38 +1300
Subject: [squid-users] cant bump ssl
In-Reply-To: <1450208816089-4675201.post@n4.nabble.com>
References: <1450208816089-4675201.post@n4.nabble.com>
Message-ID: <567096E6.70604@treenet.co.nz>

Another possibility that has not been mentioned yet is that the
sslproxy_* settings might be resulting in some form of server TLS error
that causes the connection(s) to get stuck.

On 16/12/2015 8:46 a.m., HackXBack wrote:
> 
> sslproxy_version 0

"0" is an invalid setting for this directive.

> sslproxy_options ALL

... tells Squid to actively use SSLv2 on the outbound server connection
(because SSLv2-compatibility isone of 'all' the options enabled). With a
whole lot of other hacks and features of SSL and TLS enabled - which
make this proxy wide open to hijacking attacks ... POODLE, FREAK, all
those types of thing.

Any reasonably secure server would reject those connections on sight.
The paranoid ones might even just DROP the packets rather than closing
properly - which would result in what you describe without any further
actions.


Note that the connection to the client remains secure with the default
library security minimums in place. So as far as the client can tell the
end-to-end security is supposed to be MUCH higher (if only it was),
green padlock, etc, etc. Whole bunch of lies now.


> sslproxy_cert_error allow all

After those vulnerabilities have been opened, this forces Squid to
silently accept *any* type of errors that happen with the certificate
exchange. Preventing Squid from reporting security attacks or other
issues to either you or the client.


So you have configured there is a proxy which openly permits the server
or a middleware attacker between it and the server to do whatever they
like. Silently and invisibly. Might as well be sending everything in
plain-text over the open Internet.

You are kind of lucky it dont work.

Amos



From avhernandez at uci.cu  Wed Dec 16 00:03:12 2015
From: avhernandez at uci.cu (Amaury Viera =?utf-8?Q?Hern=C3=A1ndez?=)
Date: Tue, 15 Dec 2015 19:03:12 -0500 (CST)
Subject: [squid-users] Squid: forward to another squid server with
	authentication
In-Reply-To: <1881580871.10256427.1450222026134.JavaMail.zimbra@uci.cu>
Message-ID: <356170619.10258770.1450224192856.JavaMail.zimbra@uci.cu>

Hello everyone. This is a more detailed explanation about my trouble:

I have two network cards:

a shared Wifi card(wlp2s0) : 10.42.0.1
a Network card with access to my LAN(enp4s0): 10.8.77.1

In short, I am looking for a simple way to do the following (please give code samples if possible):

Set up and start a transparent proxy server on my computer (wifi card, say that squid will listen at 10.42.0.1:3128) that can capture all web requests from my phone, once the http request from phone comes to this proxy, it will forward it to the university proxy (say address is 10.0.0.1:8080 with user and password authentication)

Note: Is posible that one of the authentication methods of my proxy server will be ntlm

Now, more details to fully explain my situation:

In my university, authentication is needed to pass through a proxy so that we can connect to the internet. I normally enter my active directory username/password to authenticate when the pop up appears in the web browser

Now, I want to connect my phone to my hared wifi(10.42.0.1) and using the network card with access to the lan(10.8.77.1), forward de http request of my phone to the proxy server in the university( 10.0.0.1:8080 with user and password authentication) because some application of my phone require a direct connection, without proxy and without proxy authentication. So, I am planning to set up a transparent proxy on my laptop to catch all requests from my phone. Of course, I don't need to use the proxy for local domains (uci.cu in this case)

I'm using ubuntu 15.10 with squid3 (3.3.8)

I have this configuration in squid.conf (This is very functional for local domain(without proxy authentications, against the local domains, for example: intranet.uci.cu, but for internet domains I need to authenticate(cache_peer my proxy with the proxy of my university)) )

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
acl localdst dstdomain
acl mi_red src 10.42.0.0/24
http_access allow mi_red
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_access deny all
http_port 10.42.0.1:3128 transparent
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
refresh_pattern .               0       20%     4320
cache_mem 512 MB
cache_dir ufs /var/spool/squid3 2048 16 256
cache_effective_user proxy
cache_effective_group proxy
half_closed_clients off
maximum_object_size 1024 KB
cache_swap_low 90
cache_swap_high 95
memory_pools off
error_directory /usr/share/squid3/errors/es/
access_log /var/log/squid3/access.log squid
cache_peer 10.0.0.1 parent 8080 0 no-query default no-digest login=avhernandez:MyPass
never_direct allow all


I'm using this firewall script

#!/bin/sh
# IP del servidor SQUID
SQUID_SERVER="10.42.0.1"
# Interface conectada a Internet
INTERNET="enp4s0"
# Interface interna
LAN_IN="wlp2s0"
# Puerto Squid
SQUID_PORT="3128"

# Limpia las reglas anteriores
iptables -F
iptables -X
iptables -t nat -F
iptables -t nat -X
iptables -t mangle -F
iptables -t mangle -X
# Carga los modulos IPTABLES para NAT e IP con soporte conntrack
modprobe ip_conntrack
modprobe ip_conntrack_ftp
echo 1 > /proc/sys/net/ipv4/ip_forward
# Politica de filtro por defecto
iptables -P INPUT DROP
iptables -P OUTPUT ACCEPT
# Acceso ilimitado a loop back
iptables -A INPUT -i lo -j ACCEPT
iptables -A OUTPUT -o lo -j ACCEPT
# Permite UDP, DNS y FTP pasivo
iptables -A INPUT -i $INTERNET -m state --state ESTABLISHED,RELATED -j ACCEPT
# Establece el servidor como router para la red
iptables --table nat --append POSTROUTING --out-interface $INTERNET -j MASQUERADE
iptables --append FORWARD --in-interface $LAN_IN -j ACCEPT
# acceso ilimiato a la LAN
iptables -A INPUT -i $LAN_IN -j ACCEPT
iptables -A OUTPUT -o $LAN_IN -j ACCEPT
# Redirige las peticiones de la red interna hacia el proxy
iptables -t nat -A PREROUTING -i $LAN_IN -p tcp --dport 80 -j DNAT --to $SQUID_SERVER:$SQUID_PORT
# Redirige la entrada al proxy
iptables -t nat -A PREROUTING -i $INTERNET -p tcp --dport 80 -j REDIRECT --to-port $SQUID_PORT

Best regards. Amaury.


From squid3 at treenet.co.nz  Wed Dec 16 02:49:55 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 15:49:55 +1300
Subject: [squid-users] Squid: forward to another squid server with
 authentication
In-Reply-To: <356170619.10258770.1450224192856.JavaMail.zimbra@uci.cu>
References: <356170619.10258770.1450224192856.JavaMail.zimbra@uci.cu>
Message-ID: <5670D153.501@treenet.co.nz>

On 16/12/2015 1:03 p.m., Amaury Viera Hern?ndez wrote:
> Hello everyone. This is a more detailed explanation about my
> trouble:
> 

The more detailed explanation makes it clear that you are not going to
be able to use the login=PASSTHRU workaround for getting NTLM to work.
Clients that are intercepted simply *cannot* authenticate to a proxy. So
there is nothing to pass through.

That leaves you with Negotiate or Basic authentication credentials
explicitly added by your proxy.


Be aware that doing what you intend will make you and your student
account personaly responsible for *all* traffic that goes through your
proxy to the upstream. If anyone else manages to hook into your wifi AP,
they will essentially have free access and you pay the costs.


<snip>
> 
> I'm using ubuntu 15.10 with squid3 (3.3.8)
> 
> I have this configuration in squid.conf (This is very functional for
> local domain(without proxy authentications, against the local
> domains, for example: intranet.uci.cu, but for internet domains I
> need to authenticate(cache_peer my proxy with the proxy of my
> university)) )
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> acl localdst dstdomain
> acl mi_red src 10.42.0.0/24
> http_access allow mi_red

So anyone connecting from 10.42.0.0/24 is allowed through this proxy.
With absolutely zero protections. That is bad.

At the very least move the "allow mi_red" line down ...

> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager

... to here.

> http_access allow localhost
> http_access deny all
> http_port 10.42.0.1:3128 transparent

3128 is the registered Squid port for foward/explicit-proxy
communications. It should remain in squid.conf but without the
"transparent" mode flag.

You should probably also set this port to be "127.0.0.1:3128" for yoru
situation.

You should pick another port number randomly for the intercept and use
that for "intercept" mode traffic. There are also additional parts to
the firewall script, which I will cover below.

Also, notice that NAT port is "intercept" not "transparent".

Please run "squid -k parse" and fix any warnings it produces about other
things. I'm only mentioing the big ones which that old version  might
not be able to mention.

> coredump_dir /var/spool/squid3
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
> refresh_pattern .               0       20%     4320
> cache_mem 512 MB
> cache_dir ufs /var/spool/squid3 2048 16 256
> cache_effective_user proxy
> cache_effective_group proxy
> half_closed_clients off
> maximum_object_size 1024 KB
> cache_swap_low 90
> cache_swap_high 95
> memory_pools off
> error_directory /usr/share/squid3/errors/es/
> access_log /var/log/squid3/access.log squid

This ...

> cache_peer 10.0.0.1 parent 8080 0 no-query default no-digest login=avhernandez:MyPass
> never_direct allow all

... is correct for sending Basic auth credentials to the upstream. That
may work, but is not very secure.

Your Squid should also be capable of the login=NEGOTIATE method of
authentication. If that works with the upstream proxy (it may or may
not) then it is better to use than Basic.

First do the firewall fixes below before experimenting with these
changes though.


> 
> I'm using this firewall script
> 

Best practice is to use the iptables-restore tool when scripting
firewall actions. Otherwise there are gaps in timing between the -F
flush command and rule setup during which any active traffic can slip
past your intended rules and have long-lasting effects on the connection
states.
IIRC it was setup the firewall manually with your rules, and use the
restore tool to save a config snapshot for fast loading by the script.


> #!/bin/sh
> # IP del servidor SQUID
> SQUID_SERVER="10.42.0.1"
> # Interface conectada a Internet
> INTERNET="enp4s0"
> # Interface interna
> LAN_IN="wlp2s0"
> # Puerto Squid
> SQUID_PORT="3128"

Change that to whatever you use in squid.conf for the intercept port.

> 
> # Limpia las reglas anteriores
> iptables -F
> iptables -X
> iptables -t nat -F
> iptables -t nat -X
> iptables -t mangle -F
> iptables -t mangle -X
> # Carga los modulos IPTABLES para NAT e IP con soporte conntrack
> modprobe ip_conntrack
> modprobe ip_conntrack_ftp
> echo 1 > /proc/sys/net/ipv4/ip_forward
> # Politica de filtro por defecto
> iptables -P INPUT DROP
> iptables -P OUTPUT ACCEPT
> # Acceso ilimitado a loop back
> iptables -A INPUT -i lo -j ACCEPT
> iptables -A OUTPUT -o lo -j ACCEPT

ICMP is a mandatory protocol, and needs to be allowed as well.
- When bad traffic is rejected by your machine it is ICMP packets that
do the rejection.
- When something is not quite working right it is ICMP error messages
which allow software like Squid to automatically repair or workaround
the damage. And to help you debug what is going on if manual attention
is needed.


> # Permite UDP, DNS y FTP pasivo
> iptables -A INPUT -i $INTERNET -m state --state ESTABLISHED,RELATED -j ACCEPT

The comment about "UDP, DNS y FTP pasivo" is does not match the rule it
is documenting.

The rule is allowing aready established connections from remote /
Internet clients to the servers running on your machine to fast-track
through the firewall.

That is normal and okay as a rule. The issue I am highlighting here is
that the comment is bad and may be making you think wrong.

You also need this rule to apply to all traffic, on all interfaces
(including "lo"). So remove the -i parameter.


This...

> # Establece el servidor como router para la red
> iptables --table nat --append POSTROUTING --out-interface $INTERNET -j MASQUERADE
> iptables --append FORWARD --in-interface $LAN_IN -j ACCEPT

... No. Remove.

There is a better MASQUERADE rule in the wiki page referenced below.

If you need to allow any traffic forwarding straight through your
machine. Do so only and specifically for individual ports or protocols.
You are not running a carrier network here.

For example; this is where you set DNS queries to be allowed:
 -t FORWARD -p udp --dport 53 -j ACCEPT
 -t FORWARD -p tcp --dport 53 -j ACCEPT

Given the phone involvement you may also want to look into whether it
wants VoIP ports. And email POP/IMAP/SMTP/Submit ports may also be
needed - be extra careful about random hijackers sending Spam on those
ones though.


> # acceso ilimiato a la LAN
> iptables -A INPUT -i $LAN_IN -j ACCEPT

That above one lets unconditionally all remote devices that can connect
to your wifi interface use any service on your machine. Which is bad.
Especially since you also unconditionally allow access through the proxy
in squid.conf.

If you need any rules on INPUT at all, you should make them specific to
the services you want to be available publicly. But remember that these
rules are for accessing services running directly on your machine - not
relevant when connecting to upstream or Internet servers.


Both INPUT and FORWARD are the main firewall protections against traffic
being sent into your machines software, or trying to forward through it
to other machines. Be very careful what you ACCEPT in those table rules.


> iptables -A OUTPUT -o $LAN_IN -j ACCEPT

This...

> # Redirige las peticiones de la red interna hacia el proxy
> iptables -t nat -A PREROUTING -i $LAN_IN -p tcp --dport 80 -j DNAT --to $SQUID_SERVER:$SQUID_PORT
> # Redirige la entrada al proxy
> iptables -t nat -A PREROUTING -i $INTERNET -p tcp --dport 80 -j REDIRECT --to-port $SQUID_PORT

... No. Remove.

For Squid use the rules on this wiki page (in the same order as shown),
instead of both sets above which I marked as "No. Remove".

<http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxDnat>


PS. Also dont forget that IPv6 exists. Your firewall settings *need* to
also correctly setup IPv6 access (or denial) with ip6tables. Since you
are working with a phone it is even more likely that IPv6 will be needed
than on a generic LAN / wifi.
 They should generally match your IPv4 settings. But there are some
small differences.

HTH
Amos



From squid3 at treenet.co.nz  Wed Dec 16 03:08:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 16:08:28 +1300
Subject: [squid-users] squid 3.5.12 and ecap
In-Reply-To: <1482652592.1446755.1450180435187.JavaMail.yahoo@mail.yahoo.com>
References: <1482652592.1446755.1450180435187.JavaMail.yahoo.ref@mail.yahoo.com>
 <1482652592.1446755.1450180435187.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <5670D5AC.9010404@treenet.co.nz>

On 16/12/2015 12:53 a.m., behrad eslami wrote:
> Hi I add simple rule to ecap module and deny some url. I forground
> (squid -N -d10) all things work well. when i run service wtih mutiple
> workers, after a while some url not filter and user can open them in
> browsers. I compile Squid 3.5.12 and libecpa 1.0.0. squid compiled
> with below options:
> '--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=${prefix}/lib/squid3' '--srcdir=.' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--datadir=/usr/share/squid3' '--sysconfdir=/etc/squid3' '--mandir=/usr/share/man' '--enable-inline' '--disable-arch-native' '--enable-async-io=8' '--enable-storeio=aufs,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-follow-x-forwarded-for' '--enable-eui' '--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-auto-locale' '--disable-translation' '--with-swapdir=/var/spool/squid3' '--with-logdir=/var/log/squid3' '--with-pidfile=/var/run/squid3.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-build-info= linux' '--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu
' 'CFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security' '--disable-ipv6' '--disable-wccp' '--disable-auth-basic' '--disable-auth-digest' '--disable-auth-negotiate' '--disable-auth-ntlm' '--disable-external-acl-helpers' '--disable-url-rewrite-helpers' '--disable-storeid-rewrite-helpers' '--without-mit-krb5' '--without-heimdal-krb5' '--without-gnugss' '--disable-unlinkd' '--disable-ident-lookups' '--disable-esi' '--disable-select' '--disable-poll' '--disable-kqueue' '--disable-devpoll' '--enable-epoll'
> 

This looks like Debian based build settings. With a bunch of extra
things disabled. What OS is this being used on?

NP: you can use --disable-auth to do all of the --disable-auth-*
settings in one simpler option.


> and my ecap config is:
> icap_enable on
> icap_send_client_ip on
> icap_client_username_encode on

None of that is eCAP configuration. The 'i' (not 'e') at the start of
the directive names should give it away.

This is the eCAP part:

> loadable_modules /usr/local/lib/ecap_adapter_MY_processing.so
> ecap_enable on
> ecap_service ecapModifier respmod_precache \
>      uri=ecap://www.deltaglobal.net/adapter_My_processing  \
>        victim=sadeghsalehi\
>         replacement=***
> adaptation_access ecapModifier allow all
> loadable_modules /usr/local/lib/ecap_adapter_My_request.so
> ecap_enable onecap_service eReqmod reqmod_precache bypass=1  ecap://e-cap.org/ecap/services/My/request
> adaptation_access   eReqmod  allow all

Looks correct, and should be working.

Notice that you have "bypass=1" configured, so any problem down to just
a long delay in processing time can cause the second eCAP module to be
bypassed and do nothing.

Your config looks fine. You will need to dig down into what the module
is actually doing and what it is having trouble with.

NP: -N is no just foreground, but also disables all multi-process
activity by the workers. Perhapse there is a problem with the ecap
module being either loaded and/or used by multiple processes simultaneously.

Amos



From squid3 at treenet.co.nz  Wed Dec 16 03:19:12 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 16 Dec 2015 16:19:12 +1300
Subject: [squid-users] issue with video
In-Reply-To: <DUB130-W51B0FFFACA318CF71E92BDBDEE0@phx.gbl>
References: <DUB130-W89E174D1006FA4F401466FBDE80@phx.gbl>
 <5668B48C.703@treenet.co.nz> <DUB130-W64B407122E68469941BB73BDE90@phx.gbl>
 <DUB130-W70D9F94323FC18DD1D6372BDE90@phx.gbl> <5669997A.70209@gmail.com>
 <DUB130-W4883D1369E0FC96B14F00ABDEA0@phx.gbl>
 <DUB130-W6B91C01FA9412AB19D44CBDED0@phx.gbl> <566F684D.4060602@ngtech.co.il>
 <566F800E.106@treenet.co.nz> <DUB130-W51B0FFFACA318CF71E92BDBDEE0@phx.gbl>
Message-ID: <5670D830.9010501@treenet.co.nz>

On 16/12/2015 3:02 a.m., Magic Link wrote:
> 
> Hi,
> the preview video here doesn't start, only the ads starts, then black screen appears. Then i don't have the choice, the play button appears and itplays the ads again and again : http://www.cbsnews.com/news/heroin-in-the-heartland-60-minutes/. Tested with squid 3.4.8 and 3.5.10If i use a direct access without the proxy with the same computer, the preview video begins (length 45 sec)
> The videos listed here works very well with squid : http://www.cbsnews.com/videos/
> 

There is nothing in the logs indicating that a large video is even being
requested through Squid. The small 4.4KB size of that CONNECT I found
could be the ads happening, but the video should follow those in the
same tunnel connection. And there are a huge amount of surrounding
requests to ad services. So I suspect the ads that do appear are in
those other requests.

I have seen similar ads-only behaviour every now any again on other
video sites when using the latest Firefox with no proxy at all. So I
suspect this is not Squid exactly but a problem with browser, media
player, or the video on the server.


You will need to do the debugging using those tools Eliezer mentioned.


One experiment I can suggest is looking through that log for the ad
services and making an http_access deny rule in squid.conf to block
them. See if the video behaviour changes in a good way, or the logs
reduce to showing anything more clear about the video transfer(s) once
the surrounding advert scripts are gone.

Amos



From antonio.petrelli at gmail.com  Wed Dec 16 10:12:04 2015
From: antonio.petrelli at gmail.com (Antonio Petrelli)
Date: Wed, 16 Dec 2015 11:12:04 +0100
Subject: [squid-users] Using cache_peer for transparent NTLM authentication
Message-ID: <CAHTRnew2OSF=AqZjOEc=WpoARSpHLUC5jyrBwC_FfAVfYGWCVw@mail.gmail.com>

Hello
sorry if this question has been asked, and answered, already, I dug the
mailing list archive but it is still not clear to me.

Is it possible to use a cache_peer that supports NTLM authentication in a
"transparent" way, so that the user of the Squid proxy does not need to
enter any authentication and Squid does all the authentication by itself?
Notice that, until now, I am using CNTLM to do this, however CNTLM has
severe problems under Windows 8.

Thank you in advance
Antonio Petrelli
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/7ea36902/attachment.htm>

From belle at bazuin.nl  Wed Dec 16 10:48:30 2015
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 16 Dec 2015 11:48:30 +0100
Subject: [squid-users] squid 3.5.10 samba4 kerberos few questions (debain
	Jessie)
Message-ID: <vmime.5671417e.77d9.2baf5672454565e@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

?

Im having the following running. 

Debian Jessie, squid 3.5.10 (recompiled from sid) ?with icap and authorisation agains a samba 4 AD DC. 

I begin with, this works great !.. so now my questions and the conf part for this. 

?

I am using the following authentications. 

First Kerberos:

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth -d \

??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/hostname.domain.tld at KERB.REALM \

??? --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN

?

And this works also

#auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \

#??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME -d \

#??? --ntlm /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --domain= NTDOMAIN \

?

I use as fallback ?basic auth.

auth_param basic program /usr/lib/squid/basic_ldap_auth -R \

??? -b "ou=SOMEOU,dc=internal,dc=domain.dc=tld" \

??? -D ldap-bind@ KERB.REALM ?-W /etc/squid/private/ldap-bind \

??? -f (|(userPrincipalName=%s)(sAMAccountName=%s)) \

??? -h samba4-dc2.internal.domain.tld \

??? -h samba4-dc1.internal.domain.tld

?

I know the following: 

## 1) Pure Kerberos. Passthrough auth for windows users with windows DOMAIN JOINED pc's.

##??? Fallback to Ldap for NON WINDOWS NON DOMAIN JOINED Devices.

##??? NO NTLM. AKA, a windows pc, NOT JOINED in the domain, with end up in always user popup for auth.

##??? Which will always fail because of NTLM TYPE 1 and TYPE 2, authorisations.

## 2) NEGOTIATE AUTH, which will do all of above, but also authenticated Windows PC's Not domain Joined.

?

When people access websites a see a lot of : TCP_DENIED/407 

Sometimes about 10-12 times the TCP_DENIED/407, even when the user already access the website and it authenticated. 

Is this because of pc?s auth, or user auth, or by design as i did read here : 

?

http://www.squid-cache.org/mail-archive/squid-users/201310/0006.html

acl AuthRequest http_status 407 
access_log ... !AuthRequest ...

?

?

is this the only solution to reduce the 407, or am i missing some setting here? 

If you need more info, just ask.. 

?

?

Greetz, 

?

Louis

?

?

?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/2198209e/attachment.htm>

From squid3 at treenet.co.nz  Wed Dec 16 11:58:50 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Dec 2015 00:58:50 +1300
Subject: [squid-users] Using cache_peer for transparent NTLM
 authentication
In-Reply-To: <CAHTRnew2OSF=AqZjOEc=WpoARSpHLUC5jyrBwC_FfAVfYGWCVw@mail.gmail.com>
References: <CAHTRnew2OSF=AqZjOEc=WpoARSpHLUC5jyrBwC_FfAVfYGWCVw@mail.gmail.com>
Message-ID: <567151FA.5030203@treenet.co.nz>

On 16/12/2015 11:12 p.m., Antonio Petrelli wrote:
> Hello
> sorry if this question has been asked, and answered, already, I dug the
> mailing list archive but it is still not clear to me.
> 
> Is it possible to use a cache_peer that supports NTLM authentication in a
> "transparent" way, so that the user of the Squid proxy does not need to
> enter any authentication and Squid does all the authentication by itself?

No that is not supported. And we have no intention of adding it, NTLM
has been deprected for nearly 10 years.

Squid supports performing Negotiate/Kerberos authentication to
cache_peer instead.


> Notice that, until now, I am using CNTLM to do this, however CNTLM has
> severe problems under Windows 8.

Notice that NTLM has increasingly severe problems under any Windows XP
SP3 or later system.

Amos



From behrad_es at yahoo.com  Wed Dec 16 12:47:11 2015
From: behrad_es at yahoo.com (behrad eslami)
Date: Wed, 16 Dec 2015 12:47:11 +0000 (UTC)
Subject: [squid-users] squid 3.5.12 and ecap
In-Reply-To: <5670D5AC.9010404@treenet.co.nz>
References: <5670D5AC.9010404@treenet.co.nz>
Message-ID: <1439477184.2010950.1450270031133.JavaMail.yahoo@mail.yahoo.com>

Hi?
thanks for you response. I compiled squid on debian jessie 


    On Wednesday, December 16, 2015 6:38 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
 

 On 16/12/2015 12:53 a.m., behrad eslami wrote:
> Hi I add simple rule to ecap module and deny some url. I forground
> (squid -N -d10) all things work well. when i run service wtih mutiple
> workers, after a while some url not filter and user can open them in
> browsers. I compile Squid 3.5.12 and libecpa 1.0.0. squid compiled
> with below options:
> '--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=${prefix}/lib/squid3' '--srcdir=.' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--datadir=/usr/share/squid3' '--sysconfdir=/etc/squid3' '--mandir=/usr/share/man' '--enable-inline' '--disable-arch-native' '--enable-async-io=8' '--enable-storeio=aufs,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-follow-x-forwarded-for' '--enable-eui' '--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-auto-locale' '--disable-translation' '--with-swapdir=/var/spool/squid3' '--with-logdir=/var/log/squid3' '--with-pidfile=/var/run/squid3.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-build-info= linux' '--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu
' 'CFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security' '--disable-ipv6' '--disable-wccp' '--disable-auth-basic' '--disable-auth-digest' '--disable-auth-negotiate' '--disable-auth-ntlm' '--disable-external-acl-helpers' '--disable-url-rewrite-helpers' '--disable-storeid-rewrite-helpers' '--without-mit-krb5' '--without-heimdal-krb5' '--without-gnugss' '--disable-unlinkd' '--disable-ident-lookups' '--disable-esi' '--disable-select' '--disable-poll' '--disable-kqueue' '--disable-devpoll' '--enable-epoll'
> 

This looks like Debian based build settings. With a bunch of extra
things disabled. What OS is this being used on?

NP: you can use --disable-auth to do all of the --disable-auth-*
settings in one simpler option.


> and my ecap config is:
> icap_enable on
> icap_send_client_ip on
> icap_client_username_encode on

None of that is eCAP configuration. The 'i' (not 'e') at the start of
the directive names should give it away.

This is the eCAP part:

> loadable_modules /usr/local/lib/ecap_adapter_MY_processing.so
> ecap_enable on
> ecap_service ecapModifier respmod_precache \
>? ? ? uri=ecap://www.deltaglobal.net/adapter_My_processing? \
>? ? ? ? victim=sadeghsalehi\
>? ? ? ? replacement=***
> adaptation_access ecapModifier allow all
> loadable_modules /usr/local/lib/ecap_adapter_My_request.so
> ecap_enable onecap_service eReqmod reqmod_precache bypass=1? ecap://e-cap.org/ecap/services/My/request
> adaptation_access? eReqmod? allow all

Looks correct, and should be working.

Notice that you have "bypass=1" configured, so any problem down to just
a long delay in processing time can cause the second eCAP module to be
bypassed and do nothing.

Your config looks fine. You will need to dig down into what the module
is actually doing and what it is having trouble with.

NP: -N is no just foreground, but also disables all multi-process
activity by the workers. Perhapse there is a problem with the ecap
module being either loaded and/or used by multiple processes simultaneously.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/71f16ea1/attachment.htm>

From antonio.petrelli at gmail.com  Wed Dec 16 13:13:41 2015
From: antonio.petrelli at gmail.com (Antonio Petrelli)
Date: Wed, 16 Dec 2015 14:13:41 +0100
Subject: [squid-users] Using cache_peer for transparent NTLM
	authentication
In-Reply-To: <567151FA.5030203@treenet.co.nz>
References: <CAHTRnew2OSF=AqZjOEc=WpoARSpHLUC5jyrBwC_FfAVfYGWCVw@mail.gmail.com>
 <567151FA.5030203@treenet.co.nz>
Message-ID: <CAHTRnewgOZV2Wmqg=uDujr_ywZ5prxm75Fu01jmktJgA6sQfxw@mail.gmail.com>

2015-12-16 12:58 GMT+01:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 16/12/2015 11:12 p.m., Antonio Petrelli wrote:
> > Hello
> > sorry if this question has been asked, and answered, already, I dug the
> > mailing list archive but it is still not clear to me.
> >
> > Is it possible to use a cache_peer that supports NTLM authentication in a
> > "transparent" way, so that the user of the Squid proxy does not need to
> > enter any authentication and Squid does all the authentication by itself?
>
> No that is not supported. And we have no intention of adding it, NTLM
> has been deprected for nearly 10 years.
>
> Squid supports performing Negotiate/Kerberos authentication to
> cache_peer instead.
>
>
> > Notice that, until now, I am using CNTLM to do this, however CNTLM has
> > severe problems under Windows 8.
>
> Notice that NTLM has increasingly severe problems under any Windows XP
> SP3 or later system.
>
>
Thank you. Notice that I asked this question because I would like to use
Squid as a personal local proxy for different type of upstream proxy, so
that a user can use their Squid instance on their machine and the only
thing to do is switch the correct configuration file when switching
workplace. Currently I do it by using Squid or CNTLM when needed and I also
wrote a proxy in Java for it, however it is really memory-consuming,
especially compared to Squid:
https://github.com/apetrelli/scafa

Thank you anyway for your answer and sorry for the rant

Antonio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/1db7925a/attachment.htm>

From squid3 at treenet.co.nz  Wed Dec 16 13:14:18 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Dec 2015 02:14:18 +1300
Subject: [squid-users] squid 3.5.10 samba4 kerberos few questions
 (debain Jessie)
In-Reply-To: <vmime.5671417e.77d9.2baf5672454565e@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.5671417e.77d9.2baf5672454565e@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <567163AA.1000801@treenet.co.nz>

On 16/12/2015 11:48 p.m., L.P.H. van Belle wrote:
> Hai, 
> 
>  
> 
> Im having the following running. 
> 
> Debian Jessie, squid 3.5.10 (recompiled from sid)  with icap and authorisation agains a samba 4 AD DC. 
> 
> I begin with, this works great !.. so now my questions and the conf part for this. 
> 
>  
> 
> I am using the following authentications. 
> 
> First Kerberos:
> 
> auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth -d \
> 
>     --kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/hostname.domain.tld at KERB.REALM \
> 
>     --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN
> 
>  
> 
> And this works also
> 
> #auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
> 
> #    --kerberos /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME -d \
> 
> #    --ntlm /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --domain= NTDOMAIN \
> 
>  
> 
> I use as fallback  basic auth.
> 
> auth_param basic program /usr/lib/squid/basic_ldap_auth -R \
> 
>     -b "ou=SOMEOU,dc=internal,dc=domain.dc=tld" \
> 
>     -D ldap-bind@ KERB.REALM  -W /etc/squid/private/ldap-bind \
> 
>     -f (|(userPrincipalName=%s)(sAMAccountName=%s)) \
> 
>     -h samba4-dc2.internal.domain.tld \
> 
>     -h samba4-dc1.internal.domain.tld
> 
>  
> 
> I know the following: 
> 
> ## 1) Pure Kerberos. Passthrough auth for windows users with windows DOMAIN JOINED pc's.
> 
> ##    Fallback to Ldap for NON WINDOWS NON DOMAIN JOINED Devices.
> 
> ##    NO NTLM. AKA, a windows pc, NOT JOINED in the domain, with end up in always user popup for auth.
> 
> ##    Which will always fail because of NTLM TYPE 1 and TYPE 2, authorisations.
> 
> ## 2) NEGOTIATE AUTH, which will do all of above, but also authenticated Windows PC's Not domain Joined.
> 

AFAIK #2 is incorrect. Negotiate still needs the *joined* part to be
true. They just do not have to have current connectivity to the DC
provided the secret-token part of credentials that comes from the DC is
still current on the client machine.


> 
> When people access websites a see a lot of : TCP_DENIED/407 
> 
> Sometimes about 10-12 times the TCP_DENIED/407, even when the user already access the website and it authenticated. 
> 
> Is this because of pc?s auth, or user auth, or by design as i did read here : 
> 
> 
> http://www.squid-cache.org/mail-archive/squid-users/201310/0006.html


> 
> acl AuthRequest http_status 407 
> access_log ... !AuthRequest ...
> 
> is this the only solution to reduce the 407, or am i missing some setting here? 

It just hides them from the logging. They still happen.

Another workaround is suggested in that thread; to bypass and not
require authentication for some popular domains. That has the added
benefit of letting HTTP performance optimizations work - most HTTP
features actually have to be disabled in the presence of NTLM or Negotiate.

The solution is for clients to actually make use of the connection
persistence that NTLM and Negotiate *require* Squid to setup just to
perform those auth types. Tearing it all down after just one HTTP level
transaction is very wasteful.

Amos



From bhsreenath at gmail.com  Wed Dec 16 14:10:12 2015
From: bhsreenath at gmail.com (Sreenath BH)
Date: Wed, 16 Dec 2015 19:40:12 +0530
Subject: [squid-users] Time for cache synchronization between siblings
In-Reply-To: <5670928C.8050805@treenet.co.nz>
References: <CALgKBSnCywpET++mS_UdgYpGpEgJ7Wx4D40Mwg2=yiXRtN-h7g@mail.gmail.com>
 <5670928C.8050805@treenet.co.nz>
Message-ID: <CALgKBSkFusG=p4kgE60_uWe9qfxHrpFAj+cTUpQSMUw+6kMftA@mail.gmail.com>

Hi,

Thanks for the tips. After disabling digest I believe performance improved.
However, I found that randomly requests were being routed to parent
even when siblings had the data cached.

>From access.log I found TIMEOUT_CARP. I assumed this meant HTCP timed
out and squid was forced to go to fetch the data. So I increased
icp_query_timeout to 4000 milliseconds, and the hit rate increased
further.

But I still find that sometimes, even after getting a HIT response
from a sibling, squid, for some reason still decides to go to the
parent for requested object.

Are there any other reasons why squid will decide to go to parent servers?

And another question: When the hash key is computed for storing cache
objects, does Squid use the hostname(or IP address) also as part of
URL, or just the part that appears after the hostname/IP:port numbers?

For example: if ip address is squid servers is 10.135.85.2 and
10.135.85.3, and a request made to 1st server would have had the IP
address as part of the URL. However, next time same request is made to
server2, a different IP address would be used. Does this affect cache
hit at the sibling server?

I think it should not, but is this the case?

We will have a load balancer that sends requests to each squid server,
and we want cache peering to work correctly in this case.

thanks,
Sreenath


On 12/16/15, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 16/12/2015 7:16 a.m., Sreenath BH wrote:
>> Hi,
>>
>> I have a setup with three squid peers (siblings in squid.conf) and
>> three upstream servers(peers with parent and originserver in
>> squid.conf).
>>
>> I am using htcp for the three squid siblings.
>> How much time does it take for one squid server to 'know' that another
>> peer has a particular object cached? I see digests exchanged between
>> the siblings, as logged in cache.log.
>
> When both HTCP an dDgests are active between siblings the maximum time
> is however long it takes for the HTCP packet to reach the sibling, be
> parsed, looked up in the cache and response to get back.
>
> Digests are used to short-circuit the ICP or HTCP process. If the digest
> contains an entry for the URL the peer will be selected as a possible
> destination server. Regardless of whether the object stored for that URL
> is the same one the client is fetching.
>
> Digests are updated every digest_rebuild_period (default 1 hr). You can
> disable digests with either "digest_generation off" or per-peer with the
> cache_peer no-digest option.
>
>
>>
>> I have been able to make a request to one sibling and it resulted in a
>> sibling_hit.
>>
>> How I do this test is this:
>> 1. bring up all siblings
>> 2. issue a request to one server (sibling 1)
>> 3. Make sure it is cached in sibling 1
>> 4. Wait for some time (I don't know how long to wait)
>
> Until the log of sibling1 contains a digest fetch from sibling2. A
> restart of sibling2 will make that happen faster.
>
>> 5. Make same request to another sibling, say sibling 2
>> 6. Check if it went to upstream server for the request or it was a sibling
>> hit.
>>
>> My problem is that the sibling hits seem to be random. I am  not able
>> to figure out exactly
>> how log it takes for the cache information to propagate to all siblings.
>
> Digest is a old algorithm designed as an optimization of ICP, and
> likewise is based on URL alone - which is great for HTTP/1.0 traffic. In
> modern HTTP/1.1 traffic the Vary headers have a big part to play and
> HTCP with full-header lookups works much better.
>
> I suggest trying with only HTCP (digests disabled) and see if your
> performance improves at all. YMMV though.
>
> Be aware that there is no guarantee that any object is still in cache,
> even with the more reliable HTCP on-demand lookups. Any object could be
> dropped from sibling1 cache picoseconds after the "i have it" reply
> started being formed for delivery to sibling2 (before it even hits the
> wire on its way back).
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From fabietto82 at gmail.com  Wed Dec 16 16:34:48 2015
From: fabietto82 at gmail.com (Fabio Bucci)
Date: Wed, 16 Dec 2015 17:34:48 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <566B9BE7.8050907@treenet.co.nz>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
 <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
 <566AE006.80609@treenet.co.nz>
 <CAJrMMC_BPiU49yd6w8dHyqbUbeujTsq41fjjdULvk9L9Eu5dSA@mail.gmail.com>
 <566B9BE7.8050907@treenet.co.nz>
Message-ID: <CAJrMMC8beqFndjUbumOFL7xzuKSL5KNS8pJ3_y=A1ZJNuUp05w@mail.gmail.com>

i'm planning to migrate to kerberos instead NTLM.....i got a question for
you Amos: sometimes a client reports issue in navigation and searching into
log file i cannot see "username" and all the request are 407

In these cases is there a way to reset a user session or it's a completely
client issue?

thanks,
Fabio

2015-12-12 5:00 GMT+01:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 12/12/2015 3:42 a.m., Fabio Bucci wrote:
> > Thank Amos i know you suggested kerberos. How can i implement it instead
> of
> > LDAP?
>
> <http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos>
>
> Amos
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151216/c62c1b18/attachment.htm>

From emz at norma.perm.ru  Wed Dec 16 16:35:02 2015
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Wed, 16 Dec 2015 21:35:02 +0500
Subject: [squid-users] squid authentication mechs
Message-ID: <567192B6.4050002@norma.perm.ru>

Hi.

Is there a way to limit the number of available authentication 
mechanisms (for a client browser) basing on certain squid IP which this 
browser connects to, like, using http_port configuration directive ? For 
example this is needed when one need to allow the non-domain machines to 
pass through authentication/authorization checks using squid with 
full-fledged AD integraion (or Kerberos/NTLM, anyway), otherwise they 
are unable to do it. Once they were, for example using Chrome < 41, but 
since >41 Chrome has removed all the options to exclude certain 
authentication methods from it's CLI sequence (I still wander what a 
genious proposed this).

If not(and I believe there isn't) could this message be treated as a 
feature request ?

Thanks.
Eugene.


From avhernandez at uci.cu  Wed Dec 16 18:38:34 2015
From: avhernandez at uci.cu (=?UTF-8?Q?Amaury_Viera_Hern=c3=a1ndez?=)
Date: Wed, 16 Dec 2015 13:38:34 -0500
Subject: [squid-users] [MASSMAIL] Squid: forward to another squid server
 with authentication
In-Reply-To: <356170619.10258770.1450224192856.JavaMail.zimbra@uci.cu>
References: <356170619.10258770.1450224192856.JavaMail.zimbra@uci.cu>
Message-ID: <5671AFAA.7080401@uci.cu>

Thank you. I will follow you instructions.

Amaury.
On 15/12/15 19:03, Amaury Viera Hern?ndez wrote:
> Hello everyone. This is a more detailed explanation about my trouble:
>
> I have two network cards:
>
> a shared Wifi card(wlp2s0) : 10.42.0.1
> a Network card with access to my LAN(enp4s0): 10.8.77.1
>
> In short, I am looking for a simple way to do the following (please give code samples if possible):
>
> Set up and start a transparent proxy server on my computer (wifi card, say that squid will listen at 10.42.0.1:3128) that can capture all web requests from my phone, once the http request from phone comes to this proxy, it will forward it to the university proxy (say address is 10.0.0.1:8080 with user and password authentication)
>
> Note: Is posible that one of the authentication methods of my proxy server will be ntlm
>
> Now, more details to fully explain my situation:
>
> In my university, authentication is needed to pass through a proxy so that we can connect to the internet. I normally enter my active directory username/password to authenticate when the pop up appears in the web browser
>
> Now, I want to connect my phone to my hared wifi(10.42.0.1) and using the network card with access to the lan(10.8.77.1), forward de http request of my phone to the proxy server in the university( 10.0.0.1:8080 with user and password authentication) because some application of my phone require a direct connection, without proxy and without proxy authentication. So, I am planning to set up a transparent proxy on my laptop to catch all requests from my phone. Of course, I don't need to use the proxy for local domains (uci.cu in this case)
>
> I'm using ubuntu 15.10 with squid3 (3.3.8)
>
> I have this configuration in squid.conf (This is very functional for local domain(without proxy authentications, against the local domains, for example: intranet.uci.cu, but for internet domains I need to authenticate(cache_peer my proxy with the proxy of my university)) )
>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> acl localdst dstdomain
> acl mi_red src 10.42.0.0/24
> http_access allow mi_red
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localhost
> http_access deny all
> http_port 10.42.0.1:3128 transparent
> coredump_dir /var/spool/squid3
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
> refresh_pattern .               0       20%     4320
> cache_mem 512 MB
> cache_dir ufs /var/spool/squid3 2048 16 256
> cache_effective_user proxy
> cache_effective_group proxy
> half_closed_clients off
> maximum_object_size 1024 KB
> cache_swap_low 90
> cache_swap_high 95
> memory_pools off
> error_directory /usr/share/squid3/errors/es/
> access_log /var/log/squid3/access.log squid
> cache_peer 10.0.0.1 parent 8080 0 no-query default no-digest login=avhernandez:MyPass
> never_direct allow all
>
>
> I'm using this firewall script
>
> #!/bin/sh
> # IP del servidor SQUID
> SQUID_SERVER="10.42.0.1"
> # Interface conectada a Internet
> INTERNET="enp4s0"
> # Interface interna
> LAN_IN="wlp2s0"
> # Puerto Squid
> SQUID_PORT="3128"
>
> # Limpia las reglas anteriores
> iptables -F
> iptables -X
> iptables -t nat -F
> iptables -t nat -X
> iptables -t mangle -F
> iptables -t mangle -X
> # Carga los modulos IPTABLES para NAT e IP con soporte conntrack
> modprobe ip_conntrack
> modprobe ip_conntrack_ftp
> echo 1 > /proc/sys/net/ipv4/ip_forward
> # Politica de filtro por defecto
> iptables -P INPUT DROP
> iptables -P OUTPUT ACCEPT
> # Acceso ilimitado a loop back
> iptables -A INPUT -i lo -j ACCEPT
> iptables -A OUTPUT -o lo -j ACCEPT
> # Permite UDP, DNS y FTP pasivo
> iptables -A INPUT -i $INTERNET -m state --state ESTABLISHED,RELATED -j ACCEPT
> # Establece el servidor como router para la red
> iptables --table nat --append POSTROUTING --out-interface $INTERNET -j MASQUERADE
> iptables --append FORWARD --in-interface $LAN_IN -j ACCEPT
> # acceso ilimiato a la LAN
> iptables -A INPUT -i $LAN_IN -j ACCEPT
> iptables -A OUTPUT -o $LAN_IN -j ACCEPT
> # Redirige las peticiones de la red interna hacia el proxy
> iptables -t nat -A PREROUTING -i $LAN_IN -p tcp --dport 80 -j DNAT --to $SQUID_SERVER:$SQUID_PORT
> # Redirige la entrada al proxy
> iptables -t nat -A PREROUTING -i $INTERNET -p tcp --dport 80 -j REDIRECT --to-port $SQUID_PORT
>
> Best regards. Amaury.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From squid3 at treenet.co.nz  Wed Dec 16 20:12:41 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Dec 2015 09:12:41 +1300
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC8beqFndjUbumOFL7xzuKSL5KNS8pJ3_y=A1ZJNuUp05w@mail.gmail.com>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
 <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
 <566AE006.80609@treenet.co.nz>
 <CAJrMMC_BPiU49yd6w8dHyqbUbeujTsq41fjjdULvk9L9Eu5dSA@mail.gmail.com>
 <566B9BE7.8050907@treenet.co.nz>
 <CAJrMMC8beqFndjUbumOFL7xzuKSL5KNS8pJ3_y=A1ZJNuUp05w@mail.gmail.com>
Message-ID: <5671C5B9.5080100@treenet.co.nz>

On 17/12/2015 5:34 a.m., Fabio Bucci wrote:
> i'm planning to migrate to kerberos instead NTLM.....i got a question for
> you Amos: sometimes a client reports issue in navigation and searching into
> log file i cannot see "username" and all the request are 407
> 
> In these cases is there a way to reset a user session or it's a completely
> client issue?

Usually it is the client stuck in a loop trying Negtiate/NTLM auth for
some reason. Some old Firefox, most Safari, and older IE can all get
stuck trying those credentials and ignoring the offers of Basic.

It might be possible to figure out some LmCompatibility settings change
that makes the problem just go away (eg, forcing NTLM of all versions to
disabled on the client).

Other than that Squid does have some workaround responses it can be made
to send back that might help the client reach the right conclusion:

a) list Basic auth first in the config. Any properly working client will
re-sort the auth types by security level and do theKerberos anyway. But
the broken ones (particularly IE7 and older) will have more chance of
using Basic.

b) sending 407 response with no auth headers. Such as a deny 407 status
generated by external ACL deny, or a URL-redirector. These tell the
client that auth failed, but there is no acceptible fallback.

c) sending Connection:close. Sometimes (mostly Firefox v20-v40) it is
the client prematurely attaching the credentials to the connection and
re-using them. That is supposed to have been fixed recently, but I've
not confirmed.

d) sending 403 status response. To just flat-out block the client once
it enters the looping state. Hoping that later requests will start to
work again.


HTH
Amos



From squid3 at treenet.co.nz  Wed Dec 16 20:35:01 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Dec 2015 09:35:01 +1300
Subject: [squid-users] Time for cache synchronization between siblings
In-Reply-To: <CALgKBSkFusG=p4kgE60_uWe9qfxHrpFAj+cTUpQSMUw+6kMftA@mail.gmail.com>
References: <CALgKBSnCywpET++mS_UdgYpGpEgJ7Wx4D40Mwg2=yiXRtN-h7g@mail.gmail.com>
 <5670928C.8050805@treenet.co.nz>
 <CALgKBSkFusG=p4kgE60_uWe9qfxHrpFAj+cTUpQSMUw+6kMftA@mail.gmail.com>
Message-ID: <5671CAF5.7010006@treenet.co.nz>

On 17/12/2015 3:10 a.m., Sreenath BH wrote:
> Hi,
> 
> Thanks for the tips. After disabling digest I believe performance improved.
> However, I found that randomly requests were being routed to parent
> even when siblings had the data cached.
> 
> From access.log I found TIMEOUT_CARP. I assumed this meant HTCP timed
> out and squid was forced to go to fetch the data. So I increased
> icp_query_timeout to 4000 milliseconds, and the hit rate increased
> further.
> 
> But I still find that sometimes, even after getting a HIT response
> from a sibling, squid, for some reason still decides to go to the
> parent for requested object.
> 
> Are there any other reasons why squid will decide to go to parent servers?

Just quirks of timing I think. Squid tracks response latency and prefers
the fastest source. If the parent is responding faster than the sibling
for man requests over a short period then Squid might switch to using
the parent as first choice for a


Some traffic is also classified as "non-hierarchical". Meaning that it
makes no sense sending it to a sibling unless all parents are down.
Things such as CONNECT, OPTIONS, POST etc where the response is not
possible to be cached at the sibling.


> 
> And another question: When the hash key is computed for storing cache
> objects, does Squid use the hostname(or IP address) also as part of
> URL, or just the part that appears after the hostname/IP:port numbers?

No. The primary Store ID/key is the absolute URL alone. Unless you are
using the Store-ID feature of Squid to change it to some other explicit
string value.

If the URL produces a reply object with Vary header, then the expansion
of the Vary header format is appended to the primary Store ID/key.

> 
> For example: if ip address is squid servers is 10.135.85.2 and
> 10.135.85.3, and a request made to 1st server would have had the IP
> address as part of the URL. However, next time same request is made to
> server2, a different IP address would be used. Does this affect cache
> hit at the sibling server?
> 
> I think it should not, but is this the case?

Correct the Squid IP has nothing to do with the cache storage.

> 
> We will have a load balancer that sends requests to each squid server,
> and we want cache peering to work correctly in this case.

FYI; the digest and HTCP algorithms you are dealing with are already
load balancing algorithms. They are just designed for use in a flat
1-layer heirarchy.

If you intend to have a 2-layer heirarchy (frontend LB and backend
caches) I suggest you might want to look into Squid as the frontend LB
using CARP algorithm. The CARP algorithm ensures deterministic storage
locations for what URLs get sent to which caches. So there is no need
for siblings communication as they all get unique URLs.

 * <http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster> has
details of how to split the frontend and backend config. The specific
example is for doing it using SMP workers within a single proxy
instance. But the split can even more easily be done across different
machines.

 * <http://wiki.squid-cache.org/ConfigExamples/ExtremeCarpFrontend> has
some details on how to add iptables port splitting on top of CARP to get
ridiculously high performance out of a proxy heirarchy. The last numbers
I heard from these setups were pushing just under the Gbps mark.

Amos



From squid3 at treenet.co.nz  Wed Dec 16 20:53:01 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Dec 2015 09:53:01 +1300
Subject: [squid-users] squid authentication mechs
In-Reply-To: <567192B6.4050002@norma.perm.ru>
References: <567192B6.4050002@norma.perm.ru>
Message-ID: <5671CF2D.6060609@treenet.co.nz>

On 17/12/2015 5:35 a.m., Eugene M. Zheganin wrote:
> Hi.
> 
> Is there a way to limit the number of available authentication
> mechanisms (for a client browser) basing on certain squid IP which this
> browser connects to, like, using http_port configuration directive ? For
> example this is needed when one need to allow the non-domain machines to
> pass through authentication/authorization checks using squid with
> full-fledged AD integraion (or Kerberos/NTLM, anyway), otherwise they
> are unable to do it. Once they were, for example using Chrome < 41, but
> since >41 Chrome has removed all the options to exclude certain
> authentication methods from it's CLI sequence (I still wander what a
> genious proposed this).

Theoretically the client browser is fully aware of what credentials it
can use for what schemes (Kerberos, Basic, NTLM, Digest [in that orer of
security]). And also for remembering which credentials worked or failed
on previosu attempts with the offered schemes.

So there is no need to filter them at the proxy. *it* is perfectly able
to authenticate any credentials it gets given using any of the schemes
it is offering. You just happen to not like the outcome when validation
prevents login.


> 
> If not(and I believe there isn't) could this message be treated as a
> feature request ?

It has been a feature request for years to allow ACL control of auth
schemes offered. I even have a design plan laid out for implemeting it.
But nobody seems to want it enough to sponsor the addition (if you do
please contact me directly to discuss).

I am specifically waiting for sponsorship on this one because it needs
someone with an actual use-case and implementation to test that it works
properly with Negotiate and NTLM.

Otherwise please open a feature request bug to track the status and get
notification when somebody does get around to adding it.

Amos



From heypaleblue at gmail.com  Thu Dec 17 00:29:07 2015
From: heypaleblue at gmail.com (PaleBlue)
Date: Wed, 16 Dec 2015 16:29:07 -0800 (PST)
Subject: [squid-users] Configure proxy to multiple physical hosts through
	one Domain Name.
Message-ID: <1450312147909-4675235.post@n4.nabble.com>

Hi All, 

I am new to squid and have only been aware of it for minutes. however it
looks like what I desparately need to accomplish is doable with squid.

I am trying to accomplish the following 

apple.mydomain.com ---> Server01 (website and Blog)
orange.mydomain.com ---> Server02 (GitLab)
pear.mydomain.com ---> Server03 (Future use)

I want to put a VM with Ubuntu server and squid behind my firewall to proxy
the requests to the different servers but have no even where to get started
as I am so new to squid. I have read the around and believe it is possible
based on  This
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Multiple-site-example-td1034364.html>  
post however I would like to stress. *I am not trying to load balance, I am
trying to make one domain name show different things from different servers.
*


if anyone could give me some guidance on getting started with this I would
be *Very* appreciative.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Configure-proxy-to-multiple-physical-hosts-through-one-Domain-Name-tp4675235.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From wayne.gillan at jurox.com.au  Thu Dec 17 03:57:25 2015
From: wayne.gillan at jurox.com.au (Wayne Gillan)
Date: Thu, 17 Dec 2015 03:57:25 +0000
Subject: [squid-users] SSTP_DUPLEX_POST method
In-Reply-To: <566FBFBA.3080500@ngtech.co.il>
References: <241CD68BD7EF6D4D8CE0A53F4166F57E3A784842@exchange.jurox>
 <566FBFBA.3080500@ngtech.co.il>
Message-ID: <241CD68BD7EF6D4D8CE0A53F4166F57E3A7861CC@exchange.jurox>

Yes SSTP is a type of SSL VPN. Why behind a reverse proxy? Well just like other SSL services I need to share port 443 with one public IP address.

I've run packet captures on the client, vpn server and squid. The request is getting through ok and the vpn server is sending a reply. But squid is not forwarding the reply to the client I believe. Here's some snippets of the squid log:

2015/12/17 14:26:48.550| http.cc(762) processReplyHeader: HTTP Server REPLY:
---------
HTTP/1.1 200
Content-Length: 18446744073709551615
Server: Microsoft-HTTPAPI/2.0
Date: Thu, 17 Dec 2015 03:26:48 GMT
----------
2015/12/17 14:26:48.556| client_side.cc(1377) sendStartOfMessage: HTTP Client local=ip.of.squid:443 remote=1.2.3.4:44582 FD 9 flags=1
2015/12/17 14:26:48.556| client_side.cc(1378) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Content-Length: 18446744073709551615
Server: Microsoft-HTTPAPI/2.0
Date: Thu, 17 Dec 2015 03:26:48 GMT
X-Cache: MISS from 
X-Cache-Lookup: MISS from :443
Connection: keep-alive
----------
2015/12/17 14:26:48.557| client_side_reply.cc(1114) storeNotOKTransferDone: storeNotOKTransferDone  out.size=240 expectedLength=-9223372036854775569
2015/12/17 14:26:48.557| client_side.cc(1827) stopSending: sending error (local=ip.of.squid:443 remote=1.2.3.4:44582 FD 9 flags=1): STREAM_UNPLANNED_COMPLETE; old receiving error: none

2015/12/17 14:26:48.673| Server.cc(362) sentRequestBody: sentRequestBody called
2015/12/17 14:26:48.673| Server.cc(423) sendMoreRequestBody: will wait for more request body bytes or eof


Seems like the large value of the Content-Length header field is causing issues. Squid waits for more data but the server never sends it because it's waiting for something from the client. 

Is there any way to make squid just pass traffic exactly as it comes in?


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Tuesday, 15 December 2015 6:23 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SSTP_DUPLEX_POST method

Isn't SSTP is some kind of secure VPN service? which is based on SSL?
Why would you want to put a reverse proxy in front of a VPN service? 
There are many things to do in the IP level but not much to do in the HTTP level.

Eliezer

On 15/12/2015 07:20, Wayne Gillan wrote:
> Hi all,
>
> I am trying to configure squid as a reverse proxy in front of a Microsoft SSTP VPN server but squid does not appear to be forwarding the requests. I think it may have something to do with this custom verb/method that Microsoft use. Seehttps://msdn.microsoft.com/en-us/library/cc247364.aspx. Should it work ok? I am running 3.1.19.
>
> Thank you,
> Wayne

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com ______________________________________________________________________

______________________________________________________________________
This email is confidential.  If you are not the intended recipient, you must not disclose  or  use the  information  contained in it.
If you have received this email in error,  please notify us immediately by return email and delete the email and any attachments.
Any personal views/ opinions expressed by the writer may not necessarily reflect the views/ opinions of the company.
______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

From yvoinov at gmail.com  Thu Dec 17 10:12:46 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 17 Dec 2015 16:12:46 +0600
Subject: [squid-users] Using subordinate CA for SSL Bump
In-Reply-To: <56706C1A.3080300@measurement-factory.com>
References: <566F3412.6060504@gmail.com> <566F4DC6.6080408@treenet.co.nz>
 <566F5534.6090801@urlfilterdb.com> <56706C1A.3080300@measurement-factory.com>
Message-ID: <56728A9E.1020609@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 




This looks like. Root CA doesn't send. Subordinate CA uses as signer for
mimicked. All and any clients got security alert.

16.12.15 1:38, Alex Rousskov ?????:
> On 12/14/2015 04:48 PM, Marcus Kool wrote:
>> On 12/14/2015 09:16 PM, Amos Jeffries wrote:
>>> Squid may be horribly sending
>>> all-but-one of the certs needed, on the assumption that the signing cert
>>> is itself installed on the client.
>
>
>> The RFC says that it is not necessary to send the signing CA certificate.
>
>
> Sending the CA certificate is usually both unnecessary (because the
> clients must have it) and borderline dangerous (because some clients do
> not expect this extra information). This is why, I bet, Squid does not
> send the signing certificate in some cases.
>
> On the other hand, sending the signing certificate is necessary if that
> signing certificate is not the CA certificate expected to be stored by
> clients. IIRC, we have fixed at least one Squid bug in this area in
> 2015, but I do not have a reference handy.
>
> And there are actually situations in-between the two extremes above
> because a CA (well-known and not) often has its own CA certificate
> hierarchy, and some clients may trust intermediate CA certificates [with
> or without storing the root CA certificate].
>
> The above does not answer the OP question. The answer may go something
> like this:
>
> If you expect your clients to store your signing certificate, then you
> can configure Squid to sign with that certificate and not worry about
> any higher-level (closer to root) certificate that may or may not exist.
> On the other hand, if your clients are storing a higher-level
> certificate, then you need to test whether Squid does the right thing
> (i.e., sends the intermediate certificate which also happens to be the
> signing certificate). If Squid does not do the right thing, file a bug
> report.
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWcoqdAAoJENNXIZxhPexGykoIAJsF/fkG0HvtMH6ACAYyc9WN
4+1z/UpVrNID4tSJapFPaCBFJ6pGcSQrAXzSzT+94nQZJMMStverO94x+YJ8a4bp
hpVzewc0jVu4PCW0+V8YyvCvx0O4/sbEhWywc/dNz22KdAt6JhyWmaJTn22/JYMb
xlvEYQ0wZ0r/u2+WMTbcMq1cyAESCYouZSxsmhQubM60d3ZUs25I3AUULEHguzXp
JO29tZcy1ZUzQZ9bCmVIwJTHfAjK3jTFRw66LpB2sooMb1O/Xfm+HGbndnpi1+ab
98/1Lhz4hTNJRFu4fxMbt1+VqXxp1q3OQA8OOOrbBu8vluFdB3WqwwqV/ACGsPo=
=zzWl
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151217/91548e5a/attachment.htm>

From eliezer at ngtech.co.il  Thu Dec 17 10:25:22 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 17 Dec 2015 12:25:22 +0200
Subject: [squid-users] Configure proxy to multiple physical hosts
 through one Domain Name.
In-Reply-To: <1450312147909-4675235.post@n4.nabble.com>
References: <1450312147909-4675235.post@n4.nabble.com>
Message-ID: <56728D92.6030402@ngtech.co.il>

Hey,

Basically what you want is called "reverse proxy".
Squid has this feature and you can see couple examples at the wiki:
http://wiki.squid-cache.org/FrontPage?action=fullsearch&context=180&value=reverse&titlesearch=Titles

This list is indeed squid users list but I will let you know that squid 
is not the only option in this area.
Other products:
- Nginx
- Varnish
- Custom proxies

Eliezer

On 17/12/2015 02:29, PaleBlue wrote:
> Hi All,
>
> I am new to squid and have only been aware of it for minutes. however it
> looks like what I desparately need to accomplish is doable with squid.
>
> I am trying to accomplish the following
>
> apple.mydomain.com ---> Server01 (website and Blog)
> orange.mydomain.com ---> Server02 (GitLab)
> pear.mydomain.com ---> Server03 (Future use)
>
> I want to put a VM with Ubuntu server and squid behind my firewall to proxy
> the requests to the different servers but have no even where to get started
> as I am so new to squid. I have read the around and believe it is possible
> based on  This
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/Multiple-site-example-td1034364.html>
> post however I would like to stress. *I am not trying to load balance, I am
> trying to make one domain name show different things from different servers.
> *
>
>
> if anyone could give me some guidance on getting started with this I would
> be *Very* appreciative.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Configure-proxy-to-multiple-physical-hosts-through-one-Domain-Name-tp4675235.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From bhsreenath at gmail.com  Thu Dec 17 12:21:28 2015
From: bhsreenath at gmail.com (Sreenath BH)
Date: Thu, 17 Dec 2015 17:51:28 +0530
Subject: [squid-users] Time for cache synchronization between siblings
In-Reply-To: <5671CAF5.7010006@treenet.co.nz>
References: <CALgKBSnCywpET++mS_UdgYpGpEgJ7Wx4D40Mwg2=yiXRtN-h7g@mail.gmail.com>
 <5670928C.8050805@treenet.co.nz>
 <CALgKBSkFusG=p4kgE60_uWe9qfxHrpFAj+cTUpQSMUw+6kMftA@mail.gmail.com>
 <5671CAF5.7010006@treenet.co.nz>
Message-ID: <CALgKBSmUhrfK1Q=Q-R9QA3RGwJCtZVq3Wv5G2uDfP4oE0z+CbQ@mail.gmail.com>

Hi,

Thanks for the detailed response. I really appreciate it.

Unfortunately the load balancer we use is not a squid load balancer
and for now I will have to use HTCP.

Please take a look at the following lines from access.log of one of
the three squid servers.
------------
1450351827.534      0 10.135.83.129 UDP_HIT/000 0 HTCP_TST
http://127.0.0.1:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?size=xs&start=0.000&end=5.930&
- HIER_NONE/- -

1450351827.562     20 10.135.83.129 TCP_HIT/200 553852 GET
http://127.0.0.1:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?
- HIER_NONE/- video/mp2t

1450352028.731      0 10.135.83.128 UDP_MISS/000 0 HTCP_TST
http://10.135.83.128:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?size=xs&start=0.000&end=5.930&
- HIER_NONE/- -
--------

The first line indicates a hit when queried by a peer. Note that the
IP address is 127.0.0.1.
It was a UDP HIT and it was followed by the actual request for the
cached object, which succeeded.

Now the third line indicates UDP query for same object, except that
URL has a different IP address, and the log says it was a MISS.

I don't know what I am doing wrong, but it consistently seems to treat
the IP address as part of the URL for purpose of HIT/MISS decision.

If all requests were made from a local client(say using curl running
locally on the machine) and using 127.0.0.1 as IP address, HTCP works
correctly.

Even without HTCP, just issuing same request from localhost and
another machine using a the externally visible IP address, squid does
not appear to use cached object. I am new to HTTP and think I must be
doing something wrong, but cant say what.

I wonder if ICP would have fared better since it uses just the URL.
Might that be a reason?

thanks,
Sreenath


On 12/17/15, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 17/12/2015 3:10 a.m., Sreenath BH wrote:
>> Hi,
>>
>> Thanks for the tips. After disabling digest I believe performance
>> improved.
>> However, I found that randomly requests were being routed to parent
>> even when siblings had the data cached.
>>
>> From access.log I found TIMEOUT_CARP. I assumed this meant HTCP timed
>> out and squid was forced to go to fetch the data. So I increased
>> icp_query_timeout to 4000 milliseconds, and the hit rate increased
>> further.
>>
>> But I still find that sometimes, even after getting a HIT response
>> from a sibling, squid, for some reason still decides to go to the
>> parent for requested object.
>>
>> Are there any other reasons why squid will decide to go to parent
>> servers?
>
> Just quirks of timing I think. Squid tracks response latency and prefers
> the fastest source. If the parent is responding faster than the sibling
> for man requests over a short period then Squid might switch to using
> the parent as first choice for a
>
>
> Some traffic is also classified as "non-hierarchical". Meaning that it
> makes no sense sending it to a sibling unless all parents are down.
> Things such as CONNECT, OPTIONS, POST etc where the response is not
> possible to be cached at the sibling.
>
>
>>
>> And another question: When the hash key is computed for storing cache
>> objects, does Squid use the hostname(or IP address) also as part of
>> URL, or just the part that appears after the hostname/IP:port numbers?
>
> No. The primary Store ID/key is the absolute URL alone. Unless you are
> using the Store-ID feature of Squid to change it to some other explicit
> string value.
>
> If the URL produces a reply object with Vary header, then the expansion
> of the Vary header format is appended to the primary Store ID/key.
>
>>
>> For example: if ip address is squid servers is 10.135.85.2 and
>> 10.135.85.3, and a request made to 1st server would have had the IP
>> address as part of the URL. However, next time same request is made to
>> server2, a different IP address would be used. Does this affect cache
>> hit at the sibling server?
>>
>> I think it should not, but is this the case?
>
> Correct the Squid IP has nothing to do with the cache storage.
>
>>
>> We will have a load balancer that sends requests to each squid server,
>> and we want cache peering to work correctly in this case.
>
> FYI; the digest and HTCP algorithms you are dealing with are already
> load balancing algorithms. They are just designed for use in a flat
> 1-layer heirarchy.
>
> If you intend to have a 2-layer heirarchy (frontend LB and backend
> caches) I suggest you might want to look into Squid as the frontend LB
> using CARP algorithm. The CARP algorithm ensures deterministic storage
> locations for what URLs get sent to which caches. So there is no need
> for siblings communication as they all get unique URLs.
>
>  * <http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster> has
> details of how to split the frontend and backend config. The specific
> example is for doing it using SMP workers within a single proxy
> instance. But the split can even more easily be done across different
> machines.
>
>  * <http://wiki.squid-cache.org/ConfigExamples/ExtremeCarpFrontend> has
> some details on how to add iptables port splitting on top of CARP to get
> ridiculously high performance out of a proxy heirarchy. The last numbers
> I heard from these setups were pushing just under the Gbps mark.
>
> Amos
>
>


From rousskov at measurement-factory.com  Thu Dec 17 17:01:29 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 17 Dec 2015 10:01:29 -0700
Subject: [squid-users] Using subordinate CA for SSL Bump
In-Reply-To: <56728A9E.1020609@gmail.com>
References: <566F3412.6060504@gmail.com> <566F4DC6.6080408@treenet.co.nz>
 <566F5534.6090801@urlfilterdb.com> <56706C1A.3080300@measurement-factory.com>
 <56728A9E.1020609@gmail.com>
Message-ID: <5672EA69.3000403@measurement-factory.com>

On 12/17/2015 03:12 AM, Yuri Voinov wrote:
> This looks like. Root CA doesn't send. Subordinate CA uses as signer for
> mimicked. All and any clients got security alert.


There may still be some terminology misunderstanding here because not
sending the root certificate is the right thing to do in most cases (as
I tried to explain in my earlier response). Let's continue with a more
specific example at Bug 4398:

http://bugs.squid-cache.org/show_bug.cgi?id=4398

Alex.


> 16.12.15 1:38, Alex Rousskov ?????:
>> On 12/14/2015 04:48 PM, Marcus Kool wrote:
>>> On 12/14/2015 09:16 PM, Amos Jeffries wrote:
>>>> Squid may be horribly sending
>>>> all-but-one of the certs needed, on the assumption that the signing cert
>>>> is itself installed on the client.
> 
> 
>>> The RFC says that it is not necessary to send the signing CA certificate.
> 
> 
>> Sending the CA certificate is usually both unnecessary (because the
>> clients must have it) and borderline dangerous (because some clients do
>> not expect this extra information). This is why, I bet, Squid does not
>> send the signing certificate in some cases.
> 
>> On the other hand, sending the signing certificate is necessary if that
>> signing certificate is not the CA certificate expected to be stored by
>> clients. IIRC, we have fixed at least one Squid bug in this area in
>> 2015, but I do not have a reference handy.
> 
>> And there are actually situations in-between the two extremes above
>> because a CA (well-known and not) often has its own CA certificate
>> hierarchy, and some clients may trust intermediate CA certificates [with
>> or without storing the root CA certificate].
> 
>> The above does not answer the OP question. The answer may go something
>> like this:
> 
>> If you expect your clients to store your signing certificate, then you
>> can configure Squid to sign with that certificate and not worry about
>> any higher-level (closer to root) certificate that may or may not exist.
>> On the other hand, if your clients are storing a higher-level
>> certificate, then you need to test whether Squid does the right thing
>> (i.e., sends the intermediate certificate which also happens to be the
>> signing certificate). If Squid does not do the right thing, file a bug
>> report.
> 
> 
>> HTH,
> 
>> Alex.
> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From Walter.H at mathemainzel.info  Thu Dec 17 18:54:16 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 17 Dec 2015 19:54:16 +0100
Subject: [squid-users] Using subordinate CA for SSL Bump
In-Reply-To: <566F3412.6060504@gmail.com>
References: <566F3412.6060504@gmail.com>
Message-ID: <567304D8.1050000@mathemainzel.info>

On 14.12.2015 22:26, Yuri Voinov wrote:
>
> Hi all.
>
> Does anybody can tell me - is it possible to use subordinate secondary
> CA in squid for SSL Bumping purpose?
this is possible; I had this for several months this way;
> I.e., we have self-signed primary CA for issue subordinate CA,
>
> subordinate CA we install in squid's setup,
>
> primary CA certificate install to clients.
>
> For example.
>
> For mimicking we'll using subordinate CA, and, in case of subordinate
> key forgery, we can use primary CA to revoke subordinate CA and re-issue
> them without total replacement primary CA on clients.
>
> This will seriously increase bumping security procedure, hm?
no; but there you have to keep some steps, you wouldn't need if squid 
used a root CA certificate; *)
you can replace the sub CA every month without extra work on client side 
because the clients have the root CA in their trust store;
> I've tried this scheme with 3.5.11, but without success.
ok I was using this with 3.4.10

*)  this is more work than someone may think, because you must fake a 
complete CA, this means:

in the sub CA certificate there must be anything neccessary to validate 
it, this means that there must be
an OCSP againt the root, and also a CRL link in the CA certificate 
attributes; and keep in mind
the only user agent in windows honoring the CRL is google's chrome; so 
keep it up to date ...

also there must be link to the root CA inside the sub CA certificate;

there must said something, when doing it this way:
the symbol chrome is showing for SSL connections may be a normal one as 
when there is no MITM ...

Walter


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151217/2742c831/attachment.bin>

From squid3 at treenet.co.nz  Thu Dec 17 21:06:27 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 18 Dec 2015 10:06:27 +1300
Subject: [squid-users] Time for cache synchronization between siblings
In-Reply-To: <CALgKBSmUhrfK1Q=Q-R9QA3RGwJCtZVq3Wv5G2uDfP4oE0z+CbQ@mail.gmail.com>
References: <CALgKBSnCywpET++mS_UdgYpGpEgJ7Wx4D40Mwg2=yiXRtN-h7g@mail.gmail.com>
 <5670928C.8050805@treenet.co.nz>
 <CALgKBSkFusG=p4kgE60_uWe9qfxHrpFAj+cTUpQSMUw+6kMftA@mail.gmail.com>
 <5671CAF5.7010006@treenet.co.nz>
 <CALgKBSmUhrfK1Q=Q-R9QA3RGwJCtZVq3Wv5G2uDfP4oE0z+CbQ@mail.gmail.com>
Message-ID: <567323D3.7030007@treenet.co.nz>

On 18/12/2015 1:21 a.m., Sreenath BH wrote:
> Hi,
> 
> Thanks for the detailed response. I really appreciate it.
> 
> Unfortunately the load balancer we use is not a squid load balancer
> and for now I will have to use HTCP.
> 
> Please take a look at the following lines from access.log of one of
> the three squid servers.
> ------------
> 1450351827.534      0 10.135.83.129 UDP_HIT/000 0 HTCP_TST
> http://127.0.0.1:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?size=xs&start=0.000&end=5.930&
> - HIER_NONE/- -
> 
> 1450351827.562     20 10.135.83.129 TCP_HIT/200 553852 GET
> http://127.0.0.1:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?
> - HIER_NONE/- video/mp2t
> 
> 1450352028.731      0 10.135.83.128 UDP_MISS/000 0 HTCP_TST
> http://10.135.83.128:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?size=xs&start=0.000&end=5.930&
> - HIER_NONE/- -
> --------
> 
> The first line indicates a hit when queried by a peer. Note that the
> IP address is 127.0.0.1.
> It was a UDP HIT and it was followed by the actual request for the
> cached object, which succeeded.
> 
> Now the third line indicates UDP query for same object, except that
> URL has a different IP address, and the log says it was a MISS.
> 
> I don't know what I am doing wrong, but it consistently seems to treat
> the IP address as part of the URL for purpose of HIT/MISS decision.


Notice how the normal HTTP request (TCP_* line) is also using
"127.0.0.1" for origin server name.

This means the two HTCP requests really are for two very different URLs.
Completely different origin servers being contacted.


> 
> If all requests were made from a local client(say using curl running
> locally on the machine) and using 127.0.0.1 as IP address, HTCP works
> correctly.

What is the output of "squid -v" ?

And beyond being a layer of caches behind a LB. What is the purpose of
this installation;
 reverse-proxy / CDN ?
 ISP forward/explicit proxy farm?
 Intranet gateway?
 some mix of the above?

and what is your full squid.conf ? (without comments and empty lines of
course).


What exactly are the clients (curl) requesting?
 from the Squid siblings directly? or through the LB?


> 
> Even without HTCP, just issuing same request from localhost and
> another machine using a the externally visible IP address, squid does
> not appear to use cached object. I am new to HTTP and think I must be
> doing something wrong, but cant say what.

Huh? Those log lines you posted above contradict. The first HTCP said
HIT and the TCP object fetch was served from the cache. The second said
MISS on the other URL, so no TCP fetch.

The sibling lookup and HTCP appears to be working perfectly correct.

> 
> I wonder if ICP would have fared better since it uses just the URL.
> Might that be a reason?

No. ICP always fares worse. It says UDP_HIT in a lot of cases where the
URL is same but the followup TCP fetch discovers HTTP mime headers
negotiating some variant object not in the sibling cache. So UDP_HIT
followed by TCP_MISS.
 That is almost the worst-case scenario: it causes a minimum of 2x proxy
processing latency delays on the whole transaction from the client
viewpoint. Unltimate worst-case is where a whole chain of parallel
siblings get relayed through due to UDP_MISS with N times the latency
multiplication.

At least with HTCP trying to fetch variants results in UDP_MISS. That is
the second-best *good* result.


That is all irrelevant to this case though. Since the raw-IP is part of
the URL, both of these siblings are working correctly.


Problem is why is the raw-IP with port 3128 part of the URL? It smells
like a miscnfiguration or bad design somewhere. The answers to my above
questions should help find the solution to that.

Amos



From Walter.H at mathemainzel.info  Fri Dec 18 04:48:03 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Fri, 18 Dec 2015 05:48:03 +0100
Subject: [squid-users] Using subordinate CA for SSL Bump
In-Reply-To: <5672EA69.3000403@measurement-factory.com>
References: <566F3412.6060504@gmail.com> <566F4DC6.6080408@treenet.co.nz>
 <566F5534.6090801@urlfilterdb.com> <56706C1A.3080300@measurement-factory.com>
 <56728A9E.1020609@gmail.com> <5672EA69.3000403@measurement-factory.com>
Message-ID: <56739003.8000906@mathemainzel.info>

On 17.12.2015 18:01, Alex Rousskov wrote:
> On 12/17/2015 03:12 AM, Yuri Voinov wrote:
>> This looks like. Root CA doesn't send. Subordinate CA uses as signer for
>> mimicked. All and any clients got security alert.
>
> There may still be some terminology misunderstanding here because not
> sending the root certificate is the right thing to do
as a correct configured web server does;
this sends only its SSL certificate with the issuing intermediate plus 
any other intermediate certificate,
but no root certificate ...

so in this case there is just the intermediate certificate the one squid 
uses for SSL bump;
the root certificate is installed on the clients and both the mimicked 
and the intermediate are sent by squid,
and all is fine;

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151218/37a4726f/attachment.bin>

From namr33b at yandex.ru  Fri Dec 18 11:42:02 2015
From: namr33b at yandex.ru (Ilya)
Date: Fri, 18 Dec 2015 14:42:02 +0300
Subject: [squid-users] 1Gb limit on https downloads
Message-ID: <BC7DDF82-8F43-4645-9459-06840A553C48@yandex.ru>

Hi

When download big files (>1Gb) by httpS protocol connection stalled on 1Gb mark and after some time dropped.
In access and cache logs no any errors or warnings about dropped connections.

Tested on Win 7 Firefox and Chrome browsers with Squid 3.1.23 running on FreeBSD 8/64 without https interception, just normal "CONNECT" tunnel.

Same result with Win 7 Firefox and Chrome browsers with Squid 3.5.12 on Ubuntu 64 with ssl-bump enabled.
In bumped logs, size of downloading file seems incorrect - around 1Gb, real file size is around 5Gb

In both situations file was downloaded from google drive, with same result - stalled on 1Gb stage

Setting reply_body_max_size to none, don't help with https.
Is here any option in squid config file or compile option to change limit of https downloads?



From yvoinov at gmail.com  Fri Dec 18 14:33:26 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 18 Dec 2015 20:33:26 +0600
Subject: [squid-users] 1Gb limit on https downloads
In-Reply-To: <BC7DDF82-8F43-4645-9459-06840A553C48@yandex.ru>
References: <BC7DDF82-8F43-4645-9459-06840A553C48@yandex.ru>
Message-ID: <56741936.6030801@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
There is no and may not be any limit in Squid.  Check your ISP.

18.12.15 17:42, Ilya ?????:
> Hi
>
> When download big files (>1Gb) by httpS protocol connection stalled on
1Gb mark and after some time dropped.
> In access and cache logs no any errors or warnings about dropped
connections.
>
> Tested on Win 7 Firefox and Chrome browsers with Squid 3.1.23 running
on FreeBSD 8/64 without https interception, just normal "CONNECT" tunnel.
>
> Same result with Win 7 Firefox and Chrome browsers with Squid 3.5.12
on Ubuntu 64 with ssl-bump enabled.
> In bumped logs, size of downloading file seems incorrect - around 1Gb,
real file size is around 5Gb
>
> In both situations file was downloaded from google drive, with same
result - stalled on 1Gb stage
>
> Setting reply_body_max_size to none, don't help with https.
> Is here any option in squid config file or compile option to change
limit of https downloads?
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWdBk2AAoJENNXIZxhPexGenUH/AyJXRRqeDWg4f2XdidleHPL
bu3KVI+U1Dglfcu/dOpFPZnKIl4OcRuxqN7dqSJxgXhN4sxrpVb0e9ac1jd2QK4o
Cv3STsKQwkm6Oc0j4uH2dCI9uyNjF2GO8ZlHETSVi8ZVLUmiiil7lTWLw0E99IRR
zm3c2pLnd/IaP4gSndKzJh4QbQN3X3F6fX2XoFfMp46LL7pmxSCR6zsNvv9kgam6
RPWShwAyREfUDYOjiTGMggXeaJKq/QGvICMPlyLoIvJiqKL1cT1o+3P9jbwhCF08
3sxTg79iWKmhj7km+81BxTBvBEH8czUkkgOhOgN/Nu1dJtPO1qhT29TCahxVSNc=
=9DXq
-----END PGP SIGNATURE-----



From bhsreenath at gmail.com  Fri Dec 18 15:14:19 2015
From: bhsreenath at gmail.com (Sreenath BH)
Date: Fri, 18 Dec 2015 20:44:19 +0530
Subject: [squid-users] Time for cache synchronization between siblings
In-Reply-To: <567323D3.7030007@treenet.co.nz>
References: <CALgKBSnCywpET++mS_UdgYpGpEgJ7Wx4D40Mwg2=yiXRtN-h7g@mail.gmail.com>
 <5670928C.8050805@treenet.co.nz>
 <CALgKBSkFusG=p4kgE60_uWe9qfxHrpFAj+cTUpQSMUw+6kMftA@mail.gmail.com>
 <5671CAF5.7010006@treenet.co.nz>
 <CALgKBSmUhrfK1Q=Q-R9QA3RGwJCtZVq3Wv5G2uDfP4oE0z+CbQ@mail.gmail.com>
 <567323D3.7030007@treenet.co.nz>
Message-ID: <CALgKBSksKmLmxwXKDi5sMcZxj_OffiWs_VhBd+PEedaShfhAuA@mail.gmail.com>

Hi Amos,

It was definitely ignorance of the tools on my part. I am using curl
for testing my setup.
I was using different URLs (different host/IP address as part of URL)
when issuing request to to Squid. That caused the problem I observed.

I read about Curl tool and found out that I can set Host header.
So when I set Host header to same value in all curl commands, cache
hits are happening as I was expecting it to. Access.log shows clearly
that the URLs are same.

So I can say that squid has solved our problem nicely.

A few words about our setup. Squid is used as a reverse caching proxy.

Our application serves video fragments. We use HLS (HTTP Live
streaming) where a given video is broken up into small fragments and
served on demand. Since transcoding to different formats and bit rates
is CPU intensive, we want to cache frequently accessed video
fragments.

Also, we use CARP to make sure that  requests for all fragments of a
given video file go to same backend webserver, because it would not
have do download the single large video file from backend server.

Thanks to this mailing list I have been able to successfully use squid.

rgds,
Sreenath


On 12/18/15, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 18/12/2015 1:21 a.m., Sreenath BH wrote:
>> Hi,
>>
>> Thanks for the detailed response. I really appreciate it.
>>
>> Unfortunately the load balancer we use is not a squid load balancer
>> and for now I will have to use HTCP.
>>
>> Please take a look at the following lines from access.log of one of
>> the three squid servers.
>> ------------
>> 1450351827.534      0 10.135.83.129 UDP_HIT/000 0 HTCP_TST
>> http://127.0.0.1:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?size=xs&start=0.000&end=5.930&
>> - HIER_NONE/- -
>>
>> 1450351827.562     20 10.135.83.129 TCP_HIT/200 553852 GET
>> http://127.0.0.1:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?
>> - HIER_NONE/- video/mp2t
>>
>> 1450352028.731      0 10.135.83.128 UDP_MISS/000 0 HTCP_TST
>> http://10.135.83.128:3128/media/stream/video/NDo3ZDY1OTRjOS02NjM4LTQyNDMtOGMyNi0zYTc3YmI1MzI3ZjAubXA0?size=xs&start=0.000&end=5.930&
>> - HIER_NONE/- -
>> --------
>>
>> The first line indicates a hit when queried by a peer. Note that the
>> IP address is 127.0.0.1.
>> It was a UDP HIT and it was followed by the actual request for the
>> cached object, which succeeded.
>>
>> Now the third line indicates UDP query for same object, except that
>> URL has a different IP address, and the log says it was a MISS.
>>
>> I don't know what I am doing wrong, but it consistently seems to treat
>> the IP address as part of the URL for purpose of HIT/MISS decision.
>
>
> Notice how the normal HTTP request (TCP_* line) is also using
> "127.0.0.1" for origin server name.
>
> This means the two HTCP requests really are for two very different URLs.
> Completely different origin servers being contacted.
>
>
>>
>> If all requests were made from a local client(say using curl running
>> locally on the machine) and using 127.0.0.1 as IP address, HTCP works
>> correctly.
>
> What is the output of "squid -v" ?
>
> And beyond being a layer of caches behind a LB. What is the purpose of
> this installation;
>  reverse-proxy / CDN ?
>  ISP forward/explicit proxy farm?
>  Intranet gateway?
>  some mix of the above?
>
> and what is your full squid.conf ? (without comments and empty lines of
> course).
>
>
> What exactly are the clients (curl) requesting?
>  from the Squid siblings directly? or through the LB?
>
>
>>
>> Even without HTCP, just issuing same request from localhost and
>> another machine using a the externally visible IP address, squid does
>> not appear to use cached object. I am new to HTTP and think I must be
>> doing something wrong, but cant say what.
>
> Huh? Those log lines you posted above contradict. The first HTCP said
> HIT and the TCP object fetch was served from the cache. The second said
> MISS on the other URL, so no TCP fetch.
>
> The sibling lookup and HTCP appears to be working perfectly correct.
>
>>
>> I wonder if ICP would have fared better since it uses just the URL.
>> Might that be a reason?
>
> No. ICP always fares worse. It says UDP_HIT in a lot of cases where the
> URL is same but the followup TCP fetch discovers HTTP mime headers
> negotiating some variant object not in the sibling cache. So UDP_HIT
> followed by TCP_MISS.
>  That is almost the worst-case scenario: it causes a minimum of 2x proxy
> processing latency delays on the whole transaction from the client
> viewpoint. Unltimate worst-case is where a whole chain of parallel
> siblings get relayed through due to UDP_MISS with N times the latency
> multiplication.
>
> At least with HTCP trying to fetch variants results in UDP_MISS. That is
> the second-best *good* result.
>
>
> That is all irrelevant to this case though. Since the raw-IP is part of
> the URL, both of these siblings are working correctly.
>
>
> Problem is why is the raw-IP with port 3128 part of the URL? It smells
> like a miscnfiguration or bad design somewhere. The answers to my above
> questions should help find the solution to that.
>
> Amos
>
>


From squid3 at treenet.co.nz  Fri Dec 18 15:48:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 19 Dec 2015 04:48:54 +1300
Subject: [squid-users] SSTP_DUPLEX_POST method
In-Reply-To: <241CD68BD7EF6D4D8CE0A53F4166F57E3A7861CC@exchange.jurox>
References: <241CD68BD7EF6D4D8CE0A53F4166F57E3A784842@exchange.jurox>
 <566FBFBA.3080500@ngtech.co.il>
 <241CD68BD7EF6D4D8CE0A53F4166F57E3A7861CC@exchange.jurox>
Message-ID: <56742AE6.6000809@treenet.co.nz>

On 17/12/2015 4:57 p.m., Wayne Gillan wrote:
> Yes SSTP is a type of SSL VPN. Why behind a reverse proxy? Well just like other SSL services I need to share port 443 with one public IP address.
> 

Port 443 is not a generic SSL port. It is the registered port for HTTPS.
Any protocol using that port MUST be able to handle HTTP transformations


> I've run packet captures on the client, vpn server and squid. The request is getting through ok and the vpn server is sending a reply. But squid is not forwarding the reply to the client I believe. Here's some snippets of the squid log:
> 
> 2015/12/17 14:26:48.550| http.cc(762) processReplyHeader: HTTP Server REPLY:
> ---------
> HTTP/1.1 200
> Content-Length: 18446744073709551615
> Server: Microsoft-HTTPAPI/2.0
> Date: Thu, 17 Dec 2015 03:26:48 GMT
> ----------
> 2015/12/17 14:26:48.556| client_side.cc(1377) sendStartOfMessage: HTTP Client local=ip.of.squid:443 remote=1.2.3.4:44582 FD 9 flags=1
> 2015/12/17 14:26:48.556| client_side.cc(1378) sendStartOfMessage: HTTP Client REPLY:
> ---------
> HTTP/1.1 200 OK
> Content-Length: 18446744073709551615
> Server: Microsoft-HTTPAPI/2.0
> Date: Thu, 17 Dec 2015 03:26:48 GMT
> X-Cache: MISS from 
> X-Cache-Lookup: MISS from :443
> Connection: keep-alive
> ----------

This is what Squid sent to the client.

> 2015/12/17 14:26:48.557| client_side_reply.cc(1114) storeNotOKTransferDone: storeNotOKTransferDone  out.size=240 expectedLength=-9223372036854775569

Note the very large negative number. That is a 64-bit wrap.

It is wrong for the application to be sending that value. It is claiming
that it has an object of size 18.4 Exabytes ready to send. What it
actually has is a non-HTTP tunnel, of *unknown* length.

Regardless, with 2^64 bytes of data object plus 240 bytes of headers
there is no way Squid can represent the message size. Let alone log it
properly if it ever completes. Squid should be detecting that and
producing a 5xx error.



> 2015/12/17 14:26:48.557| client_side.cc(1827) stopSending: sending error (local=ip.of.squid:443 remote=1.2.3.4:44582 FD 9 flags=1): STREAM_UNPLANNED_COMPLETE; old receiving error: none
> 
> 2015/12/17 14:26:48.673| Server.cc(362) sentRequestBody: sentRequestBody called
> 2015/12/17 14:26:48.673| Server.cc(423) sendMoreRequestBody: will wait for more request body bytes or eof
> 
> 
> Seems like the large value of the Content-Length header field is causing issues. Squid waits for more data but the server never sends it because it's waiting for something from the client. 
> 
> Is there any way to make squid just pass traffic exactly as it comes in?

By the application using HTTP syntax properly. *Omitting* Content-Length
header on responses where there is no in-advance known object size.

Amos



From vze2k3sa at verizon.net  Fri Dec 18 16:24:00 2015
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Fri, 18 Dec 2015 11:24:00 -0500
Subject: [squid-users] Slow App through Proxy
Message-ID: <00b401d139b0$845782d0$8d068870$@verizon.net>

Hello,

 

We have an app configured to use Squid Proxy (3.5.11). The client machine
does not have access to the internet except for the whitelisted domains in
Squid. The app launches painfully slow. It seems to be SSL Certificate
related. I found a way to fix it but don't know why it fixes it. Let me
explain.

 

If I go into IE and configure it to use the Squid Proxy and I go to our
website (SSL Based), the page comes up fine with a nice lock symbol
signifying SSL. I then turn off the proxy config in IE to stop using the
Squid Proxy. I relaunch our app and it launches fast forever more!!! I
thought that it might be downloading a certificate but I look at all the
Windows certificates either through IE or CertMgr.msc and it appears that no
new certificates are in there after this exercise. Something in the Windows
config changed and I don't know what it is. I would love to know because I
would like to see if there is an easier method to fix this as opposed to the
one I just outlined.

 

Any input would be greatly appreciated.

 

Patrick

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151218/91433714/attachment.htm>

From gkinkie at gmail.com  Fri Dec 18 17:51:26 2015
From: gkinkie at gmail.com (Kinkie)
Date: Fri, 18 Dec 2015 18:51:26 +0100
Subject: [squid-users] Slow App through Proxy
In-Reply-To: <00b401d139b0$845782d0$8d068870$@verizon.net>
References: <00b401d139b0$845782d0$8d068870$@verizon.net>
Message-ID: <CA+Y8hcOc5jgMtSf5---CuDyU4A_M7vfAgjba-q7QxsVaeqqeZg@mail.gmail.com>

Hi,
  Do you see anything denied in the squid logs? From what you say it could
be related to a failing attempt to validate a certificate.
On Dec 18, 2015 17:25, "Patrick Flaherty" <vze2k3sa at verizon.net> wrote:

> Hello,
>
>
>
> We have an app configured to use Squid Proxy (3.5.11). The client machine
> does not have access to the internet except for the whitelisted domains in
> Squid. The app launches painfully slow. It seems to be SSL Certificate
> related. I found a way to fix it but don?t know why it fixes it. Let me
> explain.
>
>
>
> If I go into IE and configure it to use the Squid Proxy and I go to our
> website (SSL Based), the page comes up fine with a nice lock symbol
> signifying SSL. I then turn off the proxy config in IE to stop using the
> Squid Proxy. I relaunch our app and it launches fast forever more!!! I
> thought that it might be downloading a certificate but I look at all the
> Windows certificates either through IE or CertMgr.msc and it appears that
> no new certificates are in there after this exercise. Something in the
> Windows config changed and I don?t know what it is. I would love to know
> because I would like to see if there is an easier method to fix this as
> opposed to the one I just outlined.
>
>
>
> Any input would be greatly appreciated.
>
>
>
> Patrick
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151218/7a48beeb/attachment.htm>

From dc.sqml at ntcomputer.de  Fri Dec 18 19:52:27 2015
From: dc.sqml at ntcomputer.de (dc)
Date: Fri, 18 Dec 2015 20:52:27 +0100
Subject: [squid-users] CVE-2009-0801
Message-ID: <567463FB.9000605@ntcomputer.de>

Hello,

please help me to understand the issue of CVE-2009-0801. Description of
the CVE:

"Squid, when transparent interception mode is enabled, uses the HTTP
Host header to determine the remote endpoint, which allows remote
attackers to bypass access controls for Flash, Java, Silverlight, and
probably other technologies, and possibly communicate with restricted
intranet sites, via a crafted web page that causes a client to send HTTP
requests with a modified Host header."

Looking at source code, to mitigate this issue, effectively
client_dst_passthru is enforced even when client_dst_passthru is set to
off in the configuration, when a mismatch between DNS resolved addresses
und original request destination address is detected.

I do not really understand how a possible attack could look like, could
you provide an example?

Many thanks!
Nikolaus


From squid3 at treenet.co.nz  Fri Dec 18 22:14:49 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 19 Dec 2015 11:14:49 +1300
Subject: [squid-users] CVE-2009-0801
In-Reply-To: <567463FB.9000605@ntcomputer.de>
References: <567463FB.9000605@ntcomputer.de>
Message-ID: <56748559.4010905@treenet.co.nz>

On 19/12/2015 8:52 a.m., dc wrote:
> Hello,
> 
> please help me to understand the issue of CVE-2009-0801. Description of
> the CVE:
> 
> "Squid, when transparent interception mode is enabled, uses the HTTP
> Host header to determine the remote endpoint, which allows remote
> attackers to bypass access controls for Flash, Java, Silverlight, and
> probably other technologies, and possibly communicate with restricted
> intranet sites, via a crafted web page that causes a client to send HTTP
> requests with a modified Host header."
> 
> Looking at source code, to mitigate this issue, effectively
> client_dst_passthru is enforced even when client_dst_passthru is set to
> off in the configuration, when a mismatch between DNS resolved addresses
> und original request destination address is detected.
> 
> I do not really understand how a possible attack could look like, could
> you provide an example?

The problem(s):

With CVE-2009-0801 the ORIGINAL_DST signals arriving at Squid look like
TCP IP:port for some ServerA.example.net domain. But the HTTP message
contains something different like:

 GET /logo.jpg HTTP/1.1
 Host: attacker.example.com

The browser Same-Origin and sandbox Origin security protections ensure
that sandboxed scripts can only open TCP connections to the same origin
server(s) they are scoped for. But scripts can send any header values
they like, including fake Host on that connection once it is open.

If Squid were to use the Host header to route the message in any
situation where the ORIGINAL_DST details do not match the Host DNS
records. Then Squid would be fetching and delivering some content into a
browser sandbox from a server that sandbox did not permit.

The fix for that is to simply fetch form the ORIGINAL_DST server
IP:port. Acting as if the proxy were not there.

BUT ... the proxy actually is there, so the cache has to be accounted
for. That stores things by URL. This causes Vuln #2 below if we use the
Host value as domain name like it is supposed to be. And if we don't the
proxy outgoing Host header is mandatory to re-write to the URL host
portion. Meaning the outbound traffic would have raw-IP:port for the
domain name.


Vuln #2:  the attacker script can cause hijacking of popular content
URLs simply by fetching the above request from its own malicious server
with Host:google.com.
[no CVE for this bit since no published Squid was ever vulnerable].

This is not just bypassing the its own sandbox protection, but causing
its attack payload to be delivered in future to another sandbox (on its
own machine OR any other machine using the proxy) in the followup proxy
cache HITs. That payload has escaped its own origin sandbox and now runs
with whatever permissions and data access the victims domain normally
has access to (plus the ability to jump again buy hijacking any of that
sandboxes valid servers/URLs).

The fix we chose to use is not to cache anything where the Host vs DNS
is not matching.

BUT ... PAIN ... it turns out rather a *lot* of content have been using
systems where the Host and origin server DNS do not match all the time.
Everything using Akamai CDN, Google web hosting, Geo-based DNS services,
so called "client-based HTTP routing" as done by some popular AV
vendors, and many other smaller sites for odd reasons. Or at least they
dont match when the DNS is looked up through two different DNS routing
paths.


The alternative would be to use raw-IP port on the URL and outgoing Host
value. That latter is mandatory but breaks Virtual Hosting on these
messages. Given the particular providers whose actions cause the pain;
breaking virtual hosting would be far worse than not caching. The common
cases are anyway low-HIT content or major providers with high speed
networks (very low MISS latency).

So the fix we use is to verify the DNS and Host details match. Only
allowing cache storage and/or Host message routing when they do.


This still leaves us with pain in all those situations where non-match
happens. There are no fixes for that, just workarounds to iprove the
chances of matching.


PS. The two vulnerabilities have been known about since at least 1990's.
The original choice was to leave the CVE-2009-0801 behaviour happening
to improve caching (and same-origin, sandbox etc did not exist back
then). But nowdays the browser protections do exist, and in 2009 active
malware was found using the proxy behaviour to escape it. So the CVE got
allocated and we had to fix. Opening the second vulnerability was never
an option, so we are where we are now.


PPS. ideas or attempts at resolving the HIT side effect is welcome. Just
be aware that every attempt so far has lead to one or other
vulnerability being re-opened and neither is acceptible behaviour. So
having what appears to be a good idea shot down and rejected is normal
when attacking this problem (it took a good year to get the fix as far
as it is).

Amos



From squid3 at treenet.co.nz  Fri Dec 18 22:27:44 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 19 Dec 2015 11:27:44 +1300
Subject: [squid-users] Slow App through Proxy
In-Reply-To: <CA+Y8hcOc5jgMtSf5---CuDyU4A_M7vfAgjba-q7QxsVaeqqeZg@mail.gmail.com>
References: <00b401d139b0$845782d0$8d068870$@verizon.net>
 <CA+Y8hcOc5jgMtSf5---CuDyU4A_M7vfAgjba-q7QxsVaeqqeZg@mail.gmail.com>
Message-ID: <56748860.1050306@treenet.co.nz>

On 19/12/2015 6:51 a.m., Kinkie wrote:
> Hi,
>   Do you see anything denied in the squid logs? From what you say it could
> be related to a failing attempt to validate a certificate.
> On Dec 18, 2015 17:25, "Patrick Flaherty" wrote:
> 
>> Hello,
>>
>>
>>
>> We have an app configured to use Squid Proxy (3.5.11). The client machine
>> does not have access to the internet except for the whitelisted domains in
>> Squid. The app launches painfully slow. It seems to be SSL Certificate
>> related. I found a way to fix it but don?t know why it fixes it. Let me
>> explain.
>>
>>
>>
>> If I go into IE and configure it to use the Squid Proxy and I go to our
>> website (SSL Based), the page comes up fine with a nice lock symbol
>> signifying SSL. I then turn off the proxy config in IE to stop using the
>> Squid Proxy. I relaunch our app and it launches fast forever more!!! I
>> thought that it might be downloading a certificate but I look at all the
>> Windows certificates either through IE or CertMgr.msc and it appears that
>> no new certificates are in there after this exercise. Something in the
>> Windows config changed and I don?t know what it is. I would love to know
>> because I would like to see if there is an easier method to fix this as
>> opposed to the one I just outlined.
>>
>>

Several other things could have happened:
* HSTS headers from the server are received by the browser,
* Alternative-Protocol headers received by the browser,
* CRL and OSCP browser lookups without the proxy,
* or any combo of the above.

Alternative-Protocol is particularly bad since it can cause the browser
to move away from HTTP entirely and use some other protocol. Chrome has
a thing for moving traffic from HTTP to Google custom protocols. MSIE
should be pretty good though it might move to HTTP/2.

HSTS requires the browser to start directly with a secure protocol
rather than HTTP (ie through the proxy). When combined with
Alternative-Protocol the two could potentially force HTTP and the proxy
to cease being even considered as a traffic route (if browser thinks the
other protocol is more secure).

Since these happen inside the CONNECT tunnel use to go through an
explicit-proxy Squid does not have a chance to prevent the
Alternative-Protocol taking effect.

OSCP and CRL are annoying but friendly enough to proxy.  Just find out
what the needed URI are and ensure they are permitted through the proxy.

Amos


From dc.sqml at ntcomputer.de  Fri Dec 18 23:30:23 2015
From: dc.sqml at ntcomputer.de (dc)
Date: Sat, 19 Dec 2015 00:30:23 +0100
Subject: [squid-users] CVE-2009-0801
In-Reply-To: <56748559.4010905@treenet.co.nz>
References: <567463FB.9000605@ntcomputer.de> <56748559.4010905@treenet.co.nz>
Message-ID: <5674970F.5060600@ntcomputer.de>

Thank you very much for this detailed explanation!

I have a setup where squid doesn't know about the original destination
IP address, so I tried to enforce using DNS responses as destination
addresses for any request, without success. Looking at the relevant code
I found the limitation (and CVE) to be quite obscure, but now I know why
it's there.
Since the vulnerability can't be exploited in my case anyway, I have
altered the code to allow the replacement of the destination address
regardless of a mismatch of the original dst.

Best regards
Nikolaus

Am 18.12.2015 um 23:14 schrieb Amos Jeffries:
>
> The problem(s):
>
> With CVE-2009-0801 the ORIGINAL_DST signals arriving at Squid look like
> TCP IP:port for some ServerA.example.net domain. But the HTTP message
> contains something different like:
>
>  GET /logo.jpg HTTP/1.1
>  Host: attacker.example.com
>
> The browser Same-Origin and sandbox Origin security protections ensure
> that sandboxed scripts can only open TCP connections to the same origin
> server(s) they are scoped for. But scripts can send any header values
> they like, including fake Host on that connection once it is open.
>
> If Squid were to use the Host header to route the message in any
> situation where the ORIGINAL_DST details do not match the Host DNS
> records. Then Squid would be fetching and delivering some content into a
> browser sandbox from a server that sandbox did not permit.
>
> The fix for that is to simply fetch form the ORIGINAL_DST server
> IP:port. Acting as if the proxy were not there.
>
> BUT ... the proxy actually is there, so the cache has to be accounted
> for. That stores things by URL. This causes Vuln #2 below if we use the
> Host value as domain name like it is supposed to be. And if we don't the
> proxy outgoing Host header is mandatory to re-write to the URL host
> portion. Meaning the outbound traffic would have raw-IP:port for the
> domain name.
>
>
> Vuln #2:  the attacker script can cause hijacking of popular content
> URLs simply by fetching the above request from its own malicious server
> with Host:google.com.
> [no CVE for this bit since no published Squid was ever vulnerable].
>
> This is not just bypassing the its own sandbox protection, but causing
> its attack payload to be delivered in future to another sandbox (on its
> own machine OR any other machine using the proxy) in the followup proxy
> cache HITs. That payload has escaped its own origin sandbox and now runs
> with whatever permissions and data access the victims domain normally
> has access to (plus the ability to jump again buy hijacking any of that
> sandboxes valid servers/URLs).
>
> The fix we chose to use is not to cache anything where the Host vs DNS
> is not matching.
>
> BUT ... PAIN ... it turns out rather a *lot* of content have been using
> systems where the Host and origin server DNS do not match all the time.
> Everything using Akamai CDN, Google web hosting, Geo-based DNS services,
> so called "client-based HTTP routing" as done by some popular AV
> vendors, and many other smaller sites for odd reasons. Or at least they
> dont match when the DNS is looked up through two different DNS routing
> paths.
>
>
> The alternative would be to use raw-IP port on the URL and outgoing Host
> value. That latter is mandatory but breaks Virtual Hosting on these
> messages. Given the particular providers whose actions cause the pain;
> breaking virtual hosting would be far worse than not caching. The common
> cases are anyway low-HIT content or major providers with high speed
> networks (very low MISS latency).
>
> So the fix we use is to verify the DNS and Host details match. Only
> allowing cache storage and/or Host message routing when they do.
>
>
> This still leaves us with pain in all those situations where non-match
> happens. There are no fixes for that, just workarounds to iprove the
> chances of matching.
>
>
> PS. The two vulnerabilities have been known about since at least 1990's.
> The original choice was to leave the CVE-2009-0801 behaviour happening
> to improve caching (and same-origin, sandbox etc did not exist back
> then). But nowdays the browser protections do exist, and in 2009 active
> malware was found using the proxy behaviour to escape it. So the CVE got
> allocated and we had to fix. Opening the second vulnerability was never
> an option, so we are where we are now.
>
>
> PPS. ideas or attempts at resolving the HIT side effect is welcome. Just
> be aware that every attempt so far has lead to one or other
> vulnerability being re-opened and neither is acceptible behaviour. So
> having what appears to be a good idea shot down and rejected is normal
> when attacking this problem (it took a good year to get the fix as far
> as it is).
>
> Amos
>



From squid3 at treenet.co.nz  Fri Dec 18 23:52:06 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 19 Dec 2015 12:52:06 +1300
Subject: [squid-users] CVE-2009-0801
In-Reply-To: <5674970F.5060600@ntcomputer.de>
References: <567463FB.9000605@ntcomputer.de> <56748559.4010905@treenet.co.nz>
 <5674970F.5060600@ntcomputer.de>
Message-ID: <56749C26.4010808@treenet.co.nz>

On 19/12/2015 12:30 p.m., dc wrote:
> Thank you very much for this detailed explanation!
> 
> I have a setup where squid doesn't know about the original destination
> IP address,

Why not?
* NAT/TPROXY is mandatory to happen on the Squid machine directly since
kernel and Squid are performing integrated operations.
* PROXY protocol passes the ORIGINAL_DST explicitly over the wire.
* SSL-Bump all happens "inside Squid".

Those are the only forms of interception Squid supports.


> so I tried to enforce using DNS responses as destination
> addresses for any request, without success. Looking at the relevant code
> I found the limitation (and CVE) to be quite obscure, but now I know why
> it's there.
> Since the vulnerability can't be exploited in my case anyway, I have
> altered the code to allow the replacement of the destination address
> regardless of a mismatch of the original dst.

If you are intercepting it can always be exploited. The browser sandbox
is just the easiest/common way to do so, with a known malware strain.
Any client capable of sending requests via an interception proxy can
achieve the same result with normal TCP connections.

If you are not intercepting then it is not relevant. Misconfigured
reverse proxy need to be fixed in the squid.conf and network design levels.

Amos



From ventura.jeanchristophe at gmail.com  Sat Dec 19 18:56:10 2015
From: ventura.jeanchristophe at gmail.com (Jean Christophe Ventura)
Date: Sat, 19 Dec 2015 19:56:10 +0100
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
Message-ID: <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>

Hi,

I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.

I have migrated the config files to be 3.3 compliant (CIDR, remove of
deprecated function,change cache from UFS to AUFS) without any change
(cache mem, policy, smp)

The new platform is a 4 node R610 (24 proc hyperthreading activate)
with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
is connected to the network using 2x1Gbit bonding 2/3 level (some
network port are available on the server).

bandwidth allocated for Internet users 400Mbit

The difference between the old plateform and the new one doesn't seem
to be very fantastic :P
I have read the mailing list history alot.

Squid release:
So i know 3.3 isn't anymore maintain but this infrastructure will be
not maintain by myself and i don't think that people behind will do
the update them self
If a official repository exist, maybe this question will be reopen
(from what i have read it's more some of you build packages from
source and give them to people)

Squid auth:
It's transparent/basic auth only filtering some ip with acl.

Squid bandwidth:
Currently a squid node treat something like 30/50Mbit (information
recovered using iftop)
>From previous viewed mail i think it's normal for a non-smp configuration

Squid measure:
[root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
client_http.requests = 233.206612/sec
other info
Cache information for squid:
        Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
        Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
        Memory hits as % of hit requests:       5min: 21.4%, 60min: 21.5%
        Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
        Storage Swap size:      9573016 KB
        Storage Swap capacity:  91.3% used,  8.7% free
        Storage Mem size:       519352 KB
        Storage Mem capacity:   99.1% used,  0.9% free
        Mean Object Size:       47.71 KB

Now question and advise :

This metrics seem too low for me. anyone of you agree ?

4 node x 50Mbit node= 200Mbit
To treat the maxbandwidth (400Mbit) + the lost of one host i need to
configure 4 thread by node.
Is there any reason or brillant idea for more (i will have some core
still available) ? calculation too empirical ?

This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
seem to be a good start :P
Using this method i can interconnect each proxy to share their cache
(maybe using dedicated network port). Usefull or not ? may this
increase the hit ratio ? if this idea is'nt stupid interconnet using
the frontend only or directy to each ?

For now i have :
- 100GB of disk available for cache
- 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)

1 front with the RAM cache and 4 back with disk cache.
AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
(i think it's will be linked to the cache content but any advise or
method is welcome)

I can get more speed and/or space for disk cache using SAN, do you
know if the data is sequential or random ?

Any advise/rules to increase the hit ratio ? :)
Any general advise/rules ?

Thanks for your help


Jean Christophe VENTURA


From yvoinov at gmail.com  Sat Dec 19 19:36:47 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 20 Dec 2015 01:36:47 +0600
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
 <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
Message-ID: <5675B1CF.3020608@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Did your configure SSL Bump?

Ever since Squid 2.7 eternity. The world has changed and now the bulk of
the traffic is https. Which in general is not cached or must not cached
for many reasons.

And even in this case, Squid 3.3 too antique. I have updated to at least
version 3.5.


20.12.15 0:56, Jean Christophe Ventura ?????:
> Hi,
>
> I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
>
> I have migrated the config files to be 3.3 compliant (CIDR, remove of
> deprecated function,change cache from UFS to AUFS) without any change
> (cache mem, policy, smp)
>
> The new platform is a 4 node R610 (24 proc hyperthreading activate)
> with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> is connected to the network using 2x1Gbit bonding 2/3 level (some
> network port are available on the server).
>
> bandwidth allocated for Internet users 400Mbit
>
> The difference between the old plateform and the new one doesn't seem
> to be very fantastic :P
> I have read the mailing list history alot.
>
> Squid release:
> So i know 3.3 isn't anymore maintain but this infrastructure will be
> not maintain by myself and i don't think that people behind will do
> the update them self
> If a official repository exist, maybe this question will be reopen
> (from what i have read it's more some of you build packages from
> source and give them to people)
>
> Squid auth:
> It's transparent/basic auth only filtering some ip with acl.
>
> Squid bandwidth:
> Currently a squid node treat something like 30/50Mbit (information
> recovered using iftop)
> From previous viewed mail i think it's normal for a non-smp configuration
>
> Squid measure:
> [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> client_http.requests = 233.206612/sec
> other info
> Cache information for squid:
>         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
>         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
>         Memory hits as % of hit requests:       5min: 21.4%, 60min: 21.5%
>         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
>         Storage Swap size:      9573016 KB
>         Storage Swap capacity:  91.3% used,  8.7% free
>         Storage Mem size:       519352 KB
>         Storage Mem capacity:   99.1% used,  0.9% free
>         Mean Object Size:       47.71 KB
>
> Now question and advise :
>
> This metrics seem too low for me. anyone of you agree ?
>
> 4 node x 50Mbit node= 200Mbit
> To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> configure 4 thread by node.
> Is there any reason or brillant idea for more (i will have some core
> still available) ? calculation too empirical ?
>
> This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> seem to be a good start :P
> Using this method i can interconnect each proxy to share their cache
> (maybe using dedicated network port). Usefull or not ? may this
> increase the hit ratio ? if this idea is'nt stupid interconnet using
> the frontend only or directy to each ?
>
> For now i have :
> - 100GB of disk available for cache
> - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
>
> 1 front with the RAM cache and 4 back with disk cache.
> AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> (i think it's will be linked to the cache content but any advise or
> method is welcome)
>
> I can get more speed and/or space for disk cache using SAN, do you
> know if the data is sequential or random ?
>
> Any advise/rules to increase the hit ratio ? :)
> Any general advise/rules ?
>
> Thanks for your help
>
>
> Jean Christophe VENTURA
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWdbHPAAoJENNXIZxhPexGizoIAM3CBf4DkJKybKh25ST4DBrz
2h790u7XgUpKrUYq+aZ4X1m55hNHsIgdOtsNpNXSZUtoYyCSRwM0nSYLHPm47Ov4
31nkO3/7hYfQoOkw514ZwGvI8YfkZJhBUZ8Nupev3HoRpbPMFf6XGaRji2LIFine
tne5JrOkQb2fkY0ev1FakPW8qcEzNtgDHC/2aoumxaq2MSKCPz34+j4W1QBYUDgy
ob7Dt7iT2bXb2pfLyXETY5K/7rznBLcMXcAaXcT6gxTOjGUpHZyq/QuZK4Db6WoD
45PwJelTkoSz8HFzajW6Du/5XItxejcLzvJq0X/wMzCvMFJaLzaL+FU49raDUl8=
=J9OH
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Sat Dec 19 19:39:13 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 20 Dec 2015 01:39:13 +0600
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
 <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
Message-ID: <5675B261.20401@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I do not understand the love of archaeological fossils. It repositories
such junk lying around? :-D

20.12.15 0:56, Jean Christophe Ventura ?????:
> Hi,
>
> I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
>
> I have migrated the config files to be 3.3 compliant (CIDR, remove of
> deprecated function,change cache from UFS to AUFS) without any change
> (cache mem, policy, smp)
>
> The new platform is a 4 node R610 (24 proc hyperthreading activate)
> with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> is connected to the network using 2x1Gbit bonding 2/3 level (some
> network port are available on the server).
>
> bandwidth allocated for Internet users 400Mbit
>
> The difference between the old plateform and the new one doesn't seem
> to be very fantastic :P
> I have read the mailing list history alot.
>
> Squid release:
> So i know 3.3 isn't anymore maintain but this infrastructure will be
> not maintain by myself and i don't think that people behind will do
> the update them self
> If a official repository exist, maybe this question will be reopen
> (from what i have read it's more some of you build packages from
> source and give them to people)
>
> Squid auth:
> It's transparent/basic auth only filtering some ip with acl.
>
> Squid bandwidth:
> Currently a squid node treat something like 30/50Mbit (information
> recovered using iftop)
> From previous viewed mail i think it's normal for a non-smp configuration
>
> Squid measure:
> [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> client_http.requests = 233.206612/sec
> other info
> Cache information for squid:
>         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
>         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
>         Memory hits as % of hit requests:       5min: 21.4%, 60min: 21.5%
>         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
>         Storage Swap size:      9573016 KB
>         Storage Swap capacity:  91.3% used,  8.7% free
>         Storage Mem size:       519352 KB
>         Storage Mem capacity:   99.1% used,  0.9% free
>         Mean Object Size:       47.71 KB
>
> Now question and advise :
>
> This metrics seem too low for me. anyone of you agree ?
>
> 4 node x 50Mbit node= 200Mbit
> To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> configure 4 thread by node.
> Is there any reason or brillant idea for more (i will have some core
> still available) ? calculation too empirical ?
>
> This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> seem to be a good start :P
> Using this method i can interconnect each proxy to share their cache
> (maybe using dedicated network port). Usefull or not ? may this
> increase the hit ratio ? if this idea is'nt stupid interconnet using
> the frontend only or directy to each ?
>
> For now i have :
> - 100GB of disk available for cache
> - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
>
> 1 front with the RAM cache and 4 back with disk cache.
> AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> (i think it's will be linked to the cache content but any advise or
> method is welcome)
>
> I can get more speed and/or space for disk cache using SAN, do you
> know if the data is sequential or random ?
>
> Any advise/rules to increase the hit ratio ? :)
> Any general advise/rules ?
>
> Thanks for your help
>
>
> Jean Christophe VENTURA
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWdbJhAAoJENNXIZxhPexGXSsIAIlKiu7C+Bw8a7XMxObb/NKw
WF8Ms77hGIfbcAdVm3zIoAeQinWLdXMU5XqYZLRUFyq1ui86bvxZoYa8VKcXIMgY
Uxyg+Un3S5nAWy0TePU3Q0DdixW96QGAPXvQAEJUAXNEWUnCiArwQt4aRZFOHBzT
HE3bsyjJZWgHKpW7YV+rrD6vffwfsn1G7BmCG1CDTjfnkdbW73M7slwUMVPTolVV
jVLp0y07VPGDg3iMVG8XMSmeCnPYIVfJk+0VMtmX2pv87voxWU2AQfrcJXXa0Jjm
f/YWBAOQS20C+2GaH2OAIQ1kr0+yOgpBRfiAhNlUrQ933BmVDCzepH/ZokxVHvQ=
=E5Oo
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Sat Dec 19 19:44:15 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 20 Dec 2015 01:44:15 +0600
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
 <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
Message-ID: <5675B38F.7020509@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You're digging in the wrong direction. The problem is not Squid's
technical tricks - there is no any magic button - but the fact that the
world - and the Web with it - indeed changed dramatically. Two things -
dynamic content and https. Dig in this direction.

20.12.15 0:56, Jean Christophe Ventura ?????:
> Hi,
>
> I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
>
> I have migrated the config files to be 3.3 compliant (CIDR, remove of
> deprecated function,change cache from UFS to AUFS) without any change
> (cache mem, policy, smp)
>
> The new platform is a 4 node R610 (24 proc hyperthreading activate)
> with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> is connected to the network using 2x1Gbit bonding 2/3 level (some
> network port are available on the server).
>
> bandwidth allocated for Internet users 400Mbit
>
> The difference between the old plateform and the new one doesn't seem
> to be very fantastic :P
> I have read the mailing list history alot.
>
> Squid release:
> So i know 3.3 isn't anymore maintain but this infrastructure will be
> not maintain by myself and i don't think that people behind will do
> the update them self
> If a official repository exist, maybe this question will be reopen
> (from what i have read it's more some of you build packages from
> source and give them to people)
>
> Squid auth:
> It's transparent/basic auth only filtering some ip with acl.
>
> Squid bandwidth:
> Currently a squid node treat something like 30/50Mbit (information
> recovered using iftop)
> From previous viewed mail i think it's normal for a non-smp configuration
>
> Squid measure:
> [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> client_http.requests = 233.206612/sec
> other info
> Cache information for squid:
>         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
>         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
>         Memory hits as % of hit requests:       5min: 21.4%, 60min: 21.5%
>         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
>         Storage Swap size:      9573016 KB
>         Storage Swap capacity:  91.3% used,  8.7% free
>         Storage Mem size:       519352 KB
>         Storage Mem capacity:   99.1% used,  0.9% free
>         Mean Object Size:       47.71 KB
>
> Now question and advise :
>
> This metrics seem too low for me. anyone of you agree ?
>
> 4 node x 50Mbit node= 200Mbit
> To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> configure 4 thread by node.
> Is there any reason or brillant idea for more (i will have some core
> still available) ? calculation too empirical ?
>
> This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> seem to be a good start :P
> Using this method i can interconnect each proxy to share their cache
> (maybe using dedicated network port). Usefull or not ? may this
> increase the hit ratio ? if this idea is'nt stupid interconnet using
> the frontend only or directy to each ?
>
> For now i have :
> - 100GB of disk available for cache
> - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
>
> 1 front with the RAM cache and 4 back with disk cache.
> AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> (i think it's will be linked to the cache content but any advise or
> method is welcome)
>
> I can get more speed and/or space for disk cache using SAN, do you
> know if the data is sequential or random ?
>
> Any advise/rules to increase the hit ratio ? :)
> Any general advise/rules ?
>
> Thanks for your help
>
>
> Jean Christophe VENTURA
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWdbOOAAoJENNXIZxhPexGK0UH/iHWC2t1Tp3+dJwwcnBJTbC6
CgnZwdA/9VNCGgo08/FFQ07Gtq5HWZD9i3UBedGv4kIaNcQfgjXaDBE++aktmWlk
fnIfzIDasw0nNpaFuBThS8LDV6/KCAurfulyVNNDHGshlFPpYTGhFowx3zQvgusV
tkbxnfvI3gi7s0gYZNVpzDrwymHwOOXThLTvGXdMyMLloTN9HoDvB9Z7Q8bU3Ofy
JMJ2ZJJau41zMmFQNMnnMAbfC4Pz+oFHvRJFZLjKiy4YAzwcMniXLMx55xEFWvB0
BDhjnJiw2UElHtJzYk70upi9fAlD4jFsMrtzmXBTWSmCkY70cS6J5lUNMDmr17k=
=XjNX
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Sat Dec 19 19:49:08 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 20 Dec 2015 01:49:08 +0600
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
 <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
Message-ID: <5675B4B4.7070504@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Bad news. To get a premium level of cache hits, it requires a very
non-trivial configuration of Squid. Also very much it is required to
ignore the requirements of the standard HTTP, to write from scratch you
own cache configuration.You need to configure caching https - which in
itself is a separate challenge.

20.12.15 0:56, Jean Christophe Ventura ?????:
> Hi,
>
> I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
>
> I have migrated the config files to be 3.3 compliant (CIDR, remove of
> deprecated function,change cache from UFS to AUFS) without any change
> (cache mem, policy, smp)
>
> The new platform is a 4 node R610 (24 proc hyperthreading activate)
> with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> is connected to the network using 2x1Gbit bonding 2/3 level (some
> network port are available on the server).
>
> bandwidth allocated for Internet users 400Mbit
>
> The difference between the old plateform and the new one doesn't seem
> to be very fantastic :P
> I have read the mailing list history alot.
>
> Squid release:
> So i know 3.3 isn't anymore maintain but this infrastructure will be
> not maintain by myself and i don't think that people behind will do
> the update them self
> If a official repository exist, maybe this question will be reopen
> (from what i have read it's more some of you build packages from
> source and give them to people)
>
> Squid auth:
> It's transparent/basic auth only filtering some ip with acl.
>
> Squid bandwidth:
> Currently a squid node treat something like 30/50Mbit (information
> recovered using iftop)
> From previous viewed mail i think it's normal for a non-smp configuration
>
> Squid measure:
> [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> client_http.requests = 233.206612/sec
> other info
> Cache information for squid:
>         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
>         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
>         Memory hits as % of hit requests:       5min: 21.4%, 60min: 21.5%
>         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
>         Storage Swap size:      9573016 KB
>         Storage Swap capacity:  91.3% used,  8.7% free
>         Storage Mem size:       519352 KB
>         Storage Mem capacity:   99.1% used,  0.9% free
>         Mean Object Size:       47.71 KB
>
> Now question and advise :
>
> This metrics seem too low for me. anyone of you agree ?
>
> 4 node x 50Mbit node= 200Mbit
> To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> configure 4 thread by node.
> Is there any reason or brillant idea for more (i will have some core
> still available) ? calculation too empirical ?
>
> This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> seem to be a good start :P
> Using this method i can interconnect each proxy to share their cache
> (maybe using dedicated network port). Usefull or not ? may this
> increase the hit ratio ? if this idea is'nt stupid interconnet using
> the frontend only or directy to each ?
>
> For now i have :
> - 100GB of disk available for cache
> - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
>
> 1 front with the RAM cache and 4 back with disk cache.
> AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> (i think it's will be linked to the cache content but any advise or
> method is welcome)
>
> I can get more speed and/or space for disk cache using SAN, do you
> know if the data is sequential or random ?
>
> Any advise/rules to increase the hit ratio ? :)
> Any general advise/rules ?
>
> Thanks for your help
>
>
> Jean Christophe VENTURA
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWdbS0AAoJENNXIZxhPexGUB8H/0a0Tda/7gth0eYC7UfiDxGF
7fNTP5+kIfO2UOj8S8s9IvKknTwVxOqW+7tecr+9rhR/9F5Mc1UPD+svHqIrMzCZ
hDp40bQem0dofZ8Bzfte5PMQjTjeqcvnvcMmB+Le9P+/oU23CmKPhKvNyh91YutJ
T0rb4HqK4yTdW+/CU2ErZAceUpSoi/cOcTd6q81tmLJbDCmw6OEuErSZmIfwkwqm
bSmTOCp/eTyju5J5Mvt+B9QTMrEaGQCz8IbWCzTt8sEt6k5TDdo+ZfBct3qHEk29
mjQTXEZicNNRFpj8q7WY88tp0HD76NlMwfnBHccwKmDQHyWqB6JQSMVmxQkJbA4=
=IYh/
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Sat Dec 19 19:51:19 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 20 Dec 2015 01:51:19 +0600
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
 <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
Message-ID: <5675B537.4090104@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I'm sorry that upset. :)

20.12.15 0:56, Jean Christophe Ventura ?????:
> Hi,
>
> I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
>
> I have migrated the config files to be 3.3 compliant (CIDR, remove of
> deprecated function,change cache from UFS to AUFS) without any change
> (cache mem, policy, smp)
>
> The new platform is a 4 node R610 (24 proc hyperthreading activate)
> with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> is connected to the network using 2x1Gbit bonding 2/3 level (some
> network port are available on the server).
>
> bandwidth allocated for Internet users 400Mbit
>
> The difference between the old plateform and the new one doesn't seem
> to be very fantastic :P
> I have read the mailing list history alot.
>
> Squid release:
> So i know 3.3 isn't anymore maintain but this infrastructure will be
> not maintain by myself and i don't think that people behind will do
> the update them self
> If a official repository exist, maybe this question will be reopen
> (from what i have read it's more some of you build packages from
> source and give them to people)
>
> Squid auth:
> It's transparent/basic auth only filtering some ip with acl.
>
> Squid bandwidth:
> Currently a squid node treat something like 30/50Mbit (information
> recovered using iftop)
> From previous viewed mail i think it's normal for a non-smp configuration
>
> Squid measure:
> [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> client_http.requests = 233.206612/sec
> other info
> Cache information for squid:
>         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
>         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
>         Memory hits as % of hit requests:       5min: 21.4%, 60min: 21.5%
>         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
>         Storage Swap size:      9573016 KB
>         Storage Swap capacity:  91.3% used,  8.7% free
>         Storage Mem size:       519352 KB
>         Storage Mem capacity:   99.1% used,  0.9% free
>         Mean Object Size:       47.71 KB
>
> Now question and advise :
>
> This metrics seem too low for me. anyone of you agree ?
>
> 4 node x 50Mbit node= 200Mbit
> To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> configure 4 thread by node.
> Is there any reason or brillant idea for more (i will have some core
> still available) ? calculation too empirical ?
>
> This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> seem to be a good start :P
> Using this method i can interconnect each proxy to share their cache
> (maybe using dedicated network port). Usefull or not ? may this
> increase the hit ratio ? if this idea is'nt stupid interconnet using
> the frontend only or directy to each ?
>
> For now i have :
> - 100GB of disk available for cache
> - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
>
> 1 front with the RAM cache and 4 back with disk cache.
> AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> (i think it's will be linked to the cache content but any advise or
> method is welcome)
>
> I can get more speed and/or space for disk cache using SAN, do you
> know if the data is sequential or random ?
>
> Any advise/rules to increase the hit ratio ? :)
> Any general advise/rules ?
>
> Thanks for your help
>
>
> Jean Christophe VENTURA
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWdbU3AAoJENNXIZxhPexG2hYH/izsN//pqXXTxRE/DyE+6L0y
u3HwM7Aiyia5LVrt7juBDrb6Th/YMHBT4zgCd9Q3tcHXz2TBuM1YX4cOO+ap7kEv
pdhTORmeErUkw3EHlKuWfCiLodnOu5d9iwbxJ2W8fUqj+rnLWlw3kVeN5DSFgGVm
hxmzFQF7dTOzAPripVnzlEnimcj3bK2fiEx4YN0d+lqakxqCSUNMUYj5O34zgsZS
zGSf4byR3FOamzk9jIUMg4FN7CogbAa0elaRr/XyBpyCTlKJ4LvRq7diB2H0Xsyi
cW5XkjE2pxpblFCJ7Cj6tHlYFDdRNDOzzWf5T2+F2EkDz14MGWZj2BQD2BKYGQA=
=CML0
-----END PGP SIGNATURE-----



From ventura.jeanchristophe at gmail.com  Sat Dec 19 19:53:01 2015
From: ventura.jeanchristophe at gmail.com (Jean Christophe Ventura)
Date: Sat, 19 Dec 2015 20:53:01 +0100
Subject: [squid-users] Fwd: Squid configuration advise
Message-ID: <CAA-A7MrkXWhgfLXFz_cckfK7dhCMOHMYQtY7Uy2n_wSMY0MXHw@mail.gmail.com>

Well

If it was my project : archlinux using yaourt and each needed package
compiled in a VM

I work at a company as sysadmin and proxy aren't in my side (network
things...)
So if i can configure a repository or sync a repository with the response :
go head it will be here for years.., if not i have to deal with distrib
package :P

Even in a VM i prefered a debian server than a RHEL
By the way the good thing it's not a AIX proxy ;)

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

I do not understand the love of archaeological fossils. It repositories
such junk lying around? :-D

20.12.15 0:56, Jean Christophe Ventura ?????:
> Hi,
>
> I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
>
> I have migrated the config files to be 3.3 compliant (CIDR, remove of
> deprecated function,change cache from UFS to AUFS) without any change
> (cache mem, policy, smp)
>
> The new platform is a 4 node R610 (24 proc hyperthreading activate)
> with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> is connected to the network using 2x1Gbit bonding 2/3 level (some
> network port are available on the server).
>
> bandwidth allocated for Internet users 400Mbit
>
> The difference between the old plateform and the new one doesn't seem
> to be very fantastic :P
> I have read the mailing list history alot.
>
> Squid release:
> So i know 3.3 isn't anymore maintain but this infrastructure will be
> not maintain by myself and i don't think that people behind will do
> the update them self
> If a official repository exist, maybe this question will be reopen
> (from what i have read it's more some of you build packages from
> source and give them to people)
>
> Squid auth:
> It's transparent/basic auth only filtering some ip with acl.
>
> Squid bandwidth:
> Currently a squid node treat something like 30/50Mbit (information
> recovered using iftop)
> From previous viewed mail i think it's normal for a non-smp configuration
>
> Squid measure:
> [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> client_http.requests = 233.206612/sec
> other info
> Cache information for squid:
>         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
>         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
>         Memory hits as % of hit requests:       5min: 21.4%, 60min: 21.5%
>         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
>         Storage Swap size:      9573016 KB
>         Storage Swap capacity:  91.3% used,  8.7% free
>         Storage Mem size:       519352 KB
>         Storage Mem capacity:   99.1% used,  0.9% free
>         Mean Object Size:       47.71 KB
>
> Now question and advise :
>
> This metrics seem too low for me. anyone of you agree ?
>
> 4 node x 50Mbit node= 200Mbit
> To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> configure 4 thread by node.
> Is there any reason or brillant idea for more (i will have some core
> still available) ? calculation too empirical ?
>
> This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> seem to be a good start :P
> Using this method i can interconnect each proxy to share their cache
> (maybe using dedicated network port). Usefull or not ? may this
> increase the hit ratio ? if this idea is'nt stupid interconnet using
> the frontend only or directy to each ?
>
> For now i have :
> - 100GB of disk available for cache
> - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
>
> 1 front with the RAM cache and 4 back with disk cache.
> AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> (i think it's will be linked to the cache content but any advise or
> method is welcome)
>
> I can get more speed and/or space for disk cache using SAN, do you
> know if the data is sequential or random ?
>
> Any advise/rules to increase the hit ratio ? :)
> Any general advise/rules ?
>
> Thanks for your help
>
>
> Jean Christophe VENTURA
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJWdbJhAAoJENNXIZxhPexGXSsIAIlKiu7C+Bw8a7XMxObb/NKw
WF8Ms77hGIfbcAdVm3zIoAeQinWLdXMU5XqYZLRUFyq1ui86bvxZoYa8VKcXIMgY
Uxyg+Un3S5nAWy0TePU3Q0DdixW96QGAPXvQAEJUAXNEWUnCiArwQt4aRZFOHBzT
HE3bsyjJZWgHKpW7YV+rrD6vffwfsn1G7BmCG1CDTjfnkdbW73M7slwUMVPTolVV
jVLp0y07VPGDg3iMVG8XMSmeCnPYIVfJk+0VMtmX2pv87voxWU2AQfrcJXXa0Jjm
f/YWBAOQS20C+2GaH2OAIQ1kr0+yOgpBRfiAhNlUrQ933BmVDCzepH/ZokxVHvQ=
=E5Oo
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151219/66678f8b/attachment.htm>

From yvoinov at gmail.com  Sat Dec 19 19:56:21 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 20 Dec 2015 01:56:21 +0600
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <CAA-A7MrkXWhgfLXFz_cckfK7dhCMOHMYQtY7Uy2n_wSMY0MXHw@mail.gmail.com>
References: <CAA-A7MrkXWhgfLXFz_cckfK7dhCMOHMYQtY7Uy2n_wSMY0MXHw@mail.gmail.com>
Message-ID: <5675B665.3070209@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
AIX great system in good hands. ;)

All the matter in the gasket between the seats and the console. :D

20.12.15 1:53, Jean Christophe Ventura ?????:
> Well
>
> If it was my project : archlinux using yaourt and each needed package
> compiled in a VM
>
> I work at a company as sysadmin and proxy aren't in my side (network
> things...)
> So if i can configure a repository or sync a repository with the
response :
> go head it will be here for years.., if not i have to deal with distrib
> package :P
>
> Even in a VM i prefered a debian server than a RHEL
> By the way the good thing it's not a AIX proxy ;)
>
> I do not understand the love of archaeological fossils. It repositories
> such junk lying around? :-D
>
> 20.12.15 0:56, Jean Christophe Ventura ?????:
> > Hi,
>
> > I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
>
> > I have migrated the config files to be 3.3 compliant (CIDR, remove of
> > deprecated function,change cache from UFS to AUFS) without any change
> > (cache mem, policy, smp)
>
> > The new platform is a 4 node R610 (24 proc hyperthreading activate)
> > with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> > is connected to the network using 2x1Gbit bonding 2/3 level (some
> > network port are available on the server).
>
> > bandwidth allocated for Internet users 400Mbit
>
> > The difference between the old plateform and the new one doesn't seem
> > to be very fantastic :P
> > I have read the mailing list history alot.
>
> > Squid release:
> > So i know 3.3 isn't anymore maintain but this infrastructure will be
> > not maintain by myself and i don't think that people behind will do
> > the update them self
> > If a official repository exist, maybe this question will be reopen
> > (from what i have read it's more some of you build packages from
> > source and give them to people)
>
> > Squid auth:
> > It's transparent/basic auth only filtering some ip with acl.
>
> > Squid bandwidth:
> > Currently a squid node treat something like 30/50Mbit (information
> > recovered using iftop)
> > From previous viewed mail i think it's normal for a non-smp
configuration
>
> > Squid measure:
> > [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> > client_http.requests = 233.206612/sec
> > other info
> > Cache information for squid:
> >         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
> >         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
> >         Memory hits as % of hit requests:       5min: 21.4%, 60min:
21.5%
> >         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
> >         Storage Swap size:      9573016 KB
> >         Storage Swap capacity:  91.3% used,  8.7% free
> >         Storage Mem size:       519352 KB
> >         Storage Mem capacity:   99.1% used,  0.9% free
> >         Mean Object Size:       47.71 KB
>
> > Now question and advise :
>
> > This metrics seem too low for me. anyone of you agree ?
>
> > 4 node x 50Mbit node= 200Mbit
> > To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> > configure 4 thread by node.
> > Is there any reason or brillant idea for more (i will have some core
> > still available) ? calculation too empirical ?
>
> > This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> > seem to be a good start :P
> > Using this method i can interconnect each proxy to share their cache
> > (maybe using dedicated network port). Usefull or not ? may this
> > increase the hit ratio ? if this idea is'nt stupid interconnet using
> > the frontend only or directy to each ?
>
> > For now i have :
> > - 100GB of disk available for cache
> > - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
>
> > 1 front with the RAM cache and 4 back with disk cache.
> > AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> > (i think it's will be linked to the cache content but any advise or
> > method is welcome)
>
> > I can get more speed and/or space for disk cache using SAN, do you
> > know if the data is sequential or random ?
>
> > Any advise/rules to increase the hit ratio ? :)
> > Any general advise/rules ?
>
> > Thanks for your help
>
>
> > Jean Christophe VENTURA
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWdbZlAAoJENNXIZxhPexGrRoH/3c+Fdii20mZJQplh5iayrQY
H2oQwYJhSw4S61NonryqPTLAxgfa8Q2De7LCpfhk52vWUvNk27WSRekQFEbs8mNO
AHthD1uNegGg0rJqLyRmLdPEArECtyTFSg7sZADWFenUphxHjYZZKPrz3qEb357X
pjA2PrNOo2i8bKVtDlTQP/mElnUoHSWG+GJWf/CROiB5/hUdwcyfagkTyB8mjqFo
b0FYj+d0KT4mtawWLOoIa06S1cIeUUVsyHGcodqD9rwTsNjKI3QiXWQFwCi+ToAf
Jrk1958Q3QjvqOaiYpCGAwpaeU7K02Prsa3WclLtud0gvXuDSq9uhI65Z32XyAQ=
=sIHo
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151220/b463340b/attachment.htm>

From ventura.jeanchristophe at gmail.com  Sat Dec 19 19:59:58 2015
From: ventura.jeanchristophe at gmail.com (Jean Christophe Ventura)
Date: Sat, 19 Dec 2015 20:59:58 +0100
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <5675B537.4090104@gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
 <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
 <5675B537.4090104@gmail.com>
Message-ID: <CAA-A7Mp9f7L2T3OTg32uJCBw5PA-_a06B6eMToL1qSGigF8=7A@mail.gmail.com>

Reading the mailing list i know that sslbump is the question to get a more
usefull hit.

But this proxy infrastructure isn't acting as my company proxy but isp
proxy for the company client and i cann't go to this way without some guy
like lawers/security guys :)

I know there is no magic button to get the full internet at home ;) but at
least my job with this project constraint is to get the best i can :)

2015-12-19 20:51 GMT+01:00 Yuri Voinov <yvoinov at gmail.com>:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> I'm sorry that upset. :)
>
> 20.12.15 0:56, Jean Christophe Ventura ?????:
> > Hi,
> >
> > I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
> >
> > I have migrated the config files to be 3.3 compliant (CIDR, remove of
> > deprecated function,change cache from UFS to AUFS) without any change
> > (cache mem, policy, smp)
> >
> > The new platform is a 4 node R610 (24 proc hyperthreading activate)
> > with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> > is connected to the network using 2x1Gbit bonding 2/3 level (some
> > network port are available on the server).
> >
> > bandwidth allocated for Internet users 400Mbit
> >
> > The difference between the old plateform and the new one doesn't seem
> > to be very fantastic :P
> > I have read the mailing list history alot.
> >
> > Squid release:
> > So i know 3.3 isn't anymore maintain but this infrastructure will be
> > not maintain by myself and i don't think that people behind will do
> > the update them self
> > If a official repository exist, maybe this question will be reopen
> > (from what i have read it's more some of you build packages from
> > source and give them to people)
> >
> > Squid auth:
> > It's transparent/basic auth only filtering some ip with acl.
> >
> > Squid bandwidth:
> > Currently a squid node treat something like 30/50Mbit (information
> > recovered using iftop)
> > From previous viewed mail i think it's normal for a non-smp configuration
> >
> > Squid measure:
> > [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> > client_http.requests = 233.206612/sec
> > other info
> > Cache information for squid:
> >         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
> >         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
> >         Memory hits as % of hit requests:       5min: 21.4%, 60min: 21.5%
> >         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
> >         Storage Swap size:      9573016 KB
> >         Storage Swap capacity:  91.3% used,  8.7% free
> >         Storage Mem size:       519352 KB
> >         Storage Mem capacity:   99.1% used,  0.9% free
> >         Mean Object Size:       47.71 KB
> >
> > Now question and advise :
> >
> > This metrics seem too low for me. anyone of you agree ?
> >
> > 4 node x 50Mbit node= 200Mbit
> > To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> > configure 4 thread by node.
> > Is there any reason or brillant idea for more (i will have some core
> > still available) ? calculation too empirical ?
> >
> > This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> > seem to be a good start :P
> > Using this method i can interconnect each proxy to share their cache
> > (maybe using dedicated network port). Usefull or not ? may this
> > increase the hit ratio ? if this idea is'nt stupid interconnet using
> > the frontend only or directy to each ?
> >
> > For now i have :
> > - 100GB of disk available for cache
> > - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
> >
> > 1 front with the RAM cache and 4 back with disk cache.
> > AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> > (i think it's will be linked to the cache content but any advise or
> > method is welcome)
> >
> > I can get more speed and/or space for disk cache using SAN, do you
> > know if the data is sequential or random ?
> >
> > Any advise/rules to increase the hit ratio ? :)
> > Any general advise/rules ?
> >
> > Thanks for your help
> >
> >
> > Jean Christophe VENTURA
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJWdbU3AAoJENNXIZxhPexG2hYH/izsN//pqXXTxRE/DyE+6L0y
> u3HwM7Aiyia5LVrt7juBDrb6Th/YMHBT4zgCd9Q3tcHXz2TBuM1YX4cOO+ap7kEv
> pdhTORmeErUkw3EHlKuWfCiLodnOu5d9iwbxJ2W8fUqj+rnLWlw3kVeN5DSFgGVm
> hxmzFQF7dTOzAPripVnzlEnimcj3bK2fiEx4YN0d+lqakxqCSUNMUYj5O34zgsZS
> zGSf4byR3FOamzk9jIUMg4FN7CogbAa0elaRr/XyBpyCTlKJ4LvRq7diB2H0Xsyi
> cW5XkjE2pxpblFCJ7Cj6tHlYFDdRNDOzzWf5T2+F2EkDz14MGWZj2BQD2BKYGQA=
> =CML0
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151219/d80f566e/attachment.htm>

From yvoinov at gmail.com  Sat Dec 19 20:02:05 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 20 Dec 2015 02:02:05 +0600
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <CAA-A7Mp9f7L2T3OTg32uJCBw5PA-_a06B6eMToL1qSGigF8=7A@mail.gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
 <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
 <5675B537.4090104@gmail.com>
 <CAA-A7Mp9f7L2T3OTg32uJCBw5PA-_a06B6eMToL1qSGigF8=7A@mail.gmail.com>
Message-ID: <5675B7BD.806@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
My best result I can achieve this day with 3.5.12 is:

http://i.imgur.com/Lm6MkwH.png

Maximum hit level is 50-55%. With VERY complex configuration.

With old good 3.4.14 I achieved cache hit over 86%, but this is in the past.

20.12.15 1:59, Jean Christophe Ventura ?????:
> Reading the mailing list i know that sslbump is the question to get a more
> usefull hit.
>
> But this proxy infrastructure isn't acting as my company proxy but isp
> proxy for the company client and i cann't go to this way without some guy
> like lawers/security guys :)
>
> I know there is no magic button to get the full internet at home ;) but at
> least my job with this project constraint is to get the best i can :)
>
> 2015-12-19 20:51 GMT+01:00 Yuri Voinov <yvoinov at gmail.com>:
>
>>
> I'm sorry that upset. :)
>
> 20.12.15 0:56, Jean Christophe Ventura ?????:
> >>> Hi,
> >>>
> >>> I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
> >>>
> >>> I have migrated the config files to be 3.3 compliant (CIDR, remove of
> >>> deprecated function,change cache from UFS to AUFS) without any change
> >>> (cache mem, policy, smp)
> >>>
> >>> The new platform is a 4 node R610 (24 proc hyperthreading activate)
> >>> with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> >>> is connected to the network using 2x1Gbit bonding 2/3 level (some
> >>> network port are available on the server).
> >>>
> >>> bandwidth allocated for Internet users 400Mbit
> >>>
> >>> The difference between the old plateform and the new one doesn't seem
> >>> to be very fantastic :P
> >>> I have read the mailing list history alot.
> >>>
> >>> Squid release:
> >>> So i know 3.3 isn't anymore maintain but this infrastructure will be
> >>> not maintain by myself and i don't think that people behind will do
> >>> the update them self
> >>> If a official repository exist, maybe this question will be reopen
> >>> (from what i have read it's more some of you build packages from
> >>> source and give them to people)
> >>>
> >>> Squid auth:
> >>> It's transparent/basic auth only filtering some ip with acl.
> >>>
> >>> Squid bandwidth:
> >>> Currently a squid node treat something like 30/50Mbit (information
> >>> recovered using iftop)
> >>> From previous viewed mail i think it's normal for a non-smp
configuration
> >>>
> >>> Squid measure:
> >>> [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> >>> client_http.requests = 233.206612/sec
> >>> other info
> >>> Cache information for squid:
> >>>         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
> >>>         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
> >>>         Memory hits as % of hit requests:       5min: 21.4%,
60min: 21.5%
> >>>         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
> >>>         Storage Swap size:      9573016 KB
> >>>         Storage Swap capacity:  91.3% used,  8.7% free
> >>>         Storage Mem size:       519352 KB
> >>>         Storage Mem capacity:   99.1% used,  0.9% free
> >>>         Mean Object Size:       47.71 KB
> >>>
> >>> Now question and advise :
> >>>
> >>> This metrics seem too low for me. anyone of you agree ?
> >>>
> >>> 4 node x 50Mbit node= 200Mbit
> >>> To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> >>> configure 4 thread by node.
> >>> Is there any reason or brillant idea for more (i will have some core
> >>> still available) ? calculation too empirical ?
> >>>
> >>> This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> >>> seem to be a good start :P
> >>> Using this method i can interconnect each proxy to share their cache
> >>> (maybe using dedicated network port). Usefull or not ? may this
> >>> increase the hit ratio ? if this idea is'nt stupid interconnet using
> >>> the frontend only or directy to each ?
> >>>
> >>> For now i have :
> >>> - 100GB of disk available for cache
> >>> - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
> >>>
> >>> 1 front with the RAM cache and 4 back with disk cache.
> >>> AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> >>> (i think it's will be linked to the cache content but any advise or
> >>> method is welcome)
> >>>
> >>> I can get more speed and/or space for disk cache using SAN, do you
> >>> know if the data is sequential or random ?
> >>>
> >>> Any advise/rules to increase the hit ratio ? :)
> >>> Any general advise/rules ?
> >>>
> >>> Thanks for your help
> >>>
> >>>
> >>> Jean Christophe VENTURA
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWdbe9AAoJENNXIZxhPexGnnMIAJCpFZJVppW4auNDES0Z1SOX
Essle25MJ1yKh3BkkkRhJa4pJjCa/9fYrnTwOTQ3IFDvuILbesjxxtIBkbBjEvzi
Ka5oHoKokN8/9kMwDjBUYUua8aHqDhPaQ197bD6HZTzX5nzq3DU3Wnoa8jkyLSX9
LJiNbdYhvbJN4CH3ui8Q0JOKlTbYM43Jc0mTfW/K3Rv2Yv68EzYTwx7OeniXyMNO
SitP72nntqntAOL48s9stG9vr3j0bPZRu/ejcW4LoTbj719nuhSYeB7a0mTgStZp
Y1Elcm61cTefFgG9Cvggnr8mkp1AionnZHffPmkaZDzuParz6UMsHcCKmZFH4BE=
=y1hW
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151220/4870ca69/attachment.htm>

From ventura.jeanchristophe at gmail.com  Sat Dec 19 20:05:55 2015
From: ventura.jeanchristophe at gmail.com (Jean Christophe Ventura)
Date: Sat, 19 Dec 2015 21:05:55 +0100
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <5675B665.3070209@gmail.com>
References: <CAA-A7MrkXWhgfLXFz_cckfK7dhCMOHMYQtY7Uy2n_wSMY0MXHw@mail.gmail.com>
 <5675B665.3070209@gmail.com>
Message-ID: <CAA-A7Mo-g8Cyp8EtA2gbg-bKNwaq4ObcpF=KnktcmmTGjrdMFg@mail.gmail.com>

powerpc is a good cpu
AIX.. well i know it a litte bit but even IBM doesn't like it anymore (lot
of stuff under powerpc but not under AIX, spectrum scale and other ibm
slideware)

some time you get more powerhorse under a RHEL/PowerPC than AIX/PowerPC
even with the IBM AIX support... it's life and like other sysadmin we go to
the best OS when we have choice ;)


2015-12-19 20:56 GMT+01:00 Yuri Voinov <yvoinov at gmail.com>:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> AIX great system in good hands. ;)
>
> All the matter in the gasket between the seats and the console. :D
>
> 20.12.15 1:53, Jean Christophe Ventura ?????:
> > Well
> >
> > If it was my project : archlinux using yaourt and each needed package
> > compiled in a VM
> >
> > I work at a company as sysadmin and proxy aren't in my side (network
> > things...)
> > So if i can configure a repository or sync a repository with the
> response :
> > go head it will be here for years.., if not i have to deal with distrib
> > package :P
> >
> > Even in a VM i prefered a debian server than a RHEL
> > By the way the good thing it's not a AIX proxy ;)
> >
> > I do not understand the love of archaeological fossils. It repositories
> > such junk lying around? :-D
> >
> > 20.12.15 0:56, Jean Christophe Ventura ?????:
> > > Hi,
> >
> > > I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
> >
> > > I have migrated the config files to be 3.3 compliant (CIDR, remove of
> > > deprecated function,change cache from UFS to AUFS) without any change
> > > (cache mem, policy, smp)
> >
> > > The new platform is a 4 node R610 (24 proc hyperthreading activate)
> > > with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> > > is connected to the network using 2x1Gbit bonding 2/3 level (some
> > > network port are available on the server).
> >
> > > bandwidth allocated for Internet users 400Mbit
> >
> > > The difference between the old plateform and the new one doesn't seem
> > > to be very fantastic :P
> > > I have read the mailing list history alot.
> >
> > > Squid release:
> > > So i know 3.3 isn't anymore maintain but this infrastructure will be
> > > not maintain by myself and i don't think that people behind will do
> > > the update them self
> > > If a official repository exist, maybe this question will be reopen
> > > (from what i have read it's more some of you build packages from
> > > source and give them to people)
> >
> > > Squid auth:
> > > It's transparent/basic auth only filtering some ip with acl.
> >
> > > Squid bandwidth:
> > > Currently a squid node treat something like 30/50Mbit (information
> > > recovered using iftop)
> > > From previous viewed mail i think it's normal for a non-smp
> configuration
> >
> > > Squid measure:
> > > [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> > > client_http.requests = 233.206612/sec
> > > other info
> > > Cache information for squid:
> > >         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
> > >         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
> > >         Memory hits as % of hit requests:       5min: 21.4%, 60min:
> 21.5%
> > >         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
> > >         Storage Swap size:      9573016 KB
> > >         Storage Swap capacity:  91.3% used,  8.7% free
> > >         Storage Mem size:       519352 KB
> > >         Storage Mem capacity:   99.1% used,  0.9% free
> > >         Mean Object Size:       47.71 KB
> >
> > > Now question and advise :
> >
> > > This metrics seem too low for me. anyone of you agree ?
> >
> > > 4 node x 50Mbit node= 200Mbit
> > > To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> > > configure 4 thread by node.
> > > Is there any reason or brillant idea for more (i will have some core
> > > still available) ? calculation too empirical ?
> >
> > > This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> > > seem to be a good start :P
> > > Using this method i can interconnect each proxy to share their cache
> > > (maybe using dedicated network port). Usefull or not ? may this
> > > increase the hit ratio ? if this idea is'nt stupid interconnet using
> > > the frontend only or directy to each ?
> >
> > > For now i have :
> > > - 100GB of disk available for cache
> > > - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
> >
> > > 1 front with the RAM cache and 4 back with disk cache.
> > > AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> > > (i think it's will be linked to the cache content but any advise or
> > > method is welcome)
> >
> > > I can get more speed and/or space for disk cache using SAN, do you
> > > know if the data is sequential or random ?
> >
> > > Any advise/rules to increase the hit ratio ? :)
> > > Any general advise/rules ?
> >
> > > Thanks for your help
> >
> >
> > > Jean Christophe VENTURA
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJWdbZlAAoJENNXIZxhPexGrRoH/3c+Fdii20mZJQplh5iayrQY
> H2oQwYJhSw4S61NonryqPTLAxgfa8Q2De7LCpfhk52vWUvNk27WSRekQFEbs8mNO
> AHthD1uNegGg0rJqLyRmLdPEArECtyTFSg7sZADWFenUphxHjYZZKPrz3qEb357X
> pjA2PrNOo2i8bKVtDlTQP/mElnUoHSWG+GJWf/CROiB5/hUdwcyfagkTyB8mjqFo
> b0FYj+d0KT4mtawWLOoIa06S1cIeUUVsyHGcodqD9rwTsNjKI3QiXWQFwCi+ToAf
> Jrk1958Q3QjvqOaiYpCGAwpaeU7K02Prsa3WclLtud0gvXuDSq9uhI65Z32XyAQ=
> =sIHo
> -----END PGP SIGNATURE-----
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151219/eed50b18/attachment.htm>

From ventura.jeanchristophe at gmail.com  Sat Dec 19 20:32:11 2015
From: ventura.jeanchristophe at gmail.com (Jean Christophe Ventura)
Date: Sat, 19 Dec 2015 21:32:11 +0100
Subject: [squid-users] Fwd: Squid configuration advise
In-Reply-To: <5675B7BD.806@gmail.com>
References: <CAA-A7MqhNvAAsgCdyuoz54tY_vgUMV0TXbCHjCrooiuAONo1SQ@mail.gmail.com>
 <CAA-A7Mod2NyVhRnxdtpAPvX+A0a7Rq8A6z_ftJjQ9QYKsmALuA@mail.gmail.com>
 <5675B537.4090104@gmail.com>
 <CAA-A7Mp9f7L2T3OTg32uJCBw5PA-_a06B6eMToL1qSGigF8=7A@mail.gmail.com>
 <5675B7BD.806@gmail.com>
Message-ID: <CAA-A7MqBmfW_veL0EpAS5EtioNygKfM8EY=4rwOnygnS4Q9+aw@mail.gmail.com>

Ok thanks for your info

2015-12-19 21:02 GMT+01:00 Yuri Voinov <yvoinov at gmail.com>:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> My best result I can achieve this day with 3.5.12 is:
>
> http://i.imgur.com/Lm6MkwH.png
>
> Maximum hit level is 50-55%. With VERY complex configuration.
>
> With old good 3.4.14 I achieved cache hit over 86%, but this is in the
> past.
>
> 20.12.15 1:59, Jean Christophe Ventura ?????:
> > Reading the mailing list i know that sslbump is the question to get a
> more
> > usefull hit.
> >
> > But this proxy infrastructure isn't acting as my company proxy but isp
> > proxy for the company client and i cann't go to this way without some guy
> > like lawers/security guys :)
> >
> > I know there is no magic button to get the full internet at home ;) but
> at
> > least my job with this project constraint is to get the best i can :)
> >
> > 2015-12-19 20:51 GMT+01:00 Yuri Voinov <yvoinov at gmail.com>
> <yvoinov at gmail.com>:
> >
> >>
> > I'm sorry that upset. :)
> >
> > 20.12.15 0:56, Jean Christophe Ventura ?????:
> > >>> Hi,
> > >>>
> > >>> I'm currently working to migrate RHEL5 2.7 Squid to RHEL7 3.3.
> > >>>
> > >>> I have migrated the config files to be 3.3 compliant (CIDR, remove of
> > >>> deprecated function,change cache from UFS to AUFS) without any change
> > >>> (cache mem, policy, smp)
> > >>>
> > >>> The new platform is a 4 node R610 (24 proc hyperthreading activate)
> > >>> with 48GB of RAM, only 143GB disk in RAID for OS and cache. Each node
> > >>> is connected to the network using 2x1Gbit bonding 2/3 level (some
> > >>> network port are available on the server).
> > >>>
> > >>> bandwidth allocated for Internet users 400Mbit
> > >>>
> > >>> The difference between the old plateform and the new one doesn't seem
> > >>> to be very fantastic :P
> > >>> I have read the mailing list history alot.
> > >>>
> > >>> Squid release:
> > >>> So i know 3.3 isn't anymore maintain but this infrastructure will be
> > >>> not maintain by myself and i don't think that people behind will do
> > >>> the update them self
> > >>> If a official repository exist, maybe this question will be reopen
> > >>> (from what i have read it's more some of you build packages from
> > >>> source and give them to people)
> > >>>
> > >>> Squid auth:
> > >>> It's transparent/basic auth only filtering some ip with acl.
> > >>>
> > >>> Squid bandwidth:
> > >>> Currently a squid node treat something like 30/50Mbit (information
> > >>> recovered using iftop)
> > >>> From previous viewed mail i think it's normal for a non-smp
> configuration
> > >>>
> > >>> Squid measure:
> > >>> [root at xxxx ~]# squidclient mgr:5min | grep 'client_http.requests'
> > >>> client_http.requests = 233.206612/sec
> > >>> other info
> > >>> Cache information for squid:
> > >>>         Hits as % of all requests:      5min: 6.8%, 60min: 7.1%
> > >>>         Hits as % of bytes sent:        5min: 4.7%, 60min: 4.4%
> > >>>         Memory hits as % of hit requests:       5min: 21.4%, 60min:
> 21.5%
> > >>>         Disk hits as % of hit requests: 5min: 34.7%, 60min: 30.8%
> > >>>         Storage Swap size:      9573016 KB
> > >>>         Storage Swap capacity:  91.3% used,  8.7% free
> > >>>         Storage Mem size:       519352 KB
> > >>>         Storage Mem capacity:   99.1% used,  0.9% free
> > >>>         Mean Object Size:       47.71 KB
> > >>>
> > >>> Now question and advise :
> > >>>
> > >>> This metrics seem too low for me. anyone of you agree ?
> > >>>
> > >>> 4 node x 50Mbit node= 200Mbit
> > >>> To treat the maxbandwidth (400Mbit) + the lost of one host i need to
> > >>> configure 4 thread by node.
> > >>> Is there any reason or brillant idea for more (i will have some core
> > >>> still available) ? calculation too empirical ?
> > >>>
> > >>> This url http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
> > >>> seem to be a good start :P
> > >>> Using this method i can interconnect each proxy to share their cache
> > >>> (maybe using dedicated network port). Usefull or not ? may this
> > >>> increase the hit ratio ? if this idea is'nt stupid interconnet using
> > >>> the frontend only or directy to each ?
> > >>>
> > >>> For now i have :
> > >>> - 100GB of disk available for cache
> > >>> - 40GB   of RAM (let 8 for OS + squid disk cache related ram usage)
> > >>>
> > >>> 1 front with the RAM cache and 4 back with disk cache.
> > >>> AUFS or ROCK cache? mix of them ? 50% each ? maybe another rules ?
> > >>> (i think it's will be linked to the cache content but any advise or
> > >>> method is welcome)
> > >>>
> > >>> I can get more speed and/or space for disk cache using SAN, do you
> > >>> know if the data is sequential or random ?
> > >>>
> > >>> Any advise/rules to increase the hit ratio ? :)
> > >>> Any general advise/rules ?
> > >>>
> > >>> Thanks for your help
> > >>>
> > >>>
> > >>> Jean Christophe VENTURA
> > >>> _______________________________________________
> > >>> squid-users mailing list
> > >>> squid-users at lists.squid-cache.org
> > >>> http://lists.squid-cache.org/listinfo/squid-users
> >
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users
> >>
> >
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJWdbe9AAoJENNXIZxhPexGnnMIAJCpFZJVppW4auNDES0Z1SOX
> Essle25MJ1yKh3BkkkRhJa4pJjCa/9fYrnTwOTQ3IFDvuILbesjxxtIBkbBjEvzi
> Ka5oHoKokN8/9kMwDjBUYUua8aHqDhPaQ197bD6HZTzX5nzq3DU3Wnoa8jkyLSX9
> LJiNbdYhvbJN4CH3ui8Q0JOKlTbYM43Jc0mTfW/K3Rv2Yv68EzYTwx7OeniXyMNO
> SitP72nntqntAOL48s9stG9vr3j0bPZRu/ejcW4LoTbj719nuhSYeB7a0mTgStZp
> Y1Elcm61cTefFgG9Cvggnr8mkp1AionnZHffPmkaZDzuParz6UMsHcCKmZFH4BE=
> =y1hW
> -----END PGP SIGNATURE-----
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151219/d4a2db4e/attachment.htm>

From alex at samad.com.au  Mon Dec 21 01:00:38 2015
From: alex at samad.com.au (Alex Samad)
Date: Mon, 21 Dec 2015 12:00:38 +1100
Subject: [squid-users] squid cache peer issues
Message-ID: <CAJ+Q1PUijVmAvYTaotYr=dWWfP+KhfkS_Dr8p0mm+sLJscYWDA@mail.gmail.com>

Hi

running on centos 6.7

3.5.12 still not available on centos 6.

rpm -qa | grep squid
squid-helpers-3.5.11-1.el6.x86_64
squid-3.5.11-1.el6.x86_64

This is the 2 cache_peer statements I use

# on alcdmz1
cache_peer gsdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
no-query standby=10
#cache_peer alcdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
no-query standby=10

# on gsdmz1
#cache_peer gsdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
no-query standby=10
cache_peer alcdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
no-query standby=10

on alcdmz1 with export http_proxy pointing to alcdmz1

wget -d  http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
-O /dev/null
Setting --output-document (outputdocument) to /dev/null
DEBUG output created by Wget 1.12 on linux-gnu.

--2015-12-21 11:58:05--
http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
Resolving alcdmz1... 10.32.20.111
Caching alcdmz1 => 10.32.20.111
Connecting to alcdmz1|10.32.20.111|:3128... connected.
Created socket 4.
Releasing 0x000000000101d540 (new refcount 1).

---request begin---
GET http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2 HTTP/1.0
User-Agent: Wget/1.12 (linux-gnu)
Accept: */*
Host: fonts.gstatic.com

---request end---
Proxy request sent, awaiting response...
---response begin---
HTTP/1.1 200 OK
Content-Type: font/woff2
Access-Control-Allow-Origin: *
Timing-Allow-Origin: *
Date: Mon, 30 Nov 2015 04:06:16 GMT
Expires: Tue, 29 Nov 2016 04:06:16 GMT
Last-Modified: Mon, 06 Oct 2014 20:40:59 GMT
X-Content-Type-Options: nosniff
Server: sffe
Content-Length: 25604
X-XSS-Protection: 1; mode=block
Cache-Control: public, max-age=31536000
Age: 1803109
Warning: 113 alcdmz1 (squid) This cache hit is still fresh and more
than 1 day old
X-Cache: HIT from alcdmz1
X-Cache-Lookup: HIT from alcdmz1:3128
Via: 1.1 alcdmz1 (squid)
Connection: close

---response end---
200 OK
Length: 25604 (25K) [font/woff2]
Saving to: `/dev/null'

100%[==============================================================================================>]
25,604      --.-K/s   in 0s

Closed fd 4
2015-12-21 11:58:05 (1.01 GB/s) - `/dev/null' saved [25604/25604]


on gsdmz1


wget -d  http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
-O /dev/null
Setting --output-document (outputdocument) to /dev/null
DEBUG output created by Wget 1.12 on linux-gnu.

--2015-12-21 11:58:59--
http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
Resolving gsdmz1... 10.32.20.110
Caching gsdmz1 => 10.32.20.110
Connecting to gsdmz1|10.32.20.110|:3128... connected.
Created socket 4.
Releasing 0x00000000010a2930 (new refcount 1).

---request begin---
GET http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2 HTTP/1.0
User-Agent: Wget/1.12 (linux-gnu)
Accept: */*
Host: fonts.gstatic.com

---request end---
Proxy request sent, awaiting response...
---response begin---
HTTP/1.1 504 Gateway Timeout
Server: squid
Mime-Version: 1.0
Date: Mon, 21 Dec 2015 00:58:59 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3964
X-Squid-Error: ERR_ONLY_IF_CACHED_MISS 0
Vary: Accept-Language
Content-Language: en
Age: 1450659540
Warning: 113 alcdmz1 (squid) This cache hit is still fresh and more
than 1 day old
Warning: 110 squid "Response is stale"
Warning: 111 squid "Revalidation failed"
X-Cache: HIT from alcdmz1
X-Cache-Lookup: HIT from alcdmz1:3128
X-Cache: MISS from gsdmz1
X-Cache-Lookup: MISS from gsdmz1:3128
Via: 1.1 alcdmz1 (squid), 1.1 gsdmz1 (squid)
Connection: close

---response end---
504 Gateway Timeout
Closed fd 4
2015-12-21 11:58:59 ERROR 504: Gateway Timeout.


so why does it work from alc and not from gs ???

A


From squid3 at treenet.co.nz  Mon Dec 21 10:26:45 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 21 Dec 2015 23:26:45 +1300
Subject: [squid-users] squid cache peer issues
In-Reply-To: <CAJ+Q1PUijVmAvYTaotYr=dWWfP+KhfkS_Dr8p0mm+sLJscYWDA@mail.gmail.com>
References: <CAJ+Q1PUijVmAvYTaotYr=dWWfP+KhfkS_Dr8p0mm+sLJscYWDA@mail.gmail.com>
Message-ID: <5677D3E5.6050600@treenet.co.nz>

On 21/12/2015 2:00 p.m., Alex Samad wrote:
> Hi
> 
> running on centos 6.7
> 
> 3.5.12 still not available on centos 6.
> 
> rpm -qa | grep squid
> squid-helpers-3.5.11-1.el6.x86_64
> squid-3.5.11-1.el6.x86_64
> 
> This is the 2 cache_peer statements I use
> 
> # on alcdmz1
> cache_peer gsdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
> no-query standby=10
> #cache_peer alcdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
> no-query standby=10
> 
> # on gsdmz1
> #cache_peer gsdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
> no-query standby=10
> cache_peer alcdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
> no-query standby=10
> 
> on alcdmz1 with export http_proxy pointing to alcdmz1
> 
> wget -d  http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
> -O /dev/null
> Setting --output-document (outputdocument) to /dev/null
> DEBUG output created by Wget 1.12 on linux-gnu.
> 
> --2015-12-21 11:58:05--
> http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
> Resolving alcdmz1... 10.32.20.111
> Caching alcdmz1 => 10.32.20.111
> Connecting to alcdmz1|10.32.20.111|:3128... connected.
> Created socket 4.
> Releasing 0x000000000101d540 (new refcount 1).
> 
> ---request begin---
> GET http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2 HTTP/1.0
> User-Agent: Wget/1.12 (linux-gnu)
> Accept: */*
> Host: fonts.gstatic.com
> 
> ---request end---
> Proxy request sent, awaiting response...
> ---response begin---
> HTTP/1.1 200 OK
> Content-Type: font/woff2
> Access-Control-Allow-Origin: *
> Timing-Allow-Origin: *
> Date: Mon, 30 Nov 2015 04:06:16 GMT
> Expires: Tue, 29 Nov 2016 04:06:16 GMT
> Last-Modified: Mon, 06 Oct 2014 20:40:59 GMT
> X-Content-Type-Options: nosniff
> Server: sffe
> Content-Length: 25604
> X-XSS-Protection: 1; mode=block
> Cache-Control: public, max-age=31536000
> Age: 1803109
> Warning: 113 alcdmz1 (squid) This cache hit is still fresh and more
> than 1 day old
> X-Cache: HIT from alcdmz1
> X-Cache-Lookup: HIT from alcdmz1:3128
> Via: 1.1 alcdmz1 (squid)
> Connection: close
> 
> ---response end---
> 200 OK
> Length: 25604 (25K) [font/woff2]
> Saving to: `/dev/null'
> 
> 100%[==============================================================================================>]
> 25,604      --.-K/s   in 0s
> 
> Closed fd 4
> 2015-12-21 11:58:05 (1.01 GB/s) - `/dev/null' saved [25604/25604]
> 
> 
> on gsdmz1
> 
> 
> wget -d  http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
> -O /dev/null
> Setting --output-document (outputdocument) to /dev/null
> DEBUG output created by Wget 1.12 on linux-gnu.
> 
> --2015-12-21 11:58:59--
> http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
> Resolving gsdmz1... 10.32.20.110
> Caching gsdmz1 => 10.32.20.110
> Connecting to gsdmz1|10.32.20.110|:3128... connected.
> Created socket 4.
> Releasing 0x00000000010a2930 (new refcount 1).
> 
> ---request begin---
> GET http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2 HTTP/1.0
> User-Agent: Wget/1.12 (linux-gnu)
> Accept: */*
> Host: fonts.gstatic.com
> 
> ---request end---
> Proxy request sent, awaiting response...
> ---response begin---
> HTTP/1.1 504 Gateway Timeout
> Server: squid
> Mime-Version: 1.0
> Date: Mon, 21 Dec 2015 00:58:59 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3964
> X-Squid-Error: ERR_ONLY_IF_CACHED_MISS 0
> Vary: Accept-Language
> Content-Language: en
> Age: 1450659540
> Warning: 113 alcdmz1 (squid) This cache hit is still fresh and more
> than 1 day old
> Warning: 110 squid "Response is stale"
> Warning: 111 squid "Revalidation failed"
> X-Cache: HIT from alcdmz1
> X-Cache-Lookup: HIT from alcdmz1:3128
> X-Cache: MISS from gsdmz1
> X-Cache-Lookup: MISS from gsdmz1:3128
> Via: 1.1 alcdmz1 (squid), 1.1 gsdmz1 (squid)
> Connection: close
> 
> ---response end---
> 504 Gateway Timeout
> Closed fd 4
> 2015-12-21 11:58:59 ERROR 504: Gateway Timeout.
> 
> 
> so why does it work from alc and not from gs ???

The alc fetch is going:
  client->alc->Internet/parent

The gs fetch is going:
  client->gs->alc->Internet/parent

This is shown in the Via headers.


The alc sibling has a response cached which matches. But that required a
revalidation. (The 113 and 110 Warning headers)

The revalidation failed for some reason (the only-if-cached ?). So it
output a 504 and sent that back to gs. (The 111 Warning header)

There are several problems here:
1) why the revalidation is failing, and
2) why the gs peer is not re-trying the fetch via another server (parent
or DIRECT) after the 504 happens.
3) The Age header says ~46yrs ago for the 504 being created,
suspiciously close to 1 Jan 1970 / unix epoch 0-second.


It seems to me you have managed to reproduce
<http://bugs.squid-cache.org/show_bug.cgi?id=4223>

Amos



From eliezer at ngtech.co.il  Mon Dec 21 10:57:16 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 21 Dec 2015 12:57:16 +0200
Subject: [squid-users] Squid 3.5.12 RPMs release for CentOS 6 and 7.
In-Reply-To: <565A94A9.1060601@treenet.co.nz>
References: <565A94A9.1060601@treenet.co.nz>
Message-ID: <5677DB0C.9020905@ngtech.co.il>

Published at: http://www1.ngtech.co.il/wpe/?p=166

I am happy to release the new RPMs of squid 3.5.12 for Centos 6 64bit, 
32bit and CentOS 7 64bit.

The new release includes couple bug fixes and improvements.
I have also took the time to build the latest beta 4.0.3 RPM for CentOS 7.
The details about the the RPMs repository are at 
squid-wiki[http://wiki.squid-cache.org/KnowledgeBase/CentOS].

Why 3DES (triple DES)? or The fall of DES.

It is known in the cryptography world that since 1997 DES(IE single DES) 
is vulnerable to some attacks  and there for is being considered to be 
unsafe for some uses. In order to resolve the DES issues the 3DES was 
implemented due to the ability to use the same fast cryptography 
machinery\chips that was used before and by that giving some time to the 
industry to find another more fit solution.
Some words about the DES encryption from Professor Gideon Samid:
[https://www.youtube.com/watch?v=r68Ft_rRZP0]

Hashing compared to Encryption

The difference between hashing  to encryption is the ability to recreate 
the original digested content. Hashes are meant to allow some kind of 
content validation verification based on the low probability of  math 
collisions. To give a simple example about the subject we can use the 
Quadratic Formula:
[http://www1.ngtech.co.il/wpe/wp-content/uploads/2015/12/Quadratic-Formula.jpg]
Quadratic Formula
The formula defines that it is possible (or it is always the right 
answer) to have two answers to the same question\issue\variables.
Based on the fact\assumption that there is a possibility for two 
answers\solutions to the same unknowns+function we can use a function to 
describe more then one number. And in the case of computers which 
everything is some kind of a number we can convert the unknown numbers 
to octets.
Once there is no difference between numbers and\or octets and letters 
and we are in the function computation world. There we can use all sorts 
of functions\equations in order to describe all sorts of numbers and by 
that letters.
Eventually hashes are some kind of known functions which implements some 
way to reflect very big numbers or very big documents in some kind of 
output .  Technically speaking it?s some function\method that is 
guaranteed to reflect very big numbers with probability(high or low) 
that multiple input values  will be reflected with the same output 
number(128 bits for example).
In many levels of applications some hashes such as 
crc32\md5\sha-1\others are being used and these applications allow 
them-self  to validate content integrity with a fully ?vulnerable? hash 
due to the fact that the validated content  do not exceed the function 
collision sizes.
I must admit that I have used MD5 and many other hashes for a very long 
time and the only collisions that I have seen that affected real world 
applications integrity are that of CRC32 hashes, maybe I have not seen 
enough yet!
And couple expert words from Professor Gideon Samid on hashing:
[https://www.youtube.com/watch?v=yXmNmckX4sI]

     Disclaimer: I am not a cryptography expert!

This RPMs release was tested for:

     ICAP 204\206 compatibility (non ssl)
     ECAP passthru adapter which digest response body using SHA256
     refresh_pattern variations
     StoreID patterns
     Basic load testing
     Basic ssl-bump usage in strict forward proxy mode
     Basic denial of memory leaks on a long period time of operation
     Basic build tests

All the above was done on a CentOS 7 x86_64 VMs.
I have not tested everything on CentOS 6 since it is assumed that if it 
works good on CentOS 7 there should not be a special reason for it to 
now work on CentOS 6.

More details about the repository at squid-wiki.

All The Bests,
Eliezer Croitoru

     I have been working on ?Store ID ? The hackers side of the 
feature?[http://wiki.squid-cache.org/Features/StoreID/Hacking]
     And I am planning an update to ?Caching Dynamic Content using 
Adaptation? (which will not include ways to cache 
youtube)[http://wiki.squid-cache.org/ConfigExamples/DynamicContent/Coordinator]




From dc.sqml at ntcomputer.de  Mon Dec 21 13:34:32 2015
From: dc.sqml at ntcomputer.de (dc)
Date: Mon, 21 Dec 2015 14:34:32 +0100
Subject: [squid-users] CVE-2009-0801
In-Reply-To: <56749C26.4010808@treenet.co.nz>
References: <567463FB.9000605@ntcomputer.de> <56748559.4010905@treenet.co.nz>
 <5674970F.5060600@ntcomputer.de> <56749C26.4010808@treenet.co.nz>
Message-ID: <5677FFE8.3070801@ntcomputer.de>


Am 19.12.2015 um 00:52 schrieb Amos Jeffries:
> Why not?
> * NAT/TPROXY is mandatory to happen on the Squid machine directly since
> kernel and Squid are performing integrated operations.
> * PROXY protocol passes the ORIGINAL_DST explicitly over the wire.
> * SSL-Bump all happens "inside Squid".
>
> Those are the only forms of interception Squid supports.
>
Thanks for making that clear! I fixed my setup accordingly. Squid now
gathers original IP addresses from NAT.
I also enabled host_verify_strict, which should make sure requests are
always sent to correct IP addresses. Is there an equivalent setting for
peek-and-spliced HTTPS connections? Or does host_verify_strict cover
that case as well? This would be important, since otherwise a malicious
application could bypass the whitelist ACLs I have installed.

Nikolaus


From tylerd at tuta.io  Mon Dec 21 14:07:14 2015
From: tylerd at tuta.io (tylerd at tuta.io)
Date: Mon, 21 Dec 2015 14:07:14 +0000 (UTC)
Subject: [squid-users] ECDH not working with Squid 4. ERROR: Unable to set
 Ephemeral ECDH: error:00000000:lib(0):func(0):reason(0)
Message-ID: <K63rOBS----0@tuta.io>

Hello,?
I'm having a hard time trying to use ECDH support in Squid and I tried a few 
different releases since v. 4 is out.?Squid version:

Squid Cache: Version 4.0.3-20151216-r14446Service Name: squidconfigure 
options: ?'--with-openssl' '--enable-basic-auth-helpers=squid_radius_auth' 
'--enable-auth' --enable-ltdl-convenience
OpenSSL is 1.0.1q
Relevant https_port settings line in my squid.conf:
https_port 443 cert=/root/ssl/squid.crt key=/root/ssl/squid.key 
tls-cafile=/root/ssl/ca.crt 
cipher=ECDH+AESGCM:DH+AESGCM:ECDH+AES:DH+AES:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS 
tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
When I try to run it, I get the following error:?2015/12/21 09:01:05| ERROR: 
Unable to set Ephemeral ECDH: error:00000000:lib(0):func(0):reason(0)
Full https_port part from the debug when rynning squid -X:
2015/12/21 09:02:24.000| Initializing https_port [::]:443 TLS 
context2015/12/21 09:02:24.001| 24,7| SBuf.cc(180) rawSpace: reserving 1 for 
SBuf1352015/12/21 09:02:24.001| 24,7| SBuf.cc(187) rawSpace: SBuf135 not 
growing2015/12/21 09:02:24.001| 24,7| SBuf.cc(180) rawSpace: reserving 1 for 
SBuf1342015/12/21 09:02:24.001| 24,7| SBuf.cc(187) rawSpace: SBuf134 not 
growing2015/12/21 09:02:24.001| Using certificate in 
/root/ssl/squid.crt2015/12/21 09:02:24.027| 83,5| support.cc(512) 
configureSslContext: Using chiper suite 
ECDH+AESGCM:DH+AESGCM:ECDH+AES:DH+AES:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS.2015/12/21 
09:02:24.027| 24,7| SBuf.cc(180) rawSpace: reserving 1 for SBuf1242015/12/21 
09:02:24.027| 24,7| SBuf.cc(187) rawSpace: SBuf124 not growing2015/12/21 
09:02:24.027| 83,9| support.cc(521) configureSslContext: Setting RSA key 
generation callback.2015/12/21 09:02:24.027| 83,9| ServerOptions.cc(164) 
updateContextEecdh: Setting Ephemeral ECDH curve to secp384r1.2015/12/21 
09:02:24.027| 24,7| SBuf.cc(180) rawSpace: reserving 1 for SBuf1302015/12/21 
09:02:24.027| 24,8| SBuf.cc(1000) cow: SBuf130 new size:102015/12/21 
09:02:24.027| 24,8| SBuf.cc(970) reAlloc: SBuf130 new size: 102015/12/21 
09:02:24.027| 24,9| MemBlob.cc(56) MemBlob: constructed, this=0x1f94670 
id=blob125 reserveSize=102015/12/21 09:02:24.027| 24,8| MemBlob.cc(101) 
memAlloc: blob125 memAlloc: requested=10, received=402015/12/21 09:02:24.027| 
24,7| SBuf.cc(979) reAlloc: SBuf130 new store capacity: 402015/12/21 
09:02:24.027| ERROR: Unable to set Ephemeral ECDH: 
error:00000000:lib(0):func(0):reason(0)2015/12/21 09:02:24.034| 83,8| 
PeerOptions.cc(534) updateContextCa: Setting CA certificate 
locations.2015/12/21 09:02:24.034| 24,8| SBuf.cc(89) SBuf: SBuf149 created 
from id SBuf1382015/12/21 09:02:24.034| 24,7| SBuf.cc(180) rawSpace: 
reserving 1 for SBuf1222015/12/21 09:02:24.034| 24,8| SBuf.cc(1000) cow: 
SBuf122 new size:12015/12/21 09:02:24.034| 24,8| SBuf.cc(970) reAlloc: 
SBuf122 new size: 12015/12/21 09:02:24.034| 24,9| MemBlob.cc(56) MemBlob: 
constructed, this=0x1f96070 id=blob126 reserveSize=12015/12/21 09:02:24.034| 
24,8| MemBlob.cc(101) memAlloc: blob126 memAlloc: requested=1, 
received=402015/12/21 09:02:24.034| 24,7| SBuf.cc(979) reAlloc: SBuf122 new 
store capacity: 402015/12/21 09:02:24.034| 24,7| SBuf.cc(180) rawSpace: 
reserving 1 for SBuf1492015/12/21 09:02:24.034| 24,7| SBuf.cc(187) rawSpace: 
SBuf149 not growing2015/12/21 09:02:24.034| WARNING: Ignoring error setting 
CA certificate locations: error:0B064071:x509 certificate 
routines:ADD_CERT_DIR:invalid directory2015/12/21 09:02:24.035| 24,8| 
SBuf.cc(135) ~SBuf: SBuf149 destructed2015/12/21 09:02:24.035| 83,9| 
support.cc(548) configureSslContext: Not requiring any client 
certificates2015/12/21 09:02:24.035| 21,3| tools.cc(499) leave_suid: 
leave_suid: PID 13102 called2015/12/21 09:02:24.035| 21,3| tools.cc(521) 
leave_suid: leave_suid: PID 13102 giving up root, becoming 'nobody'2015/12/21 
09:02:24.035| 0,9| debug.cc(403) parseOptions: command-line -X overrides: 
ALL,1

Is there anybody running it successfully with ECDH support willing to share 
some insights and a config sample??Thanks in advance.?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151221/c80fd9dd/attachment.htm>

From rafael.akchurin at diladele.com  Mon Dec 21 18:32:37 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 21 Dec 2015 18:32:37 +0000
Subject: [squid-users] Squid 3.5.12 for Microsoft Windows 64-bit is available
Message-ID: <HE1PR04MB1353CBDCF2510DB86156522A8FE40@HE1PR04MB1353.eurprd04.prod.outlook.com>

Greetings everyone,



The CygWin based build of Squid proxy for Microsoft Windows version 3.5.12 is now available (amd64 only!).



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.12-RELEASENOTES.html.

* Ready to use MSI package can be downloaded from http://squid.diladele.com.

* List of open issues for the installer - https://github.com/diladele/squid3-windows/issues



Thanks a lot for Squid developers for making this great software!



Please join our humble efforts to provide ready to run MSI installer for Squid on Microsoft Windows with all required dependencies at GitHub -

https://github.com/diladele/squid3-windows. Please report all issues/bugs/feature requests at GitHub project.

Issues about the *MSI installer only* can also be reported to support at diladele.com<mailto:support at diladele.com>.



Merry Christmas and Happy New Year!!!



Best regards,

Rafael Akchurin

Diladele B.V.

http://www.quintolabs.com

http://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151221/ffc910ba/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 21 22:04:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 22 Dec 2015 11:04:54 +1300
Subject: [squid-users] ECDH not working with Squid 4. ERROR: Unable to
 set Ephemeral ECDH: error:00000000:lib(0):func(0):reason(0)
In-Reply-To: <K63rOBS----0@tuta.io>
References: <K63rOBS----0@tuta.io>
Message-ID: <56787786.2040400@treenet.co.nz>

On 22/12/2015 3:07 a.m., tylerd wrote:
> Hello, 
> I'm having a hard time trying to use ECDH support in Squid and I tried a few 
> different releases since v. 4 is out. Squid version:
> 
> Squid Cache: Version 4.0.3-20151216-r14446Service Name: squidconfigure 
> options:  '--with-openssl' '--enable-basic-auth-helpers=squid_radius_auth' 
> '--enable-auth' --enable-ltdl-convenience

The above is equivalent to just "./configure --with-openssl"

Because "--enable-auth" is enabled by default and
"--enable-basic-auth-helpers" does not exist. Even if it did there is no
"basic_squid_radius_auth_auth" helper.

The configuration you seem to be trying to achieve is:
 ./configure --with-openssl --enable-auth-basic=RADIUS

Which will build the Squid-3.2+ helper called "basic_radius_auth".


> OpenSSL is 1.0.1q
> Relevant https_port settings line in my squid.conf:
> https_port 443 cert=/root/ssl/squid.crt key=/root/ssl/squid.key 
> tls-cafile=/root/ssl/ca.crt 
> cipher=ECDH+AESGCM:DH+AESGCM:ECDH+AES:DH+AES:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS 
> tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
> When I try to run it, I get the following error: 2015/12/21 09:01:05| ERROR: 
> Unable to set Ephemeral ECDH: error:00000000:lib(0):func(0):reason(0)


> 
> Is there anybody running it successfully with ECDH support willing to share 
> some insights and a config sample? Thanks in advance. 
> 

That was a regression in the latest betas. I have now resolved it.

FYI: It was just incorrect logging, the ECDH ciphers should have been
operating properly despite the message. If you find that ECDH is not
working that is a separate issue.

Thanks
Amos



From squid3 at treenet.co.nz  Mon Dec 21 22:20:00 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 22 Dec 2015 11:20:00 +1300
Subject: [squid-users] CVE-2009-0801
In-Reply-To: <5677FFE8.3070801@ntcomputer.de>
References: <567463FB.9000605@ntcomputer.de> <56748559.4010905@treenet.co.nz>
 <5674970F.5060600@ntcomputer.de> <56749C26.4010808@treenet.co.nz>
 <5677FFE8.3070801@ntcomputer.de>
Message-ID: <56787B10.30805@treenet.co.nz>

On 22/12/2015 2:34 a.m., dc wrote:
> 
> Am 19.12.2015 um 00:52 schrieb Amos Jeffries:
>> Why not?
>> * NAT/TPROXY is mandatory to happen on the Squid machine directly since
>> kernel and Squid are performing integrated operations.
>> * PROXY protocol passes the ORIGINAL_DST explicitly over the wire.
>> * SSL-Bump all happens "inside Squid".
>>
>> Those are the only forms of interception Squid supports.
>>
> Thanks for making that clear! I fixed my setup accordingly. Squid now
> gathers original IP addresses from NAT.
> I also enabled host_verify_strict, which should make sure requests are
> always sent to correct IP addresses. Is there an equivalent setting for
> peek-and-spliced HTTPS connections? Or does host_verify_strict cover
> that case as well? This would be important, since otherwise a malicious
> application could bypass the whitelist ACLs I have installed.

The SSL-Bump code is still undergoing polishing and still very much
experimental / volatile, so YMMV on vulnerability but it wont be
CVE-2009-0801.

That is just because the situation is rather different with TLS/SSL.
Server certificates are involved to authenticate the connection level
details. The TLS connections with server-first style of bumping are also
setup and pinned at the TCP layer before HTTP mesages get involved. So
the outbound connection has nothing to do with the HTTP message Host
header on the intercepted/decrypted messages.

Amos



From alex at samad.com.au  Mon Dec 21 22:33:23 2015
From: alex at samad.com.au (Alex Samad)
Date: Tue, 22 Dec 2015 09:33:23 +1100
Subject: [squid-users] Squid 3.5.12 RPMs release for CentOS 6 and 7.
In-Reply-To: <5677DB0C.9020905@ngtech.co.il>
References: <565A94A9.1060601@treenet.co.nz>
	<5677DB0C.9020905@ngtech.co.il>
Message-ID: <CAJ+Q1PWfKPacYO2M4Hod_5MzEYjVEswbGf9fUymj63u+2pkaGQ@mail.gmail.com>

Thanks

On 21 December 2015 at 21:57, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> Published at: http://www1.ngtech.co.il/wpe/?p=166
>
> I am happy to release the new RPMs of squid 3.5.12 for Centos 6 64bit, 32bit
> and CentOS 7 64bit.
>
> The new release includes couple bug fixes and improvements.
> I have also took the time to build the latest beta 4.0.3 RPM for CentOS 7.
> The details about the the RPMs repository are at
> squid-wiki[http://wiki.squid-cache.org/KnowledgeBase/CentOS].
>
> Why 3DES (triple DES)? or The fall of DES.
>
> It is known in the cryptography world that since 1997 DES(IE single DES) is
> vulnerable to some attacks  and there for is being considered to be unsafe
> for some uses. In order to resolve the DES issues the 3DES was implemented
> due to the ability to use the same fast cryptography machinery\chips that
> was used before and by that giving some time to the industry to find another
> more fit solution.
> Some words about the DES encryption from Professor Gideon Samid:
> [https://www.youtube.com/watch?v=r68Ft_rRZP0]
>
> Hashing compared to Encryption
>
> The difference between hashing  to encryption is the ability to recreate the
> original digested content. Hashes are meant to allow some kind of content
> validation verification based on the low probability of  math collisions. To
> give a simple example about the subject we can use the Quadratic Formula:
> [http://www1.ngtech.co.il/wpe/wp-content/uploads/2015/12/Quadratic-Formula.jpg]
> Quadratic Formula
> The formula defines that it is possible (or it is always the right answer)
> to have two answers to the same question\issue\variables.
> Based on the fact\assumption that there is a possibility for two
> answers\solutions to the same unknowns+function we can use a function to
> describe more then one number. And in the case of computers which everything
> is some kind of a number we can convert the unknown numbers to octets.
> Once there is no difference between numbers and\or octets and letters and we
> are in the function computation world. There we can use all sorts of
> functions\equations in order to describe all sorts of numbers and by that
> letters.
> Eventually hashes are some kind of known functions which implements some way
> to reflect very big numbers or very big documents in some kind of output .
> Technically speaking it?s some function\method that is guaranteed to reflect
> very big numbers with probability(high or low) that multiple input values
> will be reflected with the same output number(128 bits for example).
> In many levels of applications some hashes such as crc32\md5\sha-1\others
> are being used and these applications allow them-self  to validate content
> integrity with a fully ?vulnerable? hash due to the fact that the validated
> content  do not exceed the function collision sizes.
> I must admit that I have used MD5 and many other hashes for a very long time
> and the only collisions that I have seen that affected real world
> applications integrity are that of CRC32 hashes, maybe I have not seen
> enough yet!
> And couple expert words from Professor Gideon Samid on hashing:
> [https://www.youtube.com/watch?v=yXmNmckX4sI]
>
>     Disclaimer: I am not a cryptography expert!
>
> This RPMs release was tested for:
>
>     ICAP 204\206 compatibility (non ssl)
>     ECAP passthru adapter which digest response body using SHA256
>     refresh_pattern variations
>     StoreID patterns
>     Basic load testing
>     Basic ssl-bump usage in strict forward proxy mode
>     Basic denial of memory leaks on a long period time of operation
>     Basic build tests
>
> All the above was done on a CentOS 7 x86_64 VMs.
> I have not tested everything on CentOS 6 since it is assumed that if it
> works good on CentOS 7 there should not be a special reason for it to now
> work on CentOS 6.
>
> More details about the repository at squid-wiki.
>
> All The Bests,
> Eliezer Croitoru
>
>     I have been working on ?Store ID ? The hackers side of the
> feature?[http://wiki.squid-cache.org/Features/StoreID/Hacking]
>     And I am planning an update to ?Caching Dynamic Content using
> Adaptation? (which will not include ways to cache
> youtube)[http://wiki.squid-cache.org/ConfigExamples/DynamicContent/Coordinator]
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From alex at samad.com.au  Mon Dec 21 22:35:05 2015
From: alex at samad.com.au (Alex Samad)
Date: Tue, 22 Dec 2015 09:35:05 +1100
Subject: [squid-users] squid cache peer issues
In-Reply-To: <5677D3E5.6050600@treenet.co.nz>
References: <CAJ+Q1PUijVmAvYTaotYr=dWWfP+KhfkS_Dr8p0mm+sLJscYWDA@mail.gmail.com>
 <5677D3E5.6050600@treenet.co.nz>
Message-ID: <CAJ+Q1PUKEOS2yc3mfEjQP8fq-t9K0cc=APy=wVbQV56EPO7Lug@mail.gmail.com>

Hi

seems like .12 is now available for me. I will apply and retest. is
there anything you would like me to do if I see it again ?

A

On 21 December 2015 at 21:26, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 21/12/2015 2:00 p.m., Alex Samad wrote:
>> Hi
>>
>> running on centos 6.7
>>
>> 3.5.12 still not available on centos 6.
>>
>> rpm -qa | grep squid
>> squid-helpers-3.5.11-1.el6.x86_64
>> squid-3.5.11-1.el6.x86_64
>>
>> This is the 2 cache_peer statements I use
>>
>> # on alcdmz1
>> cache_peer gsdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
>> no-query standby=10
>> #cache_peer alcdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
>> no-query standby=10
>>
>> # on gsdmz1
>> #cache_peer gsdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
>> no-query standby=10
>> cache_peer alcdmz1.yieldbroker.com sibling 3128 4827 proxy-only htcp
>> no-query standby=10
>>
>> on alcdmz1 with export http_proxy pointing to alcdmz1
>>
>> wget -d  http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
>> -O /dev/null
>> Setting --output-document (outputdocument) to /dev/null
>> DEBUG output created by Wget 1.12 on linux-gnu.
>>
>> --2015-12-21 11:58:05--
>> http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
>> Resolving alcdmz1... 10.32.20.111
>> Caching alcdmz1 => 10.32.20.111
>> Connecting to alcdmz1|10.32.20.111|:3128... connected.
>> Created socket 4.
>> Releasing 0x000000000101d540 (new refcount 1).
>>
>> ---request begin---
>> GET http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2 HTTP/1.0
>> User-Agent: Wget/1.12 (linux-gnu)
>> Accept: */*
>> Host: fonts.gstatic.com
>>
>> ---request end---
>> Proxy request sent, awaiting response...
>> ---response begin---
>> HTTP/1.1 200 OK
>> Content-Type: font/woff2
>> Access-Control-Allow-Origin: *
>> Timing-Allow-Origin: *
>> Date: Mon, 30 Nov 2015 04:06:16 GMT
>> Expires: Tue, 29 Nov 2016 04:06:16 GMT
>> Last-Modified: Mon, 06 Oct 2014 20:40:59 GMT
>> X-Content-Type-Options: nosniff
>> Server: sffe
>> Content-Length: 25604
>> X-XSS-Protection: 1; mode=block
>> Cache-Control: public, max-age=31536000
>> Age: 1803109
>> Warning: 113 alcdmz1 (squid) This cache hit is still fresh and more
>> than 1 day old
>> X-Cache: HIT from alcdmz1
>> X-Cache-Lookup: HIT from alcdmz1:3128
>> Via: 1.1 alcdmz1 (squid)
>> Connection: close
>>
>> ---response end---
>> 200 OK
>> Length: 25604 (25K) [font/woff2]
>> Saving to: `/dev/null'
>>
>> 100%[==============================================================================================>]
>> 25,604      --.-K/s   in 0s
>>
>> Closed fd 4
>> 2015-12-21 11:58:05 (1.01 GB/s) - `/dev/null' saved [25604/25604]
>>
>>
>> on gsdmz1
>>
>>
>> wget -d  http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
>> -O /dev/null
>> Setting --output-document (outputdocument) to /dev/null
>> DEBUG output created by Wget 1.12 on linux-gnu.
>>
>> --2015-12-21 11:58:59--
>> http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2
>> Resolving gsdmz1... 10.32.20.110
>> Caching gsdmz1 => 10.32.20.110
>> Connecting to gsdmz1|10.32.20.110|:3128... connected.
>> Created socket 4.
>> Releasing 0x00000000010a2930 (new refcount 1).
>>
>> ---request begin---
>> GET http://fonts.gstatic.com/s/lato/v11/H2DMvhDLycM56KNuAtbJYA.woff2 HTTP/1.0
>> User-Agent: Wget/1.12 (linux-gnu)
>> Accept: */*
>> Host: fonts.gstatic.com
>>
>> ---request end---
>> Proxy request sent, awaiting response...
>> ---response begin---
>> HTTP/1.1 504 Gateway Timeout
>> Server: squid
>> Mime-Version: 1.0
>> Date: Mon, 21 Dec 2015 00:58:59 GMT
>> Content-Type: text/html;charset=utf-8
>> Content-Length: 3964
>> X-Squid-Error: ERR_ONLY_IF_CACHED_MISS 0
>> Vary: Accept-Language
>> Content-Language: en
>> Age: 1450659540
>> Warning: 113 alcdmz1 (squid) This cache hit is still fresh and more
>> than 1 day old
>> Warning: 110 squid "Response is stale"
>> Warning: 111 squid "Revalidation failed"
>> X-Cache: HIT from alcdmz1
>> X-Cache-Lookup: HIT from alcdmz1:3128
>> X-Cache: MISS from gsdmz1
>> X-Cache-Lookup: MISS from gsdmz1:3128
>> Via: 1.1 alcdmz1 (squid), 1.1 gsdmz1 (squid)
>> Connection: close
>>
>> ---response end---
>> 504 Gateway Timeout
>> Closed fd 4
>> 2015-12-21 11:58:59 ERROR 504: Gateway Timeout.
>>
>>
>> so why does it work from alc and not from gs ???
>
> The alc fetch is going:
>   client->alc->Internet/parent
>
> The gs fetch is going:
>   client->gs->alc->Internet/parent
>
> This is shown in the Via headers.
>
>
> The alc sibling has a response cached which matches. But that required a
> revalidation. (The 113 and 110 Warning headers)
>
> The revalidation failed for some reason (the only-if-cached ?). So it
> output a 504 and sent that back to gs. (The 111 Warning header)
>
> There are several problems here:
> 1) why the revalidation is failing, and
> 2) why the gs peer is not re-trying the fetch via another server (parent
> or DIRECT) after the 504 happens.
> 3) The Age header says ~46yrs ago for the 504 being created,
> suspiciously close to 1 Jan 1970 / unix epoch 0-second.
>
>
> It seems to me you have managed to reproduce
> <http://bugs.squid-cache.org/show_bug.cgi?id=4223>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Tue Dec 22 08:25:05 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 22 Dec 2015 21:25:05 +1300
Subject: [squid-users] FYI: Squid-3.5 Ephemeral Elliptic Curve
 Diffie-Hellman (EECDH) key exchange
Message-ID: <567908E1.3060403@treenet.co.nz>

Since the lack of this is a security hole in Squid-3.5, is already
causing trouble for people unable to use the old Diffi-Helman exchange
or to upgrade to Squid-4, and the patch is rather small with full
backward compatibility. I have decided to break with the usual policy of
no squid.conf alterations after a version goes stable for production use.

The squid.conf settings necessary to configure EECDH ciphers in TLS have
just been applied to the Squid-3.5 branch and will be part of the next
release.

If anyone has been wishing for this and is able to assist with testing,
please feel free to try out the r13967 (or later) snapshots when they
become available in a few hours.

Amos


From yvoinov at gmail.com  Tue Dec 22 14:52:05 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 22 Dec 2015 20:52:05 +0600
Subject: [squid-users] FYI: Squid-3.5 Ephemeral Elliptic Curve
 Diffie-Hellman (EECDH) key exchange
In-Reply-To: <567908E1.3060403@treenet.co.nz>
References: <567908E1.3060403@treenet.co.nz>
Message-ID: <56796395.60902@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Just built r13967. EC now visible in online SSL check. Will test more
tomorrow.

22.12.15 14:25, Amos Jeffries ?????:
> Since the lack of this is a security hole in Squid-3.5, is already
> causing trouble for people unable to use the old Diffi-Helman exchange
> or to upgrade to Squid-4, and the patch is rather small with full
> backward compatibility. I have decided to break with the usual policy of
> no squid.conf alterations after a version goes stable for production use.
>
> The squid.conf settings necessary to configure EECDH ciphers in TLS have
> just been applied to the Squid-3.5 branch and will be part of the next
> release.
>
> If anyone has been wishing for this and is able to assist with testing,
> please feel free to try out the r13967 (or later) snapshots when they
> become available in a few hours.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWeWOUAAoJENNXIZxhPexG8gUH/R6zFlvsJ/MadYf3pM5+s6IR
tiSW9oTrVuNcNoTaL0dkaLXNACaa3+C0UyaF02jsd3/Ngj3cxa3TT6bVItIt6RYj
J26dRYXIht1pPtmDhM/I6QJhYdGUmcq+uXi+KQmCT7TLm5lRfUW29t6vhc+GMmYJ
MUdv2PRElmdPtaZwWDnKCi8+XZ9aC36c5ulNef0BW3MkNtvOa2Hz+V0p417nuMfS
Qws9DeXpwwdLWRqIfCVf5ZViuZJ+Dsg07WWpUSgAmMcnq2IANlEGcw8/gzPoJ8/i
Q/M7Nrrm9k5cxtGVUMrJHrn1smwJZjq6cG2Mj/d1akup9as8P6i2vbe5EkxAIlA=
=n2n3
-----END PGP SIGNATURE-----



From fbismc at hotmail.com  Wed Dec 23 01:10:05 2015
From: fbismc at hotmail.com (fbismc)
Date: Tue, 22 Dec 2015 17:10:05 -0800 (PST)
Subject: [squid-users] New skype version can't control by squid
Message-ID: <1450833005178-4675279.post@n4.nabble.com>

Hi everyone

Below is my skype control in squid.conf

#skype
acl numeric_IPs dstdom_regex
^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9af]+)?:([0-9af:]+)?:([0-9af]+)?\])):443
acl Skype_UA browser ^skype
acl validUserAgent browser \S+
acl skypenet dstdomain .skype.com

After skype update to 7.17 ,the control is failed , I need to give a
"allowed" permission , the "allowed" means have a privilege to Internet
surfing.

How should I fix this problem , any suggestion will be a appreciated




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/New-skype-version-can-t-control-by-squid-tp4675279.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From leolistas at solutti.com.br  Wed Dec 23 13:30:27 2015
From: leolistas at solutti.com.br (Leonardo Rodrigues)
Date: Wed, 23 Dec 2015 11:30:27 -0200
Subject: [squid-users] New skype version can't control by squid
In-Reply-To: <1450833005178-4675279.post@n4.nabble.com>
References: <1450833005178-4675279.post@n4.nabble.com>
Message-ID: <567AA1F3.7020104@solutti.com.br>

Em 22/12/15 23:10, fbismc escreveu:
> Hi everyone
>
> Below is my skype control in squid.conf
>
> #skype
> acl numeric_IPs dstdom_regex
> ^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9af]+)?:([0-9af:]+)?:([0-9af]+)?\])):443
> acl Skype_UA browser ^skype
> acl validUserAgent browser \S+
> acl skypenet dstdomain .skype.com
>
> After skype update to 7.17 ,the control is failed , I need to give a
> "allowed" permission , the "allowed" means have a privilege to Internet
> surfing.
>
> How should I fix this problem , any suggestion will be a appreciated
>
>

     Well ... if you need want someone to be able to help you, you can 
start giving some real informations on the new skype accesses that are 
failing your rules.

     You have rules for user agent, IP access on port 443 and domain 
skype.com. Which accesses are not getting caught by these ? What are the 
new user agent used on the new skype accesses ???

     Provide real information if you want real help (which of course, if 
not always guaranteed on a community mailing list). But be sure that 
with no real information, you wont get any useful help at all.



-- 


	Atenciosamente / Sincerily,
	Leonardo Rodrigues
	Solutti Tecnologia
	http://www.solutti.com.br

	Minha armadilha de SPAM, N?O mandem email
	gertrudes at solutti.com.br
	My SPAMTRAP, do not email it





From dolson at ihcrc.org  Wed Dec 23 15:26:26 2015
From: dolson at ihcrc.org (dolson at ihcrc.org)
Date: Wed, 23 Dec 2015 15:26:26 +0000
Subject: [squid-users] Unable to access websites through Squid
Message-ID: <00787094CFCCA644B43359BF6304BD503EBC4952@SRV-WEBSRVCS.ihcrc.org>

Greetings,

I am working with Squid 3.4.8 on a Debian 8.2 system.   The goal is to record all web activity, not block any sites at this time utilizing squid.  I have followed several different sets of instructions on setting up Squid to utilize Active Directory Authentication to record who goes where.   I have yet to be able to access any websites, even internal sites while passing through the Squid Proxy.   The browser I'm testing on is Mozilla Firefox 42.0 on a Windows 7 Professional system.  I am using Firefox for testing as I can set the proxy without affecting my other browsers on my workstation.

I have tried various different forms of the squid.conf file, found from various sources and I have yet to get a successful connection.  Depending on the file configuration I use, I am getting an "access denied" page from the squid server, or a "Problem loading page:  The connection was reset" error.   With the current squid.conf, which brings up the second error, nothing is recorded in the access.log file, and the cache.log file keeps reporting the following error:

WARNING:  memberof #Hlpr0 exited
FATAL:  The memberof helpers are crashing too rapidly, need help!

I feel like I'm banging my head against the wall at this point.   I have tried slowly building the squid.conf file, adding one authenticator program at a time until I got some sort of different response and I have not been able to get anything to work.

I have attached several different squid.conf files that I have used.  The current "Squid.conf" file generates the "Connection was reset" error message, while the squid.conf.bk5 file just gives me an access is denied message.

Please help!


Thank you,

Dan Olson
Indian Health Care Resource Center
Network Support Specialist
Main: 918.588.1900 Ext. 2212
Direct: 918.382.1212
www.ihcrc.org<http://www.ihcrc.org>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151223/3460e340/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf.bk5
Type: application/octet-stream
Size: 2200 bytes
Desc: squid.conf.bk5
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151223/3460e340/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 3333 bytes
Desc: squid.conf
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151223/3460e340/attachment-0001.obj>

From belle at bazuin.nl  Wed Dec 23 16:54:37 2015
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 23 Dec 2015 17:54:37 +0100
Subject: [squid-users] Unable to access websites through Squid
In-Reply-To: <00787094CFCCA644B43359BF6304BD503EBC4952@SRV-WEBSRVCS.ihcrc.org>
References: <00787094CFCCA644B43359BF6304BD503EBC4952@SRV-WEBSRVCS.ihcrc.org>
Message-ID: <vmime.567ad1cd.6c24.2b842e9b730fc21d@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

?

I had troubles also with the squid config files, so i created ?squid-conf-split? 

?

Basicly this small piece of code blow. 

?

?

## code starts here. 

#!/bin/sh

?

DATE_NOW=$(date +%Y-%m-%d)

?

if [ -d /etc/squid/conf.d ]; then

??? cp -R /etc/squid/conf.d-${DATE_NOW}

else

??? mkdir /etc/squid/conf.d

fi

?

cd /etc/squid/conf.d

if [ ! -e /etc/squid/squid.conf.debian ]; then

??? if [ -e /etc/squid/squid.conf.dpkg-dist ]; then

????????cp /etc/squid/squid.conf.dpkg-dist /etc/squid/squid.conf.debian

??? else

??????? cp /etc/squid/squid.conf /etc/squid/squid.conf.debian

??? fi

fi

?

csplit -f squid- -n2 /etc/squid/squid.conf.debian '/# -----------------------------------------------------------------------------/-1' '{*}' > /dev/null

?

for x in `ls squid-*` ; do NAME=`cat $x | head -n1 | tr -s ' ' | tr "[ ]" "[\-]"| cut -c3-100` ; mv $x $x-00-$NAME.conf? ; done



?

cat << EOF > /etc/squid/squid.conf

########################################"

## Debian Squid splitted based config

## edit the files in /etc/squid/conf.d/

include /etc/squid/conf.d/*.conf"

EOF

?

## code ends here. 

?

?

You end up with a layout like this. 

All files starting with squid-XX-00 are the default settings of squid. 

All squid-XX-01-custom are my changes. 

Only 1 file with an exeption. ???squid-03-00-ACCESS-CONTROLS.conf . since order is a big thing in this file, i make a copy of it. 

And add my entries there. All other see below. 

?

squid-00-00-WELCOME-TO-SQUID-3.5.12.conf??????????????????????????????? squid-12-01-custom.conf????????????????????????????????????? squid-27-00-SNMP-OPTIONS.conf

squid-01-00-OPTIONS-FOR-SMP.conf??????????????????????????????????????? squid-13-00-OPTIONS-FOR-EXTERNAL-SUPPORT-PROGRAMS.conf?????? squid-27-01-custom.conf

squid-02-00-OPTIONS-FOR-AUTHENTICATION.conf???????????????????????????? squid-13-01-custom.conf???????????????????? ?????????????????squid-28-00-ICP-OPTIONS.conf

squid-02-01-auth-negotiate-both.conf??????????????????????????????????? squid-14-00-OPTIONS-FOR-URL-REWRITING.conf?????????????????? squid-28-01-custom.conf

squid-02-04-auth-ldap-AD.conf??????????????????????? ???????????????????squid-15-00-OPTIONS-FOR-STORE-ID.conf??????????????????????? squid-29-00-MULTICAST-ICP-OPTIONS.conf

squid-02-99-auth-acl.conf?????????????????????????????????????????????? squid-16-00-OPTIONS-FOR-TUNING-THE-CACHE.conf??????????????? squid-30-00-INTERNAL-ICON-OPTIONS.conf

squid-03-00-ACCESS-CONTROLS.conf??????????????????????????????????????? squid-16-01-custom.conf????????????????????????????????????? squid-31-00-ERROR-PAGE-OPTIONS.conf

squid-04-00-NETWORK-OPTIONS.conf??????????????????? ????????????????????squid-17-00-HTTP-OPTIONS.conf??????????????????????????????? squid-31-01-custom.conf

squid-05-00-SSL-OPTIONS.conf??????????????????????????????????????????? squid-17-01-custom.conf????????????????????????????????????? squid-32-00-OPTIONS-INFLUENCING-REQUEST-FORWARDING-.conf

squid-06-00-OPTIONS-RELATING-TO-EXTERNAL-SSL_CRTD-.conf???????????????? squid-18-00-TIMEOUTS.conf??????????????????????????????????? squid-32-01-custom.conf

squid-07-00-OPTIONS-WHICH-AFFECT-THE-NEIGHBOR-SELECTION-ALGORITHM.conf? squid-18-01-custom.conf????????????????????????????????????? squid-33-00-ADVANCED-NETWORKING-OPTIONS.conf

squid-08-00-MEMORY-CACHE-OPTIONS.conf?????????????????????????????????? squid-19-00-ADMINISTRATIVE-PARAMETERS.conf?????????????????? squid-34-00-ICAP-OPTIONS.conf

squid-08-01-custom.conf???????????????????????????????????????????????? squid-19-01-custom.conf????????????????????????????????????? squid-34-01-icap-squidclamav.conf

squid-09-00-DISK-CACHE-OPTIONS.conf???????????????????????????? ????????squid-20-00-OPTIONS-FOR-THE-CACHE-REGISTRATION-SERVICE.conf? squid-35-00-eCAP-OPTIONS.conf

squid-09-01-custom.conf???????????????????????????????????????????????? squid-21-00-HTTPD-ACCELERATOR-OPTIONS.conf?????????????????? squid-36-00-MESSAGE-ADAPTATION-OPTIONS.conf

squid-10-00-LOGFILE-OPTIONS.conf??????????????????????????????????????? squid-22-00-DELAY-POOL-PARAMETERS.conf?????????????????????? squid-37-00-DNS-OPTIONS.conf

squid-10-01-custom.conf???????????????????????????????????????????????? squid-23-00-CLIENT-DELAY-POOL-PARAMETERS.conf??????????????? squid-37-01-custom.conf

squid-11-00-OPTIONS-FOR-TROUBLESHOOTING.conf??????????????????????????? squid-24-00-WCCPv1-AND-WCCPv2-CONFIGURATION-OPTIONS.conf???? squid-38-00-MISCELLANEOUS.conf

squid-11-01-custom.conf???????????????????????????????????????????????? squid-25-00-PERSISTENT-CONNECTION-HANDLING.conf????????????? squid-38-01-custom.conf

squid-12-00-OPTIONS-FOR-FTP-GATEWAYING.conf???????????????????????????? squid-26-00-CACHE-DIGEST-OPTIONS.conf

?

?

If you use kerberos authentication. You can use a setup like this., i?ve tested both, and both works as of 3.4.8? -> 3.5.12 ( i recomiled 3.5 from sid ) 

## this line needs a good working Pricipal names. (SPN?s) Like ?HTTP/proxy1.internal.domain.tld? and you need an A and PTR record ! 

?

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth -d \

??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/proxy1.internal.domain.tld at MY.REALM.TLD \

??? --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN

?

## or same, check the -s !

#auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \

#??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME -d \

#??? --ntlm /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --domain= NTDOMAIN \

?

auth_param negotiate children 30 startup=5 idle=1

auth_param negotiate keep_alive on

?

?

take one of the above lines and test with debug on , like :? 

/usr/lib/squid/negotiate_wrapper_auth -d \

??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/proxy1.internal.domain.tld at MY.REALM.TLD \

??? --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN -D

( -D added in this line ) ?

?

So, do the following, start over with a clean new config. 

Enable these: 

#acl localnet src 10.0.0.0/8??? # RFC1918 possible internal network

#acl localnet src 172.16.0.0/12 # RFC1918 possible internal network

#acl localnet src 192.168.0.0/16??????? # RFC1918 possible internal network

#acl localnet src fc00::/7?????? # RFC 4193 local private network range

#acl localnet src fe80::/10????? # RFC 4291 link-local (directly plugged) machines

Which allows all local networks, or change them to your ip range. 

?

http_port 3128 intercept

?

add to firewall: 

-A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 3128 

?

Reload squid and test. 

?

Give it a try, im back here in 15 hours..? ;-) 

?

Greetz, 

?

Louis

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens dolson at ihcrc.org
Verzonden: woensdag 23 december 2015 16:26
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] Unable to access websites through Squid


?

Greetings,

?

I am working with Squid 3.4.8 on a Debian 8.2 system.?? The goal is to record all web activity, not block any sites at this time utilizing squid.? I have followed several different sets of instructions on setting up Squid to utilize Active Directory Authentication to record who goes where.?? I have yet to be able to access any websites, even internal sites while passing through the Squid Proxy.?? The browser I?m testing on is Mozilla Firefox 42.0 on a Windows 7 Professional system.? I am using Firefox for testing as I can set the proxy without affecting my other browsers on my workstation.

?

I have tried various different forms of the squid.conf file, found from various sources and I have yet to get a successful connection.? Depending on the file configuration I use, I am getting an ?access denied? page from the squid server, or a ?Problem loading page:? The connection was reset? error.?? With the current squid.conf, which brings up the second error, nothing is recorded in the access.log file, and the cache.log file keeps reporting the following error:

?

WARNING:? memberof #Hlpr0 exited

FATAL:? The memberof helpers are crashing too rapidly, need help!

?

I feel like I?m banging my head against the wall at this point.?? I have tried slowly building the squid.conf file, adding one authenticator program at a time until I got some sort of different response and I have not been able to get anything to work.

?

I have attached several different squid.conf files that I have used.? The current ?Squid.conf? file generates the ?Connection was reset? error message, while the squid.conf.bk5 file just gives me an access is denied message.

?

Please help!

?

?

Thank you,

?

Dan Olson

Indian Health Care Resource Center

Network Support Specialist

Main: 918.588.1900 Ext. 2212

Direct: 918.382.1212

www.ihcrc.org

?

?


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151223/3bf83a69/attachment.htm>

From Jason_Haar at trimble.com  Sun Dec 27 22:13:25 2015
From: Jason_Haar at trimble.com (Jason Haar)
Date: Mon, 28 Dec 2015 11:13:25 +1300
Subject: [squid-users] Host header forgery affects pure splice environment
	too?
Message-ID: <56806285.8080102@trimble.com>

Hi there

I use TOR a bit for testing our WAFs and found that it no longer worked
on my test network that has squid configured in TLS intercept mode. I
currently have squid configured to "splice only" (with peek to get the
SNI name) - ie no bumping - purely so that the squid access_log file
contains better records on HTTPS hostnames

2015/12/28 09:22:04.189 kid1| SECURITY ALERT: Host header forgery
detected on local=194.109.206.212:443 remote=192.168.0.21:40427 FD 30
flags=33 (local IP does not match any domain IP)
2015/12/28 09:22:04.189 kid1| SECURITY ALERT: By user agent:
2015/12/28 09:22:04.189 kid1| SECURITY ALERT: on URL: www.z2b4e372r4.com:443

Removing the redirect of tcp/443 totally fixes the problem.

Anyway, it would appear that squid-3.5.10 in splice-only mode still
enables the "Host header forgery" check? Surely if all you are doing is
splice-only, it shouldn't be doing that check at all? ie I could
understand triggering blocking actions if squid was part of the
transaction in bump-mode - but when it's "only looking", it is exactly
the same as not doing splice at all - so why trigger the Host header check?

It does look like TOR has something equivalent to a /etc/host file with
fake DNS names - so it's quite understandable that freaks squid out.
Actually, if squid cannot resolve a SNI hostname, shouldn't that skip
the Host name check?

Also, this isn't that easy to test: it would appear that once I turned
off intercept and successfully used TOR, it must have cached a bunch of
things because I then re-enabled intercept and it's no longer making any
tcp/443 connections - it goes straight out on other "native" TOR ports.
So it may be this can only be tested on a fresh install (or after some
cache timeout period)

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From yvoinov at gmail.com  Sun Dec 27 22:50:33 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 28 Dec 2015 04:50:33 +0600
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <56806285.8080102@trimble.com>
References: <56806285.8080102@trimble.com>
Message-ID: <56806B39.3050805@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I think, to eliminate this error you need to splice all torify connections.

I.e., you need to configure your squid something like this:

# SSL bump rules
acl step1 at_step SslBump1
ssl_bump peek step1
acl Splice ssl::server_name_regex -i "/usr/local/squid/etc/url.nobump"
acl Splice ssl::server_name_regex -i "/usr/local/squid/etc/url.tor"
ssl_bump splice Splice
ssl_bump bump net_bump

# Privoxy+Tor access rules
never_direct allow tor_url

and, following, url.nobump and url.tor is partially equal.

28.12.15 4:13, Jason Haar ?????:
> Hi there
>
> I use TOR a bit for testing our WAFs and found that it no longer worked
> on my test network that has squid configured in TLS intercept mode. I
> currently have squid configured to "splice only" (with peek to get the
> SNI name) - ie no bumping - purely so that the squid access_log file
> contains better records on HTTPS hostnames
>
> 2015/12/28 09:22:04.189 kid1| SECURITY ALERT: Host header forgery
> detected on local=194.109.206.212:443 remote=192.168.0.21:40427 FD 30
> flags=33 (local IP does not match any domain IP)
> 2015/12/28 09:22:04.189 kid1| SECURITY ALERT: By user agent:
> 2015/12/28 09:22:04.189 kid1| SECURITY ALERT: on URL:
www.z2b4e372r4.com:443
>
> Removing the redirect of tcp/443 totally fixes the problem.
>
> Anyway, it would appear that squid-3.5.10 in splice-only mode still
> enables the "Host header forgery" check? Surely if all you are doing is
> splice-only, it shouldn't be doing that check at all? ie I could
> understand triggering blocking actions if squid was part of the
> transaction in bump-mode - but when it's "only looking", it is exactly
> the same as not doing splice at all - so why trigger the Host header
check?
>
> It does look like TOR has something equivalent to a /etc/host file with
> fake DNS names - so it's quite understandable that freaks squid out.
> Actually, if squid cannot resolve a SNI hostname, shouldn't that skip
> the Host name check?
>
> Also, this isn't that easy to test: it would appear that once I turned
> off intercept and successfully used TOR, it must have cached a bunch of
> things because I then re-enabled intercept and it's no longer making any
> tcp/443 connections - it goes straight out on other "native" TOR ports.
> So it may be this can only be tested on a fresh install (or after some
> cache timeout period)
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWgGs5AAoJENNXIZxhPexGCPIH/1lAsDZWAzLJ7EbL1XRWXYKq
G3S3lOY68jQFRKjbrrHnFtlqltVniqLme25llD/LubgX7Qocz/bLH39LuBr9SBuJ
a1Nk9G8TW+98JIx4kAPL82NoRkkgtyNFhVocZ2vpJqN0YWdgu+lqTzQzf9NQmWCX
E8V94iuaHwXi2YLfdd61ora/Arw/9TJ2D2uNs4iKtk1t3ays9XBgM8Ga3rP2J/Us
8NTzQXoxmkHXTqlh9wdqmbNgjc3ReORsNNoSsoAgxkSFPAQuMndH/VS87RnJDQUr
EvAxw2x+sfn/gnyvUz254G8QukElcvyJFa07J6G1pxcQjB1AXKiijsU2xNcDkmg=
=GNYM
-----END PGP SIGNATURE-----



From Jason_Haar at trimble.com  Sun Dec 27 22:57:58 2015
From: Jason_Haar at trimble.com (Jason Haar)
Date: Mon, 28 Dec 2015 11:57:58 +1300
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <56806B39.3050805@gmail.com>
References: <56806285.8080102@trimble.com> <56806B39.3050805@gmail.com>
Message-ID: <56806CF6.2050108@trimble.com>

On 28/12/15 11:50, Yuri Voinov wrote:
> I think, to eliminate this error you need to splice all torify connections.
As I said - squid is configured to *only*  splice - there is no bump-ing
going on. So this is already the case

acl DiscoverSNIHost at_step SslBump1
ssl_bump peek DiscoverSNIHost
acl SSL_https port 443
ssl_bump splice SSL_https

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 181 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/42ea0ab6/attachment.sig>

From yvoinov at gmail.com  Sun Dec 27 23:00:01 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 28 Dec 2015 05:00:01 +0600
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <56806CF6.2050108@trimble.com>
References: <56806285.8080102@trimble.com> <56806B39.3050805@gmail.com>
 <56806CF6.2050108@trimble.com>
Message-ID: <56806D71.7070609@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
So, you can't get this error.

Ergo, it may be client configuration problem.

Is there is transparent proxy?

28.12.15 4:57, Jason Haar ?????:
> On 28/12/15 11:50, Yuri Voinov wrote:
>> I think, to eliminate this error you need to splice all torify
connections.
> As I said - squid is configured to *only*  splice - there is no bump-ing
> going on. So this is already the case
>
> acl DiscoverSNIHost at_step SslBump1
> ssl_bump peek DiscoverSNIHost
> acl SSL_https port 443
> ssl_bump splice SSL_https
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWgG1xAAoJENNXIZxhPexGd8sH/jmGtAoiVEihSQNYXlXLU//I
ESTzuZ/HV5i5tEctnaJnibfG1eqV7ieEAQ+JHfjLyACEGqHbT1wnwVYO1gaerCUG
Z6IiLtIe2380Nk4+TlU8/rRS8cnAszWb/CnUdYiGMUrgNfhgrlTey6hgb5vuWNfA
gmMdvHNFXB3yXXbMKDYjJ+TEuVXBzVTCFOwxxPxBSckQyL7iI8cg09Ke2tTmmdkL
lwrVnC44I2z0cTkYQwtW8O+Bhi4N4umSv1ArrJGOXX1QTcKozhpfT5QVFMD+s6yG
J4t10stb7iL2SYKclPZNS1u4UPkNTEx6/euZfyMQvZ1Z7ZjLQTxmpfUc2R7zWpA=
=Nraq
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/5584c257/attachment.htm>

From yvoinov at gmail.com  Sun Dec 27 23:04:50 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 28 Dec 2015 05:04:50 +0600
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <56806CF6.2050108@trimble.com>
References: <56806285.8080102@trimble.com> <56806B39.3050805@gmail.com>
 <56806CF6.2050108@trimble.com>
Message-ID: <56806E92.9000808@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
wpad.dat&proxy.pac?

28.12.15 4:57, Jason Haar ?????:
> On 28/12/15 11:50, Yuri Voinov wrote:
>> I think, to eliminate this error you need to splice all torify
connections.
> As I said - squid is configured to *only*  splice - there is no bump-ing
> going on. So this is already the case
>
> acl DiscoverSNIHost at_step SslBump1
> ssl_bump peek DiscoverSNIHost
> acl SSL_https port 443
> ssl_bump splice SSL_https
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWgG6SAAoJENNXIZxhPexG5goIAMEsk0p8KVhLHKhsJaJGU5ya
lhWAqEv+iA4byiXoPmGsz0FqBmw2IhQrpbyw+WXdhDuEcQkC7d4iMpGceX/PoeM7
H1FWvdLX4BtIybexi6fhj55m1xUhS7JgL0/KUCWsZBAECpc6r9ckgqoi1uysmEGF
L+2ZxLw1lyax7d7vaMDNNXHoBt+BoIUSkGZGtaU+Ry8sXtZa8elqsTDGqHtm2nPd
QjzDjFc26U2VISM7P7ecxSsZI9LO0XxPuVVS0JdbZG28p1ksTFc7TdclptlWh/sQ
Vl7R0GIaU29qJrJbOLLwIDjpI2yPMtMnq5S8AdrOJxNl5cXckog4ccCzGQ9hEdQ=
=Hv/7
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/e77c6fcf/attachment.htm>

From rousskov at measurement-factory.com  Sun Dec 27 23:45:04 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 27 Dec 2015 16:45:04 -0700
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <56806285.8080102@trimble.com>
References: <56806285.8080102@trimble.com>
Message-ID: <56807800.6040508@measurement-factory.com>

On 12/27/2015 03:13 PM, Jason Haar wrote:
> Surely if all you are doing is
> splice-only, it shouldn't be doing that check at all?


The situation is not that black-and-white, unfortunately. This general
problem can be viewed under several different angles:

A. You are not using a splice-only configuration.

As you said, you are peeking at SNI before splicing. Thus, your overall
configuration (and Squid involvement) is much more complex than
"splice-only". Pure splicing would have worked fine (or would fail for
different reasons).


B. Your splicing intent is unknown to Squid.

There are several common reasons for splicing, including:

1.  To avoid bumping things that cannot or should not be bumped.
2a. To log connection details.
2b. To return errors when connections fail certain validation checks.


C. Your final action may be unknown to validating Squid.

During a "peek" or "stare" action, Squid does not yet know whether the
final SslBump action is going to be "splice", "bump", or "terminate".
Thus, even if we manage to agree that "splice" means "check nothing",
Squid would not be able to apply that agreement to the "peek" action,
unless we also agree that "peek" means "check nothing".

And if neither peek nor splice should check anything, then how can an
admin rewrite her currently-working configuration that validates server
certificates without bumping connections to sites that pass validation?


AFAICT, given the above mixture, Squid cannot reliably determine your
true peeking-and-splicing intent and disable the right set of checks
accordingly while supporting everything it already supports. Do we need
more configuration knobs to help Squid to make the right decision?

Alex.



From saravanan.nagarajan87 at gmail.com  Mon Dec 28 00:30:57 2015
From: saravanan.nagarajan87 at gmail.com (SaRaVanAn)
Date: Sun, 27 Dec 2015 18:30:57 -0600
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
Message-ID: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>

Hi,
We are using squid 3.1.20 in our box. We are facing issues on configuring
and validating the refresh patterns. It looks like squid is not honoring
the refresh patterns properly.


*configuration*
*refresh_pattern -i ^http://.wsj./.* 10 200% 10 override-expire
override-lastmod reload-into-ims ignore-reload*
refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 480 100% 480 override-expire
override-lastmod reload-into-ims
refresh_pattern -i \.(htm|html|js|css)$ 480 100% 480 override-expire
override-lastmod reload-into-ims

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


As per above refresh pattern squid should refresh the cache every ten
minutes for "*^http://.wsj./.*" .  *But I am always getting either
TCP_HIT/TCP_MEM_HIT even after hours. Why is it so? . Please find the logs
below

*Log*

1261741.309      0 172.19.131.180 TCP_MEM_HIT/200 7635 GET
http://si.wsj.net/public/resources/images/BN-LW172_DRO
http://si.wsj.net/public/resources/images/BN-LV628_CITIOF_BR_20151223170624.jpg
- NONE/- image/jpeg
1451261741.336      0 172.19.131.180 TCP_HIT/200 10595 GET
http://si.wsj.net/public/resources/images/MI-CN459_ELNINO_BR_20151227175637.jpg
- NONE/- image/jpeg
1451261741.343      0 172.19.131.180 TCP_MEM_HIT/200 3986 GET
http://si.wsj.net/public/resources/images/BN-LV846_Tape_0_Z120_20151224145546.jpg
- NONE/- image/jpeg
1451261741.354      0 172.19.131.180 TCP_MEM_HIT/200 3432 GET
http://si.wsj.net/public/resources/images/BN-LV849_Oileco_Z120_20151224150223.jpg
- NONE/- image/jpeg
1451261741.361      0 172.19.131.180 TCP_MEM_HIT/200 2385 GET
http://video-api.wsj.com/api-video/player/v2/css/play_btn_80.png - NONE/-
image/png
1451261741.389      0 172.19.131.180 TCP_MEM_HIT/200 1675 GET
http://video-api.wsj.com/api-video/player/v2/css/play_btn_50.png - NONE/-
image/png
1451261741.407    756 172.19.131.180 TCP_HIT/200 534151 GET
http://vir.wsj.net/fp/assets/1e6e09e66457156e0903/SectionPage.js - NONE/-
application/javascript
1451261742.341     51 172.19.131.180 TCP_HIT/200 65486 GET
http://m.wsj.net/video/20151227/122715storms/122715storms_960x540.jpg -
NONE/- image/jpeg
1451261742.428    132 172.19.131.180 TCP_HIT/200 53668 GET
http://m.wsj.net/video/20151223/121415barpilots/121415barpilots_960x540.jpg
- NONE/
NE1_D_20151227175102.jpg - NONE/- image/jpeg
1451261741.310      0 172.19.131.180 TCP_MEM_HIT/200 8302 GET
http://si.wsj.net/public/resources/images/BN-LW104_itarge_D_20151227070713.jpg
- NONE/- image/jpeg
1451261741.318      0 172.19.131.180 TCP_HIT/200 12217 GET
http://si.wsj.net/public/resources/images/BN-LW010_OVERST_D_20151225160015.jpg
- NONE/- image/jpeg


Regards,
Saravanan N
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151227/2c43eb2c/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 28 01:15:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 28 Dec 2015 14:15:10 +1300
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
In-Reply-To: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
References: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
Message-ID: <56808D1E.5050209@treenet.co.nz>

On 28/12/2015 1:30 p.m., SaRaVanAn wrote:
> Hi,
> We are using squid 3.1.20 in our box. We are facing issues on configuring
> and validating the refresh patterns. It looks like squid is not honoring
> the refresh patterns properly.
> 
> 
> *configuration*
> *refresh_pattern -i ^http://.wsj./.* 10 200% 10 override-expire
> override-lastmod reload-into-ims ignore-reload*
> refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 480 100% 480 override-expire
> override-lastmod reload-into-ims
> refresh_pattern -i \.(htm|html|js|css)$ 480 100% 480 override-expire
> override-lastmod reload-into-ims
> 
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> 
> 
> As per above refresh pattern squid should refresh the cache every ten
> minutes for "*^http://.wsj./.*" .  *But I am always getting either
> TCP_HIT/TCP_MEM_HIT even after hours. Why is it so? . Please find the logs
> below

Because none of the log entries match the regex pattern "^http://.wsj./.*".

PS. the trailing ".* is useless, the other uses of '.' only match one
single character.


Try this for more correct behaviour:
  refresh_pattern -i ^http://[a-zA-Z]+\.wsj\.net/ 10 200% 10 \
    override-expire reload-into-ims

Amos


From squid3 at treenet.co.nz  Mon Dec 28 01:34:11 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 28 Dec 2015 14:34:11 +1300
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <56806285.8080102@trimble.com>
References: <56806285.8080102@trimble.com>
Message-ID: <56809193.5060602@treenet.co.nz>

On 28/12/2015 11:13 a.m., Jason Haar wrote:
> Hi there
> 
> I use TOR a bit for testing our WAFs and found that it no longer worked
> on my test network that has squid configured in TLS intercept mode. I
> currently have squid configured to "splice only" (with peek to get the
> SNI name) - ie no bumping - purely so that the squid access_log file
> contains better records on HTTPS hostnames

But logging is not the only thing that SNI is used for.

Both the peek to get the SNI and the resulting IP->hostame changes from
finding SNI introduce different logic behaviour.

> 
> 2015/12/28 09:22:04.189 kid1| SECURITY ALERT: Host header forgery
> detected on local=194.109.206.212:443 remote=192.168.0.21:40427 FD 30
> flags=33 (local IP does not match any domain IP)
> 2015/12/28 09:22:04.189 kid1| SECURITY ALERT: By user agent:
> 2015/12/28 09:22:04.189 kid1| SECURITY ALERT: on URL: www.z2b4e372r4.com:443
> 
> Removing the redirect of tcp/443 totally fixes the problem.


What redirect ?

> 
> Anyway, it would appear that squid-3.5.10 in splice-only mode still
> enables the "Host header forgery" check?

1) Host check is initiated for all requests received on intercepted traffic.

2) SSL-bump traffic fakes a CONNECT with raw-IP details that gets passed
through those (1) checks.

3) SNI presence changes the CONNECT from raw-IP to one with a Hostname.
That Hostname needs to match the TCP connection raw-IP.


> Surely if all you are doing is
> splice-only, it shouldn't be doing that check at all? ie I could
> understand triggering blocking actions if squid was part of the
> transaction in bump-mode - but when it's "only looking", it is exactly
> the same as not doing splice at all - so why trigger the Host header check?

It is not only looking. It is updating internal state and logics based
on what it sees in the TLS.

> 
> It does look like TOR has something equivalent to a /etc/host file with
> fake DNS names - so it's quite understandable that freaks squid out.
> Actually, if squid cannot resolve a SNI hostname, shouldn't that skip
> the Host name check?

Well, Squid should not get to the point of testing Host name in the HTTP
messages. SNI is mandatory to contain a resolvable FQDN. Not doing so is
a TLS protocol violation and Squid should just abort down to either
terminate or blindly tunnel based on your on_unknown_protocol settings.

> 
> Also, this isn't that easy to test: it would appear that once I turned
> off intercept and successfully used TOR, it must have cached a bunch of
> things because I then re-enabled intercept and it's no longer making any
> tcp/443 connections - it goes straight out on other "native" TOR ports.
> So it may be this can only be tested on a fresh install (or after some
> cache timeout period)
> 


if you want to dig into this further I suggest getting a "debug_options
ALL,9" output and looking at what cache.log says about the state of the
request that is being checked and failing.


Amos



From Jason_Haar at trimble.com  Mon Dec 28 03:33:22 2015
From: Jason_Haar at trimble.com (Jason Haar)
Date: Mon, 28 Dec 2015 16:33:22 +1300
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <56809193.5060602@treenet.co.nz>
References: <56806285.8080102@trimble.com> <56809193.5060602@treenet.co.nz>
Message-ID: <5680AD82.6020901@trimble.com>

On 28/12/15 14:34, Amos Jeffries wrote:
> Removing the redirect of tcp/443 totally fixes the problem.
>
> What redirect ?

tcp/443 redirect - sorry bad choice of words (really iptables REDIRECT).
ie TOR starts working if it isn't going through squid (which I
appreciate doesn't add much to this conversation - but it does prove
it's not some generic firewall/network problem)

> Well, Squid should not get to the point of testing Host name in the HTTP
> messages. SNI is mandatory to contain a resolvable FQDN. Not doing so is
> a TLS protocol violation and Squid should just abort down to either
> terminate or blindly tunnel based on your on_unknown_protocol settings.

Ooh - I haven't heard of "on_unknown_protocol"? I don't see it in the
squid.conf.documented that comes with squid-3.5.10?

That sounds exactly what's needed. What we have here is a situation
where a "bogus" application is routing through tcp/443 - which we choose
to do transparent TLS intercept on. What I want is to use peek/splice to
improve our logging - but otherwise not fiddle with any application that
happens to run over tcp/443.

I did find "on_unsupported_protocol"  - so added
"on_unsupported_protocol tunnel SSL_https" (acl SSL_https port 443) -
but that triggered a squid-3.5.10 config error? Is this a new squid-4
feature?


> if you want to dig into this further I suggest getting a
> "debug_options ALL,9" output and looking at what cache.log says about
> the state of the request that is being checked and failing.

I think we know what the problem is: TOR is making TLS connections (I
don't know if they're HTTPS) on port 443 and uses SNI names that aren't
real?


-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From saravanan.nagarajan87 at gmail.com  Mon Dec 28 04:30:22 2015
From: saravanan.nagarajan87 at gmail.com (SaRaVanAn)
Date: Sun, 27 Dec 2015 22:30:22 -0600
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
In-Reply-To: <56808D1E.5050209@treenet.co.nz>
References: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
 <56808D1E.5050209@treenet.co.nz>
Message-ID: <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>

Thanks for prompt response.

I want to match all the URL's which has a pattern of "wsj" (example: *.
wsj.com, *.wsj.net, *.wsj.edu ) . Does wildcard makes sense in squid
refresh pattern? Can we have something like this?

 refresh_pattern -i ^http://*\.wsj\.*/ 10 200% 10 \
    override-expire reload-into-ims


- Saravanan N

On Sun, Dec 27, 2015 at 7:15 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 28/12/2015 1:30 p.m., SaRaVanAn wrote:
> > Hi,
> > We are using squid 3.1.20 in our box. We are facing issues on configuring
> > and validating the refresh patterns. It looks like squid is not honoring
> > the refresh patterns properly.
> >
> >
> > *configuration*
> > *refresh_pattern -i ^http://.wsj./.* 10 200% 10 override-expire
> > override-lastmod reload-into-ims ignore-reload*
> > refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 480 100% 480 override-expire
> > override-lastmod reload-into-ims
> > refresh_pattern -i \.(htm|html|js|css)$ 480 100% 480 override-expire
> > override-lastmod reload-into-ims
> >
> > refresh_pattern ^ftp:           1440    20%     10080
> > refresh_pattern ^gopher:        1440    0%      1440
> > refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> > refresh_pattern .               0       20%     4320
> >
> >
> > As per above refresh pattern squid should refresh the cache every ten
> > minutes for "*^http://.wsj./.*" .  *But I am always getting either
> > TCP_HIT/TCP_MEM_HIT even after hours. Why is it so? . Please find the
> logs
> > below
>
> Because none of the log entries match the regex pattern "^http://
> .wsj./.*".
>
> PS. the trailing ".* is useless, the other uses of '.' only match one
> single character.
>
>
> Try this for more correct behaviour:
>   refresh_pattern -i ^http://[a-zA-Z]+\.wsj\.net/ 10 200% 10 \
>     override-expire reload-into-ims
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151227/6a7db585/attachment.htm>

From eliezer at ngtech.co.il  Mon Dec 28 04:50:48 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 28 Dec 2015 06:50:48 +0200
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
In-Reply-To: <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>
References: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
 <56808D1E.5050209@treenet.co.nz>
 <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>
Message-ID: <5680BFA8.1010008@ngtech.co.il>

Hey,

The pattern you wrote is wrong and also doesn't describe your need\desire.

A domain name can contain only certain characters so using a "." is wrong.
Also url and domain regular expressions should be as strict as possible 
so you would not have false positive matches.
Amos suggested to use:
refresh_pattern -i ^http://[a-zA-Z]+\.wsj\.net/ 10 200% 10 \
     override-expire reload-into-ims

And you can tweak it a bit to something like:
refresh_pattern -i ^http://[a-z\-\_\.A-Z0-9]+\.wsj\.(net|net|com|edu)/ 
10 200% 10 \
	override-expire reload-into-ims

which would describe what you want in a better way and will not produce 
false positive matches.
I would suggest you to use the next online tools:
https://regex101.com/
http://rubular.com/
http://www.regextester.com/

against a lost of urls such as you have mentioned:
http://www.wsj.net/wwww
http://www.wsj.donotexistdomain/wwww
http://test1.test-2.www.wsj.donotexistdomain/wwww
http://test1.test-2.www.wsj.edu/wwww
http://test1.test-2.www.wsj.text.com/wwww
http://test1.test-2.www.wsj.text.net/wwww
http://test1.test-2.www.wsj.text-4.ddd.net/wwww

And you can find couple real urls in your logs to match.

Once you have tested that different patterns you will be able to 
understand the issue with your patterns a bit better.

Eliezer

On 28/12/2015 06:30, SaRaVanAn wrote:
> Thanks for prompt response.
>
> I want to match all the URL's which has a pattern of "wsj" (example: *.
> wsj.com, *.wsj.net, *.wsj.edu ) . Does wildcard makes sense in squid
> refresh pattern? Can we have something like this?
>
>   refresh_pattern -i ^http://*\.wsj\.*/ 10 200% 10 \
>      override-expire reload-into-ims
>
>
> - Saravanan N



From squid3 at treenet.co.nz  Mon Dec 28 04:54:58 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 28 Dec 2015 17:54:58 +1300
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
In-Reply-To: <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>
References: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
 <56808D1E.5050209@treenet.co.nz>
 <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>
Message-ID: <5680C0A2.7000908@treenet.co.nz>

On 28/12/2015 5:30 p.m., SaRaVanAn wrote:
> Thanks for prompt response.
> 
> I want to match all the URL's which has a pattern of "wsj" (example: *.
> wsj.com, *.wsj.net, *.wsj.edu ) . Does wildcard makes sense in squid
> refresh pattern? Can we have something like this?
> 
>  refresh_pattern -i ^http://*\.wsj\.*/ 10 200% 10 \
>     override-expire reload-into-ims
> 

Of course. It is a regex pattern. The problem is your own understanding
of regex, so the patterns you are designing are not doing anything like
what you want.

<http://regexone.com/> might help you there.

Amos



From hack.back at hotmail.com  Mon Dec 28 10:58:29 2015
From: hack.back at hotmail.com (HackXBack)
Date: Mon, 28 Dec 2015 02:58:29 -0800 (PST)
Subject: [squid-users] cant bump ssl
In-Reply-To: <567096E6.70604@treenet.co.nz>
References: <1450208816089-4675201.post@n4.nabble.com>
 <567096E6.70604@treenet.co.nz>
Message-ID: <1451300309800-4675296.post@n4.nabble.com>

i remove all sslproxy_* settings 
and the same problem, 
facebook on android cant be load contents like images and videos and it says 
1451326656.959    253 172.22.35.1 TAG_NONE/200 0 CONNECT 104.96.90.24:443 -
ORIGINAL_DST/104.96.90.24 -
1



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/cant-bump-ssl-tp4675201p4675296.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From richard at falsyana.com  Mon Dec 28 11:51:18 2015
From: richard at falsyana.com (Richard)
Date: Mon, 28 Dec 2015 12:51:18 +0100
Subject: [squid-users] Squid as a proxy (Forwarding loop detected)
Message-ID: <CACToMp=Hwx3h=46QNNOesx=wR5JO1719ebUHdCdj4xfUjXmg+g@mail.gmail.com>

Hi,

This question has been asked many times before, but unfortunately the ones
I checked did not seem to have a solution for me.

I am trying to setup squid as transparent proxy, but I keep getting the
error Forwarding loop detected.

I have the following setup:
Client [172.24.30.11] <-> Router [172.24.30.253 && 172.24.10.253 ] <->
Squid Server [172.24.10.13]

The configuration for squid is as following:
http_port 8080
http_port 3129 intercept
http_access allow all

The iptables rule on my router is as follow:
iptables -t nat -I PREROUTING -s 172.24.30.11 -p tcp --dport 80 -j DNAT
--to 172.24.10.13:3129

Now when the client tries to download something I get the following logs:
---- access.log ----
1451303118.327      0 172.24.10.13 TCP_MISS/403 3751 GET
http://74.125.136.94/ - HIER_NONE/- text/html
1451303118.327      0 172.24.30.11 TCP_MISS/403 3915 GET
http://74.125.136.94/ - HIER_DIRECT/172.24.10.13 text/html

---- cache.log ----
2015/12/28 12:45:14 kid1| Starting Squid Cache version 3.3.8 for
x86_64-redhat-linux-gnu...
2015/12/28 12:45:14 kid1| Process ID 776
2015/12/28 12:45:14 kid1| Process Roles: worker
2015/12/28 12:45:14 kid1| With 16384 file descriptors available
2015/12/28 12:45:14 kid1| Initializing IP Cache...
2015/12/28 12:45:14 kid1| DNS Socket created at [::], FD 7
2015/12/28 12:45:14 kid1| DNS Socket created at 0.0.0.0, FD 8
2015/12/28 12:45:14 kid1| Adding domain int-mgt.bitcube.nl from
/etc/resolv.conf
2015/12/28 12:45:14 kid1| Adding domain int-prd.bitcube.nl from
/etc/resolv.conf
2015/12/28 12:45:14 kid1| Adding domain dmz-prd.bitcube.nl from
/etc/resolv.conf
2015/12/28 12:45:14 kid1| Adding nameserver 172.24.10.253 from
/etc/resolv.conf
2015/12/28 12:45:14 kid1| Logfile: opening log
daemon:/var/log/squid/access.log
2015/12/28 12:45:14 kid1| Logfile Daemon: opening log
/var/log/squid/access.log
2015/12/28 12:45:14 kid1| Local cache digest enabled; rebuild/rewrite every
3600/3600 sec
2015/12/28 12:45:14 kid1| Store logging disabled
2015/12/28 12:45:14 kid1| Swap maxSize 0 + 262144 KB, estimated 20164
objects
2015/12/28 12:45:14 kid1| Target number of buckets: 1008
2015/12/28 12:45:14 kid1| Using 8192 Store buckets
2015/12/28 12:45:14 kid1| Max Mem  size: 262144 KB
2015/12/28 12:45:14 kid1| Max Swap size: 0 KB
2015/12/28 12:45:14 kid1| Using Least Load store dir selection
2015/12/28 12:45:14 kid1| Current Directory is /
2015/12/28 12:45:14 kid1| Loaded Icons.
2015/12/28 12:45:14 kid1| HTCP Disabled.
2015/12/28 12:45:14 kid1| Squid plugin modules loaded: 0
2015/12/28 12:45:14 kid1| Adaptation support is off.
2015/12/28 12:45:14 kid1| Accepting HTTP Socket connections at
local=[::]:8080 remote=[::] FD 11 flags=9
2015/12/28 12:45:14 kid1| Accepting NAT intercepted HTTP Socket connections
at local=0.0.0.0:3129 remote=[::] FD 12 flags=41
2015/12/28 12:45:15 kid1| storeLateRelease: released 0 objects
2015/12/28 12:45:18 kid1| WARNING: Forwarding loop detected for:
GET / HTTP/1.1
User-Agent: curl/7.29.0
Host: 74.125.136.94
Accept: */*
Via: 1.1 srv-proxy01.xxxxxxxxxxxx (squid/3.3.8)
X-Forwarded-For: 172.24.30.11
Cache-Control: max-age=259200
Connection: keep-alive

If I configure the client to use a proxy (on port 8080) it all works fine.

I have a feeling i'm forgetting something simple :(
Hopefully someone can point me into the right direction?

Thanks !

Richard
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/b32a1a87/attachment.htm>

From rafael.akchurin at diladele.com  Mon Dec 28 12:01:09 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 28 Dec 2015 12:01:09 +0000
Subject: [squid-users] Squid as a proxy (Forwarding loop detected)
In-Reply-To: <CACToMp=Hwx3h=46QNNOesx=wR5JO1719ebUHdCdj4xfUjXmg+g@mail.gmail.com>
References: <CACToMp=Hwx3h=46QNNOesx=wR5JO1719ebUHdCdj4xfUjXmg+g@mail.gmail.com>
Message-ID: <VI1PR04MB135927124C30AB5E91664D7F8FFB0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Richard,

The NATting needs to happen on the gateway ? here is more info https://squidproxy.wordpress.com/2014/12/19/squid-3-2-mythbusting-nat/

Best regards,
Rafael

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Richard
Sent: Monday, December 28, 2015 12:51 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid as a proxy (Forwarding loop detected)

Hi,

This question has been asked many times before, but unfortunately the ones I checked did not seem to have a solution for me.

I am trying to setup squid as transparent proxy, but I keep getting the error Forwarding loop detected.

I have the following setup:
Client [172.24.30.11] <-> Router [172.24.30.253 && 172.24.10.253 ] <-> Squid Server [172.24.10.13]

The configuration for squid is as following:
http_port 8080
http_port 3129 intercept
http_access allow all

The iptables rule on my router is as follow:
iptables -t nat -I PREROUTING -s 172.24.30.11 -p tcp --dport 80 -j DNAT --to 172.24.10.13:3129<http://172.24.10.13:3129>

Now when the client tries to download something I get the following logs:
---- access.log ----
1451303118.327      0 172.24.10.13 TCP_MISS/403 3751 GET http://74.125.136.94/ - HIER_NONE/- text/html
1451303118.327      0 172.24.30.11 TCP_MISS/403 3915 GET http://74.125.136.94/ - HIER_DIRECT/172.24.10.13<http://172.24.10.13> text/html

---- cache.log ----
2015/12/28 12:45:14 kid1| Starting Squid Cache version 3.3.8 for x86_64-redhat-linux-gnu...
2015/12/28 12:45:14 kid1| Process ID 776
2015/12/28 12:45:14 kid1| Process Roles: worker
2015/12/28 12:45:14 kid1| With 16384 file descriptors available
2015/12/28 12:45:14 kid1| Initializing IP Cache...
2015/12/28 12:45:14 kid1| DNS Socket created at [::], FD 7
2015/12/28 12:45:14 kid1| DNS Socket created at 0.0.0.0, FD 8
2015/12/28 12:45:14 kid1| Adding domain int-mgt.bitcube.nl<http://int-mgt.bitcube.nl> from /etc/resolv.conf
2015/12/28 12:45:14 kid1| Adding domain int-prd.bitcube.nl<http://int-prd.bitcube.nl> from /etc/resolv.conf
2015/12/28 12:45:14 kid1| Adding domain dmz-prd.bitcube.nl<http://dmz-prd.bitcube.nl> from /etc/resolv.conf
2015/12/28 12:45:14 kid1| Adding nameserver 172.24.10.253 from /etc/resolv.conf
2015/12/28 12:45:14 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2015/12/28 12:45:14 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2015/12/28 12:45:14 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2015/12/28 12:45:14 kid1| Store logging disabled
2015/12/28 12:45:14 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2015/12/28 12:45:14 kid1| Target number of buckets: 1008
2015/12/28 12:45:14 kid1| Using 8192 Store buckets
2015/12/28 12:45:14 kid1| Max Mem  size: 262144 KB
2015/12/28 12:45:14 kid1| Max Swap size: 0 KB
2015/12/28 12:45:14 kid1| Using Least Load store dir selection
2015/12/28 12:45:14 kid1| Current Directory is /
2015/12/28 12:45:14 kid1| Loaded Icons.
2015/12/28 12:45:14 kid1| HTCP Disabled.
2015/12/28 12:45:14 kid1| Squid plugin modules loaded: 0
2015/12/28 12:45:14 kid1| Adaptation support is off.
2015/12/28 12:45:14 kid1| Accepting HTTP Socket connections at local=[::]:8080 remote=[::] FD 11 flags=9
2015/12/28 12:45:14 kid1| Accepting NAT intercepted HTTP Socket connections at local=0.0.0.0:3129<http://0.0.0.0:3129> remote=[::] FD 12 flags=41
2015/12/28 12:45:15 kid1| storeLateRelease: released 0 objects
2015/12/28 12:45:18 kid1| WARNING: Forwarding loop detected for:
GET / HTTP/1.1
User-Agent: curl/7.29.0
Host: 74.125.136.94
Accept: */*
Via: 1.1 srv-proxy01.xxxxxxxxxxxx (squid/3.3.8)
X-Forwarded-For: 172.24.30.11
Cache-Control: max-age=259200
Connection: keep-alive

If I configure the client to use a proxy (on port 8080) it all works fine.

I have a feeling i'm forgetting something simple :(
Hopefully someone can point me into the right direction?

Thanks !

Richard
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/e0bbbad3/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 28 12:03:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 29 Dec 2015 01:03:38 +1300
Subject: [squid-users] Squid as a proxy (Forwarding loop detected)
In-Reply-To: <CACToMp=Hwx3h=46QNNOesx=wR5JO1719ebUHdCdj4xfUjXmg+g@mail.gmail.com>
References: <CACToMp=Hwx3h=46QNNOesx=wR5JO1719ebUHdCdj4xfUjXmg+g@mail.gmail.com>
Message-ID: <5681251A.6050104@treenet.co.nz>

On 29/12/2015 12:51 a.m., Richard wrote:
> Hi,
> 
> This question has been asked many times before, but unfortunately the ones
> I checked did not seem to have a solution for me.
> 
> I am trying to setup squid as transparent proxy, but I keep getting the
> error Forwarding loop detected.
> 
> I have the following setup:
> Client [172.24.30.11] <-> Router [172.24.30.253 && 172.24.10.253 ] <->
> Squid Server [172.24.10.13]
> 
> The configuration for squid is as following:
> http_port 8080
> http_port 3129 intercept
> http_access allow all
> 
> The iptables rule on my router is as follow:

That is the problem.

NAT interception must be done *on the same machine as Squid*.

Use policy routing on the router, and NAT (or TPROXY) on the Squid machine.
<http://wiki.squid-cache.org/ConfigExamples/Intercept/IptablesPolicyRoute>

Amos



From uhlar at fantomas.sk  Mon Dec 28 12:13:59 2015
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 28 Dec 2015 13:13:59 +0100
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
In-Reply-To: <5680BFA8.1010008@ngtech.co.il>
References: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
 <56808D1E.5050209@treenet.co.nz>
 <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>
 <5680BFA8.1010008@ngtech.co.il>
Message-ID: <20151228121359.GA1357@fantomas.sk>

On 28.12.15 06:50, Eliezer Croitoru wrote:
>And you can tweak it a bit to something like:
>refresh_pattern -i 
>^http://[a-z\-\_\.A-Z0-9]+\.wsj\.(net|net|com|edu)/ 10 200% 10 \
>	override-expire reload-into-ims

- I would avoid the underscore. underscore is not valid character for an
internet hostname
- dash at the begin or end of [] will eliminate the need for an underscore

[a-zA-Z0-9.-]+ should do it.
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
"To Boot or not to Boot, that's the question." [WD1270 Caviar]


From eliezer at ngtech.co.il  Mon Dec 28 12:35:51 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 28 Dec 2015 14:35:51 +0200
Subject: [squid-users] [squid-announce] Squid 3.5.12 is available
In-Reply-To: <565A94A9.1060601@treenet.co.nz>
References: <565A94A9.1060601@treenet.co.nz>
Message-ID: <56812CA7.3050900@ngtech.co.il>

I took the time to build and test a RPM for OpenSUSE leap 42.1 at:
http://ngtech.co.il/repo/opensuse/leap/x86_64/squid-3.5.12-1.0.x86_64.rpm

SRPM at:
http://ngtech.co.il/repo/opensuse/leap/SRPMS/

Eliezer

On 29/11/2015 08:01, Amos Jeffries wrote:
> The Squid HTTP Proxy team is very pleased to announce the availability
> of the Squid-3.5.12 release!
>
>
> This release is a bug fix release resolving issues found in the prior
> Squid releases.
>
>
> The major changes to be aware of:
<SNIP>


From william.lima at hscbrasil.com.br  Mon Dec 28 12:55:17 2015
From: william.lima at hscbrasil.com.br (William Lima)
Date: Mon, 28 Dec 2015 10:55:17 -0200 (BRST)
Subject: [squid-users] Squid 3.5.x Certificate validator + SslBump memory
	leak
In-Reply-To: <501956699.856.1451306836182.JavaMail.root@hscbrasil.com.br>
Message-ID: <1105333551.886.1451307317287.JavaMail.root@hscbrasil.com.br>

Hi all,

When the certificate validator feature is enabled in Squid 3.5.x, its memory usage is up to 4.5Gb (and keeps growing). Even with r13967.


-- 
William Lima




From marcus.kool at urlfilterdb.com  Mon Dec 28 13:58:57 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 28 Dec 2015 11:58:57 -0200
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <5680AD82.6020901@trimble.com>
References: <56806285.8080102@trimble.com> <56809193.5060602@treenet.co.nz>
 <5680AD82.6020901@trimble.com>
Message-ID: <56814021.3050900@urlfilterdb.com>



On 12/28/2015 01:33 AM, Jason Haar wrote:
> On 28/12/15 14:34, Amos Jeffries wrote:
[...]
> I think we know what the problem is: TOR is making TLS connections (I
> don't know if they're HTTPS) on port 443 and uses SNI names that aren't
> real?

peeking on tor-proxy-2.cypherpunks.to shows a certificate with
   issuer '/CN=www.totaikrsupklbpy5.com'
   subject '/CN=www.bpanciu6f5cjqflv2.net'
so the certificate is definitely bogus.

marcus


From yvoinov at gmail.com  Mon Dec 28 14:29:43 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 28 Dec 2015 20:29:43 +0600
Subject: [squid-users] Host header forgery affects pure splice
 environment too?
In-Reply-To: <56814021.3050900@urlfilterdb.com>
References: <56806285.8080102@trimble.com> <56809193.5060602@treenet.co.nz>
 <5680AD82.6020901@trimble.com> <56814021.3050900@urlfilterdb.com>
Message-ID: <56814757.4080101@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Heh. It seems bogus by our opinion.

Tor certainly thinks otherwise.

Actually, from this stupid idea to do a bump Tor network traffic?

28.12.15 19:58, Marcus Kool ?????:
>
>
> On 12/28/2015 01:33 AM, Jason Haar wrote:
>> On 28/12/15 14:34, Amos Jeffries wrote:
> [...]
>> I think we know what the problem is: TOR is making TLS connections (I
>> don't know if they're HTTPS) on port 443 and uses SNI names that aren't
>> real?
>
> peeking on tor-proxy-2.cypherpunks.to shows a certificate with
>   issuer '/CN=www.totaikrsupklbpy5.com'
>   subject '/CN=www.bpanciu6f5cjqflv2.net'
> so the certificate is definitely bogus.
>
> marcus
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWgUdWAAoJENNXIZxhPexGoW4H/3aTH/y+C7pMWK+2BtHNIB4T
NMueFP/Nv2ixJf8MmqPh765R3Q6o3KWWEuK6BHcunZRjQJh1glz6h073ocVSb2EJ
BkhHUFuYbF31hwZCvZwFr7tFlKDvQ9yBvmwk3Ep3KjiFThoF+uwyV3HbEWmUx083
hAgVfXnqqeClhZx4WSrOLLLc4BTAfuCYM84ox6JRemqHq5kFpObaLRPCvNkO+VtF
M/yId+ag4pyUMGcTXN0KD+SHtgdKkraWRP7u5RrQ0kiScwv5Q30nV09MY93qkvaB
hi5qgEGLlDyO+qXkqpNoPXYqinVFRGgEE7OMzbthvCRJk1v2XVB2I+mab1McnQk=
=H3Ki
-----END PGP SIGNATURE-----



From piphonom at gmail.com  Mon Dec 28 14:34:51 2015
From: piphonom at gmail.com (Alexei Mayanov)
Date: Mon, 28 Dec 2015 17:34:51 +0300
Subject: [squid-users] Fwd: Squid authentication on the origin server during
	SslBumping
In-Reply-To: <CAODHJdx1C2s+_WQeeY0j6mDJ37gtYseb1V=ior7DEy0_OVBdRA@mail.gmail.com>
References: <CAODHJdx1C2s+_WQeeY0j6mDJ37gtYseb1V=ior7DEy0_OVBdRA@mail.gmail.com>
Message-ID: <CAODHJdwZ71CwEFCzv2M65mrdFjm4LjKPcJ7g4eEb75+GFWvRfw@mail.gmail.com>

Hello!
Sorry if my question is repeated, but I didn't find any answer.
We have the remote web server where only authenticated users have
access to it. Authentication is made by X509 certificates.
I want that  authentication to remote web server will be transparent
for our local network users. For this I'm trying to setup Squid in
transparent mode with SSL bumping.
Is it possible to setup Squid to authenticate himself on the remote
origin by X509 certificate?

I try to setup Squid 3.5.12 to make SSL bumping and authenticate
himself on the origin by the X509 certificate. But unsuccessfull.
There is part of my test config for ssl bumping:

#bumping
https_port 3131 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/home/user/squiddata/myCA.pem
ssl_bump peek all
ssl_bump bump all
sslcrtd_program /usr/lib/squid/ssl_crtd -s /home/user/squiddata/ssl_db
-M 4MB
sslcrtd_children 5
sslproxy_client_certificate /home/user/squiddata/client.crt          #
certificate to authenticate server on the Origin. Is it right?
sslproxy_client_key /home/user/squiddata/.key
 # apropreate key
sslproxy_cafile /etc/ssl/certs/ca-certificates.crt
       # CAs bundle
acl SSLERR ssl_error X509_V_ERR_DEPTH_ZERO_SELF_SIGNED_CERT
X509_V_ERR_SELF_SIGNED_CERT_IN_CHAIN
sslproxy_cert_error allow SSLERR
sslproxy_cert_error deny all

But I get the following error:

Error negotiating SSL on FD 12: error:1407743E:SSL
routines:SSL23_GET_SERVER_HELLO:tlsv1 alert inappropriate fallback
(1/-1/0)
1450974176.611     45 192.168.1.114 TAG_NONE/200 0 CONNECT <remote
ip>:443 - ORIGINAL_DST/<remote ip> -
Error negotiating SSL connection on FD 10: error:140A1175:SSL
routines:SSL_BYTES_TO_CIPHER_LIST:inappropriate fallback (1/-1)

Seems remote server can't authenticate Squid.

SSL bumping with only remote server verification works well.

Thanks for advance.


From joru.pacs at gmail.com  Mon Dec 28 15:22:58 2015
From: joru.pacs at gmail.com (joru.pacs)
Date: Mon, 28 Dec 2015 23:22:58 +0800
Subject: [squid-users]  Squid proxy whitelisting with HTTPS URL filtering
Message-ID: <E9A0B32D-0D9C-439C-AB7F-37A69C7AB3B4@gmail.com>

Hi!

I am trying to set up squid to be a whitelist proxy which should be able to filter both HTTP and HTTPS URLs. Filtering a HTTP traffic is available using url_regex. However doing the same with HTTPS traffic, I saw is not easily available. For example I want to my whitelist to be able to allow the url: https://www.example.com/login, but would not allow https://www.example.com nor https://sub.example.com nor https://www.example.com/other_path.

I have already tried using SSL Bump and tried to find any available ICAP or eCap component to go with it, but I haven?t found anything or any good documentation that would help me to do what I have just enumerated. 

May I kindly as for any answer or any lead that would help me to satisfy the requirement?

Thanks in advance!

Joru Pacs 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/2c721dde/attachment.htm>

From rafael.akchurin at diladele.com  Mon Dec 28 15:27:11 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 28 Dec 2015 15:27:11 +0000
Subject: [squid-users] Squid proxy whitelisting with HTTPS URL filtering
In-Reply-To: <E9A0B32D-0D9C-439C-AB7F-37A69C7AB3B4@gmail.com>
References: <E9A0B32D-0D9C-439C-AB7F-37A69C7AB3B4@gmail.com>
Message-ID: <VI1PR04MB13592456A532AD84AA5313C68FFB0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Joru,

May I humbly propose our ICAP server ? see preconfigured VM at http://quintolabs.com/virtual.php.
Just get it, login into Web UI, switch on the HTTPS filtering as indicated on http://docs.diladele.com/administrator_guide_4_3/https_filtering/enable_https_filtering.html and adjust the Locked policy described at http://docs.diladele.com/faq/filtering/locked_policy.html.

The VA has default Ubuntu?s Squid 3.3.8 inside (rebuilt for HTTPS filtering support) ? you might grab one from Eliezer at http://wiki.squid-cache.org/SquidFaq/BinaryPackages#KnowledgeBase.2FCentOS.Squid-3.5 . This one is better for HTTPS filtering.

Best regards,
Rafael

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of joru.pacs
Sent: Monday, December 28, 2015 4:23 PM
To: Amos Jeffries <squid-users at lists.squid-cache.org>
Subject: [squid-users] Squid proxy whitelisting with HTTPS URL filtering

Hi!

I am trying to set up squid to be a whitelist proxy which should be able to filter both HTTP and HTTPS URLs. Filtering a HTTP traffic is available using url_regex. However doing the same with HTTPS traffic, I saw is not easily available. For example I want to my whitelist to be able to allow the url: https://www.example.com/login<http://www.example.com/login>, but would not allow https://www.example.com nor https://sub.example.com nor https://www.example.com/other_path.

I have already tried using SSL Bump and tried to find any available ICAP or eCap component to go with it, but I haven?t found anything or any good documentation that would help me to do what I have just enumerated.

May I kindly as for any answer or any lead that would help me to satisfy the requirement?

Thanks in advance!

Joru Pacs
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/03c4f949/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Dec 28 15:32:12 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 28 Dec 2015 16:32:12 +0100
Subject: [squid-users] Squid proxy whitelisting with HTTPS URL filtering
In-Reply-To: <E9A0B32D-0D9C-439C-AB7F-37A69C7AB3B4@gmail.com>
References: <E9A0B32D-0D9C-439C-AB7F-37A69C7AB3B4@gmail.com>
Message-ID: <201512281632.12691.Antony.Stone@squid.open.source.it>

On Monday 28 December 2015 at 16:22:58, joru.pacs wrote:

> Hi!
> 
> I am trying to set up squid to be a whitelist proxy which should be able to
> filter both HTTP and HTTPS URLs.

> I have already tried using SSL Bump

How?  What squid.conf did you use?  What results did you get?  What didn't 
work?

> I haven?t found anything or any good documentation that would help me to do
> what I have just enumerated.

http://wiki.squid-cache.org/Features/SslPeekAndSplice should point you in the 
right direction.

Please try that, and if you run into problems, let us know:

 - what you have in squid.conf (without comments or blank lines)
 - which exact version of Squid you are using
 - which browser/s you are using
 - which URL/s you are trying to access and having problems with
 - what shows up in Squid's access log when you connect to those URLs

Good luck,


Antony.

-- 
Late in 1972 President Richard Nixon announced that the rate of increase of 
inflation was decreasing.   This was the first time a sitting president used a 
third derivative to advance his case for re-election.

 - Hugo Rossi, Notices of the American Mathematical Society

                                                   Please reply to the list;
                                                         please *don't* CC me.


From joru.pacs at gmail.com  Mon Dec 28 15:55:59 2015
From: joru.pacs at gmail.com (joru.pacs)
Date: Mon, 28 Dec 2015 23:55:59 +0800
Subject: [squid-users] Squid proxy whitelisting with HTTPS URL filtering
In-Reply-To: <201512281632.12691.Antony.Stone@squid.open.source.it>
References: <E9A0B32D-0D9C-439C-AB7F-37A69C7AB3B4@gmail.com>
 <201512281632.12691.Antony.Stone@squid.open.source.it>
Message-ID: <5200B366-663E-4EFB-A19B-5E46676E9D9E@gmail.com>

Hi!

Currently, I am using the version squid-3.5.12. I have configure the SSL bump this way:


http_port 8080 ssl-bump \
    cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
    generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

acl step1 at_step SslBump1

#sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE

ssl_bump peek step1
ssl_bump bump all

I am able to do HTTP filtering, however, using doing an HTTPS url filter does not work. A specific example is whitelisting the following URL https://www.facebook.com/login, but I do not want to allow all of facebook?s traffic to be whitelisted, thus the url https://www.facebook.com should not be allowed.

Trying to do a url_regex to www.facebook.com/login will give me the default error page from squid. I am using firefox to use the proxy. And in the logs I am given a 403 error:

"GET https://www.facebook.com/login HTTP/1.1" 403 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:42.0) Gecko/20100101 Firefox/42.0? TAG_NONE:HIER_NONE

I do not want to whitelist the whole Facebook domain. I simply want to whitelist facebook.com/login, so that we can allow websites that uses Facebook login to use it.

Hope this helps.

Thanks!

Joru


> On 28 Dec 2015, at 11:32 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Monday 28 December 2015 at 16:22:58, joru.pacs wrote:
> 
>> Hi!
>> 
>> I am trying to set up squid to be a whitelist proxy which should be able to
>> filter both HTTP and HTTPS URLs.
> 
>> I have already tried using SSL Bump
> 
> How?  What squid.conf did you use?  What results did you get?  What didn't 
> work?
> 
>> I haven?t found anything or any good documentation that would help me to do
>> what I have just enumerated.
> 
> http://wiki.squid-cache.org/Features/SslPeekAndSplice should point you in the 
> right direction.
> 
> Please try that, and if you run into problems, let us know:
> 
> - what you have in squid.conf (without comments or blank lines)
> - which exact version of Squid you are using
> - which browser/s you are using
> - which URL/s you are trying to access and having problems with
> - what shows up in Squid's access log when you connect to those URLs
> 
> Good luck,
> 
> 
> Antony.
> 
> -- 
> Late in 1972 President Richard Nixon announced that the rate of increase of 
> inflation was decreasing.   This was the first time a sitting president used a 
> third derivative to advance his case for re-election.
> 
> - Hugo Rossi, Notices of the American Mathematical Society
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/fb33c79e/attachment.htm>

From rousskov at measurement-factory.com  Mon Dec 28 16:14:17 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 28 Dec 2015 09:14:17 -0700
Subject: [squid-users] Fwd: Squid authentication on the origin server
 during SslBumping
In-Reply-To: <CAODHJdwZ71CwEFCzv2M65mrdFjm4LjKPcJ7g4eEb75+GFWvRfw@mail.gmail.com>
References: <CAODHJdx1C2s+_WQeeY0j6mDJ37gtYseb1V=ior7DEy0_OVBdRA@mail.gmail.com>
 <CAODHJdwZ71CwEFCzv2M65mrdFjm4LjKPcJ7g4eEb75+GFWvRfw@mail.gmail.com>
Message-ID: <56815FD9.3000100@measurement-factory.com>

On 12/28/2015 07:34 AM, Alexei Mayanov wrote:
> Is it possible to setup Squid to authenticate himself on the remote
> origin by X509 certificate?

I do not know for sure, but I suspect that:

1. SslBump transactions aside, one may configure Squid to authenticate
itself to an origin server using an X509 certificate mentioned in
squid.conf. If this is not possible, it is a missing feature or a bug.

2. It is possible to splice user-to-Squid and Squid-to-origin
connections while preserving user-to-origin authentication using an X509
certificate provided by the user. If this is not possible, it is a
missing feature or a bug.

3. It is possible to bump user-to-Squid and Squid-to-origin connections
while Squid authenticates itself to the origin server using an X509
certificate mentioned in squid.conf. If this is not possible, it is a
missing feature or a bug.

4. It is impossible to bump user-to-Squid and Squid-to-origin
connections while preserving user-to-origin authentication using an X509
certificate provided by the user. Bumping does not (and cannot)
impersonate an SSL client protected by a client certificate.

Which variant are you after?


> There is part of my test config for ssl bumping:
> 
> ssl_bump peek all
> ssl_bump bump all

This combination usually does not work. Look for "prevents future
bumping" and Limitations at

  http://wiki.squid-cache.org/Features/SslPeekAndSplice


HTH,

Alex.



From emz at norma.perm.ru  Mon Dec 28 18:46:46 2015
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Mon, 28 Dec 2015 23:46:46 +0500
Subject: [squid-users] sslBump, squid in transparent mode
Message-ID: <56818396.8080306@norma.perm.ru>

Hi.

I'm still trying to figure out why I get certificate generated for IP
address instead of hostname when the HTTPS traffic is intercepted bu
sllBump-enable squid. I'm using iptables to do this:

rdr on $iifs inet proto tcp from 192.168.0.0/16 to !<rfc1918> port 443
-> 127.0.0.1 port 3131
rdr on vpn inet proto tcp from 192.168.0.0/16 to !<rfc1918> port 443 ->
127.0.0.1 port 3131

and the port is configured as follows:

https_port 127.0.0.1:3131 intercept ssl-bump
cert=/usr/local/etc/squid/certs/squid.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
dhparams=/usr/local/etc/squid/certs/dhparam.pem
https_port [::1]:3131 intercept ssl-bump
cert=/usr/local/etc/squid/certs/squid.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
dhparams=/usr/local/etc/squid/certs/dhparam.pem

This way I'm getting a waring in browser (https://youtube.com is opened
in the example below):

===Cut===
youtube.com uses an invalid security certificate.

The certificate is not trusted because the issuer certificate is unknown.
The server might not be sending the appropriate intermediate certificates.
An additional root certificate may need to be imported.
The certificate is only valid for 173.194.71.91

(Error code: sec_error_unknown_issuer)
===Cut===

And the tcpdump capture clearly shows that client browser did sent an SNI:

https://gyazo.com/c1ba348fb4ee56c6c30f3e22ff9877f8

I'll apreciate any help.

Thanks.
Eugene.


From emz at norma.perm.ru  Mon Dec 28 18:47:00 2015
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Mon, 28 Dec 2015 23:47:00 +0500
Subject: [squid-users] sslBump adventures in enterprise production
 environment
In-Reply-To: <5648DF72.5080702@measurement-factory.com>
References: <5645A24B.3090503@norma.perm.ru> <5645EB51.4060000@gmail.com>
 <56478EC4.9040402@mathemainzel.info> <5648D6EB.2010106@norma.perm.ru>
 <5648DF72.5080702@measurement-factory.com>
Message-ID: <568183A4.5010500@norma.perm.ru>

Hi.

On 16.11.2015 0:39, Alex Rousskov wrote:
> On 11/15/2015 12:03 PM, Eugene M. Zheganin wrote:
>> It's not even a HTTPS, its a tunneled HTTP CONNECT. But
>> squid for some reason thinks there shoudl be a HTTPS inside.
> Hello Eugene,
>
>      Squid currently supports two kinds of CONNECT tunnels:
>
> 1. A regular opaque tunnel, as intended by HTTP specifications.
>
> 2. An inspected tunnel containing SSL/TLS-encrypted HTTP traffic.
>
> Opaque tunnels are the default. Optional SslBump-related features allow
> the admin to designate admin-selected CONNECT tunnels for HTTPS
> inspections (of various depth). This distinction explains why and when
> Squid expects "HTTPS inside".
>
> There is currently no decent support for inspecting CONNECT tunnels
> other than SSL/TLS-encrypted HTTP (i.e., HTTPS) tunnels.
>
> Splicing a tunnel at SslBump step1 converts a to-be-inspected tunnel
> into an opaque tunnel before inspection starts.
>
> The recently added on_unsupported_protocol directive can automatically
> convert being-inspected non-HTTPS tunnels into opaque ones in some
> common cases, but it needs more work to cover more cases.
>
>
> AFAICT, you assume that "splicing" turns off all tunnel inspection. This
> is correct for step1 (as I mentioned above). This is not correct for
> other steps because they happen after some inspection already took
> place. Inspection errors that on_unsupported_protocol cannot yet handle,
> may result in connection termination and other problems.
>
>
> If Squid behavior contradicts some of the above rules, it is probably a
> bug we should fix. Otherwise, it is likely to be a missing feature.
>
>
> Finally, if Squid kills your ICQ (non-HTTPS) client tunnels, you need to
> figure out whether those connections are inspected (i.e., go beyond
> SslBump step1). If they are inspected, then this is not a Squid bug but
> a misconfiguration (unless the ACL code itself is buggy!). If they are
> not inspected, then it is probably a Squid bug. I do not have enough
> information to distinguish between those cases, but I hope that others
> on the mailing list can guide you towards a resolution given the above
> information.
>

Thanks a lot for this explicit explanation.
I managed to solve the problem with ICQ using the information above, no
matter what port, 5190 or 443 it's tunneled into. Even
"on_unsupported_protocol" isn't needed, so the whole thing works just
fine on 3.5.x. In case someone will need this too, I decided to post my
config part:

#
# Minimum ICQ configuration,
# works for QIP 2012 and squid/ssl_bump, login.icq.com port should be
either 443 or 5190
#

acl icq dstdomain login.icq.com
acl icqport port 443
acl icqport port 5190

# mail.ru network where ICQ servers reside
acl icqip dst 178.237.16.0/20

acl step1 at_step SslBump1

#
# http_access part is needed; not shown here since it's ordinary, for
qip or web clients to work
#

# this should be somewhere near the top of the ssl_bump directives piece
ssl_bump splice step1 icq
ssl_bump splice step1 icqip icqport
[...other ssl_bump directives...]

Thanks.
Eugene.


From supergeorge1234 at gmail.com  Mon Dec 28 20:12:58 2015
From: supergeorge1234 at gmail.com (George Hollingshead)
Date: Mon, 28 Dec 2015 15:12:58 -0500
Subject: [squid-users] Specifiying openssl location with ./configure?
Message-ID: <CABQqRmYp3RfxD0vgGME=6bYO6yv0_S719XfLx-pYs+8mBo80cQ@mail.gmail.com>

I have a localy compilied the latest openssl to default location
 /usr/local directory.

Is there a way to run ./configure to use the openssl headers and such in
the /usr/local directories?


i compiled the latest openssl cause i'm running an old ubuntu 10.04 in
which their openssl version doesn't support sha256 and i can't run the
latest squid.

i hope this makes sense. thanx guys
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/58a87e53/attachment.htm>

From yvoinov at gmail.com  Mon Dec 28 20:16:49 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 29 Dec 2015 02:16:49 +0600
Subject: [squid-users] Specifiying openssl location with ./configure?
In-Reply-To: <CABQqRmYp3RfxD0vgGME=6bYO6yv0_S719XfLx-pYs+8mBo80cQ@mail.gmail.com>
References: <CABQqRmYp3RfxD0vgGME=6bYO6yv0_S719XfLx-pYs+8mBo80cQ@mail.gmail.com>
Message-ID: <568198B1.3020207@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Use LIBOPENSSL_CFLAGS (Feel free to run ./configure --help first ).
Something like that:

./configure '--with-openssl' '--enable-ssl-crtd'
'LIBOPENSSL_CFLAGS=-I/usr/local/include/openssl -L/usr/local/lib'

29.12.15 2:12, George Hollingshead ?????:
> I have a localy compilied the latest openssl to default location
>  /usr/local directory.
>
> Is there a way to run ./configure to use the openssl headers and such in
> the /usr/local directories?
>
>
> i compiled the latest openssl cause i'm running an old ubuntu 10.04 in
> which their openssl version doesn't support sha256 and i can't run the
> latest squid.
>
> i hope this makes sense. thanx guys
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWgZixAAoJENNXIZxhPexG/Y4H/jyHB2fHct4lHHrqTCRkEVJw
0AxqBRnVVHQJeLQcRF7fkbRxZIsZBT+V1M0JvBQO8zLJHcuYvgujs1+/N9glhsVK
J1rBR/zoA+ZFii5JZZ1JCEu4WFL24j1lv7hgvj4Hsq4g5mQtzTEWQacIK6gXfYgB
hah/cm3tr9YcrmqVK9ukFvdBmQEktS6PjUycZ94rEA1/ISG17tQ8jd3PBHqc3RMT
x0ewxp+hGu6Kmg9kPszUH4q0IC8Uzctd434MTV0EAOeDjqYmBaCPsM/qhOIqkgiO
QVlpL6tqIE4st8JaYOxOGbnJ8XF05BFTNTYmsze3K1Y6r50bR1EOIl5Rk1tXPBw=
=y1+n
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151229/d0ee9f6e/attachment.htm>

From alex at samad.com.au  Mon Dec 28 22:43:17 2015
From: alex at samad.com.au (Alex Samad)
Date: Tue, 29 Dec 2015 09:43:17 +1100
Subject: [squid-users] [squid-announce] Squid 3.5.12 is available
In-Reply-To: <56812CA7.3050900@ngtech.co.il>
References: <565A94A9.1060601@treenet.co.nz>
	<56812CA7.3050900@ngtech.co.il>
Message-ID: <CAJ+Q1PV7oMMOUPj-2zf95cm6yrgmg5Qkdj=Fgm8_4vH9KbTX3g@mail.gmail.com>

Hi

Do you provide the source rpms for RHEL/Centos

A

On 28 December 2015 at 23:35, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> I took the time to build and test a RPM for OpenSUSE leap 42.1 at:
> http://ngtech.co.il/repo/opensuse/leap/x86_64/squid-3.5.12-1.0.x86_64.rpm
>
> SRPM at:
> http://ngtech.co.il/repo/opensuse/leap/SRPMS/
>
> Eliezer
>
> On 29/11/2015 08:01, Amos Jeffries wrote:
>>
>> The Squid HTTP Proxy team is very pleased to announce the availability
>> of the Squid-3.5.12 release!
>>
>>
>> This release is a bug fix release resolving issues found in the prior
>> Squid releases.
>>
>>
>> The major changes to be aware of:
>
> <SNIP>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From supergeorge1234 at gmail.com  Mon Dec 28 22:46:04 2015
From: supergeorge1234 at gmail.com (George Hollingshead)
Date: Mon, 28 Dec 2015 17:46:04 -0500
Subject: [squid-users] problem with squidGuard redirect page after upgrading
	squid
Message-ID: <CABQqRmZKV8EW4_nfiyuFTN0+H42BM7Hgp3wS8zkEcvevL=Ujfw@mail.gmail.com>

I've had squid3.0 running with squidGuard on my old ubuntu 10.04 system
with no problems for a few months now.

I just recently was enlightened by Yuri how to compile using a local copy
of openssl so i could upgrade to latest squid.  This was a success.  Thanx
again Yuri :)

Only problem now is when squidGuard goes to redirect a blocked page it
comes up with something like   URL /block.html192.168.2.20 192.168.2.20/GET
page not found.

the local net address their is the computer that is being blocked.

Like i said earlier, this all worked before redirecting to
http://localhost/block.html when needed, but since i upgraded squid from
ubuntu's 3.0  to a compiled 3.5 i get this responce.

Any ideas as i'm not sure if squidGuard is been updated in 6 years.  i
realize this is a squid mailing list, but i could use some info if anyone
has experienced this or has insight!

Thanx guys
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151228/2935f8c2/attachment.htm>

From marcus.kool at urlfilterdb.com  Tue Dec 29 01:28:40 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 28 Dec 2015 23:28:40 -0200
Subject: [squid-users] problem with squidGuard redirect page after
 upgrading squid
In-Reply-To: <CABQqRmZKV8EW4_nfiyuFTN0+H42BM7Hgp3wS8zkEcvevL=Ujfw@mail.gmail.com>
References: <CABQqRmZKV8EW4_nfiyuFTN0+H42BM7Hgp3wS8zkEcvevL=Ujfw@mail.gmail.com>
Message-ID: <5681E1C8.2030502@urlfilterdb.com>



On 12/28/2015 08:46 PM, George Hollingshead wrote:
> I've had squid3.0 running with squidGuard on my old ubuntu 10.04 system with no problems for a few months now.
>
> I just recently was enlightened by Yuri how to compile using a local copy of openssl so i could upgrade to latest squid.  This was a success.  Thanx again Yuri :)
>
> Only problem now is when squidGuard goes to redirect a blocked page it comes up with something like   URL /block.html192.168.2.20 192.168.2.20/GET <http://192.168.2.20/GET> page not found.
>
> the local net address their is the computer that is being blocked.
>
> Like i said earlier, this all worked before redirecting to http://localhost/block.html when needed, but since i upgraded squid from ubuntu's 3.0  to a compiled 3.5 i get this responce.
>
> Any ideas as i'm not sure if squidGuard is been updated in 6 years.  i realize this is a squid mailing list, but i could use some info if anyone has experienced this or has insight!
>
> Thanx guys

You can use ufdbGuard instead of squidGuard.
ufdbGuard is Open Source and updated regularly.
If you do not use ssl-bump, ufdbGuard 1.31 works fine.
If you need ssl-bump, you have to wait for ufdbGuard 1.32 which is expected to be released in February 2016.

Marcus



From eliezer at ngtech.co.il  Tue Dec 29 06:53:33 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 29 Dec 2015 08:53:33 +0200
Subject: [squid-users] [squid-announce] Squid 3.5.12 is available
In-Reply-To: <CAJ+Q1PV7oMMOUPj-2zf95cm6yrgmg5Qkdj=Fgm8_4vH9KbTX3g@mail.gmail.com>
References: <565A94A9.1060601@treenet.co.nz> <56812CA7.3050900@ngtech.co.il>
 <CAJ+Q1PV7oMMOUPj-2zf95cm6yrgmg5Qkdj=Fgm8_4vH9KbTX3g@mail.gmail.com>
Message-ID: <56822DED.1040804@ngtech.co.il>

Just navigate in the repository at:
http://ngtech.co.il/repo/centos/

And you will find there what you are looking for.

Eliezer

On 29/12/2015 00:43, Alex Samad wrote:
> Hi
>
> Do you provide the source rpms for RHEL/Centos
>
> A
>
> On 28 December 2015 at 23:35, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
>> I took the time to build and test a RPM for OpenSUSE leap 42.1 at:
>> http://ngtech.co.il/repo/opensuse/leap/x86_64/squid-3.5.12-1.0.x86_64.rpm
>>
>> SRPM at:
>> http://ngtech.co.il/repo/opensuse/leap/SRPMS/
>>
>> Eliezer
>>
>> On 29/11/2015 08:01, Amos Jeffries wrote:
>>>
>>> The Squid HTTP Proxy team is very pleased to announce the availability
>>> of the Squid-3.5.12 release!
>>>
>>>
>>> This release is a bug fix release resolving issues found in the prior
>>> Squid releases.
>>>
>>>
>>> The major changes to be aware of:
>>
>> <SNIP>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users



From reet.vyas28 at gmail.com  Tue Dec 29 12:05:03 2015
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Tue, 29 Dec 2015 17:35:03 +0530
Subject: [squid-users] Assign multiple IP Address to squid
Message-ID: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>

Hi

I have working squid3.5.4 configuration with ssl bump, I am using this
squid machine as router and have external IP to it and have a leased line
connection but with leased line I have 10 extra IP address and I want to
NAT those external ip to local ip on same network, like we do in our
router, so that I can assign those IP ip my machines having webservers.

Please suggest me way to configure it.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151229/dc64f500/attachment.htm>

From emz at norma.perm.ru  Tue Dec 29 12:43:30 2015
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Tue, 29 Dec 2015 17:43:30 +0500
Subject: [squid-users] Assign multiple IP Address to squid
In-Reply-To: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>
References: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>
Message-ID: <56827FF2.7060704@norma.perm.ru>

Hi.

On 29.12.2015 17:05, Reet Vyas wrote:
> Hi
>
> I have working squid3.5.4 configuration with ssl bump, I am using this
> squid machine as router and have external IP to it and have a leased
> line connection but with leased line I have 10 extra IP address and I
> want to NAT those external ip to local ip on same network, like we do
> in our router, so that I can assign those IP ip my machines having
> webservers.
>
> Please suggest me way to configure it.
>
This has nothing to do with squid.

Eugene.


From leolistas at solutti.com.br  Tue Dec 29 13:06:33 2015
From: leolistas at solutti.com.br (Leonardo Rodrigues)
Date: Tue, 29 Dec 2015 11:06:33 -0200
Subject: [squid-users] Assign multiple IP Address to squid
In-Reply-To: <56827FF2.7060704@norma.perm.ru>
References: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>
 <56827FF2.7060704@norma.perm.ru>
Message-ID: <56828559.3030307@solutti.com.br>

Em 29/12/15 10:43, Eugene M. Zheganin escreveu:
> Hi.
>
> On 29.12.2015 17:05, Reet Vyas wrote:
>> Hi
>>
>> I have working squid3.5.4 configuration with ssl bump, I am using this
>> squid machine as router and have external IP to it and have a leased
>> line connection but with leased line I have 10 extra IP address and I
>> want to NAT those external ip to local ip on same network, like we do
>> in our router, so that I can assign those IP ip my machines having
>> webservers.
>>
>> Please suggest me way to configure it.
>>
> This has nothing to do with squid.
>

     Well, it can be squid-related as 'machines having webservers' is 
given by the OP. Yes, squid cannot be used to to port-forwarding as 
routers usually can do, but it can work as reverse-proxy 'publishing' 
internal-ip webservers to the world.

     You didnt specified if you're using squid for general proxy or 
reverse proxy. SSL-Bump, as far as i know, can be used for both.

     Maybe you wanna google or search the mailing list archives for 
reverse proxy setups, that's what you're looking for. But keep in mind 
if will work only for HTTP and HTTPS connections. If you want general 
port-forwarding, than Eugene is right, it's a not squid-related subject.




-- 


	Atenciosamente / Sincerily,
	Leonardo Rodrigues
	Solutti Tecnologia
	http://www.solutti.com.br

	Minha armadilha de SPAM, N?O mandem email
	gertrudes at solutti.com.br
	My SPAMTRAP, do not email it





From Massimo.Sala at asl.bergamo.it  Tue Dec 29 14:26:14 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Tue, 29 Dec 2015 15:26:14 +0100
Subject: [squid-users] squid3 / debian stable / please update to 3.4.14
Message-ID: <OF02421B9C.B0F34AB2-ONC1257F2A.004E3936-C1257F2A.004F487A@asl.bergamo.it>

ciao Luigi

I ask to update the distro to squid 3.4.14, the last stable version, 
released in august.

Rationale :
1) various bugs and memory leaks fixed;
2) security fix for CVE 2015 5400;
3) support for Alternate-Protocol HTTP header.

I need 3) to disable QUIC on youtube, otherwise squid3 cannot cache 
videos.

References :
        https://packages.debian.org/jessie/squid3
        
ftp://ftp.fu-berlin.de/unix/www/squid/squid/squid-3.4-ChangeLog.txt
        http://wiki.squid-cache.org/KnowledgeBase/Block QUIC protocol


Best regards, Massimo



From fabietto82 at gmail.com  Tue Dec 29 14:30:15 2015
From: fabietto82 at gmail.com (Fabio Bucci)
Date: Tue, 29 Dec 2015 15:30:15 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <5671C5B9.5080100@treenet.co.nz>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
 <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
 <566AE006.80609@treenet.co.nz>
 <CAJrMMC_BPiU49yd6w8dHyqbUbeujTsq41fjjdULvk9L9Eu5dSA@mail.gmail.com>
 <566B9BE7.8050907@treenet.co.nz>
 <CAJrMMC8beqFndjUbumOFL7xzuKSL5KNS8pJ3_y=A1ZJNuUp05w@mail.gmail.com>
 <5671C5B9.5080100@treenet.co.nz>
Message-ID: <CAJrMMC9qJkyRBpewH-BVdVYvXAOaGrHBGnaGY6Q9jxvCYqBJTA@mail.gmail.com>

Hi Amos,
i'm trying to implement kerberos as you suggested me. But following
the guide i read "Do not use this method if you run winbindd or other
samba services as samba will reset the machine password every x days
and thereby makes the keytab invalid !!" and my system guy told me we
use winbindd method.

How can i implement so?
Thanks

2015-12-16 21:12 GMT+01:00 Amos Jeffries <squid3 at treenet.co.nz>:
> On 17/12/2015 5:34 a.m., Fabio Bucci wrote:
>> i'm planning to migrate to kerberos instead NTLM.....i got a question for
>> you Amos: sometimes a client reports issue in navigation and searching into
>> log file i cannot see "username" and all the request are 407
>>
>> In these cases is there a way to reset a user session or it's a completely
>> client issue?
>
> Usually it is the client stuck in a loop trying Negtiate/NTLM auth for
> some reason. Some old Firefox, most Safari, and older IE can all get
> stuck trying those credentials and ignoring the offers of Basic.
>
> It might be possible to figure out some LmCompatibility settings change
> that makes the problem just go away (eg, forcing NTLM of all versions to
> disabled on the client).
>
> Other than that Squid does have some workaround responses it can be made
> to send back that might help the client reach the right conclusion:
>
> a) list Basic auth first in the config. Any properly working client will
> re-sort the auth types by security level and do theKerberos anyway. But
> the broken ones (particularly IE7 and older) will have more chance of
> using Basic.
>
> b) sending 407 response with no auth headers. Such as a deny 407 status
> generated by external ACL deny, or a URL-redirector. These tell the
> client that auth failed, but there is no acceptible fallback.
>
> c) sending Connection:close. Sometimes (mostly Firefox v20-v40) it is
> the client prematurely attaching the credentials to the connection and
> re-using them. That is supposed to have been fixed recently, but I've
> not confirmed.
>
> d) sending 403 status response. To just flat-out block the client once
> it enters the looping state. Hoping that later requests will start to
> work again.
>
>
> HTH
> Amos
>


From belle at bazuin.nl  Tue Dec 29 14:42:07 2015
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Tue, 29 Dec 2015 15:42:07 +0100
Subject: [squid-users] FW: [Samba]  Squid with NTLM auth behind netscaler
Message-ID: <vmime.56829bbf.20da.229b4e3222ab49e@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

> i read "Do not use this method if you run winbindd or other samba 
> services as samba will reset the machine password every x days and 
> thereby makes the keytab invalid

Seems wrong to me. 

If you use samba 4. ( dont know if its the same for samba 3 ) 

Make sure you have this in smb.conf    

   dedicated keytab file = /etc/krb5.keytab
   kerberos method = secrets and keytab

   winbind refresh tickets = yes
   winbind offline logon = yes

refresh tickets refreshed the machine pass in the keytab. 
Offline logon is handy if you dc is down. 

Steps to follow

Install samba and join the domain. 
Check the SPNs of the hostname, if you missing things, add them. 
Remove /etc/krb5.keytab
Recreate it again ( now it has al the needed SPN's ) with : 
net ads keytab create -U administrator

restart samba. 

Now go configure squid. 


Greetz, 

Louis> Louis
> 
> > -----Oorspronkelijk bericht-----
> > Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
> Namens
> > Fabio Bucci
> > Verzonden: dinsdag 29 december 2015 15:30
> > Aan: Amos Jeffries
> > CC: squid-users at lists.squid-cache.org
> > Onderwerp: Re: [squid-users] Squid with NTLM auth behind netscaler
> >
> > Hi Amos,
> > i'm trying to implement kerberos as you suggested me. But following
> > the guide i read "Do not use this method if you run winbindd or other
> > samba services as samba will reset the machine password every x days
> > and thereby makes the keytab invalid !!" and my system guy told me we
> > use winbindd method.
> >
> > How can i implement so?
> > Thanks
> >
> > 2015-12-16 21:12 GMT+01:00 Amos Jeffries <squid3 at treenet.co.nz>:
> > > On 17/12/2015 5:34 a.m., Fabio Bucci wrote:
> > >> i'm planning to migrate to kerberos instead NTLM.....i got a question
> > for
> > >> you Amos: sometimes a client reports issue in navigation and
> searching
> > into
> > >> log file i cannot see "username" and all the request are 407
> > >>
> > >> In these cases is there a way to reset a user session or it's a
> > completely
> > >> client issue?
> > >
> > > Usually it is the client stuck in a loop trying Negtiate/NTLM auth for
> > > some reason. Some old Firefox, most Safari, and older IE can all get
> > > stuck trying those credentials and ignoring the offers of Basic.
> > >
> > > It might be possible to figure out some LmCompatibility settings
> change
> > > that makes the problem just go away (eg, forcing NTLM of all versions
> to
> > > disabled on the client).
> > >
> > > Other than that Squid does have some workaround responses it can be
> made
> > > to send back that might help the client reach the right conclusion:
> > >
> > > a) list Basic auth first in the config. Any properly working client
> will
> > > re-sort the auth types by security level and do theKerberos anyway.
> But
> > > the broken ones (particularly IE7 and older) will have more chance of
> > > using Basic.
> > >
> > > b) sending 407 response with no auth headers. Such as a deny 407
> status
> > > generated by external ACL deny, or a URL-redirector. These tell the
> > > client that auth failed, but there is no acceptible fallback.
> > >
> > > c) sending Connection:close. Sometimes (mostly Firefox v20-v40) it is
> > > the client prematurely attaching the credentials to the connection and
> > > re-using them. That is supposed to have been fixed recently, but I've
> > > not confirmed.
> > >
> > > d) sending 403 status response. To just flat-out block the client once
> > > it enters the looping state. Hoping that later requests will start to
> > > work again.
> > >
> > >
> > > HTH
> > > Amos
> > >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> --
> To unsubscribe from this list go to the following URL and read the
> instructions:  https://lists.samba.org/mailman/options/samba




From eliezer at ngtech.co.il  Tue Dec 29 15:10:22 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 29 Dec 2015 17:10:22 +0200
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC9qJkyRBpewH-BVdVYvXAOaGrHBGnaGY6Q9jxvCYqBJTA@mail.gmail.com>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
 <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
 <566AE006.80609@treenet.co.nz>
 <CAJrMMC_BPiU49yd6w8dHyqbUbeujTsq41fjjdULvk9L9Eu5dSA@mail.gmail.com>
 <566B9BE7.8050907@treenet.co.nz>
 <CAJrMMC8beqFndjUbumOFL7xzuKSL5KNS8pJ3_y=A1ZJNuUp05w@mail.gmail.com>
 <5671C5B9.5080100@treenet.co.nz>
 <CAJrMMC9qJkyRBpewH-BVdVYvXAOaGrHBGnaGY6Q9jxvCYqBJTA@mail.gmail.com>
Message-ID: <5682A25E.3060903@ngtech.co.il>

Hey Fabio,

If you do want to use kerberos you do not need to use winbindd there are 
other options.
(I have not tried them both yet)

Eliezer

On 29/12/2015 16:30, Fabio Bucci wrote:
> Hi Amos,
> i'm trying to implement kerberos as you suggested me. But following
> the guide i read "Do not use this method if you run winbindd or other
> samba services as samba will reset the machine password every x days
> and thereby makes the keytab invalid !!" and my system guy told me we
> use winbindd method.
>
> How can i implement so?
> Thanks



From eliezer at ngtech.co.il  Tue Dec 29 15:13:40 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 29 Dec 2015 17:13:40 +0200
Subject: [squid-users] Assign multiple IP Address to squid
In-Reply-To: <56827FF2.7060704@norma.perm.ru>
References: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>
 <56827FF2.7060704@norma.perm.ru>
Message-ID: <5682A324.4050806@ngtech.co.il>

Rather then non squid it would be the iptables and routing related things.
However if you are intercepting https or http connections your might 
want to add some exceptions in the iptables to avoid the additional web 
servers traffic being intercepted by squid.

Eliezer

On 29/12/2015 14:43, Eugene M. Zheganin wrote:
> This has nothing to do with squid.
>
> Eugene.



From fabietto82 at gmail.com  Tue Dec 29 15:20:40 2015
From: fabietto82 at gmail.com (Fabio Bucci)
Date: Tue, 29 Dec 2015 16:20:40 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <5682A25E.3060903@ngtech.co.il>
References: <CAJrMMC-WO=T4O+yYogVuS6nAoDGcXO220xtyBd=xMbXNxPvsQw@mail.gmail.com>
 <5661AA55.4090407@treenet.co.nz>
 <CAJrMMC8iAa9rTXhggx3bsOkvJcOZ-0J004qH-zGb3gpoEWiriA@mail.gmail.com>
 <5662828F.5090007@treenet.co.nz>
 <CAJrMMC9oyoa8FQ1ymiLcFg=R3VoY8VcjhTTy=-wg=J0LyyMWnQ@mail.gmail.com>
 <CAJrMMC_gTfNA6fsKJo5DEqgAUZdcAMxs2Zy9KK8eGSHOjTGqLA@mail.gmail.com>
 <566AE006.80609@treenet.co.nz>
 <CAJrMMC_BPiU49yd6w8dHyqbUbeujTsq41fjjdULvk9L9Eu5dSA@mail.gmail.com>
 <566B9BE7.8050907@treenet.co.nz>
 <CAJrMMC8beqFndjUbumOFL7xzuKSL5KNS8pJ3_y=A1ZJNuUp05w@mail.gmail.com>
 <5671C5B9.5080100@treenet.co.nz>
 <CAJrMMC9qJkyRBpewH-BVdVYvXAOaGrHBGnaGY6Q9jxvCYqBJTA@mail.gmail.com>
 <5682A25E.3060903@ngtech.co.il>
Message-ID: <CAJrMMC8OngX_0Cobq9Ebxu5bcLaWVW6cO5-UV4JOnDsv0LJC-A@mail.gmail.com>

ok thanks. I think the system guys use samba and winbind to join linux
machines to domain independetly services installed

2015-12-29 16:10 GMT+01:00 Eliezer Croitoru <eliezer at ngtech.co.il>:
> Hey Fabio,
>
> If you do want to use kerberos you do not need to use winbindd there are
> other options.
> (I have not tried them both yet)
>
> Eliezer
>
> On 29/12/2015 16:30, Fabio Bucci wrote:
>>
>> Hi Amos,
>> i'm trying to implement kerberos as you suggested me. But following
>> the guide i read "Do not use this method if you run winbindd or other
>> samba services as samba will reset the machine password every x days
>> and thereby makes the keytab invalid !!" and my system guy told me we
>> use winbindd method.
>>
>> How can i implement so?
>> Thanks
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From belle at bazuin.nl  Tue Dec 29 15:34:35 2015
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Tue, 29 Dec 2015 16:34:35 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC8OngX_0Cobq9Ebxu5bcLaWVW6cO5-UV4JOnDsv0LJC-A@mail.gmail.com>
References: <5682A25E.3060903@ngtech.co.il>
Message-ID: <vmime.5682a80b.3acd.7005164d5dfb193b@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

> ok thanks. I think the system guys use samba and winbind to join linux
> machines to domain independetly services installed

Thats good, but if you want fallback and make NTLM work 
( for only kerberos its not needed ) 

You want something like : 

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
    --kerberos /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME -d \
    --ntlm /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp \
        --domain=NTDOMAIN 
Or

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth -d \
    --kerberos /usr/lib/squid/negotiate_kerberos_auth \ 
     -s HTTP/proxy.domain.tld at REALM \
    --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN


For the --ntlm you MUST install samba, since its suplied by samba. 

And a basic fallback if above fails, then this one will give a popup to auth

auth_param basic program /usr/lib/squid/basic_ldap_auth -R \
    -b "ou=Users,dc=internal,dc=domain,dc=tld" \
    -D bind2ad at User_domain -W /etc/squid/private/secretfile \
    -f (sAMAccountName=%s) \
    -h dc2.internal.domain.tld \
    -h dc1.internal.domain.tld 

Above is all tested and running in my production env. 
Few very important pointers. 
1) make sure your proxy has A and PTR record ( needed for kerberos ) 
2) make sure you have the HTTP/ spn for the hostnames of your proxy servers 
3) make sure you time is in sync on all servers and clients. 


In samba 4 i did it like this. Login with ssh on a DC. 
kinit Administrator 

samba-tool user create squid-proxy --description="Unprivileged user for SQUID-Proxy Services" --random-password
samba-tool user setexpiry squid-proxy --noexpiry
samba-tool spn add HTTP/proxy1.internal.domain.tld squid-proxy
samba-tool spn add HTTP/proxy1. internal.domain.tld at REALM squid-proxy

# export the keytab. 
samba-tool domain exportkeytab --principal=HTTP/proxy1.internal.domain.tld. /root/keytabs/proxy1.keytab

check if your hostname has all the SPNs. 
samba-tool spn list proxy1$ 
proxy1 is the name in smb.conf 
you must have:
         HOST/PROXY1
         HOST/proxy1.internal.domain.tld.

And make your you have :
/etc/default/squid
KRB5_KTNAME=/etc/squid/proxy1.keytab
export KRB5_KTNAME


Greetz, 

Louis


> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Fabio Bucci
> Verzonden: dinsdag 29 december 2015 16:21
> Aan: Eliezer Croitoru
> CC: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Squid with NTLM auth behind netscaler
> 
> ok thanks. I think the system guys use samba and winbind to join linux
> machines to domain independetly services installed
> 
> 2015-12-29 16:10 GMT+01:00 Eliezer Croitoru <eliezer at ngtech.co.il>:
> > Hey Fabio,
> >
> > If you do want to use kerberos you do not need to use winbindd there are
> > other options.
> > (I have not tried them both yet)
> >
> > Eliezer
> >
> > On 29/12/2015 16:30, Fabio Bucci wrote:
> >>
> >> Hi Amos,
> >> i'm trying to implement kerberos as you suggested me. But following
> >> the guide i read "Do not use this method if you run winbindd or other
> >> samba services as samba will reset the machine password every x days
> >> and thereby makes the keytab invalid !!" and my system guy told me we
> >> use winbindd method.
> >>
> >> How can i implement so?
> >> Thanks
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From alex at samad.com.au  Wed Dec 30 04:11:29 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 30 Dec 2015 15:11:29 +1100
Subject: [squid-users] squid reverse proxy and client certs
Message-ID: <CAJ+Q1PXq9To23qqisTKPGDgCNXbC8NTKuTtqxUcd-HuR6TaTjg@mail.gmail.com>

Hi

I have squid 3.5.12 working as a reverse proxy

cache_peer 127.0.0.1 \
 parent 443 0 proxy-only no-query no-digest originserver \
 login=PASS \
 ssl \
 sslcafile=/etc/pki/tls/certs/ca-bundle.crt \
 sslflags=DONT_VERIFY_PEER \
 name=webServer

This points to httpd which has a
        <Location /test/>
                DirectoryIndex index.shtml index.html
                Options -Indexes -Includes +IncludesNOEXEC
-SymLinksIfOwnerMatch -ExecCGI -FollowSymLinks

                SSLOptions +StdEnvVars +ExportCertData
                SSLVerifyClient optional_no_ca
                SSLVerifyDepth 4
        </Location>

Unfortunately the request for a client cert never makes it to the client.

How can I change this to allow client certs to work

Alex


From zw963 at 163.com  Wed Dec 30 10:39:12 2015
From: zw963 at 163.com (Billy.Zheng (zw963))
Date: Wed, 30 Dec 2015 18:39:12 +0800
Subject: [squid-users] Squid is not worked in OpenVZ VPS.
Message-ID: <87fuyk6x0v.fsf@2540p.emacsfans.com>

Hi, I have two VPS in same location(HONG KONG)

the two VPS is blongs to two service provider, one OpenVZ, one XEN.

I choice with same version CentOS(6.7), and with same config script for
a FORWARD proxy to access free world.

XEN always worked for me, but OpenVZ is not.

following is some simple description:

I start squid with a https port(11223), and I can access squid server
from my local host with stunnel/telnet in both VPS.

But, only zhe XEN vps can forward my request to my destination host.

e.g.
I access www.google.com from my local browser, will see following logs:

>> 1451383747.833 19921 60.221.123.69 TCP_MISS/000 0 GET http://www.google.com/ - DIRECT/www.google.com -
>> 1451383819.941 61710 60.221.123.69 TCP_MISS/503 0 CONNECT www.vpsnine.com:443 - DIRECT/2400:cb00:2048:1::6819:341f -
>> ...


the second logs is so strange,  www.vpsnine.com is my OpenVZ VPS
provider domain name, I never access it from my local browser.
and not like another XEN VPS, those log output is very very slow.

Could you give me some clue for resolve this? Thanks.
-- 
Geek, Rubyist, Emacser
Homepage: http://zw963.github.io



From uhlar at fantomas.sk  Wed Dec 30 10:56:36 2015
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 30 Dec 2015 11:56:36 +0100
Subject: [squid-users] squid reverse proxy and client certs
In-Reply-To: <CAJ+Q1PXq9To23qqisTKPGDgCNXbC8NTKuTtqxUcd-HuR6TaTjg@mail.gmail.com>
References: <CAJ+Q1PXq9To23qqisTKPGDgCNXbC8NTKuTtqxUcd-HuR6TaTjg@mail.gmail.com>
Message-ID: <20151230105636.GA24776@fantomas.sk>

On 30.12.15 15:11, Alex Samad wrote:
>I have squid 3.5.12 working as a reverse proxy
>
>cache_peer 127.0.0.1 \
> parent 443 0 proxy-only no-query no-digest originserver \
> login=PASS \
> ssl \
> sslcafile=/etc/pki/tls/certs/ca-bundle.crt \
> sslflags=DONT_VERIFY_PEER \
> name=webServer
>
>This points to httpd which has a
>        <Location /test/>
>                DirectoryIndex index.shtml index.html
>                Options -Indexes -Includes +IncludesNOEXEC
>-SymLinksIfOwnerMatch -ExecCGI -FollowSymLinks
>
>                SSLOptions +StdEnvVars +ExportCertData
>                SSLVerifyClient optional_no_ca
>                SSLVerifyDepth 4
>        </Location>
>
>Unfortunately the request for a client cert never makes it to the client.
>
>How can I change this to allow client certs to work

client certs will only work when you pass the connection directly to web
server without unbundling SSL.
That means, it's useless to use reverse proxy for HTTPS server when it needs
client certificates.

The workaround you could be in verifying client certificates by squid,
pushing that info to server and webserver trusting that info...

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Chernobyl was an Windows 95 beta test site.


From garryd at comnet.uz  Wed Dec 30 11:01:00 2015
From: garryd at comnet.uz (Garri Djavadyan)
Date: Wed, 30 Dec 2015 16:01:00 +0500
Subject: [squid-users] Host header forgery policy in service provider
	environment
Message-ID: <1451473260.12487.46.camel@comnet.uz>

Hello Squid members and developers!

First of all, I wish you a Happy New Year 2016!

The current Host header forgery policy effectively prevents a cache
poisoning. But also, I noticed, it deletes verified earlier cached
object. Is it possible to implement more careful algorithm as an
option? For example, if Squid will not delete earlier successfully
verified and valid cached object and serve forged request from the
cache if would be more effective and in same time secure behavior.

For example, in service provider tproxy environment, it is almost
impossible to effectively optimize content delivery from sophisticated
CDNs, such as appldnld.apple.com, iosapps.itunes.apple.com. For the
latter domain, DNS servers return different pairs of A records for same
host every 15 seconds regardless of Geo location. For the former
domain, local DNS servers and public DNS servers (Google) return
different records. As I emphasized SP environment, it is not possible
to control DNS settings on subscriber systems.

Thank you for attention!

-- 
Garri Djavadyan
iPlus LLC, TM Comnet, Technical Department
Phone: +99871 2333335 (ext. 27)
http://comnet.uz




From gkinkie at gmail.com  Wed Dec 30 13:46:46 2015
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 30 Dec 2015 14:46:46 +0100
Subject: [squid-users] Squid is not worked in OpenVZ VPS.
In-Reply-To: <87fuyk6x0v.fsf@2540p.emacsfans.com>
References: <87fuyk6x0v.fsf@2540p.emacsfans.com>
Message-ID: <D5D122A0-448D-4557-87A5-12B063E16E17@gmail.com>


> On 30 Dec 2015, at 11:39, Billy.Zheng(zw963) <zw963 at 163.com> wrote:
> 
> Hi, I have two VPS in same location(HONG KONG)
> 
> the two VPS is blongs to two service provider, one OpenVZ, one XEN.
> 
> I choice with same version CentOS(6.7), and with same config script for
> a FORWARD proxy to access free world.
> 
> XEN always worked for me, but OpenVZ is not.
> 

> the second logs is so strange,  www.vpsnine.com is my OpenVZ VPS
> provider domain name, I never access it from my local browser.
> and not like another XEN VPS, those log output is very very slow.
> 
> Could you give me some clue for resolve this? Thanks.

when you try accessing some destination with the proxy that is not working, what does the error page say?

	Kinkie

From zw963 at 163.com  Wed Dec 30 14:14:23 2015
From: zw963 at 163.com (Billy.Zheng (zw963))
Date: Wed, 30 Dec 2015 22:14:23 +0800
Subject: [squid-users] Squid is not worked in OpenVZ VPS.
In-Reply-To: <D5D122A0-448D-4557-87A5-12B063E16E17@gmail.com>
References: <87fuyk6x0v.fsf@2540p.emacsfans.com>
 <D5D122A0-448D-4557-87A5-12B063E16E17@gmail.com>
Message-ID: <87ege46n28.fsf@2540p.emacsfans.com>

Thanks for you reply.

The failed message is: `Connection to ???? failed', ???? is a IPV6
address somehow.

I found i just could't access part of website, not all.

so, I thought this is not Squid problem, maybe china GFW prevent this, 
I doubt OpenVZ provider's machine room exist some problem.

Thanks.

Francesco Chemolli writes:

>> On 30 Dec 2015, at 11:39, Billy.Zheng(zw963) <zw963 at 163.com> wrote:
>> 
>> Hi, I have two VPS in same location(HONG KONG)
>> 
>> the two VPS is blongs to two service provider, one OpenVZ, one XEN.
>> 
>> I choice with same version CentOS(6.7), and with same config script for
>> a FORWARD proxy to access free world.
>> 
>> XEN always worked for me, but OpenVZ is not.
>> 
>
>> the second logs is so strange,  www.vpsnine.com is my OpenVZ VPS
>> provider domain name, I never access it from my local browser.
>> and not like another XEN VPS, those log output is very very slow.
>> 
>> Could you give me some clue for resolve this? Thanks.
>
> when you try accessing some destination with the proxy that is not working, what does the error page say?
>
> 	Kinkie
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Geek, Rubyist, Emacser
Homepage: http://zw963.github.io



From gkinkie at gmail.com  Wed Dec 30 14:30:39 2015
From: gkinkie at gmail.com (Kinkie)
Date: Wed, 30 Dec 2015 15:30:39 +0100
Subject: [squid-users] Squid is not worked in OpenVZ VPS.
In-Reply-To: <87ege46n28.fsf@2540p.emacsfans.com>
References: <87fuyk6x0v.fsf@2540p.emacsfans.com>
 <D5D122A0-448D-4557-87A5-12B063E16E17@gmail.com>
 <87ege46n28.fsf@2540p.emacsfans.com>
Message-ID: <CA+Y8hcNnEJP-9GbWVqYntx_82b1cgOLaNTQuexmBTLtmCVQ6Qg@mail.gmail.com>

Well, the IPv6 address could be telling. Maybe OpenVZ is setting up a
V6 network but has no route out of it.
Can you try accessing a known V4 and a known V6 address? It could help
you understand if the issue is there. In that case, you need to fix
the issue at the OpenVZ level.


On Wed, Dec 30, 2015 at 3:14 PM, Billy.Zheng <zw963 at 163.com> wrote:
> Thanks for you reply.
>
> The failed message is: `Connection to ???? failed', ???? is a IPV6
> address somehow.
>
> I found i just could't access part of website, not all.
>
> so, I thought this is not Squid problem, maybe china GFW prevent this,
> I doubt OpenVZ provider's machine room exist some problem.
>
> Thanks.
>
> Francesco Chemolli writes:
>
>>> On 30 Dec 2015, at 11:39, Billy.Zheng(zw963) <zw963 at 163.com> wrote:
>>>
>>> Hi, I have two VPS in same location(HONG KONG)
>>>
>>> the two VPS is blongs to two service provider, one OpenVZ, one XEN.
>>>
>>> I choice with same version CentOS(6.7), and with same config script for
>>> a FORWARD proxy to access free world.
>>>
>>> XEN always worked for me, but OpenVZ is not.
>>>
>>
>>> the second logs is so strange,  www.vpsnine.com is my OpenVZ VPS
>>> provider domain name, I never access it from my local browser.
>>> and not like another XEN VPS, those log output is very very slow.
>>>
>>> Could you give me some clue for resolve this? Thanks.
>>
>> when you try accessing some destination with the proxy that is not working, what does the error page say?
>>
>>       Kinkie
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> Geek, Rubyist, Emacser
> Homepage: http://zw963.github.io
>



-- 
    Francesco


From fabietto82 at gmail.com  Wed Dec 30 14:42:36 2015
From: fabietto82 at gmail.com (Fabio Bucci)
Date: Wed, 30 Dec 2015 15:42:36 +0100
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <vmime.5682a80b.3acd.7005164d5dfb193b@ms249-lin-003.rotterdam.bazuin.nl>
References: <5682A25E.3060903@ngtech.co.il>
 <CAJrMMC8OngX_0Cobq9Ebxu5bcLaWVW6cO5-UV4JOnDsv0LJC-A@mail.gmail.com>
 <vmime.5682a80b.3acd.7005164d5dfb193b@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <CAJrMMC9YXAhyDa09eo78GjoXx6MXrEx_6RVsqCihMEjeYny=Ug@mail.gmail.com>

Could you help me in kerberos configuration only? I don't want a fallback

2015-12-29 16:34 GMT+01:00 L.P.H. van Belle <belle at bazuin.nl>:
> Hai,
>
>> ok thanks. I think the system guys use samba and winbind to join linux
>> machines to domain independetly services installed
>
> Thats good, but if you want fallback and make NTLM work
> ( for only kerberos its not needed )
>
> You want something like :
>
> auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
>     --kerberos /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME -d \
>     --ntlm /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp \
>         --domain=NTDOMAIN
> Or
>
> auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth -d \
>     --kerberos /usr/lib/squid/negotiate_kerberos_auth \
>      -s HTTP/proxy.domain.tld at REALM \
>     --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN
>
>
> For the --ntlm you MUST install samba, since its suplied by samba.
>
> And a basic fallback if above fails, then this one will give a popup to auth
>
> auth_param basic program /usr/lib/squid/basic_ldap_auth -R \
>     -b "ou=Users,dc=internal,dc=domain,dc=tld" \
>     -D bind2ad at User_domain -W /etc/squid/private/secretfile \
>     -f (sAMAccountName=%s) \
>     -h dc2.internal.domain.tld \
>     -h dc1.internal.domain.tld
>
> Above is all tested and running in my production env.
> Few very important pointers.
> 1) make sure your proxy has A and PTR record ( needed for kerberos )
> 2) make sure you have the HTTP/ spn for the hostnames of your proxy servers
> 3) make sure you time is in sync on all servers and clients.
>
>
> In samba 4 i did it like this. Login with ssh on a DC.
> kinit Administrator
>
> samba-tool user create squid-proxy --description="Unprivileged user for SQUID-Proxy Services" --random-password
> samba-tool user setexpiry squid-proxy --noexpiry
> samba-tool spn add HTTP/proxy1.internal.domain.tld squid-proxy
> samba-tool spn add HTTP/proxy1. internal.domain.tld at REALM squid-proxy
>
> # export the keytab.
> samba-tool domain exportkeytab --principal=HTTP/proxy1.internal.domain.tld. /root/keytabs/proxy1.keytab
>
> check if your hostname has all the SPNs.
> samba-tool spn list proxy1$
> proxy1 is the name in smb.conf
> you must have:
>          HOST/PROXY1
>          HOST/proxy1.internal.domain.tld.
>
> And make your you have :
> /etc/default/squid
> KRB5_KTNAME=/etc/squid/proxy1.keytab
> export KRB5_KTNAME
>
>
> Greetz,
>
> Louis
>
>
>> -----Oorspronkelijk bericht-----
>> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
>> Fabio Bucci
>> Verzonden: dinsdag 29 december 2015 16:21
>> Aan: Eliezer Croitoru
>> CC: squid-users at lists.squid-cache.org
>> Onderwerp: Re: [squid-users] Squid with NTLM auth behind netscaler
>>
>> ok thanks. I think the system guys use samba and winbind to join linux
>> machines to domain independetly services installed
>>
>> 2015-12-29 16:10 GMT+01:00 Eliezer Croitoru <eliezer at ngtech.co.il>:
>> > Hey Fabio,
>> >
>> > If you do want to use kerberos you do not need to use winbindd there are
>> > other options.
>> > (I have not tried them both yet)
>> >
>> > Eliezer
>> >
>> > On 29/12/2015 16:30, Fabio Bucci wrote:
>> >>
>> >> Hi Amos,
>> >> i'm trying to implement kerberos as you suggested me. But following
>> >> the guide i read "Do not use this method if you run winbindd or other
>> >> samba services as samba will reset the machine password every x days
>> >> and thereby makes the keytab invalid !!" and my system guy told me we
>> >> use winbindd method.
>> >>
>> >> How can i implement so?
>> >> Thanks
>> >
>> >
>> > _______________________________________________
>> > squid-users mailing list
>> > squid-users at lists.squid-cache.org
>> > http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>


From belle at bazuin.nl  Wed Dec 30 15:39:02 2015
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 30 Dec 2015 16:39:02 +0100
Subject: [squid-users] squid3 / debian stable / please update to 3.4.14
In-Reply-To: <OF02421B9C.B0F34AB2-ONC1257F2A.004E3936-C1257F2A.004F487A@asl.bergamo.it>
References: <OF02421B9C.B0F34AB2-ONC1257F2A.004E3936-C1257F2A.004F487A@asl.bergamo.it>
Message-ID: <vmime.5683fa96.5be8.521d61a706f44f6@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

You can very easy upgrade to 3.5.12 on Jessie. 
Add sid to your sources.list, or better in :
/etc/apt/sources.list.d/debian-sid.list 

Only the deb-src line is needed. 

Now apt-get update

# install dependecies.
apt-get build-dep squid

# get and build source. 
apt-get source squid -b

if you missing something, get that package first, build it, install it and do above again. 

!! thing to know when using the higher versions this way. 

/etc/squid3
Changed to
/etc/squid 

all squid3 changed to squid in debian testing/sid

and one thing. Backup first ! 

Greetz, 

Louis




> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Massimo.Sala at asl.bergamo.it
> Verzonden: dinsdag 29 december 2015 15:26
> Aan: luigi at debian.org
> CC: squid-users at lists.squid-cache.org
> Onderwerp: [squid-users] squid3 / debian stable / please update to 3.4.14
> 
> ciao Luigi
> 
> I ask to update the distro to squid 3.4.14, the last stable version,
> released in august.
> 
> Rationale :
> 1) various bugs and memory leaks fixed;
> 2) security fix for CVE 2015 5400;
> 3) support for Alternate-Protocol HTTP header.
> 
> I need 3) to disable QUIC on youtube, otherwise squid3 cannot cache
> videos.
> 
> References :
>         https://packages.debian.org/jessie/squid3
> 
> ftp://ftp.fu-berlin.de/unix/www/squid/squid/squid-3.4-ChangeLog.txt
>         http://wiki.squid-cache.org/KnowledgeBase/Block QUIC protocol
> 
> 
> Best regards, Massimo
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From zw963 at 163.com  Wed Dec 30 17:29:21 2015
From: zw963 at 163.com (Billy.Zheng (zw963))
Date: Thu, 31 Dec 2015 01:29:21 +0800
Subject: [squid-users] Squid is not worked in OpenVZ VPS.
In-Reply-To: <CA+Y8hcNnEJP-9GbWVqYntx_82b1cgOLaNTQuexmBTLtmCVQ6Qg@mail.gmail.com>
References: <87fuyk6x0v.fsf@2540p.emacsfans.com>
 <D5D122A0-448D-4557-87A5-12B063E16E17@gmail.com>
 <87ege46n28.fsf@2540p.emacsfans.com>
 <CA+Y8hcNnEJP-9GbWVqYntx_82b1cgOLaNTQuexmBTLtmCVQ6Qg@mail.gmail.com>
Message-ID: <87d1tn7slq.fsf@2540p.emacsfans.com>

I can acess `www.google.com' in side my VPS with W3M.

But, can not access www.google.com across my Squid server.

I don't what happen here, those VPS provider guys work on this two days, 
not resolved.

Kinkie writes:

> Well, the IPv6 address could be telling. Maybe OpenVZ is setting up a
> V6 network but has no route out of it.
> Can you try accessing a known V4 and a known V6 address? It could help
> you understand if the issue is there. In that case, you need to fix
> the issue at the OpenVZ level.
>
>
> On Wed, Dec 30, 2015 at 3:14 PM, Billy.Zheng <zw963 at 163.com> wrote:
>> Thanks for you reply.
>>
>> The failed message is: `Connection to ???? failed', ???? is a IPV6
>> address somehow.
>>
>> I found i just could't access part of website, not all.
>>
>> so, I thought this is not Squid problem, maybe china GFW prevent this,
>> I doubt OpenVZ provider's machine room exist some problem.
>>
>> Thanks.
>>
>> Francesco Chemolli writes:
>>
>>>> On 30 Dec 2015, at 11:39, Billy.Zheng(zw963) <zw963 at 163.com> wrote:
>>>>
>>>> Hi, I have two VPS in same location(HONG KONG)
>>>>
>>>> the two VPS is blongs to two service provider, one OpenVZ, one XEN.
>>>>
>>>> I choice with same version CentOS(6.7), and with same config script for
>>>> a FORWARD proxy to access free world.
>>>>
>>>> XEN always worked for me, but OpenVZ is not.
>>>>
>>>
>>>> the second logs is so strange,  www.vpsnine.com is my OpenVZ VPS
>>>> provider domain name, I never access it from my local browser.
>>>> and not like another XEN VPS, those log output is very very slow.
>>>>
>>>> Could you give me some clue for resolve this? Thanks.
>>>
>>> when you try accessing some destination with the proxy that is not working, what does the error page say?
>>>
>>>       Kinkie
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> --
>> Geek, Rubyist, Emacser
>> Homepage: http://zw963.github.io
>>

-- 
Geek, Rubyist, Emacser
Homepage: http://zw963.github.io



From eliezer at ngtech.co.il  Wed Dec 30 18:38:36 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 30 Dec 2015 20:38:36 +0200
Subject: [squid-users] Squid is not worked in OpenVZ VPS.
In-Reply-To: <87d1tn7slq.fsf@2540p.emacsfans.com>
References: <87fuyk6x0v.fsf@2540p.emacsfans.com>
 <D5D122A0-448D-4557-87A5-12B063E16E17@gmail.com>
 <87ege46n28.fsf@2540p.emacsfans.com>
 <CA+Y8hcNnEJP-9GbWVqYntx_82b1cgOLaNTQuexmBTLtmCVQ6Qg@mail.gmail.com>
 <87d1tn7slq.fsf@2540p.emacsfans.com>
Message-ID: <568424AC.5080601@ngtech.co.il>

On 30/12/2015 19:29, Billy.Zheng (zw963) wrote:
> I can acess `www.google.com' in side my VPS with W3M.
>
> But, can not accesswww.google.com  across my Squid server.
>
> I don't what happen here, those VPS provider guys work on this two days,
> not resolved.

Hey Billy,

 From the information page it is clear that your server tries to access 
some IPV6 host and doesn't succeeded.
If you can run couple tests, try to contact my web server at:
http://ngtech.co.il/

And see if it works.
Also does this VPS machine has ipv6 access at all? ping6 .. other tools?

There is also another option that you can try to add  "dns_v4_first on" 
(http://www.squid-cache.org/Doc/config/dns_v4_first/)

into the squid.conf and only then try to access http://www.google.com/ .
It will clear many doubts and very fast.

Eliezer






From aashima2madaan at gmail.com  Wed Dec 30 21:24:07 2015
From: aashima2madaan at gmail.com (Aashima)
Date: Wed, 30 Dec 2015 21:24:07 +0000 (UTC)
Subject: [squid-users] Squid proxy removing Transfer-Encoding header
Message-ID: <loom.20151230T221825-432@post.gmane.org>

Hey all,

I have an application in front of which I am using Squid proxy. 
Suppose application name is APP
So it is like client -> Squid -> APP and return
 If App return Transfer-Encoding header to Squid, Squid removes that response 
header and forwards rest to Client. 

Am not getting why it is removing that header ? Couldnt find any posts
 also on any discussion group or blog.

Thank you
Aashima



From rousskov at measurement-factory.com  Wed Dec 30 21:36:28 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 30 Dec 2015 14:36:28 -0700
Subject: [squid-users] Squid proxy removing Transfer-Encoding header
In-Reply-To: <loom.20151230T221825-432@post.gmane.org>
References: <loom.20151230T221825-432@post.gmane.org>
Message-ID: <56844E5C.5000004@measurement-factory.com>

On 12/30/2015 02:24 PM, Aashima wrote:

> So it is like client -> Squid -> APP and return
>  If App return Transfer-Encoding header to Squid, Squid removes that response 
> header and forwards rest to Client. 
> 
> Am not getting why it is removing that header ? Couldnt find any posts
>  also on any discussion group or blog.

Transfer-Encoding is a standard HTTP hop-by-hop header. Hop-by-hop
headers are meant for the immediate recipient (Squid in your case),
rather than the final or "end" recipient (Client in your case). Squid
must not forward hop-by-hop headers (but may add them as needed, which
may look like forwarding to an outside observer).

If you describe the actual problem you are having (in addition to this
technical detail), somebody on this list might be able to guide you
towards a solution.


Good luck,

Alex.



From alex at samad.com.au  Wed Dec 30 22:40:34 2015
From: alex at samad.com.au (Alex Samad)
Date: Thu, 31 Dec 2015 09:40:34 +1100
Subject: [squid-users] squid reverse proxy and client certs
In-Reply-To: <20151230105636.GA24776@fantomas.sk>
References: <CAJ+Q1PXq9To23qqisTKPGDgCNXbC8NTKuTtqxUcd-HuR6TaTjg@mail.gmail.com>
 <20151230105636.GA24776@fantomas.sk>
Message-ID: <CAJ+Q1PV5e7Bje4e4o2h2B=3PmucxMCEfkZUSadFoHiU2WdrygA@mail.gmail.com>

Hi

Thanks I thought that might be the issue.

could you point me to an example for requesting client certs for a directory

Thanks
Alex

On 30 December 2015 at 21:56, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
> On 30.12.15 15:11, Alex Samad wrote:
>>
>> I have squid 3.5.12 working as a reverse proxy
>>
>> cache_peer 127.0.0.1 \
>> parent 443 0 proxy-only no-query no-digest originserver \
>> login=PASS \
>> ssl \
>> sslcafile=/etc/pki/tls/certs/ca-bundle.crt \
>> sslflags=DONT_VERIFY_PEER \
>> name=webServer
>>
>> This points to httpd which has a
>>        <Location /test/>
>>                DirectoryIndex index.shtml index.html
>>                Options -Indexes -Includes +IncludesNOEXEC
>> -SymLinksIfOwnerMatch -ExecCGI -FollowSymLinks
>>
>>                SSLOptions +StdEnvVars +ExportCertData
>>                SSLVerifyClient optional_no_ca
>>                SSLVerifyDepth 4
>>        </Location>
>>
>> Unfortunately the request for a client cert never makes it to the client.
>>
>> How can I change this to allow client certs to work
>
>
> client certs will only work when you pass the connection directly to web
> server without unbundling SSL.
> That means, it's useless to use reverse proxy for HTTPS server when it needs
> client certificates.
>
> The workaround you could be in verifying client certificates by squid,
> pushing that info to server and webserver trusting that info...
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Chernobyl was an Windows 95 beta test site.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From saravanan.nagarajan87 at gmail.com  Wed Dec 30 22:48:38 2015
From: saravanan.nagarajan87 at gmail.com (SaRaVanAn)
Date: Wed, 30 Dec 2015 16:48:38 -0600
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
In-Reply-To: <20151228121359.GA1357@fantomas.sk>
References: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
 <56808D1E.5050209@treenet.co.nz>
 <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>
 <5680BFA8.1010008@ngtech.co.il> <20151228121359.GA1357@fantomas.sk>
Message-ID: <CA+86yMiqcM_6sioa1Qq-tNHoxfLsx=5BH7ENDTz8jzLDncDJ1A@mail.gmail.com>

Hi, All,
I tired suggested refresh pattern, still i was getting TCP_HIT/MEM_HIT.
It's not getting refreshed after 10 minutes.


*Conf*
refresh_pattern -i ^http://[a-z\-\_\.A-Z0-9]+\.wsj\.(net|net|com|edu)/ 10
200% 10 override-expire override-lastmod reload-into-ims ignore-reload

*Logs*


Wed Dec 30 21:31:44 2015.976   1915 172.19.131.180 TCP_MISS/200 619 GET
http://s.wsj.net/javascript/pushdownAd.js - DIRECT/184.86.240.217
application/x-javascript
*Wed Dec 30 21:31:44 2015.976   1915 172.19.131.180 TCP_MISS/200 667 GET
http://s.wsj.net/static_html_files/pushdownAd.css
<http://s.wsj.net/static_html_files/pushdownAd.css> - DIRECT/184.86.240.217
<http://184.86.240.217> text/css*
*Wed Dec 30 21:52:38 2015.577      0 172.19.131.180 TCP_MEM_HIT/200 676 GET
http://s.wsj.net/static_html_files/pushdownAd.css
<http://s.wsj.net/static_html_files/pushdownAd.css> - NONE/- text/css*
Wed Dec 30 21:52:38 2015.577      0 172.19.131.180 TCP_MEM_HIT/200 628 GET
http://s.wsj.net/javascript/pushdownAd.js - NONE/- application/x-javascript


I have gone through the packet captures. It looks like expiry time is
greater than min time of refresh_pattern. But i have used override options.
Here  I am confused whether precedence goes to expiry time or min time .I
am not clear on how it works.

Can you guide me on how it works and why it is not getting refreshed ? I
need experts guidance here


*pushdownAd.css repsonse header timings*

Last-Modified: Mon, 14 Dec 2015 04:37:00 GMT\r\n

Expires: Thu, 31 Dec 2015 01:10:17 GMT\r\n

Date: Wed, 30 Dec 2015 21:31:46 GMT\r\n

Regards,
Saravanan N

On Mon, Dec 28, 2015 at 6:13 AM, Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> On 28.12.15 06:50, Eliezer Croitoru wrote:
>
>> And you can tweak it a bit to something like:
>> refresh_pattern -i ^http://[a-z\-\_\.A-Z0-9]+\.wsj\.(net|net|com|edu)/
>> 10 200% 10 \
>>         override-expire reload-into-ims
>>
>
> - I would avoid the underscore. underscore is not valid character for an
> internet hostname
> - dash at the begin or end of [] will eliminate the need for an underscore
>
> [a-zA-Z0-9.-]+ should do it.
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> "To Boot or not to Boot, that's the question." [WD1270 Caviar]
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151230/54cc591a/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 31 05:00:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 18:00:54 +1300
Subject: [squid-users] Specifiying openssl location with ./configure?
In-Reply-To: <CABQqRmYp3RfxD0vgGME=6bYO6yv0_S719XfLx-pYs+8mBo80cQ@mail.gmail.com>
References: <CABQqRmYp3RfxD0vgGME=6bYO6yv0_S719XfLx-pYs+8mBo80cQ@mail.gmail.com>
Message-ID: <0ae56106ae55fd9bd6ce65193de10d73@treenet.co.nz>

On 2015-12-29 09:12, George Hollingshead wrote:
> I have a localy compilied the latest openssl to default location
> /usr/local directory.

If you really have done that then any Squid built after will auto-detect 
it there and link to that new OpenSSL version using only the 
"--with-openssl" build option.


> 
> Is there a way to run ./configure to use the openssl headers and such
> in the /usr/local directories?

If you actually built the newer OpenSSL and placed it somewhere 
non-default then you should build Squid using "--with-openssl=/path" 
where the path is the *base* directory under which you installed 
OpenSSL.

I.e. using --with-openssl=/path literally, autoconf will look for 
/path/include/openssl/*.h and /path/lib/openssl.a and add the -I and -L 
compiler flags automatically for you if all the required pieces are 
actually found there and working. Or will exit with an error stating 
what parts are broken.

The method Yuri pointed out (adding the compiler flags manually) can 
also work, but none of the ./configure testing is done to verify the 
things there are working. So Squid will be built with all OpenSSL bug 
workarounds disabled, and if any were needed or the openssl install is 
broken you will not find out until much later in the build process.


PS. same goes for any software correctly using autoconf --with/--without 
options to link libraries.

Amos



From xxiao8 at fosiao.com  Thu Dec 31 05:02:36 2015
From: xxiao8 at fosiao.com (xxiao8)
Date: Wed, 30 Dec 2015 23:02:36 -0600
Subject: [squid-users] ip-based ACL under transparent mode
Message-ID: <5684B6EC.2060207@fosiao.com>

Under transparent mode, is it possible to get client's IP and assign a 
specific ACL rule to it? is it possible to use the client-IP-address as 
a variable in redirector scripts? Basically when transparent mode is 
used we don't have the "user" for each requests and I'm thinking if I 
can extract the IP of client request and use that to distinguish them, 
at an IP level though. I want to proxy clients differently.

Thanks,
xxiao



From squid3 at treenet.co.nz  Thu Dec 31 05:15:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 18:15:46 +1300
Subject: [squid-users] Host header forgery affects pure splice
	environment too?
In-Reply-To: <56814757.4080101@gmail.com>
References: <56806285.8080102@trimble.com> <56809193.5060602@treenet.co.nz>
 <5680AD82.6020901@trimble.com> <56814021.3050900@urlfilterdb.com>
 <56814757.4080101@gmail.com>
Message-ID: <e2b5399391775efe7589a2fa6f12ff4d@treenet.co.nz>

On 2015-12-29 03:29, Yuri Voinov wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
> 
> Heh. It seems bogus by our opinion.
> 
> Tor certainly thinks otherwise.

Anything under the .net TLD is under resolving control of the global DNS 
lookup system. Those FQDN are invalid / NXDOMAIN. Which is the very 
definition of bogus names by that system.

If they had been .onion names, then resolving would be up to TOR to 
define whether they are bogus or not. But they are not .onion domains.


> 
> Actually, from this stupid idea to do a bump Tor network traffic?
> 

Ideally not. We have enough HTTP related protocols to deal with already. 
It would be best to determine what the correct TLS handling for these 
certificates is and ensure that happens.

We also need to check up on why Host verification is happening at all on 
these requests. It should not be getting that far AFAIK.


> 28.12.15 19:58, Marcus Kool ?????:
>> 
>> 
>> On 12/28/2015 01:33 AM, Jason Haar wrote:
>>> On 28/12/15 14:34, Amos Jeffries wrote:
>> [...]
>>> I think we know what the problem is: TOR is making TLS connections (I
>>> don't know if they're HTTPS) on port 443 and uses SNI names that 
>>> aren't
>>> real?
>> 
>> peeking on tor-proxy-2.cypherpunks.to shows a certificate with
>>   issuer '/CN=www.totaikrsupklbpy5.com'
>>   subject '/CN=www.bpanciu6f5cjqflv2.net'
>> so the certificate is definitely bogus.
>> 
>> marcus
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
> 
> iQEcBAEBCAAGBQJWgUdWAAoJENNXIZxhPexGoW4H/3aTH/y+C7pMWK+2BtHNIB4T
> NMueFP/Nv2ixJf8MmqPh765R3Q6o3KWWEuK6BHcunZRjQJh1glz6h073ocVSb2EJ
> BkhHUFuYbF31hwZCvZwFr7tFlKDvQ9yBvmwk3Ep3KjiFThoF+uwyV3HbEWmUx083
> hAgVfXnqqeClhZx4WSrOLLLc4BTAfuCYM84ox6JRemqHq5kFpObaLRPCvNkO+VtF
> M/yId+ag4pyUMGcTXN0KD+SHtgdKkraWRP7u5RrQ0kiScwv5Q30nV09MY93qkvaB
> hi5qgEGLlDyO+qXkqpNoPXYqinVFRGgEE7OMzbthvCRJk1v2XVB2I+mab1McnQk=
> =H3Ki
> -----END PGP SIGNATURE-----
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Dec 31 05:25:30 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 18:25:30 +1300
Subject: [squid-users] ip-based ACL under transparent mode
In-Reply-To: <5684B6EC.2060207@fosiao.com>
References: <5684B6EC.2060207@fosiao.com>
Message-ID: <49195ae48e082c726d2f73429854ad3c@treenet.co.nz>

On 2015-12-31 18:02, xxiao8 wrote:
> Under transparent mode, is it possible to get client's IP and assign a
> specific ACL rule to it?

The "src" ACL matches client IP. Always.

<http://wiki.squid-cache.org/SquidFaq/SquidAcl#How_do_I_allow_my_clients_to_use_the_cache.3F>

> is it possible to use the client-IP-address
> as a variable in redirector scripts?

<http://wiki.squid-cache.org/Features/AddonHelpers#URL_manipulation>

> Basically when transparent mode
> is used we don't have the "user" for each requests and I'm thinking if
> I can extract the IP of client request and use that to distinguish
> them, at an IP level though. I want to proxy clients differently.

It is almost always a bad idea to do it with redirector (especially if 
you actually mean re-writer). But you have omitted any explanation of 
what you mean by "differently", so we can't help with the actual problem 
you are trying to solve.

Amos



From squid3 at treenet.co.nz  Thu Dec 31 05:30:15 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 18:30:15 +1300
Subject: [squid-users] Squid with NTLM auth behind netscaler
In-Reply-To: <CAJrMMC9YXAhyDa09eo78GjoXx6MXrEx_6RVsqCihMEjeYny=Ug@mail.gmail.com>
References: <5682A25E.3060903@ngtech.co.il>
 <CAJrMMC8OngX_0Cobq9Ebxu5bcLaWVW6cO5-UV4JOnDsv0LJC-A@mail.gmail.com>
 <vmime.5682a80b.3acd.7005164d5dfb193b@ms249-lin-003.rotterdam.bazuin.nl>
 <CAJrMMC9YXAhyDa09eo78GjoXx6MXrEx_6RVsqCihMEjeYny=Ug@mail.gmail.com>
Message-ID: <4506890879bd632d74b896722175717c@treenet.co.nz>

On 2015-12-31 03:42, Fabio Bucci wrote:
> Could you help me in kerberos configuration only? I don't want a 
> fallback

That should be blindingly obvious ... just use the Kerberos helper 
directly as the auth_param helper. Omit the negotiate_wrapper helper and 
ntlm_auth helper parts.

Amos



From squid3 at treenet.co.nz  Thu Dec 31 08:31:53 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 21:31:53 +1300
Subject: [squid-users] Host header forgery policy in service provider
	environment
In-Reply-To: <1451473260.12487.46.camel@comnet.uz>
References: <1451473260.12487.46.camel@comnet.uz>
Message-ID: <22c381b6ff3b5f822f0a0749193abf00@treenet.co.nz>

On 2015-12-31 00:01, Garri Djavadyan wrote:
> Hello Squid members and developers!
> 
> First of all, I wish you a Happy New Year 2016!
> 
> The current Host header forgery policy effectively prevents a cache
> poisoning. But also, I noticed, it deletes verified earlier cached
> object. Is it possible to implement more careful algorithm as an
> option? For example, if Squid will not delete earlier successfully
> verified and valid cached object and serve forged request from the
> cache if would be more effective and in same time secure behavior.


This seems to be describing 
<http://bugs.squid-cache.org/show_bug.cgi?id=3940>

So far we don't have a solution. Patches very welcome.

Amos



From squid3 at treenet.co.nz  Thu Dec 31 08:54:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 21:54:38 +1300
Subject: [squid-users] Squid proxy whitelisting with HTTPS URL filtering
In-Reply-To: <5200B366-663E-4EFB-A19B-5E46676E9D9E@gmail.com>
References: <E9A0B32D-0D9C-439C-AB7F-37A69C7AB3B4@gmail.com>
 <201512281632.12691.Antony.Stone@squid.open.source.it>
 <5200B366-663E-4EFB-A19B-5E46676E9D9E@gmail.com>
Message-ID: <08e3c774c80b2e3fa4f6b68f2172da22@treenet.co.nz>

On 2015-12-29 04:55, joru.pacs wrote:
> Hi!
> 
> Currently, I am using the version squid-3.5.12. I have configure the
> SSL bump this way:
> 
> http_port 8080 ssl-bump \
>     cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
>     generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> acl step1 at_step SslBump1
> 
> #sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> 
> ssl_bump peek step1
> ssl_bump bump all
> 
> I am able to do HTTP filtering, however, using doing an HTTPS url
> filter does not work. A specific example is whitelisting the following
> URL https://www.facebook.com/login, but I do not want to allow all of
> facebook?s traffic to be whitelisted, thus the url
> https://www.facebook.com should not be allowed.
> 
> Trying to do a url_regex to www.facebook.com/login [1] will give me
> the default error page from squid. I am using firefox to use the
> proxy. And in the logs I am given a 403 error:
> 
> "GET https://www.facebook.com/login HTTP/1.1" 403 "-" "Mozilla/5.0
> (Macintosh; Intel Mac OS X 10.11; rv:42.0) Gecko/20100101
> Firefox/42.0? TAG_NONE:HIER_NONE
> 

That tells that;
- the bumping is happening, and
- traffic being decrypted, and
- request is denied by your http_access rules.


So what are the other squid.conf contents?

Amos


From reet.vyas28 at gmail.com  Thu Dec 31 08:55:30 2015
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Thu, 31 Dec 2015 14:25:30 +0530
Subject: [squid-users] Assign multiple IP Address to squid
In-Reply-To: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>
References: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>
Message-ID: <CAA8ViV-4sQ5CU0wBNtfKs1KQz4gU=Z+8LE_TJBRU=egG+iB7oA@mail.gmail.com>

Hi all

Thanks for reply.  I have this squid setup and I am using squid as my
router and my requirement is like  I have one local webserver and I want to
access it from home and I want to  nat external ip to internal ip so that I
can access my local machine from outside network.  My ISP gave 10 external
ip and one i am using with squid and rest 9 are unused so I tried to create
alias on external inferface and gave one public ip to it and nat that
external ip to localip , but I cant access machine( with webserver) using
external ip, its shows access denied

On Tue, Dec 29, 2015 at 5:35 PM, Reet Vyas <reet.vyas28 at gmail.com> wrote:

> Hi
>
> I have working squid3.5.4 configuration with ssl bump, I am using this
> squid machine as router and have external IP to it and have a leased line
> connection but with leased line I have 10 extra IP address and I want to
> NAT those external ip to local ip on same network, like we do in our
> router, so that I can assign those IP ip my machines having webservers.
>
> Please suggest me way to configure it.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151231/593929d4/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 31 09:03:59 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 22:03:59 +1300
Subject: [squid-users] sslBump, squid in transparent mode
In-Reply-To: <56818396.8080306@norma.perm.ru>
References: <56818396.8080306@norma.perm.ru>
Message-ID: <896d6caeb93606377c5b7a96ef527f2b@treenet.co.nz>

On 2015-12-29 07:46, Eugene M. Zheganin wrote:
> Hi.
> 
> I'm still trying to figure out why I get certificate generated for IP
> address instead of hostname when the HTTPS traffic is intercepted bu
> sllBump-enable squid. I'm using iptables to do this:
> 
> rdr on $iifs inet proto tcp from 192.168.0.0/16 to !<rfc1918> port 443
> -> 127.0.0.1 port 3131
> rdr on vpn inet proto tcp from 192.168.0.0/16 to !<rfc1918> port 443 ->
> 127.0.0.1 port 3131
> 
> and the port is configured as follows:
> 
> https_port 127.0.0.1:3131 intercept ssl-bump
> cert=/usr/local/etc/squid/certs/squid.cert.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> dhparams=/usr/local/etc/squid/certs/dhparam.pem
> https_port [::1]:3131 intercept ssl-bump
> cert=/usr/local/etc/squid/certs/squid.cert.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> dhparams=/usr/local/etc/squid/certs/dhparam.pem
> 
> This way I'm getting a waring in browser (https://youtube.com is opened
> in the example below):
> 
> ===Cut===
> youtube.com uses an invalid security certificate.
> 
> The certificate is not trusted because the issuer certificate is 
> unknown.
> The server might not be sending the appropriate intermediate 
> certificates.
> An additional root certificate may need to be imported.
> The certificate is only valid for 173.194.71.91
> 
> (Error code: sec_error_unknown_issuer)
> ===Cut===
> 
> And the tcpdump capture clearly shows that client browser did sent an 
> SNI:
> 
> https://gyazo.com/c1ba348fb4ee56c6c30f3e22ff9877f8
> 
> I'll apreciate any help.

You have ssl_bump rules doing a peek as well?
SNI is not known until/unless after a peek action takes place at step 1.

If your Squid is so old it does not support peek, then it also does not 
support SNI.

If you are bumping, or splicing, or terminating at stage 1 of the 
ssl-bump process then peek is not happening and the SNI is not 
available.

If you are peeking at step1 and the peek is succeeding (not doing a 
splice failure recovery) then it is likely a bug.

Amos


From belle at bazuin.nl  Thu Dec 31 09:07:17 2015
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 31 Dec 2015 10:07:17 +0100
Subject: [squid-users] Squid is not worked in OpenVZ VPS.
In-Reply-To: <568424AC.5080601@ngtech.co.il>
References: <87d1tn7slq.fsf@2540p.emacsfans.com>
Message-ID: <vmime.5684f045.4dc5.1db233e31e6c7c15@ms249-lin-003.rotterdam.bazuin.nl>

A simple test, and quick fix. 

ping6 ipv6.google.com 
No reply. 
Add in your interfaces : 

auto 6to4
iface 6to4 inet6 6to4
        local YOUR_EXTERNAL_IP

ifup 6to4 

and ping6 ipv6.google.com again. 
Not the most elegant solution but works here for me. 


Greetz, 

Louis


> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Eliezer Croitoru
> Verzonden: woensdag 30 december 2015 19:39
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Squid is not worked in OpenVZ VPS.
> 
> On 30/12/2015 19:29, Billy.Zheng (zw963) wrote:
> > I can acess `www.google.com' in side my VPS with W3M.
> >
> > But, can not accesswww.google.com  across my Squid server.
> >
> > I don't what happen here, those VPS provider guys work on this two days,
> > not resolved.
> 
> Hey Billy,
> 
>  From the information page it is clear that your server tries to access
> some IPV6 host and doesn't succeeded.
> If you can run couple tests, try to contact my web server at:
> http://ngtech.co.il/
> 
> And see if it works.
> Also does this VPS machine has ipv6 access at all? ping6 .. other tools?
> 
> There is also another option that you can try to add  "dns_v4_first on"
> (http://www.squid-cache.org/Doc/config/dns_v4_first/)
> 
> into the squid.conf and only then try to access http://www.google.com/ .
> It will clear many doubts and very fast.
> 
> Eliezer
> 
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Dec 31 09:12:45 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 22:12:45 +1300
Subject: [squid-users] Assign multiple IP Address to squid
In-Reply-To: <CAA8ViV-4sQ5CU0wBNtfKs1KQz4gU=Z+8LE_TJBRU=egG+iB7oA@mail.gmail.com>
References: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>
 <CAA8ViV-4sQ5CU0wBNtfKs1KQz4gU=Z+8LE_TJBRU=egG+iB7oA@mail.gmail.com>
Message-ID: <3f6fe24b6409fe630ef23c36abfe5313@treenet.co.nz>

On 2015-12-31 21:55, Reet Vyas wrote:
> Hi all
> 
> Thanks for reply.  I have this squid setup and I am using squid as my
> router and my requirement is like  I have one local webserver and I
> want to access it from home and I want to  nat external ip to internal
> ip so that I can access my local machine from outside network.  My ISP
> gave 10 external ip and one i am using with squid and rest 9 are
> unused so I tried to create alias on external inferface and gave one
> public ip to it and nat that external ip to localip , but I cant
> access machine( with webserver) using external ip, its shows access
> denied

You need Squid setup with this virtual hosting configuration:
<http://wiki.squid-cache.org/ConfigExamples/Reverse/VirtualHosting>


Notice how this has nothing to do with IP addresses. Whether you have 1 
or 10 pointing at the Squid does not matter. You can even have the 
router point *only* port 80 (and/or 443) to Squid and the rest of the 
ports elsewhere.

Amos



From eliezer at ngtech.co.il  Thu Dec 31 09:35:18 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 31 Dec 2015 11:35:18 +0200
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
In-Reply-To: <CA+86yMiqcM_6sioa1Qq-tNHoxfLsx=5BH7ENDTz8jzLDncDJ1A@mail.gmail.com>
References: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
 <56808D1E.5050209@treenet.co.nz>
 <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>
 <5680BFA8.1010008@ngtech.co.il> <20151228121359.GA1357@fantomas.sk>
 <CA+86yMiqcM_6sioa1Qq-tNHoxfLsx=5BH7ENDTz8jzLDncDJ1A@mail.gmail.com>
Message-ID: <5684F6D6.3050202@ngtech.co.il>

On 31/12/2015 00:48, SaRaVanAn wrote:
> Hi, All,
> I tired suggested refresh pattern, still i was getting TCP_HIT/MEM_HIT.
> It's not getting refreshed after 10 minutes.
>
>
> *Conf*
> refresh_pattern -i ^http://[a-z\-\_\.A-Z0-9]+\.wsj\.(net|net|com|edu)/ 10
> 200% 10 override-expire override-lastmod reload-into-ims ignore-reload

I am not sure but you are maybe hitting bug 4389 which I have just 
recently filed:
http://bugs.squid-cache.org/show_bug.cgi?id=4389

The basic rule is that you also need to have a Cache-Control header in 
order to enforce somethings.
If you have a "must-revalidate" rule it would be reloaded.
Also from your logs it seems that you or the client have not tried to 
"refresh" the request using some Cache-Control headers or using the F5 
button(when in some cases it won't work).

Try to remove the override instructions and use 0 value for the min and 
see what happens.

Eliezer


From devaiah at gmail.com  Thu Dec 31 09:42:04 2015
From: devaiah at gmail.com (Devaiah Mallangada Kalaiah)
Date: Thu, 31 Dec 2015 15:12:04 +0530
Subject: [squid-users] Assign fu,multiple IP Address to squid
In-Reply-To: <3f6fe24b6409fe630ef23c36abfe5313@treenet.co.nz>
References: <CAA8ViV8g=NDOmHRge=bcMEZFSdwjE5Ze882X02eNQRJiaoa5pQ@mail.gmail.com>
 <CAA8ViV-4sQ5CU0wBNtfKs1KQz4gU=Z+8LE_TJBRU=egG+iB7oA@mail.gmail.com>
 <3f6fe24b6409fe630ef23c36abfe5313@treenet.co.nz>
Message-ID: <5684f888.1048620a.ec3f1.ffffd1c2@mx.google.com>



-----Original Message-----
From: "Amos Jeffries" <squid3 at treenet.co.nz>
Sent: ?12/?31/?2015 2:42 PM
To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Assign multiple IP Address to squid

On 2015-12-31 21:55, Reet Vyas wrote:
> Hi all
> 
> Thanks for reply.  I have this squid setup and I am using squid as my
> router and my requirement is like  I have one local webserver and I
> want to access it from home and I want to  nat external ip to internal
> ip so that I can access my local machine from outside network.  My ISP
> gave 10 external ip and one i am using with squid and rest 9 are
> unused so I tried to create alias on external inferface and gave one
> public ip to it and nat that external ip to localip , but I cant
> access machine( with webserver) using external ip, its shows access
> denied

You need Squid setup with this virtual hosting configuration:
<http://wiki.squid-cache.org/ConfigExamples/Reverse/VirtualHosting>


Notice how this has nothing to do with IP addresses. Whether you have 1 
or 10 pointing at the Squid does not matter. You can even have the 
router point *only* port 80 (and/or 443) to Squid and the rest of the 
ports elsewhere.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151231/28e8b783/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 31 09:43:18 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 22:43:18 +1300
Subject: [squid-users] squid3 / debian stable / please update to 3.4.14
In-Reply-To: <OF02421B9C.B0F34AB2-ONC1257F2A.004E3936-C1257F2A.004F487A@asl.bergamo.it>
References: <OF02421B9C.B0F34AB2-ONC1257F2A.004E3936-C1257F2A.004F487A@asl.bergamo.it>
Message-ID: <63565ce8c070246b4976a4351027b99b@treenet.co.nz>

On 2015-12-30 03:26, Massimo.Sala at asl.bergamo.it wrote:
> ciao Luigi
> 
> I ask to update the distro to squid 3.4.14, the last stable version,
> released in august.
> 
> Rationale :
> 1) various bugs and memory leaks fixed;
> 2) security fix for CVE 2015 5400;
> 3) support for Alternate-Protocol HTTP header.
> 
> I need 3) to disable QUIC on youtube, otherwise squid3 cannot cache
> videos.
> 


Hi Massimo, why cc'ing squid-users? nothing this list can do about it.

Anyhow, the Debian 3.4.8-6 package has already been patched to contain 
the important fixes from later upstream 3.4 releases.
<http://metadata.ftp-master.debian.org/changelogs/main/s/squid3/squid3_3.4.8-6+deb8u1_changelog>

(that covers your #1 and #2 items)

All it lacks is the minor changes which AFAIK do not meet the criteria 
required for acceptance into the Debian stable distro.

If you need custom build with other features (such as HTTPS support), 
you are better off building the more up to date 3.5 version available 
from Stretch/Testing repository.


As for #3, the Alternate-Protocol header patch is just automating these 
squid.conf settings, which you can use explicitly in any Squid version:

  acl AP rep_header_regex Alternate-Protocol .
  reply_header_access deny AP


HTH
Amos



From belle at bazuin.nl  Thu Dec 31 10:20:18 2015
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 31 Dec 2015 11:20:18 +0100
Subject: [squid-users] squid3 / debian stable / please update to 3.4.14
In-Reply-To: <63565ce8c070246b4976a4351027b99b@treenet.co.nz>
References: <OF02421B9C.B0F34AB2-ONC1257F2A.004E3936-C1257F2A.004F487A@asl.bergamo.it>
Message-ID: <vmime.56850162.706e.16333dae7e166a82@ms249-lin-003.rotterdam.bazuin.nl>

> you are better off building the more up to date 3.5 version available 
> from Stretch/Testing repository.

I disagree with this one, use SID and not testing, testing has a longer delay in security updates and is updated after unstable.
See :  https://www.debian.org/security/faq


Greetz, 

Louis

> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Amos Jeffries
> Verzonden: donderdag 31 december 2015 10:43
> Aan: Massimo.Sala at asl.bergamo.it
> CC: luigi at debian.org; squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] squid3 / debian stable / please update to
> 3.4.14
> 
> On 2015-12-30 03:26, Massimo.Sala at asl.bergamo.it wrote:
> > ciao Luigi
> >
> > I ask to update the distro to squid 3.4.14, the last stable version,
> > released in august.
> >
> > Rationale :
> > 1) various bugs and memory leaks fixed;
> > 2) security fix for CVE 2015 5400;
> > 3) support for Alternate-Protocol HTTP header.
> >
> > I need 3) to disable QUIC on youtube, otherwise squid3 cannot cache
> > videos.
> >
> 
> 
> Hi Massimo, why cc'ing squid-users? nothing this list can do about it.
> 
> Anyhow, the Debian 3.4.8-6 package has already been patched to contain
> the important fixes from later upstream 3.4 releases.
> <http://metadata.ftp-
> master.debian.org/changelogs/main/s/squid3/squid3_3.4.8-
> 6+deb8u1_changelog>
> 
> (that covers your #1 and #2 items)
> 
> All it lacks is the minor changes which AFAIK do not meet the criteria
> required for acceptance into the Debian stable distro.
> 
> If you need custom build with other features (such as HTTPS support),
> you are better off building the more up to date 3.5 version available
> from Stretch/Testing repository.
> 
> 
> As for #3, the Alternate-Protocol header patch is just automating these
> squid.conf settings, which you can use explicitly in any Squid version:
> 
>   acl AP rep_header_regex Alternate-Protocol .
>   reply_header_access deny AP
> 
> 
> HTH
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Dec 31 10:31:44 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 23:31:44 +1300
Subject: [squid-users] Refresh pattern issue in squid 3.1.20
In-Reply-To: <5684F6D6.3050202@ngtech.co.il>
References: <CA+86yMj103mX7674_rep-Q9i-sNWyrOgf83PFWce7weeTevrTw@mail.gmail.com>
 <56808D1E.5050209@treenet.co.nz>
 <CA+86yMjY2Pq8b0PD8TTJmCarHSd39VEGhSkM9hu+7MmaBT=+Cw@mail.gmail.com>
 <5680BFA8.1010008@ngtech.co.il> <20151228121359.GA1357@fantomas.sk>
 <CA+86yMiqcM_6sioa1Qq-tNHoxfLsx=5BH7ENDTz8jzLDncDJ1A@mail.gmail.com>
 <5684F6D6.3050202@ngtech.co.il>
Message-ID: <5a23732638a897069de62ce0ae179517@treenet.co.nz>

On 2015-12-31 22:35, Eliezer Croitoru wrote:
> On 31/12/2015 00:48, SaRaVanAn wrote:
>> Hi, All,
>> I tired suggested refresh pattern, still i was getting 
>> TCP_HIT/MEM_HIT.
>> It's not getting refreshed after 10 minutes.
>> 
>> 
>> *Conf*
>> refresh_pattern -i ^http://[a-z\-\_\.A-Z0-9]+\.wsj\.(net|net|com|edu)/ 
>> 10
>> 200% 10 override-expire override-lastmod reload-into-ims ignore-reload
> 

It is not being refreshed because it does not need to be.

Basically the refresh_pattern overrides can only *extend* caching, or 
delay revalidation, not shorten it. If the origin says an object is 
fresh for X amount of time it is expensive (by all metrics; bandwidth, 
request latency, disk I/O delay, CPU cycles) to discard it earlier than 
that.

override-expires forces the 'min' value to apply. It is a *minimum* 
freshness time. If the Expires header or CC:max-age are present and 
already saying a value larger, then it has no effect.
  - this is what you are seeing SaRaVanAn.

If there were no Expires or CC:max-age, then the max limit would be 
applied and with a value of "10" it does what you want to happen.

  - notice how none of the override-* are relevant to doing what you 
want, and the Expires/CC:max-age override is just preventing some 
dynamic content from updating as fast as the origin claims it will be 
changing.


override-lastmod forces the 'min' limit to be used if the Last-Modified 
header (lmfactor) algorithm calculates a short caching time.
  - it also can only extend freshness time *up* to the min-value, not 
reduce it. If the algorithm produces a longer caching time that will be 
used.



> I am not sure but you are maybe hitting bug 4389 which I have just
> recently filed:
> http://bugs.squid-cache.org/show_bug.cgi?id=4389
> 

The CC:no-cache control is not present in the responses redbot shows me. 
So not that one.

Amos



From squid3 at treenet.co.nz  Thu Dec 31 10:43:05 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 31 Dec 2015 23:43:05 +1300
Subject: [squid-users] problem with squidGuard redirect page after
	upgrading squid
In-Reply-To: <CABQqRmZKV8EW4_nfiyuFTN0+H42BM7Hgp3wS8zkEcvevL=Ujfw@mail.gmail.com>
References: <CABQqRmZKV8EW4_nfiyuFTN0+H42BM7Hgp3wS8zkEcvevL=Ujfw@mail.gmail.com>
Message-ID: <e11ff81610b1a258f03043bfe6d57aa4@treenet.co.nz>

On 2015-12-29 11:46, George Hollingshead wrote:
> I've had squid3.0 running with squidGuard on my old ubuntu 10.04
> system with no problems for a few months now.
> 
> I just recently was enlightened by Yuri how to compile using a local
> copy of openssl so i could upgrade to latest squid.  This was a
> success.  Thanx again Yuri :)
> 
> Only problem now is when squidGuard goes to redirect a blocked page it
> comes up with something like   URL /block.html192.168.2.20
> 192.168.2.20/GET [1] page not found.
> 
> the local net address their is the computer that is being blocked.
> 
> Like i said earlier, this all worked before redirecting to
> http://localhost/block.html when needed, but since i upgraded squid
> from ubuntu's 3.0  to a compiled 3.5 i get this responce.
> 
> Any ideas as i'm not sure if squidGuard is been updated in 6 years.


SG is no longer maintained software. As Marcus already mentioned 
ufdbguard can be used instead if you really need the helper at all.

The distro providers which still provide SG are patching their packages 
to cope with the newer Squid helper protocol. If you cannot get away 
from SG, then you need to also to rebuild SG from that newer repository 
to maintain the lock-step dependency between them.
  But that said; everything SG provides a current Squid can also do 
(maybe better) by itself.

Amos



From Massimo.Sala at asl.bergamo.it  Thu Dec 31 13:16:23 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 31 Dec 2015 14:16:23 +0100
Subject: [squid-users] squid3 / debian stable / please update to 3.4.14
In-Reply-To: <63565ce8c070246b4976a4351027b99b@treenet.co.nz>
Message-ID: <OF414E1D0B.1D7F3AA4-ONC1257F2C.00484574-C1257F2C.0048E2FD@asl.bergamo.it>

Hi Amos

>       Hi Massimo, why cc'ing squid-users? nothing this list can do about 
it.


Package update : I know, it is a topic for debian users and package 
maintainer, so strictly speaking it is off-topic.

youtube video, disabling QUIC : I think it will be of general interest, I 
switch to a new thread for it.


Two subjects in one Email, excuse me !

Many thanks, Sala




Amos Jeffries <squid3 at treenet.co.nz> 
31/12/2015 10:43

To
Massimo.Sala at asl.bergamo.it
cc
luigi at debian.org,
Subject
Re: [squid-users] squid3 / debian stable / please update to 3.4.14






On 2015-12-30 03:26, Massimo.Sala at asl.bergamo.it wrote:
> ciao Luigi
> 
> I ask to update the distro to squid 3.4.14, the last stable version,
> released in august.
> 
> Rationale :
> 1) various bugs and memory leaks fixed;
> 2) security fix for CVE 2015 5400;
> 3) support for Alternate-Protocol HTTP header.
> 
> I need 3) to disable QUIC on youtube, otherwise squid3 cannot cache
> videos.
> 



Anyhow, the Debian 3.4.8-6 package has already been patched to contain 
the important fixes from later upstream 3.4 releases.
<
http://metadata.ftp-master.debian.org/changelogs/main/s/squid3/squid3_3.4.8-6+deb8u1_changelog
>

(that covers your #1 and #2 items)

All it lacks is the minor changes which AFAIK do not meet the criteria 
required for acceptance into the Debian stable distro.

If you need custom build with other features (such as HTTPS support), 
you are better off building the more up to date 3.5 version available 
from Stretch/Testing repository.


As for #3, the Alternate-Protocol header patch is just automating these 
squid.conf settings, which you can use explicitly in any Squid version:

  acl AP rep_header_regex Alternate-Protocol .
  reply_header_access deny AP


HTH
Amos





From Massimo.Sala at asl.bergamo.it  Thu Dec 31 13:45:17 2015
From: Massimo.Sala at asl.bergamo.it (Massimo.Sala at asl.bergamo.it)
Date: Thu, 31 Dec 2015 14:45:17 +0100
Subject: [squid-users] youtube video, caching, disabling QUIC
Message-ID: <OFAB8639EA.6EC153C3-ONC1257F2C.0048CEDE-C1257F2C.004B8860@asl.bergamo.it>

When you request a video on Youtube, its web servers send two new HTTP 
headers to the browser :

        alt-svc
        alternate-protocol

suggesting to the browser to switch to the new protocol QUIC.


Unfortunately

1) QUIC, working over UDP, is not cacheable by squid 3.4

2) even if cacheable, IT admins have to upgrade many tools to support and 
account videos over QUIC ( proxy, firewall, bandwidth shaping, etc... )

See :
        http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol


We want to disable QUIC, so the servers and browsers fallbacks to normal 
HTTP for videos.

---

I asked in another thread

        3) support for Alternate-Protocol HTTP header.


Amos' answer :

As for #3, the Alternate-Protocol header patch is just automating these 
squid.conf settings, which you can use explicitly in any Squid version:

  acl AP rep_header_regex Alternate-Protocol .
  reply_header_access deny AP


With that syntax :

squid3 -k reconfigure

2015/12/31 14:34:21| FATAL: Invalid ACL type 'rep_header_regex'
FATAL: Bungled /etc/squid3/squid.conf line 43: acl AP rep_header_regex 
alternate-protocol .
Squid Cache (Version 3.4.8): Terminated abnormally.
CPU Usage: 0.016 seconds = 0.008 user + 0.008 sys
Maximum Resident Size: 37936 KB
Page faults with physical i/o: 0



Is it rep_header, not rep_header_regex ?

Is it reply_header_access with 3 parameters ?

>From 
http://www.squid-cache.org/Versions/v3/3.4/cfgman/reply_header_access.html
        Usage: reply_header_access header_name allow|deny [!]aclname ...


Which is the correct syntax to suppress in the replies these headers ?
        alt-svc
        alternate-protocol

best regards, Sala



From yvoinov at gmail.com  Thu Dec 31 14:11:03 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 31 Dec 2015 20:11:03 +0600
Subject: [squid-users] youtube video, caching, disabling QUIC
In-Reply-To: <OFAB8639EA.6EC153C3-ONC1257F2C.0048CEDE-C1257F2C.004B8860@asl.bergamo.it>
References: <OFAB8639EA.6EC153C3-ONC1257F2C.0048CEDE-C1257F2C.004B8860@asl.bergamo.it>
Message-ID: <56853777.5030706@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
# Disable alternate protocols
request_header_access Alternate-Protocol deny all
reply_header_access Alternate-Protocol deny all

+ (additional recommended) on network equipment:

! Cisco, for example
 remark Deny alternate protocols
 deny   udp any any eq 80
 deny   udp any any eq 443

31.12.15 19:45, Massimo.Sala at asl.bergamo.it ?????:
> When you request a video on Youtube, its web servers send two new HTTP
> headers to the browser :
>
>         alt-svc
>         alternate-protocol
>
> suggesting to the browser to switch to the new protocol QUIC.
>
>
> Unfortunately
>
> 1) QUIC, working over UDP, is not cacheable by squid 3.4
>
> 2) even if cacheable, IT admins have to upgrade many tools to support and
> account videos over QUIC ( proxy, firewall, bandwidth shaping, etc... )
>
> See :
>         http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol
>
>
> We want to disable QUIC, so the servers and browsers fallbacks to normal
> HTTP for videos.
>
> ---
>
> I asked in another thread
>
>         3) support for Alternate-Protocol HTTP header.
>
>
> Amos' answer :
>
> As for #3, the Alternate-Protocol header patch is just automating these
> squid.conf settings, which you can use explicitly in any Squid version:
>
>   acl AP rep_header_regex Alternate-Protocol .
>   reply_header_access deny AP
>
>
> With that syntax :
>
> squid3 -k reconfigure
>
> 2015/12/31 14:34:21| FATAL: Invalid ACL type 'rep_header_regex'
> FATAL: Bungled /etc/squid3/squid.conf line 43: acl AP rep_header_regex
> alternate-protocol .
> Squid Cache (Version 3.4.8): Terminated abnormally.
> CPU Usage: 0.016 seconds = 0.008 user + 0.008 sys
> Maximum Resident Size: 37936 KB
> Page faults with physical i/o: 0
>
>
>
> Is it rep_header, not rep_header_regex ?
>
> Is it reply_header_access with 3 parameters ?
>
> From
> http://www.squid-cache.org/Versions/v3/3.4/cfgman/reply_header_access.html
>         Usage: reply_header_access header_name allow|deny [!]aclname ...
>
>
> Which is the correct syntax to suppress in the replies these headers ?
>         alt-svc
>         alternate-protocol
>
> best regards, Sala
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWhTd3AAoJENNXIZxhPexGNnMH/0FVWtBmJqQwmuPEaT3ykdgH
7Y6Zcpwdg0JhwTLFPVhV9j95k/bueukzERZwQpwosppqEUhnhVGQx+GzXqhpsM4F
kH88zvu1Jca4Pu63gUqymeISUI36hdQtkuWFx/ZEuzoPIRaqDC7YV1CN4MKW3Jh5
B+o4O8vXCeb82PoKLQCADCVuLKG5W2I5CAswkcbx8YM62f2wYNDIkVuk5UeLcCiL
pC9/doExY3xKI6nuGDhNa9cTe1i6AUNvYM1m6t5VDfvqWjZ2PZQF43+ZNyOGLm/o
HMwx/w36YUQbhKm3ZgyLs3nQPJ+SJVfguJtfNc3yFIxiyzMjHZcDtDRfpGj+nNQ=
=bm4R
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Thu Dec 31 14:12:25 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 31 Dec 2015 20:12:25 +0600
Subject: [squid-users] youtube video, caching, disabling QUIC
In-Reply-To: <OFAB8639EA.6EC153C3-ONC1257F2C.0048CEDE-C1257F2C.004B8860@asl.bergamo.it>
References: <OFAB8639EA.6EC153C3-ONC1257F2C.0048CEDE-C1257F2C.004B8860@asl.bergamo.it>
Message-ID: <568537C9.7050806@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol

31.12.15 19:45, Massimo.Sala at asl.bergamo.it ?????:
> When you request a video on Youtube, its web servers send two new HTTP
> headers to the browser :
>
>         alt-svc
>         alternate-protocol
>
> suggesting to the browser to switch to the new protocol QUIC.
>
>
> Unfortunately
>
> 1) QUIC, working over UDP, is not cacheable by squid 3.4
>
> 2) even if cacheable, IT admins have to upgrade many tools to support and
> account videos over QUIC ( proxy, firewall, bandwidth shaping, etc... )
>
> See :
>         http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol
>
>
> We want to disable QUIC, so the servers and browsers fallbacks to normal
> HTTP for videos.
>
> ---
>
> I asked in another thread
>
>         3) support for Alternate-Protocol HTTP header.
>
>
> Amos' answer :
>
> As for #3, the Alternate-Protocol header patch is just automating these
> squid.conf settings, which you can use explicitly in any Squid version:
>
>   acl AP rep_header_regex Alternate-Protocol .
>   reply_header_access deny AP
>
>
> With that syntax :
>
> squid3 -k reconfigure
>
> 2015/12/31 14:34:21| FATAL: Invalid ACL type 'rep_header_regex'
> FATAL: Bungled /etc/squid3/squid.conf line 43: acl AP rep_header_regex
> alternate-protocol .
> Squid Cache (Version 3.4.8): Terminated abnormally.
> CPU Usage: 0.016 seconds = 0.008 user + 0.008 sys
> Maximum Resident Size: 37936 KB
> Page faults with physical i/o: 0
>
>
>
> Is it rep_header, not rep_header_regex ?
>
> Is it reply_header_access with 3 parameters ?
>
> From
> http://www.squid-cache.org/Versions/v3/3.4/cfgman/reply_header_access.html
>         Usage: reply_header_access header_name allow|deny [!]aclname ...
>
>
> Which is the correct syntax to suppress in the replies these headers ?
>         alt-svc
>         alternate-protocol
>
> best regards, Sala
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJWhTfJAAoJENNXIZxhPexGFGMH/jBda+QNuEBn2bnEu2D2CDDT
LLRgumah8hP9r7rZ2SGgU7iVBGC1SjZTgZbQ1BxoAmbbwoaoFMaoGfAgQ/YONyIi
JzF40OJtWVwt/mRmNYeSRMVekSk4+zS4phDh3lTg9cVQNaaFc0JN4BTuaz3NDZp9
UpAFqkTro/liW7aOisSvEcDk75hrQ7i2X+IHVS5gc2A77F74XOOYmdM26H0L8AuO
QYR/9LXcbR4/oOqLmBDa/3C4+6wmDmKOJiy5A0YWxgSL0rjfxSfAVsEka+P77k9v
/FB28LR9CfZZPhhUQK7yuB0w7rL4MFxJ8ZzckVWWdoPGNEO8acRUPqjgsMwbmp8=
=24YO
-----END PGP SIGNATURE-----



From aashima2madaan at gmail.com  Thu Dec 31 16:02:09 2015
From: aashima2madaan at gmail.com (Aashima)
Date: Thu, 31 Dec 2015 16:02:09 +0000 (UTC)
Subject: [squid-users] Squid proxy removing Transfer-Encoding header
References: <loom.20151230T221825-432@post.gmane.org>
 <56844E5C.5000004@measurement-factory.com>
Message-ID: <loom.20151231T170139-897@post.gmane.org>

Alex Rousskov <rousskov <at> measurement-factory.com> writes:

> 
> On 12/30/2015 02:24 PM, Aashima wrote:
> 
> > So it is like client -> Squid -> APP and return
> >  If App return Transfer-Encoding header to Squid, Squid removes that 
response 
> > header and forwards rest to Client. 
> > 
> > Am not getting why it is removing that header ? Couldnt find any posts
> >  also on any discussion group or blog.
> 
> Transfer-Encoding is a standard HTTP hop-by-hop header. Hop-by-hop
> headers are meant for the immediate recipient (Squid in your case),
> rather than the final or "end" recipient (Client in your case). Squid
> must not forward hop-by-hop headers (but may add them as needed, which
> may look like forwarding to an outside observer).
> 
> If you describe the actual problem you are having (in addition to this
> technical detail), somebody on this list might be able to guide you
> towards a solution.
> 
> Good luck,
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users <at> lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


Hey Alex,

Thanks for responding so quickly on that yesterday. This really helped me in 
reaching to one point for figuring out the real problem.

So in my case, figured out when squid receives request header "Connection: 
close" , it strips of Transfer Encoding header from response. But if it does 
not receive Connection header it wil send back TE header. 

So I am left with 2 questions now. 
- Why does squid behave like that?
- Second, so in my case HA Proxy is sending those headers to squid. Since 
Connection is also hop by hop header , why is HAProxy adding that header to 
request headers.

Thanks
Aashima






From lucascastroborges at gmail.com  Thu Dec 31 17:58:04 2015
From: lucascastroborges at gmail.com (lucas castro)
Date: Thu, 31 Dec 2015 14:58:04 -0300
Subject: [squid-users] squid+ssl and CPU load 100%
Message-ID: <CALyx4TcMODV=4z8iVHSsdjpUTmUX4FQGQfgg8XkjcauN7jMYVw@mail.gmail.com>

I have squid
Squid Cache: Version 3.5.7

I don't know how to ask about this,
But I'm getting 100% load and  squid don't accept connection anymore,
 my cache.log show me this.

2015/12/31 14:27:15.869 kid2| bio.cc(942) parseV3ServerHello: TLS
Extension: 0 of size:0
2015/12/31 14:27:15.869 kid2| bio.cc(942) parseV3ServerHello: TLS
Extension: 0 of size:0
2015/12/31 14:27:15.866 kid1| bio.cc(942) parseV3ServerHello: TLS
Extension: 0 of size:0

Someone has any idea what's happening?
-- 
contatos:
Celular: ( 99 ) 99143-5954 - Vivo
skype: lucasd3castro
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20151231/94e5b260/attachment.htm>

From rousskov at measurement-factory.com  Thu Dec 31 18:00:07 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 31 Dec 2015 11:00:07 -0700
Subject: [squid-users] squid+ssl and CPU load 100%
In-Reply-To: <CALyx4TcMODV=4z8iVHSsdjpUTmUX4FQGQfgg8XkjcauN7jMYVw@mail.gmail.com>
References: <CALyx4TcMODV=4z8iVHSsdjpUTmUX4FQGQfgg8XkjcauN7jMYVw@mail.gmail.com>
Message-ID: <56856D27.2030807@measurement-factory.com>

On 12/31/2015 10:58 AM, lucas castro wrote:
> I have squid
> Squid Cache: Version 3.5.7
> 
> I don't know how to ask about this,
> But I'm getting 100% load and  squid don't accept connection anymore,
>  my cache.log show me this.
> 
> 2015/12/31 14:27:15.869 kid2| bio.cc(942) parseV3ServerHello: TLS
> Extension: 0 of size:0
> 2015/12/31 14:27:15.869 kid2| bio.cc(942) parseV3ServerHello: TLS
> Extension: 0 of size:0
> 2015/12/31 14:27:15.866 kid1| bio.cc(942) parseV3ServerHello: TLS
> Extension: 0 of size:0
> 
> Someone has any idea what's happening?

IIRC, this is an SSL parsing bug in older Squids. Sorry, I do not have a
reference. If you are using SslBump, you should upgrade to the latest
v3.5 (at least).

Alex.



From lucascastroborges at gmail.com  Thu Dec 31 18:06:43 2015
From: lucascastroborges at gmail.com (Lucas Castro)
Date: Thu, 31 Dec 2015 15:06:43 -0300
Subject: [squid-users] squid+ssl and CPU load 100%
In-Reply-To: <56856D27.2030807@measurement-factory.com>
References: <CALyx4TcMODV=4z8iVHSsdjpUTmUX4FQGQfgg8XkjcauN7jMYVw@mail.gmail.com>
 <56856D27.2030807@measurement-factory.com>
Message-ID: <56856EB3.9070104@gmail.com>



On 31-12-2015 15:00, Alex Rousskov wrote:
> On 12/31/2015 10:58 AM, lucas castro wrote:
>> I have squid
>> Squid Cache: Version 3.5.7
>>
>> I don't know how to ask about this,
>> But I'm getting 100% load and  squid don't accept connection anymore,
>>  my cache.log show me this.
>>
>> 2015/12/31 14:27:15.869 kid2| bio.cc(942) parseV3ServerHello: TLS
>> Extension: 0 of size:0
>> 2015/12/31 14:27:15.869 kid2| bio.cc(942) parseV3ServerHello: TLS
>> Extension: 0 of size:0
>> 2015/12/31 14:27:15.866 kid1| bio.cc(942) parseV3ServerHello: TLS
>> Extension: 0 of size:0
>>
>> Someone has any idea what's happening?
> IIRC, this is an SSL parsing bug in older Squids. Sorry, I do not have a
> reference. If you are using SslBump, you should upgrade to the latest
> v3.5 (at least).
>
> Alex.
I'm already using squid 3.5.7.
I'll try to upgrade to 3.5.12.
I was look for this, but didn't find anything,  do you have some link
about this?



