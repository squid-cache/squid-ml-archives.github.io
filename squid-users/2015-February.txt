From Walter.H at mathemainzel.info  Sun Feb  1 17:48:24 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Sun, 01 Feb 2015 18:48:24 +0100
Subject: [squid-users] Strange behaviour with Chrome (client OS = WinXP x64)
	...
Message-ID: <54CE66E8.4010609@mathemainzel.info>

Hello,

can someone please try the following website with Google Chrome - I use 
the latest release: Version 39.0.2171.99 m -

https://banking.ing-diba.at/   (an electronic Banking site)

with the following policy enabled:

RequireOnlineRevocationChecksForLocalAnchors = 1

with this banking site I get the following error from Google Chrome

"Your connection is not private

Attackers might be trying to steal your information from 
banking.ing-diba.at (for example, passwords, messages, or credit cards)."

with the following banking sites of other banks I have no troubles:

https://ebanking.easybank.at/ or
https://banking.raiffeisen.at/

without enabling the policy above or not setting at all, this banking 
site works, but
the symbol it shows differs; it is the same as if a man-in-the-middle 
like SSL-Bump would be between;

Google chrome uses the same cert store as IE, and with IE there is no 
connection problem,
only another thing the banking site is telling: the browser is out 
dated, of course IE 7
the IE even shows a green bar when connecting to this banking site ...

can someone please tell me what is there special with this banking 
site:   https://banking.ing-diba.at/ ?

I'm using SSL bump with the exception of banking sites, the specific 
part of the squid.conf
looks like this:

acl ssl_bump_domains_bankingsites dstdomain banking.raiffeisen.at 
banking.ing-diba.at ebanking.easybank.at services.kepler.at 
www.kepler.at www.rcb.at
acl ssl_bump_domains_msftupdates dstdomain .update.microsoft.com
ssl_bump none ssl_bump_domains_bankingsites
ssl_bump none ssl_bump_domains_msftupdates
ssl_bump server-first all

sslproxy_cert_error allow all
sslproxy_cipher HIGH:MEDIUM:!AECDH:!ADH:!DSS:!SSLv2:+SSLv3:+3DES:!MD5
sslproxy_flags DONT_VERIFY_PEER,NO_DEFAULT_CA
sslproxy_options NO_SSLv2 NO_SSLv3

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/local/squid/ssl_db -M 16MB
sslcrtd_children 8

http_port 3128 ssl-bump generate-host-certificates=on 
dynamic_cert_mem_cache_size=16MB cert=/etc/squid/cert/squid.pem 
options=NO_SSLv2,SINGLE_DH_USE dhparams=/etc/squid/cert/dhparam.pem

# squid.pem contains both cert+key

I'm using my own CA, this means this SSL-bump CA cert is signed by my 
root CA certificate;

what is missing, wrong, ... so that this one banking site will work ...?

the SSL-bump CA certificate contain this:

Authority Information Access:
                 OCSP - URI:#url-to-ocsp#
                 CA Issuers - URI:#url-to-root-cert#

and

  X509v3 CRL Distribution Points:
                 Full Name:
                   URI:#url-to-crl#

everything is working, the OCSP, the root-cert, and the CRL ...

what causes Google Chrome producing the mentioned error above, when 
activating this mentioned policy?

the question to squid specialists: was it a good idea signing the 
SSL-bump CA certificate with the root certificate of my CA?

Thanks

-- 
Best regards,
Walter H.



-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 5971 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150201/8ad5988b/attachment.bin>

From yvoinov at gmail.com  Sun Feb  1 18:16:20 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 02 Feb 2015 00:16:20 +0600
Subject: [squid-users] Strange behaviour with Chrome (client OS = WinXP
 x64) ...
In-Reply-To: <54CE66E8.4010609@mathemainzel.info>
References: <54CE66E8.4010609@mathemainzel.info>
Message-ID: <54CE6D74.6040408@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 

01.02.2015 23:48, Walter H. ?????:
> Hello,
>
> can someone please try the following website with Google Chrome - I
use the latest release: Version 39.0.2171.99 m -
>
> https://banking.ing-diba.at/   (an electronic Banking site)
>
> with the following policy enabled:
>
> RequireOnlineRevocationChecksForLocalAnchors = 1
>
> with this banking site I get the following error from Google Chrome
>
> "Your connection is not private
>
> Attackers might be trying to steal your information from
banking.ing-diba.at (for example, passwords, messages, or credit cards)."
>
> with the following banking sites of other banks I have no troubles:
>
> https://ebanking.easybank.at/ or
> https://banking.raiffeisen.at/
>
> without enabling the policy above or not setting at all, this banking
site works, but
> the symbol it shows differs; it is the same as if a man-in-the-middle
like SSL-Bump would be between;
>
> Google chrome uses the same cert store as IE, and with IE there is no
connection problem,
> only another thing the banking site is telling: the browser is out
dated, of course IE 7
> the IE even shows a green bar when connecting to this banking site ...
>
> can someone please tell me what is there special with this banking
site:   https://banking.ing-diba.at/ ?
>
> I'm using SSL bump with the exception of banking sites, the specific
part of the squid.conf
> looks like this:
>
> acl ssl_bump_domains_bankingsites dstdomain banking.raiffeisen.at
banking.ing-diba.at ebanking.easybank.at services.kepler.at
www.kepler.at www.rcb.at
> acl ssl_bump_domains_msftupdates dstdomain .update.microsoft.com
> ssl_bump none ssl_bump_domains_bankingsites
> ssl_bump none ssl_bump_domains_msftupdates
> ssl_bump server-first all
You do it wrong. You don't know site names BEFORE bump.

Just change acl for banking to dst (ip-based) type and list banking
sites IP.
> sslproxy_cert_error allow all
> sslproxy_cipher HIGH:MEDIUM:!AECDH:!ADH:!DSS:!SSLv2:+SSLv3:+3DES:!MD5
> sslproxy_flags DONT_VERIFY_PEER,NO_DEFAULT_CA
You can remove NO_DEFAULT_CA.
> sslproxy_options NO_SSLv2 NO_SSLv3
>
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/local/squid/ssl_db
-M 16MB
> sslcrtd_children 8
>
> http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=16MB cert=/etc/squid/cert/squid.pem
options=NO_SSLv2,SINGLE_DH_USE dhparams=/etc/squid/cert/dhparam.pem
Add capath parameter to your ssl-bump port. How you want to bump without
CA's public keys?
>
> # squid.pem contains both cert+key
>
> I'm using my own CA, this means this SSL-bump CA cert is signed by my
root CA certificate;
>
> what is missing, wrong, ... so that this one banking site will work ...?
>
> the SSL-bump CA certificate contain this:
>
> Authority Information Access:
>                 OCSP - URI:#url-to-ocsp#
>                 CA Issuers - URI:#url-to-root-cert#
>
> and
>
>  X509v3 CRL Distribution Points:
>                 Full Name:
>                   URI:#url-to-crl#
>
> everything is working, the OCSP, the root-cert, and the CRL ...
>
> what causes Google Chrome producing the mentioned error above, when
activating this mentioned policy?
>
> the question to squid specialists: was it a good idea signing the
SSL-bump CA certificate with the root certificate of my CA?
No. But you can ask him. :) Tell us what he says. ;)

NP. In two words: You want to be RA. I.e., you can sign your signed (by
CA) root CA anything as trusted authority. Without actually being a
trusted RA
>
> Thanks
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUzm1zAAoJENNXIZxhPexG0tgH/0PC7+RdzNml58s6vDl9eL8N
DeJuCjTkLUp2ZUXiFCOQ7S24VqfcegHUdnlin6Eghg5ksbHGFxQGEhRJbHr+HoWj
MXs4FKAv+i8SKSlFWtSTCZWNoOc3dLPYOetLHUmbF/RE6ymSUM+M8IVGpi/5r+I3
j8U+mCP58p6oBQ0iJykH85EB7IjS/U9Sx7L+tBsTiAqAuisC2yS0UqLwchVM+zeB
uf+YJSOZu3fzg+8ZutpVdwlKfdpQpC5mFKMscQ9v1A5D1cOcrPesiHfRod5XKA/Y
tLzDT/8jdkpBVb98GwfAbBh6cyfCRTey5aPIu3WopTh6SSi4vvqvuacLPFORCe0=
=Pqdl
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150202/c58b8200/attachment.htm>

From squid3 at treenet.co.nz  Sun Feb  1 18:46:03 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 02 Feb 2015 07:46:03 +1300
Subject: [squid-users] Strange behaviour with Chrome (client OS = WinXP
 x64) ...
In-Reply-To: <54CE6D74.6040408@gmail.com>
References: <54CE66E8.4010609@mathemainzel.info> <54CE6D74.6040408@gmail.com>
Message-ID: <54CE746B.3050603@treenet.co.nz>

On 2/02/2015 7:16 a.m., Yuri Voinov wrote:
> 
> 
> 01.02.2015 23:48, Walter H. ?????:
>> Hello,
> 
<snip>

>> acl ssl_bump_domains_bankingsites dstdomain banking.raiffeisen.at
> banking.ing-diba.at ebanking.easybank.at services.kepler.at
> www.kepler.at www.rcb.at
>> acl ssl_bump_domains_msftupdates dstdomain .update.microsoft.com
>> ssl_bump none ssl_bump_domains_bankingsites
>> ssl_bump none ssl_bump_domains_msftupdates
>> ssl_bump server-first all
> You do it wrong. You don't know site names BEFORE bump.
> 

No. His http_port settings are those which match a proxy being
configured explicitly in the brower, which means CONNECT messages with
domain name expected to be present.

It might not be, which could be the problem. But that can only known by
looking at the CONNECT request message itself.

Amos


From yvoinov at gmail.com  Sun Feb  1 18:50:32 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 02 Feb 2015 00:50:32 +0600
Subject: [squid-users] Strange behaviour with Chrome (client OS = WinXP
 x64) ...
In-Reply-To: <54CE746B.3050603@treenet.co.nz>
References: <54CE66E8.4010609@mathemainzel.info> <54CE6D74.6040408@gmail.com>
 <54CE746B.3050603@treenet.co.nz>
Message-ID: <54CE7578.8020802@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 

02.02.2015 0:46, Amos Jeffries ?????:
> On 2/02/2015 7:16 a.m., Yuri Voinov wrote:
>>
>>
>> 01.02.2015 23:48, Walter H. ?????:
>>> Hello,
>>
> <snip>
>
>>> acl ssl_bump_domains_bankingsites dstdomain banking.raiffeisen.at
>> banking.ing-diba.at ebanking.easybank.at services.kepler.at
>> www.kepler.at www.rcb.at
>>> acl ssl_bump_domains_msftupdates dstdomain .update.microsoft.com
>>> ssl_bump none ssl_bump_domains_bankingsites
>>> ssl_bump none ssl_bump_domains_msftupdates
>>> ssl_bump server-first all
>> You do it wrong. You don't know site names BEFORE bump.
>>
>
> No. His http_port settings are those which match a proxy being
> configured explicitly in the brower, which means CONNECT messages with
> domain name expected to be present.
Oh, of course. I compare it with my interception configuration. :)
But ip-based dst acl for bankings will works in any case. Just
pass-through banking IP without bump - and, viola! - they works.
Yes?

>
>
> It might not be, which could be the problem. But that can only known by
> looking at the CONNECT request message itself.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUznV4AAoJENNXIZxhPexGOuIIAIcq7xXlBk5UJ2cNkglcWH9s
xwCYgpH7VyiG6z9rZk4BFOvOqmIPiCIx9izzgXkK5QssKgeCBB4fXt/bOnM3WDBO
qEyA+awbMCfkPQExWd6LSNhDEqPAdhkUHnRmK+tKmhGPaipqJUsm5UH9cBTO2VdK
ARrsfu/HR+DluwhUdE5Zem81H27iQmClD7NCrFiFsrDEAcMEDueVvKjYYUuYGwor
f81lMcj2ZpnEF8Ogyo7mZOmIR3+nRlzJLLvpm0wIerFzfPOkZKqCtV9GQezlkKYf
NStXj2ei33ZwwP/QGiv4SmjBQrTU6hRIZNuPk5B1yjkXyzEVpYfhW5xGT3fzKbU=
=2JZO
-----END PGP SIGNATURE-----



From Walter.H at mathemainzel.info  Sun Feb  1 19:26:32 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Sun, 01 Feb 2015 20:26:32 +0100
Subject: [squid-users] Strange behaviour with Chrome (client OS = WinXP
 x64) ...
In-Reply-To: <54CE7578.8020802@gmail.com>
References: <54CE66E8.4010609@mathemainzel.info> <54CE6D74.6040408@gmail.com>
 <54CE746B.3050603@treenet.co.nz> <54CE7578.8020802@gmail.com>
Message-ID: <54CE7DE8.5020709@mathemainzel.info>

On 01.02.2015 19:50, Yuri Voinov wrote:
> 02.02.2015 0:46, Amos Jeffries ?????:
>> On 2/02/2015 7:16 a.m., Yuri Voinov wrote:
>>> 01.02.2015 23:48, Walter H. ?????:
>>>> Hello,
>> <snip>
>>>> acl ssl_bump_domains_bankingsites dstdomain banking.raiffeisen.at
>>> banking.ing-diba.at ebanking.easybank.at services.kepler.at
>>> www.kepler.at www.rcb.at
>>>> acl ssl_bump_domains_msftupdates dstdomain .update.microsoft.com
>>>> ssl_bump none ssl_bump_domains_bankingsites
>>>> ssl_bump none ssl_bump_domains_msftupdates
>>>> ssl_bump server-first all
>>> You do it wrong. You don't know site names BEFORE bump.
>> No. His http_port settings are those which match a proxy being
>> configured explicitly in the brower, which means CONNECT messages with
>> domain name expected to be present.
> Oh, of course. I compare it with my interception configuration. :)
> But ip-based dst acl for bankings will works in any case. Just
> pass-through banking IP without bump - and, viola! - they works.
> Yes?
>
I have a few more lines before ssl-bump server-first all in my squid.conf

acl ssl_bump_domains_none_list dstdomain 
"/etc/squid/sslbumpnonedomains-list-acl.squid"
acl ssl_bump_domains_none_regex dstdom_regex -i 
"/etc/squid/sslbumpnonedomains-regex-acl.squid"
acl ssl_bump_domains_clntfrst_list dstdomain 
"/etc/squid/sslbumpclntfrstdomains-list-acl.squid"
acl ssl_bump_domains_clntfrst_regex dstdom_regex -i 
"/etc/squid/sslbumpclntfrstdomains-regex-acl.squid"
ssl_bump none ssl_bump_domains_none_list
ssl_bump none ssl_bump_domains_none_regex
ssl_bump client-first ssl_bump_domains_clntfrst_list
ssl_bump client-first ssl_bump_domains_clntfrst_regex

and any host in one of these files is either not bumped or bumped with 
client-first - google's domains are the FF problem, this is the workaround

>>
>> It might not be, which could be the problem. But that can only known by
>> looking at the CONNECT request message itself.
>>
>> Amos
attached is the certificate chain the is shown in Google Chrome of this 
banking site, that makes problems ...
by the way, without squid it is the same ..., why?
what goes wrong?

the reason why not bumping banking sites is the following:
I have a VM that is used only for electronic banking, and there I didn't 
install my CAs root and the SSL-bump CA certificate;
so any SSL site that has nothing to do with banking will not work, and 
that should it be;

Greetings,
Walter
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: certs.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150201/6c505957/attachment.txt>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 5971 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150201/6c505957/attachment.bin>

From yvoinov at gmail.com  Sun Feb  1 19:30:41 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 02 Feb 2015 01:30:41 +0600
Subject: [squid-users] Strange behaviour with Chrome (client OS = WinXP
 x64) ...
In-Reply-To: <54CE7DE8.5020709@mathemainzel.info>
References: <54CE66E8.4010609@mathemainzel.info> <54CE6D74.6040408@gmail.com>
 <54CE746B.3050603@treenet.co.nz> <54CE7578.8020802@gmail.com>
 <54CE7DE8.5020709@mathemainzel.info>
Message-ID: <54CE7EE1.4030101@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 

02.02.2015 1:26, Walter H. ?????:
> On 01.02.2015 19:50, Yuri Voinov wrote:
>> 02.02.2015 0:46, Amos Jeffries ?????:
>>> On 2/02/2015 7:16 a.m., Yuri Voinov wrote:
>>>> 01.02.2015 23:48, Walter H. ?????:
>>>>> Hello,
>>> <snip>
>>>>> acl ssl_bump_domains_bankingsites dstdomain banking.raiffeisen.at
>>>> banking.ing-diba.at ebanking.easybank.at services.kepler.at
>>>> www.kepler.at www.rcb.at
>>>>> acl ssl_bump_domains_msftupdates dstdomain .update.microsoft.com
>>>>> ssl_bump none ssl_bump_domains_bankingsites
>>>>> ssl_bump none ssl_bump_domains_msftupdates
>>>>> ssl_bump server-first all
>>>> You do it wrong. You don't know site names BEFORE bump.
>>> No. His http_port settings are those which match a proxy being
>>> configured explicitly in the brower, which means CONNECT messages with
>>> domain name expected to be present.
>> Oh, of course. I compare it with my interception configuration. :)
>> But ip-based dst acl for bankings will works in any case. Just
>> pass-through banking IP without bump - and, viola! - they works.
>> Yes?
>>
> I have a few more lines before ssl-bump server-first all in my squid.conf
>
> acl ssl_bump_domains_none_list dstdomain
"/etc/squid/sslbumpnonedomains-list-acl.squid"
> acl ssl_bump_domains_none_regex dstdom_regex -i
"/etc/squid/sslbumpnonedomains-regex-acl.squid"
> acl ssl_bump_domains_clntfrst_list dstdomain
"/etc/squid/sslbumpclntfrstdomains-list-acl.squid"
> acl ssl_bump_domains_clntfrst_regex dstdom_regex -i
"/etc/squid/sslbumpclntfrstdomains-regex-acl.squid"
> ssl_bump none ssl_bump_domains_none_list
> ssl_bump none ssl_bump_domains_none_regex
> ssl_bump client-first ssl_bump_domains_clntfrst_list
> ssl_bump client-first ssl_bump_domains_clntfrst_regex
>
> and any host in one of these files is either not bumped or bumped with
client-first - google's domains are the FF problem, this is the workaround
Google domains not problem. For me. I have all root and intermediate
CA's and specify it to Squid when bumping. So, in my installation Google
domains bumps as usual.

>
>>>
>>> It might not be, which could be the problem. But that can only known by
>>> looking at the CONNECT request message itself.
>>>
>>> Amos
> attached is the certificate chain the is shown in Google Chrome of
this banking site, that makes problems ...
> by the way, without squid it is the same ..., why?
> what goes wrong?
>
> the reason why not bumping banking sites is the following:
> I have a VM that is used only for electronic banking, and there I
didn't install my CAs root and the SSL-bump CA certificate;
> so any SSL site that has nothing to do with banking will not work, and
that should it be;
Just dig it IP's and pass by IP with dst acl. This will works.
>
> Greetings,
> Walter

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUzn7hAAoJENNXIZxhPexGqaAIAIyeBG8FbdihhsnLnOR6O7Rn
L+beP87cKKunKk+pE4CwusNFDuyk62k0wW3dnpj0pbJ2xe12hizJArcDQ+yFMfsD
oMUM9/wJBdwbwCnrXoVqVTuHXonxlsyU9F3Kv/t7mONquF8Qt0oRPhi6PdHj0EDo
zO4OWb0Jm7R0CN1PhAKYe8Ng6RyG94ojM2w5WNuS05yY2xF/UHSbx2NRfD58bOO8
VwB/DBKpGXO11j+2JitPOFLLPFndIJTCFMjk+e/R5XkujA2ngEXBJ24lL6eQbU9K
+jFzrlVkcWryIPmtENVhZqdU/X2zkIsn6VhzunMmrN75oGJYH3cthw3e1k3WoKs=
=e+ao
-----END PGP SIGNATURE-----



From squid at proxyplayer.co.uk  Sun Feb  1 20:49:59 2015
From: squid at proxyplayer.co.uk (squid at proxyplayer.co.uk)
Date: Sun, 01 Feb 2015 20:49:59 +0000
Subject: [squid-users] google always requesting captach through
 transparent proxy
In-Reply-To: <20150119033045.199712tcod5b9mqu@webmail-srv2.servage.net>
References: <54BB1387.7070800@trimble.com>
 <1421552897374.380d3f1c@Nodemailer> <54BB9223.50406@treenet.co.nz>
 <20150118143903.2020441id44pq553@webmail-srv2.servage.net>
 <54BBC7D5.8040508@treenet.co.nz>
 <20150119033045.199712tcod5b9mqu@webmail-srv2.servage.net>
Message-ID: <20150201204959.88433rqcththfipj@webmail-srv2.servage.net>

>> On 19/01/2015 3:39 a.m., squid at proxyplayer.co.uk wrote:
>>> Google is requesting a captcha everytime I request a page as it is
>>> saying that my computer is doing something weird (via a proxy).
>>
>> What *exactly* is it saying?
>>
>
Your systems have detected unusual traffic from your computer network.
Some computers it presents a captcha, on others it just plain refuses
to show search results.
>>>
>>> How can I get rid of this message from Google. I tried redirecting
>>> directly but it makes no difference. It seems like Google is
>>> pickingup a lack of headers as an issue.
>>
>> acl google dstdom_regex -i google
>> http_access deny google
>>
>> but I suspect maybe you might not actually like the results of what
>> you are asking for.
>
What's the best directive to use to make sure that google doesn't go
through the proxy at all?
acl google dstdom_regex -i google
?




From yvoinov at gmail.com  Sun Feb  1 21:01:15 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 02 Feb 2015 03:01:15 +0600
Subject: [squid-users] google always requesting captach through
 transparent proxy
In-Reply-To: <20150201204959.88433rqcththfipj@webmail-srv2.servage.net>
References: <54BB1387.7070800@trimble.com> <1421552897374.380d3f1c@Nodemailer>
 <54BB9223.50406@treenet.co.nz>
 <20150118143903.2020441id44pq553@webmail-srv2.servage.net>
 <54BBC7D5.8040508@treenet.co.nz>
 <20150119033045.199712tcod5b9mqu@webmail-srv2.servage.net>
 <20150201204959.88433rqcththfipj@webmail-srv2.servage.net>
Message-ID: <54CE941B.90200@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 

02.02.2015 2:49, squid at proxyplayer.co.uk ?????:
>>> On 19/01/2015 3:39 a.m., squid at proxyplayer.co.uk wrote:
>>>> Google is requesting a captcha everytime I request a page as it is
>>>> saying that my computer is doing something weird (via a proxy).
>>>
>>> What *exactly* is it saying?
>>>
>>
> Your systems have detected unusual traffic from your computer network.
> Some computers it presents a captcha, on others it just plain refuses
> to show search results.

First. You have parasitic traffic from your LAN. Not from proxy.
Second. You can make HTTP-headers modifications on your proxy. In some
cases it can cause similar problems.

NP. I use transparent proxy in my infrastructure over 4 years, and seen
this problem just once. When one PC in LAN was infected with a virus.

>>>>
>>>> How can I get rid of this message from Google. I tried redirecting
>>>> directly but it makes no difference. It seems like Google is
>>>> pickingup a lack of headers as an issue.
>>>
>>> acl google dstdom_regex -i google
>>> http_access deny google
>>>
>>> but I suspect maybe you might not actually like the results of what
>>> you are asking for.
>>
> What's the best directive to use to make sure that google doesn't go
> through the proxy at all?
> acl google dstdom_regex -i google
> ?
Don't think so. Google uses not only one domain. What about youtube,
blogger.com, googleapis, gstatic etc.etc.? Also - what about it's HTTPS
versions?
The best way (and forget to traffic economy, os course) - identify all
google IP-ranges and bypass it by ACL on Cisco, for example. Completely.
But why would you do need cash?

>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUzpQbAAoJENNXIZxhPexGDL4IAKXD9qE174WOYZNsEtuPe+Y0
nRJg/vHIYT6Wefd7vYqcM+AxIU0iTn+TPcy7IvUP9YpPtcDX9rRgLYPWjeC5z8aB
o0LtxbQvPlw68kvr+idCL5dafHD6ujYBOx8l6jPat2Ny2jf8t/oR4MuklPkoRkYo
o+peiHwhDY8MjT7sy7uXaFvVeNX0r7Xk54jM5kfna2F7IBI5c/6kbm9u4jPVjXYu
Eci0CBqUqnXerQVH7GKP9UYlMPZ+BR4jXMgUS+xz1zqsHqOg9CJeLLmXxpKmMXZn
bAcA79ZD3Bjnumg2z1HrOGzRO9caDDW90DrSwhi04aPA2z8mCa+8tx9zejyRkbE=
=vqeY
-----END PGP SIGNATURE-----




From yvoinov at gmail.com  Sun Feb  1 21:09:27 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 02 Feb 2015 03:09:27 +0600
Subject: [squid-users] google always requesting captach through
 transparent proxy
In-Reply-To: <20150201204959.88433rqcththfipj@webmail-srv2.servage.net>
References: <54BB1387.7070800@trimble.com> <1421552897374.380d3f1c@Nodemailer>
 <54BB9223.50406@treenet.co.nz>
 <20150118143903.2020441id44pq553@webmail-srv2.servage.net>
 <54BBC7D5.8040508@treenet.co.nz>
 <20150119033045.199712tcod5b9mqu@webmail-srv2.servage.net>
 <20150201204959.88433rqcththfipj@webmail-srv2.servage.net>
Message-ID: <54CE9607.8020702@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Oh,

forgot yet another reason.

Too agressive cache settings can lead this problem too.


02.02.2015 2:49, squid at proxyplayer.co.uk ?????:
>>> On 19/01/2015 3:39 a.m., squid at proxyplayer.co.uk wrote:
>>>> Google is requesting a captcha everytime I request a page as it is
>>>> saying that my computer is doing something weird (via a proxy).
>>>
>>> What *exactly* is it saying?
>>>
>>
> Your systems have detected unusual traffic from your computer network.
> Some computers it presents a captcha, on others it just plain refuses
> to show search results.
>>>>
>>>> How can I get rid of this message from Google. I tried redirecting
>>>> directly but it makes no difference. It seems like Google is
>>>> pickingup a lack of headers as an issue.
>>>
>>> acl google dstdom_regex -i google
>>> http_access deny google
>>>
>>> but I suspect maybe you might not actually like the results of what
>>> you are asking for.
>>
> What's the best directive to use to make sure that google doesn't go
> through the proxy at all?
> acl google dstdom_regex -i google
> ?
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUzpYGAAoJENNXIZxhPexGmFcH/3SXmc2SpoLAB9Btqz9xHuiX
swyKqkcb+FvFMjLtdyKklXH6edOpMKImfUjcsUBszyduHyO/7+11Mv9Ugc/R1X6T
mPeaUGyO9MBNebA31JsvkNIX99LEx9Circ4sevd4ynNyPsUY9yevzA1fWvhw1cU1
Sn/6xBwYbB7e1ORh428TsTjGut9pd+P4Ndv1hU9z+OJDGmUAujQBDjihgqoWrmtg
X4xVu4hXh26wDnC3bJnv+/2R5DXg9oc3SkU0grThxm5gAB2TdigaO1ivgc3+8iLs
Ukqoeov9WcAjn0ptB4zTaletDheWWnb7VvsdNnTtUsS6S48mnLuQRe4B0IJZUt8=
=nLrS
-----END PGP SIGNATURE-----



From dan at getbusi.com  Sun Feb  1 23:14:45 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Mon, 2 Feb 2015 10:14:45 +1100
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
Message-ID: <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>

Bumping this one for the new year 'cause I still don't understand squid
traces and because it's still happening with v3.4.11.

I would speculate that's it's something to do with the External ACLs
(there's a bunch). Let me know if a more recent traceback (than those
earlier in the thread) would help.

On 2 February 2015 at 10:14, Dan Charlesworth <dan at getbusi.com> wrote:

> Bumping this one for the new year 'cause I still don't understand squid
> traces and because it's still happening with v3.4.11.
>
> I would speculate that's it's something to do with the External ACLs
> (there's a bunch). Let me know if a more recent traceback (than those
> earlier in the thread) would help.
>
> On 13 November 2014 at 16:02, <dan at getbusi.com> wrote:
>
>> Oh sure, sorry:
>>
>>  Squid Cache: Version 3.4.8
>> configure options:  '--build=x86_64-redhat-linux-gnu'
>> '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu'
>> '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr'
>> '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc'
>> '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64'
>> '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib'
>> '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--exec_prefix=/usr'
>> '--libexecdir=/usr/lib64/squid' '--localstatedir=/var'
>> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
>> '--with-logdir=$(localstatedir)/log/squid'
>> '--with-pidfile=$(localstatedir)/run/squid.pid'
>> '--disable-dependency-tracking' '--enable-follow-x-forwarded-for'
>> '--enable-auth'
>> '--enable-auth-basic=DB,LDAP,MSNT,MSNT-multi-domain,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam'
>> '--enable-auth-ntlm=smb_lm,fake'
>> '--enable-auth-digest=file,LDAP,eDirectory'
>> '--enable-auth-negotiate=kerberos,wrapper'
>> '--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,AD_group,session'
>> '--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
>> '--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
>> '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-referer-log'
>> '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl'
>> '--enable-ssl-crtd' '--enable-storeio=aufs,diskd,ufs'
>> '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' '--with-aio'
>> '--with-default-user=squid' '--with-filedescriptors=16384'
>> '--with-maxfd=65535' '--with-dl' '--with-openssl' '--with-pthreads'
>> '--with-included-ltdl' 'build_alias=x86_64-redhat-linux-gnu'
>> 'host_alias=x86_64-redhat-linux-gnu' 'target_alias=x86_64-redhat-linux-gnu'
>> 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
>> -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic'
>> 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
>> -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fPIC'
>> 'PKG_CONFIG_PATH=/usr/lib64/pkgconfig:/usr/share/pkgconfig'
>> --enable-ltdl-convenience
>>
>>
>>
>>
>>
>> On Thu, Nov 13, 2014 at 4:01 PM, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>> On 7/11/2014 12:25 p.m., dan wrote:
>>> > Bumping this with another backtrace. Happened at 16:05 this time,
>>> > when the system was not very very busy.
>>> >
>>> > It?s causing squid to crash in such a way that I actually have to
>>> > `kill -9` the process in order to get things restarted properly.
>>> >
>>> > Would really appreciate any feedback at all from anyone who can
>>> > understand these back traces.
>>>
>>>
>>> Any hints, like what release version of Squid you are using?
>>>
>>> Amos
>>>
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v2.0.22 (MingW32)
>>>
>>> iQEcBAEBAgAGBQJUZDr6AAoJELJo5wb/XPRjxL8H/iQO8pG5twVV2lcXxlFEgLuE
>>> NR0c4ezkPOiwgM3iHzrVxcDtCRLHB2YrwT9GuapslmSkcTOP6sBKxekOHsZmWtlK
>>> Sd8A/jK6l/GXFqPpdUHjut6g1aEUwTfJxsRr2NxtMW2f7a91qyOE9f31WYKQq73m
>>> odjtt6ayc+yA2jMEfHaIHaqXhIzAxV21ipN8GH5CWhrfMfo6IxpP4326z8SMa1am
>>> 6HXJQhTkt1qqV4jCjGdYQ4BkAZygBtsHNb2AKgJ5Wmb4OCsM4MZlbIiPmWqWWCfY
>>> 8ccyLVvodfpPVtjCBgStcJTkWxamu6BaHNhy8qCV03zAa4faxqcYVwAvSA5Q2sg=
>>> =tHfy
>>> -----END PGP SIGNATURE-----
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150202/6f4eb320/attachment.htm>

From eliezer at ngtech.co.il  Mon Feb  2 00:35:48 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 02 Feb 2015 02:35:48 +0200
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
Message-ID: <54CEC664.8020407@ngtech.co.il>

Hey Dan,

Just to get around the environment, can you share your 
squid.conf?(censuring confidential data)

Thanks,
Eliezer

On 02/02/2015 01:14, Dan Charlesworth wrote:
> Bumping this one for the new year 'cause I still don't understand squid
> traces and because it's still happening with v3.4.11.
>
> I would speculate that's it's something to do with the External ACLs
> (there's a bunch). Let me know if a more recent traceback (than those
> earlier in the thread) would help.




From mkraju123 at gmail.com  Mon Feb  2 04:27:12 2015
From: mkraju123 at gmail.com (Raju M K)
Date: Mon, 2 Feb 2015 09:57:12 +0530
Subject: [squid-users] Squid Authentication
Message-ID: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>

Need squid Authentication syntax for local users in Windows 7/8 workgroup
Presently using squid 2.7 stable 8
-- 
Regards,
M K Raju.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150202/8baea211/attachment.htm>

From yvoinov at gmail.com  Mon Feb  2 08:17:02 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 02 Feb 2015 14:17:02 +0600
Subject: [squid-users] Squid Authentication
In-Reply-To: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>
References: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>
Message-ID: <54CF327E.5000505@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
http://wiki.squid-cache.org/ConfigExamples#Authentication

02.02.2015 10:27, Raju M K ?????:
> Need squid Authentication syntax for local users in Windows 7/8 workgroup
> Presently using squid 2.7 stable 8
> --
> Regards,
> M K Raju.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUzzJ9AAoJENNXIZxhPexG+B8IAIEDYm0vOJarqT/VfM27jiHX
l7wWDDfb+Gt3mWKMNQLMPzLYhgCgNq7mnJ4uWUgsha/H2X2MlIrFTgrz4TMo9ygY
gftHXFXsde9YqyA0xVHib0B4BD5heE7iuZcFCM1Nqm5L4y6wDeDnpo47jIdcMMGJ
qap+8Jj8iwJ2t3UMkwIAfiONWiyhRz8lKT7F1Z0J2KJfnpgXKSwZyxEskUxdDwhV
hus5oWbxYCw3fSxXjc3oAL37mgM0JSu/+5qcN7YXACQF/I95ekkpHrbDWzTNZxMn
D1W0cRn5VhOwZgWUG2JTEjlER70uEiEyYhvf9u9QgPjoEbR8kJd/f3mOWh7TUkE=
=ztq/
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150202/8a04d6d9/attachment.htm>

From eliezer at ngtech.co.il  Mon Feb  2 09:20:04 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 02 Feb 2015 11:20:04 +0200
Subject: [squid-users] Squid Authentication
In-Reply-To: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>
References: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>
Message-ID: <54CF4144.2050005@ngtech.co.il>

Hey Raju,

For how many users?

Eliezer

On 02/02/2015 06:27, Raju M K wrote:
> Need squid Authentication syntax for local users in Windows 7/8 workgroup
> Presently using squid 2.7 stable 8
> -- Regards, M K Raju.




From squid3 at treenet.co.nz  Mon Feb  2 09:54:42 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 02 Feb 2015 22:54:42 +1300
Subject: [squid-users] Squid Authentication
In-Reply-To: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>
References: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>
Message-ID: <54CF4962.7020202@treenet.co.nz>

On 2/02/2015 5:27 p.m., Raju M K wrote:
> Need squid Authentication syntax for local users in Windows 7/8 workgroup
> Presently using squid 2.7 stable 8

2.7 was end-of-lifed *5 years ago*. Please upgrade.
http://www.squid-cache.org/Versions/

PS. I know we dont have a native windows version available of anything
newer (though Cygwin does provide 3.2/3.3 builds). But there is no
reason for Squid being tied down onto a Windows server while servicing
Windows users, and many reasons for it to *not* be.

Amos



From steve at opendium.com  Mon Feb  2 12:09:12 2015
From: steve at opendium.com (Steve Hill)
Date: Mon, 02 Feb 2015 12:09:12 +0000
Subject: [squid-users] ssl-bump doesn't like valid web server
In-Reply-To: <54C0B152.3@treenet.co.nz>
References: <54BF65E7.2080708@trimble.com> <54BF6F98.7010302@opendium.com>
 <54BFF278.7080007@ngtech.co.il> <54C0A4A5.5060607@opendium.com>
 <54C0B152.3@treenet.co.nz>
Message-ID: <54CF68E8.70606@opendium.com>

On 22.01.15 08:14, Amos Jeffries wrote:

> Squid only *generates* server certificates using that helper. If you
> are seeing the log lines "Generating SSL certificate" they are
> incorrect when not using the helper.
>
> The non-helper bumping is limited to using the configured http(s)_port
> cert= and key= contents. In essence only doing client-first or
> peek+splice SSL-bumping styles.

I'm pretty sure this is incorrect - I'm running Squid 3.4 without 
ssl_crtd, configured to bump server-first.  The cert= parameter to the 
http_port line points at a CA certificate.  When visiting an https site 
through the proxy, the certificate sent to the browser is a forged 
version of the server's certificate, signed by the cert= CA.  This 
definitely seems to be server-first bumping - if the server's CA is 
unknown, Squid generates an appropriately broken certificate, etc. as 
you would expect.

Am I missing something?

-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Direct contacts:
    Instant messager: xmpp:steve at opendium.com
    Email:            steve at opendium.com
    Phone:            sip:steve at opendium.com

Sales / enquiries contacts:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support contacts:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From eliezer at ngtech.co.il  Mon Feb  2 13:23:33 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 02 Feb 2015 15:23:33 +0200
Subject: [squid-users] ssl-bump doesn't like valid web server
In-Reply-To: <54CF68E8.70606@opendium.com>
References: <54BF65E7.2080708@trimble.com> <54BF6F98.7010302@opendium.com>
 <54BFF278.7080007@ngtech.co.il> <54C0A4A5.5060607@opendium.com>
 <54C0B152.3@treenet.co.nz> <54CF68E8.70606@opendium.com>
Message-ID: <54CF7A55.3030003@ngtech.co.il>

Hey Steve,

On what OS are you running squid? is it self compiled one?

Eliezer

On 02/02/2015 14:09, Steve Hill wrote:
>
> I'm pretty sure this is incorrect - I'm running Squid 3.4 without
> ssl_crtd, configured to bump server-first.  The cert= parameter to the
> http_port line points at a CA certificate.  When visiting an https site
> through the proxy, the certificate sent to the browser is a forged
> version of the server's certificate, signed by the cert= CA.  This
> definitely seems to be server-first bumping - if the server's CA is
> unknown, Squid generates an appropriately broken certificate, etc. as
> you would expect.
>
> Am I missing something?




From rafael.akchurin at diladele.com  Mon Feb  2 14:04:56 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 2 Feb 2015 14:04:56 +0000
Subject: [squid-users] Squid Authentication
In-Reply-To: <54CF4962.7020202@treenet.co.nz>
References: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>,
 <54CF4962.7020202@treenet.co.nz>
Message-ID: <1422885907362.27721@diladele.com>

Hello Amos,

We will soon be able to have latest 3.5 built for Cygwin x64 (hopefully).

Rafael

________________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Sent: Monday, February 2, 2015 10:54 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Authentication

On 2/02/2015 5:27 p.m., Raju M K wrote:
> Need squid Authentication syntax for local users in Windows 7/8 workgroup
> Presently using squid 2.7 stable 8

2.7 was end-of-lifed *5 years ago*. Please upgrade.
http://www.squid-cache.org/Versions/

PS. I know we dont have a native windows version available of anything
newer (though Cygwin does provide 3.2/3.3 builds). But there is no
reason for Squid being tied down onto a Windows server while servicing
Windows users, and many reasons for it to *not* be.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Mon Feb  2 14:32:02 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 03 Feb 2015 03:32:02 +1300
Subject: [squid-users] Squid Authentication
In-Reply-To: <1422885907362.27721@diladele.com>
References: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>,
 <54CF4962.7020202@treenet.co.nz> <1422885907362.27721@diladele.com>
Message-ID: <54CF8A62.3040605@treenet.co.nz>

On 3/02/2015 3:04 a.m., Rafael Akchurin wrote:
> Hello Amos,
> 
> We will soon be able to have latest 3.5 built for Cygwin x64 (hopefully).
> 

Yay! Are there any patches I can merge that will help minimize the
tracking work for future releases?

Amos


> Rafael
> 
> ________________________________________
> From: Amos Jeffries
> 
> On 2/02/2015 5:27 p.m., Raju M K wrote:
>> Need squid Authentication syntax for local users in Windows 7/8 workgroup
>> Presently using squid 2.7 stable 8
> 
> 2.7 was end-of-lifed *5 years ago*. Please upgrade.
> http://www.squid-cache.org/Versions/
> 
> PS. I know we dont have a native windows version available of anything
> newer (though Cygwin does provide 3.2/3.3 builds). But there is no
> reason for Squid being tied down onto a Windows server while servicing
> Windows users, and many reasons for it to *not* be.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From rafael.akchurin at diladele.com  Mon Feb  2 14:47:50 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 2 Feb 2015 14:47:50 +0000
Subject: [squid-users] Squid Authentication
In-Reply-To: <54CF8A62.3040605@treenet.co.nz>
References: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>,
 <54CF4962.7020202@treenet.co.nz>
 <1422885907362.27721@diladele.com>,<54CF8A62.3040605@treenet.co.nz>
Message-ID: <1422888481228.45205@diladele.com>

Eldar will send soon as we finish some initial testing.
Raf


________________________________________
From: Amos Jeffries <squid3 at treenet.co.nz>
Sent: Monday, February 2, 2015 3:32 PM
To: Rafael Akchurin; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Authentication

On 3/02/2015 3:04 a.m., Rafael Akchurin wrote:
> Hello Amos,
>
> We will soon be able to have latest 3.5 built for Cygwin x64 (hopefully).
>

Yay! Are there any patches I can merge that will help minimize the
tracking work for future releases?

Amos


> Rafael
>
> ________________________________________
> From: Amos Jeffries
>
> On 2/02/2015 5:27 p.m., Raju M K wrote:
>> Need squid Authentication syntax for local users in Windows 7/8 workgroup
>> Presently using squid 2.7 stable 8
>
> 2.7 was end-of-lifed *5 years ago*. Please upgrade.
> http://www.squid-cache.org/Versions/
>
> PS. I know we dont have a native windows version available of anything
> newer (though Cygwin does provide 3.2/3.3 builds). But there is no
> reason for Squid being tied down onto a Windows server while servicing
> Windows users, and many reasons for it to *not* be.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From yvoinov at gmail.com  Mon Feb  2 16:17:04 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 02 Feb 2015 22:17:04 +0600
Subject: [squid-users] Squid Authentication
In-Reply-To: <1422888481228.45205@diladele.com>
References: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>,
 <54CF4962.7020202@treenet.co.nz> <1422885907362.27721@diladele.com>,
 <54CF8A62.3040605@treenet.co.nz> <1422888481228.45205@diladele.com>
Message-ID: <54CFA300.9030201@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Harry up, Raf :)

I'm waiting for 3.5 Win64 for my notebook :)

And don't forget SSL Bump ! :)

02.02.2015 20:47, Rafael Akchurin ?????:
> Eldar will send soon as we finish some initial testing.
> Raf
>
>
> ________________________________________
> From: Amos Jeffries <squid3 at treenet.co.nz>
> Sent: Monday, February 2, 2015 3:32 PM
> To: Rafael Akchurin; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid Authentication
>
> On 3/02/2015 3:04 a.m., Rafael Akchurin wrote:
>> Hello Amos,
>>
>> We will soon be able to have latest 3.5 built for Cygwin x64 (hopefully).
>>
>
> Yay! Are there any patches I can merge that will help minimize the
> tracking work for future releases?
>
> Amos
>
>
>> Rafael
>>
>> ________________________________________
>> From: Amos Jeffries
>>
>> On 2/02/2015 5:27 p.m., Raju M K wrote:
>>> Need squid Authentication syntax for local users in Windows 7/8
workgroup
>>> Presently using squid 2.7 stable 8
>>
>> 2.7 was end-of-lifed *5 years ago*. Please upgrade.
>> http://www.squid-cache.org/Versions/
>>
>> PS. I know we dont have a native windows version available of anything
>> newer (though Cygwin does provide 3.2/3.3 builds). But there is no
>> reason for Squid being tied down onto a Windows server while servicing
>> Windows users, and many reasons for it to *not* be.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJUz6L/AAoJENNXIZxhPexGRPsH/AhWdMapx+a/k9iS+QnzHp/w
hQHy0HBHS4V6pQyqcWOmBxgq14SLxLUTwe8th6EavBDAERo3xstq5dt/Ped35Gg0
gK1YjT3io/WCfqs2nIzvp2UycVmbQjt5Yld1hGlPEoP5H4WaulrffkaSzdZUJOlf
0XYPTHRnQiNFb2g6f37zbQyZmhWkkx9rTIobzuMAvnLcmXACFQjv7O0pY+pbS0nO
q4S8ou7vfdhTfCkXSUd+jTqQ3dL8Vi3ZlSC8QDxDUEXCZPkBy8iHJR3pl1iRQA6u
ZLomlz1pr6cHjr6AURw5rGqPMmt4DtqJskS4yrd/Ky/rIlrGTFyhltJNvtuC2wo=
=k1L/
-----END PGP SIGNATURE-----



From vdoctor at neuf.fr  Mon Feb  2 16:56:32 2015
From: vdoctor at neuf.fr (Stakres)
Date: Mon, 2 Feb 2015 08:56:32 -0800 (PST)
Subject: [squid-users] Resolution Locker Plugin for Squid Proxy Cache 3.x
Message-ID: <1422896192924-4669489.post@n4.nabble.com>

Hi All,

SquidVideoLocker for Squid Proxy Cache is a plugin that locks and limits
video resolutions of YouTube, Vevo and iMDB. The plugin takes into account
all video formats, all resolutions from 144p up to 2160p.

Reduce video resolutions from YouTube, Vevo and iMDB to the lower existing
resolution in order to save significant amount of bandwidth for other
usages.
Once installed on your Squid Proxy Cache, each time one of your users tries
to view a web video from YouTube, Vevo or iMDB, the plugin will lock and
limit the video resolution in order to reduce the size of the audio/video to
download and free precious bandwidth for other users.

Visit our dedicated website  SquidVideoLocker <https://svl.unveiltech.com>  
and get a *free 1 year license*.

Version 2.01 - February 2th 2015
- Standalone program with no addtional library needed (no external libraries
anymore)
- Independent Squid plugin that does not need the Cloud API anymore
- Compatible All Linux distribution (tested under Debian/Ubuntu/CentOS
64bits and Debian 32bits)

Installation:
- Uncompress ut-reslocker.2.01.tgz to /etc/squid depending your compilation
options
- Depending on your platform (32bits or 64 bits), verify that the
permissions of binary ("/etc/squid/[proc]/ut-reslocker") are 0755
- Then, edit your squid.conf to add the following:
# ---------------------------------------------------- #
# SquidVideoLocker
url_rewrite_program /etc/squid/ut-reslocker
# You could increase the number of children if you manage huge traffic
url_rewrite_children 8
- Finally, reload Squid: squid -k reconfigure

Enjoy 

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Resolution-Locker-Plugin-for-Squid-Proxy-Cache-3-x-tp4669489.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dan at getbusi.com  Tue Feb  3 03:49:44 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Tue, 3 Feb 2015 14:49:44 +1100
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <54CEC664.8020407@ngtech.co.il>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
Message-ID: <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>

Hi Eliezer

Thanks for paying attention, as always. I?m working on getting an (appropriately censored) example of our squid.conf up for your perusal.

In the mean time I just wanted to point out that when this crash occurs some of the most busy external_acl_types appear to crash too. Though the exact ones seems to vary a bit between occurrences:

2015/02/03 13:03:05 kid1| assertion failed: client_side.cc:1515: "connIsUsable(http->getConn())"
Traceback (most recent call last):
  File "max_file_size_acl.pyo", line 76, in <module>
IOError: [Errno 104] Connection reset by peer
2015/02/03 13:04:01 kid1| Set Current Directory to /var/spool/squid
Traceback (most recent call last):
  File "set_finder_acl.pyo", line 94, in <module>
IOError: [Errno 104] Connection reset by peer
2015/02/03 13:04:01 kid1| Starting Squid Cache version 3.4.11 for x86_64-redhat-linux-gnu...

Those lines it?s pointing to in the Traceback are just the last line in each ACL e.g. `line = sys.stdin.readline()`

Cheers
Dan

> On 2 Feb 2015, at 11:35 am, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> Hey Dan,
> 
> Just to get around the environment, can you share your squid.conf?(censuring confidential data)
> 
> Thanks,
> Eliezer
> 
> On 02/02/2015 01:14, Dan Charlesworth wrote:
>> Bumping this one for the new year 'cause I still don't understand squid
>> traces and because it's still happening with v3.4.11.
>> 
>> I would speculate that's it's something to do with the External ACLs
>> (there's a bunch). Let me know if a more recent traceback (than those
>> earlier in the thread) would help.
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/69d7172c/attachment.htm>

From priyaiitmandi at gmail.com  Tue Feb  3 05:50:13 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Tue, 3 Feb 2015 11:20:13 +0530
Subject: [squid-users] ERROR opening swap log /var/cache/squid/swap.state:
	(5) Input/output error
Message-ID: <CALTPfpGnHO8RHSK=0CVBPDcJjK=ER43OKhYUtz_=CoFce4R90A@mail.gmail.com>

Hello,

How do I correct this error.

ERROR opening swap log /var/cache/squid/swap.state: (5) Input/output error
FATAL: UFSSwapDir::openLog: Failed to open swap log.

Background: Running squid 3.4.7 on a freescale machine (T4240QDS) with
ubuntu 12.04.
/usr/sbin/squid -k parse and /usr/sbin/squid -z didnt give any errors.
On running /usr/sbin/squid -NCd1 I get the above error.

root at t4240qds:~# /usr/sbin/squid -NCd1
2015/02/03 06:12:27| Set Current Directory to /var/cache/squid
2015/02/03 06:12:27| Starting Squid Cache version 3.4.7 for poweEXT2-fs
(mmcblk0p1): error: ext2_lookup: deleted inode referenced: 137660
rpc-fsl_networking-linux-gnu...
2015/02/03 06:12:27| Process ID 2520
2015/02/03 06:12:27| Process Roles: master worker
2015/02/03 06:12:27| With 1024 file descriptors available
2015/02/03 06:12:27| Initializing IP Cache...
2015/02/03 06:12:27| parseEtcHosts: /etc/hosts: (13) Permission denied
2015/02/03 06:12:27| DNS Socket created at [::], FD 4
2015/02/03 06:12:27| DNS Socket created at 0.0.0.0, FD 5
2015/02/03 06:12:27| Adding nameserver 10.116.65.126 from squid.conf
2015/02/03 06:12:27| Logfile: opening log daemon:/var/logs/access.log
2015/02/03 06:12:27| Logfile Daemon: opening log /var/logs/access.log
2015/02/03 06:12:27| Store logging disabled
2015/02/03 06:12:27| Swap maxSize 102400 + 262144 KB, estimated 28041
objects
2015/02/03 06:12:27| Target number of buckets: 1402
2015/02/03 06:12:27| Using 8192 Store buckets
2015/02/03 06:12:27| Max Mem  size: 262144 KB
2015/02/03 06:12:27| Max Swap size: 102400 KB
2015/02/03 06:12:27| ERROR opening swap log /var/cache/squid/swap.state:
(5) Input/output error
FATAL: UFSSwapDir::openLog: Failed to open swap log.

Since I am booting the machine from an sd card I tried to delete the entire
root filesystem and thus even swap.state file however it wouldn't get
deleted. Did a filesystem check using e2fsck, but still swap.state won't
get deleted.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/07a9c92a/attachment.htm>

From priyaiitmandi at gmail.com  Tue Feb  3 07:48:59 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Tue, 3 Feb 2015 13:18:59 +0530
Subject: [squid-users] ERROR opening swap log
 /var/cache/squid/swap.state: (5) Input/output error
In-Reply-To: <CALTPfpGnHO8RHSK=0CVBPDcJjK=ER43OKhYUtz_=CoFce4R90A@mail.gmail.com>
References: <CALTPfpGnHO8RHSK=0CVBPDcJjK=ER43OKhYUtz_=CoFce4R90A@mail.gmail.com>
Message-ID: <CALTPfpED=re5UjL=pXy1EFDsLCUKgRPn2+DnPx3Hig9KWm+ohA@mail.gmail.com>

I could solve it. Created a new partition in my sd card.

On Tue, Feb 3, 2015 at 11:20 AM, Priya Agarwal <priyaiitmandi at gmail.com>
wrote:

> Hello,
>
> How do I correct this error.
>
> ERROR opening swap log /var/cache/squid/swap.state: (5) Input/output error
> FATAL: UFSSwapDir::openLog: Failed to open swap log.
>
> Background: Running squid 3.4.7 on a freescale machine (T4240QDS) with
> ubuntu 12.04.
> /usr/sbin/squid -k parse and /usr/sbin/squid -z didnt give any errors.
> On running /usr/sbin/squid -NCd1 I get the above error.
>
> root at t4240qds:~# /usr/sbin/squid -NCd1
> 2015/02/03 06:12:27| Set Current Directory to /var/cache/squid
> 2015/02/03 06:12:27| Starting Squid Cache version 3.4.7 for poweEXT2-fs
> (mmcblk0p1): error: ext2_lookup: deleted inode referenced: 137660
> rpc-fsl_networking-linux-gnu...
> 2015/02/03 06:12:27| Process ID 2520
> 2015/02/03 06:12:27| Process Roles: master worker
> 2015/02/03 06:12:27| With 1024 file descriptors available
> 2015/02/03 06:12:27| Initializing IP Cache...
> 2015/02/03 06:12:27| parseEtcHosts: /etc/hosts: (13) Permission denied
> 2015/02/03 06:12:27| DNS Socket created at [::], FD 4
> 2015/02/03 06:12:27| DNS Socket created at 0.0.0.0, FD 5
> 2015/02/03 06:12:27| Adding nameserver 10.116.65.126 from squid.conf
> 2015/02/03 06:12:27| Logfile: opening log daemon:/var/logs/access.log
> 2015/02/03 06:12:27| Logfile Daemon: opening log /var/logs/access.log
> 2015/02/03 06:12:27| Store logging disabled
> 2015/02/03 06:12:27| Swap maxSize 102400 + 262144 KB, estimated 28041
> objects
> 2015/02/03 06:12:27| Target number of buckets: 1402
> 2015/02/03 06:12:27| Using 8192 Store buckets
> 2015/02/03 06:12:27| Max Mem  size: 262144 KB
> 2015/02/03 06:12:27| Max Swap size: 102400 KB
> 2015/02/03 06:12:27| ERROR opening swap log /var/cache/squid/swap.state:
> (5) Input/output error
> FATAL: UFSSwapDir::openLog: Failed to open swap log.
>
> Since I am booting the machine from an sd card I tried to delete the
> entire root filesystem and thus even swap.state file however it wouldn't
> get deleted. Did a filesystem check using e2fsck, but still swap.state
> won't get deleted.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/5ddba8db/attachment.htm>

From Richard.Aspley at hammonds-uk.com  Tue Feb  3 11:38:47 2015
From: Richard.Aspley at hammonds-uk.com (Rich549)
Date: Tue, 3 Feb 2015 03:38:47 -0800 (PST)
Subject: [squid-users] Webpages won't load or load slowly
In-Reply-To: <54CA4FF8.7080802@treenet.co.nz>
References: <1422530659467-4669408.post@n4.nabble.com>
 <54CA24CA.9090101@gmail.com> <1422539342797-4669414.post@n4.nabble.com>
 <54CA41F3.7000707@treenet.co.nz> <1422541395684-4669417.post@n4.nabble.com>
 <54CA4546.3090605@treenet.co.nz> <1422542932042-4669419.post@n4.nabble.com>
 <1422543008510-4669420.post@n4.nabble.com> <54CA4FF8.7080802@treenet.co.nz>
Message-ID: <1422963527304-4669493.post@n4.nabble.com>

Ok, so I grabbed Squid 3.5.1, compiled it in Ubuntu, set all of the paths for
./configure so that the new files would overwrite the old, renamed
/usr/sbin/squid to /usr/sbin/squid3 so that the service didn't need to be
altered and everything after a service restart and a -k reconfigure Squid is
working ok.

Except, I still have exactly the same issue of certain pages not loading. 
Have I done this the wrong way? Should I have removed the old install of
Squid before compiling and installing the new one?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Webpages-won-t-load-or-load-slowly-tp4669408p4669493.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Tue Feb  3 12:50:05 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 03 Feb 2015 14:50:05 +0200
Subject: [squid-users] Webpages won't load or load slowly
In-Reply-To: <1422963527304-4669493.post@n4.nabble.com>
References: <1422530659467-4669408.post@n4.nabble.com>
 <54CA24CA.9090101@gmail.com> <1422539342797-4669414.post@n4.nabble.com>
 <54CA41F3.7000707@treenet.co.nz> <1422541395684-4669417.post@n4.nabble.com>
 <54CA4546.3090605@treenet.co.nz> <1422542932042-4669419.post@n4.nabble.com>
 <1422543008510-4669420.post@n4.nabble.com> <54CA4FF8.7080802@treenet.co.nz>
 <1422963527304-4669493.post@n4.nabble.com>
Message-ID: <54D0C3FD.6010701@ngtech.co.il>

Hey Rich,

I am yet unsure about the issue you are having and even if squid 3.3.8 
is not the latest most of these sites should work fine for you throw squid.
I believe that this is the place where we can take a look at the squid 
access.log output while surfing to understand the issue better.
If you are using IE\FF\Chrome you should have some profiling and network 
tools which can help understand the issue from the client side before 
running and looking for an issue in the middle.

In IE and FF you can use the F12 button to open the tools toolbox and 
then go into network tab or icon.
You should then be able throw this tool see what happens with all the 
requests from the client side.

If you have specific public urls you are trying to access I can try to 
look at them and asses the basic available options.

If you can first try to enable the dns_v4_first option in your 
squid.conf it would be my first try.
http://www.squid-cache.org/Doc/config/dns_v4_first/

Add "dns_v4_first on" to squid.conf.

Eliezer

On 03/02/2015 13:38, Rich549 wrote:
> Except, I still have exactly the same issue of certain pages not loading.
> Have I done this the wrong way? Should I have removed the old install of
> Squid before compiling and installing the new one?
>




From omidkosari at yahoo.com  Tue Feb  3 12:45:29 2015
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 3 Feb 2015 04:45:29 -0800 (PST)
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
	squid.
In-Reply-To: <52E0B7A8.8080009@ngtech.co.il>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il>
Message-ID: <1422967529217-4669494.post@n4.nabble.com>

How we can test this ?
What protocol suggested for Squid ? NFS, iSCSI,... ?

Apart from bandwidth, is there any important difference between 1Gbit
ethernet and 10G ? Do you suggest me to buy 1Gbit storage and monitor it or
you think the money will be wasted ?

Any news about this REALLY interesting thread ?

@Eliezer , Any benchmark ?

This topic is very important for me .






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Hypothetically-comparing-SATA-SAS-to-NAS-SAN-for-squid-tp4664350p4669494.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Richard.Aspley at hammonds-uk.com  Tue Feb  3 13:01:30 2015
From: Richard.Aspley at hammonds-uk.com (Rich549)
Date: Tue, 3 Feb 2015 05:01:30 -0800 (PST)
Subject: [squid-users] Webpages won't load or load slowly
In-Reply-To: <54D0C3FD.6010701@ngtech.co.il>
References: <54CA24CA.9090101@gmail.com>
 <1422539342797-4669414.post@n4.nabble.com> <54CA41F3.7000707@treenet.co.nz>
 <1422541395684-4669417.post@n4.nabble.com> <54CA4546.3090605@treenet.co.nz>
 <1422542932042-4669419.post@n4.nabble.com>
 <1422543008510-4669420.post@n4.nabble.com> <54CA4FF8.7080802@treenet.co.nz>
 <1422963527304-4669493.post@n4.nabble.com> <54D0C3FD.6010701@ngtech.co.il>
Message-ID: <1422968490975-4669496.post@n4.nabble.com>

Eliezer Croitoru-2 wrote
> Hey Rich,
> 
> I am yet unsure about the issue you are having and even if squid 3.3.8 
> is not the latest most of these sites should work fine for you throw
> squid.
> I believe that this is the place where we can take a look at the squid 
> access.log output while surfing to understand the issue better.
> If you are using IE\FF\Chrome you should have some profiling and network 
> tools which can help understand the issue from the client side before 
> running and looking for an issue in the middle.
> 
> In IE and FF you can use the F12 button to open the tools toolbox and 
> then go into network tab or icon.
> You should then be able throw this tool see what happens with all the 
> requests from the client side.

Hi,

Thanks for the suggestion, I've attached a couple of files showing the
results of that.  I actually see a lot of DENIED errors for pretty much any
websites using port 443 (SSL). 

twitter.png
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4669496/twitter.png>  
Twitter_accesslog.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4669496/Twitter_accesslog.txt>  



Eliezer Croitoru-2 wrote
> If you have specific public urls you are trying to access I can try to 
> look at them and asses the basic available options.

The URLs are as follows : www.twitter.com, www.experts-exchange.com,
www.ubuntugreek.com, www.stackoverflow.com and www.reddit.com.


Eliezer Croitoru-2 wrote
> If you can first try to enable the dns_v4_first option in your 
> squid.conf it would be my first try.
> http://www.squid-cache.org/Doc/config/dns_v4_first/
> 
> Add "dns_v4_first on" to squid.conf.

Just added that to my config, hasn't made a difference.  I think I may have
tried this already, along with statically setting Google DNS servers.

Thanks,

Rich



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Webpages-won-t-load-or-load-slowly-tp4669408p4669496.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Richard.Aspley at hammonds-uk.com  Tue Feb  3 13:03:00 2015
From: Richard.Aspley at hammonds-uk.com (Rich549)
Date: Tue, 3 Feb 2015 05:03:00 -0800 (PST)
Subject: [squid-users] Webpages won't load or load slowly
In-Reply-To: <1422968490975-4669496.post@n4.nabble.com>
References: <1422539342797-4669414.post@n4.nabble.com>
 <54CA41F3.7000707@treenet.co.nz> <1422541395684-4669417.post@n4.nabble.com>
 <54CA4546.3090605@treenet.co.nz> <1422542932042-4669419.post@n4.nabble.com>
 <1422543008510-4669420.post@n4.nabble.com> <54CA4FF8.7080802@treenet.co.nz>
 <1422963527304-4669493.post@n4.nabble.com> <54D0C3FD.6010701@ngtech.co.il>
 <1422968490975-4669496.post@n4.nabble.com>
Message-ID: <1422968580839-4669497.post@n4.nabble.com>

Correction to example URL, http://www.ubuntugreek.com/ should be
http://www.ubuntugeek.com/.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Webpages-won-t-load-or-load-slowly-tp4669408p4669497.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marcus.kool at urlfilterdb.com  Tue Feb  3 13:29:57 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 03 Feb 2015 11:29:57 -0200
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
 squid.
In-Reply-To: <1422967529217-4669494.post@n4.nabble.com>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il> <1422967529217-4669494.post@n4.nabble.com>
Message-ID: <54D0CD55.5060302@urlfilterdb.com>

Hi Omid,

The I/O requirements can be estimated well if you tell more about the
environment.  If you know the number of requests/second that Squid prcoesses
you can add a percentage to increase performance and calculate the desired
I/Os per second (IOPS).
When you have the desired IOPS, you can calculate if 1 gbit is enough.

NFS has relatively much overhead, so I recommend a NAS with iSCSI or a SAN.

What kind of SAN/NAS did you have in mind ?

Do you already have a SAN or NAS ?

Marcus



On 02/03/2015 10:45 AM, Omid Kosari wrote:
> How we can test this ?
> What protocol suggested for Squid ? NFS, iSCSI,... ?
>
> Apart from bandwidth, is there any important difference between 1Gbit
> ethernet and 10G ? Do you suggest me to buy 1Gbit storage and monitor it or
> you think the money will be wasted ?
>
> Any news about this REALLY interesting thread ?
>
> @Eliezer , Any benchmark ?
>
> This topic is very important for me .
>
>
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Hypothetically-comparing-SATA-SAS-to-NAS-SAN-for-squid-tp4664350p4669494.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From squid3 at treenet.co.nz  Tue Feb  3 13:54:00 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 04 Feb 2015 02:54:00 +1300
Subject: [squid-users] Webpages won't load or load slowly
In-Reply-To: <1422968490975-4669496.post@n4.nabble.com>
References: <54CA24CA.9090101@gmail.com>
 <1422539342797-4669414.post@n4.nabble.com> <54CA41F3.7000707@treenet.co.nz>
 <1422541395684-4669417.post@n4.nabble.com> <54CA4546.3090605@treenet.co.nz>
 <1422542932042-4669419.post@n4.nabble.com>
 <1422543008510-4669420.post@n4.nabble.com> <54CA4FF8.7080802@treenet.co.nz>
 <1422963527304-4669493.post@n4.nabble.com> <54D0C3FD.6010701@ngtech.co.il>
 <1422968490975-4669496.post@n4.nabble.com>
Message-ID: <54D0D2F8.9030902@treenet.co.nz>

On 4/02/2015 2:01 a.m., Rich549 wrote:
> Eliezer Croitoru-2 wrote
>> Hey Rich,
>>
>> I am yet unsure about the issue you are having and even if squid 3.3.8 
>> is not the latest most of these sites should work fine for you throw
>> squid.
>> I believe that this is the place where we can take a look at the squid 
>> access.log output while surfing to understand the issue better.
>> If you are using IE\FF\Chrome you should have some profiling and network 
>> tools which can help understand the issue from the client side before 
>> running and looking for an issue in the middle.
>>
>> In IE and FF you can use the F12 button to open the tools toolbox and 
>> then go into network tab or icon.
>> You should then be able throw this tool see what happens with all the 
>> requests from the client side.
> 
> Hi,
> 
> Thanks for the suggestion, I've attached a couple of files showing the
> results of that.  I actually see a lot of DENIED errors for pretty much any
> websites using port 443 (SSL). 
> 
> twitter.png
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4669496/twitter.png>  
> Twitter_accesslog.txt
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4669496/Twitter_accesslog.txt>  
> 
> 

Looks like perfectly normal NTLM meets HTTPS traffic behaviour to me.


Browser connects to proxy, proxy replies with 407 listing available auth
schemes.

1422968109.560      0 172.31.21.3 TCP_DENIED/407 3722 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.560      0 172.31.21.3 TCP_DENIED/407 3722 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.561      0 172.31.21.3 TCP_DENIED/407 3722 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.570      0 172.31.21.3 TCP_DENIED/407 4106 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.570      0 172.31.21.3 TCP_DENIED/407 4106 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.579      0 172.31.21.3 TCP_DENIED/407 4106 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html

... taking less than 1ms in Squid.


Browser re-tries request with stage-1 NTLM auth credentials selecting,
proxy responds with NTLM stage-2 challenge.

1422968109.661      0 172.31.21.3 TCP_DENIED/407 3722 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.667      0 172.31.21.3 TCP_DENIED/407 4106 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.679      0 172.31.21.3 TCP_DENIED/407 3722 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.694      0 172.31.21.3 TCP_DENIED/407 3722 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.701      0 172.31.21.3 TCP_DENIED/407 4106 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html
1422968109.706      0 172.31.21.3 TCP_DENIED/407 4106 CONNECT
abs.twimg.com:443 - HIER_NONE/- text/html

... taking less than 1ms in Squid.

Browser re-tries request with NTLM stage-3 auth credentials.

Proxy accepts connection, opens TCP tunnel to upstream server, starts
relaying bytes between client and server...

 NP: there is no timing info on that logged.


40sec later the server closes the connection (having delivered 0
bytes!). Proxy logs completion of the HTTPS stream.

1422968149.730  40156 172.31.21.3 TCP_MISS/200 0 CONNECT
abs.twimg.com:443 aspleyri HIER_DIRECT/199.96.57.7 -
1422968149.731  40157 172.31.21.3 TCP_MISS/200 0 CONNECT
abs.twimg.com:443 aspleyri HIER_DIRECT/199.96.57.7 -
1422968149.731  40149 172.31.21.3 TCP_MISS/200 0 CONNECT
abs.twimg.com:443 aspleyri HIER_DIRECT/199.96.57.7 -
1422968149.731  40056 172.31.21.3 TCP_MISS/200 0 CONNECT
abs.twimg.com:443 aspleyri HIER_DIRECT/199.96.57.7 -
1422968149.731  40022 172.31.21.3 TCP_MISS/200 0 CONNECT
abs.twimg.com:443 aspleyri HIER_DIRECT/199.96.57.7 -
1422968149.731  40026 172.31.21.3 TCP_MISS/200 0 CONNECT
abs.twimg.com:443 aspleyri HIER_DIRECT/199.96.57.7 -


3.3 may have been introducing a bug, but 3.5 has the fix for that. So
there is nothing wrong here with Squid. The problem is somewhere in the
browser and server interactions.

Amos




From yvoinov at gmail.com  Tue Feb  3 14:26:35 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 03 Feb 2015 20:26:35 +0600
Subject: [squid-users] Alert unknown CA
Message-ID: <54D0DA9B.1090908@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Hi gents,

I think, will be good to add advanced debug options to ssl_crtd to avoid
this:

2015/02/03 20:21:37 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 28: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
alert unknown ca (1/0)

Now we have no one tools to diagnose the situations above. Excluding own
eyes and brains. And - telepathy.

Amos,

is it possible to get more informative diagnostics? URL will be enough.

WBR, Yuri

PS. Now I've added over 50 root and intermediate CA's. Still without
completely avoid this messages. It appears on site I do not know and can
not know.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0NqbAAoJENNXIZxhPexGWScH/0kzTf+ogwYsscr6qUChmnIC
oHH2tJWxC2CLK51XTWkS5LmPTEIS/yt+v6bxzghq0MFG+rdFN/8Wg/KFBZi3WayR
1UjRDbVt1U9vENSvAwkvL4n8bbuaTZCSlKCJAjN9V1wT7+FtJ5ZrTtsaS85e1zGV
xrmRygLtjcMnHYuakmK+CZjdlikSYFEQ3vfrPjvsnXVJcBDkJ+deVDikevsxuBP0
O2G1TNNVe6AUtjDNLhwpGde/T7tf5Vej4J9syzt7HIjcKL2ysoePRHb79BtNWjMs
OHE1A52ZRH4hIJ9aRa8pGw7BFDopnSaNuj6UxYT1VY10NZ08XfkD2RQt4EoaZxg=
=ArlJ
-----END PGP SIGNATURE-----



From grzeg.falkowski at gmail.com  Tue Feb  3 14:45:30 2015
From: grzeg.falkowski at gmail.com (Grzegorz Falkowski)
Date: Tue, 3 Feb 2015 15:45:30 +0100
Subject: [squid-users] Squidclamav - virus handling configuration.
Message-ID: <CAFA946D-836D-449E-9504-BCA9EA2F6541@gmail.com>

Hello,
I configured on ubuntu C-icap with squidclamav. Configuration work fine. Files are redirected to clamAV. If file is infected user is redirected and file is blocked. Squid is working as revProxy. For the first step I only need information about infected files. Because of that I would like configure it to redirect files but do not block. I can't find any solution in documentation. Can anybody help?
Thank You in advance.
Best Regards

From eliezer at ngtech.co.il  Tue Feb  3 14:47:11 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 03 Feb 2015 16:47:11 +0200
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
 squid.
In-Reply-To: <1422967529217-4669494.post@n4.nabble.com>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il> <1422967529217-4669494.post@n4.nabble.com>
Message-ID: <54D0DF6F.7070906@ngtech.co.il>

Hey Omid,

I do not have benchmarks.

I was actually in the past looking at GlusterFS and NFS for couple purposes.
The Gigabit and 10Gb have their difference.
The main big thing is that a simple SATA\SAS jack\connector\port 
supports up to 6Gb and in most cases the machine will not utilize even 
1Gb per port\disk.

If you do ask me about a comparison about ISCSI vs nfs vs glusterfs I 
would grade NFS as the best for lots of files while glusterfs is better 
for big files.
An ISCSI partition benefits are VFS in memory objects which eventually 
reduce access time compared to glusterfs and NFS.

I have tested glusterfs as a backend for a hypervisor and a local SSD 
drive was faster.

Do you have anything you think about Omid? if you have a scenario in 
hand I would like hear about it.

Eliezer

On 03/02/2015 14:45, Omid Kosari wrote:
> @Eliezer , Any benchmark ?
>
> This topic is very important for me .




From omidkosari at yahoo.com  Tue Feb  3 14:56:43 2015
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 3 Feb 2015 06:56:43 -0800 (PST)
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
	squid.
In-Reply-To: <54D0CD55.5060302@urlfilterdb.com>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il> <1422967529217-4669494.post@n4.nabble.com>
 <54D0CD55.5060302@urlfilterdb.com>
Message-ID: <1422975403825-4669503.post@n4.nabble.com>

Squidbox1: Average HTTP requests per minute since start:	16000
Squidbox2: Average HTTP requests per minute since start:	11000

About 300Mbit of bandwidth (Only http bandwidth which routed to squid boxes)

Right now squid boxes have 4 250GB SSD and there is no more free sata slots
on them . I want to use SAN/NAS to extend their capacity .

No i don't have free NAS/SAN but somebody has a 2bay model of following
model and suggest me half price
http://www.seagate.com/files/www-content/support-content/external-products/blackarmor-nas/_shared/docs/business-nas-guides/Seagate_NAS_Admin_Guide_EN.pdf

and found a review. i am not sure it is for same model
http://www.storagereview.com/seagate_business_storage_windows_server_4bay_nas_review

Is it useful for my purpose ? Or please provide general specs that i should
be aware before buy .




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Hypothetically-comparing-SATA-SAS-to-NAS-SAN-for-squid-tp4664350p4669503.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From anton at radkevich.info  Tue Feb  3 15:14:05 2015
From: anton at radkevich.info (Anton Radkevich)
Date: Tue, 3 Feb 2015 18:14:05 +0300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
Message-ID: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>

Hi everyone,

Could you please help me with configuration Squid3 as forward HTTPs proxy?
Is it possible to configure it in such way?

What we do need is a fully encrypted HTTPS forward proxy that can handle
HTTP or HTTPS connection AND uses authentication.

so just to be clear the connection flow will look like:

browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination

where <Encrypted Tunnel> is probably some form of HTTPS connection for
support with the browser PAC

Also, for client auth, can we used more "modern" hashing algorithms like
sha256/512? md5 is old and collision prone at this point.

Thank you in advance!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/2a8b8b0f/attachment.htm>

From marcus.kool at urlfilterdb.com  Tue Feb  3 18:13:07 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 03 Feb 2015 16:13:07 -0200
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
 squid.
In-Reply-To: <1422975403825-4669503.post@n4.nabble.com>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il> <1422967529217-4669494.post@n4.nabble.com>
 <54D0CD55.5060302@urlfilterdb.com> <1422975403825-4669503.post@n4.nabble.com>
Message-ID: <54D10FB3.7090505@urlfilterdb.com>



On 02/03/2015 12:56 PM, Omid Kosari wrote:
> Squidbox1: Average HTTP requests per minute since start:	16000
> Squidbox2: Average HTTP requests per minute since start:	11000

16000 request/min = 266 requests/sec.
With a well-tuned Squid system I estimate that the disk I/O is less than 2000 IOPS
and the current SSDs should be able to cope with that.  So speed should not be an issue.

Why do you want to extend? Is it only to extend the disk cache capacity?

What is are specs of the current SSDs ?
It is worthwile to replace them with new SSDs with higher performance/capacity ?

> About 300Mbit of bandwidth (Only http bandwidth which routed to squid boxes)
>
> Right now squid boxes have 4 250GB SSD and there is no more free sata slots
> on them . I want to use SAN/NAS to extend their capacity .
>
> No i don't have free NAS/SAN but somebody has a 2bay model of following
> model and suggest me half price
> http://www.seagate.com/files/www-content/support-content/external-products/blackarmor-nas/_shared/docs/business-nas-guides/Seagate_NAS_Admin_Guide_EN.pdf

The PDF points to a Windows-only based NAS !

> and found a review. i am not sure it is for same model
> http://www.storagereview.com/seagate_business_storage_windows_server_4bay_nas_review
>
> Is it useful for my purpose ? Or please provide general specs that i should
> be aware before buy .

Marcus



From squid3 at treenet.co.nz  Tue Feb  3 18:31:03 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 04 Feb 2015 07:31:03 +1300
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D0DA9B.1090908@gmail.com>
References: <54D0DA9B.1090908@gmail.com>
Message-ID: <54D113E7.4010201@treenet.co.nz>

On 4/02/2015 3:26 a.m., Yuri Voinov wrote: Hi gents,
> 
> I think, will be good to add advanced debug options to ssl_crtd to avoid
> this:
> 
> 2015/02/03 20:21:37 kid1| clientNegotiateSSL: Error negotiating SSL
> connection on FD 28: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
> alert unknown ca (1/0)
> 
> Now we have no one tools to diagnose the situations above. Excluding own
> eyes and brains. And - telepathy.
> 
> Amos,
> 
> is it possible to get more informative diagnostics? URL will be enough.

I dont think we can without re-writing OpenSSL library operations
directly in Squid.

Amos



From yvoinov at gmail.com  Tue Feb  3 18:36:47 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 00:36:47 +0600
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D113E7.4010201@treenet.co.nz>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
Message-ID: <54D1153F.7070402@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
What about linking OpenSSL libraries into Squid? Like eCAP?

Or how to trace openssl calls anywhere else?

AFAIK, URL is passed to SSL_CRTD. Then return with result, right?

Why we can't add catch errors and log it with URL?

This unrecoverable errors is makes correct bump much difficult.

04.02.2015 0:31, Amos Jeffries ?????:
> On 4/02/2015 3:26 a.m., Yuri Voinov wrote: Hi gents,
>>
>> I think, will be good to add advanced debug options to ssl_crtd to avoid
>> this:
>>
>> 2015/02/03 20:21:37 kid1| clientNegotiateSSL: Error negotiating SSL
>> connection on FD 28: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
>> alert unknown ca (1/0)
>>
>> Now we have no one tools to diagnose the situations above. Excluding own
>> eyes and brains. And - telepathy.
>>
>> Amos,
>>
>> is it possible to get more informative diagnostics? URL will be enough.
>
> I dont think we can without re-writing OpenSSL library operations
> directly in Squid.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0RU/AAoJENNXIZxhPexGRlsH/2dgwQuHz7QSPBukAqvSN3T6
RDao4nnWgM0V5ACgqRfSibwv4EuAPSJuJHDsvc3JxmNvb6bSuAu8RZ4ra+5cEdor
7yPJcSevskiuOkMFXq4XxyAIwaYMJEWGFSpyKmSQHHM0fVIHhVxWgF/0gGxUxNPm
aulE/R5zRoxt0Vvm0FLdLjgt5X1axyFeNoQYoLID24uggWXn8qkRcy1NrA9QnYOG
E9Y4vXwDHL48bBd5J7Ld1WGUAJ/xvokWOmK+Jz9dHuEIi4pT7u7IOFlkWBjZjWgi
eGuXoK0BqEBh+1izeFrpGKtfcqWC0ZWVn0Sykv6jl/l1B3PVta1GOwocFp9nPBA=
=ZzDE
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Tue Feb  3 18:50:26 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 00:50:26 +0600
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D113E7.4010201@treenet.co.nz>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
Message-ID: <54D11872.6090801@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Now I have:

root @ cthulhu /etc/opt/csw/ssl/certs # ls -al *.pem|wc -l
210

root and intermediate CA's. Most known I can found.

Note: all of them was wound in different places - in addition with
Mozilla's bundle, shipped with OpenSSL.

How I can found, which is absent?

And how to support this heap? In practice? Manually with CLI openssl?
Ok, but how to identify problem URL, when Squid's load over 100 requests
per second?

04.02.2015 0:31, Amos Jeffries ?????:
> On 4/02/2015 3:26 a.m., Yuri Voinov wrote: Hi gents,
>>
>> I think, will be good to add advanced debug options to ssl_crtd to avoid
>> this:
>>
>> 2015/02/03 20:21:37 kid1| clientNegotiateSSL: Error negotiating SSL
>> connection on FD 28: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
>> alert unknown ca (1/0)
>>
>> Now we have no one tools to diagnose the situations above. Excluding own
>> eyes and brains. And - telepathy.
>>
>> Amos,
>>
>> is it possible to get more informative diagnostics? URL will be enough.
>
> I dont think we can without re-writing OpenSSL library operations
> directly in Squid.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0RhxAAoJENNXIZxhPexGBXMH/iyom3/HPCkQB0xpAOZ7UdD0
aW5DhdzmGuaVQFbtxB4rkD+fd0KUxi3l0aOctE7xEjJFwB3R1BqjTqWD7Kw/N5I2
KaWUkxMHG2yxAjBqlOU/8ViJCpu4bq7aKQJWlfivr+qcH2QREUm5Q6cB9g18GKNy
mnS4qX7tcLp5mCtZAP4da9JkU9SqJy43AYkrPQTWVXKAz+ctZRDZVNzibhfIydmI
xXGy7iiUwwzJRLojjrp1WVpYQPV899EkhKxmFCW8uTqxMmzagDb5MmpHeaN7YyiN
VRnBD8dmiD0tZd1W69wlelVpfgdJJnOPF3UFYC97MHyBaVTDMCM6ZZOIS8xTyrQ=
=fqa6
-----END PGP SIGNATURE-----



From anton at radkevich.info  Tue Feb  3 19:03:17 2015
From: anton at radkevich.info (Anton Radkevich)
Date: Tue, 3 Feb 2015 22:03:17 +0300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
Message-ID: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>

Hi everyone,

Could you please help me with configuration Squid3 as forward HTTPs proxy?

Is it possible to configure it in such way?

What we do need is a fully encrypted HTTPS forward proxy that can handle
HTTP or HTTPS connection AND uses authentication.

so just to be clear the connection flow will look like:

browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination

where <Encrypted Tunnel> is probably some form of HTTPS connection for
support with the browser PAC

Also, for client auth, can we used more "modern" hashing algorithms like
sha256/512? md5 is old and collision prone at this point.

Thank you in advance!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/07e79e71/attachment.htm>

From yvoinov at gmail.com  Tue Feb  3 19:58:01 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 01:58:01 +0600
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>
References: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>
Message-ID: <54D12849.1060909@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

04.02.2015 1:03, Anton Radkevich ?????:
>
> Hi everyone,
>
> Could you please help me with configuration Squid3 as forward HTTPs proxy?
>
> Is it possible to configure it in such way?
>
> What we do need is a fully encrypted HTTPS forward proxy that can
handle HTTP or HTTPS connection AND uses authentication.
>
> so just to be clear the connection flow will look like:
>
> browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination
>
> where <Encrypted Tunnel> is probably some form of HTTPS connection for
support with the browser PAC
>
> Also, for client auth, can we used more "modern" hashing algorithms
like sha256/512? md5 is old and collision prone at this point.
>
> Thank you in advance!
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0ShIAAoJENNXIZxhPexGUg8H/3BGE1zXXDB5I8FxQPzEZVws
rq5MrxRoA0SjMkwOsNkmRaKkIJpiC6GsMVvkxoFgy4K3S/d5OhPd5TC6wlQk6xvf
5gOBArogKLZ/iOJiRR3cNvxsnUpjxTpZwRq6PXbTxd7u0M9NxtONva5bIkUdFJVU
aeMXZnoWJZJgrE8tcBDqsoDei8gILOT7wC0mTDV3uAJHnu728xy0oRpFq7/Osl/r
SwNi81p2sjGi/z5VDBrE/4JcfJsDsoIzI/6AIjyw6XdbQRx7QTDD213UJnqt2uQA
VddSYZp+hL5DQXhun+NSiwhpsgkmDj04hExsaPUXrZokxopOf/EAQ6ilQ2qDZ5c=
=pMq4
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/17196583/attachment.htm>

From anton at radkevich.info  Tue Feb  3 20:06:48 2015
From: anton at radkevich.info (Anton Radkevich)
Date: Tue, 3 Feb 2015 23:06:48 +0300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <54D12849.1060909@gmail.com>
References: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>
 <54D12849.1060909@gmail.com>
Message-ID: <CAN_=S83L75K=VUYEFHLDR+j+2YB76=mfgYZKzpi2JVaosyrv+g@mail.gmail.com>

Thanks for quick reply,
We don't need ssl bumping, or isn't it possible to configure by another
way, without using ssl bumping?

What's about authentication using modern hash algorithms sha256/512?

Anton
03 ????. 2015 ?. 22:58 ???????????? "Yuri Voinov" <yvoinov at gmail.com>
???????:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
> 04.02.2015 1:03, Anton Radkevich ?????:
> >
> > Hi everyone,
> >
> > Could you please help me with configuration Squid3 as forward HTTPs
> proxy?
> >
> > Is it possible to configure it in such way?
> >
> > What we do need is a fully encrypted HTTPS forward proxy that can handle
> HTTP or HTTPS connection AND uses authentication.
> >
> > so just to be clear the connection flow will look like:
> >
> > browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination
> >
> > where <Encrypted Tunnel> is probably some form of HTTPS connection for
> support with the browser PAC
> >
> > Also, for client auth, can we used more "modern" hashing algorithms like
> sha256/512? md5 is old and collision prone at this point.
> >
> > Thank you in advance!
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU0ShIAAoJENNXIZxhPexGUg8H/3BGE1zXXDB5I8FxQPzEZVws
> rq5MrxRoA0SjMkwOsNkmRaKkIJpiC6GsMVvkxoFgy4K3S/d5OhPd5TC6wlQk6xvf
> 5gOBArogKLZ/iOJiRR3cNvxsnUpjxTpZwRq6PXbTxd7u0M9NxtONva5bIkUdFJVU
> aeMXZnoWJZJgrE8tcBDqsoDei8gILOT7wC0mTDV3uAJHnu728xy0oRpFq7/Osl/r
> SwNi81p2sjGi/z5VDBrE/4JcfJsDsoIzI/6AIjyw6XdbQRx7QTDD213UJnqt2uQA
> VddSYZp+hL5DQXhun+NSiwhpsgkmDj04hExsaPUXrZokxopOf/EAQ6ilQ2qDZ5c=
> =pMq4
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/f937bc64/attachment.htm>

From yvoinov at gmail.com  Tue Feb  3 20:12:28 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 02:12:28 +0600
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S83L75K=VUYEFHLDR+j+2YB76=mfgYZKzpi2JVaosyrv+g@mail.gmail.com>
References: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>	<54D12849.1060909@gmail.com>
 <CAN_=S83L75K=VUYEFHLDR+j+2YB76=mfgYZKzpi2JVaosyrv+g@mail.gmail.com>
Message-ID: <54D12BAC.8000705@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
As forward HTTPS proxy you can use no tricks. Just preroute HTTPS
traffic to Squid and permit method CONNECT with 443 port - Squid forward
HTTPS connections by design.

I do not understand, what does authentication here. This is another
problem that is not related to proxying HTTPS.

04.02.2015 2:06, Anton Radkevich ?????:
>
> Thanks for quick reply,
> We don't need ssl bumping, or isn't it possible to configure by
another way, without using ssl bumping?
>
> What's about authentication using modern hash algorithms sha256/512?
>
> Anton
>
> 03 ????. 2015 ?. 22:58 ???????????? "Yuri Voinov" <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> ???????:
>
>
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
> 04.02.2015 1:03, Anton Radkevich ?????:
>
> > Hi everyone,
>
> > Could you please help me with configuration Squid3 as forward HTTPs
proxy?
>
> > Is it possible to configure it in such way?
>
> > What we do need is a fully encrypted HTTPS forward proxy that can
handle HTTP or HTTPS connection AND uses authentication.
>
> > so just to be clear the connection flow will look like:
>
> > browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination
>
> > where <Encrypted Tunnel> is probably some form of HTTPS connection
for support with the browser PAC
>
> > Also, for client auth, can we used more "modern" hashing algorithms
like sha256/512? md5 is old and collision prone at this point.
>
> > Thank you in advance!
>
>
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0SusAAoJENNXIZxhPexGYKsH/0eRnm1ZEuzIGmibIQiP/BxU
+4qnPAmvu/nCVnemCrOVFDV/+49j/yCqjDtbdH1p6igCmjrzv2C11pgDP00IHs+l
kOL2O/65ubae3rL3EFNIX60daXOsEGZ6kOOOZ5Ik6hHfvOeT8YhdB9ryl+JoWtXB
DUVYPCsX+dsSmZHHC3fqjml7ZYG+rUb0K3Ipeq/khJibMqLzdJ6B4Vf+xeUqz+Nx
22YgaKx2ujsXgdIRzuz/HQfl5U9moGS0/iC5JEvq1TTmV8zk+7HFqJjVaKmL2Euk
9xvqTRPjfD7s7ZlqR/qtwwDxpYX6HbiGTLfYwAuDqtD2Ixj0CjgzLEeyGj6LvWs=
=wJWL
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/b6c51bc0/attachment.htm>

From eliezer at ngtech.co.il  Tue Feb  3 20:13:39 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 03 Feb 2015 22:13:39 +0200
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
 squid.
In-Reply-To: <1422975403825-4669503.post@n4.nabble.com>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il> <1422967529217-4669494.post@n4.nabble.com>
 <54D0CD55.5060302@urlfilterdb.com> <1422975403825-4669503.post@n4.nabble.com>
Message-ID: <54D12BF3.9000308@ngtech.co.il>

On 03/02/2015 16:56, Omid Kosari wrote:
> Squidbox1: Average HTTP requests per minute since start:	16000
> Squidbox2: Average HTTP requests per minute since start:	11000
>
> About 300Mbit of bandwidth (Only http bandwidth which routed to squid boxes)
What is the hardware specs of these squid boxes? CPU? RAM?

Eliezer



From yvoinov at gmail.com  Tue Feb  3 20:18:43 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 02:18:43 +0600
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S83L75K=VUYEFHLDR+j+2YB76=mfgYZKzpi2JVaosyrv+g@mail.gmail.com>
References: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>	<54D12849.1060909@gmail.com>
 <CAN_=S83L75K=VUYEFHLDR+j+2YB76=mfgYZKzpi2JVaosyrv+g@mail.gmail.com>
Message-ID: <54D12D23.2040103@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
http://wiki.squid-cache.org/Features/Authentication
http://wiki.squid-cache.org/ConfigExamples#Authentication

This one?

04.02.2015 2:06, Anton Radkevich ?????:
>
> Thanks for quick reply,
> We don't need ssl bumping, or isn't it possible to configure by
another way, without using ssl bumping?
>
> What's about authentication using modern hash algorithms sha256/512?
>
> Anton
>
> 03 ????. 2015 ?. 22:58 ???????????? "Yuri Voinov" <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> ???????:
>
>
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
> 04.02.2015 1:03, Anton Radkevich ?????:
>
> > Hi everyone,
>
> > Could you please help me with configuration Squid3 as forward HTTPs
proxy?
>
> > Is it possible to configure it in such way?
>
> > What we do need is a fully encrypted HTTPS forward proxy that can
handle HTTP or HTTPS connection AND uses authentication.
>
> > so just to be clear the connection flow will look like:
>
> > browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination
>
> > where <Encrypted Tunnel> is probably some form of HTTPS connection
for support with the browser PAC
>
> > Also, for client auth, can we used more "modern" hashing algorithms
like sha256/512? md5 is old and collision prone at this point.
>
> > Thank you in advance!
>
>
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0S0jAAoJENNXIZxhPexGWT4H/3pQ408tRavvV1mQeO9GQ4r+
0n5JIKyE8EMJLQ4OP0CSV0o5usnMKOiPOnK6AYDDKKin4QF85kBfS4QZyzzuvxPj
YCgi/zzijEvlEjsXX6ekwz1Qt+ImrhhvBXWSUqigf9WCe/cbrbOYFCLd0QuC/PbC
lYpMyeE0VGzFZaYeKOetTkBGsphYJyHTTDuzFiZkagLfCaWbpELQNAsMyoESR/2e
/LXFFXVB33mO6AVg3nNIv/34mCbpEKEqZUBht0O+7xMnEEYwSMAiELBdY+Tv/WTQ
ejNGPqzuKndaG8Al+FN8P+pqNqdJT1xVOLcyXohOj0KwBSWgl5YOybpKwbTbnh4=
=0F5M
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/02fae119/attachment.htm>

From anton at radkevich.info  Tue Feb  3 20:20:38 2015
From: anton at radkevich.info (Anton Radkevich)
Date: Tue, 3 Feb 2015 23:20:38 +0300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <54D12BAC.8000705@gmail.com>
References: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>
 <54D12849.1060909@gmail.com>
 <CAN_=S83L75K=VUYEFHLDR+j+2YB76=mfgYZKzpi2JVaosyrv+g@mail.gmail.com>
 <54D12BAC.8000705@gmail.com>
Message-ID: <CAN_=S82yKKDtSXJ2jvCGEz-dJQ__+xwvKF-eehOR=-zY1EPy7A@mail.gmail.com>

Yuri,

I'd like to allow or deny access for a client before establishing of
encrypted channel to proxy server using an authentication method of squid
proxy.
Can I setup any authentication method for https forward proxy? If yes, is
it possible to use more secure hash algorithms than old md5?

Thanks,
Anton
03 ????. 2015 ?. 23:12 ???????????? "Yuri Voinov" <yvoinov at gmail.com>
???????:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> As forward HTTPS proxy you can use no tricks. Just preroute HTTPS traffic
> to Squid and permit method CONNECT with 443 port - Squid forward HTTPS
> connections by design.
>
> I do not understand, what does authentication here. This is another
> problem that is not related to proxying HTTPS.
>
> 04.02.2015 2:06, Anton Radkevich ?????:
> >
> > Thanks for quick reply,
> > We don't need ssl bumping, or isn't it possible to configure by another
> way, without using ssl bumping?
> >
> > What's about authentication using modern hash algorithms sha256/512?
> >
> > Anton
> >
> > 03 ????. 2015 ?. 22:58 ???????????? "Yuri Voinov" <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> ???????:
> >
> >
> > http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> >
> > 04.02.2015 1:03, Anton Radkevich ?????:
> >
> > > Hi everyone,
> >
> > > Could you please help me with configuration Squid3 as forward HTTPs
> proxy?
> >
> > > Is it possible to configure it in such way?
> >
> > > What we do need is a fully encrypted HTTPS forward proxy that can
> handle HTTP or HTTPS connection AND uses authentication.
> >
> > > so just to be clear the connection flow will look like:
> >
> > > browser <Encrypted Tunnel> Server <HTTP or HTTPS connection>
> Destination
> >
> > > where <Encrypted Tunnel> is probably some form of HTTPS connection for
> support with the browser PAC
> >
> > > Also, for client auth, can we used more "modern" hashing algorithms
> like sha256/512? md5 is old and collision prone at this point.
> >
> > > Thank you in advance!
> >
> >
> >
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> > > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU0SusAAoJENNXIZxhPexGYKsH/0eRnm1ZEuzIGmibIQiP/BxU
> +4qnPAmvu/nCVnemCrOVFDV/+49j/yCqjDtbdH1p6igCmjrzv2C11pgDP00IHs+l
> kOL2O/65ubae3rL3EFNIX60daXOsEGZ6kOOOZ5Ik6hHfvOeT8YhdB9ryl+JoWtXB
> DUVYPCsX+dsSmZHHC3fqjml7ZYG+rUb0K3Ipeq/khJibMqLzdJ6B4Vf+xeUqz+Nx
> 22YgaKx2ujsXgdIRzuz/HQfl5U9moGS0/iC5JEvq1TTmV8zk+7HFqJjVaKmL2Euk
> 9xvqTRPjfD7s7ZlqR/qtwwDxpYX6HbiGTLfYwAuDqtD2Ixj0CjgzLEeyGj6LvWs=
> =wJWL
> -----END PGP SIGNATURE-----
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/d6b699af/attachment.htm>

From eliezer at ngtech.co.il  Tue Feb  3 20:23:22 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 03 Feb 2015 22:23:22 +0200
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>
Message-ID: <54D12E3A.1040004@ngtech.co.il>

On 03/02/2015 17:14, Anton Radkevich wrote:
> so just to be clear the connection flow will look like:
>
> browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination
>
> where <Encrypted Tunnel> is probably some form of HTTPS connection for
> support with the browser PAC

Hey Anton,

Squid do not support socks connection or any other form of encryption.
The known options to encrypt the connection between the client and the 
server are:
- ssl vpn tunnel
- ssh vpn tunnel
- some other weird and special ways

Since I am not familiar with all authentication methods I cannot answer.
On the other hand squid offers couple ways to authenticate and I am sure 
that the choice between md5 or other sha algorithm is not important if 
you are encrypting the connection between the server and the client 
using a tunnel.
If you wish to use some higher security levels you can use client side 
certificates and pin IP addresses to the certificates.

All The Bests,
Eliezer



From yvoinov at gmail.com  Tue Feb  3 20:26:35 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 02:26:35 +0600
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <54D12E3A.1040004@ngtech.co.il>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>
 <54D12E3A.1040004@ngtech.co.il>
Message-ID: <54D12EFB.90909@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Eliezer,

Squid can be cascaded with Privoxy+Tor. :)

And then - we can route users into it using ACL's.... ;)

Yep, not Squid itself. But with external services......... ;)

04.02.2015 2:23, Eliezer Croitoru ?????:
> On 03/02/2015 17:14, Anton Radkevich wrote:
>> so just to be clear the connection flow will look like:
>>
>> browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination
>>
>> where <Encrypted Tunnel> is probably some form of HTTPS connection for
>> support with the browser PAC
>
> Hey Anton,
>
> Squid do not support socks connection or any other form of encryption.
> The known options to encrypt the connection between the client and the
server are:
> - ssl vpn tunnel
> - ssh vpn tunnel
> - some other weird and special ways
>
> Since I am not familiar with all authentication methods I cannot answer.
> On the other hand squid offers couple ways to authenticate and I am
sure that the choice between md5 or other sha algorithm is not important
if you are encrypting the connection between the server and the client
using a tunnel.
> If you wish to use some higher security levels you can use client side
certificates and pin IP addresses to the certificates.
>
> All The Bests,
> Eliezer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0S77AAoJENNXIZxhPexGw6QIAMUsnpSP4nYZB1rqO+M80J1q
/w6qkbtDiQIN1Uo2aVD3YG1kldEGzyyIV+j4uCHet2OLznzyReobV5k+Nc3kk3t2
7/qpclaMVR/tHVtwPv/BoKHFUWSD49bQEBff7tl+7FV7QdA3zFE3URlYDz7vQ6EJ
8+kRVnhi/N57rFjSu3V8UC77CG81jAhx1vVy2iDofVvbEpXY1zX/gNU581hPcmQ0
h8trHn8WnQmVqT1PFqQLPAjijBg546EcKzZbV+6cFnn/27+WdakwOChFrYp+sP3D
pY0DB9upmc1XSLg6le6YrHEhRaCKj3gTinOkICywttvB5Xp89jNqcT5MahwHfA8=
=pYLW
-----END PGP SIGNATURE-----



From eliezer at ngtech.co.il  Tue Feb  3 20:39:29 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 03 Feb 2015 22:39:29 +0200
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D0DA9B.1090908@gmail.com>
References: <54D0DA9B.1090908@gmail.com>
Message-ID: <54D13201.2030302@ngtech.co.il>

Hey Yuri,

 From what I remember before squid passes data into ssl_crtd can debug 
the certificates of the requested sites.
If you will record\log them you can run a script throw them and find the 
culprit pretty fast(relatively).

What debug sections have you tried using to debug it?
Since squid uses openssl libs it's probably do not know about the CA and 
there for not much details about it.

I would say that the URL is not important in the case of an intercept proxy.
In the case it's a regular forward proxy with ssl_bump you can run throw 
the list of CONNECT requests which logged before the decryption of the 
tunnel.

What squid.conf rules are you using?

I noticed you assume that squid passes URL to ssl_crtd and it's not how 
it works.

All The Bests,
Eliezer

On 03/02/2015 16:26, Yuri Voinov wrote:
> Hi gents,
>
> I think, will be good to add advanced debug options to ssl_crtd to avoid
> this:
>
> 2015/02/03 20:21:37 kid1| clientNegotiateSSL: Error negotiating SSL
> connection on FD 28: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
> alert unknown ca (1/0)
>
> Now we have no one tools to diagnose the situations above. Excluding own
> eyes and brains. And - telepathy.




From anton at radkevich.info  Tue Feb  3 20:41:23 2015
From: anton at radkevich.info (Anton Radkevich)
Date: Tue, 3 Feb 2015 23:41:23 +0300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <54D12E3A.1040004@ngtech.co.il>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>
 <54D12E3A.1040004@ngtech.co.il>
Message-ID: <CAN_=S82VwTNk9fKVg=nC5kZOp9i08=P7DCNRwCXmS2x+AgbXtg@mail.gmail.com>

Hey Eliezer,

Thank you for your explanation, just want to clarify.

Does it mean that if I configure squid to listen https_port on port 3129
with ssl certificate, connection from a client to squid server by port 3129
will be NOT encrypted?

Anton
03 ????. 2015 ?. 23:23 ???????????? "Eliezer Croitoru" <eliezer at ngtech.co.il>
???????:

> On 03/02/2015 17:14, Anton Radkevich wrote:
>
>> so just to be clear the connection flow will look like:
>>
>> browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination
>>
>> where <Encrypted Tunnel> is probably some form of HTTPS connection for
>> support with the browser PAC
>>
>
> Hey Anton,
>
> Squid do not support socks connection or any other form of encryption.
> The known options to encrypt the connection between the client and the
> server are:
> - ssl vpn tunnel
> - ssh vpn tunnel
> - some other weird and special ways
>
> Since I am not familiar with all authentication methods I cannot answer.
> On the other hand squid offers couple ways to authenticate and I am sure
> that the choice between md5 or other sha algorithm is not important if you
> are encrypting the connection between the server and the client using a
> tunnel.
> If you wish to use some higher security levels you can use client side
> certificates and pin IP addresses to the certificates.
>
> All The Bests,
> Eliezer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/6a9a1f39/attachment.htm>

From yvoinov at gmail.com  Tue Feb  3 20:42:53 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 02:42:53 +0600
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S82VwTNk9fKVg=nC5kZOp9i08=P7DCNRwCXmS2x+AgbXtg@mail.gmail.com>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>
 <54D12E3A.1040004@ngtech.co.il>
 <CAN_=S82VwTNk9fKVg=nC5kZOp9i08=P7DCNRwCXmS2x+AgbXtg@mail.gmail.com>
Message-ID: <54D132CD.3050107@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
No. It will be encrypted to both directions.

04.02.2015 2:41, Anton Radkevich ?????:
>
> Hey Eliezer,
>
> Thank you for your explanation, just want to clarify.
>
> Does it mean that if I configure squid to listen https_port on port
3129 with ssl certificate, connection from a client to squid server by
port 3129 will be NOT encrypted?
>
> Anton
>
> 03 ????. 2015 ?. 23:23 ???????????? "Eliezer Croitoru"
<eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>> ???????:
>
>     On 03/02/2015 17:14, Anton Radkevich wrote:
>
>         so just to be clear the connection flow will look like:
>
>         browser <Encrypted Tunnel> Server <HTTP or HTTPS connection>
Destination
>
>         where <Encrypted Tunnel> is probably some form of HTTPS
connection for
>         support with the browser PAC
>
>
>     Hey Anton,
>
>     Squid do not support socks connection or any other form of encryption.
>     The known options to encrypt the connection between the client and
the server are:
>     - ssl vpn tunnel
>     - ssh vpn tunnel
>     - some other weird and special ways
>
>     Since I am not familiar with all authentication methods I cannot
answer.
>     On the other hand squid offers couple ways to authenticate and I
am sure that the choice between md5 or other sha algorithm is not
important if you are encrypting the connection between the server and
the client using a tunnel.
>     If you wish to use some higher security levels you can use client
side certificates and pin IP addresses to the certificates.
>
>     All The Bests,
>     Eliezer
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0TLMAAoJENNXIZxhPexG5oQH+wST2zGmBB/QPJCMylsN8fSt
s9cLNvlJLyOR4WI+p6qy18JJijjuFsI54Ont3x/LAFKyrmrcGUnKZhPE/3S+Vcqk
zS/V7wpA7daTmUm697Dz0B34hlrVqjoUVUsINts/JE2pRCFA09crEzsFN/oWfPrQ
e5Ks5xjwqswJYtAX33r9qwsPyYjbsxZu0nMN/bNLWYvm58sU/prvCkS9M0pDMd0m
hVNLQ7Yr5xrkfMTZuEsXV8X2iM8um0voGih8LP4GU4h7VDOai2ScvJ6yXaH+P9rF
yi+0bg0lYpmBDlLB+yXBF02ZQ9etZv8AtEFZu9FepTyFbpiecds7IfbU9MBSgNA=
=JVZ0
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/3a7714e7/attachment.htm>

From anton at radkevich.info  Tue Feb  3 20:44:12 2015
From: anton at radkevich.info (Anton Radkevich)
Date: Tue, 3 Feb 2015 23:44:12 +0300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <54D12EFB.90909@gmail.com>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>
 <54D12E3A.1040004@ngtech.co.il> <54D12EFB.90909@gmail.com>
Message-ID: <CAN_=S814202EobkmQXBiy_=NxiGpWWLH2JbTJxVuJ8a0sdqL5w@mail.gmail.com>

Yuri,

Can you please share any configuration examples? ;)
03 ????. 2015 ?. 23:27 ???????????? "Yuri Voinov" <yvoinov at gmail.com>
???????:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Eliezer,
>
> Squid can be cascaded with Privoxy+Tor. :)
>
> And then - we can route users into it using ACL's.... ;)
>
> Yep, not Squid itself. But with external services......... ;)
>
> 04.02.2015 2:23, Eliezer Croitoru ?????:
> > On 03/02/2015 17:14, Anton Radkevich wrote:
> >> so just to be clear the connection flow will look like:
> >>
> >> browser <Encrypted Tunnel> Server <HTTP or HTTPS connection> Destination
> >>
> >> where <Encrypted Tunnel> is probably some form of HTTPS connection for
> >> support with the browser PAC
> >
> > Hey Anton,
> >
> > Squid do not support socks connection or any other form of encryption.
> > The known options to encrypt the connection between the client and the
> server are:
> > - ssl vpn tunnel
> > - ssh vpn tunnel
> > - some other weird and special ways
> >
> > Since I am not familiar with all authentication methods I cannot answer.
> > On the other hand squid offers couple ways to authenticate and I am
> sure that the choice between md5 or other sha algorithm is not important
> if you are encrypting the connection between the server and the client
> using a tunnel.
> > If you wish to use some higher security levels you can use client side
> certificates and pin IP addresses to the certificates.
> >
> > All The Bests,
> > Eliezer
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU0S77AAoJENNXIZxhPexGw6QIAMUsnpSP4nYZB1rqO+M80J1q
> /w6qkbtDiQIN1Uo2aVD3YG1kldEGzyyIV+j4uCHet2OLznzyReobV5k+Nc3kk3t2
> 7/qpclaMVR/tHVtwPv/BoKHFUWSD49bQEBff7tl+7FV7QdA3zFE3URlYDz7vQ6EJ
> 8+kRVnhi/N57rFjSu3V8UC77CG81jAhx1vVy2iDofVvbEpXY1zX/gNU581hPcmQ0
> h8trHn8WnQmVqT1PFqQLPAjijBg546EcKzZbV+6cFnn/27+WdakwOChFrYp+sP3D
> pY0DB9upmc1XSLg6le6YrHEhRaCKj3gTinOkICywttvB5Xp89jNqcT5MahwHfA8=
> =pYLW
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/2529f8d2/attachment.htm>

From eliezer at ngtech.co.il  Tue Feb  3 20:45:33 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 03 Feb 2015 22:45:33 +0200
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S82VwTNk9fKVg=nC5kZOp9i08=P7DCNRwCXmS2x+AgbXtg@mail.gmail.com>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>	<54D12E3A.1040004@ngtech.co.il>
 <CAN_=S82VwTNk9fKVg=nC5kZOp9i08=P7DCNRwCXmS2x+AgbXtg@mail.gmail.com>
Message-ID: <54D1336D.8030900@ngtech.co.il>

Hey Anton,

If you use https_port with ssl certificate it will be for one of two 
options:
- interception of ssl traffic
- reverse proxy with ssl

For both cases the connection between the server and the client in the 
end will be encrypted while non of them is in a forward proxy mode and 
there for will not provide and cannot provide what you need\want.

Eliezer

On 03/02/2015 22:41, Anton Radkevich wrote:
> Hey Eliezer,
>
> Thank you for your explanation, just want to clarify.
>
> Does it mean that if I configure squid to listen https_port on port 3129
> with ssl certificate, connection from a client to squid server by port 3129
> will be NOT encrypted?
>
> Anton




From yvoinov at gmail.com  Tue Feb  3 20:48:24 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 02:48:24 +0600
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D13201.2030302@ngtech.co.il>
References: <54D0DA9B.1090908@gmail.com> <54D13201.2030302@ngtech.co.il>
Message-ID: <54D13418.7090601@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 

04.02.2015 2:39, Eliezer Croitoru ?????:
> Hey Yuri,
>
> From what I remember before squid passes data into ssl_crtd can debug
the certificates of the requested sites.
> If you will record\log them you can run a script throw them and find
the culprit pretty fast(relatively).
>
> What debug sections have you tried using to debug it?
> Since squid uses openssl libs it's probably do not know about the CA
and there for not much details about it.
OpenSSL knows about CA's. With capath= option in https_port. It uses it
to verify connection from cache to server.
>
> I would say that the URL is not important in the case of an intercept
proxy.
It is important to localize CA's problem. When I can see problem URL - I
can look ath this and find, which CA was used.
> In the case it's a regular forward proxy with ssl_bump you can run throw the list of CONNECT
requests which logged before the decryption of the tunnel.
I use interception proxy. BTW, with over 100 requests per second and
corellation analyzes of two logs? access.log and cache.log? Bad idea, I
think.
>
> What squid.conf rules are you using?
>
> I noticed you assume that squid passes URL to ssl_crtd and it's not
how it works.
This is no matter. I want to find only easy way to catch problem SSL
connections through Squid.

>
> All The Bests,
> Eliezer
>
> On 03/02/2015 16:26, Yuri Voinov wrote:
>> Hi gents,
>>
>> I think, will be good to add advanced debug options to ssl_crtd to avoid
>> this:
>>
>> 2015/02/03 20:21:37 kid1| clientNegotiateSSL: Error negotiating SSL
>> connection on FD 28: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
>> alert unknown ca (1/0)
>>
>> Now we have no one tools to diagnose the situations above. Excluding own
>> eyes and brains. And - telepathy.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0TQXAAoJENNXIZxhPexGmPEH/iHVCwE821tkAxdwtHlKaCS3
wobvZVx9HAx7Q2C3S7VNR1wgtysG0psQd6P9UX6qniJpZAugZ5R27oLh0xDLtJgt
KZ7Uz0lpIkwTP5pJNmNAqA7vvPdJX6mkEEBK9ENBDGpjHo4wVvaRNfn+XXx/dfhn
k2m/ial6q0ZZ6WtLltjj0Fq73MdatQJefSWLPatTj7eMHDeACSxL/A0Me8EoyE/v
uYcTpIf2C/jy8A3x9DLGZMM+RXvtIWBJTR1ct3PrZMMLuaw0o0XAzbYPNY05RK7b
vyCuY2Ua+NrcTw0LX05vhdCwJnlvK6rh/Vi6M3yEivAkp0itjv2ZbpM3pNFD+NU=
=ajrM
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Tue Feb  3 21:12:46 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 03:12:46 +0600
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S814202EobkmQXBiy_=NxiGpWWLH2JbTJxVuJ8a0sdqL5w@mail.gmail.com>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>	<54D12E3A.1040004@ngtech.co.il>	<54D12EFB.90909@gmail.com>
 <CAN_=S814202EobkmQXBiy_=NxiGpWWLH2JbTJxVuJ8a0sdqL5w@mail.gmail.com>
Message-ID: <54D139CE.9010809@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Sure. :)

This way:

http://yvoinov.blogspot.com/2014/08/squid-tor-privoxy-transparent-dns.html
http://yvoinov.blogspot.com/2014/08/squid-tor-privoxy-transparent-dns_19.html

:)

04.02.2015 2:44, Anton Radkevich ?????:
>
> Yuri,
>
> Can you please share any configuration examples? ;)
>
> 03 ????. 2015 ?. 23:27 ???????????? "Yuri Voinov" <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> ???????:
>
>
> Eliezer,
>
> Squid can be cascaded with Privoxy+Tor. :)
>
> And then - we can route users into it using ACL's.... ;)
>
> Yep, not Squid itself. But with external services......... ;)
>
> 04.02.2015 2:23, Eliezer Croitoru ?????:
> > On 03/02/2015 17:14, Anton Radkevich wrote:
> >> so just to be clear the connection flow will look like:
> >>
> >> browser <Encrypted Tunnel> Server <HTTP or HTTPS connection>
Destination
> >>
> >> where <Encrypted Tunnel> is probably some form of HTTPS connection for
> >> support with the browser PAC
>
> > Hey Anton,
>
> > Squid do not support socks connection or any other form of encryption.
> > The known options to encrypt the connection between the client and the
> server are:
> > - ssl vpn tunnel
> > - ssh vpn tunnel
> > - some other weird and special ways
>
> > Since I am not familiar with all authentication methods I cannot answer.
> > On the other hand squid offers couple ways to authenticate and I am
> sure that the choice between md5 or other sha algorithm is not important
> if you are encrypting the connection between the server and the client
> using a tunnel.
> > If you wish to use some higher security levels you can use client side
> certificates and pin IP addresses to the certificates.
>
> > All The Bests,
> > Eliezer
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0TnOAAoJENNXIZxhPexG0KoH/0oD2VHwxS0YrE9tb/lohY7h
1sTo6/j9iKuPY97wDjNxGKl3wcmHmNF0QTGK5z60i9oj2FmjE4wXCNv2MehNjlIc
gZc+RlQlTdFEzKk2wQAWgflNg5YWw8Q2y59ApF/nhj2rQVdA1J+pVSkY8cnRSDq+
zjua8ks98+8qJEGDdgCBXeTtTYyfr0L9T7tPIHi7AZdDUMWu26+mY+F7pQVB03sE
r2ebSXlzhUXW6lNmIOGufQdUin1unTSSyoHVpEHrXNaYZIEB8EUjrFsME9W4E7M5
wALBLprKU6ZbfMljuTnG44LfXHYMuKnSLwyKQ0nB020KAdNh3CVNpgDbYR8lEp4=
=tvcQ
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/2bf9ee18/attachment.htm>

From anton at radkevich.info  Tue Feb  3 21:30:43 2015
From: anton at radkevich.info (Anton Radkevich)
Date: Wed, 4 Feb 2015 00:30:43 +0300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <54D1336D.8030900@ngtech.co.il>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>
 <54D12E3A.1040004@ngtech.co.il>
 <CAN_=S82VwTNk9fKVg=nC5kZOp9i08=P7DCNRwCXmS2x+AgbXtg@mail.gmail.com>
 <54D1336D.8030900@ngtech.co.il>
Message-ID: <CAN_=S83fTZ3r_MLQq+C70uNTQEjnihsyWPyrMSyeKzV+BVDsdw@mail.gmail.com>

Guys,

I just need an HTTPS proxy that can handle both http and https connections
for authorised clients only. I tried to configure something like it's
described here
http://www.mail-archive.com/squid-users at squid-cache.org/msg93592.html
Forward HTTPs proxy with digest_pw_auth for example.

But I am getting the same error clientNegotiateSSL: Error negotiating SSL
connection on FD 6: error:1407609C:SSL routines:SSL23_GET_CLIENT_HELLO:http
request (1/-1) if I try to open a website (http or https) with proxy
enabled on browser settings: protocol https, server proxy-squid.com, port
3129, test:test (user/password)

If I understood correctly from our communication its not possible to
configure squid like it described above. Or ther

browser(proxy settings: protocol - https, server -proxy-squid.com, port
-3129, test:test (user/password)) <------> Squid Server (https_port 3129
with certificate)<--------HTTP or HTTPS connection-------> Destination

Description of the connection flow:
1. a client set proxy settings of his browser settings: https, server:port,
user:password
2. a clients credentials were verified by squid server,  browser asks the
proxy to establish a virtual tunnel between itself and remote server
3. when a client enter https://example.com or http://example.com then
browser sends encrypted data through the squid proxy

Anton


2015-02-03 23:45 GMT+03:00 Eliezer Croitoru <eliezer at ngtech.co.il>:

> Hey Anton,
>
> If you use https_port with ssl certificate it will be for one of two
> options:
> - interception of ssl traffic
> - reverse proxy with ssl
>
> For both cases the connection between the server and the client in the end
> will be encrypted while non of them is in a forward proxy mode and there
> for will not provide and cannot provide what you need\want.
>
> Eliezer
>
>
> On 03/02/2015 22:41, Anton Radkevich wrote:
>
>> Hey Eliezer,
>>
>> Thank you for your explanation, just want to clarify.
>>
>> Does it mean that if I configure squid to listen https_port on port 3129
>> with ssl certificate, connection from a client to squid server by port
>> 3129
>> will be NOT encrypted?
>>
>> Anton
>>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/17011737/attachment.htm>

From yvoinov at gmail.com  Tue Feb  3 21:35:20 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 03:35:20 +0600
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S83fTZ3r_MLQq+C70uNTQEjnihsyWPyrMSyeKzV+BVDsdw@mail.gmail.com>
References: <CAN_=S826_ss-wTLDDhDm_jkDY6N4uQYvU154U4L=x8zaVvkRTg@mail.gmail.com>	<54D12E3A.1040004@ngtech.co.il>	<CAN_=S82VwTNk9fKVg=nC5kZOp9i08=P7DCNRwCXmS2x+AgbXtg@mail.gmail.com>	<54D1336D.8030900@ngtech.co.il>
 <CAN_=S83fTZ3r_MLQq+C70uNTQEjnihsyWPyrMSyeKzV+BVDsdw@mail.gmail.com>
Message-ID: <54D13F18.60901@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 

04.02.2015 3:30, Anton Radkevich ?????:
> Guys,
>
> I just need an HTTPS proxy that can handle both http and https
connections for authorised clients only. I tried to configure something
like it's described here
http://www.mail-archive.com/squid-users at squid-cache.org/msg93592.html
> Forward HTTPs proxy with digest_pw_auth for example.
>
> But I am getting the same error clientNegotiateSSL: Error negotiating
SSL connection on FD 6: error:1407609C:SSL
routines:SSL23_GET_CLIENT_HELLO:http request (1/-1) if I try to open a
website (http or https) with proxy enabled on browser settings: protocol
https, server proxy-squid.com <http://proxy-squid.com>, port 3129,
test:test (user/password)
Hmmmmm. This means you try to put HTTP requests over HTTPS port. You
need different Squid ports for HTTP and HTTPS. I'm afraid, you cannot
pass both protocols over one port.

>
> If I understood correctly from our communication its not possible to
configure squid like it described above. Or ther
>
> browser(proxy settings: protocol - https, server -proxy-squid.com
<http://proxy-squid.com>, port -3129, test:test (user/password))
<------> Squid Server (https_port 3129 with certificate)<--------HTTP or
HTTPS connection-------> Destination
>
> Description of the connection flow:
> 1. a client set proxy settings of his browser settings: https,
server:port, user:password
> 2. a clients credentials were verified by squid server,  browser asks
the proxy to establish a virtual tunnel between itself and remote server
> 3. when a client enter https://example.com or http://example.com then
browser sends encrypted data through the squid proxy
>
> Anton
>
>
> 2015-02-03 23:45 GMT+03:00 Eliezer Croitoru <eliezer at ngtech.co.il
<mailto:eliezer at ngtech.co.il>>:
>
>     Hey Anton,
>
>     If you use https_port with ssl certificate it will be for one of
two options:
>     - interception of ssl traffic
>     - reverse proxy with ssl
>
>     For both cases the connection between the server and the client in
the end will be encrypted while non of them is in a forward proxy mode
and there for will not provide and cannot provide what you need\want.
>
>     Eliezer
>
>
>     On 03/02/2015 22:41, Anton Radkevich wrote:
>
>         Hey Eliezer,
>
>         Thank you for your explanation, just want to clarify.
>
>         Does it mean that if I configure squid to listen https_port on
port 3129
>         with ssl certificate, connection from a client to squid server
by port 3129
>         will be NOT encrypted?
>
>         Anton
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0T8YAAoJENNXIZxhPexGdE4H/0/zBOkDtAp0+CaDHXdSUDqu
z96bEorW7rLEXusohVXImuevgSWnyxvpUmsJiN/0zu26MzDHQ4jc0XD1qmM7YZ5y
YQ1gFnHdemLLN1fwxWqsLepXPKsZkEuM8oon8kvXxNn6xwCpN7COyeXCGA7e0+FO
p3qcF0SC8vIge0NDFzf8uhh8utV/5RaTBKUNz5tsNxy861Qp+YliMltDYUgIGcwD
wwEHvSJhtedkQ69D1BDZSMKAILipQfDp4CZt4R02TrkGG4OZMK7c02NO9CCbJsLp
p4LERF66bClc/p667P+XFZpGOKmMbOEOivLFVgzGhVC56CwQitCHKjUHMbVi+hg=
=uxsh
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/5f455ec9/attachment.htm>

From squid3 at treenet.co.nz  Wed Feb  4 03:03:42 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 04 Feb 2015 16:03:42 +1300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <CAN_=S82yKKDtSXJ2jvCGEz-dJQ__+xwvKF-eehOR=-zY1EPy7A@mail.gmail.com>
References: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>
 <54D12849.1060909@gmail.com>
 <CAN_=S83L75K=VUYEFHLDR+j+2YB76=mfgYZKzpi2JVaosyrv+g@mail.gmail.com>
 <54D12BAC.8000705@gmail.com>
 <CAN_=S82yKKDtSXJ2jvCGEz-dJQ__+xwvKF-eehOR=-zY1EPy7A@mail.gmail.com>
Message-ID: <54D18C0E.70607@treenet.co.nz>

On 4/02/2015 9:20 a.m., Anton Radkevich wrote:
> Yuri,
> 
> I'd like to allow or deny access for a client before establishing of
> encrypted channel to proxy server using an authentication method of squid
> proxy.


I think you and Yuri are talking past each other on this.

This page has what you want to know
<http://wiki.squid-cache.org/Features/HTTPS>. Yuri was talking about
section-2 connections, but I read your query as being closer to
section-4 connections.


> Can I setup any authentication method for https forward proxy? If yes, is
> it possible to use more secure hash algorithms than old md5?

Squid does Basic, Digest, NTLM, Negotiate, and (with a patch) Bearer.

Its not clear what you mean about MD5. Do you have a specific auth
helper like NCSA storing passwords using that hash?

Amos


From squid3 at treenet.co.nz  Wed Feb  4 03:16:41 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 04 Feb 2015 16:16:41 +1300
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D11872.6090801@gmail.com>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
 <54D11872.6090801@gmail.com>
Message-ID: <54D18F19.7020504@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 4/02/2015 7:50 a.m., Yuri Voinov wrote:
> 
> Now I have:
> 
> root @ cthulhu /etc/opt/csw/ssl/certs # ls -al *.pem|wc -l 210
> 
> root and intermediate CA's. Most known I can found.
> 
> Note: all of them was wound in different places - in addition with 
> Mozilla's bundle, shipped with OpenSSL.
> 
> How I can found, which is absent?

Depends on your definition of "absent". If one was being really
serious about the security the Trusted CA list would be empty.**

All the domains using DANE and TLSA DNS records? I am hoping someday
to have Squid fetch and use those instead of the Trusted CA, but that
is a while off. (hint, hint sponsorship welcome etc. and so on).

> 
> And how to support this heap? In practice? Manually with CLI
> openssl? Ok, but how to identify problem URL, when Squid's load
> over 100 requests per second?

With the cert validator helper I think. Probably something custom.


** The point of the word "Trusted" in Trusted CA is that they have
passed through some difficult criteria to get listed and installed.
Just grabbing CA certs from all over the place is risking a huge
amount. The major well-known security flaw in the whole TLS/SSL system
is that any one of the Trusted CAs is capable of forging signatures on
other CAs clients. So dodgy list entries is a VERY big deal.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU0Y8YAAoJELJo5wb/XPRjYzkH/0n9xKM6oi8Uk3h4PkJVHYg6
2fqVwPkXiSiqtxuD/DQ/IYJ04UQ0gxKz7KCWt4LaWoTBoAh8GdGnWciGCIcx1eYC
GUhxOWP04ak1CSTaOOsUzAnXofp5Vc3pqaYHZVVohzE4KNvHzSEoOTGEwZpF2gtP
yK559mi1g0wH8NVjzYaO/0oMEhIPuxjr2HyLBb3ZUWMG63JtlpQX35KGGm93A5Ws
/03NhWs/iZDLpPvFivm3WxZme85Hl4XIbsWXp/AJWgK/jqr/SpFjUBs11CclTd9n
zsTGiMMC+3RX/x1V/wzSrZ2wIdyAcfId2GRLKM4JaK7ABb0g3AMhQMesRv5JkDk=
=Sgg5
-----END PGP SIGNATURE-----


From dig at digcorp.net  Wed Feb  4 05:44:37 2015
From: dig at digcorp.net (Daniel Greenwald)
Date: Tue, 3 Feb 2015 21:44:37 -0800
Subject: [squid-users] Squid Authentication
In-Reply-To: <54CFA300.9030201@gmail.com>
References: <CAGycgFh6JrrWUdk9a=CaGyx-uAOGYg=8MJ5v1-3Ccp=5CbOe_A@mail.gmail.com>
 <54CF4962.7020202@treenet.co.nz> <1422885907362.27721@diladele.com>
 <54CF8A62.3040605@treenet.co.nz> <1422888481228.45205@diladele.com>
 <54CFA300.9030201@gmail.com>
Message-ID: <CAOsHgtvPF_CWRq93w7nxBNy1thXuYfTTG5B1G36AKk1uRBfn_w@mail.gmail.com>

I have a windows server running old 2.7 for simple reason that mswin
negotiate auth works totally flawless for seamless AD authentication on ALL
browsers . Vs with  samba/heimdal on *nix server users would randomly get
annoying logon popups which I could not eliminate.  It may be old but it
just works!




-----------
Daniel I Greenwald



On Mon, Feb 2, 2015 at 8:17 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Harry up, Raf :)
>
> I'm waiting for 3.5 Win64 for my notebook :)
>
> And don't forget SSL Bump ! :)
>
> 02.02.2015 20:47, Rafael Akchurin ?????:
> > Eldar will send soon as we finish some initial testing.
> > Raf
> >
> >
> > ________________________________________
> > From: Amos Jeffries <squid3 at treenet.co.nz>
> > Sent: Monday, February 2, 2015 3:32 PM
> > To: Rafael Akchurin; squid-users at lists.squid-cache.org
> > Subject: Re: [squid-users] Squid Authentication
> >
> > On 3/02/2015 3:04 a.m., Rafael Akchurin wrote:
> >> Hello Amos,
> >>
> >> We will soon be able to have latest 3.5 built for Cygwin x64
> (hopefully).
> >>
> >
> > Yay! Are there any patches I can merge that will help minimize the
> > tracking work for future releases?
> >
> > Amos
> >
> >
> >> Rafael
> >>
> >> ________________________________________
> >> From: Amos Jeffries
> >>
> >> On 2/02/2015 5:27 p.m., Raju M K wrote:
> >>> Need squid Authentication syntax for local users in Windows 7/8
> workgroup
> >>> Presently using squid 2.7 stable 8
> >>
> >> 2.7 was end-of-lifed *5 years ago*. Please upgrade.
> >> http://www.squid-cache.org/Versions/
> >>
> >> PS. I know we dont have a native windows version available of anything
> >> newer (though Cygwin does provide 3.2/3.3 builds). But there is no
> >> reason for Squid being tied down onto a Windows server while servicing
> >> Windows users, and many reasons for it to *not* be.
> >>
> >> Amos
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users
> >>
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJUz6L/AAoJENNXIZxhPexGRPsH/AhWdMapx+a/k9iS+QnzHp/w
> hQHy0HBHS4V6pQyqcWOmBxgq14SLxLUTwe8th6EavBDAERo3xstq5dt/Ped35Gg0
> gK1YjT3io/WCfqs2nIzvp2UycVmbQjt5Yld1hGlPEoP5H4WaulrffkaSzdZUJOlf
> 0XYPTHRnQiNFb2g6f37zbQyZmhWkkx9rTIobzuMAvnLcmXACFQjv7O0pY+pbS0nO
> q4S8ou7vfdhTfCkXSUd+jTqQ3dL8Vi3ZlSC8QDxDUEXCZPkBy8iHJR3pl1iRQA6u
> ZLomlz1pr6cHjr6AURw5rGqPMmt4DtqJskS4yrd/Ky/rIlrGTFyhltJNvtuC2wo=
> =k1L/
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/d23f3c12/attachment.htm>

From dig at digcorp.net  Wed Feb  4 05:47:50 2015
From: dig at digcorp.net (Daniel Greenwald)
Date: Tue, 3 Feb 2015 21:47:50 -0800
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D18F19.7020504@treenet.co.nz>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
 <54D11872.6090801@gmail.com> <54D18F19.7020504@treenet.co.nz>
Message-ID: <CAOsHgtv=9JVQhpPO-=9W9haJwnQn=b-cA2S7aRuVu_hk_gBevg@mail.gmail.com>

Amos Wrote:
The major well-known security flaw in the whole TLS/SSL system
is that any one of the Trusted CAs is capable of forging signatures on
other CAs clients.

And happens to be one that squid desperately needs to remain in order to
continue ssl bumping..


-----------
Daniel I Greenwald



On Tue, Feb 3, 2015 at 7:16 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 4/02/2015 7:50 a.m., Yuri Voinov wrote:
> >
> > Now I have:
> >
> > root @ cthulhu /etc/opt/csw/ssl/certs # ls -al *.pem|wc -l 210
> >
> > root and intermediate CA's. Most known I can found.
> >
> > Note: all of them was wound in different places - in addition with
> > Mozilla's bundle, shipped with OpenSSL.
> >
> > How I can found, which is absent?
>
> Depends on your definition of "absent". If one was being really
> serious about the security the Trusted CA list would be empty.**
>
> All the domains using DANE and TLSA DNS records? I am hoping someday
> to have Squid fetch and use those instead of the Trusted CA, but that
> is a while off. (hint, hint sponsorship welcome etc. and so on).
>
> >
> > And how to support this heap? In practice? Manually with CLI
> > openssl? Ok, but how to identify problem URL, when Squid's load
> > over 100 requests per second?
>
> With the cert validator helper I think. Probably something custom.
>
>
> ** The point of the word "Trusted" in Trusted CA is that they have
> passed through some difficult criteria to get listed and installed.
> Just grabbing CA certs from all over the place is risking a huge
> amount. The major well-known security flaw in the whole TLS/SSL system
> is that any one of the Trusted CAs is capable of forging signatures on
> other CAs clients. So dodgy list entries is a VERY big deal.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJU0Y8YAAoJELJo5wb/XPRjYzkH/0n9xKM6oi8Uk3h4PkJVHYg6
> 2fqVwPkXiSiqtxuD/DQ/IYJ04UQ0gxKz7KCWt4LaWoTBoAh8GdGnWciGCIcx1eYC
> GUhxOWP04ak1CSTaOOsUzAnXofp5Vc3pqaYHZVVohzE4KNvHzSEoOTGEwZpF2gtP
> yK559mi1g0wH8NVjzYaO/0oMEhIPuxjr2HyLBb3ZUWMG63JtlpQX35KGGm93A5Ws
> /03NhWs/iZDLpPvFivm3WxZme85Hl4XIbsWXp/AJWgK/jqr/SpFjUBs11CclTd9n
> zsTGiMMC+3RX/x1V/wzSrZ2wIdyAcfId2GRLKM4JaK7ABb0g3AMhQMesRv5JkDk=
> =Sgg5
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150203/26711a15/attachment.htm>

From omidkosari at yahoo.com  Wed Feb  4 06:24:04 2015
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 3 Feb 2015 22:24:04 -0800 (PST)
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
	squid.
In-Reply-To: <54D10FB3.7090505@urlfilterdb.com>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il> <1422967529217-4669494.post@n4.nabble.com>
 <54D0CD55.5060302@urlfilterdb.com> <1422975403825-4669503.post@n4.nabble.com>
 <54D10FB3.7090505@urlfilterdb.com>
Message-ID: <1423031044701-4669531.post@n4.nabble.com>

The only reason for extend is more capacity .
Currently there is no problem with current setup except capacity .
I can replace each SSD with new 500GB which doubles the capacity and it is
not enough . and old SSDs will be unusable . So i prefer a long term
solution like NAS .


Current spec of squid boxes are core i3 (with current 3.1.20 version one
core utilizes) and 16GB of ram . so far so good .



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Hypothetically-comparing-SATA-SAS-to-NAS-SAN-for-squid-tp4664350p4669531.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Jason_Haar at trimble.com  Wed Feb  4 06:32:50 2015
From: Jason_Haar at trimble.com (Jason Haar)
Date: Wed, 4 Feb 2015 19:32:50 +1300
Subject: [squid-users] Alert unknown CA
In-Reply-To: <CAOsHgtv=9JVQhpPO-=9W9haJwnQn=b-cA2S7aRuVu_hk_gBevg@mail.gmail.com>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
 <54D11872.6090801@gmail.com> <54D18F19.7020504@treenet.co.nz>
 <CAOsHgtv=9JVQhpPO-=9W9haJwnQn=b-cA2S7aRuVu_hk_gBevg@mail.gmail.com>
Message-ID: <54D1BD12.6050406@trimble.com>

On 04/02/15 18:47, Daniel Greenwald wrote:
> And happens to be one that squid desperately needs to remain in order
> to continue ssl bumping..
...and is one that diminishes in value as cert pinning becomes more
popular...

It's a tough life: on the one hand we want to do TLS intercept in order
to do content filtering of HTTPS (because the bad guys are deliberately
putting more and more malware onto HTTPS websites), and yet on the other
hand we all want some things to be private.

Bring back RFC3514, then all of this would be easy!!!

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From rprasad at pranastudios.com  Wed Feb  4 06:38:13 2015
From: rprasad at pranastudios.com (Rajkumar Prasad)
Date: Wed, 4 Feb 2015 12:08:13 +0530
Subject: [squid-users] help with regard to http/https filtering
Message-ID: <061301d04045$319fed30$94dfc790$@pranastudios.com>

Hi Everyone,

 

Have been working on very basic squid configurations and need a small help.
We have done this setup for everyone to provide very limited access on
restricted no of websites. My question here is that, is there a way we can
control entire certain part of URL to be getting dropped instead of whole
website and other contents. For e.g.

 

We need to have access to http://renderman.pixar.com however we want to
control an internal link within it
"https://renderman.pixar.com/forum/download.php &
https://renderman.pixar.com/forum/teamviewer.php" . I see these are HTTPS
enabled portal and maybe I am unable to. My intention is to block these
specific URL's, keeping rest other navigation working. I tried url_regex and
urlpath_regex and those are not seems to be working.

 

See if you can add a little help.

 

Thanks 
Rajkumar

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/1925d9c0/attachment.htm>

From pavel.kazlenka at measurement-factory.com  Wed Feb  4 08:41:58 2015
From: pavel.kazlenka at measurement-factory.com (Pavel Kazlenka)
Date: Wed, 04 Feb 2015 11:41:58 +0300
Subject: [squid-users] help with regard to http/https filtering
In-Reply-To: <061301d04045$319fed30$94dfc790$@pranastudios.com>
References: <061301d04045$319fed30$94dfc790$@pranastudios.com>
Message-ID: <54D1DB56.5060105@measurement-factory.com>

Hi Rajkumar,

You need SSLBump feature (http://wiki.squid-cache.org/Features/SslBump) 
configured in order to use url_regex acl against https traffic.

Best wishes,
Pavel

On 02/04/2015 09:38 AM, Rajkumar Prasad wrote:
>
> Hi Everyone,
>
> Have been working on very basic squid configurations and need a small 
> help. We have done this setup for everyone to provide very limited 
> access on restricted no of websites. My question here is that, is 
> there a way we can control entire certain part of URL to be getting 
> dropped instead of whole website and other contents. For e.g.
>
> We need to have access to http://renderman.pixar.com however we want 
> to control an internal link within it 
> ?https://renderman.pixar.com/forum/download.php & 
> https://renderman.pixar.com/forum/teamviewer.php? . I see these are 
> HTTPS enabled portal and maybe I am unable to. My intention is to 
> block these specific URL?s, keeping rest other navigation working. I 
> tried url_regex and urlpath_regex and those are not seems to be working.
>
> See if you can add a little help.
>
> Thanks
> Rajkumar
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/433afe67/attachment.htm>

From yvoinov at gmail.com  Wed Feb  4 08:52:47 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 14:52:47 +0600
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D18F19.7020504@treenet.co.nz>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
 <54D11872.6090801@gmail.com> <54D18F19.7020504@treenet.co.nz>
Message-ID: <54D1DDDF.20901@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 

04.02.2015 9:16, Amos Jeffries ?????:
> On 4/02/2015 7:50 a.m., Yuri Voinov wrote:
>
> > Now I have:
>
> > root @ cthulhu /etc/opt/csw/ssl/certs # ls -al *.pem|wc -l 210
>
> > root and intermediate CA's. Most known I can found.
>
> > Note: all of them was wound in different places - in addition with
> > Mozilla's bundle, shipped with OpenSSL.
>
> > How I can found, which is absent?
>
> Depends on your definition of "absent". If one was being really
> serious about the security the Trusted CA list would be empty.**
It not my definition. Squid tells this. :) It indicates it as unknown CA.

>
> All the domains using DANE and TLSA DNS records? I am hoping someday
> to have Squid fetch and use those instead of the Trusted CA, but that
> is a while off. (hint, hint sponsorship welcome etc. and so on).
>
>
> > And how to support this heap? In practice? Manually with CLI
> > openssl? Ok, but how to identify problem URL, when Squid's load
> > over 100 requests per second?
>
> With the cert validator helper I think. Probably something custom.
Agrrrrrrrrrrrrrrhhhhhhhhhhhhhhhhh........ Will think.
>
>
> ** The point of the word "Trusted" in Trusted CA is that they have
> passed through some difficult criteria to get listed and installed.
> Just grabbing CA certs from all over the place is risking a huge
> amount. The major well-known security flaw in the whole TLS/SSL system
> is that any one of the Trusted CAs is capable of forging signatures on
> other CAs clients. So dodgy list entries is a VERY big deal.
Agreed. Of course, CA's cant be get anywhere. As minimum, from
provider's sites.

On the other hand, every of them cannot be checked (and could not be) in
deep. We just get it and trast. This is wrong concept, but we haven't
anything else....

>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0d3fAAoJENNXIZxhPexGozoH/Ri2ljZrROkZ+9RLqr6gY0U+
ckpX1bZUp3hmOw+i6fdASJHL2Wj4mXe7LMvTOr9P7oKiW8H0r/sAfh2zlcss2WIA
aQA+TntAyWJG66NH0MBJbTWtnlmDGMV11i2g5B30jUg7G1KPIAGd2IW1fi/Uf3Kb
bNuT5lFz6peG2l04qMjwY26xhaM+IQIh0b1JyKtpiqNnwjLw/gLpESvJB1Ah8LST
CgLsM+j5w/2sTPeg/K+SIvYwfRpng/XgvedONY0eL6RTWY1xnWS4zWmn29ZmRqkx
tAJZVHHQl4NhpJ8ulYUi1ILgWLK2FYIqTZ0ctXOpRBmNwGqPFhvA1SY7K43d5ew=
=HwCL
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/c87a8d08/attachment.htm>

From anton at radkevich.info  Wed Feb  4 09:05:20 2015
From: anton at radkevich.info (Anton Radkevich)
Date: Wed, 4 Feb 2015 12:05:20 +0300
Subject: [squid-users] SQUID3 HTTPs forward proxy and sha256/512
	authentication
In-Reply-To: <54D18C0E.70607@treenet.co.nz>
References: <CAN_=S82TR0y-e6nXeMcX1xkuesb2ioU-RbbkXuKe6ZHh9n91-w@mail.gmail.com>
 <54D12849.1060909@gmail.com>
 <CAN_=S83L75K=VUYEFHLDR+j+2YB76=mfgYZKzpi2JVaosyrv+g@mail.gmail.com>
 <54D12BAC.8000705@gmail.com>
 <CAN_=S82yKKDtSXJ2jvCGEz-dJQ__+xwvKF-eehOR=-zY1EPy7A@mail.gmail.com>
 <54D18C0E.70607@treenet.co.nz>
Message-ID: <CAN_=S81Tr_sv64Vk=fibS3khvDgXBXY2r7p_vz1BoVMPAQ_PGQ@mail.gmail.com>

Guys,

I just need an HTTPS proxy that can handle both http and https connections
for authorised clients only. I tried to configure something like it's
described here
http://www.mail-archive.com/squid-users at squid-cache.org/msg93592.html
Forward HTTPs proxy with digest_pw_auth for example.

But I am getting the same error clientNegotiateSSL: Error negotiating SSL
connection on FD 6: error:1407609C:SSL routines:SSL23_GET_CLIENT_HELLO:http
request (1/-1) if I try to open a website (http or https) with proxy
enabled on browser settings: protocol https, server proxy-squid.com, port
3129, test:test (user/password)

If I understood correctly from our communication its not possible to
configure squid like it described above. Or ther

browser(proxy settings: protocol - https, server -proxy-squid.com, port
-3129, test:test (user/password)) <------> Squid Server (https_port 3129
with certificate)<--------HTTP or HTTPS connection-------> Destination

Description of the connection flow:
1. a client set proxy settings of his browser settings: https, server:port,
user:password
2. a clients credentials were verified by squid server,  browser asks the
proxy to establish a virtual tunnel between itself and remote server
3. when a client enter https://example.com or http://example.com then
browser sends encrypted data through the squid proxy

Is it possible?

Thanks,
Anton

2015-02-04 6:03 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 4/02/2015 9:20 a.m., Anton Radkevich wrote:
> > Yuri,
> >
> > I'd like to allow or deny access for a client before establishing of
> > encrypted channel to proxy server using an authentication method of squid
> > proxy.
>
>
> I think you and Yuri are talking past each other on this.
>
> This page has what you want to know
> <http://wiki.squid-cache.org/Features/HTTPS>. Yuri was talking about
> section-2 connections, but I read your query as being closer to
> section-4 connections.
>
>
> > Can I setup any authentication method for https forward proxy? If yes, is
> > it possible to use more secure hash algorithms than old md5?
>
> Squid does Basic, Digest, NTLM, Negotiate, and (with a patch) Bearer.
>
> Its not clear what you mean about MD5. Do you have a specific auth
> helper like NCSA storing passwords using that hash?
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/a10499b3/attachment.htm>

From ansalonistefano at gmail.com  Wed Feb  4 10:06:28 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Wed, 4 Feb 2015 11:06:28 +0100
Subject: [squid-users] Problems with squid 3.5.1
Message-ID: <CALkTbdfmidm1GnT0ywDMkorbb1ToA-1o9DUpe5kwb5YS=j0zgw@mail.gmail.com>

Hi, first message here.

I have some issue with squid 3.5.1: sometimes the browser loads the page
partially (for example: header/footer without styles or missing images);
other times the browser display a "cannot connect to the proxy (proxy
refused connection)" page.
The problem seems to appear more often with https pages (squid is
configured for ssl_bump).
With 3.4.10 everything was good (I ported the config file to 3.5.1 without
modifications, except for changed/deleted keywords/tags).


Any clue on possible cause?

Thanks in advance.


PS: if you need to know configuration values and/or other info, just ask.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/24770891/attachment.htm>

From fredbmail at free.fr  Wed Feb  4 10:22:32 2015
From: fredbmail at free.fr (FredB)
Date: Wed, 4 Feb 2015 11:22:32 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbdfmidm1GnT0ywDMkorbb1ToA-1o9DUpe5kwb5YS=j0zgw@mail.gmail.com>
Message-ID: <733907678.332159342.1423045352540.JavaMail.root@zimbra4-e1.priv.proxad.net>



> I have some issue with squid 3.5.1: sometimes the browser loads the
> page partially (for example: header/footer without styles or missing
> images); other times the browser display a "cannot connect to the
> proxy (proxy refused connection)" page.
> The problem seems to appear more often with https pages (squid is
> configured for ssl_bump).
> With 3.4.10 everything was good (I ported the config file to 3.5.1
> without modifications, except for changed/deleted keywords/tags).
> 

Yes I saw exactly the same thing, but in my case without SSLBump


----

Regards,

Fred

http://numsys.eu
http://e2guardian.org


From Andreas.Reschke at mahle.com  Wed Feb  4 11:19:09 2015
From: Andreas.Reschke at mahle.com (Andreas.Reschke at mahle.com)
Date: Wed, 4 Feb 2015 12:19:09 +0100
Subject: [squid-users] Order of http_access allow/deny
Message-ID: <OF2562A001.22F6DDA1-ONC1257DE2.003D6208-C1257DE2.003E2E16@mahle.com>

Hi there,
Is there a order of http_access allow/deny? If I activate "http_access 
deny !chkglwebhttp" nobody can use the proxy, squid allways ask for user 
and password (user and password is correct)

######
acl chkglwebhttp external LDAPLookup GGPY-LO-Web-Http
acl sellingUser external LDAPLookup GGPY-LO-Web-Allowed-Selling
acl socialUser external LDAPLookup GGPY-LO-Web-Allowed-Social
acl allforbUser external LDAPLookup GGPY-LO-Web-Allowed-All
acl ftpputUser external LDAPLookup GGPY-LO-Web-Ftp-Put
acl loggingUser external LDAPLookup GGPY-LO-Web-Log-User
acl auth proxy_auth REQUIRED
acl permitt_ips src 10.143.10.247/32
acl FTP proto FTP
acl PUT method PUT

# whitelisten
http_access allow open-sites all
http_access allow localhost
http_access allow permitt_ips !denied-sites !social-sites
http_access allow indien DAY
http_access deny indien
#http_access deny !chkglwebhttp
http_access allow selling-sites sellingUser
http_access allow social-sites socialUser

http_access allow denied-sites allforbUser
http_access deny denied-sites all

http_access allow FTP PUT
http_access deny FTP PUT

http_access allow all auth
http_access allow auth

http_access deny all
######

Mit freundlichen Gr??en / Kind regards

Mr. Andreas Reschke
andreas.reschke at mahle.com, http://www.mahle.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/bf11cc29/attachment.htm>

From leolistas at solutti.com.br  Wed Feb  4 12:13:49 2015
From: leolistas at solutti.com.br (Leonardo Rodrigues)
Date: Wed, 04 Feb 2015 10:13:49 -0200
Subject: [squid-users] Order of http_access allow/deny
In-Reply-To: <OF2562A001.22F6DDA1-ONC1257DE2.003D6208-C1257DE2.003E2E16@mahle.com>
References: <OF2562A001.22F6DDA1-ONC1257DE2.003D6208-C1257DE2.003E2E16@mahle.com>
Message-ID: <54D20CFD.1060000@solutti.com.br>

On 04/02/15 09:19, Andreas.Reschke at mahle.com wrote:
> Hi there,
> Is there a order of http_access allow/deny? If I activate "http_access 
> deny !chkglwebhttp" nobody can use the proxy, squid allways ask for 
> user and password (user and password is correct)
>
> ######
> acl chkglwebhttp external LDAPLookup GGPY-LO-Web-Http
> acl sellingUser external LDAPLookup GGPY-LO-Web-Allowed-Selling
> acl socialUser external LDAPLookup GGPY-LO-Web-Allowed-Social
> acl allforbUser external LDAPLookup GGPY-LO-Web-Allowed-All
> acl ftpputUser external LDAPLookup GGPY-LO-Web-Ftp-Put
> acl loggingUser external LDAPLookup GGPY-LO-Web-Log-User
> acl auth proxy_auth REQUIRED
> acl permitt_ips src 10.143.10.247/32
> acl FTP proto FTP
> acl PUT method PUT
>
> # whitelisten
> http_access allow open-sites all
> http_access allow localhost
> http_access allow permitt_ips !denied-sites !social-sites
> http_access allow indien DAY
> http_access deny indien
> #http_access deny !chkglwebhttp
> http_access allow selling-sites sellingUser
> http_access allow social-sites socialUser

     Actually, and i dont know if this a bug or a desired behavior, 
denying a group seems to always (at least to me) brings the 
authentication popup. To avoid that and make things really work as 
expected, i usually add an 'all' to the denying clause. As the 'all' 
rule will match anything, it wont change the denying or not of your 
rule. And it will make things work. Actually this hint was found on the 
mailing list archives.

     So, instead of

http_access deny !chkglwebhttp

     try using

http_access deny !chkglwebhttp all

     if your 'indien' acl, which is also used on a deny rule, is also a 
group rule (that cannot be confirmed on the conf you posted), just add 
the all as well. In summary, always add an 'all' to an http_access rule 
which envolves denying by any king of group checking.





-- 


	Atenciosamente / Sincerily,
	Leonardo Rodrigues
	Solutti Tecnologia
	http://www.solutti.com.br

	Minha armadilha de SPAM, N?O mandem email
	gertrudes at solutti.com.br
	My SPAMTRAP, do not email it


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/3472a509/attachment.htm>

From steve at opendium.com  Wed Feb  4 12:34:23 2015
From: steve at opendium.com (Steve Hill)
Date: Wed, 04 Feb 2015 12:34:23 +0000
Subject: [squid-users] ssl-bump doesn't like valid web server
In-Reply-To: <54CF7A55.3030003@ngtech.co.il>
References: <54BF65E7.2080708@trimble.com> <54BF6F98.7010302@opendium.com>
 <54BFF278.7080007@ngtech.co.il> <54C0A4A5.5060607@opendium.com>
 <54C0B152.3@treenet.co.nz> <54CF68E8.70606@opendium.com>
 <54CF7A55.3030003@ngtech.co.il>
Message-ID: <54D211CF.4030905@opendium.com>

On 02.02.15 13:23, Eliezer Croitoru wrote:

> On what OS are you running squid? is it self compiled one?

Scientific Linux 6.6.

And yes, it's a self-compiled Squid.

I'm quite happy to change to using the helper if that is the preferred 
method (until recently I was unaware that the helper existed).  Although 
I've got to admit that I was a bit surprised to be told that the way 
I've been successfully using Squid is impossible. :)

-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Direct contacts:
    Instant messager: xmpp:steve at opendium.com
    Email:            steve at opendium.com
    Phone:            sip:steve at opendium.com

Sales / enquiries contacts:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support contacts:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From Andreas.Reschke at mahle.com  Wed Feb  4 12:34:42 2015
From: Andreas.Reschke at mahle.com (Andreas.Reschke at mahle.com)
Date: Wed, 4 Feb 2015 13:34:42 +0100
Subject: [squid-users] Antwort: Re:  Order of http_access allow/deny
In-Reply-To: <54D20CFD.1060000@solutti.com.br>
References: <OF2562A001.22F6DDA1-ONC1257DE2.003D6208-C1257DE2.003E2E16@mahle.com>
 <54D20CFD.1060000@solutti.com.br>
Message-ID: <OF54896C16.6017331D-ONC1257DE2.00449A84-C1257DE2.004518C0@mahle.com>

"squid-users" <squid-users-bounces at lists.squid-cache.org> schrieb am 
04.02.2015 13:13:49:

> Von: Leonardo Rodrigues <leolistas at solutti.com.br>
> An: squid-users at lists.squid-cache.org
> Datum: 04.02.2015 13:14
> Betreff: Re: [squid-users] Order of http_access allow/deny
> Gesendet von: "squid-users" <squid-users-bounces at lists.squid-cache.org>
> 
> On 04/02/15 09:19, Andreas.Reschke at mahle.com wrote:
> Hi there, 
> Is there a order of http_access allow/deny? If I activate 
> "http_access deny !chkglwebhttp" nobody can use the proxy, squid 
> allways ask for user and password (user and password is correct) 
> 
> ###### 
> acl chkglwebhttp external LDAPLookup GGPY-LO-Web-Http 
> acl sellingUser external LDAPLookup GGPY-LO-Web-Allowed-Selling 
> acl socialUser external LDAPLookup GGPY-LO-Web-Allowed-Social 
> acl allforbUser external LDAPLookup GGPY-LO-Web-Allowed-All 
> acl ftpputUser external LDAPLookup GGPY-LO-Web-Ftp-Put 
> acl loggingUser external LDAPLookup GGPY-LO-Web-Log-User 
> acl auth proxy_auth REQUIRED 
> acl permitt_ips src 10.143.10.247/32 
> acl FTP proto FTP 
> acl PUT method PUT 
> 
> # whitelisten 
> http_access allow open-sites all 
> http_access allow localhost 
> http_access allow permitt_ips !denied-sites !social-sites 
> http_access allow indien DAY 
> http_access deny indien 
> #http_access deny !chkglwebhttp 
> http_access allow selling-sites sellingUser 
> http_access allow social-sites socialUser 
> 
>     Actually, and i dont know if this a bug or a desired behavior, 
> denying a group seems to always (at least to me) brings the 
> authentication popup. To avoid that and make things really work as 
> expected, i usually add an 'all' to the denying clause. As the 'all'
> rule will match anything, it wont change the denying or not of your 
> rule. And it will make things work. Actually this hint was found on 
> the mailing list archives.
> 
>     So, instead of
> 
> http_access deny !chkglwebhttp
> 
>     try using
> 
> http_access deny !chkglwebhttp all
> 
>     if your 'indien' acl, which is also used on a deny rule, is also
> a group rule (that cannot be confirmed on the conf you posted), just
> add the all as well. In summary, always add an 'all' to an 
> http_access rule which envolves denying by any king of group checking.
> 
> 
> 
> 

> -- 
> 
> 
>    Atenciosamente / Sincerily,
>    Leonardo Rodrigues
>    Solutti Tecnologia
>    http://www.solutti.com.br
> 
>    Minha armadilha de SPAM, N?O mandem email
>    gertrudes at solutti.com.br
>    My SPAMTRAP, do not email it
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Hi Leonardo,

thanks for you answer. I've tested it with "http_access deny !chkglwebhttp 
all", so no access is allowed. 
I always get "ext_ldap_group_acl: WARNING: could not bind to binddn 
'Invalid credentials'"



Mit freundlichen Gr??en / Kind regards

Mr. Andreas Reschke
andreas.reschke at mahle.com, http://www.mahle.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/6e21649c/attachment.htm>

From yvoinov at gmail.com  Wed Feb  4 12:41:17 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 18:41:17 +0600
Subject: [squid-users] Antwort: Re:  Order of http_access allow/deny
In-Reply-To: <OF54896C16.6017331D-ONC1257DE2.00449A84-C1257DE2.004518C0@mahle.com>
References: <OF2562A001.22F6DDA1-ONC1257DE2.003D6208-C1257DE2.003E2E16@mahle.com>
 <54D20CFD.1060000@solutti.com.br>
 <OF54896C16.6017331D-ONC1257DE2.00449A84-C1257DE2.004518C0@mahle.com>
Message-ID: <54D2136D.9070407@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
As you can see (and warning your get shown it) the problem is not in ACL's.

But in auth helper or near it:

ext_ldap_group_acl: WARNING: could not bind to binddn 'Invalid credentials


04.02.2015 18:34, Andreas.Reschke at mahle.com ?????:
> "squid-users" <squid-users-bounces at lists.squid-cache.org> schrieb am 04.02.2015 13:13:49:
>
> > Von: Leonardo Rodrigues <leolistas at solutti.com.br>
> > An: squid-users at lists.squid-cache.org
> > Datum: 04.02.2015 13:14
> > Betreff: Re: [squid-users] Order of http_access allow/deny
> > Gesendet von: "squid-users" <squid-users-bounces at lists.squid-cache.org>
> >
> > On 04/02/15 09:19, Andreas.Reschke at mahle.com wrote:
> > Hi there,
> > Is there a order of http_access allow/deny? If I activate
> > "http_access deny !chkglwebhttp" nobody can use the proxy, squid
> > allways ask for user and password (user and password is correct)
> >
> > ######
> > acl chkglwebhttp external LDAPLookup GGPY-LO-Web-Http
> > acl sellingUser external LDAPLookup GGPY-LO-Web-Allowed-Selling
> > acl socialUser external LDAPLookup GGPY-LO-Web-Allowed-Social
> > acl allforbUser external LDAPLookup GGPY-LO-Web-Allowed-All
> > acl ftpputUser external LDAPLookup GGPY-LO-Web-Ftp-Put
> > acl loggingUser external LDAPLookup GGPY-LO-Web-Log-User
> > acl auth proxy_auth REQUIRED
> > acl permitt_ips src 10.143.10.247/32
> > acl FTP proto FTP
> > acl PUT method PUT
> >
> > # whitelisten
> > http_access allow open-sites all
> > http_access allow localhost
> > http_access allow permitt_ips !denied-sites !social-sites
> > http_access allow indien DAY
> > http_access deny indien
> > #http_access deny !chkglwebhttp
> > http_access allow selling-sites sellingUser
> > http_access allow social-sites socialUser
> >
> >     Actually, and i dont know if this a bug or a desired behavior,
> > denying a group seems to always (at least to me) brings the
> > authentication popup. To avoid that and make things really work as
> > expected, i usually add an 'all' to the denying clause. As the 'all'
> > rule will match anything, it wont change the denying or not of your
> > rule. And it will make things work. Actually this hint was found on
> > the mailing list archives.
> >
> >     So, instead of
> >
> > http_access deny !chkglwebhttp
> >
> >     try using
> >
> > http_access deny !chkglwebhttp all
> >
> >     if your 'indien' acl, which is also used on a deny rule, is also
> > a group rule (that cannot be confirmed on the conf you posted), just
> > add the all as well. In summary, always add an 'all' to an
> > http_access rule which envolves denying by any king of group checking.
> >
> >
> >
> >
>
> > --
> >
> >
> >    Atenciosamente / Sincerily,
> >    Leonardo Rodrigues
> >    Solutti Tecnologia
> >    http://www.solutti.com.br <http://www.solutti.com.br/>
> >
> >    Minha armadilha de SPAM, N?O mandem email
> >    gertrudes at solutti.com.br
> >    My SPAMTRAP, do not email it
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> Hi Leonardo,
>
> thanks for you answer. I've tested it with "http_access deny
!chkglwebhttp all", so no access is allowed.
> I always get "ext_ldap_group_acl: WARNING: could not bind to binddn
'Invalid credentials'"
>
>
>
> Mit freundlichen Gr??en / Kind regards
>
> Mr. Andreas Reschke
> andreas.reschke at mahle.com, http://www.mahle.com <http://www.mahle.com/>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0hNtAAoJENNXIZxhPexG3VUIAMV7PVirelNNZ3WaqU4Hy8EW
rwLkqMRu4tpMxWbqL3I6UaC9kjDVQUTso6zDTs99k+811JYnM36kbpE6ExzQXibg
/2AMsm9I9wTtqxEIn7JIIrvu/7fsy1AIAW/UfsFavjIhnGfYs+/Gwt6eAnnEfb64
MTQ/eyf8cZbZJv41UgBhWatYJsAMxkLN0ge069npmu0boe6ZkfZje5m71oCs0PQf
NqXQ4A10Vlqji5m5//Rlsh8JuaE9lXOSuVS9MTawkttB7J1AKRVj0ehKsnoL7RRn
JCtMQuACiOiHEaYYyvbaDV5JAXpjbCDU1lD44bDx8zp1cwBNnKwY6vF+B3JEaQc=
=Zx1q
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/c3428fb0/attachment.htm>

From Andreas.Reschke at mahle.com  Wed Feb  4 12:54:42 2015
From: Andreas.Reschke at mahle.com (Andreas.Reschke at mahle.com)
Date: Wed, 4 Feb 2015 13:54:42 +0100
Subject: [squid-users] Antwort: Re: Antwort: Re: Order of http_access
	allow/deny
In-Reply-To: <54D2136D.9070407@gmail.com>
References: <OF2562A001.22F6DDA1-ONC1257DE2.003D6208-C1257DE2.003E2E16@mahle.com>
 <54D20CFD.1060000@solutti.com.br>
 <OF54896C16.6017331D-ONC1257DE2.00449A84-C1257DE2.004518C0@mahle.com>
 <54D2136D.9070407@gmail.com>
Message-ID: <OFD316E36B.CFC7975D-ONC1257DE2.00469ED6-C1257DE2.0046ED7A@mahle.com>

"squid-users" <squid-users-bounces at lists.squid-cache.org> schrieb am 
04.02.2015 13:41:17:

> Von: Yuri Voinov <yvoinov at gmail.com>
> An: squid-users at lists.squid-cache.org
> Datum: 04.02.2015 13:41
> Betreff: Re: [squid-users] Antwort: Re:  Order of http_access allow/deny
> Gesendet von: "squid-users" <squid-users-bounces at lists.squid-cache.org>
> 
> 
> -----BEGIN PGP SIGNED MESSAGE----- 
> Hash: SHA1 
>  
> As you can see (and warning your get shown it) the problem is not in 
ACL's.
> 
> But in auth helper or near it:
> 
> ext_ldap_group_acl: WARNING: could not bind to binddn 'Invalid 
credentials

And how can i debug it? All I found is too much of output. How can I 
customize the debug level?


> 
> 
> 04.02.2015 18:34, Andreas.Reschke at mahle.com ?????:
> > "squid-users" <squid-users-bounces at lists.squid-cache.org> schrieb 
> am 04.02.2015 13:13:49:
> >
> > > Von: Leonardo Rodrigues <leolistas at solutti.com.br>
> > > An: squid-users at lists.squid-cache.org
> > > Datum: 04.02.2015 13:14
> > > Betreff: Re: [squid-users] Order of http_access allow/deny
> > > Gesendet von: "squid-users" 
<squid-users-bounces at lists.squid-cache.org>
> > >
> > > On 04/02/15 09:19, Andreas.Reschke at mahle.com wrote:
> > > Hi there,
> > > Is there a order of http_access allow/deny? If I activate
> > > "http_access deny !chkglwebhttp" nobody can use the proxy, squid
> > > allways ask for user and password (user and password is correct)
> > >
> > > ######
> > > acl chkglwebhttp external LDAPLookup GGPY-LO-Web-Http
> > > acl sellingUser external LDAPLookup GGPY-LO-Web-Allowed-Selling
> > > acl socialUser external LDAPLookup GGPY-LO-Web-Allowed-Social
> > > acl allforbUser external LDAPLookup GGPY-LO-Web-Allowed-All
> > > acl ftpputUser external LDAPLookup GGPY-LO-Web-Ftp-Put
> > > acl loggingUser external LDAPLookup GGPY-LO-Web-Log-User
> > > acl auth proxy_auth REQUIRED
> > > acl permitt_ips src 10.143.10.247/32
> > > acl FTP proto FTP
> > > acl PUT method PUT
> > >
> > > # whitelisten
> > > http_access allow open-sites all
> > > http_access allow localhost
> > > http_access allow permitt_ips !denied-sites !social-sites
> > > http_access allow indien DAY
> > > http_access deny indien
> > > #http_access deny !chkglwebhttp
> > > http_access allow selling-sites sellingUser
> > > http_access allow social-sites socialUser
> > >
> > >     Actually, and i dont know if this a bug or a desired behavior,
> > > denying a group seems to always (at least to me) brings the
> > > authentication popup. To avoid that and make things really work as
> > > expected, i usually add an 'all' to the denying clause. As the 'all'
> > > rule will match anything, it wont change the denying or not of your
> > > rule. And it will make things work. Actually this hint was found on
> > > the mailing list archives.
> > >
> > >     So, instead of
> > >
> > > http_access deny !chkglwebhttp
> > >
> > >     try using
> > >
> > > http_access deny !chkglwebhttp all
> > >
> > >     if your 'indien' acl, which is also used on a deny rule, is also
> > > a group rule (that cannot be confirmed on the conf you posted), just
> > > add the all as well. In summary, always add an 'all' to an
> > > http_access rule which envolves denying by any king of group 
checking.
> > >
> > >
> > >
> > >
> >
> > > --
> > >
> > >
> > >    Atenciosamente / Sincerily,
> > >    Leonardo Rodrigues
> > >    Solutti Tecnologia
> > >    http://www.solutti.com.br <http://www.solutti.com.br/>
> > >
> > >    Minha armadilha de SPAM, N?O mandem email
> > >    gertrudes at solutti.com.br
> > >    My SPAMTRAP, do not email it
> > >
> > >
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
> >
> > Hi Leonardo,
> >
> > thanks for you answer. I've tested it with "http_access deny !
> chkglwebhttp all", so no access is allowed.
> > I always get "ext_ldap_group_acl: WARNING: could not bind to 
> binddn 'Invalid credentials'"
> >
> >
> >
> > Mit freundlichen Gr??en / Kind regards
> >
> > Mr. Andreas Reschke
> > andreas.reschke at mahle.com, http://www.mahle.com <http://www.mahle.com/
>
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> 
> -----BEGIN PGP SIGNATURE----- 
> Version: GnuPG v2 
>  
> iQEcBAEBAgAGBQJU0hNtAAoJENNXIZxhPexG3VUIAMV7PVirelNNZ3WaqU4Hy8EW 
> rwLkqMRu4tpMxWbqL3I6UaC9kjDVQUTso6zDTs99k+811JYnM36kbpE6ExzQXibg 
> /2AMsm9I9wTtqxEIn7JIIrvu/7fsy1AIAW/UfsFavjIhnGfYs+/Gwt6eAnnEfb64 
> MTQ/eyf8cZbZJv41UgBhWatYJsAMxkLN0ge069npmu0boe6ZkfZje5m71oCs0PQf 
> NqXQ4A10Vlqji5m5//Rlsh8JuaE9lXOSuVS9MTawkttB7J1AKRVj0ehKsnoL7RRn 
> JCtMQuACiOiHEaYYyvbaDV5JAXpjbCDU1lD44bDx8zp1cwBNnKwY6vF+B3JEaQc= 
> =Zx1q 
> -----END PGP SIGNATURE----- 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Mit freundlichen Gr??en / Kind regards

Mr. Andreas Reschke
andreas.reschke at mahle.com, http://www.mahle.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/02b8cf90/attachment.htm>

From yvoinov at gmail.com  Wed Feb  4 12:56:57 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 04 Feb 2015 18:56:57 +0600
Subject: [squid-users] Antwort: Re: Antwort: Re: Order of http_access
 allow/deny
In-Reply-To: <OFD316E36B.CFC7975D-ONC1257DE2.00469ED6-C1257DE2.0046ED7A@mahle.com>
References: <OF2562A001.22F6DDA1-ONC1257DE2.003D6208-C1257DE2.003E2E16@mahle.com>
 <54D20CFD.1060000@solutti.com.br>
 <OF54896C16.6017331D-ONC1257DE2.00449A84-C1257DE2.004518C0@mahle.com>
 <54D2136D.9070407@gmail.com>
 <OFD316E36B.CFC7975D-ONC1257DE2.00469ED6-C1257DE2.0046ED7A@mahle.com>
Message-ID: <54D21719.8080009@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
http://www.squid-cache.org/Doc/config/debug_options/
http://wiki.squid-cache.org/KnowledgeBase/DebugSections

04.02.2015 18:54, Andreas.Reschke at mahle.com ?????:
> "squid-users" <squid-users-bounces at lists.squid-cache.org> schrieb am 04.02.2015 13:41:17:
>
> > Von: Yuri Voinov <yvoinov at gmail.com>
> > An: squid-users at lists.squid-cache.org
> > Datum: 04.02.2015 13:41
> > Betreff: Re: [squid-users] Antwort: Re:  Order of http_access allow/deny
> > Gesendet von: "squid-users" <squid-users-bounces at lists.squid-cache.org>
> >
> >
> As you can see (and warning your get shown it) the problem is not in
ACL's.
>
> But in auth helper or near it:
>
> ext_ldap_group_acl: WARNING: could not bind to binddn 'Invalid credentials
>
> > And how can i debug it? All I found is too much of output. How can I
customize the debug level?
>
>
>
>
> 04.02.2015 18:34, Andreas.Reschke at mahle.com ?????:
> > "squid-users" <squid-users-bounces at lists.squid-cache.org> schrieb
> am 04.02.2015 13:13:49:
>
> > > Von: Leonardo Rodrigues <leolistas at solutti.com.br>
> > > An: squid-users at lists.squid-cache.org
> > > Datum: 04.02.2015 13:14
> > > Betreff: Re: [squid-users] Order of http_access allow/deny
> > > Gesendet von: "squid-users"
<squid-users-bounces at lists.squid-cache.org>
>
> > > On 04/02/15 09:19, Andreas.Reschke at mahle.com wrote:
> > > Hi there,
> > > Is there a order of http_access allow/deny? If I activate
> > > "http_access deny !chkglwebhttp" nobody can use the proxy, squid
> > > allways ask for user and password (user and password is correct)
>
> > > ######
> > > acl chkglwebhttp external LDAPLookup GGPY-LO-Web-Http
> > > acl sellingUser external LDAPLookup GGPY-LO-Web-Allowed-Selling
> > > acl socialUser external LDAPLookup GGPY-LO-Web-Allowed-Social
> > > acl allforbUser external LDAPLookup GGPY-LO-Web-Allowed-All
> > > acl ftpputUser external LDAPLookup GGPY-LO-Web-Ftp-Put
> > > acl loggingUser external LDAPLookup GGPY-LO-Web-Log-User
> > > acl auth proxy_auth REQUIRED
> > > acl permitt_ips src 10.143.10.247/32
> > > acl FTP proto FTP
> > > acl PUT method PUT
>
> > > # whitelisten
> > > http_access allow open-sites all
> > > http_access allow localhost
> > > http_access allow permitt_ips !denied-sites !social-sites
> > > http_access allow indien DAY
> > > http_access deny indien
> > > #http_access deny !chkglwebhttp
> > > http_access allow selling-sites sellingUser
> > > http_access allow social-sites socialUser
>
> > >     Actually, and i dont know if this a bug or a desired behavior,
> > > denying a group seems to always (at least to me) brings the
> > > authentication popup. To avoid that and make things really work as
> > > expected, i usually add an 'all' to the denying clause. As the 'all'
> > > rule will match anything, it wont change the denying or not of your
> > > rule. And it will make things work. Actually this hint was found on
> > > the mailing list archives.
>
> > >     So, instead of
>
> > > http_access deny !chkglwebhttp
>
> > >     try using
>
> > > http_access deny !chkglwebhttp all
>
> > >     if your 'indien' acl, which is also used on a deny rule, is also
> > > a group rule (that cannot be confirmed on the conf you posted), just
> > > add the all as well. In summary, always add an 'all' to an
> > > http_access rule which envolves denying by any king of group checking.
>
>
>
>
>
> > > --
>
>
> > >    Atenciosamente / Sincerily,
> > >    Leonardo Rodrigues
> > >    Solutti Tecnologia
> > >    http://www.solutti.com.br
<http://www.solutti.com.br/><http://www.solutti.com.br/>
>
> > >    Minha armadilha de SPAM, N?O mandem email
> > >    gertrudes at solutti.com.br
> > >    My SPAMTRAP, do not email it
>
>
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
>
> > Hi Leonardo,
>
> > thanks for you answer. I've tested it with "http_access deny !
> chkglwebhttp all", so no access is allowed.
> > I always get "ext_ldap_group_acl: WARNING: could not bind to
> binddn 'Invalid credentials'"
>
>
>
> > Mit freundlichen Gr??en / Kind regards
>
> > Mr. Andreas Reschke
> > andreas.reschke at mahle.com, http://www.mahle.com
<http://www.mahle.com/><http://www.mahle.com/>
>
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> Mit freundlichen Gr??en / Kind regards
>
> Mr. Andreas Reschke
> andreas.reschke at mahle.com, http://www.mahle.com <http://www.mahle.com/>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0hcZAAoJENNXIZxhPexG/MkH/29hNK9TEn8NVp7ehHEQXykG
F7xHTceoL2SYndypeweKLTHU76NIArGfYgk0YKRujSvMYf9Si8qvfxTnHDg/XtsB
b3Z8RBObZ4KHKhUoaJV54Ye6qumCS70PZqlpMHr+lwrPqrdyHRTS36CLTORGdV5j
MdCiXdq3RFLCyLoKIK1lODqWjOCwz7Mw+V4BANGuc9NakCpSpR4CnGoY38XMgYmn
MvAOovBJQstRiGYOgR9IasTszynrlPISJ+uEELF2dK6G3uEA7m2qvOUA2rhKTgeY
sxOg5DA14NYlY1p9ciuwvLqTIcC/YgPNOmsqt8Uqdp6WQL3EoSfFtgtBKCOwOhM=
=wldX
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/79103a0d/attachment.htm>

From gortega at anses.gov.ar  Wed Feb  4 15:33:09 2015
From: gortega at anses.gov.ar (Ortega Gustavo Martin)
Date: Wed, 4 Feb 2015 15:33:09 +0000
Subject: [squid-users] The SSL certificate database is corrupted. Please
	rebuild
In-Reply-To: <54CC04F3.9060900@treenet.co.nz>
References: <mailman.38090.1422648817.1833.squid-users@lists.squid-cache.org>
 <CAMZauGrzEQ3uUC5B3U5+QtshgTDCXfSmiR5NT76mcW+SCyivVQ@mail.gmail.com>
 <54CC04F3.9060900@treenet.co.nz>
Message-ID: <20A2F27D26BDBF41B491D00A11D4A7A6012777D2D7@ANSESXGMBX04.anses.gov.ar>

Hello, i found multiple times this error in cache.log and then squid crashed and enter in a loop.

I found one corrupted line in "index.txt" in the database directory.
Last two lines are:

V       150828132043Z           1BDA35020BA8933E63507E7D5A59386C8329A3D3        unknown /CN=zqnvza.bay.livefilestore.com+Sign=signTrusted
ed


I thought that "ed" is the corrupted line.


This is my output of "squid -v"
Squid Cache: Version 3.4.11-20150124-r13214
configure options:  '--prefix=/export/squid-3.4.11-20150124-r13214' '--with-maxfd=400000' '--enable-delay-pools' '--enable-referer-log' '--enable-useragent-log' '--enable-auth' '--with-large-files' '--enable-follow-x-forwarded-for' '--enable-default-err-language=Spanish' '--enable-err-languages=Spanish' '--enable-external-acl-helpers=wbinfo_group' '--enable-async-io' '--enable-ssl' '--enable-ssl-crtd' '--enable-icap-client' '--enable-ltdl-convenience' '--with-openssl=/export/SOURCES/openssl-1.0.1c' '--disable-ipv6'


Thanks a lot.
Gustavo.

From squid3 at treenet.co.nz  Wed Feb  4 15:39:04 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 05 Feb 2015 04:39:04 +1300
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D1BD12.6050406@trimble.com>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
 <54D11872.6090801@gmail.com> <54D18F19.7020504@treenet.co.nz>
 <CAOsHgtv=9JVQhpPO-=9W9haJwnQn=b-cA2S7aRuVu_hk_gBevg@mail.gmail.com>
 <54D1BD12.6050406@trimble.com>
Message-ID: <54D23D18.4040007@treenet.co.nz>

On 4/02/2015 7:32 p.m., Jason Haar wrote:
> On 04/02/15 18:47, Daniel Greenwald wrote:
>> And happens to be one that squid desperately needs to remain in order
>> to continue ssl bumping..
> ...and is one that diminishes in value as cert pinning becomes more
> popular...
> 
> It's a tough life: on the one hand we want to do TLS intercept in order
> to do content filtering of HTTPS (because the bad guys are deliberately
> putting more and more malware onto HTTPS websites), and yet on the other
> hand we all want some things to be private.
> 
> Bring back RFC3514, then all of this would be easy!!!
> 

While Squid is not able to be section-3 compliant due to lack of a
portable system API. By building with --disable-http-violations it
becomes mostly compliant with section-4 under its role as a network
protection gateway. ;-P

Amos



From marcus.kool at urlfilterdb.com  Wed Feb  4 15:45:51 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 04 Feb 2015 13:45:51 -0200
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
 squid.
In-Reply-To: <1423031044701-4669531.post@n4.nabble.com>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il> <1422967529217-4669494.post@n4.nabble.com>
 <54D0CD55.5060302@urlfilterdb.com> <1422975403825-4669503.post@n4.nabble.com>
 <54D10FB3.7090505@urlfilterdb.com> <1423031044701-4669531.post@n4.nabble.com>
Message-ID: <54D23EAF.8020309@urlfilterdb.com>



On 02/04/2015 04:24 AM, Omid Kosari wrote:
> The only reason for extend is more capacity .
> Currently there is no problem with current setup except capacity .
> I can replace each SSD with new 500GB which doubles the capacity and it is
> not enough . and old SSDs will be unusable . So i prefer a long term
> solution like NAS .

Yes, a NAS will do.  I assume that you will put disks in the NAS (instead of SSDs)
so it is recommended to configure Squid to use the SSDs for small objects and
the NAS for large objects since disks more efficient in servicing larger objects
than small objects.

Since you have 300 mbit traffic and internal SSDs, a 1 gbit port for the
NAS is sufficient, so 10 gbit is not required.
Depending on the current config you might need to use a separate NIC
for the NAS.

Make sure that the NAS that you will buy is compatible with your system
since the link to the specs that you sent earlier is to a Windows-only
NAS.

Marcus

> Current spec of squid boxes are core i3 (with current 3.1.20 version one
> core utilizes) and 16GB of ram . so far so good .
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Hypothetically-comparing-SATA-SAS-to-NAS-SAN-for-squid-tp4664350p4669531.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From vdoctor at neuf.fr  Wed Feb  4 15:58:13 2015
From: vdoctor at neuf.fr (Stakres)
Date: Wed, 4 Feb 2015 07:58:13 -0800 (PST)
Subject: [squid-users] Resolution Locker Plugin for Squid Proxy Cache 3.x
In-Reply-To: <1422896192924-4669489.post@n4.nabble.com>
References: <1422896192924-4669489.post@n4.nabble.com>
Message-ID: <1423065493752-4669549.post@n4.nabble.com>

Hi All,

New  build 2.05 <https://sourceforge.net/projects/youtuberesolutionlocker/>  
including Dailymotion...

Still a free 1 year license on the  website <https://svl.unveiltech.com/>   

Bye Fred



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Resolution-Locker-Plugin-for-Squid-Proxy-Cache-3-x-tp4669489p4669549.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Wed Feb  4 16:00:18 2015
From: hack.back at hotmail.com (HackXBack)
Date: Wed, 4 Feb 2015 08:00:18 -0800 (PST)
Subject: [squid-users] FATAL: The ssl_crtd helpers are crashing too
 rapidly, need help!
In-Reply-To: <54CC0861.3040204@treenet.co.nz>
References: <1421929053162-4669257.post@n4.nabble.com>
 <1422034084407-4669297.post@n4.nabble.com> <54C2884E.4000509@treenet.co.nz>
 <1422158576716-4669314.post@n4.nabble.com>
 <1422205274028-4669322.post@n4.nabble.com> <54C557C8.7040509@gmail.com>
 <1422227373827-4669324.post@n4.nabble.com> <54C5D343.4070503@treenet.co.nz>
 <1422485986058-4669398.post@n4.nabble.com> <54CC0861.3040204@treenet.co.nz>
Message-ID: <1423065618631-4669550.post@n4.nabble.com>

i have this conf

sslcrtd_program /usr/lib/squid/ssl_crtd -s /etc/squid/ssl_db/certs/ -M 16MB
sslcrtd_children 50 startup=40 idle=1

ssl_unclean_shutdown on
sslproxy_version 1
always_direct allow all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
ssl_bump server-first all

Squid   run helpers fine for few hours maybe minutes so some times it work
fine for 10 hours and some time it work for 10 minutes
when it fails it give me error crash in cache.log
after crash i recreate ssl_db and it work fine again for few time...

how i can know what may cause ssl_db to be crashed ??

sorry for late
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/FATAL-The-ssl-crtd-helpers-are-crashing-too-rapidly-need-help-tp4669257p4669550.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Feb  4 17:15:27 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 05 Feb 2015 06:15:27 +1300
Subject: [squid-users] The SSL certificate database is corrupted. Please
 rebuild
In-Reply-To: <20A2F27D26BDBF41B491D00A11D4A7A6012777D2D7@ANSESXGMBX04.anses.gov.ar>
References: <mailman.38090.1422648817.1833.squid-users@lists.squid-cache.org>
 <CAMZauGrzEQ3uUC5B3U5+QtshgTDCXfSmiR5NT76mcW+SCyivVQ@mail.gmail.com>
 <54CC04F3.9060900@treenet.co.nz>
 <20A2F27D26BDBF41B491D00A11D4A7A6012777D2D7@ANSESXGMBX04.anses.gov.ar>
Message-ID: <54D253AF.4000901@treenet.co.nz>

On 5/02/2015 4:33 a.m., Ortega Gustavo Martin wrote:
> Hello, i found multiple times this error in cache.log and then squid
> crashed and enter in a loop.
> 
> I found one corrupted line in "index.txt" in the database directory. 
> Last two lines are:
> 
> V       150828132043Z
> 1BDA35020BA8933E63507E7D5A59386C8329A3D3        unknown
> /CN=zqnvza.bay.livefilestore.com+Sign=signTrusted ed
> 
> 
> I thought that "ed" is the corrupted line.
> 
> 
> This is my output of "squid -v" Squid Cache: Version
> 3.4.11-20150124-r13214 configure options:
> '--prefix=/export/squid-3.4.11-20150124-r13214' '--with-maxfd=400000'
> '--enable-delay-pools' '--enable-referer-log'
> '--enable-useragent-log'

Referer and Useragent logs are now built-in logformat definitions.
Remove these ./configure options.

> '--enable-auth'

Auth is enabled by default, the ./configure option is defined for use to
DISABLE authentication in Squid.

> '--with-large-files'
> '--enable-follow-x-forwarded-for'
> '--enable-default-err-language=Spanish'
> '--enable-err-languages=Spanish'

"Spanish" is not an ISO 3166 language code.

Use:  --enable-default-err-language=es


> '--enable-external-acl-helpers=wbinfo_group' '--enable-async-io'
> '--enable-ssl' '--enable-ssl-crtd' '--enable-icap-client'
> '--enable-ltdl-convenience'
> '--with-openssl=/export/SOURCES/openssl-1.0.1c' '--disable-ipv6'
> 

Please begin your migration to IPv6. BCP 177 (RFC 6540) make it clear
that IPv6 support is currenty mandatory for all machinery and software
using IP protocol. Current versions of Squid have no problems with IPv6
(remaining problem are all in the network and workarounds are configurable).

Cheers
Amos


From hack.back at hotmail.com  Wed Feb  4 17:36:59 2015
From: hack.back at hotmail.com (HackXBack)
Date: Wed, 4 Feb 2015 09:36:59 -0800 (PST)
Subject: [squid-users] FATAL: The ssl_crtd helpers are crashing too
 rapidly, need help!
In-Reply-To: <1421929053162-4669257.post@n4.nabble.com>
References: <1421929053162-4669257.post@n4.nabble.com>
Message-ID: <1423071419206-4669552.post@n4.nabble.com>

also a lot error in cache.log

2015/02/04 19:40:47 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 720: Closed by client
2015/02/04 19:40:48 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 1098: Broken pipe (32)
2015/02/04 19:41:33 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 2285: error:14094410:SSL routines:SSL3_READ_BYTES:sslv3
alert handshake failure (1/0)
2015/02/04 19:41:33 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 816: error:140A1175:SSL
routines:SSL_BYTES_TO_CIPHER_LIST:inappropriate fallback (1/-1)
2015/02/04 19:41:33 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 301: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
alert unknown ca (1/0)
2015/02/04 19:41:34 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 354: Closed by client




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/FATAL-The-ssl-crtd-helpers-are-crashing-too-rapidly-need-help-tp4669257p4669552.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Feb  4 18:03:56 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 05 Feb 2015 00:03:56 +0600
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D23D18.4040007@treenet.co.nz>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
 <54D11872.6090801@gmail.com> <54D18F19.7020504@treenet.co.nz>
 <CAOsHgtv=9JVQhpPO-=9W9haJwnQn=b-cA2S7aRuVu_hk_gBevg@mail.gmail.com>
 <54D1BD12.6050406@trimble.com> <54D23D18.4040007@treenet.co.nz>
Message-ID: <54D25F0C.1010405@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 

04.02.2015 21:39, Amos Jeffries ?????:
> On 4/02/2015 7:32 p.m., Jason Haar wrote:
>> On 04/02/15 18:47, Daniel Greenwald wrote:
>>> And happens to be one that squid desperately needs to remain in order
>>> to continue ssl bumping..
>> ...and is one that diminishes in value as cert pinning becomes more
>> popular...
>>
>> It's a tough life: on the one hand we want to do TLS intercept in order
>> to do content filtering of HTTPS (because the bad guys are deliberately
>> putting more and more malware onto HTTPS websites), and yet on the other
>> hand we all want some things to be private.
>>
>> Bring back RFC3514, then all of this would be easy!!!
>>
>
> While Squid is not able to be section-3 compliant due to lack of a
> portable system API. By building with --disable-http-violations it
> becomes mostly compliant with section-4 under its role as a network
> protection gateway. ;-P
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
Http violations is our all. :-P

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0l8MAAoJENNXIZxhPexGJW8IALZHBtjXGs6kxbRf4vKJm1nD
q/fdYBSUQ3w5fYR6FyiTY+BseSZbVglb2wBLY7hIemJDV/V+Eb/6/uD2kCSO4E0B
l7dpuO1Mem3ZmavkCPLmPN8QSFZ4cTrYVAhxgH9KY/2gO00iokuKdPDj1WzGRaGA
Snd5fXctcMCqsaVK4w1kWzXCk3RJmBxFxxArMjdvEukcWrjViWwLJp5v8cC4Vl01
eqWpw0ko+cvCf/U7pdyacSX89r8uWdjYg2H4Nl7ETRuki/XZsD+FCpRIoW/2cI3P
DPUZ+izw/G3oiXehWu/acE6YItOdiSOp5vM35VzrukGOcmTEQCmZ/nRBnNvhbb0=
=vffI
-----END PGP SIGNATURE-----



From gortega at anses.gov.ar  Wed Feb  4 18:04:51 2015
From: gortega at anses.gov.ar (Ortega Gustavo Martin)
Date: Wed, 4 Feb 2015 18:04:51 +0000
Subject: [squid-users] The SSL certificate database is corrupted. Please
	rebuild
In-Reply-To: <54D253AF.4000901@treenet.co.nz>
References: <mailman.38090.1422648817.1833.squid-users@lists.squid-cache.org>
 <CAMZauGrzEQ3uUC5B3U5+QtshgTDCXfSmiR5NT76mcW+SCyivVQ@mail.gmail.com>
 <54CC04F3.9060900@treenet.co.nz>
 <20A2F27D26BDBF41B491D00A11D4A7A6012777D2D7@ANSESXGMBX04.anses.gov.ar>
 <54D253AF.4000901@treenet.co.nz>
Message-ID: <20A2F27D26BDBF41B491D00A11D4A7A6012777E747@ANSESXGMBX04.anses.gov.ar>

Amos, thanks for your quick reply!

I ?ve got news:

i recompiled squid with your suggestions, remove the corrupted database but the same thing happens.

my squid -v now is:

Squid Cache: Version 3.4.11-20150124-r13214
configure options:  '--prefix=/export/squid-3.4.11-20150124-r13214' '--with-maxfd=400000' '--enable-delay-pools' '--with-large-files' '--enable-follow-x-forwarded-for' '--enable-default-err-language=es' '--enable-err-languages=es' '--enable-external-acl-helpers=wbinfo_group' '--enable-async-io' '--enable-ssl' '--enable-ssl-crtd' '--enable-icap-client' '--enable-ltdl-convenience' '--with-openssl=/export/SOURCES/openssl-1.0.2'

The complete line of cache.log is:

2015/02/04 15:00:57 kid1| helperOpenServers: Starting 1/200 'ssl_crtd' processes wrong number of fields on line 8 (looking for field 6, got 1, '' left)
(ssl_crtd): The SSL certificate database (....) is corrupted. Please rebuild

Thanks, Gustavo.

-----Mensaje original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] En nombre de Amos Jeffries
Enviado el: mi?rcoles, 04 de febrero de 2015 02:15 p.m.
Para: squid-users at lists.squid-cache.org
Asunto: Re: [squid-users] The SSL certificate database is corrupted. Please rebuild

On 5/02/2015 4:33 a.m., Ortega Gustavo Martin wrote:
> Hello, i found multiple times this error in cache.log and then squid 
> crashed and enter in a loop.
> 
> I found one corrupted line in "index.txt" in the database directory. 
> Last two lines are:
> 
> V       150828132043Z
> 1BDA35020BA8933E63507E7D5A59386C8329A3D3        unknown
> /CN=zqnvza.bay.livefilestore.com+Sign=signTrusted ed
> 
> 
> I thought that "ed" is the corrupted line.
> 
> 
> This is my output of "squid -v" Squid Cache: Version
> 3.4.11-20150124-r13214 configure options:
> '--prefix=/export/squid-3.4.11-20150124-r13214' '--with-maxfd=400000'
> '--enable-delay-pools' '--enable-referer-log'
> '--enable-useragent-log'

Referer and Useragent logs are now built-in logformat definitions.
Remove these ./configure options.

> '--enable-auth'

Auth is enabled by default, the ./configure option is defined for use to DISABLE authentication in Squid.

> '--with-large-files'
> '--enable-follow-x-forwarded-for'
> '--enable-default-err-language=Spanish'
> '--enable-err-languages=Spanish'

"Spanish" is not an ISO 3166 language code.

Use:  --enable-default-err-language=es


> '--enable-external-acl-helpers=wbinfo_group' '--enable-async-io'
> '--enable-ssl' '--enable-ssl-crtd' '--enable-icap-client'
> '--enable-ltdl-convenience'
> '--with-openssl=/export/SOURCES/openssl-1.0.1c' '--disable-ipv6'
> 

Please begin your migration to IPv6. BCP 177 (RFC 6540) make it clear that IPv6 support is currenty mandatory for all machinery and software using IP protocol. Current versions of Squid have no problems with IPv6 (remaining problem are all in the network and workarounds are configurable).

Cheers
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From dig at digcorp.net  Wed Feb  4 19:19:20 2015
From: dig at digcorp.net (Daniel Greenwald)
Date: Wed, 4 Feb 2015 14:19:20 -0500
Subject: [squid-users] Alert unknown CA
In-Reply-To: <54D25F0C.1010405@gmail.com>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
 <54D11872.6090801@gmail.com> <54D18F19.7020504@treenet.co.nz>
 <CAOsHgtv=9JVQhpPO-=9W9haJwnQn=b-cA2S7aRuVu_hk_gBevg@mail.gmail.com>
 <54D1BD12.6050406@trimble.com> <54D23D18.4040007@treenet.co.nz>
 <54D25F0C.1010405@gmail.com>
Message-ID: <CAOsHgtvFyVqz0HGs-PgCmUuCEYmhhFGTesNY7A5UXSFQ4nOJiQ@mail.gmail.com>

squid beware, the pins and staples are coming....

-----------
Daniel I Greenwald



On Wed, Feb 4, 2015 at 1:03 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
> 04.02.2015 21:39, Amos Jeffries ?????:
> > On 4/02/2015 7:32 p.m., Jason Haar wrote:
> >> On 04/02/15 18:47, Daniel Greenwald wrote:
> >>> And happens to be one that squid desperately needs to remain in order
> >>> to continue ssl bumping..
> >> ...and is one that diminishes in value as cert pinning becomes more
> >> popular...
> >>
> >> It's a tough life: on the one hand we want to do TLS intercept in order
> >> to do content filtering of HTTPS (because the bad guys are deliberately
> >> putting more and more malware onto HTTPS websites), and yet on the other
> >> hand we all want some things to be private.
> >>
> >> Bring back RFC3514, then all of this would be easy!!!
> >>
> >
> > While Squid is not able to be section-3 compliant due to lack of a
> > portable system API. By building with --disable-http-violations it
> > becomes mostly compliant with section-4 under its role as a network
> > protection gateway. ;-P
> >
> > Amos
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> Http violations is our all. :-P
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU0l8MAAoJENNXIZxhPexGJW8IALZHBtjXGs6kxbRf4vKJm1nD
> q/fdYBSUQ3w5fYR6FyiTY+BseSZbVglb2wBLY7hIemJDV/V+Eb/6/uD2kCSO4E0B
> l7dpuO1Mem3ZmavkCPLmPN8QSFZ4cTrYVAhxgH9KY/2gO00iokuKdPDj1WzGRaGA
> Snd5fXctcMCqsaVK4w1kWzXCk3RJmBxFxxArMjdvEukcWrjViWwLJp5v8cC4Vl01
> eqWpw0ko+cvCf/U7pdyacSX89r8uWdjYg2H4Nl7ETRuki/XZsD+FCpRIoW/2cI3P
> DPUZ+izw/G3oiXehWu/acE6YItOdiSOp5vM35VzrukGOcmTEQCmZ/nRBnNvhbb0=
> =vffI
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150204/c6004853/attachment.htm>

From yvoinov at gmail.com  Wed Feb  4 19:24:02 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 05 Feb 2015 01:24:02 +0600
Subject: [squid-users] Alert unknown CA
In-Reply-To: <CAOsHgtvFyVqz0HGs-PgCmUuCEYmhhFGTesNY7A5UXSFQ4nOJiQ@mail.gmail.com>
References: <54D0DA9B.1090908@gmail.com> <54D113E7.4010201@treenet.co.nz>
 <54D11872.6090801@gmail.com> <54D18F19.7020504@treenet.co.nz>
 <CAOsHgtv=9JVQhpPO-=9W9haJwnQn=b-cA2S7aRuVu_hk_gBevg@mail.gmail.com>
 <54D1BD12.6050406@trimble.com> <54D23D18.4040007@treenet.co.nz>
 <54D25F0C.1010405@gmail.com>
 <CAOsHgtvFyVqz0HGs-PgCmUuCEYmhhFGTesNY7A5UXSFQ4nOJiQ@mail.gmail.com>
Message-ID: <54D271D2.80009@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
I was shaking in my boots :))))))))))

While HTTPS bullshit - you can have nothing to fear. ;)
It not me - Bruce opinion. :)

05.02.2015 1:19, Daniel Greenwald ?????:
> squid beware, the pins and staples are coming....
>
> -----------
> Daniel I Greenwald
>
>
>
> On Wed, Feb 4, 2015 at 1:03 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
>
> 04.02.2015 21:39, Amos Jeffries ?????:
> > On 4/02/2015 7:32 p.m., Jason Haar wrote:
> >> On 04/02/15 18:47, Daniel Greenwald wrote:
> >>> And happens to be one that squid desperately needs to remain in order
> >>> to continue ssl bumping..
> >> ...and is one that diminishes in value as cert pinning becomes more
> >> popular...
> >>
> >> It's a tough life: on the one hand we want to do TLS intercept in order
> >> to do content filtering of HTTPS (because the bad guys are deliberately
> >> putting more and more malware onto HTTPS websites), and yet on the
other
> >> hand we all want some things to be private.
> >>
> >> Bring back RFC3514, then all of this would be easy!!!
> >>
>
> > While Squid is not able to be section-3 compliant due to lack of a
> > portable system API. By building with --disable-http-violations it
> > becomes mostly compliant with section-4 under its role as a network
> > protection gateway. ;-P
>
> > Amos
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
> Http violations is our all. :-P
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU0nHSAAoJENNXIZxhPexG6nwH/0KqqATFPr5/9+2X8zDu+lo0
zk9+nE4HEq554iqD9l5OeLaWUnu1luQESWsNJTED/tPAbiAymIwhaykn/DotxJut
JvudAd26+JHUlT0ApAzMt2oDpYasJgYmOcVZIp04fVKxJs9e0wzxE9kNYb2iNoyc
HfF/MWyQ/it0eb0rqklc0b8aQ6DAkbkl8TXWEXi+MNCHJcImnOO4GHiCHE1+UWb9
HMSLT7OMoC/fHjyfVHbxP3JyeqV9SbykBMQOCVXpXgZBXPpP2NaaQgBcFDXY2Hjt
PxxsqEEbshR+REM1XBpmTHC8wa+UPY0zgzeSi9Fpm+9AZMSrB3lT9FkBdMsxNjs=
=pUGw
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150205/83d459aa/attachment.htm>

From hack.back at hotmail.com  Wed Feb  4 21:41:53 2015
From: hack.back at hotmail.com (HackXBack)
Date: Wed, 4 Feb 2015 13:41:53 -0800 (PST)
Subject: [squid-users] FATAL: The ssl_crtd helpers are crashing too
 rapidly, need help!
In-Reply-To: <1423071419206-4669552.post@n4.nabble.com>
References: <1421929053162-4669257.post@n4.nabble.com>
 <1423071419206-4669552.post@n4.nabble.com>
Message-ID: <1423086113526-4669557.post@n4.nabble.com>

am still cant find any solution for this problem , also in faq am bumping
about 1500 client , 80% certificates are imported to browsers and mobiles



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/FATAL-The-ssl-crtd-helpers-are-crashing-too-rapidly-need-help-tp4669257p4669557.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Thu Feb  5 05:50:38 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 05 Feb 2015 07:50:38 +0200
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <733907678.332159342.1423045352540.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <733907678.332159342.1423045352540.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <54D304AE.5010708@ngtech.co.il>

Is it happening on all websites? or a specific one?

I am using 3.4.11 for most of my daily uses now.
In order to reproduce it I will need the OS and version, and if I assume 
it is a self compiled so the "squid -v" details.

Eliezer

On 04/02/2015 12:22, FredB wrote:
>
>> >I have some issue with squid 3.5.1: sometimes the browser loads the
>> >page partially (for example: header/footer without styles or missing
>> >images); other times the browser display a "cannot connect to the
>> >proxy (proxy refused connection)" page.
>> >The problem seems to appear more often with https pages (squid is
>> >configured for ssl_bump).
>> >With 3.4.10 everything was good (I ported the config file to 3.5.1
>> >without modifications, except for changed/deleted keywords/tags).
>> >
> Yes I saw exactly the same thing, but in my case without SSLBump
>
>
> ----
>
> Regards,
>
> Fred




From fredbmail at free.fr  Thu Feb  5 09:17:48 2015
From: fredbmail at free.fr (FredB)
Date: Thu, 5 Feb 2015 10:17:48 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54D304AE.5010708@ngtech.co.il>
Message-ID: <1569464157.334517175.1423127868181.JavaMail.root@zimbra4-e1.priv.proxad.net>



> Is it happening on all websites? or a specific one?
> 
> I am using 3.4.11 for most of my daily uses now.
> In order to reproduce it I will need the OS and version, and if I
> assume
> it is a self compiled so the "squid -v" details.
> 
> Eliezer
> 

Hi,

I'm just testing and writing some codes for DIGEST authentication, so I'm not totally sure (I'm using 3.4.11 in production)
But sometimes randomly squid drops SSL websites, never the same.

In my configuration there is also a filtering proxy - e2guardian - but this "problem" appears only with Squid 3.5.1.
I don't have time to investigate more now but If I find something useful I will report back.

Debian Wheezy 32 bits 

Squid Cache: Version 3.5.1-20150201-r13744
Service Name: squid
configure options:  '--build=x86_64-linux-gnu' '--prefix=/' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=/usr/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-auth-negotiate--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-basic-auth-helpers=LDAP,digest' '--enable-digest-auth-helpers=ldap,password' '--enable-arp-acl' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-filedescriptors=65536' '--with-large-files' '--disable-snmp' '--with-default-user=squid' '--disable-ipv6' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -g -Wall -O2' 'LDFLAGS=' 'CPPFLAGS=' 'CXXFLAGS=-g -O2 -g -Wall -O2' '--enable-ltdl-convenience'


----

Regards,

Fred

http://numsys.eu
http://e2guardian.org


From Job at colliniconsulting.it  Thu Feb  5 11:46:20 2015
From: Job at colliniconsulting.it (Job)
Date: Thu, 5 Feb 2015 12:46:20 +0100
Subject: [squid-users] Blocking hotshield vpn
Message-ID: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF2@W2008DC01.ColliniConsulting.lan>

Hello,

is there a way to block Hot Shield VPN with Squid, maybe in conjunction with something else?
I made some tries but is seems very difficult to block with Squid+Iptables.

Thank you, best best regards!
Francesco

From yvoinov at gmail.com  Thu Feb  5 12:32:34 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 05 Feb 2015 18:32:34 +0600
Subject: [squid-users] Blocking hotshield vpn
In-Reply-To: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF2@W2008DC01.ColliniConsulting.lan>
References: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF2@W2008DC01.ColliniConsulting.lan>
Message-ID: <54D362E2.7030601@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
No way.

Only before Squid - using Cisco or something like.

Either Cisco acl's, or NBAR protocol discovery.

05.02.2015 17:46, Job ?????:
> Hot Shield VPN

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU02LhAAoJENNXIZxhPexGKAsH/RFgyXpCdw/+7jS5i9a0aGII
NqN6qBG8PmQ9KSzkrAoXf0z8h9tmpyyP2kuB4Q5Dt+xoX26a78SZMV6MpcAFn7ho
qUg/y5EnI2QHaHxDb7esz3IvcsdxbZgdIF/mEtHntDCIWmMdU0i0ERb6iZH6zyni
dQVJPQu0Qg+EwCCCdD6HArTLrMH71acIbxmwnxRZJJ3pgx/FlSJxZQC6KorsjSN6
5/Cz494MTVGqxa5TgCTzR1BbZ7lHITvvkw8aUuY7/ef7n/L9m2wqD+tJTwqFp4jB
APXQsCLwc0s3xWBgfnC7wkuPDrXMXd47A8786CXvnndb2A7hjcgF2oIn0iHZCgk=
=8es9
-----END PGP SIGNATURE-----



From sis at open.ch  Thu Feb  5 13:47:23 2015
From: sis at open.ch (Simon Staeheli)
Date: Thu, 05 Feb 2015 14:47:23 +0100
Subject: [squid-users] =?utf-8?q?_benefits_of_using_ext=5Fkerberos=5Fldap?=
 =?utf-8?q?=5Fgroup=5Facl=09instead_of_ext=5Fldap=5Fgroup=5Facl?=
Message-ID: <f4d35d1f8cca0da32da949d6f56d0d1c@open.ch>


>> "Amos Jeffries"  wrote in message news:54BE3B5C.8040800 at 
>> treenet.co.nz...
>> 
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>> 
>> On 20/01/2015 11:31 p.m., Simon St?heli wrote:
>>> Are there any other benefits in using ext_kerberos_ldap_group_acl
>>> instead of ext_ldap_group_acl except the "Netbios name to Kerberos
>>> domain name? mappings provided by the -N option. As far as I can
>>> tell, this mapping can also easily be done by writing you own
>>> helper perl script which is doing the mapping and finally feeds the
>>> more common ext_ldap_group_acl helper.
>>> 
>> 
>> Whatever floats your boat. The point of the Addon/Plugin/helpers API
>> is that you can use scripts if thy serve your needs better.
>> 
>> All the usual Open Source benefits of "many eyeballs" and somebody
>> else doing code maintenance for you applies to using a bundled helper
>> over a custom written one.
>> 
>> Beyond that the kerberos helper also provides automatic detection of
>> which LDAP server to use via mutiple auto-configuration methods.
>> 
> 
> The idea of the helper was to automate most of the configuration ( 
> ignoring
> some performance ) and avoid using a username/password, support users 
> from
> multiple domains. Secondly I wanted check for nested groups which was 
> not
> available in the existing helper and thirdly I also check now against 
> the
> primary group of the user.
> 

Thank you Markus for your explanations. I played around with 
ext_kerberos_ldap_group_acl and would like to go into some details:

1) it is possible to define more than one LDAP server (e.g. for high 
availability reasons)? The -l parameter allows only one ldap url while 
-S allows several "server > realm" - mappings.

2) It is correct, that compared to ext_ldap_group_acl, 
ext_kerberos_ldap_group_acl does not require a groupname as input (from 
stdin), because -g -t -T or -D control the group name?!

3) What is the use case for defining -g GROUP@? What is the difference 
to -g GROUP (without @)

4) The "query DNS for SRV record _ldap._tcp.REALM" mechanism seems no to 
work for me although the DNS server is configured correctly and querying 
with "dig SRV _ldap._tcp.REALM" works fine. Anything to consider here? 
_ldap._tcp.REALM SRV query was never sent so far.

5) Similar issues with the Kerberos feature. Keytab und Kerberos config 
are available and exported, but the helper only says:
support_ldap.cc(888): DEBUG: Setup Kerberos credential cache
support_ldap.cc(897): DEBUG: Kerberos is not supported. Use 
username/password with ldap url instead

Instead of that I found a dns SRV _kerberos._udp.REALM query which was 
actually answered by the dns. I assume this is related to the Kerberos 
feature?

6) It is possible to use the helper when DNS service is not reachable? 
Got some error messages during testing:

kerberos_ldap_group: DEBUG: Canonicalise ldap server name 
213.156.236.111:3268
kerberos_ldap_group: ERROR: Error while resolving ip address with 
getnameinfo: Temporary failure in name resolution
kerberos_ldap_group: DEBUG: Error during initialisation of ldap 
connection: Success

Beside this tiny issues the helper works excellent (tested with basic, 
NTLM and Kerberos authentication). I am just trying to discover the 
whole potential. Thank you very much for any responses.

Regards
Simon

>> If you can demonstrate that the ext_kerberos_ldap_group_acl does
>> provides a superset of the functionality of ext_ldap_group_acl helper
>> then I can de-duplicate the two helpers.
>> 
>> Amos
> 
> Regards
> Markus


From dig at digcorp.net  Thu Feb  5 14:17:57 2015
From: dig at digcorp.net (Daniel Greenwald)
Date: Thu, 5 Feb 2015 09:17:57 -0500
Subject: [squid-users] Blocking hotshield vpn
In-Reply-To: <54D362E2.7030601@gmail.com>
References: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF2@W2008DC01.ColliniConsulting.lan>
 <54D362E2.7030601@gmail.com>
Message-ID: <CAOsHgttUrQAGGDg8YFmaLoMg9Q8nvZefQUUQ=DbrCHMHVgz1XQ@mail.gmail.com>

Yuri- Why can't he just block the dstdomain?

-----------
Daniel I Greenwald



On Thu, Feb 5, 2015 at 7:32 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> No way.
>
> Only before Squid - using Cisco or something like.
>
> Either Cisco acl's, or NBAR protocol discovery.
>
> 05.02.2015 17:46, Job ?????:
> > Hot Shield VPN
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU02LhAAoJENNXIZxhPexGKAsH/RFgyXpCdw/+7jS5i9a0aGII
> NqN6qBG8PmQ9KSzkrAoXf0z8h9tmpyyP2kuB4Q5Dt+xoX26a78SZMV6MpcAFn7ho
> qUg/y5EnI2QHaHxDb7esz3IvcsdxbZgdIF/mEtHntDCIWmMdU0i0ERb6iZH6zyni
> dQVJPQu0Qg+EwCCCdD6HArTLrMH71acIbxmwnxRZJJ3pgx/FlSJxZQC6KorsjSN6
> 5/Cz494MTVGqxa5TgCTzR1BbZ7lHITvvkw8aUuY7/ef7n/L9m2wqD+tJTwqFp4jB
> APXQsCLwc0s3xWBgfnC7wkuPDrXMXd47A8786CXvnndb2A7hjcgF2oIn0iHZCgk=
> =8es9
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150205/184a5480/attachment.htm>

From yvoinov at gmail.com  Thu Feb  5 14:19:23 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 05 Feb 2015 20:19:23 +0600
Subject: [squid-users] Blocking hotshield vpn
In-Reply-To: <CAOsHgttUrQAGGDg8YFmaLoMg9Q8nvZefQUUQ=DbrCHMHVgz1XQ@mail.gmail.com>
References: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF2@W2008DC01.ColliniConsulting.lan>
 <54D362E2.7030601@gmail.com>
 <CAOsHgttUrQAGGDg8YFmaLoMg9Q8nvZefQUUQ=DbrCHMHVgz1XQ@mail.gmail.com>
Message-ID: <54D37BEB.4060409@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Try it. Tell us when success.

05.02.2015 20:17, Daniel Greenwald ?????:
> Yuri- Why can't he just block the dstdomain?
>
> -----------
> Daniel I Greenwald
>
>
>
> On Thu, Feb 5, 2015 at 7:32 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> No way.
>
> Only before Squid - using Cisco or something like.
>
> Either Cisco acl's, or NBAR protocol discovery.
>
> 05.02.2015 17:46, Job ?????:
> > Hot Shield VPN
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU03vrAAoJENNXIZxhPexGchgH/1ujoWedqL1B8DLjA4FL2v+o
zeEUxCuaCE3Us51Z9HWukUcAZolIvKZ0oK5QmPjpO11h0Un0Bd1ohoFVGuMuvdxz
05Y6+EO5jz5Qt+r0vW7wGiIx/rQMRbkL6l50CJ5Ksjw3GPXmuax73JxEVF02wJgb
E0svVcKP3PxJIPhPSU5Q5TueShH8kN6nDAa0bBxH8PWFNsDj2OJoWaDIOTdq7WvW
nxH5HCcDNMwRgbmC6weJQnfNA6qx7IRsKUFReQX+6NvcsoUHXxJDM88KBBTewWp6
AZm/1iwe0OKKmkrF+dRMqkkZW/awwo0PYmcOJZhYK5Muu1cou44hwp0HJEVCw0g=
=CXR8
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150205/31aa6a8e/attachment.htm>

From fredbmail at free.fr  Thu Feb  5 15:47:54 2015
From: fredbmail at free.fr (FredB)
Date: Thu, 5 Feb 2015 16:47:54 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <1569464157.334517175.1423127868181.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1513491172.335377782.1423151274769.JavaMail.root@zimbra4-e1.priv.proxad.net>

Stefano, are using identification helper ? And which version of browser ?

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org


From eliezer at ngtech.co.il  Thu Feb  5 15:51:40 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 05 Feb 2015 17:51:40 +0200
Subject: [squid-users] Hypothetically comparing SATA\SAS to NAS\SAN for
 squid.
In-Reply-To: <1423031044701-4669531.post@n4.nabble.com>
References: <52DB73EF.9000407@ngtech.co.il> <52DC7A2C.70306@urlfilterdb.com>
 <52DFB4AE.2090206@ngtech.co.il> <52DFDE6B.5030504@urlfilterdb.com>
 <52E0B7A8.8080009@ngtech.co.il> <1422967529217-4669494.post@n4.nabble.com>
 <54D0CD55.5060302@urlfilterdb.com> <1422975403825-4669503.post@n4.nabble.com>
 <54D10FB3.7090505@urlfilterdb.com> <1423031044701-4669531.post@n4.nabble.com>
Message-ID: <54D3918C.3030001@ngtech.co.il>

Hey Omid,

Before buying any NAS or SAN solution you will need to take in account 
couple things.
Squid has an in memory objects index which requires ram and reduces the 
amount of in memory objects you can store.
You will need to first verify that your current machine memory usage can 
allow you to grow your storage.
250GB*4 can store lots of small objects and there is a chance that you 
will want to utilize more then what your machine can take.

I do not remember the exact numbers for the right calculation so others 
can help with that.

The specific NAS\SAN solution you mentioned is good and it uses windows 
storage server and the best choice of use with this solution is using ISCSI.
 From what I have seen it is using VHD files and not bare disks for 
anything.
The main thing about this storage device is the ease of use.
If it fits your needs and requirements then great.

Another benefit is the HOT-SWAP bay but you will need to verify first 
how the RAID solution is implemented, in the OS level or another.

I do not know what are the local prices for hardware and software at 
your place but I know that HP has microservers with a similar intel ATOM 
cpu and more ram in other prices(the OS costs about 220$).

RAM is important for storage solutions of any kind,type and OS!!!

For squid a NAS(NFS\CIFS) needs to be tested more before production 
usage and a SAN is preferable.

Have you considered using a more recent version of squid? What OS are 
you running?

Eliezer

On 04/02/2015 08:24, Omid Kosari wrote:
> The only reason for extend is more capacity .
> Currently there is no problem with current setup except capacity .
> I can replace each SSD with new 500GB which doubles the capacity and it is
> not enough . and old SSDs will be unusable . So i prefer a long term
> solution like NAS .
>
>
> Current spec of squid boxes are core i3 (with current 3.1.20 version one
> core utilizes) and 16GB of ram . so far so good .




From ansalonistefano at gmail.com  Thu Feb  5 17:09:39 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Thu, 5 Feb 2015 18:09:39 +0100
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <1513491172.335377782.1423151274769.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1569464157.334517175.1423127868181.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1513491172.335377782.1423151274769.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CALkTbdcqrMpyZ78khvzKsGupZcpu4ASyXFktyk86pg=eQT1b4g@mail.gmail.com>

@FrebB:
I really don't know what identification helper is (I'm not a squid guru,
please explain or drop a link).
I'm on firefox 31.4.0esr (slackware linux 13.1).


@Eliezer:
As FredB said, the issue comes up randomly for both http and https sites
(fun fact: if I try to reload a couple of times the website after
receiveing the "cannot connect to proxy" page, the site loads normally).
System info: squid 3.5.1 self compiled on Debian Wheezy 64bits

Squid Cache: Version 3.5.1
Service Name: squid
configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr'
'--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
'--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var'
'--libexecdir=${prefix}/lib/squid3' '--srcdir=.'
'--disable-maintainer-mode' '--disable-dependency-tracking'
'--disable-silent-rules' '--datadir=/usr/share/squid3'
'--sysconfdir=/etc/squid3' '--mandir=/usr/share/man' '--enable-inline'
'--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock'
'--enable-removal-policies=lru,heap' '--enable-delay-pools'
'--enable-cache-digests' '--enable-underscores' '--enable-icap-client'
'--enable-follow-x-forwarded-for'
'--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'
'--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper'
'--enable-auth-ntlm=fake,smb_lm'
'--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group'
'--enable-url-rewrite-helpers=fake' '--enable-ssl-crtd' '--enable-esi'
'--enable-eui' '--enable-icmp' '--enable-zph-qos' '--enable-snmp'
'--disable-translation' '--disable-arch-native' '--with-openssl'
'--with-swapdir=/var/spool/squid3' '--with-logdir=/var/log/squid3'
'--with-pidfile=/var/run/squid3.pid' '--with-filedescriptors=65536'
'--with-large-files' '--with-default-user=proxy' '--enable-linux-netfilter'
'--with-netfilter-conntrack' '--with-libcap' 'build_alias=x86_64-linux-gnu'
'CFLAGS=-g -O2 -fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat
-Werror=format-security -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now'
'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector
--param=ssp-buffer-size=4 -Wformat -Werror=format-security'
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150205/6e18b0f4/attachment.htm>

From leo at technomicssolutions.com  Thu Feb  5 20:01:35 2015
From: leo at technomicssolutions.com (leo at technomicssolutions.com)
Date: Thu, 05 Feb 2015 20:01:35 +0000
Subject: [squid-users] Custom requirement from Squid proxy logs
Message-ID: <f759b53d5cda7ec6838b6dd7d5b1b316@rainloop.technomicssolutions.com>

Hi all,

 I am having a custom requirement. I am monitoring my websites Google Analytics from proxy logs. My website users will be given with my Squid login details and once they login and visit my website, I can get sample logs like this from squid log.

 ===========================

 1423165907.508 122.174.196.92 TCP_MISS 200 GET HIER_DIRECT www.google-analytics.com image/gif http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home*Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%26bvm%3Dbv.85464276%2Cd.cWc&utmp=%2F&utmpg=1:Home%20Page&utmht=1423166006204&utmac=UA-1752831-1&utmni=1&utmcc=__utma%3D147427048.95111128.1423166006.1423166006.1423166006.1%3B%2B__utmz%3D147427048.1423166006.1.1.utmcsr%3Dgoogle%7Cutmccn%3D(organic)%7Cutmcmd%3Dorganic%7Cutmctr%3D(not%2520provided)%3B&utmjid=&utmu=4RAAAAAAAAAAAAAAAAAAABAE%7E

 ============================

 However I can't find what "user" they are logged in as.. The above log is not of my website, however I posted a log for a random website which used Google Analytics.?

 My question is, can I fetch the user name that visitor "logged in" with SquidProxy... Please let me know if any alternatives you are aware of.

 Thanks in advance,
 Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150205/173b4597/attachment.htm>

From yvoinov at gmail.com  Thu Feb  5 20:50:06 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 06 Feb 2015 02:50:06 +0600
Subject: [squid-users] Custom requirement from Squid proxy logs
In-Reply-To: <f759b53d5cda7ec6838b6dd7d5b1b316@rainloop.technomicssolutions.com>
References: <f759b53d5cda7ec6838b6dd7d5b1b316@rainloop.technomicssolutions.com>
Message-ID: <54D3D77E.9090701@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
I think, you can't.

The single alternative I see - using Web-application capabilities.


06.02.2015 2:01, leo at technomicssolutions.com ?????:
> Hi all,
>
> I am having a custom requirement. I am monitoring my websites Google
Analytics from proxy logs. My website users will be given with my Squid
login details and once they login and visit my website, I can get sample
logs like this from squid log.
>
> ===========================
>
> 1423165907.508 122.174.196.92 TCP_MISS 200 GET HIER_DIRECT
www.google-analytics.com image/gif
http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home*Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%26bvm%3Dbv.85464276%2Cd.cWc&utmp=%2F&utmpg=1:Home%20Page&utmht=1423166006204&utmac=UA-1752831-1&utmni=1&utmcc=__utma%3D147427048.95111128.1423166006.1423166006.1423166006.1%3B%2B__utmz%3D147427048.1423166006.1.1.utmcsr%3Dgoogle%7Cutmccn%3D(organic)%7Cutmcmd%3Dorganic%7Cutmctr%3D(not%2520provided)%3B&utmjid=&utmu=4RAAAAAAAAAAAAAAAAAAABAE%7E
>
> ============================
>
> However I can't find what "user" they are logged in as.. The above log
is not of my website, however I posted a log for a random website which
used Google Analytics.
>
> My question is, can I fetch the user name that visitor "logged in"
with SquidProxy... Please let me know if any alternatives you are aware of.
>
> Thanks in advance,
> Leo
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU09d9AAoJENNXIZxhPexGLJgH/R87yQlusU3b+kNhx3q6zl97
xqD7Dt+N/KPASxyJVBp0oLknutUI6bxgGKiIfrlr8sBLPSJ+o/rT/ln++zsG3sKr
pNqRo1GR/DtFjndQ8/ZAwiSoHel17PZNFTIMexmL2YSQbm1Gyf38zTQ+KQ5/AUha
e3r06Rh5shQsLFG//2FxeqCvhlhYk3nImDXYZD9+KnRWFmkAxuXT7OarquweuRmQ
ATmO7EjkrYO2+7nKMDhLbLI5s3H4UGhUV+ccD2OsGl5n3ZTh1vSpC0pDO978T6NN
N+HiVQau1/lutrLsGXcxr9rXZxoEfJG3ZK8FW2YfD39u2TqVO/IW+UfyQdecYyo=
=uFQF
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/d696dbed/attachment.htm>

From leo at technomicssolutions.com  Thu Feb  5 20:59:18 2015
From: leo at technomicssolutions.com (leo at technomicssolutions.com)
Date: Thu, 05 Feb 2015 20:59:18 +0000
Subject: [squid-users] Custom requirement from Squid proxy logs
In-Reply-To: <54D3D77E.9090701@gmail.com>
References: <54D3D77E.9090701@gmail.com>
 <f759b53d5cda7ec6838b6dd7d5b1b316@rainloop.technomicssolutions.com>
Message-ID: <c2b6a1cbd8a1ead7e5c39b501cd2edd9@rainloop.technomicssolutions.com>

Thank you Yuri.

 Can you suggest any of the web application framework or method to get this done.. Can I do the same with web application if I don't have access to the website hosted server.

 In between, I found the following from squid config file.

 ===========================
 ?Defined keywords:
 #
 #???????? user=???????? The users name (login)
 #???????? password=???? The users password (for login= cache_peer option)
 #???????? message=????? Message describing the reason. Available as %o
 #?????????????????????? in error pages
 #???????? tag=????????? Apply a tag to a request (for both ERR and OK results)
 #?????????????????????? Only sets a tag, does not alter existing tags.
 #???????? log=????????? String to be logged in access.log. Available as
 #?????????????????????? %ea in logformat specifications
 ============================

 Can this make any help with my requirements.

 Thanks in advance,
 Leo

 February 6 2015 2:20 AM, "Yuri Voinov"  wrote:  

	? 
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA1
 ?
 I think, you can't.

 The single alternative I see - using Web-application capabilities.
 06.02.2015 2:01, leo at technomicssolutions.com (mailto:leo at technomicssolutions.com) ?????:
> Hi all,
 >
 > I am having a custom requirement. I am monitoring my websites Google Analytics from proxy logs. My website users will be given with my Squid login details and once they login and visit my website, I can get sample logs like this from squid log.
 >
 > ===========================
 >
 > 1423165907.508 122.174.196.92 TCP_MISS 200 GET HIER_DIRECT www.google-analytics.com (http://www.google-analytics.com) image/gif http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home*Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%2 6bvm%3Dbv.85464276%2Cd.cWc&utmp=%2F&utmpg=1:Home%20Page&utmht=1423166006204&utmac=UA-1752831-1&utmni=1&utmcc=__utma%3D147427048.95111128.1423166006.1423166006.1423166006.1%3B%2B__utmz%3D147427048.1423166006.1.1.utmcsr%3Dgoogle%7Cutmccn%3D(organic)%7Cutmcmd%3Dorganic%7Cutmctr%3D(not%2520provided)%3B&utmjid=&utmu=4RAAAAAAAAAAAAAAAAAAABAE%7E (http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home*Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%26bvm%3Dbv.85464276%2Cd.cWc&utmp=%2F&utmpg=1:Home%20Page&utmht=1423166006204&utmac=UA-1752831-1&utmni=1&utmcc=__utma%3D147427048.95111128.142316%0D%0A6006.1423166006.1423166006.1%3B%2B__utmz%3D147427048.1423166006.1.1.utmcsr%3Dgoogle%7Cutmccn%3D(organic)%7Cutmcmd%3Dorganic%7Cutmctr%3D(not%2520provided)%3B&utmjid=&utmu=4RAAAAAAAAAAAAAAAAAAABAE%7E)
 >
 > ============================
 >
 > However I can't find what "user" they are logged in as.. The above log is not of my website, however I posted a log for a random website which used Google Analytics.
 >
 > My question is, can I fetch the user name that visitor "logged in" with SquidProxy... Please let me know if any alternatives you are aware of.
 >
 > Thanks in advance,
 > Leo
 >
 >
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org (mailto:squid-users at lists.squid-cache.org)
 > http://lists.squid-cache.org/listinfo/squid-users (http://lists.squid-cache.org/listinfo/squid-users)

 -----BEGIN PGP SIGNATURE-----
 Version: GnuPG v2
 ?
 iQEcBAEBAgAGBQJU09d9AAoJENNXIZxhPexGLJgH/R87yQlusU3b+kNhx3q6zl97
 xqD7Dt+N/KPASxyJVBp0oLknutUI6bxgGKiIfrlr8sBLPSJ+o/rT/ln++zsG3sKr
 pNqRo1GR/DtFjndQ8/ZAwiSoHel17PZNFTIMexmL2YSQbm1Gyf38zTQ+KQ5/AUha
 e3r06Rh5shQsLFG//2FxeqCvhlhYk3nImDXYZD9+KnRWFmkAxuXT7OarquweuRmQ
 ATmO7EjkrYO2+7nKMDhLbLI5s3H4UGhUV+ccD2OsGl5n3ZTh1vSpC0pDO978T6NN
 N+HiVQau1/lutrLsGXcxr9rXZxoEfJG3ZK8FW2YfD39u2TqVO/IW+UfyQdecYyo=
 =uFQF
 -----END PGP SIGNATURE-----
 ?  

	?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150205/3b64d51d/attachment.htm>

From yvoinov at gmail.com  Thu Feb  5 21:02:30 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 06 Feb 2015 03:02:30 +0600
Subject: [squid-users] Custom requirement from Squid proxy logs
In-Reply-To: <c2b6a1cbd8a1ead7e5c39b501cd2edd9@rainloop.technomicssolutions.com>
References: <54D3D77E.9090701@gmail.com>
 <f759b53d5cda7ec6838b6dd7d5b1b316@rainloop.technomicssolutions.com>
 <c2b6a1cbd8a1ead7e5c39b501cd2edd9@rainloop.technomicssolutions.com>
Message-ID: <54D3DA66.8000707@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
Hmmmmm. AFAIK, Google Analythics has web-site monitoring capability for
webmasters. In doubt about username logging capabilities (I've used it
years ago).

06.02.2015 2:59, leo at technomicssolutions.com ?????:
> Thank you Yuri.
>
> Can you suggest any of the web application framework or method to get
this done.. Can I do the same with web application if I don't have
access to the website hosted server.
>
> In between, I found the following from squid config file.
>
> ===========================
>
>
>  Defined keywords:
> #
> #         user=         The users name (login)
> #         password=     The users password (for login= cache_peer option)
> #         message=      Message describing the reason. Available as %o
> #                       in error pages
> #         tag=          Apply a tag to a request (for both ERR and OK
results)
> #                       Only sets a tag, does not alter existing tags.
> #         log=          String to be logged in access.log. Available as
> #                       %ea in logformat specifications
>
>
> ============================
>
> Can this make any help with my requirements.
>
> Thanks in advance,
> Leo
>
> February 6 2015 2:20 AM, "Yuri Voinov" <yvoinov at gmail.com
<mailto:%22Yuri%20Voinov%22%20<yvoinov at gmail.com>>> wrote:
>
>     
>
>
> I think, you can't.
>
> The single alternative I see - using Web-application capabilities.
>
>
> 06.02.2015 2:01, leo at technomicssolutions.com
<mailto:leo at technomicssolutions.com> ?????:
> > Hi all,
>
> > I am having a custom requirement. I am monitoring my websites Google
Analytics from proxy logs. My website users will be given with my Squid
login details and once they login and visit my website, I can get sample
logs like this from squid log.
>
> > ===========================
>
> > 1423165907.508 122.174.196.92 TCP_MISS 200 GET HIER_DIRECT
www.google-analytics.com <http://www.google-analytics.com> image/gif
http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home*Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%2
6bvm%3Dbv.85464276%2Cd.cWc&utmp=%2F&utmpg=1:Home%20Page&utmht=1423166006204&utmac=UA-1752831-1&utmni=1&utmcc=__utma%3D147427048.95111128.1423166006.1423166006.1423166006.1%3B%2B__utmz%3D147427048.1423166006.1.1.utmcsr%3Dgoogle%7Cutmccn%3D(organic)%7Cutmcmd%3Dorganic%7Cutmctr%3D(not%2520provided)%3B&utmjid=&utmu=4RAAAAAAAAAAAAAAAAAAABAE%7E
<http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home*Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%26bvm%3Dbv.85464276%2Cd.cWc&utmp=%2F&utmpg=1:Home%20Page&utmht=1423166006204&utmac=UA-1752831-1&utmni=1&utmcc=__utma%3D147427048.95111128.142316%0D%0A6006.1423166006.1423166006.1%3B%2B__utmz%3D147427048.1423166006.1.1.utmcsr%3Dgoogle%7Cutmccn%3D(organic)%7Cutmcmd%3Dorganic%7Cutmctr%3D(not%2520provided)%3B&utmjid=&utmu=4RAAAAAAAAAAAAAAAAAAABAE%7E>
>
> > ============================
>
> > However I can't find what "user" they are logged in as.. The above
log is not of my website, however I posted a log for a random website
which used Google Analytics.
>
> > My question is, can I fetch the user name that visitor "logged in"
with SquidProxy... Please let me know if any alternatives you are aware of.
>
> > Thanks in advance,
> > Leo
>
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>     
>
>     
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU09pmAAoJENNXIZxhPexGyZgH/1QPEhpTTWpnQ7P56MzdX9J3
LEjBk0qqyiWnUY96enIZwZ5k+LVMBQe4ACZHHAbt8r7wG3hgXEsVd7Zf6xODpbBJ
f/nIvGOxdFg5gQT+4Ybtb+bPvq9laiFk7pIbZf1BjI1dJrOT96b6dNalvOk+S9FY
s0opzEHEXwGQdNV8jiXORyLc6JiQaxgK8F9P9AROuGW9giazcGK4Bb8Ec2u03qE9
TeVCD6jDuq/laqn0zS+10TDjpejg0cmxmdD2XvoVlbI4HJj16QTUafQk/AhewUOL
G8yLBYzXMoB0Ya+F8MOpkva3qzwk1RvkbXXdoe5dYGloNe7BmvTex74E1+RRW1k=
=b/jR
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/8265a339/attachment.htm>

From leo at technomicssolutions.com  Thu Feb  5 21:23:45 2015
From: leo at technomicssolutions.com (leo at technomicssolutions.com)
Date: Thu, 05 Feb 2015 21:23:45 +0000
Subject: [squid-users] Custom requirement from Squid proxy logs
In-Reply-To: <54D3DA66.8000707@gmail.com>
References: <54D3DA66.8000707@gmail.com> <54D3D77E.9090701@gmail.com>
 <f759b53d5cda7ec6838b6dd7d5b1b316@rainloop.technomicssolutions.com>
 <c2b6a1cbd8a1ead7e5c39b501cd2edd9@rainloop.technomicssolutions.com>
Message-ID: <1026b272a3e0b1737b0063e726bf4ba1@rainloop.technomicssolutions.com>

Actually, I have multiple websites and some using Google Analytics and some uses Adobe. That is why I concentrated on SquidProxy as it logs corresponding entries for all types of analytics. Just to make a analytics independent, can we have any sort of solution..

 Thanks for the advise,
 Leo
 February 6 2015 2:32 AM, "Yuri Voinov"  wrote:  

	? 
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA1
 ?
 Hmmmmm. AFAIK, Google Analythics has web-site monitoring capability for webmasters. In doubt about username logging capabilities (I've used it years ago).

 06.02.2015 2:59, leo at technomicssolutions.com (mailto:leo at technomicssolutions.com) ?????:
> Thank you Yuri.
 >
 > Can you suggest any of the web application framework or method to get this done.. Can I do the same with web application if I don't have access to the website hosted server.
 >
 > In between, I found the following from squid config file.
 >
 > ===========================
 >
 >
 >? Defined keywords:
 > #
 > #???????? user=???????? The users name (login)
 > #???????? password=???? The users password (for login= cache_peer option)
 > #???????? message=????? Message describing the reason. Available as %o
 > #?????????????????????? in error pages
 > #???????? tag=????????? Apply a tag to a request (for both ERR and OK results)
 > #?????????????????????? Only sets a tag, does not alter existing tags.
 > #???????? log=????????? String to be logged in access.log. Available as
 > #?????????????????????? %ea in logformat specifications
 >
 >
 > ============================
 >
 > Can this make any help with my requirements.
 >
 > Thanks in advance,
 > Leo
 >
 > February 6 2015 2:20 AM, "Yuri Voinov"  wrote:
 >
 >?????
 >
 >
 > I think, you can't.
 >
 > The single alternative I see - using Web-application capabilities.
 >
 >
 > 06.02.2015 2:01, leo at technomicssolutions.com (mailto:leo at technomicssolutions.com)  (mailto:leo at technomicssolutions.com) ?????:
 > > Hi all,
 >
 > > I am having a custom requirement. I am monitoring my websites Google Analytics from proxy logs. My website users will be given with my Squid login details and once they login and visit my website, I can get sample logs like this from squid log.
 >
 > > ===========================
 >
 > > 1423165907.508 122.174.196.92 TCP_MISS 200 GET HIER_DIRECT www.google-analytics.com (http://www.google-analytics.com)  (http://www.google-analytics.com) image/gif http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home *Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%2 (http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home*Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%2) 6bvm%3Dbv.85464276%2Cd.cWc&utmp=%2F&utmpg=1:Home%20Page&utmht=1423166006204&utmac=UA-1752831-1&utmni=1&utmcc=__utma%3D147427048.95111128.1423166006.1423166006.1423166006.1%3B%2B__utmz%3D147427048.1423166006.1.1.utmcsr%3Dgoogle%7Cutmccn%3D(organic)%7Cutmcmd%3Dorganic%7Cutmctr%3D(not%2520provided)%3B&utmjid=&utmu=4RAAAAAAAAAAAAAAAAAAABAE%7E  (http://www.google-analytics.com/__utm.gif?utmwv=5.6.2&utms=1&utmn=55310831&utmhn=www.myntra.com&utmt=event&utme=5(Scroll%20Depth%20-%20Home*Percentage*Baseline)(1)8(3!styleRevenueAdjusted6)9(3!test11)11(3!1)&utmcs=UTF-8&utmsr=1366x768&utmvp=1351x647&utmsc=24-bit&utmul=en-us&utmje=0&utmfl=11.2%20r202&utmdt=Online%20Shopping%20India%20-%20Shop%20Online%20for%20Branded%20Shoes%2C%20Clothing%20%26%20Accessories%20in%20India%20%7C%20Myntra.com&utmhid=903208277&utmr=http%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26ved%3D0CCMQFjAA%26url%3Dhttp%253A%252F%252Fwww.myntra.com%252F%26ei%3DLcrTVKONIOTfsAT5xIHQDQ%26usg%3DAFQjCNGo7BJaaJUvqDkxZrfODUrcRXfjBw%26sig2%3Dhfw4tyHy9Tvaxb0nd7BROw%26bvm%3Dbv.85464276%2Cd.cWc&utmp=%2F&utmpg=1:Home%20Page&utmht=1423166006204&utmac=UA-1752831-1&utmni=1&utmcc=__utma%3D147427048.95111128.142316%0D%0A%0D%0A6006.1423166006.1423166006.1%3B%2B__utmz%3D147427048.1423166006.1.1.utmcsr%3Dgoogle%7Cutmccn%3D(organic)%7Cutmcmd%3Dorganic%7Cutmctr%3D(not%2520provided)%3B&utmjid=&utmu=4RAAAAAAAAAAAAAAAAAAABAE%7E)
 >
 > > ============================
 >
 > > However I can't find what "user" they are logged in as.. The above log is not of my website, however I posted a log for a random website which used Google Analytics.
 >
 > > My question is, can I fetch the user name that visitor "logged in" with SquidProxy... Please let me know if any alternatives you are aware of.
 >
 > > Thanks in advance,
 > > Leo
 >
 >
 > > _______________________________________________
 > > squid-users mailing list
 > > squid-users at lists.squid-cache.org (mailto:squid-users at lists.squid-cache.org)  (mailto:squid-users at lists.squid-cache.org)
 > > http://lists.squid-cache.org/listinfo/squid-users (http://lists.squid-cache.org/listinfo/squid-users)
 >
 >?????
 >
 >?????
 >

 -----BEGIN PGP SIGNATURE-----
 Version: GnuPG v2
 ?
 iQEcBAEBAgAGBQJU09pmAAoJENNXIZxhPexGyZgH/1QPEhpTTWpnQ7P56MzdX9J3
 LEjBk0qqyiWnUY96enIZwZ5k+LVMBQe4ACZHHAbt8r7wG3hgXEsVd7Zf6xODpbBJ
 f/nIvGOxdFg5gQT+4Ybtb+bPvq9laiFk7pIbZf1BjI1dJrOT96b6dNalvOk+S9FY
 s0opzEHEXwGQdNV8jiXORyLc6JiQaxgK8F9P9AROuGW9giazcGK4Bb8Ec2u03qE9
 TeVCD6jDuq/laqn0zS+10TDjpejg0cmxmdD2XvoVlbI4HJj16QTUafQk/AhewUOL
 G8yLBYzXMoB0Ya+F8MOpkva3qzwk1RvkbXXdoe5dYGloNe7BmvTex74E1+RRW1k=
 =b/jR
 -----END PGP SIGNATURE-----
 ?  

	?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150205/1a2d3efa/attachment.htm>

From ignazio.raia at eutelia.com  Thu Feb  5 22:43:14 2015
From: ignazio.raia at eutelia.com (Ignazio Raia)
Date: Thu, 5 Feb 2015 14:43:14 -0800 (PST)
Subject: [squid-users] login expired
Message-ID: <1423176194436-4669574.post@n4.nabble.com>

This post has NOT been accepted by the mailing list yet. 

Hello everyone, 
I installed a Squid proxy server and it works perfectly. 
I have two questions to ask about the authentication process. 
1) I configured the basic_db_auth, but the browser keeps asking login and
password even though it is right. In this regard I run the script from the
shell that responds correctly. The file basic_db_auth is in / usr / lib /
squid3. I just changed the parameters related to my mysql db (db name, user,
table name, etc.). 
Can anyone help me and tell me where am I wrong? 

2) Due to the above problem I configured an access control via htpasswd
using basic_ncsa_auth. 
In this case, after the required credentials and the correct insertion squid
gives me access to the internet. 
Now the question is: can I have the credentials expire after a certain time? 
I tried to set credentialttl = 300 seconds, but spent the time with no
activity I do not receive a new login request. 
The parameter credentialttl is designed for this purpose? 

I apologize if I made mistakes trivial, but I'm using Squid recently, so
thanks in advance to all those who will help me to understand. 

Ignazio Raia 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/login-expired-tp4669574.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rprasad at pranastudios.com  Fri Feb  6 02:20:14 2015
From: rprasad at pranastudios.com (Rajkumar Prasad)
Date: Fri, 6 Feb 2015 02:20:14 +0000
Subject: [squid-users] help with regard to http/https filtering
In-Reply-To: <54D1DB56.5060105@measurement-factory.com>
References: <061301d04045$319fed30$94dfc790$@pranastudios.com>,
 <54D1DB56.5060105@measurement-factory.com>
Message-ID: <000f4249.621c07eb04d68c11@pranastudios.com>

Hi Pavel,



Thanks for your help. I did this additional configs and now http http filterings working well for HTTPS enabled sites as well. I have another requirement wherin i need to filter http POST methods, which i am able to do for http sites. Is there a way we can achieve the same for https enabled sites? We need to ensure that there is no way people can send or upload any confidential contents for security reasons.



Thanks much for your help !



Thanks & Regards,

_______________________________________________________________

Rajkumar Prasad

Network Administrator



rprasad at pranastudios.com

_______________________________________________________________





------ Original message------

From: Pavel Kazlenka

Date: Wed, Feb 4, 2015 14:10

To: Rajkumar Prasad;squid-users at lists.squid-cache.org;

Subject:Re: [squid-users] help with regard to http/https filtering



Hi Rajkumar,

You need SSLBump feature (http://wiki.squid-cache.org/Features/SslBump) configured in order to use url_regex acl against https traffic.

Best wishes,
Pavel

On 02/04/2015 09:38 AM, Rajkumar Prasad wrote:
Hi Everyone,

Have been working on very basic squid configurations and need a small help. We have done this setup for everyone to provide very limited access on restricted no of websites. My question here is that, is there a way we can control entire certain part of URL to be getting dropped instead of whole website and other contents. For e.g.

We need to have access to http://renderman.pixar.com however we want to control an internal link within it "https://renderman.pixar.com/forum/download.php & https://renderman.pixar.com/forum/teamviewer.php" . I see these are HTTPS enabled portal and maybe I am unable to. My intention is to block these specific URL's, keeping rest other navigation working. I tried url_regex and urlpath_regex and those are not seems to be working.

See if you can add a little help.

Thanks
Rajkumar




_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/11700265/attachment.htm>

From luismiguelferreirasilva at gmail.com  Fri Feb  6 05:10:00 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Thu, 5 Feb 2015 22:10:00 -0700
Subject: [squid-users] SSL-bump certificate issues (mostly on Chrome,
	when accessing Google websites)
Message-ID: <CA+suCFhBx5ycFy0eBRNzTApjWDkg3mR7u2fywQvtBSbqHgfNiA@mail.gmail.com>

Dear all,

I recently compiled squid-3.4.9 with ssl-bump support and, although it is
working for the most part, I'm having some issues accessing some websites.

The behavior is REALLY weird so I'm going to try and describe it the best I
can:
- If i access https://www.google.com/ in Chrome, I could see that it was
processing my certificate MOST of the times...
*screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg
- some other times, it seemed to bypass my proxy altogether and I finally
figured out it was because Chrome will try to access QUIC enabled websites
using that protocol, so it would bypass my firewall redirect rules! I
believe I now have solved this by blocking FORWARDING traffic on port 443
udp...
- the weird thing is that, if I then try and access https://gmail.com, I
get a certificate error:
*screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg#1
- ...though, sometimes, I can access https://mail.gmail.com/ just fine
(without any certificate errors), but stop being able to as soon as I try
to access https://gmail.com/ and the browser complains about the
certificate.
-- and, according to my tests, I can access it from firefox just fine MOST
of the times:
*screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg#2
-- though I have also seen situations where Firefox also complains about a
certificate error when connecting to gmail.com
- and, although I cannot reproduce it 100% of the times, sometimes, even
though I have my iptables redirect rules ON, the browser still seems to
"connect direct" (or, at least, it shows it has the original certificate)!
-- like I said, at first, I was able to trace this back to QUIC in Chrome
but...I'm currently blocking traffic on port 443 udp so I don't know what's
happening here (does it use different ports?!)

So, here are *my questions*:
- why am I able to successfully ssl-bump https://www.google.com but not
https://gmail.com/
- why does the Chrome freakout about gmail but not Firefox?
- Is there a way to fix it OR, at least, to bypass it? (I tried creating an
ACL for this and allowing direct traffic but it didn't seem to work...)
-- can we make the connection go direct when ssl certificate errors are
detected?
- and has anyone else seen this problem where the browser seems to use the
original certificate, even though I'm redirecting traffic to Squid?

Not sure if this is relevant, but here are some ssl errors I caught on my
cache.log file:
root at server:/var/log/squid3# tail cache.log
2015/02/05 21:47:52 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 30: Closed by client
2015/02/05 21:48:23 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 30: Closed by client
2015/02/05 21:48:36 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 96: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
alert unknown ca (1/0)
2015/02/05 21:48:54 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 105: Closed by client
2015/02/05 21:49:15 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 79: Broken pipe (32)
2015/02/05 21:49:15 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 54: Broken pipe (32)
2015/02/05 21:49:24 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 79: Closed by client
2015/02/05 21:49:55 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 26: Closed by client
2015/02/05 21:50:26 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 45: Closed by client
2015/02/05 21:50:56 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 68: Closed by client
root at server:/var/log/squid3#

By the way, here's how I generated my certificate:
openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keyout myCA.pem
-out myCA.pem
openssl x509 -in myCA.pem -outform DER -out certificate.der
(note: myCA.pem is the certificate that squid is using and certificate.der
is the one I've been installing on the client computers)

And here's what my current squid.conf looks like:
root at server:/etc/squid3/ssl_cert# cat /etc/squid3/squid.conf
#Access Lists
acl home_network src 192.168.200.0/24

#Ports allowed through Squid
acl Safe_ports port 80 #http
acl Safe_ports port 443 #https
acl SSL_ports port 443
acl SSL method CONNECT
acl CONNECT method CONNECT

#allow/deny
http_access allow home_network
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all

http_port 3128
http_port 3129 intercept
https_port 3130 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/myCA.pem
acl broken_sites dstdomain .gmail.com
ssl_bump none localhost
ssl_bump none broken_sites
ssl_bump server-first all
sslcrtd_program /usr/lib/squid3/ssl_crtd -s
/usr/share/squid3/var/lib/ssl_db -M 4MB
sslcrtd_children 5

#caching directory
cache_dir ufs /var/spool/squid3 1024 16 128
cache_mem 1024 MB

#refresh patterns for caching static files
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200
override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90%
432000 override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$
10080 90% 43200 override-expire ignore-no-cache ignore-no-store
ignore-private
refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
refresh_pattern . 0 40% 40320

dns_nameservers 8.8.8.8

#rewrite program
redirect_program /etc/squid3/filter.php
root at server:/etc/squid3/ssl_cert#

Thanks in advance,
Luis
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150205/faed45ed/attachment.htm>

From pavel.kazlenka at measurement-factory.com  Fri Feb  6 05:39:01 2015
From: pavel.kazlenka at measurement-factory.com (Pavel Kazlenka)
Date: Fri, 06 Feb 2015 08:39:01 +0300
Subject: [squid-users] help with regard to http/https filtering
In-Reply-To: <000f4249.621c07eb04d68c11@pranastudios.com>
References: <061301d04045$319fed30$94dfc790$@pranastudios.com>,
 <54D1DB56.5060105@measurement-factory.com>
 <000f4249.621c07eb04d68c11@pranastudios.com>
Message-ID: <54D45375.1060107@measurement-factory.com>

Hi Rajkumar,

You probably need something like
acl NoUpload method POST
acl NoUpload method UPLOAD
....
ssl_bump deny NoUpload


Best wishes,
Pavel

On 02/06/2015 05:20 AM, Rajkumar Prasad wrote:
>
> Hi Pavel,
>
> Thanks for your help. I did this additional configs and now http http 
> filterings working well for HTTPS enabled sites as well. I have 
> another requirement wherin i need to filter http POST methods, which i 
> am able to do for http sites. Is there a way we can achieve the same 
> for https enabled sites? We need to ensure that there is no way people 
> can send or upload any confidential contents for security reasons.
>
> Thanks much for your help !
>
> Thanks & Regards,
>
> _______________________________________________________________
>
> Rajkumar Prasad
>
> Network Administrator
>
> rprasad at pranastudios.com
>
> _______________________________________________________________
>
> ------ Original message------
>
> *From: *Pavel Kazlenka
>
> *Date: *Wed, Feb 4, 2015 14:10
>
> *To: *Rajkumar Prasad;squid-users at lists.squid-cache.org;
>
> *Subject:*Re: [squid-users] help with regard to http/https filtering
>
> Hi Rajkumar,
>
> You need SSLBump feature 
> (http://wiki.squid-cache.org/Features/SslBump) configured in order to 
> use url_regex acl against https traffic.
>
> Best wishes,
> Pavel
>
> On 02/04/2015 09:38 AM, Rajkumar Prasad wrote:
>>
>> Hi Everyone,
>>
>> Have been working on very basic squid configurations and need a small 
>> help. We have done this setup for everyone to provide very limited 
>> access on restricted no of websites. My question here is that, is 
>> there a way we can control entire certain part of URL to be getting 
>> dropped instead of whole website and other contents. For e.g.
>>
>> We need to have access to http://renderman.pixar.com 
>> <http://renderman.pixar.com> however we want to control an internal 
>> link within it ?https://renderman.pixar.com/forum/download.php & 
>> https://renderman.pixar.com/forum/teamviewer.php? . I see these are 
>> HTTPS enabled portal and maybe I am unable to. My intention is to 
>> block these specific URL?s, keeping rest other navigation working. I 
>> tried url_regex and urlpath_regex and those are not seems to be working.
>>
>> See if you can add a little help.
>>
>> Thanks
>> Rajkumar
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/444229e4/attachment.htm>

From priyaiitmandi at gmail.com  Fri Feb  6 07:27:21 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Fri, 6 Feb 2015 12:57:21 +0530
Subject: [squid-users] Squid Source Code: What files/functions
 receive/send packets from/to hardware
In-Reply-To: <CALTPfpGWfoh1q0pnnDMLF6Zm7vaKBO1N_rNq7YM2kYQyJV-jew@mail.gmail.com>
References: <CALTPfpHJ_CX8T7YiwU0knvAyQD72VA5HZqYsdPvBqi4ABtkMPQ@mail.gmail.com>
 <54AABA53.1080408@treenet.co.nz>
 <CALTPfpEWb4CKDyAS7Y5xdL1RKtxi3ANd=kpALFRiFyXtgSLW9w@mail.gmail.com>
 <54AADB39.1010200@treenet.co.nz>
 <CALTPfpGWfoh1q0pnnDMLF6Zm7vaKBO1N_rNq7YM2kYQyJV-jew@mail.gmail.com>
Message-ID: <CALTPfpGFP16S7qM+zQMWk-Oi2NcU3XC1JDZ3T+Tyit1mmMYm7g@mail.gmail.com>

Hi,
I needed some direction again. I also need to know where in the source code
does squid open the network interface before it reads/writes from it.
Thanks.

Regards

On Tue, Jan 6, 2015 at 11:37 AM, Priya Agarwal <priyaiitmandi at gmail.com>
wrote:

> Thanks a lot. :)
> I'll sign up for squid-dev mailing list and do any further discussions
> there.
>
>
> On Tue, Jan 6, 2015 at 12:13 AM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 6/01/2015 6:01 a.m., Priya Agarwal wrote:
>> > Thank you for the reply.
>> >
>> > I do not intend to change its functionality. I just want to make it
>> > run on a processor (Freescale's T4240). For that it has to use some
>> > new architectural features (Data Path Acceleration Architecture)
>> > which are a part of the processor.
>> >
>> > For e.g. suppose squid was merely swapping ipv4/mac src and dest
>> > addresses( just an example! ) in the packet header and sends it
>> > back. So I don't want to change what it does, I just want squid to
>> > send whatever data it has prepared to a memory location. Basically
>> > instead of receiving and sending to OS Stack, I want to it read and
>> > write from memory.  (Further details : This memory is basically a
>> > memory-mapped device which is further responsible for transmitting
>> > the frame to a network interface, ethernet)
>> >
>> > So maybe if I could know where in the source code does it
>> > communicate with the OS stack.
>>
>> Ah, that kind of packet handling is all much, much lower level than Squid.
>>
>> Squid uses functions provided by the POSIX system API with socket
>> handles/"filedescriptors".
>>
>> http://man7.org/linux/man-pages/man7/socket.7.html
>> http://man7.org/linux/man-pages/man2/read.2.html
>> http://man7.org/linux/man-pages/man2/write.2.html
>>
>> The functions in src/fd.cc are where that happens, the lowest
>> networking-I/O level of Squid.
>>
>>
>> NP: If you want to take this further and/or discuss any other feature
>> additions/changes I encourage you to sign up to squid-dev mailing list
>> and discuss it with the whole dev team. This list is for general user
>> discussions, (though sometimes code talk from someone doing bug
>> investigations does slip in).
>>
>> Amos
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2.0.22 (MingW32)
>>
>> iQEcBAEBAgAGBQJUqts4AAoJELJo5wb/XPRjJu4IANCAhXt7PM48xHkERw/mz/sa
>> heSoEC7nJXaLpRz9JSq085UY2F0p55/GH0Gdh+XLq0h6kMLZB8qYTify0WMp18Jj
>> sfVOhuURZVdabS5ldW2ZrqftsqCt5eu3JvgHtQ+ewp8RhN5OI6OTQbCL9sf6llWY
>> Vqm1gno2IymyjcsuPYzpDv7sw7M3odJSETAD2eh6E3r+++uN1q5R4JZ7GZt5mgaE
>> tIJF0DyOlhAfAJIniCImZ0MDqWHLWjrzLWZRazHg4zA025TinDxkjy+qfHnjYfDc
>> oIFh9t/mtSbHPnBiZmsyUDOfl/wB0EOMuXEItoLGgBLh/71huVf2QRmfXUr6qS8=
>> =oajV
>> -----END PGP SIGNATURE-----
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/f1910c1b/attachment.htm>

From jborrell at central.aplitec.com  Fri Feb  6 07:59:25 2015
From: jborrell at central.aplitec.com (Josep Borrell)
Date: Fri, 6 Feb 2015 07:59:25 +0000
Subject: [squid-users] derive HTTP/HTTPS upload traffic to a secondary
	interface.
Message-ID: <42DE25A255671C44A93A7B58470DC09C5E2F7C6F@Michelle.aplitec.local>

Hi,

I have a squid box with two interfaces. One ADSL 20/1Mb and one SHDSL 4/4Mb.
It is a school and they are working with Google Apps for Education.
They do a lot of uploading and when using the ADSL, it collapses promptly.
Is possible to derive only HTTP/HTTPS upload traffic to the SHDSL and continue surfing with the ADSL ?
Maybe using one acl with methods POST and UPLOAD and some routing magic ?
Thoughts are welcome.

Thanks

Josep










-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/7db97554/attachment.htm>

From yvoinov at gmail.com  Fri Feb  6 08:05:02 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 06 Feb 2015 14:05:02 +0600
Subject: [squid-users] SSL-bump certificate issues (mostly on Chrome,
 when accessing Google websites)
In-Reply-To: <CA+suCFhBx5ycFy0eBRNzTApjWDkg3mR7u2fywQvtBSbqHgfNiA@mail.gmail.com>
References: <CA+suCFhBx5ycFy0eBRNzTApjWDkg3mR7u2fywQvtBSbqHgfNiA@mail.gmail.com>
Message-ID: <54D475AE.9070300@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
First. Where is you cache can found openssl public CA certs? To validate
connection from cache to server Squid must see root authority CA's.

I.e (from my configuration. Note: all google services bumped and works
perfectly):

https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt
key=/usr/local/squid/etc/rootCA.key capath=/etc/opt/csw/ssl/certs

Second. OpenSSL CA's bundle is not complete. You must add ALL
intermediate and absent root CA's and make c_rehash.

Third.
Where is

sslproxy_cert_error allow all

and

sslproxy_flags DONT_VERIFY_PEER

in your configuration? Yes, this is dangerous, but permit to suppress
errors on some sites.

And finally - you can't bypass ssl bump on 3.4.x using dstdomain ACL's.
Only IP-based DST acl's usable.

Regards,
Yuri.

06.02.2015 11:10, Luis Miguel Silva ?????:
> Dear all,
>
> I recently compiled squid-3.4.9 with ssl-bump support and, although it
is working for the most part, I'm having some issues accessing some
websites.
>
> The behavior is REALLY weird so I'm going to try and describe it the
best I can:
> - If i access https://www.google.com/ in Chrome, I could see that it
was processing my certificate MOST of the times...
> *screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg
> - some other times, it seemed to bypass my proxy altogether and I
finally figured out it was because Chrome will try to access QUIC
enabled websites using that protocol, so it would bypass my firewall
redirect rules! I believe I now have solved this by blocking FORWARDING
traffic on port 443 udp...
> - the weird thing is that, if I then try and access https://gmail.com
<https://gmail.com/>, I get a certificate error:
> *screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg#1
> - ...though, sometimes, I can access https://mail.gmail.com/ just fine
(without any certificate errors), but stop being able to as soon as I
try to access https://gmail.com/ and the browser complains about the
certificate.
> -- and, according to my tests, I can access it from firefox just fine
MOST of the times:
> *screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg#2
> -- though I have also seen situations where Firefox also complains
about a certificate error when connecting to gmail.com <http://gmail.com/>
> - and, although I cannot reproduce it 100% of the times, sometimes,
even though I have my iptables redirect rules ON, the browser still
seems to "connect direct" (or, at least, it shows it has the original
certificate)!
> -- like I said, at first, I was able to trace this back to QUIC in
Chrome but...I'm currently blocking traffic on port 443 udp so I don't
know what's happening here (does it use different ports?!)
> 
> So, here are *my questions*:
> - why am I able to successfully ssl-bump https://www.google.com
<https://www.google.com/> but not https://gmail.com/
> - why does the Chrome freakout about gmail but not Firefox?
> - Is there a way to fix it OR, at least, to bypass it? (I tried
creating an ACL for this and allowing direct traffic but it didn't seem
to work...)
> -- can we make the connection go direct when ssl certificate errors
are detected?
> - and has anyone else seen this problem where the browser seems to use
the original certificate, even though I'm redirecting traffic to Squid?
>
> Not sure if this is relevant, but here are some ssl errors I caught on
my cache.log file:
> root at server:/var/log/squid3# tail cache.log
> 2015/02/05 21:47:52 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 30: Closed by client
> 2015/02/05 21:48:23 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 30: Closed by client
> 2015/02/05 21:48:36 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 96: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
alert unknown ca (1/0)
> 2015/02/05 21:48:54 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 105: Closed by client
> 2015/02/05 21:49:15 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 79: Broken pipe (32)
> 2015/02/05 21:49:15 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 54: Broken pipe (32)
> 2015/02/05 21:49:24 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 79: Closed by client
> 2015/02/05 21:49:55 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 26: Closed by client
> 2015/02/05 21:50:26 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 45: Closed by client
> 2015/02/05 21:50:56 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 68: Closed by client
> root at server:/var/log/squid3#
>
> By the way, here's how I generated my certificate:
> openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keyout
myCA.pem -out myCA.pem
> openssl x509 -in myCA.pem -outform DER -out certificate.der
> (note: myCA.pem is the certificate that squid is using and
certificate.der is the one I've been installing on the client computers)
>
> And here's what my current squid.conf looks like:
> root at server:/etc/squid3/ssl_cert# cat /etc/squid3/squid.conf
> #Access Lists
> acl home_network src 192.168.200.0/24 <http://192.168.200.0/24>
>
> #Ports allowed through Squid
> acl Safe_ports port 80 #http
> acl Safe_ports port 443 #https
> acl SSL_ports port 443
> acl SSL method CONNECT
> acl CONNECT method CONNECT
>
> #allow/deny
> http_access allow home_network
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access deny all
>
> http_port 3128
> http_port 3129 intercept
> https_port 3130 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/myCA.pem
> acl broken_sites dstdomain .gmail.com <http://gmail.com/>
> ssl_bump none localhost
> ssl_bump none broken_sites
> ssl_bump server-first all
> sslcrtd_program /usr/lib/squid3/ssl_crtd -s
/usr/share/squid3/var/lib/ssl_db -M 4MB
> sslcrtd_children 5
>
> #caching directory
> cache_dir ufs /var/spool/squid3 1024 16 128
> cache_mem 1024 MB
>
> #refresh patterns for caching static files
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200
override-expire ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200
90% 432000 override-expire ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i
\.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$ 10080 90% 43200
override-expire ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
> refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
> refresh_pattern . 0 40% 40320
>
> dns_nameservers 8.8.8.8
>
> #rewrite program
> redirect_program /etc/squid3/filter.php
> root at server:/etc/squid3/ssl_cert#
>
> Thanks in advance,
> Luis
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU1HWtAAoJENNXIZxhPexGiRcH/A2QfRyPsmM9LhKR6ZuqTfhR
AWyg8omvGOeKwo5W0Czb/Qqo4XhtIe+jcXxFqmrvL+zxmrl66tRXp0mBDmp1FMPW
kC93hIYn72NZiThPmchqOZ/4IuUNOyJT1ll/Uef7Kr/saIF0zXMh2lkoNR5HCvhN
0nb3dW0QSSivASYB3/0Mm0szCQqLSx/zgIbdCvmlX9H3VwWM/uE88Nfp+CAHygIO
t5vioJbCTPjyFqV2QkX//fuU1ePZC1VrTw5//nMjXfCbpXjLZtgz15ubDcCH3vZ1
beMYpGYbvHUk+hxrwjW394Q+pSAso79x5hwUO3PlZAsKUx/RdhzI91VVRRO9mfE=
=N+mL
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/9e643d8a/attachment.htm>

From Job at colliniconsulting.it  Fri Feb  6 08:09:34 2015
From: Job at colliniconsulting.it (Job)
Date: Fri, 6 Feb 2015 09:09:34 +0100
Subject: [squid-users] R:  Blocking hotshield vpn
In-Reply-To: <54D362E2.7030601@gmail.com>
References: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF2@W2008DC01.ColliniConsulting.lan>,
 <54D362E2.7030601@gmail.com>
Message-ID: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF3@W2008DC01.ColliniConsulting.lan>

Hello Yuri!

>>Only before Squid - using Cisco or something like.
>>Either Cisco acl's, or NBAR protocol discovery.

is there a way to implement a sort of layer 7 for hotshield vpn (or ultrasurf) working on Linux?

Thank you again!
Francesco

From yvoinov at gmail.com  Fri Feb  6 08:24:32 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 06 Feb 2015 14:24:32 +0600
Subject: [squid-users] R:  Blocking hotshield vpn
In-Reply-To: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF3@W2008DC01.ColliniConsulting.lan>
References: <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF2@W2008DC01.ColliniConsulting.lan>,
 <54D362E2.7030601@gmail.com>
 <88EF58F000EC4B4684700C2AA3A73D7A04F5323FBEF3@W2008DC01.ColliniConsulting.lan>
Message-ID: <54D47A40.70306@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
I'm not using linux. :)

Layer 7 filtering requires application-level proxy or DPI. We talking
about filtering, isn't it?

On Cisco this task requires a bit investigation (sniffing and
tcpiputils.com) and simple add some ACL's:

ip access-list extended TO_INET
 remark Network 100 is passed
 permit ip 192.168.100.0 0.0.0.255 any
 remark Hamachi
 deny   ip 25.0.0.0 0.255.255.255 any
 deny   ip 64.34.106.0 0.0.0.255 any
 deny   ip any host 69.25.21.195
 deny   ip any host 74.201.75.195
 deny   ip any host 146.255.195.92
 remark ZenMate servers
 deny   ip any 162.159.244.0 0.0.0.255
 deny   ip any 78.137.96.0 0.0.7.255
 deny   ip any 46.165.192.0 0.0.63.255
 deny   ip any 207.244.64.0 0.0.63.255
 deny   ip any 178.162.128.0 0.0.127.255
 deny   ip any 179.43.128.0 0.0.31.255
 deny   ip any 88.150.192.0 0.0.31.255
 deny   ip any 31.7.56.0 0.0.7.255
 deny   ip any 185.12.44.0 0.0.3.255
 deny   ip any 103.10.197.0 0.0.0.255
 deny   ip any 37.58.48.0 0.0.15.255
 deny   ip any 5.152.192.0 0.0.31.255
 deny   ip any 81.17.16.0 0.0.15.255
 deny   ip any 199.115.112.0 0.0.7.255
 deny   ip any 103.10.199.0 0.0.0.255
 remark Opera Turbo servers
 deny   ip any 37.228.104.0 0.0.7.255
 deny   ip any 141.0.8.0 0.0.7.255
 deny   ip any 82.145.208.0 0.0.15.255
 deny   ip any 195.189.142.0 0.0.1.255
 deny   ip any 185.26.180.0 0.0.3.255
 remark Ultrasurf port
 deny   tcp any any eq 9666
 remark Hola
 deny   ip any host 107.22.193.119
 deny   ip any host 54.225.121.9
 deny   ip any host 54.225.227.202
 deny   ip any host 54.243.128.120
 deny   tcp any any eq 6851
 deny   tcp any any eq 6861
 deny   ip any 107.155.75.0 0.0.0.255
 deny   ip any 103.18.42.0 0.0.0.255
 deny   ip any 103.27.232.0 0.0.0.255
 deny   ip any 103.4.16.0 0.0.0.255
 deny   ip any 103.6.87.0 0.0.0.255
 deny   ip any 104.131.128.0 0.0.15.255
 deny   ip any 106.185.0.0 0.0.127.255
 deny   ip any 106.186.64.0 0.0.63.255
 deny   ip any 106.187.0.0 0.0.63.255
 deny   ip any 107.155.85.0 0.0.0.255
 deny   ip any 107.161.144.0 0.0.7.255
 deny   ip any 107.170.0.0 0.0.127.255
 deny   ip any 107.181.166.0 0.0.0.255
 deny   ip any 107.190.128.0 0.0.15.255
 deny   ip any 107.191.100.0 0.0.3.255
 deny   ip any 108.61.208.0 0.0.1.255
 deny   ip any 109.74.192.0 0.0.15.255
 deny   ip any 128.199.128.0 0.0.63.255
 deny   ip any 14.136.236.0 0.0.0.255
 deny   ip any 149.154.157.0 0.0.0.255
 deny   ip any 149.62.168.0 0.0.3.255
 deny   ip any 151.236.18.0 0.0.0.255
 deny   ip any 158.255.208.0 0.0.0.255
 deny   ip any 162.213.197.0 0.0.0.255
 deny   ip any 162.217.132.0 0.0.3.255
 deny   ip any 162.218.92.0 0.0.1.255
 deny   ip any 162.221.180.0 0.0.1.255
 deny   ip any 162.243.0.0 0.0.127.255
 deny   ip any 167.88.112.0 0.0.3.255
 deny   ip any 168.235.64.0 0.0.3.255
 deny   ip any 173.255.192.0 0.0.15.255
 deny   ip any 176.58.96.0 0.0.31.255
 deny   ip any 176.9.0.0 0.0.255.255
 deny   ip any 177.67.81.0 0.0.0.255
 deny   ip any 178.209.32.0 0.0.31.255
 deny   ip any 178.79.128.0 0.0.63.255
 deny   ip any 192.110.160.0 0.0.0.255
 deny   ip any 192.121.112.0 0.0.0.255
 deny   ip any 192.184.80.0 0.0.7.255
 deny   ip any 192.211.49.0 0.0.0.255
 deny   ip any 192.241.160.0 0.0.31.255
 deny   ip any 192.30.32.0 0.0.3.255
 deny   ip any 192.34.56.0 0.0.7.255
 deny   ip any 192.40.56.0 0.0.0.255
 deny   ip any 192.73.232.0 0.0.7.255
 deny   ip any 192.81.208.0 0.0.7.255
 deny   ip any 192.99.0.0 0.0.255.255
 deny   ip any 198.147.20.0 0.0.0.255
 deny   ip any 198.211.96.0 0.0.15.255
 deny   ip any 198.58.96.0 0.0.31.255
 deny   ip any 199.241.28.0 0.0.3.255
 deny   ip any 208.68.36.0 0.0.3.255
 deny   ip any 209.222.30.0 0.0.0.255
 deny   ip any 213.229.64.0 0.0.63.255
 deny   ip any 217.170.192.0 0.0.15.255
 deny   ip any 217.78.0.0 0.0.15.255
 deny   ip any 23.227.160.0 0.0.0.255
 deny   ip any 23.249.168.0 0.0.1.255
 deny   ip any 23.29.124.0 0.0.0.255
 deny   ip any 31.193.128.0 0.0.15.255
 deny   ip any 31.220.24.0 0.0.3.255
 deny   ip any 37.139.0.0 0.0.31.255
 deny   ip any 37.235.52.0 0.0.0.255
 deny   ip any 41.215.240.0 0.0.0.255
 deny   ip any 41.223.52.0 0.0.0.255
 deny   ip any 46.17.56.0 0.0.7.255
 deny   ip any 46.19.136.0 0.0.7.255
 deny   ip any 46.246.0.0 0.0.127.255
 deny   ip any 46.38.48.0 0.0.7.255
 deny   ip any 46.4.0.0 0.0.255.255
 deny   ip any 5.9.0.0 0.0.255.255
 deny   ip any 50.116.32.0 0.0.15.255
 deny   ip any 66.85.128.0 0.0.63.255
 deny   ip any 74.82.192.0 0.0.31.255
 deny   ip any 77.237.248.0 0.0.1.255
 deny   ip any 81.4.108.0 0.0.3.255
 deny   ip any 85.234.128.0 0.0.31.255
 deny   ip any 88.150.156.0 0.0.3.255
 deny   ip any 91.186.0.0 0.0.31.255
 deny   ip any 92.222.0.0 0.0.255.255
 deny   ip any 92.48.64.0 0.0.63.255
 deny   ip any 94.76.192.0 0.0.63.255
 deny   ip any 95.215.44.0 0.0.3.255
 deny   ip any 96.126.96.0 0.0.7.255
 remark Browsec
 deny   ip any 178.62.64.0 0.0.63.255
 deny   ip any 188.226.128.0 0.0.127.255
 deny   ip any 128.199.192.0 0.0.63.255
 deny   ip any 104.131.0.0 0.0.63.255
 remark Stealthy
 deny   ip any 118.97.128.0 0.0.15.255
 deny   ip any 41.231.0.0 0.0.255.255
 deny   ip any 195.154.0.0 0.0.255.255
 remark AWS botnet
 deny   ip any 54.0.0.0 0.255.255.255
 remark Finally pass internal LAN to NAT
 permit ip 192.168.0.0 0.0.255.255 any

That's all. The same manner you can blocked almost any unwanted
traffic/apps.

Oh, yes. Sometimes landing networks for any VPN/proxy bypass tools can
change. So, you need to monitor network activity and add needful
networks to block list. Or exclude some /32 addressess from ban - for
good sites who are in the same address range as your banned app.

06.02.2015 14:09, Job ?????:
> Hello Yuri!
>
>>> Only before Squid - using Cisco or something like.
>>> Either Cisco acl's, or NBAR protocol discovery.
>
> is there a way to implement a sort of layer 7 for hotshield vpn (or
ultrasurf) working on Linux?
>
> Thank you again!
> Francesco

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU1HpAAAoJENNXIZxhPexGR5IH/3iQtvEdmfDU2RNP3odR5KQ8
j06zL50+0Q+U94Mf3Sk/V3OIeAnw8d3RmbJMVbNMwlwaYL9sqN5ByyInt3CCLQIB
663PVUt/GvuDJIgU2ObUcZVm0Q2tVIpd3hwRF8rc67ZktmdpfXj/RR9dFe/GCx9+
zcxXXAsYl7DHjVfZCeVL3qoqN0tnwtIbO57IDdQCbyuvk30oJ+7jf+Sg7nhLVGol
W7L7vwdlZkJuzkb8GedzxN9Hc9Td7IgOQmBlYHK+E/VwE+yrTSUp6+rHRaGy2nGq
wEwMvyPPFvbTFNsUeUCd3eslcDmcFSDzqnX0aB5LUf0gpmMuuw5XFD/aJKFsi40=
=hjUX
-----END PGP SIGNATURE-----




From squid3 at treenet.co.nz  Fri Feb  6 08:32:16 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 06 Feb 2015 21:32:16 +1300
Subject: [squid-users] SSL-bump certificate issues (mostly on Chrome,
 when accessing Google websites)
In-Reply-To: <CA+suCFhBx5ycFy0eBRNzTApjWDkg3mR7u2fywQvtBSbqHgfNiA@mail.gmail.com>
References: <CA+suCFhBx5ycFy0eBRNzTApjWDkg3mR7u2fywQvtBSbqHgfNiA@mail.gmail.com>
Message-ID: <54D47C10.7020402@treenet.co.nz>

On 6/02/2015 6:10 p.m., Luis Miguel Silva wrote:
> Dear all,
> 
> I recently compiled squid-3.4.9 with ssl-bump support and, although it is
> working for the most part, I'm having some issues accessing some websites.
> 
> The behavior is REALLY weird so I'm going to try and describe it the best I
> can:
> - If i access https://www.google.com/ in Chrome, I could see that it was
> processing my certificate MOST of the times...
> *screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg
> - some other times, it seemed to bypass my proxy altogether and I finally
> figured out it was because Chrome will try to access QUIC enabled websites
> using that protocol, so it would bypass my firewall redirect rules! I
> believe I now have solved this by blocking FORWARDING traffic on port 443
> udp...

reply_header_access Alternate-Protocol deny all

This was added by default in 3.5. Your report now is the final straw for
me I'm backporting it to 3.4 now for adding in the next security release.

NOTE that this firewall bypass behaviour it seems does not qualify for a
CVE security rating because it is an intentional *designed* behaviour of
Chrome using a designed feature of HTTP.



> - the weird thing is that, if I then try and access https://gmail.com, I
> get a certificate error:
> *screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg#1

Because with HTTPS traffic to a proxy the proxy sets up the tunnel using
a) CONNECT request, or b) intercepted port 443 - in both cases
encryption handling happens before any server response message with QUIC
headers gets involved.


> - ...though, sometimes, I can access https://mail.gmail.com/ just fine
> (without any certificate errors), but stop being able to as soon as I try
> to access https://gmail.com/ and the browser complains about the
> certificate.

The google TLS certificate I've read were issued with the CN label
"mail.google.com" plus wildcard for other G* domains. This might be
related to that behaviour if the main CN is mimic'd but the wildcards not.


> -- and, according to my tests, I can access it from firefox just fine MOST
> of the times:
> *screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg#2
> -- though I have also seen situations where Firefox also complains about a
> certificate error when connecting to gmail.com
> - and, although I cannot reproduce it 100% of the times, sometimes, even
> though I have my iptables redirect rules ON, the browser still seems to
> "connect direct" (or, at least, it shows it has the original certificate)!
> -- like I said, at first, I was able to trace this back to QUIC in Chrome
> but...I'm currently blocking traffic on port 443 udp so I don't know what's
> happening here (does it use different ports?!)

Very possible. Since the port is delivered in the Alternate-Protocol
header they can change it anytime. I've see both ports 80 and 443 in
use. Blocking the reply header is the way to be most sure of disabling.


> 
> So, here are *my questions*:
> - why am I able to successfully ssl-bump https://www.google.com but not
> https://gmail.com/
> - why does the Chrome freakout about gmail but not Firefox?

Many reasons. I point at HSTS - which is a collection of certificate
management methods and protocol bits they use to perform things like
cert pinning, side channel verification, etc.

At the base of it TLS was designed from the ground up to be a security
protocol that prevented anybody from hijacking it (like SSL-bump does),
or at least shout loudly to the endpoints if someone does. Only terribly
bad mis-use or security flaws in the protocol allow things like SSL-Bump
to work in the first place. You all have just been lucky so far that so
the Trusted CA system is a big flaw and mis-use of the protocol is rampant.

Google and friends are fighting to fix those flaws. Whenever they
succeed at closing one flaw the hjacking using it "stops working".


> - Is there a way to fix it OR, at least, to bypass it? (I tried creating an
> ACL for this and allowing direct traffic but it didn't seem to work...)
> -- can we make the connection go direct when ssl certificate errors are
> detected?

Lets be clear; *you* are the brokenness here, *you* are the attacker.

 ... when SSL-Bump "dont work" it means the security *is* working.

What you are looking for is not a "fix". It is another security flaw so
you can break their now-improved encryption again.

That should tell you what the answer is.


> - and has anyone else seen this problem where the browser seems to use the
> original certificate, even though I'm redirecting traffic to Squid?
> 
> Not sure if this is relevant, but here are some ssl errors I caught on my
> cache.log file:
> root at server:/var/log/squid3# tail cache.log
> 2015/02/05 21:47:52 kid1| clientNegotiateSSL: Error negotiating SSL
> connection on FD 30: Closed by client
> 2015/02/05 21:48:36 kid1| clientNegotiateSSL: Error negotiating SSL
> connection on FD 96: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
> alert unknown ca (1/0)

> By the way, here's how I generated my certificate:
> openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keyout myCA.pem
> -out myCA.pem
> openssl x509 -in myCA.pem -outform DER -out certificate.der
> (note: myCA.pem is the certificate that squid is using and certificate.der
> is the one I've been installing on the client computers)
> 
> And here's what my current squid.conf looks like:
> root at server:/etc/squid3/ssl_cert# cat /etc/squid3/squid.conf
> #Access Lists
> acl home_network src 192.168.200.0/24
> 
> #Ports allowed through Squid
> acl Safe_ports port 80 #http
> acl Safe_ports port 443 #https
> acl SSL_ports port 443
> acl SSL method CONNECT
> acl CONNECT method CONNECT
> 
> #allow/deny
> http_access allow home_network
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access deny all
> 

Them security controls are not doing much. Its for very good reaons that
we publish this particular order with a big notice about where to put
your access policy rules:

  http_access deny !Safe_ports
  http_access deny CONNECT !SSL_ports

  ## PUT YOUR STUFF HERE
  http_access allow home_network

  http_access deny all

> http_port 3128
> http_port 3129 intercept
> https_port 3130 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/myCA.pem
> acl broken_sites dstdomain .gmail.com
> ssl_bump none localhost
> ssl_bump none broken_sites
> ssl_bump server-first all
> sslcrtd_program /usr/lib/squid3/ssl_crtd -s
> /usr/share/squid3/var/lib/ssl_db -M 4MB
> sslcrtd_children 5
> 
> #caching directory
> cache_dir ufs /var/spool/squid3 1024 16 128
> cache_mem 1024 MB
> 
> #refresh patterns for caching static files
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200
> override-expire ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90%
> 432000 override-expire ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$
> 10080 90% 43200 override-expire ignore-no-cache ignore-no-store
> ignore-private
> refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
> refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
> refresh_pattern . 0 40% 40320
> 
> dns_nameservers 8.8.8.8
> 
> #rewrite program
> redirect_program /etc/squid3/filter.php
> root at server:/etc/squid3/ssl_cert#
> 
> Thanks in advance,
> Luis
> 

HTH
Amos



From fredbmail at free.fr  Fri Feb  6 08:42:17 2015
From: fredbmail at free.fr (FredB)
Date: Fri, 6 Feb 2015 09:42:17 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbdcqrMpyZ78khvzKsGupZcpu4ASyXFktyk86pg=eQT1b4g@mail.gmail.com>
Message-ID: <1593667946.336710440.1423212137806.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> 
> @FrebB:
> I really don't know what identification helper is (I'm not a squid
> guru, please explain or drop a link).
> I'm on firefox 31.4.0esr (slackware linux 13.1).
> 


I mean Authentication from Squid, a pop-up with account (login and password)


> @Eliezer:
> As FredB said, the issue comes up randomly for both http and https
> sites (fun fact: if I try to reload a couple of times the website
> after receiveing the "cannot connect to proxy" page, the site loads
> normally).
> 


Yes me too, and hard to investigate it's a random problem

 





From squid3 at treenet.co.nz  Fri Feb  6 08:56:27 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 06 Feb 2015 21:56:27 +1300
Subject: [squid-users] login expired
In-Reply-To: <1423176194436-4669574.post@n4.nabble.com>
References: <1423176194436-4669574.post@n4.nabble.com>
Message-ID: <54D481BB.3010308@treenet.co.nz>

On 6/02/2015 11:43 a.m., Ignazio Raia wrote:
> This post has NOT been accepted by the mailing list yet. 
> 
> Hello everyone, 
> I installed a Squid proxy server and it works perfectly. 
> I have two questions to ask about the authentication process. 
> 1) I configured the basic_db_auth, but the browser keeps asking login and
> password even though it is right. In this regard I run the script from the
> shell that responds correctly. The file basic_db_auth is in / usr / lib /
> squid3. I just changed the parameters related to my mysql db (db name, user,
> table name, etc.). 
> Can anyone help me and tell me where am I wrong? 

We need to see your squid.conf contents to answer that.

NP: if you are on one of those OS who insist on overwriting squid.conf
with the 270KB documentation file, please drop the comments.
  grep -v -E "^($|#)" squid.conf


At a guess it means the DB could not be connected to, or you forgot
about the --cond parameter default value.


> 
> 2) Due to the above problem I configured an access control via htpasswd
> using basic_ncsa_auth. 
> In this case, after the required credentials and the correct insertion squid
> gives me access to the internet. 
> Now the question is: can I have the credentials expire after a certain time?
> I tried to set credentialttl = 300 seconds, but spent the time with no
> activity I do not receive a new login request. 
> The parameter credentialttl is designed for this purpose?

Yes.

If authentication is working properly you/user should only ever see one
login at start and never again.
The browser is constantly delivering updated/current credentials and
Squid re-verifying those credentials via the helper whenever the TTL
expires or they actually change. But none of that complexity is relevant
to the user - they have not changed.

Amos



From fredbmail at free.fr  Fri Feb  6 09:07:29 2015
From: fredbmail at free.fr (FredB)
Date: Fri, 6 Feb 2015 10:07:29 +0100 (CET)
Subject: [squid-users] login expired
In-Reply-To: <1423176194436-4669574.post@n4.nabble.com>
Message-ID: <1735862250.336775188.1423213649970.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 2) Due to the above problem I configured an access control via
> htpasswd
> using basic_ncsa_auth.
> In this case, after the required credentials and the correct
> insertion squid
> gives me access to the internet.
> Now the question is: can I have the credentials expire after a
> certain time?


I don't known with recent version (3.4 or 3.5) but I guess you can't, there was a way in Wiki but it doesn't works good, so I made a little patch http://numsys.eu/divers/squid/auth.patch for basic auth, but I can't say if it works with the latest Squid ...
Eg: credentialsttl 30 minutes -> After 30 minutes the pop-up appears, very useful to protect your access, the "bad" and hidden requests are banned when the user is gone (in my case spywares and other plugins), also with high load it reduce the Squid works, because many users are disconnected.

With credentialsttl 10 hours, the users are connected the working day and when someone is missing, and his browser is open, his requests are denied (407)

Perhaps a proper way is to create a new option like authentificationttl related with CRED_BANNED (new value in my patch)

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From fredbmail at free.fr  Fri Feb  6 09:08:53 2015
From: fredbmail at free.fr (FredB)
Date: Fri, 6 Feb 2015 10:08:53 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <1593667946.336710440.1423212137806.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <190926614.336777867.1423213733668.JavaMail.root@zimbra4-e1.priv.proxad.net>


I forgot, are you using ICAP protocol (AV)

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From squid3 at treenet.co.nz  Fri Feb  6 09:12:40 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 06 Feb 2015 22:12:40 +1300
Subject: [squid-users] derive HTTP/HTTPS upload traffic to a secondary
 interface.
In-Reply-To: <42DE25A255671C44A93A7B58470DC09C5E2F7C6F@Michelle.aplitec.local>
References: <42DE25A255671C44A93A7B58470DC09C5E2F7C6F@Michelle.aplitec.local>
Message-ID: <54D48588.7030301@treenet.co.nz>

On 6/02/2015 8:59 p.m., Josep Borrell wrote:
> Hi,
> 
> I have a squid box with two interfaces. One ADSL 20/1Mb and one SHDSL 4/4Mb.
> It is a school and they are working with Google Apps for Education.
> They do a lot of uploading and when using the ADSL, it collapses promptly.
> Is possible to derive only HTTP/HTTPS upload traffic to the SHDSL and continue surfing with the ADSL ?

In a roundabout way.

If you look at the OSI model of networking Squid is layers 4-7, and
those interfaces are part of layer 1-2. There is a whole disconnect
layer 3 in between (the TCP/IP layer).

What you can do in Squid is set one of the tcp_outgoing_address,
tcp_outgoing_tos, tcp_outgoing_mark directives to label the TCP traffic
out of Squid. The systems routing rules need to take that detail from
TCP and decide which interface to use.



> Maybe using one acl with methods POST and UPLOAD and some routing magic ?

Somethign like this..

squid.conf:
 acl PUTPOST method PUT POST
 tcp_outgoing_address 192.0.2.1 PUTPOST

Where 192.0.2.1 is the IP address the system uses to send out SHDSDL.
You may need both an IPv4 and IPv6 outgoing address set using PUTPOST acl.

Amos



From squid3 at treenet.co.nz  Fri Feb  6 09:17:31 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 06 Feb 2015 22:17:31 +1300
Subject: [squid-users] SSL-bump certificate issues (mostly on Chrome,
 when accessing Google websites)
In-Reply-To: <54D47C10.7020402@treenet.co.nz>
References: <CA+suCFhBx5ycFy0eBRNzTApjWDkg3mR7u2fywQvtBSbqHgfNiA@mail.gmail.com>
 <54D47C10.7020402@treenet.co.nz>
Message-ID: <54D486AB.10903@treenet.co.nz>

On 6/02/2015 9:32 p.m., Amos Jeffries wrote:
> On 6/02/2015 6:10 p.m., Luis Miguel Silva wrote:
>> Dear all,
>>
>> I recently compiled squid-3.4.9 with ssl-bump support and, although it is
>> working for the most part, I'm having some issues accessing some websites.
>>
>> The behavior is REALLY weird so I'm going to try and describe it the best I
>> can:
>> - If i access https://www.google.com/ in Chrome, I could see that it was
>> processing my certificate MOST of the times...
>> *screenshot here*: http://imgur.com/JsNiqDL,Ned5zAU,nJjRPtg
>> - some other times, it seemed to bypass my proxy altogether and I finally
>> figured out it was because Chrome will try to access QUIC enabled websites
>> using that protocol, so it would bypass my firewall redirect rules! I
>> believe I now have solved this by blocking FORWARDING traffic on port 443
>> udp...
> 
> reply_header_access Alternate-Protocol deny all
> 
> This was added by default in 3.5. Your report now is the final straw for
> me I'm backporting it to 3.4 now for adding in the next security release.

Meh, forgetful. Last straw was a while back. It's in 3.4.10 and later.

So ... "please upgrade to a current release", blah blah blah.

Amos



From squid3 at treenet.co.nz  Fri Feb  6 09:33:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 06 Feb 2015 22:33:46 +1300
Subject: [squid-users] Custom requirement from Squid proxy logs
In-Reply-To: <1026b272a3e0b1737b0063e726bf4ba1@rainloop.technomicssolutions.com>
References: <54D3DA66.8000707@gmail.com> <54D3D77E.9090701@gmail.com>
 <f759b53d5cda7ec6838b6dd7d5b1b316@rainloop.technomicssolutions.com>
 <c2b6a1cbd8a1ead7e5c39b501cd2edd9@rainloop.technomicssolutions.com>
 <1026b272a3e0b1737b0063e726bf4ba1@rainloop.technomicssolutions.com>
Message-ID: <54D48A7A.2060202@treenet.co.nz>

On 6/02/2015 10:23 a.m., leo at technomicssolutions.com wrote:
> Actually, I have multiple websites and some using Google Analytics and some uses Adobe. That is why I concentrated on SquidProxy as it logs corresponding entries for all types of analytics. Just to make a analytics independent, can we have any sort of solution..
> 

Why???  Seriously WHY ?

You are measuring the sub-set of users willing for the analytics
companies to measure *them*. AND the subset out of that of just what the
analytics are measuring.

Whereas you have a reverse-proxy right?
*all* users go through that to your sites, you have access in the proxy
to far more information than the analytics sites ever could.

Amos


From ansalonistefano at gmail.com  Fri Feb  6 11:11:38 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Fri, 6 Feb 2015 12:11:38 +0100
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <190926614.336777867.1423213733668.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1593667946.336710440.1423212137806.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <190926614.336777867.1423213733668.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CALkTbddushPE_YcfBTMrEjK+xPpREdVPpWg7gJCOkexH5xLJDw@mail.gmail.com>

I'm not using authentication (the proxy doesn't require any login/password).
I'm using icap (for clamav).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/cf69ec43/attachment.htm>

From fredbmail at free.fr  Fri Feb  6 11:13:52 2015
From: fredbmail at free.fr (FredB)
Date: Fri, 6 Feb 2015 12:13:52 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbddushPE_YcfBTMrEjK+xPpREdVPpWg7gJCOkexH5xLJDw@mail.gmail.com>
Message-ID: <1100873577.337078600.1423221232079.JavaMail.root@zimbra4-e1.priv.proxad.net>



> I'm using icap (for clamav).
> 


Please, can you make a try without ?


----

Regards,

Fred

http://numsys.eu
http://e2guardian.org

 


From ansalonistefano at gmail.com  Fri Feb  6 13:01:19 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Fri, 6 Feb 2015 14:01:19 +0100
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <1100873577.337078600.1423221232079.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <CALkTbddushPE_YcfBTMrEjK+xPpREdVPpWg7gJCOkexH5xLJDw@mail.gmail.com>
 <1100873577.337078600.1423221232079.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CALkTbddn5rt=2Cv686Xidxw-DVKRaj0bwoi7LmV9E+QFmAf62Q@mail.gmail.com>

Tested with icap disabled: the issue still there.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/e1ebae48/attachment.htm>

From admin at lctn.org  Fri Feb  6 14:37:11 2015
From: admin at lctn.org (Raymond Norton)
Date: Fri, 06 Feb 2015 08:37:11 -0600
Subject: [squid-users] Tunnelled devices losing access to squid
Message-ID: <54D4D197.5080101@lctn.org>

I have the following scenario:



  We have a number of Verizon Aps configured to run associated devices through a GRE
tunnel between Verizon and our network, using a 10.99.0.0/16 subnet which
is NATed to a public address. Policy based routing sends all
port 80 and 443 traffic originating from 10.99.0.0/16 to qlproxy IP
(10.10.1.85) (squid proxy). IPtables on qlproxy box port-forwards all 80
and 443 traffic to 3126 & 3127. Qlproxy (4.0) has appropriate
transparent and ssl_bump rules to process incoming traffic.




Squid logs show the request for web pages is made via the policy based
routing (Mikrotik Firewall/Router), but nothing is returned to the
requesting device. It just simply times out after a long wait.



However, if I configure a tunnelled device to use port 3128 in the proxy
settings of the browser, or if a tunnelled device requests the proxy url
via port 80, web requests start working, as expected for the configured
device , as well as for all devices that are hitting the proxy
transparently from the tunnel.



This will work as long as some form of traffic from the tunnelled
devices is generated. If things are left dormant for 3-5 minutes traffic
will stop working again, until a device requests the proxy url via port
80. As a workaround to minimize complaints I created a cron job, using
wget of the proxy url, which runs every couple minutes. As long as the
wget command runs, Internet works fine for all tunnelled devices.



On a side note, policy routing of local 10.10.0.0/16 devices works just
fine running through the proxy transparently, without interruptions,
even when the tunnelled devices cease working. Internet works fine if we
send tunnelled traffic through and NAT the same as the 10.10.0.0/16 network, bypassing the proxy





Squid config:



icap_enable on
icap_preview_enable on
icap_preview_size 4096
icap_persistent_connections on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Client-Username
icap_service_failure_limit -1
icap_service qlproxy1 reqmod_precache bypass=0 icap://127.0.0.1:1344/reqmod
icap_service qlproxy2 respmod_precache bypass=0 icap://127.0.0.1:1344/respmod
acl qlproxy_icap_edomains dstdomain "/opt/qlproxy/etc/squid/icap_exclusions_domains.conf"
acl qlproxy_icap_etypes rep_mime_type "/opt/qlproxy/etc/squid/icap_exclusions_contenttypes.conf"
adaptation_access qlproxy1 deny qlproxy_icap_edomains
adaptation_access qlproxy2 deny qlproxy_icap_edomains
adaptation_access qlproxy2 deny qlproxy_icap_etypes
adaptation_access qlproxy1 allow all
adaptation_access qlproxy2 allow all
acl localnet src 10.0.0.0/8
acl localnet src 172.16.0.0/12
acl localnet src 192.168.0.0/16
acl localnet src fc00::/7
acl localnet src fe80::/10
acl SSL_ports port 443
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443
acl Safe_ports port 70
acl Safe_ports port 210
acl Safe_ports port 1025-65535
acl Safe_ports port 280
acl Safe_ports port 488
acl Safe_ports port 591
acl Safe_ports port 777
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny all
include "/opt/qlproxy/etc/squid/squid.acl"
http_port  3126 transparent
https_port 3127 transparent ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/opt/qlproxy/etc/myca.pem
http_port  3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/opt/qlproxy/etc/myca.pem
sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/spool/squid3_ssldb -M 4MB
forward_max_tries 25
cache_mem 1024 MB
maximum_object_size_in_memory 1024 KB
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
refresh_pattern .		0	20%	4320
shutdown_lifetime 3 seconds
visible_hostname qlproxy
always_direct allow all
icap_enable on
icap_service_failure_limit -1
icap_preview_enable on
icap_persistent_connections on
adaptation_send_client_ip on
adaptation_send_username on
icap_service qlproxy1 reqmod_precache icap://127.0.0.1:1344/reqmod bypass=0
icap_service qlproxy2 respmod_precache icap://127.0.0.1:1344/respmod bypass=0
acl qlproxy_icap_edomains dstdomain "/opt/qlproxy/etc/squid/icap_exclusions_domains.conf"
acl qlproxy_icap_etypes rep_mime_type "/opt/qlproxy/etc/squid/icap_exclusions_contenttypes.conf"
adaptation_access qlproxy1 deny qlproxy_icap_edomains
adaptation_access qlproxy2 deny qlproxy_icap_edomains
adaptation_access qlproxy2 deny qlproxy_icap_etypes
acl icap_bypass_to_localnet dst 10.0.0.0/8
acl icap_bypass_to_localnet dst 172.16.0.0/12
acl icap_bypass_to_localnet dst 192.168.0.0/16
adaptation_access qlproxy1 deny icap_bypass_to_localnet
adaptation_access qlproxy2 deny icap_bypass_to_localnet
adaptation_access qlproxy1 allow all
adaptation_access qlproxy2 allow all
dns_v4_first on

-- 
Raymond Norton
LCTN
952.955.7766



From squid3 at treenet.co.nz  Fri Feb  6 15:15:57 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 07 Feb 2015 04:15:57 +1300
Subject: [squid-users] Tunnelled devices losing access to squid
In-Reply-To: <54D4D197.5080101@lctn.org>
References: <54D4D197.5080101@lctn.org>
Message-ID: <54D4DAAD.2000108@treenet.co.nz>

On 7/02/2015 3:37 a.m., Raymond Norton wrote:
> I have the following scenario:
> 
> 
> 
>  We have a number of Verizon Aps configured to run associated devices
> through a GRE
> tunnel between Verizon and our network, using a 10.99.0.0/16 subnet which
> is NATed to a public address. Policy based routing sends all
> port 80 and 443 traffic originating from 10.99.0.0/16 to qlproxy IP
> (10.10.1.85) (squid proxy). IPtables on qlproxy box port-forwards all 80
> and 443 traffic to 3126 & 3127. Qlproxy (4.0) has appropriate
> transparent and ssl_bump rules to process incoming traffic.
> 
> 
> 
> 
> Squid logs show the request for web pages is made via the policy based
> routing (Mikrotik Firewall/Router), but nothing is returned to the
> requesting device. It just simply times out after a long wait.
> 

Considered Path-MTU discovery?

Make sure that ICMP (and ICMPv6) are enabled and working on all networks
the traffic traverses between Squid and the devices.

Amos



From yvoinov at gmail.com  Fri Feb  6 17:40:26 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 06 Feb 2015 23:40:26 +0600
Subject: [squid-users] Tunnelled devices losing access to squid
In-Reply-To: <54D4DAAD.2000108@treenet.co.nz>
References: <54D4D197.5080101@lctn.org> <54D4DAAD.2000108@treenet.co.nz>
Message-ID: <54D4FC8A.3000104@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
I have one ;)

http://i.imgur.com/VaPu6pq.png


06.02.2015 21:15, Amos Jeffries ?????:
> On 7/02/2015 3:37 a.m., Raymond Norton wrote:
>> I have the following scenario:
>>
>>
>>
>>  We have a number of Verizon Aps configured to run associated devices
>> through a GRE
>> tunnel between Verizon and our network, using a 10.99.0.0/16 subnet which
>> is NATed to a public address. Policy based routing sends all
>> port 80 and 443 traffic originating from 10.99.0.0/16 to qlproxy IP
>> (10.10.1.85) (squid proxy). IPtables on qlproxy box port-forwards all 80
>> and 443 traffic to 3126 & 3127. Qlproxy (4.0) has appropriate
>> transparent and ssl_bump rules to process incoming traffic.
>>
>>
>>
>>
>> Squid logs show the request for web pages is made via the policy based
>> routing (Mikrotik Firewall/Router), but nothing is returned to the
>> requesting device. It just simply times out after a long wait.
>>
>
> Considered Path-MTU discovery?
>
> Make sure that ICMP (and ICMPv6) are enabled and working on all networks
> the traffic traverses between Squid and the devices.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU1PyJAAoJENNXIZxhPexGJ0kH/07GQNdoSqXlhH9iduf7TJBC
KVWHy1GpHrYmL8CPpvWy64Am5ccczmFgSVxnyLTzC6x/o8b5pSHswYm6XvBsJQYM
gOeAau3i1RHjQQcU8nWwA5K8mFumJvcjvyPt+ImY4Kx+x32nNfRVpgjq2SHzb3gJ
LVNIygHzYb1C3VoRNCCoAU17eFKoJcSRhcIa9TyVjo6Yaxs8Xmg4Zg8zIO+4qwKJ
2dmEFMKDJ6so55OxnaEjoU/1MLjJditNXGkQbjLYaXc5o4ASCC5a6k+xvP8ApYhq
VQFRKv92TAHaoF6ciyj/VVx+vD8U7IS6OmPeeaAa1Ij/tGcawVerGT/ZrPVoYj8=
=r6b4
-----END PGP SIGNATURE-----



From Walter.H at mathemainzel.info  Fri Feb  6 19:19:04 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Fri, 06 Feb 2015 20:19:04 +0100
Subject: [squid-users] Correct order of acl rules?
Message-ID: <54D513A8.2010606@mathemainzel.info>

Hello,

my squid.conf contains the following lines - in this order ...

acl allow_urlpaths urlpath_regex -i 
"/etc/squid/allowurlpaths-regex-acl.squid"
acl block_urlpaths urlpath_regex -i 
"/etc/squid/blockurlpaths-regex-acl.squid"
acl allow_urls url_regex -i "/etc/squid/allowurls-regex-acl.squid" <--
acl block_urls url_regex -i "/etc/squid/blockurls-regex-acl.squid" <--
acl allow_domains_list dstdomain "/etc/squid/allowdomains-list-acl.squid"
acl block_domains_list dstdomain "/etc/squid/blockdomains-list-acl.squid"
acl block_domains_listex dstdomain 
"/etc/squid/blockdomains-listex-acl.squid"
acl allow_domains_regex dstdom_regex -i 
"/etc/squid/allowdomains-regex-acl.squid"
acl block_domains_regex dstdom_regex -i 
"/etc/squid/blockdomains-regex-acl.squid"
deny_info ERR_URL_BLOCKED block_urlpaths
deny_info ERR_URL_BLOCKED block_urls
deny_info ERR_DOMAIN_BLOCKED block_domains_list
deny_info ERR_DOMAIN_BLOCKED block_domains_listex
deny_info ERR_DOMAIN_BLOCKED block_domains_regex
http_access allow allow_urlpaths
http_access deny block_urlpaths
http_access allow allow_urls <--
http_access deny block_urls <--
http_access allow allow_domains_list
http_access deny block_domains_list
http_access deny block_domains_listex
http_access allow allow_domains_regex
http_access deny block_domains_regex

I marked 4 lines and I get a quite strange - or correct - behaviour ...

the file blockurls-regex-acl.squid
contains e.g.
^http:\/\/s[0-9]\.domain\.tld\/

the file allowurls-regex-acl.squid
contains e.g.
^http:\/\/s[1-2]+\.domain\.tld\/[a-z0-9\_\-\.]+\.gif

the purpose should be, that only gif images of root directory of only 
the subdomains beginning with s1 or s2 of domain.tld should be allowed

the following url is blocked

http://s2443.domain.tld/ghfhfhf.gif

why?

Thanks,
Walter


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 5971 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/c8be98fa/attachment.bin>

From squid3 at treenet.co.nz  Fri Feb  6 19:27:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 07 Feb 2015 08:27:54 +1300
Subject: [squid-users] Correct order of acl rules?
In-Reply-To: <54D513A8.2010606@mathemainzel.info>
References: <54D513A8.2010606@mathemainzel.info>
Message-ID: <54D515BA.30608@treenet.co.nz>

On 7/02/2015 8:19 a.m., Walter H. wrote:
> the file blockurls-regex-acl.squid
> contains e.g.
> ^http:\/\/s[0-9]\.domain\.tld\/
> 
> the file allowurls-regex-acl.squid
> contains e.g.
> ^http:\/\/s[1-2]+\.domain\.tld\/[a-z0-9\_\-\.]+\.gif
> 
> the purpose should be, that only gif images of root directory of only
> the subdomains beginning with s1 or s2 of domain.tld should be allowed
> 
> the following url is blocked
> 
> http://s2443.domain.tld/ghfhfhf.gif
> 
> why?

"4" != "\."

Amos



From squid3 at treenet.co.nz  Fri Feb  6 19:38:15 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 07 Feb 2015 08:38:15 +1300
Subject: [squid-users] Correct order of acl rules?
In-Reply-To: <54D515BA.30608@treenet.co.nz>
References: <54D513A8.2010606@mathemainzel.info> <54D515BA.30608@treenet.co.nz>
Message-ID: <54D51827.3030405@treenet.co.nz>

On 7/02/2015 8:27 a.m., Amos Jeffries wrote:
> On 7/02/2015 8:19 a.m., Walter H. wrote:
>> the file blockurls-regex-acl.squid
>> contains e.g.
>> ^http:\/\/s[0-9]\.domain\.tld\/
>>
>> the file allowurls-regex-acl.squid
>> contains e.g.
>> ^http:\/\/s[1-2]+\.domain\.tld\/[a-z0-9\_\-\.]+\.gif
>>
>> the purpose should be, that only gif images of root directory of only
>> the subdomains beginning with s1 or s2 of domain.tld should be allowed

Also, NO that is not what your rules do. Take another look at all the
sub-domains s[1-2]+ will match against...

s1, s2,
s11, s12, s21, s22,
s111, s112, s121, s122, s211, s212, s221, s222,
s1111 ...
...


>>
>> the following url is blocked
>>
>> http://s2443.domain.tld/ghfhfhf.gif
>>
>> why?
> 
> "4" != "\."
> 

Amos



From Walter.H at mathemainzel.info  Fri Feb  6 20:06:57 2015
From: Walter.H at mathemainzel.info (Walter H.)
Date: Fri, 06 Feb 2015 21:06:57 +0100
Subject: [squid-users] Correct order of acl rules?
In-Reply-To: <54D51827.3030405@treenet.co.nz>
References: <54D513A8.2010606@mathemainzel.info>
 <54D515BA.30608@treenet.co.nz> <54D51827.3030405@treenet.co.nz>
Message-ID: <54D51EE1.4000101@mathemainzel.info>

On 06.02.2015 20:38, Amos Jeffries wrote:
> On 7/02/2015 8:27 a.m., Amos Jeffries wrote:
>> On 7/02/2015 8:19 a.m., Walter H. wrote:
>>> the file blockurls-regex-acl.squid
>>> contains e.g.
>>> ^http:\/\/s[0-9]\.domain\.tld\/
>>>
>>> the file allowurls-regex-acl.squid
>>> contains e.g.
>>> ^http:\/\/s[1-2]+\.domain\.tld\/[a-z0-9\_\-\.]+\.gif
>>>
>>> the purpose should be, that only gif images of root directory of only
>>> the subdomains beginning with s1 or s2 of domain.tld should be allowed
> Also, NO that is not what your rules do. Take another look at all the
> sub-domains s[1-2]+ will match against...
>
> s1, s2,
> s11, s12, s21, s22,
> s111, s112, s121, s122, s211, s212, s221, s222,
> s1111 ...
> ...
>
>
of, course my mistake ...
>>> the following url is blocked
>>>
>>> http://s2443.domain.tld/ghfhfhf.gif
>>>
>>> why?
>> "4" != "\."
>>
thats right ...

should the following be allowed or blocked?
http://s1.domain.tld/file.gif
http://s2.domain.tld/file.gif

I'd say the must be allowed ...

Greetings,
Walter

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 5971 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/39ab245c/attachment.bin>

From yvoinov at gmail.com  Fri Feb  6 20:54:40 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 07 Feb 2015 02:54:40 +0600
Subject: [squid-users] Correct order of acl rules?
In-Reply-To: <54D51EE1.4000101@mathemainzel.info>
References: <54D513A8.2010606@mathemainzel.info>
 <54D515BA.30608@treenet.co.nz> <54D51827.3030405@treenet.co.nz>
 <54D51EE1.4000101@mathemainzel.info>
Message-ID: <54D52A10.2020903@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
https://regex101.com/

is great resource......

Hm?

07.02.2015 2:06, Walter H. ?????:
> On 06.02.2015 20:38, Amos Jeffries wrote:
>> On 7/02/2015 8:27 a.m., Amos Jeffries wrote:
>>> On 7/02/2015 8:19 a.m., Walter H. wrote:
>>>> the file blockurls-regex-acl.squid
>>>> contains e.g.
>>>> ^http:\/\/s[0-9]\.domain\.tld\/
>>>>
>>>> the file allowurls-regex-acl.squid
>>>> contains e.g.
>>>> ^http:\/\/s[1-2]+\.domain\.tld\/[a-z0-9\_\-\.]+\.gif
>>>>
>>>> the purpose should be, that only gif images of root directory of only
>>>> the subdomains beginning with s1 or s2 of domain.tld should be allowed
>> Also, NO that is not what your rules do. Take another look at all the
>> sub-domains s[1-2]+ will match against...
>>
>> s1, s2,
>> s11, s12, s21, s22,
>> s111, s112, s121, s122, s211, s212, s221, s222,
>> s1111 ...
>> ...
>>
>>
> of, course my mistake ...
>>>> the following url is blocked
>>>>
>>>> http://s2443.domain.tld/ghfhfhf.gif
>>>>
>>>> why?
>>> "4" != "\."
>>>
> thats right ...
>
> should the following be allowed or blocked?
> http://s1.domain.tld/file.gif
> http://s2.domain.tld/file.gif
>
> I'd say the must be allowed ...
>
> Greetings,
> Walter
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU1SoQAAoJENNXIZxhPexGlCwIALzTWCzuQjVd9zBVX8NdvEav
dlH0sAAJ8mzTOinFLFfW6djpZKMaXx68NQmNBnSBpg21+N/+Ado6lktzASu2Ktie
qg+GEZ+tZ8G9bn4vgowb+htoF7btRkH/ahzPq82x56qwomwc5uwMOQUCL07aI+mj
Uqd+ot+/BIvfKQkgjmR0rFenpexHASTMJdsbDpAd+jkIAUqhOESORgbm/if9s/7u
oreRwTHw+IUjcsbWJfxMP3zP/fUs/WBa3utX7zn2ngXv+hEmEMM9krUxHCF/nfOP
+XAYpQNVsmG9v4zgi3iHNtFQt19DkgYvr6uQMq8qCzDPIjirvORw+IiOMHXE9Ls=
=rBi7
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150207/c1567470/attachment.htm>

From luismiguelferreirasilva at gmail.com  Fri Feb  6 21:54:54 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Fri, 6 Feb 2015 14:54:54 -0700
Subject: [squid-users] Blocking Chrome and QUIC
Message-ID: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>

Dear all,

This isn't entirely a squid question but more like a "transparent proxying"
question (which I'm hoping you guys will be able to help me with)...

As I started playing around with transparent ssl proxying, I learned that
Chrome uses an alternate communication (UDP based) protocol called QUIC.

When the browser uses that protocol, Squid obviously isn't used as a proxy,
so I'm trying to block QUIC traffic to force the browsers to fall back to
HTTP/HTTPS.

At first, I found out that QUIC communicates over UDP 443 but, since
blocking traffic from going out on that port didn't seem to work, I decided
to use TCPView
<https://technet.microsoft.com/en-us/sysinternals/bb897437.aspx> (on the
client computer) and look at tcpdump to try and figure out what other ports
does it use...

After looking at TCPView, I was able to see traffic going out on:
tcp 80
tcp 443
tcp 5228
udp 80
udp 443
udp 5353

...so I tried to block traffic going out on those ports:
root at appliance:~# cat /etc/iptables/rules.v4 | grep -i forward
:FORWARD DROP [41:4010]
-A FORWARD -i br0 -p tcp -m tcp --dport 5228 -j REJECT --reject-with
icmp-port-unreachable
-A FORWARD -i br0 -p udp -m udp --dport 5353 -j REJECT --reject-with
icmp-port-unreachable
-A FORWARD -i br0 -p udp -m udp --dport 80 -j REJECT --reject-with
icmp-port-unreachable
-A FORWARD -i br0 -p udp -m udp --dport 443 -j REJECT --reject-with
icmp-port-unreachable
root at appliance:~# iptables -L
Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination
REJECT     tcp  --  anywhere             anywhere             tcp dpt:5228
reject-with icmp-port-unreachable
REJECT     udp  --  anywhere             anywhere             udp dpt:mdns
reject-with icmp-port-unreachable
REJECT     udp  --  anywhere             anywhere             udp dpt:http
reject-with icmp-port-unreachable
REJECT     udp  --  anywhere             anywhere             udp dpt:https
reject-with icmp-port-unreachable

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
root at appliance:~# iptables -L -n -v
Chain INPUT (policy ACCEPT 6182 packets, 2536K bytes)
 pkts bytes target     prot opt in     out     source
destination

Chain FORWARD (policy ACCEPT 1343 packets, 160K bytes)
 pkts bytes target     prot opt in     out     source
destination
   18   912 REJECT     tcp  --  br0    *       0.0.0.0/0
0.0.0.0/0            tcp dpt:5228 reject-with icmp-port-unreachable
  100 30714 REJECT     udp  --  br0    *       0.0.0.0/0
0.0.0.0/0            udp dpt:5353 reject-with icmp-port-unreachable
    0     0 REJECT     udp  --  br0    *       0.0.0.0/0
0.0.0.0/0            udp dpt:80 reject-with icmp-port-unreachable
   73 87052 REJECT     udp  --  br0    *       0.0.0.0/0
0.0.0.0/0            udp dpt:443 reject-with icmp-port-unreachable

Chain OUTPUT (policy ACCEPT 6913 packets, 2386K bytes)
 pkts bytes target     prot opt in     out     source
destination
root at appliance:~#

The problem is that, although the rules seem to successfully be triggered,
the only way I can successfully BLOCK QUIC traffic and make the browser
fallback to HTTP/HTTPS is by setting a default FORWARD policy to DROP:
*iptables -P FORWARD DROP*

What I conclude from this is that there MUST be some more FORWARD traffic
being originated at Chrome that I have no idea how to catch and filter.

So my question is: *how can I completely block QUIC so I can guarantee my
traffic will always be redirected to Squid?*

Thanks in advance,
Luis
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/3c6d436a/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri Feb  6 22:58:58 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 6 Feb 2015 23:58:58 +0100
Subject: [squid-users] Blocking Chrome and QUIC
In-Reply-To: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>
References: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>
Message-ID: <201502062358.58831.Antony.Stone@squid.open.source.it>

On Friday 06 February 2015 at 22:54:54 (EU time), Luis Miguel Silva wrote:

> As I started playing around with transparent ssl proxying, I learned that
> Chrome uses an alternate communication (UDP based) protocol called QUIC.

I'd never heard of QUIC, and http://en.wikipedia.org/wiki/QUIC doesn't seem to 
give much technical information on how it works, however it certainly confirms 
that it's based on UDP.

> The problem is that, although the rules seem to successfully be triggered,
> the only way I can successfully BLOCK QUIC traffic and make the browser
> fallback to HTTP/HTTPS is by setting a default FORWARD policy to DROP:
> *iptables -P FORWARD DROP*

Er, why is that not your standard setup?

Allow what you know you want, drop the rest - that's standard security 
practice.

If you do set the default forward policy to drop, what problems does this 
create?

> So my question is: *how can I completely block QUIC so I can guarantee my
> traffic will always be redirected to Squid?*

1. See above :)

2. What UDP traffic do you want to permit, except port 53 to your (quite 
possibly local) DNS servers?

Maybe you're using VoIP, with its associated RTSP traffic, but that's generally 
in the port range 20000-30000 or even higher, and will also be coming from 
quite specific devices (telephones), and usually also to quite specific 
destinations (SIP proxies).

Therefore just block all UDP traffic which isn't known to be required.


Incidentally, as a general comment I would repeat the last sentence above 
without the qualifier "UDP" :)


Regards,


Antony.

-- 
Anyone that's normal doesn't really achieve much.

 - Mark Blair, Australian rocket engineer

                                                   Please reply to the list;
                                                         please *don't* CC me.


From gortega at anses.gov.ar  Fri Feb  6 23:38:05 2015
From: gortega at anses.gov.ar (Ortega Gustavo Martin)
Date: Fri, 6 Feb 2015 23:38:05 +0000
Subject: [squid-users] The SSL certificate database is corrupted.
	Please	rebuild
In-Reply-To: <20A2F27D26BDBF41B491D00A11D4A7A6012777E747@ANSESXGMBX04.anses.gov.ar>
References: <mailman.38090.1422648817.1833.squid-users@lists.squid-cache.org>
 <CAMZauGrzEQ3uUC5B3U5+QtshgTDCXfSmiR5NT76mcW+SCyivVQ@mail.gmail.com>
 <54CC04F3.9060900@treenet.co.nz>
 <20A2F27D26BDBF41B491D00A11D4A7A6012777D2D7@ANSESXGMBX04.anses.gov.ar>
 <54D253AF.4000901@treenet.co.nz>
 <20A2F27D26BDBF41B491D00A11D4A7A6012777E747@ANSESXGMBX04.anses.gov.ar>
Message-ID: <20A2F27D26BDBF41B491D00A11D4A7A60138A4536B@ANSESXGMBX04.anses.gov.ar>

Any comments?

Thanks

-----Mensaje original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] En nombre de Ortega Gustavo Martin
Enviado el: mi?rcoles, 04 de febrero de 2015 03:05 p.m.
Para: squid-users at lists.squid-cache.org
Asunto: [squid-users] The SSL certificate database is corrupted. Please rebuild

Amos, thanks for your quick reply!

I ?ve got news:

i recompiled squid with your suggestions, remove the corrupted database but the same thing happens.

my squid -v now is:

Squid Cache: Version 3.4.11-20150124-r13214 configure options:  '--prefix=/export/squid-3.4.11-20150124-r13214' '--with-maxfd=400000' '--enable-delay-pools' '--with-large-files' '--enable-follow-x-forwarded-for' '--enable-default-err-language=es' '--enable-err-languages=es' '--enable-external-acl-helpers=wbinfo_group' '--enable-async-io' '--enable-ssl' '--enable-ssl-crtd' '--enable-icap-client' '--enable-ltdl-convenience' '--with-openssl=/export/SOURCES/openssl-1.0.2'

The complete line of cache.log is:

2015/02/04 15:00:57 kid1| helperOpenServers: Starting 1/200 'ssl_crtd' processes wrong number of fields on line 8 (looking for field 6, got 1, '' left)
(ssl_crtd): The SSL certificate database (....) is corrupted. Please rebuild

Thanks, Gustavo.

-----Mensaje original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] En nombre de Amos Jeffries Enviado el: mi?rcoles, 04 de febrero de 2015 02:15 p.m.
Para: squid-users at lists.squid-cache.org
Asunto: Re: [squid-users] The SSL certificate database is corrupted. Please rebuild

On 5/02/2015 4:33 a.m., Ortega Gustavo Martin wrote:
> Hello, i found multiple times this error in cache.log and then squid 
> crashed and enter in a loop.
> 
> I found one corrupted line in "index.txt" in the database directory. 
> Last two lines are:
> 
> V       150828132043Z
> 1BDA35020BA8933E63507E7D5A59386C8329A3D3        unknown
> /CN=zqnvza.bay.livefilestore.com+Sign=signTrusted ed
> 
> 
> I thought that "ed" is the corrupted line.
> 
> 
> This is my output of "squid -v" Squid Cache: Version
> 3.4.11-20150124-r13214 configure options:
> '--prefix=/export/squid-3.4.11-20150124-r13214' '--with-maxfd=400000'
> '--enable-delay-pools' '--enable-referer-log'
> '--enable-useragent-log'

Referer and Useragent logs are now built-in logformat definitions.
Remove these ./configure options.

> '--enable-auth'

Auth is enabled by default, the ./configure option is defined for use to DISABLE authentication in Squid.

> '--with-large-files'
> '--enable-follow-x-forwarded-for'
> '--enable-default-err-language=Spanish'
> '--enable-err-languages=Spanish'

"Spanish" is not an ISO 3166 language code.

Use:  --enable-default-err-language=es


> '--enable-external-acl-helpers=wbinfo_group' '--enable-async-io'
> '--enable-ssl' '--enable-ssl-crtd' '--enable-icap-client'
> '--enable-ltdl-convenience'
> '--with-openssl=/export/SOURCES/openssl-1.0.1c' '--disable-ipv6'
> 

Please begin your migration to IPv6. BCP 177 (RFC 6540) make it clear that IPv6 support is currenty mandatory for all machinery and software using IP protocol. Current versions of Squid have no problems with IPv6 (remaining problem are all in the network and workarounds are configurable).

Cheers
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From luismiguelferreirasilva at gmail.com  Sat Feb  7 04:41:13 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Fri, 6 Feb 2015 21:41:13 -0700
Subject: [squid-users] Blocking Chrome and QUIC
In-Reply-To: <201502062358.58831.Antony.Stone@squid.open.source.it>
References: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>
 <201502062358.58831.Antony.Stone@squid.open.source.it>
Message-ID: <CA+suCFivtz-rpcdARBjd6rMCT_tS78E1hwPJt3a92EcN=4fRXQ@mail.gmail.com>

Antony,

*Comments inline!*

Thanks,
Luis

On Fri, Feb 6, 2015 at 3:58 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Friday 06 February 2015 at 22:54:54 (EU time), Luis Miguel Silva wrote:
>
> > As I started playing around with transparent ssl proxying, I learned that
> > Chrome uses an alternate communication (UDP based) protocol called QUIC.
>
> I'd never heard of QUIC, and http://en.wikipedia.org/wiki/QUIC doesn't
> seem to
> give much technical information on how it works, however it certainly
> confirms
> that it's based on UDP.
>
> > The problem is that, although the rules seem to successfully be
> triggered,
> > the only way I can successfully BLOCK QUIC traffic and make the browser
> > fallback to HTTP/HTTPS is by setting a default FORWARD policy to DROP:
> > *iptables -P FORWARD DROP*
>
> Er, why is that not your standard setup?
>
> Allow what you know you want, drop the rest - that's standard security
> practice.
>
> If you do set the default forward policy to drop, what problems does this
> create?
>
*This is supposed to be a generic solution, whose main intent is to filter
http/https content (not to block "all other traffic").*
*If I block all traffic by default, things will stop working, so all I want
to block is whatever NEEDS to be blocked :o)*


>
> > So my question is: *how can I completely block QUIC so I can guarantee my
> > traffic will always be redirected to Squid?*
>
> 1. See above :)
>
*Unfortunately, not an acceptable solution :o(*

>
> 2. What UDP traffic do you want to permit, except port 53 to your (quite
> possibly local) DNS servers?
>
*Games, voip, etc...*

>
> Maybe you're using VoIP, with its associated RTSP traffic, but that's
> generally
> in the port range 20000-30000 or even higher, and will also be coming from
> quite specific devices (telephones), and usually also to quite specific
> destinations (SIP proxies).
>
> Therefore just block all UDP traffic which isn't known to be required.
>
*I would really rather not. I just want to figure out what ports does QUIC
use :o)*
*Unfortunately, the more I talk with people, the more I'm finding out that
most people don't have any idea what QUIC is (I now I didn't about 3 days
ago heheh).*

*I might just head on to the Chromium google group and ask there! (I just
posted here cause I was sure someone else had experienced the same problem
I am experiencing while doing transparent proxying).*

*Thanks,*
*Luis*

>
>
> Incidentally, as a general comment I would repeat the last sentence above
> without the qualifier "UDP" :)
>
>
> Regards,
>
>
> Antony.
>
> --
> Anyone that's normal doesn't really achieve much.
>
>  - Mark Blair, Australian rocket engineer
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150206/60de6241/attachment.htm>

From ignazio.raia at eutelia.com  Sat Feb  7 06:32:28 2015
From: ignazio.raia at eutelia.com (Ignazio Raia)
Date: Fri, 6 Feb 2015 22:32:28 -0800 (PST)
Subject: [squid-users] login expired
In-Reply-To: <54D481BB.3010308@treenet.co.nz>
References: <1423176194436-4669574.post@n4.nabble.com>
 <54D481BB.3010308@treenet.co.nz>
Message-ID: <1423290748208-4669607.post@n4.nabble.com>

Good morning Amos,
here is my squid.conf, basic_db_auth script and the shell test. 
thanks a lot for your interesting and help.

TEST MADE FROM VIA ssh CONNECTION TO MY LAMP & SQUID SERVER (ssh
ignazio at 192.168.2.1)
$ sudo /usr/lib/squid3/basic_db_auth --user root --password rootpasswd --md5
--cond "1" --persis

ignazio 12345678	(wrong password)
ERR login failure

ignazio mypassword	(right password)
OK

# MY SQUID.CONF
# OPTIONS FOR AUTHENTICATION
auth_param basic program /usr/lib/squid3/basic_db_auth --user root
--password rootpasswd -md5 --cond "1" --persis 
#auth_param basic program /usr/lib/squid3/basic_ncsa_auth
/etc/squid3/squid.pass

auth_param basic children 5
auth_param basic realm Squid Proxy Web Server
auth_param basic credentialsttl 60 seconds
#authenticate_cache_garbage_interval 1 hour
#authenticate_ttl 60 seconds

# MY ACCESS CONTROLS
#
-----------------------------------------------------------------------------
acl localnet src 192.168.2.0/24 #my localnet
acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher 
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT
acl password proxy_auth REQUIRED

#  TAG: MY http_access
http_access deny !password
http_access deny !Safe_ports
http_access allow localhost manager
http_access deny CONNECT !SSL_ports
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny all

# NETWORK OPTIONS
http_port 8888
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
# example lin deb packages
#refresh_pattern (\.deb|\.udeb)$   129600 100% 129600
refresh_pattern .		0	20%	4320

# HTTPD-ACCELERATOR OPTIONS
#
-----------------------------------------------------------------------------
visible_hostname ubuntu-server

# DNS OPTIONS
#
-----------------------------------------------------------------------------
dns_nameservers 62.94.0.41


#basic_db_auth script
#!/usr/bin/perl
use strict;
use DBI;
use Getopt::Long;
use Pod::Usage;
use Digest::MD5 qw(md5 md5_hex md5_base64);
$|=1;

=pod

=head1 NAME

basic_db_auth - Database auth helper for Squid

=cut

my $dsn = "DBI:mysql:database=squid";
my $db_user = "root";
my $db_passwd = "rootpasswd";
my $db_table = "passwd";
my $db_usercol = "user";
my $db_passwdcol = "password";
my $db_cond = "enabled = 1";
my $plaintext = 0;
my $md5 = 0;
my $persist = 0;
my $isjoomla = 0;
my $debug = 0;
my $hashsalt = undef;
etc etc



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/login-expired-tp4669574p4669607.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From priyaiitmandi at gmail.com  Sat Feb  7 06:51:58 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Sat, 7 Feb 2015 12:21:58 +0530
Subject: [squid-users] Squid Source Code: What files/functions
 receive/send packets from/to hardware
In-Reply-To: <CALTPfpGFP16S7qM+zQMWk-Oi2NcU3XC1JDZ3T+Tyit1mmMYm7g@mail.gmail.com>
References: <CALTPfpHJ_CX8T7YiwU0knvAyQD72VA5HZqYsdPvBqi4ABtkMPQ@mail.gmail.com>
 <54AABA53.1080408@treenet.co.nz>
 <CALTPfpEWb4CKDyAS7Y5xdL1RKtxi3ANd=kpALFRiFyXtgSLW9w@mail.gmail.com>
 <54AADB39.1010200@treenet.co.nz>
 <CALTPfpGWfoh1q0pnnDMLF6Zm7vaKBO1N_rNq7YM2kYQyJV-jew@mail.gmail.com>
 <CALTPfpGFP16S7qM+zQMWk-Oi2NcU3XC1JDZ3T+Tyit1mmMYm7g@mail.gmail.com>
Message-ID: <CALTPfpG++txDayLOE0xGtyS4akHFQ-Heq+u6XxFfdO-OP52FbQ@mail.gmail.com>

Actually I am unable to mail to squid-dev. Thus asking here.
How/where does squid open the network interface and starts listening on
them.

Regards
On Fri, Feb 6, 2015 at 12:57 PM, Priya Agarwal <priyaiitmandi at gmail.com>
wrote:

> Hi,
> I needed some direction again. I also need to know where in the source
> code does squid open the network interface before it reads/writes from it.
> Thanks.
>
> Regards
>
> On Tue, Jan 6, 2015 at 11:37 AM, Priya Agarwal <priyaiitmandi at gmail.com>
> wrote:
>
>> Thanks a lot. :)
>> I'll sign up for squid-dev mailing list and do any further discussions
>> there.
>>
>>
>> On Tue, Jan 6, 2015 at 12:13 AM, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>> On 6/01/2015 6:01 a.m., Priya Agarwal wrote:
>>> > Thank you for the reply.
>>> >
>>> > I do not intend to change its functionality. I just want to make it
>>> > run on a processor (Freescale's T4240). For that it has to use some
>>> > new architectural features (Data Path Acceleration Architecture)
>>> > which are a part of the processor.
>>> >
>>> > For e.g. suppose squid was merely swapping ipv4/mac src and dest
>>> > addresses( just an example! ) in the packet header and sends it
>>> > back. So I don't want to change what it does, I just want squid to
>>> > send whatever data it has prepared to a memory location. Basically
>>> > instead of receiving and sending to OS Stack, I want to it read and
>>> > write from memory.  (Further details : This memory is basically a
>>> > memory-mapped device which is further responsible for transmitting
>>> > the frame to a network interface, ethernet)
>>> >
>>> > So maybe if I could know where in the source code does it
>>> > communicate with the OS stack.
>>>
>>> Ah, that kind of packet handling is all much, much lower level than
>>> Squid.
>>>
>>> Squid uses functions provided by the POSIX system API with socket
>>> handles/"filedescriptors".
>>>
>>> http://man7.org/linux/man-pages/man7/socket.7.html
>>> http://man7.org/linux/man-pages/man2/read.2.html
>>> http://man7.org/linux/man-pages/man2/write.2.html
>>>
>>> The functions in src/fd.cc are where that happens, the lowest
>>> networking-I/O level of Squid.
>>>
>>>
>>> NP: If you want to take this further and/or discuss any other feature
>>> additions/changes I encourage you to sign up to squid-dev mailing list
>>> and discuss it with the whole dev team. This list is for general user
>>> discussions, (though sometimes code talk from someone doing bug
>>> investigations does slip in).
>>>
>>> Amos
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v2.0.22 (MingW32)
>>>
>>> iQEcBAEBAgAGBQJUqts4AAoJELJo5wb/XPRjJu4IANCAhXt7PM48xHkERw/mz/sa
>>> heSoEC7nJXaLpRz9JSq085UY2F0p55/GH0Gdh+XLq0h6kMLZB8qYTify0WMp18Jj
>>> sfVOhuURZVdabS5ldW2ZrqftsqCt5eu3JvgHtQ+ewp8RhN5OI6OTQbCL9sf6llWY
>>> Vqm1gno2IymyjcsuPYzpDv7sw7M3odJSETAD2eh6E3r+++uN1q5R4JZ7GZt5mgaE
>>> tIJF0DyOlhAfAJIniCImZ0MDqWHLWjrzLWZRazHg4zA025TinDxkjy+qfHnjYfDc
>>> oIFh9t/mtSbHPnBiZmsyUDOfl/wB0EOMuXEItoLGgBLh/71huVf2QRmfXUr6qS8=
>>> =oajV
>>> -----END PGP SIGNATURE-----
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150207/dd2f582b/attachment.htm>

From squid3 at treenet.co.nz  Sat Feb  7 08:14:21 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 07 Feb 2015 21:14:21 +1300
Subject: [squid-users] login expired
In-Reply-To: <1423290748208-4669607.post@n4.nabble.com>
References: <1423176194436-4669574.post@n4.nabble.com>
 <54D481BB.3010308@treenet.co.nz> <1423290748208-4669607.post@n4.nabble.com>
Message-ID: <54D5C95D.3050101@treenet.co.nz>

On 7/02/2015 7:32 p.m., Ignazio Raia wrote:
> Good morning Amos,
> here is my squid.conf, basic_db_auth script and the shell test. 
> thanks a lot for your interesting and help.
> 
> TEST MADE FROM VIA ssh CONNECTION TO MY LAMP & SQUID SERVER (ssh
> ignazio at 192.168.2.1)
> $ sudo /usr/lib/squid3/basic_db_auth --user root --password rootpasswd --md5
> --cond "1" --persis

NP: missing 't' on --persist, but that seems not to matter for your perl
version.


> 
> ignazio 12345678	(wrong password)
> ERR login failure
> 
> ignazio mypassword	(right password)
> OK
> 
> # MY SQUID.CONF
> # OPTIONS FOR AUTHENTICATION
> auth_param basic program /usr/lib/squid3/basic_db_auth --user root
> --password rootpasswd -md5 --cond "1" --persis 

Missing '-' on --md5 could be the problem.

If it remains after fixing that '-', try running your manual test again
but this time after "su squid" or "su proxy", whatever Squid is using.
The results may differ.

If that works, look around for things like SELinux or Apparmor
preventing the database connection being setup.


> #auth_param basic program /usr/lib/squid3/basic_ncsa_auth
> /etc/squid3/squid.pass
> 
> auth_param basic children 5
> auth_param basic realm Squid Proxy Web Server
> auth_param basic credentialsttl 60 seconds
> #authenticate_cache_garbage_interval 1 hour
> #authenticate_ttl 60 seconds
> 
> # MY ACCESS CONTROLS
> #
> -----------------------------------------------------------------------------
> acl localnet src 192.168.2.0/24 #my localnet
> acl SSL_ports port 443
> acl Safe_ports port 80 # http
> acl Safe_ports port 21 # ftp
> acl Safe_ports port 443 # https
> acl Safe_ports port 70 # gopher 
> acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280 # http-mgmt
> acl Safe_ports port 488 # gss-http
> acl Safe_ports port 591 # filemaker
> acl Safe_ports port 777 # multiling http
> acl CONNECT method CONNECT
> acl password proxy_auth REQUIRED
> 
> #  TAG: MY http_access
> http_access deny !password
> http_access deny !Safe_ports

I would swap the order of those two. So if someone nasty starts
hammering way at port 25 for example, the auth helper wont get the load.

Maybe even moving the CONNECT !SSL_Ports above the auth check too, but
that depends on whether you really want your localhost manager to have
unrestricted CONNECT tunnel abilities.

> http_access allow localhost manager
> http_access deny CONNECT !SSL_ports
> http_access deny manager
> http_access allow localnet
> http_access allow localhost
> http_access deny all
> 

Amos



From squid3 at treenet.co.nz  Sat Feb  7 08:17:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 07 Feb 2015 21:17:10 +1300
Subject: [squid-users] Blocking Chrome and QUIC
In-Reply-To: <CA+suCFivtz-rpcdARBjd6rMCT_tS78E1hwPJt3a92EcN=4fRXQ@mail.gmail.com>
References: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>
 <201502062358.58831.Antony.Stone@squid.open.source.it>
 <CA+suCFivtz-rpcdARBjd6rMCT_tS78E1hwPJt3a92EcN=4fRXQ@mail.gmail.com>
Message-ID: <54D5CA06.9070206@treenet.co.nz>

On 7/02/2015 5:41 p.m., Luis Miguel Silva wrote:
> Antony,
> 
> *Comments inline!*
> 

Did you see the reply I sent a few days ago?

... in your previous thread entitled "SSL-bump certificate issues
(mostly on Chrome, when accessing Google websites) "

Amos


From squid3 at treenet.co.nz  Sat Feb  7 08:45:37 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 07 Feb 2015 21:45:37 +1300
Subject: [squid-users] Squid Source Code: What files/functions
 receive/send packets from/to hardware
In-Reply-To: <CALTPfpG++txDayLOE0xGtyS4akHFQ-Heq+u6XxFfdO-OP52FbQ@mail.gmail.com>
References: <CALTPfpHJ_CX8T7YiwU0knvAyQD72VA5HZqYsdPvBqi4ABtkMPQ@mail.gmail.com>	<54AABA53.1080408@treenet.co.nz>	<CALTPfpEWb4CKDyAS7Y5xdL1RKtxi3ANd=kpALFRiFyXtgSLW9w@mail.gmail.com>	<54AADB39.1010200@treenet.co.nz>	<CALTPfpGWfoh1q0pnnDMLF6Zm7vaKBO1N_rNq7YM2kYQyJV-jew@mail.gmail.com>	<CALTPfpGFP16S7qM+zQMWk-Oi2NcU3XC1JDZ3T+Tyit1mmMYm7g@mail.gmail.com>
 <CALTPfpG++txDayLOE0xGtyS4akHFQ-Heq+u6XxFfdO-OP52FbQ@mail.gmail.com>
Message-ID: <54D5D0B1.8080609@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 7/02/2015 7:51 p.m., Priya Agarwal wrote:
> Actually I am unable to mail to squid-dev. Thus asking here. 
> How/where does squid open the network interface and starts
> listening on them.
> 

I already went over how Squid only goes down to the TCP socket
interfaces layer. Nowhere near the "network interfaces".

Assuming you mean sockets, the answer is the same as before. In
src/fd.cc where the other OSI layer 4 API operations are.

... unless you mean something higher level such as specific types of
sockets. In which case there are comm (OSI layer 5) APIs in src/comm/*
(C++), src/comm.h and src/comm.cc (the old C ones we have not updated
fully yet)

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU1dCwAAoJELJo5wb/XPRj/NgH/1sRmo2saNz+IkL8Dzmeq2/o
RgIteRCgMaFeeEVVVPfAopUgHKGOcoFed/UoV2MXyHpi6byq8Hb5YOrQ0nxAKKfF
L9uJsOuqQqCqxDTQkYYWZFpaEGoK0N8xb4XhOZntCUIdIg2GssFPBwCXZU17v5In
hxxd5gUKUOlwzyJtkGM0wKG6XpPU7CRtOGLPQAtBRG7Ywmbm3aufKFOFfZb105Gp
QlvuQgGwsf0TpACy1SFP3Amwb1yZVYGZ22AAYnP3xWYIXMzLnZNPiZ8s/ftLG2Nz
O+SsKHdOCOYsvygWOoU+mfyT2paHlV+K++IZvYCqwGJzd/TNhQIR5pwc9+zYL34=
=FDHi
-----END PGP SIGNATURE-----


From luismiguelferreirasilva at gmail.com  Sat Feb  7 16:34:16 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Sat, 7 Feb 2015 09:34:16 -0700
Subject: [squid-users] Blocking Chrome and QUIC
In-Reply-To: <54D5CA06.9070206@treenet.co.nz>
References: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>
 <201502062358.58831.Antony.Stone@squid.open.source.it>
 <CA+suCFivtz-rpcdARBjd6rMCT_tS78E1hwPJt3a92EcN=4fRXQ@mail.gmail.com>
 <54D5CA06.9070206@treenet.co.nz>
Message-ID: <CA+suCFifwmP+t+WpJjrReXP9USY_m25DRyVB9OAEDy+-KYDHkA@mail.gmail.com>

I did when you sent it but it seemed to me you were saying I should add
that "reply_header_access Alternate-Protocol deny all" config parameter
but, on the other hand, I didn't understand why were you suggesting that,
seeing that my problem is that Chrome doesn't go through my proxy at all!
(I'm doing transparent proxying, NOT setting up a proxy in Chrome).

I've now re-read your email and it seemed you were telling me to upgrade to
3.5.x (which I hadn't understood the last time I read your email). I
apologize that I didn't understand what you were saying.

So are you saying I must upgrade to Squid 3.5.x to fix this? Why would that
header fix it, seeing that my problem is that Chrome is bypassing the proxy
altogether?

Thank you,
Luis

On Sat, Feb 7, 2015 at 1:17 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 7/02/2015 5:41 p.m., Luis Miguel Silva wrote:
> > Antony,
> >
> > *Comments inline!*
> >
>
> Did you see the reply I sent a few days ago?
>
> ... in your previous thread entitled "SSL-bump certificate issues
> (mostly on Chrome, when accessing Google websites) "
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150207/3efec877/attachment.htm>

From eliezer at ngtech.co.il  Sat Feb  7 16:41:39 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 07 Feb 2015 18:41:39 +0200
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbddn5rt=2Cv686Xidxw-DVKRaj0bwoi7LmV9E+QFmAf62Q@mail.gmail.com>
References: <CALkTbddushPE_YcfBTMrEjK+xPpREdVPpWg7gJCOkexH5xLJDw@mail.gmail.com>
 <1100873577.337078600.1423221232079.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <CALkTbddn5rt=2Cv686Xidxw-DVKRaj0bwoi7LmV9E+QFmAf62Q@mail.gmail.com>
Message-ID: <54D64043.6060207@ngtech.co.il>

Hey Stefano,

Can you get some access.log output from the time the issue appears\happens?

Eliezer

On 06/02/2015 15:01, Stefano Ansaloni wrote:
> Tested with icap disabled: the issue still there.




From hectorchan at gmail.com  Sat Feb  7 20:28:37 2015
From: hectorchan at gmail.com (Hector Chan)
Date: Sat, 7 Feb 2015 12:28:37 -0800
Subject: [squid-users] Default CA file
Message-ID: <CAEhCwUwiaRMzACVmu=wSL=_TK626WsgLjkviJkVFfHh58j0F-A@mail.gmail.com>

Hi all,

I have a question about the CA file for SSL certificates.  If I don't
specify anything for CA, what is default CA certs that squid will use for
the cache_peer ?

Here is a snippet of my config file.

https_port 127.0.0.1:4443 accel \
    cert=/etc/certs/certificate \
    key=/etc/certs/key \
    options=NO_SSLv2,NO_SSLv3
...
cache_peer xyz.example.com parent 443 0 \
    no-query originserver \
    ssl forceddomain= xyz.example.com \
    login=PASS \
    sslcert=/etc/certs/certificate \
    sslkey=/etc/certs/key \
    ssloptions=NO_SSLv2,NO_SSLv3
...

I am running squid-3.4.4 on CentOS 6.

Thanks,
Hector
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150207/2cf18b0d/attachment.htm>

From yvoinov at gmail.com  Sat Feb  7 20:31:41 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 08 Feb 2015 02:31:41 +0600
Subject: [squid-users] Default CA file
In-Reply-To: <CAEhCwUwiaRMzACVmu=wSL=_TK626WsgLjkviJkVFfHh58j0F-A@mail.gmail.com>
References: <CAEhCwUwiaRMzACVmu=wSL=_TK626WsgLjkviJkVFfHh58j0F-A@mail.gmail.com>
Message-ID: <54D6762D.9070503@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
 
You need openssl CA's bundle.

Which can be specify with capath= parameter.

08.02.2015 2:28, Hector Chan ?????:
> Hi all,
>
> I have a question about the CA file for SSL certificates.  If I don't
specify anything for CA, what is default CA certs that squid will use
for the cache_peer ?
>
> Here is a snippet of my config file.
>
> https_port 127.0.0.1:4443 <http://127.0.0.1:4443> accel \
>     cert=/etc/certs/certificate \
>     key=/etc/certs/key \
>     options=NO_SSLv2,NO_SSLv3
> ...
> cache_peer xyz.example.com <http://xyz.example.com> parent 443 0 \
>     no-query originserver \
>     ssl forceddomain= xyz.example.com <http://xyz.example.com> \
>     login=PASS \
>     sslcert=/etc/certs/certificate \
>     sslkey=/etc/certs/key \
>     ssloptions=NO_SSLv2,NO_SSLv3
> ...
>
> I am running squid-3.4.4 on CentOS 6.
>
> Thanks,
> Hector
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBAgAGBQJU1nYtAAoJENNXIZxhPexG37YH/iN5GowI9WZOdUx7uVLTAlJn
+h7x1J/0vRLn0vb/KksGGbaJ0xdKUzFoLdvyYE8vhOpQnMX37zBKZgAmP1D/J5r+
+SOOiaxkG9pHoeqm3tvrVvCs8cQBOzHaweT1W7DORLSgigmOQWkHsq3vcYuAeQox
ext37UtLzsvuvZI/MbY9BIDya2qr51i67+w9cZkWeIVivnFDoA4zEHtFzQPzud+U
SXbkGBVYFVxbif+H8/6D6TyRBlBEo5meO7+T+0UDxd4Ny3vr/kZeVtW+iExmEulc
r/LESnctA/LAGBitDWpgcq7+xgwb1e20yvWio6UTNKORdDzYFY3cnJXDFzwuT1w=
=J6Qv
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150208/65211c92/attachment.htm>

From alfrenovsky at gmail.com  Sat Feb  7 23:32:29 2015
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Sat, 7 Feb 2015 20:32:29 -0300
Subject: [squid-users] kid registration timed out
Message-ID: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>

I'm getting some "kid registration timed out" messages sometimes

Squid 3.5.1

Specially in servers with 6 workers and 6 cache discs (Each worker has a
cache_dir in each disc for IO balancing)

If I use only 4 discs the problem disapears.

The error appears about 7 seconds after starting squid.

There's a configuration option to increase the timeout?

(Or where in the source code is if is hardcoded?)


-- 
Alfrenovsky
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150207/7d921a5f/attachment.htm>

From squid3 at treenet.co.nz  Sun Feb  8 01:11:23 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 08 Feb 2015 14:11:23 +1300
Subject: [squid-users] Blocking Chrome and QUIC
In-Reply-To: <CA+suCFifwmP+t+WpJjrReXP9USY_m25DRyVB9OAEDy+-KYDHkA@mail.gmail.com>
References: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>
 <201502062358.58831.Antony.Stone@squid.open.source.it>
 <CA+suCFivtz-rpcdARBjd6rMCT_tS78E1hwPJt3a92EcN=4fRXQ@mail.gmail.com>
 <54D5CA06.9070206@treenet.co.nz>
 <CA+suCFifwmP+t+WpJjrReXP9USY_m25DRyVB9OAEDy+-KYDHkA@mail.gmail.com>
Message-ID: <54D6B7BB.20101@treenet.co.nz>

On 8/02/2015 5:34 a.m., Luis Miguel Silva wrote:
> I did when you sent it but it seemed to me you were saying I should add
> that "reply_header_access Alternate-Protocol deny all" config parameter
> but, on the other hand, I didn't understand why were you suggesting that,
> seeing that my problem is that Chrome doesn't go through my proxy at all!
> (I'm doing transparent proxying, NOT setting up a proxy in Chrome).
> 
> I've now re-read your email and it seemed you were telling me to upgrade to
> 3.5.x (which I hadn't understood the last time I read your email). I
> apologize that I didn't understand what you were saying.
> 

No wrries. I was saying both.

> So are you saying I must upgrade to Squid 3.5.x to fix this? Why would that
> header fix it, seeing that my problem is that Chrome is bypassing the proxy
> altogether?

The web server actively tells Chrome to use QUIC on future requests.
Remove that header from traffic and Chrome stops using QUIC (maybe
requires Chrome restart).

The removal is built into 3.4.10+ by default, but the config line I
presented does the same thing in older versions back to 3.2.

Amos



From squid3 at treenet.co.nz  Sun Feb  8 01:19:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 08 Feb 2015 14:19:24 +1300
Subject: [squid-users] Default CA file
In-Reply-To: <CAEhCwUwiaRMzACVmu=wSL=_TK626WsgLjkviJkVFfHh58j0F-A@mail.gmail.com>
References: <CAEhCwUwiaRMzACVmu=wSL=_TK626WsgLjkviJkVFfHh58j0F-A@mail.gmail.com>
Message-ID: <54D6B99C.5080304@treenet.co.nz>

On 8/02/2015 9:28 a.m., Hector Chan wrote:
> Hi all,
> 
> I have a question about the CA file for SSL certificates.  If I don't
> specify anything for CA, what is default CA certs that squid will use for
> the cache_peer ?

The ones OpenSSL is configured to use.

> 
> Here is a snippet of my config file.
> 
> https_port 127.0.0.1:4443 accel \
>     cert=/etc/certs/certificate \
>     key=/etc/certs/key \
>     options=NO_SSLv2,NO_SSLv3
> ...
> cache_peer xyz.example.com parent 443 0 \
>     no-query originserver \
>     ssl forceddomain= xyz.example.com \

NP: be careful about the whitespace there after forcedomain= .
It will force the domain to be *unset* if the parameter is whitespace.

>     login=PASS \
>     sslcert=/etc/certs/certificate \
>     sslkey=/etc/certs/key \
>     ssloptions=NO_SSLv2,NO_SSLv3


In this configuration the peer certificate will be signed by some CA
(maybe you dong self-signing).
You need to add the public key for that CA to the cache_peer like so:

cache_peer ... \
  sslcafile=/path/to/xyz.example.com/publicCAkey.pem


Amos



From luismiguelferreirasilva at gmail.com  Sun Feb  8 03:28:47 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Sat, 7 Feb 2015 20:28:47 -0700
Subject: [squid-users] Blocking Chrome and QUIC
In-Reply-To: <54D6B7BB.20101@treenet.co.nz>
References: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>
 <201502062358.58831.Antony.Stone@squid.open.source.it>
 <CA+suCFivtz-rpcdARBjd6rMCT_tS78E1hwPJt3a92EcN=4fRXQ@mail.gmail.com>
 <54D5CA06.9070206@treenet.co.nz>
 <CA+suCFifwmP+t+WpJjrReXP9USY_m25DRyVB9OAEDy+-KYDHkA@mail.gmail.com>
 <54D6B7BB.20101@treenet.co.nz>
Message-ID: <CA+suCFgW+ucBE8NLmSaihZoLJ5ob_E5xGkPky2OWaJ-okf6aWA@mail.gmail.com>

Ok, I'm using 3.4.9, so I've added that config option to my setup :o)

Thanks for the tip!
Luis

On Sat, Feb 7, 2015 at 6:11 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 8/02/2015 5:34 a.m., Luis Miguel Silva wrote:
> > I did when you sent it but it seemed to me you were saying I should add
> > that "reply_header_access Alternate-Protocol deny all" config parameter
> > but, on the other hand, I didn't understand why were you suggesting that,
> > seeing that my problem is that Chrome doesn't go through my proxy at all!
> > (I'm doing transparent proxying, NOT setting up a proxy in Chrome).
> >
> > I've now re-read your email and it seemed you were telling me to upgrade
> to
> > 3.5.x (which I hadn't understood the last time I read your email). I
> > apologize that I didn't understand what you were saying.
> >
>
> No wrries. I was saying both.
>
> > So are you saying I must upgrade to Squid 3.5.x to fix this? Why would
> that
> > header fix it, seeing that my problem is that Chrome is bypassing the
> proxy
> > altogether?
>
> The web server actively tells Chrome to use QUIC on future requests.
> Remove that header from traffic and Chrome stops using QUIC (maybe
> requires Chrome restart).
>
> The removal is built into 3.4.10+ by default, but the config line I
> presented does the same thing in older versions back to 3.2.
>
> Amos
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150207/66f61b09/attachment.htm>

From hectorchan at gmail.com  Sun Feb  8 06:03:30 2015
From: hectorchan at gmail.com (Hector Chan)
Date: Sat, 7 Feb 2015 22:03:30 -0800
Subject: [squid-users] Default CA file
In-Reply-To: <54D6B99C.5080304@treenet.co.nz>
References: <CAEhCwUwiaRMzACVmu=wSL=_TK626WsgLjkviJkVFfHh58j0F-A@mail.gmail.com>
 <54D6B99C.5080304@treenet.co.nz>
Message-ID: <CAEhCwUyWog4ZwNuYN6R-F4J2eiwsicAvc7fsFBA=Q1y=9LJsSQ@mail.gmail.com>

Yuri and Amos, thanks for the replies!  There is an openssl command that
tells where OpenSSL will search for CA certs.

$ openssl version -d
OPENSSLDIR: "/etc/pki/tls"


On Sat, Feb 7, 2015 at 5:19 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 8/02/2015 9:28 a.m., Hector Chan wrote:
> > Hi all,
> >
> > I have a question about the CA file for SSL certificates.  If I don't
> > specify anything for CA, what is default CA certs that squid will use for
> > the cache_peer ?
>
> The ones OpenSSL is configured to use.
>
> >
> > Here is a snippet of my config file.
> >
> > https_port 127.0.0.1:4443 accel \
> >     cert=/etc/certs/certificate \
> >     key=/etc/certs/key \
> >     options=NO_SSLv2,NO_SSLv3
> > ...
> > cache_peer xyz.example.com parent 443 0 \
> >     no-query originserver \
> >     ssl forceddomain= xyz.example.com \
>
> NP: be careful about the whitespace there after forcedomain= .
> It will force the domain to be *unset* if the parameter is whitespace.
>
> >     login=PASS \
> >     sslcert=/etc/certs/certificate \
> >     sslkey=/etc/certs/key \
> >     ssloptions=NO_SSLv2,NO_SSLv3
>
>
> In this configuration the peer certificate will be signed by some CA
> (maybe you dong self-signing).
> You need to add the public key for that CA to the cache_peer like so:
>
> cache_peer ... \
>   sslcafile=/path/to/xyz.example.com/publicCAkey.pem
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150207/c53665f2/attachment.htm>

From luismiguelferreirasilva at gmail.com  Sun Feb  8 06:38:40 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Sat, 7 Feb 2015 23:38:40 -0700
Subject: [squid-users] Blocking Chrome and QUIC
In-Reply-To: <CA+suCFgW+ucBE8NLmSaihZoLJ5ob_E5xGkPky2OWaJ-okf6aWA@mail.gmail.com>
References: <CA+suCFgrUGjOeVmGkEGnPz819MnYogyUwPEv9OozGxa3FbS1Ng@mail.gmail.com>
 <201502062358.58831.Antony.Stone@squid.open.source.it>
 <CA+suCFivtz-rpcdARBjd6rMCT_tS78E1hwPJt3a92EcN=4fRXQ@mail.gmail.com>
 <54D5CA06.9070206@treenet.co.nz>
 <CA+suCFifwmP+t+WpJjrReXP9USY_m25DRyVB9OAEDy+-KYDHkA@mail.gmail.com>
 <54D6B7BB.20101@treenet.co.nz>
 <CA+suCFgW+ucBE8NLmSaihZoLJ5ob_E5xGkPky2OWaJ-okf6aWA@mail.gmail.com>
Message-ID: <CA+suCFjjTYh3vB3teAR0UOnWOs3Aix9f-Jw_Cwd+6h=5a5vU2w@mail.gmail.com>

FYI, I finally solved my problem!

It turns out the problem was with PRE-ESTABLISHED connections...

In other words, when I turned on my transparent rules, any Chrome tabs I
had opened BEFORE turning on my transparent proxy rules, apparently would
communicate over a previously opened socket! So the filtering rules would
only apply after the port was closed OR after I reopened the browser.

In order to solve it, I simply had to add a FORWARD drop rule for any
established connections:
iptables -A FORWARD -p tcp -m tcp --dport 80 -m state --state
RELATED,ESTABLISHED -j DROP
iptables -A FORWARD -p tcp -m tcp --dport 443 -m state --state
RELATED,ESTABLISHED -j DROP

Hope this will be helpful to someone else!
Luis



On Sat, Feb 7, 2015 at 8:28 PM, Luis Miguel Silva <
luismiguelferreirasilva at gmail.com> wrote:

> Ok, I'm using 3.4.9, so I've added that config option to my setup :o)
>
> Thanks for the tip!
> Luis
>
> On Sat, Feb 7, 2015 at 6:11 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> On 8/02/2015 5:34 a.m., Luis Miguel Silva wrote:
>> > I did when you sent it but it seemed to me you were saying I should add
>> > that "reply_header_access Alternate-Protocol deny all" config parameter
>> > but, on the other hand, I didn't understand why were you suggesting
>> that,
>> > seeing that my problem is that Chrome doesn't go through my proxy at
>> all!
>> > (I'm doing transparent proxying, NOT setting up a proxy in Chrome).
>> >
>> > I've now re-read your email and it seemed you were telling me to
>> upgrade to
>> > 3.5.x (which I hadn't understood the last time I read your email). I
>> > apologize that I didn't understand what you were saying.
>> >
>>
>> No wrries. I was saying both.
>>
>> > So are you saying I must upgrade to Squid 3.5.x to fix this? Why would
>> that
>> > header fix it, seeing that my problem is that Chrome is bypassing the
>> proxy
>> > altogether?
>>
>> The web server actively tells Chrome to use QUIC on future requests.
>> Remove that header from traffic and Chrome stops using QUIC (maybe
>> requires Chrome restart).
>>
>> The removal is built into 3.4.10+ by default, but the config line I
>> presented does the same thing in older versions back to 3.2.
>>
>> Amos
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150207/18fee20e/attachment.htm>

From squid3 at treenet.co.nz  Sun Feb  8 11:33:16 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 09 Feb 2015 00:33:16 +1300
Subject: [squid-users] kid registration timed out
In-Reply-To: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>
References: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>
Message-ID: <54D7497C.8070809@treenet.co.nz>

On 8/02/2015 12:32 p.m., Alfredo Rezinovsky wrote:
> I'm getting some "kid registration timed out" messages sometimes
> 
> Squid 3.5.1
> 
> Specially in servers with 6 workers and 6 cache discs (Each worker has a
> cache_dir in each disc for IO balancing)
> 
> If I use only 4 discs the problem disapears.
> 
> The error appears about 7 seconds after starting squid.
> 

At least 10 seconds after the worker kid was started.

> There's a configuration option to increase the timeout?

Not at this time.

> 
> (Or where in the source code is if is hardcoded?)
> 

src/ipc/UdsOp.cc - search for "TODO: make configurable". Its the timeout
value.

Amos



From alfrenovsky at gmail.com  Mon Feb  9 04:01:02 2015
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Mon, 09 Feb 2015 04:01:02 +0000
Subject: [squid-users] kid registration timed out
References: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>
 <54D7497C.8070809@treenet.co.nz>
Message-ID: <CAMXC=Ws=QjxMx6xiweq_Q3-6T_3Zhd1-hpT4ku3BKO_8evCJZw@mail.gmail.com>

Thanks. That will do it.

El dom, feb 8, 2015 08:33, Amos Jeffries <squid3 at treenet.co.nz> escribi?:

> On 8/02/2015 12:32 p.m., Alfredo Rezinovsky wrote:
> > I'm getting some "kid registration timed out" messages sometimes
> >
> > Squid 3.5.1
> >
> > Specially in servers with 6 workers and 6 cache discs (Each worker has a
> > cache_dir in each disc for IO balancing)
> >
> > If I use only 4 discs the problem disapears.
> >
> > The error appears about 7 seconds after starting squid.
> >
>
> At least 10 seconds after the worker kid was started.
>
> > There's a configuration option to increase the timeout?
>
> Not at this time.
>
> >
> > (Or where in the source code is if is hardcoded?)
> >
>
> src/ipc/UdsOp.cc - search for "TODO: make configurable". Its the timeout
> value.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150209/65384ff1/attachment.htm>

From eliezer at ngtech.co.il  Mon Feb  9 04:35:44 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 09 Feb 2015 06:35:44 +0200
Subject: [squid-users] kid registration timed out
In-Reply-To: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>
References: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>
Message-ID: <54D83920.7050706@ngtech.co.il>

On 08/02/2015 01:32, Alfredo Rezinovsky wrote:
> Specially in servers with 6 workers and 6 cache discs (Each worker has a
> cache_dir in each disc for IO balancing)

What cache_dir settings are you using there?

Eliezer



From luismiguelferreirasilva at gmail.com  Mon Feb  9 06:54:23 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Sun, 8 Feb 2015 23:54:23 -0700
Subject: [squid-users] fwdNegotiateSSL: Error negotiating SSL connection on
	FD 110
Message-ID: <CA+suCFgx0_B4sPMRKhQSmoHbi=dh2RZFV__KKyNo53L2HVDJKw@mail.gmail.com>

Hello,

Has anybody else ever seen this error in squid's cache.log?

root at appliance:~# tail /var/log/squid3/cache.log

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 117: error:0B07C065:x509 certificate
routines:X509_STORE_add_cert:cert already in hash table (1/-1/0)

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 123: error:0B07C065:x509 certificate
routines:X509_STORE_add_cert:cert already in hash table (1/-1/0)

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 121: error:0B07C065:x509 certificate
routines:X509_STORE_add_cert:cert already in hash table (1/-1/0)

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 76: error:0B07C065:x509 certificate routines:X509_STORE_add_cert:cert
already in hash table (1/-1/0)

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 115: error:0B07C065:x509 certificate
routines:X509_STORE_add_cert:cert already in hash table (1/-1/0)

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 101: error:0B07C065:x509 certificate
routines:X509_STORE_add_cert:cert already in hash table (1/-1/0)

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 111: error:0B07C065:x509 certificate
routines:X509_STORE_add_cert:cert already in hash table (1/-1/0)

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 96: error:0B07C065:x509 certificate routines:X509_STORE_add_cert:cert
already in hash table (1/-1/0)

2015/02/09 06:51:51 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 89: error:0B07C065:x509 certificate routines:X509_STORE_add_cert:cert
already in hash table (1/-1/0)

2015/02/09 06:51:52 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 96: error:0B07C065:x509 certificate routines:X509_STORE_add_cert:cert
already in hash table (1/-1/0)

root at appliance:~#

Any idea how to fix it?

Thank you,

Luis
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150208/8cd1f02e/attachment.htm>

From ansalonistefano at gmail.com  Mon Feb  9 09:36:55 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Mon, 9 Feb 2015 10:36:55 +0100
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54D64043.6060207@ngtech.co.il>
References: <CALkTbddushPE_YcfBTMrEjK+xPpREdVPpWg7gJCOkexH5xLJDw@mail.gmail.com>
 <1100873577.337078600.1423221232079.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <CALkTbddn5rt=2Cv686Xidxw-DVKRaj0bwoi7LmV9E+QFmAf62Q@mail.gmail.com>
 <54D64043.6060207@ngtech.co.il>
Message-ID: <CALkTbdeow3t72mez-3svMa8Z==WTSgc31V1WtfMOr22MYjvi4A@mail.gmail.com>

Here is the log of github loading a page without users avatars:
1423470402.645     12 192.168.X.X TAG_NONE/200 0 CONNECT
github.com:443 - HIER_NONE/- -
1423470403.347    699 192.168.X.X TCP_MISS/200 17045 GET
https://github.com/BigBrotherBot/big-brother-bot/tree/release-1.10 -
HIER_DIRECT/192.30.252.130 text/html
1423470403.352     36 192.168.X.X TAG_NONE/200 0 CONNECT
assets-cdn.github.com:443 - HIER_NONE/- -
1423470403.455      0 192.168.X.X TAG_NONE/200 0 CONNECT
assets-cdn.github.com:443 - HIER_NONE/- -
1423470403.459      0 192.168.X.X TCP_HIT/200 7224 GET
https://assets-cdn.github.com/favicon.ico - HIER_NONE/- image/x-icon
1423470403.723    292 192.168.X.X TCP_MISS/200 47802 GET
https://assets-cdn.github.com/assets/github-b3f61646dd9db8625d1604a82679b9f23c855258f086d8f853076133744421a0.css
- HIER_DIRECT/185.31.19.133 text/css
1423470403.913    190 192.168.X.X TCP_MISS/200 54696 GET
https://assets-cdn.github.com/assets/github2-feb550e442797d7340edb43bd054d2e52f753b0cf6172fb5e3e05fef9afa1b73.css
- HIER_DIRECT/185.31.19.133 text/css
1423470403.916      0 192.168.X.X TAG_NONE/200 0 CONNECT
assets-cdn.github.com:443 - HIER_NONE/- -
1423470403.934     19 192.168.X.X TCP_HIT/200 3005 GET
https://assets-cdn.github.com/assets/spinners/octocat-spinner-32-e513294efa576953719e4e2de888dd9cf929b7d62ed8d05f25e731d02452ab6c.gif
- HIER_NONE/- image/gif
1423470403.948     32 192.168.X.X TAG_NONE/200 0 CONNECT
avatars2.githubusercontent.com:443 - HIER_NONE/- -
1423470403.949     32 192.168.X.X TAG_NONE/200 0 CONNECT
camo.githubusercontent.com:443 - HIER_NONE/- -
1423470404.166      1 192.168.X.X TCP_HIT/200 25801 GET
https://camo.githubusercontent.com/93eca4f3dcbb6880104713ad68c178f429562144/687474703a2f2f7777772e62696762726f74686572626f742e6e65742f73697465732f64656661756c742f66696c65732f62332d6c6f676f2d6c696768742d746578742e706e67
- HIER_NONE/- image/png
1423470404.171      0 192.168.X.X TAG_NONE/200 0 CONNECT
camo.githubusercontent.com:443 - HIER_NONE/- -
1423470404.171      0 192.168.X.X TAG_NONE/200 0 CONNECT
camo.githubusercontent.com:443 - HIER_NONE/- -
1423470404.171      0 192.168.X.X TAG_NONE/200 0 CONNECT
camo.githubusercontent.com:443 - HIER_NONE/- -
1423470404.171      0 192.168.X.X TAG_NONE/200 0 CONNECT
camo.githubusercontent.com:443 - HIER_NONE/- -
1423470404.172      0 192.168.X.X TAG_NONE/200 0 CONNECT
camo.githubusercontent.com:443 - HIER_NONE/- -
1423470404.172      0 192.168.X.X TAG_NONE/200 0 CONNECT
assets-cdn.github.com:443 - HIER_NONE/- -
1423470404.202     36 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
GET https://camo.githubusercontent.com/e4e69472ef17c28376ab41d57498aedfe64531bd/68747470733a2f2f7472617669732d63692e6f72672f42696742726f74686572426f742f6269672d62726f746865722d626f742e7376673f6272616e63683d72656c656173652d312e3130
- HIER_DIRECT/185.31.18.133 -
1423470404.206      3 192.168.X.X TCP_HIT/200 18253 GET
https://assets-cdn.github.com/assets/octicons/octicons/octicons-192e5fbb927be7cdb8bdfa0ecb98d3574bd395e58f9d00e5dcdfce5bc9660ac0.woff
- HIER_NONE/- application/x-font-woff
1423470404.545    394 192.168.X.X TCP_MISS/200 111485 GET
https://assets-cdn.github.com/assets/frameworks-996268c2962f947579cb9ec2908bd576591bc94b6a2db184a78e78815022ba2c.js
- HIER_DIRECT/185.31.19.133 application/javascript
1423470404.716    547 192.168.X.X TCP_SWAPFAIL_MISS/200 3082 GET
https://avatars2.githubusercontent.com/u/42300? -
HIER_DIRECT/185.31.18.133 image/png
1423470404.890    345 192.168.X.X TCP_MISS/200 103109 GET
https://assets-cdn.github.com/assets/github-adfa2ee6f7ed872963ba72937fc628d615cd1cfe2268305014aaa3a80ef2b04d.js
- HIER_DIRECT/185.31.19.133 application/javascript
1423470405.123      0 192.168.X.X TAG_NONE/200 0 CONNECT
github.com:443 - HIER_NONE/- -
1423470405.298    175 192.168.X.X TCP_MISS/200 1951 GET
https://github.com/BigBrotherBot/big-brother-bot/contributors_size -
HIER_DIRECT/192.30.252.130 text/html
1423470405.404      0 192.168.X.X TCP_HIT/200 4755 GET
https://assets-cdn.github.com/flash/ZeroClipboard.v2.1.6.swf -
HIER_NONE/- application/x-shockwave-flash
1423470405.408   1205 192.168.X.X TCP_MISS/200 1504 GET
https://camo.githubusercontent.com/671757fe55a0c195ccc405d6807cec6c7d39004e/68747470733a2f2f70797069702e696e2f6567672f62332f62616467652e7376673f7374796c653d666c6174
- HIER_DIRECT/185.31.18.133 image/svg+xml
1423470405.415   1212 192.168.X.X TCP_MISS/200 1506 GET
https://camo.githubusercontent.com/51087cc89539882f6185930c4c544b5f48914b89/68747470733a2f2f70797069702e696e2f70795f76657273696f6e732f62332f62616467652e7376673f7374796c653d666c6174
- HIER_DIRECT/185.31.18.133 image/svg+xml
1423470405.421     34 192.168.X.X TAG_NONE/200 0 CONNECT
collector-cdn.github.com:443 - HIER_NONE/- -
1423470405.423   1220 192.168.X.X TCP_MISS/200 1531 GET
https://camo.githubusercontent.com/9628b1f0ec45c623ad122817971f6fb688742ba6/68747470733a2f2f70797069702e696e2f646f776e6c6f61642f62332f62616467652e7376673f7374796c653d666c6174
- HIER_DIRECT/185.31.18.133 image/svg+xml
1423470405.437   1235 192.168.X.X TCP_MISS/200 1508 GET
https://camo.githubusercontent.com/bf594cf91b686d8307f7935d6c0f7371db255c43/68747470733a2f2f70797069702e696e2f76657273696f6e2f62332f62616467652e7376673f7374796c653d666c6174
- HIER_DIRECT/185.31.18.133 image/svg+xml
1423470405.452   1249 192.168.X.X TCP_MISS/200 1508 GET
https://camo.githubusercontent.com/30f75228ae73fd020e074db958f7b7a7469a3af5/68747470733a2f2f70797069702e696e2f6c6963656e73652f62332f62616467652e7376673f7374796c653d666c6174
- HIER_DIRECT/185.31.18.133 image/svg+xml
1423470405.527    137 192.168.X.X TCP_MISS/200 1887 GET
https://github.com/BigBrotherBot/big-brother-bot/issues/counts -
HIER_DIRECT/192.30.252.130 application/json
1423470405.642    502 192.168.X.X TCP_MISS/200 1856 GET
https://github.com/BigBrotherBot/big-brother-bot/show_partial? -
HIER_DIRECT/192.30.252.130 text/html
1423470406.043    188 192.168.X.X TCP_SWAPFAIL_MISS/200 3377 GET
https://collector-cdn.github.com/assets/api.js -
HIER_DIRECT/185.31.19.133 application/javascript
1423470406.126     61 192.168.X.X TAG_NONE/200 0 CONNECT
collector.githubapp.com:443 - HIER_NONE/- -
1423470406.616    466 192.168.X.X TCP_MISS/200 663 GET
https://collector.githubapp.com/github/page_view? -
HIER_DIRECT/54.86.253.42 image/gif
1423470407.690    544 192.168.X.X TCP_MISS/400 1398 POST
https://github.com/_stats - HIER_DIRECT/192.30.252.130 text/javascript
1423470412.670    402 192.168.X.X TCP_MISS/200 21550 GET
http://forum.arcadecontrols.com/index.php? - FIRSTUP_PARENT/127.0.0.1
text/html
1423470429.282    110 192.168.X.X TAG_NONE/200 0 CONNECT
avatars0.githubusercontent.com:443 - HIER_NONE/- -
1423470429.282    110 192.168.X.X TAG_NONE/200 0 CONNECT
avatars1.githubusercontent.com:443 - HIER_NONE/- -
1423470429.291      2 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
GET https://avatars0.githubusercontent.com/u/1245124? -
HIER_DIRECT/185.31.18.133 -
1423470429.387   1624 192.168.X.X TCP_MISS/200 16633 GET
https://github.com/BigBrotherBot/big-brother-bot/commits/release-1.10
- HIER_DIRECT/192.30.252.130 text/html
1423470429.452      0 192.168.X.X TAG_NONE/200 0 CONNECT
avatars0.githubusercontent.com:443 - HIER_NONE/- -
1423470429.452      0 192.168.X.X TAG_NONE/200 0 CONNECT
avatars1.githubusercontent.com:443 - HIER_NONE/- -
1423470429.541      0 192.168.X.X TAG_NONE/200 0 CONNECT
avatars0.githubusercontent.com:443 - HIER_NONE/- -
1423470429.546      2 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
GET https://avatars0.githubusercontent.com/u/1245124? -
HIER_DIRECT/185.31.18.133 -
1423470429.669      0 192.168.X.X TAG_NONE/200 0 CONNECT
avatars0.githubusercontent.com:443 - HIER_NONE/- -
1423470429.674      2 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
GET https://avatars0.githubusercontent.com/u/1245124? -
HIER_DIRECT/185.31.18.133 -
1423470429.815      0 192.168.X.X TAG_NONE/200 0 CONNECT
avatars0.githubusercontent.com:443 - HIER_NONE/- -
1423470429.824      2 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
GET https://avatars0.githubusercontent.com/u/1245124? -
HIER_DIRECT/185.31.18.133 -
1423470430.146    858 192.168.X.X TCP_SWAPFAIL_MISS/200 6451 GET
https://avatars1.githubusercontent.com/u/42300? -
HIER_DIRECT/185.31.19.133 image/png
1423470430.330    863 192.168.X.X TCP_MISS/200 7532 GET
https://avatars0.githubusercontent.com/u/5205363? -
HIER_DIRECT/185.31.18.133 image/png
1423470430.369    892 192.168.X.X TCP_MISS/200 2458 GET
https://avatars1.githubusercontent.com/u/42300? -
HIER_DIRECT/185.31.19.133 image/png
1423470430.833    244 192.168.X.X TCP_MISS/200 663 GET
https://collector.githubapp.com/github/page_view? -
HIER_DIRECT/54.86.253.42 image/gif
1423470432.407   1039 192.168.X.X TCP_MISS/400 1399 POST
https://github.com/_stats - HIER_DIRECT/192.30.252.130 text/javascript

I tried to get the log also when the browser shows "cannot connect to
proxy", but there isn't any.
Moreover I noticed that sometimes the browser ask me to download
"index.php" (or a page component) instead displaying it (if I cancel
the download and reload the page, everything is displayed as
intended).


From fredbmail at free.fr  Mon Feb  9 10:12:16 2015
From: fredbmail at free.fr (FredB)
Date: Mon, 9 Feb 2015 11:12:16 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbdeow3t72mez-3svMa8Z==WTSgc31V1WtfMOr22MYjvi4A@mail.gmail.com>
Message-ID: <365233982.343047156.1423476736816.JavaMail.root@zimbra4-e1.priv.proxad.net>

Yes, TCP_SWAPFAIL_MISS is the point

10.253.33.61 - fred [09/Feb/2015:10:50:21 +0100] "GET http://www.google-analytics.com/analytics.js HTTP/1.0" 200 11932 TCP_SWAPFAIL_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:35.0) Gecko/20100101 Firefox/35.0"

Amos, about our conversation this is related, after TCP_SWAPFAIL_MISS and blank page sometime there is a 407, at least with DIGEST 


----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From squid3 at treenet.co.nz  Mon Feb  9 10:20:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 09 Feb 2015 23:20:54 +1300
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbdeow3t72mez-3svMa8Z==WTSgc31V1WtfMOr22MYjvi4A@mail.gmail.com>
References: <CALkTbddushPE_YcfBTMrEjK+xPpREdVPpWg7gJCOkexH5xLJDw@mail.gmail.com>
 <1100873577.337078600.1423221232079.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <CALkTbddn5rt=2Cv686Xidxw-DVKRaj0bwoi7LmV9E+QFmAf62Q@mail.gmail.com>
 <54D64043.6060207@ngtech.co.il>
 <CALkTbdeow3t72mez-3svMa8Z==WTSgc31V1WtfMOr22MYjvi4A@mail.gmail.com>
Message-ID: <54D88A06.6060101@treenet.co.nz>

On 9/02/2015 10:36 p.m., Stefano Ansaloni wrote:
> Here is the log of github loading a page without users avatars:
> 1423470402.645     12 192.168.X.X TAG_NONE/200 0 CONNECT
> github.com:443 - HIER_NONE/- -


I think the TAG_NONE are the bumped tunnels. In 3.5 the non-bumped ones
are labeled TCP_TUNNEL.


> 1423470403.347    699 192.168.X.X TCP_MISS/200 17045 GET
> https://github.com/BigBrotherBot/big-brother-bot/tree/release-1.10 -
> HIER_DIRECT/192.30.252.130 text/html
> 1423470403.352     36 192.168.X.X TAG_NONE/200 0 CONNECT
> assets-cdn.github.com:443 - HIER_NONE/- -
> 1423470403.455      0 192.168.X.X TAG_NONE/200 0 CONNECT
> assets-cdn.github.com:443 - HIER_NONE/- -
> 1423470403.459      0 192.168.X.X TCP_HIT/200 7224 GET
> https://assets-cdn.github.com/favicon.ico - HIER_NONE/- image/x-icon
> 1423470403.723    292 192.168.X.X TCP_MISS/200 47802 GET
> https://assets-cdn.github.com/assets/github-b3f61646dd9db8625d1604a82679b9f23c855258f086d8f853076133744421a0.css
> - HIER_DIRECT/185.31.19.133 text/css
> 1423470403.913    190 192.168.X.X TCP_MISS/200 54696 GET
> https://assets-cdn.github.com/assets/github2-feb550e442797d7340edb43bd054d2e52f753b0cf6172fb5e3e05fef9afa1b73.css
> - HIER_DIRECT/185.31.19.133 text/css
> 1423470403.916      0 192.168.X.X TAG_NONE/200 0 CONNECT
> assets-cdn.github.com:443 - HIER_NONE/- -
> 1423470403.934     19 192.168.X.X TCP_HIT/200 3005 GET
> https://assets-cdn.github.com/assets/spinners/octocat-spinner-32-e513294efa576953719e4e2de888dd9cf929b7d62ed8d05f25e731d02452ab6c.gif
> - HIER_NONE/- image/gif
> 1423470403.948     32 192.168.X.X TAG_NONE/200 0 CONNECT
> avatars2.githubusercontent.com:443 - HIER_NONE/- -
> 1423470403.949     32 192.168.X.X TAG_NONE/200 0 CONNECT
> camo.githubusercontent.com:443 - HIER_NONE/- -
> 1423470404.166      1 192.168.X.X TCP_HIT/200 25801 GET
> https://camo.githubusercontent.com/93eca4f3dcbb6880104713ad68c178f429562144/687474703a2f2f7777772e62696762726f74686572626f742e6e65742f73697465732f64656661756c742f66696c65732f62332d6c6f676f2d6c696768742d746578742e706e67
> - HIER_NONE/- image/png
> 1423470404.171      0 192.168.X.X TAG_NONE/200 0 CONNECT
> camo.githubusercontent.com:443 - HIER_NONE/- -
> 1423470404.171      0 192.168.X.X TAG_NONE/200 0 CONNECT
> camo.githubusercontent.com:443 - HIER_NONE/- -
> 1423470404.171      0 192.168.X.X TAG_NONE/200 0 CONNECT
> camo.githubusercontent.com:443 - HIER_NONE/- -
> 1423470404.171      0 192.168.X.X TAG_NONE/200 0 CONNECT
> camo.githubusercontent.com:443 - HIER_NONE/- -
> 1423470404.172      0 192.168.X.X TAG_NONE/200 0 CONNECT
> camo.githubusercontent.com:443 - HIER_NONE/- -
> 1423470404.172      0 192.168.X.X TAG_NONE/200 0 CONNECT
> assets-cdn.github.com:443 - HIER_NONE/- -
> 1423470404.202     36 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
> GET https://camo.githubusercontent.com/e4e69472ef17c28376ab41d57498aedfe64531bd/68747470733a2f2f7472617669732d63692e6f72672f42696742726f74686572426f742f6269672d62726f746865722d626f742e7376673f6272616e63683d72656c656173652d312e3130
> - HIER_DIRECT/185.31.18.133 -
> 1423470404.206      3 192.168.X.X TCP_HIT/200 18253 GET
> https://assets-cdn.github.com/assets/octicons/octicons/octicons-192e5fbb927be7cdb8bdfa0ecb98d3574bd395e58f9d00e5dcdfce5bc9660ac0.woff
> - HIER_NONE/- application/x-font-woff
> 1423470404.545    394 192.168.X.X TCP_MISS/200 111485 GET
> https://assets-cdn.github.com/assets/frameworks-996268c2962f947579cb9ec2908bd576591bc94b6a2db184a78e78815022ba2c.js
> - HIER_DIRECT/185.31.19.133 application/javascript
> 1423470404.716    547 192.168.X.X TCP_SWAPFAIL_MISS/200 3082 GET
> https://avatars2.githubusercontent.com/u/42300? -
> HIER_DIRECT/185.31.18.133 image/png
> 1423470404.890    345 192.168.X.X TCP_MISS/200 103109 GET
> https://assets-cdn.github.com/assets/github-adfa2ee6f7ed872963ba72937fc628d615cd1cfe2268305014aaa3a80ef2b04d.js
> - HIER_DIRECT/185.31.19.133 application/javascript
> 1423470405.123      0 192.168.X.X TAG_NONE/200 0 CONNECT
> github.com:443 - HIER_NONE/- -
> 1423470405.298    175 192.168.X.X TCP_MISS/200 1951 GET
> https://github.com/BigBrotherBot/big-brother-bot/contributors_size -
> HIER_DIRECT/192.30.252.130 text/html
> 1423470405.404      0 192.168.X.X TCP_HIT/200 4755 GET
> https://assets-cdn.github.com/flash/ZeroClipboard.v2.1.6.swf -
> HIER_NONE/- application/x-shockwave-flash
> 1423470405.408   1205 192.168.X.X TCP_MISS/200 1504 GET
> https://camo.githubusercontent.com/671757fe55a0c195ccc405d6807cec6c7d39004e/68747470733a2f2f70797069702e696e2f6567672f62332f62616467652e7376673f7374796c653d666c6174
> - HIER_DIRECT/185.31.18.133 image/svg+xml
> 1423470405.415   1212 192.168.X.X TCP_MISS/200 1506 GET
> https://camo.githubusercontent.com/51087cc89539882f6185930c4c544b5f48914b89/68747470733a2f2f70797069702e696e2f70795f76657273696f6e732f62332f62616467652e7376673f7374796c653d666c6174
> - HIER_DIRECT/185.31.18.133 image/svg+xml
> 1423470405.421     34 192.168.X.X TAG_NONE/200 0 CONNECT
> collector-cdn.github.com:443 - HIER_NONE/- -
> 1423470405.423   1220 192.168.X.X TCP_MISS/200 1531 GET
> https://camo.githubusercontent.com/9628b1f0ec45c623ad122817971f6fb688742ba6/68747470733a2f2f70797069702e696e2f646f776e6c6f61642f62332f62616467652e7376673f7374796c653d666c6174
> - HIER_DIRECT/185.31.18.133 image/svg+xml
> 1423470405.437   1235 192.168.X.X TCP_MISS/200 1508 GET
> https://camo.githubusercontent.com/bf594cf91b686d8307f7935d6c0f7371db255c43/68747470733a2f2f70797069702e696e2f76657273696f6e2f62332f62616467652e7376673f7374796c653d666c6174
> - HIER_DIRECT/185.31.18.133 image/svg+xml
> 1423470405.452   1249 192.168.X.X TCP_MISS/200 1508 GET
> https://camo.githubusercontent.com/30f75228ae73fd020e074db958f7b7a7469a3af5/68747470733a2f2f70797069702e696e2f6c6963656e73652f62332f62616467652e7376673f7374796c653d666c6174
> - HIER_DIRECT/185.31.18.133 image/svg+xml
> 1423470405.527    137 192.168.X.X TCP_MISS/200 1887 GET
> https://github.com/BigBrotherBot/big-brother-bot/issues/counts -
> HIER_DIRECT/192.30.252.130 application/json
> 1423470405.642    502 192.168.X.X TCP_MISS/200 1856 GET
> https://github.com/BigBrotherBot/big-brother-bot/show_partial? -
> HIER_DIRECT/192.30.252.130 text/html
> 1423470406.043    188 192.168.X.X TCP_SWAPFAIL_MISS/200 3377 GET
> https://collector-cdn.github.com/assets/api.js -
> HIER_DIRECT/185.31.19.133 application/javascript
> 1423470406.126     61 192.168.X.X TAG_NONE/200 0 CONNECT
> collector.githubapp.com:443 - HIER_NONE/- -
> 1423470406.616    466 192.168.X.X TCP_MISS/200 663 GET
> https://collector.githubapp.com/github/page_view? -
> HIER_DIRECT/54.86.253.42 image/gif
> 1423470407.690    544 192.168.X.X TCP_MISS/400 1398 POST
> https://github.com/_stats - HIER_DIRECT/192.30.252.130 text/javascript
> 1423470412.670    402 192.168.X.X TCP_MISS/200 21550 GET
> http://forum.arcadecontrols.com/index.php? - FIRSTUP_PARENT/127.0.0.1
> text/html
> 1423470429.282    110 192.168.X.X TAG_NONE/200 0 CONNECT
> avatars0.githubusercontent.com:443 - HIER_NONE/- -
> 1423470429.282    110 192.168.X.X TAG_NONE/200 0 CONNECT
> avatars1.githubusercontent.com:443 - HIER_NONE/- -
> 1423470429.291      2 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
> GET https://avatars0.githubusercontent.com/u/1245124? -
> HIER_DIRECT/185.31.18.133 -
> 1423470429.387   1624 192.168.X.X TCP_MISS/200 16633 GET
> https://github.com/BigBrotherBot/big-brother-bot/commits/release-1.10
> - HIER_DIRECT/192.30.252.130 text/html
> 1423470429.452      0 192.168.X.X TAG_NONE/200 0 CONNECT
> avatars0.githubusercontent.com:443 - HIER_NONE/- -
> 1423470429.452      0 192.168.X.X TAG_NONE/200 0 CONNECT
> avatars1.githubusercontent.com:443 - HIER_NONE/- -
> 1423470429.541      0 192.168.X.X TAG_NONE/200 0 CONNECT
> avatars0.githubusercontent.com:443 - HIER_NONE/- -
> 1423470429.546      2 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
> GET https://avatars0.githubusercontent.com/u/1245124? -
> HIER_DIRECT/185.31.18.133 -
> 1423470429.669      0 192.168.X.X TAG_NONE/200 0 CONNECT
> avatars0.githubusercontent.com:443 - HIER_NONE/- -
> 1423470429.674      2 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
> GET https://avatars0.githubusercontent.com/u/1245124? -
> HIER_DIRECT/185.31.18.133 -
> 1423470429.815      0 192.168.X.X TAG_NONE/200 0 CONNECT
> avatars0.githubusercontent.com:443 - HIER_NONE/- -
> 1423470429.824      2 192.168.X.X TCP_SWAPFAIL_MISS_ABORTED/000 4258
> GET https://avatars0.githubusercontent.com/u/1245124? -

SWAPFAIL means there was an internal error in Squid fetching the stored
object out of disk cache. Thats okay, the cached object gets discarded
and Squid went to the network (MISS) instead.

Then the client ABORTED after receiving 4258 bytes and before the
transaction completed.


> HIER_DIRECT/185.31.18.133 -
> 1423470430.146    858 192.168.X.X TCP_SWAPFAIL_MISS/200 6451 GET
> https://avatars1.githubusercontent.com/u/42300? -
> HIER_DIRECT/185.31.19.133 image/png
> 1423470430.330    863 192.168.X.X TCP_MISS/200 7532 GET
> https://avatars0.githubusercontent.com/u/5205363? -
> HIER_DIRECT/185.31.18.133 image/png
> 1423470430.369    892 192.168.X.X TCP_MISS/200 2458 GET
> https://avatars1.githubusercontent.com/u/42300? -
> HIER_DIRECT/185.31.19.133 image/png
> 1423470430.833    244 192.168.X.X TCP_MISS/200 663 GET
> https://collector.githubapp.com/github/page_view? -
> HIER_DIRECT/54.86.253.42 image/gif
> 1423470432.407   1039 192.168.X.X TCP_MISS/400 1399 POST
> https://github.com/_stats - HIER_DIRECT/192.30.252.130 text/javascript
> 
> I tried to get the log also when the browser shows "cannot connect to
> proxy", but there isn't any.

Meaning the TCP handshake itelf is failing. Squid will log if some bytes
of the requet message was received.


> Moreover I noticed that sometimes the browser ask me to download
> "index.php" (or a page component) instead displaying it (if I cancel
> the download and reload the page, everything is displayed as
> intended).

I am seeing that last behaviour in Firefox and Chrome without any proxy
being used. They seem to be misinterpreting the content types for random
objects as "application/x-octet-stream" (binary downloads or encrypted
media streams).

Amos


From squid3 at treenet.co.nz  Mon Feb  9 10:31:59 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 09 Feb 2015 23:31:59 +1300
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <365233982.343047156.1423476736816.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <365233982.343047156.1423476736816.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <54D88C9F.4070501@treenet.co.nz>

On 9/02/2015 11:12 p.m., FredB wrote:
> Yes, TCP_SWAPFAIL_MISS is the point
> 
> 10.253.33.61 - fred [09/Feb/2015:10:50:21 +0100] "GET http://www.google-analytics.com/analytics.js HTTP/1.0" 200 11932 TCP_SWAPFAIL_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:35.0) Gecko/20100101 Firefox/35.0"
> 
> Amos, about our conversation this is related, after TCP_SWAPFAIL_MISS and blank page sometime there is a 407, at least with DIGEST 
> 

Which just means that the credentials have expired or been discarded.

Though whether its Squid or the browser is nowhere near clear - maybe
even both. As I mentioned some of the related symptoms I am seeing here
without using a proxy.

Amos



From fredbmail at free.fr  Mon Feb  9 11:00:15 2015
From: fredbmail at free.fr (FredB)
Date: Mon, 9 Feb 2015 12:00:15 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54D88C9F.4070501@treenet.co.nz>
Message-ID: <1251123883.343140390.1423479615293.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> Which just means that the credentials have expired or been discarded.

Yes I known, but in this case the NONCE was valid, I'm trying with a very long time TTL.
SWAP_FAIL -> blank page -> 407 -> New nonce

I guess the blank page breaks something 

> 
> Though whether its Squid or the browser is nowhere near clear - maybe
> even both. As I mentioned some of the related symptoms I am seeing
> here
> without using a proxy.

With FF ?






From ludovit.koren at gmail.com  Mon Feb  9 14:19:42 2015
From: ludovit.koren at gmail.com (Ludovit Koren)
Date: Mon, 09 Feb 2015 15:19:42 +0100
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
Message-ID: <86a90nxj41.fsf@gmail.com>



Hi,

I have setup kerberos according to:

http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory

# klist 
Credentials cache: FILE:/tmp/krb5cc_0
        Principal: HTTP/squid1.mdpt.local at MDPT.LOCAL

  Issued                Expires               Principal
Feb  9 14:55:18 2015  Feb 10 00:55:18 2015  krbtgt/MDPT.LOCAL at MDPT.LOCAL
Feb  9 14:55:20 2015  Feb 10 00:55:18 2015  HTTP/squid1.mdpt.local at MDPT.LOCAL

# klist -v
Credentials cache: FILE:/tmp/krb5cc_0
        Principal: HTTP/squid1.mdpt.local at MDPT.LOCAL
    Cache version: 4

Server: krbtgt/MDPT.LOCAL at MDPT.LOCAL
Client: HTTP/squid1.mdpt.local at MDPT.LOCAL
Ticket etype: aes256-cts-hmac-sha1-96, kvno 3
Session key: aes128-cts-hmac-sha1-96
Ticket length: 1081
Auth time:  Feb  9 14:55:18 2015
End time:   Feb 10 00:55:18 2015
Ticket flags: enc-pa-rep, pre-authent, initial, forwardable
Addresses: addressless

Server: HTTP/squid1.mdpt.local at MDPT.LOCAL
Client: HTTP/squid1.mdpt.local at MDPT.LOCAL
Ticket etype: arcfour-hmac-md5, kvno 8
Ticket length: 1090
Auth time:  Feb  9 14:55:18 2015
Start time: Feb  9 14:55:20 2015
End time:   Feb 10 00:55:18 2015
Ticket flags: enc-pa-rep, pre-authent
Addresses: addressless



# ktutil -k /etc/krb5.keytab list
/etc/krb5.keytab:

Vno  Type                     Principal                          Aliases
  8  aes128-cts-hmac-sha1-96  HTTP/squid1.mdpt.local at MDPT.LOCAL  


When I try to test it with the following command I get the error:

# /usr/local/libexec/squid/negotiate_kerberos_auth_test squid1.mdpt.local | awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | /usr/local/libexec/squid/negotiate_kerberos_auth -r -s HTTP/squid1.mdpt.local
BH gss_accept_sec_context() failed:  Miscellaneous failure (see text). unknown mech-code 2529639093 for mech unknown
BH quit command


I cannot find anything suitable for the error code. Could you, please,
point me in the right direction? Any hint appreciated.

regards,

lk


From alfrenovsky at gmail.com  Mon Feb  9 16:11:19 2015
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Mon, 09 Feb 2015 16:11:19 +0000
Subject: [squid-users] kid registration timed out
References: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>
 <54D83920.7050706@ngtech.co.il>
Message-ID: <CAMXC=Wusr+gGGEL+HYyrbHj1mwOsN3NAsRZDh3FEK=C-EhpSKw@mail.gmail.com>

I have one of these lines for each cache disc (sdb, sdc, etc)

cache_dir aufs /cache/sdb/${process_number} 230000 16 256 min-size=1
max-size=838860800

I'm using 4 or 5 discs to increase the cache I/O.

The cach? size is a little less than disk_size/workers

There's a way to run a full store rebuild and exit. So I'm sure the stores
are clean after starting the real squid and enabling transparent proxy
iptables rules?



El Mon Feb 09 2015 at 1:36:01, Eliezer Croitoru <eliezer at ngtech.co.il>
escribi?:

> On 08/02/2015 01:32, Alfredo Rezinovsky wrote:
> > Specially in servers with 6 workers and 6 cache discs (Each worker has a
> > cache_dir in each disc for IO balancing)
>
> What cache_dir settings are you using there?
>
> Eliezer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150209/72a931ef/attachment.htm>

From amit_info2k at yahoo.com  Mon Feb  9 17:07:27 2015
From: amit_info2k at yahoo.com (amitinfo2k)
Date: Mon, 9 Feb 2015 09:07:27 -0800 (PST)
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
Message-ID: <1423501647069-4669634.post@n4.nabble.com>

Hi,

I am a newbie to squid proxy world.
I have setup the squid proxy with default configuration on Fedora 19 box.
Now I wanted to configure the Spash pages. But, not able to find a single
working example for squid 3.3.13.
Can anyone provide me an example configuration for Spash pages in squid
3.3.2.

I have tried the following modified example but no luck no errors in the
logs :

# Set up the session helper in active mode. Mind the wrap - this is one
line:
external_acl_type session ipv4 concurrency=100 ttl=3 %SRC
/usr/lib64/squid/ext_session_acl -a -T 60 -b /var/lib/squid/session/

# Pass the LOGIN command to the session helper with this ACL
acl session_login external session LOGIN

# Set up the normal session helper. Mind the wrap - this is one line:
external_acl_type session_active_def ipv4 concurrency=100 ttl=3 %SRC
/usr/lib64/squid/ext_session_acl -a -T 60 -b /var/lib/squid/session/

# Normal session ACL as per simple example
acl session_is_active external session_active_def

# ACL to match URL
acl clicked_login_url url_regex -i http://example.net

# First check for the login URL. If present, login session
http_access allow clicked_login_url session_login

# If we get here, URL not present, so renew session or deny request.
http_access deny !session_is_active

# Deny page to display
deny_info http://example.net session_is_active


Thanks,
amitinfo2k




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Portal-Splash-Pages-example-on-squid-3-3-13-tp4669634.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Tue Feb 10 04:01:45 2015
From: ahmed.zaeem at netstream.ps (Ahmad)
Date: Mon, 9 Feb 2015 20:01:45 -0800
Subject: [squid-users] squid  authentication to remote sql server
Message-ID: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>

Hi , 

I followed the article in  :

http://wiki.squid-cache.org/ConfigExamples/Authenticate/Mysql

 

 

I need to connect  squid to external sql server  , what do I need to modify
in the helper command ?

 

I think that the command below :

""auth_param basic program /usr/local/squid/libexec/squid_db_auth --user
someuser --password xxxx --plaintext --persist

 

Shoud include the ip  & port of the sql server .

 

 

 

cheers

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150209/f5c12285/attachment.htm>

From huaraz at moeller.plus.com  Mon Feb  9 21:11:52 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Mon, 9 Feb 2015 21:11:52 -0000
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <86a90nxj41.fsf@gmail.com>
References: <86a90nxj41.fsf@gmail.com>
Message-ID: <mbb8e1$7l7$1@ger.gmane.org>

Hi Ludovit,

  I haven't seen that error before either, but when you test you sould have 
your own user credentials in the cache.  You should use kinit 
<user>@MDPT.LOCAL and then try again the test. is the hostname correctly set 
to squid1.mdpt.local ? If not try

   /usr/local/libexec/squid/negotiate_kerberos_auth_test squid1.mdpt.local | 
awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | 
/usr/local/libexec/squid/negotiate_kerberos_auth -r -s GSS_C_NO_NAME


Markus

"Ludovit Koren"  wrote in message news:86a90nxj41.fsf at gmail.com...



Hi,

I have setup kerberos according to:

http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory

# klist
Credentials cache: FILE:/tmp/krb5cc_0
        Principal: HTTP/squid1.mdpt.local at MDPT.LOCAL

  Issued                Expires               Principal
Feb  9 14:55:18 2015  Feb 10 00:55:18 2015  krbtgt/MDPT.LOCAL at MDPT.LOCAL
Feb  9 14:55:20 2015  Feb 10 00:55:18 2015 
HTTP/squid1.mdpt.local at MDPT.LOCAL

# klist -v
Credentials cache: FILE:/tmp/krb5cc_0
        Principal: HTTP/squid1.mdpt.local at MDPT.LOCAL
    Cache version: 4

Server: krbtgt/MDPT.LOCAL at MDPT.LOCAL
Client: HTTP/squid1.mdpt.local at MDPT.LOCAL
Ticket etype: aes256-cts-hmac-sha1-96, kvno 3
Session key: aes128-cts-hmac-sha1-96
Ticket length: 1081
Auth time:  Feb  9 14:55:18 2015
End time:   Feb 10 00:55:18 2015
Ticket flags: enc-pa-rep, pre-authent, initial, forwardable
Addresses: addressless

Server: HTTP/squid1.mdpt.local at MDPT.LOCAL
Client: HTTP/squid1.mdpt.local at MDPT.LOCAL
Ticket etype: arcfour-hmac-md5, kvno 8
Ticket length: 1090
Auth time:  Feb  9 14:55:18 2015
Start time: Feb  9 14:55:20 2015
End time:   Feb 10 00:55:18 2015
Ticket flags: enc-pa-rep, pre-authent
Addresses: addressless



# ktutil -k /etc/krb5.keytab list
/etc/krb5.keytab:

Vno  Type                     Principal                          Aliases
  8  aes128-cts-hmac-sha1-96  HTTP/squid1.mdpt.local at MDPT.LOCAL


When I try to test it with the following command I get the error:

# /usr/local/libexec/squid/negotiate_kerberos_auth_test squid1.mdpt.local | 
awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | 
/usr/local/libexec/squid/negotiate_kerberos_auth -r -s 
HTTP/squid1.mdpt.local
BH gss_accept_sec_context() failed:  Miscellaneous failure (see text). 
unknown mech-code 2529639093 for mech unknown
BH quit command


I cannot find anything suitable for the error code. Could you, please,
point me in the right direction? Any hint appreciated.

regards,

lk
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From mirza.dedic at outlook.com  Mon Feb  9 21:22:38 2015
From: mirza.dedic at outlook.com (Mirza Dedic)
Date: Mon, 9 Feb 2015 13:22:38 -0800
Subject: [squid-users] Unable to determine IP address from hostname ?
Message-ID: <BAY402-EAS18506D98D77A8903C32A95DF0270@phx.gbl>

I have users getting quite frequently this error in Squid..

Unable to determine IP address from hostname.
"The DNS server returned no DNS records"

I have in my squid.conf setup..

dns_nameservers 8.8.8.8 8.8.4.4
dns_timeout 5 second

It seems random, but 5 seconds should be enough and we're resolving against
Google public DNS servers.

The sites it is unable to resolve are up (expedia.com, and other sites that
usually don't go down).

Is there anything else I can do?


From squid3 at treenet.co.nz  Mon Feb  9 21:28:41 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Feb 2015 10:28:41 +1300
Subject: [squid-users] kid registration timed out
In-Reply-To: <CAMXC=Wusr+gGGEL+HYyrbHj1mwOsN3NAsRZDh3FEK=C-EhpSKw@mail.gmail.com>
References: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>
 <54D83920.7050706@ngtech.co.il>
 <CAMXC=Wusr+gGGEL+HYyrbHj1mwOsN3NAsRZDh3FEK=C-EhpSKw@mail.gmail.com>
Message-ID: <54D92689.4020005@treenet.co.nz>

On 10/02/2015 5:11 a.m., Alfredo Rezinovsky wrote:
> I have one of these lines for each cache disc (sdb, sdc, etc)
> 
> cache_dir aufs /cache/sdb/${process_number} 230000 16 256 min-size=1
> max-size=838860800
> 
> I'm using 4 or 5 discs to increase the cache I/O.
> 
> The cach? size is a little less than disk_size/workers
> 
> There's a way to run a full store rebuild and exit. So I'm sure the stores
> are clean after starting the real squid and enabling transparent proxy
> iptables rules?

I already mentioned to you about disk I/O contention right?

The rule-of-thumb about one cache_dir per physical disk spindle is not
removed by multiple workers. A *single* Squid process can push any disk
hardware to its bare-metal I/O write capacity. Sharing between workers
just makes disks cap-out faster.


During that startup all Squid is doing with those disks is reading the
swap.state files from each AUFS cache_dir and scanning across the rock
cache_dir slots in MB sized chunks. Provided you are right about the
caches being clean (having a non-corrupt swap.state journal).

 ... why do you think increasing the number of workers makes them slow
down until one hits that 10 second timeout?

And consider what would happen later when your full network bandwidth
get thrown at the workers (hint approx. 4/5 of network I/O gets written
to disk).

Amos



From huaraz at moeller.plus.com  Mon Feb  9 21:44:45 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Mon, 9 Feb 2015 21:44:45 -0000
Subject: [squid-users] benefits of using
	ext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <m9p4fk$b9o$1@ger.gmane.org>
References: <1EC53106-F880-4828-89AD-C3CEE0BC03ED@open.ch>
 <54BE3B5C.8040800@treenet.co.nz> <m9p4fk$b9o$1@ger.gmane.org>
Message-ID: <mbb9og$t7r$1@ger.gmane.org>


>>> "Amos Jeffries"  wrote in message news:54BE3B5C.8040800 at
>>> treenet.co.nz...
>>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>> On 20/01/2015 11:31 p.m., Simon St?heli wrote:
>>>> Are there any other benefits in using ext_kerberos_ldap_group_acl
>>>> instead of ext_ldap_group_acl except the "Netbios name to Kerberos
>>>> domain name? mappings provided by the -N option. As far as I can
>>>> tell, this mapping can also easily be done by writing you own
>>>> helper perl script which is doing the mapping and finally feeds the
>>>> more common ext_ldap_group_acl helper.
>>>>
>>>
>>> Whatever floats your boat. The point of the Addon/Plugin/helpers API
>>> is that you can use scripts if thy serve your needs better.
>>>
>>> All the usual Open Source benefits of "many eyeballs" and somebody
>>> else doing code maintenance for you applies to using a bundled helper
>>> over a custom written one.
>>>
>>> Beyond that the kerberos helper also provides automatic detection of
>>> which LDAP server to use via mutiple auto-configuration methods.
>>>
>>
>> The idea of the helper was to automate most of the configuration (
>> ignoring
>> some performance ) and avoid using a username/password, support users
>> from
>> multiple domains. Secondly I wanted check for nested groups which was
>> not
>> available in the existing helper and thirdly I also check now against
>> the
>> primary group of the user.
>>
>
>Thank you Markus for your explanations. I played around with
>ext_kerberos_ldap_group_acl and would like to go into some details:
>
>1) it is possible to define more than one LDAP server (e.g. for high
>availability reasons)? The -l parameter allows only one ldap url while
>-S allows several "server > realm" - mappings.
>

I didn't see the need.  The -l was more for cases when digest or basic auth 
is used and I do not know the domain to check against.  So a fallback 
option.


>2) It is correct, that compared to ext_ldap_group_acl,
>ext_kerberos_ldap_group_acl does not require a groupname as input (from
>stdin), because -g -t -T or -D control the group name?!
>

You have two options with ext_kerberos_ldap_group_acl  as input or as -g .. 
control


>3) What is the use case for defining -g GROUP@? What is the difference
>to -g GROUP (without @)
>

-g GROUP is for all users including the once with nor provided domain


The an pages describe it a bit under Note:

1) For user at REALM
   a) Query DNS for SRV record _ldap._tcp.REALM
   b) Query DNS for A record REALM
   c) Use LDAP_URL if given

2) For user
   a) Use domain -D REALM and follow step 1)
   b) Use LDAP_URL if given

The Groups to check against are determined as follows:

1) For user at REALM
   a)  Use  values  given  by -g option which contain a @REALM e.g. -g
GROUP1 at REALM:GROUP2 at REALM
   b) Use values given by -g option which contain a  @  only  e.g.  -g
GROUP1@:GROUP2@
   c)  Use values given by -g option which do not contain a realm e.g.
-g GROUP1:GROUP2

2) For user
   a) Use values given by -g option which do not contain a realm  e.g.
-g GROUP1:GROUP2

3) For NDOMAIN\user
   a) Use realm given by -N NDOMAIN at REALM and then use values given by
-g option which contain a @REALM e.g. -g GROUP1 at REALM:GROUP2 at REALM



>4) The "query DNS for SRV record _ldap._tcp.REALM" mechanism seems no to
>work for me although the DNS server is configured correctly and querying
>with "dig SRV _ldap._tcp.REALM" works fine. Anything to consider here?
>_ldap._tcp.REALM SRV query was never sent so far.
>

I would not see an obvious reason.   Does -d show any hints ?  I can only 
imagine that REAM is not what is send by the client.

>5) Similar issues with the Kerberos feature. Keytab und Kerberos config
>are available and exported, but the helper only says:
>support_ldap.cc(888): DEBUG: Setup Kerberos credential cache
>support_ldap.cc(897): DEBUG: Kerberos is not supported. Use
>username/password with ldap url instead
>

The message support_ldap.cc(897): DEBUG: Kerberos is not supported. means 
your Kerberos installation is not fully available. It means HAVE_KRB5 is not 
set ( maybe header files were missing).

>Instead of that I found a dns SRV _kerberos._udp.REALM query which was
>actually answered by the dns. I assume this is related to the Kerberos
>feature?

yes it is. It is a way to find the kdc.

>
>6) It is possible to use the helper when DNS service is not reachable?
>Got some error messages during testing:
>
>kerberos_ldap_group: DEBUG: Canonicalise ldap server name
>213.156.236.111:3268
>kerberos_ldap_group: ERROR: Error while resolving ip address with
>getnameinfo: Temporary failure in name resolution
>kerberos_ldap_group: DEBUG: Error during initialisation of ldap
>connection: Success
>

If you add a line to your hosts file and use the approriate nsswitch.conf it 
should work.  You can also add a line to the hosts file for the domain for 
the case the SRV record fails.


>Beside this tiny issues the helper works excellent (tested with basic,
>NTLM and Kerberos authentication). I am just trying to discover the
>whole potential. Thank you very much for any responses.
>
>Regards
>Simon
>

Regards
Markus

>>> If you can demonstrate that the ext_kerberos_ldap_group_acl does
>>> provides a superset of the functionality of ext_ldap_group_acl helper
>>> then I can de-duplicate the two helpers.
>>>
>>> Amos
>>
>> Regards
>> Markus
> 




From squid3 at treenet.co.nz  Mon Feb  9 22:13:33 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Feb 2015 11:13:33 +1300
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <1423501647069-4669634.post@n4.nabble.com>
References: <1423501647069-4669634.post@n4.nabble.com>
Message-ID: <54D9310D.8040809@treenet.co.nz>

On 10/02/2015 6:07 a.m., amitinfo2k wrote:
> Hi,
> 
> I am a newbie to squid proxy world.
> I have setup the squid proxy with default configuration on Fedora 19 box.
> Now I wanted to configure the Spash pages. But, not able to find a single
> working example for squid 3.3.13.
> Can anyone provide me an example configuration for Spash pages in squid
> 3.3.2.

Sessions and splash pages operate the same for all Squid versions.
 http://wiki.squid-cache.org/ConfigExamples/Portal/Splash

The only reason it mentions versino numbers at all is that there was a
new HTTP/1.1 status code added in 3.2.

It seems the config got a bit corrupted. I've fixed that now.


Some edits in line below:


> 
> I have tried the following modified example but no luck no errors in the
> logs :
> 
> # Set up the session helper in active mode. Mind the wrap - this is one
> line:
> external_acl_type session ipv4 concurrency=100 ttl=3 %SRC
> /usr/lib64/squid/ext_session_acl -a -T 60 -b /var/lib/squid/session/
> 
> # Pass the LOGIN command to the session helper with this ACL
> acl session_login external session LOGIN
> 

Delete ...

> # Set up the normal session helper. Mind the wrap - this is one line:
> external_acl_type session_active_def ipv4 concurrency=100 ttl=3 %SRC
> /usr/lib64/squid/ext_session_acl -a -T 60 -b /var/lib/squid/session/
> 

... to here.


> # Normal session ACL as per simple example
> acl session_is_active external session_active_def

Replace with:
  acl session_is_active external session

> 
> # ACL to match URL
> acl clicked_login_url url_regex -i http://example.net


Replace with:
  acl clicked_login_url url_regex -i ^http://example.net/$

> 
> # First check for the login URL. If present, login session
> http_access allow clicked_login_url session_login
> 
> # If we get here, URL not present, so renew session or deny request.
> http_access deny !session_is_active
> 
> # Deny page to display
> deny_info http://example.net session_is_active

Replace with:
 deny_info 511:http://example.net/ session_is_active

Notice that the URL has to be a full valid URL. Your squid version is
*not* checking it before embedding into the outgoing headers.


Amos


From luismiguelferreirasilva at gmail.com  Mon Feb  9 23:00:32 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Mon, 9 Feb 2015 16:00:32 -0700
Subject: [squid-users] light weight ICAP server that isn't dead :o)
Message-ID: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>

Dear all,

I'm looking for a light weight (opensource) ICAP server project that isn't
dead.
I need to create some custom content filters but, I'm having a hard time
finding an ICAP server that is being actively worked on...

In the squid wiki <http://wiki.squid-cache.org/Features/ICAP#ICAP_Servers>,
I was able to find the following ICAP server implementations:
- C-ICAP <http://c-icap.sourceforge.net/>
-- lates release was in October 2014 (which is pretty good) but the latest
version is 0.3.5. *How stable is it?*
- Traffic Spicer <http://spicer.measurement-factory.com/>
-- Squid's docs point to this page <http://spicer.measurement-factory.com/>
but I couldn't even figure out where to download it or find any
documentation for it.
- ICAP-Server <http://icap-server.sourceforge.net/>
-- latest version for it is 1.2.1 but it is dated from October 30, 2002.
- POESIA <http://www.poesia-filter.org/>
-- this one points to a German page that doesn't seem to have anything to
do with ICAP...
- GreasySpoon <http://greasyspoon.sourceforge.net/>
-- this one seems to have been discontinued

The most interesting one seems to be C-ICAP but I don't like that it hasn't
even reached a 1.0 version...

What do you guys recommend I adopt?

Thank you,
Luis Silva
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150209/7874b1df/attachment.htm>

From squid3 at treenet.co.nz  Mon Feb  9 23:06:22 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Feb 2015 12:06:22 +1300
Subject: [squid-users] Unable to determine IP address from hostname ?
In-Reply-To: <BAY402-EAS18506D98D77A8903C32A95DF0270@phx.gbl>
References: <BAY402-EAS18506D98D77A8903C32A95DF0270@phx.gbl>
Message-ID: <54D93D6E.5050206@treenet.co.nz>

On 10/02/2015 10:22 a.m., Mirza Dedic wrote:
> I have users getting quite frequently this error in Squid..
> 
> Unable to determine IP address from hostname.
> "The DNS server returned no DNS records"

Means exactly what it says.

> 
> I have in my squid.conf setup..
> 
> dns_nameservers 8.8.8.8 8.8.4.4
> dns_timeout 5 second
> 
> It seems random, but 5 seconds should be enough and we're resolving against
> Google public DNS servers.
> 
> The sites it is unable to resolve are up (expedia.com, and other sites that
> usually don't go down).
> 
> Is there anything else I can do?

Expedia is hosted on Akamai. Akamai load balance their CDN by doing DNS
response tricks. I'm seen a few different types of failure resulting
from that.
 - in Expedias case the DNS TTL is 12 seconds and there are two layers
of CNAME to resolve before one gets to an IP. Those CNAMEs themselves
only have TTL of a few minutes.


The Akamai behaviour that could result in that no-IPs error is when only
CNAME results are returned. Squid relies on the resolver to do the
recursion. Sometimes all Squid gets is a bunch of nested CNAME with no
IP to connect to. This is particularly bad with IPv6 lookups when the
Akamai client is not v6-enabled (expedia is one such).


Your Squid version can also impact results. 3.1 originally did two
sequential lookups, for AAAA and A records. That was changed to parallel
in 3.3, but still the longer of the two must fit within the timeout.


Amos



From squid3 at treenet.co.nz  Mon Feb  9 23:40:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Feb 2015 12:40:28 +1300
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
Message-ID: <54D9456C.5000808@treenet.co.nz>

On 10/02/2015 12:00 p.m., Luis Miguel Silva wrote:
> Dear all,
> 
> I'm looking for a light weight (opensource) ICAP server project that isn't
> dead.
> I need to create some custom content filters but, I'm having a hard time
> finding an ICAP server that is being actively worked on...
> 

The ICAP servers you are looking at are framework servers that "just"
decode the on-wire protocol and pass it to a plugin module, and reverse
that for the results. That is all they have to do and its quite simple,
the protocol itself is 12 years old. So you wont really see huge amounts
of ongoing change in any of them.

Theres a whole other category of ICAP server, such as AV vendors. They
get a lot more active turnover on their software, but are all about
custom integration for the filtering activity they do rather than
generic plugin engines. And again most of the code churn is in the
filtering parts not the ICAP bits.


> In the squid wiki <http://wiki.squid-cache.org/Features/ICAP#ICAP_Servers>,
> I was able to find the following ICAP server implementations:
> - C-ICAP <http://c-icap.sourceforge.net/>
> -- lates release was in October 2014 (which is pretty good) but the latest
> version is 0.3.5. *How stable is it?*
> - Traffic Spicer <http://spicer.measurement-factory.com/>
> -- Squid's docs point to this page <http://spicer.measurement-factory.com/>
> but I couldn't even figure out where to download it or find any
> documentation for it.
> - ICAP-Server <http://icap-server.sourceforge.net/>
> -- latest version for it is 1.2.1 but it is dated from October 30, 2002.
> - POESIA <http://www.poesia-filter.org/>
> -- this one points to a German page that doesn't seem to have anything to
> do with ICAP...
> - GreasySpoon <http://greasyspoon.sourceforge.net/>
> -- this one seems to have been discontinued
> 
> The most interesting one seems to be C-ICAP but I don't like that it hasn't
> even reached a 1.0 version...
> 
> What do you guys recommend I adopt?
> 

c-icap.

Though I have to disclaim a slight bias. The c-icap author is one of our
more active Squid developers.


You might also look into eCAP. The design intention is that you build an
eCAP module which can plug into either the c-icap engine for access over
ICAP or be loaded by Squid for faster processing directly on the HTTP
traffic flow.

Amos


From squid3 at treenet.co.nz  Tue Feb 10 00:15:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Feb 2015 13:15:24 +1300
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
Message-ID: <54D94D9C.1090108@treenet.co.nz>

On 10/02/2015 5:01 p.m., Ahmad wrote:
> Hi , 
> 
> I followed the article in  :
> 
> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Mysql
> 
>  
> 
>  
> 
> I need to connect  squid to external sql server  , what do I need to modify
> in the helper command ?
> 
>  
> 
> I think that the command below :
> 
> ""auth_param basic program /usr/local/squid/libexec/squid_db_auth --user
> someuser --password xxxx --plaintext --persist
> 
>  
> 
> Shoud include the ip  & port of the sql server .
> 

The Data Source Name (--dsn) parameter is the option string passed to
the Perl DBI module for locating the database to use.

It takes the syntax:

  "DSN:" driver ":" params

The params bit depends on what database driver (type) is. The "mysql"
driver uses semi-colon separated key=value pairs.

So you can write something like:

  --dsn "DSN:mysql:host=example.com;port=3306;database=squid"


Amos


From luismiguelferreirasilva at gmail.com  Tue Feb 10 00:18:36 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Mon, 9 Feb 2015 17:18:36 -0700
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <54D9456C.5000808@treenet.co.nz>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54D9456C.5000808@treenet.co.nz>
Message-ID: <CA+suCFhGHDFd_TUdJTvozamKB0nVc3vqnV5YRzyUnfXvLzsgUw@mail.gmail.com>

Thanks Amos.

Well, that's exactly what I'm going to need to develop too (the plugin
part), I just found it weird that the C-ICAP service was still version
0.3.5, even though it was really old. If it is mature, I would expect it to
get to v1.0 and cease development :o)

So...what one would you recommend if you wanted to easily create
(lightweight) custom filtering capabilities?
I'm very inclined to adopt c-icap. Thoughts?

Thanks,
Luis

On Mon, Feb 9, 2015 at 4:40 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 10/02/2015 12:00 p.m., Luis Miguel Silva wrote:
> > Dear all,
> >
> > I'm looking for a light weight (opensource) ICAP server project that
> isn't
> > dead.
> > I need to create some custom content filters but, I'm having a hard time
> > finding an ICAP server that is being actively worked on...
> >
>
> The ICAP servers you are looking at are framework servers that "just"
> decode the on-wire protocol and pass it to a plugin module, and reverse
> that for the results. That is all they have to do and its quite simple,
> the protocol itself is 12 years old. So you wont really see huge amounts
> of ongoing change in any of them.
>
> Theres a whole other category of ICAP server, such as AV vendors. They
> get a lot more active turnover on their software, but are all about
> custom integration for the filtering activity they do rather than
> generic plugin engines. And again most of the code churn is in the
> filtering parts not the ICAP bits.
>
>
> > In the squid wiki <
> http://wiki.squid-cache.org/Features/ICAP#ICAP_Servers>,
> > I was able to find the following ICAP server implementations:
> > - C-ICAP <http://c-icap.sourceforge.net/>
> > -- lates release was in October 2014 (which is pretty good) but the
> latest
> > version is 0.3.5. *How stable is it?*
> > - Traffic Spicer <http://spicer.measurement-factory.com/>
> > -- Squid's docs point to this page <
> http://spicer.measurement-factory.com/>
> > but I couldn't even figure out where to download it or find any
> > documentation for it.
> > - ICAP-Server <http://icap-server.sourceforge.net/>
> > -- latest version for it is 1.2.1 but it is dated from October 30, 2002.
> > - POESIA <http://www.poesia-filter.org/>
> > -- this one points to a German page that doesn't seem to have anything to
> > do with ICAP...
> > - GreasySpoon <http://greasyspoon.sourceforge.net/>
> > -- this one seems to have been discontinued
> >
> > The most interesting one seems to be C-ICAP but I don't like that it
> hasn't
> > even reached a 1.0 version...
> >
> > What do you guys recommend I adopt?
> >
>
> c-icap.
>
> Though I have to disclaim a slight bias. The c-icap author is one of our
> more active Squid developers.
>
>
> You might also look into eCAP. The design intention is that you build an
> eCAP module which can plug into either the c-icap engine for access over
> ICAP or be loaded by Squid for faster processing directly on the HTTP
> traffic flow.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150209/eace792f/attachment.htm>

From jleu at mindspring.com  Tue Feb 10 02:35:08 2015
From: jleu at mindspring.com (James Leu)
Date: Mon, 9 Feb 2015 20:35:08 -0600
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <CA+suCFhGHDFd_TUdJTvozamKB0nVc3vqnV5YRzyUnfXvLzsgUw@mail.gmail.com>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54D9456C.5000808@treenet.co.nz>
 <CA+suCFhGHDFd_TUdJTvozamKB0nVc3vqnV5YRzyUnfXvLzsgUw@mail.gmail.com>
Message-ID: <20150210023507.GA10632@mindspring.com>

Not sure if this is usefull to anyone.  Here is a simple perl server that
tries to implement ICAP.  YMMV (attached)

On Mon, Feb 09, 2015 at 05:18:36PM -0700, Luis Miguel Silva wrote:
> Thanks Amos.
> 
> Well, that's exactly what I'm going to need to develop too (the plugin
> part), I just found it weird that the C-ICAP service was still version
> 0.3.5, even though it was really old. If it is mature, I would expect it to
> get to v1.0 and cease development :o)
> 
> So...what one would you recommend if you wanted to easily create
> (lightweight) custom filtering capabilities?
> I'm very inclined to adopt c-icap. Thoughts?
> 
> Thanks,
> Luis
> 
> On Mon, Feb 9, 2015 at 4:40 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> > On 10/02/2015 12:00 p.m., Luis Miguel Silva wrote:
> > > Dear all,
> > >
> > > I'm looking for a light weight (opensource) ICAP server project that
> > isn't
> > > dead.
> > > I need to create some custom content filters but, I'm having a hard time
> > > finding an ICAP server that is being actively worked on...
> > >
> >
> > The ICAP servers you are looking at are framework servers that "just"
> > decode the on-wire protocol and pass it to a plugin module, and reverse
> > that for the results. That is all they have to do and its quite simple,
> > the protocol itself is 12 years old. So you wont really see huge amounts
> > of ongoing change in any of them.
> >
> > Theres a whole other category of ICAP server, such as AV vendors. They
> > get a lot more active turnover on their software, but are all about
> > custom integration for the filtering activity they do rather than
> > generic plugin engines. And again most of the code churn is in the
> > filtering parts not the ICAP bits.
> >
> >
> > > In the squid wiki <
> > http://wiki.squid-cache.org/Features/ICAP#ICAP_Servers>,
> > > I was able to find the following ICAP server implementations:
> > > - C-ICAP <http://c-icap.sourceforge.net/>
> > > -- lates release was in October 2014 (which is pretty good) but the
> > latest
> > > version is 0.3.5. *How stable is it?*
> > > - Traffic Spicer <http://spicer.measurement-factory.com/>
> > > -- Squid's docs point to this page <
> > http://spicer.measurement-factory.com/>
> > > but I couldn't even figure out where to download it or find any
> > > documentation for it.
> > > - ICAP-Server <http://icap-server.sourceforge.net/>
> > > -- latest version for it is 1.2.1 but it is dated from October 30, 2002.
> > > - POESIA <http://www.poesia-filter.org/>
> > > -- this one points to a German page that doesn't seem to have anything to
> > > do with ICAP...
> > > - GreasySpoon <http://greasyspoon.sourceforge.net/>
> > > -- this one seems to have been discontinued
> > >
> > > The most interesting one seems to be C-ICAP but I don't like that it
> > hasn't
> > > even reached a 1.0 version...
> > >
> > > What do you guys recommend I adopt?
> > >
> >
> > c-icap.
> >
> > Though I have to disclaim a slight bias. The c-icap author is one of our
> > more active Squid developers.
> >
> >
> > You might also look into eCAP. The design intention is that you build an
> > eCAP module which can plug into either the c-icap engine for access over
> > ICAP or be loaded by Squid for faster processing directly on the HTTP
> > traffic flow.
> >
> > Amos
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >


-- 
James R. Leu
jleu at mindspring.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: icap.pl
Type: application/x-perl
Size: 16830 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150209/fa022062/attachment.bin>

From alfrenovsky at gmail.com  Tue Feb 10 02:47:10 2015
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Mon, 9 Feb 2015 23:47:10 -0300
Subject: [squid-users] kid registration timed out
In-Reply-To: <54D92689.4020005@treenet.co.nz>
References: <CAMXC=Wux-hANWg8m8uuRYqvxGYjnr6HsCOTHxg4WoSx38gFYoQ@mail.gmail.com>
 <54D83920.7050706@ngtech.co.il>
 <CAMXC=Wusr+gGGEL+HYyrbHj1mwOsN3NAsRZDh3FEK=C-EhpSKw@mail.gmail.com>
 <54D92689.4020005@treenet.co.nz>
Message-ID: <CAMXC=Wu4FxfQRrE=ecFfg1BLAZNHPGmxoSzkkwGnLegKf6_64g@mail.gmail.com>

The workers are to use most of the CPU cores (and not only 1, which is not
enough)
The hard drivers are to increase IO.




2015-02-09 18:28 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 10/02/2015 5:11 a.m., Alfredo Rezinovsky wrote:
> > I have one of these lines for each cache disc (sdb, sdc, etc)
> >
> > cache_dir aufs /cache/sdb/${process_number} 230000 16 256 min-size=1
> > max-size=838860800
> >
> > I'm using 4 or 5 discs to increase the cache I/O.
> >
> > The cach? size is a little less than disk_size/workers
> >
> > There's a way to run a full store rebuild and exit. So I'm sure the
> stores
> > are clean after starting the real squid and enabling transparent proxy
> > iptables rules?
>
> I already mentioned to you about disk I/O contention right?
>
> The rule-of-thumb about one cache_dir per physical disk spindle is not
> removed by multiple workers. A *single* Squid process can push any disk
> hardware to its bare-metal I/O write capacity. Sharing between workers
> just makes disks cap-out faster.
>
>
> During that startup all Squid is doing with those disks is reading the
> swap.state files from each AUFS cache_dir and scanning across the rock
> cache_dir slots in MB sized chunks. Provided you are right about the
> caches being clean (having a non-corrupt swap.state journal).
>
>  ... why do you think increasing the number of workers makes them slow
> down until one hits that 10 second timeout?
>
> And consider what would happen later when your full network bandwidth
> get thrown at the workers (hint approx. 4/5 of network I/O gets written
> to disk).
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Alfrenovsky
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150209/858ffd96/attachment.htm>

From luismiguelferreirasilva at gmail.com  Tue Feb 10 03:02:21 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Mon, 9 Feb 2015 20:02:21 -0700
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <20150210023507.GA10632@mindspring.com>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54D9456C.5000808@treenet.co.nz>
 <CA+suCFhGHDFd_TUdJTvozamKB0nVc3vqnV5YRzyUnfXvLzsgUw@mail.gmail.com>
 <20150210023507.GA10632@mindspring.com>
Message-ID: <CA+suCFhZQQ16__gCJSd0fgxhoEhgS4bp0uFuY_QtHgNdzQa8JA@mail.gmail.com>

Cool, thanks for sharing!

Could you also share your icap-filter/ directory (namely,
icap-filter/html/*, icap-filter/request-filters and
icap-filter/content-filters)?

Thanks,
Luis

On Mon, Feb 9, 2015 at 7:35 PM, James Leu <jleu at mindspring.com> wrote:

> Not sure if this is usefull to anyone.  Here is a simple perl server that
> tries to implement ICAP.  YMMV (attached)
>
> On Mon, Feb 09, 2015 at 05:18:36PM -0700, Luis Miguel Silva wrote:
> > Thanks Amos.
> >
> > Well, that's exactly what I'm going to need to develop too (the plugin
> > part), I just found it weird that the C-ICAP service was still version
> > 0.3.5, even though it was really old. If it is mature, I would expect it
> to
> > get to v1.0 and cease development :o)
> >
> > So...what one would you recommend if you wanted to easily create
> > (lightweight) custom filtering capabilities?
> > I'm very inclined to adopt c-icap. Thoughts?
> >
> > Thanks,
> > Luis
> >
> > On Mon, Feb 9, 2015 at 4:40 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
> >
> > > On 10/02/2015 12:00 p.m., Luis Miguel Silva wrote:
> > > > Dear all,
> > > >
> > > > I'm looking for a light weight (opensource) ICAP server project that
> > > isn't
> > > > dead.
> > > > I need to create some custom content filters but, I'm having a hard
> time
> > > > finding an ICAP server that is being actively worked on...
> > > >
> > >
> > > The ICAP servers you are looking at are framework servers that "just"
> > > decode the on-wire protocol and pass it to a plugin module, and reverse
> > > that for the results. That is all they have to do and its quite simple,
> > > the protocol itself is 12 years old. So you wont really see huge
> amounts
> > > of ongoing change in any of them.
> > >
> > > Theres a whole other category of ICAP server, such as AV vendors. They
> > > get a lot more active turnover on their software, but are all about
> > > custom integration for the filtering activity they do rather than
> > > generic plugin engines. And again most of the code churn is in the
> > > filtering parts not the ICAP bits.
> > >
> > >
> > > > In the squid wiki <
> > > http://wiki.squid-cache.org/Features/ICAP#ICAP_Servers>,
> > > > I was able to find the following ICAP server implementations:
> > > > - C-ICAP <http://c-icap.sourceforge.net/>
> > > > -- lates release was in October 2014 (which is pretty good) but the
> > > latest
> > > > version is 0.3.5. *How stable is it?*
> > > > - Traffic Spicer <http://spicer.measurement-factory.com/>
> > > > -- Squid's docs point to this page <
> > > http://spicer.measurement-factory.com/>
> > > > but I couldn't even figure out where to download it or find any
> > > > documentation for it.
> > > > - ICAP-Server <http://icap-server.sourceforge.net/>
> > > > -- latest version for it is 1.2.1 but it is dated from October 30,
> 2002.
> > > > - POESIA <http://www.poesia-filter.org/>
> > > > -- this one points to a German page that doesn't seem to have
> anything to
> > > > do with ICAP...
> > > > - GreasySpoon <http://greasyspoon.sourceforge.net/>
> > > > -- this one seems to have been discontinued
> > > >
> > > > The most interesting one seems to be C-ICAP but I don't like that it
> > > hasn't
> > > > even reached a 1.0 version...
> > > >
> > > > What do you guys recommend I adopt?
> > > >
> > >
> > > c-icap.
> > >
> > > Though I have to disclaim a slight bias. The c-icap author is one of
> our
> > > more active Squid developers.
> > >
> > >
> > > You might also look into eCAP. The design intention is that you build
> an
> > > eCAP module which can plug into either the c-icap engine for access
> over
> > > ICAP or be loaded by Squid for faster processing directly on the HTTP
> > > traffic flow.
> > >
> > > Amos
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
> > >
>
>
> --
> James R. Leu
> jleu at mindspring.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150209/77f80dbc/attachment.htm>

From cameron at getbusi.com  Tue Feb 10 05:55:38 2015
From: cameron at getbusi.com (Cameron Charles)
Date: Tue, 10 Feb 2015 16:55:38 +1100
Subject: [squid-users] EXT_LOG not "getting passed" to http_reply_access acls
Message-ID: <CAA1s11v9oyQsrHEj33f8L9eWdsuFeJWkKexf3z6MpGEvn8isZg@mail.gmail.com>

Our setup contains a bunch of, mostly external, acls some http_access
followed by some http_reply_access, these acls use EXT_LOG frequently,
however we are having issues at the point of the last http_access and first
http_reply_access acls (both external) the EXT_LOG is "lost" at this point
and the http_reply_access acl simply gets - . i've added debugging to acls
and there are no error, they are passing out an actual EXT_LOG that is
never recieved.

Does anyone have any ideas on why this is,  how to fix it or what debug
flags in squid to activate to help find the issue?

Cameron Charles
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/1b07c599/attachment.htm>

From waldoalvarez00 at gmail.com  Tue Feb 10 06:49:55 2015
From: waldoalvarez00 at gmail.com (wac)
Date: Tue, 10 Feb 2015 01:49:55 -0500
Subject: [squid-users] testttttt
In-Reply-To: <013d01d03c1a$65401860$2fc04920$@netstream.ps>
References: <00c901d03abe$eba9b7b0$c2fd2710$@netstream.ps>
 <1422485596108-4669396.post@n4.nabble.com>
 <013d01d03c1a$65401860$2fc04920$@netstream.ps>
Message-ID: <CAMfYGUk7KvpZHta-CfBm1i4TVp2GBDs2QHKk5TmPaGy0448TyQ@mail.gmail.com>

Wellcome to nerdsland :)

On Thu, Jan 29, 2015 at 6:21 PM, Ahmad <ahmed.zaeem at netstream.ps> wrote:

> Lol .......it  seems a good joke :)
>
> Thanks for all guys @ this nice mailing list .
>
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of HackXBack
> Sent: Wednesday, January 28, 2015 2:53 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] testttttt
>
> Ping request could not find host testttttt. Please check the name and try
> again.
>
>
>
> --
> View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/testttttt-tp4669368p4669396.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/a8f4463e/attachment.htm>

From amit_info2k at yahoo.com  Tue Feb 10 06:45:33 2015
From: amit_info2k at yahoo.com (amitinfo2k)
Date: Mon, 9 Feb 2015 22:45:33 -0800 (PST)
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <54D9310D.8040809@treenet.co.nz>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz>
Message-ID: <1423550733210-4669651.post@n4.nabble.com>

thanks for the quick reply.I made the changes accordingly as follows
:---------------------------------------------------------------------------------------------....#
Set up the session helper in active mode. Mind the wrap - this is one
line:external_acl_type session ipv4 concurrency=100 ttl=3 %SRC
/usr/lib64/squid/ext_session_acl -a -T 60 -b /var/lib/squid/session/# Pass
the LOGIN command to the session helper with this ACLacl session_login
external session LOGIN# Normal session ACL as per simple exampleacl
session_is_active external session# ACL to match URLacl clicked_login_url
url_regex -i ^http://example.net/$# First check for the login URL. If
present, login sessionhttp_access allow clicked_login_url session_login# If
we get here, URL not present, so renew session or deny request.http_access
deny !session_is_active# Deny page to displaydeny_info
511:http://example.net/
session_is_active---------------------------------------------------------------------------------------------but,
after the squid restart it fails with following error
:---------------------------------------------------------------------------------------------Feb
09 22:40:31 localhost.localdomain systemd[1]: Starting Squid caching
proxy...Feb 09 22:40:31 localhost.localdomain squid[4561]: 2015/02/09
22:40:31| *FATAL: status 511 requires a template on
'511:http://example.net/'*Feb 09 22:40:31 localhost.localdomain
squid[4561]:*FATAL: Bungled /etc/squid/squid.conf line 114: deny_info
511:http://example.net/ session_is_active*Feb 09 22:40:31
localhost.localdomain systemd[1]: squid.service: control process exited,
code=exited status=1Feb 09 22:40:31 localhost.localdomain systemd[1]: Failed
to start Squid caching
proxy.---------------------------------------------------------------------------------------------



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Portal-Splash-Pages-example-on-squid-3-3-13-tp4669634p4669651.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue Feb 10 07:21:50 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 Feb 2015 13:21:50 +0600
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <54D9456C.5000808@treenet.co.nz>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54D9456C.5000808@treenet.co.nz>
Message-ID: <54D9B18E.7070805@gmail.com>


10.02.15 5:40, Amos Jeffries ?????:
> On 10/02/2015 12:00 p.m., Luis Miguel Silva wrote:
>> Dear all,
>>
>> I'm looking for a light weight (opensource) ICAP server project that isn't
>> dead.
>> I need to create some custom content filters but, I'm having a hard time
>> finding an ICAP server that is being actively worked on...
>>
> The ICAP servers you are looking at are framework servers that "just"
> decode the on-wire protocol and pass it to a plugin module, and reverse
> that for the results. That is all they have to do and its quite simple,
> the protocol itself is 12 years old. So you wont really see huge amounts
> of ongoing change in any of them.
>
> Theres a whole other category of ICAP server, such as AV vendors. They
> get a lot more active turnover on their software, but are all about
> custom integration for the filtering activity they do rather than
> generic plugin engines. And again most of the code churn is in the
> filtering parts not the ICAP bits.
>
>
>> In the squid wiki <http://wiki.squid-cache.org/Features/ICAP#ICAP_Servers>,
>> I was able to find the following ICAP server implementations:
>> - C-ICAP <http://c-icap.sourceforge.net/>
>> -- lates release was in October 2014 (which is pretty good) but the latest
>> version is 0.3.5. *How stable is it?*
Stable enougn. Used in my production over half year.
>> - Traffic Spicer <http://spicer.measurement-factory.com/>
>> -- Squid's docs point to this page <http://spicer.measurement-factory.com/>
>> but I couldn't even figure out where to download it or find any
>> documentation for it.
>> - ICAP-Server <http://icap-server.sourceforge.net/>
>> -- latest version for it is 1.2.1 but it is dated from October 30, 2002.
>> - POESIA <http://www.poesia-filter.org/>
>> -- this one points to a German page that doesn't seem to have anything to
>> do with ICAP...
>> - GreasySpoon <http://greasyspoon.sourceforge.net/>
>> -- this one seems to have been discontinued
>>
>> The most interesting one seems to be C-ICAP but I don't like that it hasn't
>> even reached a 1.0 version...
>>
>> What do you guys recommend I adopt?
>>
> c-icap.
Agreed. This project alive and software works perfectly.
>
> Though I have to disclaim a slight bias. The c-icap author is one of our
> more active Squid developers.
>
>
> You might also look into eCAP. The design intention is that you build an
> eCAP module which can plug into either the c-icap engine for access over
> ICAP or be loaded by Squid for faster processing directly on the HTTP
> traffic flow.
It uses a bit more difficult than c-icap, but very fast.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From vdoctor at neuf.fr  Tue Feb 10 07:27:29 2015
From: vdoctor at neuf.fr (Stakres)
Date: Mon, 9 Feb 2015 23:27:29 -0800 (PST)
Subject: [squid-users] Squid 2.7,
 3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster
In-Reply-To: <1422466278065-4669395.post@n4.nabble.com>
References: <1418628416193-4668707.post@n4.nabble.com>
 <1418825003303-4668738.post@n4.nabble.com>
 <1419155198462-4668803.post@n4.nabble.com>
 <1420464046420-4668929.post@n4.nabble.com> <54AA918C.10300@gmail.com>
 <1420465642362-4668933.post@n4.nabble.com> <54AA979B.7060803@gmail.com>
 <1420470567538-4668941.post@n4.nabble.com>
 <1421655817441-4669159.post@n4.nabble.com>
 <1422466278065-4669395.post@n4.nabble.com>
Message-ID: <1423553249913-4669653.post@n4.nabble.com>

 Hi All,

Advanced Caching Add-On for Linux Squid Proxy Cache v2.7, v3.4 and v3.5 with
Videos, Music, Images, Libraries and CDNs.

New  version 2.33 <https://sourceforge.net/projects/squidvideosbooster/>   -
February 8th 2015.
- New websites
More details on https://svb.unveiltech.com

Enjoy

Bye Fred




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraries-CDNs-Booster-tp4668683p4669653.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ludovit.koren at gmail.com  Tue Feb 10 07:45:36 2015
From: ludovit.koren at gmail.com (Ludovit Koren)
Date: Tue, 10 Feb 2015 08:45:36 +0100
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <mbb8e1$7l7$1@ger.gmane.org> (Markus Moeller's message of "Mon, 9
 Feb 2015 21:11:52 -0000")
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
Message-ID: <86d25i9plr.fsf@gmail.com>

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > Hi Ludovit,
    >  I haven't seen that error before either, but when you test you sould
    > have your own user credentials in the cache.  You should use kinit
    > <user>@MDPT.LOCAL and then try again the test. is the hostname
    > correctly set to squid1.mdpt.local ? If not try

    >   /usr/local/libexec/squid/negotiate_kerberos_auth_test
    > squid1.mdpt.local | awk '{sub(/Token:/,"YR"); print $0}END{print
    > "QQ"}' | /usr/local/libexec/squid/negotiate_kerberos_auth -r -s
    > GSS_C_NO_NAME


Hello,

still no progress...


# klist 
Credentials cache: FILE:/tmp/krb5cc_0
        Principal: xkoren at MDPT.LOCAL

  Issued                Expires               Principal
Feb 10 08:41:06 2015  Feb 10 18:41:06 2015  krbtgt/MDPT.LOCAL at MDPT.LOCAL
Feb 10 08:42:17 2015  Feb 10 18:41:06 2015  HTTP/squid1.mdpt.local at MDPT.LOCAL

# hostname
squid1.mdpt.local

# /usr/local/libexec/squid/negotiate_kerberos_auth_test squid1.mdpt.local | awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | /usr/local/libexec/squid/otiate_kerberos_auth -r -s HTTP/squid1.mdpt.local
BH gss_accept_sec_context() failed:  Miscellaneous failure (see text). unknown mech-code 2529639093 for mech unknown
BH quit command

# /usr/local/libexec/squid/negotiate_kerberos_auth_test squid1.mdpt.local | awk '{sub(/Token:/,"YR"); print $0}END{print "}' | /usr/local/libexec/squid/negotiate_kerberos_auth -r -s GSS_C_NO_NAME
BH gss_accept_sec_context() failed:  Miscellaneous failure (see text). unknown mech-code 2529639094 for mech unknown
BH quit command

regards,

lk


From fredbmail at free.fr  Tue Feb 10 09:19:34 2015
From: fredbmail at free.fr (FredB)
Date: Tue, 10 Feb 2015 10:19:34 +0100 (CET)
Subject: [squid-users] Squid 3.5.1 100% CPU
In-Reply-To: <1843882185.295299547.1421745793429.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1281955956.345545642.1423559974322.JavaMail.root@zimbra4-e1.priv.proxad.net>


> About Squid 3.5 wait for the moment, the 100 % CPU bug is present and
> I will make deep tests to be sure that there is nothing else.
> When this bug will be fixed and my tests (with High load) are all ok
> I will post a message here, don't worry about that.


Ok, we have worked with Amos and the bug is fixed now
Just wait the next 3.5.x release.

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From squid3 at treenet.co.nz  Tue Feb 10 10:11:45 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Feb 2015 23:11:45 +1300
Subject: [squid-users] Squid 3.5.1 100% CPU
In-Reply-To: <1281955956.345545642.1423559974322.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1281955956.345545642.1423559974322.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <54D9D961.9060809@treenet.co.nz>

On 10/02/2015 10:19 p.m., FredB wrote:
> 
>> About Squid 3.5 wait for the moment, the 100 % CPU bug is present and
>> I will make deep tests to be sure that there is nothing else.
>> When this bug will be fixed and my tests (with High load) are all ok
>> I will post a message here, don't worry about that.
> 
> 
> Ok, we have worked with Amos and the bug is fixed now
> Just wait the next 3.5.x release.
> 

Or todays 3.5 snapshot r13752 has the fixes in it.

Amos


From fredbmail at free.fr  Tue Feb 10 10:41:57 2015
From: fredbmail at free.fr (FredB)
Date: Tue, 10 Feb 2015 11:41:57 +0100 (CET)
Subject: [squid-users] Squid 3.5.1 100% CPU
In-Reply-To: <54D9D961.9060809@treenet.co.nz>
Message-ID: <451918488.345746472.1423564917393.JavaMail.root@zimbra4-e1.priv.proxad.net>


> > Just wait the next 3.5.x release.
> > 
> 
> Or todays 3.5 snapshot r13752 has the fixes in it.
> 
> Amos
> _______________________________________________


Great, I am going to be able to justify my time to my manager :)
And step away from the aspirin bottle ...

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org


From aboba0 at yahoo.com  Tue Feb 10 12:36:57 2015
From: aboba0 at yahoo.com (Alan Boba)
Date: Tue, 10 Feb 2015 12:36:57 +0000 (UTC)
Subject: [squid-users] why isn't Squid listening for tcpv4 connections?
Message-ID: <1527028881.1534704.1423571817254.JavaMail.yahoo@mail.yahoo.com>

Can't reach any web pages when browsers set to proxy with Squid.
Squid's running but doesn't appear to be listening for tcpv4 connections. This is a default install on Ubuntu 14.04 server, sudo apt-get install squid3.
Firewall is not blocking access. Here's command output showing that and apparently showing Squid not listening for tcpv4 connections.
server:~$ sudo service ufw status
ufw stop/waitingserver:~$ sudo service squid3 status
squid3 start/running, process 4048
server:~$ sudo netstat -plunt | grep squid
tcp6?????? 0????? 0 :::3128???????????????? :::*??????????????????? LISTEN????? 4048/squid3???? 
udp??????? 0????? 0 0.0.0.0:47020?????????? 0.0.0.0:*?????????????????????????? 4048/squid3???? 
udp6?????? 0????? 0 :::44475??????????????? :::*??????????????????????????????? 4048/squid3
Why is there no "tcp" line? What needs to change so there is one, and if there is one would the server be accepting connections?


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/efdd0fbf/attachment.htm>

From ajm.martinez at gmail.com  Tue Feb 10 13:30:42 2015
From: ajm.martinez at gmail.com (Alejandro Martinez)
Date: Tue, 10 Feb 2015 11:30:42 -0200
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <54D9B18E.7070805@gmail.com>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54D9456C.5000808@treenet.co.nz> <54D9B18E.7070805@gmail.com>
Message-ID: <CAFEXmxh6wu0BsnDs6MEdpmBfE9RTscJF_hQx8JTpJ4Vru_NQ6Q@mail.gmail.com>

Hi all

there is an interesting project here (https://github.com/netom/pyicap) with
some examples about implementing an Icap Server


2015-02-10 5:21 GMT-02:00 Yuri Voinov <yvoinov at gmail.com>:

>
> 10.02.15 5:40, Amos Jeffries ?????:
>
>> On 10/02/2015 12:00 p.m., Luis Miguel Silva wrote:
>>
>>> Dear all,
>>>
>>> I'm looking for a light weight (opensource) ICAP server project that
>>> isn't
>>> dead.
>>> I need to create some custom content filters but, I'm having a hard time
>>> finding an ICAP server that is being actively worked on...
>>>
>>>  The ICAP servers you are looking at are framework servers that "just"
>> decode the on-wire protocol and pass it to a plugin module, and reverse
>> that for the results. That is all they have to do and its quite simple,
>> the protocol itself is 12 years old. So you wont really see huge amounts
>> of ongoing change in any of them.
>>
>> Theres a whole other category of ICAP server, such as AV vendors. They
>> get a lot more active turnover on their software, but are all about
>> custom integration for the filtering activity they do rather than
>> generic plugin engines. And again most of the code churn is in the
>> filtering parts not the ICAP bits.
>>
>>
>>  In the squid wiki <http://wiki.squid-cache.org/
>>> Features/ICAP#ICAP_Servers>,
>>> I was able to find the following ICAP server implementations:
>>> - C-ICAP <http://c-icap.sourceforge.net/>
>>> -- lates release was in October 2014 (which is pretty good) but the
>>> latest
>>> version is 0.3.5. *How stable is it?*
>>>
>> Stable enougn. Used in my production over half year.
>
>> - Traffic Spicer <http://spicer.measurement-factory.com/>
>>> -- Squid's docs point to this page <http://spicer.measurement-
>>> factory.com/>
>>> but I couldn't even figure out where to download it or find any
>>> documentation for it.
>>> - ICAP-Server <http://icap-server.sourceforge.net/>
>>> -- latest version for it is 1.2.1 but it is dated from October 30, 2002.
>>> - POESIA <http://www.poesia-filter.org/>
>>> -- this one points to a German page that doesn't seem to have anything to
>>> do with ICAP...
>>> - GreasySpoon <http://greasyspoon.sourceforge.net/>
>>> -- this one seems to have been discontinued
>>>
>>> The most interesting one seems to be C-ICAP but I don't like that it
>>> hasn't
>>> even reached a 1.0 version...
>>>
>>> What do you guys recommend I adopt?
>>>
>>>  c-icap.
>>
> Agreed. This project alive and software works perfectly.
>
>>
>> Though I have to disclaim a slight bias. The c-icap author is one of our
>> more active Squid developers.
>>
>>
>> You might also look into eCAP. The design intention is that you build an
>> eCAP module which can plug into either the c-icap engine for access over
>> ICAP or be loaded by Squid for faster processing directly on the HTTP
>> traffic flow.
>>
> It uses a bit more difficult than c-icap, but very fast.
>
>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/330531d0/attachment.htm>

From yvoinov at gmail.com  Tue Feb 10 13:32:01 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 Feb 2015 19:32:01 +0600
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <CAFEXmxh6wu0BsnDs6MEdpmBfE9RTscJF_hQx8JTpJ4Vru_NQ6Q@mail.gmail.com>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54D9456C.5000808@treenet.co.nz> <54D9B18E.7070805@gmail.com>
 <CAFEXmxh6wu0BsnDs6MEdpmBfE9RTscJF_hQx8JTpJ4Vru_NQ6Q@mail.gmail.com>
Message-ID: <54DA0851.1050709@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Script solution is not scalable.

C-icap written on C.

10.02.15 19:30, Alejandro Martinez ?????:
> Hi all
> 
> there is an interesting project here
> (https://github.com/netom/pyicap) with some examples about
> implementing an Icap Server
> 
> 
> 2015-02-10 5:21 GMT-02:00 Yuri Voinov <yvoinov at gmail.com>:
> 
>> 
>> 10.02.15 5:40, Amos Jeffries ?????:
>> 
>>> On 10/02/2015 12:00 p.m., Luis Miguel Silva wrote:
>>> 
>>>> Dear all,
>>>> 
>>>> I'm looking for a light weight (opensource) ICAP server
>>>> project that isn't dead. I need to create some custom content
>>>> filters but, I'm having a hard time finding an ICAP server
>>>> that is being actively worked on...
>>>> 
>>>> The ICAP servers you are looking at are framework servers
>>>> that "just"
>>> decode the on-wire protocol and pass it to a plugin module, and
>>> reverse that for the results. That is all they have to do and
>>> its quite simple, the protocol itself is 12 years old. So you
>>> wont really see huge amounts of ongoing change in any of them.
>>> 
>>> Theres a whole other category of ICAP server, such as AV
>>> vendors. They get a lot more active turnover on their software,
>>> but are all about custom integration for the filtering activity
>>> they do rather than generic plugin engines. And again most of
>>> the code churn is in the filtering parts not the ICAP bits.
>>> 
>>> 
>>> In the squid wiki <http://wiki.squid-cache.org/
>>>> Features/ICAP#ICAP_Servers>, I was able to find the following
>>>> ICAP server implementations: - C-ICAP
>>>> <http://c-icap.sourceforge.net/> -- lates release was in
>>>> October 2014 (which is pretty good) but the latest version is
>>>> 0.3.5. *How stable is it?*
>>>> 
>>> Stable enougn. Used in my production over half year.
>> 
>>> - Traffic Spicer <http://spicer.measurement-factory.com/>
>>>> -- Squid's docs point to this page
>>>> <http://spicer.measurement- factory.com/> but I couldn't even
>>>> figure out where to download it or find any documentation for
>>>> it. - ICAP-Server <http://icap-server.sourceforge.net/> --
>>>> latest version for it is 1.2.1 but it is dated from October
>>>> 30, 2002. - POESIA <http://www.poesia-filter.org/> -- this
>>>> one points to a German page that doesn't seem to have
>>>> anything to do with ICAP... - GreasySpoon
>>>> <http://greasyspoon.sourceforge.net/> -- this one seems to
>>>> have been discontinued
>>>> 
>>>> The most interesting one seems to be C-ICAP but I don't like
>>>> that it hasn't even reached a 1.0 version...
>>>> 
>>>> What do you guys recommend I adopt?
>>>> 
>>>> c-icap.
>>> 
>> Agreed. This project alive and software works perfectly.
>> 
>>> 
>>> Though I have to disclaim a slight bias. The c-icap author is
>>> one of our more active Squid developers.
>>> 
>>> 
>>> You might also look into eCAP. The design intention is that you
>>> build an eCAP module which can plug into either the c-icap
>>> engine for access over ICAP or be loaded by Squid for faster
>>> processing directly on the HTTP traffic flow.
>>> 
>> It uses a bit more difficult than c-icap, but very fast.
>> 
>> 
>>> Amos _______________________________________________ 
>>> squid-users mailing list squid-users at lists.squid-cache.org 
>>> http://lists.squid-cache.org/listinfo/squid-users
>>> 
>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2ghRAAoJENNXIZxhPexGn3MIALnRZJzJ8xRohs5cM7VxI6D5
omC0GZoaFOQiBPNx1AJpoC1a1utwMAQq3DJWUdO2VyfDYgrDEUPhxBoXWn0ro41v
YgVT1MUwslGdOsy+G3ZdW03l30EPftI3NxPH64JVPxk8689kVV/IC54WIw+5P70i
GVN4D4KXgJ0bv+FVxZddkpyLPGTLdnXOEHUizZbvXl/f/Yf0pQyV03G8iIw1kaLu
cwK81lUtK2OIvF25HI18N0s3gO9LsqyDvRyoF5qrLPsz3kxUaTotK6S5/tqNyJbb
15ntXv2rjkLk5lW0gpZngcfmyZ297YkyfUOifkABJamCtGgMD5uazeeGxJ7PZJU=
=I2gC
-----END PGP SIGNATURE-----


From Richard.Aspley at hammonds-uk.com  Tue Feb 10 13:39:54 2015
From: Richard.Aspley at hammonds-uk.com (Rich549)
Date: Tue, 10 Feb 2015 05:39:54 -0800 (PST)
Subject: [squid-users] Squid 3.5.1 NTLM and LDAP
Message-ID: <1423575594700-4669661.post@n4.nabble.com>

Hi,

After running into plenty of issue with my Linux install of Squid 3.5.1 and
eventually solving those, my company has now got me to do some work for
another client that wants to use Squid. The issue with this one though is
that they will only use Windows, completely anti-Linux...

Anyway, I got a pre-compiled version of Squid 3.5.1 from here
http://squid.diladele.com/.  It has been compiled using Cygwin and works
perfectly in Server 2008 and above.  Until you want to use LDAP group
lookups.

Now, I'm getting really confused, everything seemed to be a lot simpler in
Squid 2.7 for Windows (the only reason I'm not using this is because video
buffering is slow). 

So...would someone mind having a look at my attached config and tell me
where I have gone wrong please?  My users only seem to be able to access
whitelisted sites, which leads me to believe that something is wrong with
the LDAP query for external_acl_type internet_domain_group.

A lot of the config is cannibalised from previous SquidNT 2.7 and Linux
Squid 3.5.1 configs.

example-config.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4669661/example-config.txt>  

Thanks,

Rich



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-1-NTLM-and-LDAP-tp4669661.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From sis at open.ch  Tue Feb 10 16:16:40 2015
From: sis at open.ch (=?iso-8859-1?Q?Simon_St=E4heli?=)
Date: Tue, 10 Feb 2015 17:16:40 +0100
Subject: [squid-users] benefits of
	using	ext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
Message-ID: <61AFD086-9455-4F6A-AAB7-D6FA761DB63F@open.ch>


>>>> "Amos Jeffries"  wrote in message news:54BE3B5C.8040800 at
>>>> treenet.co.nz...
>>>> 
>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>> Hash: SHA1
>>>> 
>>>> On 20/01/2015 11:31 p.m., Simon St?heli wrote:
>>>>> Are there any other benefits in using ext_kerberos_ldap_group_acl
>>>>> instead of ext_ldap_group_acl except the "Netbios name to Kerberos
>>>>> domain name? mappings provided by the -N option. As far as I can
>>>>> tell, this mapping can also easily be done by writing you own
>>>>> helper perl script which is doing the mapping and finally feeds the
>>>>> more common ext_ldap_group_acl helper.
>>>>> 
>>>> Whatever floats your boat. The point of the Addon/Plugin/helpers API
>>>> is that you can use scripts if thy serve your needs better.
>>>> 
>>>> All the usual Open Source benefits of "many eyeballs" and somebody
>>>> else doing code maintenance for you applies to using a bundled helper
>>>> over a custom written one.
>>>> 
>>>> Beyond that the kerberos helper also provides automatic detection of
>>>> which LDAP server to use via mutiple auto-configuration methods.
>>>> 
>>> The idea of the helper was to automate most of the configuration (
>>> ignoring
>>> some performance ) and avoid using a username/password, support users
>>> from
>>> multiple domains. Secondly I wanted check for nested groups which was
>>> not
>>> available in the existing helper and thirdly I also check now against
>>> the
>>> primary group of the user.
>>> 
>> Thank you Markus for your explanations. I played around with
>> ext_kerberos_ldap_group_acl and would like to go into some details:
>> 
>> 1) it is possible to define more than one LDAP server (e.g. for high
>> availability reasons)? The -l parameter allows only one ldap url while
>> -S allows several "server > realm" - mappings.
>> 
> I didn't see the need.  The -l was more for cases when digest or basic auth 
> is used and I do not know the domain to check against.  So a fallback 
> option.
My idea was to have a backup ldap / active directory server. Assumed querying _ldap._tcp.REALM returns 3 ldap servers. Are all 3 ldap servers queried successively if a previous is not reachable? And is server defined by the -l parameter being queried if all '_ldap._tcp.REALM' are not reachable?
> 
> 
>> 2) It is correct, that compared to ext_ldap_group_acl,
>> ext_kerberos_ldap_group_acl does not require a groupname as input (from
>> stdin), because -g -t -T or -D control the group name?!
>> 
> You have two options with ext_kerberos_ldap_group_acl  as input or as -g .. 
> control
Thx, very helpful.
> 
>> 3) What is the use case for defining -g GROUP@? What is the difference
>> to -g GROUP (without @)
>> 
> -g GROUP is for all users including the once with nor provided domain
Thx, this is clear now as well
> 
> The an pages describe it a bit under Note:
> 
> 1) For user at REALM
>    a) Query DNS for SRV record _ldap._tcp.REALM
>    b) Query DNS for A record REALM
>    c) Use LDAP_URL if given
> 
> 2) For user
>    a) Use domain -D REALM and follow step 1)
>    b) Use LDAP_URL if given
> 
> The Groups to check against are determined as follows:
> 
> 1) For user at REALM
>    a)  Use  values  given  by -g option which contain a @REALM e.g. -g
> GROUP1 at REALM:GROUP2 at REALM
>    b) Use values given by -g option which contain a  @  only  e.g.  -g
> GROUP1@:GROUP2@
>    c)  Use values given by -g option which do not contain a realm e.g.
> -g GROUP1:GROUP2
> 
> 2) For user
>    a) Use values given by -g option which do not contain a realm  e.g.
> -g GROUP1:GROUP2
> 
> 3) For NDOMAIN\user
>    a) Use realm given by -N NDOMAIN at REALM and then use values given by
> -g option which contain a @REALM e.g. -g GROUP1 at REALM:GROUP2 at REALM
> 
> 
> 
>> 4) The "query DNS for SRV record _ldap._tcp.REALM" mechanism seems no to
>> work for me although the DNS server is configured correctly and querying
>> with "dig SRV _ldap._tcp.REALM" works fine. Anything to consider here?
>> _ldap._tcp.REALM SRV query was never sent so far.
>> 
> I would not see an obvious reason.   Does -d show any hints ?  I can only 
> imagine that REAM is not what is send by the client.
It think I do not fully understand how the determination of the ldap server works. How is the dns query for SRV _ldap._tcp.REALM related to the missing Kerberos configuration? Why does the helper need the principal from the keytab? I am also a bit confused about the _ldap._tcp and the _kerberis._tcp queries. Can you give me an idea how this determination works step for step?
> 
>> 5) Similar issues with the Kerberos feature. Keytab und Kerberos config
>> are available and exported, but the helper only says:
>> support_ldap.cc(888): DEBUG: Setup Kerberos credential cache
>> support_ldap.cc(897): DEBUG: Kerberos is not supported. Use
>> username/password with ldap url instead
>> 
> The message support_ldap.cc(897): DEBUG: Kerberos is not supported. means 
> your Kerberos installation is not fully available. It means HAVE_KRB5 is not 
> set ( maybe header files were missing).
> 
>> Instead of that I found a dns SRV _kerberos._udp.REALM query which was
>> actually answered by the dns. I assume this is related to the Kerberos
>> feature?
> yes it is. It is a way to find the kdc.
> 
>> 6) It is possible to use the helper when DNS service is not reachable?
>> Got some error messages during testing:
>> 
>> kerberos_ldap_group: DEBUG: Canonicalise ldap server name
>> 213.156.236.111:3268
>> kerberos_ldap_group: ERROR: Error while resolving ip address with
>> getnameinfo: Temporary failure in name resolution
>> kerberos_ldap_group: DEBUG: Error during initialisation of ldap
>> connection: Success
>> 
> If you add a line to your hosts file and use the approriate nsswitch.conf it 
> should work.  You can also add a line to the hosts file for the domain for 
> the case the SRV record fails.
Thx for the hint regarding nsswitch.conf
> 
>> Beside this tiny issues the helper works excellent (tested with basic,
>> NTLM and Kerberos authentication). I am just trying to discover the
>> whole potential. Thank you very much for any responses.
>> 
>> Regards
>> Simon
>> 
> Regards
> Markus
> 
>>>> If you can demonstrate that the ext_kerberos_ldap_group_acl does
>>>> provides a superset of the functionality of ext_ldap_group_acl helper
>>>> then I can de-duplicate the two helpers.
>>>> 
>>>> Amos
>>> Regards
>>> Markus
> 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4030 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/d2723a24/attachment.bin>

From sis at open.ch  Tue Feb 10 16:33:30 2015
From: sis at open.ch (=?iso-8859-1?Q?Simon_St=E4heli?=)
Date: Tue, 10 Feb 2015 17:33:30 +0100
Subject: [squid-users] benefits of using
	ext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <mailman.41567.1423527573.1833.squid-users@lists.squid-cache.org>
References: <mailman.41567.1423527573.1833.squid-users@lists.squid-cache.org>
Message-ID: <45CAC951-F60C-4F55-9B8D-FB67B27DCCC2@open.ch>


>>>> "Amos Jeffries"  wrote in message news:54BE3B5C.8040800 at
>>>> treenet.co.nz...
>>>> 
>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>> Hash: SHA1
>>>> 
>>>> On 20/01/2015 11:31 p.m., Simon St?heli wrote:
>>>>> Are there any other benefits in using ext_kerberos_ldap_group_acl
>>>>> instead of ext_ldap_group_acl except the "Netbios name to Kerberos
>>>>> domain name? mappings provided by the -N option. As far as I can
>>>>> tell, this mapping can also easily be done by writing you own
>>>>> helper perl script which is doing the mapping and finally feeds the
>>>>> more common ext_ldap_group_acl helper.
>>>>> 
>>>> 
>>>> Whatever floats your boat. The point of the Addon/Plugin/helpers API
>>>> is that you can use scripts if thy serve your needs better.
>>>> 
>>>> All the usual Open Source benefits of "many eyeballs" and somebody
>>>> else doing code maintenance for you applies to using a bundled helper
>>>> over a custom written one.
>>>> 
>>>> Beyond that the kerberos helper also provides automatic detection of
>>>> which LDAP server to use via mutiple auto-configuration methods.
>>>> 
>>> 
>>> The idea of the helper was to automate most of the configuration (
>>> ignoring
>>> some performance ) and avoid using a username/password, support users
>>> from
>>> multiple domains. Secondly I wanted check for nested groups which was
>>> not
>>> available in the existing helper and thirdly I also check now against
>>> the
>>> primary group of the user.
>>> 
>> 
>> Thank you Markus for your explanations. I played around with
>> ext_kerberos_ldap_group_acl and would like to go into some details:
>> 
>> 1) it is possible to define more than one LDAP server (e.g. for high
>> availability reasons)? The -l parameter allows only one ldap url while
>> -S allows several "server > realm" - mappings.
>> 
> 
> I didn't see the need.  The -l was more for cases when digest or basic auth 
> is used and I do not know the domain to check against.  So a fallback 
> option.
> 
> 
>> 2) It is correct, that compared to ext_ldap_group_acl,
>> ext_kerberos_ldap_group_acl does not require a groupname as input (from
>> stdin), because -g -t -T or -D control the group name?!
>> 
> 
> You have two options with ext_kerberos_ldap_group_acl  as input or as -g .. 
> control
> 
> 
>> 3) What is the use case for defining -g GROUP@? What is the difference
>> to -g GROUP (without @)
>> 
> 
> -g GROUP is for all users including the once with nor provided domain
> 
> 
> The an pages describe it a bit under Note:
> 
> 1) For user at REALM
>   a) Query DNS for SRV record _ldap._tcp.REALM
>   b) Query DNS for A record REALM
>   c) Use LDAP_URL if given
> 
> 2) For user
>   a) Use domain -D REALM and follow step 1)
>   b) Use LDAP_URL if given
> 
> The Groups to check against are determined as follows:
> 
> 1) For user at REALM
>   a)  Use  values  given  by -g option which contain a @REALM e.g. -g
> GROUP1 at REALM:GROUP2 at REALM
>   b) Use values given by -g option which contain a  @  only  e.g.  -g
> GROUP1@:GROUP2@
>   c)  Use values given by -g option which do not contain a realm e.g.
> -g GROUP1:GROUP2
> 
> 2) For user
>   a) Use values given by -g option which do not contain a realm  e.g.
> -g GROUP1:GROUP2
> 
> 3) For NDOMAIN\user
>   a) Use realm given by -N NDOMAIN at REALM and then use values given by
> -g option which contain a @REALM e.g. -g GROUP1 at REALM:GROUP2 at REALM
> 
> 
> 
>> 4) The "query DNS for SRV record _ldap._tcp.REALM" mechanism seems no to
>> work for me although the DNS server is configured correctly and querying
>> with "dig SRV _ldap._tcp.REALM" works fine. Anything to consider here?
>> _ldap._tcp.REALM SRV query was never sent so far.
>> 
> 
> I would not see an obvious reason.   Does -d show any hints ?  I can only 
> imagine that REAM is not what is send by the client.
> 
>> 5) Similar issues with the Kerberos feature. Keytab und Kerberos config
>> are available and exported, but the helper only says:
>> support_ldap.cc(888): DEBUG: Setup Kerberos credential cache
>> support_ldap.cc(897): DEBUG: Kerberos is not supported. Use
>> username/password with ldap url instead
>> 
> 
> The message support_ldap.cc(897): DEBUG: Kerberos is not supported. means 
> your Kerberos installation is not fully available. It means HAVE_KRB5 is not 
> set ( maybe header files were missing).


Can you give me some further information about the requirements of the helper regarding kerberos? I am trying to use it with Heimdal kerberos (Heimdal 1.3.3). negotiate_kerberos_auth for example works very well with the present kerberos libraries. 


> 
>> Instead of that I found a dns SRV _kerberos._udp.REALM query which was
>> actually answered by the dns. I assume this is related to the Kerberos
>> feature?
> 
> yes it is. It is a way to find the kdc.
> 
>> 
>> 6) It is possible to use the helper when DNS service is not reachable?
>> Got some error messages during testing:
>> 
>> kerberos_ldap_group: DEBUG: Canonicalise ldap server name
>> 213.156.236.111:3268
>> kerberos_ldap_group: ERROR: Error while resolving ip address with
>> getnameinfo: Temporary failure in name resolution
>> kerberos_ldap_group: DEBUG: Error during initialisation of ldap
>> connection: Success
>> 
> 
> If you add a line to your hosts file and use the approriate nsswitch.conf it 
> should work.  You can also add a line to the hosts file for the domain for 
> the case the SRV record fails.
> 
> 
>> Beside this tiny issues the helper works excellent (tested with basic,
>> NTLM and Kerberos authentication). I am just trying to discover the
>> whole potential. Thank you very much for any responses.
>> 
>> Regards
>> Simon
>> 
> 
> Regards
> Markus
> 
>>>> If you can demonstrate that the ext_kerberos_ldap_group_acl does
>>>> provides a superset of the functionality of ext_ldap_group_acl helper
>>>> then I can de-duplicate the two helpers.
>>>> 
>>>> Amos
>>> 
>>> Regards
>>> Markus
>> 
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4030 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/f5f16b0f/attachment.bin>

From christos at chtsanti.net  Tue Feb 10 16:40:10 2015
From: christos at chtsanti.net (Christos Tsantilas)
Date: Tue, 10 Feb 2015 18:40:10 +0200
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
Message-ID: <54DA346A.9080909@chtsanti.net>

On 02/10/2015 01:00 AM, Luis Miguel Silva wrote:
>
> The most interesting one seems to be C-ICAP but I don't like that it
> hasn't even reached a 1.0 version...

If you believe that it is interesting then at least test it to see if it 
matches your needs.

The version number has to do with its goals and number of implemented 
features and not with its stability.

Regards,
    Christos

>
> What do you guys recommend I adopt?
>
> Thank you,
> Luis Silva


From luismiguelferreirasilva at gmail.com  Tue Feb 10 16:56:39 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Tue, 10 Feb 2015 09:56:39 -0700
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <54DA346A.9080909@chtsanti.net>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54DA346A.9080909@chtsanti.net>
Message-ID: <CA+suCFiMvF=2kjapQ48B-6hzU_puDgr1UNdBOtYKZQWr1fW0Rg@mail.gmail.com>

I've already installed it and took a look at it but I didn't want to waste
time evaluating "5 different solutions" so I asked you guys to learn what
was, statistically, the most popular choice :o).

How about the performance of i-icap with e-cap on top of it?
Its my understanding that squid can hook directly into e-cap (which would
eliminate the i-cap layer [in case I want to use e-cap]). On the other
hand, I would have to compile squid with e-cap support (which I would
rather not have to do)...

Thoughts?

Thanks,
Luis

On Tue, Feb 10, 2015 at 9:40 AM, Christos Tsantilas <christos at chtsanti.net>
wrote:

> On 02/10/2015 01:00 AM, Luis Miguel Silva wrote:
>
>>
>> The most interesting one seems to be C-ICAP but I don't like that it
>> hasn't even reached a 1.0 version...
>>
>
> If you believe that it is interesting then at least test it to see if it
> matches your needs.
>
> The version number has to do with its goals and number of implemented
> features and not with its stability.
>
> Regards,
>    Christos
>
>
>> What do you guys recommend I adopt?
>>
>> Thank you,
>> Luis Silva
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/442e201d/attachment.htm>

From yvoinov at gmail.com  Tue Feb 10 16:59:26 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 Feb 2015 22:59:26 +0600
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <CA+suCFiMvF=2kjapQ48B-6hzU_puDgr1UNdBOtYKZQWr1fW0Rg@mail.gmail.com>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54DA346A.9080909@chtsanti.net>
 <CA+suCFiMvF=2kjapQ48B-6hzU_puDgr1UNdBOtYKZQWr1fW0Rg@mail.gmail.com>
Message-ID: <54DA38EE.5030602@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



10.02.15 22:56, Luis Miguel Silva ?????:
> I've already installed it and took a look at it but I didn't want
> to waste time evaluating "5 different solutions" so I asked you
> guys to learn what was, statistically, the most popular choice
> :o).
C-ICAP and eCAP.

That's all.

> 
> How about the performance of i-icap with e-cap on top of it?

I see no difference.

> Its my understanding that squid can hook directly into e-cap (which
> would eliminate the i-cap layer [in case I want to use e-cap]). On
> the other hand, I would have to compile squid with e-cap support
> (which I would rather not have to do)...

This is no problem and took approx 30 minutes. With two coffee breaks. :)

> 
> Thoughts?
> 
> Thanks, Luis
> 
> On Tue, Feb 10, 2015 at 9:40 AM, Christos Tsantilas
> <christos at chtsanti.net> wrote:
> 
>> On 02/10/2015 01:00 AM, Luis Miguel Silva wrote:
>> 
>>> 
>>> The most interesting one seems to be C-ICAP but I don't like
>>> that it hasn't even reached a 1.0 version...
>>> 
>> 
>> If you believe that it is interesting then at least test it to
>> see if it matches your needs.
>> 
>> The version number has to do with its goals and number of
>> implemented features and not with its stability.
>> 
>> Regards, Christos
>> 
>> 
>>> What do you guys recommend I adopt?
>>> 
>>> Thank you, Luis Silva
>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2jjuAAoJENNXIZxhPexGL/8IAJtwFrMoCFkeoSry2lN9sUHK
o0/6r2EbY/VL6Fqt/lP9AOH9iOcEnh/XgAjSqsL6Pi+zworeVVgBIhrEzSpsALie
/5Eqjsy6yZR71MHzbkVeigNcHNlTVpB5JH9fsvmXCRJ4VT/UhI1eyuuQvwa1CFes
pV1sn105eMyoeF8btRuTLlIylbl+AY1TyySWcgtEnII0DcZwnsIRofOokV0SS6+8
GJGhnrKItk28zOJENMPB9WcetIPyggH7W6/EfNmB0l9SuEQNLCk71xGgMHH1ba+x
1aN42SSefeM2V9XXxWuy/+LkEDrsAX2ifmRcUdiopJ2RPd96g+PIE2mxeE6q82g=
=c3p5
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Tue Feb 10 17:01:26 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 Feb 2015 23:01:26 +0600
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <CA+suCFiMvF=2kjapQ48B-6hzU_puDgr1UNdBOtYKZQWr1fW0Rg@mail.gmail.com>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54DA346A.9080909@chtsanti.net>
 <CA+suCFiMvF=2kjapQ48B-6hzU_puDgr1UNdBOtYKZQWr1fW0Rg@mail.gmail.com>
Message-ID: <54DA3966.9020005@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

http://i.imgur.com/fKAUq66.png

5 c-icap processes is good enough to all office building. On squid box
you can see above.

10.02.15 22:56, Luis Miguel Silva ?????:
> I've already installed it and took a look at it but I didn't want
> to waste time evaluating "5 different solutions" so I asked you
> guys to learn what was, statistically, the most popular choice
> :o).
> 
> How about the performance of i-icap with e-cap on top of it? Its my
> understanding that squid can hook directly into e-cap (which would 
> eliminate the i-cap layer [in case I want to use e-cap]). On the
> other hand, I would have to compile squid with e-cap support (which
> I would rather not have to do)...
> 
> Thoughts?
> 
> Thanks, Luis
> 
> On Tue, Feb 10, 2015 at 9:40 AM, Christos Tsantilas
> <christos at chtsanti.net> wrote:
> 
>> On 02/10/2015 01:00 AM, Luis Miguel Silva wrote:
>> 
>>> 
>>> The most interesting one seems to be C-ICAP but I don't like
>>> that it hasn't even reached a 1.0 version...
>>> 
>> 
>> If you believe that it is interesting then at least test it to
>> see if it matches your needs.
>> 
>> The version number has to do with its goals and number of
>> implemented features and not with its stability.
>> 
>> Regards, Christos
>> 
>> 
>>> What do you guys recommend I adopt?
>>> 
>>> Thank you, Luis Silva
>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2jlmAAoJENNXIZxhPexGkN0IAMapdc/Fs5jlQTvih7JB1atT
y0s5xUCWuYk+u9K8cVFnyKOOZ7Hoe9xKTmZyisbZ5T3xsKFeqnB8TcdbFEO6T6sm
VYaRYOS47xP0Hb0Cwtt3Cw2ufB2GkbwR67yafuADfQTDyrr20knA8BMz8B5fiah/
oxg6kSM9IFrFAr5Wnom74JLnp3mDwrX7ETD0pv6bX6ZfDY6wfhyZLtMxMeA7bFHl
q+wJq3WpGsLoZ3GQ6pSECAksIl8mUd9ZAME/x6MLnHhy5OvDFEaTgVuE+NTf00f7
W3HJP/OWmBvXRkMFq0UEMoBpnUVrE4q2/YuCt9hkahrWKY7UD81Yv1tOF8idt5Q=
=coB+
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Feb 10 18:53:05 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 07:53:05 +1300
Subject: [squid-users] why isn't Squid listening for tcpv4 connections?
In-Reply-To: <1527028881.1534704.1423571817254.JavaMail.yahoo@mail.yahoo.com>
References: <1527028881.1534704.1423571817254.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54DA5391.10401@treenet.co.nz>

On 11/02/2015 1:36 a.m., Alan Boba wrote:
> Can't reach any web pages when browsers set to proxy with Squid.
> Squid's running but doesn't appear to be listening for tcpv4 connections. This is a default install on Ubuntu 14.04 server, sudo apt-get install squid3.
> Firewall is not blocking access. Here's command output showing that and apparently showing Squid not listening for tcpv4 connections.
> server:~$ sudo service ufw status
> ufw stop/waitingserver:~$ sudo service squid3 status
> squid3 start/running, process 4048
> server:~$ sudo netstat -plunt | grep squid
> tcp6       0      0 :::3128                 :::*                    LISTEN      4048/squid3     
> udp        0      0 0.0.0.0:47020           0.0.0.0:*                           4048/squid3     
> udp6       0      0 :::44475                :::*                                4048/squid3
> Why is there no "tcp" line? What needs to change so there is one, and if there is one would the server be accepting connections?
> 

Ubuntu is a dual-stack operating system. On dual-stack systems the IPv4
address space is a sub-set of IPv6 numbers. IPv6 sockets like the 3128
and 44475 shown above receive all versions of IP protocol connection.

The 47020 port is possibly a problem, its only accepting IPv4 protocol.

Amos



From ahmed.zaeem at netstream.ps  Wed Feb 11 05:41:53 2015
From: ahmed.zaeem at netstream.ps (Ahmad)
Date: Tue, 10 Feb 2015 21:41:53 -0800
Subject: [squid-users] squid access list based on sql database  ,
	is it possible ?
Message-ID: <000001d045bd$71cfe590$556fb0b0$@netstream.ps>

Hi , 

I need to do an access list that get info mysql database.

 

Can squid get info of accesslist from external db coloum ?

 

cheers

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/5fb19cd4/attachment.htm>

From yvoinov at gmail.com  Tue Feb 10 19:45:32 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 01:45:32 +0600
Subject: [squid-users] squid access list based on sql database  ,
 is it possible ?
In-Reply-To: <000001d045bd$71cfe590$556fb0b0$@netstream.ps>
References: <000001d045bd$71cfe590$556fb0b0$@netstream.ps>
Message-ID: <54DA5FDC.3090601@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

http://wiki.squid-cache.org/SquidFaq/SquidAcl#Does_Squid_support_the_use_of_a_database_such_as_mySQL_for_storing_the_ACL_list.3F

11.02.15 11:41, Ahmad ?????:
> Hi ,
> 
> I need to do an access list that get info mysql database.
> 
> 
> 
> Can squid get info of accesslist from external db coloum ?
> 
> 
> 
> cheers
> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2l/cAAoJENNXIZxhPexGbHMIAJyNxY/2OqiLOAc0yT1U1+hQ
4JfG4lbeCR8CKcXSlnC6bGIOu7paEFG2WYn79IvIInvh4j9a22Cx92kvuZB0C5zv
lm6pZjg2S8x1s9pXJXAwT+gc6WfXI4MbNk3RpgXtbPz9TtxTG8V/soBL/y1bgM3+
jkxOO4Xkcmn2d10vPb7PH3fctPocVajfFw1lqnkSGnv6EOJh6t2r4m2P4AJ9ZEQ6
lWOOlfgR04Y1x/IiKUZ1e2NpLqeggmTg9LcXu9NxJ+q8hSvpU6dSgh/ZgzctFbSE
M6BXva9YqKOF3wnOqfuHIpkNtmpBH3r0U7c4EanNGg7mbbNISau05bDw6ovdo4o=
=NN89
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Tue Feb 10 19:48:20 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 01:48:20 +0600
Subject: [squid-users] squid access list based on sql database  ,
 is it possible ?
In-Reply-To: <000001d045bd$71cfe590$556fb0b0$@netstream.ps>
References: <000001d045bd$71cfe590$556fb0b0$@netstream.ps>
Message-ID: <54DA6084.20000@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

basic_db_auth helper is included in Squid distribution.

#!/usr/bin/perl

use strict;
use Pod::Usage;
use Getopt::Long;

=pod

=head1 NAME

 basic_db_auth - Database auth helper for Squid

=head1 SYNOPSIS

 basic_db_auth [options]

=head1 DESCRIPTOIN

This program verifies username & password to a database

=head1 OPTIONS

=over 12

=item B<--debug>

Write debug info to stderr.

=item B<--dsn>

Database DSN. Default "DBI:mysql:database=squid"

=item B<--user>

Database User

=item B<--password>

Database password

=item B<--table>

Database table. Default "passwd".

=item B<--usercol>

Username column. Default "user".

=item B<--passwdcol>

Password column. Default "password".

=item B<--cond>

Condition, defaults to enabled=1. Specify 1 or "" for no condition
If you use --joomla flag, this condition will be changed to block=0

=item B<--plaintext>

Database contains plain-text passwords

=item B<--md5>

Database contains unsalted md5 passwords

=item B<--salt>

Selects the correct salt to evaluate passwords

=item B<--persist>

Keep a persistent database connection open between queries.

=item B<--joomla>

Tells helper that user database is Joomla DB.  So their unusual salt
hashing is understood.

=back

=head1 AUTHOR

This program was written by
I<Henrik Nordstrom <henrik at henriknordstrom.net>> and
I<Luis Daniel Lucio Quiroz <dlucio at okay.com.mx>>

This manual was written by I<Henrik Nordstrom
<henrik at henriknordstrom.net>>

=head1 COPYRIGHT

 * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.

Copyright (C) 2007 Henrik Nordstrom <henrik at henriknordstrom.net>
Copyright (C) 2010 Luis Daniel Lucio Quiroz <dlucio at okay.com.mx>
(Joomla support)
This program is free software. You may redistribute copies of it under the
terms of the GNU General Public License version 2, or (at youropinion) any
later version.

=head1 QUESTIONS

Questions on the usage of this program can be sent to the I<Squid
Users mailing list <squid-users at squid-cache.org>>

=head1 REPORTING BUGS

Bug reports need to be made in English.
See http://wiki.squid-cache.org/SquidFaq/BugReporting for details of
what you need to include with your bug report.

Report bugs or bug fixes using http://bugs.squid-cache.org/

Report serious security bugs to I<Squid Bugs <squid-bugs at squid-cache.org>>

Report ideas for new improvements to the I<Squid Developers mailing
list <squid-dev at squid-cache.org>>

=head1 SEE ALSO

squid (8), GPL (7),

The Squid FAQ wiki http://wiki.squid-cache.org/SquidFaq

The Squid Configuration Manual http://www.squid-cache.org/Doc/config/

=cut

use DBI;
use Digest::MD5 qw(md5 md5_hex md5_base64);

my $dsn = "DBI:mysql:database=squid";
my $db_user = undef;
my $db_passwd = undef;
my $db_table = "passwd";
my $db_usercol = "user";
my $db_passwdcol = "password";
my $db_cond = "enabled = 1";
my $plaintext = 0;
my $md5 = 0;
my $persist = 0;
my $isjoomla = 0;
my $debug = 0;
my $hashsalt = undef;

GetOptions(
	'dsn=s' => \$dsn,
	'user=s' => \$db_user,
	'password=s' => \$db_passwd,
	'table=s' => \$db_table,
	'usercol=s' => \$db_usercol,
	'passwdcol=s' => \$db_passwdcol,
	'cond=s' => \$db_cond,
	'plaintext' => \$plaintext,
	'md5' => \$md5,
	'persist' => \$persist,
	'joomla' => \$isjoomla,
	'debug' => \$debug,
	'salt=s' => \$hashsalt,
	);

my ($_dbh, $_sth);
$db_cond = "block = 0" if $isjoomla;

sub close_db()
{
    return if !defined($_dbh);
    undef $_sth;
    $_dbh->disconnect();
    undef $_dbh;
}

sub open_db()
{
    return $_sth if defined $_sth;
    $_dbh = DBI->connect($dsn, $db_user, $db_passwd);
    if (!defined $_dbh) {
    	warn ("Could not connect to $dsn\n");
	my @driver_names = DBI->available_drivers();
	my $msg = "DSN drivers apparently installed, available:\n";
	foreach my $dn (@driver_names) {
		$msg .= "\t$dn";
	}
	warn($msg."\n");
	return undef;
    }
    my $sql_query;
    $sql_query = "SELECT $db_passwdcol FROM $db_table WHERE
$db_usercol = ?" . ($db_cond ne "" ? " AND $db_cond" : "");
    $_sth = $_dbh->prepare($sql_query) || die;
    return $_sth;
}

sub check_password($$)
{
    my ($password, $key) = @_;

    if ($isjoomla){
        my $salt;
        my $key2;
        ($key2,$salt) = split (/:/, $key);
        return 1 if md5_hex($password.$salt).':'.$salt eq $key;
    }
    else{
        return 1 if defined $hashsalt && crypt($password, $hashsalt)
eq $key;
        return 1 if crypt($password, $key) eq $key;
        return 1 if $md5 && md5_hex($password) eq $key;
        return 1 if $plaintext && $password eq $key;
    }

    return 0;
}

sub query_db($) {
    my ($user) = @_;
    my ($sth) = open_db() || return undef;
    if (!$sth->execute($user)) {
	close_db();
	open_db() || return undef;
	$sth->execute($user) || return undef;;
    }
    return $sth;
}
my $status;

$|=1;
while (<>) {
    my ($user, $password) = split;
    $status = "ERR";
    $user =~ s/%(..)/pack("H*", $1)/ge;
    $password =~ s/%(..)/pack("H*", $1)/ge;

    $status = "ERR database error";
    my $sth = query_db($user) || next;
    $status = "ERR unknown login";
    my $row = $sth->fetchrow_arrayref() || next;
    $status = "ERR login failure";
    next if (!check_password($password, @$row[0]));
    $status = "OK";
} continue {
    close_db() if (!$persist);
    print $status . "\n";
}


11.02.15 11:41, Ahmad ?????:
> Hi ,
> 
> I need to do an access list that get info mysql database.
> 
> 
> 
> Can squid get info of accesslist from external db coloum ?
> 
> 
> 
> cheers
> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEbBAEBAgAGBQJU2mCEAAoJENNXIZxhPexGD5kH92xXaGjspM5QtJk2kSAUthvj
wS+NwY07A0tpSgONNB8Wi5SyweAQm3RnU9UvNcrV7Nyj8LUIdeuV3WiLafcn6bv8
fBf7+aUOVbVwkUJXe6XXPfKI4wWBtkKkKXy53s/L1F3u5aFvSMEzCFcLv4pMJSzl
zszPFHGjr+ShVZofd/ex8gXK+l1PW7YAG3b+oOwDuwmr8hHCUc4dJlNjYqbNj84+
mPhiwYz40OyRglLDIgxto1p5EVHx2eRRKjk01htsZisclOh5eISF6ds+bm1bOjqw
q4C9eXSB2ehg3sDZ90rhCuYdJXgnYI+ZQ29EsNMh6wRTZ29QPUjXjjqw8raUmQ==
=Ogyq
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Feb 10 19:56:05 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 08:56:05 +1300
Subject: [squid-users] Squid 3.5.1 NTLM and LDAP
In-Reply-To: <1423575594700-4669661.post@n4.nabble.com>
References: <1423575594700-4669661.post@n4.nabble.com>
Message-ID: <54DA6255.5070502@treenet.co.nz>

On 11/02/2015 2:39 a.m., Rich549 wrote:
> Hi,
> 
> After running into plenty of issue with my Linux install of Squid 3.5.1 and
> eventually solving those, my company has now got me to do some work for
> another client that wants to use Squid. The issue with this one though is
> that they will only use Windows, completely anti-Linux...
> 

And yet they use Squid :-P lol.


> Anyway, I got a pre-compiled version of Squid 3.5.1 from here
> http://squid.diladele.com/.  It has been compiled using Cygwin and works
> perfectly in Server 2008 and above.  Until you want to use LDAP group
> lookups.

Please keep in mind that these builds are semi-experimental at present.
Squid-3.x Cygwin builds have been available longer than others for
Windows, but the user base for Windows in total is not very big. It may
just be that nobody before you used or tested this particular helper setup.

> 
> Now, I'm getting really confused, everything seemed to be a lot simpler in
> Squid 2.7 for Windows (the only reason I'm not using this is because video
> buffering is slow). 

Are you finding 3.5 any faster on Windows?

The major bottleneck that makes Squid people avoid Windows is that they
are capped with a permanent absolute limit of 2048 sockets. At 2 sockets
per client connection (client+server or client+disk) and 8 connections
per user browser (just 'cause they do) thats a capacity of roughly
120-240 users that can be going through the proxy at any one time.

> 
> So...would someone mind having a look at my attached config and tell me
> where I have gone wrong please?  My users only seem to be able to access
> whitelisted sites, which leads me to believe that something is wrong with
> the LDAP query for external_acl_type internet_domain_group.
> 
> A lot of the config is cannibalised from previous SquidNT 2.7 and Linux
> Squid 3.5.1 configs.

Please note the message about "SquidNT" at the top of
<http://wiki.squid-cache.org/KnowledgeBase/Windows>



> http_port 3128

These ...

> acl QUERY urlpath_regex cgi-bin \?
> cache deny ALL
> acl apache rep_header Server ^Apache

... should not be needed at all in 3.5.

> cache_mem 1024 MB
> #cache_dir ufs d:/squid/var/cache/squid/ 8000 16 256
> access_log d:/squid/var/log/squid/access.log squid
> cache_log d:/squid/var/cache/squid/cache.log

These...

> cache_store_log d:/squid/var/log/store.log
> mime_table d:/Squid/etc/squid/mime.conf
> pid_filename d:/squid/var/log/squid/squid.pid
> unlinkd_program d:/squid/lib/squid/unlinkd.exe
> logfile_daemon d:/Squid/lib/squid/log_file_daemon.exe
> icon_directory d:/squid/usr/share/squid/icons

 ... to here should also not be necessary in 3.5.

> error_directory d:/squid/usr/share/squid/errors/en-uk
> coredump_dir d:/squid/var/cache/squid/
> dns_nameservers 172.30.12.9 172.31.12.10
> 
> ### New NTLM Authentication Method
> auth_param ntlm program d:/Squid/lib/squid/ntlm_fake_auth
> auth_param ntlm children 80
> auth_param ntlm keep_alive off

Note that all this helper does is check that the NTLM protocol is
syntactically accurate.

> 
> ### Helper Processes
> external_acl_type internet_domain_group %LOGIN d:/Squid/lib/squid/ext_ldap_group_acl.exe \
>    -b "ou=Domain_Groups,dc=domain-uk,dc=com" \
>    -f %v=Internet_Users -h srvham09.domain-uk.com
>

The documentation for -f option says that %u (not %v) will be replaced
with username and %g with group name.


> # ------------------------------------------------
> # ----  Declare domains for individual access ----
> # ------------------------------------------------
> 
> # Blacklisted domains
> acl BlacklistedSites dstdomain .yahoo.com .ebay.com .ebay.co.uk mail.google.com outlook.com hotmail.com hotmail.co.uk live.co.uk
> 
> # These domains will be reachable without authentication
> acl OK_Unauthenticated dstdomain .domain-uk.com .stanford.edu
> acl OK_Unauthenticated dstdomain .domainretail.local .everythingbedrooms.co.uk .canonical.com .sophos.com .ubuntu.com .oracle.com .bt.com
> acl OK_Unauthenticated dstdomain .oanda.com .dell.com .launchpad.net
> acl OK_Unauthenticated dstdomain .dashboards.my-tmac.co.uk
> 
> # ------------------------------------------------
> # ---  Map web access to AD groups via helpers ---
> # ------------------------------------------------
> 
> # Allow Members of Internet Users To Anywhere Not Explicitly Denied
> acl InetAllow external internet_domain_group Internet_Users
> 
> # Allow Store Access
> #acl StoresAllow external stores_domain_group Stores_Internet_Access
> 
> # ------------------------------------------------
> # ---------------  Misc settings -----------------
> # ------------------------------------------------
> 
> 
> # These domains wont be cached - every request will be pulled directly from the web
> acl do_not_cache dstdomain domain-uk.com youtube.com
> cache deny do_not_cache
> 
> # Append domain-uk.com to hostnames without a dot in them
> append_domain .domain-uk.com 

The above will only have any effect if you also define:

 dns_defnames on

<http://www.squid-cache.org/Doc/config/dns_defnames/>

If you need it fine, if not remove from the config.

> 
> # Allow these static IPs access to everything without authentication
> acl StaticIPWhitelist src 172.31.12.* ....
> 
> # ------------------------------------------------
> # ------ Permit/Deny access as appropriate -------
> # ------------------------------------------------
> 
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0     
> refresh_pattern ^ftp:		1440	20%	10080
> refresh_pattern ^gopher:	1440	0%	1440
> refresh_pattern .		0	20%	4320
> shutdown_lifetime 10 seconds
> acl SSL_ports port 443 563 21
> acl Safe_ports port 80		# http
> acl Safe_ports port 21  	# ftp
> acl Safe_ports port 22		# sftp
> acl Safe_ports port 443 563	# https, snews
> acl Safe_ports port 70		# gopher
> acl Safe_ports port 210		# wais
> acl Safe_ports port 1025-65535	# unregistered ports
> acl Safe_ports port 280		# http-mgmt
> acl Safe_ports port 488		# gss-http
> acl Safe_ports port 591		# filemaker
> acl Safe_ports port 777		# multiling http
> acl Safe_ports port 4004	# Radii website download site uses this port
> acl Safe_ports port 10000	# Webmin

Note that the above two ports are within the 1024-65535 range. No need
to configurethem in.

> acl Safe_ports port 900		# Swat
> acl Safe_ports port 82		# Pacejet request - test site hosted on HTTP 82
> acl Safe_ports port 81		# Image plus test server (hepplewhite)
> 
> acl CONNECT method CONNECT
> 
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> 
> #http_access deny BlacklistedSites StoresAllow

If the above were enabled any blacklisted site would get an auth popup
from the StoresAllow requiring %LOGIN. This may be part of your problem.
You need to sort out a policy logic order***.

> 
> http_access allow OK_Unauthenticated
> http_access allow StaticIPWhitelist
> 
> acl auth proxy_auth REQUIRED
> http_access deny !auth
> 
> http_access allow InetAllow
> #http_access allow StoresAllow
> 
> http_access allow localhost manager
> http_access deny all
> 

This block...
> acl ftp proto FTP
> #http_access allow ftp
> #http_access allow CONNECT Safe_ports
> http_access deny manager
> http_reply_access allow all
> icp_access allow all

.. to here can be erased in 3.5.

> cache_mgr otrs at hammonds-uk.com
> forwarded_for off



***

I recommend something like this:

  http_access deny !Safe_ports
  http_access deny CONNECT !SSL_ports

  # whitelists that dont need authenticating first
  http_access allow OK_Unauthenticated
  http_access allow StaticIPWhitelist

  # followed by auth (a blacklist against un-authenticated people)
  acl auth proxy_auth REQUIRED
  http_access deny !auth

  # blacklists applied even if they login
  http_access deny BlacklistedSites StoresAllow

  # then where authenticated users can go
  http_access allow localhost manager
  http_access allow InetAllow
  http_access allow StoresAllow
  http_access deny all



After the above changes, if you are still having issues please try
testing the group helper manually from the command line. The input it is
expecting a username followed by one space then the group name being
tested. It should return OK (user in group) ERR (user not in group) or
BH (internal error).

NOTE you are not using the -S helper option so the username part is
actually the full DOMAIN\user syntax from NTLM.

If it turns out to be not working you can also try with the -d option to
get a debug trace about what the helper is doing.


Differences since 2.7 that may be affecting the helper:
* LDAP version bumped from v2 to v3
* LDAP over TLS support added - it may or may not need using

Most importantly: Windows 7+ all use Kerberos auth by default and
Windows8+ have NTLM actually removed from the OS - it may actually be
the NTLM auth check which is failing.

HTH
Amos



From ahmed.zaeem at netstream.ps  Wed Feb 11 06:24:16 2015
From: ahmed.zaeem at netstream.ps (Ahmad)
Date: Tue, 10 Feb 2015 22:24:16 -0800
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54D94D9C.1090108@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
Message-ID: <000a01d045c3$5d5894d0$1809be70$@netstream.ps>

Thank you amos , but I have an issue with connection :
Here is my mysql info :
========
grant select on squid.* to 'squid'@'%' identified by 'squid';
=====================
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| squid              |
+--------------------+
3 rows in set (0.00 sec)

mysql> use squid
Database changed
mysql> ;
ERROR: 
No query specified

mysql> show tables;
+-----------------+
| Tables_in_squid |
+-----------------+
| passwd          |
+-----------------+
1 row in set (0.00 sec)

mysql> select from * passwd;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'from * passwd' at line 1
mysql> select * from  passwd;
+--------+----------+---------+-----------+---------------------+
| user   | password | enabled | fullname  | comment             |
+--------+----------+---------+-----------+---------------------+
| Nikesh | test     |       1 | Test User | for testing purpose |
+--------+----------+---------+-----------+---------------------+
1 row in set (0.00 sec)

mysql> show GRANTS FOR 'squid'
    -> ;
+------------------------------------------------------------------------------------------------------+
| Grants for squid@%                                                                                   |
+------------------------------------------------------------------------------------------------------+
| GRANT USAGE ON *.* TO 'squid'@'%' IDENTIFIED BY PASSWORD '*AFD42D37182BDB40880BEF624CC64B0F4A1E35B4' |
| GRANT SELECT ON `squid`.* TO 'squid'@'%'                                                             |
+------------------------------------------------------------------------------------------------------+
2 rows in set (0.00 sec)

mysql>
===========================================

now on the squid box , I do the conection below :

here is the connection from remote squid:
/lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:host=x.x189.177" --user "squid" --password "squid" --table "user" --usercol "user" --passwdcol "password" --cond "" --plaintext





DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at /lib/squid/basic_db_auth line 215, <> line 1.
DBD::mysql::st execute failed: MySQL server has gone away at /lib/squid/basic_db_auth line 218, <> line 1.
ERR database error
DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at /lib/squid/basic_db_auth line 215, <> line 2.
DBD::mysql::st execute failed: MySQL server has gone away at /lib/squid/basic_db_auth line 218, <> line 2.
ERR database error
DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at /lib/squid/basic_db_auth line 215, <> line 3.
DBD::mysql::st execute failed: MySQL server has gone away at /lib/squid/basic_db_auth line 218, <> line 3.
ERR database error
DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at /lib/squid/basic_db_auth line 215, <> line 4.
DBD::mysql::st execute failed: MySQL server has gone away at /lib/squid/basic_db_auth line 218, <> line 4.
ERR database error
^C


Selinux , iptables are down on both mahcines .


Any other things we need to look @  ??????

The question is being asked , is it suid or mysql issue??

Wt other thing need to check ?


==========
squid -v
Squid Cache: Version 3.5.1
Service Name: squid
configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=drx' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=131072' '--with-large-files' '--with-default-user=squid' '--enable-linux-netfilter' '--enable-ltdl-convenience' '--enable-ssl' '--enable-ssl-crtd' '--enable-arp-acl' 'CXXFLAGS=-DMAXTCPLISTENPORTS=20000' '--with-openssl' '--enable-snmp'
[root at squid ~]#
==================================

Thanks again for help
-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, February 9, 2015 4:15 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid authentication to remote sql server

On 10/02/2015 5:01 p.m., Ahmad wrote:
> Hi ,
> 
> I followed the article in  :
> 
> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Mysql
> 
>  
> 
>  
> 
> I need to connect  squid to external sql server  , what do I need to 
> modify in the helper command ?
> 
>  
> 
> I think that the command below :
> 
> ""auth_param basic program /usr/local/squid/libexec/squid_db_auth 
> --user someuser --password xxxx --plaintext --persist
> 
>  
> 
> Shoud include the ip  & port of the sql server .
> 

The Data Source Name (--dsn) parameter is the option string passed to the Perl DBI module for locating the database to use.

It takes the syntax:

  "DSN:" driver ":" params

The params bit depends on what database driver (type) is. The "mysql"
driver uses semi-colon separated key=value pairs.

So you can write something like:

  --dsn "DSN:mysql:host=example.com;port=3306;database=squid"


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ahmed.zaeem at netstream.ps  Wed Feb 11 06:24:48 2015
From: ahmed.zaeem at netstream.ps (Ahmad)
Date: Tue, 10 Feb 2015 22:24:48 -0800
Subject: [squid-users] squid access list based on sql database  ,
	is it possible ?
In-Reply-To: <54DA6084.20000@gmail.com>
References: <000001d045bd$71cfe590$556fb0b0$@netstream.ps>
 <54DA6084.20000@gmail.com>
Message-ID: <000b01d045c3$70490fc0$50db2f40$@netstream.ps>

Thank you , can you  show me a directive with that as an example plz ?


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Tuesday, February 10, 2015 11:48 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid access list based on sql database , is it possible ?

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

basic_db_auth helper is included in Squid distribution.

#!/usr/bin/perl

use strict;
use Pod::Usage;
use Getopt::Long;

=pod

=head1 NAME

 basic_db_auth - Database auth helper for Squid

=head1 SYNOPSIS

 basic_db_auth [options]

=head1 DESCRIPTOIN

This program verifies username & password to a database

=head1 OPTIONS

=over 12

=item B<--debug>

Write debug info to stderr.

=item B<--dsn>

Database DSN. Default "DBI:mysql:database=squid"

=item B<--user>

Database User

=item B<--password>

Database password

=item B<--table>

Database table. Default "passwd".

=item B<--usercol>

Username column. Default "user".

=item B<--passwdcol>

Password column. Default "password".

=item B<--cond>

Condition, defaults to enabled=1. Specify 1 or "" for no condition If you use --joomla flag, this condition will be changed to block=0

=item B<--plaintext>

Database contains plain-text passwords

=item B<--md5>

Database contains unsalted md5 passwords

=item B<--salt>

Selects the correct salt to evaluate passwords

=item B<--persist>

Keep a persistent database connection open between queries.

=item B<--joomla>

Tells helper that user database is Joomla DB.  So their unusual salt hashing is understood.

=back

=head1 AUTHOR

This program was written by
I<Henrik Nordstrom <henrik at henriknordstrom.net>> and I<Luis Daniel Lucio Quiroz <dlucio at okay.com.mx>>

This manual was written by I<Henrik Nordstrom <henrik at henriknordstrom.net>>

=head1 COPYRIGHT

 * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.

Copyright (C) 2007 Henrik Nordstrom <henrik at henriknordstrom.net> Copyright (C) 2010 Luis Daniel Lucio Quiroz <dlucio at okay.com.mx> (Joomla support) This program is free software. You may redistribute copies of it under the terms of the GNU General Public License version 2, or (at youropinion) any later version.

=head1 QUESTIONS

Questions on the usage of this program can be sent to the I<Squid Users mailing list <squid-users at squid-cache.org>>

=head1 REPORTING BUGS

Bug reports need to be made in English.
See http://wiki.squid-cache.org/SquidFaq/BugReporting for details of what you need to include with your bug report.

Report bugs or bug fixes using http://bugs.squid-cache.org/

Report serious security bugs to I<Squid Bugs <squid-bugs at squid-cache.org>>

Report ideas for new improvements to the I<Squid Developers mailing list <squid-dev at squid-cache.org>>

=head1 SEE ALSO

squid (8), GPL (7),

The Squid FAQ wiki http://wiki.squid-cache.org/SquidFaq

The Squid Configuration Manual http://www.squid-cache.org/Doc/config/

=cut

use DBI;
use Digest::MD5 qw(md5 md5_hex md5_base64);

my $dsn = "DBI:mysql:database=squid";
my $db_user = undef;
my $db_passwd = undef;
my $db_table = "passwd";
my $db_usercol = "user";
my $db_passwdcol = "password";
my $db_cond = "enabled = 1";
my $plaintext = 0;
my $md5 = 0;
my $persist = 0;
my $isjoomla = 0;
my $debug = 0;
my $hashsalt = undef;

GetOptions(
	'dsn=s' => \$dsn,
	'user=s' => \$db_user,
	'password=s' => \$db_passwd,
	'table=s' => \$db_table,
	'usercol=s' => \$db_usercol,
	'passwdcol=s' => \$db_passwdcol,
	'cond=s' => \$db_cond,
	'plaintext' => \$plaintext,
	'md5' => \$md5,
	'persist' => \$persist,
	'joomla' => \$isjoomla,
	'debug' => \$debug,
	'salt=s' => \$hashsalt,
	);

my ($_dbh, $_sth);
$db_cond = "block = 0" if $isjoomla;

sub close_db()
{
    return if !defined($_dbh);
    undef $_sth;
    $_dbh->disconnect();
    undef $_dbh;
}

sub open_db()
{
    return $_sth if defined $_sth;
    $_dbh = DBI->connect($dsn, $db_user, $db_passwd);
    if (!defined $_dbh) {
    	warn ("Could not connect to $dsn\n");
	my @driver_names = DBI->available_drivers();
	my $msg = "DSN drivers apparently installed, available:\n";
	foreach my $dn (@driver_names) {
		$msg .= "\t$dn";
	}
	warn($msg."\n");
	return undef;
    }
    my $sql_query;
    $sql_query = "SELECT $db_passwdcol FROM $db_table WHERE $db_usercol = ?" . ($db_cond ne "" ? " AND $db_cond" : "");
    $_sth = $_dbh->prepare($sql_query) || die;
    return $_sth;
}

sub check_password($$)
{
    my ($password, $key) = @_;

    if ($isjoomla){
        my $salt;
        my $key2;
        ($key2,$salt) = split (/:/, $key);
        return 1 if md5_hex($password.$salt).':'.$salt eq $key;
    }
    else{
        return 1 if defined $hashsalt && crypt($password, $hashsalt) eq $key;
        return 1 if crypt($password, $key) eq $key;
        return 1 if $md5 && md5_hex($password) eq $key;
        return 1 if $plaintext && $password eq $key;
    }

    return 0;
}

sub query_db($) {
    my ($user) = @_;
    my ($sth) = open_db() || return undef;
    if (!$sth->execute($user)) {
	close_db();
	open_db() || return undef;
	$sth->execute($user) || return undef;;
    }
    return $sth;
}
my $status;

$|=1;
while (<>) {
    my ($user, $password) = split;
    $status = "ERR";
    $user =~ s/%(..)/pack("H*", $1)/ge;
    $password =~ s/%(..)/pack("H*", $1)/ge;

    $status = "ERR database error";
    my $sth = query_db($user) || next;
    $status = "ERR unknown login";
    my $row = $sth->fetchrow_arrayref() || next;
    $status = "ERR login failure";
    next if (!check_password($password, @$row[0]));
    $status = "OK";
} continue {
    close_db() if (!$persist);
    print $status . "\n";
}


11.02.15 11:41, Ahmad ?????:
> Hi ,
> 
> I need to do an access list that get info mysql database.
> 
> 
> 
> Can squid get info of accesslist from external db coloum ?
> 
> 
> 
> cheers
> 
> 
> 
> 
> _______________________________________________ squid-users mailing 
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEbBAEBAgAGBQJU2mCEAAoJENNXIZxhPexGD5kH92xXaGjspM5QtJk2kSAUthvj
wS+NwY07A0tpSgONNB8Wi5SyweAQm3RnU9UvNcrV7Nyj8LUIdeuV3WiLafcn6bv8
fBf7+aUOVbVwkUJXe6XXPfKI4wWBtkKkKXy53s/L1F3u5aFvSMEzCFcLv4pMJSzl
zszPFHGjr+ShVZofd/ex8gXK+l1PW7YAG3b+oOwDuwmr8hHCUc4dJlNjYqbNj84+
mPhiwYz40OyRglLDIgxto1p5EVHx2eRRKjk01htsZisclOh5eISF6ds+bm1bOjqw
q4C9eXSB2ehg3sDZ90rhCuYdJXgnYI+ZQ29EsNMh6wRTZ29QPUjXjjqw8raUmQ==
=Ogyq
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Tue Feb 10 20:29:13 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 02:29:13 +0600
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
Message-ID: <54DA6A19.9020607@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



11.02.15 12:24, Ahmad ?????:
> Thank you amos , but I have an issue with connection : Here is my
> mysql info : ======== grant select on squid.* to 'squid'@'%'
> identified by 'squid'; ===================== mysql> show
> databases; +--------------------+ | Database           | 
> +--------------------+ | information_schema | | mysql
> | | squid              | +--------------------+ 3 rows in set (0.00
> sec)
> 
> mysql> use squid Database changed mysql> ; ERROR: No query
> specified
> 
> mysql> show tables; +-----------------+ | Tables_in_squid | 
> +-----------------+ | passwd          | +-----------------+ 1 row
> in set (0.00 sec)
> 
> mysql> select from * passwd; ERROR 1064 (42000): You have an error
> in your SQL syntax; check the manual that corresponds to your MySQL
> server version for the right syntax to use near 'from * passwd' at
> line 1 mysql> select * from  passwd; 
> +--------+----------+---------+-----------+---------------------+ |
> user   | password | enabled | fullname  | comment             | 
> +--------+----------+---------+-----------+---------------------+ |
> Nikesh | test     |       1 | Test User | for testing purpose | 
> +--------+----------+---------+-----------+---------------------+ 1
> row in set (0.00 sec)
> 
> mysql> show GRANTS FOR 'squid' -> ; 
> +------------------------------------------------------------------------------------------------------+
>
> 
| Grants for squid@%
                               |
> +------------------------------------------------------------------------------------------------------+
>
> 
| GRANT USAGE ON *.* TO 'squid'@'%' IDENTIFIED BY PASSWORD
'*AFD42D37182BDB40880BEF624CC64B0F4A1E35B4' |
> | GRANT SELECT ON `squid`.* TO 'squid'@'%'
> | 
> +------------------------------------------------------------------------------------------------------+
>
> 
2 rows in set (0.00 sec)
> 
> mysql> ===========================================
> 
> now on the squid box , I do the conection below :
> 
> here is the connection from remote squid: /lib/squid/basic_db_auth
> --dsn "DBI:mysql:database=squid:host=x.x189.177" --user "squid"
> --password "squid" --table "user" --usercol "user" --passwdcol
> "password" --cond "" --plaintext
> 
> 
> 
> 
> 
> DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at
> /lib/squid/basic_db_auth line 215, <> line 1. DBD::mysql::st
> execute failed: MySQL server has gone away at
> /lib/squid/basic_db_auth line 218, <> line 1. ERR database error 
> DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at
> /lib/squid/basic_db_auth line 215, <> line 2. DBD::mysql::st
> execute failed: MySQL server has gone away at
> /lib/squid/basic_db_auth line 218, <> line 2. ERR database error 
> DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at
> /lib/squid/basic_db_auth line 215, <> line 3. DBD::mysql::st
> execute failed: MySQL server has gone away at
> /lib/squid/basic_db_auth line 218, <> line 3. ERR database error 
> DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at
> /lib/squid/basic_db_auth line 215, <> line 4. DBD::mysql::st
> execute failed: MySQL server has gone away at
> /lib/squid/basic_db_auth line 218, <> line 4. ERR database error 
> ^C
> 
> 
> Selinux , iptables are down on both mahcines .
> 
> 
> Any other things we need to look @  ??????
> 
> The question is being asked , is it suid or mysql issue??

This is database issue. Your user have not object provolege to access
table. This is default database behavoiur. the principle of least
privilege.

> 
> Wt other thing need to check ?
> 
I think, MySQL manuals. :)

> 
> ========== squid -v Squid Cache: Version 3.5.1 Service Name: squid 
> configure options:  '--prefix=/usr' '--includedir=/include'
> '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc'
> '--enable-cachemgr-hostname=drx' '--localstatedir=/var'
> '--libexecdir=/lib/squid' '--disable-maintainer-mode'
> '--disable-dependency-tracking' '--disable-silent-rules'
> '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
> '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8'
> '--enable-storeio=ufs,aufs,diskd,rock'
> '--enable-removal-policies=lru,heap' '--enable-delay-pools'
> '--enable-cache-digests' '--enable-underscores'
> '--enable-icap-client' '--enable-follow-x-forwarded-for'
> '--enable-auth'
> '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM'
> '--enable-ntlm-auth-helpers=smb_lm'
> '--enable-digest-auth-helpers=ldap,password'
> '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi'
> '--disable-translation' '--with-logdir=/var/log/squid'
> '--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=131072'
> '--with-large-files' '--with-default-user=squid'
> '--enable-linux-netfilter' '--enable-ltdl-convenience'
> '--enable-ssl' '--enable-ssl-crtd' '--enable-arp-acl'
> 'CXXFLAGS=-DMAXTCPLISTENPORTS=20000' '--with-openssl'
> '--enable-snmp' [root at squid ~]# ==================================
> 
> Thanks again for help -----Original Message----- From: squid-users
> [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of
> Amos Jeffries Sent: Monday, February 9, 2015 4:15 PM To:
> squid-users at lists.squid-cache.org Subject: Re: [squid-users] squid
> authentication to remote sql server
> 
> On 10/02/2015 5:01 p.m., Ahmad wrote:
>> Hi ,
>> 
>> I followed the article in  :
>> 
>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Mysql
>> 
>> 
>> 
>> 
>> 
>> I need to connect  squid to external sql server  , what do I need
>> to modify in the helper command ?
>> 
>> 
>> 
>> I think that the command below :
>> 
>> ""auth_param basic program /usr/local/squid/libexec/squid_db_auth
>>  --user someuser --password xxxx --plaintext --persist
>> 
>> 
>> 
>> Shoud include the ip  & port of the sql server .
>> 
> 
> The Data Source Name (--dsn) parameter is the option string passed
> to the Perl DBI module for locating the database to use.
> 
> It takes the syntax:
> 
> "DSN:" driver ":" params
> 
> The params bit depends on what database driver (type) is. The
> "mysql" driver uses semi-colon separated key=value pairs.
> 
> So you can write something like:
> 
> --dsn "DSN:mysql:host=example.com;port=3306;database=squid"
> 
> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2moZAAoJENNXIZxhPexGBNYH/2vArGMG2/iepXT3FV29ZqAK
XsBd8Cn+FzssnlmGiwp6yfNurMJVxu1DlAtRC8HOvduoI4IwfF1E4L/cFhfFw+Zr
uTyVwb1nzZ/yFrErjU2XEE0Va4pGtskAKWgSXnOSo1cJ9af+IltLtWZGbv1RO6yO
4mvCosjJX4TosFVO/bi4xIssqz+4+Yn249HXzey8DA/kiIkUF7TMi09ttwp6yW1w
YxTu5MAy7gNNpbCwgBaosLl+1JpJt+r7/Omdv8ojNJ838TtR/iDDu6TAlf6PEVud
/Y002/uo2QrOp7jfc9nkbhsBXXWKUzCCKKVf0wEgJLs6c/wDikSfgI+55AaZ3Fg=
=cJ4m
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Feb 10 20:32:00 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 09:32:00 +1300
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
Message-ID: <54DA6AC0.2080801@treenet.co.nz>

On 11/02/2015 7:24 p.m., Ahmad wrote:
> Thank you amos , but I have an issue with connection :
> Here is my mysql info :
> ========
> grant select on squid.* to 'squid'@'%' identified by 'squid';
> =====================
> mysql> show databases;
> +--------------------+
> | Database           |
> +--------------------+
> | information_schema |
> | mysql              |
> | squid              |
> +--------------------+
> 3 rows in set (0.00 sec)
> 
> mysql> use squid
> Database changed
> mysql> ;
> ERROR: 
> No query specified
> 
> mysql> show tables;
> +-----------------+
> | Tables_in_squid |
> +-----------------+
> | passwd          |
> +-----------------+
> 1 row in set (0.00 sec)
> 
> mysql> select from * passwd;
> ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'from * passwd' at line 1
> mysql> select * from  passwd;
> +--------+----------+---------+-----------+---------------------+
> | user   | password | enabled | fullname  | comment             |
> +--------+----------+---------+-----------+---------------------+
> | Nikesh | test     |       1 | Test User | for testing purpose |
> +--------+----------+---------+-----------+---------------------+
> 1 row in set (0.00 sec)
> 
<snip>

> mysql>
> ===========================================
> 
> now on the squid box , I do the conection below :
> 
> here is the connection from remote squid:
> /lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:host=x.x189.177"

No *semi-colons* in the driver parameters bit.

 --dsn "DBI:mysql:host=x.x189.177;port=3306;database=squid"


NP: I also like to order them by significance just in case they are
processed in-order.

Amos


From yvoinov at gmail.com  Tue Feb 10 20:33:32 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 02:33:32 +0600
Subject: [squid-users] squid access list based on sql database  ,
 is it possible ?
In-Reply-To: <000b01d045c3$70490fc0$50db2f40$@netstream.ps>
References: <000001d045bd$71cfe590$556fb0b0$@netstream.ps>
 <54DA6084.20000@gmail.com> <000b01d045c3$70490fc0$50db2f40$@netstream.ps>
Message-ID: <54DA6B1C.5080501@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I don't use database with ACL's. But I can make the assumption that it
is necessary to dig in the direction of the database adapter Perl.

11.02.15 12:24, Ahmad ?????:
> Thank you , can you  show me a directive with that as an example
> plz ?
> 
> 
> -----Original Message----- From: squid-users
> [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of
> Yuri Voinov Sent: Tuesday, February 10, 2015 11:48 AM To:
> squid-users at lists.squid-cache.org Subject: Re: [squid-users] squid
> access list based on sql database , is it possible ?
> 
> basic_db_auth helper is included in Squid distribution.
> 
> #!/usr/bin/perl
> 
> use strict; use Pod::Usage; use Getopt::Long;
> 
> =pod
> 
> =head1 NAME
> 
> basic_db_auth - Database auth helper for Squid
> 
> =head1 SYNOPSIS
> 
> basic_db_auth [options]
> 
> =head1 DESCRIPTOIN
> 
> This program verifies username & password to a database
> 
> =head1 OPTIONS
> 
> =over 12
> 
> =item B<--debug>
> 
> Write debug info to stderr.
> 
> =item B<--dsn>
> 
> Database DSN. Default "DBI:mysql:database=squid"
> 
> =item B<--user>
> 
> Database User
> 
> =item B<--password>
> 
> Database password
> 
> =item B<--table>
> 
> Database table. Default "passwd".
> 
> =item B<--usercol>
> 
> Username column. Default "user".
> 
> =item B<--passwdcol>
> 
> Password column. Default "password".
> 
> =item B<--cond>
> 
> Condition, defaults to enabled=1. Specify 1 or "" for no condition
> If you use --joomla flag, this condition will be changed to
> block=0
> 
> =item B<--plaintext>
> 
> Database contains plain-text passwords
> 
> =item B<--md5>
> 
> Database contains unsalted md5 passwords
> 
> =item B<--salt>
> 
> Selects the correct salt to evaluate passwords
> 
> =item B<--persist>
> 
> Keep a persistent database connection open between queries.
> 
> =item B<--joomla>
> 
> Tells helper that user database is Joomla DB.  So their unusual
> salt hashing is understood.
> 
> =back
> 
> =head1 AUTHOR
> 
> This program was written by I<Henrik Nordstrom
> <henrik at henriknordstrom.net>> and I<Luis Daniel Lucio Quiroz
> <dlucio at okay.com.mx>>
> 
> This manual was written by I<Henrik Nordstrom
> <henrik at henriknordstrom.net>>
> 
> =head1 COPYRIGHT
> 
> * Copyright (C) 1996-2015 The Squid Software Foundation and
> contributors * * Squid software is distributed under GPLv2+ license
> and includes * contributions from numerous individuals and
> organizations. * Please see the COPYING and CONTRIBUTORS files for
> details.
> 
> Copyright (C) 2007 Henrik Nordstrom <henrik at henriknordstrom.net>
> Copyright (C) 2010 Luis Daniel Lucio Quiroz <dlucio at okay.com.mx>
> (Joomla support) This program is free software. You may
> redistribute copies of it under the terms of the GNU General Public
> License version 2, or (at youropinion) any later version.
> 
> =head1 QUESTIONS
> 
> Questions on the usage of this program can be sent to the I<Squid
> Users mailing list <squid-users at squid-cache.org>>
> 
> =head1 REPORTING BUGS
> 
> Bug reports need to be made in English. See
> http://wiki.squid-cache.org/SquidFaq/BugReporting for details of
> what you need to include with your bug report.
> 
> Report bugs or bug fixes using http://bugs.squid-cache.org/
> 
> Report serious security bugs to I<Squid Bugs
> <squid-bugs at squid-cache.org>>
> 
> Report ideas for new improvements to the I<Squid Developers mailing
> list <squid-dev at squid-cache.org>>
> 
> =head1 SEE ALSO
> 
> squid (8), GPL (7),
> 
> The Squid FAQ wiki http://wiki.squid-cache.org/SquidFaq
> 
> The Squid Configuration Manual
> http://www.squid-cache.org/Doc/config/
> 
> =cut
> 
> use DBI; use Digest::MD5 qw(md5 md5_hex md5_base64);
> 
> my $dsn = "DBI:mysql:database=squid"; my $db_user = undef; my
> $db_passwd = undef; my $db_table = "passwd"; my $db_usercol =
> "user"; my $db_passwdcol = "password"; my $db_cond = "enabled =
> 1"; my $plaintext = 0; my $md5 = 0; my $persist = 0; my $isjoomla =
> 0; my $debug = 0; my $hashsalt = undef;
> 
> GetOptions( 'dsn=s' => \$dsn, 'user=s' => \$db_user, 'password=s'
> => \$db_passwd, 'table=s' => \$db_table, 'usercol=s' =>
> \$db_usercol, 'passwdcol=s' => \$db_passwdcol, 'cond=s' =>
> \$db_cond, 'plaintext' => \$plaintext, 'md5' => \$md5, 'persist' =>
> \$persist, 'joomla' => \$isjoomla, 'debug' => \$debug, 'salt=s' =>
> \$hashsalt, );
> 
> my ($_dbh, $_sth); $db_cond = "block = 0" if $isjoomla;
> 
> sub close_db() { return if !defined($_dbh); undef $_sth; 
> $_dbh->disconnect(); undef $_dbh; }
> 
> sub open_db() { return $_sth if defined $_sth; $_dbh =
> DBI->connect($dsn, $db_user, $db_passwd); if (!defined $_dbh) { 
> warn ("Could not connect to $dsn\n"); my @driver_names =
> DBI->available_drivers(); my $msg = "DSN drivers apparently
> installed, available:\n"; foreach my $dn (@driver_names) { $msg .=
> "\t$dn"; } warn($msg."\n"); return undef; } my $sql_query; 
> $sql_query = "SELECT $db_passwdcol FROM $db_table WHERE $db_usercol
> = ?" . ($db_cond ne "" ? " AND $db_cond" : ""); $_sth =
> $_dbh->prepare($sql_query) || die; return $_sth; }
> 
> sub check_password($$) { my ($password, $key) = @_;
> 
> if ($isjoomla){ my $salt; my $key2; ($key2,$salt) = split (/:/,
> $key); return 1 if md5_hex($password.$salt).':'.$salt eq $key; } 
> else{ return 1 if defined $hashsalt && crypt($password, $hashsalt)
> eq $key; return 1 if crypt($password, $key) eq $key; return 1 if
> $md5 && md5_hex($password) eq $key; return 1 if $plaintext &&
> $password eq $key; }
> 
> return 0; }
> 
> sub query_db($) { my ($user) = @_; my ($sth) = open_db() || return
> undef; if (!$sth->execute($user)) { close_db(); open_db() || return
> undef; $sth->execute($user) || return undef;; } return $sth; } my
> $status;
> 
> $|=1; while (<>) { my ($user, $password) = split; $status = "ERR"; 
> $user =~ s/%(..)/pack("H*", $1)/ge; $password =~ s/%(..)/pack("H*",
> $1)/ge;
> 
> $status = "ERR database error"; my $sth = query_db($user) || next; 
> $status = "ERR unknown login"; my $row = $sth->fetchrow_arrayref()
> || next; $status = "ERR login failure"; next if
> (!check_password($password, @$row[0])); $status = "OK"; } continue
> { close_db() if (!$persist); print $status . "\n"; }
> 
> 
> 11.02.15 11:41, Ahmad ?????:
>> Hi ,
> 
>> I need to do an access list that get info mysql database.
> 
> 
> 
>> Can squid get info of accesslist from external db coloum ?
> 
> 
> 
>> cheers
> 
> 
> 
> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2mscAAoJENNXIZxhPexGduIIAK3qmZ+zjTgGxv6nhfQ3TsJp
pi5ed8H9vWTZFlC7HewHYWEImaoPc0Slzr+R6fJfEYvPLXKaJtYHbEDuTNjEUCI/
et72oe/YexYWJb52ztU7CsacW1TeUdcTGRsXIIOmAFmgDJEPX+dP8oqDHS4/pIzM
Agn+1dk3X4E7XA7zEEH4rQSZ3T5mMKSTZfqDThoYOFCNdvA0Mw3Qz9r7IhRkpG2+
9hkDa8ou5C5ezWhd5K73bdBBaKhpe23JN2pAaYDvWSIYHwQYyWBo+VGrlWtm7E7V
de6UMQ1G1VWNdA0dbGtUx8DOvwfu47TFaqLCPW8rcDS0IzYbtFes5gpmiXTM3k4=
=fPlO
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Tue Feb 10 20:35:14 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 02:35:14 +0600
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DA6AC0.2080801@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6AC0.2080801@treenet.co.nz>
Message-ID: <54DA6B82.60007@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Wow, it just cannot connect with DB?!

11.02.15 2:32, Amos Jeffries ?????:
> On 11/02/2015 7:24 p.m., Ahmad wrote:
>> Thank you amos , but I have an issue with connection : Here is my
>> mysql info : ======== grant select on squid.* to 'squid'@'%'
>> identified by 'squid'; ===================== mysql> show
>> databases; +--------------------+ | Database           | 
>> +--------------------+ | information_schema | | mysql
>> | | squid              | +--------------------+ 3 rows in set
>> (0.00 sec)
>> 
>> mysql> use squid Database changed mysql> ; ERROR: No query
>> specified
>> 
>> mysql> show tables; +-----------------+ | Tables_in_squid | 
>> +-----------------+ | passwd          | +-----------------+ 1 row
>> in set (0.00 sec)
>> 
>> mysql> select from * passwd; ERROR 1064 (42000): You have an
>> error in your SQL syntax; check the manual that corresponds to
>> your MySQL server version for the right syntax to use near 'from
>> * passwd' at line 1 mysql> select * from  passwd; 
>> +--------+----------+---------+-----------+---------------------+
>>
>> 
| user   | password | enabled | fullname  | comment             |
>> +--------+----------+---------+-----------+---------------------+
>>
>> 
| Nikesh | test     |       1 | Test User | for testing purpose |
>> +--------+----------+---------+-----------+---------------------+
>>
>> 
1 row in set (0.00 sec)
>> 
> <snip>
> 
>> mysql> ===========================================
>> 
>> now on the squid box , I do the conection below :
>> 
>> here is the connection from remote squid: 
>> /lib/squid/basic_db_auth --dsn
>> "DBI:mysql:database=squid:host=x.x189.177"
> 
> No *semi-colons* in the driver parameters bit.
> 
> --dsn "DBI:mysql:host=x.x189.177;port=3306;database=squid"
> 
> 
> NP: I also like to order them by significance just in case they
> are processed in-order.
> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2muCAAoJENNXIZxhPexGwVUH/3GLWgF+hvm2EKIFI5FN/GI0
tPf7+GmRn+/5Aq3qVJxPUll363Q5jxw8eCRG17Z1W/oqsncjZW3VNYbBUwtCLazj
5MsRaMYkQdhmgLhkRCH2uTiOKfeen76BySrhYm6lb09A9be40JbMwhpVwBAyREdj
Dx7u4LFdgUyEWPTOLXxZmZ+3vaO1egidxhf55+yUOXKyuUVFqlSc3bVRiIqUaPq8
qCxSwVDJrUcXB5UOLSttugftTh3zmm/HVg9JDC6G6N2CL6vm8jmCntIKvO5YcQrH
eIcjbnSlFbuvOPe1kOMyP+zqgciCscGdv9XKVUySDILdrWEKs+aazJ9HSQVvBIY=
=Hz+L
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Feb 10 20:42:16 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 09:42:16 +1300
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
Message-ID: <54DA6D28.9010806@treenet.co.nz>

Replying again because I missed the --table parameter value earlier.


On 11/02/2015 7:24 p.m., Ahmad wrote:
> Thank you amos , but I have an issue with connection :


> mysql> select * from  passwd;


===> notice the TABLE NAME.

> +--------+----------+---------+-----------+---------------------+
> | user   | password | enabled | fullname  | comment             |
> +--------+----------+---------+-----------+---------------------+
> | Nikesh | test     |       1 | Test User | for testing purpose |
> +--------+----------+---------+-----------+---------------------+
> 1 row in set (0.00 sec)
> 

> 
> now on the squid box , I do the conection below :
> 
> here is the connection from remote squid:
> /lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:host=x.x189.177" \

blah. blah about semi-colons from both of my earlier posts..


> --user "squid" --password "squid" --table "user"

==>  notice the TABLE NAME

> --usercol "user" --passwdcol "password" 


> --cond "" --plaintext
> 

You have an "enabled" column in the table for disabling peoples
accounts. The default --cond is fine.

> 
> DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at /lib/squid/basic_db_auth line 215, <> line 1.
> DBD::mysql::st execute failed: MySQL server has gone away at /lib/squid/basic_db_auth line 218, <> line 1.
> ERR database error

Because TABLE NAME.

Amos


From yvoinov at gmail.com  Tue Feb 10 20:43:38 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 02:43:38 +0600
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DA6AC0.2080801@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6AC0.2080801@treenet.co.nz>
Message-ID: <54DA6D7A.3040204@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Heh. Pure SQL database is VERY bad idea to store any security
credentials or ACL's. They too easy to hack.

11.02.15 2:32, Amos Jeffries ?????:
> On 11/02/2015 7:24 p.m., Ahmad wrote:
>> Thank you amos , but I have an issue with connection : Here is my
>> mysql info : ======== grant select on squid.* to 'squid'@'%'
>> identified by 'squid'; ===================== mysql> show
>> databases; +--------------------+ | Database           | 
>> +--------------------+ | information_schema | | mysql
>> | | squid              | +--------------------+ 3 rows in set
>> (0.00 sec)
>> 
>> mysql> use squid Database changed mysql> ; ERROR: No query
>> specified
>> 
>> mysql> show tables; +-----------------+ | Tables_in_squid | 
>> +-----------------+ | passwd          | +-----------------+ 1 row
>> in set (0.00 sec)
>> 
>> mysql> select from * passwd; ERROR 1064 (42000): You have an
>> error in your SQL syntax; check the manual that corresponds to
>> your MySQL server version for the right syntax to use near 'from
>> * passwd' at line 1 mysql> select * from  passwd; 
>> +--------+----------+---------+-----------+---------------------+
>>
>> 
| user   | password | enabled | fullname  | comment             |
>> +--------+----------+---------+-----------+---------------------+
>>
>> 
| Nikesh | test     |       1 | Test User | for testing purpose |
>> +--------+----------+---------+-----------+---------------------+
>>
>> 
1 row in set (0.00 sec)
>> 
> <snip>
> 
>> mysql> ===========================================
>> 
>> now on the squid box , I do the conection below :
>> 
>> here is the connection from remote squid: 
>> /lib/squid/basic_db_auth --dsn
>> "DBI:mysql:database=squid:host=x.x189.177"
> 
> No *semi-colons* in the driver parameters bit.
> 
> --dsn "DBI:mysql:host=x.x189.177;port=3306;database=squid"
> 
> 
> NP: I also like to order them by significance just in case they
> are processed in-order.
> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2m16AAoJENNXIZxhPexGIr8IALMxa6Gfh9qGLtE+LPLOozfb
YB5U/+QvNMV9/BD4wYD9B9/jTi9DGXOp7QvkG+OM3xB6etR1hOA0/Ppt1OOWY8co
Mc4QZhWNHXP+iLoajI6yIeXYQu6I8Hj3rYUbetf80M8j5TiIMivJjNpejGOJcJ76
6j0qwDbvfl/pV7q8qs+b4+gax7oqC8Zc5jHJM8uKwr8tknHfuGlqVTY7QPbYBX+G
an2HlaIr/gSY6p3drPCsvY3faprp24o8xuXNEex56558mOAw8dV8R7/7NVfd2bIJ
Mig+rYa4BPCEPu9Q8FELOwkiSaYl8c0LsQVvNyx7lptNNywcuj5IETxggflNHyY=
=vMtZ
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Feb 10 20:44:00 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 09:44:00 +1300
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DA6B82.60007@gmail.com>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6AC0.2080801@treenet.co.nz> <54DA6B82.60007@gmail.com>
Message-ID: <54DA6D90.5050900@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/02/2015 9:35 a.m., Yuri Voinov wrote:
> Wow, it just cannot connect with DB?!
> 

Maybe, maybe not, maybe its connecting to the localhost instead of
remote (he had a localhost test earlier). I just spotted table names
were different too.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU2m2QAAoJELJo5wb/XPRjsCcH/2wibaD27jyliAcZZAu5o0jF
f1rfT57rg7J4GaBOhbhTJPm1JYJKkra+bD4OTjOo3lPyZxqi5hq1hxjmOn0UEoe9
HIgaTJxyCuvoyWUsROEVKsw9ReAJoUqpLCMAuTyJkvV0w1tIwyCWovjbGsgsMc/K
xYELuTg/60yAlF4+xHdIZiuSOOhqgrEfAsSIIMdT/RfB+2hjjfyBZmIx6irqTfpg
w5O9iGpOhuFg/A1wD8EUsIHp1bre+t7YC2FWbwHcU0V+ba90mZMAZAOMHoMzi1rm
RpZx3enB1eTXOY9uQjcBZH+5JTSDMo7KI9rx+0cnk7IQENqouGB4jH6qca6ahKc=
=YjS+
-----END PGP SIGNATURE-----


From huaraz at moeller.plus.com  Tue Feb 10 20:46:06 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Tue, 10 Feb 2015 20:46:06 -0000
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <86d25i9plr.fsf@gmail.com>
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com>
Message-ID: <mbdqmh$ere$1@ger.gmane.org>

Hi Ludovit,

  Which Kerberos library version do you use ?    Is it possible that the 
encryption types don't match ?  I saw in your first email the following:

Your klist shows a HTTP ticket for arcfour

Server: HTTP/squid1.mdpt.local at MDPT.LOCAL
Client: HTTP/squid1.mdpt.local at MDPT.LOCAL
Ticket etype: arcfour-hmac-md5, kvno 8
Ticket length: 1090
Auth time:  Feb  9 14:55:18 2015
Start time: Feb  9 14:55:20 2015
End time:   Feb 10 00:55:18 2015
Ticket flags: enc-pa-rep, pre-authent
Addresses: addressless

but the keytab has aes128.

# ktutil -k /etc/krb5.keytab list
/etc/krb5.keytab:

Vno  Type                     Principal                          Aliases
  8  aes128-cts-hmac-sha1-96  HTTP/squid1.mdpt.local at MDPT.LOCAL

Markus

"Ludovit Koren"  wrote in message news:86d25i9plr.fsf at gmail.com...

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > Hi Ludovit,
    >  I haven't seen that error before either, but when you test you sould
    > have your own user credentials in the cache.  You should use kinit
    > <user>@MDPT.LOCAL and then try again the test. is the hostname
    > correctly set to squid1.mdpt.local ? If not try

    >   /usr/local/libexec/squid/negotiate_kerberos_auth_test
    > squid1.mdpt.local | awk '{sub(/Token:/,"YR"); print $0}END{print
    > "QQ"}' | /usr/local/libexec/squid/negotiate_kerberos_auth -r -s
    > GSS_C_NO_NAME


Hello,

still no progress...


# klist
Credentials cache: FILE:/tmp/krb5cc_0
        Principal: xkoren at MDPT.LOCAL

  Issued                Expires               Principal
Feb 10 08:41:06 2015  Feb 10 18:41:06 2015  krbtgt/MDPT.LOCAL at MDPT.LOCAL
Feb 10 08:42:17 2015  Feb 10 18:41:06 2015 
HTTP/squid1.mdpt.local at MDPT.LOCAL

# hostname
squid1.mdpt.local

# /usr/local/libexec/squid/negotiate_kerberos_auth_test squid1.mdpt.local | 
awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | 
/usr/local/libexec/squid/otiate_kerberos_auth -r -s HTTP/squid1.mdpt.local
BH gss_accept_sec_context() failed:  Miscellaneous failure (see text). 
unknown mech-code 2529639093 for mech unknown
BH quit command

# /usr/local/libexec/squid/negotiate_kerberos_auth_test squid1.mdpt.local | 
awk '{sub(/Token:/,"YR"); print $0}END{print "}' | 
/usr/local/libexec/squid/negotiate_kerberos_auth -r -s GSS_C_NO_NAME
BH gss_accept_sec_context() failed:  Miscellaneous failure (see text). 
unknown mech-code 2529639094 for mech unknown
BH quit command

regards,

lk
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From yvoinov at gmail.com  Tue Feb 10 20:49:43 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 02:49:43 +0600
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DA6D90.5050900@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6AC0.2080801@treenet.co.nz> <54DA6B82.60007@gmail.com>
 <54DA6D90.5050900@treenet.co.nz>
Message-ID: <54DA6EE7.4030601@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

As I think, this is around DB. Not squid. :) Just misconfiguration.

11.02.15 2:44, Amos Jeffries ?????:
> On 11/02/2015 9:35 a.m., Yuri Voinov wrote:
>> Wow, it just cannot connect with DB?!
> 
> 
> Maybe, maybe not, maybe its connecting to the localhost instead of 
> remote (he had a localhost test earlier). I just spotted table
> names were different too.
> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2m7nAAoJENNXIZxhPexGO24H/2IxYwtls5RZOSD6wYEqPPNQ
2xeGrmLZeyc9L9G+wIgYUgjvwmQzR+GerGiDA36lTNiRntZWlTVjyvGcAjwf/PsH
9p3N8X0UeJoA1lDSUfGpKeEDLOWCtVXWJ9wxK+a+wMyB3TGWS/GB6DZ+4DwYamT9
V8P78Ud7o4p2O1L3A1TIaY/GezG+te2qxydLYzlCeX41yDx54AVeBnyg/Eh4qd5i
8QZCZoLpKOZ67w8L43EjS0syBx5g70oHx3lDhafB7C9ZNV01u/Cds66TpuclqBug
tpa5MIIBOjSwLZV5RIQMfdaMjmKEbusqSrTe+IPi7/ymlfWhVzQRFhKoghA6DQA=
=2kOM
-----END PGP SIGNATURE-----


From ahmed.zaeem at netstream.ps  Wed Feb 11 07:17:38 2015
From: ahmed.zaeem at netstream.ps (Ahmad)
Date: Tue, 10 Feb 2015 23:17:38 -0800
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DA6D28.9010806@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
Message-ID: <000001d045ca$d217f480$7647dd80$@netstream.ps>

Thank you amos , I fixed the table thing , but I have new error now :

/lib/squid/basic_db_auth --dsn "DBI:mysql:host=x.xx..189.177;port=3306;database=squid" --user "squid" --password "squid" --table "passwd" --usercol "user" --passwdcol "password" --cond "" --plaintext

ERR unknown login
ERR unknown login
ERR unknown login
ERR unknown login
ERR unknown login


Wt do u think ??
Mysql issue ?


-----Original Message-----
From: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Sent: Tuesday, February 10, 2015 12:42 PM
To: Ahmad; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid authentication to remote sql server

Replying again because I missed the --table parameter value earlier.


On 11/02/2015 7:24 p.m., Ahmad wrote:
> Thank you amos , but I have an issue with connection :


> mysql> select * from  passwd;


===> notice the TABLE NAME.

> +--------+----------+---------+-----------+---------------------+
> | user   | password | enabled | fullname  | comment             |
> +--------+----------+---------+-----------+---------------------+
> | Nikesh | test     |       1 | Test User | for testing purpose |
> +--------+----------+---------+-----------+---------------------+
> 1 row in set (0.00 sec)
> 

> 
> now on the squid box , I do the conection below :
> 
> here is the connection from remote squid:
> /lib/squid/basic_db_auth --dsn 
> "DBI:mysql:database=squid:host=x.x189.177" \

blah. blah about semi-colons from both of my earlier posts..


> --user "squid" --password "squid" --table "user"

==>  notice the TABLE NAME

> --usercol "user" --passwdcol "password" 


> --cond "" --plaintext
> 

You have an "enabled" column in the table for disabling peoples accounts. The default --cond is fine.

> 
> DBD::mysql::st execute failed: Table 'squid.user' doesn't exist at /lib/squid/basic_db_auth line 215, <> line 1.
> DBD::mysql::st execute failed: MySQL server has gone away at /lib/squid/basic_db_auth line 218, <> line 1.
> ERR database error

Because TABLE NAME.

Amos



From squid3 at treenet.co.nz  Tue Feb 10 21:28:55 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 10:28:55 +1300
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <000001d045ca$d217f480$7647dd80$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
Message-ID: <54DA7817.9060506@treenet.co.nz>

On 11/02/2015 8:17 p.m., Ahmad wrote:
> Thank you amos , I fixed the table thing , but I have new error now :
> 
> /lib/squid/basic_db_auth --dsn "DBI:mysql:host=x.xx..189.177;port=3306;database=squid" --user "squid" --password "squid" --table "passwd" --usercol "user" --passwdcol "password" --cond "" --plaintext
> 
> ERR unknown login
> ERR unknown login
> ERR unknown login
> ERR unknown login
> ERR unknown login
> 
> 
> Wt do u think ??
> Mysql issue ?

Input issue. Thats a user:password combination being presented that does
not exist in the table.

Though it might be mysql interpreting the "password" in queries as the
built-in password() function. I renamed that column to "token" in my
auth DB.

And like Yuri pointed out a DB of passwords in clear-text is not the
greatest of security. At minimum use salted MD5 for the final setup.

Amos


From ahmed.zaeem at netstream.ps  Wed Feb 11 07:40:30 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Tue, 10 Feb 2015 23:40:30 -0800
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DA7817.9060506@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
 <54DA7817.9060506@treenet.co.nz>
Message-ID: <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>

Hi amos
I hadded squi/squid in the table

mysql> show tables
    -> ;
+-----------------+
| Tables_in_squid |
+-----------------+
| passwd          |
+-----------------+
1 row in set (0.00 sec)

mysql> select * from passwd;
+--------+----------+---------+-----------+---------------------+
| user   | password | enabled | fullname  | comment             |
+--------+----------+---------+-----------+---------------------+
| Nikesh | test     |       1 | Test User | for testing purpose |
| squid  | squid    |       1 | Test User | for testing purpose |
+--------+----------+---------+-----------+---------------------+
2 rows in set (0.00 sec)

mysql>



still has same error ?



how can u help me ?
login with md5 or wt ??


-----Original Message-----
From: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Sent: Tuesday, February 10, 2015 1:29 PM
To: Ahmad; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid authentication to remote sql server

On 11/02/2015 8:17 p.m., Ahmad wrote:
> Thank you amos , I fixed the table thing , but I have new error now :
> 
> /lib/squid/basic_db_auth --dsn 
> "DBI:mysql:host=x.xx..189.177;port=3306;database=squid" --user "squid" 
> --password "squid" --table "passwd" --usercol "user" --passwdcol 
> "password" --cond "" --plaintext
> 
> ERR unknown login
> ERR unknown login
> ERR unknown login
> ERR unknown login
> ERR unknown login
> 
> 
> Wt do u think ??
> Mysql issue ?

Input issue. Thats a user:password combination being presented that does not exist in the table.

Though it might be mysql interpreting the "password" in queries as the built-in password() function. I renamed that column to "token" in my auth DB.

And like Yuri pointed out a DB of passwords in clear-text is not the greatest of security. At minimum use salted MD5 for the final setup.

Amos



From yvoinov at gmail.com  Tue Feb 10 21:46:25 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 03:46:25 +0600
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DA7817.9060506@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
 <54DA7817.9060506@treenet.co.nz>
Message-ID: <54DA7C31.9040606@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Amos, MD5 insufficient. As minimum, SHA256 with salt. New Oracle RDBMS
use SHA to store user's password.

And don't forget about SQL Injection and password cracking farms..........

11.02.15 3:28, Amos Jeffries ?????:
> On 11/02/2015 8:17 p.m., Ahmad wrote:
>> Thank you amos , I fixed the table thing , but I have new error
>> now :
>> 
>> /lib/squid/basic_db_auth --dsn
>> "DBI:mysql:host=x.xx..189.177;port=3306;database=squid" --user
>> "squid" --password "squid" --table "passwd" --usercol "user"
>> --passwdcol "password" --cond "" --plaintext
>> 
>> ERR unknown login ERR unknown login ERR unknown login ERR unknown
>> login ERR unknown login
>> 
>> 
>> Wt do u think ?? Mysql issue ?
> 
> Input issue. Thats a user:password combination being presented that
> does not exist in the table.
> 
> Though it might be mysql interpreting the "password" in queries as
> the built-in password() function. I renamed that column to "token"
> in my auth DB.
> 
> And like Yuri pointed out a DB of passwords in clear-text is not
> the greatest of security. At minimum use salted MD5 for the final
> setup.
> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2nwxAAoJENNXIZxhPexGR84H/0A1ZldvWUbknbLPggemiXI7
fGF4B06K1IlgpVcXFZuyrCl9YQWdQfCv2PYbh5bVJuHzao4D146dmom7Ppvh0H4r
lcZEHb8ahr69Mzn43iozx5g8uuWJtoLRv3MFg73yR209H08XClJo7cnBYIj/Ije5
CftttAz0c+kxnR2GkyOU2Rp3xkwK1RQdre8BeRSPRYrFww11jqv35QY4O0M2VCQg
L5Ljx2s+rBto1Bg79VvV5syyEo3aOMIOXS8nUFqFYboVR4LFrakFk6mKVOI7klvH
t+4x/oUG3ZGlMdSbxKEn1w2mP1dpWnrN1d2lKCkQPv2qVmm6gInNPzXr2PAoNAI=
=gzYx
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Tue Feb 10 21:47:32 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 03:47:32 +0600
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
 <54DA7817.9060506@treenet.co.nz>
 <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>
Message-ID: <54DA7C74.2030902@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

(facepalm)


11.02.15 13:40, snakeeyes ?????:
> Hi amos I hadded squi/squid in the table
> 
> mysql> show tables -> ; +-----------------+ | Tables_in_squid | 
> +-----------------+ | passwd          | +-----------------+ 1 row
> in set (0.00 sec)
> 
> mysql> select * from passwd; 
> +--------+----------+---------+-----------+---------------------+ |
> user   | password | enabled | fullname  | comment             | 
> +--------+----------+---------+-----------+---------------------+ |
> Nikesh | test     |       1 | Test User | for testing purpose | |
> squid  | squid    |       1 | Test User | for testing purpose | 
> +--------+----------+---------+-----------+---------------------+ 2
> rows in set (0.00 sec)
> 
> mysql>
> 
> 
> 
> still has same error ?
> 
> 
> 
> how can u help me ? login with md5 or wt ??

Of course, no.

> 
> 
> -----Original Message----- From: Amos Jeffries
> [mailto:squid3 at treenet.co.nz] Sent: Tuesday, February 10, 2015 1:29
> PM To: Ahmad; squid-users at lists.squid-cache.org Subject: Re:
> [squid-users] squid authentication to remote sql server
> 
> On 11/02/2015 8:17 p.m., Ahmad wrote:
>> Thank you amos , I fixed the table thing , but I have new error
>> now :
>> 
>> /lib/squid/basic_db_auth --dsn 
>> "DBI:mysql:host=x.xx..189.177;port=3306;database=squid" --user
>> "squid" --password "squid" --table "passwd" --usercol "user"
>> --passwdcol "password" --cond "" --plaintext
>> 
>> ERR unknown login ERR unknown login ERR unknown login ERR unknown
>> login ERR unknown login
>> 
>> 
>> Wt do u think ?? Mysql issue ?
> 
> Input issue. Thats a user:password combination being presented that
> does not exist in the table.
> 
> Though it might be mysql interpreting the "password" in queries as
> the built-in password() function. I renamed that column to "token"
> in my auth DB.
> 
> And like Yuri pointed out a DB of passwords in clear-text is not
> the greatest of security. At minimum use salted MD5 for the final
> setup.
> 
> Amos
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2nx0AAoJENNXIZxhPexGt0cH/3JsKrG62EZryBe6fAjtxxXW
mJ505t31637yV5ajjn52jN+drwj+Xm+BvW/I9zaM9Xj3apf8cw6V0wM/JTNjdsr3
VFt+QHH8ZOIy+TpMbriEcl0VIxG1F9TRi7WR/O6DbLe3uyhKbj4pdsgYTs/aho8i
uzwWMDnnejWrN0ekT4YuC5ewTwild6rmJUxbwxWlHOLAsPut1ZqWPp0/3UPgElDJ
B/8pUIUq05BAaoK2TQwHsobyYUltVyLUK2DFgzd3uGf2Kkpfp1Z1MGrG8tkQKKcj
FBSwWijRot4Or//EgQWx9qMaq78XHJHCkPwJCJ7qWPHcOxR337m1dTfxdD5y0b8=
=bc1A
-----END PGP SIGNATURE-----


From luismiguelferreirasilva at gmail.com  Tue Feb 10 21:50:34 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Tue, 10 Feb 2015 14:50:34 -0700
Subject: [squid-users] Calculate time spent on website (per ip address)
Message-ID: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>

Dear all,

I was wondering if there is a built in feature in Squid to calculate the
time spent on a website, per ip address (e.g. 32 minutes between 12pm and
1pm, 5 minutes between 1pm and 2pm)? And, if not, how would you do it?

I immediately thought about using the log files for this BUT, because we
only log individual connections, how would you guys conclude the amount of
time spent per website? Would you, for instance, for each 5 minutes, add 5
minute chunks IF there was data flowing between the 5 minutes?

That would work but...Isn't there a more elegant way of doing this?

Thanks,
Luis
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/c8a25672/attachment.htm>

From yvoinov at gmail.com  Tue Feb 10 21:52:01 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 03:52:01 +0600
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
Message-ID: <54DA7D81.3070001@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hmmmmmmm.... Access.log? sqTop?

11.02.15 3:50, Luis Miguel Silva ?????:
> Dear all,
> 
> I was wondering if there is a built in feature in Squid to
> calculate the time spent on a website, per ip address (e.g. 32
> minutes between 12pm and 1pm, 5 minutes between 1pm and 2pm)? And,
> if not, how would you do it?
> 
> I immediately thought about using the log files for this BUT,
> because we only log individual connections, how would you guys
> conclude the amount of time spent per website? Would you, for
> instance, for each 5 minutes, add 5 minute chunks IF there was data
> flowing between the 5 minutes?
> 
> That would work but...Isn't there a more elegant way of doing
> this?
> 
> Thanks, Luis
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2n2AAAoJENNXIZxhPexGm34IAJ9klyyQymc8NKDLkmC2chwP
wqMaWdcNqagOelXCA1IKh9YJ/nqVm0O99StAa2HITrQNlb6t94AkD/tnOg8fi8hz
dDgz/wIVgvBX588sNQGvixJ0pHw8I6l3DNGzKAuXHWko3r5rzGCUdmJSWBl5LUmE
n8cwe/L1Ze3ETJfq9QrpSR9Mq8W02XnkDeZRgnJ7is3pt5wfDYds/moEcl20PKlN
KMLYVqDQMnMQUwANwtGuhUHMYnvnILknEGcVgLkJkRySVhC9RyzvZc/g5NvdMdvu
NclkJkz/pmd2lzrf2KgD7L53B9yIXnEnSqzM83T03MTGjXsGhAf9/oeWGn0EeGc=
=uUYv
-----END PGP SIGNATURE-----


From luismiguelferreirasilva at gmail.com  Tue Feb 10 21:52:39 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Tue, 10 Feb 2015 14:52:39 -0700
Subject: [squid-users] Marking outgoing packets
Message-ID: <CA+suCFgu0N=2jfPa3jLz8uGe4eP8ZHXH6RGVfgoGF9HA_-NhVg@mail.gmail.com>

Dear all,

I just found this REALLY cool feature that allows you to mark packets for
Netfilter to then intercept and handle:
http://www.squid-cache.org/Doc/config/tcp_outgoing_mark/

What I was wondering was, is there a way for us to mark based on a ICAP
filter or redirect_program output?

The objective would be to, depending on a decision made by the ICAP filter,
mark a packet so we could apply different firewall rules to it.

Thank you,
Luis
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/657d9781/attachment.htm>

From yvoinov at gmail.com  Tue Feb 10 21:54:48 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 03:54:48 +0600
Subject: [squid-users] Marking outgoing packets
In-Reply-To: <CA+suCFgu0N=2jfPa3jLz8uGe4eP8ZHXH6RGVfgoGF9HA_-NhVg@mail.gmail.com>
References: <CA+suCFgu0N=2jfPa3jLz8uGe4eP8ZHXH6RGVfgoGF9HA_-NhVg@mail.gmail.com>
Message-ID: <54DA7E28.6000006@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I think, the answer is 'no' without Squid code customization.

I'm right, Amos?

11.02.15 3:52, Luis Miguel Silva ?????:
> Dear all,
> 
> I just found this REALLY cool feature that allows you to mark
> packets for Netfilter to then intercept and handle: 
> http://www.squid-cache.org/Doc/config/tcp_outgoing_mark/
> 
> What I was wondering was, is there a way for us to mark based on a
> ICAP filter or redirect_program output?
> 
> The objective would be to, depending on a decision made by the ICAP
> filter, mark a packet so we could apply different firewall rules to
> it.
> 
> Thank you, Luis
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2n4oAAoJENNXIZxhPexGOJAH/A6pXiGW+m019m+MQ9tfzJb3
PBCsOwzsjfk+6nteaSH0/jX2Fg+sruHfrGDz51v2rR0IjAISEDSDIQcfE70Fq8RS
C/Hqi/oa9xgy+e3Wv3sylSALi6Mrs9CFqxj+1RQJszA/D6YP1c6SZm9WMspurSrf
2srmVVb3u0gifESQyWBN2d/IYDknG/7wpdSfXFRkLJLuZUUh+g+V0Pu6aZVhvska
8QaZDhDGiJ9aUuBY1YxfMj4sNigusKmwNTy8tm4pd+TWB37oBHudSzECrKk1AUjF
06K2lbMXUF67QrFA8PiyFLHI7wdNltSd8zOWfh7mQXjg6Hjqg1IFj45Eyns7lQY=
=cMOr
-----END PGP SIGNATURE-----


From luismiguelferreirasilva at gmail.com  Tue Feb 10 21:57:15 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Tue, 10 Feb 2015 14:57:15 -0700
Subject: [squid-users] Marking outgoing packets
In-Reply-To: <54DA7E28.6000006@gmail.com>
References: <CA+suCFgu0N=2jfPa3jLz8uGe4eP8ZHXH6RGVfgoGF9HA_-NhVg@mail.gmail.com>
 <54DA7E28.6000006@gmail.com>
Message-ID: <CA+suCFh33SFJh0kicEj1bRxr3iDsVxicF2OURFaUzoGXOEiPXA@mail.gmail.com>

Anyway to work around that? (e.g. based on the output of the c-ical call,
make the request land on a certain ACL?)

On Tue, Feb 10, 2015 at 2:54 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> I think, the answer is 'no' without Squid code customization.
>
> I'm right, Amos?
>
> 11.02.15 3:52, Luis Miguel Silva ?????:
> > Dear all,
> >
> > I just found this REALLY cool feature that allows you to mark
> > packets for Netfilter to then intercept and handle:
> > http://www.squid-cache.org/Doc/config/tcp_outgoing_mark/
> >
> > What I was wondering was, is there a way for us to mark based on a
> > ICAP filter or redirect_program output?
> >
> > The objective would be to, depending on a decision made by the ICAP
> > filter, mark a packet so we could apply different firewall rules to
> > it.
> >
> > Thank you, Luis
> >
> >
> >
> > _______________________________________________ squid-users mailing
> > list squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU2n4oAAoJENNXIZxhPexGOJAH/A6pXiGW+m019m+MQ9tfzJb3
> PBCsOwzsjfk+6nteaSH0/jX2Fg+sruHfrGDz51v2rR0IjAISEDSDIQcfE70Fq8RS
> C/Hqi/oa9xgy+e3Wv3sylSALi6Mrs9CFqxj+1RQJszA/D6YP1c6SZm9WMspurSrf
> 2srmVVb3u0gifESQyWBN2d/IYDknG/7wpdSfXFRkLJLuZUUh+g+V0Pu6aZVhvska
> 8QaZDhDGiJ9aUuBY1YxfMj4sNigusKmwNTy8tm4pd+TWB37oBHudSzECrKk1AUjF
> 06K2lbMXUF67QrFA8PiyFLHI7wdNltSd8zOWfh7mQXjg6Hjqg1IFj45Eyns7lQY=
> =cMOr
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/9c73dbdb/attachment.htm>

From squid3 at treenet.co.nz  Tue Feb 10 21:57:41 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 10:57:41 +1300
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
 <54DA7817.9060506@treenet.co.nz>
 <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>
Message-ID: <54DA7ED5.1050801@treenet.co.nz>

On 11/02/2015 8:40 p.m., snakeeyes wrote:
> Hi amos
> I hadded squi/squid in the table
> 
> mysql> show tables
>     -> ;
> +-----------------+
> | Tables_in_squid |
> +-----------------+
> | passwd          |
> +-----------------+
> 1 row in set (0.00 sec)
> 
> mysql> select * from passwd;
> +--------+----------+---------+-----------+---------------------+
> | user   | password | enabled | fullname  | comment             |
> +--------+----------+---------+-----------+---------------------+
> | Nikesh | test     |       1 | Test User | for testing purpose |
> | squid  | squid    |       1 | Test User | for testing purpose |
> +--------+----------+---------+-----------+---------------------+
> 2 rows in set (0.00 sec)
> 
> mysql>
> 
> 
> 
> still has same error ?
> 
> 
> 
> how can u help me ?
> login with md5 or wt ??
> 

Try renaming the "password" column.
 - rename it in the DB, change the squid.conf helper parameter, then
reload squid config.


Perhapse show us what you are entering on the command line test for
username and password?

Perhapse try using the --debug option? to get the helper to record in
cache log (or on screen for the manul tests).

Amos



From luismiguelferreirasilva at gmail.com  Tue Feb 10 21:58:32 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Tue, 10 Feb 2015 14:58:32 -0700
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <54DA7D81.3070001@gmail.com>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
 <54DA7D81.3070001@gmail.com>
Message-ID: <CA+suCFhP4RpzVhMJG2qpxC+WhppACCe0Ps-Jj9CzD_wMcH1Zug@mail.gmail.com>

I did not know about sqtop. Too bad it requires access to Squid's manager
interface (I was hoping it used access.log or something)...

Any other tools you know that might provide me with (time usage) statistics
from access.log (I don't want to reinvent the wheel here :o)).

On Tue, Feb 10, 2015 at 2:52 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Hmmmmmmm.... Access.log? sqTop?
>
> 11.02.15 3:50, Luis Miguel Silva ?????:
> > Dear all,
> >
> > I was wondering if there is a built in feature in Squid to
> > calculate the time spent on a website, per ip address (e.g. 32
> > minutes between 12pm and 1pm, 5 minutes between 1pm and 2pm)? And,
> > if not, how would you do it?
> >
> > I immediately thought about using the log files for this BUT,
> > because we only log individual connections, how would you guys
> > conclude the amount of time spent per website? Would you, for
> > instance, for each 5 minutes, add 5 minute chunks IF there was data
> > flowing between the 5 minutes?
> >
> > That would work but...Isn't there a more elegant way of doing
> > this?
> >
> > Thanks, Luis
> >
> >
> >
> > _______________________________________________ squid-users mailing
> > list squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU2n2AAAoJENNXIZxhPexGm34IAJ9klyyQymc8NKDLkmC2chwP
> wqMaWdcNqagOelXCA1IKh9YJ/nqVm0O99StAa2HITrQNlb6t94AkD/tnOg8fi8hz
> dDgz/wIVgvBX588sNQGvixJ0pHw8I6l3DNGzKAuXHWko3r5rzGCUdmJSWBl5LUmE
> n8cwe/L1Ze3ETJfq9QrpSR9Mq8W02XnkDeZRgnJ7is3pt5wfDYds/moEcl20PKlN
> KMLYVqDQMnMQUwANwtGuhUHMYnvnILknEGcVgLkJkRySVhC9RyzvZc/g5NvdMdvu
> NclkJkz/pmd2lzrf2KgD7L53B9yIXnEnSqzM83T03MTGjXsGhAf9/oeWGn0EeGc=
> =uUYv
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/e9ad942e/attachment.htm>

From yvoinov at gmail.com  Tue Feb 10 22:04:58 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 04:04:58 +0600
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <CA+suCFhP4RpzVhMJG2qpxC+WhppACCe0Ps-Jj9CzD_wMcH1Zug@mail.gmail.com>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
 <54DA7D81.3070001@gmail.com>
 <CA+suCFhP4RpzVhMJG2qpxC+WhppACCe0Ps-Jj9CzD_wMcH1Zug@mail.gmail.com>
Message-ID: <54DA808A.4060108@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

You can't get any meaningful info about client connections times
without cache_object://localhost/active_requests access.

11.02.15 3:58, Luis Miguel Silva ?????:
> I did not know about sqtop. Too bad it requires access to Squid's
> manager interface (I was hoping it used access.log or
> something)...
> 
> Any other tools you know that might provide me with (time usage)
> statistics from access.log (I don't want to reinvent the wheel here
> :o)).
> 
> On Tue, Feb 10, 2015 at 2:52 PM, Yuri Voinov <yvoinov at gmail.com>
> wrote:
> 
> Hmmmmmmm.... Access.log? sqTop?
> 
> 11.02.15 3:50, Luis Miguel Silva ?????:
>>>> Dear all,
>>>> 
>>>> I was wondering if there is a built in feature in Squid to 
>>>> calculate the time spent on a website, per ip address (e.g.
>>>> 32 minutes between 12pm and 1pm, 5 minutes between 1pm and
>>>> 2pm)? And, if not, how would you do it?
>>>> 
>>>> I immediately thought about using the log files for this
>>>> BUT, because we only log individual connections, how would
>>>> you guys conclude the amount of time spent per website? Would
>>>> you, for instance, for each 5 minutes, add 5 minute chunks IF
>>>> there was data flowing between the 5 minutes?
>>>> 
>>>> That would work but...Isn't there a more elegant way of
>>>> doing this?
>>>> 
>>>> Thanks, Luis
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________ squid-users
>>>> mailing list squid-users at lists.squid-cache.org 
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2oCKAAoJENNXIZxhPexGlH0H/RnBx4OqPOHznjMRacL5SLIH
3fRBKhwRffgGxLKKznIiRTBvn86fO/q/pRwrX/kv4TFPhtOAKsPcsDlbybrtAy+k
4TXozLupSDCP9eMJXC8+DrGKUbA5xhxSzKEzG88J/cfjZL++wvqjlJzzreAO6HdH
y7N5EH5apdEutMqp0b62Rt4xJC9eBZq5NUMgEpPcvGZLPkbIpt1jpE0ttUP2L9II
KmsRw/uZinhl8WjCQm7f6gTqmlG/j1VSXBpBd+GVD46ioIk1QBYxngjz17yzZ3sd
1bRKMWMYN8B5Xn0QCHmMzjGFhy2NMpTdu3TkMjoPnYqYKmbb0USv0YoUnqh8q7A=
=Trbl
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Feb 10 22:16:37 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 11:16:37 +1300
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
Message-ID: <54DA8345.5010802@treenet.co.nz>

On 11/02/2015 10:50 a.m., Luis Miguel Silva wrote:
> Dear all,
> 
> I was wondering if there is a built in feature in Squid to calculate the
> time spent on a website, per ip address (e.g. 32 minutes between 12pm and
> 1pm, 5 minutes between 1pm and 2pm)? And, if not, how would you do it?
> 

No there is nothing built-in. The whole concept of "website" and "page"
is an abstract concept that only really exists in peoples heads, with
some browser participation. It simply does not exist at lower levels
than the browser.

Some of the Squid helpers (for auth, session, quota) use a scaling
window of time between transactions to estimate whether any two requests
are from the same end-user. But even that does not really match up well
to "website" or "page" concepts.


> I immediately thought about using the log files for this BUT, because we
> only log individual connections, how would you guys conclude the amount of
> time spent per website? Would you, for instance, for each 5 minutes, add 5
> minute chunks IF there was data flowing between the 5 minutes?

There is an entire field of research called Usability seeking to answer
that question for decades now. Its up to you.

> 
> That would work but...Isn't there a more elegant way of doing this?

Look at it from another angle. What are you trying to get out of all
this monitoring? What is the actual purpose of it?

Amos



From squid3 at treenet.co.nz  Tue Feb 10 22:21:09 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 11:21:09 +1300
Subject: [squid-users] Marking outgoing packets
In-Reply-To: <54DA7E28.6000006@gmail.com>
References: <CA+suCFgu0N=2jfPa3jLz8uGe4eP8ZHXH6RGVfgoGF9HA_-NhVg@mail.gmail.com>
 <54DA7E28.6000006@gmail.com>
Message-ID: <54DA8455.5000107@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/02/2015 10:54 a.m., Yuri Voinov wrote:
> I think, the answer is 'no' without Squid code customization.
> 
> I'm right, Amos?

No your not ;-)

We have this other really, REALLY cool feature of transaction
annotations. Where the squid helpers add little tags/notes to the
transaction and a "notes" type ACL can be used in any access control
list to decide things based on them.

There is ICAP involvement too, but I'm only (halfway) sure about the
fact that notes get sent to ICAP. Not about what comes out.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU2oRVAAoJELJo5wb/XPRj2QsH/A+In1a7ljaop/GhP1t1abTz
33xPQwWfYtKiLEspX1/uDTGWJyklRkmV45c+31y5zIa2OUIU23B8xPABr8bqHQaZ
MtwB1FliT4CO/2lpNBwKgkCnl3C2LzbwIvI8ZC0NRukqL1drgDFSVUwoKuLmUs4n
9+6I8o/rBYfy7aBsewCdkZoQzB5tD/oicgDT9r6WftutqVPdFA5E9tZtUgGoG9OX
J/6scu8rWU+2iTCrNZNM/0md6QMsnBVTIT3DYMznusnNrf+0sqSSR5PP2jyVbFdW
XQB8K7nfC1vNDxbicnPTEjLHnDqruMHjgLMr4u6Uy0JufuesJlnjPdpV4L0CN80=
=yyCw
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Tue Feb 10 22:23:58 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 04:23:58 +0600
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <54DA8345.5010802@treenet.co.nz>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
 <54DA8345.5010802@treenet.co.nz>
Message-ID: <54DA84FE.7040703@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I forgot about one thing ;)

HTTP is stateless protocol (in most cases, excluding presistant
connections). So, it is impossible to determine how much time user
spent on site. Only very approximately. Right?

11.02.15 4:16, Amos Jeffries ?????:
> On 11/02/2015 10:50 a.m., Luis Miguel Silva wrote:
>> Dear all,
>> 
>> I was wondering if there is a built in feature in Squid to
>> calculate the time spent on a website, per ip address (e.g. 32
>> minutes between 12pm and 1pm, 5 minutes between 1pm and 2pm)?
>> And, if not, how would you do it?
>> 
> 
> No there is nothing built-in. The whole concept of "website" and
> "page" is an abstract concept that only really exists in peoples
> heads, with some browser participation. It simply does not exist at
> lower levels than the browser.
> 
> Some of the Squid helpers (for auth, session, quota) use a scaling 
> window of time between transactions to estimate whether any two
> requests are from the same end-user. But even that does not really
> match up well to "website" or "page" concepts.
> 
> 
>> I immediately thought about using the log files for this BUT,
>> because we only log individual connections, how would you guys
>> conclude the amount of time spent per website? Would you, for
>> instance, for each 5 minutes, add 5 minute chunks IF there was
>> data flowing between the 5 minutes?
> 
> There is an entire field of research called Usability seeking to
> answer that question for decades now. Its up to you.
> 
>> 
>> That would work but...Isn't there a more elegant way of doing
>> this?
> 
> Look at it from another angle. What are you trying to get out of
> all this monitoring? What is the actual purpose of it?
> 
> Amos
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2oT+AAoJENNXIZxhPexGNCAH/iSEtQfyOnqw9vEW2FUCbxe8
HFU3F3P6hsky50/AHk9apcvHu6k64ggKVaXp2i0eDk0+Z2Oc62tPdA65uPsYMO71
yQkZc7TNqZiR1haIQgw7mKQQ+CQnRIDCjsFAU4UPlR6z7zq7AEFMYbXPvMXRaxBQ
nWRzo25mSe8PnaM3KE75uzO1TcK3Cm9XURr6R5HCqob39SoU7VjAamzvWdYeomhJ
Ow186sAFc9bRlbtoCw44W45YSkGIFp/cs6OAajZL31DMznnLR3qiuzUWLGRDC3Yh
IVQGP3ngO58duuVD9d7X7OB1bGVAM4HuXzi2U+RxgPluPMI1019xIbjMTV9lVyU=
=Ksr+
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Tue Feb 10 22:25:25 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 04:25:25 +0600
Subject: [squid-users] Marking outgoing packets
In-Reply-To: <54DA8455.5000107@treenet.co.nz>
References: <CA+suCFgu0N=2jfPa3jLz8uGe4eP8ZHXH6RGVfgoGF9HA_-NhVg@mail.gmail.com>
 <54DA7E28.6000006@gmail.com> <54DA8455.5000107@treenet.co.nz>
Message-ID: <54DA8555.9080402@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Wow, I have forgotten about this.

It is really cool feature!

11.02.15 4:21, Amos Jeffries ?????:
> On 11/02/2015 10:54 a.m., Yuri Voinov wrote:
>> I think, the answer is 'no' without Squid code customization.
> 
>> I'm right, Amos?
> 
> No your not ;-)
> 
> We have this other really, REALLY cool feature of transaction 
> annotations. Where the squid helpers add little tags/notes to the 
> transaction and a "notes" type ACL can be used in any access
> control list to decide things based on them.
> 
> There is ICAP involvement too, but I'm only (halfway) sure about
> the fact that notes get sent to ICAP. Not about what comes out.
Aha, so adapter must do it?

> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU2oVVAAoJENNXIZxhPexG1foH/jqM48Xi8Xl2ZIZ7MCssJL90
4aiM+zrgmkV0RK50G14X4PHUKd0yhGPTZSXKmcKSzSgnI4r9YQXdt+TyHCd3YqNm
QsC7c8Z/ZuFP1V9NLT/m6vCaqrQD4/YCuxGt8vqbEvGsBfykEqlro8552wScVxzI
2z+ZZOL5WiqmdqGEuHAo+IN/DIb4Etm8sUgrgqiizpuJcyCpbqA0wzWkC1ScgtBR
47OoFG6ytWA7tUXOArpw+843lR2NRhZyhRnc52gymJsDWh/8d0RIQ4xvUzDGHRTx
3zyhaT+SPofznejRDED8klA8QkEUowhO4wzTPkrfEWa3IUTkS97lsiSLIZT+58k=
=a+yK
-----END PGP SIGNATURE-----


From dan at getbusi.com  Tue Feb 10 22:30:46 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Wed, 11 Feb 2015 09:30:46 +1100
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
Message-ID: <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>

Hi Eliezer

Took a while to get this up?sorry about that. Here?s an example of a production config of ours (with some confidential stuff necessarily taken out/edited):
https://gist.github.com/djch/92cf44440b04afbd7917 <https://gist.github.com/djch/92cf44440b04afbd7917>

Let me know if there?s any other info I can provide that might point towards the cause of this crash.

And thanks again for taking a look.

> On 3 Feb 2015, at 2:49 pm, Dan Charlesworth <dan at getbusi.com> wrote:
> 
> Hi Eliezer
> 
> Thanks for paying attention, as always. I?m working on getting an (appropriately censored) example of our squid.conf up for your perusal.
> 
> In the mean time I just wanted to point out that when this crash occurs some of the most busy external_acl_types appear to crash too. Though the exact ones seems to vary a bit between occurrences:
> 
> 2015/02/03 13:03:05 kid1| assertion failed: client_side.cc:1515: "connIsUsable(http->getConn())"
> Traceback (most recent call last):
>   File "max_file_size_acl.pyo", line 76, in <module>
> IOError: [Errno 104] Connection reset by peer
> 2015/02/03 13:04:01 kid1| Set Current Directory to /var/spool/squid
> Traceback (most recent call last):
>   File "set_finder_acl.pyo", line 94, in <module>
> IOError: [Errno 104] Connection reset by peer
> 2015/02/03 13:04:01 kid1| Starting Squid Cache version 3.4.11 for x86_64-redhat-linux-gnu...
> 
> Those lines it?s pointing to in the Traceback are just the last line in each ACL e.g. `line = sys.stdin.readline()`
> 
> Cheers
> Dan
> 
>> On 2 Feb 2015, at 11:35 am, Eliezer Croitoru <eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>> wrote:
>> 
>> Hey Dan,
>> 
>> Just to get around the environment, can you share your squid.conf?(censuring confidential data)
>> 
>> Thanks,
>> Eliezer
>> 
>> On 02/02/2015 01:14, Dan Charlesworth wrote:
>>> Bumping this one for the new year 'cause I still don't understand squid
>>> traces and because it's still happening with v3.4.11.
>>> 
>>> I would speculate that's it's something to do with the External ACLs
>>> (there's a bunch). Let me know if a more recent traceback (than those
>>> earlier in the thread) would help.
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150211/09239c14/attachment.htm>

From luismiguelferreirasilva at gmail.com  Wed Feb 11 00:35:26 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Tue, 10 Feb 2015 17:35:26 -0700
Subject: [squid-users] Marking outgoing packets
In-Reply-To: <54DA8455.5000107@treenet.co.nz>
References: <CA+suCFgu0N=2jfPa3jLz8uGe4eP8ZHXH6RGVfgoGF9HA_-NhVg@mail.gmail.com>
 <54DA7E28.6000006@gmail.com> <54DA8455.5000107@treenet.co.nz>
Message-ID: <CA+suCFjHV-C31OGJoruABy9qJoYGpLP_vNqDG4608k7dmaoCsA@mail.gmail.com>

That's GREAT Amos,

Where can I learn more about it? Can you point me to some documentation?
I was able to find this here:
http://www.eu.squid-cache.org/Doc/config/note/

It does seem that I could use this to note to tag things to an ACL but it
isn't clear to me how to use it (especially leveraging I-CAP).

Thank you,
Luis

On Tue, Feb 10, 2015 at 3:21 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 11/02/2015 10:54 a.m., Yuri Voinov wrote:
> > I think, the answer is 'no' without Squid code customization.
> >
> > I'm right, Amos?
>
> No your not ;-)
>
> We have this other really, REALLY cool feature of transaction
> annotations. Where the squid helpers add little tags/notes to the
> transaction and a "notes" type ACL can be used in any access control
> list to decide things based on them.
>
> There is ICAP involvement too, but I'm only (halfway) sure about the
> fact that notes get sent to ICAP. Not about what comes out.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJU2oRVAAoJELJo5wb/XPRj2QsH/A+In1a7ljaop/GhP1t1abTz
> 33xPQwWfYtKiLEspX1/uDTGWJyklRkmV45c+31y5zIa2OUIU23B8xPABr8bqHQaZ
> MtwB1FliT4CO/2lpNBwKgkCnl3C2LzbwIvI8ZC0NRukqL1drgDFSVUwoKuLmUs4n
> 9+6I8o/rBYfy7aBsewCdkZoQzB5tD/oicgDT9r6WftutqVPdFA5E9tZtUgGoG9OX
> J/6scu8rWU+2iTCrNZNM/0md6QMsnBVTIT3DYMznusnNrf+0sqSSR5PP2jyVbFdW
> XQB8K7nfC1vNDxbicnPTEjLHnDqruMHjgLMr4u6Uy0JufuesJlnjPdpV4L0CN80=
> =yyCw
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/05b5a3f8/attachment.htm>

From luismiguelferreirasilva at gmail.com  Wed Feb 11 00:37:39 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Tue, 10 Feb 2015 17:37:39 -0700
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <54DA8345.5010802@treenet.co.nz>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
 <54DA8345.5010802@treenet.co.nz>
Message-ID: <CA+suCFibj3OPyRcy0ThFgbTB+z2iOEJPjbVS5dsoJaJYbJHJww@mail.gmail.com>

I'm trying to export this information and create pretty reports detailing
how much time each device spent online / on each site.

I understand I'll probably need to create this myself, I'm just trying to
figure out what the state of the art is so I don't waste time on problems
that have already been solved by others! :o)

Thank you,
Luis


> > That would work but...Isn't there a more elegant way of doing this?
>
> Look at it from another angle. What are you trying to get out of all
> this monitoring? What is the actual purpose of it?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/c0f1e6c5/attachment.htm>

From squid3 at treenet.co.nz  Wed Feb 11 02:09:09 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 15:09:09 +1300
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <CA+suCFibj3OPyRcy0ThFgbTB+z2iOEJPjbVS5dsoJaJYbJHJww@mail.gmail.com>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
 <54DA8345.5010802@treenet.co.nz>
 <CA+suCFibj3OPyRcy0ThFgbTB+z2iOEJPjbVS5dsoJaJYbJHJww@mail.gmail.com>
Message-ID: <54DAB9C5.4000504@treenet.co.nz>

On 11/02/2015 1:37 p.m., Luis Miguel Silva wrote:
> I'm trying to export this information and create pretty reports detailing
> how much time each device spent online / on each site.

The graph of online will shock you. Network access times are seriously tiny.

The Squid access.log column #2 is the count of milliseconds the client
spent online accessing the resource in the URL field. Add that up
per-site and you have the answer for online time. All the rest of the
time is OFFLINE - user reading, viewing, doing other stuff.

You will need to adjust for CONNECT transactions, which skew the data by
staying active/counting across times when actually nothing is going on.

The other unsolved problem is figuring out what a "site" actually is.
Most people start off assuming domain name == website. They are wrong so
very, very wrong.

When it comes to anything above small business sites or personal domains
a "site" turns into a unholy mashup of multiple domain names (yay
multiple sites ... or is it one? and how are they overlaid with
embedding? .... eek!) and objects from all over the place.


> 
> I understand I'll probably need to create this myself, I'm just trying to
> figure out what the state of the art is so I don't waste time on problems
> that have already been solved by others! :o)

State of the art AFAIK is proprietary information. You will have to ask
the big "social network" crowd if they will let you in on.

The Squid time quote helper uses 5 minutes default, but is configurable.

The session helpers use 1 hour defaults, but is not easily per-site (see
above).

The Squid built-in client DB uses a threshold with frequency of access
over the past T seconds. But its only session-tracking to know whether
the resources consumed by state about the client can be discarded or are
better kept for some future traffic.

Amos



From squid3 at treenet.co.nz  Wed Feb 11 02:15:42 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 15:15:42 +1300
Subject: [squid-users] Marking outgoing packets
In-Reply-To: <CA+suCFjHV-C31OGJoruABy9qJoYGpLP_vNqDG4608k7dmaoCsA@mail.gmail.com>
References: <CA+suCFgu0N=2jfPa3jLz8uGe4eP8ZHXH6RGVfgoGF9HA_-NhVg@mail.gmail.com>
 <54DA7E28.6000006@gmail.com> <54DA8455.5000107@treenet.co.nz>
 <CA+suCFjHV-C31OGJoruABy9qJoYGpLP_vNqDG4608k7dmaoCsA@mail.gmail.com>
Message-ID: <54DABB4E.9070001@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11/02/2015 1:35 p.m., Luis Miguel Silva wrote:
> That's GREAT Amos,
> 
> Where can I learn more about it? Can you point me to some
> documentation? I was able to find this here: 
> http://www.eu.squid-cache.org/Doc/config/note/
> 

http://www.squid-cache.org/Versions/v3/3.4/RELEASENOTES.html#ss2.5

> It does seem that I could use this to note to tag things to an ACL
> but it isn't clear to me how to use it (especially leveraging
> I-CAP).


Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU2rtOAAoJELJo5wb/XPRjg6sH/jwZnWyQ9AQ2H4zI7XM3QDrx
RrUIdFPE2fiiZ3kLxcA312AwPaD4xXET/dt6m01aKKXy0kITybyMu26ql51Fx8Qy
vrTEC5c168QqIFpYj9w/Fw6qAlDXD+FM7MtGUfQsolgk4f79AdFYNH/ELoiaQ/KY
zNhMEhXzfDLgOCdzwgxyAu/2Z3nhlK4QuAOzXrmW9QmeIz1eU1pgn4VvBhuXHV3E
hFI8glD6EF/30U9N1Xioh6yLnfua7ZgH4CJXxTRw3uRGtuuDHLo7dmGULVRlm6ha
mUf/26tNYl+palLPOrII2ariEEnKAX7kxTAMuHw1icyYpxaNWb6YcDjDVyJu1pE=
=QrGI
-----END PGP SIGNATURE-----


From luismiguelferreirasilva at gmail.com  Wed Feb 11 05:25:39 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Tue, 10 Feb 2015 22:25:39 -0700
Subject: [squid-users] Redirecting to DIRECT_CONNECT failed ssl-bump
	connections
Message-ID: <CA+suCFgq33avo4GBkcmCFnZFarRM70Ne6sO8Eb2gboLgj4mX2w@mail.gmail.com>

Dear all,

I'm seeing several error messages in my cache.log, complaining that the
destination certificate is invalid:
2015/02/08 19:27:28 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 22: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2015/02/08 19:27:28 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 20: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
alert unknown ca (1/0)
2015/02/08 19:27:32 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 50: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2015/02/08 19:27:33 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 49: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
alert certificate unknown (1/0)
2015/02/08 19:27:33 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 50: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2015/02/08 19:27:33 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 49: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
alert unknown ca (1/0)
2015/02/08 19:27:34 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 49: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
alert unknown ca (1/0)
2015/02/08 19:27:37 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 50: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1
alert unknown ca (1/0)
2015/02/08 19:27:37 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 51: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2015/02/08 19:27:37 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
alert certificate unknown (1/0)
2015/02/08 19:27:39 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 51: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2015/02/08 19:27:39 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
alert certificate unknown (1/0)
2015/02/08 19:27:40 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
alert certificate unknown (1/0)
2015/02/08 19:27:40 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
alert certificate unknown (1/0)
2015/02/08 19:27:41 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
alert certificate unknown (1/0)
2015/02/08 19:27:42 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 51: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2015/02/08 19:27:42 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
alert certificate unknown (1/0)
2015/02/08 19:27:42 kid1| clientNegotiateSSL: Error negotiating SSL
connection on FD 52: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
alert certificate unknown (1/0)

Is there a way for me to intercept these and, when they happen, allow a
direct connection between the client and the destination?

In other words, I want to ssl-bump ALL connections *but*, if we encounter
certificate errors, I would like to make a direct connection instead. Is
this possible?

Thank you,
Luis
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/ae460931/attachment.htm>

From fredbmail at free.fr  Wed Feb 11 08:16:04 2015
From: fredbmail at free.fr (FredB)
Date: Wed, 11 Feb 2015 09:16:04 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <1251123883.343140390.1423479615293.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <957440820.348223543.1423642564009.JavaMail.root@zimbra4-e1.priv.proxad.net>

Stefano, Please can you try this "grep assert /var/log/squid/cache.log" after the blank page 

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From yvoinov at gmail.com  Wed Feb 11 08:49:13 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 14:49:13 +0600
Subject: [squid-users] Redirecting to DIRECT_CONNECT failed ssl-bump
	connections
In-Reply-To: <CA+suCFgq33avo4GBkcmCFnZFarRM70Ne6sO8Eb2gboLgj4mX2w@mail.gmail.com>
References: <CA+suCFgq33avo4GBkcmCFnZFarRM70Ne6sO8Eb2gboLgj4mX2w@mail.gmail.com>
Message-ID: <54DB1789.3040101@gmail.com>

First of all,

read this:

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

Second - no way to find what site generates this error excluding user 
complains.

WBR, Yuri.

11.02.15 11:25, Luis Miguel Silva ?????:
> Dear all,
>
> I'm seeing several error messages in my cache.log, complaining that 
> the destination certificate is invalid:
> 2015/02/08 19:27:28 kid1| fwdNegotiateSSL: Error negotiating SSL 
> connection on FD 22: error:14090086:SSL 
> routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
> 2015/02/08 19:27:28 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 20: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 
> alert unknown ca (1/0)
> 2015/02/08 19:27:32 kid1| fwdNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14090086:SSL 
> routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
> 2015/02/08 19:27:33 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 49: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 
> alert certificate unknown (1/0)
> 2015/02/08 19:27:33 kid1| fwdNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14090086:SSL 
> routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
> 2015/02/08 19:27:33 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 49: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 
> alert unknown ca (1/0)
> 2015/02/08 19:27:34 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 49: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 
> alert unknown ca (1/0)
> 2015/02/08 19:27:37 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 
> alert unknown ca (1/0)
> 2015/02/08 19:27:37 kid1| fwdNegotiateSSL: Error negotiating SSL 
> connection on FD 51: error:14090086:SSL 
> routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
> 2015/02/08 19:27:37 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 
> alert certificate unknown (1/0)
> 2015/02/08 19:27:39 kid1| fwdNegotiateSSL: Error negotiating SSL 
> connection on FD 51: error:14090086:SSL 
> routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
> 2015/02/08 19:27:39 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 
> alert certificate unknown (1/0)
> 2015/02/08 19:27:40 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 
> alert certificate unknown (1/0)
> 2015/02/08 19:27:40 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 
> alert certificate unknown (1/0)
> 2015/02/08 19:27:41 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 
> alert certificate unknown (1/0)
> 2015/02/08 19:27:42 kid1| fwdNegotiateSSL: Error negotiating SSL 
> connection on FD 51: error:14090086:SSL 
> routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
> 2015/02/08 19:27:42 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 50: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 
> alert certificate unknown (1/0)
> 2015/02/08 19:27:42 kid1| clientNegotiateSSL: Error negotiating SSL 
> connection on FD 52: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 
> alert certificate unknown (1/0)
>
> Is there a way for me to intercept these and, when they happen, allow 
> a direct connection between the client and the destination?
>
> In other words, I want to ssl-bump ALL connections *but*, if we 
> encounter certificate errors, I would like to make a direct connection 
> instead. Is this possible?
>
> Thank you,
> Luis
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150211/b75553e4/attachment.htm>

From ansalonistefano at gmail.com  Wed Feb 11 09:35:04 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Wed, 11 Feb 2015 10:35:04 +0100
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <957440820.348223543.1423642564009.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1251123883.343140390.1423479615293.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <957440820.348223543.1423642564009.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CALkTbde=3v1OBCvck7jFcVp4PaAkotPu-QnXHrH=GZe2N=4KLg@mail.gmail.com>

Here is the output of "grep assert /var/log/squid/cache.log":
2015/02/11 08:33:49 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:38:05 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:41:48 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:41:53 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:41:59 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:42:57 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:43:17 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:46:54 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:46:59 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 09:48:13 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 10:15:51 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 10:17:52 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 10:23:01 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 10:28:04 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 10:28:08 kid1| assertion failed: store.cc:1887: "isEmpty()"
2015/02/11 10:28:25 kid1| assertion failed: store.cc:1887: "isEmpty()"


From fredbmail at free.fr  Wed Feb 11 09:46:20 2015
From: fredbmail at free.fr (FredB)
Date: Wed, 11 Feb 2015 10:46:20 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbde=3v1OBCvck7jFcVp4PaAkotPu-QnXHrH=GZe2N=4KLg@mail.gmail.com>
Message-ID: <375954204.348450738.1423647980817.JavaMail.root@zimbra4-e1.priv.proxad.net>


> Here is the output of "grep assert /var/log/squid/cache.log":
> 2015/02/11 08:33:49 kid1| assertion failed: store.cc:1887:
> "isEmpty()"
> 2015/02/11 09:38:05 kid1| assertion failed: store.cc:1887:
> "isEmpty()"


Ok it's what I think .. Please can you remove/format your cache a retry. 
This is a migration ? I mean from squid 3.x to 3.5 ?

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From ansalonistefano at gmail.com  Wed Feb 11 10:00:02 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Wed, 11 Feb 2015 11:00:02 +0100
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <375954204.348450738.1423647980817.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <CALkTbde=3v1OBCvck7jFcVp4PaAkotPu-QnXHrH=GZe2N=4KLg@mail.gmail.com>
 <375954204.348450738.1423647980817.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CALkTbddgotLL9-Z_QOQZfivzOZpsRqBCEgzFW0vOOPTDzfNuCw@mail.gmail.com>

Sorry for the noob question: is there a special command to wipe the cache?

As I wrote in the first message, I upgraded from 3.4.10 to 3.5.1.


From Silamael at coronamundi.de  Wed Feb 11 10:02:47 2015
From: Silamael at coronamundi.de (Silamael)
Date: Wed, 11 Feb 2015 11:02:47 +0100
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
Message-ID: <54DB28C7.8000906@coronamundi.de>

Hi,

One of our customers does constantly mirroring of some FTP directories
and noticed a huge memory consumption of Squid. As far as I can see with
squidclient mgr:mem, the 2K buffers are constantly increasing if Squid
is processing FTP requests like wget ftp://some.server/pub/ or wget -m
ftp://...
In my tests the first variant resulted in an increase of 29 kb per request.
If I directly request a certain file, the increase of the 2K buffers
seems not to happen.
I have reproduced this behaviour with both squid 3.2.13 and also 3.4.6
and 3.4.11.

Greeting,
Matthias


From yvoinov at gmail.com  Wed Feb 11 10:05:52 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 16:05:52 +0600
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbddgotLL9-Z_QOQZfivzOZpsRqBCEgzFW0vOOPTDzfNuCw@mail.gmail.com>
References: <CALkTbde=3v1OBCvck7jFcVp4PaAkotPu-QnXHrH=GZe2N=4KLg@mail.gmail.com>
 <375954204.348450738.1423647980817.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <CALkTbddgotLL9-Z_QOQZfivzOZpsRqBCEgzFW0vOOPTDzfNuCw@mail.gmail.com>
Message-ID: <54DB2980.8060105@gmail.com>


11.02.15 16:00, Stefano Ansaloni ?????:
> Sorry for the noob question: is there a special command to wipe the cache?
Yes, rm -Rf * :) Or, unlink on ufs :)

>
> As I wrote in the first message, I upgraded from 3.4.10 to 3.5.1.
They uses the same cache format.

> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Wed Feb 11 10:10:33 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 16:10:33 +0600
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DB28C7.8000906@coronamundi.de>
References: <54DB28C7.8000906@coronamundi.de>
Message-ID: <54DB2A99.4000009@gmail.com>

Squid first saves object in memory. Then swapout object to cache. As usual:

# MEMORY CACHE OPTIONS
# 
-----------------------------------------------------------------------------

#  TAG: cache_mem    (bytes)
#    NOTE: THIS PARAMETER DOES NOT SPECIFY THE MAXIMUM PROCESS SIZE.
#    IT ONLY PLACES A LIMIT ON HOW MUCH ADDITIONAL MEMORY SQUID WILL
#    USE AS A MEMORY CACHE OF OBJECTS. SQUID USES MEMORY FOR OTHER
#    THINGS AS WELL. SEE THE SQUID FAQ SECTION 8 FOR DETAILS.
#
#    'cache_mem' specifies the ideal amount of memory to be used
#    for:
#        * In-Transit objects
#        * Hot Objects
#        * Negative-Cached objects
#
#    Data for these objects are stored in 4 KB blocks.  This
#    parameter specifies the ideal upper limit on the total size of
#    4 KB blocks allocated.  In-Transit objects take the highest
#    priority.
#
#    In-transit objects have priority over the others.  When
#    additional space is needed for incoming data, negative-cached
#    and hot objects will be released.  In other words, the
#    negative-cached and hot objects will fill up any unused space
#    not needed for in-transit objects.
#
#    If circumstances require, this limit will be exceeded.
#    Specifically, if your incoming request rate requires more than
#    'cache_mem' of memory to hold in-transit objects, Squid will
#    exceed this limit to satisfy the new requests.  When the load
#    decreases, blocks will be freed until the high-water mark is
#    reached.  Thereafter, blocks will be used to store hot
#    objects.
#
#    If shared memory caching is enabled, Squid does not use the shared
#    cache space for in-transit objects, but they still consume as much
#    local memory as they need. For more details about the shared memory
#    cache, see memory_cache_shared.
#Default:
# cache_mem 256 MB

#  TAG: maximum_object_size_in_memory    (bytes)
#    Objects greater than this size will not be attempted to kept in
#    the memory cache. This should be set high enough to keep objects
#    accessed frequently in memory to improve performance whilst low
#    enough to keep larger objects from hoarding cache_mem.
#Default:
# maximum_object_size_in_memory 512 KB

#  TAG: memory_cache_shared    on|off
#    Controls whether the memory cache is shared among SMP workers.
#
#    The shared memory cache is meant to occupy cache_mem bytes and replace
#    the non-shared memory cache, although some entities may still be
#    cached locally by workers for now (e.g., internal and in-transit
#    objects may be served from a local memory cache even if shared memory
#    caching is enabled).
#
#    By default, the memory cache is shared if and only if all of the
#    following conditions are satisfied: Squid runs in SMP mode with
#    multiple workers, cache_mem is positive, and Squid environment
#    supports required IPC primitives (e.g., POSIX shared memory segments
#    and GCC-style atomic operations).
#
#    To avoid blocking locks, shared memory uses opportunistic algorithms
#    that do not guarantee that every cachable entity that could have been
#    shared among SMP workers will actually be shared.
#
#    Currently, entities exceeding 32KB in size cannot be shared.
#Default:
# "on" where supported if doing memory caching with multiple SMP workers.

#  TAG: memory_cache_mode
#    Controls which objects to keep in the memory cache (cache_mem)
#
#    always    Keep most recently fetched objects in memory (default)
#
#    disk    Only disk cache hits are kept in memory, which means
#        an object must first be cached on disk and then hit
#        a second time before cached in memory.
#
#    network    Only objects fetched from network is kept in memory
#Default:
# Keep the most recently fetched objects in memory

This is no memory leaking, but normal cache behaviour. As documented.

You can play around with range_offset_limit and quick_abort_min parameters.

Or try to no cache this FTP with ACL.

Usually, when suggests memory leaking, this often OS issue. Not Squid.

11.02.15 16:02, Silamael ?????:
> Hi,
>
> One of our customers does constantly mirroring of some FTP directories
> and noticed a huge memory consumption of Squid. As far as I can see with
> squidclient mgr:mem, the 2K buffers are constantly increasing if Squid
> is processing FTP requests like wget ftp://some.server/pub/ or wget -m
> ftp://...
> In my tests the first variant resulted in an increase of 29 kb per request.
> If I directly request a certain file, the increase of the 2K buffers
> seems not to happen.
> I have reproduced this behaviour with both squid 3.2.13 and also 3.4.6
> and 3.4.11.
>
> Greeting,
> Matthias
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Feb 11 10:13:13 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Feb 2015 23:13:13 +1300
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54DB2980.8060105@gmail.com>
References: <CALkTbde=3v1OBCvck7jFcVp4PaAkotPu-QnXHrH=GZe2N=4KLg@mail.gmail.com>
 <375954204.348450738.1423647980817.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <CALkTbddgotLL9-Z_QOQZfivzOZpsRqBCEgzFW0vOOPTDzfNuCw@mail.gmail.com>
 <54DB2980.8060105@gmail.com>
Message-ID: <54DB2B39.6050201@treenet.co.nz>

On 11/02/2015 11:05 p.m., Yuri Voinov wrote:
> 
> 11.02.15 16:00, Stefano Ansaloni ?????:
>> Sorry for the noob question: is there a special command to wipe the
>> cache?
> Yes, rm -Rf * :) Or, unlink on ufs :)


If you get this in time. I am looking for a copy of a swap.state file
from a proxy which is having these issues.

Also,
<http://wiki.squid-cache.org/SquidFaq/OperatingSquid#How_can_I_delete_a_cache_directory.3F>


Amos



From fredbmail at free.fr  Wed Feb 11 10:14:31 2015
From: fredbmail at free.fr (FredB)
Date: Wed, 11 Feb 2015 11:14:31 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <CALkTbddgotLL9-Z_QOQZfivzOZpsRqBCEgzFW0vOOPTDzfNuCw@mail.gmail.com>
Message-ID: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>

> Sorry for the noob question: is there a special command to wipe the
> cache?
> 

Depends, If your cache is not big a rm or mv is enough http://wiki.squid-cache.org/SquidFaq/OperatingSquid#I_want_to_restart_Squid_with_an_empty_cache 
Don't forget "squid -z" after 

> As I wrote in the first message, I upgraded from 3.4.10 to 3.5.1.
> _______________________________________________


Yes, I mean upgrade with the same cache (without purge)
I guess there is a problem between the 3.4 and 3.5

Shame on me, our problems are not related with auth or SSL at all .. 
The answer was in cache.log but I searched something particular with debug mode and grep command ...

--

Regards,

Fred

http://numsys.eu
http://e2guardian.org


From yvoinov at gmail.com  Wed Feb 11 10:17:48 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 16:17:48 +0600
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <54DB2C4C.4020600@gmail.com>


11.02.15 16:14, FredB ?????:
>> Sorry for the noob question: is there a special command to wipe the
>> cache?
>>
> Depends, If your cache is not big a rm or mv is enough http://wiki.squid-cache.org/SquidFaq

Fred, this is no matter. Millions of files can remove with one piped 
command:

*find . |xargs rm

:)
*
> /OperatingSquid#I_want_to_restart_Squid_with_an_empty_cache
> Don't forget "squid -z" after
>
>> As I wrote in the first message, I upgraded from 3.4.10 to 3.5.1.
>> _______________________________________________
>
> Yes, I mean upgrade with the same cache (without purge)
> I guess there is a problem between the 3.4 and 3.5
>
> Shame on me, our problems are not related with auth or SSL at all ..
> The answer was in cache.log but I searched something particular with debug mode and grep command ...
>
> --
>
> Regards,
>
> Fred
>
> http://numsys.eu
> http://e2guardian.org
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150211/75cd8e10/attachment.htm>

From fredbmail at free.fr  Wed Feb 11 10:25:34 2015
From: fredbmail at free.fr (FredB)
Date: Wed, 11 Feb 2015 11:25:34 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <1251123883.343140390.1423479615293.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <162051299.348539822.1423650334755.JavaMail.root@zimbra4-e1.priv.proxad.net>



> Yes I known, but in this case the NONCE was valid, I'm trying with a
> very long time TTL.
> 
> 

Amos

So, Crash -> SWAP_FAIL -> blank page -> 407 -> New nonce

Elementary, my dear Watson ...

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From ansalonistefano at gmail.com  Wed Feb 11 11:02:21 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Wed, 11 Feb 2015 12:02:21 +0100
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <162051299.348539822.1423650334755.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1251123883.343140390.1423479615293.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <162051299.348539822.1423650334755.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CALkTbdcYyQ4=M2D4Dm5Cp2A-_gkbquJH2Wt1K7a_6uFxFoNWPw@mail.gmail.com>

> I am looking for a copy of a swap.state file
> from a proxy which is having these issues.
I will send you the file in private.


> Yes, I mean upgrade with the same cache (without purge)
Yes, I upgraded from 3.4.10 to 3.5.1 without cache purge.


Now testing with empy cache (hoping everything will work as expected).


From eliezer at ngtech.co.il  Wed Feb 11 11:38:08 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 Feb 2015 13:38:08 +0200
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54DB2C4C.4020600@gmail.com>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <54DB2C4C.4020600@gmail.com>
Message-ID: <54DB3F20.3060103@ngtech.co.il>

On 11/02/2015 12:17, Yuri Voinov wrote:
> Fred, this is no matter. Millions of files can remove with one piped
> command:
>
> *find . |xargs rm
>
> :)
> *

And it should be used wisely!!!!!
Any recommendation to run rm should take in account that the rm can in a 
way wipe out files which you might not understand their meaning.
Run the rm only inside the cache_dir after verifying that you are in the 
right place and it is the right time to run the command.

Eliezer




From eliezer at ngtech.co.il  Wed Feb 11 11:42:19 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 Feb 2015 13:42:19 +0200
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <1569464157.334517175.1423127868181.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1569464157.334517175.1423127868181.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <54DB401B.2090300@ngtech.co.il>

On 05/02/2015 11:17, FredB wrote:
> Squid Cache: Version 3.5.1-20150201-r13744
> Service Name: squid
> configure options:  '--build=x86_64-linux-gnu' '--prefix=/' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=/usr/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-auth-negotiate--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-basic-auth-helpers=LDAP,digest' '--enable-digest-auth-helpers=ldap,password' '--enable-arp-acl' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-filedescriptors=65536' '--with-large-files' '--disable-snmp' '--with-default-user=squid' '--disable-ipv6' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -g -Wall -
O2' 'LDFLAGS=' 'CPPFLAGS=' 'CXXFLAGS=-g -O2 -g -Wall -O2' '--enable-ltdl-convenience'


Things about this build:
- it has no rock cache support.(which is kind of a thing in this new 
version of squid)

How big is the cache_dir? it is now maybe late to ask but, can you try 
to compile squid with rock cache_dir support and try to actually use 
it?.. it will be much more SMP friendly.

Eliezer




From yvoinov at gmail.com  Wed Feb 11 11:43:10 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 17:43:10 +0600
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54DB3F20.3060103@ngtech.co.il>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <54DB2C4C.4020600@gmail.com> <54DB3F20.3060103@ngtech.co.il>
Message-ID: <54DB404E.8040305@gmail.com>

Thanks, Captain :)))))))))))

Eliezer, we not so stupid. :)))))))))

This is obvious for System Administrator, isn't it?

11.02.15 17:38, Eliezer Croitoru ?????:
> On 11/02/2015 12:17, Yuri Voinov wrote:
>> Fred, this is no matter. Millions of files can remove with one piped
>> command:
>>
>> *find . |xargs rm
>>
>> :)
>> *
>
> And it should be used wisely!!!!!
> Any recommendation to run rm should take in account that the rm can in 
> a way wipe out files which you might not understand their meaning.
> Run the rm only inside the cache_dir after verifying that you are in 
> the right place and it is the right time to run the command.
>
> Eliezer
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From Silamael at coronamundi.de  Wed Feb 11 11:51:41 2015
From: Silamael at coronamundi.de (Silamael)
Date: Wed, 11 Feb 2015 12:51:41 +0100
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DB2A99.4000009@gmail.com>
References: <54DB28C7.8000906@coronamundi.de> <54DB2A99.4000009@gmail.com>
Message-ID: <54DB424D.8080501@coronamundi.de>

On 02/11/2015 11:10 AM, Yuri Voinov wrote:
> Squid first saves object in memory. Then swapout object to cache. As usual:
> This is no memory leaking, but normal cache behaviour. As documented.
> 
> You can play around with range_offset_limit and quick_abort_min parameters.
> 
> Or try to no cache this FTP with ACL.
> 
> Usually, when suggests memory leaking, this often OS issue. Not Squid.

Hello Yuri,

Thanks for your quick reply.
The ACL you suggested will probably solve the problem.

Nevertheless I'm not sure that this is working as intended as the memory
used by Squid is constantly increasing and not settling after a while.
How does range_offset_limit is relevant for FTP requests?
quick_abort_min does not make any sense for me as there are no aborted
requests in my test case.

It seems more that Squid generates the index.html when I do a wget
ftp://foo.bar/pub/ and does not free the cached object later on.

Just for the records, the memory footprint of the process serving the
FTP request is 10 times higher than the one of Squids processing normal
web traffic at a high request rate.

-- Matthias


From eliezer at ngtech.co.il  Wed Feb 11 12:09:34 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 Feb 2015 14:09:34 +0200
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
 <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
Message-ID: <54DB467E.10106@ngtech.co.il>

Hey Dan,

First I must admit that this squid.conf is quite complicated but kind of 
self explanatory.

I have tried to understand the next lines:
# File size (download) restrictions
acl response_size_100 external response_size_type 100 192.168.0.10
http_access allow response_size_100 response_size_100
reply_body_max_size 100 MB response_size_100

But I am unsure how it works with external_acl exactly.
If you wish to deny 100MB size files you should have only one rule for 
the reply body max size, what are the others for exactly?

Eliezer

* I might missing some concepts some sorry in advance.

On 11/02/2015 00:30, Dan Charlesworth wrote:
> Hi Eliezer
>
> Took a while to get this up?sorry about that. Here?s an example of a production config of ours (with some confidential stuff necessarily taken out/edited):
> https://gist.github.com/djch/92cf44440b04afbd7917  <https://gist.github.com/djch/92cf44440b04afbd7917>
>
> Let me know if there?s any other info I can provide that might point towards the cause of this crash.
>
> And thanks again for taking a look.




From Antony.Stone at squid.open.source.it  Wed Feb 11 12:20:53 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 11 Feb 2015 12:20:53 +0000
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54DB404E.8040305@gmail.com>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <54DB3F20.3060103@ngtech.co.il> <54DB404E.8040305@gmail.com>
Message-ID: <201502111220.53633.Antony.Stone@squid.open.source.it>

On Wednesday 11 Feb 2015 at 11:43, Yuri Voinov wrote:

> Thanks, Captain :)))))))))))
> 
> Eliezer, we not so stupid. :)))))))))
> 
> This is obvious for System Administrator, isn't it?

You never know who may come across this "recommendation" in the mailing list 
archives in months or years to come, and apply it without realising its 
dangers.

This is not just a reply to the original poster, this will stay on the 
Internet for ever (or at least until the Internet disappears and is replaced 
by something even more bizarre and inexplicable).

> 11.02.15 17:38, Eliezer Croitoru ?????:
> > On 11/02/2015 12:17, Yuri Voinov wrote:
> >> Fred, this is no matter. Millions of files can remove with one piped
> >> command:
> >> 
> >> *find . |xargs rm
> >> 
> >> :)
> >> 
> >> *
> > 
> > And it should be used wisely!!!!!
> > Any recommendation to run rm should take in account that the rm can in
> > a way wipe out files which you might not understand their meaning.
> > Run the rm only inside the cache_dir after verifying that you are in
> > the right place and it is the right time to run the command.

Regards,


Antony.

-- 
"Black holes are where God divided by zero."

 - Steven Wright

                                                   Please reply to the list;
                                                         please *don't* CC me.


From eliezer at ngtech.co.il  Wed Feb 11 12:32:47 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 Feb 2015 14:32:47 +0200
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <201502111220.53633.Antony.Stone@squid.open.source.it>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <54DB3F20.3060103@ngtech.co.il> <54DB404E.8040305@gmail.com>
 <201502111220.53633.Antony.Stone@squid.open.source.it>
Message-ID: <54DB4BEF.6050509@ngtech.co.il>

+1 for Anthony reply.

Eliezer

On 11/02/2015 14:20, Antony Stone wrote:
> On Wednesday 11 Feb 2015 at 11:43, Yuri Voinov wrote:
>
>> Thanks, Captain :)))))))))))
>>
>> Eliezer, we not so stupid. :)))))))))
>>
>> This is obvious for System Administrator, isn't it?
>
> You never know who may come across this "recommendation" in the mailing list
> archives in months or years to come, and apply it without realising its
> dangers.
>
> This is not just a reply to the original poster, this will stay on the
> Internet for ever (or at least until the Internet disappears and is replaced
> by something even more bizarre and inexplicable).
>
>> 11.02.15 17:38, Eliezer Croitoru ?????:
>>> On 11/02/2015 12:17, Yuri Voinov wrote:
>>>> Fred, this is no matter. Millions of files can remove with one piped
>>>> command:
>>>>
>>>> *find . |xargs rm
>>>>
>>>> :)
>>>>
>>>> *
>>>
>>> And it should be used wisely!!!!!
>>> Any recommendation to run rm should take in account that the rm can in
>>> a way wipe out files which you might not understand their meaning.
>>> Run the rm only inside the cache_dir after verifying that you are in
>>> the right place and it is the right time to run the command.
>
> Regards,
>
>
> Antony.
>




From Richard.Aspley at hammonds-uk.com  Wed Feb 11 12:35:19 2015
From: Richard.Aspley at hammonds-uk.com (Rich549)
Date: Wed, 11 Feb 2015 04:35:19 -0800 (PST)
Subject: [squid-users] Squid 3.5.1 NTLM and LDAP
In-Reply-To: <54DA6255.5070502@treenet.co.nz>
References: <1423575594700-4669661.post@n4.nabble.com>
 <54DA6255.5070502@treenet.co.nz>
Message-ID: <1423658119022-4669727.post@n4.nabble.com>

*Ok, I've made all of the advised changes and it still didn't work.

I've just tried pasting my helper command into command prompt and it just
seems to hang.  I tried the following:*

-----
D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -d -S -b
"ou=Domain_Groups,dc=domain-uk,dc=com" -f  %g=Internet_Users -h
srvham09.domain-uk.com

D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -d -S -b
"ou=Domain_Groups,dc=domain-uk,dc=com" -f Internet_Users -h
srvham09.domain-uk.com

D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -d -b
"ou=Domain_Groups,dc=domain-uk,dc=com" -f %u "Internet_Users" -h
srvham09.domain-uk.com

D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -d -b
ou=Domain_Groups,dc=domain-uk,dc=com -f %u %g=Internet_Users -h
srvham09.domain-uk.com

D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -v 2 -d -b
ou=Domain_Groups,dc=domain-uk,dc=com -f Internet_Users -h
srvham09.domain-uk.com
-----

*I'm also seeing the following in the cache.log each time I try to access a
webpage as a user who is a member of Internet_Users, is this anything to be
concerned about?*
----
2015/02/11 12:21:47 kid1| helperOpenServers: Starting 1/80 'ntlm_fake_auth'
processes
2015/02/11 12:21:47 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
----

*And now, just to top things off I have errors in the cache.log stating:*

d:/Squid/lib/squid/ext_ldap_group_acl.exe: (6) No such device or address

*Quickly losing faith :-(*



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-1-NTLM-and-LDAP-tp4669661p4669727.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Feb 11 12:56:13 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 18:56:13 +0600
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <201502111220.53633.Antony.Stone@squid.open.source.it>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <54DB3F20.3060103@ngtech.co.il> <54DB404E.8040305@gmail.com>
 <201502111220.53633.Antony.Stone@squid.open.source.it>
Message-ID: <54DB516D.20100@gmail.com>

Natural selection usually takes the most stupid individuals in a 
population. Who am I to stop him?

Electrical outlet, a knife and matches are dangerous. Should I keep 
repeating it, not to forget, and to inspire everyone around us?


11.02.15 18:20, Antony Stone ?????:
> On Wednesday 11 Feb 2015 at 11:43, Yuri Voinov wrote:
>
>> Thanks, Captain :)))))))))))
>>
>> Eliezer, we not so stupid. :)))))))))
>>
>> This is obvious for System Administrator, isn't it?
> You never know who may come across this "recommendation" in the mailing list
> archives in months or years to come, and apply it without realising its
> dangers.
This is not just a reply to the original poster, this will stay on the 
Internet for ever (or at least until the Internet disappears and is 
replaced by something even more bizarre and inexplicable).
>> 11.02.15 17:38, Eliezer Croitoru ?????:
>>> On 11/02/2015 12:17, Yuri Voinov wrote:
>>>> Fred, this is no matter. Millions of files can remove with one piped
>>>> command:
>>>>
>>>> *find . |xargs rm
>>>>
>>>> :)
>>>>
>>>> *
>>> And it should be used wisely!!!!!
>>> Any recommendation to run rm should take in account that the rm can in
>>> a way wipe out files which you might not understand their meaning.
>>> Run the rm only inside the cache_dir after verifying that you are in
>>> the right place and it is the right time to run the command.
> Regards,
>
>
> Antony.
>



From Silamael at coronamundi.de  Wed Feb 11 13:07:57 2015
From: Silamael at coronamundi.de (Silamael)
Date: Wed, 11 Feb 2015 14:07:57 +0100
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DB424D.8080501@coronamundi.de>
References: <54DB28C7.8000906@coronamundi.de> <54DB2A99.4000009@gmail.com>
 <54DB424D.8080501@coronamundi.de>
Message-ID: <54DB542D.9060303@coronamundi.de>

On 02/11/2015 12:51 PM, Silamael wrote:
> On 02/11/2015 11:10 AM, Yuri Voinov wrote:
>> Squid first saves object in memory. Then swapout object to cache. As usual:
>> This is no memory leaking, but normal cache behaviour. As documented.
>>
>> You can play around with range_offset_limit and quick_abort_min parameters.
>>
>> Or try to no cache this FTP with ACL.
>>
>> Usually, when suggests memory leaking, this often OS issue. Not Squid.
> 
> Hello Yuri,
> 
> Thanks for your quick reply.
> The ACL you suggested will probably solve the problem.

Just got the info that the customer already has disabled the caching.
Sounds no longer as "normal behaviour" to me.

Greetings,
Matthias


From yvoinov at gmail.com  Wed Feb 11 13:11:58 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 Feb 2015 19:11:58 +0600
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DB542D.9060303@coronamundi.de>
References: <54DB28C7.8000906@coronamundi.de> <54DB2A99.4000009@gmail.com>
 <54DB424D.8080501@coronamundi.de> <54DB542D.9060303@coronamundi.de>
Message-ID: <54DB551E.3070705@gmail.com>


11.02.15 19:07, Silamael ?????:
> On 02/11/2015 12:51 PM, Silamael wrote:
>> On 02/11/2015 11:10 AM, Yuri Voinov wrote:
>>> Squid first saves object in memory. Then swapout object to cache. As usual:
>>> This is no memory leaking, but normal cache behaviour. As documented.
>>>
>>> You can play around with range_offset_limit and quick_abort_min parameters.
>>>
>>> Or try to no cache this FTP with ACL.
>>>
>>> Usually, when suggests memory leaking, this often OS issue. Not Squid.
>> Hello Yuri,
>>
>> Thanks for your quick reply.
>> The ACL you suggested will probably solve the problem.
> Just got the info that the customer already has disabled the caching.
> Sounds no longer as "normal behaviour" to me.
As Amos said, may be - may be not.

Some FTP files pointless to cache.

If it need just once..... For what cache it?
>
> Greetings,
> Matthias
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From rwheeler at artifact-software.com  Tue Feb 10 22:14:30 2015
From: rwheeler at artifact-software.com (Ron Wheeler)
Date: Tue, 10 Feb 2015 17:14:30 -0500
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
Message-ID: <54DA82C6.9060305@artifact-software.com>

You could process the logs and set some rules about what period between 
transactions should count as a single visit.
ie if ip  123.123.1.23 made requests at
9:01
9:03
9:15
9:50
9:51 and
9:54,
is this one visit of 53 minutes (total time 53 minutes) or
3 visits of 2 minutes, 0 minutes and 4 minutes (total time 6 minutes) or
2 visits of 14 minutes and  4 minutes (total time 18 minutes)

Each of these calculations is defensible and easy to do with a rather 
trivial program that reads the log.

Ron

On 10/02/2015 4:50 PM, Luis Miguel Silva wrote:
> Dear all,
>
> I was wondering if there is a built in feature in Squid to calculate 
> the time spent on a website, per ip address (e.g. 32 minutes between 
> 12pm and 1pm, 5 minutes between 1pm and 2pm)? And, if not, how would 
> you do it?
>
> I immediately thought about using the log files for this BUT, because 
> we only log individual connections, how would you guys conclude the 
> amount of time spent per website? Would you, for instance, for each 5 
> minutes, add 5 minute chunks IF there was data flowing between the 5 
> minutes?
>
> That would work but...Isn't there a more elegant way of doing this?
>
> Thanks,
> Luis
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-- 
Ron Wheeler
President
Artifact Software Inc
email: rwheeler at artifact-software.com
skype: ronaldmwheeler
phone: 866-970-2435, ext 102

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150210/deb8fbc6/attachment.htm>

From ahmed.zaeem at netstream.ps  Thu Feb 12 00:55:21 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Wed, 11 Feb 2015 16:55:21 -0800
Subject: [squid-users] squid authentication , & ACL select from databse SQL ,
	is that possible ?
Message-ID: <003d01d0465e$94d48450$be7d8cf0$@netstream.ps>

Hi 

I need to do many operations :

I need squid with sql with the following needs :

1-      Squid authenticate user/pwd from sql databse.

2-      Then if authentication was okay  , they I need to see that username
logged in and go to sql databse and select from there a cloum with the
websites correspond to that user

3-      Then I will do access list that permit the websites domain name only
for that user based on info from sql.

Is that possible with squid ?

Im using last squid stable version 3.5.1 and hope it be okay .

 

 

cheers

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150211/97ced8b4/attachment.htm>

From ludovit.koren at gmail.com  Wed Feb 11 15:09:31 2015
From: ludovit.koren at gmail.com (Ludovit Koren)
Date: Wed, 11 Feb 2015 16:09:31 +0100
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <mbdqmh$ere$1@ger.gmane.org> (Markus Moeller's message of "Tue,
 10 Feb 2015 20:46:06 -0000")
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
Message-ID: <86h9usfpsk.fsf@gmail.com>

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > Hi Ludovit,
    >  Which Kerberos library version do you use ?    Is it possible that
    > the encryption types don't match ?  I saw in your first email the
    > following:

It is standard Heimdal library on FreeBSD:
# kinit --version
kinit (Heimdal 1.5.2)
Copyright 1995-2011 Kungliga Tekniska H??gskolan
Send bug-reports to heimdal-bugs at h5l.org

FreeBSD 10.1-STABLE #1 r275861

    > Your klist shows a HTTP ticket for arcfour

    > Server: HTTP/squid1.mdpt.local at MDPT.LOCAL
    > Client: HTTP/squid1.mdpt.local at MDPT.LOCAL
    > Ticket etype: arcfour-hmac-md5, kvno 8
    > Ticket length: 1090
    > Auth time:  Feb  9 14:55:18 2015
    > Start time: Feb  9 14:55:20 2015
    > End time:   Feb 10 00:55:18 2015
    > Ticket flags: enc-pa-rep, pre-authent
    > Addresses: addressless

    > but the keytab has aes128.

    > # ktutil -k /etc/krb5.keytab list
    > /etc/krb5.keytab:

    > Vno  Type                     Principal                          Aliases
    >  8  aes128-cts-hmac-sha1-96  HTTP/squid1.mdpt.local at MDPT.LOCAL


You are right... I tried to find out how to change it. Is it option on
KDC server? I am not able to find anything relevant. 


lk


From Silamael at coronamundi.de  Wed Feb 11 15:14:11 2015
From: Silamael at coronamundi.de (Silamael)
Date: Wed, 11 Feb 2015 16:14:11 +0100
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DB551E.3070705@gmail.com>
References: <54DB28C7.8000906@coronamundi.de> <54DB2A99.4000009@gmail.com>
 <54DB424D.8080501@coronamundi.de> <54DB542D.9060303@coronamundi.de>
 <54DB551E.3070705@gmail.com>
Message-ID: <54DB71C3.5060301@coronamundi.de>

On 02/11/2015 02:11 PM, Yuri Voinov wrote:
> 
> 11.02.15 19:07, Silamael ?????:
>> On 02/11/2015 12:51 PM, Silamael wrote:
>>> On 02/11/2015 11:10 AM, Yuri Voinov wrote:
>>>> Squid first saves object in memory. Then swapout object to cache. As
>>>> usual:
>>>> This is no memory leaking, but normal cache behaviour. As documented.
>>>>
>>>> You can play around with range_offset_limit and quick_abort_min
>>>> parameters.
>>>>
>>>> Or try to no cache this FTP with ACL.
>>>>
>>>> Usually, when suggests memory leaking, this often OS issue. Not Squid.
>>> Hello Yuri,
>>>
>>> Thanks for your quick reply.
>>> The ACL you suggested will probably solve the problem.
>> Just got the info that the customer already has disabled the caching.
>> Sounds no longer as "normal behaviour" to me.
> As Amos said, may be - may be not.

Amos said something? Got no mail from him.

> Some FTP files pointless to cache.

Sure, maybe some FTP files are not to be cached.

> 
> If it need just once..... For what cache it?

I do not want to cache any. And I think a 'cache deny all' does that.
Nevertheless, even with no caching at all the Squid process constantly
needs more memory and squidclient reports that the memory is used for
the 2K buffers.

Just try it. Squid with default configuration and cache deny all and
then do some wget ftp://server/path/. Each requests will increase the 2K
buffers.

-- Matthias


From leolistas at solutti.com.br  Wed Feb 11 15:24:35 2015
From: leolistas at solutti.com.br (Leonardo Rodrigues)
Date: Wed, 11 Feb 2015 13:24:35 -0200
Subject: [squid-users] Calculate time spent on website (per ip address)
In-Reply-To: <54DA84FE.7040703@gmail.com>
References: <CA+suCFg5V5UXiJDDT-b6VwqKV48L0zyVM4_zN_dV5oMDuNbbAg@mail.gmail.com>
 <54DA8345.5010802@treenet.co.nz> <54DA84FE.7040703@gmail.com>
Message-ID: <54DB7433.5020605@solutti.com.br>

On 10/02/15 20:23, Yuri Voinov wrote:
>
> HTTP is stateless protocol (in most cases, excluding presistant
> connections). So, it is impossible to determine how much time user
> spent on site. Only very approximately. Right?
>
>

     in most cases, probably not even close to the real deal !

-- 


	Atenciosamente / Sincerily,
	Leonardo Rodrigues
	Solutti Tecnologia
	http://www.solutti.com.br

	Minha armadilha de SPAM, N?O mandem email
	gertrudes at solutti.com.br
	My SPAMTRAP, do not email it





From alberto2perez at gmail.com  Wed Feb 11 15:43:01 2015
From: alberto2perez at gmail.com (Alberto Perez)
Date: Wed, 11 Feb 2015 10:43:01 -0500
Subject: [squid-users] Receiving blank input in External ACL
Message-ID: <CAMZauGqJ8F9PB+XBqB24rbWnrhFumiTX7ArX9RrCBE12bR7xFg@mail.gmail.com>

Hi to all  and thanks for the time given to read and reply these emails


I am having an strange issue with my external ACL, ocassionally im
getting blank inputs from squid to by proccessed by the external ACL,
for those cases I am returning ERR but squid is complainting showing
in cache.log errors like

2015/02/11 10:01:36| helperHandleRead: unexpected read from
session_active_def #Hlpr5, 4 bytes 'ERR
'

My question is, what should I return in those cases? its normal to
recieve those blanks? how to avoid them if possible?

Im worried about this detail because related to this events (only some
times) squid stop serving to client who fired the event, client has to
change IP to continue surfing.

Here is the definition of the external ACL, its supposed to receive IP

# Set up the normal session helper.
external_acl_type session_active_def concurrency=1 children-max=15
children-startup=12  ipv4 ttl=3 negative_ttl=1 %SRC
/etc/squid3/captive/sessionHelper.php

And here the code

#!/usr/bin/php
<?php
error_reporting(0);
$meminstance = new Memcache();
$meminstance->pconnect('127.0.0.1', 11211);
ini_set("memory_limit",($memoryLimit=512)."M");
while (!@feof(STDIN)) {
try{

	$line = trim(fgets(STDIN));
	if (!$line) { shell_exec("echo \"SESSION - No client ip error: \"
".$line." - "." - $(date) >> /var/log/squid3/session.log");
fwrite(STDOUT, "ERR\n"); continue;}

	$line = explode(" ", $line);

	$clientip = count($line > 1)?$line[1]:false; //1738

	if (!$clientip) { shell_exec("echo \"SESSION - No client ip error: \"
".$line." - "." - $(date) >> /var/log/squid3/session.log");
fwrite(STDOUT, "ERR\n"); continue;}

	 $username = $meminstance->get($clientip);
	$hasInternet = $username?$meminstance->get("has_internet_$username"):false;
	if ($username && $hasInternet){
			// extend session
 			$meminstance->set($clientip, $username, 0,3600); // extend 10 min
			$meminstance->set("ip_".$username, $clientip, 0, 3600); // 10 min
			$meminstance->set("has_internet_".$username, true, 0, 3600); // 10 min
	                fwrite(STDOUT, "OK user=$username\n");
	}else{
        	fwrite(STDOUT, "ERR\n");
	}
}catch(Exception $e){
        	fwrite(STDOUT, "BH\n");
}
}
exit;
?>



Thanks to all


From squid at visolve.com  Wed Feb 11 18:12:36 2015
From: squid at visolve.com (squid-list)
Date: Wed, 11 Feb 2015 23:42:36 +0530
Subject: [squid-users] squid authentication ,
 & ACL select from databse SQL , is that possible ?
In-Reply-To: <003d01d0465e$94d48450$be7d8cf0$@netstream.ps>
References: <003d01d0465e$94d48450$be7d8cf0$@netstream.ps>
Message-ID: <54DB9B94.5000304@visolve.com>

Hi,

You can authenticate user and password from sql database using the 
helper "squid_db_auth".

But, allowing website for corresponding user by storing in db is not 
possible. You can use various ACLs to control the site access for the 
individual users.

Instead of storing website in particular column in db, you can store it 
in separate txt file and can control the site access of the users.

Squid will support user defined helper. If it necessary to verify site 
from db, you can create your own helper as per you requirement and you 
can use it. If you need any customization assistance, you can contact 
us(squid at visolve.com).

Regards,
Siva Prakash
ViSolve Squid Team

On 02/12/2015 06:25 AM, snakeeyes wrote:
>
> Hi
>
> I need to do many operations :
>
> I need squid with sql with the following needs :
>
> 1-Squid authenticate user/pwd from sql databse.
>
> 2-Then if authentication was okay  , they I need to see that username 
> logged in and go to sql databse and select from there a cloum with the 
> websites correspond to that user
>
> 3-Then I will do access list that permit the websites domain name only 
> for that user based on info from sql.
>
> Is that possible with squid ?
>
> Im using last squid stable version 3.5.1 and hope it be okay .
>
> cheers
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150211/0e898a0e/attachment.htm>

From eliezer at ngtech.co.il  Wed Feb 11 18:25:15 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 Feb 2015 20:25:15 +0200
Subject: [squid-users] Receiving blank input in External ACL
In-Reply-To: <CAMZauGqJ8F9PB+XBqB24rbWnrhFumiTX7ArX9RrCBE12bR7xFg@mail.gmail.com>
References: <CAMZauGqJ8F9PB+XBqB24rbWnrhFumiTX7ArX9RrCBE12bR7xFg@mail.gmail.com>
Message-ID: <54DB9E8B.1000203@ngtech.co.il>

Hey Alberto,

PHP as a squid helper turned to be a bad choice.
I know that Ruby,Python,Perl,Golang and many others do work fine with squid.

All The Bests,
Eliezer

On 11/02/2015 17:43, Alberto Perez wrote:
> # Set up the normal session helper.
> external_acl_type session_active_def concurrency=1 children-max=15
> children-startup=12  ipv4 ttl=3 negative_ttl=1 %SRC
> /etc/squid3/captive/sessionHelper.php
>
> And here the code
>
> #!/usr/bin/php
> <?php
> error_reporting(0);
> $meminstance = new Memcache();
> $meminstance->pconnect('127.0.0.1', 11211);
> ini_set("memory_limit",($memoryLimit=512)."M");
> while (!@feof(STDIN)) {
> try{
>
> 	$line = trim(fgets(STDIN));
> 	if (!$line) { shell_exec("echo \"SESSION - No client ip error: \"
> ".$line." - "." - $(date) >> /var/log/squid3/session.log");
> fwrite(STDOUT, "ERR\n"); continue;}
>
> 	$line = explode(" ", $line);
>
> 	$clientip = count($line > 1)?$line[1]:false; //1738
>
> 	if (!$clientip) { shell_exec("echo \"SESSION - No client ip error: \"
> ".$line." - "." - $(date) >> /var/log/squid3/session.log");
> fwrite(STDOUT, "ERR\n"); continue;}
>
> 	 $username = $meminstance->get($clientip);
> 	$hasInternet = $username?$meminstance->get("has_internet_$username"):false;
> 	if ($username && $hasInternet){
> 			// extend session
>   			$meminstance->set($clientip, $username, 0,3600); // extend 10 min
> 			$meminstance->set("ip_".$username, $clientip, 0, 3600); // 10 min
> 			$meminstance->set("has_internet_".$username, true, 0, 3600); // 10 min
> 	                fwrite(STDOUT, "OK user=$username\n");
> 	}else{
>          	fwrite(STDOUT, "ERR\n");
> 	}
> }catch(Exception $e){
>          	fwrite(STDOUT, "BH\n");
> }
> }
> exit;
> ?>
>
>
>
> Thanks to all




From squid3 at treenet.co.nz  Wed Feb 11 19:56:37 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Feb 2015 08:56:37 +1300
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54DB404E.8040305@gmail.com>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <54DB2C4C.4020600@gmail.com> <54DB3F20.3060103@ngtech.co.il>
 <54DB404E.8040305@gmail.com>
Message-ID: <54DBB3F5.6080902@treenet.co.nz>

On 12/02/2015 12:43 a.m., Yuri Voinov wrote:
> Thanks, Captain :)))))))))))
> 
> Eliezer, we not so stupid. :)))))))))
> 
> This is obvious for System Administrator, isn't it?
> 

Not everybody on this list is a professional. And its public, so random
amateurs using their favourite search engine will find the advice
eventually.

(Thats another reason I'm so verbose/details answering stuff).

Amos



From squid3 at treenet.co.nz  Wed Feb 11 20:00:33 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Feb 2015 09:00:33 +1300
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54DB516D.20100@gmail.com>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <54DB3F20.3060103@ngtech.co.il> <54DB404E.8040305@gmail.com>
 <201502111220.53633.Antony.Stone@squid.open.source.it>
 <54DB516D.20100@gmail.com>
Message-ID: <54DBB4E1.3050605@treenet.co.nz>

On 12/02/2015 1:56 a.m., Yuri Voinov wrote:
> Natural selection usually takes the most stupid individuals in a
> population. Who am I to stop him?
> 
> Electrical outlet, a knife and matches are dangerous. Should I keep
> repeating it, not to forget, and to inspire everyone around us?
> 

You still wouldn't place a stick of dynamite and lit candle in front of
a baby though would you?

FS erasure command lines really are that dangerous. And actually getting
more so in the world where "sysadmin" is coming to include anyone who
can drives a GUI web page with buttons.

Amos



From squid3 at treenet.co.nz  Wed Feb 11 20:05:04 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Feb 2015 09:05:04 +1300
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DB71C3.5060301@coronamundi.de>
References: <54DB28C7.8000906@coronamundi.de> <54DB2A99.4000009@gmail.com>
 <54DB424D.8080501@coronamundi.de> <54DB542D.9060303@coronamundi.de>
 <54DB551E.3070705@gmail.com> <54DB71C3.5060301@coronamundi.de>
Message-ID: <54DBB5F0.9070809@treenet.co.nz>

On 12/02/2015 4:14 a.m., Silamael wrote:
> On 02/11/2015 02:11 PM, Yuri Voinov wrote:
>>
>> 11.02.15 19:07, Silamael ?????:
>>> On 02/11/2015 12:51 PM, Silamael wrote:
>>>> On 02/11/2015 11:10 AM, Yuri Voinov wrote:
>>>>> Squid first saves object in memory. Then swapout object to cache. As
>>>>> usual:
>>>>> This is no memory leaking, but normal cache behaviour. As documented.
>>>>>
>>>>> You can play around with range_offset_limit and quick_abort_min
>>>>> parameters.
>>>>>
>>>>> Or try to no cache this FTP with ACL.
>>>>>
>>>>> Usually, when suggests memory leaking, this often OS issue. Not Squid.
>>>> Hello Yuri,
>>>>
>>>> Thanks for your quick reply.
>>>> The ACL you suggested will probably solve the problem.
>>> Just got the info that the customer already has disabled the caching.
>>> Sounds no longer as "normal behaviour" to me.
>> As Amos said, may be - may be not.
> 
> Amos said something? Got no mail from him.
> 

Must have been earlier threads, this is my first reply in this thread.

>> Some FTP files pointless to cache.
> 
> Sure, maybe some FTP files are not to be cached.
> 
>>
>> If it need just once..... For what cache it?
> 
> I do not want to cache any. And I think a 'cache deny all' does that.

Correct.

> Nevertheless, even with no caching at all the Squid process constantly
> needs more memory and squidclient reports that the memory is used for
> the 2K buffers.
> 
> Just try it. Squid with default configuration and cache deny all and
> then do some wget ftp://server/path/. Each requests will increase the 2K
> buffers.
> 

Thank you. Can you drop that into a bug report please so we dont loose
track of it?

Cheers
Amos



From huaraz at moeller.plus.com  Wed Feb 11 21:07:39 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Wed, 11 Feb 2015 21:07:39 -0000
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <86h9usfpsk.fsf@gmail.com>
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
 <86h9usfpsk.fsf@gmail.com>
Message-ID: <mbggb0$fi0$1@ger.gmane.org>

Hi Ludovit,

   How did you create the keytab ? Usually there is an option allowing you 
to select the encryption type.  The other place to check would be 
/etc/krb5.conf. It can contain a list of supported encryption types. See 
http://www.freebsd.org/cgi/man.cgi?query=krb5.conf&apropos=0&sektion=5&manpath=FreeBSD+Ports+10.1-RELEASE&arch=default&format=html

default_tgs_enctypes, default_tkt_enctypes and permitted_enctypes

Markus

"Ludovit Koren"  wrote in message news:86h9usfpsk.fsf at gmail.com...

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > Hi Ludovit,
    >  Which Kerberos library version do you use ?    Is it possible that
    > the encryption types don't match ?  I saw in your first email the
    > following:

It is standard Heimdal library on FreeBSD:
# kinit --version
kinit (Heimdal 1.5.2)
Copyright 1995-2011 Kungliga Tekniska H??gskolan
Send bug-reports to heimdal-bugs at h5l.org

FreeBSD 10.1-STABLE #1 r275861

    > Your klist shows a HTTP ticket for arcfour

    > Server: HTTP/squid1.mdpt.local at MDPT.LOCAL
    > Client: HTTP/squid1.mdpt.local at MDPT.LOCAL
    > Ticket etype: arcfour-hmac-md5, kvno 8
    > Ticket length: 1090
    > Auth time:  Feb  9 14:55:18 2015
    > Start time: Feb  9 14:55:20 2015
    > End time:   Feb 10 00:55:18 2015
    > Ticket flags: enc-pa-rep, pre-authent
    > Addresses: addressless

    > but the keytab has aes128.

    > # ktutil -k /etc/krb5.keytab list
    > /etc/krb5.keytab:

    > Vno  Type                     Principal 
Aliases
    >  8  aes128-cts-hmac-sha1-96  HTTP/squid1.mdpt.local at MDPT.LOCAL


You are right... I tried to find out how to change it. Is it option on
KDC server? I am not able to find anything relevant.


lk
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From huaraz at moeller.plus.com  Wed Feb 11 21:28:47 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Wed, 11 Feb 2015 21:28:47 -0000
Subject: [squid-users] benefits
	ofusing	ext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <61AFD086-9455-4F6A-AAB7-D6FA761DB63F@open.ch>
References: <61AFD086-9455-4F6A-AAB7-D6FA761DB63F@open.ch>
Message-ID: <mbghik$5br$1@ger.gmane.org>

>>>>> "Amos Jeffries"  wrote in message news:54BE3B5C.8040800 at
>>>>> treenet.co.nz...
>>>>>
>>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>>> Hash: SHA1
>>>>>
>>>>> On 20/01/2015 11:31 p.m., Simon St?heli wrote:
>>>>>> Are there any other benefits in using ext_kerberos_ldap_group_acl
>>>>>> instead of ext_ldap_group_acl except the "Netbios name to Kerberos
>>>>>> domain name? mappings provided by the -N option. As far as I can
>>>>>> tell, this mapping can also easily be done by writing you own
>>>>>> helper perl script which is doing the mapping and finally feeds the
>>>>>> more common ext_ldap_group_acl helper.
>>>>>>
>>>>> Whatever floats your boat. The point of the Addon/Plugin/helpers API
>>>>> is that you can use scripts if thy serve your needs better.
>>>>>
>>>>> All the usual Open Source benefits of "many eyeballs" and somebody
>>>>> else doing code maintenance for you applies to using a bundled helper
>>>>> over a custom written one.
>>>>>
>>>>> Beyond that the kerberos helper also provides automatic detection of
>>>>> which LDAP server to use via mutiple auto-configuration methods.
>>>>>
>>>> The idea of the helper was to automate most of the configuration (
>>>> ignoring
>>>> some performance ) and avoid using a username/password, support users
>>>> from
>>>> multiple domains. Secondly I wanted check for nested groups which was
>>>> not
>>>> available in the existing helper and thirdly I also check now against
>>>> the
>>>> primary group of the user.
>>>>
>>> Thank you Markus for your explanations. I played around with
>>> ext_kerberos_ldap_group_acl and would like to go into some details:
>>>
>>> 1) it is possible to define more than one LDAP server (e.g. for high
>>> availability reasons)? The -l parameter allows only one ldap url while
>>> -S allows several "server > realm" - mappings.
>>>
>> I didn't see the need.  The -l was more for cases when digest or basic 
>> auth
>> is used and I do not know the domain to check against.  So a fallback
>> option.
>My idea was to have a backup ldap / active directory server. Assumed 
>querying _ldap._tcp.REALM returns 3 ldap servers. Are all 3 ldap servers 
>queried successively if a previous is not reachable? And is server defined 
>by the -l parameter being queried if all '_ldap._tcp.REALM' are not 
>reachable?

The 3 servers returned by the SRV will be checked. I will take priority and 
weight into account when choosing which ldap server to check firts.

-l  is used when the user has no REALM information and no default REALM is 
provided and as last resort

>>
>>
>>> 2) It is correct, that compared to ext_ldap_group_acl,
>>> ext_kerberos_ldap_group_acl does not require a groupname as input (from
>>> stdin), because -g -t -T or -D control the group name?!
>>>
>> You have two options with ext_kerberos_ldap_group_acl  as input or as -g 
>> ..
>> control
>Thx, very helpful.
>>
>>> 3) What is the use case for defining -g GROUP@? What is the difference
>>> to -g GROUP (without @)
>>>
>> -g GROUP is for all users including the once with nor provided domain
>Thx, this is clear now as well
>>
>> The an pages describe it a bit under Note:
>>
>> 1) For user at REALM
>>    a) Query DNS for SRV record _ldap._tcp.REALM
>>    b) Query DNS for A record REALM
>>    c) Use LDAP_URL if given
>>
>> 2) For user
>>    a) Use domain -D REALM and follow step 1)
>>    b) Use LDAP_URL if given
>>
>> The Groups to check against are determined as follows:
>>
>> 1) For user at REALM
>>    a)  Use  values  given  by -g option which contain a @REALM e.g. -g
>> GROUP1 at REALM:GROUP2 at REALM
>>    b) Use values given by -g option which contain a  @  only  e.g.  -g
>> GROUP1@:GROUP2@
>>    c)  Use values given by -g option which do not contain a realm e.g.
>> -g GROUP1:GROUP2
>>
>> 2) For user
>>    a) Use values given by -g option which do not contain a realm  e.g.
>> -g GROUP1:GROUP2
>>
>> 3) For NDOMAIN\user
>>    a) Use realm given by -N NDOMAIN at REALM and then use values given by
>> -g option which contain a @REALM e.g. -g GROUP1 at REALM:GROUP2 at REALM
>>
>>
>>
>>> 4) The "query DNS for SRV record _ldap._tcp.REALM" mechanism seems no to
>>> work for me although the DNS server is configured correctly and querying
>>> with "dig SRV _ldap._tcp.REALM" works fine. Anything to consider here?
>>> _ldap._tcp.REALM SRV query was never sent so far.
>>>
>> I would not see an obvious reason.   Does -d show any hints ?  I can only
>> imagine that REAM is not what is send by the client.
>It think I do not fully understand how the determination of the ldap server 
>works. How is the dns query for SRV _ldap._tcp.REALM related to the missing 
>Kerberos configuration? Why does the helper need the principal from the 
>keytab? I am also a bit confused about the _ldap._tcp and the 
>_kerberis._tcp queries. Can you give me an idea how this determination 
>works step for step?

The DNS query is done based on the full name (including domain/realm) of the 
user.   e.g. if the user is abc at DOM1  the helper will look for SRV records 
for _ldap._tcp.DOM1 .   If your Kerberos configuration is for DOM2 then you 
won't get valid responses.


Can you send the output created with the -d option ?

>>
>>> 5) Similar issues with the Kerberos feature. Keytab und Kerberos config
>>> are available and exported, but the helper only says:
>>> support_ldap.cc(888): DEBUG: Setup Kerberos credential cache
>>> support_ldap.cc(897): DEBUG: Kerberos is not supported. Use
>>> username/password with ldap url instead
>>>
>> The message support_ldap.cc(897): DEBUG: Kerberos is not supported. means
>> your Kerberos installation is not fully available. It means HAVE_KRB5 is 
>> not
>> set ( maybe header files were missing).
>>
>>> Instead of that I found a dns SRV _kerberos._udp.REALM query which was
>>> actually answered by the dns. I assume this is related to the Kerberos
>>> feature?
>> yes it is. It is a way to find the kdc.
>>
>>> 6) It is possible to use the helper when DNS service is not reachable?
>>> Got some error messages during testing:
>>>
>>> kerberos_ldap_group: DEBUG: Canonicalise ldap server name
>>> 213.156.236.111:3268
>>> kerberos_ldap_group: ERROR: Error while resolving ip address with
>>> getnameinfo: Temporary failure in name resolution
>>> kerberos_ldap_group: DEBUG: Error during initialisation of ldap
>>> connection: Success
>>>
>> If you add a line to your hosts file and use the approriate nsswitch.conf 
>> it
>> should work.  You can also add a line to the hosts file for the domain 
>> for
>> the case the SRV record fails.
>Thx for the hint regarding nsswitch.conf
>>
>>> Beside this tiny issues the helper works excellent (tested with basic,
>>> NTLM and Kerberos authentication). I am just trying to discover the
>>> whole potential. Thank you very much for any responses.
>>>
>>> Regards
>>> Simon
>>>
>> Regards
>> Markus
>>
>>>>> If you can demonstrate that the ext_kerberos_ldap_group_acl does
>>>>> provides a superset of the functionality of ext_ldap_group_acl helper
>>>>> then I can de-duplicate the two helpers.
>>>>>
>>>>> Amos
>>>> Regards
>>>> Markus
>>

Markus 




From huaraz at moeller.plus.com  Wed Feb 11 21:32:11 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Wed, 11 Feb 2015 21:32:11 -0000
Subject: [squid-users] benefits of
	usingext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <45CAC951-F60C-4F55-9B8D-FB67B27DCCC2@open.ch>
References: <mailman.41567.1423527573.1833.squid-users@lists.squid-cache.org>
 <45CAC951-F60C-4F55-9B8D-FB67B27DCCC2@open.ch>
Message-ID: <mbghp0$8dk$1@ger.gmane.org>

>>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>>> Hash: SHA1
>>>>>
>>>>> On 20/01/2015 11:31 p.m., Simon St?heli wrote:
>>>>>> Are there any other benefits in using ext_kerberos_ldap_group_acl
>>>>>> instead of ext_ldap_group_acl except the "Netbios name to Kerberos
>>>>>> domain name? mappings provided by the -N option. As far as I can
>>>>>> tell, this mapping can also easily be done by writing you own
>>>>>> helper perl script which is doing the mapping and finally feeds the
>>>>>> more common ext_ldap_group_acl helper.
>>>>>>
>>>>>
>>>>> Whatever floats your boat. The point of the Addon/Plugin/helpers API
>>>>> is that you can use scripts if thy serve your needs better.
>>>>>
>>>>> All the usual Open Source benefits of "many eyeballs" and somebody
>>>>> else doing code maintenance for you applies to using a bundled helper
>>>>> over a custom written one.
>>>>>
>>>>> Beyond that the kerberos helper also provides automatic detection of
>>>>> which LDAP server to use via mutiple auto-configuration methods.
>>>>>
>>>>
>>>> The idea of the helper was to automate most of the configuration (
>>>> ignoring
>>>> some performance ) and avoid using a username/password, support users
>>>> from
>>>> multiple domains. Secondly I wanted check for nested groups which was
>>>> not
>>>> available in the existing helper and thirdly I also check now against
>>>> the
>>>> primary group of the user.
>>>>
>>>
>>> Thank you Markus for your explanations. I played around with
>>> ext_kerberos_ldap_group_acl and would like to go into some details:
>>>
>>> 1) it is possible to define more than one LDAP server (e.g. for high
>>> availability reasons)? The -l parameter allows only one ldap url while
>>> -S allows several "server > realm" - mappings.
>>>
>>
>> I didn't see the need.  The -l was more for cases when digest or basic 
>> auth
>> is used and I do not know the domain to check against.  So a fallback
>> option.
>>
>>
>>> 2) It is correct, that compared to ext_ldap_group_acl,
>>> ext_kerberos_ldap_group_acl does not require a groupname as input (from
>>> stdin), because -g -t -T or -D control the group name?!
>>>
>>
>> You have two options with ext_kerberos_ldap_group_acl  as input or as -g 
>> ..
>> control
>>
>>
>>> 3) What is the use case for defining -g GROUP@? What is the difference
>>> to -g GROUP (without @)
>>>
>>
>> -g GROUP is for all users including the once with nor provided domain
>>
>>
>> The an pages describe it a bit under Note:
>>
>> 1) For user at REALM
>>   a) Query DNS for SRV record _ldap._tcp.REALM
>>   b) Query DNS for A record REALM
>>   c) Use LDAP_URL if given
>>
>> 2) For user
>>   a) Use domain -D REALM and follow step 1)
>>   b) Use LDAP_URL if given
>>
>> The Groups to check against are determined as follows:
>>
>> 1) For user at REALM
>>   a)  Use  values  given  by -g option which contain a @REALM e.g. -g
>> GROUP1 at REALM:GROUP2 at REALM
>>   b) Use values given by -g option which contain a  @  only  e.g.  -g
>> GROUP1@:GROUP2@
>>   c)  Use values given by -g option which do not contain a realm e.g.
>> -g GROUP1:GROUP2
>>
>> 2) For user
>>   a) Use values given by -g option which do not contain a realm  e.g.
>> -g GROUP1:GROUP2
>>
>> 3) For NDOMAIN\user
>>   a) Use realm given by -N NDOMAIN at REALM and then use values given by
>> -g option which contain a @REALM e.g. -g GROUP1 at REALM:GROUP2 at REALM
>>
>>
>>
>>> 4) The "query DNS for SRV record _ldap._tcp.REALM" mechanism seems no to
>>> work for me although the DNS server is configured correctly and querying
>>> with "dig SRV _ldap._tcp.REALM" works fine. Anything to consider here?
>>> _ldap._tcp.REALM SRV query was never sent so far.
>>>
>>
>> I would not see an obvious reason.   Does -d show any hints ?  I can only
>> imagine that REAM is not what is send by the client.
>>
>>> 5) Similar issues with the Kerberos feature. Keytab und Kerberos config
>>> are available and exported, but the helper only says:
>>> support_ldap.cc(888): DEBUG: Setup Kerberos credential cache
>>> support_ldap.cc(897): DEBUG: Kerberos is not supported. Use
>>> username/password with ldap url instead
>>>
>>
>> The message support_ldap.cc(897): DEBUG: Kerberos is not supported. means
>> your Kerberos installation is not fully available. It means HAVE_KRB5 is 
>> not
>> set ( maybe header files were missing).
>
>
>Can you give me some further information about the requirements of the 
>helper regarding kerberos? I am trying to use it with Heimdal kerberos 
>(Heimdal 1.3.3). negotiate_kerberos_auth for example works very well with 
>the present kerberos libraries.
>
>

Can you send the config.log file ?  For some reason HAVE_KRB5 is not set ( 
which is a bit strange as it is also used for the auth helper)

>>
>>> Instead of that I found a dns SRV _kerberos._udp.REALM query which was
>>> actually answered by the dns. I assume this is related to the Kerberos
>>> feature?
>>
>> yes it is. It is a way to find the kdc.
>>
>>>
>>> 6) It is possible to use the helper when DNS service is not reachable?
>>> Got some error messages during testing:
>>>
>>> kerberos_ldap_group: DEBUG: Canonicalise ldap server name
>>> 213.156.236.111:3268
>>> kerberos_ldap_group: ERROR: Error while resolving ip address with
>>> getnameinfo: Temporary failure in name resolution
>>> kerberos_ldap_group: DEBUG: Error during initialisation of ldap
>>> connection: Success
>>>
>>
>> If you add a line to your hosts file and use the approriate nsswitch.conf 
>> it
>> should work.  You can also add a line to the hosts file for the domain 
>> for
>> the case the SRV record fails.
>>
>>
>>> Beside this tiny issues the helper works excellent (tested with basic,
>>> NTLM and Kerberos authentication). I am just trying to discover the
>>> whole potential. Thank you very much for any responses.
>>>
>>> Regards
>>> Simon
>>>
>>
>> Regards
>> Markus
>>
>>>>> If you can demonstrate that the ext_kerberos_ldap_group_acl does
>>>>> provides a superset of the functionality of ext_ldap_group_acl helper
>>>>> then I can de-duplicate the two helpers.
>>>>>
>>>>> Amos
>>>>
>>>> Regards
>>>> Markus
>>>
>>
Markus 




From dan at getbusi.com  Wed Feb 11 22:51:22 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Thu, 12 Feb 2015 09:51:22 +1100
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <54DB467E.10106@ngtech.co.il>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
 <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
 <54DB467E.10106@ngtech.co.il>
Message-ID: <4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>

Hey Eliezer

With the response_size_100 ACL definition:
- 100 tells the external ACL the limit in MB
- 192.168.0.10 tells the external ACL the squid IP

I think one or both of these is only needed to build the deny page. You can?t use deny_info with reply_body_max_size so we had to customise the ERR_TOO_BIG source to do a redirect to our own page.

The http_access allow line is because result caching cannot alter the EXT_LOG for fast ACLs as cache lookups include the EXT_LOG, so we need to check the result twice to alter the EXT_LOG and then have the result cached against the altered EXT_LOG.

Cheers
Dan

> On 11 Feb 2015, at 11:09 pm, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> Hey Dan,
> 
> First I must admit that this squid.conf is quite complicated but kind of self explanatory.
> 
> I have tried to understand the next lines:
> # File size (download) restrictions
> acl response_size_100 external response_size_type 100 192.168.0.10
> http_access allow response_size_100 response_size_100
> reply_body_max_size 100 MB response_size_100
> 
> But I am unsure how it works with external_acl exactly.
> If you wish to deny 100MB size files you should have only one rule for the reply body max size, what are the others for exactly?
> 
> Eliezer
> 
> * I might missing some concepts some sorry in advance.
> 
> On 11/02/2015 00:30, Dan Charlesworth wrote:
>> Hi Eliezer
>> 
>> Took a while to get this up?sorry about that. Here?s an example of a production config of ours (with some confidential stuff necessarily taken out/edited):
>> https://gist.github.com/djch/92cf44440b04afbd7917  <https://gist.github.com/djch/92cf44440b04afbd7917>
>> 
>> Let me know if there?s any other info I can provide that might point towards the cause of this crash.
>> 
>> And thanks again for taking a look.
> 
> 



From brett.lymn at baesystems.com  Wed Feb 11 23:05:39 2015
From: brett.lymn at baesystems.com (Brett Lymn)
Date: Thu, 12 Feb 2015 09:35:39 +1030
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <54DB2C4C.4020600@gmail.com>
References: <948151246.348514119.1423649671876.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <54DB2C4C.4020600@gmail.com>
Message-ID: <20150211230539.GA23630@baea.com.au>

On Wed, Feb 11, 2015 at 04:17:48PM +0600, Yuri Voinov wrote:
> 
> Fred, this is no matter. Millions of files can remove with one piped 
> command:
> 
> *find . |xargs rm
> 

That will work but rm will complain when find hands it the name of a
directory.  You can avoid that by:

find . -type f | xargs rm

Though if you have a large cache then it will take a very long time to
remove the files.  If your cache is on a separate file system then it
may be quicker and simpler just to unmount the file system and
reinitialise it.

-- 
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

    BAE Systems Australia Limited - Australian Company Number 008 423 005
    BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846
    BAE Systems Australia Logistics Pty Limited - Australian Company Number 086 228 864

Our registered office is Evans Building, Taranaki Road, Edinburgh Parks,
Edinburgh, South Australia, 5111. If the identity of the sending company is
not clear from the content of this email please contact the sender.

This email and any attachments may contain confidential and legally
privileged information.  If you are not the intended recipient, do not copy or
disclose its content, but please reply to this email immediately and highlight
the error to the sender and then immediately delete the message.



From squid3 at treenet.co.nz  Wed Feb 11 23:45:20 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Feb 2015 12:45:20 +1300
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <1423550733210-4669651.post@n4.nabble.com>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz> <1423550733210-4669651.post@n4.nabble.com>
Message-ID: <54DBE990.9080003@treenet.co.nz>

On 10/02/2015 7:45 p.m., amitinfo2k wrote:
> thanks for the quick reply.I made the changes accordingly as follows
> :---------------------------------------------------------------------------------------------....#
> Set up the session helper in active mode. Mind the wrap - this is one
> line:external_acl_type session ipv4 concurrency=100 ttl=3 %SRC
> /usr/lib64/squid/ext_session_acl -a -T 60 -b /var/lib/squid/session/# Pass
> the LOGIN command to the session helper with this ACLacl session_login
> external session LOGIN# Normal session ACL as per simple exampleacl
> session_is_active external session# ACL to match URLacl clicked_login_url
> url_regex -i ^http://example.net/$# First check for the login URL. If
> present, login sessionhttp_access allow clicked_login_url session_login# If
> we get here, URL not present, so renew session or deny request.http_access
> deny !session_is_active# Deny page to displaydeny_info
> 511:http://example.net/
> session_is_active---------------------------------------------------------------------------------------------but,
> after the squid restart it fails with following error
> :---------------------------------------------------------------------------------------------Feb
> 09 22:40:31 localhost.localdomain systemd[1]: Starting Squid caching
> proxy...Feb 09 22:40:31 localhost.localdomain squid[4561]: 2015/02/09
> 22:40:31| *FATAL: status 511 requires a template on
> '511:http://example.net/'*Feb 09 22:40:31 localhost.localdomain
> squid[4561]:*FATAL: Bungled /etc/squid/squid.conf line 114: deny_info
> 511:http://example.net/ session_is_active*Feb 09 22:40:31
> localhost.localdomain systemd[1]: squid.service: control process exited,
> code=exited status=1Feb 09 22:40:31 localhost.localdomain systemd[1]: Failed
> to start Squid caching
> proxy.---------------------------------------------------------------------------------------------
> 

Ar, sorry I keep forgetting. 511 is a response that has a body not a
redirect. You need to write your denial info in a static template file
for Squid to deliver. Any dynamics that need to be done can be written
in that with scripting.

Amos



From luismiguelferreirasilva at gmail.com  Thu Feb 12 05:54:02 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Wed, 11 Feb 2015 22:54:02 -0700
Subject: [squid-users] A little help with squid and e-cap
Message-ID: <CA+suCFjJ=04g3VFK2yYDEm2ye6DYsvPDixG5=wF=gNu1Ee6+Bg@mail.gmail.com>

Dear all,

This might not be the ideal place to ask questions about e-cap but, since
e-cap's mailing list is not working, I decided to ask my question here.

So, here goes:
- *My ecap service only seems to work on some pages*...
-- I've added the following configuration to my squid.conf:
loadable_modules /usr/local/lib/ecap_adapter_modifying.so
ecap_enable on
ecap_service ecapModifier respmod_precache 0 ecap://
e-cap.org/ecap/services/sample/modifying victim=professor
replacement=teacher
adaptation_access ecapModifier allow all
-- unfortunately, it *only seems to work some times* (e.g. for instance, it
works on this one <http://www.pedagua.com/lmsilva/> [
http://www.pedagua.com/lmsilva/] but not on this one
<http://en.wikipedia.org/wiki/Professor> [
http://en.wikipedia.org/wiki/Professor]).
-- *any idea on how I can debug why? access_log and cache.log aren't very
helpful.*

- *Does squid obey any specific order between ICAP and E-CAP calls?*
-- for instance, if the E-CAP module changes the content, will the ICAP
service receive the changed content OR the original content?
-- *does ecap and icap directive order in squid.conf matter?*

- *Is each ecap_service loaded on each page load?*
-- Or does it preload a couple of ecap_services and keep using those over
and over again (just like it does with c-icap and redirect_programs?)
-- I can see each ecap module implements configure, reconfigure, start,
stop and retire methods so...it SHOULD be possible to preload the script
and just call reconfigure on each call. What does Squid do?

p.s. I'm using squid 3.4.9 (compiled from source), with libecap 0.2 and I'm
using the ecap adapter sample package v0.2.1.

Thank you,
Luis
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150211/3fa22263/attachment.htm>

From vdoctor at neuf.fr  Thu Feb 12 07:20:44 2015
From: vdoctor at neuf.fr (Stakres)
Date: Wed, 11 Feb 2015 23:20:44 -0800 (PST)
Subject: [squid-users] Resolution Locker Plugin for Squid Proxy Cache 3.x
In-Reply-To: <1423065493752-4669549.post@n4.nabble.com>
References: <1422896192924-4669489.post@n4.nabble.com>
 <1423065493752-4669549.post@n4.nabble.com>
Message-ID: <1423725644117-4669749.post@n4.nabble.com>

Hi All,

New  build 2.06 <https://sourceforge.net/projects/youtuberesolutionlocker/> 
:
- YouTube
- Vevo
- iMDB
- Dailymotion
- Break.com
- Apple Trailers

Ask your free 1 year license  on the website <https://svl.unveiltech.com/>   

Bye Fred




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Resolution-Locker-Plugin-for-Squid-Proxy-Cache-3-x-tp4669489p4669749.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From silamael at coronamundi.de  Thu Feb 12 08:03:00 2015
From: silamael at coronamundi.de (Silamael Darkomen)
Date: Thu, 12 Feb 2015 09:03:00 +0100
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DBB5F0.9070809@treenet.co.nz>
References: <54DB28C7.8000906@coronamundi.de> <54DB2A99.4000009@gmail.com>
 <54DB424D.8080501@coronamundi.de> <54DB542D.9060303@coronamundi.de>
 <54DB551E.3070705@gmail.com> <54DB71C3.5060301@coronamundi.de>
 <54DBB5F0.9070809@treenet.co.nz>
Message-ID: <54DC5E34.4090505@coronamundi.de>

On 11.02.2015 21:05, Amos Jeffries wrote:
>>> Some FTP files pointless to cache.
>>
>> Sure, maybe some FTP files are not to be cached.
>>
>>>
>>> If it need just once..... For what cache it?
>>
>> I do not want to cache any. And I think a 'cache deny all' does that.
> 
> Correct.
> 
>> Nevertheless, even with no caching at all the Squid process constantly
>> needs more memory and squidclient reports that the memory is used for
>> the 2K buffers.
>>
>> Just try it. Squid with default configuration and cache deny all and
>> then do some wget ftp://server/path/. Each requests will increase the 2K
>> buffers.
>>
> 
> Thank you. Can you drop that into a bug report please so we dont loose
> track of it?
> 
> Cheers
> Amos

Hi Amos,

I will file a proper bug report with debug output and such when I'm back
at work next monday.
Any idea what's wrong here? For me it seems that the index.html Squid is
generating for FTP requests with just an directory is not freed internally.

Greetings,
Matthias


From yvoinov at gmail.com  Thu Feb 12 08:10:51 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 12 Feb 2015 14:10:51 +0600
Subject: [squid-users] A little help with squid and e-cap
In-Reply-To: <CA+suCFjJ=04g3VFK2yYDEm2ye6DYsvPDixG5=wF=gNu1Ee6+Bg@mail.gmail.com>
References: <CA+suCFjJ=04g3VFK2yYDEm2ye6DYsvPDixG5=wF=gNu1Ee6+Bg@mail.gmail.com>
Message-ID: <54DC600B.7040900@gmail.com>

Start from here:

http://wiki.squid-cache.org/ConfigExamples#Content_Adaptation_features

12.02.15 11:54, Luis Miguel Silva ?????:
> Dear all,
>
> This might not be the ideal place to ask questions about e-cap but, 
> since e-cap's mailing list is not working, I decided to ask my 
> question here.
>
> So, here goes:
> - *My ecap service only seems to work on some pages*...
> -- I've added the following configuration to my squid.conf:
> loadable_modules /usr/local/lib/ecap_adapter_modifying.so
> ecap_enable on
> ecap_service ecapModifier respmod_precache 0 
> ecap://e-cap.org/ecap/services/sample/modifying 
> <http://e-cap.org/ecap/services/sample/modifying> victim=professor 
> replacement=teacher
> adaptation_access ecapModifier allow all
> -- unfortunately, it *only seems to work some times* (e.g. for 
> instance, it works on this one <http://www.pedagua.com/lmsilva/> 
> [http://www.pedagua.com/lmsilva/] but not on this one 
> <http://en.wikipedia.org/wiki/Professor> 
> [http://en.wikipedia.org/wiki/Professor]).
> -- *any idea on how I can debug why? access_log and cache.log aren't 
> very helpful.*
>
> - *Does squid obey any specific order between ICAP and E-CAP calls?*
> -- for instance, if the E-CAP module changes the content, will the 
> ICAP service receive the changed content OR the original content?
As you configured.
> -- *does ecap and icap directive order in squid.conf matter?*
No.
>
> - *Is each ecap_service loaded on each page load?*
No. Just one time, when Squid starts.
> -- Or does it preload a couple of ecap_services and keep using those 
> over and over again (just like it does with c-icap and redirect_programs?)
> -- I can see each ecap module implements configure, reconfigure, 
> start, stop and retire methods so...it SHOULD be possible to preload 
> the script and just call reconfigure on each call. What does Squid do?
>
> p.s. I'm using squid 3.4.9 (compiled from source), with libecap 0.2 
> and I'm using the ecap adapter sample package v0.2.1.
Once more - it is strictly recommended to upgrade to last Squid version, 
etc.etc., blah-blah-blah....
>
> Thank you,
> Luis
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/0dac2447/attachment.htm>

From fredbmail at free.fr  Thu Feb 12 08:11:50 2015
From: fredbmail at free.fr (FredB)
Date: Thu, 12 Feb 2015 09:11:50 +0100 (CET)
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <20150211230539.GA23630@baea.com.au>
Message-ID: <858760942.350505087.1423728710955.JavaMail.root@zimbra4-e1.priv.proxad.net>


> remove the files.  If your cache is on a separate file system then it
> may be quicker and simpler just to unmount the file system and
> reinitialise it.
> 

Yes I agree, cache in a separate partition is a good advice, like that you can easily format (just a few seconds)


----

Regards,

Fred

http://numsys.eu
http://e2guardian.org


From squid3 at treenet.co.nz  Thu Feb 12 08:18:59 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Feb 2015 21:18:59 +1300
Subject: [squid-users] A little help with squid and e-cap
In-Reply-To: <CA+suCFjJ=04g3VFK2yYDEm2ye6DYsvPDixG5=wF=gNu1Ee6+Bg@mail.gmail.com>
References: <CA+suCFjJ=04g3VFK2yYDEm2ye6DYsvPDixG5=wF=gNu1Ee6+Bg@mail.gmail.com>
Message-ID: <54DC61F3.9090700@treenet.co.nz>

On 12/02/2015 6:54 p.m., Luis Miguel Silva wrote:
> Dear all,
> 
> This might not be the ideal place to ask questions about e-cap but, since
> e-cap's mailing list is not working, I decided to ask my question here.
> 
> So, here goes:
> - *My ecap service only seems to work on some pages*...
> -- I've added the following configuration to my squid.conf:
> loadable_modules /usr/local/lib/ecap_adapter_modifying.so
> ecap_enable on
> ecap_service ecapModifier respmod_precache 0 ecap://
> e-cap.org/ecap/services/sample/modifying victim=professor
> replacement=teacher
> adaptation_access ecapModifier allow all
> -- unfortunately, it *only seems to work some times* (e.g. for instance, it
> works on this one <http://www.pedagua.com/lmsilva/> [
> http://www.pedagua.com/lmsilva/] but not on this one
> <http://en.wikipedia.org/wiki/Professor> [
> http://en.wikipedia.org/wiki/Professor]).
> -- *any idea on how I can debug why? access_log and cache.log aren't very
> helpful.*


With debug_options 93,9 and/or debug traces in your adapter code itself.

> 
> - *Does squid obey any specific order between ICAP and E-CAP calls?*

Yes.

> -- for instance, if the E-CAP module changes the content, will the ICAP
> service receive the changed content OR the original content?

Yes.

> -- *does ecap and icap directive order in squid.conf matter?*

No. The order of execution is configured explicitly with
<http://www.squid-cache.org/Doc/config/adaptation_service_chain/> and/or
<http://www.squid-cache.org/Doc/config/adaptation_service_set/>


> 
> - *Is each ecap_service loaded on each page load?*
> -- Or does it preload a couple of ecap_services and keep using those over
> and over again (just like it does with c-icap and redirect_programs?)
> -- I can see each ecap module implements configure, reconfigure, start,
> stop and retire methods so...it SHOULD be possible to preload the script
> and just call reconfigure on each call. What does Squid do?

No. Yes. Squid loads a library.

> 
> p.s. I'm using squid 3.4.9 (compiled from source), with libecap 0.2 and I'm
> using the ecap adapter sample package v0.2.1.
> 
> Thank you,
> Luis
> 

Amos



From squid3 at treenet.co.nz  Thu Feb 12 08:49:56 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Feb 2015 21:49:56 +1300
Subject: [squid-users] Squid 3.5.1 NTLM and LDAP
In-Reply-To: <1423658119022-4669727.post@n4.nabble.com>
References: <1423575594700-4669661.post@n4.nabble.com>
 <54DA6255.5070502@treenet.co.nz> <1423658119022-4669727.post@n4.nabble.com>
Message-ID: <54DC6934.4020905@treenet.co.nz>

On 12/02/2015 1:35 a.m., Rich549 wrote:
> *Ok, I've made all of the advised changes and it still didn't work.
> 
> I've just tried pasting my helper command into command prompt and it just
> seems to hang.  I tried the following:*
> 


The helper takes -b string as the base DN and appends the dynamic -f
string to it.

You have configured this as the ACL test:

  # Allow Members of Internet Users To Anywhere Not Explicitly Denied
  acl InetAllow external internet_domain_group Internet_Users


So the "Internet_Users" is the name of the group being checked for using
the internet_domain_group helper. %g will always be "Internet_Users"
when testing this ACL, %u will change with each user login as its their
username value.


> -----
> D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -d -S -b
> "ou=Domain_Groups,dc=domain-uk,dc=com" -f  %g=Internet_Users -h
> srvham09.domain-uk.com
> 

That queries server srvham09.domain-uk.com for:

  ou=Domain_Groups,dc=domain-uk,dc=com,Internet_Users=Internet_Users


> D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -d -S -b
> "ou=Domain_Groups,dc=domain-uk,dc=com" -f Internet_Users -h
> srvham09.domain-uk.com

That queries server srvham09.domain-uk.com for:

  ou=Domain_Groups,dc=domain-uk,dc=com,Internet_Users


> 
> D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -d -b
> "ou=Domain_Groups,dc=domain-uk,dc=com" -f %u "Internet_Users" -h
> srvham09.domain-uk.com


-f only takes one argument so that queries servers Internet_Users and
srvham09.domain-uk.com for:

  ou=Domain_Groups,dc=domain-uk,dc=com,<username>

> 
> D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -d -b
> ou=Domain_Groups,dc=domain-uk,dc=com -f %u %g=Internet_Users -h
> srvham09.domain-uk.com

-f only takes one argument so that queries servers %g=Internet_Users and
srvham09.domain-uk.com for:

  ou=Domain_Groups,dc=domain-uk,dc=com,Internet_Users=Internet_Users


> 
> D:\Squid>d:/Squid/lib/squid/ext_ldap_group_acl.exe -v 2 -d -b
> ou=Domain_Groups,dc=domain-uk,dc=com -f Internet_Users -h
> srvham09.domain-uk.com


That queries server srvham09.domain-uk.com using LDAPv2 for:

  ou=Domain_Groups,dc=domain-uk,dc=com,Internet_Users



Do any of the above LDAP syntaxes look right to you?
I suspect you want some code like ou=%g in the filter.


Only you know what the actual AD directory structure is, and I'm not
very clued up on what the LDAP kv-pairs mean sorry. So that is just a
guess that I hope will point you in the right direction.


> -----
> 
> *I'm also seeing the following in the cache.log each time I try to access a
> webpage as a user who is a member of Internet_Users, is this anything to be
> concerned about?*
> ----
> 2015/02/11 12:21:47 kid1| helperOpenServers: Starting 1/80 'ntlm_fake_auth'
> processes

Squid starts helpers incrementally as they are needed nowdays. You can
expect 80 of those mostly when you restart Squid. Messages about dying
helpers are the sign of problems.


> 2015/02/11 12:21:47 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument

Thats okay, I think. Squid is attempting to drop security privileges but
can't. Some OS seem to do it automatically then complain when its done
explicitly.

> ----
> 
> *And now, just to top things off I have errors in the cache.log stating:*
> 
> d:/Squid/lib/squid/ext_ldap_group_acl.exe: (6) No such device or address

That is a OS error being hit by the helper. Probably when it tries to
contact the LDAP servers "Internet_Users" or "%g=Internet_Users" in your
tests above.


Amos


From squid3 at treenet.co.nz  Thu Feb 12 08:51:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Feb 2015 21:51:28 +1300
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DC5E34.4090505@coronamundi.de>
References: <54DB28C7.8000906@coronamundi.de> <54DB2A99.4000009@gmail.com>
 <54DB424D.8080501@coronamundi.de> <54DB542D.9060303@coronamundi.de>
 <54DB551E.3070705@gmail.com> <54DB71C3.5060301@coronamundi.de>
 <54DBB5F0.9070809@treenet.co.nz> <54DC5E34.4090505@coronamundi.de>
Message-ID: <54DC6990.3000307@treenet.co.nz>

On 12/02/2015 9:03 p.m., Silamael Darkomen wrote:
>
> I will file a proper bug report with debug output and such when I'm back
> at work next monday.
> Any idea what's wrong here? For me it seems that the index.html Squid is
> generating for FTP requests with just an directory is not freed internally.

I think you are right, but havent looked into it yet.

Amos


From naser.sonbaty at gmail.com  Thu Feb 12 10:52:12 2015
From: naser.sonbaty at gmail.com (naser sonbaty)
Date: Thu, 12 Feb 2015 11:52:12 +0100
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected for
Message-ID: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>

Hi guys,

I need your help with setting squid 3.5.1 with intercept.
My topolgy Clients PC <--> Router PC <--> SquidPC

Router:
Send trafic from 80 to squid 192.168.15.2:3129

my config:
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access deny manager

http_access allow localnet
http_access allow localhost

http_access deny all

http_port 127.0.0.1:3128
http_port 192.168.15.2:3129 intercept

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

coredump_dir /var/cache/squid/coredump_squid
pid_filename /var/run/squid.pid
access_log /var/log/squid/frontend.access.log
cache_log /var/log/squid/frontend.cache.log
cache_dir aufs /var/cache/squid/cache1 1024 128 128

I got following error:
1423737360.412      0 192.168.15.2 TCP_MISS/403 4256 GET
http://www.yahoo.com/ - HIER_NONE/- text/html
1423737360.412     18 10.0.0.7 TCP_MISS/403 4313 GET http://www.yahoo.com/
- ORIGINAL_DST/192.168.15.2 text/html
1423737360.426      0 192.168.15.2 TCP_MISS/403 4291 GET
http://www.squid-cache.org/Artwork/SN.png - HIER_NONE/- text/html
1423737360.426      1 10.0.0.7 TCP_MISS/403 4348 GET
http://www.squid-cache.org/Artwork/SN.png - ORIGINAL_DST/192.168.15.2
text/html

and log from cache:
2015/02/12 11:36:00 kid1| WARNING: Forwarding loop detected for:
GET / HTTP/1.1
Accept: text/html, application/xhtml+xml, */*
Referer: http://www.yahoo.com/
Accept-Language: en
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like
Gecko/20100101 Firefox/12.0
Accept-Encoding: gzip, deflate
DNT: 1
Host: www.yahoo.com
Cookie: B=7938nbda0dlii&b=3&s=9t
Via: 1.1 proxy (squid/3.5.1)
X-Forwarded-For: 10.0.0.7
Cache-Control: max-age=259200
Connection: keep-alive


2015/02/12 11:36:00 kid1| WARNING: Forwarding loop detected for:
GET /Artwork/SN.png HTTP/1.1
Accept: image/png, image/svg+xml, image/*;q=0.8, */*;q=0.5
Referer: http://www.yahoo.com/
Accept-Language: en
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like
Gecko/20100101 Firefox/12.0
Accept-Encoding: gzip, deflate
DNT: 1
Host: www.squid-cache.org
Via: 1.1 proxy (squid/3.5.1)
X-Forwarded-For: 10.0.0.7
Cache-Control: max-age=259200
Connection: keep-alive

THX for helping
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/ac164259/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Feb 12 10:58:12 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 12 Feb 2015 10:58:12 +0000
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
Message-ID: <201502121058.12973.Antony.Stone@squid.open.source.it>

On Thursday 12 Feb 2015 at 10:52, naser sonbaty wrote:

> Hi guys,
> 
> I need your help with setting squid 3.5.1 with intercept.
> My topolgy Clients PC <--> Router PC <--> SquidPC

Where is the Internet connection in the above diagram?

> Router:
> Send trafic from 80 to squid 192.168.15.2:3129

Have you configured the router to redirect port 80 traffic from the Client PC 
to Squid 3129, or have you configured it to redirect *all* port 80 traffic 
(including from Squid) to Squid 3129?

> 2015/02/12 11:36:00 kid1| WARNING: Forwarding loop detected for:

Looks like the Router is making Squid talk to itself.


Regards,


Antony.

-- 
"In fact I wanted to be John Cleese and it took me some time to realise that 
the job was already taken."

 - Douglas Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From priyaiitmandi at gmail.com  Thu Feb 12 11:01:59 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Thu, 12 Feb 2015 16:31:59 +0530
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
Message-ID: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>

Hi,

I know this must be a very common error. But I am unable to remove it. My
permissions are set correct. Network connection is also fine. Here is my
log:

root at t4240qds:~# /usr/sbin/squid -NCd1
2015/02/12 11:44:06| Set Current Directory to /var/cache/squid
2015/02/12 11:44:06| Starting Squid Cache version 3.4.7 for
powerpc-fsl_networking-linux-gnu...
2015/02/12 11:44:06| Process ID 2172
2015/02/12 11:44:06| Process Roles: master worker
2015/02/12 11:44:06| With 1024 file descriptors available
2015/02/12 11:44:06| Initializing IP Cache...
2015/02/12 11:44:06| DNS Socket created at [::], FD 4
2015/02/12 11:44:06| DNS Socket created at 0.0.0.0, FD 5
2015/02/12 11:44:06| Adding nameserver 8.8.8.8 from squid.conf
2015/02/12 11:44:06| Logfile: opening log daemon:/var/logs/access.log
2015/02/12 11:44:06| Logfile Daemon: opening log /var/logs/access.log
2015/02/12 11:44:06| Unlinkd pipe opened on FD 11
2015/02/12 11:44:06| Store logging disabled
2015/02/12 11:44:06| Swap maxSize 102400 + 262144 KB, estimated 28041
objects
2015/02/12 11:44:06| Target number of buckets: 1402
2015/02/12 11:44:06| Using 8192 Store buckets
2015/02/12 11:44:06| Max Mem  size: 262144 KB
2015/02/12 11:44:06| Max Swap size: 102400 KB
2015/02/12 11:44:06| Rebuilding storage in /var/cache/squid (clean log)
2015/02/12 11:44:06| Using Least Load store dir selection
2015/02/12 11:44:06| Set Current Directory to /var/cache/squid
2015/02/12 11:44:06| Finished loading MIME types and icons.
2015/02/12 11:44:06| HTCP Disabled.
2015/02/12 11:44:06| Squid plugin modules loaded: 0
2015/02/12 11:44:06| Accepting HTTP Socket connections at local=
10.116.65.155:8080 remote=[::] FD 14 flags=9
2015/02/12 11:44:06| Done reading /var/cache/squid swaplog (0 entries)
2015/02/12 11:44:06| Store rebuilding is 0.00% complete
2015/02/12 11:44:06| Finished rebuilding storage from disk.
2015/02/12 11:44:06|         0 Entries scanned
2015/02/12 11:44:06|         0 Invalid entries.
2015/02/12 11:44:06|         0 With invalid flags.
2015/02/12 11:44:06|         0 Objects loaded.
2015/02/12 11:44:06|         0 Objects expired.
2015/02/12 11:44:06|         0 Objects cancelled.
2015/02/12 11:44:06|         0 Duplicate URLs purged.
2015/02/12 11:44:06|         0 Swapfile clashes avoided.
2015/02/12 11:44:06|   Took 0.05 seconds (  0.00 objects/sec).
2015/02/12 11:44:06| Beginning Validation Procedure
2015/02/12 11:44:06|   Completed Validation Procedure
2015/02/12 11:44:06|   Validated 0 Entries
2015/02/12 11:44:06|   store_swap_size = 0.00 KB
2015/02/12 11:44:07| logfileHandleWrite: daemon:/var/logs/access.log: error
writing ((32) Broken pipe)
2015/02/12 11:44:07| Closing HTTP port 10.116.65.155:8080
2015/02/12 11:44:07| storeDirWriteCleanLogs: Starting...
2015/02/12 11:44:07|   Finished.  Wrote 0 entries.
2015/02/12 11:44:07|   Took 0.00 seconds (  0.00 entries/sec).
FATAL: I don't handle this error well!

I have also attached my squid.conf.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/0ef2f080/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 2495 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/0ef2f080/attachment.obj>

From Antony.Stone at squid.open.source.it  Thu Feb 12 11:08:26 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 12 Feb 2015 11:08:26 +0000
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
	error writing ((32) Broken pipe)
In-Reply-To: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
Message-ID: <201502121108.26834.Antony.Stone@squid.open.source.it>

On Thursday 12 Feb 2015 at 11:01, Priya Agarwal wrote:

> My permissions are set correct.

Please show us the output of:

ls -al /var/logs/access.log

> 2015/02/12 11:44:06| Logfile: opening log daemon:/var/logs/access.log
> 2015/02/12 11:44:06| Logfile Daemon: opening log /var/logs/access.log
> 2015/02/12 11:44:07| logfileHandleWrite: daemon:/var/logs/access.log: error
> writing ((32) Broken pipe)

Make sure you copy and paste (don't retype), both the command I've given 
above, and the output into your reply.


Regards,


Antony.

-- 
If you were ploughing a field, which would you rather use - two strong oxen or 
1024 chickens?

 - Seymour Cray, pioneer of supercomputing

                                                   Please reply to the list;
                                                         please *don't* CC me.


From naser.sonbaty at gmail.com  Thu Feb 12 11:26:25 2015
From: naser.sonbaty at gmail.com (naser sonbaty)
Date: Thu, 12 Feb 2015 12:26:25 +0100
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <201502121058.12973.Antony.Stone@squid.open.source.it>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
Message-ID: <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>

Hi,

Internet is connected to Router PC

Only trafic to port 80 is send to squid.

thx

On Thu, Feb 12, 2015 at 11:58 AM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Thursday 12 Feb 2015 at 10:52, naser sonbaty wrote:
>
> > Hi guys,
> >
> > I need your help with setting squid 3.5.1 with intercept.
> > My topolgy Clients PC <--> Router PC <--> SquidPC
>
> Where is the Internet connection in the above diagram?
>
> > Router:
> > Send trafic from 80 to squid 192.168.15.2:3129
>
> Have you configured the router to redirect port 80 traffic from the Client
> PC
> to Squid 3129, or have you configured it to redirect *all* port 80 traffic
> (including from Squid) to Squid 3129?
>
> > 2015/02/12 11:36:00 kid1| WARNING: Forwarding loop detected for:
>
> Looks like the Router is making Squid talk to itself.
>
>
> Regards,
>
>
> Antony.
>
> --
> "In fact I wanted to be John Cleese and it took me some time to realise
> that
> the job was already taken."
>
>  - Douglas Adams
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/5f200fab/attachment.htm>

From naser.sonbaty at gmail.com  Thu Feb 12 11:26:25 2015
From: naser.sonbaty at gmail.com (naser sonbaty)
Date: Thu, 12 Feb 2015 12:26:25 +0100
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <201502121058.12973.Antony.Stone@squid.open.source.it>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
Message-ID: <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>

Hi,

Internet is connected to Router PC

Only trafic to port 80 is send to squid.

thx

On Thu, Feb 12, 2015 at 11:58 AM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Thursday 12 Feb 2015 at 10:52, naser sonbaty wrote:
>
> > Hi guys,
> >
> > I need your help with setting squid 3.5.1 with intercept.
> > My topolgy Clients PC <--> Router PC <--> SquidPC
>
> Where is the Internet connection in the above diagram?
>
> > Router:
> > Send trafic from 80 to squid 192.168.15.2:3129
>
> Have you configured the router to redirect port 80 traffic from the Client
> PC
> to Squid 3129, or have you configured it to redirect *all* port 80 traffic
> (including from Squid) to Squid 3129?
>
> > 2015/02/12 11:36:00 kid1| WARNING: Forwarding loop detected for:
>
> Looks like the Router is making Squid talk to itself.
>
>
> Regards,
>
>
> Antony.
>
> --
> "In fact I wanted to be John Cleese and it took me some time to realise
> that
> the job was already taken."
>
>  - Douglas Adams
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/5f200fab/attachment-0001.htm>

From Antony.Stone at squid.open.source.it  Thu Feb 12 11:40:55 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 12 Feb 2015 11:40:55 +0000
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
 <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
Message-ID: <201502121140.55913.Antony.Stone@squid.open.source.it>

On Thursday 12 Feb 2015 at 11:26, naser sonbaty wrote:

> Hi,
> 
> Internet is connected to Router PC
> 
> Only trafic to port 80 is send to squid.

Yes, I know that, but traffic *from* where?

Please answer the question below.  Even better, show us the redirect rule 
you're using on the router to do it.

> On Thu, Feb 12, 2015 at 11:58 AM, Antony Stone wrote:
> > 
> > Have you configured the router to redirect port 80 traffic from the
> > Client PC to Squid 3129, or have you configured it to redirect *all* port
> > 80 traffic (including from Squid) to Squid 3129?
> > 
> > Looks like the Router is making Squid talk to itself.


Regards,


Antony.

-- 
I love deadlines.   I love the whooshing noise they make as they go by.

 - Douglas Noel Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Thu Feb 12 11:57:34 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 00:57:34 +1300
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
 for
In-Reply-To: <201502121140.55913.Antony.Stone@squid.open.source.it>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
 <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
 <201502121140.55913.Antony.Stone@squid.open.source.it>
Message-ID: <54DC952E.4060400@treenet.co.nz>

On 13/02/2015 12:40 a.m., Antony Stone wrote:
> On Thursday 12 Feb 2015 at 11:26, naser sonbaty wrote:
> 
>> Hi,
>>
>> Internet is connected to Router PC
>>
>> Only trafic to port 80 is send to squid.
> 
> Yes, I know that, but traffic *from* where?
> 
> Please answer the question below.  Even better, show us the redirect rule 
> you're using on the router to do it.


Specifically *where* in your system the NAT is happening is important.


... because the client PC (10.0.0.7) contacting the web server
192.168.15.2 to fetch "http://www.yahoo.com/" is not making any sense.

But that is what the TCP packets arriving at Squid say.

Amos



From squid3 at treenet.co.nz  Thu Feb 12 11:59:04 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 00:59:04 +1300
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <201502121108.26834.Antony.Stone@squid.open.source.it>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502121108.26834.Antony.Stone@squid.open.source.it>
Message-ID: <54DC9588.4000502@treenet.co.nz>

On 13/02/2015 12:08 a.m., Antony Stone wrote:
> On Thursday 12 Feb 2015 at 11:01, Priya Agarwal wrote:
> 
>> My permissions are set correct.
> 
> Please show us the output of:
> 
> ls -al /var/logs/access.log


... and squid -v

> 
>> 2015/02/12 11:44:06| Logfile: opening log daemon:/var/logs/access.log
>> 2015/02/12 11:44:06| Logfile Daemon: opening log /var/logs/access.log
>> 2015/02/12 11:44:07| logfileHandleWrite: daemon:/var/logs/access.log: error
>> writing ((32) Broken pipe)
> 
> Make sure you copy and paste (don't retype), both the command I've given 
> above, and the output into your reply.
> 
> 
> Regards,
> 
> 
> Antony.
> 

Amos



From amit_info2k at yahoo.com  Thu Feb 12 12:21:51 2015
From: amit_info2k at yahoo.com (amitinfo2k)
Date: Thu, 12 Feb 2015 04:21:51 -0800 (PST)
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <54DBE990.9080003@treenet.co.nz>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz> <1423550733210-4669651.post@n4.nabble.com>
 <54DBE990.9080003@treenet.co.nz>
Message-ID: <1423743711753-4669764.post@n4.nabble.com>

Thanks I changed the config now the service is up no errors in the logs but,
I don't see spash screen 
any time. Following the configuration i did with default squid config 
----------------------------------------------------------------------------------------------------
# Set up the session helper in active mode. Mind the wrap - this is one
line:
external_acl_type session ipv4 concurrency=100 ttl=3 %SRC
/usr/lib64/squid/ext_session_acl -a -T 60 -b /var/lib/squid/session/

# Pass the LOGIN command to the session helper with this ACL
acl session_login external session LOGIN


# Normal session ACL as per simple example
acl session_is_active external session

# ACL to match URL
acl clicked_login_url url_regex -i ^http://example.net/$

# First check for the login URL. If present, login session
http_access allow clicked_login_url session_login

# If we get here, URL not present, so renew session or deny request.
http_access deny !session_is_active

# Deny page to display
deny_info 511:/etc/squid/splash.html session_is_active
----------------------------------------------------------------------------------------------------

I haven't enabled authentication. I tried testing from local m/c by
configuring the proxy in the browser and also tried from remote m/c. I am
able to browse the internet via proxy. But, I am not getting the splash
screen.


Thanks,
Amit Wankhede



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Portal-Splash-Pages-example-on-squid-3-3-13-tp4669634p4669764.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Thu Feb 12 13:06:11 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 12 Feb 2015 15:06:11 +0200
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
 for
In-Reply-To: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
Message-ID: <54DCA543.9080700@ngtech.co.il>

Hey Naser,

What OS does the squid server run upon and what OS is the router running?
Also what rules have you used on each machine? and what are the exact 
network topology you have there?

Eliezer

On 12/02/2015 12:52, naser sonbaty wrote:
> Hi guys,
>
> I need your help with setting squid 3.5.1 with intercept.
> My topolgy Clients PC <--> Router PC <--> SquidPC
>
> Router:
> Send trafic from 80 to squid 192.168.15.2:3129




From squid3 at treenet.co.nz  Thu Feb 12 13:10:47 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 02:10:47 +1300
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <1423743711753-4669764.post@n4.nabble.com>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz> <1423550733210-4669651.post@n4.nabble.com>
 <54DBE990.9080003@treenet.co.nz> <1423743711753-4669764.post@n4.nabble.com>
Message-ID: <54DCA657.4040605@treenet.co.nz>

On 13/02/2015 1:21 a.m., amitinfo2k wrote:
> Thanks I changed the config now the service is up no errors in the logs but,
> I don't see spash screen 
> any time. Following the configuration i did with default squid config 
> ----------------------------------------------------------------------------------------------------
> # Set up the session helper in active mode. Mind the wrap - this is one
> line:
> external_acl_type session ipv4 concurrency=100 ttl=3 %SRC
> /usr/lib64/squid/ext_session_acl -a -T 60 -b /var/lib/squid/session/
> 
> # Pass the LOGIN command to the session helper with this ACL
> acl session_login external session LOGIN
> 
> 
> # Normal session ACL as per simple example
> acl session_is_active external session
> 
> # ACL to match URL
> acl clicked_login_url url_regex -i ^http://example.net/$
> 
> # First check for the login URL. If present, login session
> http_access allow clicked_login_url session_login
> 
> # If we get here, URL not present, so renew session or deny request.
> http_access deny !session_is_active
> 
> # Deny page to display
> deny_info 511:/etc/squid/splash.html session_is_active
> ----------------------------------------------------------------------------------------------------
> 
> I haven't enabled authentication. I tried testing from local m/c by
> configuring the proxy in the browser and also tried from remote m/c. I am
> able to browse the internet via proxy. But, I am not getting the splash
> screen.


Okay, so how are you testing this? and what does the splash.html contain
exactly?


Amos


From amit_info2k at yahoo.com  Thu Feb 12 14:12:50 2015
From: amit_info2k at yahoo.com (amitinfo2k)
Date: Thu, 12 Feb 2015 06:12:50 -0800 (PST)
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <54DCA657.4040605@treenet.co.nz>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz> <1423550733210-4669651.post@n4.nabble.com>
 <54DBE990.9080003@treenet.co.nz> <1423743711753-4669764.post@n4.nabble.com>
 <54DCA657.4040605@treenet.co.nz>
Message-ID: <1423750370136-4669767.post@n4.nabble.com>

Splash is just a static HTML page as folllows:
----------------------------------------------------------
/etc/squid/splash.html
----------------------------------------------------------
<html>
    <head>
        <title>splash screen example</title>
    </head>
    <body>
     This is splash screen
    </body>
</html>
----------------------------------------------------------
I have a VM (Fedora19) where i have installed the squid and this VM has
internet access.
now on this VM itself I am opening a Browser with proxy setting a VM IP and
port 3128.
Also, I tried from host m/c browser configured proxy settings as VM IP and
port 3128.
I am able to browse the internet. But no splash screen coming in between.
so, how does the session work here ? as per configuration -T 60 sec every
one min session should be expired right ? and then i should be able to see
the splash.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Portal-Splash-Pages-example-on-squid-3-3-13-tp4669634p4669767.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From luismiguelferreirasilva at gmail.com  Thu Feb 12 14:34:32 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Thu, 12 Feb 2015 07:34:32 -0700
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <201502121140.55913.Antony.Stone@squid.open.source.it>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
 <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
 <201502121140.55913.Antony.Stone@squid.open.source.it>
Message-ID: <CA+suCFgMGX0JiBzjNau+Fhg_baV7oUNxLUwneLKgWugZAYDgNw@mail.gmail.com>

I bumped into this same "forwarding loop" problem yesterday!
In my case, it was because I had two transparent proxies in the same
network and was basically redirecting traffic twice:
[internet] <-> [appliance 1] <-> [appliance 2] <-> [client computer]

I mistakenly added iptables redirect rules in both appliance 1 and
appliance 2 and that caused Squid to spit out that "forwarding loop
detected" error.


On Thu, Feb 12, 2015 at 4:40 AM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Thursday 12 Feb 2015 at 11:26, naser sonbaty wrote:
>
> > Hi,
> >
> > Internet is connected to Router PC
> >
> > Only trafic to port 80 is send to squid.
>
> Yes, I know that, but traffic *from* where?
>
> Please answer the question below.  Even better, show us the redirect rule
> you're using on the router to do it.
>
> > On Thu, Feb 12, 2015 at 11:58 AM, Antony Stone wrote:
> > >
> > > Have you configured the router to redirect port 80 traffic from the
> > > Client PC to Squid 3129, or have you configured it to redirect *all*
> port
> > > 80 traffic (including from Squid) to Squid 3129?
> > >
> > > Looks like the Router is making Squid talk to itself.
>
>
> Regards,
>
>
> Antony.
>
> --
> I love deadlines.   I love the whooshing noise they make as they go by.
>
>  - Douglas Noel Adams
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/563f7a40/attachment.htm>

From luismiguelferreirasilva at gmail.com  Thu Feb 12 14:34:32 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Thu, 12 Feb 2015 07:34:32 -0700
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <201502121140.55913.Antony.Stone@squid.open.source.it>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
 <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
 <201502121140.55913.Antony.Stone@squid.open.source.it>
Message-ID: <CA+suCFgMGX0JiBzjNau+Fhg_baV7oUNxLUwneLKgWugZAYDgNw@mail.gmail.com>

I bumped into this same "forwarding loop" problem yesterday!
In my case, it was because I had two transparent proxies in the same
network and was basically redirecting traffic twice:
[internet] <-> [appliance 1] <-> [appliance 2] <-> [client computer]

I mistakenly added iptables redirect rules in both appliance 1 and
appliance 2 and that caused Squid to spit out that "forwarding loop
detected" error.


On Thu, Feb 12, 2015 at 4:40 AM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Thursday 12 Feb 2015 at 11:26, naser sonbaty wrote:
>
> > Hi,
> >
> > Internet is connected to Router PC
> >
> > Only trafic to port 80 is send to squid.
>
> Yes, I know that, but traffic *from* where?
>
> Please answer the question below.  Even better, show us the redirect rule
> you're using on the router to do it.
>
> > On Thu, Feb 12, 2015 at 11:58 AM, Antony Stone wrote:
> > >
> > > Have you configured the router to redirect port 80 traffic from the
> > > Client PC to Squid 3129, or have you configured it to redirect *all*
> port
> > > 80 traffic (including from Squid) to Squid 3129?
> > >
> > > Looks like the Router is making Squid talk to itself.
>
>
> Regards,
>
>
> Antony.
>
> --
> I love deadlines.   I love the whooshing noise they make as they go by.
>
>  - Douglas Noel Adams
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/563f7a40/attachment-0001.htm>

From luismiguelferreirasilva at gmail.com  Thu Feb 12 14:40:05 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Thu, 12 Feb 2015 07:40:05 -0700
Subject: [squid-users] A little help with squid and e-cap
In-Reply-To: <54DC61F3.9090700@treenet.co.nz>
References: <CA+suCFjJ=04g3VFK2yYDEm2ye6DYsvPDixG5=wF=gNu1Ee6+Bg@mail.gmail.com>
 <54DC61F3.9090700@treenet.co.nz>
Message-ID: <CA+suCFj5-0s5qEHD04JbyyWDWymD8GO_iEEwwYUgDA36Mh9cig@mail.gmail.com>

Thanks Amos!

I understand it loads a library (probably only once) but, what about the
actual ecap service object? Does it load once per page request? Or does it
pre-load it every time?

The reason why I'm asking this is that I would like to create a ecap
modifier service that reads a big list from the hard drive and, ideally, it
would just keep that list in memory between page requests instead of
loading it every single time.

Thank you,
Luis

On Thu, Feb 12, 2015 at 1:18 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> > - *Is each ecap_service loaded on each page load?*
> > -- Or does it preload a couple of ecap_services and keep using those over
> > and over again (just like it does with c-icap and redirect_programs?)
> > -- I can see each ecap module implements configure, reconfigure, start,
> > stop and retire methods so...it SHOULD be possible to preload the script
> > and just call reconfigure on each call. What does Squid do?
>
> No. Yes. Squid loads a library.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/3d1fd8ca/attachment.htm>

From yvoinov at gmail.com  Thu Feb 12 15:34:42 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 12 Feb 2015 21:34:42 +0600
Subject: [squid-users] A little help with squid and e-cap
In-Reply-To: <CA+suCFj5-0s5qEHD04JbyyWDWymD8GO_iEEwwYUgDA36Mh9cig@mail.gmail.com>
References: <CA+suCFjJ=04g3VFK2yYDEm2ye6DYsvPDixG5=wF=gNu1Ee6+Bg@mail.gmail.com>
 <54DC61F3.9090700@treenet.co.nz>
 <CA+suCFj5-0s5qEHD04JbyyWDWymD8GO_iEEwwYUgDA36Mh9cig@mail.gmail.com>
Message-ID: <54DCC812.1020204@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Squid loads ecap service only one time. When starts.

12.02.15 20:40, Luis Miguel Silva ?????:
> Thanks Amos!
> 
> I understand it loads a library (probably only once) but, what
> about the actual ecap service object? Does it load once per page
> request? Or does it pre-load it every time?
> 
> The reason why I'm asking this is that I would like to create a
> ecap modifier service that reads a big list from the hard drive
> and, ideally, it would just keep that list in memory between page
> requests instead of loading it every single time.
> 
> Thank you, Luis
> 
> On Thu, Feb 12, 2015 at 1:18 AM, Amos Jeffries
> <squid3 at treenet.co.nz> wrote:
> 
>>> - *Is each ecap_service loaded on each page load?* -- Or does
>>> it preload a couple of ecap_services and keep using those over 
>>> and over again (just like it does with c-icap and
>>> redirect_programs?) -- I can see each ecap module implements
>>> configure, reconfigure, start, stop and retire methods so...it
>>> SHOULD be possible to preload the script and just call
>>> reconfigure on each call. What does Squid do?
>> 
>> No. Yes. Squid loads a library.
>> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3MgSAAoJENNXIZxhPexGe9wH/2Bg0jT1w9mMDTDw4VZBL3BF
Y1Jmhf9W5nHH/qO+Js/7CsGzR6yRP2fXgvHjA3N3jzP6zx5OaYZ5uXOOhHY8rEcY
obiEpAyJAONird6g9ZHBEHR/6RDQimYtnQGaO/OefEVcRO/k1ha5gSGt776Bv1Gr
MTFGL6SDPm14hEeXHGFgj7qtJp7I3VGsK4X7+zekXw8b7fqE3cN5VNeO/tFLf5xK
nP+saiOtOWevshqSEJuZcySXDSKwevyGsp/5tL0LT2gFJPRw/bqNyXgl5QUn6AyC
C/cY0Wcl3Vr+o74WTZPBCTajiyXkci67bUR43nlMdueEfDXtUWkr+8TNsByr33I=
=4p57
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Thu Feb 12 16:22:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 05:22:24 +1300
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <1423750370136-4669767.post@n4.nabble.com>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz> <1423550733210-4669651.post@n4.nabble.com>
 <54DBE990.9080003@treenet.co.nz> <1423743711753-4669764.post@n4.nabble.com>
 <54DCA657.4040605@treenet.co.nz> <1423750370136-4669767.post@n4.nabble.com>
Message-ID: <54DCD340.2060608@treenet.co.nz>

On 13/02/2015 3:12 a.m., amitinfo2k wrote:
> Splash is just a static HTML page as folllows:
> ----------------------------------------------------------
> /etc/squid/splash.html
> ----------------------------------------------------------
> <html>
>     <head>
>         <title>splash screen example</title>
>     </head>
>     <body>
>      This is splash screen

You are missing the bit which directs the user to the login URL:

  <br>
  <a href="http://example.net/">Click to start browsing</a>

>     </body>
> </html>
> ----------------------------------------------------------
> I have a VM (Fedora19) where i have installed the squid and this VM has
> internet access.
> now on this VM itself I am opening a Browser with proxy setting a VM IP and
> port 3128.
> Also, I tried from host m/c browser configured proxy settings as VM IP and
> port 3128.
> I am able to browse the internet. But no splash screen coming in between.
> so, how does the session work here ? as per configuration -T 60 sec every
> one min session should be expired right ? and then i should be able to see
> the splash.

I meant what does "browse the internet" involve for your tests.

If you visit "http://example.net/" at any point the session is logged in
created and you can then browse. Even if you have not seen the splash page.

Make sure the session DB from old experiments is erased. You may be
using an old session.

All this also depends on where it is in relation to other http_access
rules in the config file.

Amos



From sis at open.ch  Thu Feb 12 16:41:30 2015
From: sis at open.ch (=?iso-8859-1?Q?Simon_St=E4heli?=)
Date: Thu, 12 Feb 2015 17:41:30 +0100
Subject: [squid-users] benefits of
	usingext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <mailman.42287.1423690543.1833.squid-users@lists.squid-cache.org>
References: <mailman.42287.1423690543.1833.squid-users@lists.squid-cache.org>
Message-ID: <A77FDA65-6F38-4C4F-A323-C1B749878B5A@open.ch>

> 
> 
> From: "Markus Moeller" <huaraz at moeller.plus.com>
> Subject: Re: [squid-users] benefits of usingext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
> Date: 11. Februar 2015 22:32:11 MEZ
> To: squid-users at squid-cache.org
> 
> 
>>>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>>>> Hash: SHA1
>>>>>> 
>>>>>> On 20/01/2015 11:31 p.m., Simon St?heli wrote:
>>>>>>> Are there any other benefits in using ext_kerberos_ldap_group_acl
>>>>>>> instead of ext_ldap_group_acl except the "Netbios name to Kerberos
>>>>>>> domain name? mappings provided by the -N option. As far as I can
>>>>>>> tell, this mapping can also easily be done by writing you own
>>>>>>> helper perl script which is doing the mapping and finally feeds the
>>>>>>> more common ext_ldap_group_acl helper.
>>>>>>> 
>>>>>> 
>>>>>> Whatever floats your boat. The point of the Addon/Plugin/helpers API
>>>>>> is that you can use scripts if thy serve your needs better.
>>>>>> 
>>>>>> All the usual Open Source benefits of "many eyeballs" and somebody
>>>>>> else doing code maintenance for you applies to using a bundled helper
>>>>>> over a custom written one.
>>>>>> 
>>>>>> Beyond that the kerberos helper also provides automatic detection of
>>>>>> which LDAP server to use via mutiple auto-configuration methods.
>>>>>> 
>>>>> 
>>>>> The idea of the helper was to automate most of the configuration (
>>>>> ignoring
>>>>> some performance ) and avoid using a username/password, support users
>>>>> from
>>>>> multiple domains. Secondly I wanted check for nested groups which was
>>>>> not
>>>>> available in the existing helper and thirdly I also check now against
>>>>> the
>>>>> primary group of the user.
>>>>> 
>>>> 
>>>> Thank you Markus for your explanations. I played around with
>>>> ext_kerberos_ldap_group_acl and would like to go into some details:
>>>> 
>>>> 1) it is possible to define more than one LDAP server (e.g. for high
>>>> availability reasons)? The -l parameter allows only one ldap url while
>>>> -S allows several "server > realm" - mappings.
>>>> 
>>> 
>>> I didn't see the need.  The -l was more for cases when digest or basic auth
>>> is used and I do not know the domain to check against.  So a fallback
>>> option.
>>> 
>>> 
>>>> 2) It is correct, that compared to ext_ldap_group_acl,
>>>> ext_kerberos_ldap_group_acl does not require a groupname as input (from
>>>> stdin), because -g -t -T or -D control the group name?!
>>>> 
>>> 
>>> You have two options with ext_kerberos_ldap_group_acl  as input or as -g ..
>>> control
>>> 
>>> 
>>>> 3) What is the use case for defining -g GROUP@? What is the difference
>>>> to -g GROUP (without @)
>>>> 
>>> 
>>> -g GROUP is for all users including the once with nor provided domain
>>> 
>>> 
>>> The an pages describe it a bit under Note:
>>> 
>>> 1) For user at REALM
>>>  a) Query DNS for SRV record _ldap._tcp.REALM
>>>  b) Query DNS for A record REALM
>>>  c) Use LDAP_URL if given
>>> 
>>> 2) For user
>>>  a) Use domain -D REALM and follow step 1)
>>>  b) Use LDAP_URL if given
>>> 
>>> The Groups to check against are determined as follows:
>>> 
>>> 1) For user at REALM
>>>  a)  Use  values  given  by -g option which contain a @REALM e.g. -g
>>> GROUP1 at REALM:GROUP2 at REALM
>>>  b) Use values given by -g option which contain a  @  only  e.g.  -g
>>> GROUP1@:GROUP2@
>>>  c)  Use values given by -g option which do not contain a realm e.g.
>>> -g GROUP1:GROUP2
>>> 
>>> 2) For user
>>>  a) Use values given by -g option which do not contain a realm  e.g.
>>> -g GROUP1:GROUP2
>>> 
>>> 3) For NDOMAIN\user
>>>  a) Use realm given by -N NDOMAIN at REALM and then use values given by
>>> -g option which contain a @REALM e.g. -g GROUP1 at REALM:GROUP2 at REALM
>>> 
>>> 
>>> 
>>>> 4) The "query DNS for SRV record _ldap._tcp.REALM" mechanism seems no to
>>>> work for me although the DNS server is configured correctly and querying
>>>> with "dig SRV _ldap._tcp.REALM" works fine. Anything to consider here?
>>>> _ldap._tcp.REALM SRV query was never sent so far.
>>>> 
>>> 
>>> I would not see an obvious reason.   Does -d show any hints ?  I can only
>>> imagine that REAM is not what is send by the client.
>>> 
>>>> 5) Similar issues with the Kerberos feature. Keytab und Kerberos config
>>>> are available and exported, but the helper only says:
>>>> support_ldap.cc(888): DEBUG: Setup Kerberos credential cache
>>>> support_ldap.cc(897): DEBUG: Kerberos is not supported. Use
>>>> username/password with ldap url instead
>>>> 
>>> 
>>> The message support_ldap.cc(897): DEBUG: Kerberos is not supported. means
>>> your Kerberos installation is not fully available. It means HAVE_KRB5 is not
>>> set ( maybe header files were missing).
>> 
>> 
>> Can you give me some further information about the requirements of the helper regarding kerberos? I am trying to use it with Heimdal kerberos (Heimdal 1.3.3). negotiate_kerberos_auth for example works very well with the present kerberos libraries.
>> 
>> 
> 
> Can you send the config.log file ?  For some reason HAVE_KRB5 is not set ( which is a bit strange as it is also used for the auth helper)


hmh, HAVE_KRB5 seems not to be set in include/autoconf.h

What is the correct way to provide squid the path to the kerberos header files? 

./configure ?help doesn?t show a useful option as --with-krb5-config= seems not to be the right option.

What I did: set KRBINCS and KRBLIBS to following values:

KRB5INCS="-DHAVE_GSSAPI -DHAVE_GSSAPI_GSSAPI_H -DHAVE_GSSAPI_H -DHAVE_HEIMDAL_KERBEROS -I/path/to/krb5/include -DHAVE_STRING_H -DHAVE_STDOI_H -DHAVE_NETDB_H -DHAVE_UNISTD_H -DHAVE_TIME_H?
KRB5LIBS="-L/path/to/krb5/lib -lgssapi -lkrb5 -lcom_err -lasn1 -lroken?

and executed ./configure with following parameters

./configure --prefix=/path/to/squid --sysconfdir=/path/to/squid/etc --mandir=/usr/share/man --enable-auth --enable-auth-basic="LDAP" --enable-auth-digest="none" --enable-auth-ntlm="none" --enable-auth-negotiate="kerberos,wrapper" --enable-url-rewrite-helpers="none" --enable-storeio="ufs,aufs" --with-default-user=squid --enable-delay-pools --with-large-files --enable-icap-client --with-pthreads --disable-ident-lookups --disable-icmp --enable-ipv6 --with-filedescriptors=65536 --disable-translation --enable-removal-policies="heap,lru" --enable-ssl --enable-ssl-crtd --enable-log-daemon-helpers="file" --disable-translation --disable-auto-locale --enable-stacktraces ?includedir=?/path/to/krb5/include" --with-krb5-config=?/path/to/krb5/include? --enable-external-acl-helpers="LDAP_group,wbinfo_group,kerberos_ldap_group?

kerberos_ldap_group does not compile automatically when executing make. I had to compile it manually by executing make in ./helpers/external_acl/kerberos_ldap_group

negotiate_kerberos_auth works this way.



> 
>>> 
>>>> Instead of that I found a dns SRV _kerberos._udp.REALM query which was
>>>> actually answered by the dns. I assume this is related to the Kerberos
>>>> feature?
>>> 
>>> yes it is. It is a way to find the kdc.
>>> 
>>>> 
>>>> 6) It is possible to use the helper when DNS service is not reachable?
>>>> Got some error messages during testing:
>>>> 
>>>> kerberos_ldap_group: DEBUG: Canonicalise ldap server name
>>>> 213.156.236.111:3268
>>>> kerberos_ldap_group: ERROR: Error while resolving ip address with
>>>> getnameinfo: Temporary failure in name resolution
>>>> kerberos_ldap_group: DEBUG: Error during initialisation of ldap
>>>> connection: Success
>>>> 
>>> 
>>> If you add a line to your hosts file and use the approriate nsswitch.conf it
>>> should work.  You can also add a line to the hosts file for the domain for
>>> the case the SRV record fails.
>>> 
>>> 
>>>> Beside this tiny issues the helper works excellent (tested with basic,
>>>> NTLM and Kerberos authentication). I am just trying to discover the
>>>> whole potential. Thank you very much for any responses.
>>>> 
>>>> Regards
>>>> Simon
>>>> 
>>> 
>>> Regards
>>> Markus
>>> 
>>>>>> If you can demonstrate that the ext_kerberos_ldap_group_acl does
>>>>>> provides a superset of the functionality of ext_ldap_group_acl helper
>>>>>> then I can de-duplicate the two helpers.
>>>>>> 
>>>>>> Amos
>>>>> 
>>>>> Regards
>>>>> Markus
>>>> 
>>> 
> Markus 
> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/e4088593/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4030 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/e4088593/attachment.bin>

From squid3 at treenet.co.nz  Thu Feb 12 16:58:53 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 05:58:53 +1300
Subject: [squid-users] benefits of
 usingext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <A77FDA65-6F38-4C4F-A323-C1B749878B5A@open.ch>
References: <mailman.42287.1423690543.1833.squid-users@lists.squid-cache.org>
 <A77FDA65-6F38-4C4F-A323-C1B749878B5A@open.ch>
Message-ID: <54DCDBCD.5070909@treenet.co.nz>

On 13/02/2015 5:41 a.m., Simon St?heli wrote:
>
> hmh, HAVE_KRB5 seems not to be set in include/autoconf.h
> 
> What is the correct way to provide squid the path to the kerberos header files? 
> 
> ./configure ?help doesn?t show a useful option as --with-krb5-config= seems not to be the right option.

If you are using Squid-3.4 or older versions where that option exists,
you need to insted use CXXFLAGS to set the -I (library headers) and -L
(library binary) locations.
Something like:
 ./configure CXXFLAGS="-I/path/to/include -L/path/to/lib" ...


Squid-3.5 and later have per-library ./configure options. In the case of
Heimdal use --with-heimdal-krb5=PATH


Amos



From yvoinov at gmail.com  Thu Feb 12 18:01:36 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 00:01:36 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
	children?
Message-ID: <54DCEA80.2090204@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi gents,

subj.

And, of course - question. How to do that? I've don't seen this, if it
exists.

For example, for this config stub:

url_rewrite_program /usr/local/bin/squidGuard -c
/usr/local/squidGuard/squidGuard.conf
url_rewrite_children 100 startup=0 idle=1 concurrency=0

After daily activity, at midnight, still remain near 60 processes.
Absolutely idle.

So, why?

WBR, Yuri
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3OqAAAoJENNXIZxhPexG05YH/1sSGYcFRPQe2eXpSiigO534
U2X5Cr2VYfbXTWzPTiygwPTL5vUqgsJTg62XdgX5MDyetFtATiYbQri/ic7jf7yd
EC8ZRUGgpT5XtwPqfXtPAKHrUYGi+jqW7HF/llI7/vGt2d6TlkuV8fu9yHxhqmC/
tSbJUkQy+GeRs7dzhtgtKRIGPgtssjlx39wa6Pw/8j47ZaGO7qjUyjIpIIrI0MVS
D+X6uc16iNPMGh3icMj/WEbXiKB0xmtbxZWMO0ES32By2yDfxnIMSWZzcTnakpN0
ahdSLoOi7Y72eTBcvxi8cdQl55DeUK9/6zDC+CJ9s3L/RApwEgMCF7tVW+DFyDY=
=3eyj
-----END PGP SIGNATURE-----


From amit_info2k at yahoo.com  Thu Feb 12 18:14:02 2015
From: amit_info2k at yahoo.com (amitinfo2k)
Date: Thu, 12 Feb 2015 10:14:02 -0800 (PST)
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <54DCD340.2060608@treenet.co.nz>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz> <1423550733210-4669651.post@n4.nabble.com>
 <54DBE990.9080003@treenet.co.nz> <1423743711753-4669764.post@n4.nabble.com>
 <54DCA657.4040605@treenet.co.nz> <1423750370136-4669767.post@n4.nabble.com>
 <54DCD340.2060608@treenet.co.nz>
Message-ID: <1423764842792-4669775.post@n4.nabble.com>

Thanks I have rearranged the rules and now after the session is expired
I am seeing the page with following content :
-----------------------------------------------------
Internal Error: Missing Template /etc/squid/splash.html
-----------------------------------------------------
It's like it is not able to locate the template splash even though it exists
there.
no error in the logs.






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Portal-Splash-Pages-example-on-squid-3-3-13-tp4669634p4669775.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Thu Feb 12 18:49:30 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 07:49:30 +1300
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCEA80.2090204@gmail.com>
References: <54DCEA80.2090204@gmail.com>
Message-ID: <54DCF5BA.5010207@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
> Hi gents,
> 
> subj.
> 
> And, of course - question. How to do that? I've don't seen this, if
> it exists.
> 
> For example, for this config stub:
> 
> url_rewrite_program /usr/local/bin/squidGuard -c 
> /usr/local/squidGuard/squidGuard.conf url_rewrite_children 100
> startup=0 idle=1 concurrency=0
> 
> After daily activity, at midnight, still remain near 60 processes. 
> Absolutely idle.
> 
> So, why?

The idle=1 parameter "Sets a minimum ..."

It actually is quite expensive to start them. At least one client is
being held in a pause waiting for it, and others are slowed down while
the CPU spawns the process.

Chances are high that the next day, or even a few seconds later you
will need to use them again anyway. So its a bit better to have them
idle than to discard completely.

*Particularly* since you have no concurrency for the helper. A single
client loading a page with many objects can initiate many parallel
requests. Each of which will need to be processed by one of those helpers.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU3PW6AAoJELJo5wb/XPRjfkoIAKdLnuooSopmUfHiHALLRZJP
y8SCobhh34GXIHV2GoG+c/z9qJCKbbUlO4U7uKswH//HpNWGN56in6bkIex8I52d
1JpDT1GQvSHVgXuArHYjKWjrHmRBWxkR8U5SfMXfJNvm7FxrRaLlxuPPPeEK6+WZ
oNUbA3NH4pJr+7LGMDfBD3wlcZqedXPY8zav7hoNQsg1AphojgDDHSyrd6P7eLO8
dY4vJhYE81plcwsZJm8WRSc+yb/bqdiZBYWm6sZbOddo/GtOltdzstY9DZUhERqE
ag+boubub/9lQ74vm4WuJ08SZd4KLqv/B3lurT0dOjgnfotf79mKwhK1DxyMAwo=
=2ssc
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Thu Feb 12 19:01:21 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 01:01:21 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCF5BA.5010207@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
Message-ID: <54DCF881.7020102@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



13.02.15 0:49, Amos Jeffries ?????:
> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>> Hi gents,
> 
>> subj.
> 
>> And, of course - question. How to do that? I've don't seen this,
>> if it exists.
> 
>> For example, for this config stub:
> 
>> url_rewrite_program /usr/local/bin/squidGuard -c 
>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children 100 
>> startup=0 idle=1 concurrency=0
> 
>> After daily activity, at midnight, still remain near 60
>> processes. Absolutely idle.
> 
>> So, why?
> 
> The idle=1 parameter "Sets a minimum ..."
> 
> It actually is quite expensive to start them. At least one client
> is being held in a pause waiting for it, and others are slowed down
> while the CPU spawns the process.

I understand. But Apache-like model will be better. And so, it works
much years in web-front's. Timeout for idle - then shutdown all idle
processed.

> 
> Chances are high that the next day, or even a few seconds later
> you will need to use them again anyway. So its a bit better to have
> them idle than to discard completely.
> 
> *Particularly* since you have no concurrency for the helper. A
> single
SquidGuard was never been threaded.

> client loading a page with many objects can initiate many parallel 
> requests. Each of which will need to be processed by one of those
> helpers.

I understand. But will be better to have more weak instrumentation to
manage children. Either Apache-like, or default.

First query latency is important, but when I tun out of memory, this
query will never be executed in any case.

Moreover - some kernels - especially after swap out idle process, can
not return it quickly to CPU.

The system, which has permanently low memory, have hi risk to slow
down to deep swaping.

Amos, current mechanism is so ungainly. I want to have more powerful
control over rewriter processes.

Now they live their lives. By the end of the day I have a lot of
running processes that do not do anything. And can occupy more than 1
GB of RAM valuable. And there is no mechanism other than sporadic
displacement of the operating system. If you accidentally took the memory.

It's better than it was before, when I had 100 running redirectors
always and 1.5 GB of memory consumed with the threat of a swap, but
worse than the management of processes in Apache. And, therefore,
memory management.

> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3PiBAAoJENNXIZxhPexGL9QIAMgNh7ANHIfxBAITFka4tJB6
neM0p29jBYlNHskrLyVNqhgDL6XagRCCYp9VzJqVajtCDCejasxx0NV0qDW19uu0
7HcepMGhL6l9WDGm9JyvQo4uz4/00F9ZE3EvUu2lyZmIFaX39rDNnVg64b7EbrJI
fKoS0MfoXSPi+8I+nMcaGNdvWXIKXqsVhL5EJ6X690c2XvpjCv9HmGnf1/k2O6qe
GJprX0yPDgXj0OJhNeM1WZfSa+PQIjD6VXwuqUXpSPU9DFnBT5sZoZ9QqZdUc3Io
fhahOi7Rve3QD13sPb+4FE+pIZECLdvvJ1lWySn+l5zOJD5ZoEGis3qGJmj7xNM=
=hYfs
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Thu Feb 12 19:05:14 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 01:05:14 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCF5BA.5010207@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
Message-ID: <54DCF96A.3060502@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I want to say:

A system with low consumpted memory will starts processes more quickly
against system with low free memory and overloaded cheduler and more
sleep processes in most cases.

So, IMHO better solution is possibility to shutdown idle children
after configured timeout and starts them up when required.

Also, OS cache also still exists..... and can hold rewriter ELF near
CPU.... did you remember? ;)

13.02.15 0:49, Amos Jeffries ?????:
> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>> Hi gents,
> 
>> subj.
> 
>> And, of course - question. How to do that? I've don't seen this,
>> if it exists.
> 
>> For example, for this config stub:
> 
>> url_rewrite_program /usr/local/bin/squidGuard -c 
>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children 100 
>> startup=0 idle=1 concurrency=0
> 
>> After daily activity, at midnight, still remain near 60
>> processes. Absolutely idle.
> 
>> So, why?
> 
> The idle=1 parameter "Sets a minimum ..."
> 
> It actually is quite expensive to start them. At least one client
> is being held in a pause waiting for it, and others are slowed down
> while the CPU spawns the process.
> 
> Chances are high that the next day, or even a few seconds later
> you will need to use them again anyway. So its a bit better to have
> them idle than to discard completely.
> 
> *Particularly* since you have no concurrency for the helper. A
> single client loading a page with many objects can initiate many
> parallel requests. Each of which will need to be processed by one
> of those helpers.
> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3PlpAAoJENNXIZxhPexGiIcH/2rXn42yxPtwmnaxoqhIkyZd
U3Jj9AQBQeKMz+Ncbzs/rBTWYBmqTqDh70q9toMqDO+UVPyhEx/ltzM9A38ClbO9
XJS3x0SI25TegG1rkJuT6B98RUA15lcS3CsQg6hU8YNbT/ERMPCrX+oL8F9f6qAG
pHmQHM5EHVe+5YTWi8V2CaP+ybw6xoBg8eWQtyTca5JbzChgCckzS/LFHYiBmTRM
pC5KJy2buSTMxuDsBowbv3DkNUabzz5pbuGt0skIoO6rLh+qo6ZT+w+Q8BVK8nrr
mHHsXtl4MvFJpnljqhqti9MAqnksr+N1Yj5VLVWl0Q+PWD2eN49pgTt9hUpka3E=
=E/7E
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Thu Feb 12 19:15:50 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 08:15:50 +1300
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <1423764842792-4669775.post@n4.nabble.com>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz> <1423550733210-4669651.post@n4.nabble.com>
 <54DBE990.9080003@treenet.co.nz> <1423743711753-4669764.post@n4.nabble.com>
 <54DCA657.4040605@treenet.co.nz> <1423750370136-4669767.post@n4.nabble.com>
 <54DCD340.2060608@treenet.co.nz> <1423764842792-4669775.post@n4.nabble.com>
Message-ID: <54DCFBE6.6050307@treenet.co.nz>

On 13/02/2015 7:14 a.m., amitinfo2k wrote:
> Thanks I have rearranged the rules and now after the session is expired
> I am seeing the page with following content :
> -----------------------------------------------------
> Internal Error: Missing Template /etc/squid/splash.html
> -----------------------------------------------------
> It's like it is not able to locate the template splash even though it exists
> there.
> no error in the logs.
> 

Doh! Sorry I keep forgetting the patch I use for allowing absolute
template paths is not merged.


You need to place the page in the default error page templates directory
(.../error/templates/), or create a symlink from there to your
/etc/squid/splash.html file.

The deny_info line gets just the name of the file/symlink within the
templates directory.
 deny_info 511:splash.html ...


Amos



From yvoinov at gmail.com  Thu Feb 12 19:19:28 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 01:19:28 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCF5BA.5010207@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
Message-ID: <54DCFCC0.1060603@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

BTW,

the expected behavior of a directive -

url_rewrite_children 100 startup=0 idle=1 concurrency=0

Starts with 0 initial processes,

then starts when requests up to 100,

and after some idle timeout (and be better to specify this timeout to
accomplish proxy specific behaviour) - kill idle processes to "idle=1"
value.

13.02.15 0:49, Amos Jeffries ?????:
> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>> Hi gents,
> 
>> subj.
> 
>> And, of course - question. How to do that? I've don't seen this,
>> if it exists.
> 
>> For example, for this config stub:
> 
>> url_rewrite_program /usr/local/bin/squidGuard -c 
>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children 100 
>> startup=0 idle=1 concurrency=0
> 
>> After daily activity, at midnight, still remain near 60
>> processes. Absolutely idle.
> 
>> So, why?
> 
> The idle=1 parameter "Sets a minimum ..."
> 
> It actually is quite expensive to start them. At least one client
> is being held in a pause waiting for it, and others are slowed down
> while the CPU spawns the process.
> 
> Chances are high that the next day, or even a few seconds later
> you will need to use them again anyway. So its a bit better to have
> them idle than to discard completely.
> 
> *Particularly* since you have no concurrency for the helper. A
> single client loading a page with many objects can initiate many
> parallel requests. Each of which will need to be processed by one
> of those helpers.
> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3PzAAAoJENNXIZxhPexGovkH/iUAkmF22F8JLl9W9loDRALv
r0RdPA0hXf3WcFrKEXZS4a/aS//Ckd3AP4wimfiFFXHPzhM9QuW0WtiqEydIOyzr
Fn3pRKsfvV7/aexn9bByrahAxGiTCcSLI3BG2lJt7TyTcQbxWAjPdmWjGJ+Y7rLC
+8IYzIOnIdkGoXZQ7EepYjaRm4DzYhHznlCAjvFtWSxQq45RpOCnzsrPhVU2NKIU
B7nmrI2znQ3UxkaTqMMjBef1uh5tHj1Lv4+P+1kuir6AFGYtnJ8eyP9FJ3e0piNl
+DfCXMewKkOgWwAiZlALRvE6aPBwYTd0UY36bF9gomU8AZJ0gHu7PFKTJGehvVU=
=vOrV
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Thu Feb 12 19:54:53 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 01:54:53 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCF5BA.5010207@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
Message-ID: <54DD050D.9020809@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

So simple.

I want to see only one additional parameter.

idle_timeout.

When I specify it to 0 - by default - all started rewriter processess
remains after user requests,

but! it I specify it over 0 in seconds - all idle rewriters after
timeout must dies to achieve idle= value.

Logically, isn't it? This permits me to design, how cache will works
with user's sessions. And, moreover, in other software products such
behavior with shared processes is the default. I.e - Oracle shared
server. Apache WEB server in some configurations. And others.

Otherwise idle= parameter for children just do not make sense. SQUID
decides for me, it's better for my system. I want to have better
control over rewriter's children and memory consumption.

Did you agree?

13.02.15 0:49, Amos Jeffries ?????:
> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>> Hi gents,
> 
>> subj.
> 
>> And, of course - question. How to do that? I've don't seen this,
>> if it exists.
> 
>> For example, for this config stub:
> 
>> url_rewrite_program /usr/local/bin/squidGuard -c 
>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children 100 
>> startup=0 idle=1 concurrency=0
> 
>> After daily activity, at midnight, still remain near 60
>> processes. Absolutely idle.
> 
>> So, why?
> 
> The idle=1 parameter "Sets a minimum ..."
> 
> It actually is quite expensive to start them. At least one client
> is being held in a pause waiting for it, and others are slowed down
> while the CPU spawns the process.
> 
> Chances are high that the next day, or even a few seconds later
> you will need to use them again anyway. So its a bit better to have
> them idle than to discard completely.
> 
> *Particularly* since you have no concurrency for the helper. A
> single client loading a page with many objects can initiate many
> parallel requests. Each of which will need to be processed by one
> of those helpers.
> 
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3QUNAAoJENNXIZxhPexG688H+gOtiiVEHv2r0AtR8r/FL6qW
M0aElM8ghDpJtuRQaPULD51cav8mui9u4Q6/z25uRl+8tf0MCqtijpV56IdH3Rpd
pfQ7jcI/MuGb/XDZxLNBH858IMyu4kFtbwdT2OIw7chcszOZNxo6B6ZNiX7Vpkcy
tBxPCjgQvlPzNiZc1w8bbn4TXmVMWRH8hn3NbzI8x4PEWRteBQm7bwQVrvI4LILk
qagoKg5+rhPrAEcjk+iON04Meb/GDurL7ubQE/OsxJNQc3fFn8qWDQbb0mkKv5Vi
q+871IytNgPkhJlxHaYzG1sv9J/lJv4oi9e9rfOhXuA/lZcXKJG4YwzZWhnc9TU=
=J1xo
-----END PGP SIGNATURE-----


From marcus.kool at urlfilterdb.com  Thu Feb 12 20:06:41 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 12 Feb 2015 18:06:41 -0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCF881.7020102@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DCF881.7020102@gmail.com>
Message-ID: <54DD07D1.2040306@urlfilterdb.com>

Yuri,

I suggest to consider using ufdbGuard instead of squidGuard.
Besides being faster is has a different structure:
the redirector that squid starts is a small lightweight process
that forwards requests to ufdbguardd, a multithreaded daemon which
has the URL database in memory.  The database is optimised
for memory and occupies less memory than all those squidguard
processes - where each process has a database cache of 10% or 15%
of the database - so 64 processes means that ufdbguard uses 640%
of the size of the database.

Marcus


On 02/12/2015 05:01 PM, Yuri Voinov wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
>
> 13.02.15 0:49, Amos Jeffries ?????:
>> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>>> Hi gents,
>>
>>> subj.
>>
>>> And, of course - question. How to do that? I've don't seen this,
>>> if it exists.
>>
>>> For example, for this config stub:
>>
>>> url_rewrite_program /usr/local/bin/squidGuard -c
>>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children 100
>>> startup=0 idle=1 concurrency=0
>>
>>> After daily activity, at midnight, still remain near 60
>>> processes. Absolutely idle.
>>
>>> So, why?
>>
>> The idle=1 parameter "Sets a minimum ..."
>>
>> It actually is quite expensive to start them. At least one client
>> is being held in a pause waiting for it, and others are slowed down
>> while the CPU spawns the process.
>
> I understand. But Apache-like model will be better. And so, it works
> much years in web-front's. Timeout for idle - then shutdown all idle
> processed.
>
>>
>> Chances are high that the next day, or even a few seconds later
>> you will need to use them again anyway. So its a bit better to have
>> them idle than to discard completely.
>>
>> *Particularly* since you have no concurrency for the helper. A
>> single
> SquidGuard was never been threaded.
>
>> client loading a page with many objects can initiate many parallel
>> requests. Each of which will need to be processed by one of those
>> helpers.
>
> I understand. But will be better to have more weak instrumentation to
> manage children. Either Apache-like, or default.
>
> First query latency is important, but when I tun out of memory, this
> query will never be executed in any case.
>
> Moreover - some kernels - especially after swap out idle process, can
> not return it quickly to CPU.
>
> The system, which has permanently low memory, have hi risk to slow
> down to deep swaping.
>
> Amos, current mechanism is so ungainly. I want to have more powerful
> control over rewriter processes.
>
> Now they live their lives. By the end of the day I have a lot of
> running processes that do not do anything. And can occupy more than 1
> GB of RAM valuable. And there is no mechanism other than sporadic
> displacement of the operating system. If you accidentally took the memory.
>
> It's better than it was before, when I had 100 running redirectors
> always and 1.5 GB of memory consumed with the threat of a swap, but
> worse than the management of processes in Apache. And, therefore,
> memory management.
>
>>
>> Amos _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU3PiBAAoJENNXIZxhPexGL9QIAMgNh7ANHIfxBAITFka4tJB6
> neM0p29jBYlNHskrLyVNqhgDL6XagRCCYp9VzJqVajtCDCejasxx0NV0qDW19uu0
> 7HcepMGhL6l9WDGm9JyvQo4uz4/00F9ZE3EvUu2lyZmIFaX39rDNnVg64b7EbrJI
> fKoS0MfoXSPi+8I+nMcaGNdvWXIKXqsVhL5EJ6X690c2XvpjCv9HmGnf1/k2O6qe
> GJprX0yPDgXj0OJhNeM1WZfSa+PQIjD6VXwuqUXpSPU9DFnBT5sZoZ9QqZdUc3Io
> fhahOi7Rve3QD13sPb+4FE+pIZECLdvvJ1lWySn+l5zOJD5ZoEGis3qGJmj7xNM=
> =hYfs
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From yvoinov at gmail.com  Thu Feb 12 20:11:19 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 02:11:19 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DD07D1.2040306@urlfilterdb.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DCF881.7020102@gmail.com> <54DD07D1.2040306@urlfilterdb.com>
Message-ID: <54DD08E7.5030307@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I talking not about another redirector. But about smart Squid
behaviour with redirector's children.

If I wanted to change redirector - I would have already done it. I am
aware of the existence of ufdvGuard. Moreover - I've tried to build it
on my system. Failed - it cannot build without dancing with a
tambourine. I have enough Squid with his tambourines.

I only want to more control over redirector's processes. Not more. And
cnanging free redirector to commercial one is not an option.


13.02.15 2:06, Marcus Kool ?????:
> Yuri,
> 
> I suggest to consider using ufdbGuard instead of squidGuard. 
> Besides being faster is has a different structure: the redirector
> that squid starts is a small lightweight process that forwards
> requests to ufdbguardd, a multithreaded daemon which has the URL
> database in memory.  The database is optimised for memory and
> occupies less memory than all those squidguard processes - where
> each process has a database cache of 10% or 15% of the database -
> so 64 processes means that ufdbguard uses 640% of the size of the
> database.
> 
> Marcus
> 
> 
> On 02/12/2015 05:01 PM, Yuri Voinov wrote:
> 
> 
> 13.02.15 0:49, Amos Jeffries ?????:
>>>> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>>>>> Hi gents,
>>>> 
>>>>> subj.
>>>> 
>>>>> And, of course - question. How to do that? I've don't seen
>>>>> this, if it exists.
>>>> 
>>>>> For example, for this config stub:
>>>> 
>>>>> url_rewrite_program /usr/local/bin/squidGuard -c 
>>>>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children
>>>>> 100 startup=0 idle=1 concurrency=0
>>>> 
>>>>> After daily activity, at midnight, still remain near 60 
>>>>> processes. Absolutely idle.
>>>> 
>>>>> So, why?
>>>> 
>>>> The idle=1 parameter "Sets a minimum ..."
>>>> 
>>>> It actually is quite expensive to start them. At least one
>>>> client is being held in a pause waiting for it, and others
>>>> are slowed down while the CPU spawns the process.
> 
> I understand. But Apache-like model will be better. And so, it
> works much years in web-front's. Timeout for idle - then shutdown
> all idle processed.
> 
>>>> 
>>>> Chances are high that the next day, or even a few seconds
>>>> later you will need to use them again anyway. So its a bit
>>>> better to have them idle than to discard completely.
>>>> 
>>>> *Particularly* since you have no concurrency for the helper.
>>>> A single
> SquidGuard was never been threaded.
> 
>>>> client loading a page with many objects can initiate many
>>>> parallel requests. Each of which will need to be processed by
>>>> one of those helpers.
> 
> I understand. But will be better to have more weak instrumentation
> to manage children. Either Apache-like, or default.
> 
> First query latency is important, but when I tun out of memory,
> this query will never be executed in any case.
> 
> Moreover - some kernels - especially after swap out idle process,
> can not return it quickly to CPU.
> 
> The system, which has permanently low memory, have hi risk to slow 
> down to deep swaping.
> 
> Amos, current mechanism is so ungainly. I want to have more
> powerful control over rewriter processes.
> 
> Now they live their lives. By the end of the day I have a lot of 
> running processes that do not do anything. And can occupy more than
> 1 GB of RAM valuable. And there is no mechanism other than
> sporadic displacement of the operating system. If you accidentally
> took the memory.
> 
> It's better than it was before, when I had 100 running redirectors 
> always and 1.5 GB of memory consumed with the threat of a swap,
> but worse than the management of processes in Apache. And,
> therefore, memory management.
> 
>>>> 
>>>> Amos _______________________________________________
>>>> squid-users mailing list squid-users at lists.squid-cache.org 
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3QjnAAoJENNXIZxhPexG6b4H/ibFEpNS5f25ESr3H6EttwrN
2kW2bWd52g3C7SeM783K9f92EOpNgwLSXd2SDKXnQAfJeYoYl6AqPge5vjg7l6R2
YB0PbAnjJZvju7gmRfYqhhcXAasGBPq1Ot5vbnoo6JNP3JEjoxRlFPo9KKPxXmLF
q32bw1z7D8hExkMBZx/Esq44kISpxo3fNx9Zd1EwhnzzXcX5qcwoZ46/pWOiHd5/
4hd9u1ZAoOFFfAc64YiP49rXcelAFgO7nl5NLOcx50n4F+uTa14lRhrhmmmex/Wz
tdwEXXpwnXsJKCwt/zMJo3StW05/DxmVXidjfUWuHlSA10RKRbsPRaWRBtKPba0=
=t+/k
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Thu Feb 12 20:18:57 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 02:18:57 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DD07D1.2040306@urlfilterdb.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DCF881.7020102@gmail.com> <54DD07D1.2040306@urlfilterdb.com>
Message-ID: <54DD0AB1.3090300@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I am quite satisfied with the existing configuration and just want
more flexibility in the management of redirectors. ;)

13.02.15 2:06, Marcus Kool ?????:
> Yuri,
> 
> I suggest to consider using ufdbGuard instead of squidGuard. 
> Besides being faster is has a different structure: the redirector
> that squid starts is a small lightweight process that forwards
> requests to ufdbguardd, a multithreaded daemon which has the URL
> database in memory.  The database is optimised for memory and
> occupies less memory than all those squidguard processes - where
> each process has a database cache of 10% or 15% of the database -
> so 64 processes means that ufdbguard uses 640% of the size of the
> database.
> 
> Marcus
> 
> 
> On 02/12/2015 05:01 PM, Yuri Voinov wrote:
> 
> 
> 13.02.15 0:49, Amos Jeffries ?????:
>>>> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>>>>> Hi gents,
>>>> 
>>>>> subj.
>>>> 
>>>>> And, of course - question. How to do that? I've don't seen
>>>>> this, if it exists.
>>>> 
>>>>> For example, for this config stub:
>>>> 
>>>>> url_rewrite_program /usr/local/bin/squidGuard -c 
>>>>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children
>>>>> 100 startup=0 idle=1 concurrency=0
>>>> 
>>>>> After daily activity, at midnight, still remain near 60 
>>>>> processes. Absolutely idle.
>>>> 
>>>>> So, why?
>>>> 
>>>> The idle=1 parameter "Sets a minimum ..."
>>>> 
>>>> It actually is quite expensive to start them. At least one
>>>> client is being held in a pause waiting for it, and others
>>>> are slowed down while the CPU spawns the process.
> 
> I understand. But Apache-like model will be better. And so, it
> works much years in web-front's. Timeout for idle - then shutdown
> all idle processed.
> 
>>>> 
>>>> Chances are high that the next day, or even a few seconds
>>>> later you will need to use them again anyway. So its a bit
>>>> better to have them idle than to discard completely.
>>>> 
>>>> *Particularly* since you have no concurrency for the helper.
>>>> A single
> SquidGuard was never been threaded.
> 
>>>> client loading a page with many objects can initiate many
>>>> parallel requests. Each of which will need to be processed by
>>>> one of those helpers.
> 
> I understand. But will be better to have more weak instrumentation
> to manage children. Either Apache-like, or default.
> 
> First query latency is important, but when I tun out of memory,
> this query will never be executed in any case.
> 
> Moreover - some kernels - especially after swap out idle process,
> can not return it quickly to CPU.
> 
> The system, which has permanently low memory, have hi risk to slow 
> down to deep swaping.
> 
> Amos, current mechanism is so ungainly. I want to have more
> powerful control over rewriter processes.
> 
> Now they live their lives. By the end of the day I have a lot of 
> running processes that do not do anything. And can occupy more than
> 1 GB of RAM valuable. And there is no mechanism other than
> sporadic displacement of the operating system. If you accidentally
> took the memory.
> 
> It's better than it was before, when I had 100 running redirectors 
> always and 1.5 GB of memory consumed with the threat of a swap,
> but worse than the management of processes in Apache. And,
> therefore, memory management.
> 
>>>> 
>>>> Amos _______________________________________________
>>>> squid-users mailing list squid-users at lists.squid-cache.org 
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3QqxAAoJENNXIZxhPexGs6kIAMFisRsnMyUDZAJmAqCyFcQk
7cjz77MWXQ3SM7t2feuJ9J6ntVaiNNHgriD5S6ubtfiBKAvbRIoFm+02ZPSzJZtD
dtTXe8k8D+1ulB2LCr9xtk0fm7QFZ2o2A0+y5mwRAZqCjJU9Lp1OxQNMOB6yBh/a
nvfALwDhBdx3FwABlrG9kV6guqnZ9V23ZM2dhm1LSnJs9nGAHMLKCq+N+lVPkBeE
iPFOgKqCEmD0fYcsjphcXPo+kku9POfpV4hEDAIbNtGY61rCVKUpazDkU37Y3tyc
1DIYwZa7mKgBT10rsVbTjmzT8157V5uLjdu8SlWNh5E61R3P5hTzeXaYHhwquZA=
=JweN
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Thu Feb 12 20:25:39 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 02:25:39 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DD07D1.2040306@urlfilterdb.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DCF881.7020102@gmail.com> <54DD07D1.2040306@urlfilterdb.com>
Message-ID: <54DD0C43.9070505@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

BTW,

now I have average 300-400 Mb total memory consumption over all
working instances of squidGuard. And see only one problem - idle
processes never dies after peak hours, and therefore idle= parameter
is meaningless.

13.02.15 2:06, Marcus Kool ?????:
> Yuri,
> 
> I suggest to consider using ufdbGuard instead of squidGuard. 
> Besides being faster is has a different structure: the redirector
> that squid starts is a small lightweight process that forwards
> requests to ufdbguardd, a multithreaded daemon which has the URL
> database in memory.  The database is optimised for memory and
> occupies less memory than all those squidguard processes - where
> each process has a database cache of 10% or 15% of the database -
> so 64 processes means that ufdbguard uses 640% of the size of the
> database.
> 
> Marcus
> 
> 
> On 02/12/2015 05:01 PM, Yuri Voinov wrote:
> 
> 
> 13.02.15 0:49, Amos Jeffries ?????:
>>>> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>>>>> Hi gents,
>>>> 
>>>>> subj.
>>>> 
>>>>> And, of course - question. How to do that? I've don't seen
>>>>> this, if it exists.
>>>> 
>>>>> For example, for this config stub:
>>>> 
>>>>> url_rewrite_program /usr/local/bin/squidGuard -c 
>>>>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children
>>>>> 100 startup=0 idle=1 concurrency=0
>>>> 
>>>>> After daily activity, at midnight, still remain near 60 
>>>>> processes. Absolutely idle.
>>>> 
>>>>> So, why?
>>>> 
>>>> The idle=1 parameter "Sets a minimum ..."
>>>> 
>>>> It actually is quite expensive to start them. At least one
>>>> client is being held in a pause waiting for it, and others
>>>> are slowed down while the CPU spawns the process.
> 
> I understand. But Apache-like model will be better. And so, it
> works much years in web-front's. Timeout for idle - then shutdown
> all idle processed.
> 
>>>> 
>>>> Chances are high that the next day, or even a few seconds
>>>> later you will need to use them again anyway. So its a bit
>>>> better to have them idle than to discard completely.
>>>> 
>>>> *Particularly* since you have no concurrency for the helper.
>>>> A single
> SquidGuard was never been threaded.
> 
>>>> client loading a page with many objects can initiate many
>>>> parallel requests. Each of which will need to be processed by
>>>> one of those helpers.
> 
> I understand. But will be better to have more weak instrumentation
> to manage children. Either Apache-like, or default.
> 
> First query latency is important, but when I tun out of memory,
> this query will never be executed in any case.
> 
> Moreover - some kernels - especially after swap out idle process,
> can not return it quickly to CPU.
> 
> The system, which has permanently low memory, have hi risk to slow 
> down to deep swaping.
> 
> Amos, current mechanism is so ungainly. I want to have more
> powerful control over rewriter processes.
> 
> Now they live their lives. By the end of the day I have a lot of 
> running processes that do not do anything. And can occupy more than
> 1 GB of RAM valuable. And there is no mechanism other than
> sporadic displacement of the operating system. If you accidentally
> took the memory.
> 
> It's better than it was before, when I had 100 running redirectors 
> always and 1.5 GB of memory consumed with the threat of a swap,
> but worse than the management of processes in Apache. And,
> therefore, memory management.
> 
>>>> 
>>>> Amos _______________________________________________
>>>> squid-users mailing list squid-users at lists.squid-cache.org 
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3QxDAAoJENNXIZxhPexGJK8H/3N3Td4opmjjuEH8WDfWJllO
UxTHGzZ134pgv5gl52QLahAn1gmq99MqPYWQOlwlgLjCJEiarH4aE5G5evlfeZLs
9lAY7aZVqyb1z6iOBI+93mxjzSVqkjQ9gO7V2K6/pP6bQhos3Z1IAoFq2rHSGe/6
XBdqrTqg4wKgDGLRPkN0d5PP5MQakJdsCZ+jogDzi0hkx//1g264s+j4isdlw+UY
iWTAX2rtqj0So4TwUPSFd8MRmzKB82gMaRTh3yr/F+TcMyrcJQdUgefVWdVi59qB
4CPw5mm1V4gGkjrGbuHnq8XOwrjL6k95KRnBiy8V4d5ZG7Jv1wiE8v8VwDc7mqg=
=sGS+
-----END PGP SIGNATURE-----


From marcus.kool at urlfilterdb.com  Thu Feb 12 21:21:51 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 12 Feb 2015 19:21:51 -0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DD08E7.5030307@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DCF881.7020102@gmail.com> <54DD07D1.2040306@urlfilterdb.com>
 <54DD08E7.5030307@gmail.com>
Message-ID: <54DD196F.9030103@urlfilterdb.com>



On 02/12/2015 06:11 PM, Yuri Voinov wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> I talking not about another redirector. But about smart Squid
> behaviour with redirector's children.
>
> If I wanted to change redirector - I would have already done it. I am
> aware of the existence of ufdvGuard. Moreover - I've tried to build it
> on my system. Failed - it cannot build without dancing with a
> tambourine. I have enough Squid with his tambourines.

You never tried the support desk of ufdbGuard either.

> I only want to more control over redirector's processes. Not more. And
> cnanging free redirector to commercial one is not an option.

ufdbGuard is not a commercial redirector, but is free and
works with any free database or your own database/blacklist.
It has an additional option to use a commercial database.

>
> 13.02.15 2:06, Marcus Kool ?????:
>> Yuri,
>>
>> I suggest to consider using ufdbGuard instead of squidGuard.
>> Besides being faster is has a different structure: the redirector
>> that squid starts is a small lightweight process that forwards
>> requests to ufdbguardd, a multithreaded daemon which has the URL
>> database in memory.  The database is optimised for memory and
>> occupies less memory than all those squidguard processes - where
>> each process has a database cache of 10% or 15% of the database -
>> so 64 processes means that ufdbguard uses 640% of the size of the
>> database.
>>
>> Marcus
>>
>>
>> On 02/12/2015 05:01 PM, Yuri Voinov wrote:
>>
>>
>> 13.02.15 0:49, Amos Jeffries ?????:
>>>>> On 13/02/2015 7:01 a.m., Yuri Voinov wrote:
>>>>>> Hi gents,
>>>>>
>>>>>> subj.
>>>>>
>>>>>> And, of course - question. How to do that? I've don't seen
>>>>>> this, if it exists.
>>>>>
>>>>>> For example, for this config stub:
>>>>>
>>>>>> url_rewrite_program /usr/local/bin/squidGuard -c
>>>>>> /usr/local/squidGuard/squidGuard.conf url_rewrite_children
>>>>>> 100 startup=0 idle=1 concurrency=0
>>>>>
>>>>>> After daily activity, at midnight, still remain near 60
>>>>>> processes. Absolutely idle.
>>>>>
>>>>>> So, why?
>>>>>
>>>>> The idle=1 parameter "Sets a minimum ..."
>>>>>
>>>>> It actually is quite expensive to start them. At least one
>>>>> client is being held in a pause waiting for it, and others
>>>>> are slowed down while the CPU spawns the process.
>>
>> I understand. But Apache-like model will be better. And so, it
>> works much years in web-front's. Timeout for idle - then shutdown
>> all idle processed.
>>
>>>>>
>>>>> Chances are high that the next day, or even a few seconds
>>>>> later you will need to use them again anyway. So its a bit
>>>>> better to have them idle than to discard completely.
>>>>>
>>>>> *Particularly* since you have no concurrency for the helper.
>>>>> A single
>> SquidGuard was never been threaded.
>>
>>>>> client loading a page with many objects can initiate many
>>>>> parallel requests. Each of which will need to be processed by
>>>>> one of those helpers.
>>
>> I understand. But will be better to have more weak instrumentation
>> to manage children. Either Apache-like, or default.
>>
>> First query latency is important, but when I tun out of memory,
>> this query will never be executed in any case.
>>
>> Moreover - some kernels - especially after swap out idle process,
>> can not return it quickly to CPU.
>>
>> The system, which has permanently low memory, have hi risk to slow
>> down to deep swaping.
>>
>> Amos, current mechanism is so ungainly. I want to have more
>> powerful control over rewriter processes.
>>
>> Now they live their lives. By the end of the day I have a lot of
>> running processes that do not do anything. And can occupy more than
>> 1 GB of RAM valuable. And there is no mechanism other than
>> sporadic displacement of the operating system. If you accidentally
>> took the memory.
>>
>> It's better than it was before, when I had 100 running redirectors
>> always and 1.5 GB of memory consumed with the threat of a swap,
>> but worse than the management of processes in Apache. And,
>> therefore, memory management.
>>
>>>>>
>>>>> Amos _______________________________________________
>>>>> squid-users mailing list squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>> _______________________________________________ squid-users
>>> mailing list squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU3QjnAAoJENNXIZxhPexG6b4H/ibFEpNS5f25ESr3H6EttwrN
> 2kW2bWd52g3C7SeM783K9f92EOpNgwLSXd2SDKXnQAfJeYoYl6AqPge5vjg7l6R2
> YB0PbAnjJZvju7gmRfYqhhcXAasGBPq1Ot5vbnoo6JNP3JEjoxRlFPo9KKPxXmLF
> q32bw1z7D8hExkMBZx/Esq44kISpxo3fNx9Zd1EwhnzzXcX5qcwoZ46/pWOiHd5/
> 4hd9u1ZAoOFFfAc64YiP49rXcelAFgO7nl5NLOcx50n4F+uTa14lRhrhmmmex/Wz
> tdwEXXpwnXsJKCwt/zMJo3StW05/DxmVXidjfUWuHlSA10RKRbsPRaWRBtKPba0=
> =t+/k
> -----END PGP SIGNATURE-----
>
>


From aboba0 at yahoo.com  Thu Feb 12 21:27:11 2015
From: aboba0 at yahoo.com (Alan Boba)
Date: Thu, 12 Feb 2015 21:27:11 +0000 (UTC)
Subject: [squid-users] when/who login in to proxy?
Message-ID: <1045579365.2442624.1423776432001.JavaMail.yahoo@mail.yahoo.com>

I've been able to set up digest file authentication on the Squid proxy by adding the following to squid3.conf.
auth_param digest program /usr/lib/squid3/digest_file_auth -c /etc/squid3/passwordsauth_param digest realm proxyacl authenticated proxy_auth REQUIREDhttp_access allow authenticated

I have a user called testuser. When attempting to browse a login challenge is displayed. The account login works, web browsing works.?
How to track account used and when logins occur? My online searches have been fruitless.
I tried discovering what log file it may be in by examining all logs on the server# grep testuser /var/log/*

That produced only two hits, both in /var/log/auth.log
The first hit was from the?htdigest command used to create testuser and the second was from the sudo grep testuser command used to search the log files

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/2d580911/attachment.htm>

From rousskov at measurement-factory.com  Thu Feb 12 23:08:08 2015
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 12 Feb 2015 16:08:08 -0700
Subject: [squid-users] light weight ICAP server that isn't dead :o)
In-Reply-To: <54D9456C.5000808@treenet.co.nz>
References: <CA+suCFiat52pwPTfOKQ=rW+JXef72_C4xM_vg2tGLOssiRatiw@mail.gmail.com>
 <54D9456C.5000808@treenet.co.nz>
Message-ID: <54DD3258.1030701@measurement-factory.com>

On 02/09/2015 04:40 PM, Amos Jeffries wrote:

> You might also look into eCAP. The design intention is that you build an
> eCAP module which can plug into either the c-icap engine for access over
> ICAP


I did not realize c-icap added eCAP support. Christos, is that true? We
are adding eCAP support to Traffic Spicer, but it would be nice to have
an open source ICAP+eCAP option as well!


Thank you,

Alex.



From squid3 at treenet.co.nz  Thu Feb 12 23:43:36 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 12:43:36 +1300
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCF96A.3060502@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DCF96A.3060502@gmail.com>
Message-ID: <54DD3AA8.7040501@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 13/02/2015 8:05 a.m., Yuri Voinov wrote:
> I want to say:
> 
> A system with low consumpted memory will starts processes more
> quickly against system with low free memory and overloaded cheduler
> and more sleep processes in most cases.
> 
> So, IMHO better solution is possibility to shutdown idle children 
> after configured timeout and starts them up when required.
> 
> Also, OS cache also still exists..... and can hold rewriter ELF
> near CPU.... did you remember? ;)

It is a tradeoff. The forking method Squid currently uses causes the
child process to get as much virtual memory allocated as the Squid
worker process was using at the time, including a full copy of the
cache_mem contents.

In a low memory system its better to start a bunch of the helpers via
startup=N before the parent allocates too much memory and keep them
running than it is to start later via idle=N when traffic is going
through.

Now that you know your peak usage is around 60 helpers worth of
traffic you may want to check out what the memory profile is like with
startup=50.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU3TqnAAoJELJo5wb/XPRjyxoIAN5zCpFoaIt/SEpor0WA1U/6
rdG4dSKO5rYBwglHqAKxNLh13nB2MHxMfasHjcje8Z1W59+E/EIYuy6mrCyGTiBm
Ckr1wg6JrUcnRQRx7OJBO+9pd6ONtg6wJx4jGarE3kVbHDoccWKhmk60m/LQiPSJ
UuXBdEiDPSJW7FV2wEWekp+nZhsIwIgm2xgF6IyVUqYBZ8MsNIeIwJx5z2oJVwaB
dloQgExgaCgD23L6j7KzwWfCZsc1JA8pefdjXHYlUTpekUxHB6KZzAUFrSPLokov
D8LauV2nXhRl+eVWXAz9uV8bbN6kPbN6GbKdD6eFCtIwwkpy4oOSwsj/UqPUUe0=
=52ZF
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Thu Feb 12 23:48:40 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 12:48:40 +1300
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DD0C43.9070505@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DCF881.7020102@gmail.com> <54DD07D1.2040306@urlfilterdb.com>
 <54DD0C43.9070505@gmail.com>
Message-ID: <54DD3BD8.1060203@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 13/02/2015 9:25 a.m., Yuri Voinov wrote:
> BTW,
> 
> now I have average 300-400 Mb total memory consumption over all 
> working instances of squidGuard. And see only one problem - idle 
> processes never dies after peak hours, and therefore idle=
> parameter is meaningless.

... and yet you just described in the other email how happy you were
not to have 100 helpers running constantly. Its the designed idle=N
behaviour which does that, the other parameters are just limits
bounding where the idle/standby initializer starts and stops having
effect.
Just set idle=100 and see how much meaningless it is.

It was created for a specific purpose, which it meets quite well. Its
documented as being what it is: the *minimum* amount of idle processes
to have running at any one time. And thats how it operates.

The helper itself is free to exit early if it needs to. Just not too
often or in big batches.

If you look at the numbers of objects requested when loading a page
like Facebook (240 objects) or CNN (170 objects) you will see that 60
is not that large a number of helpers anyway. The proxy can go from no
traffic to 60 concurrent requests in less than a second *at any time*.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU3TvYAAoJELJo5wb/XPRjLu8IAI+EvtMVaalfyUCCfjCeSwpd
o5idmVNF3NokuOZpysEeb0kU7LPedCxQJitbBVZbLLuRXxaTkPC+KnjkbMmH1YUs
FrzyBKznO7K7Onv5UxtJkZrNhvFseLDG3l643IW8KMdpVfEOcKNAib9QUcY4vbuR
w9yjx25VciSoSiEFpGA+MAr9aHkkgwr7b9tWHU7czEmlx60hdTkc1v+5/wbgNTSP
0B+BkRIH3aQCSqt/N+skW/5SFurS6iXl24JH3eO7SrRNNRVR8zuRVE4rRMIm14r5
k+6wrWUrbRfXKKMRG4OwTuCmFUJelw/U8Q6Bs6IDy7fI58J2Yswf6zcZKF+zkc0=
=3vU8
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Thu Feb 12 23:57:11 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 12:57:11 +1300
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCFCC0.1060603@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DCFCC0.1060603@gmail.com>
Message-ID: <54DD3DD7.5020908@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 13/02/2015 8:19 a.m., Yuri Voinov wrote:
> BTW,
> 
> the expected behavior of a directive -
> 
> url_rewrite_children 100 startup=0 idle=1 concurrency=0
> 
> Starts with 0 initial processes,
> 
> then starts when requests up to 100,
> 
> and after some idle timeout (and be better to specify this timeout
> to accomplish proxy specific behaviour) - kill idle processes to
> "idle=1" value.

Expected by someone who did not RTFM.

The docs explain clearly that above means ensure no more than 100
helpers are ever running, startup begins with 0 and when traffic
happens 1+ are kept available for use.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU3T3XAAoJELJo5wb/XPRjKVsH/il8zfktPJlv8pVc57utxMTS
apBsR60jhD2TzCIVgJrMKuhqd9BJlJQGaTO1nQzJBxqgPHDa4Kf6PWhg4ebP4SS4
vfEAjf4pxr3Ecp8xw8JZM/TYr3Y/F0Os0RtMeNdys9f0hI6iTT9FCTOIfGsWzrLb
LEI0pouoWweILM9Fj20H3iZmmzywwj1icYRWXHQOUK3ezDp4eesKdUVQkXDvenbI
IUc4JJKzNkVhEh8Mq7GQvQB7IJaE+fBVnwLJh9B7sRlytDitk6LfgGmL+u46eMqE
OEWOvF+HllIW06y4xShucQ2fdBfOn87O9XiGCNkjec9LI/3cHRvJ5hTD8M7/Eyw=
=yjc/
-----END PGP SIGNATURE-----


From tmblue at gmail.com  Fri Feb 13 00:24:40 2015
From: tmblue at gmail.com (Tory M Blue)
Date: Thu, 12 Feb 2015 16:24:40 -0800
Subject: [squid-users] 2.7.9 to 3.5 CentOS No-Cache
Message-ID: <CAEaSS0Zq2ztRYC3ceKBr9hbGQhGNggMTK954DP2NGYUOdS1tJQ@mail.gmail.com>

Greetings all, been a bit.

So I'm working on a new server config and loaded the latest 3.5 and have
tweaked my 2.7 configs a bit. Things are working but I've got one that I
can't figure out.

I have a test that insures that objects with an explicit "
Cache-Control: no-cache" header are NOT cached by Squid. This is done by
keeping a special hit counter on the server and counting origin requests. A
unique URL is fetched exactly 10 times, and all of them are asserted to be
cache misses (both Squid headers must be MISS). At the end, the hit counter
is tested and made sure it equals the number of requests (10)."

I'm getting a fail when testing against 3.5, meaning it's providing a cache
object

Miss with no-cache                  | FAIL    <------


Running test: Miss with no-cache...
Resetting hit counter...
Fetching URL:
http://10.13.5.222/admin/squid_test.php?action=reset_hit_count&random=0.385536803712753
HTTP 200: 200 OK
X-Cache: MISS from dev-centOS
X-Cache-Lookup: MISS from dev-centOS:80
Fetching URL:
http://10.13.5.222/admin/squid_test.php?action=simple&type=no_cache&random=0.0843643311677589
HTTP 200: 200 OK
X-Cache: MISS from dev-centOS
X-Cache-Lookup: MISS from dev-centOS:80
Fetching URL:
http://10.13.5.222/admin/squid_test.php?action=simple&type=no_cache&random=0.0843643311677589
HTTP 200: 200 OK
X-Cache: MISS from dev-centOS
X-Cache-Lookup: HIT from dev-centOS:80 *<?? Shows a hit (this should be 10
misses , a hit should never happen)*

*Test fails*

w/ 2.7.9 config
Miss with no-cache                  | Pass

Running test: Miss with no-cache...
Resetting hit counter...
Fetching URL:
http://devcache01.eng.admission.net/admin/squid_test.php?action=reset_hit_count&random=0.671442807268036
HTTP 200: 200 OK
X-Cache: MISS from dev-cache
X-Cache-Lookup: MISS from dev-cache:80

*I get 10 of the above responses (test passes).*

I'm wondering what I'm missing, 3.5 should be fully http 1.1 compliant
meaning that there should not be any squid directives guiding this (nor can
I find any). If the client sends a "Cache-Control: no-cache" it should be
honored natively ya?

Thanks for any pointers

Tory
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150212/d8674e56/attachment.htm>

From squid3 at treenet.co.nz  Fri Feb 13 00:34:00 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 13:34:00 +1300
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DD050D.9020809@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DD050D.9020809@gmail.com>
Message-ID: <54DD4678.7020701@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 13/02/2015 8:54 a.m., Yuri Voinov wrote:
> So simple.
> 
> I want to see only one additional parameter.
> 
> idle_timeout.
> 
> When I specify it to 0 - by default - all started rewriter
> processess remains after user requests,
> 
> but! it I specify it over 0 in seconds - all idle rewriters after 
> timeout must dies to achieve idle= value.
> 
> Logically, isn't it? This permits me to design, how cache will
> works with user's sessions. And, moreover, in other software
> products such behavior with shared processes is the default. I.e -
> Oracle shared server. Apache WEB server in some configurations. And
> others.

Your examples are software which spawns a whole worker process for
each user transaction, executes that one transaction then tears down
the whole worker process.

Apache is a good example, we had some of their devs coming to us a few
years ago asking for explanations about how Squid manages to process
some of the I/O stuff asynchronously as they are/were moving Apache to
something like *our* process model for performance reasons.


> 
> Otherwise idle= parameter for children just do not make sense.
> SQUID decides for me, it's better for my system. I want to have
> better control over rewriter's children and memory consumption.
> 
> Did you agree?

Why would anyone agree with someone who does not understand the
current behaviour and repeatedly insults it due to their own lack of
understanding?




You already rejected the ufdbGuard suggestion which offers you better
memory operations, peformance, and Squid integration.


If you know perl I suggest taking the helper-mux tool
(tools/helper-mux/ in the sources) and adjusting it to do the timeout
management. That will gain you three major benefits in one go:
 1) concurrency
 2) smaller virtual memory overheads
 3) the helper fine tuning


Alternatively you can pay for a patch to be written into Squid adding
the automatic closure. I would be happy to take on that contract.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU3UZ3AAoJELJo5wb/XPRjyEwIAKDMAGGjV3QPQgV4lx+RRsgr
TIG8BoxvpSUyViRcNUQ4YsH+eg4r4BT835m5EByPU0B5WlM+3+07jJjoMEqarsWK
aDqjow3g0TcSwaZngKh6u6lkDt0WSYemhYQajg7ggf8wa150td5n7/DjWCcxoYVp
ia+Js9tzN6oqwWJCihWeBlCd9gJ2QVExrKKL8JrdBZNOkYJpENtB/E0DhmrICy4O
UtumFkvbNfUpku2SapvIkhqPHfDPl8QwS/ZZZvLTnV1vmWuTmGaGjWvLF3fT8ISr
owgjsKni04AvvAjUfn3XzRXHWu/F8LE4P+zieskv5v0upejaEvwHRCl4zj0jaKQ=
=7g6V
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Feb 13 01:13:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 14:13:10 +1300
Subject: [squid-users] 2.7.9 to 3.5 CentOS No-Cache
In-Reply-To: <CAEaSS0Zq2ztRYC3ceKBr9hbGQhGNggMTK954DP2NGYUOdS1tJQ@mail.gmail.com>
References: <CAEaSS0Zq2ztRYC3ceKBr9hbGQhGNggMTK954DP2NGYUOdS1tJQ@mail.gmail.com>
Message-ID: <54DD4FA6.3070600@treenet.co.nz>

On 13/02/2015 1:24 p.m., Tory M Blue wrote:
> Greetings all, been a bit.
> 
> So I'm working on a new server config and loaded the latest 3.5 and have
> tweaked my 2.7 configs a bit. Things are working but I've got one that I
> can't figure out.
> 
> I have a test that insures that objects with an explicit "
> Cache-Control: no-cache" header are NOT cached by Squid.

Your test is wrong. What the HTTP/1.1 specification says about no-cache
is that it has three forms of behaviour:

 1) when Cache-Control:no-cache is sent by a client it means do not
deliver cached contect in the response.

 2) when Cache-Control:no-cache is sent by the server it means the
content *can* be cached but must be revalidated before each use.
 - its effectively an alias for Cache-Control:must-revalidate

 3) when Cache-Control:no-cache="Hello" is sent by the server it means
the header "Hello: ..." must not be delivered on HIT responses, if
possible a revalidation should take place.



PS. since you are testing HTTP behaviour you may also need to be aware
that authenticated and Cache-Control:private="Set-Cookie" responses have
similar cacheability in HTTP/1.1.
 Responses with confidential data *can* be cached if it also contains
controls to ensure the origin server has explicit involvement in each
HIT determination.


> This is done by
> keeping a special hit counter on the server and counting origin requests. A
> unique URL is fetched exactly 10 times, and all of them are asserted to be
> cache misses (both Squid headers must be MISS). At the end, the hit counter
> is tested and made sure it equals the number of requests (10)."
> 
> I'm getting a fail when testing against 3.5, meaning it's providing a cache
> object
> 
> Miss with no-cache                  | FAIL    <------
> 
> 
> Running test: Miss with no-cache...
> Resetting hit counter...
> Fetching URL:
> http://10.13.5.222/admin/squid_test.php?action=reset_hit_count&random=0.385536803712753
> HTTP 200: 200 OK
> X-Cache: MISS from dev-centOS
> X-Cache-Lookup: MISS from dev-centOS:80
> Fetching URL:
> http://10.13.5.222/admin/squid_test.php?action=simple&type=no_cache&random=0.0843643311677589
> HTTP 200: 200 OK
> X-Cache: MISS from dev-centOS
> X-Cache-Lookup: MISS from dev-centOS:80
> Fetching URL:
> http://10.13.5.222/admin/squid_test.php?action=simple&type=no_cache&random=0.0843643311677589
> HTTP 200: 200 OK
> X-Cache: MISS from dev-centOS
> X-Cache-Lookup: HIT from dev-centOS:80 *<?? Shows a hit (this should be 10
> misses , a hit should never happen)*

... those headers lie sometimes with HTTP/1.1. That in particular is a
REFRESH (near-HIT), not a full HIT.

> 
> *Test fails*
> 


Your test should probably be passing anyway. The server should still be
counting the refresh queries and get to 10. Checking for the value of
the Squid headers is the problem.

A small update to your test so that the server sends back its counter in
a custom header for each response would be a better verification of
correctness and should pass.


> w/ 2.7.9 config
> Miss with no-cache                  | Pass
> 
> Running test: Miss with no-cache...
> Resetting hit counter...
> Fetching URL:
> http://devcache01.eng.admission.net/admin/squid_test.php?action=reset_hit_count&random=0.671442807268036
> HTTP 200: 200 OK
> X-Cache: MISS from dev-cache
> X-Cache-Lookup: MISS from dev-cache:80
> 
> *I get 10 of the above responses (test passes).*
> 
> I'm wondering what I'm missing, 3.5 should be fully http 1.1 compliant
> meaning that there should not be any squid directives guiding this (nor can
> I find any). If the client sends a "Cache-Control: no-cache" it should be
> honored natively ya?

It is HTTP/1.1 software and implements the Cache-Control:no-cache
feature closely according to RFC.


Squid-2.7 is HTTP/1.0 software which does not implement the HTTP/1.1
Cache-Control:no-cache feature (or many others either).

Instead it contains a custom hack that treats Cache-Control:no-cache as
if it were Cache-Control:no-store because that is the closest safe
mapping into HTTP/1.0 behaviour where revalidation does not exist.

Amos



From squid3 at treenet.co.nz  Fri Feb 13 01:37:42 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Feb 2015 14:37:42 +1300
Subject: [squid-users] when/who login in to proxy?
In-Reply-To: <1045579365.2442624.1423776432001.JavaMail.yahoo@mail.yahoo.com>
References: <1045579365.2442624.1423776432001.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54DD5566.1020202@treenet.co.nz>

On 13/02/2015 10:27 a.m., Alan Boba wrote:
> I've been able to set up digest file authentication on the Squid proxy by adding the following to squid3.conf.
> auth_param digest program /usr/lib/squid3/digest_file_auth -c /etc/squid3/passwordsauth_param digest realm proxyacl authenticated proxy_auth REQUIREDhttp_access allow authenticated
> 
> I have a user called testuser. When attempting to browse a login challenge is displayed. The account login works, web browsing works. 
> How to track account used and when logins occur? My online searches have been fruitless.
> I tried discovering what log file it may be in by examining all logs on the server# grep testuser /var/log/*
> 
> That produced only two hits, both in /var/log/auth.log
> The first hit was from the htdigest command used to create testuser and the second was from the sudo grep testuser command used to search the log files
> 

The Squid access.log has a username column which should contain a name
for each transaction where a login was used. That is probably in
/var/log/squid/access.log or a similar path.

<http://wiki.squid-cache.org/Features/LogFormat#Squid_native_access.log_format_in_detail>

Amos



From ahmed.zaeem at netstream.ps  Fri Feb 13 11:50:03 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Fri, 13 Feb 2015 03:50:03 -0800
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DA7ED5.1050801@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
 <54DA7817.9060506@treenet.co.nz>
 <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>
 <54DA7ED5.1050801@treenet.co.nz>
Message-ID: <000001d04783$36589fd0$a309df70$@netstream.ps>

Hi Amos ,  I had changed the table name but still no luck :


I  connected to mysql server from remote other sql tool and it worked , I used squid/squid user/pwd in the tool and no problem

So im sure the issue is in squid side ,



I did as u told me , I changed the password table to ==>squid table

here is info on mysql server :

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| squid              |
+--------------------+
3 rows in set (0.00 sec)

mysql> use squid;
Database changed
mysql> show tables
    -> ;
+-----------------+
| Tables_in_squid |
+-----------------+
| squid           |
+-----------------+
1 row in set (0.00 sec)

mysql> select * from squid ;
+--------+----------+---------+-----------+---------------------+
| user   | password | enabled | fullname  | comment             |
+--------+----------+---------+-----------+---------------------+
| Nikesh | test     |       1 | Test User | for testing purpose |
+--------+----------+---------+-----------+---------------------+
1 row in set (0.00 sec)

mysql> show GRANTS FOR squid;
+------------------------------------------------------------------------------------------------------+
| Grants for squid@%                                                                                   |
+------------------------------------------------------------------------------------------------------+
| GRANT USAGE ON *.* TO 'squid'@'%' IDENTIFIED BY PASSWORD '*AFD42D37182BDB40880BEF624CC64B0F4A1E35B4' |
| GRANT SELECT ON `squid`.* TO 'squid'@'%'                                                             |
+------------------------------------------------------------------------------------------------------+
2 rows in set (0.00 sec)

mysql> grant select on squid.* to "squid"@"%" identified by 'squid';
Query OK, 0 rows affected (0.00 sec)

==========================
here is tesing from the remote squid machine using the helper :
/lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "squid" --password "squid" --table "squid" --usercol "user" --passwdcol "password"

ERR unknown login
ERR unknown login
ERR unknown login


Here is tesing with only same parameters :
/lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "squid" --password "squid" 




DBD::mysql::st execute failed: Table 'squid.passwd' doesn't exist at /lib/squid/basic_db_auth line 215, <> line 1.
DBD::mysql::st execute failed: MySQL server has gone away at /lib/squid/basic_db_auth line 218, <> line 1.
ERR database error
DBD::mysql::st execute failed: Table 'squid.passwd' doesn't exist at /lib/squid/basic_db_auth line 215, <> line 2.
DBD::mysql::st execute failed: MySQL server has gone away at /lib/squid/basic_db_auth line 218, <> line 2.
ERR database error
======================


So , as u told me , I will tun squid now with helper and see the debug mode :

Here is my squid.conf :

auth_param basic program /lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx.189.177" --user "squid" --password "squid" --table "squid" --usercol "user" --passwdcol "password"
auth_param basic children 5
auth_param basic realm Web-Proxy
auth_param basic credentialsttl 1 minute
auth_param basic casesensitive off

acl db-auth proxy_auth REQUIRED
http_access allow db-auth


here is squid in debug mode :
2015/02/12 22:46:13.403 kid1| client_side.cc(1546) keepaliveNextRequest: ConnnStateData(local=192.168.1.8:3128 remote=192.168.1.6:52221 FD 10 flags=1), Context(local=192.168.1.8:3128 remote=192.168.1.6:52221 FD 10 flags=1)
2015/02/12 22:46:13.403 kid1| clientStream.cc(202) clientStreamDetach: clientStreamDetach: Detaching node 0x2834678
2015/02/12 22:46:13.403 kid1| clientStream.cc(287) clientStreamFree: Freeing clientStreamNode 0x2834678
2015/02/12 22:46:13.403 kid1| client_side_request.cc(246) ~ClientHttpRequest: httpRequestFree: http://yahoo.com/
2015/02/12 22:46:13.403 kid1| SBuf.cc(139) assign: assigning SBuf479 from SBuf480
2015/02/12 22:46:13.403 kid1| Checklist.cc(68) preCheck: 0x7fff89df6c70 checking fast ACLs
2015/02/12 22:46:13.403 kid1| Acl.cc(138) matches: checking access_log daemon:/var/log/squid/access.log
2015/02/12 22:46:13.403 kid1| Acl.cc(138) matches: checking (access_log daemon:/var/log/squid/access.log line)
2015/02/12 22:46:13.404 kid1| Acl.cc(158) matches: checked: (access_log daemon:/var/log/squid/access.log line) = 1
2015/02/12 22:46:13.404 kid1| Acl.cc(158) matches: checked: access_log daemon:/var/log/squid/access.log = 1
2015/02/12 22:46:13.404 kid1| Checklist.cc(61) markFinished: 0x7fff89df6c70 answer ALLOWED for match
2015/02/12 22:46:13.404 kid1| ModDaemon.cc(65) logfileNewBuffer: logfileNewBuffer: daemon:/var/log/squid/access.log: new buffer
2015/02/12 22:46:13.404 kid1| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/var/log/squid/access.log: appending 1 bytes
2015/02/12 22:46:13.404 kid1| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 0 of 32768 bytes before append
2015/02/12 22:46:13.404 kid1| SBuf.cc(139) assign: assigning SBuf477 from SBuf2
2015/02/12 22:46:13.404 kid1| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/var/log/squid/access.log: appending 105 bytes
2015/02/12 22:46:13.404 kid1| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 1 of 32768 bytes before append
2015/02/12 22:46:13.404 kid1| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/var/log/squid/access.log: appending 2 bytes
2015/02/12 22:46:13.404 kid1| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 106 of 32768 bytes before append
2015/02/12 22:46:13.404 kid1| ModEpoll.cc(116) SetSelect: FD 9, type=2, handler=1, client_data=0x282a1e8, timeout=0
2015/02/12 22:46:13.404 kid1| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff89df6c70
2015/02/12 22:46:13.404 kid1| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff89df6c70
2015/02/12 22:46:13.404 kid1| store.cc(523) unlock: ClientHttpRequest::loggingEntry unlocking key 9025F4F15092391E81517BA23C94F29E e:=sXINV/0x28345e0*2
2015/02/12 22:46:13.405 kid1| clientStream.cc(247) clientStreamAbort: clientStreamAbort: Aborting stream with tail 0x2c4fd88
2015/02/12 22:46:13.405 kid1| clientStream.cc(202) clientStreamDetach: clientStreamDetach: Detaching node 0x2c4fd88
2015/02/12 22:46:13.405 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall Initiate::noteInitiatorAborted constructed, this=0x2c5e480 [call149]
2015/02/12 22:46:13.405 kid1| AsyncCall.cc(93) ScheduleCall: Initiator.cc(40) will call Initiate::noteInitiatorAborted() [call149]
2015/02/12 22:46:13.405 kid1| client_side_request.cc(115) ~ClientRequestContext: 0x2c52bf8 ClientRequestContext destructed
2015/02/12 22:46:13.405 kid1| UserRequest.cc(101) ~UserRequest: freeing request 0x2c535c0
2015/02/12 22:46:13.405 kid1| HttpHeader.cc(479) clean: cleaning hdr: 0x2bf5b98 owner: 2
2015/02/12 22:46:13.405 kid1| HttpRequest.cc(55) ~HttpRequest: destructed, this=0x2bf5b80
2015/02/12 22:46:13.405 kid1| HttpHeader.cc(479) clean: cleaning hdr: 0x2bf5b98 owner: 2
2015/02/12 22:46:13.405 kid1| AsyncJob.cc(40) ~AsyncJob: AsyncJob destructed, this=0x2834860 type=ClientHttpRequest [job4]
2015/02/12 22:46:13.405 kid1| clientStream.cc(223) clientStreamDetach: clientStreamDetach: Calling 1 with cbdata 0x2c523a0
2015/02/12 22:46:13.405 kid1| clientStream.cc(287) clientStreamFree: Freeing clientStreamNode 0x2c4fd88
2015/02/12 22:46:13.405 kid1| store_client.cc(663) storeUnregister: storeUnregister: called for '9025F4F15092391E81517BA23C94F29E'
2015/02/12 22:46:13.405 kid1| store.cc(955) checkCachable: StoreEntry::checkCachable: NO: not cachable
2015/02/12 22:46:13.405 kid1| store_dir.cc(821) memoryOut: keepInLocalMemory: 0
2015/02/12 22:46:13.405 kid1| store.cc(1967) trimMemory: e:=sXINV/0x28345e0*1 inmem_lo=4047
2015/02/12 22:46:13.406 kid1| store.cc(485) lock: storeUnregister locked key 9025F4F15092391E81517BA23C94F29E e:=sXINV/0x28345e0*2
2015/02/12 22:46:13.406 kid1| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2015/02/12 22:46:13.406 kid1| store.cc(523) unlock: storeUnregister unlocking key 9025F4F15092391E81517BA23C94F29E e:=sXINV/0x28345e0*2
2015/02/12 22:46:13.406 kid1| store.cc(523) unlock: clientReplyContext::removeStoreReference unlocking key 9025F4F15092391E81517BA23C94F29E e:=sXINV/0x28345e0*1
2015/02/12 22:46:13.406 kid1| store_client.cc(757) storePendingNClients: storePendingNClients: returning 0
2015/02/12 22:46:13.406 kid1| store.cc(1239) release: releasing e:=sXINV/0x28345e0*0 9025F4F15092391E81517BA23C94F29E
2015/02/12 22:46:13.406 kid1| store.cc(404) destroyMemObject: destroyMemObject 0x2c53d20
2015/02/12 22:46:13.406 kid1| MemObject.cc(110) ~MemObject: del MemObject 0x2c53d20
2015/02/12 22:46:13.406 kid1| ctx: enter level  0: 'http://yahoo.com/'
2015/02/12 22:46:13.406 kid1| HttpHeader.cc(479) clean: cleaning hdr: 0x2c53ff8 owner: 3
2015/02/12 22:46:13.406 kid1| HttpHeader.cc(479) clean: cleaning hdr: 0x2c53ff8 owner: 3
2015/02/12 22:46:13.406 kid1| ctx: exit level  0
2015/02/12 22:46:13.406 kid1| store.cc(422) destroyStoreEntry: destroyStoreEntry: destroying 0x28345e8
2015/02/12 22:46:13.406 kid1| store.cc(404) destroyMemObject: destroyMemObject 0
2015/02/12 22:46:13.406 kid1| store.cc(377) ~StoreEntry: StoreEntry destructed, this=0x28345e0
2015/02/12 22:46:13.406 kid1| HttpHeader.cc(479) clean: cleaning hdr: 0x2bf4e08 owner: 3
2015/02/12 22:46:13.406 kid1| HttpHeader.cc(479) clean: cleaning hdr: 0x2bf4e08 owner: 3
2015/02/12 22:46:13.406 kid1| client_side.cc(3167) clientParseRequests: local=192.168.1.8:3128 remote=192.168.1.6:52221 FD 10 flags=1: attempting to parse
2015/02/12 22:46:13.406 kid1| client_side.cc(1616) keepaliveNextRequest: local=192.168.1.8:3128 remote=192.168.1.6:52221 FD 10 flags=1: calling conn->readNextRequest()
2015/02/12 22:46:13.406 kid1| client_side.cc(1503) readNextRequest: local=192.168.1.8:3128 remote=192.168.1.6:52221 FD 10 flags=1 reading next req
2015/02/12 22:46:13.407 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::requestTimeout constructed, this=0x2c5e9e0 [call150]
2015/02/12 22:46:13.407 kid1| comm.cc(553) commSetConnTimeout: local=192.168.1.8:3128 remote=192.168.1.6:52221 FD 10 flags=1 timeout 120
2015/02/12 22:46:13.407 kid1| AsyncCallQueue.cc(57) fireNext: leaving clientWriteComplete(local=192.168.1.8:3128 remote=192.168.1.6:52221 FD 10 flags=1, data=0x2c50028)
2015/02/12 22:46:13.407 kid1| AsyncCallQueue.cc(55) fireNext: entering Initiate::noteInitiatorAborted()
2015/02/12 22:46:13.407 kid1| AsyncCall.cc(38) make: make call Initiate::noteInitiatorAborted [call149]
2015/02/12 22:46:13.407 kid1| AsyncCall.cc(56) cancel: will not call Initiate::noteInitiatorAborted [call149] because job gone
2015/02/12 22:46:13.407 kid1| AsyncCall.cc(48) make: will not call Initiate::noteInitiatorAborted [call149] because of job gone
2015/02/12 22:46:13.407 kid1| AsyncCallQueue.cc(57) fireNext: leaving Initiate::noteInitiatorAborted()
2015/02/12 22:46:13.407 kid1| ModEpoll.cc(116) SetSelect: FD 10, type=2, handler=0, client_data=0, timeout=0
2015/02/12 22:46:13.407 kid1| ModDaemon.cc(108) logfileHandleWrite: daemon:/var/log/squid/access.log: write returned 108
2015/02/12 22:46:13.407 kid1| ModEpoll.cc(116) SetSelect: FD 9, type=2, handler=0, client_data=0, timeout=0
2015/02/12 22:46:14.295 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall logfileFlush constructed, this=0x2834ec0 [call151]
2015/02/12 22:46:14.295 kid1| AsyncCall.cc(93) ScheduleCall: event.cc(237) will call logfileFlush(0x282a1e8*?) [call151]
2015/02/12 22:46:14.295 kid1| AsyncCallQueue.cc(55) fireNext: entering logfileFlush(0x282a1e8*?)
2015/02/12 22:46:14.295 kid1| AsyncCall.cc(38) make: make call logfileFlush [call151]
2015/02/12 22:46:14.296 kid1| event.cc(322) schedule: schedule: Adding 'logfileFlush', in 1.00 seconds
2015/02/12 22:46:14.296 kid1| AsyncCallQueue.cc(57) fireNext: leaving logfileFlush(0x282a1e8*?)
2015/02/12 22:46:14.296 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall MaintainSwapSpace constructed, this=0x2834ec0 [call152]
2015/02/12 22:46:14.296 kid1| AsyncCall.cc(93) ScheduleCall: event.cc(237) will call MaintainSwapSpace() [call152]
2015/02/12 22:46:14.296 kid1| AsyncCallQueue.cc(55) fireNext: entering MaintainSwapSpace()
2015/02/12 22:46:14.296 kid1| AsyncCall.cc(38) make: make call MaintainSwapSpace [call152]
2015/02/12 22:46:14.296 kid1| event.cc(322) schedule: schedule: Adding 'MaintainSwapSpace', in 1.00 seconds
2015/02/12 22:46:14.296 kid1| AsyncCallQueue.cc(57) fireNext: leaving MaintainSwapSpace()
2015/02/12 22:46:15.298 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall logfileFlush constructed, this=0x2834ec0 [call153]
2015/02/12 22:46:15.298 kid1| AsyncCall.cc(93) ScheduleCall: event.cc(237) will call logfileFlush(0x282a1e8*?) [call153]
2015/02/12 22:46:15.298 kid1| AsyncCallQueue.cc(55) fireNext: entering logfileFlush(0x282a1e8*?)
2015/02/12 22:46:15.298 kid1| AsyncCall.cc(38) make: make call logfileFlush [call153]
2015/02/12 22:46:15.298 kid1| event.cc(322) schedule: schedule: Adding 'logfileFlush', in 1.00 seconds
2015/02/12 22:46:15.298 kid1| AsyncCallQueue.cc(57) fireNext: leaving logfileFlush(0x282a1e8*?)
2015/02/12 22:46:15.298 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall MaintainSwapSpace constructed, this=0x2834ec0 [call154]
2015/02/12 22:46:15.298 kid1| AsyncCall.cc(93) ScheduleCall: event.cc(237) will call MaintainSwapSpace() [call154]
2015/02/12 22:46:15.298 kid1| AsyncCallQueue.cc(55) fireNext: entering MaintainSwapSpace()
2015/02/12 22:46:15.299 kid1| AsyncCall.cc(38) make: make call MaintainSwapSpace [call154]
2015/02/12 22:46:15.299 kid1| event.cc(322) schedule: schedule: Adding 'MaintainSwapSpace', in 1.00 seconds
2015/02/12 22:46:15.299 kid1| AsyncCallQueue.cc(57) fireNext: leaving MaintainSwapSpace()
2015/02/12 22:46:16.301 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall logfileFlush constructed, this=0x2834ec0 [call155]
2015/02/12 22:46:16.301 kid1| AsyncCall.cc(93) ScheduleCall: event.cc(237) will call logfileFlush(0x282a1e8*?) [call155]
2015/02/12 22:46:16.301 kid1| AsyncCallQueue.cc(55) fireNext: entering logfileFlush(0x282a1e8*?)
2015/02/12 22:46:16.301 kid1| AsyncCall.cc(38) make: make call logfileFlush [call155]
2015/02/12 22:46:16.301 kid1| event.cc(322) schedule: schedule: Adding 'logfileFlush', in 1.00 seconds
2015/02/12 22:46:16.301 kid1| AsyncCallQueue.cc(57) fireNext: leaving logfileFlush(0x282a1e8*?)
2015/02/12 22:46:16.301 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall MaintainSwapSpace constructed, this=0x2834ec0 [call156]
2015/02/12 22:46:16.301 kid1| AsyncCall.cc(93) ScheduleCall: event.cc(237) will call MaintainSwapSpace() [call156]
2015/02/12 22:46:16.301 kid1| AsyncCallQueue.cc(55) fireNext: entering MaintainSwapSpace()
2015/02/12 22:46:16.301 kid1| AsyncCall.cc(38) make: make call MaintainSwapSpace [call156]
2015/02/12 22:46:16.302 kid1| event.cc(322) schedule: schedule: Adding 'MaintainSwapSpace', in 1.00 seconds
2015/02/12 22:46:16.302 kid1| AsyncCallQueue.cc(57) fireNext: leaving MaintainSwapSpace()




Agia I put the user/pwd in y browser with ni luck , each time it refuse my connection .

Here is access.log :
1423799039.114   1072 192.168.1.6 TCP_DENIED/407 4197 CONNECT developer.mozilla.org:443 nikesh HIER_NONE/- text/html
1423799152.251    117 192.168.1.6 TCP_DENIED/407 4097 GET http://yahoo.com/ - HIER_NONE/- text/html
1423799173.404   1143 192.168.1.6 TCP_DENIED/407 4200 GET http://yahoo.com/ nikesh HIER_NONE/- text/html


1423799270.459   1556 192.168.1.6 TCP_DENIED/407 4194 GET http://yahoo.com/ nikesh HIER_NONE/- text/html



Any help ??

Should shoud I try more ?






-----Original Message-----
From: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Sent: Tuesday, February 10, 2015 1:58 PM
To: snakeeyes; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid authentication to remote sql server

On 11/02/2015 8:40 p.m., snakeeyes wrote:
> Hi amos
> I hadded squi/squid in the table
> 
> mysql> show tables
>     -> ;
> +-----------------+
> | Tables_in_squid |
> +-----------------+
> | passwd          |
> +-----------------+
> 1 row in set (0.00 sec)
> 
> mysql> select * from passwd;
> +--------+----------+---------+-----------+---------------------+
> | user   | password | enabled | fullname  | comment             |
> +--------+----------+---------+-----------+---------------------+
> | Nikesh | test     |       1 | Test User | for testing purpose |
> | squid  | squid    |       1 | Test User | for testing purpose |
> +--------+----------+---------+-----------+---------------------+
> 2 rows in set (0.00 sec)
> 
> mysql>
> 
> 
> 
> still has same error ?
> 
> 
> 
> how can u help me ?
> login with md5 or wt ??
> 

Try renaming the "password" column.
 - rename it in the DB, change the squid.conf helper parameter, then reload squid config.


Perhapse show us what you are entering on the command line test for username and password?

Perhapse try using the --debug option? to get the helper to record in cache log (or on screen for the manul tests).

Amos



From priyaiitmandi at gmail.com  Fri Feb 13 03:53:41 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Fri, 13 Feb 2015 09:23:41 +0530
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <54DC9588.4000502@treenet.co.nz>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502121108.26834.Antony.Stone@squid.open.source.it>
 <54DC9588.4000502@treenet.co.nz>
Message-ID: <CALTPfpGUR8w2wFgQS5qht+Wdz1fb-fReNsV+8ATiT5nj7ZdOtA@mail.gmail.com>

These are the output:

root at t4240qds:~# /usr/sbin/squid ls -al /var/logs/access.log
2015/02/13 04:38:18| http_port_port: missing Port: l
FATAL: Bungled (null) line 0:
Squid Cache (Version 3.4.7): Terminated abnormally.
CPU Usage: 0.006 seconds = 0.003 user + 0.003 sys
Maximum Resident Size: 11056 KB
Page faults with physical i/o: 0
root at t4240qds:~# /usr/sbin/squid -v
Squid Cache: Version 3.4.7
configure options:  '--build=x86_64-linux'
'--host=powerpc-fsl_networking-linux'
'--target=powerpc-fsl_networking-linux' '--prefix=/usr'
'--exec_prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin'
'--libexecdir=/usr/lib/squid' '--datadir=/usr/share' '--sysconfdir=/etc'
'--sharedstatedir=/com' '--localstatedir=/var' '--libdir=/usr/lib'
'--includedir=/usr/include' '--oldincludedir=/usr/include'
'--infodir=/usr/share/info' '--mandir=/usr/share/man'
'--disable-silent-rules' '--disable-dependency-tracking'
'--with-libtool-sysroot=/media/NewVolume/yocto/build_t4240qds_release/tmp/sysroots/t4240qds'
'--with-default-user=squid' '--without-netfilter-conntrack'
'build_alias=x86_64-linux' 'host_alias=powerpc-fsl_networking-linux'
'target_alias=powerpc-fsl_networking-linux'
'CC=powerpc-fsl_networking-linux-gcc  -m32 -mhard-float   -mcpu=e6500
--sysroot=/media/NewVolume/yocto/build_t4240qds_release/tmp/sysroots/t4240qds'
'CFLAGS=-O2 -pipe -g -feliminate-unused-debug-types' 'LDFLAGS=-Wl,-O1
-Wl,--hash-style=gnu -Wl,--as-needed' 'CPPFLAGS='
'CXX=powerpc-fsl_networking-linux-g++  -m32 -mhard-float   -mcpu=e6500
--sysroot=/media/NewVolume/yocto/build_t4240qds_release/tmp/sysroots/t4240qds'
'CXXFLAGS=-O2 -pipe -g -feliminate-unused-debug-types -fpermissive
-fvisibility-inlines-hidden' 'CPP=powerpc-fsl_networking-linux-gcc -E
--sysroot=/media/NewVolume/yocto/build_t4240qds_release/tmp/sysroots/t4240qds
-m32 -mhard-float   -mcpu=e6500'
'PKG_CONFIG_PATH=/media/NewVolume/yocto/build_t4240qds_release/tmp/sysroots/t4240qds//usr/lib/pkgconfig:/media/NewVolume/yocto/build_t4240qds_release/tmp/sysroots/t4240qds/usr/share/pkgconfig'
'PKG_CONFIG_LIBDIR=/media/NewVolume/yocto/build_t4240qds_release/tmp/sysroots/t4240qds//usr/lib/pkgconfig'


On Thu, Feb 12, 2015 at 5:29 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 13/02/2015 12:08 a.m., Antony Stone wrote:
> > On Thursday 12 Feb 2015 at 11:01, Priya Agarwal wrote:
> >
> >> My permissions are set correct.
> >
> > Please show us the output of:
> >
> > ls -al /var/logs/access.log
>
>
> ... and squid -v
>
> >
> >> 2015/02/12 11:44:06| Logfile: opening log daemon:/var/logs/access.log
> >> 2015/02/12 11:44:06| Logfile Daemon: opening log /var/logs/access.log
> >> 2015/02/12 11:44:07| logfileHandleWrite: daemon:/var/logs/access.log:
> error
> >> writing ((32) Broken pipe)
> >
> > Make sure you copy and paste (don't retype), both the command I've given
> > above, and the output into your reply.
> >
> >
> > Regards,
> >
> >
> > Antony.
> >
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/dd2e5337/attachment.htm>

From yvoinov at gmail.com  Fri Feb 13 08:44:14 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 14:44:14 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DD4678.7020701@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DD050D.9020809@gmail.com> <54DD4678.7020701@treenet.co.nz>
Message-ID: <54DDB95E.5080200@gmail.com>

Amos,

I understand the idea of the current implementation. I read the manual 
no one time. I only want one thing - let the administrator to decide how 
to adjust his system to him. Not through patches. By means of parameters.

Squid runs on different OS'es, and it is logical to have a flexible 
mechanism for managing child redirectors processes. This must be 
mandatory option. The similar to automatically close applications on 
Android. As I said, changing the redirector is not an option. 
Development of a crutch to automatically stop the processes is not an 
option.

I misled the common interpretation of shared processes and management in 
other software products. But I believe that to be able to automatically 
close the unnecessary processes and free up resources is correct.

On my OS, I have a very powerful system resource management that allows, 
in particular, killing idle processes or processes over the limit. But 
other operating systems do not have advanced resource management. And 
this is not good solution. How to behave Suid when OS forbade him to 
start another redirector? Or begin to kill idle processes? Fatal error 
and fall? I don't know. And do not want to test on production server.

In addition, the operating system with a constant load of RAM in the 
90-95% is just on the edge of a swap or a kernel panic. For Solaris this 
is not care - but it has a very specific kernel. Most of the other OS 
just goes to swap or initiates OOM.

In my opinion the software that claims to be a universal platform, is 
bound to have a more flexible mechanism for managing processes. As 
Oracle, for example. Which is known to work on all platforms without 
exception.

WBR, Yuri

13.02.15 6:34, Amos Jeffries ?????:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 13/02/2015 8:54 a.m., Yuri Voinov wrote:
>> So simple.
>>
>> I want to see only one additional parameter.
>>
>> idle_timeout.
>>
>> When I specify it to 0 - by default - all started rewriter
>> processess remains after user requests,
>>
>> but! it I specify it over 0 in seconds - all idle rewriters after
>> timeout must dies to achieve idle= value.
>>
>> Logically, isn't it? This permits me to design, how cache will
>> works with user's sessions. And, moreover, in other software
>> products such behavior with shared processes is the default. I.e -
>> Oracle shared server. Apache WEB server in some configurations. And
>> others.
> Your examples are software which spawns a whole worker process for
> each user transaction, executes that one transaction then tears down
> the whole worker process.
>
> Apache is a good example, we had some of their devs coming to us a few
> years ago asking for explanations about how Squid manages to process
> some of the I/O stuff asynchronously as they are/were moving Apache to
> something like *our* process model for performance reasons.
>
>
>> Otherwise idle= parameter for children just do not make sense.
>> SQUID decides for me, it's better for my system. I want to have
>> better control over rewriter's children and memory consumption.
>>
>> Did you agree?
> Why would anyone agree with someone who does not understand the
> current behaviour and repeatedly insults it due to their own lack of
> understanding?
>
>
>
>
> You already rejected the ufdbGuard suggestion which offers you better
> memory operations, peformance, and Squid integration.
>
>
> If you know perl I suggest taking the helper-mux tool
> (tools/helper-mux/ in the sources) and adjusting it to do the timeout
> management. That will gain you three major benefits in one go:
>   1) concurrency
>   2) smaller virtual memory overheads
>   3) the helper fine tuning
>
>
> Alternatively you can pay for a patch to be written into Squid adding
> the automatic closure. I would be happy to take on that contract.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJU3UZ3AAoJELJo5wb/XPRjyEwIAKDMAGGjV3QPQgV4lx+RRsgr
> TIG8BoxvpSUyViRcNUQ4YsH+eg4r4BT835m5EByPU0B5WlM+3+07jJjoMEqarsWK
> aDqjow3g0TcSwaZngKh6u6lkDt0WSYemhYQajg7ggf8wa150td5n7/DjWCcxoYVp
> ia+Js9tzN6oqwWJCihWeBlCd9gJ2QVExrKKL8JrdBZNOkYJpENtB/E0DhmrICy4O
> UtumFkvbNfUpku2SapvIkhqPHfDPl8QwS/ZZZvLTnV1vmWuTmGaGjWvLF3fT8ISr
> owgjsKni04AvvAjUfn3XzRXHWu/F8LE4P+zieskv5v0upejaEvwHRCl4zj0jaKQ=
> =7g6V
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Fri Feb 13 09:04:10 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 Feb 2015 15:04:10 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DD4678.7020701@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DD050D.9020809@gmail.com> <54DD4678.7020701@treenet.co.nz>
Message-ID: <54DDBE0A.5030004@gmail.com>

I am ready to sponsor the development of such a patch - but only as a 
basic redirector's functional and subject to the inclusion in the upstream.

13.02.15 6:34, Amos Jeffries ?????:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 13/02/2015 8:54 a.m., Yuri Voinov wrote:
>> So simple.
>>
>> I want to see only one additional parameter.
>>
>> idle_timeout.
>>
>> When I specify it to 0 - by default - all started rewriter
>> processess remains after user requests,
>>
>> but! it I specify it over 0 in seconds - all idle rewriters after
>> timeout must dies to achieve idle= value.
>>
>> Logically, isn't it? This permits me to design, how cache will
>> works with user's sessions. And, moreover, in other software
>> products such behavior with shared processes is the default. I.e -
>> Oracle shared server. Apache WEB server in some configurations. And
>> others.
> Your examples are software which spawns a whole worker process for
> each user transaction, executes that one transaction then tears down
> the whole worker process.
>
> Apache is a good example, we had some of their devs coming to us a few
> years ago asking for explanations about how Squid manages to process
> some of the I/O stuff asynchronously as they are/were moving Apache to
> something like *our* process model for performance reasons.
>
>
>> Otherwise idle= parameter for children just do not make sense.
>> SQUID decides for me, it's better for my system. I want to have
>> better control over rewriter's children and memory consumption.
>>
>> Did you agree?
> Why would anyone agree with someone who does not understand the
> current behaviour and repeatedly insults it due to their own lack of
> understanding?
>
>
>
>
> You already rejected the ufdbGuard suggestion which offers you better
> memory operations, peformance, and Squid integration.
>
>
> If you know perl I suggest taking the helper-mux tool
> (tools/helper-mux/ in the sources) and adjusting it to do the timeout
> management. That will gain you three major benefits in one go:
>   1) concurrency
>   2) smaller virtual memory overheads
>   3) the helper fine tuning
>
>
> Alternatively you can pay for a patch to be written into Squid adding
> the automatic closure. I would be happy to take on that contract.
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJU3UZ3AAoJELJo5wb/XPRjyEwIAKDMAGGjV3QPQgV4lx+RRsgr
> TIG8BoxvpSUyViRcNUQ4YsH+eg4r4BT835m5EByPU0B5WlM+3+07jJjoMEqarsWK
> aDqjow3g0TcSwaZngKh6u6lkDt0WSYemhYQajg7ggf8wa150td5n7/DjWCcxoYVp
> ia+Js9tzN6oqwWJCihWeBlCd9gJ2QVExrKKL8JrdBZNOkYJpENtB/E0DhmrICy4O
> UtumFkvbNfUpku2SapvIkhqPHfDPl8QwS/ZZZvLTnV1vmWuTmGaGjWvLF3fT8ISr
> owgjsKni04AvvAjUfn3XzRXHWu/F8LE4P+zieskv5v0upejaEvwHRCl4zj0jaKQ=
> =7g6V
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From Antony.Stone at squid.open.source.it  Fri Feb 13 09:12:50 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 13 Feb 2015 09:12:50 +0000
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
	error writing ((32) Broken pipe)
In-Reply-To: <CALTPfpGUR8w2wFgQS5qht+Wdz1fb-fReNsV+8ATiT5nj7ZdOtA@mail.gmail.com>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <54DC9588.4000502@treenet.co.nz>
 <CALTPfpGUR8w2wFgQS5qht+Wdz1fb-fReNsV+8ATiT5nj7ZdOtA@mail.gmail.com>
Message-ID: <201502130912.50514.Antony.Stone@squid.open.source.it>

On Friday 13 Feb 2015 at 03:53, Priya Agarwal wrote:

> These are the output:
> 
> root at t4240qds:~# /usr/sbin/squid ls -al /var/logs/access.log

Thanks, but I asked for the output of

	ls -al /var/logs/access.log

There is no squid command in there.

All I want to see is that this file (and path) really exists, and what its 
ownership / permissions are.


Thanks,


Antony.

-- 
"It is easy to be blinded to the essential uselessness of them by the sense of 
achievement you get from getting them to work at all. In other words - and 
this is the rock solid principle on which the whole of the Corporation's 
Galaxy-wide success is founded - their fundamental design flaws are completely 
hidden by their superficial design flaws."

 - Douglas Noel Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Fri Feb 13 09:27:31 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 13 Feb 2015 09:27:31 +0000
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
	error writing ((32) Broken pipe)
In-Reply-To: <201502130912.50514.Antony.Stone@squid.open.source.it>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <CALTPfpGUR8w2wFgQS5qht+Wdz1fb-fReNsV+8ATiT5nj7ZdOtA@mail.gmail.com>
 <201502130912.50514.Antony.Stone@squid.open.source.it>
Message-ID: <201502130927.31478.Antony.Stone@squid.open.source.it>

On Friday 13 Feb 2015 at 09:12, Antony Stone wrote:

> On Friday 13 Feb 2015 at 03:53, Priya Agarwal wrote:
> > These are the output:
> > 
> > root at t4240qds:~# /usr/sbin/squid ls -al /var/logs/access.log
> 
> Thanks, but I asked for the output of
> 
> 	ls -al /var/logs/access.log
> 
> There is no squid command in there.

NB: If you get the output:

	ls: cannot access /var/logs/access.log: No such file or directory

then please show us the output from

	ls -ld /var/logs

as well.

> All I want to see is that this file (and path) really exists, and what its
> ownership / permissions are.
> 
> 
> Thanks,
> 
> 
> Antony.

-- 
"The future is already here.   It's just not evenly distributed yet."

 - William Gibson

                                                   Please reply to the list;
                                                         please *don't* CC me.


From sis at open.ch  Fri Feb 13 09:50:14 2015
From: sis at open.ch (=?iso-8859-1?Q?Simon_St=E4heli?=)
Date: Fri, 13 Feb 2015 10:50:14 +0100
Subject: [squid-users] benefits of
	usingext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <54DCDBCD.5070909@treenet.co.nz>
References: <mailman.42287.1423690543.1833.squid-users@lists.squid-cache.org>
 <A77FDA65-6F38-4C4F-A323-C1B749878B5A@open.ch>
 <54DCDBCD.5070909@treenet.co.nz>
Message-ID: <3BFE59DF-A379-49E6-B177-D4A86DE7678D@open.ch>


On 12.02.2015, at 17:58, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 13/02/2015 5:41 a.m., Simon St?heli wrote:
>> 
>> hmh, HAVE_KRB5 seems not to be set in include/autoconf.h
>> 
>> What is the correct way to provide squid the path to the kerberos header files? 
>> 
>> ./configure ?help doesn?t show a useful option as --with-krb5-config= seems not to be the right option.
> 
> If you are using Squid-3.4 or older versions where that option exists,
> you need to insted use CXXFLAGS to set the -I (library headers) and -L
> (library binary) locations.
> Something like:
> ./configure CXXFLAGS="-I/path/to/include -L/path/to/lib" ?


Thx for the hint! Tried ./configure CXXFLAGS="-I/opt/krb5/include -L/opt/krb5/lib" --prefix=/opt/squid --sysconfdir=/opt/squid/etc --enable-auth --enable-auth-negotiate="kerberos" --enable-external-acl-helpers=?kerberos_ldap_group? but without success. The /opt/krb5/ paths have been set in the Makefile, but HAVE_KRB5 is still no defined. Anything else to do here? (used Squid-3.4.11)


> 
> 
> Squid-3.5 and later have per-library ./configure options. In the case of
> Heimdal use --with-heimdal-krb5=PATH


tried it with Squid-3.5 and --with-heimdal-krb5=PATH and seems to work until make tries to compile kerberos_ldap_group

make[2]: Entering directory `/usr/src/packages/src/squid-3.5.1/helpers/external_acl/kerberos_ldap_group'
g++ -DHAVE_CONFIG_H   -I../../.. -I../../../include -I../../../lib -I../../../src -I../../../include  -I/opt/krb5/include  -I/opt/krb5/include   -I.  -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -m64 -I/opt/krb5/include   -I/opt/krb5/include -L/opt/krb5/lib -march=native -MT support_krb5.o -MD -MP -MF .deps/support_krb5.Tpo -c -o support_krb5.o support_krb5.cc
cc1plus: warnings being treated as errors
support_krb5.cc: In function 'int krb5_create_cache(char*)':
support_krb5.cc:89:9: error: 'const char* krb5_get_err_text(krb5_context_data*, krb5_error_code)' is deprecated (declared at /opt/krb5/include/krb5-protos.h:2089)
...
make[2]: *** [support_krb5.o] Error 1
make[2]: Leaving directory `/usr/src/packages/src/OSAGsquid-sis/squid-3.5.1/helpers/external_acl/kerberos_ldap_group?

my Heimdal Kerberos (Heimdal 1.3.3) libs seemed no to be compatible with kerberos_ldap_group?!


> 
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4030 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/b14ad911/attachment.bin>

From priyaiitmandi at gmail.com  Fri Feb 13 11:06:28 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Fri, 13 Feb 2015 16:36:28 +0530
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <201502130927.31478.Antony.Stone@squid.open.source.it>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <CALTPfpGUR8w2wFgQS5qht+Wdz1fb-fReNsV+8ATiT5nj7ZdOtA@mail.gmail.com>
 <201502130912.50514.Antony.Stone@squid.open.source.it>
 <201502130927.31478.Antony.Stone@squid.open.source.it>
Message-ID: <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>

So sorry. In squid.conf I had done cache_effective_user to nobody and set
permissions of /var and /usr to nobody. So those are the permissions.

root at t4240qds:/var/logs# ls -al /var/logs/access.log
ls: cannot access /var/logs/access.log: No such file or directory
root at t4240qds:/var/logs# ls -ld /var/logs
drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs


On Fri, Feb 13, 2015 at 2:57 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Friday 13 Feb 2015 at 09:12, Antony Stone wrote:
>
> > On Friday 13 Feb 2015 at 03:53, Priya Agarwal wrote:
> > > These are the output:
> > >
> > > root at t4240qds:~# /usr/sbin/squid ls -al /var/logs/access.log
> >
> > Thanks, but I asked for the output of
> >
> >       ls -al /var/logs/access.log
> >
> > There is no squid command in there.
>
> NB: If you get the output:
>
>         ls: cannot access /var/logs/access.log: No such file or directory
>
> then please show us the output from
>
>         ls -ld /var/logs
>
> as well.
>
> > All I want to see is that this file (and path) really exists, and what
> its
> > ownership / permissions are.
> >
> >
> > Thanks,
> >
> >
> > Antony.
>
> --
> "The future is already here.   It's just not evenly distributed yet."
>
>  - William Gibson
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/1496e8d7/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri Feb 13 11:34:29 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 13 Feb 2015 11:34:29 +0000
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
	error writing ((32) Broken pipe)
In-Reply-To: <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502130927.31478.Antony.Stone@squid.open.source.it>
 <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>
Message-ID: <201502131134.29803.Antony.Stone@squid.open.source.it>

On Friday 13 Feb 2015 at 11:06, Priya Agarwal wrote:

> So sorry. In squid.conf I had done cache_effective_user to nobody and set
> permissions of /var and /usr to nobody. So those are the permissions.

Are you saying that /var is owned by 'nobody'?

That sounds like a problem for the system to me.  /var should be owned by 
root; if you want to have subdirectories owned by 'nobody', or with 
permissions to let 'nobody' write to them, that's okay, but I think /var being 
owned by 'nobody' will cause more problems than just for squid.

> root at t4240qds:/var/logs# ls -al /var/logs/access.log
> ls: cannot access /var/logs/access.log: No such file or directory
> root at t4240qds:/var/logs# ls -ld /var/logs
> drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs

Maybe someone more familiar with squid than I am can comment on this, but 
isn't the log file opened before squid drops its privileges (same as the 
network sockets), so you don't actually need the logfile path to be writable 
by the squid_effective_user?

Regards,


Antony.

-- 
All generalisations are inaccurate.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From priyaiitmandi at gmail.com  Fri Feb 13 11:42:43 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Fri, 13 Feb 2015 17:12:43 +0530
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <201502131134.29803.Antony.Stone@squid.open.source.it>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502130927.31478.Antony.Stone@squid.open.source.it>
 <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>
 <201502131134.29803.Antony.Stone@squid.open.source.it>
Message-ID: <CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>

Then It is unable to write cache.log:
Here is the output:

root at t4240qds:~# /usr/sbin/squid -k parse
2015/02/13 12:27:14| Startup: Initializing Authentication Schemes ...
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'basic'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'digest'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'negotiate'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'ntlm'
2015/02/13 12:27:14| Startup: Initialized Authentication.
2015/02/13 12:27:14| Processing Configuration File: /etc/squid.conf (depth
0)
2015/02/13 12:27:14| Processing: cache_mgr priyaiitmandi at gmail.com
2015/02/13 12:27:14| Processing: visible_hostname t4240qds
2015/02/13 12:27:14| Processing: cache_effective_user nobody
2015/02/13 12:27:14| Processing: dns_nameservers 8.8.8.8
2015/02/13 12:27:14| Processing: acl mynet src 10.116.65.0/24
2015/02/13 12:27:14| Processing: acl localnet src 10.0.0.0/8    # RFC1918
possible internal network
2015/02/13 12:27:14| Processing: acl localnet src 172.16.0.0/12    #
RFC1918 possible internal network
2015/02/13 12:27:14| Processing: acl localnet src 192.168.0.0/16    #
RFC1918 possible internal network
2015/02/13 12:27:14| Processing: acl localnet src fc00::/7       # RFC 4193
local private network range
2015/02/13 12:27:14| Processing: acl localnet src fe80::/10      # RFC 4291
link-local (directly plugged) machines
2015/02/13 12:27:14| Processing: acl SSL_ports port 443
2015/02/13 12:27:14| Processing: acl Safe_ports port 80        # http
2015/02/13 12:27:14| Processing: acl Safe_ports port 21        # ftp
2015/02/13 12:27:14| Processing: acl Safe_ports port 443        # https
2015/02/13 12:27:14| Processing: acl Safe_ports port 70        # gopher
2015/02/13 12:27:14| Processing: acl Safe_ports port 210        # wais
2015/02/13 12:27:14| Processing: acl Safe_ports port 1025-65535    #
unregistered ports
2015/02/13 12:27:14| Processing: acl Safe_ports port 280        # http-mgmt
2015/02/13 12:27:14| Processing: acl Safe_ports port 488        # gss-http
2015/02/13 12:27:14| Processing: acl Safe_ports port 591        # filemaker
2015/02/13 12:27:14| Processing: acl Safe_ports port 777        # multiling
http
2015/02/13 12:27:14| Processing: acl CONNECT method CONNECT
2015/02/13 12:27:14| Processing: http_access deny !Safe_ports
2015/02/13 12:27:14| Processing: http_access deny CONNECT !SSL_ports
2015/02/13 12:27:14| Processing: http_access allow localhost manager
2015/02/13 12:27:14| Processing: http_access deny manager
2015/02/13 12:27:14| Processing: http_access allow mynet
2015/02/13 12:27:14| Processing: http_access allow localnet
2015/02/13 12:27:14| Processing: http_access allow localhost
2015/02/13 12:27:14| Processing: http_access deny all
2015/02/13 12:27:14| Processing: http_port 10.116.65.155:8080
2015/02/13 12:27:14| Processing: cache_dir ufs /var/cache/squid 100 16 256
2015/02/13 12:27:14| Processing: coredump_dir /var/cache/squid
2015/02/13 12:27:14| Processing: refresh_pattern ^ftp:        1440
20%    10080
2015/02/13 12:27:14| Processing: refresh_pattern ^gopher:    1440    0%
1440
2015/02/13 12:27:14| Processing: refresh_pattern -i (/cgi-bin/|\?) 0
0%    0
2015/02/13 12:27:14| Processing: refresh_pattern .        0    20%    4320
WARNING: Cannot write log file: /var/logs/cache.log
/var/logs/cache.log: Permission denied
         messages will be sent to 'stderr'.
root at t4240qds:~# ls -ld /var/logs
drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs



On Fri, Feb 13, 2015 at 5:04 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Friday 13 Feb 2015 at 11:06, Priya Agarwal wrote:
>
> > So sorry. In squid.conf I had done cache_effective_user to nobody and set
> > permissions of /var and /usr to nobody. So those are the permissions.
>
> Are you saying that /var is owned by 'nobody'?
>
> That sounds like a problem for the system to me.  /var should be owned by
> root; if you want to have subdirectories owned by 'nobody', or with
> permissions to let 'nobody' write to them, that's okay, but I think /var
> being
> owned by 'nobody' will cause more problems than just for squid.
>
> > root at t4240qds:/var/logs# ls -al /var/logs/access.log
> > ls: cannot access /var/logs/access.log: No such file or directory
> > root at t4240qds:/var/logs# ls -ld /var/logs
> > drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs
>
> Maybe someone more familiar with squid than I am can comment on this, but
> isn't the log file opened before squid drops its privileges (same as the
> network sockets), so you don't actually need the logfile path to be
> writable
> by the squid_effective_user?
>
> Regards,
>
>
> Antony.
>
> --
> All generalisations are inaccurate.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/16363840/attachment.htm>

From priyaiitmandi at gmail.com  Fri Feb 13 11:42:43 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Fri, 13 Feb 2015 17:12:43 +0530
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <201502131134.29803.Antony.Stone@squid.open.source.it>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502130927.31478.Antony.Stone@squid.open.source.it>
 <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>
 <201502131134.29803.Antony.Stone@squid.open.source.it>
Message-ID: <CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>

Then It is unable to write cache.log:
Here is the output:

root at t4240qds:~# /usr/sbin/squid -k parse
2015/02/13 12:27:14| Startup: Initializing Authentication Schemes ...
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'basic'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'digest'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'negotiate'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'ntlm'
2015/02/13 12:27:14| Startup: Initialized Authentication.
2015/02/13 12:27:14| Processing Configuration File: /etc/squid.conf (depth
0)
2015/02/13 12:27:14| Processing: cache_mgr priyaiitmandi at gmail.com
2015/02/13 12:27:14| Processing: visible_hostname t4240qds
2015/02/13 12:27:14| Processing: cache_effective_user nobody
2015/02/13 12:27:14| Processing: dns_nameservers 8.8.8.8
2015/02/13 12:27:14| Processing: acl mynet src 10.116.65.0/24
2015/02/13 12:27:14| Processing: acl localnet src 10.0.0.0/8    # RFC1918
possible internal network
2015/02/13 12:27:14| Processing: acl localnet src 172.16.0.0/12    #
RFC1918 possible internal network
2015/02/13 12:27:14| Processing: acl localnet src 192.168.0.0/16    #
RFC1918 possible internal network
2015/02/13 12:27:14| Processing: acl localnet src fc00::/7       # RFC 4193
local private network range
2015/02/13 12:27:14| Processing: acl localnet src fe80::/10      # RFC 4291
link-local (directly plugged) machines
2015/02/13 12:27:14| Processing: acl SSL_ports port 443
2015/02/13 12:27:14| Processing: acl Safe_ports port 80        # http
2015/02/13 12:27:14| Processing: acl Safe_ports port 21        # ftp
2015/02/13 12:27:14| Processing: acl Safe_ports port 443        # https
2015/02/13 12:27:14| Processing: acl Safe_ports port 70        # gopher
2015/02/13 12:27:14| Processing: acl Safe_ports port 210        # wais
2015/02/13 12:27:14| Processing: acl Safe_ports port 1025-65535    #
unregistered ports
2015/02/13 12:27:14| Processing: acl Safe_ports port 280        # http-mgmt
2015/02/13 12:27:14| Processing: acl Safe_ports port 488        # gss-http
2015/02/13 12:27:14| Processing: acl Safe_ports port 591        # filemaker
2015/02/13 12:27:14| Processing: acl Safe_ports port 777        # multiling
http
2015/02/13 12:27:14| Processing: acl CONNECT method CONNECT
2015/02/13 12:27:14| Processing: http_access deny !Safe_ports
2015/02/13 12:27:14| Processing: http_access deny CONNECT !SSL_ports
2015/02/13 12:27:14| Processing: http_access allow localhost manager
2015/02/13 12:27:14| Processing: http_access deny manager
2015/02/13 12:27:14| Processing: http_access allow mynet
2015/02/13 12:27:14| Processing: http_access allow localnet
2015/02/13 12:27:14| Processing: http_access allow localhost
2015/02/13 12:27:14| Processing: http_access deny all
2015/02/13 12:27:14| Processing: http_port 10.116.65.155:8080
2015/02/13 12:27:14| Processing: cache_dir ufs /var/cache/squid 100 16 256
2015/02/13 12:27:14| Processing: coredump_dir /var/cache/squid
2015/02/13 12:27:14| Processing: refresh_pattern ^ftp:        1440
20%    10080
2015/02/13 12:27:14| Processing: refresh_pattern ^gopher:    1440    0%
1440
2015/02/13 12:27:14| Processing: refresh_pattern -i (/cgi-bin/|\?) 0
0%    0
2015/02/13 12:27:14| Processing: refresh_pattern .        0    20%    4320
WARNING: Cannot write log file: /var/logs/cache.log
/var/logs/cache.log: Permission denied
         messages will be sent to 'stderr'.
root at t4240qds:~# ls -ld /var/logs
drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs



On Fri, Feb 13, 2015 at 5:04 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Friday 13 Feb 2015 at 11:06, Priya Agarwal wrote:
>
> > So sorry. In squid.conf I had done cache_effective_user to nobody and set
> > permissions of /var and /usr to nobody. So those are the permissions.
>
> Are you saying that /var is owned by 'nobody'?
>
> That sounds like a problem for the system to me.  /var should be owned by
> root; if you want to have subdirectories owned by 'nobody', or with
> permissions to let 'nobody' write to them, that's okay, but I think /var
> being
> owned by 'nobody' will cause more problems than just for squid.
>
> > root at t4240qds:/var/logs# ls -al /var/logs/access.log
> > ls: cannot access /var/logs/access.log: No such file or directory
> > root at t4240qds:/var/logs# ls -ld /var/logs
> > drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs
>
> Maybe someone more familiar with squid than I am can comment on this, but
> isn't the log file opened before squid drops its privileges (same as the
> network sockets), so you don't actually need the logfile path to be
> writable
> by the squid_effective_user?
>
> Regards,
>
>
> Antony.
>
> --
> All generalisations are inaccurate.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/16363840/attachment-0001.htm>

From priyaiitmandi at gmail.com  Fri Feb 13 11:45:18 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Fri, 13 Feb 2015 17:15:18 +0530
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502130927.31478.Antony.Stone@squid.open.source.it>
 <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>
 <201502131134.29803.Antony.Stone@squid.open.source.it>
 <CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>
Message-ID: <CALTPfpH56aP8RRUkXtoY5N3d-7R68MW81iYiDtAg_huHGBg9tA@mail.gmail.com>

root at t4240qds:~# chown -R nobody:nogroup /var/logs
root at t4240qds:~# /usr/sbin/squid -k parse
2015/02/13 12:27:14| Startup: Initializing Authentication Schemes ...
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'basic'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'digest'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'negotiate'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'ntlm'
2015/02/13 12:27:14| Startup: Initialized Authentication.
2015/02/13 12:27:14| Processing Configuration File: /etc/squid.conf (depth
0)
2015/02/13 12:27:14| Processing: cache_mgr priyaiitmandi at gmail.com
2015/02/13 12:27:14| Processing: visible_hostname t4240qds
2015/02/13 12:27:14| Processing: cache_effective_user nobody
2015/02/13 12:27:14| Processing: dns_nameservers 8.8.8.8
2015/02/13 12:27:14| Processing: acl mynet src 10.116.65.0/24
2015/02/13 12:27:14| Processing: acl localnet src 10.0.0.0/8    # RFC1918
possible internal network
2015/02/13 12:27:14| Processing: acl localnet src 172.16.0.0/12    #
RFC1918 possible internal network
2015/02/13 12:27:14| Processing: acl localnet src 192.168.0.0/16    #
RFC1918 possible internal network
2015/02/13 12:27:14| Processing: acl localnet src fc00::/7       # RFC 4193
local private network range
2015/02/13 12:27:14| Processing: acl localnet src fe80::/10      # RFC 4291
link-local (directly plugged) machines
2015/02/13 12:27:14| Processing: acl SSL_ports port 443
2015/02/13 12:27:14| Processing: acl Safe_ports port 80        # http
2015/02/13 12:27:14| Processing: acl Safe_ports port 21        # ftp
2015/02/13 12:27:14| Processing: acl Safe_ports port 443        # https
2015/02/13 12:27:14| Processing: acl Safe_ports port 70        # gopher
2015/02/13 12:27:14| Processing: acl Safe_ports port 210        # wais
2015/02/13 12:27:14| Processing: acl Safe_ports port 1025-65535    #
unregistered ports
2015/02/13 12:27:14| Processing: acl Safe_ports port 280        # http-mgmt
2015/02/13 12:27:14| Processing: acl Safe_ports port 488        # gss-http
2015/02/13 12:27:14| Processing: acl Safe_ports port 591        # filemaker
2015/02/13 12:27:14| Processing: acl Safe_ports port 777        # multiling
http
2015/02/13 12:27:14| Processing: acl CONNECT method CONNECT
2015/02/13 12:27:14| Processing: http_access deny !Safe_ports
2015/02/13 12:27:14| Processing: http_access deny CONNECT !SSL_ports
2015/02/13 12:27:14| Processing: http_access allow localhost manager
2015/02/13 12:27:14| Processing: http_access deny manager
2015/02/13 12:27:14| Processing: http_access allow mynet
2015/02/13 12:27:14| Processing: http_access allow localnet
2015/02/13 12:27:14| Processing: http_access allow localhost
2015/02/13 12:27:14| Processing: http_access deny all
2015/02/13 12:27:14| Processing: http_port 10.116.65.155:8080
2015/02/13 12:27:14| Processing: cache_dir ufs /var/cache/squid 100 16 256
2015/02/13 12:27:14| Processing: coredump_dir /var/cache/squid
2015/02/13 12:27:14| Processing: refresh_pattern ^ftp:        1440
20%    10080
2015/02/13 12:27:14| Processing: refresh_pattern ^gopher:    1440    0%
1440
2015/02/13 12:27:14| Processing: refresh_pattern -i (/cgi-bin/|\?) 0
0%    0
2015/02/13 12:27:14| Processing: refresh_pattern .        0    20%    4320
WARNING: Cannot write log file: /var/logs/cache.log
/var/logs/cache.log: Permission denied
         messages will be sent to 'stderr'.
root at t4240qds:~# ls -ld /var/logs
drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs


On Fri, Feb 13, 2015 at 5:12 PM, Priya Agarwal <priyaiitmandi at gmail.com>
wrote:

> Then It is unable to write cache.log:
> Here is the output:
>
> root at t4240qds:~# /usr/sbin/squid -k parse
> 2015/02/13 12:27:14| Startup: Initializing Authentication Schemes ...
> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'basic'
> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'digest'
> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'negotiate'
> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'ntlm'
> 2015/02/13 12:27:14| Startup: Initialized Authentication.
> 2015/02/13 12:27:14| Processing Configuration File: /etc/squid.conf (depth
> 0)
> 2015/02/13 12:27:14| Processing: cache_mgr priyaiitmandi at gmail.com
> 2015/02/13 12:27:14| Processing: visible_hostname t4240qds
> 2015/02/13 12:27:14| Processing: cache_effective_user nobody
> 2015/02/13 12:27:14| Processing: dns_nameservers 8.8.8.8
> 2015/02/13 12:27:14| Processing: acl mynet src 10.116.65.0/24
> 2015/02/13 12:27:14| Processing: acl localnet src 10.0.0.0/8    # RFC1918
> possible internal network
> 2015/02/13 12:27:14| Processing: acl localnet src 172.16.0.0/12    #
> RFC1918 possible internal network
> 2015/02/13 12:27:14| Processing: acl localnet src 192.168.0.0/16    #
> RFC1918 possible internal network
> 2015/02/13 12:27:14| Processing: acl localnet src fc00::/7       # RFC
> 4193 local private network range
> 2015/02/13 12:27:14| Processing: acl localnet src fe80::/10      # RFC
> 4291 link-local (directly plugged) machines
> 2015/02/13 12:27:14| Processing: acl SSL_ports port 443
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 80        # http
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 21        # ftp
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 443        # https
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 70        # gopher
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 210        # wais
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 1025-65535    #
> unregistered ports
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 280        # http-mgmt
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 488        # gss-http
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 591        # filemaker
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 777        #
> multiling http
> 2015/02/13 12:27:14| Processing: acl CONNECT method CONNECT
> 2015/02/13 12:27:14| Processing: http_access deny !Safe_ports
> 2015/02/13 12:27:14| Processing: http_access deny CONNECT !SSL_ports
> 2015/02/13 12:27:14| Processing: http_access allow localhost manager
> 2015/02/13 12:27:14| Processing: http_access deny manager
> 2015/02/13 12:27:14| Processing: http_access allow mynet
> 2015/02/13 12:27:14| Processing: http_access allow localnet
> 2015/02/13 12:27:14| Processing: http_access allow localhost
> 2015/02/13 12:27:14| Processing: http_access deny all
> 2015/02/13 12:27:14| Processing: http_port 10.116.65.155:8080
> 2015/02/13 12:27:14| Processing: cache_dir ufs /var/cache/squid 100 16 256
> 2015/02/13 12:27:14| Processing: coredump_dir /var/cache/squid
> 2015/02/13 12:27:14| Processing: refresh_pattern ^ftp:        1440
> 20%    10080
> 2015/02/13 12:27:14| Processing: refresh_pattern ^gopher:    1440    0%
> 1440
> 2015/02/13 12:27:14| Processing: refresh_pattern -i (/cgi-bin/|\?) 0
> 0%    0
> 2015/02/13 12:27:14| Processing: refresh_pattern .        0    20%    4320
> WARNING: Cannot write log file: /var/logs/cache.log
> /var/logs/cache.log: Permission denied
>          messages will be sent to 'stderr'.
> root at t4240qds:~# ls -ld /var/logs
> drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs
>
>
>
> On Fri, Feb 13, 2015 at 5:04 PM, Antony Stone <
> Antony.Stone at squid.open.source.it> wrote:
>
>> On Friday 13 Feb 2015 at 11:06, Priya Agarwal wrote:
>>
>> > So sorry. In squid.conf I had done cache_effective_user to nobody and
>> set
>> > permissions of /var and /usr to nobody. So those are the permissions.
>>
>> Are you saying that /var is owned by 'nobody'?
>>
>> That sounds like a problem for the system to me.  /var should be owned by
>> root; if you want to have subdirectories owned by 'nobody', or with
>> permissions to let 'nobody' write to them, that's okay, but I think /var
>> being
>> owned by 'nobody' will cause more problems than just for squid.
>>
>> > root at t4240qds:/var/logs# ls -al /var/logs/access.log
>> > ls: cannot access /var/logs/access.log: No such file or directory
>> > root at t4240qds:/var/logs# ls -ld /var/logs
>> > drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs
>>
>> Maybe someone more familiar with squid than I am can comment on this, but
>> isn't the log file opened before squid drops its privileges (same as the
>> network sockets), so you don't actually need the logfile path to be
>> writable
>> by the squid_effective_user?
>>
>> Regards,
>>
>>
>> Antony.
>>
>> --
>> All generalisations are inaccurate.
>>
>>                                                    Please reply to the
>> list;
>>                                                          please *don't*
>> CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/f91e0b05/attachment.htm>

From priyaiitmandi at gmail.com  Fri Feb 13 11:45:18 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Fri, 13 Feb 2015 17:15:18 +0530
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502130927.31478.Antony.Stone@squid.open.source.it>
 <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>
 <201502131134.29803.Antony.Stone@squid.open.source.it>
 <CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>
Message-ID: <CALTPfpH56aP8RRUkXtoY5N3d-7R68MW81iYiDtAg_huHGBg9tA@mail.gmail.com>

root at t4240qds:~# chown -R nobody:nogroup /var/logs
root at t4240qds:~# /usr/sbin/squid -k parse
2015/02/13 12:27:14| Startup: Initializing Authentication Schemes ...
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'basic'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'digest'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'negotiate'
2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'ntlm'
2015/02/13 12:27:14| Startup: Initialized Authentication.
2015/02/13 12:27:14| Processing Configuration File: /etc/squid.conf (depth
0)
2015/02/13 12:27:14| Processing: cache_mgr priyaiitmandi at gmail.com
2015/02/13 12:27:14| Processing: visible_hostname t4240qds
2015/02/13 12:27:14| Processing: cache_effective_user nobody
2015/02/13 12:27:14| Processing: dns_nameservers 8.8.8.8
2015/02/13 12:27:14| Processing: acl mynet src 10.116.65.0/24
2015/02/13 12:27:14| Processing: acl localnet src 10.0.0.0/8    # RFC1918
possible internal network
2015/02/13 12:27:14| Processing: acl localnet src 172.16.0.0/12    #
RFC1918 possible internal network
2015/02/13 12:27:14| Processing: acl localnet src 192.168.0.0/16    #
RFC1918 possible internal network
2015/02/13 12:27:14| Processing: acl localnet src fc00::/7       # RFC 4193
local private network range
2015/02/13 12:27:14| Processing: acl localnet src fe80::/10      # RFC 4291
link-local (directly plugged) machines
2015/02/13 12:27:14| Processing: acl SSL_ports port 443
2015/02/13 12:27:14| Processing: acl Safe_ports port 80        # http
2015/02/13 12:27:14| Processing: acl Safe_ports port 21        # ftp
2015/02/13 12:27:14| Processing: acl Safe_ports port 443        # https
2015/02/13 12:27:14| Processing: acl Safe_ports port 70        # gopher
2015/02/13 12:27:14| Processing: acl Safe_ports port 210        # wais
2015/02/13 12:27:14| Processing: acl Safe_ports port 1025-65535    #
unregistered ports
2015/02/13 12:27:14| Processing: acl Safe_ports port 280        # http-mgmt
2015/02/13 12:27:14| Processing: acl Safe_ports port 488        # gss-http
2015/02/13 12:27:14| Processing: acl Safe_ports port 591        # filemaker
2015/02/13 12:27:14| Processing: acl Safe_ports port 777        # multiling
http
2015/02/13 12:27:14| Processing: acl CONNECT method CONNECT
2015/02/13 12:27:14| Processing: http_access deny !Safe_ports
2015/02/13 12:27:14| Processing: http_access deny CONNECT !SSL_ports
2015/02/13 12:27:14| Processing: http_access allow localhost manager
2015/02/13 12:27:14| Processing: http_access deny manager
2015/02/13 12:27:14| Processing: http_access allow mynet
2015/02/13 12:27:14| Processing: http_access allow localnet
2015/02/13 12:27:14| Processing: http_access allow localhost
2015/02/13 12:27:14| Processing: http_access deny all
2015/02/13 12:27:14| Processing: http_port 10.116.65.155:8080
2015/02/13 12:27:14| Processing: cache_dir ufs /var/cache/squid 100 16 256
2015/02/13 12:27:14| Processing: coredump_dir /var/cache/squid
2015/02/13 12:27:14| Processing: refresh_pattern ^ftp:        1440
20%    10080
2015/02/13 12:27:14| Processing: refresh_pattern ^gopher:    1440    0%
1440
2015/02/13 12:27:14| Processing: refresh_pattern -i (/cgi-bin/|\?) 0
0%    0
2015/02/13 12:27:14| Processing: refresh_pattern .        0    20%    4320
WARNING: Cannot write log file: /var/logs/cache.log
/var/logs/cache.log: Permission denied
         messages will be sent to 'stderr'.
root at t4240qds:~# ls -ld /var/logs
drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs


On Fri, Feb 13, 2015 at 5:12 PM, Priya Agarwal <priyaiitmandi at gmail.com>
wrote:

> Then It is unable to write cache.log:
> Here is the output:
>
> root at t4240qds:~# /usr/sbin/squid -k parse
> 2015/02/13 12:27:14| Startup: Initializing Authentication Schemes ...
> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'basic'
> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'digest'
> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'negotiate'
> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'ntlm'
> 2015/02/13 12:27:14| Startup: Initialized Authentication.
> 2015/02/13 12:27:14| Processing Configuration File: /etc/squid.conf (depth
> 0)
> 2015/02/13 12:27:14| Processing: cache_mgr priyaiitmandi at gmail.com
> 2015/02/13 12:27:14| Processing: visible_hostname t4240qds
> 2015/02/13 12:27:14| Processing: cache_effective_user nobody
> 2015/02/13 12:27:14| Processing: dns_nameservers 8.8.8.8
> 2015/02/13 12:27:14| Processing: acl mynet src 10.116.65.0/24
> 2015/02/13 12:27:14| Processing: acl localnet src 10.0.0.0/8    # RFC1918
> possible internal network
> 2015/02/13 12:27:14| Processing: acl localnet src 172.16.0.0/12    #
> RFC1918 possible internal network
> 2015/02/13 12:27:14| Processing: acl localnet src 192.168.0.0/16    #
> RFC1918 possible internal network
> 2015/02/13 12:27:14| Processing: acl localnet src fc00::/7       # RFC
> 4193 local private network range
> 2015/02/13 12:27:14| Processing: acl localnet src fe80::/10      # RFC
> 4291 link-local (directly plugged) machines
> 2015/02/13 12:27:14| Processing: acl SSL_ports port 443
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 80        # http
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 21        # ftp
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 443        # https
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 70        # gopher
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 210        # wais
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 1025-65535    #
> unregistered ports
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 280        # http-mgmt
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 488        # gss-http
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 591        # filemaker
> 2015/02/13 12:27:14| Processing: acl Safe_ports port 777        #
> multiling http
> 2015/02/13 12:27:14| Processing: acl CONNECT method CONNECT
> 2015/02/13 12:27:14| Processing: http_access deny !Safe_ports
> 2015/02/13 12:27:14| Processing: http_access deny CONNECT !SSL_ports
> 2015/02/13 12:27:14| Processing: http_access allow localhost manager
> 2015/02/13 12:27:14| Processing: http_access deny manager
> 2015/02/13 12:27:14| Processing: http_access allow mynet
> 2015/02/13 12:27:14| Processing: http_access allow localnet
> 2015/02/13 12:27:14| Processing: http_access allow localhost
> 2015/02/13 12:27:14| Processing: http_access deny all
> 2015/02/13 12:27:14| Processing: http_port 10.116.65.155:8080
> 2015/02/13 12:27:14| Processing: cache_dir ufs /var/cache/squid 100 16 256
> 2015/02/13 12:27:14| Processing: coredump_dir /var/cache/squid
> 2015/02/13 12:27:14| Processing: refresh_pattern ^ftp:        1440
> 20%    10080
> 2015/02/13 12:27:14| Processing: refresh_pattern ^gopher:    1440    0%
> 1440
> 2015/02/13 12:27:14| Processing: refresh_pattern -i (/cgi-bin/|\?) 0
> 0%    0
> 2015/02/13 12:27:14| Processing: refresh_pattern .        0    20%    4320
> WARNING: Cannot write log file: /var/logs/cache.log
> /var/logs/cache.log: Permission denied
>          messages will be sent to 'stderr'.
> root at t4240qds:~# ls -ld /var/logs
> drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs
>
>
>
> On Fri, Feb 13, 2015 at 5:04 PM, Antony Stone <
> Antony.Stone at squid.open.source.it> wrote:
>
>> On Friday 13 Feb 2015 at 11:06, Priya Agarwal wrote:
>>
>> > So sorry. In squid.conf I had done cache_effective_user to nobody and
>> set
>> > permissions of /var and /usr to nobody. So those are the permissions.
>>
>> Are you saying that /var is owned by 'nobody'?
>>
>> That sounds like a problem for the system to me.  /var should be owned by
>> root; if you want to have subdirectories owned by 'nobody', or with
>> permissions to let 'nobody' write to them, that's okay, but I think /var
>> being
>> owned by 'nobody' will cause more problems than just for squid.
>>
>> > root at t4240qds:/var/logs# ls -al /var/logs/access.log
>> > ls: cannot access /var/logs/access.log: No such file or directory
>> > root at t4240qds:/var/logs# ls -ld /var/logs
>> > drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs
>>
>> Maybe someone more familiar with squid than I am can comment on this, but
>> isn't the log file opened before squid drops its privileges (same as the
>> network sockets), so you don't actually need the logfile path to be
>> writable
>> by the squid_effective_user?
>>
>> Regards,
>>
>>
>> Antony.
>>
>> --
>> All generalisations are inaccurate.
>>
>>                                                    Please reply to the
>> list;
>>                                                          please *don't*
>> CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/f91e0b05/attachment-0001.htm>

From vartaxe at hotmail.com  Fri Feb 13 12:20:48 2015
From: vartaxe at hotmail.com (Claudio Mendes)
Date: Fri, 13 Feb 2015 13:20:48 +0100
Subject: [squid-users] requested url could not be retrieved/tweak the way it
	resolves dns
Message-ID: <DUB130-W53D1A8AE1FCED2EE448ABEA2230@phx.gbl>

hi,

i was wondering if there is a way to allow web browser use google search for url input which dns can't resolve just like if there was no proxy setup (?example get this https://www.google.com/search?q=example.com when inputing example.com )?instead of getting this:
The requested URL could not be retrieved

While trying to retrieve the URL:?http://example.com/
The following error was encountered:
Unable to determine IP address from host name for?example.com
The dnsserver returned:
Name Error: The domain name does not exist.
This means that:
 The cache was not able to resolve the hostname presented in the URL. 
 Check if the address is correct. 
Your cache administrator is administrator at example.com.?
Generated Fri, 13 Feb 2015 12:06:53 GMT by proxy.example.local (squid/2.5.STABLE12)

thanks for helping 		 	   		  

From amit_info2k at yahoo.com  Fri Feb 13 13:28:41 2015
From: amit_info2k at yahoo.com (amitinfo2k)
Date: Fri, 13 Feb 2015 05:28:41 -0800 (PST)
Subject: [squid-users] Portal Splash Pages example on squid 3.3.13
In-Reply-To: <54DCFBE6.6050307@treenet.co.nz>
References: <1423501647069-4669634.post@n4.nabble.com>
 <54D9310D.8040809@treenet.co.nz> <1423550733210-4669651.post@n4.nabble.com>
 <54DBE990.9080003@treenet.co.nz> <1423743711753-4669764.post@n4.nabble.com>
 <54DCA657.4040605@treenet.co.nz> <1423750370136-4669767.post@n4.nabble.com>
 <54DCD340.2060608@treenet.co.nz> <1423764842792-4669775.post@n4.nabble.com>
 <54DCFBE6.6050307@treenet.co.nz>
Message-ID: <1423834121183-4669808.post@n4.nabble.com>

Thanks a lot I can see the spalsh screen now but, session expiry is little
confusing may be some rule i messed up with will play around it to
understand it. thanks again 





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Portal-Splash-Pages-example-on-squid-3-3-13-tp4669634p4669808.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From demonihin at gmail.com  Fri Feb 13 18:32:29 2015
From: demonihin at gmail.com (Dima Ermakov)
Date: Fri, 13 Feb 2015 22:32:29 +0400
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
Message-ID: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>

Good day!

I have a problem with squid proxy in intercept ssl_bump mode.

If I want to attach big file (>25MB) to my e-mail message on https://mail.ru
web site, I have error "Can not upload file".

Into access.log I have errors: TCP_MISS_ABORTED/000

My squid configuration, access.log, cache.log in attachment.
Thank you!

-- 
? ?????????, ??????? ???????.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/43c530ae/attachment.htm>
-------------- next part --------------
2015/02/13 21:16:42 kid1| Current Directory is /
2015/02/13 21:16:42 kid1| Starting Squid Cache version 3.5.1 for i486-pc-linux-gnu...
2015/02/13 21:16:42 kid1| Service Name: squid
2015/02/13 21:16:42 kid1| Process ID 32428
2015/02/13 21:16:42 kid1| Process Roles: worker
2015/02/13 21:16:42 kid1| With 65535 file descriptors available
2015/02/13 21:16:42 kid1| Initializing IP Cache...
2015/02/13 21:16:42 kid1| DNS Socket created at [::], FD 7
2015/02/13 21:16:42 kid1| DNS Socket created at 0.0.0.0, FD 8
2015/02/13 21:16:42 kid1| Adding nameserver 8.8.8.8 from /etc/resolv.conf
2015/02/13 21:16:42 kid1| helperOpenServers: Starting 5/50 'ssl_crtd' processes
2015/02/13 21:16:42 kid1| Logfile: opening log daemon:/var/log/squid3/access.log
2015/02/13 21:16:42 kid1| Logfile Daemon: opening log /var/log/squid3/access.log
2015/02/13 21:16:42 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2015/02/13 21:16:42 kid1| Store logging disabled
2015/02/13 21:16:42 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2015/02/13 21:16:42 kid1| Target number of buckets: 1008
2015/02/13 21:16:42 kid1| Using 8192 Store buckets
2015/02/13 21:16:42 kid1| Max Mem  size: 262144 KB
2015/02/13 21:16:42 kid1| Max Swap size: 0 KB
2015/02/13 21:16:42 kid1| Using Least Load store dir selection
2015/02/13 21:16:42 kid1| Current Directory is /
2015/02/13 21:16:42 kid1| Finished loading MIME types and icons.
2015/02/13 21:16:42 kid1| HTCP Disabled.
2015/02/13 21:16:42 kid1| Squid plugin modules loaded: 0
2015/02/13 21:16:42 kid1| Adaptation support is off.
2015/02/13 21:16:42 kid1| Accepting HTTP Socket connections at local=[::]:3130 remote=[::] FD 23 flags=9
2015/02/13 21:16:42 kid1| Accepting NAT intercepted HTTP Socket connections at local=[::]:3128 remote=[::] FD 24 flags=41
2015/02/13 21:16:42 kid1| Accepting NAT intercepted SSL bumped HTTPS Socket connections at local=[::]:3127 remote=[::] FD 25 flags=41
2015/02/13 21:16:43 kid1| storeLateRelease: released 0 objects
2015/02/13 21:17:26 kid1| Preparing for shutdown after 66 requests
2015/02/13 21:17:26 kid1| Waiting 30 seconds for active connections to finish
2015/02/13 21:17:26 kid1| Closing HTTP port [::]:3130
2015/02/13 21:17:26 kid1| Closing HTTP port [::]:3128
2015/02/13 21:17:26 kid1| Closing HTTPS port [::]:3127
2015/02/13 21:17:26 kid1| Shutdown: NTLM authentication.
2015/02/13 21:17:26 kid1| Shutdown: Negotiate authentication.
2015/02/13 21:17:26 kid1| Shutdown: Digest authentication.
2015/02/13 21:17:26 kid1| Shutdown: Basic authentication.
2015/02/13 21:17:57 kid1| Shutting down...
2015/02/13 21:17:57 kid1| storeDirWriteCleanLogs: Starting...
2015/02/13 21:17:57 kid1|   Finished.  Wrote 0 entries.
2015/02/13 21:17:57 kid1|   Took 0.00 seconds (  0.00 entries/sec).
CPU Usage: 0.880 seconds = 0.660 user + 0.220 sys
Maximum Resident Size: 87968 KB
Page faults with physical i/o: 0
2015/02/13 21:17:57 kid1| Logfile: closing log daemon:/var/log/squid3/access.log
2015/02/13 21:17:57 kid1| Logfile Daemon: closing log daemon:/var/log/squid3/access.log
2015/02/13 21:17:57 kid1| Open FD UNSTARTED     7 DNS Socket IPv6
2015/02/13 21:17:57 kid1| Open FD READ/WRITE    8 DNS Socket IPv4
2015/02/13 21:17:57 kid1| Open FD READ/WRITE   10 ssl_crtd #1
2015/02/13 21:17:57 kid1| Open FD UNSTARTED    12 ssl_crtd #2
2015/02/13 21:17:57 kid1| Open FD UNSTARTED    14 ssl_crtd #3
2015/02/13 21:17:57 kid1| Open FD UNSTARTED    16 ssl_crtd #4
2015/02/13 21:17:57 kid1| Open FD UNSTARTED    18 ssl_crtd #5
2015/02/13 21:17:57 kid1| Open FD UNSTARTED    21 IPC UNIX STREAM Parent
2015/02/13 21:17:57 kid1| Squid Cache (Version 3.5.1): Exiting normally.
-------------- next part --------------
acl localnet src 192.168.100.0/24

acl SSL_ports port 443
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl CONNECT method CONNECT

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access deny manager



http_access allow localnet
http_access allow localhost

http_access deny all

http_port 3130

http_port 3128 intercept
https_port 3127 intercept ssl-bump generate-host-certificates=on 
dynamic_cert_mem_cache_size=8MB cert=/etc/squid3/ssl_certs/squidCA.pem
acl broken_sites dstdomain .example.com

acl broken_sites dstdomain "/etc/squid3/adapted_sites/files.mail.ru"




sslproxy_cafile /etc/ssl/certs/ca-certificates.crt
ssl_bump none localhost
ssl_bump none broken_sites
ssl_bump server-first all
sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/squid/ssl_db -M 4MB
sslcrtd_children 50


acl no_cache dstdomain "/etc/squid3/adapted_sites/files.mail.ru"
cache deny no_cache
cache allow all


refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

-------------- next part --------------
1423851413.365    235 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.150:443 - ORIGINAL_DST/217.69.141.150 -
1423851413.368    228 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.150:443 - ORIGINAL_DST/217.69.141.150 -
1423851413.565    178 192.168.100.111 TCP_MISS/410 291 GET https://jim24.mail.ru/connect? - ORIGINAL_DST/217.69.141.150 text/html
1423851413.570    228 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.150:443 - ORIGINAL_DST/217.69.141.150 -
1423851413.670     81 192.168.100.111 TCP_MISS/410 291 POST https://jim24.mail.ru/helper? - ORIGINAL_DST/217.69.141.150 text/html
1423851413.904    233 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.180.77:443 - ORIGINAL_DST/94.100.180.77 -
1423851413.943    240 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.139.56:443 - ORIGINAL_DST/217.69.139.56 -
1423851413.950    236 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.139.56:443 - ORIGINAL_DST/217.69.139.56 -
1423851413.974    309 192.168.100.111 TAG_NONE/200 0 CONNECT 185.5.137.172:443 - ORIGINAL_DST/185.5.137.172 -
1423851414.018    312 192.168.100.111 TAG_NONE/200 0 CONNECT 185.5.137.172:443 - ORIGINAL_DST/185.5.137.172 -
1423851414.051    244 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.181.219:443 - ORIGINAL_DST/94.100.181.219 -
1423851414.117    154 192.168.100.111 TCP_MISS/200 651 GET https://jiml.mail.ru/user/status? - ORIGINAL_DST/217.69.139.56 application/json
1423851414.202    175 192.168.100.111 TCP_MISS/200 329 GET https://waerr.radar.imgsmail.ru/update? - ORIGINAL_DST/185.5.137.172 image/gif
1423851414.210    151 192.168.100.111 TCP_MISS/200 408 GET https://rs.mail.ru/d1346376.gif? - ORIGINAL_DST/94.100.181.219 image/gif
1423851414.249     77 192.168.100.111 TCP_MISS/200 408 GET https://rs.mail.ru/d706711.gif? - ORIGINAL_DST/94.100.180.77 image/gif
1423851414.550    313 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.180.174:443 - ORIGINAL_DST/94.100.180.174 -
1423851414.673    309 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.139.174:443 - ORIGINAL_DST/217.69.139.174 -
1423851414.777    306 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.151:443 - ORIGINAL_DST/217.69.141.151 -
1423851414.834    154 192.168.100.111 TCP_MISS/200 329 GET https://mrilog.mail.ru/empty.gif? - ORIGINAL_DST/217.69.139.174 image/gif
1423851414.955    167 192.168.100.111 TCP_MISS/200 2462 GET https://jim25.mail.ru/communicate.html? - ORIGINAL_DST/217.69.141.151 text/html
1423851415.299    233 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.190.95:443 - ORIGINAL_DST/94.100.190.95 -
1423851415.450    303 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.151:443 - ORIGINAL_DST/217.69.141.151 -
1423851415.626    163 192.168.100.111 TCP_MISS/200 669 GET https://jim25.mail.ru/connect? - ORIGINAL_DST/217.69.141.151 application/json
1423851416.000    307 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.151:443 - ORIGINAL_DST/217.69.141.151 -
1423851416.014    310 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.151:443 - ORIGINAL_DST/217.69.141.151 -
1423851416.106     83 192.168.100.111 TCP_MISS/200 669 GET https://jim25.mail.ru/connect? - ORIGINAL_DST/217.69.141.151 application/json
1423851416.245     80 192.168.100.111 TCP_MISS/200 394 POST https://jim25.mail.ru/wp? - ORIGINAL_DST/217.69.141.151 text/html
1423851416.410    232 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.151:443 - ORIGINAL_DST/217.69.141.151 -
1423851416.420    236 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.151:443 - ORIGINAL_DST/217.69.141.151 -
1423851416.506     78 192.168.100.111 TCP_MISS/200 957 GET https://jim25.mail.ru/connect? - ORIGINAL_DST/217.69.141.151 application/json
1423851416.619     80 192.168.100.111 TCP_MISS/200 394 POST https://jim25.mail.ru/wp? - ORIGINAL_DST/217.69.141.151 text/html
1423851416.792    242 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.151:443 - ORIGINAL_DST/217.69.141.151 -
1423851416.796    241 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.151:443 - ORIGINAL_DST/217.69.141.151 -
1423851416.909     96 192.168.100.111 TCP_MISS/200 721 GET https://jim25.mail.ru/connect? - ORIGINAL_DST/217.69.141.151 application/json
1423851433.265    253 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.181.219:443 - ORIGINAL_DST/94.100.181.219 -
1423851433.284    267 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.181.219:443 - ORIGINAL_DST/94.100.181.219 -
1423851433.442     77 192.168.100.111 TCP_MISS/200 408 GET https://rs.mail.ru/d440893.gif? - ORIGINAL_DST/94.100.181.219 image/gif
1423851433.508    242 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.181.219:443 - ORIGINAL_DST/94.100.181.219 -
1423851433.592     76 192.168.100.111 TCP_MISS/200 321 GET https://rs.mail.ru/sb440893.gif? - ORIGINAL_DST/94.100.181.219 image/gif
1423851433.735    251 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.181.219:443 - ORIGINAL_DST/94.100.181.219 -
1423851436.106    249 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.190.95:443 - ORIGINAL_DST/94.100.190.95 -
1423851436.121    255 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.190.95:443 - ORIGINAL_DST/94.100.190.95 -
1423851436.220    260 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.184.41:443 - ORIGINAL_DST/94.100.184.41 -
1423851436.239    258 192.168.100.111 TAG_NONE/200 0 CONNECT 94.100.184.41:443 - ORIGINAL_DST/94.100.184.41 -
1423851436.284    331 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.138:443 - ORIGINAL_DST/217.69.141.138 -
1423851436.360    247 192.168.100.111 TAG_NONE/200 0 CONNECT 128.140.168.248:443 - ORIGINAL_DST/128.140.168.248 -
1423851436.378    254 192.168.100.111 TAG_NONE/200 0 CONNECT 128.140.168.248:443 - ORIGINAL_DST/128.140.168.248 -
1423851436.461    210 192.168.100.111 TCP_MISS/200 966 GET https://ssl.files.mail.ru/cgi-bin/files/fajaxcall? - ORIGINAL_DST/94.100.184.41 text/plain
1423851436.463    322 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.144:443 - ORIGINAL_DST/217.69.141.144 -
1423851436.528    157 192.168.100.111 TCP_MISS/304 371 GET https://img.imgsmail.ru/mail/ru/images/popupbox_tail.gif - ORIGINAL_DST/128.140.168.248 -
1423851436.528    141 192.168.100.111 TCP_MISS/304 372 GET https://img.imgsmail.ru/mail/ru/images/ru/_sp_ico.png? - ORIGINAL_DST/128.140.168.248 -
1423851436.654    159 192.168.100.111 TCP_MISS/200 329 GET https://mail.radar.imgsmail.ru/update? - ORIGINAL_DST/217.69.141.144 image/gif
1423851436.657    159 192.168.100.111 TCP_MISS/200 329 GET https://mail.radar.imgsmail.ru/update? - ORIGINAL_DST/217.69.141.138 image/gif
1423851437.135    244 192.168.100.111 TAG_NONE/200 0 CONNECT 128.140.171.172:443 - ORIGINAL_DST/128.140.171.172 -
1423851437.395    250 192.168.100.111 TCP_MISS/200 552 OPTIONS https://upload196.files.mail.ru/upload_ext_1394/? - ORIGINAL_DST/128.140.171.172 -
1423851437.493     92 192.168.100.111 TCP_MISS_ABORTED/000 0 POST https://upload196.files.mail.ru/upload_ext_1394/? - ORIGINAL_DST/128.140.171.172 -
1423851437.865    245 192.168.100.111 TAG_NONE/200 0 CONNECT 128.140.171.172:443 - ORIGINAL_DST/128.140.171.172 -

##after this error in log, I have error "Can not upload file" in browser.
1423851437.957     82 192.168.100.111 TCP_MISS_ABORTED/000 0 POST https://upload196.files.mail.ru/upload_ext_1394/? - ORIGINAL_DST/128.140.171.172 -

1423851440.091    310 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.144:443 - ORIGINAL_DST/217.69.141.144 -
1423851440.093    308 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.144:443 - ORIGINAL_DST/217.69.141.144 -
1423851440.097    306 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.144:443 - ORIGINAL_DST/217.69.141.144 -
1423851440.192     85 192.168.100.111 TCP_MISS/200 329 GET https://mail.radar.imgsmail.ru/update? - ORIGINAL_DST/217.69.141.144 image/gif
1423851440.220    307 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.144:443 - ORIGINAL_DST/217.69.141.144 -
1423851440.227    309 192.168.100.111 TAG_NONE/200 0 CONNECT 217.69.141.144:443 - ORIGINAL_DST/217.69.141.144 -
1423851440.270     76 192.168.100.111 TCP_MISS/200 329 GET https://mail.radar.imgsmail.ru/update? - ORIGINAL_DST/217.69.141.144 image/gif
1423851440.274     78 192.168.100.111 TCP_MISS/200 329 GET https://mail.radar.imgsmail.ru/update? - ORIGINAL_DST/217.69.141.144 image/gif
1423851473.129  56160 192.168.100.111 TCP_MISS_ABORTED/000 0 GET https://jim25.mail.ru/connect? - ORIGINAL_DST/217.69.141.151 -

From yvoinov at gmail.com  Fri Feb 13 18:37:43 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 14 Feb 2015 00:37:43 +0600
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>
Message-ID: <54DE4477.5010301@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dmitry,

you need to pass mail.ru attachments servers as dst no bump ACL's to work.

In my configuration I use following workaround:

squid.conf:

# Only ip-based dst acl!
acl dst_nobump dst "/usr/local/squid/etc/dst.nobump"

# SSL bump rules
sslproxy_cert_error allow all
ssl_bump none localhost
ssl_bump none url_nobump
ssl_bump none dst_nobump
ssl_bump server-first net_bump

(squid 3.4.11)

dst.nobump contents contains:

# Attachments Mail.ru
94.100.180.215/32
94.100.180.216/32
217.69.139.215/32
217.69.139.216/32
217.69.139.126/32

That's all. Works for me.

Hope this helps.

WBR, Yuri

14.02.15 0:32, Dima Ermakov ?????:
> Good day!
> 
> I have a problem with squid proxy in intercept ssl_bump mode.
> 
> If I want to attach big file (>25MB) to my e-mail message on
> https://mail.ru web site, I have error "Can not upload file".
> 
> Into access.log I have errors: TCP_MISS_ABORTED/000
> 
> My squid configuration, access.log, cache.log in attachment. Thank
> you!
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3kR3AAoJENNXIZxhPexGiCIIAJIBDEHPZdgjmupykCrUCpxc
cSyKlHFhTNiEteUV9ZbgQSSqJ4cwXZD8eDdfazfs7uOkHQqMi2EE58tX+mp2aLV4
sOjOViTsxDmfsc0oydda7isL2hc6iQ9x18IUSom0Z90XMzM6Tl/X2i9DfxZ++ZoL
AK0xE+2bkfGP8XShzDxM/ZjSDT3DeD2ZN3noiDmwfHTn5nlJSqnSt9izUlCTCt0A
tfm3qxv9gAZ4nTY3xW0JoA2/zpI4+4VahfIx304ezxwpjfcHu39HqhmPHmCB1/Ck
9s1JoAfr0WxVw2VFsbHbOMAhrVH6KDrmFS7KvH9MsZ1QRd0pnMmtxGX+YRN7Yfw=
=0l+3
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Fri Feb 13 18:38:54 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 14 Feb 2015 00:38:54 +0600
Subject: [squid-users] requested url could not be retrieved/tweak the
 way it resolves dns
In-Reply-To: <DUB130-W53D1A8AE1FCED2EE448ABEA2230@phx.gbl>
References: <DUB130-W53D1A8AE1FCED2EE448ABEA2230@phx.gbl>
Message-ID: <54DE44BE.6000407@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Claudio,

what is your /etc/resolv.conf on squid cache host contents?

13.02.15 18:20, Claudio Mendes ?????:
> hi,
> 
> i was wondering if there is a way to allow web browser use google
> search for url input which dns can't resolve just like if there was
> no proxy setup ( example get this
> https://www.google.com/search?q=example.com when inputing
> example.com ) instead of getting this: The requested URL could not
> be retrieved
> 
> While trying to retrieve the URL: http://example.com/ The following
> error was encountered: Unable to determine IP address from host
> name for example.com The dnsserver returned: Name Error: The domain
> name does not exist. This means that: The cache was not able to
> resolve the hostname presented in the URL. Check if the address is
> correct. Your cache administrator is administrator at example.com. 
> Generated Fri, 13 Feb 2015 12:06:53 GMT by proxy.example.local
> (squid/2.5.STABLE12)
> 
> thanks for helping _______________________________________________ 
> squid-users mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3kS+AAoJENNXIZxhPexGmB0H/RmR0DD0a0b07fAdL9yINmW/
RmwugwcyuZOo2FBCLBJ7PEqGau8s8hQpGr3/1gL25zu1e73f+Z5UlT+jjSWXGO7D
6AAW1KszhlFvToCVLDT681LJRGNH2FW5BO+X0lstXxFRLr8kWavsayhSy2+VNRIR
rMs5rzsEnXrcGGtKhzDCO2JYIRERMwd7msbTQiVZAuZKXAABRyh4Qv9y39mQ2net
gF9d1LkAuk2lElboTwR4E4x6dzlRp8/Bli9hItMHtxn6xh5WGJCm0mVRAZlj5VrO
cq7dqvdVcpu3yTxlrG/WqGePkcBMWeRdZumIHz6m5Lt2dZd+Fq++9wISI3RFFxA=
=JyVw
-----END PGP SIGNATURE-----


From demonihin at gmail.com  Fri Feb 13 19:28:07 2015
From: demonihin at gmail.com (Dima Ermakov)
Date: Fri, 13 Feb 2015 23:28:07 +0400
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <54DE4477.5010301@gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>
 <54DE4477.5010301@gmail.com>
Message-ID: <CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>

Thank you for your help, but your solution doesn't work on my server.
I have same error, but other ip addresses of uploadXXX.mail.ru servers.
Now I use:
acl mail_ru dstdomain .mail.ru
ssl_bump none mail_ru


Good day!

On 13 February 2015 at 21:37, Yuri Voinov <yvoinov at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Dmitry,
>
> you need to pass mail.ru attachments servers as dst no bump ACL's to work.
>
> In my configuration I use following workaround:
>
> squid.conf:
>
> # Only ip-based dst acl!
> acl dst_nobump dst "/usr/local/squid/etc/dst.nobump"
>
> # SSL bump rules
> sslproxy_cert_error allow all
> ssl_bump none localhost
> ssl_bump none url_nobump
> ssl_bump none dst_nobump
> ssl_bump server-first net_bump
>
> (squid 3.4.11)
>
> dst.nobump contents contains:
>
> # Attachments Mail.ru
> 94.100.180.215/32
> 94.100.180.216/32
> 217.69.139.215/32
> 217.69.139.216/32
> 217.69.139.126/32
>
> That's all. Works for me.
>
> Hope this helps.
>
> WBR, Yuri
>
> 14.02.15 0:32, Dima Ermakov ?????:
> > Good day!
> >
> > I have a problem with squid proxy in intercept ssl_bump mode.
> >
> > If I want to attach big file (>25MB) to my e-mail message on
> > https://mail.ru web site, I have error "Can not upload file".
> >
> > Into access.log I have errors: TCP_MISS_ABORTED/000
> >
> > My squid configuration, access.log, cache.log in attachment. Thank
> > you!
> >
> >
> >
> > _______________________________________________ squid-users mailing
> > list squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU3kR3AAoJENNXIZxhPexGiCIIAJIBDEHPZdgjmupykCrUCpxc
> cSyKlHFhTNiEteUV9ZbgQSSqJ4cwXZD8eDdfazfs7uOkHQqMi2EE58tX+mp2aLV4
> sOjOViTsxDmfsc0oydda7isL2hc6iQ9x18IUSom0Z90XMzM6Tl/X2i9DfxZ++ZoL
> AK0xE+2bkfGP8XShzDxM/ZjSDT3DeD2ZN3noiDmwfHTn5nlJSqnSt9izUlCTCt0A
> tfm3qxv9gAZ4nTY3xW0JoA2/zpI4+4VahfIx304ezxwpjfcHu39HqhmPHmCB1/Ck
> 9s1JoAfr0WxVw2VFsbHbOMAhrVH6KDrmFS7KvH9MsZ1QRd0pnMmtxGX+YRN7Yfw=
> =0l+3
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
? ?????????, ??????? ???????.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150213/d545eae3/attachment.htm>

From yvoinov at gmail.com  Fri Feb 13 19:32:00 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 14 Feb 2015 01:32:00 +0600
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>
 <54DE4477.5010301@gmail.com>
 <CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>
Message-ID: <54DE5130.6030006@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

You have no bump whole .mail.ru domain, which is contains minimum 40%
and over overall traffic...... Not good solution.

I think, be better to no bump only attachments servers.

14.02.15 1:28, Dima Ermakov ?????:
> Thank you for your help, but your solution doesn't work on my
> server. I have same error, but other ip addresses of
> uploadXXX.mail.ru servers. Now I use: acl mail_ru dstdomain
> .mail.ru ssl_bump none mail_ru
> 
> 
> Good day!
> 
> On 13 February 2015 at 21:37, Yuri Voinov <yvoinov at gmail.com>
> wrote:
> 
> Dmitry,
> 
> you need to pass mail.ru attachments servers as dst no bump ACL's
> to work.
> 
> In my configuration I use following workaround:
> 
> squid.conf:
> 
> # Only ip-based dst acl! acl dst_nobump dst
> "/usr/local/squid/etc/dst.nobump"
> 
> # SSL bump rules sslproxy_cert_error allow all ssl_bump none
> localhost ssl_bump none url_nobump ssl_bump none dst_nobump 
> ssl_bump server-first net_bump
> 
> (squid 3.4.11)
> 
> dst.nobump contents contains:
> 
> # Attachments Mail.ru 94.100.180.215/32 94.100.180.216/32 
> 217.69.139.215/32 217.69.139.216/32 217.69.139.126/32
> 
> That's all. Works for me.
> 
> Hope this helps.
> 
> WBR, Yuri
> 
> 14.02.15 0:32, Dima Ermakov ?????:
>>>> Good day!
>>>> 
>>>> I have a problem with squid proxy in intercept ssl_bump
>>>> mode.
>>>> 
>>>> If I want to attach big file (>25MB) to my e-mail message on 
>>>> https://mail.ru web site, I have error "Can not upload
>>>> file".
>>>> 
>>>> Into access.log I have errors: TCP_MISS_ABORTED/000
>>>> 
>>>> My squid configuration, access.log, cache.log in attachment.
>>>> Thank you!
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________ squid-users
>>>> mailing list squid-users at lists.squid-cache.org 
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3lEwAAoJENNXIZxhPexGuFgH/i//Is36huA3zIdvC8cAKLU1
feLbkiTnbMsvUDE7NfbCgkByguc4qt0/xcbke2HshpXVJQON79C4BG5LVunTPg61
N+c3nxNXJIWYmSXJFytfXQNtj8dI6SOav7//IvmNXpgBK/KVTXOhGdS5+E61IM20
32MJ3GpDs1BtEcOTseTbHEYiJ+St6zq0DhMd5sA7tWU+zYpo/6aTpeP3VMO4/hjW
IE/AA8AQIc11WLizX3GxVYt08umGIhyZ9jM8ISUjZJ4Dcijo5Ku6ixf44ZwKeWot
x5gpjE1iOyxzSJ6zjsxADeyKumgTdiTmiQw/Zwpo3rvj8xyktBphEip5mV6jrIk=
=kIDJ
-----END PGP SIGNATURE-----


From ludovit.koren at gmail.com  Fri Feb 13 19:55:50 2015
From: ludovit.koren at gmail.com (Ludovit Koren)
Date: Fri, 13 Feb 2015 20:55:50 +0100
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <mbggb0$fi0$1@ger.gmane.org> (Markus Moeller's message of "Wed,
 11 Feb 2015 21:07:39 -0000")
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
 <86h9usfpsk.fsf@gmail.com> <mbggb0$fi0$1@ger.gmane.org>
Message-ID: <86r3ttbn7d.fsf@gmail.com>

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > Hi Ludovit,
    >   How did you create the keytab ? Usually there is an option allowing
    > you to select the encryption type.  The other place to check would be
    > /etc/krb5.conf. It can contain a list of supported encryption
    > types. See
    > http://www.freebsd.org/cgi/man.cgi?query=krb5.conf&apropos=0&sektion=5&manpath=FreeBSD+Ports+10.1-RELEASE&arch=default&format=html

    > default_tgs_enctypes, default_tkt_enctypes and permitted_enctypes


Hello,

I am sorry, I was not able to contact windows ADS administrator...

I am not able to get the same ciphers in session key and ticket etype.

Here is my /etc/krb5.conf:

[logging]
default = SYSLOG:INFO:USER
kdc = SYSLOG:INFO
kdc = FILE:/var/log/krb.log
admin_server = FILE:/var/log/krb.log
default_keytab_name = FILE:/usr/local/etc/squid/HTTP.keytab

[libdefaults]
default_realm = MDPT.LOCAL
dns_lookup_realm = false
dns_lookup_kdc = false
ticket_lifetime = 24h
forwardable = yes
default_etypes = aes128-cts-hmac-sha1-96
default_tgs_enctypes = aes128-cts-hmac-sha1-96
default_tkt_enctypes = aes128-cts-hmac-sha1-96
permitted_enctypes = aes128-cts-hmac-sha1-96
allow_weak_crypto = true

[realms]
 MDPT.LOCAL = {
  kdc = 10.1.8.21:88
  admin_server = 10.1.8.21:464
 }

[domain_realm]
.mdpt.local = MDPT.LOCAL
.local = MDPT.LOCAL

[appdefaults]
pam = {
 ticket_lifetime = 1d
 renew_lifetime = 1d
 forwardable = true
 proxiable = false
}


I do not know where to setup ticket etype on the squid server side.

regards,

lk


From huaraz at moeller.plus.com  Fri Feb 13 20:28:59 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Fri, 13 Feb 2015 20:28:59 -0000
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <86r3ttbn7d.fsf@gmail.com>
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
 <86h9usfpsk.fsf@gmail.com> <mbggb0$fi0$1@ger.gmane.org>
 <86r3ttbn7d.fsf@gmail.com>
Message-ID: <mblmqb$nqt$1@ger.gmane.org>

Hi Ludovit,

  Firstly, these lines are contradictory

permitted_enctypes = aes128-cts-hmac-sha1-96
allow_weak_crypto = true

weak crypto is des and permitted is aes.  Do you use a mixed AD environment 
( 2003/2008 )  ?  2003 does not support aes.

Markus


"Ludovit Koren"  wrote in message news:86r3ttbn7d.fsf at gmail.com...

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > Hi Ludovit,
    >   How did you create the keytab ? Usually there is an option allowing
    > you to select the encryption type.  The other place to check would be
    > /etc/krb5.conf. It can contain a list of supported encryption
    > types. See
    > 
http://www.freebsd.org/cgi/man.cgi?query=krb5.conf&apropos=0&sektion=5&manpath=FreeBSD+Ports+10.1-RELEASE&arch=default&format=html

    > default_tgs_enctypes, default_tkt_enctypes and permitted_enctypes


Hello,

I am sorry, I was not able to contact windows ADS administrator...

I am not able to get the same ciphers in session key and ticket etype.

Here is my /etc/krb5.conf:

[logging]
default = SYSLOG:INFO:USER
kdc = SYSLOG:INFO
kdc = FILE:/var/log/krb.log
admin_server = FILE:/var/log/krb.log
default_keytab_name = FILE:/usr/local/etc/squid/HTTP.keytab

[libdefaults]
default_realm = MDPT.LOCAL
dns_lookup_realm = false
dns_lookup_kdc = false
ticket_lifetime = 24h
forwardable = yes
default_etypes = aes128-cts-hmac-sha1-96
default_tgs_enctypes = aes128-cts-hmac-sha1-96
default_tkt_enctypes = aes128-cts-hmac-sha1-96
permitted_enctypes = aes128-cts-hmac-sha1-96
allow_weak_crypto = true

[realms]
MDPT.LOCAL = {
  kdc = 10.1.8.21:88
  admin_server = 10.1.8.21:464
}

[domain_realm]
.mdpt.local = MDPT.LOCAL
.local = MDPT.LOCAL

[appdefaults]
pam = {
ticket_lifetime = 1d
renew_lifetime = 1d
forwardable = true
proxiable = false
}


I do not know where to setup ticket etype on the squid server side.

regards,

lk
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From ludovit.koren at gmail.com  Fri Feb 13 20:40:21 2015
From: ludovit.koren at gmail.com (Ludovit Koren)
Date: Fri, 13 Feb 2015 21:40:21 +0100
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <mblmqb$nqt$1@ger.gmane.org> (Markus Moeller's message of "Fri,
 13 Feb 2015 20:28:59 -0000")
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
 <86h9usfpsk.fsf@gmail.com> <mbggb0$fi0$1@ger.gmane.org>
 <86r3ttbn7d.fsf@gmail.com> <mblmqb$nqt$1@ger.gmane.org>
Message-ID: <86mw4hbl56.fsf@gmail.com>

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > Hi Ludovit,
    >  Firstly, these lines are contradictory

    > permitted_enctypes = aes128-cts-hmac-sha1-96
    > allow_weak_crypto = true

    > weak crypto is des and permitted is aes.  Do you use a mixed AD
    > environment ( 2003/2008 )  ?  2003 does not support aes.

Hello,

the AD cluster is due to be upgraded. I think the old is 2003 and new is
2010(?). I am trying to authenticate against new one, I got the keytab
from it with the following:

# ktutil -k /etc/krb5.keytab list
/etc/krb5.keytab:

Vno  Type                     Principal                         Aliases
  5  aes128-cts-hmac-sha1-96  HTTP/proxy.mdpt.local at MDPT.LOCAL  

I commented out allow_weak_crypto. The result is the same.


lk


From squid3 at treenet.co.nz  Fri Feb 13 21:18:27 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Feb 2015 10:18:27 +1300
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <CALTPfpH56aP8RRUkXtoY5N3d-7R68MW81iYiDtAg_huHGBg9tA@mail.gmail.com>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502130927.31478.Antony.Stone@squid.open.source.it>
 <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>
 <201502131134.29803.Antony.Stone@squid.open.source.it>
 <CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>
 <CALTPfpH56aP8RRUkXtoY5N3d-7R68MW81iYiDtAg_huHGBg9tA@mail.gmail.com>
Message-ID: <54DE6A23.6090800@treenet.co.nz>

On 14/02/2015 12:45 a.m., Priya Agarwal wrote:
> root at t4240qds:~# chown -R nobody:nogroup /var/logs


STOP!!!


You are demonstrating in the last few posts that you do not understand
how the command line tools or the permissions work.

Please stop right now from doing anything on your own. This may take a
while to get your system working again, but it is still possible.

If you have anyone who has a lot of experience with the OS you are using
and the command line in particualr please get them to check over the
permissions in your entire /var directory structure.


We can help guide you through what needs to be done for Squid, but only
if you follow the advice exactly as given and not take other steps.



> WARNING: Cannot write log file: /var/logs/cache.log
> /var/logs/cache.log: Permission denied
>          messages will be sent to 'stderr'.
> root at t4240qds:~# ls -ld /var/logs
> drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs
> 

What that means is that the permissions have gotten all screwed up.

As Anthony mentioned your setting of them on /var/ screwed the entire
operating system from being able to write content in the /var directory
and subdirectories.


The top /var directory is always owned by root and group with full read
and execute permissions.

  chown root:root /var
  chmod 755 /var

  chown root:root /var/logs /var/cache /var/run
  chmod 755 /var/cache
  chmod 775 /var/logs


Your proxy is built with the default username of "squid". So there
should be a system user and group by that name

  addgroup --system squid
  adduser --system --no-create-home \
      --disabled-login --disabled-password \
      --ingroup squid squid

If the add* commands complain about existing user/group that is okay.


then show us the output of:
  ls -la /var
  ls -la /var/logs


> 
> On Fri, Feb 13, 2015 at 5:12 PM, Priya Agarwal wrote:
> 
>> Then It is unable to write cache.log:
>> Here is the output:
>>
>> root at t4240qds:~# /usr/sbin/squid -k parse
>> 2015/02/13 12:27:14| Startup: Initializing Authentication Schemes ...
>> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'basic'
>> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'digest'
>> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'negotiate'
>> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'ntlm'
>> 2015/02/13 12:27:14| Startup: Initialized Authentication.
>> 2015/02/13 12:27:14| Processing Configuration File: /etc/squid.conf (depth
>> 0)
>> 2015/02/13 12:27:14| Processing: cache_mgr priyaiitmandi at gmail.com
>> 2015/02/13 12:27:14| Processing: visible_hostname t4240qds
>> 2015/02/13 12:27:14| Processing: cache_effective_user nobody


There is no need for that directive in your squid.conf file.

Your Squid is explicitly built with username "squid".


Amos


From squid3 at treenet.co.nz  Fri Feb 13 21:27:18 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Feb 2015 10:27:18 +1300
Subject: [squid-users] requested url could not be retrieved/tweak the
 way it resolves dns
In-Reply-To: <DUB130-W53D1A8AE1FCED2EE448ABEA2230@phx.gbl>
References: <DUB130-W53D1A8AE1FCED2EE448ABEA2230@phx.gbl>
Message-ID: <54DE6C36.9080104@treenet.co.nz>

On 14/02/2015 1:20 a.m., Claudio Mendes wrote:
> hi,
> 
> i was wondering if there is a way to allow web browser use google search for url input which dns can't resolve just like if there was no proxy setup ( example get this https://www.google.com/search?q=example.com when inputing example.com ) instead of getting this:
> The requested URL could not be retrieved

No, Squid is a web proxy, not a search engine.

If you want the behaviour type into the browser search bar instead of
address bar.

> 
> While trying to retrieve the URL: http://example.com/
> The following error was encountered:
> Unable to determine IP address from host name for example.com
> The dnsserver returned:
> Name Error: The domain name does not exist.
> This means that:
>  The cache was not able to resolve the hostname presented in the URL. 
>  Check if the address is correct. 
> Your cache administrator is administrator at example.com. 
> Generated Fri, 13 Feb 2015 12:06:53 GMT by proxy.example.local (squid/2.5.STABLE12)

WOW! ... *10 years* without software updates. I think you are close to
the record of what I've seen.

The current version of Squid is 3.5.1. With 3.5.2 about to come out.

Upgrade, seriously *Upgrade*.

Amos



From squid3 at treenet.co.nz  Fri Feb 13 21:54:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Feb 2015 10:54:28 +1300
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <003001d0480f$9a0c21a0$ce2464e0$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
 <54DA7817.9060506@treenet.co.nz>
 <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>
 <54DA7ED5.1050801@treenet.co.nz>
 <000001d04783$36589fd0$a309df70$@netstream.ps>
 <003001d0480f$9a0c21a0$ce2464e0$@netstream.ps>
Message-ID: <54DE7294.7070103@treenet.co.nz>

On 14/02/2015 5:35 p.m., snakeeyes wrote:
> Hi Amos , can you chk below plz ?
> 
> 
> mysql> select * from squid ;
> +--------+----------+---------+-----------+---------------------+
> | user   | password | enabled | fullname  | comment             |
> +--------+----------+---------+-----------+---------------------+
> | Nikesh | test     |       1 | Test User | for testing purpose |
> +--------+----------+---------+-----------+---------------------+
> 1 row in set (0.00 sec)
> 
> 
> ==========================
> here is tesing from the remote squid machine using the helper :
> /lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "squid" --password "squid" --table "squid" --usercol "user" --passwdcol "password"
> 
> ERR unknown login
> ERR unknown login
> ERR unknown login
> 

The username tested for does not exist in the database.

You dont show what input you typed, so I cannot be certain why the
manual test gives that result. However looking at your access.log lines...

> Agia I put the user/pwd in y browser with ni luck , each time it refuse my connection .
> 
> Here is access.log :
> 1423799039.114   1072 192.168.1.6 TCP_DENIED/407 4197 CONNECT developer.mozilla.org:443 nikesh HIER_NONE/- text/html

This user has logged in with username "nikesh". The database contains
"Nikesh" with an upper case 'N' character.

Try with typing the same case, and if that dont work with lower case
username in the database.

Amos



From huaraz at moeller.plus.com  Fri Feb 13 22:21:04 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Fri, 13 Feb 2015 22:21:04 -0000
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <86mw4hbl56.fsf@gmail.com>
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
 <86h9usfpsk.fsf@gmail.com> <mbggb0$fi0$1@ger.gmane.org>
 <86r3ttbn7d.fsf@gmail.com> <mblmqb$nqt$1@ger.gmane.org>
 <86mw4hbl56.fsf@gmail.com>
Message-ID: <mbltcf$2ei$1@ger.gmane.org>

It could be the new AD server  is setup to be backward  compatible meaning 
it use RC4 despite being able to use AES.  I suggest you crate an additional 
keytab entry for RC4.  How did you create the keytab ?

Markus


"Ludovit Koren"  wrote in message news:86mw4hbl56.fsf at gmail.com...

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > Hi Ludovit,
    >  Firstly, these lines are contradictory

    > permitted_enctypes = aes128-cts-hmac-sha1-96
    > allow_weak_crypto = true

    > weak crypto is des and permitted is aes.  Do you use a mixed AD
    > environment ( 2003/2008 )  ?  2003 does not support aes.

Hello,

the AD cluster is due to be upgraded. I think the old is 2003 and new is
2010(?). I am trying to authenticate against new one, I got the keytab
from it with the following:

# ktutil -k /etc/krb5.keytab list
/etc/krb5.keytab:

Vno  Type                     Principal                         Aliases
  5  aes128-cts-hmac-sha1-96  HTTP/proxy.mdpt.local at MDPT.LOCAL

I commented out allow_weak_crypto. The result is the same.


lk
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From ludovit.koren at gmail.com  Fri Feb 13 22:28:46 2015
From: ludovit.koren at gmail.com (Ludovit Koren)
Date: Fri, 13 Feb 2015 23:28:46 +0100
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <mbltcf$2ei$1@ger.gmane.org> (Markus Moeller's message of "Fri,
 13 Feb 2015 22:21:04 -0000")
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
 <86h9usfpsk.fsf@gmail.com> <mbggb0$fi0$1@ger.gmane.org>
 <86r3ttbn7d.fsf@gmail.com> <mblmqb$nqt$1@ger.gmane.org>
 <86mw4hbl56.fsf@gmail.com> <mbltcf$2ei$1@ger.gmane.org>
Message-ID: <86egptbg4h.fsf@gmail.com>

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > It could be the new AD server  is setup to be backward  compatible
    > meaning it use RC4 despite being able to use AES.  I suggest you crate
    > an additional keytab entry for RC4.  How did you create the keytab ?

It was created with ktpass on AD. The exact switches used I do not
know. I will manage to get keytab with the RC4.

lk


From priyaiitmandi at gmail.com  Sat Feb 14 05:13:00 2015
From: priyaiitmandi at gmail.com (Priya Agarwal)
Date: Sat, 14 Feb 2015 10:43:00 +0530
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <54DE6A23.6090800@treenet.co.nz>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>
 <201502130927.31478.Antony.Stone@squid.open.source.it>
 <CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>
 <201502131134.29803.Antony.Stone@squid.open.source.it>
 <CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>
 <CALTPfpH56aP8RRUkXtoY5N3d-7R68MW81iYiDtAg_huHGBg9tA@mail.gmail.com>
 <54DE6A23.6090800@treenet.co.nz>
Message-ID: <CALTPfpFuzoAbribgjP_D7ewsbOfpvsKf-txq-w1XtvJ7oOZQTQ@mail.gmail.com>

In the adduser command --disabled-login and --disabled password options are
not there in my system. Got this:

root at t4240qds:~# adduser --system --no-create-home \
> --disabled-login --disabled-password \
> --ingroup squid squid
adduser: unrecognized option '--disabled-login'
Tinylogin v1.4 (2015.01.19-06:01+0000) multi-call binary

Usage: adduser [OPTIONS] <user_name>

And the ouput of ls commands are:
root at t4240qds:~# ls -la /var
total 44
drwxr-xr-x 12 root root    4096 Feb 11 08:34 .
drwxr-xr-x 17 root root    4096 Feb 11 09:28 ..
drwx------  2 root nogroup 4096 Feb 11 08:34 backups
drwxr-xr-x  4 root root    4096 Feb 11 08:34 cache
drwx------  2 root nogroup 4096 Feb 11 08:34 krb5kdc
drwx------  7 root nogroup 4096 Feb 11 09:28 lib
drwx------  2 root nogroup 4096 Feb 11 08:34 local
lrwxrwxrwx  1 root nogroup   13 Feb 11 08:34 lock -> volatile/lock
lrwxrwxrwx  1 root nogroup   12 Feb 11 08:34 log -> volatile/log
drwxrwxr-x  2 root root    4096 Feb 13 11:49 logs
drwx------  2 root nogroup 4096 Feb 11 08:34 openldap-data
drwx------  2 root nogroup 4096 Feb 11 08:34 racoon
lrwxrwxrwx  1 root nogroup   12 Feb 11 08:34 run -> volatile/run
drwx------  3 root nogroup 4096 Feb 11 08:34 spool
lrwxrwxrwx  1 root nogroup   12 Feb 11 08:34 tmp -> volatile/tmp
drwxrwxrwt  6 root root     120 Feb 14 05:41 volatile
root at t4240qds:~# ls -la /var/logs
total 96
drwxrwxr-x  2 root root     4096 Feb 13 11:49 .
drwxr-xr-x 12 root root     4096 Feb 11 08:34 ..
-rw-r-----  1 root nogroup 82104 Feb 13 12:40 cache.log

I had also set the permission of '/usr ' to nobody. I can reboot my system
with the default permissions if I have screwd up my system way too much. If
I try running squid again it would show ' WARNING: Cannot write log file:
/var/logs/cache.log /var/logs/cache.log: Permission denied  messages will
be sent to 'stderr'. '.





On Sat, Feb 14, 2015 at 2:48 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 14/02/2015 12:45 a.m., Priya Agarwal wrote:
> > root at t4240qds:~# chown -R nobody:nogroup /var/logs
>
>
> STOP!!!
>
>
> You are demonstrating in the last few posts that you do not understand
> how the command line tools or the permissions work.
>
> Please stop right now from doing anything on your own. This may take a
> while to get your system working again, but it is still possible.
>
> If you have anyone who has a lot of experience with the OS you are using
> and the command line in particualr please get them to check over the
> permissions in your entire /var directory structure.
>
>
> We can help guide you through what needs to be done for Squid, but only
> if you follow the advice exactly as given and not take other steps.
>
>
>
> > WARNING: Cannot write log file: /var/logs/cache.log
> > /var/logs/cache.log: Permission denied
> >          messages will be sent to 'stderr'.
> > root at t4240qds:~# ls -ld /var/logs
> > drwx------ 2 nobody nogroup 4096 Feb 13 11:49 /var/logs
> >
>
> What that means is that the permissions have gotten all screwed up.
>
> As Anthony mentioned your setting of them on /var/ screwed the entire
> operating system from being able to write content in the /var directory
> and subdirectories.
>
>
> The top /var directory is always owned by root and group with full read
> and execute permissions.
>
>   chown root:root /var
>   chmod 755 /var
>
>   chown root:root /var/logs /var/cache /var/run
>   chmod 755 /var/cache
>   chmod 775 /var/logs
>
>
> Your proxy is built with the default username of "squid". So there
> should be a system user and group by that name
>
>   addgroup --system squid
>   adduser --system --no-create-home \
>       --disabled-login --disabled-password \
>       --ingroup squid squid
>
> If the add* commands complain about existing user/group that is okay.
>
>
> then show us the output of:
>   ls -la /var
>   ls -la /var/logs
>
>
> >
> > On Fri, Feb 13, 2015 at 5:12 PM, Priya Agarwal wrote:
> >
> >> Then It is unable to write cache.log:
> >> Here is the output:
> >>
> >> root at t4240qds:~# /usr/sbin/squid -k parse
> >> 2015/02/13 12:27:14| Startup: Initializing Authentication Schemes ...
> >> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'basic'
> >> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'digest'
> >> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme
> 'negotiate'
> >> 2015/02/13 12:27:14| Startup: Initialized Authentication Scheme 'ntlm'
> >> 2015/02/13 12:27:14| Startup: Initialized Authentication.
> >> 2015/02/13 12:27:14| Processing Configuration File: /etc/squid.conf
> (depth
> >> 0)
> >> 2015/02/13 12:27:14| Processing: cache_mgr priyaiitmandi at gmail.com
> >> 2015/02/13 12:27:14| Processing: visible_hostname t4240qds
> >> 2015/02/13 12:27:14| Processing: cache_effective_user nobody
>
>
> There is no need for that directive in your squid.conf file.
>
> Your Squid is explicitly built with username "squid".
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150214/3aec6ddb/attachment.htm>

From demonihin at gmail.com  Sat Feb 14 06:55:32 2015
From: demonihin at gmail.com (Dima Ermakov)
Date: Sat, 14 Feb 2015 10:55:32 +0400
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <54DE5130.6030006@gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>
 <54DE4477.5010301@gmail.com>
 <CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>
 <54DE5130.6030006@gmail.com>
Message-ID: <CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>

I think, that it's not good solution too, but uploadXXX.files.mail.ru has
about 100 servers.

Now i write small script on python, that creates a file with ip addresses
of uploadXXX.files.mail.ru.

Script and list of ip addresses in attachment.

On 13 February 2015 at 22:32, Yuri Voinov <yvoinov at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> You have no bump whole .mail.ru domain, which is contains minimum 40%
> and over overall traffic...... Not good solution.
>
> I think, be better to no bump only attachments servers.
>
> 14.02.15 1:28, Dima Ermakov ?????:
> > Thank you for your help, but your solution doesn't work on my
> > server. I have same error, but other ip addresses of
> > uploadXXX.mail.ru servers. Now I use: acl mail_ru dstdomain
> > .mail.ru ssl_bump none mail_ru
> >
> >
> > Good day!
> >
> > On 13 February 2015 at 21:37, Yuri Voinov <yvoinov at gmail.com>
> > wrote:
> >
> > Dmitry,
> >
> > you need to pass mail.ru attachments servers as dst no bump ACL's
> > to work.
> >
> > In my configuration I use following workaround:
> >
> > squid.conf:
> >
> > # Only ip-based dst acl! acl dst_nobump dst
> > "/usr/local/squid/etc/dst.nobump"
> >
> > # SSL bump rules sslproxy_cert_error allow all ssl_bump none
> > localhost ssl_bump none url_nobump ssl_bump none dst_nobump
> > ssl_bump server-first net_bump
> >
> > (squid 3.4.11)
> >
> > dst.nobump contents contains:
> >
> > # Attachments Mail.ru 94.100.180.215/32 94.100.180.216/32
> > 217.69.139.215/32 217.69.139.216/32 217.69.139.126/32
> >
> > That's all. Works for me.
> >
> > Hope this helps.
> >
> > WBR, Yuri
> >
> > 14.02.15 0:32, Dima Ermakov ?????:
> >>>> Good day!
> >>>>
> >>>> I have a problem with squid proxy in intercept ssl_bump
> >>>> mode.
> >>>>
> >>>> If I want to attach big file (>25MB) to my e-mail message on
> >>>> https://mail.ru web site, I have error "Can not upload
> >>>> file".
> >>>>
> >>>> Into access.log I have errors: TCP_MISS_ABORTED/000
> >>>>
> >>>> My squid configuration, access.log, cache.log in attachment.
> >>>> Thank you!
> >>>>
> >>>>
> >>>>
> >>>> _______________________________________________ squid-users
> >>>> mailing list squid-users at lists.squid-cache.org
> >>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>
> >> _______________________________________________ squid-users
> >> mailing list squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users
> >>
> >
> >
> >
> >
> >
> > _______________________________________________ squid-users mailing
> > list squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU3lEwAAoJENNXIZxhPexGuFgH/i//Is36huA3zIdvC8cAKLU1
> feLbkiTnbMsvUDE7NfbCgkByguc4qt0/xcbke2HshpXVJQON79C4BG5LVunTPg61
> N+c3nxNXJIWYmSXJFytfXQNtj8dI6SOav7//IvmNXpgBK/KVTXOhGdS5+E61IM20
> 32MJ3GpDs1BtEcOTseTbHEYiJ+St6zq0DhMd5sA7tWU+zYpo/6aTpeP3VMO4/hjW
> IE/AA8AQIc11WLizX3GxVYt08umGIhyZ9jM8ISUjZJ4Dcijo5Ku6ixf44ZwKeWot
> x5gpjE1iOyxzSJ6zjsxADeyKumgTdiTmiQw/Zwpo3rvj8xyktBphEip5mV6jrIk=
> =kIDJ
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
? ?????????, ??????? ???????.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150214/e126bd90/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: upload.files.mail.ru.py
Type: text/x-python
Size: 593 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150214/e126bd90/attachment.py>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: files.mail.ru
Type: application/octet-stream
Size: 1523 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150214/e126bd90/attachment.obj>

From ludovit.koren at gmail.com  Sat Feb 14 08:46:37 2015
From: ludovit.koren at gmail.com (Ludovit Koren)
Date: Sat, 14 Feb 2015 09:46:37 +0100
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <mbltcf$2ei$1@ger.gmane.org> (Markus Moeller's message of "Fri,
 13 Feb 2015 22:21:04 -0000")
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
 <86h9usfpsk.fsf@gmail.com> <mbggb0$fi0$1@ger.gmane.org>
 <86r3ttbn7d.fsf@gmail.com> <mblmqb$nqt$1@ger.gmane.org>
 <86mw4hbl56.fsf@gmail.com> <mbltcf$2ei$1@ger.gmane.org>
Message-ID: <86lhk0j2xe.fsf@gmail.com>

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > It could be the new AD server  is setup to be backward  compatible
    > meaning it use RC4 despite being able to use AES.  I suggest you crate
    > an additional keytab entry for RC4.  How did you create the keytab ?

Now it seems to work:


# /usr/local/libexec/squid/negotiate_kerberos_auth_test proxy.mdpt.local | awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | /usr/local/libexec/squid/negotiate_kerberos_auth -r -s HTTP/proxy.mdpt.local
AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== HTTP/proxy.mdpt.local
BH quit command

respectively with debug output

# /usr/local/libexec/squid/negotiate_kerberos_auth_test proxy.mdpt.local | awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | /usr/local/libexec/squid/negotiate_kerberos_auth -d -r -s HTTP/proxy.mdpt.local
negotiate_kerberos_auth.cc(212): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: INFO: Starting version 3.0.4sq
negotiate_kerberos_auth.cc(258): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: DEBUG: Got 'YR YIIFkgYGKwYBBQUCoIIFhjCCBYKgDTALBgkqhkiG9xIBAgKiggVvBIIFa2CCBWcGCSqGSIb3EgECAgEAboIFVjCCBVKgAwIBBaEDAgEOogcDBQAAAAAAo4IEQGGCBDwwggQ4oAMCAQWhDBsKTURQVC5MT0NBTKIjMCGgAwIBA6EaMBgbBEhUVFAbEHByb3h5Lm1kcHQubG9jYWyjggP8MIID+KADAgEXoQMCAQaiggPqBIID5sVhPZfpC5bIQPSFoRRkg/yI1a3e+rJhYMx9v8sahJtT0prtSF715Q1TAqiXKDZJ479BKKPA27BL63p/mwvu7bf4gznZNTZLFIfHYU/ImK//RrvgkDv1uFSqm/skfzEECQBth4rxozQMfqLgmADCvAdEQVBIeG3D/QlhJ6LNdk4V4f0RBPr8zsagJ7529iSJK0otclE8McAg/5ZB4uA4L9PW6db+UOE3wR1LXK1w40dJkh3YRZX7SjZTEEpT003IRCulEq+fqIfLOPbL8+bbTrECYvvShaMuZF+RAlRZTrxS8P4KPk1f7muLEvA5/EvsGKXmtyTeytd9eRdfAhw5LBuUbwjDsuoliD1ARTPXL1syTtUy4CgJUNu6a6GGgh3uBF2zdDu7cY/4wtU1do3DJRq2NFzjQxcc4TzT64/HjYR+pi2MgchXJBbD3J79AQmKAvtO2B0xI9w/qSCH2uLoPwwzGEXGvr4DsXNgBbkaandw0UtpUyyfd6Gk313mc58dc+G10J3xPhsUOz9a1EOmmETquEPLgjkfpUQY6/MTRbWk/aRl9l681664Ywb6gp9mJioNfz6cxcF7C7fIGKrvBDSyZCBEGH+HOBfBr0REYkqKOqw1xVg0LfYYX4/6pE9ZfJMk3XTHmWKDa+EIahs5ibMsfi+MBx5iEOva3SC8s+rEZyWiG3soowE3U2BCgkGihRAI1thGJVUKLMQy3AokSX7xZF/RiYA4C4MdnFbDdCUJ14vNH4gYZs3A15wbbBUe6aUz3hblSHhFM/vjc4+EyMMyhiJLLYJ9wqe+Y2+eAl0H8wErSjb4ivFv8pNUZuGgbtT4buAE4AHYahWn+f/0S0r05T9uV+273KyA56+KZ4tXnbzhMo9ybqSA6B0BYpsEeDvZDYfUfrDyo4fyT/W2Rem+UMvuJ/o5HRrZWiSP45ANGkqLQcOXwjSDPQQUQaytPeClrqUamnZxbD/XsBosKUUbOfvxnQgWOrVbaDwNN8WfQ+Tv1ZQO8tXoDt9RE1fewaKF8cJS9zsbcSuucBsmQGcMHKn035bsEni8JoiWU1g9ieXeqvRTg5nAkf6bzP3rs4awhXTa3if11liCSZojMUi1Q2d/HZ8X9ZJhu2VS6+EVNQ0dlHspnH3nV8GMz5JI0eQuwPfE2rTOcv4vFZldK2+jJVlCOHu/sMW+gojLjoTg4yrMp1RFq9P3JIlo388eoInu94nAjrbcRgX6W/t+tdUMxGs7+xEoVuCwvnl7jbny31QHzSV2B2n5bGH04z0kAzgOfZmUkJyZivOR8fFisBEX69BWAPXuhQaJFhRsA1pHPPASEYcApIH4MIH1oAMCAReige0Eger41GqgKOrnmoPBzgQ+QQQICBbu/8WBFqzn7Cn4vVSrhsU5umcgSpzTIioLSNQWktPeZQRh/ZcPb+gIWZHaP9LvUEeqXbIT0oYTyStS1bgMCl/yfI4WzGpCKhZbd43jShcQB6SOjQlua7V/0dFOpUv+q1LVD//FFl2dIGoKZHXU5NYpf1yl9dX5Cgd4oKlJUyqgXWclIRzPeGl8nJ8oPvi2af9GGPazSF31Cu7jA/fG9mM4Tses4gI3EPBQBgCAThJ7QeNASK0GEXKsoQE2gYcmaQBTOUP0mhMs43vPqCQckoOcK3/l7SsPwg0=' from squid (length: 1911).
negotiate_kerberos_auth.cc(311): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: DEBUG: Decode 'YIIFkgYGKwYBBQUCoIIFhjCCBYKgDTALBgkqhkiG9xIBAgKiggVvBIIFa2CCBWcGCSqGSIb3EgECAgEAboIFVjCCBVKgAwIBBaEDAgEOogcDBQAAAAAAo4IEQGGCBDwwggQ4oAMCAQWhDBsKTURQVC5MT0NBTKIjMCGgAwIBA6EaMBgbBEhUVFAbEHByb3h5Lm1kcHQubG9jYWyjggP8MIID+KADAgEXoQMCAQaiggPqBIID5sVhPZfpC5bIQPSFoRRkg/yI1a3e+rJhYMx9v8sahJtT0prtSF715Q1TAqiXKDZJ479BKKPA27BL63p/mwvu7bf4gznZNTZLFIfHYU/ImK//RrvgkDv1uFSqm/skfzEECQBth4rxozQMfqLgmADCvAdEQVBIeG3D/QlhJ6LNdk4V4f0RBPr8zsagJ7529iSJK0otclE8McAg/5ZB4uA4L9PW6db+UOE3wR1LXK1w40dJkh3YRZX7SjZTEEpT003IRCulEq+fqIfLOPbL8+bbTrECYvvShaMuZF+RAlRZTrxS8P4KPk1f7muLEvA5/EvsGKXmtyTeytd9eRdfAhw5LBuUbwjDsuoliD1ARTPXL1syTtUy4CgJUNu6a6GGgh3uBF2zdDu7cY/4wtU1do3DJRq2NFzjQxcc4TzT64/HjYR+pi2MgchXJBbD3J79AQmKAvtO2B0xI9w/qSCH2uLoPwwzGEXGvr4DsXNgBbkaandw0UtpUyyfd6Gk313mc58dc+G10J3xPhsUOz9a1EOmmETquEPLgjkfpUQY6/MTRbWk/aRl9l681664Ywb6gp9mJioNfz6cxcF7C7fIGKrvBDSyZCBEGH+HOBfBr0REYkqKOqw1xVg0LfYYX4/6pE9ZfJMk3XTHmWKDa+EIahs5ibMsfi+MBx5iEOva3SC8s+rEZyWiG3soowE3U2BCgkGihRAI1thGJVUKLMQy3AokSX7xZF/RiYA4C4MdnFbDdCUJ14vNH4gYZs3A15wbbBUe6aUz3hblSHhFM/vjc4+EyMMyhiJLLYJ9wqe+Y2+eAl0H8wErSjb4ivFv8pNUZuGgbtT4buAE4AHYahWn+f/0S0r05T9uV+273KyA56+KZ4tXnbzhMo9ybqSA6B0BYpsEeDvZDYfUfrDyo4fyT/W2Rem+UMvuJ/o5HRrZWiSP45ANGkqLQcOXwjSDPQQUQaytPeClrqUamnZxbD/XsBosKUUbOfvxnQgWOrVbaDwNN8WfQ+Tv1ZQO8tXoDt9RE1fewaKF8cJS9zsbcSuucBsmQGcMHKn035bsEni8JoiWU1g9ieXeqvRTg5nAkf6bzP3rs4awhXTa3if11liCSZojMUi1Q2d/HZ8X9ZJhu2VS6+EVNQ0dlHspnH3nV8GMz5JI0eQuwPfE2rTOcv4vFZldK2+jJVlCOHu/sMW+gojLjoTg4yrMp1RFq9P3JIlo388eoInu94nAjrbcRgX6W/t+tdUMxGs7+xEoVuCwvnl7jbny31QHzSV2B2n5bGH04z0kAzgOfZmUkJyZivOR8fFisBEX69BWAPXuhQaJFhRsA1pHPPASEYcApIH4MIH1oAMCAReige0Eger41GqgKOrnmoPBzgQ+QQQICBbu/8WBFqzn7Cn4vVSrhsU5umcgSpzTIioLSNQWktPeZQRh/ZcPb+gIWZHaP9LvUEeqXbIT0oYTyStS1bgMCl/yfI4WzGpCKhZbd43jShcQB6SOjQlua7V/0dFOpUv+q1LVD//FFl2dIGoKZHXU5NYpf1yl9dX5Cgd4oKlJUyqgXWclIRzPeGl8nJ8oPvi2af9GGPazSF31Cu7jA/fG9mM4Tses4gI3EPBQBgCAThJ7QeNASK0GEXKsoQE2gYcmaQBTOUP0mhMs43vPqCQckoOcK3/l7SsPwg0=' (decoded length: 1430).
negotiate_kerberos_pac.cc(368): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: INFO: Got PAC data of lengh 464
negotiate_kerberos_pac.cc(186): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: INFO: Found 2 rids
negotiate_kerberos_pac.cc(193): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: Info: Got rid: 513
negotiate_kerberos_pac.cc(193): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: Info: Got rid: 8830
negotiate_kerberos_pac.cc(255): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: INFO: Got DomainLogonId S-1-5-21-770342266-1452753317-1341851483
negotiate_kerberos_pac.cc(277): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: INFO: Found 1 ExtraSIDs
negotiate_kerberos_pac.cc(325): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: INFO: Got ExtraSid S-1-18-1
negotiate_kerberos_pac.cc(448): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: INFO: Read 464 of 464 bytes 
negotiate_kerberos_auth.cc(426): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: DEBUG: Groups group=AQUAAAAAAAUVAAAAen3qLaVBl1ZbB/tPAQIAAA== group=AQUAAAAAAAUVAAAAen3qLaVBl1ZbB/tPfiIAAA== group=AQEAAAAAABIBAAAA
AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== HTTP/proxy.mdpt.local
negotiate_kerberos_auth.cc(431): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: DEBUG: AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== HTTP/proxy.mdpt.local
negotiate_kerberos_auth.cc(258): pid=59316 :2015/02/14 09:40:23| negotiate_kerberos_auth: DEBUG: Got 'QQ' from squid (length: 2).
BH quit command

It looks like there should be specified all ciphers which could use
different MS clients...

Am I right?

lk


From squid3 at treenet.co.nz  Sat Feb 14 08:58:39 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Feb 2015 21:58:39 +1300
Subject: [squid-users] logfileHandleWrite: daemon:/var/logs/access.log:
 error writing ((32) Broken pipe)
In-Reply-To: <CALTPfpFuzoAbribgjP_D7ewsbOfpvsKf-txq-w1XtvJ7oOZQTQ@mail.gmail.com>
References: <CALTPfpFB4hsM=-EJuLk8+K+AJts=GfNppRjdg+WHgPs6VOEYuA@mail.gmail.com>	<201502130927.31478.Antony.Stone@squid.open.source.it>	<CALTPfpG4NpkMx7aAQ-X9_xYxegFOWRs9=LCVWd_0MLcSgB659g@mail.gmail.com>	<201502131134.29803.Antony.Stone@squid.open.source.it>	<CALTPfpHCs=VB7ipnWGRfc29f26Mi4DB5_B3q_MozpiokXi0WuA@mail.gmail.com>	<CALTPfpH56aP8RRUkXtoY5N3d-7R68MW81iYiDtAg_huHGBg9tA@mail.gmail.com>	<54DE6A23.6090800@treenet.co.nz>
 <CALTPfpFuzoAbribgjP_D7ewsbOfpvsKf-txq-w1XtvJ7oOZQTQ@mail.gmail.com>
Message-ID: <54DF0E3F.8090008@treenet.co.nz>

On 14/02/2015 6:13 p.m., Priya Agarwal wrote:
> 
> I had also set the permission of '/usr ' to nobody. I can reboot my system
> with the default permissions if I have screwd up my system way too much. If


Okay. Do that.

Then let me know what the output is from:

  ls -la /var
  ls -la /var/logs


Amos


From ahmed.zaeem at netstream.ps  Sat Feb 14 19:25:22 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Sat, 14 Feb 2015 11:25:22 -0800
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <54DE7294.7070103@treenet.co.nz>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
 <54DA7817.9060506@treenet.co.nz>
 <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>
 <54DA7ED5.1050801@treenet.co.nz>
 <000001d04783$36589fd0$a309df70$@netstream.ps>
 <003001d0480f$9a0c21a0$ce2464e0$@netstream.ps>
 <54DE7294.7070103@treenet.co.nz>
Message-ID: <004001d0488b$fb25b1f0$f17115d0$@netstream.ps>

Hi Amos , 

Shoudnt the user tested is the user that I gave him the grant ???

I mean I gave grant for user/pwd ==>squid/squid

Now how to test it ?

Shoudnt I test with squid/squid ?? or test with user in db ???
I mean I used :
/lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "squid" --password "squid" --table "squid" --usercol "user" --passwdcol "password"


Shoud I use :

/lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "Nikesh" --password "test" --table "squid" --usercol "user" --passwdcol "password"

??

Anyway I used both methods above and didn?t work and gave me error login

Also I created another user with small letter and tried with same string above and still error login.

I logged locally to the mysql and applied the command :
/lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "squid" --password "squid" --table "squid" --usercol "user" --passwdcol "password"


And still not working !!!

In access.log ==> is says access denied 


Wt do  you think Amos ?

Try another squid verson ? or wt ?


-----Original Message-----
From: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Sent: Friday, February 13, 2015 1:54 PM
To: snakeeyes; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid authentication to remote sql server

On 14/02/2015 5:35 p.m., snakeeyes wrote:
> Hi Amos , can you chk below plz ?
> 
> 
> mysql> select * from squid ;
> +--------+----------+---------+-----------+---------------------+
> | user   | password | enabled | fullname  | comment             |
> +--------+----------+---------+-----------+---------------------+
> | Nikesh | test     |       1 | Test User | for testing purpose |
> +--------+----------+---------+-----------+---------------------+
> 1 row in set (0.00 sec)
> 
> 
> ==========================
> here is tesing from the remote squid machine using the helper :
> /lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "squid" --password "squid" --table "squid" --usercol "user" --passwdcol "password"
> 
> ERR unknown login
> ERR unknown login
> ERR unknown login
> 

The username tested for does not exist in the database.

You dont show what input you typed, so I cannot be certain why the manual test gives that result. However looking at your access.log lines...

> Agia I put the user/pwd in y browser with ni luck , each time it refuse my connection .
> 
> Here is access.log :
> 1423799039.114   1072 192.168.1.6 TCP_DENIED/407 4197 CONNECT developer.mozilla.org:443 nikesh HIER_NONE/- text/html

This user has logged in with username "nikesh". The database contains "Nikesh" with an upper case 'N' character.

Try with typing the same case, and if that dont work with lower case username in the database.

Amos



From yvoinov at gmail.com  Sat Feb 14 10:15:33 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 14 Feb 2015 16:15:33 +0600
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>
 <54DE4477.5010301@gmail.com>
 <CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>
 <54DE5130.6030006@gmail.com>
 <CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>
Message-ID: <54DF2045.4000303@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I.e, you want to say you cannot upload file above 25 megabytes?

14.02.15 12:55, Dima Ermakov ?????:
> I think, that it's not good solution too, but
> uploadXXX.files.mail.ru has about 100 servers.
> 
> Now i write small script on python, that creates a file with ip
> addresses of uploadXXX.files.mail.ru.
> 
> Script and list of ip addresses in attachment.
> 
> On 13 February 2015 at 22:32, Yuri Voinov <yvoinov at gmail.com>
> wrote:
> 
> You have no bump whole .mail.ru domain, which is contains minimum
> 40% and over overall traffic...... Not good solution.
> 
> I think, be better to no bump only attachments servers.
> 
> 14.02.15 1:28, Dima Ermakov ?????:
>>>> Thank you for your help, but your solution doesn't work on
>>>> my server. I have same error, but other ip addresses of 
>>>> uploadXXX.mail.ru servers. Now I use: acl mail_ru dstdomain 
>>>> .mail.ru ssl_bump none mail_ru
>>>> 
>>>> 
>>>> Good day!
>>>> 
>>>> On 13 February 2015 at 21:37, Yuri Voinov
>>>> <yvoinov at gmail.com> wrote:
>>>> 
>>>> Dmitry,
>>>> 
>>>> you need to pass mail.ru attachments servers as dst no bump
>>>> ACL's to work.
>>>> 
>>>> In my configuration I use following workaround:
>>>> 
>>>> squid.conf:
>>>> 
>>>> # Only ip-based dst acl! acl dst_nobump dst 
>>>> "/usr/local/squid/etc/dst.nobump"
>>>> 
>>>> # SSL bump rules sslproxy_cert_error allow all ssl_bump none 
>>>> localhost ssl_bump none url_nobump ssl_bump none dst_nobump 
>>>> ssl_bump server-first net_bump
>>>> 
>>>> (squid 3.4.11)
>>>> 
>>>> dst.nobump contents contains:
>>>> 
>>>> # Attachments Mail.ru 94.100.180.215/32 94.100.180.216/32 
>>>> 217.69.139.215/32 217.69.139.216/32 217.69.139.126/32
>>>> 
>>>> That's all. Works for me.
>>>> 
>>>> Hope this helps.
>>>> 
>>>> WBR, Yuri
>>>> 
>>>> 14.02.15 0:32, Dima Ermakov ?????:
>>>>>>> Good day!
>>>>>>> 
>>>>>>> I have a problem with squid proxy in intercept
>>>>>>> ssl_bump mode.
>>>>>>> 
>>>>>>> If I want to attach big file (>25MB) to my e-mail
>>>>>>> message on https://mail.ru web site, I have error "Can
>>>>>>> not upload file".
>>>>>>> 
>>>>>>> Into access.log I have errors: TCP_MISS_ABORTED/000
>>>>>>> 
>>>>>>> My squid configuration, access.log, cache.log in
>>>>>>> attachment. Thank you!
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> _______________________________________________
>>>>>>> squid-users mailing list
>>>>>>> squid-users at lists.squid-cache.org 
>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>>> 
>>>>> _______________________________________________
>>>>> squid-users mailing list squid-users at lists.squid-cache.org 
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________ squid-users
>>>> mailing list squid-users at lists.squid-cache.org 
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3yBFAAoJENNXIZxhPexG/OwIAMg7v5BZTXx3tbGMbL8451zl
gYxLJoY+ooUk5kj90jgQjJr4XhFkdmH+GKM5MTn8o0lVnMrk9O6kA8XHVTTzirzR
k5Eo5Fv4ubdztwAnWkxGH1Oy4rkPjuySIRpejrlomtUqhOBqNDTS1PV0m049+CIc
gRiDir6jnVzCrNTv6vt8K1BJP8mS/lPNY0jBNYnm147NkLoV5hNZs+Y1PwOjIAxd
oT6+msic8jBrL4eNl2toqstimff3EoCl6VBhSwBMAPKoXA90cD09cVWIbijZEv6t
TK6J0RQm79DSvIx3R/YeeaEx2N1su4PJsuO/mnJHf0rrqq0eOzzUxIYpcyX/H+E=
=0+ks
-----END PGP SIGNATURE-----


From demonihin at gmail.com  Sat Feb 14 10:20:15 2015
From: demonihin at gmail.com (Dima Ermakov)
Date: Sat, 14 Feb 2015 14:20:15 +0400
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <54DF2045.4000303@gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>
 <54DE4477.5010301@gmail.com>
 <CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>
 <54DE5130.6030006@gmail.com>
 <CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>
 <54DF2045.4000303@gmail.com>
Message-ID: <CAOpdYyukaX4SbTZhzTNHh+=WkTAUn8S8EFQAvBHLMaWAFmsYBg@mail.gmail.com>

Now i can upload, after adding ip addresses from my previous message to
ssl_bump none acl.
Thank you.
On Feb 14, 2015 1:15 PM, "Yuri Voinov" <yvoinov at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> I.e, you want to say you cannot upload file above 25 megabytes?
>
> 14.02.15 12:55, Dima Ermakov ?????:
> > I think, that it's not good solution too, but
> > uploadXXX.files.mail.ru has about 100 servers.
> >
> > Now i write small script on python, that creates a file with ip
> > addresses of uploadXXX.files.mail.ru.
> >
> > Script and list of ip addresses in attachment.
> >
> > On 13 February 2015 at 22:32, Yuri Voinov <yvoinov at gmail.com>
> > wrote:
> >
> > You have no bump whole .mail.ru domain, which is contains minimum
> > 40% and over overall traffic...... Not good solution.
> >
> > I think, be better to no bump only attachments servers.
> >
> > 14.02.15 1:28, Dima Ermakov ?????:
> >>>> Thank you for your help, but your solution doesn't work on
> >>>> my server. I have same error, but other ip addresses of
> >>>> uploadXXX.mail.ru servers. Now I use: acl mail_ru dstdomain
> >>>> .mail.ru ssl_bump none mail_ru
> >>>>
> >>>>
> >>>> Good day!
> >>>>
> >>>> On 13 February 2015 at 21:37, Yuri Voinov
> >>>> <yvoinov at gmail.com> wrote:
> >>>>
> >>>> Dmitry,
> >>>>
> >>>> you need to pass mail.ru attachments servers as dst no bump
> >>>> ACL's to work.
> >>>>
> >>>> In my configuration I use following workaround:
> >>>>
> >>>> squid.conf:
> >>>>
> >>>> # Only ip-based dst acl! acl dst_nobump dst
> >>>> "/usr/local/squid/etc/dst.nobump"
> >>>>
> >>>> # SSL bump rules sslproxy_cert_error allow all ssl_bump none
> >>>> localhost ssl_bump none url_nobump ssl_bump none dst_nobump
> >>>> ssl_bump server-first net_bump
> >>>>
> >>>> (squid 3.4.11)
> >>>>
> >>>> dst.nobump contents contains:
> >>>>
> >>>> # Attachments Mail.ru 94.100.180.215/32 94.100.180.216/32
> >>>> 217.69.139.215/32 217.69.139.216/32 217.69.139.126/32
> >>>>
> >>>> That's all. Works for me.
> >>>>
> >>>> Hope this helps.
> >>>>
> >>>> WBR, Yuri
> >>>>
> >>>> 14.02.15 0:32, Dima Ermakov ?????:
> >>>>>>> Good day!
> >>>>>>>
> >>>>>>> I have a problem with squid proxy in intercept
> >>>>>>> ssl_bump mode.
> >>>>>>>
> >>>>>>> If I want to attach big file (>25MB) to my e-mail
> >>>>>>> message on https://mail.ru web site, I have error "Can
> >>>>>>> not upload file".
> >>>>>>>
> >>>>>>> Into access.log I have errors: TCP_MISS_ABORTED/000
> >>>>>>>
> >>>>>>> My squid configuration, access.log, cache.log in
> >>>>>>> attachment. Thank you!
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> _______________________________________________
> >>>>>>> squid-users mailing list
> >>>>>>> squid-users at lists.squid-cache.org
> >>>>>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>>>>
> >>>>> _______________________________________________
> >>>>> squid-users mailing list squid-users at lists.squid-cache.org
> >>>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> _______________________________________________ squid-users
> >>>> mailing list squid-users at lists.squid-cache.org
> >>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>
> >> _______________________________________________ squid-users
> >> mailing list squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users
> >>
> >
> >
> >
> >
> >
> > _______________________________________________ squid-users mailing
> > list squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU3yBFAAoJENNXIZxhPexG/OwIAMg7v5BZTXx3tbGMbL8451zl
> gYxLJoY+ooUk5kj90jgQjJr4XhFkdmH+GKM5MTn8o0lVnMrk9O6kA8XHVTTzirzR
> k5Eo5Fv4ubdztwAnWkxGH1Oy4rkPjuySIRpejrlomtUqhOBqNDTS1PV0m049+CIc
> gRiDir6jnVzCrNTv6vt8K1BJP8mS/lPNY0jBNYnm147NkLoV5hNZs+Y1PwOjIAxd
> oT6+msic8jBrL4eNl2toqstimff3EoCl6VBhSwBMAPKoXA90cD09cVWIbijZEv6t
> TK6J0RQm79DSvIx3R/YeeaEx2N1su4PJsuO/mnJHf0rrqq0eOzzUxIYpcyX/H+E=
> =0+ks
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150214/be110abc/attachment.htm>

From yvoinov at gmail.com  Sat Feb 14 10:22:26 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 14 Feb 2015 16:22:26 +0600
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <CAOpdYyukaX4SbTZhzTNHh+=WkTAUn8S8EFQAvBHLMaWAFmsYBg@mail.gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>	<54DE4477.5010301@gmail.com>	<CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>	<54DE5130.6030006@gmail.com>	<CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>	<54DF2045.4000303@gmail.com>
 <CAOpdYyukaX4SbTZhzTNHh+=WkTAUn8S8EFQAvBHLMaWAFmsYBg@mail.gmail.com>
Message-ID: <54DF21E2.5020508@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

No problem. ;)

100 ip's is no problem. If they in one subnet, you can pass only this
sublet with one row in acl. Overall *.mail.ru is much more networks,
so 100 ip's no matter. ;) But bumping remains can give your better hit
rate.


14.02.15 16:20, Dima Ermakov ?????:
> Now i can upload, after adding ip addresses from my previous
> message to ssl_bump none acl. Thank you. On Feb 14, 2015 1:15 PM,
> "Yuri Voinov" <yvoinov at gmail.com> wrote:
> 
> I.e, you want to say you cannot upload file above 25 megabytes?
> 
> 14.02.15 12:55, Dima Ermakov ?????:
>>>> I think, that it's not good solution too, but 
>>>> uploadXXX.files.mail.ru has about 100 servers.
>>>> 
>>>> Now i write small script on python, that creates a file with
>>>> ip addresses of uploadXXX.files.mail.ru.
>>>> 
>>>> Script and list of ip addresses in attachment.
>>>> 
>>>> On 13 February 2015 at 22:32, Yuri Voinov
>>>> <yvoinov at gmail.com> wrote:
>>>> 
>>>> You have no bump whole .mail.ru domain, which is contains
>>>> minimum 40% and over overall traffic...... Not good
>>>> solution.
>>>> 
>>>> I think, be better to no bump only attachments servers.
>>>> 
>>>> 14.02.15 1:28, Dima Ermakov ?????:
>>>>>>> Thank you for your help, but your solution doesn't work
>>>>>>> on my server. I have same error, but other ip addresses
>>>>>>> of uploadXXX.mail.ru servers. Now I use: acl mail_ru
>>>>>>> dstdomain .mail.ru ssl_bump none mail_ru
>>>>>>> 
>>>>>>> 
>>>>>>> Good day!
>>>>>>> 
>>>>>>> On 13 February 2015 at 21:37, Yuri Voinov 
>>>>>>> <yvoinov at gmail.com> wrote:
>>>>>>> 
>>>>>>> Dmitry,
>>>>>>> 
>>>>>>> you need to pass mail.ru attachments servers as dst no
>>>>>>> bump ACL's to work.
>>>>>>> 
>>>>>>> In my configuration I use following workaround:
>>>>>>> 
>>>>>>> squid.conf:
>>>>>>> 
>>>>>>> # Only ip-based dst acl! acl dst_nobump dst 
>>>>>>> "/usr/local/squid/etc/dst.nobump"
>>>>>>> 
>>>>>>> # SSL bump rules sslproxy_cert_error allow all ssl_bump
>>>>>>> none localhost ssl_bump none url_nobump ssl_bump none
>>>>>>> dst_nobump ssl_bump server-first net_bump
>>>>>>> 
>>>>>>> (squid 3.4.11)
>>>>>>> 
>>>>>>> dst.nobump contents contains:
>>>>>>> 
>>>>>>> # Attachments Mail.ru 94.100.180.215/32
>>>>>>> 94.100.180.216/32 217.69.139.215/32 217.69.139.216/32
>>>>>>> 217.69.139.126/32
>>>>>>> 
>>>>>>> That's all. Works for me.
>>>>>>> 
>>>>>>> Hope this helps.
>>>>>>> 
>>>>>>> WBR, Yuri
>>>>>>> 
>>>>>>> 14.02.15 0:32, Dima Ermakov ?????:
>>>>>>>>>> Good day!
>>>>>>>>>> 
>>>>>>>>>> I have a problem with squid proxy in intercept 
>>>>>>>>>> ssl_bump mode.
>>>>>>>>>> 
>>>>>>>>>> If I want to attach big file (>25MB) to my
>>>>>>>>>> e-mail message on https://mail.ru web site, I
>>>>>>>>>> have error "Can not upload file".
>>>>>>>>>> 
>>>>>>>>>> Into access.log I have errors:
>>>>>>>>>> TCP_MISS_ABORTED/000
>>>>>>>>>> 
>>>>>>>>>> My squid configuration, access.log, cache.log in 
>>>>>>>>>> attachment. Thank you!
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> _______________________________________________ 
>>>>>>>>>> squid-users mailing list 
>>>>>>>>>> squid-users at lists.squid-cache.org 
>>>>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>>>>>>
>>>>>>>>
>>>>>>>>>> 
_______________________________________________
>>>>>>>> squid-users mailing list
>>>>>>>> squid-users at lists.squid-cache.org 
>>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> _______________________________________________
>>>>>>> squid-users mailing list
>>>>>>> squid-users at lists.squid-cache.org 
>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>>> 
>>>>> _______________________________________________
>>>>> squid-users mailing list squid-users at lists.squid-cache.org 
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________ squid-users
>>>> mailing list squid-users at lists.squid-cache.org 
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU3yHiAAoJENNXIZxhPexGN34H/2fo1Ky6mBpjUCYqmfLOMcNA
UD8pmQlvsPEc+AFzq0aGod9Wd7Dv/LJSxYx9WeUZb5ltUUCaG6MnVAkh/fxhMH6X
/CYswYi83j+o6C/PmfD2vilm/Ee4kGuhTlT3Tq7L3oT/8g4MiF3o1z2aLEfN1xYy
evl6dKUm8obEDO8qsx+PLPPGVeFpR546g4qmLPbIVY0T3GY4zxwOrzvSg4G3VDJY
C07H6jpzFa35nDFiwbqQPsUlNOIqS3DLFp+47cRonUBCvbaESXJvjQ2Y4mMlYR0Q
xR8nAdZz+ZoWwZyzBybdFXsF2OYCJPpujc8h0KnXJj29652/0zBB8Q+qKGSRO3c=
=oF+/
-----END PGP SIGNATURE-----


From demonihin at gmail.com  Sat Feb 14 10:40:49 2015
From: demonihin at gmail.com (Dima Ermakov)
Date: Sat, 14 Feb 2015 14:40:49 +0400
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <54DF21E2.5020508@gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>
 <54DE4477.5010301@gmail.com>
 <CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>
 <54DE5130.6030006@gmail.com>
 <CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>
 <54DF2045.4000303@gmail.com>
 <CAOpdYyukaX4SbTZhzTNHh+=WkTAUn8S8EFQAvBHLMaWAFmsYBg@mail.gmail.com>
 <54DF21E2.5020508@gmail.com>
Message-ID: <CAOpdYytzg-DQ0QEo8ygt-1bZg5_WCvSxdx9cg6UrfUpAv54j9Q@mail.gmail.com>

Yes! No problem;) Thank you!!!
On Feb 14, 2015 1:22 PM, "Yuri Voinov" <yvoinov at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> No problem. ;)
>
> 100 ip's is no problem. If they in one subnet, you can pass only this
> sublet with one row in acl. Overall *.mail.ru is much more networks,
> so 100 ip's no matter. ;) But bumping remains can give your better hit
> rate.
>
>
> 14.02.15 16:20, Dima Ermakov ?????:
> > Now i can upload, after adding ip addresses from my previous
> > message to ssl_bump none acl. Thank you. On Feb 14, 2015 1:15 PM,
> > "Yuri Voinov" <yvoinov at gmail.com> wrote:
> >
> > I.e, you want to say you cannot upload file above 25 megabytes?
> >
> > 14.02.15 12:55, Dima Ermakov ?????:
> >>>> I think, that it's not good solution too, but
> >>>> uploadXXX.files.mail.ru has about 100 servers.
> >>>>
> >>>> Now i write small script on python, that creates a file with
> >>>> ip addresses of uploadXXX.files.mail.ru.
> >>>>
> >>>> Script and list of ip addresses in attachment.
> >>>>
> >>>> On 13 February 2015 at 22:32, Yuri Voinov
> >>>> <yvoinov at gmail.com> wrote:
> >>>>
> >>>> You have no bump whole .mail.ru domain, which is contains
> >>>> minimum 40% and over overall traffic...... Not good
> >>>> solution.
> >>>>
> >>>> I think, be better to no bump only attachments servers.
> >>>>
> >>>> 14.02.15 1:28, Dima Ermakov ?????:
> >>>>>>> Thank you for your help, but your solution doesn't work
> >>>>>>> on my server. I have same error, but other ip addresses
> >>>>>>> of uploadXXX.mail.ru servers. Now I use: acl mail_ru
> >>>>>>> dstdomain .mail.ru ssl_bump none mail_ru
> >>>>>>>
> >>>>>>>
> >>>>>>> Good day!
> >>>>>>>
> >>>>>>> On 13 February 2015 at 21:37, Yuri Voinov
> >>>>>>> <yvoinov at gmail.com> wrote:
> >>>>>>>
> >>>>>>> Dmitry,
> >>>>>>>
> >>>>>>> you need to pass mail.ru attachments servers as dst no
> >>>>>>> bump ACL's to work.
> >>>>>>>
> >>>>>>> In my configuration I use following workaround:
> >>>>>>>
> >>>>>>> squid.conf:
> >>>>>>>
> >>>>>>> # Only ip-based dst acl! acl dst_nobump dst
> >>>>>>> "/usr/local/squid/etc/dst.nobump"
> >>>>>>>
> >>>>>>> # SSL bump rules sslproxy_cert_error allow all ssl_bump
> >>>>>>> none localhost ssl_bump none url_nobump ssl_bump none
> >>>>>>> dst_nobump ssl_bump server-first net_bump
> >>>>>>>
> >>>>>>> (squid 3.4.11)
> >>>>>>>
> >>>>>>> dst.nobump contents contains:
> >>>>>>>
> >>>>>>> # Attachments Mail.ru 94.100.180.215/32
> >>>>>>> 94.100.180.216/32 217.69.139.215/32 217.69.139.216/32
> >>>>>>> 217.69.139.126/32
> >>>>>>>
> >>>>>>> That's all. Works for me.
> >>>>>>>
> >>>>>>> Hope this helps.
> >>>>>>>
> >>>>>>> WBR, Yuri
> >>>>>>>
> >>>>>>> 14.02.15 0:32, Dima Ermakov ?????:
> >>>>>>>>>> Good day!
> >>>>>>>>>>
> >>>>>>>>>> I have a problem with squid proxy in intercept
> >>>>>>>>>> ssl_bump mode.
> >>>>>>>>>>
> >>>>>>>>>> If I want to attach big file (>25MB) to my
> >>>>>>>>>> e-mail message on https://mail.ru web site, I
> >>>>>>>>>> have error "Can not upload file".
> >>>>>>>>>>
> >>>>>>>>>> Into access.log I have errors:
> >>>>>>>>>> TCP_MISS_ABORTED/000
> >>>>>>>>>>
> >>>>>>>>>> My squid configuration, access.log, cache.log in
> >>>>>>>>>> attachment. Thank you!
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> _______________________________________________
> >>>>>>>>>> squid-users mailing list
> >>>>>>>>>> squid-users at lists.squid-cache.org
> >>>>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>>>>>>>
> >>>>>>>>
> >>>>>>>>>>
> _______________________________________________
> >>>>>>>> squid-users mailing list
> >>>>>>>> squid-users at lists.squid-cache.org
> >>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> _______________________________________________
> >>>>>>> squid-users mailing list
> >>>>>>> squid-users at lists.squid-cache.org
> >>>>>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>>>>
> >>>>> _______________________________________________
> >>>>> squid-users mailing list squid-users at lists.squid-cache.org
> >>>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> _______________________________________________ squid-users
> >>>> mailing list squid-users at lists.squid-cache.org
> >>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>
> >> _______________________________________________ squid-users
> >> mailing list squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users
> >>
> >
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU3yHiAAoJENNXIZxhPexGN34H/2fo1Ky6mBpjUCYqmfLOMcNA
> UD8pmQlvsPEc+AFzq0aGod9Wd7Dv/LJSxYx9WeUZb5ltUUCaG6MnVAkh/fxhMH6X
> /CYswYi83j+o6C/PmfD2vilm/Ee4kGuhTlT3Tq7L3oT/8g4MiF3o1z2aLEfN1xYy
> evl6dKUm8obEDO8qsx+PLPPGVeFpR546g4qmLPbIVY0T3GY4zxwOrzvSg4G3VDJY
> C07H6jpzFa35nDFiwbqQPsUlNOIqS3DLFp+47cRonUBCvbaESXJvjQ2Y4mMlYR0Q
> xR8nAdZz+ZoWwZyzBybdFXsF2OYCJPpujc8h0KnXJj29652/0zBB8Q+qKGSRO3c=
> =oF+/
> -----END PGP SIGNATURE-----
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150214/7dbd14dc/attachment.htm>

From huaraz at moeller.plus.com  Sat Feb 14 13:00:13 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sat, 14 Feb 2015 13:00:13 -0000
Subject: [squid-users] Kerberos authentication problem - squid 3.4.11
In-Reply-To: <86lhk0j2xe.fsf@gmail.com>
References: <86a90nxj41.fsf@gmail.com> <mbb8e1$7l7$1@ger.gmane.org>
 <86d25i9plr.fsf@gmail.com> <mbdqmh$ere$1@ger.gmane.org>
 <86h9usfpsk.fsf@gmail.com> <mbggb0$fi0$1@ger.gmane.org>
 <86r3ttbn7d.fsf@gmail.com> <mblmqb$nqt$1@ger.gmane.org>
 <86mw4hbl56.fsf@gmail.com> <mbltcf$2ei$1@ger.gmane.org>
 <86lhk0j2xe.fsf@gmail.com>
Message-ID: <mbngst$r8$1@ger.gmane.org>

Hi Ludovit,

  Yes the client determines the encryption strength and squid needs to have 
all of them in the keytab (You can disallow DES or other weak encryption by 
not adding these encryptions to the keytab).

Regards
Markus

"Ludovit Koren"  wrote in message news:86lhk0j2xe.fsf at gmail.com...

>>>>> Markus Moeller <huaraz at moeller.plus.com> writes:

    > It could be the new AD server  is setup to be backward  compatible
    > meaning it use RC4 despite being able to use AES.  I suggest you crate
    > an additional keytab entry for RC4.  How did you create the keytab ?

Now it seems to work:


# /usr/local/libexec/squid/negotiate_kerberos_auth_test proxy.mdpt.local | 
awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | 
/usr/local/libexec/squid/negotiate_kerberos_auth -r -s HTTP/proxy.mdpt.local
AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== HTTP/proxy.mdpt.local
BH quit command

respectively with debug output

# /usr/local/libexec/squid/negotiate_kerberos_auth_test proxy.mdpt.local | 
awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | 
/usr/local/libexec/squid/negotiate_kerberos_auth -d -r -s 
HTTP/proxy.mdpt.local
negotiate_kerberos_auth.cc(212): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: INFO: Starting version 3.0.4sq
negotiate_kerberos_auth.cc(258): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: DEBUG: Got 'YR 
YIIFkgYGKwYBBQUCoIIFhjCCBYKgDTALBgkqhkiG9xIBAgKiggVvBIIFa2CCBWcGCSqGSIb3EgECAgEAboIFVjCCBVKgAwIBBaEDAgEOogcDBQAAAAAAo4IEQGGCBDwwggQ4oAMCAQWhDBsKTURQVC5MT0NBTKIjMCGgAwIBA6EaMBgbBEhUVFAbEHByb3h5Lm1kcHQubG9jYWyjggP8MIID+KADAgEXoQMCAQaiggPqBIID5sVhPZfpC5bIQPSFoRRkg/yI1a3e+rJhYMx9v8sahJtT0prtSF715Q1TAqiXKDZJ479BKKPA27BL63p/mwvu7bf4gznZNTZLFIfHYU/ImK//RrvgkDv1uFSqm/skfzEECQBth4rxozQMfqLgmADCvAdEQVBIeG3D/QlhJ6LNdk4V4f0RBPr8zsagJ7529iSJK0otclE8McAg/5ZB4uA4L9PW6db+UOE3wR1LXK1w40dJkh3YRZX7SjZTEEpT003IRCulEq+fqIfLOPbL8+bbTrECYvvShaMuZF+RAlRZTrxS8P4KPk1f7muLEvA5/EvsGKXmtyTeytd9eRdfAhw5LBuUbwjDsuoliD1ARTPXL1syTtUy4CgJUNu6a6GGgh3uBF2zdDu7cY/4wtU1do3DJRq2NFzjQxcc4TzT64/HjYR+pi2MgchXJBbD3J79AQmKAvtO2B0xI9w/qSCH2uLoPwwzGEXGvr4DsXNgBbkaandw0UtpUyyfd6Gk313mc58dc+G10J3xPhsUOz9a1EOmmETquEPLgjkfpUQY6/MTRbWk/aRl9l681664Ywb6gp9mJioNfz6cxcF7C7fIGKrvBDSyZCBEGH+HOBfBr0REYkqKOqw1xVg0LfYYX4/6pE9ZfJMk3XTHmWKDa+EIahs5ibMsfi+MBx5iEOva3SC8s+rEZyWiG3soowE3U2BCgkGihRAI1thGJVUKLMQy3AokSX7xZF/RiYA4C4MdnFbDdCUJ14vNH4gYZs3A15wbbBUe6aUz3hblSHhFM/vjc4+EyMMyhiJLLYJ9wqe+Y2+eAl0H8wErSjb4ivFv8pNUZuGgbtT4buAE4AHYahWn+f/0S0r05T9uV+273KyA56+KZ4tXnbzhMo9ybqSA6B0BYpsEeDvZDYfUfrDyo4fyT/W2Rem+UMvuJ/o5HRrZWiSP45ANGkqLQcOXwjSDPQQUQaytPeClrqUamnZxbD/XsBosKUUbOfvxnQgWOrVbaDwNN8WfQ+Tv1ZQO8tXoDt9RE1fewaKF8cJS9zsbcSuucBsmQGcMHKn035bsEni8JoiWU1g9ieXeqvRTg5nAkf6bzP3rs4awhXTa3if11liCSZojMUi1Q2d/HZ8X9ZJhu2VS6+EVNQ0dlHspnH3nV8GMz5JI0eQuwPfE2rTOcv4vFZldK2+jJVlCOHu/sMW+gojLjoTg4yrMp1RFq9P3JIlo388eoInu94nAjrbcRgX6W/t+tdUMxGs7+xEoVuCwvnl7jbny31QHzSV2B2n5bGH04z0kAzgOfZmUkJyZivOR8fFisBEX69BWAPXuhQaJFhRsA1pHPPASEYcApIH4MIH1oAMCAReige0Eger41GqgKOrnmoPBzgQ+QQQICBbu/8WBFqzn7Cn4vVSrhsU5umcgSpzTIioLSNQWktPeZQRh/ZcPb+gIWZHaP9LvUEeqXbIT0oYTyStS1bgMCl/yfI4WzGpCKhZbd43jShcQB6SOjQlua7V/0dFOpUv+q1LVD//FFl2dIGoKZHXU5NYpf1yl9dX5Cgd4oKlJUyqgXWclIRzPeGl8nJ8oPvi2af9GGPazSF31Cu7jA/fG9mM4Tses4gI3EPBQBgCAThJ7QeNASK0GEXKsoQE2gYcmaQBTOUP0mhMs43vPqCQckoOcK3/l7SsPwg0=' 
from squid (length: 1911).
negotiate_kerberos_auth.cc(311): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: DEBUG: Decode 
'YIIFkgYGKwYBBQUCoIIFhjCCBYKgDTALBgkqhkiG9xIBAgKiggVvBIIFa2CCBWcGCSqGSIb3EgECAgEAboIFVjCCBVKgAwIBBaEDAgEOogcDBQAAAAAAo4IEQGGCBDwwggQ4oAMCAQWhDBsKTURQVC5MT0NBTKIjMCGgAwIBA6EaMBgbBEhUVFAbEHByb3h5Lm1kcHQubG9jYWyjggP8MIID+KADAgEXoQMCAQaiggPqBIID5sVhPZfpC5bIQPSFoRRkg/yI1a3e+rJhYMx9v8sahJtT0prtSF715Q1TAqiXKDZJ479BKKPA27BL63p/mwvu7bf4gznZNTZLFIfHYU/ImK//RrvgkDv1uFSqm/skfzEECQBth4rxozQMfqLgmADCvAdEQVBIeG3D/QlhJ6LNdk4V4f0RBPr8zsagJ7529iSJK0otclE8McAg/5ZB4uA4L9PW6db+UOE3wR1LXK1w40dJkh3YRZX7SjZTEEpT003IRCulEq+fqIfLOPbL8+bbTrECYvvShaMuZF+RAlRZTrxS8P4KPk1f7muLEvA5/EvsGKXmtyTeytd9eRdfAhw5LBuUbwjDsuoliD1ARTPXL1syTtUy4CgJUNu6a6GGgh3uBF2zdDu7cY/4wtU1do3DJRq2NFzjQxcc4TzT64/HjYR+pi2MgchXJBbD3J79AQmKAvtO2B0xI9w/qSCH2uLoPwwzGEXGvr4DsXNgBbkaandw0UtpUyyfd6Gk313mc58dc+G10J3xPhsUOz9a1EOmmETquEPLgjkfpUQY6/MTRbWk/aRl9l681664Ywb6gp9mJioNfz6cxcF7C7fIGKrvBDSyZCBEGH+HOBfBr0REYkqKOqw1xVg0LfYYX4/6pE9ZfJMk3XTHmWKDa+EIahs5ibMsfi+MBx5iEOva3SC8s+rEZyWiG3soowE3U2BCgkGihRAI1thGJVUKLMQy3AokSX7xZF/RiYA4C4MdnFbDdCUJ14vNH4gYZs3A15wbbBUe6aUz3hblSHhFM/vjc4+EyMMyhiJLLYJ9wqe+Y2+eAl0H8wErSjb4ivFv8pNUZuGgbtT4buAE4AHYahWn+f/0S0r05T9uV+273KyA56+KZ4tXnbzhMo9ybqSA6B0BYpsEeDvZDYfUfrDyo4fyT/W2Rem+UMvuJ/o5HRrZWiSP45ANGkqLQcOXwjSDPQQUQaytPeClrqUamnZxbD/XsBosKUUbOfvxnQgWOrVbaDwNN8WfQ+Tv1ZQO8tXoDt9RE1fewaKF8cJS9zsbcSuucBsmQGcMHKn035bsEni8JoiWU1g9ieXeqvRTg5nAkf6bzP3rs4awhXTa3if11liCSZojMUi1Q2d/HZ8X9ZJhu2VS6+EVNQ0dlHspnH3nV8GMz5JI0eQuwPfE2rTOcv4vFZldK2+jJVlCOHu/sMW+gojLjoTg4yrMp1RFq9P3JIlo388eoInu94nAjrbcRgX6W/t+tdUMxGs7+xEoVuCwvnl7jbny31QHzSV2B2n5bGH04z0kAzgOfZmUkJyZivOR8fFisBEX69BWAPXuhQaJFhRsA1pHPPASEYcApIH4MIH1oAMCAReige0Eger41GqgKOrnmoPBzgQ+QQQICBbu/8WBFqzn7Cn4vVSrhsU5umcgSpzTIioLSNQWktPeZQRh/ZcPb+gIWZHaP9LvUEeqXbIT0oYTyStS1bgMCl/yfI4WzGpCKhZbd43jShcQB6SOjQlua7V/0dFOpUv+q1LVD//FFl2dIGoKZHXU5NYpf1yl9dX5Cgd4oKlJUyqgXWclIRzPeGl8nJ8oPvi2af9GGPazSF31Cu7jA/fG9mM4Tses4gI3EPBQBgCAThJ7QeNASK0GEXKsoQE2gYcmaQBTOUP0mhMs43vPqCQckoOcK3/l7SsPwg0=' 
(decoded length: 1430).
negotiate_kerberos_pac.cc(368): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: INFO: Got PAC data of lengh 464
negotiate_kerberos_pac.cc(186): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: INFO: Found 2 rids
negotiate_kerberos_pac.cc(193): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: Info: Got rid: 513
negotiate_kerberos_pac.cc(193): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: Info: Got rid: 8830
negotiate_kerberos_pac.cc(255): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: INFO: Got DomainLogonId 
S-1-5-21-770342266-1452753317-1341851483
negotiate_kerberos_pac.cc(277): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: INFO: Found 1 ExtraSIDs
negotiate_kerberos_pac.cc(325): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: INFO: Got ExtraSid S-1-18-1
negotiate_kerberos_pac.cc(448): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: INFO: Read 464 of 464 bytes
negotiate_kerberos_auth.cc(426): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: DEBUG: Groups 
group=AQUAAAAAAAUVAAAAen3qLaVBl1ZbB/tPAQIAAA== 
group=AQUAAAAAAAUVAAAAen3qLaVBl1ZbB/tPfiIAAA== group=AQEAAAAAABIBAAAA
AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== HTTP/proxy.mdpt.local
negotiate_kerberos_auth.cc(431): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: DEBUG: AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== 
HTTP/proxy.mdpt.local
negotiate_kerberos_auth.cc(258): pid=59316 :2015/02/14 09:40:23| 
negotiate_kerberos_auth: DEBUG: Got 'QQ' from squid (length: 2).
BH quit command

It looks like there should be specified all ciphers which could use
different MS clients...

Am I right?

lk
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From huaraz at moeller.plus.com  Sat Feb 14 14:43:52 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sat, 14 Feb 2015 14:43:52 -0000
Subject: [squid-users] benefits
	ofusingext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <3BFE59DF-A379-49E6-B177-D4A86DE7678D@open.ch>
References: <mailman.42287.1423690543.1833.squid-users@lists.squid-cache.org>
 <A77FDA65-6F38-4C4F-A323-C1B749878B5A@open.ch>
 <54DCDBCD.5070909@treenet.co.nz>
 <3BFE59DF-A379-49E6-B177-D4A86DE7678D@open.ch>
Message-ID: <mbnmv8$sdd$1@ger.gmane.org>


>On 12.02.2015, at 17:58, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>> On 13/02/2015 5:41 a.m., Simon St?heli wrote:
>>>
>>> hmh, HAVE_KRB5 seems not to be set in include/autoconf.h
>>>
>>> What is the correct way to provide squid the path to the kerberos header 
>>> files?
>>>
>>> ./configure ?help doesn?t show a useful option as --with-krb5-config= 
>>> seems not to be the right option.
>>
>> If you are using Squid-3.4 or older versions where that option exists,
>> you need to insted use CXXFLAGS to set the -I (library headers) and -L
>> (library binary) locations.
>> Something like:
>> ./configure CXXFLAGS="-I/path/to/include -L/path/to/lib" ?
>
>
>Thx for the hint! Tried ./configure 
>CXXFLAGS="-I/opt/krb5/include -L/opt/krb5/lib" --prefix=/opt/squid --sysconfdir=/opt/squid/etc 
> --enable-auth --enable-auth-negotiate="kerberos" --enable-external-acl-helpers=?kerberos_ldap_group? 
>but without success. The /opt/krb5/ paths have been set in the Makefile, 
>but HAVE_KRB5 is still no defined. Anything else to do here? (used 
>Squid-3.4.11)
>
>
>>
>>
>> Squid-3.5 and later have per-library ./configure options. In the case of
>> Heimdal use --with-heimdal-krb5=PATH
>
>
>tried it with Squid-3.5 and --with-heimdal-krb5=PATH and seems to work 
>until make tries to compile kerberos_ldap_group
>
>make[2]: Entering directory 
>`/usr/src/packages/src/squid-3.5.1/helpers/external_acl/kerberos_ldap_group'
>g++ -DHAVE_CONFIG_H   -I../../.. -I../../../include -I../../../lib -I../../../src 
> -I../../../include  -I/opt/krb5/include  -I/opt/krb5/include   -I.  -Wall  
>-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -pipe -D_REENTRANT 
> -m64 -I/opt/krb5/include   -I/opt/krb5/include -L/opt/krb5/lib -march=native 
> -MT support_krb5.o -MD -MP -MF .deps/support_krb5.Tpo -c -o support_krb5.o 
>support_krb5.cc
>cc1plus: warnings being treated as errors
>support_krb5.cc: In function 'int krb5_create_cache(char*)':
>support_krb5.cc:89:9: error: 'const char* 
>krb5_get_err_text(krb5_context_data*, krb5_error_code)' is deprecated 
>(declared at /opt/krb5/include/krb5-protos.h:2089)
>...
>make[2]: *** [support_krb5.o] Error 1
>make[2]: Leaving directory 
>`/usr/src/packages/src/OSAGsquid-sis/squid-3.5.1/helpers/external_acl/kerberos_ldap_group?
>
>my Heimdal Kerberos (Heimdal 1.3.3) libs seemed no to be compatible with 
>kerberos_ldap_group?!
>
>

I am a bit surprised as I did not see this when testing on freebsd with 
heimdal.   I update my  trunk version at 
https://code.launchpad.net/~huaraz/squid/kerberos-updates. Can you test with 
that and if OK I will ask to include the updates.

>>
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>

Markus 




From squid3 at treenet.co.nz  Sat Feb 14 20:02:31 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 15 Feb 2015 09:02:31 +1300
Subject: [squid-users] squid  authentication to remote sql server
In-Reply-To: <004001d0488b$fb25b1f0$f17115d0$@netstream.ps>
References: <002e01d044e6$4b3bc700$e1b35500$@netstream.ps>
 <54D94D9C.1090108@treenet.co.nz>
 <000a01d045c3$5d5894d0$1809be70$@netstream.ps>
 <54DA6D28.9010806@treenet.co.nz>
 <000001d045ca$d217f480$7647dd80$@netstream.ps>
 <54DA7817.9060506@treenet.co.nz>
 <000101d045ce$03fe95a0$0bfbc0e0$@netstream.ps>
 <54DA7ED5.1050801@treenet.co.nz>
 <000001d04783$36589fd0$a309df70$@netstream.ps>
 <003001d0480f$9a0c21a0$ce2464e0$@netstream.ps>
 <54DE7294.7070103@treenet.co.nz>
 <004001d0488b$fb25b1f0$f17115d0$@netstream.ps>
Message-ID: <54DFA9D7.5020301@treenet.co.nz>

On 15/02/2015 8:25 a.m., snakeeyes wrote:
> Hi Amos , 
> 
> Shoudnt the user tested is the user that I gave him the grant ???

The 'user' who got a SQL "GRANT" is the software user whch is allowed to
acccess the DB contents. That should only be Squid and/or your sysadmin
who changes users records.


The username records inside the DB is what login to Squid.


> 
> I mean I gave grant for user/pwd ==>squid/squid
> 
> Now how to test it ?
> 
> Shoudnt I test with squid/squid ?? or test with user in db ???
> I mean I used :
> /lib/squid/basic_db_auth 


These mean database to use and how to access it:

> --dsn "DBI:mysql:database=squid:xx189.177" --user "squid" --password
"squid"


These mean where to find the end-users account data:

> --table "squid" --usercol "user" --passwdcol "password"
> 
> 
> Shoud I use :
> 
> /lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "Nikesh" --password "test" --table "squid" --usercol "user" --passwdcol "password"
> 
> ??

No.

> 
> Anyway I used both methods above and didn?t work and gave me error login
> 
> Also I created another user with small letter and tried with same string above and still error login.
> 
> I logged locally to the mysql and applied the command :
> /lib/squid/basic_db_auth --dsn "DBI:mysql:database=squid:xx189.177" --user "squid" --password "squid" --table "squid" --usercol "user" --passwdcol "password"
> 
> 
> And still not working !!!
> 
> In access.log ==> is says access denied 
> 
> 
> Wt do  you think Amos ?
> 

I think it works for me and my clients. Must be something in how you are
testing it.

> Try another squid verson ? or wt ?
> 
> 

When I test it I get this:


> ./basic_db_auth \
>   --dsn ... \
>   --user "squid" --password "..." \
>   --table "accounts" --usercol "user" --passwdcol "passwd" \
>   --cond "" --plaintext
a b
ERR unknown login
c d
ERR unknown login
squid demo
OK
user password
ERR unknown login
amos test
OK

ERR unknown login

ERR unknown login


I run the lastest alpha / "pre-beta" Squid version so I know what people
will be encountering. But the helper code has not changed much since
3.1. It should work the same in any version.

Amos



From Jason_Haar at trimble.com  Sat Feb 14 20:26:48 2015
From: Jason_Haar at trimble.com (Jason Haar)
Date: Sun, 15 Feb 2015 09:26:48 +1300
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <54DF21E2.5020508@gmail.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>	<54DE4477.5010301@gmail.com>	<CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>	<54DE5130.6030006@gmail.com>	<CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>	<54DF2045.4000303@gmail.com>
 <CAOpdYyukaX4SbTZhzTNHh+=WkTAUn8S8EFQAvBHLMaWAFmsYBg@mail.gmail.com>
 <54DF21E2.5020508@gmail.com>
Message-ID: <54DFAF88.3010104@trimble.com>

But this is just a hack around a problem isn't it? ie why can't squid
successfully intercept 20M+ transfers from this website? I guess it's
working for 1byte-10M transactions, so why not 20M?

Jason

On 14/02/15 23:22, Yuri Voinov wrote:
>  No problem. ;)
>
> 100 ip's is no problem. If they in one subnet, you can pass only this
> sublet with one row in acl. Overall *.mail.ru is much more networks,
> so 100 ip's no matter. ;) But bumping remains can give your better hit
> rate.
-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 181 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150215/643cede9/attachment.sig>

From yvoinov at gmail.com  Sat Feb 14 20:39:27 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 15 Feb 2015 02:39:27 +0600
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <54DFAF88.3010104@trimble.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>	<54DE4477.5010301@gmail.com>	<CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>	<54DE5130.6030006@gmail.com>	<CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>	<54DF2045.4000303@gmail.com>
 <CAOpdYyukaX4SbTZhzTNHh+=WkTAUn8S8EFQAvBHLMaWAFmsYBg@mail.gmail.com>
 <54DF21E2.5020508@gmail.com> <54DFAF88.3010104@trimble.com>
Message-ID: <54DFB27F.3060603@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Yep. This is dirty hack.:)

But I guess this is site-specific limitations. Besides the fact that
the bump does not work with attachments to many Webmail services and
clouds.

I think, this is because mail.ru uses cloud as backend of mail
attachments. With own restrictions and limitations.

15.02.15 2:26, Jason Haar ?????:
> But this is just a hack around a problem isn't it? ie why can't
> squid successfully intercept 20M+ transfers from this website? I
> guess it's working for 1byte-10M transactions, so why not 20M?
> 
> Jason
> 
> On 14/02/15 23:22, Yuri Voinov wrote:
>> No problem. ;)
>> 
>> 100 ip's is no problem. If they in one subnet, you can pass only
>> this sublet with one row in acl. Overall *.mail.ru is much more
>> networks, so 100 ip's no matter. ;) But bumping remains can give
>> your better hit rate.
>> 
>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU37J/AAoJENNXIZxhPexGZggIAIXlN1s6SiSK5r5QdGRbx9Sn
/MVbstifBXVT/q3Bs6aTLM65yB2g7RgzN/RAjn6+iBj8wOK+nTxpv0KxqvbBlwFC
8G03AJk5GzyIyHplF0sGBF7sOI5mnmrCX2zvz8vvdL98yvSlmxguN8PD4i2lg5dS
mv+MQIxZMwGgptd6O4Ed/DUizzbr6P6GtIQv4m1qIrius4+uKzquJOW3ckktIzRK
r3ziQ1vmZ3udGRgzR0x4BQ/1pPAxr03g6qpKIVpXWXUF5RzlFvBMhftKido08eoC
xf0rmwQOUlB9jVsMpHCLlnHr39SCS3X3rEAb3YaeLklZvgnQ5220cQJu8RQGia8=
=5qU0
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Sat Feb 14 21:46:13 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 15 Feb 2015 10:46:13 +1300
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <54DFAF88.3010104@trimble.com>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>	<54DE4477.5010301@gmail.com>	<CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>	<54DE5130.6030006@gmail.com>	<CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>	<54DF2045.4000303@gmail.com>
 <CAOpdYyukaX4SbTZhzTNHh+=WkTAUn8S8EFQAvBHLMaWAFmsYBg@mail.gmail.com>
 <54DF21E2.5020508@gmail.com> <54DFAF88.3010104@trimble.com>
Message-ID: <54DFC225.5010601@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15/02/2015 9:26 a.m., Jason Haar wrote:
> But this is just a hack around a problem isn't it?

Yes.

> ie why can't squid successfully intercept 20M+ transfers from this
> website?

Well, Squid *is* intercepting them. Its what happens after that is
going wrong.

> I guess it's working for 1byte-10M transactions, so why not 20M?

Indeed. Lets look closer...


> 1423851413.570    228 192.168.100.111 TAG_NONE/200 0 CONNECT
> 217.69.141.150:443 - ORIGINAL_DST/217.69.141.150 -

Squid receives a CONNECT, bumps it...


> 1423851413.670     81 192.168.100.111 TCP_MISS/410 291 POST
> https://jim24.mail.ru/helper? - ORIGINAL_DST/217.69.141.150
> text/html


.. inside is a POST to "jim24.mail.ru:443"

Squid delivers that to the server the CONNECT was going to
(217.69.141.150:443).

The server responds "410 Gone".


A debug_options 11,2 trace might provide more insight.

Amos

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU38IkAAoJELJo5wb/XPRjS4UIAOEMiMhYYhfdKR6RncP2dS8w
SjpjPDcpBnGPBgrgfZDGqRna3wkq3m2VvsHfgez//c7hiRkSJ6tWZdIlZMIVvI/P
cZ1x4DSUdsovfVNK/Yfs2Vc6oPjgkpBWrMAlNw3/TcNwHcn6PQCsj0xXxUdZ/Br6
jQ56WuL5FZA+dsIdbKQFwvuVfziwkcGwFfeBLmfEynbEjfV3H6fSe8t5lj5tbLnq
1qUvqdMtyGN4Nvji9T4hslRIgFoFBKs+lJVSSQD9Rqs8/bomukAcoj6H4XplMSZq
zg+zxuMamZJrepM+URqgVxWR8fW+qQH173yq4eHjsTibpyJ5HpGhC+hSmQrCZjY=
=MN2Y
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Sat Feb 14 21:48:54 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 15 Feb 2015 03:48:54 +0600
Subject: [squid-users] intercept squid 3.5.1, http://mail.ru
In-Reply-To: <54DFC225.5010601@treenet.co.nz>
References: <CAOpdYyt8RPvNmTEzncF3KT8sCbdsQeNC=TbDuqWHbuWA+C9uBA@mail.gmail.com>	<54DE4477.5010301@gmail.com>	<CAOpdYysi-Sxm7KfX4EFjE84Z4ccRNhQkw6fNH+66r1Br1evA7g@mail.gmail.com>	<54DE5130.6030006@gmail.com>	<CAOpdYyvibBvOa9iG3MHi7b8kwiZtv_Tv4WvWHX6KfjvyeZRJXw@mail.gmail.com>	<54DF2045.4000303@gmail.com>
 <CAOpdYyukaX4SbTZhzTNHh+=WkTAUn8S8EFQAvBHLMaWAFmsYBg@mail.gmail.com>
 <54DF21E2.5020508@gmail.com> <54DFAF88.3010104@trimble.com>
 <54DFC225.5010601@treenet.co.nz>
Message-ID: <54DFC2C6.80009@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


I can to reproduce this with trace at Monday. My users uses that.

15.02.15 3:46, Amos Jeffries ?????:
> On 15/02/2015 9:26 a.m., Jason Haar wrote:
>> But this is just a hack around a problem isn't it?
> 
> Yes.
> 
>> ie why can't squid successfully intercept 20M+ transfers from
>> this website?
> 
> Well, Squid *is* intercepting them. Its what happens after that is 
> going wrong.
> 
>> I guess it's working for 1byte-10M transactions, so why not 20M?
> 
> Indeed. Lets look closer...
> 
> 
>> 1423851413.570    228 192.168.100.111 TAG_NONE/200 0 CONNECT 
>> 217.69.141.150:443 - ORIGINAL_DST/217.69.141.150 -
> 
> Squid receives a CONNECT, bumps it...
> 
> 
>> 1423851413.670     81 192.168.100.111 TCP_MISS/410 291 POST 
>> https://jim24.mail.ru/helper? - ORIGINAL_DST/217.69.141.150 
>> text/html
> 
> 
> .. inside is a POST to "jim24.mail.ru:443"
> 
> Squid delivers that to the server the CONNECT was going to 
> (217.69.141.150:443).
> 
> The server responds "410 Gone".
> 
> 
> A debug_options 11,2 trace might provide more insight.
> 
> Amos
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU38LGAAoJENNXIZxhPexGbJcH/1LYvgYWwlczMjSTOSgXIkDb
UjNTDUGMO5b4MnJbGKE+4RYDle6zImYFXvw7hQCzfTigpJk8X6V+ZB6GhyKULjY+
+ACndtPj4WyixE2Om59Vf3iXZXv47c1rLitFSaARg8dHJh8BnAuBX1fEgeL+uhVO
oNZjq4hl5QOObixrrd9YtxiN34nL1suY0Hd8LCBcd1UuGqEqTM7Q4C0mp9GZ1Y0m
8OEQA8wUxjiES4b2b44Dv4DwwG5ulomHXZedJXMUMIiPPsmLM4ro46bdKQ+gQNj/
ouQ9t3yDnw4UJaqzy4WVZ0/hdCWkCBDmsLaD6OFYboQrZvZe5/xzfYl5kh1Q9Cs=
=fQUk
-----END PGP SIGNATURE-----


From naser.sonbaty at gmail.com  Sat Feb 14 23:19:35 2015
From: naser.sonbaty at gmail.com (naser sonbaty)
Date: Sun, 15 Feb 2015 00:19:35 +0100
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <CA+suCFgMGX0JiBzjNau+Fhg_baV7oUNxLUwneLKgWugZAYDgNw@mail.gmail.com>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
 <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
 <201502121140.55913.Antony.Stone@squid.open.source.it>
 <CA+suCFgMGX0JiBzjNau+Fhg_baV7oUNxLUwneLKgWugZAYDgNw@mail.gmail.com>
Message-ID: <CAEXOXs1x+FG6m1bJdQxnS4wfxuZ7KpV-j6Ne_Hothh00iDH0vA@mail.gmail.com>

Hi,

thx for support.

I found second running squid on same box. I shut-down the second squid.
But the problems are not gone......

Sorry I don't have access to the router pc :-( I can not get the rule ....

I have set up web browsers to use direct squid with 3129.
But the result its same.
I found another logs too:

2015/02/14 23:52:25.957 kid1| SECURITY ALERT: Host header forgery detected
on local=192.168.15.2:3129 remote=10.0.0.7:54648 FD 77 flags=33
(intercepted port does not match 443)
2015/02/14 23:52:25.957 kid1| SECURITY ALERT: By user agent: Mozilla/5.0
(Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko/20100101
Firefox/12.0
2015/02/14 23:52:25.957 kid1| SECURITY ALERT: on URL: www.youtube.com:443

OS ist Slackware on squid box.
All web browser on client PCs is set to use proxy server

Topology is:
Clients PC connected to switch -> switch to Router pc -> squid its on DMZ
Von Router pc

thx for support


On Thu, Feb 12, 2015 at 3:34 PM, Luis Miguel Silva <
luismiguelferreirasilva at gmail.com> wrote:

> I bumped into this same "forwarding loop" problem yesterday!
> In my case, it was because I had two transparent proxies in the same
> network and was basically redirecting traffic twice:
> [internet] <-> [appliance 1] <-> [appliance 2] <-> [client computer]
>
> I mistakenly added iptables redirect rules in both appliance 1 and
> appliance 2 and that caused Squid to spit out that "forwarding loop
> detected" error.
>
>
> On Thu, Feb 12, 2015 at 4:40 AM, Antony Stone <
> Antony.Stone at squid.open.source.it> wrote:
>
>> On Thursday 12 Feb 2015 at 11:26, naser sonbaty wrote:
>>
>> > Hi,
>> >
>> > Internet is connected to Router PC
>> >
>> > Only trafic to port 80 is send to squid.
>>
>> Yes, I know that, but traffic *from* where?
>>
>> Please answer the question below.  Even better, show us the redirect rule
>> you're using on the router to do it.
>>
>> > On Thu, Feb 12, 2015 at 11:58 AM, Antony Stone wrote:
>> > >
>> > > Have you configured the router to redirect port 80 traffic from the
>> > > Client PC to Squid 3129, or have you configured it to redirect *all*
>> port
>> > > 80 traffic (including from Squid) to Squid 3129?
>> > >
>> > > Looks like the Router is making Squid talk to itself.
>>
>>
>> Regards,
>>
>>
>> Antony.
>>
>> --
>> I love deadlines.   I love the whooshing noise they make as they go by.
>>
>>  - Douglas Noel Adams
>>
>>                                                    Please reply to the
>> list;
>>                                                          please *don't*
>> CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150215/b6707aec/attachment.htm>

From naser.sonbaty at gmail.com  Sat Feb 14 23:19:35 2015
From: naser.sonbaty at gmail.com (naser sonbaty)
Date: Sun, 15 Feb 2015 00:19:35 +0100
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <CA+suCFgMGX0JiBzjNau+Fhg_baV7oUNxLUwneLKgWugZAYDgNw@mail.gmail.com>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
 <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
 <201502121140.55913.Antony.Stone@squid.open.source.it>
 <CA+suCFgMGX0JiBzjNau+Fhg_baV7oUNxLUwneLKgWugZAYDgNw@mail.gmail.com>
Message-ID: <CAEXOXs1x+FG6m1bJdQxnS4wfxuZ7KpV-j6Ne_Hothh00iDH0vA@mail.gmail.com>

Hi,

thx for support.

I found second running squid on same box. I shut-down the second squid.
But the problems are not gone......

Sorry I don't have access to the router pc :-( I can not get the rule ....

I have set up web browsers to use direct squid with 3129.
But the result its same.
I found another logs too:

2015/02/14 23:52:25.957 kid1| SECURITY ALERT: Host header forgery detected
on local=192.168.15.2:3129 remote=10.0.0.7:54648 FD 77 flags=33
(intercepted port does not match 443)
2015/02/14 23:52:25.957 kid1| SECURITY ALERT: By user agent: Mozilla/5.0
(Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko/20100101
Firefox/12.0
2015/02/14 23:52:25.957 kid1| SECURITY ALERT: on URL: www.youtube.com:443

OS ist Slackware on squid box.
All web browser on client PCs is set to use proxy server

Topology is:
Clients PC connected to switch -> switch to Router pc -> squid its on DMZ
Von Router pc

thx for support


On Thu, Feb 12, 2015 at 3:34 PM, Luis Miguel Silva <
luismiguelferreirasilva at gmail.com> wrote:

> I bumped into this same "forwarding loop" problem yesterday!
> In my case, it was because I had two transparent proxies in the same
> network and was basically redirecting traffic twice:
> [internet] <-> [appliance 1] <-> [appliance 2] <-> [client computer]
>
> I mistakenly added iptables redirect rules in both appliance 1 and
> appliance 2 and that caused Squid to spit out that "forwarding loop
> detected" error.
>
>
> On Thu, Feb 12, 2015 at 4:40 AM, Antony Stone <
> Antony.Stone at squid.open.source.it> wrote:
>
>> On Thursday 12 Feb 2015 at 11:26, naser sonbaty wrote:
>>
>> > Hi,
>> >
>> > Internet is connected to Router PC
>> >
>> > Only trafic to port 80 is send to squid.
>>
>> Yes, I know that, but traffic *from* where?
>>
>> Please answer the question below.  Even better, show us the redirect rule
>> you're using on the router to do it.
>>
>> > On Thu, Feb 12, 2015 at 11:58 AM, Antony Stone wrote:
>> > >
>> > > Have you configured the router to redirect port 80 traffic from the
>> > > Client PC to Squid 3129, or have you configured it to redirect *all*
>> port
>> > > 80 traffic (including from Squid) to Squid 3129?
>> > >
>> > > Looks like the Router is making Squid talk to itself.
>>
>>
>> Regards,
>>
>>
>> Antony.
>>
>> --
>> I love deadlines.   I love the whooshing noise they make as they go by.
>>
>>  - Douglas Noel Adams
>>
>>                                                    Please reply to the
>> list;
>>                                                          please *don't*
>> CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150215/b6707aec/attachment-0001.htm>

From squid3 at treenet.co.nz  Sun Feb 15 00:02:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 15 Feb 2015 13:02:46 +1300
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
 for
In-Reply-To: <CAEXOXs1x+FG6m1bJdQxnS4wfxuZ7KpV-j6Ne_Hothh00iDH0vA@mail.gmail.com>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
 <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
 <201502121140.55913.Antony.Stone@squid.open.source.it>
 <CA+suCFgMGX0JiBzjNau+Fhg_baV7oUNxLUwneLKgWugZAYDgNw@mail.gmail.com>
 <CAEXOXs1x+FG6m1bJdQxnS4wfxuZ7KpV-j6Ne_Hothh00iDH0vA@mail.gmail.com>
Message-ID: <54DFE226.5060508@treenet.co.nz>

On 15/02/2015 12:19 p.m., naser sonbaty wrote:
> Hi,
> 
> thx for support.
> 
> I found second running squid on same box. I shut-down the second squid.
> But the problems are not gone......
> 
> Sorry I don't have access to the router pc :-( I can not get the rule ....
> 
> I have set up web browsers to use direct squid with 3129.
> But the result its same.

Your proxy is configued to receive browser traffic on port 3128, and
connections intercepted by the local machines NAT system on port 3129.
The two traffic modes MUST NOT be crossed over.

If it happens that the wrong type of traffic goes to a port this is the
result.

Amos



From naser.sonbaty at gmail.com  Sun Feb 15 00:21:43 2015
From: naser.sonbaty at gmail.com (naser sonbaty)
Date: Sun, 15 Feb 2015 01:21:43 +0100
Subject: [squid-users] Squid 3.5.1 intercept / Forwarding loop detected
	for
In-Reply-To: <54DFE226.5060508@treenet.co.nz>
References: <CAEXOXs0smChH0JjCrBYwCoOwZxgHczezo3UxTt50eJ8uS2+N9w@mail.gmail.com>
 <201502121058.12973.Antony.Stone@squid.open.source.it>
 <CAEXOXs1Wz8VEjWA4nKnEyVEerCpnwsJzdsQdapEt1X+-cTnZEg@mail.gmail.com>
 <201502121140.55913.Antony.Stone@squid.open.source.it>
 <CA+suCFgMGX0JiBzjNau+Fhg_baV7oUNxLUwneLKgWugZAYDgNw@mail.gmail.com>
 <CAEXOXs1x+FG6m1bJdQxnS4wfxuZ7KpV-j6Ne_Hothh00iDH0vA@mail.gmail.com>
 <54DFE226.5060508@treenet.co.nz>
Message-ID: <CAEXOXs0duiJNfh1j=wzPsfexOWoHBbZHT9vh4m-baZY9KrOZZA@mail.gmail.com>

Hi,

thx,

if I change this:
http_port 127.0.0.1:3128
http_port 192.168.15.2:3129 intercept

to this:
http_port 192.168.15.2:3129

then its working

On Sun, Feb 15, 2015 at 1:02 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 15/02/2015 12:19 p.m., naser sonbaty wrote:
> > Hi,
> >
> > thx for support.
> >
> > I found second running squid on same box. I shut-down the second squid.
> > But the problems are not gone......
> >
> > Sorry I don't have access to the router pc :-( I can not get the rule
> ....
> >
> > I have set up web browsers to use direct squid with 3129.
> > But the result its same.
>
> Your proxy is configued to receive browser traffic on port 3128, and
> connections intercepted by the local machines NAT system on port 3129.
> The two traffic modes MUST NOT be crossed over.
>
> If it happens that the wrong type of traffic goes to a port this is the
> result.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150215/37e075d3/attachment.htm>

From hack.back at hotmail.com  Sun Feb 15 18:32:51 2015
From: hack.back at hotmail.com (HackXBack)
Date: Sun, 15 Feb 2015 10:32:51 -0800 (PST)
Subject: [squid-users] assertion failed: comm.cc:769:
	"Comm::IsConnOpen(conn)"
Message-ID: <1424025171679-4669842.post@n4.nabble.com>

assertion failed: comm.cc:769: "Comm::IsConnOpen(conn)"

every few hours i got this error this squid restart automatically 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/assertion-failed-comm-cc-769-Comm-IsConnOpen-conn-tp4669842.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From shakirgil at yahoo.com  Sun Feb 15 19:41:55 2015
From: shakirgil at yahoo.com (Mohammad Shakir)
Date: Sun, 15 Feb 2015 19:41:55 +0000 (UTC)
Subject: [squid-users] squid error assertion failed: filemap.cc:72
Message-ID: <1695005425.3697142.1424029315973.JavaMail.yahoo@mail.yahoo.com>

We are using squid 3.4.9 on centos 64bit and getting following error.


assertion failed: filemap.cc:72: "capacity_ <= (1 << 24)"

In cache directory  swap.state file size is.


-rw-r-----  1 squid squid 1.2G Feb 16 00:15 swap.state

Should we upgrade to new version to resolve this issue ?



Squid Cache: Version 3.4.9
configure options:  '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/sbin' '--sbindir=/usr/sbin' '--sysconfdir=/etc/squid' '--datadir=/usr/share/squid' '--includedir=/usr/include' '--libdir=/usr/lib' '--libexecdir=/usr/lib/squid' '--localstatedir=/var' '--sharedstatedir=/usr/com' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--x-includes=/usr/include' '--x-libraries=/usr/lib' '--enable-storeio=aufs' '--enable-removal-policies=heap,lru' '--disable-icmp' '--disable-delay-pools' '--enable-useragent-log' '--enable-referer-log' '--disable-kill-parent-hack' '--enable-snmp' '--enable-cachemgr-hostname=localhost' '--enable-arp-acl' '--disable-htcp' '--disable-forw-via-db' '--enable-follow-x-forwarded-for' '--disable-cache-digests' '--disable-poll' '--enable-epoll' '--enable-linux-netfilter' '--disable-ident-lookups' '--enable-default-hostsfile=/etc/hosts' '--enable-http-violations' '--enable-gnuregex' '--enable-async-io=64' '--with-aufs-threads=64' '--with-pthreads' '--with-aio' '--enable-err-languages=English' '--disable-wccp' '--disable-wccpv2' '--disable-devpoll' '--with-large-files' '--enable-large-cache-files' '--with-maxfd=65536' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'target_alias=x86_64-redhat-linux-gnu' '--enable-ltdl-convenience' '--enable-ssl' '--disable-auth' '--disable-ipv6'


From squid3 at treenet.co.nz  Sun Feb 15 20:04:15 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 16 Feb 2015 09:04:15 +1300
Subject: [squid-users] squid error assertion failed: filemap.cc:72
In-Reply-To: <1695005425.3697142.1424029315973.JavaMail.yahoo@mail.yahoo.com>
References: <1695005425.3697142.1424029315973.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54E0FBBF.8070108@treenet.co.nz>

On 16/02/2015 8:41 a.m., Mohammad Shakir wrote:
> We are using squid 3.4.9 on centos 64bit and getting following error.
> 
> 
> assertion failed: filemap.cc:72: "capacity_ <= (1 << 24)"


This is http://bugs.squid-cache.org/show_bug.cgi?id=3566

The filemap is a 24-bit map value used to represent the on-disk file
names. This assertion means that you are trying to store greater than
2^24 files in one of your cache_dir.

> 
> In cache directory  swap.state file size is.
> 
> 
> -rw-r-----  1 squid squid 1.2G Feb 16 00:15 swap.state
> 
> Should we upgrade to new version to resolve this issue ?

The workaround for this is increasing the frequency of cache LRU garbage
collection, reducing its total size, and/or using the min-size/max-size
parameters to split the cache_dir into size range brackets so you never
end up with a GB sized cache storing under-1KB objects or a TB cache
storing under-100KB sized objects.

Upgrading to 3.5 series will allow you to store objects between 32Kb and
100KB in a Rock cache to avoid the TB size issues. But that is all.

Amos



From alanpalmer72 at yahoo.com  Sun Feb 15 21:36:30 2015
From: alanpalmer72 at yahoo.com (Alan Palmer)
Date: Sun, 15 Feb 2015 16:36:30 -0500
Subject: [squid-users] ssl proxy error: No valid signing SSL certificate
 configured for https_port [::]:3127
Message-ID: <54E1115E.3040804@yahoo.com>

I'm trying to get squid 3.4.11 on openbsd 5.6 to act as a transparent 
ssl proxy.

I've rebuilt squid with --enable-ssl-crtd, generated my own self signed 
cert (ala http://www.akadia.com/services/ssh_test_certificate.html) and 
have the following config lines:

https_port 3127 transparent ssl-bump generate-host-certificates=on 
dynamic_cert_mem_cache_size=4MB cert='/etc/squid/ssl_cert/my-cert.crt'
ssl_bump server-first all
always_direct allow all
sslproxy_flags DONT_VERIFY_PEER
sslcrtd_program /usr/local/libexec/squid/ssl_crtd -s 
/usr/local/squid/var/lib/ssl_db -M 4MB
sslcrtd_children 5

I've read all the notes, hints, email list archives, to not avail.
No matter what I do I get:

FATAL: No valid signing SSL certificate configured for https_port [::]:3127

I get the same error with the 3.4.6.p1 package from openbsd.org (sans 
ssl_crtd config lines)

ideas? solutions? help?


From eliezer at ngtech.co.il  Sun Feb 15 21:49:00 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 15 Feb 2015 23:49:00 +0200
Subject: [squid-users] ssl proxy error: No valid signing SSL certificate
 configured for https_port [::]:3127
In-Reply-To: <54E1115E.3040804@yahoo.com>
References: <54E1115E.3040804@yahoo.com>
Message-ID: <54E1144C.2040503@ngtech.co.il>

On 15/02/2015 23:36, Alan Palmer wrote:
> I'm trying to get squid 3.4.11 on openbsd 5.6 to act as a transparent
> ssl proxy.
>
> I've rebuilt squid with --enable-ssl-crtd, generated my own self signed
> cert (ala http://www.akadia.com/services/ssh_test_certificate.html) and
> have the following config lines:

Hey Alan,

What is the full output of "squid -v"?

I am unsure about the akadia tutorial.
Please take a look at:
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/SSLBUMP

It contains some hints on how to create the certificate and contains a 
snippet of squid configuration to make a basic ssl-bump work(the echo 
command code might not be right)

I am pretty sure the certificate you have created is not the right type 
for the task.

Eliezer



From james.d.beecham at gmail.com  Sun Feb 15 22:02:35 2015
From: james.d.beecham at gmail.com (James Beecham)
Date: Sun, 15 Feb 2015 14:02:35 -0800
Subject: [squid-users] Add header to SSL requests to my own domain using my
	domains certs
Message-ID: <CA+NB0u97zWq7YVmo7T+eC37wXXPUiiD31z8ZrD=+nEeEGe6cgg@mail.gmail.com>

Hello,

Thank you to everyone who works on this great project! I have been using
Squid as an intercept for a while now and am very happy.

I have a high level question regarding SSL_Bump.

My company recently switched to using SSL for our web services, which
requires me to make some changes to the way that we use Squid.

I have a need to place a header value into requests coming to our own
domain (ex. https://www.myhost.com) for proper usage. Before using SSL I
was using request_header_add without any issues and getting perfect
performance. Now with SSL I still need to get a header value into the
requests to our domain.

I do not wish to bump/inspect all traffic over 443, I only wish to add a
header to request to my own domain. Since I am the domain admin I have
access to the certs from the CA. I understand how acls work and am not
concerned about setting this up.

I would like to know what you all think about using our domains actual
certs (www.myhost.com) to bump only that domain and add the header field
that I need. Will this allow me to modify the header without the client
knowing or their browser telling them about man in the middle? My knowledge
of SSL/TLS is low but growing everyday.

Thank you for your attention and please ask more questions if my situation
is not clear.'

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150215/b6e86992/attachment.htm>

From yvoinov at gmail.com  Sun Feb 15 22:37:37 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 04:37:37 +0600
Subject: [squid-users] Add header to SSL requests to my own domain using
 my domains certs
In-Reply-To: <CA+NB0u97zWq7YVmo7T+eC37wXXPUiiD31z8ZrD=+nEeEGe6cgg@mail.gmail.com>
References: <CA+NB0u97zWq7YVmo7T+eC37wXXPUiiD31z8ZrD=+nEeEGe6cgg@mail.gmail.com>
Message-ID: <54E11FB1.8040702@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

16.02.15 4:02, James Beecham ?????:
> Hello,
> 
> Thank you to everyone who works on this great project! I have been
> using Squid as an intercept for a while now and am very happy.
> 
> I have a high level question regarding SSL_Bump.
> 
> My company recently switched to using SSL for our web services,
> which requires me to make some changes to the way that we use
> Squid.
> 
> I have a need to place a header value into requests coming to our
> own domain (ex. https://www.myhost.com) for proper usage. Before
> using SSL I was using request_header_add without any issues and
> getting perfect performance. Now with SSL I still need to get a
> header value into the requests to our domain.
> 
> I do not wish to bump/inspect all traffic over 443, I only wish to
> add a header to request to my own domain. Since I am the domain
> admin I have access to the certs from the CA. I understand how acls
> work and am not concerned about setting this up.
> 
> I would like to know what you all think about using our domains
> actual certs (www.myhost.com) to bump only that domain and add the
> header field that I need. Will this allow me to modify the header
> without the client knowing or their browser telling them about man
> in the middle? My knowledge of SSL/TLS is low but growing
> everyday.
> 
> Thank you for your attention and please ask more questions if my
> situation is not clear.'
> 
> James
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4R+xAAoJENNXIZxhPexGap0IAI8I9aimys3+1pdZAPWYtxDQ
N4Otv7Lz8rJx+TJGITgHbsvg5l09plilGLz2LmA05IkqpSOEtEGVQMUusx8sI/kH
G9fPlY0r1MD2IUs5nKD9HK/oqZ2FhUceJG+XLs1tKCsPgMLSmIiEzGg4oM2pZEzw
h3kH2b8hP7BHUWh2TtPkpjxVT37wFfJ+mX87M2F47Fz7Dc9149g/bugDo9yk4WjY
9Nx/zHahDLK4PCwgKySQZOHFyK0NNH52R6kBDNcILnUrvuCzp0yGbIxPCD2AuS4U
bMj4J+e+o8eqrwAw63/vVDtC2yoGUlYW6z5KuxbYZbBSTq4fJW2lk+5N5lmWmu0=
=lPPU
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Sun Feb 15 22:39:11 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 04:39:11 +0600
Subject: [squid-users] ssl proxy error: No valid signing SSL certificate
 configured for https_port [::]:3127
In-Reply-To: <54E1144C.2040503@ngtech.co.il>
References: <54E1115E.3040804@yahoo.com> <54E1144C.2040503@ngtech.co.il>
Message-ID: <54E1200F.70205@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

And here....

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

16.02.15 3:49, Eliezer Croitoru ?????:
> On 15/02/2015 23:36, Alan Palmer wrote:
>> I'm trying to get squid 3.4.11 on openbsd 5.6 to act as a
>> transparent ssl proxy.
>> 
>> I've rebuilt squid with --enable-ssl-crtd, generated my own self
>> signed cert (ala
>> http://www.akadia.com/services/ssh_test_certificate.html) and 
>> have the following config lines:
> 
> Hey Alan,
> 
> What is the full output of "squid -v"?
> 
> I am unsure about the akadia tutorial. Please take a look at: 
> http://wiki.squid-cache.org/EliezerCroitoru/Drafts/SSLBUMP
> 
> It contains some hints on how to create the certificate and
> contains a snippet of squid configuration to make a basic ssl-bump
> work(the echo command code might not be right)
> 
> I am pretty sure the certificate you have created is not the right
> type for the task.
> 
> Eliezer
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4SAPAAoJENNXIZxhPexGqzIIAIEth3UUr3+BNiSBQqX8/fch
ZjVwU3pLPV/qBnEBiMBVf87a90B+Kut4Y2ybzw+DfaX7PUvyD1GWoOYq49F2yQIN
pIiBm6kAJufKOJVSVQPpk7YglylHS8JNkoV4Ict52yB7R/26usxrWGS9pOXJkIiL
0iRFJojwPCZDjvxqaMEPMy6DNG1VFmyOdbcP2g4uFaJeNUfydM1usauhk2J5KVUn
yqB6YQdA5DarAEtj011PifLtxpkOtacDdQ/Vv3cRxxP7dgt7DLq5gec4LNFcvnvy
UYjRoKagvJHyqAa8wEzypIRVk1Rv46jh2Bv//i4UsFIV1nhJPJcD/Ny7vwTasqU=
=BlvH
-----END PGP SIGNATURE-----


From james.d.beecham at gmail.com  Sun Feb 15 22:40:52 2015
From: james.d.beecham at gmail.com (James Beecham)
Date: Sun, 15 Feb 2015 14:40:52 -0800
Subject: [squid-users] Add header to SSL requests to my own domain using
 my domains certs
In-Reply-To: <54E11FB1.8040702@gmail.com>
References: <CA+NB0u97zWq7YVmo7T+eC37wXXPUiiD31z8ZrD=+nEeEGe6cgg@mail.gmail.com>
 <54E11FB1.8040702@gmail.com>
Message-ID: <CA+NB0u9jxEN4WV3SvkSxdNuR=C8yyrD3=xctmL6Fhu-UhmrdXg@mail.gmail.com>

Hi Yuri,

Thank you.

Are these HTTPS CONNECT requests coming over port 80? If not would I need
to make a rule to forward 443 to another Squid port configured to ssl_bump?

James

On Sun, Feb 15, 2015 at 2:37 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
> 16.02.15 4:02, James Beecham ?????:
> > Hello,
> >
> > Thank you to everyone who works on this great project! I have been
> > using Squid as an intercept for a while now and am very happy.
> >
> > I have a high level question regarding SSL_Bump.
> >
> > My company recently switched to using SSL for our web services,
> > which requires me to make some changes to the way that we use
> > Squid.
> >
> > I have a need to place a header value into requests coming to our
> > own domain (ex. https://www.myhost.com) for proper usage. Before
> > using SSL I was using request_header_add without any issues and
> > getting perfect performance. Now with SSL I still need to get a
> > header value into the requests to our domain.
> >
> > I do not wish to bump/inspect all traffic over 443, I only wish to
> > add a header to request to my own domain. Since I am the domain
> > admin I have access to the certs from the CA. I understand how acls
> > work and am not concerned about setting this up.
> >
> > I would like to know what you all think about using our domains
> > actual certs (www.myhost.com) to bump only that domain and add the
> > header field that I need. Will this allow me to modify the header
> > without the client knowing or their browser telling them about man
> > in the middle? My knowledge of SSL/TLS is low but growing
> > everyday.
> >
> > Thank you for your attention and please ask more questions if my
> > situation is not clear.'
> >
> > James
> >
> >
> >
> > _______________________________________________ squid-users mailing
> > list squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU4R+xAAoJENNXIZxhPexGap0IAI8I9aimys3+1pdZAPWYtxDQ
> N4Otv7Lz8rJx+TJGITgHbsvg5l09plilGLz2LmA05IkqpSOEtEGVQMUusx8sI/kH
> G9fPlY0r1MD2IUs5nKD9HK/oqZ2FhUceJG+XLs1tKCsPgMLSmIiEzGg4oM2pZEzw
> h3kH2b8hP7BHUWh2TtPkpjxVT37wFfJ+mX87M2F47Fz7Dc9149g/bugDo9yk4WjY
> 9Nx/zHahDLK4PCwgKySQZOHFyK0NNH52R6kBDNcILnUrvuCzp0yGbIxPCD2AuS4U
> bMj4J+e+o8eqrwAw63/vVDtC2yoGUlYW6z5KuxbYZbBSTq4fJW2lk+5N5lmWmu0=
> =lPPU
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150215/98bf50a4/attachment.htm>

From yvoinov at gmail.com  Sun Feb 15 22:46:41 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 04:46:41 +0600
Subject: [squid-users] Add header to SSL requests to my own domain using
 my domains certs
In-Reply-To: <CA+NB0u9jxEN4WV3SvkSxdNuR=C8yyrD3=xctmL6Fhu-UhmrdXg@mail.gmail.com>
References: <CA+NB0u97zWq7YVmo7T+eC37wXXPUiiD31z8ZrD=+nEeEGe6cgg@mail.gmail.com>	<54E11FB1.8040702@gmail.com>
 <CA+NB0u9jxEN4WV3SvkSxdNuR=C8yyrD3=xctmL6Fhu-UhmrdXg@mail.gmail.com>
Message-ID: <54E121D1.8000101@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



16.02.15 4:40, James Beecham ?????:
> Hi Yuri,
> 
> Thank you.
> 
> Are these HTTPS CONNECT requests coming over port 80? If not would
> I need

It depends. In different configurations uses different ports. In
transparent interception mode your absolutely need separate ports for
HTTP/HTTPS. In forwarding mode you cah use one port, but with SSL
parameters.

Transparent interception Squid generates error in cache.log if HTTP
passes over HTTPS port and vice versa. This is a bit problem in
current used versions, but it promised to fix in a future release. ;)


> to make a rule to forward 443 to another Squid port configured to
> ssl_bump?
> 
> James
> 
> On Sun, Feb 15, 2015 at 2:37 PM, Yuri Voinov <yvoinov at gmail.com>
> wrote:
> 
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
>  16.02.15 4:02, James Beecham ?????:
>>>> Hello,
>>>> 
>>>> Thank you to everyone who works on this great project! I have
>>>> been using Squid as an intercept for a while now and am very
>>>> happy.
>>>> 
>>>> I have a high level question regarding SSL_Bump.
>>>> 
>>>> My company recently switched to using SSL for our web
>>>> services, which requires me to make some changes to the way
>>>> that we use Squid.
>>>> 
>>>> I have a need to place a header value into requests coming to
>>>> our own domain (ex. https://www.myhost.com) for proper usage.
>>>> Before using SSL I was using request_header_add without any
>>>> issues and getting perfect performance. Now with SSL I still
>>>> need to get a header value into the requests to our domain.
>>>> 
>>>> I do not wish to bump/inspect all traffic over 443, I only
>>>> wish to add a header to request to my own domain. Since I am
>>>> the domain admin I have access to the certs from the CA. I
>>>> understand how acls work and am not concerned about setting
>>>> this up.
>>>> 
>>>> I would like to know what you all think about using our
>>>> domains actual certs (www.myhost.com) to bump only that
>>>> domain and add the header field that I need. Will this allow
>>>> me to modify the header without the client knowing or their
>>>> browser telling them about man in the middle? My knowledge of
>>>> SSL/TLS is low but growing everyday.
>>>> 
>>>> Thank you for your attention and please ask more questions if
>>>> my situation is not clear.'
>>>> 
>>>> James
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________ squid-users
>>>> mailing list squid-users at lists.squid-cache.org 
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4SHRAAoJENNXIZxhPexGjcQH/AwTPjGd5OLW9yEz82AKPjkm
mXVvdZymFYjB63jH485jaSilgbZLMKbV7MoEPf1qy/AZ3UlhqxKwyneLh0a2WhgK
kzmKGzrc3O+KkNliGWKxRnnShEJHXQYf6YgO+vq7qsAjS/QIBd4yEkvw4Kmt2QTi
2ooRJiSRMjh+69jzKL4LopRJq+fGzdw9NgiRXU9/G3l8LJy0szINjyplHm08rZTq
9IiQumwJSdoSPFOUBP0/lcDaZo74QUEwhXv0+igST8Dki5wcT0Qu0GCL0faw2RN6
W912Qfe/pUtWCo+sVsro8kDQhGdvwGObICeH3GgeK98mQ3WkKOYvlhODQHbYYlk=
=4Gjy
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Mon Feb 16 00:45:08 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 16 Feb 2015 13:45:08 +1300
Subject: [squid-users] Add header to SSL requests to my own domain using
 my domains certs
In-Reply-To: <54E121D1.8000101@gmail.com>
References: <CA+NB0u97zWq7YVmo7T+eC37wXXPUiiD31z8ZrD=+nEeEGe6cgg@mail.gmail.com>	<54E11FB1.8040702@gmail.com>
 <CA+NB0u9jxEN4WV3SvkSxdNuR=C8yyrD3=xctmL6Fhu-UhmrdXg@mail.gmail.com>
 <54E121D1.8000101@gmail.com>
Message-ID: <54E13D94.2000205@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 16/02/2015 11:46 a.m., Yuri Voinov wrote:
> 
> 
> 16.02.15 4:40, James Beecham ?????:
>> Hi Yuri,
> 
>> Thank you.
> 
>> Are these HTTPS CONNECT requests coming over port 80? If not
>> would I need
> 
> It depends. In different configurations uses different ports. In 
> transparent interception mode your absolutely need separate ports
> for HTTP/HTTPS. In forwarding mode you cah use one port, but with
> SSL parameters.
> 

And James, since you are domain admin the question becomes why are you
not running a reverse-proxy "https_port 443" with your domain cert to
receive the HTTPS traffic and forward it to the origin servers?

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU4T2TAAoJELJo5wb/XPRjAmAIAK5HfCAwSMUCXIeFNIPzppBG
24i0loL2Bhg9z/J9ec0iENOEO4XV0LPkNQT2UmyRxO4HZis5Su3Hc8R50tG6mrPf
EdU1H+nTUTygGQkm3nK7OmfdbSy/kV6aXmLM4pToYwwV3j15GDlW0wA0DN9JZhIG
WIBfwb+fCcjD5FJq9HWdGajeWgT9yuT54ufqrRJyjnq2LQMW8q7kbxrr6ue9eZxZ
9Fsz1GnoneHO5nQ1BHbp/rTo+GCEfZLO+r87/6tCcYkYmtKsvP6kI7fCCSE1X0N6
bjUj1iya5Ec92PsPc2ubmemTBIL/P572nO15fKesxlSYWCsdkpsbA0bygiksbZI=
=ZEKG
-----END PGP SIGNATURE-----


From james.d.beecham at gmail.com  Mon Feb 16 02:38:49 2015
From: james.d.beecham at gmail.com (James Beecham)
Date: Sun, 15 Feb 2015 18:38:49 -0800
Subject: [squid-users] Add header to SSL requests to my own domain using
 my domains certs
In-Reply-To: <54E13D94.2000205@treenet.co.nz>
References: <CA+NB0u97zWq7YVmo7T+eC37wXXPUiiD31z8ZrD=+nEeEGe6cgg@mail.gmail.com>
 <54E11FB1.8040702@gmail.com>
 <CA+NB0u9jxEN4WV3SvkSxdNuR=C8yyrD3=xctmL6Fhu-UhmrdXg@mail.gmail.com>
 <54E121D1.8000101@gmail.com> <54E13D94.2000205@treenet.co.nz>
Message-ID: <CA+NB0u-y1k7UVNr1TDqXv3ACrBqsjcoteuW_2=w2+QRiaQFEFw@mail.gmail.com>

Hi Amos,

Thank you for your reply.

The information I need to apply to the header is client specific, ex their
internal ip address.

The issue I am facing is that the network that is hosting the web services
is different from the network that the clients are accessing it from. So my
Squid instances live at the client site and they access the web services
out of a data center.

I need to know the clients internal ip at the data center for a number of
reasons. Therefore if I am understanding your suggestion correctly the
reverse ssl proxy would not work as the squid reverse proxy needs to be on
the same internal network/vlan as the destination host to function?
http://wiki.squid-cache.org/ConfigExamples/Reverse/SslWithWildcardCertifiate

Essentially what I have is the clients internal ip at the client site,
which with HTTP only used to allow me the pack the internal ip into the
HTTP header via 'request_header_add'. Now, I still need to get the internal
ip into the HTTPS request so that the web services can operate as normal.
Whether the clients internal ip is in the header or apart of each request
(query param) doesnt really matter, just how can I get the internal ip to
the server without disrupting the normal browsing activity of our users?

Please let me know if I have misunderstood your suggestion about the
reverse proxy. FWIW we use nginx as a reverse proxy at the datacenter to
load balance and handle certain API endpoints.

Thanks,

James



On Sun, Feb 15, 2015 at 4:45 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 16/02/2015 11:46 a.m., Yuri Voinov wrote:
> >
> >
> > 16.02.15 4:40, James Beecham ?????:
> >> Hi Yuri,
> >
> >> Thank you.
> >
> >> Are these HTTPS CONNECT requests coming over port 80? If not
> >> would I need
> >
> > It depends. In different configurations uses different ports. In
> > transparent interception mode your absolutely need separate ports
> > for HTTP/HTTPS. In forwarding mode you cah use one port, but with
> > SSL parameters.
> >
>
> And James, since you are domain admin the question becomes why are you
> not running a reverse-proxy "https_port 443" with your domain cert to
> receive the HTTPS traffic and forward it to the origin servers?
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJU4T2TAAoJELJo5wb/XPRjAmAIAK5HfCAwSMUCXIeFNIPzppBG
> 24i0loL2Bhg9z/J9ec0iENOEO4XV0LPkNQT2UmyRxO4HZis5Su3Hc8R50tG6mrPf
> EdU1H+nTUTygGQkm3nK7OmfdbSy/kV6aXmLM4pToYwwV3j15GDlW0wA0DN9JZhIG
> WIBfwb+fCcjD5FJq9HWdGajeWgT9yuT54ufqrRJyjnq2LQMW8q7kbxrr6ue9eZxZ
> 9Fsz1GnoneHO5nQ1BHbp/rTo+GCEfZLO+r87/6tCcYkYmtKsvP6kI7fCCSE1X0N6
> bjUj1iya5Ec92PsPc2ubmemTBIL/P572nO15fKesxlSYWCsdkpsbA0bygiksbZI=
> =ZEKG
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150215/889530b2/attachment.htm>

From vin.krish25 at gmail.com  Mon Feb 16 04:17:34 2015
From: vin.krish25 at gmail.com (vin_krish)
Date: Sun, 15 Feb 2015 20:17:34 -0800 (PST)
Subject: [squid-users] syslog using squid-3.4.8
Message-ID: <1424060254349-4669854.post@n4.nabble.com>

Hi guys,

            I'm using squid-3.4.8 in my box running on Linux platform. I
want to syslog the access_log to remote server.
But I don't see any logs on remote server when I use 'NOTICE' priority in my
config file. Below is my config file.

http_port 3128 transparent
access_log syslog:local7.notice netsrc_acl_0 netdst_acl_0
access_log syslog:local7.notice netsrc_acl_1 netdst_acl_1
access_log none all

Below is my syslogd.conf:

local7.notice   @10.0.1.2

Please help me in this issue.

Regards,
krish



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/syslog-using-squid-3-4-8-tp4669854.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From brett.lymn at baesystems.com  Mon Feb 16 04:24:44 2015
From: brett.lymn at baesystems.com (Brett Lymn)
Date: Mon, 16 Feb 2015 14:54:44 +1030
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
	children?
In-Reply-To: <54DDB95E.5080200@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54DCF5BA.5010207@treenet.co.nz>
 <54DD050D.9020809@gmail.com> <54DD4678.7020701@treenet.co.nz>
 <54DDB95E.5080200@gmail.com>
Message-ID: <20150216042444.GF1219@baea.com.au>

On Fri, Feb 13, 2015 at 02:44:14PM +0600, Yuri Voinov wrote:
> 
> In addition, the operating system with a constant load of RAM in the 
> 90-95% is just on the edge of a swap or a kernel panic. For Solaris this 
> is not care - but it has a very specific kernel. Most of the other OS 
> just goes to swap or initiates OOM.
> 

No, 90-95% memory utilisation means the OS is effectively using the
resources it has available.  This is normal on an active machine,
particularly Solaris.  What memory is not being used for processes directly is
being used as file cache to speed accesses.  As long as your process
demands do not exceed physical RAM then all will be fine, the file cache
size will shrink and grow depending on process demands.

-- 
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

    BAE Systems Australia Limited - Australian Company Number 008 423 005
    BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846
    BAE Systems Australia Logistics Pty Limited - Australian Company Number 086 228 864

Our registered office is Evans Building, Taranaki Road, Edinburgh Parks,
Edinburgh, South Australia, 5111. If the identity of the sending company is
not clear from the content of this email please contact the sender.

This email and any attachments may contain confidential and legally
privileged information.  If you are not the intended recipient, do not copy or
disclose its content, but please reply to this email immediately and highlight
the error to the sender and then immediately delete the message.



From jkillimangalam at in.rm.com  Mon Feb 16 05:54:36 2015
From: jkillimangalam at in.rm.com (John Killimangalam Jacob)
Date: Mon, 16 Feb 2015 05:54:36 +0000
Subject: [squid-users] Error when using peek/splice/terminate with Squid
	3.5.1
Message-ID: <DBXPR04MB493572511458A97F114279B862E0@DBXPR04MB493.eurprd04.prod.outlook.com>

Hi All,

I am trying to configure an intercept proxy with peek/splice/terminate features in Squid 3.5.1 on CentOS 7 - 64 bit. I wanted to peak at steps 1 and step 2 and to decide on terminate on step 3 based on the SNI and server certificate values. It is working only for https://www.google.com, but lot of other ssl sites (likes of https://www.yahoo.com etc) are not getting loaded logging an " Error negotiating SSL on FD 36: error:140920E3:SSL routines:SSL3_GET_SERVER_HELLO:parse tlsext  "  in the cache.log (trying the same sites using openssl s_client command works). I was wondering if it has to do anything with my config or open ssl (version 1.0.1e) or anything else. The web sites are being accessed from a windows 7 workstation with IE 8 and Firefox 35.0.1 . Below is the squid.config section for peek and splice I am using.

acl step1 at_step  SslBump1
acl step2 at_step  SslBump2
acl step3 at_step  SslBump3


external_acl_type SSL_URL_Filter %SRC %ssl::>sni %ssl::<cert_subject </path/to/urlfilterscript>

acl URL_Allowed external SSL_URL_Filter


ssl_bump peek step1 all

ssl_bump peek step2 all

ssl_bump terminate step3 !URL_Allowed

ssl_bump splice step3 all

# Squid normally listens to port 3128
http_port 3128
http_port 3129 intercept
https_port 3130 intercept ssl-bump cert=/tmp/sslcertificates/server.cert.pem key=/tmp/sslcertificates/server.key.pem

Thanks in Advance,
John

Visit our Website at www.rmesi.co.in<http://www.rmesi.co.in>

This message is confidential and should not be copied or disclosed to anyone. If this email has come to you in error, please delete it, along with any attachments. Any views or opinions presented are only those of the author and not those of RMESI. RMESI accepts no liability for any loss or damage which may be caused by software viruses and it is your responsibility to ensure that this email and any attachments are free of viruses when you receive it. You may use and apply this email and the information contained in it for the intended purpose only and RMESI shall not be liable in any way in respect of use for any other purpose. In respect of all other matters, to the fullest extent permitted by applicable law, RMESI disclaims all responsibility and liability for the contents of this email (including any attachments). Please note that RMESI may intercept incoming and outgoing email communications.

RM Education Solutions India Pvt Ltd (CIN: U72200KL2003PTC015931) is a company registered in India with its registered office at B-5 Gayatri Building, Technopark Campus, Trivandrum, Kerala, 695 581.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150216/aa3ad62b/attachment.htm>

From luismiguelferreirasilva at gmail.com  Mon Feb 16 06:26:37 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Sun, 15 Feb 2015 23:26:37 -0700
Subject: [squid-users] Squid stopped logging to access.log
Message-ID: <CA+suCFjtCuVssafxdYTgAVcGzOn_ttaWaCrMWLdiZwjy8sWAUQ@mail.gmail.com>

Dear all,

As I was playing around with Squid and e-cap, I decided to shutdown squid,
clear the cache and the log files.

Now, when I start it, it seems to create both the access.log and cache.log
files, but it only writes to the cache.log file:
root at appliance:/var/log/squid3# ls -al
total 16
drwxr-xr-x  2 proxy proxy 4096 Feb 15 23:12 .
drwxr-xr-x 11 root  root  4096 Feb 15 06:25 ..
-rw-r--r--  1 proxy proxy    0 Feb 15 23:12 access.log
-rw-r--r--  1 proxy proxy 8046 Feb 15 23:13 cache.log
root at appliance:/var/log/squid3#

As far as I know, I've reverted ALL my changes to a known working state
(e.g. disabled e-cap altogether, the debug_options and the
request_header_access directives I had turned on earlier today), but I just
can't get squid to write to access.log.

Here's what I'm getting (this time with debug_options ALL, 2 , so we can
see a little more info on what is going on):

root at appliance:/var/log/squid3# rm *
root at appliance:/var/log/squid3# /etc/init.d/squid3 start
[ ok ] Starting Squid HTTP Proxy 3.x: squid3.
root at appliance:/var/log/squid3# ls -l
total 12
-rw-r----- 1 proxy proxy    0 Feb 15 23:25 access.log
-rw-r----- 1 proxy proxy 9002 Feb 15 23:25 cache.log
root at appliance:/var/log/squid3# cat cache.log
2015/02/15 23:25:39.890| main.cc(1424) SquidMain: Doing post-config
initialization

2015/02/15 23:25:39.890| main.cc(1426) SquidMain: running
RegisteredRunner::finalizeConfig
2015/02/15 23:25:39.891| main.cc(1427) SquidMain: running
RegisteredRunner::claimMemoryNeeds
2015/02/15 23:25:39.891| main.cc(1428) SquidMain: running
RegisteredRunner::useConfig
2015/02/15 23:25:39.930 kid1| main.cc(1424) SquidMain: Doing post-config
initialization

2015/02/15 23:25:39.930 kid1| main.cc(1426) SquidMain: running
RegisteredRunner::finalizeConfig
2015/02/15 23:25:39.930 kid1| main.cc(1427) SquidMain: running
RegisteredRunner::claimMemoryNeeds
2015/02/15 23:25:39.930 kid1| main.cc(1428) SquidMain: running
RegisteredRunner::useConfig
2015/02/15 23:25:39.930 kid1| Current Directory is /
2015/02/15 23:25:39.930 kid1| Starting Squid Cache version 3.5.1 for
x86_64-unknown-linux-gnu...
2015/02/15 23:25:39.930 kid1| Service Name: squid
2015/02/15 23:25:39.930 kid1| Process ID 11312
2015/02/15 23:25:39.930 kid1| Process Roles: worker
2015/02/15 23:25:39.930 kid1| With 65535 file descriptors available
2015/02/15 23:25:39.930 kid1| Initializing IP Cache...
2015/02/15 23:25:39.941 kid1| dns_internal.cc(1529) dnsInit: idnsInit:
attempt open DNS socket to: [::]
2015/02/15 23:25:39.941 kid1| dns_internal.cc(1538) dnsInit: idnsInit:
attempt open DNS socket to: 0.0.0.0
2015/02/15 23:25:39.941 kid1| DNS Socket created at [::], FD 6
2015/02/15 23:25:39.941 kid1| DNS Socket created at 0.0.0.0, FD 7
2015/02/15 23:25:39.941 kid1| Adding nameserver 8.8.8.8 from squid.conf
2015/02/15 23:25:39.941 kid1| helperOpenServers: Starting 5/5 'ssl_crtd'
processes
2015/02/15 23:25:39.963 kid1| Format.cc(64) parse: got definition '%>a/%>A
%un %>rm myip=%la myport=%lp'
2015/02/15 23:25:39.963 kid1| Format.cc(64) parse: got definition '%>a/%>A
%un %>rm myip=%la myport=%lp'
2015/02/15 23:25:39.963 kid1| Logfile: opening log
daemon:/var/log/squid3/access.log
2015/02/15 23:25:39.963 kid1| Logfile Daemon: opening log
/var/log/squid3/access.log
2015/02/15 23:25:40 kid1| Unlinkd pipe opened on FD 25
2015/02/15 23:25:40.227 kid1| store_digest.cc(490) storeDigestCalcCap:
storeDigestCalcCap: have: 0, want 161319 entries; limits: [1, 161319]
2015/02/15 23:25:40.227 kid1| CacheDigest.cc(49) cacheDigestInit:
cacheDigestInit: capacity: 161319 entries, bpe: 5; size: 100825 bytes
2015/02/15 23:25:40.227 kid1| Local cache digest enabled; rebuild/rewrite
every 3600/3600 sec
2015/02/15 23:25:40.227 kid1| Store logging disabled
2015/02/15 23:25:40.227 kid1| Swap maxSize 2097152 + 1048576 KB, estimated
241979 objects
2015/02/15 23:25:40.227 kid1| Target number of buckets: 12098
2015/02/15 23:25:40.227 kid1| Using 16384 Store buckets
2015/02/15 23:25:40.227 kid1| Max Mem  size: 1048576 KB
2015/02/15 23:25:40.227 kid1| Max Swap size: 2097152 KB
2015/02/15 23:25:40.228 kid1| ufs/UFSSwapLogParser.cc(96)
GetUFSSwapLogParser: Swap file version: 2
2015/02/15 23:25:40.228 kid1| Rebuilding storage in /var/spool/squid3
(clean log)
2015/02/15 23:25:40.228 kid1| Using Least Load store dir selection
2015/02/15 23:25:40.228 kid1| Current Directory is /
2015/02/15 23:25:40.228 kid1| Finished loading MIME types and icons.
2015/02/15 23:25:40.259 kid1| wccp.cc(112) wccpConnectionOpen: WCCPv1
disabled.
2015/02/15 23:25:40.259 kid1| wccp2.cc(960) wccp2ConnectionOpen: WCCPv2
Disabled. No IPv4 Router(s) configured.
2015/02/15 23:25:40.259 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall
clientListenerConnectionOpened constructed, this=0x30a4470 [call20]
2015/02/15 23:25:40.259 kid1| AsyncCall.cc(93) ScheduleCall:
StartListening.cc(59) will call
clientListenerConnectionOpened(local=[::]:3128 remote=[::] FD 28 flags=9,
err=0, HTTP Socket port=0x30a44d0) [call20]
2015/02/15 23:25:40.259 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall
clientListenerConnectionOpened constructed, this=0x30a47f0 [call22]
2015/02/15 23:25:40.260 kid1| AsyncCall.cc(93) ScheduleCall:
StartListening.cc(59) will call
clientListenerConnectionOpened(local=[::]:3129 remote=[::] FD 29 flags=41,
err=0, HTTP Socket port=0x30a4850) [call22]
2015/02/15 23:25:40.260 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall
clientListenerConnectionOpened constructed, this=0x30a4980 [call24]
2015/02/15 23:25:40.260 kid1| AsyncCall.cc(93) ScheduleCall:
StartListening.cc(59) will call
clientListenerConnectionOpened(local=[::]:3130 remote=[::] FD 30 flags=41,
err=0, HTTPS Socket port=0x30a49e0) [call24]
2015/02/15 23:25:40.260 kid1| HTCP Disabled.
2015/02/15 23:25:40.260 kid1| Squid plugin modules loaded: 0
2015/02/15 23:25:40.260 kid1| Adaptation support is on
2015/02/15 23:25:40.260 kid1| Config.cc(211) FinalizeEach: Initialized 1
message adaptation services
2015/02/15 23:25:40.260 kid1| Config.cc(211) FinalizeEach: Initialized 0
message adaptation service groups
2015/02/15 23:25:40.260 kid1| Config.cc(211) FinalizeEach: Initialized 1
message adaptation access rules
2015/02/15 23:25:40.260 kid1| AsyncCallQueue.cc(55) fireNext: entering
clientListenerConnectionOpened(local=[::]:3128 remote=[::] FD 28 flags=9,
err=0, HTTP Socket port=0x30a44d0)
2015/02/15 23:25:40.260 kid1| AsyncCall.cc(38) make: make call
clientListenerConnectionOpened [call20]
2015/02/15 23:25:40.260 kid1| Accepting HTTP Socket connections at
local=[::]:3128 remote=[::] FD 28 flags=9
2015/02/15 23:25:40.260 kid1| AsyncCallQueue.cc(57) fireNext: leaving
clientListenerConnectionOpened(local=[::]:3128 remote=[::] FD 28 flags=9,
err=0, HTTP Socket port=0x30a44d0)
2015/02/15 23:25:40.260 kid1| AsyncCallQueue.cc(55) fireNext: entering
clientListenerConnectionOpened(local=[::]:3129 remote=[::] FD 29 flags=41,
err=0, HTTP Socket port=0x30a4850)
2015/02/15 23:25:40.260 kid1| AsyncCall.cc(38) make: make call
clientListenerConnectionOpened [call22]
2015/02/15 23:25:40.260 kid1| Accepting NAT intercepted HTTP Socket
connections at local=[::]:3129 remote=[::] FD 29 flags=41
2015/02/15 23:25:40.260 kid1| AsyncCallQueue.cc(57) fireNext: leaving
clientListenerConnectionOpened(local=[::]:3129 remote=[::] FD 29 flags=41,
err=0, HTTP Socket port=0x30a4850)
2015/02/15 23:25:40.261 kid1| AsyncCallQueue.cc(55) fireNext: entering
clientListenerConnectionOpened(local=[::]:3130 remote=[::] FD 30 flags=41,
err=0, HTTPS Socket port=0x30a49e0)
2015/02/15 23:25:40.261 kid1| AsyncCall.cc(38) make: make call
clientListenerConnectionOpened [call24]
2015/02/15 23:25:40.261 kid1| Accepting NAT intercepted SSL bumped HTTPS
Socket connections at local=[::]:3130 remote=[::] FD 30 flags=41
2015/02/15 23:25:40.261 kid1| AsyncCallQueue.cc(57) fireNext: leaving
clientListenerConnectionOpened(local=[::]:3130 remote=[::] FD 30 flags=41,
err=0, HTTPS Socket port=0x30a49e0)
2015/02/15 23:25:40.261 kid1| Done reading /var/spool/squid3 swaplog (0
entries)
2015/02/15 23:25:40.261 kid1| Store rebuilding is 0.00% complete
2015/02/15 23:25:40.261 kid1| Finished rebuilding storage from disk.
2015/02/15 23:25:40.261 kid1|         0 Entries scanned
2015/02/15 23:25:40.261 kid1|         0 Invalid entries.
2015/02/15 23:25:40.261 kid1|         0 With invalid flags.
2015/02/15 23:25:40.261 kid1|         0 Objects loaded.
2015/02/15 23:25:40.261 kid1|         0 Objects expired.
2015/02/15 23:25:40.261 kid1|         0 Objects cancelled.
2015/02/15 23:25:40.261 kid1|         0 Duplicate URLs purged.
2015/02/15 23:25:40.261 kid1|         0 Swapfile clashes avoided.
2015/02/15 23:25:40.261 kid1|   Took 0.03 seconds (  0.00 objects/sec).
2015/02/15 23:25:40.261 kid1| Beginning Validation Procedure
2015/02/15 23:25:40.261 kid1| disk.cc(503) xrename: xrename: renaming
/var/spool/squid3/swap.state.new to /var/spool/squid3/swap.state
2015/02/15 23:25:40.261 kid1| store_rebuild.cc(96) storeCleanup: Seen: 51
entries
2015/02/15 23:25:40.261 kid1|   Completed Validation Procedure
2015/02/15 23:25:40.261 kid1|   Validated 0 Entries
2015/02/15 23:25:40.261 kid1|   store_swap_size = 0.00 KB
2015/02/15 23:25:40.261 kid1| store_digest.cc(283) storeDigestRebuildStart:
storeDigestRebuildStart: rebuild #1
2015/02/15 23:25:40.261 kid1| store_digest.cc(490) storeDigestCalcCap:
storeDigestCalcCap: have: 51, want 51 entries; limits: [1, 161319]
2015/02/15 23:25:40.261 kid1| store_digest.cc(512) storeDigestResize:
storeDigestResize: 161319 -> 51; change: 161268 (100%)
2015/02/15 23:25:40.261 kid1| store_digest.cc(519) storeDigestResize:
storeDigestResize: big change, resizing.
2015/02/15 23:25:40.262 kid1| CacheDigest.cc(49) cacheDigestInit:
cacheDigestInit: capacity: 51 entries, bpe: 5; size: 32 bytes
2015/02/15 23:25:40.262 kid1| store_digest.cc(363) storeDigestRewriteStart:
storeDigestRewrite: start rewrite #1
2015/02/15 23:25:40.262 kid1| store_digest.cc(377) storeDigestRewriteStart:
storeDigestRewriteStart: waiting for rebuild to finish.
2015/02/15 23:25:40.262 kid1| store_digest.cc(317)
storeDigestRebuildFinish: storeDigestRebuildFinish: done.
2015/02/15 23:25:40.262 kid1| store_digest.cc(418)
storeDigestRewriteFinish: storeDigestRewriteFinish: digest expires at
1424071540 (+3600)
2015/02/15 23:25:41 kid1| storeLateRelease: released 0 objects
root at appliance:/var/log/squid3# cat cache.log  | grep -i access
2015/02/15 23:25:39.963 kid1| Logfile: opening log
daemon:/var/log/squid3/access.log
2015/02/15 23:25:39.963 kid1| Logfile Daemon: opening log
/var/log/squid3/access.log
2015/02/15 23:25:40.260 kid1| Config.cc(211) FinalizeEach: Initialized 1
message adaptation access rules
root at appliance:/var/log/squid3# ls -al
total 20
drwxr-xr-x  2 proxy proxy 4096 Feb 15 23:25 .
drwxr-xr-x 11 root  root  4096 Feb 15 06:25 ..
-rw-r-----  1 proxy proxy    0 Feb 15 23:25 access.log
-rw-r-----  1 proxy proxy 9065 Feb 15 23:25 cache.log
root at appliance:/var/log/squid3#

Everything seems to be working fine, and traffic IS being routed through
squid. Its just that nothing gets logged to access.log...

Any idea on what might be causing this?

Thank you,
Luis
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150215/05effc1e/attachment.htm>

From Silamael at coronamundi.de  Mon Feb 16 08:08:14 2015
From: Silamael at coronamundi.de (Silamael)
Date: Mon, 16 Feb 2015 09:08:14 +0100
Subject: [squid-users] Squid Memory Leak with certain FTP requests?
In-Reply-To: <54DC6990.3000307@treenet.co.nz>
References: <54DB28C7.8000906@coronamundi.de> <54DB2A99.4000009@gmail.com>
 <54DB424D.8080501@coronamundi.de> <54DB542D.9060303@coronamundi.de>
 <54DB551E.3070705@gmail.com> <54DB71C3.5060301@coronamundi.de>
 <54DBB5F0.9070809@treenet.co.nz> <54DC5E34.4090505@coronamundi.de>
 <54DC6990.3000307@treenet.co.nz>
Message-ID: <54E1A56E.2040505@coronamundi.de>

On 02/12/2015 09:51 AM, Amos Jeffries wrote:
> On 12/02/2015 9:03 p.m., Silamael Darkomen wrote:
>>
>> I will file a proper bug report with debug output and such when I'm back
>> at work next monday.
>> Any idea what's wrong here? For me it seems that the index.html Squid is
>> generating for FTP requests with just an directory is not freed internally.
> 
> I think you are right, but havent looked into it yet.
> 
> Amos

Added new bug bugs.squid-cache.org/show_bug.cgi?id=4139

If you need more information, feel free to contact me.

Cheers,
Matthias


From luismiguelferreirasilva at gmail.com  Mon Feb 16 08:30:31 2015
From: luismiguelferreirasilva at gmail.com (Luis Miguel Silva)
Date: Mon, 16 Feb 2015 01:30:31 -0700
Subject: [squid-users] Squid stopped logging to access.log
In-Reply-To: <CA+suCFjtCuVssafxdYTgAVcGzOn_ttaWaCrMWLdiZwjy8sWAUQ@mail.gmail.com>
References: <CA+suCFjtCuVssafxdYTgAVcGzOn_ttaWaCrMWLdiZwjy8sWAUQ@mail.gmail.com>
Message-ID: <CA+suCFgpbMWcV=W=DK66RFR8qvpQJ6U-ReyO2rDVqiEtZz0uug@mail.gmail.com>

Figured out the problem (I had another squid on the network that was
intercepting my requests)...sorry about that!

Luis

On Sun, Feb 15, 2015 at 11:26 PM, Luis Miguel Silva <
luismiguelferreirasilva at gmail.com> wrote:

> Dear all,
>
> As I was playing around with Squid and e-cap, I decided to shutdown squid,
> clear the cache and the log files.
>
> Now, when I start it, it seems to create both the access.log and cache.log
> files, but it only writes to the cache.log file:
> root at appliance:/var/log/squid3# ls -al
> total 16
> drwxr-xr-x  2 proxy proxy 4096 Feb 15 23:12 .
> drwxr-xr-x 11 root  root  4096 Feb 15 06:25 ..
> -rw-r--r--  1 proxy proxy    0 Feb 15 23:12 access.log
> -rw-r--r--  1 proxy proxy 8046 Feb 15 23:13 cache.log
> root at appliance:/var/log/squid3#
>
> As far as I know, I've reverted ALL my changes to a known working state
> (e.g. disabled e-cap altogether, the debug_options and the
> request_header_access directives I had turned on earlier today), but I just
> can't get squid to write to access.log.
>
> Here's what I'm getting (this time with debug_options ALL, 2 , so we can
> see a little more info on what is going on):
>
> root at appliance:/var/log/squid3# rm *
> root at appliance:/var/log/squid3# /etc/init.d/squid3 start
> [ ok ] Starting Squid HTTP Proxy 3.x: squid3.
> root at appliance:/var/log/squid3# ls -l
> total 12
> -rw-r----- 1 proxy proxy    0 Feb 15 23:25 access.log
> -rw-r----- 1 proxy proxy 9002 Feb 15 23:25 cache.log
> root at appliance:/var/log/squid3# cat cache.log
> 2015/02/15 23:25:39.890| main.cc(1424) SquidMain: Doing post-config
> initialization
>
> 2015/02/15 23:25:39.890| main.cc(1426) SquidMain: running
> RegisteredRunner::finalizeConfig
> 2015/02/15 23:25:39.891| main.cc(1427) SquidMain: running
> RegisteredRunner::claimMemoryNeeds
> 2015/02/15 23:25:39.891| main.cc(1428) SquidMain: running
> RegisteredRunner::useConfig
> 2015/02/15 23:25:39.930 kid1| main.cc(1424) SquidMain: Doing post-config
> initialization
>
> 2015/02/15 23:25:39.930 kid1| main.cc(1426) SquidMain: running
> RegisteredRunner::finalizeConfig
> 2015/02/15 23:25:39.930 kid1| main.cc(1427) SquidMain: running
> RegisteredRunner::claimMemoryNeeds
> 2015/02/15 23:25:39.930 kid1| main.cc(1428) SquidMain: running
> RegisteredRunner::useConfig
> 2015/02/15 23:25:39.930 kid1| Current Directory is /
> 2015/02/15 23:25:39.930 kid1| Starting Squid Cache version 3.5.1 for
> x86_64-unknown-linux-gnu...
> 2015/02/15 23:25:39.930 kid1| Service Name: squid
> 2015/02/15 23:25:39.930 kid1| Process ID 11312
> 2015/02/15 23:25:39.930 kid1| Process Roles: worker
> 2015/02/15 23:25:39.930 kid1| With 65535 file descriptors available
> 2015/02/15 23:25:39.930 kid1| Initializing IP Cache...
> 2015/02/15 23:25:39.941 kid1| dns_internal.cc(1529) dnsInit: idnsInit:
> attempt open DNS socket to: [::]
> 2015/02/15 23:25:39.941 kid1| dns_internal.cc(1538) dnsInit: idnsInit:
> attempt open DNS socket to: 0.0.0.0
> 2015/02/15 23:25:39.941 kid1| DNS Socket created at [::], FD 6
> 2015/02/15 23:25:39.941 kid1| DNS Socket created at 0.0.0.0, FD 7
> 2015/02/15 23:25:39.941 kid1| Adding nameserver 8.8.8.8 from squid.conf
> 2015/02/15 23:25:39.941 kid1| helperOpenServers: Starting 5/5 'ssl_crtd'
> processes
> 2015/02/15 23:25:39.963 kid1| Format.cc(64) parse: got definition '%>a/%>A
> %un %>rm myip=%la myport=%lp'
> 2015/02/15 23:25:39.963 kid1| Format.cc(64) parse: got definition '%>a/%>A
> %un %>rm myip=%la myport=%lp'
> 2015/02/15 23:25:39.963 kid1| Logfile: opening log
> daemon:/var/log/squid3/access.log
> 2015/02/15 23:25:39.963 kid1| Logfile Daemon: opening log
> /var/log/squid3/access.log
> 2015/02/15 23:25:40 kid1| Unlinkd pipe opened on FD 25
> 2015/02/15 23:25:40.227 kid1| store_digest.cc(490) storeDigestCalcCap:
> storeDigestCalcCap: have: 0, want 161319 entries; limits: [1, 161319]
> 2015/02/15 23:25:40.227 kid1| CacheDigest.cc(49) cacheDigestInit:
> cacheDigestInit: capacity: 161319 entries, bpe: 5; size: 100825 bytes
> 2015/02/15 23:25:40.227 kid1| Local cache digest enabled; rebuild/rewrite
> every 3600/3600 sec
> 2015/02/15 23:25:40.227 kid1| Store logging disabled
> 2015/02/15 23:25:40.227 kid1| Swap maxSize 2097152 + 1048576 KB, estimated
> 241979 objects
> 2015/02/15 23:25:40.227 kid1| Target number of buckets: 12098
> 2015/02/15 23:25:40.227 kid1| Using 16384 Store buckets
> 2015/02/15 23:25:40.227 kid1| Max Mem  size: 1048576 KB
> 2015/02/15 23:25:40.227 kid1| Max Swap size: 2097152 KB
> 2015/02/15 23:25:40.228 kid1| ufs/UFSSwapLogParser.cc(96)
> GetUFSSwapLogParser: Swap file version: 2
> 2015/02/15 23:25:40.228 kid1| Rebuilding storage in /var/spool/squid3
> (clean log)
> 2015/02/15 23:25:40.228 kid1| Using Least Load store dir selection
> 2015/02/15 23:25:40.228 kid1| Current Directory is /
> 2015/02/15 23:25:40.228 kid1| Finished loading MIME types and icons.
> 2015/02/15 23:25:40.259 kid1| wccp.cc(112) wccpConnectionOpen: WCCPv1
> disabled.
> 2015/02/15 23:25:40.259 kid1| wccp2.cc(960) wccp2ConnectionOpen: WCCPv2
> Disabled. No IPv4 Router(s) configured.
> 2015/02/15 23:25:40.259 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall
> clientListenerConnectionOpened constructed, this=0x30a4470 [call20]
> 2015/02/15 23:25:40.259 kid1| AsyncCall.cc(93) ScheduleCall:
> StartListening.cc(59) will call
> clientListenerConnectionOpened(local=[::]:3128 remote=[::] FD 28 flags=9,
> err=0, HTTP Socket port=0x30a44d0) [call20]
> 2015/02/15 23:25:40.259 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall
> clientListenerConnectionOpened constructed, this=0x30a47f0 [call22]
> 2015/02/15 23:25:40.260 kid1| AsyncCall.cc(93) ScheduleCall:
> StartListening.cc(59) will call
> clientListenerConnectionOpened(local=[::]:3129 remote=[::] FD 29 flags=41,
> err=0, HTTP Socket port=0x30a4850) [call22]
> 2015/02/15 23:25:40.260 kid1| AsyncCall.cc(26) AsyncCall: The AsyncCall
> clientListenerConnectionOpened constructed, this=0x30a4980 [call24]
> 2015/02/15 23:25:40.260 kid1| AsyncCall.cc(93) ScheduleCall:
> StartListening.cc(59) will call
> clientListenerConnectionOpened(local=[::]:3130 remote=[::] FD 30 flags=41,
> err=0, HTTPS Socket port=0x30a49e0) [call24]
> 2015/02/15 23:25:40.260 kid1| HTCP Disabled.
> 2015/02/15 23:25:40.260 kid1| Squid plugin modules loaded: 0
> 2015/02/15 23:25:40.260 kid1| Adaptation support is on
> 2015/02/15 23:25:40.260 kid1| Config.cc(211) FinalizeEach: Initialized 1
> message adaptation services
> 2015/02/15 23:25:40.260 kid1| Config.cc(211) FinalizeEach: Initialized 0
> message adaptation service groups
> 2015/02/15 23:25:40.260 kid1| Config.cc(211) FinalizeEach: Initialized 1
> message adaptation access rules
> 2015/02/15 23:25:40.260 kid1| AsyncCallQueue.cc(55) fireNext: entering
> clientListenerConnectionOpened(local=[::]:3128 remote=[::] FD 28 flags=9,
> err=0, HTTP Socket port=0x30a44d0)
> 2015/02/15 23:25:40.260 kid1| AsyncCall.cc(38) make: make call
> clientListenerConnectionOpened [call20]
> 2015/02/15 23:25:40.260 kid1| Accepting HTTP Socket connections at
> local=[::]:3128 remote=[::] FD 28 flags=9
> 2015/02/15 23:25:40.260 kid1| AsyncCallQueue.cc(57) fireNext: leaving
> clientListenerConnectionOpened(local=[::]:3128 remote=[::] FD 28 flags=9,
> err=0, HTTP Socket port=0x30a44d0)
> 2015/02/15 23:25:40.260 kid1| AsyncCallQueue.cc(55) fireNext: entering
> clientListenerConnectionOpened(local=[::]:3129 remote=[::] FD 29 flags=41,
> err=0, HTTP Socket port=0x30a4850)
> 2015/02/15 23:25:40.260 kid1| AsyncCall.cc(38) make: make call
> clientListenerConnectionOpened [call22]
> 2015/02/15 23:25:40.260 kid1| Accepting NAT intercepted HTTP Socket
> connections at local=[::]:3129 remote=[::] FD 29 flags=41
> 2015/02/15 23:25:40.260 kid1| AsyncCallQueue.cc(57) fireNext: leaving
> clientListenerConnectionOpened(local=[::]:3129 remote=[::] FD 29 flags=41,
> err=0, HTTP Socket port=0x30a4850)
> 2015/02/15 23:25:40.261 kid1| AsyncCallQueue.cc(55) fireNext: entering
> clientListenerConnectionOpened(local=[::]:3130 remote=[::] FD 30 flags=41,
> err=0, HTTPS Socket port=0x30a49e0)
> 2015/02/15 23:25:40.261 kid1| AsyncCall.cc(38) make: make call
> clientListenerConnectionOpened [call24]
> 2015/02/15 23:25:40.261 kid1| Accepting NAT intercepted SSL bumped HTTPS
> Socket connections at local=[::]:3130 remote=[::] FD 30 flags=41
> 2015/02/15 23:25:40.261 kid1| AsyncCallQueue.cc(57) fireNext: leaving
> clientListenerConnectionOpened(local=[::]:3130 remote=[::] FD 30 flags=41,
> err=0, HTTPS Socket port=0x30a49e0)
> 2015/02/15 23:25:40.261 kid1| Done reading /var/spool/squid3 swaplog (0
> entries)
> 2015/02/15 23:25:40.261 kid1| Store rebuilding is 0.00% complete
> 2015/02/15 23:25:40.261 kid1| Finished rebuilding storage from disk.
> 2015/02/15 23:25:40.261 kid1|         0 Entries scanned
> 2015/02/15 23:25:40.261 kid1|         0 Invalid entries.
> 2015/02/15 23:25:40.261 kid1|         0 With invalid flags.
> 2015/02/15 23:25:40.261 kid1|         0 Objects loaded.
> 2015/02/15 23:25:40.261 kid1|         0 Objects expired.
> 2015/02/15 23:25:40.261 kid1|         0 Objects cancelled.
> 2015/02/15 23:25:40.261 kid1|         0 Duplicate URLs purged.
> 2015/02/15 23:25:40.261 kid1|         0 Swapfile clashes avoided.
> 2015/02/15 23:25:40.261 kid1|   Took 0.03 seconds (  0.00 objects/sec).
> 2015/02/15 23:25:40.261 kid1| Beginning Validation Procedure
> 2015/02/15 23:25:40.261 kid1| disk.cc(503) xrename: xrename: renaming
> /var/spool/squid3/swap.state.new to /var/spool/squid3/swap.state
> 2015/02/15 23:25:40.261 kid1| store_rebuild.cc(96) storeCleanup: Seen: 51
> entries
> 2015/02/15 23:25:40.261 kid1|   Completed Validation Procedure
> 2015/02/15 23:25:40.261 kid1|   Validated 0 Entries
> 2015/02/15 23:25:40.261 kid1|   store_swap_size = 0.00 KB
> 2015/02/15 23:25:40.261 kid1| store_digest.cc(283)
> storeDigestRebuildStart: storeDigestRebuildStart: rebuild #1
> 2015/02/15 23:25:40.261 kid1| store_digest.cc(490) storeDigestCalcCap:
> storeDigestCalcCap: have: 51, want 51 entries; limits: [1, 161319]
> 2015/02/15 23:25:40.261 kid1| store_digest.cc(512) storeDigestResize:
> storeDigestResize: 161319 -> 51; change: 161268 (100%)
> 2015/02/15 23:25:40.261 kid1| store_digest.cc(519) storeDigestResize:
> storeDigestResize: big change, resizing.
> 2015/02/15 23:25:40.262 kid1| CacheDigest.cc(49) cacheDigestInit:
> cacheDigestInit: capacity: 51 entries, bpe: 5; size: 32 bytes
> 2015/02/15 23:25:40.262 kid1| store_digest.cc(363)
> storeDigestRewriteStart: storeDigestRewrite: start rewrite #1
> 2015/02/15 23:25:40.262 kid1| store_digest.cc(377)
> storeDigestRewriteStart: storeDigestRewriteStart: waiting for rebuild to
> finish.
> 2015/02/15 23:25:40.262 kid1| store_digest.cc(317)
> storeDigestRebuildFinish: storeDigestRebuildFinish: done.
> 2015/02/15 23:25:40.262 kid1| store_digest.cc(418)
> storeDigestRewriteFinish: storeDigestRewriteFinish: digest expires at
> 1424071540 (+3600)
> 2015/02/15 23:25:41 kid1| storeLateRelease: released 0 objects
> root at appliance:/var/log/squid3# cat cache.log  | grep -i access
> 2015/02/15 23:25:39.963 kid1| Logfile: opening log
> daemon:/var/log/squid3/access.log
> 2015/02/15 23:25:39.963 kid1| Logfile Daemon: opening log
> /var/log/squid3/access.log
> 2015/02/15 23:25:40.260 kid1| Config.cc(211) FinalizeEach: Initialized 1
> message adaptation access rules
> root at appliance:/var/log/squid3# ls -al
> total 20
> drwxr-xr-x  2 proxy proxy 4096 Feb 15 23:25 .
> drwxr-xr-x 11 root  root  4096 Feb 15 06:25 ..
> -rw-r-----  1 proxy proxy    0 Feb 15 23:25 access.log
> -rw-r-----  1 proxy proxy 9065 Feb 15 23:25 cache.log
> root at appliance:/var/log/squid3#
>
> Everything seems to be working fine, and traffic IS being routed through
> squid. Its just that nothing gets logged to access.log...
>
> Any idea on what might be causing this?
>
> Thank you,
> Luis
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150216/9e175a87/attachment.htm>

From sis at open.ch  Mon Feb 16 09:50:33 2015
From: sis at open.ch (=?iso-8859-1?Q?Simon_St=E4heli?=)
Date: Mon, 16 Feb 2015 10:50:33 +0100
Subject: [squid-users] benefits
	ofusingext_kerberos_ldap_group_aclinstead of ext_ldap_group_acl
In-Reply-To: <mbnmv8$sdd$1@ger.gmane.org>
References: <mailman.42287.1423690543.1833.squid-users@lists.squid-cache.org>
 <A77FDA65-6F38-4C4F-A323-C1B749878B5A@open.ch>
 <54DCDBCD.5070909@treenet.co.nz>
 <3BFE59DF-A379-49E6-B177-D4A86DE7678D@open.ch> <mbnmv8$sdd$1@ger.gmane.org>
Message-ID: <EE58FC57-6B97-4DE6-9FDF-2881209A5AB3@open.ch>


On 14.02.2015, at 15:43, Markus Moeller <huaraz at moeller.plus.com> wrote:

>> 
>> On 12.02.2015, at 17:58, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> 
>>> On 13/02/2015 5:41 a.m., Simon St?heli wrote:
>>>> 
>>>> hmh, HAVE_KRB5 seems not to be set in include/autoconf.h
>>>> 
>>>> What is the correct way to provide squid the path to the kerberos header files?
>>>> 
>>>> ./configure ?help doesn?t show a useful option as --with-krb5-config= seems not to be the right option.
>>> 
>>> If you are using Squid-3.4 or older versions where that option exists,
>>> you need to insted use CXXFLAGS to set the -I (library headers) and -L
>>> (library binary) locations.
>>> Something like:
>>> ./configure CXXFLAGS="-I/path/to/include -L/path/to/lib" ?
>> 
>> 
>> Thx for the hint! Tried ./configure CXXFLAGS="-I/opt/krb5/include -L/opt/krb5/lib" --prefix=/opt/squid --sysconfdir=/opt/squid/etc --enable-auth --enable-auth-negotiate="kerberos" --enable-external-acl-helpers=?kerberos_ldap_group? but without success. The /opt/krb5/ paths have been set in the Makefile, but HAVE_KRB5 is still no defined. Anything else to do here? (used Squid-3.4.11)
>> 
>> 
>>> 
>>> 
>>> Squid-3.5 and later have per-library ./configure options. In the case of
>>> Heimdal use --with-heimdal-krb5=PATH
>> 
>> 
>> tried it with Squid-3.5 and --with-heimdal-krb5=PATH and seems to work until make tries to compile kerberos_ldap_group
>> 
>> make[2]: Entering directory `/usr/src/packages/src/squid-3.5.1/helpers/external_acl/kerberos_ldap_group'
>> g++ -DHAVE_CONFIG_H   -I../../.. -I../../../include -I../../../lib -I../../../src -I../../../include  -I/opt/krb5/include  -I/opt/krb5/include   -I.  -Wall  -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -m64 -I/opt/krb5/include   -I/opt/krb5/include -L/opt/krb5/lib -march=native -MT support_krb5.o -MD -MP -MF .deps/support_krb5.Tpo -c -o support_krb5.o support_krb5.cc
>> cc1plus: warnings being treated as errors
>> support_krb5.cc: In function 'int krb5_create_cache(char*)':
>> support_krb5.cc:89:9: error: 'const char* krb5_get_err_text(krb5_context_data*, krb5_error_code)' is deprecated (declared at /opt/krb5/include/krb5-protos.h:2089)
>> ...
>> make[2]: *** [support_krb5.o] Error 1
>> make[2]: Leaving directory `/usr/src/packages/src/OSAGsquid-sis/squid-3.5.1/helpers/external_acl/kerberos_ldap_group?
>> 
>> my Heimdal Kerberos (Heimdal 1.3.3) libs seemed no to be compatible with kerberos_ldap_group?!
>> 
>> 
> 
> I am a bit surprised as I did not see this when testing on freebsd with heimdal.   I update my  trunk version at https://code.launchpad.net/~huaraz/squid/kerberos-updates. Can you test with that and if OK I will ask to include the updates.
> 


Your trunk version works perfectly. Thank you very much Markus!


>>> 
>>> 
>>> Amos
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> Markus 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150216/0c78b9c2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4030 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150216/0c78b9c2/attachment.bin>

From ahmed.zaeem at netstream.ps  Mon Feb 16 22:54:38 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Mon, 16 Feb 2015 14:54:38 -0800
Subject: [squid-users] cache peer load balancing round robin problem
Message-ID: <000a01d04a3b$8c8ad8e0$a5a08aa0$@netstream.ps>

Hi , 

I have many account from same provider and I would like to use those
accounts as round robin and each request has different IP as possible

 

The issue is , I open whatismyipaddress.com

 

for  some freshesh I can see my ip is rotating  but after about 1 minute I
see my ip is stuck on same ip and not rotating .

 

Im wondering wt I need to modify the config below so that the round robin
keep working and each time change the ip :

 

cache_peer  vvvv  parent 22225 0 no-query round-robin name=1 no-digest
no-tproxy proxy-only login=xxxxx

cache_peer  vvv  parent 22225 0 no-query round-robin name=2  no-digest
no-tproxy proxy-only login=xxx

cache_peer  vvv  parent 22225 0 no-query round-robin  name=3 no-digest
no-tproxy proxy-only login=xxx

cache_peer  vvv  parent 22225 0 no-query round-robin name=4  no-digest
no-tproxy proxy-only login=xxx

cache_peer  vvvv  parent 22225 0 no-query round-robin  name=5 no-digest
no-tproxy proxy-only login=xxx

 

 

 

 

 

cheers

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150216/5e48d7a1/attachment.htm>

From eliezer at ngtech.co.il  Mon Feb 16 13:13:54 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 15:13:54 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54DCEA80.2090204@gmail.com>
References: <54DCEA80.2090204@gmail.com>
Message-ID: <54E1ED12.8040606@ngtech.co.il>

Hey Yuri,

There are couple sides and side-effects to the issue you describe.
If it's OK with you I will for a sec look aside squid and the helpers 
code to another issue in Computer Science.

Let say we are running some server\software which it's purpose is to 
calculate the distance from point X to Y for a user.(A real world 
existing software which was written for DOS)
Since this piece of software size is about 50kB the user never 
experienced any issues with this particular software.
The issues came in when the user needed to run some complex calculations 
on a big list of points from a map.
 From what I have seen in the past a 133Mhz CPU should take the load, 
and indeed did not had any issues working with a big set of points what 
so ever was thrown at it.
The main complexity with this piece of software was when the 
calculations needed to be more complex and turned from X to Y to "from X 
to Y considering A B C D E F G H I".
Then the CPU got hogged a bit and there for the calculation took a bit 
longer then expected by the user.
Just as a side note this DOS system didn't had any SWAP at all.
This software is still in use since about 198x until these days with no 
SWAP at all while the calculations are being made daily by lots of users 
around my country.
 From Computer Science point of view this piece of software is one of 
the most efficient ever existed on earth and while it was written for 
DOS it is still efficient enough to support many other systems around 
the world.

Wouldn't any developer want to write a code in this level?? I believe 
and know that any developer strives to write a software that will use 
the available system resources efficiently.
But for any developer there is a point which he sees how his knowledge 
alone might not be enough to make a simple piece of software run as 
smooth and as efficient as this simple DOS software.
I have never asked the creator of this DOS program how much efforts it 
took from him and his companions to write such a great piece of ART 
which is one of a kind, it was not because he is dead or something 
similar but since I understand it's a complex task which I am not trying 
to mimic.

And back to squidguard, I myself have tried to understand why it uses so 
much ram and other resources which should have not being occupied at all.
Eventually I have written my own version which is a mimic for squidguard 
basic filtering logic.
I have seen this behavior you do see and I have couple of times tried to 
at least make something better then it is now.
The task was not simple but my idea after lots of time of thinking was 
to separate most of the logic outside of the url_rewrite interface.

I would not just try to solve the issue as "60 processes Absolutely 
idle", this might not be the issue in hands at all!
This conclusion can divert you from the real issue in this situation.

If you are up to the task to share(publicly is not a must) a top 
snapshot of the machine at midnight while you see the issue I will 
gladly be more then happy to try and understand the issue in hands.
I am pretty sure that the command "top -n1 -b" should work in any unix 
system I have seen until today.

Do you have access to this squid machine cache manager interface?

Eliezer

On 12/02/2015 20:01, Yuri Voinov wrote:
> Hi gents,
>
> subj.
>
> And, of course - question. How to do that? I've don't seen this, if it
> exists.
>
> For example, for this config stub:
>
> url_rewrite_program /usr/local/bin/squidGuard -c
> /usr/local/squidGuard/squidGuard.conf
> url_rewrite_children 100 startup=0 idle=1 concurrency=0
>
> After daily activity, at midnight, still remain near 60 processes.
> Absolutely idle.
>
> So, why?
>
> WBR, Yuri




From yvoinov at gmail.com  Mon Feb 16 13:17:01 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 19:17:01 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E1ED12.8040606@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
Message-ID: <54E1EDCD.3040703@gmail.com>

root @ cthulhu / # top -n1 -b
top: illegal option -- 1
Top version 3.7
Usage: top [-ISTabcinqu] [-d x] [-s x] [-o field] [-U username] [number]
root @ cthulhu / # top -n -b
last pid:  7353;  load avg:  0.16,  0.14,  0.13;  up 7+20:05:37        
19:16:08
72 processes: 71 sleeping, 1 on cpu
CPU states: 99.8% idle,  0.0% user,  0.3% kernel,  0.0% iowait, 0.0% swap
Kernel: 826 ctxsw, 3 trap, 907 intr, 890 syscall, 3 flt
Memory: 4095M phys mem, 146M free mem, 8192M total swap, 8192M free swap

    PID USERNAME LWP PRI NICE  SIZE   RES STATE    TIME    CPU COMMAND
   7352 root       1  54    0 3140K 1852K cpu/0    0:00  0.04% top
  44198 root       1  59    0  862M  849M sleep   14:20  0.03% squid
    924 tor        1  59    0   39M   37M sleep    4:39  0.00% tor
  18319 root       1  59    0   41M 4576K sleep    0:03  0.00% httpd.prefork
   1141 root       1 100  -20 3016K 1364K sleep    0:29  0.00% xntpd
    939 root       1  59    0   12M 6272K sleep    0:26  0.00% munin-node
  12803 squid      1  59    0 5144K 2292K sleep    0:01  0.00% 
log_file_daemon
    808 root      19  59    0   19M   11M sleep    0:03  0.00% fmd
    925 root       1  59    0 9192K 2452K sleep    0:05  0.00% sendmail
  44209 squid      1  59    0 5752K 2476K sleep    0:14  0.00% diskd
     11 root      15  59    0   12M   10M sleep    0:05  0.00% svc.startd
  44208 squid      1  59    0 5752K 2756K sleep    1:10  0.00% diskd
  44206 squid      1  59    0 5752K 2504K sleep    0:43  0.00% diskd
    909 squid      1  59    0 4248K 1456K sleep    0:16  0.00% c-icap
  44207 squid      1  59    0 5752K 2756K sleep    0:46  0.00% diskd
   7350 squid     32  59    0 4532K 1616K sleep    0:00  0.00% c-icap
   5996 squid     32  59    0 4772K 2096K sleep    0:03  0.00% c-icap
     89 root       7  59    0 3888K 2228K sleep    0:04  0.00% devfsadm
    358 root       1  59    0 3928K  812K sleep    0:06  0.00% ipmon
    800 root       1  59    0 1496K  728K sleep    0:01  0.00% utmpd
    927 clamav     1  59    0   19M 4656K sleep   11:30  0.00% freshclam
   1386 clamav     3  59    0  321M  296M sleep   10:42  0.00% clamd
      1 root       1  59    0 2584K 1360K sleep    2:33  0.00% init
  12810 squid      1  59    0   21M   18M sleep    2:19  0.00% squidGuard
    921 unbound    4  59    0  210M  111M sleep    0:59  0.00% unbound
  12812 squid      1  59    0   19M   16M sleep    0:09  0.00% squidGuard
     13 root      17  59    0   11M   10M sleep    0:06  0.00% svc.configd
   5369 root       1  59    0 3436K 1904K sleep    0:06  0.00% squidview
    918 root       1  59    0 4588K 1040K sleep    0:06  0.00% 
dnscrypt-proxy
    705 root       1  59    0 3112K 1344K sleep    0:02  0.00% cron

16.02.15 19:13, Eliezer Croitoru ?????:
> top -n1 -b



From yvoinov at gmail.com  Mon Feb 16 13:23:16 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 19:23:16 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E1ED12.8040606@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
Message-ID: <54E1EF44.6030507@gmail.com>

http://i58.tinypic.com/rsqwxh.png

0 shutting down. Always.

During nights and weekends.

16.02.15 19:13, Eliezer Croitoru ?????:
> Hey Yuri,
>
> There are couple sides and side-effects to the issue you describe.
> If it's OK with you I will for a sec look aside squid and the helpers 
> code to another issue in Computer Science.
>
> Let say we are running some server\software which it's purpose is to 
> calculate the distance from point X to Y for a user.(A real world 
> existing software which was written for DOS)
> Since this piece of software size is about 50kB the user never 
> experienced any issues with this particular software.
> The issues came in when the user needed to run some complex 
> calculations on a big list of points from a map.
> From what I have seen in the past a 133Mhz CPU should take the load, 
> and indeed did not had any issues working with a big set of points 
> what so ever was thrown at it.
> The main complexity with this piece of software was when the 
> calculations needed to be more complex and turned from X to Y to "from 
> X to Y considering A B C D E F G H I".
> Then the CPU got hogged a bit and there for the calculation took a bit 
> longer then expected by the user.
> Just as a side note this DOS system didn't had any SWAP at all.
> This software is still in use since about 198x until these days with 
> no SWAP at all while the calculations are being made daily by lots of 
> users around my country.
> From Computer Science point of view this piece of software is one of 
> the most efficient ever existed on earth and while it was written for 
> DOS it is still efficient enough to support many other systems around 
> the world.
>
> Wouldn't any developer want to write a code in this level?? I believe 
> and know that any developer strives to write a software that will use 
> the available system resources efficiently.
> But for any developer there is a point which he sees how his knowledge 
> alone might not be enough to make a simple piece of software run as 
> smooth and as efficient as this simple DOS software.
> I have never asked the creator of this DOS program how much efforts it 
> took from him and his companions to write such a great piece of ART 
> which is one of a kind, it was not because he is dead or something 
> similar but since I understand it's a complex task which I am not 
> trying to mimic.
>
> And back to squidguard, I myself have tried to understand why it uses 
> so much ram and other resources which should have not being occupied 
> at all.
> Eventually I have written my own version which is a mimic for 
> squidguard basic filtering logic.
> I have seen this behavior you do see and I have couple of times tried 
> to at least make something better then it is now.
> The task was not simple but my idea after lots of time of thinking was 
> to separate most of the logic outside of the url_rewrite interface.
>
> I would not just try to solve the issue as "60 processes Absolutely 
> idle", this might not be the issue in hands at all!
> This conclusion can divert you from the real issue in this situation.
>
> If you are up to the task to share(publicly is not a must) a top 
> snapshot of the machine at midnight while you see the issue I will 
> gladly be more then happy to try and understand the issue in hands.
> I am pretty sure that the command "top -n1 -b" should work in any unix 
> system I have seen until today.
>
> Do you have access to this squid machine cache manager interface?
>
> Eliezer
>
> On 12/02/2015 20:01, Yuri Voinov wrote:
>> Hi gents,
>>
>> subj.
>>
>> And, of course - question. How to do that? I've don't seen this, if it
>> exists.
>>
>> For example, for this config stub:
>>
>> url_rewrite_program /usr/local/bin/squidGuard -c
>> /usr/local/squidGuard/squidGuard.conf
>> url_rewrite_children 100 startup=0 idle=1 concurrency=0
>>
>> After daily activity, at midnight, still remain near 60 processes.
>> Absolutely idle.
>>
>> So, why?
>>
>> WBR, Yuri
>
>



From Antony.Stone at squid.open.source.it  Mon Feb 16 13:24:39 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 16 Feb 2015 13:24:39 +0000
Subject: [squid-users] cache peer load balancing round robin problem
In-Reply-To: <000a01d04a3b$8c8ad8e0$a5a08aa0$@netstream.ps>
References: <000a01d04a3b$8c8ad8e0$a5a08aa0$@netstream.ps>
Message-ID: <201502161324.39873.Antony.Stone@squid.open.source.it>

On Monday 16 Feb 2015 at 22:54, snakeeyes wrote:

> Hi ,
> 
> I have many account from same provider and I would like to use those
> accounts as round robin and each request has different IP as possible

How many client machines are you trying to distribute in this way?  Your 
example suggests you're only testing with one, which is going to be 
unrepresentative if your goal is to do it for 10, 100 or more.

Are you happy if requests to different websites come from different source 
addresses, or do you require that multiple requests to the same site from the 
same client get different source IPs (as outlined in your example)?

Finally, have you looked at network routing solutions (eg: IProute2) to this 
problem, rather than an application layer proxy?


Regards,


Antony.

-- 
Never automate fully anything that does not have a manual override capability. 
Never design anything that cannot work under degraded conditions in emergency.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ahmed.zaeem at netstream.ps  Mon Feb 16 23:51:20 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Mon, 16 Feb 2015 15:51:20 -0800
Subject: [squid-users] cache peer load balancing round robin problem
In-Reply-To: <201502161324.39873.Antony.Stone@squid.open.source.it>
References: <000a01d04a3b$8c8ad8e0$a5a08aa0$@netstream.ps>
 <201502161324.39873.Antony.Stone@squid.open.source.it>
Message-ID: <001401d04a43$77b1a720$6714f560$@netstream.ps>

Hi , a
All I need I need to load balance my request as I can
So , 
I want if I go 1st time to ==> whatismyipaddfress.com
I want  to be ip1 
2nd time ==>ip2

3rd time==> ip3

And so on

Do u think my config needs to be modified ?

cheers 

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antony Stone
Sent: Monday, February 16, 2015 5:25 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] cache peer load balancing round robin problem

On Monday 16 Feb 2015 at 22:54, snakeeyes wrote:

> Hi ,
> 
> I have many account from same provider and I would like to use those 
> accounts as round robin and each request has different IP as possible

How many client machines are you trying to distribute in this way?  Your example suggests you're only testing with one, which is going to be unrepresentative if your goal is to do it for 10, 100 or more.

Are you happy if requests to different websites come from different source addresses, or do you require that multiple requests to the same site from the same client get different source IPs (as outlined in your example)?

Finally, have you looked at network routing solutions (eg: IProute2) to this problem, rather than an application layer proxy?


Regards,


Antony.

-- 
Never automate fully anything that does not have a manual override capability. 
Never design anything that cannot work under degraded conditions in emergency.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From martin at fuchs-kiel.de  Mon Feb 16 14:16:33 2015
From: martin at fuchs-kiel.de (Martin Fuchs)
Date: Mon, 16 Feb 2015 15:16:33 +0100
Subject: [squid-users] reverse-proxy with client certificates pass-thru
Message-ID: <DUB407-EAS313BF2AC598B078EB64EC55F42E0@phx.gbl>

Hi !

 

I'm looking for a possibility to tell squid to pass a certificate presented
by the client to a cache peer.

Since i did not find anything, i decided to ask here ;-)

I saw that it's possibe to let squid pass a client crtificate tot he cache
peer, but this would not work for out purposes.

 

It's an apple mobile device management system which needs to authenticate
the clients by their certificates.

Does anyone have apple remote profile-management running thru a
reverse-proxy with squid ?

 

This dirctive alone does not work:

cache_peer xx.xx.xx.xx parent 443 0 proxy-only no-query no-digest
originserver login=PASSTHRU ssl sslflags=DONT_VERIFY_PEER front-end-https=on
name=MDM_HOST_443

 

thanks in advance,

regards,

martin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150216/6105813a/attachment.htm>

From eliezer at ngtech.co.il  Mon Feb 16 14:46:17 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 16:46:17 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E1EDCD.3040703@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
 <54E1EDCD.3040703@gmail.com>
Message-ID: <54E202B9.3080207@ngtech.co.il>

On 16/02/2015 15:17, Yuri Voinov wrote:
> root @ cthulhu / # top -n1 -b
> top: illegal option -- 1
> Top version 3.7
Hey Yuri,

Since top is missing couple details..
You can try "-n 1" instead of "-n1" and it will might show more details.
If it's not working then a simple "ps" might shed some more light.
In linux I can use "ps axuf" to show the process list in a tree like 
form which is very nice to understand couple things.

Eliezer




From eliezer at ngtech.co.il  Mon Feb 16 14:58:56 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 16:58:56 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E1EF44.6030507@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
 <54E1EF44.6030507@gmail.com>
Message-ID: <54E205B0.50807@ngtech.co.il>

On 16/02/2015 15:23, Yuri Voinov wrote:
> http://i58.tinypic.com/rsqwxh.png
>
> 0 shutting down. Always.
>
> During nights and weekends.

Are you talking about these 10? I am unsure I understand the issue 
yet..(I need to understand a bit more), is this the situation which 
stays forever?

Eliezer



From eliezer at ngtech.co.il  Mon Feb 16 15:13:37 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 17:13:37 +0200
Subject: [squid-users] cache peer load balancing round robin problem
In-Reply-To: <001401d04a43$77b1a720$6714f560$@netstream.ps>
References: <000a01d04a3b$8c8ad8e0$a5a08aa0$@netstream.ps>
 <201502161324.39873.Antony.Stone@squid.open.source.it>
 <001401d04a43$77b1a720$6714f560$@netstream.ps>
Message-ID: <54E20921.8040804@ngtech.co.il>

Hey,

There are couple things to consider while using multiple IPs for the 
same network\user.
It is possible to do what you want in the OS level and in a way using squid.
You should consider first what is the exact effect you want\need and if 
it can meet reality in usability level.
It is not very smart to just spread the traffic from different IPs since 
there is an application level issues that you and your users might 
encounter while operating this logic.

Eliezer

On 17/02/2015 01:51, snakeeyes wrote:
> Hi , a
> All I need I need to load balance my request as I can
> So ,
> I want if I go 1st time to ==> whatismyipaddfress.com
> I want  to be ip1
> 2nd time ==>ip2
>
> 3rd time==> ip3
>
> And so on
>
> Do u think my config needs to be modified ?
>
> cheers




From yvoinov at gmail.com  Mon Feb 16 15:27:32 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 21:27:32 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E202B9.3080207@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
 <54E1EDCD.3040703@gmail.com> <54E202B9.3080207@ngtech.co.il>
Message-ID: <54E20C64.2050003@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

root @ cthulhu / # top -n 1 -b
last pid: 43244;  load avg:  0.06,  0.07,  0.07;  up 7+22:16:44
 21:27:15
62 processes: 61 sleeping, 1 on cpu
CPU states: 99.3% idle,  0.5% user,  0.2% kernel,  0.0% iowait,  0.0% swap
Kernel: 510 ctxsw, 4 trap, 754 intr, 1070 syscall, 3 flt
Memory: 4095M phys mem, 118M free mem, 8192M total swap, 8192M free swap

   PID USERNAME LWP PRI NICE  SIZE   RES STATE    TIME    CPU COMMAND
 41878 squid     32  59    0 4684K 2012K sleep    0:02  0.50% c-icap

16.02.15 20:46, Eliezer Croitoru ?????:
> On 16/02/2015 15:17, Yuri Voinov wrote:
>> root @ cthulhu / # top -n1 -b top: illegal option -- 1 Top
>> version 3.7
> Hey Yuri,
> 
> Since top is missing couple details.. You can try "-n 1" instead of
> "-n1" and it will might show more details. If it's not working then
> a simple "ps" might shed some more light. In linux I can use "ps
> axuf" to show the process list in a tree like form which is very
> nice to understand couple things.
> 
> Eliezer
> 
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4gxkAAoJENNXIZxhPexGr0kH/3j65CY/uZHHEmMzarLj5okW
fFCe+GC80MhjGHjXwAJYZAeqgVTBDaTCD9ppugQzuP9Qb1xNOcSRAyIJSrS/H8S/
0Rr7GPNDgYBL3sEvis+dp+MlxCzkDV+xlRsiqI+yYyqgArMPy0hyILxV8bFDRrVU
YEnYR4IMbUlJ51xyXTvdbKPXEutHUXz+0sLJqxrYuONpepGe6XMQg6Q7FbTZZMU+
UbuY1kj8jiwH/gO4hpx2Ldw8mw9lzul57BaCkgYRuKAyD7CJZ0U3DjwIPhoVyAJT
OVWai9EJ6iy+IVlhSAITff9ZCbCiEyQRBZJT97gCvjzjlYg9Fdykp9vCzveP4Mg=
=JK5W
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Mon Feb 16 15:27:59 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 21:27:59 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E205B0.50807@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
 <54E1EF44.6030507@gmail.com> <54E205B0.50807@ngtech.co.il>
Message-ID: <54E20C7F.9050105@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Yep.

16.02.15 20:58, Eliezer Croitoru ?????:
> On 16/02/2015 15:23, Yuri Voinov wrote:
>> http://i58.tinypic.com/rsqwxh.png
>> 
>> 0 shutting down. Always.
>> 
>> During nights and weekends.
> 
> Are you talking about these 10? I am unsure I understand the issue 
> yet..(I need to understand a bit more), is this the situation
> which stays forever?
> 
> Eliezer
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4gx+AAoJENNXIZxhPexGx6sH/jLsQyB1mWg4YTdh42Zdvqe0
xOSKix2hp1bc0bAXGRmAIpRT0l58yHXEaP7WRjv/BkMcontVNhi5CfTF6LQktPFH
sicxwqUijwycZq8lGDBx5jq+kn/MUDXjo2Zdp9MMT9PqvkpXCliEcDrfssdjDg0D
0dqwlTS7eW9bz4DeRpNLPEoPIUYsHAzi/6BKDKUnlxwUu8fOa98XznN3/GCA192c
jGiZVChbUrL+h/fUze96jyNgViKWyWBuac3KNPLwzeYu/TpQAdHR+7LKzqGRxoWd
yb0wXxsNK/1Efh1HQMNEd3VXfVv9oA7RbcMISbR13Us7LWV1VQr9XttqmH1ff8o=
=C5wp
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Mon Feb 16 16:15:59 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 18:15:59 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E20C64.2050003@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
 <54E1EDCD.3040703@gmail.com> <54E202B9.3080207@ngtech.co.il>
 <54E20C64.2050003@gmail.com>
Message-ID: <54E217BF.5040108@ngtech.co.il>

On 16/02/2015 17:27, Yuri Voinov wrote:
> root @ cthulhu / # top -n 1 -b
> last pid: 43244;  load avg:  0.06,  0.07,  0.07;  up 7+22:16:44
>   21:27:15
> 62 processes: 61 sleeping, 1 on cpu
> CPU states: 99.3% idle,  0.5% user,  0.2% kernel,  0.0% iowait,  0.0% swap
> Kernel: 510 ctxsw, 4 trap, 754 intr, 1070 syscall, 3 flt
> Memory: 4095M phys mem, 118M free mem, 8192M total swap, 8192M free swap
>
>     PID USERNAME LWP PRI NICE  SIZE   RES STATE    TIME    CPU COMMAND
>   41878 squid     32  59    0 4684K 2012K sleep    0:02  0.50% c-icap

Hey Yuri,

Still not enough data.
Can you get the "ps axuf" output?

Eliezer



From alanpalmer72 at yahoo.com  Mon Feb 16 16:16:21 2015
From: alanpalmer72 at yahoo.com (Alan Palmer)
Date: Mon, 16 Feb 2015 11:16:21 -0500
Subject: [squid-users] ssl proxy error: No valid signing SSL certificate
 configured for https_port [::]:3127
In-Reply-To: <54E1144C.2040503@ngtech.co.il>
References: <54E1115E.3040804@yahoo.com> <54E1144C.2040503@ngtech.co.il>
Message-ID: <54E217D5.70005@yahoo.com>

Tried the two links provided, still no luck.

details:
squid -v
Squid Cache: Version 3.4.11
configure options:  '--disable-strict-error-checking' 
'--disable-arch-native' '--enable-shared' 
'--datadir=/usr/local/share/squid' 
'--libexecdir=/usr/local/libexec/squid' '--disable-loadable-modules' 
'--enable-arp-acl' '--enable-auth' '--enable-delay-pools' 
'--enable-follow-x-forwarded-for' '--enable-forw-via-db' 
'--enable-http-violations' '--enable-icap-client' '--enable-ipv6' 
'--enable-referer-log' '--enable-removal-policies=lru heap' 
'--enable-ssl' '--with-openssl' '--enable-storeio=aufs ufs diskd' 
'--with-default-user=_squid' '--with-filedescriptors=8192' 
'--with-krb5-config=no' '--with-pidfile=/var/run/squid.pid' 
'--with-pthreads' '--with-swapdir=/var/squid/cache' 
'--disable-pf-transparent' '--enable-ipfw-transparent' 
'--enable-external-acl-helpers=LDAP_group SQL_session file_userip 
time_quota session  unix_group wbinfo_group LDAP_group 
eDirectory_userip' '--prefix=/usr/local' '--sysconfdir=/etc/squid' 
'--mandir=/usr/local/man' '--infodir=/usr/local/info' 
'--localstatedir=/var/squid' '--disable-silent-rules' 'CC=cc' 
'CFLAGS=-O2 -pipe' 'LDFLAGS=-L/usr/local/lib' 
'CPPFLAGS=-I/usr/local/include' 'CXX=c++' 'CXXFLAGS=-O2 -pipe' 
'--enable-ssl-crtd' --enable-ltdl-convenience

tail -10 squid.conf
https_port 3127 intercept ssl-bump generate-host-certificates=on 
dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl_cert/server1.crt
sslcrtd_program /usr/local/libexec/squid/ssl_crtd -s 
/usr/local/squid/var/lib/ssl_db -M 16MB
sslcrtd_children 10
ssl_bump server-first all

cert generation
openssl genrsa -des3 -passout pass:x -out server.pass.key 2048
openssl rsa -passin pass:x -in server.pass.key -out server.key
rm server.pass.key
openssl req -new -key server.key -out server.csr
openssl req -new -key server.key -out server.csr
openssl x509 -req -days 730 -in server.csr -signkey server.key
openssl x509 -req -days 730 -in server.csr -signkey server.key -out 
server.crt
cat server.key server.crt > server1.crt

squid -z
FATAL: No valid signing SSL certificate configured for https_port 
0.0.0.0:3127
Squid Cache (Version 3.4.11): Terminated abnormally.
CPU Usage: 0.080 seconds = 0.060 user + 0.020 sys
Maximum Resident Size: 6752 KB
Page faults with physical i/o: 0

cert generation ala 
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/SSLBUMP (squid.conf 
changed to cert=/etc/squid/ssl_cert/myCA.pem)

openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keyout 
myCA.pem -out myCA.pem

squid -z
FATAL: No valid signing SSL certificate configured for https_port [::]:3127
Squid Cache (Version 3.4.11): Terminated abnormally.
CPU Usage: 0.040 seconds = 0.010 user + 0.030 sys
Maximum Resident Size: 6288 KB
Page faults with physical i/o: 0

In Reply To:

Hey Alan,

What is the full output of "squid -v"?

I am unsure about the akadia tutorial.
Please take a look at:
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/SSLBUMP

It contains some hints on how to create the certificate and contains a 
snippet of squid configuration to make a basic ssl-bump work(the echo 
command code might not be right)

I am pretty sure the certificate you have created is not the right type 
for the task.

Eliezer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


In reply to:
















On 2/15/2015 4:49 PM, Eliezer Croitoru wrote:
> On 15/02/2015 23:36, Alan Palmer wrote:
>> I'm trying to get squid 3.4.11 on openbsd 5.6 to act as a transparent
>> ssl proxy.
>>
>> I've rebuilt squid with --enable-ssl-crtd, generated my own self signed
>> cert (ala http://www.akadia.com/services/ssh_test_certificate.html) and
>> have the following config lines:
>
> Hey Alan,
>
> What is the full output of "squid -v"?
>
> I am unsure about the akadia tutorial.
> Please take a look at:
> http://wiki.squid-cache.org/EliezerCroitoru/Drafts/SSLBUMP
>
> It contains some hints on how to create the certificate and contains a 
> snippet of squid configuration to make a basic ssl-bump work(the echo 
> command code might not be right)
>
> I am pretty sure the certificate you have created is not the right 
> type for the task.
>
> Eliezer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Mon Feb 16 16:20:04 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 22:20:04 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E217BF.5040108@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
 <54E1EDCD.3040703@gmail.com> <54E202B9.3080207@ngtech.co.il>
 <54E20C64.2050003@gmail.com> <54E217BF.5040108@ngtech.co.il>
Message-ID: <54E218B4.7030607@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

root @ cthulhu / # ps axuf
usage: ps [ -aAdeflcjLPyZ ] [ -o format ] [ -t termlist ]
        [ -u userlist ] [ -U userlist ] [ -G grouplist ]
        [ -p proclist ] [ -g pgrplist ] [ -s sidlist ] [ -z zonelist ]
  'format' is one or more of:
        user ruser group rgroup uid ruid gid rgid pid ppid pgid sid
taskid ctid
        pri opri pcpu pmem vsz rss osz nice class time etime stime
zone zoneid
        f s c lwp nlwp psr tty addr wchan fname comm args projid
project pset

May be, you want to know my OS?

16.02.15 22:15, Eliezer Croitoru ?????:
> ps axuf
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4hi0AAoJENNXIZxhPexG/XsH/R9unH4HhaMsM/566Rt9qDe3
ySQcJCV3P0stQMkod3DgUcXYusx0TEKNdrcbo33wqCj5VrvZdCON25dkmoTXDnD/
n8X8RX/QZsHDjeiOyC3NIUNSUKMAuI2r3mWe1fV9vs5+HT1q08iMOqwVLssoHnc5
nH7LXJg6h2+xgKF/suuKtDEXDO93ffgtz5Yoasd8IDkp2pPgTDk/Zs+yfjqubNbR
9AM2Acj7p2OY08OtA0ZDuDs+V/93cbJe1dqT6gAsSB+XNZzGNzEMMrngO7axuOhk
79hSdr4YMeckdD/2hAx9Mwl3144vyzWeGgwkbi4hTwz1of4a6BHABCbG6gH4/Ao=
=kHGe
-----END PGP SIGNATURE-----


From Antony.Stone at squid.open.source.it  Mon Feb 16 16:35:40 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 16 Feb 2015 16:35:40 +0000
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
	children?
In-Reply-To: <54E218B4.7030607@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
Message-ID: <201502161635.40518.Antony.Stone@squid.open.source.it>

On Monday 16 Feb 2015 at 16:20, Yuri Voinov wrote:

> root @ cthulhu / # ps axuf
> usage: ps [ -aAdeflcjLPyZ ] [ -o format ] [ -t termlist ]
>         [ -u userlist ] [ -U userlist ] [ -G grouplist ]
>         [ -p proclist ] [ -g pgrplist ] [ -s sidlist ] [ -z zonelist ]

> May be, you want to know my OS?

I'm going to guess it's Solaris.

Regards,


Antony.

-- 
"Once you have a panic, things tend to become rather undefined."

 - murble

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Mon Feb 16 16:37:23 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 22:37:23 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <201502161635.40518.Antony.Stone@squid.open.source.it>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
Message-ID: <54E21CC3.5070707@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Yes.


root @ cthulhu / # uname -a
SunOS cthulhu 5.10 Generic_150401-16 i86pc i386 i86pc Solaris

Are you an expert in it?

16.02.15 22:35, Antony Stone ?????:
> On Monday 16 Feb 2015 at 16:20, Yuri Voinov wrote:
> 
>> root @ cthulhu / # ps axuf usage: ps [ -aAdeflcjLPyZ ] [ -o
>> format ] [ -t termlist ] [ -u userlist ] [ -U userlist ] [ -G
>> grouplist ] [ -p proclist ] [ -g pgrplist ] [ -s sidlist ] [ -z
>> zonelist ]
> 
>> May be, you want to know my OS?
> 
> I'm going to guess it's Solaris.
> 
> Regards,
> 
> 
> Antony.
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4hzCAAoJENNXIZxhPexGdQgH/Rp0WfG5VGUMIG7zjNc2qugO
aAcT1MUdceyUH5Yk0r00Y8n28xSnQNRG3MZ78EUnx1hj3CDn5WFQm3jmjF/D9l6G
Q/wjzg9gePPVoEmm1Oi4bluXu6nVwJKxz7XyYL5gwKu4RSSKPMKDU3lxrvVGlgo2
jQlg0UIcP50tGCDLi5hD5xO525Mm4rKWCrc8j5NVkj5B4D58yCBNElU+/zZ8Kibw
kdsqR11S9JewA1lRVaw58J37o+Dav8jawXxqBs6LIEYtjzl5G7BUBX+Oxc1dykSw
ByFC9PTzO29lg381xcCM18c0CBfcCG4NSlvwCMxZx9u06TWh4uCIRJr28XXJH0A=
=n9gQ
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Mon Feb 16 16:48:41 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 18:48:41 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E21CC3.5070707@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com>
Message-ID: <54E21F69.8050009@ngtech.co.il>

Hey Yuri,

I would try first "ps -aux" just to find out if this is the right way to 
use ps in solaris.

If it works show me the details first and we will see what to do next.

Eliezer

On 16/02/2015 18:37, Yuri Voinov wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Yes.
>
>
> root @ cthulhu / # uname -a
> SunOS cthulhu 5.10 Generic_150401-16 i86pc i386 i86pc Solaris
>
> Are you an expert in it?
>
> 16.02.15 22:35, Antony Stone ?????:
>> On Monday 16 Feb 2015 at 16:20, Yuri Voinov wrote:
>>
>>> root @ cthulhu / # ps axuf usage: ps [ -aAdeflcjLPyZ ] [ -o
>>> format ] [ -t termlist ] [ -u userlist ] [ -U userlist ] [ -G
>>> grouplist ] [ -p proclist ] [ -g pgrplist ] [ -s sidlist ] [ -z
>>> zonelist ]
>>
>>> May be, you want to know my OS?
>>
>> I'm going to guess it's Solaris.
>>
>> Regards,
>>
>>
>> Antony.
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU4hzCAAoJENNXIZxhPexGdQgH/Rp0WfG5VGUMIG7zjNc2qugO
> aAcT1MUdceyUH5Yk0r00Y8n28xSnQNRG3MZ78EUnx1hj3CDn5WFQm3jmjF/D9l6G
> Q/wjzg9gePPVoEmm1Oi4bluXu6nVwJKxz7XyYL5gwKu4RSSKPMKDU3lxrvVGlgo2
> jQlg0UIcP50tGCDLi5hD5xO525Mm4rKWCrc8j5NVkj5B4D58yCBNElU+/zZ8Kibw
> kdsqR11S9JewA1lRVaw58J37o+Dav8jawXxqBs6LIEYtjzl5G7BUBX+Oxc1dykSw
> ByFC9PTzO29lg381xcCM18c0CBfcCG4NSlvwCMxZx9u06TWh4uCIRJr28XXJH0A=
> =n9gQ
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>




From yvoinov at gmail.com  Mon Feb 16 16:55:13 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 22:55:13 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E21F69.8050009@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
Message-ID: <54E220F1.1080202@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

root @ cthulhu / # ps -aux
ps: unknown user x

Really, I don't understand subject of discussion.

I think, will good to have possibility to autoclose idle Squid
redirectors after time specified. Regardless of the operating system.
Like autoclose applications on Android.

I want stupid thing?

I'm not hard to execute through the cron pkill -9 squidGuard command
every hour. But it is a crutch. Did you agree?

16.02.15 22:48, Eliezer Croitoru ?????:
> ps -aux
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4iDwAAoJENNXIZxhPexGZI4H/Rab0XbeDf+bh8gVegJ3N0c+
CrUhZjcBD+pidDHNfFCC6mwZAdGrDY48qy2krUHo2NDOBEXpJDADfLKGwS6l2x81
4wS97Yt2xDJ6goribeR0diN0Sui2HGWfwS2+dEsQO6ANASVhTo+yRU/cD8pz5fM6
n81N/8VxWZJV279KrSUY/yXkzmd9PBAD2vDxcC5/UH5t0MBhPWg0X3LC4LmTHZg0
Gl+qYiLvbmeRxIwwzE/gxZHuVn8Q2+6XJZNiltpyTLhvBRECZvg65gV4XFUTafaz
IFbTP30ubXlYkcxDd9TqVCs7RMqXVH6yr4ipQQ1v4ugl4EOVGtFfiD6L5LMT4hM=
=cp5c
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Mon Feb 16 17:07:56 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 23:07:56 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E21F69.8050009@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
Message-ID: <54E223EC.2080600@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

You can see:

root @ cthulhu / # ps -efl|grep squidGuard|grep -v grep
 0 S    squid  3648 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3647 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3643 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3639 44198   0  40 20        ?   3974        ? 23:01:38
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3646 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3642 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3644 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3640 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3641 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua
 0 S    squid  3645 44198   0  40 20        ?   3674        ? 23:01:39
?           0:00 (squidGuard) -c /usr/local/squidGua

All redirector's sleeping. Second column. 'S' means 'Sleeping'. Why
they not shutdown? Now wallclock says '23:07'. No activity. Hm?

16.02.15 22:48, Eliezer Croitoru ?????:
> ps -aux
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4iPsAAoJENNXIZxhPexGx44IAMS455/ymD4+CLxAj8OppMbt
run8qGNFlkOxetGScSn8MfemtwDvXoxe5VwNXs8715vzNY12Ao24nAF+EoOHJtGe
vr1TdOouhM79MkqKWWmD1Of0i3LTiR8R20c5CCybUaR7IL9bxsVL41oeBNqWSrwg
mrYk1McLZtIgt84++aJ+oFG6ePcLwzaNKa2BnWa/hRavyUxsf4L+rUxnxF+baCj6
jR4IxF0kSJcMmlnqVAL2P8M7wpkBvgzZ8HlgjO6suwNbjOKTZ5P+1aWeu4n902pj
4f2EXhlrjvY2EBmm+DDTNduW73L8JtQND79ufAs/i+t0z1uZlVWQfdSeIYsXynw=
=XkWB
-----END PGP SIGNATURE-----


From ignazio.raia at eutelia.com  Mon Feb 16 17:28:49 2015
From: ignazio.raia at eutelia.com (Ignazio Raia)
Date: Mon, 16 Feb 2015 09:28:49 -0800 (PST)
Subject: [squid-users] login expired
In-Reply-To: <54D5C95D.3050101@treenet.co.nz>
References: <1423176194436-4669574.post@n4.nabble.com>
 <54D481BB.3010308@treenet.co.nz> <1423290748208-4669607.post@n4.nabble.com>
 <54D5C95D.3050101@treenet.co.nz>
Message-ID: <1424107729424-4669882.post@n4.nabble.com>

Hi Amos 
I finally made the changes you suggested and now I have squid asks
authentication as required.
I still have two troubles:
1) the directive auth_param basic credentialsttl 60 seconds doesn't work.
Squid doesn't ask me a new login request
2) If I use Internet Explorer I don't have the login request (I.e., is
configured to use proxy)
Thank you very much for your help

Ignazio










--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/login-expired-tp4669574p4669882.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Feb 16 17:54:31 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 23:54:31 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E21F69.8050009@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
Message-ID: <54E22ED7.2040208@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I think, this looks like platform-specific bug.

Yes, sir.

AFAIK, Solaris idle processes almost never has state 'Idle', but 'Sleep',

so this is why Squid doesn't shutting down idle redirectors.

Amos, is this explanation possible?

16.02.15 22:48, Eliezer Croitoru ?????:
> Hey Yuri,
> 
> I would try first "ps -aux" just to find out if this is the right
> way to use ps in solaris.
> 
> If it works show me the details first and we will see what to do
> next.
> 
> Eliezer
> 
> On 16/02/2015 18:37, Yuri Voinov wrote: Yes.
> 
> 
> root @ cthulhu / # uname -a SunOS cthulhu 5.10 Generic_150401-16
> i86pc i386 i86pc Solaris
> 
> Are you an expert in it?
> 
> 16.02.15 22:35, Antony Stone ?????:
>>>> On Monday 16 Feb 2015 at 16:20, Yuri Voinov wrote:
>>>> 
>>>>> root @ cthulhu / # ps axuf usage: ps [ -aAdeflcjLPyZ ] [
>>>>> -o format ] [ -t termlist ] [ -u userlist ] [ -U userlist ]
>>>>> [ -G grouplist ] [ -p proclist ] [ -g pgrplist ] [ -s
>>>>> sidlist ] [ -z zonelist ]
>>>> 
>>>>> May be, you want to know my OS?
>>>> 
>>>> I'm going to guess it's Solaris.
>>>> 
>>>> Regards,
>>>> 
>>>> 
>>>> Antony.
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4i7XAAoJENNXIZxhPexGcDcH/iUs2x22xbxdPe9Xf4tch866
qs/ipVCpEy+qLi/GvQcKygl6E/75VVKPgco+bU+KsVIzX8AtqqqL7RbGgTc95Hqe
bl1z8JL9Hax8Facu3kmggmdFfgSDzuIKCKEM1+8VJa7iAN8TEGNg0+HuYmdtkM/u
ZIBd1ibIdYBNZq0bft+Ietjsv5dGwh3x42WjbNpLxdqOT3B3NrWhMGhha8ovLwwJ
/7wTXrNac9UWg16EvEKjy4Cmc/ZfBbkLW+D/GW+TPdm/zYMjKqNr0oLkFkw8kuMG
3/PjrSrjvbHtYBdPZxjVkt5rV/6a8PQwi48XR1hMx39LcFhN+5BVeqh6skLs7Hs=
=WfGt
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Mon Feb 16 17:57:08 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 16 Feb 2015 23:57:08 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E21F69.8050009@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
Message-ID: <54E22F74.2000907@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Just look at this:

http://i.imgur.com/fFRW3Hv.png

Now i've tried to toggle 'I' on top. To show idle processes.

Did you seen?

16.02.15 22:48, Eliezer Croitoru ?????:
> Hey Yuri,
> 
> I would try first "ps -aux" just to find out if this is the right
> way to use ps in solaris.
> 
> If it works show me the details first and we will see what to do
> next.
> 
> Eliezer
> 
> On 16/02/2015 18:37, Yuri Voinov wrote: Yes.
> 
> 
> root @ cthulhu / # uname -a SunOS cthulhu 5.10 Generic_150401-16
> i86pc i386 i86pc Solaris
> 
> Are you an expert in it?
> 
> 16.02.15 22:35, Antony Stone ?????:
>>>> On Monday 16 Feb 2015 at 16:20, Yuri Voinov wrote:
>>>> 
>>>>> root @ cthulhu / # ps axuf usage: ps [ -aAdeflcjLPyZ ] [
>>>>> -o format ] [ -t termlist ] [ -u userlist ] [ -U userlist ]
>>>>> [ -G grouplist ] [ -p proclist ] [ -g pgrplist ] [ -s
>>>>> sidlist ] [ -z zonelist ]
>>>> 
>>>>> May be, you want to know my OS?
>>>> 
>>>> I'm going to guess it's Solaris.
>>>> 
>>>> Regards,
>>>> 
>>>> 
>>>> Antony.
>>>> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4i90AAoJENNXIZxhPexGXYIH/ApODOe9o7tHKok5it45aGCx
hRDtOVJYmVNxIFN8TDzt6ua25rN8pnOgYICyCLz1s8bNklzC7k3jGE+csRLdzSjU
VrsRNMi4wD9DOLgyQf8DI6FGdQE8WsYzSNxTIEGYQA5rb6F+RcySpvrgokgMgthl
GV1gg48cJpkOeSKwCjo50UlU2sLbEDKv7B1bheVvy+koqex8uHu/oXEeRG+H26j1
AX/2MBwkgrCwjAgi4W9rYyWHRZGZNPL2UcwDWS6OLHo+7hH3K5II44TgHDxjLTSG
x6OVqWgoE27sK7/AsMg/i4KznvlGxSLZz3DthEZBZh6HAxyrHNtMmKUN7D37hU0=
=QDnd
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Mon Feb 16 18:22:36 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 20:22:36 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E220F1.1080202@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com>
Message-ID: <54E2356C.3040204@ngtech.co.il>

Hey Yuri,

I looked eventually at Solaris 11 man pages at:
http://docs.oracle.com/cd/E26502_01/html/E29030/ps-1.html#scrolltoc

Just to be sure the next command would run:
"ps -e"

There is no subject to the discussion yet since the issue is yet to be 
defined as an issue.

You mentioned Android autoclose but you must first be clear from a doubt!
Android is indeed Linux kernel based and provides some APIs for gui and 
other components of the system but it is much different by nature.
If you would take a simple PC from 10 years ago indeed an Android device 
beats it's specs and will have much more ram and CPU speed\power.
Android however with all it's API would not allow just any process 
handle "iptables" rules out of the box in any form.
Is there a reason for that? maybe yes and maybe not but I mostly don't 
care about it since it's not being used mostly for servers grade operations.

I would definitely not want to call you stupid but sometimes even I 
cannot catch\understand\hold others way of thinking.

It's indeed not hard to execute pkill -9 "XYZ" but from my experience 
any similar operation should not be considered as a production action.
In a case of bug that is being fixed\tested or a software that is out of 
maintenance it might be the only solution but yet is not recommended.

Notice that any action you would do regarding this squidGuard helpers 
will cost something like any other server simple operation.

Squid basically tries to take in account that to every operation there 
is cost and the admin will prefer to run the server for more then a 
period of 24\48 hours.
I understand that there is memory that is being used by squidGuard and I 
would not expect it to not consume any memory at all.

The next step are not common CS use practice:
- The first step before rushing to terminate squidGuard would be to 
check what is the DB files size which squidGuard uses.
- Then I would try to estimate what RAM usage I would expect for this 
logic and for the DB files.
- At this point some would try to sacrifice some aspects of performance 
compared to others due to what so ever reason.
- Others might try other directions.(I will take this "other" one.)
-- Consider what is more important between couple things:
* System ram or CPU utilization
* System stability
* System disk access reduction
* System network utilization
* System ching ching (ie $$ or other concurrency) costs
-- Based on choosing one or more from the options above and\or others 
that the human mind can take in account, list them and make sure what 
the current issue in hands hits and maybe by that costs or might cost 
money or sleep or fuel or happiness or other important things that are 
considered to be a loss and or a benefit.
 From this point on the solution in most of the time is simpler then 
some might imagine.

Now I think is the right place to stop the actual lookup for one 
solution or other and simply understand the technical issue you see and 
understand it.

All The Bests,
Eliezer

* Waiting for the ps output.

On 16/02/2015 18:55, Yuri Voinov wrote:
> root @ cthulhu / # ps -aux
> ps: unknown user x
>
> Really, I don't understand subject of discussion.
>
> I think, will good to have possibility to autoclose idle Squid
> redirectors after time specified. Regardless of the operating system.
> Like autoclose applications on Android.
>
> I want stupid thing?
>
> I'm not hard to execute through the cron pkill -9 squidGuard command
> every hour. But it is a crutch. Did you agree?




From yvoinov at gmail.com  Mon Feb 16 18:38:05 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 00:38:05 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E2356C.3040204@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
Message-ID: <54E2390D.1050708@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

We are talking not about the differences between any *NIX-based or
*NIX-like OS. Android just an example. I guess an observerd behaviour
of redirector's processes is not expected.

Now I've observed mentioned behaviour of redirectors over one month. I
just want to know - is this desired behaviour or this is a bug.

If this is bug - need to report it as bug.

If this need, I'm ready to grant access to bare-metal installed
Solaris system with Squid and squidGuard to tests for developers.

If your one of them - you are welcome.


17.02.15 0:22, Eliezer Croitoru ?????:
> Hey Yuri,
> 
> I looked eventually at Solaris 11 man pages at: 
> http://docs.oracle.com/cd/E26502_01/html/E29030/ps-1.html#scrolltoc
>
>  Just to be sure the next command would run: "ps -e"
> 
> There is no subject to the discussion yet since the issue is yet to
> be defined as an issue.
> 
> You mentioned Android autoclose but you must first be clear from a
> doubt! Android is indeed Linux kernel based and provides some APIs
> for gui and other components of the system but it is much different
> by nature. If you would take a simple PC from 10 years ago indeed
> an Android device beats it's specs and will have much more ram and
> CPU speed\power. Android however with all it's API would not allow
> just any process handle "iptables" rules out of the box in any
> form. Is there a reason for that? maybe yes and maybe not but I
> mostly don't care about it since it's not being used mostly for
> servers grade operations.
> 
> I would definitely not want to call you stupid but sometimes even
> I cannot catch\understand\hold others way of thinking.
> 
> It's indeed not hard to execute pkill -9 "XYZ" but from my
> experience any similar operation should not be considered as a
> production action. In a case of bug that is being fixed\tested or a
> software that is out of maintenance it might be the only solution
> but yet is not recommended.
> 
> Notice that any action you would do regarding this squidGuard
> helpers will cost something like any other server simple
> operation.
> 
> Squid basically tries to take in account that to every operation
> there is cost and the admin will prefer to run the server for more
> then a period of 24\48 hours. I understand that there is memory
> that is being used by squidGuard and I would not expect it to not
> consume any memory at all.
> 
> The next step are not common CS use practice: - The first step
> before rushing to terminate squidGuard would be to check what is
> the DB files size which squidGuard uses. - Then I would try to
> estimate what RAM usage I would expect for this logic and for the
> DB files. - At this point some would try to sacrifice some aspects
> of performance compared to others due to what so ever reason. -
> Others might try other directions.(I will take this "other" one.) 
> -- Consider what is more important between couple things: * System
> ram or CPU utilization * System stability * System disk access
> reduction * System network utilization * System ching ching (ie $$
> or other concurrency) costs -- Based on choosing one or more from
> the options above and\or others that the human mind can take in
> account, list them and make sure what the current issue in hands
> hits and maybe by that costs or might cost money or sleep or fuel
> or happiness or other important things that are considered to be a
> loss and or a benefit. From this point on the solution in most of
> the time is simpler then some might imagine.
> 
> Now I think is the right place to stop the actual lookup for one 
> solution or other and simply understand the technical issue you see
> and understand it.
> 
> All The Bests, Eliezer
> 
> * Waiting for the ps output.
> 
> On 16/02/2015 18:55, Yuri Voinov wrote:
>> root @ cthulhu / # ps -aux ps: unknown user x
>> 
>> Really, I don't understand subject of discussion.
>> 
>> I think, will good to have possibility to autoclose idle Squid 
>> redirectors after time specified. Regardless of the operating
>> system. Like autoclose applications on Android.
>> 
>> I want stupid thing?
>> 
>> I'm not hard to execute through the cron pkill -9 squidGuard
>> command every hour. But it is a crutch. Did you agree?
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4jkNAAoJENNXIZxhPexGD68H/0qJA1sZQ2Pv6v+6kSSNw1Az
h6cRXpV6u/pUQF+oJf7xV0l/iqBtxGsyhYX6HTz48xinm27COzC6cwiuTVlgRVxA
W3jDJaQmTjzTKHogOZ1sRviww0pu2LQWzUIPkDA7k7cfpTDaVVUpLd4dCgg5YqGK
ZRCQZtNWqvfpMtZ3i/UInRLgxl1BI8TFQk73PhUL0XzyHnn7StYdM4HIuG+LJBTS
i24Chot+d00C8yKz62ZOaBw2z1j0dOC4xAMShMY7YHlJgV6cX0Uvqm86EBOJbvpm
rhsiNMAjFyCAuXTx04WX6yHxzVfIx23bEvBN46S+s8OBWEW3h1hfjigYkPVtR1E=
=+kqp
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Mon Feb 16 18:42:00 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 00:42:00 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E2356C.3040204@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
Message-ID: <54E239F8.6070605@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

root @ cthulhu / # ps -efl|grep squidGuard|grep -v grep|awk {'print $2
" " $5'}
S 6475

Now you can see one squidGuard process. Squid was restarted hour ago.

Process is idle (no traffic now), but this is as desired by config. As
you can see, it state is "S", not 'I'. Feel the difference.

The same picture I've observed every night. With some dozens
redirector processes.

17.02.15 0:22, Eliezer Croitoru ?????:
> Hey Yuri,
> 
> I looked eventually at Solaris 11 man pages at: 
> http://docs.oracle.com/cd/E26502_01/html/E29030/ps-1.html#scrolltoc
>
>  Just to be sure the next command would run: "ps -e"
> 
> There is no subject to the discussion yet since the issue is yet to
> be defined as an issue.
> 
> You mentioned Android autoclose but you must first be clear from a
> doubt! Android is indeed Linux kernel based and provides some APIs
> for gui and other components of the system but it is much different
> by nature. If you would take a simple PC from 10 years ago indeed
> an Android device beats it's specs and will have much more ram and
> CPU speed\power. Android however with all it's API would not allow
> just any process handle "iptables" rules out of the box in any
> form. Is there a reason for that? maybe yes and maybe not but I
> mostly don't care about it since it's not being used mostly for
> servers grade operations.
> 
> I would definitely not want to call you stupid but sometimes even
> I cannot catch\understand\hold others way of thinking.
> 
> It's indeed not hard to execute pkill -9 "XYZ" but from my
> experience any similar operation should not be considered as a
> production action. In a case of bug that is being fixed\tested or a
> software that is out of maintenance it might be the only solution
> but yet is not recommended.
> 
> Notice that any action you would do regarding this squidGuard
> helpers will cost something like any other server simple
> operation.
> 
> Squid basically tries to take in account that to every operation
> there is cost and the admin will prefer to run the server for more
> then a period of 24\48 hours. I understand that there is memory
> that is being used by squidGuard and I would not expect it to not
> consume any memory at all.
> 
> The next step are not common CS use practice: - The first step
> before rushing to terminate squidGuard would be to check what is
> the DB files size which squidGuard uses. - Then I would try to
> estimate what RAM usage I would expect for this logic and for the
> DB files. - At this point some would try to sacrifice some aspects
> of performance compared to others due to what so ever reason. -
> Others might try other directions.(I will take this "other" one.) 
> -- Consider what is more important between couple things: * System
> ram or CPU utilization * System stability * System disk access
> reduction * System network utilization * System ching ching (ie $$
> or other concurrency) costs -- Based on choosing one or more from
> the options above and\or others that the human mind can take in
> account, list them and make sure what the current issue in hands
> hits and maybe by that costs or might cost money or sleep or fuel
> or happiness or other important things that are considered to be a
> loss and or a benefit. From this point on the solution in most of
> the time is simpler then some might imagine.
> 
> Now I think is the right place to stop the actual lookup for one 
> solution or other and simply understand the technical issue you see
> and understand it.
> 
> All The Bests, Eliezer
> 
> * Waiting for the ps output.
> 
> On 16/02/2015 18:55, Yuri Voinov wrote:
>> root @ cthulhu / # ps -aux ps: unknown user x
>> 
>> Really, I don't understand subject of discussion.
>> 
>> I think, will good to have possibility to autoclose idle Squid 
>> redirectors after time specified. Regardless of the operating
>> system. Like autoclose applications on Android.
>> 
>> I want stupid thing?
>> 
>> I'm not hard to execute through the cron pkill -9 squidGuard
>> command every hour. But it is a crutch. Did you agree?
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4jn4AAoJENNXIZxhPexG/ggH/2QQ0GyVmADIzd0JIDhYtcn6
BnYGztozSfGlyOCKdp822EtJfVFg+lJN2V3Phcn3iWFmdIhyX2hvvbyBJDfSbLCN
lxciDnRBp5tbnNiKQ0vNuYwH6nwQ4IwR0+5JwXV3RLJ4NlRTgoaeth6owYj7SnXW
2vG2+LWZBK+K5N/rvCtmMLnx9L6A1V2FRHVSio3460pYLzR+T5M/HKKewZ90jqmQ
ibO46Uu8TXI/ckpey7hX0YISlgHBXP8AYTHWL8V3oFP2HSM3aoY3ThD9gCkpdZi+
k99iYHpL6m6OiJIYcQjEc00EX09sEd9EDmcnfPSopk6R88KdUJnNOJWemCr7AI8=
=c+UO
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Mon Feb 16 19:08:08 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 21:08:08 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E239F8.6070605@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com>
Message-ID: <54E24018.5010402@ngtech.co.il>

Hey Yuri,

You missed the whole point.
I didn't wanted you to grep any output.
I wanted to see the whole server process list as a whole to understand 
the issue you see.
If you see the server only with grep you might missing something since I 
have yet to see your server do any swap what so ever until now.

An idle process is fine by nature.
Many systems has many idle processes at the background.
It's in SLEEP mode while waiting for squid to send it's data\request.
What have you seen wrong about it? I am happy to understand.
 From squid point of view idle is not about if the process is in SLEEP 
or IDLE mode and you will see the OS in SLEEP mode while from squid 
aspect it's IDLE.

I have tried to understand what version of squid are you running but 
until now didn't got it.

Some dozens? and what is the cachemgr url_rewrite helper statistics 
output at the time you see the issue?

Eliezer

On 16/02/2015 20:42, Yuri Voinov wrote:
> root @ cthulhu / # ps -efl|grep squidGuard|grep -v grep|awk {'print $2
> " " $5'}
> S 6475
>
> Now you can see one squidGuard process. Squid was restarted hour ago.
>
> Process is idle (no traffic now), but this is as desired by config. As
> you can see, it state is "S", not 'I'. Feel the difference.
>
> The same picture I've observed every night. With some dozens
> redirector processes.




From yvoinov at gmail.com  Mon Feb 16 19:10:44 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 01:10:44 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E24018.5010402@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
Message-ID: <54E240B4.5050609@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I know. Now I see Squid source to determine helper's shutdown logic. I
see helper shutdown subroutine, but not find fire conditions yet.

Look:


root @ cthulhu / # ps -e
   PID TTY         TIME CMD
     0 ?           1:21 sched
     5 ?           6:10 zpool-rp
     6 ?           0:07 kmem_tas
     1 ?           2:38 init
     2 ?           0:00 pageout
     3 ?          14:36 fsflush
     7 ?           0:00 vmtasks
  6477 ?           0:00 ssl_crtd
    11 ?           0:05 svc.star
    13 ?           0:07 svc.conf
   925 ?           0:06 sendmail
    87 ?           9:51 zpool-da
    89 ?           0:04 devfsadm
   769 ?           0:00 sac
   921 ?           1:00 unbound
   358 ?           0:07 ipmon
  1386 ?          11:15 clamd
   498 ?           0:00 picld
   207 ?           0:00 kcfd
   148 ?           0:00 sysevent
   918 ?           0:07 dnscrypt
   705 ?           0:02 cron
   756 ?           0:00 rpcbind
   909 ?           0:17 c-icap
   796 ?           0:01 privoxy
   799 ?           0:00 inetd
   800 ?           0:01 utmpd
   924 ?           4:48 tor
   807 ?           0:00 ttymon
   808 ?           0:04 fmd
   836 ?           0:01 syslogd
   811 console     0:00 ttymon
   939 ?           0:27 munin-no
   917 ?           0:00 sshd
   927 ?          11:54 freshcla
  6486 ?           0:00 diskd
 37146 ?           0:00 httpd.pr
 37143 ?           0:00 httpd.pr
 18321 ?           0:00 httpd.pr
  1141 ?           0:30 xntpd
 37151 pts/1       0:00 bash
  6478 ?           0:00 ssl_crtd
  6479 ?           0:00 ssl_crtd
  6473 ?           0:00 squid
  6483 ?           0:00 diskd
 33784 ?           0:00 c-icap
  6480 ?           0:00 ssl_crtd
 19016 ?           0:00 c-icap
  6476 ?           0:00 ssl_crtd
 18319 ?           0:04 httpd.pr
  6484 ?           0:00 diskd
 14856 ?           0:00 sshd
  6482 ?           0:00 unlinkd
 14859 pts/2       0:00 bash
 37144 ?           0:00 httpd.pr
  6485 ?           0:00 diskd
  6562 ?           0:00 squidGua
 37145 ?           0:00 httpd.pr
 37148 ?           0:00 sshd
 38510 pts/1       0:00 ps
  6475 ?           0:18 squid
  6481 ?           0:00 log_file


17.02.15 1:08, Eliezer Croitoru ?????:
> Hey Yuri,
> 
> You missed the whole point. I didn't wanted you to grep any
> output. I wanted to see the whole server process list as a whole to
> understand the issue you see. If you see the server only with grep
> you might missing something since I have yet to see your server do
> any swap what so ever until now.
> 
> An idle process is fine by nature. Many systems has many idle
> processes at the background. It's in SLEEP mode while waiting for
> squid to send it's data\request. What have you seen wrong about it?
> I am happy to understand. From squid point of view idle is not
> about if the process is in SLEEP or IDLE mode and you will see the
> OS in SLEEP mode while from squid aspect it's IDLE.
> 
> I have tried to understand what version of squid are you running
> but until now didn't got it.
> 
> Some dozens? and what is the cachemgr url_rewrite helper
> statistics output at the time you see the issue?
> 
> Eliezer
> 
> On 16/02/2015 20:42, Yuri Voinov wrote:
>> root @ cthulhu / # ps -efl|grep squidGuard|grep -v grep|awk
>> {'print $2 " " $5'} S 6475
>> 
>> Now you can see one squidGuard process. Squid was restarted hour
>> ago.
>> 
>> Process is idle (no traffic now), but this is as desired by
>> config. As you can see, it state is "S", not 'I'. Feel the
>> difference.
>> 
>> The same picture I've observed every night. With some dozens 
>> redirector processes.
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4kC0AAoJENNXIZxhPexGiusH/i5Ehe5L3M0rKzKLtMjo6dP3
U5e0558XHltSEdQTnfgNSx7OfLOadll/fcg3pobFBKhGMjA5Yn6XMPGisOHJkIdt
y/k1tkVFrY6zsWSMgiED/gswcYK5nASe8VeWqvz4k1J66P0yv7bJ9gAER/bcfzEa
cJoSpOiO7TKNP4kE9IWMp15Cb9yVpd7K2fAjWmnbBF17v2SXqIxlyOA2rIX7yFUu
pAlEBT64Mm0jTInHBYT1iLCNGfg+38nPzXOU6wLH4qXQUD11tp1yNwzuzPlBjTND
UQOz4FCsklaimHFzCzXqMsm1pJRwVj9rQ+aI+i9jEJRyqHOsy8j3tusuZ+9Tf+g=
=JiJg
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Mon Feb 16 19:14:17 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 Feb 2015 21:14:17 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E240B4.5050609@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com>
Message-ID: <54E24189.1030104@ngtech.co.il>

On 16/02/2015 21:10, Yuri Voinov wrote:
> root @ cthulhu / # ps -e

Yuri,

Can you find the right ps command that will include user and memory 
usage by each process?

Thanks,
Eliezer



From yvoinov at gmail.com  Mon Feb 16 19:16:29 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 01:16:29 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E24189.1030104@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
Message-ID: <54E2420D.4010506@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Sure.

Here is it:

root @ cthulhu / # ps -e -o user,pid,rss,comm
    USER   PID  RSS COMMAND
    root     0    0 sched
    root     5    0 zpool-rpool
    root     6    0 kmem_task
    root     1 1360 /sbin/init
    root     2    0 pageout
    root     3    0 fsflush
    root     7    0 vmtasks
   squid  6477 3412 (ssl_crtd)
    root    11 10088 /lib/svc/bin/svc.startd
    root    13 10124 /lib/svc/bin/svc.configd
    root   925 2452 /usr/lib/sendmail
    root    87    0 zpool-data
    root    89 2228 devfsadmd
    root   769 1036 /usr/lib/saf/sac
 unbound   921 113444 /usr/local/sbin/unbound
    root   358  812 /usr/sbin/ipmon
  clamav  1386 303580 /opt/csw/sbin/clamd
    root   498 2152 /usr/lib/picl/picld
  daemon   207 2636 /usr/lib/crypto/kcfd
    root   148 2400 /usr/lib/sysevent/syseventd
    root   918 1040 /usr/local/sbin/dnscrypt-proxy
    root   705 1344 /usr/sbin/cron
  daemon   756 1060 /usr/sbin/rpcbind
   squid   909 1456 /usr/local/bin/c-icap
 privoxy   796 2744 /opt/csw/sbin/privoxy
    root   799 2824 /usr/lib/inet/inetd
    root   800  728 /usr/lib/utmpd
     tor   924 37636 /opt/csw/bin/tor
    root   807 1412 /usr/lib/saf/ttymon
    root   808 10896 /usr/lib/fm/fmd/fmd
    root   836 1948 /usr/sbin/syslogd
    root   811 1552 /usr/lib/saf/ttymon
    root   939 6276 /opt/csw/bin/perl
    root   917  952 /usr/local/sbin/sshd
  clamav   927 4816 /opt/csw/bin/freshclam
   squid  6486 2236 diskd
   squid 37146 1664 /opt/csw/apache2/sbin/httpd
   squid 37143 1664 /opt/csw/apache2/sbin/httpd
   squid 18321 1596 /opt/csw/apache2/sbin/httpd
    root  1141 1364 /usr/lib/inet/xntpd
    root 37151 2512 -bash
   squid  6478 3412 (ssl_crtd)
   squid  6479 3412 (ssl_crtd)
    root  6473 1156 /usr/local/squid/sbin/squid
   squid  6483 2248 diskd
   squid 33784 1616 /usr/local/bin/c-icap
   squid  6480 3412 (ssl_crtd)
   squid 19016 1972 /usr/local/bin/c-icap
   squid  6476 3912 (ssl_crtd)
    root 18319 4576 /opt/csw/apache2/sbin/httpd
   squid  6484 2236 diskd
    root 14856 4028 /usr/local/sbin/sshd
   squid  6482 2064 (unlinkd)
    root 14859 2504 -bash
   squid 37144 1664 /opt/csw/apache2/sbin/httpd
   squid  6485 2264 diskd
   squid  6562 13948 (squidGuard)
   squid 37145 1664 /opt/csw/apache2/sbin/httpd
    root 37148 3928 /usr/local/sbin/sshd
    root 41220 1528 ps
   squid  6475 161260 (squid-1)
   squid  6481 2176 (logfile-daemon)



17.02.15 1:14, Eliezer Croitoru ?????:
> On 16/02/2015 21:10, Yuri Voinov wrote:
>> root @ cthulhu / # ps -e
> 
> Yuri,
> 
> Can you find the right ps command that will include user and
> memory usage by each process?
> 
> Thanks, Eliezer
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4kIMAAoJENNXIZxhPexGzNsH/iVK+oGhRhM54RmJKQi+LVhj
xqm9rKJlMpha4ayApTp+kDtRUXQLtO9mDt6FRF+YyTiF15WTMtuqHm/Ln4VvZ7mX
3CnIu8Zopc+fxNRZUhHODhY9C5VoXLUKPampLAnooi5m2m30IoXd6HJkLXnB5C7h
gSTt2PNAwbgRpMStGb6PuXKOIzac1g6VNFXGRSg/wVnnAZCgpWAlUCzutNUQr7Rw
9qYY0meRYE2xRe2YiUBaBaWPlAqxNVLMnb09iiiiAVSua3t6rWX56ueImUQGezHA
toSDK6avzPbPc7hiaQ1GbZGbVq5RoL/NG1hFK+UMKwNdxKydxpdcTk26NW0psi0=
=aENM
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Mon Feb 16 19:56:33 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 01:56:33 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E24189.1030104@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
Message-ID: <54E24B71.1090406@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Now:

2015/02/16 23:10:23 kid1|   store_swap_size = 29826351.50 KB
2015/02/16 23:10:24 kid1| storeLateRelease: released 0 objects
2015/02/16 23:15:01 kid1| Starting new redirector helpers...
2015/02/16 23:15:01 kid1| helperOpenServers: Starting 1/100
'squidGuard' processes
2015/02/17 01:40:15 kid1| Starting new redirector helpers...
2015/02/17 01:40:15 kid1| helperOpenServers: Starting 1/100
'squidGuard' processes
^Croot @ cthulhu / # ps -e -o user,pid,rss,comm
    USER   PID  RSS COMMAND
    root     0    0 sched
    root     5    0 zpool-rpool
    root     6    0 kmem_task
    root     1 1360 /sbin/init
    root     2    0 pageout
    root     3    0 fsflush
    root     7    0 vmtasks
   squid  6477 3412 (ssl_crtd)
    root    11 10088 /lib/svc/bin/svc.startd
    root    13 10124 /lib/svc/bin/svc.configd
    root   925 2452 /usr/lib/sendmail
    root    87    0 zpool-data
    root    89 2228 devfsadmd
    root   769 1036 /usr/lib/saf/sac
 unbound   921 113444 /usr/local/sbin/unbound
    root   358  812 /usr/sbin/ipmon
  clamav  1386 303580 /opt/csw/sbin/clamd
    root   498 2152 /usr/lib/picl/picld
  daemon   207 2636 /usr/lib/crypto/kcfd
    root   148 2400 /usr/lib/sysevent/syseventd
    root   918 1040 /usr/local/sbin/dnscrypt-proxy
    root   705 1344 /usr/sbin/cron
  daemon   756 1060 /usr/sbin/rpcbind
   squid   909 1456 /usr/local/bin/c-icap
 privoxy   796 2744 /opt/csw/sbin/privoxy
    root   799 2824 /usr/lib/inet/inetd
    root   800  728 /usr/lib/utmpd
     tor   924 37636 /opt/csw/bin/tor
    root   807 1412 /usr/lib/saf/ttymon
    root   808 10896 /usr/lib/fm/fmd/fmd
    root   836 1948 /usr/sbin/syslogd
    root   811 1552 /usr/lib/saf/ttymon
    root   939 6276 /opt/csw/bin/perl
    root   917  952 /usr/local/sbin/sshd
  clamav   927 4816 /opt/csw/bin/freshclam
   squid  6486 2252 diskd
   squid 37146 1664 /opt/csw/apache2/sbin/httpd
   squid 18321 1596 /opt/csw/apache2/sbin/httpd
    root  1141 1364 /usr/lib/inet/xntpd
   squid 47986 1616 /usr/local/bin/c-icap
    root 37151 2512 -bash
   squid  6478 3412 (ssl_crtd)
   squid  6479 3412 (ssl_crtd)
    root  6473 1156 /usr/local/squid/sbin/squid
   squid  6483 2248 diskd
   squid 33784 2024 /usr/local/bin/c-icap
   squid  6480 3412 (ssl_crtd)
    root 50700 1528 ps
   squid  6476 3912 (ssl_crtd)
    root 18319 4576 /opt/csw/apache2/sbin/httpd
   squid  6484 2260 diskd
    root 14856 4028 /usr/local/sbin/sshd
   squid  6482 2064 (unlinkd)
    root 14859 2504 -bash
   squid 37144 1664 /opt/csw/apache2/sbin/httpd
   squid  6485 2264 diskd
   squid  6562 14284 (squidGuard)
   squid 37145 1664 /opt/csw/apache2/sbin/httpd
    root 37148 3952 /usr/local/sbin/sshd
   squid 47988 11900 (squidGuard)
   squid  6475 161332 (squid-1)
   squid  6481 2176 (logfile-daemon)

As you can see, two redirectors started. Now is 1:53 AM. Activity is
zero over 15 minutes.

Configuration is:

url_rewrite_program /usr/local/bin/squidGuard -c
/usr/local/squidGuard/squidGuard.conf
url_rewrite_children 100 startup=0 idle=1 concurrency=0

I.e, second process must be down, correct? Idle=1, so, only one
redirector process must remains.

But we seen two redirectors. One of them is completely idle.

Look, activity is gone:

root @ cthulhu / # squidview
                                Mon Pri | h = help
0.0.1         cache_object://localhost/info
0.0.1         cache_object://localhost/info
0.0.1         cache_object://localhost/server_list
0.0.1         cache_object://localhost/server_list
0.0.1         cache_object://localhost/counters
0.0.1         cache_object://localhost/info
0.0.1         cache_object://localhost/counters
0.0.1         cache_object://localhost/storedir
0.0.1         cache_object://localhost/info
0.0.1         cache_object://localhost/info
0.0.1         cache_object://localhost/server_list
0.0.1         cache_object://localhost/server_list
0.0.1         cache_object://localhost/counters
0.0.1         cache_object://localhost/info
0.0.1         cache_object://localhost/counters
0.0.1         cache_object://localhost/storedir
0.0.1         cache_object://localhost/info
0.0.1         cache_object://localhost/info
0.0.1         cache_object://localhost/server_list
0.0.1         cache_object://localhost/server_list
0.0.1         cache_object://localhost/counters
0.0.1         cache_object://localhost/info
0.0.1   cache_object://localhostcounters
100.00% Tue Feb 17 01:55 2015



17.02.15 1:14, Eliezer Croitoru ?????:
> On 16/02/2015 21:10, Yuri Voinov wrote:
>> root @ cthulhu / # ps -e
> 
> Yuri,
> 
> Can you find the right ps command that will include user and
> memory usage by each process?
> 
> Thanks, Eliezer
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU4ktxAAoJENNXIZxhPexGIisH/jvrG3LLjv3GBdsLxagtnjmt
/VLCMOPC3xp/M8aiLaIPC8HCUp1maLiFT3LNi190r1mf3WHjU80qMil2kaMB26C3
baJfjPkKS2Pkh4gus4u/kNSHPuO+cMyavFtph0j+Y0IjpqHW895w/LWAjiWXtPSI
aRze/q1yZ9KYQwFE4R7MrXAw3Gli7W3wVtW2w+g6KvofwHUMD1PwLa2+X4SOcsey
UwzMarPOLiGBac0RJgkJQLtzdeFjf7GCxNCoWJFTbzy6GZ8UHMGtUIIgMLbzZci3
Xpj7rqqdRm0ZzsNb19oLpJvXtFGw7O4+y1DUb6KIMZY0/kQGKMwq+i3YxL2/sUI=
=URcr
-----END PGP SIGNATURE-----


From huaraz at moeller.plus.com  Mon Feb 16 20:25:12 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Mon, 16 Feb 2015 20:25:12 -0000
Subject: [squid-users] benefitsofusingext_kerberos_ldap_group_aclinstead
	of ext_ldap_group_acl
In-Reply-To: <EE58FC57-6B97-4DE6-9FDF-2881209A5AB3@open.ch>
References: <mailman.42287.1423690543.1833.squid-users@lists.squid-cache.org>
 <A77FDA65-6F38-4C4F-A323-C1B749878B5A@open.ch>
 <54DCDBCD.5070909@treenet.co.nz>
 <3BFE59DF-A379-49E6-B177-D4A86DE7678D@open.ch> <mbnmv8$sdd$1@ger.gmane.org>
 <EE58FC57-6B97-4DE6-9FDF-2881209A5AB3@open.ch>
Message-ID: <mbtjna$h0f$1@ger.gmane.org>

Good to hear.  It seems freebsd  has com_err.h why I did not come across it lately.

Markus

"Simon St?heli" <sis at open.ch> wrote in message news:EE58FC57-6B97-4DE6-9FDF-2881209A5AB3 at open.ch...

On 14.02.2015, at 15:43, Markus Moeller <huaraz at moeller.plus.com> wrote:



    On 12.02.2015, at 17:58, Amos Jeffries <squid3 at treenet.co.nz> wrote:


      On 13/02/2015 5:41 a.m., Simon St?heli wrote:


        hmh, HAVE_KRB5 seems not to be set in include/autoconf.h

        What is the correct way to provide squid the path to the kerberos header files?

        ./configure ?help doesn?t show a useful option as --with-krb5-config= seems not to be the right option.


      If you are using Squid-3.4 or older versions where that option exists,
      you need to insted use CXXFLAGS to set the -I (library headers) and -L
      (library binary) locations.
      Something like:
      ./configure CXXFLAGS="-I/path/to/include -L/path/to/lib" ?



    Thx for the hint! Tried ./configure CXXFLAGS="-I/opt/krb5/include -L/opt/krb5/lib" --prefix=/opt/squid --sysconfdir=/opt/squid/etc --enable-auth --enable-auth-negotiate="kerberos" --enable-external-acl-helpers=?kerberos_ldap_group? but without success. The /opt/krb5/ paths have been set in the Makefile, but HAVE_KRB5 is still no defined. Anything else to do here? (used Squid-3.4.11)





      Squid-3.5 and later have per-library ./configure options. In the case of
      Heimdal use --with-heimdal-krb5=PATH



    tried it with Squid-3.5 and --with-heimdal-krb5=PATH and seems to work until make tries to compile kerberos_ldap_group

    make[2]: Entering directory `/usr/src/packages/src/squid-3.5.1/helpers/external_acl/kerberos_ldap_group'
    g++ -DHAVE_CONFIG_H   -I../../.. -I../../../include -I../../../lib -I../../../src -I../../../include  -I/opt/krb5/include  -I/opt/krb5/include   -I.  -Wall  -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Werror -pipe -D_REENTRANT -m64 -I/opt/krb5/include   -I/opt/krb5/include -L/opt/krb5/lib -march=native -MT support_krb5.o -MD -MP -MF .deps/support_krb5.Tpo -c -o support_krb5.o support_krb5.cc
    cc1plus: warnings being treated as errors
    support_krb5.cc: In function 'int krb5_create_cache(char*)':
    support_krb5.cc:89:9: error: 'const char* krb5_get_err_text(krb5_context_data*, krb5_error_code)' is deprecated (declared at /opt/krb5/include/krb5-protos.h:2089)
    ...
    make[2]: *** [support_krb5.o] Error 1
    make[2]: Leaving directory `/usr/src/packages/src/OSAGsquid-sis/squid-3.5.1/helpers/external_acl/kerberos_ldap_group?

    my Heimdal Kerberos (Heimdal 1.3.3) libs seemed no to be compatible with kerberos_ldap_group?!




  I am a bit surprised as I did not see this when testing on freebsd with heimdal.   I update my  trunk version at https://code.launchpad.net/~huaraz/squid/kerberos-updates. Can you test with that and if OK I will ask to include the updates.




Your trunk version works perfectly. Thank you very much Markus!





      Amos

      _______________________________________________
      squid-users mailing list
      squid-users at lists.squid-cache.org
      http://lists.squid-cache.org/listinfo/squid-users




  Markus 

  _______________________________________________
  squid-users mailing list
  squid-users at lists.squid-cache.org
  http://lists.squid-cache.org/listinfo/squid-users




--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150216/e55b2ec2/attachment.htm>

From alfrenovsky at gmail.com  Mon Feb 16 21:30:18 2015
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Mon, 16 Feb 2015 18:30:18 -0300
Subject: [squid-users] OOKLA speedtest can't upload with squid
Message-ID: <CAMXC=WtfPFjqMBnqwZSY5+c9d-eK2_mvFcRUAveB+gG1z1-WMQ@mail.gmail.com>

I'm using a custom compiled version
Squid Cache: Version 3.5.1-20150206-r13746
Service Name: squid
configure options:  '--disable-auth' '--disable-auto-locale'
'--disable-cache-digests' '--disable-cpu-profiling'
'--disable-debug-cbdata' '--disable-delay-pools' '--disable-devpoll'
'--disable-ecap' '--disable-esi' '--disable-eui'
'--disable-external-acl-helpers' '--disable-follow-x-forwarded-for'
'--disable-forw-via-db' '--enable-gnuregex' '--disable-htcp'
'--disable-icap-client' '--disable-ident-lookups' '--enable-internal-dns'
'--disable-ipf-transparent' '--disable-ipfw-transparent' '--disable-ipv6'
'--disable-leakfinder' '--disable-pf-transparent' '--disable-poll'
'--disable-select' '--disable-snmp' '--enable-ssl' '--disable-stacktraces'
'--disable-translation' '--disable-url-rewrite-helpers' '--disable-wccp'
'--disable-wccpv2' '--disable-win32-service' '--disable-x-accelerator-vary'
'--disable-icmp' '--disable-storeid-rewrite-helpers' '--enable-async-io'
'--enable-disk-io' '--enable-epoll' '--enable-http-violations'
'--enable-inline' '--enable-kill-parent-hack' '--enable-linux-netfilter'
'--enable-log-daemon-helpers' '--enable-removal-policies'
'--enable-storeio' '--enable-unlinkd' '--enable-x-accelerator-vary'
'--enable-zph-qos' '--with-default-user=nobody' '--with-pthreads'
'--with-included-ltdl' '--with-netfilter-conntrack' '--disable-arch-native'
--enable-ltdl-convenience

I tried to simplify my squid.conf to this:

http_port 3128 transparent
http_access allow all
strip_query_terms off
access_log stdio:/var/log/squid/access.log
cache deny all

And still can't do an upload test with ookla products.

When accessing http://www.speed.com.do I get this access.log

1424121146.052    358 10.55.127.10 TCP_MISS/304 251 GET
http://www.speed.com.do/ - ORIGINAL_DST/200.88.127.14 -
1424121149.705    190 10.55.127.10 TCP_MISS/200 3743 GET
http://www.speed.com.do/settings.xml?x=1424121149355 - ORIGINAL_DST/
200.88.127.14 application/xml
1424121150.334    385 10.55.127.10 TCP_MISS/200 519 GET
http://api.ookla.com/ipaddress.php - ORIGINAL_DST/72.21.92.82 text/html
1424121168.694    587 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121168097 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121168.982    184 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121168744 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121169.212    191 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121169010 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121169.458    186 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121169260 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121169.721    188 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121169526 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121169.977    177 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121169793 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121170.305    212 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121170011 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121170.532    180 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121170344 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121170.777    178 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121170593 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121171.034    200 10.55.127.10 TCP_MISS/200 363 GET
http://www.speed.com.do/speedtest/latency.txt?x=1424121170826 -
ORIGINAL_DST/200.88.127.14 text/plain
1424121175.336   3733 10.55.127.10 TCP_MISS/200 1118375 GET
http://www.speed.com.do/speedtest/random750x750.jpg?x=1424121171593&y=1 -
ORIGINAL_DST/200.88.127.14 image/jpeg
1424121177.454   5846 10.55.127.10 TCP_MISS/200 1118375 GET
http://www.speed.com.do/speedtest/random750x750.jpg?x=1424121171593&y=2 -
ORIGINAL_DST/200.88.127.14 image/jpeg
1424121185.545   8021 10.55.127.10 TCP_MISS/200 1986647 GET
http://www.speed.com.do/speedtest/random1000x1000.jpg?x=1424121177504&y=2 -
ORIGINAL_DST/200.88.127.14 image/jpeg
1424121188.656  11135 10.55.127.10 TCP_MISS/200 1986647 GET
http://www.speed.com.do/speedtest/random1000x1000.jpg?x=1424121177504&y=1 -
ORIGINAL_DST/200.88.127.14 image/jpeg
1424121191.109    377 10.55.127.10 TCP_MISS/500 1564 POST
http://www.speed.com.do/speedtest/upload.asp?x=0.5987499579787254 -
ORIGINAL_DST/200.88.127.14 text/html
1424121191.134    399 10.55.127.10 TCP_MISS/500 1557 POST
http://www.speed.com.do/speedtest/upload.asp?x=0.8488976825028658 -
ORIGINAL_DST/200.88.127.14 text/html

If I do a traffic analisys in the internet traffic I can see the server
sends squid an Internal Server Error (500) at the middle of the POST
(BEFORE the POST is complete).

The error comes from the server. But this doesn't happens in squid 3.4 or
with a direct connection.

The POST content-length is 26761 So I don't think buffers may be a problem.

?Any clue?

-- 
Alfrenovsky
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150216/0fc93356/attachment.htm>

From eliezer at ngtech.co.il  Mon Feb 16 22:00:34 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 17 Feb 2015 00:00:34 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E24B71.1090406@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
 <54E24B71.1090406@gmail.com>
Message-ID: <54E26882.6050608@ngtech.co.il>

Hey Yuri,

OK I have seen something...
Now we might need also the virtual memory which might be vsz.
And the cachemgr output is not from squidview..
The last image I have seen from cachemgr was much helpful(with 10 helpers).

 From what I have seen until now squidGuard uses about 13 MB of ram 
constantly.
If this is what it costs to run a squidGuard helper you should consider 
that it has some peak usage time and lower bound usage time and you will 
need to calculate how much helpers you need to provide smooth surfing on 
peak usage time.
You should consider this peak usage as the required memory from 
squidGuard for smooth operation.
Since not you and not will be able to change the basic memory 
footprint(required) for squidGuard you will need to somehow decide if 
you require a much efficient software or to adjust your system accordingly.

I would agree that 100 * 13 MB of ram means about 1.3 GB of ram usage 
and might not be acceptable for a "simple" filtering mechanism.

The main reasons for the unknown need for 100 helpers might be since it 
was not designed to be used this way.
I must say that squidGuard is a very good piece of software but it lacks 
couple things which might make it un-usable for some if not many systems 
and maybe including yours.
Indeed in your case there is a chance that if you will even install a 
full blown DB that will be stored all in ram and you will write a helper 
that will mimic squidguard functionality\logic with concurrency support 
you will get much less memory consumption with much more efficient 
request handling.

It is much smarter to write a helper which will have a overall 
efficiency mark on it then to add into squid something that might not be 
even needed in the first place.

For now before writing any helper etc I will want to see the cachemgr 
interface output for the "redirector" option in two cases:
- startup
- after midnight when there are lots of helpers running under squid

You can see that squid since version 3.2 squid offers access to the 
squid cache manager interface using a simple url such as:
"http://filter:3128/squid-internal-mgr/redirector"
(using the visible_hostname and the forward proxy port of squid)

All The Bests,
Eliezer

On 16/02/2015 21:56, Yuri Voinov wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Now:
>
> 2015/02/16 23:10:23 kid1|   store_swap_size = 29826351.50 KB
> 2015/02/16 23:10:24 kid1| storeLateRelease: released 0 objects
> 2015/02/16 23:15:01 kid1| Starting new redirector helpers...
> 2015/02/16 23:15:01 kid1| helperOpenServers: Starting 1/100
> 'squidGuard' processes
> 2015/02/17 01:40:15 kid1| Starting new redirector helpers...
> 2015/02/17 01:40:15 kid1| helperOpenServers: Starting 1/100
> 'squidGuard' processes
> ^Croot @ cthulhu / # ps -e -o user,pid,rss,comm




From squid3 at treenet.co.nz  Mon Feb 16 22:01:21 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 11:01:21 +1300
Subject: [squid-users] Add header to SSL requests to my own domain using
 my domains certs
In-Reply-To: <CA+NB0u-y1k7UVNr1TDqXv3ACrBqsjcoteuW_2=w2+QRiaQFEFw@mail.gmail.com>
References: <CA+NB0u97zWq7YVmo7T+eC37wXXPUiiD31z8ZrD=+nEeEGe6cgg@mail.gmail.com>	<54E11FB1.8040702@gmail.com>	<CA+NB0u9jxEN4WV3SvkSxdNuR=C8yyrD3=xctmL6Fhu-UhmrdXg@mail.gmail.com>	<54E121D1.8000101@gmail.com>	<54E13D94.2000205@treenet.co.nz>
 <CA+NB0u-y1k7UVNr1TDqXv3ACrBqsjcoteuW_2=w2+QRiaQFEFw@mail.gmail.com>
Message-ID: <54E268B1.9070203@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 16/02/2015 3:38 p.m., James Beecham wrote:
> Hi Amos,
> 
> Thank you for your reply.
> 
> The information I need to apply to the header is client specific,
> ex their internal ip address.
> 
> The issue I am facing is that the network that is hosting the web
> services is different from the network that the clients are
> accessing it from. So my Squid instances live at the client site
> and they access the web services out of a data center.
> 
> I need to know the clients internal ip at the data center for a
> number of reasons. Therefore if I am understanding your suggestion
> correctly the reverse ssl proxy would not work as the squid reverse
> proxy needs to be on the same internal network/vlan as the
> destination host to function? 
> http://wiki.squid-cache.org/ConfigExamples/Reverse/SslWithWildcardCertifiate

No.
> 
Reverse-proxy only needs is that the client looking up the domain
in DNS finds where it is and the cert it offers is valid for the domain.

The connection between the proxy and origin server is
explicitly/manually configured at the proxy so does not matter where
its going to.

Think of how the major CDN operators put their gateway proxies out
around the world in or near ISP networks then do something special
from that proxy to where the hosted site actually is.

> 
> Essentially what I have is the clients internal ip at the client
> site, which with HTTP only used to allow me the pack the internal
> ip into the HTTP header via 'request_header_add'. Now, I still need
> to get the internal ip into the HTTPS request so that the web
> services can operate as normal. Whether the clients internal ip is
> in the header or apart of each request (query param) doesnt really
> matter, just how can I get the internal ip to the server without
> disrupting the normal browsing activity of our users?


This is what the X-Forwarded-For/Forwarded HTTP headers are for.
Set "forwarded_for on" in squid.conf of the gateway proxy the clients
connect to, and the same or "forwarded_for transparent" on any
internal squid proxies it goes across within your network.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU4miwAAoJELJo5wb/XPRjasUH/jf6ZHo75tqmKdW/gQcYtHKl
Et38pBbvXXIJ9/+DE/DvrW/t4LJU1tuxFk/uplwvORqOyZ2VNy/mxp1Omf3NMKoG
SfUo3LTOqlvIAtI1oHZYadS9qEsIDxSGDJ0HFeag7z9wj4acOeUnVSBLUueyV5TK
ouspgmpuS3GCCqMWjWsEkdUKqDXC+ThyUeF7w0ABfZIXoJPtC2Q++7UznQm840ad
lV4lLx/vxbXSEFlR+YEZXJwEBUwcKr9uUDVru7Rn4LfIZ9KRr6gVbzwzFMuilY0P
GmMJBYMDZZSezvtVA2vAR99KbDpUSC/8seGL2VrXZxNndh8eSmK5kprlUvwIC1w=
=Ra8E
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Mon Feb 16 22:17:22 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 11:17:22 +1300
Subject: [squid-users] Error when using peek/splice/terminate with Squid
 3.5.1
In-Reply-To: <DBXPR04MB493572511458A97F114279B862E0@DBXPR04MB493.eurprd04.prod.outlook.com>
References: <DBXPR04MB493572511458A97F114279B862E0@DBXPR04MB493.eurprd04.prod.outlook.com>
Message-ID: <54E26C72.3000702@treenet.co.nz>

On 16/02/2015 6:54 p.m., John Killimangalam Jacob wrote:
> Hi All,
> 
> I am trying to configure an intercept proxy with
> peek/splice/terminate features in Squid 3.5.1 on CentOS 7 - 64 bit. I
> wanted to peak at steps 1 and step 2 and to decide on terminate on
> step 3 based on the SNI and server certificate values. It is working
> only for https://www.google.com, but lot of other ssl sites (likes of
> https://www.yahoo.com etc) are not getting loaded logging an " Error
> negotiating SSL on FD 36: error:140920E3:SSL
> routines:SSL3_GET_SERVER_HELLO:parse tlsext  "  in the cache.log
> (trying the same sites using openssl s_client command works). I was
> wondering if it has to do anything with my config or open ssl
> (version 1.0.1e) or anything else. The web sites are being accessed
> from a windows 7 workstation with IE 8 and Firefox 35.0.1 . Below is
> the squid.config section for peek and splice I am using.
> 

Your config looks fine to me. The complaints seem to be about peek on
the server TLS-extensions values havign something unknown in them.

There is a bug winding its way through QA right now to fix interaction
of peek/stare ons erver connections with sslproxy_options setting.
The workaround is to not set sslproxy_options for now.


I dont think OpenSSL version is related (maybe, maybe not) but do try to
use the latest OpenSSL version you can just because of security
vulnerabilities and bug fixes found in it over the last few months.

Also, there are SNI fixes in the latest 3.5.1 snapshot you will be needing.


PS. You may want to seriously consider removing that disclaimer from
public posts, particularly when discussing the legally borderline topic
of SSL-bump.

Amos



From squid3 at treenet.co.nz  Mon Feb 16 22:34:27 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 11:34:27 +1300
Subject: [squid-users] reverse-proxy with client certificates pass-thru
In-Reply-To: <DUB407-EAS313BF2AC598B078EB64EC55F42E0@phx.gbl>
References: <DUB407-EAS313BF2AC598B078EB64EC55F42E0@phx.gbl>
Message-ID: <54E27073.8010301@treenet.co.nz>

On 17/02/2015 3:16 a.m., Martin Fuchs wrote:
> Hi !
> 
>  
> 
> I'm looking for a possibility to tell squid to pass a certificate presented
> by the client to a cache peer.
> 
> Since i did not find anything, i decided to ask here ;-)
> 
> I saw that it's possibe to let squid pass a client crtificate tot he cache
> peer, but this would not work for out purposes.
> 
>  
> 
> It's an apple mobile device management system which needs to authenticate
> the clients by their certificates.
> 
> Does anyone have apple remote profile-management running thru a
> reverse-proxy with squid ?

Reverse proxy terminate the HTTPS connection. The client cert only
applies to validate the connection between client and Squid, and Squid
does not have the clients private key needed to encrypt traffic from
that client.

There is splice mode in 3.5. Which is to say "dont bump that traffic".

The proper setup is for the proxy to have a cert representing itself
which it uses to validate the HTTPS with backend service. But I dont
know enough about the Apple system to say if that works like its
supposed to or if they are tying the cert to what data is accessible.


> 
> This dirctive alone does not work:
> 
> cache_peer xx.xx.xx.xx parent 443 0 proxy-only no-query no-digest
> originserver login=PASSTHRU ssl sslflags=DONT_VERIFY_PEER front-end-https=on
> name=MDM_HOST_443


PS. DONT_VERIFY_PEER is evil. It basically tells Squid not to care what
the encryption is doing on the connection. You may as well be using
plain-text for all the security offers now.

The correct configuration is to have the remote peers CA (and CA chain)
configured as trusted for this peer. Adding that CA to the system
trusted CA set works but is risky, adding it just for those connections
with cache_peer sslcafile=/sslcapath= option is best.

Amos


From squid3 at treenet.co.nz  Mon Feb 16 22:45:02 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 11:45:02 +1300
Subject: [squid-users] ssl proxy error: No valid signing SSL certificate
 configured for https_port [::]:3127
In-Reply-To: <54E217D5.70005@yahoo.com>
References: <54E1115E.3040804@yahoo.com> <54E1144C.2040503@ngtech.co.il>
 <54E217D5.70005@yahoo.com>
Message-ID: <54E272EE.8040506@treenet.co.nz>

On 17/02/2015 5:16 a.m., Alan Palmer wrote:
> Tried the two links provided, still no luck.
> 
> details:
> squid -v
> Squid Cache: Version 3.4.11
> configure options:  '--disable-strict-error-checking'
> '--disable-arch-native' '--enable-shared'
> '--datadir=/usr/local/share/squid'
> '--libexecdir=/usr/local/libexec/squid' '--disable-loadable-modules'
> '--enable-arp-acl' '--enable-auth' '--enable-delay-pools'
> '--enable-follow-x-forwarded-for' '--enable-forw-via-db'
> '--enable-http-violations' '--enable-icap-client' '--enable-ipv6'
> '--enable-referer-log' '--enable-removal-policies=lru heap'
> '--enable-ssl' '--with-openssl' '--enable-storeio=aufs ufs diskd'
> '--with-default-user=_squid' '--with-filedescriptors=8192'
> '--with-krb5-config=no' '--with-pidfile=/var/run/squid.pid'
> '--with-pthreads' '--with-swapdir=/var/squid/cache'
> '--disable-pf-transparent' '--enable-ipfw-transparent'
> '--enable-external-acl-helpers=LDAP_group SQL_session file_userip
> time_quota session  unix_group wbinfo_group LDAP_group
> eDirectory_userip' '--prefix=/usr/local' '--sysconfdir=/etc/squid'
> '--mandir=/usr/local/man' '--infodir=/usr/local/info'
> '--localstatedir=/var/squid' '--disable-silent-rules' 'CC=cc'
> 'CFLAGS=-O2 -pipe' 'LDFLAGS=-L/usr/local/lib'
> 'CPPFLAGS=-I/usr/local/include' 'CXX=c++' 'CXXFLAGS=-O2 -pipe'
> '--enable-ssl-crtd' --enable-ltdl-convenience
> 
> tail -10 squid.conf
> https_port 3127 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl_cert/server1.crt
> sslcrtd_program /usr/local/libexec/squid/ssl_crtd -s
> /usr/local/squid/var/lib/ssl_db -M 16MB
> sslcrtd_children 10
> ssl_bump server-first all
> 
> cert generation
> openssl genrsa -des3 -passout pass:x -out server.pass.key 2048
> openssl rsa -passin pass:x -in server.pass.key -out server.key
> rm server.pass.key
> openssl req -new -key server.key -out server.csr
> openssl req -new -key server.key -out server.csr
> openssl x509 -req -days 730 -in server.csr -signkey server.key
> openssl x509 -req -days 730 -in server.csr -signkey server.key -out
> server.crt
> cat server.key server.crt > server1.crt
> 

All of that process is what the "generate-host-certificates=on" does.

The server1.crt file contains the output bytes Squid will be sending
on-the-wire, not what the cert= input parameter needs.



> squid -z
> FATAL: No valid signing SSL certificate configured for https_port
> 0.0.0.0:3127

Which is correct.
The file "server1.crt" contains a server cert not a CA cert.

> Squid Cache (Version 3.4.11): Terminated abnormally.
> CPU Usage: 0.080 seconds = 0.060 user + 0.020 sys
> Maximum Resident Size: 6752 KB
> Page faults with physical i/o: 0
> 
> cert generation ala
> http://wiki.squid-cache.org/EliezerCroitoru/Drafts/SSLBUMP (squid.conf
> changed to cert=/etc/squid/ssl_cert/myCA.pem)
> 

That is a draft, and a bit outdated.

Use this instead:
 http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit


> openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keyout
> myCA.pem -out myCA.pem
> 
> squid -z
> FATAL: No valid signing SSL certificate configured for https_port [::]:3127
> Squid Cache (Version 3.4.11): Terminated abnormally.

Notice how the port details have changed from IPv4-only to IPv6-only.

You are using a split-stack OS where each of the IPv4 and IPv6 ports
needs separate TLS/SSL context. You can set the same settings and load
the same cert file, just have to place the config separately in
squid.conf for now:


https_port 0.0.0.0:3127 intercept ssl-bump \
  generate-host-certificates=on \
  dynamic_cert_mem_cache_size=16MB \
  cert=/etc/squid/ssl_cert/server1.crt

https_port [::]:3127 intercept ssl-bump \
  generate-host-certificates=on \
  dynamic_cert_mem_cache_size=16MB \
  cert=/etc/squid/ssl_cert/server1.crt


Amos



From squid3 at treenet.co.nz  Mon Feb 16 22:55:18 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 11:55:18 +1300
Subject: [squid-users] login expired
In-Reply-To: <1424107729424-4669882.post@n4.nabble.com>
References: <1423176194436-4669574.post@n4.nabble.com>
 <54D481BB.3010308@treenet.co.nz> <1423290748208-4669607.post@n4.nabble.com>
 <54D5C95D.3050101@treenet.co.nz> <1424107729424-4669882.post@n4.nabble.com>
Message-ID: <54E27556.20900@treenet.co.nz>

On 17/02/2015 6:28 a.m., Ignazio Raia wrote:
> Hi Amos 
> I finally made the changes you suggested and now I have squid asks
> authentication as required.
> I still have two troubles:
> 1) the directive auth_param basic credentialsttl 60 seconds doesn't work.
> Squid doesn't ask me a new login request

It is not meant to. That directive is how often Squid checks the
credentials it has cached for validity. Unless the credentials are
actully invalid when Squid re-checks them you should not see anything.


> 2) If I use Internet Explorer I don't have the login request (I.e., is
> configured to use proxy)

See if its using SSO with your machines login account, or has the
password stored in the browser password manager.

With either of those the credentials should still show up in access.log,
but "the popup" already happened way back when the user has logged into
their machine or browser.

(Yes, Basic auth contains SSO. All that talk about SSO being a feature
of NTLM is marketing BS.)

Amos



From squid3 at treenet.co.nz  Mon Feb 16 23:01:15 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 12:01:15 +1300
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E20C7F.9050105@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
 <54E1EF44.6030507@gmail.com> <54E205B0.50807@ngtech.co.il>
 <54E20C7F.9050105@gmail.com>
Message-ID: <54E276BB.2070101@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 17/02/2015 4:27 a.m., Yuri Voinov wrote:
> Yep.
> 
> 16.02.15 20:58, Eliezer Croitoru ?????:
>> On 16/02/2015 15:23, Yuri Voinov wrote:
>>> http://i58.tinypic.com/rsqwxh.png
>>> 
>>> 0 shutting down. Always.
>>> 
>>> During nights and weekends.

Um, how often do you run "squid -k rotate" ??

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU4na7AAoJELJo5wb/XPRjQI8H/RovqwldDet9cVGefc36TRNx
c9OsYDTcHPUbIlSXg7K3ZJOa1+EFqWrZC4btLYZHdjQRwpLs9nl9pVxm4Q3e9911
iriwgcYKXI9u6NNaTQmUSob7rU7+Y3kxRzLHUp+A+pLsekMocus1qwYujOUxfzUP
1Vrg5HfEKeI7d9wSaf7Tq2P4FGwFDsg85Uddro0ycx0qJpC+PmKOYmFpst7s+WqG
5qags64+BcgG40PupNzJ8F/8LCxv80+q3ikXBRcfwFRm8LcVfkQqeye11oKGjxQl
HvY5PwV796QhkOkv6vEts3jOnKDKLJ7McbeWSeGyfKRaviw1RWcUMzCFyPdrUF8=
=djSX
-----END PGP SIGNATURE-----


From Jason_Haar at trimble.com  Mon Feb 16 23:03:52 2015
From: Jason_Haar at trimble.com (Jason Haar)
Date: Tue, 17 Feb 2015 12:03:52 +1300
Subject: [squid-users] reverse-proxy with client certificates pass-thru
In-Reply-To: <54E27073.8010301@treenet.co.nz>
References: <DUB407-EAS313BF2AC598B078EB64EC55F42E0@phx.gbl>
 <54E27073.8010301@treenet.co.nz>
Message-ID: <54E27758.4040402@trimble.com>

On 17/02/15 11:34, Amos Jeffries wrote:
> There is splice mode in 3.5. Which is to say "dont bump that traffic".

If you have a reverse-proxy between a client and backend server and the
backend server insists on seeing the client cert, then I think at best
squid is simply a tcp forwarder (ie splice mode). It could be easier to
put a xinetd-based forwarder in place or even to publish the backend
onto the Internet directly. Basically squid can add nothing

We're going through the same process with Microsoft's SCCM server. The
agents use client certs, but we're hoping we can disable the requirement
for client certs on the backend and get the DMZ "security portal" to do
that check itself (as we trust patching our "security portal" more than
patching Microsoft apps). However, that probably won't work and then we
too will be basically doing a tcp forward...

In all fairness, any HTTPS web server that is kept patched, and which
requires validating client certs before even getting to the home page is
an extremely hard target to hack. Irrespective of the security quality
of the web application itself, if the bad guys can't actually interact
with the web app (because they have no client cert), then their options
are extremely limited

-- 
Cheers

Jason Haar
Corporate Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1



From squid3 at treenet.co.nz  Mon Feb 16 23:08:02 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 12:08:02 +1300
Subject: [squid-users] cache peer load balancing round robin problem
In-Reply-To: <54E20921.8040804@ngtech.co.il>
References: <000a01d04a3b$8c8ad8e0$a5a08aa0$@netstream.ps>
 <201502161324.39873.Antony.Stone@squid.open.source.it>
 <001401d04a43$77b1a720$6714f560$@netstream.ps>
 <54E20921.8040804@ngtech.co.il>
Message-ID: <54E27852.1060904@treenet.co.nz>

On 17/02/2015 4:13 a.m., Eliezer Croitoru wrote:
> Hey,
> 
> There are couple things to consider while using multiple IPs for the
> same network\user.
> It is possible to do what you want in the OS level and in a way using
> squid.
> You should consider first what is the exact effect you want\need and if
> it can meet reality in usability level.
> It is not very smart to just spread the traffic from different IPs since
> there is an application level issues that you and your users might
> encounter while operating this logic.
> 

And by that Eliezer means that all websites using IP address as a part
of in their session key security will simply stop working.

For example; shopping carts that dont require you to login first, web
forms with multiple pages, most types of webmail accounts, most banking
sites, many HTTPS websites, a lot of smartphone apps, ...

The problem for these systems is bad enough with IPv6 so-called "privacy
addressing" changing the IP every 30 minutes.

Amos



From marcus.kool at urlfilterdb.com  Tue Feb 17 00:07:19 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 16 Feb 2015 22:07:19 -0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E26882.6050608@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
 <54E24B71.1090406@gmail.com> <54E26882.6050608@ngtech.co.il>
Message-ID: <54E28637.4080601@urlfilterdb.com>



On 02/16/2015 08:00 PM, Eliezer Croitoru wrote:
> Hey Yuri,
>
> OK I have seen something...
> Now we might need also the virtual memory which might be vsz.
> And the cachemgr output is not from squidview..
> The last image I have seen from cachemgr was much helpful(with 10 helpers).
>
>  From what I have seen until now squidGuard uses about 13 MB of ram constantly.
> If this is what it costs to run a squidGuard helper you should consider that it has some peak usage time and lower bound usage time and you will need to calculate how much helpers you need to provide
> smooth surfing on peak usage time.
> You should consider this peak usage as the required memory from squidGuard for smooth operation.
> Since not you and not will be able to change the basic memory footprint(required) for squidGuard you will need to somehow decide if you require a much efficient software or to adjust your system
> accordingly.
>
> I would agree that 100 * 13 MB of ram means about 1.3 GB of ram usage and might not be acceptable for a "simple" filtering mechanism.

It is because squidGuard uses Berkeley DB which uses a default cache size of 256 KB for each URL table.
And each squidGuard process does this.  And of course the OS keeps a full copy in the file system buffer cache.
So with 100 redirectors and N URL tables, N * 100 * 256K is used by buffers for Berkeley DB alone.

> The main reasons for the unknown need for 100 helpers might be since it was not designed to be used this way.

squidGuard does not support the Squid feature 'concurrency' for url_rewrite_children.  ufdbGuard does.
With concurrency, latency goes down and the number of processes can also be reduced.

> I must say that squidGuard is a very good piece of software but it lacks couple things which might make it un-usable for some if not many systems and maybe including yours.
> Indeed in your case there is a chance that if you will even install a full blown DB that will be stored all in ram and you will write a helper that will mimic squidguard functionality\logic with
> concurrency support you will get much less memory consumption with much more efficient request handling.
>
> It is much smarter to write a helper which will have a overall efficiency mark on it then to add into squid something that might not be even needed in the first place.

ufdbGuard has all that you need.  It holds one copy of the database in memory without allocating extra memory.
The ufdbGuard URL redirectors are leightweight processes using very little memory and
the redirectors support concurrency so less are required.

Off list, Yuri asked help for compilation on Solaris and I made a fix for ufdbGuard which is availabe for Yuri.
If there are no further complaints from Yuri, I will release the patch in one or two days.

Marcus

> For now before writing any helper etc I will want to see the cachemgr interface output for the "redirector" option in two cases:
> - startup
> - after midnight when there are lots of helpers running under squid
>
> You can see that squid since version 3.2 squid offers access to the squid cache manager interface using a simple url such as:
> "http://filter:3128/squid-internal-mgr/redirector"
> (using the visible_hostname and the forward proxy port of squid)
>
> All The Bests,
> Eliezer
>
> On 16/02/2015 21:56, Yuri Voinov wrote:
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> Now:
>>
>> 2015/02/16 23:10:23 kid1|   store_swap_size = 29826351.50 KB
>> 2015/02/16 23:10:24 kid1| storeLateRelease: released 0 objects
>> 2015/02/16 23:15:01 kid1| Starting new redirector helpers...
>> 2015/02/16 23:15:01 kid1| helperOpenServers: Starting 1/100
>> 'squidGuard' processes
>> 2015/02/17 01:40:15 kid1| Starting new redirector helpers...
>> 2015/02/17 01:40:15 kid1| helperOpenServers: Starting 1/100
>> 'squidGuard' processes
>> ^Croot @ cthulhu / # ps -e -o user,pid,rss,comm
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From ahmed.zaeem at netstream.ps  Tue Feb 17 10:21:38 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Tue, 17 Feb 2015 02:21:38 -0800
Subject: [squid-users] can squid handle indirect request from clients ?
Message-ID: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>

Hi Guys,

I wanted to ask .

 

If I have as topology below :

 

 

Client====>(HAPRoxy  or redirector )==>squid with ACLs & basic ncsa
authentication

 

The client when it ask google.com

It will passs thorugh the HAproxy , and it will direct the request to the
squid

 

Example =>

Client go to google.com:80 , the HPA proxy will send it google.com:3128 to
the ip of squid.

 

 

How let squid handle this task ???

I trid to to do natting any port 80 ==>3128  , but it failed !!!

Any suggestion ? or  even is it possible ?

Not I have ACLS and authentication @ squid , will it work ???

 

cheers

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150217/3ba93012/attachment.htm>

From eliezer at ngtech.co.il  Tue Feb 17 00:30:04 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 17 Feb 2015 02:30:04 +0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E28637.4080601@urlfilterdb.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
 <54E24B71.1090406@gmail.com> <54E26882.6050608@ngtech.co.il>
 <54E28637.4080601@urlfilterdb.com>
Message-ID: <54E28B8C.5000001@ngtech.co.il>

Hey Marcus,

Great to hear about it!!
I must say that the mentioned issues are the killers for squidGuard 
usage in many systems.

Eliezer

On 17/02/2015 02:07, Marcus Kool wrote:
> Off list, Yuri asked help for compilation on Solaris and I made a fix
> for ufdbGuard which is availabe for Yuri.
> If there are no further complaints from Yuri, I will release the patch
> in one or two days.
>
> Marcus




From eliezer at ngtech.co.il  Tue Feb 17 00:36:29 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 17 Feb 2015 02:36:29 +0200
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
Message-ID: <54E28D0D.7070208@ngtech.co.il>

Hey,

Squid and any other HTTP proxy cannot support basic authentication when 
it is being used as an intercept proxy.
The only options to do such a thing is to use some kind of a captive 
portal or an external network system which will identify the user 
directly in a webserver or another way which will put the client IP 
address in a LOGIN mode and then it will allow the client access to the 
internet based on the client IP address.

All The Bests,
Eliezer

On 17/02/2015 12:21, snakeeyes wrote:
> Any suggestion ? or  even is it possible ?
>
> Not I have ACLS and authentication @ squid , will it work ???
>
>
>
> cheers




From squid3 at treenet.co.nz  Tue Feb 17 01:24:25 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 14:24:25 +1300
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
Message-ID: <54E29849.4040707@treenet.co.nz>

On 17/02/2015 11:21 p.m., snakeeyes wrote:
> Hi Guys,
> 
> I wanted to ask .
> 
>  
> 
> If I have as topology below :
> 
>  
> 
>  
> 
> Client====>(HAPRoxy  or redirector )==>squid with ACLs & basic ncsa
> authentication
> 
>  
> 
> The client when it ask google.com
> 
> It will passs thorugh the HAproxy , and it will direct the request to the
> squid
> 
>  
> 
> Example =>
> 
> Client go to google.com:80 , the HPA proxy will send it google.com:3128 to
> the ip of squid.
> 

So google are hosting their public web services on port 3128 now? I very
much doubt that.

Perhapse you are using HAproxy to receive remotely NAT'ed traffic
because it does not complain like Squid?
 If so; the NAT lies are still there, just not being *mentioned* by the
HAproxy receiver. Them Squid complaints are designed to protect the
*entire Internet* (your LAN included) against NAT system
misconfiguration problems.



> 
> How let squid handle this task ???
> 
> I trid to to do natting any port 80 ==>3128  , but it failed !!!
> 

Yeah. Dont do that.

> Any suggestion ? or  even is it possible ?
> 
> Not I have ACLS and authentication @ squid , will it work ???
> 

Chaining proxies is perfectly fine in HTTP. You just have to know how
the HTTP auth framework operates.

 - WWW-Auth* headers are about user accessing the origin server resources.

 - Proxy-Auth* headers are about a client accessing a proxy.

The small difference in meaning between "client" (the initiating
endpoint of a TCP connection) and "user" (the person using some device)
matters a lot here.

So...

On the HAproxy->Squid connection, the client is *HAproxy*. Any
Proxy-Auth credentials received are considered by Squid to belong to
HAProxy itself. Where HAProxy gets them is its own business.

   But be clear, there is no "user" to Squid,
   just a client and that is _HAproxy_ in this setup.

So to perform auth in this setup all you need is to be able to configure
HAProxy to send the right credentials on each request. Since HTTP has
stateless auth they can be different client credentials representing
some different "user" for each request if you want that.

Contact the HAProxy support for help on how to configure it to send
credentials to Squid.


NP: if you have Squid-3.5 you can use the PROXY protocol between HAproxy
and Squid to relay the end-client TCP connection details down the chain
far better than X-Forwarded-For.

Amos


From squid3 at treenet.co.nz  Tue Feb 17 01:43:18 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 14:43:18 +1300
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E28B8C.5000001@ngtech.co.il>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
 <54E24B71.1090406@gmail.com> <54E26882.6050608@ngtech.co.il>
 <54E28637.4080601@urlfilterdb.com> <54E28B8C.5000001@ngtech.co.il>
Message-ID: <54E29CB6.4020904@treenet.co.nz>

On 17/02/2015 1:30 p.m., Eliezer Croitoru wrote:
> Hey Marcus,
> 
> Great to hear about it!!
> I must say that the mentioned issues are the killers for squidGuard
> usage in many systems.
> 

Yeah and one of the many reasons its effectively a dead project now.
IIRC, Shalla were going to maintain SG for a while but with all the
useful functionality being duplicated in ufdbGuard (amongst others)
and/or Squid itself there is not much point in keeping the old helper
around.

It has got so many legacy installs depending on it and tutorials
encouraging people to use it even today. Its proving hard to oust the
dear old zombie. :-(


PS. Marcus, perhapse you should go on search around to find distro
maintainers who are publishing SG and convince them to replace the
defaults with ufdbguard. I have to do that periodically to clear up old
Squid versions being forced on users. It helps to find out what bugs
they are patching or struggling with silently as well.
 Making the upgrade/switch as seamless as possible is important too.


Amos



From squid3 at treenet.co.nz  Tue Feb 17 02:18:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 15:18:24 +1300
Subject: [squid-users] OOKLA speedtest can't upload with squid
In-Reply-To: <CAMXC=WtfPFjqMBnqwZSY5+c9d-eK2_mvFcRUAveB+gG1z1-WMQ@mail.gmail.com>
References: <CAMXC=WtfPFjqMBnqwZSY5+c9d-eK2_mvFcRUAveB+gG1z1-WMQ@mail.gmail.com>
Message-ID: <54E2A4F0.80107@treenet.co.nz>

On 17/02/2015 10:30 a.m., Alfredo Rezinovsky wrote:
> 
> If I do a traffic analisys in the internet traffic I can see the server
> sends squid an Internal Server Error (500) at the middle of the POST
> (BEFORE the POST is complete).
> 
> The error comes from the server. But this doesn't happens in squid 3.4 or
> with a direct connection.
> 
> The POST content-length is 26761 So I don't think buffers may be a problem.

What are the message headers for those POST, the ones the server is
rejecting?


PS. also please be aware that the Buffer Bloat guys have pretty much
proven that common speed test metrics use a flawed design. They tend to
suppress bottlenecks / congestion seen in normal traffic environments
where there are multiple parallel connections existing.

Amos



From squid3 at treenet.co.nz  Tue Feb 17 02:26:55 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 15:26:55 +1300
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E2390D.1050708@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E2390D.1050708@gmail.com>
Message-ID: <54E2A6EF.1050403@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 17/02/2015 7:38 a.m., Yuri Voinov wrote:
> We are talking not about the differences between any *NIX-based or 
> *NIX-like OS. Android just an example. I guess an observerd
> behaviour of redirector's processes is not expected.
> 
> Now I've observed mentioned behaviour of redirectors over one
> month. I just want to know - is this desired behaviour or this is a
> bug.
> 
> If this is bug - need to report it as bug.
> 

Its not an error bug. Its a feature request.

But before you make a report I'd like an answer to the question of how
often you are using "squid -k rotate" ?
 and if you noticed whan happend during those processes

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU4qbvAAoJELJo5wb/XPRj1GwH/jf5ndTyqj9mKTHHzeS0srhI
k9zWyfRRgYyhMw6vAzQ0iI9ILGa4p3tmhWXuIKvvI5cG0lMRKo3OnjEidByxC4UT
9Zaw73UHEn1p6hlZ0i6SzhliUsb3oAFHIsqO6/erl9pkQXCqoErsTDniEG4pXaGQ
VNo3tMOoSBsZ8m/sjP9O/1OpAf9VSz5yV5AjLLq/IaO8h6d44HFGOpQ1RC+KPc+b
sRshINMTpWQXjXwHMZ2dfZ6F9TLejMUhfHeGzd/idlkupx/NN7xbSS+zK7PMYMaa
FZb3VA5CrH0dVyPqJECOFb9JgmCchNdWT4liscXkulu/GdcrdUJdlzUmt7VGOwk=
=OV0f
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Tue Feb 17 03:25:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 Feb 2015 16:25:28 +1300
Subject: [squid-users] EXT_LOG not "getting passed" to http_reply_access
 acls
In-Reply-To: <CAA1s11v9oyQsrHEj33f8L9eWdsuFeJWkKexf3z6MpGEvn8isZg@mail.gmail.com>
References: <CAA1s11v9oyQsrHEj33f8L9eWdsuFeJWkKexf3z6MpGEvn8isZg@mail.gmail.com>
Message-ID: <54E2B4A8.1050407@treenet.co.nz>

On 10/02/2015 6:55 p.m., Cameron Charles wrote:
> Our setup contains a bunch of, mostly external, acls some http_access
> followed by some http_reply_access, these acls use EXT_LOG frequently,
> however we are having issues at the point of the last http_access and first
> http_reply_access acls (both external) the EXT_LOG is "lost" at this point
> and the http_reply_access acl simply gets - . i've added debugging to acls
> and there are no error, they are passing out an actual EXT_LOG that is
> never recieved.
> 
> Does anyone have any ideas on why this is,  how to fix it or what debug
> flags in squid to activate to help find the issue?

Are you using URL-rewrite helpers or ICAP/eCAP adaptation to replace the
request that came from the client?

Amos


From yvoinov at gmail.com  Tue Feb 17 09:27:13 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 15:27:13 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E276BB.2070101@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54E1ED12.8040606@ngtech.co.il>
 <54E1EF44.6030507@gmail.com> <54E205B0.50807@ngtech.co.il>
 <54E20C7F.9050105@gmail.com> <54E276BB.2070101@treenet.co.nz>
Message-ID: <54E30971.2050802@gmail.com>


17.02.15 5:01, Amos Jeffries ?????:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 17/02/2015 4:27 a.m., Yuri Voinov wrote:
>> Yep.
>>
>> 16.02.15 20:58, Eliezer Croitoru ?????:
>>> On 16/02/2015 15:23, Yuri Voinov wrote:
>>>> http://i58.tinypic.com/rsqwxh.png
>>>>
>>>> 0 shutting down. Always.
>>>>
>>>> During nights and weekends.
> Um, how often do you run "squid -k rotate" ??
Never. Log rotation is made by logadm (external Solaris facility) on 
cron basis.

>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJU4na7AAoJELJo5wb/XPRjQI8H/RovqwldDet9cVGefc36TRNx
> c9OsYDTcHPUbIlSXg7K3ZJOa1+EFqWrZC4btLYZHdjQRwpLs9nl9pVxm4Q3e9911
> iriwgcYKXI9u6NNaTQmUSob7rU7+Y3kxRzLHUp+A+pLsekMocus1qwYujOUxfzUP
> 1Vrg5HfEKeI7d9wSaf7Tq2P4FGwFDsg85Uddro0ycx0qJpC+PmKOYmFpst7s+WqG
> 5qags64+BcgG40PupNzJ8F/8LCxv80+q3ikXBRcfwFRm8LcVfkQqeye11oKGjxQl
> HvY5PwV796QhkOkv6vEts3jOnKDKLJ7McbeWSeGyfKRaviw1RWcUMzCFyPdrUF8=
> =djSX
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Tue Feb 17 10:21:20 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 16:21:20 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E28637.4080601@urlfilterdb.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
 <54E24B71.1090406@gmail.com> <54E26882.6050608@ngtech.co.il>
 <54E28637.4080601@urlfilterdb.com>
Message-ID: <54E31620.6020005@gmail.com>


17.02.15 6:07, Marcus Kool ?????:
>
>
> On 02/16/2015 08:00 PM, Eliezer Croitoru wrote:
>> Hey Yuri,
>>
>> OK I have seen something...
>> Now we might need also the virtual memory which might be vsz.
>> And the cachemgr output is not from squidview..
>> The last image I have seen from cachemgr was much helpful(with 10 
>> helpers).
>>
>>  From what I have seen until now squidGuard uses about 13 MB of ram 
>> constantly.
>> If this is what it costs to run a squidGuard helper you should 
>> consider that it has some peak usage time and lower bound usage time 
>> and you will need to calculate how much helpers you need to provide
>> smooth surfing on peak usage time.
>> You should consider this peak usage as the required memory from 
>> squidGuard for smooth operation.
>> Since not you and not will be able to change the basic memory 
>> footprint(required) for squidGuard you will need to somehow decide if 
>> you require a much efficient software or to adjust your system
>> accordingly.
>>
>> I would agree that 100 * 13 MB of ram means about 1.3 GB of ram usage 
>> and might not be acceptable for a "simple" filtering mechanism.
>
> It is because squidGuard uses Berkeley DB which uses a default cache 
> size of 256 KB for each URL table.
> And each squidGuard process does this.  And of course the OS keeps a 
> full copy in the file system buffer cache.
> So with 100 redirectors and N URL tables, N * 100 * 256K is used by 
> buffers for Berkeley DB alone.
>
>> The main reasons for the unknown need for 100 helpers might be since 
>> it was not designed to be used this way.
>
> squidGuard does not support the Squid feature 'concurrency' for 
> url_rewrite_children.  ufdbGuard does.
> With concurrency, latency goes down and the number of processes can 
> also be reduced.
The lack of concurrency is main disadvantage of squidGuard. Old 
process-based model is not acceptable on modern OS'es.

BTW, can I configure ufdbGuard children like this:

url_rewrite_children 1 startup=1 idle=1 concurrency=100

?

Another reason is store ID rewriter too. With this we have the same 
problem, but a bit smaller, of course.
I think, global parameter to firce shutdown idle redirectirs will be 
best solution.


>
>> I must say that squidGuard is a very good piece of software but it 
>> lacks couple things which might make it un-usable for some if not 
>> many systems and maybe including yours.
>> Indeed in your case there is a chance that if you will even install a 
>> full blown DB that will be stored all in ram and you will write a 
>> helper that will mimic squidguard functionality\logic with
>> concurrency support you will get much less memory consumption with 
>> much more efficient request handling.
>>
>> It is much smarter to write a helper which will have a overall 
>> efficiency mark on it then to add into squid something that might not 
>> be even needed in the first place.
>
> ufdbGuard has all that you need.  It holds one copy of the database in 
> memory without allocating extra memory.
> The ufdbGuard URL redirectors are leightweight processes using very 
> little memory and
> the redirectors support concurrency so less are required.
>
> Off list, Yuri asked help for compilation on Solaris and I made a fix 
> for ufdbGuard which is availabe for Yuri.
> If there are no further complaints from Yuri, I will release the patch 
> in one or two days.
Will try. Also will be good to support modern startup facility on 
Solaris ;) against deprecated SVR4 init. ;)
>
> Marcus
>
>> For now before writing any helper etc I will want to see the cachemgr 
>> interface output for the "redirector" option in two cases:
>> - startup
>> - after midnight when there are lots of helpers running under squid
>>
>> You can see that squid since version 3.2 squid offers access to the 
>> squid cache manager interface using a simple url such as:
>> "http://filter:3128/squid-internal-mgr/redirector"
>> (using the visible_hostname and the forward proxy port of squid)
>>
>> All The Bests,
>> Eliezer
>>
>> On 16/02/2015 21:56, Yuri Voinov wrote:
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>> Now:
>>>
>>> 2015/02/16 23:10:23 kid1|   store_swap_size = 29826351.50 KB
>>> 2015/02/16 23:10:24 kid1| storeLateRelease: released 0 objects
>>> 2015/02/16 23:15:01 kid1| Starting new redirector helpers...
>>> 2015/02/16 23:15:01 kid1| helperOpenServers: Starting 1/100
>>> 'squidGuard' processes
>>> 2015/02/17 01:40:15 kid1| Starting new redirector helpers...
>>> 2015/02/17 01:40:15 kid1| helperOpenServers: Starting 1/100
>>> 'squidGuard' processes
>>> ^Croot @ cthulhu / # ps -e -o user,pid,rss,comm
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Tue Feb 17 10:23:13 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 16:23:13 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E2A6EF.1050403@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E2390D.1050708@gmail.com> <54E2A6EF.1050403@treenet.co.nz>
Message-ID: <54E31691.4050800@gmail.com>

As I said - never. I use external log rotation facility.
Squid log rotation is completely off in my installation.

17.02.15 8:26, Amos Jeffries ?????:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 17/02/2015 7:38 a.m., Yuri Voinov wrote:
>> We are talking not about the differences between any *NIX-based or
>> *NIX-like OS. Android just an example. I guess an observerd
>> behaviour of redirector's processes is not expected.
>>
>> Now I've observed mentioned behaviour of redirectors over one
>> month. I just want to know - is this desired behaviour or this is a
>> bug.
>>
>> If this is bug - need to report it as bug.
>>
> Its not an error bug. Its a feature request.
>
> But before you make a report I'd like an answer to the question of how
> often you are using "squid -k rotate" ?
>   and if you noticed whan happend during those processes
>
> Amos
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2.0.22 (MingW32)
>
> iQEcBAEBAgAGBQJU4qbvAAoJELJo5wb/XPRj1GwH/jf5ndTyqj9mKTHHzeS0srhI
> k9zWyfRRgYyhMw6vAzQ0iI9ILGa4p3tmhWXuIKvvI5cG0lMRKo3OnjEidByxC4UT
> 9Zaw73UHEn1p6hlZ0i6SzhliUsb3oAFHIsqO6/erl9pkQXCqoErsTDniEG4pXaGQ
> VNo3tMOoSBsZ8m/sjP9O/1OpAf9VSz5yV5AjLLq/IaO8h6d44HFGOpQ1RC+KPc+b
> sRshINMTpWQXjXwHMZ2dfZ6F9TLejMUhfHeGzd/idlkupx/NN7xbSS+zK7PMYMaa
> FZb3VA5CrH0dVyPqJECOFb9JgmCchNdWT4liscXkulu/GdcrdUJdlzUmt7VGOwk=
> =OV0f
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From marcus.kool at urlfilterdb.com  Tue Feb 17 10:55:21 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 17 Feb 2015 08:55:21 -0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E31620.6020005@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
 <54E24B71.1090406@gmail.com> <54E26882.6050608@ngtech.co.il>
 <54E28637.4080601@urlfilterdb.com> <54E31620.6020005@gmail.com>
Message-ID: <54E31E19.1000201@urlfilterdb.com>



On 02/17/2015 08:21 AM, Yuri Voinov wrote:
>> squidGuard does not support the Squid feature 'concurrency' for url_rewrite_children.  ufdbGuard does.
>> With concurrency, latency goes down and the number of processes can also be reduced.
> The lack of concurrency is main disadvantage of squidGuard. Old process-based model is not acceptable on modern OS'es.
>
> BTW, can I configure ufdbGuard children like this:
>
> url_rewrite_children 1 startup=1 idle=1 concurrency=100

Yes you can, but it is not recommended :-(   since throughput is higher with
    url_rewrite_children 50 startup=5 idle=2 concurrency=3

When concurrency was built into the ufdbGuard redirector (named ufdbgclient)
it was done to increase the flow of requests:
     Squid  <--pipe-->  ufdbgclient  <--UNIX-socket-->  ufdbguardd daemon
To keep ufdbgclient busy, there must always be a next request in the pipe and
and concurrency of 2 or 3 does that.  It is not optimised for having
100 requests in the pipe.

Since ufdbgclient is leightweight, there is no problem with having 30 or more
of them and therefore ufdbgclient was never optimised for the use case of
    url_rewrite_children 1 startup=1 idle=1 concurrency=100

Marcus


From marcus.kool at urlfilterdb.com  Tue Feb 17 11:00:08 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 17 Feb 2015 09:00:08 -0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E29CB6.4020904@treenet.co.nz>
References: <54DCEA80.2090204@gmail.com> <54E217BF.5040108@ngtech.co.il>
 <54E218B4.7030607@gmail.com>
 <201502161635.40518.Antony.Stone@squid.open.source.it>
 <54E21CC3.5070707@gmail.com> <54E21F69.8050009@ngtech.co.il>
 <54E220F1.1080202@gmail.com> <54E2356C.3040204@ngtech.co.il>
 <54E239F8.6070605@gmail.com> <54E24018.5010402@ngtech.co.il>
 <54E240B4.5050609@gmail.com> <54E24189.1030104@ngtech.co.il>
 <54E24B71.1090406@gmail.com> <54E26882.6050608@ngtech.co.il>
 <54E28637.4080601@urlfilterdb.com> <54E28B8C.5000001@ngtech.co.il>
 <54E29CB6.4020904@treenet.co.nz>
Message-ID: <54E31F38.5050408@urlfilterdb.com>



On 02/16/2015 11:43 PM, Amos Jeffries wrote:
> PS. Marcus, perhapse you should go on search around to find distro
> maintainers who are publishing SG and convince them to replace the
> defaults with ufdbguard. I have to do that periodically to clear up old
> Squid versions being forced on users. It helps to find out what bugs
> they are patching or struggling with silently as well.
>   Making the upgrade/switch as seamless as possible is important too.
>
>
> Amos

For reasons unknown I am not very good in convincing other people what
they should do :-)
Perhaps it is better to wait for the time that maintainers and admins
see for themselves what is best.

Marcus


From Antony.Stone at squid.open.source.it  Tue Feb 17 11:28:33 2015
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 17 Feb 2015 11:28:33 +0000
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
	children?
In-Reply-To: <54E31F38.5050408@urlfilterdb.com>
References: <54DCEA80.2090204@gmail.com> <54E29CB6.4020904@treenet.co.nz>
 <54E31F38.5050408@urlfilterdb.com>
Message-ID: <201502171128.34074.Antony.Stone@squid.open.source.it>

On Tuesday 17 Feb 2015 at 11:00, Marcus Kool wrote:

> On 02/16/2015 11:43 PM, Amos Jeffries wrote:
> > PS. Marcus, perhaps you should go on search around to find distro
> > maintainers who are publishing SG and convince them to replace the
> > defaults with ufdbguard. I have to do that periodically to clear up old
> > Squid versions being forced on users. It helps to find out what bugs
> > they are patching or struggling with silently as well.

> For reasons unknown I am not very good in convincing other people what
> they should do :-)
> Perhaps it is better to wait for the time that maintainers and admins
> see for themselves what is best.

Hm, the problem I see with that is that package maintainers are not always 
admins of the systems using those packages, therefore they're not the people 
who run into the problems caused by outdated packages.

Lots of system admins (the ones who don't appear on this list, for example) 
just assume "it's the current software being provided by my distro, therefore 
it must be the one recommended by the developers", therefore they never find 
out that the developers of the software recommend doing something new, while 
the package maintainers have never moved on from old versions or old 
techniques.

I do think we need to inform package maintainers that what they're doing is no 
longer what the developers recommend, to try to close the gap between the 
people who start from "here's what I get from my distro" and "but this is the 
right way to do things" (which we see often enough on this and similar lists).

When the package maintainer is a developer, this situation generally sorts 
itself out pretty quickly, but this is not often (AFAIK) the case, so 
announcing the current recommendations to the people runnning the distros can 
make a big difference.


Regards,


Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Tue Feb 17 13:30:09 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 19:30:09 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <201502171128.34074.Antony.Stone@squid.open.source.it>
References: <54DCEA80.2090204@gmail.com> <54E29CB6.4020904@treenet.co.nz>
 <54E31F38.5050408@urlfilterdb.com>
 <201502171128.34074.Antony.Stone@squid.open.source.it>
Message-ID: <54E34261.8070408@gmail.com>

Also, gents.

ufdbGuard is cool, but:

- Where is good documentation? I found only one connon PDF. No 
performance recommendations, no administrator's guide - this good piece 
of software not so trivial as squidGuard, i.e., I don't know, how to 
support only used blocking categories databases without rebuilding them 
all, no concepts guide - the architecture of solution is not obvious. 
May be I need glasses, but Reference manual + man pages is not enough 
for average SA's. Not at all will read sources.

- AFAIK, it uses daemon-centric architecture. Well, but different OS 
uses different startup facilities. I want to have possibility to tune it 
up by myself or installation must correct do it on target OS. And please 
note, that not only Linux existing in the world. ;) SystemV init was 
deprecated in some systems years ago. ;) And will be good to document 
all of this in installation guide.

Did you agree?

17.02.15 17:28, Antony Stone ?????:
> On Tuesday 17 Feb 2015 at 11:00, Marcus Kool wrote:
>
>> On 02/16/2015 11:43 PM, Amos Jeffries wrote:
>>> PS. Marcus, perhaps you should go on search around to find distro
>>> maintainers who are publishing SG and convince them to replace the
>>> defaults with ufdbguard. I have to do that periodically to clear up old
>>> Squid versions being forced on users. It helps to find out what bugs
>>> they are patching or struggling with silently as well.
>> For reasons unknown I am not very good in convincing other people what
>> they should do :-)
>> Perhaps it is better to wait for the time that maintainers and admins
>> see for themselves what is best.
> Hm, the problem I see with that is that package maintainers are not always
> admins of the systems using those packages, therefore they're not the people
> who run into the problems caused by outdated packages.
>
> Lots of system admins (the ones who don't appear on this list, for example)
> just assume "it's the current software being provided by my distro, therefore
> it must be the one recommended by the developers", therefore they never find
> out that the developers of the software recommend doing something new, while
> the package maintainers have never moved on from old versions or old
> techniques.
>
> I do think we need to inform package maintainers that what they're doing is no
> longer what the developers recommend, to try to close the gap between the
> people who start from "here's what I get from my distro" and "but this is the
> right way to do things" (which we see often enough on this and similar lists).
>
> When the package maintainer is a developer, this situation generally sorts
> itself out pretty quickly, but this is not often (AFAIK) the case, so
> announcing the current recommendations to the people runnning the distros can
> make a big difference.
>
>
> Regards,
>
>
> Antony.
>



From alanpalmer72 at yahoo.com  Tue Feb 17 13:56:38 2015
From: alanpalmer72 at yahoo.com (Alan Palmer)
Date: Tue, 17 Feb 2015 08:56:38 -0500
Subject: [squid-users] ssl proxy error: No valid signing SSL certificate
 configured for https_port [::]:3127
In-Reply-To: <54E272EE.8040506@treenet.co.nz>
References: <54E1115E.3040804@yahoo.com> <54E1144C.2040503@ngtech.co.il>
 <54E217D5.70005@yahoo.com> <54E272EE.8040506@treenet.co.nz>
Message-ID: <54E34896.4000300@yahoo.com>


On 2/16/2015 5:45 PM, Amos Jeffries wrote:
> Notice how the port details have changed from IPv4-only to IPv6-only. 
> You are using a split-stack OS where each of the IPv4 and IPv6 ports 
> needs separate TLS/SSL context. You can set the same settings and load 
> the same cert file, just have to place the config separately in 
> squid.conf for now: https_port 0.0.0.0:3127 intercept ssl-bump \ 
> generate-host-certificates=on \ dynamic_cert_mem_cache_size=16MB \ 
> cert=/etc/squid/ssl_cert/server1.crt https_port [::]:3127 intercept 
> ssl-bump \ generate-host-certificates=on \ 
> dynamic_cert_mem_cache_size=16MB \ 
> cert=/etc/squid/ssl_cert/server1.crt Amos 
> _______________________________________________ squid-users mailing 
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users 


openssl req -new -newkey rsa:2048 -sha256 -days 3650 -nodes -x509 
-keyout myCA.pem -out myCA.pem

tail -20 squid.conf
http_port 3128 transparent
#
#       transparent SSL proxy setup
#
https_port 0.0.0.0:3127 intercept ssl-bump \
   generate-host-certificates=on \
   dynamic_cert_mem_cache_size=16MB \
   cert=/etc/squid/ssl_cert/JaroszCA.pem

https_port [::]:3127 intercept ssl-bump \
   generate-host-certificates=on \
   dynamic_cert_mem_cache_size=16MB \
   cert=/etc/squid/ssl_cert/JaroszCA.pem

#
sslcrtd_program /usr/local/libexec/squid/ssl_crtd -s /data/squid/ssl_db 
-M 16MB
sslcrtd_children 10
always_direct allow all
sslproxy_cert_error allow all
ssl_bump server-first all

/etc/squid: squid -z
FATAL: No valid signing SSL certificate configured for https_port 
0.0.0.0:3127
Squid Cache (Version 3.4.11): Terminated abnormally.
CPU Usage: 0.080 seconds = 0.070 user + 0.010 sys
Maximum Resident Size: 6764 KB
Page faults with physical i/o: 0

BUT:

tail -20 squid.conf
http_port 3128 transparent
#
#       transparent SSL proxy setup
#
https_port 127.0.0.1:3127 intercept ssl-bump \
   generate-host-certificates=on \
   dynamic_cert_mem_cache_size=16MB \
   cert=/etc/squid/ssl_cert/JaroszCA.pem

https_port [::1]:3127 intercept ssl-bump \
   generate-host-certificates=on \
   dynamic_cert_mem_cache_size=16MB \
   cert=/etc/squid/ssl_cert/JaroszCA.pem

/etc/squid: squid -z
/etc/squid: 2015/02/17 07:47:03 kid1| Set Current Directory
to /var/squid/cache
2015/02/17 07:47:03 kid1| Creating missing swap directories
...

Its not just specifying separate lines for the split stack, using the 
non-specific addresses 0.0.0.0 and [::] fails.  I had to put a real ip 
address, in this case loopback, but using another real interface on my 
machine also worked.

Bug/'Feature' in OpenBSD 5.6 implementation or all split stack OSs?

Thanks muchly for the help.

Alan




From marcus.kool at urlfilterdb.com  Tue Feb 17 14:29:23 2015
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 17 Feb 2015 12:29:23 -0200
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E34261.8070408@gmail.com>
References: <54DCEA80.2090204@gmail.com> <54E29CB6.4020904@treenet.co.nz>
 <54E31F38.5050408@urlfilterdb.com>
 <201502171128.34074.Antony.Stone@squid.open.source.it>
 <54E34261.8070408@gmail.com>
Message-ID: <54E35043.4000707@urlfilterdb.com>



On 02/17/2015 11:30 AM, Yuri Voinov wrote:
> Also, gents.
>
> ufdbGuard is cool, but:
>
> - Where is good documentation? I found only one connon PDF. No performance recommendations, no administrator's guide - this good piece of software not so trivial as squidGuard, i.e., I don't know, how
> to support only used blocking categories databases without rebuilding them all, no concepts guide - the architecture of solution is not obvious. May be I need glasses, but Reference manual + man pages
> is not enough for average SA's. Not at all will read sources.
>
> - AFAIK, it uses daemon-centric architecture. Well, but different OS uses different startup facilities. I want to have possibility to tune it up by myself or installation must correct do it on target
> OS. And please note, that not only Linux existing in the world. ;) SystemV init was deprecated in some systems years ago. ;) And will be good to document all of this in installation guide.
>
> Did you agree?

Let me give you some pointers:

http://www.urlfilterdb.com/files/downloads/ReferenceManual.pdf

The architecture is in section 3, Architecture.
This section also explains what is a URL redirector and how URL redirectors sit between Squid and the ufdbguardd daemon.

Performance recommendations are in section 11, Solaris specifics in section 11.5
If you have some feedback regarding what might be added, you are invited to supply it and I will add it to the Reference Manual.

In addition, section 6.12.2 Large System Configuration, recommends to use concurrency for the URL redirectors.

Note that ufdbguard does not need much tuning: it can do 50,000 URL verifications per second
on a single Intel Xeon 2420v1 core which is 10x more than the number of URL request per second that Squid will process.

Marcus


From yvoinov at gmail.com  Tue Feb 17 14:54:54 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 Feb 2015 20:54:54 +0600
Subject: [squid-users] Is Squid can shutdown unused idle redirector's
 children?
In-Reply-To: <54E35043.4000707@urlfilterdb.com>
References: <54DCEA80.2090204@gmail.com> <54E29CB6.4020904@treenet.co.nz>
 <54E31F38.5050408@urlfilterdb.com>
 <201502171128.34074.Antony.Stone@squid.open.source.it>
 <54E34261.8070408@gmail.com> <54E35043.4000707@urlfilterdb.com>
Message-ID: <54E3563E.5090407@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Sure. Will read manual more carefully. ;)

17.02.15 20:29, Marcus Kool ?????:
> 
> 
> On 02/17/2015 11:30 AM, Yuri Voinov wrote:
>> Also, gents.
>> 
>> ufdbGuard is cool, but:
>> 
>> - Where is good documentation? I found only one connon PDF. No 
>> performance recommendations, no administrator's guide - this
>> good piece of software not so trivial as squidGuard, i.e., I
>> don't know, how to support only used blocking categories
>> databases without rebuilding them all, no concepts guide - the
>> architecture of solution is not obvious. May be I need glasses,
>> but Reference manual + man pages is not enough for average SA's.
>> Not at all will read sources.
>> 
>> - AFAIK, it uses daemon-centric architecture. Well, but different
>> OS uses different startup facilities. I want to have possibility
>> to tune it up by myself or installation must correct do it on
>> target OS. And please note, that not only Linux existing in the
>> world. ;) SystemV init was deprecated in some systems years ago.
>> ;) And will be good to document all of this in installation
>> guide.
>> 
>> Did you agree?
> 
> Let me give you some pointers:
> 
> http://www.urlfilterdb.com/files/downloads/ReferenceManual.pdf
> 
> The architecture is in section 3, Architecture. This section also
> explains what is a URL redirector and how URL redirectors sit
> between Squid and the ufdbguardd daemon.
> 
> Performance recommendations are in section 11, Solaris specifics
> in section 11.5 If you have some feedback regarding what might be
> added, you are invited to supply it and I will add it to the
> Reference Manual.
> 
> In addition, section 6.12.2 Large System Configuration, recommends
> to use concurrency for the URL redirectors.
> 
> Note that ufdbguard does not need much tuning: it can do 50,000
> URL verifications per second on a single Intel Xeon 2420v1 core
> which is 10x more than the number of URL request per second that
> Squid will process.
> 
> Marcus
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU41Y+AAoJENNXIZxhPexGMhUH/R2mWawc/w7JtkqWhiGHu0R3
OK2ROh8l78qzt3k6m8m9DaJlj1kN8Y6272f5BzuOKft9SYa99mJkqzkPTYbtR5rm
yH/gfKYVrxaJOsevBoTf8hdZHR3zWbjhBPkzZFl+4/D4pZ6hN1eWhSPOMUzae6jE
Yp+zUEWeCw+ZHHqLeqFD9OvWxArqwSemZiNOj+4jC8cOw2ePq3vFOk3WjAM5EiPw
inifsMV/Zn3HdUa6h1sJdqmbTjF1yePuPJixUuHGYlI0MquIFCAd3gzZBOq3KIqr
eNVXpc+AyUrRA9yxOjCBmyiNg4ZK9bZoos+dXvlV5AGQe+oT4SrJDol3f2pFesE=
=GPva
-----END PGP SIGNATURE-----


From annaj at hi.is  Tue Feb 17 14:58:46 2015
From: annaj at hi.is (Anna Jonna Armannsdottir)
Date: Tue, 17 Feb 2015 14:58:46 +0000
Subject: [squid-users] Squid latency at ApacheCon 2014 in comparison between
 Squid, NGINX, Apache Traffic Server, Varnish and Apache
Message-ID: <1424185126.4005.36.camel@hi.is>

Hi everybody! 
My question may be rather theoretical, but in essence I need to know if
Squid really has a flaw regarding latency for connections where
keepalive is on. 

At ApacheCon 2014, Bryan Call presented slides where slides nr. 40 to 49
show where he writes on slide 46 about Squid: 
"Worst median latency for keep-alive benchmarks" . 
The slides are here:
http://www.slideshare.net/bryan_call/choosing-a-proxy-server-apachecon-2014 
The configuration for Squid is shown on slide nr. 36. To my eyes it
looks a little over simplistic. I hope he has not configured Squid
correctly and that somebody here can point me at better configuration
that expressly does not have latency of many seconds and a 95 percentile
of over 10 seconds. Those numbers were achieved by mesurement using
CoAdvisor 
( see
http://coad.measurement-factory.com/cgi-bin/coad/FaqCgi?item_id=ALL )

My intent, is to use Squid with CARP or VRRP as a reverse proxy and load
balancer for a cluster of webservers. 

My main reason for using Squid rather than NGINX or ATX or Varnish is
Squid's superior protocol compliance. Byan Call's demostrated latency 
gives me reasons for concern. 

I spent the last weeks searching but I have not found anything that
seems to counter Mr. Call's claim. On behalf of the Squid developers and
users, I would be wery grateful if anybody could show or demonstrate the
contrary. Preferably with configuration. 

About me: 
I have been a Squid proxy admin for almost 10 years now, and also
administrating web cluster solutions for a small university. I am
already deploying VRRP with NGINX as a load-balancer, but me and my
coworkers are not satisfied with its performance. 

Best regards, 
-- 
Anna Jonna Armannsdottir <annaj at hi.is>
University of Iceland Computing Services



From ahmed.zaeem at netstream.ps  Wed Feb 18 02:02:19 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Tue, 17 Feb 2015 18:02:19 -0800
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <54E29849.4040707@treenet.co.nz>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
 <54E29849.4040707@treenet.co.nz>
Message-ID: <000001d04b1e$eed171b0$cc745510$@netstream.ps>

Hi Amos,

Lets forget the authentication now  I don?t need it now  I will use the ACL Rules on squid only

Wt I need to configure squid so that it handle requests from HAproxy ?


Note that I see traffic in tcpdump , but no log in access.log 

cheers

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, February 16, 2015 5:24 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] can squid handle indirect request from clients ?

On 17/02/2015 11:21 p.m., snakeeyes wrote:
> Hi Guys,
> 
> I wanted to ask .
> 
>  
> 
> If I have as topology below :
> 
>  
> 
>  
> 
> Client====>(HAPRoxy  or redirector )==>squid with ACLs & basic ncsa 
> authentication
> 
>  
> 
> The client when it ask google.com
> 
> It will passs thorugh the HAproxy , and it will direct the request to 
> the squid
> 
>  
> 
> Example =>
> 
> Client go to google.com:80 , the HPA proxy will send it 
> google.com:3128 to the ip of squid.
> 

So google are hosting their public web services on port 3128 now? I very much doubt that.

Perhapse you are using HAproxy to receive remotely NAT'ed traffic because it does not complain like Squid?
 If so; the NAT lies are still there, just not being *mentioned* by the HAproxy receiver. Them Squid complaints are designed to protect the *entire Internet* (your LAN included) against NAT system misconfiguration problems.



> 
> How let squid handle this task ???
> 
> I trid to to do natting any port 80 ==>3128  , but it failed !!!
> 

Yeah. Dont do that.

> Any suggestion ? or  even is it possible ?
> 
> Not I have ACLS and authentication @ squid , will it work ???
> 

Chaining proxies is perfectly fine in HTTP. You just have to know how the HTTP auth framework operates.

 - WWW-Auth* headers are about user accessing the origin server resources.

 - Proxy-Auth* headers are about a client accessing a proxy.

The small difference in meaning between "client" (the initiating endpoint of a TCP connection) and "user" (the person using some device) matters a lot here.

So...

On the HAproxy->Squid connection, the client is *HAproxy*. Any Proxy-Auth credentials received are considered by Squid to belong to HAProxy itself. Where HAProxy gets them is its own business.

   But be clear, there is no "user" to Squid,
   just a client and that is _HAproxy_ in this setup.

So to perform auth in this setup all you need is to be able to configure HAProxy to send the right credentials on each request. Since HTTP has stateless auth they can be different client credentials representing some different "user" for each request if you want that.

Contact the HAProxy support for help on how to configure it to send credentials to Squid.


NP: if you have Squid-3.5 you can use the PROXY protocol between HAproxy and Squid to relay the end-client TCP connection details down the chain far better than X-Forwarded-For.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ahmed.zaeem at netstream.ps  Wed Feb 18 02:04:12 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Tue, 17 Feb 2015 18:04:12 -0800
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <54E28D0D.7070208@ngtech.co.il>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
 <54E28D0D.7070208@ngtech.co.il>
Message-ID: <000101d04b1f$31d311d0$95793570$@netstream.ps>

Thanks eleizer , but does it support other types like radius authentication ?

I mean all types of  authentications are forbidden in intercept mode ?

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Monday, February 16, 2015 4:36 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] can squid handle indirect request from clients ?

Hey,

Squid and any other HTTP proxy cannot support basic authentication when it is being used as an intercept proxy.
The only options to do such a thing is to use some kind of a captive portal or an external network system which will identify the user directly in a webserver or another way which will put the client IP address in a LOGIN mode and then it will allow the client access to the internet based on the client IP address.

All The Bests,
Eliezer

On 17/02/2015 12:21, snakeeyes wrote:
> Any suggestion ? or  even is it possible ?
>
> Not I have ACLS and authentication @ squid , will it work ???
>
>
>
> cheers


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Tue Feb 17 21:48:36 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 Feb 2015 10:48:36 +1300
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <000101d04b1f$31d311d0$95793570$@netstream.ps>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
 <54E28D0D.7070208@ngtech.co.il>
 <000101d04b1f$31d311d0$95793570$@netstream.ps>
Message-ID: <54E3B734.1010201@treenet.co.nz>

On 18/02/2015 3:04 p.m., snakeeyes wrote:
> Thanks eleizer , but does it support other types like radius authentication ?
> 
> I mean all types of  authentications are forbidden in intercept mode ?


<http://wiki.squid-cache.org/SquidFaq/InterceptionProxy>

"
* Why can't I use authentication together with interception proxying?

Interception Proxying works by having an active agent (the proxy) where
there should be none. The browser is not expecting it to be there, and
it's for all effects and purposes being cheated or, at best, confused.

As an user of that browser, I would require it not to give away any
credentials to an unexpected party, wouldn't you agree? Especially so
when the user-agent can do so without notifying the user, like Microsoft
browsers can do when the proxy offers any of the Microsoft-designed
authentication schemes such as NTLM (see SquidFaq/ProxyAuthentication
and Features/NegotiateAuthentication).

In other words, it's not a squid bug, but a browser security feature.

"

Amos



From hack.back at hotmail.com  Tue Feb 17 21:44:00 2015
From: hack.back at hotmail.com (HackXBack)
Date: Tue, 17 Feb 2015 13:44:00 -0800 (PST)
Subject: [squid-users] assertion failed: comm.cc:769:
	"Comm::IsConnOpen(conn)"
In-Reply-To: <1424025171679-4669842.post@n4.nabble.com>
References: <1424025171679-4669842.post@n4.nabble.com>
Message-ID: <1424209440077-4669927.post@n4.nabble.com>

root at dotspot:~# gdb /usr/sbin/squid /var/spool/squid/cache/squid/core.53359
GNU gdb (GDB) 7.4.1-debian
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /usr/sbin/squid...done.
[New LWP 53359]
[New LWP 53461]
[New LWP 53479]
[New LWP 53462]
[New LWP 53476]
[New LWP 53477]
[New LWP 53463]
[New LWP 53464]
[New LWP 53466]
[New LWP 53475]
[New LWP 53465]
[New LWP 53470]
[New LWP 53468]
[New LWP 53467]
[New LWP 53483]
[New LWP 53491]
[New LWP 53486]
[New LWP 53478]
[New LWP 53469]
[New LWP 53473]
[New LWP 53492]
[New LWP 53471]
[New LWP 53484]
[New LWP 53472]
[New LWP 53489]
[New LWP 53488]
[New LWP 53482]
[New LWP 53490]
[New LWP 53487]
[New LWP 53481]
[New LWP 53485]
[New LWP 53474]
[New LWP 53480]

warning: Can't read pathname for load map: Input/output error.
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Core was generated by `(squid-1) -YC -f /etc/squid/squid.conf'.
Program terminated with signal 6, Aborted.
#0  0x00007f81777ab165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
(gdb) backtrace
#0  0x00007f81777ab165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f81777ae3e0 in abort () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x000000000055b10f in xassert (msg=<optimized out>, file=<optimized
out>, line=<optimized out>) at debug.cc:566
#3  0x00000000006adbc8 in commSetConnTimeout (conn=..., timeout=15,
callback=...) at comm.cc:769
#4  0x000000000052d9ca in ConnStateData::getSslContextDone
(this=this at entry=0x1895518b8, sslContext=<optimized out>,
sslContext at entry=0x1890abac0, isNew=isNew at entry=false) at
client_side.cc:3997
#5  0x000000000052e530 in ConnStateData::getSslContextStart
(this=this at entry=0x1895518b8) at client_side.cc:3907
#6  0x000000000052eb49 in ConnStateData::httpsPeeked (this=0x1895518b8,
serverConnection=...) at client_side.cc:4069
#7  0x0000000000596188 in UnaryMemFunT<ConnStateData,
RefCount&lt;Comm::Connection>, RefCount<Comm::Connection> >::doDial
(this=0x188dcda00) at base/AsyncJobCalls.h:113
#8  0x000000000053b0aa in JobDialer<ConnStateData>::dial (this=0x188dcda00,
call=...) at base/AsyncJobCalls.h:166
#9  0x00000000006a28d9 in AsyncCall::make (this=0x188dcd9d0) at
AsyncCall.cc:32
#10 0x00000000006a653f in AsyncCallQueue::fireNext
(this=this at entry=0xdb01b0) at AsyncCallQueue.cc:52
#11 0x00000000006a6870 in AsyncCallQueue::fire (this=0xdb01b0) at
AsyncCallQueue.cc:38
#12 0x000000000056c39c in EventLoop::runOnce
(this=this at entry=0x7fffe23c3690) at EventLoop.cc:135
#13 0x000000000056c528 in EventLoop::run (this=0x7fffe23c3690) at
EventLoop.cc:99
#14 0x00000000005e3b6a in SquidMain (argc=<optimized out>, argv=<optimized
out>) at main.cc:1528
#15 0x00000000004f26cb in SquidMainSafe (argv=<optimized out>,
argc=<optimized out>) at main.cc:1260
#16 main (argc=<optimized out>, argv=<optimized out>) at main.cc:1252
(gdb)




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/assertion-failed-comm-cc-769-Comm-IsConnOpen-conn-tp4669842p4669927.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Tue Feb 17 21:45:34 2015
From: hack.back at hotmail.com (HackXBack)
Date: Tue, 17 Feb 2015 13:45:34 -0800 (PST)
Subject: [squid-users] assertion failed: comm.cc:769:
	"Comm::IsConnOpen(conn)"
In-Reply-To: <1424209440077-4669927.post@n4.nabble.com>
References: <1424025171679-4669842.post@n4.nabble.com>
 <1424209440077-4669927.post@n4.nabble.com>
Message-ID: <1424209534367-4669928.post@n4.nabble.com>

root at dotspot:~# squid -v
Squid Cache: Version 3.4.9
build by : ANDO_TBLRB && HackXBack
configure options:  '--prefix=/usr' '--bindir=/usr/bin'
'--sbindir=/usr/sbin' '--libexecdir=/usr/lib/squid'
'--sysconfdir=/etc/squid' '--localstatedir=/var' '--libdir=/usr/lib'
'--includedir=/usr/include' '--datadir=/usr/share/squid'
'--infodir=/usr/share/info' '--mandir=/usr/share/man'
'--disable-dependency-tracking' '--disable-strict-error-checking'
'--enable-async-io=32' '--with-aufs-threads=32' '--with-pthreads'
'--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap'
'--with-aio' '--with-dl' '--disable-icmp' '--enable-esi'
'--enable-icap-client' '--disable-wccp' '--enable-wccpv2'
'--enable-kill-parent-hack' '--enable-cache-digests' '--disable-select'
'--enable-http-violations' '--enable-linux-netfilter'
'--enable-follow-x-forwarded-for' '--disable-ident-lookups'
'--enable-x-accelerator-vary' '--enable-zph-qos' '--with-default-user=proxy'
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'
'--with-swapdir=/var/spool/squid' '--with-large-files'
'--enable-ltdl-convenience' '--with-filedescriptors=65536' '--enable-ssl'
'--enable-ssl-crtd' '--with-openssl' '--disable-auth' '--disable-ipv6'
'--enable-build-info=build by : ANDO_TBLRB && HackXBack'
'--with-included-ltdl' '--enable-arp-acl' '--enable-epoll' '--enable-snmp'
'--enable-referer-log' '--disable-unlinkd' '--enable-truncate'
'--enable-useragent-log' '--enable-eui' '--enable-large-cache-files'
'--with-maxfd=65536' 'CFLAGS=-Wall -g -O3 -march=native -mtune=native -pipe
-DNUMTHREADS=60 -fomit-frame-pointer -fno-strict-aliasing -funroll-loops
-ffast-math -fno-exceptions' 'LDFLAGS=-Wl,-Bsymbolic-functions'




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/assertion-failed-comm-cc-769-Comm-IsConnOpen-conn-tp4669842p4669928.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue Feb 17 21:54:15 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 Feb 2015 10:54:15 +1300
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <000001d04b1e$eed171b0$cc745510$@netstream.ps>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
 <54E29849.4040707@treenet.co.nz>
 <000001d04b1e$eed171b0$cc745510$@netstream.ps>
Message-ID: <54E3B887.5020104@treenet.co.nz>

On 18/02/2015 3:02 p.m., snakeeyes wrote:
> Hi Amos,
> 
> Lets forget the authentication now  I don?t need it now  I will use the ACL Rules on squid only
> 
> Wt I need to configure squid so that it handle requests from HAproxy ?


This:

  acl from_haproxy src <IP of HAProxy machine>
  http_access allow from_haproxy


If you want the PROXY protocol wrapping/tunnel as well, see
<http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html#ss2.7>


Amos



From squid3 at treenet.co.nz  Tue Feb 17 22:13:16 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 Feb 2015 11:13:16 +1300
Subject: [squid-users] ssl proxy error: No valid signing SSL certificate
 configured for https_port [::]:3127
In-Reply-To: <54E34896.4000300@yahoo.com>
References: <54E1115E.3040804@yahoo.com> <54E1144C.2040503@ngtech.co.il>
 <54E217D5.70005@yahoo.com> <54E272EE.8040506@treenet.co.nz>
 <54E34896.4000300@yahoo.com>
Message-ID: <54E3BCFC.4070903@treenet.co.nz>

On 18/02/2015 2:56 a.m., Alan Palmer wrote:
> 
> Its not just specifying separate lines for the split stack, using the
> non-specific addresses 0.0.0.0 and [::] fails.  I had to put a real ip
> address, in this case loopback, but using another real interface on my
> machine also worked.
> 
> Bug/'Feature' in OpenBSD 5.6 implementation or all split stack OSs?
> 

It will be the same on all.

Can you try with the patch here:
http://www.squid-cache.org/Versions/v3/3.4/changesets/squid-3.4-13208.patch

Amos



From eliezer at ngtech.co.il  Tue Feb 17 22:25:36 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 18 Feb 2015 00:25:36 +0200
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <000101d04b1f$31d311d0$95793570$@netstream.ps>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
 <54E28D0D.7070208@ngtech.co.il>
 <000101d04b1f$31d311d0$95793570$@netstream.ps>
Message-ID: <54E3BFE0.4030502@ngtech.co.il>

Hey,

There are couple ways to look at authentication and some would sometimes 
trade authorization to authentication and vise versa.

In some environments there is a mix of both terms which is required to 
build a logical service unit.
I do not have all my archives but I remember that someone have asked 
about some single sign on system which grants access using a login page 
to many in campus systems.
It was based on a very complex system which I do not remember right now.

There are options to run some process triggered by a radius server login 
or any other system that would be considered the authorization authority 
to mark a specific IP as ALLOWED or under some group.
I know that there are many network systems which uses a network level 
authorization and it is very useful.
The main difference between directly authenticating to squid vs 3rd 
party authentication is the way and level of authentication.

For example a radius server with an enterprise level switch and\or wifi 
access point can provide authentication encryption layer which squid 
direct authentication cannot provide and no matter what you will do.
Of course that in many cases it will require absolute reliability and 
should not allow mistakes.
One rule of thumb in the raidus lands network authentication security 
level is:
Every authenticated user can be only identified with one IP at a time.

So yes squid doesn't support a direct proxy authentication level in 
intercept and tproxy modes BUT using some external_acl helpers it's 
pretty simple to connect squid and an external authentication system. 
Here the answer turns the tables and makes it possible to authenticate 
even in intercept and tproxy mode but not at the same way many might 
think of.

All The Bests,
Eliezer

On 18/02/2015 04:04, snakeeyes wrote:
> Thanks eleizer , but does it support other types like radius authentication ?
>
> I mean all types of  authentications are forbidden in intercept mode ?




From eliezer at ngtech.co.il  Tue Feb 17 23:22:59 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 18 Feb 2015 01:22:59 +0200
Subject: [squid-users] Squid latency at ApacheCon 2014 in comparison
 between Squid, NGINX, Apache Traffic Server, Varnish and Apache
In-Reply-To: <1424185126.4005.36.camel@hi.is>
References: <1424185126.4005.36.camel@hi.is>
Message-ID: <54E3CD53.30504@ngtech.co.il>

Hey Anna,

Thanks for the links and the detailed comments and thoughts.
In most cases I am not a friend of countering others if not really needed.
I have yet to implement VARNISH or ATS in production and the blame for 
this is strictly on me since I am a bit spoiled and a learning curve is 
not always what I seek.
I have been told more then once or twice in my past to "google" things 
which I see as a very bad habit.
Not everyone can use google to understand or learn things and a simple 
example might be a Doctor of Medicine.

Squid or any other proxy system operation requires more then some might 
have and it is the same to about writing and running a performance test.

Any of the pieces of software you have mentioned are very complex to 
understand and operate.
I assume that if someone would be willing to write a performance tests 
and comparison he would need more then basic knowledge of 
IP,HTTP,Programming, Math and many other CS related subjects and last 
but not least a bit humility.

I am unsure about me meeting the profile which allows me to say this or 
that about Mr. Call's work.

And still what I can bring to the desk is that every setup is different 
in too much levels.
Before deciding that squid CPU usage might be an issue we can make sure 
that we are looking for a tool which will provide a stable service.
I can take out of this picture a DDOS "ready" system.
There is no such thing as a bullet proof system what so ever.

Squid strives to cache any of the cachable GET requests considering the 
server side in the picture while allowing stable operations for a well 
respected period of time.
I have implemented couple times a webserver based NGINX and I have 
discovered that a human wrote this software and not god and which I 
respect very well and uses for very specific tasks.
However squid won in many cases due to it's reliability and user\admin 
friendliness.

Varnish is a very good product that can beat squid in many ways.. and If 
I had time to learn it a bit more.. I would might do that.

With all the above in mind I learned to believe that squid works very good.
Yes indeed in cases which you would run it ontop a 8 cores machine(not 
HyperThreaded) with 0 disk cache or local logging you can see that 1 
worker\process can take some load but as you rise the workers size to 6 
you will start to see miracles.
Ho and yea, squid uses md5 each time a request flows in so it takes 
CPU... also it runs a lookup for this MD5 hash.. takes CPU.

Like I would say just anyone that wants to implement a squid solution do 
first:
Run a dumb test of squid with enough workers to take the load and not 
crack( 1k per sec per worker is fine.).
Use only the default cahce ram size and default rules with no cache_dirs.
Measure the server load using the cachemgr interface.
After you got the basic load of the system tune the workers to match a 
higher load but not too high.
In this state of squid with multiple workers and RAM ONLY(defaults) 
caching you throw in the needed settings for the cache_peers.

Be aware that you might see some high CPU usage in a DDOS alert status 
and maybe even on normal operations.

Now the main issue is: How it works now with little ram and no disk 
cache at all.

I have proved in the past that for a specific client of mine nginx was a 
very bad choice while squid out of the box with a bit of tuning(max 
object size and 4 workers) gave a piece of mind to his website.

So first test then tune and only then get a conclusion that meets your 
environment.

* They are all good!! "SQUID,ATS,NGINX,VARNISH"


And Anna if you have some specific performance issues with nginx and 
considering the options feel free to contact me off-list aobut it.

All The Bests,
Eliezer

On 17/02/2015 16:58, Anna Jonna Armannsdottir wrote:
> I spent the last weeks searching but I have not found anything that
> seems to counter Mr. Call's claim. On behalf of the Squid developers and
> users, I would be wery grateful if anybody could show or demonstrate the
> contrary. Preferably with configuration.
>
> About me:
> I have been a Squid proxy admin for almost 10 years now, and also
> administrating web cluster solutions for a small university. I am
> already deploying VRRP with NGINX as a load-balancer, but me and my
> coworkers are not satisfied with its performance.
>
> Best regards,
> -- Anna Jonna Armannsdottir <annaj at hi.is> University of Iceland
> Computing Services




From squid3 at treenet.co.nz  Wed Feb 18 00:44:06 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 Feb 2015 13:44:06 +1300
Subject: [squid-users] Squid latency at ApacheCon 2014 in comparison
 between Squid, NGINX, Apache Traffic Server, Varnish and Apache
In-Reply-To: <1424185126.4005.36.camel@hi.is>
References: <1424185126.4005.36.camel@hi.is>
Message-ID: <54E3E056.7030007@treenet.co.nz>

On 18/02/2015 3:58 a.m., Anna Jonna Armannsdottir wrote:
> Hi everybody! 
> My question may be rather theoretical, but in essence I need to know if
> Squid really has a flaw regarding latency for connections where
> keepalive is on. 
> 
> At ApacheCon 2014, Bryan Call presented slides where slides nr. 40 to 49
> show where he writes on slide 46 about Squid: 
> "Worst median latency for keep-alive benchmarks" . 
> The slides are here:
> http://www.slideshare.net/bryan_call/choosing-a-proxy-server-apachecon-2014 
> The configuration for Squid is shown on slide nr. 36. To my eyes it
> looks a little over simplistic. I hope he has not configured Squid
> correctly and that somebody here can point me at better configuration
> that expressly does not have latency of many seconds and a 95 percentile
> of over 10 seconds. Those numbers were achieved by mesurement using
> CoAdvisor 
> ( see
> http://coad.measurement-factory.com/cgi-bin/coad/FaqCgi?item_id=ALL )
> 


Thank you for pointing this out. Its nice to see someone other than me
mentioning '00K RPS rates for Squid, even if it is just lab tests.

We also usually end up with some performance improvements whenever
anyone tests anything. This time could be the I/O latency :-)
[cc'ing the squid-dev mailign list in case anyone there want to also
respond or pick up the challenge of improving latency.]


> My intent, is to use Squid with CARP or VRRP as a reverse proxy and load
> balancer for a cluster of webservers. 
> 
> My main reason for using Squid rather than NGINX or ATX or Varnish is
> Squid's superior protocol compliance. Byan Call's demostrated latency 
> gives me reasons for concern. 

Its not clear on a few points that are needed for replication of the
results:

* what software versions he is using.

We had a lot of trouble with Varnish vs Squid benchmarks where the
latest Varnish was being compared to a 10-year-older Squid version. In
our tests a conteporary Squid proved to be within 20% of Varnish speed,
but the published documents showed orders of magnitude difference.

Also, event driven software like Squid has a "sweet spot" for peak
performance balancing CPU between processing I/O queue or event queue.
At that spot latency is quite low, go higher and the event processing
increases it, go lower and modern CPUs decrease their power usage to
reduce available cycles. 1K clients looks suspiciously like its just
over the sweet spot for the currently most popular squid-3 versions. I
like to see what a comparison looks like with +/- 200 clients.


* How many cores the test machine had for the proxy to use.

Its not clear if his testing was on a machine with 25+ physical cores.
If not then there is worker contention for CPU time going on.

Squid was historically designed to make the most of a single-core CPU,
all that design is still present in each worker so its best to allocate
only one worker per CPU with a spare core for the OS (virtual or
hyperthreaded cores dont count). There is also threading in Squid
(contrary to slide 29), but that is mostly for disk I/O so he can be
forgiven for ignoring it.

Its not clear how many worker processes or thread httpd or Varnish are
using. Maybe their defaults which are quite high.

NginX is also stuck with 24 workers. They are more lightweight than
Squid ones, however...

ATS is configured with 3 "lightweight threads" which should work
stunningly well for anything at or above a single quad-core CPU.


* whether the test is done over a network link, or the loccalhost
machien is oping with both the leint and proxy and server


Some oddities:

* on slide 40-41 I am surprised to see that both ATS and Varnish are
supplying more responses per second than the test client was reportedly
sending. Note how its "100K rated limited", but they reach above 100K RPS.


* If you look closely there is a 5x reduction in latency by closing TCP
connections immediately after processing one request. Despite Squid
processing quite a lot more code in the close case. The CPU usage
numbers do match the extra processing though. This maybe something we
could improve.


* slide 28 mention of open()/locking - those are completely irrelevant
to properly written event processing. Though its common to see
*threading* processing model people write code like that. As if an event
was a thread that could pause.



* Not sure if its an oddity since its so common, but there is a clearly
a biased review.

Listing only how others compare to ATS features rather than how they all
stand overall. Slide 44 claim of "Best cache implementation" seems a
little rich given the lack of HTTP/1.1 features shown - fastest
responding in these tests perhapse. Claim of Apache community as a
bonus, but no mention of others having any communities. Probably other
suble things.


> 
> I spent the last weeks searching but I have not found anything that
> seems to counter Mr. Call's claim. On behalf of the Squid developers and
> users, I would be wery grateful if anybody could show or demonstrate the
> contrary. Preferably with configuration. 
> 

Since Adrian left us a few years back nobody has been doing detailed
performance analysis an test results on Squid AFAIK. We run CI polygraph
and coadvisor tests to try and make gains but there are many small
specific areas they dont cover in detail - at least in the setup we have.



1) pipeline_prefetch directive in Squid defaults to 1.

Meaning that keep-alive only saves on TCP handshake latency, not on HTTP
request parsing latency. AIUI the others default to a pipeline length of
5 or 10 so they can process the HTTP bytes 5-10x more parallel.

In a lab benchmark this matters since TCP latency is often extremely
small and variable whereas HTTP latency is from a fixed amount of
message bytes.


2) I would also like to point out the implicit meaning of slides 22 & 24.

The lack of HTTP feature support in the other software indicates that
their processing pathways are checking for less cases and conditions in
each protocol message. I have been finding that CPU consumption of Squid
rises each time new HTTP features are supported. Within the CPU
capabilities the performance and/or caching ability grows better, but we
are spending CPU to gain that. His tests are not exactly straining the
extra HTTP features (mostly relevant to MISS traffic and revalidation**)
the others are lacking, so Squid is effectively wasting CPU cycles
checking or setting up message state for them.
  ** I doubt it given the lab test. But if the "100% HIT" was actually a
near-HIT needing revalidation under HTTP/1.1 conditions Squid may have
extra server latency hiding in the background there.

We are already going down the track of reducing that type of
pre-processing work for squid-3.6+, but there is only so much that is
possible.



> About me: 
> I have been a Squid proxy admin for almost 10 years now, and also
> administrating web cluster solutions for a small university. I am
> already deploying VRRP with NGINX as a load-balancer, but me and my
> coworkers are not satisfied with its performance. 


If Squid is not up to your needs there I suggest taking a look at
HAproxy. Its specializing in the LB role and Willy T. is pretty "onto
it" with both performance and HTTP/1.1 compliance.

Amos


From hectorchan at gmail.com  Wed Feb 18 01:18:17 2015
From: hectorchan at gmail.com (Hector Chan)
Date: Tue, 17 Feb 2015 17:18:17 -0800
Subject: [squid-users] usage of sslcapath in cache_peer
Message-ID: <CAEhCwUypWXJ1O3id+hV_uGzSM_VUt2fz7OEC-0NfAan2o+xOAw@mail.gmail.com>

Hi All,

I have a question about using sslcapath in cache_peer.  My
server.example.com has a self-signed cert, which I imported into my squid
box under /data/certs.  The following cache_peer line actually worked.
However, if I remove the sslcafile, squid won't verify the self-signed cert.

cache_peer server.example.com parent 443 0 \
       no-query originserver ssl \
       forceddomain=server.example.com \
       login=PASS \
       sslcert=/data/certs/certificate sslkey=/data/certs/key \
       ssloptions=NO_SSLv2,NO_SSLv3 \
       sslcafile=/data/cacerts/72af835f.0 \
       sslcapath=/data/cacerts

[admin at dsg214 cacerts]# ls -l
total 0
lrwxrwxrwx 1 admin root 53 Feb 18 00:22 35fa123a.0 ->
../certs/a4a521af41327a4ab3ff1feb16a1a76888a0c2ea.crt

Running openssl command from the squid box verified the certificate chain
ok with the -CApath option, which really puzzled me.
# openssl s_clients -CApath /data/certs -connect server.example.com:443

Any ideas?

Thanks,
Hector
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150217/89b01100/attachment.htm>

From hectorchan at gmail.com  Wed Feb 18 01:24:26 2015
From: hectorchan at gmail.com (Hector Chan)
Date: Tue, 17 Feb 2015 17:24:26 -0800
Subject: [squid-users] usage of sslcapath in cache_peer
In-Reply-To: <CAEhCwUypWXJ1O3id+hV_uGzSM_VUt2fz7OEC-0NfAan2o+xOAw@mail.gmail.com>
References: <CAEhCwUypWXJ1O3id+hV_uGzSM_VUt2fz7OEC-0NfAan2o+xOAw@mail.gmail.com>
Message-ID: <CAEhCwUzzTOMuzAtGHBSiY0Efc8q_vvStaGAK3nciizNBwAum3g@mail.gmail.com>

Forgot to add.  The actual cert is world readable.

[admin at dsg214 ~]# ll
/data/cacerts/../certs/a4a521af41327a4ab3ff1feb16a1a76888a0c2ea.crt
-rw-r--r-- 1 admin root 1108 Feb 18 00:21
/data/cacerts/../certs/a4a521af41327a4ab3ff1feb16a1a76888a0c2ea.crt

On Tue, Feb 17, 2015 at 5:18 PM, Hector Chan <hectorchan at gmail.com> wrote:

> Hi All,
>
> I have a question about using sslcapath in cache_peer.  My
> server.example.com has a self-signed cert, which I imported into my squid
> box under /data/certs.  The following cache_peer line actually worked.
> However, if I remove the sslcafile, squid won't verify the self-signed cert.
>
> cache_peer server.example.com parent 443 0 \
>        no-query originserver ssl \
>        forceddomain=server.example.com \
>        login=PASS \
>        sslcert=/data/certs/certificate sslkey=/data/certs/key \
>        ssloptions=NO_SSLv2,NO_SSLv3 \
>        sslcafile=/data/cacerts/72af835f.0 \
>        sslcapath=/data/cacerts
>
> [admin at dsg214 cacerts]# ls -l
> total 0
> lrwxrwxrwx 1 admin root 53 Feb 18 00:22 35fa123a.0 ->
> ../certs/a4a521af41327a4ab3ff1feb16a1a76888a0c2ea.crt
>
> Running openssl command from the squid box verified the certificate chain
> ok with the -CApath option, which really puzzled me.
> # openssl s_clients -CApath /data/certs -connect server.example.com:443
>
> Any ideas?
>
> Thanks,
> Hector
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150217/247e4790/attachment.htm>

From squid3 at treenet.co.nz  Wed Feb 18 01:52:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 Feb 2015 14:52:24 +1300
Subject: [squid-users] assertion failed: comm.cc:769:
	"Comm::IsConnOpen(conn)"
In-Reply-To: <1424209440077-4669927.post@n4.nabble.com>
References: <1424025171679-4669842.post@n4.nabble.com>
 <1424209440077-4669927.post@n4.nabble.com>
Message-ID: <54E3F058.3040200@treenet.co.nz>

On 18/02/2015 10:44 a.m., HackXBack wrote:
> root at dotspot:~# gdb /usr/sbin/squid /var/spool/squid/cache/squid/core.53359
> GNU gdb (GDB) 7.4.1-debian

> Core was generated by `(squid-1) -YC -f /etc/squid/squid.conf'.
> Program terminated with signal 6, Aborted.
> #0  0x00007f81777ab165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
> (gdb) backtrace
> #0  0x00007f81777ab165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
> #1  0x00007f81777ae3e0 in abort () from /lib/x86_64-linux-gnu/libc.so.6
> #2  0x000000000055b10f in xassert (msg=<optimized out>, file=<optimized
> out>, line=<optimized out>) at debug.cc:566
> #3  0x00000000006adbc8 in commSetConnTimeout (conn=..., timeout=15,
> callback=...) at comm.cc:769
> #4  0x000000000052d9ca in ConnStateData::getSslContextDone
> (this=this at entry=0x1895518b8, sslContext=<optimized out>,
> sslContext at entry=0x1890abac0, isNew=isNew at entry=false) at
> client_side.cc:3997
> #5  0x000000000052e530 in ConnStateData::getSslContextStart
> (this=this at entry=0x1895518b8) at client_side.cc:3907
> #6  0x000000000052eb49 in ConnStateData::httpsPeeked (this=0x1895518b8,
> serverConnection=...) at client_side.cc:4069
> #7  0x0000000000596188 in UnaryMemFunT<ConnStateData,
> RefCount&lt;Comm::Connection>, RefCount<Comm::Connection> >::doDial
> (this=0x188dcda00) at base/AsyncJobCalls.h:113

The client is disconnecting or some other error is happening to close
the connection before the SSL context is setup. The SSL-bump code in 3.4
and older does not handle that at all well.

If you are able can you please try 3.5 and see if the problem is
resolved. There was some timeout handling added there, but I'm not sure
if it covers this particular case.

Amos



From squid3 at treenet.co.nz  Wed Feb 18 01:58:24 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 Feb 2015 14:58:24 +1300
Subject: [squid-users] usage of sslcapath in cache_peer
In-Reply-To: <CAEhCwUzzTOMuzAtGHBSiY0Efc8q_vvStaGAK3nciizNBwAum3g@mail.gmail.com>
References: <CAEhCwUypWXJ1O3id+hV_uGzSM_VUt2fz7OEC-0NfAan2o+xOAw@mail.gmail.com>
 <CAEhCwUzzTOMuzAtGHBSiY0Efc8q_vvStaGAK3nciizNBwAum3g@mail.gmail.com>
Message-ID: <54E3F1C0.1010605@treenet.co.nz>

On 18/02/2015 2:24 p.m., Hector Chan wrote:
> Forgot to add.  The actual cert is world readable.
> 
> [admin at dsg214 ~]# ll
> /data/cacerts/../certs/a4a521af41327a4ab3ff1feb16a1a76888a0c2ea.crt
> -rw-r--r-- 1 admin root 1108 Feb 18 00:21
> /data/cacerts/../certs/a4a521af41327a4ab3ff1feb16a1a76888a0c2ea.crt
> 
> On Tue, Feb 17, 2015 at 5:18 PM, Hector Chan <hectorchan at gmail.com> wrote:
> 
>> Hi All,
>>
>> I have a question about using sslcapath in cache_peer.  My
>> server.example.com has a self-signed cert, which I imported into my squid
>> box under /data/certs.  The following cache_peer line actually worked.
>> However, if I remove the sslcafile, squid won't verify the self-signed cert.
>>
>> cache_peer server.example.com parent 443 0 \
>>        no-query originserver ssl \
>>        forceddomain=server.example.com \
>>        login=PASS \
>>        sslcert=/data/certs/certificate sslkey=/data/certs/key \
>>        ssloptions=NO_SSLv2,NO_SSLv3 \
>>        sslcafile=/data/cacerts/72af835f.0 \
>>        sslcapath=/data/cacerts
>>
>> [admin at dsg214 cacerts]# ls -l
>> total 0
>> lrwxrwxrwx 1 admin root 53 Feb 18 00:22 35fa123a.0 ->
>> ../certs/a4a521af41327a4ab3ff1feb16a1a76888a0c2ea.crt
>>
>> Running openssl command from the squid box verified the certificate chain
>> ok with the -CApath option, which really puzzled me.
>> # openssl s_clients -CApath /data/certs -connect server.example.com:443
>>
>> Any ideas?

Those parameters are treated as strings passed directly as the input to
this OpenSSL API:
<http://www.openssl.org/docs/ssl/SSL_CTX_load_verify_locations.html>

It does not seem to define what happens if CAFile is NULL. So anything
could happen.

Amos


From eraya at a21an.org  Wed Feb 18 08:02:02 2015
From: eraya at a21an.org (Eray Aslan)
Date: Wed, 18 Feb 2015 08:02:02 +0000
Subject: [squid-users] squid-3.5.1 with perl-5.20
Message-ID: <20150218080202.GA2507@angelfall>

I have a user report that says ext_wbinfo_group_acl is not working with
perl-5.20:

Global symbol "$groupSID" requires explicit package name at
/usr/libexec/squid/ext_wbinfo_group_acl
in cache.log and these lines:
FATAL: The nt_group helpers are crashing too rapidly, need help!
Squid Cache (Version 3.5.1): Terminated abnormally.

Apparently, the following patch fixes the problem:

--- helpers/external_acl/wbinfo_group/ext_wbinfo_group_acl.pl.in.orig	2015-02-09 21:50:59.184021388 +0300
+++ helpers/external_acl/wbinfo_group/ext_wbinfo_group_acl.pl.in	2015-02-09 21:52:56.759492956 +0300
@@ -121,6 +121,11 @@
 #
 use vars qw/ %opt /;
 
+my $user;
+my $group;
+my @groups;
+my $ans;
+
 # Disable output buffering
 $|=1;
 
@@ -132,7 +137,11 @@
 # Check if a user belongs to a group
 #
 sub check {
-        local($user, $group) = @_;
+	my $groupSID;
+	my $groupGID;
+	my @tmpuser;
+
+        our($user, $group) = @_;
 	if ($opt{K} && ($user =~ m/\@/)) {
 		@tmpuser = split(/\@/, $user);
 		$user = "$tmpuser[1]\\$tmpuser[0]";

Details at:
https://bugs.gentoo.org/show_bug.cgi?id=539500

-- 
Eray


From mkraju123 at gmail.com  Wed Feb 18 08:33:52 2015
From: mkraju123 at gmail.com (Raju M K)
Date: Wed, 18 Feb 2015 14:03:52 +0530
Subject: [squid-users] Latest squid for Windows
Message-ID: <CAGycgFjjXnun7Q+Lz_DbLF6YbEcrMXY2UhDaNshCZBdafsvEAA@mail.gmail.com>

Dear Team,
Where can i get Latest Squid Binary(compiled one) package for windows??


-- 
Regards,
M K Raju.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150218/e53a78e6/attachment.htm>

From yvoinov at gmail.com  Wed Feb 18 08:40:25 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 Feb 2015 14:40:25 +0600
Subject: [squid-users] Latest squid for Windows
In-Reply-To: <CAGycgFjjXnun7Q+Lz_DbLF6YbEcrMXY2UhDaNshCZBdafsvEAA@mail.gmail.com>
References: <CAGycgFjjXnun7Q+Lz_DbLF6YbEcrMXY2UhDaNshCZBdafsvEAA@mail.gmail.com>
Message-ID: <54E44FF9.9030001@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

http://packages.diladele.com/squid/squid.msi

18.02.15 14:33, Raju M K ?????:
> Dear Team, Where can i get Latest Squid Binary(compiled one)
> package for windows??
> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU5E/5AAoJENNXIZxhPexGPoQH/A+6yv0yv28r3jwZUWEFPmU+
DX1I0DkpTtKGnI3l78eopzahWn3lCilKHZBqRVpQruDrgjxCp8SLa33Fuis8x8cM
FV2Aoyc6gc6iOP+HDXM2n5NaeVuaxhK7gaau/sVjawxzKGiwqtRcdEDdkpzTa3ST
2ComqEMBP8+sHW8u7Ndi+xE4jtVhNSmodUBfh+UL9YxYML2yDaq3YBTpAubjjq4p
Xc0D1qbLZpMt0IUIWqsOtDf5qOHByiagMAh5R25kcaf+E3eKBoU/H8Vb64ROeSlx
IY7D3g3YZblZmBu9+bRFGXRU5/mvT/f7VyN21+VNI7nK9VHBcDKmGATeofJ4pfs=
=mFps
-----END PGP SIGNATURE-----


From rafael.akchurin at diladele.com  Wed Feb 18 08:54:56 2015
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 18 Feb 2015 08:54:56 +0000
Subject: [squid-users] Latest squid for Windows
In-Reply-To: <54E44FF9.9030001@gmail.com>
References: <CAGycgFjjXnun7Q+Lz_DbLF6YbEcrMXY2UhDaNshCZBdafsvEAA@mail.gmail.com>,
 <54E44FF9.9030001@gmail.com>
Message-ID: <1424249702082.21581@diladele.com>

Hello Raju,

And if you would like to get involved please also visit http://squid.diladele.com to get to the GitHub repo.
@Yuri - I remember about HTTPS filtering in squid windows settings - give me two more days please :)

Raf


________________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Yuri Voinov <yvoinov at gmail.com>
Sent: Wednesday, February 18, 2015 9:40 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Latest squid for Windows

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

http://packages.diladele.com/squid/squid.msi

18.02.15 14:33, Raju M K ?????:
> Dear Team, Where can i get Latest Squid Binary(compiled one)
> package for windows??
>
>
>
>
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU5E/5AAoJENNXIZxhPexGPoQH/A+6yv0yv28r3jwZUWEFPmU+
DX1I0DkpTtKGnI3l78eopzahWn3lCilKHZBqRVpQruDrgjxCp8SLa33Fuis8x8cM
FV2Aoyc6gc6iOP+HDXM2n5NaeVuaxhK7gaau/sVjawxzKGiwqtRcdEDdkpzTa3ST
2ComqEMBP8+sHW8u7Ndi+xE4jtVhNSmodUBfh+UL9YxYML2yDaq3YBTpAubjjq4p
Xc0D1qbLZpMt0IUIWqsOtDf5qOHByiagMAh5R25kcaf+E3eKBoU/H8Vb64ROeSlx
IY7D3g3YZblZmBu9+bRFGXRU5/mvT/f7VyN21+VNI7nK9VHBcDKmGATeofJ4pfs=
=mFps
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Wed Feb 18 09:45:21 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 Feb 2015 15:45:21 +0600
Subject: [squid-users] Latest squid for Windows
In-Reply-To: <1424249702082.21581@diladele.com>
References: <CAGycgFjjXnun7Q+Lz_DbLF6YbEcrMXY2UhDaNshCZBdafsvEAA@mail.gmail.com>,
 <54E44FF9.9030001@gmail.com> <1424249702082.21581@diladele.com>
Message-ID: <54E45F31.1080106@gmail.com>

Raf, no problem ;) Remain functionality works charm. ;)

18.02.15 14:54, Rafael Akchurin ?????:
> Hello Raju,
>
> And if you would like to get involved please also visit http://squid.diladele.com to get to the GitHub repo.
> @Yuri - I remember about HTTPS filtering in squid windows settings - give me two more days please :)
>
> Raf
>
>
> ________________________________________
> From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Yuri Voinov <yvoinov at gmail.com>
> Sent: Wednesday, February 18, 2015 9:40 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Latest squid for Windows
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> http://packages.diladele.com/squid/squid.msi
>
> 18.02.15 14:33, Raju M K ?????:
>> Dear Team, Where can i get Latest Squid Binary(compiled one)
>> package for windows??
>>
>>
>>
>>
>> _______________________________________________ squid-users mailing
>> list squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBAgAGBQJU5E/5AAoJENNXIZxhPexGPoQH/A+6yv0yv28r3jwZUWEFPmU+
> DX1I0DkpTtKGnI3l78eopzahWn3lCilKHZBqRVpQruDrgjxCp8SLa33Fuis8x8cM
> FV2Aoyc6gc6iOP+HDXM2n5NaeVuaxhK7gaau/sVjawxzKGiwqtRcdEDdkpzTa3ST
> 2ComqEMBP8+sHW8u7Ndi+xE4jtVhNSmodUBfh+UL9YxYML2yDaq3YBTpAubjjq4p
> Xc0D1qbLZpMt0IUIWqsOtDf5qOHByiagMAh5R25kcaf+E3eKBoU/H8Vb64ROeSlx
> IY7D3g3YZblZmBu9+bRFGXRU5/mvT/f7VyN21+VNI7nK9VHBcDKmGATeofJ4pfs=
> =mFps
> -----END PGP SIGNATURE-----
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From ahmed.zaeem at netstream.ps  Wed Feb 18 19:57:37 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Wed, 18 Feb 2015 11:57:37 -0800
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <54E3BFE0.4030502@ngtech.co.il>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
 <54E28D0D.7070208@ngtech.co.il>
 <000101d04b1f$31d311d0$95793570$@netstream.ps>
 <54E3BFE0.4030502@ngtech.co.il>
Message-ID: <001301d04bb5$280b3010$78219030$@netstream.ps>

Great , 
Another question ,
Does it differ if it was http request ot https request ?

I want to authenticate https request and I would like to buy a trusted certificate for that.

Do u think it will be possible ?

-----Original Message-----
From: Eliezer Croitoru [mailto:eliezer at ngtech.co.il] 
Sent: Tuesday, February 17, 2015 2:26 PM
To: squid-users at lists.squid-cache.org
Cc: snakeeyes
Subject: Re: [squid-users] can squid handle indirect request from clients ?

Hey,

There are couple ways to look at authentication and some would sometimes trade authorization to authentication and vise versa.

In some environments there is a mix of both terms which is required to build a logical service unit.
I do not have all my archives but I remember that someone have asked about some single sign on system which grants access using a login page to many in campus systems.
It was based on a very complex system which I do not remember right now.

There are options to run some process triggered by a radius server login or any other system that would be considered the authorization authority to mark a specific IP as ALLOWED or under some group.
I know that there are many network systems which uses a network level authorization and it is very useful.
The main difference between directly authenticating to squid vs 3rd party authentication is the way and level of authentication.

For example a radius server with an enterprise level switch and\or wifi access point can provide authentication encryption layer which squid direct authentication cannot provide and no matter what you will do.
Of course that in many cases it will require absolute reliability and should not allow mistakes.
One rule of thumb in the raidus lands network authentication security level is:
Every authenticated user can be only identified with one IP at a time.

So yes squid doesn't support a direct proxy authentication level in intercept and tproxy modes BUT using some external_acl helpers it's pretty simple to connect squid and an external authentication system. 
Here the answer turns the tables and makes it possible to authenticate even in intercept and tproxy mode but not at the same way many might think of.

All The Bests,
Eliezer

On 18/02/2015 04:04, snakeeyes wrote:
> Thanks eleizer , but does it support other types like radius authentication ?
>
> I mean all types of  authentications are forbidden in intercept mode ?




From hack.back at hotmail.com  Wed Feb 18 09:54:01 2015
From: hack.back at hotmail.com (HackXBack)
Date: Wed, 18 Feb 2015 01:54:01 -0800 (PST)
Subject: [squid-users] assertion failed: comm.cc:769:
	"Comm::IsConnOpen(conn)"
In-Reply-To: <54E3F058.3040200@treenet.co.nz>
References: <1424025171679-4669842.post@n4.nabble.com>
 <1424209440077-4669927.post@n4.nabble.com> <54E3F058.3040200@treenet.co.nz>
Message-ID: <1424253241949-4669944.post@n4.nabble.com>

last time i used 3.5 i lost about 6TB data because squid crash's and then
need to format the hdd's
so am afraid to use it again and no update addedd to that version



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/assertion-failed-comm-cc-769-Comm-IsConnOpen-conn-tp4669842p4669944.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Feb 18 11:29:19 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 18 Feb 2015 13:29:19 +0200
Subject: [squid-users] can squid handle indirect request from clients ?
In-Reply-To: <001301d04bb5$280b3010$78219030$@netstream.ps>
References: <002c01d04a9b$851ab250$8f5016f0$@netstream.ps>
 <54E28D0D.7070208@ngtech.co.il>
 <000101d04b1f$31d311d0$95793570$@netstream.ps>
 <54E3BFE0.4030502@ngtech.co.il>
 <001301d04bb5$280b3010$78219030$@netstream.ps>
Message-ID: <54E4778F.5050104@ngtech.co.il>

Hey,

No it doesn't differ.
You can maybe buy a certificate for this or other use but it's not in 
any squid related lands.
It will be used for EAP encryption and other methods which you may use 
for authentication.

If you wish to block https traffic in any way and allow them only by 
authentication you will might not be able to notify about it to your 
clients.

If you wish to hold an authentication portal which will use https 
certificate then, yes you will be able to buy a single domain 
certificate and by that allowing the user to authenticate him self 
before surfing the https sites.

Is this related to ssl-bump? in any way?

Eliezer

On 18/02/2015 21:57, snakeeyes wrote:
> Great ,
> Another question ,
> Does it differ if it was http request ot https request ?
>
> I want to authenticate https request and I would like to buy a trusted certificate for that.
>
> Do u think it will be possible ?




From richter at richtercloud.de  Wed Feb 18 13:22:27 2015
From: richter at richtercloud.de (Karl-Philipp Richter)
Date: Wed, 18 Feb 2015 13:22:27 +0000
Subject: [squid-users] How to cache everything with an Etag HTTP header?
Message-ID: <4tucwpkqm7kf.ma9n39-4bd4m5oxvsw625@api.elasticemail.com>

Hi,
I'm quite new to advanced squid configuration and want to enhance my
HTTP cache expensive-bandwidth-cheap-storage setup where I'm mostly
interested in storing large downloads with a refresh_pattern, e.g.

    refresh_pattern -i
\.(deb|rpm|exe|zip|tar|tgz|tar\.gz|txz|tar\.xz|ram|rar|bin|ppt|doc|tiff)$ 100800
99% 432000 override-expire override-lastmod
ignore-no-cache ignore-no-store

and after some reading around `refresh_pattern` and some search engine
research I was wondering how to cache everything that provides an Etag
because I thinks that'd be very useful for my scenario (very low starge
cost and very high bandwidth costs).

Any help or pointers are appreciated.

Best regards,
Kalle

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 484 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150218/ace5be53/attachment.sig>

From squid3 at treenet.co.nz  Wed Feb 18 14:32:06 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 Feb 2015 03:32:06 +1300
Subject: [squid-users] How to cache everything with an Etag HTTP header?
In-Reply-To: <4tucwpkqm7kf.ma9n39-4bd4m5oxvsw625@api.elasticemail.com>
References: <4tucwpkqm7kf.ma9n39-4bd4m5oxvsw625@api.elasticemail.com>
Message-ID: <54E4A266.8080104@treenet.co.nz>

On 19/02/2015 2:22 a.m., Karl-Philipp Richter wrote:
> Hi,
> I'm quite new to advanced squid configuration and want to enhance my
> HTTP cache expensive-bandwidth-cheap-storage setup where I'm mostly
> interested in storing large downloads with a refresh_pattern, e.g.
> 
>     refresh_pattern -i
> \.(deb|rpm|exe|zip|tar|tgz|tar\.gz|txz|tar\.xz|ram|rar|bin|ppt|doc|tiff)$ 100800
> 99% 432000 override-expire override-lastmod
> ignore-no-cache ignore-no-store
> 
> and after some reading around `refresh_pattern` and some search engine
> research I was wondering how to cache everything that provides an Etag
> because I thinks that'd be very useful for my scenario (very low starge
> cost and very high bandwidth costs).
> 
> Any help or pointers are appreciated.

Pointer #1 - ETag does mean cacheable. It is just a unique ID for the
object.

In an ideal HTTP world everything has an ETag to identify it, cacheable
or not.

And BTW just by using Squid everything gets stored. Whether its still
usable next time the same URL is requested is another matter entirely.
This is why Squid disk behaviour is mostly-write (2-5 objects written to
disk for every 1 read back out).


Pointer #2 - if your squid accepts the "ignore-no-cache" option then its
too old.

Upgrade to a squid-3.2+ which do HTTP/1.1 caching of
no-cache/private/auth objects then work on it in the context of the
newer versions extra capabilities.


Amos



From yvoinov at gmail.com  Wed Feb 18 14:46:09 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 Feb 2015 20:46:09 +0600
Subject: [squid-users] How to cache everything with an Etag HTTP header?
In-Reply-To: <54E4A266.8080104@treenet.co.nz>
References: <4tucwpkqm7kf.ma9n39-4bd4m5oxvsw625@api.elasticemail.com>
 <54E4A266.8080104@treenet.co.nz>
Message-ID: <54E4A5B1.8000901@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



18.02.15 20:32, Amos Jeffries ?????:
> On 19/02/2015 2:22 a.m., Karl-Philipp Richter wrote:
>> Hi, I'm quite new to advanced squid configuration and want to
>> enhance my HTTP cache expensive-bandwidth-cheap-storage setup
>> where I'm mostly interested in storing large downloads with a
>> refresh_pattern, e.g.
>> 
>> refresh_pattern -i 
>> \.(deb|rpm|exe|zip|tar|tgz|tar\.gz|txz|tar\.xz|ram|rar|bin|ppt|doc|tiff)$
>> 100800 99% 432000 override-expire override-lastmod 
>> ignore-no-cache ignore-no-store
>> 
>> and after some reading around `refresh_pattern` and some search
>> engine research I was wondering how to cache everything that
>> provides an Etag because I thinks that'd be very useful for my
>> scenario (very low starge cost and very high bandwidth costs).
>> 
>> Any help or pointers are appreciated.
> 
> Pointer #1 - ETag does mean cacheable. It is just a unique ID for
> the object.
> 
> In an ideal HTTP world everything has an ETag to identify it,
> cacheable or not.
> 
> And BTW just by using Squid everything gets stored. Whether its
> still usable next time the same URL is requested is another matter
> entirely. This is why Squid disk behaviour is mostly-write (2-5
> objects written to disk for every 1 read back out).

Absolutely right, Amos.

Here is IO stats from my Squid:

http://i.imgur.com/g6P8u8b.png

Writes over reads.

> 
> 
> Pointer #2 - if your squid accepts the "ignore-no-cache" option
> then its too old.
> 
> Upgrade to a squid-3.2+ which do HTTP/1.1 caching of 
> no-cache/private/auth objects then work on it in the context of
> the newer versions extra capabilities.

And, this works like charm - hit ratio not decreasing. ;)

> 
> 
> Amos
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU5KWxAAoJENNXIZxhPexG8IEH/3l4l8nvL1mmXBlN9CVOJYJC
53+LY7jO6WYsJWBooZc4vb73bTOGK27/e8YOOcN5PX9j1f8/bc2fq2jVGysWxTiM
CeDcKkdnyjorQF67gcwdGwBfxEeIf+KSMgqehCsaitBjXSx5NQKx1TcHrj7Ywn8m
UxW2NN8GUehwdybGeN/5GpvovFIgfPVpMoJGHqYpiwZ1b6ca6vgtECe8RiTmB3hf
ZSY0NfQ1vMzC6+sYiYShCmvxY2XA7LcIetBssD4O5epRveRjpG+E3LLE3VCEjlJh
ZCLKuLjrqGGyUnV/14S45if3y1Udz0XOPHJMFTcZ/Ozg1FlIfNCJNZSNL7L8iT4=
=yC9q
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Thu Feb 19 00:01:51 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 Feb 2015 13:01:51 +1300
Subject: [squid-users] [squid-announce] Squid 3.4.12 is available
Message-ID: <54E527EF.6040305@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.4.12 release!


This release is a security fix release resolving several major issues
found in the prior Squid releases.

    REMINDER: This and older releases are already deprecated by
              Squid-3.5 availablility.


The major changes to be aware of:


* Bug #3997: Excessive NTLM or Negotiate auth helper annotations

This bug appears whenever NTLM or Negotiate authentication are taking
place. On a busy server the outward appearance is excessive CPU usage
and associated loss of performance, a memory "leak" may also be seen
depending on the size of authentication token. This state appears at
the worst possible moments when users are busy, and disappears some
time after users stop accessing the proxy.

Deepest apologies that this took so long to pin down, and a great
big Thank You to Steve Hill for tracking it down in the end.


* Bug #4066: Digest auth nonce indefinite rollover

This bug prevented the backend authentication system being contacted
to re-verify user credentials after their TTL has expired. Making it
near impossible to kick off an active user by closing their account or
changing password.

Please note that while this does have a security impact it is NOT
being considerd for an advisory with CVE rating since the user has to
properly authenticate before they can abuse this.

A big Thank You to Frederic Bourgeois for tracking this one down.


* Set cap_net_admin capability when Squid sets TOS/Diffserv packet values.

This bug was behind the strange behaviour on some installations where
TOS/Diffserv packet markings were not being performed despite explicit
configuration. Squid is now retaining the needed security permissions.


* Add TLS/SSL option NO_TICKET to http[s]_port

Squid now supports configuration of the TLS session ticket extension.
Specifically disabling it in situations where its undesirable to allow
OpenSSL the feature.




 All users are encouraged to upgrade to the 3.5 series.

 All users of older 3.4 are urged to upgrade to this release as soon
as possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.4/RELEASENOTES.html
when you are ready to make the switch to Squid-3.4

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU5SfuAAoJELJo5wb/XPRjkoAH/2oCy+NcBYGpv5B70omId8Nr
JkaL0YzDYm2zhPtaSlC8MfVigE8OpA9C95vz2FEvE4/5rMS/6y3Hi1ObWlzPf3N2
iqf7GIuxNo5D200Wzh4j7lMAz+pwEKorK9y+4hssgLfEgkKHp+1SPTGgY3h5HHsP
8TAikJVg40b6pfFihVEyOgYSlMhxYUvehlKt/B6Zm/fUdYu/71xyhp+YG4KK4GYZ
rHRSDzhCFsy/xDSdwjK25fIaPVzl5kQ6poukZ8nkMDKDtfRRGadi/e0pBPlkniN2
pvPkRR1ibqMomO0tAnr9ITu6GNVcPzPhxuUo4Pi+1VYXRN2AJ3Fynx4yPJPUpRw=
=A1g0
-----END PGP SIGNATURE-----
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Thu Feb 19 00:47:54 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 Feb 2015 13:47:54 +1300
Subject: [squid-users] [squid-announce] Squid 3.5.2 is available
Message-ID: <54E532BA.1010702@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.5.2 release!


This release is a bug fix release resolving several issues found in
the prior Squid releases.


The major changes to be aware of:


* Regression Bug #4176: Digest auth too many helper lookups

It was found that the Digest authentication helper was being called to
validate credentials on every client request regardless of an
appropriate TTL or nonce re-use counter being available.

This release decreases CPU usage and improves latency of client
traffic on all installations using Digest authentication.


* SSL-Bump feature transparency improvements

The SSL-Bump feature is now relaying SNI information from the client
to server when performing server-first bumping of intercepted traffic.

The sslproxy_options directive is now no longer being applied to
server connections when peek/stare operations are performed.

Squid will now supply to the external verification helper the missing
root CAs (i.e. fill in the gaps) when validating chains that already
passed internal checks.

Each of these reduces TLS errors induced by the existence of Squid in
the path, making SSL-Bump much more transparent than before.


* Fix some cbdataFree related memory leaks

This resolves some slow memory leaks resulting from the use of
cache_peer. Be aware there are other issues still outstanding which
have the appearance of memory leaks in some installations. If you are
seeing what appears to be a leak this may help, but it also may not be
the whole issue.


* All security fixes from 3.4.12 are also present in this release.



 All users of Squid SSL-Bump feature are urged to upgrade to this
release as soon as possible.

 All users of NTLM or Negotiate (Kerberos) authentication features are
urged to upgrade to this release as soon as possible.

 All users of Squid are encouraged to upgrade to this release as soon as
possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU5TK5AAoJELJo5wb/XPRjtYcH/35kDtQ5zLgtZ1RScVhPjOnT
KKAkLTru/FGPtaonO/fBDV9t3bwqU1NkzIiBfJ0wodkQaAYpg+/iD0Zs7Mjq5++d
0aXoRWEK7n8Pbx1v9UOzymUgweHQqjBeY9iPaViil1mgg0/V70Gvb6qIVGtGU+Qz
8tTeWb1zl66TxdGm++XUb+3seY4jRPfC6RoarhTj5VB6S3n3YUYqJ3njidWwv/oN
NovSJNDSyB7rZKyOyUodURu74Mi/Qoej39SqlGB3pfp1LVujqQjUYaKPCuRT57/q
527Ni5IShf+k2MOCJYFFcuw9Gy9Of9t1E7p7spbADeNyjFuUvjRsE0ZOpN09kpo=
=UkbJ
-----END PGP SIGNATURE-----
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Thu Feb 19 03:04:33 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 Feb 2015 16:04:33 +1300
Subject: [squid-users] squid-3.5.1 with perl-5.20
In-Reply-To: <20150218080202.GA2507@angelfall>
References: <20150218080202.GA2507@angelfall>
Message-ID: <54E552C1.506@treenet.co.nz>

On 18/02/2015 9:02 p.m., Eray Aslan wrote:
> I have a user report that says ext_wbinfo_group_acl is not working with
> perl-5.20:
> 
> Global symbol "$groupSID" requires explicit package name at
> /usr/libexec/squid/ext_wbinfo_group_acl
> in cache.log and these lines:
> FATAL: The nt_group helpers are crashing too rapidly, need help!
> Squid Cache (Version 3.5.1): Terminated abnormally.
> 

Thank you. Patch verified and applied to Squid-3.

Amos



From esr+squid at g.jct.ac.il  Thu Feb 19 06:01:04 2015
From: esr+squid at g.jct.ac.il (E.S. Rosenberg)
Date: Thu, 19 Feb 2015 08:01:04 +0200
Subject: [squid-users] How to cache everything with an Etag HTTP header?
In-Reply-To: <4tucwpkqm7kf.ma9n39-4bd4m5oxvsw625@api.elasticemail.com>
References: <4tucwpkqm7kf.ma9n39-4bd4m5oxvsw625@api.elasticemail.com>
Message-ID: <CAHTx_BOFqx7JakN=BDEDCt+RR+KKjvSUr_ri9DKXSyKgURH6gw@mail.gmail.com>

2015-02-18 15:22 GMT+02:00 Karl-Philipp Richter <richter at richtercloud.de>:
>
> Hi,
> I'm quite new to advanced squid configuration and want to enhance my
> HTTP cache expensive-bandwidth-cheap-storage setup where I'm mostly
> interested in storing large downloads with a refresh_pattern, e.g.
>
>     refresh_pattern -i
> \.(deb|rpm|exe|zip|tar|tgz|tar\.gz|txz|tar\.xz|ram|rar|bin|ppt|doc|tiff)$ 100800
> 99% 432000 override-expire override-lastmod
> ignore-no-cache ignore-no-store
For debs if they are very common on your network you may consider
setting up an apt-cacher and configuring squid to use it as a parent
cache for deb requests...
Regards,
Eli
>
> and after some reading around `refresh_pattern` and some search engine
> research I was wondering how to cache everything that provides an Etag
> because I thinks that'd be very useful for my scenario (very low starge
> cost and very high bandwidth costs).
>
> Any help or pointers are appreciated.
>
> Best regards,
> Kalle
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From odhiambo at gmail.com  Thu Feb 19 09:49:27 2015
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 19 Feb 2015 12:49:27 +0300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
Message-ID: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>

I have been hoping that 3.5.2 would possibly help address my problems with
ACLs, but alas!

root at mail:~wash/ILI/Squid/3.5/squid-3.5.2 # /opt/squid-3.5.1/sbin/squid -v
Squid Cache: Version 3.5.2
Service Name: squid
configure options:  '--prefix=/opt/squid-3.5.1'
'--enable-removal-policies=lru heap' '--disable-epoll' '--enable-auth'
'--enable-auth-basic=
DB NCSA PAM PAM POP3 SSPI' '--enable-external-acl-helpers=session
unix_group file_userip' '--enable-auth-negotiate=kerberos' '--with-pthread
s' '--enable-storeio=ufs diskd rock aufs' '--enable-delay-pools'
'--enable-snmp' '--with-openssl=/usr' '--enable-forw-via-db' '--enable-cach
e-digests' '--enable-wccpv2' '--enable-follow-x-forwarded-for'
'--with-large-files' '--enable-large-cache-files' '--enable-esi'
'--enable-kq
ueue' '--enable-icap-client' '--enable-kill-parent-hack' '--enable-ssl'
'--enable-leakfinder' '--enable-ssl-crtd' '--enable-url-rewrite-help
ers' '--enable-xmalloc-statistics' '--enable-stacktraces'
'--enable-zph-qos' '--enable-eui' '--with-nat-devpf'
'--enable-pf-transparent' 'CC=clang' 'CXX=clang++' --enable-ltdl-convenience


root at mail:~wash/ILI/Squid/3.5/squid-3.5.2 # /opt/squid-3.5.1/sbin/squid -k
reconfigure
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 12:45:32.653| Acl.cc(380) ~ACL: freeing ACL


Is anyone running this version of FreeBSD and NOT seeing the problem I
have? Maybe it's a FreeBSD-10.1 specific bug and not Squid's.

I'd really love to get help with this, as it leads to Squid intermittently
(though more often) just ignoring my ACLs.



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254733744121/+254722743223
"I can't hear you -- I'm using the scrambler."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150219/94e29064/attachment.htm>

From squid3 at treenet.co.nz  Thu Feb 19 11:07:21 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Feb 2015 00:07:21 +1300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
Message-ID: <54E5C3E9.8000103@treenet.co.nz>

On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
> I have been hoping that 3.5.2 would possibly help address my problems with
> ACLs, but alas!

Ah, I thought you saw this announcement made just after your last
message in Jan:

<http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html>

Its sounds very much like what your last few threads have been
describing as happening. Signal handling issues will affect all the
squid -k operations.

Amos



From odhiambo at gmail.com  Thu Feb 19 12:12:56 2015
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 19 Feb 2015 15:12:56 +0300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <54E5C3E9.8000103@treenet.co.nz>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
Message-ID: <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>

Hi Amos,

I did see that thread. However, the discussion was still continuing then.


I will apply it to my server and see.

Reporting back today!



On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
> > I have been hoping that 3.5.2 would possibly help address my problems
> with
> > ACLs, but alas!
>
> Ah, I thought you saw this announcement made just after your last
> message in Jan:
>
> <
> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
> >
>
> Its sounds very much like what your last few threads have been
> describing as happening. Signal handling issues will affect all the
> squid -k operations.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254733744121/+254722743223
"I can't hear you -- I'm using the scrambler."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150219/c22fc460/attachment.htm>

From jaguarpk at yandex.ru  Thu Feb 19 15:44:45 2015
From: jaguarpk at yandex.ru (Mail_Agent)
Date: Thu, 19 Feb 2015 18:44:45 +0300
Subject: [squid-users] about negotiate_kerb_auth helper
Message-ID: <84981424360685@web1o.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150219/565d51dc/attachment.htm>

From odhiambo at gmail.com  Thu Feb 19 16:15:40 2015
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 19 Feb 2015 19:15:40 +0300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
 <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
Message-ID: <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>

On 19 February 2015 at 15:12, Odhiambo Washington <odhiambo at gmail.com>
wrote:

> Hi Amos,
>
> I did see that thread. However, the discussion was still continuing then.
>
>
> I will apply it to my server and see.
>
> Reporting back today!
>
>
>
> On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
>> > I have been hoping that 3.5.2 would possibly help address my problems
>> with
>> > ACLs, but alas!
>>
>> Ah, I thought you saw this announcement made just after your last
>> message in Jan:
>>
>> <
>> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
>> >
>>
>> Its sounds very much like what your last few threads have been
>> describing as happening. Signal handling issues will affect all the
>> squid -k operations.
>>
>> Amos
>>
>

I have compiled a custom kernel after applying this patch mentioned in that
thread.

wash at mail:~$ uname -a
FreeBSD mail.ili.or.ug 10.1-RELEASE-p5 FreeBSD 10.1-RELEASE-p5 #4: Thu Feb
19 16:55:56 EAT 2015     root at mail.ili.or.ug:/usr/obj/usr/src/sys
/BEASTIE-10.x  amd64


However, my issues still persist.

root at mail:/opt # /opt/squid-3.5.2/sbin/squid -k reconfigure
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL


Would this then suggest there is a problem with my squid.conf
<http://pastebin.com/wwwcnHnF> ?

Or the FreeBSD problem isn't quite solved?



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254733744121/+254722743223
"I can't hear you -- I'm using the scrambler."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150219/3816c7fa/attachment.htm>

From sis at open.ch  Thu Feb 19 16:30:43 2015
From: sis at open.ch (=?iso-8859-1?Q?Simon_St=E4heli?=)
Date: Thu, 19 Feb 2015 17:30:43 +0100
Subject: [squid-users] about negotiate_kerb_auth helper
In-Reply-To: <84981424360685@web1o.yandex.ru>
References: <84981424360685@web1o.yandex.ru>
Message-ID: <F4998F33-DBF5-4F79-AF34-76340F432B0D@open.ch>


On 19.02.2015, at 16:44, Mail_Agent <jaguarpk at yandex.ru> wrote:

> Hello, can you tell me where can i find detailed instruction about negotiate_kerb_auth_helper, please, I've configured squid.conf, checked kerberos, it's ok,but i get IE8 prompt to login and then access denied.
> Thank you
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

The man page of negotiate_kerberos_auth is quite good. Have you added following lines to squid.conf?

auth_param negotiate program /path/to/negotiate_kerberos_auth
auth_param negotiate children 10
auth_param negotiate keep_alive on

- have you configured kerberos as well on you proxy server?
- have you created a keytab file?
- does your windows client have a proper kerberos ticket for the proxy service principal?
- how does the HTTP header in the response of the proxy looks like? is negotiate listed as authentication method?

cheers
simon


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4030 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150219/2b3781d3/attachment.bin>

From yvoinov at gmail.com  Thu Feb 19 16:46:27 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 19 Feb 2015 22:46:27 +0600
Subject: [squid-users] about negotiate_kerb_auth helper
In-Reply-To: <84981424360685@web1o.yandex.ru>
References: <84981424360685@web1o.yandex.ru>
Message-ID: <54E61363.6040500@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos

19.02.15 21:44, Mail_Agent ?????:
> Hello, can you tell me where can i find detailed instruction about
>  negotiate_kerb_auth_helper, please, I've configured squid.conf,
> checked kerberos, it's ok,but i get IE8 prompt to login and then
> access denied. Thank you
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU5hNjAAoJENNXIZxhPexGWKIH/2O1RPsY+lhPgjUq5634M2dF
twgFs7hEBSM4vQiOVNertlK2zDw2zZArRsIZhKbyLaMEOKqtuGM/zitriPWWrLiI
bVP8Lmr7QYIKFSNFP9ihclTYDxPFT2wqMfNfMiH7kiuqlRkaffdZe/Mc5G66MBHT
UmSnOTI8aiAc0KlkQTeuXZa93hg9fZhJAynA9bq0bYmxawSUXLtTqicTe6qbfDCQ
NrrBrA3O8Sfigo5pRcUjS7GH7VhmysYn1C+vndIckaRFqQF2yoJmCWKPIDfqwhmV
LsLO6dtZctSfaKBeEQeF0nCm8w0dSAn3EwZmfRp4BpYay7sU7OCMNKAzIVwmD54=
=X9Xq
-----END PGP SIGNATURE-----


From gecom at tubosider.it  Thu Feb 19 17:35:25 2015
From: gecom at tubosider.it (masterx81)
Date: Thu, 19 Feb 2015 09:35:25 -0800 (PST)
Subject: [squid-users] Squid and site ryanair.com
In-Reply-To: <54C80299.1040606@treenet.co.nz>
References: <1421337529987-4669105.post@n4.nabble.com>
 <54B88B33.5010701@treenet.co.nz> <1421692947043-4669205.post@n4.nabble.com>
 <54BDB6B3.9010409@treenet.co.nz> <1422366247155-4669366.post@n4.nabble.com>
 <54C80299.1040606@treenet.co.nz>
Message-ID: <1424367325544-4669962.post@n4.nabble.com>

After futher search seem that the webpage now is trying to get files from
cdnjs.cloudflare.com, but it resolves as an ipv6 address. My network is not
ready for ipv6. I've already shut off ipv6 on the interface, used the
"dns_v4_first on" and "tcp_outgoing_address 0.0.0.0", but still no luck....
It tries always to use the ipv6.
What i can do?




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-and-site-ryanair-com-tp4669105p4669962.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Feb 19 19:16:38 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 20 Feb 2015 01:16:38 +0600
Subject: [squid-users] Squid and site ryanair.com
In-Reply-To: <1424367325544-4669962.post@n4.nabble.com>
References: <1421337529987-4669105.post@n4.nabble.com>
 <54B88B33.5010701@treenet.co.nz> <1421692947043-4669205.post@n4.nabble.com>
 <54BDB6B3.9010409@treenet.co.nz> <1422366247155-4669366.post@n4.nabble.com>
 <54C80299.1040606@treenet.co.nz> <1424367325544-4669962.post@n4.nabble.com>
Message-ID: <54E63696.5050909@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

https://www.google.com/search?q=ipv4+to+ipv6

19.02.15 23:35, masterx81 ?????:
> After futher search seem that the webpage now is trying to get
> files from cdnjs.cloudflare.com, but it resolves as an ipv6
> address. My network is not ready for ipv6. I've already shut off
> ipv6 on the interface, used the "dns_v4_first on" and
> "tcp_outgoing_address 0.0.0.0", but still no luck.... It tries
> always to use the ipv6. What i can do?
> 
> 
> 
> 
> -- View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-and-site-ryanair-com-tp4669105p4669962.html
>
> 
Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU5jaWAAoJENNXIZxhPexGH54H/3Vdmh8qbLby7ZNrHNVnXTjE
R6mxABaQ5W8l1dyPRXLr7ZykNAHbJuIXyEP7z4kexZSd2CkX49HGJFPfhnyEQJ6f
s+niceFQ0Rf5USRrIpba2E+gqISYhkzSKWa1+bBN0eyBGjr5VAhU9N2+/sj4LIQB
RicHNJ3PcpAmFuMRSVyFa5+hoDfSBWlNZq+bz8lCYWdWcv3PdREDP/ml1A2ustkp
E8BGuIkNJkFChlm3eTGDEMwh0EXZnbWWYtkBch7LKrctXs9ed0EOYnGhdThcvlFz
ws34qlwxVeMj/xPsgzltWCQMvyUddzw0cedQNHfY4rCFa/+v7uBS41z83sH6Z4M=
=B2DK
-----END PGP SIGNATURE-----


From hack.back at hotmail.com  Thu Feb 19 20:16:48 2015
From: hack.back at hotmail.com (HackXBack)
Date: Thu, 19 Feb 2015 12:16:48 -0800 (PST)
Subject: [squid-users] assertion failed: comm.cc:769:
	"Comm::IsConnOpen(conn)"
In-Reply-To: <1424253241949-4669944.post@n4.nabble.com>
References: <1424025171679-4669842.post@n4.nabble.com>
 <1424209440077-4669927.post@n4.nabble.com> <54E3F058.3040200@treenet.co.nz>
 <1424253241949-4669944.post@n4.nabble.com>
Message-ID: <1424377008695-4669964.post@n4.nabble.com>

root at dotspot:~# gdb /usr/sbin/squid /var/spool/squid/cache/squid/core.3543
GNU gdb (GDB) 7.4.1-debian
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /usr/sbin/squid...done.
[New LWP 3543]
[New LWP 3656]
[New LWP 3649]
[New LWP 3648]
[New LWP 3655]
[New LWP 3650]
[New LWP 3647]
[New LWP 3661]
[New LWP 3670]
[New LWP 3658]
[New LWP 3653]
[New LWP 3672]
[New LWP 3677]
[New LWP 3673]
[New LWP 3662]
[New LWP 3657]
[New LWP 3651]
[New LWP 3669]
[New LWP 3660]
[New LWP 3671]
[New LWP 3674]
[New LWP 3667]
[New LWP 3666]
[New LWP 3678]
[New LWP 3659]
[New LWP 3664]
[New LWP 3675]
[New LWP 3668]
[New LWP 3652]
[New LWP 3665]
[New LWP 3663]
[New LWP 3654]
[New LWP 3676]

warning: Can't read pathname for load map: Input/output error.
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Core was generated by `(squid-1) -YC -f /etc/squid/squid.conf'.
Program terminated with signal 6, Aborted.
#0  0x00007f56e33f6165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
(gdb) backtrace
#0  0x00007f56e33f6165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f56e33f93e0 in abort () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x000000000055b12f in xassert (msg=<optimized out>, file=<optimized
out>, line=<optimized out>) at debug.cc:566
#3  0x00000000006ade68 in commSetConnTimeout (conn=..., timeout=15,
callback=...) at comm.cc:769
#4  0x000000000052d6ca in ConnStateData::getSslContextDone
(this=this at entry=0x9170a588, sslContext=<optimized out>,
sslContext at entry=0x819f9420, isNew=isNew at entry=false) at client_side.cc:3997
#5  0x000000000052e230 in ConnStateData::getSslContextStart
(this=this at entry=0x9170a588) at client_side.cc:3907
#6  0x000000000052e849 in ConnStateData::httpsPeeked (this=0x9170a588,
serverConnection=...) at client_side.cc:4069
#7  0x00000000005961e8 in UnaryMemFunT<ConnStateData,
RefCount&lt;Comm::Connection>, RefCount<Comm::Connection> >::doDial
(this=0x91293570) at base/AsyncJobCalls.h:113
#8  0x000000000053adaa in JobDialer<ConnStateData>::dial (this=0x91293570,
call=...) at base/AsyncJobCalls.h:166
#9  0x00000000006a2b79 in AsyncCall::make (this=0x91293540) at
AsyncCall.cc:32
#10 0x00000000006a67df in AsyncCallQueue::fireNext
(this=this at entry=0xbbd140) at AsyncCallQueue.cc:52
#11 0x00000000006a6b10 in AsyncCallQueue::fire (this=0xbbd140) at
AsyncCallQueue.cc:38
#12 0x000000000056c3bc in EventLoop::runOnce
(this=this at entry=0x7fffeab5ea70) at EventLoop.cc:135
#13 0x000000000056c548 in EventLoop::run (this=0x7fffeab5ea70) at
EventLoop.cc:99
#14 0x00000000005e3bea in SquidMain (argc=<optimized out>, argv=<optimized
out>) at main.cc:1528
#15 0x00000000004f231b in SquidMainSafe (argv=<optimized out>,
argc=<optimized out>) at main.cc:1260
#16 main (argc=<optimized out>, argv=<optimized out>) at main.cc:1252




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/assertion-failed-comm-cc-769-Comm-IsConnOpen-conn-tp4669842p4669964.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hectorchan at gmail.com  Thu Feb 19 22:20:51 2015
From: hectorchan at gmail.com (Hector Chan)
Date: Thu, 19 Feb 2015 14:20:51 -0800
Subject: [squid-users] delay pool
Message-ID: <CAEhCwUyrsCeu2YSHwnh82YY_ix9v5h_5DMWdLon5AqvjHLg6Hw@mail.gmail.com>

Hi all,

Is there anyway I can apply the delay pool to only cache miss ?  I wanted
to let the client download as fast as possible if the request resulted in a
cache hit, but not on cache miss.

Thanks,
Hector
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150219/6db8b689/attachment.htm>

From squid3 at treenet.co.nz  Thu Feb 19 23:58:25 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Feb 2015 12:58:25 +1300
Subject: [squid-users] Squid and site ryanair.com
In-Reply-To: <54E63696.5050909@gmail.com>
References: <1421337529987-4669105.post@n4.nabble.com>
 <54B88B33.5010701@treenet.co.nz> <1421692947043-4669205.post@n4.nabble.com>
 <54BDB6B3.9010409@treenet.co.nz> <1422366247155-4669366.post@n4.nabble.com>
 <54C80299.1040606@treenet.co.nz> <1424367325544-4669962.post@n4.nabble.com>
 <54E63696.5050909@gmail.com>
Message-ID: <54E678A1.2090609@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 20/02/2015 8:16 a.m., Yuri Voinov wrote:
> https://www.google.com/search?q=ipv4+to+ipv6
> 

WTF? google-fu failure ;-)


> 19.02.15 23:35, masterx81 ?????:
>> After futher search seem that the webpage now is trying to get 
>> files from cdnjs.cloudflare.com, but it resolves as an ipv6 
>> address. My network is not ready for ipv6. I've already shut off 
>> ipv6 on the interface,

1) Disabling the NIC has never been a good idea, or even truely
possible. If you followed almost any of the online tutorials then its
not so much disabled as broken (like smashing a window to let in the
breeze).


2) Squid does kernel capability detection and v4-only kernels will
cause Squid to not even lookup AAAA records or attempt IPv6
connections. v6-enabled kernels without network connectivity (actual
connectivity "down" no-IPv6 state, not borked NIC drivers) will inform
Squid on connection setup that the IP is unreachable, causing
immediate retry with a differnet IP address.


3) Its seriously well past time you started making things
IPv6-enabled. ARIN exhaustion is expected to occur in *less than 90
days*. Most of the "eyeballs" user population lives in areas that
already ran out years ago (WiFi NAT upon DSL NAT upon Tier-3 CGNAT
upon Tier-2 CGNAT ... my last two employers VPN tools didn't stand a
chance   /rant).


4) Instead of disabling components in the kernel your firewalls should
instead be configured to block unwanted traffic just like for unwanted
IPv4 **. Let the IPv6-enabled bits operate within the machine the way
its designed to, even if there is no global IPv6 assigned or
permission to leave the box. That way when your network links do come
online with IPv6 you already have the on-machine parts mostly
operating okay and there will be fewer changes.
 You can even (for now) work on rollign network links out slowly
between specific devices or services so when things go noticably mad
in IPv4 world you have less to do.

** If you dont have a firewall capable of controlling IPv6 then you
urgently need it upgraded, priority #1, right now.


> used the "dns_v4_first on" and
>> "tcp_outgoing_address 0.0.0.0", but still no luck.... It tries 
>> always to use the ipv6. What i can do?
> 

Cloudflare are one of the CDN presenting very long lists of IP
addresses for both IPv4 and IPv6 (10 of each for me).

You need to increase the forward_max_tries from your versions default
10 to the current recommended 25 before Squid has much hope of
handling the connect failover at all.

After that dns_v4_first should just be a latency tuning knob. Set to
ON reduces useless v6 attempts on an IPv4-only network. Set to OFF
reduces them on a IPv6-enabled network. NOTE: it has no effect at all
unless both the kernel and the domain being visited are IPv6-enabled,
its just a sorting order for IP lookup results.


You should also try an upgrade to a more current Squid version. No
guarantees, but we are constantly doing improvements to match Internet
environmental changes (like that forwarding retries setting change)
and there may be a more obscure bug involved.

Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU5nigAAoJELJo5wb/XPRjocYIAIzDWagLD52sazB/FAEAnzKG
fzMs7EeZuL4sbpS6kYH7JGbu6IfbVCDKxl4Dy03pToIGHSPyzOerBiHXo1J1IlU0
E3mgQab1x6XAa10TyOJ29UJp+Pqx0wmADSIfWdFkre29NYUrB99AdL5Jo18mMkLz
67Lp+3S4ZrFIqUCk/ASbXaJUoHUg7Q02ryJOGYN9dV7y+sE+4rlcIHA3YeyQMnV4
NMMV+dDwzO19G2YJa8E5LfaFSgCv7berpbixP2ku98NmT/bAahu1qmKHTAp+F1ig
TxnEkaLRcMpBBUXp/Ye3cUF+jRlGdH2HTc1wOnAqOc5k0PlY/Diyyshfdsm58Cc=
=xRGy
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Feb 20 00:02:00 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Feb 2015 13:02:00 +1300
Subject: [squid-users] delay pool
In-Reply-To: <CAEhCwUyrsCeu2YSHwnh82YY_ix9v5h_5DMWdLon5AqvjHLg6Hw@mail.gmail.com>
References: <CAEhCwUyrsCeu2YSHwnh82YY_ix9v5h_5DMWdLon5AqvjHLg6Hw@mail.gmail.com>
Message-ID: <54E67978.6030101@treenet.co.nz>

On 20/02/2015 11:20 a.m., Hector Chan wrote:
> Hi all,
> 
> Is there anyway I can apply the delay pool to only cache miss ?  I wanted
> to let the client download as fast as possible if the request resulted in a
> cache hit, but not on cache miss.

That is the default behaviour for delay pools.

They operate by limiting the traffic read/downloaded from a server by
clients. Cache HITs and uploads are not restricted. Collapsed forwarding
HITs are controlled by the initial clients pool.

Amos



From squid3 at treenet.co.nz  Fri Feb 20 01:15:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Feb 2015 14:15:28 +1300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
 <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
 <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>
Message-ID: <54E68AB0.2010609@treenet.co.nz>

On 20/02/2015 5:15 a.m., Odhiambo Washington wrote:
> On 19 February 2015 at 15:12, Odhiambo Washington <odhiambo at gmail.com>
> wrote:
> 
>> Hi Amos,
>>
>> I did see that thread. However, the discussion was still continuing then.
>>
>>
>> I will apply it to my server and see.
>>
>> Reporting back today!
>>
>>
>>
>> On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>
>>> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
>>>> I have been hoping that 3.5.2 would possibly help address my problems
>>> with
>>>> ACLs, but alas!
>>>
>>> Ah, I thought you saw this announcement made just after your last
>>> message in Jan:
>>>
>>> <
>>> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
>>>>
>>>
>>> Its sounds very much like what your last few threads have been
>>> describing as happening. Signal handling issues will affect all the
>>> squid -k operations.
>>>
>>> Amos
>>>
>>
> 
> I have compiled a custom kernel after applying this patch mentioned in that
> thread.

Er. There were two patches mentioned as being applied in the FreeBSD
mail and bug reports.

> 
> wash at mail:~$ uname -a
> FreeBSD mail.ili.or.ug 10.1-RELEASE-p5 FreeBSD 10.1-RELEASE-p5 #4: Thu Feb
> 19 16:55:56 EAT 2015     root at mail.ili.or.ug:/usr/obj/usr/src/sys
> /BEASTIE-10.x  amd64
> 
> 
> However, my issues still persist.
> 
> root at mail:/opt # /opt/squid-3.5.2/sbin/squid -k reconfigure
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> 
> 
> Would this then suggest there is a problem with my squid.conf
> <http://pastebin.com/wwwcnHnF> ?
> 
> Or the FreeBSD problem isn't quite solved?
> 

Could you re-state what the problem is?

Now your pastebin is expired all we have on record about this problems
is the sentence: "it's crashing with errors as seen from <DEAD URL>"

Amos




From dan at getbusi.com  Fri Feb 20 03:34:48 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Fri, 20 Feb 2015 14:34:48 +1100
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
 <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
 <54DB467E.10106@ngtech.co.il>
 <4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>
Message-ID: <CAN8nrKCq+ZRQb6E178MsVfdqFrwfiAKiwY6XSJ9mo=ni2hbO5g@mail.gmail.com>

Installed v3.4.12 and almost went a whole day without this crash.
Ended up rearing its head during a spike in traffic after lunch. Seems
to be more prone to occurring when the HTTP requests per second
reaches about 100.

I have a script running that runs a squid reload whenever this crash
occurs and that seems to limit the impact (downtime) to a few
seconds?but occasionally Squid seems to get deadlocked by the crash
and needs to be killed (sometimes with -9) before it can be restarted.

In lieu of being able to diagnose and fix this, does anyone have any
other creative ideas as to limiting its impact?

Thanks
Dan


On 12 February 2015 at 09:51, Dan Charlesworth <dan at getbusi.com> wrote:
> Hey Eliezer
>
> With the response_size_100 ACL definition:
> - 100 tells the external ACL the limit in MB
> - 192.168.0.10 tells the external ACL the squid IP
>
> I think one or both of these is only needed to build the deny page. You can?t use deny_info with reply_body_max_size so we had to customise the ERR_TOO_BIG source to do a redirect to our own page.
>
> The http_access allow line is because result caching cannot alter the EXT_LOG for fast ACLs as cache lookups include the EXT_LOG, so we need to check the result twice to alter the EXT_LOG and then have the result cached against the altered EXT_LOG.
>
> Cheers
> Dan
>
>> On 11 Feb 2015, at 11:09 pm, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
>>
>> Hey Dan,
>>
>> First I must admit that this squid.conf is quite complicated but kind of self explanatory.
>>
>> I have tried to understand the next lines:
>> # File size (download) restrictions
>> acl response_size_100 external response_size_type 100 192.168.0.10
>> http_access allow response_size_100 response_size_100
>> reply_body_max_size 100 MB response_size_100
>>
>> But I am unsure how it works with external_acl exactly.
>> If you wish to deny 100MB size files you should have only one rule for the reply body max size, what are the others for exactly?
>>
>> Eliezer
>>
>> * I might missing some concepts some sorry in advance.
>>
>> On 11/02/2015 00:30, Dan Charlesworth wrote:
>>> Hi Eliezer
>>>
>>> Took a while to get this up?sorry about that. Here?s an example of a production config of ours (with some confidential stuff necessarily taken out/edited):
>>> https://gist.github.com/djch/92cf44440b04afbd7917  <https://gist.github.com/djch/92cf44440b04afbd7917>
>>>
>>> Let me know if there?s any other info I can provide that might point towards the cause of this crash.
>>>
>>> And thanks again for taking a look.
>>
>>
>


From eliezer at ngtech.co.il  Fri Feb 20 03:57:21 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 20 Feb 2015 05:57:21 +0200
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <CAN8nrKCq+ZRQb6E178MsVfdqFrwfiAKiwY6XSJ9mo=ni2hbO5g@mail.gmail.com>
References: <54643AFA.4000006@treenet.co.nz>	<1415854939929.9166aac8@Nodemailer>	<CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>	<CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>	<54CEC664.8020407@ngtech.co.il>	<87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>	<FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>	<54DB467E.10106@ngtech.co.il>	<4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>
 <CAN8nrKCq+ZRQb6E178MsVfdqFrwfiAKiwY6XSJ9mo=ni2hbO5g@mail.gmail.com>
Message-ID: <54E6B0A1.2090400@ngtech.co.il>

Hey Dan,

I am not the best at reading squid long debug output and it is needed in 
order to understand the path that the request is traveling between the 
ACLs and helper to determine if the issue is since the connection is 
unusable because of a helper or because of another reason.

And so from what you describe I assume that the needed helper\external 
ACL is a fake one so a python helper is out of the question for such a 
purpose.
The fact that it's crashing describes some kind of failure from the 
combination of something.
In order to test if the issue is because of the helper or something 
related to the existence of this specific helper for the reply body max 
try to disable this helper and use only the basic limit, while it will 
force you to not show a nice deny info page it will prevent the some of 
the issues from happening.

 From stability point of view running all these kill -9 what so ever is 
a very wrong approach.
The crashes else then causing "down time" causing a much deeper issue.
Assuming that the users transactions are important these crashes are 
damaging in many cases even more then any "down time".
I know that some admins do not agree with my approach but a stable 
service is one of the basic fundamentals for success and happiness!!

I must admit that there are cases which a kill -9 can help but it has 
it's price.

Just asking loudly from both CEO + SYSADMIN + CLIENTS + others:
What would you prefer?
- stability based a good product
- stability based on patches
- stability based on human resources recruitment's
- stability based on some unclosed known bugs
- stability based on 1k programmers work
- stability based on protocol compatibility
....

And I must stop here with the list since the above list can become very 
long and which will prove that humans can look at the same picture and 
see many different things.

Eliezer

* I am almost sure that you may use a "fake" acl that will match all 
requests instead of using an external_acl helper that will help you to 
"select" the 100MB limit.

On 20/02/2015 05:34, Dan Charlesworth wrote:
> Installed v3.4.12 and almost went a whole day without this crash.
> Ended up rearing its head during a spike in traffic after lunch. Seems
> to be more prone to occurring when the HTTP requests per second
> reaches about 100.
>
> I have a script running that runs a squid reload whenever this crash
> occurs and that seems to limit the impact (downtime) to a few
> seconds?but occasionally Squid seems to get deadlocked by the crash
> and needs to be killed (sometimes with -9) before it can be restarted.
>
> In lieu of being able to diagnose and fix this, does anyone have any
> other creative ideas as to limiting its impact?
>
> Thanks
> Dan
>
>
> On 12 February 2015 at 09:51, Dan Charlesworth <dan at getbusi.com> wrote:
>> Hey Eliezer
>>
>> With the response_size_100 ACL definition:
>> - 100 tells the external ACL the limit in MB
>> - 192.168.0.10 tells the external ACL the squid IP
>>
>> I think one or both of these is only needed to build the deny page. You can?t use deny_info with reply_body_max_size so we had to customise the ERR_TOO_BIG source to do a redirect to our own page.
>>
>> The http_access allow line is because result caching cannot alter the EXT_LOG for fast ACLs as cache lookups include the EXT_LOG, so we need to check the result twice to alter the EXT_LOG and then have the result cached against the altered EXT_LOG.
>>
>> Cheers
>> Dan
>>
>>> On 11 Feb 2015, at 11:09 pm, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
>>>
>>> Hey Dan,
>>>
>>> First I must admit that this squid.conf is quite complicated but kind of self explanatory.
>>>
>>> I have tried to understand the next lines:
>>> # File size (download) restrictions
>>> acl response_size_100 external response_size_type 100 192.168.0.10
>>> http_access allow response_size_100 response_size_100
>>> reply_body_max_size 100 MB response_size_100
>>>
>>> But I am unsure how it works with external_acl exactly.
>>> If you wish to deny 100MB size files you should have only one rule for the reply body max size, what are the others for exactly?
>>>
>>> Eliezer
>>>
>>> * I might missing some concepts some sorry in advance.
>>>
>>> On 11/02/2015 00:30, Dan Charlesworth wrote:
>>>> Hi Eliezer
>>>>
>>>> Took a while to get this up?sorry about that. Here?s an example of a production config of ours (with some confidential stuff necessarily taken out/edited):
>>>> https://gist.github.com/djch/92cf44440b04afbd7917  <https://gist.github.com/djch/92cf44440b04afbd7917>
>>>>
>>>> Let me know if there?s any other info I can provide that might point towards the cause of this crash.
>>>>
>>>> And thanks again for taking a look.
>>>
>>>
>>




From dan at getbusi.com  Fri Feb 20 04:06:02 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Fri, 20 Feb 2015 15:06:02 +1100
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <54E6B0A1.2090400@ngtech.co.il>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
 <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
 <54DB467E.10106@ngtech.co.il>
 <4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>
 <CAN8nrKCq+ZRQb6E178MsVfdqFrwfiAKiwY6XSJ9mo=ni2hbO5g@mail.gmail.com>
 <54E6B0A1.2090400@ngtech.co.il>
Message-ID: <F7A152AC-CAF8-46F7-9EB3-0E32F2B1744C@getbusi.com>

Thanks Eliezer ?

We've only ever used `kill` as very last resort when the squid process wouldn?t respond to anything else.

Anyway, I think I missed what led you to think the crash is related to the reply_body_max_size rules' external ACL as opposed to the many others we define?

That would certainly narrow it down a lot further than before.

Cheers
Dan

> On 20 Feb 2015, at 2:57 pm, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> Hey Dan,
> 
> I am not the best at reading squid long debug output and it is needed in order to understand the path that the request is traveling between the ACLs and helper to determine if the issue is since the connection is unusable because of a helper or because of another reason.
> 
> And so from what you describe I assume that the needed helper\external ACL is a fake one so a python helper is out of the question for such a purpose.
> The fact that it's crashing describes some kind of failure from the combination of something.
> In order to test if the issue is because of the helper or something related to the existence of this specific helper for the reply body max try to disable this helper and use only the basic limit, while it will force you to not show a nice deny info page it will prevent the some of the issues from happening.
> 
> From stability point of view running all these kill -9 what so ever is a very wrong approach.
> The crashes else then causing "down time" causing a much deeper issue.
> Assuming that the users transactions are important these crashes are damaging in many cases even more then any "down time".
> I know that some admins do not agree with my approach but a stable service is one of the basic fundamentals for success and happiness!!
> 
> I must admit that there are cases which a kill -9 can help but it has it's price.
> 
> Just asking loudly from both CEO + SYSADMIN + CLIENTS + others:
> What would you prefer?
> - stability based a good product
> - stability based on patches
> - stability based on human resources recruitment's
> - stability based on some unclosed known bugs
> - stability based on 1k programmers work
> - stability based on protocol compatibility
> ....
> 
> And I must stop here with the list since the above list can become very long and which will prove that humans can look at the same picture and see many different things.
> 
> Eliezer
> 
> * I am almost sure that you may use a "fake" acl that will match all requests instead of using an external_acl helper that will help you to "select" the 100MB limit.
> 
> On 20/02/2015 05:34, Dan Charlesworth wrote:
>> Installed v3.4.12 and almost went a whole day without this crash.
>> Ended up rearing its head during a spike in traffic after lunch. Seems
>> to be more prone to occurring when the HTTP requests per second
>> reaches about 100.
>> 
>> I have a script running that runs a squid reload whenever this crash
>> occurs and that seems to limit the impact (downtime) to a few
>> seconds?but occasionally Squid seems to get deadlocked by the crash
>> and needs to be killed (sometimes with -9) before it can be restarted.
>> 
>> In lieu of being able to diagnose and fix this, does anyone have any
>> other creative ideas as to limiting its impact?
>> 
>> Thanks
>> Dan
>> 
>> 
>> On 12 February 2015 at 09:51, Dan Charlesworth <dan at getbusi.com> wrote:
>>> Hey Eliezer
>>> 
>>> With the response_size_100 ACL definition:
>>> - 100 tells the external ACL the limit in MB
>>> - 192.168.0.10 tells the external ACL the squid IP
>>> 
>>> I think one or both of these is only needed to build the deny page. You can?t use deny_info with reply_body_max_size so we had to customise the ERR_TOO_BIG source to do a redirect to our own page.
>>> 
>>> The http_access allow line is because result caching cannot alter the EXT_LOG for fast ACLs as cache lookups include the EXT_LOG, so we need to check the result twice to alter the EXT_LOG and then have the result cached against the altered EXT_LOG.
>>> 
>>> Cheers
>>> Dan
>>> 
>>>> On 11 Feb 2015, at 11:09 pm, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
>>>> 
>>>> Hey Dan,
>>>> 
>>>> First I must admit that this squid.conf is quite complicated but kind of self explanatory.
>>>> 
>>>> I have tried to understand the next lines:
>>>> # File size (download) restrictions
>>>> acl response_size_100 external response_size_type 100 192.168.0.10
>>>> http_access allow response_size_100 response_size_100
>>>> reply_body_max_size 100 MB response_size_100
>>>> 
>>>> But I am unsure how it works with external_acl exactly.
>>>> If you wish to deny 100MB size files you should have only one rule for the reply body max size, what are the others for exactly?
>>>> 
>>>> Eliezer
>>>> 
>>>> * I might missing some concepts some sorry in advance.
>>>> 
>>>> On 11/02/2015 00:30, Dan Charlesworth wrote:
>>>>> Hi Eliezer
>>>>> 
>>>>> Took a while to get this up?sorry about that. Here?s an example of a production config of ours (with some confidential stuff necessarily taken out/edited):
>>>>> https://gist.github.com/djch/92cf44440b04afbd7917  <https://gist.github.com/djch/92cf44440b04afbd7917>
>>>>> 
>>>>> Let me know if there?s any other info I can provide that might point towards the cause of this crash.
>>>>> 
>>>>> And thanks again for taking a look.
>>>> 
>>>> 
>>> 
> 
> 



From eliezer at ngtech.co.il  Fri Feb 20 04:46:29 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 20 Feb 2015 06:46:29 +0200
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <F7A152AC-CAF8-46F7-9EB3-0E32F2B1744C@getbusi.com>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
 <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
 <54DB467E.10106@ngtech.co.il>
 <4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>
 <CAN8nrKCq+ZRQb6E178MsVfdqFrwfiAKiwY6XSJ9mo=ni2hbO5g@mail.gmail.com>
 <54E6B0A1.2090400@ngtech.co.il>
 <F7A152AC-CAF8-46F7-9EB3-0E32F2B1744C@getbusi.com>
Message-ID: <54E6BC25.7020001@ngtech.co.il>

Hey Dan,

The basic rule of thumb in programming lands is script vs compiled code.
Where compiled code can be considered very reliable and in most cases 
tested much more then scripts.
I am fearing that there is some race between all sorts of things on 
runtime which might lead to this failed test.

There are couple possibilities that can cause the issue you are writing 
about.
 From the compiled side of the code the main suspect is that the 
connection got into a "non usable" state before squid could do something 
else.
I have not seen yet the source code for connIsUsable but if you wish I 
can try and look at the function\method\call\code source and start a 
basic lookup to understand the issue a bit more.
I do not remember if you have opened a bug report yet but I think this 
issue needs a bug report.

Take your time to write a brief bug report at:
http://bugs.squid-cache.org/index.cgi

While referring to this thread.
If you are up for the task then maybe you would be able to provide some 
more information based on the wiki:
http://wiki.squid-cache.org/SquidFaq/BugReporting

Thanks,
Eliezer

On 20/02/2015 06:06, Dan Charlesworth wrote:
> Thanks Eliezer ?
>
> We've only ever used `kill` as very last resort when the squid process wouldn?t respond to anything else.
>
> Anyway, I think I missed what led you to think the crash is related to the reply_body_max_size rules' external ACL as opposed to the many others we define?
>
> That would certainly narrow it down a lot further than before.
>
> Cheers
> Dan




From eliezer at ngtech.co.il  Fri Feb 20 04:50:49 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 20 Feb 2015 06:50:49 +0200
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <54E5C3E9.8000103@treenet.co.nz>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
Message-ID: <54E6BD29.8050102@ngtech.co.il>

Hey Amos,

I have not followed the threads you mentioned.
Can you link to any of these threads?

Eliezer

On 19/02/2015 13:07, Amos Jeffries wrote:
> Ah, I thought you saw this announcement made just after your last
> message in Jan:
>
> <http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html>
>
> Its sounds very much like what your last few threads have been
> describing as happening. Signal handling issues will affect all the
> squid -k operations.
>
> Amos




From squid3 at treenet.co.nz  Fri Feb 20 06:06:59 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Feb 2015 19:06:59 +1300
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <54E6BC25.7020001@ngtech.co.il>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
 <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
 <54DB467E.10106@ngtech.co.il>
 <4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>
 <CAN8nrKCq+ZRQb6E178MsVfdqFrwfiAKiwY6XSJ9mo=ni2hbO5g@mail.gmail.com>
 <54E6B0A1.2090400@ngtech.co.il>
 <F7A152AC-CAF8-46F7-9EB3-0E32F2B1744C@getbusi.com>
 <54E6BC25.7020001@ngtech.co.il>
Message-ID: <54E6CF03.3080605@treenet.co.nz>

On 20/02/2015 5:46 p.m., Eliezer Croitoru wrote:
> Hey Dan,
> 
> The basic rule of thumb in programming lands is script vs compiled code.
> Where compiled code can be considered very reliable and in most cases
> tested much more then scripts.
> I am fearing that there is some race between all sorts of things on
> runtime which might lead to this failed test.
> 
> There are couple possibilities that can cause the issue you are writing
> about.
> From the compiled side of the code the main suspect is that the
> connection got into a "non usable" state before squid could do something
> else.
> I have not seen yet the source code for connIsUsable but if you wish I
> can try and look at the function\method\call\code source and start a
> basic lookup to understand the issue a bit more.

Its a simple test to check to ensure the client connection is open when
writing some response data to it.

Something has earlier cause client connection closure, and something
else earlier has failed to cleanup the state or check the state was sane
before getting to the point of assertion.

Amos



From dan at getbusi.com  Fri Feb 20 06:15:47 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Fri, 20 Feb 2015 17:15:47 +1100
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <54E6CF03.3080605@treenet.co.nz>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
 <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
 <54DB467E.10106@ngtech.co.il>
 <4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>
 <CAN8nrKCq+ZRQb6E178MsVfdqFrwfiAKiwY6XSJ9mo=ni2hbO5g@mail.gmail.com>
 <54E6B0A1.2090400@ngtech.co.il>
 <F7A152AC-CAF8-46F7-9EB3-0E32F2B1744C@getbusi.com>
 <54E6BC25.7020001@ngtech.co.il> <54E6CF03.3080605@treenet.co.nz>
Message-ID: <F7FD602C-1628-4855-BCD0-569133E9EE63@getbusi.com>

Thanks Amos -

So then it more than likely is related to our external ACLs that deal with the HTTP response?

> On 20 Feb 2015, at 5:06 pm, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 20/02/2015 5:46 p.m., Eliezer Croitoru wrote:
>> Hey Dan,
>> 
>> The basic rule of thumb in programming lands is script vs compiled code.
>> Where compiled code can be considered very reliable and in most cases
>> tested much more then scripts.
>> I am fearing that there is some race between all sorts of things on
>> runtime which might lead to this failed test.
>> 
>> There are couple possibilities that can cause the issue you are writing
>> about.
>> From the compiled side of the code the main suspect is that the
>> connection got into a "non usable" state before squid could do something
>> else.
>> I have not seen yet the source code for connIsUsable but if you wish I
>> can try and look at the function\method\call\code source and start a
>> basic lookup to understand the issue a bit more.
> 
> Its a simple test to check to ensure the client connection is open when
> writing some response data to it.
> 
> Something has earlier cause client connection closure, and something
> else earlier has failed to cleanup the state or check the state was sane
> before getting to the point of assertion.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Feb 20 06:23:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Feb 2015 19:23:28 +1300
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <F7FD602C-1628-4855-BCD0-569133E9EE63@getbusi.com>
References: <54643AFA.4000006@treenet.co.nz>
 <1415854939929.9166aac8@Nodemailer>
 <CAN8nrKCupuVkB+znb2T6aEEgW3h4VycUCbF6mC1uEN5WTtQpaQ@mail.gmail.com>
 <CAN8nrKCOLLJSpwVjx4CdZWNf09MtaKAszfWEqX6MQq=a1JwULQ@mail.gmail.com>
 <54CEC664.8020407@ngtech.co.il>
 <87EC815E-593F-4AE4-8B24-1869FFD421F6@getbusi.com>
 <FB08EF07-1792-4C50-B116-9B1033B653E4@getbusi.com>
 <54DB467E.10106@ngtech.co.il>
 <4ECBA8D0-938E-4AE9-9C5B-8F400EE17C4A@getbusi.com>
 <CAN8nrKCq+ZRQb6E178MsVfdqFrwfiAKiwY6XSJ9mo=ni2hbO5g@mail.gmail.com>
 <54E6B0A1.2090400@ngtech.co.il>
 <F7A152AC-CAF8-46F7-9EB3-0E32F2B1744C@getbusi.com>
 <54E6BC25.7020001@ngtech.co.il> <54E6CF03.3080605@treenet.co.nz>
 <F7FD602C-1628-4855-BCD0-569133E9EE63@getbusi.com>
Message-ID: <54E6D2E0.8000409@treenet.co.nz>

On 20/02/2015 7:15 p.m., Dan Charlesworth wrote:
> Thanks Amos -
> 
> So then it more than likely is related to our external ACLs that deal with the HTTP response?
> 

I think they may be making the issue more noticable by slowing down the
request processing. But Squid should not be getting into that state
either way.

Amos



From squid3 at treenet.co.nz  Fri Feb 20 06:41:46 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Feb 2015 19:41:46 +1300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <54E6BD29.8050102@ngtech.co.il>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz> <54E6BD29.8050102@ngtech.co.il>
Message-ID: <54E6D72A.6080602@treenet.co.nz>

On 20/02/2015 5:50 p.m., Eliezer Croitoru wrote:
> Hey Amos,
> 
> I have not followed the threads you mentioned.
> Can you link to any of these threads?

<http://lists.squid-cache.org/pipermail/squid-users/2015-January/001567.html>

<http://lists.squid-cache.org/pipermail/squid-users/2015-January/001743.html>


> 
> Eliezer
> 
> On 19/02/2015 13:07, Amos Jeffries wrote:
>> Ah, I thought you saw this announcement made just after your last
>> message in Jan:
>>
>> <http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html>
>>
>>
>> Its sounds very much like what your last few threads have been
>> describing as happening. Signal handling issues will affect all the
>> squid -k operations.
>>
>> Amos
> 



From odhiambo at gmail.com  Fri Feb 20 09:09:30 2015
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 20 Feb 2015 12:09:30 +0300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <54E68AB0.2010609@treenet.co.nz>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
 <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
 <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>
 <54E68AB0.2010609@treenet.co.nz>
Message-ID: <CAAdA2WOZxAVvA17tM4ButCO0WDhsopaBah5fn-Uq6_DFAiDK+g@mail.gmail.com>

On 20 February 2015 at 04:15, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 20/02/2015 5:15 a.m., Odhiambo Washington wrote:
> > On 19 February 2015 at 15:12, Odhiambo Washington <odhiambo at gmail.com>
> > wrote:
> >
> >> Hi Amos,
> >>
> >> I did see that thread. However, the discussion was still continuing
> then.
> >>
> >>
> >> I will apply it to my server and see.
> >>
> >> Reporting back today!
> >>
> >>
> >>
> >> On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
> >>
> >>> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
> >>>> I have been hoping that 3.5.2 would possibly help address my problems
> >>> with
> >>>> ACLs, but alas!
> >>>
> >>> Ah, I thought you saw this announcement made just after your last
> >>> message in Jan:
> >>>
> >>> <
> >>>
> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
> >>>>
> >>>
> >>> Its sounds very much like what your last few threads have been
> >>> describing as happening. Signal handling issues will affect all the
> >>> squid -k operations.
> >>>
> >>> Amos
> >>>
> >>
> >
> > I have compiled a custom kernel after applying this patch mentioned in
> that
> > thread.
>
> Er. There were two patches mentioned as being applied in the FreeBSD
> mail and bug reports.
>
> >
> > wash at mail:~$ uname -a
> > FreeBSD mail.ili.or.ug 10.1-RELEASE-p5 FreeBSD 10.1-RELEASE-p5 #4: Thu
> Feb
> > 19 16:55:56 EAT 2015     root at mail.ili.or.ug:/usr/obj/usr/src/sys
> > /BEASTIE-10.x  amd64
> >
> >
> > However, my issues still persist.
> >
> > root at mail:/opt # /opt/squid-3.5.2/sbin/squid -k reconfigure
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> > 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >
> >
> > Would this then suggest there is a problem with my squid.conf
> > <http://pastebin.com/wwwcnHnF> ?
> >
> > Or the FreeBSD problem isn't quite solved?
> >
>
> Could you re-state what the problem is?
>
> Now your pastebin is expired all we have on record about this problems
> is the sentence: "it's crashing with errors as seen from <DEAD URL>"
>


Generally, Squid seems to partially ignore my time-based ACLS as seen in
the squid.conf

It would block one site but allow the others. I expect a standard blocking
within the specied time.

I have not been able to figure out why.

For instance, my ACL for TIMEWASTAGESITED contains .facebook.com, .gmail.com
and .youtube.com as dstdomains.

I find that youtube.com is blocked while facebook.com is not blocked. Both
should be blocked at this time (11:58)

root at mail:/opt/squid-3.5.2/etc # tail -f /usr/local/squid/logs/access.log |
grep DENIED
1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
http://youtube.com/ - HIER_NONE/- text/html
1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
http://youtube.com/favicon.ico - HIER_NONE/- text/html

root at mail:/opt/squid-3.5.2/etc # tail -f /usr/local/squid/logs/access.log |
grep 192.168.2.2
1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
http://youtube.com/ - HIER_NONE/- text/html
1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
http://youtube.com/favicon.ico - HIER_NONE/- text/html
1424422710.537    863 192.168.2.2 TCP_MISS/400 372 POST
http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.221.228.66 text/html
1424422710.578    903 192.168.2.2 TCP_MISS/400 372 POST
http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.197.243.221 text/html
1424422755.202   1239 192.168.2.2 TCP_MISS/200 280 POST
http://bench.utorrent.com/e?i=20 - ORIGINAL_DST/54.243.183.178 text/html
1424422756.602    846 192.168.2.2 TCP_MISS/200 1016 GET
http://cdn.ap.bittorrent.com/control/feature/tags/ut.json - ORIGINAL_DST/
54.230.128.
193 application/json
1424422895.279    593 192.168.2.2 TCP_MISS/404 1792 GET
http://www.gstatic.com/chrome/profile_avatars/NothingToDownload -
ORIGINAL_DST/196.0
.3.114 text/html


The odd part:

While facebook.com and gmail.com are accessible, nothing appears at all in
the access.log and cache.log (debug mode) about them yet this is an
intercept proxy. The sites just load. No log enties:(

I am willing to give access to both the Squid Server and the test machine
if someone can figure this out for me.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254733744121/+254722743223
"I can't hear you -- I'm using the scrambler."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/c99e77a7/attachment.htm>

From karpoftea at gmail.com  Fri Feb 20 09:14:32 2015
From: karpoftea at gmail.com (Ilya Karpov)
Date: Fri, 20 Feb 2015 12:14:32 +0300
Subject: [squid-users] Mutual authentication managed by Squid
Message-ID: <93616B9A-9EE9-4FE8-8A5B-70F9EC3FA773@gmail.com>

Hi guys,
can anyone suggest solution to make following scenario work using squid:

step1. 
Client(actually server application) calls HTTP://example <http://example/>.org squid via proxy.
 |
V 
step2. 
Proxy(Squid) understands that all calls to HTTP://example.org <http://example.org/> should be changed to HTTPS://example.org <https://example.org/>, trusts CA that uses example.org <http://example.org/> and knows client certificate to use for https client authentication
 |
V 
step3.
Origin(some server in internet) accepts https request, authenticates client, returns response

The main aim is to make client know nothing about https complexity (storing certificates/keys, knowing specific algorithms etc), and make squid manage this things.


Best regards,
Ilya Karpov
karpoftea at gmail.com



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/912dc31c/attachment.htm>

From yvoinov at gmail.com  Fri Feb 20 09:24:10 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 20 Feb 2015 15:24:10 +0600
Subject: [squid-users] Mutual authentication managed by Squid
In-Reply-To: <93616B9A-9EE9-4FE8-8A5B-70F9EC3FA773@gmail.com>
References: <93616B9A-9EE9-4FE8-8A5B-70F9EC3FA773@gmail.com>
Message-ID: <54E6FD3A.6040109@gmail.com>

Transparent SSL Bump interception, eh?

20.02.15 15:14, Ilya Karpov ?????:
> Hi guys,
> can anyone suggest solution to make following scenario work using squid:
>
> step1.
> Client(actually server application) calls HTTP://example 
> <http://example>.org squid via proxy.
>  |
> V
> step2.
> Proxy(Squid) understands that all calls to HTTP://example.org 
> <http://example.org> should be changed to HTTPS://example.org 
> <httpS://example.org>, trusts CA that uses example.org 
> <http://example.org> and knows client certificate to use for https 
> client authentication
>  |
> V
> step3.
> Origin(some server in internet) accepts https request, authenticates 
> client, returns response
>
> The main aim is to make client know nothing about https complexity 
> (storing certificates/keys, knowing specific algorithms etc), and make 
> squid manage this things.
>
>
> Best regards,
> Ilya Karpov
> karpoftea at gmail.com <mailto:karpoftea at gmail.com>
>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/70586e1a/attachment.htm>

From karpoftea at gmail.com  Fri Feb 20 09:34:51 2015
From: karpoftea at gmail.com (Ilya Karpov)
Date: Fri, 20 Feb 2015 12:34:51 +0300
Subject: [squid-users] Mutual authentication managed by Squid
In-Reply-To: <54E6FD3A.6040109@gmail.com>
References: <93616B9A-9EE9-4FE8-8A5B-70F9EC3FA773@gmail.com>
 <54E6FD3A.6040109@gmail.com>
Message-ID: <1C8751EC-13A0-4650-B4D9-D395FE69E721@gmail.com>

I?m not sure that using transparent sslbump squid will understand how to use client certificate for mutual authentication.
At least without transparent ssl bump it doesn?t.
Did you try to use trspr-sslbump for client auth? How does squid pick right client certificate for certain host?

Best regards,
Ilya Karpov
karpoftea at gmail.com


> 20 ????. 2015 ?., ? 12:24, Yuri Voinov <yvoinov at gmail.com> ???????(?):
> 
> Transparent SSL Bump interception, eh?
> 
> 20.02.15 15:14, Ilya Karpov ?????:
>> Hi guys,
>> can anyone suggest solution to make following scenario work using squid:
>> 
>> step1. 
>> Client(actually server application) calls HTTP://example <http://example/>.org squid via proxy.
>>  |
>> V 
>> step2. 
>> Proxy(Squid) understands that all calls to HTTP://example.org <http://example.org/> should be changed to HTTPS://example.org <https://example.org/>, trusts CA that uses example.org <http://example.org/> and knows client certificate to use for https client authentication
>>  |
>> V 
>> step3.
>> Origin(some server in internet) accepts https request, authenticates client, returns response
>> 
>> The main aim is to make client know nothing about https complexity (storing certificates/keys, knowing specific algorithms etc), and make squid manage this things.
>> 
>> 
>> Best regards,
>> Ilya Karpov
>> karpoftea at gmail.com <mailto:karpoftea at gmail.com>
>> 
>> 
>> 
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/b42254f3/attachment.htm>

From yvoinov at gmail.com  Fri Feb 20 09:41:26 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 20 Feb 2015 15:41:26 +0600
Subject: [squid-users] Mutual authentication managed by Squid
In-Reply-To: <1C8751EC-13A0-4650-B4D9-D395FE69E721@gmail.com>
References: <93616B9A-9EE9-4FE8-8A5B-70F9EC3FA773@gmail.com>
 <54E6FD3A.6040109@gmail.com> <1C8751EC-13A0-4650-B4D9-D395FE69E721@gmail.com>
Message-ID: <54E70146.7080603@gmail.com>


20.02.15 15:34, Ilya Karpov ?????:
> I?m not sure that using transparent sslbump squid will understand how 
> to use client certificate for mutual authentication.
As you configure it.
> At least without transparent ssl bump it doesn?t.
Sure.
> Did you try to use trspr-sslbump for client auth? How does squid pick 
> right client certificate for certain host?
Client auth on HTTPS sites is not function of transparent proxy. And 
yes, we don't use client serts on our transparent proxy. We simple 
bypass this sites directly without bumping. Let's client's do it 
yourself. This is not our responsibility.

I see two ways to do that as you wish.

1. Add sites, required client-certs auth to exclude bump list. I.e., 
exclude proxy from chain.
2. Configure proxy to use client certs with sites requires it using ACL's.

>
> Best regards,
> Ilya Karpov
> karpoftea at gmail.com <mailto:karpoftea at gmail.com>
>
>
>> 20 ????. 2015 ?., ? 12:24, Yuri Voinov <yvoinov at gmail.com 
>> <mailto:yvoinov at gmail.com>> ???????(?):
>>
>> Transparent SSL Bump interception, eh?
>>
>> 20.02.15 15:14, Ilya Karpov ?????:
>>> Hi guys,
>>> can anyone suggest solution to make following scenario work using squid:
>>>
>>> step1.
>>> Client(actually server application) calls HTTP://example 
>>> <http://example/>.org squid via proxy.
>>>  |
>>> V
>>> step2.
>>> Proxy(Squid) understands that all calls to HTTP://example.org 
>>> <http://example.org/> should be changed to HTTPS://example.org 
>>> <https://example.org/>, trusts CA that uses example.org 
>>> <http://example.org/> and knows client certificate to use for https 
>>> client authentication
>>>  |
>>> V
>>> step3.
>>> Origin(some server in internet) accepts https request, authenticates 
>>> client, returns response
>>>
>>> The main aim is to make client know nothing about https complexity 
>>> (storing certificates/keys, knowing specific algorithms etc), and 
>>> make squid manage this things.
>>>
>>>
>>> Best regards,
>>> Ilya Karpov
>>> karpoftea at gmail.com <mailto:karpoftea at gmail.com>
>>>
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org 
>> <mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/d1ef949f/attachment.htm>

From codl at codl.fr  Fri Feb 20 09:55:41 2015
From: codl at codl.fr (Corentin Delcourt)
Date: Fri, 20 Feb 2015 10:55:41 +0100
Subject: [squid-users] "Valid document was not found in the cache" forwarded
	to clients
Message-ID: <54E7049D.2070102@codl.fr>

Hello list.

I described this issue a few days ago on IRC and no-one could help me, 
so I am now turning to you. Here's my problem:

I run two squid servers, siblings with each other, let's call them A and 
B. When clients send requests to A, and A thinks B has the resource 
cached, but in reality B doesn't, the client will get a 504 error with 
the message: ?Valid document was not found in the cache and 
?only-if-cached? directive was specified.? Vice versa if clients send 
requests to B.

I believe that A should catch this error and fetch the resource 
directly, but instead it forwards it to the client, and I cannot figure 
out why. I am not using allow-miss.

What confuses me even more is that this didn't happen a month ago, with 
the same setup.

Below is my squid.conf for A. The squid.conf for B is the same, but with 
B swapped for A in the cache_peer directive.

acl localnet src 10.0.0.0/8
acl localnet src fc00::/7
acl localnet src fe80::/10

http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128

icp_access allow localnet
icp_access allow localhost
icp_access deny all
icp_port 3130

cache_dir aufs /var/cache/squid 16000 64 256

coredump_dir /var/cache/squid

refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

cache_peer B sibling 3128 3130

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/28c8f224/attachment.htm>

From BennoBright.MariaEphrem at cognizant.com  Fri Feb 20 09:52:27 2015
From: BennoBright.MariaEphrem at cognizant.com (BennoBright.MariaEphrem at cognizant.com)
Date: Fri, 20 Feb 2015 09:52:27 +0000
Subject: [squid-users] Squid compatibility with Ubuntu Server 14.10
Message-ID: <30C3345C44B22C43BED78A9A7C25BB013AD1A009@CTSINCHNSXMBM.cts.com>

Hi,

We got a requirement as setting up a squid proxy in the Linux OS.  Squid proxy is new for me.   It will be helpful if I got clarification for the below questions.


1)       Is it Squid proxy compatible with Ubuntu Server 14.10.

2)      Which Squid proxy version fit in more appropriate with the Ubuntu Server 14.10.

3)      Performance wise is there any recommendation to choose OS and Squid proxy combination with respect to the version etc?

4)      Where can I see the list of Linux server versions which are compatible with the Squid Proxy.

With Regards,
Benno Bright M.
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/28cbc552/attachment.htm>

From squid3 at treenet.co.nz  Fri Feb 20 10:57:37 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Feb 2015 23:57:37 +1300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <CAAdA2WOZxAVvA17tM4ButCO0WDhsopaBah5fn-Uq6_DFAiDK+g@mail.gmail.com>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
 <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
 <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>
 <54E68AB0.2010609@treenet.co.nz>
 <CAAdA2WOZxAVvA17tM4ButCO0WDhsopaBah5fn-Uq6_DFAiDK+g@mail.gmail.com>
Message-ID: <54E71321.3080504@treenet.co.nz>

On 20/02/2015 10:09 p.m., Odhiambo Washington wrote:
> On 20 February 2015 at 04:15, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 20/02/2015 5:15 a.m., Odhiambo Washington wrote:
>>> On 19 February 2015 at 15:12, Odhiambo Washington <odhiambo at gmail.com>
>>> wrote:
>>>
>>>> Hi Amos,
>>>>
>>>> I did see that thread. However, the discussion was still continuing
>> then.
>>>>
>>>>
>>>> I will apply it to my server and see.
>>>>
>>>> Reporting back today!
>>>>
>>>>
>>>>
>>>> On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>>>
>>>>> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
>>>>>> I have been hoping that 3.5.2 would possibly help address my problems
>>>>> with
>>>>>> ACLs, but alas!
>>>>>
>>>>> Ah, I thought you saw this announcement made just after your last
>>>>> message in Jan:
>>>>>
>>>>> <
>>>>>
>> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
>>>>>>
>>>>>
>>>>> Its sounds very much like what your last few threads have been
>>>>> describing as happening. Signal handling issues will affect all the
>>>>> squid -k operations.
>>>>>
>>>>> Amos
>>>>>
>>>>
>>>
>>> I have compiled a custom kernel after applying this patch mentioned in
>> that
>>> thread.
>>
>> Er. There were two patches mentioned as being applied in the FreeBSD
>> mail and bug reports.
>>
>>>
>>> wash at mail:~$ uname -a
>>> FreeBSD mail.ili.or.ug 10.1-RELEASE-p5 FreeBSD 10.1-RELEASE-p5 #4: Thu
>> Feb
>>> 19 16:55:56 EAT 2015     root at mail.ili.or.ug:/usr/obj/usr/src/sys
>>> /BEASTIE-10.x  amd64
>>>
>>>
>>> However, my issues still persist.
>>>
>>> root at mail:/opt # /opt/squid-3.5.2/sbin/squid -k reconfigure
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>
>>>
>>> Would this then suggest there is a problem with my squid.conf
>>> <http://pastebin.com/wwwcnHnF> ?
>>>
>>> Or the FreeBSD problem isn't quite solved?
>>>
>>
>> Could you re-state what the problem is?
>>
>> Now your pastebin is expired all we have on record about this problems
>> is the sentence: "it's crashing with errors as seen from <DEAD URL>"
>>
> 
> 
> Generally, Squid seems to partially ignore my time-based ACLS as seen in
> the squid.conf
> 

Oh. I thought you were talking about crashes still since you keep
posting that -k reconfigure output (its odd, but only in that it should
not be that visible).



> It would block one site but allow the others. I expect a standard blocking
> within the specied time.
> 
> I have not been able to figure out why.
> 
> For instance, my ACL for TIMEWASTAGESITED contains .facebook.com, .gmail.com
> and .youtube.com as dstdomains.
> 
> I find that youtube.com is blocked while facebook.com is not blocked. Both
> should be blocked at this time (11:58)
> 
> root at mail:/opt/squid-3.5.2/etc # tail -f /usr/local/squid/logs/access.log |
> grep DENIED
> 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
> http://youtube.com/ - HIER_NONE/- text/html
> 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
> http://youtube.com/favicon.ico - HIER_NONE/- text/html
> 
> root at mail:/opt/squid-3.5.2/etc # tail -f /usr/local/squid/logs/access.log |
> grep 192.168.2.2
> 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
> http://youtube.com/ - HIER_NONE/- text/html
> 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
> http://youtube.com/favicon.ico - HIER_NONE/- text/html
> 1424422710.537    863 192.168.2.2 TCP_MISS/400 372 POST
> http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.221.228.66 text/html
> 1424422710.578    903 192.168.2.2 TCP_MISS/400 372 POST
> http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.197.243.221 text/html
> 1424422755.202   1239 192.168.2.2 TCP_MISS/200 280 POST
> http://bench.utorrent.com/e?i=20 - ORIGINAL_DST/54.243.183.178 text/html
> 1424422756.602    846 192.168.2.2 TCP_MISS/200 1016 GET
> http://cdn.ap.bittorrent.com/control/feature/tags/ut.json - ORIGINAL_DST/
> 54.230.128.
> 193 application/json
> 1424422895.279    593 192.168.2.2 TCP_MISS/404 1792 GET
> http://www.gstatic.com/chrome/profile_avatars/NothingToDownload -
> ORIGINAL_DST/196.0
> .3.114 text/html
> 
> 
> The odd part:
> 
> While facebook.com and gmail.com are accessible, nothing appears at all in
> the access.log and cache.log (debug mode) about them yet this is an
> intercept proxy. The sites just load. No log enties:(

The browser is maybe ...
- not using the proxy for them at all (QUIC or WebSockets protocol), or
- using a CONNECT tunnel which will only appear when its closed (HTTPS
SPDY, HTTP/2), or
- using a domain you dont have listed ("Google" services are actually
*.1e100.net and "Facebook" is actually *.fbcdn.net).

NP: If they are using SPDY or HTTP/2 within a CONNECT tunnel it may be
used for a day or so without anything appearing in the log.

Check your cachemgr active_requests report to see if there is CONNECT to
facebook or gmail active. They may have been opened before your block
period and stay open into it.


Amos



From odhiambo at gmail.com  Fri Feb 20 11:35:33 2015
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 20 Feb 2015 14:35:33 +0300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <54E71321.3080504@treenet.co.nz>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
 <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
 <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>
 <54E68AB0.2010609@treenet.co.nz>
 <CAAdA2WOZxAVvA17tM4ButCO0WDhsopaBah5fn-Uq6_DFAiDK+g@mail.gmail.com>
 <54E71321.3080504@treenet.co.nz>
Message-ID: <CAAdA2WN+NxYit01fdjAas6Np3YF1Q=tweLii-R0a4mkVxPn1uA@mail.gmail.com>

On 20 February 2015 at 13:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 20/02/2015 10:09 p.m., Odhiambo Washington wrote:
> > On 20 February 2015 at 04:15, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
> >
> >> On 20/02/2015 5:15 a.m., Odhiambo Washington wrote:
> >>> On 19 February 2015 at 15:12, Odhiambo Washington <odhiambo at gmail.com>
> >>> wrote:
> >>>
> >>>> Hi Amos,
> >>>>
> >>>> I did see that thread. However, the discussion was still continuing
> >> then.
> >>>>
> >>>>
> >>>> I will apply it to my server and see.
> >>>>
> >>>> Reporting back today!
> >>>>
> >>>>
> >>>>
> >>>> On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz>
> >> wrote:
> >>>>
> >>>>> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
> >>>>>> I have been hoping that 3.5.2 would possibly help address my
> problems
> >>>>> with
> >>>>>> ACLs, but alas!
> >>>>>
> >>>>> Ah, I thought you saw this announcement made just after your last
> >>>>> message in Jan:
> >>>>>
> >>>>> <
> >>>>>
> >>
> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
> >>>>>>
> >>>>>
> >>>>> Its sounds very much like what your last few threads have been
> >>>>> describing as happening. Signal handling issues will affect all the
> >>>>> squid -k operations.
> >>>>>
> >>>>> Amos
> >>>>>
> >>>>
> >>>
> >>> I have compiled a custom kernel after applying this patch mentioned in
> >> that
> >>> thread.
> >>
> >> Er. There were two patches mentioned as being applied in the FreeBSD
> >> mail and bug reports.
> >>
> >>>
> >>> wash at mail:~$ uname -a
> >>> FreeBSD mail.ili.or.ug 10.1-RELEASE-p5 FreeBSD 10.1-RELEASE-p5 #4: Thu
> >> Feb
> >>> 19 16:55:56 EAT 2015     root at mail.ili.or.ug:/usr/obj/usr/src/sys
> >>> /BEASTIE-10.x  amd64
> >>>
> >>>
> >>> However, my issues still persist.
> >>>
> >>> root at mail:/opt # /opt/squid-3.5.2/sbin/squid -k reconfigure
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>
> >>>
> >>> Would this then suggest there is a problem with my squid.conf
> >>> <http://pastebin.com/wwwcnHnF> ?
> >>>
> >>> Or the FreeBSD problem isn't quite solved?
> >>>
> >>
> >> Could you re-state what the problem is?
> >>
> >> Now your pastebin is expired all we have on record about this problems
> >> is the sentence: "it's crashing with errors as seen from <DEAD URL>"
> >>
> >
> >
> > Generally, Squid seems to partially ignore my time-based ACLS as seen in
> > the squid.conf
> >
>
> Oh. I thought you were talking about crashes still since you keep
> posting that -k reconfigure output (its odd, but only in that it should
> not be that visible).
>
>
>
> > It would block one site but allow the others. I expect a standard
> blocking
> > within the specied time.
> >
> > I have not been able to figure out why.
> >
> > For instance, my ACL for TIMEWASTAGESITED contains .facebook.com, .
> gmail.com
> > and .youtube.com as dstdomains.
> >
> > I find that youtube.com is blocked while facebook.com is not blocked.
> Both
> > should be blocked at this time (11:58)
> >
> > root at mail:/opt/squid-3.5.2/etc # tail -f
> /usr/local/squid/logs/access.log |
> > grep DENIED
> > 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
> > http://youtube.com/ - HIER_NONE/- text/html
> > 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
> > http://youtube.com/favicon.ico - HIER_NONE/- text/html
> >
> > root at mail:/opt/squid-3.5.2/etc # tail -f
> /usr/local/squid/logs/access.log |
> > grep 192.168.2.2
> > 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
> > http://youtube.com/ - HIER_NONE/- text/html
> > 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
> > http://youtube.com/favicon.ico - HIER_NONE/- text/html
> > 1424422710.537    863 192.168.2.2 TCP_MISS/400 372 POST
> > http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.221.228.66 text/html
> > 1424422710.578    903 192.168.2.2 TCP_MISS/400 372 POST
> > http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.197.243.221 text/html
> > 1424422755.202   1239 192.168.2.2 TCP_MISS/200 280 POST
> > http://bench.utorrent.com/e?i=20 - ORIGINAL_DST/54.243.183.178 text/html
> > 1424422756.602    846 192.168.2.2 TCP_MISS/200 1016 GET
> > http://cdn.ap.bittorrent.com/control/feature/tags/ut.json -
> ORIGINAL_DST/
> > 54.230.128.
> > 193 application/json
> > 1424422895.279    593 192.168.2.2 TCP_MISS/404 1792 GET
> > http://www.gstatic.com/chrome/profile_avatars/NothingToDownload -
> > ORIGINAL_DST/196.0
> > .3.114 text/html
> >
> >
> > The odd part:
> >
> > While facebook.com and gmail.com are accessible, nothing appears at all
> in
> > the access.log and cache.log (debug mode) about them yet this is an
> > intercept proxy. The sites just load. No log enties:(
>
> The browser is maybe ...
> - not using the proxy for them at all (QUIC or WebSockets protocol), or
>

I am using Google Chrome on Windows. Pretty vanilla Chrome so that's not
possible.


> - using a CONNECT tunnel which will only appear when its closed (HTTPS
> SPDY, HTTP/2), or
> - using a domain you dont have listed ("Google" services are actually
> *.1e100.net and "Facebook" is actually *.fbcdn.net).
>

 I see none of such entries in the logs


> NP: If they are using SPDY or HTTP/2 within a CONNECT tunnel it may be
> used for a day or so without anything appearing in the log.
>
>
There I am lost completey.



> Check your cachemgr active_requests report to see if there is CONNECT to
> facebook or gmail active. They may have been opened before your block
> period and stay open into it.
>
>
root at mail:/opt/squid-3.5.2/etc # /opt/squid-3.5.2/bin/squidclient -h
localhost -p 13128 cache_object://localhost/ mgr:active_requests
HTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Fri, 20 Feb 2015 11:35:17 GMT
Content-Type: text/plain;charset=utf-8
Expires: Fri, 20 Feb 2015 11:35:17 GMT
Last-Modified: Fri, 20 Feb 2015 11:35:17 GMT
X-Cache: MISS from aardvark
X-Cache-Lookup: MISS from aardvark:13127
Via: 1.1 aardvark (squid)
Connection: close

Connection: 0x809319418
        FD 13, read 137, wrote 0
        FD desc: Reading next request
        in: buf 0x809c9c600, used 137, free 374
        remote: 127.0.0.1:29252
        local: 127.0.0.1:13128
        nrequests: 1
uri cache_object://localhost/active_requests
logType TCP_MISS
out.offset 0, out.size 0
req_sz 137
entry 0x80a2c3c80/7C63DF06F8D015F656D5D9CA81CF8BDE
start 1424432117.586294 (0.000978 seconds ago)
username -
delay_pool 0

That's all I see....



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254733744121/+254722743223
"I can't hear you -- I'm using the scrambler."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/0c5a35fc/attachment.htm>

From squid3 at treenet.co.nz  Fri Feb 20 11:49:25 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Feb 2015 00:49:25 +1300
Subject: [squid-users] Squid compatibility with Ubuntu Server 14.10
In-Reply-To: <30C3345C44B22C43BED78A9A7C25BB013AD1A009@CTSINCHNSXMBM.cts.com>
References: <30C3345C44B22C43BED78A9A7C25BB013AD1A009@CTSINCHNSXMBM.cts.com>
Message-ID: <54E71F45.9050603@treenet.co.nz>

On 20/02/2015 10:52 p.m., BennoBright.MariaEphrem wrote:
> Hi,
> 
> We got a requirement as setting up a squid proxy in the Linux OS.  Squid proxy is new for me.   It will be helpful if I got clarification for the below questions.
> 
> 
> 1)       Is it Squid proxy compatible with Ubuntu Server 14.10.

Yes. Squid is compatible with all popular OS in the market - and quite a
few others as well. With some major limitations when used on Windows or
MacOS.

> 
> 2)      Which Squid proxy version fit in more appropriate with the Ubuntu Server 14.10.
> 

"apt-get install squid" (or maybe selecting Squid in the package manager
menu) installs the Ubuntu provided 3.1 package. This is the definitively
the most appropriate fit for that Ubuntu version - because it was
created and built specifically for installing there.

For a newer Squid I think you can also install the "squid3" package from
the Debian Testing/Jesse or Unstable/Sid repositories fairly easily. It
is a recent 3.4 with some relevant patches from the latest 3.4.11/12
releases.

Going to the Debian package you trade Upstart integration and Ubuntu
paid support for more up-to-date bug fixes, features and speed.



> 3)      Performance wise is there any recommendation to choose OS and Squid proxy combination with respect to the version etc?
> 

Performance is an ongoing work. Each Squid version is a little better
than the previous. So the answer will always be "the latest".

Whether the gradual improvements actually matter for you depends on what
the expected bandwith load is going to be...

- If you are installing it to have up to 30Mbps of traffic thrown
through it then any of the recent Squid should be just fine.

- If you are expecting over 30Mbps traffic rates from a single proxy
then go with the latest (see answer for #2) and prepare yourself to
start learning how to fine tune the config for performance, and later
perhapse also how to custom build with even more tuning.

- A single Squid can reach to somewhere between 50Mbps and 100Mbps at
present with tuning last I heard, then things start to get fancy with
heirarchies for higher traffic volumes.



> 4)      Where can I see the list of Linux server versions which are compatible with the Squid Proxy.
> 

All of them are. See answer for #1.

The best choice is to go with the OS you (or your sysadmin) are most
comfortible with managing already. Learning one new piece of software is
enough, and Squid will operate pretty much the same on most OS.


Amos



From squid3 at treenet.co.nz  Fri Feb 20 12:05:35 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Feb 2015 01:05:35 +1300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <CAAdA2WN+NxYit01fdjAas6Np3YF1Q=tweLii-R0a4mkVxPn1uA@mail.gmail.com>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
 <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
 <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>
 <54E68AB0.2010609@treenet.co.nz>
 <CAAdA2WOZxAVvA17tM4ButCO0WDhsopaBah5fn-Uq6_DFAiDK+g@mail.gmail.com>
 <54E71321.3080504@treenet.co.nz>
 <CAAdA2WN+NxYit01fdjAas6Np3YF1Q=tweLii-R0a4mkVxPn1uA@mail.gmail.com>
Message-ID: <54E7230F.4010705@treenet.co.nz>

On 21/02/2015 12:35 a.m., Odhiambo Washington wrote:
> On 20 February 2015 at 13:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 20/02/2015 10:09 p.m., Odhiambo Washington wrote:
>>> On 20 February 2015 at 04:15, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>>
>>>> On 20/02/2015 5:15 a.m., Odhiambo Washington wrote:
>>>>> On 19 February 2015 at 15:12, Odhiambo Washington <odhiambo at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Amos,
>>>>>>
>>>>>> I did see that thread. However, the discussion was still continuing
>>>> then.
>>>>>>
>>>>>>
>>>>>> I will apply it to my server and see.
>>>>>>
>>>>>> Reporting back today!
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz>
>>>> wrote:
>>>>>>
>>>>>>> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
>>>>>>>> I have been hoping that 3.5.2 would possibly help address my
>> problems
>>>>>>> with
>>>>>>>> ACLs, but alas!
>>>>>>>
>>>>>>> Ah, I thought you saw this announcement made just after your last
>>>>>>> message in Jan:
>>>>>>>
>>>>>>> <
>>>>>>>
>>>>
>> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
>>>>>>>>
>>>>>>>
>>>>>>> Its sounds very much like what your last few threads have been
>>>>>>> describing as happening. Signal handling issues will affect all the
>>>>>>> squid -k operations.
>>>>>>>
>>>>>>> Amos
>>>>>>>
>>>>>>
>>>>>
>>>>> I have compiled a custom kernel after applying this patch mentioned in
>>>> that
>>>>> thread.
>>>>
>>>> Er. There were two patches mentioned as being applied in the FreeBSD
>>>> mail and bug reports.
>>>>
>>>>>
>>>>> wash at mail:~$ uname -a
>>>>> FreeBSD mail.ili.or.ug 10.1-RELEASE-p5 FreeBSD 10.1-RELEASE-p5 #4: Thu
>>>> Feb
>>>>> 19 16:55:56 EAT 2015     root at mail.ili.or.ug:/usr/obj/usr/src/sys
>>>>> /BEASTIE-10.x  amd64
>>>>>
>>>>>
>>>>> However, my issues still persist.
>>>>>
>>>>> root at mail:/opt # /opt/squid-3.5.2/sbin/squid -k reconfigure
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>>
>>>>>
>>>>> Would this then suggest there is a problem with my squid.conf
>>>>> <http://pastebin.com/wwwcnHnF> ?
>>>>>
>>>>> Or the FreeBSD problem isn't quite solved?
>>>>>
>>>>
>>>> Could you re-state what the problem is?
>>>>
>>>> Now your pastebin is expired all we have on record about this problems
>>>> is the sentence: "it's crashing with errors as seen from <DEAD URL>"
>>>>
>>>
>>>
>>> Generally, Squid seems to partially ignore my time-based ACLS as seen in
>>> the squid.conf
>>>
>>
>> Oh. I thought you were talking about crashes still since you keep
>> posting that -k reconfigure output (its odd, but only in that it should
>> not be that visible).
>>
>>
>>
>>> It would block one site but allow the others. I expect a standard
>> blocking
>>> within the specied time.
>>>
>>> I have not been able to figure out why.
>>>
>>> For instance, my ACL for TIMEWASTAGESITED contains .facebook.com, .
>> gmail.com
>>> and .youtube.com as dstdomains.
>>>
>>> I find that youtube.com is blocked while facebook.com is not blocked.
>> Both
>>> should be blocked at this time (11:58)
>>>
>>> root at mail:/opt/squid-3.5.2/etc # tail -f
>> /usr/local/squid/logs/access.log |
>>> grep DENIED
>>> 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
>>> http://youtube.com/ - HIER_NONE/- text/html
>>> 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
>>> http://youtube.com/favicon.ico - HIER_NONE/- text/html
>>>
>>> root at mail:/opt/squid-3.5.2/etc # tail -f
>> /usr/local/squid/logs/access.log |
>>> grep 192.168.2.2
>>> 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
>>> http://youtube.com/ - HIER_NONE/- text/html
>>> 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
>>> http://youtube.com/favicon.ico - HIER_NONE/- text/html
>>> 1424422710.537    863 192.168.2.2 TCP_MISS/400 372 POST
>>> http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.221.228.66 text/html
>>> 1424422710.578    903 192.168.2.2 TCP_MISS/400 372 POST
>>> http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.197.243.221 text/html
>>> 1424422755.202   1239 192.168.2.2 TCP_MISS/200 280 POST
>>> http://bench.utorrent.com/e?i=20 - ORIGINAL_DST/54.243.183.178 text/html
>>> 1424422756.602    846 192.168.2.2 TCP_MISS/200 1016 GET
>>> http://cdn.ap.bittorrent.com/control/feature/tags/ut.json -
>> ORIGINAL_DST/
>>> 54.230.128.
>>> 193 application/json
>>> 1424422895.279    593 192.168.2.2 TCP_MISS/404 1792 GET
>>> http://www.gstatic.com/chrome/profile_avatars/NothingToDownload -
>>> ORIGINAL_DST/196.0
>>> .3.114 text/html
>>>
>>>
>>> The odd part:
>>>
>>> While facebook.com and gmail.com are accessible, nothing appears at all
>> in
>>> the access.log and cache.log (debug mode) about them yet this is an
>>> intercept proxy. The sites just load. No log enties:(
>>
>> The browser is maybe ...
>> - not using the proxy for them at all (QUIC or WebSockets protocol), or
>>
> 
> I am using Google Chrome on Windows. Pretty vanilla Chrome so that's not
> possible.

QUIC is Googles' latest experimental protocol trying to replace HTTP. So
it more possible with Chrome visiting Google sites than on any other
traffic.


> 
>> - using a CONNECT tunnel which will only appear when its closed (HTTPS
>> SPDY, HTTP/2), or
>> - using a domain you dont have listed ("Google" services are actually
>> *.1e100.net and "Facebook" is actually *.fbcdn.net).
>>
> 
>  I see none of such entries in the logs
> 
> 
>> NP: If they are using SPDY or HTTP/2 within a CONNECT tunnel it may be
>> used for a day or so without anything appearing in the log.
>>
>>
> There I am lost completey.
> 
> 
> 
>> Check your cachemgr active_requests report to see if there is CONNECT to
>> facebook or gmail active. They may have been opened before your block
>> period and stay open into it.
>>
>>
> root at mail:/opt/squid-3.5.2/etc # /opt/squid-3.5.2/bin/squidclient -h
> localhost -p 13128 cache_object://localhost/ mgr:active_requests
> HTTP/1.1 200 OK
> Server: squid
> Mime-Version: 1.0
> Date: Fri, 20 Feb 2015 11:35:17 GMT
> Content-Type: text/plain;charset=utf-8
> Expires: Fri, 20 Feb 2015 11:35:17 GMT
> Last-Modified: Fri, 20 Feb 2015 11:35:17 GMT
> X-Cache: MISS from aardvark
> X-Cache-Lookup: MISS from aardvark:13127
> Via: 1.1 aardvark (squid)
> Connection: close
> 
> Connection: 0x809319418
>         FD 13, read 137, wrote 0
>         FD desc: Reading next request
>         in: buf 0x809c9c600, used 137, free 374
>         remote: 127.0.0.1:29252
>         local: 127.0.0.1:13128
>         nrequests: 1
> uri cache_object://localhost/active_requests
> logType TCP_MISS
> out.offset 0, out.size 0
> req_sz 137
> entry 0x80a2c3c80/7C63DF06F8D015F656D5D9CA81CF8BDE
> start 1424432117.586294 (0.000978 seconds ago)
> username -
> delay_pool 0
> 
> That's all I see....
> 

Okay. The only answer left is that the browser is NOT using the proxy.

Amos


From squid3 at treenet.co.nz  Fri Feb 20 12:05:18 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Feb 2015 01:05:18 +1300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <CAAdA2WN+NxYit01fdjAas6Np3YF1Q=tweLii-R0a4mkVxPn1uA@mail.gmail.com>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
 <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
 <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>
 <54E68AB0.2010609@treenet.co.nz>
 <CAAdA2WOZxAVvA17tM4ButCO0WDhsopaBah5fn-Uq6_DFAiDK+g@mail.gmail.com>
 <54E71321.3080504@treenet.co.nz>
 <CAAdA2WN+NxYit01fdjAas6Np3YF1Q=tweLii-R0a4mkVxPn1uA@mail.gmail.com>
Message-ID: <54E722FD.3020002@treenet.co.nz>

On 21/02/2015 12:35 a.m., Odhiambo Washington wrote:
> On 20 February 2015 at 13:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 20/02/2015 10:09 p.m., Odhiambo Washington wrote:
>>> On 20 February 2015 at 04:15, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>>
>>>> On 20/02/2015 5:15 a.m., Odhiambo Washington wrote:
>>>>> On 19 February 2015 at 15:12, Odhiambo Washington <odhiambo at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Amos,
>>>>>>
>>>>>> I did see that thread. However, the discussion was still continuing
>>>> then.
>>>>>>
>>>>>>
>>>>>> I will apply it to my server and see.
>>>>>>
>>>>>> Reporting back today!
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz>
>>>> wrote:
>>>>>>
>>>>>>> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
>>>>>>>> I have been hoping that 3.5.2 would possibly help address my
>> problems
>>>>>>> with
>>>>>>>> ACLs, but alas!
>>>>>>>
>>>>>>> Ah, I thought you saw this announcement made just after your last
>>>>>>> message in Jan:
>>>>>>>
>>>>>>> <
>>>>>>>
>>>>
>> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
>>>>>>>>
>>>>>>>
>>>>>>> Its sounds very much like what your last few threads have been
>>>>>>> describing as happening. Signal handling issues will affect all the
>>>>>>> squid -k operations.
>>>>>>>
>>>>>>> Amos
>>>>>>>
>>>>>>
>>>>>
>>>>> I have compiled a custom kernel after applying this patch mentioned in
>>>> that
>>>>> thread.
>>>>
>>>> Er. There were two patches mentioned as being applied in the FreeBSD
>>>> mail and bug reports.
>>>>
>>>>>
>>>>> wash at mail:~$ uname -a
>>>>> FreeBSD mail.ili.or.ug 10.1-RELEASE-p5 FreeBSD 10.1-RELEASE-p5 #4: Thu
>>>> Feb
>>>>> 19 16:55:56 EAT 2015     root at mail.ili.or.ug:/usr/obj/usr/src/sys
>>>>> /BEASTIE-10.x  amd64
>>>>>
>>>>>
>>>>> However, my issues still persist.
>>>>>
>>>>> root at mail:/opt # /opt/squid-3.5.2/sbin/squid -k reconfigure
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
>>>>>
>>>>>
>>>>> Would this then suggest there is a problem with my squid.conf
>>>>> <http://pastebin.com/wwwcnHnF> ?
>>>>>
>>>>> Or the FreeBSD problem isn't quite solved?
>>>>>
>>>>
>>>> Could you re-state what the problem is?
>>>>
>>>> Now your pastebin is expired all we have on record about this problems
>>>> is the sentence: "it's crashing with errors as seen from <DEAD URL>"
>>>>
>>>
>>>
>>> Generally, Squid seems to partially ignore my time-based ACLS as seen in
>>> the squid.conf
>>>
>>
>> Oh. I thought you were talking about crashes still since you keep
>> posting that -k reconfigure output (its odd, but only in that it should
>> not be that visible).
>>
>>
>>
>>> It would block one site but allow the others. I expect a standard
>> blocking
>>> within the specied time.
>>>
>>> I have not been able to figure out why.
>>>
>>> For instance, my ACL for TIMEWASTAGESITED contains .facebook.com, .
>> gmail.com
>>> and .youtube.com as dstdomains.
>>>
>>> I find that youtube.com is blocked while facebook.com is not blocked.
>> Both
>>> should be blocked at this time (11:58)
>>>
>>> root at mail:/opt/squid-3.5.2/etc # tail -f
>> /usr/local/squid/logs/access.log |
>>> grep DENIED
>>> 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
>>> http://youtube.com/ - HIER_NONE/- text/html
>>> 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
>>> http://youtube.com/favicon.ico - HIER_NONE/- text/html
>>>
>>> root at mail:/opt/squid-3.5.2/etc # tail -f
>> /usr/local/squid/logs/access.log |
>>> grep 192.168.2.2
>>> 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
>>> http://youtube.com/ - HIER_NONE/- text/html
>>> 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
>>> http://youtube.com/favicon.ico - HIER_NONE/- text/html
>>> 1424422710.537    863 192.168.2.2 TCP_MISS/400 372 POST
>>> http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.221.228.66 text/html
>>> 1424422710.578    903 192.168.2.2 TCP_MISS/400 372 POST
>>> http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.197.243.221 text/html
>>> 1424422755.202   1239 192.168.2.2 TCP_MISS/200 280 POST
>>> http://bench.utorrent.com/e?i=20 - ORIGINAL_DST/54.243.183.178 text/html
>>> 1424422756.602    846 192.168.2.2 TCP_MISS/200 1016 GET
>>> http://cdn.ap.bittorrent.com/control/feature/tags/ut.json -
>> ORIGINAL_DST/
>>> 54.230.128.
>>> 193 application/json
>>> 1424422895.279    593 192.168.2.2 TCP_MISS/404 1792 GET
>>> http://www.gstatic.com/chrome/profile_avatars/NothingToDownload -
>>> ORIGINAL_DST/196.0
>>> .3.114 text/html
>>>
>>>
>>> The odd part:
>>>
>>> While facebook.com and gmail.com are accessible, nothing appears at all
>> in
>>> the access.log and cache.log (debug mode) about them yet this is an
>>> intercept proxy. The sites just load. No log enties:(
>>
>> The browser is maybe ...
>> - not using the proxy for them at all (QUIC or WebSockets protocol), or
>>
> 
> I am using Google Chrome on Windows. Pretty vanilla Chrome so that's not
> possible.

QUIC is Googles' latest experimental protocol trying to replace HTTP. So
it more possible with Chrome visiting Google sites than on any other
traffic.


> 
>> - using a CONNECT tunnel which will only appear when its closed (HTTPS
>> SPDY, HTTP/2), or
>> - using a domain you dont have listed ("Google" services are actually
>> *.1e100.net and "Facebook" is actually *.fbcdn.net).
>>
> 
>  I see none of such entries in the logs
> 
> 
>> NP: If they are using SPDY or HTTP/2 within a CONNECT tunnel it may be
>> used for a day or so without anything appearing in the log.
>>
>>
> There I am lost completey.
> 
> 
> 
>> Check your cachemgr active_requests report to see if there is CONNECT to
>> facebook or gmail active. They may have been opened before your block
>> period and stay open into it.
>>
>>
> root at mail:/opt/squid-3.5.2/etc # /opt/squid-3.5.2/bin/squidclient -h
> localhost -p 13128 cache_object://localhost/ mgr:active_requests
> HTTP/1.1 200 OK
> Server: squid
> Mime-Version: 1.0
> Date: Fri, 20 Feb 2015 11:35:17 GMT
> Content-Type: text/plain;charset=utf-8
> Expires: Fri, 20 Feb 2015 11:35:17 GMT
> Last-Modified: Fri, 20 Feb 2015 11:35:17 GMT
> X-Cache: MISS from aardvark
> X-Cache-Lookup: MISS from aardvark:13127
> Via: 1.1 aardvark (squid)
> Connection: close
> 
> Connection: 0x809319418
>         FD 13, read 137, wrote 0
>         FD desc: Reading next request
>         in: buf 0x809c9c600, used 137, free 374
>         remote: 127.0.0.1:29252
>         local: 127.0.0.1:13128
>         nrequests: 1
> uri cache_object://localhost/active_requests
> logType TCP_MISS
> out.offset 0, out.size 0
> req_sz 137
> entry 0x80a2c3c80/7C63DF06F8D015F656D5D9CA81CF8BDE
> start 1424432117.586294 (0.000978 seconds ago)
> username -
> delay_pool 0
> 
> That's all I see....
> 

Okay. The only answer left is that the browser is NOT using the proxy.

Amos


From odhiambo at gmail.com  Fri Feb 20 12:16:09 2015
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 20 Feb 2015 15:16:09 +0300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <54E7230F.4010705@treenet.co.nz>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E5C3E9.8000103@treenet.co.nz>
 <CAAdA2WPp3eO+pxdT2=wS3uEh5SrEgQJ6XJWvtN-uE_A0Gf3-Tg@mail.gmail.com>
 <CAAdA2WNpvzGaxbjkQjiu0mbJAHcG7PUaLN+3oFwfc2zbboiigg@mail.gmail.com>
 <54E68AB0.2010609@treenet.co.nz>
 <CAAdA2WOZxAVvA17tM4ButCO0WDhsopaBah5fn-Uq6_DFAiDK+g@mail.gmail.com>
 <54E71321.3080504@treenet.co.nz>
 <CAAdA2WN+NxYit01fdjAas6Np3YF1Q=tweLii-R0a4mkVxPn1uA@mail.gmail.com>
 <54E7230F.4010705@treenet.co.nz>
Message-ID: <CAAdA2WPejP7CSHOfp-QS2m+HwufSoqOZ4i0Z+5b-VUKCFSR54Q@mail.gmail.com>

When I configure the browser to manually use proxy, the pages fail to load
and here is what I get:

root at mail:/opt/squid-3.5.2/etc # tail -f /usr/local/squid/logs/access.log |
grep 192.168.2.2
1424434499.542   1411 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.542    111 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.542    361 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.542    592 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.543   1025 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.553      1 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.553      1 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.553      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.555      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.560      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434499.658      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434501.789    459 192.168.2.2 TAG_NONE/409 4309 CONNECT
mail.google.com:443 - HIER_NONE/- text/html
1424434502.053      0 192.168.2.2 TAG_NONE/409 4309 CONNECT
mail.google.com:443 - HIER_NONE/- text/html
1424434507.086      0 192.168.2.2 TAG_NONE/409 4309 CONNECT
mail.google.com:443 - HIER_NONE/- text/html
1424434537.127      0 192.168.2.2 TAG_NONE/409 4309 CONNECT
mail.google.com:443 - HIER_NONE/- text/html
1424434538.527      2 192.168.2.254 TCP_MISS/403 4246 GET
http://www.gstatic.com/generate_204 - HIER_NONE/- text/html
1424434538.527   1401 192.168.2.2 TCP_MISS/403 4339 GET
http://www.gstatic.com/generate_204 - ORIGINAL_DST/192.168.2.254 text/html
1424434541.027      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434541.166      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434541.325      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434541.465      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434541.791      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434542.091      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434542.185      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434542.297      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434542.490      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434542.680      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434542.845      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434543.036      0 192.168.2.2 TAG_NONE/409 4306 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1424434543.258    205 192.168.2.2 TAG_NONE/409 4300 CONNECT facebook.com:443
- HIER_NONE/- text/html
1424434543.324      0 192.168.2.2 TAG_NONE/409 4300 CONNECT facebook.com:443
- HIER_NONE/- text/html
1424434544.384      0 192.168.2.2 TAG_NONE/409 4300 CONNECT facebook.com:443
- HIER_NONE/- text/html
1424434544.596      0 192.168.2.2 TAG_NONE/409 4300 CONNECT facebook.com:443
- HIER_NONE/- text/html
1424434549.609      0 192.168.2.2 TAG_NONE/409 4300 CONNECT facebook.com:443
- HIER_NONE/- text/html



On 20 February 2015 at 15:05, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 21/02/2015 12:35 a.m., Odhiambo Washington wrote:
> > On 20 February 2015 at 13:57, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
> >
> >> On 20/02/2015 10:09 p.m., Odhiambo Washington wrote:
> >>> On 20 February 2015 at 04:15, Amos Jeffries <squid3 at treenet.co.nz>
> >> wrote:
> >>>
> >>>> On 20/02/2015 5:15 a.m., Odhiambo Washington wrote:
> >>>>> On 19 February 2015 at 15:12, Odhiambo Washington <
> odhiambo at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> Hi Amos,
> >>>>>>
> >>>>>> I did see that thread. However, the discussion was still continuing
> >>>> then.
> >>>>>>
> >>>>>>
> >>>>>> I will apply it to my server and see.
> >>>>>>
> >>>>>> Reporting back today!
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> On 19 February 2015 at 14:07, Amos Jeffries <squid3 at treenet.co.nz>
> >>>> wrote:
> >>>>>>
> >>>>>>> On 19/02/2015 10:49 p.m., Odhiambo Washington wrote:
> >>>>>>>> I have been hoping that 3.5.2 would possibly help address my
> >> problems
> >>>>>>> with
> >>>>>>>> ACLs, but alas!
> >>>>>>>
> >>>>>>> Ah, I thought you saw this announcement made just after your last
> >>>>>>> message in Jan:
> >>>>>>>
> >>>>>>> <
> >>>>>>>
> >>>>
> >>
> http://lists.squid-cache.org/pipermail/squid-users/2015-January/001745.html
> >>>>>>>>
> >>>>>>>
> >>>>>>> Its sounds very much like what your last few threads have been
> >>>>>>> describing as happening. Signal handling issues will affect all the
> >>>>>>> squid -k operations.
> >>>>>>>
> >>>>>>> Amos
> >>>>>>>
> >>>>>>
> >>>>>
> >>>>> I have compiled a custom kernel after applying this patch mentioned
> in
> >>>> that
> >>>>> thread.
> >>>>
> >>>> Er. There were two patches mentioned as being applied in the FreeBSD
> >>>> mail and bug reports.
> >>>>
> >>>>>
> >>>>> wash at mail:~$ uname -a
> >>>>> FreeBSD mail.ili.or.ug 10.1-RELEASE-p5 FreeBSD 10.1-RELEASE-p5 #4:
> Thu
> >>>> Feb
> >>>>> 19 16:55:56 EAT 2015     root at mail.ili.or.ug:/usr/obj/usr/src/sys
> >>>>> /BEASTIE-10.x  amd64
> >>>>>
> >>>>>
> >>>>> However, my issues still persist.
> >>>>>
> >>>>> root at mail:/opt # /opt/squid-3.5.2/sbin/squid -k reconfigure
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>> 2015/02/19 19:10:53.639| Acl.cc(380) ~ACL: freeing ACL
> >>>>>
> >>>>>
> >>>>> Would this then suggest there is a problem with my squid.conf
> >>>>> <http://pastebin.com/wwwcnHnF> ?
> >>>>>
> >>>>> Or the FreeBSD problem isn't quite solved?
> >>>>>
> >>>>
> >>>> Could you re-state what the problem is?
> >>>>
> >>>> Now your pastebin is expired all we have on record about this problems
> >>>> is the sentence: "it's crashing with errors as seen from <DEAD URL>"
> >>>>
> >>>
> >>>
> >>> Generally, Squid seems to partially ignore my time-based ACLS as seen
> in
> >>> the squid.conf
> >>>
> >>
> >> Oh. I thought you were talking about crashes still since you keep
> >> posting that -k reconfigure output (its odd, but only in that it should
> >> not be that visible).
> >>
> >>
> >>
> >>> It would block one site but allow the others. I expect a standard
> >> blocking
> >>> within the specied time.
> >>>
> >>> I have not been able to figure out why.
> >>>
> >>> For instance, my ACL for TIMEWASTAGESITED contains .facebook.com, .
> >> gmail.com
> >>> and .youtube.com as dstdomains.
> >>>
> >>> I find that youtube.com is blocked while facebook.com is not blocked.
> >> Both
> >>> should be blocked at this time (11:58)
> >>>
> >>> root at mail:/opt/squid-3.5.2/etc # tail -f
> >> /usr/local/squid/logs/access.log |
> >>> grep DENIED
> >>> 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
> >>> http://youtube.com/ - HIER_NONE/- text/html
> >>> 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
> >>> http://youtube.com/favicon.ico - HIER_NONE/- text/html
> >>>
> >>> root at mail:/opt/squid-3.5.2/etc # tail -f
> >> /usr/local/squid/logs/access.log |
> >>> grep 192.168.2.2
> >>> 1424422669.545    456 192.168.2.2 TCP_DENIED/403 4345 GET
> >>> http://youtube.com/ - HIER_NONE/- text/html
> >>> 1424422671.910      1 192.168.2.2 TCP_DENIED/403 4291 GET
> >>> http://youtube.com/favicon.ico - HIER_NONE/- text/html
> >>> 1424422710.537    863 192.168.2.2 TCP_MISS/400 372 POST
> >>> http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.221.228.66
> text/html
> >>> 1424422710.578    903 192.168.2.2 TCP_MISS/400 372 POST
> >>> http://bench.utorrent.com/e?i=36 - ORIGINAL_DST/54.197.243.221
> text/html
> >>> 1424422755.202   1239 192.168.2.2 TCP_MISS/200 280 POST
> >>> http://bench.utorrent.com/e?i=20 - ORIGINAL_DST/54.243.183.178
> text/html
> >>> 1424422756.602    846 192.168.2.2 TCP_MISS/200 1016 GET
> >>> http://cdn.ap.bittorrent.com/control/feature/tags/ut.json -
> >> ORIGINAL_DST/
> >>> 54.230.128.
> >>> 193 application/json
> >>> 1424422895.279    593 192.168.2.2 TCP_MISS/404 1792 GET
> >>> http://www.gstatic.com/chrome/profile_avatars/NothingToDownload -
> >>> ORIGINAL_DST/196.0
> >>> .3.114 text/html
> >>>
> >>>
> >>> The odd part:
> >>>
> >>> While facebook.com and gmail.com are accessible, nothing appears at
> all
> >> in
> >>> the access.log and cache.log (debug mode) about them yet this is an
> >>> intercept proxy. The sites just load. No log enties:(
> >>
> >> The browser is maybe ...
> >> - not using the proxy for them at all (QUIC or WebSockets protocol), or
> >>
> >
> > I am using Google Chrome on Windows. Pretty vanilla Chrome so that's not
> > possible.
>
> QUIC is Googles' latest experimental protocol trying to replace HTTP. So
> it more possible with Chrome visiting Google sites than on any other
> traffic.
>
>
> >
> >> - using a CONNECT tunnel which will only appear when its closed (HTTPS
> >> SPDY, HTTP/2), or
> >> - using a domain you dont have listed ("Google" services are actually
> >> *.1e100.net and "Facebook" is actually *.fbcdn.net).
> >>
> >
> >  I see none of such entries in the logs
> >
> >
> >> NP: If they are using SPDY or HTTP/2 within a CONNECT tunnel it may be
> >> used for a day or so without anything appearing in the log.
> >>
> >>
> > There I am lost completey.
> >
> >
> >
> >> Check your cachemgr active_requests report to see if there is CONNECT to
> >> facebook or gmail active. They may have been opened before your block
> >> period and stay open into it.
> >>
> >>
> > root at mail:/opt/squid-3.5.2/etc # /opt/squid-3.5.2/bin/squidclient -h
> > localhost -p 13128 cache_object://localhost/ mgr:active_requests
> > HTTP/1.1 200 OK
> > Server: squid
> > Mime-Version: 1.0
> > Date: Fri, 20 Feb 2015 11:35:17 GMT
> > Content-Type: text/plain;charset=utf-8
> > Expires: Fri, 20 Feb 2015 11:35:17 GMT
> > Last-Modified: Fri, 20 Feb 2015 11:35:17 GMT
> > X-Cache: MISS from aardvark
> > X-Cache-Lookup: MISS from aardvark:13127
> > Via: 1.1 aardvark (squid)
> > Connection: close
> >
> > Connection: 0x809319418
> >         FD 13, read 137, wrote 0
> >         FD desc: Reading next request
> >         in: buf 0x809c9c600, used 137, free 374
> >         remote: 127.0.0.1:29252
> >         local: 127.0.0.1:13128
> >         nrequests: 1
> > uri cache_object://localhost/active_requests
> > logType TCP_MISS
> > out.offset 0, out.size 0
> > req_sz 137
> > entry 0x80a2c3c80/7C63DF06F8D015F656D5D9CA81CF8BDE
> > start 1424432117.586294 (0.000978 seconds ago)
> > username -
> > delay_pool 0
> >
> > That's all I see....
> >
>
> Okay. The only answer left is that the browser is NOT using the proxy.
>
> Amos
>



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254733744121/+254722743223
"I can't hear you -- I'm using the scrambler."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/9006c60c/attachment.htm>

From squid3 at treenet.co.nz  Fri Feb 20 12:29:26 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Feb 2015 01:29:26 +1300
Subject: [squid-users] "Valid document was not found in the cache"
 forwarded to clients
In-Reply-To: <54E7049D.2070102@codl.fr>
References: <54E7049D.2070102@codl.fr>
Message-ID: <54E728A6.4010606@treenet.co.nz>

On 20/02/2015 10:55 p.m., Corentin Delcourt wrote:
> Hello list.
> 
> I described this issue a few days ago on IRC and no-one could help me,
> so I am now turning to you. Here's my problem:
> 
> I run two squid servers, siblings with each other, let's call them A and
> B. When clients send requests to A, and A thinks B has the resource
> cached, but in reality B doesn't,

Use HTCP protocol between the peers, far less false positives than ICP
or digest.


> the client will get a 504 error with
> the message: ?Valid document was not found in the cache and
> ?only-if-cached? directive was specified.? Vice versa if clients send
> requests to B.
> 
> I believe that A should catch this error and fetch the resource
> directly, but instead it forwards it to the client, and I cannot figure
> out why. I am not using allow-miss.

It should be but there are conditions to that:

* another source of the URL is actually accessible (think IPv6-only
websites, routing outages, DNS lookup failures, Path-MTU failures,
traffic blackholes, etc)

* there is time remaining within the forward_timeout for the alterative
route to be contacted. If the timeout occurs the last error state
encountered will be reported, if there is no earlier error the timeout
itself is mentioned.

* the 504 is not being cached. That error response is one which is
allowed to be cached by proxies if it gets delivered with cacheability
headers. NP: It could be cached and delivered by either proxy, so even
coming from the other one *it* may still have been cached and what
caused the "HIT" to be identified.


> 
> What confuses me even more is that this didn't happen a month ago, with
> the same setup.
> 

... what version of Squid?
... and is it the same setup AND version(s) of Squid from a month ago?


Amos


From codl at codl.fr  Fri Feb 20 14:28:51 2015
From: codl at codl.fr (Corentin Delcourt)
Date: Fri, 20 Feb 2015 15:28:51 +0100
Subject: [squid-users] "Valid document was not found in the cache"
 forwarded to clients
In-Reply-To: <54E728A6.4010606@treenet.co.nz>
References: <54E7049D.2070102@codl.fr> <54E728A6.4010606@treenet.co.nz>
Message-ID: <54E744A3.7080601@codl.fr>


On 20/02/15 13:29, Amos Jeffries wrote:
> On 20/02/2015 10:55 p.m., Corentin Delcourt wrote:
>> I run two squid servers, siblings with each other, let's call them A and
>> B. When clients send requests to A, and A thinks B has the resource
>> cached, but in reality B doesn't,
> Use HTCP protocol between the peers, far less false positives than ICP
> or digest.
Will do, thanks for the tip.
>> the client will get a 504 error with
>> the message: ?Valid document was not found in the cache and
>> ?only-if-cached? directive was specified.? Vice versa if clients send
>> requests to B.
>>
>> I believe that A should catch this error and fetch the resource
>> directly, but instead it forwards it to the client, and I cannot figure
>> out why. I am not using allow-miss.
> It should be but there are conditions to that:
>
> * another source of the URL is actually accessible (think IPv6-only
> websites, routing outages, DNS lookup failures, Path-MTU failures,
> traffic blackholes, etc)
If I re-send a failing request with Cache-Control: no-cache, or if I 
remove the cache_peer directive, I don't get any errors at all so it 
doesn't seem like this is the problem here.
> * there is time remaining within the forward_timeout for the alterative
> route to be contacted. If the timeout occurs the last error state
> encountered will be reported, if there is no earlier error the timeout
> itself is mentioned.
I believe the default timeout is 4 minutes? I set it explicitely to 10 
minutes, and forward-max-tries to 25 for good measure, and requests are 
still failing within hundreds of milliseconds so I don't think this is 
related.
> * the 504 is not being cached. That error response is one which is
> allowed to be cached by proxies if it gets delivered with cacheability
> headers. NP: It could be cached and delivered by either proxy, so even
> coming from the other one *it* may still have been cached and what
> caused the "HIT" to be identified.
I don't think the error is being served from cache. If I look at the 
access logs for both machines I see:

1424437827.131	6 127.0.0.1 	TCP_MISS/504		4913	GET http://example.net/ - SIBLING_HIT/10.0.1.2	text/html

? on A and

1424437827.882	0 10.0.1.1	TCP_MISS/504		4801	GET http://example.net/ - HIER_NONE/- 		text/html

? on B, 10.0.1.1 being A and 10.0.1.2 being B.
>> What confuses me even more is that this didn't happen a month ago, with
>> the same setup.
> ... what version of Squid?
> ... and is it the same setup AND version(s) of Squid from a month ago?
I'm running Squid 3.5.2 on both servers. I was running 3.5.1 on both a 
week ago and observing the same problem.

I can't say for sure which version I was running before this started 
happening, but I believe it was 3.4.8 on one machine and 3.4.10 on the 
other.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/8c7db2ad/attachment.htm>

From eliezer at ngtech.co.il  Fri Feb 20 14:29:01 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 20 Feb 2015 16:29:01 +0200
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
Message-ID: <54E744AD.7090701@ngtech.co.il>

On 19/02/2015 11:49, Odhiambo Washington wrote:
> I have been hoping that 3.5.2 would possibly help address my problems with
> ACLs, but alas!

Sorry for hijacking the thread but the wiki freebsd buildfarm node 
install page:
http://wiki.squid-cache.org/BuildFarm/FreeBsdInstall

Doesn't include any information regarding FBSD 10.
Any directions? I assume that the wiki applies to 10.1 also?

Thanks,
Eliezer



From odhiambo at gmail.com  Fri Feb 20 14:35:22 2015
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 20 Feb 2015 17:35:22 +0300
Subject: [squid-users] Squid-3.5.2 and FreeBSD 10.1
In-Reply-To: <54E744AD.7090701@ngtech.co.il>
References: <CAAdA2WMoE3a22jh_gTOBPpE3eJzbRhPdOK6VZF-kEPjy5Q5Bxg@mail.gmail.com>
 <54E744AD.7090701@ngtech.co.il>
Message-ID: <CAAdA2WNDTj=3jKkLsJzG-Ugi8xhA+tKbkBcsRHa9HWcjxWo=gw@mail.gmail.com>

On 20 February 2015 at 17:29, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:

> On 19/02/2015 11:49, Odhiambo Washington wrote:
>
>> I have been hoping that 3.5.2 would possibly help address my problems with
>> ACLs, but alas!
>>
>
> Sorry for hijacking the thread but the wiki freebsd buildfarm node install
> page:
> http://wiki.squid-cache.org/BuildFarm/FreeBsdInstall
>
> Doesn't include any information regarding FBSD 10.
> Any directions? I assume that the wiki applies to 10.1 also?
>
>
I haven't used jenkins, but in 10.x, `pkg install ...` is what is
recommended.
>From that wiki, go with the instructions for 9+ as they apply to 10 and
above.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254733744121/+254722743223
"I can't hear you -- I'm using the scrambler."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/fbeef634/attachment.htm>

From ahmed.zaeem at netstream.ps  Sat Feb 21 01:37:51 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Fri, 20 Feb 2015 17:37:51 -0800
Subject: [squid-users] many vms behind router to same proxy ips problems !
Message-ID: <008201d04d77$02fbd590$08f380b0$@netstream.ps>

Hi ,

 

I have  squid  with many ips already installed with and configured well with
tcp_outgoing directive.

 

The provlem that I face is ;

When many pc behind a router with same public ip use the proxy ips.

 

Assume I have 2 pcs

Pc1===> Using proxy ip 1.1.1.1

Pc2===>using proxy 1.1.1.2 

Note that 1.1.1.1 & 1.1.1.2 are just for example and we assume those ips are
existed on the main server squid.

 

Pc1 & pc2 ips are 192.168.1.100 & 192.168.1.101 and their public ip is
31.220.243.0

 

 

I go to pc1 and type "whatismyipaddrss.com "  I see 1.1.1.1

 

Then I go to pc2 and type "whatismyipaddrss.com "  I see 2.2.2.2

Now lets go back to pc1 and refresh the page  whatismyipaddrss.com ===?>
then I see 2.2.2.2 not 1.1.1.1 

 

This is my problem.

 

Why sometimes after somefrefresh I get the other ip not ip I put in in
browser ??

 

Could it because same pcs has same public ip ??

 

 

I tried to put por for each ip like 1.1.1.1:1333 and 2.2.2.2:1222 .... but
same resukt , the ip keep changes

 

Also I disabled cacing on squid but no luck .

 

Is that a natural thing ?

 

Or squid can be optimized ?

 

[root at dbmedia ~]# cat /etc/squid/squid.conf

# Lockdown Procedures

auth_param basic program /usr/lib/squid/ncsa_auth /etc/squid/squid_passwd

acl ncsa_users proxy_auth REQUIRED

http_access allow ncsa_users 

#

#

# Recommended minimum configuration:

#

acl manager proto cache_object

acl localhost src 127.0.0.1/32 ::1

acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

 

# Example rule allowing access from your local networks.

# Adapt to list your (internal) IP networks from where browsing

# should be allowed

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network

acl localnet src 172.16.0.0/12  # RFC1918 possible internal network

acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

acl localnet src fc00::/7       # RFC 4193 local private network range

acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

 

acl SSL_ports port 443

acl Safe_ports port 80          # http

acl Safe_ports port 21          # ftp

acl Safe_ports port 443         # https

acl Safe_ports port 70          # gopher

acl Safe_ports port 210         # wais

acl Safe_ports port 1025-65535  # unregistered ports

acl Safe_ports port 280         # http-mgmt

acl Safe_ports port 488         # gss-http

acl Safe_ports port 591         # filemaker

acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

 

#

# Recommended minimum Access Permission configuration:

#

# Only allow cachemgr access from localhost

http_access allow manager localhost

http_access deny manager

 

# Deny requests to certain unsafe ports

http_access deny !Safe_ports

 

# Deny CONNECT to other than secure SSL ports

http_access deny CONNECT !SSL_ports

 

# We strongly recommend the following be uncommented to protect innocent

# web applications running on the proxy server who think the only

# one who can access services on "localhost" is a local user

#http_access deny to_localhost

 

#

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

#

 

# Example rule allowing access from your local networks.

# Adapt localnet in the ACL section to list your (internal) IP networks

# from where browsing should be allowed

http_access allow localnet

http_access allow localhost

 

# And finally deny all other access to this proxy

http_access deny all

 

# Squid normally listens to port 3128

http_port 1111

http_port xxx.27.65:1165

http_port xx.27.68:1168

# We recommend you to use at least the following line.

hierarchy_stoplist cgi-bin ?

 

# Uncomment and adjust the following to add a disk cache directory.

#cache_dir ufs /var/spool/squid 100 16 256

#cache_dir null

cache deny all

# Leave coredumps in the first cache dir

coredump_dir /var/spool/squid

 

# Add any of your own refresh_pattern entries above these.

refresh_pattern ^ftp:           1440    20%     10080

refresh_pattern ^gopher:        1440    0%      1440

refresh_pattern -i (/cgi-bin/|\?) 0     0%      0

refresh_pattern .               0       20%     4320

###############################

forwarded_for off

request_header_access Allow allow all

request_header_access Authorization allow all

request_header_access WWW-Authenticate allow all

request_header_access Proxy-Authorization allow all

request_header_access Proxy-Authenticate allow all

request_header_access Cache-Control allow all

request_header_access Content-Encoding allow all

request_header_access Content-Length allow all

request_header_access Content-Type allow all

request_header_access Date allow all

request_header_access Expires allow all

request_header_access Host allow all

request_header_access If-Modified-Since allow all

request_header_access Last-Modified allow all

request_header_access Location allow all

request_header_access Pragma allow all

request_header_access Accept allow all

request_header_access Accept-Charset allow all

request_header_access Accept-Encoding allow all

request_header_access Accept-Language allow all

request_header_access Content-Language allow all

request_header_access Mime-Version allow all

request_header_access Retry-After allow all

request_header_access Title allow all

request_header_access Connection allow all

request_header_access Proxy-Connection allow all

request_header_access User-Agent allow all

request_header_access Cookie allow all

request_header_access X-Forwarded-For deny all

request_header_access Via deny all

request_header_access All allow all

########################################

acl ipxx myip xx
acl ipxx myip xx
acl ipxx myip xx

 

#######################################

tcp_outgoing_address xxxx ipxxx

tcp_outgoing_address xxxx ipxxx

 

tcp_outgoing_address xxxx ipxxx

 

tcp_outgoing_address xxxx ipxxx

 

#####################################

 

 

 

 

 

squid -v

Squid Cache: Version 3.1.10

configure options:  '--build=i386-redhat-linux-gnu'
'--host=i386-redhat-linux-gnu' '--target=i686-redhat-linux-gnu'
'--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin'
'--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share'
'--includedir=/usr/include' '--libdir=/usr/lib' '--libexecdir=/usr/libexec'
'--sharedstatedir=/var/lib' '--mandir=/usr/share/man'
'--infodir=/usr/share/info' '--enable-internal-dns'
'--disable-strict-error-checking' '--exec_prefix=/usr'
'--libexecdir=/usr/lib/squid' '--localstatedir=/var'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--with-logdir=$(localstatedir)/log/squid'
'--with-pidfile=$(localstatedir)/run/squid.pid'
'--disable-dependency-tracking' '--enable-arp-acl'
'--enable-follow-x-forwarded-for'
'--enable-auth=basic,digest,ntlm,negotiate'
'--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain
-NTLM,SASL,DB,POP3,squid_radius_auth'
'--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth'
'--enable-digest-auth-helpers=password,ldap,eDirectory'
'--enable-negotiate-auth-helpers=squid_kerb_auth'
'--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_
group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
'--enable-ident-lookups' '--with-large-files' '--enable-linux-netfilter'
'--enable-referer-log' '--enable-removal-policies=heap,lru' '--enable-snmp'
'--enable-ssl' '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log'
'--enable-wccpv2' '--enable-esi' '--with-aio' '--with-default-user=squid'
'--with-filedescriptors=16384' '--with-dl' '--with-openssl'
'--with-pthreads' 'build_alias=i386-redhat-linux-gnu'
'host_alias=i386-redhat-linux-gnu' 'target_alias=i686-redhat-linux-gnu'
'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
-fstack-protector --param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom
-fasynchronous-unwind-tables -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g -pipe
-Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom
-fasynchronous-unwind-tables -fpie'
--with-squid=/builddir/build/BUILD/squid-3.1.10

 

 

cheers

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150220/eb4652ef/attachment.htm>

From yvoinov at gmail.com  Fri Feb 20 15:41:02 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 20 Feb 2015 21:41:02 +0600
Subject: [squid-users] many vms behind router to same proxy ips problems
 !
In-Reply-To: <008201d04d77$02fbd590$08f380b0$@netstream.ps>
References: <008201d04d77$02fbd590$08f380b0$@netstream.ps>
Message-ID: <54E7558E.7070704@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

This is not squid problem, man.

Did you hear about TCP routing?

This is the thing your need.

21.02.15 7:37, snakeeyes ?????:
> Hi ,
> 
> 
> 
> I have  squid  with many ips already installed with and configured
> well with tcp_outgoing directive.
> 
> 
> 
> The provlem that I face is ;
> 
> When many pc behind a router with same public ip use the proxy
> ips.
> 
> 
> 
> Assume I have 2 pcs
> 
> Pc1===> Using proxy ip 1.1.1.1
> 
> Pc2===>using proxy 1.1.1.2
> 
> Note that 1.1.1.1 & 1.1.1.2 are just for example and we assume
> those ips are existed on the main server squid.
> 
> 
> 
> Pc1 & pc2 ips are 192.168.1.100 & 192.168.1.101 and their public ip
> is 31.220.243.0
> 
> 
> 
> 
> 
> I go to pc1 and type "whatismyipaddrss.com "  I see 1.1.1.1
> 
> 
> 
> Then I go to pc2 and type "whatismyipaddrss.com "  I see 2.2.2.2
> 
> Now lets go back to pc1 and refresh the page  whatismyipaddrss.com
> ===?> then I see 2.2.2.2 not 1.1.1.1
> 
> 
> 
> This is my problem.
> 
> 
> 
> Why sometimes after somefrefresh I get the other ip not ip I put in
> in browser ??
> 
> 
> 
> Could it because same pcs has same public ip ??
> 
> 
> 
> 
> 
> I tried to put por for each ip like 1.1.1.1:1333 and 2.2.2.2:1222
> .... but same resukt , the ip keep changes
> 
> 
> 
> Also I disabled cacing on squid but no luck .
> 
> 
> 
> Is that a natural thing ?
> 
> 
> 
> Or squid can be optimized ?
> 
> 
> 
> [root at dbmedia ~]# cat /etc/squid/squid.conf
> 
> # Lockdown Procedures
> 
> auth_param basic program /usr/lib/squid/ncsa_auth
> /etc/squid/squid_passwd
> 
> acl ncsa_users proxy_auth REQUIRED
> 
> http_access allow ncsa_users
> 
> #
> 
> #
> 
> # Recommended minimum configuration:
> 
> #
> 
> acl manager proto cache_object
> 
> acl localhost src 127.0.0.1/32 ::1
> 
> acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
> 
> 
> 
> # Example rule allowing access from your local networks.
> 
> # Adapt to list your (internal) IP networks from where browsing
> 
> # should be allowed
> 
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal
> network
> 
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal
> network
> 
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal
> network
> 
> acl localnet src fc00::/7       # RFC 4193 local private network
> range
> 
> acl localnet src fe80::/10      # RFC 4291 link-local (directly
> plugged) machines
> 
> 
> 
> acl SSL_ports port 443
> 
> acl Safe_ports port 80          # http
> 
> acl Safe_ports port 21          # ftp
> 
> acl Safe_ports port 443         # https
> 
> acl Safe_ports port 70          # gopher
> 
> acl Safe_ports port 210         # wais
> 
> acl Safe_ports port 1025-65535  # unregistered ports
> 
> acl Safe_ports port 280         # http-mgmt
> 
> acl Safe_ports port 488         # gss-http
> 
> acl Safe_ports port 591         # filemaker
> 
> acl Safe_ports port 777         # multiling http
> 
> acl CONNECT method CONNECT
> 
> 
> 
> #
> 
> # Recommended minimum Access Permission configuration:
> 
> #
> 
> # Only allow cachemgr access from localhost
> 
> http_access allow manager localhost
> 
> http_access deny manager
> 
> 
> 
> # Deny requests to certain unsafe ports
> 
> http_access deny !Safe_ports
> 
> 
> 
> # Deny CONNECT to other than secure SSL ports
> 
> http_access deny CONNECT !SSL_ports
> 
> 
> 
> # We strongly recommend the following be uncommented to protect
> innocent
> 
> # web applications running on the proxy server who think the only
> 
> # one who can access services on "localhost" is a local user
> 
> #http_access deny to_localhost
> 
> 
> 
> #
> 
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> 
> #
> 
> 
> 
> # Example rule allowing access from your local networks.
> 
> # Adapt localnet in the ACL section to list your (internal) IP
> networks
> 
> # from where browsing should be allowed
> 
> http_access allow localnet
> 
> http_access allow localhost
> 
> 
> 
> # And finally deny all other access to this proxy
> 
> http_access deny all
> 
> 
> 
> # Squid normally listens to port 3128
> 
> http_port 1111
> 
> http_port xxx.27.65:1165
> 
> http_port xx.27.68:1168
> 
> # We recommend you to use at least the following line.
> 
> hierarchy_stoplist cgi-bin ?
> 
> 
> 
> # Uncomment and adjust the following to add a disk cache
> directory.
> 
> #cache_dir ufs /var/spool/squid 100 16 256
> 
> #cache_dir null
> 
> cache deny all
> 
> # Leave coredumps in the first cache dir
> 
> coredump_dir /var/spool/squid
> 
> 
> 
> # Add any of your own refresh_pattern entries above these.
> 
> refresh_pattern ^ftp:           1440    20%     10080
> 
> refresh_pattern ^gopher:        1440    0%      1440
> 
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> 
> refresh_pattern .               0       20%     4320
> 
> ###############################
> 
> forwarded_for off
> 
> request_header_access Allow allow all
> 
> request_header_access Authorization allow all
> 
> request_header_access WWW-Authenticate allow all
> 
> request_header_access Proxy-Authorization allow all
> 
> request_header_access Proxy-Authenticate allow all
> 
> request_header_access Cache-Control allow all
> 
> request_header_access Content-Encoding allow all
> 
> request_header_access Content-Length allow all
> 
> request_header_access Content-Type allow all
> 
> request_header_access Date allow all
> 
> request_header_access Expires allow all
> 
> request_header_access Host allow all
> 
> request_header_access If-Modified-Since allow all
> 
> request_header_access Last-Modified allow all
> 
> request_header_access Location allow all
> 
> request_header_access Pragma allow all
> 
> request_header_access Accept allow all
> 
> request_header_access Accept-Charset allow all
> 
> request_header_access Accept-Encoding allow all
> 
> request_header_access Accept-Language allow all
> 
> request_header_access Content-Language allow all
> 
> request_header_access Mime-Version allow all
> 
> request_header_access Retry-After allow all
> 
> request_header_access Title allow all
> 
> request_header_access Connection allow all
> 
> request_header_access Proxy-Connection allow all
> 
> request_header_access User-Agent allow all
> 
> request_header_access Cookie allow all
> 
> request_header_access X-Forwarded-For deny all
> 
> request_header_access Via deny all
> 
> request_header_access All allow all
> 
> ########################################
> 
> acl ipxx myip xx acl ipxx myip xx acl ipxx myip xx
> 
> 
> 
> #######################################
> 
> tcp_outgoing_address xxxx ipxxx
> 
> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
> #####################################
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> squid -v
> 
> Squid Cache: Version 3.1.10
> 
> configure options:  '--build=i386-redhat-linux-gnu' 
> '--host=i386-redhat-linux-gnu' '--target=i686-redhat-linux-gnu' 
> '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr'
> '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc'
> '--datadir=/usr/share' '--includedir=/usr/include'
> '--libdir=/usr/lib' '--libexecdir=/usr/libexec' 
> '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' 
> '--infodir=/usr/share/info' '--enable-internal-dns' 
> '--disable-strict-error-checking' '--exec_prefix=/usr' 
> '--libexecdir=/usr/lib/squid' '--localstatedir=/var' 
> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
> '--with-logdir=$(localstatedir)/log/squid' 
> '--with-pidfile=$(localstatedir)/run/squid.pid' 
> '--disable-dependency-tracking' '--enable-arp-acl' 
> '--enable-follow-x-forwarded-for' 
> '--enable-auth=basic,digest,ntlm,negotiate' 
> '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain
>
> 
- -NTLM,SASL,DB,POP3,squid_radius_auth'
> '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' 
> '--enable-digest-auth-helpers=password,ldap,eDirectory' 
> '--enable-negotiate-auth-helpers=squid_kerb_auth' 
> '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_
>
> 
group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
> '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
> '--enable-ident-lookups' '--with-large-files'
> '--enable-linux-netfilter' '--enable-referer-log'
> '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl'
> '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log' 
> '--enable-wccpv2' '--enable-esi' '--with-aio'
> '--with-default-user=squid' '--with-filedescriptors=16384'
> '--with-dl' '--with-openssl' '--with-pthreads'
> 'build_alias=i386-redhat-linux-gnu' 
> 'host_alias=i386-redhat-linux-gnu'
> 'target_alias=i686-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
> --param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom 
> -fasynchronous-unwind-tables -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g
> -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
> --param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom 
> -fasynchronous-unwind-tables -fpie' 
> --with-squid=/builddir/build/BUILD/squid-3.1.10
> 
> 
> 
> 
> 
> cheers
> 
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU51WNAAoJENNXIZxhPexGt2EIAKkQ9qSo2UJ+hc9bz0vLB9aK
FDpA84Y5vh7wu/a1srHjt35CWGTQw1kSHo4C74ibDtdoNMts9BNY6CLGhn/V2u/o
FWHk772XPrAPSIlVrdM5sFBoaZhuzGF4mKH5+isAKGae/+LeDkCgx8ud87YVGq9s
AfnblhnkTKZM1O2kgljTjIUV1T/YyAB2kI6KnzX67JVez8FSmKarZnFlIyoWd8OE
VXCR0xaGYnQfMjOlnzU4LHvNKirHl+YvhU2PFCva1zFWI621DpbZ6wg6jvencJvy
iWxan/yysp8pt7OyxpOeomsnqmetLayIFB9HfqzSxn7JcNFtUIcr3p8B+9E9DaE=
=l5Wh
-----END PGP SIGNATURE-----


From jborrell at central.aplitec.com  Fri Feb 20 15:50:35 2015
From: jborrell at central.aplitec.com (Josep Borrell)
Date: Fri, 20 Feb 2015 15:50:35 +0000
Subject: [squid-users] derive HTTP/HTTPS upload traffic to a secondary
 interface.
In-Reply-To: <54D48588.7030301@treenet.co.nz>
References: <42DE25A255671C44A93A7B58470DC09C5E2F7C6F@Michelle.aplitec.local>
 <54D48588.7030301@treenet.co.nz>
Message-ID: <42DE25A255671C44A93A7B58470DC09C5EAA55BF@Michelle.aplitec.local>

Hi Amos,

I tried your suggestion and even if the acl is matched the outgoing IP is not changed.
How to know why ?
Working with squid 3.5.1. 
Original IP 192.168.111.10 must be changed for 192.168.111.20

Thanks

Josep


Squid.conf:

debug_options ALL,1 33,2 28,9 11,3


#HTTPS (SSL) trafic interception options
sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/spool/squid3_ssldb -M 4MB
sslcrtd_children 8 startup=1 idle=1

acl disable-ssl-bump dstdomain -i "/etc/squid3/no-ssl-bump.acl"
acl step1 at_step SSLBump1
acl step2 at_step SSLBump2
acl step3 at_step SSLBump3

ssl_bump peek step1 all
ssl_bump splice step2 disable-ssl-bump
ssl_bump stare step2 all
ssl_bump splice step3 disable-ssl-bump
ssl_bump bump step3 all


acl UPLOAD method PUT
acl UPLOAD method POST
tcp_outgoing_address 192.168.111.20 UPLOAD


http_access allow all

http_port 3128
http_port 8080 intercept
https_port 8081 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squidcert.pem

forward_max_tries 25
cache_mem 2 GB
maximum_object_size_in_memory 25 MB
maximum_object_size 1 GB

visible_hostname squid-v2

workers 3

coredump_dir /var/spool/squid3
cache_replacement_policy heap LFUDA
cache_dir rock /var/spool/squid3/cache1 4000 max-size=500
cache_dir aufs /var/spool/squid3/cache2 10000 16 256

refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 10080
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 80% 10080


# FortiGate interface of wccp
wccp2_router 192.168.111.1
# wccp version 2 configuration
wccp2_service standard 90
# tunneling method GRE for forward traffic
wccp2_forwarding_method gre
# tunneling method GRE for return traffic
wccp2_return_method gre
# which interface to use for WCCP (0.0.0.0 determines the interface from routing)
wccp2_address 0.0.0.0




Debug sample:
----------
2015/02/20 16:27:22.879| Checklist.cc(68) preCheck: 0x7fe877ccc7c8 checking slow rules
2015/02/20 16:27:22.879| Acl.cc(138) matches: checking http_access
2015/02/20 16:27:22.879| Acl.cc(138) matches: checking http_access#1
2015/02/20 16:27:22.879| Acl.cc(138) matches: checking all
2015/02/20 16:27:22.879| Ip.cc(107) aclIpAddrNetworkCompare: aclIpAddrNetworkCompare: compare: 192.168.1.100:1887/[::] ([::]:1887)  vs [::]-[::]/[::]
2015/02/20 16:27:22.879| Ip.cc(538) match: aclIpMatchIp: '192.168.1.100:1887' found
2015/02/20 16:27:22.879| Acl.cc(158) matches: checked: all = 1
2015/02/20 16:27:22.879| Acl.cc(158) matches: checked: http_access#1 = 1
2015/02/20 16:27:22.879| Acl.cc(158) matches: checked: http_access = 1
2015/02/20 16:27:22.880| Checklist.cc(61) markFinished: 0x7fe877ccc7c8 answer ALLOWED for match
2015/02/20 16:27:22.880| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x7fe877ccc7c8 answer=ALLOWED
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21ee80
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21ee80
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21ee80
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21ee80
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21e540
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21e540
2015/02/20 16:27:22.880| Checklist.cc(68) preCheck: 0x7fff7a21e540 checking fast ACLs
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking tcp_outgoing_address 192.168.111.20
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking (tcp_outgoing_address 192.168.111.20 line)
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking UPLOAD
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: UPLOAD = 1
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: (tcp_outgoing_address 192.168.111.20 line) = 1
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: tcp_outgoing_address 192.168.111.20 = 1
2015/02/20 16:27:22.880| Checklist.cc(61) markFinished: 0x7fff7a21e540 answer ALLOWED for match
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21e540
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21e540
2015/02/20 16:27:22.880| Checklist.cc(68) preCheck: 0x7fff7a21e460 checking fast ACLs
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking tcp_outgoing_address 192.168.111.20
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking (tcp_outgoing_address 192.168.111.20 line)
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking UPLOAD
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: UPLOAD = 1
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: (tcp_outgoing_address 192.168.111.20 line) = 1
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: tcp_outgoing_address 192.168.111.20 = 1
2015/02/20 16:27:22.880| Checklist.cc(61) markFinished: 0x7fff7a21e460 answer ALLOWED for match
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21e460
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21e460
2015/02/20 16:27:22.880| http.cc(2261) httpStart: POST https://drive.google.com/stat
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fe877ccc7c8
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fe877ccc7c8
2015/02/20 16:27:22| Error sending to ICMPv6 packet to [2a00:1450:4003:805::200e]. ERR: (101) Network is unreachable
2015/02/20 16:27:22.880| Client.cc(232) startRequestBodyFlow: expecting request body from  [0<=274<=274 274+1773 pipe0x7fe87814d198 cons0x7fe87814e688]
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21f390
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21f390
2015/02/20 16:27:22.881| http.cc(2217) sendRequest: HTTP Server local=192.168.111.10:53172 remote=216.58.211.238:443 FD 23 flags=1
2015/02/20 16:27:22.881| http.cc(2218) sendRequest: HTTP Server REQUEST:
---------
POST /stat HTTP/1.1
Host: drive.google.com
User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:35.0) Gecko/20100101 Firefox/35.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate
Content-control: no-cache
X-Same-Domain: explorer
X-Json-Requested: true
Content-Type: application/x-www-form-urlencoded;charset=utf-8
Referer: https://drive.google.com/?authuser=0
Content-Length: 274
Cookie: NID=67=Gm7vcswCbOO55hZsjfaz-pTurlVu7ExNrsoWfJDDcTg8rumGt-xCQD6RezS9pYZypbeHEAfm1bcWQwc82QCvsL6rL9lDcDeEtjaPKdHT0C885UB6wiWl9TY_nTI4d38_9ccpMqC5Q5jnGzRntaOaIjm_nfhe; SID=DQAAAPwAAABdqFewpHnz9c-jo5Z0nyI7av_uC-pbzCxPtnThJe_3zg4ska6$
Pragma: no-cache
Via: 1.1 squid-v2 (squid/3.5.1)
X-Forwarded-For: 192.168.1.100
Cache-Control: no-cache
Connection: keep-alive


----------








-----Mensaje original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] En nombre de Amos Jeffries
Enviado el: viernes, 06 de febrero de 2015 10:13
Para: squid-users at lists.squid-cache.org
Asunto: Re: [squid-users] derive HTTP/HTTPS upload traffic to a secondary interface.

On 6/02/2015 8:59 p.m., Josep Borrell wrote:
> Hi,
> 
> I have a squid box with two interfaces. One ADSL 20/1Mb and one SHDSL 4/4Mb.
> It is a school and they are working with Google Apps for Education.
> They do a lot of uploading and when using the ADSL, it collapses promptly.
> Is possible to derive only HTTP/HTTPS upload traffic to the SHDSL and continue surfing with the ADSL ?

In a roundabout way.

If you look at the OSI model of networking Squid is layers 4-7, and those interfaces are part of layer 1-2. There is a whole disconnect layer 3 in between (the TCP/IP layer).

What you can do in Squid is set one of the tcp_outgoing_address, tcp_outgoing_tos, tcp_outgoing_mark directives to label the TCP traffic out of Squid. The systems routing rules need to take that detail from TCP and decide which interface to use.



> Maybe using one acl with methods POST and UPLOAD and some routing magic ?

Somethign like this..

squid.conf:
 acl PUTPOST method PUT POST
 tcp_outgoing_address 192.0.2.1 PUTPOST

Where 192.0.2.1 is the IP address the system uses to send out SHDSDL.
You may need both an IPv4 and IPv6 outgoing address set using PUTPOST acl.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From max at principiumtech.com  Fri Feb 20 15:57:17 2015
From: max at principiumtech.com (maxt)
Date: Fri, 20 Feb 2015 07:57:17 -0800 (PST)
Subject: [squid-users] One Squid proxy for multi-tenant environment
Message-ID: <1424447837043-4669998.post@n4.nabble.com>

I'm just wondering if it is possible to do the following:

Have one Squid proxy that covers multiple domains/tenants.  Each tenant
would have their own specific whitelist and blacklist of sites.  Each tenant
would have their own customized/branded block page that would have
instructions for requesting a site be whitelisted.

I've looked a bit at ACL lists since that has been mentioned when trying to
filter different groups into different levels of blocking/access.  The
discussion I've read about these is in regard to different departments
within one domain.  

My experience with Squid in the past has been using it within a single
domain and it worked perfectly.  

Thanks in advance for your help!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/One-Squid-proxy-for-multi-tenant-environment-tp4669998.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Sat Feb 21 02:15:58 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Fri, 20 Feb 2015 18:15:58 -0800
Subject: [squid-users] many vms behind router to same proxy ips problems
	!
In-Reply-To: <54E7558E.7070704@gmail.com>
References: <008201d04d77$02fbd590$08f380b0$@netstream.ps>
 <54E7558E.7070704@gmail.com>
Message-ID: <008c01d04d7c$55ad0430$01070c90$@netstream.ps>

Not yet , I know ip routing :)


Also I searched but didn?t fins a useful thing about my issue

Can u guide more plz ?

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Friday, February 20, 2015 7:41 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] many vms behind router to same proxy ips problems !

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

This is not squid problem, man.

Did you hear about TCP routing?

This is the thing your need.

21.02.15 7:37, snakeeyes ?????:
> Hi ,
> 
> 
> 
> I have  squid  with many ips already installed with and configured 
> well with tcp_outgoing directive.
> 
> 
> 
> The provlem that I face is ;
> 
> When many pc behind a router with same public ip use the proxy ips.
> 
> 
> 
> Assume I have 2 pcs
> 
> Pc1===> Using proxy ip 1.1.1.1
> 
> Pc2===>using proxy 1.1.1.2
> 
> Note that 1.1.1.1 & 1.1.1.2 are just for example and we assume those 
> ips are existed on the main server squid.
> 
> 
> 
> Pc1 & pc2 ips are 192.168.1.100 & 192.168.1.101 and their public ip is 
> 31.220.243.0
> 
> 
> 
> 
> 
> I go to pc1 and type "whatismyipaddrss.com "  I see 1.1.1.1
> 
> 
> 
> Then I go to pc2 and type "whatismyipaddrss.com "  I see 2.2.2.2
> 
> Now lets go back to pc1 and refresh the page  whatismyipaddrss.com 
> ===?> then I see 2.2.2.2 not 1.1.1.1
> 
> 
> 
> This is my problem.
> 
> 
> 
> Why sometimes after somefrefresh I get the other ip not ip I put in in 
> browser ??
> 
> 
> 
> Could it because same pcs has same public ip ??
> 
> 
> 
> 
> 
> I tried to put por for each ip like 1.1.1.1:1333 and 2.2.2.2:1222 .... 
> but same resukt , the ip keep changes
> 
> 
> 
> Also I disabled cacing on squid but no luck .
> 
> 
> 
> Is that a natural thing ?
> 
> 
> 
> Or squid can be optimized ?
> 
> 
> 
> [root at dbmedia ~]# cat /etc/squid/squid.conf
> 
> # Lockdown Procedures
> 
> auth_param basic program /usr/lib/squid/ncsa_auth 
> /etc/squid/squid_passwd
> 
> acl ncsa_users proxy_auth REQUIRED
> 
> http_access allow ncsa_users
> 
> #
> 
> #
> 
> # Recommended minimum configuration:
> 
> #
> 
> acl manager proto cache_object
> 
> acl localhost src 127.0.0.1/32 ::1
> 
> acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
> 
> 
> 
> # Example rule allowing access from your local networks.
> 
> # Adapt to list your (internal) IP networks from where browsing
> 
> # should be allowed
> 
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal
> network
> 
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> 
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> 
> acl localnet src fc00::/7       # RFC 4193 local private network
> range
> 
> acl localnet src fe80::/10      # RFC 4291 link-local (directly
> plugged) machines
> 
> 
> 
> acl SSL_ports port 443
> 
> acl Safe_ports port 80          # http
> 
> acl Safe_ports port 21          # ftp
> 
> acl Safe_ports port 443         # https
> 
> acl Safe_ports port 70          # gopher
> 
> acl Safe_ports port 210         # wais
> 
> acl Safe_ports port 1025-65535  # unregistered ports
> 
> acl Safe_ports port 280         # http-mgmt
> 
> acl Safe_ports port 488         # gss-http
> 
> acl Safe_ports port 591         # filemaker
> 
> acl Safe_ports port 777         # multiling http
> 
> acl CONNECT method CONNECT
> 
> 
> 
> #
> 
> # Recommended minimum Access Permission configuration:
> 
> #
> 
> # Only allow cachemgr access from localhost
> 
> http_access allow manager localhost
> 
> http_access deny manager
> 
> 
> 
> # Deny requests to certain unsafe ports
> 
> http_access deny !Safe_ports
> 
> 
> 
> # Deny CONNECT to other than secure SSL ports
> 
> http_access deny CONNECT !SSL_ports
> 
> 
> 
> # We strongly recommend the following be uncommented to protect 
> innocent
> 
> # web applications running on the proxy server who think the only
> 
> # one who can access services on "localhost" is a local user
> 
> #http_access deny to_localhost
> 
> 
> 
> #
> 
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> 
> #
> 
> 
> 
> # Example rule allowing access from your local networks.
> 
> # Adapt localnet in the ACL section to list your (internal) IP 
> networks
> 
> # from where browsing should be allowed
> 
> http_access allow localnet
> 
> http_access allow localhost
> 
> 
> 
> # And finally deny all other access to this proxy
> 
> http_access deny all
> 
> 
> 
> # Squid normally listens to port 3128
> 
> http_port 1111
> 
> http_port xxx.27.65:1165
> 
> http_port xx.27.68:1168
> 
> # We recommend you to use at least the following line.
> 
> hierarchy_stoplist cgi-bin ?
> 
> 
> 
> # Uncomment and adjust the following to add a disk cache directory.
> 
> #cache_dir ufs /var/spool/squid 100 16 256
> 
> #cache_dir null
> 
> cache deny all
> 
> # Leave coredumps in the first cache dir
> 
> coredump_dir /var/spool/squid
> 
> 
> 
> # Add any of your own refresh_pattern entries above these.
> 
> refresh_pattern ^ftp:           1440    20%     10080
> 
> refresh_pattern ^gopher:        1440    0%      1440
> 
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> 
> refresh_pattern .               0       20%     4320
> 
> ###############################
> 
> forwarded_for off
> 
> request_header_access Allow allow all
> 
> request_header_access Authorization allow all
> 
> request_header_access WWW-Authenticate allow all
> 
> request_header_access Proxy-Authorization allow all
> 
> request_header_access Proxy-Authenticate allow all
> 
> request_header_access Cache-Control allow all
> 
> request_header_access Content-Encoding allow all
> 
> request_header_access Content-Length allow all
> 
> request_header_access Content-Type allow all
> 
> request_header_access Date allow all
> 
> request_header_access Expires allow all
> 
> request_header_access Host allow all
> 
> request_header_access If-Modified-Since allow all
> 
> request_header_access Last-Modified allow all
> 
> request_header_access Location allow all
> 
> request_header_access Pragma allow all
> 
> request_header_access Accept allow all
> 
> request_header_access Accept-Charset allow all
> 
> request_header_access Accept-Encoding allow all
> 
> request_header_access Accept-Language allow all
> 
> request_header_access Content-Language allow all
> 
> request_header_access Mime-Version allow all
> 
> request_header_access Retry-After allow all
> 
> request_header_access Title allow all
> 
> request_header_access Connection allow all
> 
> request_header_access Proxy-Connection allow all
> 
> request_header_access User-Agent allow all
> 
> request_header_access Cookie allow all
> 
> request_header_access X-Forwarded-For deny all
> 
> request_header_access Via deny all
> 
> request_header_access All allow all
> 
> ########################################
> 
> acl ipxx myip xx acl ipxx myip xx acl ipxx myip xx
> 
> 
> 
> #######################################
> 
> tcp_outgoing_address xxxx ipxxx
> 
> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
> #####################################
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> squid -v
> 
> Squid Cache: Version 3.1.10
> 
> configure options:  '--build=i386-redhat-linux-gnu' 
> '--host=i386-redhat-linux-gnu' '--target=i686-redhat-linux-gnu' 
> '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr'
> '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc'
> '--datadir=/usr/share' '--includedir=/usr/include'
> '--libdir=/usr/lib' '--libexecdir=/usr/libexec' 
> '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' 
> '--infodir=/usr/share/info' '--enable-internal-dns' 
> '--disable-strict-error-checking' '--exec_prefix=/usr' 
> '--libexecdir=/usr/lib/squid' '--localstatedir=/var' 
> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
> '--with-logdir=$(localstatedir)/log/squid' 
> '--with-pidfile=$(localstatedir)/run/squid.pid' 
> '--disable-dependency-tracking' '--enable-arp-acl' 
> '--enable-follow-x-forwarded-for' 
> '--enable-auth=basic,digest,ntlm,negotiate' 
> '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-
> domain
>
> 
- -NTLM,SASL,DB,POP3,squid_radius_auth'
> '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' 
> '--enable-digest-auth-helpers=password,ldap,eDirectory' 
> '--enable-negotiate-auth-helpers=squid_kerb_auth' 
> '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,w
> binfo_
>
> 
group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
> '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
> '--enable-ident-lookups' '--with-large-files'
> '--enable-linux-netfilter' '--enable-referer-log'
> '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl'
> '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log' 
> '--enable-wccpv2' '--enable-esi' '--with-aio'
> '--with-default-user=squid' '--with-filedescriptors=16384'
> '--with-dl' '--with-openssl' '--with-pthreads'
> 'build_alias=i386-redhat-linux-gnu' 
> 'host_alias=i386-redhat-linux-gnu'
> 'target_alias=i686-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
> --param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom 
> -fasynchronous-unwind-tables -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g 
> -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
> --param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom 
> -fasynchronous-unwind-tables -fpie'
> --with-squid=/builddir/build/BUILD/squid-3.1.10
> 
> 
> 
> 
> 
> cheers
> 
> 
> 
> 
> _______________________________________________ squid-users mailing 
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU51WNAAoJENNXIZxhPexGt2EIAKkQ9qSo2UJ+hc9bz0vLB9aK
FDpA84Y5vh7wu/a1srHjt35CWGTQw1kSHo4C74ibDtdoNMts9BNY6CLGhn/V2u/o
FWHk772XPrAPSIlVrdM5sFBoaZhuzGF4mKH5+isAKGae/+LeDkCgx8ud87YVGq9s
AfnblhnkTKZM1O2kgljTjIUV1T/YyAB2kI6KnzX67JVez8FSmKarZnFlIyoWd8OE
VXCR0xaGYnQfMjOlnzU4LHvNKirHl+YvhU2PFCva1zFWI621DpbZ6wg6jvencJvy
iWxan/yysp8pt7OyxpOeomsnqmetLayIFB9HfqzSxn7JcNFtUIcr3p8B+9E9DaE=
=l5Wh
-----END PGP SIGNATURE-----
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From hack.back at hotmail.com  Fri Feb 20 16:16:09 2015
From: hack.back at hotmail.com (HackXBack)
Date: Fri, 20 Feb 2015 08:16:09 -0800 (PST)
Subject: [squid-users] assertion failed: comm.cc:769:
	"Comm::IsConnOpen(conn)"
In-Reply-To: <1424377008695-4669964.post@n4.nabble.com>
References: <1424025171679-4669842.post@n4.nabble.com>
 <1424209440077-4669927.post@n4.nabble.com> <54E3F058.3040200@treenet.co.nz>
 <1424253241949-4669944.post@n4.nabble.com>
 <1424377008695-4669964.post@n4.nabble.com>
Message-ID: <1424448969719-4670000.post@n4.nabble.com>

root at dotspot:~# gdb /usr/sbin/squid  /var/spool/squid/cache/squid/core.3722
GNU gdb (GDB) 7.4.1-debian
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /usr/sbin/squid...done.
[New LWP 3722]
[New LWP 3823]
[New LWP 3819]
[New LWP 3829]
[New LWP 3822]
[New LWP 3825]
[New LWP 3833]
[New LWP 3824]
[New LWP 3820]
[New LWP 3821]
[New LWP 3826]
[New LWP 3827]
[New LWP 3837]
[New LWP 3834]
[New LWP 3828]
[New LWP 3844]
[New LWP 3849]
[New LWP 3830]
[New LWP 3848]
[New LWP 3843]
[New LWP 3845]
[New LWP 3832]
[New LWP 3835]
[New LWP 3839]
[New LWP 3841]
[New LWP 3838]
[New LWP 3850]
[New LWP 3831]
[New LWP 3840]
[New LWP 3847]
[New LWP 3842]
[New LWP 3846]
[New LWP 3836]

warning: Can't read pathname for load map: Input/output error.
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Core was generated by `(squid-1) -YC -f /etc/squid/squid.conf'.
Program terminated with signal 6, Aborted.
#0  0x00007f0290968165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
(gdb) backtrace
#0  0x00007f0290968165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f029096b3e0 in abort () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x000000000055b12f in xassert (msg=<optimized out>, file=<optimized
out>, line=<optimized out>) at debug.cc:566
#3  0x00000000006ade68 in commSetConnTimeout (conn=..., timeout=15,
callback=...) at comm.cc:769
#4  0x000000000052d6ca in ConnStateData::getSslContextDone
(this=this at entry=0xdce12938, sslContext=<optimized out>,
sslContext at entry=0x8356d700, isNew=isNew at entry=false) at client_side.cc:3997
#5  0x000000000052e230 in ConnStateData::getSslContextStart
(this=this at entry=0xdce12938) at client_side.cc:3907
#6  0x000000000052e849 in ConnStateData::httpsPeeked (this=0xdce12938,
serverConnection=...) at client_side.cc:4069
#7  0x00000000005961e8 in UnaryMemFunT<ConnStateData,
RefCount&lt;Comm::Connection>, RefCount<Comm::Connection> >::doDial
(this=0xd894afb0) at base/AsyncJobCalls.h:113
#8  0x000000000053adaa in JobDialer<ConnStateData>::dial (this=0xd894afb0,
call=...) at base/AsyncJobCalls.h:166
#9  0x00000000006a2b79 in AsyncCall::make (this=0xd894af80) at
AsyncCall.cc:32
#10 0x00000000006a67df in AsyncCallQueue::fireNext
(this=this at entry=0xcb5ae0) at AsyncCallQueue.cc:52
#11 0x00000000006a6b10 in AsyncCallQueue::fire (this=0xcb5ae0) at
AsyncCallQueue.cc:38
#12 0x000000000056c3bc in EventLoop::runOnce
(this=this at entry=0x7fff7e2cea40) at EventLoop.cc:135
#13 0x000000000056c548 in EventLoop::run (this=0x7fff7e2cea40) at
EventLoop.cc:99
#14 0x00000000005e3bea in SquidMain (argc=<optimized out>, argv=<optimized
out>) at main.cc:1528
#15 0x00000000004f231b in SquidMainSafe (argv=<optimized out>,
argc=<optimized out>) at main.cc:1260
#16 main (argc=<optimized out>, argv=<optimized out>) at main.cc:1252




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/assertion-failed-comm-cc-769-Comm-IsConnOpen-conn-tp4669842p4670000.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Fri Feb 20 16:17:44 2015
From: hack.back at hotmail.com (HackXBack)
Date: Fri, 20 Feb 2015 08:17:44 -0800 (PST)
Subject: [squid-users] assertion failed: comm.cc:769:
	"Comm::IsConnOpen(conn)"
In-Reply-To: <1424377008695-4669964.post@n4.nabble.com>
References: <1424025171679-4669842.post@n4.nabble.com>
 <1424209440077-4669927.post@n4.nabble.com> <54E3F058.3040200@treenet.co.nz>
 <1424253241949-4669944.post@n4.nabble.com>
 <1424377008695-4669964.post@n4.nabble.com>
Message-ID: <1424449064181-4670001.post@n4.nabble.com>

root at dotspot:~# gdb /usr/sbin/squid  /var/spool/squid/cache/squid/core.4434
GNU gdb (GDB) 7.4.1-debian
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /usr/sbin/squid...done.
[New LWP 4434]
[New LWP 4516]
[New LWP 4521]
[New LWP 4534]
[New LWP 4518]
[New LWP 4541]
[New LWP 4519]
[New LWP 4533]
[New LWP 4522]
[New LWP 4545]
[New LWP 4523]
[New LWP 4538]
[New LWP 4520]
[New LWP 4544]
[New LWP 4517]
[New LWP 4540]
[New LWP 4537]
[New LWP 4546]
[New LWP 4547]
[New LWP 4536]
[New LWP 4543]
[New LWP 4531]
[New LWP 4526]
[New LWP 4524]
[New LWP 4532]
[New LWP 4527]
[New LWP 4535]
[New LWP 4528]
[New LWP 4525]
[New LWP 4539]
[New LWP 4542]
[New LWP 4529]
[New LWP 4530]

warning: Can't read pathname for load map: Input/output error.
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Core was generated by `(squid-1) -YC -f /etc/squid/squid.conf'.
Program terminated with signal 6, Aborted.
#0  0x00007f656d67c165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
(gdb) backtrace
#0  0x00007f656d67c165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f656d67f3e0 in abort () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x000000000055b12f in xassert (msg=<optimized out>, file=<optimized
out>, line=<optimized out>) at debug.cc:566
#3  0x00000000006ade68 in commSetConnTimeout (conn=..., timeout=15,
callback=...) at comm.cc:769
#4  0x000000000052d6ca in ConnStateData::getSslContextDone
(this=this at entry=0x833e5598, sslContext=<optimized out>,
sslContext at entry=0x8cd0c110, isNew=isNew at entry=false) at client_side.cc:3997
#5  0x000000000052e230 in ConnStateData::getSslContextStart
(this=this at entry=0x833e5598) at client_side.cc:3907
#6  0x000000000052e849 in ConnStateData::httpsPeeked (this=0x833e5598,
serverConnection=...) at client_side.cc:4069
#7  0x00000000005961e8 in UnaryMemFunT<ConnStateData,
RefCount&lt;Comm::Connection>, RefCount<Comm::Connection> >::doDial
(this=0xac883b50) at base/AsyncJobCalls.h:113
#8  0x000000000053adaa in JobDialer<ConnStateData>::dial (this=0xac883b50,
call=...) at base/AsyncJobCalls.h:166
#9  0x00000000006a2b79 in AsyncCall::make (this=0xac883b20) at
AsyncCall.cc:32
#10 0x00000000006a67df in AsyncCallQueue::fireNext
(this=this at entry=0xd6e2d0) at AsyncCallQueue.cc:52
#11 0x00000000006a6b10 in AsyncCallQueue::fire (this=0xd6e2d0) at
AsyncCallQueue.cc:38
#12 0x000000000056c3bc in EventLoop::runOnce
(this=this at entry=0x7fff2c09e4c0) at EventLoop.cc:135
#13 0x000000000056c548 in EventLoop::run (this=0x7fff2c09e4c0) at
EventLoop.cc:99
#14 0x00000000005e3bea in SquidMain (argc=<optimized out>, argv=<optimized
out>) at main.cc:1528
#15 0x00000000004f231b in SquidMainSafe (argv=<optimized out>,
argc=<optimized out>) at main.cc:1260
#16 main (argc=<optimized out>, argv=<optimized out>) at main.cc:1252
(gdb)




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/assertion-failed-comm-cc-769-Comm-IsConnOpen-conn-tp4669842p4670001.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Feb 20 16:25:07 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 20 Feb 2015 22:25:07 +0600
Subject: [squid-users] many vms behind router to same proxy ips problems
 !
In-Reply-To: <008c01d04d7c$55ad0430$01070c90$@netstream.ps>
References: <008201d04d77$02fbd590$08f380b0$@netstream.ps>
 <54E7558E.7070704@gmail.com> <008c01d04d7c$55ad0430$01070c90$@netstream.ps>
Message-ID: <54E75FE3.2080500@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

You want well-known thing in operating systems world. In Solaris it
known as ip_strict_dst_multihoming.

It divides in some levels:

1. On OS IP-stack's level must be specified strict dst respondes. I'e,
when request comes from one NIC - respond must be from the same NIC.
2. External routers must have static routes for outgoing packets.
3. Service on server must have capability to bind listeners/responders
to specified NIC's.

Some years ago I've built the similar configuration with BIND DNS
server on server with two different NIC's binded on two different ISP
and supported two independent domain zones. :)

So, finally - your can dig on this direction (see above).

21.02.15 8:15, snakeeyes ?????:
> Not yet , I know ip routing :)
> 
> 
> Also I searched but didn?t fins a useful thing about my issue
> 
> Can u guide more plz ?
> 
> -----Original Message----- From: squid-users
> [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of
> Yuri Voinov Sent: Friday, February 20, 2015 7:41 AM To:
> squid-users at lists.squid-cache.org Subject: Re: [squid-users] many
> vms behind router to same proxy ips problems !
> 
> This is not squid problem, man.
> 
> Did you hear about TCP routing?
> 
> This is the thing your need.
> 
> 21.02.15 7:37, snakeeyes ?????:
>> Hi ,
> 
> 
> 
>> I have  squid  with many ips already installed with and
>> configured well with tcp_outgoing directive.
> 
> 
> 
>> The provlem that I face is ;
> 
>> When many pc behind a router with same public ip use the proxy
>> ips.
> 
> 
> 
>> Assume I have 2 pcs
> 
>> Pc1===> Using proxy ip 1.1.1.1
> 
>> Pc2===>using proxy 1.1.1.2
> 
>> Note that 1.1.1.1 & 1.1.1.2 are just for example and we assume
>> those ips are existed on the main server squid.
> 
> 
> 
>> Pc1 & pc2 ips are 192.168.1.100 & 192.168.1.101 and their public
>> ip is 31.220.243.0
> 
> 
> 
> 
> 
>> I go to pc1 and type "whatismyipaddrss.com "  I see 1.1.1.1
> 
> 
> 
>> Then I go to pc2 and type "whatismyipaddrss.com "  I see 2.2.2.2
> 
>> Now lets go back to pc1 and refresh the page
>> whatismyipaddrss.com ===?> then I see 2.2.2.2 not 1.1.1.1
> 
> 
> 
>> This is my problem.
> 
> 
> 
>> Why sometimes after somefrefresh I get the other ip not ip I put
>> in in browser ??
> 
> 
> 
>> Could it because same pcs has same public ip ??
> 
> 
> 
> 
> 
>> I tried to put por for each ip like 1.1.1.1:1333 and 2.2.2.2:1222
>> .... but same resukt , the ip keep changes
> 
> 
> 
>> Also I disabled cacing on squid but no luck .
> 
> 
> 
>> Is that a natural thing ?
> 
> 
> 
>> Or squid can be optimized ?
> 
> 
> 
>> [root at dbmedia ~]# cat /etc/squid/squid.conf
> 
>> # Lockdown Procedures
> 
>> auth_param basic program /usr/lib/squid/ncsa_auth 
>> /etc/squid/squid_passwd
> 
>> acl ncsa_users proxy_auth REQUIRED
> 
>> http_access allow ncsa_users
> 
>> #
> 
>> #
> 
>> # Recommended minimum configuration:
> 
>> #
> 
>> acl manager proto cache_object
> 
>> acl localhost src 127.0.0.1/32 ::1
> 
>> acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
> 
> 
> 
>> # Example rule allowing access from your local networks.
> 
>> # Adapt to list your (internal) IP networks from where browsing
> 
>> # should be allowed
> 
>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal 
>> network
> 
>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal
>> network
> 
>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal
>> network
> 
>> acl localnet src fc00::/7       # RFC 4193 local private network 
>> range
> 
>> acl localnet src fe80::/10      # RFC 4291 link-local (directly 
>> plugged) machines
> 
> 
> 
>> acl SSL_ports port 443
> 
>> acl Safe_ports port 80          # http
> 
>> acl Safe_ports port 21          # ftp
> 
>> acl Safe_ports port 443         # https
> 
>> acl Safe_ports port 70          # gopher
> 
>> acl Safe_ports port 210         # wais
> 
>> acl Safe_ports port 1025-65535  # unregistered ports
> 
>> acl Safe_ports port 280         # http-mgmt
> 
>> acl Safe_ports port 488         # gss-http
> 
>> acl Safe_ports port 591         # filemaker
> 
>> acl Safe_ports port 777         # multiling http
> 
>> acl CONNECT method CONNECT
> 
> 
> 
>> #
> 
>> # Recommended minimum Access Permission configuration:
> 
>> #
> 
>> # Only allow cachemgr access from localhost
> 
>> http_access allow manager localhost
> 
>> http_access deny manager
> 
> 
> 
>> # Deny requests to certain unsafe ports
> 
>> http_access deny !Safe_ports
> 
> 
> 
>> # Deny CONNECT to other than secure SSL ports
> 
>> http_access deny CONNECT !SSL_ports
> 
> 
> 
>> # We strongly recommend the following be uncommented to protect 
>> innocent
> 
>> # web applications running on the proxy server who think the
>> only
> 
>> # one who can access services on "localhost" is a local user
> 
>> #http_access deny to_localhost
> 
> 
> 
>> #
> 
>> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> 
>> #
> 
> 
> 
>> # Example rule allowing access from your local networks.
> 
>> # Adapt localnet in the ACL section to list your (internal) IP 
>> networks
> 
>> # from where browsing should be allowed
> 
>> http_access allow localnet
> 
>> http_access allow localhost
> 
> 
> 
>> # And finally deny all other access to this proxy
> 
>> http_access deny all
> 
> 
> 
>> # Squid normally listens to port 3128
> 
>> http_port 1111
> 
>> http_port xxx.27.65:1165
> 
>> http_port xx.27.68:1168
> 
>> # We recommend you to use at least the following line.
> 
>> hierarchy_stoplist cgi-bin ?
> 
> 
> 
>> # Uncomment and adjust the following to add a disk cache
>> directory.
> 
>> #cache_dir ufs /var/spool/squid 100 16 256
> 
>> #cache_dir null
> 
>> cache deny all
> 
>> # Leave coredumps in the first cache dir
> 
>> coredump_dir /var/spool/squid
> 
> 
> 
>> # Add any of your own refresh_pattern entries above these.
> 
>> refresh_pattern ^ftp:           1440    20%     10080
> 
>> refresh_pattern ^gopher:        1440    0%      1440
> 
>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> 
>> refresh_pattern .               0       20%     4320
> 
>> ###############################
> 
>> forwarded_for off
> 
>> request_header_access Allow allow all
> 
>> request_header_access Authorization allow all
> 
>> request_header_access WWW-Authenticate allow all
> 
>> request_header_access Proxy-Authorization allow all
> 
>> request_header_access Proxy-Authenticate allow all
> 
>> request_header_access Cache-Control allow all
> 
>> request_header_access Content-Encoding allow all
> 
>> request_header_access Content-Length allow all
> 
>> request_header_access Content-Type allow all
> 
>> request_header_access Date allow all
> 
>> request_header_access Expires allow all
> 
>> request_header_access Host allow all
> 
>> request_header_access If-Modified-Since allow all
> 
>> request_header_access Last-Modified allow all
> 
>> request_header_access Location allow all
> 
>> request_header_access Pragma allow all
> 
>> request_header_access Accept allow all
> 
>> request_header_access Accept-Charset allow all
> 
>> request_header_access Accept-Encoding allow all
> 
>> request_header_access Accept-Language allow all
> 
>> request_header_access Content-Language allow all
> 
>> request_header_access Mime-Version allow all
> 
>> request_header_access Retry-After allow all
> 
>> request_header_access Title allow all
> 
>> request_header_access Connection allow all
> 
>> request_header_access Proxy-Connection allow all
> 
>> request_header_access User-Agent allow all
> 
>> request_header_access Cookie allow all
> 
>> request_header_access X-Forwarded-For deny all
> 
>> request_header_access Via deny all
> 
>> request_header_access All allow all
> 
>> ########################################
> 
>> acl ipxx myip xx acl ipxx myip xx acl ipxx myip xx
> 
> 
> 
>> #######################################
> 
>> tcp_outgoing_address xxxx ipxxx
> 
>> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
>> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
>> tcp_outgoing_address xxxx ipxxx
> 
> 
> 
>> #####################################
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>> squid -v
> 
>> Squid Cache: Version 3.1.10
> 
>> configure options:  '--build=i386-redhat-linux-gnu' 
>> '--host=i386-redhat-linux-gnu' '--target=i686-redhat-linux-gnu' 
>> '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' 
>> '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' 
>> '--datadir=/usr/share' '--includedir=/usr/include' 
>> '--libdir=/usr/lib' '--libexecdir=/usr/libexec' 
>> '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' 
>> '--infodir=/usr/share/info' '--enable-internal-dns' 
>> '--disable-strict-error-checking' '--exec_prefix=/usr' 
>> '--libexecdir=/usr/lib/squid' '--localstatedir=/var' 
>> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
>> '--with-logdir=$(localstatedir)/log/squid' 
>> '--with-pidfile=$(localstatedir)/run/squid.pid' 
>> '--disable-dependency-tracking' '--enable-arp-acl' 
>> '--enable-follow-x-forwarded-for' 
>> '--enable-auth=basic,digest,ntlm,negotiate' 
>> '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-
>>
>> 
domain
> 
> 
> -NTLM,SASL,DB,POP3,squid_radius_auth'
>> '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' 
>> '--enable-digest-auth-helpers=password,ldap,eDirectory' 
>> '--enable-negotiate-auth-helpers=squid_kerb_auth' 
>> '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,w
>>
>> 
binfo_
> 
> 
> group' '--enable-cache-digests'
> '--enable-cachemgr-hostname=localhost'
>> '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
>> '--enable-ident-lookups' '--with-large-files' 
>> '--enable-linux-netfilter' '--enable-referer-log' 
>> '--enable-removal-policies=heap,lru' '--enable-snmp'
>> '--enable-ssl' '--enable-storeio=aufs,diskd,ufs'
>> '--enable-useragent-log' '--enable-wccpv2' '--enable-esi'
>> '--with-aio' '--with-default-user=squid'
>> '--with-filedescriptors=16384' '--with-dl' '--with-openssl'
>> '--with-pthreads' 'build_alias=i386-redhat-linux-gnu' 
>> 'host_alias=i386-redhat-linux-gnu' 
>> 'target_alias=i686-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
>> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
>> --param=ssp-buffer-size=4 -m32 -march=i686 -mtune=atom 
>> -fasynchronous-unwind-tables -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2
>> -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
>> -fstack-protector --param=ssp-buffer-size=4 -m32 -march=i686
>> -mtune=atom -fasynchronous-unwind-tables -fpie' 
>> --with-squid=/builddir/build/BUILD/squid-3.1.10
> 
> 
> 
> 
> 
>> cheers
> 
> 
> 
> 
>> _______________________________________________ squid-users
>> mailing list squid-users at lists.squid-cache.org 
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU51/jAAoJENNXIZxhPexGv3sH/3iTphx+a2qq1w1oP5FyqGaW
L/Xmsu+f/2TDQIF7lnUIQBh8W7yDSD9kW7H7ucT3HEGgJKlw7bll/PZPgqQsj1fR
Q3wn7bY7b6ez5hoHtswUmf6SktA8zG3eTOv0xOf7afOrjzI9jlm+v6MBVCZ4qJT7
wFsTDoFFxjNnSq3wA6k83bidA3kmY7SmCq+XjGw90GNlp4IYdFK94wz61lkgfB1+
pgE6tJNftZlD4Owf22wvn62xUMdDqlhYA72wK4lyopXTg4PtJUVIGXsZ5Lyo+yjT
4xPyIPrAJXqMGC8Miu+K9DUEXkHTZcce1EmACfm2NTlIo5cIxFSQoYsEqC5uQMg=
=O5ER
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Feb 20 23:55:56 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Feb 2015 12:55:56 +1300
Subject: [squid-users] One Squid proxy for multi-tenant environment
In-Reply-To: <1424447837043-4669998.post@n4.nabble.com>
References: <1424447837043-4669998.post@n4.nabble.com>
Message-ID: <54E7C98C.4050305@treenet.co.nz>

On 21/02/2015 4:57 a.m., maxt wrote:
> I'm just wondering if it is possible to do the following:
> 
> Have one Squid proxy that covers multiple domains/tenants.  Each tenant
> would have their own specific whitelist and blacklist of sites.  Each tenant
> would have their own customized/branded block page that would have
> instructions for requesting a site be whitelisted.

Sort of. We are partway there with SMP support. There are two easy-ish
ways it can be done:


1) 3.2+ SMP worker per tenant.

NP: There is still crossover with things like shared memory (if you
choose to leabve it enabled) and cachemgr reports.


Add this line to squid.conf between the "http_access CONNECT !SSL_ports"
and "http_access deny all" lines:

 include /etc/squid/client-${processs_number}.conf


All the client-specific configuration then goes in the numbered
client-N.conf files. You may need to shuffle things like the default
refresh_patterns around so they are below the include (so not overriding
the client settings).

There is still some crossover with settings that can only be set once
per proxy instance (PID file etc). Those need to be set in the main
squid.conf, which you can also use to set local network defaults
different from the hard coded ones, or override some client abilities.


2) 3.5+ named service per tenant

This is not really single-proxy but allows you to run separate
instances/services per-tenant from one installed Squid. It does not have
any of the crossover issues the above (which may be either Pro or Con
for your needs).

 In squid.conf put this:

   include /etc/squid/client-${service_name}.conf

Service name much only be alphanumeric characters.

Same caveats apply about shuffling things around within squid.conf so
they dont collide with the per-client settings.

 Run Squid using:

   squid -n <some_name> ...

Note that is a lower case 'n', upper case is very different.


HTH
Amos


From squid3 at treenet.co.nz  Sat Feb 21 00:16:16 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Feb 2015 13:16:16 +1300
Subject: [squid-users] many vms behind router to same proxy ips problems
 !
In-Reply-To: <008201d04d77$02fbd590$08f380b0$@netstream.ps>
References: <008201d04d77$02fbd590$08f380b0$@netstream.ps>
Message-ID: <54E7CE50.4000107@treenet.co.nz>

On 21/02/2015 2:37 p.m., snakeeyes wrote:
> Hi ,
> 
>  
> 
> I have  squid  with many ips already installed with and configured well with
> tcp_outgoing directive.
> 

You have two problems:


1) Your Squid version is too old.


Squid-3.1 does not contain the IPv6 split-stack bug fixes that allow
tcp_outgoing_address to deal with persistent connections to servers, or
to select an outgoing IP per-message.



2) "myip" ACL ties the tcp_outgoing_address to the *Squid* receiving IP
address, not the client IP.

If the packets just happen to go from PC2 to the Squid receiving IP for
client1 for any reason they will use client1's assigned outgoing IP.


You require Squid-3.3 or later to do what you are attempting.

Amos



From alanpalmer72 at yahoo.com  Sat Feb 21 13:03:37 2015
From: alanpalmer72 at yahoo.com (Alan Palmer)
Date: Sat, 21 Feb 2015 08:03:37 -0500
Subject: [squid-users] squid 3.5.2 compile error on openbsd5.6
Message-ID: <54E88229.2080909@yahoo.com>

So I get the following error building squid 3.5.2 on openbsd 5.6-release

libtool: compile:  c++ -DHAVE_CONFIG_H -I../.. -I../../include 
-I../../lib -I../
../src -I../../include -I/usr/local/include -I/usr/local/include -Wall 
-Wpointer
-arith -Wwrite-strings -Wcomments -Wshadow -pipe -D_REENTRANT 
-I/usr/include -I/
usr/local/include -I/usr/local/include/p11-kit-1 -I/usr/include -O2 
-pipe -MT bi
o.lo -MD -MP -MF .deps/bio.Tpo -c bio.cc  -fPIC -DPIC -o .libs/bio.o
bio.cc: In function 'bool adjustSSL(SSL*, Ssl::Bio::sslFeatures&)':
bio.cc:328: error: 'struct ssl_ctx_st' has no member named 'comp_methods'
bio.cc: In member function 'bool Ssl::Bio::sslFeatures::get(const SSL*)':
bio.cc:672: error: 'struct ssl_session_st' has no member named 
'compress_meth'
bio.cc:673: error: 'struct ssl_session_st' has no member named 
'compress_meth'
*** Error 1 in src/ssl (Makefile:894 'bio.lo')
*** Error 1 in src (Makefile:7126 'all-recursive')
*** Error 1 in src (Makefile:5989 'all')
*** Error 1 in /data/src/squid-3.5.2 (Makefile:592 'all-recursive')

details:
[apalmer]:/data/src/squid-3.5.2# uname -a
OpenBSD jarosz-fw 5.6 GENERIC.MP#299 i386
[apalmer]:/data/src/squid-3.5.2# gcc -v
Reading specs from /usr/lib/gcc-lib/i386-unknown-openbsd5.6/4.2.1/specs
Target: i386-unknown-openbsd5.6
Configured with: OpenBSD/i386 system compiler
Thread model: posix
gcc version 4.2.1 20070719

  $ ./configure --disable-strict-error-checking --disable-arch-native 
--enable-shared --datadir=/usr/local/share/squid 
--libexecdir=/usr/local/libexec/squid --disable-loadable-modules 
--enable-arp-acl --enable-auth --enable-delay-pools 
--enable-follow-x-forwarded-for --enable-forw-via-db 
--enable-http-violations --enable-icap-client --enable-ipv6 
--enable-referer-log --enable-removal-policies=lru heap --enable-ssl 
--with-openssl --enable-storeio=aufs ufs diskd 
--with-default-user=_squid --with-filedescriptors=8192 
--with-krb5-config=no --with-pidfile=/var/run/squid.pid --with-pthreads 
--with-swapdir=/var/squid/cache --disable-pf-transparent 
--enable-ipfw-transparent --enable-external-acl-helpers=LDAP_group 
SQL_session file_userip time_quota session  unix_group wbinfo_group 
LDAP_group eDirectory_userip --prefix=/usr/local --sysconfdir=/etc/squid 
--mandir=/usr/local/man --infodir=/usr/local/info 
--localstatedir=/var/squid --disable-silent-rules CC=cc CFLAGS=-O2 -pipe 
LDFLAGS=-L/usr/local/lib CPPFLAGS=-I/usr/local/include CXX=c++ 
CXXFLAGS=-O2 -pipe --enable-ssl-crtd --enable-ltdl-convenience

I borrowed the configure options from squid-v of the squid 3.4 binary 
packages from openbsd.  Did I throw ina bad configure option?

Alan



From squid3 at treenet.co.nz  Sat Feb 21 14:27:26 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 22 Feb 2015 03:27:26 +1300
Subject: [squid-users] squid 3.5.2 compile error on openbsd5.6
In-Reply-To: <54E88229.2080909@yahoo.com>
References: <54E88229.2080909@yahoo.com>
Message-ID: <54E895CE.70105@treenet.co.nz>

On 22/02/2015 2:03 a.m., Alan Palmer wrote:
> So I get the following error building squid 3.5.2 on openbsd 5.6-release
> 
> libtool: compile:  c++ -DHAVE_CONFIG_H -I../.. -I../../include
> -I../../lib -I../
> ../src -I../../include -I/usr/local/include -I/usr/local/include -Wall
> -Wpointer
> -arith -Wwrite-strings -Wcomments -Wshadow -pipe -D_REENTRANT
> -I/usr/include -I/
> usr/local/include -I/usr/local/include/p11-kit-1 -I/usr/include -O2
> -pipe -MT bi
> o.lo -MD -MP -MF .deps/bio.Tpo -c bio.cc  -fPIC -DPIC -o .libs/bio.o
> bio.cc: In function 'bool adjustSSL(SSL*, Ssl::Bio::sslFeatures&)':
> bio.cc:328: error: 'struct ssl_ctx_st' has no member named 'comp_methods'
> bio.cc: In member function 'bool Ssl::Bio::sslFeatures::get(const SSL*)':
> bio.cc:672: error: 'struct ssl_session_st' has no member named
> 'compress_meth'
> bio.cc:673: error: 'struct ssl_session_st' has no member named
> 'compress_meth'
> *** Error 1 in src/ssl (Makefile:894 'bio.lo')
> *** Error 1 in src (Makefile:7126 'all-recursive')
> *** Error 1 in src (Makefile:5989 'all')
> *** Error 1 in /data/src/squid-3.5.2 (Makefile:592 'all-recursive')
> 
> details:
> [apalmer]:/data/src/squid-3.5.2# uname -a
> OpenBSD jarosz-fw 5.6 GENERIC.MP#299 i386
> [apalmer]:/data/src/squid-3.5.2# gcc -v
> Reading specs from /usr/lib/gcc-lib/i386-unknown-openbsd5.6/4.2.1/specs
> Target: i386-unknown-openbsd5.6
> Configured with: OpenBSD/i386 system compiler
> Thread model: posix
> gcc version 4.2.1 20070719


What version of OpenSSL are you building against?

> 
>  $ ./configure --disable-strict-error-checking --disable-arch-native
> --enable-shared --datadir=/usr/local/share/squid
> --libexecdir=/usr/local/libexec/squid --disable-loadable-modules
> --enable-arp-acl --enable-auth --enable-delay-pools
> --enable-follow-x-forwarded-for --enable-forw-via-db
> --enable-http-violations --enable-icap-client --enable-ipv6
> --enable-referer-log --enable-removal-policies=lru heap --enable-ssl
> --with-openssl --enable-storeio=aufs ufs diskd
> --with-default-user=_squid --with-filedescriptors=8192
> --with-krb5-config=no --with-pidfile=/var/run/squid.pid --with-pthreads
> --with-swapdir=/var/squid/cache --disable-pf-transparent
> --enable-ipfw-transparent --enable-external-acl-helpers=LDAP_group
> SQL_session file_userip time_quota session  unix_group wbinfo_group
> LDAP_group eDirectory_userip --prefix=/usr/local --sysconfdir=/etc/squid
> --mandir=/usr/local/man --infodir=/usr/local/info
> --localstatedir=/var/squid --disable-silent-rules CC=cc CFLAGS=-O2 -pipe
> LDFLAGS=-L/usr/local/lib CPPFLAGS=-I/usr/local/include CXX=c++
> CXXFLAGS=-O2 -pipe --enable-ssl-crtd --enable-ltdl-convenience
> 
> I borrowed the configure options from squid-v of the squid 3.4 binary
> packages from openbsd.  Did I throw ina bad configure option?

The configure options are missing quotation marks around these options
parameters:

 --enable-removal-policies="lru heap"
 --enable-storeio="aufs ufs diskd"
 --enable-external-acl-helpers="LDAP_group SQL_session file_userip
time_quota session  unix_group wbinfo_group LDAP_group eDirectory_userip"
 CFLAGS="-O2 -pipe"
 CXXFLAGS="-O2 -pipe"

These options are useless. All they do is turn ON features which are
default-ON anyway:

 --enable-auth
 --enable-http-violations
 --enable-ipv6
 --enable-icap-client


These options are obsolete:

 --enable-arp-acl
 --enable-referer-log
 --enable-ssl
 --with-krb5-config=no

Amos


From alanpalmer72 at yahoo.com  Sat Feb 21 15:00:20 2015
From: alanpalmer72 at yahoo.com (Alan Palmer)
Date: Sat, 21 Feb 2015 10:00:20 -0500
Subject: [squid-users] squid 3.5.2 compile error on openbsd5.6
In-Reply-To: <54E895CE.70105@treenet.co.nz>
References: <54E88229.2080909@yahoo.com> <54E895CE.70105@treenet.co.nz>
Message-ID: <563846CF-041C-417F-94C3-1D8542751995@yahoo.com>

[apalmer]:/data/src/squid-3.5.2# openssl version
LibreSSL 2.0

Alan Palmer
DO NOT SPAM

> On Feb 21, 2015, at 09:27, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 22/02/2015 2:03 a.m., Alan Palmer wrote:
>> So I get the following error building squid 3.5.2 on openbsd 5.6-release
>> 
>> libtool: compile:  c++ -DHAVE_CONFIG_H -I../.. -I../../include
>> -I../../lib -I../
>> ../src -I../../include -I/usr/local/include -I/usr/local/include -Wall
>> -Wpointer
>> -arith -Wwrite-strings -Wcomments -Wshadow -pipe -D_REENTRANT
>> -I/usr/include -I/
>> usr/local/include -I/usr/local/include/p11-kit-1 -I/usr/include -O2
>> -pipe -MT bi
>> o.lo -MD -MP -MF .deps/bio.Tpo -c bio.cc  -fPIC -DPIC -o .libs/bio.o
>> bio.cc: In function 'bool adjustSSL(SSL*, Ssl::Bio::sslFeatures&)':
>> bio.cc:328: error: 'struct ssl_ctx_st' has no member named 'comp_methods'
>> bio.cc: In member function 'bool Ssl::Bio::sslFeatures::get(const SSL*)':
>> bio.cc:672: error: 'struct ssl_session_st' has no member named
>> 'compress_meth'
>> bio.cc:673: error: 'struct ssl_session_st' has no member named
>> 'compress_meth'
>> *** Error 1 in src/ssl (Makefile:894 'bio.lo')
>> *** Error 1 in src (Makefile:7126 'all-recursive')
>> *** Error 1 in src (Makefile:5989 'all')
>> *** Error 1 in /data/src/squid-3.5.2 (Makefile:592 'all-recursive')
>> 
>> details:
>> [apalmer]:/data/src/squid-3.5.2# uname -a
>> OpenBSD jarosz-fw 5.6 GENERIC.MP#299 i386
>> [apalmer]:/data/src/squid-3.5.2# gcc -v
>> Reading specs from /usr/lib/gcc-lib/i386-unknown-openbsd5.6/4.2.1/specs
>> Target: i386-unknown-openbsd5.6
>> Configured with: OpenBSD/i386 system compiler
>> Thread model: posix
>> gcc version 4.2.1 20070719
> 
> 
> What version of OpenSSL are you building against?
> 
>> 
>> $ ./configure --disable-strict-error-checking --disable-arch-native
>> --enable-shared --datadir=/usr/local/share/squid
>> --libexecdir=/usr/local/libexec/squid --disable-loadable-modules
>> --enable-arp-acl --enable-auth --enable-delay-pools
>> --enable-follow-x-forwarded-for --enable-forw-via-db
>> --enable-http-violations --enable-icap-client --enable-ipv6
>> --enable-referer-log --enable-removal-policies=lru heap --enable-ssl
>> --with-openssl --enable-storeio=aufs ufs diskd
>> --with-default-user=_squid --with-filedescriptors=8192
>> --with-krb5-config=no --with-pidfile=/var/run/squid.pid --with-pthreads
>> --with-swapdir=/var/squid/cache --disable-pf-transparent
>> --enable-ipfw-transparent --enable-external-acl-helpers=LDAP_group
>> SQL_session file_userip time_quota session  unix_group wbinfo_group
>> LDAP_group eDirectory_userip --prefix=/usr/local --sysconfdir=/etc/squid
>> --mandir=/usr/local/man --infodir=/usr/local/info
>> --localstatedir=/var/squid --disable-silent-rules CC=cc CFLAGS=-O2 -pipe
>> LDFLAGS=-L/usr/local/lib CPPFLAGS=-I/usr/local/include CXX=c++
>> CXXFLAGS=-O2 -pipe --enable-ssl-crtd --enable-ltdl-convenience
>> 
>> I borrowed the configure options from squid-v of the squid 3.4 binary
>> packages from openbsd.  Did I throw ina bad configure option?
> 
> The configure options are missing quotation marks around these options
> parameters:
> 
> --enable-removal-policies="lru heap"
> --enable-storeio="aufs ufs diskd"
> --enable-external-acl-helpers="LDAP_group SQL_session file_userip
> time_quota session  unix_group wbinfo_group LDAP_group eDirectory_userip"
> CFLAGS="-O2 -pipe"
> CXXFLAGS="-O2 -pipe"
> 
> These options are useless. All they do is turn ON features which are
> default-ON anyway:
> 
> --enable-auth
> --enable-http-violations
> --enable-ipv6
> --enable-icap-client
> 
> 
> These options are obsolete:
> 
> --enable-arp-acl
> --enable-referer-log
> --enable-ssl
> --with-krb5-config=no
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From eliezer at ngtech.co.il  Sun Feb 22 00:31:24 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 22 Feb 2015 02:31:24 +0200
Subject: [squid-users] squid 3.5.2 compile error on openbsd5.6
In-Reply-To: <563846CF-041C-417F-94C3-1D8542751995@yahoo.com>
References: <54E88229.2080909@yahoo.com> <54E895CE.70105@treenet.co.nz>
 <563846CF-041C-417F-94C3-1D8542751995@yahoo.com>
Message-ID: <54E9235C.4020606@ngtech.co.il>

Hey Alan,

I am unsure but is this SSL library headers files are compatible with 
OpenSSL or it would require some existing OpenSSL APIs calls changes?

Eliezer

On 21/02/2015 17:00, Alan Palmer wrote:
> [apalmer]:/data/src/squid-3.5.2# openssl version
> LibreSSL 2.0
>
> Alan Palmer
> DO NOT SPAM




From eliezer at ngtech.co.il  Sun Feb 22 00:37:03 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 22 Feb 2015 02:37:03 +0200
Subject: [squid-users] One Squid proxy for multi-tenant environment
In-Reply-To: <1424447837043-4669998.post@n4.nabble.com>
References: <1424447837043-4669998.post@n4.nabble.com>
Message-ID: <54E924AF.5080602@ngtech.co.il>

Hey,

I have a question to consider the options.
What is the tenants special identity?
How do you distinguish each and every one of the clients?

Eliezer

On 20/02/2015 17:57, maxt wrote:
> I'm just wondering if it is possible to do the following:
>
> Have one Squid proxy that covers multiple domains/tenants.  Each tenant
> would have their own specific whitelist and blacklist of sites.  Each tenant
> would have their own customized/branded block page that would have
> instructions for requesting a site be whitelisted.





From max at principiumtech.com  Sun Feb 22 00:47:58 2015
From: max at principiumtech.com (maxt)
Date: Sat, 21 Feb 2015 16:47:58 -0800 (PST)
Subject: [squid-users] One Squid proxy for multi-tenant environment
In-Reply-To: <54E924AF.5080602@ngtech.co.il>
References: <1424447837043-4669998.post@n4.nabble.com>
 <54E924AF.5080602@ngtech.co.il>
Message-ID: <1424566078707-4670010.post@n4.nabble.com>

Amos -- Thanks for the quick reply.  I will look into the configuration.

Each tenant has a unique domain that has a trust relationship with our
management domain.  They also have a unique IP address range so there is no
need for VLANS.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/One-Squid-proxy-for-multi-tenant-environment-tp4669998p4670010.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun Feb 22 01:02:28 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 22 Feb 2015 14:02:28 +1300
Subject: [squid-users] squid 3.5.2 compile error on openbsd5.6
In-Reply-To: <54E9235C.4020606@ngtech.co.il>
References: <54E88229.2080909@yahoo.com> <54E895CE.70105@treenet.co.nz>
 <563846CF-041C-417F-94C3-1D8542751995@yahoo.com>
 <54E9235C.4020606@ngtech.co.il>
Message-ID: <54E92AA4.6000007@treenet.co.nz>

On 22/02/2015 1:31 p.m., Eliezer Croitoru wrote:
> Hey Alan,
> 
> I am unsure but is this SSL library headers files are compatible with
> OpenSSL or it would require some existing OpenSSL APIs calls changes?
> 
> Eliezer
> 
> On 21/02/2015 17:00, Alan Palmer wrote:
>> [apalmer]:/data/src/squid-3.5.2# openssl version
>> LibreSSL 2.0
>>

LibreSSL should be compatible, but they have been purging a lot of
unsafe or obsolete API. Give that SSL/TLS compression is a security
vulnerability I can imagine quiet easily that it walked into the firing
line and got dropped now.

This is probably a good sign that its time for a separate
--with-libressl option.

Alan, would you be interested in helping to test that?

Amos



From alanpalmer72 at yahoo.com  Sun Feb 22 01:05:06 2015
From: alanpalmer72 at yahoo.com (Alan Palmer)
Date: Sat, 21 Feb 2015 20:05:06 -0500
Subject: [squid-users] squid 3.5.2 compile error on openbsd5.6
In-Reply-To: <54E92AA4.6000007@treenet.co.nz>
References: <54E88229.2080909@yahoo.com> <54E895CE.70105@treenet.co.nz>
 <563846CF-041C-417F-94C3-1D8542751995@yahoo.com>
 <54E9235C.4020606@ngtech.co.il> <54E92AA4.6000007@treenet.co.nz>
Message-ID: <ABBECAC2-2E80-4865-9CDE-9FAAF069A905@yahoo.com>

Surely


Alan Palmer
DO NOT SPAM

> On Feb 21, 2015, at 20:02, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 22/02/2015 1:31 p.m., Eliezer Croitoru wrote:
>> Hey Alan,
>> 
>> I am unsure but is this SSL library headers files are compatible with
>> OpenSSL or it would require some existing OpenSSL APIs calls changes?
>> 
>> Eliezer
>> 
>>> On 21/02/2015 17:00, Alan Palmer wrote:
>>> [apalmer]:/data/src/squid-3.5.2# openssl version
>>> LibreSSL 2.0
> 
> LibreSSL should be compatible, but they have been purging a lot of
> unsafe or obsolete API. Give that SSL/TLS compression is a security
> vulnerability I can imagine quiet easily that it walked into the firing
> line and got dropped now.
> 
> This is probably a good sign that its time for a separate
> --with-libressl option.
> 
> Alan, would you be interested in helping to test that?
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From eliezer at ngtech.co.il  Sun Feb 22 01:08:36 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 22 Feb 2015 03:08:36 +0200
Subject: [squid-users] One Squid proxy for multi-tenant environment
In-Reply-To: <1424566078707-4670010.post@n4.nabble.com>
References: <1424447837043-4669998.post@n4.nabble.com>
 <54E924AF.5080602@ngtech.co.il> <1424566078707-4670010.post@n4.nabble.com>
Message-ID: <54E92C14.9050604@ngtech.co.il>

On 22/02/2015 02:47, maxt wrote:
> Each tenant has a unique domain that has a trust relationship with our
> management domain.  They also have a unique IP address range so there is no
> need for VLANS.

Hey Max,

You can use deny_info with a specific ip range or ip list and somehow 
make acls that will identify the uniqueness of the blacklist deny and 
whitelist allow.

I think that it is possible to do so without the need for any 
association between a client to a SMP worker unless you want to dedicate 
one complete CPU for each tenant.

All The Bests,
Eliezer



From david at articatech.com  Sun Feb 22 11:01:37 2015
From: david at articatech.com (David Touzeau)
Date: Sun, 22 Feb 2015 12:01:37 +0100
Subject: [squid-users] Need tips in order to force youtube in HTTP only
Message-ID: <54E9B711.8070304@articatech.com>

Hi the best...

We using Youtube For School by adding Headers in HTTP protocol
Since Youtube force everybody to use SSL, using Youtube For School 
trough squid is not possible.

Sure using ssl-bump can do the trick but dealing with certificates on 
students computers is very difficult.

Did anyone have found a tip in order to force using Youtube only in HTTP 
Mode ?


best regards


From vdoctor at neuf.fr  Sun Feb 22 11:23:19 2015
From: vdoctor at neuf.fr (Stakres)
Date: Sun, 22 Feb 2015 03:23:19 -0800 (PST)
Subject: [squid-users] Squid 2.7,
 3.4 and 3.5 Videos/Music/Images/Libraris/CDNs Booster
In-Reply-To: <1423553249913-4669653.post@n4.nabble.com>
References: <1418825003303-4668738.post@n4.nabble.com>
 <1419155198462-4668803.post@n4.nabble.com>
 <1420464046420-4668929.post@n4.nabble.com> <54AA918C.10300@gmail.com>
 <1420465642362-4668933.post@n4.nabble.com> <54AA979B.7060803@gmail.com>
 <1420470567538-4668941.post@n4.nabble.com>
 <1421655817441-4669159.post@n4.nabble.com>
 <1422466278065-4669395.post@n4.nabble.com>
 <1423553249913-4669653.post@n4.nabble.com>
Message-ID: <1424604199892-4670015.post@n4.nabble.com>

Hi All,

Advanced Caching Add-On for Linux Squid Proxy Cache v2.7, v3.4 and v3.5 with
Videos, Music, Images, Libraries and CDNs.

New  version 2.35 <https://sourceforge.net/projects/squidvideosbooster/>   -
February 22th 2015.
- New websites
More details on https://svb.unveiltech.com

Enjoy 

Bye Fred 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-3-4-and-3-5-Videos-Music-Images-Libraries-CDNs-Booster-tp4668683p4670015.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun Feb 22 11:56:38 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Feb 2015 00:56:38 +1300
Subject: [squid-users] Need tips in order to force youtube in HTTP only
In-Reply-To: <54E9B711.8070304@articatech.com>
References: <54E9B711.8070304@articatech.com>
Message-ID: <54E9C3F6.8090209@treenet.co.nz>

On 23/02/2015 12:01 a.m., David Touzeau wrote:
> Hi the best...
> 
> We using Youtube For School by adding Headers in HTTP protocol
> Since Youtube force everybody to use SSL, using Youtube For School
> trough squid is not possible.
> 
> Sure using ssl-bump can do the trick but dealing with certificates on
> students computers is very difficult.
> 
> Did anyone have found a tip in order to force using Youtube only in HTTP
> Mode ?

Other than SSL-Bump no.

The google page about forcing safesearch currently recommends hijacking
DNS. Which may also work for YouTube but its not clear.

I have a sneaking suspicion its possibly because I pointed out in IETF
that they were openly recommending SSL-Bump style HTTPS hijacking while
simultaneously going on a crusade against it. The page got changed
within a few weeks of that.

Amos



From richter at richtercloud.de  Sun Feb 22 12:19:43 2015
From: richter at richtercloud.de (Karl-Philipp Richter)
Date: Sun, 22 Feb 2015 12:19:43 +0000
Subject: [squid-users] Should `squid -k check` complain about presence of
 `ignore-no-cache` in 3.4.11
Message-ID: <4tue4by5d1vb.ma9n39-4br8tz9rhimk3m@api.elasticemail.com>

Hi,
According to
http://lists.squid-cache.org/pipermail/squid-users/2015-February/002323.html
the `ignore-no-cache` option is outdated. Shouldn't `squid -k check`
warn about its presence (I verified that the check works by adding `bla`
at the end of the config file with causes a warning `unrecognized:
'bla'`)? Currently the validation passes in 3.4.11 (on FreeBSD 9.3).

In case it should, is that a bug or a feature request?

Best regards,
Kalle

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 484 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150222/3a61274c/attachment.sig>

From vdoctor at neuf.fr  Sun Feb 22 12:54:29 2015
From: vdoctor at neuf.fr (Stakres)
Date: Sun, 22 Feb 2015 04:54:29 -0800 (PST)
Subject: [squid-users] Resolution Locker Plugin for Squid Proxy Cache 3.x
In-Reply-To: <1423725644117-4669749.post@n4.nabble.com>
References: <1422896192924-4669489.post@n4.nabble.com>
 <1423065493752-4669549.post@n4.nabble.com>
 <1423725644117-4669749.post@n4.nabble.com>
Message-ID: <1424609669952-4670018.post@n4.nabble.com>

Hi All,

New  build 2.07 <https://sourceforge.net/projects/youtuberesolutionlocker/> 
:
- YouTube
- Vevo
- Vimeo
- iMDB
- Dailymotion
- Break.com
- Apple Trailers

Ask your free 1 year license on the website 

Bye Fred 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Resolution-Locker-Plugin-for-Squid-Proxy-Cache-3-x-tp4669489p4670018.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From monahbaki at gmail.com  Sun Feb 22 14:06:12 2015
From: monahbaki at gmail.com (Monah Baki)
Date: Sun, 22 Feb 2015 09:06:12 -0500
Subject: [squid-users] squid 3.5.2 and MRTG
Message-ID: <CALP3=x8H1CrVX6FzW8fEOSeRhQWeWcz+e39Di0v1RXM+e0dnBQ@mail.gmail.com>

Hi all,

I need to monitor squid 3.5.2 using MRTG and can't seem to find any
examples on how to do that.

I found the following but nothing happens.Clueless on how to do this.

Thanks



Target[proxy-hit]: cacheHttpHits&cacheServerRequests:public at proxy.sg.private
:3401
# If you are using Squid 2.6 or later, uncomment the following line
#RouterName[proxy-hit]: cacheUniqName
MaxBytes[proxy-hit]: 100000
Title[proxy-hit]: HTTP Hits
PageTop[proxy-hit]: <H2>proxy Cache Statistics: HTTP Hits/Requests</H2>
 <TABLE>
   <TR><TD>System:</TD><TD>proxy.sg.private</TD></TR>
   <TR><TD>Maintainer:</TD><TD>Serassio Guido</TD></TR>
   <TR><TD>Description:</TD><TD>Squid Proxy server</TD></TR>
 </TABLE>
Suppress[proxy-hit]: y
LegendI[proxy-hit]:  HTTP hits
LegendO[proxy-hit]:  HTTP requests
Legend1[proxy-hit]:  HTTP hits
Legend2[proxy-hit]:  HTTP requests
YLegend[proxy-hit]: perminute
ShortLegend[proxy-hit]: req/min
Options[proxy-hit]: nopercent, perminute, dorelpercent, unknaszero
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150222/323c163f/attachment.htm>

From squid3 at treenet.co.nz  Sun Feb 22 14:58:00 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Feb 2015 03:58:00 +1300
Subject: [squid-users] Should `squid -k check` complain about presence
 of `ignore-no-cache` in 3.4.11
In-Reply-To: <4tue4by5d1vb.ma9n39-4br8tz9rhimk3m@api.elasticemail.com>
References: <4tue4by5d1vb.ma9n39-4br8tz9rhimk3m@api.elasticemail.com>
Message-ID: <54E9EE78.3030100@treenet.co.nz>

On 23/02/2015 1:19 a.m., Karl-Philipp Richter wrote:
> Hi,
> According to
> http://lists.squid-cache.org/pipermail/squid-users/2015-February/002323.html
> the `ignore-no-cache` option is outdated. Shouldn't `squid -k check`
> warn about its presence (I verified that the check works by adding `bla`
> at the end of the config file with causes a warning `unrecognized:
> 'bla'`)? Currently the validation passes in 3.4.11 (on FreeBSD 9.3).

Squid is capable of running with it present in the config. It just has
no meaning any more. So there is no reason to halt an otherwise usable
proxy.

If you run "squid -k parse" to verify the config it displays an UPGRADE
notice about it.

squid -k parse is better to use for verifying configurations. It will
continue past some types of FATAL and give you a better list of the
errors that exist, rather than just the first detected.

Amos


From squid3 at treenet.co.nz  Sun Feb 22 15:00:27 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Feb 2015 04:00:27 +1300
Subject: [squid-users] squid 3.5.2 and MRTG
In-Reply-To: <CALP3=x8H1CrVX6FzW8fEOSeRhQWeWcz+e39Di0v1RXM+e0dnBQ@mail.gmail.com>
References: <CALP3=x8H1CrVX6FzW8fEOSeRhQWeWcz+e39Di0v1RXM+e0dnBQ@mail.gmail.com>
Message-ID: <54E9EF0B.6030808@treenet.co.nz>

On 23/02/2015 3:06 a.m., Monah Baki wrote:
> Hi all,
> 
> I need to monitor squid 3.5.2 using MRTG and can't seem to find any
> examples on how to do that.
> 
> I found the following but nothing happens.Clueless on how to do this.


<http://wiki.squid-cache.org/Features/Snmp>


Amos


From stanford.prescott at yahoo.com  Sun Feb 22 17:46:05 2015
From: stanford.prescott at yahoo.com (Stanford Prescott)
Date: Sun, 22 Feb 2015 17:46:05 +0000 (UTC)
Subject: [squid-users] Compile errors Squid 3.5.2
Message-ID: <1890898106.6825940.1424627165497.JavaMail.yahoo@mail.yahoo.com>

When trying to compile Squid 3.5.2 the compile fails. The only error messages I can find are these:
"tar: ./usr/share/errors/zh-cn: Cannot create symlink to `zh-hans': File exists"
"tar: ./usr/share/errors/zh-cn: Cannot create symlink to `zh-hant': File exists"

A squid binary is produced but won't start when I replace the working squid 3.4.10 binary in my distribution (Smoothwall Express 3.1) with the 3.5.2 binary. I get this error message in the cache.log when trying to start squid 3.5.2.
"FATAL: Ipc::Mem::Segment::create failed to shm_open(/squid-cf__metadata.shm): (13) Permission denied"

I was not surprised that the Squid 3.5.2 binary would not start due to the compile errors, but I thought I would try anyway.
Does anyone have any idea what I might be doing wrong?
Thank you,
Stan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150222/55de401a/attachment.htm>

From nobody at snovc.com  Sun Feb 22 22:00:47 2015
From: nobody at snovc.com (Private Sender)
Date: Sun, 22 Feb 2015 14:00:47 -0800
Subject: [squid-users] assertion failed: client_side.h:364: "sslServerBump
	== srvBump"
Message-ID: <54EA518F.8040300@snovc.com>

Hello,

I keep getting this same error, regardless of what version of squid I'm
running (3.5.2 currently).

Anyone have any ideas?

Output from log:

2015/02/22 13:30:22 kid1| assertion failed: client_side.h:364:
"sslServerBump == srvBump"
2015/02/22 13:30:25 kid1| Set Current Directory to /var/spool/squid1
2015/02/22 13:30:25 kid1| Starting Squid Cache version 3.5.2 for
x86_64-unknown-linux-gnu...
2015/02/22 13:30:25 kid1| Service Name: squid
2015/02/22 13:30:25 kid1| Process ID 10158
2015/02/22 13:30:25 kid1| Process Roles: worker
2015/02/22 13:30:25 kid1| With 1024 file descriptors available
2015/02/22 13:30:25 kid1| Initializing IP Cache...
2015/02/22 13:30:26 kid1| DNS Socket created at 0.0.0.0, FD 6
2015/02/22 13:30:26 kid1| Adding nameserver 127.0.0.1 from squid.conf
2015/02/22 13:30:26 kid1| helperOpenServers: Starting 5/10 'ssl_crtd'
processes
2015/02/22 13:30:26 kid1| helperOpenServers: Starting 0/10 'squidGuard'
processes
2015/02/22 13:30:26 kid1| helperOpenServers: No 'squidGuard' processes
needed.
2015/02/22 13:30:26 kid1| Logfile: opening log /var/log/combo.log
2015/02/22 13:30:26 kid1| WARNING: log name now starts with a module
name. Use 'stdio:/var/log/combo.log'
2015/02/22 13:30:26 kid1| Unlinkd pipe opened on FD 23
2015/02/22 13:30:26 kid1| Store logging disabled
2015/02/22 13:30:26 kid1| Swap maxSize 2097152 + 2097152 KB, estimated
322638 objects
2015/02/22 13:30:26 kid1| Target number of buckets: 16131
2015/02/22 13:30:26 kid1| Using 16384 Store buckets
2015/02/22 13:30:26 kid1| Max Mem  size: 2097152 KB
2015/02/22 13:30:26 kid1| Max Swap size: 2097152 KB
2015/02/22 13:30:26 kid1| Rebuilding storage in /mnt/squid1 (dirty log)
2015/02/22 13:30:26 kid1| Using Least Load store dir selection
2015/02/22 13:30:26 kid1| Set Current Directory to /var/spool/squid1
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
2015/02/22 13:30:26 kid1| Finished loading MIME types and icons.
2015/02/22 13:30:26 kid1| HTCP Disabled.
2015/02/22 13:30:26 kid1| Pinger socket opened on FD 28
2015/02/22 13:30:26 kid1| Squid plugin modules loaded: 0
2015/02/22 13:30:26 kid1| Adaptation support is on
2015/02/22 13:30:26 kid1| Accepting NAT intercepted SSL bumped HTTPS
Socket connections at local=0.0.0.0:443 remote=[::] FD 26 flags=41
2015/02/22 13:30:26| pinger: Initialising ICMP pinger ...
2015/02/22 13:30:26|  icmp_sock: (1) Operation not permitted
2015/02/22 13:30:26| pinger: Unable to start ICMP pinger.
2015/02/22 13:30:26| FATAL: pinger: Unable to open any ICMP sockets.
2015/02/22 13:30:26 kid1| Done reading /mnt/squid1 swaplog (3374 entries)
2015/02/22 13:30:26 kid1| Finished rebuilding storage from disk.
2015/02/22 13:30:26 kid1|      3374 Entries scanned
2015/02/22 13:30:26 kid1|         0 Invalid entries.
2015/02/22 13:30:26 kid1|         0 With invalid flags.
2015/02/22 13:30:26 kid1|      3374 Objects loaded.
2015/02/22 13:30:26 kid1|         0 Objects expired.
2015/02/22 13:30:26 kid1|         0 Objects cancelled.
2015/02/22 13:30:26 kid1|         0 Duplicate URLs purged.
2015/02/22 13:30:26 kid1|         0 Swapfile clashes avoided.
2015/02/22 13:30:26 kid1|   Took 0.08 seconds (41055.72 objects/sec).
2015/02/22 13:30:26 kid1| Beginning Validation Procedure
2015/02/22 13:30:26 kid1|   Completed Validation Procedure
2015/02/22 13:30:26 kid1|   Validated 3374 Entries
2015/02/22 13:30:26 kid1|   store_swap_size = 54324.00 KB
2015/02/22 13:30:27 kid1| storeLateRelease: released 0 objects

Squid was built with these options:

root at squid:~/squid# squid -v
Squid Cache: Version 3.5.2
Service Name: squid
configure options:  '--enable-ssl' '--enable-ssl-crtd' '--enable-icmp'
'--enable-linux-netfilter' '--disable-ipv6' '--with-openssl'
'--with-large-files' '--prefix=/usr' '--localstatedir=/var'
'--libexecdir=/lib/squid' '--srcdir=.' '--datadir=/share/squid'
'--sysconfdir=/etc/squid' '--with-default-user=proxy'
'--with-logdir=/var/log' '--with-pidfile=/var/run/squid.pid'
'--enable-icap-client'

SSLBump works, the problem is this error seems to crash the daemon,
and forces a reload.

Any help would be appreciated. Thanks


From nobody at snovc.com  Sun Feb 22 22:03:39 2015
From: nobody at snovc.com (Private Sender)
Date: Sun, 22 Feb 2015 14:03:39 -0800
Subject: [squid-users] assertion failed: client_side.h:364:
 "sslServerBump == srvBump"
In-Reply-To: <54EA518F.8040300@snovc.com>
References: <54EA518F.8040300@snovc.com>
Message-ID: <54EA523B.5050007@snovc.com>

Error negotiating SSL connection on FD 44: error:140A1175:SSL
routines:SSL_BYTES_TO_CIPHER_LIST:inappropriate fallback (1/-1)

This prepends the previous info.




From eliezer at ngtech.co.il  Sun Feb 22 22:10:12 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 23 Feb 2015 00:10:12 +0200
Subject: [squid-users] Need tips in order to force youtube in HTTP only
In-Reply-To: <54E9C3F6.8090209@treenet.co.nz>
References: <54E9B711.8070304@articatech.com> <54E9C3F6.8090209@treenet.co.nz>
Message-ID: <54EA53C4.9040903@ngtech.co.il>

On 22/02/2015 13:56, Amos Jeffries wrote:
> The google page about forcing safesearch currently recommends hijacking
> DNS. Which may also work for YouTube but its not clear.

I must mention also:

If only youtube is the issue, there is an idea to pre-identify these dns 
requests and only ssl-bump these IP addresses which would point into any 
youtube http domain.(*.youtube.com and similar)
If there is an option to pre create a ssl certificate which contains all 
the needed domains for this interception you might be able to install 
only a "bundle" of certificates which can be used by the users.
Installing a certificate in a windows system can be pretty simple if you 
have the knowledge and the right permissions.

The main issue is "pinning" this certificate inside the ssl_crtd 
certificates directory.

Eliezer



From squid3 at treenet.co.nz  Mon Feb 23 01:10:42 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Feb 2015 14:10:42 +1300
Subject: [squid-users] Compile errors Squid 3.5.2
In-Reply-To: <1890898106.6825940.1424627165497.JavaMail.yahoo@mail.yahoo.com>
References: <1890898106.6825940.1424627165497.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54EA7E12.90507@treenet.co.nz>

On 23/02/2015 6:46 a.m., Stanford Prescott wrote:
> When trying to compile Squid 3.5.2 the compile fails. The only error messages I can find are these:
> "tar: ./usr/share/errors/zh-cn: Cannot create symlink to `zh-hans': File exists"
> "tar: ./usr/share/errors/zh-cn: Cannot create symlink to `zh-hant': File exists"
> 
> A squid binary is produced but won't start when I replace the working squid 3.4.10 binary in my distribution (Smoothwall Express 3.1) with the 3.5.2 binary. I get this error message in the cache.log when trying to start squid 3.5.2.
> "FATAL: Ipc::Mem::Segment::create failed to shm_open(/squid-cf__metadata.shm): (13) Permission denied"
> 
> I was not surprised that the Squid 3.5.2 binary would not start due to the compile errors, but I thought I would try anyway.
> Does anyone have any idea what I might be doing wrong?

Squid is not a script. "compiler errors" only happen at runtime when
runngin scripts.
Squid is a binary, it has to be compiled successfully to use. Your is
having a "permission" error.


It sounds like the system integration build options have not been set
the same. The paths options are obvious, but they also include things
like the --with-default-user.

Or may SELinux/Apparmour settings are getting in the way. 3.5 changes
the UDS names slightly so they may not be configured to permit the squid
process to use the new names.
In this case from cf__metadata.shm to ${service_name}-cf__metadata.shm
where ${service_name} is teh value pased in the -n (lower case) command
line parameter.

Amos



From squid3 at treenet.co.nz  Mon Feb 23 01:36:48 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Feb 2015 14:36:48 +1300
Subject: [squid-users] assertion failed: client_side.h:364:
 "sslServerBump == srvBump"
In-Reply-To: <54EA518F.8040300@snovc.com>
References: <54EA518F.8040300@snovc.com>
Message-ID: <54EA8430.6040400@treenet.co.nz>

On 23/02/2015 11:00 a.m., Private Sender wrote:
> Hello,
> 
> I keep getting this same error, regardless of what version of squid I'm
> running (3.5.2 currently).
> 
> Anyone have any ideas?
> 
> Output from log:
> 
> 2015/02/22 13:30:22 kid1| assertion failed: client_side.h:364:
> "sslServerBump == srvBump"

This needs a big report. Christos may or may not be aware of it already.

...
> 2015/02/22 13:30:26 kid1| ERROR: No forward-proxy ports configured.
> 2015/02/22 13:30:26 kid1| Finished loading MIME types and icons.


Squid generates URLs for clients to fetch icons etc directly from eth
proxy. Now that we are being strict about what types of traffci work n a
NATO intercept port, it needs a forward-proxy port aconfigured to
receive these requests.

The officially registered port is 3128 so these are fixed by:
   http_port 3128



> 2015/02/22 13:30:26 kid1| HTCP Disabled.
> 2015/02/22 13:30:26 kid1| Pinger socket opened on FD 28
> 2015/02/22 13:30:26 kid1| Squid plugin modules loaded: 0
> 2015/02/22 13:30:26 kid1| Adaptation support is on
> 2015/02/22 13:30:26 kid1| Accepting NAT intercepted SSL bumped HTTPS
> Socket connections at local=0.0.0.0:443 remote=[::] FD 26 flags=41

The Squid listening port number has nothing to do with the port-80/443
clients are sending to and this type of config will cause nasty bugs
if/when the machine runs a proper web server.

Its best to use a random port of your own selection outside the 0-1024
well-known port range. Its only needed between the NAT firewall and
Squid so can (and SHOULD) be firewalled to prevent remote access
directly to it.



> 2015/02/22 13:30:26| pinger: Initialising ICMP pinger ...
> 2015/02/22 13:30:26|  icmp_sock: (1) Operation not permitted
> 2015/02/22 13:30:26| pinger: Unable to start ICMP pinger.
> 2015/02/22 13:30:26| FATAL: pinger: Unable to open any ICMP sockets.

Your "pinger" binary is not installed with suid (aka root as owner).


> 2015/02/22 13:30:26 kid1| Done reading /mnt/squid1 swaplog (3374 entries)
> 2015/02/22 13:30:26 kid1| Finished rebuilding storage from disk.
> 2015/02/22 13:30:26 kid1|      3374 Entries scanned
> 2015/02/22 13:30:26 kid1|         0 Invalid entries.
> 2015/02/22 13:30:26 kid1|         0 With invalid flags.
> 2015/02/22 13:30:26 kid1|      3374 Objects loaded.
> 2015/02/22 13:30:26 kid1|         0 Objects expired.
> 2015/02/22 13:30:26 kid1|         0 Objects cancelled.
> 2015/02/22 13:30:26 kid1|         0 Duplicate URLs purged.
> 2015/02/22 13:30:26 kid1|         0 Swapfile clashes avoided.
> 2015/02/22 13:30:26 kid1|   Took 0.08 seconds (41055.72 objects/sec).
> 2015/02/22 13:30:26 kid1| Beginning Validation Procedure
> 2015/02/22 13:30:26 kid1|   Completed Validation Procedure
> 2015/02/22 13:30:26 kid1|   Validated 3374 Entries
> 2015/02/22 13:30:26 kid1|   store_swap_size = 54324.00 KB
> 2015/02/22 13:30:27 kid1| storeLateRelease: released 0 objects
> 
> Squid was built with these options:
> 
> root at squid:~/squid# squid -v
> Squid Cache: Version 3.5.2
> Service Name: squid
> configure options:  '--enable-ssl'

The "--enable-ssl'" directive is obsolete. You can simplify by removing
it. The --with-openssl you have below does the same thing this used to.

> '--enable-ssl-crtd' '--enable-icmp'
> '--enable-linux-netfilter' '--disable-ipv6' '--with-openssl'

NP: its time to stop using that IPv6 directove. Squid works fine nowdays
on a properly configured network. Even if its configured to be IPv4-only.

> '--with-large-files' '--prefix=/usr' '--localstatedir=/var'
> '--libexecdir=/lib/squid' '--srcdir=.' '--datadir=/share/squid'
> '--sysconfdir=/etc/squid' '--with-default-user=proxy'
> '--with-logdir=/var/log' '--with-pidfile=/var/run/squid.pid'
> '--enable-icap-client'
> 
> SSLBump works, the problem is this error seems to crash the daemon,
> and forces a reload.
> 

Not much help sorry. The SSL_Bump fixes available today are almost all
in 3.5.2.

Amos



From denizlist at denizeren.net  Mon Feb 23 12:33:55 2015
From: denizlist at denizeren.net (Deniz Eren)
Date: Mon, 23 Feb 2015 14:33:55 +0200
Subject: [squid-users] ACL Check for Established Connections
Message-ID: <CAHQdsZ_bz1eysuxsVN7HjQGp-AzMecTVTFZJs-+cinCaVW_BbQ@mail.gmail.com>

Hi,

I have an authentication system that authenticates a connection after
10-20 packet flows and I want to integrate this authentication system
with squid using external_acl functionality. However when I inspected
squid, I realized that it asks external_acl tool only when connection
is being established. Is there a way to force squid to check ACLs for
already established connections periodically?

Regards
Deniz Eren


From alanpalmer72 at yahoo.com  Mon Feb 23 19:49:28 2015
From: alanpalmer72 at yahoo.com (Alan Palmer)
Date: Mon, 23 Feb 2015 14:49:28 -0500
Subject: [squid-users] tlsv1 alert errors
Message-ID: <54EB8448.7050702@yahoo.com>

So I got squid to intercept http and https traffic, but I get the 
following error on any https access

2015/02/23 12:50:15 kid1| clientNegotiateSSL: Error negotiating SSL 
connection o
n FD 28: error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown 
ca (1/0
)

This of course leads to all kinds of site untrusted/compromised errors 
in client browsers.

 From looking in the archives this usually occurs because of a 
missing/outdated root CA file.
I have the following liness in squid.conf

https_port 127.0.0.1:3127 intercept ssl-bump \
   generate-host-certificates=on \
   dynamic_cert_mem_cache_size=16MB \
   cert=/etc/squid/ssl_cert/MyCA.pem\
   cafile=/etc/ssl/cert.pem # tried without the cafile cirective here as 
well


https_port [::1]:3127 intercept ssl-bump \
   generate-host-certificates=on \
   dynamic_cert_mem_cache_size=16MB \
   cert=/etc/squid/ssl_cert/MyCA.pem\
   cafile=/etc/ssl/cert.pem #tried without the cafile directive here as well

#
sslcrtd_program /usr/local/libexec/squid/ssl_crtd -s /data/squid/ssl_db 
-M 16MB
sslcrtd_children 10
always_direct allow all
sslproxy_cert_error allow all
ssl_bump server-first all
sslproxy_cafile /etc/ssl/cert.pem
#sslproxy_cert_error allow all
#sslproxy_flags DONT_VERIFY_PEER

The /etc/ssl/cert.pem file distributed with openbsd 5.6 has 44 root ca's 
listed (see below).

Is there anyway to get squid to tell me which CA is unknown? If so I can 
get that CA file and add it in.  Or is there a place to get a good 
rootca.pem file? Or is something else wrong?

Thanks muchly for helping the newbie.

Alan

the openbsd5.6 cert.pem contains the following issuers/certificates:
# grep Issuer /etc/ssl/cert.pem
         Issuer: C=US, O=GTE Corporation, OU=GTE CyberTrust Solutions, 
Inc., CN=G
TE CyberTrust Global Root
         Issuer: C=US, O=Equifax, OU=Equifax Secure Certificate Authority
         Issuer: C=US, O=VeriSign, Inc., OU=Class 3 Public Primary 
Certification
Authority - G2, OU=(c) 1998 VeriSign, Inc. - For authorized use only, 
OU=VeriSig
n Trust Network
         Issuer: C=BE, O=GlobalSign nv-sa, OU=Root CA, CN=GlobalSign Root CA
         Issuer: OU=GlobalSign Root CA - R2, O=GlobalSign, CN=GlobalSign
         Issuer: OU=GlobalSign Root CA - R3, O=GlobalSign, CN=GlobalSign
         Issuer: C=ZA, ST=Western Cape, L=Cape Town, O=Thawte Consulting 
cc, OU=C
ertification Services Division, CN=Thawte Premium Server 
CA/emailAddress=premium
-server at thawte.com
         Issuer: C=ZA, ST=Western Cape, L=Cape Town, O=Thawte Consulting 
cc, OU=C
ertification Services Division, CN=Thawte Server 
CA/emailAddress=server-certs at th
awte.com
         Issuer: C=US, O=VeriSign, Inc., OU=Class 3 Public Primary 
Certification
Authority
         Issuer: C=US, O=VeriSign, Inc., OU=VeriSign Trust Network, 
OU=(c) 2006 V
eriSign, Inc. - For authorized use only, CN=VeriSign Class 3 Public 
Primary Cert
ification Authority - G5
         Issuer: C=US, O=VeriSign, Inc., OU=VeriSign Trust Network, 
OU=(c) 1999 V
eriSign, Inc. - For authorized use only, CN=VeriSign Class 3 Public 
Primary Cert
ification Authority - G3
         Issuer: C=US, O=VeriSign, Inc., OU=VeriSign Trust Network, 
OU=(c) 2007 V
eriSign, Inc. - For authorized use only, CN=VeriSign Class 3 Public 
Primary Cert
ification Authority - G4
         Issuer: C=US, O=VeriSign, Inc., OU=VeriSign Trust Network, 
OU=(c) 2008 V
eriSign, Inc. - For authorized use only, CN=VeriSign Universal Root 
Certificatio
n Authority
         Issuer: C=US, O=VeriSign, Inc., OU=VeriSign Trust Network, 
OU=(c) 1999 V
eriSign, Inc. - For authorized use only, CN=VeriSign Class 4 Public 
Primary Cert
ification Authority - G3
         Issuer: C=IL, O=StartCom Ltd., OU=Secure Digital Certificate 
Signing, CN
=StartCom Certification Authority
         Issuer: L=ValiCert Validation Network, O=ValiCert, Inc., 
OU=ValiCert Class 2 Policy Validation Authority, 
CN=http://www.valicert.com//emailAddress=info at valicert.com
         Issuer: C=US, O=Entrust.net, OU=www.entrust.net/CPS incorp. by 
ref. (limits liab.), OU=(c) 1999 Entrust.net Limited, CN=Entrust.net 
Secure Server Certification Authority
         Issuer: C=US, O=DigiCert Inc, OU=www.digicert.com, CN=DigiCert 
High Assurance EV Root CA
         Issuer: C=US, O=DigiCert Inc, OU=www.digicert.com, CN=DigiCert 
Assured ID Root CA
         Issuer: C=US, O=DigiCert Inc, OU=www.digicert.com, CN=DigiCert 
Global Root CA
         Issuer: C=US, O=Equifax Secure Inc., CN=Equifax Secure Global 
eBusiness CA-1
         Issuer: C=US, O=Equifax Secure Inc., CN=Equifax Secure 
eBusiness CA-1
         Issuer: C=US, O=GeoTrust Inc., CN=GeoTrust Global CA
         Issuer: C=US, O=GeoTrust Inc., CN=GeoTrust Global CA 2
         Issuer: C=US, O=GeoTrust Inc., CN=GeoTrust Primary 
Certification Authority
         Issuer: C=US, O=GeoTrust Inc., OU=(c) 2008 GeoTrust Inc. - For 
authorized use only, CN=GeoTrust Primary Certification Authority - G3
         Issuer: C=US, O=GeoTrust Inc., CN=GeoTrust Universal CA
         Issuer: C=US, O=GeoTrust Inc., CN=GeoTrust Universal CA 2
         Issuer: C=US, O=The Go Daddy Group, Inc., OU=Go Daddy Class 2 
Certification Authority
         Issuer: C=US, ST=Arizona, L=Scottsdale, O=GoDaddy.com, Inc., 
CN=Go Daddy Root Certificate Authority - G2
         Issuer: C=US, O=Starfield Technologies, Inc., OU=Starfield 
Class 2 Certification Authority
         Issuer: C=US, ST=Arizona, L=Scottsdale, O=Starfield 
Technologies, Inc., CN=Starfield Root Certificate Authority - G2
         Issuer: C=US, ST=Arizona, L=Scottsdale, O=Starfield 
Technologies, Inc., CN=Starfield Services Root Certificate Authority - G2
         Issuer: C=IL, O=StartCom Ltd., CN=StartCom Certification 
Authority G2
         Issuer: C=US, O=thawte, Inc., OU=Certification Services 
Division, OU=(c) 2006 thawte, Inc. - For authorized use only, CN=thawte 
Primary Root CA
         Issuer: C=US, O=thawte, Inc., OU=(c) 2007 thawte, Inc. - For 
authorized use only, CN=thawte Primary Root CA - G2
         Issuer: C=US, O=thawte, Inc., OU=Certification Services 
Division, OU=(c) 2008 thawte, Inc. - For authorized use only, CN=thawte 
Primary Root CA - G3
         Issuer: C=SE, O=AddTrust AB, OU=AddTrust External TTP Network, 
CN=AddTrust External CA Root
         Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Comodo CA 
Limited, CN=AAA Certificate Services
         Issuer: C=US, ST=UT, L=Salt Lake City, O=The USERTRUST Network, 
OU=http://www.usertrust.com, CN=UTN-USERFirst-Hardware
         Issuer: C=IE, O=Baltimore, OU=CyberTrust, CN=Baltimore 
CyberTrust Root
         Issuer: C=DE, O=Deutsche Telekom AG, OU=T-TeleSec Trust Center, 
CN=Deutsche Telekom Root CA 2
         Issuer: C=DE, O=T-Systems Enterprise Services GmbH, 
OU=T-Systems Trust Center, CN=T-TeleSec GlobalRoot Class 2
         Issuer: C=DE, O=T-Systems Enterprise Services GmbH, 
OU=T-Systems Trust Center, CN=T-TeleSec GlobalRoot Class 3



From eliezer at ngtech.co.il  Mon Feb 23 19:49:04 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 23 Feb 2015 21:49:04 +0200
Subject: [squid-users] ACL Check for Established Connections
In-Reply-To: <CAHQdsZ_bz1eysuxsVN7HjQGp-AzMecTVTFZJs-+cinCaVW_BbQ@mail.gmail.com>
References: <CAHQdsZ_bz1eysuxsVN7HjQGp-AzMecTVTFZJs-+cinCaVW_BbQ@mail.gmail.com>
Message-ID: <54EB8430.8000809@ngtech.co.il>

Hey Deniz,

Squid is an HTTP proxy and is built upon the idea of a "request" and a 
"response".
Currently squid code allows and do couple things as the request starts.
The only option I can think of that can "do" what you need is ICAP or 
ECAP which can inspect the traffic on the fly when it flows from the 
server to the client else then on the request side.
external_acl cannot do you what you need\want.

All The Bests,
Eliezer Croitoru

On 23/02/2015 14:33, Deniz Eren wrote:
> Hi,
>
> I have an authentication system that authenticates a connection after
> 10-20 packet flows and I want to integrate this authentication system
> with squid using external_acl functionality. However when I inspected
> squid, I realized that it asks external_acl tool only when connection
> is being established. Is there a way to force squid to check ACLs for
> already established connections periodically?
>
> Regards
> Deniz Eren




From Mike.Mitchell at sas.com  Mon Feb 23 21:48:14 2015
From: Mike.Mitchell at sas.com (Mike Mitchell)
Date: Mon, 23 Feb 2015 21:48:14 +0000
Subject: [squid-users] Building 3.5.1 without libcom_err?
In-Reply-To: <1423755779747.27506@sas.com>
References: <1423755584147.31095@sas.com>,<1423755779747.27506@sas.com>
Message-ID: <1424728094455.60211@sas.com>

Is there a way to build 3.5.1 without libcom_err?
On my old Redhat system (2.6.18-128.1.1.el5) I get compilation failures unless I remove all references to libcom_err.

Here's a snippet from the config log:

configure:24277: checking for krb5.h
configure:24277: result: yes
configure:24277: checking com_err.h usability
configure:24277: g++ -c -g -O2??? conftest.cpp >&5
conftest.cpp:110:21: error: com_err.h: No such file or directory
configure:24277: $? = 1
configure: failed program was:
| /* confdefs.h */
...

configure:24330: checking for error_message in -lcom_err
configure:24355: g++ -o conftest -g -O2??? -g conftest.cpp -lcom_err? -lrt -ldl -ldl??? -lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err -lkrb5 -lk5crypto -lcom_err? >&5
/usr/bin/ld: skipping incompatible /usr/lib/libcom_err.so when searching for -lcom_err
/usr/bin/ld: skipping incompatible /usr/lib/libcom_err.a when searching for -lcom_err
/usr/bin/ld: cannot find -lcom_err
collect2: ld returned 1 exit status


Later when I try to build squid I get the same "incompatible /usr/lib/libcom_err.so" error message and the build stops.

If I hand-edit the Makefiles in the various directories and remove "-lcom_err", the build succeeds and the executables run properly.

I run configure with --with-krb5-config="no" --without-mit-krb5 --without-heimdal-krb5 --without-gnutls

But it still tries linking in the krb libraries and the com_err library.

Any suggestions?

Mike Mitchell


From Mike.Mitchell at sas.com  Mon Feb 23 22:01:02 2015
From: Mike.Mitchell at sas.com (Mike Mitchell)
Date: Mon, 23 Feb 2015 22:01:02 +0000
Subject: [squid-users] request_body_max_size on transparent proxy
Message-ID: <1424728863146.58160@sas.com>


I'm trying to POST large files (>1MB) through a squid 3.5.2 proxy set up to intercept connections.

The client is including an 'Expect: 100-continue' header, and sends all headers in a single network packet.
POSTs of content smaller than 1MB go through, but larger POSTs do not.
The client's TCP connection is being reset without squid sending any sort of error page.
Nothing is logged in squid -- not in the access log, not in the cache log.  It's as if that request never happened.
The client just gets a closed connection.

I'm running with the default 'request_body_max_size', it is not specified in my configuration.
That should mean "unlimited" for the request body.

If I configure the client to explicitly use the same proxy on a different, non-transparent port, the large POSTs go through correctly.  It is as if request_body_max_size does not function on a port marked 'transparent'.

Has anyone else seen this problem?
I've found one reference to it in my searches, http://nerdanswer.com/answer.php?q=336233

Mike Mitchell



From hack.back at hotmail.com  Mon Feb 23 22:53:01 2015
From: hack.back at hotmail.com (HackXBack)
Date: Mon, 23 Feb 2015 14:53:01 -0800 (PST)
Subject: [squid-users] Need tips in order to force youtube in HTTP only
In-Reply-To: <54EA53C4.9040903@ngtech.co.il>
References: <54E9B711.8070304@articatech.com> <54E9C3F6.8090209@treenet.co.nz>
 <54EA53C4.9040903@ngtech.co.il>
Message-ID: <1424731981721-4670034.post@n4.nabble.com>

there is a way without using ssl_bump
without forwarding https
but this will work with browsers and not with youtube mobile app.
its in header replace



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Need-tips-in-order-to-force-youtube-in-HTTP-only-tp4670014p4670034.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hack.back at hotmail.com  Tue Feb 24 00:16:27 2015
From: hack.back at hotmail.com (HackXBack)
Date: Mon, 23 Feb 2015 16:16:27 -0800 (PST)
Subject: [squid-users] again i lost my cache with upgrading for 3.5.2
Message-ID: <1424736987209-4670035.post@n4.nabble.com>

i did that with version 3.5.1
now wen upgrade again for 3.5.2 my cache damaged again !!
i just want to know how this version is stable !!
its full of bugs !!

cache.log = 
2015/02/23 19:20:51 kid1| Could not parse headers from on disk object
2015/02/23 19:20:51 kid1| BUG 3279: HTTP reply without Date:
2015/02/23 19:20:51 kid1| StoreEntry->key: BCE3520785CBE31A447841BAEB9FC542
2015/02/23 19:20:51 kid1| StoreEntry->next: 0
2015/02/23 19:20:51 kid1| StoreEntry->mem_obj: 0x6dab40f0
2015/02/23 19:20:51 kid1| StoreEntry->timestamp: -1
2015/02/23 19:20:51 kid1| StoreEntry->lastref: 1424737251
2015/02/23 19:20:51 kid1| StoreEntry->expires: -1
2015/02/23 19:20:51 kid1| StoreEntry->lastmod: -1
2015/02/23 19:20:51 kid1| StoreEntry->swap_file_sz: 0
2015/02/23 19:20:51 kid1| StoreEntry->refcount: 1
2015/02/23 19:20:51 kid1| StoreEntry->flags:
DISPATCHED,PRIVATE,FWD_HDR_WAIT,VALIDATED
2015/02/23 19:20:51 kid1| StoreEntry->swap_dirn: -1
2015/02/23 19:20:51 kid1| StoreEntry->swap_filen: -1
2015/02/23 19:20:51 kid1| StoreEntry->lock_count: 3
2015/02/23 19:20:51 kid1| StoreEntry->mem_status: 0
2015/02/23 19:20:51 kid1| StoreEntry->ping_status: 2
2015/02/23 19:20:51 kid1| StoreEntry->store_status: 1
2015/02/23 19:20:51 kid1| StoreEntry->swap_status: 0
2015/02/23 19:20:51 kid1| assertion failed: store.cc:1885: "isEmpty()"

=================== and keep restarting ....


and for debug gdb
=============================================================
root at loai:~# gdb /usr/sbin/squid /var/spool/squid/cache/squid/core
GNU gdb (GDB) 7.4.1-debian
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /usr/sbin/squid...done.
[New LWP 20099]
[New LWP 20155]
[New LWP 20147]
[New LWP 20153]
[New LWP 20149]
[New LWP 20146]
[New LWP 20154]
[New LWP 20152]
[New LWP 20157]
[New LWP 20151]
[New LWP 20161]
[New LWP 20158]
[New LWP 20166]
[New LWP 20168]
[New LWP 20164]
[New LWP 20148]
[New LWP 20163]
[New LWP 20172]
[New LWP 20144]
[New LWP 20145]
[New LWP 20171]
[New LWP 20162]
[New LWP 20165]
[New LWP 20167]
[New LWP 20174]
[New LWP 20159]
[New LWP 20175]
[New LWP 20169]
[New LWP 20160]
[New LWP 20150]
[New LWP 20170]
[New LWP 20173]
[New LWP 20156]

warning: Can't read pathname for load map: Input/output error.
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Core was generated by `(squid-1) -YC -f /etc/squid/squid.conf'.
Program terminated with signal 6, Aborted.
#0  0x00007f854c547165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
(gdb) backtrace
#0  0x00007f854c547165 in raise () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f854c54a3e0 in abort () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x000000000058739f in xassert (msg=<optimized out>, file=<optimized
out>, line=<optimized out>) at debug.cc:544
#3  0x0000000000648a0c in StoreEntry::startWriting (this=0x6e50d970) at
store.cc:1885
#4  0x000000000077459e in Client::setFinalReply (this=0x71474228,
rep=0x70f79970) at Client.cc:158
#5  0x00000000005d0d68 in HttpStateData::processReply (this=0x71474228) at
http.cc:1238
#6  0x00000000005d354a in JobDialer<HttpStateData>::dial (this=0x719fe0f0,
call=...) at base/AsyncJobCalls.h:174
#7  0x00000000006c8139 in AsyncCall::make (this=0x719fe0c0) at
AsyncCall.cc:40
#8  0x00000000006cbd8f in AsyncCallQueue::fireNext
(this=this at entry=0x27c5bf0) at AsyncCallQueue.cc:56
#9  0x00000000006cc0c0 in AsyncCallQueue::fire (this=0x27c5bf0) at
AsyncCallQueue.cc:42
#10 0x000000000059872c in EventLoop::runOnce
(this=this at entry=0x7fffb403fbe0) at EventLoop.cc:120
#11 0x00000000005988d0 in EventLoop::run (this=0x7fffb403fbe0) at
EventLoop.cc:82
#12 0x00000000005fc468 in SquidMain (argc=<optimized out>, argv=<optimized
out>) at main.cc:1508
#13 0x00000000005154bb in SquidMainSafe (argv=<optimized out>,
argc=<optimized out>) at main.cc:1240
#14 main (argc=<optimized out>, argv=<optimized out>) at main.cc:1233
(gdb)




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/again-i-lost-my-cache-with-upgrading-for-3-5-2-tp4670035.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Tue Feb 24 00:43:36 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 24 Feb 2015 02:43:36 +0200
Subject: [squid-users] Need tips in order to force youtube in HTTP only
In-Reply-To: <1424731981721-4670034.post@n4.nabble.com>
References: <54E9B711.8070304@articatech.com> <54E9C3F6.8090209@treenet.co.nz>
 <54EA53C4.9040903@ngtech.co.il> <1424731981721-4670034.post@n4.nabble.com>
Message-ID: <54EBC938.1010206@ngtech.co.il>

On 24/02/2015 00:53, HackXBack wrote:
> there is a way without using ssl_bump
> without forwarding https
> but this will work with browsers and not with youtube mobile app.
> its in header replace

Hey HackXBack,

I am not to familiar with all of the mobile apps but if the client needs 
filtering he needs it..
I do not think that youtube should be used in a mobile app that is not 
using any of the device certificates DB.
I have seen that most apps are using Android or any other device 
certificate device since these devices are a part of a service that 
serves enterprises and corporations which needs this restriction.
If someone is a part of an enterprise or a corporation he should not use 
a non-compatible to his needs device.

I will need to test how different devices react to a ssl-bump situation 
but it's not one of my goals for now.
I am happy with what I have that works fine for me and many others.
Maybe in the future I will have more needs that will might force to some 
new things.

The main thing I am working on now is the 3.5.2 testing for general use 
which not includes ssl-bump as a tested feature but the RPM includes it 
in order to make it available to the CentOS users who wish to make some 
progress and understand that squid has a class of it's own.

Eliezer



From eliezer at ngtech.co.il  Tue Feb 24 01:27:54 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 24 Feb 2015 03:27:54 +0200
Subject: [squid-users] again i lost my cache with upgrading for 3.5.2
In-Reply-To: <1424736987209-4670035.post@n4.nabble.com>
References: <1424736987209-4670035.post@n4.nabble.com>
Message-ID: <54EBD39A.7020907@ngtech.co.il>

On 24/02/2015 02:16, HackXBack wrote:
> i did that with version 3.5.1
> now wen upgrade again for 3.5.2 my cache damaged again !!
> i just want to know how this version is stable !!
> its full of bugs !!


Hey HackXBack,

Some would imagine that squid is perfect and if you will look at the 
Bugzilla you will see that it's not.
Any such upgrades tests are recommended to be done on a *non production* 
system.
If it means loosing your cache and it happens each time you update it is 
most likely that the issue is the upgrade path you do things and not an 
issue with the software itself.
I do not like to redirect into docs since docs cannot answer lots of 
things which humans can.

In this specific case I must describe to you couple things for an 
upgrade\update path:
- make sure the traffic from the server is down(do it slowly so the 
users will not curse your deeds and later you will be fired), 60 seconds 
should be enough in many cases but not all.
- Then let squid shutdown slow enough to allow it flush all the in 
memory data into disk.
- Start squid in a memory only state to make sure nobody touches the 
cache at all
- Add the clients traffic back for the testing period of the new version.
- Write a "testing" simple squid.conf that uses some very high port such 
as 127.0.0.1:23128
- Add one cache_dir at a time into this squid configuration file and 
make sure that this cache_dir is not too big(in a case you fear from 
cache corruption)
- After making sure the new version meets your basic needs you can try 
to repeat the process from the first step while adding the cache_dir 
back into the original squid configuration files.

Notice that an upgrade path is there to help the admin in his work since 
it can affect many users and can cause all sort of weird things.

Loosing cache_dir might be worth a lot to you since you indeed say over 
and over that squid is blame for it.
Before any such upgrade try if possible to look at the release notes 
since Amos is writing them down each and every time to make sure the 
admin will understand what is the current state of the squid release.

All The Bests,
Eliezer Croitoru



From nobody at snovc.com  Tue Feb 24 02:30:33 2015
From: nobody at snovc.com (Private Sender)
Date: Mon, 23 Feb 2015 18:30:33 -0800
Subject: [squid-users] assertion failed: client_side.h:364:
 "sslServerBump == srvBump"
In-Reply-To: <54EA8430.6040400@treenet.co.nz>
References: <54EA518F.8040300@snovc.com> <54EA8430.6040400@treenet.co.nz>
Message-ID: <54EBE249.3040800@snovc.com>

Thanks for the help!

In file client_side.h:

    inline void setServerBump(Ssl::ServerBump *srvBump) {
        if (!sslServerBump)
            sslServerBump = srvBump;
        else
            assert(sslServerBump == srvBump);
    }

Changed to:

    inline void setServerBump(Ssl::ServerBump *srvBump) {
        if (!sslServerBump)
            sslServerBump = srvBump;
        else
            assert(sslServerBump = srvBump);

And the crashes are gone.

This is in the 2-22-15 dev release.

Squid Cache: Version 3.HEAD-20150222-r13945
Service Name: squid
configure options:  '--enable-ssl-crtd' '--enable-icmp' '--enable-esi'
'--enable-follow-x-forwarded-for' '--enable-stacktraces'
'--enable-linux-netfilter' '--with-openssl' '--with-large-files'
'--prefix=/usr' '--localstatedir=/var' '--libexecdir=/lib/squid'
'--srcdir=.' '--datadir=/share/squid' '--sysconfdir=/etc/squid'
'--with-default-user=proxy' '--with-logdir=/var/log'
'--with-pidfile=/var/run/squid.pid' '--enable-icap-client'


From dan at getbusi.com  Tue Feb 24 03:47:55 2015
From: dan at getbusi.com (dan at getbusi.com)
Date: Mon, 23 Feb 2015 19:47:55 -0800 (PST)
Subject: [squid-users] assertion failed: client_side.cc:1515:
 "connIsUsable(http->getConn())
In-Reply-To: <54E6D2E0.8000409@treenet.co.nz>
References: <54E6D2E0.8000409@treenet.co.nz>
Message-ID: <1424749675359.dfea22c5@Nodemailer>

This is kind of off-topic but on one of our deployments this crash is now consistently deadlocking squid whenever it occurs rather than just ending the process. Meaning that is can?t be restarted by any means except kill -9, which obviously a huge disruption to hundreds of clients and incredibly frustrating for the sysadmin.




Nothing has really changed in the configuration since this deadlocking started happening ?but I?ve noticed when that there?s no longer anything in /var/log/messages from abrtd etc. like there usually would be.




I have a very similar deployment where this still crashes ?cleanly?.




Both on CentOS 6.6 and Squid 3.4.12.




Anyone have a clue what might cause this ?deadlocking? type behaviour after an ?assertion failed" crash?

On Fri, Feb 20, 2015 at 5:23 PM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 20/02/2015 7:15 p.m., Dan Charlesworth wrote:
>> Thanks Amos -
>> 
>> So then it more than likely is related to our external ACLs that deal with the HTTP response?
>> 
> I think they may be making the issue more noticable by slowing down the
> request processing. But Squid should not be getting into that state
> either way.
> Amos
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150223/a9aa6343/attachment.htm>

From frankhartza at gmail.com  Tue Feb 24 06:25:51 2015
From: frankhartza at gmail.com (zanettiza)
Date: Mon, 23 Feb 2015 22:25:51 -0800 (PST)
Subject: [squid-users] Authenication denies access to ports
Message-ID: <1424759151676-4670040.post@n4.nabble.com>

Hi Everyone,I've searched and search but have not found an answer to my
question.I'm running CentOS 7 and Squid 3.3.4. When I insert "http_access
allow Safe_ports" AFTER "http_access allow authenticated_users" I have no
access to ports listed under my Safe_ports ACL, however when I put it before
then everything works just fine, obviously that is then ignoring
authentication.Any thoughts on how I can overcome this? I have tried many
different configurations but nothing really works.Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Authenication-denies-access-to-ports-tp4670040.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From david at articatech.com  Tue Feb 24 11:15:43 2015
From: david at articatech.com (David Touzeau)
Date: Tue, 24 Feb 2015 12:15:43 +0100
Subject: [squid-users] Need tips in order to force youtube in HTTP only
In-Reply-To: <1424731981721-4670034.post@n4.nabble.com>
References: <54E9B711.8070304@articatech.com> <54E9C3F6.8090209@treenet.co.nz>
 <54EA53C4.9040903@ngtech.co.il> <1424731981721-4670034.post@n4.nabble.com>
Message-ID: <54EC5D5F.3040408@articatech.com>


You means replace the 301 because youtube answer to this when connecting 
on HTTP

HTTP/1.1 301 Moved Permanently
Date: Tue, 24 Feb 2015 11:11:28 GMT
Server: gwiseguy/2.0
Location: https://www.youtube.com/

Do you have tested this because if squid replace the header i think 
there will be a loop.

Notice: I have seen that vendors based on squid have found a solution 
but i think they are changed something inside the source code...





Le 23/02/2015 23:53, HackXBack a ?crit :
> there is a way without using ssl_bump
> without forwarding https
> but this will work with browsers and not with youtube mobile app.
> its in header replace
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Need-tips-in-order-to-force-youtube-in-HTTP-only-tp4670014p4670034.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From longbeakedechidna1 at gmail.com  Tue Feb 24 12:54:05 2015
From: longbeakedechidna1 at gmail.com (Greg)
Date: Tue, 24 Feb 2015 12:54:05 +0000
Subject: [squid-users] Need better debug_options values to track down cache
	MISSes
Message-ID: <CALXdjAKvTcvDhcgih3-FXuohh1A5xVqMvv792KXPN7ZifLSVkw@mail.gmail.com>

Hi all,

I'm new to squid administration, with basic *nix admin skills. My task now
is to replace an old Squid reverse proxy server (3.1.15 on an old Fedora)
with a new one (Squid 3.3.8 on Ubuntu 14 LTS) and ran into a problem.

I've spent 2 days tweaking-googling-debugging, now looking for some help...

Problem is, with the ~same configuration, the old Squid caches HTML pages
well and the new doesn't. This is a major concern, we're using Squid
exactly to do that and get the load off our appservers.

In this first mail, I'm only asking for a hint on what debug_options to
use. In previous list emails I've seen that some details help, so here they
are:
- Reverse proxy, port 80 only, one uplink straight to the app servers.
- Pretty standard configuration, standard refresh_patterns.
- Disk and memory cache, disk cache initialised with -z.
- Clocks are in sync (except for the old proxy server) using ntpd.
- Squid gives HITs for favicon.ico and RSS feeds only - these have
different headers and mimetypes compared to HTML files (and that's by
design).
- This new server seems to save accessed HTML files on disk but still gives
X-Cache-Lookup:MISS for all of them later.
- I've found the debug_options sections page but section names are
ambiguous for someone who's not a Squid programmer. I had to download the
source code, analysed it and tried "debug_options 11,1 22,6 85,3 88,5 33,1
31,5 90,5" which is too much and "debug_options 88,5 85,5 22,6 11,5 33,1"
which might be too little.
- Headers look okay (Cache-Control, Pragma, Vary), stale/fresh calculation
looks okay (pages are deemed fresh) in the debug log.
- The best I got so far is this: "client_side_reply.cc(1618)
identifyFoundObject: clientProcessRequest2: StoreEntry is NULL -  MISS",
even for pages I see in the disk cache -- I'd like to know why does it
occur, probably need some more good debug_options. I don't understand the
code too well, don't know which direction to take.

Please suggest some more good debug_options to continue with.

Best regards,
Greg

PS. Also, I'll submit another mail with the details of the problem + the
config, hoping someone spots a problem right away.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150224/7b5278ad/attachment.htm>

From peter at decycive.com  Tue Feb 24 14:04:52 2015
From: peter at decycive.com (Peter Oruba)
Date: Tue, 24 Feb 2015 15:04:52 +0100
Subject: [squid-users] Log proxy hostname along with HTTP access URI
Message-ID: <5C5B6F1F-AA35-4839-91AD-583765117A69@decycive.com>

Hello everybody,

I?d like to distinguish multiple clients that are behind NAT from Squid?s perspective. Proxy authentication or sessions are not an option for different reasons and the idea that came up was to assign each client a unique hostname through which Squid would be addressed (e.g. UUID1.proxy.example.com <http://uuid1.proxy.example.com/> and UUID2.proxy.example.com <http://uuid2.proxy.example.com/>) A DNS wildcard entry *.proxy.example.com <http://proxy.example.com/> would make sure each proxy referral points to the same machine. Question: Is there a way to let Squid log the DNS name through which a client referred to it? I was not able to find any example in this regard and I assume that the proxy hostname is ?lost? after the client's DNS lookup and that the client-proxy connection is established.

Thanks,
Peter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150224/5cff1cbf/attachment.htm>

From bpk678 at gmail.com  Tue Feb 24 14:37:53 2015
From: bpk678 at gmail.com (Brendan Kearney)
Date: Tue, 24 Feb 2015 09:37:53 -0500
Subject: [squid-users] Log proxy hostname along with HTTP access URI
In-Reply-To: <5C5B6F1F-AA35-4839-91AD-583765117A69@decycive.com>
References: <5C5B6F1F-AA35-4839-91AD-583765117A69@decycive.com>
Message-ID: <1424788673.5124.4.camel@desktop.bpk2.com>

On Tue, 2015-02-24 at 15:04 +0100, Peter Oruba wrote:
> Hello everybody,
> 
> 
> I?d like to distinguish multiple clients that are behind NAT from
> Squid?s perspective. Proxy authentication or sessions are not an
> option for different reasons and the idea that came up was to assign
> each client a unique hostname through which Squid would be addressed
> (e.g. UUID1.proxy.example.com and UUID2.proxy.example.com) A DNS
> wildcard entry *.proxy.example.com would make sure each proxy referral
> points to the same machine. Question: Is there a way to let Squid log
> the DNS name through which a client referred to it? I was not able to
> find any example in this regard and I assume that the proxy hostname
> is ?lost? after the client's DNS lookup and that the client-proxy
> connection is established.
> 
> 
> Thanks,
> Peter
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

with the below directives, you can avoid all of this grief and reference
the client ip address where you need to.  just be sure the NAT adds the
XFF header.

#  TAG: follow_x_forwarded_for
#  TAG: acl_uses_indirect_client        on|off
#  TAG: delay_pool_uses_indirect_client on|off
#  TAG: log_uses_indirect_client        on|off
#  TAG: tproxy_uses_indirect_client     on|off




From peter at decycive.com  Tue Feb 24 14:40:38 2015
From: peter at decycive.com (Peter Oruba)
Date: Tue, 24 Feb 2015 15:40:38 +0100
Subject: [squid-users] Log proxy hostname along with HTTP access URI
In-Reply-To: <1424788673.5124.4.camel@desktop.bpk2.com>
References: <5C5B6F1F-AA35-4839-91AD-583765117A69@decycive.com>
 <1424788673.5124.4.camel@desktop.bpk2.com>
Message-ID: <347D26D8-74B2-40B6-BC6C-95C5FA2B641C@decycive.com>

Thanks, Brendan, but unfortunately I don?t have access to the NAT configuration.

> Am 24.02.2015 um 15:37 schrieb Brendan Kearney <bpk678 at gmail.com>:
> 
> On Tue, 2015-02-24 at 15:04 +0100, Peter Oruba wrote:
>> Hello everybody,
>> 
>> 
>> I?d like to distinguish multiple clients that are behind NAT from
>> Squid?s perspective. Proxy authentication or sessions are not an
>> option for different reasons and the idea that came up was to assign
>> each client a unique hostname through which Squid would be addressed
>> (e.g. UUID1.proxy.example.com and UUID2.proxy.example.com) A DNS
>> wildcard entry *.proxy.example.com would make sure each proxy referral
>> points to the same machine. Question: Is there a way to let Squid log
>> the DNS name through which a client referred to it? I was not able to
>> find any example in this regard and I assume that the proxy hostname
>> is ?lost? after the client's DNS lookup and that the client-proxy
>> connection is established.
>> 
>> 
>> Thanks,
>> Peter
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> with the below directives, you can avoid all of this grief and reference
> the client ip address where you need to.  just be sure the NAT adds the
> XFF header.
> 
> #  TAG: follow_x_forwarded_for
> #  TAG: acl_uses_indirect_client        on|off
> #  TAG: delay_pool_uses_indirect_client on|off
> #  TAG: log_uses_indirect_client        on|off
> #  TAG: tproxy_uses_indirect_client     on|off
> 
> 



From peter at decycive.com  Tue Feb 24 14:44:30 2015
From: peter at decycive.com (Peter Oruba)
Date: Tue, 24 Feb 2015 15:44:30 +0100
Subject: [squid-users] Log proxy hostname along with HTTP access URI
In-Reply-To: <54EC8D32.9030005@artifact-software.com>
References: <5C5B6F1F-AA35-4839-91AD-583765117A69@decycive.com>
 <54EC8D32.9030005@artifact-software.com>
Message-ID: <C2F5AD5D-BD66-4AC1-BF1E-E06DD8B7805A@decycive.com>



> Am 24.02.2015 um 15:39 schrieb Ron Wheeler <rwheeler at artifact-software.com>:
> 
> On 24/02/2015 9:04 AM, Peter Oruba wrote:
>> Hello everybody,
>> 
>> I?d like to distinguish multiple clients that are behind NAT from Squid?s perspective. Proxy authentication or sessions are not an option for different reasons and the idea that came up was to assign each client a unique hostname through which Squid would be addressed (e.g. UUID1.proxy.example.com <http://uuid1.proxy.example.com/> and UUID2.proxy.example.com <http://uuid2.proxy.example.com/>) A DNS wildcard entry *.proxy.example.com <http://proxy.example.com/> would make sure each proxy referral points to the same machine. Question: Is there a way to let Squid log the DNS name through which a client referred to it? I was not able to find any example in this regard and I assume that the proxy hostname is ?lost? after the client's DNS lookup and that the client-proxy connection is established.
>> 
>> Thanks,
>> Peter
>> 
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
> Not a direct answer but...
> Is it possible to get this info from the log kept by the service(http) that is getting the request?
> 
> -- 
> Ron Wheeler
> President
> Artifact Software Inc
> email: rwheeler at artifact-software.com <mailto:rwheeler at artifact-software.com>
> skype: ronaldmwheeler
> phone: 866-970-2435, ext 102
Virtual hosts on web servers?  Yes, the same principle, but on Squid.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150224/fa26c168/attachment.htm>

From pavel.kazlenka at measurement-factory.com  Tue Feb 24 14:57:11 2015
From: pavel.kazlenka at measurement-factory.com (Pavel Kazlenka)
Date: Tue, 24 Feb 2015 17:57:11 +0300
Subject: [squid-users] Need better debug_options values to track down
 cache MISSes
In-Reply-To: <CALXdjAKvTcvDhcgih3-FXuohh1A5xVqMvv792KXPN7ZifLSVkw@mail.gmail.com>
References: <CALXdjAKvTcvDhcgih3-FXuohh1A5xVqMvv792KXPN7ZifLSVkw@mail.gmail.com>
Message-ID: <54EC9147.6070301@measurement-factory.com>

Hi Greg,

I use this combo to check if request is cached or no and why:
debug_options 20,9 27,9 31,9 70,9 82,9 22,9 84,9 90,9

Then in cache.log file you can search by 'YES' or 'NO' (uppercase) to 
see if the content is cacheable (and cached) or not and the reason of 
this decision. Hope this will help.

Best wishes,
Pavel

On 02/24/2015 03:54 PM, Greg wrote:
> Hi all,
>
> I'm new to squid administration, with basic *nix admin skills. My task 
> now is to replace an old Squid reverse proxy server (3.1.15 on an old 
> Fedora) with a new one (Squid 3.3.8 on Ubuntu 14 LTS) and ran into a 
> problem.
>
> I've spent 2 days tweaking-googling-debugging, now looking for some 
> help...
>
> Problem is, with the ~same configuration, the old Squid caches HTML 
> pages well and the new doesn't. This is a major concern, we're using 
> Squid exactly to do that and get the load off our appservers.
>
> In this first mail, I'm only asking for a hint on what debug_options 
> to use. In previous list emails I've seen that some details help, so 
> here they are:
> - Reverse proxy, port 80 only, one uplink straight to the app servers.
> - Pretty standard configuration, standard refresh_patterns.
> - Disk and memory cache, disk cache initialised with -z.
> - Clocks are in sync (except for the old proxy server) using ntpd.
> - Squid gives HITs for favicon.ico and RSS feeds only - these have 
> different headers and mimetypes compared to HTML files (and that's by 
> design).
> - This new server seems to save accessed HTML files on disk but still 
> gives X-Cache-Lookup:MISS for all of them later.
> - I've found the debug_options sections page but section names are 
> ambiguous for someone who's not a Squid programmer. I had to download 
> the source code, analysed it and tried "debug_options 11,1 22,6 85,3 
> 88,5 33,1 31,5 90,5" which is too much and "debug_options 88,5 85,5 
> 22,6 11,5 33,1" which might be too little.
> - Headers look okay (Cache-Control, Pragma, Vary), stale/fresh 
> calculation looks okay (pages are deemed fresh) in the debug log.
> - The best I got so far is this: "client_side_reply.cc(1618) 
> identifyFoundObject: clientProcessRequest2: StoreEntry is NULL - 
>  MISS", even for pages I see in the disk cache -- I'd like to know why 
> does it occur, probably need some more good debug_options. I don't 
> understand the code too well, don't know which direction to take.
>
> Please suggest some more good debug_options to continue with.
>
> Best regards,
> Greg
>
> PS. Also, I'll submit another mail with the details of the problem + 
> the config, hoping someone spots a problem right away.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150224/34361e7a/attachment.htm>

From jborrell at central.aplitec.com  Tue Feb 24 15:09:18 2015
From: jborrell at central.aplitec.com (Josep Borrell)
Date: Tue, 24 Feb 2015 15:09:18 +0000
Subject: [squid-users] derive HTTP/HTTPS upload traffic to a secondary
 interface.
In-Reply-To: <42DE25A255671C44A93A7B58470DC09C5EAA55BF@Michelle.aplitec.local>
References: <42DE25A255671C44A93A7B58470DC09C5E2F7C6F@Michelle.aplitec.local>
 <54D48588.7030301@treenet.co.nz>
 <42DE25A255671C44A93A7B58470DC09C5EAA55BF@Michelle.aplitec.local>
Message-ID: <42DE25A255671C44A93A7B58470DC09C5EAB3AFD@Michelle.aplitec.local>

Hi,

After some digging I realized that this setup works fine for HTTP traffic but not for HTTPS. I'm using ssl_bump in intercept mode.
Is possible that for HTTPS traffic I can't split the upload / download ?

answers are welcome !!

Thanks

Josep


-----Mensaje original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] En nombre de Josep Borrell
Enviado el: viernes, 20 de febrero de 2015 16:51
Para: squid-users at lists.squid-cache.org
Asunto: Re: [squid-users] derive HTTP/HTTPS upload traffic to a secondary interface.

Hi Amos,

I tried your suggestion and even if the acl is matched the outgoing IP is not changed.
How to know why ?
Working with squid 3.5.1. 
Original IP 192.168.111.10 must be changed for 192.168.111.20

Thanks

Josep


Squid.conf:

debug_options ALL,1 33,2 28,9 11,3


#HTTPS (SSL) trafic interception options sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/spool/squid3_ssldb -M 4MB sslcrtd_children 8 startup=1 idle=1

acl disable-ssl-bump dstdomain -i "/etc/squid3/no-ssl-bump.acl"
acl step1 at_step SSLBump1
acl step2 at_step SSLBump2
acl step3 at_step SSLBump3

ssl_bump peek step1 all
ssl_bump splice step2 disable-ssl-bump
ssl_bump stare step2 all
ssl_bump splice step3 disable-ssl-bump
ssl_bump bump step3 all


acl UPLOAD method PUT
acl UPLOAD method POST
tcp_outgoing_address 192.168.111.20 UPLOAD


http_access allow all

http_port 3128
http_port 8080 intercept
https_port 8081 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squidcert.pem

forward_max_tries 25
cache_mem 2 GB
maximum_object_size_in_memory 25 MB
maximum_object_size 1 GB

visible_hostname squid-v2

workers 3

coredump_dir /var/spool/squid3
cache_replacement_policy heap LFUDA
cache_dir rock /var/spool/squid3/cache1 4000 max-size=500 cache_dir aufs /var/spool/squid3/cache2 10000 16 256

refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 10080
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0 refresh_pattern . 0 80% 10080


# FortiGate interface of wccp
wccp2_router 192.168.111.1
# wccp version 2 configuration
wccp2_service standard 90
# tunneling method GRE for forward traffic wccp2_forwarding_method gre # tunneling method GRE for return traffic wccp2_return_method gre # which interface to use for WCCP (0.0.0.0 determines the interface from routing) wccp2_address 0.0.0.0




Debug sample:
----------
2015/02/20 16:27:22.879| Checklist.cc(68) preCheck: 0x7fe877ccc7c8 checking slow rules
2015/02/20 16:27:22.879| Acl.cc(138) matches: checking http_access
2015/02/20 16:27:22.879| Acl.cc(138) matches: checking http_access#1
2015/02/20 16:27:22.879| Acl.cc(138) matches: checking all
2015/02/20 16:27:22.879| Ip.cc(107) aclIpAddrNetworkCompare: aclIpAddrNetworkCompare: compare: 192.168.1.100:1887/[::] ([::]:1887)  vs [::]-[::]/[::]
2015/02/20 16:27:22.879| Ip.cc(538) match: aclIpMatchIp: '192.168.1.100:1887' found
2015/02/20 16:27:22.879| Acl.cc(158) matches: checked: all = 1
2015/02/20 16:27:22.879| Acl.cc(158) matches: checked: http_access#1 = 1
2015/02/20 16:27:22.879| Acl.cc(158) matches: checked: http_access = 1
2015/02/20 16:27:22.880| Checklist.cc(61) markFinished: 0x7fe877ccc7c8 answer ALLOWED for match
2015/02/20 16:27:22.880| Checklist.cc(161) checkCallback: ACLChecklist::checkCallback: 0x7fe877ccc7c8 answer=ALLOWED
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21ee80
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21ee80
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21ee80
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21ee80
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21e540
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21e540
2015/02/20 16:27:22.880| Checklist.cc(68) preCheck: 0x7fff7a21e540 checking fast ACLs
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking tcp_outgoing_address 192.168.111.20
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking (tcp_outgoing_address 192.168.111.20 line)
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking UPLOAD
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: UPLOAD = 1
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: (tcp_outgoing_address 192.168.111.20 line) = 1
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: tcp_outgoing_address 192.168.111.20 = 1
2015/02/20 16:27:22.880| Checklist.cc(61) markFinished: 0x7fff7a21e540 answer ALLOWED for match
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21e540
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21e540
2015/02/20 16:27:22.880| Checklist.cc(68) preCheck: 0x7fff7a21e460 checking fast ACLs
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking tcp_outgoing_address 192.168.111.20
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking (tcp_outgoing_address 192.168.111.20 line)
2015/02/20 16:27:22.880| Acl.cc(138) matches: checking UPLOAD
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: UPLOAD = 1
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: (tcp_outgoing_address 192.168.111.20 line) = 1
2015/02/20 16:27:22.880| Acl.cc(158) matches: checked: tcp_outgoing_address 192.168.111.20 = 1
2015/02/20 16:27:22.880| Checklist.cc(61) markFinished: 0x7fff7a21e460 answer ALLOWED for match
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21e460
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21e460
2015/02/20 16:27:22.880| http.cc(2261) httpStart: POST https://drive.google.com/stat
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fe877ccc7c8
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fe877ccc7c8
2015/02/20 16:27:22| Error sending to ICMPv6 packet to [2a00:1450:4003:805::200e]. ERR: (101) Network is unreachable
2015/02/20 16:27:22.880| Client.cc(232) startRequestBodyFlow: expecting request body from  [0<=274<=274 274+1773 pipe0x7fe87814d198 cons0x7fe87814e688]
2015/02/20 16:27:22.880| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7fff7a21f390
2015/02/20 16:27:22.880| Checklist.cc(195) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7fff7a21f390
2015/02/20 16:27:22.881| http.cc(2217) sendRequest: HTTP Server local=192.168.111.10:53172 remote=216.58.211.238:443 FD 23 flags=1
2015/02/20 16:27:22.881| http.cc(2218) sendRequest: HTTP Server REQUEST:
---------
POST /stat HTTP/1.1
Host: drive.google.com
User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:35.0) Gecko/20100101 Firefox/35.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate
Content-control: no-cache
X-Same-Domain: explorer
X-Json-Requested: true
Content-Type: application/x-www-form-urlencoded;charset=utf-8
Referer: https://drive.google.com/?authuser=0
Content-Length: 274
Cookie: NID=67=Gm7vcswCbOO55hZsjfaz-pTurlVu7ExNrsoWfJDDcTg8rumGt-xCQD6RezS9pYZypbeHEAfm1bcWQwc82QCvsL6rL9lDcDeEtjaPKdHT0C885UB6wiWl9TY_nTI4d38_9ccpMqC5Q5jnGzRntaOaIjm_nfhe; SID=DQAAAPwAAABdqFewpHnz9c-jo5Z0nyI7av_uC-pbzCxPtnThJe_3zg4ska6$
Pragma: no-cache
Via: 1.1 squid-v2 (squid/3.5.1)
X-Forwarded-For: 192.168.1.100
Cache-Control: no-cache
Connection: keep-alive


----------








-----Mensaje original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] En nombre de Amos Jeffries Enviado el: viernes, 06 de febrero de 2015 10:13
Para: squid-users at lists.squid-cache.org
Asunto: Re: [squid-users] derive HTTP/HTTPS upload traffic to a secondary interface.

On 6/02/2015 8:59 p.m., Josep Borrell wrote:
> Hi,
> 
> I have a squid box with two interfaces. One ADSL 20/1Mb and one SHDSL 4/4Mb.
> It is a school and they are working with Google Apps for Education.
> They do a lot of uploading and when using the ADSL, it collapses promptly.
> Is possible to derive only HTTP/HTTPS upload traffic to the SHDSL and continue surfing with the ADSL ?

In a roundabout way.

If you look at the OSI model of networking Squid is layers 4-7, and those interfaces are part of layer 1-2. There is a whole disconnect layer 3 in between (the TCP/IP layer).

What you can do in Squid is set one of the tcp_outgoing_address, tcp_outgoing_tos, tcp_outgoing_mark directives to label the TCP traffic out of Squid. The systems routing rules need to take that detail from TCP and decide which interface to use.



> Maybe using one acl with methods POST and UPLOAD and some routing magic ?

Somethign like this..

squid.conf:
 acl PUTPOST method PUT POST
 tcp_outgoing_address 192.0.2.1 PUTPOST

Where 192.0.2.1 is the IP address the system uses to send out SHDSDL.
You may need both an IPv4 and IPv6 outgoing address set using PUTPOST acl.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From longbeakedechidna1 at gmail.com  Tue Feb 24 15:14:19 2015
From: longbeakedechidna1 at gmail.com (Greg)
Date: Tue, 24 Feb 2015 15:14:19 +0000
Subject: [squid-users] Need better debug_options values to track down
	cache MISSes
In-Reply-To: <CALXdjAKvTcvDhcgih3-FXuohh1A5xVqMvv792KXPN7ZifLSVkw@mail.gmail.com>
References: <CALXdjAKvTcvDhcgih3-FXuohh1A5xVqMvv792KXPN7ZifLSVkw@mail.gmail.com>
Message-ID: <CALXdjAKY1Vz9jX0gbezXb85SgyVsYxmhUc+XqR1UHtc4nbXXgA@mail.gmail.com>

Hi all,

so, there's my proxy problem I couldn't crack, even after spending 2+
days tweaking-googling-debugging. :(

The problem: my _new_ Squid installation (Ubuntu 14 LTS with Squid 3.3.8)
won't cache most pages the old Squid does (old Fedora with Squid 3.1.15).

Infos:
- Simple reverse proxy, port 80 only, one uplink straight to the app
servers. (The old one points to a load balancer. For testing purposes and
seeing the mail on "Thu, 4 Apr 2013 16:54:10 -0700", I'm pointing the new
one to a specific app server.)
- Pretty standard configuration, standard refresh_patterns. (I'd be
surprised if it was a config problem since ICOs are cached well.)
- I have disk caching on the new one, the disk cache has been initialised
with -z.
- The old one has a very relaxed iptables, the new one has ufw, later set
to allow port 80 and 22 only for incoming connections.
- Clocks are in sync using ntpd - the old one has +20min delay (ie. shows a
later time than now). Since it's the live one, it's working and it handles
a lot of load well, I haven't dared to correct it.
- The new Squid gives HITs for favicon.ico and RSS feeds only - these have
different headers and mimetypes compared to HTML files (and that's by
design).
- This new server seems to save accessed HTML files in the disk cache but
still gives X-Cache-Lookup:MISS for all of them later.
- I debugged using debug_options and logging: headers look okay
(Cache-Control, Pragma, Vary - pasted below), stale/fresh calculation looks
okay (pages are deemed fresh).
- The best I got so far is this: "client_side_reply.cc(1618)
identifyFoundObject: clientProcessRequest2: StoreEntry is NULL -  MISS",
even for pages I see in the disk cache.
- I don't want to use overriding in refresh_patterns, because I don't
understand the problem yet, I don't know what problem would this hack hide
(and for how long).
- I don't want to move away from the current platform and version if
possible because this has LTS support and we'll have many proxy servers if
we finally figure out the right config.
- Strange thing, the old proxy seems to return stuff with HTTP/1.0 and the
new one with HTTP/1.1 in the same browser. No idea why.

What I've tried:
- Compared my squid.conf files - nothing special.
- Googling and mailing list archives - only found common MISS problems that
don't apply to my case.
- Have even experimented removing max-age from the headers sent by the
server and only featuring public, also set Last-Modified 10 minutes in the
past - no change.
- I've only moved one low-traffic live site to the new proxy so I can test
the old one and the new with the same app server engine.
- I know of Vary:Accept-Encoding issues with testing, so I test in the same
browser, clearing the cache before the second page access. With this, I see
HITs on the old server and MISS for the new.
- Heavy logging and debugging, checking out HTTP headers too - seems okay.
The same HTTP headers yield in HITs on the old server and MISS on the new
one.

I've collected some resources:
- Old server squid.conf - http://pastebin.com/h0C7t96n
- New server squid.conf - http://pastebin.com/KaHDVWYt
- Examples that gets cached on both servers - http://pastebin.com/Be4RqVLq
 , http://pastebin.com/yVDeuyQp
- Example that gets cached on the old server but is a MISS on the new one -
http://pastebin.com/VvTU6ieR vs http://pastebin.com/ysKJwbmh
- Old server firewall settings - http://pastebin.com/v688dDMU
- New server firewall settings - http://pastebin.com/HyzGdjb4

Any tips, hints? This is driving me crazy!

Best regards,
Greg
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150224/c8f8fe70/attachment.htm>

From yvoinov at gmail.com  Tue Feb 24 15:19:17 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 24 Feb 2015 21:19:17 +0600
Subject: [squid-users] Need better debug_options values to track down
 cache MISSes
In-Reply-To: <CALXdjAKY1Vz9jX0gbezXb85SgyVsYxmhUc+XqR1UHtc4nbXXgA@mail.gmail.com>
References: <CALXdjAKvTcvDhcgih3-FXuohh1A5xVqMvv792KXPN7ZifLSVkw@mail.gmail.com>
 <CALXdjAKY1Vz9jX0gbezXb85SgyVsYxmhUc+XqR1UHtc4nbXXgA@mail.gmail.com>
Message-ID: <54EC9675.3020908@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


24.02.15 21:14, Greg ?????:
> Hi all,
> 
> so, there's my proxy problem I couldn't crack, even after spending
> 2+ days tweaking-googling-debugging. :(
> 
> The problem: my _new_ Squid installation (Ubuntu 14 LTS with Squid
> 3.3.8) won't cache most pages the old Squid does (old Fedora with
> Squid 3.1.15).

Both versions are antique.

Man, you change one rancid meat to another rancid meat.

Just FYI - current Squid version at least 3.4.12. Oh, this branch is
already deprecated... shit, current version is 3.5.2!

This must be your starting point.
> 
> Infos: - Simple reverse proxy, port 80 only, one uplink straight to
> the app servers. (The old one points to a load balancer. For
> testing purposes and seeing the mail on "Thu, 4 Apr 2013 16:54:10
> -0700", I'm pointing the new one to a specific app server.) -
> Pretty standard configuration, standard refresh_patterns. (I'd be 
> surprised if it was a config problem since ICOs are cached well.) -
> I have disk caching on the new one, the disk cache has been
> initialised with -z. - The old one has a very relaxed iptables, the
> new one has ufw, later set to allow port 80 and 22 only for
> incoming connections. - Clocks are in sync using ntpd - the old one
> has +20min delay (ie. shows a later time than now). Since it's the
> live one, it's working and it handles a lot of load well, I haven't
> dared to correct it. - The new Squid gives HITs for favicon.ico and
> RSS feeds only - these have different headers and mimetypes
> compared to HTML files (and that's by design). - This new server
> seems to save accessed HTML files in the disk cache but still gives
> X-Cache-Lookup:MISS for all of them later. - I debugged using
> debug_options and logging: headers look okay (Cache-Control,
> Pragma, Vary - pasted below), stale/fresh calculation looks okay
> (pages are deemed fresh). - The best I got so far is this:
> "client_side_reply.cc(1618) identifyFoundObject:
> clientProcessRequest2: StoreEntry is NULL -  MISS", even for pages
> I see in the disk cache. - I don't want to use overriding in
> refresh_patterns, because I don't understand the problem yet, I
> don't know what problem would this hack hide (and for how long). -
> I don't want to move away from the current platform and version if 
> possible because this has LTS support and we'll have many proxy
> servers if we finally figure out the right config. - Strange thing,
> the old proxy seems to return stuff with HTTP/1.0 and the new one
> with HTTP/1.1 in the same browser. No idea why.
> 
> What I've tried: - Compared my squid.conf files - nothing special. 
> - Googling and mailing list archives - only found common MISS
> problems that don't apply to my case. - Have even experimented
> removing max-age from the headers sent by the server and only
> featuring public, also set Last-Modified 10 minutes in the past -
> no change. - I've only moved one low-traffic live site to the new
> proxy so I can test the old one and the new with the same app
> server engine. - I know of Vary:Accept-Encoding issues with
> testing, so I test in the same browser, clearing the cache before
> the second page access. With this, I see HITs on the old server and
> MISS for the new. - Heavy logging and debugging, checking out HTTP
> headers too - seems okay. The same HTTP headers yield in HITs on
> the old server and MISS on the new one.
> 
> I've collected some resources: - Old server squid.conf -
> http://pastebin.com/h0C7t96n - New server squid.conf -
> http://pastebin.com/KaHDVWYt - Examples that gets cached on both
> servers - http://pastebin.com/Be4RqVLq ,
> http://pastebin.com/yVDeuyQp - Example that gets cached on the old
> server but is a MISS on the new one - http://pastebin.com/VvTU6ieR
> vs http://pastebin.com/ysKJwbmh - Old server firewall settings -
> http://pastebin.com/v688dDMU - New server firewall settings -
> http://pastebin.com/HyzGdjb4
> 
> Any tips, hints? This is driving me crazy!
> 
> Best regards, Greg
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU7JZ1AAoJENNXIZxhPexGvCgH/0RdkThse93Y3rzakMIN2dTC
btiS46wVFqIm/vDtDoIS3qjHiqNn3Q1Xz7LQkUcJSbhkrTwTQFELLOKHWxDsQTan
Ar2cVWKVwACR+xaW4gcNFBarWxOPnG9Wbe2eDh2CskcSu2rHE4busd9eOyMnFkAk
GSEypJliKa+vyfK0QbUK/o3xJh9C9ROyPbZ4K4VG7ioke29jUfr7sPhPCIAknwcX
HHuOLc5lUb5bfbdxY//StrPSe1EagoFj8ykoQbmKjv/FXkkF4Epte9GXi5atz6LL
T7AhqZzPD4YQanROxtCw/jW8cglI62c1O8WbpREmf5z7aXrKaNxkYInmGAI3E7Y=
=7xak
-----END PGP SIGNATURE-----


From ahmed.zaeem at netstream.ps  Wed Feb 25 01:34:43 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Tue, 24 Feb 2015 17:34:43 -0800
Subject: [squid-users] many vms behind router to same proxy ips problems
	!
In-Reply-To: <54E7CE50.4000107@treenet.co.nz>
References: <008201d04d77$02fbd590$08f380b0$@netstream.ps>
 <54E7CE50.4000107@treenet.co.nz>
Message-ID: <00eb01d0509b$3c9539f0$b5bfadd0$@netstream.ps>

Amos , ........ you are the rock !!
It worked with 3.5.1 

Thank you a lot and appreciate ur help

regards

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, February 20, 2015 4:16 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] many vms behind router to same proxy ips problems !

On 21/02/2015 2:37 p.m., snakeeyes wrote:
> Hi ,
> 
>  
> 
> I have  squid  with many ips already installed with and configured 
> well with tcp_outgoing directive.
> 

You have two problems:


1) Your Squid version is too old.


Squid-3.1 does not contain the IPv6 split-stack bug fixes that allow tcp_outgoing_address to deal with persistent connections to servers, or to select an outgoing IP per-message.



2) "myip" ACL ties the tcp_outgoing_address to the *Squid* receiving IP address, not the client IP.

If the packets just happen to go from PC2 to the Squid receiving IP for
client1 for any reason they will use client1's assigned outgoing IP.


You require Squid-3.3 or later to do what you are attempting.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From longbeakedechidna1 at gmail.com  Tue Feb 24 16:11:11 2015
From: longbeakedechidna1 at gmail.com (Greg)
Date: Tue, 24 Feb 2015 16:11:11 +0000
Subject: [squid-users] Need better debug_options values to track down
 cache MISSes
Message-ID: <CALXdjAJmkRoKd8aetPVJKDL7WgU5M39D0xzBAUTpm8jFPM73Eg@mail.gmail.com>

> From: Pavel Kazlenka <pavel.kazlenka at measurement-factory.com>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Need better debug_options values to track
>         down cache MISSes
> Message-ID: <54EC9147.6070301 at measurement-factory.com>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
> Hi Greg,
>
> I use this combo to check if request is cached or no and why:
> debug_options 20,9 27,9 31,9 70,9 82,9 22,9 84,9 90,9
>
> Then in cache.log file you can search by 'YES' or 'NO' (uppercase) to
> see if the content is cacheable (and cached) or not and the reason of
> this decision. Hope this will help.

Thanks, that was useful! I've tried that; the results:
- First access (at least from my computer in this session):
http://pastebin.com/EHNJ9N6F
- Second access (plus HTTP headers): http://pastebin.com/u8ZsHQfk

It's rather strange. Even though it's "cacheableReply: YES", it seems
that the system stores the page with key
C284A5F1C95D3B6C6D0F37A54517BEC9 but searches for it with
F588DBC3D17E4F32409C1AF22FC627FE in both test cases. (But in all
fairness, these might be different keys, I don't know the code too
well.)

Could you take a look at the debug log?

Best regards,
Greg


From longbeakedechidna1 at gmail.com  Tue Feb 24 16:31:06 2015
From: longbeakedechidna1 at gmail.com (Greg)
Date: Tue, 24 Feb 2015 16:31:06 +0000
Subject: [squid-users] Tracking down cache MISSes
Message-ID: <CALXdjAKUYmqrGV_MkeXtegsEXifC-dAxeOcHFx0YENPH7RkxuQ@mail.gmail.com>

>> Hi all,
>>
>> so, there's my proxy problem I couldn't crack, even after spending
>> 2+ days tweaking-googling-debugging. :(
>>
>> The problem: my _new_ Squid installation (Ubuntu 14 LTS with Squid
>> 3.3.8) won't cache most pages the old Squid does (old Fedora with
>> Squid 3.1.15).
>
> Both versions are antique.
>
> Man, you change one rancid meat to another rancid meat.
>
> Just FYI - current Squid version at least 3.4.12. Oh, this branch is
> already deprecated... shit, current version is 3.5.2!
>
> This must be your starting point.

Thanks for your comment. Please note that this version is what's
supported by Ubuntu LTS for the next 5 years. This happens with all
packages - LTS maintainers choose a stable version and merge security
updates into it, so it stays secure and needs no config updates for 5
years. This is just we need, and it has worked well for Ubuntu 10
(squid 2.7.STABLE7-1ubuntu12.6 is still being supported until this
April!), but it has EOL now and we have to upgrade.

I'd very much like to stay inside this safe zone with our servers. I
understand that others might not do so - please understand some people
do though.

Best regards,
Greg


From fredbmail at free.fr  Tue Feb 24 16:34:34 2015
From: fredbmail at free.fr (FredB)
Date: Tue, 24 Feb 2015 17:34:34 +0100 (CET)
Subject: [squid-users] Need tips in order to force youtube in HTTP only
In-Reply-To: <54EC5D5F.3040408@articatech.com>
Message-ID: <1629259687.378566688.1424795674205.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hi David, 

I quickly tested something. 
with E2Guardian I changed my header: 

Mozilla/5.0 (Windows NT 6.1; WOW64; rv:35.0) Gecko/20100101 Firefox/35.0
By
Mozilla/5.0 (Windows NT 6.1; WOW64; rv:35.0) Gecko/20100101

Now I can use http://www.google.fr and http://www.youtube.com without redirection.
As I said it's just a quick test but it's seems works. 

Perhaps you can try something like this:

1 With Squid change your header 
2 Use a redirection https://www.google.fr to http://www.google.fr

----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From yvoinov at gmail.com  Tue Feb 24 16:37:22 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 24 Feb 2015 22:37:22 +0600
Subject: [squid-users] Need tips in order to force youtube in HTTP only
In-Reply-To: <1629259687.378566688.1424795674205.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1629259687.378566688.1424795674205.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <54ECA8C2.7080906@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Fred,

this is dirty hack and can be not work with HSTS-enabled browsers.


24.02.15 22:34, FredB ?????:
> Hi David,
> 
> I quickly tested something. with E2Guardian I changed my header:
> 
> Mozilla/5.0 (Windows NT 6.1; WOW64; rv:35.0) Gecko/20100101
> Firefox/35.0 By Mozilla/5.0 (Windows NT 6.1; WOW64; rv:35.0)
> Gecko/20100101
> 
> Now I can use http://www.google.fr and http://www.youtube.com
> without redirection. As I said it's just a quick test but it's
> seems works.
> 
> Perhaps you can try something like this:
> 
> 1 With Squid change your header 2 Use a redirection
> https://www.google.fr to http://www.google.fr
> 
> ----
> 
> Regards,
> 
> Fred
> 
> http://numsys.eu http://e2guardian.org
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU7KjCAAoJENNXIZxhPexGDeIH/iaRnfO+ZnEDmyOjnSsRScJz
YtmsNNrRnRzn1YJerhJkHPCpxe3xr+4es+qpI7teKq4x+jvzk/coJHX0KGSWCMSc
nej2ZKPWa/lY2kDOlzKC/hWBNtCJOeO4AGDjxAaPyEZOyYVDaVsYhGAVAHjpJjRv
PUbrGQHUsX3RZgvwOo8fMyeU37gQrs9pv3H5aeD9YuXSPIbI/KMzrOmEnBmN5rYW
ucoyXtPeHqaTm3w09FyylvyL+qcTKo8Z+POddqA+hTnldRG/pxMWBYM4F5J6puKi
OVbP/4RPCa/2pU7YEjNNiem+zjiXMvS8zbvw9U5V70g/it/MJ1mx14+2RJQ8/cw=
=q+WD
-----END PGP SIGNATURE-----


From fredbmail at free.fr  Tue Feb 24 17:10:48 2015
From: fredbmail at free.fr (FredB)
Date: Tue, 24 Feb 2015 18:10:48 +0100 (CET)
Subject: [squid-users] Need tips in order to force youtube in HTTP only
In-Reply-To: <54ECA8C2.7080906@gmail.com>
Message-ID: <1229813579.378637333.1424797848498.JavaMail.root@zimbra4-e1.priv.proxad.net>

It's just a test

But yes and it didn't works good with youtube ... 
Except with google search and FF 35 no problem at all, I'm surfing without any SSL 


----

Regards,

Fred

http://numsys.eu
http://e2guardian.org



From hack.back at hotmail.com  Tue Feb 24 23:43:24 2015
From: hack.back at hotmail.com (HackXBack)
Date: Tue, 24 Feb 2015 15:43:24 -0800 (PST)
Subject: [squid-users] again i lost my cache with upgrading for 3.5.2
In-Reply-To: <54EBD39A.7020907@ngtech.co.il>
References: <1424736987209-4670035.post@n4.nabble.com>
 <54EBD39A.7020907@ngtech.co.il>
Message-ID: <1424821404283-4670057.post@n4.nabble.com>

this is not logic i use same conf in 3.4 and it worked like a charm !! even
the same hardware !!
what is the difference between 3.4  and 3.5 ? or what option in 3.4 if used
in 3.5 will make it crashed ?
i didnt fine and sense !!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/again-i-lost-my-cache-with-upgrading-for-3-5-2-tp4670035p4670057.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Feb 25 00:21:08 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 25 Feb 2015 13:21:08 +1300
Subject: [squid-users] Authenication denies access to ports
In-Reply-To: <1424759151676-4670040.post@n4.nabble.com>
References: <1424759151676-4670040.post@n4.nabble.com>
Message-ID: <857737f0dfc59e7700423d8afb9fb530@treenet.co.nz>

On 2015-02-24 19:25, zanettiza wrote:
> Hi Everyone,I've searched and search but have not found an answer to my
> question.I'm running CentOS 7 and Squid 3.3.4. When I insert 
> "http_access
> allow Safe_ports" AFTER "http_access allow authenticated_users" I have 
> no
> access to ports listed under my Safe_ports ACL, however when I put it 
> before
> then everything works just fine, obviously that is then ignoring
> authentication.Any thoughts on how I can overcome this? I have tried 
> many
> different configurations but nothing really works.Thanks!
> 

http://wiki.squid-cache.org/SquidFaq/OrderIsImportant
http://wiki.squid-cache.org/SquidFaq/SquidAcl

There is a very big difference between your two policies:

A)
  # allow unlimited access to all "safe" ports
  http_access allow Safe_ports

  # then authenticate access to unsafe ports
  http_access allow authenticated

B)
  # allow access to anywhere authenticated
  http_access allow authenticated

  # then allow access to safe ports if authentication fails
  http_access allow Safe_ports


versus the squid default security settings:

C)
  # prevent access to unsafe ports
  http_access deny !Safe_ports

  # prevent use of CONNECT tunnels by non-HTTPS
  http_access deny CONNECT !SSL_ports

  # then allow access (to safe ports and HTTPS) if authenticated
  http_access allow authenticated


Amos


From ip2trama at gmail.com  Wed Feb 25 01:52:50 2015
From: ip2trama at gmail.com (Pedro Valera)
Date: Wed, 25 Feb 2015 01:52:50 +0000
Subject: [squid-users] Squid-users, estos descuentos te van a encantar
Message-ID: <f6173bb9d4b5e5b0b055696065edd77ae5257800@yullove.it>

Invitacion
  http://join.yullove.it/r?001:eNqNT8uOgjAA/Bq9bNaUR1s5cGAFF3Vd4mp8XQilVVsoYC2ofP02nva4yRxmMpPJzElqX7OHHpaVbw1b/6J1M3CCgT01eHupF1XszG9aZZrX1ajkFa9HeS1HDTNex1VW/g0MnKkpCVdTuSufSRM/F/McWv3sZ3Nxv7ESn10KnHuwd4VYvHOPuCICs6hQd8bboz6Iyf5jt8llUdRXFGtolyjnMU/7KIpp+Lj0ebAe37IvxTE67en1ub6mqb3wQm/Zhsv7qrNku662QZaIJBBHfCaHRLOJpNt5cTDXEK86rplKJaO8lWZpY14iWRh2QhZ2CPGoSyCDBBAAIfIQQJBRinHGoA3xGIChLPz/Zn8BAANzfw== 
 
 
Hola Squid-users,
 
Quiero recomendarte Linio, la tienda online m?s grande de Latinoamerica. Tiene descuentos incre?bles y productos de todo tipo.
 
Si te suscribes a su newsletter a trav?s de mi invitaci?n, recibir?s S/.25 de descuento en tu primera compra.
 
?Con?cela! Yo creo que te gustar?
 
Pedro Valera 
 
 
 
SUSCRIBIRME http://join.yullove.it/r?001:eNqNT8uOgjAA/Bq5bNZUoK0cOLCCi7oucTW+LoTSqi0UsBZQv34bT3vcZA4zmclk5iS1r9ldW2Xl21brX7RuBk4wsKcGby/1ooqd+U2rTPO6Gpa84vUwr+WwYcbruMrKv4GBMzUl4Woqd+UjaeLHYp7D0XP2s7m431iJzy4FTh/sXSEW79wjrojALCpUz3h71Acx2X/sNrksivqKYg3tEuU85ukzimIa3i/PPFiPb9mX4hid9vT6WF/T1F54obdsw2W/6kayXVfbIEtEEogjPpNDotlE0u28OJhriFcd10ylklHeSrO0MS+RLAw7oRF2CPGoSyCDBBAAIfIQQJBRinHGoA3xGABLFv5/s78BW3OA 
 
 
 
 
Al hacer click en el link anterior, est?s aceptando la pol?tica de privacidad http://join.yullove.it/r?001:eNqNikEKwjAQRU+TbIQwNk5iF1kI0nsknSmGNm2Q0Xh8a08gvMV/nzcVCcIf0csarH6Fh0hV9qa6Yed02DFba2bJa97MuBVTeb/qM7/jmCnSL7FDmZW9T+7sbUo9XRIyJkiA6HoHDpnI+8jYob8C6DKHf9svZOowNA==  de Linio.com.pe adem?s de recibir notificaciones de sus ofertas y promociones.
Este mensaje ha sido enviado a trav?s de ip2trama at gmail.com para que descubras Linio.com.pe. Si no quieres recibir otras recomendaciones para conocer Linio.com.pe, puedes desuscribirte aqu? http://join.yullove.it/r?001:eNqNi0EOwiAQRU8DGxOCpQN2wcLE9B6OTFMs0MYORm8v6QlM/uK/n/enzJ7pwzIV38vqZ+ZNmKvoxpbTQUd9rrGob01pfZOK3JZa9or74xWR1Da305gXYW6TPTuDOIQegQA1agA7WG2BQnDuTtCBu2gt8+L/dX/4/DF3 .
? 2014, Linio o sus compa??as afiliadas. Todos los derechos reservados.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150225/2aebc9f6/attachment.htm>

From dan at getbusi.com  Wed Feb 25 02:11:03 2015
From: dan at getbusi.com (dan at getbusi.com)
Date: Tue, 24 Feb 2015 18:11:03 -0800 (PST)
Subject: [squid-users] assertion failed: client_side.cc:1515:
 "connIsUsable(http->getConn())
In-Reply-To: <1424749675359.dfea22c5@Nodemailer>
References: <1424749675359.dfea22c5@Nodemailer>
Message-ID: <1424830263614.384f0f01@Nodemailer>

By the way, I think Eliezer suggested I should file a bug report. There is in fact one already filed here:
http://bugs.squid-cache.org/show_bug.cgi?id=3930




Which brings me to my next question ...



Amos, is it possible to sponsor bug fixes?

On Tue, Feb 24, 2015 at 2:47 PM, null <dan at getbusi.com> wrote:

> This is kind of off-topic but on one of our deployments this crash is now consistently deadlocking squid whenever it occurs rather than just ending the process. Meaning that is can?t be restarted by any means except kill -9, which obviously a huge disruption to hundreds of clients and incredibly frustrating for the sysadmin.
> Nothing has really changed in the configuration since this deadlocking started happening ?but I?ve noticed when that there?s no longer anything in /var/log/messages from abrtd etc. like there usually would be.
> I have a very similar deployment where this still crashes ?cleanly?.
> Both on CentOS 6.6 and Squid 3.4.12.
> Anyone have a clue what might cause this ?deadlocking? type behaviour after an ?assertion failed" crash?
> On Fri, Feb 20, 2015 at 5:23 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>> On 20/02/2015 7:15 p.m., Dan Charlesworth wrote:
>>> Thanks Amos -
>>> 
>>> So then it more than likely is related to our external ACLs that deal with the HTTP response?
>>> 
>> I think they may be making the issue more noticable by slowing down the
>> request processing. But Squid should not be getting into that state
>> either way.
>> Amos
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150224/031fad1f/attachment.htm>

From squid3 at treenet.co.nz  Wed Feb 25 02:37:32 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 25 Feb 2015 15:37:32 +1300
Subject: [squid-users] Log proxy hostname along with HTTP access URI
In-Reply-To: <C2F5AD5D-BD66-4AC1-BF1E-E06DD8B7805A@decycive.com>
References: <5C5B6F1F-AA35-4839-91AD-583765117A69@decycive.com>
 <54EC8D32.9030005@artifact-software.com>
 <C2F5AD5D-BD66-4AC1-BF1E-E06DD8B7805A@decycive.com>
Message-ID: <86728cbb757b79758ddcb410a4132eae@treenet.co.nz>

On 2015-02-25 03:44, Peter Oruba wrote:
>> Am 24.02.2015 um 15:39 schrieb Ron Wheeler :
>> 
>> On 24/02/2015 9:04 AM, Peter Oruba wrote:
>>> Hello everybody,
>>> 
>>> I?d like to distinguish multiple clients that are behind NAT from 
>>> Squid?s perspective. Proxy authentication or sessions are not an 
>>> option for different reasons and the idea that came up was to assign 
>>> each client a unique hostname through which Squid would be addressed 
>>> (e.g. UUID1.proxy.example.com <http://uuid1.proxy.example.com/> and 
>>> UUID2.proxy.example.com <http://uuid2.proxy.example.com/>) A DNS 
>>> wildcard entry *.proxy.example.com <http://proxy.example.com/> would 
>>> make sure each proxy referral points to the same machine. Question: 
>>> Is there a way to let Squid log the DNS name through which a client 
>>> referred to it? I was not able to find any example in this regard and 
>>> I assume that the proxy hostname is ?lost? after the client's DNS 
>>> lookup and that the client-proxy connection is established.

I think there is a major misunderstanding about how things work in the 
above.

With NAT authentication is not possible because the browser is not aware 
its talking to a proxy. It thinks its talking to the origin hostname. 
Given that situation, what proxy hostname are you expecting the browser 
to be "using" ?

The origin server hostname the browser was connecting to is in the Host: 
header and already logged as the URL hostname in access.log.


>> Not a direct answer but...
>> Is it possible to get this info from the log kept by the service(http) 
>> that is getting the request?
>> 
> Virtual hosts on web servers?  Yes, the same principle, but on Squid.

If you are using virtual hosting with Squid reverse-proxy the 
client/browser destination domain (big hint in that name) and is again 
in the Host header and logged as the URL domain name.


Amos


From squid3 at treenet.co.nz  Wed Feb 25 03:03:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 25 Feb 2015 16:03:10 +1300
Subject: [squid-users]
	=?utf-8?q?assertion_failed=3A_client=5Fside=2Ecc=3A?=
	=?utf-8?b?MTUxNTogImNvbm5Jc1VzYWJsZShodHRwLT5nZXRDb25uKCkp?=
In-Reply-To: <1424830263614.384f0f01@Nodemailer>
References: <1424749675359.dfea22c5@Nodemailer>
 <1424830263614.384f0f01@Nodemailer>
Message-ID: <79efaedce25a8b9d22b59625e158fe38@treenet.co.nz>

On 2015-02-25 15:11, dan at getbusi.com wrote:
> By the way, I think Eliezer suggested I should file a bug report.
> There is in fact one already filed here:
> http://bugs.squid-cache.org/show_bug.cgi?id=3930
> 
> 
> Which brings me to my next question ...
> 
> 
> 
> Amos, is it possible to sponsor bug fixes?

Of course. Though be aware that if its an outstanding bug it means we 
are having difficulty resolving it for some reason so we can't really 
provide any guarantees about what it will take to fix.

So far the issue seems to be a lack of information, with a stack trace 
only coming in recently and the build and config details having come 
from someone other than the one with stack trace. Ideally we need all 
the details from a single proxy instance encountering the crash.

Amos



From squid3 at treenet.co.nz  Wed Feb 25 03:30:31 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 25 Feb 2015 16:30:31 +1300
Subject: [squid-users] Tracking down cache MISSes
In-Reply-To: <CALXdjAKUYmqrGV_MkeXtegsEXifC-dAxeOcHFx0YENPH7RkxuQ@mail.gmail.com>
References: <CALXdjAKUYmqrGV_MkeXtegsEXifC-dAxeOcHFx0YENPH7RkxuQ@mail.gmail.com>
Message-ID: <c57f540e4c6c9ea8465b7bc0760e2346@treenet.co.nz>

On 2015-02-25 05:31, Greg wrote:
>>> Hi all,
>>> 
>>> so, there's my proxy problem I couldn't crack, even after spending
>>> 2+ days tweaking-googling-debugging. :(
>>> 
>>> The problem: my _new_ Squid installation (Ubuntu 14 LTS with Squid
>>> 3.3.8) won't cache most pages the old Squid does (old Fedora with
>>> Squid 3.1.15).
>> 
>> Both versions are antique.
>> 
>> Man, you change one rancid meat to another rancid meat.
>> 
>> Just FYI - current Squid version at least 3.4.12. Oh, this branch is
>> already deprecated... shit, current version is 3.5.2!
>> 
>> This must be your starting point.
> 
> Thanks for your comment. Please note that this version is what's
> supported by Ubuntu LTS for the next 5 years. This happens with all
> packages - LTS maintainers choose a stable version and merge security
> updates into it, so it stays secure and needs no config updates for 5
> years. This is just we need, and it has worked well for Ubuntu 10
> (squid 2.7.STABLE7-1ubuntu12.6 is still being supported until this
> April!), but it has EOL now and we have to upgrade.


And these types of problem are the cost. Ubuntu and other distros 
providing long LTS support choose not to backport bug fixes *unless* its 
a security fix. That is their choice, and your choice to accept by using 
their distro version.

For the record this appears to be bug 3806 which was fixed in 3.3.12 
just over a year ago. 3.3.8 is just too old by ~4 months.


> 
> I'd very much like to stay inside this safe zone with our servers. I
> understand that others might not do so - please understand some people
> do though.


Amos


From alex at samad.com.au  Wed Feb 25 04:18:03 2015
From: alex at samad.com.au (Alex Samad)
Date: Wed, 25 Feb 2015 15:18:03 +1100
Subject: [squid-users] Interesting problem
Message-ID: <CAJ+Q1PXnDvOsxByFcn=ihmgb+fL5iaZkv4w-P+58w79db3=ftw@mail.gmail.com>

Hi

I am running squid on Centos 6.5
squid-3.1.10-29.el6.x86_64

when I browse to https://www.quadriserv.com from IE or Chrome via the
squid proxy, it seems to corrupt the server cert.

when i browse to the site by passing squid it works fine.

I have tried wget from the squid box works fine also tried openssl s_client

openssl s_client -connect www.quadriserv.com:443 -showcerts </dev/null | less

-----BEGIN CERTIFICATE-----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-----END CERTIFICATE-----

seems to be okay

but the one thing I can't do it verify it. seems lilke
C=US, O=Network Solutions L.L.C., CN=Network Solutions Certificate Authority
is missing from my rootCA bundle.

would that be enough to cause this ?

Alex


From dan at getbusi.com  Wed Feb 25 05:12:25 2015
From: dan at getbusi.com (dan at getbusi.com)
Date: Tue, 24 Feb 2015 21:12:25 -0800 (PST)
Subject: [squid-users] assertion failed: client_side.cc:1515:
 "connIsUsable(http->getConn())
In-Reply-To: <79efaedce25a8b9d22b59625e158fe38@treenet.co.nz>
References: <79efaedce25a8b9d22b59625e158fe38@treenet.co.nz>
Message-ID: <1424841145197.56934ef5@Nodemailer>

I?d be happy to provide a recent backtrace to match the config details but abrtd always seems to shit the bed:





Feb 25 10:19:14 hostname abrt[10776]: Saved core dump of pid 63925 (/usr/sbin/squid) to /var/spool/abrt/ccpp-2015-02-25-10:19:08-63925 (525869056 bytes)

Feb 25 10:19:14 hostname abrtd: Directory 'ccpp-2015-02-25-10:19:08-63925' creation detected


Feb 25 10:19:15 hostname squid[63923]: Squid Parent: (squid-1) process 63925 exited due to signal 6 with status 0


Feb 25 10:19:15 hostname abrtd: Package 'squid' isn't signed with proper key


Feb 25 10:19:15 hostname abrtd: 'post-create' on '/var/spool/abrt/ccpp-2015-02-25-10:19:08-63925' exited with 1


Feb 25 10:19:15 hostname abrtd: Deleting problem directory '/var/spool/abrt/ccpp-2015-02-25-10:19:08-63925?





Not sure what counts as a ?proper key? we compile our own squid RPMs and sign them ourselves for our own private repo.

On Wed, Feb 25, 2015 at 2:03 PM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 2015-02-25 15:11, dan at getbusi.com wrote:
>> By the way, I think Eliezer suggested I should file a bug report.
>> There is in fact one already filed here:
>> http://bugs.squid-cache.org/show_bug.cgi?id=3930
>> 
>> 
>> Which brings me to my next question ...
>> 
>> 
>> 
>> Amos, is it possible to sponsor bug fixes?
> Of course. Though be aware that if its an outstanding bug it means we 
> are having difficulty resolving it for some reason so we can't really 
> provide any guarantees about what it will take to fix.
> So far the issue seems to be a lack of information, with a stack trace 
> only coming in recently and the build and config details having come 
> from someone other than the one with stack trace. Ideally we need all 
> the details from a single proxy instance encountering the crash.
> Amos
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150224/4552ba72/attachment.htm>

From yvoinov at gmail.com  Wed Feb 25 08:40:33 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 25 Feb 2015 14:40:33 +0600
Subject: [squid-users] Interesting problem
In-Reply-To: <CAJ+Q1PXnDvOsxByFcn=ihmgb+fL5iaZkv4w-P+58w79db3=ftw@mail.gmail.com>
References: <CAJ+Q1PXnDvOsxByFcn=ihmgb+fL5iaZkv4w-P+58w79db3=ftw@mail.gmail.com>
Message-ID: <54ED8A81.7090401@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

In theory - yes. You must add all intermediate CA's to you openssl
cert's bundle manually.

25.02.15 10:18, Alex Samad ?????:
> Hi
> 
> I am running squid on Centos 6.5 squid-3.1.10-29.el6.x86_64
> 
> when I browse to https://www.quadriserv.com from IE or Chrome via
> the squid proxy, it seems to corrupt the server cert.
> 
> when i browse to the site by passing squid it works fine.
> 
> I have tried wget from the squid box works fine also tried openssl
> s_client
> 
> openssl s_client -connect www.quadriserv.com:443 -showcerts
> </dev/null | less
> 
> -----BEGIN CERTIFICATE----- 
> MIIFyTCCBLGgAwIBAgIRAJfNWR72clr8JgXbvgA+uqgwDQYJKoZIhvcNAQEFBQAw 
> YjELMAkGA1UEBhMCVVMxITAfBgNVBAoTGE5ldHdvcmsgU29sdXRpb25zIEwuTC5D 
> LjEwMC4GA1UEAxMnTmV0d29yayBTb2x1dGlvbnMgQ2VydGlmaWNhdGUgQXV0aG9y 
> aXR5MB4XDTEzMTAyMjAwMDAwMFoXDTE4MDQxMjIzNTk1OVowgdMxCzAJBgNVBAYT 
> AlVTMQ4wDAYDVQQREwUxMDAxNzELMAkGA1UECBMCTlkxFjAUBgNVBAcTDU5ldyBZ 
> b3JrIENpdHkxEzARBgNVBAkTCjE0dGggRmxvb3IxFjAUBgNVBAkTDTUyOSBGaWZ0 
> aCBBdmUxFzAVBgNVBAoTDlF1YWRyaXNlcnYgSW5jMQswCQYDVQQLEwJJVDEhMB8G 
> A1UECxMYU2VjdXJlIExpbmsgU1NMIFdpbGRjYXJkMRkwFwYDVQQDFBAqLnF1YWRy 
> aXNlcnYuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA3Oa12dWu 
> 84WE2CeA0hVoFAw50+HpoB30Gi7uQ9/NK0A+gt8Igk5Vcwub6atldIiVc62k7v/9 
> DPZNoBxsOVopaTuDA54E6wnHEYve6VCr2xlQAnJEraIDZnvvQG/YnC8/ll44Yg06 
> MWVvMSug7oDSLhPPRX5ZjkQikpB6XKO1OhUUOJghUfo0YlG4I/8MBWpvJitaJOH9 
> pELBmepJFcpBvkij20Nk6MZu8kwzVs21Rp4FTEHpSH9Iagn7kw186nHqZkl+9D7e 
> UxM4IKc74j++Z2RjEPpPLLMcJYakD6kgkCUSkqiGmUS6R/4KBtbsE39lgJxNQDHU 
> Kqn5boHiyOjEZwIDAQABo4ICBjCCAgIwHwYDVR0jBBgwFoAUPEHijwgIqUwliY1t 
> xTjQ/IWMYhcwHQYDVR0OBBYEFCEGQeaf1tkMz9/3AA3y99GiCgzQMA4GA1UdDwEB 
> /wQEAwIFoDAMBgNVHRMBAf8EAjAAMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEF 
> BQcDAjB1BgNVHSAEbjBsMGAGDCsGAQQBhg4BAgEDATBQME4GCCsGAQUFBwIBFkJo 
> dHRwOi8vd3d3Lm5ldHdvcmtzb2x1dGlvbnMuY29tL2xlZ2FsL1NTTC1sZWdhbC1y 
> ZXBvc2l0b3J5LWNwcy5qc3AwCAYGZ4EMAQICMHoGA1UdHwRzMHEwNqA0oDKGMGh0 
> dHA6Ly9jcmwubmV0c29sc3NsLmNvbS9OZXR3b3JrU29sdXRpb25zX0NBLmNybDA3 
> oDWgM4YxaHR0cDovL2NybDIubmV0c29sc3NsLmNvbS9OZXR3b3JrU29sdXRpb25z 
> X0NBLmNybDBzBggrBgEFBQcBAQRnMGUwPAYIKwYBBQUHMAKGMGh0dHA6Ly93d3cu 
> bmV0c29sc3NsLmNvbS9OZXR3b3JrU29sdXRpb25zX0NBLmNydDAlBggrBgEFBQcw 
> AYYZaHR0cDovL29jc3AubmV0c29sc3NsLmNvbTAbBgNVHREEFDASghAqLnF1YWRy 
> aXNlcnYuY29tMA0GCSqGSIb3DQEBBQUAA4IBAQCsgRiTxwFDYa+3AZFzFj7XuhP3 
> LuEuI55Ppj0SwLfBjLeiHuQB616V536O1TWqbJGUc1KhXwiTh6kDFx5RXVGohV1f 
> qoaVFoKMkX+fVkG3VNjGmaqaZalweWRf0s6jMskWuSUQkWdADGnNCnqRxIrtyLfS 
> 7/OHak+o2W0R+0jdsiUiLC7iZLzgpdFwHUa1wEVSjz2rCaI0TjEDkUKGfDITzZ9J 
> IY64c7QiYjzNF/PzlCIpL6zwPqnswLp25WOPM1jE4mqsK/9Z6Q0SWckk8WRTnlQA 
> YIbTFxXiY5fkkc4wdNNJZDv2R/nW9VkkK4u4qiJQ5Q5Y3iqHic+D3GZ2l2nT 
> -----END CERTIFICATE-----
> 
> seems to be okay
> 
> but the one thing I can't do it verify it. seems lilke C=US,
> O=Network Solutions L.L.C., CN=Network Solutions Certificate
> Authority is missing from my rootCA bundle.
> 
> would that be enough to cause this ?
> 
> Alex _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU7YqBAAoJENNXIZxhPexGFi4H/idMIbVpk6GzwBP0QPm29eR+
JQCnuDRbqT8ZmTgaHTS2z6ho/RcaKfWjc59vLuA2P2Zoh6BqdM+DJJMaX8t5k+lL
DjXaLwjYruDu97BaW2dM1L2NBiUbQX0f41cSgQOonCbzOnRglZInG+3kD8Oag8er
/wOqRLjQPUdJBH/+j/fyZ3sQkRk0NoN906F5vsTY5Iv03ZMK0Ng7cVNAmEI+XxWH
4AY8K2TySbVHx0hstGRPCOf2fgqDVRnM6uQYQnMU59tt/Nz4mSVXenFWT2OyRLm2
ENRtJr9gExHuAJYaJsTWMySB1BVl7sLHz+V6Tv/v0AYF/jlAc6Q3F42lnjCH+lQ=
=7e/p
-----END PGP SIGNATURE-----


From longbeakedechidna1 at gmail.com  Wed Feb 25 10:46:10 2015
From: longbeakedechidna1 at gmail.com (Greg)
Date: Wed, 25 Feb 2015 10:46:10 +0000
Subject: [squid-users] Tracking down cache MISSes
In-Reply-To: <c57f540e4c6c9ea8465b7bc0760e2346@treenet.co.nz>
References: <CALXdjAKUYmqrGV_MkeXtegsEXifC-dAxeOcHFx0YENPH7RkxuQ@mail.gmail.com>
 <c57f540e4c6c9ea8465b7bc0760e2346@treenet.co.nz>
Message-ID: <CALXdjAKjqo+yZhKFH_UbZt+Uht+GLcuf-pwwyogB5A8nTXGJ1w@mail.gmail.com>

On 25 February 2015 at 03:30, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 2015-02-25 05:31, Greg wrote:
>>>> so, there's my proxy problem I couldn't crack, even after spending
>>>> 2+ days tweaking-googling-debugging. :(
>>>>
>>>> The problem: my _new_ Squid installation (Ubuntu 14 LTS with Squid
>>>> 3.3.8) won't cache most pages the old Squid does (old Fedora with
>>>> Squid 3.1.15).
>>>
>>>
>>> Both versions are antique.
>>>
>>> Man, you change one rancid meat to another rancid meat.
>>>
>>> Just FYI - current Squid version at least 3.4.12. Oh, this branch is
>>> already deprecated... shit, current version is 3.5.2!
>>>
>>> This must be your starting point.
>>
>>
>> Thanks for your comment. Please note that this version is what's
>> supported by Ubuntu LTS for the next 5 years. This happens with all
>> packages - LTS maintainers choose a stable version and merge security
>> updates into it, so it stays secure and needs no config updates for 5
>> years. This is just we need, and it has worked well for Ubuntu 10
>> (squid 2.7.STABLE7-1ubuntu12.6 is still being supported until this
>> April!), but it has EOL now and we have to upgrade.
>
>
>
> And these types of problem are the cost. Ubuntu and other distros providing
> long LTS support choose not to backport bug fixes *unless* its a security
> fix. That is their choice, and your choice to accept by using their distro
> version.

Exactly. I reckon it's not easy for everyone involved.

> For the record this appears to be bug 3806 which was fixed in 3.3.12 just
> over a year ago. 3.3.8 is just too old by ~4 months.

Wow, thanks! This is a breakthrough for me. Indeed, the requests that
do get cached don't have a Vary header.

This one's for you: http://goo.gl/qK5dE3

Now that I understand the problem I can think about a possible solution:
- Try to convince the Ubuntu 14 LTS maintainers to merge the fixes (
http://bugs.squid-cache.org/attachment.cgi?id=2854&action=diff and
http://bugs.squid-cache.org/attachment.cgi?id=2969&action=diff ). Not
sure about my chances ;)
- Create a new baseline server for our proxies with Ubuntu 12 LTS
(Squid 3.1.19-1ubuntu3.12.04.3) and upgrade to Ubuntu 16 LTS in 2017.
Pro: I tested it and that old Squid version doesn't seem to have this
bug. Will work and will be getting security fixes until 2017. Con:
well it's a rather old Squid and a less comfortable Ubuntu.
- Step out of the safe zone of LTS and install the latest stable
Squid. Pro: all the fixes and fresh code. Con: will have to manually
monitor the Squid security fixes, and on each security update upgrade
to the newest stable, manually testing if anything breaks,
merging/changing configs when necessary, then manually upgrade all
(10+) proxies - from now till forever.

Since I'm a ~beginner sysadmin, any thoughts and comments are warmly welcome.

Best regards,
Greg


From yvoinov at gmail.com  Wed Feb 25 10:48:26 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 25 Feb 2015 16:48:26 +0600
Subject: [squid-users] Tracking down cache MISSes
In-Reply-To: <CALXdjAKjqo+yZhKFH_UbZt+Uht+GLcuf-pwwyogB5A8nTXGJ1w@mail.gmail.com>
References: <CALXdjAKUYmqrGV_MkeXtegsEXifC-dAxeOcHFx0YENPH7RkxuQ@mail.gmail.com>
 <c57f540e4c6c9ea8465b7bc0760e2346@treenet.co.nz>
 <CALXdjAKjqo+yZhKFH_UbZt+Uht+GLcuf-pwwyogB5A8nTXGJ1w@mail.gmail.com>
Message-ID: <54EDA87A.2060304@gmail.com>


25.02.15 16:46, Greg ?????:
> On 25 February 2015 at 03:30, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> On 2015-02-25 05:31, Greg wrote:
>>>>> so, there's my proxy problem I couldn't crack, even after spending
>>>>> 2+ days tweaking-googling-debugging. :(
>>>>>
>>>>> The problem: my _new_ Squid installation (Ubuntu 14 LTS with Squid
>>>>> 3.3.8) won't cache most pages the old Squid does (old Fedora with
>>>>> Squid 3.1.15).
>>>>
>>>> Both versions are antique.
>>>>
>>>> Man, you change one rancid meat to another rancid meat.
>>>>
>>>> Just FYI - current Squid version at least 3.4.12. Oh, this branch is
>>>> already deprecated... shit, current version is 3.5.2!
>>>>
>>>> This must be your starting point.
>>>
>>> Thanks for your comment. Please note that this version is what's
>>> supported by Ubuntu LTS for the next 5 years. This happens with all
>>> packages - LTS maintainers choose a stable version and merge security
>>> updates into it, so it stays secure and needs no config updates for 5
>>> years. This is just we need, and it has worked well for Ubuntu 10
>>> (squid 2.7.STABLE7-1ubuntu12.6 is still being supported until this
>>> April!), but it has EOL now and we have to upgrade.
>>
>>
>> And these types of problem are the cost. Ubuntu and other distros providing
>> long LTS support choose not to backport bug fixes *unless* its a security
>> fix. That is their choice, and your choice to accept by using their distro
>> version.
> Exactly. I reckon it's not easy for everyone involved.
>
>> For the record this appears to be bug 3806 which was fixed in 3.3.12 just
>> over a year ago. 3.3.8 is just too old by ~4 months.
> Wow, thanks! This is a breakthrough for me. Indeed, the requests that
> do get cached don't have a Vary header.
>
> This one's for you: http://goo.gl/qK5dE3
>
> Now that I understand the problem I can think about a possible solution:
> - Try to convince the Ubuntu 14 LTS maintainers to merge the fixes (
> http://bugs.squid-cache.org/attachment.cgi?id=2854&action=diff and
> http://bugs.squid-cache.org/attachment.cgi?id=2969&action=diff ). Not
> sure about my chances ;)
Try it. They just men the same as we.

> - Create a new baseline server for our proxies with Ubuntu 12 LTS
> (Squid 3.1.19-1ubuntu3.12.04.3) and upgrade to Ubuntu 16 LTS in 2017.
> Pro: I tested it and that old Squid version doesn't seem to have this
> bug. Will work and will be getting security fixes until 2017. Con:
> well it's a rather old Squid and a less comfortable Ubuntu.
> - Step out of the safe zone of LTS and install the latest stable
> Squid. Pro: all the fixes and fresh code. Con: will have to manually
> monitor the Squid security fixes, and on each security update upgrade
> to the newest stable, manually testing if anything breaks,
> merging/changing configs when necessary, then manually upgrade all
> (10+) proxies - from now till forever.
>
> Since I'm a ~beginner sysadmin, any thoughts and comments are warmly welcome.
>
> Best regards,
> Greg
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From CLmjmonaghan at glowmail.org.uk  Wed Feb 25 12:22:41 2015
From: CLmjmonaghan at glowmail.org.uk (Mark Monaghan)
Date: Wed, 25 Feb 2015 12:22:41 +0000
Subject: [squid-users] Basic LDAP Authentication
Message-ID: <1424866961580.44143@glowmail.org.uk>

Hi All,

          I'm wondering if anyone can help me with the following issue I'm having getting various non-domain devices (mainly tablets, but some non-domain windows and apple mac computers) working with the basic_ldap_auth helper. I've had a good search of the mailing list, as well as a huge trawl of the internet, but I cannot get the helper to work within squid, and all information points to the fact that I've got the command set up as it should be.


Testing on the command line works perfectly, with the helper returning the correct information. As soon as I attempt to do the same through squid, it fails, returning technically nothing.


I've even attempted different versions, from 3.2 right through to the latest 3.5, just in case there was a bug with one of the builds on the helper. All have the same result.


In production, I've got the proxy working with domain devices via kerberos authentication perfectly, but the basic ldap authentication fails. So I've got a development system where the config has been stripped right back to check the LDAP authentication, and the results are the same, so I know that I'm not having problems with any other authentication method failover.


If I put the following line on the cli, then a domain username and password, everything returns normally:


/usr/lib64/squid/basic_ldap_auth -d -v 3 -R -b "dc=domain,dc=com" -D "CN=KerbAuth,OU=ServiceAccounts,DC=domain,DC=com" -W /etc/squid/kerbauth -f sAMAccountName=%s -u uid -h windows2012r2.domain.com


Output:


ctest ctest3
basic_ldap_auth.cc(684): pid=20130 :user filter 'sAMAccountName=ctest', searchbase 'dc=domain,dc=com'
basic_ldap_auth.cc(739): pid=20130 :attempting to authenticate user 'CN=Test User,OU=Dept1,OU=Dept2,OU=Dept3,OU=Dept4,OU=Company,DC=domain,DC=com'
OK

However, when used within the squid.conf file, when a user attempts to authenticate, the output in the cache.log is this:

basic_ldap_auth.cc(684): pid=20006 :user filter 'sAMAccountName=0', searchbase 'dc=domain,dc=com'
basic_ldap_auth.cc(706): pid=20006 :Ldap search returned nothing


I'm at a complete loss as to what to do next.

If there is any further information that I can provide, I would be more than happy to provide it.

Cheers,
             Monty

OS: Centos 6.6

Squid.conf file:

dns_v4_first on
dns_nameservers 10.7.128.21 10.7.128.22
negative_dns_ttl 5 minutes
forwarded_for delete
via off
cache_replacement_policy heap LFUDA
cache_swap_low 90
cache_swap_high 95
cache_dir aufs /cache 8192 16 256
cache_mem 256 MB
memory_pools on
maximum_object_size_in_memory 10 MB
maximum_object_size 50 MB
logfile_rotate 10
quick_abort_min 16 KB
quick_abort_max 16 KB
log_icp_queries off
client_db off
buffered_logs on

/usr/lib64/squid/basic_ldap_auth -d -v 3 -R -b "dc=domain,dc=com" -D "CN=KerbAuth,OU=ServiceAccounts,DC=domain,DC=com" -W /etc/squid/kerbauth -f sAMAccountName=%s -u uid -h windows2012r2.domain.com
auth_param basic children 80 startup=20 idle=10 concurrency=2
auth_param basic credentialsttl 5 hours

cache_peer 10.0.100.192 parent 8080 3130 no-query
cache_effective_user squid
cache_effective_group squid
visible_hostname Domain-Cache

acl SSL method CONNECT

acl SSL_ports port 443
acl SSL_ports port 1494 # Citrix XenApp
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443 # https
acl Safe_ports port 1494 # Citrix XenApp
acl Safe_ports port 70 # ftp
acl Safe_ports port 210 # https
acl Safe_ports port 1025-65535 # gopher
acl Safe_ports port 280 # wais
acl Safe_ports port 488 # unregistered ports
acl Safe_ports port 591 # http-mgmt
acl Safe_ports port 777 # gss-http
acl Safe_ports port 143 # IMAP
acl Safe_ports port 993 # IMAP over SSL
acl Safe_ports port 82
acl GLOW_SMTP port 587
acl GLOW_IMAP port 993
acl CONNECT method CONNECT # filemaker

acl goodusers proxy_auth REQUIRED
deny_info ERR_BANNED badusers

http_access allow manager localhost
http_access deny all !goodusers
http_access allow all goodusers
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all

http_port 3128
redirector_bypass off
coredump_dir /var/spool/squid

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
delay_pools 0

access_log stdio:/var/log/squid/access.log






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150225/bdff9e5e/attachment.htm>

From tmblue at gmail.com  Wed Feb 25 16:59:02 2015
From: tmblue at gmail.com (Tory M Blue)
Date: Wed, 25 Feb 2015 08:59:02 -0800
Subject: [squid-users] Squid 3.5 Reverse proxy. Pinger... icp/htcp
Message-ID: <CAEaSS0ZA-8dYDRAz0TBAKG2A3dx98WP=6yOtwmPYADjzJS5Gfg@mail.gmail.com>

Greetings

I'm getting further along with my testing and am trying to go the route of
lcp or htcp since I have a 3 squid cache cluster.

So the questions are..

1) What is the best debug level to set in order to see either icp or htcp
information? (I've been using tcpdump at the server level, just to see if I
can see traffic (and I'm not) :)

2) I've got the reported pinger exiting errors and wondering if this is why
icp or htcp doesn't seem to be working?

[@cache01]# tail -f /var/log/squid/cache.log
2015/02/25 08:46:42 kid1| Configuring Sibling
cache02.pp.sv.admission.net/80/3130
2015/02/25 08:46:42| pinger: Initialising ICMP pinger ...
2015/02/25 08:46:42| pinger: ICMP socket opened.
2015/02/25 08:46:42| pinger: ICMPv6 socket opened
2015/02/25 08:46:42 kid1| Finished loading MIME types and icons.
2015/02/25 08:46:42 kid1| Accepting reverse-proxy HTTP Socket connections
at local=[::]:80 remote=[::] FD 9 flags=9
2015/02/25 08:46:42 kid1| Accepting ICP messages on [::]:3130
2015/02/25 08:46:42 kid1| Sending ICP messages from [::]:3130
2015/02/25 08:46:42 kid1| Accepting SNMP messages on [::]:3401
2015/02/25 08:47:02| Pinger exiting

3) how do I tell squid to ignore ipv6 and concentrate on ipv4?

Thanks
Tory
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150225/811188d5/attachment.htm>

From mcsnv96 at afo.net  Wed Feb 25 19:44:22 2015
From: mcsnv96 at afo.net (Mike)
Date: Wed, 25 Feb 2015 13:44:22 -0600
Subject: [squid-users] TCP_DENIED and TCP_MISS_ABORTED
Message-ID: <54EE2616.6010305@afo.net>

We have recently been seeing this error on squid where one site that our 
users need access to is not loading at all.

1424889858.688      0 127.0.0.1 TCP_DENIED/407 3968 GET 
http://www.afa.net/ - HIER_NONE/- text/html
1424889878.725  20014 127.0.0.1 TCP_MISS_ABORTED/000 0 GET 
http://www.afa.net/ testuser1 HIER_DIRECT/66.210.221.116

[root at xeserver squid]# squid -v
Squid Cache: Version 3.4.7

Attempted to add an acl:
acl allowafa dstdomain .afa.net .afastore.net
http_access allow allowafa

but this did not fix it.

I understand the /407 as it related to http access means proxy 
authentication required, which is what every customer does when the 
browser is opened up, so authentication is already done and active in 
the server, otherwise other websites would not be loading either.

All other sites we need access to work fine, it is just something about 
this one... Any suggestions?

Mike


From dan at getbusi.com  Thu Feb 26 01:23:10 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Thu, 26 Feb 2015 12:23:10 +1100
Subject: [squid-users] Curious about: ipcacheParse: No Address records
Message-ID: <1A3FBC4C-5E3C-4D0D-9544-55516B91D9C6@getbusi.com>

Hey y?all

I don?t remember this being covered before?

I see this error (warning?) pretty frequently for hostnames which I can always resolve fine if I try them on the same server with dig or nslookup.

What?s the deal? And what does the client experience in the browser when one of these occurs?

Cheers
Dan

From squid3 at treenet.co.nz  Thu Feb 26 04:26:06 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 Feb 2015 17:26:06 +1300
Subject: [squid-users] TCP_DENIED and TCP_MISS_ABORTED
In-Reply-To: <54EE2616.6010305@afo.net>
References: <54EE2616.6010305@afo.net>
Message-ID: <54EEA05E.3020600@treenet.co.nz>

On 26/02/2015 8:44 a.m., Mike wrote:
> We have recently been seeing this error on squid where one site that our
> users need access to is not loading at all.
> 
> 1424889858.688      0 127.0.0.1 TCP_DENIED/407 3968 GET
> http://www.afa.net/ - HIER_NONE/- text/html
> 1424889878.725  20014 127.0.0.1 TCP_MISS_ABORTED/000 0 GET
> http://www.afa.net/ testuser1 HIER_DIRECT/66.210.221.116
> 
> [root at xeserver squid]# squid -v
> Squid Cache: Version 3.4.7
> 
> Attempted to add an acl:
> acl allowafa dstdomain .afa.net .afastore.net
> http_access allow allowafa
> 
> but this did not fix it.
> 
> I understand the /407 as it related to http access means proxy
> authentication required, which is what every customer does when the
> browser is opened up, so authentication is already done

That does not follow from the 407. In fact it means exactly the opposite
-  authentication *not* done.

The existence of "testuser1" information is what tells that
authentication is done.

> and active in
> the server, otherwise other websites would not be loading either.
> 
> All other sites we need access to work fine, it is just something about
> this one... Any suggestions?

ABORTED means the client disconnected. As they are able to do at any
time. This particular transaction tool 20 seconds and transferred 0
bytes to the client. No surprise they give up and disconnect.

The usual culprits are:
* broken Path-MTU discovery
* broken ECMP support
* Expect:100-continue
* broken TCP ECN support
* TCP window scaling

The 100-continue problem could be from the client, but the rest for your
case will be happening between Squid and server somewhere (if at all).

Amos


From squid3 at treenet.co.nz  Thu Feb 26 04:53:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 Feb 2015 17:53:10 +1300
Subject: [squid-users] Squid 3.5 Reverse proxy. Pinger... icp/htcp
In-Reply-To: <CAEaSS0ZA-8dYDRAz0TBAKG2A3dx98WP=6yOtwmPYADjzJS5Gfg@mail.gmail.com>
References: <CAEaSS0ZA-8dYDRAz0TBAKG2A3dx98WP=6yOtwmPYADjzJS5Gfg@mail.gmail.com>
Message-ID: <54EEA6B6.2000409@treenet.co.nz>

On 26/02/2015 5:59 a.m., Tory M Blue wrote:
> Greetings
> 
> I'm getting further along with my testing and am trying to go the route of
> lcp or htcp since I have a 3 squid cache cluster.
> 
> So the questions are..
> 
> 1) What is the best debug level to set in order to see either icp or htcp
> information? (I've been using tcpdump at the server level, just to see if I
> can see traffic (and I'm not) :)
> 

Its UDP traffic ;-P.

"debug_options 12,9" will show everything.


PS. you can use one or the other, not both at the same time to a given
peer. HTCP is far more accurate than ICP with HTTP/1.1 (thus
recommmended) but more bandwidth heavy.


> 2) I've got the reported pinger exiting errors and wondering if this is why
> icp or htcp doesn't seem to be working?

No pinger is doing ICMP.

It will mean the ICMP metrics for peer latency, and up/down status will
be a bit more inaccurate than they could otherwise be. But generally
nothing to worry over. It can be fixed by setting pinger binary owner to
"root" with permissions 755.

> 
> 3) how do I tell squid to ignore ipv6 and concentrate on ipv4?

"dns_v4_first on"

Squid will not ignore IPv6 entirely (see RFC 6540 / BCP 177 for why),
but will prefer IPv4 servers.

This is generally not a good idea. For ~80% of networks IPv6 operates
faster than IPv4. The ~20% where it only operates just-as-fast as IPv4
are suspected to be operating over tunnels.

Amos



From squid3 at treenet.co.nz  Thu Feb 26 04:58:19 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 Feb 2015 17:58:19 +1300
Subject: [squid-users] Curious about: ipcacheParse: No Address records
In-Reply-To: <1A3FBC4C-5E3C-4D0D-9544-55516B91D9C6@getbusi.com>
References: <1A3FBC4C-5E3C-4D0D-9544-55516B91D9C6@getbusi.com>
Message-ID: <54EEA7EB.5060304@treenet.co.nz>

On 26/02/2015 2:23 p.m., Dan Charlesworth wrote:
> Hey y?all
> 
> I don?t remember this being covered before?
> 
> I see this error (warning?) pretty frequently for hostnames which I can always resolve fine if I try them on the same server with dig or nslookup.
> 

Are you sure you are resolving them in the same way Squid is?

dig in particular will send a request and does the recursion lookups
itself. Whereas Squid has to work with the first response the NS(s)
provide for each for A and AAAA queries ... and *will* cache that
response for the TTL provided in the packet.


You may also need to enable EDNS0 advertisements in Squid to receive
back large sets of IP addresses from some servers (and avoid TCP
failover on others).
<http://www.squid-cache.org/Doc/config/dns_packet_max/>


> What?s the deal? And what does the client experience in the browser when one of these occurs?

Something along the lines of:
"
ERROR: The requested URL could not be retrieved

The following error was encountered while trying to retrieve the URL: ...

Unable to determine IP address from host name <domain>

The DNS server returned:
 No Address records

This means that the cache was not able to resolve the hostname presented
in the URL. Check if the address is correct.
"

... unless they are using one of the browsers the replace proxy error
reports with their own "friendly" pages (MSIE and Chrome). Then its some
obscure error code label or number. Or if it was a javascript XHR
request it may be in a hard-to-see popup that disappears quickly -
leaving them thinking nothing happened.

Amos



From dan at getbusi.com  Thu Feb 26 05:08:14 2015
From: dan at getbusi.com (dan at getbusi.com)
Date: Wed, 25 Feb 2015 21:08:14 -0800 (PST)
Subject: [squid-users] Curious about: ipcacheParse: No Address records
In-Reply-To: <54EEA7EB.5060304@treenet.co.nz>
References: <54EEA7EB.5060304@treenet.co.nz>
Message-ID: <1424927294555.e58f9e81@Nodemailer>

Thanks Amos!


I reckon that dns_packet_max directive might be playing into it. Most of the problematic hostnames seem to return large pools of IPs.




Only one way to find out ...

On Thu, Feb 26, 2015 at 3:59 PM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 26/02/2015 2:23 p.m., Dan Charlesworth wrote:
>> Hey y?all
>> 
>> I don?t remember this being covered before?
>> 
>> I see this error (warning?) pretty frequently for hostnames which I can always resolve fine if I try them on the same server with dig or nslookup.
>> 
> Are you sure you are resolving them in the same way Squid is?
> dig in particular will send a request and does the recursion lookups
> itself. Whereas Squid has to work with the first response the NS(s)
> provide for each for A and AAAA queries ... and *will* cache that
> response for the TTL provided in the packet.
> You may also need to enable EDNS0 advertisements in Squid to receive
> back large sets of IP addresses from some servers (and avoid TCP
> failover on others).
> <http://www.squid-cache.org/Doc/config/dns_packet_max/>
>> What?s the deal? And what does the client experience in the browser when one of these occurs?
> Something along the lines of:
> "
> ERROR: The requested URL could not be retrieved
> The following error was encountered while trying to retrieve the URL: ...
> Unable to determine IP address from host name <domain>
> The DNS server returned:
>  No Address records
> This means that the cache was not able to resolve the hostname presented
> in the URL. Check if the address is correct.
> "
> ... unless they are using one of the browsers the replace proxy error
> reports with their own "friendly" pages (MSIE and Chrome). Then its some
> obscure error code label or number. Or if it was a javascript XHR
> request it may be in a hard-to-see popup that disappears quickly -
> leaving them thinking nothing happened.
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150225/71125ed0/attachment.htm>

From squid3 at treenet.co.nz  Thu Feb 26 05:09:06 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 Feb 2015 18:09:06 +1300
Subject: [squid-users] Basic LDAP Authentication
In-Reply-To: <1424866961580.44143@glowmail.org.uk>
References: <1424866961580.44143@glowmail.org.uk>
Message-ID: <54EEAA72.7050404@treenet.co.nz>

On 26/02/2015 1:22 a.m., Mark Monaghan wrote:
> Hi All,
> 

> I'm wondering if anyone can help me with the following issue I'm
having getting various non-domain devices (mainly tablets, but some
non-domain windows and apple mac computers) working with the
basic_ldap_auth helper. I've had a good search of the mailing list, as
well as a huge trawl of the internet, but I cannot get the helper to
work within squid, and all information points to the fact that I've got
the command set up as it should be.
> 
> 
> Testing on the command line works perfectly, with the helper
> returning
the correct information. As soon as I attempt to do the same through
squid, it fails, returning technically nothing.
> 
> 
> I've even attempted different versions, from 3.2 right through to
> the
latest 3.5, just in case there was a bug with one of the builds on the
helper. All have the same result.
> 
> 
> In production, I've got the proxy working with domain devices via
kerberos authentication perfectly, but the basic ldap authentication
fails. So I've got a development system where the config has been
stripped right back to check the LDAP authentication, and the results
are the same, so I know that I'm not having problems with any other
authentication method failover.
> 
> 
> If I put the following line on the cli, then a domain username and
password, everything returns normally:
> 
> 
> /usr/lib64/squid/basic_ldap_auth -d -v 3 -R -b "dc=domain,dc=com" -D
"CN=KerbAuth,OU=ServiceAccounts,DC=domain,DC=com" -W /etc/squid/kerbauth
-f sAMAccountName=%s -u uid -h windows2012r2.domain.com

> 
> Output:
> 
> 
> ctest ctest3
> basic_ldap_auth.cc(684): pid=20130 :user filter 'sAMAccountName=ctest', searchbase 'dc=domain,dc=com'
> basic_ldap_auth.cc(739): pid=20130 :attempting to authenticate user 'CN=Test User,OU=Dept1,OU=Dept2,OU=Dept3,OU=Dept4,OU=Company,DC=domain,DC=com'
> OK
> 
> However, when used within the squid.conf file, when a user attempts to authenticate, the output in the cache.log is this:
> 
> basic_ldap_auth.cc(684): pid=20006 :user filter 'sAMAccountName=0', searchbase 'dc=domain,dc=com'
> basic_ldap_auth.cc(706): pid=20006 :Ldap search returned nothing
> 
> 
> I'm at a complete loss as to what to do next.

That helper does not support concurrency. Your test works because it is
not testing what Squid is sending, but what the helper actually expects.

Squid is sending it "0 ctest ctest3" ... "channel-ID username password".

The relevant config line is:

> auth_param basic children 80 startup=20 idle=10 concurrency=2

Should be:
  auth_param basic children 80 startup=20 idle=10 concurrency=0


Amos



From squid3 at treenet.co.nz  Thu Feb 26 05:20:07 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 Feb 2015 18:20:07 +1300
Subject: [squid-users] Curious about: ipcacheParse: No Address records
In-Reply-To: <1424927294555.e58f9e81@Nodemailer>
References: <54EEA7EB.5060304@treenet.co.nz>
 <1424927294555.e58f9e81@Nodemailer>
Message-ID: <54EEAD07.8020200@treenet.co.nz>

On 26/02/2015 6:08 p.m., dan at getbusi.com wrote:
> Thanks Amos!
> 
> 
> I reckon that dns_packet_max directive might be playing into it. Most of the problematic hostnames seem to return large pools of IPs.
> 

Well, its not doing anything by default. But can be turned on to gain.

Just be aware that your firewall and routing software all along the DNS
pathways needs to support EDNS0 and large UDP packets. Its off by
default because some popular devices (cheap Cisco kit / Linksys /
DynaLink in my experience, but not necessarily only them) often crash
when these type of DNS packets are delivered over them.

Amos



From dan at getbusi.com  Thu Feb 26 05:22:18 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Thu, 26 Feb 2015 16:22:18 +1100
Subject: [squid-users] Curious about: ipcacheParse: No Address records
In-Reply-To: <54EEAD07.8020200@treenet.co.nz>
References: <54EEA7EB.5060304@treenet.co.nz>
 <1424927294555.e58f9e81@Nodemailer> <54EEAD07.8020200@treenet.co.nz>
Message-ID: <7DC9757C-0C5A-455B-8E85-F9E4313035D3@getbusi.com>

Oh ?

Duly noted.

> On 26 Feb 2015, at 4:20 pm, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 26/02/2015 6:08 p.m., dan at getbusi.com wrote:
>> Thanks Amos!
>> 
>> 
>> I reckon that dns_packet_max directive might be playing into it. Most of the problematic hostnames seem to return large pools of IPs.
>> 
> 
> Well, its not doing anything by default. But can be turned on to gain.
> 
> Just be aware that your firewall and routing software all along the DNS
> pathways needs to support EDNS0 and large UDP packets. Its off by
> default because some popular devices (cheap Cisco kit / Linksys /
> DynaLink in my experience, but not necessarily only them) often crash
> when these type of DNS packets are delivered over them.
> 
> Amos
> 



From squid3 at treenet.co.nz  Thu Feb 26 05:41:58 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 Feb 2015 18:41:58 +1300
Subject: [squid-users] derive HTTP/HTTPS upload traffic to a secondary
 interface.
In-Reply-To: <42DE25A255671C44A93A7B58470DC09C5EAB3AFD@Michelle.aplitec.local>
References: <42DE25A255671C44A93A7B58470DC09C5E2F7C6F@Michelle.aplitec.local>
 <54D48588.7030301@treenet.co.nz>
 <42DE25A255671C44A93A7B58470DC09C5EAA55BF@Michelle.aplitec.local>
 <42DE25A255671C44A93A7B58470DC09C5EAB3AFD@Michelle.aplitec.local>
Message-ID: <54EEB226.4000509@treenet.co.nz>

On 25/02/2015 4:09 a.m., Josep Borrell wrote:
> Hi,
> 
> After some digging I realized that this setup works fine for HTTP traffic but not for HTTPS. I'm using ssl_bump in intercept mode.
> Is possible that for HTTPS traffic I can't split the upload / download ?
> 

At the connection level Squid is performing multiplexing for the HTTP
messages. They are stateless, so can be split up and delivered over any
connection it finds that meet the criteria.

SSL-Bump however is a single encrypted inbound stream of bytes. Squid is
being a "transaprent proxy" for it by ensuring that the outbound is as
closely matching the inbound behaviour as possible. All the messages
that come in on an encrypted stream should be going out on a matching
(singular) outgoing encryted connection. There are some unavoidable
differencs for HITS, error/deny's, forged certs etc but for the most
part it needs to be kept as transparent as possible to reduce HTTPS
problems.

For intercepted traffic you can/should do load balancing by selecting
the paths for new connections rather than messages. This is a major
reason why I recommend doing load balancing at the OS level where NIC
load vs capacity and the additional packet overheads can be taken into
account.

Amos



From jborrell at central.aplitec.com  Thu Feb 26 08:29:38 2015
From: jborrell at central.aplitec.com (Josep Borrell)
Date: Thu, 26 Feb 2015 08:29:38 +0000
Subject: [squid-users] derive HTTP/HTTPS upload traffic to a secondary
 interface.
In-Reply-To: <54EEB226.4000509@treenet.co.nz>
References: <42DE25A255671C44A93A7B58470DC09C5E2F7C6F@Michelle.aplitec.local>
 <54D48588.7030301@treenet.co.nz>
 <42DE25A255671C44A93A7B58470DC09C5EAA55BF@Michelle.aplitec.local>
 <42DE25A255671C44A93A7B58470DC09C5EAB3AFD@Michelle.aplitec.local>
 <54EEB226.4000509@treenet.co.nz>
Message-ID: <42DE25A255671C44A93A7B58470DC09C5EAC5115@Michelle.aplitec.local>

Hi Amos,

We are a school. Our Internet connection are 4 ADSL (8/0.8Mb) and 1 SDSL (4/4Mb)
We are doing session balancing in the firewall appliance.
The problem is when the students save this work, they
are using Google Apps for Education, so is very easy to saturate the upload channel of the ADSL. The ones that are luckily in the SDSL can save fast their work. The rest must wait some minutes.
We thought that deriving the upload traffic to the SDSL must alleviate the situation.
Our ISP admits no aggregation protocol, like MLPPP, that would be a solution.

Maybe there are another solution that we missing.
Thoughts are welcome.

Thanks

Josep


-----Mensaje original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] En nombre de Amos Jeffries
Enviado el: jueves, 26 de febrero de 2015 6:42
Para: squid-users at lists.squid-cache.org
Asunto: Re: [squid-users] derive HTTP/HTTPS upload traffic to a secondary interface.

On 25/02/2015 4:09 a.m., Josep Borrell wrote:
> Hi,
> 
> After some digging I realized that this setup works fine for HTTP traffic but not for HTTPS. I'm using ssl_bump in intercept mode.
> Is possible that for HTTPS traffic I can't split the upload / download ?
> 

At the connection level Squid is performing multiplexing for the HTTP messages. They are stateless, so can be split up and delivered over any connection it finds that meet the criteria.

SSL-Bump however is a single encrypted inbound stream of bytes. Squid is being a "transaprent proxy" for it by ensuring that the outbound is as closely matching the inbound behaviour as possible. All the messages that come in on an encrypted stream should be going out on a matching
(singular) outgoing encryted connection. There are some unavoidable differencs for HITS, error/deny's, forged certs etc but for the most part it needs to be kept as transparent as possible to reduce HTTPS problems.

For intercepted traffic you can/should do load balancing by selecting the paths for new connections rather than messages. This is a major reason why I recommend doing load balancing at the OS level where NIC load vs capacity and the additional packet overheads can be taken into account.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From ahmed.zaeem at netstream.ps  Thu Feb 26 18:42:29 2015
From: ahmed.zaeem at netstream.ps (snakeeyes)
Date: Thu, 26 Feb 2015 10:42:29 -0800
Subject: [squid-users] cache peer load balancing round robin problem
Message-ID: <000e01d051f4$06ff5050$14fdf0f0$@netstream.ps>

Wt do u think Mr Amos ?

 

 

From: snakeeyes [mailto:ahmed.zaeem at netstream.ps] 
Sent: Monday, February 16, 2015 2:55 PM
To: squid-users at lists.squid-cache.org
Subject: cache peer load balancing round robin problem

 

Hi , 

I have many account from same provider and I would like to use those
accounts as round robin and each request has different IP as possible

 

The issue is , I open whatismyipaddress.com

 

for  some freshesh I can see my ip is rotating  but after about 1 minute I
see my ip is stuck on same ip and not rotating .

 

Im wondering wt I need to modify the config below so that the round robin
keep working and each time change the ip :

 

cache_peer  vvvv  parent 22225 0 no-query round-robin name=1 no-digest
no-tproxy proxy-only login=xxxxx

cache_peer  vvv  parent 22225 0 no-query round-robin name=2  no-digest
no-tproxy proxy-only login=xxx

cache_peer  vvv  parent 22225 0 no-query round-robin  name=3 no-digest
no-tproxy proxy-only login=xxx

cache_peer  vvv  parent 22225 0 no-query round-robin name=4  no-digest
no-tproxy proxy-only login=xxx

cache_peer  vvvv  parent 22225 0 no-query round-robin  name=5 no-digest
no-tproxy proxy-only login=xxx

 

 

 

 

 

cheers

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150226/67b2d24a/attachment.htm>

From longbeakedechidna1 at gmail.com  Thu Feb 26 10:51:39 2015
From: longbeakedechidna1 at gmail.com (Greg)
Date: Thu, 26 Feb 2015 10:51:39 +0000
Subject: [squid-users] Tracking down cache MISSes
In-Reply-To: <54EDA87A.2060304@gmail.com>
References: <CALXdjAKUYmqrGV_MkeXtegsEXifC-dAxeOcHFx0YENPH7RkxuQ@mail.gmail.com>
 <c57f540e4c6c9ea8465b7bc0760e2346@treenet.co.nz>
 <CALXdjAKjqo+yZhKFH_UbZt+Uht+GLcuf-pwwyogB5A8nTXGJ1w@mail.gmail.com>
 <54EDA87A.2060304@gmail.com>
Message-ID: <CALXdjALEVghFiNWCvRtCKvYePwq-4XzYTJoTHuWJDhLGW_R6=g@mail.gmail.com>

On 25 February 2015 at 10:48, Yuri Voinov <yvoinov at gmail.com> wrote:
>
> 25.02.15 16:46, Greg ?????:
>
>> On 25 February 2015 at 03:30, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>
>>> On 2015-02-25 05:31, Greg wrote:
>>>>>>
>>>>>> so, there's my proxy problem I couldn't crack, even after spending
>>>>>> 2+ days tweaking-googling-debugging. :(
>>>>>>
>>>>>> The problem: my _new_ Squid installation (Ubuntu 14 LTS with Squid
>>>>>> 3.3.8) won't cache most pages the old Squid does (old Fedora with
>>>>>> Squid 3.1.15).
>>>>>
[...]
>>
>>> For the record this appears to be bug 3806 which was fixed in 3.3.12 just
>>> over a year ago. 3.3.8 is just too old by ~4 months.
>>
[...]
>> Now that I understand the problem I can think about a possible solution:
>> - Try to convince the Ubuntu 14 LTS maintainers to merge the fixes (
>> http://bugs.squid-cache.org/attachment.cgi?id=2854&action=diff and
>> http://bugs.squid-cache.org/attachment.cgi?id=2969&action=diff ). Not
>> sure about my chances ;)
>
> Try it. They just men the same as we.
>

Got some fresh infos!

The good news: Ubuntu acknowledges this as a bug important enough to
merge it to their code.
https://bugs.launchpad.net/ubuntu/+source/squid3/+bug/1336742

The bad news: noone has stepped up so far to do the merging. Also, I
was told their workflow is like they merge it to Ubuntu 15, then it's
merged back to 14 - also, 15 has entered feature freeze so a "freeze
exception" should be raised (which would likely be granted in this
case, moar in https://wiki.ubuntu.com/FeatureFreeze ). I haven't
programmed in C/C++ for a good while and don't have Squid programming
experience anyway, also don't know the workflow, so I can't do it
myself I'm afraid. It seems that what's needed is communication with
Ubuntu maintainers, a merge against 15, maybe with some regression
tests (?), a merge against 14 (or is it automerged? dunno), and
basically pushing this all the way so the Ubuntu Server flagship
version expected to be widely used for the next 5 years would have a
supported Squid version that'd actually cache HTML-JS-CSS too. (Oh I
wish!)

Is there a good soul who'd be willing to do this now?

Optionally I can offer a bit of a monetary compensation (yea that's
cold hard cash) for you or the FLOSS project/charity of your choice,
or that much of consultation/work for you in my area (web programming
and startups), or some work on the Squid documentation (yes I'm
looking at you debug_options).

Best regards,
Greg


From longbeakedechidna1 at gmail.com  Thu Feb 26 11:39:09 2015
From: longbeakedechidna1 at gmail.com (Greg)
Date: Thu, 26 Feb 2015 11:39:09 +0000
Subject: [squid-users] Remote configuration management software for managing
	Squid proxies?
Message-ID: <CALXdjA+z+QXey5oZax_qj33AhM8a=xBUkf9uxY3DTq-fukP6sA@mail.gmail.com>

Hi all,

I'm a ~beginner sysadmin starting managing a flock of (10+) existing
Squid proxies in different VPS companies. Right now it's a mix of
different OSes and Squid versions, some of them are rather old, and
all is managed manually over SSH - I'd very much like to roll out a
better set of proxies, installing and managing them from a central
interface.

I know there are configuration management software (
http://en.wikipedia.org/wiki/Comparison_of_open-source_configuration_management_software
), just don't know their limitations - which is usually well hidden
and will pop up when you're already in neck deep. Most of them don't
seem to give full access to the Squid config file anyway.

I'm hoping some of you already manages Squid proxies from a central
interface and can share your experiences.

What I'm looking for:
- Free and preferably FLOSS, being maintained
- Can pick up existing machines using different distributions and
versions (Juju fails here), playing well with our changes done on the
servers (no need to revert to stored config if config changes on the
server)
- Can manage the full Squid config incl. eg. refresh_pattern and
httpd_suppress_version_string without having to learn and write
Python/Ruby/... code (Chef-Puppet-Ansible-Salt-OPSI seem to fail here?
It seems these were not designed for this scenario and just support
the most important settings)
- Can read (!) and write config files on the server
- Can restart services and show their status
- Can list and install packages
- Preferably has a GUI, even better if there's one for Windows

Any tips and experience with some related software?

Best regards,
Greg


From yvoinov at gmail.com  Thu Feb 26 11:57:34 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 26 Feb 2015 17:57:34 +0600
Subject: [squid-users] Remote configuration management software for
 managing Squid proxies?
In-Reply-To: <CALXdjA+z+QXey5oZax_qj33AhM8a=xBUkf9uxY3DTq-fukP6sA@mail.gmail.com>
References: <CALXdjA+z+QXey5oZax_qj33AhM8a=xBUkf9uxY3DTq-fukP6sA@mail.gmail.com>
Message-ID: <54EF0A2E.2040805@gmail.com>

:)))))))))))))))

26.02.15 17:39, Greg ?????:
> Hi all,
>
> I'm a ~beginner sysadmin starting managing a flock of (10+) existing
> Squid proxies in different VPS companies. Right now it's a mix of
> different OSes and Squid versions, some of them are rather old, and
> all is managed manually over SSH - I'd very much like to roll out a
> better set of proxies, installing and managing them from a central
> interface.
>
> I know there are configuration management software (
> http://en.wikipedia.org/wiki/Comparison_of_open-source_configuration_management_software
> ), just don't know their limitations - which is usually well hidden
> and will pop up when you're already in neck deep. Most of them don't
> seem to give full access to the Squid config file anyway.
>
> I'm hoping some of you already manages Squid proxies from a central
> interface and can share your experiences.
>
> What I'm looking for:
> - Free and preferably FLOSS, being maintained
> - Can pick up existing machines using different distributions and
> versions (Juju fails here), playing well with our changes done on the
> servers (no need to revert to stored config if config changes on the
> server)
> - Can manage the full Squid config incl. eg. refresh_pattern and
> httpd_suppress_version_string without having to learn and write
> Python/Ruby/... code (Chef-Puppet-Ansible-Salt-OPSI seem to fail here?
> It seems these were not designed for this scenario and just support
> the most important settings)
> - Can read (!) and write config files on the server
> - Can restart services and show their status
> - Can list and install packages
> - Preferably has a GUI, even better if there's one for Windows
>
> Any tips and experience with some related software?
>
> Best regards,
> Greg
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From longbeakedechidna1 at gmail.com  Thu Feb 26 12:26:35 2015
From: longbeakedechidna1 at gmail.com (Greg)
Date: Thu, 26 Feb 2015 12:26:35 +0000
Subject: [squid-users] Remote configuration management software for
 managing Squid proxies?
In-Reply-To: <54EF0A2E.2040805@gmail.com>
References: <CALXdjA+z+QXey5oZax_qj33AhM8a=xBUkf9uxY3DTq-fukP6sA@mail.gmail.com>
 <54EF0A2E.2040805@gmail.com>
Message-ID: <CALXdjAJkog-goHwUvycmWxfWBVS4mYGwsS_=RX9TORXnD5Y15g@mail.gmail.com>

On 26 February 2015 at 11:57, Yuri Voinov <yvoinov at gmail.com> wrote:
> :)))))))))))))))

Why is this funny? :/ I'd like to make one step ahead. Even though I'm
noob, that doesn't mean I'm happy to manage 10+ Squid boxes manually,
and I'd be happy if there was a tool easing that, that plays well with
our many different Squid installations.


From yvoinov at gmail.com  Thu Feb 26 12:31:49 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 26 Feb 2015 18:31:49 +0600
Subject: [squid-users] Remote configuration management software for
 managing Squid proxies?
In-Reply-To: <CALXdjAJkog-goHwUvycmWxfWBVS4mYGwsS_=RX9TORXnD5Y15g@mail.gmail.com>
References: <CALXdjA+z+QXey5oZax_qj33AhM8a=xBUkf9uxY3DTq-fukP6sA@mail.gmail.com>
 <54EF0A2E.2040805@gmail.com>
 <CALXdjAJkog-goHwUvycmWxfWBVS4mYGwsS_=RX9TORXnD5Y15g@mail.gmail.com>
Message-ID: <54EF1235.6050107@gmail.com>

Yep, this is very funny. :)

https://www.google.com/search?q=Squid+gui+management+tool

First result is yours. :)

26.02.15 18:26, Greg ?????:
> On 26 February 2015 at 11:57, Yuri Voinov <yvoinov at gmail.com> wrote:
>> :)))))))))))))))
> Why is this funny? :/ I'd like to make one step ahead. Even though I'm
> noob, that doesn't mean I'm happy to manage 10+ Squid boxes manually,
> and I'd be happy if there was a tool easing that, that plays well with
> our many different Squid installations.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From monahbaki at gmail.com  Thu Feb 26 17:12:08 2015
From: monahbaki at gmail.com (Monah Baki)
Date: Thu, 26 Feb 2015 12:12:08 -0500
Subject: [squid-users] Squid in transparent
Message-ID: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>

Hi all,

I have client who has his Policy Based Routing as:

interface GigabitEthernet0/0/1.1 (route policy on the LAN interface)

ip policy route-map CFLOW





ip access-list extended REDIRECT (Redirect of my IP www)

deny   tcp host 10.0.0.24 any eq www

permit tcp host 10.0.0.23 any eq www



route-map CFLOW permit 10  (route map)

match ip address REDIRECT
set ip next-hop 10.0.0.24



The 10.0.0.24 is my FreeBSD 10.1 running squid 3.5, with one interface,
10.0.0.23 is his laptop. The IP address of the Cisco is 10.0.0.9

I configured squid as:
./configure --prefix=/cache/squid --enable-follow-x-forwarded-for
--with-large-files --enable-ssl --disable-ipv6 --enable-esi
--enable-kill-parent-hack --enable-snmp --with-pthreads
--with-filedescriptors=65535 --enable-cachemgr-hostname=hostname
--enable-storeio=ufs,aufs,diskd,rock --enable-ipfw-transparent
--enable-pf-transparent

My squid.conf has the following;
# Squid normally listens to port 3128
http_port 3128 intercept
http_port 80 intercept
snmp_port 3401


If I remove the intercept and from a client browser points to the squid, it
works. If I add the intercept, it does not work, I do not see any logs in
my access.log file.


Any help will be highly appreciated


Thanks
Monah
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150226/3b037955/attachment.htm>

From yvoinov at gmail.com  Thu Feb 26 17:14:45 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 26 Feb 2015 23:14:45 +0600
Subject: [squid-users] Squid in transparent
In-Reply-To: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
References: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
Message-ID: <54EF5485.2070003@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

http://wiki.squid-cache.org/ConfigExamples/Intercept

26.02.15 23:12, Monah Baki ?????:
> Hi all,
> 
> I have client who has his Policy Based Routing as:
> 
> interface GigabitEthernet0/0/1.1 (route policy on the LAN
> interface)
> 
> ip policy route-map CFLOW
> 
> 
> 
> 
> 
> ip access-list extended REDIRECT (Redirect of my IP www)
> 
> deny   tcp host 10.0.0.24 any eq www
> 
> permit tcp host 10.0.0.23 any eq www
> 
> 
> 
> route-map CFLOW permit 10  (route map)
> 
> match ip address REDIRECT set ip next-hop 10.0.0.24
> 
> 
> 
> The 10.0.0.24 is my FreeBSD 10.1 running squid 3.5, with one
> interface, 10.0.0.23 is his laptop. The IP address of the Cisco is
> 10.0.0.9
> 
> I configured squid as: ./configure --prefix=/cache/squid
> --enable-follow-x-forwarded-for --with-large-files --enable-ssl
> --disable-ipv6 --enable-esi --enable-kill-parent-hack --enable-snmp
> --with-pthreads --with-filedescriptors=65535
> --enable-cachemgr-hostname=hostname 
> --enable-storeio=ufs,aufs,diskd,rock --enable-ipfw-transparent 
> --enable-pf-transparent
> 
> My squid.conf has the following; # Squid normally listens to port
> 3128 http_port 3128 intercept http_port 80 intercept snmp_port
> 3401
> 
> 
> If I remove the intercept and from a client browser points to the
> squid, it works. If I add the intercept, it does not work, I do not
> see any logs in my access.log file.
> 
> 
> Any help will be highly appreciated
> 
> 
> Thanks Monah
> 
> 
> 
> _______________________________________________ squid-users mailing
> list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
> 
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU71SFAAoJENNXIZxhPexGRrYH/3aN8FnRdm9kbM1867C3SKeO
1iA1ZvEa7QuwLox1VvigjGS22cX5qqt/uodNzDI/WPPDj8C56PWbCoCWlHy2mpJE
xXYwNV+yYSPb4TYHooUPyxqH8G0Ghod3TAyOGnGLSSL3Hf3KPP5M3VWjsxJNI7ox
+TDaAAgsWzcKblJHGT3wTOGAT6Kzqm0MAaQyoacI+bTfPUhaLrm5VyV6kYAIQQCf
41mfMLvR8RG9TE/oCIbCzciZan5JoKIcTpqrpnU7K16qoEmZXDmsbJM5cDpXM7dG
6RG8EW9auRyg8xc3XjpR7ZpXVkKipqmieRqGMyQUnKsobeGv2jI0LZqkEPDEX9M=
=EwCL
-----END PGP SIGNATURE-----


From eliezer at ngtech.co.il  Thu Feb 26 18:18:09 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 26 Feb 2015 20:18:09 +0200
Subject: [squid-users] Interesting problem
In-Reply-To: <CAJ+Q1PXnDvOsxByFcn=ihmgb+fL5iaZkv4w-P+58w79db3=ftw@mail.gmail.com>
References: <CAJ+Q1PXnDvOsxByFcn=ihmgb+fL5iaZkv4w-P+58w79db3=ftw@mail.gmail.com>
Message-ID: <54EF6361.3090505@ngtech.co.il>

On 25/02/2015 06:18, Alex Samad wrote:
> Hi
>
> I am running squid on Centos 6.5
> squid-3.1.10-29.el6.x86_64

Hey Mike,

Can you share your squid.conf?

It's unreal that you will have the feature you might want in 3.1.10.
Are you trying to intercept ssl traffic or just use it as a reverse proxy?

Eliezer


From eliezer at ngtech.co.il  Thu Feb 26 18:36:41 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 26 Feb 2015 20:36:41 +0200
Subject: [squid-users] Squid in transparent
In-Reply-To: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
References: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
Message-ID: <54EF67B9.10107@ngtech.co.il>

On 26/02/2015 19:12, Monah Baki wrote:
> Hi all,
>
> I have client who has his Policy Based Routing as:
>
> interface GigabitEthernet0/0/1.1 (route policy on the LAN interface)
>
> ip policy route-map CFLOW

Hey Monah,

How is it all related to squid?
What OS are you using for squid?

Eliezer


From yvoinov at gmail.com  Thu Feb 26 18:43:49 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 27 Feb 2015 00:43:49 +0600
Subject: [squid-users] Squid in transparent
In-Reply-To: <54EF67B9.10107@ngtech.co.il>
References: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
 <54EF67B9.10107@ngtech.co.il>
Message-ID: <54EF6965.3010002@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


Directly, Eliezer :)

His installation doesn't work. Somebody have forgotten about NAT ;)

27.02.15 0:36, Eliezer Croitoru ?????:
> On 26/02/2015 19:12, Monah Baki wrote:
>> Hi all,
>> 
>> I have client who has his Policy Based Routing as:
>> 
>> interface GigabitEthernet0/0/1.1 (route policy on the LAN
>> interface)
>> 
>> ip policy route-map CFLOW
> 
> Hey Monah,
> 
> How is it all related to squid? What OS are you using for squid?
> 
> Eliezer _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU72lkAAoJENNXIZxhPexGiJkIAKDdSZOMtYT2kkr5MIn3tJnl
ol76rG2yaIqD6+hvW9hvMEjqPXcK/TVInbNgw1g6v+t67+6k/vocS2aENRjFjH/G
5fJV43BQFik0f1XFWousKpHzHfrZW3uRDkx4aMBt/hBRNhJyp/yR8RupqTt44u3b
pR8wMjmgwBGP/gLE2GwYkKMDMKkNcjT/qiJdWL2OcARjpHuyHH6xe1b7OBCa118e
36tK07cj3pIZej3Tju9l4LyB3s0fGzMD6N69GOnnMMU3t8qPNBvpprQPCUoqJ71C
oTsbul8lygvw+wvR5D6vOKPL5QUb4kUQRo/JNdyYHYqzh5Hqo+t9gaiTgqGeZeA=
=xmY5
-----END PGP SIGNATURE-----


From yvoinov at gmail.com  Thu Feb 26 18:44:47 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 27 Feb 2015 00:44:47 +0600
Subject: [squid-users] Squid in transparent
In-Reply-To: <54EF67B9.10107@ngtech.co.il>
References: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
 <54EF67B9.10107@ngtech.co.il>
Message-ID: <54EF699F.5050101@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

And if you seen this:

- --enable-ipfw-transparent
- --enable-pf-transparent

I think this is xBSD. ;)

27.02.15 0:36, Eliezer Croitoru ?????:
> On 26/02/2015 19:12, Monah Baki wrote:
>> Hi all,
>> 
>> I have client who has his Policy Based Routing as:
>> 
>> interface GigabitEthernet0/0/1.1 (route policy on the LAN
>> interface)
>> 
>> ip policy route-map CFLOW
> 
> Hey Monah,
> 
> How is it all related to squid? What OS are you using for squid?
> 
> Eliezer _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU72mfAAoJENNXIZxhPexG09AH/jvaWX0Yf5JQ+Mm9y60anI1d
AKngAIN1uH/8wl7dLtuwumytdYHUdp5j6obPs3Ekhnn/uFaoU9V8MtoWdzFx99WB
W6car5S4YYpvAipvFDFB0zws8Sy5gyFa7WguKyoaB2jnRSWM5AJivMuW/PR8J/T1
FQPuF0L07hldKb8qQS9nTNKn1BLgaz3pjo2/UlVZDRnBKHL/VbxM4t8U5ueJA+pe
PNpi4r4sY3boPWwGJKt+Hnw35EL25y96tfIy3jjeHDdE2SZJmr7QLfOOr8RnjNsJ
p2m/oNEA3wmKcrtQRhmbaiVgSs4KvTyH4Qrj+l/wE3FCMLPrctsmlvSSmlkmisY=
=gk/N
-----END PGP SIGNATURE-----


From curtism at connect-up.co.uk  Thu Feb 26 18:38:13 2015
From: curtism at connect-up.co.uk (Curtis.M)
Date: Thu, 26 Feb 2015 10:38:13 -0800 (PST)
Subject: [squid-users] Authentication Passthrough Failing
Message-ID: <1424975893900-4670095.post@n4.nabble.com>

Hi all, 

I have squid 2.7 setup on a Win2012R2 DC used for caching purposes. The main
use is for caching Apple iOS updates but is also starting to be used for
general web browsing. 

The issue I have is there is a web filtering system being used in this
environment that relies on AD usernames to filter web traffic. When clients
are configured with squid, they are essentially unfiltered. Reason being is
the box squid runs off is excluded from filtering and it seems all clients
using the configured proxy receive the same level of filtering as the host
squid is running from. 

I have already researched this and found that I may need to use Connection
Pinning but when the line "connection-auth=on" is added to the conf, squid
refuses to start. 
(Full error below) 

So my questions are: 
     Am I right in trying to use Connection Pinning to resolve this issue? 
     Am I missing code needed from the conf I mentioned? 
      

Thanks for reading and I hope you can help! 

Kind Regards, 

Curtis. 


Squid.conf 
----------------------------------------------------------------------------------------------------------------------- 
http_port 3128 connection-auth=on 

acl all src all 
acl manager proto cache_object 
acl localhost src 127.0.0.1/32 
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network 
acl localnet src 172.16.0.0/12	# RFC1918 possible internal network 
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network 
acl SSL_ports port 443 
acl Safe_ports port 80	# http 
acl Safe_ports port 21	# ftp 
acl Safe_ports port 443	# https 
acl Safe_ports port 70	# gopher 
acl Safe_ports port 210	# wais 
acl Safe_ports port 1025-65535	# unregistered ports 
acl Safe_ports port 280	# http-mgmt 
acl Safe_ports port 488	# gss-http 
acl Safe_ports port 591	# filemaker 
acl Safe_ports port 777	# multiling http 
acl CONNECT method CONNECT 

http_access allow manager localhost 
http_access deny manager 
http_access deny !Safe_ports 
http_access deny CONNECT !SSL_ports 

http_access allow localnet 

http_access deny all 



icp_access allow localnet 
icp_access deny all 



hierarchy_stoplist cgi-bin ? 

maximum_object_size 3072000000 bytes 
cache_dir aufs C:\squid\var\cache 256000 128 256 max-size=2048000000 

access_log c:/squid/var/logs/access.log squid 

Cache-Control: max-age=0, no-cache, no-store 
Pragma: no-cache 
refresh_pattern -i appldnld\.apple\.com 129600 100% 129600 ignore-reload
ignore-no-store override-expire override-lastmod ignore-must-revalidate 
refresh_pattern -i phobos\.apple\.com 129600 100% 129600 ignore-reload
ignore-no-store override-expire override-lastmod ignore-must-revalidate 
refresh_pattern ^ftp:	1440	20%	10080 
refresh_pattern ^gopher:	1440	0%	1440 
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0 
refresh_pattern .	0	20%	4320 

acl shoutcast rep_header X-HTTP09-First-Line ^ICY.[0-9] 
upgrade_http0.9 deny shoutcast 

acl apache rep_header Server ^Apache 
broken_vary_encoding allow apache 

coredump_dir c:/squid/var/cache 
----------------------------------------------------------------------------------------------------------------------- 
Full Error: 
FATAL: Bungled squid.conf line 1: http_port 3128 connection-auth=on 
Squid Cache (Version 2.7.STABLE8): Terminated abnormally.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Authentication-Passthrough-Failing-tp4670095.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Thu Feb 26 18:52:25 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 26 Feb 2015 20:52:25 +0200
Subject: [squid-users] Squid in transparent
In-Reply-To: <54EF6965.3010002@gmail.com>
References: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
 <54EF67B9.10107@ngtech.co.il> <54EF6965.3010002@gmail.com>
Message-ID: <54EF6B69.9010309@ngtech.co.il>

On 26/02/2015 20:43, Yuri Voinov wrote:
> Directly, Eliezer:)
>
> His installation doesn't work. Somebody have forgotten about NAT;)

It happen to me many times and still happen to me here and there when 
the memory is getting old.

Eliezer


From yvoinov at gmail.com  Thu Feb 26 18:53:29 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 27 Feb 2015 00:53:29 +0600
Subject: [squid-users] Squid in transparent
In-Reply-To: <54EF6B69.9010309@ngtech.co.il>
References: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
 <54EF67B9.10107@ngtech.co.il> <54EF6965.3010002@gmail.com>
 <54EF6B69.9010309@ngtech.co.il>
Message-ID: <54EF6BA9.1020305@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

:))))))))))))

Parity Check? ;) You need better RAM with ECC ;)

27.02.15 0:52, Eliezer Croitoru ?????:
> On 26/02/2015 20:43, Yuri Voinov wrote:
>> Directly, Eliezer:)
>> 
>> His installation doesn't work. Somebody have forgotten about
>> NAT;)
> 
> It happen to me many times and still happen to me here and there
> when the memory is getting old.
> 
> Eliezer _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org 
> http://lists.squid-cache.org/listinfo/squid-users
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU72uoAAoJENNXIZxhPexGg1AIALsG5ql7bkwxjWbuALfDRGIt
gy7KdvXnhtrOJ012Uu5mwy1KJQARYb7vfeP0+FRch5K9jLuNJeaZrEeN6y8EYX+I
KR7h4VIGOtxFamVFOsFNobTQ08xwbSvbDu3fAYravfProHFg92SQf1P+mhTTvWNI
0kRPnCI5u1BW4w12W3zmLb9dF7XPPm/DXAVbkz+X6f257rpGpu8JjWpzkR6F1EB8
rLZZ0v3WIyzWnUHLnH4cyzM3j5txczGSS9RTwmwF3ZANkpuw4zQv7fB7bBUPBhrE
rTvK55wJJ8Zu+49b3WWqFagCydK5dIih5u1dWy+r6OJeTtQP/c1VBZvdS7OvPpA=
=8BFM
-----END PGP SIGNATURE-----


From alanpalmer72 at yahoo.com  Thu Feb 26 19:03:09 2015
From: alanpalmer72 at yahoo.com (Alan Palmer)
Date: Thu, 26 Feb 2015 14:03:09 -0500
Subject: [squid-users] Different squid-3.5.2 compile error on OpenBSD 5.6
Message-ID: <54EF6DED.4030604@yahoo.com>

While waiting with baited breath for --with-libressl support, I 
installed openssl-1.02 on openbsd-5.6 to
get squid to compile, but got this error in the final linking:

MemStore.o(.text+0x4fe0): In function 
`MemStore::copyFromShm(StoreEntry&, int, Ipc::StoreMapAnchor const&)':
: undefined reference to `__sync_fetch_and_add_8'
MemStore.o(.text+0x5197): more undefined references to 
`__sync_fetch_and_add_8' follow

Now this is a bit odd because, from the config.log:

configure:20105: inlining optimizations enabled: yes
configure:20124: checking for GNU atomic operations support
configure:20151: c++ -o conftest -O2 -pipe -I/usr/local/include 
-L/usr/local/lib
  conftest.cpp  >&5
configure:20151: $? = 0
configure:20151: ./conftest
configure:20151: $? = 0
configure:20156: result: yes

now configure only checks for __sync_fetch_and_add not 
__sync_fetch_and_add_8.

The issue, I believe, is libc++ hasnt been ported to openbsd so it uses 
libstdc++

the compiler in question:
[apalmer]:/data/src/squid-3.5.2# g++ -v
Reading specs from /usr/lib/gcc-lib/i386-unknown-openbsd5.6/4.2.1/specs
Target: i386-unknown-openbsd5.6
Configured with: OpenBSD/i386 system compiler
Thread model: posix
gcc version 4.2.1 20070719

soooooo, manually editing autoconf.h to:
#define HAVE_ATOMIC_OPS 0

Is there a more graceful way to deal with this?

Alan


From eliezer at ngtech.co.il  Thu Feb 26 19:14:58 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 26 Feb 2015 21:14:58 +0200
Subject: [squid-users] Squid in transparent
In-Reply-To: <54EF6BA9.1020305@gmail.com>
References: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
 <54EF67B9.10107@ngtech.co.il> <54EF6965.3010002@gmail.com>
 <54EF6B69.9010309@ngtech.co.il> <54EF6BA9.1020305@gmail.com>
Message-ID: <54EF70B2.4040801@ngtech.co.il>

On 26/02/2015 20:53, Yuri Voinov wrote:
> Parity Check?;)  You need better RAM with ECC;)

I have used ECC for couple month(7-8) but it used too much Watts.

Thanks,
Eliezer



From dan at getbusi.com  Thu Feb 26 23:25:30 2015
From: dan at getbusi.com (Dan Charlesworth)
Date: Fri, 27 Feb 2015 10:25:30 +1100
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <1424841145197.56934ef5@Nodemailer>
References: <79efaedce25a8b9d22b59625e158fe38@treenet.co.nz>
 <1424841145197.56934ef5@Nodemailer>
Message-ID: <E42A1770-6F1C-4209-B0B8-1438477542E5@getbusi.com>

Alright I got abrtd on board, finally.

Here?s a a backtrace from this morning (bt and bt full versions included separately):


I?ll go put these in http://bugs.squid-cache.org/show_bug.cgi?id=3930 <http://bugs.squid-cache.org/show_bug.cgi?id=3930> as well.


> On 25 Feb 2015, at 4:12 pm, dan at getbusi.com wrote:
> 
> I?d be happy to provide a recent backtrace to match the config details but abrtd always seems to shit the bed:
> 
> Feb 25 10:19:14 hostname abrt[10776]: Saved core dump of pid 63925 (/usr/sbin/squid) to /var/spool/abrt/ccpp-2015-02-25-10:19:08-63925 (525869056 bytes)
> Feb 25 10:19:14 hostname abrtd: Directory 'ccpp-2015-02-25-10:19:08-63925' creation detected
> Feb 25 10:19:15 hostname squid[63923]: Squid Parent: (squid-1) process 63925 exited due to signal 6 with status 0
> Feb 25 10:19:15 hostname abrtd: Package 'squid' isn't signed with proper key
> Feb 25 10:19:15 hostname abrtd: 'post-create' on '/var/spool/abrt/ccpp-2015-02-25-10:19:08-63925' exited with 1
> Feb 25 10:19:15 hostname abrtd: Deleting problem directory '/var/spool/abrt/ccpp-2015-02-25-10:19:08-63925?
> 
> Not sure what counts as a ?proper key? we compile our own squid RPMs and sign them ourselves for our own private repo.
> 
> 
>  
> 
> 
> On Wed, Feb 25, 2015 at 2:03 PM, Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>> wrote:
> 
> On 2015-02-25 15:11, dan at getbusi.com wrote: 
> > By the way, I think Eliezer suggested I should file a bug report. 
> > There is in fact one already filed here: 
> > http://bugs.squid-cache.org/show_bug.cgi?id=3930 
> > 
> > 
> > Which brings me to my next question ... 
> > 
> > 
> > 
> > Amos, is it possible to sponsor bug fixes? 
> 
> Of course. Though be aware that if its an outstanding bug it means we 
> are having difficulty resolving it for some reason so we can't really 
> provide any guarantees about what it will take to fix. 
> 
> So far the issue seems to be a lack of information, with a stack trace 
> only coming in recently and the build and config details having come 
> from someone other than the one with stack trace. Ideally we need all 
> the details from a single proxy instance encountering the crash. 
> 
> Amos 
> 
> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150227/f05dad5c/attachment.htm>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: connisusable-bt1.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150227/f05dad5c/attachment.txt>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150227/f05dad5c/attachment-0001.htm>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: connisusable-bt-full1.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150227/f05dad5c/attachment-0001.txt>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150227/f05dad5c/attachment-0002.htm>

From carvakaguru at gmail.com  Thu Feb 26 23:41:02 2015
From: carvakaguru at gmail.com (Carvaka Guru)
Date: Thu, 26 Feb 2015 18:41:02 -0500
Subject: [squid-users] Unable to get TPROXY working with squid
Message-ID: <CAKL8bP5fniDHdBDzdKn_vhafZgKfz8inqwXtCQihx66B0N2BFg@mail.gmail.com>

I am building a simple linux firewall router with eth1 LAN port and eth0
WAN port. I have squid3 running on it that I have built with netfilter
enabled. The linux version running on the firewall is debian wheezy which
has iptables with TPROXY and socket support.

By setting up the iptables to send traffic to squid3 using the original nat
prerouting REDIRECT method everything works fine but I can't get the TPROXY
method to work. I followed all the steps outlined in
http://wiki.squid-cache.org/Features/Tproxy4 but no traffic gets to squid3.
In fact all HTTP traffic goes into some hole as soon as I issue the
following two routing commands -

ip rule add fwmark 1 lookup 100
ip route add local 0.0.0.0/0 dev lo table 100

Without these two commands the HTTP traffic goes through but never gets
routed to squid3.

I think the "ip route" command is the culprit but I don't know why or how
to change it?

Any suggestions, help would be much appreciated.

Thanks,
carvaka
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150226/b75978d1/attachment.htm>

From squid3 at treenet.co.nz  Fri Feb 27 01:12:50 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 27 Feb 2015 14:12:50 +1300
Subject: [squid-users] Authentication Passthrough Failing
In-Reply-To: <1424975893900-4670095.post@n4.nabble.com>
References: <1424975893900-4670095.post@n4.nabble.com>
Message-ID: <54EFC492.2040407@treenet.co.nz>

On 27/02/2015 7:38 a.m., Curtis.M wrote:
> Hi all, 
> 
> I have squid 2.7 setup on a Win2012R2 DC used for caching purposes. The main
> use is for caching Apple iOS updates but is also starting to be used for
> general web browsing. 
> 
> The issue I have is there is a web filtering system being used in this
> environment that relies on AD usernames to filter web traffic. When clients
> are configured with squid, they are essentially unfiltered. Reason being is
> the box squid runs off is excluded from filtering and it seems all clients
> using the configured proxy receive the same level of filtering as the host
> squid is running from. 
> 
> I have already researched this and found that I may need to use Connection
> Pinning but when the line "connection-auth=on" is added to the conf, squid
> refuses to start. 
> (Full error below) 
> 
> So my questions are: 
>      Am I right in trying to use Connection Pinning to resolve this issue? 

No connection pinning is enabled by default anyway. Its about relaying
credentials so the client can (try to) login to a website foolishly
using NTLM and/or Negotiate authentication.

It doesn't work for remote Internet traffic, but if the service the
credentials are being delivered to is on the local LAN it usually (but
not always) works well enough. Provided Squid is the only proxy between
client and service.


>      Am I missing code needed from the conf I mentioned? 
>       

I dont see any config related to Squid passing the HTTP traffic to this
web filtering system you mention. That would normally be done with
cache_peer. With that in place the upstream web filtering system does
the relevant auth and Squid pins connections to/from it which need to be
pinned.


> 
> Thanks for reading and I hope you can help! 
> 
> Kind Regards, 
> 
> Curtis. 
> 
> 
> Squid.conf 
> ----------------------------------------------------------------------------------------------------------------------- 
> http_port 3128 connection-auth=on 

Problem #1:
 Squid-2.7 does not contain the connection-auth=X parameter.

That "feature" is on by default in 2.7 with an option to disable. So
there is nothing you need to do to allow it to work.


> 
> acl all src all 
> acl manager proto cache_object 
> acl localhost src 127.0.0.1/32 
> acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 
> acl localnet src 10.0.0.0/8	# RFC1918 possible internal network 
> acl localnet src 172.16.0.0/12	# RFC1918 possible internal network 
> acl localnet src 192.168.0.0/16	# RFC1918 possible internal network 
> acl SSL_ports port 443 
> acl Safe_ports port 80	# http 
> acl Safe_ports port 21	# ftp 
> acl Safe_ports port 443	# https 
> acl Safe_ports port 70	# gopher 
> acl Safe_ports port 210	# wais 
> acl Safe_ports port 1025-65535	# unregistered ports 
> acl Safe_ports port 280	# http-mgmt 
> acl Safe_ports port 488	# gss-http 
> acl Safe_ports port 591	# filemaker 
> acl Safe_ports port 777	# multiling http 
> acl CONNECT method CONNECT 
> 
> http_access allow manager localhost 
> http_access deny manager 
> http_access deny !Safe_ports 
> http_access deny CONNECT !SSL_ports 
> 
> http_access allow localnet 
> 
> http_access deny all 
> 
> 
> 
> icp_access allow localnet 
> icp_access deny all 
> 
> 
> 
> hierarchy_stoplist cgi-bin ? 
> 
> maximum_object_size 3072000000 bytes 
> cache_dir aufs C:\squid\var\cache 256000 128 256 max-size=2048000000 
> 
> access_log c:/squid/var/logs/access.log squid 
> 
> Cache-Control: max-age=0, no-cache, no-store 
> Pragma: no-cache 

Problem #2:
The above two lines are HTTP protocol message headers. Not squid.conf
directives. Did you miss out a commmet "#" prefix on the line?


> refresh_pattern -i appldnld\.apple\.com 129600 100% 129600 ignore-reload
> ignore-no-store override-expire override-lastmod ignore-must-revalidate 
> refresh_pattern -i phobos\.apple\.com 129600 100% 129600 ignore-reload
> ignore-no-store override-expire override-lastmod ignore-must-revalidate 

Potential Problem #3:
 You are forcing Squid to ignore the HTTP/1.1 cache revalidation
features which need to be carefully handled by Squid when operating in
the presence of NTLM or Negotiate authentication.

What do you expect to happen when the 407 response is forced to be
cached and re-used with to all following requests for apple.com
downloads? eg. a HIT on a cached 407 is ... a 407 ... stored for 90 days
with no chance of alteration.



> refresh_pattern ^ftp:	1440	20%	10080 
> refresh_pattern ^gopher:	1440	0%	1440 
> refresh_pattern -i (/cgi-bin/|\?) 0	0%	0 
> refresh_pattern .	0	20%	4320 
> 
> acl shoutcast rep_header X-HTTP09-First-Line ^ICY.[0-9] 
> upgrade_http0.9 deny shoutcast 
> 
> acl apache rep_header Server ^Apache 
> broken_vary_encoding allow apache 
> 
> coredump_dir c:/squid/var/cache 
> ----------------------------------------------------------------------------------------------------------------------- 
> Full Error: 
> FATAL: Bungled squid.conf line 1: http_port 3128 connection-auth=on 
> Squid Cache (Version 2.7.STABLE8): Terminated abnormally.

That is from problem #1.


PS. Don't assume that its Squid being the problem. Even if connections
"only" have a problem when going through Squid.

Direct-to-origin server messages and proxy-relayed messages have
different format, different requirements, and different limitations. The
authentication mechanisms are also quite different in one critical way
(end-to-end vs hop-by-hop processing). In order to pass NTLM and
Negotiate authentication to the server through a proxy most of the
HTTP/1.1 features have to be understood and disabled by that proxy.
Squid-2.7 is HTTP/1.0 software with only a limited understanding of ~60%
of HTTP/1.1 features.

The modern Internet also has a mix of several other protocols (HTTP/2,
WebSockets, SPDY, QUIC) operating over what were once the HTTP-only
ports. Squid-2.7 is old enough that it only understands HTTP/1.0
properly and some of HTTP/1.1. Its quite possible that "working" origin
connections are not using anything even remotely resembling HTTP/1.0.

Amos


From squid3 at treenet.co.nz  Fri Feb 27 01:20:04 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 27 Feb 2015 14:20:04 +1300
Subject: [squid-users] Squid in transparent
In-Reply-To: <54EF699F.5050101@gmail.com>
References: <CALP3=x-8mL_3yyEiJUxHn1gko5+=ERVscKCJqt9EEcaOMZg4AQ@mail.gmail.com>
 <54EF67B9.10107@ngtech.co.il> <54EF699F.5050101@gmail.com>
Message-ID: <54EFC644.1030704@treenet.co.nz>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 27/02/2015 7:44 a.m., Yuri Voinov wrote:
> And if you seen this:
> 
> --enable-ipfw-transparent --enable-pf-transparent
> 
> I think this is xBSD. ;)


And on FreeBSD also --with-nat-devpf


Amos
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2.0.22 (MingW32)

iQEcBAEBAgAGBQJU78ZEAAoJELJo5wb/XPRjaYYH/15gYv4JbgjNtTpWPniefXAX
aXLXu7gX4/EHtAjzWuRwHW2lLW9fjiwVYGNtnzc9lDEM1RGRE4aeGkZ2eXM04gQe
s+S67G1eLLpyuTCteDmRetbp+ijtBXWa41GMrrqJmnAwZN1s24FxieROyEYfnZvX
cJuxEW2wKXYnjoXX5Avg4DftryeVA1TPMLGUJ3MMUmkdddQU5WKi1QAj1h9821fP
WvlY5yMvfzTP028BtmKCRI6hcGn+riTJxtMGYCajHlGOZfooYXwj1u/aYbmsRRWH
j3eJpsa3TqmpRUDJfPGv27xhcmu+y6JEABzRMBmM/mRaDRBoxOgXzRBcBpPZsKc=
=r+5y
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Feb 27 01:30:06 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 27 Feb 2015 14:30:06 +1300
Subject: [squid-users] Unable to get TPROXY working with squid
In-Reply-To: <CAKL8bP5fniDHdBDzdKn_vhafZgKfz8inqwXtCQihx66B0N2BFg@mail.gmail.com>
References: <CAKL8bP5fniDHdBDzdKn_vhafZgKfz8inqwXtCQihx66B0N2BFg@mail.gmail.com>
Message-ID: <54EFC89E.4070908@treenet.co.nz>

On 27/02/2015 12:41 p.m., Carvaka Guru wrote:
> I am building a simple linux firewall router with eth1 LAN port and eth0
> WAN port. I have squid3 running on it that I have built with netfilter
> enabled. The linux version running on the firewall is debian wheezy which
> has iptables with TPROXY and socket support.
> 
> By setting up the iptables to send traffic to squid3 using the original nat
> prerouting REDIRECT method everything works fine but I can't get the TPROXY
> method to work. I followed all the steps outlined in
> http://wiki.squid-cache.org/Features/Tproxy4

Uhm... no. You ran a *completely* different command line.


> but no traffic gets to squid3.
> In fact all HTTP traffic goes into some hole as soon as I issue the
> following two routing commands -
> 
> ip rule add fwmark 1 lookup 100
> ip route add local 0.0.0.0/0 dev lo table 100
> 
> Without these two commands the HTTP traffic goes through but never gets
> routed to squid3.
> 
> I think the "ip route" command is the culprit but I don't know why or how
> to change it?

That is explained in the "/!\" notes directly following the example
configuration you "followed".

It even has a whole section "Some routing problems to be aware of" just
to repeat the message about this problem and what to do about it.

<http://wiki.squid-cache.org/Features/Tproxy4#Routing_configuration>

Amos


From donny.vibianto at gmail.com  Fri Feb 27 04:41:01 2015
From: donny.vibianto at gmail.com (Donny Vibianto)
Date: Fri, 27 Feb 2015 11:41:01 +0700
Subject: [squid-users] 3.5.2 Basic LDAP auth is missing
Message-ID: <CAC49LV7m1X9nkjqt9o2a86ND2uDzsmhj8eVBsBVPC7Js_EgnFw@mail.gmail.com>

is there any change in 3.5.2 regarding basic ldap auth? i cant find ldap
helpder in my helper list.

Squid Cache: Version 3.5.2
Service Name: squid
configure options:  '--enable-basic=LDAP' --enable-ltdl-convenience

even i try to enable all basic helpder, that ldap helper still missing. in
3.5.1 everything work fine. am i miss something?


thanks,
Donny
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150227/587177ac/attachment.htm>

From squid3 at treenet.co.nz  Fri Feb 27 12:18:25 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 28 Feb 2015 01:18:25 +1300
Subject: [squid-users] assertion failed: client_side.cc:1515:
	"connIsUsable(http->getConn())
In-Reply-To: <E42A1770-6F1C-4209-B0B8-1438477542E5@getbusi.com>
References: <79efaedce25a8b9d22b59625e158fe38@treenet.co.nz>
 <1424841145197.56934ef5@Nodemailer>
 <E42A1770-6F1C-4209-B0B8-1438477542E5@getbusi.com>
Message-ID: <54F06091.5010806@treenet.co.nz>

On 27/02/2015 12:25 p.m., Dan Charlesworth wrote:
> Alright I got abrtd on board, finally.
> 
> Here?s a a backtrace from this morning (bt and bt full versions included 
> separately):
> 

Wonderful.

Can you get a print from frame 3 please of which of the connIsUsable()
checks if failing?


gdb commands:
 frame 3
 print http->getConn()
 print cbdataReferenceValid(http->getConn())
 print Comm::IsConnOpen(http->getConn()->clientConnection)

Amos



From squid3 at treenet.co.nz  Fri Feb 27 12:34:21 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 28 Feb 2015 01:34:21 +1300
Subject: [squid-users] Different squid-3.5.2 compile error on OpenBSD 5.6
In-Reply-To: <54EF6DED.4030604@yahoo.com>
References: <54EF6DED.4030604@yahoo.com>
Message-ID: <54F0644D.7070909@treenet.co.nz>

On 27/02/2015 8:03 a.m., Alan Palmer wrote:
> While waiting with baited breath for --with-libressl support, I
> installed openssl-1.02 on openbsd-5.6 to
> get squid to compile, but got this error in the final linking:
> 
> MemStore.o(.text+0x4fe0): In function
> `MemStore::copyFromShm(StoreEntry&, int, Ipc::StoreMapAnchor const&)':
> : undefined reference to `__sync_fetch_and_add_8'
> MemStore.o(.text+0x5197): more undefined references to
> `__sync_fetch_and_add_8' follow
> 
> Now this is a bit odd because, from the config.log:
> 
> configure:20105: inlining optimizations enabled: yes
> configure:20124: checking for GNU atomic operations support
> configure:20151: c++ -o conftest -O2 -pipe -I/usr/local/include
> -L/usr/local/lib
>  conftest.cpp  >&5
> configure:20151: $? = 0
> configure:20151: ./conftest
> configure:20151: $? = 0
> configure:20156: result: yes
> 
> now configure only checks for __sync_fetch_and_add not
> __sync_fetch_and_add_8.

Because Squid does not use __sync_fetch_and_add_8. It uses
__sync_fetch_and_add()

The OS is itelf defining __sync_fetch_and_add() in terms of
__sync_fetch_and_add_8 but then not providing the operator it depends on.

> 
> The issue, I believe, is libc++ hasnt been ported to openbsd so it uses
> libstdc++
> 
> the compiler in question:
> [apalmer]:/data/src/squid-3.5.2# g++ -v
> Reading specs from /usr/lib/gcc-lib/i386-unknown-openbsd5.6/4.2.1/specs
> Target: i386-unknown-openbsd5.6
> Configured with: OpenBSD/i386 system compiler
> Thread model: posix
> gcc version 4.2.1 20070719
> 
> soooooo, manually editing autoconf.h to:
> #define HAVE_ATOMIC_OPS 0
> 
> Is there a more graceful way to deal with this?


Perhapse building with Clang instead of the old GCC.

The recent BSD operating systems have all given up on GCC due to GPLv3
compatibility issues.

Amos


From eliezer at ngtech.co.il  Fri Feb 27 14:06:38 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 27 Feb 2015 16:06:38 +0200
Subject: [squid-users] 3.5.2 Basic LDAP auth is missing
In-Reply-To: <CAC49LV7m1X9nkjqt9o2a86ND2uDzsmhj8eVBsBVPC7Js_EgnFw@mail.gmail.com>
References: <CAC49LV7m1X9nkjqt9o2a86ND2uDzsmhj8eVBsBVPC7Js_EgnFw@mail.gmail.com>
Message-ID: <54F079EE.6090403@ngtech.co.il>

Hey Donny,

What OS are you using?

Eliezer

On 27/02/2015 06:41, Donny Vibianto wrote:
> is there any change in 3.5.2 regarding basic ldap auth? i cant find ldap
> helpder in my helper list.
>
> Squid Cache: Version 3.5.2
> Service Name: squid
> configure options:  '--enable-basic=LDAP' --enable-ltdl-convenience
>
> even i try to enable all basic helpder, that ldap helper still missing. in
> 3.5.1 everything work fine. am i miss something?
>
>
> thanks,
> Donny
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From steve at opendium.com  Fri Feb 27 15:48:21 2015
From: steve at opendium.com (Steve Hill)
Date: Fri, 27 Feb 2015 15:48:21 +0000
Subject: [squid-users] Dual-stack IPv4/IPv6 captive portal
Message-ID: <54F091C5.9090900@opendium.com>


I'm wondering whether anyone has implemented a captive portal on a 
dual-stacked network, and whether they can provide any insight into the 
best way of going about it.


The problems:

- Networks are frequently routed with the proxy server on the border. 
This means the proxy doesn't get to see the client's MAC address, so 
captive portals have to work by associating the IP address with the 
user's credentials.

- In a dual-stacked environment, a clients' requests come from both its 
IPv4 address and IPv6 address.  Treating them independently of each 
other would lead to a bad user experience since the user would need to 
authenticate separately for each address.

- Where IPv6 privacy extensions are enabled, the client has multiple 
addresses at the same time, with the preferred address changing at 
regular intervals.  The address rotation interval is typically quite 
long (e.g. 1 day) but the change-over between addresses will occur 
spontaneously with the captive portal not being informed in advance. 
Again, we don't want to auth each address individually.

- Captive portals often want to support WISPr to allow client devices to 
perform automated logins.


Possible solutions:

- The captive portal page could include embedded objects from the 
captive portal server's v4 and v6 addresses.  This would allow the 
captive portal to temporarily link the addresses together and therefore 
link the authentication credentials to both.  The portal would still 
have to work correctly when used from single-stacked devices.  This also 
isn't going to work for WISPr clients since the client will never render 
the page when doing an automated login so we wouldn't expect any 
embedded objects to be requested.

- Using DHCPv6 instead of SLAAC to do the address assignment would 
disable IPv6 privacy extensions, which would be desirable in this case. 
  However, many devices don't support DHCPv6.

- The DHCP and DHCPv6 servers know the MAC and IPv[46] address of each 
client and could cooperate with each other to link this data together. 
However, the proxy does not always have control of the DHCP/DHCPv6 servers.


-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Direct contacts:
    Instant messager: xmpp:steve at opendium.com
    Email:            steve at opendium.com
    Phone:            sip:steve at opendium.com

Sales / enquiries contacts:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support contacts:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From ansalonistefano at gmail.com  Fri Feb 27 15:53:57 2015
From: ansalonistefano at gmail.com (Stefano Ansaloni)
Date: Fri, 27 Feb 2015 16:53:57 +0100
Subject: [squid-users] Problems with squid 3.5.1
In-Reply-To: <858760942.350505087.1423728710955.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <20150211230539.GA23630@baea.com.au>
 <858760942.350505087.1423728710955.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CALkTbde8nS+uVuteg17Q4e-t0t=yF1Cfr9Bs7RwWEMUPwkE1qw@mail.gmail.com>

Sorry for the long delay, I can confirm that cleaning the cache solved
my problem.


From bergonz at labs.it  Fri Feb 27 17:00:58 2015
From: bergonz at labs.it (Michele Bergonzoni)
Date: Fri, 27 Feb 2015 18:00:58 +0100 (CET)
Subject: [squid-users] Dual-stack IPv4/IPv6 captive portal
In-Reply-To: <54F091C5.9090900@opendium.com>
References: <54F091C5.9090900@opendium.com>
Message-ID: <1521450889.828153.1425056458279.JavaMail.zimbra@labs.it>

> - The DHCP and DHCPv6 servers know the MAC and IPv[46] address of each
> client and could cooperate with each other to link this data together.

This is true for v6 if the client uses its MAC as an identifier, which it's not supposed to do and last time I checked was not true for Windows, or if clients or DHCP relays support RFC6939, which is quite new. See for example:

https://lists.isc.org/pipermail/kea-dev/2014-June/000043.html

> However, the proxy does not always have control of the DHCP/DHCPv6 servers.

Yes, and if you really have complete control of everything you can as well poll the first hop routers for their ARP/neighbor tables.

Have you thought about engineering your captive portal with a dual stack DNS name (having both A and AAAA), a v4 only and a v6 only, and having you HTML embed requests with appropriate identifiers to correlate addresses? Of course there are HTTP complications and it is not perfect, but I guess that as long as it's a captive portal, kludginess cannot decrease below some level.

I am really interested to hear what people are doing in the field of squid-powered captive portals, even more when interoperating with iptables/ip6tables.

Regards,
                     Bergonz

-- 
Ing. Michele Bergonzoni - Laboratori Guglielmo Marconi S.p.a.
Phone:+39-051-6781926 e-mail: bergonz at labs.it
alt.advanced.networks.design.configure.operate


From steve at opendium.com  Fri Feb 27 17:55:39 2015
From: steve at opendium.com (Steve Hill)
Date: Fri, 27 Feb 2015 17:55:39 +0000
Subject: [squid-users] Dual-stack IPv4/IPv6 captive portal
In-Reply-To: <1521450889.828153.1425056458279.JavaMail.zimbra@labs.it>
References: <54F091C5.9090900@opendium.com>
 <1521450889.828153.1425056458279.JavaMail.zimbra@labs.it>
Message-ID: <54F0AF9B.2000600@opendium.com>

On 27.02.15 17:00, Michele Bergonzoni wrote:

> This is true for v6 if the client uses its MAC as an identifier,
> which it's not supposed to do and last time I checked was not true
> for Windows, or if clients or DHCP relays support RFC6939, which is
> quite new. See for example:
>
> https://lists.isc.org/pipermail/kea-dev/2014-June/000043.html

Oh, interesting - I hadn't realised that.

> Have you thought about engineering your captive portal with a dual
> stack DNS name (having both A and AAAA), a v4 only and a v6 only, and
> having you HTML embed requests with appropriate identifiers to
> correlate addresses? Of course there are HTTP complications and it is
> not perfect, but I guess that as long as it's a captive portal,
> kludginess cannot decrease below some level.

That was one of my options.  However, it won't work in the case of WISPr 
auto-logons because the page wouldn't be rendered by the client, so you 
wouldn't expect it to fetch embedded bits either.

> I am really interested to hear what people are doing in the field of
> squid-powered captive portals, even more when interoperating with
> iptables/ip6tables.

At the moment, we've written a hybrid captive portal/http-auth system. 
Essentially, we use HTTP proxy auth where we can and a captive portal 
where we can't.  HTTP proxy auth is preferable because every request 
gets authenticated individually and we can use Kerberos.  Unfortunately 
a lot of software doesn't support it properly (I'm looking at you, apple 
and google, although everyone else is getting pretty bad at it too) and 
it also can't be used for transparent proxying (and again, a lot of 
software just doesn't bother to support proxies these days, and it's 
only getting worse).  So we use the user-agent string to try and 
identify the clients we can safely authenticate, and the rest rely on 
cached credentials or captive portal.

Yes, it's a horrible bodge, but unfortunately that's where modern 
software is driving us. :(  For iOS and Android you can pretty much 
forget using pure HTTP proxy authentication.  Luckily iOS can use WISPr 
to automatically log into a portal, sadly vanilla Android still doesn't 
include a WISPr client (I'd put money on this being down to patents!).


-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Direct contacts:
    Instant messager: xmpp:steve at opendium.com
    Email:            steve at opendium.com
    Phone:            sip:steve at opendium.com

Sales / enquiries contacts:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support contacts:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From yvoinov at gmail.com  Fri Feb 27 20:59:05 2015
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 28 Feb 2015 02:59:05 +0600
Subject: [squid-users] How to use access.log codes in custom error page
Message-ID: <54F0DA99.2030600@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hi gents.

Can I use log codes in custom error page and how to do this? Some
examples will be useful.

In details, interested in using adapt::<last_h code.

Just point me on right way.

Thank you.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBAgAGBQJU8NqZAAoJENNXIZxhPexG0QgIAM0AaBLJOTCQUP2fk3fiVmLB
tEPrtPK/zuGkVgRNCRrj4kF3nwoCcV/RMy6d/xU46tsGgfVR5EFvJtIilN/YmPn6
gqa1lluQNJ95IAHijbm6UNRIEmlTsPKNN2lEls9343d+4xk8etpAE8CL66Hppmoy
6tsvKXQznmV2wnWpTnizJ9r8mEBjNqAqnmA5snc+HMSqr0yO0+DOx2meJ3QbFLro
BczLMIKZkifwJSb2cXAY9eaCUj9qy3gpLliayocp3NEgVsBOjkhQY0ePH0xaBCBz
Bs5DI6k4Ql9S7LruuRuYEw2bdOsyzC9G/U33Dp6PJ5tM5gqnp/ZLK9xULflG8TY=
=nvCK
-----END PGP SIGNATURE-----


From squid3 at treenet.co.nz  Fri Feb 27 23:54:10 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 28 Feb 2015 12:54:10 +1300
Subject: [squid-users] 3.5.2 Basic LDAP auth is missing
In-Reply-To: <CAC49LV7m1X9nkjqt9o2a86ND2uDzsmhj8eVBsBVPC7Js_EgnFw@mail.gmail.com>
References: <CAC49LV7m1X9nkjqt9o2a86ND2uDzsmhj8eVBsBVPC7Js_EgnFw@mail.gmail.com>
Message-ID: <54F103A2.9070400@treenet.co.nz>

On 27/02/2015 5:41 p.m., Donny Vibianto wrote:
> is there any change in 3.5.2 regarding basic ldap auth? i cant find ldap
> helpder in my helper list.
> 
> Squid Cache: Version 3.5.2
> Service Name: squid
> configure options:  '--enable-basic=LDAP' --enable-ltdl-convenience
> 
> even i try to enable all basic helpder, that ldap helper still missing. in
> 3.5.1 everything work fine. am i miss something?
> 

The dependencies needs to build it.

Correct configure option is --enable-auth-basic="..."

Though helpers are auto-detected, so if the dependencies are on the
build machine the helper should be detected and built by default.

Check the config.log file created during ./configure to see what is missing.

Amos



From l4ng1t at gmail.com  Sat Feb 28 02:46:49 2015
From: l4ng1t at gmail.com (Donny Vibianto)
Date: Sat, 28 Feb 2015 09:46:49 +0700
Subject: [squid-users] 3.5.2 Basic LDAP auth is missing
In-Reply-To: <54F103A2.9070400@treenet.co.nz>
References: <CAC49LV7m1X9nkjqt9o2a86ND2uDzsmhj8eVBsBVPC7Js_EgnFw@mail.gmail.com>
 <54F103A2.9070400@treenet.co.nz>
Message-ID: <CAC49LV6X1eyvRpbfctCQKgqQ58xe6EEwNbqVgZQ3bK5muPv4aQ@mail.gmail.com>

?i was noticed that i am missed the important thing when i check
status.log, dependency. after i fixed it, now i can see ldap auth in my
helper.

thanks eliezer and amos?

On Sat, Feb 28, 2015 at 6:54 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 27/02/2015 5:41 p.m., Donny Vibianto wrote:
> > is there any change in 3.5.2 regarding basic ldap auth? i cant find ldap
> > helpder in my helper list.
> >
> > Squid Cache: Version 3.5.2
> > Service Name: squid
> > configure options:  '--enable-basic=LDAP' --enable-ltdl-convenience
> >
> > even i try to enable all basic helpder, that ldap helper still missing.
> in
> > 3.5.1 everything work fine. am i miss something?
> >
>
> The dependencies needs to build it.
>
> Correct configure option is --enable-auth-basic="..."
>
> Though helpers are auto-detected, so if the dependencies are on the
> build machine the helper should be detected and built by default.
>
> Check the config.log file created during ./configure to see what is
> missing.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150228/a5b4137a/attachment.htm>

From johnzeng2013 at yahoo.com  Sat Feb 28 03:18:32 2015
From: johnzeng2013 at yahoo.com (johnzeng)
Date: Sat, 28 Feb 2015 11:18:32 +0800
Subject: [squid-users] i meet a problem ,
 --- Unsupported Request Method and Protocol'' for such connections
 ( non-HTTP connections ) based 80 port ----, if possible ,
 please give me some advisement or help
In-Reply-To: <54F07195.3070708@yahoo.com>
References: <54F07195.3070708@yahoo.com>
Message-ID: <54F13388.8090504@yahoo.com>

Hi all :



i meet a problem ,Squid cannot currently deal with such connections (
non-HTTP connections ) based 80 port , and We get some error ,

Unsupported Request Method and Protocol'' for https URLs..

i search via www.ask.com , but i don't good way .

if possible ,i hope to use squid 2.7 stable9 , Maybe it will be stable version untile now .

Whether we can resolve the problem via other tunnel tools + squid 2.7 ( for example:
http://www.nocrew.org/software/httptunnel.html ) or
http://desproxy.sourceforge.net <http://desproxy.sourceforge.net/>????



 if possible , please give me some advisement .


This is some detail , but i don't any way

11.45 ``Unsupported Request Method and Protocol'' for https URLs.

Note: The information here is current for version 2.3.

This is correct. Squid does not know what to do with an https URL. To
handle such a URL, Squid would need to speak the SSL protocol.
Unfortunately, it does not (yet).

Normally, when you type an https URL into your browser, one of two
things happens.

1. The browser opens an SSL connection directly to the origin server.
2. The browser tunnels the request through Squid with the CONNECT
request method.

The CONNECT method is a way to tunnel any kind of connection through an
HTTP proxy. The proxy doesn't understand or interpret the contents. It
just passes bytes back and forth between the client and server. For the
gory details on tunnelling and the CONNECT method, please see RFC 2817
and Tunneling TCP based protocols through Web proxy servers (expired).







From squid3 at treenet.co.nz  Sat Feb 28 03:42:35 2015
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 28 Feb 2015 16:42:35 +1300
Subject: [squid-users] i meet a problem ,
 --- Unsupported Request Method and Protocol'' for such connections
 ( non-HTTP connections ) based 80 port ----, if possible ,
 please give me some advisement or help
In-Reply-To: <54F13388.8090504@yahoo.com>
References: <54F07195.3070708@yahoo.com> <54F13388.8090504@yahoo.com>
Message-ID: <54F1392B.9030601@treenet.co.nz>

On 28/02/2015 4:18 p.m., johnzeng wrote:
> Hi all :
> 
> 
> 
> i meet a problem ,Squid cannot currently deal with such connections (
> non-HTTP connections ) based 80 port , and We get some error ,
> 
> Unsupported Request Method and Protocol'' for https URLs..

NOTE: HTTPS never goes over port 80.

HTTPS native port is 443, and when proxied uses the proxy port.

Intercepted HTTPS traffic MUST NOT be delivered to a http_port listening
port in Squid. Use https_port instead.

> 
> i search via www.ask.com , but i don't good way .
> 
> if possible ,i hope to use squid 2.7 stable9 , Maybe it will be stable version untile now .
> 
> Whether we can resolve the problem via other tunnel tools + squid 2.7 ( for example:
> http://www.nocrew.org/software/httptunnel.html ) or
> http://desproxy.sourceforge.net <http://desproxy.sourceforge.net/>????


Current stable version is 3.5.2. Please use that.

Particularly if you are intercepting HTTPS traffic. There is an arms
race going on between people trying to use HTTPS for security and people
trying to filter it. Things are changing rapidly.

Amos



From johnzeng2013 at yahoo.com  Sat Feb 28 11:40:30 2015
From: johnzeng2013 at yahoo.com (johnzeng)
Date: Sat, 28 Feb 2015 19:40:30 +0800
Subject: [squid-users] if i use  squid 3.5.2 ,
 which part is stable between coss and rock for operating small http
 object .
In-Reply-To: <54F1392B.9030601@treenet.co.nz>
References: <54F07195.3070708@yahoo.com> <54F13388.8090504@yahoo.com>
 <54F1392B.9030601@treenet.co.nz>
Message-ID: <54F1A92E.3010001@yahoo.com>


Hi Amos Jeffries:

                            Thanks again .

                           because squid 2.7 stable 9 can support coss 
for small http object , if i use  squid 3.5.2 ,

                            which part is stable between coss and rock 
for operating small http object ?


                            Whether squid 3.5.2 can support wccp ?


                             Best Regards

                              John



? 2015?02?28? 11:42, Amos Jeffries ??:
> On 28/02/2015 4:18 p.m., johnzeng wrote:
>> Hi all :
>>
>>
>>
>> i meet a problem ,Squid cannot currently deal with such connections (
>> non-HTTP connections ) based 80 port , and We get some error ,
>>
>> Unsupported Request Method and Protocol'' for https URLs..
> NOTE: HTTPS never goes over port 80.
>
> HTTPS native port is 443, and when proxied uses the proxy port.
>
> Intercepted HTTPS traffic MUST NOT be delivered to a http_port listening
> port in Squid. Use https_port instead.
>
>> i search via www.ask.com , but i don't good way .
>>
>> if possible ,i hope to use squid 2.7 stable9 , Maybe it will be stable version untile now .
>>
>> Whether we can resolve the problem via other tunnel tools + squid 2.7 ( for example:
>> http://www.nocrew.org/software/httptunnel.html ) or
>> http://desproxy.sourceforge.net <http://desproxy.sourceforge.net/>????
>
> Current stable version is 3.5.2. Please use that.
>
> Particularly if you are intercepting HTTPS traffic. There is an arms
> race going on between people trying to use HTTPS for security and people
> trying to filter it. Things are changing rapidly.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From huaraz at moeller.plus.com  Sat Feb 28 15:55:33 2015
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sat, 28 Feb 2015 15:55:33 -0000
Subject: [squid-users] Logging variable  question
Message-ID: <mcsodm$i43$1@ger.gmane.org>

Spam detection software, running on the system "master.squid-cache.org",
has identified this incoming email as possible spam.  The original
message has been attached to this so you can view it or label
similar future email.  If you have any questions, see
@@CONTACT_ADDRESS@@ for details.

Content preview:  Hi, I wonder about the total size variables <st and >st for
   squid logs # <st Sent reply size including HTTP headers # >st Received request
   size including HTTP headers. In the # case of chunked requests the chunked
   encoding metadata # are not included [...] 

Content analysis details:   (7.8 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
 0.2 STOX_REPLY_TYPE        No description available.
 0.9 SPF_FAIL               SPF: sender does not match SPF record (fail)
[SPF failed: Please see http://www.openspf.org/Why?s=mfrom;id=gcwsg-squid-users%40m.gmane.org;ip=81.174.172.105;r=master.squid-cache.org]
 0.0 T_HEADER_FROM_DIFFERENT_DOMAINS From and EnvelopeFrom 2nd level mail
                            domains are different
 1.9 STOX_REPLY_TYPE_WITHOUT_QUOTES No description available.
 0.0 UNPARSEABLE_RELAY      Informational: message has unparseable relay lines
 1.3 RDNS_NONE              Delivered to internal network by a host with no rDNS
 3.5 TO_NO_BRKTS_MSFT       To: misformatted and supposed Microsoft tool


-------------- next part --------------
An embedded message was scrubbed...
From: "Markus Moeller" <huaraz at moeller.plus.com>
Subject: Logging variable  question
Date: Sat, 28 Feb 2015 15:55:33 -0000
Size: 3139
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20150228/6ea58d01/attachment.eml>

From eliezer at ngtech.co.il  Sat Feb 28 21:45:47 2015
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 28 Feb 2015 23:45:47 +0200
Subject: [squid-users] i meet a problem ,
 --- Unsupported Request Method and Protocol'' for such connections
 ( non-HTTP connections ) based 80 port ----, if possible ,
 please give me some advisement or help
In-Reply-To: <54F13388.8090504@yahoo.com>
References: <54F07195.3070708@yahoo.com> <54F13388.8090504@yahoo.com>
Message-ID: <54F2370B.8020200@ngtech.co.il>

Hey,

It is a bit hard to understand the scenario but I assume it's a 
transparent proxy for port 80? right?

In any case what so ever squid 2.7 is old and preferably should not be 
used in production unless there is a very specific need for it while 
taking into account the advantages and disadvantages.

If you search via www.ask.com it should work on any version of squid 
like it worked for me in the last who knows how many years.

The best start point would be to get couple lines from the access.log 
and a description of the network infrastructure.
(consider to replace\remove any confidential information)

All The Bests,
Eliezer Croitoru

On 28/02/2015 05:18, johnzeng wrote:
> Hi all :
>
>
>
> i meet a problem ,Squid cannot currently deal with such connections (
> non-HTTP connections ) based 80 port , and We get some error ,
>
> Unsupported Request Method and Protocol'' for https URLs..
>
> i search viawww.ask.com  , but i don't good way .
>
> if possible ,i hope to use squid 2.7 stable9 , Maybe it will be stable version untile now .



From alex at samad.com.au  Sat Feb 28 21:48:35 2015
From: alex at samad.com.au (Alex Samad)
Date: Sun, 1 Mar 2015 08:48:35 +1100
Subject: [squid-users] Interesting problem
In-Reply-To: <54EF6361.3090505@ngtech.co.il>
References: <CAJ+Q1PXnDvOsxByFcn=ihmgb+fL5iaZkv4w-P+58w79db3=ftw@mail.gmail.com>
 <54EF6361.3090505@ngtech.co.il>
Message-ID: <CAJ+Q1PVT3P0YzqeFggErg3iiKH0OPW18cGLv0+P1ZaLVn0ChWg@mail.gmail.com>

me  (Alex)?

forward proxy ?



On 27 February 2015 at 05:18, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> On 25/02/2015 06:18, Alex Samad wrote:
>>
>> Hi
>>
>> I am running squid on Centos 6.5
>> squid-3.1.10-29.el6.x86_64
>
>
> Hey Mike,
>
> Can you share your squid.conf?
>
> It's unreal that you will have the feature you might want in 3.1.10.
> Are you trying to intercept ssl traffic or just use it as a reverse proxy?
>
> Eliezer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


