<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] acl for redirect - re Amos
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20acl%20for%20redirect%20-%20re%20Amos&In-Reply-To=%3C558D7949.6090206%40afo.net%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="004252.html">
   <LINK REL="Next"  HREF="004182.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] acl for redirect - re Amos</H1>
    <B>Mike</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20acl%20for%20redirect%20-%20re%20Amos&In-Reply-To=%3C558D7949.6090206%40afo.net%3E"
       TITLE="[squid-users] acl for redirect - re Amos">mcsnv96 at afo.net
       </A><BR>
    <I>Fri Jun 26 16:09:45 UTC 2015</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="004252.html">[squid-users] acl for redirect - re Fred
</A></li>
        <LI>Next message (by thread): <A HREF="004182.html">[squid-users] TCP_MISS/503
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#4239">[ date ]</a>
              <a href="thread.html#4239">[ thread ]</a>
              <a href="subject.html#4239">[ subject ]</a>
              <a href="author.html#4239">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Amos,

I would like to use e2guardian if possible, and after checking it out, 
<A HREF="http://www.google.com/webhp?nord=1">http://www.google.com/webhp?nord=1</A> does force the insecure, but previous 
entries attempted just cause all searches to loop back to that same url 
instead of passing it along.

We could use a regex option in squid, but since we want the rest of the 
sites to be handled normally through e2guardian, what acl entries would 
we use to set it up to only take effect on google.com? Essentially &quot;if 
dstdomain = google.com then use acl blocklist /etc/squid/badwords&quot;.
I have not used a 2 layer or referring acl setup before, but before now 
never needed to.

Thank you so much for the help!

Mike


On 6/26/2015 0:29 AM, Amos Jeffries wrote:
&gt;<i> On 26/06/2015 2:36 a.m., Mike wrote:
</I>&gt;&gt;<i> Amos, thanks for info.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> The primary settings being used in squid.conf:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> http_port 8080
</I>&gt;&gt;<i> # this port is what will be used for SSL Proxy on client browser
</I>&gt;&gt;<i> http_port 8081 intercept
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> https_port 8082 intercept ssl-bump connection-auth=off
</I>&gt;&gt;<i> generate-host-certificates=on dynamic_cert_mem_cache_size=16MB
</I>&gt;&gt;<i> cert=/etc/squid/ssl/squid.pem key=/etc/squid/ssl/squid.key
</I>&gt;&gt;<i> cipher=ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:DHE-RSA-CAMELLIA128-SHA:AES128-SHA:RC4-SHA:HIGH:!aNULL:!MD5:!ADH
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid_ssl_db -M 16MB
</I>&gt;&gt;<i> sslcrtd_children 50 startup=5 idle=1
</I>&gt;&gt;<i> ssl_bump server-first all
</I>&gt;&gt;<i> ssl_bump none localhost
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Then e2guardian uses 10101 for the browsers, and uses 8080 for
</I>&gt;&gt;<i> connecting to squid on the same server.
</I>&gt;<i> Doesn;t matter. Due to TLS security requirements Squid ensures the TLS
</I>&gt;<i> connection in re-encrypted on outgoing.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> I am doubtful eth nord works anymore since Googles own documentation for
</I>&gt;<i> schools states that one must install a MITM proxy that does the traffic
</I>&gt;<i> filtering - e2guardian is not one of those. IMO you should convert your
</I>&gt;<i> e2guardian config into Squid ACL rules that can be applied to the bumped
</I>&gt;<i> traffic without forcing <A HREF="http://">http://</A>
</I>&gt;<i>
</I>&gt;<i> But if nord does work, so should the deny_info in Squid. Something like
</I>&gt;<i> this probably:
</I>&gt;<i>
</I>&gt;<i>   acl google dstdomain .google.com
</I>&gt;<i>   deny_info 301:<A HREF="http://%H%R?nord=1">http://%H%R?nord=1</A> google
</I>&gt;<i>
</I>&gt;<i>   acl GwithQuery urlpath_regex ?
</I>&gt;<i>   deny_info 301:<A HREF="http://%H%R&amp;nord=1">http://%H%R&amp;nord=1</A> GwithQuery
</I>&gt;<i>
</I>&gt;<i>   http_access deny google Gquery
</I>&gt;<i>   http_access deny google
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Amos
</I>&gt;<i> _______________________________________________
</I>&gt;<i> squid-users mailing list
</I>&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>
</I>&gt;<i> <A HREF="http://lists.squid-cache.org/listinfo/squid-users">http://lists.squid-cache.org/listinfo/squid-users</A>
</I>&gt;<i>
</I>

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="004252.html">[squid-users] acl for redirect - re Fred
</A></li>
	<LI>Next message (by thread): <A HREF="004182.html">[squid-users] TCP_MISS/503
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#4239">[ date ]</a>
              <a href="thread.html#4239">[ thread ]</a>
              <a href="subject.html#4239">[ subject ]</a>
              <a href="author.html#4239">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
