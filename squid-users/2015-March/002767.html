<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] Reverse Proxy Funny Logging Issue
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Reverse%20Proxy%20Funny%20Logging%20Issue&In-Reply-To=%3C2be09011d9c5f16220f0c781c793e242%40dweimer.net%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002756.html">
   <LINK REL="Next"  HREF="002783.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] Reverse Proxy Funny Logging Issue</H1>
    <B>dweimer</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Reverse%20Proxy%20Funny%20Logging%20Issue&In-Reply-To=%3C2be09011d9c5f16220f0c781c793e242%40dweimer.net%3E"
       TITLE="[squid-users] Reverse Proxy Funny Logging Issue">dweimer at dweimer.net
       </A><BR>
    <I>Fri Mar 13 16:19:07 UTC 2015</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="002756.html">[squid-users] Reverse Proxy Funny Logging Issue
</A></li>
        <LI>Next message (by thread): <A HREF="002783.html">[squid-users] Reverse Proxy Funny Logging Issue
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2767">[ date ]</a>
              <a href="thread.html#2767">[ thread ]</a>
              <a href="subject.html#2767">[ subject ]</a>
              <a href="author.html#2767">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 03/12/2015 10:31 am, dweimer wrote:
&gt;<i> On 01/23/2013 10:39 pm, Amos Jeffries wrote:
</I>&gt;&gt;<i> On 24/01/2013 4:13 a.m., dweimer wrote:
</I>&gt;&gt;&gt;<i> On 2013-01-23 08:40, dweimer wrote:
</I>&gt;&gt;&gt;&gt;<i> On 2013-01-22 23:30, Amos Jeffries wrote:
</I>&gt;&gt;&gt;&gt;&gt;<i> On 23/01/2013 5:34 a.m., dweimer wrote:
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> I just upgraded my reverse proxy server last night from 3.1.20 to 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 3.2.6, all is working well except one of my log rules, and I can't 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> figure out why.
</I>&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;<i> Please run &quot;squid -k parse&quot; and resolve the WARNING or ERROR which 
</I>&gt;&gt;&gt;&gt;&gt;<i> are listed.
</I>&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;<i> There are two possible reasons...
</I>&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> I have a several sites behind the server, with dstdomain access 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> rules setup.
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> acl website1 dstdomain www.website1.com
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> acl website2 dstdomain www.website2.com
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> acl website2 dstdomain www.website3.com
</I>&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;<i> Possible reason #1 (assuming thi is an accurate copy-n-paste from
</I>&gt;&gt;&gt;&gt;&gt;<i> yoru config file).....  you have no website3 ACL definition?
</I>&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;<i> That was a typo in the email, correct ACL is in the configuration,
</I>&gt;&gt;&gt;&gt;<i> squid -k parse outputs no warnings or errors.
</I>&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> ...
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> Followed by the access rules
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> http_access allow website1
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> http_access allow website2
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> http_access allow website3
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> ...
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> http_access deny all
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> Some are using rewrites
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> url_rewrite_program /usr/local/etc/squid/url_rewrite.py
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> url_rewrite_children 20
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> url_rewrite_access allow website1
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> url_rewrite_access allow website3
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> ...
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> url_rewrite_access deny all
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> Then my access logs
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> # First I grab everything in one
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> access_log daemon:/var/log/squid/access.log squid all
</I>&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> access_log daemon:/var/log/squid/website1.log combined website1
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> access_log daemon:/var/log/squid/website2.log combined website2
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> access_log daemon:/var/log/squid/website3.log combined website3
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> ...
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> everything works, write down to one of the access logs, the data 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> shows up in the access.log file, the data shows up in the 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> individual logs for all the others, except that one.  If we use 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> website3 from the above example like my actual file the access 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> rule works on the url_rewrite_access allow line, but for some 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> reason is failing on the log line.  squid -k parse doesn't show 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> any errors, and shows a Processing: access_log 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> daemon:/var/log/squid/website3.log combined website3 line in the 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> output.
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> The log in question was originally at the end of my access_log 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> list section, so I changed the order around to see if for some 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> reason it was only the last one not working, no change still only 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> that one not working, And the new last one in the list still works 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> as expected.
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> I know the ACL is working as it works correctly on the rewrite 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> rule and the http access just above the log rules, anyone have any 
</I>&gt;&gt;&gt;&gt;&gt;&gt;<i> ideas on how I can figure out why the log entry isn't working?
</I>&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;<i> Changed lines back to daemon, changed acl on logs to the rewrite side 
</I>&gt;&gt;&gt;<i> used on the cache_peer_access lines later in the configuration.  
</I>&gt;&gt;&gt;<i> Works now, and logs even show up with the pre-rewrite rule host 
</I>&gt;&gt;&gt;<i> information...
</I>&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;<i> That does make me wonder why some lines were getting logged but not 
</I>&gt;&gt;&gt;<i> all, the sites I thought were working do have higher usage, maybe I 
</I>&gt;&gt;&gt;<i> was still missing a lot from them, and just not knowing it.  I guess 
</I>&gt;&gt;&gt;<i> I will see if my webalizer reports show a huge gain in hit count over 
</I>&gt;&gt;&gt;<i> the old records from the the 3.1.20 installation, of if this behavior 
</I>&gt;&gt;&gt;<i> is only evident in the 3.2 branch.
</I>&gt;&gt;&gt;<i> 
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> I think you will find that the lines being logged previously were on
</I>&gt;&gt;<i> the requests which were either not rewritten at all or were re-written
</I>&gt;&gt;<i> from another requests URL which was being logged.
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> Each of the ACL-driven directive labels in squid.conf is effectively
</I>&gt;&gt;<i> an event trigger script - deciding whether or not to perform some
</I>&gt;&gt;<i> action. This only makes sense testing when that action choice is
</I>&gt;&gt;<i> requried.  Squid processing pathway checks http_access first, ... then
</I>&gt;&gt;<i> some others, ... then url_rewriting, ... then the destination
</I>&gt;&gt;<i> selection (cache_peer and others), ... then when the transaction is
</I>&gt;&gt;<i> fully completed access_log output decision are done.
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> Amos
</I>&gt;<i> 
</I>&gt;<i> Last night I applied the FreeBSD 10.1-RELEASE-p6 Update and Upgraded
</I>&gt;<i> the ports which included Squid 3.4.12, I enabled the LAX HTTP option
</I>&gt;<i> in the ports configuration with adds the --enable-http-violations
</I>&gt;<i> compile option. With the intention to enable broken_posts option in
</I>&gt;<i> the configuration. I will hopefully be able to apply any necessary
</I>&gt;<i> changes to the production system after I test them now.
</I>&gt;<i> When doing this update I did have a thought the system is running in a
</I>&gt;<i> FreeBSD jail and not on the base system is there a chance this issue
</I>&gt;<i> is caused by running within a jail? curious if anyone has ran into
</I>&gt;<i> specific issues running Squid in a FreeBSD jail before?
</I>
Well I am at a loss, debugging hasn't led to anything more than a 
timeout occurs. I was able to create a test PHP form to upload files on 
an Apache server and upload up to a 264MB file. I didn't try any larger 
files though I suspect it would work up to the configured 1024MB that I 
had Apache configured for. So its not all HTTPS only those files going 
to our OWA and Sharepoint servers. The only settings I can find that 
changes the behavior at all is to change the &quot;write_timeout&quot; to 
something smaller, like 45 seconds and then it errors sooner instead of 
taking forever to give up.

I tried uninstalling the Squid 3.4 FreeBSD port and using the 3.3 port 
instead on the test system, no change. I also tried installing 3.5 from 
source using the same configure options that my 3.4 port returned with 
squid -v, again no change.

I have verified that the IIS logs show a client request timeout has 
occurred, the broken_posts allow didn't create any change in behavior. I 
do know that if I point the browser directly to the Exchange server it 
works, so its only broken going through the reverse the proxy. If I 
point the browser through a forwarding Squid proxy that knows how to 
talk directly to the exchange server instead of the reverse proxy it 
works with no special settings. If I post a large debugging file to a 
website do I have any volunteers to look at it and see if they can see 
what's going on?


-- 
Thanks,
    Dean E. Weimer
    <A HREF="http://www.dweimer.net/">http://www.dweimer.net/</A>

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="002756.html">[squid-users] Reverse Proxy Funny Logging Issue
</A></li>
	<LI>Next message (by thread): <A HREF="002783.html">[squid-users] Reverse Proxy Funny Logging Issue
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2767">[ date ]</a>
              <a href="thread.html#2767">[ thread ]</a>
              <a href="subject.html#2767">[ subject ]</a>
              <a href="author.html#2767">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
