From squid at peralex.com  Fri Apr  1 05:47:00 2016
From: squid at peralex.com (squid at peralex.com)
Date: Fri, 1 Apr 2016 07:47:00 +0200
Subject: [squid-users] Slowly rising CPU load (eventually hits 100)
In-Reply-To: <56FD53D3.4040006@measurement-factory.com>
References: <ndja5h$f9j$1@ger.gmane.org>
 <56FD53D3.4040006@measurement-factory.com>
Message-ID: <56FE0B54.20505@peralex.com>

On 2016-03-31 18:44, Alex Rousskov wrote:
> 
> My working theory is that the longer you let your Squid run, the bigger
> objects it might store in RAM, increasing the severity of the linear
> search delays mentioned below. A similar pattern may also be caused by
> larger objects becoming more popular during certain days of the week.
> 

Thanks.  The current maximum_object_size_in_memory is 19 MB.

> 
> In summary, dealing with in-RAM objects significantly larger than 1MB
> bigger the object, the longer Squid takes to scan its nodes.
> 
> Short term, try limiting the size of in-RAM objects using
> maximum_object_size_in_memory first. If that solves the problem, then,
> most likely, only cached objects are affected.

I'll try this next, after I've given Yuri's suggestion a while to yield
results (or not).

> Also, forcing shared memory cache (even if you are not using SMP Squid)
> shared memory code itself does not have the above linear search, SMP
> Squid still uses local memory code and might hit the same linear search.

I'll look at that too.

> guess less. Please point to or copy to this email exchange to your bug
> report.

I've added bug http://bugs.squid-cache.org/show_bug.cgi?id=4477, and
included a reference to this thread at the end of the bug report.

Thanks for the assistance.
Mark






From o.calvano at gmail.com  Fri Apr  1 08:38:45 2016
From: o.calvano at gmail.com (Olivier CALVANO)
Date: Fri, 1 Apr 2016 10:38:45 +0200
Subject: [squid-users] We have a big problems with Squid 3.3.8,
	it's a bug ?
In-Reply-To: <56FD0104.4060903@treenet.co.nz>
References: <CAJajPeev0UR1EnqNJ55EMiFCAiRU55ZFUqc+csZ-t5xvJ_dzcQ@mail.gmail.com>
 <CAJajPed=dbAv=cA4fgbBFFAGMLavt+EOhmidMMHURXrvvqhXZg@mail.gmail.com>
 <56FD0104.4060903@treenet.co.nz>
Message-ID: <CAJajPeeDyXk5+Mu346gRffh+KUb5r4ZrHpA0zO8t+K=7kq5iwA@mail.gmail.com>

switch to 3.5 will be complicated because you have to upgrade all CentOS

how I can do to find the cause?

2016-03-31 12:50 GMT+02:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 31/03/2016 10:18 p.m., Olivier CALVANO wrote:
> > anyone think's if this bug are on 3.5 version too ?
> >
>
> It is difficult to say without actually knowing the cause (even
> roughly). There have been so many things that could be causing it which
> changed between those two versions. Even within the 3.5 series - so it
> may exist or not in early 3.5 and be different in current releases.
>
> If you are in a position to upgrade to 3.5 and it works okay for you I
> recommend doing so anyway. There are significant other issues (like the
> security vulnerabilities) that make the upgrade away from older Squid
> versions a very good idea.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160401/2d74a365/attachment.htm>

From bhsreenath at gmail.com  Fri Apr  1 12:40:33 2016
From: bhsreenath at gmail.com (Sreenath BH)
Date: Fri, 1 Apr 2016 18:10:33 +0530
Subject: [squid-users] Query about login=pass
Message-ID: <CALgKBSmu4DnmGbFhMdvUUu5WVVpn=uNwQVkoZ5gLvUT8_4kNtQ@mail.gmail.com>

Hi All,

We have a setup with two squid servers lets say, squid1 and squid2.
Requests land at Squid1 and it sends the request to squid2. Squid2
uses X-User-ID and Authorization headers for authenticating the user,
and on success, fetches data from another webserver and returns the
data. If authentication fails, it returns a 401 response.

What we have observed is that for some reason, squid does not send the
Authorization header to the upstream squid server. However, X-User-ID
header is always sent to upstre.

10.135.81.100 is squid2.

Here is configuration of squid1, where we see the problem.
------------------
acl    test_upload   urlpath_regex   ^/upload
acl    test_nms       urlpath_regex   ^/nms
acl    trash_misc    urlpath_regex   ^/trash

http_port 80 accel defaultsite=sitgateway.qiodrive.com vhost
https_port 443 cert=/etc/squid3/certificates/test.crt
key=/etc/squid3/certificates/qiodrivekey.key
cafile=/etc/squid3/certificates/gd_bundle-g2-g1.crt accel

cache_peer 10.135.81.100 parent 80 0 no-query login=PASS originserver name=name1
cache_peer_access name1 allow test_upload
cache_peer_access name1 deny all

cache_peer 10.135.81.100 parent 80 0 no-query login=PASS originserver name=name2
cache_peer_access name2 allow test_nms
cache_peer_access name2 deny all

cache_peer 10.135.81.100 parent 80 0 no-query originserver name=name3
cache_peer_access name3 allow trash_misc
cache_peer_access name3 deny all
----------------

As can be seen above, we have associated different names  (name1,
name2 and name3) for the same Squid2 server, all listening at same
port also. Is this a correct way of doing it? I ran squid -parse on
the squid.conf file and it did not report any problem.

1. Squid1 listens on both 80 and SSL port. If request comes on SSL
port, will it send Authorization token to Squid that is not SSL squid?

2. In the source code of squid (http.c) I see following lines in the function:

void
copyOneHeaderFromClientsideRequestToUpstreamRequest(const
HttpHeaderEntry *e, const String strConnection, const HttpRequest *
request, HttpHeader * hdr_out, const int we_do_ranges, const
HttpStateFlags &flags)

   case HDR_AUTHORIZATION:
        /** \par WWW-Authorization:
         * Pass on WWW authentication */

        if (!flags.originpeer) {
            hdr_out->addEntry(e->clone());
        } else {
            /** \note In accelerators, only forward authentication if enabled
             * (see also httpFixupAuthentication for special cases)
             */
            if (request->peer_login &&
                    (strcmp(request->peer_login, "PASS") == 0 ||
                     strcmp(request->peer_login, "PASSTHRU") == 0 ||
                     strcmp(request->peer_login, "PROXYPASS") == 0)) {
                hdr_out->addEntry(e->clone());
            }
        }

        break;


I don't understand what might prevent squid from sending the
Authorization header.

Any help appreciated,

thanks,
Sreenath


From mkraju123 at gmail.com  Fri Apr  1 13:56:11 2016
From: mkraju123 at gmail.com (Raju M K)
Date: Fri, 1 Apr 2016 19:26:11 +0530
Subject: [squid-users] videos caching over https
Message-ID: <CAGycgFgQvXM=dUz3ZnAAV1ACKchA8HTWjQAbVnN4O9ahau8XdA@mail.gmail.com>

Hi users,
iam able to cache videos through http
by adding refresh_pattern -i .amazonaws.com(m4f|mp4)
but i need to cache through https as well. from single url only
please help
-- 
Regards,
M K Raju.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160401/594109d2/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr  1 18:08:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 2 Apr 2016 07:08:09 +1300
Subject: [squid-users] We have a big problems with Squid 3.3.8,
 it's a bug ?
In-Reply-To: <CAJajPeeDyXk5+Mu346gRffh+KUb5r4ZrHpA0zO8t+K=7kq5iwA@mail.gmail.com>
References: <CAJajPeev0UR1EnqNJ55EMiFCAiRU55ZFUqc+csZ-t5xvJ_dzcQ@mail.gmail.com>
 <CAJajPed=dbAv=cA4fgbBFFAGMLavt+EOhmidMMHURXrvvqhXZg@mail.gmail.com>
 <56FD0104.4060903@treenet.co.nz>
 <CAJajPeeDyXk5+Mu346gRffh+KUb5r4ZrHpA0zO8t+K=7kq5iwA@mail.gmail.com>
Message-ID: <56FEB909.7050105@treenet.co.nz>

On 1/04/2016 9:38 p.m., Olivier CALVANO wrote:
> switch to 3.5 will be complicated because you have to upgrade all CentOS
> 

These packages might be some help with that:
<http://wiki.squid-cache.org/KnowledgeBase/CentOS#Squid-3.5>

> how I can do to find the cause?
> 

There isn't any clear ccause, so if you really want to go that way it
starts with configuring "debug_options ALL,9" to log all debug
information your Squid can produce. Once that is running you will need
to preproduce the problem. Note that you will have to capture the
entirety of one of those multiple-hour long transactions.

This will result in a rather large cache.log which will then have to be
searched through to find the transaction TCP connection details. Which
will show the FD number(s) being used by it.

Filtering the log on that "FD n" will give you a trace of what is being
done on the connection and the timing of those things - hopefully giving
a hint as to where to look for more details.

Good luck.
Amos



From squid3 at treenet.co.nz  Fri Apr  1 18:27:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 2 Apr 2016 07:27:04 +1300
Subject: [squid-users] Query about login=pass
In-Reply-To: <CALgKBSmu4DnmGbFhMdvUUu5WVVpn=uNwQVkoZ5gLvUT8_4kNtQ@mail.gmail.com>
References: <CALgKBSmu4DnmGbFhMdvUUu5WVVpn=uNwQVkoZ5gLvUT8_4kNtQ@mail.gmail.com>
Message-ID: <56FEBD78.30004@treenet.co.nz>

On 2/04/2016 1:40 a.m., Sreenath BH wrote:
> Hi All,
> 
> We have a setup with two squid servers lets say, squid1 and squid2.
> Requests land at Squid1 and it sends the request to squid2. Squid2
> uses X-User-ID and Authorization headers for authenticating the user,
> and on success, fetches data from another webserver and returns the
> data. If authentication fails, it returns a 401 response.
> 
> What we have observed is that for some reason, squid does not send the
> Authorization header to the upstream squid server. However, X-User-ID
> header is always sent to upstre.

X-User-ID is a custom header. It would appear that it is not listed in
the Connection: header, so that makes it an end-to-end feature to be
delivered all the way to the origin server.
 This is why Squid passes it onward.



> 
> 10.135.81.100 is squid2.
> 
> Here is configuration of squid1, where we see the problem.
> ------------------
> acl    test_upload   urlpath_regex   ^/upload
> acl    test_nms       urlpath_regex   ^/nms
> acl    trash_misc    urlpath_regex   ^/trash
> 
> http_port 80 accel defaultsite=sitgateway.qiodrive.com vhost
> https_port 443 cert=/etc/squid3/certificates/test.crt
> key=/etc/squid3/certificates/qiodrivekey.key
> cafile=/etc/squid3/certificates/gd_bundle-g2-g1.crt accel

You have configured your Squid to be a reverse-proxy. So that it acts as
if it were an origin server and *consumes* the WWW-Auth headers (rather
than the usual Proxy-Auth headers).



> cache_peer 10.135.81.100 parent 80 0 no-query login=PASS originserver name=name1
> cache_peer_access name1 allow test_upload
> cache_peer_access name1 deny all
> 
> cache_peer 10.135.81.100 parent 80 0 no-query login=PASS originserver name=name2
> cache_peer_access name2 allow test_nms
> cache_peer_access name2 deny all


login=PASS will attempt to login with Basic auth credentials to the
peer. If, and only if, Squid has some Basic auth credentials to send.


> 
> cache_peer 10.135.81.100 parent 80 0 no-query originserver name=name3
> cache_peer_access name3 allow trash_misc
> cache_peer_access name3 deny all
> ----------------
> 
> As can be seen above, we have associated different names  (name1,
> name2 and name3) for the same Squid2 server, all listening at same
> port also. Is this a correct way of doing it? I ran squid -parse on
> the squid.conf file and it did not report any problem.
> 
> 1. Squid1 listens on both 80 and SSL port. If request comes on SSL
> port, will it send Authorization token to Squid that is not SSL squid?

The two details are not related. So there is not any yes/no answer to that.
 For any message, *if* that message is allowed to be sent to the
particular peer, then the headers allowed to be sent to that peer will
be sent.


> 
> 2. In the source code of squid (http.c) I see following lines in the function:
> 

> void
> copyOneHeaderFromClientsideRequestToUpstreamRequest(const
> HttpHeaderEntry *e, const String strConnection, const HttpRequest *
> request, HttpHeader * hdr_out, const int we_do_ranges, const
> HttpStateFlags &flags)
> 

This function happens long after the auth header is consumed and/or
re-constructed by Squid. It is only relevant to whatever auth headers
Squid has decided to send upstream have been added back into the request.

> 
> I don't understand what might prevent squid from sending the
> Authorization header.


What login=PASS does is tell Squid to use the Basic authentication
credentials it has - either from the Basic authentication helper it is
using to perform auth, or the external ACL helper, or the original
client request (in that order) to login to the upstream peer.

This can be prevented by several things:
 * the upstream peer not requesting login.
 * no Basic auth credentials being known. eg, if you are not using Basic
auth to the client.
 * ICAP/eCAP adaptation stripping away the credentials

To pass on any non-Basic auth credentials use login=PASSTHRU instead of
login=PASS.

Amos



From squid3 at treenet.co.nz  Fri Apr  1 18:32:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 2 Apr 2016 07:32:42 +1300
Subject: [squid-users] videos caching over https
In-Reply-To: <CAGycgFgQvXM=dUz3ZnAAV1ACKchA8HTWjQAbVnN4O9ahau8XdA@mail.gmail.com>
References: <CAGycgFgQvXM=dUz3ZnAAV1ACKchA8HTWjQAbVnN4O9ahau8XdA@mail.gmail.com>
Message-ID: <56FEBECA.7020200@treenet.co.nz>

On 2/04/2016 2:56 a.m., Raju M K wrote:
> Hi users,
> iam able to cache videos through http
> by adding refresh_pattern -i .amazonaws.com(m4f|mp4)
> but i need to cache through https as well. from single url only
> please help
> 

To do anything like caching with HTTPS content you need to have access
to the decrypted messages. Squid provides SSL-Bump feature for
intercepted traffic decryption.

Once Squid has the decrypted content the messages are handled the same
way as HTTP messages when it comes to caching.

Note that content "in the cloud" has a bad habit of not being cacheable.
And that when the web service is using TLS properly it cannot be bumped.

Amos



From squid3 at treenet.co.nz  Sat Apr  2 08:25:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 2 Apr 2016 21:25:29 +1300
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2016:4 Denial of
 Service issue in HTTP Response processing.
Message-ID: <56FF81F9.7000202@treenet.co.nz>

__________________________________________________________________

Squid Proxy Cache Security Update Advisory SQUID-2016:4
__________________________________________________________________

Advisory ID:        SQUID-2016:4
Date:               April 02, 2016
Summary:            Denial of Service issue
                    in HTTP Response processing.
Affected versions:  Squid 3.x -> 3.5.15
                    Squid 4.x -> 4.0.7
Fixed in version:   Squid 4.0.8, 3.5.16
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_4.txt
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3948
__________________________________________________________________

Problem Description:

 Due to incorrect bounds checking Squid is vulnerable to a denial
 of service attack when processing HTTP responses.

__________________________________________________________________

Severity:

 This problem allows a malicious client script and remote server
 delivering certain unusual HTTP response syntax to trigger a
 denial of service for all clients accessing the Squid service.

__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid version 3.5.16 and 4.0.8.

 In addition, a patch addressing this problem for the stable
 release can be found in our patch archives:

Squid 3.5:
 http://www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14016.patch

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

 All unpatched Squid-3.0 versions are vulnerable.

 All unpatched Squid-3.1 versions are vulnerable.

 All unpatched Squid-3.2 versions are vulnerable.

 All unpatched Squid-3.3 versions are vulnerable.

 All unpatched Squid-3.4 versions are vulnerable.

 All unpatched Squid-3.5 up to and including Squid-3.5.15 are
 vulnerable.

 All unpatched Squid-4.0 up to and including 4.0.7 are vulnerable.

__________________________________________________________________

Workaround:

 There are no good workarounds known for this vulnerability.

 The following squid.conf settings can protect Squid-3.5 (only):

   acl Vary rep_header Vary .
   store_miss deny Vary

Or,

 The following squid.conf setting can protect Squid-3.0 or later:

   cache deny all

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If your install and build Squid from the original Squid sources
 then the squid-users at lists.squid-cache.org mailing list is your
 primary support point. For subscription details see
 <http://www.squid-cache.org/Support/mailing-lists.html>.

 For reporting of non-security bugs in the latest STABLE release
 the squid bugzilla database should be used
 <http://bugs.squid-cache.org/>.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at lists.squid-cache.org mailing list. It's a closed
 list (though anyone can post) and security related bug reports
 are treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 This vulnerability was reported by Santiago R. Rincon of Debian.
 Fixed by Amos Jeffries from Treehouse Networks Ltd.

__________________________________________________________________

Revision history:

 2016-03-20 11:25:04 UTC Initial Report
 2016-04-01 06:15:31 UTC Patch Released
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Sat Apr  2 08:25:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 2 Apr 2016 21:25:23 +1300
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2016:3 Buffer
 overrun issue in pinger ICMPv6 processing.
Message-ID: <56FF81F3.3020606@treenet.co.nz>

__________________________________________________________________

Squid Proxy Cache Security Update Advisory SQUID-2016:3
__________________________________________________________________

Advisory ID:        SQUID-2016:3
Date:               April 02, 2016
Summary:            Buffer overrun issue
                    in pinger ICMPv6 processing.
Affected versions:  Squid 3.1.0 -> 3.5.15
                    Squid 4.0 -> 4.0.7
Fixed in version:   Squid 4.0.8, 3.5.16
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_3.txt
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-3947
__________________________________________________________________

Problem Description:

 Due to a buffer overrun Squid pinger binary is vulnerable to
 denial of service or information leak attack when processing
 ICMPv6 packets.

 This bug also permits the server response to manipulate other
 ICMP and ICMPv6 queries processing to cause information leak.
__________________________________________________________________

Severity:

 This bug allows any remote server to perform a denial of service
 attack on the Squid service by crashing the pinger. This may
 affect Squid HTTP routing decisions. In some configurations,
 sub-optimal routing decisions may result in serious service
 degradation or even transaction failures.

 If the system does not contain buffer-overrun protection leading
 to that crash this bug will instead allow attackers to leak
 arbitrary amounts of information from the heap into Squid log
 files. This is of higher importance than usual because the pinger
 process operates with root priviliges.
__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid version 3.5.15 and 4.0.8.

 In addition, patches addressing this problem for stable releases
 can be found in our patch archives:

Squid 3.1:
 http://www.squid-cache.org/Versions/v3/3.1/changesets/squid-3.1-10495.patch

Squid 3.2:
 http://www.squid-cache.org/Versions/v3/3.2/changesets/squid-3.2-11839.patch

Squid 3.3:
 http://www.squid-cache.org/Versions/v3/3.3/changesets/squid-3.3-12694.patch

Squid 3.4:
 http://www.squid-cache.org/Versions/v3/3.4/changesets/squid-3.4-13232.patch

Squid 3.5:
 http://www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14015.patch

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

 All Squid-2.x versions are not vulnerable to this problem.

 All Squid-3.0 versions are not vulnerable to this problem.

 All Squid built with --disable-icmp are not vulnerable to this
 problem.

 All Squid built with --disable-ipv6 are not vulnerable to this
 problem.

 All Squid-3.x configured with "pinger_enable off" in squid.conf
 are not vulnerable to this problem.

 Check the server running processes list to determine if the Squid
 service is running a "pinger" child process.

 All unpatched Squid-3 versions up to and including 3.5.15
 running the pinger process are vulnerable to this problem.

 All unpatched Squid-4 versions up to and including 4.0.7
 running the pinger process are vulnerable to this problem.

__________________________________________________________________

Workaround:

 Disable the pinger process in squid.conf:

   pinger_enable off

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If your install and build Squid from the original Squid sources
 then the squid-users at lists.squid-cache.org mailing list is your
 primary support point. For subscription details see
 <http://www.squid-cache.org/Support/mailing-lists.html>.

 For reporting of non-security bugs in the latest STABLE release
 the squid bugzilla database should be used
 <http://bugs.squid-cache.org/>.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at lists.squid-cache.org mailing list. It's a closed
 list (though anyone can post) and security related bug reports
 are treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 The vulnerability was reported and fixed by Yuriy M. Kaminskiy.

__________________________________________________________________

Revision history:

 2016-02-21 23:42:28 GMT Initial Report
 2016-03-28 22:52:58 GMT Patch Released
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Sat Apr  2 08:26:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 2 Apr 2016 21:26:14 +1300
Subject: [squid-users] [squid-announce] Squid 3.5.16 is available
Message-ID: <56FF8226.8080700@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.5.16 release!


This release is a security and bug fix release resolving several
vulnerabilities and issues found in the prior Squid releases.


The major changes to be aware of:


* SQUID-2016:4 - Denial of Service issue in HTTP Response processing

    http://www.squid-cache.org/Advisories/SQUID-2016_4.txt
    aka. CVE-2016-3948

This is another of the bugs left unfixed by the SQUID-2016:2 patches.
The visible symptom is assertions about:
 "String.cc:*: 'len_ + len <65536'"

There is an attack in the wild for this one, but not as widely as for
the previous issues.


* SQUID-2016:3 - Buffer overrun issue in pinger ICMPv6 processing.

    http://www.squid-cache.org/Advisories/SQUID-2016_3.txt
    aka. CVE-2016-3947

This bug shows up as pinger crashing with Icmp6::Recv errors. This may
affect Squid HTTP routing decisions. In some configurations, sub-optimal
routing decisions may result in serious service degradation or even
transaction failures.

All previous Squid-3 releases are affected by both these issues. See the
advisory for further details. Upgrade or patching should be considered a
high priority.


* pinger: drop capabilities on Linux

On Linux, it is now possible to install pinger helper with only
CAP_NET_RAW permissions raised instead of full setuid-root:

  (setcap cap_net_raw+ep /path/to/pinger &&
   chmod u-s /path/to/pinger) || :

Other operating systems without libcap capabilities features are not
affected by this change.


* Bug #4447: FwdState.cc:447 "serverConnection() == conn" assertion

This rather cripling bug appears after the CVE-2016-2569 patch. It
turned out to be a race condition closing connections and has now been
fully fixed.



 All users of Squid-3 or older are urged to upgrade to this release as
soon as possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Sat Apr  2 08:26:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 2 Apr 2016 21:26:37 +1300
Subject: [squid-users] [squid-announce] Squid 4.0.8 beta is available
Message-ID: <56FF823D.6040507@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.8 release!


This release is a security and bug fix release resolving several
vulnerabilities and issues found in the prior Squid releases.


The major changes to be aware of:


* SQUID-2016:4 - Denial of Service issue in HTTP Response processing

    http://www.squid-cache.org/Advisories/SQUID-2016_4.txt
    aka. CVE-2016-3948

This is another of the bugs left unfixed by the SQUID-2016:2 patches.
The visible symptom is assertions about:
"String.cc:*: 'len_ + len <65536'"

There is an attack in the wild for this one, but not as widely as for
the previous issues.


* SQUID-2016:3 - Buffer overrun issue in pinger ICMPv6 processing.

    http://www.squid-cache.org/Advisories/SQUID-2016_3.txt
    aka. CVE-2016-3947

This bug shows up as pinger crashing with Icmp6::Recv errors. This may
affect Squid HTTP routing decisions. In some configurations, sub-optimal
routing decisions may result in serious service degradation or even
transaction failures.


All previous Squid-4 releases are affected by both these issues. See the
advisory for further details. Upgrade should be considered a high priority.


* Bug #3826: SMP compatibility with systemd and --foreground option

The process management redesign in Squid-4 has finally reached a point
where we can say Squid is compatible with the systemd init system even
when SMP workers are used. A .service file is provided to control Squid
properly without any noticable glitches or lack of SMP functionality.

These changes are not specific to systemd, the same design fixes many
outstanding issues Squid had with Upstart and OpenRC init systems and
third party daemon managers in general.


* Bug #1979: Add ACL-driven server_pconn_for_nonretriable

This new squid.conf directive allows admin to tune when Squid can re-use
existing persistent connections for requests such as POST which are
usually quite risky. The risk is that the connection gets terminated
suddenly while Squid is still sending and it has to be bumped back to
the client as an error page. Some networks are loaded with enough
traffic that this is only a low risk and can use persistent connections
fine.


* Bug #4459: FHS compliance updates

The FHS standard indicates the /var/cache/squid/ path should be used for
cached data. The netdb features data journal fully meets the criteria so
has been moved there. The ssl_crtd database (ssl_db/ directory) almost
meets the criteria, and has been moved due to its security need for
particular path permissions.

Explicitly configured alternative locations will remain where they are.
New installations and implicit default paths will automatically change
to using these locations when upgrading to this Squid version.


* Add reply_header_add directive

This new directivs adds the ability to add custom response headers to
replies sent to the client. Matching the already existing
request_header_add directive which operates on server requests. At
present CONNECT tunnels and 1xx status responses are not affected by
this new directive.


* Add reply_header_add directive

When using SMP functionality Squid makes use of shared memory. If the
system is not able to allocate enough memory Squid can crash with SIGBUS
errors.

This new directive adds the ability to pre-allocate all necessary shared
memory when Squid is starting. Doing this will ensure that Squid has the
necessary amount of shared memory available when running (or will halt
during startup), but the process can be quite slow. The default for now
is to retain the old behaviour and allocate shared memory only when it
is needed.



 All users of Squid-4.0.x are urged to upgrade to this release as soon
as possible.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From chip_pop at hotmail.com  Sat Apr  2 22:09:39 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 2 Apr 2016 15:09:39 -0700 (PDT)
Subject: [squid-users] clientProcessHit
In-Reply-To: <1457552680940-4676573.post@n4.nabble.com>
References: <56E06C67.4050708@gmail.com>
 <1457547955501-4676562.post@n4.nabble.com> <56E0723A.5040903@gmail.com>
 <1457548800299-4676565.post@n4.nabble.com> <56E0759D.3020000@gmail.com>
 <1457549844762-4676567.post@n4.nabble.com> <56E07A26.4090101@gmail.com>
 <1457551370293-4676571.post@n4.nabble.com> <56E08037.3000004@gmail.com>
 <1457552680940-4676573.post@n4.nabble.com>
Message-ID: <1459634979927-4676891.post@n4.nabble.com>

again if i only me on server just sending this file multiple of time i keep
getting in acsess.log 
2016/04/03 01:08:09.245 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://12kms.tayyar.org/Services.asmx/JsonFile'
'accept-encoding="gzip,%20deflate"'
2016/04/03 01:08:09.245 kid1| 24,8| SBuf.cc(124) ~SBuf: SBuf2908458
destructed
2016/04/03 01:08:09.245 kid1| clientProcessHit: Vary object loop!
ifs it bug or what ??  here is the debug output all,9
--------------------------------------------------
http://12kms.tayyar.org/Services.asmx/JsonFile

GET /Services.asmx/JsonFile HTTP/1.1
Host: 12kms.tayyar.org
User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:43.0) Gecko/20100101
Firefox/43.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
DNT: 1
Cookie: __cfduid=d8312ea7ec9e0cad35fc1c33aeeea42c31456783212;
__utma=80610962.1196730177.1456783246.1459622933.1459633131.47;
__utmz=80610962.1456783246.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none);
_em_vt=1c38b4dd1820be77bbff4015840d56d4bf7bf79fd3-4198383757003d93;
__gads=ID=9ac649b1dd30ef2e:T=1456783233:S=ALNI_MYsBTt4cTqQuwii3xpn7mBiCsKA1A;
__utmc=80610962; __utmb=80610962.4.10.1459633131;
_em_v=8cfac1d515380b25f9feecec18de57003ba9e1f053-3690364257003d93
Connection: keep-alive
Pragma: no-cache
Cache-Control: no-cache

HTTP/1.1 200 OK
Date: Sat, 02 Apr 2016 22:12:05 GMT
Content-Type: application/json; charset=utf-8
Content-Length: 27262
Cache-Control: private, max-age=0
Content-Encoding: gzip
Vary: Accept-Encoding
access-control-allow-origin: *
X-AspNet-Version: 4.0.30319
X-Powered-By: ASP.NET
Strict-Transport-Security: max-age=0; includeSubDomains
Server: cloudflare-nginx
X-Cache: MISS from proxy.netgates.com
Connection: keep-alive
----------------------------------------------------------
2016/04/03 01:08:09.244 kid1| 73,3| HttpRequest.cc(687) storeId: sent back
canonicalUrl:http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.244 kid1| 20,3| store_dir.cc(1073) get: storeGet:
looking up DD53DC3A473A865ED9C70084B05E7385
2016/04/03 01:08:09.244 kid1| 20,3| store_dir.cc(697) find: got in-transit
entry: e:d110885 at 0=msw2RDV/0x317b7b50*0
2016/04/03 01:08:09.244 kid1| 47,3| ufs/UFSSwapDir.cc(526) reference:
referencing 0x317b7b50 0/110885

----> as you see its in cache and it supost to be hiy insted it return miss 
2016/04/03 01:08:09.244 kid1| 85,3| client_side_reply.cc(1684)
identifyFoundObject: default HIT e:d110885 at 0=msw2RDV/0x317b7b50*0
2016/04/03 01:08:09.244 kid1| 20,3| store.cc(483) lock:
clientReplyContext::doGetMoreData locked key
DD53DC3A473A865ED9C70084B05E7385 e:d110885 at 0=msw2RDV/0x317b7b50*1
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(299) cbdataInternalAlloc:
Allocating 0x8f3a7ca8
2016/04/03 01:08:09.244 kid1| 20,7| store.cc(317) storeClientType:
0x4de7a700 lo: 0 hi: 3917 size: 24740
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x830a9b08

prepare tos to send hit match our file 
2016/04/03 01:08:09.244 kid1| 33,2| QosConfig.cc(177) doTosLocalHit: QOS:
Setting TOS for local hit, TOS=48
2016/04/03 01:08:09.244 kid1| 50,3| ../../src/ip/Qos.cci(22) setSockTos: for
FD 9 to 48
2016/04/03 01:08:09.244 kid1| 90,3| store_client.cc(200) copy:
store_client::copy: DD53DC3A473A865ED9C70084B05E7385, from 0, for length
4096, cb 1, cbdata 0x32b5bd28
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x32b5bd28=1
2016/04/03 01:08:09.244 kid1| 20,3| store.cc(483) lock: store_client::copy
locked key DD53DC3A473A865ED9C70084B05E7385 e:d110885 at 0=msw2RDV/0x317b7b50*2
2016/04/03 01:08:09.244 kid1| 90,3| store_client.cc(297) storeClientCopy2:
storeClientCopy2: DD53DC3A473A865ED9C70084B05E7385
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x8f3a7ca8=1
2016/04/03 01:08:09.244 kid1| 33,5| store_client.cc(329) doCopy:
store_client::doCopy: co: 0, hi: 3917
so  the file in memory 
2016/04/03 01:08:09.244 kid1| 90,3| store_client.cc(369) startSwapin:
store_client::doCopy: Need to open swap in file
2016/04/03 01:08:09.244 kid1| 20,3| store_swapin.cc(32) storeSwapInStart:
already IN_MEMORY

2016/04/03 01:08:09.244 kid1| 20,3| store_swapin.cc(36) storeSwapInStart:
storeSwapInStart: called for : 0 0001B125 DD53DC3A473A865ED9C70084B05E7385
2016/04/03 01:08:09.244 kid1| 20,3| store_swapin.cc(49) storeSwapInStart:
storeSwapInStart: Opening fileno 0001B125
2016/04/03 01:08:09.244 kid1| 79,3| ufs/UFSStrategy.cc(62) open: fileno
0001B125
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(299) cbdataInternalAlloc:
Allocating 0x32be5a68
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x8f3a7ca8=2
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(299) cbdataInternalAlloc:
Allocating 0x32be5b28
2016/04/03 01:08:09.244 kid1| 79,3|
DiskIO/DiskThreads/DiskThreadsDiskFile.cc(33) DiskThreadsDiskFile:
UFSFile::UFSFile: /mnt/cache-a/01/B1/0001B125
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x32be5b28=1
2016/04/03 01:08:09.244 kid1| 43,9| DiskIO/DiskThreads/aiops.cc(465)
squidaio_queue_request: squidaio_queue_request: 0x365d2220 type=1
result=0x35ca6ad0

2016/04/03 01:08:09.244 kid1| 90,3| store_client.cc(433) scheduleMemRead:
store_client::doCopy: Copying normal from memory
2016/04/03 01:08:09.244 kid1| 19,6| stmem.cc(229) copy: memCopy: 0x4de7a720
[0,4096)
2016/04/03 01:08:09.244 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x32b5bd28
cache hit with file size  3917
2016/04/03 01:08:09.244 kid1| 88,3| client_side_reply.cc(462) cacheHit:
clientCacheHit: http://12kms.tayyar.org/Services.asmx/JsonFile, 3917 bytes
2016/04/03 01:08:09.244 kid1| 73,3| HttpRequest.cc(687) storeId: sent back
canonicalUrl:http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.244 kid1| 24,8| SBuf.cc(87) SBuf: SBuf2908458 created
from id SBuf2908451
2016/04/03 01:08:09.244 kid1| 55,9| HttpHeader.cc(1201) has: 0x4de7a978
lookup for 67
2016/04/03 01:08:09.244 kid1| 24,8| SBuf.cc(79) SBuf: SBuf2908459 created
2016/04/03 01:08:09.245 kid1| 55,9| HttpHeader.cc(1053) getList:
0x4de7a978joining for id 67
2016/04/03 01:08:09.245 kid1| 55,6| HttpHeader.cc(1076) getList: 0x4de7a978:
joined for id 67: Accept-Encoding
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(218) append: from c-string to id
SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(169) rawSpace: reserving 15 for
SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,8| SBuf.cc(932) cow: SBuf2908459 new
size:15
2016/04/03 01:08:09.245 kid1| 24,8| SBuf.cc(902) reAlloc: SBuf2908459 new
size: 15
2016/04/03 01:08:09.245 kid1| 24,9| MemBlob.cc(57) MemBlob: constructed,
this=0x92e01ea0 id=blob943044 reserveSize=15
2016/04/03 01:08:09.245 kid1| 24,8| MemBlob.cc(102) memAlloc: blob943044
memAlloc: requested=15, received=40
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(911) reAlloc: SBuf2908459 new
store capacity: 40
2016/04/03 01:08:09.245 kid1| 55,9| HttpHeader.cc(1201) has: 0x8ea00d78
lookup for 2
2016/04/03 01:08:09.245 kid1| 55,9| HttpHeader.cc(1053) getList:
0x8ea00d78joining for id 2
2016/04/03 01:08:09.245 kid1| 55,6| HttpHeader.cc(1076) getList: 0x8ea00d78:
joined for id 2: gzip, deflate
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(218) append: from c-string to id
SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(169) rawSpace: reserving 2 for
SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(176) rawSpace: SBuf2908459 not
growing
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(218) append: from c-string to id
SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(169) rawSpace: reserving 15 for
SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(176) rawSpace: SBuf2908459 not
growing
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(218) append: from c-string to id
SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(169) rawSpace: reserving 1 for
SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(176) rawSpace: SBuf2908459 not
growing
2016/04/03 01:08:09.245 kid1| 11,3| http.cc(660) httpMakeVaryMark:
accept-encoding="gzip,%20deflate"
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(139) assign: assigning
SBuf2908458 from SBuf2908459
2016/04/03 01:08:09.245 kid1| 24,8| SBuf.cc(124) ~SBuf: SBuf2908459
destructed
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(139) assign: assigning
SBuf2908451 from SBuf2908458

oops?? wat went wrong
2016/04/03 01:08:09.245 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://12kms.tayyar.org/Services.asmx/JsonFile'
'accept-encoding="gzip,%20deflate"'
2016/04/03 01:08:09.245 kid1| 24,8| SBuf.cc(124) ~SBuf: SBuf2908458
destructed

2016/04/03 01:08:09.245 kid1| clientProcessHit: Vary object loop!
2016/04/03 01:08:09.245 kid1| 88,4| client_side_reply.cc(630) processMiss:
GET http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.245 kid1| 90,3| store_client.cc(664) storeUnregister:
storeUnregister: called for 'DD53DC3A473A865ED9C70084B05E7385'
2016/04/03 01:08:09.245 kid1| 20,3| store_io.cc(76) storeClose: storeClose:
calling sio->close(2)
2016/04/03 01:08:09.245 kid1| 79,3| ufs/UFSStoreState.cc(120) close:
UFSStoreState::close: dirno 0, fileno 0001B125
2016/04/03 01:08:09.245 kid1| 79,3| ufs/UFSStoreState.cc(452) tryClosing:
0x32be5a68 tryClosing() closing = 0 flags.try_closing = 0 ioInProgress = 1
2016/04/03 01:08:09.245 kid1| 79,3| ufs/UFSStoreState.cc(456) tryClosing:
0x32be5a68 won't close since ioInProgress is true, bailing
2016/04/03 01:08:09.245 kid1| 45,9| cbdata.cc(321) cbdataInternalFree:
0x8f3a7ca8
2016/04/03 01:08:09.245 kid1| 45,9| cbdata.cc(333) cbdataInternalFree:
0x8f3a7ca8 has 2 locks, not freeing
2016/04/03 01:08:09.245 kid1| 20,3| store.cc(483) lock: storeUnregister
locked key DD53DC3A473A865ED9C70084B05E7385 e:d110885 at 0=msw2RDV/0x317b7b50*3
2016/04/03 01:08:09.245 kid1| 90,3| store_client.cc(758)
storePendingNClients: storePendingNClients: returning 0
2016/04/03 01:08:09.245 kid1| 20,3| store.cc(521) unlock: storeUnregister
unlocking key DD53DC3A473A865ED9C70084B05E7385
e:d110885 at 0=msw2RDV/0x317b7b50*3
2016/04/03 01:08:09.245 kid1| 20,3| store.cc(521) unlock:
clientReplyContext::removeStoreReference unlocking key
DD53DC3A473A865ED9C70084B05E7385 e:d110885 at 0=msw2RDV/0x317b7b50*2
2016/04/03 01:08:09.245 kid1| 20,3| store.cc(774) storeCreatePureEntry:
storeCreateEntry: 'http://12kms.tayyar.org/Services.asmx/JsonFile'
2016/04/03 01:08:09.245 kid1| 20,5| store.cc(370) StoreEntry: StoreEntry
constructed, this=0x339177b0
2016/04/03 01:08:09.245 kid1| 24,8| SBuf.cc(79) SBuf: SBuf2908460 created
2016/04/03 01:08:09.245 kid1| 19,9| stmem.cc(375) mem_hdr: 0x33917660 hi: 0
2016/04/03 01:08:09.245 kid1| 24,8| SBuf.cc(79) SBuf: SBuf2908461 created
2016/04/03 01:08:09.245 kid1| 20,3| MemObject.cc(97) MemObject: new
MemObject 0x33917640
2016/04/03 01:08:09.245 kid1| 55,7| HttpHeader.cc(446) HttpHeader: init-ing
hdr: 0x32ddf7f8 owner: 3
2016/04/03 01:08:09.245 kid1| 45,9| cbdata.cc(299) cbdataInternalAlloc:
Allocating 0x17e35c8
2016/04/03 01:08:09.245 kid1| 55,9| HttpHeader.cc(1201) has: 0x32ddf7f8
lookup for 49
2016/04/03 01:08:09.245 kid1| 55,9| HttpHeader.cc(1201) has: 0x32ddf7f8
lookup for 11
2016/04/03 01:08:09.245 kid1| 55,9| HttpHeader.cc(1201) has: 0x32ddf7f8
lookup for 26
2016/04/03 01:08:09.245 kid1| 24,7| SBuf.cc(139) assign: assigning
SBuf2908460 from SBuf2908450
2016/04/03 01:08:09.246 kid1| 20,3| store.cc(483) lock: storeCreateEntry
locked key [null_store_key] e:=V/0x339177b0*1
2016/04/03 01:08:09.246 kid1| 20,3| store_key_md5.cc(89) storeKeyPrivate:
storeKeyPrivate: GET http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.246 kid1| 20,3| store.cc(447) hashInsert:
StoreEntry::hashInsert: Inserting Entry e:=IV/0x339177b0*1 key
'0E226A96EBBE0B01539C215BA0A0436D'
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(299) cbdataInternalAlloc:
Allocating 0x34596e58
2016/04/03 01:08:09.246 kid1| 90,3| store_client.cc(200) copy:
store_client::copy: 0E226A96EBBE0B01539C215BA0A0436D, from 0, for length
4096, cb 1, cbdata 0x32b5bd28
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x32b5bd28=2
2016/04/03 01:08:09.246 kid1| 20,3| store.cc(483) lock: store_client::copy
locked key 0E226A96EBBE0B01539C215BA0A0436D e:=IV/0x339177b0*2
2016/04/03 01:08:09.246 kid1| 90,3| store_client.cc(297) storeClientCopy2:
storeClientCopy2: 0E226A96EBBE0B01539C215BA0A0436D
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x34596e58=1
2016/04/03 01:08:09.246 kid1| 33,5| store_client.cc(329) doCopy:
store_client::doCopy: co: 0, hi: 0
2016/04/03 01:08:09.246 kid1| 90,3| store_client.cc(341) doCopy:
store_client::doCopy: Waiting for more
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(426) cbdataInternalUnlock:
0x34596e58=0
2016/04/03 01:08:09.246 kid1| 20,3| store.cc(521) unlock: store_client::copy
unlocking key 0E226A96EBBE0B01539C215BA0A0436D e:=IV/0x339177b0*2
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x830a9b08
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x830a9b08=11
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(426) cbdataInternalUnlock:
0x830a9b08=10
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x830a9b08
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x830a9b08
2016/04/03 01:08:09.246 kid1| 17,3| FwdState.cc(332) Start:
'http://12kms.tayyar.org/Services.asmx/JsonFile'
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(299) cbdataInternalAlloc:
Allocating 0x8a4a0f48
2016/04/03 01:08:09.246 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding
client request local=192.168.55.5:3128 remote=10.4.4.60:2367 FD 9 flags=1,
url=http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.246 kid1| 20,3| store.cc(483) lock: FwdState locked key
0E226A96EBBE0B01539C215BA0A0436D e:=IV/0x339177b0*2
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x8a4a0f48=1
2016/04/03 01:08:09.246 kid1| 44,3| peer_select.cc(137) peerSelect:
e:=IWV/0x339177b0*2 http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(299) cbdataInternalAlloc:
Allocating 0x50a4b048
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x8a4a0f48=2
2016/04/03 01:08:09.246 kid1| 20,3| store.cc(483) lock: peerSelect locked
key 0E226A96EBBE0B01539C215BA0A0436D e:=IWV/0x339177b0*3
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x8a4a0f48
2016/04/03 01:08:09.246 kid1| 44,3| peer_select.cc(441) peerSelectFoo: GET
12kms.tayyar.org
2016/04/03 01:08:09.246 kid1| 44,3| peer_select.cc(474) peerSelectFoo:
peerSelectFoo: direct = DIRECT_MAYBE (default)
2016/04/03 01:08:09.246 kid1| 44,3| peer_select.cc(477) peerSelectFoo:
peerSelectFoo: direct = DIRECT_MAYBE
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x830a9b08
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x830a9b08
2016/04/03 01:08:09.246 kid1| 44,3| peer_select.cc(110) peerSelectIcpPing:
peerSelectIcpPing: http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.246 kid1| 15,3| neighbors.cc(289) neighborsCount:
neighborsCount: 0
2016/04/03 01:08:09.246 kid1| 44,3| peer_select.cc(121) peerSelectIcpPing:
peerSelectIcpPing: counted 0 neighbors
2016/04/03 01:08:09.246 kid1| 44,3| peer_select.cc(685) peerGetSomeParent:
GET 12kms.tayyar.org
2016/04/03 01:08:09.246 kid1| 15,3| neighbors.cc(350) getRoundRobinParent:
returning NULL
2016/04/03 01:08:09.246 kid1| 15,3| neighbors.cc(400)
getWeightedRoundRobinParent: getWeightedRoundRobinParent: returning NULL
2016/04/03 01:08:09.246 kid1| 15,3| neighbors.cc(312) getFirstUpParent:
getFirstUpParent: returning NULL
2016/04/03 01:08:09.246 kid1| 15,3| neighbors.cc(490) getDefaultParent:
getDefaultParent: returning NULL
2016/04/03 01:08:09.246 kid1| 15,3| neighbors.cc(490) getDefaultParent:
getDefaultParent: returning NULL
2016/04/03 01:08:09.246 kid1| 44,5| peer_select.cc(940) peerAddFwdServer:
peerAddFwdServer: adding DIRECT HIER_DIRECT
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x8a4a0f48
2016/04/03 01:08:09.246 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
Find IP destination for: http://12kms.tayyar.org/Services.asmx/JsonFile' via
12kms.tayyar.org
2016/04/03 01:08:09.246 kid1| 14,4| ipcache.cc(501) ipcache_nbgethostbyname:
ipcache_nbgethostbyname: Name '12kms.tayyar.org'.
2016/04/03 01:08:09.246 kid1| 14,3| Address.cc(389) lookupHostIP: Given
Non-IP '12kms.tayyar.org': Name or service not known
2016/04/03 01:08:09.246 kid1| 14,4| ipcache.cc(533) ipcache_nbgethostbyname:
ipcache_nbgethostbyname: HIT for '12kms.tayyar.org'
2016/04/03 01:08:09.246 kid1| 45,9| cbdata.cc(394) cbdataInternalLock:
0x50a4b048=1
2016/04/03 01:08:09.247 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x50a4b048
2016/04/03 01:08:09.247 kid1| 45,9| cbdata.cc(426) cbdataInternalUnlock:
0x50a4b048=0
2016/04/03 01:08:09.247 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x8a4a0f48
2016/04/03 01:08:09.247 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x8a4a0f48
2016/04/03 01:08:09.247 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for 'http://12kms.tayyar.org/Services.asmx/JsonFile'
2016/04/03 01:08:09.247 kid1| 44,2| peer_select.cc(281) peerSelectDnsPaths:  
always_direct = DENIED
2016/04/03 01:08:09.247 kid1| 44,2| peer_select.cc(282) peerSelectDnsPaths:   
never_direct = DENIED
2016/04/03 01:08:09.247 kid1| 44,2| peer_select.cc(286) peerSelectDnsPaths:         
DIRECT = local=0.0.0.0 remote=104.20.19.143:80 flags=1
2016/04/03 01:08:09.247 kid1| 44,2| peer_select.cc(286) peerSelectDnsPaths:         
DIRECT = local=0.0.0.0 remote=104.20.20.143:80 flags=1
2016/04/03 01:08:09.247 kid1| 44,2| peer_select.cc(295) peerSelectDnsPaths:       
timedout = 0
2016/04/03 01:08:09.247 kid1| 45,9| cbdata.cc(492) cbdataReferenceValid:
0x8a4a0f48
2016/04/03 01:08:09.247 kid1| 45,9| cbdata.cc(426) cbdataInternalUnlock:
0x8a4a0f48=1
2016/04/03 01:08:09.247 kid1| 17,3| FwdState.cc(387) startConnectionOrFail:
http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.247 kid1| 11,7| HttpRequest.cc(484) clearError: old
error details: 0/0
2016/04/03 01:08:09.247 kid1| 17,3| FwdState.cc(806) connectStart:
fwdConnectStart: http://12kms.tayyar.org/Services.asmx/JsonFile
2016/04/03 01:08:09.247 kid1| 48,6| pconn.cc(329) key:
PconnPool::key(local=0.0.0.0 remote=104.20.19.143:80 flags=1,
12kms.tayyar.org) is {104.20.19.143:80/12kms.tayyar.org}
2016/04/03 01:08:09.247 kid1| 48,3| pconn.cc(445) pop: found
104.20.19.143:80/12kms.tayyar.org to use



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/clientProcessHit-tp4676484p4676891.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sat Apr  2 23:31:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 3 Apr 2016 11:31:35 +1200
Subject: [squid-users] clientProcessHit
In-Reply-To: <1459634979927-4676891.post@n4.nabble.com>
References: <56E06C67.4050708@gmail.com>
 <1457547955501-4676562.post@n4.nabble.com> <56E0723A.5040903@gmail.com>
 <1457548800299-4676565.post@n4.nabble.com> <56E0759D.3020000@gmail.com>
 <1457549844762-4676567.post@n4.nabble.com> <56E07A26.4090101@gmail.com>
 <1457551370293-4676571.post@n4.nabble.com> <56E08037.3000004@gmail.com>
 <1457552680940-4676573.post@n4.nabble.com>
 <1459634979927-4676891.post@n4.nabble.com>
Message-ID: <57005657.6040802@treenet.co.nz>

On 3/04/2016 10:09 a.m., joe wrote:
> again if i only me on server just sending this file multiple of time i keep
> getting in acsess.log 
> 2016/04/03 01:08:09.245 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt, 'http://12kms.tayyar.org/Services.asmx/JsonFile'
> 'accept-encoding="gzip,%20deflate"'
> 2016/04/03 01:08:09.245 kid1| 24,8| SBuf.cc(124) ~SBuf: SBuf2908458
> destructed
> 2016/04/03 01:08:09.245 kid1| clientProcessHit: Vary object loop!
> ifs it bug or what ??  here is the debug output all,9
> --------------------------------------------------
> http://12kms.tayyar.org/Services.asmx/JsonFile
> 
> GET /Services.asmx/JsonFile HTTP/1.1
> Host: 12kms.tayyar.org
> User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:43.0) Gecko/20100101
> Firefox/43.0
> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
> Accept-Language: en-US,en;q=0.5
> Accept-Encoding: gzip, deflate
> DNT: 1
> Cookie: __cfduid=d8312ea7ec9e0cad35fc1c33aeeea42c31456783212;
> __utma=80610962.1196730177.1456783246.1459622933.1459633131.47;
> __utmz=80610962.1456783246.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none);
> _em_vt=1c38b4dd1820be77bbff4015840d56d4bf7bf79fd3-4198383757003d93;
> __gads=ID=9ac649b1dd30ef2e:T=1456783233:S=ALNI_MYsBTt4cTqQuwii3xpn7mBiCsKA1A;
> __utmc=80610962; __utmb=80610962.4.10.1459633131;
> _em_v=8cfac1d515380b25f9feecec18de57003ba9e1f053-3690364257003d93
> Connection: keep-alive
> Pragma: no-cache
> Cache-Control: no-cache

Your request "Cache-Control: no-cache" requires that the cache not be
used. Only a MISS is permitted.


> 
> HTTP/1.1 200 OK
> Date: Sat, 02 Apr 2016 22:12:05 GMT
> Content-Type: application/json; charset=utf-8
> Content-Length: 27262
> Cache-Control: private, max-age=0

The reply "Cache-Control: private, max-age=0" additionally mandates that
this response is private fr the individual user making the request and
not be stored in any cache for more than 0 seconds.


> Content-Encoding: gzip
> Vary: Accept-Encoding
> access-control-allow-origin: *
> X-AspNet-Version: 4.0.30319
> X-Powered-By: ASP.NET
> Strict-Transport-Security: max-age=0; includeSubDomains
> Server: cloudflare-nginx
> X-Cache: MISS from proxy.netgates.com
> Connection: keep-alive
> ----------------------------------------------------------
> 2016/04/03 01:08:09.244 kid1| 73,3| HttpRequest.cc(687) storeId: sent back
> canonicalUrl:http://12kms.tayyar.org/Services.asmx/JsonFile
> 2016/04/03 01:08:09.244 kid1| 20,3| store_dir.cc(1073) get: storeGet:
> looking up DD53DC3A473A865ED9C70084B05E7385
> 2016/04/03 01:08:09.244 kid1| 20,3| store_dir.cc(697) find: got in-transit
> entry: e:d110885 at 0=msw2RDV/0x317b7b50*0
> 2016/04/03 01:08:09.244 kid1| 47,3| ufs/UFSSwapDir.cc(526) reference:
> referencing 0x317b7b50 0/110885
> 
> ----> as you see its in cache and it supost to be hiy insted it return miss 

I think what the remainder of the log is showing is that Squid attemts
to setup the Vary marker stuff in cache for this object. But the object
itself is not permitted to be stored, so nothing gets stored at the
location the Vary marker object points to.

Following requests then cannot find the object and log the warning.


Amos



From bpk678 at gmail.com  Sun Apr  3 16:22:53 2016
From: bpk678 at gmail.com (Brendan Kearney)
Date: Sun, 03 Apr 2016 12:22:53 -0400
Subject: [squid-users] Identifying intercepted clients
Message-ID: <5701435D.7090102@gmail.com>

with fedora 24 being released in a couple months, haproxy v1.6.x will be 
available, and the ability to easily intercept HTTP traffic will be in 
the version (see the set-uri directive).  with v1.6 i will be able to 
rewrite the URL, so that squid can process the request properly.  my 
problem is that i run authenticated access on the proxy, and will need 
to exempt the traffic from that restriction.

what mechanisms can i use to identify the fact that the client traffic 
has been intercepted, so that i can create ACLs to match the traffic?  i 
don't want to use things like IPs or User-Agent strings, as they may 
change or be unknown.

i was thinking about sending the intercepted traffic to a different 
port, say 3129, and then using localport to identify the traffic. with 
an ACL, i would exempt the traffic from auth, etc.  are there better 
options?  how are other folks dealing with intercepted and explicit 
traffic on the same box?

thanks,

brendan


From eliezer at ngtech.co.il  Sun Apr  3 16:36:07 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 3 Apr 2016 19:36:07 +0300
Subject: [squid-users] videos caching over https
In-Reply-To: <CAGycgFgQvXM=dUz3ZnAAV1ACKchA8HTWjQAbVnN4O9ahau8XdA@mail.gmail.com>
References: <CAGycgFgQvXM=dUz3ZnAAV1ACKchA8HTWjQAbVnN4O9ahau8XdA@mail.gmail.com>
Message-ID: <b0ad301d18dc6$ec2da370$c488ea50$@ngtech.co.il>

I am unsure what you want to achieve.

Do you want to cache one specific url or a set of urls?

Also are you targeting one host\url and\or also one client or more?

It will depend on the level of control that you have on the client side.

If you are in a position to Intercept all the traffic it would be pretty simple(in most cases) to achieve what you are describing.

 

Eliezer

 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Raju M K
Sent: Friday, April 1, 2016 4:56 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] videos caching over https

 

Hi users,

iam able to cache videos through http 
by adding refresh_pattern -i .amazonaws.com <http://amazonaws.com> (m4f|mp4)


but i need to cache through https as well. from single url only

please help

-- 

Regards,
M K Raju.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160403/2e1a84a9/attachment.htm>

From squid3 at treenet.co.nz  Sun Apr  3 23:54:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 4 Apr 2016 11:54:46 +1200
Subject: [squid-users] Query about login=pass
In-Reply-To: <CALgKBS=65SmEA1MeA=h7-4s-qQ0qpucc8ceOVxUZ5eiNFNE6Zw@mail.gmail.com>
References: <CALgKBSmu4DnmGbFhMdvUUu5WVVpn=uNwQVkoZ5gLvUT8_4kNtQ@mail.gmail.com>
 <56FEBD78.30004@treenet.co.nz>
 <CALgKBS=65SmEA1MeA=h7-4s-qQ0qpucc8ceOVxUZ5eiNFNE6Zw@mail.gmail.com>
Message-ID: <5701AD46.6020207@treenet.co.nz>

On 4/04/2016 12:46 a.m., Sreenath BH wrote:
> Hi Amos,
> 
> Thanks for the information.
> We are not using any helpers in the first squid, no ICAP/rCAP as well.

Aha. That will be the problem then. With no helper to make Squid aware
that there is anything special about the WWW-Auth headers they will get
dropped on arrival.
Note that Authorization header going out from Squid to the origin is
*Squid* login to the origin, not the clients. WWW-Auth is only passed
through forward-proxy.

> 
> I remember seeing that the copyHeaders function was actually copying
> the Authorization header, but not sending it out. Since our servers
> have been rebooted unfortunately I can not provide the log file
> contents here.
> 
> If I change login=PASS to login=PASSTHRU, will squid always send all
> received headers upstream.

Yes Squid will send the auth credentials from the client as its own. And
send the origins challenge (if any) back to the client.


> 
> Also you mention that if the upstream server "does not request login"
> squid will not send Authentication headers. How does one make the
> upstream ask for Basic authorization?

That is software specific config, so I can't say specifically what you
will need.

Amos



From squid3 at treenet.co.nz  Mon Apr  4 00:06:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 4 Apr 2016 12:06:34 +1200
Subject: [squid-users] Identifying intercepted clients
In-Reply-To: <5701435D.7090102@gmail.com>
References: <5701435D.7090102@gmail.com>
Message-ID: <5701B00A.7050504@treenet.co.nz>

On 4/04/2016 4:22 a.m., Brendan Kearney wrote:
> with fedora 24 being released in a couple months, haproxy v1.6.x will be
> available, and the ability to easily intercept HTTP traffic will be in
> the version (see the set-uri directive).  with v1.6 i will be able to
> rewrite the URL, so that squid can process the request properly.

That does not make sense. Intercepting and URL-rewriting are completely
different actions.

The Squid-3.5 and later versions are able to receive PROXY protocol
headers from HAProxy. You may find that much better than fiddling around
with URLs and available in your current HAProxy.


>  my
> problem is that i run authenticated access on the proxy, and will need
> to exempt the traffic from that restriction.
> 

What restriction?


> what mechanisms can i use to identify the fact that the client traffic
> has been intercepted, so that i can create ACLs to match the traffic?  i
> don't want to use things like IPs or User-Agent strings, as they may
> change or be unknown.

Only the interceptor can do that traffic distinction. Once traffic gets
multiplexed the information is lost.

> 
> i was thinking about sending the intercepted traffic to a different
> port, say 3129, and then using localport to identify the traffic. with
> an ACL, i would exempt the traffic from auth, etc.  are there better
> options?  how are other folks dealing with intercepted and explicit
> traffic on the same box?

That would be one fairly good way to distinguish the traffic types. So
why is the URL fiddling happening?

Amos



From jok at spikes.com  Mon Apr  4 04:18:03 2016
From: jok at spikes.com (Jok Thuau)
Date: Sun, 3 Apr 2016 21:18:03 -0700
Subject: [squid-users] filtering http(s) sites, transparently
Message-ID: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>

I'm attempting to build a transparent proxy (policy based routing on
firewall to squid proxy) with the following behavior:

1) proxies http traffic for a given set of domains, provide an message
otherwise such "domain not allowed" or similar
2) proxies https traffic for a given set of domains (ideally, splicing
those, so as not to break HSTS, if enabled), otherwise provide an error
message (bumping and providing "domain not allowed")

I'm attempting this with a 3.5.15 compiled with icap (not yet used) and
ssl-bumping.

Part 1 seems easy enough (and is well documented)...

acl whitelist dstdomain .domain1.tld
acl whitelist dstdomain .domain2.tld

acl http_ok all-of whitelist !SSL_ports

http_access allow http_ok
http_access deny all

Moving onto Part 2 (the peek and splice setup) appears to be the topic of a
few discussions out there...

acl sni_whitelist ssl::server_name .domain1.tld
acl sni_whitelist ssl::server_name .domain2.tld

ssl_bump peek step1
ssl_bump splice sni_whitelist
ssl_bump bump all

It appears however that when combining the two, the generated
certificate(s), instead of mimic'ing the original server's certificate
comes out with the CN=<IP> where <IP> is the ip used by the "connect" part
of the connection. In addition, it appears that only the first entry ever
matches (at this point, i've tried so many combinations, i'm no longer
certain of anything).

If i remove *all* the http_access lines, then the behavior appears correct
(from a "splicing/bumping" standpoint).

Can anyone confirm that this is indeed possible to achieve?

I believe, based on experimentation that any http_access i have, because of
the "deny all" cause the bumping to "short circuit" and effectively send an
early "access denied" based on the only information it has (the ip address
from the "connect", rather than the SNI that would come later).

Would a setup where "deny http+!whitelist" so have the allow be the default
allow for the bumping to work and get to step2 and match the sni* acls
somehow? (with a "deny step2 !sni_whitelist").

Is 3.5.15 capable of doing this? If this requires some feature/effort, what
would be the procedure to sponsor that work?

Thanks,
Jok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160403/4732411b/attachment.htm>

From squid3 at treenet.co.nz  Mon Apr  4 04:59:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 4 Apr 2016 16:59:28 +1200
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
Message-ID: <5701F4B0.8060001@treenet.co.nz>

On 4/04/2016 4:18 p.m., Jok Thuau wrote:
> I'm attempting to build a transparent proxy (policy based routing on
> firewall to squid proxy) with the following behavior:
> 
> 1) proxies http traffic for a given set of domains, provide an message
> otherwise such "domain not allowed" or similar
> 2) proxies https traffic for a given set of domains (ideally, splicing
> those, so as not to break HSTS, if enabled), otherwise provide an error
> message (bumping and providing "domain not allowed")
> 
> I'm attempting this with a 3.5.15 compiled with icap (not yet used) and
> ssl-bumping.
> 
> Part 1 seems easy enough (and is well documented)...
> 
> acl whitelist dstdomain .domain1.tld
> acl whitelist dstdomain .domain2.tld
> 
> acl http_ok all-of whitelist !SSL_ports
> 
> http_access allow http_ok
> http_access deny all

This is denying the HTTPS traffic CONNECT requests (synthesized by
Squid), since they only have IP address no domain name.


> 
> Moving onto Part 2 (the peek and splice setup) appears to be the topic of a
> few discussions out there...
> 
> acl sni_whitelist ssl::server_name .domain1.tld
> acl sni_whitelist ssl::server_name .domain2.tld
> 
> ssl_bump peek step1

You have omitted the definition of step1 ACL.

> ssl_bump splice sni_whitelist
> ssl_bump bump all
> 
> It appears however that when combining the two, the generated
> certificate(s), instead of mimic'ing the original server's certificate
> comes out with the CN=<IP> where <IP> is the ip used by the "connect" part
> of the connection. In addition, it appears that only the first entry ever
> matches (at this point, i've tried so many combinations, i'm no longer
> certain of anything).

You have omitted the http(s)_port configuration details, and the step1
ACL. So its not possible to say if you have the cert generation settings
wrong, or if the peeking step is matching wrong, or something else.

> 
> If i remove *all* the http_access lines, then the behavior appears correct
> (from a "splicing/bumping" standpoint).
> 

Strange. Squid without any http_access lines should be denying traffic 100%.

> Can anyone confirm that this is indeed possible to achieve?
> 
> I believe, based on experimentation that any http_access i have, because of
> the "deny all" cause the bumping to "short circuit" and effectively send an
> early "access denied" based on the only information it has (the ip address
> from the "connect", rather than the SNI that would come later).
> 
> Would a setup where "deny http+!whitelist" so have the allow be the default
> allow for the bumping to work and get to step2 and match the sni* acls
> somehow? (with a "deny step2 !sni_whitelist").
> 
> Is 3.5.15 capable of doing this? If this requires some feature/effort, what
> would be the procedure to sponsor that work?

It is not possible to answer any of those questsions properly without
full config details. You have omitted a lot.

Amos



From squid at peralex.com  Mon Apr  4 07:56:59 2016
From: squid at peralex.com (squid at peralex.com)
Date: Mon, 4 Apr 2016 09:56:59 +0200
Subject: [squid-users] Slowly rising CPU load (eventually hits 100)
In-Reply-To: <ndjbq1$b0g$1@ger.gmane.org>
References: <ndja5h$f9j$1@ger.gmane.org> <56FD2F2F.9060301@gmail.com>
 <ndjbq1$b0g$1@ger.gmane.org>
Message-ID: <ndt6oa$k48$1@ger.gmane.org>

On 2016-03-31 16:21, squid at peralex.com wrote:
> On 2016-03-31 16:07, Yuri Voinov wrote:
>>
>> Looks like permanently running clients, which is exausted network
>> resources and then initiating connection abort.
>>
>> Try to add
>>
>> client_persistent_connections off

This option didn't fix the problem.  The CPU usage went wild again after
about a day.

I've changed the maximum_object_size_in_memory setting as suggested by
Alex, and I'll report back on that.

Mark




From rafael.akchurin at diladele.com  Mon Apr  4 08:26:07 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 4 Apr 2016 08:26:07 +0000
Subject: [squid-users] Squid 3.5.16 for Microsoft Windows 64-bit is available
Message-ID: <VI1PR04MB13591B733E66B8FDA86079B38F9D0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Greetings everyone,



The CygWin based build of Squid proxy for Microsoft Windows version 3.5.16 is now available (amd64 only!).



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.16-RELEASENOTES.html.

* Ready to use MSI package can be downloaded from http://squid.diladele.com.

* List of open issues for the installer - https://github.com/diladele/squid3-windows/issues



Thanks a lot for Squid developers for making this great software!



Please join our humble efforts to provide ready to run MSI installer for Squid on Microsoft Windows with all required dependencies at GitHub -

https://github.com/diladele/squid3-windows. Please report all issues/bugs/feature requests at GitHub project.

Issues about the *MSI installer only* can also be reported to support at diladele.com<mailto:support at diladele.com>.



NOTE: the 3.5.16 version of Squid for Ubuntu 14.04 LTS will be also available during today. The repo is at http://ubuntu.diladele.com. This version is recompiled using Squid DEB source from Debian Testing with some changes required to support SSL bump / libecap3 on Ubuntu 14.04 LTS. See more at http://docs.diladele.com/tutorials/build_squid_ubuntu14/index.html.



Best regards,

Rafael Akchurin

Diladele B.V.

http://www.quintolabs.com

http://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/958a2ca0/attachment.htm>

From fredbmail at free.fr  Mon Apr  4 08:28:07 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 4 Apr 2016 10:28:07 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1343104378.73068095.1459757930718.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello

I migrated my Squid to the latest version 3.5.16 (from 3.5.10) and now I have many many "Vary loop objects"
What happen ? I made no configuration changes 

After 1 hours

Squid 3.5.16
grep "Vary" /var/log/squid/cache.log | wc -l
18176

Squid 3.5.10
grep "Vary" /var/log/squid/cache.log | wc -l
4

My cache value is also very slow, -15%

As you can see there many lines each seconds 

2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://abonnes.lemonde.fr/ajah/5m/lemonde/abonnes/Controller_Module_Pave_Edito_Chat/actionAfficherPave/WzM/yMT/Bd/EMPTY/?key=7d65cf7d4c3a74e05cb76a09e96f5afb430d22e3' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://abonnes.lemonde.fr/ajah/5m/lemonde/abonnes/Controller_Module_Abonnes_AppelJelec/actionAfficher/W3R/ydW/UsI/kJMT0NBQk9TRVFDT0xEUjE0IiwiIiwzMjEwXQ--/?key=3e9cf6640e7918a9414ffdf81f2d59ea943790df' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://abonnes.lemonde.fr/ajah/5m/lemonde/abonnes/Controller_Module_General_Colonne_Defaut/actionAfficher/W10/-/EMPTY/EMPTY/?key=dc4d5d30403d8d1a697e69255a95c47f05e387bd' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://abonnes.lemonde.fr/ws/1/jelec/kiosque/' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://abonnes.lemonde.fr/ajah/5m/lemonde/abonnes/Controller_Module_Pave_Edito_Item/actionAfficherPave/W25/1bG/wse/yJydWJyaXF1ZV9pZCI6MzIxMH0sNDg1NDMwNixudWxsXQ--/?key=2c4363f33e0fda86711e649d14ae9ec6f513ccbe' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:08 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://www.sudouest.fr/img/meteo/102.png' 'host="www.sudouest.fr", accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:08 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:08 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://www.sudouest.fr/img/meteo/10.png' 'host="www.sudouest.fr", accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:08 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://s2.cdscdn.com/cds/showCaseCss.css?LanguageCode=fr&SiteId=100&md5=89f22cc02227662988361ba3aed55805' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://s2.cdscdn.com/Css/cdsrwd/wl/rwd/master/fullrwd.css?LanguageCode=fr&SiteId=100' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://s3.cdscdn.com/Js/cdsrwd/wl/rwd/block/recs.js' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://s3.cdscdn.com/cds/showCaseJs.js?md5=e2ef12f58f4161c79776f239ad0c34f0' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://s2.cdscdn.com/Css/cdsrwd/wl/rwd/block/button.css?LanguageCode=fr&SiteId=100' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://s3.cdscdn.com/Js/external/tagcommander/tc_nav.js' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://www.cdiscount.com/favicon.ico' 'user-agent="Mozilla%2F5.0%20(Windows%20NT%206.1%3B%20rv%3A38.0)%20Gecko%2F20100101%20Firefox%2F38.0"'
2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://regie2.moto-net.com/adimage.php?filename=ban-starplaq-2014.gif&contenttype=gif' 'accept-encoding="identity,gzip,deflate", user-agent="Mozilla%2F5.0%20(compatible%3B%20MSIE%209.0%3B%20Windows%20NT%206.1%3B%20Trident%2F5.0)"'
2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!


From yvoinov at gmail.com  Mon Apr  4 08:39:10 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 4 Apr 2016 14:39:10 +0600
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <5702282E.6060408@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Version 4.0.8 has the same issue after upgrading without cache clean-up.

04.04.16 14:28, FredB ?????:
> Hello
>
> I migrated my Squid to the latest version 3.5.16 (from 3.5.10) and now
I have many many "Vary loop objects"
> What happen ? I made no configuration changes
>
> After 1 hours
>
> Squid 3.5.16
> grep "Vary" /var/log/squid/cache.log | wc -l
> 18176
>
> Squid 3.5.10
> grep "Vary" /var/log/squid/cache.log | wc -l
> 4
>
> My cache value is also very slow, -15%
>
> As you can see there many lines each seconds
>
> 2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://abonnes.lemonde.fr/ajah/5m/lemonde/abonnes/Controller_Module_Pave_Edito_Chat/actionAfficherPave/WzM/yMT/Bd/EMPTY/?key=7d65cf7d4c3a74e05cb76a09e96f5afb430d22e3'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://abonnes.lemonde.fr/ajah/5m/lemonde/abonnes/Controller_Module_Abonnes_AppelJelec/actionAfficher/W3R/ydW/UsI/kJMT0NBQk9TRVFDT0xEUjE0IiwiIiwzMjEwXQ--/?key=3e9cf6640e7918a9414ffdf81f2d59ea943790df'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://abonnes.lemonde.fr/ajah/5m/lemonde/abonnes/Controller_Module_General_Colonne_Defaut/actionAfficher/W10/-/EMPTY/EMPTY/?key=dc4d5d30403d8d1a697e69255a95c47f05e387bd'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://abonnes.lemonde.fr/ws/1/jelec/kiosque/'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:07 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://abonnes.lemonde.fr/ajah/5m/lemonde/abonnes/Controller_Module_Pave_Edito_Item/actionAfficherPave/W25/1bG/wse/yJydWJyaXF1ZV9pZCI6MzIxMH0sNDg1NDMwNixudWxsXQ--/?key=2c4363f33e0fda86711e649d14ae9ec6f513ccbe'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:07 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:08 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.sudouest.fr/img/meteo/102.png'
'host="www.sudouest.fr", accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:08 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:08 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.sudouest.fr/img/meteo/10.png'
'host="www.sudouest.fr", accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:08 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://s2.cdscdn.com/cds/showCaseCss.css?LanguageCode=fr&SiteId=100&md5=89f22cc02227662988361ba3aed55805'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://s2.cdscdn.com/Css/cdsrwd/wl/rwd/master/fullrwd.css?LanguageCode=fr&SiteId=100'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://s3.cdscdn.com/Js/cdsrwd/wl/rwd/block/recs.js'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://s3.cdscdn.com/cds/showCaseJs.js?md5=e2ef12f58f4161c79776f239ad0c34f0'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://s2.cdscdn.com/Css/cdsrwd/wl/rwd/block/button.css?LanguageCode=fr&SiteId=100'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://s3.cdscdn.com/Js/external/tagcommander/tc_nav.js'
'accept-encoding="identity,gzip,deflate"'
> 2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.cdiscount.com/favicon.ico'
'user-agent="Mozilla%2F5.0%20(Windows%20NT%206.1%3B%20rv%3A38.0)%20Gecko%2F20100101%20Firefox%2F38.0"'
> 2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
> 2016/04/04 10:17:09 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://regie2.moto-net.com/adimage.php?filename=ban-starplaq-2014.gif&contenttype=gif'
'accept-encoding="identity,gzip,deflate",
user-agent="Mozilla%2F5.0%20(compatible%3B%20MSIE%209.0%3B%20Windows%20NT%206.1%3B%20Trident%2F5.0)"'
> 2016/04/04 10:17:09 kid1| clientProcessHit: Vary object loop!
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXAiguAAoJENNXIZxhPexGs4QH/2GBkMNx//UZuBSwKDS41/Zd
6Nz90E+Qs5yIYLURQtcrZmNw7YvdK7sw3nkYaL+Xm29OxkmxDFqI62vnVKXWuuN8
NLfr2wP0KdIfFY3vIyICwCu09UwOB4TnrnFBMYICEX5LXOqQJ7BKjI0YA0u5jfWB
Fv6cjrjPwMhSyjJ5h1jJVzEun++NGpM/xJQZ07DXEUCl2XWh+r/YqZofQiPPcO7n
sEnTFrOqKHujs2GARtrEbEp+7A+rBai5KK4lR8eqO3gmOh7E4HomT/zshJDSD2zU
sUJPx16PJ+nMJ6ZI7lbWGp6A0CNw7WJ/ZwZuAgZ3UOyS2bI3PaEFq381LZYFZlc=
=YQGU
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/349dfe88/attachment.key>

From raphghost22 at hotmail.com  Mon Apr  4 09:25:41 2016
From: raphghost22 at hotmail.com (Raph Ghost)
Date: Mon, 4 Apr 2016 09:25:41 +0000
Subject: [squid-users] Problem to configure squid for HTTPS website (HSTS or
 others certificate problems)
Message-ID: <DB5PR06MB098440CE459284307D4DCFB8A39D0@DB5PR06MB0984.eurprd06.prod.outlook.com>

Hi users :)


What I want to do: I have a dedicated server and I want to make it as a transparent adblocker through a VPN. So I have installed and configured OpenVPN and route my traffic from the VPN tun into the squid proxy.


What is the problem: Websites based on http work great but those based on httpS doesn't work at all.


I have already tried two squid configurations and look for that problem in the user mail list history but I can't find any workaround that works.


My compilation options (squid 3.5.15 -with-openssl is enabled):

'--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=${prefix}/lib/squid3' '--srcdir=.' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' 'BUILDCXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -fPIE -pie -Wl,-z,relro -Wl,-z,now' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--libexecdir=/usr/lib/squid' '--mandir=/usr/share/man' '--enable-inline' '--disable-arch-native' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB' '--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper' '--enable-auth-ntlm=fake,smb_lm' '--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group' '--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi' '--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-translation' '--with-openssl=/etc/ssl' '--enable-ssl-crtd' '--with-swapdir=/var/spool/squid' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-build-info= linux' '--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-Wdate-time -D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security'


My iptable conf (port 22: my ssh server/ input port 443: my OpenVPN server):

-P INPUT DROP
-P FORWARD DROP
-P OUTPUT DROP
-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -i lo -j ACCEPT
-A INPUT -p tcp -m tcp --dport 22 -j ACCEPT
-A INPUT -p tcp -m tcp --dport 53 -j ACCEPT
-A INPUT -p udp -m udp --dport 53 -j ACCEPT
-A INPUT -i eth0 -p tcp -m state --state NEW -m tcp --dport 443 -j ACCEPT
-A INPUT -i tun0 -j ACCEPT
-A FORWARD -i tun0 -j ACCEPT
-A FORWARD -o tun0 -j ACCEPT
-A FORWARD -i tun0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -i eth0 -o tun0 -m state --state RELATED,ESTABLISHED -j ACCEPT
-A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
-A OUTPUT -o lo -j ACCEPT
-A OUTPUT -p tcp -m tcp --dport 22 -j ACCEPT
-A OUTPUT -p tcp -m tcp --dport 53 -j ACCEPT
-A OUTPUT -p udp -m udp --dport 53 -j ACCEPT
-A OUTPUT -p tcp -m tcp --dport 80 -j ACCEPT
-A OUTPUT -p udp -m udp --dport 123 -j ACCEPT
-A OUTPUT -o tun0 -j ACCEPT
-A OUTPUT -p icmp -j ACCEPT

My iptable conf (nat table):
-P PREROUTING ACCEPT
-P INPUT ACCEPT
-P OUTPUT ACCEPT
-P POSTROUTING ACCEPT
-A PREROUTING -s 10.8.0.0/24 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3129
-A PREROUTING -s 10.8.0.0/24 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3130
-A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE

This iptables configuration works great to route vpn input trafic into squid.


1st squid conf I've tried (based on this tutorial http://monblog.system-linux.net/blog/2013/03/23/mettre-en-oeuvre-squid-transparent-https-sous-debian/ and others):

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.8.0.0/24 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all


# Squid normally listens to port 3128
http_port 10.8.0.1:3128
http_port 10.8.0.1:3129 transparent
https_port 10.8.0.1:3130 intercept ssl-bump key=/etc/squid/ssl_cert2/key.key cert=/etc/squid/ssl_cert2/cert.pem

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

2nd conf I have tried (based on many tutorials and the official squid wiki especially to configure Ssl Bump/Peek and Slice function):
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.8.0.0/24 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all


always_direct allow all
sslproxy_cert_error allow all
sslproxy_cafile /etc/ssl/certs/ca-certificates.crt
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
# Squid normally listens to port 3128
http_port 10.8.0.1:3128
http_port 10.8.0.1:3129 transparent
https_port 10.8.0.1:3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=6MB cert=/etc/squid/ssl_cert/myCA.pem

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

ssl_bump peek step1 all
ssl_bump stare step2
ssl_bump bump step3


# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320


Unfortunately none of these conf work.

With the first conf:
If i try to connect to https://openclassrooms.com/ for example I get a warning about that the certificate is not trust. I can overpass this warning (by clicking on "continue on this website (dangerous)") but after few seconds I get an error generated by squid:
"L'erreur suivante s'est produite en essayant d'acc?der ? l'URL : https://openclassrooms.com/
La connexion 190.93.240.239 a ?chou?e.
Le syst?me a retourn? : (110) Connection timed out   < ----- Important line
L'h?te distant ou le r?seau sont peut-?tre d?faillant. Veuillez renouveler votre requ?te.
Votre administrateur proxy est webmaster."

In access.log I get:
1459756883.952     42 10.8.0.6 TCP_MISS/200 565 GET http://www.google-analytics.com/__utm.gif? - ORIGINAL_DST/216.58.214.78 image/gif
1459756885.636     14 10.8.0.6 TCP_MISS/204 262 GET http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.214.67 -
1459756890.842     17 10.8.0.6 TCP_MISS/302 505 GET http://openclassrooms.com/ - ORIGINAL_DST/190.93.240.239 -
1459756891.129     14 10.8.0.6 TCP_MISS/204 262 GET http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.214.67 -
1459756961.902  60814 10.8.0.6 TCP_MISS/503 4850 GET https://openclassrooms.com/ - ORIGINAL_DST/190.93.240.239 text/html

In cache.log there is nothing especial.

When I try to connect to https://www.google.fr I get a warning (from my browser, here Chrome) but I can't overpass it (due to HSTS technologie).



With the second conf (which is supposed to dynamically generate certificate from the original certificate to overpass HSTS - at least this I did think but it doesn't work):
Both of google or openclassroom websites generate the same result:
On browser I get a ERR_TIMED_OUT.

In access.log:
1459755020.622  59785 10.8.0.6 TAG_NONE/200 0 CONNECT 46.228.47.114:443 - ORIGINAL_DST/46.228.47.114 -
1459755043.645  60448 10.8.0.6 TAG_NONE/200 0 CONNECT 46.228.47.115:443 - ORIGINAL_DST/46.228.47.115 -
1459755045.000  60058 10.8.0.6 TAG_NONE/200 0 CONNECT 216.58.211.106:443 - ORIGINAL_DST/216.58.211.106 -

In store.log I get SOMETIMES (rarely) this:
2016/04/01 11:43:05| Pinger exiting.
2016/04/01 11:46:02 kid1| Error negotiating SSL connection on FD 27: Closed by client
2016/04/01 11:46:09 kid1| Error negotiating SSL connection on FD 36: Closed by client
2016/04/01 11:46:16 kid1| Error negotiating SSL connection on FD 30: Closed by client
2016/04/01 11:46:23 kid1| Error negotiating SSL connection on FD 38: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:46:31 kid1| Error negotiating SSL connection on FD 18: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:46:38 kid1| Error negotiating SSL connection on FD 43: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:46:46 kid1| Error negotiating SSL connection on FD 10: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:46:54 kid1| Error negotiating SSL connection on FD 33: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:47:32 kid1| Error negotiating SSL connection on FD 14: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:47:40 kid1| Error negotiating SSL connection on FD 28: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:47:48 kid1| Error negotiating SSL connection on FD 10: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:47:55 kid1| Error negotiating SSL connection on FD 16: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:48:03 kid1| Error negotiating SSL connection on FD 27: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:48:54 kid1| Error negotiating SSL connection on FD 10: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:49:01 kid1| Error negotiating SSL connection on FD 14: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:49:08 kid1| Error negotiating SSL connection on FD 18: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:49:15 kid1| Error negotiating SSL connection on FD 28: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:49:24 kid1| Error negotiating SSL connection on FD 36: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 11:49:31 kid1| Error negotiating SSL connection on FD 38: Closed by client
2016/04/01 11:49:38 kid1| Error negotiating SSL connection on FD 40: Closed by client
2016/04/01 11:49:45 kid1| Error negotiating SSL connection on FD 53: Closed by client
2016/04/01 11:49:53 kid1| Error negotiating SSL connection on FD 59: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)
2016/04/01 12:22:55 kid1| Logfile: opening log stdio:/var/log/squid/netdb.state
2016/04/01 12:22:55 kid1| Logfile: closing log stdio:/var/log/squid/netdb.state
2016/04/01 12:22:55 kid1| NETDB state saved; 4 entries, 0 msec
2016/04/01 13:04:35 kid1| Logfile: opening log stdio:/var/log/squid/netdb.state
2016/04/01 13:04:35 kid1| Logfile: closing log stdio:/var/log/squid/netdb.state
2016/04/01 13:04:35 kid1| NETDB state saved; 4 entries, 0 msec
2016/04/01 13:54:40 kid1| Logfile: opening log stdio:/var/log/squid/netdb.state
2016/04/01 13:54:40 kid1| Logfile: closing log stdio:/var/log/squid/netdb.state


Whatever configuration that I used I have import certificate into my browser correctly.

Can you help me ??

Thanks in advance and sorry if my English is not perfect. I can send you any other informations that you would need.

Best regards,
Raph








-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/2c256780/attachment.htm>

From chip_pop at hotmail.com  Mon Apr  4 10:30:03 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 4 Apr 2016 03:30:03 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1459765803566-4676904.post@n4.nabble.com>

intercept  ??
mostly those you see on accelerator that what i,m trying to explain in my
other post 
i know the cause it's in varyEvaluateMatch in source code some how the vary
its not empty and it might not match mem_obj->vary_headers   so you end up
in cache.log  varyEvaluateMatch: Oops. Not a Vary match on second attempt  
and even if its public header dose same usually if its privet on
Cache-Control dose that
but it dose it on public as well  i did some testing modifying the function
i got excellent result but not the correct way its and old issue
may be i was not posting the issue in correct way for the dev... to
understand



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676904.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Mon Apr  4 10:34:39 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 4 Apr 2016 03:34:39 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1459766079665-4676905.post@n4.nabble.com>

forgot to say  if its possible to get one of those link re send thim meny
time you should get alwes varyEvaluateMatch: Oops  not just once ok
and try to get  Cache-Control header  should be   public   if its privet 
then that normal as amos says




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676905.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Mon Apr  4 11:40:10 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 4 Apr 2016 13:40:10 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459765803566-4676904.post@n4.nabble.com>
Message-ID: <1873463697.73579830.1459770010313.JavaMail.root@zimbra4-e1.priv.proxad.net>


> Objet: Re: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
> 
> intercept  ??

No, implicit proxy 

> i got excellent result but not the correct way its and old issue
> may be i was not posting the issue in correct way for the dev... to
> understand

Very recent for me, not problem with 6 proxies and squid 3.5.13 but present with 2 new 3.5.16



From fredbmail at free.fr  Mon Apr  4 11:47:04 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 4 Apr 2016 13:47:04 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <5702282E.6060408@gmail.com>
Message-ID: <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>


>  
> Version 4.0.8 has the same issue after upgrading without cache
> clean-up.
> 

Thanks I will test, I confirm the problem still present after a while 
Eg: this object seems never cleaned/fixed from cache 

Snip, there are many requests before ...

2016/04/04 13:39:11 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:14 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:16 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:17 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:21 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:22 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:22 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:22 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:22 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:23 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:23 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:23 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:23 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:23 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:23 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:24 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:26 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:27 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:28 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:29 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:30 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:32 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:32 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:35 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:35 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:35 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:35 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:35 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:35 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:36 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:37 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:39 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:40 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:43 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:43 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:43 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:43 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:44 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'
2016/04/04 13:39:44 kid1| varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'http://live.lemde.fr/mux.json' 'accept-encoding="identity,gzip,deflate"'


From chip_pop at hotmail.com  Mon Apr  4 11:30:06 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 4 Apr 2016 04:30:06 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1873463697.73579830.1459770010313.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1459765803566-4676904.post@n4.nabble.com>
 <1873463697.73579830.1459770010313.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1459769406356-4676908.post@n4.nabble.com>

FredB wrote
>> Objet: Re: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
>> 
>> intercept  ??
> 
> No, implicit proxy 
> 
>> i got excellent result but not the correct way its and old issue
>> may be i was not posting the issue in correct way for the dev... to
>> understand
> 
> Very recent for me, not problem with 6 proxies and squid 3.5.13 but
> present with 2 new 3.5.16
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

mmm code ar the same must be something else corrupt the vary before
varyEvaluateMatch()

i can provide testing patch    just for testing  .. not for production until
they find the right cause
but   make shurr the header ar  public for those link might be your
situation ar diff...

diff -Naur src/client_side.cc src/client_side.cc
--- src/client_side.cc	2016-04-02 03:38:47.000000000 +0300
+++ src/client_side.cc	2016-04-03 16:47:02.000000000 +0300
@@ -4725,13 +4725,26 @@
             if (!vary.isEmpty())
                 request->vary_headers = vary;
         }
+        if (vary.isEmpty()) {
+            vary = entry->mem_obj->vary_headers;
+
+            if (!vary.isEmpty())
+                request->vary_headers = vary;
+        }
 
         if (vary.isEmpty()) {
             /* Ouch.. we cannot handle this kind of variance */
             /* XXX This cannot really happen, but just to be complete */
             return VARY_CANCEL;
+
         } else if (vary.cmp(entry->mem_obj->vary_headers) == 0) {
             return VARY_MATCH;
+
+        } else if (vary.cmp(httpMakeVaryMark(request, entry->getReply()))
== 0) {
+            return VARY_MATCH;
+
+        } else if (!vary.isEmpty() &&
!entry->mem_obj->vary_headers.isEmpty()) {
+            return VARY_MATCH;
         } else {
             /* Oops.. we have already been here and still haven't
              * found the requested variant. Bail out




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676908.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Mon Apr  4 12:16:14 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 4 Apr 2016 14:16:14 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459769406356-4676908.post@n4.nabble.com>
Message-ID: <1464262280.73674043.1459772174772.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> mmm code ar the same must be something else corrupt the vary before
> varyEvaluateMatch()
> 

This ? http://www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14016.patch


From jlay at slave-tothe-box.net  Mon Apr  4 12:18:59 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 04 Apr 2016 06:18:59 -0600
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
Message-ID: <1459772339.2673.1.camel@gamebox>

On Sun, 2016-04-03 at 21:18 -0700, Jok Thuau wrote:
> I'm attempting to build a transparent proxy (policy based routing on
> firewall to squid proxy) with the following behavior:
> 
> 
> 
> 1) proxies http traffic for a given set of domains, provide an message
> otherwise such "domain not allowed" or similar
> 2) proxies https traffic for a given set of domains (ideally, splicing
> those, so as not to break HSTS, if enabled), otherwise provide an
> error message (bumping and providing "domain not allowed")
> 
> 
> 
> I'm attempting this with a 3.5.15 compiled with icap (not yet used)
> and ssl-bumping.
> 
> 
> Part 1 seems easy enough (and is well documented)...
> 
> 
> acl whitelist dstdomain .domain1.tld
> 
> acl whitelist dstdomain .domain2.tld
> 
> 
> acl http_ok all-of whitelist !SSL_ports
> 
> 
> http_access allow http_ok
> http_access deny all
> 
> 
> Moving onto Part 2 (the peek and splice setup) appears to be the topic
> of a few discussions out there...
> 
> 
> acl sni_whitelist ssl::server_name .domain1.tld
> acl sni_whitelist ssl::server_name .domain2.tld
> 
> 
> ssl_bump peek step1
> ssl_bump splice sni_whitelist
> ssl_bump bump all
> 
> 
> It appears however that when combining the two, the generated
> certificate(s), instead of mimic'ing the original server's certificate
> comes out with the CN=<IP> where <IP> is the ip used by the "connect"
> part of the connection. In addition, it appears that only the first
> entry ever matches (at this point, i've tried so many combinations,
> i'm no longer certain of anything). 
> 
> 
> If i remove *all* the http_access lines, then the behavior appears
> correct (from a "splicing/bumping" standpoint).
> 
> 
> Can anyone confirm that this is indeed possible to achieve?
> 
> 
> I believe, based on experimentation that any http_access i have,
> because of the "deny all" cause the bumping to "short circuit" and
> effectively send an early "access denied" based on the only
> information it has (the ip address from the "connect", rather than the
> SNI that would come later). 
> 
> 
> Would a setup where "deny http+!whitelist" so have the allow be the
> default allow for the bumping to work and get to step2 and match the
> sni* acls somehow? (with a "deny step2 !sni_whitelist").
> 
> 
> Is 3.5.15 capable of doing this? If this requires some feature/effort,
> what would be the procedure to sponsor that work?
> 
> 
> Thanks,
> Jok
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


This may assist:

http://article.gmane.org/gmane.comp.web.squid.general/114389

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/af8c1c30/attachment.htm>

From chip_pop at hotmail.com  Mon Apr  4 11:57:43 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 4 Apr 2016 04:57:43 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1464262280.73674043.1459772174772.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1459765803566-4676904.post@n4.nabble.com>
 <1873463697.73579830.1459770010313.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1459769406356-4676908.post@n4.nabble.com>
 <1464262280.73674043.1459772174772.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1459771063147-4676911.post@n4.nabble.com>

the convertion they did might has bug im using the latest trunk
try my patch if it work so i may can fix it or they  .
im using my patch on production for testing so fare its ok   but as i sayd 
it need to be done in correct way




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676911.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Mon Apr  4 14:44:50 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 4 Apr 2016 16:44:50 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> Thanks I will test, I confirm the problem still present after a while
> Eg: this object seems never cleaned/fixed from cache
> 

No more success with fresh cache, after 5 minutes the messages appears again and again 
Joe is right there is a bug somewhere 


From fredbmail at free.fr  Mon Apr  4 14:47:38 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 4 Apr 2016 16:47:38 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459769406356-4676908.post@n4.nabble.com>
Message-ID: <514212592.74135674.1459781258643.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> i can provide testing patch    just for testing  .. not for
> production until
> they find the right cause
> but   make shurr the header ar  public for those link might be your
> situation ar diff...

I will, but later on a platform test 
Now I will fallback to a previous release 




From giray_simsek at hotmail.com  Mon Apr  4 14:52:59 2016
From: giray_simsek at hotmail.com (Giray Simsek)
Date: Mon, 4 Apr 2016 07:52:59 -0700
Subject: [squid-users] Can Squid send the response time information to icap?
Message-ID: <BLU184-W6706AE1D09008F0A08F3FCFE9D0@phx.gbl>

Hi,

Can Squid send the response time information to icap by passing a header and a value pair to icap?

I am trying to get the duration for the http responses within the icap module. That is, the time it takes to get the response from the external web server after the initial http get request is sent. 

I am hoping there is a way to pass this information from squid to c-icap.

I see that it is possible to log this information in squid using the format code:

 tr	Response time (milliseconds)

Thanks in advance,
Giray 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/fc5f2f87/attachment.htm>

From mcsnv96 at afo.net  Mon Apr  4 15:06:15 2016
From: mcsnv96 at afo.net (Mike)
Date: Mon, 04 Apr 2016 10:06:15 -0500
Subject: [squid-users] squid 3.5 vs 4.0
Message-ID: <570282E7.7030709@afo.net>

Is there any list or page with any comparison information, say for the 2 
latest versions 3.5.16 and 4.0.8 beta? I understand many of the fixes 
coming out are being done for both, but so far I do not see any 
information that describes any benefit to using 4.0 over 3.5. any help 
would be appreciated.

Mike


From yvoinov at gmail.com  Mon Apr  4 15:08:58 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 4 Apr 2016 21:08:58 +0600
Subject: [squid-users] squid 3.5 vs 4.0
In-Reply-To: <570282E7.7030709@afo.net>
References: <570282E7.7030709@afo.net>
Message-ID: <5702838A.4010203@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://wiki.squid-cache.org/RoadMap

04.04.16 21:06, Mike ?????:
> Is there any list or page with any comparison information, say for the 2 latest versions 3.5.16 and
4.0.8 beta? I understand many of the fixes coming out are being done for
both, but so far I do not see any information that describes any benefit
to using 4.0 over 3.5. any help would be appreciated.
>
> Mike
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXAoOJAAoJENNXIZxhPexGNnIH/it1hZt9ohuAtwNwPfNoeufL
pVOFPHlkUtIoPYUDvKU27nmfmrxB8GnrEx4ECSbxIWUysl7gvKSYj2RNNhFv66Pd
IOLLhE3cIkHMsUw73od0a1ISdMVqD1KXn71W4v6Or9+66gbSoH72J3Hlg+0TtB3V
RVrp8TAHSKhuOMbCw/XHYKZQnGjuRi+y9iqayNQ9nR8BadmaTeZD8kPGASEdCMLL
dvxWGajs9+0XokS1cpYaM3gX++ohRbBMu4e/0ASY4happl1ESx0rWDNlyRnQGPnt
VgLHRRwokoR/SeEmrlupvgkzuuL97hi+SJcuanG374WFMEpFXDdMCx2XocaSSJU=
=PITA
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/37013cab/attachment.key>

From rousskov at measurement-factory.com  Mon Apr  4 15:52:49 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 4 Apr 2016 09:52:49 -0600
Subject: [squid-users] Can Squid send the response time information to
 icap?
In-Reply-To: <BLU184-W6706AE1D09008F0A08F3FCFE9D0@phx.gbl>
References: <BLU184-W6706AE1D09008F0A08F3FCFE9D0@phx.gbl>
Message-ID: <57028DD1.4050307@measurement-factory.com>

On 04/04/2016 08:52 AM, Giray Simsek wrote:
> Hi,
> 
> Can Squid send the response time information to icap by passing a header
> and a value pair to icap?

Yes, Squid can do that via adaptation_meta, but true "response time" may
not be the information you actually want.

  http://www.squid-cache.org/Doc/config/adaptation_meta/


> I am trying to get the duration for the http responses within the icap
> module. That is, the time it takes to get the response from the external
> web server after the initial http get request is sent. 
> 
> I am hoping there is a way to pass this information from squid to c-icap.
> 
> I see that it is possible to log this information in squid using the
> format code:
> 
>  tr Response time (milliseconds)

You might be assuming (incorrectly) that the ICAP transaction starts
when the HTTP transaction with the origin server ends. In reality, the
two transactions may overlap. They usually do overlap for large
responses. Thus, the response time is often not yet known at the ICAP
transaction start time.

Furthermore, %tr includes Squid-to-client delivery delays so it is
especially inappropriate at pre-cache RESPMOD time. Use %<pt or %<tt to
solve that part of the problem:

> [http::]<pt     Peer response time in milliseconds. The timer starts
>                 when the last request byte is sent to the next hop
>                 and stops when the last response byte is received.
> [http::]<tt     Total [peering] time in milliseconds. The timer 
>                 starts with the first connect request (or write I/O)
>                 sent to the first selected peer. The timer stops
>                 with the last I/O with the last peer.



I have not checked whether %tr or %<tt logs "response time so far" if
used for yet-unfinished transactions. If it does, then you may use it
(but you would be relying on undocumented/not-guaranteed behavior!).

You might be better off with using a combination of %ts.%03tu and %tS
(instead of %<tt). The difference between %ts.%03tu and %tS values may
be a better approximation for what you want:

> tS      Approximate master transaction start time in 
>         <full seconds since epoch>.<fractional seconds> format.
>         Currently, Squid considers the master transaction
>         started when a complete HTTP request header initiating
>         the transaction is received from the client. This is
>         the same value that Squid uses to calculate transaction
>         response time when logging %tr to access.log. Currently,
>         Squid uses millisecond resolution for %tS values,
>         similar to the default access.log "current time" field
>         (%ts.%03tu).

Ideally, you need a new logformat codes with Squid-to-origin request
start time (to pair with the already supported %<pt and %<tt). Please
consider adding those codes to Squid:

http://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F


HTH,

Alex.



From jok at spikes.com  Mon Apr  4 16:49:48 2016
From: jok at spikes.com (Jok Thuau)
Date: Mon, 4 Apr 2016 09:49:48 -0700
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <5701F4B0.8060001@treenet.co.nz>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
Message-ID: <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>

On Sun, Apr 3, 2016 at 9:59 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 4/04/2016 4:18 p.m., Jok Thuau wrote:
> > I'm attempting to build a transparent proxy (policy based routing on
> > firewall to squid proxy) with the following behavior:
> >
> > 1) proxies http traffic for a given set of domains, provide an message
> > otherwise such "domain not allowed" or similar
> > 2) proxies https traffic for a given set of domains (ideally, splicing
> > those, so as not to break HSTS, if enabled), otherwise provide an error
> > message (bumping and providing "domain not allowed")
> >
> > I'm attempting this with a 3.5.15 compiled with icap (not yet used) and
> > ssl-bumping.
> >
> > Part 1 seems easy enough (and is well documented)...
> >
> > acl whitelist dstdomain .domain1.tld
> > acl whitelist dstdomain .domain2.tld
> >
> > acl http_ok all-of whitelist !SSL_ports
> >
> > http_access allow http_ok
> > http_access deny all
>
> This is denying the HTTPS traffic CONNECT requests (synthesized by
> Squid), since they only have IP address no domain name.
>

yes, this is where I started with just http.


>
>
> >
> > Moving onto Part 2 (the peek and splice setup) appears to be the topic
> of a
> > few discussions out there...
> >
> > acl sni_whitelist ssl::server_name .domain1.tld
> > acl sni_whitelist ssl::server_name .domain2.tld
> >
> > ssl_bump peek step1
>
> You have omitted the definition of step1 ACL.
>
>
the definition of "step1" is the same as the one on the wiki (See full
config below)


> > ssl_bump splice sni_whitelist
> > ssl_bump bump all
> >
> > It appears however that when combining the two, the generated
> > certificate(s), instead of mimic'ing the original server's certificate
> > comes out with the CN=<IP> where <IP> is the ip used by the "connect"
> part
> > of the connection. In addition, it appears that only the first entry ever
> > matches (at this point, i've tried so many combinations, i'm no longer
> > certain of anything).
>
> You have omitted the http(s)_port configuration details, and the step1
> ACL. So its not possible to say if you have the cert generation settings
> wrong, or if the peeking step is matching wrong, or something else.
>
>
That's included in the config below.


> >
> > If i remove *all* the http_access lines, then the behavior appears
> correct
> > (from a "splicing/bumping" standpoint).
> >
>
> Strange. Squid without any http_access lines should be denying traffic
> 100%.
>
>
I do not see this behavior. Traffic appears to be allowed, and bumped
(though with the wrong certificate, depending on the config, as explained
before).


> > Can anyone confirm that this is indeed possible to achieve?
> >
> > I believe, based on experimentation that any http_access i have, because
> of
> > the "deny all" cause the bumping to "short circuit" and effectively send
> an
> > early "access denied" based on the only information it has (the ip
> address
> > from the "connect", rather than the SNI that would come later).
> >
> > Would a setup where "deny http+!whitelist" so have the allow be the
> default
> > allow for the bumping to work and get to step2 and match the sni* acls
> > somehow? (with a "deny step2 !sni_whitelist").
> >
> > Is 3.5.15 capable of doing this? If this requires some feature/effort,
> what
> > would be the procedure to sponsor that work?
>
> It is not possible to answer any of those questsions properly without
> full config details. You have omitted a lot.
>

my apologies for trying to show only the relevant parts. Find below the
current config.
It appears to be bumping everything rather than splicing any of the config
(which may be due to the limitations documented on the wiki)

acl Safe_ports port 80 # http
acl Safe_ports port 443 # https
acl SSL_ports port 443
acl CONNECT method CONNECT
http_port 3129 intercept
https_port 8443 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=64MB \
    cert=/etc/squid/ssl/proxy.pem \
    key=/etc/squid/ssl/proxy.key \
    cafile=/etc/squid/ssl/proxy.pem
always_direct allow all
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl SniBypass ssl::server_name_regex \.slashdot\.org
acl SniBypass ssl::server_name_regex \.fsdn\.com
acl http_bypass dstdomain .slashdot.org
acl http_bypass dstdomain .fsdn.com
acl https_bypass all-of CONNECT SniBypass
acl http_ok all-of http_bypass Safe_ports
ssl_bump peek step1
ssl_bump splice SniBypass step2
ssl_bump bump all
sslproxy_cert_sign_hash sha256
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
always_direct allow all
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1
http_access allow http_ok
http_access allow CONNECT
no_cache allow all
cache deny all
shutdown_lifetime 3 seconds
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/3de40961/attachment.htm>

From jok at spikes.com  Mon Apr  4 16:50:29 2016
From: jok at spikes.com (Jok Thuau)
Date: Mon, 4 Apr 2016 09:50:29 -0700
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <1459772339.2673.1.camel@gamebox>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <1459772339.2673.1.camel@gamebox>
Message-ID: <CADSSinMGfFGxA9y7JYebFLwvOkKmJF2-grwxkjNBjX0r3kui2w@mail.gmail.com>

Thanks James! This is really close to what I need. Comparing this to my
existing config, it looks like i'm pretty close, except that i don't want
to "terminate" the sslbump, i need to send an error notification to the
end-user.

?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/14ced2b6/attachment.htm>

From sebastien at damaye.fr  Mon Apr  4 17:11:56 2016
From: sebastien at damaye.fr (=?UTF-8?Q?S=c3=a9bastien_Damaye?=)
Date: Mon, 4 Apr 2016 19:11:56 +0200
Subject: [squid-users] X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY error
 with transparent proxy configured with peek and splice
Message-ID: <5702A05C.1070702@damaye.fr>

Hi community,

I have setup Squid as transparent proxy (iptable is taking care of
redirecting 80/tcp and 443/tcp traffic to Squid) with peek and splice on
a Debian Jessie server to perform SSL inspection. Below is the
interesting part of my squid.conf file:

http_port 3130
http_port 3128 intercept
https_port 3129 intercept ssl-bump \
    cert=/etc/squid/ssl_cert/myCA.pem \
    generate-host-certificates=on \
    dynamic_cert_mem_cache_size=4MB \
    options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE \
    dhparams=/etc/squid/ssl_cert/dhparam.pem

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl nobumpSites ssl::server_name "/etc/squid/domain.nobump"

ssl_bump peek step1 all
ssl_bump peek step2 nobumpSites
ssl_bump splice step3 nobumpSites
ssl_bump bump

sslproxy_cipher
EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

The SSL inspection works fine for the majority of the websites (I
populate domain.nobump with some domains from time to time) but I had a
X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY error that I'm not able to
fix while visiting https://blog.kaspersky.com. I have added
".blog.kaspersky.com" in my domain.nobump file but I still can't visit
the website.

Could you please help? Many thanks in advance for your inputs.

-- 
Cordialement/Regards,

S?bastien Damaye
PGP keyID: 0x59B1D7DE


From rafael.akchurin at diladele.com  Mon Apr  4 17:21:19 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 4 Apr 2016 17:21:19 +0000
Subject: [squid-users] Squid 3.5.16-1 is available for Ubuntu 14.04 LTS
 (online repo ubuntu.diladele.com)
Message-ID: <VI1PR04MB1359183D8D4F92E7187E04E78F9D0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Greetings everyone,

The Squid 3.5.16-1 package for Ubuntu 14.04 LTS is now available. This version is recompiled using Squid DEB source from Debian Testing with some changes required to support SSL bump / libecap3 on Ubuntu 14.04 LTS. 

* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.16-RELEASENOTES.html 
* The online repo is at http://ubuntu.diladele.com 
* Tutorial showing how we rebuilt Squid 3.5.16 on Ubuntu 14.04 LTS http://docs.diladele.com/tutorials/build_squid_ubuntu14/index.html 
* Scripts we used to build it are at https://github.com/ra-at-diladele-com/qlproxy_external/tree/master/src/squid.ssl/scripts.squid3

If you have installed previous version 3.5.15-1 from this repo then please run "sudo apt-get update && sudo apt-get upgrade".  Please also check that your current squid.conf file from previous version is not overwritten. 

If you are installing this version for the first time run the following commands:

    # add repo
    echo "deb http://ubuntu.diladele.com/ubuntu/ trusty main" > /etc/apt/sources.list.d/ubuntu.diladele.com.list

    # update the apt cache
   apt-get update

   # install 
   apt-get install libecap3
   apt-get install squid-common
   apt-get install squid 
   apt-get install squidclient

All questions/comments and suggestions are welcome at support at diladele.com or here in the mailing list.

Best regards,
Rafael Akchurin
Diladele B.V. 
http://www.quintolabs.com 
http://www.diladele.com 

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com.



From yvoinov at gmail.com  Mon Apr  4 17:42:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 4 Apr 2016 23:42:18 +0600
Subject: [squid-users] X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY
 error with transparent proxy configured with peek and splice
In-Reply-To: <5702A05C.1070702@damaye.fr>
References: <5702A05C.1070702@damaye.fr>
Message-ID: <5702A77A.5050808@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
acl BrokenButTrustedServers2 dstdomain "/usr/local/squid/etc/dstdom2.broken"
acl UnableGetIssuer ssl_error
X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY
X509_V_ERR_UNABLE_TO_VERIFY_LEAF_SIGNATURE
sslproxy_cert_error allow BrokenButTrustedServers2 UnableGetIssuer
sslproxy_cert_error deny all

Something like this.

04.04.16 23:11, S?bastien Damaye ?????:
> Hi community,
>
> I have setup Squid as transparent proxy (iptable is taking care of
> redirecting 80/tcp and 443/tcp traffic to Squid) with peek and splice on
> a Debian Jessie server to perform SSL inspection. Below is the
> interesting part of my squid.conf file:
>
> http_port 3130
> http_port 3128 intercept
> https_port 3129 intercept ssl-bump \
>     cert=/etc/squid/ssl_cert/myCA.pem \
>     generate-host-certificates=on \
>     dynamic_cert_mem_cache_size=4MB \
>     options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE \
>     dhparams=/etc/squid/ssl_cert/dhparam.pem
>
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> acl nobumpSites ssl::server_name "/etc/squid/domain.nobump"
>
> ssl_bump peek step1 all
> ssl_bump peek step2 nobumpSites
> ssl_bump splice step3 nobumpSites
> ssl_bump bump
>
> sslproxy_cipher
>
EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
> The SSL inspection works fine for the majority of the websites (I
> populate domain.nobump with some domains from time to time) but I had a
> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY error that I'm not able to
> fix while visiting https://blog.kaspersky.com. I have added
> ".blog.kaspersky.com" in my domain.nobump file but I still can't visit
> the website.
>
> Could you please help? Many thanks in advance for your inputs.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXAqd6AAoJENNXIZxhPexGxoMH+wVN/kjAe85+oWbn47j2dyL6
biJKM+CepVzrubilhC4uL6zjTYIsZjD1JXv3VuoY6l+vFbg2Drip76yo9qO49fjh
83afktO+o1YsfxLhbQZjByknCbuDqd5a2Udzo8dhEHTYNV0vieq2tE7QgJvHOxvP
wFC8neOwglKzDq7yD4h30nidVhP6f8gCKwv9MzlXpT+kkHAEM0rn5OnXRDc6UQxm
3mNOJJwo9y5E5gqjJAt7PulNJvqJ+crDoW+T6IgTkxQFD8+tBXy+qyqk7hrTOIF0
DQgiLFL+X5C4YKVtpmBIaxko6pxmmXZAO0LUtLjuj/qNHoc63ZZZIQYgIFvbUgw=
=b8wV
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160404/4dc7c418/attachment.key>

From bpk678 at gmail.com  Mon Apr  4 22:25:46 2016
From: bpk678 at gmail.com (Brendan Kearney)
Date: Mon, 04 Apr 2016 18:25:46 -0400
Subject: [squid-users] Identifying intercepted clients
In-Reply-To: <5701B00A.7050504@treenet.co.nz>
References: <5701435D.7090102@gmail.com> <5701B00A.7050504@treenet.co.nz>
Message-ID: <5702E9EA.9050200@gmail.com>

On 04/03/2016 08:06 PM, Amos Jeffries wrote:
> On 4/04/2016 4:22 a.m., Brendan Kearney wrote:
>> with fedora 24 being released in a couple months, haproxy v1.6.x will be
>> available, and the ability to easily intercept HTTP traffic will be in
>> the version (see the set-uri directive).  with v1.6 i will be able to
>> rewrite the URL, so that squid can process the request properly.
> That does not make sense. Intercepting and URL-rewriting are completely
> different actions.
>
> The Squid-3.5 and later versions are able to receive PROXY protocol
> headers from HAProxy. You may find that much better than fiddling around
> with URLs and available in your current HAProxy.
i use iptables to intercept the request, and need the set-uri option in 
haproxy 1.6.x to concatenate the Host header with the GET, in order to 
have the request in the form that squid expects the request.  yes, they 
are separate actions and i should have been clearer.

i will look into the PROXY protocol additions, but that may not be an 
option until i can get all my boxes upgraded.
>
>
>>   my
>> problem is that i run authenticated access on the proxy, and will need
>> to exempt the traffic from that restriction.
>>
> What restriction?
the authenticated access restriction.  not much of my policy allows for 
unauthenticated access.
>
>
>> what mechanisms can i use to identify the fact that the client traffic
>> has been intercepted, so that i can create ACLs to match the traffic?  i
>> don't want to use things like IPs or User-Agent strings, as they may
>> change or be unknown.
> Only the interceptor can do that traffic distinction. Once traffic gets
> multiplexed the information is lost.
i tried to create / insert a header at the router/firewall/load 
balancer, and test for the existence of the header in squid, but that 
did not seem to go as well as i thought it might.
>
>> i was thinking about sending the intercepted traffic to a different
>> port, say 3129, and then using localport to identify the traffic. with
>> an ACL, i would exempt the traffic from auth, etc.  are there better
>> options?  how are other folks dealing with intercepted and explicit
>> traffic on the same box?
> That would be one fairly good way to distinguish the traffic types. So
> why is the URL fiddling happening?
because i need to concatenate the Host header with the GET line (URI), 
in order for squid to be able to process the request.  i dont have squid 
3.5 yet, nor do i have haproxy 1.6 yet, so i have to use the old 
interception methods to accomplish this, at this point.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
thanks for the feedback.  seems i might be able to do things, just have 
to find my way through until newer versions give me better means of 
doing it.

thanks,

brendan


From squid3 at treenet.co.nz  Mon Apr  4 23:44:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Apr 2016 11:44:04 +1200
Subject: [squid-users] squid 3.5 vs 4.0
In-Reply-To: <5702838A.4010203@gmail.com>
References: <570282E7.7030709@afo.net> <5702838A.4010203@gmail.com>
Message-ID: <5702FC44.3030207@treenet.co.nz>

> 04.04.16 21:06, Mike ?????:
>> Is there any list or page with any comparison information, say for the 2 latest versions 3.5.16 and
> 4.0.8 beta? I understand many of the fixes coming out are being done for
> both, but so far I do not see any information that describes any benefit
> to using 4.0 over 3.5. any help would be appreciated.


On 5/04/2016 3:08 a.m., Yuri Voinov wrote:
>
> http://wiki.squid-cache.org/RoadMap
>

4.0 release notes has more up to date list of changes, with explanation.
<http://www.squid-cache.org/Versions/v4/RELEASENOTES.html>

Amos



From squid3 at treenet.co.nz  Tue Apr  5 00:18:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Apr 2016 12:18:42 +1200
Subject: [squid-users] Problem to configure squid for HTTPS website
 (HSTS or others certificate problems)
In-Reply-To: <DB5PR06MB098440CE459284307D4DCFB8A39D0@DB5PR06MB0984.eurprd06.prod.outlook.com>
References: <DB5PR06MB098440CE459284307D4DCFB8A39D0@DB5PR06MB0984.eurprd06.prod.outlook.com>
Message-ID: <57030462.3080802@treenet.co.nz>

On 4/04/2016 9:25 p.m., Raph Ghost wrote:
> Hi users :)
> 
> 
> What I want to do: I have a dedicated server and I want to make it as a transparent adblocker through a VPN. So I have installed and configured OpenVPN and route my traffic from the VPN tun into the squid proxy.
> 
> 
> What is the problem: Websites based on http work great but those based on httpS doesn't work at all.
> 
> 
> I have already tried two squid configurations and look for that problem in the user mail list history but I can't find any workaround that works.
> 
> 
> My compilation options (squid 3.5.15 -with-openssl is enabled):
> 

Please upgrade to 3.5.16.


> '--with-openssl=/etc/ssl' '--enable-ssl-crtd'

 /etc is a location for config files. I somehow doubt that you have
installed the openssl binaries in there.

If you installed libssl-dev package correctly then you don't need the
"=/path" piece to be specified at all. Squid build script will find
OpenSSL in its normal place.


> My iptable conf (port 22: my ssh server/ input port 443: my OpenVPN server):
> 
> -P INPUT DROP
> -P FORWARD DROP
> -P OUTPUT DROP
> -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
> -A INPUT -i lo -j ACCEPT
> -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT
> -A INPUT -p tcp -m tcp --dport 53 -j ACCEPT
> -A INPUT -p udp -m udp --dport 53 -j ACCEPT
> -A INPUT -i eth0 -p tcp -m state --state NEW -m tcp --dport 443 -j ACCEPT
> -A INPUT -i tun0 -j ACCEPT
> -A FORWARD -i tun0 -j ACCEPT
> -A FORWARD -o tun0 -j ACCEPT
> -A FORWARD -i tun0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT
> -A FORWARD -i eth0 -o tun0 -m state --state RELATED,ESTABLISHED -j ACCEPT
> -A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
> -A OUTPUT -o lo -j ACCEPT
> -A OUTPUT -p tcp -m tcp --dport 22 -j ACCEPT
> -A OUTPUT -p tcp -m tcp --dport 53 -j ACCEPT
> -A OUTPUT -p udp -m udp --dport 53 -j ACCEPT
> -A OUTPUT -p tcp -m tcp --dport 80 -j ACCEPT
> -A OUTPUT -p udp -m udp --dport 123 -j ACCEPT
> -A OUTPUT -o tun0 -j ACCEPT
> -A OUTPUT -p icmp -j ACCEPT
> 
> My iptable conf (nat table):
> -P PREROUTING ACCEPT
> -P INPUT ACCEPT
> -P OUTPUT ACCEPT
> -P POSTROUTING ACCEPT
> -A PREROUTING -s 10.8.0.0/24 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3129
> -A PREROUTING -s 10.8.0.0/24 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3130
> -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE
> 
> This iptables configuration works great to route vpn input trafic into squid.
> 
<snip>

> 2nd conf I have tried (based on many tutorials and the official squid wiki especially to configure Ssl Bump/Peek and Slice function):
> #
> # Recommended minimum configuration:
> #
<snip>

> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> 
> always_direct allow all

always_direct is not relevant since 3.1. Remove.

> sslproxy_cert_error allow all

By instructing Squid to ignore all errors, you are hiding all cert
related errors. Remove the above line to see if there is some error
being encountered that is leading to your problem.

> sslproxy_cafile /etc/ssl/certs/ca-certificates.crt
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> # Squid normally listens to port 3128
> http_port 10.8.0.1:3128
> http_port 10.8.0.1:3129 transparent

"transparent" is obsolete. Use "intercept" instead.

> https_port 10.8.0.1:3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=6MB cert=/etc/squid/ssl_cert/myCA.pem

... 6MB here and the 4MB on the helper. Those numbers need to be the
same IIRC.

> 
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> 
> ssl_bump peek step1 all
> ssl_bump stare step2
> ssl_bump bump step3
> 
> 
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /var/spool/squid 100 16 256
> 
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
> 
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
> 
> 
> Unfortunately none of these conf work.
> 
> With the first conf:
> If i try to connect to https://openclassrooms.com/ for example I get a warning about that the certificate is not trust. I can overpass this warning (by clicking on "continue on this website (dangerous)") but after few seconds I get an error generated by squid:
> "L'erreur suivante s'est produite en essayant d'acc?der ? l'URL : https://openclassrooms.com/
> La connexion 190.93.240.239 a ?chou?e.
> Le syst?me a retourn? : (110) Connection timed out   < ----- Important line
> L'h?te distant ou le r?seau sont peut-?tre d?faillant. Veuillez renouveler votre requ?te.
> Votre administrateur proxy est webmaster."
> 
> In access.log I get:
> 1459756883.952     42 10.8.0.6 TCP_MISS/200 565 GET http://www.google-analytics.com/__utm.gif? - ORIGINAL_DST/216.58.214.78 image/gif
> 1459756885.636     14 10.8.0.6 TCP_MISS/204 262 GET http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.214.67 -
> 1459756890.842     17 10.8.0.6 TCP_MISS/302 505 GET http://openclassrooms.com/ - ORIGINAL_DST/190.93.240.239 -
> 1459756891.129     14 10.8.0.6 TCP_MISS/204 262 GET http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.214.67 -
> 1459756961.902  60814 10.8.0.6 TCP_MISS/503 4850 GET https://openclassrooms.com/ - ORIGINAL_DST/190.93.240.239 text/html
> 
> In cache.log there is nothing especial.
> 
> When I try to connect to https://www.google.fr I get a warning (from my browser, here Chrome) but I can't overpass it (due to HSTS technologie).
> 
> 
> 
> With the second conf (which is supposed to dynamically generate certificate from the original certificate to overpass HSTS - at least this I did think but it doesn't work):

When TLS is used properly/securely it cannot be bumped.

When visiting Google sites using Chrome (Google software) they employ
certificate pinning (aka hard-coded their official certificate(s) into
the browser), which prevents bumping from working.

HSTS is a different feature, which does not actually do any security
improvement to TLS itself. So can still be bumped - unless other TLS
usage prevents the bumping.


> Both of google or openclassroom websites generate the same result:
> On browser I get a ERR_TIMED_OUT.
> 
> In access.log:
> 1459755020.622  59785 10.8.0.6 TAG_NONE/200 0 CONNECT 46.228.47.114:443 - ORIGINAL_DST/46.228.47.114 -
> 1459755043.645  60448 10.8.0.6 TAG_NONE/200 0 CONNECT 46.228.47.115:443 - ORIGINAL_DST/46.228.47.115 -
> 1459755045.000  60058 10.8.0.6 TAG_NONE/200 0 CONNECT 216.58.211.106:443 - ORIGINAL_DST/216.58.211.106 -
> 
> In store.log I get SOMETIMES (rarely) this:
> 2016/04/01 11:43:05| Pinger exiting.
> 2016/04/01 11:46:02 kid1| Error negotiating SSL connection on FD 27: Closed by client
> 2016/04/01 11:46:09 kid1| Error negotiating SSL connection on FD 36: Closed by client
> 2016/04/01 11:46:16 kid1| Error negotiating SSL connection on FD 30: Closed by client
> 2016/04/01 11:46:23 kid1| Error negotiating SSL connection on FD 38: error:14076102:SSL routines:SSL23_GET_CLIENT_HELLO:unsupported protocol (1/-1)

Meaning that non-HTTPS is being sent over port 443. Sadly that is very
common these days. You will need the on_unsupported_protocol feature of
Squid-4 to get around that.

Squid-4 is also able to handle certain types of TLS hello message that
Squid-3 will report the above message for.

> 
> Whatever configuration that I used I have import certificate into my browser correctly.
> 

"I get a warning about that the certificate is not trust" indicates that
it has *not* been imported correctly into the trusted certs.

Amos



From squid3 at treenet.co.nz  Tue Apr  5 00:35:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Apr 2016 12:35:37 +1200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <57030859.5060609@treenet.co.nz>

On 5/04/2016 2:44 a.m., FredB wrote:
>>
>> Thanks I will test, I confirm the problem still present after a while
>> Eg: this object seems never cleaned/fixed from cache
>>
> 
> No more success with fresh cache, after 5 minutes the messages appears again and again 
> Joe is right there is a bug somewhere 

The only Vary related change between .15 and .16 was the CVE fix
<www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14016.patch>.

I am suspicious of the +1 being added in src/store_swapmeta.cc. There is
a TODO next to it. Would you mind trying without it?

I expect the cache will need clearing to make that change operate
properly after the change. But if it is the problem the loops should not
return like they do now.

Amos



From squid3 at treenet.co.nz  Tue Apr  5 01:23:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Apr 2016 13:23:28 +1200
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
Message-ID: <57031390.8020604@treenet.co.nz>

On 5/04/2016 4:49 a.m., Jok Thuau wrote:
> On Sun, Apr 3, 2016 at 9:59 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 4/04/2016 4:18 p.m., Jok Thuau wrote:
>>> I'm attempting to build a transparent proxy (policy based routing on
>>> firewall to squid proxy) with the following behavior:
>>>
>>> 1) proxies http traffic for a given set of domains, provide an message
>>> otherwise such "domain not allowed" or similar
>>> 2) proxies https traffic for a given set of domains (ideally, splicing
>>> those, so as not to break HSTS, if enabled), otherwise provide an error
>>> message (bumping and providing "domain not allowed")
>>>
>>> I'm attempting this with a 3.5.15 compiled with icap (not yet used) and
>>> ssl-bumping.
>>>
>>> Part 1 seems easy enough (and is well documented)...
>>>
>>> acl whitelist dstdomain .domain1.tld
>>> acl whitelist dstdomain .domain2.tld
>>>
>>> acl http_ok all-of whitelist !SSL_ports
>>>
>>> http_access allow http_ok
>>> http_access deny all
>>
>> This is denying the HTTPS traffic CONNECT requests (synthesized by
>> Squid), since they only have IP address no domain name.
>>
> 
> yes, this is where I started with just http.
> 
> 
>>
>>
>>>
>>> Moving onto Part 2 (the peek and splice setup) appears to be the topic
>> of a
>>> few discussions out there...
>>>
>>> acl sni_whitelist ssl::server_name .domain1.tld
>>> acl sni_whitelist ssl::server_name .domain2.tld
>>>
>>> ssl_bump peek step1
>>
>> You have omitted the definition of step1 ACL.
>>
>>
> the definition of "step1" is the same as the one on the wiki (See full
> config below)
> 
> 
>>> ssl_bump splice sni_whitelist
>>> ssl_bump bump all
>>>
>>> It appears however that when combining the two, the generated
>>> certificate(s), instead of mimic'ing the original server's certificate
>>> comes out with the CN=<IP> where <IP> is the ip used by the "connect"
>> part
>>> of the connection. In addition, it appears that only the first entry ever
>>> matches (at this point, i've tried so many combinations, i'm no longer
>>> certain of anything).
>>
>> You have omitted the http(s)_port configuration details, and the step1
>> ACL. So its not possible to say if you have the cert generation settings
>> wrong, or if the peeking step is matching wrong, or something else.
>>
>>
> That's included in the config below.
> 
> 
>>>
>>> If i remove *all* the http_access lines, then the behavior appears
>> correct
>>> (from a "splicing/bumping" standpoint).
>>>
>>
>> Strange. Squid without any http_access lines should be denying traffic
>> 100%.
>>
>>
> I do not see this behavior. Traffic appears to be allowed, and bumped
> (though with the wrong certificate, depending on the config, as explained
> before).
> 
> 
>>> Can anyone confirm that this is indeed possible to achieve?
>>>
>>> I believe, based on experimentation that any http_access i have, because
>> of
>>> the "deny all" cause the bumping to "short circuit" and effectively send
>> an
>>> early "access denied" based on the only information it has (the ip
>> address
>>> from the "connect", rather than the SNI that would come later).
>>>
>>> Would a setup where "deny http+!whitelist" so have the allow be the
>> default
>>> allow for the bumping to work and get to step2 and match the sni* acls
>>> somehow? (with a "deny step2 !sni_whitelist").
>>>
>>> Is 3.5.15 capable of doing this? If this requires some feature/effort,
>> what
>>> would be the procedure to sponsor that work?
>>
>> It is not possible to answer any of those questsions properly without
>> full config details. You have omitted a lot.
>>
> 
> my apologies for trying to show only the relevant parts. Find below the
> current config.
> It appears to be bumping everything rather than splicing any of the config
> (which may be due to the limitations documented on the wiki)
> 
> acl Safe_ports port 80 # http
> acl Safe_ports port 443 # https
> acl SSL_ports port 443
> acl CONNECT method CONNECT
> http_port 3129 intercept
> https_port 8443 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=64MB \
>     cert=/etc/squid/ssl/proxy.pem \
>     key=/etc/squid/ssl/proxy.key \
>     cafile=/etc/squid/ssl/proxy.pem
> always_direct allow all

always_direct has not been necessary with SSL-Bump sice 3.1 series. You
should remove it.

> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> acl SniBypass ssl::server_name_regex \.slashdot\.org
> acl SniBypass ssl::server_name_regex \.fsdn\.com
> acl http_bypass dstdomain .slashdot.org
> acl http_bypass dstdomain .fsdn.com
> acl https_bypass all-of CONNECT SniBypass

This https_bypass ACL definition is a bit weird. It requires a single
message to match both TLS and HTTP properties simultaneously.

As you might imagine it is difficult for a TLS messages to match HTTP
properties, and vice versa. So it wont ever match.

Note: SNI is *not* equivalent to Host or URL domain name. They can
contain very different values. The only thing they have in common is
that they both are supposed to point at the IP of the server being
contacted.


> acl http_ok all-of http_bypass Safe_ports
> ssl_bump peek step1
> ssl_bump splice SniBypass step2

This splice will work if (and only if) the client sends TLS SNI values
to Squid. It will ignore the server cert details.

For clients which do not send SNI or for all connections where the SNI
does not match your ACL the bump rule below will do client-first bumping
(without the server cert).

> ssl_bump bump all

I suggets you try these ssl_bump rules instead:

 ssl_bump splice SniBypass
 ssl_bump peek step1
 ssl_bump stare step2
 ssl_bump bump all

> sslproxy_cert_sign_hash sha256
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
> always_direct allow all

repeated useless line.

> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
> http_access allow http_ok
> http_access allow CONNECT

 ... implicit "deny all" for everything which is not a CONNECT message
or matching http_bypass.

Okay. That sort of matches your policy. Except that you are missing the
security defaults. Those lines are carefully tuned for the specific
behaviour to protect against security attacks:

 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_ports

.. and should be above your custom rules.

> no_cache allow all
> cache deny all

"no_cache" is an old confusing name for "cache" directive. So what you
have there is actually:

 cache allow all
 cache deny all

... pick one.


> shutdown_lifetime 3 seconds
> 

Amos



From supriyaprasad32 at gmail.com  Tue Apr  5 04:53:01 2016
From: supriyaprasad32 at gmail.com (Supriya Prasad)
Date: Tue, 5 Apr 2016 10:23:01 +0530
Subject: [squid-users] Squid Queries
Message-ID: <CAApL2HcLnSb9hCXgCpLeJ9bR0q-XBtqjqHtbUKHWsPyZ4DtJiA@mail.gmail.com>

Hi Team,

I had some queries regarding the squid configuration:


We are using squid as a cache for our CWS proxy. As we are aware of the
max-forwards header, it decrements as it goes through each of the
proxies.Currently, our CWS proxy and squid both decrement the max forwards
header value when processing options requests. So if we send a max-forwards
header of 5 from the client side, by the time is comes out of squid it
shows 3. However as our proxy and squid is seen as 1 entity, we want the
decrement to happen only once.

I went through a number of squid documentation and nowhere it mentions how
to disable the max forward header from decrementing on squid. Could you
please let us know what is to be done?


Thanks and Regards,

Supriya
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/bab4e355/attachment.htm>

From fredbmail at free.fr  Tue Apr  5 07:09:13 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 5 Apr 2016 09:09:13 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <57030859.5060609@treenet.co.nz>
Message-ID: <674788680.75792897.1459840153781.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hi Amos,

I confirm, cleaning the cache (mkfs in my case) do not fix the issue 

Fred 


From phafer at 163.com  Tue Apr  5 07:50:51 2016
From: phafer at 163.com (phafer)
Date: Tue, 5 Apr 2016 15:50:51 +0800 (CST)
Subject: [squid-users] how to use squid as a tcp forward proxy?
Message-ID: <7c750b4d.93ae.153e5671728.Coremail.phafer@163.com>

hi,


how can I extend squid to process/modify payload of my private application protocol basing on TCP?
Client->squid->my squid plugin which is used to process/modify payload of tcp traffic->Server


BR,
Bin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/2e7e09d9/attachment.htm>

From Axel.Eberhardt at t-systems.com  Tue Apr  5 09:08:05 2016
From: Axel.Eberhardt at t-systems.com (Axel.Eberhardt at t-systems.com)
Date: Tue, 5 Apr 2016 11:08:05 +0200
Subject: [squid-users] squid ftp-proxy
Message-ID: <6872D3617BB75149A218368CB61B73A3064AECB4900D@HE113669.emea1.cds.t-internal.com>

Hello,

Maybe someone can give me a hint :-)

I try to enable the Native ftp proxying.
The documentation I have found is:
http://wiki.squid-cache.org/Features/FtpRelay

But there is no example for this. Also in the Mail Archives I was not able to find a hint.

I have configured the ftp proxy with parameter:
	ftp_port 21

Version:
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
squid -v
Squid Cache: Version 3.5.15
Service Name: squid
configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--verbose' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake' '--enable-auth-ntlm=smb_lm,fake' '--enable-auth-digest=file,LDAP,eDirectory' '--enable-auth-negotiate=kerberos,wrapper' '--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,file_userip,SQL_session,unix_group,session,time_quota' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi' '--enable-ssl-crtd' '--enable-icmp' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' '--with-included-ltdl' '--disable-arch-native' '--enable-ecap' '--without-nettle' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic' 'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -fPIC' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' --enable-ltdl-convenience
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Now my problem.

I am able to connect via ftp client to the squid.
Also the login will be correct:	
	example:  anonymous at ftp.informatik.rwth-aachen.de
	
But after a command which use a data channel the connection fails:
	421 Service not available, remote server has closed connection


I try a tcpdump but I cannot find a failure. 
The only different between a native ftp session and a connection over the squid is a missing TCP ACK after the last ftp data package. 

___________________________________________________________ 
? 
Kind regards
Axel Eberhardt 



From pascal at watteel.be  Tue Apr  5 12:08:32 2016
From: pascal at watteel.be (Pascal Watteel)
Date: Tue, 5 Apr 2016 12:08:32 +0000
Subject: [squid-users] select parent proxy based on ACL
In-Reply-To: <1459857825.9684.21.camel@watteel.be>
References: <1459857825.9684.21.camel@watteel.be>
Message-ID: <1459858102.9684.23.camel@watteel.be>

Hi peeps,

I have written a python based download accelerator based proxy.
It does exactly the same thing as what aria2c would do, but as a proxy.

I now want to tell squid to only send .zip .iso .whatever to this proxy
as an parent proxy.
But i only find a way how to tell squid to do this for domains with
peer_domain.

Is there a way how i can tell squid to decide the parent proxy based on
a ACL so i can just use regex define the files i wanna send to this
parent?

Regards

Watteel Pascal

From drikus at geocastsp.co.za  Tue Apr  5 13:50:59 2016
From: drikus at geocastsp.co.za (Drikus Brits)
Date: Tue, 05 Apr 2016 15:50:59 +0200
Subject: [squid-users] Kerberos authentication only working with 1 domain
	server
Message-ID: <b4b1da51a97d924d6188ad24c7066d3c@webmail.die-britsies.co.za>

 

Hi Experts, 

After much struggling it seems i've reached some point of success but
yet still not. I've checked a multitude of websites for help before
coming here, but didn't get anything valuable yet. My problem as follows
: 

I have 1x win2008R2 server that works with kerberos authentication, but
none of the other PC's in the network wants to work, the others all come
up with a login challenge/ 

My Configs : 

/etc/krb5.conf 

<snip>
 #cat /etc/krb5.conf
 [logging]

 default = FILE:/var/log/krb5libs.log
 kdc = FILE:/var/log/krb5kdc.log
 admin_server = FILE:/var/log/kadmind.log [1]

 [libdefaults]
 default_realm = DOMAIN.CO.ZA
 dns_lookup_kdc = yes
 dns_lookup_realm = yes
 ticket_lifetime = 24h
 default_keytab_name = /etc/squid/PROXY.keytab

 #; for Windows 2008 with AES
 default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
 default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
 permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5

 [realms]

 DOMAIN.CO.ZA = {
 kdc = mw-ad.domain.co.za
 admin_server = mw-ad.domain.co.za
 default_domain = domain.co.za
 }

 [domain_realm]

 .domain.co.za = DOMAIN.CO.ZA
 domain.co.za = DOMAIN.CO.ZA

 [login]
 krb4_convert = true
 krb4_get_tickets = false
</snip> 

my /etc/squid/squid.conf 

 <snip>
 #auth_param negotiate program /usr/local/bin/negotiate_wrapper -d
--ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=gss-spnego
--domain=DOMAIN --kerberos /usr/lib/squid3/negotiate_kerberos_auth -d -i
###WORKING - half/half
 auth_param negotiate program /usr/lib/squid3/negotiate_wrapper_auth -d
--ntlm /usr/bin/ntlm_auth --diagnostics
--helper-protocol=squid-2.5-ntlmssp --domain=DOMAIN.CO.ZA --kerberos
/usr/lib/squid3/negotiate_kerberos_auth -d -s GSS_C_NO_NAME
 #auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth
-d -s GSS_C_NO_NAME

 auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
--helper-protocol=gss-spnego --domain=DOMAIN.CO.ZA
 auth_param ntlm children 10
 auth_param ntlm keep_alive off

 auth_param basic program /usr/lib/squid3/basic_ldap_auth -b
"DC=domain,DC=co,DC=za" -f sAMAccountName=%s -D "CN=Folder
Authentication,CN=Users,DC=domain,DC=co,DC=za" -w P at 55w0rd -H
ldap://MW-AD.domain.co.za -R
 auth_param basic realm Web-Proxy
 auth_param basic credentialsttl 1 minute

 acl proxy-auth proxy_auth REQUIRED

 http_access allow proxy-auth
 </snip> 

When the Win2008R2 connectes is get the following in
/var/log/squid3/cache.log 

 <snip> 

 2016/04/05 12:26:46| negotiate_wrapper: Got 'YR
YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBgkqhkiC9xIBAgIGCSq<truncated>DVzSeCUH4ntF1lHc='
from squid (length: 2419).
 2016/04/05 12:26:46| negotiate_wrapper: Decode
'YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBg<truncated>UnIKhxWxh52aDVzSeCUH4ntF1lHc='
(decoded length: 1811).
 2016/04/05 12:26:46| negotiate_wrapper: received Kerberos token
 negotiate_kerberos_auth.cc(315): pid=8218 :2016/04/05 12:26:46|
negotiate_kerberos_auth: DEBUG: Got 'YR
YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuB<truncated>JDp51PN7RjUnIKhxWxh52aDVzSeCUH4ntF1lHc='
from squid (length: 2419).
 negotiate_kerberos_auth.cc(378): pid=8218 :2016/04/05 12:26:46|
negotiate_kerberos_auth: DEBUG: Decode
'YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBgkqhkiC9xI<truncated>51PN7RjUnIKhxWxh52aDVzSeCUH4ntF1lHc='
(decoded length: 1811).
 2016/04/05 12:26:46| negotiate_wrapper: Return 'AF
oYG2MIGzoAMKAQChCwYJ<truncated>ZuxzWyWJhUSZttUH70Vw595AsuKtUWvtGjGC7vGmD5Ugufw=
Administrator at DOMAIN.CO.ZA 

 </snip> 

But when other PC's connect of which another win2008R2 or win10 or win7
i get : 

 <snip> 

 negotiate_kerberos_auth.cc(315): pid=9389 :2016/04/05 12:33:47|
negotiate_kerberos_auth: DEBUG: Got 'YR
YIIHDwYGKwYBBQUCoII<truncated>+BnGBajMprtChSPMuUX9nnZfT+cJk=' from squid
(length: 2419).
 negotiate_kerberos_auth.cc(378): pid=9389 :2016/04/05 12:33:47|
negotiate_kerberos_auth: DEBUG: Decode
'YIIHDwYGKwYBBQUCoIIHAzCCBv<truncated>MprtChSPMuUX9nnZfT+cJk=' (decoded
length: 1811).
 negotiate_kerberos_auth.cc(200): pid=9389 :2016/04/05 12:33:47|
negotiate_kerberos_auth: ERROR: gss_accept_sec_context() failed:
Unspecified GSS failure. Minor code may provide more information.
 2016/04/05 12:33:47| ERROR: Negotiate Authentication validating user.
Error returned 'BH gss_accept_sec_context() failed: Unspecified GSS
failure. Minor code may provide more information. ' 

 </snip> 

My kinit -V -kt /etc/squid3/PROXY.keytab , of which i'm sure if not
supposed to say that :). I've had others that had Successfully
authenticated to Kerberos V5 as well, but then the working win2008r2
doesn't work -- see below.. 

 <snip> 

 # kinit -V -kt /etc/squid3/PROXY.keytab
 Using default cache: /tmp/krb5cc_0
 Using principal: host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
 Using keytab: /etc/squid3/PROXY.keytab
 kinit: Preauthentication failed while getting initial credentials 

 </snip> 

working with "authenticated with kerberos but no srv or pc working 

 <snip> 

 msktutil -c -b "CN=COMPUTERS" -s HTTP/mw-sqproxy-test -s
HTTP/mw-sqproxy-test.domain.co.za -h mw-sqproxy-test.domain.co.za -k
/etc/squid3/PROXY.keytab --computer-name MWSQPROXYTEST --upn
HOST/mw-sqproxy-test.domain.co.za --server mw-ad.domain.co.za --verbose
--enctypes 28 

 </snip> 

my working klist entries 

 <snip> 

 klist -ekt /etc/squid3/PROXY.keytab 

 Keytab name: FILE:/etc/squid3/PROXY.keytab
 KVNO Timestamp Principal
 ---- -------------------
------------------------------------------------------
 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA (arcfour-hmac)
 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(arcfour-hmac)
 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(arcfour-hmac)
 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA (arcfour-hmac)
 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA (arcfour-hmac)
 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(arcfour-hmac)
 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 4 04/04/2016 16:29:08 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
 4 04/04/2016 16:29:09 host/mw-sqproxy-test at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 4 04/04/2016 16:29:09 host/mw-sqproxy-test at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(arcfour-hmac)
 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96)
 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA
(aes128-cts-hmac-sha1-96)
 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA
(aes256-cts-hmac-sha1-96) 

 </snip> 

I'm using the fqdn in IE to authenticate with kerberos, if i change it
to IP it only tries NTLM, which i'm assuming is correct or not? 

I've investigated the PC's and all of them have properly joined the
domain. 

I've checked and i'm getting kvno 3 values from a working win2008r2 as
well as kvno 3 values from other pc's but yet, they have a popup asking
auth details. 
-- 

Drikus Brits 

 

Links:
------
[1] FILE:/var/log/kadmind.log
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/a9af4fbb/attachment.htm>

From drikus at geocastsp.co.za  Tue Apr  5 14:01:27 2016
From: drikus at geocastsp.co.za (Drikus Brits)
Date: Tue, 05 Apr 2016 16:01:27 +0200
Subject: [squid-users] Kerberos authentication only working with 1
 domain server
In-Reply-To: <b4b1da51a97d924d6188ad24c7066d3c@webmail.die-britsies.co.za>
References: <b4b1da51a97d924d6188ad24c7066d3c@webmail.die-britsies.co.za>
Message-ID: <5375edc8c98de0866c193d007199d9df@webmail.die-britsies.co.za>

 

Extra info : 

root at mw-sqproxy-test:/home/geosupport# uname -a
Linux mw-sqproxy-test 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul
24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux 

root at mw-sqproxy-test:/home/geosupport# squid3 -v
Squid Cache: Version 3.3.8
Ubuntu
configure options: '--build=x86_64-linux-gnu' '--prefix=/usr'
'--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
'--infodir=${prefix}/share/info' '--sysconfdir=/etc'
'--localstatedir=/var' '--libexecdir=${prefix}/lib/squid3' '--srcdir=.'
'--disable-maintainer-mode' '--disable-dependency-tracking'
'--disable-silent-rules' '--datadir=/usr/share/squid3'
'--sysconfdir=/etc/squid3' '--mandir=/usr/share/man' '--enable-inline'
'--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock'
'--enable-removal-policies=lru,heap' '--enable-delay-pools'
'--enable-cache-digests' '--enable-underscores' '--enable-icap-client'
'--enable-follow-x-forwarded-for'
'--enable-auth-basic=DB,fake,getpwnam,LDAP,MSNT,MSNT-multi-domain,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'
'--enable-auth-digest=file,LDAP'
'--enable-auth-negotiate=kerberos,wrapper'
'--enable-auth-ntlm=fake,smb_lm'
'--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group'
'--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi'
'--enable-icmp' '--enable-zph-qos' '--enable-ecap'
'--disable-translation' '--with-swapdir=/var/spool/squid3'
'--with-logdir=/var/log/squid3' '--with-pidfile=/var/run/squid3.pid'
'--with-filedescriptors=65536' '--with-large-files'
'--with-default-user=proxy' '--enable-linux-netfilter'
'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -fPIE -fstack-protector
--param=ssp-buffer-size=4 -Wformat -Werror=format-security -Wall'
'LDFLAGS=-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now'
'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector
--param=ssp-buffer-size=4 -Wformat -Werror=format-security'
root at mw-sqproxy-test:/home/geosupport# 

Thanks, 

Drikus 

On 2016-04-05 15:50, Drikus Brits wrote: 

> Hi Experts, 
> 
> After much struggling it seems i've reached some point of success but yet still not. I've checked a multitude of websites for help before coming here, but didn't get anything valuable yet. My problem as follows : 
> 
> I have 1x win2008R2 server that works with kerberos authentication, but none of the other PC's in the network wants to work, the others all come up with a login challenge/ 
> 
> My Configs : 
> 
> /etc/krb5.conf 
> 
> <snip>
> #cat /etc/krb5.conf
> [logging]
> 
> default = FILE:/var/log/krb5libs.log
> kdc = FILE:/var/log/krb5kdc.log
> admin_server = FILE:/var/log/kadmind.log [1]
> 
> [libdefaults]
> default_realm = DOMAIN.CO.ZA
> dns_lookup_kdc = yes
> dns_lookup_realm = yes
> ticket_lifetime = 24h
> default_keytab_name = /etc/squid/PROXY.keytab
> 
> #; for Windows 2008 with AES
> default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
> default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
> permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
> 
> [realms]
> 
> DOMAIN.CO.ZA = {
> kdc = mw-ad.domain.co.za
> admin_server = mw-ad.domain.co.za
> default_domain = domain.co.za
> }
> 
> [domain_realm]
> 
> .domain.co.za = DOMAIN.CO.ZA
> domain.co.za = DOMAIN.CO.ZA
> 
> [login]
> krb4_convert = true
> krb4_get_tickets = false
> </snip> 
> 
> my /etc/squid/squid.conf 
> 
> <snip>
> #auth_param negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=gss-spnego --domain=DOMAIN --kerberos /usr/lib/squid3/negotiate_kerberos_auth -d -i ###WORKING - half/half
> auth_param negotiate program /usr/lib/squid3/negotiate_wrapper_auth -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=DOMAIN.CO.ZA --kerberos /usr/lib/squid3/negotiate_kerberos_auth -d -s GSS_C_NO_NAME
> #auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -d -s GSS_C_NO_NAME
> 
> auth_param ntlm program /usr/bin/ntlm_auth --diagnostics --helper-protocol=gss-spnego --domain=DOMAIN.CO.ZA
> auth_param ntlm children 10
> auth_param ntlm keep_alive off
> 
> auth_param basic program /usr/lib/squid3/basic_ldap_auth -b "DC=domain,DC=co,DC=za" -f sAMAccountName=%s -D "CN=Folder Authentication,CN=Users,DC=domain,DC=co,DC=za" -w P at 55w0rd -H ldap://MW-AD.domain.co.za -R
> auth_param basic realm Web-Proxy
> auth_param basic credentialsttl 1 minute
> 
> acl proxy-auth proxy_auth REQUIRED
> 
> http_access allow proxy-auth
> </snip> 
> 
> When the Win2008R2 connectes is get the following in /var/log/squid3/cache.log 
> 
> <snip> 
> 
> 2016/04/05 12:26:46| negotiate_wrapper: Got 'YR YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBgkqhkiC9xIBAgIGCSq<truncated>DVzSeCUH4ntF1lHc=' from squid (length: 2419).
> 2016/04/05 12:26:46| negotiate_wrapper: Decode 'YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBg<truncated>UnIKhxWxh52aDVzSeCUH4ntF1lHc=' (decoded length: 1811).
> 2016/04/05 12:26:46| negotiate_wrapper: received Kerberos token
> negotiate_kerberos_auth.cc(315): pid=8218 :2016/04/05 12:26:46| negotiate_kerberos_auth: DEBUG: Got 'YR YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuB<truncated>JDp51PN7RjUnIKhxWxh52aDVzSeCUH4ntF1lHc=' from squid (length: 2419).
> negotiate_kerberos_auth.cc(378): pid=8218 :2016/04/05 12:26:46| negotiate_kerberos_auth: DEBUG: Decode 'YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBgkqhkiC9xI<truncated>51PN7RjUnIKhxWxh52aDVzSeCUH4ntF1lHc=' (decoded length: 1811).
> 2016/04/05 12:26:46| negotiate_wrapper: Return 'AF oYG2MIGzoAMKAQChCwYJ<truncated>ZuxzWyWJhUSZttUH70Vw595AsuKtUWvtGjGC7vGmD5Ugufw= Administrator at DOMAIN.CO.ZA 
> 
> </snip> 
> 
> But when other PC's connect of which another win2008R2 or win10 or win7 i get : 
> 
> <snip> 
> 
> negotiate_kerberos_auth.cc(315): pid=9389 :2016/04/05 12:33:47| negotiate_kerberos_auth: DEBUG: Got 'YR YIIHDwYGKwYBBQUCoII<truncated>+BnGBajMprtChSPMuUX9nnZfT+cJk=' from squid (length: 2419).
> negotiate_kerberos_auth.cc(378): pid=9389 :2016/04/05 12:33:47| negotiate_kerberos_auth: DEBUG: Decode 'YIIHDwYGKwYBBQUCoIIHAzCCBv<truncated>MprtChSPMuUX9nnZfT+cJk=' (decoded length: 1811).
> negotiate_kerberos_auth.cc(200): pid=9389 :2016/04/05 12:33:47| negotiate_kerberos_auth: ERROR: gss_accept_sec_context() failed: Unspecified GSS failure. Minor code may provide more information.
> 2016/04/05 12:33:47| ERROR: Negotiate Authentication validating user. Error returned 'BH gss_accept_sec_context() failed: Unspecified GSS failure. Minor code may provide more information. ' 
> 
> </snip> 
> 
> My kinit -V -kt /etc/squid3/PROXY.keytab , of which i'm sure if not supposed to say that :). I've had others that had Successfully authenticated to Kerberos V5 as well, but then the working win2008r2 doesn't work -- see below.. 
> 
> <snip> 
> 
> # kinit -V -kt /etc/squid3/PROXY.keytab
> Using default cache: /tmp/krb5cc_0
> Using principal: host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
> Using keytab: /etc/squid3/PROXY.keytab
> kinit: Preauthentication failed while getting initial credentials 
> 
> </snip> 
> 
> working with "authenticated with kerberos but no srv or pc working 
> 
> <snip> 
> 
> msktutil -c -b "CN=COMPUTERS" -s HTTP/mw-sqproxy-test -s HTTP/mw-sqproxy-test.domain.co.za -h mw-sqproxy-test.domain.co.za -k /etc/squid3/PROXY.keytab --computer-name MWSQPROXYTEST --upn HOST/mw-sqproxy-test.domain.co.za --server mw-ad.domain.co.za --verbose --enctypes 28 
> 
> </snip> 
> 
> my working klist entries 
> 
> <snip> 
> 
> klist -ekt /etc/squid3/PROXY.keytab 
> 
> Keytab name: FILE:/etc/squid3/PROXY.keytab
> KVNO Timestamp Principal
> ---- ------------------- ------------------------------------------------------
> 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA (arcfour-hmac)
> 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
> 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
> 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (arcfour-hmac)
> 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (arcfour-hmac)
> 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA (arcfour-hmac)
> 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA (arcfour-hmac)
> 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (arcfour-hmac)
> 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 4 04/04/2016 16:29:08 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
> 4 04/04/2016 16:29:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 4 04/04/2016 16:29:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (arcfour-hmac)
> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
> 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
> 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
> 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
> 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
> 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96) 
> 
> </snip> 
> 
> I'm using the fqdn in IE to authenticate with kerberos, if i change it to IP it only tries NTLM, which i'm assuming is correct or not? 
> 
> I've investigated the PC's and all of them have properly joined the domain. 
> 
> I've checked and i'm getting kvno 3 values from a working win2008r2 as well as kvno 3 values from other pc's but yet, they have a popup asking auth details. 
> -- 
> 
> Drikus Brits 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users [2]
 

Links:
------
[1] FILE:/var/log/kadmind.log
[2] http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/87beda5b/attachment.htm>

From drikus at geocastsp.co.za  Tue Apr  5 15:27:33 2016
From: drikus at geocastsp.co.za (Drikus Brits)
Date: Tue, 05 Apr 2016 17:27:33 +0200
Subject: [squid-users] Kerberos authentication only working with 1
 domain server
In-Reply-To: <5375edc8c98de0866c193d007199d9df@webmail.die-britsies.co.za>
References: <b4b1da51a97d924d6188ad24c7066d3c@webmail.die-britsies.co.za>
 <5375edc8c98de0866c193d007199d9df@webmail.die-britsies.co.za>
Message-ID: <0c2162e96fdaec9803d4b7ee9be80675@webmail.die-britsies.co.za>

 

i believe i might have fixed it.... 

will advise soonest. 

On 2016-04-05 16:01, Drikus Brits wrote: 

> Extra info : 
> 
> root at mw-sqproxy-test:/home/geosupport# uname -a
> Linux mw-sqproxy-test 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux 
> 
> root at mw-sqproxy-test:/home/geosupport# squid3 -v
> Squid Cache: Version 3.3.8
> Ubuntu
> configure options: '--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=${prefix}/lib/squid3' '--srcdir=.' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--datadir=/usr/share/squid3' '--sysconfdir=/etc/squid3' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth-basic=DB,fake,getpwnam,LDAP,MSNT,MSNT-multi-domain,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB' '--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper' '--enable-auth-ntlm=fake,smb_lm' '--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group'
'--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi' '--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-translation' '--with-swapdir=/var/spool/squid3' '--with-logdir=/var/log/squid3' '--with-pidfile=/var/run/squid3.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -Wall' 'LDFLAGS=-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security'
> root at mw-sqproxy-test:/home/geosupport# 
> 
> Thanks, 
> 
> Drikus 
> 
> On 2016-04-05 15:50, Drikus Brits wrote: 
> 
>> Hi Experts, 
>> 
>> After much struggling it seems i've reached some point of success but yet still not. I've checked a multitude of websites for help before coming here, but didn't get anything valuable yet. My problem as follows : 
>> 
>> I have 1x win2008R2 server that works with kerberos authentication, but none of the other PC's in the network wants to work, the others all come up with a login challenge/ 
>> 
>> My Configs : 
>> 
>> /etc/krb5.conf 
>> 
>> <snip>
>> #cat /etc/krb5.conf
>> [logging]
>> 
>> default = FILE:/var/log/krb5libs.log
>> kdc = FILE:/var/log/krb5kdc.log
>> admin_server = FILE:/var/log/kadmind.log [1]
>> 
>> [libdefaults]
>> default_realm = DOMAIN.CO.ZA
>> dns_lookup_kdc = yes
>> dns_lookup_realm = yes
>> ticket_lifetime = 24h
>> default_keytab_name = /etc/squid/PROXY.keytab
>> 
>> #; for Windows 2008 with AES
>> default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
>> default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
>> permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
>> 
>> [realms]
>> 
>> DOMAIN.CO.ZA = {
>> kdc = mw-ad.domain.co.za
>> admin_server = mw-ad.domain.co.za
>> default_domain = domain.co.za
>> }
>> 
>> [domain_realm]
>> 
>> .domain.co.za = DOMAIN.CO.ZA
>> domain.co.za = DOMAIN.CO.ZA
>> 
>> [login]
>> krb4_convert = true
>> krb4_get_tickets = false
>> </snip> 
>> 
>> my /etc/squid/squid.conf 
>> 
>> <snip>
>> #auth_param negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=gss-spnego --domain=DOMAIN --kerberos /usr/lib/squid3/negotiate_kerberos_auth -d -i ###WORKING - half/half
>> auth_param negotiate program /usr/lib/squid3/negotiate_wrapper_auth -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=DOMAIN.CO.ZA --kerberos /usr/lib/squid3/negotiate_kerberos_auth -d -s GSS_C_NO_NAME
>> #auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -d -s GSS_C_NO_NAME
>> 
>> auth_param ntlm program /usr/bin/ntlm_auth --diagnostics --helper-protocol=gss-spnego --domain=DOMAIN.CO.ZA
>> auth_param ntlm children 10
>> auth_param ntlm keep_alive off
>> 
>> auth_param basic program /usr/lib/squid3/basic_ldap_auth -b "DC=domain,DC=co,DC=za" -f sAMAccountName=%s -D "CN=Folder Authentication,CN=Users,DC=domain,DC=co,DC=za" -w P at 55w0rd -H ldap://MW-AD.domain.co.za -R
>> auth_param basic realm Web-Proxy
>> auth_param basic credentialsttl 1 minute
>> 
>> acl proxy-auth proxy_auth REQUIRED
>> 
>> http_access allow proxy-auth
>> </snip> 
>> 
>> When the Win2008R2 connectes is get the following in /var/log/squid3/cache.log 
>> 
>> <snip> 
>> 
>> 2016/04/05 12:26:46| negotiate_wrapper: Got 'YR YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBgkqhkiC9xIBAgIGCSq<truncated>DVzSeCUH4ntF1lHc=' from squid (length: 2419).
>> 2016/04/05 12:26:46| negotiate_wrapper: Decode 'YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBg<truncated>UnIKhxWxh52aDVzSeCUH4ntF1lHc=' (decoded length: 1811).
>> 2016/04/05 12:26:46| negotiate_wrapper: received Kerberos token
>> negotiate_kerberos_auth.cc(315): pid=8218 :2016/04/05 12:26:46| negotiate_kerberos_auth: DEBUG: Got 'YR YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuB<truncated>JDp51PN7RjUnIKhxWxh52aDVzSeCUH4ntF1lHc=' from squid (length: 2419).
>> negotiate_kerberos_auth.cc(378): pid=8218 :2016/04/05 12:26:46| negotiate_kerberos_auth: DEBUG: Decode 'YIIHDwYGKwYBBQUCoIIHAzCCBv+gMDAuBgkqhkiC9xI<truncated>51PN7RjUnIKhxWxh52aDVzSeCUH4ntF1lHc=' (decoded length: 1811).
>> 2016/04/05 12:26:46| negotiate_wrapper: Return 'AF oYG2MIGzoAMKAQChCwYJ<truncated>ZuxzWyWJhUSZttUH70Vw595AsuKtUWvtGjGC7vGmD5Ugufw= Administrator at DOMAIN.CO.ZA 
>> 
>> </snip> 
>> 
>> But when other PC's connect of which another win2008R2 or win10 or win7 i get : 
>> 
>> <snip> 
>> 
>> negotiate_kerberos_auth.cc(315): pid=9389 :2016/04/05 12:33:47| negotiate_kerberos_auth: DEBUG: Got 'YR YIIHDwYGKwYBBQUCoII<truncated>+BnGBajMprtChSPMuUX9nnZfT+cJk=' from squid (length: 2419).
>> negotiate_kerberos_auth.cc(378): pid=9389 :2016/04/05 12:33:47| negotiate_kerberos_auth: DEBUG: Decode 'YIIHDwYGKwYBBQUCoIIHAzCCBv<truncated>MprtChSPMuUX9nnZfT+cJk=' (decoded length: 1811).
>> negotiate_kerberos_auth.cc(200): pid=9389 :2016/04/05 12:33:47| negotiate_kerberos_auth: ERROR: gss_accept_sec_context() failed: Unspecified GSS failure. Minor code may provide more information.
>> 2016/04/05 12:33:47| ERROR: Negotiate Authentication validating user. Error returned 'BH gss_accept_sec_context() failed: Unspecified GSS failure. Minor code may provide more information. ' 
>> 
>> </snip> 
>> 
>> My kinit -V -kt /etc/squid3/PROXY.keytab , of which i'm sure if not supposed to say that :). I've had others that had Successfully authenticated to Kerberos V5 as well, but then the working win2008r2 doesn't work -- see below.. 
>> 
>> <snip> 
>> 
>> # kinit -V -kt /etc/squid3/PROXY.keytab
>> Using default cache: /tmp/krb5cc_0
>> Using principal: host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA
>> Using keytab: /etc/squid3/PROXY.keytab
>> kinit: Preauthentication failed while getting initial credentials 
>> 
>> </snip> 
>> 
>> working with "authenticated with kerberos but no srv or pc working 
>> 
>> <snip> 
>> 
>> msktutil -c -b "CN=COMPUTERS" -s HTTP/mw-sqproxy-test -s HTTP/mw-sqproxy-test.domain.co.za -h mw-sqproxy-test.domain.co.za -k /etc/squid3/PROXY.keytab --computer-name MWSQPROXYTEST --upn HOST/mw-sqproxy-test.domain.co.za --server mw-ad.domain.co.za --verbose --enctypes 28 
>> 
>> </snip> 
>> 
>> my working klist entries 
>> 
>> <snip> 
>> 
>> klist -ekt /etc/squid3/PROXY.keytab 
>> 
>> Keytab name: FILE:/etc/squid3/PROXY.keytab
>> KVNO Timestamp Principal
>> ---- ------------------- ------------------------------------------------------
>> 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA (arcfour-hmac)
>> 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 2 04/04/2016 11:43:43 MW-SQPROXY-TEST$@DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
>> 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 2 05/04/2016 09:50:05 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
>> 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 2 05/04/2016 09:43:05 HOST/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (arcfour-hmac)
>> 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 2 05/04/2016 09:43:06 HOST/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (arcfour-hmac)
>> 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 2 05/04/2016 09:50:06 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA (arcfour-hmac)
>> 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 2 05/04/2016 09:50:05 MWSQPROXYTEST$@DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA (arcfour-hmac)
>> 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 3 05/04/2016 10:15:33 MWSQPROXYTEST$@DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (arcfour-hmac)
>> 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 3 05/04/2016 10:15:33 host/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 4 04/04/2016 16:29:08 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
>> 4 04/04/2016 16:29:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 4 04/04/2016 16:29:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
>> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (arcfour-hmac)
>> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 3 05/04/2016 10:15:33 HTTP/mw-sqproxy-test.domain.co.za at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
>> 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 5 04/04/2016 19:19:28 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
>> 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 6 04/04/2016 19:22:47 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96)
>> 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (arcfour-hmac)
>> 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes128-cts-hmac-sha1-96)
>> 7 04/04/2016 20:40:09 host/mw-sqproxy-test at DOMAIN.CO.ZA (aes256-cts-hmac-sha1-96) 
>> 
>> </snip> 
>> 
>> I'm using the fqdn in IE to authenticate with kerberos, if i change it to IP it only tries NTLM, which i'm assuming is correct or not? 
>> 
>> I've investigated the PC's and all of them have properly joined the domain. 
>> 
>> I've checked and i'm getting kvno 3 values from a working win2008r2 as well as kvno 3 values from other pc's but yet, they have a popup asking auth details. 
>> -- 
>> 
>> Drikus Brits 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users [2]
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users [2]
 

Links:
------
[1] FILE:/var/log/kadmind.log
[2] http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/1938f42d/attachment.htm>

From jok at spikes.com  Tue Apr  5 18:50:13 2016
From: jok at spikes.com (Jok Thuau)
Date: Tue, 5 Apr 2016 11:50:13 -0700
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <57031390.8020604@treenet.co.nz>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
 <57031390.8020604@treenet.co.nz>
Message-ID: <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>

On Mon, Apr 4, 2016 at 6:23 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> >>>
> >>> If i remove *all* the http_access lines, then the behavior appears
> >> correct
> >>> (from a "splicing/bumping" standpoint).
> >>>
> >>
> >> Strange. Squid without any http_access lines should be denying traffic
> >> 100%.
> >>
> >>
> > I do not see this behavior. Traffic appears to be allowed, and bumped
> > (though with the wrong certificate, depending on the config, as explained
> > before).
> >
> >
>




> >
> > my apologies for trying to show only the relevant parts. Find below the
> > current config.
> > It appears to be bumping everything rather than splicing any of the
> config
> > (which may be due to the limitations documented on the wiki)
> >
> > acl Safe_ports port 80 # http
> > acl Safe_ports port 443 # https
> > acl SSL_ports port 443
> > acl CONNECT method CONNECT
> > http_port 3129 intercept
> > https_port 8443 intercept ssl-bump generate-host-certificates=on
> > dynamic_cert_mem_cache_size=64MB \
> >     cert=/etc/squid/ssl/proxy.pem \
> >     key=/etc/squid/ssl/proxy.key \
> >     cafile=/etc/squid/ssl/proxy.pem
> > always_direct allow all
>
> always_direct has not been necessary with SSL-Bump sice 3.1 series. You
> should remove it.
>
> > acl step1 at_step SslBump1
> > acl step2 at_step SslBump2
> > acl step3 at_step SslBump3
> > acl SniBypass ssl::server_name_regex \.slashdot\.org
> > acl SniBypass ssl::server_name_regex \.fsdn\.com
>

I have moved those "SniBypass" acl into a separate files and replaced this
with an include, as that list will end up growing.


> > acl http_bypass dstdomain .slashdot.org
> > acl http_bypass dstdomain .fsdn.com


and similarly here, replaced by an include...


>
> > acl https_bypass all-of CONNECT SniBypass
>
> This https_bypass ACL definition is a bit weird. It requires a single
> message to match both TLS and HTTP properties simultaneously.


> As you might imagine it is difficult for a TLS messages to match HTTP
> properties, and vice versa. So it wont ever match.
>
>
I don't understand. SniBypass is based on ssl::server_name_regex which
shouldn't apply to http at all...
Would that not be coming from the (client|server)Hello?


> Note: SNI is *not* equivalent to Host or URL domain name. They can
> contain very different values. The only thing they have in common is
> that they both are supposed to point at the IP of the server being
> contacted.
>
>
> > acl http_ok all-of http_bypass Safe_ports
> > ssl_bump peek step1
> > ssl_bump splice SniBypass step2
>
> This splice will work if (and only if) the client sends TLS SNI values
> to Squid. It will ignore the server cert details.
>
> For clients which do not send SNI or for all connections where the SNI
> does not match your ACL the bump rule below will do client-first bumping
> (without the server cert).
>
> > ssl_bump bump all
>
> I suggets you try these ssl_bump rules instead:
> [snip]

 OK

> [snip]
> Okay. That sort of matches your policy. Except that you are missing the
> security defaults. Those lines are carefully tuned for the specific
> behaviour to protect against security attacks:
>
>  http_access deny !Safe_ports
>  http_access deny CONNECT !SSL_ports
>
> .. and should be above your custom rules.
>

I added those at the top as requested...


>  cache allow all
>  cache deny all
>
> ... pick one.
>
>
done - the deny one is the one left in there now.

>
> > shutdown_lifetime 3 seconds
>

for clarification, I also moved the two sets of ACLs into separate files,
as those will eventually be maintained externally (SniBypass and
http_bypass).

The config file is now:

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_port 3128
http_port 3129 intercept
https_port 8443 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=64MB \
    cert=/etc/squid/ssl/proxy.pem \
    key=/etc/squid/ssl/proxy.key \
    cafile=/etc/squid/ssl/proxy.pem
workers 6
always_direct allow all
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
include "/etc/squid/snibypass.acl"
include "/etc/squid/dstbypass.acl"
acl https_ok all-of CONNECT SniBypass
acl http_ok all-of http_bypass Safe_ports
ssl_bump splice SniBypass
ssl_bump peek step1
ssl_bump stare step2
ssl_bump bump all
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
sslproxy_cert_sign_hash sha256
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1
http_access allow http_ok
http_access allow https_ok
http_access deny all
cache deny all
shutdown_lifetime 3 seconds

Note that with that config, the http_access deny all (couple lines before
the end) appears to deny the TLS/SSL connection before the ssl_bump steps
have a chance to match, so i get certs that are not mimic'ed (they have
CN=<ip>). If i remove all 3 http_access at the end, then the
splicing/bumping behavior appears to work as expected, but then i'm not
denying anything...

that seems to confirm my suspicion that the access control (http_access)
apply too early for me to match anything related to the ssl::server_name or
ssl::server_name_regex.

I keep thinking that what i'm missing is that the http_access applies too
early. I played with "terminate" instead of "bump" at the last ssl_bump
command, but i really need the error message. I keep wanting to have
something like this:

ssl_bump splice SniBypass
ssl_bump peek step1
ssl_bump stare step2
ssl_bump deny all

where the last one would effectively bump the connection, and provide the
ERR_ACCESS_DENIED page.

Thank you so much for your help.
Jok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/398932fe/attachment.htm>

From rousskov at measurement-factory.com  Tue Apr  5 21:05:57 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 5 Apr 2016 15:05:57 -0600
Subject: [squid-users] how to use squid as a tcp forward proxy?
In-Reply-To: <7c750b4d.93ae.153e5671728.Coremail.phafer@163.com>
References: <7c750b4d.93ae.153e5671728.Coremail.phafer@163.com>
Message-ID: <570428B5.8060007@measurement-factory.com>

On 04/05/2016 01:50 AM, phafer wrote:

> how can I extend squid to process/modify payload of my private
> application protocol basing on TCP?

You probably should not -- Squid is not designed to be a TCP proxy and
there ought to be better/true TCP proxies out there.


> Client->squid->my squid plugin which is used to process/modify payload
> of tcp traffic->Server

If you insist on modifying Squid, you can try to do what Native FTP code
in Squid does today:

1. Accept traffic from FTP clients at ftp_port.
2. Convert FTP traffic into fake HTTP messages.
3. General Squid code, including eCAP/ICAP, handles those HTTP messages.
4. Convert fake HTTP messages back into FTP traffic sent to FTP servers.

Doing so requires lots of complicated development, but should give you
what you want at the end. Standard eCAP/ICAP "plugin" interfaces can
then be used for message adaptation:
http://wiki.squid-cache.org/SquidFaq/ContentAdaptation


Again, most likely, Squid is the wrong solution for your problem.


HTH,

Alex.


From Tommy.Craddock at bicgraphic.com  Tue Apr  5 21:16:23 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Tue, 5 Apr 2016 21:16:23 +0000
Subject: [squid-users] External ACL Lookup
Message-ID: <CA86A9283AA07E478F6B0629521FFEE734B879@CLWSEXCMBX02.na.bicworld.com>

Hello,

Trying to use an external ACL helper to do a lookup of my user in a group in a Windows AD.  I can test from the command line:


/usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com -W /etc/squid/password -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com
tcraddock at EXAMPLE.COM Full.Access
OK


In the cache.log w/debug set to ALL,3:

2016/04/05 16:54:39.768| aclMatchExternal: memberof user not authenticated (0)
GETTING KERB TOKEN.....
...
2016/04/05 16:54:39.780| authenticateAuthUserAddIp: user 'tcraddock at EXAMPLE.COM' has been seen at a new IP address (172.23.5.193:56059)
2016/04/05 16:54:39.780| aclMatchExternal: memberof("tcraddock at EXAMPLE.COM Full.Access") = lookup needed
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": entry=@0, age=0
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": queueing a call.
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": return -1.
2016/04/05 16:54:39.780| externalAclLookup: lookup in 'memberof' for 'tcraddock at EXAMPLE.COM Full.Access'
2016/04/05 16:54:39.784| externalAclHandleReply: reply="ERR"
2016/04/05 16:54:39.785| external_acl_cache_add: Adding 'tcraddock at EXAMPLE.COM Full.Access' = 0
2016/04/05 16:54:39.785| aclMatchExternal: memberof = 0

In the file referenced in the ACLs:

acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
acl FullAccess          external memberof "/etc/squid/full_access.txt"


it has:

cat /etc/squid/full_access.txt
Full.Access

cat /etc/squid/restricted_access.txt
Restricted.Access

Im not sure why the logs show my user is getting ERR as the response to group checking, when I run it from the command line, I get an OK.


Info about my setup:

[root at clwslprox01p squid]# squid -v
Squid Cache: Version 3.1.23
configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--enable-internal-dns' '--disable-strict-error-checking' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-arp-acl' '--enable-follow-x-forwarded-for' '--enable-auth=basic,digest,ntlm,negotiate' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL,DB,POP3,squid_radius_auth' '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' '--enable-digest-auth-helpers=password,ldap,eDirectory' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-referer-log' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' '--enable-http-violations' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' --with-squid=/builddir/build/BUILD/squid-3.1.23

[root at clwslprox01p squid]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)

Using negotiate w/NTLM and Kerberos to do user auth, and trying to use external helpers to do group lookups to a Windows AD.  Windows AD is 2008 and 2012 in my env.

Squid.conf:


### cache manager
cache_mgr pclan at example.com

#Define the cache_peer to be used
# cache_peer proxy1.ap.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest
  cache_peer proxy1.us.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.hk.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest


### negotiate kerberos and ntlm authentication
auth_param negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=EXAMPLE.COM --require-membership-of=EXAMPLE\\Full.Access -kerberos /usr/lib64/squid/squid_kerb_auth -d -s GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive off

### pure ntlm authentication
auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --require-membership-of=EXAMPLE\\Full.Access
auth_param ntlm children 30
auth_param ntlm keep_alive off

### provide basic authentication via ldap for clients not authenticated via kerberos/ntlm
auth_param basic program /usr/lib64/squid/squid_ldap_auth -R -b "dc=example,dc=com" -D Squid at EXAMPLE.COM -W /etc/squid/password -f sAMAccountName=%s -h DC01.EXAMPLE.COM
auth_param basic children 10
auth_param basic realm Internet Proxy
auth_param basic credentialsttl 1 minute

### ldap authorisation
external_acl_type memberof %LOGIN /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at EXAMPLE.COM -W /etc/squid/.ldappass.txt -f "(&(objectclass=person)(sAMAccountName=$)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h DC01.EXAMPLE.COM

### acl for proxy auth and ldap authorizations
acl our_networks src  172.16.0.0/12 10.0.0.0/8 192.170.0.0/24
acl INTERNAL dst 172.16.0.0/12 10.0.0.0/8
acl auth proxy_auth REQUIRED
acl HEAD method HEAD
acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
acl FullAccess          external memberof "/etc/squid/full_access.txt"
acl Approved_Domains dstdomain "/etc/squid/acls/approved.txt"
acl WindowsUpdate dstdomain -i "/etc/squid/acls/windowsupdates.txt"
acl local-servers dstdomain "/etc/squid/acls/localservers.txt"
acl RestrictedHost src "/etc/squid/acls/restrictedhost_ip.txt"
acl bypass_auth src "/etc/squid/acls/bypass_auth_src_ip.txt"
acl bypass_auth-external dstdomain "/etc/squid/acls/bypass_auth_dst_domain.txt"
acl blocksites dstdomain "/etc/squid/acls/block_sites.txt"
acl DIRECT src "/etc/squid/acls/direct_src_ip.txt"
acl DIRECT-external dstdomain "/etc/squid/acls/direct_dst_domains.txt"
acl Smartconnect dstdomain ned.webscanningservice.com
acl Java browser Java/[0-9]
acl JavaSites dstdomain .gotomeeting.com
always_direct allow INTERNAL
always_direct allow local-servers
cache deny INTERNAL
cache deny local-servers



### squid defaults
acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
acl SSL_ports port 443 563 33808
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443 563     # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
#allow custom ports
acl goto_meeting dst 216.115.208.0/20 216.219.112.0/20 66.151.158.0/24 66.151.150.160/27 66.151.115.128/26 64.74.80.0/24 202.173.24.0/21 67.217.64.0/19 78.108.112.0/20 68.64.0.0/19 206.183.100.0/22
acl Safe_ports port 8200        # gotomeeting
acl Safe_ports port 31303 33808 # TD Merchant
acl Safe_ports port 8443        # Symantec SEP Manager
acl Safe_ports port 8014               # Symantec SEPM Client
acl SSL_ports port 9443         # pingdevfed
acl SSL_ports port 9444         # pingdevfed
acl SSL_ports port 5443         # pingdev
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
#http_access deny !memberof
http_access allow localhost
http_access allow HEAD
http_access deny !our_networks
http_access allow Smartconnect
http_access deny blocksites all
http_access allow Approved_Domains
http_access deny RestrictedHost all
http_access allow FullAccess auth
http_access allow Java
http_access allow WindowsUpdate
http_access allow bypass_auth
http_access allow bypass_auth-external
http_access allow goto_meeting
http_access allow our_networks all
http_access allow Java our_networks JavaSites
http_access allow auth
http_access deny !auth
http_access deny all


deny_info error-blocksites blocksites

#Logs to look like apache
emulate_httpd_log on

#Level of Log debugging
debug_options ALL,1

#Log file locations
cache_log /var/log/squid/cache.log
access_log /var/log/squid/access.log
useragent_log /var/log/squid/useragent.log

#Hostname shown in error pages
visible_hostname proxy01p
http_port 3128
hierarchy_stoplist cgi-bin ?
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320




CONFIDENTIALITY NOTICE
This electronic message is confidential and may contain legally privileged information intended only for the use of the individual or company named above.
If the reader of this message is not the intended recipient, or the employee or agent responsible to deliver it to the intended recipient, you are hereby notified
that any dissemination, distribution or copying of this communications is strictly prohibited. If you have received this communication in error, please immediately
notify us by telephone, and return the original message to us at the address above


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/ec8e4290/attachment.htm>

From rafael.akchurin at diladele.com  Tue Apr  5 21:25:03 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 5 Apr 2016 21:25:03 +0000
Subject: [squid-users] External ACL Lookup
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE734B879@CLWSEXCMBX02.na.bicworld.com>
References: <CA86A9283AA07E478F6B0629521FFEE734B879@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <VI1PR04MB13594D930512E5F7AD1F98AE8F9E0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Tommy,

Just my two cents. Try using usePrincipalName, and not sAMAccountName in LDAP filter.
The squid logs indicate the user is authenticated as tcraddock at EXAMPLE.COM<mailto:tcraddock at EXAMPLE.COM> which is *not* in sAMAccountName for sure.

Best regards,
Rafael Akchurin
Diladele B.V.
http://www.quintolabs.com
http://www.diladele.com

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com.

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Craddock, Tommy
Sent: Tuesday, April 5, 2016 11:16 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] External ACL Lookup

Hello,

Trying to use an external ACL helper to do a lookup of my user in a group in a Windows AD.  I can test from the command line:


/usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com<mailto:Squid at example.com> -W /etc/squid/password -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com
tcraddock at EXAMPLE.COM<mailto:tcraddock at EXAMPLE.COM> Full.Access
OK


In the cache.log w/debug set to ALL,3:

2016/04/05 16:54:39.768| aclMatchExternal: memberof user not authenticated (0)
GETTING KERB TOKEN.....
...
2016/04/05 16:54:39.780| authenticateAuthUserAddIp: user 'tcraddock at EXAMPLE.COM' has been seen at a new IP address (172.23.5.193:56059)
2016/04/05 16:54:39.780| aclMatchExternal: memberof("tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>") = lookup needed
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": entry=@0, age=0
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": queueing a call.
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": return -1.
2016/04/05 16:54:39.780| externalAclLookup: lookup in 'memberof' for 'tcraddock at EXAMPLE.COM Full.Access'
2016/04/05 16:54:39.784| externalAclHandleReply: reply="ERR"
2016/04/05 16:54:39.785| external_acl_cache_add: Adding 'tcraddock at EXAMPLE.COM Full.Access' = 0
2016/04/05 16:54:39.785| aclMatchExternal: memberof = 0

In the file referenced in the ACLs:

acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
acl FullAccess          external memberof "/etc/squid/full_access.txt"


it has:

cat /etc/squid/full_access.txt
Full.Access

cat /etc/squid/restricted_access.txt
Restricted.Access

Im not sure why the logs show my user is getting ERR as the response to group checking, when I run it from the command line, I get an OK.


Info about my setup:

[root at clwslprox01p squid]# squid -v
Squid Cache: Version 3.1.23
configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--enable-internal-dns' '--disable-strict-error-checking' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-arp-acl' '--enable-follow-x-forwarded-for' '--enable-auth=basic,digest,ntlm,negotiate' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL,DB,POP3,squid_radius_auth' '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' '--enable-digest-auth-helpers=password,ldap,eDirectory' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-referer-log' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' '--enable-http-violations' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' --with-squid=/builddir/build/BUILD/squid-3.1.23

[root at clwslprox01p squid]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)

Using negotiate w/NTLM and Kerberos to do user auth, and trying to use external helpers to do group lookups to a Windows AD.  Windows AD is 2008 and 2012 in my env.

Squid.conf:


### cache manager
cache_mgr pclan at example.com<mailto:pclan at example.com>

#Define the cache_peer to be used
# cache_peer proxy1.ap.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest
  cache_peer proxy1.us.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.hk.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest


### negotiate kerberos and ntlm authentication
auth_param negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=EXAMPLE.COM --require-membership-of=EXAMPLE\\Full.Access -kerberos /usr/lib64/squid/squid_kerb_auth -d -s GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive off

### pure ntlm authentication
auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --require-membership-of=EXAMPLE\\Full.Access
auth_param ntlm children 30
auth_param ntlm keep_alive off

### provide basic authentication via ldap for clients not authenticated via kerberos/ntlm
auth_param basic program /usr/lib64/squid/squid_ldap_auth -R -b "dc=example,dc=com" -D Squid at EXAMPLE.COM<mailto:Squid at EXAMPLE.COM> -W /etc/squid/password -f sAMAccountName=%s -h DC01.EXAMPLE.COM
auth_param basic children 10
auth_param basic realm Internet Proxy
auth_param basic credentialsttl 1 minute

### ldap authorisation
external_acl_type memberof %LOGIN /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at EXAMPLE.COM<mailto:Squid at EXAMPLE.COM> -W /etc/squid/.ldappass.txt -f "(&(objectclass=person)(sAMAccountName=$)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h DC01.EXAMPLE.COM

### acl for proxy auth and ldap authorizations
acl our_networks src  172.16.0.0/12 10.0.0.0/8 192.170.0.0/24
acl INTERNAL dst 172.16.0.0/12 10.0.0.0/8
acl auth proxy_auth REQUIRED
acl HEAD method HEAD
acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
acl FullAccess          external memberof "/etc/squid/full_access.txt"
acl Approved_Domains dstdomain "/etc/squid/acls/approved.txt"
acl WindowsUpdate dstdomain -i "/etc/squid/acls/windowsupdates.txt"
acl local-servers dstdomain "/etc/squid/acls/localservers.txt"
acl RestrictedHost src "/etc/squid/acls/restrictedhost_ip.txt"
acl bypass_auth src "/etc/squid/acls/bypass_auth_src_ip.txt"
acl bypass_auth-external dstdomain "/etc/squid/acls/bypass_auth_dst_domain.txt"
acl blocksites dstdomain "/etc/squid/acls/block_sites.txt"
acl DIRECT src "/etc/squid/acls/direct_src_ip.txt"
acl DIRECT-external dstdomain "/etc/squid/acls/direct_dst_domains.txt"
acl Smartconnect dstdomain ned.webscanningservice.com
acl Java browser Java/[0-9]
acl JavaSites dstdomain .gotomeeting.com
always_direct allow INTERNAL
always_direct allow local-servers
cache deny INTERNAL
cache deny local-servers



### squid defaults
acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
acl SSL_ports port 443 563 33808
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443 563     # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
#allow custom ports
acl goto_meeting dst 216.115.208.0/20 216.219.112.0/20 66.151.158.0/24 66.151.150.160/27 66.151.115.128/26 64.74.80.0/24 202.173.24.0/21 67.217.64.0/19 78.108.112.0/20 68.64.0.0/19 206.183.100.0/22
acl Safe_ports port 8200        # gotomeeting
acl Safe_ports port 31303 33808 # TD Merchant
acl Safe_ports port 8443        # Symantec SEP Manager
acl Safe_ports port 8014               # Symantec SEPM Client
acl SSL_ports port 9443         # pingdevfed
acl SSL_ports port 9444         # pingdevfed
acl SSL_ports port 5443         # pingdev
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
#http_access deny !memberof
http_access allow localhost
http_access allow HEAD
http_access deny !our_networks
http_access allow Smartconnect
http_access deny blocksites all
http_access allow Approved_Domains
http_access deny RestrictedHost all
http_access allow FullAccess auth
http_access allow Java
http_access allow WindowsUpdate
http_access allow bypass_auth
http_access allow bypass_auth-external
http_access allow goto_meeting
http_access allow our_networks all
http_access allow Java our_networks JavaSites
http_access allow auth
http_access deny !auth
http_access deny all


deny_info error-blocksites blocksites

#Logs to look like apache
emulate_httpd_log on

#Level of Log debugging
debug_options ALL,1

#Log file locations
cache_log /var/log/squid/cache.log
access_log /var/log/squid/access.log
useragent_log /var/log/squid/useragent.log

#Hostname shown in error pages
visible_hostname proxy01p
http_port 3128
hierarchy_stoplist cgi-bin ?
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320




CONFIDENTIALITY NOTICE
This electronic message is confidential and may contain legally privileged information intended only for the use of the individual or company named above.
If the reader of this message is not the intended recipient, or the employee or agent responsible to deliver it to the intended recipient, you are hereby notified
that any dissemination, distribution or copying of this communications is strictly prohibited. If you have received this communication in error, please immediately
notify us by telephone, and return the original message to us at the address above


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/23841fee/attachment.htm>

From Tommy.Craddock at bicgraphic.com  Tue Apr  5 21:53:00 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Tue, 5 Apr 2016 21:53:00 +0000
Subject: [squid-users] External ACL Lookup
In-Reply-To: <VI1PR04MB13594D930512E5F7AD1F98AE8F9E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <CA86A9283AA07E478F6B0629521FFEE734B879@CLWSEXCMBX02.na.bicworld.com>
 <VI1PR04MB13594D930512E5F7AD1F98AE8F9E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE734B8A0@CLWSEXCMBX02.na.bicworld.com>

Rafael,

Thanks for your reply.   Substituting userPrincipalName for sAMAccountName in both the command line and squid.conf produces an ERR:

/usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com -W /etc/squid/password -f "(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com
tcraddock at EXAMPLE.COM Full.Access
ERR

cat /etc/squid/squid.conf | grep userPrin
external_acl_type memberof %LOGIN /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com -W /etc/squid/password -f "(&(objectclass=person)(userPrincipalName=$)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com

cache.log:

2016/04/05 17:45:24.190| authenticateAuthUserAddIp: user 'tcraddock at EXAMPLE.COM' has been seen at a new IP address (172.23.5.193:57445)
2016/04/05 17:45:24.190| aclMatchExternal: memberof("tcraddock at EXAMPLE.COM Full.Access") = lookup needed
2016/04/05 17:45:24.190| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": entry=@0, age=0
2016/04/05 17:45:24.190| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": queueing a call.
2016/04/05 17:45:24.190| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": return -1.
2016/04/05 17:45:24.190| externalAclLookup: lookup in 'memberof' for 'tcraddock at EXAMPLE.COM Full.Access'
2016/04/05 17:45:24.196| externalAclHandleReply: reply="ERR"
2016/04/05 17:45:24.196| external_acl_cache_add: Adding 'tcraddock at EXAMPLE.COM Full.Access' = 0
2016/04/05 17:45:24.196| aclMatchExternal: memberof = 0

 [cid:E16BB7E4-AAA7-4D07-803E-E39F6201D081]
Tommy E CRADDOCK JR
Systems Admin
BIC Advertising & Promotional Products
14421 Myer Lake Circle
Clearwater, FL  33760
727-507-3080
tommy.craddock at bicgraphic.com

www.bicgraphic.com<http://www.bicgraphic.com/>

[cid:37DF6999-C959-46F8-BA13-A4CFA37F691F]

CONFIDENTIALITY NOTICE
This electronic message is confidential and may contain legally privileged information intended only for the use of the individual or company named above.
If the reader of this message is not the intended recipient, or the employee or agent responsible to deliver it to the intended recipient, you are hereby notified
that any dissemination, distribution or copying of this communications is strictly prohibited. If you have received this communication in error, please immediately
notify us by telephone, and return the original message to us at the address above

From: Rafael Akchurin [mailto:rafael.akchurin at diladele.com]
Sent: Tuesday, April 05, 2016 5:25 PM
To: Craddock, Tommy; squid-users at lists.squid-cache.org
Subject: RE: External ACL Lookup

Hello Tommy,

Just my two cents. Try using usePrincipalName, and not sAMAccountName in LDAP filter.
The squid logs indicate the user is authenticated as tcraddock at EXAMPLE.COM<mailto:tcraddock at EXAMPLE.COM> which is *not* in sAMAccountName for sure.

Best regards,
Rafael Akchurin
Diladele B.V.
http://www.quintolabs.com
http://www.diladele.com

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com.

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Craddock, Tommy
Sent: Tuesday, April 5, 2016 11:16 PM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: [squid-users] External ACL Lookup

Hello,

Trying to use an external ACL helper to do a lookup of my user in a group in a Windows AD.  I can test from the command line:


/usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com<mailto:Squid at example.com> -W /etc/squid/password -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com
tcraddock at EXAMPLE.COM<mailto:tcraddock at EXAMPLE.COM> Full.Access
OK


In the cache.log w/debug set to ALL,3:

2016/04/05 16:54:39.768| aclMatchExternal: memberof user not authenticated (0)
GETTING KERB TOKEN.....
...
2016/04/05 16:54:39.780| authenticateAuthUserAddIp: user 'tcraddock at EXAMPLE.COM' has been seen at a new IP address (172.23.5.193:56059)
2016/04/05 16:54:39.780| aclMatchExternal: memberof("tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>") = lookup needed
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": entry=@0, age=0
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": queueing a call.
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": return -1.
2016/04/05 16:54:39.780| externalAclLookup: lookup in 'memberof' for 'tcraddock at EXAMPLE.COM Full.Access'
2016/04/05 16:54:39.784| externalAclHandleReply: reply="ERR"
2016/04/05 16:54:39.785| external_acl_cache_add: Adding 'tcraddock at EXAMPLE.COM Full.Access' = 0
2016/04/05 16:54:39.785| aclMatchExternal: memberof = 0

In the file referenced in the ACLs:

acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
acl FullAccess          external memberof "/etc/squid/full_access.txt"


it has:

cat /etc/squid/full_access.txt
Full.Access

cat /etc/squid/restricted_access.txt
Restricted.Access

Im not sure why the logs show my user is getting ERR as the response to group checking, when I run it from the command line, I get an OK.


Info about my setup:

[root at clwslprox01p squid]# squid -v
Squid Cache: Version 3.1.23
configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--enable-internal-dns' '--disable-strict-error-checking' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-arp-acl' '--enable-follow-x-forwarded-for' '--enable-auth=basic,digest,ntlm,negotiate' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL,DB,POP3,squid_radius_auth' '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' '--enable-digest-auth-helpers=password,ldap,eDirectory' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-referer-log' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' '--enable-http-violations' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' --with-squid=/builddir/build/BUILD/squid-3.1.23

[root at clwslprox01p squid]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)

Using negotiate w/NTLM and Kerberos to do user auth, and trying to use external helpers to do group lookups to a Windows AD.  Windows AD is 2008 and 2012 in my env.

Squid.conf:


### cache manager
cache_mgr pclan at example.com<mailto:pclan at example.com>

#Define the cache_peer to be used
# cache_peer proxy1.ap.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest
  cache_peer proxy1.us.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.hk.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest


### negotiate kerberos and ntlm authentication
auth_param negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=EXAMPLE.COM --require-membership-of=EXAMPLE\\Full.Access -kerberos /usr/lib64/squid/squid_kerb_auth -d -s GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive off

### pure ntlm authentication
auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --require-membership-of=EXAMPLE\\Full.Access
auth_param ntlm children 30
auth_param ntlm keep_alive off

### provide basic authentication via ldap for clients not authenticated via kerberos/ntlm
auth_param basic program /usr/lib64/squid/squid_ldap_auth -R -b "dc=example,dc=com" -D Squid at EXAMPLE.COM<mailto:Squid at EXAMPLE.COM> -W /etc/squid/password -f sAMAccountName=%s -h DC01.EXAMPLE.COM
auth_param basic children 10
auth_param basic realm Internet Proxy
auth_param basic credentialsttl 1 minute

### ldap authorisation
external_acl_type memberof %LOGIN /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at EXAMPLE.COM<mailto:Squid at EXAMPLE.COM> -W /etc/squid/.ldappass.txt -f "(&(objectclass=person)(sAMAccountName=$)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h DC01.EXAMPLE.COM

### acl for proxy auth and ldap authorizations
acl our_networks src  172.16.0.0/12 10.0.0.0/8 192.170.0.0/24
acl INTERNAL dst 172.16.0.0/12 10.0.0.0/8
acl auth proxy_auth REQUIRED
acl HEAD method HEAD
acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
acl FullAccess          external memberof "/etc/squid/full_access.txt"
acl Approved_Domains dstdomain "/etc/squid/acls/approved.txt"
acl WindowsUpdate dstdomain -i "/etc/squid/acls/windowsupdates.txt"
acl local-servers dstdomain "/etc/squid/acls/localservers.txt"
acl RestrictedHost src "/etc/squid/acls/restrictedhost_ip.txt"
acl bypass_auth src "/etc/squid/acls/bypass_auth_src_ip.txt"
acl bypass_auth-external dstdomain "/etc/squid/acls/bypass_auth_dst_domain.txt"
acl blocksites dstdomain "/etc/squid/acls/block_sites.txt"
acl DIRECT src "/etc/squid/acls/direct_src_ip.txt"
acl DIRECT-external dstdomain "/etc/squid/acls/direct_dst_domains.txt"
acl Smartconnect dstdomain ned.webscanningservice.com
acl Java browser Java/[0-9]
acl JavaSites dstdomain .gotomeeting.com
always_direct allow INTERNAL
always_direct allow local-servers
cache deny INTERNAL
cache deny local-servers



### squid defaults
acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
acl SSL_ports port 443 563 33808
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443 563     # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
#allow custom ports
acl goto_meeting dst 216.115.208.0/20 216.219.112.0/20 66.151.158.0/24 66.151.150.160/27 66.151.115.128/26 64.74.80.0/24 202.173.24.0/21 67.217.64.0/19 78.108.112.0/20 68.64.0.0/19 206.183.100.0/22
acl Safe_ports port 8200        # gotomeeting
acl Safe_ports port 31303 33808 # TD Merchant
acl Safe_ports port 8443        # Symantec SEP Manager
acl Safe_ports port 8014               # Symantec SEPM Client
acl SSL_ports port 9443         # pingdevfed
acl SSL_ports port 9444         # pingdevfed
acl SSL_ports port 5443         # pingdev
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
#http_access deny !memberof
http_access allow localhost
http_access allow HEAD
http_access deny !our_networks
http_access allow Smartconnect
http_access deny blocksites all
http_access allow Approved_Domains
http_access deny RestrictedHost all
http_access allow FullAccess auth
http_access allow Java
http_access allow WindowsUpdate
http_access allow bypass_auth
http_access allow bypass_auth-external
http_access allow goto_meeting
http_access allow our_networks all
http_access allow Java our_networks JavaSites
http_access allow auth
http_access deny !auth
http_access deny all


deny_info error-blocksites blocksites

#Logs to look like apache
emulate_httpd_log on

#Level of Log debugging
debug_options ALL,1

#Log file locations
cache_log /var/log/squid/cache.log
access_log /var/log/squid/access.log
useragent_log /var/log/squid/useragent.log

#Hostname shown in error pages
visible_hostname proxy01p
http_port 3128
hierarchy_stoplist cgi-bin ?
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320




CONFIDENTIALITY NOTICE
This electronic message is confidential and may contain legally privileged information intended only for the use of the individual or company named above.
If the reader of this message is not the intended recipient, or the employee or agent responsible to deliver it to the intended recipient, you are hereby notified
that any dissemination, distribution or copying of this communications is strictly prohibited. If you have received this communication in error, please immediately
notify us by telephone, and return the original message to us at the address above


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/8be48c54/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 6709 bytes
Desc: image001.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/8be48c54/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 4042 bytes
Desc: image002.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/8be48c54/attachment-0001.png>

From rafael.akchurin at diladele.com  Tue Apr  5 21:59:41 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 5 Apr 2016 21:59:41 +0000
Subject: [squid-users] External ACL Lookup
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE734B8A0@CLWSEXCMBX02.na.bicworld.com>
References: <CA86A9283AA07E478F6B0629521FFEE734B879@CLWSEXCMBX02.na.bicworld.com>
 <VI1PR04MB13594D930512E5F7AD1F98AE8F9E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CA86A9283AA07E478F6B0629521FFEE734B8A0@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <VI1PR04MB1359D75A357042526216DB778F9E0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Well I would then first run the request with ldp.exe just to be sure the user is indeed in the group
In our ICAP we use a little different filter - may be it can give you some ideas :(
Please note I do not know squid equivalents for {{ bla-bla }} macros.

(&(|(userPrincipalName={{USER_NAME}})(sAMAccountName={{USER_NAME_STRIPPED}}))(memberOf:1.2.840.113556.1.4.1941:=CN=Internet Relaxed,CN=Users,DC=diladele,DC=lan))

Sorry nothing to offer more.

Best regards,
Rafael

From: Craddock, Tommy [mailto:Tommy.Craddock at bicgraphic.com]
Sent: Tuesday, April 5, 2016 11:53 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>; squid-users at lists.squid-cache.org
Subject: RE: External ACL Lookup

Rafael,

Thanks for your reply.   Substituting userPrincipalName for sAMAccountName in both the command line and squid.conf produces an ERR:

/usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com<mailto:Squid at example.com> -W /etc/squid/password -f "(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com
tcraddock at EXAMPLE.COM<mailto:tcraddock at EXAMPLE.COM> Full.Access
ERR

cat /etc/squid/squid.conf | grep userPrin
external_acl_type memberof %LOGIN /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com<mailto:Squid at example.com> -W /etc/squid/password -f "(&(objectclass=person)(userPrincipalName=$)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com

cache.log:

2016/04/05 17:45:24.190| authenticateAuthUserAddIp: user 'tcraddock at EXAMPLE.COM' has been seen at a new IP address (172.23.5.193:57445)
2016/04/05 17:45:24.190| aclMatchExternal: memberof("tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>") = lookup needed
2016/04/05 17:45:24.190| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": entry=@0, age=0
2016/04/05 17:45:24.190| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": queueing a call.
2016/04/05 17:45:24.190| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": return -1.
2016/04/05 17:45:24.190| externalAclLookup: lookup in 'memberof' for 'tcraddock at EXAMPLE.COM Full.Access'
2016/04/05 17:45:24.196| externalAclHandleReply: reply="ERR"
2016/04/05 17:45:24.196| external_acl_cache_add: Adding 'tcraddock at EXAMPLE.COM Full.Access' = 0
2016/04/05 17:45:24.196| aclMatchExternal: memberof = 0

 [cid:E16BB7E4-AAA7-4D07-803E-E39F6201D081]
Tommy E CRADDOCK JR
Systems Admin
BIC Advertising & Promotional Products
14421 Myer Lake Circle
Clearwater, FL  33760
727-507-3080
tommy.craddock at bicgraphic.com<mailto:tommy.craddock at bicgraphic.com>

www.bicgraphic.com<http://www.bicgraphic.com/>

[cid:37DF6999-C959-46F8-BA13-A4CFA37F691F]

CONFIDENTIALITY NOTICE
This electronic message is confidential and may contain legally privileged information intended only for the use of the individual or company named above.
If the reader of this message is not the intended recipient, or the employee or agent responsible to deliver it to the intended recipient, you are hereby notified
that any dissemination, distribution or copying of this communications is strictly prohibited. If you have received this communication in error, please immediately
notify us by telephone, and return the original message to us at the address above

From: Rafael Akchurin [mailto:rafael.akchurin at diladele.com]
Sent: Tuesday, April 05, 2016 5:25 PM
To: Craddock, Tommy; squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: RE: External ACL Lookup

Hello Tommy,

Just my two cents. Try using usePrincipalName, and not sAMAccountName in LDAP filter.
The squid logs indicate the user is authenticated as tcraddock at EXAMPLE.COM<mailto:tcraddock at EXAMPLE.COM> which is *not* in sAMAccountName for sure.

Best regards,
Rafael Akchurin
Diladele B.V.
http://www.quintolabs.com
http://www.diladele.com

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com.

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Craddock, Tommy
Sent: Tuesday, April 5, 2016 11:16 PM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: [squid-users] External ACL Lookup

Hello,

Trying to use an external ACL helper to do a lookup of my user in a group in a Windows AD.  I can test from the command line:


/usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com<mailto:Squid at example.com> -W /etc/squid/password -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com
tcraddock at EXAMPLE.COM<mailto:tcraddock at EXAMPLE.COM> Full.Access
OK


In the cache.log w/debug set to ALL,3:

2016/04/05 16:54:39.768| aclMatchExternal: memberof user not authenticated (0)
GETTING KERB TOKEN.....
...
2016/04/05 16:54:39.780| authenticateAuthUserAddIp: user 'tcraddock at EXAMPLE.COM' has been seen at a new IP address (172.23.5.193:56059)
2016/04/05 16:54:39.780| aclMatchExternal: memberof("tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>") = lookup needed
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": entry=@0, age=0
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": queueing a call.
2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access<mailto:tcraddock at EXAMPLE.COM%20Full.Access>": return -1.
2016/04/05 16:54:39.780| externalAclLookup: lookup in 'memberof' for 'tcraddock at EXAMPLE.COM Full.Access'
2016/04/05 16:54:39.784| externalAclHandleReply: reply="ERR"
2016/04/05 16:54:39.785| external_acl_cache_add: Adding 'tcraddock at EXAMPLE.COM Full.Access' = 0
2016/04/05 16:54:39.785| aclMatchExternal: memberof = 0

In the file referenced in the ACLs:

acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
acl FullAccess          external memberof "/etc/squid/full_access.txt"


it has:

cat /etc/squid/full_access.txt
Full.Access

cat /etc/squid/restricted_access.txt
Restricted.Access

Im not sure why the logs show my user is getting ERR as the response to group checking, when I run it from the command line, I get an OK.


Info about my setup:

[root at clwslprox01p squid]# squid -v
Squid Cache: Version 3.1.23
configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--enable-internal-dns' '--disable-strict-error-checking' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-arp-acl' '--enable-follow-x-forwarded-for' '--enable-auth=basic,digest,ntlm,negotiate' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL,DB,POP3,squid_radius_auth' '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' '--enable-digest-auth-helpers=password,ldap,eDirectory' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-referer-log' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' '--enable-http-violations' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' --with-squid=/builddir/build/BUILD/squid-3.1.23

[root at clwslprox01p squid]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.7 (Santiago)

Using negotiate w/NTLM and Kerberos to do user auth, and trying to use external helpers to do group lookups to a Windows AD.  Windows AD is 2008 and 2012 in my env.

Squid.conf:


### cache manager
cache_mgr pclan at example.com<mailto:pclan at example.com>

#Define the cache_peer to be used
# cache_peer proxy1.ap.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest
  cache_peer proxy1.us.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.hk.webscanningservice.com parent 3128 0000 default no-query no-digest
# cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest


### negotiate kerberos and ntlm authentication
auth_param negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=EXAMPLE.COM --require-membership-of=EXAMPLE\\Full.Access -kerberos /usr/lib64/squid/squid_kerb_auth -d -s GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive off

### pure ntlm authentication
auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --require-membership-of=EXAMPLE\\Full.Access
auth_param ntlm children 30
auth_param ntlm keep_alive off

### provide basic authentication via ldap for clients not authenticated via kerberos/ntlm
auth_param basic program /usr/lib64/squid/squid_ldap_auth -R -b "dc=example,dc=com" -D Squid at EXAMPLE.COM<mailto:Squid at EXAMPLE.COM> -W /etc/squid/password -f sAMAccountName=%s -h DC01.EXAMPLE.COM
auth_param basic children 10
auth_param basic realm Internet Proxy
auth_param basic credentialsttl 1 minute

### ldap authorisation
external_acl_type memberof %LOGIN /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at EXAMPLE.COM<mailto:Squid at EXAMPLE.COM> -W /etc/squid/.ldappass.txt -f "(&(objectclass=person)(sAMAccountName=$)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h DC01.EXAMPLE.COM

### acl for proxy auth and ldap authorizations
acl our_networks src  172.16.0.0/12 10.0.0.0/8 192.170.0.0/24
acl INTERNAL dst 172.16.0.0/12 10.0.0.0/8
acl auth proxy_auth REQUIRED
acl HEAD method HEAD
acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
acl FullAccess          external memberof "/etc/squid/full_access.txt"
acl Approved_Domains dstdomain "/etc/squid/acls/approved.txt"
acl WindowsUpdate dstdomain -i "/etc/squid/acls/windowsupdates.txt"
acl local-servers dstdomain "/etc/squid/acls/localservers.txt"
acl RestrictedHost src "/etc/squid/acls/restrictedhost_ip.txt"
acl bypass_auth src "/etc/squid/acls/bypass_auth_src_ip.txt"
acl bypass_auth-external dstdomain "/etc/squid/acls/bypass_auth_dst_domain.txt"
acl blocksites dstdomain "/etc/squid/acls/block_sites.txt"
acl DIRECT src "/etc/squid/acls/direct_src_ip.txt"
acl DIRECT-external dstdomain "/etc/squid/acls/direct_dst_domains.txt"
acl Smartconnect dstdomain ned.webscanningservice.com
acl Java browser Java/[0-9]
acl JavaSites dstdomain .gotomeeting.com
always_direct allow INTERNAL
always_direct allow local-servers
cache deny INTERNAL
cache deny local-servers



### squid defaults
acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
acl SSL_ports port 443 563 33808
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443 563     # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
#allow custom ports
acl goto_meeting dst 216.115.208.0/20 216.219.112.0/20 66.151.158.0/24 66.151.150.160/27 66.151.115.128/26 64.74.80.0/24 202.173.24.0/21 67.217.64.0/19 78.108.112.0/20 68.64.0.0/19 206.183.100.0/22
acl Safe_ports port 8200        # gotomeeting
acl Safe_ports port 31303 33808 # TD Merchant
acl Safe_ports port 8443        # Symantec SEP Manager
acl Safe_ports port 8014               # Symantec SEPM Client
acl SSL_ports port 9443         # pingdevfed
acl SSL_ports port 9444         # pingdevfed
acl SSL_ports port 5443         # pingdev
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
#http_access deny !memberof
http_access allow localhost
http_access allow HEAD
http_access deny !our_networks
http_access allow Smartconnect
http_access deny blocksites all
http_access allow Approved_Domains
http_access deny RestrictedHost all
http_access allow FullAccess auth
http_access allow Java
http_access allow WindowsUpdate
http_access allow bypass_auth
http_access allow bypass_auth-external
http_access allow goto_meeting
http_access allow our_networks all
http_access allow Java our_networks JavaSites
http_access allow auth
http_access deny !auth
http_access deny all


deny_info error-blocksites blocksites

#Logs to look like apache
emulate_httpd_log on

#Level of Log debugging
debug_options ALL,1

#Log file locations
cache_log /var/log/squid/cache.log
access_log /var/log/squid/access.log
useragent_log /var/log/squid/useragent.log

#Hostname shown in error pages
visible_hostname proxy01p
http_port 3128
hierarchy_stoplist cgi-bin ?
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320




CONFIDENTIALITY NOTICE
This electronic message is confidential and may contain legally privileged information intended only for the use of the individual or company named above.
If the reader of this message is not the intended recipient, or the employee or agent responsible to deliver it to the intended recipient, you are hereby notified
that any dissemination, distribution or copying of this communications is strictly prohibited. If you have received this communication in error, please immediately
notify us by telephone, and return the original message to us at the address above


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/3b0ceef2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 6709 bytes
Desc: image001.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/3b0ceef2/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 4042 bytes
Desc: image002.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160405/3b0ceef2/attachment-0001.png>

From spider at smoothnet.org  Tue Apr  5 22:49:39 2016
From: spider at smoothnet.org (Nicolaas Hyatt)
Date: Tue, 05 Apr 2016 17:49:39 -0500
Subject: [squid-users] Sending intermediate certificate with SSL-Bumped
 Certificate. (V3.5.1516-3-2-r14000)
Message-ID: <cf0f6972f77514fcaaddcf18736f4b4a@smoothnet.org>

I know I'm a few minor revisions behind, but I am a little confused as 
to if it is possible to request squid include the configured certificate 
along with the certificate generated. I know that this is somewhat 
confusing to read.

+Root (Self Signed) CA Cert
|
`+ Intermediate Certificate (Used by squid.)
  |
  `- Squid Auto Generated Certificate

I have the Self Signed Root CA Cert installed on all the systems, but 
the Intermediate Certificate is not sent by squid, so the trust chain 
fails. I have been reading threads here and there and saw a post form 
Amos a bit ago (referring to squid v3.3) where there may (or may not) 
have been a configuration option to modify squid's behavior to do as I 
am requesting, but details in the thread do not include the 
configuration directive.

If this is not a valid feature, I understand, and can fully accept that 
answer, I'm not complaining about free software!




From pascal at watteel.be  Wed Apr  6 05:38:12 2016
From: pascal at watteel.be (Pascal Watteel)
Date: Wed, 6 Apr 2016 05:38:12 +0000
Subject: [squid-users] select parent proxy based on ACL
In-Reply-To: <1459858102.9684.23.camel@watteel.be>
References: <1459857825.9684.21.camel@watteel.be>
 <1459858102.9684.23.camel@watteel.be>
Message-ID: <1459921092.9684.28.camel@watteel.be>

anyone?

On Tue, 2016-04-05 at 12:08 +0000, Pascal Watteel wrote:
> Hi peeps,
> 
> I have written a python based download accelerator based proxy.
> It does exactly the same thing as what aria2c would do, but as a
> proxy.
> 
> I now want to tell squid to only send .zip .iso .whatever to this
> proxy
> as an parent proxy.
> But i only find a way how to tell squid to do this for domains with
> peer_domain.
> 
> Is there a way how i can tell squid to decide the parent proxy based
> on
> a ACL so i can just use regex define the files i wanna send to this
> parent?
> 
> Regards
> 
> Watteel Pascal
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

From Silamael at coronamundi.de  Wed Apr  6 06:29:00 2016
From: Silamael at coronamundi.de (Silamael)
Date: Wed, 6 Apr 2016 08:29:00 +0200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <57030859.5060609@treenet.co.nz>
References: <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz>
Message-ID: <5704ACAC.3090203@coronamundi.de>

On 04/05/2016 02:35 AM, Amos Jeffries wrote:
> On 5/04/2016 2:44 a.m., FredB wrote:
>>>
>>> Thanks I will test, I confirm the problem still present after a while
>>> Eg: this object seems never cleaned/fixed from cache
>>>
>>
>> No more success with fresh cache, after 5 minutes the messages appears again and again 
>> Joe is right there is a bug somewhere 
> 
> The only Vary related change between .15 and .16 was the CVE fix
> <www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14016.patch>.
> 
> I am suspicious of the +1 being added in src/store_swapmeta.cc. There is
> a TODO next to it. Would you mind trying without it?
> 
> I expect the cache will need clearing to make that change operate
> properly after the change. But if it is the problem the loops should not
> return like they do now.
> 
> Amos

As I'm currently updating too: is this a bug or have I only to clear the
old cache directories to prevent these error messages?

Cheers,
Matthias


From fredbmail at free.fr  Wed Apr  6 07:47:27 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 6 Apr 2016 09:47:27 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <5704ACAC.3090203@coronamundi.de>
Message-ID: <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> As I'm currently updating too: is this a bug or have I only to clear
> the
> old cache directories to prevent these error messages?
> 

As far as I know, no, I tried


From chip_pop at hotmail.com  Wed Apr  6 08:51:21 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 01:51:21 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <57030859.5060609@treenet.co.nz>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz>
Message-ID: <1459932681097-4676948.post@n4.nabble.com>

amos  one think i notice 
=== modified file 'src/MemObject.cc'
--- src/MemObject.cc	2016-01-01 00:14:27 +0000
+++ src/MemObject.cc	2016-04-01 06:15:31 +0000
@@ -136,8 +136,6 @@
     HTTPMSGUNLOCK(request);
 
     ctx_exit(ctx);              /* must exit before we free mem->url */
-
-    safe_free(vary_headers); /*??????? do we need to clear (vary_headers)
if yes then you forget to insert vary_headers.clear(); */
+    vary_headers.clear();      /* missing for reason on patch
squid-3.5-14016.patch */
 }



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676948.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Ralf.Hildebrandt at charite.de  Wed Apr  6 09:35:14 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Wed, 6 Apr 2016 11:35:14 +0200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <5704ACAC.3090203@coronamundi.de>
References: <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
Message-ID: <20160406093510.GA4978@charite.de>

* Silamael <Silamael at coronamundi.de>:

> As I'm currently updating too: is this a bug or have I only to clear the
> old cache directories to prevent these error messages?

Clearing the cache doesn't help (for long). It's a bug.

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From squid3 at treenet.co.nz  Wed Apr  6 10:40:15 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Apr 2016 22:40:15 +1200
Subject: [squid-users] Squid Queries
In-Reply-To: <CAApL2HcLnSb9hCXgCpLeJ9bR0q-XBtqjqHtbUKHWsPyZ4DtJiA@mail.gmail.com>
References: <CAApL2HcLnSb9hCXgCpLeJ9bR0q-XBtqjqHtbUKHWsPyZ4DtJiA@mail.gmail.com>
Message-ID: <5704E78F.6040302@treenet.co.nz>

On 5/04/2016 4:53 p.m., Supriya Prasad wrote:
> Hi Team,
> 
> I had some queries regarding the squid configuration:
> 
> 
> We are using squid as a cache for our CWS proxy. As we are aware of the
> max-forwards header, it decrements as it goes through each of the
> proxies.Currently, our CWS proxy and squid both decrement the max forwards
> header value when processing options requests. So if we send a max-forwards
> header of 5 from the client side, by the time is comes out of squid it
> shows 3. However as our proxy and squid is seen as 1 entity, we want the
> decrement to happen only once.
> 
> I went through a number of squid documentation and nowhere it mentions how
> to disable the max forward header from decrementing on squid. Could you
> please let us know what is to be done?

RFC 7231:
"
  Each intermediary that receives a TRACE or OPTIONS request containing
  a Max-Forwards header field MUST check and update its value prior to
  forwarding the request.
"
... notice the 'MUST' means mandatory behaviour. There is a goood reason
for that.

Regardless of whether you conceptually describe CWS + Squid as the one
"entity". They are in fact two different pieces of software. It is
entirely possible to create an infinite loop between just the two
pieces: CWS sends to Squid a request to send to CWS a request to send to
Squid a request to send to CWS ... and so on.
 The Via or Max-Forwards header are the only ways to protect against
that in regular traffic - and Via is optional.
 The Max-Forwards header is also the only way to target OPTIONS and
TRACE requests to diagnose the network behaviour in particular software
along the route. Adjusting it in undefined ways along the way will break
the protocol.

Amos



From squid3 at treenet.co.nz  Wed Apr  6 11:32:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Apr 2016 23:32:19 +1200
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
 <57031390.8020604@treenet.co.nz>
 <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>
Message-ID: <5704F3C3.2050709@treenet.co.nz>

On 6/04/2016 6:50 a.m., Jok Thuau wrote:
> On Mon, Apr 4, 2016 at 6:23 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>>>>>
>>>>> If i remove *all* the http_access lines, then the behavior appears
>>>> correct
>>>>> (from a "splicing/bumping" standpoint).
>>>>>
>>>>
>>>> Strange. Squid without any http_access lines should be denying traffic
>>>> 100%.
>>>>
>>>>
>>> I do not see this behavior. Traffic appears to be allowed, and bumped
>>> (though with the wrong certificate, depending on the config, as explained
>>> before).
>>>
>>>
>>
> 
> 
> 
> 
>>>
>>> my apologies for trying to show only the relevant parts. Find below the
>>> current config.
>>> It appears to be bumping everything rather than splicing any of the
>> config
>>> (which may be due to the limitations documented on the wiki)
>>>
>>> acl Safe_ports port 80 # http
>>> acl Safe_ports port 443 # https
>>> acl SSL_ports port 443
>>> acl CONNECT method CONNECT
>>> http_port 3129 intercept
>>> https_port 8443 intercept ssl-bump generate-host-certificates=on
>>> dynamic_cert_mem_cache_size=64MB \
>>>     cert=/etc/squid/ssl/proxy.pem \
>>>     key=/etc/squid/ssl/proxy.key \
>>>     cafile=/etc/squid/ssl/proxy.pem
>>> always_direct allow all
>>
>> always_direct has not been necessary with SSL-Bump sice 3.1 series. You
>> should remove it.
>>
>>> acl step1 at_step SslBump1
>>> acl step2 at_step SslBump2
>>> acl step3 at_step SslBump3
>>> acl SniBypass ssl::server_name_regex \.slashdot\.org
>>> acl SniBypass ssl::server_name_regex \.fsdn\.com
>>
> 
> I have moved those "SniBypass" acl into a separate files and replaced this
> with an include, as that list will end up growing.
> 

It would be better to add only the list of values to a file. It will
save you entering the ACL name and type repeatedly in the included file.
Like this ...

/some/file/bypass_domains:
 .slashdot.org
 .fsdn.com


/etc/squid/squid.conf:
 ...
 acl http_bypass dstdomain "/some/file/bypass_domains"



> 
>>> acl http_bypass dstdomain .slashdot.org
>>> acl http_bypass dstdomain .fsdn.com
> 
> 
> and similarly here, replaced by an include...
> 
> 
>>
>>> acl https_bypass all-of CONNECT SniBypass
>>
>> This https_bypass ACL definition is a bit weird. It requires a single
>> message to match both TLS and HTTP properties simultaneously.
> 
> 
>> As you might imagine it is difficult for a TLS messages to match HTTP
>> properties, and vice versa. So it wont ever match.
>>
>>
> I don't understand. SniBypass is based on ssl::server_name_regex which
> shouldn't apply to http at all...

Yes.

> Would that not be coming from the (client|server)Hello?
> 

yes.

Also the CONNECT ACL is based on the HTTP method.

For the https_bypass ACL to return true/match the message being tested
must match both ("all-of") CONNECT and SniBypass.

HTTP messages cannot match SniBypass.
TLS messages cannot match CONNECT.
Therefore nothing will ever match all of https_bypass requirements.

> 
>> Note: SNI is *not* equivalent to Host or URL domain name. They can
>> contain very different values. The only thing they have in common is
>> that they both are supposed to point at the IP of the server being
>> contacted.
>>
>>
>>> acl http_ok all-of http_bypass Safe_ports
>>> ssl_bump peek step1
>>> ssl_bump splice SniBypass step2
>>
>> This splice will work if (and only if) the client sends TLS SNI values
>> to Squid. It will ignore the server cert details.
>>
>> For clients which do not send SNI or for all connections where the SNI
>> does not match your ACL the bump rule below will do client-first bumping
>> (without the server cert).
>>
>>> ssl_bump bump all
>>
>> I suggets you try these ssl_bump rules instead:
>> [snip]
> 
>  OK
> 
>> [snip]
>> Okay. That sort of matches your policy. Except that you are missing the
>> security defaults. Those lines are carefully tuned for the specific
>> behaviour to protect against security attacks:
>>
>>  http_access deny !Safe_ports
>>  http_access deny CONNECT !SSL_ports
>>
>> .. and should be above your custom rules.
>>
> 
> I added those at the top as requested...
> 
> 
>>  cache allow all
>>  cache deny all
>>
>> ... pick one.
>>
>>
> done - the deny one is the one left in there now.
> 
>>
>>> shutdown_lifetime 3 seconds
>>
> 
> for clarification, I also moved the two sets of ACLs into separate files,
> as those will eventually be maintained externally (SniBypass and
> http_bypass).
> 
> The config file is now:
> 
> acl SSL_ports port 443
> acl Safe_ports port 80 # http
> acl Safe_ports port 21 # ftp
> acl Safe_ports port 443 # https
> acl Safe_ports port 70 # gopher
> acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280 # http-mgmt
> acl Safe_ports port 488 # gss-http
> acl Safe_ports port 591 # filemaker
> acl Safe_ports port 777 # multiling http
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_port 3128
> http_port 3129 intercept
> https_port 8443 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=64MB \
>     cert=/etc/squid/ssl/proxy.pem \
>     key=/etc/squid/ssl/proxy.key \
>     cafile=/etc/squid/ssl/proxy.pem
> workers 6
> always_direct allow all
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> include "/etc/squid/snibypass.acl"
> include "/etc/squid/dstbypass.acl"
> acl https_ok all-of CONNECT SniBypass
> acl http_ok all-of http_bypass Safe_ports
> ssl_bump splice SniBypass
> ssl_bump peek step1
> ssl_bump stare step2
> ssl_bump bump all
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
> sslproxy_cert_sign_hash sha256
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
> http_access allow http_ok
> http_access allow https_ok
> http_access deny all
> cache deny all
> shutdown_lifetime 3 seconds
> 
> Note that with that config, the http_access deny all (couple lines before
> the end) appears to deny the TLS/SSL connection before the ssl_bump steps
> have a chance to match, so i get certs that are not mimic'ed (they have
> CN=<ip>). If i remove all 3 http_access at the end, then the
> splicing/bumping behavior appears to work as expected, but then i'm not
> denying anything...

You used to have "allow CONNECT" where you now have "allow https_ok".

As mentioned above the https_ok ACL will never match anything because
its sub-ACL tests cannot all produce a true result at the same time.

The "allow CONNECT" was fine at its previous location, and is likely the
best way to keep it there.


> 
> that seems to confirm my suspicion that the access control (http_access)
> apply too early for me to match anything related to the ssl::server_name or
> ssl::server_name_regex.

Both yes and no. The server_name ACL when tested in http_access can
match the host/server name given in a CONNECT message if (and only if)
it actually *is* a name, not a raw-IP address. server_name does not do
DNS lookups like dstdomain.
 For intercepted traffic that field will always be a raw-IP, so
server_name cannot match it against any textual host name.


> 
> I keep thinking that what i'm missing is that the http_access applies too
> early.

You are right so far as that is what is going on. But you are missing an
additional detail as well:

Each of these 'access rule sets are being applied multiple times at
different stages (http_access included).

http_access is being applied on the CONNECT request right at the start
of the processing. And again on the HTTPS bumped traffic after ssl_bump
has finished all its stuff.

> I played with "terminate" instead of "bump" at the last ssl_bump
> command, but i really need the error message. I keep wanting to have
> something like this:
> 
> ssl_bump splice SniBypass
> ssl_bump peek step1
> ssl_bump stare step2
> ssl_bump deny all
> 
> where the last one would effectively bump the connection, and provide the
> ERR_ACCESS_DENIED page.

You cannot emit an HTTP + HTML format denial message in TLS layer protocol.

NP: the 'proper' way to deny TLS layer traffic is with "terminate"
ssl_bump action which sends a TLS layer terminate/abort message. Which
is very different to the HTTP+HTML "Access Denied" page. Namely you do
not get to write anything for the "user" to see.


How all this Squid processing is working is that Squid receives a TCP
connection, synthesizes a CONNECT with raw-IP. Which gets processed by
your http_access rules. That "allow CONNECT" rule at the end of the set
usually matches and lets the bumping begin step1 (unless you decided to
send a denied error page early).

After step1 Squid should have the SNI details for SniBypass to work with
(only inside ssl_bump rules).

So to summarize the sequence is:

-> TCP SYN packets
-> Squid fake CONNECT request:
 http_access --> error page?
 ssl_bump (step 1) --> splice?
 ssl_bump (step 2) --> splice?
 ssl_bump (step 3) --> splice?

-> Some HTTPS request:
 http_access --> error page!


* Only the http_access steps can produce an error page in HTTP.

* The ssl_bump can splice (to accept the tunnel with no error page
possible), or bump (so http_access denying the first HTTPS request
generates the visible access denied error page).

Amos



From squid3 at treenet.co.nz  Wed Apr  6 12:00:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Apr 2016 00:00:28 +1200
Subject: [squid-users] select parent proxy based on ACL
In-Reply-To: <1459921092.9684.28.camel@watteel.be>
References: <1459857825.9684.21.camel@watteel.be>
 <1459858102.9684.23.camel@watteel.be> <1459921092.9684.28.camel@watteel.be>
Message-ID: <5704FA5C.2020600@treenet.co.nz>

On 6/04/2016 5:38 p.m., Pascal Watteel wrote:
> anyone?

NP: Messages sent at 12am should be expected to have some response
delay. (and its always 12am somewhere in the world :-).

> 
> On Tue, 2016-04-05 at 12:08 +0000, Pascal Watteel wrote:
>> Hi peeps,
>>
>> I have written a python based download accelerator based proxy.
>> It does exactly the same thing as what aria2c would do, but as a
>> proxy.

Huh?

aria2c is a "client" (or "user agent") in HTTP terminology.

A proxy is ... a proxy. Which is to say both client and server. But
definitely NOT a user-agent.

So either you have written a proxy, or you have written something like
aria2c. Not both.

"accelerator" is a marketing jargon word. Particularly when used in the
phrase "download acclerator".


>>
>> I now want to tell squid to only send .zip .iso .whatever to this
>> proxy
>> as an parent proxy.
>> But i only find a way how to tell squid to do this for domains with
>> peer_domain.
>>
>> Is there a way how i can tell squid to decide the parent proxy based
>> on
>> a ACL so i can just use regex define the files i wanna send to this
>> parent?
>>

Terminology clash again. Squid does not send files anywhere. Two reasons
for that:

1) HTTP is a "pull" protocol: Requests go out (aka "send"). Responses
come back (aka "receive"). That is all.

2) HTTP has therefore no protocol concept of "files". Squid is only
aware of the response content-type (note that its "payload" or
"content", not 'file') when it is already on its way back to the client.
Far too late to decide which server to send the request message to.


I *think* what you are asking for is:
 <http://www.squid-cache.org/Doc/config/cache_peer_access/>

But I am seriously doubting whether you have the right HTTP model with
all this malformed terminology you are using.

You can approximately guess what the traffic will be by urlpath_regex
matching the URL path values. But unless you control the servers URL
design that is just a rough guess.


PS. "download accelerator" is an old concept from the days 20-odd years
go when networks were slow and HTTP/1.0 was wasting bandwidth to make
things slower. As with all old concepts in HTTP Squid probably already
does it in one way or several.
In particular modern HTTP/1.1 plus Caching obsoletes almost all
"download accelerator" designs in a much more efficient way.
 If you describe what you actualy want the whole system to do in a clear
way we can perhapse provide you with squid.conf settings to avoid
needing the extra layer of custom proxy software.

Amos



From squid3 at treenet.co.nz  Wed Apr  6 12:10:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Apr 2016 00:10:09 +1200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459932681097-4676948.post@n4.nabble.com>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <1459932681097-4676948.post@n4.nabble.com>
Message-ID: <5704FCA1.1020708@treenet.co.nz>

On 6/04/2016 8:51 p.m., joe wrote:
> amos  one think i notice 
> === modified file 'src/MemObject.cc'
> --- src/MemObject.cc	2016-01-01 00:14:27 +0000
> +++ src/MemObject.cc	2016-04-01 06:15:31 +0000
> @@ -136,8 +136,6 @@
>      HTTPMSGUNLOCK(request);
>  
>      ctx_exit(ctx);              /* must exit before we free mem->url */
> -
> -    safe_free(vary_headers); /*??????? do we need to clear (vary_headers)
> if yes then you forget to insert vary_headers.clear(); */
> +    vary_headers.clear();      /* missing for reason on patch
> squid-3.5-14016.patch */
>  }
> 

That was intentional. The line of code above was in an objects
destructor. The safe_free() used to be needed to prevent the C-style bit
of memory being leaked.

The new code uses a C++ smart pointer called SBuf and it automatically
does that memory releasing in destructors without an explicit clear()
being needed.

(You can add a clear() if you want. All it will do is waste a few CPU
cycles.)

Amos



From squid3 at treenet.co.nz  Wed Apr  6 12:14:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Apr 2016 00:14:28 +1200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <5704FDA4.60606@treenet.co.nz>

On 6/04/2016 7:47 p.m., FredB wrote:
> 
>>
>> As I'm currently updating too: is this a bug or have I only to clear
>> the
>> old cache directories to prevent these error messages?
>>
> 
> As far as I know, no, I tried

I think you guys misundersood what I was asking about.

So lets try this again...

Can somebody check whether applying the attached patch _and_ clearing
the cache does anything useful?
(should apply with "patch -p0" to squid-3.5.16)

If the answer is yes, then it can be used while I work on a better fix
that wont need clearing the cache.

Amos

-------------- next part --------------
=== modified file 'src/store_swapmeta.cc'
--- src/store_swapmeta.cc	2016-04-01 06:15:31 +0000
+++ src/store_swapmeta.cc	2016-04-06 12:03:43 +0000
@@ -89,9 +89,7 @@
     SBuf vary(e->mem_obj->vary_headers);
 
     if (!vary.isEmpty()) {
-        // TODO: do we still need +1 here? StoreMetaVary::checkConsistency
-        //       no longer relies on nul-termination, but other things might.
-        t = StoreMeta::Factory(STORE_META_VARY_HEADERS, vary.length() + 1, vary.c_str());
+        t = StoreMeta::Factory(STORE_META_VARY_HEADERS, vary.length(), vary.c_str());
 
         if (!t) {
             storeSwapTLVFree(TLV);


From Ralf.Hildebrandt at charite.de  Wed Apr  6 12:16:59 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Wed, 6 Apr 2016 14:16:59 +0200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <5704FDA4.60606@treenet.co.nz>
References: <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz>
Message-ID: <20160406121659.GD4978@charite.de>

* Amos Jeffries <squid3 at treenet.co.nz>:

> So lets try this again...
> 
> Can somebody check whether applying the attached patch _and_ clearing
> the cache does anything useful?
> (should apply with "patch -p0" to squid-3.5.16)

Will try, but then I'm on 4.0.8...
 
> If the answer is yes, then it can be used while I work on a better fix
> that wont need clearing the cache.
> 
> Amos
> 

> === modified file 'src/store_swapmeta.cc'
> --- src/store_swapmeta.cc	2016-04-01 06:15:31 +0000
> +++ src/store_swapmeta.cc	2016-04-06 12:03:43 +0000
> @@ -89,9 +89,7 @@
>      SBuf vary(e->mem_obj->vary_headers);
>  
>      if (!vary.isEmpty()) {
> -        // TODO: do we still need +1 here? StoreMetaVary::checkConsistency
> -        //       no longer relies on nul-termination, but other things might.
> -        t = StoreMeta::Factory(STORE_META_VARY_HEADERS, vary.length() + 1, vary.c_str());
> +        t = StoreMeta::Factory(STORE_META_VARY_HEADERS, vary.length(), vary.c_str());
>  
>          if (!t) {
>              storeSwapTLVFree(TLV);
> 

> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From Ralf.Hildebrandt at charite.de  Wed Apr  6 12:20:19 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Wed, 6 Apr 2016 14:20:19 +0200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <5704FDA4.60606@treenet.co.nz>
References: <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz>
Message-ID: <20160406122019.GE4978@charite.de>

* Amos Jeffries <squid3 at treenet.co.nz>:

> Can somebody check whether applying the attached patch _and_ clearing
> the cache does anything useful?
> (should apply with "patch -p0" to squid-3.5.16)
> 
> If the answer is yes, then it can be used while I work on a better fix
> that wont need clearing the cache.

Rebuilt, reinstalled, cache cleared & restarted...
-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From squid3 at treenet.co.nz  Wed Apr  6 12:42:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Apr 2016 00:42:30 +1200
Subject: [squid-users] External ACL Lookup
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE734B879@CLWSEXCMBX02.na.bicworld.com>
References: <CA86A9283AA07E478F6B0629521FFEE734B879@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <57050436.9070908@treenet.co.nz>

On 6/04/2016 9:16 a.m., Craddock, Tommy wrote:
> Hello,
> 
> Trying to use an external ACL helper to do a lookup of my user in a group in a Windows AD.  I can test from the command line:
> 
> 
> /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com -W /etc/squid/password -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com
> tcraddock at EXAMPLE.COM Full.Access
> OK
> 

I'm always a little suspicious about whitespace in the LDAP parameters.
Such as you have for "ou=Some Group" in the -f filter.

It does depend on how new vs old your Squid is whether that will be
treated as two parameters or one passed to the helper by Squid. The
commmad line test will always pass it as one parameter.

If you can rework your ou= parameter to avoid the whitespace it might
work better (just a maybe, but you do have Squid 3.1).

> 
> In the cache.log w/debug set to ALL,3:
> 
> 2016/04/05 16:54:39.768| aclMatchExternal: memberof user not authenticated (0)
> GETTING KERB TOKEN.....
> ...
> 2016/04/05 16:54:39.780| authenticateAuthUserAddIp: user 'tcraddock at EXAMPLE.COM' has been seen at a new IP address (172.23.5.193:56059)
> 2016/04/05 16:54:39.780| aclMatchExternal: memberof("tcraddock at EXAMPLE.COM Full.Access") = lookup needed
> 2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": entry=@0, age=0
> 2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": queueing a call.
> 2016/04/05 16:54:39.780| aclMatchExternal: "tcraddock at EXAMPLE.COM Full.Access": return -1.
> 2016/04/05 16:54:39.780| externalAclLookup: lookup in 'memberof' for 'tcraddock at EXAMPLE.COM Full.Access'
> 2016/04/05 16:54:39.784| externalAclHandleReply: reply="ERR"
> 2016/04/05 16:54:39.785| external_acl_cache_add: Adding 'tcraddock at EXAMPLE.COM Full.Access' = 0
> 2016/04/05 16:54:39.785| aclMatchExternal: memberof = 0
> 
> In the file referenced in the ACLs:
> 
> acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
> acl FullAccess          external memberof "/etc/squid/full_access.txt"
> 
> 
> it has:
> 
> cat /etc/squid/full_access.txt
> Full.Access
> 
> cat /etc/squid/restricted_access.txt
> Restricted.Access
> 

Speaking of white spaces. The only reason for using files there is when
the group name contains a whitespace character. TO avoid a squid.conf
parser bug (Sorry). If those dots are in fact dots and not spaces, then
you dont need the extra files.


> Im not sure why the logs show my user is getting ERR as the response to group checking, when I run it from the command line, I get an OK.
> 
> 
> Info about my setup:
> 
> [root at clwslprox01p squid]# squid -v
> Squid Cache: Version 3.1.23
> configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--enable-internal-dns' '--disable-strict-error-checking' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-arp-acl' '--enable-follow-x-forwarded-for' '--enable-auth=basic,digest,ntlm,negotiate' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL,DB,POP3,squid_radius_auth' '--enable-ntlm-auth-helpers=smb_lm,no_check,fake
auth' '--enable-digest-auth-helpers=password,ldap,eDirectory' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-referer-log' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' '--enable-http-violations' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'LDFLAGS=-pie' 'CXXFLAGS=-O2 -g -pipe -Wall -W
p,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' --with-squid=/builddir/build/BUILD/squid-3.1.23
> 
> [root at clwslprox01p squid]# cat /etc/redhat-release
> Red Hat Enterprise Linux Server release 6.7 (Santiago)
> 
> Using negotiate w/NTLM and Kerberos to do user auth, and trying to use external helpers to do group lookups to a Windows AD.  Windows AD is 2008 and 2012 in my env.
> 
> Squid.conf:
> 
> 
> ### cache manager
> cache_mgr pclan at example.com
> 
> #Define the cache_peer to be used
> # cache_peer proxy1.ap.webscanningservice.com parent 3128 0000 default no-query no-digest
> # cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest
>   cache_peer proxy1.us.webscanningservice.com parent 3128 0000 default no-query no-digest
> # cache_peer proxy1.hk.webscanningservice.com parent 3128 0000 default no-query no-digest
> # cache_peer proxy1.eu.webscanningservice.com parent 3128 0000 default no-query no-digest
> 
> 
> ### negotiate kerberos and ntlm authentication
> auth_param negotiate program /usr/local/bin/negotiate_wrapper -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=EXAMPLE.COM --require-membership-of=EXAMPLE\\Full.Access -kerberos /usr/lib64/squid/squid_kerb_auth -d -s GSS_C_NO_NAME
> auth_param negotiate children 10
> auth_param negotiate keep_alive off
> 
> ### pure ntlm authentication
> auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --require-membership-of=EXAMPLE\\Full.Access
> auth_param ntlm children 30
> auth_param ntlm keep_alive off
> 
> ### provide basic authentication via ldap for clients not authenticated via kerberos/ntlm
> auth_param basic program /usr/lib64/squid/squid_ldap_auth -R -b "dc=example,dc=com" -D Squid at EXAMPLE.COM -W /etc/squid/password -f sAMAccountName=%s -h DC01.EXAMPLE.COM
> auth_param basic children 10
> auth_param basic realm Internet Proxy
> auth_param basic credentialsttl 1 minute
> 


Your NTLM and Negotiate authenticators have a parameter requiring
membership of the Ful.Access group as part of the auth process.

That means you should be able to use the auth type to tell what group
they are a member of.


> ### ldap authorisation
> external_acl_type memberof %LOGIN /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at EXAMPLE.COM -W /etc/squid/.ldappass.txt -f "(&(objectclass=person)(sAMAccountName=$)(memberof=cn=%g,ou=Some Group,dc=EXAMPLE,dc=COM))" -h DC01.EXAMPLE.COM
> 
> ### acl for proxy auth and ldap authorizations
> acl our_networks src  172.16.0.0/12 10.0.0.0/8 192.170.0.0/24
> acl INTERNAL dst 172.16.0.0/12 10.0.0.0/8
> acl auth proxy_auth REQUIRED
> acl HEAD method HEAD
> acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
> acl FullAccess          external memberof "/etc/squid/full_access.txt"
> acl Approved_Domains dstdomain "/etc/squid/acls/approved.txt"
> acl WindowsUpdate dstdomain -i "/etc/squid/acls/windowsupdates.txt"
> acl local-servers dstdomain "/etc/squid/acls/localservers.txt"
> acl RestrictedHost src "/etc/squid/acls/restrictedhost_ip.txt"
> acl bypass_auth src "/etc/squid/acls/bypass_auth_src_ip.txt"
> acl bypass_auth-external dstdomain "/etc/squid/acls/bypass_auth_dst_domain.txt"
> acl blocksites dstdomain "/etc/squid/acls/block_sites.txt"
> acl DIRECT src "/etc/squid/acls/direct_src_ip.txt"
> acl DIRECT-external dstdomain "/etc/squid/acls/direct_dst_domains.txt"
> acl Smartconnect dstdomain ned.webscanningservice.com
> acl Java browser Java/[0-9]
> acl JavaSites dstdomain .gotomeeting.com
> always_direct allow INTERNAL
> always_direct allow local-servers
> cache deny INTERNAL
> cache deny local-servers
> 
> 
> 
> ### squid defaults
> acl manager proto cache_object
> acl localhost src 127.0.0.1/32 ::1
> acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
> acl SSL_ports port 443 563 33808
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443 563     # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> #allow custom ports
> acl goto_meeting dst 216.115.208.0/20 216.219.112.0/20 66.151.158.0/24 66.151.150.160/27 66.151.115.128/26 64.74.80.0/24 202.173.24.0/21 67.217.64.0/19 78.108.112.0/20 68.64.0.0/19 206.183.100.0/22
> acl Safe_ports port 8200        # gotomeeting
> acl Safe_ports port 31303 33808 # TD Merchant
> acl Safe_ports port 8443        # Symantec SEP Manager
> acl Safe_ports port 8014               # Symantec SEPM Client
> acl SSL_ports port 9443         # pingdevfed
> acl SSL_ports port 9444         # pingdevfed
> acl SSL_ports port 5443         # pingdev
> acl CONNECT method CONNECT
> http_access allow manager localhost
> http_access deny manager
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> #http_access deny !memberof
> http_access allow localhost
> http_access allow HEAD
> http_access deny !our_networks
> http_access allow Smartconnect
> http_access deny blocksites all
> http_access allow Approved_Domains
> http_access deny RestrictedHost all
> http_access allow FullAccess auth

NP: FullAccess and auth ACLs require authentication to take place.

What is the point of the Java and WindowsUpdate and bypass_auth ACLs
being tested *after* auth has already been required of the client?

Surely the bypasses should be first and the auth related things after.

> http_access allow Java
> http_access allow WindowsUpdate
> http_access allow bypass_auth
> http_access allow bypass_auth-external
> http_access allow goto_meeting
> http_access allow our_networks all
> http_access allow Java our_networks JavaSites
> http_access allow auth
> http_access deny !auth
> http_access deny all
> 

Generally the best pattern to use when designing http_access sequences
is this:

+ allow <things that bypass auth>
+ "deny !auth"
+ allow <things that require auth>
+ "deny all"



Amos




From Ralf.Hildebrandt at charite.de  Wed Apr  6 12:42:45 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Wed, 6 Apr 2016 14:42:45 +0200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <20160406122019.GE4978@charite.de>
References: <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <20160406122019.GE4978@charite.de>
Message-ID: <20160406124245.GF4978@charite.de>

* Ralf Hildebrandt <Ralf.Hildebrandt at charite.de>:
> * Amos Jeffries <squid3 at treenet.co.nz>:
> 
> > Can somebody check whether applying the attached patch _and_ clearing
> > the cache does anything useful?
> > (should apply with "patch -p0" to squid-3.5.16)
> > 
> > If the answer is yes, then it can be used while I work on a better fix
> > that wont need clearing the cache.
> 
> Rebuilt, reinstalled, cache cleared & restarted...

It SEEMS to work. All I see now are a some messages like:

2016/04/06 14:34:23| Exception error:corrupted chunk extension value
2016/04/06 14:34:47| Exception error:corrupted chunk extension value
2016/04/06 14:34:54| Exception error:corrupted chunk extension value
2016/04/06 14:34:57| Exception error:corrupted chunk extension value

and

2016/04/06 14:40:16| Exception error:found data between chunk end and CRLF
2016/04/06 14:40:53| Exception error:found data between chunk end and CRLF
2016/04/06 14:41:14| Exception error:found data between chunk end andCRLF

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From squid3 at treenet.co.nz  Wed Apr  6 13:01:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Apr 2016 01:01:47 +1200
Subject: [squid-users] Sending intermediate certificate with SSL-Bumped
 Certificate. (V3.5.1516-3-2-r14000)
In-Reply-To: <cf0f6972f77514fcaaddcf18736f4b4a@smoothnet.org>
References: <cf0f6972f77514fcaaddcf18736f4b4a@smoothnet.org>
Message-ID: <570508BB.6040103@treenet.co.nz>

On 6/04/2016 10:49 a.m., Nicolaas Hyatt wrote:
> I know I'm a few minor revisions behind, but I am a little confused as
> to if it is possible to request squid include the configured certificate
> along with the certificate generated. I know that this is somewhat
> confusing to read.
> 
> +Root (Self Signed) CA Cert
> |
> `+ Intermediate Certificate (Used by squid.)
>  |
>  `- Squid Auto Generated Certificate
> 
> I have the Self Signed Root CA Cert installed on all the systems, but
> the Intermediate Certificate is not sent by squid, so the trust chain
> fails. I have been reading threads here and there and saw a post form
> Amos a bit ago (referring to squid v3.3) where there may (or may not)
> have been a configuration option to modify squid's behavior to do as I
> am requesting, but details in the thread do not include the
> configuration directive.

FYI: each of the Squid 3.2 -> 4.0 series so far have had significantly
different TLS handling code. So commments about one series are unlikely
to be relevant to the others, particularly in regards to SSL-Bump
functionality.

> 
> If this is not a valid feature, I understand, and can fully accept that
> answer, I'm not complaining about free software!

This is one of the things that is currently still being sorted out. In
some cases the current releases should just send the certs, in some it
should not, in others it should but doesn't. So YMMV.

The patch that just went in today sounds to me like what you are
needing. So you might want to try the Squid-4.0.8 with this extra patch
(<http://www.squid-cache.org/Versions/v4/changesets/squid-4-14626.patch>) or
a 4.0 daily snapshot rev.14626 (or later) when it becomes available.

Amos



From pascal at watteel.be  Wed Apr  6 13:14:10 2016
From: pascal at watteel.be (Pascal Watteel)
Date: Wed, 6 Apr 2016 13:14:10 +0000
Subject: [squid-users] select parent proxy based on ACL
In-Reply-To: <5704FA5C.2020600@treenet.co.nz>
References: <1459857825.9684.21.camel@watteel.be>
 <1459858102.9684.23.camel@watteel.be> <1459921092.9684.28.camel@watteel.be>
 <5704FA5C.2020600@treenet.co.nz>
Message-ID: <1459948450.9684.43.camel@watteel.be>

Ok maybe it was't all clear.

I live in Dubai. Our local ISP limits the bandwith per TCP connection
when connections are made outside of the gulf.
Don't ask me why, they just do.
I have a fast 128Mbit link but as i'm limited to 4Mbit per TCP, the
moment i download a file from a non local mirror it's slow.

Aria2c or Uget works perfect on my desktop but i wanted a solution that
would work universal without any software on a pc.

the solution is ranged downloads if the server supports it.
This will make my download split in example 16 ranged byte gets -> 16
TCP connections => 16X 4Mbit => descent download speed.

My solution was to write a python based proxy.
https://github.com/intagger/paraproxio

It does exaclty that but in a proxy form.?
Anything that is not .iso .zip or other that you can define in the
config will just be transparent. Anything that is defined will be split
in segmented downloads and so downloaded faster on my ISP.

Now i already have a Squid proxy in my network with a another Squid
proxy parent in AWS.
I use the proxy for local caching nothing fancy, But use the parent
with an acl to send specific domains to the parent and so enable me to
access sites without the need of a VPN.

I now want to add my Python based proxy as another parent.
However i have no option to tell squid what parent to use.
I would like to create a regex acl in squid and someway tell squid to
use parent proxy X for ACL_X and parent proxy Y for ACL Y.
But i can only use the ACL to say direct or indirect.

And use the proxy-peer-domain statement to choose the parent based on a
domain or tld.

so my question is how to make squid choose the parent based on an ACL.

hope this explanes it better for you.
what my parent does, is not important. It could be anyother parent
proxy.


















On Thu, 2016-04-07 at 00:00 +1200, Amos Jeffries wrote:
> On 6/04/2016 5:38 p.m., Pascal Watteel wrote:
> > 
> > anyone?
> NP: Messages sent at 12am should be expected to have some response
> delay. (and its always 12am somewhere in the world :-).
> 
> > 
> > 
> > On Tue, 2016-04-05 at 12:08 +0000, Pascal Watteel wrote:
> > > 
> > > Hi peeps,
> > > 
> > > I have written a python based download accelerator based proxy.
> > > It does exactly the same thing as what aria2c would do, but as a
> > > proxy.
> Huh?
> 
> aria2c is a "client" (or "user agent") in HTTP terminology.
> 
> A proxy is ... a proxy. Which is to say both client and server. But
> definitely NOT a user-agent.
> 
> So either you have written a proxy, or you have written something
> like
> aria2c. Not both.
> 
> "accelerator" is a marketing jargon word. Particularly when used in
> the
> phrase "download acclerator".
> 
> 
> > 
> > > 
> > > 
> > > I now want to tell squid to only send .zip .iso .whatever to this
> > > proxy
> > > as an parent proxy.
> > > But i only find a way how to tell squid to do this for domains
> > > with
> > > peer_domain.
> > > 
> > > Is there a way how i can tell squid to decide the parent proxy
> > > based
> > > on
> > > a ACL so i can just use regex define the files i wanna send to
> > > this
> > > parent?
> > > 
> Terminology clash again. Squid does not send files anywhere. Two
> reasons
> for that:
> 
> 1) HTTP is a "pull" protocol: Requests go out (aka "send"). Responses
> come back (aka "receive"). That is all.
> 
> 2) HTTP has therefore no protocol concept of "files". Squid is only
> aware of the response content-type (note that its "payload" or
> "content", not 'file') when it is already on its way back to the
> client.
> Far too late to decide which server to send the request message to.
> 
> 
> I *think* what you are asking for is:
> ?<http://www.squid-cache.org/Doc/config/cache_peer_access/>
> 
> But I am seriously doubting whether you have the right HTTP model
> with
> all this malformed terminology you are using.
> 
> You can approximately guess what the traffic will be by urlpath_regex
> matching the URL path values. But unless you control the servers URL
> design that is just a rough guess.
> 
> 
> PS. "download accelerator" is an old concept from the days 20-odd
> years
> go when networks were slow and HTTP/1.0 was wasting bandwidth to make
> things slower. As with all old concepts in HTTP Squid probably
> already
> does it in one way or several.
> In particular modern HTTP/1.1 plus Caching obsoletes almost all
> "download accelerator" designs in a much more efficient way.
> ?If you describe what you actualy want the whole system to do in a
> clear
> way we can perhapse provide you with squid.conf settings to avoid
> needing the extra layer of custom proxy software.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

From chip_pop at hotmail.com  Wed Apr  6 13:20:36 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 06:20:36 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <5704FDA4.60606@treenet.co.nz>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz>
Message-ID: <1459948836715-4676962.post@n4.nabble.com>

amos

vary.length()    = 33
vary.c_str()    = accept-encoding="gzip,%20deflate"
 so without +1 is fine



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676962.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Apr  6 13:54:48 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Apr 2016 01:54:48 +1200
Subject: [squid-users] select parent proxy based on ACL
In-Reply-To: <1459948450.9684.43.camel@watteel.be>
References: <1459857825.9684.21.camel@watteel.be>
 <1459858102.9684.23.camel@watteel.be> <1459921092.9684.28.camel@watteel.be>
 <5704FA5C.2020600@treenet.co.nz> <1459948450.9684.43.camel@watteel.be>
Message-ID: <57051528.7090409@treenet.co.nz>

Comments inline, For the TL;DR skip to the bottom.

On 7/04/2016 1:14 a.m., Pascal Watteel wrote:
> Ok maybe it was't all clear.
> 
> I live in Dubai. Our local ISP limits the bandwith per TCP connection
> when connections are made outside of the gulf.
> Don't ask me why, they just do.
> I have a fast 128Mbit link but as i'm limited to 4Mbit per TCP, the
> moment i download a file from a non local mirror it's slow.

That is very odd. Are you sure its not a problem created by some
partially broken hardware somewhere? if they are selling you 128Mbps it
should work (close to) full rate with 1 TCP connection as well as with many.
Perhapse you should try and talk to the ISP sysadmin to see if it is
intentional (if so why its done) or a bug in the network itself.

> 
> Aria2c or Uget works perfect on my desktop but i wanted a solution that
> would work universal without any software on a pc.
> 
> the solution is ranged downloads if the server supports it.
> This will make my download split in example 16 ranged byte gets -> 16
> TCP connections => 16X 4Mbit => descent download speed.

"descent" is the right word for it. Descent into network congestion for
your ISP. :-P

If they are doing their job well you will find that this type of
behaviour actually lowers your network performance and/or raises the
monetary cost. If you actually tested and found that 16x increase
happens then they are not doing their job well - or perhapse the 'limit'
is actually an artifact of the network structure rather than any imposed
shaping.

If they are doing their job very badly you might find the same, only
everyone else using them has worse network experience too as the
congestion hits everyone.


> 
> My solution was to write a python based proxy.
> https://github.com/intagger/paraproxio
> 
> It does exaclty that but in a proxy form. 
> Anything that is not .iso .zip or other that you can define in the
> config will just be transparent. Anything that is defined will be split
> in segmented downloads and so downloaded faster on my ISP.
> 
> Now i already have a Squid proxy in my network with a another Squid
> proxy parent in AWS.
> I use the proxy for local caching nothing fancy, But use the parent
> with an acl to send specific domains to the parent and so enable me to
> access sites without the need of a VPN.
> 
> I now want to add my Python based proxy as another parent.
> However i have no option to tell squid what parent to use.
> I would like to create a regex acl in squid and someway tell squid to
> use parent proxy X for ACL_X and parent proxy Y for ACL Y.
> But i can only use the ACL to say direct or indirect.
> 
> And use the proxy-peer-domain statement to choose the parent based on a
> domain or tld.
> 
> so my question is how to make squid choose the parent based on an ACL.
> 
> hope this explanes it better for you.
> what my parent does, is not important. It could be anyother parent
> proxy.
> 

Okay. What you are wanting is definitely
<http://www.squid-cache.org/Doc/config/cache_peer_access/>.

I suggest you may also want to look into the Store-ID and collapsed
forwarding features in Squid if you have one that supports them. Both of
them allow Squid to de-duplicate requests for identical objects. If your
custom Range requests reach a Squid with collapsed forwarding enabled
that Squid might even de-duplicate them back into a single fetch (for
example in your ISPs network).

Amos



From chip_pop at hotmail.com  Wed Apr  6 13:26:15 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 06:26:15 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459948836715-4676962.post@n4.nabble.com>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
Message-ID: <1459949175747-4676964.post@n4.nabble.com>

vary.length()      =       41
vary.c_str()        =      accept-encoding="gzip,%20deflate,%20sdch"



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676964.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Wed Apr  6 14:02:29 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 6 Apr 2016 16:02:29 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <5704FDA4.60606@treenet.co.nz>
Message-ID: <944185771.80114262.1459951349488.JavaMail.root@zimbra4-e1.priv.proxad.net>

Oh sorry 
Ok it seems work for me


From squid3 at treenet.co.nz  Wed Apr  6 14:05:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Apr 2016 02:05:55 +1200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459948836715-4676962.post@n4.nabble.com>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
Message-ID: <570517C3.2080805@treenet.co.nz>

On 7/04/2016 1:20 a.m., joe wrote:
> amos
> 
> vary.length()    = 33
> vary.c_str()    = accept-encoding="gzip,%20deflate"
>  so without +1 is fine
> 

Nod. What I'm thinking is that old Squid versions saved the string
terminator byte to the cache entries, and builds with the +1 replicate
that. BuUT that is being loaded back as part of the string (counted in
length). So the compare against the new un-terminated strings now fails
due to different lengths (off-by-1) and re-saving it to disk might make
length +2 (and +3 on the next cycle etc).

Attached is a patch which I think will fix 3.5.16 (should apply fine on
4.0.8 too) without needing the cache reset. Anyone able to test it please?

Amos

-------------- next part --------------
=== modified file 'src/StoreMetaVary.cc'
--- src/StoreMetaVary.cc	2016-04-01 06:15:31 +0000
+++ src/StoreMetaVary.cc	2016-04-06 13:18:55 +0000
@@ -22,6 +22,9 @@
         /* XXX separate this mutator from the query */
         /* Assume the object is OK.. remember the vary request headers */
         e->mem_obj->vary_headers.assign(static_cast<const char *>(value), length);
+        /* entries created before SBuf vary handling may include string terminator */
+        static const SBuf nul("\0", 1);
+        e->mem_obj->vary_headers.trim(nul);
         return true;
     }
 

=== modified file 'src/store_swapmeta.cc'
--- src/store_swapmeta.cc	2016-04-01 06:15:31 +0000
+++ src/store_swapmeta.cc	2016-04-06 12:03:43 +0000
@@ -89,9 +89,7 @@
     SBuf vary(e->mem_obj->vary_headers);
 
     if (!vary.isEmpty()) {
-        // TODO: do we still need +1 here? StoreMetaVary::checkConsistency
-        //       no longer relies on nul-termination, but other things might.
-        t = StoreMeta::Factory(STORE_META_VARY_HEADERS, vary.length() + 1, vary.c_str());
+        t = StoreMeta::Factory(STORE_META_VARY_HEADERS, vary.length(), vary.c_str());
 
         if (!t) {
             storeSwapTLVFree(TLV);


From fredbmail at free.fr  Wed Apr  6 14:10:15 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 6 Apr 2016 16:10:15 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <570517C3.2080805@treenet.co.nz>
Message-ID: <770168678.80144344.1459951815746.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> Attached is a patch which I think will fix 3.5.16 (should apply fine
> on
> 4.0.8 too) without needing the cache reset. Anyone able to test it
> please?
> 

Reset the cache still needed, at least in my case 

Fred


From chip_pop at hotmail.com  Wed Apr  6 13:42:53 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 06:42:53 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <770168678.80144344.1459951815746.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz>
 <770168678.80144344.1459951815746.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1459950173942-4676968.post@n4.nabble.com>

yes

FredB wrote
>> 
>> Attached is a patch which I think will fix 3.5.16 (should apply fine
>> on
>> 4.0.8 too) without needing the cache reset. Anyone able to test it
>> please?
>> 
> 
> Reset the cache still needed, at least in my case 
> 
> Fred
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676968.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From freebsd at lidstrom.eu  Wed Apr  6 14:18:09 2016
From: freebsd at lidstrom.eu (=?UTF-8?Q?Henrik_Lidstr=c3=b6m?=)
Date: Wed, 6 Apr 2016 16:18:09 +0200
Subject: [squid-users] select parent proxy based on ACL
In-Reply-To: <1459948450.9684.43.camel@watteel.be>
References: <1459857825.9684.21.camel@watteel.be>
 <1459858102.9684.23.camel@watteel.be> <1459921092.9684.28.camel@watteel.be>
 <5704FA5C.2020600@treenet.co.nz> <1459948450.9684.43.camel@watteel.be>
Message-ID: <57051AA1.50903@lidstrom.eu>


On 04/06/16 15:14, Pascal Watteel wrote:
> I have a fast 128Mbit link but as i'm limited to 4Mbit per TCP, the
> moment i download a file from a non local mirror it's slow.
>

Thats sound a bit like window scaling (rfc1323) is disabled/not working.

/Henrik


From chip_pop at hotmail.com  Wed Apr  6 14:34:18 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 07:34:18 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <570517C3.2080805@treenet.co.nz>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz>
Message-ID: <1459953258060-4676970.post@n4.nabble.com>

working nice :)       vary_experiment_p2_s35.patch 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676970.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From odhiambo at gmail.com  Wed Apr  6 15:16:18 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Wed, 6 Apr 2016 18:16:18 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
Message-ID: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>

I am getting the following error in cache.log:

Squid Cache (Version 3.5.16): Terminated abnormally.
CPU Usage: 0.082 seconds = 0.052 user + 0.030 sys
Maximum Resident Size: 54992 KB
Page faults with physical i/o: 0
FATAL: Ipc::Mem::Segment::create failed to
shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File exists


However, that file doesn't exist.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160406/72b6e7cf/attachment.htm>

From chip_pop at hotmail.com  Wed Apr  6 15:03:28 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 08:03:28 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <570517C3.2080805@treenet.co.nz>
References: <1875985969.73092830.1459758487151.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz>
Message-ID: <1459955008255-4676972.post@n4.nabble.com>

befor clearing cache

2016/04/06 18:15:43 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/04/06 18:15:43 kid1| 	/mnt/cache/00/25/00002523
2016/04/06 18:15:47 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/04/06 18:15:47 kid1| 	/mnt/cache/00/03/000003D5
2016/04/06 18:15:47 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory

after i clear the cache no error so fare 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676972.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From odhiambo at gmail.com  Wed Apr  6 15:57:22 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Wed, 6 Apr 2016 18:57:22 +0300
Subject: [squid-users] compiling 4.0.8 on FreeBSD-10.1
Message-ID: <CAAdA2WODXj0oeDr9q3t0dOPFSS+4HAy1zmVpTiiaV=pWAbs46Q@mail.gmail.com>

Hi,

My configure options:


setenv CC  clang
setenv CXX clang++

CPPFLAGS=-I/usr/local/include

./configure --prefix=/opt/squid-4 \
        --enable-debug-cbdata \
        --enable-removal-policies="lru heap" \
        --disable-epoll \
        --enable-auth \
        --enable-auth-basic="DB NCSA PAM PAM POP3" \
        --with-pthreads \
        --enable-storeio="ufs diskd aufs" \
        --enable-delay-pools \
        --enable-snmp  \
        --with-openssl=/usr \
        --enable-forw-via-db \
        --enable-cache-digests \
        --enable-wccpv2 \
        --enable-follow-x-forwarded-for \
        --with-large-files \
        --enable-large-cache-files \
        --enable-esi \
        --enable-kqueue \
        --enable-icap-client \
        --enable-kill-parent-hack \
        --enable-ssl \
        --enable-ssl-crtd \
        --enable-url-rewrite-helpers \
        --enable-xmalloc-statistics \
        --enable-stacktraces \
        --enable-eui \
        --enable-zph-qos \
        --with-nat-devpf \
        --enable-pf-transparent
#       --enable-ipf-transparent


The error I get during `make` is:

root at mail:~wash/ILI/Squid/4.x/squid-4.0.8 # make
Making all in compat
depbase=`echo assert.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`; /bin/sh
../libtool  --tag=CXX    --mode=compile c++ -DHAVE_CONFIG_H    -I..
-I../include  -I../lib -I../src  -I../include  -I/usr/include
 -I/usr/include  -I../libltdl -I/usr/include -I/usr/local/include/libxml2
 -I/usr/local/include/libxml2  -Werror -Qunused-arguments
-Wno-deprecated-register  -D_REENTRANT -g -O2 -march=native -std=c++11
-I/usr/local/include -MT assert.lo -MD -MP -MF $depbase.Tpo -c -o assert.lo
assert.cc && mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  c++ -DHAVE_CONFIG_H -I.. -I../include -I../lib -I../src
-I../include -I/usr/include -I/usr/include -I../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT assert.lo -MD -MP -MF
.deps/assert.Tpo -c assert.cc  -fPIC -DPIC -o .libs/assert.o
libtool: compile:  c++ -DHAVE_CONFIG_H -I.. -I../include -I../lib -I../src
-I../include -I/usr/include -I/usr/include -I../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT assert.lo -MD -MP -MF
.deps/assert.Tpo -c assert.cc -o assert.o >/dev/null 2>&1
depbase=`echo compat.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`; /bin/sh
../libtool  --tag=CXX    --mode=compile c++ -DHAVE_CONFIG_H    -I..
-I../include  -I../lib -I../src  -I../include  -I/usr/include
 -I/usr/include  -I../libltdl -I/usr/include -I/usr/local/include/libxml2
 -I/usr/local/include/libxml2  -Werror -Qunused-arguments
-Wno-deprecated-register  -D_REENTRANT -g -O2 -march=native -std=c++11
-I/usr/local/include -MT compat.lo -MD -MP -MF $depbase.Tpo -c -o compat.lo
compat.cc && mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  c++ -DHAVE_CONFIG_H -I.. -I../include -I../lib -I../src
-I../include -I/usr/include -I/usr/include -I../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT compat.lo -MD -MP -MF
.deps/compat.Tpo -c compat.cc  -fPIC -DPIC -o .libs/compat.o
libtool: compile:  c++ -DHAVE_CONFIG_H -I.. -I../include -I../lib -I../src
-I../include -I/usr/include -I/usr/include -I../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT compat.lo -MD -MP -MF
.deps/compat.Tpo -c compat.cc -o compat.o >/dev/null 2>&1
depbase=`echo debug.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`; /bin/sh
../libtool  --tag=CXX    --mode=compile c++ -DHAVE_CONFIG_H    -I..
-I../include  -I../lib -I../src  -I../include  -I/usr/include
 -I/usr/include  -I../libltdl -I/usr/include -I/usr/local/include/libxml2
 -I/usr/local/include/libxml2  -Werror -Qunused-arguments
-Wno-deprecated-register  -D_REENTRANT -g -O2 -march=native -std=c++11
-I/usr/local/include -MT debug.lo -MD -MP -MF $depbase.Tpo -c -o debug.lo
debug.cc && mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  c++ -DHAVE_CONFIG_H -I.. -I../include -I../lib -I../src
-I../include -I/usr/include -I/usr/include -I../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT debug.lo -MD -MP -MF
.deps/debug.Tpo -c debug.cc  -fPIC -DPIC -o .libs/debug.o
libtool: compile:  c++ -DHAVE_CONFIG_H -I.. -I../include -I../lib -I../src
-I../include -I/usr/include -I/usr/include -I../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT debug.lo -MD -MP -MF
.deps/debug.Tpo -c debug.cc -o debug.o >/dev/null 2>&1
depbase=`echo eui64_aton.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`; /bin/sh
../libtool  --tag=CC    --mode=compile gcc -DHAVE_CONFIG_H    -I..
-I../include  -I../lib -I../src  -I../include  -I/usr/include
 -I/usr/include  -I../libltdl -I/usr/include -I/usr/local/include/libxml2
 -Werror -Qunused-arguments  -D_REENTRANT -g -O2 -I/usr/local/include -MT
eui64_aton.lo -MD -MP -MF $depbase.Tpo -c -o eui64_aton.lo eui64_aton.c &&
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  gcc -DHAVE_CONFIG_H -I.. -I../include -I../lib -I../src
-I../include -I/usr/include -I/usr/include -I../libltdl -I/usr/include
-I/usr/local/include/libxml2 -Werror -Qunused-arguments -D_REENTRANT -g -O2
-I/usr/local/include -MT eui64_aton.lo -MD -MP -MF .deps/eui64_aton.Tpo -c
eui64_aton.c  -fPIC -DPIC -o .libs/eui64_aton.o
gcc: error: unrecognized command line option '-Qunused-arguments'
*** Error code 1

Stop.
make[1]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/compat
*** Error code 1

Stop.
make: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160406/5b88054e/attachment.htm>

From Sebastien.Boulianne at cpu.ca  Wed Apr  6 17:24:32 2016
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Wed, 6 Apr 2016 13:24:32 -0400
Subject: [squid-users] Attached file on OWA with Squid
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5837FD147F@CPUMAIL2.cpu.qc.ca>

I configured my OWA to pass thru the Squid.
Auth work perfectly.
Browsing is working perfectly.
All is working perfectly except when I try to attach files or documents to an email.

[cid:image002.png at 01D19007.A7E26D20]


And It stops here. Nothing else happens.

I did some tests and I noticed that happens when I am connecting from external to OWA.
If I connect to the VPN then I try to send an attached file with the OWA, it works.

Here is my config for my OWA.

### OWA
cache_peer owa.domain.qc.ca parent 443 0 no-query originserver login=PASS ssl sslcert=/etc/pki/tls/certs/domain.qc.ca.cert.pem sslkey=/etc/pki/tls/private/domain.qc.ca.key.pem options=NO_SSLv2:NO_SSLv3:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE dhparams=/etc/pki/tls/private/dhparams.pem cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS name=owa
acl owahttps url_regex ^https://owa\.domain\.qc\.ca
cache_peer_access owa allow owahttps
http_access allow www443 owahttps
acl owahttp url_regex ^http://owa\.domain\.qc\.ca
http_access deny owahttp
deny_info 302:https://%H%R owahttp

Thanks you very much for your advice.

S?bastien.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160406/43481071/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 50172 bytes
Desc: image002.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160406/43481071/attachment.png>

From spider at smoothnet.org  Wed Apr  6 17:25:50 2016
From: spider at smoothnet.org (Nicolaas Hyatt)
Date: Wed, 06 Apr 2016 12:25:50 -0500
Subject: [squid-users] Sending intermediate certificate with SSL-Bumped
 Certificate. (V3.5.1516-3-2-r14000)
Message-ID: <e816f8036c6f8912fd6bb6eda5717889@smoothnet.org>

Amos,
Thanks for your quick response and your time. I have not yet messed with 
4.0. Is this something that may find its way into the 3.x stable branch 
at some point?




From chip_pop at hotmail.com  Wed Apr  6 17:05:25 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 10:05:25 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459955008255-4676972.post@n4.nabble.com>
References: <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz> <1459955008255-4676972.post@n4.nabble.com>
Message-ID: <1459962325673-4676976.post@n4.nabble.com>

amos question ?

off topic sorry for that 

vary is the second key store right ?

same object with 2 browser  firefox
accept-encoding="gzip,%20deflate"

chrome
accept-encoding="gzip,%20deflate,%20sdch"

so if they ar 2*1 object stored is that right   ? 
and other browser might have more compression 
accept-encoding="gzip,%20deflate,%xxxxxxxxxxx
that will be 3*1   right  if yes   why not filtering only the one has (not
%) = accept-encoding="gzip"
and use that only it will be beter hit and save more storage
just idea what you think  ??  since "%"  meaning those compression not used
for the object only
the one without it 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676976.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Wed Apr  6 21:00:45 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 14:00:45 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459962325673-4676976.post@n4.nabble.com>
References: <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz> <1459955008255-4676972.post@n4.nabble.com>
 <1459962325673-4676976.post@n4.nabble.com>
Message-ID: <1459976445655-4676977.post@n4.nabble.com>

more result of that bug as i mention befor that
using same link  on firefox  keep refreshing   no error
once i switch to chrome error  so i switch between chrome and firefox   the
error keep going on same object
only on same browser  you wont notice any error 

please guys  do same test  don't depend on one browser 


chrome
-------
2016/04/07 00:15:44.760 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://api-public.addthis.com/url/shares.json?url=http%3A%2F%2Fwww.tayyar.org%2F&callback=_ate.cbs.sc_httpwwwtayyarorg0'
'accept-encoding="gzip,%20deflate,%20sdch"
2016/04/07 00:15:44.760 kid1| clientProcessHit: Vary object loop!
vary.length() = 41 
vary.c_str()) = accept-encoding="gzip,%20deflate,%20sdch"


firefox
--------
2016/04/07 00:16:23.512 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://api-public.addthis.com/url/shares.json?url=http%3A%2F%2Fwww.tayyar.org%2F&callback=_ate.cbs.sc_httpwwwtayyarorg0'
'accept-encoding="gzip,%20deflate"'
2016/04/07 00:16:23.512 kid1| clientProcessHit: Vary object loop!
vary.length() = 33 
vary.c_str()) = accept-encoding="gzip,%20deflate"

so  what amos fix is good but not for this    its continue of the bug
so i don't know if we should call it different bug or  its continuing of the
same bug



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676977.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Wed Apr  6 21:05:01 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 6 Apr 2016 14:05:01 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459976445655-4676977.post@n4.nabble.com>
References: <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz> <1459955008255-4676972.post@n4.nabble.com>
 <1459962325673-4676976.post@n4.nabble.com>
 <1459976445655-4676977.post@n4.nabble.com>
Message-ID: <1459976701729-4676978.post@n4.nabble.com>

forgot to post full req. rep...


http://api-public.addthis.com/url/shares.json?url=http%3A%2F%2Fwww.tayyar.org%2F&callback=_ate.cbs.sc_httpwwwtayyarorg0

GET
/url/shares.json?url=http%3A%2F%2Fwww.tayyar.org%2F&callback=_ate.cbs.sc_httpwwwtayyarorg0
HTTP/1.1
Host: api-public.addthis.com
User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:43.0) Gecko/20100101
Firefox/43.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
DNT: 1
Cookie: uid=56c8f85e0c04ec43;
uvc=126%7C10%2C254%7C11%2C239%7C12%2C86%7C13%2C142%7C14; ssc=google%3B18;
loc=MDAwMDBBU0xCMDAyMTM4MjE1NTAwMDAwMDAwVg==; dt=X; di2=O3WJL4.UYM; vc=3;
bt2=56e48cd7001Es0002003ys0002; __atuvc=1%7C12%2C2%7C13%2C1%7C14
Connection: keep-alive
Pragma: no-cache
Cache-Control: no-cache

HTTP/1.1 200 OK
Date: Wed, 06 Apr 2016 21:18:59 GMT
Content-Type: application/json
Content-Length: 66
Cache-Control: no-transform, must-revalidate, max-age=0, s-maxage=3600
Surrogate-Key: www.tayyar.org/
Last-Modified: Wed, 06 Apr 2016 19:58:29 GMT
Content-Encoding: gzip
X-Varnish: 2775916359 2772615008
Via: 1.1 varnish
Vary: Accept-Encoding
Accept-Ranges: bytes
Server: cloudflare-nginx
Age: 991
X-Cache: HIT from proxy.netgatesss.com
Connection: keep-alive




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676978.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ibarra at ith.mx  Wed Apr  6 21:55:56 2016
From: ibarra at ith.mx (ibarra at ith.mx)
Date: Wed, 6 Apr 2016 15:55:56 -0600 (MDT)
Subject: [squid-users] squid and hotmail problems
Message-ID: <65000.187.191.54.243.1459979756.squirrel@ith.mx>

>From about 10 days ago hotmail and yahoo stopped working on my data networks
using squid. Does anyone else have this problem? Apparently there is a problem
with the SSL certificates. Any solution?

Thanks
Fco Ibarra Lemas




From Antony.Stone at squid.open.source.it  Wed Apr  6 22:16:19 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 7 Apr 2016 00:16:19 +0200
Subject: [squid-users] squid and hotmail problems
In-Reply-To: <65000.187.191.54.243.1459979756.squirrel@ith.mx>
References: <65000.187.191.54.243.1459979756.squirrel@ith.mx>
Message-ID: <201604070016.20130.Antony.Stone@squid.open.source.it>

On Wednesday 06 April 2016 at 23:55:56, ibarra at ith.mx wrote:

> From about 10 days ago hotmail and yahoo stopped working on my data
> networks using squid.

Do you have any error messages / logfile entries / configuration information / 
etc you might be able to share with us?

> Apparently there is a problem with the SSL certificates.

Well, what problem?

More information => more likelihood of a solution.


Antony.

-- 
Ren? Descartes walks in to a bar.
The barman asks him "Do you want a drink?"
Descartes says "I think not," and disappears.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From crmanik at gmail.com  Thu Apr  7 00:31:22 2016
From: crmanik at gmail.com (crmanik)
Date: Wed, 6 Apr 2016 17:31:22 -0700 (PDT)
Subject: [squid-users] Unable to Proxy https traffic using squid
Message-ID: <1459989082183-4676981.post@n4.nabble.com>

Hi,

  I'm trying to intercept and proxy https traffic using squid 3.5.15 running
on linux machine [ubuntu ], which   is configured  as a router.  However
with below squid configuration, the browsers in client machine is able to
identify that there is a ?man in the middle? and never gives me an option to
accept the certificate generated by squid. Can some one please review the
configuration and let me know what I'm missing:

cat squid.conf

sslcrtd_program
/home/crmanik/squid/squid-3.5.15-20160330-r14015/libexec/ssl_crtd -s
/home/crmanik/tmp/squid/ssl_db -M 4MB
http_port 3128
https_port 3130 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB key=/home/crmanik/tmp/squid/certs/server.key
cert=/home/crmanik/tmp/squid/certs/server.crt


acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all
### New config ends
sslproxy_capath /etc/ssl/certs
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

access_log /home/crmanik/tmp/squid/log/access.log
cache_log  /home/crmanik/tmp/squid/log/cache.log
cache_store_log /home/crmanik/tmp/squid/log/store.log
logfile_rotate 0

===============================================
Squid Compile Option:

Squid Configure Options:Squid Cache: Version 3.5.15-20160330-r14015
Service Name: squid
configure options:  '--disable-dependency-tracking' '--disable-silent-rules'
'--enable-inline' '--enable-async-io=8' '--enable-follow-x-forwarded-for'
'--enable-linux-netfilter' 'CFLAGS=-g -O2 -fPIE -fstack-protector
--param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security' 'LDFLAGS=-Wl,-Bsymbolic-functions -fPIE -pie
-Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2
-fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security' '--with-openssl'
'--prefix=/home/crmanik/squid/squid-3.5.15-20160330-r14015'
'--enable-ssl-crtd' ?enable-ltdl-convenience
================================================
iptable Configuration:
crmanik at crmanik-HP-Z600-Workstation:~/squid/squid-3.5.15-20160330-r14015$
sudo iptables -t nat -nvL
Chain PREROUTING (policy ACCEPT 31983 packets, 4632K bytes)
 pkts bytes target     prot opt in     out     source              
destination         
    0     0 REDIRECT   tcp  --  br-lan *       0.0.0.0/0           
0.0.0.0/0            tcp dpt:80 redir ports 3128
  500 30000 REDIRECT   tcp  --  eth1   *       0.0.0.0/0           
0.0.0.0/0            tcp dpt:80 redir ports 3128
 1368 82080 REDIRECT   tcp  --  eth1   *       0.0.0.0/0           
0.0.0.0/0            tcp dpt:443 redir ports 3130

Chain INPUT (policy ACCEPT 32548 packets, 4662K bytes)
 pkts bytes target     prot opt in     out     source              
destination         

Chain OUTPUT (policy ACCEPT 5409 packets, 339K bytes)
 pkts bytes target     prot opt in     out     source              
destination         

Chain POSTROUTING (policy ACCEPT 1293 packets, 83596 bytes)
 pkts bytes target     prot opt in     out     source              
destination         
24520 1537K MASQUERADE  all  --  *      eth0    0.0.0.0/0           
0.0.0.0/0          



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Unable-to-Proxy-https-traffic-using-squid-tp4676981.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From crmanik at gmail.com  Thu Apr  7 01:34:11 2016
From: crmanik at gmail.com (crmanik)
Date: Wed, 6 Apr 2016 18:34:11 -0700 (PDT)
Subject: [squid-users] Unable to Proxy https traffic using squid
In-Reply-To: <1459989082183-4676981.post@n4.nabble.com>
References: <1459989082183-4676981.post@n4.nabble.com>
Message-ID: <1459992851533-4676982.post@n4.nabble.com>

Got this intersting log using -X option:

2016/04/06 18:34:53.767 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for '52.84.243.6:443'
2016/04/06 18:34:53.767 kid1| 44,2| peer_select.cc(281) peerSelectDnsPaths:  
always_direct = DENIED

2016/04/06 18:34:53.767 kid1| 44,2| peer_select.cc(282) peerSelectDnsPaths:   
never_direct = DENIED

2016/04/06 18:34:53.767 kid1| 44,2| peer_select.cc(288) peerSelectDnsPaths:   
ORIGINAL_DST = local=0.0.0.0 remote=52.84.243.6:443 flags=1

2016/04/06 18:34:53.767 kid1| 44,2| peer_select.cc(295) peerSelectDnsPaths:       
timedout = 0

*2016/04/06 18:34:53.817 kid1| Error negotiating SSL on FD 12:
error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake
failure (1/-1/0)
*
2016/04/06 18:34:53.817 kid1| 17,2| FwdState.cc(608) serverClosed: FD -1
52.84.243.6:443 after -1 requests

2016/04/06 18:34:53.818 kid1| 4,2| errorpage.cc(1262) BuildContent: No exis

*ssl version that I have is:*
~/tmp/squid/certs$ openssl version
OpenSSL 1.0.1 14 Mar 2012

~




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Unable-to-Proxy-https-traffic-using-squid-tp4676981p4676982.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bmarkey at steinmancommunications.com  Thu Apr  7 13:11:27 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Thu, 7 Apr 2016 13:11:27 +0000
Subject: [squid-users] Logging of https
In-Reply-To: <bcaa7eab41e6068c3ef4842cc6f2c174@localhost>
References: <2B77BF184EAC2F43BB9FC908954D8B1266F42F78@Ex5.lnpnews.com>
 <bcaa7eab41e6068c3ef4842cc6f2c174@localhost>
Message-ID: <2B77BF184EAC2F43BB9FC908954D8B1266FFD74E@Ex5.lnpnews.com>

Ok thanks for that.  I think I have a slightly better understanding of what is going on.    That being said this is what I've come up with.  

No caching.  All sites allowed, peeking at all. 

I'm hoping this config will simply give me the logging that I'm looking for and nothing else.  And from that link you sent I don't have to install the client side cert?

Thanks

  1 #Access Lists
  2 acl internal src 192.168.200.0/21
  3 acl wireless src 192.168.100.0/23
  4 
  5 #Ports allowed through Squid
  6 acl Safe_ports port 80
  7 acl Safe_ports port 443
  8 acl SSL_ports port 443
  9 acl CONNECT method CONNECT
 10 
 11 #allow/deny
 12 http_access allow internal
 13 http_access allow wireless
 14 http_access deny !Safe_ports
 15 http_access deny CONNECT !SSL_ports
 16 http_access deny all
 17 
 18 #Bumping 
 19 acl step1 at_step SslBump1
 20 acl step2 at_step SslBump2
 21 acl step3 at_step SslBump3
 22 
 23 ssl_bump peek all
 24 ssl_bump splice all
 25 
 26 sslproxy_capath /etc/ssl/certs
 27 
 28 sslcrtd_program /usr/lib/squid3/ssl_crtd -s /opt/var/ssl_db -M 6MB
 29 sslcrtd_children 5
 30 
 31 #certs
 32 cert=/etc/squid3/certs/squid.pem
 33 cafile=/etc/squid3/certs/squid.pem
 34 key=/etc/squid3/certs/squid.pem generate-host-certificates=on dynamic_cert_mem_cache_size=6MB sslflags=NO_SESSION_REUSE
 35 
 36 logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni %ssl::>cert_subject %>Hs %<st %Ss:%Sh
 37 
 38 access_log syslog:daemon.info mine
 39 
 40 #intercept
 41 http_port 3128 intercept
 42 https_port 3129 intercept ssl-bump
 43 
 44 #nameservers
 45 dns_nameservers 192.168.201.1 8.8.8.8
 46 
 47 #WCCPv2 items
 48 wccp_version 2
 49 wccp2_router 192.168.200.73
 50 wccp2_forwarding_method gre
 51 wccp2_return_method gre
 52 wccp2_service standard 0 password=LNP1
 53 wccp2_service dynamic 70 password=LNP1
 54 wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 ports=443
 55

Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758?(o) |?bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of James Lay
Sent: Thursday, March 24, 2016 4:14 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Logging of https

On 2016-03-24 13:41, Markey, Bruce wrote:
> I'm hoping this is a simple question, I've gotten/seen differing 
> answers and I'd just like a final answer.
> 
> With squid setup as a transparent proxy via wccp will there be any log 
> entries for https sites, even just the ip?  Just the initial get 
> request is what I'd expect.
> 
> ( I have no interest in breaking https, I'd simply like to get any 
> data I can without having to go down that road)
> 
> If yes then what needs to be done to make that happen. Currently 
> everything is working on the http side perfectly.  Oh the https side 
> as soon as I enable wccp redirection of 443 to squid it breaks https.
>  ( I'll add here that I've read all the peek and splice info and I 
> don't really understand it.)
> 
> Thanks
> 
> BRUCE MARKEY | Network Security Analyst
> 
> STEINMAN COMMUNICATIONS
> 
> 717.291.8758 (o) | bmarkey at steinmancommunications.com
> 
> 8 West King St | PO Box 1328, Lancaster, PA 17608-1328
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


Read this:

http://thread.gmane.org/gmane.comp.web.squid.general/114384/focus=114389

Sample messages:

allowed https:
Mar 24 14:02:11 gateway (squid-1): 192.168.1.101 - -
[24/Mar/2016:14:02:11 -0600] "CONNECT 209.59.180.48:443 HTTP/1.1" - -
200 5511 TCP_TUNNEL:ORIGINAL_DST

note the size, 5511, and the TCP_TUNNEL, this has no SNI

denied https:
Mar 24 13:36:01 gateway (squid-1): 192.168.1.101 - -
[24/Mar/2016:13:36:01 -0600] "CONNECT 54.171.35.38:443 HTTP/1.1" - - 200
0 TAG_NONE:ORIGINAL_DST

note the size, 0, and the TAG_NONE, and this also has no SNI

Mar 24 13:36:01 gateway (squid-1): 192.168.1.101 - -
[24/Mar/2016:13:36:01 -0600] "CONNECT 54.171.177.121:443 HTTP/1.1" 
track.appsflyer.com - 200 0 TAG_NONE:ORIGINAL_DST

again, size, and TAG_NONE, but we saw SNI for this one.

the above are the output when using the config info in the link.  Hope that helps.

James
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Thu Apr  7 13:23:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Apr 2016 01:23:08 +1200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459950173942-4676968.post@n4.nabble.com>
References: <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz>
 <770168678.80144344.1459951815746.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1459950173942-4676968.post@n4.nabble.com>
Message-ID: <57065F3C.3020201@treenet.co.nz>

On 7/04/2016 1:42 a.m., joe wrote:
> yes
> 
> FredB wrote
>>>
>>> Attached is a patch which I think will fix 3.5.16 (should apply fine
>>> on
>>> 4.0.8 too) without needing the cache reset. Anyone able to test it
>>> please?
>>>
>>
>> Reset the cache still needed, at least in my case 
>>

Hmm. I'm not sure why that reset would be needed. I just ran a series of
tests with detailed debugging of the vary details being loaded from disk
and it seems the last patch was correctly erasing the \0 terminators
(and they were wrongly being stored).

So at least this new regression is fixed. Anything else seen in Vary is
a separate bug.

FYI Ralf reported bug 4481 to track it. I have updated the bug with an
explanation of the issue and applied that last patch to Squid-4 now. It
should be in 3.5 in a day or two.

Amos



From squid3 at treenet.co.nz  Thu Apr  7 13:59:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Apr 2016 01:59:28 +1200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1459962325673-4676976.post@n4.nabble.com>
References: <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz> <1459955008255-4676972.post@n4.nabble.com>
 <1459962325673-4676976.post@n4.nabble.com>
Message-ID: <570667C0.4000704@treenet.co.nz>

On 7/04/2016 5:05 a.m., joe wrote:
> amos question ?
> 
> off topic sorry for that 
> 
> vary is the second key store right ?

I'm not sure what you mean by "second key store". Its a bit ambiguous.

Squid looks up the URL and finds an object saying there is Vary header
details also needed.
Squid does a second lookup (on the same cache) for a string containing
URL + extras.
Squid then verifies that the object found by that second lookup actually
matches the URL *and* that it has a correct Vary header for the pattern
being looked up (to make sure its from the current Vary set and not some
older obsolete set).

> 
> same object with 2 browser  firefox
> accept-encoding="gzip,%20deflate"
> 
> chrome
> accept-encoding="gzip,%20deflate,%20sdch"
> 
> so if they ar 2*1 object stored is that right   ? 

 (2 +1) objects. Add not multiply.

> and other browser might have more compression 
> accept-encoding="gzip,%20deflate,%xxxxxxxxxxx
> that will be 3*1   right  if yes

That would be a third variant, yes.

>   why not filtering only the one has (not
> %) = accept-encoding="gzip"
> and use that only it will be beter hit and save more storage
> just idea what you think  ??  since "%"  meaning those compression not used
> for the object only
> the one without it 

The object encoding is not relevant. Surprising maybe, but true.

Think of it like this:

 If you request from me a drink, indicating that you will take Coffee or
Tea. I hand you a Coffee.
 *  Does that mean I dont have plain Water? of course not.

 If you asked me for a drink and indicated you will take Coffee, Tea or
Water. I might hand you Water.

 If you asked for Coffee or Tea a second time. I might hand you Tea.

 If you asked for Beer or Coffee. I might hand you Water. (Even though I
did have Coffee earlier, and I might have Beer but not be willing to
deliver it yet)


The one thing in common with all the requests above was Coffee. But
notice how the most common thing delivered was actually Water, and
sometimes Tea.



Back to caching.

The variant object stored at cache location:
   URL + 'accept-encoding="gzip,%20deflate"'

... is *only* guaranteed to be whatever object needs to be delivered
when the client sends "Accept-Encoding: gzip, deflate". That is all.


When the server response contains "Vary: Accept-Encoding" then even a
single-character difference in two client requests Accept-Encoding
header means a different cache variant object. Because that small
difference does mean it could be a different type coming back. Including
the *absence* of that header being one possible variant.

Amos



From squid3 at treenet.co.nz  Thu Apr  7 14:16:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Apr 2016 02:16:00 +1200
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
Message-ID: <57066BA0.80308@treenet.co.nz>

On 7/04/2016 3:16 a.m., Odhiambo Washington wrote:
> I am getting the following error in cache.log:
> 
> Squid Cache (Version 3.5.16): Terminated abnormally.
> CPU Usage: 0.082 seconds = 0.052 user + 0.030 sys
> Maximum Resident Size: 54992 KB
> Page faults with physical i/o: 0
> FATAL: Ipc::Mem::Segment::create failed to
> shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File exists
> 
> 
> However, that file doesn't exist.
> 

This can happen if you have a startup script the runs 'squid -z' or
similar just prior to starting the main proxy, and not waiting
sufficiently long for the -z run to finish.

Amos



From odhiambo at gmail.com  Thu Apr  7 14:21:23 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 7 Apr 2016 17:21:23 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <57066BA0.80308@treenet.co.nz>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz>
Message-ID: <CAAdA2WPhcZokx8fb7zvWDOqDja1H7=ziOko3GFodHy05iw0QiA@mail.gmail.com>

On 7 April 2016 at 17:16, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 7/04/2016 3:16 a.m., Odhiambo Washington wrote:
> > I am getting the following error in cache.log:
> >
> > Squid Cache (Version 3.5.16): Terminated abnormally.
> > CPU Usage: 0.082 seconds = 0.052 user + 0.030 sys
> > Maximum Resident Size: 54992 KB
> > Page faults with physical i/o: 0
> > FATAL: Ipc::Mem::Segment::create failed to
> > shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File exists
> >
> >
> > However, that file doesn't exist.
> >
>
> This can happen if you have a startup script the runs 'squid -z' or
> similar just prior to starting the main proxy, and not waiting
> sufficiently long for the -z run to finish.
>
> Amos
>
>
I am gonna check this out again tonight although I doubt if that is the
cause.

I run squid using daemontools, invoked as:

exec setuidgid root /opt/squid-3.5/sbin/squid -f
/opt/squid-3.5/etc/squid.conf -N

/opt/squid-3.5/var/run/squid/ is actually empty when I get this error.








-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160407/c5148a33/attachment.htm>

From squid3 at treenet.co.nz  Thu Apr  7 14:24:01 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Apr 2016 02:24:01 +1200
Subject: [squid-users] compiling 4.0.8 on FreeBSD-10.1
In-Reply-To: <CAAdA2WODXj0oeDr9q3t0dOPFSS+4HAy1zmVpTiiaV=pWAbs46Q@mail.gmail.com>
References: <CAAdA2WODXj0oeDr9q3t0dOPFSS+4HAy1zmVpTiiaV=pWAbs46Q@mail.gmail.com>
Message-ID: <57066D81.2080601@treenet.co.nz>

On 7/04/2016 3:57 a.m., Odhiambo Washington wrote:
> Hi,
> 
> My configure options:
> 
> 
> setenv CC  clang
> setenv CXX clang++
> 

Something is not right with the above. I dont think its doing what you
think it does.

The Squid ./configure found that a compiler called "c++" was the only
working one, and the libtool ./configure found that gcc was available
and used that. That can only happen if they both see the CC/CXX
variables as being empty.


Normally we setup the environment using shell parameters like this:
 ./configure CC=clang CXX=clang++ ...


Amos



From Tommy.Craddock at bicgraphic.com  Thu Apr  7 14:47:23 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Thu, 7 Apr 2016 14:47:23 +0000
Subject: [squid-users] External ACL Lookup
In-Reply-To: <57050436.9070908@treenet.co.nz>
References: <CA86A9283AA07E478F6B0629521FFEE734B879@CLWSEXCMBX02.na.bicworld.com>
 <57050436.9070908@treenet.co.nz>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE734D05D@CLWSEXCMBX02.na.bicworld.com>

My replies are interspersed below, in between lines of

_______________________________________________________________________________________________________________________________________


On 6/04/2016 9:16 a.m., Craddock, Tommy wrote:
> Hello,
> 
> Trying to use an external ACL helper to do a lookup of my user in a group in a Windows AD.  I can test from the command line:
> 
> 
> /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D 
> Squid at example.com -W /etc/squid/password -f 
> "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=Some 
> Group,dc=EXAMPLE,dc=COM))" -h dc01.example.com tcraddock at EXAMPLE.COM 
> Full.Access OK
> 

I'm always a little suspicious about whitespace in the LDAP parameters.
Such as you have for "ou=Some Group" in the -f filter.

It does depend on how new vs old your Squid is whether that will be treated as two parameters or one passed to the helper by Squid. The commmad line test will always pass it as one parameter.

If you can rework your ou= parameter to avoid the whitespace it might work better (just a maybe, but you do have Squid 3.1).

_______________________________________________________________________________________________________________________________________________
MY REPLY:


Amos, I moved my group into a different OU, called Some.OU, and it still gives me the same result in the cache.log:


In squid.conf:

external_acl_type memberof %LOGIN /usr/lib64/squid/squid_ldap_group -R -K -S -b "dc=example,dc=com" -D Squid at example.com -W /etc/squid/password -f "(&(objectclass=person)(sAMAccountName=$)(memberof=cn=%g,ou=Some.OU,dc=example,dc=com))" -h dc01.example.com


In cache.log:

2016/04/07 09:26:55.123| aclMatchExternal: memberof("tcraddock at example.com Full.Access") = lookup needed
2016/04/07 09:26:55.123| aclMatchExternal: "tcraddock at example.com Full.Access": entry=@0, age=0
2016/04/07 09:26:55.123| aclMatchExternal: "tcraddock at example.com Full.Access": queueing a call.
2016/04/07 09:26:55.123| aclMatchExternal: "tcraddock at example.com Full.Access": return -1.
2016/04/07 09:26:55.123| externalAclLookup: lookup in 'memberof' for 'tcraddock at example.com Full.Access'
2016/04/07 09:26:55.128| externalAclHandleReply: reply="ERR"
2016/04/07 09:26:55.128| external_acl_cache_add: Adding 'tcraddock at example.com Full.Access' = 0
2016/04/07 09:26:55.128| aclMatchExternal: memberof = 0

__________________________________________________________________________________________________________________________________________________________________
> 
> In the file referenced in the ACLs:
> 
> acl RestrictedAccess    external memberof "/etc/squid/restricted_access.txt"
> acl FullAccess          external memberof "/etc/squid/full_access.txt"
> 
> 
> it has:
> 
> cat /etc/squid/full_access.txt
> Full.Access
> 
> cat /etc/squid/restricted_access.txt
> Restricted.Access
> 

Speaking of white spaces. The only reason for using files there is when the group name contains a whitespace character. TO avoid a squid.conf parser bug (Sorry). If those dots are in fact dots and not spaces, then you dont need the extra files.


______________________________________________________________________________________________________________________________________
MY REPLY:

Understood, changed this to:

acl RestrictedAccess    external memberof Restricted.Access
acl FullAccess external memberof Full.Access

_______________________________________________________________________________________________________________________________________
> 
> ### provide basic authentication via ldap for clients not 
> authenticated via kerberos/ntlm auth_param basic program 
> /usr/lib64/squid/squid_ldap_auth -R -b "dc=example,dc=com" -D 
> Squid at EXAMPLE.COM -W /etc/squid/password -f sAMAccountName=%s -h 
> DC01.EXAMPLE.COM auth_param basic children 10 auth_param basic realm 
> Internet Proxy auth_param basic credentialsttl 1 minute
> 


Your NTLM and Negotiate authenticators have a parameter requiring membership of the Ful.Access group as part of the auth process.

That means you should be able to use the auth type to tell what group they are a member of.


_______________________________________________________________________________________________________________________________________

How?  Ive tried to find out how to use that in a ACL but I haven?t been able to find an example. Plus, since Im using negotiate with NTLM and Kerberos, if the client uses Kerberos, does the NTLM group membership parameter even get used?
_______________________________________________________________________________________________________________________________________
> http_access allow manager localhost
> http_access deny manager
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> #http_access deny !memberof
> http_access allow localhost
> http_access allow HEAD
> http_access deny !our_networks
> http_access allow Smartconnect
> http_access deny blocksites all
> http_access allow Approved_Domains
> http_access deny RestrictedHost all
> http_access allow FullAccess auth

NP: FullAccess and auth ACLs require authentication to take place.

What is the point of the Java and WindowsUpdate and bypass_auth ACLs being tested *after* auth has already been required of the client?

Surely the bypasses should be first and the auth related things after.

> http_access allow Java
> http_access allow WindowsUpdate
> http_access allow bypass_auth
> http_access allow bypass_auth-external http_access allow goto_meeting 
> http_access allow our_networks all http_access allow Java our_networks 
> JavaSites http_access allow auth http_access deny !auth http_access 
> deny all
> 

Generally the best pattern to use when designing http_access sequences is this:

+ allow <things that bypass auth>
+ "deny !auth"
+ allow <things that require auth>
+ "deny all"



Amos
_______________________________________________________________________________________________________________________________________

How does this look?

http_access deny !our_networks
http_access allow manager localhost
http_access allow HEAD
http_access allow Smartconnect
http_access allow Java
http_access allow WindowsUpdate
http_access allow bypass_auth
http_access allow bypass_auth-external
http_access allow Approved_Domains
http_access allow goto_meeting
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny blocksites
http_access deny RestrictedHost
http_access deny !auth
http_access allow FullAccess auth
http_access allow auth
http_access deny all

_______________________________________________________________________________________________________________________________________

Thanks!


Tommy Craddock









______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

From chip_pop at hotmail.com  Thu Apr  7 14:39:13 2016
From: chip_pop at hotmail.com (joe)
Date: Thu, 7 Apr 2016 07:39:13 -0700 (PDT)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <570667C0.4000704@treenet.co.nz>
References: <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz> <1459955008255-4676972.post@n4.nabble.com>
 <1459962325673-4676976.post@n4.nabble.com> <570667C0.4000704@treenet.co.nz>
Message-ID: <1460039953628-4676990.post@n4.nabble.com>

some of my post you miss reading or
wen i ask for water  and i get water  same size same glas  but i was offered
somthing else i was refuse that
and my friend ask for the same he should get same glas of water same size
so what i was trying to enplane is
 

i ask  for gzip  the the md5 vary calculate with string
accept-encoding="gzip,%20deflate,%20sdch" 
so the gzip dose not have %20  on front of it so we can use only that and
filter out those ,%20deflate,%20sdch
it will be string accept-encoding="gzip" use  that in md5 calc only
if other browser has in vary string accept-encoding="gzip,%20deflate" 
without examle  %20sdch
md5 calc use string accept-encoding="gzip,%20deflate"
so we also filter out -- > ,%20deflate
and keep only to use md5 with  string accept-encoding="gzip"

since  gzip dose not have %20 on front of it

that will make a beter hit without any problem on all browser

as i says and i test the link i provide before   
on firefox   first time after the cache ar empty  i get HIT  alwes just by
using firefox
until now perfect

but  wen i use chrome since it send and resive in very  string
accept-encoding="gzip,%20deflate,%20sdch"
the cached file ar deleted and resolt  = MISS  then it re creat new file
with HIT alwes just by using chrome

if i return to firefox its  MISS  then file got purged from cache then its
HIT again

if other browser has  vary  with string
accept-encoding="%20gzip,deflate,%20sdch"
watch this      deflate   has no --->> %20 in front of it so md5 calc should
use only deflate   not encluding the one with  %20   string
this how i understand it   and i monitor those prossess i prove that is
waste

so anoter example cause i dont know if im trying to explain it in right
manner 
 another browser get vary  string accept-encoding="%20gzip,%20deflate,sdch"
as you see  sdch  its the one used  so we must use that filter out the rest 

variety with string confuse the correct match match lookup it it purge the
same file just becaus somthing in vary has extra string and its not used






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-16-and-vary-loop-objects-bug-tp4676901p4676990.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jlay at slave-tothe-box.net  Thu Apr  7 15:34:22 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Thu, 07 Apr 2016 09:34:22 -0600
Subject: [squid-users] Logging of https
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B1266FFD74E@Ex5.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B1266F42F78@Ex5.lnpnews.com>
 <bcaa7eab41e6068c3ef4842cc6f2c174@localhost>
 <2B77BF184EAC2F43BB9FC908954D8B1266FFD74E@Ex5.lnpnews.com>
Message-ID: <e825fc3535053d282235d6f1ccef6b22@localhost>

That's correct....peek/stare don't require a cert on the client end.  
Just keep in mind you won't get a full URL in the logs with https 
sites...just the host/ip:

Apr  7 09:30:31 gateway (squid-1): 192.168.1.106 - - 
[07/Apr/2016:09:30:31 -0600] "CONNECT 216.58.193.78:443 HTTP/1.1" 
safebrowsing.google.com - 200 871538 TCP_TUNNEL:ORIGINAL_DST

James

On 2016-04-07 07:11, Markey, Bruce wrote:
> Ok thanks for that.  I think I have a slightly better understanding of
> what is going on.    That being said this is what I've come up with.
> 
> No caching.  All sites allowed, peeking at all.
> 
> I'm hoping this config will simply give me the logging that I'm
> looking for and nothing else.  And from that link you sent I don't
> have to install the client side cert?
> 
> Thanks
> 
>   1 #Access Lists
>   2 acl internal src 192.168.200.0/21
>   3 acl wireless src 192.168.100.0/23
>   4
>   5 #Ports allowed through Squid
>   6 acl Safe_ports port 80
>   7 acl Safe_ports port 443
>   8 acl SSL_ports port 443
>   9 acl CONNECT method CONNECT
>  10
>  11 #allow/deny
>  12 http_access allow internal
>  13 http_access allow wireless
>  14 http_access deny !Safe_ports
>  15 http_access deny CONNECT !SSL_ports
>  16 http_access deny all
>  17
>  18 #Bumping
>  19 acl step1 at_step SslBump1
>  20 acl step2 at_step SslBump2
>  21 acl step3 at_step SslBump3
>  22
>  23 ssl_bump peek all
>  24 ssl_bump splice all
>  25
>  26 sslproxy_capath /etc/ssl/certs
>  27
>  28 sslcrtd_program /usr/lib/squid3/ssl_crtd -s /opt/var/ssl_db -M 6MB
>  29 sslcrtd_children 5
>  30
>  31 #certs
>  32 cert=/etc/squid3/certs/squid.pem
>  33 cafile=/etc/squid3/certs/squid.pem
>  34 key=/etc/squid3/certs/squid.pem generate-host-certificates=on
> dynamic_cert_mem_cache_size=6MB sslflags=NO_SESSION_REUSE
>  35
>  36 logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni
> %ssl::>cert_subject %>Hs %<st %Ss:%Sh
>  37
>  38 access_log syslog:daemon.info mine
>  39
>  40 #intercept
>  41 http_port 3128 intercept
>  42 https_port 3129 intercept ssl-bump
>  43
>  44 #nameservers
>  45 dns_nameservers 192.168.201.1 8.8.8.8
>  46
>  47 #WCCPv2 items
>  48 wccp_version 2
>  49 wccp2_router 192.168.200.73
>  50 wccp2_forwarding_method gre
>  51 wccp2_return_method gre
>  52 wccp2_service standard 0 password=LNP1
>  53 wccp2_service dynamic 70 password=LNP1
>  54 wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 
> ports=443
>  55
> 
> Bruce Markey | Network Security Analyst
> STEINMAN COMMUNICATIONS
> 717.291.8758?(o) |?bmarkey at steinmancommunications.com
> 8 West King St | PO Box 1328, Lancaster, PA 17608-1328
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
> On Behalf Of James Lay
> Sent: Thursday, March 24, 2016 4:14 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Logging of https
> 
> On 2016-03-24 13:41, Markey, Bruce wrote:
>> I'm hoping this is a simple question, I've gotten/seen differing
>> answers and I'd just like a final answer.
>> 
>> With squid setup as a transparent proxy via wccp will there be any log
>> entries for https sites, even just the ip?  Just the initial get
>> request is what I'd expect.
>> 
>> ( I have no interest in breaking https, I'd simply like to get any
>> data I can without having to go down that road)
>> 
>> If yes then what needs to be done to make that happen. Currently
>> everything is working on the http side perfectly.  Oh the https side
>> as soon as I enable wccp redirection of 443 to squid it breaks https.
>>  ( I'll add here that I've read all the peek and splice info and I
>> don't really understand it.)
>> 
>> Thanks
>> 
>> BRUCE MARKEY | Network Security Analyst
>> 
>> STEINMAN COMMUNICATIONS
>> 
>> 717.291.8758 (o) | bmarkey at steinmancommunications.com
>> 
>> 8 West King St | PO Box 1328, Lancaster, PA 17608-1328
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> Read this:
> 
> http://thread.gmane.org/gmane.comp.web.squid.general/114384/focus=114389
> 
> Sample messages:
> 
> allowed https:
> Mar 24 14:02:11 gateway (squid-1): 192.168.1.101 - -
> [24/Mar/2016:14:02:11 -0600] "CONNECT 209.59.180.48:443 HTTP/1.1" - -
> 200 5511 TCP_TUNNEL:ORIGINAL_DST
> 
> note the size, 5511, and the TCP_TUNNEL, this has no SNI
> 
> denied https:
> Mar 24 13:36:01 gateway (squid-1): 192.168.1.101 - -
> [24/Mar/2016:13:36:01 -0600] "CONNECT 54.171.35.38:443 HTTP/1.1" - - 
> 200
> 0 TAG_NONE:ORIGINAL_DST
> 
> note the size, 0, and the TAG_NONE, and this also has no SNI
> 
> Mar 24 13:36:01 gateway (squid-1): 192.168.1.101 - -
> [24/Mar/2016:13:36:01 -0600] "CONNECT 54.171.177.121:443 HTTP/1.1"
> track.appsflyer.com - 200 0 TAG_NONE:ORIGINAL_DST
> 
> again, size, and TAG_NONE, but we saw SNI for this one.
> 
> the above are the output when using the config info in the link.  Hope
> that helps.
> 
> James
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From bmarkey at steinmancommunications.com  Thu Apr  7 15:58:56 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Thu, 7 Apr 2016 15:58:56 +0000
Subject: [squid-users] Debian jessie + squid 3.5.16 - Will not start.
Message-ID: <2B77BF184EAC2F43BB9FC908954D8B126700102E@Ex5.lnpnews.com>

I'm running debian Jessie.
Squid 3.5.16 compiled from source with the following:

./configure --build=x86_64-linux-gnu \
--prefix=/usr \
--includedir=${prefix}/include \
--mandir=${prefix}/share/man \
--infodir=${prefix}/share/info \
--sysconfdir=/etc \
--localstatedir=/var \
--libexecdir=${prefix}/lib/squid3 \
--srcdir=. \
--disable-maintainer-mode \
--disable-dependency-tracking \
--disable-silent-rules \
--datadir=/usr/share/squid3 \
--sysconfdir=/etc/squid3 \
--mandir=/usr/share/man \
--enable-inline \
--enable-gnuregex \
--enable-xmalloc-statistics \
--enable-useragent-log \
--enable-kill-parent-hack \
--enable-htpc \
--enable-forw-via-db \
--enable-dl-malloc \
--enable-time-hack \
--enable-err-language=English \
--disable-arch-native \
--enable-async-io=8 \
--enable-storeio=ufs,aufs,diskd,rock \
--enable-removal-policies=lru,heap \
--enable-delay-pools \
--enable-cache-digests \
--enable-icap-client \
--enable-follow-x-forwarded-for \
--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB \
--enable-auth-digest=file,LDAP \
--enable-auth-negotiate=kerberos,wrapper \
--enable-auth-ntlm=fake,smb_lm \
--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group \
--enable-url-rewrite-helpers=fake \
--enable-eui \
--enable-esi \
--enable-icmp \
--enable-zph-qos \
--enable-ecap \
--disable-translation \
--with-swapdir=/var/spool/squid3 \
--with-logdir=/var/log/squid3 \
--with-pidfile=/var/run/squid3.pid \
--with-filedescriptors=65536 \
--with-large-files \
--with-default-user=proxy \
--enable-ssl \
--enable-ssl-crtd \
--enable-wccpv2 \
--with-openssl \
--enable-linux-netfilter \
'CFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall' \
'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' \
'CPPFLAGS=-D_FORTIFY_SOURCE=2' \
'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security'

Here is my squid.conf

#Access Lists
acl internal src 192.168.200.0/21
acl wireless src 192.168.100.0/23

#Ports allowed through Squid
acl Safe_ports port 80
acl Safe_ports port 443
acl SSL_ports port 443
acl CONNECT method CONNECT

#allow/deny
http_access allow internal
http_access allow wireless
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all

#Bumping
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

ssl_bump peek all
ssl_bump splice all

sslproxy_capath /etc/ssl/certs

sslcrtd_program /usr/lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
sslcrtd_children 5


logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni %ssl::>cert_subject %>Hs %<st %Ss:%Sh

#access_log syslog:daemon.info mine
access_log daemon:/var/log/squid3/access.log mine

#intercept
http_port 3128 intercept
https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem  generate-host-cer
tificates=on dynamic_cert_mem_cache_size=4MB sslflags=NO_SESSION_REUSE

#nameservers
dns_nameservers 192.168.201.1 8.8.8.8

#WCCPv2 items
wccp_version 2
wccp2_router 192.168.200.73
wccp2_forwarding_method gre
wccp2_return_method gre
wccp2_service standard 0 password=LNP1
wccp2_service dynamic 70 password=LNP1
wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 ports=443

-I did initialize the ssl_db
-I did create certs

I'm simply trying to start via :  sudo squid   It throws no errors nothing.  The pid lives for a sec then dies. This is the only log message I get.

Apr  7 11:51:19 LNP-Proxy (squid-1): The ssl_crtd helpers are crashing too rapidly, need help!

I tried deleting and recreating the ssl_db as I saw from a few other posts, did not work.

Other info:

Tunnel is up:

gre0: gre/ip  remote any  local any  ttl inherit  nopmtudisc
wccp0: gre/ip  remote 192.168.200.73  local 192.168.201.248  dev eth3  ttl inherit

Iptables:

bruce at LNP-Proxy:/var/log$ sudo iptables -t nat -L
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
DNAT       tcp  --  anywhere             anywhere             tcp dpt:http to:192.168.201.248:3128
DNAT       tcp  --  anywhere             anywhere             tcp dpt:https to:192.168.201.248:3129

Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination

Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination

I'm not sure what to even check next.  I cant do a sudo squid -k debug since the process doesn't last long enough.

Thanks


Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758 (o) | bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160407/ec6d32f1/attachment.htm>

From bmarkey at steinmancommunications.com  Thu Apr  7 16:09:41 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Thu, 7 Apr 2016 16:09:41 +0000
Subject: [squid-users] Logging of https
In-Reply-To: <e825fc3535053d282235d6f1ccef6b22@localhost>
References: <2B77BF184EAC2F43BB9FC908954D8B1266F42F78@Ex5.lnpnews.com>
 <bcaa7eab41e6068c3ef4842cc6f2c174@localhost>
 <2B77BF184EAC2F43BB9FC908954D8B1266FFD74E@Ex5.lnpnews.com>,
 <e825fc3535053d282235d6f1ccef6b22@localhost>
Message-ID: <9387a5ec-2604-466f-9598-8940bfe2aaed@steinmancommunications.com>

Perfect.  I'm totally fine without the full url.

Thanks
Bruce

On Apr 7, 2016 11:34 AM, James Lay <jlay at slave-tothe-box.net> wrote:
That's correct....peek/stare don't require a cert on the client end.
Just keep in mind you won't get a full URL in the logs with https
sites...just the host/ip:

Apr  7 09:30:31 gateway (squid-1): 192.168.1.106 - -
[07/Apr/2016:09:30:31 -0600] "CONNECT 216.58.193.78:443 HTTP/1.1"
safebrowsing.google.com - 200 871538 TCP_TUNNEL:ORIGINAL_DST

James

On 2016-04-07 07:11, Markey, Bruce wrote:
> Ok thanks for that.  I think I have a slightly better understanding of
> what is going on.    That being said this is what I've come up with.
>
> No caching.  All sites allowed, peeking at all.
>
> I'm hoping this config will simply give me the logging that I'm
> looking for and nothing else.  And from that link you sent I don't
> have to install the client side cert?
>
> Thanks
>
>   1 #Access Lists
>   2 acl internal src 192.168.200.0/21
>   3 acl wireless src 192.168.100.0/23
>   4
>   5 #Ports allowed through Squid
>   6 acl Safe_ports port 80
>   7 acl Safe_ports port 443
>   8 acl SSL_ports port 443
>   9 acl CONNECT method CONNECT
>  10
>  11 #allow/deny
>  12 http_access allow internal
>  13 http_access allow wireless
>  14 http_access deny !Safe_ports
>  15 http_access deny CONNECT !SSL_ports
>  16 http_access deny all
>  17
>  18 #Bumping
>  19 acl step1 at_step SslBump1
>  20 acl step2 at_step SslBump2
>  21 acl step3 at_step SslBump3
>  22
>  23 ssl_bump peek all
>  24 ssl_bump splice all
>  25
>  26 sslproxy_capath /etc/ssl/certs
>  27
>  28 sslcrtd_program /usr/lib/squid3/ssl_crtd -s /opt/var/ssl_db -M 6MB
>  29 sslcrtd_children 5
>  30
>  31 #certs
>  32 cert=/etc/squid3/certs/squid.pem
>  33 cafile=/etc/squid3/certs/squid.pem
>  34 key=/etc/squid3/certs/squid.pem generate-host-certificates=on
> dynamic_cert_mem_cache_size=6MB sslflags=NO_SESSION_REUSE
>  35
>  36 logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni
> %ssl::>cert_subject %>Hs %<st %Ss:%Sh
>  37
>  38 access_log syslog:daemon.info mine
>  39
>  40 #intercept
>  41 http_port 3128 intercept
>  42 https_port 3129 intercept ssl-bump
>  43
>  44 #nameservers
>  45 dns_nameservers 192.168.201.1 8.8.8.8
>  46
>  47 #WCCPv2 items
>  48 wccp_version 2
>  49 wccp2_router 192.168.200.73
>  50 wccp2_forwarding_method gre
>  51 wccp2_return_method gre
>  52 wccp2_service standard 0 password=LNP1
>  53 wccp2_service dynamic 70 password=LNP1
>  54 wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240
> ports=443
>  55
>
> Bruce Markey | Network Security Analyst
> STEINMAN COMMUNICATIONS
> 717.291.8758 (o) | bmarkey at steinmancommunications.com
> 8 West King St | PO Box 1328, Lancaster, PA 17608-1328
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
> On Behalf Of James Lay
> Sent: Thursday, March 24, 2016 4:14 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Logging of https
>
> On 2016-03-24 13:41, Markey, Bruce wrote:
>> I'm hoping this is a simple question, I've gotten/seen differing
>> answers and I'd just like a final answer.
>>
>> With squid setup as a transparent proxy via wccp will there be any log
>> entries for https sites, even just the ip?  Just the initial get
>> request is what I'd expect.
>>
>> ( I have no interest in breaking https, I'd simply like to get any
>> data I can without having to go down that road)
>>
>> If yes then what needs to be done to make that happen. Currently
>> everything is working on the http side perfectly.  Oh the https side
>> as soon as I enable wccp redirection of 443 to squid it breaks https.
>>  ( I'll add here that I've read all the peek and splice info and I
>> don't really understand it.)
>>
>> Thanks
>>
>> BRUCE MARKEY | Network Security Analyst
>>
>> STEINMAN COMMUNICATIONS
>>
>> 717.291.8758 (o) | bmarkey at steinmancommunications.com
>>
>> 8 West King St | PO Box 1328, Lancaster, PA 17608-1328
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
> Read this:
>
> http://thread.gmane.org/gmane.comp.web.squid.general/114384/focus=114389
>
> Sample messages:
>
> allowed https:
> Mar 24 14:02:11 gateway (squid-1): 192.168.1.101 - -
> [24/Mar/2016:14:02:11 -0600] "CONNECT 209.59.180.48:443 HTTP/1.1" - -
> 200 5511 TCP_TUNNEL:ORIGINAL_DST
>
> note the size, 5511, and the TCP_TUNNEL, this has no SNI
>
> denied https:
> Mar 24 13:36:01 gateway (squid-1): 192.168.1.101 - -
> [24/Mar/2016:13:36:01 -0600] "CONNECT 54.171.35.38:443 HTTP/1.1" - -
> 200
> 0 TAG_NONE:ORIGINAL_DST
>
> note the size, 0, and the TAG_NONE, and this also has no SNI
>
> Mar 24 13:36:01 gateway (squid-1): 192.168.1.101 - -
> [24/Mar/2016:13:36:01 -0600] "CONNECT 54.171.177.121:443 HTTP/1.1"
> track.appsflyer.com - 200 0 TAG_NONE:ORIGINAL_DST
>
> again, size, and TAG_NONE, but we saw SNI for this one.
>
> the above are the output when using the config info in the link.  Hope
> that helps.
>
> James
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Thu Apr  7 16:35:45 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 7 Apr 2016 10:35:45 -0600
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <CAAdA2WPhcZokx8fb7zvWDOqDja1H7=ziOko3GFodHy05iw0QiA@mail.gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz>
 <CAAdA2WPhcZokx8fb7zvWDOqDja1H7=ziOko3GFodHy05iw0QiA@mail.gmail.com>
Message-ID: <57068C61.1030608@measurement-factory.com>

On 04/07/2016 08:21 AM, Odhiambo Washington wrote:

> On 7 April 2016 at 17:16, Amos Jeffries wrote:
> 
>     On 7/04/2016 3:16 a.m., Odhiambo Washington wrote:
>     > I am getting the following error in cache.log:
>     >
>     > Squid Cache (Version 3.5.16): Terminated abnormally.
>     > FATAL: Ipc::Mem::Segment::create failed to
>     > shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File exists
>     >
>     > However, that file doesn't exist.

>     This can happen if you have a startup script the runs 'squid -z' or
>     similar just prior to starting the main proxy, and not waiting
>     sufficiently long for the -z run to finish.


> I am gonna check this out again tonight although I doubt if that is the
> cause.
> 
> I run squid using daemontools, invoked as:
> 
> exec setuidgid root /opt/squid-3.5/sbin/squid -f
> /opt/squid-3.5/etc/squid.conf -N
> 
> /opt/squid-3.5/var/run/squid/ is actually empty when I get this error.


I see two possibilities:

1. The file was there at the time the error was triggered but was not
there at the time you checked the directory. This would mean that
something is starting a second Squid while the first Squid has not
removed the shared memory segment file (yet). Amos mentioned one such
common scenario (not waiting for background squid-z) but there are
others, possibly including handling of Squid crashes. Do you see any
other errors, assertions, or FATAL messages in your cache.log?

2. Squid code that is trying to open the shared segment is broken or,
more likely, not compatible with your FreeBSD environment. For example,
it tries to exclusively create a shared segment using the wrong name.

If you can reproduce this, I recommend starting Squid via strace (or
equivalent) to see the system calls that Squid is making when calling
shm_open() and the exact call parameters. This can confirm or eliminate
#2 as the suspect.


HTH,

Alex.



From squid3 at treenet.co.nz  Thu Apr  7 17:56:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Apr 2016 05:56:56 +1200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <1460039953628-4676990.post@n4.nabble.com>
References: <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz> <1459955008255-4676972.post@n4.nabble.com>
 <1459962325673-4676976.post@n4.nabble.com> <570667C0.4000704@treenet.co.nz>
 <1460039953628-4676990.post@n4.nabble.com>
Message-ID: <57069F68.6010000@treenet.co.nz>

On 8/04/2016 2:39 a.m., joe wrote:
> some of my post you miss reading or
> wen i ask for water  and i get water  same size same glas  but i was offered
> somthing else i was refuse that

In terms of the protocol, you cant refuse exactly. It is what was
responded with. The server/provider 'owns' the resource and is the
control authority about what should be provided to any request.


> and my friend ask for the same he should get same glas of water same size
> so what i was trying to enplane is
>  
> 
> i ask  for gzip  the the md5 vary calculate with string

Asking for gzip would be sending the header exact and full value of:
  Accept-Ecoding: gzip\r\n

... not the below multiple list of values:

> accept-encoding="gzip,%20deflate,%20sdch" 
> so the gzip dose not have %20  on front of it so we can use only that and

%20 is a space character when URL-encoded for adding to the URL hash key.

The client sending a request with that header value(s) is asking for
gzip OR deflate OR sdch encoding (in that order of preference). The
server decides whether one of those can be produced. And identity
encoding (unencoded) is guaranteed to always be acceptible.


> filter out those ,%20deflate,%20sdch
> it will be string accept-encoding="gzip" use  that in md5 calc only
> if other browser has in vary string accept-encoding="gzip,%20deflate" 
> without examle  %20sdch
> md5 calc use string accept-encoding="gzip,%20deflate"
> so we also filter out -- > ,%20deflate
> and keep only to use md5 with  string accept-encoding="gzip"
> 
> since  gzip dose not have %20 on front of it

What if the sdch was the type that server actually wanted to produce?
If you are using Google Docs sdch objects actually *are* more often than
not what gets sent. Its a type of patch/diff format for collaborative
tools updating an object in bits and pieces.

> 
> that will make a beter hit without any problem on all browser
> 

*Maybe*. You are free to do so if you like. We cannot do it in the
general case though for Squid has to work according to proper HTTP
requirements in networks other than yours (and there are several others
also wanting this same thing have configured their proxies to do it).


> as i says and i test the link i provide before   
> on firefox   first time after the cache ar empty  i get HIT  alwes just by
> using firefox
> until now perfect
> 
> but  wen i use chrome since it send and resive in very  string
> accept-encoding="gzip,%20deflate,%20sdch"
> the cached file ar deleted and resolt  = MISS  then it re creat new file
> with HIT alwes just by using chrome
> 
> if i return to firefox its  MISS  then file got purged from cache then its
> HIT again

Two things:

1) MISS does not mean any content was thrown away. It just means what
was already in the cache was not able to be used.
  - it can happen because of a max-age=0 or no-cache from the client.
Chrome and other Google products seem to like sending those. Very
unfriendly to caches.
  - it can happen if Vary exists and the particular object this request
needs is not one of the current set of variants in the cache.

2) You can have the appearance of stuff being "thrown away" if the Vary
marker object used to store the pattern actually was thrown away for
some reason. Without it there is no way to reach the variant objects
which are still in cache.
 - A MISS is needed in order to re-fetch a response with Vary pattern to
create the marker, and bingo all the variants that pattern describes
which were still in the cache can be fetched as HITs again.
 - BUT, if the Vary pattern changed they stay 'lost'.

This #2 is a common problem seen with Apache servers which emit
different Vary patterns depending on which modules were run on the request.


> 
> if other browser has  vary  with string
> accept-encoding="%20gzip,deflate,%20sdch"
> watch this      deflate   has no --->> %20 in front of it so md5 calc should
> use only deflate   not encluding the one with  %20   string
> this how i understand it   and i monitor those prossess i prove that is
> waste

Whitespace normalization (or lack of it rather) does cause wastage. The
only reason that is not done is nobody did it yet. Patches fixing that
are welcome.

> 
> so anoter example cause i dont know if im trying to explain it in right
> manner 
>  another browser get vary  string accept-encoding="%20gzip,%20deflate,sdch"
> as you see  sdch  its the one used  so we must use that filter out the rest 
> 
> variety with string confuse the correct match match lookup it it purge the
> same file just becaus somthing in vary has extra string and its not used
> 

A)
I know what you are trying to say. I'm trying to say why its not
necessarily such a great idea (for Squid). There are subtle things in
the protocol design that prevent it and/or would be broken by it.


B)
You are also focused on The Browser(s). Some of the smart guys in IETF
HTTP Working Group did some research a few months ago. Its a funny story
really:

* the Chrome guys did their research and found that almost all servers
responding to Chrome could be forced to send gzip. With all modern
browsers supporting gzip there are great bandwidth reduction benefits
waiting to be had. Therefore argued that gzip should be the one and only
output from server by default and middleware like Squid should
auto-encode to produce gzip only.

* the server guys did their own research and found that Browser traffic
was less than ~20% of HTTP total traffic (and declining as IoT
increases). Optimizing all networks for the Browsers causes big problems
for all that major portion of non-Browser traffic which consists of
tools using other encoding types (there are at least 8 now in active use
around the world, some of them much better than gzip).

 --> Oops.

C)
Vary as a header is kind of set in stone. We can adjust a few things.
But its really depended on by too many pieces of old software.

There is another header called Key being designed by IETF right now. It
does a better job to describe the variant patterns in a more detailed
way. Such as to say that any Accept-Encoding header containing 'gzip'
could get this reply, or any Accept-Encoding header containing 'deflate'
gets another.

 That new header is just very experimental right now and I haven't had
much time to make Squid use it yet.

Amos



From squid3 at treenet.co.nz  Thu Apr  7 17:59:40 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Apr 2016 05:59:40 +1200
Subject: [squid-users] Sending intermediate certificate with SSL-Bumped
 Certificate. (V3.5.1516-3-2-r14000)
In-Reply-To: <e816f8036c6f8912fd6bb6eda5717889@smoothnet.org>
References: <e816f8036c6f8912fd6bb6eda5717889@smoothnet.org>
Message-ID: <5706A00C.6060604@treenet.co.nz>

On 7/04/2016 5:25 a.m., Nicolaas Hyatt wrote:
> Amos,
> Thanks for your quick response and your time. I have not yet messed with
> 4.0. Is this something that may find its way into the 3.x stable branch
> at some point?
> 

Maybe. I am reliant on the guys doing OpenSSL code (aka. Christos) to
test the backporting though. So it will depend on whether he thinks its
important enough.

I'm hopeful, but no guarantees.

Amos



From jok at spikes.com  Thu Apr  7 18:15:49 2016
From: jok at spikes.com (Jok Thuau)
Date: Thu, 7 Apr 2016 11:15:49 -0700
Subject: [squid-users] Sending intermediate certificate with SSL-Bumped
 Certificate. (V3.5.1516-3-2-r14000)
In-Reply-To: <5706A00C.6060604@treenet.co.nz>
References: <e816f8036c6f8912fd6bb6eda5717889@smoothnet.org>
 <5706A00C.6060604@treenet.co.nz>
Message-ID: <CADSSinP1dYy=DX_k6k8eTORBpMskLPqjUiaXXbsyZCsRR36pFQ@mail.gmail.com>

with 3.5.15, I have this config:

---8<---
https_port 8443 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=64MB \
    cert=/etc/squid/ssl/proxy.pem \
    key=/etc/squid/ssl/proxy.key \
    cafile=/etc/squid/ssl/proxy.pem
--->8---

proxy.pem is the concatenation of both the CA cert (intermediate) followed
by the root cert (my offline CA). Best i can tell, all of it is sent back
to the client (generated cert, intermediate and root CA).

HTH
Jok




On Thu, Apr 7, 2016 at 10:59 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 7/04/2016 5:25 a.m., Nicolaas Hyatt wrote:
> > Amos,
> > Thanks for your quick response and your time. I have not yet messed with
> > 4.0. Is this something that may find its way into the 3.x stable branch
> > at some point?
> >
>
> Maybe. I am reliant on the guys doing OpenSSL code (aka. Christos) to
> test the backporting though. So it will depend on whether he thinks its
> important enough.
>
> I'm hopeful, but no guarantees.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160407/dc9580c7/attachment.htm>

From odhiambo at gmail.com  Thu Apr  7 18:21:05 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 7 Apr 2016 21:21:05 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <57068C61.1030608@measurement-factory.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz>
 <CAAdA2WPhcZokx8fb7zvWDOqDja1H7=ziOko3GFodHy05iw0QiA@mail.gmail.com>
 <57068C61.1030608@measurement-factory.com>
Message-ID: <CAAdA2WP-ntbYjh7MTXF4R60US9L0y8Yrtejvc-Wt77_XY1gQsQ@mail.gmail.com>

On 7 April 2016 at 19:35, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/07/2016 08:21 AM, Odhiambo Washington wrote:
>
> > On 7 April 2016 at 17:16, Amos Jeffries wrote:
> >
> >     On 7/04/2016 3:16 a.m., Odhiambo Washington wrote:
> >     > I am getting the following error in cache.log:
> >     >
> >     > Squid Cache (Version 3.5.16): Terminated abnormally.
> >     > FATAL: Ipc::Mem::Segment::create failed to
> >     > shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File
> exists
> >     >
> >     > However, that file doesn't exist.
>
> >     This can happen if you have a startup script the runs 'squid -z' or
> >     similar just prior to starting the main proxy, and not waiting
> >     sufficiently long for the -z run to finish.
>
>
> > I am gonna check this out again tonight although I doubt if that is the
> > cause.
> >
> > I run squid using daemontools, invoked as:
> >
> > exec setuidgid root /opt/squid-3.5/sbin/squid -f
> > /opt/squid-3.5/etc/squid.conf -N
> >
> > /opt/squid-3.5/var/run/squid/ is actually empty when I get this error.
>
>
> I see two possibilities:
>
> 1. The file was there at the time the error was triggered but was not
> there at the time you checked the directory. This would mean that
> something is starting a second Squid while the first Squid has not
> removed the shared memory segment file (yet). Amos mentioned one such
> common scenario (not waiting for background squid-z) but there are
> others, possibly including handling of Squid crashes. Do you see any
> other errors, assertions, or FATAL messages in your cache.log?
>
> 2. Squid code that is trying to open the shared segment is broken or,
> more likely, not compatible with your FreeBSD environment. For example,
> it tries to exclusively create a shared segment using the wrong name.
>
> If you can reproduce this, I recommend starting Squid via strace (or
> equivalent) to see the system calls that Squid is making when calling
> shm_open() and the exact call parameters. This can confirm or eliminate
> #2 as the suspect.
>
>
> HTH,
>
> Alex.
>

All I get from running strace -ff -vvv -o /tmp/squid-strace.txt
/opt/squid-3.5/sbin/squid -f /opt/squid-3.5/etc/squid.conf:
..
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
pread: Device busy
PIOCRUN: Input/output error
trouble opening proc file



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160407/111309a4/attachment.htm>

From yvoinov at gmail.com  Thu Apr  7 19:15:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 8 Apr 2016 01:15:31 +0600
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <57066BA0.80308@treenet.co.nz>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz>
Message-ID: <5706B1D3.8070603@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://bugs.squid-cache.org/show_bug.cgi?id=4486

07.04.16 20:16, Amos Jeffries ?????:
> On 7/04/2016 3:16 a.m., Odhiambo Washington wrote:
>> I am getting the following error in cache.log:
>>
>> Squid Cache (Version 3.5.16): Terminated abnormally.
>> CPU Usage: 0.082 seconds = 0.052 user + 0.030 sys
>> Maximum Resident Size: 54992 KB
>> Page faults with physical i/o: 0
>> FATAL: Ipc::Mem::Segment::create failed to
>> shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File exists
>>
>>
>> However, that file doesn't exist.
>>
>
> This can happen if you have a startup script the runs 'squid -z' or
> similar just prior to starting the main proxy, and not waiting
> sufficiently long for the -z run to finish.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXBrHTAAoJENNXIZxhPexGyn8IALAK0K2WLF3NfRX/fszUr/X/
6syPQWbGXUkw/ktauWB4HqegDEoDHMdRI5+EDUKNS8eFdfMgC8HY0EOVMowsw2RL
6hyKSwWzmVV0p+OzC77dzeAPC2MqlLa5kb8yCTHC1ZDtQv5ZJmgaHsMixzTHCCfj
fAme3vRG/HCJnQ4BbdybTz1XhYduB8aF91cRTQtQyGCYhkuRKYdVWpxDn1t2/+3D
lQrqymKFS34C5eqcm1HiaIoXLdiPUUcmLyY8QjXfaAQbrRR6yKLa613pjU6XFYP+
Aj7WthR4zHJgGPx65QLyEyHvyzAdgYCbjhRnyT7K4yonFvrEBC4a3DV6tePEzZg=
=+50D
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/6195d56f/attachment.key>

From yvoinov at gmail.com  Thu Apr  7 19:16:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 8 Apr 2016 01:16:20 +0600
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <57066BA0.80308@treenet.co.nz>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz>
Message-ID: <5706B204.6000203@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
https://vgy.me/GnhuDD.png

07.04.16 20:16, Amos Jeffries ?????:
> On 7/04/2016 3:16 a.m., Odhiambo Washington wrote:
>> I am getting the following error in cache.log:
>>
>> Squid Cache (Version 3.5.16): Terminated abnormally.
>> CPU Usage: 0.082 seconds = 0.052 user + 0.030 sys
>> Maximum Resident Size: 54992 KB
>> Page faults with physical i/o: 0
>> FATAL: Ipc::Mem::Segment::create failed to
>> shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File exists
>>
>>
>> However, that file doesn't exist.
>>
>
> This can happen if you have a startup script the runs 'squid -z' or
> similar just prior to starting the main proxy, and not waiting
> sufficiently long for the -z run to finish.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXBrIDAAoJENNXIZxhPexGhukH/i2RaUjjkbK5XQ7pgBmvfJgQ
+SktSTKKpRWNMqferypXWfoLr44ojXLELj6KB/cHTfY1fhCmKQy0pUSQxsiB8QFp
Yz3R8xxw/2rJPJDcZKQzxazDalVs7ihfTUAcMs8gA9FaebjOIs1kPNjy99t0Veow
QL0dZe3GYoL6eIaK+jeo6cRwckGsp6009s92icXTrGasIiDELMlBwGLz8VrdTjBP
QppjdSlV2EZA5q+8+WMvHxsWbJ7oZocnO+YW8LfunoJfmkC0kh0WUjORZjUiQ1/R
9MA69WmhdREKtnMmB2aKyuYtnSYPy4UXZRXlD/a9i9faOdVQR6hthCLNWDe3KtU=
=tD45
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/26a11401/attachment.key>

From rousskov at measurement-factory.com  Thu Apr  7 19:57:57 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 7 Apr 2016 13:57:57 -0600
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <CAAdA2WP-ntbYjh7MTXF4R60US9L0y8Yrtejvc-Wt77_XY1gQsQ@mail.gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz>
 <CAAdA2WPhcZokx8fb7zvWDOqDja1H7=ziOko3GFodHy05iw0QiA@mail.gmail.com>
 <57068C61.1030608@measurement-factory.com>
 <CAAdA2WP-ntbYjh7MTXF4R60US9L0y8Yrtejvc-Wt77_XY1gQsQ@mail.gmail.com>
Message-ID: <5706BBC5.1050507@measurement-factory.com>

On 04/07/2016 12:21 PM, Odhiambo Washington wrote:
> 
> 
> On 7 April 2016 at 19:35, Alex Rousskov
> <rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>> wrote:
> 
>     On 04/07/2016 08:21 AM, Odhiambo Washington wrote:
> 
>     > On 7 April 2016 at 17:16, Amos Jeffries wrote:
>     >
>     >     On 7/04/2016 3:16 a.m., Odhiambo Washington wrote:
>     >     > I am getting the following error in cache.log:
>     >     >
>     >     > Squid Cache (Version 3.5.16): Terminated abnormally.
>     >     > FATAL: Ipc::Mem::Segment::create failed to
>     >     > shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File exists
>     >     >
>     >     > However, that file doesn't exist.
> 
>     >     This can happen if you have a startup script the runs 'squid -z' or
>     >     similar just prior to starting the main proxy, and not waiting
>     >     sufficiently long for the -z run to finish.
> 
> 
>     > I am gonna check this out again tonight although I doubt if that is the
>     > cause.
>     >
>     > I run squid using daemontools, invoked as:
>     >
>     > exec setuidgid root /opt/squid-3.5/sbin/squid -f
>     > /opt/squid-3.5/etc/squid.conf -N
>     >
>     > /opt/squid-3.5/var/run/squid/ is actually empty when I get this error.
> 
> 
>     I see two possibilities:
> 
>     1. The file was there at the time the error was triggered but was not
>     there at the time you checked the directory. This would mean that
>     something is starting a second Squid while the first Squid has not
>     removed the shared memory segment file (yet). Amos mentioned one such
>     common scenario (not waiting for background squid-z) but there are
>     others, possibly including handling of Squid crashes. Do you see any
>     other errors, assertions, or FATAL messages in your cache.log?
> 
>     2. Squid code that is trying to open the shared segment is broken or,
>     more likely, not compatible with your FreeBSD environment. For example,
>     it tries to exclusively create a shared segment using the wrong name.
> 
>     If you can reproduce this, I recommend starting Squid via strace (or
>     equivalent) to see the system calls that Squid is making when calling
>     shm_open() and the exact call parameters. This can confirm or eliminate
>     #2 as the suspect.


3. The error reported by Squid is bogus. Squid has lots of code that
corrupts/overwrites the error number before actually reporting the
system call error...



> All I get from running strace -ff -vvv -o /tmp/squid-strace.txt
> /opt/squid-3.5/sbin/squid -f /opt/squid-3.5/etc/squid.conf:
> ..
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> pread: Device busy
> PIOCRUN: Input/output error
> trouble opening proc file 

The above does not look like strace output I am used to [on Linux], but
I cannot help you with making strace work. There may be a better tool on
FreeBSD. Hopefully, somebody else will tell you how to get the necessary
info on FreeBSD.

Alex.



From luisabdon8 at hotmail.com  Thu Apr  7 23:24:09 2016
From: luisabdon8 at hotmail.com (Luis Abdon Diaz Parra)
Date: Thu, 7 Apr 2016 18:24:09 -0500
Subject: [squid-users] query ?
Message-ID: <COL128-W59152075AF88007F1D249692900@phx.gbl>

Hello, good day to ask quisera
there any way atra instead of a domain allows me to upload all your files
I mean a group of users only allow you to access a specific domain dstdomain say "facebook.com" but does not load your images that refer to other URLs and domains

Luis Abdon Diaz ParraMovil: 951159908?La posibilidad de realizar un sue?o es lo que hace que la vida sea interesante?.
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160407/5086b39a/attachment.htm>

From asakura at ioc.dnp.co.jp  Fri Apr  8 05:21:30 2016
From: asakura at ioc.dnp.co.jp (asakura at ioc.dnp.co.jp)
Date: Fri, 08 Apr 2016 14:21:30 +0900 (JST)
Subject: [squid-users] ext_ldap_group_acl is returned ERR when LDAP bind
	was fail.
In-Reply-To: <20160323.150850.737004071327910996.asakura@ioc.dnp.co.jp>
References: <20160323.150850.737004071327910996.asakura@ioc.dnp.co.jp>
Message-ID: <20160408.142130.737004071327929819.asakura@ioc.dnp.co.jp>

Hello,

I posted a question last month below. However, I haven't receivedany replies.
Does anyone want to respond to this?

Thanks in advance for any comments you might have.

I investigating source code of ext_ldap_group_acl.cc below.

helpers/external_acl/LDAP_group/ext_ldap_group_acl.cc
571                     rc = ldap_simple_bind_s(ld, binddn, bindpasswd);
572                     if (rc != LDAP_SUCCESS) {
573                         fprintf(stderr, PROGRAM_NAME ": WARNING: could not bind to binddn '%s'\n        ", ldap_err2string(rc));
574                         ldap_unbind(ld);
575                         ld = NULL;
576                         break;
577                     }
snip...

593         if (found)
594             SEND_OK("");
595         else {
596             SEND_ERR("");
597         }

Regards,
Kazuhiro

From: asakura at ioc.dnp.co.jp
Subject: [squid-users] ext_ldap_group_acl is returned ERR when LDAP bind was fail.
Date: Wed, 23 Mar 2016 15:08:50 +0900 (JST)

> Hello,
> 
> Thank you always for your kind support.
> 
> I would like to ask you about SEND_ERR reply of ext_ldap_group_acl.
> In our environment, squid fail ldap_bind to LDAP server sometimes.
> Then, ext_ldap_group_acl replies "ERR". So, username is registered
> in the negative_cache.
> 
> I don't want to register in the negative_cache when external_acl
> failed ldap_bind.
> I guess that to solve if ext_ldap_group_acl reply SEND_BH instead of
> SEND_ERR.
> 
> I would appreciate it if you could investigate this.
> 
> Regards,
> Kazuhiro


From odhiambo at gmail.com  Fri Apr  8 10:28:54 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 8 Apr 2016 13:28:54 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <5706B1D3.8070603@gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
Message-ID: <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>

Hello Yuri,

Thanks, but this patch is for squid-4.0.8, right??


If applied to 3.5.16, the compilation fails as follows:


depbase=`echo mem/Segment.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;
/bin/bash ../../libtool  --tag=CXX    --mode=compile g++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-3.5/var/run/squid\"    -I../..
-I../../include  -I../../lib -I../../src  -I../../include  -I/usr/include
 -I/usr/include  -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2  -I/usr/local/include/libxml2 -Wall
-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual
-Werror -pipe -D_REENTRANT -I/usr/local/include  -g -O2 -march=native
-I/usr/local/include -MT mem/Segment.lo -MD -MP -MF $depbase.Tpo -c -o
mem/Segment.lo mem/Segment.cc && mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-3.5/var/run/squid\" -I../.. -I../../include
-I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
-I../../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings
-Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe -D_REENTRANT
-I/usr/local/include -g -O2 -march=native -I/usr/local/include -MT
mem/Segment.lo -MD -MP -MF mem/.deps/Segment.Tpo -c mem/Segment.cc  -fPIC
-DPIC -o mem/.libs/Segment.o
mem/Segment.cc: In member function 'void Ipc::Mem::Segment::create(off_t)':
mem/Segment.cc:95: error: no matching function for call to
'Ipc::Mem::Segment::createFresh()'
../../src/ipc/mem/Segment.h:57: note: candidates are: bool
Ipc::Mem::Segment::createFresh(int&)
mem/Segment.cc:97: error: no matching function for call to
'Ipc::Mem::Segment::createFresh()'
../../src/ipc/mem/Segment.h:57: note: candidates are: bool
Ipc::Mem::Segment::createFresh(int&)
mem/Segment.cc:107: error: 'xerrno' was not declared in this scope
*** Error code 1

Stop in /usr/home/wash/Tools/Squid/3.5/squid-3.5.16/src/ipc.
*** Error code 1

Stop in /usr/home/wash/Tools/Squid/3.5/squid-3.5.16/src.
*** Error code 1

Stop in /usr/home/wash/Tools/Squid/3.5/squid-3.5.16/src.
*** Error code 1

Stop in /usr/home/wash/Tools/Squid/3.5/squid-3.5.16.



On 7 April 2016 at 22:15, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> http://bugs.squid-cache.org/show_bug.cgi?id=4486
>
> 07.04.16 20:16, Amos Jeffries ?????:
> > On 7/04/2016 3:16 a.m., Odhiambo Washington wrote:
> >> I am getting the following error in cache.log:
> >>
> >> Squid Cache (Version 3.5.16): Terminated abnormally.
> >> CPU Usage: 0.082 seconds = 0.052 user + 0.030 sys
> >> Maximum Resident Size: 54992 KB
> >> Page faults with physical i/o: 0
> >> FATAL: Ipc::Mem::Segment::create failed to
> >> shm_open(/opt/squid-3.5/var/run/squid/cf__metadata.shm): (17) File
> exists
> >>
> >>
> >> However, that file doesn't exist.
> >>
> >
> > This can happen if you have a startup script the runs 'squid -z' or
> > similar just prior to starting the main proxy, and not waiting
> > sufficiently long for the -z run to finish.
> >
> > Amos
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXBrHTAAoJENNXIZxhPexGyn8IALAK0K2WLF3NfRX/fszUr/X/
> 6syPQWbGXUkw/ktauWB4HqegDEoDHMdRI5+EDUKNS8eFdfMgC8HY0EOVMowsw2RL
> 6hyKSwWzmVV0p+OzC77dzeAPC2MqlLa5kb8yCTHC1ZDtQv5ZJmgaHsMixzTHCCfj
> fAme3vRG/HCJnQ4BbdybTz1XhYduB8aF91cRTQtQyGCYhkuRKYdVWpxDn1t2/+3D
> lQrqymKFS34C5eqcm1HiaIoXLdiPUUcmLyY8QjXfaAQbrRR6yKLa613pjU6XFYP+
> Aj7WthR4zHJgGPx65QLyEyHvyzAdgYCbjhRnyT7K4yonFvrEBC4a3DV6tePEzZg=
> =+50D
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/78816f5f/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr  8 12:05:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 00:05:34 +1200
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
Message-ID: <57079E8E.4080800@treenet.co.nz>

On 8/04/2016 10:28 p.m., Odhiambo Washington wrote:
> Hello Yuri,
> 
> Thanks, but this patch is for squid-4.0.8, right??
> 

Yes the patch in that bug report is specific to the latest 4.0 snapshot,
which Yuri is running.

As Alex mentioned the errno usage in Squid was a bit wrong. The latest
4.0 have a patch to fix that, which is causing Yuri's problem. Your 3.5
issue may or may not be related. But we wont know until after Yuri
applies that patch and checks the results.

Amos



From yvoinov at gmail.com  Fri Apr  8 14:19:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 8 Apr 2016 20:19:50 +0600
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <57079E8E.4080800@treenet.co.nz>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz>
Message-ID: <5707BE06.3060809@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Seems fixed.

http://bugs.squid-cache.org/show_bug.cgi?id=4486#c2

08.04.16 18:05, Amos Jeffries ?????:
> On 8/04/2016 10:28 p.m., Odhiambo Washington wrote:
>> Hello Yuri,
>>
>> Thanks, but this patch is for squid-4.0.8, right??
>>
>
> Yes the patch in that bug report is specific to the latest 4.0 snapshot,
> which Yuri is running.
>
> As Alex mentioned the errno usage in Squid was a bit wrong. The latest
> 4.0 have a patch to fix that, which is causing Yuri's problem. Your 3.5
> issue may or may not be related. But we wont know until after Yuri
> applies that patch and checks the results.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXB74GAAoJENNXIZxhPexGwkwH/ipdtdS23EuZHIQHWEN7DeSM
aJ+b1lhRb+052wbL1vx8uyvhwGf++QVZcvFTGcxwFN0yQ1EaN1b1tE6IYlosG8IC
1rCOkARyZnyLK0MZKqvajrv4RZMR9CAvcRspv7DftQwS/2/h2uhnakc2PZYKBSUO
eF+hkxjUq2bSySY0sQ6tMTCr/U5x9IKzpg21VEE2tnn2S1HujnAEQ/C7pyi1ws7U
SXyqQBOVr25wxQq3AZMg5Sk6uZ7pSF02soCaIon7SeBdx6K+eWTngg9/t1Rn5zit
EGSrVLdEHsVFID/y5PsDMylpy4TwL+m0VCWSPbwYDGM+rp3tikfU/XAorFMR79M=
=mVL9
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/89c0af18/attachment.key>

From odhiambo at gmail.com  Fri Apr  8 14:38:13 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 8 Apr 2016 17:38:13 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <57079E8E.4080800@treenet.co.nz>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz>
Message-ID: <CAAdA2WPdCqVY3_qvH7iNSLhdZjACdTxRN4Hq4vfZNoZ8=yxuDQ@mail.gmail.com>

Now that Yuri has reported success, shall I wait for something for 3.5.16??
Could it be that I am the onlt one trying 3.5.16 on this old version of
FreeBSD? I am saying that because it is running well on FreeBSD-10.3 since
two days ago.

There is another e-mail I sent about 4.0.8 failing to compile successfully
on FreeBSD 10.3. Still waiting for response on that too.

I'd like to 'transparently intercept' https traffic (facebook, youtube and
a few other sites which users love so much) and subject those to time-based
ACLs. I have been looking around the cookbooks/howtos and I cannot pinpoint
which one is the definitive one to follow. Is it this one:
http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit



On 8 April 2016 at 15:05, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 8/04/2016 10:28 p.m., Odhiambo Washington wrote:
> > Hello Yuri,
> >
> > Thanks, but this patch is for squid-4.0.8, right??
> >
>
> Yes the patch in that bug report is specific to the latest 4.0 snapshot,
> which Yuri is running.
>
> As Alex mentioned the errno usage in Squid was a bit wrong. The latest
> 4.0 have a patch to fix that, which is causing Yuri's problem. Your 3.5
> issue may or may not be related. But we wont know until after Yuri
> applies that patch and checks the results.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/92b2bee4/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr  8 14:59:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 02:59:30 +1200
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <CAAdA2WPdCqVY3_qvH7iNSLhdZjACdTxRN4Hq4vfZNoZ8=yxuDQ@mail.gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz>
 <CAAdA2WPdCqVY3_qvH7iNSLhdZjACdTxRN4Hq4vfZNoZ8=yxuDQ@mail.gmail.com>
Message-ID: <5707C752.3050009@treenet.co.nz>

On 9/04/2016 2:38 a.m., Odhiambo Washington wrote:
> Now that Yuri has reported success, shall I wait for something for 3.5.16??

No that means his problem was unrelated to yours.

The 3.5.16 code in this area was correctly using errno. So the message
it was giving you was correct for your issue.

> Could it be that I am the onlt one trying 3.5.16 on this old version of
> FreeBSD? I am saying that because it is running well on FreeBSD-10.3 since
> two days ago.


Possibly yes. Or a compiler / stdlib related issue. 10 uses clang and
8.x use an old GCC IIRC.

> 
> There is another e-mail I sent about 4.0.8 failing to compile successfully
> on FreeBSD 10.3. Still waiting for response on that too.

If you mean the list query "compiling 4.0.8 on FreeBSD-10.1" I replied
to yesterday.

> 
> I'd like to 'transparently intercept' https traffic (facebook, youtube and
> a few other sites which users love so much) and subject those to time-based
> ACLs. I have been looking around the cookbooks/howtos and I cannot pinpoint
> which one is the definitive one to follow. Is it this one:
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> 

Thats the best one we have in the wiki at the moment.

Amos



From odhiambo at gmail.com  Fri Apr  8 15:20:02 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 8 Apr 2016 18:20:02 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <5707C752.3050009@treenet.co.nz>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz>
 <CAAdA2WPdCqVY3_qvH7iNSLhdZjACdTxRN4Hq4vfZNoZ8=yxuDQ@mail.gmail.com>
 <5707C752.3050009@treenet.co.nz>
Message-ID: <CAAdA2WNYnkN6SZow==OOedbV1UaGyxi=hHkU3E+jTkCwgTspLA@mail.gmail.com>

On 8 April 2016 at 17:59, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 9/04/2016 2:38 a.m., Odhiambo Washington wrote:
> > Now that Yuri has reported success, shall I wait for something for
> 3.5.16??
>
> No that means his problem was unrelated to yours.
>

Alright.


>
> The 3.5.16 code in this area was correctly using errno. So the message
> it was giving you was correct for your issue.
>

:-)


>
> > Could it be that I am the onlt one trying 3.5.16 on this old version of
> > FreeBSD? I am saying that because it is running well on FreeBSD-10.3
> since
> > two days ago.
>
>
> Possibly yes. Or a compiler / stdlib related issue. 10 uses clang and
> 8.x use an old GCC IIRC.
>

How do I get round to fixing it then??


>
> >
> > There is another e-mail I sent about 4.0.8 failing to compile
> successfully
> > on FreeBSD 10.3. Still waiting for response on that too.
>
> If you mean the list query "compiling 4.0.8 on FreeBSD-10.1" I replied
> to yesterday.
>
>
I hadn't seen the reply. Lemme follow that advise.


> >
> > I'd like to 'transparently intercept' https traffic (facebook, youtube
> and
> > a few other sites which users love so much) and subject those to
> time-based
> > ACLs. I have been looking around the cookbooks/howtos and I cannot
> pinpoint
> > which one is the definitive one to follow. Is it this one:
> > http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> >
>
> Thats the best one we have in the wiki at the moment.
>


Hopefully I get the 3.5.16 running, because 4.0.x doesnt compile on
FreeBSD-8.4 as follows:

[wash at gw ~/Tools/Squid/4.x/squid-4.0.8]$ ../build-4.sh
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... cfgaux/install-sh -c -d
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking whether UID '1001' is supported by ustar format... yes
checking whether GID '0' is supported by ustar format... yes
checking how to create a ustar tar archive... gnutar
checking whether to enable maintainer-specific portions of Makefiles... no
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking whether gcc understands -c and -o together... yes
checking for style of include used by make... GNU
checking dependency style of gcc... gcc3
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking dependency style of g++... gcc3
checking build system type... i386-unknown-freebsd8.4
checking host system type... i386-unknown-freebsd8.4
configure: CPU arch native optimization enabled: auto
checking whether compiler accepts -march=native... yes
checking simplified host os... freebsd (version 8.4)
checking whether g++ supports C++11 features by default... no
checking whether g++ supports C++11 features with -std=c++11... no
checking whether g++ supports C++11 features with -std=c++0x... no
*configure: error: *** A compiler with support for C++11 language features
is required.*
[wash at gw ~/Tools/Squid/4.x/squid-4.0.8]$ uname -a
FreeBSD gw.cVWWV.com 8.4-STABLE FreeBSD 8.4-STABLE #15: Sun May 17 14:28:17
EAT 2015     root at gw.VWWV.com:/usr/obj/usr/src/sys/GW  i386







-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/56f543dd/attachment.htm>

From yvoinov at gmail.com  Fri Apr  8 15:46:19 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 8 Apr 2016 21:46:19 +0600
Subject: [squid-users] Intermediace CA's repo
Message-ID: <5707D24B.6040604@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I just put it here. :)

https://github.com/iangcarroll/ca-intermediaries
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXB9JKAAoJENNXIZxhPexGyJwIAIYFfDZwBQ3CZJIDyWpNKvi1
URyu5/+JXTYf6CMR2ZSuuNaLSkLOjPAlI4itsbSX8hM/j4UBISJ5lQDTV7KH+Ntf
KK3IOalFlW9cuO9nzUkgAD08F/OtkP04YQVzXw0TUymHKia6DCJ6P+qGD3kUHNI2
bAZw53p+5pKMwWRxc1tPawTarOLVnMWi0COG8dhlGIfsjV6ShxhzZJmsZ58i0ins
2PPku9b6BN28Lqs6UvSKFbj+3mlG9ZZncLz4z0Wg+4xoNoxFPhbIFNkWGzuB6JiF
MU5ndIO2P9OgvxiCAj4METkzgVUiTl7ftu+xsI4yYy+XRVcu52Ea0WAd2aMcpu0=
=8Z0N
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/24bae6d7/attachment.key>

From odhiambo at gmail.com  Fri Apr  8 17:23:49 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 8 Apr 2016 20:23:49 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <5707BE06.3060809@gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz> <5707BE06.3060809@gmail.com>
Message-ID: <CAAdA2WPD4GS0ULA8tStG9J9mECcs=V2D06=Qaxz8Z5bGbVP_rQ@mail.gmail.com>

Hi Yuri,

Sorry to be a thorn in the flesh in this one.

Which source code were you applying this patch against?

I applied this patch on the released squid-4.0.8.tar.xz and it doesn't
apply cleanly for starters... Maybe I am doing it wrongly? Just doing patch
< /path/to/patch

wash at mail:~/ILI/Squid/4.x/squid-4.0.8$ patch < ../squid-4-14633.patch
Hmm...  Looks like a unified diff to me...
The text leading up to this was:
--------------------------
|------------------------------------------------------------
|revno: 14633
|revision-id: squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920
|parent: chtsanti at users.sourceforge.net-20160407163610-yl8zzhc08l1ysv5f
|committer: Amos Jeffries <squid3 at treenet.co.nz>
|branch nick: trunk
|timestamp: Fri 2016-04-08 19:35:47 +1200
|message:
|  Fix shm_open error message after rev.14625
|------------------------------------------------------------
|# Bazaar merge directive format 2 (Bazaar 0.90)
|# revision_id: squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920
|# target_branch: http://bzr.squid-cache.org/bzr/squid3/trunk/
|# testament_sha1: c1983f6601c29e4d03f936e60ecee221a860f932
|# timestamp: 2016-04-08 07:51:00 +0000
|# source_branch: http://bzr.squid-cache.org/bzr/squid3/trunk
|# base_revision_id: chtsanti at users.sourceforge.net-20160407163610-\
|#   yl8zzhc08l1ysv5f
|#
|# Begin patch
|=== modified file 'src/ipc/mem/Segment.cc'
|--- src/ipc/mem/Segment.cc     2016-04-03 23:41:58 +0000
|+++ src/ipc/mem/Segment.cc     2016-04-08 07:35:47 +0000
--------------------------
Patching file src/ipc/mem/Segment.cc using Plan A...
Hunk #1 failed at 91.
Hunk #2 succeeded at 105 (offset -4 lines).
Hunk #3 succeeded at 121 (offset -4 lines).
Hunk #4 succeeded at 151 (offset -1 lines).
1 out of 4 hunks failed--saving rejects to src/ipc/mem/Segment.cc.rej
Hmm...  The next patch looks like a unified diff to me...
The text leading up to this was:
--------------------------
|
|=== modified file 'src/ipc/mem/Segment.h'
|--- src/ipc/mem/Segment.h      2016-03-24 17:02:25 +0000
|+++ src/ipc/mem/Segment.h      2016-04-08 07:35:47 +0000
--------------------------
Patching file src/ipc/mem/Segment.h using Plan A...
Hunk #1 succeeded at 53.
Hmm...  Ignoring the trailing garbage.
done


Then when I compile, the compilation fails as follows (though without the
patch the compilation succeeds):

libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
-I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
-I../../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include/libxml2 -Werror -Qunused-arguments
-Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
-I/usr/local/include -MT mem/Pages.lo -MD -MP -MF mem/.deps/Pages.Tpo -c
mem/Pages.cc  -fPIC -DPIC -o mem/.libs/Pages.o
libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
-I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
-I../../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include/libxml2 -Werror -Qunused-arguments
-Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
-I/usr/local/include -MT mem/Pages.lo -MD -MP -MF mem/.deps/Pages.Tpo -c
mem/Pages.cc -o mem/Pages.o >/dev/null 2>&1
depbase=`echo mem/PageStack.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;
/bin/sh ../../libtool  --tag=CXX    --mode=compile clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\"    -I../..
-I../../include  -I../../lib -I../../src  -I../../include  -I/usr/include
 -I/usr/include  -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2  -I/usr/local/include/libxml2  -Werror
-Qunused-arguments -Wno-deprecated-register  -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/PageStack.lo -MD -MP
-MF $depbase.Tpo -c -o mem/PageStack.lo mem/PageStack.cc && mv -f
$depbase.Tpo $depbase.Plo
libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
-I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
-I../../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include/libxml2 -Werror -Qunused-arguments
-Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
-I/usr/local/include -MT mem/PageStack.lo -MD -MP -MF
mem/.deps/PageStack.Tpo -c mem/PageStack.cc  -fPIC -DPIC -o
mem/.libs/PageStack.o
libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
-I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
-I../../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include/libxml2 -Werror -Qunused-arguments
-Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
-I/usr/local/include -MT mem/PageStack.lo -MD -MP -MF
mem/.deps/PageStack.Tpo -c mem/PageStack.cc -o mem/PageStack.o >/dev/null
2>&1
depbase=`echo mem/Segment.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`; /bin/sh
../../libtool  --tag=CXX    --mode=compile clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\"    -I../..
-I../../include  -I../../lib -I../../src  -I../../include  -I/usr/include
 -I/usr/include  -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2  -I/usr/local/include/libxml2  -Werror
-Qunused-arguments -Wno-deprecated-register  -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/Segment.lo -MD -MP
-MF $depbase.Tpo -c -o mem/Segment.lo mem/Segment.cc && mv -f $depbase.Tpo
$depbase.Plo
libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
-I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
-I../../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include/libxml2 -Werror -Qunused-arguments
-Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
-I/usr/local/include -MT mem/Segment.lo -MD -MP -MF mem/.deps/Segment.Tpo
-c mem/Segment.cc  -fPIC -DPIC -o mem/.libs/Segment.o
mem/Segment.cc:96:22: error: too few arguments to function call, single
argument 'err' was not specified
    if (!createFresh() && errno == EEXIST) {
         ~~~~~~~~~~~ ^
../../src/ipc/mem/Segment.h:56:5: note: 'createFresh' declared here
    bool createFresh(int &err);
    ^
mem/Segment.cc:98:21: error: too few arguments to function call, single
argument 'err' was not specified
        createFresh();
        ~~~~~~~~~~~ ^
../../src/ipc/mem/Segment.h:56:5: note: 'createFresh' declared here
    bool createFresh(int &err);
    ^
mem/Segment.cc:108:9: error: use of undeclared identifier 'xerrno'
        xerrno = errno;
        ^
mem/Segment.cc:110:66: error: use of undeclared identifier 'xerrno'
        debugs(54, 5, "ftruncate " << theName << ": " << xstrerr(xerrno));
                                                                 ^
../../src/Debug.h:107:21: note: expanded from macro 'debugs'
            _dbo << CONTENT; \
                    ^
mem/Segment.cc:112:45: error: use of undeclared identifier 'xerrno'
               theName.termedBuf(), xstrerr(xerrno));
                                            ^
5 errors generated.
*** Error code 1

Stop.
make[3]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src/ipc
*** Error code 1

Stop.
make[2]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src
*** Error code 1

Stop.
make[1]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src
*** Error code 1

Stop.
make: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8


Okay, I know I am being a bug here myself since I am focused on 3.5 now
more than 4.x but I also like giving the little feedback I can from these
FreeBSD servers I have:-)





On 8 April 2016 at 17:19, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Seems fixed.
>
> http://bugs.squid-cache.org/show_bug.cgi?id=4486#c2
>
> 08.04.16 18:05, Amos Jeffries ?????:
> > On 8/04/2016 10:28 p.m., Odhiambo Washington wrote:
> >> Hello Yuri,
> >>
> >> Thanks, but this patch is for squid-4.0.8, right??
> >>
> >
> > Yes the patch in that bug report is specific to the latest 4.0 snapshot,
> > which Yuri is running.
> >
> > As Alex mentioned the errno usage in Squid was a bit wrong. The latest
> > 4.0 have a patch to fix that, which is causing Yuri's problem. Your 3.5
> > issue may or may not be related. But we wont know until after Yuri
> > applies that patch and checks the results.
> >
> > Amos
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXB74GAAoJENNXIZxhPexGwkwH/ipdtdS23EuZHIQHWEN7DeSM
> aJ+b1lhRb+052wbL1vx8uyvhwGf++QVZcvFTGcxwFN0yQ1EaN1b1tE6IYlosG8IC
> 1rCOkARyZnyLK0MZKqvajrv4RZMR9CAvcRspv7DftQwS/2/h2uhnakc2PZYKBSUO
> eF+hkxjUq2bSySY0sQ6tMTCr/U5x9IKzpg21VEE2tnn2S1HujnAEQ/C7pyi1ws7U
> SXyqQBOVr25wxQq3AZMg5Sk6uZ7pSF02soCaIon7SeBdx6K+eWTngg9/t1Rn5zit
> EGSrVLdEHsVFID/y5PsDMylpy4TwL+m0VCWSPbwYDGM+rp3tikfU/XAorFMR79M=
> =mVL9
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/ebd7a6ef/attachment.htm>

From yvoinov at gmail.com  Fri Apr  8 17:26:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 8 Apr 2016 23:26:31 +0600
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <CAAdA2WPD4GS0ULA8tStG9J9mECcs=V2D06=Qaxz8Z5bGbVP_rQ@mail.gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz> <5707BE06.3060809@gmail.com>
 <CAAdA2WPD4GS0ULA8tStG9J9mECcs=V2D06=Qaxz8Z5bGbVP_rQ@mail.gmail.com>
Message-ID: <5707E9C7.8030303@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Note: Codebase for 4.0.x is different with 3.5.x.  So, most patches for
4.x.x series can't be applied onto 3.5.x.

08.04.16 23:23, Odhiambo Washington ?????:
> Hi Yuri,
>
> Sorry to be a thorn in the flesh in this one.
>
> Which source code were you applying this patch against?
>
> I applied this patch on the released squid-4.0.8.tar.xz and it doesn't
apply cleanly for starters... Maybe I am doing it wrongly? Just doing
patch < /path/to/patch
>
> wash at mail:~/ILI/Squid/4.x/squid-4.0.8$ patch < ../squid-4-14633.patch
> Hmm...  Looks like a unified diff to me...
> The text leading up to this was:
> --------------------------
> |------------------------------------------------------------
> |revno: 14633
> |revision-id: squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920
> |parent: chtsanti at users.sourceforge.net-20160407163610-yl8zzhc08l1ysv5f
> |committer: Amos Jeffries <squid3 at treenet.co.nz
<mailto:squid3 at treenet.co.nz>>
> |branch nick: trunk
> |timestamp: Fri 2016-04-08 19:35:47 +1200
> |message:
> |  Fix shm_open error message after rev.14625
> |------------------------------------------------------------
> |# Bazaar merge directive format 2 (Bazaar 0.90)
> |# revision_id: squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920
> |# target_branch: http://bzr.squid-cache.org/bzr/squid3/trunk/
> |# testament_sha1: c1983f6601c29e4d03f936e60ecee221a860f932
> |# timestamp: 2016-04-08 07:51:00 +0000
> |# source_branch: http://bzr.squid-cache.org/bzr/squid3/trunk
> |# base_revision_id: chtsanti at users.sourceforge.net-20160407163610-\
> |#   yl8zzhc08l1ysv5f
> |#
> |# Begin patch
> |=== modified file 'src/ipc/mem/Segment.cc'
> |--- src/ipc/mem/Segment.cc     2016-04-03 23:41:58 +0000
> |+++ src/ipc/mem/Segment.cc     2016-04-08 07:35:47 +0000
> --------------------------
> Patching file src/ipc/mem/Segment.cc using Plan A...
> Hunk #1 failed at 91.
> Hunk #2 succeeded at 105 (offset -4 lines).
> Hunk #3 succeeded at 121 (offset -4 lines).
> Hunk #4 succeeded at 151 (offset -1 lines).
> 1 out of 4 hunks failed--saving rejects to src/ipc/mem/Segment.cc.rej
> Hmm...  The next patch looks like a unified diff to me...
> The text leading up to this was:
> --------------------------
> |
> |=== modified file 'src/ipc/mem/Segment.h'
> |--- src/ipc/mem/Segment.h      2016-03-24 17:02:25 +0000
> |+++ src/ipc/mem/Segment.h      2016-04-08 07:35:47 +0000
> --------------------------
> Patching file src/ipc/mem/Segment.h using Plan A...
> Hunk #1 succeeded at 53.
> Hmm...  Ignoring the trailing garbage.
> done
>
>
> Then when I compile, the compilation fails as follows (though without
the patch the compilation succeeds):
>
> libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
-I../../include -I../../lib -I../../src -I../../include -I/usr/include
-I/usr/include -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/Pages.lo -MD -MP
-MF mem/.deps/Pages.Tpo -c mem/Pages.cc  -fPIC -DPIC -o mem/.libs/Pages.o
> libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
-I../../include -I../../lib -I../../src -I../../include -I/usr/include
-I/usr/include -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/Pages.lo -MD -MP
-MF mem/.deps/Pages.Tpo -c mem/Pages.cc -o mem/Pages.o >/dev/null 2>&1
> depbase=`echo mem/PageStack.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;
/bin/sh ../../libtool  --tag=CXX    --mode=compile clang++
-DHAVE_CONFIG_H -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\"   
-I../.. -I../../include  -I../../lib -I../../src  -I../../include 
-I/usr/include  -I/usr/include  -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2  -I/usr/local/include/libxml2  -Werror
-Qunused-arguments -Wno-deprecated-register  -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/PageStack.lo -MD
-MP -MF $depbase.Tpo -c -o mem/PageStack.lo mem/PageStack.cc && mv -f
$depbase.Tpo $depbase.Plo
> libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
-I../../include -I../../lib -I../../src -I../../include -I/usr/include
-I/usr/include -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/PageStack.lo -MD
-MP -MF mem/.deps/PageStack.Tpo -c mem/PageStack.cc  -fPIC -DPIC -o
mem/.libs/PageStack.o
> libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
-I../../include -I../../lib -I../../src -I../../include -I/usr/include
-I/usr/include -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/PageStack.lo -MD
-MP -MF mem/.deps/PageStack.Tpo -c mem/PageStack.cc -o mem/PageStack.o
>/dev/null 2>&1
> depbase=`echo mem/Segment.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;
/bin/sh ../../libtool  --tag=CXX    --mode=compile clang++
-DHAVE_CONFIG_H -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\"   
-I../.. -I../../include  -I../../lib -I../../src  -I../../include 
-I/usr/include  -I/usr/include  -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2  -I/usr/local/include/libxml2  -Werror
-Qunused-arguments -Wno-deprecated-register  -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/Segment.lo -MD -MP
-MF $depbase.Tpo -c -o mem/Segment.lo mem/Segment.cc && mv -f
$depbase.Tpo $depbase.Plo
> libtool: compile:  clang++ -DHAVE_CONFIG_H
-DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
-I../../include -I../../lib -I../../src -I../../include -I/usr/include
-I/usr/include -I../../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
-Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
-march=native -std=c++11 -I/usr/local/include -MT mem/Segment.lo -MD -MP
-MF mem/.deps/Segment.Tpo -c mem/Segment.cc  -fPIC -DPIC -o
mem/.libs/Segment.o
> mem/Segment.cc:96:22: error: too few arguments to function call,
single argument 'err' was not specified
>     if (!createFresh() && errno == EEXIST) {
>          ~~~~~~~~~~~ ^
> ../../src/ipc/mem/Segment.h:56:5: note: 'createFresh' declared here
>     bool createFresh(int &err);
>     ^
> mem/Segment.cc:98:21: error: too few arguments to function call,
single argument 'err' was not specified
>         createFresh();
>         ~~~~~~~~~~~ ^
> ../../src/ipc/mem/Segment.h:56:5: note: 'createFresh' declared here
>     bool createFresh(int &err);
>     ^
> mem/Segment.cc:108:9: error: use of undeclared identifier 'xerrno'
>         xerrno = errno;
>         ^
> mem/Segment.cc:110:66: error: use of undeclared identifier 'xerrno'
>         debugs(54, 5, "ftruncate " << theName << ": " << xstrerr(xerrno));
>                                                                  ^
> ../../src/Debug.h:107:21: note: expanded from macro 'debugs'
>             _dbo << CONTENT; \
>                     ^
> mem/Segment.cc:112:45: error: use of undeclared identifier 'xerrno'
>                theName.termedBuf(), xstrerr(xerrno));
>                                             ^
> 5 errors generated.
> *** Error code 1
>
> Stop.
> make[3]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src/ipc
> *** Error code 1
>
> Stop.
> make[2]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src
> *** Error code 1
>
> Stop.
> make[1]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src
> *** Error code 1
>
> Stop.
> make: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8
>
>
> Okay, I know I am being a bug here myself since I am focused on 3.5
now more than 4.x but I also like giving the little feedback I can from
these FreeBSD servers I have:-)
>
>
>
>
>
> On 8 April 2016 at 17:19, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> Seems fixed.
>
> http://bugs.squid-cache.org/show_bug.cgi?id=4486#c2
>
> 08.04.16 18:05, Amos Jeffries ?????:
> > On 8/04/2016 10:28 p.m., Odhiambo Washington wrote:
> >> Hello Yuri,
> >>
> >> Thanks, but this patch is for squid-4.0.8, right??
> >>
>
> > Yes the patch in that bug report is specific to the latest 4.0 snapshot,
> > which Yuri is running.
>
> > As Alex mentioned the errno usage in Squid was a bit wrong. The latest
> > 4.0 have a patch to fix that, which is causing Yuri's problem. Your 3.5
> > issue may or may not be related. But we wont know until after Yuri
> > applies that patch and checks the results.
>
> > Amos
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXB+nGAAoJENNXIZxhPexGPbwH/2vQ0DotjjMQ8rtS+bUYri27
qtF91SKYcxUVlpMYqZ4WkCY4J6f9R0s2lyejUM2UxXaPK+Y5Sule4OSzUzjUt/TH
bmHWlfEQ4m/RP8fcAI9LVLfrJauT7MagnT6DsE/Yz3CAKFGJ5E1TnGy7ppzbVA0K
mEqlspld/ZDnFAJTCz616BKGfmZIXISd7KxxB9V4uOgLjVKwSydczDSse4xqA+GQ
MFW4MHf3RtS7TAU6CwSdykGrTGGlO8JE+c0E2MPcZs+gYjwoE2qFjv/U8PKC1482
AZZxJ05+Ew5c/VN7mJpjSRavC1yeBy0l0ReiZlKpcuno2cuXIp6qeZ7OjxIj7oc=
=9dU1
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/3fdaca9a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/3fdaca9a/attachment.key>

From odhiambo at gmail.com  Fri Apr  8 17:32:15 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 8 Apr 2016 20:32:15 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <5707E9C7.8030303@gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz> <5707BE06.3060809@gmail.com>
 <CAAdA2WPD4GS0ULA8tStG9J9mECcs=V2D06=Qaxz8Z5bGbVP_rQ@mail.gmail.com>
 <5707E9C7.8030303@gmail.com>
Message-ID: <CAAdA2WO5=hmi-on1HWZjQV9tMjD2Cvramk5+RPpZfVrH7Y_w-Q@mail.gmail.com>

Hi Yuri,

I applied the patch against 4.0.8, not 3.5.16. Check my e-mail well well :-)

Could it be that you have a different code base from the tarballs available
for everyone?



On 8 April 2016 at 20:26, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Note: Codebase for 4.0.x is different with 3.5.x.  So, most patches for
> 4.x.x series can't be applied onto 3.5.x.
>
> 08.04.16 23:23, Odhiambo Washington ?????:
> > Hi Yuri,
> >
> > Sorry to be a thorn in the flesh in this one.
> >
> > Which source code were you applying this patch against?
> >
> > I applied this patch on the released squid-4.0.8.tar.xz and it doesn't
> apply cleanly for starters... Maybe I am doing it wrongly? Just doing patch
> < /path/to/patch
> >
> > wash at mail:~/ILI/Squid/4.x/squid-4.0.8$ patch < ../squid-4-14633.patch
> > Hmm...  Looks like a unified diff to me...
> > The text leading up to this was:
> > --------------------------
> > |------------------------------------------------------------
> > |revno: 14633
> > |revision-id: squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920
> > |parent: chtsanti at users.sourceforge.net-20160407163610-yl8zzhc08l1ysv5f
> > |committer: Amos Jeffries <squid3 at treenet.co.nz
> <mailto:squid3 at treenet.co.nz> <squid3 at treenet.co.nz>>
>
> > |branch nick: trunk
> > |timestamp: Fri 2016-04-08 19:35:47 +1200
> > |message:
> > |  Fix shm_open error message after rev.14625
> > |------------------------------------------------------------
> > |# Bazaar merge directive format 2 (Bazaar 0.90)
> > |# revision_id: squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920
> > |# target_branch: http://bzr.squid-cache.org/bzr/squid3/trunk/
> > |# testament_sha1: c1983f6601c29e4d03f936e60ecee221a860f932
> > |# timestamp: 2016-04-08 07:51:00 +0000
> > |# source_branch: http://bzr.squid-cache.org/bzr/squid3/trunk
> > |# base_revision_id: chtsanti at users.sourceforge.net-20160407163610-\
> > |#   yl8zzhc08l1ysv5f
> > |#
> > |# Begin patch
> > |=== modified file 'src/ipc/mem/Segment.cc'
> > |--- src/ipc/mem/Segment.cc     2016-04-03 23:41:58 +0000
> > |+++ src/ipc/mem/Segment.cc     2016-04-08 07:35:47 +0000
> > --------------------------
> > Patching file src/ipc/mem/Segment.cc using Plan A...
> > Hunk #1 failed at 91.
> > Hunk #2 succeeded at 105 (offset -4 lines).
> > Hunk #3 succeeded at 121 (offset -4 lines).
> > Hunk #4 succeeded at 151 (offset -1 lines).
> > 1 out of 4 hunks failed--saving rejects to src/ipc/mem/Segment.cc.rej
> > Hmm...  The next patch looks like a unified diff to me...
> > The text leading up to this was:
> > --------------------------
> > |
> > |=== modified file 'src/ipc/mem/Segment.h'
> > |--- src/ipc/mem/Segment.h      2016-03-24 17:02:25 +0000
> > |+++ src/ipc/mem/Segment.h      2016-04-08 07:35:47 +0000
> > --------------------------
> > Patching file src/ipc/mem/Segment.h using Plan A...
> > Hunk #1 succeeded at 53.
> > Hmm...  Ignoring the trailing garbage.
> > done
> >
> >
> > Then when I compile, the compilation fails as follows (though without
> the patch the compilation succeeds):
> >
> > libtool: compile:  clang++ -DHAVE_CONFIG_H
> -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
> -I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
> -I../../libltdl -I/usr/include -I/usr/local/include/libxml2
> -I/usr/local/include/libxml2 -Werror -Qunused-arguments
> -Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
> -I/usr/local/include -MT mem/Pages.lo -MD -MP -MF mem/.deps/Pages.Tpo -c
> mem/Pages.cc  -fPIC -DPIC -o mem/.libs/Pages.o
> > libtool: compile:  clang++ -DHAVE_CONFIG_H
> -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
> -I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
> -I../../libltdl -I/usr/include -I/usr/local/include/libxml2
> -I/usr/local/include/libxml2 -Werror -Qunused-arguments
> -Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
> -I/usr/local/include -MT mem/Pages.lo -MD -MP -MF mem/.deps/Pages.Tpo -c
> mem/Pages.cc -o mem/Pages.o >/dev/null 2>&1
> > depbase=`echo mem/PageStack.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;
> /bin/sh ../../libtool  --tag=CXX    --mode=compile clang++ -DHAVE_CONFIG_H
> -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\"    -I../..
> -I../../include  -I../../lib -I../../src  -I../../include  -I/usr/include
> -I/usr/include  -I../../libltdl -I/usr/include
> -I/usr/local/include/libxml2  -I/usr/local/include/libxml2  -Werror
> -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT -g -O2
> -march=native -std=c++11 -I/usr/local/include -MT mem/PageStack.lo -MD -MP
> -MF $depbase.Tpo -c -o mem/PageStack.lo mem/PageStack.cc && mv -f
> $depbase.Tpo $depbase.Plo
> > libtool: compile:  clang++ -DHAVE_CONFIG_H
> -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
> -I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
> -I../../libltdl -I/usr/include -I/usr/local/include/libxml2
> -I/usr/local/include/libxml2 -Werror -Qunused-arguments
> -Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
> -I/usr/local/include -MT mem/PageStack.lo -MD -MP -MF
> mem/.deps/PageStack.Tpo -c mem/PageStack.cc  -fPIC -DPIC -o
> mem/.libs/PageStack.o
> > libtool: compile:  clang++ -DHAVE_CONFIG_H
> -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
> -I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
> -I../../libltdl -I/usr/include -I/usr/local/include/libxml2
> -I/usr/local/include/libxml2 -Werror -Qunused-arguments
> -Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
> -I/usr/local/include -MT mem/PageStack.lo -MD -MP -MF
> mem/.deps/PageStack.Tpo -c mem/PageStack.cc -o mem/PageStack.o >/dev/null
> 2>&1
> > depbase=`echo mem/Segment.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;
> /bin/sh ../../libtool  --tag=CXX    --mode=compile clang++ -DHAVE_CONFIG_H
> -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\"    -I../..
> -I../../include  -I../../lib -I../../src  -I../../include  -I/usr/include
> -I/usr/include  -I../../libltdl -I/usr/include
> -I/usr/local/include/libxml2  -I/usr/local/include/libxml2  -Werror
> -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT -g -O2
> -march=native -std=c++11 -I/usr/local/include -MT mem/Segment.lo -MD -MP
> -MF $depbase.Tpo -c -o mem/Segment.lo mem/Segment.cc && mv -f $depbase.Tpo
> $depbase.Plo
> > libtool: compile:  clang++ -DHAVE_CONFIG_H
> -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../.. -I../../include
> -I../../lib -I../../src -I../../include -I/usr/include -I/usr/include
> -I../../libltdl -I/usr/include -I/usr/local/include/libxml2
> -I/usr/local/include/libxml2 -Werror -Qunused-arguments
> -Wno-deprecated-register -D_REENTRANT -g -O2 -march=native -std=c++11
> -I/usr/local/include -MT mem/Segment.lo -MD -MP -MF mem/.deps/Segment.Tpo
> -c mem/Segment.cc  -fPIC -DPIC -o mem/.libs/Segment.o
> > mem/Segment.cc:96:22: error: too few arguments to function call, single
> argument 'err' was not specified
> >     if (!createFresh() && errno == EEXIST) {
> >          ~~~~~~~~~~~ ^
> > ../../src/ipc/mem/Segment.h:56:5: note: 'createFresh' declared here
> >     bool createFresh(int &err);
> >     ^
> > mem/Segment.cc:98:21: error: too few arguments to function call, single
> argument 'err' was not specified
> >         createFresh();
> >         ~~~~~~~~~~~ ^
> > ../../src/ipc/mem/Segment.h:56:5: note: 'createFresh' declared here
> >     bool createFresh(int &err);
> >     ^
> > mem/Segment.cc:108:9: error: use of undeclared identifier 'xerrno'
> >         xerrno = errno;
> >         ^
> > mem/Segment.cc:110:66: error: use of undeclared identifier 'xerrno'
> >         debugs(54, 5, "ftruncate " << theName << ": " <<
> xstrerr(xerrno));
> >                                                                  ^
> > ../../src/Debug.h:107:21: note: expanded from macro 'debugs'
> >             _dbo << CONTENT; \
> >                     ^
> > mem/Segment.cc:112:45: error: use of undeclared identifier 'xerrno'
> >                theName.termedBuf(), xstrerr(xerrno));
> >                                             ^
> > 5 errors generated.
> > *** Error code 1
> >
> > Stop.
> > make[3]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src/ipc
> > *** Error code 1
> >
> > Stop.
> > make[2]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src
> > *** Error code 1
> >
> > Stop.
> > make[1]: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src
> > *** Error code 1
> >
> > Stop.
> > make: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8
> >
> >
> > Okay, I know I am being a bug here myself since I am focused on 3.5 now
> more than 4.x but I also like giving the little feedback I can from these
> FreeBSD servers I have:-)
> >
> >
> >
> >
> >
> > On 8 April 2016 at 17:19, Yuri Voinov <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> wrote:
> >
> >
> > Seems fixed.
> >
> > http://bugs.squid-cache.org/show_bug.cgi?id=4486#c2
> >
> > 08.04.16 18:05, Amos Jeffries ?????:
> > > On 8/04/2016 10:28 p.m., Odhiambo Washington wrote:
> > >> Hello Yuri,
> > >>
> > >> Thanks, but this patch is for squid-4.0.8, right??
> > >>
> >
> > > Yes the patch in that bug report is specific to the latest 4.0
> snapshot,
> > > which Yuri is running.
> >
> > > As Alex mentioned the errno usage in Squid was a bit wrong. The latest
> > > 4.0 have a patch to fix that, which is causing Yuri's problem. Your 3.5
> > > issue may or may not be related. But we wont know until after Yuri
> > > applies that patch and checks the results.
> >
> > > Amos
> >
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> > > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >
> > --
> > Best regards,
> > Odhiambo WASHINGTON,
> > Nairobi,KE
> > +254 7 3200 0004/+254 7 2274 3223
> > "Oh, the cruft."
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXB+nGAAoJENNXIZxhPexGPbwH/2vQ0DotjjMQ8rtS+bUYri27
> qtF91SKYcxUVlpMYqZ4WkCY4J6f9R0s2lyejUM2UxXaPK+Y5Sule4OSzUzjUt/TH
> bmHWlfEQ4m/RP8fcAI9LVLfrJauT7MagnT6DsE/Yz3CAKFGJ5E1TnGy7ppzbVA0K
> mEqlspld/ZDnFAJTCz616BKGfmZIXISd7KxxB9V4uOgLjVKwSydczDSse4xqA+GQ
> MFW4MHf3RtS7TAU6CwSdykGrTGGlO8JE+c0E2MPcZs+gYjwoE2qFjv/U8PKC1482
> AZZxJ05+Ew5c/VN7mJpjSRavC1yeBy0l0ReiZlKpcuno2cuXIp6qeZ7OjxIj7oc=
> =9dU1
> -----END PGP SIGNATURE-----
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/f05d62dd/attachment.htm>

From yvoinov at gmail.com  Fri Apr  8 17:37:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 8 Apr 2016 23:37:31 +0600
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <CAAdA2WO5=hmi-on1HWZjQV9tMjD2Cvramk5+RPpZfVrH7Y_w-Q@mail.gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz> <5707BE06.3060809@gmail.com>
 <CAAdA2WPD4GS0ULA8tStG9J9mECcs=V2D06=Qaxz8Z5bGbVP_rQ@mail.gmail.com>
 <5707E9C7.8030303@gmail.com>
 <CAAdA2WO5=hmi-on1HWZjQV9tMjD2Cvramk5+RPpZfVrH7Y_w-Q@mail.gmail.com>
Message-ID: <5707EC5B.3080701@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Don't think so. I've gave latest 4.0.8 tarball from site. Applied patch
- viola! - issue is gone.

08.04.16 23:32, Odhiambo Washington ?????:
> Hi Yuri,
>
> I applied the patch against 4.0.8, not 3.5.16. Check my e-mail well
well :-)
>
> Could it be that you have a different code base from the tarballs
available for everyone?
>
>
>
> On 8 April 2016 at 20:26, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> Note: Codebase for 4.0.x is different with 3.5.x.  So, most patches
for 4.x.x series can't be applied onto 3.5.x.
>
> 08.04.16 23:23, Odhiambo Washington ?????:
> > Hi Yuri,
>
>
>
>       > Sorry to be a thorn in the flesh in this one.
>
>
>
>       > Which source code were you applying this patch against?
>
>
>
>       > I applied this patch on the released squid-4.0.8.tar.xz and
>       it doesn't apply cleanly for starters... Maybe I am doing it
>       wrongly? Just doing patch < /path/to/patch
>
>
>
>       > wash at mail:~/ILI/Squid/4.x/squid-4.0.8$
<mailto:wash at mail:~/ILI/Squid/4.x/squid-4.0.8$> patch <
>       ../squid-4-14633.patch
>
>       > Hmm...  Looks like a unified diff to me...
>
>       > The text leading up to this was:
>
>       > --------------------------
>
>       > |------------------------------------------------------------
>
>       > |revno: 14633
>
>       > |revision-id:
>       squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920
<mailto:squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920>
>
>       > |parent:
>       chtsanti at users.sourceforge.net-20160407163610-yl8zzhc08l1ysv5f
<mailto:chtsanti at users.sourceforge.net-20160407163610-yl8zzhc08l1ysv5f>
>
>       > |committer: Amos Jeffries <squid3 at treenet.co.nz
<mailto:squid3 at treenet.co.nz>
>       <mailto:squid3 at treenet.co.nz> <mailto:squid3 at treenet.co.nz>>
>
>
>       > |branch nick: trunk
>
>       > |timestamp: Fri 2016-04-08 19:35:47 +1200
>
>       > |message:
>
>       > |  Fix shm_open error message after rev.14625
>
>       > |------------------------------------------------------------
>
>       > |# Bazaar merge directive format 2 (Bazaar 0.90)
>
>       > |# revision_id:
>       squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920
<mailto:squid3 at treenet.co.nz-20160408073547-xtjco0mpai4lr920>
>
>       > |# target_branch:
>       http://bzr.squid-cache.org/bzr/squid3/trunk/
>
>       > |# testament_sha1: c1983f6601c29e4d03f936e60ecee221a860f932
>
>       > |# timestamp: 2016-04-08 07:51:00 +0000
>
>       > |# source_branch: http://bzr.squid-cache.org/bzr/squid3/trunk
>
>       > |# base_revision_id:
>       chtsanti at users.sourceforge.net-20160407163610-\
<mailto:chtsanti at users.sourceforge.net-20160407163610-%5C>
>
>       > |#   yl8zzhc08l1ysv5f
>
>       > |#
>
>       > |# Begin patch
>
>       > |=== modified file 'src/ipc/mem/Segment.cc'
>
>       > |--- src/ipc/mem/Segment.cc     2016-04-03 23:41:58 +0000
>
>       > |+++ src/ipc/mem/Segment.cc     2016-04-08 07:35:47 +0000
>
>       > --------------------------
>
>       > Patching file src/ipc/mem/Segment.cc using Plan A...
>
>       > Hunk #1 failed at 91.
>
>       > Hunk #2 succeeded at 105 (offset -4 lines).
>
>       > Hunk #3 succeeded at 121 (offset -4 lines).
>
>       > Hunk #4 succeeded at 151 (offset -1 lines).
>
>       > 1 out of 4 hunks failed--saving rejects to
>       src/ipc/mem/Segment.cc.rej
>
>       > Hmm...  The next patch looks like a unified diff to me...
>
>       > The text leading up to this was:
>
>       > --------------------------
>
>       > |
>
>       > |=== modified file 'src/ipc/mem/Segment.h'
>
>       > |--- src/ipc/mem/Segment.h      2016-03-24 17:02:25 +0000
>
>       > |+++ src/ipc/mem/Segment.h      2016-04-08 07:35:47 +0000
>
>       > --------------------------
>
>       > Patching file src/ipc/mem/Segment.h using Plan A...
>
>       > Hunk #1 succeeded at 53.
>
>       > Hmm...  Ignoring the trailing garbage.
>
>       > done
>
>
>
>
>
>       > Then when I compile, the compilation fails as follows (though
>       without the patch the compilation succeeds):
>
>
>
>       > libtool: compile:  clang++ -DHAVE_CONFIG_H
>       -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
>       -I../../include -I../../lib -I../../src -I../../include
>       -I/usr/include -I/usr/include -I../../libltdl -I/usr/include
>       -I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
>       -Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
>       -march=native -std=c++11 -I/usr/local/include -MT mem/Pages.lo -MD
>       -MP -MF mem/.deps/Pages.Tpo -c mem/Pages.cc  -fPIC -DPIC -o
>       mem/.libs/Pages.o
>
>       > libtool: compile:  clang++ -DHAVE_CONFIG_H
>       -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
>       -I../../include -I../../lib -I../../src -I../../include
>       -I/usr/include -I/usr/include -I../../libltdl -I/usr/include
>       -I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
>       -Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
>       -march=native -std=c++11 -I/usr/local/include -MT mem/Pages.lo -MD
>       -MP -MF mem/.deps/Pages.Tpo -c mem/Pages.cc -o mem/Pages.o
>       >/dev/null 2>&1
>
>       > depbase=`echo mem/PageStack.lo | sed
>       's|[^/]*$|.deps/&|;s|\.lo$||'`; /bin/sh ../../libtool
>       --tag=CXX    --mode=compile clang++ -DHAVE_CONFIG_H
>       -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\"    -I../..
>       -I../../include  -I../../lib -I../../src  -I../../include
>       -I/usr/include  -I/usr/include  -I../../libltdl -I/usr/include
>       -I/usr/local/include/libxml2  -I/usr/local/include/libxml2
>       -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
>       -g -O2 -march=native -std=c++11 -I/usr/local/include -MT
>       mem/PageStack.lo -MD -MP -MF $depbase.Tpo -c -o mem/PageStack.lo
>       mem/PageStack.cc && mv -f $depbase.Tpo $depbase.Plo
>
>       > libtool: compile:  clang++ -DHAVE_CONFIG_H
>       -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
>       -I../../include -I../../lib -I../../src -I../../include
>       -I/usr/include -I/usr/include -I../../libltdl -I/usr/include
>       -I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
>       -Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
>       -march=native -std=c++11 -I/usr/local/include -MT mem/PageStack.lo
>       -MD -MP -MF mem/.deps/PageStack.Tpo -c mem/PageStack.cc  -fPIC
>       -DPIC -o mem/.libs/PageStack.o
>
>       > libtool: compile:  clang++ -DHAVE_CONFIG_H
>       -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
>       -I../../include -I../../lib -I../../src -I../../include
>       -I/usr/include -I/usr/include -I../../libltdl -I/usr/include
>       -I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
>       -Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
>       -march=native -std=c++11 -I/usr/local/include -MT mem/PageStack.lo
>       -MD -MP -MF mem/.deps/PageStack.Tpo -c mem/PageStack.cc -o
>       mem/PageStack.o >/dev/null 2>&1
>
>       > depbase=`echo mem/Segment.lo | sed
>       's|[^/]*$|.deps/&|;s|\.lo$||'`; /bin/sh ../../libtool
>       --tag=CXX    --mode=compile clang++ -DHAVE_CONFIG_H
>       -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\"    -I../..
>       -I../../include  -I../../lib -I../../src  -I../../include
>       -I/usr/include  -I/usr/include  -I../../libltdl -I/usr/include
>       -I/usr/local/include/libxml2  -I/usr/local/include/libxml2
>       -Werror -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
>       -g -O2 -march=native -std=c++11 -I/usr/local/include -MT
>       mem/Segment.lo -MD -MP -MF $depbase.Tpo -c -o mem/Segment.lo
>       mem/Segment.cc && mv -f $depbase.Tpo $depbase.Plo
>
>       > libtool: compile:  clang++ -DHAVE_CONFIG_H
>       -DDEFAULT_STATEDIR=\"/opt/squid-4/var/run/squid\" -I../..
>       -I../../include -I../../lib -I../../src -I../../include
>       -I/usr/include -I/usr/include -I../../libltdl -I/usr/include
>       -I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Werror
>       -Qunused-arguments -Wno-deprecated-register -D_REENTRANT -g -O2
>       -march=native -std=c++11 -I/usr/local/include -MT mem/Segment.lo
>       -MD -MP -MF mem/.deps/Segment.Tpo -c mem/Segment.cc  -fPIC -DPIC
>       -o mem/.libs/Segment.o
>
>       > mem/Segment.cc:96:22: error: too few arguments to function
>       call, single argument 'err' was not specified
>
>       >     if (!createFresh() && errno == EEXIST) {
>
>       >          ~~~~~~~~~~~ ^
>
>       > ../../src/ipc/mem/Segment.h:56:5: note: 'createFresh'
>       declared here
>
>       >     bool createFresh(int &err);
>
>       >     ^
>
>       > mem/Segment.cc:98:21: error: too few arguments to function
>       call, single argument 'err' was not specified
>
>       >         createFresh();
>
>       >         ~~~~~~~~~~~ ^
>
>       > ../../src/ipc/mem/Segment.h:56:5: note: 'createFresh'
>       declared here
>
>       >     bool createFresh(int &err);
>
>       >     ^
>
>       > mem/Segment.cc:108:9: error: use of undeclared identifier
>       'xerrno'
>
>       >         xerrno = errno;
>
>       >         ^
>
>       > mem/Segment.cc:110:66: error: use of undeclared identifier
>       'xerrno'
>
>       >         debugs(54, 5, "ftruncate " << theName <<
>       ": " << xstrerr(xerrno));
>
>
>       ^
>
>       > ../../src/Debug.h:107:21: note: expanded from macro 'debugs'
>
>       >             _dbo << CONTENT; \
>
>       >                     ^
>
>       > mem/Segment.cc:112:45: error: use of undeclared identifier
>       'xerrno'
>
>       >                theName.termedBuf(), xstrerr(xerrno));
>
>       >                                             ^
>
>       > 5 errors generated.
>
>       > *** Error code 1
>
>
>
>       > Stop.
>
>       > make[3]: stopped in
>       /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src/ipc
>
>       > *** Error code 1
>
>
>
>       > Stop.
>
>       > make[2]: stopped in
>       /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src
>
>       > *** Error code 1
>
>
>
>       > Stop.
>
>       > make[1]: stopped in
>       /usr/home/wash/ILI/Squid/4.x/squid-4.0.8/src
>
>       > *** Error code 1
>
>
>
>       > Stop.
>
>       > make: stopped in /usr/home/wash/ILI/Squid/4.x/squid-4.0.8
>
>
>
>
>
>       > Okay, I know I am being a bug here myself since I am focused
>       on 3.5 now more than 4.x but I also like giving the little
>       feedback I can from these FreeBSD servers I have:-)
>
>
>
>
>
>
>
>
>
>
>
>       > On 8 April 2016 at 17:19, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>
>       <mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>> wrote:
>
>
>
>
>
>       > Seems fixed.
>
>
>
>       > http://bugs.squid-cache.org/show_bug.cgi?id=4486#c2
>
>
>
>       > 08.04.16 18:05, Amos Jeffries ?????:
>
>       > > On 8/04/2016 10:28 p.m., Odhiambo Washington wrote:
>
>       > >> Hello Yuri,
>
>       > >>
>
>       > >> Thanks, but this patch is for squid-4.0.8, right??
>
>       > >>
>
>
>
>       > > Yes the patch in that bug report is specific to the
>       latest 4.0 snapshot,
>
>       > > which Yuri is running.
>
>
>
>       > > As Alex mentioned the errno usage in Squid was a bit
>       wrong. The latest
>
>       > > 4.0 have a patch to fix that, which is causing Yuri's
>       problem. Your 3.5
>
>       > > issue may or may not be related. But we wont know until
>       after Yuri
>
>       > > applies that patch and checks the results.
>
>
>
>       > > Amos
>
>
>
>       > > _______________________________________________
>
>       > > squid-users mailing list
>
>       > > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>       > > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       >     _______________________________________________
>
>       >     squid-users mailing list
>
>       >     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>       >     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>       > --
>
>       > Best regards,
>
>       > Odhiambo WASHINGTON,
>
>       > Nairobi,KE
>
>       > +254 7 3200 0004/+254 7 2274 3223
>
>       > "Oh, the cruft."
>
>
>
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXB+xbAAoJENNXIZxhPexGDP8IALxFdLWjHoL29fr9KntwP4ci
RExibg32ivhh7fMAQq7DiYtafUO2bNfV/ZstJgDu7qGyglX96fn2buwAE/a/7EU3
Bama9Beku9Mv+/+ByU/w0UmLTZe+8wk0L5GsBX3vwhGG1cyzE2dp2ntm+CpJfXGv
SQSTqG/rOCZc1M1aKgdqZhMoEd+J/4NQXz1oJrXbZZSDIMLhZg+hfE66ugOjt3gB
CEQnQ6O7dvodwam5QplaM6MaqQtgKJJ0m4O47dUhAXdp9tbgKO/Xn/E5biouKOiL
pVvEeXmM5LM8/tbO8cCrch/xMBxRnvD5OxoQoWEHFAbqjxpGuDXUheE8DxJaFP0=
=yp2M
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/21cb3577/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160408/21cb3577/attachment.key>

From squid3 at treenet.co.nz  Sat Apr  9 03:57:48 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 15:57:48 +1200
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <5707EC5B.3080701@gmail.com>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz> <5707BE06.3060809@gmail.com>
 <CAAdA2WPD4GS0ULA8tStG9J9mECcs=V2D06=Qaxz8Z5bGbVP_rQ@mail.gmail.com>
 <5707E9C7.8030303@gmail.com>
 <CAAdA2WO5=hmi-on1HWZjQV9tMjD2Cvramk5+RPpZfVrH7Y_w-Q@mail.gmail.com>
 <5707EC5B.3080701@gmail.com>
Message-ID: <57087DBC.8000103@treenet.co.nz>

On 9/04/2016 5:37 a.m., Yuri Voinov wrote:
> 
> Don't think so. I've gave latest 4.0.8 tarball from site. Applied patch
> - viola! - issue is gone.
> 
> 08.04.16 23:32, Odhiambo Washington ?????:
>> Hi Yuri,
> 
>> I applied the patch against 4.0.8, not 3.5.16. Check my e-mail well
> well :-)
> 
>> Could it be that you have a different code base from the tarballs
> available for everyone?

The patch fixes a regression which only exists in the daily snapshot
tarballs of 4.0.8 numbered r14625 thru r14632.

The patch itself was applied as r14633.

Amos


From squid3 at treenet.co.nz  Sat Apr  9 04:16:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 16:16:10 +1200
Subject: [squid-users] Attached file on OWA with Squid
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5837FD147F@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD147F@CPUMAIL2.cpu.qc.ca>
Message-ID: <5708820A.8090303@treenet.co.nz>

On 7/04/2016 5:24 a.m., Sebastien.Boulianne wrote:
> I configured my OWA to pass thru the Squid.
> Auth work perfectly.
> Browsing is working perfectly.
> All is working perfectly except when I try to attach files or documents to an email.
> 
> [cid:image002.png at 01D19007.A7E26D20]
> 
> 
> And It stops here. Nothing else happens.
> 
> I did some tests and I noticed that happens when I am connecting from external to OWA.
> If I connect to the VPN then I try to send an attached file with the OWA, it works.

If you mean that you are using Squid through the VPN, then that probably
means its not a Squid problem.


> 
> Here is my config for my OWA.
> 
> ### OWA
> cache_peer owa.domain.qc.ca parent 443 0 no-query originserver login=PASS ssl sslcert=/etc/pki/tls/certs/domain.qc.ca.cert.pem sslkey=/etc/pki/tls/private/domain.qc.ca.key.pem options=NO_SSLv2:NO_SSLv3:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE dhparams=/etc/pki/tls/private/dhparams.pem cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS name=owa
> acl owahttps url_regex ^https://owa\.domain\.qc\.ca
> cache_peer_access owa allow owahttps
> http_access allow www443 owahttps
> acl owahttp url_regex ^http://owa\.domain\.qc\.ca
> http_access deny owahttp
> deny_info 302:https://%H%R owahttp

You probably need to use 308 status here. 302 tells the client to try
again using the *GET* method. Sending of things is not a GET action.


> 
> Thanks you very much for your advice.
> 

What version of Squid (squid -v) ?

Amos



From squid3 at treenet.co.nz  Sat Apr  9 04:22:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 16:22:36 +1200
Subject: [squid-users] Unable to Proxy https traffic using squid
In-Reply-To: <1459992851533-4676982.post@n4.nabble.com>
References: <1459989082183-4676981.post@n4.nabble.com>
 <1459992851533-4676982.post@n4.nabble.com>
Message-ID: <5708838C.1090700@treenet.co.nz>

On 7/04/2016 1:34 p.m., crmanik wrote:
> Got this intersting log using -X option:
> 
<snip>
> 
> *2016/04/06 18:34:53.817 kid1| Error negotiating SSL on FD 12:
> error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake
> failure (1/-1/0)
> *

Your OpenSSL library may not be supporting the TLS or SSL version that
the other endpoint of the connection is trying to speak.
 ** There is no sign of specific SSL/TLS version in your squid.conf, so
this will be controlled by the library config file.


Squid-4 is needed for non-HTTPS traffic support on port 443 if that is
not HTTPS happening.

Amos



From squid3 at treenet.co.nz  Sat Apr  9 04:28:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 16:28:43 +1200
Subject: [squid-users] Debian jessie + squid 3.5.16 - Will not start.
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B126700102E@Ex5.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B126700102E@Ex5.lnpnews.com>
Message-ID: <570884FB.9000708@treenet.co.nz>

On 8/04/2016 3:58 a.m., Markey, Bruce wrote:
> I'm running debian Jessie.
> Squid 3.5.16 compiled from source with the following:
> 
<snip>

> 
> #allow/deny
> http_access allow internal
> http_access allow wireless

These...

> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports

... security rules do not do anything useful unless they are at the top
of the http_access rules.

> http_access deny all
> 
> #Bumping
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> 
> ssl_bump peek all
> ssl_bump splice all
> 
> sslproxy_capath /etc/ssl/certs
> 
> sslcrtd_program /usr/lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
> sslcrtd_children 5
> 
> 
> logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni %ssl::>cert_subject %>Hs %<st %Ss:%Sh
> 
> #access_log syslog:daemon.info mine
> access_log daemon:/var/log/squid3/access.log mine
> 
> #intercept
> http_port 3128 intercept
> https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem  generate-host-cer
> tificates=on dynamic_cert_mem_cache_size=4MB sslflags=NO_SESSION_REUSE
> 

> 
> -I did initialize the ssl_db

Did you do so with the "proxy" user account privileges?

There is an open bug about that helper that when you run it as root it
creates the directory with root privileges and then can't use it when
run by Squid low-privilege account.


> -I did create certs
> 
> I'm simply trying to start via :  sudo squid   It throws no errors nothing.  The pid lives for a sec then dies. This is the only log message I get.
> 
> Apr  7 11:51:19 LNP-Proxy (squid-1): The ssl_crtd helpers are crashing too rapidly, need help!
> 

Add the -d parameter to the helper command line for debug info about
what its doing.

Amos



From squid3 at treenet.co.nz  Sat Apr  9 04:29:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 16:29:59 +1200
Subject: [squid-users] query ?
In-Reply-To: <COL128-W59152075AF88007F1D249692900@phx.gbl>
References: <COL128-W59152075AF88007F1D249692900@phx.gbl>
Message-ID: <57088547.4090006@treenet.co.nz>

On 8/04/2016 11:24 a.m., Luis Abdon Diaz Parra wrote:
> Hello, good day to ask quisera
> there any way atra instead of a domain allows me to upload all your files
> I mean a group of users only allow you to access a specific domain dstdomain say "facebook.com" but does not load your images that refer to other URLs and domains
> 

Sorry I don't understand what you are trying to say there.

Could you try writing it in your native language and using a tool like
Google translate?

Amos


From squid3 at treenet.co.nz  Sat Apr  9 04:37:22 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 16:37:22 +1200
Subject: [squid-users] squid ftp-proxy
In-Reply-To: <6872D3617BB75149A218368CB61B73A3064AECB4900D@HE113669.emea1.cds.t-internal.com>
References: <6872D3617BB75149A218368CB61B73A3064AECB4900D@HE113669.emea1.cds.t-internal.com>
Message-ID: <57088702.8020303@treenet.co.nz>

On 5/04/2016 9:08 p.m., Axel.Eberhardt at t-systems.com wrote:
> Hello,
> 
> Maybe someone can give me a hint :-)
> 
> I try to enable the Native ftp proxying.
> The documentation I have found is:
> http://wiki.squid-cache.org/Features/FtpRelay
> 
> But there is no example for this. Also in the Mail Archives I was not able to find a hint.
> 
> I have configured the ftp proxy with parameter:
> 	ftp_port 21
> 

AFAIK that port is intended either for use as above when the Squid IP
address or hostname is given to the client FTP tool as the FTP server
IP/host.
 Or when intercepting port 21 traffic - with the 'intercept' option on
the port config line.

It is still a new / experimental and rarely used feature so YMMV.



> Version:
> xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
> squid -v
> Squid Cache: Version 3.5.15
> Service Name: squid
> configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--verbose' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake' '--enable-auth-ntlm=smb_lm,fake' '--enable-auth-digest=file,LDAP,eDirectory' '--enable-auth-negotiate=kerberos,wrapper' '--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,file_user
ip,SQL_session,unix_group,session,time_quota' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi' '--enable-ssl-crtd' '--enable-icmp' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' '--with-included-ltdl' '--disable-arch-native' '--enable-ecap' '--without-nettle' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic' 'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune
=generic -fPIC' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' --enable-ltdl-convenience
> xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
> 
> Now my problem.
> 
> I am able to connect via ftp client to the squid.
> Also the login will be correct:	
> 	example:  anonymous at ftp.informatik.rwth-aachen.de
> 	
> But after a command which use a data channel the connection fails:
> 	421 Service not available, remote server has closed connection
> 
> 
> I try a tcpdump but I cannot find a failure. 
> The only different between a native ftp session and a connection over the squid is a missing TCP ACK after the last ftp data package. 
> 

Um, missing ACK on which of the four connections involved?
  and from which of the three software involved?

Amos



From squid3 at treenet.co.nz  Sat Apr  9 04:38:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Apr 2016 16:38:08 +1200
Subject: [squid-users] Kerberos authentication only working with 1
 domain server
In-Reply-To: <0c2162e96fdaec9803d4b7ee9be80675@webmail.die-britsies.co.za>
References: <b4b1da51a97d924d6188ad24c7066d3c@webmail.die-britsies.co.za>
 <5375edc8c98de0866c193d007199d9df@webmail.die-britsies.co.za>
 <0c2162e96fdaec9803d4b7ee9be80675@webmail.die-britsies.co.za>
Message-ID: <57088730.7080508@treenet.co.nz>

On 6/04/2016 3:27 a.m., Drikus Brits wrote:
>  
> 
> i believe i might have fixed it.... 
> 
> will advise soonest. 
> 

Any update?

Amos



From spider at smoothnet.org  Sat Apr  9 05:56:04 2016
From: spider at smoothnet.org (The_Spider)
Date: Sat, 9 Apr 2016 00:56:04 -0500
Subject: [squid-users] Sending intermediate certificate with SSL-Bumped
 Certificate. (V3.5.1516-3-2-r14000)
In-Reply-To: <CADSSinP1dYy=DX_k6k8eTORBpMskLPqjUiaXXbsyZCsRR36pFQ@mail.gmail.com>
References: <e816f8036c6f8912fd6bb6eda5717889@smoothnet.org>
 <5706A00C.6060604@treenet.co.nz>
 <CADSSinP1dYy=DX_k6k8eTORBpMskLPqjUiaXXbsyZCsRR36pFQ@mail.gmail.com>
Message-ID: <CAJfE2f7zpLmJTLsHLeE-_u8j+OZQ14Fp61SY_p-kaK1T9m=KiQ@mail.gmail.com>

I can confirm that this configuration works as requested with the
configuration Jok Thuau had posted with the latest version 3.5.16.

Thank you so much for the response and the assistance.

On Thu, Apr 7, 2016 at 1:15 PM, Jok Thuau <jok at spikes.com> wrote:
> with 3.5.15, I have this config:
>
> ---8<---
> https_port 8443 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=64MB \
>     cert=/etc/squid/ssl/proxy.pem \
>     key=/etc/squid/ssl/proxy.key \
>     cafile=/etc/squid/ssl/proxy.pem
> --->8---
>
> proxy.pem is the concatenation of both the CA cert (intermediate) followed
> by the root cert (my offline CA). Best i can tell, all of it is sent back to
> the client (generated cert, intermediate and root CA).
>
> HTH
> Jok
>
>
>
>
> On Thu, Apr 7, 2016 at 10:59 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>
>> On 7/04/2016 5:25 a.m., Nicolaas Hyatt wrote:
>> > Amos,
>> > Thanks for your quick response and your time. I have not yet messed with
>> > 4.0. Is this something that may find its way into the 3.x stable branch
>> > at some point?
>> >
>>
>> Maybe. I am reliant on the guys doing OpenSSL code (aka. Christos) to
>> test the backporting though. So it will depend on whether he thinks its
>> important enough.
>>
>> I'm hopeful, but no guarantees.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From faisalusuf at yahoo.com  Sat Apr  9 09:06:48 2016
From: faisalusuf at yahoo.com (Muhammad Faisal)
Date: Sat, 09 Apr 2016 09:06:48 +0000
Subject: [squid-users] Squid 3.5 no traffic saving
Message-ID: <em8b07a9f0-b83e-4c40-9ff4-51106aea3c65@augere-1>

Hi,
I have deployed squid 3.5.16 as transparent proxy. I'm using squid store 
ID help for CDN content caching despite all efforts i dont see any 
traffic saving on upstream. From access logs most of the content is 
generating from CDNs streaming videos and downloads which always comes 
from destination despite using Store-ID helper.

If someone has deployed and have working configs please help me out.

--
Regards,
Faisal.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160409/40959427/attachment.htm>

From odhiambo at gmail.com  Sat Apr  9 10:46:42 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Sat, 9 Apr 2016 13:46:42 +0300
Subject: [squid-users] Error starting 3.5.16 on FreeBSD-8.4
In-Reply-To: <57087DBC.8000103@treenet.co.nz>
References: <CAAdA2WPYABsUB5DQ8ZLAgzpJLaseQx38V-uEH5qP=nokvbFMvw@mail.gmail.com>
 <57066BA0.80308@treenet.co.nz> <5706B1D3.8070603@gmail.com>
 <CAAdA2WOtu81_cYMydW11i3jaLkAaO7FTa+DyHHsLsvwPTfbX0g@mail.gmail.com>
 <57079E8E.4080800@treenet.co.nz> <5707BE06.3060809@gmail.com>
 <CAAdA2WPD4GS0ULA8tStG9J9mECcs=V2D06=Qaxz8Z5bGbVP_rQ@mail.gmail.com>
 <5707E9C7.8030303@gmail.com>
 <CAAdA2WO5=hmi-on1HWZjQV9tMjD2Cvramk5+RPpZfVrH7Y_w-Q@mail.gmail.com>
 <5707EC5B.3080701@gmail.com> <57087DBC.8000103@treenet.co.nz>
Message-ID: <CAAdA2WN-7ZrV0c0PdwmWMKx5gf-hya6WVvCrzEKZeuTwx7E3Hg@mail.gmail.com>

On 9 April 2016 at 06:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 9/04/2016 5:37 a.m., Yuri Voinov wrote:
> >
> > Don't think so. I've gave latest 4.0.8 tarball from site. Applied patch
> > - viola! - issue is gone.
> >
> > 08.04.16 23:32, Odhiambo Washington ?????:
> >> Hi Yuri,
> >
> >> I applied the patch against 4.0.8, not 3.5.16. Check my e-mail well
> > well :-)
> >
> >> Could it be that you have a different code base from the tarballs
> > available for everyone?
>
> The patch fixes a regression which only exists in the daily snapshot
> tarballs of 4.0.8 numbered r14625 thru r14632.
>
> The patch itself was applied as r14633.
>
> Amos
>

Noted and downloaded squid-4.0.8-20160408-r14633.tar.bz2

But I am still anxious to be able to run 3.5.16 on FreeBSD-8.4. Please. I
need guidnace and patience.

-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160409/5a0d833a/attachment.htm>

From yvoinov at gmail.com  Sat Apr  9 10:51:54 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 9 Apr 2016 16:51:54 +0600
Subject: [squid-users] squid-cache.org misconfigured
Message-ID: <5708DECA.2050704@gmail.com>

https://i1.someimage.com/Mv9LdJN.png


From eliezer at ngtech.co.il  Sun Apr 10 11:30:17 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 10 Apr 2016 14:30:17 +0300
Subject: [squid-users] squid-cache.org misconfigured
In-Reply-To: <5708DECA.2050704@gmail.com>
References: <5708DECA.2050704@gmail.com>
Message-ID: <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il>

Hey Yuri,

I filled a bug report about this couple times and the answer that I received and is the actual case is:
There is a sync process to the squid-cache mirror\cache web servers.
Since the synchronization "reset" the permissions of the files apache cannot access the web page files.
Due to this we see a forbidden access page when accessing once in a while, while the sync is done.

I do not know this specific system and I think that with the budget and tools of the project it's OK to have this kind of "down" time.

Eliezer

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Saturday, April 9, 2016 1:52 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid-cache.org misconfigured

https://i1.someimage.com/Mv9LdJN.png
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Sun Apr 10 11:31:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 10 Apr 2016 17:31:47 +0600
Subject: [squid-users] squid-cache.org misconfigured
In-Reply-To: <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il>
References: <5708DECA.2050704@gmail.com>
 <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il>
Message-ID: <570A39A3.1090404@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Yep, I understand. Simple this occurs some often and take long enough time.

10.04.16 17:30, Eliezer Croitoru ?????:
> Hey Yuri,
>
> I filled a bug report about this couple times and the answer that I
received and is the actual case is:
> There is a sync process to the squid-cache mirror\cache web servers.
> Since the synchronization "reset" the permissions of the files apache
cannot access the web page files.
> Due to this we see a forbidden access page when accessing once in a
while, while the sync is done.
>
> I do not know this specific system and I think that with the budget
and tools of the project it's OK to have this kind of "down" time.
>
> Eliezer
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of Yuri Voinov
> Sent: Saturday, April 9, 2016 1:52 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] squid-cache.org misconfigured
>
> https://i1.someimage.com/Mv9LdJN.png
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXCjmiAAoJENNXIZxhPexGBfUIAMCgV79BxBwbG4wh7jgc2XX/
87af/Hf2TvPMZgqAFGWG7B8eY2WDQSValsSfKtoUO4b52og6/8hStoKcUMhmwCkl
BBeY6bE90onwneHNAjoPb5Gx/ncVKukzSx9rv3ywlvl1oC/kX4OVSMlzV3Tcso1a
Np0Z1UGOycSX0VBNw7gGpdEJnHLnmm24SbmGzQdxFH0pXTpqa+Vbe9a6hELWYb+m
smfvdR05AQhrfPTK6+zErYDcAHB21N+V8npEw7i6QVp66VYYCHUmvJ6odZwB/i3c
UpN+SWVNM7FXUxZpsz9+3bOmKBLtmstSOYf+1i5RazQxBLaHACg5BLmRN3zdD34=
=ggQk
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/3c3b1e0c/attachment.key>

From eliezer at ngtech.co.il  Sun Apr 10 11:54:17 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 10 Apr 2016 14:54:17 +0300
Subject: [squid-users] squid-cache.org misconfigured
In-Reply-To: <570A39A3.1090404@gmail.com>
References: <5708DECA.2050704@gmail.com>
 <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il> <570A39A3.1090404@gmail.com>
Message-ID: <570A3EE9.8060109@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/18d4309c/attachment.htm>

From yvoinov at gmail.com  Sun Apr 10 11:56:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 10 Apr 2016 17:56:57 +0600
Subject: [squid-users] squid-cache.org misconfigured
In-Reply-To: <570A3EE9.8060109@ngtech.co.il>
References: <5708DECA.2050704@gmail.com>
 <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il> <570A39A3.1090404@gmail.com>
 <570A3EE9.8060109@ngtech.co.il>
Message-ID: <570A3F89.6050506@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


10.04.16 17:54, Eliezer Croitoru ?????:
> Hey Yuri,
>
> I will try to put up a "status" page for some of the project web
services in order to describe\explain the current status of the down time.
Good idea, Eliezer. Really good.
>
> How long is it "long enough" that you mean\know?
I've observed half-hour - hour. Usually less, but it depends...
>
> If for example the project page would be down for a whole day as a
rest day it would be acceptable if the work days and hours are during
the week.
> If the case is that an upgrade\update of systems is done only on
weekends without preparations during the week then it would be very
acceptable to not have down time during the weekend.
>
> I do not know RedHat or SUSE and others policy of
updates\upgrades\patches and other things but they do not reveal to me
their "secret" for high up-time.
> My assumption is that it requires more "time" more "work hours" more
"voluntaries" and many other things which are too much for a single
human to handle by himself alone.
>
> Eliezer
>
> * I believe that more support for any project is one of the big
secrets of the black magic of up-time.
>
> On 10/04/2016 14:31, Yuri Voinov wrote:
>> Yep, I understand. Simple this occurs some often and take long enough
time.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXCj+JAAoJENNXIZxhPexGbSEH/ij9aRP2apYz8KtRV+epVhqT
/QgiC6gmX313g7AofIXoALPW7kN34YZ36viD67wfSqzn/nKIPWI1JhbdKuKMaJGU
uT8z79XYq5lgPmhcyjM7oilKM5YBQ3T1N/lJtub7QDEQcUplHnpOFLcN+Sm9vJgX
h/qQ99MWFiJ76GGThjqix96UCnKe7FJWqZlmpbGy+IcAYkbmyq1+8RyGaVn4H/8m
7kH+/cEv+3Ob/iDyKQSaOl4jws//5KQyVdiS+5CvVr59JZdFXvOmK+Vu0Hq7bjwM
zsLDV0bl+18ByBRoSmzUYAIwxt6pXHJMNoKEzjYxKRjHgxGzfbrSv72uPfT+FPU=
=WlWN
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/8e05fb64/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/8e05fb64/attachment.key>

From yvoinov at gmail.com  Sun Apr 10 11:58:00 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 10 Apr 2016 17:58:00 +0600
Subject: [squid-users] squid-cache.org misconfigured
In-Reply-To: <570A3EE9.8060109@ngtech.co.il>
References: <5708DECA.2050704@gmail.com>
 <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il> <570A39A3.1090404@gmail.com>
 <570A3EE9.8060109@ngtech.co.il>
Message-ID: <570A3FC8.3010504@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I've go to project site some times per day - tracking nev
snapshots/fixed bugs. So, periodic downtime is annoying.

10.04.16 17:54, Eliezer Croitoru ?????:
> Hey Yuri,
>
> I will try to put up a "status" page for some of the project web
services in order to describe\explain the current status of the down time.
>
> How long is it "long enough" that you mean\know?
>
> If for example the project page would be down for a whole day as a
rest day it would be acceptable if the work days and hours are during
the week.
> If the case is that an upgrade\update of systems is done only on
weekends without preparations during the week then it would be very
acceptable to not have down time during the weekend.
>
> I do not know RedHat or SUSE and others policy of
updates\upgrades\patches and other things but they do not reveal to me
their "secret" for high up-time.
> My assumption is that it requires more "time" more "work hours" more
"voluntaries" and many other things which are too much for a single
human to handle by himself alone.
>
> Eliezer
>
> * I believe that more support for any project is one of the big
secrets of the black magic of up-time.
>
> On 10/04/2016 14:31, Yuri Voinov wrote:
>> Yep, I understand. Simple this occurs some often and take long enough
time.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXCj/IAAoJENNXIZxhPexGPw4H/AtftzcpYDd3pVo9E9Uzmde9
5LMuIm0NSH2k5btlnlwEDLDOM2jkYSMDx0loJjWFF6VYEzWMLf0e/KB+LKxdmynd
vWm4eRrL0W29PoaDX5t9lmUGBI/U4N/r1esxhs+DhPOIvvdJFH42kYheMMZB5myt
yRrMgWyQOc+9/yh905ekhuECgaQK3nyobMfWoIUoiJS6YOBPfisyat9x+6qreR72
h2gPkbv5YarBAEJwM9eUwsYZ3jsaqDizgFDkFEbvqOEjSk95/igDxirwbwlWagMX
bk4++TesUWQXaS9sH/34vJZZPrWE8AMQQS9GbU4myx9/c5ORVe+8bte11j+ANg4=
=u47b
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/a2fd766f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/a2fd766f/attachment.key>

From eliezer at ngtech.co.il  Sun Apr 10 12:04:06 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 10 Apr 2016 15:04:06 +0300
Subject: [squid-users] squid-cache.org misconfigured
In-Reply-To: <570A3F89.6050506@gmail.com>
References: <5708DECA.2050704@gmail.com>
 <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il> <570A39A3.1090404@gmail.com>
 <570A3EE9.8060109@ngtech.co.il> <570A3F89.6050506@gmail.com>
Message-ID: <570A4136.5070608@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/7d81e542/attachment.htm>

From drikus at geocastsp.co.za  Sun Apr 10 14:20:46 2016
From: drikus at geocastsp.co.za (Drikus Brits)
Date: Sun, 10 Apr 2016 16:20:46 +0200
Subject: [squid-users] Kerberos authentication only working with 1
 domain server
In-Reply-To: <57088730.7080508@treenet.co.nz>
References: <b4b1da51a97d924d6188ad24c7066d3c@webmail.die-britsies.co.za>
 <5375edc8c98de0866c193d007199d9df@webmail.die-britsies.co.za>
 <0c2162e96fdaec9803d4b7ee9be80675@webmail.die-britsies.co.za>
 <57088730.7080508@treenet.co.nz>
Message-ID: <ebe56d921a5e89717ae8c360c84b15e4@webmail.geocastsp.co.za>

 

Heya Amos, 

The problem was the keytab that didn't work correctly. I deleted the
objects from AD db and recreated keytab from linux side. The output now
says that using HTTP/mq-sqproxy.domain.co.za is "Authenticated to
kerberos", whilst the others now fail. I guess the HTTP is the only one
that should be working :) 

Hope this helps, 

On 2016-04-09 06:38, Amos Jeffries wrote: 

> On 6/04/2016 3:27 a.m., Drikus Brits wrote: 
> 
>> i believe i might have fixed it.... 
>> 
>> will advise soonest.
> 
> Any update?
> 
> Amos
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/35065334/attachment.htm>

From eliezer at ngtech.co.il  Sun Apr 10 18:20:49 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 10 Apr 2016 21:20:49 +0300
Subject: [squid-users] squid-cache.org misconfigured
In-Reply-To: <570A3FC8.3010504@gmail.com>
References: <5708DECA.2050704@gmail.com>
 <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il> <570A39A3.1090404@gmail.com>
 <570A3EE9.8060109@ngtech.co.il> <570A3FC8.3010504@gmail.com>
Message-ID: <78cdd01d19355$b52fffa0$1f8ffee0$@ngtech.co.il>

I do not know the reason but it seems that:

https://rsync.samba.org/ftp/rsync/src/rsync-3.1.0-NEWS

 

have couple things which can solve the issue using the:

 

    - Added the --usermap/--groupmap/--chown options for manipulating file

      ownership during the copy.

 

I will try to update the bugzilla report later to have this info with hope that it will be resolved.

 

Eliezer

 

From: Yuri Voinov [mailto:yvoinov at gmail.com] 
Sent: Sunday, April 10, 2016 2:58 PM
To: Eliezer Croitoru; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid-cache.org misconfigured

 


-----BEGIN PGP SIGNED MESSAGE----- 
Hash: SHA256 
 
I've go to project site some times per day - tracking nev snapshots/fixed bugs. So, periodic downtime is annoying.

10.04.16 17:54, Eliezer Croitoru ?????:
> Hey Yuri,



      >



      > I will try to put up a "status" page for some of the project

      web services in order to describe\explain the current status of

      the down time.



      >



      > How long is it "long enough" that you mean\know?



      >



      > If for example the project page would be down for a whole day

      as a rest day it would be acceptable if the work days and hours

      are during the week.



      > If the case is that an upgrade\update of systems is done only

      on weekends without preparations during the week then it would be

      very acceptable to not have down time during the weekend.



      >



      > I do not know RedHat or SUSE and others policy of

      updates\upgrades\patches and other things but they do not reveal

      to me their "secret" for high up-time.



      > My assumption is that it requires more "time" more "work

      hours" more "voluntaries" and many other things which are too much

      for a single human to handle by himself alone.



      >



      > Eliezer



      >



      > * I believe that more support for any project is one of the

      big secrets of the black magic of up-time.



      >



      > On 10/04/2016 14:31, Yuri Voinov wrote:



      >> Yep, I understand. Simple this occurs some often and take

      long enough time.



      >

-----BEGIN PGP SIGNATURE----- 
Version: GnuPG v2 
 
iQEcBAEBCAAGBQJXCj/IAAoJENNXIZxhPexGPw4H/AtftzcpYDd3pVo9E9Uzmde9 
5LMuIm0NSH2k5btlnlwEDLDOM2jkYSMDx0loJjWFF6VYEzWMLf0e/KB+LKxdmynd 
vWm4eRrL0W29PoaDX5t9lmUGBI/U4N/r1esxhs+DhPOIvvdJFH42kYheMMZB5myt 
yRrMgWyQOc+9/yh905ekhuECgaQK3nyobMfWoIUoiJS6YOBPfisyat9x+6qreR72 
h2gPkbv5YarBAEJwM9eUwsYZ3jsaqDizgFDkFEbvqOEjSk95/igDxirwbwlWagMX 
bk4++TesUWQXaS9sH/34vJZZPrWE8AMQQS9GbU4myx9/c5ORVe+8bte11j+ANg4= 
=u47b 
-----END PGP SIGNATURE----- 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160410/232a13ce/attachment.htm>

From johnzeng2013 at yahoo.com  Mon Apr 11 04:34:40 2016
From: johnzeng2013 at yahoo.com (johnzeng)
Date: Mon, 11 Apr 2016 12:34:40 +0800
Subject: [squid-users] a strange problem ( ORIGINAL_DST( can't be cache )
 HIER_DIRECT ( can be cache )
Message-ID: <570B2960.1050407@yahoo.com>


Hello Dear Sir :

i am trying to imporve hit ration for cache pic file now , but i found a
strange problem .

When i access the pic url via firefox browser , i found the content
can't be cache .( http_port 8080 tproxy at bridge mode )

and some helpful info is ORIGINAL_DST/171.107.188.173 at access.log

When i access the pic url via firefox wget , i found the content can be
cache .

wget -e "http_proxy=http://localhost:8081" -e robots=off
--user-agent="Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3)
Gecko/2008092416 Firefox/3.0.3" -r -p -nd -np -H --level=2 --tries=1
--limit-rate=500k
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
( http_port 8081 via bridge self-host )

and some helpful info is - HIER_DIRECT/222.84.188.200


if possible , please give me some advisement , thanks .






1460347543.192 155 192.168.0.66 TCP_MISS/200 35296 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- ORIGINAL_DST/171.107.188.173 image/jpeg
1460347544.209 85 192.168.0.66 TCP_MISS/200 35296 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- ORIGINAL_DST/171.107.188.173 image/jpeg
1460347546.448 72 192.168.0.66 TCP_MISS/200 35296 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- ORIGINAL_DST/171.107.188.173 image/jpeg
1460347547.922 402 192.168.0.66 TCP_MISS/200 35296 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- ORIGINAL_DST/171.107.188.173 image/jpeg
1460347572.097 162 127.0.0.1 TCP_MISS/200 35296 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- HIER_DIRECT/222.84.188.200 image/jpeg
1460347573.224 3 127.0.0.1 TCP_HIT/200 35295 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- HIER_NONE/- image/jpeg
1460347578.570 3 127.0.0.1 TCP_HIT/200 35295 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- HIER_NONE/- image/jpeg
1460347579.342 3 127.0.0.1 TCP_HIT/200 35295 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- HIER_NONE/- image/jpeg
1460347579.950 3 127.0.0.1 TCP_HIT/200 35295 GET
http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
- HIER_NONE/- image/jpeg



From rousskov at measurement-factory.com  Mon Apr 11 04:35:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 10 Apr 2016 22:35:52 -0600
Subject: [squid-users] squid ftp-proxy
In-Reply-To: <57088702.8020303@treenet.co.nz>
References: <6872D3617BB75149A218368CB61B73A3064AECB4900D@HE113669.emea1.cds.t-internal.com>
 <57088702.8020303@treenet.co.nz>
Message-ID: <570B29A8.4050606@measurement-factory.com>

On 04/08/2016 10:37 PM, Amos Jeffries wrote:
> On 5/04/2016 9:08 p.m., Axel.Eberhardt at t-systems.com wrote:
>> I try to enable the Native ftp proxying.
>> The documentation I have found is:
>> http://wiki.squid-cache.org/Features/FtpRelay
>>
>> But there is no example for this. Also in the Mail Archives I was not able to find a hint.
>>
>> I have configured the ftp proxy with parameter:
>> 	ftp_port 21


> AFAIK that port is intended either for use as above when the Squid IP
> address or hostname is given to the client FTP tool as the FTP server
> IP/host.

IIRC, the Squid address is given as the FTP proxy address. Some popular
FTP clients support that kind of proxying even though the original FTP
does not have such a concept. How this is done from FTP commands point
of view is mentioned further below.


> Or when intercepting port 21 traffic - with the 'intercept' option on
> the port config line.

Yes.


> It is still a new / experimental and rarely used feature so YMMV.

Agreed, provided that "rarely" means "by few Squid admins" here. AFAIK,
v3.5 implementation is used on some busy production servers. There are
many corner cases it does not handle well yet, but it is "working OK" in
those environments. YMMV.



>> Version:
>> xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
>> squid -v
>> Squid Cache: Version 3.5.15
>> Service Name: squid
>> configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--verbose' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake' '--enable-auth-ntlm=smb_lm,fake' '--enable-auth-digest=file,LDAP,eDirectory' '--enable-auth-negotiate=kerberos,wrapper' '--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,file_user

> ip,SQL_session,unix_group,session,time_quota' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi' '--enable-ssl-crtd' '--enable-icmp' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' '--with-included-ltdl' '--disable-arch-native' '--enable-ecap' '--without-nettle' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic' 'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtu
 n
e
> =generic -fPIC' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' --enable-ltdl-convenience
>> xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
>>
>> Now my problem.
>>
>> I am able to connect via ftp client to the squid.
>> Also the login will be correct:	
>> 	example:  anonymous at ftp.informatik.rwth-aachen.de


Correct from client, Squid, or FTP origin server point of view?


>> But after a command which use a data channel the connection fails:
>> 	421 Service not available, remote server has closed connection
>>
>>
>> I try a tcpdump but I cannot find a failure. 
>> The only different between a native ftp session and a connection over the squid is a missing TCP ACK after the last ftp data package. 

Does Squid know where to connect? If you are not intercepting, then
(IIRC) the FTP origin server address comes from your FTP login, which
should use two "@" characters. If you are not intimate with FTP in
general or FTP proxying specifically, then it might be easier to first
get this to work with a client that supports a concept of FTP proxy so
that you can compare apples to apples.

If nothing works, consider attached full TCP captures of user-Squid
_and_ Squid-origin connections.


HTH,

Alex.



From squid3 at treenet.co.nz  Mon Apr 11 06:28:40 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 11 Apr 2016 18:28:40 +1200
Subject: [squid-users] squid-cache.org misconfigured
In-Reply-To: <570A4136.5070608@ngtech.co.il>
References: <5708DECA.2050704@gmail.com>
 <6470601d1931c$5c5b4df0$1511e9d0$@ngtech.co.il> <570A39A3.1090404@gmail.com>
 <570A3EE9.8060109@ngtech.co.il> <570A3F89.6050506@gmail.com>
 <570A4136.5070608@ngtech.co.il>
Message-ID: <570B4418.6090605@treenet.co.nz>

On 11/04/2016 12:04 a.m., Eliezer Croitoru wrote:
> Even two hours is acceptable!
> If someone requires the squid sources I have it on my own web service at:
> http://ngtech.co.il/squid/src/

The rsync and FTP services of squid-cache.org are always available and
up to date.

The actual 403 from www service lasts for less than ~2min every few
hours at ~10 past the hour when sync happens on just 1 of the 5 servers.
If peoples systems are caching error pages for long times we can't do
much about it.

Amos



From ahmed.zaeem at netstream.ps  Mon Apr 11 06:40:03 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 11 Apr 2016 09:40:03 +0300
Subject: [squid-users] TCP RDP on squid Pfsense not woking
Message-ID: <E0943D77-75E8-46AC-B061-D89502E952D5@netstream.ps>

Hi dev ,

when i use socks5 client on my pc to connect to squid proxy on centos  , i can tunnel RDP traffic using squid .

recently when i changed to pfsense , 
I?m unable to use RDP  using proxy .

MY CACHE PEER proxy is 10.12.0.32 , if  i use it directly i can use RDP.

but RDP from pfsense always forbidden and i already allowed rdp port in the ports in pfsense squid config .!


i will paste my squid config below and the error i face when i try .

===============
[2.2.2-RELEASE][admin <mailto:admin at pfsense.mpwh.ps>@ <mailto:admin at pfsense.mpwh.ps>pfSense <mailto:admin at pfsense.mpwh.ps>]/root: squid -k parse
2016/04/11 09:25:53| Startup: Initializing Authentication Schemes ...
2016/04/11 09:25:53| Startup: Initialized Authentication Scheme 'basic'
2016/04/11 09:25:53| Startup: Initialized Authentication Scheme 'digest'
2016/04/11 09:25:53| Startup: Initialized Authentication Scheme 'negotiate'
2016/04/11 09:25:53| Startup: Initialized Authentication Scheme 'ntlm'
2016/04/11 09:25:53| Startup: Initialized Authentication.
2016/04/11 09:25:53| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
2016/04/11 09:25:53| Processing: http_port 10.12.140.254:8080
2016/04/11 09:25:53| Processing: http_port 127.0.0.1:8080
2016/04/11 09:25:53| Processing: icp_port 0
2016/04/11 09:25:53| Processing: dns_v4_first off
2016/04/11 09:25:53| Processing: pid_filename /var/run/squid/squid.pid
2016/04/11 09:25:53| Processing: cache_effective_user proxy
2016/04/11 09:25:53| Processing: cache_effective_group proxy
2016/04/11 09:25:53| Processing: error_default_language en
2016/04/11 09:25:53| Processing: icon_directory /usr/pbi/squid-amd64/local/etc/squid/icons
2016/04/11 09:25:53| Processing: visible_hostname mpwh
2016/04/11 09:25:53| Processing: cache_mgr admin at localhost
2016/04/11 09:25:53| Processing: access_log /var/squid/logs/access.log
2016/04/11 09:25:53| Processing: cache_log /var/squid/logs/cache.log
2016/04/11 09:25:53| Processing: cache_store_log none
2016/04/11 09:25:53| Processing: netdb_filename /var/squid/logs/netdb.state
2016/04/11 09:25:53| Processing: pinger_enable on
2016/04/11 09:25:53| Processing: pinger_program /usr/pbi/squid-amd64/local/libexec/squid/pinger
2016/04/11 09:25:53| Processing: logfile_rotate 0
2016/04/11 09:25:53| Processing: debug_options rotate=0
2016/04/11 09:25:53| Processing: shutdown_lifetime 3 seconds
2016/04/11 09:25:53| Processing: acl localnet src  10.12.140.0/24 127.0.0.0/8
2016/04/11 09:25:53| Processing: forwarded_for on
2016/04/11 09:25:53| Processing: uri_whitespace strip
2016/04/11 09:25:53| Processing: acl dynamic urlpath_regex cgi-bin \?
2016/04/11 09:25:53| Processing: cache deny dynamic
2016/04/11 09:25:53| Processing: cache_mem 64 MB
2016/04/11 09:25:53| Processing: maximum_object_size_in_memory 256 KB
2016/04/11 09:25:53| Processing: memory_replacement_policy heap GDSF
2016/04/11 09:25:53| Processing: cache_replacement_policy heap LFUDA
2016/04/11 09:25:53| Processing: minimum_object_size 0 KB
2016/04/11 09:25:53| Processing: maximum_object_size 4 MB
2016/04/11 09:25:53| Processing: cache_dir ufs /var/squid/cache 100 16 256
2016/04/11 09:25:53| Processing: offline_mode off
2016/04/11 09:25:53| Processing: cache_swap_low 90
2016/04/11 09:25:53| Processing: cache_swap_high 95
2016/04/11 09:25:53| Processing: cache allow all
2016/04/11 09:25:53| Processing: refresh_pattern ^ftp:    1440  20%  10080
2016/04/11 09:25:53| Processing: refresh_pattern ^gopher:  1440  0%  1440
2016/04/11 09:25:53| Processing: refresh_pattern -i (/cgi-bin/|\?) 0  0%  0
2016/04/11 09:25:53| Processing: refresh_pattern .    0  20%  4320
2016/04/11 09:25:53| Processing: acl allsrc src all
2016/04/11 09:25:53| Processing: acl safeports port 3389 21 70 80 210 280 443 488 563 591 631 777 901  8080 3129 1025-65535
2016/04/11 09:25:53| Processing: acl sslports port 443 563
2016/04/11 09:25:53| Processing: acl safeports port 3389 12345
2016/04/11 09:25:53| Processing: acl purge method PURGE
2016/04/11 09:25:53| Processing: acl connect method CONNECT
2016/04/11 09:25:53| Processing: acl HTTP proto HTTP
2016/04/11 09:25:53| Processing: acl HTTPS proto HTTPS
2016/04/11 09:25:53| Processing: http_access allow manager localhost
2016/04/11 09:25:53| Processing: http_access deny manager
2016/04/11 09:25:53| Processing: http_access allow purge localhost
2016/04/11 09:25:53| Processing: http_access deny purge
2016/04/11 09:25:53| Processing: http_access deny !safeports
2016/04/11 09:25:53| Processing: http_access deny CONNECT !sslports
2016/04/11 09:25:53| Processing: request_body_max_size 0 KB
2016/04/11 09:25:53| Processing: delay_pools 1
2016/04/11 09:25:53| Processing: delay_class 1 2
2016/04/11 09:25:53| Processing: delay_parameters 1 -1/-1 -1/-1
2016/04/11 09:25:53| Processing: delay_initial_bucket_level 100
2016/04/11 09:25:53| Processing: delay_access 1 allow allsrc
2016/04/11 09:25:53| Processing: acl rdp dat XXXX.XX.70.0/24
2016/04/11 09:25:53| Processing: http_access allow rdp
2016/04/11 09:25:53| Processing: dns_nameservers 8.8.8.8 10.12.0.33
2016/04/11 09:25:53| Processing: never_direct allow all
2016/04/11 09:25:53| Processing: cache_peer  10.12.0.32 parent  80 0 no-query no-digest default
2016/04/11 09:25:53| Processing: http_access allow localnet
2016/04/11 09:25:53| Processing: http_access deny allsrc
2016/04/11 09:25:53| Initializing https proxy context
[2.2.2-RELEASE][admin <mailto:admin at pfsense.mpwh.ps>@ <mailto:admin at pfsense.mpwh.ps>pfSense. <mailto:admin at pfsense.mpwh.ps>/root: 






and here is the error when i try to connect RDP :
1460356516.600      0 10.12.140.114 TCP_DENIED/403 3450 CONNECT XX/XX.XX.26:3389 - HIER_NONE/- text/html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160411/41392b03/attachment.htm>

From squid3 at treenet.co.nz  Mon Apr 11 06:40:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 11 Apr 2016 18:40:28 +1200
Subject: [squid-users] a strange problem ( ORIGINAL_DST( can't be cache
 ) HIER_DIRECT ( can be cache )
In-Reply-To: <570B2960.1050407@yahoo.com>
References: <570B2960.1050407@yahoo.com>
Message-ID: <570B46DC.3090106@treenet.co.nz>

On 11/04/2016 4:34 p.m., johnzeng wrote:
> 
> Hello Dear Sir :
> 
> i am trying to imporve hit ration for cache pic file now , but i found a
> strange problem .
> 
> When i access the pic url via firefox browser , i found the content
> can't be cache .( http_port 8080 tproxy at bridge mode )
> 
> and some helpful info is ORIGINAL_DST/171.107.188.173 at access.log
> 

ORIGINAL_DST means that interception is being used and that NAT system
was used to find the server.

> When i access the pic url via firefox wget , i found the content can be
> cache .
> 
> wget -e "http_proxy=http://localhost:8081" -e robots=off
> --user-agent="Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3)
> Gecko/2008092416 Firefox/3.0.3" -r -p -nd -np -H --level=2 --tries=1
> --limit-rate=500k
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> ( http_port 8081 via bridge self-host )
> 
> and some helpful info is - HIER_DIRECT/222.84.188.200
> 

DIRECT means regular forward-proxy is happening, and that DNS system was
used to find the server.

> 
> if possible , please give me some advisement , thanks .
> 

When NAT intercept or TPROXY are involved Squid has additional security
checks that have to be applied. Host header verification / forgery
detection is the most noticed one.

If Squid determines that the client is in fact *not* going to the server
mentioned in the Host header it will let the transaction happen to that
ORIGINAL_DST but cannot cache it.

Some things you can do to minimize the false verify results are detailed
in <http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>. Due to
how some popular CDN operate we cannot completely eliminate the false
results, best we can do is let it through with disabled caching.

Amos



From johnzeng2013 at yahoo.com  Mon Apr 11 07:12:31 2016
From: johnzeng2013 at yahoo.com (johnzeng)
Date: Mon, 11 Apr 2016 15:12:31 +0800
Subject: [squid-users] a strange problem ( ORIGINAL_DST( can't be cache
 ) HIER_DIRECT ( can be cache )
In-Reply-To: <570B2960.1050407@yahoo.com>
References: <570B2960.1050407@yahoo.com>
Message-ID: <570B4E5F.5080808@yahoo.com>



Hi Amos :

Thanks you really , i get your Very timely help and advisement alway .


Have a good everyday with you .


Johnzeng
> Hello Dear Sir :
>
> i am trying to imporve hit ration for cache pic file now , but i found a
> strange problem .
>
> When i access the pic url via firefox browser , i found the content
> can't be cache .( http_port 8080 tproxy at bridge mode )
>
> and some helpful info is ORIGINAL_DST/171.107.188.173 at access.log
>
> When i access the pic url via firefox wget , i found the content can be
> cache .
>
> wget -e "http_proxy=http://localhost:8081" -e robots=off
> --user-agent="Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3)
> Gecko/2008092416 Firefox/3.0.3" -r -p -nd -np -H --level=2 --tries=1
> --limit-rate=500k
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> ( http_port 8081 via bridge self-host )
>
> and some helpful info is - HIER_DIRECT/222.84.188.200
>
>
> if possible , please give me some advisement , thanks .
>
>
>
>
>
>
> 1460347543.192 155 192.168.0.66 TCP_MISS/200 35296 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - ORIGINAL_DST/171.107.188.173 image/jpeg
> 1460347544.209 85 192.168.0.66 TCP_MISS/200 35296 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - ORIGINAL_DST/171.107.188.173 image/jpeg
> 1460347546.448 72 192.168.0.66 TCP_MISS/200 35296 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - ORIGINAL_DST/171.107.188.173 image/jpeg
> 1460347547.922 402 192.168.0.66 TCP_MISS/200 35296 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - ORIGINAL_DST/171.107.188.173 image/jpeg
> 1460347572.097 162 127.0.0.1 TCP_MISS/200 35296 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - HIER_DIRECT/222.84.188.200 image/jpeg
> 1460347573.224 3 127.0.0.1 TCP_HIT/200 35295 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - HIER_NONE/- image/jpeg
> 1460347578.570 3 127.0.0.1 TCP_HIT/200 35295 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - HIER_NONE/- image/jpeg
> 1460347579.342 3 127.0.0.1 TCP_HIT/200 35295 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - HIER_NONE/- image/jpeg
> 1460347579.950 3 127.0.0.1 TCP_HIT/200 35295 GET
> http://d.ifengimg.com/w670_h326/y2.ifengimg.com/a/2016_16/93353429f03c891_size198_w670_h326.jpg
> - HIER_NONE/- image/jpeg
>



From eliezer at ngtech.co.il  Mon Apr 11 11:09:38 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 11 Apr 2016 14:09:38 +0300
Subject: [squid-users] TCP RDP on squid Pfsense not woking
In-Reply-To: <E0943D77-75E8-46AC-B061-D89502E952D5@netstream.ps>
References: <E0943D77-75E8-46AC-B061-D89502E952D5@netstream.ps>
Message-ID: <570B85F2.7000509@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160411/f7b13343/attachment.htm>

From Axel.Eberhardt at t-systems.com  Mon Apr 11 11:16:41 2016
From: Axel.Eberhardt at t-systems.com (Axel.Eberhardt at t-systems.com)
Date: Mon, 11 Apr 2016 13:16:41 +0200
Subject: [squid-users] squid ftp-proxy
In-Reply-To: <57088702.8020303@treenet.co.nz>
References: <6872D3617BB75149A218368CB61B73A3064AECB4900D@HE113669.emea1.cds.t-internal.com>
 <57088702.8020303@treenet.co.nz>
Message-ID: <6872D3617BB75149A218368CB61B73A3064AECC07C9B@HE113669.emea1.cds.t-internal.com>

Hi Amos,

>Von: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Im Auftrag von Amos Jeffries

>>On 5/04/2016 9:08 p.m., Axel.Eberhardt at t-systems.com wrote:
>> Hello,
>> 
>> Maybe someone can give me a hint :-)
>> 
>> I try to enable the Native ftp proxying.
>> The documentation I have found is:
>> http://wiki.squid-cache.org/Features/FtpRelay
>> 
>> But there is no example for this. Also in the Mail Archives I was not able to find a hint.
>> 
>> I have configured the ftp proxy with parameter:
>> 	ftp_port 21
>> 

>AFAIK that port is intended either for use as above when the Squid IP address or hostname is given to the client FTP tool as the FTP server >IP/host.

Yes, that is correct. But I'am not sure if this is the only necessary option. Maybe I have to configure more options. 

> Or when intercepting port 21 traffic - with the 'intercept' option on the port config line.

>It is still a new / experimental and rarely used feature so YMMV.


.........................

>> Now my problem.
>> 
>> I am able to connect via ftp client to the squid.
>> Also the login will be correct:	
>> 	example:  anonymous at ftp.informatik.rwth-aachen.de
>> 	
>> But after a command which use a data channel the connection fails:
>> 	421 Service not available, remote server has closed connection
>> 
>> 
>> I try a tcpdump but I cannot find a failure. 
>> The only different between a native ftp session and a connection over the squid is a missing TCP ACK after the last ftp data package. 
>>

>Um, missing ACK on which of the four connections involved?
>  and from which of the three software involved?

I have traced the network interface at the squid server. 
The ftp connection was established from localhost. So I cannot see the traffic between squid and ftp client.
The missing ACK I have seen comes from the ftp server. Maybe the ftp server answer is different between 'ftp over http' and ftp.
But this issue is similar to different ftp servers.

>Amos

Axel
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Mon Apr 11 14:37:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 12 Apr 2016 02:37:04 +1200
Subject: [squid-users] Squid 3.5 no traffic saving
In-Reply-To: <em8b07a9f0-b83e-4c40-9ff4-51106aea3c65@augere-1>
References: <em8b07a9f0-b83e-4c40-9ff4-51106aea3c65@augere-1>
Message-ID: <570BB690.50703@treenet.co.nz>

On 9/04/2016 9:06 p.m., Muhammad Faisal wrote:
> Hi,
> I have deployed squid 3.5.16 as transparent proxy. I'm using squid store
> ID help for CDN content caching despite all efforts i dont see any
> traffic saving on upstream. From access logs most of the content is
> generating from CDNs streaming videos and downloads which always comes
> from destination despite using Store-ID helper.
> 
> If someone has deployed and have working configs please help me out.
> 

see my answre to johnzeng yesterday about ORIGINAL_DST and caching.


There is also a regression bug (#4481) in 3.5.16 which prevents Vary
caching properly. The patch for that just went into 3.5 so will be fixed
in tomorrows snapshot (r14022 or later).

Amos



From amadaan at ncsu.edu  Mon Apr 11 19:11:25 2016
From: amadaan at ncsu.edu (amadaan)
Date: Mon, 11 Apr 2016 12:11:25 -0700 (PDT)
Subject: [squid-users] FATAL: Ipc::Mem::Segment::create failed to
 shm_open(/squid-cf__metadata.shm): (13) Permission denied
In-Reply-To: <1460388196384-4677044.post@n4.nabble.com>
References: <1460388196384-4677044.post@n4.nabble.com>
Message-ID: <1460401885099-4677045.post@n4.nabble.com>

So I actually dig deeper into this issue and found stack traced error of 
squid: ERROR: Could not read pid file
	/var/run/squid.pid: (13) Permission denied

Tried one of the responses from one of the forums. Saying the issue is with
SELinux being enabled.
I disabled that and it worked fine after that. 

But that means I am removing security from my system. Now this awesome blog
tells me how to add policy rules to allow your new software to run when
SELinux is enabled.

http://sharadchhetri.com/2014/03/07/selinux-squid-service-failed-startrestart/

Quite helpful but not sure if that is real solution. Can any changes be done
on squid end to ignore above steps . Any suggestions on this will be of
help.

Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/FATAL-Ipc-Mem-Segment-create-failed-to-shm-open-squid-cf-metadata-shm-13-Permission-denied-tp4677044p4677045.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Mon Apr 11 20:39:34 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 11 Apr 2016 23:39:34 +0300
Subject: [squid-users] FATAL: Ipc::Mem::Segment::create failed to
 shm_open(/squid-cf__metadata.shm): (13) Permission denied
In-Reply-To: <1460401885099-4677045.post@n4.nabble.com>
References: <1460388196384-4677044.post@n4.nabble.com>
 <1460401885099-4677045.post@n4.nabble.com>
Message-ID: <570C0B86.5030900@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160411/6e36d66a/attachment.htm>

From ahmed.zaeem at netstream.ps  Mon Apr 11 20:54:33 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 11 Apr 2016 23:54:33 +0300
Subject: [squid-users] TCP RDP on squid Pfsense not woking
In-Reply-To: <E0943D77-75E8-46AC-B061-D89502E952D5@netstream.ps>
References: <E0943D77-75E8-46AC-B061-D89502E952D5@netstream.ps>
Message-ID: <FE676333-4231-4E1F-A0E9-ADCDD4506919@netstream.ps>





> On Apr 11, 2016, at 9:40 AM, --Ahmad-- <> wrote:
> 
> Hi dev ,
> 
> when i use socks5 client on my pc to connect to squid proxy on centos  , i can tunnel RDP traffic using squid .
> 
> recently when i changed to pfsense , 
> I?m unable to use RDP  using proxy .
> 
> MY CACHE PEER proxy is 10.12.0.32 , if  i use it directly i can use RDP.
> 
> but RDP from pfsense always forbidden and i already allowed rdp port in the ports in pfsense squid config .!
> 
> 
> i will paste my squid config below and the error i face when i try .
> 
> ===============
> [2.2.2-RELEASE][admin <mailto:admin at pfsense.mpwh.ps>@ <mailto:admin at pfsense.mpwh.ps>pfSense <mailto:admin at pfsense.mpwh.ps>]/root: squid -k parse
> 2016/04/11 09:25:53| Startup: Initializing Authentication Schemes ...
> 2016/04/11 09:25:53| Startup: Initialized Authentication Scheme 'basic'
> 2016/04/11 09:25:53| Startup: Initialized Authentication Scheme 'digest'
> 2016/04/11 09:25:53| Startup: Initialized Authentication Scheme 'negotiate'
> 2016/04/11 09:25:53| Startup: Initialized Authentication Scheme 'ntlm'
> 2016/04/11 09:25:53| Startup: Initialized Authentication.
> 2016/04/11 09:25:53| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
> 2016/04/11 09:25:53| Processing: http_port 10.12.140.254:8080
> 2016/04/11 09:25:53| Processing: http_port 127.0.0.1:8080
> 2016/04/11 09:25:53| Processing: icp_port 0
> 2016/04/11 09:25:53| Processing: dns_v4_first off
> 2016/04/11 09:25:53| Processing: pid_filename /var/run/squid/squid.pid
> 2016/04/11 09:25:53| Processing: cache_effective_user proxy
> 2016/04/11 09:25:53| Processing: cache_effective_group proxy
> 2016/04/11 09:25:53| Processing: error_default_language en
> 2016/04/11 09:25:53| Processing: icon_directory /usr/pbi/squid-amd64/local/etc/squid/icons
> 2016/04/11 09:25:53| Processing: visible_hostname mpwh
> 2016/04/11 09:25:53| Processing: cache_mgr admin at localhost
> 2016/04/11 09:25:53| Processing: access_log /var/squid/logs/access.log
> 2016/04/11 09:25:53| Processing: cache_log /var/squid/logs/cache.log
> 2016/04/11 09:25:53| Processing: cache_store_log none
> 2016/04/11 09:25:53| Processing: netdb_filename /var/squid/logs/netdb.state
> 2016/04/11 09:25:53| Processing: pinger_enable on
> 2016/04/11 09:25:53| Processing: pinger_program /usr/pbi/squid-amd64/local/libexec/squid/pinger
> 2016/04/11 09:25:53| Processing: logfile_rotate 0
> 2016/04/11 09:25:53| Processing: debug_options rotate=0
> 2016/04/11 09:25:53| Processing: shutdown_lifetime 3 seconds
> 2016/04/11 09:25:53| Processing: acl localnet src  10.12.140.0/24 127.0.0.0/8
> 2016/04/11 09:25:53| Processing: forwarded_for on
> 2016/04/11 09:25:53| Processing: uri_whitespace strip
> 2016/04/11 09:25:53| Processing: acl dynamic urlpath_regex cgi-bin \?
> 2016/04/11 09:25:53| Processing: cache deny dynamic
> 2016/04/11 09:25:53| Processing: cache_mem 64 MB
> 2016/04/11 09:25:53| Processing: maximum_object_size_in_memory 256 KB
> 2016/04/11 09:25:53| Processing: memory_replacement_policy heap GDSF
> 2016/04/11 09:25:53| Processing: cache_replacement_policy heap LFUDA
> 2016/04/11 09:25:53| Processing: minimum_object_size 0 KB
> 2016/04/11 09:25:53| Processing: maximum_object_size 4 MB
> 2016/04/11 09:25:53| Processing: cache_dir ufs /var/squid/cache 100 16 256
> 2016/04/11 09:25:53| Processing: offline_mode off
> 2016/04/11 09:25:53| Processing: cache_swap_low 90
> 2016/04/11 09:25:53| Processing: cache_swap_high 95
> 2016/04/11 09:25:53| Processing: cache allow all
> 2016/04/11 09:25:53| Processing: refresh_pattern ^ftp:    1440  20%  10080
> 2016/04/11 09:25:53| Processing: refresh_pattern ^gopher:  1440  0%  1440
> 2016/04/11 09:25:53| Processing: refresh_pattern -i (/cgi-bin/|\?) 0  0%  0
> 2016/04/11 09:25:53| Processing: refresh_pattern .    0  20%  4320
> 2016/04/11 09:25:53| Processing: acl allsrc src all
> 2016/04/11 09:25:53| Processing: acl safeports port 3389 21 70 80 210 280 443 488 563 591 631 777 901  8080 3129 1025-65535
> 2016/04/11 09:25:53| Processing: acl sslports port 443 563
> 2016/04/11 09:25:53| Processing: acl safeports port 3389 12345
> 2016/04/11 09:25:53| Processing: acl purge method PURGE
> 2016/04/11 09:25:53| Processing: acl connect method CONNECT
> 2016/04/11 09:25:53| Processing: acl HTTP proto HTTP
> 2016/04/11 09:25:53| Processing: acl HTTPS proto HTTPS
> 2016/04/11 09:25:53| Processing: http_access allow manager localhost
> 2016/04/11 09:25:53| Processing: http_access deny manager
> 2016/04/11 09:25:53| Processing: http_access allow purge localhost
> 2016/04/11 09:25:53| Processing: http_access deny purge
> 2016/04/11 09:25:53| Processing: http_access deny !safeports
> 2016/04/11 09:25:53| Processing: http_access deny CONNECT !sslports
> 2016/04/11 09:25:53| Processing: request_body_max_size 0 KB
> 2016/04/11 09:25:53| Processing: delay_pools 1
> 2016/04/11 09:25:53| Processing: delay_class 1 2
> 2016/04/11 09:25:53| Processing: delay_parameters 1 -1/-1 -1/-1
> 2016/04/11 09:25:53| Processing: delay_initial_bucket_level 100
> 2016/04/11 09:25:53| Processing: delay_access 1 allow allsrc
> 2016/04/11 09:25:53| Processing: acl rdp dat XXXX.XX.70.0/24
> 2016/04/11 09:25:53| Processing: http_access allow rdp
> 2016/04/11 09:25:53| Processing: dns_nameservers 8.8.8.8 10.12.0.33
> 2016/04/11 09:25:53| Processing: never_direct allow all
> 2016/04/11 09:25:53| Processing: cache_peer  10.12.0.32 parent  80 0 no-query no-digest default
> 2016/04/11 09:25:53| Processing: http_access allow localnet
> 2016/04/11 09:25:53| Processing: http_access deny allsrc
> 2016/04/11 09:25:53| Initializing https proxy context
> [2.2.2-RELEASE][admin <mailto:admin at pfsense.mpwh.ps>@ <mailto:admin at pfsense.mpwh.ps>pfSense. <mailto:admin at pfsense.mpwh.ps>/root: 
> 
> 
> 
> 
> 
> 
> and here is the error when i try to connect RDP :
> 1460356516.600      0 10.12.140.114 TCP_DENIED/403 3450 CONNECT XX/XX.XX.26:3389 - HIER_NONE/- text/html

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160411/aa5191c9/attachment.htm>

From eliezer at ngtech.co.il  Mon Apr 11 20:57:42 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 11 Apr 2016 23:57:42 +0300
Subject: [squid-users] TCP RDP on squid Pfsense not woking
In-Reply-To: <FE676333-4231-4E1F-A0E9-ADCDD4506919@netstream.ps>
References: <E0943D77-75E8-46AC-B061-D89502E952D5@netstream.ps>
 <FE676333-4231-4E1F-A0E9-ADCDD4506919@netstream.ps>
Message-ID: <570C0FC6.80100@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160411/4814db66/attachment.htm>

From dan at getbusi.com  Tue Apr 12 05:52:59 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Tue, 12 Apr 2016 15:52:59 +1000
Subject: [squid-users] Any problems with %ssl::>sni in 3.5.16?
Message-ID: <86E0F05F-C170-4762-A8F6-EA22650F7EED@getbusi.com>

We have an External ACL Type with %ssl::>sni and %URI

We get access log lines that record the %ssl::>sni just fine, but the corresponding line sent to our external ACL is missing it.

For example, from the same request;

Log: 12/Apr/2016-15:42:47    608 10.0.1.60 TAG_NONE 200 0 CONNECT 23.111.9.31:443 code.jquery.com - peek - ORIGINAL_DST/23.111.9.31 - -

Line sent to Ext. ACL: 23.111.9.31:443 -

?

Not sure if many people on this list use external ACLs as much, but anyone encountered this?

From johnzeng2013 at yahoo.com  Tue Apr 12 07:04:40 2016
From: johnzeng2013 at yahoo.com (johnzeng)
Date: Tue, 12 Apr 2016 15:04:40 +0800
Subject: [squid-users] i have two question about https_port tproxy
Message-ID: <570C9E08.4010107@yahoo.com>


Hello Dear Sir :

i will optimize https traffic recently at bridge tproxy environment , i
know squid will https_port tproxy ,

question one : Whether the feature ( https_port) will be stable at squid
3.5 ?

question two : https_proxy will optimize special website url via acl or
https_proxy can optimize full https website .

Sorry , i have't more experience about https_port .

Which direction will be suitable for small isp environtment

if possible , please give me some advisement .


Thanks


From squid3 at treenet.co.nz  Tue Apr 12 07:40:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 12 Apr 2016 19:40:55 +1200
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <57065F3C.3020201@treenet.co.nz>
References: <5702282E.6060408@gmail.com>
 <267414581.73594822.1459770424481.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <83622676.74127435.1459781090004.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <57030859.5060609@treenet.co.nz> <5704ACAC.3090203@coronamundi.de>
 <1997585430.79061926.1459928847941.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <5704FDA4.60606@treenet.co.nz> <1459948836715-4676962.post@n4.nabble.com>
 <570517C3.2080805@treenet.co.nz>
 <770168678.80144344.1459951815746.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1459950173942-4676968.post@n4.nabble.com> <57065F3C.3020201@treenet.co.nz>
Message-ID: <570CA687.7020907@treenet.co.nz>

On 8/04/2016 1:23 a.m., Amos Jeffries wrote:
> On 7/04/2016 1:42 a.m., joe wrote:
>> yes
>>
>> FredB wrote
>>>>
>>>> Attached is a patch which I think will fix 3.5.16 (should apply fine
>>>> on
>>>> 4.0.8 too) without needing the cache reset. Anyone able to test it
>>>> please?
>>>>
>>>
>>> Reset the cache still needed, at least in my case 
>>>
> 
> Hmm. I'm not sure why that reset would be needed. I just ran a series of
> tests with detailed debugging of the vary details being loaded from disk
> and it seems the last patch was correctly erasing the \0 terminators
> (and they were wrongly being stored).
> 
> So at least this new regression is fixed. Anything else seen in Vary is
> a separate bug.
> 
> FYI Ralf reported bug 4481 to track it. I have updated the bug with an
> explanation of the issue and applied that last patch to Squid-4 now. It
> should be in 3.5 in a day or two.
> 
And for those following this thread instead of bugzilla that 3.5 patch
is now up at
<http://www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14022.patch>

Amos



From squid3 at treenet.co.nz  Tue Apr 12 08:28:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 12 Apr 2016 20:28:05 +1200
Subject: [squid-users] i have two question about https_port tproxy
In-Reply-To: <570C9E08.4010107@yahoo.com>
References: <570C9E08.4010107@yahoo.com>
Message-ID: <570CB195.6030909@treenet.co.nz>

On 12/04/2016 7:04 p.m., johnzeng wrote:
> 
> Hello Dear Sir :
> 
> i will optimize https traffic recently at bridge tproxy environment , i
> know squid will https_port tproxy ,
> 
> question one : Whether the feature ( https_port) will be stable at squid
> 3.5 ?

https_port is not a feature. It is a config directive used by many
features. So feature stability depends on how you will be using it.

If you mean MITM - then no. The SSL-Bump feature which does that MITM is
still being stabilized.

The TPROXY feature usually can be considered stable, but depends on the
specific environment you use it in. Regardless of which Squid port type
you use it on.

> 
> question two : https_proxy will optimize special website url via acl or
> https_proxy can optimize full https website .

That is a statement. If I assume you mean *can* it optimize? the port
directive itself does not do any optimizing. It is simply telling Squid
what type of traffic will be arriving there. The features using it or
the features applied to the traffic after it has arrived through a port
(any port) may or may not optimize.


Squid (as a whole) does optimization. But "optimize" may not mean what
you think it does. What happens to traffic arriving at a partiular port
changes depending on what a) could be done with that traffic, and b)
been configured to be done.

Optimize could mean anything from simply re-arranging message headers
into a format that is faster to process at the server end. Through to
dropping requests as they arrive. Or many other things in between.

Processing the traffic also has a cost. So optimizing for one thing may
make other things get worse.


> 
> Sorry , i have't more experience about https_port .
> 
> Which direction will be suitable for small isp environtment
> 
> if possible , please give me some advisement .


An ISP usually does not have the ability (both technical and legal
abilities are required) to install self-signed custom CA certificates
onto all the client devices and/or software. That means that full HTTPS
interception cannot be performed by ISP. They are usually limited to
doing splice or block that traffic.
 That limited amount of action is enough to perform some types of
optimization such as rejecting traffic based on SNI values. But not
sufficient to do others such as caching.

Amos



From elsaesser at animate.de  Tue Apr 12 08:36:25 2016
From: elsaesser at animate.de (=?UTF-8?Q?Thomas_Els=C3=A4=C3=9Fer?=)
Date: Tue, 12 Apr 2016 10:36:25 +0200
Subject: [squid-users] Squid Cache: Version 3.5.16 and ext_ldap_group_acl
Message-ID: <5571d5d7c2d79848da17a63f846be77f@webmail.animate.de>

Dear all,

I call from Shell:

/usr/local/squid/libexec/ext_ldap_group_acl -d -R -b 
"OU=UMW,DC=a,DC=b,DC=de" -D "XXXXXXX at a.b.DE" -w "XXXXXXX" \
  -f 
"(&(objectClass=person)(sAMAccountName=%v)(MemberOf=CN=%g,OU=DomLokaleGruppen,OU=Gruppen,OU=Benutzer,OU=Min-PRD,OU=XXX,DC=a,DC=b,DC=de))" 
-h dc.a.b.de


I type:

username groupname

and the command return OK

If i configure this in squid:(same command how type in shell)

external_acl_type ldap_group %LOGIN 
/usr/local/squid/libexec/ext_ldap_group_acl -d -R -b 
"OU=UMW,DC=a,DC=b,DC=de" -D "XXXXXXX at a.b.DE" -w "XXXXXXX" \
  -f 
"(&(objectClass=person)(sAMAccountName=%v)(MemberOf=CN=%g,OU=DomLokaleGruppen,OU=Gruppen,OU=Benutzer,OU=Min-PRD,OU=XXX,DC=a,DC=b,DC=de))" 
-h dc.a.b.de


And i trace the helper process, i can see that squid replace the %v with 
username at a.b.de
So the helper give an ERR return to squid.

Where can i this configure , that passed variable is only the username ?

Thanks for help,
Thomas


From squid3 at treenet.co.nz  Tue Apr 12 08:58:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 12 Apr 2016 20:58:26 +1200
Subject: [squid-users] Squid Cache: Version 3.5.16 and ext_ldap_group_acl
In-Reply-To: <5571d5d7c2d79848da17a63f846be77f@webmail.animate.de>
References: <5571d5d7c2d79848da17a63f846be77f@webmail.animate.de>
Message-ID: <570CB8B2.7070903@treenet.co.nz>

On 12/04/2016 8:36 p.m., Thomas Els??er wrote:
> Dear all,
> 
> I call from Shell:
> 
> /usr/local/squid/libexec/ext_ldap_group_acl -d -R -b
> "OU=UMW,DC=a,DC=b,DC=de" -D "XXXXXXX at a.b.DE" -w "XXXXXXX" \
>  -f
> "(&(objectClass=person)(sAMAccountName=%v)(MemberOf=CN=%g,OU=DomLokaleGruppen,OU=Gruppen,OU=Benutzer,OU=Min-PRD,OU=XXX,DC=a,DC=b,DC=de))"
> -h dc.a.b.de
> 
<snip>
> 
> And i trace the helper process, i can see that squid replace the %v with
> username at a.b.de
> So the helper give an ERR return to squid.
> 
> Where can i this configure , that passed variable is only the username ?

That is the user name/label as provided to Squid by the auth helper. It
depends on whether the particular auth helper(s) you are using allow the
credentials domain to be cropped away.

Since it is using "@" symbol look at the Negotiate auth helper options.

Amos



From elsaesser at animate.de  Tue Apr 12 10:52:18 2016
From: elsaesser at animate.de (=?UTF-8?Q?Thomas_Els=C3=A4=C3=9Fer?=)
Date: Tue, 12 Apr 2016 12:52:18 +0200
Subject: [squid-users] Squid Cache: Version 3.5.16 and ext_ldap_group_acl
In-Reply-To: <570CB8B2.7070903@treenet.co.nz>
References: <5571d5d7c2d79848da17a63f846be77f@webmail.animate.de>
 <570CB8B2.7070903@treenet.co.nz>
Message-ID: <a86c75e344d0308aa3f7daff470d3924@webmail.animate.de>

Am 12-04-2016 10:58, schrieb Amos Jeffries:
> On 12/04/2016 8:36 p.m., Thomas Els??er wrote:
>> Dear all,
>> 
>> I call from Shell:
>> 
>> /usr/local/squid/libexec/ext_ldap_group_acl -d -R -b
>> "OU=UMW,DC=a,DC=b,DC=de" -D "XXXXXXX at a.b.DE" -w "XXXXXXX" \
>>  -f
>> "(&(objectClass=person)(sAMAccountName=%v)(MemberOf=CN=%g,OU=DomLokaleGruppen,OU=Gruppen,OU=Benutzer,OU=Min-PRD,OU=XXX,DC=a,DC=b,DC=de))"
>> -h dc.a.b.de
>> 
> <snip>
>> 
>> And i trace the helper process, i can see that squid replace the %v 
>> with
>> username at a.b.de
>> So the helper give an ERR return to squid.
>> 
>> Where can i this configure , that passed variable is only the username 
>> ?
> 
> That is the user name/label as provided to Squid by the auth helper. It
> depends on whether the particular auth helper(s) you are using allow 
> the
> credentials domain to be cropped away.
> 
> Since it is using "@" symbol look at the Negotiate auth helper options.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
yes - sorry for the stupid questions - the minus r option is that what i 
need. thanks again!!!
auth_param negotiate program 
/usr/local/squid/libexec/negotiate_kerberos_auth -d -r -s  HTTP/...

Best wishes
Thomas


From fredbmail at free.fr  Tue Apr 12 11:05:12 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 12 Apr 2016 13:05:12 +0200 (CEST)
Subject: [squid-users] Squid 3.5.16 and vary loop objects (bug ?)
In-Reply-To: <570CA687.7020907@treenet.co.nz>
Message-ID: <1935895907.96206905.1460459112966.JavaMail.root@zimbra4-e1.priv.proxad.net>

Amos I don't know if this is related or not, but I have a lot of

2016/04/12 13:00:50| Could not parse headers from on disk object
2016/04/12 13:00:50| Could not parse headers from on disk object
2016/04/12 13:00:50| Could not parse headers from on disk object
2016/04/12 13:00:50| Could not parse headers from on disk object
2016/04/12 13:00:51| Could not parse headers from on disk object
2016/04/12 13:00:51| Could not parse headers from on disk object
2016/04/12 13:00:56| Could not parse headers from on disk object
2016/04/12 13:00:56| Could not parse headers from on disk object
2016/04/12 13:00:56| Could not parse headers from on disk object
2016/04/12 13:00:57| Could not parse headers from on disk object
2016/04/12 13:00:57| Could not parse headers from on disk object
2016/04/12 13:00:57| Could not parse headers from on disk object
2016/04/12 13:00:57| Could not parse headers from on disk object
2016/04/12 13:00:57| Could not parse headers from on disk object
2016/04/12 13:00:57| Could not parse headers from on disk object
2016/04/12 13:00:57| Could not parse headers from on disk object

My cache was cleaned and squid patched

Fred


From yvoinov at gmail.com  Tue Apr 12 11:55:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 12 Apr 2016 17:55:50 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
Message-ID: <570CE246.40008@gmail.com>

Does anybody faces this problem with 4.0.8:

https://i1.someimage.com/3lD2cvV.png

?

It accomplished this error in cache.log:

2016/04/12 17:39:38 kid1| Error negotiating SSL on FD 54: 
error:00000000:lib(0):func(0):reason(0) (5/0/0)

and "NONE/503" in access.log.

Without proxy works like sharm. 3.5.16 with the similar squid.conf works 
like sharm.

NB: Cloudflare support said, that they key feature for SSL is SNI and 
ECDSA now. AFAIK, 4.0.8 is fully supports this features.

Any advice will be helpful.

Yes, I know this looks like DDoS protection on Cloudflare. But WTF? Any 
workaround required. Half-Internet is hosted on Cloudflare.

WBR, Yuri


From yvoinov at gmail.com  Tue Apr 12 14:03:59 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 12 Apr 2016 20:03:59 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570CE246.40008@gmail.com>
References: <570CE246.40008@gmail.com>
Message-ID: <570D004F.3030406@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
UPDATE:

https://i1.someimage.com/b8w5dFz.png

This is answer from Cloudflare support.

But: 3.5.16 can deal with ECDSA TLS 1.2 but 4.0.8 not?

12.04.16 17:55, Yuri Voinov ?????:
> Does anybody faces this problem with 4.0.8:
>
> https://i1.someimage.com/3lD2cvV.png
>
> ?
>
> It accomplished this error in cache.log:
>
> 2016/04/12 17:39:38 kid1| Error negotiating SSL on FD 54:
error:00000000:lib(0):func(0):reason(0) (5/0/0)
>
> and "NONE/503" in access.log.
>
> Without proxy works like sharm. 3.5.16 with the similar squid.conf
works like sharm.
>
> NB: Cloudflare support said, that they key feature for SSL is SNI and
ECDSA now. AFAIK, 4.0.8 is fully supports this features.
>
> Any advice will be helpful.
>
> Yes, I know this looks like DDoS protection on Cloudflare. But WTF?
Any workaround required. Half-Internet is hosted on Cloudflare.
>
> WBR, Yuri

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXDQBOAAoJENNXIZxhPexGKx4H/3V9jDRNKu1xVzQhLbyVMB2u
uu9+N6umos9wi9GTRnIbMyHVS99BKUbQZf8DpdnJL+k4CPdaiHdgh/Z2QsfJoA3h
KZyI6/fpQPcsXX0xgtfpDLSPmHt61H3Dni9lRmR77BNFkq7JUKLFe71rW+8XcDBz
QeynTNi3EWfnufj332tMPj6LESZWTA5paREB1Y39sTl13kZqlmoe8hFrkckkNGRJ
38p3dl6HkMkb5eznP8fkMOjnCo61UA5BKrnzlTpFwjF21Fdv6zlrIApW8ljc7s2B
B+VkTXmuPUY/WjDybMnxdDvAYbtRAfcE4K8pE74CbHsJ/tbmfk1e0VdhD/TfpAk=
=4ka+
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160412/609715c2/attachment.key>

From amadaan at ncsu.edu  Tue Apr 12 13:41:56 2016
From: amadaan at ncsu.edu (amadaan)
Date: Tue, 12 Apr 2016 06:41:56 -0700 (PDT)
Subject: [squid-users] FATAL: Ipc::Mem::Segment::create failed to
 shm_open(/squid-cf__metadata.shm): (13) Permission denied
In-Reply-To: <570C0B86.5030900@ngtech.co.il>
References: <1460388196384-4677044.post@n4.nabble.com>
 <1460401885099-4677045.post@n4.nabble.com> <570C0B86.5030900@ngtech.co.il>
Message-ID: <1460468516848-4677061.post@n4.nabble.com>

Hey Eliezer,

Thanks for looking into details.

Here is my te file

module MYPOLICY 1.0;

require {
	type unconfined_t;
	type var_run_t;
	type usr_t;
	type syslogd_t;
	type user_tmpfs_t;
	type squid_t;
	type tmpfs_t;
	class process signal;
	class file { getattr read create unlink open };
	class dir { write remove_name add_name };
}

#============= squid_t ==============
#!!!! The source type 'squid_t' can write to a 'dir' of the following types:
# var_log_t, var_run_t, pcscd_var_run_t, squid_var_run_t, squid_cache_t,
squid_log_t, cluster_var_lib_t, cluster_var_run_t, root_t,
krb5_host_rcache_t, cluster_conf_t, tmp_t

allow squid_t tmpfs_t:dir { write remove_name add_name };
allow squid_t tmpfs_t:file { create unlink };
allow squid_t unconfined_t:process signal;
allow squid_t user_tmpfs_t:file unlink;
allow squid_t var_run_t:file { read getattr open };

#============= syslogd_t ==============
#!!!! The source type 'syslogd_t' can write to a 'dir' of the following
types:
# var_log_t, var_run_t, syslogd_tmp_t, syslogd_var_lib_t, syslogd_var_run_t,
innd_log_t, device_t, tmp_t, logfile, cluster_var_lib_t, cluster_var_run_t,
root_t, krb5_host_rcache_t, cluster_conf_t, tmp_t

allow syslogd_t usr_t:dir write;




Also, can you give me link to your unofficial RPMs.

Thanks
Aashima



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/FATAL-Ipc-Mem-Segment-create-failed-to-shm-open-squid-cf-metadata-shm-13-Permission-denied-tp4677044p4677061.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue Apr 12 15:29:19 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 12 Apr 2016 21:29:19 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570D004F.3030406@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
Message-ID: <570D144F.7020206@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
UPDATE:

Every failed connect produce the next sequence in access.log:

1460474791.631  15444 192.168.100.103 NONE_ABORTED/200 0 CONNECT
198.41.215.162:443 - ORIGINAL_DST/198.41.215.162 -
1460474791.658      0 192.168.100.103 NONE/503 3951 GET
https://www.cloudflare.com/* - HIER_NONE/- text/html

Note: 198.41.215.162 is current cloudflare.com IP.

Also: NONE_ABORTED/200 is often occurs in access.log with another
accessible sites.

12.04.16 20:03, Yuri Voinov ?????:
>
> UPDATE:
>
> https://i1.someimage.com/b8w5dFz.png
>
> This is answer from Cloudflare support.
>
> But: 3.5.16 can deal with ECDSA TLS 1.2 but 4.0.8 not?
>
> 12.04.16 17:55, Yuri Voinov ?????:
> > Does anybody faces this problem with 4.0.8:
>
> > https://i1.someimage.com/3lD2cvV.png
>
> > ?
>
> > It accomplished this error in cache.log:
>
> > 2016/04/12 17:39:38 kid1| Error negotiating SSL on FD 54:
> error:00000000:lib(0):func(0):reason(0) (5/0/0)
>
> > and "NONE/503" in access.log.
>
> > Without proxy works like sharm. 3.5.16 with the similar squid.conf
> works like sharm.
>
> > NB: Cloudflare support said, that they key feature for SSL is SNI and
> ECDSA now. AFAIK, 4.0.8 is fully supports this features.
>
> > Any advice will be helpful.
>
> > Yes, I know this looks like DDoS protection on Cloudflare. But WTF?
> Any workaround required. Half-Internet is hosted on Cloudflare.
>
> > WBR, Yuri
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXDRRPAAoJENNXIZxhPexGmZcIAI1gcVCHUjCrDk0vI/f7omMP
ALa5XYk0VrsoOioc5cIh0DuIRN8THqkdXxtRXdKnxC8hgRfvOxN6h7NFilZhVAiT
tvgQkmKxAXXkCXik03AYU5DBoElMDcCgznksAxcckvXGCyWxN7pFwSY2p87WPHa/
5G/K5BTG1rf30OjVYIMPRtsfkHyA5xWIPNHKcbu6bCsV7H+oXh8x8oCNHdF06Q1i
s3U1kiFEudOKC1bMGVY4RJlzqDgGdANsHMSh0/v3rS4it5KBFxPsuz/DDcU1DlkO
MIEMF7FgvxORtgBZPUnxa+sF5gunZqDuv2R2aJuxJpYK2OriOC7+e40dZiw7xpQ=
=/LGq
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160412/ae08c7dc/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160412/ae08c7dc/attachment.key>

From eliezer at ngtech.co.il  Tue Apr 12 18:19:43 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 12 Apr 2016 21:19:43 +0300
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570D144F.7020206@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com>
Message-ID: <570D3C3F.8040603@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160412/10d257b4/attachment.htm>

From yvoinov at gmail.com  Tue Apr 12 18:39:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 13 Apr 2016 00:39:18 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570D3C3F.8040603@ngtech.co.il>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
Message-ID: <570D40D6.5050502@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
My openssl test show the next Cloudflare cipher:

ECDHE-ECDSA-AES128-GCM-SHA256

So, result is:

root @ cthulhu /patch # openssl s_client -cipher
'ECDHE-ECDSA-AES128-GCM-SHA256' -connect www.cloudflare.com:443
CONNECTED(00000003)
depth=3 C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN
= AddTrust External CA Root
verify return:1
depth=2 C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA
Limited, CN = COMODO ECC Certification Authority
verify return:1
depth=1 C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA
Limited, CN = COMODO ECC Extended Validation Secure Server CA
verify return:1
depth=0 serialNumber = 4710875, 1.3.6.1.4.1.311.60.2.1.3 = US,
1.3.6.1.4.1.311.60.2.1.2 = Delaware, businessCategory = Private
Organization, C = US, postalCode = 94107, ST = California, L = San
Francisco, street = "655 Third Street, Suite 200", O = "CloudFlare,
Inc.", OU = COMODO EV Multi-Domain SSL
verify return:1
- ---
Certificate chain
 0
s:/serialNumber=4710875/1.3.6.1.4.1.311.60.2.1.3=US/1.3.6.1.4.1.311.60.2.1.2=Delaware/businessCategory=Private
Organization/C=US/postalCode=94107/ST=California/L=San
Francisco/street=655 Third Street, Suite 200/O=CloudFlare,
Inc./OU=COMODO EV Multi-Domain SSL
   i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO
ECC Extended Validation Secure Server CA
 1 s:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO
ECC Extended Validation Secure Server CA
   i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO
ECC Certification Authority
 2 s:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO
ECC Certification Authority
   i:/C=SE/O=AddTrust AB/OU=AddTrust External TTP Network/CN=AddTrust
External CA Root
- ---
Server certificate
- -----BEGIN CERTIFICATE-----
MIIFiTCCBS+gAwIBAgIQBmy2JcYivinKaUJSCKGtKDAKBggqhkjOPQQDAjCBkjEL
MAkGA1UEBhMCR0IxGzAZBgNVBAgTEkdyZWF0ZXIgTWFuY2hlc3RlcjEQMA4GA1UE
BxMHU2FsZm9yZDEaMBgGA1UEChMRQ09NT0RPIENBIExpbWl0ZWQxODA2BgNVBAMT
L0NPTU9ETyBFQ0MgRXh0ZW5kZWQgVmFsaWRhdGlvbiBTZWN1cmUgU2VydmVyIENB
MB4XDTE1MTIwMTAwMDAwMFoXDTE2MTEzMDIzNTk1OVowggERMRAwDgYDVQQFEwc0
NzEwODc1MRMwEQYLKwYBBAGCNzwCAQMTAlVTMRkwFwYLKwYBBAGCNzwCAQITCERl
bGF3YXJlMR0wGwYDVQQPExRQcml2YXRlIE9yZ2FuaXphdGlvbjELMAkGA1UEBhMC
VVMxDjAMBgNVBBETBTk0MTA3MRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQH
Ew1TYW4gRnJhbmNpc2NvMSQwIgYDVQQJExs2NTUgVGhpcmQgU3RyZWV0LCBTdWl0
ZSAyMDAxGTAXBgNVBAoTEENsb3VkRmxhcmUsIEluYy4xIzAhBgNVBAsTGkNPTU9E
TyBFViBNdWx0aS1Eb21haW4gU1NMMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE
mPbUxrSaUGUh0fWajjE6zyy35uwYkOwNOKll7E0jKcJvxJLR9IC2ySQduynfb2Mo
t5+rzrL5k3RWt7ZCMDsyWaOCAuMwggLfMB8GA1UdIwQYMBaAFNNOwxm6WFnRHGC3
YVNHO6d3j/iKMB0GA1UdDgQWBBT/eDUPVHJ3p6neXJv8NVND7rkLIDAOBgNVHQ8B
Af8EBAMCBYAwDAYDVR0TAQH/BAIwADAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYB
BQUHAwIwRgYDVR0gBD8wPTA7BgwrBgEEAbIxAQIBBQEwKzApBggrBgEFBQcCARYd
aHR0cHM6Ly9zZWN1cmUuY29tb2RvLmNvbS9DUFMwVgYDVR0fBE8wTTBLoEmgR4ZF
aHR0cDovL2NybC5jb21vZG9jYS5jb20vQ09NT0RPRUNDRXh0ZW5kZWRWYWxpZGF0
aW9uU2VjdXJlU2VydmVyQ0EuY3JsMIGHBggrBgEFBQcBAQR7MHkwUQYIKwYBBQUH
MAKGRWh0dHA6Ly9jcnQuY29tb2RvY2EuY29tL0NPTU9ET0VDQ0V4dGVuZGVkVmFs
aWRhdGlvblNlY3VyZVNlcnZlckNBLmNydDAkBggrBgEFBQcwAYYYaHR0cDovL29j
c3AuY29tb2RvY2EuY29tMC0GA1UdEQQmMCSCDmNsb3VkZmxhcmUuY29tghJ3d3cu
Y2xvdWRmbGFyZS5jb20wggEFBgorBgEEAdZ5AgQCBIH2BIHzAPEAdgBo9pj4H2SC
vjqM7rkoHUz8cVFdZ5PURNEKZ6y7T0/7xAAAAVFfF/KGAAAEAwBHMEUCIQCYn9hT
zH7HDl8ssKN1YWXtk09MEMbNCAgONEM33Orv6gIgH99BJXaehbgEQmEBW7372nPv
x3/hqhO9svDabmNm1vIAdwBWFAaaL9fC7NP14b1Esj7HRna5vJkRXMDvlJhV1onQ
3QAAAVFfF++7AAAEAwBIMEYCIQDlr9Q35uiX37IciNrb8I3lSIKAEB73zB0YMPVl
TSl/yQIhAMCcle0L3Gu11iud65NFRogfrOmk9mtuW3ruf5Mt63D5MAoGCCqGSM49
BAMCA0gAMEUCIQDuxJ4FoYrW0fnaNkRajRSwqKcXb8XpV1dYklpVVGxQOgIgRA96
apf7bQLXWdoGLBJg0M7sRB1Bv9Fh+MIzLKhn5lg=
- -----END CERTIFICATE-----
subject=/serialNumber=4710875/1.3.6.1.4.1.311.60.2.1.3=US/1.3.6.1.4.1.311.60.2.1.2=Delaware/businessCategory=Private
Organization/C=US/postalCode=94107/ST=California/L=San
Francisco/street=655 Third Street, Suite 200/O=CloudFlare,
Inc./OU=COMODO EV Multi-Domain SSL
issuer=/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA
Limited/CN=COMODO ECC Extended Validation Secure Server CA
- ---
No client certificate CA names sent
- ---
SSL handshake has read 3826 bytes and written 289 bytes
- ---
New, TLSv1/SSLv3, Cipher is ECDHE-ECDSA-AES128-GCM-SHA256
Server public key is 256 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : ECDHE-ECDSA-AES128-GCM-SHA256
    Session-ID:
46639E396A6540A888C8A9B1994C744D03810678A4F95951A5BBA293DD4BE284
    Session-ID-ctx:
    Master-Key:
26F7F58D4913230F3F93872E2E7390C7D762CDC3E46FC5AAA300866F316ED5A283A813DAFF738457C5B8F5E1340CC156
    Key-Arg   : None
    PSK identity: None
    PSK identity hint: None
    SRP username: None
    TLS session ticket lifetime hint: 64800 (seconds)
    TLS session ticket:
    0000 - 94 71 18 10 6e 8b 7b d3-b1 a7 d9 d7 65 8f a6 ea  
.q..n.{.....e...
    0010 - 45 fa 1b f8 c7 9b 94 a3-64 95 e7 15 c7 98 04 27  
E.......d......'
    0020 - 09 bf 36 7e db f3 ab 82-17 21 f4 2b 26 13 79 94  
..6~.....!.+&.y.
    0030 - ce e7 30 7f c1 c2 3b 65-7e 76 28 46 d2 46 f3 8d  
..0...;e~v(F.F..
    0040 - 5a 54 2f 70 71 53 7a fd-fb 44 e0 df 4c 46 96 99  
ZT/pqSz..D..LF..
    0050 - e7 63 c9 93 eb 34 32 0a-b4 af 6a db c1 f0 5d 10  
.c...42...j...].
    0060 - 5e c3 af 9e 16 59 32 8c-b0 fb 8e cc 9a 48 8e 6a  
^....Y2......H.j
    0070 - 8d ee 85 5d d3 26 9d b1-96 32 ff 78 cb 93 3a ec  
...].&...2.x..:.
    0080 - 9c 5c bd c5 6c 24 93 d6-ad 0a c3 4e 86 a2 e6 28  
.\..l$.....N...(
    0090 - 8c b1 a9 55 f0 01 6d ab-a2 44 52 b3 37 d6 9e 5a  
...U..m..DR.7..Z
    00a0 - 0c b8 1d 5b 6d 10 13 db-31 2b 4c 1a e4 46 36 84  
...[m...1+L..F6.

    Start Time: 1460486320
    Timeout   : 300 (sec)
    Verify return code: 0 (ok)
- ---

13.04.16 0:19, Eliezer Croitoru ?????:
> Hey Yuri,
>
> I will try to test it with couple versions of 4.0.x.
> But it's weird...
> The reason it's weird is since some kind of trust or understand this test:
>
https://www.ssllabs.com/ssltest/analyze.html?d=www.cloudflare.com&s=198.41.214.162&latest
>
> I am not an SSL expert in general but I can use openssl client to test
and verify things.
> I have tested this scenario with openssl like this:
> # openssl s_client -cipher 'ECDHE-ECDSA-AES256-SHA' -connect
www.cloudflare.com:443
> CONNECTED(00000003)
> 139990857013152:error:14077410:SSL
routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake
failure:s23_clnt.c:744:
> ---
> no peer certificate available
> ---
> No client certificate CA names sent
> ---
> SSL handshake has read 7 bytes and written 119 bytes
> ---
> New, (NONE), Cipher is (NONE)
> Secure Renegotiation IS NOT supported
> Compression: NONE
> Expansion: NONE
> ---
>
> And it seems that openssl does something which might be my fault but
if squid 3.5.16 works fine with it and 4.0.8 it might be connected to
the connection between openssl library to the service and squid only
displays the issue in the nice html page.
> I do not know what service cloudflare uses and how it all works but if
openssl states that there is an issue with what the service is either
sending or itself analyzing then the issue is in the openssl level
rather then squid.
>
> I am sure that both cloudflare and openssl and squid users, admins and
devs wants to resolve the issue.
>
> Eliezer
>
> On 12/04/2016 18:29, Yuri Voinov wrote:
>>
> UPDATE:
>
> Every failed connect produce the next sequence in access.log:
>
> 1460474791.631  15444 192.168.100.103 NONE_ABORTED/200 0 CONNECT
198.41.215.162:443 - ORIGINAL_DST/198.41.215.162 -
> 1460474791.658      0 192.168.100.103 NONE/503 3951 GET
https://www.cloudflare.com/* - HIER_NONE/- text/html
>
> Note: 198.41.215.162 is current cloudflare.com IP.
>
> Also: NONE_ABORTED/200 is often occurs in access.log with another
accessible sites.
>
> 12.04.16 20:03, Yuri Voinov ?????:
>
>
>       > UPDATE:
>
>
>
>       > https://i1.someimage.com/b8w5dFz.png
>
>
>
>       > This is answer from Cloudflare support.
>
>
>
>       > But: 3.5.16 can deal with ECDSA TLS 1.2 but 4.0.8 not?
>
>
>
>       > 12.04.16 17:55, Yuri Voinov ?????:
>
>       > > Does anybody faces this problem with 4.0.8:
>
>
>
>       > > https://i1.someimage.com/3lD2cvV.png
>
>
>
>       > > ?
>
>
>
>       > > It accomplished this error in cache.log:
>
>
>
>       > > 2016/04/12 17:39:38 kid1| Error negotiating SSL on FD
>       54:
>
>       > error:00000000:lib(0):func(0):reason(0) (5/0/0)
>
>
>
>       > > and "NONE/503" in access.log.
>
>
>
>       > > Without proxy works like sharm. 3.5.16 with the similar
>       squid.conf
>
>       > works like sharm.
>
>
>
>       > > NB: Cloudflare support said, that they key feature for
>       SSL is SNI and
>
>       > ECDSA now. AFAIK, 4.0.8 is fully supports this features.
>
>
>
>       > > Any advice will be helpful.
>
>
>
>       > > Yes, I know this looks like DDoS protection on
>       Cloudflare. But WTF?
>
>       > Any workaround required. Half-Internet is hosted on
>       Cloudflare.
>
>
>
>       > > WBR, Yuri
>
>
>
>
>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXDUDWAAoJENNXIZxhPexGKC8IAMyl3KxLSB89wgvI8THpMgAH
MKyv6PiSOk6IyXc3w0bbk/H6CpbJZZReOA7HWX8uUNy2zfzq/KGZsOUFpuC1WCR+
J7DbGDWjQbPm8BiYPLOtfziY/yvCiON7N0Iw9VTfu8JmjZ/1Dkn+PLMhphNWxZ0K
gCKukIl8/RQcy8VPSntVriKD43kEsSR854GbJq57DfUgZbBGmo7IKCRepHpijjyj
0GyVtwhI24rgMRasmoOIr6QK6x6+zom3RkusZCQs3u0U1vpqHI70R9eiPbORgiYS
mkX9CQtN6rOlZtDgtZ7ZFuSzO2TWSTRAYBXArdov4CsWjTP+YsxT9TJ5cLhKopk=
=IoWl
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/263ff375/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/263ff375/attachment.key>

From eliezer at ngtech.co.il  Tue Apr 12 20:02:46 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 12 Apr 2016 23:02:46 +0300
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570D40D6.5050502@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com>
Message-ID: <570D5466.6090502@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160412/00adc832/attachment.htm>

From yvoinov at gmail.com  Tue Apr 12 20:29:16 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 13 Apr 2016 02:29:16 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570D5466.6090502@ngtech.co.il>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
Message-ID: <570D5A9C.5030809@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
root @ cthulhu /patch # dig www.cloudflare.com

; <<>> DiG 9.6-ESV-R11-P4 <<>> www.cloudflare.com
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 32548
;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;www.cloudflare.com.            IN      A

;; ANSWER SECTION:
www.cloudflare.com.     86400   IN      A       198.41.214.162
www.cloudflare.com.     86400   IN      A       198.41.215.162

;; Query time: 538 msec
;; SERVER: 127.0.0.1#53(127.0.0.1)
;; WHEN: Wed Apr 13 02:28:34 ALMT 2016
;; MSG SIZE  rcvd: 68

root @ cthulhu /patch # uname -a
SunOS cthulhu 5.10 Generic_150401-30 i86pc i386 i86pc Solaris

But I think OS does not matter here.

13.04.16 2:02, Eliezer Croitoru ?????:
> What "dig www.cloudflare.com" results with?
> Also what OS are you using? I am using CentOS 7 up to date...
>
> Eliezer
>
> On 12/04/2016 21:39, Yuri Voinov wrote:
>> root @ cthulhu /patch # openssl s_client -cipher
'ECDHE-ECDSA-AES128-GCM-SHA256' -connect www.cloudflare.com:443
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXDVqcAAoJENNXIZxhPexGwDUH/0QxKY59wZ5+epR1ccrhKYRK
IqNdZFSTAkVgdy+q9FwAJX4gunI/+l2iexI0Ry8lPPd3m6aGSBMZeHjFuD9Fip4U
GSfg93OXM3x9YkPIuuVY7VRt2lIkRg9nBw312GoqDcRvRisxw6ciDpiHIoiV70kq
Eh9RpyV7VYMGEk1BlF981Li9TZ9Kj+9lTXOgKY0+/gGB55/Bbvroyt3JG7tZNgqv
Zu6BII7WWrun1Xa88lzDD3W2XKgyPDyYGA0cdM45cWyd+MCKFOTT0mV4Y6nhV7Sj
2Z+rqfjweWVGqzwfOZZQZ6T3mEeoeULUDbVq5Zja64dpZSKzac12HOcg+DAjLFI=
=jmpr
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/d004eda5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/d004eda5/attachment.key>

From yvoinov at gmail.com  Tue Apr 12 20:37:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 13 Apr 2016 02:37:21 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570D5A9C.5030809@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com>
Message-ID: <570D5C81.2030900@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I suggests the matter can be openssl not OS:

root @ cthulhu /patch # openssl version -a
OpenSSL 1.0.1s  1 Mar 2016
built on: Tue Mar  1 15:42:26 2016
platform: solaris64-x86_64-cc-sunw
options:  bn(64,64) rc4(16x,int) des(ptr,cisc,16,int) idea(int)
blowfish(ptr)
compiler: /opt/solarisstudio12.4/bin/cc -I. -I.. -I../include  -KPIC
-DOPENSSL_PIC -DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H
-DPK11_LIB_LOCATION="/usr/lib/64/libpkcs11.so" -DHAVE_ISSETUGID
-DAV_SPARC_FJAES=0 -xO3 -m64 -xstrconst -Xa -DL_ENDIAN
-DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5
-DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DMD5_ASM
-DAES_ASM -DVPAES_ASM -DBSAES_ASM -DWHIRLPOOL_ASM -DGHASH_ASM
OPENSSLDIR: "/etc/opt/csw/ssl"


13.04.16 2:29, Yuri Voinov ?????:
>
> root @ cthulhu /patch # dig www.cloudflare.com
>
> ; <<>> DiG 9.6-ESV-R11-P4 <<>> www.cloudflare.com
> ;; global options: +cmd
> ;; Got answer:
> ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 32548
> ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0
>
> ;; QUESTION SECTION:
> ;www.cloudflare.com.            IN      A
>
> ;; ANSWER SECTION:
> www.cloudflare.com.     86400   IN      A       198.41.214.162
> www.cloudflare.com.     86400   IN      A       198.41.215.162
>
> ;; Query time: 538 msec
> ;; SERVER: 127.0.0.1#53(127.0.0.1)
> ;; WHEN: Wed Apr 13 02:28:34 ALMT 2016
> ;; MSG SIZE  rcvd: 68
>
> root @ cthulhu /patch # uname -a
> SunOS cthulhu 5.10 Generic_150401-30 i86pc i386 i86pc Solaris
>
> But I think OS does not matter here.
>
> 13.04.16 2:02, Eliezer Croitoru ?????:
> > What "dig www.cloudflare.com"
>       results with?
>
>       > Also what OS are you using? I am using CentOS 7 up to date...
>
>
>
>       > Eliezer
>
>
>
>       > On 12/04/2016 21:39, Yuri Voinov wrote:
>
>       >> root @ cthulhu /patch # openssl s_client -cipher
>       'ECDHE-ECDSA-AES128-GCM-SHA256' -connect www.cloudflare.com:443
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXDVyBAAoJENNXIZxhPexGpbAIALBIKKiTm3MsZYgftZ9sNzjg
CU0EzJIWxAnkVLfqcZEHOe+LyTV5wVLsHvv6jE2WjHmk84OL13OQh2vxSgB0uDa/
KwPfVr1cnibUku4KrA/+gScSIxjk0chkjugHjFGIlBz1wb8ARV3Rb7Ug5KbFMEbt
1QYuOX/iOntzzZYaXi0a2xL2+9e3r75GLZc39NStYBq169qFI9WsO2nweB/0WZMO
pcWX8Q5rxy6ha3xgxS4vLmyGdNNYVP3JBHQFJurDtd32zV+CJpZjK2OB0Pqj74kN
PMrUi3voUZNG2QZRVUwxkIHCWK4o44F7ZZvRjWbIhoLhQi8MP0m63gY+xS12KYU=
=DEfh
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/565836c9/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/565836c9/attachment.key>

From squid3 at treenet.co.nz  Wed Apr 13 00:55:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Apr 2016 12:55:41 +1200
Subject: [squid-users] FATAL: Ipc::Mem::Segment::create failed to
 shm_open(/squid-cf__metadata.shm): (13) Permission denied
In-Reply-To: <1460468516848-4677061.post@n4.nabble.com>
References: <1460388196384-4677044.post@n4.nabble.com>
 <1460401885099-4677045.post@n4.nabble.com> <570C0B86.5030900@ngtech.co.il>
 <1460468516848-4677061.post@n4.nabble.com>
Message-ID: <570D990D.7000804@treenet.co.nz>

On 13/04/2016 1:41 a.m., amadaan wrote:
> 
> Also, can you give me link to your unofficial RPMs.
> 

That would be <http://wiki.squid-cache.org/KnowledgeBase/CentOS>

Amos



From hydrapolic at gmail.com  Wed Apr 13 14:23:21 2016
From: hydrapolic at gmail.com (Tomas Mozes)
Date: Wed, 13 Apr 2016 16:23:21 +0200
Subject: [squid-users] Sibling cache returns 504 when accessing cached
	objects
Message-ID: <CAG6MAzSDLx31YSSxKDCD5fvY1yJn4fx9=6mbx=6U1ZEkU36WPA@mail.gmail.com>

Hello,
I had a squid (3.5.15) instance (named t1) in reverse-proxy mode:

http_port 80 accel
cache_peer up.example.com parent 80 0 default no-query no-digest
no-netdb-exchange originserver name=origin

It works great, no problems so far.

Now I wanted to add an instance (named t2), having both in sibling relation
(cache hierarchy):

on t1:
http_port 80 accel
cache_peer up.example.com parent 80 0 default no-query no-digest
no-netdb-exchange originserver
cache_peer t2 sibling 80 4827 htcp no-digest

on t2:
http_port 80 accel
cache_peer up.example.com parent 80 0 default no-query no-digest
no-netdb-exchange originserver
cache_peer t1 sibling 80 4827 htcp no-digest

Since t1 had many files cached, t2 started pulling files from t1, but
sometimes, the following error occurs.

Client request from t2:
GET /test.zip HTTP/1.1
User-Agent: Wget/1.17.1 (linux-gnu)
Accept: */*
Accept-Encoding: identity
Host: cache.example.com
Connection: Keep-Alive

t2 asks t1 via htcp:
GET http://cache.example.com/test.zip
User-Agent: Wget/1.17.1 (linux-gnu)
Accept: */*
Accept-Encoding: identity
Host: cache.example.com
Via: 1.1 t2 (squid/3.5.15)
Surrogate-Capability: t2="Surrogate/1.0"
X-Forwarded-For: 1.2.3.4
Cache-Control: max-age=259200

t1 replies to htcp with:
Age: 782932
Expires: Sat, 01 Oct 2016 09:07:09 GMT
Last-Modified: Sun, 15 Nov 2015 00:09:20 GMT
Cache-to-Origin: cache.example.com 1 0.001000 1

then t2 requests the file from t1 via http:
GET http://cache.example.com/test.zip HTTP/1.1
User-Agent: Wget/1.17.1 (linux-gnu)
Accept: */*
Accept-Encoding: identity
Host: cache.example.com
Via: 1.1 t2 (squid/3.5.15)
Surrogate-Capability: t2="Surrogate/1.0"
X-Forwarded-For: 1.2.3.4
Cache-Control: max-age=259200, only-if-cached
Connection: keep-alive

and t1 replies with 504:
HTTP/1.1 504 Gateway Timeout
Server: squid/3.5.15
Mime-Version: 1.0
Date: Wed, 13 Apr 2016 10:36:01 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 4182
X-Squid-Error: ERR_ONLY_IF_CACHED_MISS 0
Vary: Accept-Language
Content-Language: en
Age: 1460543762
Warning: 113 t1 (squid/3.5.15) This cache hit is still fresh and more than
1 day old
Warning: 110 squid/3.5.15 "Response is stale"
Warning: 111 squid/3.5.15 "Revalidation failed"
X-Cache: HIT from t1
X-Cache-Lookup: HIT from t1:80
Via: 1.1 t1 (squid/3.5.15)
Connection: keep-alive

I checked upstream (up.example.com) and there was no connection attempt.
Tried with ICP/HTCP, same result. I'm not sure, is this bug
http://bugs.squid-cache.org/show_bug.cgi?id=4223?

Thanks,
Tomas Mozes
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/e9f124c1/attachment.htm>

From squid3 at treenet.co.nz  Wed Apr 13 15:39:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Apr 2016 03:39:35 +1200
Subject: [squid-users] Sibling cache returns 504 when accessing cached
 objects
In-Reply-To: <CAG6MAzSDLx31YSSxKDCD5fvY1yJn4fx9=6mbx=6U1ZEkU36WPA@mail.gmail.com>
References: <CAG6MAzSDLx31YSSxKDCD5fvY1yJn4fx9=6mbx=6U1ZEkU36WPA@mail.gmail.com>
Message-ID: <570E6837.20000@treenet.co.nz>

On 14/04/2016 2:23 a.m., Tomas Mozes wrote:
> 
> I checked upstream (up.example.com) and there was no connection attempt.
> Tried with ICP/HTCP, same result. I'm not sure, is this bug
> http://bugs.squid-cache.org/show_bug.cgi?id=4223?
> 

I think it is, yes.

Amos



From hydrapolic at gmail.com  Wed Apr 13 16:28:03 2016
From: hydrapolic at gmail.com (Tomas Mozes)
Date: Wed, 13 Apr 2016 18:28:03 +0200
Subject: [squid-users] Sibling cache returns 504 when accessing cached
	objects
In-Reply-To: <570E6837.20000@treenet.co.nz>
References: <CAG6MAzSDLx31YSSxKDCD5fvY1yJn4fx9=6mbx=6U1ZEkU36WPA@mail.gmail.com>
 <570E6837.20000@treenet.co.nz>
Message-ID: <CAG6MAzQJD+51m+25MiFAdXx-qZbN5Z5D+h4+t=gC4DPcPs3e0A@mail.gmail.com>

On Wed, Apr 13, 2016 at 5:39 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 14/04/2016 2:23 a.m., Tomas Mozes wrote:
> >
> > I checked upstream (up.example.com) and there was no connection attempt.
> > Tried with ICP/HTCP, same result. I'm not sure, is this bug
> > http://bugs.squid-cache.org/show_bug.cgi?id=4223?
> >
>
> I think it is, yes.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



Can I supply any more information to help fixing this?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/27471877/attachment.htm>

From odhiambo at gmail.com  Wed Apr 13 18:02:32 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Wed, 13 Apr 2016 21:02:32 +0300
Subject: [squid-users] Stuggling with 3.5.16 on FreeBSD-9.3
Message-ID: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>

Hi Amos,

I bit the bullet and upgraded my FreeBSD-8.4 -> 9.3.

I am struggling to compile squid-3.5.16. I just have to find a way to make
it compile and run, by all means.

So now here is what happens:


#!/bin/sh
./configure --prefix=/opt/squid-3.5 \
        --enable-removal-policies="lru heap" \
        --disable-epoll \
        --with-pthreads \
        --enable-storeio="ufs diskd rock aufs" \
        --enable-delay-pools \
        --enable-snmp  \
        --with-openssl=/usr \
        --enable-forw-via-db \
        --enable-cache-digests \
        --enable-wccpv2 \
        --enable-follow-x-forwarded-for \
        --with-large-files \
        --enable-esi \
        --enable-kqueue \
        --enable-icap-client \
        --enable-kill-parent-hack \
        --enable-ssl \
        --enable-ssl-crtd \
        --enable-url-rewrite-helpers \
        --enable-xmalloc-statistics \
        --enable-stacktraces \
        --enable-zph-qos \
        --enable-eui \
        --with-nat-devpf \
        --enable-pf-transparent \
        --enable-ipf-transparent \
        --enable-auth \

My config.log output is here: *http://goo.gl/LcV1yN <http://goo.gl/LcV1yN>*

And this is how the compile fails:Making all in negotiate_auth
Making all in kerberos
depbase=`echo negotiate_kerberos_auth.o | sed
's|[^/]*$|.deps/&|;s|\.o$||'`; g++ -DHAVE_CONFIG_H    -I../../..
-I../../../include  -I../../../lib -I../../../src  -I../../../include
 -I/usr/include  -I/usr/include  -I../../../libltdl -I. -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Wall
-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual
-Werror -pipe -D_REENTRANT -I/usr/local/include  -g -O2 -march=native
-I/usr/local/include -MT negotiate_kerberos_auth.o -MD -MP -MF $depbase.Tpo
-c -o negotiate_kerberos_auth.o negotiate_kerberos_auth.cc && mv -f
$depbase.Tpo $depbase.Po
negotiate_kerberos_auth.cc: In function 'int main(int, char* const*)':
negotiate_kerberos_auth.cc:754: error:
'gsskrb5_extract_authz_data_from_sec_context' was not declared in this scope
*** [negotiate_kerberos_auth.o] Error code 1

Stop in
/usr/home/wash/Tools/Squid/3.5/squid-3.5.16/helpers/negotiate_auth/kerberos.
*** [all-recursive] Error code 1

Stop in
/usr/home/wash/Tools/Squid/3.5/squid-3.5.16/helpers/negotiate_auth/kerberos.
*** [all-recursive] Error code 1

Stop in /usr/home/wash/Tools/Squid/3.5/squid-3.5.16/helpers/negotiate_auth.
*** [all-recursive] Error code 1

Stop in /usr/home/wash/Tools/Squid/3.5/squid-3.5.16/helpers.
*** [all-recursive] Error code 1

Stop in /usr/home/wash/Tools/Squid/3.5/squid-3.5.16.



I am getting closer I think.

The initial compile that I had before the upgrade from 8.4 to 9.3 cannot
run. Gives a different error:

2016/04/13 14:12:13| Accepting NAT intercepted SSL bumped HTTPS Socket
connections at local=192.168.55.254:13129 remote=[::] FD 36 flags=41
2016/04/13 14:12:13| Accepting ICP messages on [::]:3130
2016/04/13 14:12:13| Sending ICP messages from [::]:3130
2016/04/13 14:12:13| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.83:50648 FD 14 flags=33
2016/04/13 14:12:14| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.93:54178 FD 14 flags=33
2016/04/13 14:12:14| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.93:54166 FD 14 flags=33
2016/04/13 14:12:14| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.93:54165 FD 14 flags=33
2016/04/13 14:12:14| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.93:54180 FD 14 flags=33
2016/04/13 14:12:14| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.93:54179 FD 14 flags=33
2016/04/13 14:12:14| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.93:54182 FD 14 flags=33
2016/04/13 14:12:14| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.93:54181 FD 14 flags=33

I therefore feel I must compile afresh against FreeBSD-9.3

Your help is highly appreciated.



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/29c3b115/attachment.htm>

From crmanik at gmail.com  Wed Apr 13 23:28:10 2016
From: crmanik at gmail.com (Manikandan Ramachandran)
Date: Wed, 13 Apr 2016 23:28:10 +0000
Subject: [squid-users] Unable to Proxy https traffic using squid
In-Reply-To: <5708838C.1090700@treenet.co.nz>
References: <1459989082183-4676981.post@n4.nabble.com>
 <1459992851533-4676982.post@n4.nabble.com>
 <5708838C.1090700@treenet.co.nz>
Message-ID: <CANfDHstNQD-HQJrQkNc8r_mGN794AxQEmHe58AG_ObBTwjpghQ@mail.gmail.com>

Thanks Amos that helped!
On Fri, Apr 8, 2016 at 9:22 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 7/04/2016 1:34 p.m., crmanik wrote:
> > Got this intersting log using -X option:
> >
> <snip>
> >
> > *2016/04/06 18:34:53.817 kid1| Error negotiating SSL on FD 12:
> > error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake
> > failure (1/-1/0)
> > *
>
> Your OpenSSL library may not be supporting the TLS or SSL version that
> the other endpoint of the connection is trying to speak.
>  ** There is no sign of specific SSL/TLS version in your squid.conf, so
> this will be controlled by the library config file.
>
>
> Squid-4 is needed for non-HTTPS traffic support on port 443 if that is
> not HTTPS happening.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160413/cc95ef83/attachment.htm>

From squid3 at treenet.co.nz  Thu Apr 14 00:36:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Apr 2016 12:36:34 +1200
Subject: [squid-users] Sibling cache returns 504 when accessing cached
 objects
In-Reply-To: <CAG6MAzQJD+51m+25MiFAdXx-qZbN5Z5D+h4+t=gC4DPcPs3e0A@mail.gmail.com>
References: <CAG6MAzSDLx31YSSxKDCD5fvY1yJn4fx9=6mbx=6U1ZEkU36WPA@mail.gmail.com>
 <570E6837.20000@treenet.co.nz>
 <CAG6MAzQJD+51m+25MiFAdXx-qZbN5Z5D+h4+t=gC4DPcPs3e0A@mail.gmail.com>
Message-ID: <570EE612.2080501@treenet.co.nz>

On 14/04/2016 4:28 a.m., Tomas Mozes wrote:
> On Wed, Apr 13, 2016 at 5:39 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 14/04/2016 2:23 a.m., Tomas Mozes wrote:
>>>
>>> I checked upstream (up.example.com) and there was no connection attempt.
>>> Tried with ICP/HTCP, same result. I'm not sure, is this bug
>>> http://bugs.squid-cache.org/show_bug.cgi?id=4223?
>>>
>>
>> I think it is, yes.
>>
>> Amos
> 
> 
> 
> Can I supply any more information to help fixing this?
> 

There is a quick-fix and a full fix.

* The quick fix would be to just remove the "only-if-cached" from
sibling lookups. That would let the sibling revalidate. Queries would
result in 200 or such 'successfully', but much slower than they should.

* The full fix for good performance we still need someone to get a ALL,9
debug trace from both proxies and then to figure out from that;
 A) why the sibling is trying to do 304 revalidation on the full fetch
instead of identifying such problems on the HTCP lookup, and
 B) why the front proxy is not doing failover properly on the 504
response it gets back.

Amos



From squid3 at treenet.co.nz  Thu Apr 14 00:56:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Apr 2016 12:56:16 +1200
Subject: [squid-users] Stuggling with 3.5.16 on FreeBSD-9.3
In-Reply-To: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
References: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
Message-ID: <570EEAB0.2050700@treenet.co.nz>

On 14/04/2016 6:02 a.m., Odhiambo Washington wrote:
> Hi Amos,
> 
> I bit the bullet and upgraded my FreeBSD-8.4 -> 9.3.
> 
> I am struggling to compile squid-3.5.16. I just have to find a way to make
> it compile and run, by all means.
> 
> So now here is what happens:
> 
> 
> #!/bin/sh
> ./configure --prefix=/opt/squid-3.5 \
>         --enable-removal-policies="lru heap" \
>         --disable-epoll \
>         --with-pthreads \
>         --enable-storeio="ufs diskd rock aufs" \
>         --enable-delay-pools \
>         --enable-snmp  \
>         --with-openssl=/usr \
>         --enable-forw-via-db \
>         --enable-cache-digests \
>         --enable-wccpv2 \
>         --enable-follow-x-forwarded-for \
>         --with-large-files \
>         --enable-esi \
>         --enable-kqueue \
>         --enable-icap-client \
>         --enable-kill-parent-hack \
>         --enable-ssl \
>         --enable-ssl-crtd \
>         --enable-url-rewrite-helpers \
>         --enable-xmalloc-statistics \
>         --enable-stacktraces \
>         --enable-zph-qos \
>         --enable-eui \
>         --with-nat-devpf \
>         --enable-pf-transparent \
>         --enable-ipf-transparent \
>         --enable-auth \
> 
> My config.log output is here: *http://goo.gl/LcV1yN <http://goo.gl/LcV1yN>*
> 
> And this is how the compile fails:Making all in negotiate_auth
> Making all in kerberos
> depbase=`echo negotiate_kerberos_auth.o | sed
> 's|[^/]*$|.deps/&|;s|\.o$||'`; g++ -DHAVE_CONFIG_H    -I../../..
> -I../../../include  -I../../../lib -I../../../src  -I../../../include
>  -I/usr/include  -I/usr/include  -I../../../libltdl -I. -I/usr/include
> -I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Wall
> -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual
> -Werror -pipe -D_REENTRANT -I/usr/local/include  -g -O2 -march=native
> -I/usr/local/include -MT negotiate_kerberos_auth.o -MD -MP -MF $depbase.Tpo
> -c -o negotiate_kerberos_auth.o negotiate_kerberos_auth.cc && mv -f
> $depbase.Tpo $depbase.Po
> negotiate_kerberos_auth.cc: In function 'int main(int, char* const*)':
> negotiate_kerberos_auth.cc:754: error:
> 'gsskrb5_extract_authz_data_from_sec_context' was not declared in this scope
> *** [negotiate_kerberos_auth.o] Error code 1
> 

Strange. Check the Kerberos / krb5 libraries available are up to date.
Or for now you may need to use one or more of these:
 --without-mit-kerberos \
 --without-heimdal-kerbers \
 --without-gssapi-kerberos


> 
> I am getting closer I think.
> 
> The initial compile that I had before the upgrade from 8.4 to 9.3 cannot
> run. Gives a different error:
> 
> 2016/04/13 14:12:13| Accepting NAT intercepted SSL bumped HTTPS Socket
> connections at local=192.168.55.254:13129 remote=[::] FD 36 flags=41
> 2016/04/13 14:12:13| Accepting ICP messages on [::]:3130
> 2016/04/13 14:12:13| Sending ICP messages from [::]:3130
> 2016/04/13 14:12:13| ERROR: NAT/TPROXY lookup failed to locate original IPs
> on local=192.168.55.254:13128 remote=192.168.55.83:50648 FD 14 flags=33


<http://www.squid-cache.org/Versions/v3/3.4/RELEASENOTES.html#ss2.4>

I dont think IPFilter (--enable-ipf-transparent) works on FreeBSD.

paketFilte (PF, --enable-pf-transparent --with-nat-devpf) and IFPW
(--enable-ipfw-transparent) should do.

Be careful of the 'f' and 'w' characters there, it can be a bit
confusing with them all those different names.


NP: the same error message can occur if you have simply configured DNAT
/ REDIRECT external to the Squid machine.

Amos


From talroz0 at gmail.com  Thu Apr 14 05:03:43 2016
From: talroz0 at gmail.com (rozi)
Date: Wed, 13 Apr 2016 22:03:43 -0700 (PDT)
Subject: [squid-users] splash page + ubuntu 14.04 + squid 3.3.8
Message-ID: <1460610223055-4677076.post@n4.nabble.com>

Hi

trying to set a splash page that popup once a day for the clients here is my
conf:

external_acl_type splash_page concurrency=100 ttl=10 %SRC
/usr/lib/squid3/ext_session_acl -a -T 60 -b /home/e987654654/sessions.db
acl existing_users external splash_page
http_access deny !existing_users
deny_info 511:splash.html Mynetwork
deny_info 511:splash.html existing_users
http_access allow Mynetwork


cant get it to work , in this conf example after 60 sec i get conecction
refuse for 10 sec and the splash page dont popup during the 10 sec 

Anyone can help me ?

Thanks alot rozi



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/splash-page-ubuntu-14-04-squid-3-3-8-tp4677076.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From faisalusuf at yahoo.com  Thu Apr 14 07:51:30 2016
From: faisalusuf at yahoo.com (Muhammad Faisal)
Date: Thu, 14 Apr 2016 07:51:30 +0000
Subject: [squid-users] Squid 3.5 no traffic saving
In-Reply-To: <em8b07a9f0-b83e-4c40-9ff4-51106aea3c65@augere-1>
Message-ID: <em33222d70-90f3-44da-922c-c237a1692464@augere-1>

Hi Amos,
The regression is fixed in the latest snapshot?
--
Regards,
Faisal.

On 9/04/2016 9:06 p.m., Muhammad Faisal wrote:
 > Hi,
 > I have deployed squid 3.5.16 as transparent proxy. I'm using squid 
store
 > ID help for CDN content caching despite all efforts i dont see any
 > traffic saving on upstream. From access logs most of the content is
 > generating from CDNs streaming videos and downloads which always comes
 > from destination despite using Store-ID helper.
 >
 > If someone has deployed and have working configs please help me out.
 >

see my answre to johnzeng yesterday about ORIGINAL_DST and caching.


There is also a regression bug (#4481) in 3.5.16 which prevents Vary
caching properly. The patch for that just went into 3.5 so will be fixed
in tomorrows snapshot (r14022 or later).

Amos

------ Original Message ------
From: "Muhammad Faisal" <faisalusuf at yahoo.com>
To: squid-users at lists.squid-cache.org
Sent: 4/9/2016 2:06:48 PM
Subject: Squid 3.5 no traffic saving

>Hi,
>I have deployed squid 3.5.16 as transparent proxy. I'm using squid 
>store ID help for CDN content caching despite all efforts i dont see 
>any traffic saving on upstream. From access logs most of the content is 
>generating from CDNs streaming videos and downloads which always comes 
>from destination despite using Store-ID helper.
>
>If someone has deployed and have working configs please help me out.
>
>--
>Regards,
>Faisal.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160414/8cdf191e/attachment.htm>

From faisalusuf at yahoo.com  Thu Apr 14 08:03:58 2016
From: faisalusuf at yahoo.com (Muhammad Faisal)
Date: Thu, 14 Apr 2016 08:03:58 +0000
Subject: [squid-users] Dynamic/CDN Content Caching Challenges
Message-ID: <emf0252ebd-79a7-4524-8666-220414ca5ecf@augere-1>

Hi,
I'm trying to deal with dynamic content to be cached by Squid 3.5 (i 
tried many other version of squid e.g 2.7, 3.1, 3.4). By Dynamic I mean 
the URL for the actual content is always change this results in the 
wastage of Cache storage and low hit rate. As per my understanding I 
have two challenges atm:

1- Websites with dynamic URL for requested content (e.g filehippo, 
download.com etc etc)
2- Streaming web sites where the dynamic URL has 206 (partial content) 
tune.pk videos for e.g or windows updates (enabling range off set limit 
to -1 causes havoc on upstream to we kept it disable is there some way 
to control the behavior ?)

If someone has successfully configured the above scenario please help me 
out as i dont have programming background to deal with this complexity.

I tried using different store-ID helpers but no saving on upstream the 
content is still coming from origin. Below is the helper i have used:

My Setup Summary:
Centos 6.5
Tproxy
Single Ethernet
Squid v3.5.16 (yum installed from repo)

Squid Cache: Version 3.5.16
Service Name: squid
configure options:  '--build=x86_64-redhat-linux-gnu' 
'--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' 
'--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' 
'--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' 
'--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' 
'--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' 
'--mandir=/usr/share/man' '--infodir=/usr/share/info' '--verbose' 
'--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' 
'--localstatedir=/var' '--datadir=/usr/share/squid' 
'--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' 
'--with-pidfile=$(localstatedir)/run/squid.pid' 
'--disable-dependency-tracking' '--enable-follow-x-forwarded-for' 
'--enable-auth' 
'--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam' 
'--enable-auth-ntlm=smb_lm,fake' '--enable-auth-digest=file,LDAP' 
'--enable-auth-negotiate=kerberos,wrapper' 
'--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group' 
'--enable-cache-digests' '--enable-cachemgr-hostname=localhost' 
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
'--enable-ident-lookups' '--enable-linux-netfilter' 
'--enable-removal-policies=heap,lru' '--enable-snmp' 
'--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi' 
'--enable-ssl-crtd' '--enable-icmp' '--with-aio' 
'--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' 
'--with-openssl' '--with-pthreads' '--with-included-ltdl' 
'--disable-arch-native' '--without-nettle' 
'build_alias=x86_64-redhat-linux-gnu' 
'host_alias=x86_64-redhat-linux-gnu' 
'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic' 'CXXFLAGS=-O2 -g -pipe 
-Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -fPIC' 
'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' 
--enable-ltdl-convenience

-----------------------------------------------
Store ID Helper
===============================================
#!/usr/bin/perl
# Improved\Converted StoreID helper based on perl and not on ruby
# this helper dosn't have my logic about youtube and other StoreID
# but it still do the trick in most cases and for my understanding.
# if you do want to understand the script logic rather then just
# use it try to look at: http://www1.ngtech.co.il/paste/1016/
# Eliezer Croitoru eliezer<at>ngtech.co.il

$|=1;
while (<>) {
         chomp;
         @X = split;
         if (@X[0] =~ m/^(exit|quit|x|q)/) {
                 print STDERR "quiting helper quietly\n";
                 exit 0;
         }


if ($X[0] =~ 
m/^http\:\/\/.*(youtube|google).*(videoplayback|liveplay).*/){
         @itag = m/[&?](itag=[0-9]*)/;
         @id = m/[&?](id=[^\&]*)/;
         @range = m/[&?](range=[^\&\s]*)/;
         @begin = m/[&?](begin=[^\&\s]*)/;
         @redirect = m/[&?](redirect_counter=[^\&]*)/;
         
$out="http://video-srv.youtube.com.squid.internal/@id&@itag&@range at begin@redirect";

} elsif ($X[0] =~ 
m/^http\:\/\/.*(profile|photo|creative).*\.ak\.fbcdn\.net\/((h|)(profile|photos)-ak-)(snc|ash|prn)[0-9]?(.*)/) 
{
         $out="http://fbcdn.net.squid.internal/" . $2  . "fb" .  $6  ;

} elsif ($X[0] =~ m/^http:\/\/i[1-4]\.ytimg\.com\/(.*)/) {
         $out="http://ytimg.com.squid.internal/" . $1 ;

} elsif ($X[0] =~ m/^http:\/\/.*\.dl\.sourceforge\.net\/(.*)/) {
           $out="http://dl.sourceforge.net.squid.internal/" . $1 ;

                 #Speedtest
} elsif ($X[0] =~ m/^http\:\/\/.*\/speedtest\/(.*\.(jpg|txt)).*/) {
         $out="http://speedtest.squid.internal/" . $1 ;

                 #BLOGSPOT
} elsif ($X[0] =~ m/^http:\/\/[1-4]\.bp\.(blogspot\.com.*)/) {
         $out="http://blog-cdn." . $1  ;

                 #AVAST
} elsif ($X[0] =~ m/^http:\/\/download[0-9]{3}.(avast.com.*)/) {
           $out="http://avast-cdn." . $1  ;

               #AVAST
} elsif ($X[0] =~ m/^http:\/\/[0-9]*\.[0-9]*\.[0-9]*\.[0-9]*\/(iavs.*)/) 
{
         $out="http://avast-cdn.avast.com/" . $1  ;

         #KAV
} elsif ($X[0] =~ m/^http:\/\/dnl-[0-9]{2}.(geo.kaspersky.com.*)/) {
           $out="http://kav-cdn." . $1  ;

                 #AVG
} elsif ($X[0] =~ m/^http:\/\/update.avg.com/) {
           $out="http://avg-cdn." . $1  ;

                 #maps.google.com
} elsif ($X[0] =~ 
m/^http:\/\/(cbk|mt|khm|mlt|tbn)[0-9]?(.google\.co(m|\.uk|\.id).*)/) {
         $out="http://" . $1  . $2 ;

                 #gstatic and/or wikimapia
} elsif ($X[0] =~ 
m/^http:\/\/([a-z])[0-9]?(\.gstatic\.com.*|\.wikimapia\.org.*)/) {
         $out="http://" . $1  . $2 ;

                 #maps.google.com
} elsif ($X[0] =~ m/^http:\/\/(khm|mt)[0-9]?(.google.com.*)/) {
         $out="http://" . $1  . $2 ;

                 #Google
} elsif ($X[0] =~ 
m/^http:\/\/www\.google-analytics\.com\/__utm\.gif\?.*/) {
         $out="http://www.google-analytics.com/__utm.gif\n";

} elsif ($X[0] =~ m/^http:\/\/(www\.ziddu\.com.*\.[^\/]{3,4})\/(.*?)/) {
         $out="http://" . $1 ;

                 #cdn, varialble 1st path
} elsif (($X[0] =~ /filehippo/) && 
(m/^http:\/\/(.*?)\.(.*?)\/(.*?)\/(.*)\.([a-z0-9]{3,4})(\?.*)?/)) {
         @y = ($1,$2,$4,$5);
         $y[0] =~ s/[a-z0-9]{2,5}/cdn./;
         $out="http://" . $y[0] . $y[1] . "/" . $y[2] . "." . $y[3] ;

                 #rapidshare
} elsif (($X[0] =~ /rapidshare/) && 
(m/^http:\/\/(([A-Za-z]+[0-9-.]+)*?)([a-z]*\.[^\/]{3}\/[a-z]*\/[0-9]*)\/(.*?)\/([^\/\?\&]{4,})$/)) 
{
         $out="http://cdn." . $3 . "/squid.internal/" . $5 ;

                 #for yimg.com video
} elsif ($X[0] =~ 
m/^http:\/\/(.*yimg.com)\/\/(.*)\/([^\/\?\&]*\/[^\/\?\&]*\.[^\/\?\&]{3,4})(\?.*)?$/) 
{
         $out="http://cdn.yimg.com/" . $3 ;

                 #for yimg.com doubled
} elsif ($X[0] =~ 
m/^http:\/\/(.*?)\.yimg\.com\/(.*?)\.yimg\.com\/(.*?)\?(.*)/) {
         $out="http://cdn.yimg.com/"  . $3 ;

                 #for Filehippo files
} elsif ($X[0] =~ 
m/^https?:\/\/.*\.(filehippo\.com)\/.*\/(.*[\.exe|zip|cab|msi|mru|mri|bz2|gzip|tgz|rar|pdf])/) 
{
                 $out="http://filehippo.sqinternal/" . $1 . $2 ;


                 #for yimg.com with &sig=
} elsif ($X[0] =~ m/^http:\/\/([^\.]*)\.yimg\.com\/(.*)/) {
         @y = ($1,$2);
         $y[0] =~ s/[a-z]+([0-9]+)?/cdn/;
         $y[1] =~ s/&sig=.*//;
         $out="http://" . $y[0] . ".yimg.com/"  . $y[1] ;

} else {
         $out="ERR";

}
if ( $out =~ m/^http\:\/\/.*/) {
  print "OK store-id=$out\n" ;
} else {
  print "ERR\n" ;
}
}
--
Regards,
Faisal.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160414/b3c5bcb2/attachment.htm>

From squid3 at treenet.co.nz  Thu Apr 14 08:45:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Apr 2016 20:45:58 +1200
Subject: [squid-users] splash page + ubuntu 14.04 + squid 3.3.8
In-Reply-To: <1460610223055-4677076.post@n4.nabble.com>
References: <1460610223055-4677076.post@n4.nabble.com>
Message-ID: <570F58C5.4080104@treenet.co.nz>

On 14/04/2016 5:03 p.m., rozi wrote:
> Hi
> 
> trying to set a splash page that popup once a day for the clients here is my
> conf:
> 
> external_acl_type splash_page concurrency=100 ttl=10 %SRC
> /usr/lib/squid3/ext_session_acl -a -T 60 -b /home/e987654654/sessions.db
> acl existing_users external splash_page
> http_access deny !existing_users
> deny_info 511:splash.html Mynetwork
> deny_info 511:splash.html existing_users
> http_access allow Mynetwork
> 
> 
> cant get it to work , in this conf example after 60 sec i get conecction
> refuse for 10 sec and the splash page dont popup during the 10 sec 
> 
> Anyone can help me ?

You have two problems here:

1a) The -a parameter enables active mode sessions. Which means the
'existing_users' ACL (or another ACL matching an 'accept button' URL)
has to pass "LOGIN" to the helper for sessions to exist.

1b) The ACL 'MyNetwork' is not used to deny anything, so the deny_info
has nothing to do.


2) you do not seem to have any logic to identify when a particular
request will be user-visible.
 This is kind of important since modern browsers and OS perform a huge
amount of automated requests in the background. Or even things with XHR
scripts during user browsing.
None of which the user will ever see in 'page' format, but which can
screw up the system or web service behaviour of the recipient software.
That 511 is the right way to do this, but is a fairly new feature in
HTTP so a lot of software still dont handle it well.

HTH
Amos



From squid3 at treenet.co.nz  Thu Apr 14 08:54:20 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Apr 2016 20:54:20 +1200
Subject: [squid-users] Squid 3.5 no traffic saving
In-Reply-To: <em33222d70-90f3-44da-922c-c237a1692464@augere-1>
References: <em33222d70-90f3-44da-922c-c237a1692464@augere-1>
Message-ID: <570F5ABC.3060105@treenet.co.nz>

On 14/04/2016 7:51 p.m., Muhammad Faisal wrote:
> Hi Amos,
> The regression is fixed in the latest snapshot?

The Vary regression is, yes.

But I'm not clear on what your 'regression' was exactly. So you will
have to test and see.

Amos



From faisalusuf at yahoo.com  Thu Apr 14 08:55:47 2016
From: faisalusuf at yahoo.com (Muhammad Faisal)
Date: Thu, 14 Apr 2016 08:55:47 +0000
Subject: [squid-users] Squid 3.5 no traffic saving
In-Reply-To: <570F5ABC.3060105@treenet.co.nz>
Message-ID: <em20fbeee7-f51e-4c4a-89d2-5292478b0f81@augere-1>

okay Thanks Amos. Im compiling the latest snapshot 
squid-3.5.16-20160412-r14025 let see.
--
Regards,
Faisal.



------ Original Message ------
From: "Amos Jeffries" <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Sent: 4/14/2016 1:54:20 PM
Subject: Re: [squid-users] Squid 3.5 no traffic saving

>On 14/04/2016 7:51 p.m., Muhammad Faisal wrote:
>>  Hi Amos,
>>  The regression is fixed in the latest snapshot?
>
>The Vary regression is, yes.
>
>But I'm not clear on what your 'regression' was exactly. So you will
>have to test and see.
>
>Amos
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Apr 14 09:18:25 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Apr 2016 21:18:25 +1200
Subject: [squid-users] Dynamic/CDN Content Caching Challenges
In-Reply-To: <emf0252ebd-79a7-4524-8666-220414ca5ecf@augere-1>
References: <emf0252ebd-79a7-4524-8666-220414ca5ecf@augere-1>
Message-ID: <570F6061.7000100@treenet.co.nz>

On 14/04/2016 8:03 p.m., Muhammad Faisal wrote:
> Hi,
> I'm trying to deal with dynamic content to be cached by Squid 3.5 (i
> tried many other version of squid e.g 2.7, 3.1, 3.4). By Dynamic I mean
> the URL for the actual content is always change this results in the
> wastage of Cache storage and low hit rate. As per my understanding I
> have two challenges atm:
> 
> 1- Websites with dynamic URL for requested content (e.g filehippo,
> download.com etc etc)

If the URL is dynamicaly generated, the resource/content behind it may
be too and thus would fail to meet the uniqueness requirement of StoreID:
 That every *object* cached at a particular store ID MUST be identical
(either binary and/or semantically) regardless of the URL(s) mapped to
that ID.


> 2- Streaming web sites where the dynamic URL has 206 (partial content)
> tune.pk videos for e.g or windows updates (enabling range off set limit
> to -1 causes havoc on upstream to we kept it disable is there some way
> to control the behavior ?)

3- non-HTTP streaming. ICY and such like which are transferred over HTTP
proxies and supported by Squid but are not cacheable.

4- Dynamic sites where the content *actually* changes between two URLs
which you think are the same. Unless one has access to the server code
(ie open source CDN, or at minimum they published the mirroring URL
structure) it can be a lot of work to guarantee that any two URLs
matched by a regex pattern meet the uniqueness requirement of StoreID.

Solving #4 usually solves #1 on the way.


> 
> If someone has successfully configured the above scenario please help me
> out as i dont have programming background to deal with this complexity.

NP: You should not need programming know-how for this. Just "good" level
of regex experience and knowledge (mistakes are painful in this
particular situation). Plus ability+willingness to analyse the targeted
CDNs URL structure vs behaviour in a lot of detail (more systems
analysis skill than coding).


The Store-ID helper provided with Squid fed with the regex patterns in
the wiki "database" for some of the popular CDNs should give you some
savings. If only the popular jQuery ones.


> 
> I tried using different store-ID helpers but no saving on upstream the
> content is still coming from origin. Below is the helper i have used:

Your low success rate may be from the focus on http:// URLs. Most of the
majors CDNs you are listing in this helper are actually using https://
URLs for their content nowdays.

Amos



From faisalusuf at yahoo.com  Thu Apr 14 09:32:42 2016
From: faisalusuf at yahoo.com (Muhammad Faisal)
Date: Thu, 14 Apr 2016 09:32:42 +0000
Subject: [squid-users] Dynamic/CDN Content Caching Challenges
In-Reply-To: <570F6061.7000100@treenet.co.nz>
Message-ID: <ema60ded53-9c53-4d3c-830e-87f234a99878@augere-1>

Thanks Amos for a detailed response.
Well for Squid we are redirecting only HTTP traffic from policy routing. 
The object is unique which is being served to clients but due to 
different redirection of every user a new object is stored.

What about http streaming content having 206 response code how to deal 
with it? afaik squid dont cache 206 partial content. Is this correct?

e.g filehippo below is the sequence:

When I click download button there are two requests one 301 which 
contains (Location header for the requested content) and second 200:

301 Headers: ?

GET 
/download/file/6853a2c840eaefd1d7da43d6f2c94863adc5f470927402e6518d70573a99114d/ 
HTTP/1.1
Host: filehippo.com
Accept: 
text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Encoding: gzip, deflate, sdch
Accept-Language: en-US,en;q=0.8
Cookie: FHSession=mfzdaugt4nu11q3yfxfkjyox; 
FH_PreferredCulture=l=en-US&e=3/30/2017 1:38:22 PM; 
__utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148; 
__utma=144473122.1934842269.1459345103.1459345103.1459345103.1; 
__utmb=144473122.3.10.1459345119355; __utmc=144473122; 
__utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); 
__utmv=144473122.|1=AB%20Test=new-home-v1=1
Referer: 
http://filehippo.com/download_vlc_64/download/56a450f832aee6bb4fda3b01259f9866/
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 
(KHTML, like Gecko) Chrome/49.0.2623.87 Safari/537.36

HTTP/1.1 301 Moved Permanently
Accept-Ranges: bytes
Age: 0
Cache-Control: private
Connection: keep-alive
Content-Length: 0
Content-Type: text/html
Date: Wed, 30 Mar 2016 13:38:45 GMT
Location: 
http://fs37.filehippo.com/9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe
Via: 1.1 varnish
X-Cache: MISS
X-Cache-Hits: 0
x-debug-output: FHSession=mfzdaugt4nu11q3yfxfkjyox; 
FH_PreferredCulture=l=en-US&e=3/30/2017 1:38:22 PM; 
__utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148; 
__utma=144473122.1934842269.1459345103.1459345103.1459345103.1; 
__utmb=144473122.3.10.1459345119355; __utmc=144473122; 
__utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); 
__utmv=144473122.|1=AB%20Test=new-home-v1=1
X-Served-By: cache-lhr6334-LHR

200 Header: Why ATS is not caching octet stream despite having CONFIG 
proxy.config.http.cache.required_headers INT 1
GET /9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe HTTP/1.1
Host: fs37.filehippo.com
Accept: 
text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Encoding: gzip, deflate, sdch
Accept-Language: en-US,en;q=0.8
Cookie: __utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148; 
__utma=144473122.1934842269.1459345103.1459345103.1459345103.1; 
__utmb=144473122.3.10.1459345119355; __utmc=144473122; 
__utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); 
__utmv=144473122.|1=AB%20Test=new-home-v1=1
Referer: 
http://filehippo.com/download_vlc_64/download/56a450f832aee6bb4fda3b01259f9866/
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 
(KHTML, like Gecko) Chrome/49.0.2623.87 Safari/537.36

HTTP/1.1 200 OK
Accept-Ranges: bytes
Age: 739
Connection: keep-alive
Content-Length: 31367109
Content-Type: application/octet-stream
Date: Wed, 30 Mar 2016 13:26:43 GMT
ETag: "81341be3a62d11:0"
Last-Modified: Mon, 08 Feb 2016 06:34:21 GMT

--
Regards,
Faisal.



------ Original Message ------
From: "Amos Jeffries" <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Sent: 4/14/2016 2:18:25 PM
Subject: Re: [squid-users] Dynamic/CDN Content Caching Challenges

>On 14/04/2016 8:03 p.m., Muhammad Faisal wrote:
>>  Hi,
>>  I'm trying to deal with dynamic content to be cached by Squid 3.5 (i
>>  tried many other version of squid e.g 2.7, 3.1, 3.4). By Dynamic I 
>>mean
>>  the URL for the actual content is always change this results in the
>>  wastage of Cache storage and low hit rate. As per my understanding I
>>  have two challenges atm:
>>
>>  1- Websites with dynamic URL for requested content (e.g filehippo,
>>  download.com etc etc)
>
>If the URL is dynamicaly generated, the resource/content behind it may
>be too and thus would fail to meet the uniqueness requirement of 
>StoreID:
>  That every *object* cached at a particular store ID MUST be identical
>(either binary and/or semantically) regardless of the URL(s) mapped to
>that ID.
>
>
>>  2- Streaming web sites where the dynamic URL has 206 (partial 
>>content)
>>  tune.pk videos for e.g or windows updates (enabling range off set 
>>limit
>>  to -1 causes havoc on upstream to we kept it disable is there some 
>>way
>>  to control the behavior ?)
>
>3- non-HTTP streaming. ICY and such like which are transferred over 
>HTTP
>proxies and supported by Squid but are not cacheable.
>
>4- Dynamic sites where the content *actually* changes between two URLs
>which you think are the same. Unless one has access to the server code
>(ie open source CDN, or at minimum they published the mirroring URL
>structure) it can be a lot of work to guarantee that any two URLs
>matched by a regex pattern meet the uniqueness requirement of StoreID.
>
>Solving #4 usually solves #1 on the way.
>
>
>>
>>  If someone has successfully configured the above scenario please help 
>>me
>>  out as i dont have programming background to deal with this 
>>complexity.
>
>NP: You should not need programming know-how for this. Just "good" 
>level
>of regex experience and knowledge (mistakes are painful in this
>particular situation). Plus ability+willingness to analyse the targeted
>CDNs URL structure vs behaviour in a lot of detail (more systems
>analysis skill than coding).
>
>
>The Store-ID helper provided with Squid fed with the regex patterns in
>the wiki "database" for some of the popular CDNs should give you some
>savings. If only the popular jQuery ones.
>
>
>>
>>  I tried using different store-ID helpers but no saving on upstream 
>>the
>>  content is still coming from origin. Below is the helper i have used:
>
>Your low success rate may be from the focus on http:// URLs. Most of 
>the
>majors CDNs you are listing in this helper are actually using https://
>URLs for their content nowdays.
>
>Amos
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>http://lists.squid-cache.org/listinfo/squid-users



From faisalusuf at yahoo.com  Thu Apr 14 09:55:33 2016
From: faisalusuf at yahoo.com (Muhammad Faisal)
Date: Thu, 14 Apr 2016 09:55:33 +0000
Subject: [squid-users] Squid 3.5 no traffic saving
In-Reply-To: <570F5ABC.3060105@treenet.co.nz>
Message-ID: <em28dbda72-09a1-462f-b4e2-17c90d53955b@augere-1>

Hi,
im seeing the following in cache.log after upgrade:

Squid Cache: Version 3.5.16-20160412-r14025
2016/04/14 14:47:01 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://connect.facebook.net/en_US/sdk.js' 
'accept-encoding="gzip,%20deflate,%20sdch"'
2016/04/14 14:47:01 kid1| clientProcessHit: Vary object loop!

--
Regards,
Faisal.



------ Original Message ------
From: "Amos Jeffries" <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Sent: 4/14/2016 1:54:20 PM
Subject: Re: [squid-users] Squid 3.5 no traffic saving

>On 14/04/2016 7:51 p.m., Muhammad Faisal wrote:
>>  Hi Amos,
>>  The regression is fixed in the latest snapshot?
>
>The Vary regression is, yes.
>
>But I'm not clear on what your 'regression' was exactly. So you will
>have to test and see.
>
>Amos
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>http://lists.squid-cache.org/listinfo/squid-users



From talroz0 at gmail.com  Thu Apr 14 09:42:46 2016
From: talroz0 at gmail.com (rozi)
Date: Thu, 14 Apr 2016 02:42:46 -0700 (PDT)
Subject: [squid-users] splash page + ubuntu 14.04 + squid 3.3.8
In-Reply-To: <570F58C5.4080104@treenet.co.nz>
References: <1460610223055-4677076.post@n4.nabble.com>
 <570F58C5.4080104@treenet.co.nz>
Message-ID: <CAPHbOMUwjXKk9cRuuhEsTmKbORmRFkTPgx+TPxDbB-da8Q18rw@mail.gmail.com>

Thanks for the answer Amos...

2016-04-14 11:14 GMT+03:00 Amos Jeffries [via Squid Web Proxy Cache] <
ml-node+s1019090n4677079h32 at n4.nabble.com>:

> On 14/04/2016 5:03 p.m., rozi wrote:
>
> > Hi
> >
> > trying to set a splash page that popup once a day for the clients here
> is my
> > conf:
> >
> > external_acl_type splash_page concurrency=100 ttl=10 %SRC
> > /usr/lib/squid3/ext_session_acl -a -T 60 -b /home/e987654654/sessions.db
> > acl existing_users external splash_page
> > http_access deny !existing_users
> > deny_info 511:splash.html Mynetwork
> > deny_info 511:splash.html existing_users
> > http_access allow Mynetwork
> >
> >
> > cant get it to work , in this conf example after 60 sec i get conecction
> > refuse for 10 sec and the splash page dont popup during the 10 sec
> >
> > Anyone can help me ?
>
> You have two problems here:
>
> 1a) The -a parameter enables active mode sessions. Which means the
> 'existing_users' ACL (or another ACL matching an 'accept button' URL)
> has to pass "LOGIN" to the helper for sessions to exist.
>
> 1b) The ACL 'MyNetwork' is not used to deny anything, so the deny_info
> has nothing to do.
>
>
> 2) you do not seem to have any logic to identify when a particular
> request will be user-visible.
>  This is kind of important since modern browsers and OS perform a huge
> amount of automated requests in the background. Or even things with XHR
> scripts during user browsing.
> None of which the user will ever see in 'page' format, but which can
> screw up the system or web service behaviour of the recipient software.
> That 511 is the right way to do this, but is a fairly new feature in
> HTTP so a lot of software still dont handle it well.
>
> HTH
> Amos
>
> _______________________________________________
> squid-users mailing list
> [hidden email] <http:///user/SendEmail.jtp?type=node&node=4677079&i=0>
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
> If you reply to this email, your message will be added to the discussion
> below:
>
> http://squid-web-proxy-cache.1019090.n4.nabble.com/splash-page-ubuntu-14-04-squid-3-3-8-tp4677076p4677079.html
> To unsubscribe from splash page + ubuntu 14.04 + squid 3.3.8, click here
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4677076&code=dGFscm96MEBnbWFpbC5jb218NDY3NzA3NnwxOTAwNDc5MTI5>
> .
> NAML
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/splash-page-ubuntu-14-04-squid-3-3-8-tp4677076p4677085.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Thu Apr 14 10:59:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Apr 2016 22:59:14 +1200
Subject: [squid-users] Dynamic/CDN Content Caching Challenges
In-Reply-To: <ema60ded53-9c53-4d3c-830e-87f234a99878@augere-1>
References: <ema60ded53-9c53-4d3c-830e-87f234a99878@augere-1>
Message-ID: <570F7802.5050306@treenet.co.nz>

On 14/04/2016 9:32 p.m., Muhammad Faisal wrote:
> Thanks Amos for a detailed response.
> Well for Squid we are redirecting only HTTP traffic from policy routing.
> The object is unique which is being served to clients but due to
> different redirection of every user a new object is stored.
> 
> What about http streaming content having 206 response code how to deal
> with it? afaik squid dont cache 206 partial content. Is this correct?

Squid does not cache 206 from the server. But a HIT served by Squid can
be 206 status.

> 
> e.g filehippo below is the sequence:
> 
> When I click download button there are two requests one 301 which
> contains (Location header for the requested content) and second 200:
> 
> 301 Headers: ?
> 
> GET
> /download/file/6853a2c840eaefd1d7da43d6f2c94863adc5f470927402e6518d70573a99114d/
> HTTP/1.1
> Host: filehippo.com
> Accept:
> text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
> Accept-Encoding: gzip, deflate, sdch
> Accept-Language: en-US,en;q=0.8
> Cookie: FHSession=mfzdaugt4nu11q3yfxfkjyox;
> FH_PreferredCulture=l=en-US&e=3/30/2017 1:38:22 PM;
> __utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148;
> __utma=144473122.1934842269.1459345103.1459345103.1459345103.1;
> __utmb=144473122.3.10.1459345119355; __utmc=144473122;
> __utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none);
> __utmv=144473122.|1=AB%20Test=new-home-v1=1
> Referer:
> http://filehippo.com/download_vlc_64/download/56a450f832aee6bb4fda3b01259f9866/
> 
> Upgrade-Insecure-Requests: 1
> User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36
> (KHTML, like Gecko) Chrome/49.0.2623.87 Safari/537.36
> 
> HTTP/1.1 301 Moved Permanently
> Accept-Ranges: bytes
> Age: 0
> Cache-Control: private
> Connection: keep-alive
> Content-Length: 0
> Content-Type: text/html
> Date: Wed, 30 Mar 2016 13:38:45 GMT
> Location:
> http://fs37.filehippo.com/9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe
> 
> Via: 1.1 varnish
> X-Cache: MISS
> X-Cache-Hits: 0
> x-debug-output: FHSession=mfzdaugt4nu11q3yfxfkjyox;
> FH_PreferredCulture=l=en-US&e=3/30/2017 1:38:22 PM;
> __utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148;
> __utma=144473122.1934842269.1459345103.1459345103.1459345103.1;
> __utmb=144473122.3.10.1459345119355; __utmc=144473122;
> __utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none);
> __utmv=144473122.|1=AB%20Test=new-home-v1=1
> X-Served-By: cache-lhr6334-LHR
> 

Ew. Borked server. 302 may be old but there are situations (this being
one) where it actually is appropriate to respond with a temporary status.

It also seems to contain an amateur attempt at cache-optimization by
someone who does not understand what middleware does.


You could technically force this to cache. But its not worth it. Let the
site admin who made that yucky response deal with the 2x latency cost
they created. Better to Store-ID cache the thing its Location header is
pointing to.


> 200 Header: Why ATS is not caching octet stream despite having CONFIG
> proxy.config.http.cache.required_headers INT 1

Squid is not ATS. The 301 response above is CC:private so only the
receiving browser is allowed to cache it. What was the question?

> GET /9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe HTTP/1.1
> Host: fs37.filehippo.com

What do you know about the components of that URL...

* What does "9546" mean;
 - just a random number?
 - some form of customer-ID videolan have with Filehippo ?
 - some form of category ID that represents VLC software type etc?

* What does the long random looking hex number mean;
 - just a random visitor session ID?
 - the hash sum for the VLC binary being fetched?

... or something else?

try some manual requests with different values and see what happens to
the response. Pay particular attention to the ETag response header, its
size, and if you want to be paranoid take the SHA1 and MD5 hashes of the
response object when it looks like it should be identical.

Check your logs for patterns in the URLs and test in teh same ways the
other files you find people fetching.

If that checks out then you know what your Store-ID pattern can drop and
what needs to be kept.

This is the hard way, and a "lot of work" as I mentioned earlier. If you
want to help the community then please contribute back by putting your
findings into the wiki Store-ID database pages so all that work does not
go to waste.

> 
> HTTP/1.1 200 OK
> Accept-Ranges: bytes
> Age: 739
> Connection: keep-alive
> Content-Length: 31367109
> Content-Type: application/octet-stream
> Date: Wed, 30 Mar 2016 13:26:43 GMT
> ETag: "81341be3a62d11:0"
> Last-Modified: Mon, 08 Feb 2016 06:34:21 GMT
> 

Amos



From faisalusuf at yahoo.com  Thu Apr 14 11:21:16 2016
From: faisalusuf at yahoo.com (Muhammad Faisal)
Date: Thu, 14 Apr 2016 11:21:16 +0000
Subject: [squid-users] Dynamic/CDN Content Caching Challenges
In-Reply-To: <570F7802.5050306@treenet.co.nz>
Message-ID: <eme8c1c788-5add-4fc1-ac7f-9c88e050dfa4@augere-1>

Thanks i will keep grinding on other websites. Currently working on 
streaming videos to be served from Cache. I'm a bit confuse on cache hit 
reason why its miss is it because of 206 or some other reason:

TCP_MISS/206 3874196 GET 
http://cw002.foo.net/files/videos/2015/12/30/145148227265e28-360.mp4 - 
ORIGINAL_DST/a.b.c.d video/mp4

Im trying with the regexp with store-ID helper to be served from the 
cache and save it as single object because [cw002] could change and will 
result in a different object.

so my understanding with storeid helper to deal with those objects which 
are similar but originating from different hosts is correct?
http:\/\/(cws[0-9]+)\.foo.net\/files\/videos\/.*\/.*\/(.*\.mp4)

to store as http://cdn.foo.net/" . $1



--
Regards,
Faisal.



------ Original Message ------
From: "Amos Jeffries" <squid3 at treenet.co.nz>
To: "Muhammad Faisal" <faisalusuf at yahoo.com>; 
squid-users at lists.squid-cache.org
Sent: 4/14/2016 3:59:14 PM
Subject: Re: [squid-users] Dynamic/CDN Content Caching Challenges

>On 14/04/2016 9:32 p.m., Muhammad Faisal wrote:
>>  Thanks Amos for a detailed response.
>>  Well for Squid we are redirecting only HTTP traffic from policy 
>>routing.
>>  The object is unique which is being served to clients but due to
>>  different redirection of every user a new object is stored.
>>
>>  What about http streaming content having 206 response code how to 
>>deal
>>  with it? afaik squid dont cache 206 partial content. Is this correct?
>
>Squid does not cache 206 from the server. But a HIT served by Squid can
>be 206 status.
>
>>
>>  e.g filehippo below is the sequence:
>>
>>  When I click download button there are two requests one 301 which
>>  contains (Location header for the requested content) and second 200:
>>
>>  301 Headers: ?
>>
>>  GET
>>  
>>/download/file/6853a2c840eaefd1d7da43d6f2c94863adc5f470927402e6518d70573a99114d/
>>  HTTP/1.1
>>  Host: filehippo.com
>>  Accept:
>>  
>>text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
>>  Accept-Encoding: gzip, deflate, sdch
>>  Accept-Language: en-US,en;q=0.8
>>  Cookie: FHSession=mfzdaugt4nu11q3yfxfkjyox;
>>  FH_PreferredCulture=l=en-US&e=3/30/2017 1:38:22 PM;
>>  __utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148;
>>  __utma=144473122.1934842269.1459345103.1459345103.1459345103.1;
>>  __utmb=144473122.3.10.1459345119355; __utmc=144473122;
>>  
>>__utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none);
>>  __utmv=144473122.|1=AB%20Test=new-home-v1=1
>>  Referer:
>>  
>>http://filehippo.com/download_vlc_64/download/56a450f832aee6bb4fda3b01259f9866/
>>
>>  Upgrade-Insecure-Requests: 1
>>  User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36
>>  (KHTML, like Gecko) Chrome/49.0.2623.87 Safari/537.36
>>
>>  HTTP/1.1 301 Moved Permanently
>>  Accept-Ranges: bytes
>>  Age: 0
>>  Cache-Control: private
>>  Connection: keep-alive
>>  Content-Length: 0
>>  Content-Type: text/html
>>  Date: Wed, 30 Mar 2016 13:38:45 GMT
>>  Location:
>>  
>>http://fs37.filehippo.com/9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe
>>
>>  Via: 1.1 varnish
>>  X-Cache: MISS
>>  X-Cache-Hits: 0
>>  x-debug-output: FHSession=mfzdaugt4nu11q3yfxfkjyox;
>>  FH_PreferredCulture=l=en-US&e=3/30/2017 1:38:22 PM;
>>  __utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148;
>>  __utma=144473122.1934842269.1459345103.1459345103.1459345103.1;
>>  __utmb=144473122.3.10.1459345119355; __utmc=144473122;
>>  
>>__utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none);
>>  __utmv=144473122.|1=AB%20Test=new-home-v1=1
>>  X-Served-By: cache-lhr6334-LHR
>>
>
>Ew. Borked server. 302 may be old but there are situations (this being
>one) where it actually is appropriate to respond with a temporary 
>status.
>
>It also seems to contain an amateur attempt at cache-optimization by
>someone who does not understand what middleware does.
>
>
>You could technically force this to cache. But its not worth it. Let 
>the
>site admin who made that yucky response deal with the 2x latency cost
>they created. Better to Store-ID cache the thing its Location header is
>pointing to.
>
>
>>  200 Header: Why ATS is not caching octet stream despite having CONFIG
>>  proxy.config.http.cache.required_headers INT 1
>
>Squid is not ATS. The 301 response above is CC:private so only the
>receiving browser is allowed to cache it. What was the question?
>
>>  GET /9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe 
>>HTTP/1.1
>>  Host: fs37.filehippo.com
>
>What do you know about the components of that URL...
>
>* What does "9546" mean;
>  - just a random number?
>  - some form of customer-ID videolan have with Filehippo ?
>  - some form of category ID that represents VLC software type etc?
>
>* What does the long random looking hex number mean;
>  - just a random visitor session ID?
>  - the hash sum for the VLC binary being fetched?
>
>... or something else?
>
>try some manual requests with different values and see what happens to
>the response. Pay particular attention to the ETag response header, its
>size, and if you want to be paranoid take the SHA1 and MD5 hashes of 
>the
>response object when it looks like it should be identical.
>
>Check your logs for patterns in the URLs and test in teh same ways the
>other files you find people fetching.
>
>If that checks out then you know what your Store-ID pattern can drop 
>and
>what needs to be kept.
>
>This is the hard way, and a "lot of work" as I mentioned earlier. If 
>you
>want to help the community then please contribute back by putting your
>findings into the wiki Store-ID database pages so all that work does 
>not
>go to waste.
>
>>
>>  HTTP/1.1 200 OK
>>  Accept-Ranges: bytes
>>  Age: 739
>>  Connection: keep-alive
>>  Content-Length: 31367109
>>  Content-Type: application/octet-stream
>>  Date: Wed, 30 Mar 2016 13:26:43 GMT
>>  ETag: "81341be3a62d11:0"
>>  Last-Modified: Mon, 08 Feb 2016 06:34:21 GMT
>>
>
>Amos
>



From faisalusuf at yahoo.com  Thu Apr 14 13:18:46 2016
From: faisalusuf at yahoo.com (Muhammad Faisal)
Date: Thu, 14 Apr 2016 13:18:46 +0000
Subject: [squid-users] Dynamic/CDN Content Caching Challenges
In-Reply-To: <eme8c1c788-5add-4fc1-ac7f-9c88e050dfa4@augere-1>
Message-ID: <em7ddbe311-8922-45da-a409-21f2be3cdfc1@augere-1>

Hi Amos,
As you mentioned "Better to Store-ID cache the thing its Location header 
is pointing to." The problem is Location header has random strings in 
the URL that caused unique URL for the same object.
Location: 
http://fs37.filehippo.com/9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe

Random string in the URL "/9546/46cfd241f1da4ae9812f512f7b36643c"

I was trying to deal with this situation.

--
Regards,
Faisal.



------ Original Message ------
From: "Muhammad Faisal" <faisalusuf at yahoo.com>
To: "Amos Jeffries" <squid3 at treenet.co.nz>; 
squid-users at lists.squid-cache.org
Sent: 4/14/2016 4:21:16 PM
Subject: Re: [squid-users] Dynamic/CDN Content Caching Challenges

>Thanks i will keep grinding on other websites. Currently working on 
>streaming videos to be served from Cache. I'm a bit confuse on cache 
>hit reason why its miss is it because of 206 or some other reason:
>
>TCP_MISS/206 3874196 GET 
>http://cw002.foo.net/files/videos/2015/12/30/145148227265e28-360.mp4 - 
>ORIGINAL_DST/a.b.c.d video/mp4
>
>Im trying with the regexp with store-ID helper to be served from the 
>cache and save it as single object because [cw002] could change and 
>will result in a different object.
>
>so my understanding with storeid helper to deal with those objects 
>which are similar but originating from different hosts is correct?
>http:\/\/(cws[0-9]+)\.foo.net\/files\/videos\/.*\/.*\/(.*\.mp4)
>
>to store as http://cdn.foo.net/" . $1
>
>
>
>--
>Regards,
>Faisal.
>
>
>
>------ Original Message ------
>From: "Amos Jeffries" <squid3 at treenet.co.nz>
>To: "Muhammad Faisal" <faisalusuf at yahoo.com>; 
>squid-users at lists.squid-cache.org
>Sent: 4/14/2016 3:59:14 PM
>Subject: Re: [squid-users] Dynamic/CDN Content Caching Challenges
>
>>On 14/04/2016 9:32 p.m., Muhammad Faisal wrote:
>>>  Thanks Amos for a detailed response.
>>>  Well for Squid we are redirecting only HTTP traffic from policy 
>>>routing.
>>>  The object is unique which is being served to clients but due to
>>>  different redirection of every user a new object is stored.
>>>
>>>  What about http streaming content having 206 response code how to 
>>>deal
>>>  with it? afaik squid dont cache 206 partial content. Is this 
>>>correct?
>>
>>Squid does not cache 206 from the server. But a HIT served by Squid 
>>can
>>be 206 status.
>>
>>>
>>>  e.g filehippo below is the sequence:
>>>
>>>  When I click download button there are two requests one 301 which
>>>  contains (Location header for the requested content) and second 200:
>>>
>>>  301 Headers: ?
>>>
>>>  GET
>>>  
>>>/download/file/6853a2c840eaefd1d7da43d6f2c94863adc5f470927402e6518d70573a99114d/
>>>  HTTP/1.1
>>>  Host: filehippo.com
>>>  Accept:
>>>  
>>>text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
>>>  Accept-Encoding: gzip, deflate, sdch
>>>  Accept-Language: en-US,en;q=0.8
>>>  Cookie: FHSession=mfzdaugt4nu11q3yfxfkjyox;
>>>  FH_PreferredCulture=l=en-US&e=3/30/2017 1:38:22 PM;
>>>  __utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148;
>>>  __utma=144473122.1934842269.1459345103.1459345103.1459345103.1;
>>>  __utmb=144473122.3.10.1459345119355; __utmc=144473122;
>>>  
>>>__utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none);
>>>  __utmv=144473122.|1=AB%20Test=new-home-v1=1
>>>  Referer:
>>>  
>>>http://filehippo.com/download_vlc_64/download/56a450f832aee6bb4fda3b01259f9866/
>>>
>>>  Upgrade-Insecure-Requests: 1
>>>  User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36
>>>  (KHTML, like Gecko) Chrome/49.0.2623.87 Safari/537.36
>>>
>>>  HTTP/1.1 301 Moved Permanently
>>>  Accept-Ranges: bytes
>>>  Age: 0
>>>  Cache-Control: private
>>>  Connection: keep-alive
>>>  Content-Length: 0
>>>  Content-Type: text/html
>>>  Date: Wed, 30 Mar 2016 13:38:45 GMT
>>>  Location:
>>>  
>>>http://fs37.filehippo.com/9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe
>>>
>>>  Via: 1.1 varnish
>>>  X-Cache: MISS
>>>  X-Cache-Hits: 0
>>>  x-debug-output: FHSession=mfzdaugt4nu11q3yfxfkjyox;
>>>  FH_PreferredCulture=l=en-US&e=3/30/2017 1:38:22 PM;
>>>  __utmt_UA-5815250-1=1; __qca=P0-1359511593-1459345103148;
>>>  __utma=144473122.1934842269.1459345103.1459345103.1459345103.1;
>>>  __utmb=144473122.3.10.1459345119355; __utmc=144473122;
>>>  
>>>__utmz=144473122.1459345103.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none);
>>>  __utmv=144473122.|1=AB%20Test=new-home-v1=1
>>>  X-Served-By: cache-lhr6334-LHR
>>>
>>
>>Ew. Borked server. 302 may be old but there are situations (this being
>>one) where it actually is appropriate to respond with a temporary 
>>status.
>>
>>It also seems to contain an amateur attempt at cache-optimization by
>>someone who does not understand what middleware does.
>>
>>
>>You could technically force this to cache. But its not worth it. Let 
>>the
>>site admin who made that yucky response deal with the 2x latency cost
>>they created. Better to Store-ID cache the thing its Location header 
>>is
>>pointing to.
>>
>>
>>>  200 Header: Why ATS is not caching octet stream despite having 
>>>CONFIG
>>>  proxy.config.http.cache.required_headers INT 1
>>
>>Squid is not ATS. The 301 response above is CC:private so only the
>>receiving browser is allowed to cache it. What was the question?
>>
>>>  GET /9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe 
>>>HTTP/1.1
>>>  Host: fs37.filehippo.com
>>
>>What do you know about the components of that URL...
>>
>>* What does "9546" mean;
>>  - just a random number?
>>  - some form of customer-ID videolan have with Filehippo ?
>>  - some form of category ID that represents VLC software type etc?
>>
>>* What does the long random looking hex number mean;
>>  - just a random visitor session ID?
>>  - the hash sum for the VLC binary being fetched?
>>
>>... or something else?
>>
>>try some manual requests with different values and see what happens to
>>the response. Pay particular attention to the ETag response header, 
>>its
>>size, and if you want to be paranoid take the SHA1 and MD5 hashes of 
>>the
>>response object when it looks like it should be identical.
>>
>>Check your logs for patterns in the URLs and test in teh same ways the
>>other files you find people fetching.
>>
>>If that checks out then you know what your Store-ID pattern can drop 
>>and
>>what needs to be kept.
>>
>>This is the hard way, and a "lot of work" as I mentioned earlier. If 
>>you
>>want to help the community then please contribute back by putting your
>>findings into the wiki Store-ID database pages so all that work does 
>>not
>>go to waste.
>>
>>>
>>>  HTTP/1.1 200 OK
>>>  Accept-Ranges: bytes
>>>  Age: 739
>>>  Connection: keep-alive
>>>  Content-Length: 31367109
>>>  Content-Type: application/octet-stream
>>>  Date: Wed, 30 Mar 2016 13:26:43 GMT
>>>  ETag: "81341be3a62d11:0"
>>>  Last-Modified: Mon, 08 Feb 2016 06:34:21 GMT
>>>
>>
>>Amos
>>



From squid3 at treenet.co.nz  Thu Apr 14 13:48:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 15 Apr 2016 01:48:49 +1200
Subject: [squid-users] Dynamic/CDN Content Caching Challenges
In-Reply-To: <em7ddbe311-8922-45da-a409-21f2be3cdfc1@augere-1>
References: <em7ddbe311-8922-45da-a409-21f2be3cdfc1@augere-1>
Message-ID: <570F9FC1.50208@treenet.co.nz>

On 15/04/2016 1:18 a.m., Muhammad Faisal wrote:
> Hi Amos,
> As you mentioned "Better to Store-ID cache the thing its Location header
> is pointing to." The problem is Location header has random strings in
> the URL that caused unique URL for the same object.
> Location:
> http://fs37.filehippo.com/9546/46cfd241f1da4ae9812f512f7b36643c/vlc-2.2.2-win64.exe
> 
> 
> Random string in the URL "/9546/46cfd241f1da4ae9812f512f7b36643c"
> 
> I was trying to deal with this situation.

I think you are missing the point of Store-ID.

Store-ID helper is simply the process of removing such randomness from
the URL - to point all possible permutations of the URL(s) at one cache
slot (aka ID). De-duplication of duplicate cache objects - nothing more.

The Store-ID is a text string naming the cache slot where the object is
stored. It can be anything but is important that your custom ones not
accidentally match a real possible URL - the ".squid.internal" piece in
the helper output is used for that.


That long and sometimes difficult analysis I wrote about is needed to
ensure that it truely is randomness that can be dropped and does not
have any meaning that affects the object in the response. If you drop
something that is not actual randomness then you end up with wrong
client responses sometimes - usually nasty results.

Amos



From yvoinov at gmail.com  Thu Apr 14 14:38:06 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 14 Apr 2016 20:38:06 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570D5C81.2030900@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
Message-ID: <570FAB4E.1020108@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Any ideas?

Anybody?

13.04.16 2:37, Yuri Voinov ?????:
>
> I suggests the matter can be openssl not OS:
>
> root @ cthulhu /patch # openssl version -a
> OpenSSL 1.0.1s  1 Mar 2016
> built on: Tue Mar  1 15:42:26 2016
> platform: solaris64-x86_64-cc-sunw
> options:  bn(64,64) rc4(16x,int) des(ptr,cisc,16,int) idea(int)
blowfish(ptr)
> compiler: /opt/solarisstudio12.4/bin/cc -I. -I.. -I../include  -KPIC
-DOPENSSL_PIC -DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H
-DPK11_LIB_LOCATION="/usr/lib/64/libpkcs11.so" -DHAVE_ISSETUGID
-DAV_SPARC_FJAES=0 -xO3 -m64 -xstrconst -Xa -DL_ENDIAN
-DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5
-DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DMD5_ASM
-DAES_ASM -DVPAES_ASM -DBSAES_ASM -DWHIRLPOOL_ASM -DGHASH_ASM
> OPENSSLDIR: "/etc/opt/csw/ssl"
>
>
> 13.04.16 2:29, Yuri Voinov ?????:
>
>
>       > root @ cthulhu /patch # dig www.cloudflare.com
>
>
>
>       > ; <<>> DiG 9.6-ESV-R11-P4 <<>>
>       www.cloudflare.com
>
>       > ;; global options: +cmd
>
>       > ;; Got answer:
>
>       > ;; ->>HEADER<<- opcode: QUERY, status: NOERROR,
>       id: 32548
>
>       > ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0,
>       ADDITIONAL: 0
>
>
>
>       > ;; QUESTION SECTION:
>
>       > ;www.cloudflare.com.            IN      A
>
>
>
>       > ;; ANSWER SECTION:
>
>       > www.cloudflare.com.     86400   IN      A     
>       198.41.214.162
>
>       > www.cloudflare.com.     86400   IN      A     
>       198.41.215.162
>
>
>
>       > ;; Query time: 538 msec
>
>       > ;; SERVER: 127.0.0.1#53(127.0.0.1)
>
>       > ;; WHEN: Wed Apr 13 02:28:34 ALMT 2016
>
>       > ;; MSG SIZE  rcvd: 68
>
>
>
>       > root @ cthulhu /patch # uname -a
>
>       > SunOS cthulhu 5.10 Generic_150401-30 i86pc i386 i86pc Solaris
>
>
>
>       > But I think OS does not matter here.
>
>
>
>       > 13.04.16 2:02, Eliezer Croitoru ?????:
>
>       > > What "dig www.cloudflare.com"
>
>       >       results with?
>
>
>
>       >       > Also what OS are you using? I am using CentOS 7 up
>       to date...
>
>
>
>
>
>
>
>       >       > Eliezer
>
>
>
>
>
>
>
>       >       > On 12/04/2016 21:39, Yuri Voinov wrote:
>
>
>
>       >       >> root @ cthulhu /patch # openssl s_client
>       -cipher
>
>       >       'ECDHE-ECDSA-AES128-GCM-SHA256' -connect
>       www.cloudflare.com:443
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       > squid-users at lists.squid-cache.org
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXD6tOAAoJENNXIZxhPexGlRgIAI96ykwrDgOIzbTZoK9A3QyB
dZ3VcTRKMR9L0zZj7tu9lg8UoRBzKDMiETaIH2yiykaLw7V0leR0dK/8UkrZmNxw
XuiaKD0+zVPf1WlyG8BOilI67Y9wlzMaN4Q35niHseg5GGn1kSH90dz2TAjq3Vum
e5nV74J/bHJfuauOv4YQfA5uJ0m5nhOuYYViKqi+S0y/1nrpZEINhYaRZ5AKbDML
1zNQip16yFCPBd/g7HviKSmUliV2OE6byF4xWsaYWjoX9bCAXxIVhVs4ln4BHO6q
t3h85zGlI5MCmxMqkSa8D5XvTdJPUE9yyxMYeTfXq5ncBEQYJacgfisZxDwFr7U=
=bje3
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160414/040ba731/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160414/040ba731/attachment.key>

From yvoinov at gmail.com  Thu Apr 14 18:31:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 15 Apr 2016 00:31:43 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570FAB4E.1020108@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com>
Message-ID: <570FE20F.5080704@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Ok, nobody.

Well.

I've done my own research.

My suggestions:

CloudFlare now uses it's own custom OpenSSL 1.0.2 with very custom
patches with CHACHA Poly support.

This patches is not in upstream. Moreover, OpenSSL team no plans in the
foreseeable future to support the latest ciphers.

So, Squid 4 can't handshake TLS with CF right now. Possible it is Squid
4.x branch bug. Because of 3.5.x does CF handshake.

LibreSSL does CHACHA right now.

The question is:

Amos, does Squid can support LibreSSL and, if no, when you plan to support?

14.04.16 20:38, Yuri Voinov ?????:
>
> Any ideas?
>
> Anybody?
>
> 13.04.16 2:37, Yuri Voinov ?????:
>
>
>       > I suggests the matter can be openssl not OS:
>
>
>
>       > root @ cthulhu /patch # openssl version -a
>
>       > OpenSSL 1.0.1s  1 Mar 2016
>
>       > built on: Tue Mar  1 15:42:26 2016
>
>       > platform: solaris64-x86_64-cc-sunw
>
>       > options:  bn(64,64) rc4(16x,int) des(ptr,cisc,16,int)
>       idea(int) blowfish(ptr)
>
>       > compiler: /opt/solarisstudio12.4/bin/cc -I. -I..
>       -I../include  -KPIC -DOPENSSL_PIC -DOPENSSL_THREADS -D_REENTRANT
>       -DDSO_DLFCN -DHAVE_DLFCN_H
>       -DPK11_LIB_LOCATION="/usr/lib/64/libpkcs11.so" -DHAVE_ISSETUGID
>       -DAV_SPARC_FJAES=0 -xO3 -m64 -xstrconst -Xa -DL_ENDIAN
>       -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5
>       -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM
>       -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM -DWHIRLPOOL_ASM
>       -DGHASH_ASM
>
>       > OPENSSLDIR: "/etc/opt/csw/ssl"
>
>
>
>
>
>       > 13.04.16 2:29, Yuri Voinov ?????:
>
>
>
>
>
>       >       > root @ cthulhu /patch # dig www.cloudflare.com
>
>
>
>
>
>
>
>       >       > ; <<>> DiG 9.6-ESV-R11-P4
>       <<>>
>
>       >       www.cloudflare.com
>
>
>
>       >       > ;; global options: +cmd
>
>
>
>       >       > ;; Got answer:
>
>
>
>       >       > ;; ->>HEADER<<- opcode: QUERY, status:
>       NOERROR,
>
>       >       id: 32548
>
>
>
>       >       > ;; flags: qr rd ra; QUERY: 1, ANSWER: 2,
>       AUTHORITY: 0,
>
>       >       ADDITIONAL: 0
>
>
>
>
>
>
>
>       >       > ;; QUESTION SECTION:
>
>
>
>       >       > ;www.cloudflare.com.            IN      A
>
>
>
>
>
>
>
>       >       > ;; ANSWER SECTION:
>
>
>
>       >       > www.cloudflare.com.     86400   IN      A     
>
>       >       198.41.214.162
>
>
>
>       >       > www.cloudflare.com.     86400   IN      A     
>
>       >       198.41.215.162
>
>
>
>
>
>
>
>       >       > ;; Query time: 538 msec
>
>
>
>       >       > ;; SERVER: 127.0.0.1#53(127.0.0.1)
>
>
>
>       >       > ;; WHEN: Wed Apr 13 02:28:34 ALMT 2016
>
>
>
>       >       > ;; MSG SIZE  rcvd: 68
>
>
>
>
>
>
>
>       >       > root @ cthulhu /patch # uname -a
>
>
>
>       >       > SunOS cthulhu 5.10 Generic_150401-30 i86pc i386
>       i86pc Solaris
>
>
>
>
>
>
>
>       >       > But I think OS does not matter here.
>
>
>
>
>
>
>
>       >       > 13.04.16 2:02, Eliezer Croitoru ?????:
>
>
>
>       >       > > What "dig www.cloudflare.com"
>
>
>
>       >       >       results with?
>
>
>
>
>
>
>
>       >       >       > Also what OS are you using? I am using
>       CentOS 7 up
>
>       >       to date...
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Eliezer
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > On 12/04/2016 21:39, Yuri Voinov wrote:
>
>
>
>
>
>
>
>       >       >       >> root @ cthulhu /patch # openssl
>       s_client
>
>       >       -cipher
>
>
>
>       >       >       'ECDHE-ECDSA-AES128-GCM-SHA256' -connect
>
>       >       www.cloudflare.com:443
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >
>       _______________________________________________
>
>
>
>
>
>
>
>       >       >       > squid-users mailing list
>
>
>
>
>
>
>
>       >       >       > squid-users at lists.squid-cache.org
>
>
>
>
>
>
>
>       >       >       >
>       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXD+IPAAoJENNXIZxhPexGhe4IAIdg3PLM/s5YxkP822HNwDA2
fbHLf9XcWe6koYNMMuHJ1NgN4thr5KtXEuQZBTno5TYFlce9P8PaXnnZCPD/xOjM
Bs+J705QG5tqDy5d7EYk606wiefXa8IuifLY0gQnZYjz0pM+CneJw8zVK47VrRwl
jUr/aohgAXuGfUcFMQyX/Jxc/mHHOdC2Pyd1R0qkw93r5LbppDQ5vuS/Hm2clTtt
bSIjFcPv7Ug+kNYp47g6WIoYjbBK7BPpWoolJMIf9p0sF7Scq7RCo30aViWBOcKh
TjVjZdwwTypW0tyLb89D2OKc1ieDVSk6HKcL+Ed1V0TMg2AakXmkXurRR73WP+o=
=umi3
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/d3ea5f78/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/d3ea5f78/attachment.key>

From yvoinov at gmail.com  Thu Apr 14 18:40:10 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 15 Apr 2016 00:40:10 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570FE20F.5080704@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
Message-ID: <570FE40A.8010607@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Finally.

1. Squid 4 can be built with LibreSSL.
2. Squid 4 with LibreSSL start supporting CHACHA20_POLY1305 cryptography.
3. Squid 4 with LibreSSL still can't connect with CloudFlare itself.

WBR, Yuri.

PS. I suggests bug in 4.x branch specific for CF handshake.

15.04.16 0:31, Yuri Voinov ?????:
>
> Ok, nobody.
>
> Well.
>
> I've done my own research.
>
> My suggestions:
>
> CloudFlare now uses it's own custom OpenSSL 1.0.2 with very custom
patches with CHACHA Poly support.
>
> This patches is not in upstream. Moreover, OpenSSL team no plans in
the foreseeable future to support the latest ciphers.
>
> So, Squid 4 can't handshake TLS with CF right now. Possible it is
Squid 4.x branch bug. Because of 3.5.x does CF handshake.
>
> LibreSSL does CHACHA right now.
>
> The question is:
>
> Amos, does Squid can support LibreSSL and, if no, when you plan to
support?
>
> 14.04.16 20:38, Yuri Voinov ?????:
>
>
>       > Any ideas?
>
>
>
>       > Anybody?
>
>
>
>       > 13.04.16 2:37, Yuri Voinov ?????:
>
>
>
>
>
>       >       > I suggests the matter can be openssl not OS:
>
>
>
>
>
>
>
>       >       > root @ cthulhu /patch # openssl version -a
>
>
>
>       >       > OpenSSL 1.0.1s  1 Mar 2016
>
>
>
>       >       > built on: Tue Mar  1 15:42:26 2016
>
>
>
>       >       > platform: solaris64-x86_64-cc-sunw
>
>
>
>       >       > options:  bn(64,64) rc4(16x,int)
>       des(ptr,cisc,16,int)
>
>       >       idea(int) blowfish(ptr)
>
>
>
>       >       > compiler: /opt/solarisstudio12.4/bin/cc -I. -I..
>
>       >       -I../include  -KPIC -DOPENSSL_PIC -DOPENSSL_THREADS
>       -D_REENTRANT
>
>       >       -DDSO_DLFCN -DHAVE_DLFCN_H
>
>       >       -DPK11_LIB_LOCATION="/usr/lib/64/libpkcs11.so"
>       -DHAVE_ISSETUGID
>
>       >       -DAV_SPARC_FJAES=0 -xO3 -m64 -xstrconst -Xa -DL_ENDIAN
>
>       >       -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT
>       -DOPENSSL_BN_ASM_MONT5
>
>       >       -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM
>       -DSHA512_ASM
>
>       >       -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM
>       -DWHIRLPOOL_ASM
>
>       >       -DGHASH_ASM
>
>
>
>       >       > OPENSSLDIR: "/etc/opt/csw/ssl"
>
>
>
>
>
>
>
>
>
>
>
>       >       > 13.04.16 2:29, Yuri Voinov ?????:
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > root @ cthulhu /patch # dig
>       www.cloudflare.com
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > ; <<>> DiG 9.6-ESV-R11-P4
>
>       >       <<>>
>
>
>
>       >       >       www.cloudflare.com
>
>
>
>
>
>
>
>       >       >       > ;; global options: +cmd
>
>
>
>
>
>
>
>       >       >       > ;; Got answer:
>
>
>
>
>
>
>
>       >       >       > ;; ->>HEADER<<- opcode:
>       QUERY, status:
>
>       >       NOERROR,
>
>
>
>       >       >       id: 32548
>
>
>
>
>
>
>
>       >       >       > ;; flags: qr rd ra; QUERY: 1, ANSWER:
>       2,
>
>       >       AUTHORITY: 0,
>
>
>
>       >       >       ADDITIONAL: 0
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > ;; QUESTION SECTION:
>
>
>
>
>
>
>
>       >       >       > ;www.cloudflare.com.            IN    
>       A
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > ;; ANSWER SECTION:
>
>
>
>
>
>
>
>       >       >       > www.cloudflare.com.     86400   IN    
>       A     
>
>
>
>       >       >       198.41.214.162
>
>
>
>
>
>
>
>       >       >       > www.cloudflare.com.     86400   IN    
>       A     
>
>
>
>       >       >       198.41.215.162
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > ;; Query time: 538 msec
>
>
>
>
>
>
>
>       >       >       > ;; SERVER: 127.0.0.1#53(127.0.0.1)
>
>
>
>
>
>
>
>       >       >       > ;; WHEN: Wed Apr 13 02:28:34 ALMT 2016
>
>
>
>
>
>
>
>       >       >       > ;; MSG SIZE  rcvd: 68
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > root @ cthulhu /patch # uname -a
>
>
>
>
>
>
>
>       >       >       > SunOS cthulhu 5.10 Generic_150401-30
>       i86pc i386
>
>       >       i86pc Solaris
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > But I think OS does not matter here.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > 13.04.16 2:02, Eliezer Croitoru ?????:
>
>
>
>
>
>
>
>       >       >       > > What "dig www.cloudflare.com"
>
>
>
>
>
>
>
>       >       >       >       results with?
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > Also what OS are you using?
>       I am using
>
>       >       CentOS 7 up
>
>
>
>       >       >       to date...
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > Eliezer
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > On 12/04/2016 21:39, Yuri
>       Voinov wrote:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >> root @ cthulhu /patch #
>       openssl
>
>       >       s_client
>
>
>
>       >       >       -cipher
>
>
>
>
>
>
>
>       >       >       >       'ECDHE-ECDSA-AES128-GCM-SHA256'
>       -connect
>
>
>
>       >       >       www.cloudflare.com:443
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >
>
>       >       _______________________________________________
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > squid-users mailing list
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >
>       squid-users at lists.squid-cache.org
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >
>
>       >       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXD+QJAAoJENNXIZxhPexGi2UIALGs33SbczbZwpi9DT9gVSzl
j7vU7+0AfyUJCu+m8BOF/rHUdxV+7a3zInIe9ujjoS6zurddjuLiUcIfA3wkIaZp
LwAz3vVZHCixRuUAjvrlilbesdf3a5iHcQt/7H195/R4iZTV/bEHzfWaR7Z6Aq4e
HajrLkPPjGaKTGr0hzrkUoBAFwC5e+VD0tiXxZxy8hNfLqKyKPrsgWfUbjiMV7Wp
41K6hACb8NO5sYob5k79n7+ksbhx7+p4lJMLIIWbzZm4/uBje248yCWzYnFZxeq1
yva0nteVe8WUxIO+eTKoHwKG0g8ZO1OSsET+1LUTiMKV00YX1/dRne67X/6UgAA=
=ja0u
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/170ed35c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/170ed35c/attachment.key>

From yvoinov at gmail.com  Thu Apr 14 20:21:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 15 Apr 2016 02:21:50 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570FE40A.8010607@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <570FE40A.8010607@gmail.com>
Message-ID: <570FFBDE.4010704@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Strange:

connect directly from server via wget using proxy is works:

root @ cthulhu /tmp # wget -S https://cloudflare.com
- --2016-04-15 02:19:41--  https://cloudflare.com/
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 302 Moved Temporarily
  Server: cloudflare-nginx
  Date: Thu, 14 Apr 2016 20:19:41 GMT
  Transfer-Encoding: chunked
  Connection: keep-alive
  Set-Cookie: __cfduid=dfeddf543b09766778140e887d88543c71460665181;
expires=Fri, 14-Apr-17 20:19:41 GMT; path=/; domain=.cloudflare.com;
HttpOnly
  Cache-Control: private, max-age=0, no-store, no-cache,
must-revalidate, post-check=0, pre-check=0
  Expires: Thu, 01 Jan 1970 00:00:01 GMT
  Location: https://www.cloudflare.com/
  CF-RAY: 2939daab044b2654-FRA
Location: https://www.cloudflare.com/ [following]
- --2016-04-15 02:19:41--  https://www.cloudflare.com/
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 200 OK
  Server: cloudflare-nginx
  Date: Thu, 14 Apr 2016 20:19:42 GMT
  Content-Type: text/html
  Transfer-Encoding: chunked
  Connection: keep-alive
  Last-Modified: Thu, 14 Apr 2016 19:46:02 GMT
  Strict-Transport-Security: max-age=31536000
  X-Content-Type-Options: nosniff
  X-Frame-Options: SAMEORIGIN
  Content-Security-Policy: default-src 'self' https://*; script-src
'self' 'unsafe-inline' 'unsafe-eval' https://* data:; img-src 'self'
https://* data:; style-src 'self' 'unsafe-inline' https://*; font-src
'self' https://* data:; frame-src https://*; connect-src 'self' data:
https://*
  X-XSS-Protection: 1; mode=block
  CF-Cache-Status: HIT
  Vary: Accept-Encoding
  Expires: Fri, 15 Apr 2016 00:19:42 GMT
  Cache-Control: public, max-age=14400
  CF-RAY: 2939daae503c0f75-FRA
Length: unspecified [text/html]
Saving to: 'index.html.1'

index.html.1            [ <=>                  ]  15.23K  --.-KB/s   in
0.1s  

2016-04-15 02:19:42 (121 KB/s) - 'index.html.1' saved [15597]

But clients behind proxy can't handshake.



15.04.16 0:40, Yuri Voinov ?????:
>
> Finally.
>
> 1. Squid 4 can be built with LibreSSL.
> 2. Squid 4 with LibreSSL start supporting CHACHA20_POLY1305 cryptography.
> 3. Squid 4 with LibreSSL still can't connect with CloudFlare itself.
>
> WBR, Yuri.
>
> PS. I suggests bug in 4.x branch specific for CF handshake.
>
> 15.04.16 0:31, Yuri Voinov ?????:
>
>
>       > Ok, nobody.
>
>
>
>       > Well.
>
>
>
>       > I've done my own research.
>
>
>
>       > My suggestions:
>
>
>
>       > CloudFlare now uses it's own custom OpenSSL 1.0.2 with very
>       custom patches with CHACHA Poly support.
>
>
>
>       > This patches is not in upstream. Moreover, OpenSSL team no
>       plans in the foreseeable future to support the latest ciphers.
>
>
>
>       > So, Squid 4 can't handshake TLS with CF right now. Possible
>       it is Squid 4.x branch bug. Because of 3.5.x does CF handshake.
>
>
>
>       > LibreSSL does CHACHA right now.
>
>
>
>       > The question is:
>
>
>
>       > Amos, does Squid can support LibreSSL and, if no, when you
>       plan to support?
>
>
>
>       > 14.04.16 20:38, Yuri Voinov ?????:
>
>
>
>
>
>       >       > Any ideas?
>
>
>
>
>
>
>
>       >       > Anybody?
>
>
>
>
>
>
>
>       >       > 13.04.16 2:37, Yuri Voinov ?????:
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > I suggests the matter can be openssl
>       not OS:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > root @ cthulhu /patch # openssl version
>       -a
>
>
>
>
>
>
>
>       >       >       > OpenSSL 1.0.1s  1 Mar 2016
>
>
>
>
>
>
>
>       >       >       > built on: Tue Mar  1 15:42:26 2016
>
>
>
>
>
>
>
>       >       >       > platform: solaris64-x86_64-cc-sunw
>
>
>
>
>
>
>
>       >       >       > options:  bn(64,64) rc4(16x,int)
>
>       >       des(ptr,cisc,16,int)
>
>
>
>       >       >       idea(int) blowfish(ptr)
>
>
>
>
>
>
>
>       >       >       > compiler: /opt/solarisstudio12.4/bin/cc
>       -I. -I..
>
>
>
>       >       >       -I../include  -KPIC -DOPENSSL_PIC
>       -DOPENSSL_THREADS
>
>       >       -D_REENTRANT
>
>
>
>       >       >       -DDSO_DLFCN -DHAVE_DLFCN_H
>
>
>
>       >       >     
>       -DPK11_LIB_LOCATION="/usr/lib/64/libpkcs11.so"
>
>       >       -DHAVE_ISSETUGID
>
>
>
>       >       >       -DAV_SPARC_FJAES=0 -xO3 -m64 -xstrconst -Xa
>       -DL_ENDIAN
>
>
>
>       >       >       -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT
>
>       >       -DOPENSSL_BN_ASM_MONT5
>
>
>
>       >       >       -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM
>       -DSHA256_ASM
>
>       >       -DSHA512_ASM
>
>
>
>       >       >       -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM
>
>       >       -DWHIRLPOOL_ASM
>
>
>
>       >       >       -DGHASH_ASM
>
>
>
>
>
>
>
>       >       >       > OPENSSLDIR: "/etc/opt/csw/ssl"
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > 13.04.16 2:29, Yuri Voinov ?????:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > root @ cthulhu /patch # dig
>
>       >       www.cloudflare.com
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ; <<>> DiG
>       9.6-ESV-R11-P4
>
>
>
>       >       >       <<>>
>
>
>
>
>
>
>
>       >       >       >       www.cloudflare.com
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; global options: +cmd
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; Got answer:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; ->>HEADER<<-
>       opcode:
>
>       >       QUERY, status:
>
>
>
>       >       >       NOERROR,
>
>
>
>
>
>
>
>       >       >       >       id: 32548
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; flags: qr rd ra; QUERY:
>       1, ANSWER:
>
>       >       2,
>
>
>
>       >       >       AUTHORITY: 0,
>
>
>
>
>
>
>
>       >       >       >       ADDITIONAL: 0
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; QUESTION SECTION:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >
>       ;www.cloudflare.com.            IN    
>
>       >       A
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; ANSWER SECTION:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > www.cloudflare.com.   
>       86400   IN    
>
>       >       A     
>
>
>
>
>
>
>
>       >       >       >       198.41.214.162
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > www.cloudflare.com.   
>       86400   IN    
>
>       >       A     
>
>
>
>
>
>
>
>       >       >       >       198.41.215.162
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; Query time: 538 msec
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; SERVER:
>       127.0.0.1#53(127.0.0.1)
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; WHEN: Wed Apr 13 02:28:34
>       ALMT 2016
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ;; MSG SIZE  rcvd: 68
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > root @ cthulhu /patch #
>       uname -a
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > SunOS cthulhu 5.10
>       Generic_150401-30
>
>       >       i86pc i386
>
>
>
>       >       >       i86pc Solaris
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > But I think OS does not
>       matter here.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > 13.04.16 2:02, Eliezer
>       Croitoru ?????:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > > What "dig
>       www.cloudflare.com"
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       results with?
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       > Also what OS are
>       you using?
>
>       >       I am using
>
>
>
>       >       >       CentOS 7 up
>
>
>
>
>
>
>
>       >       >       >       to date...
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       > Eliezer
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       > On 12/04/2016
>       21:39, Yuri
>
>       >       Voinov wrote:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       >> root @
>       cthulhu /patch #
>
>       >       openssl
>
>
>
>       >       >       s_client
>
>
>
>
>
>
>
>       >       >       >       -cipher
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >     
>       'ECDHE-ECDSA-AES128-GCM-SHA256'
>
>       >       -connect
>
>
>
>
>
>
>
>       >       >       >       www.cloudflare.com:443
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       >
>
>
>
>       >       >     
>       _______________________________________________
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       > squid-users
>       mailing list
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       >
>
>       >       squid-users at lists.squid-cache.org
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >       >
>
>
>
>       >       >     
>       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXD/vdAAoJENNXIZxhPexGHUgIALjkentpBtLulIyNbIlxtLLq
t5YHwsOUP9ZDEA8AieD1HN3DXkno3JFwxGxQ1G5hL/wkbKP685NnmJ+LQeYoEhDC
tyqMQjx1aZfPm0dHv4IpiNrCYw2ViP3lArKp1g36Q6aD6pE98hciOhTkBvgu50b6
yRZGPWV7fHySXjRW+3SuoeLoZ/J7R4sA0MRh9iBpU2HkrQDSrdT70jXMogWDyqey
+/SEGpCBmB8RbvKpL5tJLPqcv9lSa9TRTWSyg1JpKAJHC3w/5dPTgiaE3vcRMiGI
rkd1cpz81PkEb4v5ndTs67watmidy+DB6Xs5LUZV5gq2zOHElXIOXn1rFUPrdNs=
=gN9e
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/73fb6fcb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/73fb6fcb/attachment.key>

From michael.pelletier at palmbeachschools.org  Fri Apr 15 04:04:27 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Fri, 15 Apr 2016 00:04:27 -0400
Subject: [squid-users] grove.microsoft.com
Message-ID: <CAEnCSG61daOnfWZ6ekp-iQHr9STt5bSNijFb+r2U9Wf1o6rZYQ@mail.gmail.com>

I am blocking grove.microsoft.com. Even though I am blocking it, I am
seeing large, 2 Gig, uploads from the client to the proxy (which indeed
blocks it). It is almost like the connection request (explicit) contains
the 2 gig post request. Why is this happening? Has anyone seen this?


Michael

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/6f497844/attachment.htm>

From jason_haar at trimble.com  Fri Apr 15 04:57:39 2016
From: jason_haar at trimble.com (Jason Haar)
Date: Fri, 15 Apr 2016 16:57:39 +1200
Subject: [squid-users] grove.microsoft.com
In-Reply-To: <CAEnCSG61daOnfWZ6ekp-iQHr9STt5bSNijFb+r2U9Wf1o6rZYQ@mail.gmail.com>
References: <CAEnCSG61daOnfWZ6ekp-iQHr9STt5bSNijFb+r2U9Wf1o6rZYQ@mail.gmail.com>
Message-ID: <CAFChrgLCzhxsKuyT-sRoSRAFOm+eOncJzvGL36tpxJ46UeDDZw@mail.gmail.com>

If you are blocking it, then it can't be uploading 2G? How are you
measuring that it uploads 2G? Did you change squid's logging to support
that (it doesn't log upload sizes - only download sizes by default). Are
you simply referring to the Content-Length header - as that would say 2G -
even if the upload is then blocked.

On Fri, Apr 15, 2016 at 4:04 PM, Michael Pelletier <
michael.pelletier at palmbeachschools.org> wrote:

> I am blocking grove.microsoft.com. Even though I am blocking it, I am
> seeing large, 2 Gig, uploads from the client to the proxy (which indeed
> blocks it). It is almost like the connection request (explicit) contains
> the 2 gig post request. Why is this happening? Has anyone seen this?
>
>
> Michael
>
> *Disclaimer: *Under Florida law, e-mail addresses are public records. If
> you do not want your e-mail address released in response to a public
> records request, do not send electronic mail to this entity. Instead,
> contact this office by phone or in writing.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


-- 
Cheers

Jason Haar
Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/d3926fc1/attachment.htm>

From stefand at korbitec.com  Fri Apr 15 05:35:53 2016
From: stefand at korbitec.com (stefand at korbitec.com)
Date: Fri, 15 Apr 2016 05:35:53 +0000
Subject: [squid-users] Access log to syslog
Message-ID: <58D17FFEF248BA4997C61EA1775AC69E0FAC222B@CPTISNMAIL02>

I'm trying to log multiple ACLs to syslog using squid 3.3.8 on CentOS 7

When I add the line :

access_log syslog:local4.info squid ACL1 ACL2 ACL3

Nothing gets logged to syslog

However when I change the line to :

access_log syslog:local4.info squid ACL1

It logs correctly, but just for ACL1 (as expected)

Should I then rather have the configuration file with the following lines:

access_log syslog:local4.info squid ACL1
access_log syslog:local4.info squid ACL2
access_log syslog:local4.info squid ACL3

Doesn't make sense to me as the documentation states (http://www.squid-cache.org/Versions/v3/3.3/cfgman/access_log.html) :

access_log <module>:<place> [<logformat name> [acl acl ...]]


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/cda48de2/attachment.htm>

From ms.nasiri at gmail.com  Fri Apr 15 07:26:23 2016
From: ms.nasiri at gmail.com (Mohammad Sadegh Nasiri)
Date: Fri, 15 Apr 2016 11:56:23 +0430
Subject: [squid-users] High CPU usage
Message-ID: <CAL1kE9DAt=VBphGKywsE4-Yzy9pM2N5Ej_BwdJmh0C5LzzEm3Q@mail.gmail.com>

Hi

Does anyone knows why my squid cpu usage is 100%?

When it works fine:
Last 5 minutes:
sample_start_time = 1460357653.263150 (Mon, 11 Apr 2016 06:54:13 GMT)
sample_end_time = 1460357953.264761 (Mon, 11 Apr 2016 06:59:13 GMT)
client_http.requests = 1149.670493/sec
client_http.hits = 357.521413/sec
client_http.errors = 3.199983/sec
client_http.kbytes_in = 840.588819/sec
client_http.kbytes_out = 57427.721613/sec
client_http.all_median_svc_time = 0.150482 seconds
client_http.miss_median_svc_time = 0.288533 seconds
client_http.nm_median_svc_time = 0.000000 seconds
client_http.nh_median_svc_time = 0.108570 seconds
client_http.hit_median_svc_time = 0.000000 seconds
server.all.requests = 778.229154/sec
server.all.errors = 0.000000/sec
server.all.kbytes_in = 43018.655656/sec
server.all.kbytes_out = 705.229546/sec
server.http.requests = 773.162515/sec
server.http.errors = 0.000000/sec
server.http.kbytes_in = 42988.509152/sec
server.http.kbytes_out = 701.642899/sec
server.ftp.requests = 0.000000/sec
server.ftp.errors = 0.000000/sec
server.ftp.kbytes_in = 0.000000/sec
server.ftp.kbytes_out = 0.000000/sec
server.other.requests = 5.066639/sec
server.other.errors = 0.000000/sec
server.other.kbytes_in = 30.149838/sec
server.other.kbytes_out = 3.586647/sec
icp.pkts_sent = 0.000000/sec
icp.pkts_recv = 0.000000/sec
icp.queries_sent = 0.000000/sec
icp.replies_sent = 0.000000/sec
icp.queries_recv = 0.000000/sec
icp.replies_recv = 0.000000/sec
icp.replies_queued = 0.000000/sec
icp.query_timeouts = 0.000000/sec
icp.kbytes_sent = 0.000000/sec
icp.kbytes_recv = 0.000000/sec
icp.q_kbytes_sent = 0.000000/sec
icp.r_kbytes_sent = 0.000000/sec
icp.q_kbytes_recv = 0.000000/sec
icp.r_kbytes_recv = 0.000000/sec
icp.query_median_svc_time = 0.000000 seconds
icp.reply_median_svc_time = 0.000000 seconds
dns.median_svc_time = 0.000945 seconds
unlink.requests = 0.000000/sec
page_faults = 0.000000/sec
select_loops = 14570.791755/sec
select_fds = 27229.437111/se
average_select_fd_period = 0.000037/fd
median_select_fds = 0.000000
swap.outs = 309.515005/sec
swap.ins = 593.013482/sec
swap.files_cleaned = 0.000000/sec
aborted_requests = 50.606395/sec
syscalls.polls = 14570.791755/sec
syscalls.disk.opens = 160.005807/sec
syscalls.disk.closes = 320.351613/sec
syscalls.disk.reads = 3520.644427/sec
syscalls.disk.writes = 3868.092562/sec
syscalls.disk.seeks = 0.000000/sec
syscalls.disk.unlinks = 51.959721/sec
syscalls.sock.accepts = 1153.950470/sec
syscalls.sock.sockets = 478.724096/sec
syscalls.sock.connects = 469.890810/sec
syscalls.sock.binds = 478.724096/sec
syscalls.sock.closes = 1098.090770/sec
syscalls.sock.reads = 7904.917551/sec
syscalls.sock.writes = 18578.413567/sec
syscalls.sock.recvfroms = 106.432762/sec
syscalls.sock.sendtos = 51.699722/sec
cpu_time = 202.038000 seconds
wall_time = 300.001611 seconds
cpu_usage = 67.345638%

and when it use 100%
Last 5 minutes:
sample_start_time = 1460359453.520662 (Mon, 11 Apr 2016 07:24:13 GMT)
sample_end_time = 1460359753.537375 (Mon, 11 Apr 2016 07:29:13 GMT)
client_http.requests = 1124.314031/sec
client_http.hits = 341.530973/sec
client_http.errors = 3.309816/sec
client_http.kbytes_in = 772.766949/sec
client_http.kbytes_out = 44051.135911/sec
client_http.all_median_svc_time = 0.685775 second
client_http.miss_median_svc_time = 0.806511 seconds
client_http.nm_median_svc_time = 0.092188 seconds
client_http.nh_median_svc_time = 0.469653 seconds
client_http.hit_median_svc_time = 0.399283 seconds
server.all.requests = 747.688346/sec
server.all.errors = 0.000000/sec
server.all.kbytes_in = 33436.033945/sec
server.all.kbytes_out = 636.631200/sec
server.http.requests = 741.872004/sec
server.http.errors = 0.000000/sec
server.http.kbytes_in = 33395.426207/sec
server.http.kbytes_out = 630.834856/sec
server.ftp.requests = 0.000000/sec
server.ftp.errors = 0.000000/sec
server.ftp.kbytes_in = 0.000000/sec
server.ftp.kbytes_out = 0.000000/sec
server.other.requests = 5.816343/sec
server.other.errors = 0.000000/sec
server.other.kbytes_in = 40.611071/sec
server.other.kbytes_out = 5.796344/sec
icp.pkts_sent = 0.000000/sec
icp.pkts_recv = 0.000000/sec
icp.queries_sent = 0.000000/sec
icp.replies_sent = 0.000000/sec
icp.queries_recv = 0.000000/sec
icp.replies_recv = 0.000000/sec
icp.replies_queued = 0.000000/sec
icp.query_timeouts = 0.000000/sec
icp.kbytes_sent = 0.000000/sec
icp.kbytes_recv = 0.000000/sec
icp.q_kbytes_sent = 0.000000/sec
icp.r_kbytes_sent = 0.000000/sec
icp.q_kbytes_recv = 0.000000/sec
icp.r_kbytes_recv = 0.000000/sec
icp.query_median_svc_time = 0.000000 seconds
icp.reply_median_svc_time = 0.000000 seconds
dns.median_svc_time = 0.063638 seconds
unlink.requests = 0.000000/sec
page_faults = 0.000000/sec
select_loops = 68.769502/sec
select_fds = 17469.616768/sec
average_select_fd_period = 0.000057/f
median_select_fds = 253.007812
swap.outs = 309.809407/sec
swap.ins = 606.672869/sec
swap.files_cleaned = 0.000000/sec
aborted_requests = 64.026433/sec
syscalls.polls = 68.769502/sec
syscalls.disk.opens = 162.004308/sec
syscalls.disk.closes = 323.981951/sec
syscalls.disk.reads = 3170.013399/sec
syscalls.disk.writes = 3344.553675/sec
syscalls.disk.seeks = 0.000000/sec
syscalls.disk.unlinks = 52.953717/sec
syscalls.sock.accepts = 884.907368/sec
syscalls.sock.sockets = 488.359460/sec
syscalls.sock.connects = 479.986593/sec
syscalls.sock.binds = 488.359460/sec
syscalls.sock.closes = 1127.137207/sec
syscalls.sock.reads = 4520.671487/sec
syscalls.sock.writes = 13540.768977/sec
syscalls.sock.recvfroms = 129.662776/sec
syscalls.sock.sendtos = 50.653845/sec
cpu_time = 302.344000 seconds
wall_time = 300.016713 seconds
cpu_usage = 100.775719%

and you can see It was fine and after 30 min cpu_usage is 100.775719%
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/3b9e014e/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 15 09:17:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 15 Apr 2016 21:17:19 +1200
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570FE20F.5080704@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
Message-ID: <5710B19F.4020504@treenet.co.nz>

On 15/04/2016 6:31 a.m., Yuri Voinov wrote:
> 
> Ok, nobody.
> 
> Well.
> 
> I've done my own research.
> 
> My suggestions:
> 
> CloudFlare now uses it's own custom OpenSSL 1.0.2 with very custom
> patches with CHACHA Poly support.
> 
> This patches is not in upstream. Moreover, OpenSSL team no plans in the
> foreseeable future to support the latest ciphers.
> 
> So, Squid 4 can't handshake TLS with CF right now. Possible it is Squid
> 4.x branch bug. Because of 3.5.x does CF handshake.
> 
> LibreSSL does CHACHA right now.
> 
> The question is:
> 
> Amos, does Squid can support LibreSSL and, if no, when you plan to support?

Yes Squid does support LibreSSL. You can build against it with the
--with-openssl configure option, maybe using a =path parameter to ensure
it dont find an OpenSSL install.

The difference between LibreSSL and OpenSSL is likely to be more visible
in the squid.conf settings that it will accept and those that it
rejects. They are still basically the same but I know that the LibreSSL
guys are being very proactive removing old things like SSLv2 support. So
those config options wont work even when Squid-3.5 normally would
accepts them with OpenSSL.

Amos


From squid3 at treenet.co.nz  Fri Apr 15 09:25:45 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 15 Apr 2016 21:25:45 +1200
Subject: [squid-users] grove.microsoft.com
In-Reply-To: <CAFChrgLCzhxsKuyT-sRoSRAFOm+eOncJzvGL36tpxJ46UeDDZw@mail.gmail.com>
References: <CAEnCSG61daOnfWZ6ekp-iQHr9STt5bSNijFb+r2U9Wf1o6rZYQ@mail.gmail.com>
 <CAFChrgLCzhxsKuyT-sRoSRAFOm+eOncJzvGL36tpxJ46UeDDZw@mail.gmail.com>
Message-ID: <5710B399.1090805@treenet.co.nz>

> On Fri, Apr 15, 2016 at 4:04 PM, Michael Pelletier wrote:
> 
>> I am blocking grove.microsoft.com. Even though I am blocking it, I am
>> seeing large, 2 Gig, uploads from the client to the proxy (which indeed
>> blocks it). It is almost like the connection request (explicit) contains
>> the 2 gig post request. Why is this happening? Has anyone seen this?
>>

On 15/04/2016 4:57 p.m., Jason Haar wrote:
> If you are blocking it, then it can't be uploading 2G? How are you
> measuring that it uploads 2G? Did you change squid's logging to support
> that (it doesn't log upload sizes - only download sizes by default). Are
> you simply referring to the Content-Length header - as that would say 2G -
> even if the upload is then blocked.


Also, you may be completely misunderstanding what you have configured.

Once a request starts it must be finished. There are only two ways to
finish requests in HTTP/1.1 and one of those ways is to absorb and
discard any payload that exists on the request message. Which matches
your description perfectly.


We will need to see how you have 'blocked' the traffic and what the
message headers going through contain.

Amos



From squid3 at treenet.co.nz  Fri Apr 15 09:33:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 15 Apr 2016 21:33:41 +1200
Subject: [squid-users] Access log to syslog
In-Reply-To: <58D17FFEF248BA4997C61EA1775AC69E0FAC222B@CPTISNMAIL02>
References: <58D17FFEF248BA4997C61EA1775AC69E0FAC222B@CPTISNMAIL02>
Message-ID: <5710B575.5020800@treenet.co.nz>

On 15/04/2016 5:35 p.m., stefand at korbitec.com wrote:
> I'm trying to log multiple ACLs to syslog using squid 3.3.8 on CentOS 7
> 
> When I add the line :
> 
> access_log syslog:local4.info squid ACL1 ACL2 ACL3
> 
> Nothing gets logged to syslog
> 
> However when I change the line to :
> 
> access_log syslog:local4.info squid ACL1
> 
> It logs correctly, but just for ACL1 (as expected)
> 
> Should I then rather have the configuration file with the following lines:
> 
> access_log syslog:local4.info squid ACL1
> access_log syslog:local4.info squid ACL2
> access_log syslog:local4.info squid ACL3
> 
> Doesn't make sense to me as the documentation states (http://www.squid-cache.org/Versions/v3/3.3/cfgman/access_log.html) :
> 
> access_log <module>:<place> [<logformat name> [acl acl ...]]
> 

Any list of ACL conditions in a line of squid.conf like that are joined
with a boolean "AND" condition. All of them must be true for the action
being decided to happen.

In this case the action is to record a log line about the current
transaction.
* In your first non-working setup (ACL1 and ACL2 and ACL3) had to be
true for it to record.
* In your second setup only ACL1 had to be true for it to record.

If you have not met them already take a look at the all-of and any-of
ACL types which can be used to join simpler ACLs into a single test with
complex conditions - like having brackets in the boolean test.

You may need to upgrade your Squid to get those newer ACL types. You can
find details of newer Squid pckages for CentOS at
<http://wiki.squid-cache.org/KnowledgeBase/CentOS>

Amos


From squid3 at treenet.co.nz  Fri Apr 15 11:22:48 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 15 Apr 2016 23:22:48 +1200
Subject: [squid-users] High CPU usage
In-Reply-To: <CAL1kE9DAt=VBphGKywsE4-Yzy9pM2N5Ej_BwdJmh0C5LzzEm3Q@mail.gmail.com>
References: <CAL1kE9DAt=VBphGKywsE4-Yzy9pM2N5Ej_BwdJmh0C5LzzEm3Q@mail.gmail.com>
Message-ID: <5710CF08.7060603@treenet.co.nz>

On 15/04/2016 7:26 p.m., Mohammad Sadegh Nasiri wrote:
> Hi
> 
> Does anyone knows why my squid cpu usage is 100%?
> 

Before trying to answer you need to be aware that when/if it needs to
Squid will push CPU, RAM, disk I/O etc right to the hardware limits.


Your first trace is telling the story about 1150 RPS happening. Very few
transactions overlapping, so Squid spends most of its time pushing
individual or small groups of responses very fast. This reaches 800 Mbps
with Squid still spending a measurable chunk of its time (~30%) waiting
for something to do.


Your second trace is telling of a proxy receiving almost as many client
requests per second, but now juggling about 8,000 of them at a time.
Often 250 needing things to be done every cycle. Thats a lot of work, so
Squid has slowed down to 600 Mbps and is now using all of the CPU it can
get.

I think at some point between the traces something went a bit slower, or
some clients did a big transaction making more overlap, or generally
just pushed Squid up to a peak in its workoad that needed more CPU than
was available.
Since CPU can only give 100% that thing took a short while to finish.
Resulting in some transaction overlap, which made those take more CPU to
finish so Squid stays at 100% slightly longer, and round it goes in a
feedback loop.


The numbers that I'm looking at for that are:

 client_http.requests = 	 1150 ->  1124/sec

 client_http.kbytes_in = 	  841 ->   773/sec
 client_http.kbytes_out = 	57428 -> 44051/sec
 server.all.kbytes_in = 	43019 -> 33436/sec
 server.all.kbytes_out =	  705 ->   637/sec

  (adding these gives a ~800 Mbps -> ~600 Mbps drop)

 select_loops = 	14571 ->    69/sec
 select_fds = 		27229 -> 17470/sec

 median_select_fds = 0.000000 -> 253.007812

Significantly more FDs needing things to do each time Squid checks. So
it checks fewer times per sec. Meaning more each time it checks, and so on.
 - the low select loops per sec is what I think is driving the service
times to be longer. They are still under 1sec so not very noticable to
clients.


Watch the median_select_fds to see if it is reducing. If so Squid is
(slowly) recovering after the peak event. Otherwise Squid is falling
behind the workload.


Amos



From odhiambo at gmail.com  Fri Apr 15 13:29:38 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 15 Apr 2016 16:29:38 +0300
Subject: [squid-users] Stuggling with 3.5.16 on FreeBSD-9.3
In-Reply-To: <570EEAB0.2050700@treenet.co.nz>
References: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
 <570EEAB0.2050700@treenet.co.nz>
Message-ID: <CAAdA2WOeX5F57_QzVvA-8-nA-wK3LRYgxSpqwhdy-WoRWbsbDA@mail.gmail.com>

On 14 April 2016 at 03:56, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 14/04/2016 6:02 a.m., Odhiambo Washington wrote:
> > Hi Amos,
> >
> > I bit the bullet and upgraded my FreeBSD-8.4 -> 9.3.
> >
> > I am struggling to compile squid-3.5.16. I just have to find a way to
> make
> > it compile and run, by all means.
> >
> > So now here is what happens:
> >
> >
> > #!/bin/sh
> > ./configure --prefix=/opt/squid-3.5 \
> >         --enable-removal-policies="lru heap" \
> >         --disable-epoll \
> >         --with-pthreads \
> >         --enable-storeio="ufs diskd rock aufs" \
> >         --enable-delay-pools \
> >         --enable-snmp  \
> >         --with-openssl=/usr \
> >         --enable-forw-via-db \
> >         --enable-cache-digests \
> >         --enable-wccpv2 \
> >         --enable-follow-x-forwarded-for \
> >         --with-large-files \
> >         --enable-esi \
> >         --enable-kqueue \
> >         --enable-icap-client \
> >         --enable-kill-parent-hack \
> >         --enable-ssl \
> >         --enable-ssl-crtd \
> >         --enable-url-rewrite-helpers \
> >         --enable-xmalloc-statistics \
> >         --enable-stacktraces \
> >         --enable-zph-qos \
> >         --enable-eui \
> >         --with-nat-devpf \
> >         --enable-pf-transparent \
> >         --enable-ipf-transparent \
> >         --enable-auth \
> >
> > My config.log output is here: *http://goo.gl/LcV1yN <
> http://goo.gl/LcV1yN>*
> >
> > And this is how the compile fails:Making all in negotiate_auth
> > Making all in kerberos
> > depbase=`echo negotiate_kerberos_auth.o | sed
> > 's|[^/]*$|.deps/&|;s|\.o$||'`; g++ -DHAVE_CONFIG_H    -I../../..
> > -I../../../include  -I../../../lib -I../../../src  -I../../../include
> >  -I/usr/include  -I/usr/include  -I../../../libltdl -I. -I/usr/include
> > -I/usr/local/include/libxml2 -I/usr/local/include/libxml2 -Wall
> > -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual
> > -Werror -pipe -D_REENTRANT -I/usr/local/include  -g -O2 -march=native
> > -I/usr/local/include -MT negotiate_kerberos_auth.o -MD -MP -MF
> $depbase.Tpo
> > -c -o negotiate_kerberos_auth.o negotiate_kerberos_auth.cc && mv -f
> > $depbase.Tpo $depbase.Po
> > negotiate_kerberos_auth.cc: In function 'int main(int, char* const*)':
> > negotiate_kerberos_auth.cc:754: error:
> > 'gsskrb5_extract_authz_data_from_sec_context' was not declared in this
> scope
> > *** [negotiate_kerberos_auth.o] Error code 1
> >
>
> Strange. Check the Kerberos / krb5 libraries available are up to date.
> Or for now you may need to use one or more of these:
>  --without-mit-kerberos \
>  --without-heimdal-kerbers \
>  --without-gssapi-kerberos
>
>
With luck, I have managed to get squid to compile successfully (after
upgrading a few components here and there). I used:

#!/bin/sh
env LDFLAGS=-L/usr/local/lib CPPFLAGS=-I/usr/local/include CC=clang
CXX=clang++ CPP=clang-cpp ./configure --prefix=/opt/squid-3.5 \
        --enable-removal-policies="lru heap" \
        --disable-epoll \
        --with-pthreads \
        --enable-storeio="ufs diskd rock aufs" \
        --enable-delay-pools \
        --enable-snmp  \
        --with-openssl=/usr \
        --enable-forw-via-db \
        --enable-cache-digests \
        --enable-wccpv2 \
        --enable-follow-x-forwarded-for \
        --with-large-files \
        --enable-esi \
        --enable-kqueue \
        --enable-icap-client \
        --enable-kill-parent-hack \
        --enable-ssl \
        --enable-ssl-crtd \
        --enable-url-rewrite-helpers \
        --enable-xmalloc-statistics \
        --enable-stacktraces \
        --enable-zph-qos \
        --enable-eui \
        --with-nat-devpf \
        --enable-pf-transparent \
        --enable-ipf-transparent \
        --with-nat-devpf \
        --without-mit-kerberos \
        --without-heimdal-kerbers \
        --without-gssapi-kerberos \
        --enable-auth





>
> >
> > I am getting closer I think.
> >
> > The initial compile that I had before the upgrade from 8.4 to 9.3 cannot
> > run. Gives a different error:
> >
> > 2016/04/13 14:12:13| Accepting NAT intercepted SSL bumped HTTPS Socket
> > connections at local=192.168.55.254:13129 remote=[::] FD 36 flags=41
> > 2016/04/13 14:12:13| Accepting ICP messages on [::]:3130
> > 2016/04/13 14:12:13| Sending ICP messages from [::]:3130
> > 2016/04/13 14:12:13| ERROR: NAT/TPROXY lookup failed to locate original
> IPs
> > on local=192.168.55.254:13128 remote=192.168.55.83:50648 FD 14 flags=33
>
>
> <http://www.squid-cache.org/Versions/v3/3.4/RELEASENOTES.html#ss2.4>
>
> I dont think IPFilter (--enable-ipf-transparent) works on FreeBSD.
>
> paketFilte (PF, --enable-pf-transparent --with-nat-devpf) and IFPW
> (--enable-ipfw-transparent) should do.
>
> Be careful of the 'f' and 'w' characters there, it can be a bit
> confusing with them all those different names.
>
>
> NP: the same error message can occur if you have simply configured DNAT
> / REDIRECT external to the Squid machine.
>


I have it running now (redirecting using IPFilter/IPNAT), but once in a
while I see this error about NAT:


2016/04/15 16:15:52| Starting Squid Cache version 3.5.16 for
i386-unknown-freebsd9.3...
2016/04/15 16:15:52| Service Name: squid
2016/04/15 16:15:52| Process ID 21761
2016/04/15 16:15:52| Process Roles: master worker
2016/04/15 16:15:52| With 32768 file descriptors available
2016/04/15 16:15:52| Initializing IP Cache...
2016/04/15 16:15:52| DNS Socket created at [::], FD 9
2016/04/15 16:15:52| DNS Socket created at 0.0.0.0, FD 10
2016/04/15 16:15:52| Adding domain crownkenya.com from /etc/resolv.conf
2016/04/15 16:15:52| Adding nameserver 192.168.55.254 from /etc/resolv.conf
2016/04/15 16:15:52| Adding nameserver 208.67.222.222 from /etc/resolv.conf
2016/04/15 16:15:52| Adding nameserver 208.67.220.220 from /etc/resolv.conf
2016/04/15 16:15:52| Adding nameserver 196.201.225.19 from /etc/resolv.conf
2016/04/15 16:15:52| Adding nameserver 41.222.10.26 from /etc/resolv.conf
2016/04/15 16:15:52| helperOpenServers: Starting 5/15 'ssl_crtd' processes
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:52| helperOpenServers: Starting 5/10 'perl' processes
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:52| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:53| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/04/15 16:15:53| Logfile: opening log
stdio:/usr/local/squid/logs/access.log
2016/04/15 16:15:53| Local cache digest enabled; rebuild/rewrite every
3600/3600 sec
2016/04/15 16:15:53| Store logging disabled
2016/04/15 16:15:53| Swap maxSize 20971520 + 131072 KB, estimated 1623276
objects
2016/04/15 16:15:53| Target number of buckets: 81163
2016/04/15 16:15:53| Using 131072 Store buckets
2016/04/15 16:15:53| Max Mem  size: 131072 KB
2016/04/15 16:15:53| Max Swap size: 20971520 KB
2016/04/15 16:15:53| Rejecting swap file v1 to avoid cache index
corruption. Forcing a full cache index rebuild. See Squid bug #3441.
2016/04/15 16:15:53| Rebuilding storage in /usr/local/squid/cache (clean
log)
2016/04/15 16:15:53| Using Least Load store dir selection
2016/04/15 16:15:53| Set Current Directory to /usr/local/squid/logs
2016/04/15 16:15:53| Finished loading MIME types and icons.
2016/04/15 16:15:53| HTCP Disabled.
2016/04/15 16:15:53| Squid plugin modules loaded: 0
2016/04/15 16:15:53| Adaptation support is off.
2016/04/15 16:15:53| Accepting NAT intercepted HTTP Socket connections at
local=192.168.55.254:13128 remote=[::] FD 34 flags=41
2016/04/15 16:15:53| Accepting HTTP Socket connections at local=[::]:13130
remote=[::] FD 35 flags=9
2016/04/15 16:15:53| Accepting NAT intercepted SSL bumped HTTPS Socket
connections at local=192.168.55.254:13129 remote=[::] FD 36 flags=41
2016/04/15 16:15:53| Accepting ICP messages on [::]:3130
2016/04/15 16:15:53| Sending ICP messages from [::]:3130
2016/04/15 16:17:23| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.62:57724 FD 29 flags=33
2016/04/15 16:18:53| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.62:57726 FD 357 flags=33
2016/04/15 16:21:57| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.62:57742 FD 29 flags=33
2016/04/15 16:23:21| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.62:57757 FD 60 flags=33
2016/04/15 16:24:17| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.60:49166 FD 79 flags=33
2016/04/15 16:24:17| ERROR: NAT/TPROXY lookup failed to locate original IPs
on local=192.168.55.254:13128 remote=192.168.55.60:49168 FD 79 flags=33


In any case, I am planning to rewrite the IPNAT rules into PF and use PF.
It's the inception stage so I haven't delved deep into ssl-bump
configurations...


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/64b069af/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 15 15:13:40 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 16 Apr 2016 03:13:40 +1200
Subject: [squid-users] Stuggling with 3.5.16 on FreeBSD-9.3
In-Reply-To: <CAAdA2WOeX5F57_QzVvA-8-nA-wK3LRYgxSpqwhdy-WoRWbsbDA@mail.gmail.com>
References: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
 <570EEAB0.2050700@treenet.co.nz>
 <CAAdA2WOeX5F57_QzVvA-8-nA-wK3LRYgxSpqwhdy-WoRWbsbDA@mail.gmail.com>
Message-ID: <57110524.5080405@treenet.co.nz>

On 16/04/2016 1:29 a.m., Odhiambo Washington wrote:
>
> With luck, I have managed to get squid to compile successfully (after
> upgrading a few components here and there). I used:

Yay!

> 
> I have it running now (redirecting using IPFilter/IPNAT), but once in a
> while I see this error about NAT:
> 
<snip>
> 2016/04/15 16:17:23| ERROR: NAT/TPROXY lookup failed to locate original IPs
> on local=192.168.55.254:13128 remote=192.168.55.62:57724 FD 29 flags=33

These are the kernel NAT system telling Squid the connection being
looked up has not record there.

It could be TCP connections being made straight to the intercept port.
If so you need to update the firewall config to prevent them, even from
localhost.
 In Linux we use a mangle table rule, since that is the filter pre-NAT
that can do it. I'm not sure how FreeBSD would do that. It has to be
done on packets first arrival pre-NAT. Any filter that is applied after
the NAT action will get it wrong due to the NAT changes.


It could be the NAT systems table of connections filling up and
overflowing. If so there should be a kernel sysctl somewhere to increase
that table size.

> 
> In any case, I am planning to rewrite the IPNAT rules into PF and use PF.
> It's the inception stage so I haven't delved deep into ssl-bump
> configurations...
> 

HTH
Amos



From odhiambo at gmail.com  Fri Apr 15 15:45:14 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 15 Apr 2016 18:45:14 +0300
Subject: [squid-users] Stuggling with 3.5.16 on FreeBSD-9.3
In-Reply-To: <57110524.5080405@treenet.co.nz>
References: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
 <570EEAB0.2050700@treenet.co.nz>
 <CAAdA2WOeX5F57_QzVvA-8-nA-wK3LRYgxSpqwhdy-WoRWbsbDA@mail.gmail.com>
 <57110524.5080405@treenet.co.nz>
Message-ID: <CAAdA2WNKfZdwj96wTM_zLAbAgO33ZNyMn=s-qy6yfk0L=9X5Xg@mail.gmail.com>

Hello Amos,

All noted.

Lemme consult with some FreeBSD guys on these .

On 15 April 2016 at 18:13, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 16/04/2016 1:29 a.m., Odhiambo Washington wrote:
> >
> > With luck, I have managed to get squid to compile successfully (after
> > upgrading a few components here and there). I used:
>
> Yay!
>
> >
> > I have it running now (redirecting using IPFilter/IPNAT), but once in a
> > while I see this error about NAT:
> >
> <snip>
> > 2016/04/15 16:17:23| ERROR: NAT/TPROXY lookup failed to locate original
> IPs
> > on local=192.168.55.254:13128 remote=192.168.55.62:57724 FD 29 flags=33
>
> These are the kernel NAT system telling Squid the connection being
> looked up has not record there.
>
> It could be TCP connections being made straight to the intercept port.
> If so you need to update the firewall config to prevent them, even from
> localhost.
>  In Linux we use a mangle table rule, since that is the filter pre-NAT
> that can do it. I'm not sure how FreeBSD would do that. It has to be
> done on packets first arrival pre-NAT. Any filter that is applied after
> the NAT action will get it wrong due to the NAT changes.
>
>
> It could be the NAT systems table of connections filling up and
> overflowing. If so there should be a kernel sysctl somewhere to increase
> that table size.
>
> >
> > In any case, I am planning to rewrite the IPNAT rules into PF and use PF.
> > It's the inception stage so I haven't delved deep into ssl-bump
> > configurations...
> >
>
> HTH
> Amos
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/7ffbc95c/attachment.htm>

From renatoriolino at gmail.com  Fri Apr 15 17:13:03 2016
From: renatoriolino at gmail.com (Renato)
Date: Fri, 15 Apr 2016 14:13:03 -0300
Subject: [squid-users] Not sure if reverse proxy is what I need
Message-ID: <CAG_2TMcx9k-Z-qg5OK6EYKahvPoK3HWspbP9Gn-oOzK+Pt2pSA@mail.gmail.com>

Hi guys,

I'm not sure if squid is what I need, so I'll try to explain my
scenario to make it clear what I need:

I have lots of virtual machines, each one running a web service.
Those virtual machines are not exposed to the internet.

To access the virtual machines, I want to have a "client database",
each client will have an username, a password and the IP address and
port number for the virtual machine, like this:

client1, pass_cli1, http://192.168.0.1:8081
client2, pass_cli2, http://192.168.0.1:8082
client3, pass_cli3, http://192.168.0.1:8083
client4, pass_cli4, http://192.168.0.2:8081
...

What I'm thinking of doing is to let squid exposed to the internet,
with authentication.  When a client connects, a login/password is
asked.  If the login/pass matches one of the clients on the list,
squid will reverse proxy to the corresponding address on database.

Is it possible to achieve this only with squid or I need others tools too?

Thanks

Renato Riolino


From tit at irk.ru  Fri Apr 15 18:06:35 2016
From: tit at irk.ru (Alexander Titaev)
Date: Sat, 16 Apr 2016 02:06:35 +0800
Subject: [squid-users] ntlm user in access.log
Message-ID: <1702156600.20160416020635@irk.ru>

Hi, Squid-users.

before was
fbsd 9.3 i386, squid-2.7.9_1, samba36-3.6.23
1448899275.777 5230 192.168.0.29 TCP_MISS/200 2823 CONNECT rs.mail.ru:443 IGM\mtiunov DIRECT/94.100.180.76 -

is now
10.2 amd64, squid-3.5.16, samba36-3.6.25_3
1460709029.057 1 192.168.0.74 TCP_MISS/503 4751 GET http://vk.com/widget_community.php? IGM\\mtiunov HIER_DIRECT/192.168.1.254 text/html

how I can get
DOM\user
instead
DOM\\user


-- 
? ?????????,
 Alexander                          mailto:tit at irk.ru



From david at articatech.com  Fri Apr 15 21:59:33 2016
From: david at articatech.com (David Touzeau)
Date: Fri, 15 Apr 2016 23:59:33 +0200
Subject: [squid-users] High CPU usage
In-Reply-To: <5710CF08.7060603@treenet.co.nz>
References: <CAL1kE9DAt=VBphGKywsE4-Yzy9pM2N5Ej_BwdJmh0C5LzzEm3Q@mail.gmail.com>
 <5710CF08.7060603@treenet.co.nz>
Message-ID: <507d01d19762$18a571e0$49f055a0$@articatech.com>

We have the same issue when upgrading to 3.5.16

3.5.16 -> squid take 100% CPU
Back to 3.5.13 -> 12% CPU

-----Message d'origine-----
De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Amos Jeffries
Envoy? : vendredi 15 avril 2016 13:23
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] High CPU usage

On 15/04/2016 7:26 p.m., Mohammad Sadegh Nasiri wrote:
> Hi
> 
> Does anyone knows why my squid cpu usage is 100%?
> 

Before trying to answer you need to be aware that when/if it needs to Squid will push CPU, RAM, disk I/O etc right to the hardware limits.


Your first trace is telling the story about 1150 RPS happening. Very few transactions overlapping, so Squid spends most of its time pushing individual or small groups of responses very fast. This reaches 800 Mbps with Squid still spending a measurable chunk of its time (~30%) waiting for something to do.


Your second trace is telling of a proxy receiving almost as many client requests per second, but now juggling about 8,000 of them at a time.
Often 250 needing things to be done every cycle. Thats a lot of work, so Squid has slowed down to 600 Mbps and is now using all of the CPU it can get.

I think at some point between the traces something went a bit slower, or some clients did a big transaction making more overlap, or generally just pushed Squid up to a peak in its workoad that needed more CPU than was available.
Since CPU can only give 100% that thing took a short while to finish.
Resulting in some transaction overlap, which made those take more CPU to finish so Squid stays at 100% slightly longer, and round it goes in a feedback loop.


The numbers that I'm looking at for that are:

 client_http.requests = 	 1150 ->  1124/sec

 client_http.kbytes_in = 	  841 ->   773/sec
 client_http.kbytes_out = 	57428 -> 44051/sec
 server.all.kbytes_in = 	43019 -> 33436/sec
 server.all.kbytes_out =	  705 ->   637/sec

  (adding these gives a ~800 Mbps -> ~600 Mbps drop)

 select_loops = 	14571 ->    69/sec
 select_fds = 		27229 -> 17470/sec

 median_select_fds = 0.000000 -> 253.007812

Significantly more FDs needing things to do each time Squid checks. So it checks fewer times per sec. Meaning more each time it checks, and so on.
 - the low select loops per sec is what I think is driving the service times to be longer. They are still under 1sec so not very noticable to clients.


Watch the median_select_fds to see if it is reducing. If so Squid is
(slowly) recovering after the peak event. Otherwise Squid is falling behind the workload.


Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From michael.pelletier at palmbeachschools.org  Fri Apr 15 23:13:34 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Fri, 15 Apr 2016 19:13:34 -0400
Subject: [squid-users] grove.microsoft.com
In-Reply-To: <CAFChrgLCzhxsKuyT-sRoSRAFOm+eOncJzvGL36tpxJ46UeDDZw@mail.gmail.com>
References: <CAEnCSG61daOnfWZ6ekp-iQHr9STt5bSNijFb+r2U9Wf1o6rZYQ@mail.gmail.com>
 <CAFChrgLCzhxsKuyT-sRoSRAFOm+eOncJzvGL36tpxJ46UeDDZw@mail.gmail.com>
Message-ID: <CAEnCSG7sN+fgV6sQHqYf4LNxshhOQ2iZy=tREsbqyX+U3NpjAA@mail.gmail.com>

Hello,
Bellow is the message that I retrieve from logstash. We use logstash as our
logging system. Now, I do add tags to log messages in log stash. I believe
the %st is my size right?

Apr 14 01:31:13 Proxy-SI-1 (squid-2): Proxy-SI-1 1460611873.853 0 2
10.88.14.225 TCP_DENIED_ABORTED 301 2147480505 535 2147479970 POST 1.0
text/html - - - - 3128 - [Mozilla/4.0 (compatible; MSIE 5.5; Win32)] [-]
sq_err:[301 Access Denied] c_hdr:[Accept: */*\r\nContent-Type:
application/octet-stream\r\nUser-Agent: Mozilla/4.0 (compatible; MSIE 5.5;
Win32)\r\nUserAgent: blugro3relay.groove.microsoft.com\r\nContent-Length:
2147479552\r\nPragma: no-cache\r\nCache-Control: no-cache\r\nExpires:
0\r\nCache-Control: max-age=0\r\n] s_hdr:[HTTP/1.1 301 Moved
Permanently\r\nServer: squid/3.4.13\r\nMime-Version: 1.0\r\nDate: Thu, 14
Apr 2016 05:31:13 GMT\r\nContent-Type: text/html\r\nContent-Length:
0\r\nLocation:
http://blockmessage.palmbeach.k12.fl.us/block_message.php?clientaddr=10.88.14.225&clientname=-&clientuser=-&clientgroup=SDPBC-Network&targetgroup=Blacklist&url=HTTP://blugro3relay.groove.microsoft.com\r\nX-Squid-Error:
301 Access Denied\r\n\r]

Here is the custom syslog from the config
logformat custom Proxy-SI-1 %ts.%tu %dt %tr %>a %Ss %03Hs %st %<st %>st %rm
%rv %mt %[un %<A %<a %<p %>lp %{Referer}>h [%{User-Agent}>h\
] [%{Host}>h] sq_err:[%{X-Squid-Error}<h] c_hdr:[%>h] s_hdr:[%<h]


On Fri, Apr 15, 2016 at 12:57 AM, Jason Haar <jason_haar at trimble.com> wrote:

> If you are blocking it, then it can't be uploading 2G? How are you
> measuring that it uploads 2G? Did you change squid's logging to support
> that (it doesn't log upload sizes - only download sizes by default). Are
> you simply referring to the Content-Length header - as that would say 2G -
> even if the upload is then blocked.
>
> On Fri, Apr 15, 2016 at 4:04 PM, Michael Pelletier <
> michael.pelletier at palmbeachschools.org> wrote:
>
>> I am blocking grove.microsoft.com. Even though I am blocking it, I am
>> seeing large, 2 Gig, uploads from the client to the proxy (which indeed
>> blocks it). It is almost like the connection request (explicit) contains
>> the 2 gig post request. Why is this happening? Has anyone seen this?
>>
>>
>> Michael
>>
>> *Disclaimer: *Under Florida law, e-mail addresses are public records. If
>> you do not want your e-mail address released in response to a public
>> records request, do not send electronic mail to this entity. Instead,
>> contact this office by phone or in writing.
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
>
> --
> Cheers
>
> Jason Haar
> Information Security Manager, Trimble Navigation Ltd.
> Phone: +1 408 481 8171
> PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160415/065f7bb3/attachment.htm>

From johnzeng2013 at yahoo.com  Sat Apr 16 01:46:07 2016
From: johnzeng2013 at yahoo.com (johnzeng)
Date: Sat, 16 Apr 2016 09:46:07 +0800
Subject: [squid-users] How to replace (squid/3.x.x) info at http reponse
 header via and warning
Message-ID: <5711995F.4010503@yahoo.com>


Hello Dear Sir

How to replace (squid/3.x.x) info at http reponse header via and warning ,

Whether i will updated HttpHeader.cc ?

{"Via", HDR_VIA, ftStr}, /* for now */
{"Warning", HDR_WARNING, ftStr}, /* for now */


Best Regards


John


From squid3 at treenet.co.nz  Sat Apr 16 06:26:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 16 Apr 2016 18:26:49 +1200
Subject: [squid-users] How to replace (squid/3.x.x) info at http reponse
 header via and warning
In-Reply-To: <5711995F.4010503@yahoo.com>
References: <5711995F.4010503@yahoo.com>
Message-ID: <5711DB29.3040705@treenet.co.nz>

On 16/04/2016 1:46 p.m., johnzeng wrote:
> 
> Hello Dear Sir
> 
> How to replace (squid/3.x.x) info at http reponse header via and warning ,

What is the problem you have with these RFC required headers?


> 
> Whether i will updated HttpHeader.cc ?
> 
> {"Via", HDR_VIA, ftStr}, /* for now */
> {"Warning", HDR_WARNING, ftStr}, /* for now */
> 

No. Regardless of what you want to do that is just a registry of which
headers exist in HTTP.

Amos



From squid3 at treenet.co.nz  Sat Apr 16 06:54:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 16 Apr 2016 18:54:39 +1200
Subject: [squid-users] grove.microsoft.com
In-Reply-To: <CAEnCSG7sN+fgV6sQHqYf4LNxshhOQ2iZy=tREsbqyX+U3NpjAA@mail.gmail.com>
References: <CAEnCSG61daOnfWZ6ekp-iQHr9STt5bSNijFb+r2U9Wf1o6rZYQ@mail.gmail.com>
 <CAFChrgLCzhxsKuyT-sRoSRAFOm+eOncJzvGL36tpxJ46UeDDZw@mail.gmail.com>
 <CAEnCSG7sN+fgV6sQHqYf4LNxshhOQ2iZy=tREsbqyX+U3NpjAA@mail.gmail.com>
Message-ID: <5711E1AF.2030600@treenet.co.nz>

On 16/04/2016 11:13 a.m., Michael Pelletier wrote:
> Hello,
> Bellow is the message that I retrieve from logstash. We use logstash as our
> logging system. Now, I do add tags to log messages in log stash. I believe
> the %st is my size right?

Yes that should be teh sum of request and reply payload sizes.

> 
> Apr 14 01:31:13 Proxy-SI-1 (squid-2): Proxy-SI-1 1460611873.853 0 2
> 10.88.14.225 TCP_DENIED_ABORTED 301 2147480505 535 2147479970 POST 1.0
> text/html - - - - 3128 - [Mozilla/4.0 (compatible; MSIE 5.5; Win32)] [-]
> sq_err:[301 Access Denied] c_hdr:[Accept: */*\r\nContent-Type:
> application/octet-stream\r\nUser-Agent: Mozilla/4.0 (compatible; MSIE 5.5;
> Win32)\r\nUserAgent: blugro3relay.groove.microsoft.com\r\nContent-Length:
> 2147479552\r\nPragma: no-cache\r\nCache-Control: no-cache\r\nExpires:
> 0\r\nCache-Control: max-age=0\r\n] s_hdr:[HTTP/1.1 301 Moved
> Permanently\r\nServer: squid/3.4.13\r\nMime-Version: 1.0\r\nDate: Thu, 14
> Apr 2016 05:31:13 GMT\r\nContent-Type: text/html\r\nContent-Length:
> 0\r\nLocation:
> http://blockmessage.palmbeach.k12.fl.us/block_message.php?clientaddr=10.88.14.225&clientname=-&clientuser=-&clientgroup=SDPBC-Network&targetgroup=Blacklist&url=HTTP://blugro3relay.groove.microsoft.com\r\nX-Squid-Error:
> 301 Access Denied\r\n\r]
> 

The client is an HTTP/1.0 agent - that is part of the problem here. In
HTTP/1.0 the only way to stop the POST payload being sent is to tear
down the entire TCP connection. Which is what Squid should do naturally
after those 2GB have finished arriving.

However Squid is being told how big it is up front. So the decision to
do so is possible. Provided that you have also not configured the
quick_abort settings to be "infinity" / keep-going then it may be
reasonable to abort the POST arrival.


There appear to be two bugs involved:

1) Squid not sending a Connection header in its response. Which tells
the 1.0 client what Squid expects to happen.

 This is a bug. To a 1.0 client Squid should always be sending either
keep-alive or close explicitly. It is reasonable to expect
'Connection:close' here (relative to quick_abort) given that payload has
a pre-known 2GB size and the response was internally generated by Squid.

 * You could try a newer Squid than 3.4, we might have fixed it already.
If the current releases still do the same please report it to our
bugzilla (against Squid 3.4 version) so this wont get lost.


2) The connection not being closed when the client received the respone.

This one is tricky. Squid has *no* knowledges of when that response
is/was/will be received b the other end. There are some popular tools
out there which would send the entire 2GB of data before even trying to
read any bytes of Squid response.
 So if Squid closes the connection itself earlier than that, the whole
301 could be lost and all the client sees is a broken proxy. So we have
to send the "Connection:close" and wait for the client to obey.

Fixing bug #1 above might solve the issue if the client is behaving
properly.

Otherwise it will have to be fixed at the client end. Even if Squid
tears down the TCP connection that closure signal / packet will not
arrive until the client tries to read(2)/write(2) - in the case of the
broken clients that could be after the 2GB was sent anyway. So no useful
improvement.
 - and good luck getting MSIE 5.5 stuff fixed these days :-(


You may have lucked out if someone has or can fix #1. I currently lack
the time sorry.

Amos



From yvoinov at gmail.com  Sat Apr 16 11:18:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 16 Apr 2016 17:18:17 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <5710B19F.4020504@treenet.co.nz>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz>
Message-ID: <57121F79.2040607@gmail.com>

mozilla.org now has the same issue on Squid 4 like CloudFlare:

https://i1.someimage.com/P03GmSY.png

All ok but handshake does not complete:

root @ cthulhu / # /usr/local/bin/openssl s_client -connect 
mozilla.org:443 -CApath /etc/ope/csw/ssl/certs
CONNECTED(00000003)
depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert 
High Assurance EV Root CA
verify return:1
depth=1 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert 
High Assurance EV CA-1
verify return:1
depth=0 businessCategory = Private Organization, 
1.3.6.1.4.1.311.60.2.1.3 = US, 1.3.6.1.4.1.311.60.2.1.2 = California, 
serialNumber = C2543436, street = 650 Castro St Ste 300, postalCode = 
94041, C = US, ST = California, L = Mountain View, O = Mozilla 
Foundation, CN = www.mozilla.org
verify return:1
---
Certificate chain
  0 s:/businessCategory=Private 
Organization/1.3.6.1.4.1.311.60.2.1.3=US/1.3.6.1.4.1.311.60.2.1.2=California/serialNumber=C2543436/street=650 
Castro St Ste 300/postalCode=94041/C=US/ST=California/L=Mountain 
View/O=Mozilla Foundation/CN=www.mozilla.org
    i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High 
Assurance EV CA-1
  1 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High 
Assurance EV CA-1
    i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High 
Assurance EV Root CA
---
Server certificate
-----BEGIN CERTIFICATE-----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-----END CERTIFICATE-----
subject=/businessCategory=Private 
Organization/1.3.6.1.4.1.311.60.2.1.3=US/1.3.6.1.4.1.311.60.2.1.2=California/serialNumber=C2543436/street=650 
Castro St Ste 300/postalCode=94041/C=US/ST=California/L=Mountain 
View/O=Mozilla Foundation/CN=www.mozilla.org
issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High 
Assurance EV CA-1
---
No client certificate CA names sent
---
SSL handshake has read 4163 bytes and written 446 bytes
---
New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES128-GCM-SHA256
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
SSL-Session:
     Protocol  : TLSv1.2
     Cipher    : ECDHE-RSA-AES128-GCM-SHA256
     Session-ID: 
E32E470329327A2E39ADDEB384FBB9D351103F1BBA798A47EBFFF121C5001CCA
     Session-ID-ctx:
     Master-Key: 
D2C6E671DB649951C999E1DF83DC038852215500C57F81E4660AFB7ED96039C76E8A384F3ED78A44BBD129C56DD6F45B
     Start Time: 1460805325
     Timeout   : 300 (sec)
     Verify return code: 0 (ok)
---

access.log also got NONE/503:

1460805179.734      0 192.168.100.103 NONE/503 3944 GET 
https://www.mozilla.org/favicon.ico - HIER_NONE/- text/html

and cache.log:

2016/04/16 17:12:59 kid1| Error negotiating SSL on FD 56: 
error:00000000:lib(0):func(0):reason(0) (5/0/0)

15.04.16 15:17, Amos Jeffries ?????:
> On 15/04/2016 6:31 a.m., Yuri Voinov wrote:
>> Ok, nobody.
>>
>> Well.
>>
>> I've done my own research.
>>
>> My suggestions:
>>
>> CloudFlare now uses it's own custom OpenSSL 1.0.2 with very custom
>> patches with CHACHA Poly support.
>>
>> This patches is not in upstream. Moreover, OpenSSL team no plans in the
>> foreseeable future to support the latest ciphers.
>>
>> So, Squid 4 can't handshake TLS with CF right now. Possible it is Squid
>> 4.x branch bug. Because of 3.5.x does CF handshake.
>>
>> LibreSSL does CHACHA right now.
>>
>> The question is:
>>
>> Amos, does Squid can support LibreSSL and, if no, when you plan to support?
> Yes Squid does support LibreSSL. You can build against it with the
> --with-openssl configure option, maybe using a =path parameter to ensure
> it dont find an OpenSSL install.
>
> The difference between LibreSSL and OpenSSL is likely to be more visible
> in the squid.conf settings that it will accept and those that it
> rejects. They are still basically the same but I know that the LibreSSL
> guys are being very proactive removing old things like SSLv2 support. So
> those config options wont work even when Squid-3.5 normally would
> accepts them with OpenSSL.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From johnzeng2013 at yahoo.com  Sat Apr 16 12:19:02 2016
From: johnzeng2013 at yahoo.com (johnzeng)
Date: Sat, 16 Apr 2016 20:19:02 +0800
Subject: [squid-users] How to replace (squid/3.x.x) info at http reponse
 header via and warning
In-Reply-To: <5711995F.4010503@yahoo.com>
References: <5711995F.4010503@yahoo.com>
Message-ID: <57122DB6.8050605@yahoo.com>

Hello Amos :

Thanks again .

John
> Hello Dear Sir
>
> How to replace (squid/3.x.x) info at http reponse header via and warning ,
>
> Whether i will updated HttpHeader.cc ?
>
> {"Via", HDR_VIA, ftStr}, /* for now */
> {"Warning", HDR_WARNING, ftStr}, /* for now */
>
>
> Best Regards
>
>
> John



From a.alii85 at gmail.com  Sat Apr 16 13:39:59 2016
From: a.alii85 at gmail.com (asad)
Date: Sat, 16 Apr 2016 18:39:59 +0500
Subject: [squid-users] Transition from Squid to bluecoat ProxySG
Message-ID: <CAP3=H7vfA4WBAPkxUNutdxLZdjejZ8unr3vTbi1TicvVBpBxbQ@mail.gmail.com>

Hello,

I'm in the process of helping a friend who works in a bank whose management
have decided to move from Squid infra to bluecoat PorxySG solution.

I want to know what are the pitfalls that must be imagined from project
management as on technical end.

Few info that I'm allowed to share is
       users are 1000 and bandwidth is 40 Mbps.
       Between BCP and HQ site active passive setup/configuration.

There are good and bad of each tech, but when there is mgt executive
decision there leaves not much gap of debating what is better. I'm wishing
anyone from the community who has been involved in such a task in past ,
current or in near future.

Thanks

regards
asad
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160416/8be8e388/attachment.htm>

From bpk678 at gmail.com  Sat Apr 16 14:14:26 2016
From: bpk678 at gmail.com (Brendan Kearney)
Date: Sat, 16 Apr 2016 10:14:26 -0400
Subject: [squid-users] Transition from Squid to bluecoat ProxySG
In-Reply-To: <CAP3=H7vfA4WBAPkxUNutdxLZdjejZ8unr3vTbi1TicvVBpBxbQ@mail.gmail.com>
References: <CAP3=H7vfA4WBAPkxUNutdxLZdjejZ8unr3vTbi1TicvVBpBxbQ@mail.gmail.com>
Message-ID: <571248C2.8010700@gmail.com>

On 04/16/2016 09:39 AM, asad wrote:
> Hello,
>
> I'm in the process of helping a friend who works in a bank whose 
> management have decided to move from Squid infra to bluecoat PorxySG 
> solution.
>
> I want to know what are the pitfalls that must be imagined from 
> project management as on technical end.
>
> Few info that I'm allowed to share is
>        users are 1000 and bandwidth is 40 Mbps.
>        Between BCP and HQ site active passive setup/configuration.
>
> There are good and bad of each tech, but when there is mgt executive 
> decision there leaves not much gap of debating what is better. I'm 
> wishing anyone from the community who has been involved in such a task 
> in past , current or in near future.
>
> Thanks
>
> regards
> asad
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
i support blue coat proxies professionally, and run squid proxies 
personally.  while i have not migrated from one to the other, i have 
done data center relocation work where 4 existing sites with proxy 
footprints were consolidated into two new sites.  i had to support 
physically moving 14 production proxies to the new sites without 
interrupting internet access for 30k+ users and myriads of production 
applications that use the proxies to access internet resources.

can you explain what you mean by active / passive config?  i take this 
to mean some sort of failover mechanism is used.  are you using load 
balancing to manage this?  if you are, your cutover can be a lot easier, 
as  you would simply insert the blue coat into the load balanced pool 
and assign traffic to it.

if you are using a proxy script or PAC file, and not load balancing, you 
can assign certain traffic to the blue coat in the PAC.  a lot of 
flexibility can be exercised in a PAC file, since you dictate the logic.

i had the luxury of both load balancing and PAC file in order to manage 
my moves.  i did a little of both the above to manage traffic levels 
during transition periods.  i was able to move the initial devices 
because one site had newer gear with plenty of performance head room.  
then it was a cycle of reassign traffic, move more hardware, lather, 
rinse and repeat...

i would suggest you build and test your new gear extensively before 
starting any cutover.  develop a build process and separate validation 
process to ensure consistency and accuracy of the build. check interface 
settings, routing, dns settings, authentication pieces and any 
particular items in your environment that is considered a show-stopper, 
unacceptable risk or gap in security posture.  have technical personnel 
use the blue coat proxies for a couple days to a week before giving the 
general user audience access to them.  you can get their input about 
issues and performance and tweak things.

recommend that the environment use both load balancing and a PAC file, 
if you can convince the mgmt.  sell them one buying more capable 
hardware than you need, because failover events such as ISP (as opposed 
to WAN) outages could be almost seamless and the additional load of 
users pushed to an alternate device in the load balanced pool wont bring 
down the box.  this assumes that you maintain the active / passive 
config i think you have.  sell them on reliability, stability and high 
availability.

i am interested to hear what decisions are made and how things progress 
for you.  best of luck.

brendan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160416/4a136d49/attachment.htm>

From squid3 at treenet.co.nz  Sat Apr 16 14:49:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 Apr 2016 02:49:06 +1200
Subject: [squid-users] High CPU usage
In-Reply-To: <CAL1kE9C6RuXUHe_d3era8smb7EjqBKY7Yty8g19KopZ_C+kBzA@mail.gmail.com>
References: <CAL1kE9DAt=VBphGKywsE4-Yzy9pM2N5Ej_BwdJmh0C5LzzEm3Q@mail.gmail.com>
 <5710CF08.7060603@treenet.co.nz>
 <CAL1kE9C6RuXUHe_d3era8smb7EjqBKY7Yty8g19KopZ_C+kBzA@mail.gmail.com>
Message-ID: <571250E2.9050103@treenet.co.nz>

On 16/04/2016 6:41 a.m., Mohammad Sadegh Nasiri wrote:
> Thanks Amos for your reply.
> 
> 
> This reaches 800 Mbps with Squid still spending a measurable chunk of its
>> time (~30%) waiting for something to do.
> 
> How do you discovered to this numbers (800Mbps and ~30%)?

I explained the 800 Mbps in my last post. "adding these together" right
under the set of values which were added together.

~30% CPU is 100% CPU - 67% CPU. The difference of CPU rates in your traces.

> 
> What is median_select_fds means?

It is the average (median) number of sockets (FD) which the kernel tells
Squid need some processing done (using CPU) when Squid performs an I/O
select(2) to find that out.

> 
> HW info:
> Server model: ProLiant DL380 Gen8]
> CPU: Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz
> RAM: 128GB
> Disks: Samsung SSD [1TB+512GB+512GB]
> 
> I'm suspicious to Squid configuration or I/O (DMA, RAID)

If RAID is having any effect it would be making your CPU baseline higher
than it would be without RAID. And during a overload peak slowing down
the recovery. It is unlikely to be the direct cause of the peak event.

The bottleneck for your system appears to be concurrent transactions and
CPU. The amount of work the CPU used by Squid can do each I/O cycle is
less than the work the active FD are needing done.

If you think it is configuration related, then show the config and I/we
can point at things that are making that CPU work exist.

Amos



From yvoinov at gmail.com  Sat Apr 16 16:50:36 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 16 Apr 2016 22:50:36 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <57121F79.2040607@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
Message-ID: <57126D5C.2020900@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
3.5.16 on *NIX is also has this issue.

Only 3.5.16 Win64 is works like sharm.

16.04.16 17:18, Yuri Voinov ?????:
> mozilla.org now has the same issue on Squid 4 like CloudFlare:
>
> https://i1.someimage.com/P03GmSY.png
>
> All ok but handshake does not complete:
>
> root @ cthulhu / # /usr/local/bin/openssl s_client -connect
mozilla.org:443 -CApath /etc/ope/csw/ssl/certs
> CONNECTED(00000003)
> depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert
High Assurance EV Root CA
> verify return:1
> depth=1 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert
High Assurance EV CA-1
> verify return:1
> depth=0 businessCategory = Private Organization,
1.3.6.1.4.1.311.60.2.1.3 = US, 1.3.6.1.4.1.311.60.2.1.2 = California,
serialNumber = C2543436, street = 650 Castro St Ste 300, postalCode =
94041, C = US, ST = California, L = Mountain View, O = Mozilla
Foundation, CN = www.mozilla.org
> verify return:1
> ---
> Certificate chain
>  0 s:/businessCategory=Private
Organization/1.3.6.1.4.1.311.60.2.1.3=US/1.3.6.1.4.1.311.60.2.1.2=California/serialNumber=C2543436/street=650
Castro St Ste 300/postalCode=94041/C=US/ST=California/L=Mountain
View/O=Mozilla Foundation/CN=www.mozilla.org
>    i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High
Assurance EV CA-1
>  1 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High
Assurance EV CA-1
>    i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High
Assurance EV Root CA
> ---
> Server certificate
> -----BEGIN CERTIFICATE-----
> MIIHWTCCBkGgAwIBAgIQBQ5gs8e9nTbV62rD+8G95jANBgkqhkiG9w0BAQUFADBp
> MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3
> d3cuZGlnaWNlcnQuY29tMSgwJgYDVQQDEx9EaWdpQ2VydCBIaWdoIEFzc3VyYW5j
> ZSBFViBDQS0xMB4XDTE1MTEyNDAwMDAwMFoXDTE2MTIyOTEyMDAwMFowggEFMR0w
> GwYDVQQPDBRQcml2YXRlIE9yZ2FuaXphdGlvbjETMBEGCysGAQQBgjc8AgEDEwJV
> UzEbMBkGCysGAQQBgjc8AgECEwpDYWxpZm9ybmlhMREwDwYDVQQFEwhDMjU0MzQz
> NjEeMBwGA1UECRMVNjUwIENhc3RybyBTdCBTdGUgMzAwMQ4wDAYDVQQREwU5NDA0
> MTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1v
> dW50YWluIFZpZXcxGzAZBgNVBAoTEk1vemlsbGEgRm91bmRhdGlvbjEYMBYGA1UE
> AxMPd3d3Lm1vemlsbGEub3JnMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC
> AQEAuHHB4NGHII28Vm4WrSFjZN5YM0bEBuVbPcwbwBAEinRe9Iwwwye359vVs24o
> 5YRnSkjkJYfrXHEb8f836GXBotN1xcxsrOi7brTJcA4qeE5ntby6V6wdlxKEy5mt
> 2Fd9P7wl9v1UlXmHyFxpF9UlDDoSuiDGUO+Q0U9lipKOrKoA3Q1Uzp/ntwrZL01B
> V4AUgTQf6b1HLu3ZD8CUG9xrq4Isi4OIMaJQX+kVwrQqxLe3Ahmjq9uP2iXAiLf7
> aVluTyFgfAfvv1/pf0193zgQoe0oGDReh5/QrbO6j+XtV2sHDnDen+mQO2/GNwET
> fQPCIKIroGf4JUnftt7Cwz1KmQIDAQABo4IDXTCCA1kwHwYDVR0jBBgwFoAUTFjL
> JfBBT1L0KMiBQ5umqKDmkuUwHQYDVR0OBBYEFIPU1A81pLqLvmE3YsGWDTbHxzc5
> MCcGA1UdEQQgMB6CD3d3dy5tb3ppbGxhLm9yZ4ILbW96aWxsYS5vcmcwDgYDVR0P
> AQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEFBQcDAjBjBgNVHR8E
> XDBaMCugKaAnhiVodHRwOi8vY3JsMy5kaWdpY2VydC5jb20vZXZjYTEtZzUuY3Js
> MCugKaAnhiVodHRwOi8vY3JsNC5kaWdpY2VydC5jb20vZXZjYTEtZzUuY3JsMEsG
> A1UdIAREMEIwNwYJYIZIAYb9bAIBMCowKAYIKwYBBQUHAgEWHGh0dHBzOi8vd3d3
> LmRpZ2ljZXJ0LmNvbS9DUFMwBwYFZ4EMAQEwfQYIKwYBBQUHAQEEcTBvMCQGCCsG
> AQUFBzABhhhodHRwOi8vb2NzcC5kaWdpY2VydC5jb20wRwYIKwYBBQUHMAKGO2h0
> dHA6Ly9jYWNlcnRzLmRpZ2ljZXJ0LmNvbS9EaWdpQ2VydEhpZ2hBc3N1cmFuY2VF
> VkNBLTEuY3J0MAwGA1UdEwEB/wQCMAAwggF+BgorBgEEAdZ5AgQCBIIBbgSCAWoB
> aAB2AKS5CZC0GFgUh7sTosxncAo8NZgE+RvfuON3zQ7IDdwQAAABUTfFoGwAAAQD
> AEcwRQIgPZSqJS9xxOfr4sFkB73ocAWRnHK4/fgEkIvVubEtLwkCIQDIXB59Y1A4
> SgdJPmwIeRXjshq7jkmz7mgc0Nap53UG2AB2AGj2mPgfZIK+OozuuSgdTPxxUV1n
> k9RE0QpnrLtPT/vEAAABUTfFoJ0AAAQDAEcwRQIgUGvntxlKFSY7iveb6BCCdGhs
> 28DU5EF1TcFH4DHAnX0CIQDstuSiKY0gs3YJ6x4S+GOxuK7V/8zEhNF7vEYADCPX
> 6QB2AFYUBpov18Ls0/XhvUSyPsdGdrm8mRFcwO+UmFXWidDdAAABUTfFoVUAAAQD
> AEcwRQIhAInj1bkZoUGmg39jrIN0z9tAmjPPc39UW3X/xP49q3C1AiBLG+iv0BKe
> sbUPcoFF6DYlr+rp7fbplMYNT60UnVAlrTANBgkqhkiG9w0BAQUFAAOCAQEAvc7m
> sTP08cANcDPsPyEKXAvv9CW1ugYLUK4XC/JylqCiluDYbgazfjRTraTbDNlmXk+Y
> SEVBFGJX005hIhn/qztA/+p2XEcnMJWy1cyCflxdQKWn51XGhN1jlTAa31Ps7WI/
> YPAL2taqn5EBDtUFT5790/ve09Fnyhh6elnXuy9ujJRCuVn+oXTtKlhVrIjEjzZ9
> zFyyv3SaTWX9xb9MBfOPaO6cGihHjhAo4mj3X6fJsvEnNGqs/NJXCpwiprjbidjL
> yeKPUhN2/hSSDAmzFd4X+B1Xx7cUXWkJHQrfosFSoiRDYmX/JnAgr0ObibjKuWPV
> 9Rs6HCB6QKS3grfX/w==
> -----END CERTIFICATE-----
> subject=/businessCategory=Private
Organization/1.3.6.1.4.1.311.60.2.1.3=US/1.3.6.1.4.1.311.60.2.1.2=California/serialNumber=C2543436/street=650
Castro St Ste 300/postalCode=94041/C=US/ST=California/L=Mountain
View/O=Mozilla Foundation/CN=www.mozilla.org
> issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High
Assurance EV CA-1
> ---
> No client certificate CA names sent
> ---
> SSL handshake has read 4163 bytes and written 446 bytes
> ---
> New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES128-GCM-SHA256
> Server public key is 2048 bit
> Secure Renegotiation IS supported
> Compression: NONE
> Expansion: NONE
> No ALPN negotiated
> SSL-Session:
>     Protocol  : TLSv1.2
>     Cipher    : ECDHE-RSA-AES128-GCM-SHA256
>     Session-ID:
E32E470329327A2E39ADDEB384FBB9D351103F1BBA798A47EBFFF121C5001CCA
>     Session-ID-ctx:
>     Master-Key:
D2C6E671DB649951C999E1DF83DC038852215500C57F81E4660AFB7ED96039C76E8A384F3ED78A44BBD129C56DD6F45B
>     Start Time: 1460805325
>     Timeout   : 300 (sec)
>     Verify return code: 0 (ok)
> ---
>
> access.log also got NONE/503:
>
> 1460805179.734      0 192.168.100.103 NONE/503 3944 GET
https://www.mozilla.org/favicon.ico - HIER_NONE/- text/html
>
> and cache.log:
>
> 2016/04/16 17:12:59 kid1| Error negotiating SSL on FD 56:
error:00000000:lib(0):func(0):reason(0) (5/0/0)
>
> 15.04.16 15:17, Amos Jeffries ?????:
>> On 15/04/2016 6:31 a.m., Yuri Voinov wrote:
>>> Ok, nobody.
>>>
>>> Well.
>>>
>>> I've done my own research.
>>>
>>> My suggestions:
>>>
>>> CloudFlare now uses it's own custom OpenSSL 1.0.2 with very custom
>>> patches with CHACHA Poly support.
>>>
>>> This patches is not in upstream. Moreover, OpenSSL team no plans in the
>>> foreseeable future to support the latest ciphers.
>>>
>>> So, Squid 4 can't handshake TLS with CF right now. Possible it is Squid
>>> 4.x branch bug. Because of 3.5.x does CF handshake.
>>>
>>> LibreSSL does CHACHA right now.
>>>
>>> The question is:
>>>
>>> Amos, does Squid can support LibreSSL and, if no, when you plan to
support?
>> Yes Squid does support LibreSSL. You can build against it with the
>> --with-openssl configure option, maybe using a =path parameter to ensure
>> it dont find an OpenSSL install.
>>
>> The difference between LibreSSL and OpenSSL is likely to be more visible
>> in the squid.conf settings that it will accept and those that it
>> rejects. They are still basically the same but I know that the LibreSSL
>> guys are being very proactive removing old things like SSLv2 support. So
>> those config options wont work even when Squid-3.5 normally would
>> accepts them with OpenSSL.
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXEm1cAAoJENNXIZxhPexGWV8IALf6vko/r2iYJzwqnubial+w
JBgJQrZHnVLxXHhDJjBEwiJjQtFwZz61drJ60a6mV4TJn6VS1D0pFSbLkdiatUpG
jmWMKq5axZd4rWtH4H8ukF1l849hA1+GQ8Y/N586NMXcRmRBbhfG9vd312Y2i6cv
ShQLg5v5YIW5OS9SFGVY/8rV6njBhvBn+N0RSoXRgOSow3NT9oMihjDmU0ZHIh7o
uM/3dWG02xJej5yjF3ewNUOLIBIvl10HvDumG3AdhA+9h+1lf+ycZ2HzSui0P185
dFlVo4foVam+vBF9TIY2AKVgOTFltkE597PxS6W+WcC1MUBhDOlnz8AU90Bpb64=
=Mekx
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160416/9ea90314/attachment.key>

From yvoinov at gmail.com  Sat Apr 16 16:55:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 16 Apr 2016 22:55:31 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <57126D5C.2020900@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com>
Message-ID: <57126E83.70600@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
So.

Still has no ideas?

16.04.16 22:50, Yuri Voinov ?????:
>
> 3.5.16 on *NIX is also has this issue.
>
> Only 3.5.16 Win64 is works like sharm.
>
> 16.04.16 17:18, Yuri Voinov ?????:
> > mozilla.org now has the same issue on Squid 4 like CloudFlare:
>
> > https://i1.someimage.com/P03GmSY.png
>
> > All ok but handshake does not complete:
>
> > root @ cthulhu / # /usr/local/bin/openssl s_client -connect
> mozilla.org:443 -CApath /etc/ope/csw/ssl/certs
> > CONNECTED(00000003)
> > depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert
> High Assurance EV Root CA
> > verify return:1
> > depth=1 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert
> High Assurance EV CA-1
> > verify return:1
> > depth=0 businessCategory = Private Organization,
> 1.3.6.1.4.1.311.60.2.1.3 = US, 1.3.6.1.4.1.311.60.2.1.2 = California,
> serialNumber = C2543436, street = 650 Castro St Ste 300, postalCode =
> 94041, C = US, ST = California, L = Mountain View, O = Mozilla
> Foundation, CN = www.mozilla.org
> > verify return:1
> > ---
> > Certificate chain
> >  0 s:/businessCategory=Private
>
Organization/1.3.6.1.4.1.311.60.2.1.3=US/1.3.6.1.4.1.311.60.2.1.2=California/serialNumber=C2543436/street=650
> Castro St Ste 300/postalCode=94041/C=US/ST=California/L=Mountain
> View/O=Mozilla Foundation/CN=www.mozilla.org
> >    i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High
> Assurance EV CA-1
> >  1 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High
> Assurance EV CA-1
> >    i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High
> Assurance EV Root CA
> > ---
> > Server certificate
> > -----BEGIN CERTIFICATE-----
> > MIIHWTCCBkGgAwIBAgIQBQ5gs8e9nTbV62rD+8G95jANBgkqhkiG9w0BAQUFADBp
> > MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3
> > d3cuZGlnaWNlcnQuY29tMSgwJgYDVQQDEx9EaWdpQ2VydCBIaWdoIEFzc3VyYW5j
> > ZSBFViBDQS0xMB4XDTE1MTEyNDAwMDAwMFoXDTE2MTIyOTEyMDAwMFowggEFMR0w
> > GwYDVQQPDBRQcml2YXRlIE9yZ2FuaXphdGlvbjETMBEGCysGAQQBgjc8AgEDEwJV
> > UzEbMBkGCysGAQQBgjc8AgECEwpDYWxpZm9ybmlhMREwDwYDVQQFEwhDMjU0MzQz
> > NjEeMBwGA1UECRMVNjUwIENhc3RybyBTdCBTdGUgMzAwMQ4wDAYDVQQREwU5NDA0
> > MTELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDU1v
> > dW50YWluIFZpZXcxGzAZBgNVBAoTEk1vemlsbGEgRm91bmRhdGlvbjEYMBYGA1UE
> > AxMPd3d3Lm1vemlsbGEub3JnMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC
> > AQEAuHHB4NGHII28Vm4WrSFjZN5YM0bEBuVbPcwbwBAEinRe9Iwwwye359vVs24o
> > 5YRnSkjkJYfrXHEb8f836GXBotN1xcxsrOi7brTJcA4qeE5ntby6V6wdlxKEy5mt
> > 2Fd9P7wl9v1UlXmHyFxpF9UlDDoSuiDGUO+Q0U9lipKOrKoA3Q1Uzp/ntwrZL01B
> > V4AUgTQf6b1HLu3ZD8CUG9xrq4Isi4OIMaJQX+kVwrQqxLe3Ahmjq9uP2iXAiLf7
> > aVluTyFgfAfvv1/pf0193zgQoe0oGDReh5/QrbO6j+XtV2sHDnDen+mQO2/GNwET
> > fQPCIKIroGf4JUnftt7Cwz1KmQIDAQABo4IDXTCCA1kwHwYDVR0jBBgwFoAUTFjL
> > JfBBT1L0KMiBQ5umqKDmkuUwHQYDVR0OBBYEFIPU1A81pLqLvmE3YsGWDTbHxzc5
> > MCcGA1UdEQQgMB6CD3d3dy5tb3ppbGxhLm9yZ4ILbW96aWxsYS5vcmcwDgYDVR0P
> > AQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEFBQcDAjBjBgNVHR8E
> > XDBaMCugKaAnhiVodHRwOi8vY3JsMy5kaWdpY2VydC5jb20vZXZjYTEtZzUuY3Js
> > MCugKaAnhiVodHRwOi8vY3JsNC5kaWdpY2VydC5jb20vZXZjYTEtZzUuY3JsMEsG
> > A1UdIAREMEIwNwYJYIZIAYb9bAIBMCowKAYIKwYBBQUHAgEWHGh0dHBzOi8vd3d3
> > LmRpZ2ljZXJ0LmNvbS9DUFMwBwYFZ4EMAQEwfQYIKwYBBQUHAQEEcTBvMCQGCCsG
> > AQUFBzABhhhodHRwOi8vb2NzcC5kaWdpY2VydC5jb20wRwYIKwYBBQUHMAKGO2h0
> > dHA6Ly9jYWNlcnRzLmRpZ2ljZXJ0LmNvbS9EaWdpQ2VydEhpZ2hBc3N1cmFuY2VF
> > VkNBLTEuY3J0MAwGA1UdEwEB/wQCMAAwggF+BgorBgEEAdZ5AgQCBIIBbgSCAWoB
> > aAB2AKS5CZC0GFgUh7sTosxncAo8NZgE+RvfuON3zQ7IDdwQAAABUTfFoGwAAAQD
> > AEcwRQIgPZSqJS9xxOfr4sFkB73ocAWRnHK4/fgEkIvVubEtLwkCIQDIXB59Y1A4
> > SgdJPmwIeRXjshq7jkmz7mgc0Nap53UG2AB2AGj2mPgfZIK+OozuuSgdTPxxUV1n
> > k9RE0QpnrLtPT/vEAAABUTfFoJ0AAAQDAEcwRQIgUGvntxlKFSY7iveb6BCCdGhs
> > 28DU5EF1TcFH4DHAnX0CIQDstuSiKY0gs3YJ6x4S+GOxuK7V/8zEhNF7vEYADCPX
> > 6QB2AFYUBpov18Ls0/XhvUSyPsdGdrm8mRFcwO+UmFXWidDdAAABUTfFoVUAAAQD
> > AEcwRQIhAInj1bkZoUGmg39jrIN0z9tAmjPPc39UW3X/xP49q3C1AiBLG+iv0BKe
> > sbUPcoFF6DYlr+rp7fbplMYNT60UnVAlrTANBgkqhkiG9w0BAQUFAAOCAQEAvc7m
> > sTP08cANcDPsPyEKXAvv9CW1ugYLUK4XC/JylqCiluDYbgazfjRTraTbDNlmXk+Y
> > SEVBFGJX005hIhn/qztA/+p2XEcnMJWy1cyCflxdQKWn51XGhN1jlTAa31Ps7WI/
> > YPAL2taqn5EBDtUFT5790/ve09Fnyhh6elnXuy9ujJRCuVn+oXTtKlhVrIjEjzZ9
> > zFyyv3SaTWX9xb9MBfOPaO6cGihHjhAo4mj3X6fJsvEnNGqs/NJXCpwiprjbidjL
> > yeKPUhN2/hSSDAmzFd4X+B1Xx7cUXWkJHQrfosFSoiRDYmX/JnAgr0ObibjKuWPV
> > 9Rs6HCB6QKS3grfX/w==
> > -----END CERTIFICATE-----
> > subject=/businessCategory=Private
>
Organization/1.3.6.1.4.1.311.60.2.1.3=US/1.3.6.1.4.1.311.60.2.1.2=California/serialNumber=C2543436/street=650
> Castro St Ste 300/postalCode=94041/C=US/ST=California/L=Mountain
> View/O=Mozilla Foundation/CN=www.mozilla.org
> > issuer=/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert High
> Assurance EV CA-1
> > ---
> > No client certificate CA names sent
> > ---
> > SSL handshake has read 4163 bytes and written 446 bytes
> > ---
> > New, TLSv1/SSLv3, Cipher is ECDHE-RSA-AES128-GCM-SHA256
> > Server public key is 2048 bit
> > Secure Renegotiation IS supported
> > Compression: NONE
> > Expansion: NONE
> > No ALPN negotiated
> > SSL-Session:
> >     Protocol  : TLSv1.2
> >     Cipher    : ECDHE-RSA-AES128-GCM-SHA256
> >     Session-ID:
> E32E470329327A2E39ADDEB384FBB9D351103F1BBA798A47EBFFF121C5001CCA
> >     Session-ID-ctx:
> >     Master-Key:
>
D2C6E671DB649951C999E1DF83DC038852215500C57F81E4660AFB7ED96039C76E8A384F3ED78A44BBD129C56DD6F45B
> >     Start Time: 1460805325
> >     Timeout   : 300 (sec)
> >     Verify return code: 0 (ok)
> > ---
>
> > access.log also got NONE/503:
>
> > 1460805179.734      0 192.168.100.103 NONE/503 3944 GET
> https://www.mozilla.org/favicon.ico - HIER_NONE/- text/html
>
> > and cache.log:
>
> > 2016/04/16 17:12:59 kid1| Error negotiating SSL on FD 56:
> error:00000000:lib(0):func(0):reason(0) (5/0/0)
>
> > 15.04.16 15:17, Amos Jeffries ?????:
> >> On 15/04/2016 6:31 a.m., Yuri Voinov wrote:
> >>> Ok, nobody.
> >>>
> >>> Well.
> >>>
> >>> I've done my own research.
> >>>
> >>> My suggestions:
> >>>
> >>> CloudFlare now uses it's own custom OpenSSL 1.0.2 with very custom
> >>> patches with CHACHA Poly support.
> >>>
> >>> This patches is not in upstream. Moreover, OpenSSL team no plans
in the
> >>> foreseeable future to support the latest ciphers.
> >>>
> >>> So, Squid 4 can't handshake TLS with CF right now. Possible it is
Squid
> >>> 4.x branch bug. Because of 3.5.x does CF handshake.
> >>>
> >>> LibreSSL does CHACHA right now.
> >>>
> >>> The question is:
> >>>
> >>> Amos, does Squid can support LibreSSL and, if no, when you plan to
> support?
> >> Yes Squid does support LibreSSL. You can build against it with the
> >> --with-openssl configure option, maybe using a =path parameter to
ensure
> >> it dont find an OpenSSL install.
> >>
> >> The difference between LibreSSL and OpenSSL is likely to be more
visible
> >> in the squid.conf settings that it will accept and those that it
> >> rejects. They are still basically the same but I know that the LibreSSL
> >> guys are being very proactive removing old things like SSLv2
support. So
> >> those config options wont work even when Squid-3.5 normally would
> >> accepts them with OpenSSL.
> >>
> >> Amos
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXEm6DAAoJENNXIZxhPexGcRgIAKsvCRwsmEyeIKeFy6RN+Bui
DKzfFn5iOLb9IZeG+dBAyDKVXeOey5IHqP+ACwQIjvxdh2NPNVbVvryqZohjCf6n
mMF5RPrSrpi6pxiN3ptC5HDlWrI3DmQ1nqhMm/gvO0Iw2WYNLyQlxD7SD03f43IX
uKJdW+Q2REO5ulSG70mY3WT+D+02tR3WHVXxhs6na+xts+y7Yw9cO8NNxuhk+fqK
LfWc1LWevwmBLEsXSiosfQxwRmpRA2e83jRbg/MbmqUjJHA3Gpbw2q3n3Wfh7cJJ
QgYAuzpAk/fLHeKQ2sWwUKP+eD+4Lt7SrWL/8jWEYZ4npO6jOzh+u2F5XZlPSzA=
=/UXE
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160416/742dfb3a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160416/742dfb3a/attachment.key>

From sebelk at gmail.com  Sat Apr 16 23:10:49 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Sat, 16 Apr 2016 20:10:49 -0300
Subject: [squid-users] Browser circunvents acl's blocking https (intercept
	mode)
Message-ID: <CABZC=5yTw0v=ec4=TvwrqZ3NegRdTwjkxg7DoeVMJFHvjULWMA@mail.gmail.com>

Hi,

I cannot block some sites using squid 3.4.8, this the configuration. On
Firefox, blocking works, browser says:

`Error code: SSL_ERROR_RX_RECORD_TOO_LONG`

But on Chromium Versi?n 49.0.2623.108, browser is not affected by the
blocking acl's, despite access_logs says:

````
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443
HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request
HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443
HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443
HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443
HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request
HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443
HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "
%BA%5D%B71A%E2%90C%BD0:Ep%82%99%FE%88 HTTP/0.0" 400 3638 "-" "-"
TAG_NONE:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443
HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request
HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443
HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request
HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] " %11Tf%03%A4%83%F3%8C%EE
HTTP/0.0" 400 3614 "-" "-" TAG_NONE:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request
HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:23 -0300] "CONNECT 172.217.29.14:443
HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
192.168.80.250 - - [16/Apr/2016:19:53:23 -0300] "NONE error:invalid-request
HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
````

Debugging I've found this in cache.log:

````
2016/04/16 20:00:21.924 kid1| client_side.cc(864) swanSong: local=
172.217.28.225:443 remote=192.168.80.250:55068 flags=33
2016/04/16 20:00:21.925 kid1| Checklist.cc(62) preCheck: 0x7eff3754
checking fast ACLs
2016/04/16 20:00:21.925 kid1| Acl.cc(157) matches: checking access_log
daemon:/var/log/squid3/access.log
2016/04/16 20:00:21.925 kid1| Acl.cc(157) matches: checking (access_log
daemon:/var/log/squid3/access.log line)
2016/04/16 20:00:21.925 kid1| Acl.cc(177) matches: checked: (access_log
daemon:/var/log/squid3/access.log line) = 1
2016/04/16 20:00:21.926 kid1| Acl.cc(177) matches: checked: access_log
daemon:/var/log/squid3/access.log = 1
2016/04/16 20:00:21.926 kid1| Checklist.cc(55) markFinished: 0x7eff3754
answer ALLOWED for match
````

Please could you help? Am I missing something? Below, my configuration:

````
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
acl tvsamsung src 192.168.80.160
acl sarmiento src 192.168.80.248
acl netbook src 192.168.80.245
acl dompermitidos dstdomain "/etc/squid3/rules/whitelistdom"
acl streaming dstdomain "/etc/squid3/rules/streaming"
acl test  dstdomain .debian.org
acl streamingips dst "/etc/squid3/rules/streamingips"
acl sergiocel src 192.168.80.249
acl tiempojuanse time SMTWHFA 10:00-13:00
acl tiempojuanse time SMTWHFA 16:00-22:00
acl yt dstdomain .youtube.com
acl facebook dstdomain .facebook.com
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
always_direct allow all
ssl_bump none all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
http_access allow  tvsamsung
http_access deny yt
http_access allow facebook
http_access deny  streaming
http_access deny  streamingips
http_access allow dompermitidos
http_access allow  sarmiento
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128
http_port 3127 intercept
https_port 8080 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/home/proxy/ssl_cert/example.com.cert
key=/home/proxy/ssl_cert/example.com.private
sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/spool/squid3_ssldb -M 4MB
access_log daemon:/var/log/squid3/access.log combined
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
````

Thanks in advance!
-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160416/0654e284/attachment.htm>

From jok at spikes.com  Sun Apr 17 01:53:00 2016
From: jok at spikes.com (Jok Thuau)
Date: Sat, 16 Apr 2016 18:53:00 -0700
Subject: [squid-users] Browser circunvents acl's blocking https
	(intercept mode)
In-Reply-To: <CABZC=5yTw0v=ec4=TvwrqZ3NegRdTwjkxg7DoeVMJFHvjULWMA@mail.gmail.com>
References: <CABZC=5yTw0v=ec4=TvwrqZ3NegRdTwjkxg7DoeVMJFHvjULWMA@mail.gmail.com>
Message-ID: <70483071-2612-49EC-8994-21C6F35D9170@spikes.com>

Blocking YouTube (appear to be on your list) is tricky, if the browser is chrome:

https://en.m.wikipedia.org/wiki/QUIC

If you click on the 'green lock' and look at the connection you will see it's not using https (funnily enough, the ads there do!).

Look at the wiki for more info on how to block QUIC.

> On Apr 16, 2016, at 4:10 PM, Sergio Belkin <sebelk at gmail.com> wrote:
> 
> Hi,
> 
> I cannot block some sites using squid 3.4.8, this the configuration. On Firefox, blocking works, browser says:
> 
> `Error code: SSL_ERROR_RX_RECORD_TOO_LONG`
> 
> But on Chromium Versi?n 49.0.2623.108, browser is not affected by the blocking acl's, despite access_logs says:
> 
> ````
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] " %BA%5D%B71A%E2%90C%BD0:Ep%82%99%FE%88 HTTP/0.0" 400 3638 "-" "-" TAG_NONE:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] " %11Tf%03%A4%83%F3%8C%EE HTTP/0.0" 400 3614 "-" "-" TAG_NONE:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:23 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.80.250 - - [16/Apr/2016:19:53:23 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
> ````
> 
> Debugging I've found this in cache.log:
> 
> ````
> 2016/04/16 20:00:21.924 kid1| client_side.cc(864) swanSong: local=172.217.28.225:443 remote=192.168.80.250:55068 flags=33
> 2016/04/16 20:00:21.925 kid1| Checklist.cc(62) preCheck: 0x7eff3754 checking fast ACLs
> 2016/04/16 20:00:21.925 kid1| Acl.cc(157) matches: checking access_log daemon:/var/log/squid3/access.log
> 2016/04/16 20:00:21.925 kid1| Acl.cc(157) matches: checking (access_log daemon:/var/log/squid3/access.log line)
> 2016/04/16 20:00:21.925 kid1| Acl.cc(177) matches: checked: (access_log daemon:/var/log/squid3/access.log line) = 1
> 2016/04/16 20:00:21.926 kid1| Acl.cc(177) matches: checked: access_log daemon:/var/log/squid3/access.log = 1
> 2016/04/16 20:00:21.926 kid1| Checklist.cc(55) markFinished: 0x7eff3754 answer ALLOWED for match
> ````
> 
> Please could you help? Am I missing something? Below, my configuration:
> 
> ````
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> acl tvsamsung src 192.168.80.160
> acl sarmiento src 192.168.80.248
> acl netbook src 192.168.80.245
> acl dompermitidos dstdomain "/etc/squid3/rules/whitelistdom"
> acl streaming dstdomain "/etc/squid3/rules/streaming"
> acl test  dstdomain .debian.org
> acl streamingips dst "/etc/squid3/rules/streamingips"
> acl sergiocel src 192.168.80.249
> acl tiempojuanse time SMTWHFA 10:00-13:00
> acl tiempojuanse time SMTWHFA 16:00-22:00
> acl yt dstdomain .youtube.com
> acl facebook dstdomain .facebook.com
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> always_direct allow all
> ssl_bump none all
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> http_access allow  tvsamsung
> http_access deny yt
> http_access allow facebook
> http_access deny  streaming
> http_access deny  streamingips
> http_access allow dompermitidos
> http_access allow  sarmiento
> http_access allow localnet
> http_access allow localhost
> http_access deny all
> http_port 3128
> http_port 3127 intercept
> https_port 8080 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/home/proxy/ssl_cert/example.com.cert key=/home/proxy/ssl_cert/example.com.private
> sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/spool/squid3_ssldb -M 4MB
> access_log daemon:/var/log/squid3/access.log combined
> coredump_dir /var/spool/squid3
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> ````
> 
> Thanks in advance!
> -- 
> --
> Sergio Belkin
> LPIC-2 Certified - http://www.lpi.org
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160416/fd385694/attachment.htm>

From eliezer at ngtech.co.il  Sun Apr 17 08:58:12 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 17 Apr 2016 11:58:12 +0300
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <57126D5C.2020900@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com>
Message-ID: <57135024.1020503@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160417/314cef4b/attachment.htm>

From squid3 at treenet.co.nz  Sun Apr 17 09:11:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 Apr 2016 21:11:28 +1200
Subject: [squid-users] Browser circunvents acl's blocking https
 (intercept mode)
In-Reply-To: <70483071-2612-49EC-8994-21C6F35D9170@spikes.com>
References: <CABZC=5yTw0v=ec4=TvwrqZ3NegRdTwjkxg7DoeVMJFHvjULWMA@mail.gmail.com>
 <70483071-2612-49EC-8994-21C6F35D9170@spikes.com>
Message-ID: <57135340.5080503@treenet.co.nz>

On 17/04/2016 1:53 p.m., Jok Thuau wrote:
> Blocking YouTube (appear to be on your list) is tricky, if the browser is chrome:
> 
> https://en.m.wikipedia.org/wiki/QUIC
> 
> If you click on the 'green lock' and look at the connection you will see it's not using https (funnily enough, the ads there do!).
> 
> Look at the wiki for more info on how to block QUIC.
> 
>> On Apr 16, 2016, at 4:10 PM, Sergio Belkin wrote:
>>
>> Hi,
>>
>> I cannot block some sites using squid 3.4.8,

Please upgrade to at least the latest Squid version for SSL-Bump
functionality.

SSL-Bump is part of an "arms race" going on in TLS and things are still
quite volatile. It is a lot of work just to keep up so we are not fixing
TLS/SSL bugs unless they are still present in the latest 3.5 or 4.x
releases, and debugging needs to be done using those releases.


> this the configuration. On Firefox, blocking works, browser says:
>>
>> `Error code: SSL_ERROR_RX_RECORD_TOO_LONG`
>>

What you are doing there is not so much "blocking" as completely
screwing up the TLS protocol traffic by injecting garbage into the
binary data stream. The browser is complaining about that. It is
possibly also accepting some of the garbage as TLS features being
negotiated - which is highly dangerous.


>> But on Chromium Versi?n 49.0.2623.108, browser is not affected by the blocking acl's, despite access_logs says:
>>
>> ````
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] " %BA%5D%B71A%E2%90C%BD0:Ep%82%99%FE%88 HTTP/0.0" 400 3638 "-" "-" TAG_NONE:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] " %11Tf%03%A4%83%F3%8C%EE HTTP/0.0" 400 3614 "-" "-" TAG_NONE:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:17 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:23 -0300] "CONNECT 172.217.29.14:443 HTTP/1.1" 403 3443 "-" "-" TCP_DENIED:HIER_NONE
>> 192.168.80.250 - - [16/Apr/2016:19:53:23 -0300] "NONE error:invalid-request HTTP/0.0" 400 4042 "-" "-" TAG_NONE:HIER_NONE
>> ````
>>
>> Debugging I've found this in cache.log:
>>
>> ````
>> 2016/04/16 20:00:21.924 kid1| client_side.cc(864) swanSong: local=172.217.28.225:443 remote=192.168.80.250:55068 flags=33
>> 2016/04/16 20:00:21.925 kid1| Checklist.cc(62) preCheck: 0x7eff3754 checking fast ACLs
>> 2016/04/16 20:00:21.925 kid1| Acl.cc(157) matches: checking access_log daemon:/var/log/squid3/access.log
>> 2016/04/16 20:00:21.925 kid1| Acl.cc(157) matches: checking (access_log daemon:/var/log/squid3/access.log line)
>> 2016/04/16 20:00:21.925 kid1| Acl.cc(177) matches: checked: (access_log daemon:/var/log/squid3/access.log line) = 1
>> 2016/04/16 20:00:21.926 kid1| Acl.cc(177) matches: checked: access_log daemon:/var/log/squid3/access.log = 1
>> 2016/04/16 20:00:21.926 kid1| Checklist.cc(55) markFinished: 0x7eff3754 answer ALLOWED for match
>> ````

This only says that Squid is allowed to record the log messages to
access.log. Dont worry about that.


>>
>> Please could you help? Am I missing something? Below, my configuration:
>>
>> ````
>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>> acl SSL_ports port 443
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>> acl CONNECT method CONNECT
>> acl tvsamsung src 192.168.80.160
>> acl sarmiento src 192.168.80.248
>> acl netbook src 192.168.80.245
>> acl dompermitidos dstdomain "/etc/squid3/rules/whitelistdom"
>> acl streaming dstdomain "/etc/squid3/rules/streaming"
>> acl test  dstdomain .debian.org
>> acl streamingips dst "/etc/squid3/rules/streamingips"
>> acl sergiocel src 192.168.80.249
>> acl tiempojuanse time SMTWHFA 10:00-13:00
>> acl tiempojuanse time SMTWHFA 16:00-22:00
>> acl yt dstdomain .youtube.com
>> acl facebook dstdomain .facebook.com
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>> always_direct allow all

 always_direct is irrelevant. You are not using cache_peer.

>> ssl_bump none all

>> sslproxy_cert_error allow all
>> sslproxy_flags DONT_VERIFY_PEER

These disable all security TLS might have offered to outbound secure
https:// requests made by the proxy to upstream servers.

It has no relevance or effect on the traffic relayed by "ssl_bump none all".


>> http_access allow  tvsamsung
>> http_access deny yt
>> http_access allow facebook
>> http_access deny  streaming
>> http_access deny  streamingips
>> http_access allow dompermitidos
>> http_access allow  sarmiento
>> http_access allow localnet
>> http_access allow localhost
>> http_access deny all
>> http_port 3128
>> http_port 3127 intercept
>> https_port 8080 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/home/proxy/ssl_cert/example.com.cert key=/home/proxy/ssl_cert/example.com.private
>> sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/spool/squid3_ssldb -M 4MB

Since you have configured "ssl_bump none all" Squid does not participate
in any of the HTTPS traffic it intercepts. Just blindly relays it to
upstream whenever your https_access permit the CONNECT message with
raw-IP to happen.

That means none of these cert generation details are relevant. Only the
cert= and key= parameters are used when Squid needs to send an error to
the client. Your version does not appear to be doing that correctly anyway.


Like Jok mentioned Chrome is probably using QUIC protocol or one of the
other non-HTTPS is uses. If you upgrade to latest 3.5 Squid does some
header pruning to prevent that where possible. And Squid 4.x has a
feature to handle non-HTTPS and non-TLS protocols happening on port 443.

Also, if the raw-IP on the CONNECT message happens not to have
reverse-DNS matching your dstdomain list entries it will go through the
proxy. That could open you to a lot of issues from your clients being
infected or hijacked by scripts.

Amos



From squid3 at treenet.co.nz  Sun Apr 17 09:16:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 Apr 2016 21:16:24 +1200
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <57126E83.70600@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57126E83.70600@gmail.com>
Message-ID: <57135468.1010807@treenet.co.nz>

On 17/04/2016 4:55 a.m., Yuri Voinov wrote:
> 
> So.
> 
> Still has no ideas?
> 

Only things I assume you probably already looked at:

Maybe churn in the CA certificates. Linux and Windows distros have had
CA cert package updates happen in the past few weeks.

The ChaCha cipher you mentioned CloudFlare using should not be an issue
provided your SSL library is able to negotiate some other cipher to be
used. So the cipher sets in your config is something else to look at.

Amos


From squid3 at treenet.co.nz  Sun Apr 17 09:17:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 Apr 2016 21:17:52 +1200
Subject: [squid-users] High CPU usage
In-Reply-To: <507d01d19762$18a571e0$49f055a0$@articatech.com>
References: <CAL1kE9DAt=VBphGKywsE4-Yzy9pM2N5Ej_BwdJmh0C5LzzEm3Q@mail.gmail.com>
 <5710CF08.7060603@treenet.co.nz>
 <507d01d19762$18a571e0$49f055a0$@articatech.com>
Message-ID: <571354C0.7@treenet.co.nz>

On 16/04/2016 9:59 a.m., David Touzeau wrote:
> We have the same issue when upgrading to 3.5.16
> 
> 3.5.16 -> squid take 100% CPU
> Back to 3.5.13 -> 12% CPU
> 

Does the latest 3.5 snapshot perform better? This may be related to the
Vary regression making varant objects all MISS - and thus longer
processing times.

Amos



From squid3 at treenet.co.nz  Sun Apr 17 09:28:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 Apr 2016 21:28:59 +1200
Subject: [squid-users] Not sure if reverse proxy is what I need
In-Reply-To: <CAG_2TMcx9k-Z-qg5OK6EYKahvPoK3HWspbP9Gn-oOzK+Pt2pSA@mail.gmail.com>
References: <CAG_2TMcx9k-Z-qg5OK6EYKahvPoK3HWspbP9Gn-oOzK+Pt2pSA@mail.gmail.com>
Message-ID: <5713575B.1030909@treenet.co.nz>

On 16/04/2016 5:13 a.m., Renato wrote:
> Hi guys,
> 
> I'm not sure if squid is what I need, so I'll try to explain my
> scenario to make it clear what I need:
> 
> I have lots of virtual machines, each one running a web service.
> Those virtual machines are not exposed to the internet.
> 
> To access the virtual machines, I want to have a "client database",
> each client will have an username, a password and the IP address and
> port number for the virtual machine, like this:
> 
> client1, pass_cli1, http://192.168.0.1:8081
> client2, pass_cli2, http://192.168.0.1:8082
> client3, pass_cli3, http://192.168.0.1:8083
> client4, pass_cli4, http://192.168.0.2:8081
> ...
> 
> What I'm thinking of doing is to let squid exposed to the internet,
> with authentication.  When a client connects, a login/password is
> asked.  If the login/pass matches one of the clients on the list,
> squid will reverse proxy to the corresponding address on database.
> 
> Is it possible to achieve this only with squid or I need others tools too?

You will need some tool to export the database records into files
containing the cache_peer settings for each VM. One file per VM is
usually best so you can add/delete easily.

Make a directory where these config snippet files go. Only put
squid.conf snippets in there.

Use the "include" directive in squid.conf to pull in the directory
contents and have your DB tool trigger Squid to be reconfigured each
time it changes those files.

Use HTTP authentication rules in cache_peer_access to determine which VM
peer is accessible to each username to avoid needing to reconfigure each
time somebody logs in.

Amos



From squid3 at treenet.co.nz  Sun Apr 17 10:30:20 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 Apr 2016 22:30:20 +1200
Subject: [squid-users] ntlm user in access.log
In-Reply-To: <1702156600.20160416020635@irk.ru>
References: <1702156600.20160416020635@irk.ru>
Message-ID: <571365BC.3050905@treenet.co.nz>

On 16/04/2016 6:06 a.m., Alexander Titaev wrote:
> Hi, Squid-users.
> 
> before was
> fbsd 9.3 i386, squid-2.7.9_1, samba36-3.6.23
> 1448899275.777 5230 192.168.0.29 TCP_MISS/200 2823 CONNECT rs.mail.ru:443 IGM\mtiunov DIRECT/94.100.180.76 -
> 
> is now
> 10.2 amd64, squid-3.5.16, samba36-3.6.25_3
> 1460709029.057 1 192.168.0.74 TCP_MISS/503 4751 GET http://vk.com/widget_community.php? IGM\\mtiunov HIER_DIRECT/192.168.1.254 text/html
> 
> how I can get
> DOM\user
> instead
> DOM\\user
> 
> 

Your log processor needs to cope with usernames being shell escaped and
URL-encoded. The shell escaping of slash, CR and LF characters was added
to resolve problems found with Squid-2.

Or you can create a custom logformat with whatever type of escaping you
wish on any parameter. Details at
<http://www.squid-cache.org/Doc/config/logformat/>

Amos



From yvoinov at gmail.com  Sun Apr 17 10:37:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 17 Apr 2016 16:37:15 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <57135468.1010807@treenet.co.nz>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57126E83.70600@gmail.com>
 <57135468.1010807@treenet.co.nz>
Message-ID: <4d01e69c-069d-6ba6-b797-fc5d8b199646@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I've tried any ciphersuites, including SSL default. With no effect. I
don't think so the issue is in cipher's negotiation.

The only strange I found - queries to problematic sites directly from
proxy box (via proxy) with curl/wget works.

Only LAN connection can't handshake.


17.04.16 15:16, Amos Jeffries ?????:
> On 17/04/2016 4:55 a.m., Yuri Voinov wrote:
>>
>> So.
>>
>> Still has no ideas?
>>
>
> Only things I assume you probably already looked at:
>
> Maybe churn in the CA certificates. Linux and Windows distros have had
> CA cert package updates happen in the past few weeks.
>
> The ChaCha cipher you mentioned CloudFlare using should not be an issue
> provided your SSL library is able to negotiate some other cipher to be
> used. So the cipher sets in your config is something else to look at.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXE2dbAAoJENNXIZxhPexG0lwH/RAuJvYodMvVY2SxONdtghyE
dzXGMEYpjrlglDZKqCY2lxRIe2ea5tvynflYmRbMQP6VIbOw70TW/Mw8ajILjKNI
lV6LTfn8+YNk2YtYfPhFrHYDmalEbMA9AAm5nhISTUb4hfOGBeSKM8dphNBj4tcY
KA1ArYhSjVpTTErH794tHUu1fDKP8ade/BS/YsQQ7uY6qz/wky+W0ZNncXzao+Pv
oJZjgE0O/KqEridQjyMtgeiGA6lfxWFBndA+PGNiQvuUb92TEd5mmErFZu14BIbZ
46W5LBB88GE5nuK0lN43fzzX7XXoFF5OBQo+5+l1E0X97/Of/tgJXOnSeVTxHzM=
=gWZ1
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160417/367d322e/attachment.key>

From squid3 at treenet.co.nz  Sun Apr 17 10:49:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 Apr 2016 22:49:10 +1200
Subject: [squid-users] Any problems with %ssl::>sni in 3.5.16?
In-Reply-To: <86E0F05F-C170-4762-A8F6-EA22650F7EED@getbusi.com>
References: <86E0F05F-C170-4762-A8F6-EA22650F7EED@getbusi.com>
Message-ID: <57136A26.2060908@treenet.co.nz>

On 12/04/2016 5:52 p.m., Dan Charlesworth wrote:
> We have an External ACL Type with %ssl::>sni and %URI
> 
> We get access log lines that record the %ssl::>sni just fine, but the corresponding line sent to our external ACL is missing it.
> 
> For example, from the same request;
> 
> Log: 12/Apr/2016-15:42:47    608 10.0.1.60 TAG_NONE 200 0 CONNECT 23.111.9.31:443 code.jquery.com - peek - ORIGINAL_DST/23.111.9.31 - -
> 
> Line sent to Ext. ACL: 23.111.9.31:443 -
> 
> ?
> 
> Not sure if many people on this list use external ACLs as much, but anyone encountered this?

>From the silence it would seem not. But most likely its not a very
commonly used config setting yet.

It could be you are using the ACL just prior to the SNI being peeked at.
The ACL is pulling its value straight from the TCP connection state so
not even any temporary location involved that could be out of sync.

I dont recall there having been any significant changes to the external
ACL code since it went in. There may have been some changes that
affected it on the SSL-Bump side, but unlikely.

Amos



From yvoinov at gmail.com  Sun Apr 17 10:50:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 17 Apr 2016 16:50:57 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <57135024.1020503@ngtech.co.il>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57135024.1020503@ngtech.co.il>
Message-ID: <668aa91a-ac71-599a-cf5d-93af25b6da2f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
*NIX means UNIX. Solaris is AT&T UNIX. Linux is not UNIX (C) Linus
Torvalds. :) We are not speaking about all possible OS'es. I suggests
the matter in SSL/TLS, not OS or hands or something similar.

The problem is in CF, I think. As a maximum in peek-n-splice.


Because of I've not changed my squid.conf over last year, but approx. in
january 2016 CloudFlare stopped work via proxy, as said my field SA.
AFAIK, CF change own security settings. Also, I suggests, mozilla .org
also moved behind CF.

Ok, let's talk about squid.conf. SSL-related rows are here:

# SSL bump rules
acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex -i
"/usr/local/squid/etc/url.nobump"
acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/squid/etc/url.tor"
ssl_bump peek DiscoverSNIHost
ssl_bump splice NoSSLIntercept
ssl_bump bump all

http_port 3126 intercept
https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt
key=/usr/local/squid/etc/rootCA.key
options=SINGLE_DH_USE,SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt
key=/usr/local/squid/etc/rootCA.key
options=SINGLE_DH_USE,SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt
options=SINGLE_DH_USE,SINGLE_ECDH_USE
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
sslproxy_foreign_intermediate_certs /usr/local/squid/etc/intermediate_ca.pem
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB

I see no anomalies in this lines. Ciphersuite is very relaxed.

Also, if we discuss a bug - may be better to turn on debug to know, why
4.x got first NONE_ABORTED/200 during CONNECT phase and then NONE/503
during TLS negotiate?


17.04.16 14:58, Eliezer Croitoru ?????:
> For me it works.
> ...
> The first thing to do is publish the squid.conf with a bug report and
all other related info.
> *NIX doesn't mean CentOS since on CentOS this specific issue doesn't exit.
> I assume that if it works on CentOS it will work almost the same for
Ubuntu and Debian.
>
> Eliezer
>
> On 16/04/2016 19:50, Yuri Voinov wrote:
>> 3.5.16 on *NIX is also has this issue.
>>
>> Only 3.5.16 Win64 is works like sharm.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXE2qQAAoJENNXIZxhPexGD0wH/1SkyQyaa4gHV4AhXf5RrUTM
oEyGkOcEPwYw6M4+uYgvZ1FzvjrQhS6G8RTH/XrpSZ1utt9nbNSHP+W6FnXyxNPN
J/bauCQeADWf/NUGLG8GnOMXA9LD7w20ylAwOeLe1MUQJ4DTDT4arwzExkx0kohk
4mQNqq1Q105lgh0xyUQWF/wt0Uy3hSs2pPjyK4CGPWCbRO2kmYpPANT0ejoglfsF
uWNYBN5gl4hCd9kVzo0oaVwY2sNUftc1MyYztBpYUQ9WSoHoTnlvAWcWEF7FqHV6
TIB77Pr2fURIkEIlyLIQJ7weXkueOLI8VJp3EYLX5arDDLwu4tfXKpItHx5Tjd8=
=eQPH
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160417/d5433e63/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160417/d5433e63/attachment.key>

From yvoinov at gmail.com  Sun Apr 17 12:59:10 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 17 Apr 2016 18:59:10 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <57135468.1010807@treenet.co.nz>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57126E83.70600@gmail.com>
 <57135468.1010807@treenet.co.nz>
Message-ID: <1fa489b8-4193-5e3d-239a-e37f477dc098@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


17.04.16 15:16, Amos Jeffries ?????:
> On 17/04/2016 4:55 a.m., Yuri Voinov wrote:
>>
>> So.
>>
>> Still has no ideas?
>>
>
> Only things I assume you probably already looked at:
>
> Maybe churn in the CA certificates. Linux and Windows distros have had
> CA cert package updates happen in the past few weeks.
Don't think so, Amos.
We are talking not about clients. We are talking about Squid. Which is
utilize own ca-bundle (in my case), which is got and updated from
Mozilla (heh, the only one place in the world with all CA's.... hehehe)
every week, and manually updated intermediate CA's file.

When I test connect with openssl with this CA - it returned 0 - i.e. no
errors, all CA's validated.
When I test connection with wget from proxy box - all ok, files
downloaded etc.etc.

And only from LAN these connections got NONE/503. IDK what does it mean.
There is not goes via cache_peer. There is not goes via any parent proxy.
>
>
> The ChaCha cipher you mentioned CloudFlare using should not be an issue
> provided your SSL library is able to negotiate some other cipher to be
Yep, this is not cipher issue. I've checked already.
>
> used. So the cipher sets in your config is something else to look at.
Also checked. No one cipher combinations not work on CF/Mozilla. Oh, it
works on all any sites, of course.
>
>
> Amos
Still in doubt. IDK whats happening.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXE4ieAAoJENNXIZxhPexGNAcIAMA+m5zFDEvxzR/Q0RWYuiWd
1bCK+7BtYCTUmqD+KAbpBWfWlbgp6e9t0O+G7yzelmvoUugoFqbeyqq6aJUKmW3T
/sN9hsEnBVh644K1U4WNS6UawhsypBYZXQ13UegWNmP/hw54/urrGCNxa2buRFck
8fbCy9ZY92HloWwEUpclsn/mJ2SuzMLLoBUFRji61OtFpgYXn+PHaACerPAYaF7W
JrOrcviQP5Bx1+JIdvbUHM9Q83xFeBXremf87CBAQg4f1fCCf2en24dc/Vj9v+aB
K5hbm7XLCVDmerkb1M3S2RTm8nv4Xx6S9MtyOgnEGO+Qj25FWWZxoqSOycpmqz0=
=lSAK
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160417/f710e70a/attachment.key>

From rousskov at measurement-factory.com  Sun Apr 17 14:41:16 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 17 Apr 2016 08:41:16 -0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <1fa489b8-4193-5e3d-239a-e37f477dc098@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57126E83.70600@gmail.com>
 <57135468.1010807@treenet.co.nz>
 <1fa489b8-4193-5e3d-239a-e37f477dc098@gmail.com>
Message-ID: <5713A08C.6090503@measurement-factory.com>

On 04/17/2016 06:59 AM, Yuri Voinov wrote:
> IDK whats happening.

The answer is probably in the ALL,9 log. Since you can reproduce this
problem on an isolated system with a single transaction, you may be able
to analyze that log to pinpoint the failure. If you cannot or will not
perform that analysis, then I second Eliezer Croitoru's suggestion to
file a bug report with that log attached. However, it may take a long
time for somebody to volunteer to analyze your log.

Alex.



From per at computer.org  Sun Apr 17 16:21:05 2016
From: per at computer.org (Per Jessen)
Date: Sun, 17 Apr 2016 18:21:05 +0200
Subject: [squid-users] http_port with "transparent" or "intercept"?
Message-ID: <nf0d5h$kc3$1@saturn.local.net>

I am in the process if migrating from 2.7 to 3.4, and have hit a minor 
problem - 
if I use "http_port 3128 transparent" as I did in 2.7, it works very well, 
but I get a slew of errors on start-up:

squid[1735]: ERROR: No forward-proxy ports configured.
squid: Last message 'ERROR: No forward-pr' repeated 176 times, suppressed by 
syslog-ng on sogo

If I only specify "http_port 3128", browsers being redirected to squid get 
this:

<--------------
The following error was encountered while trying to retrieve the URL: 
/schools/gcsebitesize/science/add_aqa/photosynthesis/photosynthesisrev3.shtml

    Invalid URL

Some aspect of the requested URL is incorrect.

Some possible problems are:

    Missing or incorrect access protocol (should be "http://" or similar)

    Missing hostname

    Illegal double-escape in the URL-Path

    Illegal character in hostname; underscores are not allowed.

Your cache administrator is webmaster.
----------->

I'm using squid-3.4.4 on openSUSE 13.2.  I have seen the 'intercept' option, 
but it produces the same error messages. 


thanks
Per Jessen, Z?rich.



From yvoinov at gmail.com  Sun Apr 17 16:34:52 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 17 Apr 2016 22:34:52 +0600
Subject: [squid-users] http_port with "transparent" or "intercept"?
In-Reply-To: <nf0d5h$kc3$1@saturn.local.net>
References: <nf0d5h$kc3$1@saturn.local.net>
Message-ID: <0a184777-b66b-fb95-463b-7e7fa9e493c1@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
#       intercept    Support for IP-Layer NAT interception delivering
#            traffic to this Squid port.
#            NP: disables authentication on the port.

Squid tells you what's wrong:

 ERROR: No forward-proxy ports configured.


In addition with interception port you MUST define also forwarding port
(starting from 3.x AFAIK).

Better to you will be specify forwarding port 3128, by default (it uses
by cachemgr and other optional software), and some another, for example,
3127, as interception port.

17.04.16 22:21, Per Jessen ?????:
> I am in the process if migrating from 2.7 to 3.4, and have hit a minor
> problem -
> if I use "http_port 3128 transparent" as I did in 2.7, it works very
well,
> but I get a slew of errors on start-up:
>
> squid[1735]: ERROR: No forward-proxy ports configured.
> squid: Last message 'ERROR: No forward-pr' repeated 176 times,
suppressed by
> syslog-ng on sogo
>
> If I only specify "http_port 3128", browsers being redirected to squid
get
> this:
>
> <--------------
> The following error was encountered while trying to retrieve the URL:
>
/schools/gcsebitesize/science/add_aqa/photosynthesis/photosynthesisrev3.shtml
>
>     Invalid URL
>
> Some aspect of the requested URL is incorrect.
>
> Some possible problems are:
>
>     Missing or incorrect access protocol (should be "http://" or similar)
>
>     Missing hostname
>
>     Illegal double-escape in the URL-Path
>
>     Illegal character in hostname; underscores are not allowed.
>
> Your cache administrator is webmaster.
> ----------->
>
> I'm using squid-3.4.4 on openSUSE 13.2.  I have seen the 'intercept'
option,
> but it produces the same error messages.
>
>
> thanks
> Per Jessen, Z?rich.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXE7srAAoJENNXIZxhPexG6pcH/06SIdSg91HfbfjHBPjRJFak
5awblFidUpxm3u9gJbuX7DQ7BxPLUtcs+7ihF3uY0KhTS7QjcSoX7j3EU/EjDywi
0Tz4YZruPY/4oJj4lk1sB0wB/YBXmgG6DKE9IIB2ujosVtXVkoHG3hgRfqLUh4ZU
Cj7MrctsVyk4aelGFO2Nla9ukw2GoCa3ufzDFIKZuUqF0mWPLUqXSOi0tl7qC/K5
QLLoIsYHFKYfLiyXMYj1ag7N83i2Iry1ae97/4DJFBWyHEdmlYmh564eL0JVQzzZ
ed+P/OOR6VEHrnRgHoQf9cITdZPCxGxokFHY0KWLGRb5G/RyF1L5rq5E/8H5DyI=
=UPxo
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160417/6aa016f1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160417/6aa016f1/attachment.key>

From per at computer.org  Sun Apr 17 16:44:54 2016
From: per at computer.org (Per Jessen)
Date: Sun, 17 Apr 2016 18:44:54 +0200
Subject: [squid-users] http_port with "transparent" or "intercept"?
References: <nf0d5h$kc3$1@saturn.local.net>
 <0a184777-b66b-fb95-463b-7e7fa9e493c1@gmail.com>
Message-ID: <nf0ei6$kht$1@saturn.local.net>

Yuri Voinov wrote:

> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>  
> #       intercept    Support for IP-Layer NAT interception delivering
> #            traffic to this Squid port.
> #            NP: disables authentication on the port.
> 
> Squid tells you what's wrong:
> 
>  ERROR: No forward-proxy ports configured.
> 
> In addition with interception port you MUST define also forwarding port
> (starting from 3.x AFAIK).

Aha, thanks. I'm adding this:

http_port 3129 intercept
http_port 3128 

Seems to have done the trick. 


Per Jessen, Z?rich.



From marko.cupac at mimar.rs  Mon Apr 18 08:16:47 2016
From: marko.cupac at mimar.rs (Marko =?ISO-8859-1?Q?Cupa=3F?=)
Date: Mon, 18 Apr 2016 10:16:47 +0200
Subject: [squid-users] Stuggling with 3.5.16 on FreeBSD-9.3
In-Reply-To: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
References: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
Message-ID: <20160418101647.3b0c7c01@mephala.kappastar.com>

On Wed, 13 Apr 2016 21:02:32 +0300
Odhiambo Washington <odhiambo at gmail.com> wrote:

> Hi Amos,
> 
> I bit the bullet and upgraded my FreeBSD-8.4 -> 9.3.
> 
> I am struggling to compile squid-3.5.16. I just have to find a way to
> make it compile and run, by all means.

Why don't you compile it from ports?
https://www.freshports.org/www/squid/
-- 
Before enlightenment - chop wood, draw water.
After  enlightenment - chop wood, draw water.

Marko Cupa?
https://www.mimar.rs/


From squid at peralex.com  Mon Apr 18 12:42:32 2016
From: squid at peralex.com (squid at peralex.com)
Date: Mon, 18 Apr 2016 14:42:32 +0200
Subject: [squid-users] Slowly rising CPU load (eventually hits 100)
In-Reply-To: <56FE0B54.20505@peralex.com>
References: <ndja5h$f9j$1@ger.gmane.org>
 <56FD53D3.4040006@measurement-factory.com> <56FE0B54.20505@peralex.com>
Message-ID: <nf2knp$vnk$1@ger.gmane.org>


> Thanks.  The current maximum_object_size_in_memory is 19 MB.
> 
>>
>> In summary, dealing with in-RAM objects significantly larger than 1MB
>> bigger the object, the longer Squid takes to scan its nodes.
>>
>> Short term, try limiting the size of in-RAM objects using
>> maximum_object_size_in_memory first. If that solves the problem, then,
>> most likely, only cached objects are affected.
> 

This seems to have fixed (or rather worked around) the problem.  I've
set maximum_object_size_in_memory down to 1 MB, and I haven't had
problem in more than a week.






From yvoinov at gmail.com  Mon Apr 18 12:48:36 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 18 Apr 2016 18:48:36 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <5713A08C.6090503@measurement-factory.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57126E83.70600@gmail.com>
 <57135468.1010807@treenet.co.nz>
 <1fa489b8-4193-5e3d-239a-e37f477dc098@gmail.com>
 <5713A08C.6090503@measurement-factory.com>
Message-ID: <3dc2526c-4d6d-261e-e5bf-617143c6c288@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://bugs.squid-cache.org/show_bug.cgi?id=4497

Debul logs are here:

https://drive.google.com/file/d/0B4nS4FYXsqTfdlpqeHJSRWtmcFE/view?usp=sharing

Here is one transaction done from wget on separated testing setup.


17.04.16 20:41, Alex Rousskov ?????:
> On 04/17/2016 06:59 AM, Yuri Voinov wrote:
>> IDK whats happening.
>
> The answer is probably in the ALL,9 log. Since you can reproduce this
> problem on an isolated system with a single transaction, you may be able
> to analyze that log to pinpoint the failure. If you cannot or will not
> perform that analysis, then I second Eliezer Croitoru's suggestion to
> file a bug report with that log attached. However, it may take a long
> time for somebody to volunteer to analyze your log.
>
> Alex.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXFNekAAoJENNXIZxhPexG940IALKvPGmwoBd9zjx6g2PyRFwq
Kl3uMb3XSgFO1ig2S9w0kkxwfYTSwdKBZy6t7IhJznjUK0qWZQEDOC4+3JJ7aVIt
Emmey2LaVk8RVBH+wtsvHxIqwTBd5v80IU8omZRwtdFsSYtCv5niKCKHIN6WPj+1
bOZlfszw+zzsaSYcJ5nYkHfMzGKX7RoDY3XoBAhPiHyTgSXk6sUoeDeffvRSdDf3
F8Kvncsk1OWyNKwdaucHjv4GtrTUTGGz7O4XqPzkj+7Rvl9+BAQYaN65KzelF1dr
a7BuJMowBFlwkVRnLU96oUaOaxYlmIbdORztlNps6lCshpFHxN9uNNqh4MsTEUc=
=Dke/
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160418/e5038f74/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160418/e5038f74/attachment.key>

From guy.helmer at gmail.com  Mon Apr 18 16:11:39 2016
From: guy.helmer at gmail.com (Guy Helmer)
Date: Mon, 18 Apr 2016 11:11:39 -0500
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <668aa91a-ac71-599a-cf5d-93af25b6da2f@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57135024.1020503@ngtech.co.il>
 <668aa91a-ac71-599a-cf5d-93af25b6da2f@gmail.com>
Message-ID: <1867F539-757B-491A-A6CC-A297F8CFFF00@gmail.com>


> On Apr 17, 2016, at 5:50 AM, Yuri Voinov <yvoinov at gmail.com> wrote:
> 
> 
> -----BEGIN PGP SIGNED MESSAGE----- 
> Hash: SHA256 
>  
> *NIX means UNIX. Solaris is AT&T UNIX. Linux is not UNIX (C) Linus Torvalds. :) We are not speaking about all possible OS'es. I suggests the matter in SSL/TLS, not OS or hands or something similar.
> 
> The problem is in CF, I think. As a maximum in peek-n-splice.
> 
> 
> Because of I've not changed my squid.conf over last year, but approx. in january 2016 CloudFlare stopped work via proxy, as said my field SA. AFAIK, CF change own security settings. Also, I suggests, mozilla .org also moved behind CF.
> 
> Ok, let's talk about squid.conf. SSL-related rows are here:
> 
> # SSL bump rules
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/squid/etc/url.nobump"
> acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/squid/etc/url.tor"
> ssl_bump peek DiscoverSNIHost
> ssl_bump splice NoSSLIntercept
> ssl_bump bump all
> 
> http_port 3126 intercept
> https_port 3127 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt key=/usr/local/squid/etc/rootCA.key options=SINGLE_DH_USE,SINGLE_ECDH_USE tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt key=/usr/local/squid/etc/rootCA.key options=SINGLE_DH_USE,SINGLE_ECDH_USE tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt options=SINGLE_DH_USE,SINGLE_ECDH_USE cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> sslproxy_foreign_intermediate_certs /usr/local/squid/etc/intermediate_ca.pem
> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s /var/lib/ssl_db -M 4MB
> 
> I see no anomalies in this lines. Ciphersuite is very relaxed.
> 
> Also, if we discuss a bug - may be better to turn on debug to know, why 4.x got first NONE_ABORTED/200 during CONNECT phase and then NONE/503 during TLS negotiate?

Hi, Yuri,

If I understand correctly, the issue is between squid and the origin proxy. In case it would help, have you enabled ECDH sslproxy_options or sslproxy_cipher settings in this snippet that would enable Squid to use ECDH when talking to the origin servers?

Do you happen to have a packet capture between your squid server and a CloudFlare server that could help diagnose the TLS protocol?s problem?

Regards,
Guy




From yvoinov at gmail.com  Mon Apr 18 16:37:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 18 Apr 2016 22:37:40 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <1867F539-757B-491A-A6CC-A297F8CFFF00@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57135024.1020503@ngtech.co.il>
 <668aa91a-ac71-599a-cf5d-93af25b6da2f@gmail.com>
 <1867F539-757B-491A-A6CC-A297F8CFFF00@gmail.com>
Message-ID: <f3094651-353f-4113-a3a8-a25f9bbd2ba2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


18.04.16 22:11, Guy Helmer ?????:
>
>> On Apr 17, 2016, at 5:50 AM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>> 
>> *NIX means UNIX. Solaris is AT&T UNIX. Linux is not UNIX (C) Linus
Torvalds. :) We are not speaking about all possible OS'es. I suggests
the matter in SSL/TLS, not OS or hands or something similar.
>>
>> The problem is in CF, I think. As a maximum in peek-n-splice.
>>
>>
>> Because of I've not changed my squid.conf over last year, but approx.
in january 2016 CloudFlare stopped work via proxy, as said my field SA.
AFAIK, CF change own security settings. Also, I suggests, mozilla .org
also moved behind CF.
>>
>> Ok, let's talk about squid.conf. SSL-related rows are here:
>>
>> # SSL bump rules
>> acl DiscoverSNIHost at_step SslBump1
>> acl NoSSLIntercept ssl::server_name_regex -i
"/usr/local/squid/etc/url.nobump"
>> acl NoSSLIntercept ssl::server_name_regex -i
"/usr/local/squid/etc/url.tor"
>> ssl_bump peek DiscoverSNIHost
>> ssl_bump splice NoSSLIntercept
>> ssl_bump bump all
>>
>> http_port 3126 intercept
>> https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt
key=/usr/local/squid/etc/rootCA.key
options=SINGLE_DH_USE,SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>> http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt
key=/usr/local/squid/etc/rootCA.key
options=SINGLE_DH_USE,SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>> tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt
options=SINGLE_DH_USE,SINGLE_ECDH_USE
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>> sslproxy_foreign_intermediate_certs
/usr/local/squid/etc/intermediate_ca.pem
>> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB
>>
>> I see no anomalies in this lines. Ciphersuite is very relaxed.
>>
>> Also, if we discuss a bug - may be better to turn on debug to know,
why 4.x got first NONE_ABORTED/200 during CONNECT phase and then
NONE/503 during TLS negotiate?
>
> Hi, Yuri,
>
> If I understand correctly, the issue is between squid and the origin
proxy. In case it would help, have you enabled ECDH sslproxy_options or
sslproxy_cipher settings in this snippet that would enable Squid to use
ECDH when talking to the origin servers?
As you can see above - yes, ECDH enabled, and I've checked it via Qualys
SSL Labs - Projects / SSL Client Test
<https://www.ssllabs.com/ssltest/viewMyClient.html>. Also another sites
utilize ECDH with this setup like sharm.
>
>
> Do you happen to have a packet capture between your squid server and a
CloudFlare server that could help diagnose the TLS protocol?s problem?
Not now. First this issue occurs onto production environment, which has
own DMZ and heavy enough traffic from a few dozen customers. Some
difficults to isolate one transaction with sniffing.
>
>
> Regards,
> Guy
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXFQ1UAAoJENNXIZxhPexGEJYH/jkPrxiY9ztyltmoXJLeYsMy
YxuGgtFWyW96Z8HZ1Zf9BzucDGAvUdfTLnvZb/4dh22bs+COQbX2s53RcSqGAJaP
CVfRG4AgU+R8AUNA9nLxAbM4NQM4EAbB16ZsF8jeyZzJXPiRjozLtDjo1vMslJtV
791L5gn//izooJAlLMNKxoSy37RniEcaRLnuol+xVb4jqfx3nWo4lQzWnS2cXe5k
YFIb4X8uTEo6lgH8Ld8FHQYRq6KZz11TZbQ+ft5CKFY5pqNqLP+Cjrq1bgTUgKVK
WA0F96GR9IECDe4pWCPXnX2bijTax5nY9NNs/rA1Pawch4j4ZyUY2I/M9ngI6RU=
=Y/pM
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160418/a774afef/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160418/a774afef/attachment.key>

From yvoinov at gmail.com  Mon Apr 18 16:47:16 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 18 Apr 2016 22:47:16 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <1867F539-757B-491A-A6CC-A297F8CFFF00@gmail.com>
References: <570CE246.40008@gmail.com> <570D004F.3030406@gmail.com>
 <570D144F.7020206@gmail.com> <570D3C3F.8040603@ngtech.co.il>
 <570D40D6.5050502@gmail.com> <570D5466.6090502@ngtech.co.il>
 <570D5A9C.5030809@gmail.com> <570D5C81.2030900@gmail.com>
 <570FAB4E.1020108@gmail.com> <570FE20F.5080704@gmail.com>
 <5710B19F.4020504@treenet.co.nz> <57121F79.2040607@gmail.com>
 <57126D5C.2020900@gmail.com> <57135024.1020503@ngtech.co.il>
 <668aa91a-ac71-599a-cf5d-93af25b6da2f@gmail.com>
 <1867F539-757B-491A-A6CC-A297F8CFFF00@gmail.com>
Message-ID: <7d96ad2f-4e61-27d3-2cd6-af0cd6992fff@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


18.04.16 22:11, Guy Helmer ?????:
>
>> On Apr 17, 2016, at 5:50 AM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>> 
>> *NIX means UNIX. Solaris is AT&T UNIX. Linux is not UNIX (C) Linus
Torvalds. :) We are not speaking about all possible OS'es. I suggests
the matter in SSL/TLS, not OS or hands or something similar.
>>
>> The problem is in CF, I think. As a maximum in peek-n-splice.
>>
>>
>> Because of I've not changed my squid.conf over last year, but approx.
in january 2016 CloudFlare stopped work via proxy, as said my field SA.
AFAIK, CF change own security settings. Also, I suggests, mozilla .org
also moved behind CF.
>>
>> Ok, let's talk about squid.conf. SSL-related rows are here:
>>
>> # SSL bump rules
>> acl DiscoverSNIHost at_step SslBump1
>> acl NoSSLIntercept ssl::server_name_regex -i
"/usr/local/squid/etc/url.nobump"
>> acl NoSSLIntercept ssl::server_name_regex -i
"/usr/local/squid/etc/url.tor"
>> ssl_bump peek DiscoverSNIHost
>> ssl_bump splice NoSSLIntercept
>> ssl_bump bump all
>>
>> http_port 3126 intercept
>> https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt
key=/usr/local/squid/etc/rootCA.key
options=SINGLE_DH_USE,SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>> http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/rootCA.crt
key=/usr/local/squid/etc/rootCA.key
options=SINGLE_DH_USE,SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>> tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt
options=SINGLE_DH_USE,SINGLE_ECDH_USE
cipher=HIGH:MEDIUM:!aNULL:!eNULL:!RC4:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>> sslproxy_foreign_intermediate_certs
/usr/local/squid/etc/intermediate_ca.pem
>> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB
>>
>> I see no anomalies in this lines. Ciphersuite is very relaxed.
>>
>> Also, if we discuss a bug - may be better to turn on debug to know,
why 4.x got first NONE_ABORTED/200 during CONNECT phase and then
NONE/503 during TLS negotiate?
>
> Hi, Yuri,
>
> If I understand correctly, the issue is between squid and the origin
proxy. In case it would help, have you enabled ECDH sslproxy_options or
sslproxy_cipher settings in this snippet that would enable Squid to use
ECDH when talking to the origin servers?
>
> Do you happen to have a packet capture between your squid server and a
CloudFlare server that could help diagnose the TLS protocol?s problem?
At the first look capture between one client and CF IP looks good:

snoop -i cf.pcap -S -V
________________________________
  1   0.00000 192.168.100.103 -> 198.41.214.162 length:   66  ETHER
Type=0800 (IP), size=66 bytes
  1   0.00000 192.168.100.103 -> 198.41.214.162 length:   66  IP 
D=198.41.214.162 S=192.168.100.103 LEN=52, ID=24968, TOS=0x0, TTL=63
  1   0.00000 192.168.100.103 -> 198.41.214.162 length:   66  TCP D=443
S=13938 Syn Seq=3817347029 Len=0 Win=8192 Options=<mss 1260,nop,wscale
8,nop,nop,sackOK>
  1   0.00000 192.168.100.103 -> 198.41.214.162 length:   66  HTTPS C
port=13938
________________________________
  2   0.00005 198.41.214.162 -> 192.168.100.103 length:   66  ETHER
Type=0800 (IP), size=66 bytes
  2   0.00005 198.41.214.162 -> 192.168.100.103 length:   66  IP 
D=192.168.100.103 S=198.41.214.162 LEN=52, ID=46549, TOS=0x0, TTL=60
  2   0.00005 198.41.214.162 -> 192.168.100.103 length:   66  TCP
D=13938 S=443 Syn Ack=3817347030 Seq=318920410 Len=0 Win=65520
Options=<mss 1460,nop,wscale 0,nop,nop,sackOK>
  2   0.00005 198.41.214.162 -> 192.168.100.103 length:   66  HTTPS R
port=13938
________________________________
  3   0.00102 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
  3   0.00102 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=24969, TOS=0x0, TTL=63
  3   0.00102 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13938 Ack=318920411 Seq=3817347030 Len=0 Win=260
  3   0.00102 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13938
________________________________
  4   0.00265 192.168.100.103 -> 198.41.214.162 length:  571  ETHER
Type=0800 (IP), size=571 bytes
  4   0.00265 192.168.100.103 -> 198.41.214.162 length:  571  IP 
D=198.41.214.162 S=192.168.100.103 LEN=557, ID=24970, TOS=0x0, TTL=63
  4   0.00265 192.168.100.103 -> 198.41.214.162 length:  571  TCP D=443
S=13938 Push Ack=318920411 Seq=3817347030 Len=517 Win=260
  4   0.00265 192.168.100.103 -> 198.41.214.162 length:  571  HTTPS C
port=13938
________________________________
  5   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
  5   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46550, TOS=0x0, TTL=60
  5   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13938 S=443 Ack=3817347547 Seq=318920411 Len=0 Win=65520
  5   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13938
________________________________
  6  16.45220 198.41.214.162 -> 192.168.100.103 length: 1275  ETHER
Type=0800 (IP), size=1275 bytes
  6  16.45220 198.41.214.162 -> 192.168.100.103 length: 1275  IP 
D=192.168.100.103 S=198.41.214.162 LEN=1261, ID=46578, TOS=0x0, TTL=60
  6  16.45220 198.41.214.162 -> 192.168.100.103 length: 1275  TCP
D=13938 S=443 Push Ack=3817347547 Seq=318920411 Len=1221 Win=65520
  6  16.45220 198.41.214.162 -> 192.168.100.103 length: 1275  HTTPS R
port=13938
________________________________
  7   0.01078 192.168.100.103 -> 198.41.214.162 length:  172  ETHER
Type=0800 (IP), size=172 bytes
  7   0.01078 192.168.100.103 -> 198.41.214.162 length:  172  IP 
D=198.41.214.162 S=192.168.100.103 LEN=158, ID=26443, TOS=0x0, TTL=63
  7   0.01078 192.168.100.103 -> 198.41.214.162 length:  172  TCP D=443
S=13938 Push Ack=318921632 Seq=3817347547 Len=118 Win=256
  7   0.01078 192.168.100.103 -> 198.41.214.162 length:  172  HTTPS C
port=13938
________________________________
  8   0.00002 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
  8   0.00002 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46579, TOS=0x0, TTL=60
  8   0.00002 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13938 S=443 Ack=3817347665 Seq=318921632 Len=0 Win=65520
  8   0.00002 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13938
________________________________
  9   0.00104 198.41.214.162 -> 192.168.100.103 length:  288  ETHER
Type=0800 (IP), size=288 bytes
  9   0.00104 198.41.214.162 -> 192.168.100.103 length:  288  IP 
D=192.168.100.103 S=198.41.214.162 LEN=274, ID=46580, TOS=0x0, TTL=60
  9   0.00104 198.41.214.162 -> 192.168.100.103 length:  288  TCP
D=13938 S=443 Push Ack=3817347665 Seq=318921632 Len=234 Win=65520
  9   0.00104 198.41.214.162 -> 192.168.100.103 length:  288  HTTPS R
port=13938
________________________________
 10   0.00225 192.168.100.103 -> 198.41.214.162 length:  487  ETHER
Type=0800 (IP), size=487 bytes
 10   0.00225 192.168.100.103 -> 198.41.214.162 length:  487  IP 
D=198.41.214.162 S=192.168.100.103 LEN=473, ID=26444, TOS=0x0, TTL=63
 10   0.00225 192.168.100.103 -> 198.41.214.162 length:  487  TCP D=443
S=13938 Push Ack=318921866 Seq=3817347665 Len=433 Win=260
 10   0.00225 192.168.100.103 -> 198.41.214.162 length:  487  HTTPS C
port=13938
________________________________
 11   0.00028 198.41.214.162 -> 192.168.100.103 length: 1314  ETHER
Type=0800 (IP), size=1314 bytes
 11   0.00028 198.41.214.162 -> 192.168.100.103 length: 1314  IP 
D=192.168.100.103 S=198.41.214.162 LEN=1300, ID=46581, TOS=0x0, TTL=60
 11   0.00028 198.41.214.162 -> 192.168.100.103 length: 1314  TCP
D=13938 S=443 Ack=3817348098 Seq=318921866 Len=1260 Win=65520
 11   0.00028 198.41.214.162 -> 192.168.100.103 length: 1314  HTTPS R
port=13938
________________________________
 12   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  ETHER
Type=0800 (IP), size=1314 bytes
 12   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  IP 
D=192.168.100.103 S=198.41.214.162 LEN=1300, ID=46582, TOS=0x0, TTL=60
 12   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  TCP
D=13938 S=443 Ack=3817348098 Seq=318923126 Len=1260 Win=65520
 12   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  HTTPS R
port=13938
________________________________
 13   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  ETHER
Type=0800 (IP), size=1314 bytes
 13   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  IP 
D=192.168.100.103 S=198.41.214.162 LEN=1300, ID=46583, TOS=0x0, TTL=60
 13   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  TCP
D=13938 S=443 Ack=3817348098 Seq=318924386 Len=1260 Win=65520
 13   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  HTTPS R
port=13938
________________________________
 14   0.00000 198.41.214.162 -> 192.168.100.103 length:  249  ETHER
Type=0800 (IP), size=249 bytes
 14   0.00000 198.41.214.162 -> 192.168.100.103 length:  249  IP 
D=192.168.100.103 S=198.41.214.162 LEN=235, ID=46584, TOS=0x0, TTL=60
 14   0.00000 198.41.214.162 -> 192.168.100.103 length:  249  TCP
D=13938 S=443 Push Ack=3817348098 Seq=318925646 Len=195 Win=65520
 14   0.00000 198.41.214.162 -> 192.168.100.103 length:  249  HTTPS R
port=13938
________________________________
 15   0.00002 198.41.214.162 -> 192.168.100.103 length:   77  ETHER
Type=0800 (IP), size=77 bytes
 15   0.00002 198.41.214.162 -> 192.168.100.103 length:   77  IP 
D=192.168.100.103 S=198.41.214.162 LEN=63, ID=46585, TOS=0x0, TTL=60
 15   0.00002 198.41.214.162 -> 192.168.100.103 length:   77  TCP
D=13938 S=443 Push Ack=3817348098 Seq=318925841 Len=23 Win=65520
 15   0.00002 198.41.214.162 -> 192.168.100.103 length:   77  HTTPS R
port=13938
________________________________
 16   0.00111 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
 16   0.00111 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46586, TOS=0x0, TTL=60
 16   0.00111 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13938 S=443 Fin Ack=3817348098 Seq=318925864 Len=0 Win=65520
 16   0.00111 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13938
________________________________
 17   0.00082 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 17   0.00082 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=26445, TOS=0x0, TTL=63
 17   0.00082 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13938 Ack=318924386 Seq=3817348098 Len=0 Win=260
 17   0.00082 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13938
________________________________
 18   0.00000 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 18   0.00000 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=26446, TOS=0x0, TTL=63
 18   0.00000 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13938 Ack=318925841 Seq=3817348098 Len=0 Win=260
 18   0.00000 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13938
________________________________
 19   0.00013 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 19   0.00013 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=26447, TOS=0x0, TTL=63
 19   0.00013 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13938 Ack=318925865 Seq=3817348098 Len=0 Win=260
 19   0.00013 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13938
________________________________
 20   0.00918 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 20   0.00918 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=26448, TOS=0x0, TTL=63
 20   0.00918 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13938 Fin Ack=318925865 Seq=3817348098 Len=0 Win=260
 20   0.00918 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13938
________________________________
 21   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
 21   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46587, TOS=0x0, TTL=60
 21   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13938 S=443 Ack=3817348099 Seq=318925865 Len=0 Win=65520
 21   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13938
________________________________
 22   0.49521 192.168.100.103 -> 198.41.214.162 length:   66  ETHER
Type=0800 (IP), size=66 bytes
 22   0.49521 192.168.100.103 -> 198.41.214.162 length:   66  IP 
D=198.41.214.162 S=192.168.100.103 LEN=52, ID=26488, TOS=0x0, TTL=63
 22   0.49521 192.168.100.103 -> 198.41.214.162 length:   66  TCP D=443
S=13944 Syn Seq=2038838096 Len=0 Win=8192 Options=<mss 1260,nop,wscale
8,nop,nop,sackOK>
 22   0.49521 192.168.100.103 -> 198.41.214.162 length:   66  HTTPS C
port=13944
________________________________
 23   0.00005 198.41.214.162 -> 192.168.100.103 length:   66  ETHER
Type=0800 (IP), size=66 bytes
 23   0.00005 198.41.214.162 -> 192.168.100.103 length:   66  IP 
D=192.168.100.103 S=198.41.214.162 LEN=52, ID=46588, TOS=0x0, TTL=60
 23   0.00005 198.41.214.162 -> 192.168.100.103 length:   66  TCP
D=13944 S=443 Syn Ack=2038838097 Seq=1203583234 Len=0 Win=65520
Options=<mss 1460,nop,wscale 0,nop,nop,sackOK>
 23   0.00005 198.41.214.162 -> 192.168.100.103 length:   66  HTTPS R
port=13944
________________________________
 24   0.00101 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 24   0.00101 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=26489, TOS=0x0, TTL=63
 24   0.00101 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13944 Ack=1203583235 Seq=2038838097 Len=0 Win=260
 24   0.00101 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13944
________________________________
 25   0.00187 192.168.100.103 -> 198.41.214.162 length:  571  ETHER
Type=0800 (IP), size=571 bytes
 25   0.00187 192.168.100.103 -> 198.41.214.162 length:  571  IP 
D=198.41.214.162 S=192.168.100.103 LEN=557, ID=26490, TOS=0x0, TTL=63
 25   0.00187 192.168.100.103 -> 198.41.214.162 length:  571  TCP D=443
S=13944 Push Ack=1203583235 Seq=2038838097 Len=517 Win=260
 25   0.00187 192.168.100.103 -> 198.41.214.162 length:  571  HTTPS C
port=13944
________________________________
 26   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
 26   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46589, TOS=0x0, TTL=60
 26   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13944 S=443 Ack=2038838614 Seq=1203583235 Len=0 Win=65520
 26   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13944
________________________________
 27  15.24873 198.41.214.162 -> 192.168.100.103 length: 1275  ETHER
Type=0800 (IP), size=1275 bytes
 27  15.24873 198.41.214.162 -> 192.168.100.103 length: 1275  IP 
D=192.168.100.103 S=198.41.214.162 LEN=1261, ID=46670, TOS=0x0, TTL=60
 27  15.24873 198.41.214.162 -> 192.168.100.103 length: 1275  TCP
D=13944 S=443 Push Ack=2038838614 Seq=1203583235 Len=1221 Win=65520
 27  15.24873 198.41.214.162 -> 192.168.100.103 length: 1275  HTTPS R
port=13944
________________________________
 28   0.00837 192.168.100.103 -> 198.41.214.162 length:  172  ETHER
Type=0800 (IP), size=172 bytes
 28   0.00837 192.168.100.103 -> 198.41.214.162 length:  172  IP 
D=198.41.214.162 S=192.168.100.103 LEN=158, ID=27820, TOS=0x0, TTL=63
 28   0.00837 192.168.100.103 -> 198.41.214.162 length:  172  TCP D=443
S=13944 Push Ack=1203584456 Seq=2038838614 Len=118 Win=256
 28   0.00837 192.168.100.103 -> 198.41.214.162 length:  172  HTTPS C
port=13944
________________________________
 29   0.00002 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
 29   0.00002 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46671, TOS=0x0, TTL=60
 29   0.00002 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13944 S=443 Ack=2038838732 Seq=1203584456 Len=0 Win=65520
 29   0.00002 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13944
________________________________
 30   0.00105 198.41.214.162 -> 192.168.100.103 length:  288  ETHER
Type=0800 (IP), size=288 bytes
 30   0.00105 198.41.214.162 -> 192.168.100.103 length:  288  IP 
D=192.168.100.103 S=198.41.214.162 LEN=274, ID=46672, TOS=0x0, TTL=60
 30   0.00105 198.41.214.162 -> 192.168.100.103 length:  288  TCP
D=13944 S=443 Push Ack=2038838732 Seq=1203584456 Len=234 Win=65520
 30   0.00105 198.41.214.162 -> 192.168.100.103 length:  288  HTTPS R
port=13944
________________________________
 31   0.00224 192.168.100.103 -> 198.41.214.162 length:  479  ETHER
Type=0800 (IP), size=479 bytes
 31   0.00224 192.168.100.103 -> 198.41.214.162 length:  479  IP 
D=198.41.214.162 S=192.168.100.103 LEN=465, ID=27821, TOS=0x0, TTL=63
 31   0.00224 192.168.100.103 -> 198.41.214.162 length:  479  TCP D=443
S=13944 Push Ack=1203584690 Seq=2038838732 Len=425 Win=260
 31   0.00224 192.168.100.103 -> 198.41.214.162 length:  479  HTTPS C
port=13944
________________________________
 32   0.00028 198.41.214.162 -> 192.168.100.103 length: 1314  ETHER
Type=0800 (IP), size=1314 bytes
 32   0.00028 198.41.214.162 -> 192.168.100.103 length: 1314  IP 
D=192.168.100.103 S=198.41.214.162 LEN=1300, ID=46673, TOS=0x0, TTL=60
 32   0.00028 198.41.214.162 -> 192.168.100.103 length: 1314  TCP
D=13944 S=443 Ack=2038839157 Seq=1203584690 Len=1260 Win=65520
 32   0.00028 198.41.214.162 -> 192.168.100.103 length: 1314  HTTPS R
port=13944
________________________________
 33   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  ETHER
Type=0800 (IP), size=1314 bytes
 33   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  IP 
D=192.168.100.103 S=198.41.214.162 LEN=1300, ID=46674, TOS=0x0, TTL=60
 33   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  TCP
D=13944 S=443 Ack=2038839157 Seq=1203585950 Len=1260 Win=65520
 33   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  HTTPS R
port=13944
________________________________
 34   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  ETHER
Type=0800 (IP), size=1314 bytes
 34   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  IP 
D=192.168.100.103 S=198.41.214.162 LEN=1300, ID=46675, TOS=0x0, TTL=60
 34   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  TCP
D=13944 S=443 Ack=2038839157 Seq=1203587210 Len=1260 Win=65520
 34   0.00000 198.41.214.162 -> 192.168.100.103 length: 1314  HTTPS R
port=13944 +_H(`I\267Q\251\315\253\320\4E\7 at x\241)t
________________________________
 35   0.00000 198.41.214.162 -> 192.168.100.103 length:  249  ETHER
Type=0800 (IP), size=249 bytes
 35   0.00000 198.41.214.162 -> 192.168.100.103 length:  249  IP 
D=192.168.100.103 S=198.41.214.162 LEN=235, ID=46676, TOS=0x0, TTL=60
 35   0.00000 198.41.214.162 -> 192.168.100.103 length:  249  TCP
D=13944 S=443 Push Ack=2038839157 Seq=1203588470 Len=195 Win=65520
 35   0.00000 198.41.214.162 -> 192.168.100.103 length:  249  HTTPS R
port=13944
________________________________
 36   0.00002 198.41.214.162 -> 192.168.100.103 length:   77  ETHER
Type=0800 (IP), size=77 bytes
 36   0.00002 198.41.214.162 -> 192.168.100.103 length:   77  IP 
D=192.168.100.103 S=198.41.214.162 LEN=63, ID=46677, TOS=0x0, TTL=60
 36   0.00002 198.41.214.162 -> 192.168.100.103 length:   77  TCP
D=13944 S=443 Push Ack=2038839157 Seq=1203588665 Len=23 Win=65520
 36   0.00002 198.41.214.162 -> 192.168.100.103 length:   77  HTTPS R
port=13944
________________________________
 37   0.00104 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
 37   0.00104 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46678, TOS=0x0, TTL=60
 37   0.00104 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13944 S=443 Fin Ack=2038839157 Seq=1203588688 Len=0 Win=65520
 37   0.00104 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13944
________________________________
 38   0.00063 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 38   0.00063 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=27823, TOS=0x0, TTL=63
 38   0.00063 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13944 Ack=1203587210 Seq=2038839157 Len=0 Win=260
 38   0.00063 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13944
________________________________
 39   0.00013 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 39   0.00013 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=27824, TOS=0x0, TTL=63
 39   0.00013 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13944 Ack=1203588665 Seq=2038839157 Len=0 Win=260
 39   0.00013 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13944
________________________________
 40   0.00000 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 40   0.00000 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=27825, TOS=0x0, TTL=63
 40   0.00000 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13944 Ack=1203588689 Seq=2038839157 Len=0 Win=260
 40   0.00000 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13944
________________________________
 41   0.00465 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 41   0.00465 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=27826, TOS=0x0, TTL=63
 41   0.00465 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13944 Fin Ack=1203588689 Seq=2038839157 Len=0 Win=260
 41   0.00465 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13944
________________________________
 42   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
 42   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46679, TOS=0x0, TTL=60
 42   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13944 S=443 Ack=2038839158 Seq=1203588689 Len=0 Win=65520
 42   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13944
________________________________
 43   0.13164 192.168.100.103 -> 198.41.214.162 length:   66  ETHER
Type=0800 (IP), size=66 bytes
 43   0.13164 192.168.100.103 -> 198.41.214.162 length:   66  IP 
D=198.41.214.162 S=192.168.100.103 LEN=52, ID=27846, TOS=0x0, TTL=63
 43   0.13164 192.168.100.103 -> 198.41.214.162 length:   66  TCP D=443
S=13954 Syn Seq=1593639683 Len=0 Win=8192 Options=<mss 1260,nop,wscale
8,nop,nop,sackOK>
 43   0.13164 192.168.100.103 -> 198.41.214.162 length:   66  HTTPS C
port=13954
________________________________
 44   0.00002 198.41.214.162 -> 192.168.100.103 length:   66  ETHER
Type=0800 (IP), size=66 bytes
 44   0.00002 198.41.214.162 -> 192.168.100.103 length:   66  IP 
D=192.168.100.103 S=198.41.214.162 LEN=52, ID=46682, TOS=0x0, TTL=60
 44   0.00002 198.41.214.162 -> 192.168.100.103 length:   66  TCP
D=13954 S=443 Syn Ack=1593639684 Seq=479332036 Len=0 Win=65520
Options=<mss 1460,nop,wscale 0,nop,nop,sackOK>
 44   0.00002 198.41.214.162 -> 192.168.100.103 length:   66  HTTPS R
port=13954
________________________________
 45   0.00103 192.168.100.103 -> 198.41.214.162 length:   60  ETHER
Type=0800 (IP), size=60 bytes
 45   0.00103 192.168.100.103 -> 198.41.214.162 length:   60  IP 
D=198.41.214.162 S=192.168.100.103 LEN=40, ID=27847, TOS=0x0, TTL=63
 45   0.00103 192.168.100.103 -> 198.41.214.162 length:   60  TCP D=443
S=13954 Ack=479332037 Seq=1593639684 Len=0 Win=260
 45   0.00103 192.168.100.103 -> 198.41.214.162 length:   60  HTTPS C
port=13954
________________________________
 46   0.00093 192.168.100.103 -> 198.41.214.162 length:  571  ETHER
Type=0800 (IP), size=571 bytes
 46   0.00093 192.168.100.103 -> 198.41.214.162 length:  571  IP 
D=198.41.214.162 S=192.168.100.103 LEN=557, ID=27848, TOS=0x0, TTL=63
 46   0.00093 192.168.100.103 -> 198.41.214.162 length:  571  TCP D=443
S=13954 Push Ack=479332037 Seq=1593639684 Len=517 Win=260
 46   0.00093 192.168.100.103 -> 198.41.214.162 length:  571  HTTPS C
port=13954
________________________________
 47   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  ETHER
Type=0800 (IP), size=54 bytes
 47   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  IP 
D=192.168.100.103 S=198.41.214.162 LEN=40, ID=46683, TOS=0x0, TTL=60
 47   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  TCP
D=13954 S=443 Ack=1593640201 Seq=479332037 Len=0 Win=65003
 47   0.00001 198.41.214.162 -> 192.168.100.103 length:   54  HTTPS R
port=13954


I.e., at the transport level exchanges occurs. So, it can't be
ACL/access/IP level problem with infrastructure.

But this session was finished with:

https://i1.someimage.com/b3mYkjp.png

>
>
> Regards,
> Guy
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXFQ+UAAoJENNXIZxhPexGbywH/1G+cfThlzXkH2xNy+PZwBBC
WdEPywb/hLBa7XUg6MfT2I95cE17GawOztcFd9piws8lRp7gTkwx+V8ZNa8h5yvU
oLA4RRQhMLjg22zh5IJi7fg6H37hzAzxTHd1d5vlTW9b10xMH9SxH0lxiQ2ilz+f
CPtJN4EuZdsA0dos10rbKRdIHAEtXTUDaxa7vm2eaJ7Nz5oVb2dbZrhIx4oUr+CL
/Vshx2MXAB9bPrDrTnqaMGA8WZvX/VihJYIJymHZNPxsN3t1EQrjOANuBfp+q12c
eqDY40GqnOh5HHP1jcvy26e1/TENMSmD9S41IGpY5yDIIKNq4P61eR4GSVjhxMU=
=NNIE
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160418/af2b8380/attachment.key>

From ncrogers at gmail.com  Mon Apr 18 17:14:37 2016
From: ncrogers at gmail.com (Nick Rogers)
Date: Mon, 18 Apr 2016 10:14:37 -0700
Subject: [squid-users] Stuggling with 3.5.16 on FreeBSD-9.3
In-Reply-To: <CAAdA2WNKfZdwj96wTM_zLAbAgO33ZNyMn=s-qy6yfk0L=9X5Xg@mail.gmail.com>
References: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
 <570EEAB0.2050700@treenet.co.nz>
 <CAAdA2WOeX5F57_QzVvA-8-nA-wK3LRYgxSpqwhdy-WoRWbsbDA@mail.gmail.com>
 <57110524.5080405@treenet.co.nz>
 <CAAdA2WNKfZdwj96wTM_zLAbAgO33ZNyMn=s-qy6yfk0L=9X5Xg@mail.gmail.com>
Message-ID: <CAKOb=YaXzZTw+G5t=XYvmQOpQqCS2Ak-kFaJT1g8FbGyLgXwfA@mail.gmail.com>

On Fri, Apr 15, 2016 at 8:45 AM, Odhiambo Washington <odhiambo at gmail.com>
wrote:

> Hello Amos,
>
> All noted.
>
> Lemme consult with some FreeBSD guys on these .
>

As a FreeBSD user, here's my two cents.

You should be using the www/squid port.

If the port doesn't compile with the options you wish, open a problem
report with FreeBSD and/or ask on the FreeBSD ports mailing list. The
maintainer of the www/squid port is pretty responsive and helpful.

I don't have any issues with www/squid on FreeBSD 10.1-RELEASE.


>
> On 15 April 2016 at 18:13, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>> On 16/04/2016 1:29 a.m., Odhiambo Washington wrote:
>> >
>> > With luck, I have managed to get squid to compile successfully (after
>> > upgrading a few components here and there). I used:
>>
>> Yay!
>>
>> >
>> > I have it running now (redirecting using IPFilter/IPNAT), but once in a
>> > while I see this error about NAT:
>> >
>> <snip>
>> > 2016/04/15 16:17:23| ERROR: NAT/TPROXY lookup failed to locate original
>> IPs
>> > on local=192.168.55.254:13128 remote=192.168.55.62:57724 FD 29 flags=33
>>
>> These are the kernel NAT system telling Squid the connection being
>> looked up has not record there.
>>
>> It could be TCP connections being made straight to the intercept port.
>> If so you need to update the firewall config to prevent them, even from
>> localhost.
>>  In Linux we use a mangle table rule, since that is the filter pre-NAT
>> that can do it. I'm not sure how FreeBSD would do that. It has to be
>> done on packets first arrival pre-NAT. Any filter that is applied after
>> the NAT action will get it wrong due to the NAT changes.
>>
>>
>> It could be the NAT systems table of connections filling up and
>> overflowing. If so there should be a kernel sysctl somewhere to increase
>> that table size.
>>
>> >
>> > In any case, I am planning to rewrite the IPNAT rules into PF and use
>> PF.
>> > It's the inception stage so I haven't delved deep into ssl-bump
>> > configurations...
>> >
>>
>> HTH
>> Amos
>>
>>
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160418/e643d152/attachment.htm>

From odhiambo at gmail.com  Tue Apr 19 08:46:14 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Tue, 19 Apr 2016 11:46:14 +0300
Subject: [squid-users] Stuggling with 3.5.16 on FreeBSD-9.3
In-Reply-To: <CAKOb=YaXzZTw+G5t=XYvmQOpQqCS2Ak-kFaJT1g8FbGyLgXwfA@mail.gmail.com>
References: <CAAdA2WOPhMib5XjwcsUtFUkphFqocwK-9QYhrPAkq5Sq_r+eWg@mail.gmail.com>
 <570EEAB0.2050700@treenet.co.nz>
 <CAAdA2WOeX5F57_QzVvA-8-nA-wK3LRYgxSpqwhdy-WoRWbsbDA@mail.gmail.com>
 <57110524.5080405@treenet.co.nz>
 <CAAdA2WNKfZdwj96wTM_zLAbAgO33ZNyMn=s-qy6yfk0L=9X5Xg@mail.gmail.com>
 <CAKOb=YaXzZTw+G5t=XYvmQOpQqCS2Ak-kFaJT1g8FbGyLgXwfA@mail.gmail.com>
Message-ID: <CAAdA2WMsKite5Nq1=J4EO8aGx5-G8raB7rPr+qPwX9VwR2uqPA@mail.gmail.com>

On 18 April 2016 at 20:14, Nick Rogers <ncrogers at gmail.com> wrote:

>
>
> On Fri, Apr 15, 2016 at 8:45 AM, Odhiambo Washington <odhiambo at gmail.com>
> wrote:
>
>> Hello Amos,
>>
>> All noted.
>>
>> Lemme consult with some FreeBSD guys on these .
>>
>
> As a FreeBSD user, here's my two cents.
>
> You should be using the www/squid port.
>
> If the port doesn't compile with the options you wish, open a problem
> report with FreeBSD and/or ask on the FreeBSD ports mailing list. The
> maintainer of the www/squid port is pretty responsive and helpful.
>
> I don't have any issues with www/squid on FreeBSD 10.1-RELEASE.
>
>
That much I know, and love, but this box was running squid-2.7.9 for years
and was in production servicing about 100 users. I wasn't going to do 'make
install' from the port and cause disruption. Plus I came to realize only
later that 3.2.16 was the www/squid.
For the record, I like playing with new software manually, compiling by
hand and testing before deploying. That's why I was struggling with this
'by hand'. Also note that my FreeBSD version was 8.4 (EoL).



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160419/99d26fc5/attachment.htm>

From Sebastien.Boulianne at cpu.ca  Tue Apr 19 13:04:55 2016
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Tue, 19 Apr 2016 09:04:55 -0400
Subject: [squid-users] Attached file on OWA with Squid
In-Reply-To: <5708820A.8090303@treenet.co.nz>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD147F@CPUMAIL2.cpu.qc.ca>
 <5708820A.8090303@treenet.co.nz>
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5837FD15BB@CPUMAIL2.cpu.qc.ca>

Hi Amos, Eliezer and all ;),
As I wrote, if I connect to our VPN then I try to attach a file with the OWA, it works.
If I forward all owa requests directly to the mail server, I can attach a file without any issues.

I isolated the issue and we can see the problem happens when owa requests pass thru the Squid.

Is it a server issue or a Squid issue ?
Im running MS Exchange 2007 SP3 x64.

Im using the very latest version of Squid.

I will try to change the 302 status to 308.

Thanks you very much for ur help guys.

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Amos Jeffries
Envoy??: 9 avril 2016 00:16
??: squid-users at lists.squid-cache.org
Objet?: Re: [squid-users] Attached file on OWA with Squid

On 7/04/2016 5:24 a.m., Sebastien.Boulianne wrote:
> I configured my OWA to pass thru the Squid.
> Auth work perfectly.
> Browsing is working perfectly.
> All is working perfectly except when I try to attach files or documents to an email.
> 
> [cid:image002.png at 01D19007.A7E26D20]
> 
> 
> And It stops here. Nothing else happens.
> 
> I did some tests and I noticed that happens when I am connecting from external to OWA.
> If I connect to the VPN then I try to send an attached file with the OWA, it works.

If you mean that you are using Squid through the VPN, then that probably means its not a Squid problem.


> 
> Here is my config for my OWA.
> 
> ### OWA
> cache_peer owa.domain.qc.ca parent 443 0 no-query originserver 
> login=PASS ssl sslcert=/etc/pki/tls/certs/domain.qc.ca.cert.pem 
> sslkey=/etc/pki/tls/private/domain.qc.ca.key.pem 
> options=NO_SSLv2:NO_SSLv3:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE 
> dhparams=/etc/pki/tls/private/dhparams.pem 
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+E
> CDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:E
> DH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
> name=owa acl owahttps url_regex ^https://owa\.domain\.qc\.ca 
> cache_peer_access owa allow owahttps http_access allow www443 owahttps 
> acl owahttp url_regex ^http://owa\.domain\.qc\.ca http_access deny 
> owahttp deny_info 302:https://%H%R owahttp

You probably need to use 308 status here. 302 tells the client to try again using the *GET* method. Sending of things is not a GET action.


> 
> Thanks you very much for your advice.
> 

What version of Squid (squid -v) ?

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From bmarkey at steinmancommunications.com  Tue Apr 19 13:16:13 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Tue, 19 Apr 2016 13:16:13 +0000
Subject: [squid-users] Two questions regarding ssl_bump and peek/splice.
Message-ID: <2B77BF184EAC2F43BB9FC908954D8B126704E1A2@Ex5.lnpnews.com>

Can anyone point me to a deep dive or something like that about how ssl_bump and peek/splice etc work? The more technical the better.   I don't want to ask a ton of questions about some of the errors I'm getting without fully understanding what is going on.

I currently have squid working almost the way I want it, with just a few remaining issues.  One of them being is that with ssl sites I seem to get a lot of "not private, cert authority" messages then I have to add that site to an acl to not be bumped.    Regarding my first question, I want to understand why.

My second question I think is a quickie.  Can you run 2 log files?  Reason being is that I use squidanalyzer and it only reads the standard log format.  But there are better log formats for what I'm doing. I'd like to keep dual logs while I work on my own analyzer that reads that log file.   You can see the logformat line commented out along with some other log  lines.

Thanks much

Here is my current working config.

#Access Lists
acl internal src 192.168.200.0/21
acl wireless src 192.168.100.0/23

#Ports allowed through Squid
acl Safe_ports port 80
acl Safe_ports port 443
acl SSL_ports port 443
acl CONNECT method CONNECT

#acls from blacklist
acl allowed dstdomain -i "/etc/squid3/acls/http_allowed.acl"
acl prime dstdomain -i "/etc/squid3/acls/squid-prime.acl"
acl china dst -n "/etc/squid3/acls/ccd-china.acl"
acl india dst -n "/etc/squid3/acls/ccd-india.acl"
acl iran dst -n "/etc/squid3/acls/ccd-iran.acl"
acl nigeria dst -n "/etc/squid3/acls/ccd-nigeria.acl"
acl pakistan dst -n "/etc/squid3/acls/ccd-nigeria.acl"
acl romania dst -n "/etc/squid3/acls/ccd-romania.acl"
acl russia dst -n "/etc/squid3/acls/ccd-russia.acl"
acl syria dst -n "/etc/squid3/acls/ccd-syria.acl"
acl ukraine dst -n "/etc/squid3/acls/ccd-ukraine.acl"
acl uzbekistan dst -n "/etc/squid3/acls/ccd-uzbekistan.acl"
acl ips dst -n "/etc/squid3/acls/broken_ips.acl"

#allow/deny
http_access allow allowed
http_access allow ips
http_access deny prime
http_access deny china
http_access deny india
http_access deny iran
http_access deny nigeria
http_access deny pakistan
http_access deny romania
http_access deny russia
http_access deny syria
http_access deny ukraine
http_access deny uzbekistan

http_access allow internal
http_access allow wireless
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all

#Bumping
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"

#ssl_bump peek all
ssl_bump peek !broken_sites
ssl_bump splice all
#ssl_bump splice !broken_sites

sslproxy_capath /etc/ssl/certs

sslcrtd_program /lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
sslcrtd_children 32 startup=5 idle=1


#logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni %ssl::>cert_subject %>Hs %<st %Ss:%Sh

#access_log syslog:daemon.info mine
#access_log daemon:/var/log/squid3/test.log mine

#intercept
http_port 3128 intercept
https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB sslflags=NO_SESSION_REUSE

#nameservers
dns_nameservers 192.168.201.1 8.8.8.8

#WCCPv2 items
wccp_version 2
wccp2_router 192.168.200.73
wccp2_forwarding_method gre
wccp2_return_method gre
wccp2_service standard 0 password=LNP1
wccp2_service dynamic 70 password=LNP1
wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 ports=443

Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758 (o) | bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160419/ac42f99c/attachment.htm>

From squid3 at treenet.co.nz  Tue Apr 19 14:40:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 20 Apr 2016 02:40:41 +1200
Subject: [squid-users] Two questions regarding ssl_bump and peek/splice.
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B126704E1A2@Ex5.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B126704E1A2@Ex5.lnpnews.com>
Message-ID: <57164369.10605@treenet.co.nz>

On 20/04/2016 1:16 a.m., Markey, Bruce wrote:
> Can anyone point me to a deep dive or something like that about how
> ssl_bump and peek/splice etc work? The more technical the better.   I
> don't want to ask a ton of questions about some of the errors I'm
> getting without fully understanding what is going on.

The most technical you can get is to read the code itself. Second best
would be <http://wiki.squid-cache.org/Features/SslPeekAndSplice>.

> 
> I currently have squid working almost the way I want it, with just a
> few remaining issues.  One of them being is that with ssl sites I
> seem to get a lot of "not private, cert authority" messages then I
> have to add that site to an acl to not be bumped.    Regarding my
> first question, I want to understand why.

Odd. Neither OpenSSL nor Squid produce a message saying that.

> 
> My second question I think is a quickie.  Can you run 2 log files?
> Reason being is that I use squidanalyzer and it only reads the
> standard log format.  But there are better log formats for what I'm
> doing. I'd like to keep dual logs while I work on my own analyzer
> that reads that log file.   You can see the logformat line commented
> out along with some other log  lines.
> 

Yes. Just put multiple access_log lines in. One for each file/output you
want.

Amos



From bmarkey at steinmancommunications.com  Tue Apr 19 14:43:20 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Tue, 19 Apr 2016 14:43:20 +0000
Subject: [squid-users] Two questions regarding ssl_bump and peek/splice.
In-Reply-To: <57164369.10605@treenet.co.nz>
References: <2B77BF184EAC2F43BB9FC908954D8B126704E1A2@Ex5.lnpnews.com>
 <57164369.10605@treenet.co.nz>
Message-ID: <2B77BF184EAC2F43BB9FC908954D8B126704F3C9@Ex5.lnpnews.com>

Gotcha.  

I should have been clear about the cert authority error, I'm getting that in client browsers for some https sites.  It seems random as to which ones.   



Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758?(o) |?bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, April 19, 2016 10:41 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Two questions regarding ssl_bump and peek/splice.

On 20/04/2016 1:16 a.m., Markey, Bruce wrote:
> Can anyone point me to a deep dive or something like that about how
> ssl_bump and peek/splice etc work? The more technical the better.   I
> don't want to ask a ton of questions about some of the errors I'm 
> getting without fully understanding what is going on.

The most technical you can get is to read the code itself. Second best would be <http://wiki.squid-cache.org/Features/SslPeekAndSplice>.

> 
> I currently have squid working almost the way I want it, with just a 
> few remaining issues.  One of them being is that with ssl sites I seem 
> to get a lot of "not private, cert authority" messages then I
> have to add that site to an acl to not be bumped.    Regarding my
> first question, I want to understand why.

Odd. Neither OpenSSL nor Squid produce a message saying that.

> 
> My second question I think is a quickie.  Can you run 2 log files?
> Reason being is that I use squidanalyzer and it only reads the 
> standard log format.  But there are better log formats for what I'm 
> doing. I'd like to keep dual logs while I work on my own analyzer
> that reads that log file.   You can see the logformat line commented
> out along with some other log  lines.
> 

Yes. Just put multiple access_log lines in. One for each file/output you want.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From rousskov at measurement-factory.com  Tue Apr 19 14:43:28 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 19 Apr 2016 08:43:28 -0600
Subject: [squid-users] Two questions regarding ssl_bump and peek/splice.
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B126704E1A2@Ex5.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B126704E1A2@Ex5.lnpnews.com>
Message-ID: <57164410.4030108@measurement-factory.com>

On 04/19/2016 07:16 AM, Markey, Bruce wrote:
> Can anyone point me to a deep dive or something like that about how
> ssl_bump and peek/splice etc work? The more technical the better.

That's easy! https://code.launchpad.net/squid

http://wiki.squid-cache.org/Features/SslPeekAndSplice is less technical
but documents most of the modern mechanics. Unfortunately, it is
difficult to grok quickly or without good understanding of how SSL and
HTTP work in general. There are also a few bug reports on Bugzilla
covering various corner cases.


> I
> don?t want to ask a ton of questions about some of the errors I?m
> getting without fully understanding what is going on.  

Do not worry about full understanding. There are probably less than 10
people in the world that got close to that coveted level of "full
understanding". Unfortunately, they got there through years of pain and
suffering, not reading documentation. And they are too busy to document
everything they know.


> I currently have squid working almost the way I want it, with just a few
> remaining issues.  One of them being is that with ssl sites I seem to
> get a lot of ?not private, cert authority? messages then I have to add
> that site to an acl to not be bumped.    Regarding my first question, I
> want to understand why.

Please make sure you specify the exact error message and which agent is
generating it when asking about this problem in the future. Also,
examine and report which certificate (origin server or one of the
Squid-generated ones; which one?) is being received by that agent if
possible.


> My second question I think is a quickie.  Can you run 2 log files? 
> Reason being is that I use squidanalyzer and it only reads the standard
> log format.  But there are better log formats for what I?m doing. I?d
> like to keep dual logs while I work on my own analyzer that reads that
> log file.   You can see the logformat line commented out along with some
> other log  lines.

Yes, you can have many access_log directives.


HTH,

Alex.



From al_luhaybi at yahoo.com  Tue Apr 19 15:23:18 2016
From: al_luhaybi at yahoo.com (Mohammad Tariq)
Date: Tue, 19 Apr 2016 15:23:18 +0000 (UTC)
Subject: [squid-users] Two questions regarding ssl_bump and peek/splice.
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B126704F3C9@Ex5.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B126704E1A2@Ex5.lnpnews.com>
 <57164369.10605@treenet.co.nz>
 <2B77BF184EAC2F43BB9FC908954D8B126704F3C9@Ex5.lnpnews.com>
Message-ID: <1589239417.3614415.1461079398729.JavaMail.yahoo@mail.yahoo.com>

hay mate,
as far as my testings took me, you need to have the certificate installed on your client; to avoid any possible errors.
also, bump server first.
B.R.
Mohammad


      From: "Markey, Bruce" <bmarkey at steinmancommunications.com>
 To: 'Amos Jeffries' <squid3 at treenet.co.nz>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Tuesday, April 19, 2016 6:43 PM
 Subject: Re: [squid-users] Two questions regarding ssl_bump and peek/splice.
   
Gotcha.? 

I should have been clear about the cert authority error, I'm getting that in client browsers for some https sites.? It seems random as to which ones.? 



Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758?(o) |?bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, April 19, 2016 10:41 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Two questions regarding ssl_bump and peek/splice.

On 20/04/2016 1:16 a.m., Markey, Bruce wrote:
> Can anyone point me to a deep dive or something like that about how
> ssl_bump and peek/splice etc work? The more technical the better.? I
> don't want to ask a ton of questions about some of the errors I'm 
> getting without fully understanding what is going on.

The most technical you can get is to read the code itself. Second best would be <http://wiki.squid-cache.org/Features/SslPeekAndSplice>.

> 
> I currently have squid working almost the way I want it, with just a 
> few remaining issues.? One of them being is that with ssl sites I seem 
> to get a lot of "not private, cert authority" messages then I
> have to add that site to an acl to not be bumped.? ? Regarding my
> first question, I want to understand why.

Odd. Neither OpenSSL nor Squid produce a message saying that.

> 
> My second question I think is a quickie.? Can you run 2 log files?
> Reason being is that I use squidanalyzer and it only reads the 
> standard log format.? But there are better log formats for what I'm 
> doing. I'd like to keep dual logs while I work on my own analyzer
> that reads that log file.? You can see the logformat line commented
> out along with some other log? lines.
> 

Yes. Just put multiple access_log lines in. One for each file/output you want.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160419/23ca08ea/attachment.htm>

From michael.pelletier at palmbeachschools.org  Tue Apr 19 16:02:46 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Tue, 19 Apr 2016 12:02:46 -0400
Subject: [squid-users] Changing negotiate_kerberos_auth default location for
	rcache
Message-ID: <CAEnCSG74PkXndiAsR4yfgy9UUzQhK21JL5uYtzXP6_TmPEUGVw@mail.gmail.com>

Hello,
I am using squid 3.4 and need to change the default location from /var/tmp
to a tmpfs filesystem. The current version does not have the "-c" option to
change the default location. I was wondering if there was another way.

Michael

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160419/39698860/attachment.htm>

From cjwengler at icloud.com  Tue Apr 19 16:11:28 2016
From: cjwengler at icloud.com (cjwengler)
Date: Tue, 19 Apr 2016 09:11:28 -0700 (PDT)
Subject: [squid-users] New to proxies
Message-ID: <1461082288339-4677151.post@n4.nabble.com>

I used to have someone in this forum make me proxies for sneakers and
shopping websites. I bought so many he would charge me $0.75 per proxy. I
was wondering if someone else could make these proxies for me or teach me
how to make them myself. Either way, I will pay you for your efforts.
Thanks.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/New-to-proxies-tp4677151.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From nking4930 at hotmail.com  Tue Apr 19 18:16:05 2016
From: nking4930 at hotmail.com (nkingsquid)
Date: Tue, 19 Apr 2016 11:16:05 -0700 (PDT)
Subject: [squid-users] Routing Internally And/Or Externally?
Message-ID: <1461089765594-4677152.post@n4.nabble.com>

Trying to figure out if I need to write a script for this or not... 
I am Brand new to Squid but have done a ton of searches and can't find this.

I have authenticated traffic coming to my squid server from the Internet
(Via a NetScaler).  If the request is for an INTERNAL resource I want it to
continue on its journey.  However, if it is anything else I want it
re-directed back to the internet via the netscaler.  (just going to list the
applicable portion and throw in example data)


acl localnetPAC src 192.168.0.0/24                        #resource within
my network
acl localnetPAC src internal.resources.com              #resource within my
network
acl localnetPAC src internal1.resources.com            #resource within my
network
acl localnetPAC src internal2.resources.com            #resource within my
network
acl localnetPAC src internal3.resources.com            #resource within my
network

acl InboundNet scr 10.24.62.51           #NetScaler
acl OutboundNet scr 10.24.62.51           #NetScaler

http_access allow localnetPAC                     #user will be let thru to
the local resources
InboundNet !localnetPAC allow OutboundNet    #this is what I WANT to do but
isn't working
                                                               #can anyone
steer me to the right track?

Thanks!





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Routing-Internally-And-Or-Externally-tp4677152.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From nking4930 at hotmail.com  Tue Apr 19 18:18:30 2016
From: nking4930 at hotmail.com (nkingsquid)
Date: Tue, 19 Apr 2016 11:18:30 -0700 (PDT)
Subject: [squid-users] Routing Internally And/Or Externally?
In-Reply-To: <1461089765594-4677152.post@n4.nabble.com>
References: <1461089765594-4677152.post@n4.nabble.com>
Message-ID: <1461089910833-4677153.post@n4.nabble.com>

I should probably mention that its important that the request NOT be denied,
just redirected if it is not a listed internal resource...



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Routing-Internally-And-Or-Externally-tp4677152p4677153.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From huaraz at moeller.plus.com  Tue Apr 19 19:30:39 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Tue, 19 Apr 2016 20:30:39 +0100
Subject: [squid-users] Changing negotiate_kerberos_auth default location
	forrcache
In-Reply-To: <CAEnCSG74PkXndiAsR4yfgy9UUzQhK21JL5uYtzXP6_TmPEUGVw@mail.gmail.com>
References: <CAEnCSG74PkXndiAsR4yfgy9UUzQhK21JL5uYtzXP6_TmPEUGVw@mail.gmail.com>
Message-ID: <nf6116$n0q$1@ger.gmane.org>

Hi Michael,

   Yes you should be able to set a environment variable KRB5RCACHEDIR in your startup script. You can also use KRB5RCACHETYPE to set (or disable) the cache type. 

Markus

"Michael Pelletier" <michael.pelletier at palmbeachschools.org> wrote in message news:CAEnCSG74PkXndiAsR4yfgy9UUzQhK21JL5uYtzXP6_TmPEUGVw at mail.gmail.com...
Hello,

I am using squid 3.4 and need to change the default location from /var/tmp to a tmpfs filesystem. The current version does not have the "-c" option to change the default location. I was wondering if there was another way.


Michael






Disclaimer: Under Florida law, e-mail addresses are public records. If you do not want your e-mail address released in response to a public records request, do not send electronic mail to this entity. Instead, contact this office by phone or in writing.





--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160419/c5edf259/attachment.htm>

From eliezer at ngtech.co.il  Wed Apr 20 02:14:02 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 20 Apr 2016 05:14:02 +0300
Subject: [squid-users] Routing Internally And/Or Externally?
In-Reply-To: <1461089910833-4677153.post@n4.nabble.com>
References: <1461089765594-4677152.post@n4.nabble.com>
 <1461089910833-4677153.post@n4.nabble.com>
Message-ID: <002b01d19aaa$4eaf1570$ec0d4050$@ngtech.co.il>

Hey There,

In general what you want is possible but couple things are not clear to me yet.
The config you mentioned has couple issues:
##START OF INFO
acl localnetPAC src 192.168.0.0/24                        #resource within my network
acl localnetPAC src internal.resources.com              #resource within my network
acl localnetPAC src internal1.resources.com            #resource within my network
acl localnetPAC src internal2.resources.com            #resource within my network
acl localnetPAC src internal3.resources.com            #resource within my network

acl InboundNet scr 10.24.62.51           #NetScaler
acl OutboundNet scr 10.24.62.51           #NetScaler

http_access allow localnetPAC                     #user will be let thru to the local resources
#InboundNet !localnetPAC allow OutboundNet    
#this is what I WANT to do but isn't working 
#can anyone steer me to the right track?
##END OF INFO

In general if you want to deny with a redirection you can use the deny_info and a custom "shebang"  dummy acl.
One example of implementation can be found in the list archives at:
http://lists.squid-cache.org/pipermail/squid-users/2015-October/006092.html

Squid allows you to customize the "deny" action and which one of them can be a redirection.
You have used in your example an acl like:
acl localnetPAC src internal3.resources.com            

which uses a domain, but the "src" type acl cannot be used with a domain name and can only be an IP address.
Peek at the acl docs at: http://www.squid-cache.org/Doc/config/acl/
But you have mentioned the bottom line as:
#InboundNet !localnetPAC allow OutboundNet

Which is not clear to me but I will try to be creative with an example:
acl local_network_addresses dst 192.168.0.0/24	#Internal services
acl internal_domains dstdomain internal1.resources.com #Internal domains names
acl internal_domains dstdomain internal2.resources.com  #Internal domains names
acl dummy_match dstdom_regex .		#dummy match all domain regex 
acl InboundNet scr 10.24.62.51           #NetScaler source IP(the clients IP is not visible behind the NetScaler)
deny_info 302:http://www.google.com/?%H dummy_match 	#Customized deny_info that will redirect to google with some addition
http_access allow InboundNet internal_domains 	#rule that allows netscaler sources traffic to access internal domains
http_access allow InboundNet acl local_network_addresses	#rule that allows netscaler sources traffic to access internal ip addresses
http_access deny dummy_match	# rule that should match all traffic and redirect any request to google
##END OF example

I hope the example helps you.
Let me know If it helped you and\or if you need more help or if I didn't understood the question.

Eliezer

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of nkingsquid
Sent: Tuesday, April 19, 2016 9:19 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Routing Internally And/Or Externally?

I should probably mention that its important that the request NOT be denied, just redirected if it is not a listed internal resource...



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Routing-Internally-And-Or-Externally-tp4677152p4677153.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From michael.pelletier at palmbeachschools.org  Wed Apr 20 02:45:05 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Tue, 19 Apr 2016 22:45:05 -0400
Subject: [squid-users] Changing negotiate_kerberos_auth default location
	forrcache
In-Reply-To: <nf6116$n0q$1@ger.gmane.org>
References: <CAEnCSG74PkXndiAsR4yfgy9UUzQhK21JL5uYtzXP6_TmPEUGVw@mail.gmail.com>
 <nf6116$n0q$1@ger.gmane.org>
Message-ID: <CAEnCSG4Qf-1-AbLb-U0Hsz3g7D+q773Z-h20EByp8OO9k7SHzw@mail.gmail.com>

Thanks!!!!!!!!!!!!!!

On Tue, Apr 19, 2016 at 3:30 PM, Markus Moeller <huaraz at moeller.plus.com>
wrote:

> Hi Michael,
>
>    Yes you should be able to set a environment variable KRB5RCACHEDIR in
> your startup script. You can also use KRB5RCACHETYPE to set (or disable)
> the cache type.
>
> Markus
>
> "Michael Pelletier" <michael.pelletier at palmbeachschools.org> wrote in
> message
> news:CAEnCSG74PkXndiAsR4yfgy9UUzQhK21JL5uYtzXP6_TmPEUGVw at mail.gmail.com...
> Hello,
> I am using squid 3.4 and need to change the default location from /var/tmp
> to a tmpfs filesystem. The current version does not have the "-c" option to
> change the default location. I was wondering if there was another way.
>
> Michael
>
> *Disclaimer: *Under Florida law, e-mail addresses are public records. If
> you do not want your e-mail address released in response to a public
> records request, do not send electronic mail to this entity. Instead,
> contact this office by phone or in writing.
>
> ------------------------------
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160419/e02275aa/attachment.htm>

From squid3 at treenet.co.nz  Wed Apr 20 06:13:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 20 Apr 2016 18:13:46 +1200
Subject: [squid-users] Routing Internally And/Or Externally?
In-Reply-To: <1461089765594-4677152.post@n4.nabble.com>
References: <1461089765594-4677152.post@n4.nabble.com>
Message-ID: <57171E1A.2070404@treenet.co.nz>

On 20/04/2016 6:16 a.m., nkingsquid wrote:
> Trying to figure out if I need to write a script for this or not... 
> I am Brand new to Squid but have done a ton of searches and can't find this.
> 
> I have authenticated traffic coming to my squid server from the Internet
> (Via a NetScaler).

How exactly is the NetScalar sending it?
 via NAT or explicit-proxy configuration on the NetScalar?
 how is the Squid expected to validate that the traffic received is from
the NetScalar and not some malware?


>  If the request is for an INTERNAL resource I want it to
> continue on its journey.  However, if it is anything else I want it
> re-directed back to the internet via the netscaler.  (just going to list the
> applicable portion and throw in example data)

As you have described it sounds like an "open proxy". Having one of
these in your network is an instant security fail.

> 
> acl localnetPAC src 192.168.0.0/24                        #resource within
> my network
> acl localnetPAC src internal.resources.com              #resource within my
> network
> acl localnetPAC src internal1.resources.com            #resource within my
> network
> acl localnetPAC src internal2.resources.com            #resource within my
> network
> acl localnetPAC src internal3.resources.com            #resource within my
> network
> 
> acl InboundNet scr 10.24.62.51           #NetScaler
> acl OutboundNet scr 10.24.62.51           #NetScaler
> 
> http_access allow localnetPAC                     #user will be let thru to
> the local resources
> InboundNet !localnetPAC allow OutboundNet    #this is what I WANT to do but
> isn't working
>                                                                #can anyone
> steer me to the right track?


You seem to have made one of the usual beginners mistakes, thinking of
things from a client perspective where source is the place data comes from.

In HTTP we deal with request message orientation. Source (src) is the
place the request came from (the client IP) and destination is where it
is going to (the URL domain, dstdomain).

So what you have configured is that when an *LAN* generated request is
received it is allowed through.


For any request that is allowed to be processed, Squid will lookup where
to send it in DNS and send it there. Use your networks normal recursive
DNS resolver with split-DNS / views delivering the right
internal/external IPs things will "just work" in regards to Squid
delivering the requests. You do have one of those right?

Notice that "internal" and "external" are meaningless. There is simply
"where DNS told me/Squid to go for this URL domain".


The part you need to work on is what traffic is allowed to be processed.
And how Squid knows that. I suggest at minimum limiting it to only
accepting traffic arriving from the NetScalar IP:

 # The usual security protections go first.
 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_Ports

 # Your local custom permissions go here:
 acl NetScalar src 10.24.62.51
 http_access allow NetScalar

 # deny anything not explicitly permitted.
 http_access deny all


How you have configured the NetScalar to receive traffic and/or to relay
it to Squid may affect what you need to configure. Or may allow better
security protections on the channel between NetScalar and Squid.

Amos



From squid3 at treenet.co.nz  Wed Apr 20 06:33:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 20 Apr 2016 18:33:00 +1200
Subject: [squid-users] New to proxies
In-Reply-To: <1461082288339-4677151.post@n4.nabble.com>
References: <1461082288339-4677151.post@n4.nabble.com>
Message-ID: <5717229C.50201@treenet.co.nz>

On 20/04/2016 4:11 a.m., cjwengler wrote:
> I used to have someone in this forum make me proxies for sneakers and
> shopping websites. I bought so many he would charge me $0.75 per proxy. I
> was wondering if someone else could make these proxies for me or teach me
> how to make them myself. Either way, I will pay you for your efforts.
> Thanks.

Would you mind expanding a little on what you need the proxy(s) for?

Its hard to see why you would need more than one (or a few). We have
people here reporting individual Squid to be reaching almost Gbps
traffic loads before they hit trouble.


For learning Squid;
  the <http://wiki.squid-cache.org/SquidFaq> or the "Squid 3.1:
Beginners Guide" book should cover almost everything you need. This
mailing list is provided for helping out to clarify things if you need
more assistance.

(Disclaimer: Squid Software Foundation recieves a small funding donation
from each book sold).

Amos



From vkukk at xvidservices.com  Wed Apr 20 07:24:00 2016
From: vkukk at xvidservices.com (Veiko Kukk)
Date: Wed, 20 Apr 2016 10:24:00 +0300
Subject: [squid-users] Never expire any object Squid configuration
Message-ID: <57172E90.9020204@xvidservices.com>

Hi,

We have a Squid between our server application and openstack swift 
backend in accel/reverse mode with store-id configuraton (to strip 
temporary authentication URL-s). We want that any object that has been 
stored in squid cache is never again fetched from source and never again 
checked if it is fresh. Well, never in this case could be one year.

Relevant section from current configuration:

refresh_pattern -i ^https:\/\/AUTH_.*squid.internal.* 526000 100% 526000 
override-expire ignore-reload ignore-no-store ignore-private store-stale 
max-stale=52

With this configuration, we still see lots of TCP_REFRESH_MODIFIED/200 
TCP_REFRESH_UNMODIFIED/200 and TCP_REFRESH_UNMODIFIED/304 in logs.

How must Squid be configured to completely disable any refreshes? Those 
objects never change after they have been created and we only want them 
to be pushed out from cache by cache replacement policy.

I read from old post 
http://www.squid-cache.org/mail-archive/squid-dev/201108/0029.html that 
if client requests object without etag and server sends with etag, then 
Squid fetches object again. How to disable this?


Best regards,
Veiko


From squid3 at treenet.co.nz  Wed Apr 20 10:07:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 20 Apr 2016 22:07:06 +1200
Subject: [squid-users] Never expire any object Squid configuration
In-Reply-To: <57172E90.9020204@xvidservices.com>
References: <57172E90.9020204@xvidservices.com>
Message-ID: <571754CA.70101@treenet.co.nz>

On 20/04/2016 7:24 p.m., Veiko Kukk wrote:
> Hi,
> 
> We have a Squid between our server application and openstack swift
> backend in accel/reverse mode with store-id configuraton (to strip
> temporary authentication URL-s). We want that any object that has been
> stored in squid cache is never again fetched from source and never again
> checked if it is fresh. Well, never in this case could be one year.

The usual resonse to this is "Squid is a cache, not an archive".

Squid obeys the instructions given to it by the client and the server.
If the union of those instructions requires a fetch or revalidation it
is important to do so to ensure data integrity.

> 
> Relevant section from current configuration:
> 
> refresh_pattern -i ^https:\/\/AUTH_.*squid.internal.* 526000 100% 526000
> override-expire ignore-reload ignore-no-store ignore-private store-stale
> max-stale=52
> 
> With this configuration, we still see lots of TCP_REFRESH_MODIFIED/200
> TCP_REFRESH_UNMODIFIED/200 and TCP_REFRESH_UNMODIFIED/304 in logs.
> 
> How must Squid be configured to completely disable any refreshes? Those
> objects never change after they have been created and we only want them
> to be pushed out from cache by cache replacement policy.


The refresh_pattern ignore-* and override-* are hacks for ISP proxies to
cope with and fix traffic from badly designed web applications. They do
not have control over the origin so at times have no other choice.

A good rule of thumb to follow with reverse-proxy is that any problem
you see with your proxy, so does every other proxy on the planet have
with your sites traffic. It is best to fix things using HTTP mechanisms
properly, not with proxy config workarounds. That way you can benefit
from those other proxies caching as well as your own.


The correct way to do this in HTTP is to have the origin server /
application deliver an Expires: header with a date 1 year in the future
and/or a Cache-Control header with max-age=N with an equivalent value in
seconds. Squid will obey that.

 NP: HTTP allows caching for up to 68 years (2^31 seconds). Squid will
revalidate objects older than 1 year.

If you want objects to be cached, *do not* send Cache-Control:no-store
or Cache-Control:private on them. Nor small values of max-age=N.

If you want to avoid revalidation, *do not* send Cache-Control with
must-revalidate, proxy-revalidate, no-cache, or private. Also avoid
www-auth.


A reverse-proxy has some more options than other proxies:

* As a reverse-proxy you are allowed to use the 'ignore-cc' option on
http_port directives. This will cause the reverse-proxy to ignore any
client Cache-Control demands for revalidation.

* reverse-proxy contain the Surrogate feature. This can be used to give
the CDN proxy completely different max-age values than are sent in
Cache-Control for general caching.
 <http://www.squid-cache.org/Doc/config/http_accel_surrogate_remote/>
 <http://www.squid-cache.org/Doc/config/httpd_accel_surrogate_id/>


> 
> I read from old post
> http://www.squid-cache.org/mail-archive/squid-dev/201108/0029.html that
> if client requests object without etag and server sends with etag, then
> Squid fetches object again. How to disable this?

What I was trying to convey in that post was that empty / non-existent
is one of the valid ETag values. ETag is a unique identifier within the
URI scope. If the client explicitly asks for a variant of the object in
a conditional If-Match request, then using another value of ETag to
respond is not valid/legal.

Think of ETag like a MD5/SHA hash of the object. You cant just decide
that the value is different - you have to actually change the object to
make it different. Then you have two versions of it with different tags
and the client might ask specifically about either one.

Amos



From eliezer at ngtech.co.il  Wed Apr 20 11:14:18 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 20 Apr 2016 14:14:18 +0300
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <570CE246.40008@gmail.com>
References: <570CE246.40008@gmail.com>
Message-ID: <5717648A.6090907@ngtech.co.il>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160420/55e300ce/attachment.htm>

From yvoinov at gmail.com  Wed Apr 20 11:48:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 20 Apr 2016 17:48:07 +0600
Subject: [squid-users] Squid 4: Cloudflare SSL connection problem
In-Reply-To: <5717648A.6090907@ngtech.co.il>
References: <570CE246.40008@gmail.com> <5717648A.6090907@ngtech.co.il>
Message-ID: <57176C77.4090304@gmail.com>

The latest tests shows that Squid for unknown reasons do outgoing 
connection using IPv6 only.

Which leads to "Network unreacheble" with my ISP - it does not support IPv6.

Full wireshark dumps for single outgoing transaction attached to bug 
already.

20.04.16 17:14, Eliezer Croitoru ?????:
> Hey Yuri,
>
> I think that the bug solution or identification is requiring a full 
> tcpdump trace for a single request as was mentioned on the bug report:
> http://bugs.squid-cache.org/show_bug.cgi?id=4497#c39
> http://bugs.squid-cache.org/show_bug.cgi?id=4497#c40
>
> I have opened the port to my proxy, so you would be able to run couple 
> requests to verify that your curl and wget and other clients doesn't 
> have this "handshake" issue when accessing https://cloudflare.com 
> using my local testing proxy.
> Send me privately your origin IP address so I would add an exception 
> in my proxy for it.
>
> Eliezer
>
> On 12/04/2016 14:55, Yuri Voinov wrote:
>> Does anybody faces this problem with 4.0.8:
>>
>> https://i1.someimage.com/3lD2cvV.png
>>
>> ?
>>
>> It accomplished this error in cache.log:
>>
>> 2016/04/12 17:39:38 kid1| Error negotiating SSL on FD 54: 
>> error:00000000:lib(0):func(0):reason(0) (5/0/0)
>>
>> and "NONE/503" in access.log.
>>
>> Without proxy works like sharm. 3.5.16 with the similar squid.conf 
>> works like sharm.
>>
>> NB: Cloudflare support said, that they key feature for SSL is SNI and 
>> ECDSA now. AFAIK, 4.0.8 is fully supports this features.
>>
>> Any advice will be helpful.
>>
>> Yes, I know this looks like DDoS protection on Cloudflare. But WTF? 
>> Any workaround required. Half-Internet is hosted on Cloudflare.
>>
>> WBR, Yuri
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160420/53a97faa/attachment.htm>

From cjwengler at icloud.com  Wed Apr 20 12:34:07 2016
From: cjwengler at icloud.com (cjwengler)
Date: Wed, 20 Apr 2016 05:34:07 -0700 (PDT)
Subject: [squid-users] New to proxies
In-Reply-To: <5717229C.50201@treenet.co.nz>
References: <1461082288339-4677151.post@n4.nabble.com>
 <5717229C.50201@treenet.co.nz>
Message-ID: <1461155647357-4677164.post@n4.nabble.com>

I use the proxies for my sneaker program and I need one proxy per account for
that. Sometimes I run up to 1000 accounts. The proxies are used for
purchasing sneakers and clothing on sites such as Nike, Adidas, Supreme,
Footlocker, Eastbay, Champs, Finishline, etc.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/New-to-proxies-tp4677151p4677164.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Wed Apr 20 14:02:11 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 20 Apr 2016 16:02:11 +0200
Subject: [squid-users] New to proxies
In-Reply-To: <1461155647357-4677164.post@n4.nabble.com>
References: <1461082288339-4677151.post@n4.nabble.com>
 <5717229C.50201@treenet.co.nz> <1461155647357-4677164.post@n4.nabble.com>
Message-ID: <201604201602.11199.Antony.Stone@squid.open.source.it>

On Wednesday 20 April 2016 at 14:34:07, cjwengler wrote:

> I use the proxies for my sneaker program and I need one proxy per account
> for that.

Why?

> Sometimes I run up to 1000 accounts.

Do you have 1000 IP addresses?

> The proxies are used for purchasing sneakers and clothing on sites such as
> Nike, Adidas, Supreme, Footlocker, Eastbay, Champs, Finishline, etc.

And, er, why are proxies, indeed multiple ones, needed for this?


Antony.

-- 
"How I managed so long without this book baffles the mind."

 - Richard Stoakley, Group Program Manager, Microsoft Corporation,
   referring to "The Art of Project Management", O'Reilly press

                                                   Please reply to the list;
                                                         please *don't* CC me.


From cjwengler at icloud.com  Wed Apr 20 13:33:20 2016
From: cjwengler at icloud.com (cjwengler)
Date: Wed, 20 Apr 2016 06:33:20 -0700 (PDT)
Subject: [squid-users] New to proxies
In-Reply-To: <201604201602.11199.Antony.Stone@squid.open.source.it>
References: <1461082288339-4677151.post@n4.nabble.com>
 <5717229C.50201@treenet.co.nz> <1461155647357-4677164.post@n4.nabble.com>
 <201604201602.11199.Antony.Stone@squid.open.source.it>
Message-ID: <1461159200750-4677166.post@n4.nabble.com>

Most sneaker websites only allow you to purchase one shoe/item per IP or
orders cancel. I have 700 IPs right now but most aren't working. I need more
too. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/New-to-proxies-tp4677151p4677166.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From odhiambo at gmail.com  Wed Apr 20 14:16:07 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Wed, 20 Apr 2016 17:16:07 +0300
Subject: [squid-users] ssl_bump newbie troubles
Message-ID: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>

Hi,

I am trying my hands on ssl_bump and it's almost working, but that's
ish-ish.. because I have several problems.

I even wonder if this config is correct:

*acl step1 at_step SslBump1*
*acl step2 at_step SslBump2*
*acl step3 at_step SslBump3*

*acl ssl_bump_broken_sites  dstdomain
"/usr/local/etc/squid/ssl_bump_broken_sites.txt"*
*ssl_bump none ssl_bump_broken_sites*


*acl step1 at_step SslBump1*
*ssl_bump peek step1*
*ssl_bump stare step2*
*ssl_bump bump all*

*sslproxy_capath /etc/ssl/certs*
*sslproxy_cert_error allow all*
*#sslproxy_cert_error deny all*
*sslproxy_flags DONT_VERIFY_PEER*
*sslproxy_cafile /usr/local/share/certs/ca-root-nss.crt*


<cut>

The following error was encountered while trying to retrieve the URL:
https://org.ke.m-pesa.com/*

*Failed to establish a secure connection to 196.201.214.212*

The system returned:

(92) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Handshake with SSL server failed: error:14094412:SSL
routines:SSL3_READ_BYTES:sslv3 alert bad certificate

This proxy and the remote host failed to negotiate a mutually acceptable
security settings for handling your request. It is possible that the remote
host does not support secure connections, or the proxy is not satisfied
with the host security credentials.

Your cache administrator is <odhiambo at gmail.com>
<%3codhiambo at gmail.com%3e?subject=CacheErrorInfo%20-%20ERR_SECURE_CONNECT_FAIL&body=CacheHost%3A%20gw.crownkenya.com%0D%0AErrPage%3A%20ERR_SECURE_CONNECT_FAIL%0D%0AErr%3A%20(92)%20Protocol%20error%0D%0ATimeStamp%3A%20Wed,%2020%20Apr%202016%2013%3A22%3A02%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.54.63%0D%0AServerIP%3A%20196.201.214.212%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%20196.201.214.212%3A443%0D%0A%0D%0A%0D%0A>
.

</cut>



I thought I could mitigate that with the:

*acl ssl_bump_broken_sites  dstdomain
"/usr/local/etc/squid/ssl_bump_broken_sites.txt"*
*ssl_bump none ssl_bump_broken_sites*

..but that doesn't do it...

Secondly, I had to import my CA to all devices (as a trusted CA) on the
network so that they don't get the MITM notification. This is a challenge,
because I have to do the same for smart phones too, and that is not easy.
People don't like intrusive changes. For example on Android phone, you have
to set screen security before you can import such a CA, and after you do,
you cannot disable the screen security! Now, that is not something people
want.

Another issue is that we allow guests who come in to the premises to use
our Wi-Fi (on a different SSID). Without them importing the CA, they get
the MITM notification and cannot browse. This is because they get assigned
IPs in the same subnet we use in the office.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160420/e340f55e/attachment.htm>

From nking4930 at hotmail.com  Wed Apr 20 13:59:43 2016
From: nking4930 at hotmail.com (nkingsquid)
Date: Wed, 20 Apr 2016 06:59:43 -0700 (PDT)
Subject: [squid-users] Routing Internally And/Or Externally?
In-Reply-To: <002b01d19aaa$4eaf1570$ec0d4050$@ngtech.co.il>
References: <1461089765594-4677152.post@n4.nabble.com>
 <1461089910833-4677153.post@n4.nabble.com>
 <002b01d19aaa$4eaf1570$ec0d4050$@ngtech.co.il>
Message-ID: <1461160783542-4677168.post@n4.nabble.com>

Eliezer, this was very Helpful!  I have changed several things that you
mentioned that were incorrect and I will post my code below (changing names
and IPs to protect the confused :P ).  

At a high level this is my situation:  Our users have devices that are
supplied by us.  On these devices we have sandboxed apps that we ONLY allow
to come to our domain.  They also have their regular browser & Apps that can
access the web.  

While they are within the sandboxed apps however we want that app (for
various reasons) to both go to internal sites and external sites.

So when traffic hits the Squid (This is *AFTER* it gets authenticated thru
various security layers, and lastly thru a NetScaler) it either matches the
list of internal resources and is allowed to continue OR it does not and is
re-directed to a second proxy that will then send it to the internet.  ( I
was mistaken before about it going back to the original netscaler it came
from).

For example:
I browse to *me.examp.com*
     Squid recognizes that is an internal resource and lets me go to the
internal resource

I browse to *google.com*
     Squid recognizes that is NOT an internal resource and sends the traffic
to a second proxy to go to google.com

I browse to *facebook.com*
     Squid recognizes that is NOT an internal resource and sends the traffic
to a second proxy to go to facebook.com

I browse to *anywhere on the internet*
     Squid recognizes that is NOT an internal resource and sends the traffic
to a second proxy to go to anywhere else on the internet

Last ?...  if I have: acl Internal_Domain dstdomain [-n] .examp.com  do I
NEED to list me.examp.com or them.examp.com ?




CODE:

acl Local_Network dst 11.0.0.0/8
acl Local_Network dst 132.0.0.0/8
acl Internal_Domain dstdomain [-n] .examp.com
acl Internal_Domain dstdomain me.examp.com
acl Internal_Domain dstdomain them.examp.com
acl Internal_Domain dstdomain here.examp.com
acl Internal_Domain dstdomain hereagain.examp.com
acl Internal_Domain dstdomain sigh.examp.com
acl Internal_Domain dstdomain me.examp2.com
acl Internal_Domain dstdomain  [-n] .me.examp3.com
acl Local_Network dst 149.200.214.0/24
acl Local_Network dst 152.130.186.0/24
acl Local_Network dst 192.168.0.0/16
acl Local_Network src 121.0.0.1

acl dummy_match dstdom_regex . #dummy match all domain regex

acl Inbound_Net_Scaler src 10.24.62.51
acl Outbound_Proxy src 10.213.51.18

acl SSL_ports port 443
acl Safe_ports port 80		
acl Safe_ports port 443		
acl CONNECT method CONNECT


# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports


deny_info 302: http://www.google.com/?%H dummy_match              
#Customized deny_info that will redirect to google with some addition 

http_access allow Inbound_Net_Scaler Internal_Domain            #rule that
allows netscaler sources traffic to access internal domains 
http_access allow Inbound_Net_Scaler acl Local_Network          #rule that
allows netscaler sources traffic to access internal ip addresses 


####Need code that states if traffic is from <http://www.google.com/?%H>
*Inbound_Net_Scaler * but does not match *Internal_Domain* or
*Local_Network* to re-direct it to *Outbound_Proxy* ####                  

http_access deny all


END CODE










--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Routing-Internally-And-Or-Externally-tp4677152p4677168.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From mcsnv96 at afo.net  Wed Apr 20 14:42:51 2016
From: mcsnv96 at afo.net (Mike)
Date: Wed, 20 Apr 2016 09:42:51 -0500
Subject: [squid-users] New to proxies
In-Reply-To: <201604201602.11199.Antony.Stone@squid.open.source.it>
References: <1461082288339-4677151.post@n4.nabble.com>
 <5717229C.50201@treenet.co.nz> <1461155647357-4677164.post@n4.nabble.com>
 <201604201602.11199.Antony.Stone@squid.open.source.it>
Message-ID: <5717956B.3020905@afo.net>

These are code words, they're looking to setup proxies to bypass 
filters, corporate networks, school blocks, and other setups designed to 
restrict their use (which they agreed to by using these limited 
networks). Another possibility is scammer/spammer using a virus with a 
proxy to reroute all sales based terms through their compromised links 
instead of legitimate searches and retailers, instead sending them to 
sellers of fake items in China and the Middle East.


On 4/20/2016 9:02 AM, Antony Stone wrote:
> On Wednesday 20 April 2016 at 14:34:07, cjwengler wrote:
>
>> I use the proxies for my sneaker program and I need one proxy per account
>> for that.
> Why?
>
>> Sometimes I run up to 1000 accounts.
> Do you have 1000 IP addresses?
>
>> The proxies are used for purchasing sneakers and clothing on sites such as
>> Nike, Adidas, Supreme, Footlocker, Eastbay, Champs, Finishline, etc.
> And, er, why are proxies, indeed multiple ones, needed for this?
>
>
> Antony.
>



From nking4930 at hotmail.com  Wed Apr 20 14:12:06 2016
From: nking4930 at hotmail.com (nkingsquid)
Date: Wed, 20 Apr 2016 07:12:06 -0700 (PDT)
Subject: [squid-users] Routing Internally And/Or Externally?
In-Reply-To: <57171E1A.2070404@treenet.co.nz>
References: <1461089765594-4677152.post@n4.nabble.com>
 <57171E1A.2070404@treenet.co.nz>
Message-ID: <1461161526230-4677170.post@n4.nabble.com>

Amos, I have changed the code around a bit to reflect what you guys have been
telling me.  The Netscaler is NATing.  Security before, after, and around
the device is substantial, I will tweak the coded to reflect that at a later
time, at the moment I am desperately looking for that 1 answer I mentioned
in the post above.

I did make a mistake originally saying that traffic that did NOT meet the
rules for internal sites goes back to the Netscaler, it will instead go to
another proxy (and various security measures) before it goes out to the
internet.

That's the code I am looking for.  redirect traffic to 2nd proxy if its not
trying to go to an internal resource.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Routing-Internally-And-Or-Externally-tp4677152p4677170.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From cjwengler at icloud.com  Wed Apr 20 14:12:42 2016
From: cjwengler at icloud.com (cjwengler)
Date: Wed, 20 Apr 2016 07:12:42 -0700 (PDT)
Subject: [squid-users] New to proxies
In-Reply-To: <5717956B.3020905@afo.net>
References: <1461082288339-4677151.post@n4.nabble.com>
 <5717229C.50201@treenet.co.nz> <1461155647357-4677164.post@n4.nabble.com>
 <201604201602.11199.Antony.Stone@squid.open.source.it>
 <5717956B.3020905@afo.net>
Message-ID: <1461161562975-4677171.post@n4.nabble.com>

I'm confused. I simply need high speed private proxies that work on sneakers
and shopping websites. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/New-to-proxies-tp4677151p4677171.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Apr 20 14:59:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Apr 2016 02:59:47 +1200
Subject: [squid-users] New to proxies
In-Reply-To: <1461161562975-4677171.post@n4.nabble.com>
References: <1461082288339-4677151.post@n4.nabble.com>
 <5717229C.50201@treenet.co.nz> <1461155647357-4677164.post@n4.nabble.com>
 <201604201602.11199.Antony.Stone@squid.open.source.it>
 <5717956B.3020905@afo.net> <1461161562975-4677171.post@n4.nabble.com>
Message-ID: <57179963.6080200@treenet.co.nz>

On 21/04/2016 2:12 a.m., cjwengler wrote:
> I'm confused. I simply need high speed private proxies that work on sneakers
> and shopping websites. 
> 

The use to which you would put them seems to be skirting the fine edge
of the law in many countries. For certain you would be violating the
shopping sites T&C policies, or you would not need a proxy. That alone
will limit who is willing and/or able to assist you.

Amos



From squid3 at treenet.co.nz  Wed Apr 20 15:34:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Apr 2016 03:34:35 +1200
Subject: [squid-users] Routing Internally And/Or Externally?
In-Reply-To: <1461161526230-4677170.post@n4.nabble.com>
References: <1461089765594-4677152.post@n4.nabble.com>
 <57171E1A.2070404@treenet.co.nz> <1461161526230-4677170.post@n4.nabble.com>
Message-ID: <5717A18B.8030503@treenet.co.nz>

On 21/04/2016 2:12 a.m., nkingsquid wrote:
> Amos, I have changed the code around a bit to reflect what you guys have been
> telling me.  The Netscaler is NATing.  Security before, after, and around
> the device is substantial, I will tweak the coded to reflect that at a later
> time, at the moment I am desperately looking for that 1 answer I mentioned
> in the post above.
> 
> I did make a mistake originally saying that traffic that did NOT meet the
> rules for internal sites goes back to the Netscaler, it will instead go to
> another proxy (and various security measures) before it goes out to the
> internet.
> 
> That's the code I am looking for.  redirect traffic to 2nd proxy if its not
> trying to go to an internal resource.
> 


Unfortunately no amount of security checks work in the presence of an
interception proxy. By definition the intercept itself is an attack that
has to be let through and there are major side effects of the secondary
things that become possible once it is through.

The security built into Squid itself to prevent CVE-2009-0801 and
related holes from bypassing everything else is also substantial and
forbids D-NAT being done externally to the machine Squid is running on.

Squid requires direct access to the kernel NAT table to de-obfuscate the
TCP traffic and validate that it is going to the place the client
intended it to. In the event of that validation failing Squid will act
transparently and ensure the packets continue where they were supposed
to if it were not there.

You need to:
* policy-route the traffic from the NetScaler to Squid,
* do the NAT on the Squid machine dirctly,
* use 'intercept' on the http_port receiving the NAT'ed traffic.

You can re-NAT the traffic outbound from Squid after it leaves Squid and
into your other proxy if you like, or "never_direct allow all". That
other proxy will be responsible for its own version of the CVE
protections all over again.

Amos



From rousskov at measurement-factory.com  Wed Apr 20 15:38:06 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 Apr 2016 09:38:06 -0600
Subject: [squid-users] ssl_bump newbie troubles
In-Reply-To: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>
References: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>
Message-ID: <5717A25E.9060605@measurement-factory.com>

On 04/20/2016 08:16 AM, Odhiambo Washington wrote:

> I even wonder if this config is correct:
> 
> acl ssl_bump_broken_sites  dstdomain ...
> ssl_bump none ssl_bump_broken_sites
> ssl_bump peek step1
> ssl_bump stare step2
> ssl_bump bump all

You did not say what you want Squid to do, so it is difficult to say
whether the config is correct. However, the following combinations look
strange to me:

* old "none" and new "peek" actions; use "splice" instead of "none"
* sometimes contradictory "peek" and "stare" actions; pick one kind
* sometimes contradictory "peek" and "bump" actions; if you intend to
bump, use "stare"

Also, you may want to use ssl::server_name ACL instead of dstdomain.
Remember that Squid may have no domain information until it is too late
to splice. Here is a polished config that may or may not do what you want:

  # Bump aggressively, including discovered-too-late broken_sites:
  acl ssl_bump_broken_sites ssl::server_name ...
  ssl_bump splice ssl_bump_broken_sites
  ssl_bump stare all
  ssl_bump bump all


> I had to import my CA to all devices (as a trusted CA) on
> the network so that they don't get the MITM notification. [...] People
> don't like intrusive changes.

"ssl_bump bump" implies intrusiveness. You need to decide whether
bumping connections is important enough to be intrusive. The alternative
is passive monitoring/splicing that does not require intrusive changes
but gives you less control. Pick your poison.

Alex.



From squid3 at treenet.co.nz  Wed Apr 20 15:51:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Apr 2016 03:51:42 +1200
Subject: [squid-users] ssl_bump newbie troubles
In-Reply-To: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>
References: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>
Message-ID: <5717A58E.5070802@treenet.co.nz>

On 21/04/2016 2:16 a.m., Odhiambo Washington wrote:
> Hi,
> 
> I am trying my hands on ssl_bump and it's almost working, but that's
> ish-ish.. because I have several problems.
> 
> I even wonder if this config is correct:
> 
> *acl step1 at_step SslBump1*
> *acl step2 at_step SslBump2*
> *acl step3 at_step SslBump3*
> 
> *acl ssl_bump_broken_sites  dstdomain
> "/usr/local/etc/squid/ssl_bump_broken_sites.txt"*
> *ssl_bump none ssl_bump_broken_sites*
> 

There is no HTTP message URL in TLS, so dstdomain does not work in
ssl_bump. Use ACL type "ssl::server_name" instead.

Also, the legacy action "none" is not compatible with peek/stare
actions. Use "splice" instead.

> 
> *acl step1 at_step SslBump1*
> *ssl_bump peek step1*
> *ssl_bump stare step2*
> *ssl_bump bump all*
> 
> *sslproxy_capath /etc/ssl/certs*
> *sslproxy_cert_error allow all*
> *#sslproxy_cert_error deny all*
> *sslproxy_flags DONT_VERIFY_PEER*

You should test with verification and errors enabled. That way you get
told by Squid what the problems are. This way things just get ignored
and then maybe TLS "mysteriously" dies.

> *sslproxy_cafile /usr/local/share/certs/ca-root-nss.crt*
> 
> 
> <cut>
> 
> The following error was encountered while trying to retrieve the URL:
> https://org.ke.m-pesa.com/*
> 
> *Failed to establish a secure connection to 196.201.214.212*
> 
> The system returned:
> 
> (92) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
> 
> Handshake with SSL server failed: error:14094412:SSL
> routines:SSL3_READ_BYTES:sslv3 alert bad certificate
> 
> This proxy and the remote host failed to negotiate a mutually acceptable
> security settings for handling your request. It is possible that the remote
> host does not support secure connections, or the proxy is not satisfied
> with the host security credentials.
> 
> 
> </cut>
> 
> 
> 
> I thought I could mitigate that with the:
> 
> *acl ssl_bump_broken_sites  dstdomain
> "/usr/local/etc/squid/ssl_bump_broken_sites.txt"*
> *ssl_bump none ssl_bump_broken_sites*
> 
> ..but that doesn't do it...

What you seem to have intended (splice) might work.

The message seem pretty clear. Squid was unable to validate the
certificate of that origin server.


> 
> Secondly, I had to import my CA to all devices (as a trusted CA) on the
> network so that they don't get the MITM notification. This is a challenge,
> because I have to do the same for smart phones too, and that is not easy.
> People don't like intrusive changes. For example on Android phone, you have
> to set screen security before you can import such a CA, and after you do,
> you cannot disable the screen security! Now, that is not something people
> want.

That import is mandatory for "bump" action to work without SSL/TLS warnings.

If you only use peek and splice actions then Squid is not touching the
crypto and it is not needed.

Amos



From auaauabubu at yahoo.de  Wed Apr 20 15:39:55 2016
From: auaauabubu at yahoo.de (epytir)
Date: Wed, 20 Apr 2016 08:39:55 -0700 (PDT)
Subject: [squid-users] Squid 3.5.9 Problems with Teamviewer
Message-ID: <1461166795323-4677176.post@n4.nabble.com>

Hey Squid Users,

Sorry for my bad english im learning it currently.

I got a little problem with my squid proxy.
I installed it with ufdbguard and squidclamav and everything works fine.

The users login with kerberos ntlm or normal username passowrt
authentication.

My Problem is when Users start Teamviewer (every Version) some time
teamviewer doing nothing then the message "no connection please check proxy
settings" appears. Then i klick nothing after 10 more seconds the teamviewer
is connected without changing anything.
So Teamviewer needs up to 1 minute to connect through the proxy without i
need like 5 seconds.

Teamviewer is not blocked for the users with the problems and it connects
but needs to much time. I have 1500 User so the normal user dont understand
that he must wait and dont klick on change settings or abort.

I log squid in database and every connect i see is not blocked:
| 23731740 |   1461164861.040 | 2016-04-20 | 17:07:41  | 48 | ip  | TCP_MISS 
| 200 | 15623 | GET | www.teamviewer.com     | Username| FIRSTUP_PARENT    |
NULL | NULL   |
| 23733412 |   1461165077.533 | 2016-04-20 | 17:11:18  |  11 | ip  |
TCP_MEM_HIT | 200  |   15631 | GET   | www.teamviewer.com  | Username|
HIER_NONE         | NULL           | NULL      |

The parent Proxy is not the problem cause our old proxy is tmg from
microsoft and use the same proxy without teamviewer problems. (we want to
shutdown tmg cause its extremly slow and squid is so fast :) ) 


Here are some information:
Squid 3.5.9
UFDB 1.31-16
Server Ubuntu 14.04 LTS

Squid config snip:
auth_param negotiate program /usr/lib/squid3/negotiate_wrapper_auth  --ntlm 
/usr/lib/squid3/fakeauth_auth  --kerberos 
/usr/lib/squid3/negotiate_kerberos_auth -r -s GSS_C_NO_NA$
auth_param negotiate children 80
auth_param negotiate keep_alive on

auth_param ntlm program /usr/lib/squid3/fakeauth_auth x.x.x\DC
auth_param ntlm children 30
auth_param ntlm keep_alive off

#LDAP Authentication
auth_param basic program  /usr/lib/squid3/basic_ldap_auth -b
"dc=X,dc=X,dc=X" -D "XXX at X.X.X" -w "XXXXXXXXX" -v 3 -h ldaps://X.X.X
auth_param basic children 30
auth_param basic realm Domain-Internet-Proxy
auth_param basic credentialsttl 30 day  #How often ask for Login credentials
auth_param basic casesensitive off

acl ldap-auth proxy_auth REQUIRED # Rule authentication needed
never_direct allow all
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
#http_access allow CONNECT SSL_ports
http_access allow localnet
http_access allow localhost

#LDAP User are allowed to connect to the Internet
http_access allow ldap-auth
http_access allow CONNECT  SSL_ports ldap-auth


# And finally deny all other access to this proxy
http_access deny all
.
.
.

Normal ntlm dont work but we have some old programms that need ntlm so i use
fake tnlm for them browsers only use kerberos.

In squid log i see nothing no entrys for the connection time.

Hope someone got the same issues and solved it.

Greetings,

Epytir




 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-9-Problems-with-Teamviewer-tp4677176.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bmarkey at steinmancommunications.com  Wed Apr 20 20:18:27 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Wed, 20 Apr 2016 20:18:27 +0000
Subject: [squid-users] Cert authority invalid failures.
Message-ID: <2B77BF184EAC2F43BB9FC908954D8B12670530CA@Ex5.lnpnews.com>

I'm curious as to why this is happening.

Proxy was implemented last week and since then I've been dealing with all the sites that don't work. Not a problem, knew it was going to happen. I'd like to understand why the following is happening.


1.       User goes to https://www.whatever.com

2.       Browser, mostly chrome, gives the following error.   Connection not private. NET:ERR_CERT_AUTHORITY_INVALID

3.       If you view the cert it shows the dynamic cert listed.

4.       Click the "Proceed to www.whatever.com<http://www.whatever.com> (unsafe )

5.       Now I get a squid error.  Requested url could not be retrieved.  Access denied while trying to retrieve https:// some ip address/*

Thing is I don't have an acl blocking that ip?   ( Small sub question here, is there a way to tell which acl blocks something? )

What I've had to do to get around this is add www.whatever.com<http://www.whatever.com> to my broken_sites.acl.    Then add the ip to an allowed_ips.acl.

Then I http_access allow the ips list

And skip peeking at the broken site.

acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"
ssl_bump peek !broken_sites
ssl_bump splice all

I'm trying to understand why this is breaking and if I'm doing the right thing in fixing it.


The second error I'm getting is:


The following error was encountered while trying to retrieve the URL: https://*.agentimediaservices.com/*<https://%2A.agentimediaservices.com/*>

Failed to establish a secure connection to 63.240.52.151

The system returned:

(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)

SSL Certficate error: certificate issuer (CA) not known: /C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA
Same question.  From what I've read this means that I don't have the correct root ca?  Is that correct?  If so is the fix to then go try to find the correct .crt and add it to the standard ca-cert store? ( I'm on debian so /usr/share/ca-certificates/Mozilla )

Again, is this correct as to what is going wrong and the correct fix?

Thank you


Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758 (o) | bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160420/5a8c744b/attachment.htm>

From odhiambo at gmail.com  Wed Apr 20 20:22:23 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Wed, 20 Apr 2016 23:22:23 +0300
Subject: [squid-users] ssl_bump newbie troubles
In-Reply-To: <5717A25E.9060605@measurement-factory.com>
References: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>
 <5717A25E.9060605@measurement-factory.com>
Message-ID: <CAAdA2WOKT6XzmZFERyxaL2U4_V-B39viW1asmiFLBXDrx-5qJA@mail.gmail.com>

On 20 April 2016 at 18:38, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/20/2016 08:16 AM, Odhiambo Washington wrote:
>
> > I even wonder if this config is correct:
> >
> > acl ssl_bump_broken_sites  dstdomain ...
> > ssl_bump none ssl_bump_broken_sites
> > ssl_bump peek step1
> > ssl_bump stare step2
> > ssl_bump bump all
>
> You did not say what you want Squid to do, so it is difficult to say
> whether the config is correct. However, the following combinations look
> strange to me:
>
> * old "none" and new "peek" actions; use "splice" instead of "none"
> * sometimes contradictory "peek" and "stare" actions; pick one kind
> * sometimes contradictory "peek" and "bump" actions; if you intend to
> bump, use "stare"
>
Also, you may want to use ssl::server_name ACL instead of dstdomain.
> Remember that Squid may have no domain information until it is too late
> to splice. Here is a polished config that may or may not do what you want:
>
>   # Bump aggressively, including discovered-too-late broken_sites:
>   acl ssl_bump_broken_sites ssl::server_name ...
>   ssl_bump splice ssl_bump_broken_sites
>   ssl_bump stare all
>   ssl_bump bump all
>

Hi Alex,

Thank you for looking into and advising about this. I really do not want to
get intrusive on the setup.
All I want is the ability to intercept SSL sites and control access to them
using TIME ACLs. That's all.
Sites should be accessed without any interference apart from determining at
what time they can be
accessed by certain restricted users. Think about restricting facebook.com,
youtube.com, etc which
otherwise I would not have control over in a normal intercept. That's the
only reaon I need this ssl_bump stuff.

So in simple:
1. UserX tries to access facebook.com/youtube.com
2. I intercept transparently https traffic
3. I tell squid "don't allow this user to access facebook.com at this time,
but let them access at some-other-time
4. If time is right, let userX access the site.

I still need to wrap my hear around thise 'stare' and 'peek' and what
happens with them.


> > I had to import my CA to all devices (as a trusted CA) on
> > the network so that they don't get the MITM notification. [...] People
> > don't like intrusive changes.
>
> "ssl_bump bump" implies intrusiveness. You need to decide whether
> bumping connections is important enough to be intrusive. The alternative
> is passive monitoring/splicing that does not require intrusive changes
> but gives you less control. Pick your poison.
>
> Alex.
>


So looks like all I need is a setup of passive monitoring, given my
explanation above, right?
Don't bump, just monitor and restrict access to some users based on time.
Generally I want to
control access to those sites users usually waste time on during work
hours:-)




-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160420/e21378ee/attachment.htm>

From rousskov at measurement-factory.com  Wed Apr 20 21:11:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 Apr 2016 15:11:52 -0600
Subject: [squid-users] ssl_bump newbie troubles
In-Reply-To: <CAAdA2WOKT6XzmZFERyxaL2U4_V-B39viW1asmiFLBXDrx-5qJA@mail.gmail.com>
References: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>
 <5717A25E.9060605@measurement-factory.com>
 <CAAdA2WOKT6XzmZFERyxaL2U4_V-B39viW1asmiFLBXDrx-5qJA@mail.gmail.com>
Message-ID: <5717F098.3090206@measurement-factory.com>

On 04/20/2016 02:22 PM, Odhiambo Washington wrote:

> All I want is the ability to intercept SSL sites and control access to
> them using TIME ACLs. That's all.

I will assume that your definition of a "site" is "domain name".


> So in simple:
> 1. UserX tries to access facebook.com/youtube.com
> 2. I intercept transparently https traffic 
> 3. I tell squid "don't allow this user to access facebook.com
>  at this time, but let them access at some-other-time
> 4. If time is right, let userX access the site.

> So looks like all I need is a setup of passive monitoring, given my
> explanation above, right? 

The answer depends on what you want Squid to do when access is not
allowed. If you are OK with terminating the prohibited connection (no
error messages explaining company policy sent by Squid to your users!),
then yes:

  ssl_bump terminate restricted_sites
  ssl_bump peek all
  ssl_bump splice all

As typical for SslBump, Squid has bugs and missing features in some
corner cases touched by the above simple configuration, so some
babysitting and additional configuration is likely, but it should work
in principle. Known bugs can be fixed and missing features added.


HTH,

Alex.



From odhiambo at gmail.com  Wed Apr 20 22:18:00 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 01:18:00 +0300
Subject: [squid-users] ssl_bump newbie troubles
In-Reply-To: <5717F098.3090206@measurement-factory.com>
References: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>
 <5717A25E.9060605@measurement-factory.com>
 <CAAdA2WOKT6XzmZFERyxaL2U4_V-B39viW1asmiFLBXDrx-5qJA@mail.gmail.com>
 <5717F098.3090206@measurement-factory.com>
Message-ID: <CAAdA2WMSKPDMwicdQbqz62B_nCsJQ2mdbeu7Zj0yQr_AaeYkxQ@mail.gmail.com>

On 21 April 2016 at 00:11, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/20/2016 02:22 PM, Odhiambo Washington wrote:
>
> > All I want is the ability to intercept SSL sites and control access to
> > them using TIME ACLs. That's all.
>
> I will assume that your definition of a "site" is "domain name".
>

Yes.


>
> > So in simple:
> > 1. UserX tries to access facebook.com/youtube.com
> > 2. I intercept transparently https traffic
> > 3. I tell squid "don't allow this user to access facebook.com
> >  at this time, but let them access at some-other-time
> > 4. If time is right, let userX access the site.
>
> > So looks like all I need is a setup of passive monitoring, given my
> > explanation above, right?
>
> The answer depends on what you want Squid to do when access is not
> allowed. If you are OK with terminating the prohibited connection (no
> error messages explaining company policy sent by Squid to your users!),
> then yes:
>
>   ssl_bump terminate restricted_sites
>   ssl_bump peek all
>   ssl_bump splice all
>


What I would like is:

1. that squid is able to 'see' that *userX* is trying to visit
https://www.facebook.com
2. but at that particular time (time ACL) *userX* is not allowed to go to
facebook.com, so squid denies access, throws a default error on their
browser
3. However, *userY* has unrestricted access to anywhere at all times so
squid allows the user to proceed.
The time logic is already built in squid.conf. All that remains is just
intercept https traffic and let the time acls decide whether or not a user
can get there..


So allow me to ask: in *ssl_bump terminate restricted_sites, * I am lost as
to what restricted_sites represent.

If my squid.conf matters, I have it here: http://goo.gl/vA6nrB. All I want
is to restrict/control (using time) access to TIMEWASTAGESITES :-)
I do not need to bump at all.

(My English could be my undoing here :-))

Thanks for your patience in baby-sitting me.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/68fd129a/attachment.htm>

From rousskov at measurement-factory.com  Wed Apr 20 22:46:04 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 Apr 2016 16:46:04 -0600
Subject: [squid-users] ssl_bump newbie troubles
In-Reply-To: <CAAdA2WMSKPDMwicdQbqz62B_nCsJQ2mdbeu7Zj0yQr_AaeYkxQ@mail.gmail.com>
References: <CAAdA2WMPvm9US20+m3Dk=PMg=ddXjO9gq9RZitBomDVOSznM4g@mail.gmail.com>
 <5717A25E.9060605@measurement-factory.com>
 <CAAdA2WOKT6XzmZFERyxaL2U4_V-B39viW1asmiFLBXDrx-5qJA@mail.gmail.com>
 <5717F098.3090206@measurement-factory.com>
 <CAAdA2WMSKPDMwicdQbqz62B_nCsJQ2mdbeu7Zj0yQr_AaeYkxQ@mail.gmail.com>
Message-ID: <571806AC.4010002@measurement-factory.com>

On 04/20/2016 04:18 PM, Odhiambo Washington wrote:
> On 21 April 2016 at 00:11, Alex Rousskov wrote:
> 
>     On 04/20/2016 02:22 PM, Odhiambo Washington wrote:
> 
>     > All I want is the ability to intercept SSL sites and control access to
>     > them using TIME ACLs. That's all.

You also want to serve custom errors over encrypted connections. That is
a huge addition to the above "all".


>     If you are OK with terminating the prohibited connection (no
>     error messages explaining company policy sent by Squid to your users!),
>     then yes:
> 
>       ssl_bump terminate restricted_sites
>       ssl_bump peek all
>       ssl_bump splice all
> 
> 
> 
> What I would like is:
> 
> 1. that squid is able to 'see' that *userX* is trying to visit
> https://www.facebook.com
> 2. but at that particular time (time ACL) *userX* is not allowed to go
> to facebook.com <http://facebook.com>, so squid denies access, throws a
> default error on their browser

Serving a Squid-generated error over [what the browser believes is] a
secure connection to the _origin server_ requires bumping that
connection. Bumping (as opposed to splicing) implies installing company
root certificates and many other headaches.

In other words, your desire to immediately inform the user about the
denied access opens a Pandora box and adds a whole new order of
complexity (or two) to the project.

Instant gratification is very important these days, but there are
probably alternatives to serving error pages over bumped connections.
The simplest to implement might be something like sending a "you have
been blocked" email to the offending user (from the blocking ACL
script), but one can think of a lot fancier notification vectors than that.


> The time logic is already built in squid.conf. All that remains is just
> intercept https traffic and let the time acls decide whether or not a
> user can get there.

... and bump the supposedly secure connection to serve the error page if
the user cannot get there.


> So allow me to ask: in *ssl_bump terminate restricted_sites, * I am lost
> as to what restricted_sites represent.

It is an ACL that represents your "access control" logic. It is too
boring/standard to discuss while we are talking about SslBump. I am sure
you can define it (yourself or with help from this mailing list).

If you allow me an analogy, discussing that ACL is like discussing the
color of the paint on the atomic bomb. I am sure you will find a nice
color scheme eventually, but I am more concerned about your users
staying alive after you drop it on them.


Alex.



From azzialink at gmail.com  Thu Apr 21 01:51:35 2016
From: azzialink at gmail.com (zodyo)
Date: Wed, 20 Apr 2016 18:51:35 -0700 (PDT)
Subject: [squid-users] squid 2.7/lusca not work with web auth IIS
In-Reply-To: <1461121237878-4677157.post@n4.nabble.com>
References: <1461121237878-4677157.post@n4.nabble.com>
Message-ID: <1461203495317-4677182.post@n4.nabble.com>

anybody here? im newbie and need some advice here, or how to bypass some
sites with auth



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-2-7-lusca-not-work-with-web-auth-IIS-tp4677157p4677182.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Thu Apr 21 07:48:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Apr 2016 19:48:34 +1200
Subject: [squid-users] squid 2.7/lusca not work with web auth IIS
In-Reply-To: <1461203495317-4677182.post@n4.nabble.com>
References: <1461121237878-4677157.post@n4.nabble.com>
 <1461203495317-4677182.post@n4.nabble.com>
Message-ID: <571885D2.70704@treenet.co.nz>

On 21/04/2016 1:51 p.m., zodyo wrote:
> anybody here? im newbie and need some advice here, or how to bypass some
> sites with auth
>

Lusca is not Squid. It is a fork by Xenion with quite a few changes. You
will need to contact there about support.

... or upgrade to a Squid-3 version we provide support for.

Amos



From squid3 at treenet.co.nz  Thu Apr 21 11:28:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Apr 2016 23:28:47 +1200
Subject: [squid-users] [squid-announce] Squid 3.5.17 is available
Message-ID: <5718B96F.3020805@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.5.17 release!


This release is a security and bug fix release resolving several
vulnerabilities and issues found in the prior Squid releases.


The major changes to be aware of:


* SQUID-2016:5 - Buffer overflow in cachemgr.cgi

    http://www.squid-cache.org/Advisories/SQUID-2016_5.txt
    aka. CVE-2016-4051

Due to incorrect buffer management Squid cachemgr.cgi tool is
vulnerable to a buffer overflow when processing remotely supplied
inputs relayed to it from Squid.


* SQUID-2016:6 - Multiple issues in ESI processing.

    http://www.squid-cache.org/Advisories/SQUID-2016_6.txt
    aka. CVE-2016-4052, CVE-2016-4053, CVE-2016-4054

This issue is really quite nasty and has been rated 8.3 on the CVSS
scale. Upgrade or patching should be considered a very high priority.

At best it creates a denial of service. At worst it allows clients to
read contents of the Squid process stack and remote servers to inject
code into that stack for execution.

Most Squid-3 and Squid-4 configured as reverse-proxy or SSL-Bump'ing are
at risk. Check the advisory for more specific details on determining
whether your Squid is vulnerable.


* Bug #4481: varyEvaluateMatch: Oops. Not a Vary match on second attempt

This bug was a regression introdued by the CVE-2016-3948 patch. Any
Squid patched for that issue should have this bug patched as well.


* Bug 4465: Header forgery detection leads to crash

This very annoying bug has finally been tracked down and solved.


* Add chained and signing cert to peek-then-bumped connections.

Until now Squid with this particular configuration case was only
delivering one of the certificates in the chain. Which can cause
problems when the clients are configured with a CA higher up the chain
than the one Squid is using to sign generated domain certs.

From this release onwards Squid will deliver the whole certificate chain
and let the client determine whether it wil be trusted or not.



 All users of Squid-3 or older are urged to upgrade to this release as
soon as possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Thu Apr 21 11:28:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Apr 2016 23:28:52 +1200
Subject: [squid-users] [squid-announce] Squid 4.0.9 beta is available
Message-ID: <5718B974.7060902@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.9 release!


This release is a security and bug fix release resolving several
vulnerabilities and issues found in the prior Squid releases.


The major changes to be aware of:


* SQUID-2016:5 - Buffer overflow in cachemgr.cgi

    http://www.squid-cache.org/Advisories/SQUID-2016_5.txt
    aka. CVE-2016-4051

Due to incorrect buffer management Squid cachemgr.cgi tool is
vulnerable to a buffer overflow when processing remotely supplied
inputs relayed to it from Squid.


* SQUID-2016:6 - Multiple issues in ESI processing.

    http://www.squid-cache.org/Advisories/SQUID-2016_6.txt
    aka. CVE-2016-4052, CVE-2016-4053, CVE-2016-4054

This issue is really quite nasty and has been rated 8.3 on the CVSS
scale. Upgrade or patching should be considered a very high priority.

At best it creates a denial of service. At worst it allows clients to
read contents of the Squid process stack and remote servers to inject
code into that stack for execution.

Most Squid-3 and Squid-4 configured as reverse-proxy or SSL-Bump'ing are
at risk. Check the advisory for more specific details on determining
whether your Squid is vulnerable.


* Add a new error page token for unquoted external ACL messages.

This small feature addition may be of use to those who have been asking
for ways to insert content into Squid error pages from external ACL
helper responses.


* Stop parsing response prefix after discovering an "HTTP/0.9" response.

It appears that there are still some very old servers out there or at
least services using port 80 for non-HTTP protocols. The new Squid-4
parser has not been dealing with these very well. This release should be
a lot more stable with the HTTP/1.1 conversion of that response traffic.



 All users of Squid-4.0.x are urged to upgrade to this release as soon
as possible.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Thu Apr 21 11:28:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Apr 2016 23:28:55 +1200
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2016:5 Buffer
	overflow in	cachemgr.cgi
Message-ID: <5718B977.20204@treenet.co.nz>

__________________________________________________________________

    Squid Proxy Cache Security Update Advisory SQUID-2016:5
__________________________________________________________________

Advisory ID:            SQUID-2016:5
Date:                   April 20, 2016
Summary:                Buffer overflow in cachemgr.cgi
Affected versions:      Squid 2.x all releases
                        Squid 3.x -> 3.5.16
                        Squid 4.x -> 4.0.8
Fixed in version:       Squid 3.5.17, 4.0.9
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_5.txt
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4051
    CESG REF: 56397140 / VULNERABILITY ID: 394201
__________________________________________________________________

Problem Description:

 Due to incorrect buffer management Squid cachemgr.cgi tool is
 vulnerable to a buffer overflow when processing remotely supplied
 inputs relayed to it from Squid.

__________________________________________________________________

Severity:

 This problem allows any client to seed the Squid manager reports
 with data that will cause a buffer overflow when processed by
 the cachemgr.cgi tool.

 However, this does require manual administrator actions to take
 place. Which greatly reduces the impact and possible uses.
__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid versions 3.5.17 and 4.0.9

 In addition, patches addressing this problem for stable releases
 can be found in our patch archives:

Squid 3.2:
 <http://www.squid-cache.org/Versions/v3/3.2/changesets/SQUID-2016_5.patch>

Squid 3.3:
 <http://www.squid-cache.org/Versions/v3/3.3/changesets/SQUID-2016_5.patch>

Squid 3.4:
 <http://www.squid-cache.org/Versions/v3/3.4/changesets/SQUID-2016_5.patch>

Squid 3.5:
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/SQUID-2016_5.patch>

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

 Squid proxy is not vulnerable. The problem is isolated to the
 manager CGI interface tool.

 The vulnerability is also limited to reports displaying full URL
 and/or similar unbounded values provided by the client. That
 includes the reports:

  filedescriptors, objects, vm_objects, active_requests,
  client_list, and mem on certain systems.


 cachemgr.cgi tool displays its version number in the HTML page
 footer:

  All 2.x versions up to and including 2.7.STABLE9 are vulnerable.

  All 3.x versions up to and including 3.5.16 are vulnerable.

  All 4.x versions up to and including 4.0.8 are vulnerable.

  If your cachemgr.cgi does not display a version it is likely
  to be one of the older vulnerable versions.

__________________________________________________________________

Workaround:

 Use tools other than cachemgr.cgi, such as squidclient to view
 affected reports until the CGI tool can be patched or upgraded.

OR,

 In recent Squid versions use the HTTP management interface
 directly from the squid proxy to view affected reports.

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If you install and build Squid from the original Squid sources
 then the squid-users at squid-cache.org mailing list is your
 primary support point. For subscription details see
 http://www.squid-cache.org/Support/mailing-lists.html.

 For reporting of non-security bugs in the latest release
 the squid bugzilla database should be used
 http://bugs.squid-cache.org/.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at squid-cache.org mailing list. It is a closed list
 (though anyone can post) and security related bug reports are
 treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 The vulnerability was discovered independently by CESG and
 by Yuriy M. Kaminskiy.

 Fixed by Amos Jeffries from Treehouse Networks Ltd.

__________________________________________________________________

Revision history:

 2016-04-15 10:54:39 GMT Initial Report
 2016-04-20 03:54:54 GMT Patches Released
 2016-04-20 13:42:00 GMT Packages Released
 2016-04-20 15:47:01 GMT CVE Assigned
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Thu Apr 21 11:28:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Apr 2016 23:28:59 +1200
Subject: [squid-users] [squid-announce] [ADVISORY SQUID-2016:6 Multiple
	issues in ESI	processing.
Message-ID: <5718B97B.8060502@treenet.co.nz>

__________________________________________________________________

Squid Proxy Cache Security Update Advisory SQUID-2016:6
__________________________________________________________________

Advisory ID:        SQUID-2016:6
Date:               April 20, 2016
Summary:            Multiple issues in ESI processing.
Affected versions:  Squid 3.x -> 3.5.16
                    Squid 4.x -> 4.0.8
Fixed in version:   Squid 3.5.17, 4.0.9
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_6.txt
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4052
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4053
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4054
    CESG REF: 56284998 / VULNERABILITY ID: 393536
__________________________________________________________________

Problem Description:

 Due to buffer overflow issues Squid is vulnerable to a denial
 of service attack when processing ESI responses.

 Due to incorrect input validation Squid is vulnerable to public
 information disclosure of the server stack layout when processing
 ESI responses.

 Due to incorrect input validation and buffer overflow Squid is
 vulnerable to remote code execution when processing ESI
 responses.
__________________________________________________________________

Severity:

 These problems allow ESI components to be used to perform a
 denial of service attack on the Squid service and all other
 services on the same machine.

 Under certain build conditions these problems allow remote
 clients to view large sections of the server memory.

 However, the bugs are exploitable only if you have built and
 configured the ESI features to be used by a reverse-proxy and if
 the ESI components being processed by Squid can be controlled by
 an attacker.
__________________________________________________________________

Updated Packages:

 These bugs are fixed by Squid version 3.5.17 and 4.0.9.

 In addition, patches addressing this problem for stable releases
 can be found in our patch archives:

Squid 3.2:
 <http://www.squid-cache.org/Versions/v3/3.2/changesets/squid-3.2-11841.patch>

Squid 3.3:
 <http://www.squid-cache.org/Versions/v3/3.3/changesets/squid-3.3-12697.patch>

Squid 3.4:
 <http://www.squid-cache.org/Versions/v3/3.4/changesets/squid-3.4-13235.patch>

Squid 3.5:
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14034.patch>

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

Use the command 'squid -v' to view version and build details of
your proxy;

 All Squid 2.x are not vulnerable.

 All Squid built with --disable-esi are not vulnerable.

 All Squid built without --enable-esi are not vulnerable.


Check squid.conf or use the (version 3.4+) command
  (squid -k parse 2>&1) | grep "Processing: http.*_port"
to view the active configuration settings for your proxy;

 Unpatched Squid 3.x and 4.x built with --enable-esi and
 configured with 'accel' or 'vhost' or 'defaultsite=' or
 'ssl-bump' on an http_port or https_port are vulnerable.

 All Squid configured without reverse-proxy or ssl-bump are
 not vulnerable.

__________________________________________________________________

Workaround:

 Build Squid with --disable-esi if ESI is not needed.

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If you install and build Squid from the original Squid sources
 then the squid-users at squid-cache.org mailing list is your
 primary support point. For subscription details see
 http://www.squid-cache.org/Support/mailing-lists.html.

 For reporting of non-security bugs in the latest release
 the squid bugzilla database should be used
 http://bugs.squid-cache.org/.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at squid-cache.org mailing list. It is a closed list
 (though anyone can post) and security related bug reports are
 treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 The vulnerability was reported by CESG.

 Fixed by Amos Jeffries, Treehouse Networks Ltd.

__________________________________________________________________

Revision history:

 2016-04-15 10:54:39 GMT Initial Report
 2016-04-20 03:54:54 GMT Patches Released
 2016-04-20 13:42:00 GMT Packages Released
 2016-04-20 15:47:01 GMT CVE Assigned
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Thu Apr 21 12:59:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Apr 2016 00:59:00 +1200
Subject: [squid-users] Cert authority invalid failures.
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B12670530CA@Ex5.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B12670530CA@Ex5.lnpnews.com>
Message-ID: <5718CE94.7020004@treenet.co.nz>

On 21/04/2016 8:18 a.m., Markey, Bruce wrote:
> I'm curious as to why this is happening.
> 
> Proxy was implemented last week and since then I've been dealing with all the sites that don't work. Not a problem, knew it was going to happen. I'd like to understand why the following is happening.
> 
> 
> 1.       User goes to https://www.whatever.com
> 
> 2.       Browser, mostly chrome, gives the following error.   Connection not private. NET:ERR_CERT_AUTHORITY_INVALID
> 

Typing that into search engine produces a thread explaining that it is
the browser message shown when HSTS is in effect on a website and the
server cert is not trusted by the browser.



> 3.       If you view the cert it shows the dynamic cert listed.
> 
> 4.       Click the "Proceed to www.whatever.com<http://www.whatever.com> (unsafe )
> 
> 5.       Now I get a squid error.  Requested url could not be retrieved.  Access denied while trying to retrieve https:// some ip address/*
> 

And that #5 explains why. It was actually not the web server producing
the cert. But Squid doing SSL-Bumping in order to show you the error page.



> Thing is I don't have an acl blocking that ip?   ( Small sub question here, is there a way to tell which acl blocks something? )
> 

Something clearly is. But not what you expect, or you would not be here
asking about it.

> What I've had to do to get around this is add www.whatever.com<http://www.whatever.com> to my broken_sites.acl.    Then add the ip to an allowed_ips.acl.
> 
> Then I http_access allow the ips list
> 
> And skip peeking at the broken site.
> 
> acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"
> ssl_bump peek !broken_sites
> ssl_bump splice all
> 
> I'm trying to understand why this is breaking and if I'm doing the right thing in fixing it.
> 

Please provide your whole squid.conf (except empty or # comment lines).
We might need to see it all to find what the problem is.


> 
> The second error I'm getting is:
> 
> 
> The following error was encountered while trying to retrieve the URL: https://*.agentimediaservices.com/*<https://%2A.agentimediaservices.com/*>
> 
> Failed to establish a secure connection to 63.240.52.151
> 
> The system returned:
> 
> (71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
> 
> SSL Certficate error: certificate issuer (CA) not known: /C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA
> Same question.  From what I've read this means that I don't have the correct root ca?  Is that correct?  If so is the fix to then go try to find the correct .crt and add it to the standard ca-cert store? ( I'm on debian so /usr/share/ca-certificates/Mozilla )
> 
> Again, is this correct as to what is going wrong and the correct fix?

Well, first step is to ensure your ca-certificates package is up to
date. That usually solves these.

But not always, especially if the CA has been caught doing bad things
and suddenly dropped. Or if they have begun issuing certs to clients
before being accepted by the Mozilla CA list people.

It could also be a problem with intermediary cert just being omitted by
the server. In that case adding it to your server-wide cert store or
configuring it to be loaded by Squid will be needed.

Amos



From odhiambo at gmail.com  Thu Apr 21 13:18:32 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 16:18:32 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
Message-ID: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>

Is is expected that  using ssl_bump results into high CPU usage all the
time?

This is squid-3.5.17

That is what I am seeing:

last pid: 26673;  load averages:  2.24,  2.00,  2.10

              up 0+03:47:56  16:08:30
160 processes: 2 running, 157 sleeping, 1 zombie
CPU: 86.1% user,  0.0% nice,  7.8% system,  3.3% interrupt,  2.7% idle
Mem: 843M Active, 1942M Inact, 185M Wired, 43M Cache, 89M Buf, 97M Free
Swap: 5900M Total, 1248K Used, 5899M Free

  PID USERNAME       THR PRI NICE   SIZE    RES STATE   C   TIME    WCPU
COMMAND
13309 squid           17  20    0   305M   264M uwait   0   7:38  80.86%
squid
26088 squid            1  21    0 12812K  5352K sbwait  1   0:04   2.49%
ssl_crtd
26090 squid            1  20    0 12812K  5272K sbwait  1   0:01   0.88%
ssl_crtd


My config has:



acl no_ssl_interception ssl::server_name
"/usr/local/etc/squid/ssl_bump_broken_sites.txt"
ssl_bump splice no_ssl_interception
ssl_bump peek step1
ssl_bump stare step2
#ssl_bump bump all
#ssl_bump splice all

I think I read somewhere that 'ssl_bump splice all" is the default
behaviour, hence why I have commented it out. All I need is just become a
TCP tunnel without decrypting proxied traffic.

Thank you.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/e1e407c8/attachment.htm>

From yvoinov at gmail.com  Thu Apr 21 13:22:52 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 21 Apr 2016 19:22:52 +0600
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
Message-ID: <bb03c512-857c-38af-a3ab-1f0455113ecd@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
It must not be. My most active setup has 3% CPU all time dirung peak hours.

Typical view:

https://i1.someimage.com/NzM1erI.png


21.04.16 19:18, Odhiambo Washington ?????:
> Is is expected that  using ssl_bump results into high CPU usage all the time?
>
> This is squid-3.5.17
>
> That is what I am seeing:
>
> last pid: 26673;  load averages:  2.24,  2.00, 
2.10                                                                                                                
up 0+03:47:56  16:08:30
> 160 processes: 2 running, 157 sleeping, 1 zombie
> CPU: 86.1% user,  0.0% nice,  7.8% system,  3.3% interrupt,  2.7% idle
> Mem: 843M Active, 1942M Inact, 185M Wired, 43M Cache, 89M Buf, 97M Free
> Swap: 5900M Total, 1248K Used, 5899M Free
>
>   PID USERNAME       THR PRI NICE   SIZE    RES STATE   C   TIME   
WCPU COMMAND
> 13309 squid           17  20    0   305M   264M uwait   0   7:38 
80.86% squid
> 26088 squid            1  21    0 12812K  5352K sbwait  1   0:04  
2.49% ssl_crtd
> 26090 squid            1  20    0 12812K  5272K sbwait  1   0:01  
0.88% ssl_crtd
>
>
> My config has:
>
>
>
> acl no_ssl_interception ssl::server_name
"/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> ssl_bump splice no_ssl_interception
> ssl_bump peek step1
> ssl_bump stare step2
> #ssl_bump bump all
> #ssl_bump splice all
>
> I think I read somewhere that 'ssl_bump splice all" is the default
behaviour, hence why I have commented it out. All I need is just become
a TCP tunnel without decrypting proxied traffic.
>
> Thank you.
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXGNQsAAoJENNXIZxhPexGcZUIAL3zFz9UFuQdyfXFBilFQ0Gj
8F4HkxuJjNtCUYdb6BEwux9jBOjZpYScr8sRHRBPvIV8O4/2Z3QF7exjEW8Duj/G
REWO3txPiE4pICD/AbdBuX8O++dvfjj46nz+lVeCH9JjGW0VoMHiyGtwGx1shSfY
pGX0MguEGEtWp/7hxKAFbRivGuvyQ7Ogj8i9IgMBptMrRu4D3G75UO+9WmaHcpVx
VAf1revHh+dWFWrO1k+zrWFIIFcwbR5LcrJeBYJ94scgPV3p68LC2ZpqUBZreYCM
Koo9+Rss+Ix1rTSUkvTaoGOcMdrHJ1oMICHwyqtDMWlbDds5dAnnWXh5faNYPFk=
=7YlO
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/f6780d6e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/f6780d6e/attachment.key>

From squid3 at treenet.co.nz  Thu Apr 21 13:26:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Apr 2016 01:26:08 +1200
Subject: [squid-users] Squid 3.5.9 Problems with Teamviewer
In-Reply-To: <1461166795323-4677176.post@n4.nabble.com>
References: <1461166795323-4677176.post@n4.nabble.com>
Message-ID: <5718D4F0.7020601@treenet.co.nz>

On 21/04/2016 3:39 a.m., epytir wrote:
> Hey Squid Users,
> 
> Sorry for my bad english im learning it currently.
> 
> I got a little problem with my squid proxy.
> I installed it with ufdbguard and squidclamav and everything works fine.
> 
> The users login with kerberos ntlm or normal username passowrt
> authentication.
> 
> My Problem is when Users start Teamviewer (every Version) some time
> teamviewer doing nothing then the message "no connection please check proxy
> settings" appears. Then i klick nothing after 10 more seconds the teamviewer
> is connected without changing anything.
> So Teamviewer needs up to 1 minute to connect through the proxy without i
> need like 5 seconds.
> 
> Teamviewer is not blocked for the users with the problems and it connects
> but needs to much time. I have 1500 User so the normal user dont understand
> that he must wait and dont klick on change settings or abort.
> 
> I log squid in database and every connect i see is not blocked:
> | 23731740 |   1461164861.040 | 2016-04-20 | 17:07:41  | 48 | ip  | TCP_MISS 
> | 200 | 15623 | GET | www.teamviewer.com     | Username| FIRSTUP_PARENT    |
> NULL | NULL   |
> | 23733412 |   1461165077.533 | 2016-04-20 | 17:11:18  |  11 | ip  |
> TCP_MEM_HIT | 200  |   15631 | GET   | www.teamviewer.com  | Username|
> HIER_NONE         | NULL           | NULL      |
> 

You missed out the bit where the column titles were described so we know
what that above means.


> The parent Proxy is not the problem cause our old proxy is tmg from
> microsoft and use the same proxy without teamviewer problems. (we want to
> shutdown tmg cause its extremly slow and squid is so fast :) ) 
> 

Maybe it, is maybe it isn't. Not a safe assumption.

It is likely tmg and Squid are talking to it slightly differently which
might make it do different things and hit some bug you never saw before.
The older that parent proxy software is the more likely this is to happen.


> 
> Here are some information:
> Squid 3.5.9
> UFDB 1.31-16
> Server Ubuntu 14.04 LTS
> 

The old Squid version could also be a problem. We have found and fixed
quite a lot of bugs in the last 2 years.

A useful rule of thumb when dealing with squid issues is to first try an
upgrade and see if the issue is resolved already.

If you can wait a few days I suggest trying for an upgrade to Ubuntu
Xenial 16.04 LTS, which should appear any day now and has a much better
Squid in it.


> Squid config snip:
> auth_param negotiate program /usr/lib/squid3/negotiate_wrapper_auth  --ntlm 
> /usr/lib/squid3/fakeauth_auth  --kerberos 
> /usr/lib/squid3/negotiate_kerberos_auth -r -s GSS_C_NO_NA$

The above line got truncated.

> auth_param negotiate children 80
> auth_param negotiate keep_alive on

I recommend using "off" here. It seems to be needed by recent Firefox
and some other tools as well.

> 
> auth_param ntlm program /usr/lib/squid3/fakeauth_auth x.x.x\DC

This "x.x.x\DC" thing is suspicious. If it is actually needed, then I
suspect it should be on the Negotiate/NTLM helper as well as the NTLM one.


> auth_param ntlm children 30
> auth_param ntlm keep_alive off
> 
> #LDAP Authentication
> auth_param basic program  /usr/lib/squid3/basic_ldap_auth -b
> "dc=X,dc=X,dc=X" -D "XXX at X.X.X" -w "XXXXXXXXX" -v 3 -h ldaps://X.X.X
> auth_param basic children 30
> auth_param basic realm Domain-Internet-Proxy
> auth_param basic credentialsttl 30 day  #How often ask for Login credentials
> auth_param basic casesensitive off
> 
> acl ldap-auth proxy_auth REQUIRED # Rule authentication needed
> never_direct allow all
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> #http_access allow CONNECT SSL_ports

The security rule provided is "deny CONNECT !SSL_Ports".

That is *not* the same as "allow CONNECT SSL_Ports".

It uses "deny" explicitly to prevent other rules later in the config
doing unexpected bad things...


> http_access allow localnet
> http_access allow localhost
> 
> #LDAP User are allowed to connect to the Internet
> http_access allow ldap-auth
> http_access allow CONNECT  SSL_ports ldap-auth
> 

... like this rule doing nothing.

Why?
  Because ldap-auth, localnet, localhost ACLs already let users do
anything they want. Anything. Oops.


> 
> # And finally deny all other access to this proxy
> http_access deny all
> .
> .
> .
> 
> Normal ntlm dont work but we have some old programms that need ntlm so i use
> fake tnlm for them browsers only use kerberos.
> 
> In squid log i see nothing no entrys for the connection time.

Squid logs transactions when they complete. If the teamviewer is still
using it for some minutes/hours/days you wont see it until its over.

"Days" is not a joke, some can last that long. GoogleTalk, Facebook
Chat, Skype etc are known for it already. It woud not surprise me to
find TeamViewer is similar.

Amos



From odhiambo at gmail.com  Thu Apr 21 13:25:48 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 16:25:48 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <bb03c512-857c-38af-a3ab-1f0455113ecd@gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <bb03c512-857c-38af-a3ab-1f0455113ecd@gmail.com>
Message-ID: <CAAdA2WPdEZVKBvXAc5ON2coTTcwt4i5kbK5LNAEy48oouAX1LQ@mail.gmail.com>

So, what could possibly be wrong with my setup, that squid consumes so much
CPU?

On 21 April 2016 at 16:22, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> It must not be. My most active setup has 3% CPU all time dirung peak hours.
>
> Typical view:
>
> https://i1.someimage.com/NzM1erI.png
>
>
> 21.04.16 19:18, Odhiambo Washington ?????:
> > Is is expected that  using ssl_bump results into high CPU usage all the
> time?
> >
> > This is squid-3.5.17
> >
> > That is what I am seeing:
> >
> > last pid: 26673;  load averages:  2.24,  2.00,
> 2.10
> up 0+03:47:56  16:08:30
> > 160 processes: 2 running, 157 sleeping, 1 zombie
> > CPU: 86.1% user,  0.0% nice,  7.8% system,  3.3% interrupt,  2.7% idle
> > Mem: 843M Active, 1942M Inact, 185M Wired, 43M Cache, 89M Buf, 97M Free
> > Swap: 5900M Total, 1248K Used, 5899M Free
> >
> >   PID USERNAME       THR PRI NICE   SIZE    RES STATE   C   TIME    WCPU
> COMMAND
> > 13309 squid           17  20    0   305M   264M uwait   0   7:38  80.86%
> squid
> > 26088 squid            1  21    0 12812K  5352K sbwait  1   0:04   2.49%
> ssl_crtd
> > 26090 squid            1  20    0 12812K  5272K sbwait  1   0:01   0.88%
> ssl_crtd
> >
> >
> > My config has:
> >
> >
> >
> > acl no_ssl_interception ssl::server_name
> "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> > ssl_bump splice no_ssl_interception
> > ssl_bump peek step1
> > ssl_bump stare step2
> > #ssl_bump bump all
> > #ssl_bump splice all
> >
> > I think I read somewhere that 'ssl_bump splice all" is the default
> behaviour, hence why I have commented it out. All I need is just become a
> TCP tunnel without decrypting proxied traffic.
> >
> > Thank you.
> >
> >
> > --
> > Best regards,
> > Odhiambo WASHINGTON,
> > Nairobi,KE
> > +254 7 3200 0004/+254 7 2274 3223
> > "Oh, the cruft."
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXGNQsAAoJENNXIZxhPexGcZUIAL3zFz9UFuQdyfXFBilFQ0Gj
> 8F4HkxuJjNtCUYdb6BEwux9jBOjZpYScr8sRHRBPvIV8O4/2Z3QF7exjEW8Duj/G
> REWO3txPiE4pICD/AbdBuX8O++dvfjj46nz+lVeCH9JjGW0VoMHiyGtwGx1shSfY
> pGX0MguEGEtWp/7hxKAFbRivGuvyQ7Ogj8i9IgMBptMrRu4D3G75UO+9WmaHcpVx
> VAf1revHh+dWFWrO1k+zrWFIIFcwbR5LcrJeBYJ94scgPV3p68LC2ZpqUBZreYCM
> Koo9+Rss+Ix1rTSUkvTaoGOcMdrHJ1oMICHwyqtDMWlbDds5dAnnWXh5faNYPFk=
> =7YlO
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/a838e63f/attachment.htm>

From yvoinov at gmail.com  Thu Apr 21 13:33:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 21 Apr 2016 19:33:47 +0600
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WPdEZVKBvXAc5ON2coTTcwt4i5kbK5LNAEy48oouAX1LQ@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <bb03c512-857c-38af-a3ab-1f0455113ecd@gmail.com>
 <CAAdA2WPdEZVKBvXAc5ON2coTTcwt4i5kbK5LNAEy48oouAX1LQ@mail.gmail.com>
Message-ID: <2ac4ef71-2768-a27a-61d4-2ff1919e71f6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Not necessary. May be bottleneck in OS.

21.04.16 19:25, Odhiambo Washington ?????:
> So, what could possibly be wrong with my setup, that squid consumes so much CPU?
>
> On 21 April 2016 at 16:22, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> It must not be. My most active setup has 3% CPU all time dirung peak
hours.
>
> Typical view:
>
> https://i1.someimage.com/NzM1erI.png
>
>
> 21.04.16 19:18, Odhiambo Washington ?????:
> > Is is expected that  using
>       ssl_bump results into high CPU usage all the time?
>
>
>
>       > This is squid-3.5.17
>
>
>
>       > That is what I am seeing:
>
>
>
>       > last pid: 26673;  load averages:  2.24,  2.00,
>
2.10                                                                                                               

>       up 0+03:47:56  16:08:30
>
>       > 160 processes: 2 running, 157 sleeping, 1 zombie
>
>       > CPU: 86.1% user,  0.0% nice,  7.8% system,  3.3% interrupt,
>       2.7% idle
>
>       > Mem: 843M Active, 1942M Inact, 185M Wired, 43M Cache, 89M
>       Buf, 97M Free
>
>       > Swap: 5900M Total, 1248K Used, 5899M Free
>
>
>
>       >   PID USERNAME       THR PRI NICE   SIZE    RES STATE   C 
>       TIME    WCPU COMMAND
>
>       > 13309 squid           17  20    0   305M   264M uwait   0 
>       7:38  80.86% squid
>
>       > 26088 squid            1  21    0 12812K  5352K sbwait  1 
>       0:04   2.49% ssl_crtd
>
>       > 26090 squid            1  20    0 12812K  5272K sbwait  1 
>       0:01   0.88% ssl_crtd
>
>
>
>
>
>       > My config has:
>
>
>
>
>
>
>
>       > acl no_ssl_interception ssl::server_name
>       "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
>
>       > ssl_bump splice no_ssl_interception
>
>       > ssl_bump peek step1
>
>       > ssl_bump stare step2
>
>       > #ssl_bump bump all
>
>       > #ssl_bump splice all
>
>
>
>       > I think I read somewhere that 'ssl_bump splice all" is the
>       default behaviour, hence why I have commented it out. All I need
>       is just become a TCP tunnel without decrypting proxied traffic.
>
>
>
>       > Thank you.
>
>
>
>
>
>       > --
>
>       > Best regards,
>
>       > Odhiambo WASHINGTON,
>
>       > Nairobi,KE
>
>       > +254 7 3200 0004/+254 7 2274 3223
>
>       > "Oh, the cruft."
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXGNa7AAoJENNXIZxhPexGQw0H+QG5jXWboYFaClEOOwwMJ3Vl
KUI6h4pnzRrcSEkMNMu0bBRytqGVXzplK5cl2U4T+scDWWpCj3pgcb1i8wITtwze
nEhvCeG9Xq6BZujvIKvQ32pe64EIl/tjstbpxxMdGLprSFre5mUXKd1NG5JghD0E
7oWYvA/hNwo/rpevzxUzU9Z+FOmgRYJ+JEGThGa86Qe+bE3B2Kxt6RAVAUbRfBcY
M/xJBX9wgeBgxncYG0IFtbJEG12X2j9Y4KXIOoh3nTpinOi7nbACF2ryr2H7z+GT
pFuNWiSnf5eSz3lEdAv+GHPZb9Fg1noD8Mxq8+P83d4BwA/L2ba/DJIweVTSEpQ=
=asuL
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/1cdbcdd5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/1cdbcdd5/attachment.key>

From squid3 at treenet.co.nz  Thu Apr 21 13:34:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Apr 2016 01:34:05 +1200
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
Message-ID: <5718D6CD.8030409@treenet.co.nz>

On 22/04/2016 1:18 a.m., Odhiambo Washington wrote:
> Is is expected that  using ssl_bump results into high CPU usage all the
> time?
> 

Encryption adds CPU overhead, but how much depends on what your normal
use was. I dont think any of us have a good rule-of-thumb or educated
guess yet because Squid code has been changing so much.

If its worrying you, I suggest trying your favourite profiling tools out
and see if anything useful shows up.


> This is squid-3.5.17
> 
> That is what I am seeing:
> 
> last pid: 26673;  load averages:  2.24,  2.00,  2.10
> 
>               up 0+03:47:56  16:08:30
> 160 processes: 2 running, 157 sleeping, 1 zombie
> CPU: 86.1% user,  0.0% nice,  7.8% system,  3.3% interrupt,  2.7% idle
> Mem: 843M Active, 1942M Inact, 185M Wired, 43M Cache, 89M Buf, 97M Free
> Swap: 5900M Total, 1248K Used, 5899M Free
> 
>   PID USERNAME       THR PRI NICE   SIZE    RES STATE   C   TIME    WCPU
> COMMAND
> 13309 squid           17  20    0   305M   264M uwait   0   7:38  80.86%
> squid
> 26088 squid            1  21    0 12812K  5352K sbwait  1   0:04   2.49%
> ssl_crtd
> 26090 squid            1  20    0 12812K  5272K sbwait  1   0:01   0.88%
> ssl_crtd
> 
> 
> My config has:
> 
> 
> 
> acl no_ssl_interception ssl::server_name
> "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> ssl_bump splice no_ssl_interception
> ssl_bump peek step1
> ssl_bump stare step2
> #ssl_bump bump all
> #ssl_bump splice all
> 
> I think I read somewhere that 'ssl_bump splice all" is the default
> behaviour, hence why I have commented it out. All I need is just become a
> TCP tunnel without decrypting proxied traffic.

I wouldn't rely on the default for things like this. Squid makes a
*guess* based on what data it has to work with on a per-connection
basis. There is no extra cost to having it configured, Squid has to
check the whole set anyway.

Amos



From odhiambo at gmail.com  Thu Apr 21 13:43:35 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 16:43:35 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <5718D6CD.8030409@treenet.co.nz>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718D6CD.8030409@treenet.co.nz>
Message-ID: <CAAdA2WN0m+e_uO=yM88KAJg2JSjAr=y8JTYNBpkug+9NvB0J8w@mail.gmail.com>

I will put the splice explicitly and observe.

Without ssl_bump I never saw such cpu usage with squid.

However, lemme watch and also listen to feedback..


On 21 April 2016 at 16:34, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 22/04/2016 1:18 a.m., Odhiambo Washington wrote:
> > Is is expected that  using ssl_bump results into high CPU usage all the
> > time?
> >
>
> Encryption adds CPU overhead, but how much depends on what your normal
> use was. I dont think any of us have a good rule-of-thumb or educated
> guess yet because Squid code has been changing so much.
>
> If its worrying you, I suggest trying your favourite profiling tools out
> and see if anything useful shows up.
>
>
> > This is squid-3.5.17
> >
> > That is what I am seeing:
> >
> > last pid: 26673;  load averages:  2.24,  2.00,  2.10
> >
> >               up 0+03:47:56  16:08:30
> > 160 processes: 2 running, 157 sleeping, 1 zombie
> > CPU: 86.1% user,  0.0% nice,  7.8% system,  3.3% interrupt,  2.7% idle
> > Mem: 843M Active, 1942M Inact, 185M Wired, 43M Cache, 89M Buf, 97M Free
> > Swap: 5900M Total, 1248K Used, 5899M Free
> >
> >   PID USERNAME       THR PRI NICE   SIZE    RES STATE   C   TIME    WCPU
> > COMMAND
> > 13309 squid           17  20    0   305M   264M uwait   0   7:38  80.86%
> > squid
> > 26088 squid            1  21    0 12812K  5352K sbwait  1   0:04   2.49%
> > ssl_crtd
> > 26090 squid            1  20    0 12812K  5272K sbwait  1   0:01   0.88%
> > ssl_crtd
> >
> >
> > My config has:
> >
> >
> >
> > acl no_ssl_interception ssl::server_name
> > "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> > ssl_bump splice no_ssl_interception
> > ssl_bump peek step1
> > ssl_bump stare step2
> > #ssl_bump bump all
> > #ssl_bump splice all
> >
> > I think I read somewhere that 'ssl_bump splice all" is the default
> > behaviour, hence why I have commented it out. All I need is just become a
> > TCP tunnel without decrypting proxied traffic.
>
> I wouldn't rely on the default for things like this. Squid makes a
> *guess* based on what data it has to work with on a per-connection
> basis. There is no extra cost to having it configured, Squid has to
> check the whole set anyway.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/b07d4007/attachment.htm>

From rousskov at measurement-factory.com  Thu Apr 21 13:48:27 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 21 Apr 2016 07:48:27 -0600
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
Message-ID: <5718DA2B.50504@measurement-factory.com>

On 04/21/2016 07:18 AM, Odhiambo Washington wrote:
> Is is expected that  using ssl_bump results into high CPU usage all the
> time?

Your question is impossible to answer in general: The CPU usage levels
depend on the amount of Squid traffic, the portion of SSL traffic in the
overall traffic mix, the portion of step1, step2, and step3 traffic in
the SSL traffic mix, hardware resources available to Squid, the number
of Squid workers, and many other factors.

> acl no_ssl_interception ssl::server_name ...
> ssl_bump splice no_ssl_interception 
> ssl_bump peek step1
> ssl_bump stare step2

The above config continues to violate the specific advice given to you
previously: Do not mix "peek" and "stare" unless you have a very
specific need for doing so.


> I think I read somewhere that 'ssl_bump splice all" is the default
> behaviour, hence why I have commented it out. All I need is just become
> a TCP tunnel without decrypting proxied traffic.

"splice all" is not the default in the latest Squids. The default there
is closer to something like "bump if the last step was 'stare' and
splice otherwise". I do not remember what the default is in your Squid
version, but, as Amos has already said, relying on _any_ default in this
complex environment is the wrong approach.

Alex.



From odhiambo at gmail.com  Thu Apr 21 14:12:33 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 17:12:33 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <5718DA2B.50504@measurement-factory.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
Message-ID: <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>

On 21 April 2016 at 16:48, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/21/2016 07:18 AM, Odhiambo Washington wrote:
> > Is is expected that  using ssl_bump results into high CPU usage all the
> > time?
>
> Your question is impossible to answer in general: The CPU usage levels
> depend on the amount of Squid traffic, the portion of SSL traffic in the
> overall traffic mix, the portion of step1, step2, and step3 traffic in
> the SSL traffic mix, hardware resources available to Squid, the number
> of Squid workers, and many other factors.
>
> > acl no_ssl_interception ssl::server_name ...
> > ssl_bump splice no_ssl_interception
> > ssl_bump peek step1
> > ssl_bump stare step2
>
> The above config continues to violate the specific advice given to you
> previously:
> *Do not mix "peek" and "stare" unless you have a very specific need for
> doing so.*
>

I have noted that instruction. It was actually an oversight caused by slow
understanding of the terminologies.
Once I have changed to what you advised before, the CPU usage has gone down
considerably:


acl no_ssl_interception ssl::server_name
"/usr/local/etc/squid/ssl_bump_broken_sites.txt"
ssl_bump splice no_ssl_interception
ssl_bump stare step2
#ssl_bump bump all
ssl_bump splice all

So basically I should just have two options, I think, no?? Like

ssl_bump stare step2
ssl_bump splice all

If one day, for some reason I want to bump, then I could change to:

acl no_ssl_interception ssl::server_name
"/usr/local/etc/squid/ssl_bump_broken_sites.txt"
ssl_bump splice no_ssl_interception
ssl_bump stare step2
ssl_bump bump all


Thank you so much Alex.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/71801506/attachment.htm>

From bmarkey at steinmancommunications.com  Thu Apr 21 14:36:10 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Thu, 21 Apr 2016 14:36:10 +0000
Subject: [squid-users] Cert authority invalid failures.
In-Reply-To: <5718CE94.7020004@treenet.co.nz>
References: <2B77BF184EAC2F43BB9FC908954D8B12670530CA@Ex5.lnpnews.com>
 <5718CE94.7020004@treenet.co.nz>
Message-ID: <2B77BF184EAC2F43BB9FC908954D8B12670559EE@Ex5.lnpnews.com>

acl internal src 192.168.200.0/21
acl wireless src 192.168.100.0/23

acl Safe_ports port 80
acl Safe_ports port 443
acl SSL_ports port 443
acl CONNECT method CONNECT

acl allowed dstdomain -i "/etc/squid3/acls/http_allowed.acl"
acl prime dstdomain -i "/etc/squid3/acls/squid-prime.acl"
acl ips dst -n "/etc/squid3/acls/broken_ips.acl"
acl blocked dstdomain -i "/etc/squid3/acls/http_blocked.acl"

http_access allow allowed
http_access allow ips
http_access deny blocked
http_access deny prime

http_access allow internal
http_access allow wireless
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"
ssl_bump peek !broken_sites
ssl_bump splice all

sslproxy_capath /etc/ssl/certs

sslcrtd_program /lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
sslcrtd_children 32 startup=5 idle=1



http_port 3128 intercept
https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB sslflags=NO_SESSION_REUSE

dns_nameservers 192.168.201.1 8.8.8.8

wccp_version 2
wccp2_router 192.168.200.73
wccp2_forwarding_method gre
wccp2_return_method gre
wccp2_service standard 0 password=xxxx
wccp2_service dynamic 70 password=xxxx
wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 ports=443

I did update the ca bundle if that helps. 



Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758?(o) |?bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Thursday, April 21, 2016 8:59 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Cert authority invalid failures.

On 21/04/2016 8:18 a.m., Markey, Bruce wrote:
> I'm curious as to why this is happening.
> 
> Proxy was implemented last week and since then I've been dealing with all the sites that don't work. Not a problem, knew it was going to happen. I'd like to understand why the following is happening.
> 
> 
> 1.       User goes to https://www.whatever.com
> 
> 2.       Browser, mostly chrome, gives the following error.   Connection not private. NET:ERR_CERT_AUTHORITY_INVALID
> 

Typing that into search engine produces a thread explaining that it is the browser message shown when HSTS is in effect on a website and the server cert is not trusted by the browser.



> 3.       If you view the cert it shows the dynamic cert listed.
> 
> 4.       Click the "Proceed to www.whatever.com<http://www.whatever.com> (unsafe )
> 
> 5.       Now I get a squid error.  Requested url could not be retrieved.  Access denied while trying to retrieve https:// some ip address/*
> 

And that #5 explains why. It was actually not the web server producing the cert. But Squid doing SSL-Bumping in order to show you the error page.



> Thing is I don't have an acl blocking that ip?   ( Small sub question here, is there a way to tell which acl blocks something? )
> 

Something clearly is. But not what you expect, or you would not be here asking about it.

> What I've had to do to get around this is add www.whatever.com<http://www.whatever.com> to my broken_sites.acl.    Then add the ip to an allowed_ips.acl.
> 
> Then I http_access allow the ips list
> 
> And skip peeking at the broken site.
> 
> acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"
> ssl_bump peek !broken_sites
> ssl_bump splice all
> 
> I'm trying to understand why this is breaking and if I'm doing the right thing in fixing it.
> 

Please provide your whole squid.conf (except empty or # comment lines).
We might need to see it all to find what the problem is.


> 
> The second error I'm getting is:
> 
> 
> The following error was encountered while trying to retrieve the URL: 
> https://*.agentimediaservices.com/*<https://%2A.agentimediaservices.co
> m/*>
> 
> Failed to establish a secure connection to 63.240.52.151
> 
> The system returned:
> 
> (71) Protocol error (TLS code: 
> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
> 
> SSL Certficate error: certificate issuer (CA) not known: 
> /C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO 
> RSA Organization Validation Secure Server CA Same question.  From what 
> I've read this means that I don't have the correct root ca?  Is that 
> correct?  If so is the fix to then go try to find the correct .crt and 
> add it to the standard ca-cert store? ( I'm on debian so 
> /usr/share/ca-certificates/Mozilla )
> 
> Again, is this correct as to what is going wrong and the correct fix?

Well, first step is to ensure your ca-certificates package is up to date. That usually solves these.

But not always, especially if the CA has been caught doing bad things and suddenly dropped. Or if they have begun issuing certs to clients before being accepted by the Mozilla CA list people.

It could also be a problem with intermediary cert just being omitted by the server. In that case adding it to your server-wide cert store or configuring it to be loaded by Squid will be needed.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From auaauabubu at yahoo.de  Thu Apr 21 14:31:26 2016
From: auaauabubu at yahoo.de (epytir)
Date: Thu, 21 Apr 2016 07:31:26 -0700 (PDT)
Subject: [squid-users] Squid 3.5.9 Problems with Teamviewer
In-Reply-To: <5718D4F0.7020601@treenet.co.nz>
References: <1461166795323-4677176.post@n4.nabble.com>
 <5718D4F0.7020601@treenet.co.nz>
Message-ID: <1461249086982-4677203.post@n4.nabble.com>

Hey Amons,

thanks for your replay.

The line  /usr/lib/squid3/negotiate_kerberos_auth -r -s GSS_C_NO_NA$ 
there only missing the 2 letters ME sorry for that.

I will build a test server with the newest squid version and config changes.

>I log squid in database and every connect i see is not blocked:
The Column titles are
        ID        time_since_epoch     date_day      date_time  
response_time    squid_request_status
> | 23731740 |   1461164861.040 | 2016-04-20 | 17:07:41  | 48 | ip          
> | TCP_MISS
    http_status_code    reply_size       request_url                   user            
squid_hier_status
> | 200 |                 15623 | GET | www.teamviewer.com     | Username|
> FIRSTUP_PARENT    |
> NULL | NULL   |
> | 23733412 |   1461165077.533 | 2016-04-20 | 17:11:18  |  11 | ip  |
> TCP_MEM_HIT | 200  |   15631 | GET   | www.teamviewer.com  | Username|
> HIER_NONE         | NULL           | NULL      |
>

>You missed out the bit where the column titles were described so we know
>what that above means. 


I dont know what the parent proxy is cause it is outsourced by our customer
and they dont say what it is...
I think its squid or tmg and yes if it is tmg or an old verison of squid
maybe this is the problem..

Im new with squid so i might make some config mistakes thanks for correcting
me :)


I will write here when I have new Informations

Greetings Epytir



Amos Jeffries wrote
> On 21/04/2016 3:39 a.m., epytir wrote:
>> Hey Squid Users,
>> 
>> Sorry for my bad english im learning it currently.
>> 
>> I got a little problem with my squid proxy.
>> I installed it with ufdbguard and squidclamav and everything works fine.
>> 
>> The users login with kerberos ntlm or normal username passowrt
>> authentication.
>> 
>> My Problem is when Users start Teamviewer (every Version) some time
>> teamviewer doing nothing then the message "no connection please check
>> proxy
>> settings" appears. Then i klick nothing after 10 more seconds the
>> teamviewer
>> is connected without changing anything.
>> So Teamviewer needs up to 1 minute to connect through the proxy without i
>> need like 5 seconds.
>> 
>> Teamviewer is not blocked for the users with the problems and it connects
>> but needs to much time. I have 1500 User so the normal user dont
>> understand
>> that he must wait and dont klick on change settings or abort.
>> 
>> I log squid in database and every connect i see is not blocked:
>> | 23731740 |   1461164861.040 | 2016-04-20 | 17:07:41  | 48 | ip  |
>> TCP_MISS 
>> | 200 | 15623 | GET | www.teamviewer.com     | Username| FIRSTUP_PARENT   
>> |
>> NULL | NULL   |
>> | 23733412 |   1461165077.533 | 2016-04-20 | 17:11:18  |  11 | ip  |
>> TCP_MEM_HIT | 200  |   15631 | GET   | www.teamviewer.com  | Username|
>> HIER_NONE         | NULL           | NULL      |
>> 
> 
> You missed out the bit where the column titles were described so we know
> what that above means.
> 
> 
>> The parent Proxy is not the problem cause our old proxy is tmg from
>> microsoft and use the same proxy without teamviewer problems. (we want to
>> shutdown tmg cause its extremly slow and squid is so fast :) ) 
>> 
> 
> Maybe it, is maybe it isn't. Not a safe assumption.
> 
> It is likely tmg and Squid are talking to it slightly differently which
> might make it do different things and hit some bug you never saw before.
> The older that parent proxy software is the more likely this is to happen.
> 
> 
>> 
>> Here are some information:
>> Squid 3.5.9
>> UFDB 1.31-16
>> Server Ubuntu 14.04 LTS
>> 
> 
> The old Squid version could also be a problem. We have found and fixed
> quite a lot of bugs in the last 2 years.
> 
> A useful rule of thumb when dealing with squid issues is to first try an
> upgrade and see if the issue is resolved already.
> 
> If you can wait a few days I suggest trying for an upgrade to Ubuntu
> Xenial 16.04 LTS, which should appear any day now and has a much better
> Squid in it.
> 
> 
>> Squid config snip:
>> auth_param negotiate program /usr/lib/squid3/negotiate_wrapper_auth 
>> --ntlm 
>> /usr/lib/squid3/fakeauth_auth  --kerberos 
>> /usr/lib/squid3/negotiate_kerberos_auth -r -s GSS_C_NO_NA$
> 
> The above line got truncated.
> 
>> auth_param negotiate children 80
>> auth_param negotiate keep_alive on
> 
> I recommend using "off" here. It seems to be needed by recent Firefox
> and some other tools as well.
> 
>> 
>> auth_param ntlm program /usr/lib/squid3/fakeauth_auth x.x.x\DC
> 
> This "x.x.x\DC" thing is suspicious. If it is actually needed, then I
> suspect it should be on the Negotiate/NTLM helper as well as the NTLM one.
> 
> 
>> auth_param ntlm children 30
>> auth_param ntlm keep_alive off
>> 
>> #LDAP Authentication
>> auth_param basic program  /usr/lib/squid3/basic_ldap_auth -b
>> "dc=X,dc=X,dc=X" -D "

> XXX at .X

> " -w "XXXXXXXXX" -v 3 -h ldaps://X.X.X
>> auth_param basic children 30
>> auth_param basic realm Domain-Internet-Proxy
>> auth_param basic credentialsttl 30 day  #How often ask for Login
>> credentials
>> auth_param basic casesensitive off
>> 
>> acl ldap-auth proxy_auth REQUIRED # Rule authentication needed
>> never_direct allow all
>> # Deny requests to certain unsafe ports
>> http_access deny !Safe_ports
>> 
>> # Deny CONNECT to other than secure SSL ports
>> #http_access allow CONNECT SSL_ports
> 
> The security rule provided is "deny CONNECT !SSL_Ports".
> 
> That is *not* the same as "allow CONNECT SSL_Ports".
> 
> It uses "deny" explicitly to prevent other rules later in the config
> doing unexpected bad things...
> 
> 
>> http_access allow localnet
>> http_access allow localhost
>> 
>> #LDAP User are allowed to connect to the Internet
>> http_access allow ldap-auth
>> http_access allow CONNECT  SSL_ports ldap-auth
>> 
> 
> ... like this rule doing nothing.
> 
> Why?
>   Because ldap-auth, localnet, localhost ACLs already let users do
> anything they want. Anything. Oops.
> 
> 
>> 
>> # And finally deny all other access to this proxy
>> http_access deny all
>> .
>> .
>> .
>> 
>> Normal ntlm dont work but we have some old programms that need ntlm so i
>> use
>> fake tnlm for them browsers only use kerberos.
>> 
>> In squid log i see nothing no entrys for the connection time.
> 
> Squid logs transactions when they complete. If the teamviewer is still
> using it for some minutes/hours/days you wont see it until its over.
> 
> "Days" is not a joke, some can last that long. GoogleTalk, Facebook
> Chat, Skype etc are known for it already. It woud not surprise me to
> find TeamViewer is similar.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users


Amos Jeffries wrote
> On 21/04/2016 3:39 a.m., epytir wrote:
>> Hey Squid Users,
>> 
>> Sorry for my bad english im learning it currently.
>> 
>> I got a little problem with my squid proxy.
>> I installed it with ufdbguard and squidclamav and everything works fine.
>> 
>> The users login with kerberos ntlm or normal username passowrt
>> authentication.
>> 
>> My Problem is when Users start Teamviewer (every Version) some time
>> teamviewer doing nothing then the message "no connection please check
>> proxy
>> settings" appears. Then i klick nothing after 10 more seconds the
>> teamviewer
>> is connected without changing anything.
>> So Teamviewer needs up to 1 minute to connect through the proxy without i
>> need like 5 seconds.
>> 
>> Teamviewer is not blocked for the users with the problems and it connects
>> but needs to much time. I have 1500 User so the normal user dont
>> understand
>> that he must wait and dont klick on change settings or abort.
>> 
>> I log squid in database and every connect i see is not blocked:
>> | 23731740 |   1461164861.040 | 2016-04-20 | 17:07:41  | 48 | ip  |
>> TCP_MISS 
>> | 200 | 15623 | GET | www.teamviewer.com     | Username| FIRSTUP_PARENT   
>> |
>> NULL | NULL   |
>> | 23733412 |   1461165077.533 | 2016-04-20 | 17:11:18  |  11 | ip  |
>> TCP_MEM_HIT | 200  |   15631 | GET   | www.teamviewer.com  | Username|
>> HIER_NONE         | NULL           | NULL      |
>> 
> 
> You missed out the bit where the column titles were described so we know
> what that above means.
> 
> 
>> The parent Proxy is not the problem cause our old proxy is tmg from
>> microsoft and use the same proxy without teamviewer problems. (we want to
>> shutdown tmg cause its extremly slow and squid is so fast :) ) 
>> 
> 
> Maybe it, is maybe it isn't. Not a safe assumption.
> 
> It is likely tmg and Squid are talking to it slightly differently which
> might make it do different things and hit some bug you never saw before.
> The older that parent proxy software is the more likely this is to happen.
> 
> 
>> 
>> Here are some information:
>> Squid 3.5.9
>> UFDB 1.31-16
>> Server Ubuntu 14.04 LTS
>> 
> 
> The old Squid version could also be a problem. We have found and fixed
> quite a lot of bugs in the last 2 years.
> 
> A useful rule of thumb when dealing with squid issues is to first try an
> upgrade and see if the issue is resolved already.
> 
> If you can wait a few days I suggest trying for an upgrade to Ubuntu
> Xenial 16.04 LTS, which should appear any day now and has a much better
> Squid in it.
> 
> 
>> Squid config snip:
>> auth_param negotiate program /usr/lib/squid3/negotiate_wrapper_auth 
>> --ntlm 
>> /usr/lib/squid3/fakeauth_auth  --kerberos 
>> /usr/lib/squid3/negotiate_kerberos_auth -r -s GSS_C_NO_NA$
> 
> The above line got truncated.
> 
>> auth_param negotiate children 80
>> auth_param negotiate keep_alive on
> 
> I recommend using "off" here. It seems to be needed by recent Firefox
> and some other tools as well.
> 
>> 
>> auth_param ntlm program /usr/lib/squid3/fakeauth_auth x.x.x\DC
> 
> This "x.x.x\DC" thing is suspicious. If it is actually needed, then I
> suspect it should be on the Negotiate/NTLM helper as well as the NTLM one.
> 
> 
>> auth_param ntlm children 30
>> auth_param ntlm keep_alive off
>> 
>> #LDAP Authentication
>> auth_param basic program  /usr/lib/squid3/basic_ldap_auth -b
>> "dc=X,dc=X,dc=X" -D "

> XXX at .X

> " -w "XXXXXXXXX" -v 3 -h ldaps://X.X.X
>> auth_param basic children 30
>> auth_param basic realm Domain-Internet-Proxy
>> auth_param basic credentialsttl 30 day  #How often ask for Login
>> credentials
>> auth_param basic casesensitive off
>> 
>> acl ldap-auth proxy_auth REQUIRED # Rule authentication needed
>> never_direct allow all
>> # Deny requests to certain unsafe ports
>> http_access deny !Safe_ports
>> 
>> # Deny CONNECT to other than secure SSL ports
>> #http_access allow CONNECT SSL_ports
> 
> The security rule provided is "deny CONNECT !SSL_Ports".
> 
> That is *not* the same as "allow CONNECT SSL_Ports".
> 
> It uses "deny" explicitly to prevent other rules later in the config
> doing unexpected bad things...
> 
> 
>> http_access allow localnet
>> http_access allow localhost
>> 
>> #LDAP User are allowed to connect to the Internet
>> http_access allow ldap-auth
>> http_access allow CONNECT  SSL_ports ldap-auth
>> 
> 
> ... like this rule doing nothing.
> 
> Why?
>   Because ldap-auth, localnet, localhost ACLs already let users do
> anything they want. Anything. Oops.
> 
> 
>> 
>> # And finally deny all other access to this proxy
>> http_access deny all
>> .
>> .
>> .
>> 
>> Normal ntlm dont work but we have some old programms that need ntlm so i
>> use
>> fake tnlm for them browsers only use kerberos.
>> 
>> In squid log i see nothing no entrys for the connection time.
> 
> Squid logs transactions when they complete. If the teamviewer is still
> using it for some minutes/hours/days you wont see it until its over.
> 
> "Days" is not a joke, some can last that long. GoogleTalk, Facebook
> Chat, Skype etc are known for it already. It woud not surprise me to
> find TeamViewer is similar.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-9-Problems-with-Teamviewer-tp4677176p4677203.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Thu Apr 21 17:29:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Apr 2016 05:29:47 +1200
Subject: [squid-users] Cert authority invalid failures.
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B12670559EE@Ex5.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B12670530CA@Ex5.lnpnews.com>
 <5718CE94.7020004@treenet.co.nz>
 <2B77BF184EAC2F43BB9FC908954D8B12670559EE@Ex5.lnpnews.com>
Message-ID: <57190E0B.3060902@treenet.co.nz>

On 22/04/2016 2:36 a.m., Markey, Bruce wrote:
> acl internal src 192.168.200.0/21
> acl wireless src 192.168.100.0/23
> 
> acl Safe_ports port 80
> acl Safe_ports port 443
> acl SSL_ports port 443
> acl CONNECT method CONNECT
> 
> acl allowed dstdomain -i "/etc/squid3/acls/http_allowed.acl"
> acl prime dstdomain -i "/etc/squid3/acls/squid-prime.acl"
> acl ips dst -n "/etc/squid3/acls/broken_ips.acl"
> acl blocked dstdomain -i "/etc/squid3/acls/http_blocked.acl"
> 
> http_access allow allowed
> http_access allow ips
> http_access deny blocked
> http_access deny prime

It would seem that it could only be these two ACLs blocked or prime
which are causing your denial.

Note that when dstdomain is passed a raw-IP the reverse-DNS will be
looked up and if that domain OR the raw-IP match an entry in the list it
will be a match.

Note2 that when a connection arrives at your "intercept ssl-bump" port
Squid will generate a CONNECT message using the raw-IP of that
connection and pass it through your http_access controls. The denial
could happen then.

Once the SNI is found by the peek another pass of the http_access
happens. Denial could happen then as well.
Then your splice kicks in.

> 
> http_access allow internal
> http_access allow wireless

Move these ...

> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports

... default security controls back up to the top of your config.

> http_access deny all
> 
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> 
> acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"
> ssl_bump peek !broken_sites
> ssl_bump splice all
> 
> sslproxy_capath /etc/ssl/certs
> 
> sslcrtd_program /lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
> sslcrtd_children 32 startup=5 idle=1
> 
> 
> 
> http_port 3128 intercept
> https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB sslflags=NO_SESSION_REUSE
> 
> dns_nameservers 192.168.201.1 8.8.8.8
> 
> wccp_version 2
> wccp2_router 192.168.200.73
> wccp2_forwarding_method gre
> wccp2_return_method gre
> wccp2_service standard 0 password=xxxx
> wccp2_service dynamic 70 password=xxxx
> wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 ports=443
> 
> I did update the ca bundle if that helps. 
> 
> 
> 
> Bruce Markey | Network Security Analyst
> STEINMAN COMMUNICATIONS
> 717.291.8758 (o) | bmarkey at steinmancommunications.com
> 8 West King St | PO Box 1328, Lancaster, PA 17608-1328
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
> Sent: Thursday, April 21, 2016 8:59 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Cert authority invalid failures.
> 
> On 21/04/2016 8:18 a.m., Markey, Bruce wrote:
>> I'm curious as to why this is happening.
>>
>> Proxy was implemented last week and since then I've been dealing with all the sites that don't work. Not a problem, knew it was going to happen. I'd like to understand why the following is happening.
>>
>>
>> 1.       User goes to https://www.whatever.com
>>
>> 2.       Browser, mostly chrome, gives the following error.   Connection not private. NET:ERR_CERT_AUTHORITY_INVALID
>>
> 
> Typing that into search engine produces a thread explaining that it is the browser message shown when HSTS is in effect on a website and the server cert is not trusted by the browser.
> 
> 
> 
>> 3.       If you view the cert it shows the dynamic cert listed.
>>
>> 4.       Click the "Proceed to www.whatever.com<http://www.whatever.com> (unsafe )
>>
>> 5.       Now I get a squid error.  Requested url could not be retrieved.  Access denied while trying to retrieve https:// some ip address/*
>>
> 
> And that #5 explains why. It was actually not the web server producing the cert. But Squid doing SSL-Bumping in order to show you the error page.
> 
> 
> 
>> Thing is I don't have an acl blocking that ip?   ( Small sub question here, is there a way to tell which acl blocks something? )
>>
> 
> Something clearly is. But not what you expect, or you would not be here asking about it.
> 
>> What I've had to do to get around this is add www.whatever.com<http://www.whatever.com> to my broken_sites.acl.    Then add the ip to an allowed_ips.acl.
>>
>> Then I http_access allow the ips list
>>
>> And skip peeking at the broken site.
>>
>> acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"
>> ssl_bump peek !broken_sites
>> ssl_bump splice all
>>
>> I'm trying to understand why this is breaking and if I'm doing the right thing in fixing it.
>>
> 
> Please provide your whole squid.conf (except empty or # comment lines).
> We might need to see it all to find what the problem is.
> 
> 
>>
>> The second error I'm getting is:
>>
>>
>> The following error was encountered while trying to retrieve the URL: 
>> https://*.agentimediaservices.com/*<https://%2A.agentimediaservices.co
>> m/*>
>>
>> Failed to establish a secure connection to 63.240.52.151
>>
>> The system returned:
>>
>> (71) Protocol error (TLS code: 
>> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
>>
>> SSL Certficate error: certificate issuer (CA) not known: 
>> /C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO 
>> RSA Organization Validation Secure Server CA Same question.  From what 
>> I've read this means that I don't have the correct root ca?  Is that 
>> correct?  If so is the fix to then go try to find the correct .crt and 
>> add it to the standard ca-cert store? ( I'm on debian so 
>> /usr/share/ca-certificates/Mozilla )
>>
>> Again, is this correct as to what is going wrong and the correct fix?
> 
> Well, first step is to ensure your ca-certificates package is up to date. That usually solves these.
> 
> But not always, especially if the CA has been caught doing bad things and suddenly dropped. Or if they have begun issuing certs to clients before being accepted by the Mozilla CA list people.
> 
> It could also be a problem with intermediary cert just being omitted by the server. In that case adding it to your server-wide cert store or configuring it to be loaded by Squid will be needed.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From rousskov at measurement-factory.com  Thu Apr 21 18:06:19 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 21 Apr 2016 12:06:19 -0600
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
Message-ID: <5719169B.4010700@measurement-factory.com>

On 04/21/2016 08:12 AM, Odhiambo Washington wrote:

> acl no_ssl_interception ssl::server_name ...
> ssl_bump splice no_ssl_interception 
> ssl_bump stare step2
> ssl_bump splice all

You are mixing splice and stare now. There are two groups of actions:

* peek and then splice
* stare and then bump

Do not mix actions from different groups together unless you know what
you are doing.


> So basically I should just have two options, I think, no?? Like
> 
> ssl_bump stare step2
> ssl_bump splice all

Two bugs in this config:

1. It will splice everything during step #1. It is equivalent to:

   ssl_bump splice all


2. To quote the wiki page:

stare (step2): Receive server certificate while preserving the
possibility of bumping the connection. Staring at the server certificate
usually precludes future splicing of the connection.

squid.conf.documented has very similar text as well.

You are telling Squid to splice do exactly what the documentation tells
you is not usually possible.


I can understand that it may be difficult to find and interpret
documentation correctly. I can understand that it is difficult to
evaluate a given configuration correctly. What I cannot understand is
why you are not starting with configurations suggested specifically for
your use case, on this email thread.


> If one day, for some reason I want to bump, then I could change to:
> 
> ssl_bump splice no_ssl_interception
> ssl_bump stare step2
> ssl_bump bump all

Similar to #1 above, this will bump all connections not matching the
[misnamed] no_ssl_interception during step1.

The first matching action wins. During step1, that action is "bump" from
your last rule if no_ssl_interception does not match.


HTH,

Alex.



From odhiambo at gmail.com  Thu Apr 21 18:12:30 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 21:12:30 +0300
Subject: [squid-users] Squid-4.0.9 and FreeBSD 9.3 / FreeBSD-10.3
Message-ID: <CAAdA2WOMbjm64pDo3vdjEgSqNY7xCFro3FKbQA9=9iMFF1dS2A@mail.gmail.com>

Hi Amos,

I have just now succeeded in compiling squid-4.0.9 on FreeBSD 10.3 and I'm
even able to run it.
The server I am testing on serves about 20 users. It's been successfully
running 3.5.x (upgraded to 3.5.17 today).

On my other server that is FreeBSD-9.3 (the one I upgraded recently from
8.4) I still get stuck at a point, but hopefully someone could help me out:

[wash at gw ~/Tools/Squid/4.x/squid-4.0.9]$ make
Making all in compat
depbase=`echo assert.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`; /bin/sh
../libtool  --tag=CXX    --mode=compile clang++ -DHAVE_CONFIG_H    -I..
-I../include  -I../lib -I../src  -I../include  -I/usr/local/include
 -I../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include  -I/usr/local/include/libxml2  -Werror
-Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
-I/usr/local/include  -g -O2 -march=native -std=c++11 -I/usr/local/include
-MT assert.lo -MD -MP -MF $depbase.Tpo -c -o assert.lo assert.cc && mv -f
$depbase.Tpo $depbase.Plo
libtool: compile:  clang++ -DHAVE_CONFIG_H -I.. -I../include -I../lib
-I../src -I../include -I/usr/local/include -I../libltdl -I/usr/include
-I/usr/local/include/libxml2 -I/usr/local/include
-I/usr/local/include/libxml2 -Werror -Qunused-arguments
-Wno-deprecated-register -D_REENTRANT -I/usr/local/include -g -O2
-march=native -std=c++11 -I/usr/local/include -MT assert.lo -MD -MP -MF
.deps/assert.Tpo -c assert.cc  -fPIC -DPIC -o .libs/assert.o
In file included from assert.cc:9:
In file included from ../include/squid.h:43:
In file included from ../compat/compat.h:70:
../compat/types.h:62:10: fatal error: 'cstdint' file not found
#include <cstdint>
         ^
1 error generated.
*** [assert.lo] Error code 1

Stop in /usr/home/wash/Tools/Squid/4.x/squid-4.0.9/compat.
*** [all-recursive] Error code 1

Stop in /usr/home/wash/Tools/Squid/4.x/squid-4.0.9.


I have posted my config.log on this link: http://goo.gl/eH9RcA

Is there anything obvious from the config.log that makes it impossible to
install 4.0.9 on the FreeBSD-9.x (i386) branch? If so, then I will abandon
the attempts to compile:)

Below are my configure options:


env CPPFLAGS=-I/usr/local/include CC=clang CXX=clang++ ./configure
--prefix=/opt/squid-4 \
        --enable-removal-policies="lru heap" \
        --disable-epoll \
        --enable-auth \
        --enable-auth-basic="DB NCSA PAM PAM POP3" \
        --with-pthreads \
        --enable-storeio="ufs diskd aufs" \
        --enable-delay-pools \
        --enable-snmp  \
        --with-openssl=/usr \
        --enable-forw-via-db \
        --enable-cache-digests \
        --enable-wccpv2 \
        --enable-follow-x-forwarded-for \
        --with-large-files \
        --enable-large-cache-files \
        --enable-esi \
        --enable-kqueue \
        --enable-icap-client \
        --enable-kill-parent-hack \
        --enable-ssl \
        --enable-ssl-crtd \
        --enable-url-rewrite-helpers \
        --enable-xmalloc-statistics \
        --enable-eui \
        --enable-zph-qos \
        --with-nat-devpf \
        --enable-pf-transparent \
        --without-mit-kerberos \
        --without-heimdal-kerbers \
        --without-gssapi-kerberos




-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/e57b0f21/attachment.htm>

From odhiambo at gmail.com  Thu Apr 21 18:20:51 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 21:20:51 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <5719169B.4010700@measurement-factory.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
Message-ID: <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>

Hi Alex,

I have now changed to *configurations suggested specifically for your use
case, on this email thread* :)



acl no_ssl_interception ssl::server_name
"/usr/local/etc/squid/ssl_bump_broken_sites.txt"
ssl_bump splice no_ssl_interception
ssl_bump stare all
ssl_bump bump all

Now, suppose, as I think in my mind, bumping isn't really what I need, can
I just comment out 'ssl_bump bump all'  and sit easy or should I switch to
ssl_bump splice all ??

I am sorry for my confusion...I think I have been on this way too long that
my small brain has reached /etc (saturation point).

Thank you once again.



On 21 April 2016 at 21:06, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/21/2016 08:12 AM, Odhiambo Washington wrote:
>
> > acl no_ssl_interception ssl::server_name ...
> > ssl_bump splice no_ssl_interception
> > ssl_bump stare step2
> > ssl_bump splice all
>
> You are mixing splice and stare now. There are two groups of actions:
>
> * peek and then splice
> * stare and then bump
>
> Do not mix actions from different groups together unless you know what
> you are doing.
>
>
> > So basically I should just have two options, I think, no?? Like
> >
> > ssl_bump stare step2
> > ssl_bump splice all
>
> Two bugs in this config:
>
> 1. It will splice everything during step #1. It is equivalent to:
>
>    ssl_bump splice all
>
>
> 2. To quote the wiki page:
>
> stare (step2): Receive server certificate while preserving the
> possibility of bumping the connection. Staring at the server certificate
> usually precludes future splicing of the connection.
>
> squid.conf.documented has very similar text as well.
>
> You are telling Squid to splice do exactly what the documentation tells
> you is not usually possible.
>
>
> I can understand that it may be difficult to find and interpret
> documentation correctly. I can understand that it is difficult to
> evaluate a given configuration correctly. What I cannot understand is
> why you are not starting with configurations suggested specifically for
> your use case, on this email thread.
>
>
> > If one day, for some reason I want to bump, then I could change to:
> >
> > ssl_bump splice no_ssl_interception
> > ssl_bump stare step2
> > ssl_bump bump all
>
> Similar to #1 above, this will bump all connections not matching the
> [misnamed] no_ssl_interception during step1.
>
> The first matching action wins. During step1, that action is "bump" from
> your last rule if no_ssl_interception does not match.
>
>
> HTH,
>
> Alex.
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/71d31d4d/attachment.htm>

From squid3 at treenet.co.nz  Thu Apr 21 18:52:48 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Apr 2016 06:52:48 +1200
Subject: [squid-users] Squid-4.0.9 and FreeBSD 9.3 / FreeBSD-10.3
In-Reply-To: <CAAdA2WOMbjm64pDo3vdjEgSqNY7xCFro3FKbQA9=9iMFF1dS2A@mail.gmail.com>
References: <CAAdA2WOMbjm64pDo3vdjEgSqNY7xCFro3FKbQA9=9iMFF1dS2A@mail.gmail.com>
Message-ID: <57192180.50602@treenet.co.nz>

On 22/04/2016 6:12 a.m., Odhiambo Washington wrote:
> Hi Amos,
> 
> I have just now succeeded in compiling squid-4.0.9 on FreeBSD 10.3 and I'm
> even able to run it.
> The server I am testing on serves about 20 users. It's been successfully
> running 3.5.x (upgraded to 3.5.17 today).
> 
> On my other server that is FreeBSD-9.3 (the one I upgraded recently from
> 8.4) I still get stuck at a point, but hopefully someone could help me out:
> 
> [wash at gw ~/Tools/Squid/4.x/squid-4.0.9]$ make


> libtool: compile:  clang++ -DHAVE_CONFIG_H -I.. -I../include -I../lib
> -I../src -I../include -I/usr/local/include -I../libltdl -I/usr/include
> -I/usr/local/include/libxml2 -I/usr/local/include
> -I/usr/local/include/libxml2 -Werror -Qunused-arguments
> -Wno-deprecated-register -D_REENTRANT -I/usr/local/include -g -O2
> -march=native -std=c++11 -I/usr/local/include -MT assert.lo -MD -MP -MF
> .deps/assert.Tpo -c assert.cc  -fPIC -DPIC -o .libs/assert.o
> In file included from assert.cc:9:
> In file included from ../include/squid.h:43:
> In file included from ../compat/compat.h:70:
> ../compat/types.h:62:10: fatal error: 'cstdint' file not found
> #include <cstdint>
>          ^

This is one of the standard library files. It is required to be present
in C++11 compiler systems. So our configure is not testing for it.

It would seem clang is not finding the correct C++11 stdlib headers. I
assume you know how and where to check for those?


> 
> I have posted my config.log on this link: http://goo.gl/eH9RcA
> 
> Is there anything obvious from the config.log that makes it impossible to
> install 4.0.9 on the FreeBSD-9.x (i386) branch? If so, then I will abandon
> the attempts to compile:)

Nothing obvious. It finishes without an error message, so the things you
have required to be built with your ./configure parameters can be used
somehow.

Amos



From squid3 at treenet.co.nz  Thu Apr 21 19:04:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Apr 2016 07:04:21 +1200
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
Message-ID: <57192435.6070807@treenet.co.nz>

On 22/04/2016 6:20 a.m., Odhiambo Washington wrote:
> Hi Alex,
> 
> I have now changed to *configurations suggested specifically for your use
> case, on this email thread* :)
> 
> 
> 
> acl no_ssl_interception ssl::server_name
> "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> ssl_bump splice no_ssl_interception
> ssl_bump stare all
> ssl_bump bump all
> 
> Now, suppose, as I think in my mind, bumping isn't really what I need, can
> I just comment out 'ssl_bump bump all'  and sit easy or should I switch to
> ssl_bump splice all ??

No the "stare" being done will prevent splice and you will see breakage
or unexpected things again.

You have to replace 'stare' with 'peek' AND replace 'bump' with 'splice'.

Amos



From odhiambo at gmail.com  Thu Apr 21 19:59:43 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 22:59:43 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <57192435.6070807@treenet.co.nz>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
Message-ID: <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>

On 21 April 2016 at 22:04, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 22/04/2016 6:20 a.m., Odhiambo Washington wrote:
> > Hi Alex,
> >
> > I have now changed to *configurations suggested specifically for your use
> > case, on this email thread* :)
> >
> >
> >
> > acl no_ssl_interception ssl::server_name
> > "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> > ssl_bump splice no_ssl_interception
> > ssl_bump stare all
> > ssl_bump bump all
> >
> > Now, suppose, as I think in my mind, bumping isn't really what I need,
> can
> > I just comment out 'ssl_bump bump all'  and sit easy or should I switch
> to
> > ssl_bump splice all ??
>
> No the "stare" being done will prevent splice and you will see breakage
> or unexpected things again.
>
> You have to replace 'stare' with 'peek' AND replace 'bump' with 'splice'.
> <http://lists.squid-cache.org/listinfo/squid-users>
>

Like below???


acl no_ssl_interception ssl::server_name
"/usr/local/etc/squid/ssl_bump_broken_sites.txt"
ssl_bump splice no_ssl_interception
ssl_bump peek all
ssl_bump splice all


Thank you.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/c787275c/attachment.htm>

From odhiambo at gmail.com  Thu Apr 21 20:03:02 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 23:03:02 +0300
Subject: [squid-users] Squid-4.0.9 and FreeBSD 9.3 / FreeBSD-10.3
In-Reply-To: <57192180.50602@treenet.co.nz>
References: <CAAdA2WOMbjm64pDo3vdjEgSqNY7xCFro3FKbQA9=9iMFF1dS2A@mail.gmail.com>
 <57192180.50602@treenet.co.nz>
Message-ID: <CAAdA2WMGkHxW22tTz1r7GFTQxMuND-4VZuBHXUbBZopZ-NSG6g@mail.gmail.com>

On 21 April 2016 at 21:52, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 22/04/2016 6:12 a.m., Odhiambo Washington wrote:
> > Hi Amos,
> >
> > I have just now succeeded in compiling squid-4.0.9 on FreeBSD 10.3 and
> I'm
> > even able to run it.
> > The server I am testing on serves about 20 users. It's been successfully
> > running 3.5.x (upgraded to 3.5.17 today).
> >
> > On my other server that is FreeBSD-9.3 (the one I upgraded recently from
> > 8.4) I still get stuck at a point, but hopefully someone could help me
> out:
> >
> > [wash at gw ~/Tools/Squid/4.x/squid-4.0.9]$ make
>
>
> > libtool: compile:  clang++ -DHAVE_CONFIG_H -I.. -I../include -I../lib
> > -I../src -I../include -I/usr/local/include -I../libltdl -I/usr/include
> > -I/usr/local/include/libxml2 -I/usr/local/include
> > -I/usr/local/include/libxml2 -Werror -Qunused-arguments
> > -Wno-deprecated-register -D_REENTRANT -I/usr/local/include -g -O2
> > -march=native -std=c++11 -I/usr/local/include -MT assert.lo -MD -MP -MF
> > .deps/assert.Tpo -c assert.cc  -fPIC -DPIC -o .libs/assert.o
> > In file included from assert.cc:9:
> > In file included from ../include/squid.h:43:
> > In file included from ../compat/compat.h:70:
> > ../compat/types.h:62:10: fatal error: 'cstdint' file not found
> > #include <cstdint>
> >          ^
>
> This is one of the standard library files. It is required to be present
> in C++11 compiler systems. So our configure is not testing for it.
>
> It would seem clang is not finding the correct C++11 stdlib headers. I
> assume you know how and where to check for those?
>

Heheeee... I wouldn't lie that I know. How do I go about it??


>
> > I have posted my config.log on this link: http://goo.gl/eH9RcA
> >
> > Is there anything obvious from the config.log that makes it impossible to
> > install 4.0.9 on the FreeBSD-9.x (i386) branch? If so, then I will
> abandon
> > the attempts to compile:)
>
> Nothing obvious. It finishes without an error message, so the things you
> have required to be built with your ./configure parameters can be used
> somehow.
>

That is comforting.



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/a518e65d/attachment.htm>

From rousskov at measurement-factory.com  Thu Apr 21 20:14:08 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 21 Apr 2016 14:14:08 -0600
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
Message-ID: <57193490.8@measurement-factory.com>

On 04/21/2016 01:59 PM, Odhiambo Washington wrote:
> On 21 April 2016 at 22:04, Amos Jeffries wrote:
> 
>     On 22/04/2016 6:20 a.m., Odhiambo Washington wrote:
>     > I have now changed to *configurations suggested specifically for your use
>     > case, on this email thread* :)

>     > acl no_ssl_interception ssl::server_name
>     > "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
>     > ssl_bump splice no_ssl_interception
>     > ssl_bump stare all
>     > ssl_bump bump all


>     No the "stare" being done will prevent splice and you will see breakage
>     or unexpected things again. 
>     You have to replace 'stare' with 'peek' AND replace 'bump' with
>     'splice'.


> Like below???


> acl no_ssl_interception ssl::server_name
> "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> ssl_bump splice no_ssl_interception
> ssl_bump peek all
> ssl_bump splice all 


Logging aside, your latest random configuration is equivalent to

  ssl_bump splice all

which means you are better off not intercepting SSL at all, which brings
us back to the old question: What do you want Squid to do?


If you want Squid to not intrude except when terminating prohibited
traffic, then start with this sketch:

  ssl_bump terminate prohibited_traffic
  ssl_bump peek all
  ssl_bump splice all

If you want Squid to intrude (where possible) and block prohibited
traffic, then install your CA certificates on all user devices and start
with this sketch:

  ssl_bump splice things_that_are_impossible_to_bump
  ssl_bump stare all
  ssl_bump bump all
  http_access deny prohibited_traffic

Alex.



From serdebronce at gmail.com  Thu Apr 21 20:21:15 2016
From: serdebronce at gmail.com (Ser de Bronce)
Date: Thu, 21 Apr 2016 23:21:15 +0300
Subject: [squid-users] Is it possible to log request's proxy hostname in the
 access log?
Message-ID: <CABzQUcS7BV5gAHxtt5EQF1J-xueDmrdo6M6=gNFwLtwGiUrtHg@mail.gmail.com>

Hi there,

Maybe someone already knows any solution:

I have a squid server that can be accessed from multiple subdomains.
For example, user A does a proxy request on "aaa.myproxy.com" and user B on
"bbb.myproxy.com"
Is it possible to log which subdomain was requested by the user?

Best Regards,
Sergey
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/76a5141c/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Apr 21 20:22:40 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 21 Apr 2016 22:22:40 +0200
Subject: [squid-users] Extraneous question regarding SSL interception
Message-ID: <201604212222.41104.Antony.Stone@squid.open.source.it>

Hi.

Forgive me if this is answered in the documentation somewhere (but please 
point me at it if so, because I haven't been able to find it), but where do the 
terms "bump", "peek", "splice" and "stare" come from?

Personally I don't find them particularly intuitive to comprehend, in terms of 
what they're doing in the course of an SSL connection, so I'm just wondering 
where they came from and why they were chosen as the best way to describe 
what's going on at various points in the communication?


Thanks,


Antony.

-- 
You can tell that the day just isn't going right when you find yourself using 
the telephone before the toilet.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Thu Apr 21 20:26:35 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 21 Apr 2016 22:26:35 +0200
Subject: [squid-users] Is it possible to log request's proxy hostname in
	the access log?
In-Reply-To: <CABzQUcS7BV5gAHxtt5EQF1J-xueDmrdo6M6=gNFwLtwGiUrtHg@mail.gmail.com>
References: <CABzQUcS7BV5gAHxtt5EQF1J-xueDmrdo6M6=gNFwLtwGiUrtHg@mail.gmail.com>
Message-ID: <201604212226.35275.Antony.Stone@squid.open.source.it>

On Thursday 21 April 2016 at 22:21:15, Ser de Bronce wrote:

> I have a squid server that can be accessed from multiple subdomains.
> For example, user A does a proxy request on "aaa.myproxy.com" and user B on
> "bbb.myproxy.com"
> Is it possible to log which subdomain was requested by the user?

No, because DNS resolves both hostnames to the IP address of your proxy, and 
the requests are then sent to that IP address.  The requests contain no 
information about the hostname which the client thought the proxy should have.


Antony.

-- 
Most people are aware that the Universe is big.

 - Paul Davies, Professor of Theoretical Physics

                                                   Please reply to the list;
                                                         please *don't* CC me.


From serdebronce at gmail.com  Thu Apr 21 20:30:15 2016
From: serdebronce at gmail.com (Ser de Bronce)
Date: Thu, 21 Apr 2016 23:30:15 +0300
Subject: [squid-users] Is it possible to log request's proxy hostname in
 the access log?
In-Reply-To: <201604212226.35275.Antony.Stone@squid.open.source.it>
References: <CABzQUcS7BV5gAHxtt5EQF1J-xueDmrdo6M6=gNFwLtwGiUrtHg@mail.gmail.com>
 <201604212226.35275.Antony.Stone@squid.open.source.it>
Message-ID: <CABzQUcTpCbp8KO=1-AD8qhcfoXfPdTGs2EpyHmME3YyXGkhjhQ@mail.gmail.com>

Thank you for immediate answer, Antony.

Best Regards,
Sergey

2016-04-21 23:26 GMT+03:00 Antony Stone <Antony.Stone at squid.open.source.it>:

> On Thursday 21 April 2016 at 22:21:15, Ser de Bronce wrote:
>
> > I have a squid server that can be accessed from multiple subdomains.
> > For example, user A does a proxy request on "aaa.myproxy.com" and user
> B on
> > "bbb.myproxy.com"
> > Is it possible to log which subdomain was requested by the user?
>
> No, because DNS resolves both hostnames to the IP address of your proxy,
> and
> the requests are then sent to that IP address.  The requests contain no
> information about the hostname which the client thought the proxy should
> have.
>
>
> Antony.
>
> --
> Most people are aware that the Universe is big.
>
>  - Paul Davies, Professor of Theoretical Physics
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/b58c06d4/attachment.htm>

From rousskov at measurement-factory.com  Thu Apr 21 20:53:35 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 21 Apr 2016 14:53:35 -0600
Subject: [squid-users] Extraneous question regarding SSL interception
In-Reply-To: <201604212222.41104.Antony.Stone@squid.open.source.it>
References: <201604212222.41104.Antony.Stone@squid.open.source.it>
Message-ID: <57193DCF.8060104@measurement-factory.com>

On 04/21/2016 02:22 PM, Antony Stone wrote:

> Forgive me if this is answered in the documentation somewhere (but please 
> point me at it if so, because I haven't been able to find it), but where do the 
> terms "bump", "peek", "splice" and "stare" come from?

"splice" comes from a standard networking technique of "TCP splicing"
which is exactly what Squid is trying to do when the "splice" action wins.

"bump" comes from a more-or-less standard networking concept of "bump in
the wire" that describes temporary elevating processing to the next
protocol level. In Squid's case, we are temporary elevating processing
from SSL to HTTP level.

"peek" comes from the English verb "to peek" which means "look quickly"
and has such synonyms as "take a stealthy look", which is exactly what
Squid is trying to do when the "peek" action wins.

"stare" comes from the English verb "to stare" and was chosen as a kind
of antonym to "to peek". When Squid stares at the SSL exchanges, it may
modify things and generally prepare connections for bumping, which is a
much longer operation compared to peeking.

There is also "terminate" which does what it says.


In my biased opinion, the action names are actually pretty accurate and
descriptive. My only regret is that the feature itself was called SSL
_Bump_ and not something more action-neutral. Unfortunately, I did not
predict the necessary for more actions when we started writing bumping code.

Alex.



From odhiambo at gmail.com  Thu Apr 21 21:26:58 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 22 Apr 2016 00:26:58 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <57193490.8@measurement-factory.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
Message-ID: <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>

On 21 April 2016 at 23:14, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/21/2016 01:59 PM, Odhiambo Washington wrote:
> > On 21 April 2016 at 22:04, Amos Jeffries wrote:
> >
> >     On 22/04/2016 6:20 a.m., Odhiambo Washington wrote:
> >     > I have now changed to *configurations suggested specifically for
> your use
> >     > case, on this email thread* :)
>
> >     > acl no_ssl_interception ssl::server_name
> >     > "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> >     > ssl_bump splice no_ssl_interception
> >     > ssl_bump stare all
> >     > ssl_bump bump all
>
>
> >     No the "stare" being done will prevent splice and you will see
> breakage
> >     or unexpected things again.
> >     You have to replace 'stare' with 'peek' AND replace 'bump' with
> >     'splice'.
>
>
> > Like below???
>
>
> > acl no_ssl_interception ssl::server_name
> > "/usr/local/etc/squid/ssl_bump_broken_sites.txt"
> > ssl_bump splice no_ssl_interception
> > ssl_bump peek all
> > ssl_bump splice all
>
>
> Logging aside, your latest random configuration is equivalent to
>
>   ssl_bump splice all
>
> which means you are better off not intercepting SSL at all, which brings
> us back to the old question: What do you want Squid to do?
>

If I could intercept SSL and do nothing EXCEPT subject the domains to time
ACLs, that'd be all. I do not need any bumping to be precise.
I just want the data passing through squid for me to determine who is
allowed to access it and at what time.

I do have time ACLs, which I use in conjunction with MAC ACLs and certain
domain, like facebook.com. Right now I rely on destdomain to identify the
domains.
With domains using SSL, I cannot use destdomain, right? Let me demonstrate
with config snippets from my squid.conf, perhaps that would explain it
better and maybe I will find a better easier way out that this ssl_bump
monster:-)

acl TIMEweekdaysALLDAY time MTWHF 09:00-17:00
acl TIMEafterhoursMORN time MTWHF 00:00-09:00
acl TIMElunch time MTWHF 12:00-13:59
acl TIMEafterhoursAFT time MTWHF 14:30-23:59
acl TIMEsatMORN time A 00:00-07:00
acl TIMEsatAFT time A 11:00-23:59
acl TIMEsatALLDAY time A 00:00-23:59
acl TIMEsundALLDAY time S 00:00-23:59

# Internet Access Regulation
# Some privileged staff - can browse unrestricted
acl privileged-staff arp "/usr/local/etc/squid/privileged_mac_addresses.txt"

# Sites staff waste all their time on - Social Networks, streaming sites, etc
acl TIMEWASTAGESITES dstdomain "/usr/local/etc/squid/time_wastage_sites.txt"

# TIMEWASTAGESITES
http_access allow TIMEWASTAGESITES privileged-staff
http_access allow TIMEWASTAGESITES TIMElunch
http_access allow TIMEWASTAGESITES TIMEafterhoursAFT
http_access allow TIMEWASTAGESITES TIMEafterhoursMORN
http_access allow TIMEWASTAGESITES TIMEsatALLDAY
http_access allow TIMEWASTAGESITES TIMEsundALLDAY
http_access deny  TIMEWASTAGESITES


Now, the above used to work until facebook.com, youtube.com, and
others switched to HTTPS. After that it wasn't possible for me to
control access to them.

So really, all I want is the ability to intercept SSL and subject it
to those time ACLs for a class of users. Nothing more.



> If you want Squid to not intrude except when terminating prohibited
> traffic, then start with this sketch:
>
>   ssl_bump terminate prohibited_traffic
>   ssl_bump peek all
>   ssl_bump splice all
>

Lemme see if I understand this. I have a problem wrapping my head around
'terminate' (as a terminology, maybe) and 'prohibited_traffic' (also as a
terminology).
So, are you saying that prohibited_traffic here is something like:

acl TIMEWASTAGE_SSL
ssl::server_name "/usr/local/etc/squid/time_wastage_SSL_sites.txt"

And in that file I have
.facebook.com
.youtube.com
...

Then I just apply my usual time ACLs..

http_access allow TIMEWASTAGESITES_SSL privileged_staff
http_access allow TIMEWASTAGESITES_SSL TIMElunch
http_access allow TIMEWASTAGESITES_SSL TIMEafterhoursAFT
http_access allow TIMEWASTAGESITES_SSL TIMEafterhoursMORN
http_access allow TIMEWASTAGESITES_SSL TIMEsatALLDAY
http_access allow TIMEWASTAGESITES_SSL TIMEsundALLDAY
http_access deny  TIMEWASTAGESITES_SSL

That is more like all I want - use *ssl::server_name* instead of *dstdomain.
* The sites are NOT prohibited per se, and 'terminate' kinda scares me. I
need to RTFM about this 'terminate' again and again until I can sing it:)



> If you want Squid to intrude (where possible) and block prohibited
> traffic, then install your CA certificates on all user devices and start
> with this sketch:
>
>   ssl_bump splice things_that_are_impossible_to_bump
>   ssl_bump stare all
>   ssl_bump bump all
>   http_access deny prohibited_traffic
>
> Alex.
>
>

I actually believe I do not need any mention of ssl_bump, but the confusion
for me arises out of TWO things:

1. In my firewall (FreeBSD PF), redirecting traffic destined to port 443
via squid wasn't an option prior to the intruduction of the SSL
interception, right?
2. In squid.conf, I did not yet figure out if I can use just


     https_port 13129 intercept

Instead of

    https_ports NNNN intercept ssl-bump ...... ....



I hope this time round I have explained myself well.

Thank you.

-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160422/e2ad236b/attachment.htm>

From odhiambo at gmail.com  Thu Apr 21 21:41:39 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Thu, 21 Apr 2016 21:41:39 +0000
Subject: [squid-users] Extraneous question regarding SSL interception
In-Reply-To: <57193DCF.8060104@measurement-factory.com>
References: <201604212222.41104.Antony.Stone@squid.open.source.it>
 <57193DCF.8060104@measurement-factory.com>
Message-ID: <CAAdA2WOOKff6hJtXdGQ75arvhhymVhCmv8M7KLab47188wYbZw@mail.gmail.com>

Yes! That SSL _Bump_ name!

Thanks for explaining the origins.

On 23:53, Thu, Apr 21, 2016 Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/21/2016 02:22 PM, Antony Stone wrote:
>
> > Forgive me if this is answered in the documentation somewhere (but please
> > point me at it if so, because I haven't been able to find it), but where
> do the
> > terms "bump", "peek", "splice" and "stare" come from?
>
> "splice" comes from a standard networking technique of "TCP splicing"
> which is exactly what Squid is trying to do when the "splice" action wins.
>
> "bump" comes from a more-or-less standard networking concept of "bump in
> the wire" that describes temporary elevating processing to the next
> protocol level. In Squid's case, we are temporary elevating processing
> from SSL to HTTP level.
>
> "peek" comes from the English verb "to peek" which means "look quickly"
> and has such synonyms as "take a stealthy look", which is exactly what
> Squid is trying to do when the "peek" action wins.
>
> "stare" comes from the English verb "to stare" and was chosen as a kind
> of antonym to "to peek". When Squid stares at the SSL exchanges, it may
> modify things and generally prepare connections for bumping, which is a
> much longer operation compared to peeking.
>
> There is also "terminate" which does what it says.
>
>
> In my biased opinion, the action names are actually pretty accurate and
> descriptive. My only regret is that the feature itself was called SSL
> _Bump_ and not something more action-neutral. Unfortunately, I did not
> predict the necessary for more actions when we started writing bumping
> code.
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160421/6161bb97/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Apr 21 21:53:39 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 21 Apr 2016 23:53:39 +0200
Subject: [squid-users] Extraneous question regarding SSL interception
In-Reply-To: <57193DCF.8060104@measurement-factory.com>
References: <201604212222.41104.Antony.Stone@squid.open.source.it>
 <57193DCF.8060104@measurement-factory.com>
Message-ID: <201604212353.39345.Antony.Stone@squid.open.source.it>

On Thursday 21 April 2016 at 22:53:35, Alex Rousskov wrote a good explanation 
of SSL bumping.

> On 04/21/2016 02:22 PM, Antony Stone wrote:
> > Forgive me if this is answered in the documentation somewhere (but please
> > point me at it if so, because I haven't been able to find it), but where
> > do the terms "bump", "peek", "splice" and "stare" come from?

Thank you greatly for your answer to that.

Any chance of getting it added to the Squid documentation for newbies, so they 
have a better concept of what these terms mean and where they apply?


Antony.

-- 
I conclude that there are two ways of constructing a software design: One way 
is to make it so simple that there are _obviously_ no deficiencies, and the 
other way is to make it so complicated that there are no _obvious_ 
deficiencies.

 - C A R Hoare

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Thu Apr 21 22:43:37 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 21 Apr 2016 16:43:37 -0600
Subject: [squid-users] Extraneous question regarding SSL interception
In-Reply-To: <201604212353.39345.Antony.Stone@squid.open.source.it>
References: <201604212222.41104.Antony.Stone@squid.open.source.it>
 <57193DCF.8060104@measurement-factory.com>
 <201604212353.39345.Antony.Stone@squid.open.source.it>
Message-ID: <57195799.6090403@measurement-factory.com>

On 04/21/2016 03:53 PM, Antony Stone wrote:

> Any chance of getting it added to the Squid documentation for newbies, so they 
> have a better concept of what these terms mean and where they apply?

Please do!

Alex.



From rousskov at measurement-factory.com  Thu Apr 21 23:16:50 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 21 Apr 2016 17:16:50 -0600
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
 <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
Message-ID: <57195F62.3010209@measurement-factory.com>

On 04/21/2016 03:26 PM, Odhiambo Washington wrote:
> On 21 April 2016 at 23:14, Alex Rousskov wrote:
>     Logging aside, your latest random configuration is equivalent to
>     [...] not intercepting SSL at all, which brings
>     us back to the old question: What do you want Squid to do?


> If I could intercept SSL and do nothing EXCEPT subject the domains to
> time ACLs, that'd be all.

You are going back to the problem we have already discussed. Please slow
down and translate your description above into what should happen to
user connections that match your "time ACLs".

* Does "subject the domains to time ACLs" mean "immediately close
connections that match" those ACLs?

* Or does it mean "serve Squid error pages" over connections that match
those ACLs?

Once you decide, apply one of the two templates provided (the two
templates correspond to which of the two questions you answer "yes").


> I just want the data passing through squid for me to determine who is
> allowed to access it and at what time.

Assume Squid has made that access determination you want to make, and
the user is not allowed. Now what: Close the connection? Or serve an
error page?


> I do have time ACLs, [...]

The specifics of your ACLs are irrelevant at this stage. You can fix
them later once you get overall SslBump setup working the way you want.
You can assume that there is just one ACL called "prohibited_traffic" or
"good_traffic". Now write the rules that determine what happens to
connections that match one of those two ACLs.


>     If you want Squid to not intrude except when terminating prohibited
>     traffic, then start with this sketch:
> 
>       ssl_bump terminate prohibited_traffic
>       ssl_bump peek all
>       ssl_bump splice all
> 
> 
> Lemme see if I understand this. I have a problem wrapping my head around
> 'terminate' (as a terminology, maybe)

"terminate" means "close the SSL connection(s) immediately". No error
response is sent by Squid to the user. It does not get much simpler than
that! The browser will probably show some "secure connection could not
be negotiated" error to the user with no usable details [because Squid
sent nothing to the browser in this case].


> and 'prohibited_traffic' (also as a terminology).

Just some ACL name. You will define that aggregate ACL later to match
any traffic you want to prohibit. It will contain a combination of time
and server name ACLs. Other details are not important until your SslBump
[and http_access rules] are correct.

If you do not know how to aggregate ACLs, look for "any-of" and "all-of"
in squid.conf.documented, but, again, ACL specifics are not important
right now. They will become important at stage three. Now you are
struggling with stage one: Deciding what to do with matching SSL
connections (close or serve error pages).

FWIW, my recommendation is to terminate/close and find other ways to
inform users about their policy violations.

Alex.



From odhiambo at gmail.com  Fri Apr 22 08:23:48 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 22 Apr 2016 11:23:48 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <57195F62.3010209@measurement-factory.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
 <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
 <57195F62.3010209@measurement-factory.com>
Message-ID: <CAAdA2WN53xFWcSy_HjmwOr7gftKdWSgHRoqYC6U3U3EkWHUSqg@mail.gmail.com>

On 22 April 2016 at 02:16, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/21/2016 03:26 PM, Odhiambo Washington wrote:
> > On 21 April 2016 at 23:14, Alex Rousskov wrote:
> >     Logging aside, your latest random configuration is equivalent to
> >     [...] not intercepting SSL at all, which brings
> >     us back to the old question: What do you want Squid to do?
>
>
> > If I could intercept SSL and do nothing EXCEPT subject the domains to
> > time ACLs, that'd be all.
>
> You are going back to the problem we have already discussed. Please slow
> down and translate your description above into what should happen to
> user connections that match your "time ACLs".
>


*slow down mode engaged*

You have given me these two templates:

(1)
If you want Squid to not intrude except when terminating prohibited traffic,
then start with this sketch:

  ssl_bump terminate prohibited_traffic
  ssl_bump peek all
  ssl_bump splice all

I would have preffered this option, first because it doesn't involve me
installing my CA on all user devices and secondly because of no intrusion.
However I cannot figure out how to deal with this when it comes to ACLs
because '*terminate*' isn't really what I think I want. What I want is as
follows:
(a) squid receives requiest from a particular host for facebook.com. Host
is identified by MAC Address or IP
(b) squid decides (based on ACLs) if host is allowed access to facebook.com
at this time, then allows it
(c) squid throws an error message if host is not allowed access at this
time.

If I could achieve the above, I will be fine. How to craft the configs is
my trouble. I keep fumbling.


(2)
If you want Squid to intrude (where possible) and block prohibited
traffic, then install your CA certificates on all user devices and start
with this sketch:

  ssl_bump splice things_that_are_impossible_to_bump
  ssl_bump stare all
  ssl_bump bump all
  http_access deny prohibited_traffic

Now here, the CA challenge abounds. We have a guest SSID on our WLAN and
this means I have to install the CAs even for guests or redo the network to
be able to accommodate guest users browsing without being subjected to our
internal policies.



>
> * Does "subject the domains to time ACLs" mean "immediately close
> connections that match" those ACLs?
>

No.


>
> * Or does it mean "serve Squid error pages" over connections that match
> those ACLs?
>

Yes.


>
> Once you decide, apply one of the two templates provided (the two
> templates correspond to which of the two questions you answer "yes").
>
>
> > I just want the data passing through squid for me to determine who is
> > allowed to access it and at what time.
>
> Assume Squid has made that access determination you want to make, and
> the user is not allowed. Now what: Close the connection? Or serve an
> error page?
>
>
Serve an error page.

.

>
> > I do have time ACLs, [...]
>
> The specifics of your ACLs are irrelevant at this stage. You can fix
> them later once you get overall SslBump setup working the way you want.
> You can assume that there is just one ACL called "prohibited_traffic" or
> "good_traffic". Now write the rules that determine what happens to
> connections that match one of those two ACLs.
>



>     If you want Squid to not intrude except when terminating prohibited
> >     traffic, then start with this sketch:
> >
> >       ssl_bump terminate prohibited_traffic
> >       ssl_bump peek all
> >       ssl_bump splice all
> >
> >
> > Lemme see if I understand this. I have a problem wrapping my head around
> > 'terminate' (as a terminology, maybe)
>
> "terminate" means "close the SSL connection(s) immediately". No error
> response is sent by Squid to the user. It does not get much simpler than
> that! The browser will probably show some "secure connection could not
> be negotiated" error to the user with no usable details [because Squid
> sent nothing to the browser in this case].
>
>
That is NOT what I want. I need squid to serve an error page that "Access
is denied at this time.."
I think it's usually something like "access controls prohibit you from
access this page at this time...".


>
> > and 'prohibited_traffic' (also as a terminology).
>
> Just some ACL name. You will define that aggregate ACL later to match
> any traffic you want to prohibit. It will contain a combination of time
> and server name ACLs. Other details are not important until your SslBump
> [and http_access rules] are correct.
>

Okay.


>
> If you do not know how to aggregate ACLs, look for "any-of" and "all-of"
> in squid.conf.documented, but, again, ACL specifics are not important
> right now. They will become important at stage three. Now you are
> struggling with stage one: Deciding what to do with matching SSL
> connections (close or serve error pages).
>

Sure, I am really struggling to understand this. I would like to serve
error pages. A complete example of this would really help. I am thinking,
based on the two templates you gave and going with the one where squid
intrudes, that it could be like below, but to be honest I am not sure so
kindly correct me.


acl time_wastage_sites_ssl ssl::server_name .facebook.com .youtube.com
ssl_bump splice time_wastage_sites_ssl
ssl_bump stare all
ssl_bump bump all
http_access allow time_wastage_sites_ssl privileged-staff
http_access allow time_wastage_sites_ssl privileged-clients
http_access allow time_wastage_sites_ssl TIMElunch
http_access allow time_wastage_sites_ssl TIMEafterhoursAFT
http_access allow time_wastage_sites_ssl TIMEafterhoursMORN
http_access allow time_wastage_sites_ssl TIMEsatALLDAY
http_access allow time_wastage_sites_ssl TIMEsundALLDAY
http_access deny  time_wastage_sites_ssl



>
> FWIW, my recommendation is to terminate/close and find other ways to
> inform users about their policy violations.





-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160422/d4c5993e/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 22 10:45:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Apr 2016 22:45:57 +1200
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WN53xFWcSy_HjmwOr7gftKdWSgHRoqYC6U3U3EkWHUSqg@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
 <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
 <57195F62.3010209@measurement-factory.com>
 <CAAdA2WN53xFWcSy_HjmwOr7gftKdWSgHRoqYC6U3U3EkWHUSqg@mail.gmail.com>
Message-ID: <571A00E5.4000309@treenet.co.nz>

On 22/04/2016 8:23 p.m., Odhiambo Washington wrote:
> 
> Sure, I am really struggling to understand this. I would like to serve
> error pages. A complete example of this would really help. I am thinking,
> based on the two templates you gave and going with the one where squid
> intrudes, that it could be like below, but to be honest I am not sure so
> kindly correct me.
> 
> 
> acl time_wastage_sites_ssl ssl::server_name .facebook.com .youtube.com
> ssl_bump splice time_wastage_sites_ssl
> ssl_bump stare all
> ssl_bump bump all
> http_access allow time_wastage_sites_ssl privileged-staff
> http_access allow time_wastage_sites_ssl privileged-clients
> http_access allow time_wastage_sites_ssl TIMElunch
> http_access allow time_wastage_sites_ssl TIMEafterhoursAFT
> http_access allow time_wastage_sites_ssl TIMEafterhoursMORN
> http_access allow time_wastage_sites_ssl TIMEsatALLDAY
> http_access allow time_wastage_sites_ssl TIMEsundALLDAY
> http_access deny  time_wastage_sites_ssl
> 

In a file called "/etc/squid/tws":
.facebook.com
.youtube.com


squid.conf:
 acl time_wastage_sites_ssl  ssl::server_name "/etc/squid/tws"
 acl time_wastage_sites_http dstdomain        "/etc/squid/tws"

 acl privileged_traffic any-of \
    privileged-staff privileged-clients \
    TIMElunch TIMEafterhoursAFT TIMEafterhoursMORN \
    TIMEsatALLDAY TIMEsundALLDAY

 http_access allow privileged_traffic
 http_access deny time_wastage_sites_http

 ssl_bump splice privileged_traffic time_wastage_sites_ssl
 ssl_bump stare all
 ssl_bump bump all



You can probably merge the TIME* ACLs down as well like:
  # lunch
  acl okay_times time ...
  # afterhours PM
  acl okay_times time ...
  # afterhours AM
  acl okay_times time ...
  # Saturday and Sunday all day
  acl okay_times time SA

Amos



From odhiambo at gmail.com  Fri Apr 22 12:39:59 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 22 Apr 2016 15:39:59 +0300
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <571A00E5.4000309@treenet.co.nz>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
 <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
 <57195F62.3010209@measurement-factory.com>
 <CAAdA2WN53xFWcSy_HjmwOr7gftKdWSgHRoqYC6U3U3EkWHUSqg@mail.gmail.com>
 <571A00E5.4000309@treenet.co.nz>
Message-ID: <CAAdA2WNF1O6y03C8mhEE+hfANBER0O2CDWv7jBOdcSY+0C9tOg@mail.gmail.com>

On 22 April 2016 at 13:45, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 22/04/2016 8:23 p.m., Odhiambo Washington wrote:
> >
> > Sure, I am really struggling to understand this. I would like to serve
> > error pages. A complete example of this would really help. I am thinking,
> > based on the two templates you gave and going with the one where squid
> > intrudes, that it could be like below, but to be honest I am not sure so
> > kindly correct me.
> >
> >
> > acl time_wastage_sites_ssl ssl::server_name .facebook.com .youtube.com
> > ssl_bump splice time_wastage_sites_ssl
> > ssl_bump stare all
> > ssl_bump bump all
> > http_access allow time_wastage_sites_ssl privileged-staff
> > http_access allow time_wastage_sites_ssl privileged-clients
> > http_access allow time_wastage_sites_ssl TIMElunch
> > http_access allow time_wastage_sites_ssl TIMEafterhoursAFT
> > http_access allow time_wastage_sites_ssl TIMEafterhoursMORN
> > http_access allow time_wastage_sites_ssl TIMEsatALLDAY
> > http_access allow time_wastage_sites_ssl TIMEsundALLDAY
> > http_access deny  time_wastage_sites_ssl
> >
>
> In a file called "/etc/squid/tws":
> .facebook.com
> .youtube.com
>
>
> squid.conf:
>  acl time_wastage_sites_ssl  ssl::server_name "/etc/squid/tws"
>  acl time_wastage_sites_http dstdomain        "/etc/squid/tws"
>
>  acl privileged_traffic any-of \
>     privileged-staff privileged-clients \
>     TIMElunch TIMEafterhoursAFT TIMEafterhoursMORN \
>     TIMEsatALLDAY TIMEsundALLDAY
>
>  http_access allow privileged_traffic
>  http_access deny time_wastage_sites_http
>
>  ssl_bump splice privileged_traffic time_wastage_sites_ssl
>  ssl_bump stare all
>  ssl_bump bump all
>
>
>
> You can probably merge the TIME* ACLs down as well like:
>   # lunch
>   acl okay_times time ...
>   # afterhours PM
>   acl okay_times time ...
>   # afterhours AM
>   acl okay_times time ...
>   # Saturday and Sunday all day
>   acl okay_times time SA
>
> Amos
>
>
Quoting Alex:
"
If you want Squid to not intrude except when terminating prohibited traffic,
then start with this sketch:

>       ssl_bump terminate prohibited_traffic
>       ssl_bump peek all
>       ssl_bump splice all
"

So is it possible to achieve such a non-intrusive setup, but without
'terminate'?



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160422/22c404a3/attachment.htm>

From yvoinov at gmail.com  Fri Apr 22 12:42:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 22 Apr 2016 18:42:57 +0600
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WNF1O6y03C8mhEE+hfANBER0O2CDWv7jBOdcSY+0C9tOg@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
 <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
 <57195F62.3010209@measurement-factory.com>
 <CAAdA2WN53xFWcSy_HjmwOr7gftKdWSgHRoqYC6U3U3EkWHUSqg@mail.gmail.com>
 <571A00E5.4000309@treenet.co.nz>
 <CAAdA2WNF1O6y03C8mhEE+hfANBER0O2CDWv7jBOdcSY+0C9tOg@mail.gmail.com>
Message-ID: <2115802f-40e5-12d6-ee91-780d4cdb6c2e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


22.04.16 18:39, Odhiambo Washington ?????:
>
>
> On 22 April 2016 at 13:45, Amos Jeffries <squid3 at treenet.co.nz
<mailto:squid3 at treenet.co.nz>> wrote:
>
>     On 22/04/2016 8:23 p.m., Odhiambo Washington wrote:
>     >
>     > Sure, I am really struggling to understand this. I would like to
serve
>     > error pages. A complete example of this would really help. I am
thinking,
>     > based on the two templates you gave and going with the one where
squid
>     > intrudes, that it could be like below, but to be honest I am not
sure so
>     > kindly correct me.
>     >
>     >
>     > acl time_wastage_sites_ssl ssl::server_name .facebook.com
<http://facebook.com> .youtube.com <http://youtube.com>
>     > ssl_bump splice time_wastage_sites_ssl
>     > ssl_bump stare all
>     > ssl_bump bump all
>     > http_access allow time_wastage_sites_ssl privileged-staff
>     > http_access allow time_wastage_sites_ssl privileged-clients
>     > http_access allow time_wastage_sites_ssl TIMElunch
>     > http_access allow time_wastage_sites_ssl TIMEafterhoursAFT
>     > http_access allow time_wastage_sites_ssl TIMEafterhoursMORN
>     > http_access allow time_wastage_sites_ssl TIMEsatALLDAY
>     > http_access allow time_wastage_sites_ssl TIMEsundALLDAY
>     > http_access deny  time_wastage_sites_ssl
>     >
>
>     In a file called "/etc/squid/tws":
>     .facebook.com <http://facebook.com>
>     .youtube.com <http://youtube.com>
>
>
>     squid.conf:
>      acl time_wastage_sites_ssl  ssl::server_name "/etc/squid/tws"
>      acl time_wastage_sites_http dstdomain        "/etc/squid/tws"
>
>      acl privileged_traffic any-of \
>         privileged-staff privileged-clients \
>         TIMElunch TIMEafterhoursAFT TIMEafterhoursMORN \
>         TIMEsatALLDAY TIMEsundALLDAY
>
>      http_access allow privileged_traffic
>      http_access deny time_wastage_sites_http
>
>      ssl_bump splice privileged_traffic time_wastage_sites_ssl
>      ssl_bump stare all
>      ssl_bump bump all
>
>
>
>     You can probably merge the TIME* ACLs down as well like:
>       # lunch
>       acl okay_times time ...
>       # afterhours PM
>       acl okay_times time ...
>       # afterhours AM
>       acl okay_times time ...
>       # Saturday and Sunday all day
>       acl okay_times time SA
>
>     Amos
>
>
> Quoting Alex:
> "
> If you want Squid to not intrude except when terminating prohibited
traffic, then start with this sketch:
>
> >       ssl_bump terminate prohibited_traffic
> >       ssl_bump peek all
> >       ssl_bump splice all
> "
>
> So is it possible to achieve such a non-intrusive setup, but without
'terminate'?
Not only possible. This is the only solution if you do not want legal
problems. But, of course, you will forgot about high cache hit....
:))))))))))
>
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXGhxQAAoJENNXIZxhPexG+vMH/1BC4CuOMJKp9RYxHcpf/0a+
HsBW3wdCJxCMUI6gq89wCxD9FRq/7gmJIl1vM22l6zZP15JigYrUrosBaD2bjyhk
U+e8daGrOORdnxqajgggKrCOC+pBmkjlmaceU5etteb6QfkHW4sOVTxL9kF8dx1o
0/p1Dvl4LtRynsAloBhK8mr0BMhFFYSLoYipEKSBadK0mckqxAdCIyt1EQiyNAdy
aMRfPMit5KU9JhiK8R28v0c6eSiIyP0cZ7oQG1YL2DmlGOiJ6zwPBmrsDTkb7hRZ
10XPFtzAyRydVI5ca4kN+W2o/pmIc2yUEi0CLX7qUMV88PJjS4Ep7l7+QJF5/SM=
=zxK+
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160422/6a71923d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160422/6a71923d/attachment.key>

From squid3 at treenet.co.nz  Fri Apr 22 14:45:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 23 Apr 2016 02:45:37 +1200
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WNF1O6y03C8mhEE+hfANBER0O2CDWv7jBOdcSY+0C9tOg@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
 <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
 <57195F62.3010209@measurement-factory.com>
 <CAAdA2WN53xFWcSy_HjmwOr7gftKdWSgHRoqYC6U3U3EkWHUSqg@mail.gmail.com>
 <571A00E5.4000309@treenet.co.nz>
 <CAAdA2WNF1O6y03C8mhEE+hfANBER0O2CDWv7jBOdcSY+0C9tOg@mail.gmail.com>
Message-ID: <571A3911.2010001@treenet.co.nz>

On 23/04/2016 12:39 a.m., Odhiambo Washington wrote:
> 
> So is it possible to achieve such a non-intrusive setup, but without
> 'terminate'?

You declared the requirement "Serve an error page.".

That is intrusive.

As Alex has said repeatedly:
  terminate or produce an error. Pick one.

Amos



From jspegal at spegalnetworks.net  Fri Apr 22 15:09:04 2016
From: jspegal at spegalnetworks.net (Jason Spegal)
Date: Fri, 22 Apr 2016 09:09:04 -0600
Subject: [squid-users] Need help with Squid on Windows
Message-ID: <daf6423a-c117-ba4a-cb7a-611c2fe0bdf0@spegalnetworks.net>

Hello all,

I need help with an issue that is now beyond me. I've installed squid 
3.5.16 (From: http://squid.diladele.com/) on my Windows 10 laptop, and 
I'm trying to enable the URL Rewrite helpers that I wrote in perl for my 
linux server. I've already done the necessary adjustments to them to 
make them work on windows. Running them directly seems to be fine, 
however when squid runs them they fail to execute. I've gotten as far as 
finding out perl is executing okay, however the script is not. I am 
unable to figure out how to debug it further. Running squid with full 
debugging (squid.exe -N -X -d 7) did not produce any significant 
information as to why they were not executing. My linux server is 
running squid 3.5.11 and is not having any issues with the helpers. The 
very first thing the helpers do is open a log file and write an 
initialization statement to it. I'm not seeing this when squid tried to 
execute it, so I'm fairly certain it has something to do with the 
execution of the script rather than a problem with the script itself. 
I've also examined the permissions, and those should be good.

Thanks in advance for the help.

--Jason


squid.conf
-------------------------------------------
url_rewrite_program /cygdrive/c/strawberry/perl/bin/perl.exe 
C:\Squid\etc\squid\filtered_sites\squidRed.pl
url_rewrite_children 100 startup=10 idle=1 concurrency=10
url_rewrite_access allow all
url_rewrite_bypass off


Also tried url_rewrite_program 
/cygdrive/c/squid/etc/squid/filtered_sites/squidRed.pl


cache.log
-------------------------------------------
Squid Cache (Version 3.5.16): Terminated abnormally.
CPU Usage: 0.281 seconds = 0.078 user + 0.203 sys
Maximum Resident Size: 1371136 KB
Page faults with physical i/o: 5488
2016/04/22 08:53:06 kid1| Set Current Directory to 
/cygdrive/c/squid/var/cache/squid
2016/04/22 08:53:06 kid1| Starting Squid Cache version 3.5.16 for 
x86_64-unknown-cygwin...
2016/04/22 08:53:06 kid1| Service Name: squid
2016/04/22 08:53:06 kid1| Process ID 10296
2016/04/22 08:53:06 kid1| Process Roles: worker
2016/04/22 08:53:06 kid1| With 256 file descriptors available
2016/04/22 08:53:06 kid1| Initializing IP Cache...
2016/04/22 08:53:06 kid1| parseEtcHosts: /etc/hosts: (2) No such file or 
directory
2016/04/22 08:53:06 kid1| DNS Socket created at [::], FD 5
2016/04/22 08:53:06 kid1| DNS Socket created at 0.0.0.0, FD 6
2016/04/22 08:53:06 kid1| Adding nameserver 10.10.124.1 from squid.conf
2016/04/22 08:53:06 kid1| Adding nameserver 10.10.122.250 from squid.conf
2016/04/22 08:53:06 kid1| Adding nameserver 8.8.8.8 from squid.conf
2016/04/22 08:53:06 kid1| helperOpenServers: Starting 5/32 
'ssl_crtd.exe' processes
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| helperOpenServers: Starting 10/100 'perl.exe' 
processes
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| Logfile: opening log 
daemon:/var/log/squid/access.log
2016/04/22 08:53:06 kid1| Logfile Daemon: opening log 
/var/log/squid/access.log
2016/04/22 08:53:06 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2016/04/22 08:53:06 kid1| Store logging disabled
2016/04/22 08:53:06 kid1| Swap maxSize 2097152 + 131072 KB, estimated 
171401 objects
2016/04/22 08:53:06 kid1| Target number of buckets: 8570
2016/04/22 08:53:06 kid1| Using 16384 Store buckets
2016/04/22 08:53:06 kid1| Max Mem  size: 131072 KB
2016/04/22 08:53:06 kid1| Max Swap size: 2097152 KB
2016/04/22 08:53:06 kid1| Rebuilding storage in /cygdrive/c/squid/cache 
(clean log)
2016/04/22 08:53:06 kid1| Using Least Load store dir selection
2016/04/22 08:53:06 kid1| Set Current Directory to 
/cygdrive/c/squid/var/cache/squid
2016/04/22 08:53:06 kid1| Finished loading MIME types and icons.
2016/04/22 08:53:06 kid1| HTCP Disabled.
2016/04/22 08:53:06 kid1| Configuring Parent 10.10.124.1/3128/3130
2016/04/22 08:53:06 kid1| Configuring Parent 10.10.122.250/3128/3130
2016/04/22 08:53:06 kid1| Squid plugin modules loaded: 0
2016/04/22 08:53:06 kid1| Adaptation support is off.
2016/04/22 08:53:06 kid1| Accepting SSL bumped HTTP Socket connections 
at local=[::]:3128 remote=[::] FD 43 flags=9
2016/04/22 08:53:06 kid1| Done reading /cygdrive/c/squid/cache swaplog 
(98 entries)
2016/04/22 08:53:06 kid1| Finished rebuilding storage from disk.
2016/04/22 08:53:06 kid1|        98 Entries scanned
2016/04/22 08:53:06 kid1|         0 Invalid entries.
2016/04/22 08:53:06 kid1|         0 With invalid flags.
2016/04/22 08:53:06 kid1|        98 Objects loaded.
2016/04/22 08:53:06 kid1|         0 Objects expired.
2016/04/22 08:53:06 kid1|         0 Objects cancelled.
2016/04/22 08:53:06 kid1|         0 Duplicate URLs purged.
2016/04/22 08:53:06 kid1|         0 Swapfile clashes avoided.
2016/04/22 08:53:06 kid1|   Took 0.10 seconds (967.63 objects/sec).
2016/04/22 08:53:06 kid1| Beginning Validation Procedure
2016/04/22 08:53:06 kid1|   Completed Validation Procedure
2016/04/22 08:53:06 kid1|   Validated 98 Entries
2016/04/22 08:53:06 kid1|   store_swap_size = 4280.00 KB
2016/04/22 08:53:06 kid1| WARNING: redirector #Hlpr6 exited
2016/04/22 08:53:06 kid1| Too few redirector processes are running (need 
1/100)
2016/04/22 08:53:06 kid1| Closing HTTP port [::]:3128
2016/04/22 08:53:06 kid1| storeDirWriteCleanLogs: Starting...
2016/04/22 08:53:06 kid1|   Finished.  Wrote 98 entries.
2016/04/22 08:53:06 kid1|   Took 0.00 seconds (58965.10 entries/sec).
FATAL: The redirector helpers are crashing too rapidly, need help!

Squid Cache (Version 3.5.16): Terminated abnormally.
CPU Usage: 0.218 seconds = 0.109 user + 0.109 sys
Maximum Resident Size: 1371648 KB
Page faults with physical i/o: 5489



From frank.trifiletti at developpement-durable.gouv.fr  Fri Apr 22 14:40:59 2016
From: frank.trifiletti at developpement-durable.gouv.fr (FTRIF)
Date: Fri, 22 Apr 2016 07:40:59 -0700 (PDT)
Subject: [squid-users] change between squid 3.1 and 3.3.8
Message-ID: <1461336059437-4677229.post@n4.nabble.com>

Hello,
i have a problem using /usr/lib/squid3/ext_ldap_group_acl which appears in
3.3.8

i have a ldap attribut called InternetAccess which contains the value
"ACCESSINTER"

i want to make an ACL to authorize such people to surf on the net by using a
ldap_group, built with the people who had the value ACCESSINTER in the ldap
attribut called InternetAccess

in command line it works both with squid 3.1 and 3.3.8, the answer is OK:

/usr/lib/squid3/ext_ldap_group_acl -d -b dc=eq,dc=fr -f
"(&(objectclass=person)(InternetAccess=%a)(uid=%u))" myLdapDNSname

fk.tf ACCESSINTER
ext_ldap_group_acl.cc(587): pid=25599 :Connected OK
ext_ldap_group_acl.cc(726): pid=25599 :group filter
'(&(objectclass=person)(InternetAccess=ACCESSINTER)(uid=fk.tf))', searchbase
'dc=eq,dc=fr'
OK

but in the squid.conf v3.3.8, i put the line below  :

external_acl_type ldap_group ipv4 %LOGIN /usr/lib/squid3/ext_ldap_group_acl
-d -b dc=eq,dc=fr -f "(&(objectclass=person)(InternetAccess=%a)(uid=%u))"
myLdapDNSname

it don't work and in my cache.log i found :

779292:2016/04/22 15:56:40.335| external_acl.cc(793) aclMatchExternal:
acl="ldap_group"
779293:2016/04/22 15:56:40.335| external_acl.cc(822) aclMatchExternal: No
helper entry available
779294:2016/04/22 15:56:40.335| external_acl.cc(826) aclMatchExternal:
ldap_group check user authenticated.
779295:2016/04/22 15:56:40.335| external_acl.cc(832) aclMatchExternal:
ldap_group user is authenticated.
779296:2016/04/22 15:56:40.335| external_acl.cc(856) aclMatchExternal:
ldap_group("fk.tf ACCESSINTER") = lookup needed
779297:2016/04/22 15:56:40.335| external_acl.cc(858) aclMatchExternal:
"fk.tf ACCESSINTER": entry=@0, age=0
779298:2016/04/22 15:56:40.335| external_acl.cc(861) aclMatchExternal:
"fk.tf ACCESSINTER": queueing a call.
779299:2016/04/22 15:56:40.335| external_acl.cc(863) aclMatchExternal:
"fk.tf ACCESSINTER": return -1.

It's work in squid 3.1 with the external acl called "squid_ldap_group"
instead of "ext_ldap_group_acl"

perhaps i used something in 3.1 which was a bug corrected in 3.3 ?

Thanks for your help







--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/change-between-squid-3-1-and-3-3-8-tp4677229.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From odhiambo at gmail.com  Fri Apr 22 15:19:27 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Fri, 22 Apr 2016 15:19:27 +0000
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <571A3911.2010001@treenet.co.nz>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
 <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
 <57195F62.3010209@measurement-factory.com>
 <CAAdA2WN53xFWcSy_HjmwOr7gftKdWSgHRoqYC6U3U3EkWHUSqg@mail.gmail.com>
 <571A00E5.4000309@treenet.co.nz>
 <CAAdA2WNF1O6y03C8mhEE+hfANBER0O2CDWv7jBOdcSY+0C9tOg@mail.gmail.com>
 <571A3911.2010001@treenet.co.nz>
Message-ID: <CAAdA2WMwzWLfVicBrE86iQYuu7mCLQYjK5VbK7gf-2wUMMLjWA@mail.gmail.com>

Can I terminate based on time? By just modifying the bits you wrote for me?

On 17:45, Fri, Apr 22, 2016 Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 23/04/2016 12:39 a.m., Odhiambo Washington wrote:
> >
> > So is it possible to achieve such a non-intrusive setup, but without
> > 'terminate'?
>
> You declared the requirement "Serve an error page.".
>
> That is intrusive.
>
> As Alex has said repeatedly:
>   terminate or produce an error. Pick one.
>
> Amos
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160422/a58c04b3/attachment.htm>

From rousskov at measurement-factory.com  Fri Apr 22 18:13:26 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 22 Apr 2016 12:13:26 -0600
Subject: [squid-users] High CPU Usage with ssl_bump
In-Reply-To: <CAAdA2WMwzWLfVicBrE86iQYuu7mCLQYjK5VbK7gf-2wUMMLjWA@mail.gmail.com>
References: <CAAdA2WO3DXka+aR4ZWbcVw=t44iK5uEsh3Mmisiv_kWMO=KGqg@mail.gmail.com>
 <5718DA2B.50504@measurement-factory.com>
 <CAAdA2WPOh8V=cppTb1u900CpAJGQa4=naWsKOkG8Boj67AD=wQ@mail.gmail.com>
 <5719169B.4010700@measurement-factory.com>
 <CAAdA2WPK7V87hVYid595C1G7Kad3+TkpWWhK6sbDKWFbFB+cAQ@mail.gmail.com>
 <57192435.6070807@treenet.co.nz>
 <CAAdA2WONWk-pyVZxZZ8P+PFVVGbFiBxMBhzynvCo9pYkTtfyhQ@mail.gmail.com>
 <57193490.8@measurement-factory.com>
 <CAAdA2WN9FGqQWGMUmzEKEbE=B=qJwuJYH7X4cf1N7v1cLmhDzQ@mail.gmail.com>
 <57195F62.3010209@measurement-factory.com>
 <CAAdA2WN53xFWcSy_HjmwOr7gftKdWSgHRoqYC6U3U3EkWHUSqg@mail.gmail.com>
 <571A00E5.4000309@treenet.co.nz>
 <CAAdA2WNF1O6y03C8mhEE+hfANBER0O2CDWv7jBOdcSY+0C9tOg@mail.gmail.com>
 <571A3911.2010001@treenet.co.nz>
 <CAAdA2WMwzWLfVicBrE86iQYuu7mCLQYjK5VbK7gf-2wUMMLjWA@mail.gmail.com>
Message-ID: <571A69C6.8080802@measurement-factory.com>

On 04/22/2016 09:19 AM, Odhiambo Washington wrote:
> Can I terminate based on time? 

Yes. You can terminate based on any information except information
contained inside HTTP messages. Time is always available.
ssl::server_name will give you an approximation of what you call "site".


> By just modifying the bits you wrote for me?

Technically yes (any configuration can be written "by just modifying
some other configuration"). In practice, the two directions
(splice/terminate versus bump/block) are so different that I recommend
the following approach instead:

1. Study the bits Amos gave you. Do not proceed until you understand
what each line means/does. Ask specific questions if needed. IMHO, if
you cannot complete this step, then you should not subject humans to
SslBump. Without this knowledge, there will be too much suffering, on
all sides.

2. Use the first template I gave you. Add your own rules so that Squid
terminates the connections you want it to terminate and splices
everything else. If you honestly complete step #1 above, then you should
be able to do this too (and, more importantly, you would be able to
troubleshoot deployment problems).

3. Test, deploy, and ask questions/file bug reports as needed.

Alex.



> On 17:45, Fri, Apr 22, 2016 Amos Jeffries wrote:
> 
>     On 23/04/2016 12:39 a.m., Odhiambo Washington wrote:
>     >
>     > So is it possible to achieve such a non-intrusive setup, but without
>     > 'terminate'?
> 
>     You declared the requirement "Serve an error page.".
> 
>     That is intrusive.
> 
>     As Alex has said repeatedly:
>       terminate or produce an error. Pick one.
> 
>     Amos
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From r.ollin at yahoo.com  Fri Apr 22 19:02:10 2016
From: r.ollin at yahoo.com (Zee)
Date: Fri, 22 Apr 2016 19:02:10 +0000 (UTC)
Subject: [squid-users] Squid SSL Bump
References: <1330359101.420588.1461351730784.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1330359101.420588.1461351730784.JavaMail.yahoo@mail.yahoo.com>

I am doing SSL bump it seems like Squid utilizes openssl library. I went ahead and updated openssl library to reflect new CA certificates, but it still fails to work and I see the following error.
"The system returned:
(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)"
Upgraded the library with the following yum install ca-certificates

--> Running transaction check
---> Package ca-certificates.noarch 0:2014.1.98-65.1.el6 will be updated
---> Package ca-certificates.noarch 0:2015.2.6-65.0.1.el6_7 will be an update

But it still fails to work.






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160422/6ec74691/attachment.htm>

From squid3 at treenet.co.nz  Sat Apr 23 03:29:25 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 23 Apr 2016 15:29:25 +1200
Subject: [squid-users] change between squid 3.1 and 3.3.8
In-Reply-To: <1461336059437-4677229.post@n4.nabble.com>
References: <1461336059437-4677229.post@n4.nabble.com>
Message-ID: <571AEC15.70007@treenet.co.nz>

On 23/04/2016 2:40 a.m., FTRIF wrote:
> Hello,
> i have a problem using /usr/lib/squid3/ext_ldap_group_acl which appears in
> 3.3.8
> 
> i have a ldap attribut called InternetAccess which contains the value
> "ACCESSINTER"
> 
> i want to make an ACL to authorize such people to surf on the net by using a
> ldap_group, built with the people who had the value ACCESSINTER in the ldap
> attribut called InternetAccess
> 
> in command line it works both with squid 3.1 and 3.3.8, the answer is OK:
> 
> /usr/lib/squid3/ext_ldap_group_acl -d -b dc=eq,dc=fr -f
> "(&(objectclass=person)(InternetAccess=%a)(uid=%u))" myLdapDNSname
> 
> fk.tf ACCESSINTER
> ext_ldap_group_acl.cc(587): pid=25599 :Connected OK
> ext_ldap_group_acl.cc(726): pid=25599 :group filter
> '(&(objectclass=person)(InternetAccess=ACCESSINTER)(uid=fk.tf))', searchbase
> 'dc=eq,dc=fr'
> OK

Use '%g' macro for group. It will not to collide with URL-encoding of
the parameters.

> 
> but in the squid.conf v3.3.8, i put the line below  :
> 
> external_acl_type ldap_group ipv4 %LOGIN /usr/lib/squid3/ext_ldap_group_acl
> -d -b dc=eq,dc=fr -f "(&(objectclass=person)(InternetAccess=%a)(uid=%u))"
> myLdapDNSname
> 
> it don't work and in my cache.log i found :
> 
<snip>
> 779298:2016/04/22 15:56:40.335| external_acl.cc(861) aclMatchExternal:
> "fk.tf ACCESSINTER": queueing a call.
> 779299:2016/04/22 15:56:40.335| external_acl.cc(863) aclMatchExternal:
> "fk.tf ACCESSINTER": return -1.

That is sending the lookup. Now Squid awaits the helper response.


> 
> It's work in squid 3.1 with the external acl called "squid_ldap_group"
> instead of "ext_ldap_group_acl"
> 
> perhaps i used something in 3.1 which was a bug corrected in 3.3 ?
> 

There is no sign of any problem in that log snippet. Can you find the
followup where the helper responds?

Amos



From squid3 at treenet.co.nz  Sat Apr 23 03:41:31 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 23 Apr 2016 15:41:31 +1200
Subject: [squid-users] Need help with Squid on Windows
In-Reply-To: <daf6423a-c117-ba4a-cb7a-611c2fe0bdf0@spegalnetworks.net>
References: <daf6423a-c117-ba4a-cb7a-611c2fe0bdf0@spegalnetworks.net>
Message-ID: <571AEEEB.9010108@treenet.co.nz>

On 23/04/2016 3:09 a.m., Jason Spegal wrote:
> Hello all,
> 
> I need help with an issue that is now beyond me. I've installed squid
> 3.5.16 (From: http://squid.diladele.com/) on my Windows 10 laptop, and
> I'm trying to enable the URL Rewrite helpers that I wrote in perl for my
> linux server. I've already done the necessary adjustments to them to
> make them work on windows. Running them directly seems to be fine,
> however when squid runs them they fail to execute. I've gotten as far as
> finding out perl is executing okay, however the script is not. I am
> unable to figure out how to debug it further. Running squid with full
> debugging (squid.exe -N -X -d 7) did not produce any significant
> information as to why they were not executing.

You usually need to enable debugging in the helper itself to get that.
Squid only knows that the helper died on startup.


> My linux server is
> running squid 3.5.11 and is not having any issues with the helpers. The
> very first thing the helpers do is open a log file and write an
> initialization statement to it. I'm not seeing this when squid tried to
> execute it, so I'm fairly certain it has something to do with the
> execution of the script rather than a problem with the script itself.
> I've also examined the permissions, and those should be good.
> 

FWIW: Nothing has changed inside Squid for helpers between those two
releases.


> Thanks in advance for the help.
> 
> --Jason
> 
> 
> squid.conf
> -------------------------------------------
> url_rewrite_program /cygdrive/c/strawberry/perl/bin/perl.exe
> C:\Squid\etc\squid\filtered_sites\squidRed.pl
> url_rewrite_children 100 startup=10 idle=1 concurrency=10
> url_rewrite_access allow all
> url_rewrite_bypass off
> 
> 
> Also tried url_rewrite_program
> /cygdrive/c/squid/etc/squid/filtered_sites/squidRed.pl
> 
> 
> cache.log
> -------------------------------------------
> Squid Cache (Version 3.5.16): Terminated abnormally.

Maybe something left over from this previous aborted Squid instance and
its helpers that kills the next one to start?

> CPU Usage: 0.281 seconds = 0.078 user + 0.203 sys
> Maximum Resident Size: 1371136 KB
> Page faults with physical i/o: 5488
> 2016/04/22 08:53:06 kid1| Set Current Directory to
> /cygdrive/c/squid/var/cache/squid
> 2016/04/22 08:53:06 kid1| Starting Squid Cache version 3.5.16 for
> x86_64-unknown-cygwin...
...
> 2016/04/22 08:53:06 kid1| helperOpenServers: Starting 10/100 'perl.exe'
> processes
...
> 2016/04/22 08:53:06 kid1| WARNING: redirector #Hlpr6 exited
...
> 2016/04/22 08:53:06 kid1| Too few redirector processes are running (need
> 1/100)
...
> FATAL: The redirector helpers are crashing too rapidly, need help!

Note that it is only the 6th helper that dies. The first 5 seem to be
okay at this point.

Maybe something they share which has a limited connection count?

Amos



From squid3 at treenet.co.nz  Sat Apr 23 03:51:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 23 Apr 2016 15:51:07 +1200
Subject: [squid-users] Squid SSL Bump
In-Reply-To: <1330359101.420588.1461351730784.JavaMail.yahoo@mail.yahoo.com>
References: <1330359101.420588.1461351730784.JavaMail.yahoo.ref@mail.yahoo.com>
 <1330359101.420588.1461351730784.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <571AF12B.9000003@treenet.co.nz>

On 23/04/2016 7:02 a.m., Zee wrote:
> I am doing SSL bump it seems like Squid utilizes openssl library. I went ahead and updated openssl library to reflect new CA certificates, but it still fails to work and I see the following error.
> "The system returned:
> (71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)"
> Upgraded the library with the following yum install ca-certificates
> 
> --> Running transaction check
> ---> Package ca-certificates.noarch 0:2014.1.98-65.1.el6 will be updated
> ---> Package ca-certificates.noarch 0:2015.2.6-65.0.1.el6_7 will be an update
> 

The date in that package name (Feb 2015) seems to still be very old. IME
the global CA certs list changes every month or two. Particularly in the
past year when all CA have been rolling over to 2048 or 4096 bit crypto.

> But it still fails to work.
> 

Squid version?
 The latest 4.0.9 (beta) and 3.5.17 releases contain several bug fixes
to intermediate cert handling that might show up like this.


What CA certificate can't be found?
 If needed you can always workaround it by loading the CA cert into
Squid explicitly.

Amos



From squid3 at treenet.co.nz  Sat Apr 23 04:24:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 23 Apr 2016 16:24:35 +1200
Subject: [squid-users] Squid-4.0.9 and FreeBSD 9.3 / FreeBSD-10.3
In-Reply-To: <CAAdA2WMGkHxW22tTz1r7GFTQxMuND-4VZuBHXUbBZopZ-NSG6g@mail.gmail.com>
References: <CAAdA2WOMbjm64pDo3vdjEgSqNY7xCFro3FKbQA9=9iMFF1dS2A@mail.gmail.com>
 <57192180.50602@treenet.co.nz>
 <CAAdA2WMGkHxW22tTz1r7GFTQxMuND-4VZuBHXUbBZopZ-NSG6g@mail.gmail.com>
Message-ID: <571AF903.1020300@treenet.co.nz>

On 22/04/2016 8:03 a.m., Odhiambo Washington wrote:
> On 21 April 2016 at 21:52, Amos Jeffries wrote:
> 
>> On 22/04/2016 6:12 a.m., Odhiambo Washington wrote:
>>> Hi Amos,
>>>
>>> I have just now succeeded in compiling squid-4.0.9 on FreeBSD 10.3 and
>> I'm
>>> even able to run it.
>>> The server I am testing on serves about 20 users. It's been successfully
>>> running 3.5.x (upgraded to 3.5.17 today).
>>>
>>> On my other server that is FreeBSD-9.3 (the one I upgraded recently from
>>> 8.4) I still get stuck at a point, but hopefully someone could help me
>> out:
>>>
>>> [wash at gw ~/Tools/Squid/4.x/squid-4.0.9]$ make
>>
>>
>>> libtool: compile:  clang++ -DHAVE_CONFIG_H -I.. -I../include -I../lib
>>> -I../src -I../include -I/usr/local/include -I../libltdl -I/usr/include
>>> -I/usr/local/include/libxml2 -I/usr/local/include
>>> -I/usr/local/include/libxml2 -Werror -Qunused-arguments
>>> -Wno-deprecated-register -D_REENTRANT -I/usr/local/include -g -O2
>>> -march=native -std=c++11 -I/usr/local/include -MT assert.lo -MD -MP -MF
>>> .deps/assert.Tpo -c assert.cc  -fPIC -DPIC -o .libs/assert.o
>>> In file included from assert.cc:9:
>>> In file included from ../include/squid.h:43:
>>> In file included from ../compat/compat.h:70:
>>> ../compat/types.h:62:10: fatal error: 'cstdint' file not found
>>> #include <cstdint>
>>>          ^
>>
>> This is one of the standard library files. It is required to be present
>> in C++11 compiler systems. So our configure is not testing for it.
>>
>> It would seem clang is not finding the correct C++11 stdlib headers. I
>> assume you know how and where to check for those?
>>
> 
> Heheeee... I wouldn't lie that I know. How do I go about it??
> 

Try command line "locate cstdint".
If that dont work then its a manual search through the directories.

On our FreeBSD 9.3 build node it is:
 /usr/include/c++/4.2/tr1/cstdint
 /usr/local/include/c++/v1/c++/v1/cstdint
 /usr/local/include/c++/v1/cstdint
 /usr/local/lib/gcc49/include/c++/cstdint
 /usr/local/lib/gcc49/include/c++/tr1/cstdint

Amos



From squid3 at treenet.co.nz  Sat Apr 23 04:31:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 23 Apr 2016 16:31:26 +1200
Subject: [squid-users] Squid-4.0.9 and FreeBSD 9.3 / FreeBSD-10.3
In-Reply-To: <571AF903.1020300@treenet.co.nz>
References: <CAAdA2WOMbjm64pDo3vdjEgSqNY7xCFro3FKbQA9=9iMFF1dS2A@mail.gmail.com>
 <57192180.50602@treenet.co.nz>
 <CAAdA2WMGkHxW22tTz1r7GFTQxMuND-4VZuBHXUbBZopZ-NSG6g@mail.gmail.com>
 <571AF903.1020300@treenet.co.nz>
Message-ID: <571AFA9E.5070803@treenet.co.nz>

On 23/04/2016 4:24 p.m., Amos Jeffries wrote:
> On 22/04/2016 8:03 a.m., Odhiambo Washington wrote:
>> On 21 April 2016 at 21:52, Amos Jeffries wrote:
>>
>>> On 22/04/2016 6:12 a.m., Odhiambo Washington wrote:
>>>> Hi Amos,
>>>>
>>>> I have just now succeeded in compiling squid-4.0.9 on FreeBSD 10.3 and
>>> I'm
>>>> even able to run it.
>>>> The server I am testing on serves about 20 users. It's been successfully
>>>> running 3.5.x (upgraded to 3.5.17 today).
>>>>
>>>> On my other server that is FreeBSD-9.3 (the one I upgraded recently from
>>>> 8.4) I still get stuck at a point, but hopefully someone could help me
>>> out:
>>>>
>>>> [wash at gw ~/Tools/Squid/4.x/squid-4.0.9]$ make
>>>
>>>
>>>> libtool: compile:  clang++ -DHAVE_CONFIG_H -I.. -I../include -I../lib
>>>> -I../src -I../include -I/usr/local/include -I../libltdl -I/usr/include
>>>> -I/usr/local/include/libxml2 -I/usr/local/include
>>>> -I/usr/local/include/libxml2 -Werror -Qunused-arguments
>>>> -Wno-deprecated-register -D_REENTRANT -I/usr/local/include -g -O2
>>>> -march=native -std=c++11 -I/usr/local/include -MT assert.lo -MD -MP -MF
>>>> .deps/assert.Tpo -c assert.cc  -fPIC -DPIC -o .libs/assert.o
>>>> In file included from assert.cc:9:
>>>> In file included from ../include/squid.h:43:
>>>> In file included from ../compat/compat.h:70:
>>>> ../compat/types.h:62:10: fatal error: 'cstdint' file not found
>>>> #include <cstdint>
>>>>          ^
>>>
>>> This is one of the standard library files. It is required to be present
>>> in C++11 compiler systems. So our configure is not testing for it.
>>>
>>> It would seem clang is not finding the correct C++11 stdlib headers. I
>>> assume you know how and where to check for those?
>>>
>>
>> Heheeee... I wouldn't lie that I know. How do I go about it??
>>
> 
> Try command line "locate cstdint".
> If that dont work then its a manual search through the directories.
> 
> On our FreeBSD 9.3 build node it is:
>  /usr/include/c++/4.2/tr1/cstdint
>  /usr/local/include/c++/v1/c++/v1/cstdint
>  /usr/local/include/c++/v1/cstdint
>  /usr/local/lib/gcc49/include/c++/cstdint
>  /usr/local/lib/gcc49/include/c++/tr1/cstdint
> 

Which was setup with these instructions:
 <http://wiki.squid-cache.org/BuildFarm/FreeBsdInstall>

Amos



From jason_haar at trimble.com  Sat Apr 23 10:08:31 2016
From: jason_haar at trimble.com (Jason Haar)
Date: Sat, 23 Apr 2016 22:08:31 +1200
Subject: [squid-users] Browser circunvents acl's blocking https
	(intercept mode)
In-Reply-To: <57135340.5080503@treenet.co.nz>
References: <CABZC=5yTw0v=ec4=TvwrqZ3NegRdTwjkxg7DoeVMJFHvjULWMA@mail.gmail.com>
 <70483071-2612-49EC-8994-21C6F35D9170@spikes.com>
 <57135340.5080503@treenet.co.nz>
Message-ID: <CAFChrgK-uy3nF64FiojEeAavtTevkcAVvgJOiwKpg4EUYz+aFg@mail.gmail.com>

On Sun, Apr 17, 2016 at 9:11 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> Like Jok mentioned Chrome is probably using QUIC protocol or one of the
> other non-HTTPS is uses.
>


Other non-HTTPS? Can you expand on that? I'm aware of QUIC (udp/443) and
ensure our firewalls block it so as to force it to tcp/443 - but you're
implying there are yet more alternatives?

-- 
Cheers

Jason Haar
Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/b3f8ad4e/attachment.htm>

From squid3 at treenet.co.nz  Sat Apr 23 11:59:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 23 Apr 2016 23:59:16 +1200
Subject: [squid-users] Browser circunvents acl's blocking https
 (intercept mode)
In-Reply-To: <CAFChrgK-uy3nF64FiojEeAavtTevkcAVvgJOiwKpg4EUYz+aFg@mail.gmail.com>
References: <CABZC=5yTw0v=ec4=TvwrqZ3NegRdTwjkxg7DoeVMJFHvjULWMA@mail.gmail.com>
 <70483071-2612-49EC-8994-21C6F35D9170@spikes.com>
 <57135340.5080503@treenet.co.nz>
 <CAFChrgK-uy3nF64FiojEeAavtTevkcAVvgJOiwKpg4EUYz+aFg@mail.gmail.com>
Message-ID: <571B6394.3000007@treenet.co.nz>

On 23/04/2016 10:08 p.m., Jason Haar wrote:
> On Sun, Apr 17, 2016 at 9:11 PM, Amos Jeffries wrote:
> 
>> Like Jok mentioned Chrome is probably using QUIC protocol or one of the
>> other non-HTTPS is uses.
>>
> 
> 
> Other non-HTTPS? Can you expand on that? I'm aware of QUIC (udp/443) and
> ensure our firewalls block it so as to force it to tcp/443 - but you're
> implying there are yet more alternatives?

There are a couple of versions of SPDY and WebSockets at least. They
tend to announce these things a year or so after its been up and
running, so there may be others I've not heard of yet.

Amos



From rafael.akchurin at diladele.com  Sat Apr 23 12:26:59 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 23 Apr 2016 12:26:59 +0000
Subject: [squid-users] Need help with Squid on Windows
In-Reply-To: <571AEEEB.9010108@treenet.co.nz>
References: <daf6423a-c117-ba4a-cb7a-611c2fe0bdf0@spegalnetworks.net>
 <571AEEEB.9010108@treenet.co.nz>
Message-ID: <VI1PR04MB135930DB77E62C7DA7B178738F600@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Jason, Amos, all,

Possibly the issue can be related to Squid being compiled with Cygwin https://cygwin.com/ml/cygwin/2012-03/msg00302.html, I'm not sure whether this issue with standard output has been fixed in the current Cygwin.

One of the workarounds that could possibly work is to install Cygwin and build squid yourself as described here: http://docs.diladele.com/tutorials/build_squid_windows/index.html, this should start helpers from Cygwin terminal instead of cmd.

Best regards,
Rafael Akchurin
Diladele B.V. 
http://www.quintolabs.com 
http://www.diladele.com 

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com.



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Saturday, April 23, 2016 5:42 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Need help with Squid on Windows

On 23/04/2016 3:09 a.m., Jason Spegal wrote:
> Hello all,
> 
> I need help with an issue that is now beyond me. I've installed squid
> 3.5.16 (From: http://squid.diladele.com/) on my Windows 10 laptop, and 
> I'm trying to enable the URL Rewrite helpers that I wrote in perl for 
> my linux server. I've already done the necessary adjustments to them 
> to make them work on windows. Running them directly seems to be fine, 
> however when squid runs them they fail to execute. I've gotten as far 
> as finding out perl is executing okay, however the script is not. I am 
> unable to figure out how to debug it further. Running squid with full 
> debugging (squid.exe -N -X -d 7) did not produce any significant 
> information as to why they were not executing.

You usually need to enable debugging in the helper itself to get that.
Squid only knows that the helper died on startup.


> My linux server is
> running squid 3.5.11 and is not having any issues with the helpers. 
> The very first thing the helpers do is open a log file and write an 
> initialization statement to it. I'm not seeing this when squid tried 
> to execute it, so I'm fairly certain it has something to do with the 
> execution of the script rather than a problem with the script itself.
> I've also examined the permissions, and those should be good.
> 

FWIW: Nothing has changed inside Squid for helpers between those two releases.


> Thanks in advance for the help.
> 
> --Jason
> 
> 
> squid.conf
> -------------------------------------------
> url_rewrite_program /cygdrive/c/strawberry/perl/bin/perl.exe
> C:\Squid\etc\squid\filtered_sites\squidRed.pl
> url_rewrite_children 100 startup=10 idle=1 concurrency=10 
> url_rewrite_access allow all url_rewrite_bypass off
> 
> 
> Also tried url_rewrite_program
> /cygdrive/c/squid/etc/squid/filtered_sites/squidRed.pl
> 
> 
> cache.log
> -------------------------------------------
> Squid Cache (Version 3.5.16): Terminated abnormally.

Maybe something left over from this previous aborted Squid instance and its helpers that kills the next one to start?

> CPU Usage: 0.281 seconds = 0.078 user + 0.203 sys Maximum Resident 
> Size: 1371136 KB Page faults with physical i/o: 5488
> 2016/04/22 08:53:06 kid1| Set Current Directory to 
> /cygdrive/c/squid/var/cache/squid
> 2016/04/22 08:53:06 kid1| Starting Squid Cache version 3.5.16 for 
> x86_64-unknown-cygwin...
...
> 2016/04/22 08:53:06 kid1| helperOpenServers: Starting 10/100 'perl.exe'
> processes
...
> 2016/04/22 08:53:06 kid1| WARNING: redirector #Hlpr6 exited
...
> 2016/04/22 08:53:06 kid1| Too few redirector processes are running 
> (need
> 1/100)
...
> FATAL: The redirector helpers are crashing too rapidly, need help!

Note that it is only the 6th helper that dies. The first 5 seem to be okay at this point.

Maybe something they share which has a limited connection count?

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From yvoinov at gmail.com  Sat Apr 23 14:57:29 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 23 Apr 2016 20:57:29 +0600
Subject: [squid-users] Need help with Squid on Windows
In-Reply-To: <VI1PR04MB135930DB77E62C7DA7B178738F600@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <daf6423a-c117-ba4a-cb7a-611c2fe0bdf0@spegalnetworks.net>
 <571AEEEB.9010108@treenet.co.nz>
 <VI1PR04MB135930DB77E62C7DA7B178738F600@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <7ad96d93-0bba-bb08-1278-e03934528a05@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Raf,

I can confirm - perl helpers (I've tried to use store-ID with Active
Perl) does not work with Win version of Squid. I've tried to configure
it several times. Without success. With the same symptoms.

WBR, Yuri

23.04.16 18:26, Rafael Akchurin ?????:
> Hello Jason, Amos, all,
>
> Possibly the issue can be related to Squid being compiled with Cygwin
https://cygwin.com/ml/cygwin/2012-03/msg00302.html, I'm not sure whether
this issue with standard output has been fixed in the current Cygwin.
>
> One of the workarounds that could possibly work is to install Cygwin
and build squid yourself as described here:
http://docs.diladele.com/tutorials/build_squid_windows/index.html, this
should start helpers from Cygwin terminal instead of cmd.
>
> Best regards,
> Rafael Akchurin
> Diladele B.V.
> http://www.quintolabs.com
> http://www.diladele.com
>
> --
> Please take a look at Web Safety - our ICAP based web filter server
for Squid proxy at http://www.diladele.com.
>
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of Amos Jeffries
> Sent: Saturday, April 23, 2016 5:42 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Need help with Squid on Windows
>
> On 23/04/2016 3:09 a.m., Jason Spegal wrote:
>> Hello all,
>>
>> I need help with an issue that is now beyond me. I've installed squid
>> 3.5.16 (From: http://squid.diladele.com/) on my Windows 10 laptop, and
>> I'm trying to enable the URL Rewrite helpers that I wrote in perl for
>> my linux server. I've already done the necessary adjustments to them
>> to make them work on windows. Running them directly seems to be fine,
>> however when squid runs them they fail to execute. I've gotten as far
>> as finding out perl is executing okay, however the script is not. I am
>> unable to figure out how to debug it further. Running squid with full
>> debugging (squid.exe -N -X -d 7) did not produce any significant
>> information as to why they were not executing.
>
> You usually need to enable debugging in the helper itself to get that.
> Squid only knows that the helper died on startup.
>
>
>> My linux server is
>> running squid 3.5.11 and is not having any issues with the helpers.
>> The very first thing the helpers do is open a log file and write an
>> initialization statement to it. I'm not seeing this when squid tried
>> to execute it, so I'm fairly certain it has something to do with the
>> execution of the script rather than a problem with the script itself.
>> I've also examined the permissions, and those should be good.
>>
>
> FWIW: Nothing has changed inside Squid for helpers between those two
releases.
>
>
>> Thanks in advance for the help.
>>
>> --Jason
>>
>>
>> squid.conf
>> -------------------------------------------
>> url_rewrite_program /cygdrive/c/strawberry/perl/bin/perl.exe
>> C:\Squid\etc\squid\filtered_sites\squidRed.pl
>> url_rewrite_children 100 startup=10 idle=1 concurrency=10
>> url_rewrite_access allow all url_rewrite_bypass off
>>
>>
>> Also tried url_rewrite_program
>> /cygdrive/c/squid/etc/squid/filtered_sites/squidRed.pl
>>
>>
>> cache.log
>> -------------------------------------------
>> Squid Cache (Version 3.5.16): Terminated abnormally.
>
> Maybe something left over from this previous aborted Squid instance
and its helpers that kills the next one to start?
>
>> CPU Usage: 0.281 seconds = 0.078 user + 0.203 sys Maximum Resident
>> Size: 1371136 KB Page faults with physical i/o: 5488
>> 2016/04/22 08:53:06 kid1| Set Current Directory to
>> /cygdrive/c/squid/var/cache/squid
>> 2016/04/22 08:53:06 kid1| Starting Squid Cache version 3.5.16 for
>> x86_64-unknown-cygwin...
> ...
>> 2016/04/22 08:53:06 kid1| helperOpenServers: Starting 10/100 'perl.exe'
>> processes
> ...
>> 2016/04/22 08:53:06 kid1| WARNING: redirector #Hlpr6 exited
> ...
>> 2016/04/22 08:53:06 kid1| Too few redirector processes are running
>> (need
>> 1/100)
> ...
>> FATAL: The redirector helpers are crashing too rapidly, need help!
>
> Note that it is only the 6th helper that dies. The first 5 seem to be
okay at this point.
>
> Maybe something they share which has a limited connection count?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG41ZAAoJENNXIZxhPexGDnkIAJZaoZXnT2HGdkBbKmd+ztD/
/gEMwmk7IL7WJkiHbfRMiEaJWLlhgb1mnpXOHsviO6zC5DbAWBQhwNu20nevjL0v
DJaz65tqIo3je2k9oKY/MyySdFcP1Ezuv4gcmJH5KnxdH2GPTNo4HbxRmHKfotUM
ZaybRw2EaAxkfkzaFpc84gsbERPa/tiPViAmOPj29lf/PUTofeGsyTH4pfe0sJeF
6B5YqCULu41R0QzYatxh+B9iHrF4gZn922EDsp3A45SDdlAJxvjMlCCnuNudFAXA
NWXGiQcVV88FdFR9pBpcDtzrfezlcGeoyd8lIO61iLJjbfcD9pwbKoc42WspOho=
=wKrJ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/240d0e0a/attachment.key>

From rafael.akchurin at diladele.com  Sat Apr 23 16:19:37 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 23 Apr 2016 16:19:37 +0000
Subject: [squid-users] Need help with Squid on Windows
In-Reply-To: <7ad96d93-0bba-bb08-1278-e03934528a05@gmail.com>
References: <daf6423a-c117-ba4a-cb7a-611c2fe0bdf0@spegalnetworks.net>
 <571AEEEB.9010108@treenet.co.nz>
 <VI1PR04MB135930DB77E62C7DA7B178738F600@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <7ad96d93-0bba-bb08-1278-e03934528a05@gmail.com>
Message-ID: <VI1PR04MB135927BC6C47873EE18FF5CC8F600@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Yuri and all,

I would then try the process monitor that will most probably give an answer why the perl exe helper does not start. 

Best regards,
Rafael

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Saturday, April 23, 2016 4:57 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Need help with Squid on Windows


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Raf,

I can confirm - perl helpers (I've tried to use store-ID with Active
Perl) does not work with Win version of Squid. I've tried to configure it several times. Without success. With the same symptoms.

WBR, Yuri

23.04.16 18:26, Rafael Akchurin ?????:
> Hello Jason, Amos, all,
>
> Possibly the issue can be related to Squid being compiled with Cygwin
https://cygwin.com/ml/cygwin/2012-03/msg00302.html, I'm not sure whether this issue with standard output has been fixed in the current Cygwin.
>
> One of the workarounds that could possibly work is to install Cygwin
and build squid yourself as described here:
http://docs.diladele.com/tutorials/build_squid_windows/index.html, this should start helpers from Cygwin terminal instead of cmd.
>
> Best regards,
> Rafael Akchurin
> Diladele B.V.
> http://www.quintolabs.com
> http://www.diladele.com
>
> --
> Please take a look at Web Safety - our ICAP based web filter server
for Squid proxy at http://www.diladele.com.
>
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of Amos Jeffries
> Sent: Saturday, April 23, 2016 5:42 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Need help with Squid on Windows
>
> On 23/04/2016 3:09 a.m., Jason Spegal wrote:
>> Hello all,
>>
>> I need help with an issue that is now beyond me. I've installed squid
>> 3.5.16 (From: http://squid.diladele.com/) on my Windows 10 laptop, 
>> and I'm trying to enable the URL Rewrite helpers that I wrote in perl 
>> for my linux server. I've already done the necessary adjustments to 
>> them to make them work on windows. Running them directly seems to be 
>> fine, however when squid runs them they fail to execute. I've gotten 
>> as far as finding out perl is executing okay, however the script is 
>> not. I am unable to figure out how to debug it further. Running squid 
>> with full debugging (squid.exe -N -X -d 7) did not produce any 
>> significant information as to why they were not executing.
>
> You usually need to enable debugging in the helper itself to get that.
> Squid only knows that the helper died on startup.
>
>
>> My linux server is
>> running squid 3.5.11 and is not having any issues with the helpers.
>> The very first thing the helpers do is open a log file and write an 
>> initialization statement to it. I'm not seeing this when squid tried 
>> to execute it, so I'm fairly certain it has something to do with the 
>> execution of the script rather than a problem with the script itself.
>> I've also examined the permissions, and those should be good.
>>
>
> FWIW: Nothing has changed inside Squid for helpers between those two
releases.
>
>
>> Thanks in advance for the help.
>>
>> --Jason
>>
>>
>> squid.conf
>> -------------------------------------------
>> url_rewrite_program /cygdrive/c/strawberry/perl/bin/perl.exe
>> C:\Squid\etc\squid\filtered_sites\squidRed.pl
>> url_rewrite_children 100 startup=10 idle=1 concurrency=10 
>> url_rewrite_access allow all url_rewrite_bypass off
>>
>>
>> Also tried url_rewrite_program
>> /cygdrive/c/squid/etc/squid/filtered_sites/squidRed.pl
>>
>>
>> cache.log
>> -------------------------------------------
>> Squid Cache (Version 3.5.16): Terminated abnormally.
>
> Maybe something left over from this previous aborted Squid instance
and its helpers that kills the next one to start?
>
>> CPU Usage: 0.281 seconds = 0.078 user + 0.203 sys Maximum Resident
>> Size: 1371136 KB Page faults with physical i/o: 5488
>> 2016/04/22 08:53:06 kid1| Set Current Directory to 
>> /cygdrive/c/squid/var/cache/squid
>> 2016/04/22 08:53:06 kid1| Starting Squid Cache version 3.5.16 for 
>> x86_64-unknown-cygwin...
> ...
>> 2016/04/22 08:53:06 kid1| helperOpenServers: Starting 10/100 'perl.exe'
>> processes
> ...
>> 2016/04/22 08:53:06 kid1| WARNING: redirector #Hlpr6 exited
> ...
>> 2016/04/22 08:53:06 kid1| Too few redirector processes are running 
>> (need
>> 1/100)
> ...
>> FATAL: The redirector helpers are crashing too rapidly, need help!
>
> Note that it is only the 6th helper that dies. The first 5 seem to be
okay at this point.
>
> Maybe something they share which has a limited connection count?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG41ZAAoJENNXIZxhPexGDnkIAJZaoZXnT2HGdkBbKmd+ztD/
/gEMwmk7IL7WJkiHbfRMiEaJWLlhgb1mnpXOHsviO6zC5DbAWBQhwNu20nevjL0v
DJaz65tqIo3je2k9oKY/MyySdFcP1Ezuv4gcmJH5KnxdH2GPTNo4HbxRmHKfotUM
ZaybRw2EaAxkfkzaFpc84gsbERPa/tiPViAmOPj29lf/PUTofeGsyTH4pfe0sJeF
6B5YqCULu41R0QzYatxh+B9iHrF4gZn922EDsp3A45SDdlAJxvjMlCCnuNudFAXA
NWXGiQcVV88FdFR9pBpcDtzrfezlcGeoyd8lIO61iLJjbfcD9pwbKoc42WspOho=
=wKrJ
-----END PGP SIGNATURE-----


From rafael.akchurin at diladele.com  Sat Apr 23 16:48:38 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 23 Apr 2016 16:48:38 +0000
Subject: [squid-users] Squid 3.5.17 for Microsoft Windows 64-bit is available
Message-ID: <VI1PR04MB1359E0AC6D60C4C87A20FD728F600@VI1PR04MB1359.eurprd04.prod.outlook.com>

Greetings everyone,



The CygWin based build of Squid proxy for Microsoft Windows version 3.5.17 is now available (amd64 only!).



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.17-RELEASENOTES.html.

* Ready to use MSI package can be downloaded from http://squid.diladele.com.

* List of open issues for the installer - https://github.com/diladele/squid3-windows/issues



Thanks a lot for Squid developers for making this great software!



Please join our humble efforts to provide ready to run MSI installer for Squid on Microsoft Windows with all required dependencies at GitHub -

https://github.com/diladele/squid3-windows. Please report all issues/bugs/feature requests at GitHub project. Issues about the *MSI installer only* can also be reported to support at diladele.com<mailto:support at diladele.com>.





NOTE: the 3.5.17 version of Squid for Ubuntu 14.04 LTS will be also available today (or tomorrow). The repo is at http://ubuntu.diladele.com. This version is recompiled using Squid DEB source from Debian Testing with some changes required to support SSL bump / libecap3 on Ubuntu 14.04 LTS. See repo with all the scripts at https://github.com/diladele/squid-ubuntu .



NOTE: for those who are interested in Docker - we plan to make Squid available as Docker container (including our ICAP web filter). You can track the progress at https://github.com/diladele/docker-cluster (clustered version) or https://github.com/diladele/docker-websafety (non clustered version when everything runs in one container).



Best regards,

Rafael Akchurin

Diladele B.V.

http://www.quintolabs.com

http://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/458c5fc6/attachment.htm>

From tom at kudude.com  Sat Apr 23 17:08:07 2016
From: tom at kudude.com (Tom Ku)
Date: Sat, 23 Apr 2016 13:08:07 -0400
Subject: [squid-users] Using Squid with 1 NIC
Message-ID: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>

Hi All,

I know this question has been beaten to death but I can't seem to find any
answers via google.  So i'm trying to set up a Squid proxy for my VMware
infrastructure.  I have multiple port groups networks and I plan to put a
Squid server in each port group to monitor network/internet traffic.  So I
would like my setup like this:

192.168.1.1 - Gateway
^
l
l
l
Squid Proxy - 192.168.1.2)
^
l
l
l
VMs (clients - 192.168.1.x/24)

Now i can only have 1 NIC on the Squid server.  I've read that iptables
will probably have to be configured.  Any help would be appreciated.

Thanks,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/9f64b36d/attachment.htm>

From yvoinov at gmail.com  Sat Apr 23 17:12:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 23 Apr 2016 23:12:56 +0600
Subject: [squid-users] Using Squid with 1 NIC
In-Reply-To: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>
References: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>
Message-ID: <f2406748-c8c2-cc60-b804-e9dfb4d4ca2a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://wiki.squid-cache.org/ConfigExamples/Intercept


23.04.16 23:08, Tom Ku ?????:
> Hi All,
>
> I know this question has been beaten to death but I can't seem to find
any answers via google.  So i'm trying to set up a Squid proxy for my
VMware infrastructure.  I have multiple port groups networks and I plan
to put a Squid server in each port group to monitor network/internet
traffic.  So I would like my setup like this:
>
> 192.168.1.1 - Gateway
> ^
> l
> l
> l
> Squid Proxy - 192.168.1.2)
> ^
> l
> l
> l
> VMs (clients - 192.168.1.x/24)
>
> Now i can only have 1 NIC on the Squid server.  I've read that
iptables will probably have to be configured.  Any help would be
appreciated.
>
> Thanks,
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG60YAAoJENNXIZxhPexG+poH/0XSOu2UZ7MCG+2Xf58mn20w
nWHxz3PVaH0DmQehjqkzRQjg3OqqG88UL36vP9nySwL9h2P4VKteMTPlO3eJom6i
8Cj+K13AEsri69Xnd1aOkPh1HPC5R3WrHk4Whog9UNTgeOheMmY7sO3qz8PpWv8r
bK4KmDHWgLQrdyQY9Aw2Q/nd5tps1ibLJAWPYxlBxFKSeruTZJRysdkwDf8zhEZk
AQJGfocFm8PsJBKohOcoUiG1y3QYGJa489l5VyhBsHbb1EjvgXZ43MrgEAuYARXW
jMxB6/2rO8WKlTFMP9d8lLLeWAAJjPhNkn20UEWRJ8YMIjFJze5NfNvD+EowxwA=
=9Bpt
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/67103cba/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/67103cba/attachment.key>

From Antony.Stone at squid.open.source.it  Sat Apr 23 17:46:40 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 23 Apr 2016 19:46:40 +0200
Subject: [squid-users] Using Squid with 1 NIC
In-Reply-To: <f2406748-c8c2-cc60-b804-e9dfb4d4ca2a@gmail.com>
References: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>
 <f2406748-c8c2-cc60-b804-e9dfb4d4ca2a@gmail.com>
Message-ID: <201604231946.40422.Antony.Stone@squid.open.source.it>

On Saturday 23 April 2016 at 19:12:56, Yuri Voinov wrote:

> http://wiki.squid-cache.org/ConfigExamples/Intercept

Surely there's no reason to have to set up intercept mode (unless the OP can't 
configure the applications to use an explicit proxy)?

I'm assuming the gateway 192.168.1.1 does outbound NAT to the Internet 
(otherwise nothing would work), so all that's needed is to set up Squid on 
192.168.1.2 to allow access from 192.168.1.0/24, with a default gateway of 
192.168.1.1, and then configure each of the 192.168.1.x client machines to use 
192.168.1.2:3128 as their proxy server?

> 23.04.16 23:08, Tom Ku ?????:
> > Hi All,
> > 
> > I know this question has been beaten to death but I can't seem to find
> > any answers via google.  So i'm trying to set up a Squid proxy for my
> > VMware infrastructure.  I have multiple port groups networks and I plan
> > to put a Squid server in each port group to monitor network/internet
> > traffic.  So I would like my setup like this:
> >
> > 192.168.1.1 - Gateway
> > ^
> > l
> > l
> > l
> > Squid Proxy - 192.168.1.2)
> > ^
> > l
> > l
> > l
> > VMs (clients - 192.168.1.x/24)
> > 
> > Now i can only have 1 NIC on the Squid server.  I've read that
> > iptables will probably have to be configured.  Any help would be
> > appreciated.

I think one important thing you have missed out is why you need to use Squid 
at all in such a setup?  What are you trying to achieve by implementing it, 
instead of just giving all clients direct access to the Internet?



Antony.

-- 
There are two possible outcomes:

 If the result confirms the hypothesis, then you've made a measurement.
 If the result is contrary to the hypothesis, then you've made a discovery.

 - Enrico Fermi

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Sat Apr 23 17:50:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 23 Apr 2016 23:50:15 +0600
Subject: [squid-users] Using Squid with 1 NIC
In-Reply-To: <201604231946.40422.Antony.Stone@squid.open.source.it>
References: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>
 <f2406748-c8c2-cc60-b804-e9dfb4d4ca2a@gmail.com>
 <201604231946.40422.Antony.Stone@squid.open.source.it>
Message-ID: <6b4cc20f-601c-7530-869a-1d157a86c07b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I've based on op's diagram. We are know nothing about what he want.
Thelepaty on Bali on vacation.


23.04.16 23:46, Antony Stone ?????:
> On Saturday 23 April 2016 at 19:12:56, Yuri Voinov wrote:
>
>> http://wiki.squid-cache.org/ConfigExamples/Intercept
>
> Surely there's no reason to have to set up intercept mode (unless the
OP can't
> configure the applications to use an explicit proxy)?
>
> I'm assuming the gateway 192.168.1.1 does outbound NAT to the Internet
> (otherwise nothing would work), so all that's needed is to set up
Squid on
> 192.168.1.2 to allow access from 192.168.1.0/24, with a default
gateway of
> 192.168.1.1, and then configure each of the 192.168.1.x client
machines to use
> 192.168.1.2:3128 as their proxy server?
>
>> 23.04.16 23:08, Tom Ku ?????:
>>> Hi All,
>>>
>>> I know this question has been beaten to death but I can't seem to find
>>> any answers via google.  So i'm trying to set up a Squid proxy for my
>>> VMware infrastructure.  I have multiple port groups networks and I plan
>>> to put a Squid server in each port group to monitor network/internet
>>> traffic.  So I would like my setup like this:
>>>
>>> 192.168.1.1 - Gateway
>>> ^
>>> l
>>> l
>>> l
>>> Squid Proxy - 192.168.1.2)
>>> ^
>>> l
>>> l
>>> l
>>> VMs (clients - 192.168.1.x/24)
>>>
>>> Now i can only have 1 NIC on the Squid server.  I've read that
>>> iptables will probably have to be configured.  Any help would be
>>> appreciated.
>
> I think one important thing you have missed out is why you need to use
Squid
> at all in such a setup?  What are you trying to achieve by
implementing it,
> instead of just giving all clients direct access to the Internet?
>
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG7XXAAoJENNXIZxhPexGWKYIAIJUX7abHDZSiBxo/Oy1LF5h
LPlubXUf02zUB8mM7dTGLhCLmd+Pr/BL7X6euB0C5CF/1I0EV/RQqv5/M0wXWiRT
1H/eVGK+8uhG3MMv5AvMbRuGmoNhPul02xgVYNMiqoTCiEwzIGvBDmeMmTNj7USI
Aboya+ZXphOF+ZHZyegg8veg3cy1LaUMuMcQl+jTVm7neUQk3LqEjZvdZPH6EOZK
NG3woml1Ma6QD1SlFu1NZ9ZOJLLD6mALJ6CXbOy0AjM9lVwiYxZB2FkFTbDnL2g+
pnorE474AAjb24zB7aQORpvNILZcqWIL7AT4I/bmNBF3ckzN4380SAaWz5blaXg=
=fC/p
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/9f9cb653/attachment.key>

From tom at kudude.com  Sat Apr 23 19:26:22 2016
From: tom at kudude.com (Tom)
Date: Sat, 23 Apr 2016 15:26:22 -0400
Subject: [squid-users] Using Squid with 1 NIC
In-Reply-To: <6b4cc20f-601c-7530-869a-1d157a86c07b@gmail.com>
References: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>
 <f2406748-c8c2-cc60-b804-e9dfb4d4ca2a@gmail.com>
 <201604231946.40422.Antony.Stone@squid.open.source.it>
 <6b4cc20f-601c-7530-869a-1d157a86c07b@gmail.com>
Message-ID: <CAN3v6ZG+43qju5q=dJFapyYA4jAFHAaF2QTzGwobYqOG0Ydgbw@mail.gmail.com>

Sorry for not being more clearer on my first post. So I have a VMware
environment running mostly CentOS 6 and multiple port groups:

Each port group it its own network segment.  Please see below:

192.168.1.0/24
GW 192.168.1.1
proxy=192.168.1.2
CentOS servers in this network 192.168.1.0/24

192.168.2.0/24
GW 192.168.2.1
proxy=192.168.2.2
CentOS servers in this network 192.168.2.0/24

192.168.3.0/24
GW 192.168.3.1
proxy=192.168.3.2
CentOS servers in this network 192.168.3.0/24

Now I planned to install/configure a Squid proxy server (one NIC) in each
network and all clients will be going through it.  Now these are CentOS 6
servers, not workstations.  I need all servers in each network segment to
go through the proxy so traffic can be monitored for each network.  Now
would a transparent proxy help?? Hope this make sense.

On Sat, Apr 23, 2016 at 1:50 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> I've based on op's diagram. We are know nothing about what he want.
> Thelepaty on Bali on vacation.
>
>
> 23.04.16 23:46, Antony Stone ?????:
> > On Saturday 23 April 2016 at 19:12:56, Yuri Voinov wrote:
> >
> >> http://wiki.squid-cache.org/ConfigExamples/Intercept
> >
> > Surely there's no reason to have to set up intercept mode (unless the
> OP can't
> > configure the applications to use an explicit proxy)?
> >
> > I'm assuming the gateway 192.168.1.1 does outbound NAT to the Internet
> > (otherwise nothing would work), so all that's needed is to set up
> Squid on
> > 192.168.1.2 to allow access from 192.168.1.0/24, with a default
> gateway of
> > 192.168.1.1, and then configure each of the 192.168.1.x client
> machines to use
> > 192.168.1.2:3128 as their proxy server?
> >
> >> 23.04.16 23:08, Tom Ku ?????:
> >>> Hi All,
> >>>
> >>> I know this question has been beaten to death but I can't seem to find
> >>> any answers via google.  So i'm trying to set up a Squid proxy for my
> >>> VMware infrastructure.  I have multiple port groups networks and I plan
> >>> to put a Squid server in each port group to monitor network/internet
> >>> traffic.  So I would like my setup like this:
> >>>
> >>> 192.168.1.1 - Gateway
> >>> ^
> >>> l
> >>> l
> >>> l
> >>> Squid Proxy - 192.168.1.2)
> >>> ^
> >>> l
> >>> l
> >>> l
> >>> VMs (clients - 192.168.1.x/24)
> >>>
> >>> Now i can only have 1 NIC on the Squid server.  I've read that
> >>> iptables will probably have to be configured.  Any help would be
> >>> appreciated.
> >
> > I think one important thing you have missed out is why you need to use
> Squid
> > at all in such a setup?  What are you trying to achieve by
> implementing it,
> > instead of just giving all clients direct access to the Internet?
> >
> >
> >
> > Antony.
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXG7XXAAoJENNXIZxhPexGWKYIAIJUX7abHDZSiBxo/Oy1LF5h
> LPlubXUf02zUB8mM7dTGLhCLmd+Pr/BL7X6euB0C5CF/1I0EV/RQqv5/M0wXWiRT
> 1H/eVGK+8uhG3MMv5AvMbRuGmoNhPul02xgVYNMiqoTCiEwzIGvBDmeMmTNj7USI
> Aboya+ZXphOF+ZHZyegg8veg3cy1LaUMuMcQl+jTVm7neUQk3LqEjZvdZPH6EOZK
> NG3woml1Ma6QD1SlFu1NZ9ZOJLLD6mALJ6CXbOy0AjM9lVwiYxZB2FkFTbDnL2g+
> pnorE474AAjb24zB7aQORpvNILZcqWIL7AT4I/bmNBF3ckzN4380SAaWz5blaXg=
> =fC/p
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/b831d1bb/attachment.htm>

From yvoinov at gmail.com  Sat Apr 23 19:30:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 24 Apr 2016 01:30:05 +0600
Subject: [squid-users] Using Squid with 1 NIC
In-Reply-To: <CAN3v6ZG+43qju5q=dJFapyYA4jAFHAaF2QTzGwobYqOG0Ydgbw@mail.gmail.com>
References: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>
 <f2406748-c8c2-cc60-b804-e9dfb4d4ca2a@gmail.com>
 <201604231946.40422.Antony.Stone@squid.open.source.it>
 <6b4cc20f-601c-7530-869a-1d157a86c07b@gmail.com>
 <CAN3v6ZG+43qju5q=dJFapyYA4jAFHAaF2QTzGwobYqOG0Ydgbw@mail.gmail.com>
Message-ID: <4dffab89-7764-3c34-235e-cb17e8eaa988@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.04.16 1:26, Tom ?????:
> Sorry for not being more clearer on my first post. So I have a VMware environment running mostly
CentOS 6 and multiple port groups:
>
> Each port group it its own network segment.  Please see below:
>
> 192.168.1.0/24 <http://192.168.1.0/24>
> GW 192.168.1.1
> proxy=192.168.1.2
> CentOS servers in this network 192.168.1.0/24 <http://192.168.1.0/24>
>
> 192.168.2.0/24 <http://192.168.2.0/24>
> GW 192.168.2.1
> proxy=192.168.2.2
> CentOS servers in this network 192.168.2.0/24 <http://192.168.2.0/24>
>
> 192.168.3.0/24 <http://192.168.3.0/24>
> GW 192.168.3.1
> proxy=192.168.3.2
> CentOS servers in this network 192.168.3.0/24 <http://192.168.3.0/24>
>
> Now I planned to install/configure a Squid proxy server (one NIC) in
each network and all clients will be going through it.  Now these are
CentOS 6 servers, not workstations.  I need all servers in each network
segment to go through the proxy so traffic can be monitored for each
network.  Now would a transparent proxy help?? Hope this make sense.

Using a transparent proxy depends on whether it is possible to configure
clients to use a proxy or not.

In most cases, no one here recommends the use of a transparent proxy,
because there are a number of restrictions and high technical expertise
for quality implementation. Also the most fundamental restriction (but I
don't think so) is only possible to proxying HTTP/HTTPS.

>
> On Sat, Apr 23, 2016 at 1:50 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> I've based on op's diagram. We are know nothing about what he want.
> Thelepaty on Bali on vacation.
>
>
> 23.04.16 23:46, Antony Stone ?????:
> > On Saturday 23 April 2016 at 19:12:56, Yuri Voinov wrote:
>
> >> http://wiki.squid-cache.org/ConfigExamples/Intercept
>
> > Surely there's no reason to have to set up intercept mode (unless the
> OP can't
> > configure the applications to use an explicit proxy)?
>
> > I'm assuming the gateway 192.168.1.1 does outbound NAT to the Internet
> > (otherwise nothing would work), so all that's needed is to set up
> Squid on
> > 192.168.1.2 to allow access from 192.168.1.0/24
<http://192.168.1.0/24>, with a default
> gateway of
> > 192.168.1.1, and then configure each of the 192.168.1.x client
> machines to use
> > 192.168.1.2:3128 <http://192.168.1.2:3128> as their proxy server?
>
> >> 23.04.16 23:08, Tom Ku ?????:
> >>> Hi All,
> >>>
> >>> I know this question has been beaten to death but I can't seem to find
> >>> any answers via google.  So i'm trying to set up a Squid proxy for my
> >>> VMware infrastructure.  I have multiple port groups networks and I
plan
> >>> to put a Squid server in each port group to monitor network/internet
> >>> traffic.  So I would like my setup like this:
> >>>
> >>> 192.168.1.1 - Gateway
> >>> ^
> >>> l
> >>> l
> >>> l
> >>> Squid Proxy - 192.168.1.2)
> >>> ^
> >>> l
> >>> l
> >>> l
> >>> VMs (clients - 192.168.1.x/24)
> >>>
> >>> Now i can only have 1 NIC on the Squid server.  I've read that
> >>> iptables will probably have to be configured.  Any help would be
> >>> appreciated.
>
> > I think one important thing you have missed out is why you need to use
> Squid
> > at all in such a setup?  What are you trying to achieve by
> implementing it,
> > instead of just giving all clients direct access to the Internet?
>
>
>
> > Antony.
>
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG809AAoJENNXIZxhPexG18cH/3AXP3mwu/lAmNdTru8rbPT1
iStds/GKw9BOTebKRMtdkOB9F5kBqYSVugksXwAKbOjrisMC0d69iA9ovocUvQiY
DpsaZHybtwZYnSc8TO+hKgI5U4DGYFsBIYudDPyRlLIj6iluCRziHjetyQ2iMHru
d9KNZiQGMMBTwjPyI+YDP4IVYuE8BGyEzlYSib4vAYb1nQAsMyX0tElrfvzmZB4h
DaeKbJlyK7HdsaSZMFR+hz3CNW0uHzsTxchrW6lXPBkFsU25tcwuRhE1Rfh2i0UQ
MqHUIzwTqNIvmIFbKkbQeLXbIPFUDNWtAeOBKy/XkKCiIZJJ0fm42g/5oFwaIas=
=bfyf
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/a45d09e2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/a45d09e2/attachment.key>

From yvoinov at gmail.com  Sat Apr 23 19:32:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 24 Apr 2016 01:32:05 +0600
Subject: [squid-users] Using Squid with 1 NIC
In-Reply-To: <CAN3v6ZG+43qju5q=dJFapyYA4jAFHAaF2QTzGwobYqOG0Ydgbw@mail.gmail.com>
References: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>
 <f2406748-c8c2-cc60-b804-e9dfb4d4ca2a@gmail.com>
 <201604231946.40422.Antony.Stone@squid.open.source.it>
 <6b4cc20f-601c-7530-869a-1d157a86c07b@gmail.com>
 <CAN3v6ZG+43qju5q=dJFapyYA4jAFHAaF2QTzGwobYqOG0Ydgbw@mail.gmail.com>
Message-ID: <5ceee1c4-7d82-f233-00c6-a2108ae2d523@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
In general, you're nobody forbids specify one visible from all networks
IP address / network interface, define a proxy on it and use WPAD / PAC
to configure clients by means of DHCP / DNS.

24.04.16 1:26, Tom ?????:
> Sorry for not being more clearer on my first post. So I have a VMware environment running mostly
CentOS 6 and multiple port groups:
>
> Each port group it its own network segment.  Please see below:
>
> 192.168.1.0/24 <http://192.168.1.0/24>
> GW 192.168.1.1
> proxy=192.168.1.2
> CentOS servers in this network 192.168.1.0/24 <http://192.168.1.0/24>
>
> 192.168.2.0/24 <http://192.168.2.0/24>
> GW 192.168.2.1
> proxy=192.168.2.2
> CentOS servers in this network 192.168.2.0/24 <http://192.168.2.0/24>
>
> 192.168.3.0/24 <http://192.168.3.0/24>
> GW 192.168.3.1
> proxy=192.168.3.2
> CentOS servers in this network 192.168.3.0/24 <http://192.168.3.0/24>
>
> Now I planned to install/configure a Squid proxy server (one NIC) in
each network and all clients will be going through it.  Now these are
CentOS 6 servers, not workstations.  I need all servers in each network
segment to go through the proxy so traffic can be monitored for each
network.  Now would a transparent proxy help?? Hope this make sense.
>
> On Sat, Apr 23, 2016 at 1:50 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> I've based on op's diagram. We are know nothing about what he want.
> Thelepaty on Bali on vacation.
>
>
> 23.04.16 23:46, Antony Stone ?????:
> > On Saturday 23 April 2016 at 19:12:56, Yuri Voinov wrote:
>
> >> http://wiki.squid-cache.org/ConfigExamples/Intercept
>
> > Surely there's no reason to have to set up intercept mode (unless the
> OP can't
> > configure the applications to use an explicit proxy)?
>
> > I'm assuming the gateway 192.168.1.1 does outbound NAT to the Internet
> > (otherwise nothing would work), so all that's needed is to set up
> Squid on
> > 192.168.1.2 to allow access from 192.168.1.0/24
<http://192.168.1.0/24>, with a default
> gateway of
> > 192.168.1.1, and then configure each of the 192.168.1.x client
> machines to use
> > 192.168.1.2:3128 <http://192.168.1.2:3128> as their proxy server?
>
> >> 23.04.16 23:08, Tom Ku ?????:
> >>> Hi All,
> >>>
> >>> I know this question has been beaten to death but I can't seem to find
> >>> any answers via google.  So i'm trying to set up a Squid proxy for my
> >>> VMware infrastructure.  I have multiple port groups networks and I
plan
> >>> to put a Squid server in each port group to monitor network/internet
> >>> traffic.  So I would like my setup like this:
> >>>
> >>> 192.168.1.1 - Gateway
> >>> ^
> >>> l
> >>> l
> >>> l
> >>> Squid Proxy - 192.168.1.2)
> >>> ^
> >>> l
> >>> l
> >>> l
> >>> VMs (clients - 192.168.1.x/24)
> >>>
> >>> Now i can only have 1 NIC on the Squid server.  I've read that
> >>> iptables will probably have to be configured.  Any help would be
> >>> appreciated.
>
> > I think one important thing you have missed out is why you need to use
> Squid
> > at all in such a setup?  What are you trying to achieve by
> implementing it,
> > instead of just giving all clients direct access to the Internet?
>
>
>
> > Antony.
>
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG821AAoJENNXIZxhPexGE/MH/2JSW+xQbYvtKdrTv0kbGQgi
vCFLYtxR5Ti8TTH2ds1k453+ROu9K4CRHSmwxfo9wINHkKT7WpFkJDavAJcoGH0/
xOyPDT63gm3khN6qiAYTZycN2B6rDv8r03pCALiz5A5zXA3cqkLPHm1eTV2T7BZy
42JZP5aXu17HUxYipnwWtIr2B4iWWNKZQs65wOUVpNQB1IKNLPCaViBZGyE7m05v
JNWaP1VpNQNppabGQeINr4fPplK99cSrCZE3RXls+nr/LCt2SUGiiPp0EN5eUf/X
sgwJtcQC9UPni0BcoQ+U3XiPGAajyRWYlmKTGJ/3rNjxPLr8iZWpRz/qvrBlros=
=pNnP
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/bc49861a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/bc49861a/attachment.key>

From yvoinov at gmail.com  Sat Apr 23 19:33:01 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 24 Apr 2016 01:33:01 +0600
Subject: [squid-users] Using Squid with 1 NIC
In-Reply-To: <CAN3v6ZG+43qju5q=dJFapyYA4jAFHAaF2QTzGwobYqOG0Ydgbw@mail.gmail.com>
References: <CAN3v6ZGems4mNgEKFSMptW=cQ0YTomBWtt3mnG_8CemJH-ziAw@mail.gmail.com>
 <f2406748-c8c2-cc60-b804-e9dfb4d4ca2a@gmail.com>
 <201604231946.40422.Antony.Stone@squid.open.source.it>
 <6b4cc20f-601c-7530-869a-1d157a86c07b@gmail.com>
 <CAN3v6ZG+43qju5q=dJFapyYA4jAFHAaF2QTzGwobYqOG0Ydgbw@mail.gmail.com>
Message-ID: <3796a39f-6e4d-151e-df60-5cd2249d7b9b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Without any sexual perversion with WCCP/NAT etc.etc.etc. Only regular
CCNA/SA works. :)

24.04.16 1:26, Tom ?????:
> Sorry for not being more clearer on my first post. So I have a VMware environment running mostly
CentOS 6 and multiple port groups:
>
> Each port group it its own network segment.  Please see below:
>
> 192.168.1.0/24 <http://192.168.1.0/24>
> GW 192.168.1.1
> proxy=192.168.1.2
> CentOS servers in this network 192.168.1.0/24 <http://192.168.1.0/24>
>
> 192.168.2.0/24 <http://192.168.2.0/24>
> GW 192.168.2.1
> proxy=192.168.2.2
> CentOS servers in this network 192.168.2.0/24 <http://192.168.2.0/24>
>
> 192.168.3.0/24 <http://192.168.3.0/24>
> GW 192.168.3.1
> proxy=192.168.3.2
> CentOS servers in this network 192.168.3.0/24 <http://192.168.3.0/24>
>
> Now I planned to install/configure a Squid proxy server (one NIC) in
each network and all clients will be going through it.  Now these are
CentOS 6 servers, not workstations.  I need all servers in each network
segment to go through the proxy so traffic can be monitored for each
network.  Now would a transparent proxy help?? Hope this make sense.
>
> On Sat, Apr 23, 2016 at 1:50 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> I've based on op's diagram. We are know nothing about what he want.
> Thelepaty on Bali on vacation.
>
>
> 23.04.16 23:46, Antony Stone ?????:
> > On Saturday 23 April 2016 at 19:12:56, Yuri Voinov wrote:
>
> >> http://wiki.squid-cache.org/ConfigExamples/Intercept
>
> > Surely there's no reason to have to set up intercept mode (unless the
> OP can't
> > configure the applications to use an explicit proxy)?
>
> > I'm assuming the gateway 192.168.1.1 does outbound NAT to the Internet
> > (otherwise nothing would work), so all that's needed is to set up
> Squid on
> > 192.168.1.2 to allow access from 192.168.1.0/24
<http://192.168.1.0/24>, with a default
> gateway of
> > 192.168.1.1, and then configure each of the 192.168.1.x client
> machines to use
> > 192.168.1.2:3128 <http://192.168.1.2:3128> as their proxy server?
>
> >> 23.04.16 23:08, Tom Ku ?????:
> >>> Hi All,
> >>>
> >>> I know this question has been beaten to death but I can't seem to find
> >>> any answers via google.  So i'm trying to set up a Squid proxy for my
> >>> VMware infrastructure.  I have multiple port groups networks and I
plan
> >>> to put a Squid server in each port group to monitor network/internet
> >>> traffic.  So I would like my setup like this:
> >>>
> >>> 192.168.1.1 - Gateway
> >>> ^
> >>> l
> >>> l
> >>> l
> >>> Squid Proxy - 192.168.1.2)
> >>> ^
> >>> l
> >>> l
> >>> l
> >>> VMs (clients - 192.168.1.x/24)
> >>>
> >>> Now i can only have 1 NIC on the Squid server.  I've read that
> >>> iptables will probably have to be configured.  Any help would be
> >>> appreciated.
>
> > I think one important thing you have missed out is why you need to use
> Squid
> > at all in such a setup?  What are you trying to achieve by
> implementing it,
> > instead of just giving all clients direct access to the Internet?
>
>
>
> > Antony.
>
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG83tAAoJENNXIZxhPexGAlgH/2TlqwiZYQFgG6Dgyr0UIyQa
at3BvW9GeFdQ6larwhn7L8b8Yk89BmEx3RIO/kT4RHGIHDPzVZudI65OXm5XfizJ
vS0sOwkd9v+U+4XusV9O5uEGQkx5drfZIwYmPz6TJa9nzcn5bcK2hrfXtYThH+TF
EuFJLj+4Brxq3YF7jAOR01jf72MomaUOnTZug/DWedtg72U4Z1UGAfmrR/zyjfx5
Iq0+0+3g1nExk9ncxoeUpP36mLzut/T1ZjgqT9abCzKbu9a/6fc8o3+DLzH37g/Z
jlyV1O2f8eius6w8t1Myax8PDqOJrvAij5+rxrPzH4nMKakL2w0aSW8d6bx1Do8=
=edI7
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/58efa813/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/58efa813/attachment.key>

From yvoinov at gmail.com  Sat Apr 23 20:38:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 24 Apr 2016 02:38:30 +0600
Subject: [squid-users] Why 3.5 and 4.x shows different tags in access.log
	due to CONNECT?
Message-ID: <d212c98b-8874-396e-d357-6adfd72b8708@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
4.x shows:

1461442623.529    580 192.168.100.103 NONE_ABORTED/200 0 CONNECT
45.55.230.38:443 - ORIGINAL_DST/45.55.230.38 -

and this CONNECT is NOT aborted!

3.5.x shows:

1461442791.695    462 192.168.100.102 TAG_NONE/200 0 CONNECT
91.250.107.40:443 - ORIGINAL_DST/91.250.107.40 -

Is is bug or feature? :)


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG91GAAoJENNXIZxhPexGc3sH/iADHhJKuYbmZYecMM3sJ22k
bV02PDnL7Ge3pRUPoYXDlfCJDoxFS+keWRIRH53IhiYB21gGfo+PfEEcJtBIQ1bZ
OJHQaR3Mi8/L2hkLuwuanTGxaQECSYaBlgn+pHNkSOvpD+Bi4p2DQ0ZXDbTBQOZR
D4Xjv2cWSl5N/LUGp9HALgSnNtnzA/e5YoZ8ec1zuCfqP48hSYcO6fK3Kq6ThdRB
uZp0uAmUFtinRLBE3kp4kA8r7MSSKNq3nZSub1UZbiNAq3PfZC/Eio1XtxhEgdwO
PC693aiweRjy4z+8qrJ7+B8KUr7kdVHJvItTLZggJpr5yPYqJFh0KGGGST+9Q5k=
=4hIP
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/ee1ac185/attachment.key>

From rafael.akchurin at diladele.com  Sat Apr 23 20:56:39 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 23 Apr 2016 20:56:39 +0000
Subject: [squid-users] Squid 3.5.17-1 is available for Ubuntu 14.04 LTS
 (online repo ubuntu.diladele.com)
Message-ID: <VI1PR04MB135935FAFFC6E7CB7BCC71198F600@VI1PR04MB1359.eurprd04.prod.outlook.com>

Greetings everyone,



The Squid 3.5.17-1 package for Ubuntu 14.04 LTS is now available. This version is recompiled using Squid DEB source from Debian Testing with some changes required to support SSL bump / libecap3 on Ubuntu 14.04 LTS.



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.17-RELEASENOTES.html

* The online repo is at http://ubuntu.diladele.com

* Tutorial showing how we rebuilt Squid 3.5.17 on Ubuntu 14.04 LTS http://docs.diladele.com/tutorials/build_squid_ubuntu14/index.html

* Scripts we used to build it are at https://github.com/diladele/squid-ubuntu



If you have installed previous version 3.5.16-1 from this repo then please run "sudo apt-get update && sudo apt-get upgrade".  Please also check that your current squid.conf file from previous version is not overwritten.

If you are installing this version for the first time run the following commands:



    # add repo

    echo "deb http://ubuntu.diladele.com/ubuntu/ trusty main" > /etc/apt/sources.list.d/ubuntu.diladele.com.list



    # update the apt cache

   apt-get update



   # install

   apt-get install libecap3

   apt-get install squid-common

   apt-get install squid

   apt-get install squidclient



All questions/comments and suggestions are welcome at support at diladele.com<mailto:support at diladele.com> or here in the mailing list.



Best regards,

Rafael Akchurin

Diladele B.V.

http://www.quintolabs.com

http://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160423/9c0fa53b/attachment.htm>

From rousskov at measurement-factory.com  Sat Apr 23 21:25:54 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 23 Apr 2016 15:25:54 -0600
Subject: [squid-users] Why 3.5 and 4.x shows different tags in
 access.log due to CONNECT?
In-Reply-To: <d212c98b-8874-396e-d357-6adfd72b8708@gmail.com>
References: <d212c98b-8874-396e-d357-6adfd72b8708@gmail.com>
Message-ID: <571BE862.9090103@measurement-factory.com>

On 04/23/2016 02:38 PM, Yuri Voinov wrote:
> 
> 4.x shows:
> 
> 1461442623.529    580 192.168.100.103 NONE_ABORTED/200 0 CONNECT
> 45.55.230.38:443 - ORIGINAL_DST/45.55.230.38 -
> 
> and this CONNECT is NOT aborted!
> 
> 3.5.x shows:
> 
> 1461442791.695    462 192.168.100.102 TAG_NONE/200 0 CONNECT
> 91.250.107.40:443 - ORIGINAL_DST/91.250.107.40 -
> 
> Is is bug or feature? :)

I have seen wrong transaction categories in v4 [bumping] logs as well. I
suspect it is a bug.

Alex.



From yvoinov at gmail.com  Sat Apr 23 21:27:54 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 24 Apr 2016 03:27:54 +0600
Subject: [squid-users] Why 3.5 and 4.x shows different tags in
 access.log due to CONNECT?
In-Reply-To: <571BE862.9090103@measurement-factory.com>
References: <d212c98b-8874-396e-d357-6adfd72b8708@gmail.com>
 <571BE862.9090103@measurement-factory.com>
Message-ID: <ecf12c5a-be08-4c68-c087-969078c2fb42@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Opens bug?


24.04.16 3:25, Alex Rousskov ?????:
> On 04/23/2016 02:38 PM, Yuri Voinov wrote:
>>
>> 4.x shows:
>>
>> 1461442623.529    580 192.168.100.103 NONE_ABORTED/200 0 CONNECT
>> 45.55.230.38:443 - ORIGINAL_DST/45.55.230.38 -
>>
>> and this CONNECT is NOT aborted!
>>
>> 3.5.x shows:
>>
>> 1461442791.695    462 192.168.100.102 TAG_NONE/200 0 CONNECT
>> 91.250.107.40:443 - ORIGINAL_DST/91.250.107.40 -
>>
>> Is is bug or feature? :)
>
> I have seen wrong transaction categories in v4 [bumping] logs as well. I
> suspect it is a bug.
>
> Alex.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG+jZAAoJENNXIZxhPexG2kIH/jrqgmSJ0ZNj5yv7eyiwb4+z
Q6vC3P2IHhHbJaKmHZaHiWbi1QPISImjg1tkhQxVenEP1taiY73BtUJ+FWmcSuQC
FxEUfD3LpCEy9Djnz+Azlo1ybk7vyJa7zOxiY+/nZulWlwwwIiriuZrXDDA6xH1L
BA6lGHHgRUuvoLwsU8//BJb9eCPnqQ/YIj0ZOR3dVBZLwk/PZMrk/vyVqsWGVrYj
zdWRsadlMxqdjVLcjraO8mqiQdx9S8IlFikCJO/UNlhIw6orvcV0VZ4ISaPe7HkE
B3aNRQxJIOZjWCRcFot5eiH4Yt+zGiDtQLIANzJ4ybh2aDtwBmAgmzvoqO0Xrhw=
=meLJ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/43b48219/attachment.key>

From yvoinov at gmail.com  Sat Apr 23 21:33:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 24 Apr 2016 03:33:20 +0600
Subject: [squid-users] Why 3.5 and 4.x shows different tags in
 access.log due to CONNECT?
In-Reply-To: <571BE862.9090103@measurement-factory.com>
References: <d212c98b-8874-396e-d357-6adfd72b8708@gmail.com>
 <571BE862.9090103@measurement-factory.com>
Message-ID: <81c45b5d-9e67-ef79-101f-b25f5f8a9839@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://bugs.squid-cache.org/show_bug.cgi?id=4503


24.04.16 3:25, Alex Rousskov ?????:
> On 04/23/2016 02:38 PM, Yuri Voinov wrote:
>>
>> 4.x shows:
>>
>> 1461442623.529    580 192.168.100.103 NONE_ABORTED/200 0 CONNECT
>> 45.55.230.38:443 - ORIGINAL_DST/45.55.230.38 -
>>
>> and this CONNECT is NOT aborted!
>>
>> 3.5.x shows:
>>
>> 1461442791.695    462 192.168.100.102 TAG_NONE/200 0 CONNECT
>> 91.250.107.40:443 - ORIGINAL_DST/91.250.107.40 -
>>
>> Is is bug or feature? :)
>
> I have seen wrong transaction categories in v4 [bumping] logs as well. I
> suspect it is a bug.
>
> Alex.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXG+ofAAoJENNXIZxhPexG9bEIAI6Zt53ldHhoujzMie1G7PUb
U1XTrRBEyVp3H+PDniNUj5v8IAGMkuVQaFInmHXlmS08oFbMB4rXEwK6Gt8xm9ZH
XsnrkIHCijVl82ltL2vvEeZlxgDBb/15A+kfMBdqHzGqU2Kw7QSVAPBCrYLTH3md
gmnuq5VuaXwh7wI1UIGV56QCoYM5ZXalnt8nMCukcYuAMaGEis8fGv46Egtww4xs
mSmcSVejI+AKMpjhdB41ZyhyjvrRsEDhUGDYcyJNRwMe5xKv7A4+wg565kAyOgzz
IhclYlQalH0gutSiGRc7Oh6646hlfCSYFTr32zCGmrzJLJ4qSUM3oyKStE8Gcpw=
=sleL
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/9fa58a5d/attachment.key>

From hackensolo at gmail.com  Sun Apr 24 14:11:27 2016
From: hackensolo at gmail.com (Hack Ensolo)
Date: Sun, 24 Apr 2016 16:11:27 +0200
Subject: [squid-users] NTLM_AUTH authentification send BH SPNEGO request
	invalid prefix
Message-ID: <CALOGGjTj3yDkh7RdKQ8ww+VDj-_fEQO1R+eKSTk1xS1zVmTf4A@mail.gmail.com>

Hi,
I try to log a user who is in active directory group "webusers" with
ntlm_auth
but I have some problems.

/usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp
--require-membership-of=DOMAIN\\webusers

This command doens't work.
An idea ?

Debian_version 8.4
Squid 3.4.8
ntlm_auth 4.2.10-Debian
Active Directory on Windows Server 2008 R2 x64
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/1b864818/attachment.htm>

From yvoinov at gmail.com  Sun Apr 24 14:52:09 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 24 Apr 2016 20:52:09 +0600
Subject: [squid-users] NTLM_AUTH authentification send BH SPNEGO request
 invalid prefix
In-Reply-To: <CALOGGjTj3yDkh7RdKQ8ww+VDj-_fEQO1R+eKSTk1xS1zVmTf4A@mail.gmail.com>
References: <CALOGGjTj3yDkh7RdKQ8ww+VDj-_fEQO1R+eKSTk1xS1zVmTf4A@mail.gmail.com>
Message-ID: <6d347585-93f1-fc94-b388-0647da13934b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Any logs?


24.04.16 20:11, Hack Ensolo ?????:
> Hi,
> I try to log a user who is in active directory group "webusers" with
ntlm_auth
> but I have some problems.
>
> /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp
--require-membership-of=DOMAIN\\webusers
>
> This command doens't work.
> An idea ?
>
> Debian_version 8.4
> Squid 3.4.8
> ntlm_auth 4.2.10-Debian
> Active Directory on Windows Server 2008 R2 x64
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXHN2ZAAoJENNXIZxhPexGDBwH/jCZ4rIEl20e7BjuUSRlnjpa
dVDdlPaRpyRCmu/UrfTW3ba+AEt2E2QS7TKGKDMoxudExon4S32MwFzV1Mlojfq+
lx0veCYWmxqNNKOfcUKJ6ebFuTNV3geX59qTg8RAEiVCdE6Zakt7y/gkWje+zmbe
lT1c5UdK+dTtOgDCIKmgqvgWyblVhvWmyAmKbZUi/1uUHBFvBMDWhuiOmXP3i2S3
9kRslAT8IlHk6EQX3yrZRCoertTYd94tfdULE8BAO0uApzVuLtSvu2ydwKheJcV4
opOkhMSASLP/tXAREydzUKWKdlJdHjW+jZx2mmBASpoLiq7O0gt2M1Wt28vplSo=
=mrjr
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/fecf29e8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160424/fecf29e8/attachment.key>

From yvoinov at gmail.com  Sun Apr 24 20:12:53 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 25 Apr 2016 02:12:53 +0600
Subject: [squid-users] Intermediate CA's file for using in
 sslproxy_foreign_intermediate_certs
Message-ID: <e657fe45-76fd-183f-54a7-78d474bdfed7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I'll just leave it here.

https://drive.google.com/file/d/0B4nS4FYXsqTfTlo4UVQ3TF8xdms/view?usp=sharing

Updates are performed as needed. On a relatively regular basis.

WBR, Yuri


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXHSjFAAoJENNXIZxhPexG0NkH+wT7+l7NK4wqfGHqrjZNJPoo
wXzD23Xrezbpu9vVP/BRQpxXveGN8U0uZcaHZXm4zCIz1jBYOkWyHLA735/OB0bR
KYGCEfxc9sKr+guXkulFnE0NDFeP08hKFEGYqWKaS6dZcrQBdKXPAd1Lv6PGk/SF
wnnhIR3oHGK0RjSam0yHNQYON/+WLhEs0odqtR1UmJ43J1+MrC/UEDBzzX//Bb/R
OX0/QudIdeTyZ9zlukj9lyBR0OUSvaVYweiDSQbPurexLnHnPLM2qH2e4Z7WOz5U
g/xSfUPR/s6YA8LMb7LYBfpFqLVnTuSVvuxnRDKNXxBjHt99kEmEYyHGimtk5UQ=
=iCs/
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160425/18dbb665/attachment.key>

From r.ollin at yahoo.com  Mon Apr 25 02:09:44 2016
From: r.ollin at yahoo.com (skeetz9r)
Date: Sun, 24 Apr 2016 19:09:44 -0700 (PDT)
Subject: [squid-users] Squid SSL Bump
In-Reply-To: <571AF12B.9000003@treenet.co.nz>
References: <1330359101.420588.1461351730784.JavaMail.yahoo@mail.yahoo.com>
 <571AF12B.9000003@treenet.co.nz>
Message-ID: <1461550184251-4677260.post@n4.nabble.com>


When I updated the package, I now see the root CA (AAA) in the list

*cat  /etc/pki/tls/certs/ca-bundle.crt | grep "AAA"*

But the SSL server I am accessing is in the following chain

*AAA (issued)-> Intermediate Cert (issued)-> SSL Server Cert*

When I grep the ca-bundle, I don't see the Intermediate cert in the list.
Maybe it only contains ROOT CAs and not intermediate?

Squid version is *3.5.11*

How do I define explicitly?

If I update ca-bundle package do I need to restart Squid? Or any other
services?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-SSL-Bump-tp4677232p4677260.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From r.ollin at yahoo.com  Mon Apr 25 02:34:20 2016
From: r.ollin at yahoo.com (skeetz9r)
Date: Sun, 24 Apr 2016 19:34:20 -0700 (PDT)
Subject: [squid-users] Squid SSL Bump
In-Reply-To: <571AF12B.9000003@treenet.co.nz>
References: <1330359101.420588.1461351730784.JavaMail.yahoo@mail.yahoo.com>
 <571AF12B.9000003@treenet.co.nz>
Message-ID: <1461551660811-4677261.post@n4.nabble.com>

UPDATE **

On more digging it seems like the SSL server is using SHA 1 and that may be
the issue here. Any way around that?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-SSL-Bump-tp4677232p4677261.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From vkukk at xvidservices.com  Mon Apr 25 07:55:57 2016
From: vkukk at xvidservices.com (Veiko Kukk)
Date: Mon, 25 Apr 2016 10:55:57 +0300
Subject: [squid-users] Never expire any object Squid configuration
In-Reply-To: <571754CA.70101@treenet.co.nz>
References: <57172E90.9020204@xvidservices.com> <571754CA.70101@treenet.co.nz>
Message-ID: <571DCD8D.4060501@xvidservices.com>

On 20/04/16 13:07, Amos Jeffries wrote:
> On 20/04/2016 7:24 p.m., Veiko Kukk wrote:
>> Hi,
>>
>> We have a Squid between our server application and openstack swift
>> backend in accel/reverse mode with store-id configuraton (to strip
>> temporary authentication URL-s). We want that any object that has been
>> stored in squid cache is never again fetched from source and never again
>> checked if it is fresh. Well, never in this case could be one year.
>
> The usual resonse to this is "Squid is a cache, not an archive".

I turned out, what we need was offline_mode on.
http://www.squid-cache.org/Versions/v3/3.5/cfgman/offline_mode.html

Best regards,
Veiko




From hackensolo at gmail.com  Mon Apr 25 14:33:12 2016
From: hackensolo at gmail.com (Hack Ensolo)
Date: Mon, 25 Apr 2016 16:33:12 +0200
Subject: [squid-users] Squid 3.4.8 helpers doesn't work how I want !
Message-ID: <CALOGGjSuYRxNerB5hUFXVkS0M93eeb2BH+cxqO+7b=ovJa9qVw@mail.gmail.com>

Hi,
I try to authenticate a user in AD (windows server 2008 R2).
When he is in a group Webusers he must authenticated and when I remove the
user of this group, he must not authenticated.
And this process doesn't work because he is always authticated.

Sorry for my english.

I post the squid configuration...
I don't post the logs because I 'm not errors.

cache_mgr service.informatique@ <service.informatique at ipl.be>example.com

### Negotiate kerberos authentification
auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -s
HTTP/rex.example.com at EXAMPLE.COM
auth_param negotiate children 20 startup=0 idle=1
auth_param negotiate keep_alive off

### ldap authorisation
external_acl_type kerbgroup ttl=60 children-max=15 children-startup=10 ipv4
%LOGIN /usr/lib/squid3/ext_ldap_group_acl -R -K -b
ou=students,dc=server,dc=example,dc=com -D squid at example.com -W
/etc/squid3/ldappass.txt -f
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=students,dc=server,dc=example,dc=com))"
-h dc1.server.example.com

### acl for proxy auth and ldap authorizations
acl auth proxy_auth REQUIRED
acl kerbusers external kerbgroup webusers

### squid defaults
acl localnet src 172.17.0.0/16
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost

### http_access rules
http_access allow manager localhost
http_access allow auth
http_access deny !auth
http_access allow kerbusers
http_access allow localnet
http_access deny manager
http_access deny all

### logging
access_log stdio:/var/log/squid3/access.log
cache_store_log stdio:/var/log/squid3/store.log

### squid Debian defaults
http_port 3128
cache_effective_user proxy
cache_effective_group proxy
cache_dir ufs /cache1 20000 16 256
cache_dir ufs /cache2 20000 16 256
coredump_dir /var/spool/squid3

### default squid rules
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160425/b0c8bc5a/attachment.htm>

From yvoinov at gmail.com  Mon Apr 25 14:39:35 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 25 Apr 2016 20:39:35 +0600
Subject: [squid-users] Squid 3.4.8 helpers doesn't work how I want !
In-Reply-To: <CALOGGjSuYRxNerB5hUFXVkS0M93eeb2BH+cxqO+7b=ovJa9qVw@mail.gmail.com>
References: <CALOGGjSuYRxNerB5hUFXVkS0M93eeb2BH+cxqO+7b=ovJa9qVw@mail.gmail.com>
Message-ID: <067110d9-d794-4c85-a851-6e2c7585295e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Logs from AD, man.


25.04.16 20:33, Hack Ensolo ?????:
> Hi,
> I try to authenticate a user in AD (windows server 2008 R2).
> When he is in a group Webusers he must authenticated and when I remove
the user of this group, he must not authenticated.
> And this process doesn't work because he is always authticated.
>
> Sorry for my english.
>
> I post the squid configuration...
> I don't post the logs because I 'm not errors.
>
> cache_mgr service.informatique@
<mailto:service.informatique at ipl.be>example.com <http://example.com>
>
> ### Negotiate kerberos authentification
> auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth
-s HTTP/rex.example.com at EXAMPLE.COM <mailto:rex.example.com at EXAMPLE.COM>
> auth_param negotiate children 20 startup=0 idle=1
> auth_param negotiate keep_alive off
>
> ### ldap authorisation
> external_acl_type kerbgroup ttl=60 children-max=15 children-startup=10
ipv4 %LOGIN /usr/lib/squid3/ext_ldap_group_acl -R -K -b
ou=students,dc=server,dc=example,dc=com -D squid at example.com
<mailto:squid at example.com> -W /etc/squid3/ldappass.txt -f
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=students,dc=server,dc=example,dc=com))"
-h dc1.server.example.com <http://dc1.server.example.com>
>
> ### acl for proxy auth and ldap authorizations
> acl auth proxy_auth REQUIRED
> acl kerbusers external kerbgroup webusers
>
> ### squid defaults
> acl localnet src 172.17.0.0/16 <http://172.17.0.0/16>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost
>
> ### http_access rules
> http_access allow manager localhost
> http_access allow auth
> http_access deny !auth
> http_access allow kerbusers
> http_access allow localnet
> http_access deny manager
> http_access deny all
>
> ### logging
> access_log stdio:/var/log/squid3/access.log
> cache_store_log stdio:/var/log/squid3/store.log
>
> ### squid Debian defaults
> http_port 3128
> cache_effective_user proxy
> cache_effective_group proxy
> cache_dir ufs /cache1 20000 16 256
> cache_dir ufs /cache2 20000 16 256
> coredump_dir /var/spool/squid3
>
> ### default squid rules
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXHiwmAAoJENNXIZxhPexGErgIAMHORuxEGPdj5UKhoKAa3dDK
jp9wcb0vrgH0F2YT+vM5AdlgPqG97/7UlB/jrfbmrMOwXcz0e1mdxDlRo9vJbeJA
eC9k9u7AxqTTBCeOTMdIW11CGF8Fh8gVr5lhO6ue7YIfAzr1CzrhlWhBNxqNKxD+
LvzkSGNXdn6JCaNRTLYcSJJGKYj7pGjS/RClEnoi2LADpO66N3k4dOFYgrASRKU2
J+kn1EOLM/FkKJOUQPrKeUo8fTZ/v04ysxdI5UWqqdFj7hE1ISBJT5XzKQmQ/U0P
qmI6Y8ypL8IClEvbevi6xIacVezVJols+Cj3tS35fAxJVjiY3q4VfhkMAHRopLo=
=kg1R
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160425/d9eb0ce1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160425/d9eb0ce1/attachment.key>

From Sebastien.Boulianne at cpu.ca  Mon Apr 25 15:16:15 2016
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Mon, 25 Apr 2016 11:16:15 -0400
Subject: [squid-users] Attached file on OWA with Squid
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5837FD15BB@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD147F@CPUMAIL2.cpu.qc.ca>
 <5708820A.8090303@treenet.co.nz>
 <5FE0959288C73D448BB44CB7E9CC320F5837FD15BB@CPUMAIL2.cpu.qc.ca>
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5837FD1648@CPUMAIL2.cpu.qc.ca>

Hi all,

I changed the status from 302 to 308.

I can now upload a small txt files but if I try to attach a file bigger than 1meg, I got the same issue as the begginning... The browser freeze and nothing happens.

What else can I try ?

Thanks.

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Sebastien.Boulianne at cpu.ca
Envoy??: 19 avril 2016 09:05
??: squid3 at treenet.co.nz; squid-users at lists.squid-cache.org
Cc?: Marc-Andre Bouchard <marc-andre.bouchard at cpu.ca>
Objet?: Re: [squid-users] Attached file on OWA with Squid

Hi Amos, Eliezer and all ;),
As I wrote, if I connect to our VPN then I try to attach a file with the OWA, it works.
If I forward all owa requests directly to the mail server, I can attach a file without any issues.

I isolated the issue and we can see the problem happens when owa requests pass thru the Squid.

Is it a server issue or a Squid issue ?
Im running MS Exchange 2007 SP3 x64.

Im using the very latest version of Squid.

I will try to change the 302 status to 308.

Thanks you very much for ur help guys.

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Amos Jeffries Envoy??: 9 avril 2016 00:16 ??: squid-users at lists.squid-cache.org Objet?: Re: [squid-users] Attached file on OWA with Squid

On 7/04/2016 5:24 a.m., Sebastien.Boulianne wrote:
> I configured my OWA to pass thru the Squid.
> Auth work perfectly.
> Browsing is working perfectly.
> All is working perfectly except when I try to attach files or documents to an email.
> 
> [cid:image002.png at 01D19007.A7E26D20]
> 
> 
> And It stops here. Nothing else happens.
> 
> I did some tests and I noticed that happens when I am connecting from external to OWA.
> If I connect to the VPN then I try to send an attached file with the OWA, it works.

If you mean that you are using Squid through the VPN, then that probably means its not a Squid problem.


> 
> Here is my config for my OWA.
> 
> ### OWA
> cache_peer owa.domain.qc.ca parent 443 0 no-query originserver 
> login=PASS ssl sslcert=/etc/pki/tls/certs/domain.qc.ca.cert.pem
> sslkey=/etc/pki/tls/private/domain.qc.ca.key.pem
> options=NO_SSLv2:NO_SSLv3:SINGLE_DH_USE:CIPHER_SERVER_PREFERENCE
> dhparams=/etc/pki/tls/private/dhparams.pem
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+E
> CDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:E
> DH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> name=owa acl owahttps url_regex ^https://owa\.domain\.qc\.ca 
> cache_peer_access owa allow owahttps http_access allow www443 owahttps 
> acl owahttp url_regex ^http://owa\.domain\.qc\.ca http_access deny 
> owahttp deny_info 302:https://%H%R owahttp

You probably need to use 308 status here. 302 tells the client to try again using the *GET* method. Sending of things is not a GET action.


> 
> Thanks you very much for your advice.
> 

What version of Squid (squid -v) ?

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From jok at spikes.com  Mon Apr 25 15:28:41 2016
From: jok at spikes.com (Jok Thuau)
Date: Mon, 25 Apr 2016 08:28:41 -0700
Subject: [squid-users] Squid 3.4.8 helpers doesn't work how I want !
In-Reply-To: <CALOGGjSuYRxNerB5hUFXVkS0M93eeb2BH+cxqO+7b=ovJa9qVw@mail.gmail.com>
References: <CALOGGjSuYRxNerB5hUFXVkS0M93eeb2BH+cxqO+7b=ovJa9qVw@mail.gmail.com>
Message-ID: <CADSSinMMC0DYNsteQSD7v=KdPbxO9rrFhM6U0Y=bR5U0ZFKzoA@mail.gmail.com>

On Mon, Apr 25, 2016 at 7:33 AM, Hack Ensolo <hackensolo at gmail.com> wrote:

> ### http_access rules
> http_access allow manager localhost
> http_access allow auth
> http_access deny !auth
> http_access allow kerbusers
> http_access allow localnet
> http_access deny manager
> http_access deny all
>
>
Since the rules are "first match", once you have "allow auth", squid is
done. it will not look at the group membership (under "kerbusers").

you should look at the acl type "all-of" and "any-of" to build your logic:
acl authn_authz all-of auth kerbusers

might be helpful and would make your config slightly easier to read...

With that in mind, reconsider how you organize the rules...

Jok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160425/9a9ce3f5/attachment.htm>

From squid at borrill.org.uk  Mon Apr 25 15:51:09 2016
From: squid at borrill.org.uk (Stephen Borrill)
Date: Mon, 25 Apr 2016 16:51:09 +0100
Subject: [squid-users] Logging ACL that triggered denied access with
	http_access
Message-ID: <571E3CED.7090907@borrill.org.uk>

Is there a way to log which ACL caused a block with http_access? This
information is present for deny_info to use, but I cannot see a entry I
can add to logformat to present such a thing in a custom log format (if
using an external acl helper, you can spoof something up with the et and
ea formats).

-- 
Stephen


From yvoinov at gmail.com  Mon Apr 25 15:57:00 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 25 Apr 2016 21:57:00 +0600
Subject: [squid-users] Logging ACL that triggered denied access with
 http_access
In-Reply-To: <571E3CED.7090907@borrill.org.uk>
References: <571E3CED.7090907@borrill.org.uk>
Message-ID: <754a612a-21d1-c893-532f-89e5273cb7ba@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Usually for this task uses external url rewriter which has own block
log. For example, ufdbguard/squidguard/dansguardian etc.

Also you can use DB-based ACL's to this task. Which is better than
manual maintained huge plain-text inclusions in squid.conf.


25.04.16 21:51, Stephen Borrill ?????:
> Is there a way to log which ACL caused a block with http_access? This
> information is present for deny_info to use, but I cannot see a entry I
> can add to logformat to present such a thing in a custom log format (if
> using an external acl helper, you can spoof something up with the et and
> ea formats).
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXHj5MAAoJENNXIZxhPexGIMAH/3giepHwCBEANSzk+6HiwNfv
Av1NDBpjwlNWKvSnFbeaENpJOPzr5T8eWxT0jLIBaLaZzO79odsNTxDCtdmR1yaD
2bLk+yG3S14DNfP4aVYS/h5pYTh/86gA+ukSGLaZrHyj0R0bNuLFz9GaZqMkuZDn
aVRsHYfGV8GkC6qd1wMLgq7Zw4fltZp9wD8M/0g1hsaqJ2Mlrg13aitHPoxNFnnf
UHsTLM/cKVFfFKuKrE4ZYoRJlLOvygQpB+PuE2wkm4wFuBPELB35X2T1vrn27ZON
g0DakHUH4vCP8AoLctCf1JDbF+xLMR7bq6+3AoCbE/WBea3fieOrFGWeyMVulQQ=
=TWu+
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160425/172832d5/attachment.key>

From Frank.Trifiletti at developpement-durable.gouv.fr  Mon Apr 25 16:41:55 2016
From: Frank.Trifiletti at developpement-durable.gouv.fr (TRIFILETTI Frank (Adjoint au chef du DO Sud-Est / Chef du groupe
 expertise technique) - SG/SPSSI/CPII/DOSE/ET)
Date: Mon, 25 Apr 2016 18:41:55 +0200
Subject: [squid-users] change between squid 3.1 and 3.3.8
In-Reply-To: <571AEC15.70007@treenet.co.nz>
References: <1461336059437-4677229.post@n4.nabble.com>
 <571AEC15.70007@treenet.co.nz>
Message-ID: <571E48D3.90204@developpement-durable.gouv.fr>

Hello Amos,

thanks for your answer

my answer in the body of the message below

Frank

Le 23/04/2016 05:29, "> Amos Jeffries (par Internet, d?p?t 
squid-users-bounces at lists.squid-cache.org)" a ?crit :
> On 23/04/2016 2:40 a.m., FTRIF wrote:
>> Hello,
>> i have a problem using /usr/lib/squid3/ext_ldap_group_acl which appears in
>> 3.3.8
>>
>> i have a ldap attribut called InternetAccess which contains the value
>> "ACCESSINTER"
>>
>> i want to make an ACL to authorize such people to surf on the net by using a
>> ldap_group, built with the people who had the value ACCESSINTER in the ldap
>> attribut called InternetAccess
>>
>> in command line it works both with squid 3.1 and 3.3.8, the answer is OK:
>>
>> /usr/lib/squid3/ext_ldap_group_acl -d -b dc=eq,dc=fr -f
>> "(&(objectclass=person)(InternetAccess=%a)(uid=%u))" myLdapDNSname
>>
>> fk.tf ACCESSINTER
>> ext_ldap_group_acl.cc(587): pid=25599 :Connected OK
>> ext_ldap_group_acl.cc(726): pid=25599 :group filter
>> '(&(objectclass=person)(InternetAccess=ACCESSINTER)(uid=fk.tf))', searchbase
>> 'dc=eq,dc=fr'
>> OK
>
> Use '%g' macro for group. It will not to collide with URL-encoding of
> the parameters.
>

in the squid.conf i forget indicate that i have a line
acl profil_ACCESSINTERNET external ldap_group ACCESSINTER

in command line i replace %a by '%g' in command line but it doesn't work only if 
i put %g

but in squid.conf i put '%g' instead of %a and i have the same result with in 
the cache.log

2016/04/25 18:17:25.835| Acl.cc(319) checklistMatches: ACL::checklistMatches: 
checking 'profil_ACCESSINTERNET'
2016/04/25 18:17:25.835| external_acl.cc(793) aclMatchExternal: acl="ldap_group"
2016/04/25 18:17:25.835| external_acl.cc(822) aclMatchExternal: No helper entry 
available
2016/04/25 18:17:25.835| external_acl.cc(826) aclMatchExternal: ldap_group check 
user authenticated.
2016/04/25 18:17:25.835| external_acl.cc(832) aclMatchExternal: ldap_group user 
is authenticated.
2016/04/25 18:17:25.835| external_acl.cc(856) aclMatchExternal: 
ldap_group("fk.tf ACCESSINTER") = lookup needed
2016/04/25 18:17:25.835| external_acl.cc(858) aclMatchExternal: "fk.tf 
ACCESSINTER": entry=@0, age=0
2016/04/25 18:17:25.835| external_acl.cc(861) aclMatchExternal: "fk.tf 
ACCESSINTER": queueing a call.
2016/04/25 18:17:25.835| external_acl.cc(863) aclMatchExternal: "fk.tf 
ACCESSINTER": return -1.
2016/04/25 18:17:25.835| Acl.cc(321) checklistMatches: ACL::ChecklistMatches: 
result for 'profil_ACCESSINTERNET' is -1
2016/04/25 18:17:25.835| Acl.cc(346) matches: profil_ACCESSINTERNET needs async 
lookup
2016/04/25 18:17:25.835| Acl.cc(354) matches: profil_ACCESSINTERNET result is false
2016/04/25 18:30:36.709| Checklist.cc(275) matchNode: 0x7ffdc7f66fb0 matched=0 
async=1 finished=0
2016/04/25 18:30:36.709| Checklist.cc(146) markFinished: 0x7ffdc7f66fb0 answer 
DUNNO for async required but prohibited
2016/04/25 18:30:36.709| Checklist.cc(308) matchNode: 0x7ffdc7f66fb0 DUNNO 
because cannot async
2016/04/25 18:30:36.709| FilledChecklist.cc(77) ~ACLFilledChecklist: 
ACLFilledChecklist destroyed 0x7ffdc7f66fb0
2016/04/25 18:30:36.709| Checklist.cc(334) ~ACLChecklist: 
ACLChecklist::~ACLChecklist: destroyed 0x7ffdc7f66fb0
2016/04/25 18:30:36.709| Checklist.cc(153) preCheck: 0x7ffdc7f66fb0 checking 
fast rules
2016/04/25 18:30:36.709| Checklist.cc(414) fastCheck: aclCheckFast: list: 
0x56353080b548

is it these last lines indicate the followup where the helper responds you asked 
for ?

if not which type of text i have to search ?

my debug_options 28,9 82,9 84,9
section 82 External AC
section 84 Helper process maintenance
section 28 Access Control



>>
>> but in the squid.conf v3.3.8, i put the line below  :
>>
>> external_acl_type ldap_group ipv4 %LOGIN /usr/lib/squid3/ext_ldap_group_acl
>> -d -b dc=eq,dc=fr -f "(&(objectclass=person)(InternetAccess=%a)(uid=%u))"
>> myLdapDNSname
>>
>> it don't work and in my cache.log i found :
>>
> <snip>
>> 779298:2016/04/22 15:56:40.335| external_acl.cc(861) aclMatchExternal:
>> "fk.tf ACCESSINTER": queueing a call.
>> 779299:2016/04/22 15:56:40.335| external_acl.cc(863) aclMatchExternal:
>> "fk.tf ACCESSINTER": return -1.
>
> That is sending the lookup. Now Squid awaits the helper response.
>
>
>>
>> It's work in squid 3.1 with the external acl called "squid_ldap_group"
>> instead of "ext_ldap_group_acl"
>>
>> perhaps i used something in 3.1 which was a bug corrected in 3.3 ?
>>
>
> There is no sign of any problem in that log snippet. Can you find the
> followup where the helper responds?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From squid3 at treenet.co.nz  Mon Apr 25 18:08:51 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 26 Apr 2016 06:08:51 +1200
Subject: [squid-users] Squid 3.4.8 helpers doesn't work how I want !
In-Reply-To: <CADSSinMMC0DYNsteQSD7v=KdPbxO9rrFhM6U0Y=bR5U0ZFKzoA@mail.gmail.com>
References: <CALOGGjSuYRxNerB5hUFXVkS0M93eeb2BH+cxqO+7b=ovJa9qVw@mail.gmail.com>
 <CADSSinMMC0DYNsteQSD7v=KdPbxO9rrFhM6U0Y=bR5U0ZFKzoA@mail.gmail.com>
Message-ID: <571E5D33.3000601@treenet.co.nz>

On 26/04/2016 3:28 a.m., Jok Thuau wrote:
> On Mon, Apr 25, 2016 at 7:33 AM, Hack Ensolo wrote:
> 
>> ### http_access rules
>> http_access allow manager localhost
>> http_access allow auth
>> http_access deny !auth
>> http_access allow kerbusers
>> http_access allow localnet
>> http_access deny manager
>> http_access deny all
>>
>>
> Since the rules are "first match", once you have "allow auth", squid is
> done. it will not look at the group membership (under "kerbusers").
> 
> you should look at the acl type "all-of" and "any-of" to build your logic:
> acl authn_authz all-of auth kerbusers
> 
> might be helpful and would make your config slightly easier to read...

I this simple case it will just make it a bit more confusing. Especially
since the admin is clearly not understanding the basics properly yet.

It also slows down Squid with additional authentication checks compared
to the config he does need.

> 
> With that in mind, reconsider how you organize the rules...
> 

Seconded. <http://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes>

Amos



From squid3 at treenet.co.nz  Mon Apr 25 18:25:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 26 Apr 2016 06:25:49 +1200
Subject: [squid-users] change between squid 3.1 and 3.3.8
In-Reply-To: <571E48D3.90204@developpement-durable.gouv.fr>
References: <1461336059437-4677229.post@n4.nabble.com>
 <571AEC15.70007@treenet.co.nz> <571E48D3.90204@developpement-durable.gouv.fr>
Message-ID: <571E612D.1030008@treenet.co.nz>

On 26/04/2016 4:41 a.m., TRIFILETTI Frank (Adjoint au chef du DO Sud-Est
/ Chef du groupe expertise technique) - SG/SPSSI/CPII/DOSE/ET wrote:
> Hello Amos,
> 
> thanks for your answer
> 
> my answer in the body of the message below
> 
> Frank
> 
> Le 23/04/2016 05:29, "> Amos Jeffries (par Internet, d?p?t
> squid-users-bounces at lists.squid-cache.org)" a ?crit :
>> On 23/04/2016 2:40 a.m., FTRIF wrote:
>>> Hello,
>>> i have a problem using /usr/lib/squid3/ext_ldap_group_acl which
>>> appears in
>>> 3.3.8
>>>
>>> i have a ldap attribut called InternetAccess which contains the value
>>> "ACCESSINTER"
>>>
>>> i want to make an ACL to authorize such people to surf on the net by
>>> using a
>>> ldap_group, built with the people who had the value ACCESSINTER in
>>> the ldap
>>> attribut called InternetAccess
>>>
>>> in command line it works both with squid 3.1 and 3.3.8, the answer is
>>> OK:
>>>
>>> /usr/lib/squid3/ext_ldap_group_acl -d -b dc=eq,dc=fr -f
>>> "(&(objectclass=person)(InternetAccess=%a)(uid=%u))" myLdapDNSname
>>>
>>> fk.tf ACCESSINTER
>>> ext_ldap_group_acl.cc(587): pid=25599 :Connected OK
>>> ext_ldap_group_acl.cc(726): pid=25599 :group filter
>>> '(&(objectclass=person)(InternetAccess=ACCESSINTER)(uid=fk.tf))',
>>> searchbase
>>> 'dc=eq,dc=fr'
>>> OK
>>
>> Use '%g' macro for group. It will not to collide with URL-encoding of
>> the parameters.
>>
> 
> in the squid.conf i forget indicate that i have a line
> acl profil_ACCESSINTERNET external ldap_group ACCESSINTER
> 
> in command line i replace %a by '%g' in command line but it doesn't work
> only if i put %g
> 
> but in squid.conf i put '%g' instead of %a and i have the same result
> with in the cache.log
> 
> 2016/04/25 18:17:25.835| Acl.cc(319) checklistMatches:
> ACL::checklistMatches: checking 'profil_ACCESSINTERNET'
> 2016/04/25 18:17:25.835| external_acl.cc(793) aclMatchExternal:
> acl="ldap_group"
> 2016/04/25 18:17:25.835| external_acl.cc(822) aclMatchExternal: No
> helper entry available
> 2016/04/25 18:17:25.835| external_acl.cc(826) aclMatchExternal:
> ldap_group check user authenticated.
> 2016/04/25 18:17:25.835| external_acl.cc(832) aclMatchExternal:
> ldap_group user is authenticated.
> 2016/04/25 18:17:25.835| external_acl.cc(856) aclMatchExternal:
> ldap_group("fk.tf ACCESSINTER") = lookup needed
> 2016/04/25 18:17:25.835| external_acl.cc(858) aclMatchExternal: "fk.tf
> ACCESSINTER": entry=@0, age=0
> 2016/04/25 18:17:25.835| external_acl.cc(861) aclMatchExternal: "fk.tf
> ACCESSINTER": queueing a call.
> 2016/04/25 18:17:25.835| external_acl.cc(863) aclMatchExternal: "fk.tf
> ACCESSINTER": return -1.
> 2016/04/25 18:17:25.835| Acl.cc(321) checklistMatches:
> ACL::ChecklistMatches: result for 'profil_ACCESSINTERNET' is -1

These lines are important:

> 2016/04/25 18:17:25.835| Acl.cc(346) matches: profil_ACCESSINTERNET
> needs async lookup
> 2016/04/25 18:17:25.835| Acl.cc(354) matches: profil_ACCESSINTERNET
> result is false
> 2016/04/25 18:30:36.709| Checklist.cc(275) matchNode: 0x7ffdc7f66fb0
> matched=0 async=1 finished=0
> 2016/04/25 18:30:36.709| Checklist.cc(146) markFinished: 0x7ffdc7f66fb0
> answer DUNNO for async required but prohibited
> 2016/04/25 18:30:36.709| Checklist.cc(308) matchNode: 0x7ffdc7f66fb0
> DUNNO because cannot async
> 2016/04/25 18:30:36.709| FilledChecklist.cc(77) ~ACLFilledChecklist:
> ACLFilledChecklist destroyed 0x7ffdc7f66fb0
> 2016/04/25 18:30:36.709| Checklist.cc(334) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0x7ffdc7f66fb0
> 2016/04/25 18:30:36.709| Checklist.cc(153) preCheck: 0x7ffdc7f66fb0
> checking fast rules
> 2016/04/25 18:30:36.709| Checklist.cc(414) fastCheck: aclCheckFast:
> list: 0x56353080b548
> 
> is it these last lines indicate the followup where the helper responds
> you asked for ?

Better. Those lines are saying you are using the group lookup in an
access control list which cannot do group lookups or any other kind of
delayed (async) data lookup.

The answer is needed immediately by the access control and all Squid has
to work with is DUNNO / "insufficient data".

See <http://wiki.squid-cache.org/SquidFaq/SquidAcl#Fast_and_Slow_ACLs>

> 
> if not which type of text i have to search ?
> 
> my debug_options 28,9 82,9 84,9
> section 82 External AC
> section 84 Helper process maintenance
> section 28 Access Control
> 

Okay.

The -d parameter on the helper command line for Squid helpers produces
their internal debug.


Amos



From squid3 at treenet.co.nz  Mon Apr 25 18:36:15 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 26 Apr 2016 06:36:15 +1200
Subject: [squid-users] Logging ACL that triggered denied access with
 http_access
In-Reply-To: <571E3CED.7090907@borrill.org.uk>
References: <571E3CED.7090907@borrill.org.uk>
Message-ID: <571E639F.2010507@treenet.co.nz>

On 26/04/2016 3:51 a.m., Stephen Borrill wrote:
> Is there a way to log which ACL caused a block with http_access? This
> information is present for deny_info to use, but I cannot see a entry I
> can add to logformat to present such a thing in a custom log format (if
> using an external acl helper, you can spoof something up with the et and
> ea formats).
> 

There is no single ACL which does so. Even if you configure only one ACL
name per access control line in all access controls of squid.conf it is
sequences of ACLs both matching and non-matching (across multiple access
control types) which lead to a particular denial *line* happening.

The deny_info is not logging any single one ACL that did blocking. It is
logging the ACL name to which the deny_info action is attached. Same for
the external_acl_type %ACL parameter displaying the ACL it has been
called on.

Amos



From squid3 at treenet.co.nz  Mon Apr 25 18:39:22 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 26 Apr 2016 06:39:22 +1200
Subject: [squid-users] Squid SSL Bump
In-Reply-To: <1461551660811-4677261.post@n4.nabble.com>
References: <1330359101.420588.1461351730784.JavaMail.yahoo@mail.yahoo.com>
 <571AF12B.9000003@treenet.co.nz> <1461551660811-4677261.post@n4.nabble.com>
Message-ID: <571E645A.7040302@treenet.co.nz>

On 25/04/2016 2:34 p.m., skeetz9r wrote:
> UPDATE **
> 
> On more digging it seems like the SSL server is using SHA 1 and that may be
> the issue here. Any way around that?
> 

Check out the options your OpenSSL library supports. It may or may not
support SHA1 being added to the allowed hashes list. You will need to do
that as well as adding the broken cert to the set loaded by
sslproxy_cafiles directive.

Amos



From squid3 at treenet.co.nz  Mon Apr 25 18:40:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 26 Apr 2016 06:40:59 +1200
Subject: [squid-users] NTLM_AUTH authentification send BH SPNEGO request
 invalid prefix
In-Reply-To: <CALOGGjTj3yDkh7RdKQ8ww+VDj-_fEQO1R+eKSTk1xS1zVmTf4A@mail.gmail.com>
References: <CALOGGjTj3yDkh7RdKQ8ww+VDj-_fEQO1R+eKSTk1xS1zVmTf4A@mail.gmail.com>
Message-ID: <571E64BB.9080500@treenet.co.nz>

On 25/04/2016 2:11 a.m., Hack Ensolo wrote:
> Hi,
> I try to log a user who is in active directory group "webusers" with
> ntlm_auth
> but I have some problems.
> 

The first being that "SPNEGO ..." is a Kerberos authentication error
output by Negotiate authentication.

Amos



From squid3 at treenet.co.nz  Tue Apr 26 03:24:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 26 Apr 2016 15:24:08 +1200
Subject: [squid-users] Attached file on OWA with Squid
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5837FD1648@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD147F@CPUMAIL2.cpu.qc.ca>
 <5708820A.8090303@treenet.co.nz>
 <5FE0959288C73D448BB44CB7E9CC320F5837FD15BB@CPUMAIL2.cpu.qc.ca>
 <5FE0959288C73D448BB44CB7E9CC320F5837FD1648@CPUMAIL2.cpu.qc.ca>
Message-ID: <571EDF58.5000200@treenet.co.nz>

On 26/04/2016 3:16 a.m., Sebastien.Boulianne wrote:
> Hi all,
> 
> I changed the status from 302 to 308.
> 
> I can now upload a small txt files but if I try to attach a file bigger than 1meg, I got the same issue as the begginning... The browser freeze and nothing happens.
> 

Hmm. That sounds familiar but my mind is too fuzzy with other things
right now. You might have some luck searching this lists archives for
earlier posts about OWA.


> What else can I try ?

Telling us the output of squid -v ?

"latest Squid" could be any one of the 4 tarballs we publish, or several
dozen downstream binary versions which vendors publish.

Amos



From Sebastien.Boulianne at cpu.ca  Tue Apr 26 13:08:19 2016
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Tue, 26 Apr 2016 09:08:19 -0400
Subject: [squid-users] Attached file on OWA with Squid
In-Reply-To: <571EDF58.5000200@treenet.co.nz>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD147F@CPUMAIL2.cpu.qc.ca>
 <5708820A.8090303@treenet.co.nz>
 <5FE0959288C73D448BB44CB7E9CC320F5837FD15BB@CPUMAIL2.cpu.qc.ca>
 <5FE0959288C73D448BB44CB7E9CC320F5837FD1648@CPUMAIL2.cpu.qc.ca>
 <571EDF58.5000200@treenet.co.nz>
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5837FD165C@CPUMAIL2.cpu.qc.ca>

Hi Amos,

Thanks you very much for your great answer.

I already checked in the list archives but I couldn?t find anything.

Here is my Squid version detail.
I use the Eliezer's package. :)

squid -v
Squid Cache: Version 3.5.16
Service Name: squid
configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--verbose' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' '--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake' '--enable-auth-ntlm=smb_lm,fake' '--enable-auth-digest=file,LDAP,eDirectory' '--enable-auth-negotiate=kerberos,wrapper' '--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,file_userip,SQL_session,unix_group,session,time_quota' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi' '--enable-ssl-crtd' '--enable-icmp' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads' '--with-included-ltdl' '--disable-arch-native' '--enable-ecap' '--without-nettle' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic' 'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -fPIC' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' --enable-ltdl-convenience

S?bastien

-----Message d'origine-----
De?: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Envoy??: 25 avril 2016 23:24
??: Sebastien Boulianne <Sebastien.Boulianne at cpu.ca>; squid-users at lists.squid-cache.org
Objet?: Re: [squid-users] Attached file on OWA with Squid

On 26/04/2016 3:16 a.m., Sebastien.Boulianne wrote:
> Hi all,
> 
> I changed the status from 302 to 308.
> 
> I can now upload a small txt files but if I try to attach a file bigger than 1meg, I got the same issue as the begginning... The browser freeze and nothing happens.
> 

Hmm. That sounds familiar but my mind is too fuzzy with other things right now. You might have some luck searching this lists archives for earlier posts about OWA.


> What else can I try ?

Telling us the output of squid -v ?

"latest Squid" could be any one of the 4 tarballs we publish, or several dozen downstream binary versions which vendors publish.

Amos


From amadaan at ncsu.edu  Tue Apr 26 19:20:42 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Tue, 26 Apr 2016 15:20:42 -0400
Subject: [squid-users] Logging in squid
Message-ID: <CAO4ouAZndvtRh6pGc3GzUHCVnVJ=kAExw7EgVadU2jvpknhm3A@mail.gmail.com>

Hey,

I have kept squid between a proxy and a server. Requests and response pass
from proxy to squid to server and back.

Does squid has any other logs except cache.log and access.log?  are there
any ways to improve squid logging or enable any debug logs?

Thanks
Aashima
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160426/bb049f78/attachment.htm>

From yvoinov at gmail.com  Tue Apr 26 19:32:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 01:32:31 +0600
Subject: [squid-users] Logging in squid
In-Reply-To: <CAO4ouAZndvtRh6pGc3GzUHCVnVJ=kAExw7EgVadU2jvpknhm3A@mail.gmail.com>
References: <CAO4ouAZndvtRh6pGc3GzUHCVnVJ=kAExw7EgVadU2jvpknhm3A@mail.gmail.com>
Message-ID: <0252a1ad-0a1d-2928-752b-a1cb9e665b27@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Read squid.cache.documented carefully again:

# LOGFILE OPTIONS
#
-----------------------------------------------------------------------------

#  TAG: logformat
#    Usage:
#
#    logformat <name> <format specification>
#
#    Defines an access log format.
#
#    The <format specification> is a string with embedded % format codes
#
#    % format codes all follow the same basic structure where all but
#    the formatcode is optional. Output strings are automatically escaped
#    as required according to their context and the output format
#    modifiers are usually not needed, but can be specified if an explicit
#    output format is desired.
#
#        % ["|[|'|#] [-] [[0]width] [{argument}] formatcode
#
#        "    output in quoted string format
#        [    output in squid text log format as used by log_mime_hdrs
#        #    output in URL quoted format
#        '    output as-is
#
#        -    left aligned
#
#        width    minimum and/or maximum field width:
#                [width_min][.width_max]
#            When minimum starts with 0, the field is zero-padded.
#            String values exceeding maximum width are truncated.
#
#        {arg}    argument such as header name etc
#
#    Format codes:
#
#        %    a literal % character
#        sn    Unique sequence number per log line entry
#        err_code    The ID of an error response served by Squid or
#                a similar internal error identifier.
#        err_detail  Additional err_code-dependent error information.
#        note    The annotation specified by the argument. Also
#            logs the adaptation meta headers set by the
#            adaptation_meta configuration parameter.
#            If no argument given all annotations logged.
#            The argument may include a separator to use with
#            annotation values:
#                            name[:separator]
#            By default, multiple note values are separated with ","
#            and multiple notes are separated with "\r\n".
#            When logging named notes with %{name}note, the
#            explicitly configured separator is used between note
#            values. When logging all notes with %note, the
#            explicitly configured separator is used between
#            individual notes. There is currently no way to
#            specify both value and notes separators when logging
#            all notes with %note.
#
#    Connection related format codes:
#
#        >a    Client source IP address
#        >A    Client FQDN
#        >p    Client source port
#        >eui    Client source EUI (MAC address, EUI-48 or EUI-64
identifier)
#        >la    Local IP address the client connected to
#        >lp    Local port number the client connected to
#        >qos    Client connection TOS/DSCP value set by Squid
#        >nfmark Client connection netfilter mark set by Squid
#
#        la    Local listening IP address the client connection was
connected to.
#        lp    Local listening port number the client connection was
connected to.
#
#        <a    Server IP address of the last server or peer connection
#        <A    Server FQDN or peer name
#        <p    Server port number of the last server or peer connection
#        <la    Local IP address of the last server or peer connection
#        <lp     Local port number of the last server or peer connection
#        <qos    Server connection TOS/DSCP value set by Squid
#        <nfmark Server connection netfilter mark set by Squid
#
#    Time related format codes:
#
#        ts    Seconds since epoch
#        tu    subsecond time (milliseconds)
#        tl    Local time. Optional strftime format argument
#                default %d/%b/%Y:%H:%M:%S %z
#        tg    GMT time. Optional strftime format argument
#                default %d/%b/%Y:%H:%M:%S %z
#        tr    Response time (milliseconds)
#        dt    Total time spent making DNS lookups (milliseconds)
#        tS    Approximate master transaction start time in
#            <full seconds since epoch>.<fractional seconds> format.
#            Currently, Squid considers the master transaction
#            started when a complete HTTP request header initiating
#            the transaction is received from the client. This is
#            the same value that Squid uses to calculate transaction
#            response time when logging %tr to access.log. Currently,
#            Squid uses millisecond resolution for %tS values,
#            similar to the default access.log "current time" field
#            (%ts.%03tu).
#
#    Access Control related format codes:
#
#        et    Tag returned by external acl
#        ea    Log string returned by external acl
#        un    User name (any available)
#        ul    User name from authentication
#        ue    User name from external acl helper
#        ui    User name from ident
#        un    A user name. Expands to the first available name
#            from the following list of information sources:
#            - authenticated user name, like %ul
#            - user name supplied by an external ACL, like %ue
#            - SSL client name, like %us
#            - ident user name, like %ui
#        credentials Client credentials. The exact meaning depends on
#            the authentication scheme: For Basic authentication,
#            it is the password; for Digest, the realm sent by the
#            client; for NTLM and Negotiate, the client challenge
#            or client credentials prefixed with "YR " or "KK ".
#
#    HTTP related format codes:
#
#        REQUEST
#
#        [http::]rm    Request method (GET/POST etc)
#        [http::]>rm    Request method from client
#        [http::]<rm    Request method sent to server or peer
#        [http::]ru    Request URL from client (historic, filtered for
logging)
#        [http::]>ru    Request URL from client
#        [http::]<ru    Request URL sent to server or peer
#        [http::]>rs    Request URL scheme from client
#        [http::]<rs    Request URL scheme sent to server or peer
#        [http::]>rd    Request URL domain from client
#        [http::]<rd    Request URL domain sent to server or peer
#        [http::]>rP    Request URL port from client
#        [http::]<rP    Request URL port sent to server or peer
#        [http::]rp    Request URL path excluding hostname
#        [http::]>rp    Request URL path excluding hostname from client
#        [http::]<rp    Request URL path excluding hostname sent to
server or peer
#        [http::]rv    Request protocol version
#        [http::]>rv    Request protocol version from client
#        [http::]<rv    Request protocol version sent to server or peer
#
#        [http::]>h    Original received request header.
#                Usually differs from the request header sent by
#                Squid, although most fields are often preserved.
#                Accepts optional header field name/value filter
#                argument using name[:[separator]element] format.
#        [http::]>ha    Received request header after adaptation and
#                redirection (pre-cache REQMOD vectoring point).
#                Usually differs from the request header sent by
#                Squid, although most fields are often preserved.
#                Optional header name argument as for >h
#
#
#        RESPONSE
#
#        [http::]<Hs    HTTP status code received from the next hop
#        [http::]>Hs    HTTP status code sent to the client
#
#        [http::]<h    Reply header. Optional header name argument
#                as for >h
#
#        [http::]mt    MIME content type
#
#
#        SIZE COUNTERS
#
#        [http::]st    Total size of request + reply traffic with client
#        [http::]>st    Total size of request received from client.
#                Excluding chunked encoding bytes.
#        [http::]<st    Total size of reply sent to client (after
adaptation)
#
#        [http::]>sh    Size of request headers received from client
#        [http::]<sh    Size of reply headers sent to client (after
adaptation)
#
#        [http::]<sH    Reply high offset sent
#        [http::]<sS    Upstream object size
#
#        [http::]<bs    Number of HTTP-equivalent message body bytes
#                received from the next hop, excluding chunked
#                transfer encoding and control messages.
#                Generated FTP/Gopher listings are treated as
#                received bodies.
#
#
#        TIMING
#
#        [http::]<pt    Peer response time in milliseconds. The timer starts
#                when the last request byte is sent to the next hop
#                and stops when the last response byte is received.
#        [http::]<tt    Total time in milliseconds. The timer
#                starts with the first connect request (or write I/O)
#                sent to the first selected peer. The timer stops
#                with the last I/O with the last peer.
#
#    Squid handling related format codes:
#
#        Ss    Squid request status (TCP_MISS etc)
#        Sh    Squid hierarchy status (DEFAULT_PARENT etc)
#
#    SSL-related format codes:
#
#        ssl::bump_mode    SslBump decision for the transaction:
#
#                For CONNECT requests that initiated bumping of
#                a connection and for any request received on
#                an already bumped connection, Squid logs the
#                corresponding SslBump mode ("server-first" or
#                "client-first"). See the ssl_bump option for
#                more information about these modes.
#
#                A "none" token is logged for requests that
#                triggered "ssl_bump" ACL evaluation matching
#                either a "none" rule or no rules at all.
#
#                In all other cases, a single dash ("-") is
#                logged.
#
#        ssl::>sni    SSL client SNI sent to Squid. Available only
#                after the peek, stare, or splice SSL bumping
#                actions.
#
#    If ICAP is enabled, the following code becomes available (as
#    well as ICAP log codes documented with the icap_log option):
#
#        icap::tt        Total ICAP processing time for the HTTP
#                transaction. The timer ticks when ICAP
#                ACLs are checked and when ICAP
#                transaction is in progress.
#
#    If adaptation is enabled the following three codes become available:
#
#        adapt::<last_h    The header of the last ICAP response or
#                meta-information from the last eCAP
#                transaction related to the HTTP transaction.
#                Like <h, accepts an optional header name
#                argument.
#
#        adapt::sum_trs Summed adaptation transaction response
#                times recorded as a comma-separated list in
#                the order of transaction start time. Each time
#                value is recorded as an integer number,
#                representing response time of one or more
#                adaptation (ICAP or eCAP) transaction in
#                milliseconds.  When a failed transaction is
#                being retried or repeated, its time is not
#                logged individually but added to the
#                replacement (next) transaction. See also:
#                adapt::all_trs.
#
#        adapt::all_trs All adaptation transaction response times.
#                Same as adaptation_strs but response times of
#                individual transactions are never added
#                together. Instead, all transaction response
#                times are recorded individually.
#
#    You can prefix adapt::*_trs format codes with adaptation
#    service name in curly braces to record response time(s) specific
#    to that service. For example: %{my_service}adapt::sum_trs
#
#    If SSL is enabled, the following formating codes become available:
#
#        %ssl::>cert_subject The Subject field of the received client
#                SSL certificate or a dash ('-') if Squid has
#                received an invalid/malformed certificate or
#                no certificate at all. Consider encoding the
#                logged value because Subject often has spaces.
#
#        %ssl::>cert_issuer The Issuer field of the received client
#                SSL certificate or a dash ('-') if Squid has
#                received an invalid/malformed certificate or
#                no certificate at all. Consider encoding the
#                logged value because Issuer often has spaces.
#
#    The default formats available (which do not need re-defining) are:
#
#logformat squid      %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un
%Sh/%<a %mt
#logformat common     %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
%Ss:%Sh
#logformat combined   %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
"%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
#logformat referrer   %ts.%03tu %>a %{Referer}>h %ru
#logformat useragent  %>a [%tl] "%{User-Agent}>h"
#
#    NOTE: When the log_mime_hdrs directive is set to ON.
#        The squid, common and combined formats have a safely encoded copy
#        of the mime headers appended to each line within a pair of
brackets.
#
#    NOTE: The common and combined formats are not quite true to the
Apache definition.
#        The logs from Squid contain an extra status and hierarchy code
appended.
#
#Default:
# The format definitions squid, common, combined, referrer, useragent
are built in.

#  TAG: access_log
#    Configures whether and how Squid logs HTTP and ICP transactions.
#    If access logging is enabled, a single line is logged for every
#    matching HTTP or ICP request. The recommended directive formats are:
#
#    access_log <module>:<place> [option ...] [acl acl ...]
#    access_log none [acl acl ...]
#
#    The following directive format is accepted but may be deprecated:
#    access_log <module>:<place> [<logformat name> [acl acl ...]]
#
#        In most cases, the first ACL name must not contain the '='
character
#    and should not be equal to an existing logformat name. You can always
#    start with an 'all' ACL to work around those restrictions.
#   
#    Will log to the specified module:place using the specified format
(which
#    must be defined in a logformat directive) those entries which match
#    ALL the acl's specified (which must be defined in acl clauses).
#    If no acl is specified, all requests will be logged to this
destination.
#   
#    ===== Available options for the recommended directive format =====
#
#    logformat=name        Names log line format (either built-in or
#                defined by a logformat directive). Defaults
#                to 'squid'.
#
#    buffer-size=64KB    Defines approximate buffering limit for log
#                records (see buffered_logs).  Squid should not
#                keep more than the specified size and, hence,
#                should flush records before the buffer becomes
#                full to avoid overflows under normal
#                conditions (the exact flushing algorithm is
#                module-dependent though).  The on-error option
#                controls overflow handling.
#
#    on-error=die|drop    Defines action on unrecoverable errors. The
#                'drop' action ignores (i.e., does not log)
#                affected log records. The default 'die' action
#                kills the affected worker. The drop action
#                support has not been tested for modules other
#                than tcp.
#
#    ===== Modules Currently available =====
#   
#    none    Do not log any requests matching these ACL.
#        Do not specify Place or logformat name.
#   
#    stdio    Write each log line to disk immediately at the completion of
#        each request.
#        Place: the filename and path to be written.
#   
#    daemon    Very similar to stdio. But instead of writing to disk the log
#        line is passed to a daemon helper for asychronous handling instead.
#        Place: varies depending on the daemon.
#       
#        log_file_daemon Place: the file name and path to be written.
#   
#    syslog    To log each request via syslog facility.
#        Place: The syslog facility and priority level for these entries.
#        Place Format:  facility.priority
#
#        where facility could be any of:
#            authpriv, daemon, local0 ... local7 or user.
#
#        And priority could be any of:
#            err, warning, notice, info, debug.
#   
#    udp    To send each log line as text data to a UDP receiver.
#        Place: The destination host name or IP and port.
#        Place Format:   //host:port
#
#    tcp    To send each log line as text data to a TCP receiver.
#        Lines may be accumulated before sending (see buffered_logs).
#        Place: The destination host name or IP and port.
#        Place Format:   //host:port
#
#    Default:
#        access_log daemon:/usr/local/squid/var/logs/access.log squid
#Default:
# access_log daemon:/usr/local/squid/var/logs/access.log squid

You can define any custom access.log, for example, and write this custom
log at the same time.

27.04.16 1:20, Aashima Madaan ?????:
> Hey,
>
> I have kept squid between a proxy and a server. Requests and response
pass from proxy to squid to server and back.
>
> Does squid has any other logs except cache.log and access.log?  are
there any ways to improve squid logging or enable any debug logs?
>
> Thanks
> Aashima
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXH8JPAAoJENNXIZxhPexGB88H/2wnTr0o3K/A9hkHcMHzE/fj
CzOOL5B0YYijwk4m+8UBqmBkt6WQVc5AeWASmzHsxjh6/wqRK8up8dOmgS7uSbI+
wM+5c8AhvcBQlMkHQB58bMbcBKjxZVFeo/YYD8iglZ/o95Fflv+6d+Tv2Wh0s7Bb
iKN2riLryC244OciEiNTjU9TpaofsmOAGvTddoJerZse43Az9av7B4xLWfhs6NRs
LY6zk1Rj/QXF/U1CH9Lnxs84LfyuPDXuC1q+/jfYgbr7f1UZPrOV7wuQo7DksmHi
V3T53mfg2qRqShjo/Ezxc+YMkfgmouGR4Nz2UQekOfphFqrHNCuB6Jmyh3NkaiA=
=rx3x
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/ebcc8d44/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/ebcc8d44/attachment.key>

From maile.halatuituia at tcc.to  Tue Apr 26 21:05:00 2016
From: maile.halatuituia at tcc.to (maileh)
Date: Tue, 26 Apr 2016 14:05:00 -0700 (PDT)
Subject: [squid-users] help for my intercept proxy setup
Message-ID: <1461704700055-4677279.post@n4.nabble.com>

Hi
Here is my router wccp config
In global config i enable ip wccp 
#ip wccp web-cache redirect-list WCCP_HTTP
#ip wccp 70 redirect-list WCCP_HTTPS
Interface facing my Clients and also Squid is in the same subnet

int g0/0.904
ip wccp web-cache redirect out
ip wccp 70 redirect out.

Verification

#sh ip wccp sum
WCCP version 2 enabled, 2 services

Service     Clients   Routers   Assign      Redirect   Bypass
-------     -------   -------   ------      --------   ------
Default routing table (Router Id: x.x.x.x):
web-cache   1         1         HASH        GRE        GRE
70                  1         1         HASH        GRE        GRE

#sh tunnel groups wccp
 WCCP : service group 0 in "Default", ver v2, assgnmnt: hash-table
   intf: Tunnel2, locally sourced
 WCCP : service group 326 in "Default", ver v2, assgnmnt: hash-table
   intf: Tunnel0, locally sourced

#sh adjacency tunnel 0 detail
Protocol Interface                 Address
IP       Tunnel0                   10.240.0.30(3)
                                   connectionid 1
                                   0 packets, 0 bytes
                                   epoch 0
                                   sourced in sev-epoch 31
                                   Encap length 28
                                   4500000000000000FF2FC732CA861F08
                                   0AF0001E0000883E01460000
                                   Tun endpt
                                   Next chain element:
                                    IP adj out of GigabitEthernet0/0.904,
addr 10.240.0.30
#sh adjacency tunnel 2 detail
    Protocol Interface                 Address
IP       Tunnel2                   10.240.0.30(3)
                                   connectionid 1
                                   0 packets, 0 bytes
                                   epoch 0
                                   sourced in sev-epoch 32
                                   Encap length 28
                                   4500000000000000FF2FC732CA861F08
                                   0AF0001E0000883E00000000
                                   Tun endpt
                                   Next chain element:
                                    IP adj out of GigabitEthernet0/0.904,
addr 10.240.0.30
#sh ip wccp web-cache detail
WCCP Client information:
        WCCP Client ID:          10.240.0.30
        Protocol Version:        2.0
        State:                   Usable
        Redirection:             GRE
        Packet Return:           GRE
        Assignment:              HASH
        Initial Hash Info:       00000000000000000000000000000000
                                 00000000000000000000000000000000
        Assigned Hash Info:      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
                                 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
        Hash Allotment:          256 (100.00%)
        Packets s/w Redirected:  0
        Connect Time:            00:08:42
        GRE Bypassed Packets
          Process:               0
          CEF:                   0
          Errors:                0
If you can see all seems to be established between the router and squid box
but no PACKET has been redirected.
For my IOS
ROM: System Bootstrap, Version 15.0(1r)M15, RELEASE SOFTWARE (fc1)

It's been over two weeks now and i seems to looking everywhere but no luck. 
Also here is my iptables rules for you info whch run on ubuntu 14.04 with
squid 

# squid -v
Squid Cache: Version 3.5.16
Service Name: squid
Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC Production
configure options:  '--prefix=/usr/local' '--enable-translation'
'--enable-external-acl-helpers=none' '--enable-storeio=ufs,aufs,diskd,rock'
'--enable-removal-policies=lru,heap' '--enable-wccp2'
'--enable-follow-x-forwarded-for' '--enable-cache-digests'
'--enable-auth-negotiate=none' '--disable-auth-digest' '--disable-auth-ntlm'
'--disable-url-rewrite-helpers' '--enable-storeid-rewrite-helpers=file'
'--enable-log-daemon-helpers=file' '--with-openssl=/usr/local'
'--enable-ssl' '--enable-ssl-crtd' '--enable-zph-qos' '--enable-snmp'
'--enable-inline' '--with-dl' '--with-build-environment=POSIX_V6_LP64_OFF64'
'CFLAGS=-O3 -m64 -pipe' 'CXXFLAGS=-O3 -m64 -pipe'
'LIBOPENSSL_CFLAGS=-I/usr/local/include'
'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig' '--disable-strict-error-checking'
'--enable-build-info=Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC
Production'
IPtables Rules for redirection to squid ports
-A PREROUTING -i wccp0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3127
-A PREROUTING -i wccp0 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129
-A POSTROUTING -j MASQUERADE


Appreciate you kind asistance ....
hanks in advance
Maile



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue Apr 26 21:57:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 03:57:21 +0600
Subject: [squid-users] help for my intercept proxy setup
In-Reply-To: <1461704700055-4677279.post@n4.nabble.com>
References: <1461704700055-4677279.post@n4.nabble.com>
Message-ID: <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Show WCCP section of yout squid.conf please.


27.04.16 3:05, maileh ?????:
> Hi
> Here is my router wccp config
> In global config i enable ip wccp
> #ip wccp web-cache redirect-list WCCP_HTTP
> #ip wccp 70 redirect-list WCCP_HTTPS
> Interface facing my Clients and also Squid is in the same subnet
>
> int g0/0.904
> ip wccp web-cache redirect out
> ip wccp 70 redirect out.
>
> Verification
>
> #sh ip wccp sum
> WCCP version 2 enabled, 2 services
>
> Service     Clients   Routers   Assign      Redirect   Bypass
> -------     -------   -------   ------      --------   ------
> Default routing table (Router Id: x.x.x.x):
> web-cache   1         1         HASH        GRE        GRE
> 70                  1         1         HASH        GRE        GRE
>
> #sh tunnel groups wccp
>  WCCP : service group 0 in "Default", ver v2, assgnmnt: hash-table
>    intf: Tunnel2, locally sourced
>  WCCP : service group 326 in "Default", ver v2, assgnmnt: hash-table
>    intf: Tunnel0, locally sourced
>
> #sh adjacency tunnel 0 detail
> Protocol Interface                 Address
> IP       Tunnel0                   10.240.0.30(3)
>                                    connectionid 1
>                                    0 packets, 0 bytes
>                                    epoch 0
>                                    sourced in sev-epoch 31
>                                    Encap length 28
>                                    4500000000000000FF2FC732CA861F08
>                                    0AF0001E0000883E01460000
>                                    Tun endpt
>                                    Next chain element:
>                                     IP adj out of GigabitEthernet0/0.904,
> addr 10.240.0.30
> #sh adjacency tunnel 2 detail
>     Protocol Interface                 Address
> IP       Tunnel2                   10.240.0.30(3)
>                                    connectionid 1
>                                    0 packets, 0 bytes
>                                    epoch 0
>                                    sourced in sev-epoch 32
>                                    Encap length 28
>                                    4500000000000000FF2FC732CA861F08
>                                    0AF0001E0000883E00000000
>                                    Tun endpt
>                                    Next chain element:
>                                     IP adj out of GigabitEthernet0/0.904,
> addr 10.240.0.30
> #sh ip wccp web-cache detail
> WCCP Client information:
>         WCCP Client ID:          10.240.0.30
>         Protocol Version:        2.0
>         State:                   Usable
>         Redirection:             GRE
>         Packet Return:           GRE
>         Assignment:              HASH
>         Initial Hash Info:       00000000000000000000000000000000
>                                  00000000000000000000000000000000
>         Assigned Hash Info:      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
>                                  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
>         Hash Allotment:          256 (100.00%)
>         Packets s/w Redirected:  0
>         Connect Time:            00:08:42
>         GRE Bypassed Packets
>           Process:               0
>           CEF:                   0
>           Errors:                0
> If you can see all seems to be established between the router and
squid box
> but no PACKET has been redirected.
> For my IOS
> ROM: System Bootstrap, Version 15.0(1r)M15, RELEASE SOFTWARE (fc1)
>
> It's been over two weeks now and i seems to looking everywhere but no
luck.
> Also here is my iptables rules for you info whch run on ubuntu 14.04 with
> squid
>
> # squid -v
> Squid Cache: Version 3.5.16
> Service Name: squid
> Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC Production
> configure options:  '--prefix=/usr/local' '--enable-translation'
> '--enable-external-acl-helpers=none'
'--enable-storeio=ufs,aufs,diskd,rock'
> '--enable-removal-policies=lru,heap' '--enable-wccp2'
> '--enable-follow-x-forwarded-for' '--enable-cache-digests'
> '--enable-auth-negotiate=none' '--disable-auth-digest'
'--disable-auth-ntlm'
> '--disable-url-rewrite-helpers' '--enable-storeid-rewrite-helpers=file'
> '--enable-log-daemon-helpers=file' '--with-openssl=/usr/local'
> '--enable-ssl' '--enable-ssl-crtd' '--enable-zph-qos' '--enable-snmp'
> '--enable-inline' '--with-dl'
'--with-build-environment=POSIX_V6_LP64_OFF64'
> 'CFLAGS=-O3 -m64 -pipe' 'CXXFLAGS=-O3 -m64 -pipe'
> 'LIBOPENSSL_CFLAGS=-I/usr/local/include'
> 'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig'
'--disable-strict-error-checking'
>
'--enable-build-info=Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC
> Production'
> IPtables Rules for redirection to squid ports
> -A PREROUTING -i wccp0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports
3127
> -A PREROUTING -i wccp0 -p tcp -m tcp --dport 443 -j REDIRECT
--to-ports 3129
> -A POSTROUTING -j MASQUERADE
>
>
> Appreciate you kind asistance ....
> hanks in advance
> Maile
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXH+RBAAoJENNXIZxhPexG174H/3r5IBojH3EKdMCMknRQjwD3
RVrM29M9K3VQX4U2UXj8RVYoBWju+X4NQDtDn/k21Zd3albE/L9bFP0fmPEMb1z1
r0hPUoskPBFqXXYUp6NZ4Yi8TNbbvgvbJ1tGWeMdPWaoE/qvv1tqAKBHeGCCcM2A
P67chV8418cUsTqRyOYCKF9ad4fj1FobWRr9/o826PQ+azCVN0xDD3BjswB8DAzE
i+ZCHCIAEOyCwis84nFb2EqvKGnlqN64WrOkJ6IkFHKxuWg8PTqWnj+NZmMuzhkf
VsMvKrVxd/w9Eh1T6xW0CGfxG/B9V8bCXId0ez0NPyLr/H7kiFqYPNlWZyzCBIw=
=G5AM
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/7d74fd32/attachment.key>

From maile.halatuituia at tcc.to  Tue Apr 26 21:27:45 2016
From: maile.halatuituia at tcc.to (maileh)
Date: Tue, 26 Apr 2016 14:27:45 -0700 (PDT)
Subject: [squid-users] help for my intercept proxy setup
In-Reply-To: <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>
References: <1461704700055-4677279.post@n4.nabble.com>
 <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>
Message-ID: <f4b1ccda23934f5791f3ff5872494d68@mail.tcc.to>

wccp2_router 10.240.0.254
wccp_version 4
wccp2_forwarding_method gre
wccp2_return_method gre
wccp2_rebuild_wait off
wccp2_assignment_method hash
wccp2_service standard 0
wccp2_service dynamic 70
wccp2_service_info 70 protocol=tcp flags=dst_ip_hash,src_ip_alt_hash,src_port_alt_hash priority=240 ports=443,80
always_direct allow all

?
thanks


________________________________
From: Yuri Voinov [via Squid Web Proxy Cache] <ml-node+s1019090n4677280h0 at n4.nabble.com>
Sent: Wednesday, April 27, 2016 10:24 AM
To: Maile Halatuituia
Subject: Re: help for my intercept proxy setup


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

Show WCCP section of yout squid.conf please.


27.04.16 3:05, maileh ?????:

> Hi
> Here is my router wccp config
> In global config i enable ip wccp
> #ip wccp web-cache redirect-list WCCP_HTTP
> #ip wccp 70 redirect-list WCCP_HTTPS
> Interface facing my Clients and also Squid is in the same subnet
>
> int g0/0.904
> ip wccp web-cache redirect out
> ip wccp 70 redirect out.
>
> Verification
>
> #sh ip wccp sum
> WCCP version 2 enabled, 2 services
>
> Service     Clients   Routers   Assign      Redirect   Bypass
> -------     -------   -------   ------      --------   ------
> Default routing table (Router Id: x.x.x.x):
> web-cache   1         1         HASH        GRE        GRE
> 70                  1         1         HASH        GRE        GRE
>
> #sh tunnel groups wccp
>  WCCP : service group 0 in "Default", ver v2, assgnmnt: hash-table
>    intf: Tunnel2, locally sourced
>  WCCP : service group 326 in "Default", ver v2, assgnmnt: hash-table
>    intf: Tunnel0, locally sourced
>
> #sh adjacency tunnel 0 detail
> Protocol Interface                 Address
> IP       Tunnel0                   10.240.0.30(3)
>                                    connectionid 1
>                                    0 packets, 0 bytes
>                                    epoch 0
>                                    sourced in sev-epoch 31
>                                    Encap length 28
>                                    4500000000000000FF2FC732CA861F08
>                                    0AF0001E0000883E01460000
>                                    Tun endpt
>                                    Next chain element:
>                                     IP adj out of GigabitEthernet0/0.904,
> addr 10.240.0.30
> #sh adjacency tunnel 2 detail
>     Protocol Interface                 Address
> IP       Tunnel2                   10.240.0.30(3)
>                                    connectionid 1
>                                    0 packets, 0 bytes
>                                    epoch 0
>                                    sourced in sev-epoch 32
>                                    Encap length 28
>                                    4500000000000000FF2FC732CA861F08
>                                    0AF0001E0000883E00000000
>                                    Tun endpt
>                                    Next chain element:
>                                     IP adj out of GigabitEthernet0/0.904,
> addr 10.240.0.30
> #sh ip wccp web-cache detail
> WCCP Client information:
>         WCCP Client ID:          10.240.0.30
>         Protocol Version:        2.0
>         State:                   Usable
>         Redirection:             GRE
>         Packet Return:           GRE
>         Assignment:              HASH
>         Initial Hash Info:       00000000000000000000000000000000
>                                  00000000000000000000000000000000
>         Assigned Hash Info:      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
>                                  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
>         Hash Allotment:          256 (100.00%)
>         Packets s/w Redirected:  0
>         Connect Time:            00:08:42
>         GRE Bypassed Packets
>           Process:               0
>           CEF:                   0
>           Errors:                0
> If you can see all seems to be established between the router and
squid box
> but no PACKET has been redirected.
> For my IOS
> ROM: System Bootstrap, Version 15.0(1r)M15, RELEASE SOFTWARE (fc1)
>
> It's been over two weeks now and i seems to looking everywhere but no
luck.
> Also here is my iptables rules for you info whch run on ubuntu 14.04 with
> squid
>
> # squid -v
> Squid Cache: Version 3.5.16
> Service Name: squid
> Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC Production
> configure options:  '--prefix=/usr/local' '--enable-translation'
> '--enable-external-acl-helpers=none'
'--enable-storeio=ufs,aufs,diskd,rock'
> '--enable-removal-policies=lru,heap' '--enable-wccp2'
> '--enable-follow-x-forwarded-for' '--enable-cache-digests'
> '--enable-auth-negotiate=none' '--disable-auth-digest'
'--disable-auth-ntlm'
> '--disable-url-rewrite-helpers' '--enable-storeid-rewrite-helpers=file'
> '--enable-log-daemon-helpers=file' '--with-openssl=/usr/local'
> '--enable-ssl' '--enable-ssl-crtd' '--enable-zph-qos' '--enable-snmp'
> '--enable-inline' '--with-dl'
'--with-build-environment=POSIX_V6_LP64_OFF64'
> 'CFLAGS=-O3 -m64 -pipe' 'CXXFLAGS=-O3 -m64 -pipe'
> 'LIBOPENSSL_CFLAGS=-I/usr/local/include'
> 'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig'
'--disable-strict-error-checking'
>
'--enable-build-info=Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC
> Production'
> IPtables Rules for redirection to squid ports
> -A PREROUTING -i wccp0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports
3127
> -A PREROUTING -i wccp0 -p tcp -m tcp --dport 443 -j REDIRECT
--to-ports 3129

> -A POSTROUTING -j MASQUERADE
>
>
> Appreciate you kind asistance ....
> hanks in advance
> Maile
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> [hidden email]</user/SendEmail.jtp?type=node&node=4677280&i=0>
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJXH+RBAAoJENNXIZxhPexG174H/3r5IBojH3EKdMCMknRQjwD3
RVrM29M9K3VQX4U2UXj8RVYoBWju+X4NQDtDn/k21Zd3albE/L9bFP0fmPEMb1z1
r0hPUoskPBFqXXYUp6NZ4Yi8TNbbvgvbJ1tGWeMdPWaoE/qvv1tqAKBHeGCCcM2A
P67chV8418cUsTqRyOYCKF9ad4fj1FobWRr9/o826PQ+azCVN0xDD3BjswB8DAzE
i+ZCHCIAEOyCwis84nFb2EqvKGnlqN64WrOkJ6IkFHKxuWg8PTqWnj+NZmMuzhkf
VsMvKrVxd/w9Eh1T6xW0CGfxG/B9V8bCXId0ez0NPyLr/H7kiFqYPNlWZyzCBIw=
=G5AM
-----END PGP SIGNATURE-----


_______________________________________________
squid-users mailing list
[hidden email]</user/SendEmail.jtp?type=node&node=4677280&i=1>
http://lists.squid-cache.org/listinfo/squid-users

[http://squid-web-proxy-cache.1019090.n4.nabble.com/images/icon_attachment.gif] 0x613DEC46.asc (2K) Download Attachment<http://squid-web-proxy-cache.1019090.n4.nabble.com/attachment/4677280/0/0x613DEC46.asc>


________________________________
If you reply to this email, your message will be added to the discussion below:
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279p4677280.html
To unsubscribe from help for my intercept proxy setup, click here<http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4677279&code=bWFpbGUuaGFsYXR1aXR1aWFAdGNjLnRvfDQ2NzcyNzl8LTEwMTI1NzgwODY=>.
NAML<http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.
Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279p4677281.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From maile.halatuituia at tcc.to  Tue Apr 26 22:01:30 2016
From: maile.halatuituia at tcc.to (Maile Halatuituia)
Date: Tue, 26 Apr 2016 22:01:30 +0000
Subject: [squid-users] help for my intercept proxy setup
In-Reply-To: <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>
References: <1461704700055-4677279.post@n4.nabble.com>,
 <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>
Message-ID: <3271d495b9094e20bbea8d35e4031c62@mail.tcc.to>

wccp2_router 10.240.0.254
wccp_version 4
wccp2_forwarding_method gre
wccp2_return_method gre
wccp2_rebuild_wait off
wccp2_assignment_method hash
wccp2_service standard 0
wccp2_service dynamic 70
wccp2_service_info 70 protocol=tcp flags=dst_ip_hash,src_ip_alt_hash,src_port_alt_hash priority=240 ports=443,80
always_direct allow all
thanks
________________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Yuri Voinov <yvoinov at gmail.com>
Sent: Wednesday, April 27, 2016 10:57 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] help for my intercept proxy setup

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

Show WCCP section of yout squid.conf please.


27.04.16 3:05, maileh ?????:
> Hi
> Here is my router wccp config
> In global config i enable ip wccp
> #ip wccp web-cache redirect-list WCCP_HTTP
> #ip wccp 70 redirect-list WCCP_HTTPS
> Interface facing my Clients and also Squid is in the same subnet
>
> int g0/0.904
> ip wccp web-cache redirect out
> ip wccp 70 redirect out.
>
> Verification
>
> #sh ip wccp sum
> WCCP version 2 enabled, 2 services
>
> Service     Clients   Routers   Assign      Redirect   Bypass
> -------     -------   -------   ------      --------   ------
> Default routing table (Router Id: x.x.x.x):
> web-cache   1         1         HASH        GRE        GRE
> 70                  1         1         HASH        GRE        GRE
>
> #sh tunnel groups wccp
>  WCCP : service group 0 in "Default", ver v2, assgnmnt: hash-table
>    intf: Tunnel2, locally sourced
>  WCCP : service group 326 in "Default", ver v2, assgnmnt: hash-table
>    intf: Tunnel0, locally sourced
>
> #sh adjacency tunnel 0 detail
> Protocol Interface                 Address
> IP       Tunnel0                   10.240.0.30(3)
>                                    connectionid 1
>                                    0 packets, 0 bytes
>                                    epoch 0
>                                    sourced in sev-epoch 31
>                                    Encap length 28
>                                    4500000000000000FF2FC732CA861F08
>                                    0AF0001E0000883E01460000
>                                    Tun endpt
>                                    Next chain element:
>                                     IP adj out of GigabitEthernet0/0.904,
> addr 10.240.0.30
> #sh adjacency tunnel 2 detail
>     Protocol Interface                 Address
> IP       Tunnel2                   10.240.0.30(3)
>                                    connectionid 1
>                                    0 packets, 0 bytes
>                                    epoch 0
>                                    sourced in sev-epoch 32
>                                    Encap length 28
>                                    4500000000000000FF2FC732CA861F08
>                                    0AF0001E0000883E00000000
>                                    Tun endpt
>                                    Next chain element:
>                                     IP adj out of GigabitEthernet0/0.904,
> addr 10.240.0.30
> #sh ip wccp web-cache detail
> WCCP Client information:
>         WCCP Client ID:          10.240.0.30
>         Protocol Version:        2.0
>         State:                   Usable
>         Redirection:             GRE
>         Packet Return:           GRE
>         Assignment:              HASH
>         Initial Hash Info:       00000000000000000000000000000000
>                                  00000000000000000000000000000000
>         Assigned Hash Info:      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
>                                  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
>         Hash Allotment:          256 (100.00%)
>         Packets s/w Redirected:  0
>         Connect Time:            00:08:42
>         GRE Bypassed Packets
>           Process:               0
>           CEF:                   0
>           Errors:                0
> If you can see all seems to be established between the router and
squid box
> but no PACKET has been redirected.
> For my IOS
> ROM: System Bootstrap, Version 15.0(1r)M15, RELEASE SOFTWARE (fc1)
>
> It's been over two weeks now and i seems to looking everywhere but no
luck.
> Also here is my iptables rules for you info whch run on ubuntu 14.04 with
> squid
>
> # squid -v
> Squid Cache: Version 3.5.16
> Service Name: squid
> Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC Production
> configure options:  '--prefix=/usr/local' '--enable-translation'
> '--enable-external-acl-helpers=none'
'--enable-storeio=ufs,aufs,diskd,rock'
> '--enable-removal-policies=lru,heap' '--enable-wccp2'
> '--enable-follow-x-forwarded-for' '--enable-cache-digests'
> '--enable-auth-negotiate=none' '--disable-auth-digest'
'--disable-auth-ntlm'
> '--disable-url-rewrite-helpers' '--enable-storeid-rewrite-helpers=file'
> '--enable-log-daemon-helpers=file' '--with-openssl=/usr/local'
> '--enable-ssl' '--enable-ssl-crtd' '--enable-zph-qos' '--enable-snmp'
> '--enable-inline' '--with-dl'
'--with-build-environment=POSIX_V6_LP64_OFF64'
> 'CFLAGS=-O3 -m64 -pipe' 'CXXFLAGS=-O3 -m64 -pipe'
> 'LIBOPENSSL_CFLAGS=-I/usr/local/include'
> 'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig'
'--disable-strict-error-checking'
>
'--enable-build-info=Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC
> Production'
> IPtables Rules for redirection to squid ports
> -A PREROUTING -i wccp0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports
3127
> -A PREROUTING -i wccp0 -p tcp -m tcp --dport 443 -j REDIRECT
--to-ports 3129
> -A POSTROUTING -j MASQUERADE
>
>
> Appreciate you kind asistance ....
> hanks in advance
> Maile
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJXH+RBAAoJENNXIZxhPexG174H/3r5IBojH3EKdMCMknRQjwD3
RVrM29M9K3VQX4U2UXj8RVYoBWju+X4NQDtDn/k21Zd3albE/L9bFP0fmPEMb1z1
r0hPUoskPBFqXXYUp6NZ4Yi8TNbbvgvbJ1tGWeMdPWaoE/qvv1tqAKBHeGCCcM2A
P67chV8418cUsTqRyOYCKF9ad4fj1FobWRr9/o826PQ+azCVN0xDD3BjswB8DAzE
i+ZCHCIAEOyCwis84nFb2EqvKGnlqN64WrOkJ6IkFHKxuWg8PTqWnj+NZmMuzhkf
VsMvKrVxd/w9Eh1T6xW0CGfxG/B9V8bCXId0ez0NPyLr/H7kiFqYPNlWZyzCBIw=
=G5AM
-----END PGP SIGNATURE-----

Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.
Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.


From yvoinov at gmail.com  Tue Apr 26 22:04:42 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 04:04:42 +0600
Subject: [squid-users] help for my intercept proxy setup
In-Reply-To: <f4b1ccda23934f5791f3ff5872494d68@mail.tcc.to>
References: <1461704700055-4677279.post@n4.nabble.com>
 <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>
 <f4b1ccda23934f5791f3ff5872494d68@mail.tcc.to>
Message-ID: <4fc7831b-77c8-8383-52b4-6f256e4567e3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


27.04.16 3:27, maileh ?????:
> wccp_version 4

#    This directive is only relevant if you need to set up WCCP(v1)
#    to some very old and end-of-life Cisco routers. In all other
#    setups it must be left unset or at the default setting.
#    It defines an internal version in the WCCP(v1) protocol,
#    with version 4 being the officially documented protocol.
#
#    According to some users, Cisco IOS 11.2 and earlier only
#    support WCCP version 3.  If you're using that or an earlier
#    version of IOS, you may need to change this value to 3, otherwise
#    do not specify this parameter.
#Default:
# wccp_version 4

> wccp2_forwarding_method gre
> wccp2_return_method gre

Well, does you configure GRE on your proxy box?

> always_direct allow all

This can be irrelewant your rest config.
>
> ?
> thanks
>
>
> ________________________________
> From: Yuri Voinov [via Squid Web Proxy Cache]
<ml-node+s1019090n4677280h0 at n4.nabble.com>
> Sent: Wednesday, April 27, 2016 10:24 AM
> To: Maile Halatuituia
> Subject: Re: help for my intercept proxy setup
>
>
> Show WCCP section of yout squid.conf please.
>
>
> 27.04.16 3:05, maileh ?????:
>
> > Hi
> > Here is my router wccp config
> > In global config i enable ip wccp
> > #ip wccp web-cache redirect-list WCCP_HTTP
> > #ip wccp 70 redirect-list WCCP_HTTPS
> > Interface facing my Clients and also Squid is in the same subnet
>
> > int g0/0.904
> > ip wccp web-cache redirect out
> > ip wccp 70 redirect out.
>
> > Verification
>
> > #sh ip wccp sum
> > WCCP version 2 enabled, 2 services
>
> > Service     Clients   Routers   Assign      Redirect   Bypass
> > -------     -------   -------   ------      --------   ------
> > Default routing table (Router Id: x.x.x.x):
> > web-cache   1         1         HASH        GRE        GRE
> > 70                  1         1         HASH        GRE        GRE
>
> > #sh tunnel groups wccp
> >  WCCP : service group 0 in "Default", ver v2, assgnmnt: hash-table
> >    intf: Tunnel2, locally sourced
> >  WCCP : service group 326 in "Default", ver v2, assgnmnt: hash-table
> >    intf: Tunnel0, locally sourced
>
> > #sh adjacency tunnel 0 detail
> > Protocol Interface                 Address
> > IP       Tunnel0                   10.240.0.30(3)
> >                                    connectionid 1
> >                                    0 packets, 0 bytes
> >                                    epoch 0
> >                                    sourced in sev-epoch 31
> >                                    Encap length 28
> >                                    4500000000000000FF2FC732CA861F08
> >                                    0AF0001E0000883E01460000
> >                                    Tun endpt
> >                                    Next chain element:
> >                                     IP adj out of
GigabitEthernet0/0.904,
> > addr 10.240.0.30
> > #sh adjacency tunnel 2 detail
> >     Protocol Interface                 Address
> > IP       Tunnel2                   10.240.0.30(3)
> >                                    connectionid 1
> >                                    0 packets, 0 bytes
> >                                    epoch 0
> >                                    sourced in sev-epoch 32
> >                                    Encap length 28
> >                                    4500000000000000FF2FC732CA861F08
> >                                    0AF0001E0000883E00000000
> >                                    Tun endpt
> >                                    Next chain element:
> >                                     IP adj out of
GigabitEthernet0/0.904,
> > addr 10.240.0.30
> > #sh ip wccp web-cache detail
> > WCCP Client information:
> >         WCCP Client ID:          10.240.0.30
> >         Protocol Version:        2.0
> >         State:                   Usable
> >         Redirection:             GRE
> >         Packet Return:           GRE
> >         Assignment:              HASH
> >         Initial Hash Info:       00000000000000000000000000000000
> >                                  00000000000000000000000000000000
> >         Assigned Hash Info:      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
> >                                  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
> >         Hash Allotment:          256 (100.00%)
> >         Packets s/w Redirected:  0
> >         Connect Time:            00:08:42
> >         GRE Bypassed Packets
> >           Process:               0
> >           CEF:                   0
> >           Errors:                0
> > If you can see all seems to be established between the router and
> squid box
> > but no PACKET has been redirected.
> > For my IOS
> > ROM: System Bootstrap, Version 15.0(1r)M15, RELEASE SOFTWARE (fc1)
>
> > It's been over two weeks now and i seems to looking everywhere but no
> luck.
> > Also here is my iptables rules for you info whch run on ubuntu 14.04
with
> > squid
>
> > # squid -v
> > Squid Cache: Version 3.5.16
> > Service Name: squid
> > Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC Production
> > configure options:  '--prefix=/usr/local' '--enable-translation'
> > '--enable-external-acl-helpers=none'
> '--enable-storeio=ufs,aufs,diskd,rock'
> > '--enable-removal-policies=lru,heap' '--enable-wccp2'
> > '--enable-follow-x-forwarded-for' '--enable-cache-digests'
> > '--enable-auth-negotiate=none' '--disable-auth-digest'
> '--disable-auth-ntlm'
> > '--disable-url-rewrite-helpers' '--enable-storeid-rewrite-helpers=file'
> > '--enable-log-daemon-helpers=file' '--with-openssl=/usr/local'
> > '--enable-ssl' '--enable-ssl-crtd' '--enable-zph-qos' '--enable-snmp'
> > '--enable-inline' '--with-dl'
> '--with-build-environment=POSIX_V6_LP64_OFF64'
> > 'CFLAGS=-O3 -m64 -pipe' 'CXXFLAGS=-O3 -m64 -pipe'
> > 'LIBOPENSSL_CFLAGS=-I/usr/local/include'
> > 'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig'
> '--disable-strict-error-checking'
>
>
'--enable-build-info=Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC
> > Production'
> > IPtables Rules for redirection to squid ports
> > -A PREROUTING -i wccp0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports
> 3127
> > -A PREROUTING -i wccp0 -p tcp -m tcp --dport 443 -j REDIRECT
> --to-ports 3129
>
> > -A POSTROUTING -j MASQUERADE
>
>
> > Appreciate you kind asistance ....
> > hanks in advance
> > Maile
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > [hidden email]</user/SendEmail.jtp?type=node&node=4677280&i=0>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> [hidden email]</user/SendEmail.jtp?type=node&node=4677280&i=1>
> http://lists.squid-cache.org/listinfo/squid-users
>
>
[http://squid-web-proxy-cache.1019090.n4.nabble.com/images/icon_attachment.gif]
0x613DEC46.asc (2K) Download
Attachment<http://squid-web-proxy-cache.1019090.n4.nabble.com/attachment/4677280/0/0x613DEC46.asc>
>
>
> ________________________________
> If you reply to this email, your message will be added to the
discussion below:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279p4677280.html
> To unsubscribe from help for my intercept proxy setup, click
here<http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4677279&code=bWFpbGUuaGFsYXR1aXR1aWFAdGNjLnRvfDQ2NzcyNzl8LTEwMTI1NzgwODY=>.
>
NAML<http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279p4677281.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXH+X6AAoJENNXIZxhPexG6Y4IAJuMLCthWf0MPkuWRuCaIySC
DZ12K5UXb/CU4tFBaHRIwCOAUavrwqb4NpZ2pdAZuBjbQPijc2WUwnLQGIuffHqo
1Z7NTkAgt28ioYXv7s/p1BOFKGFKCg98xioEPs02Zr806k7sH2IyMRWUYoO3ZJrg
abYtxLUAzZMP0zDNxF+Fz01YOwcy35yOXZQlKjihWoGYtYmzRztLzG/DUcNKQ3oL
v2eFM8n0B3+/0BR9SKQLFDFNyRjRnoU8YUxAFWwbBLLRgl8tTKrAmFm2RvqI66S5
1ovX4ixJZ0qvPaRqE7bgiAzvdR88cy0hrgEhBAbVnVVkWq5HyQ8NX2kr/AVZPiM=
=2sqc
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/a9ea1585/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/a9ea1585/attachment.key>

From yvoinov at gmail.com  Tue Apr 26 22:07:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 04:07:14 +0600
Subject: [squid-users] help for my intercept proxy setup
In-Reply-To: <3271d495b9094e20bbea8d35e4031c62@mail.tcc.to>
References: <1461704700055-4677279.post@n4.nabble.com>
 <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>
 <3271d495b9094e20bbea8d35e4031c62@mail.tcc.to>
Message-ID: <20196313-83a0-5298-4ebf-5d9bb6d7d8a2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Note this:

#  TAG: wccp2_forwarding_method
#    WCCP2 allows the setting of forwarding methods between the
#    router/switch and the cache.  Valid values are as follows:
#
#    gre - GRE encapsulation (forward the packet in a GRE/WCCP tunnel)
#    l2  - L2 redirect (forward the packet using Layer 2/MAC rewriting)
#
#    Currently (as of IOS 12.4) cisco routers only support GRE.
#    Cisco switches only support the L2 redirect assignment method.
#Default:
# wccp2_forwarding_method gre

iOS 15.x has switch functionality. As by as most Sicso's modern routers:

scilla#sho cdp neighbors
Capability Codes: R - Router, T - Trans Bridge, B - Source Route Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater, P - Phone,
                  D - Remote, C - CVTA, M - Two-port Mac Relay

Device ID        Local Intrfce     Holdtme    Capability  Platform  Port ID
                 Gig 0/1           152             R B S  CISCO2901 Gig 0/1



27.04.16 4:01, Maile Halatuituia ?????:
> wccp2_router 10.240.0.254
> wccp_version 4
> wccp2_forwarding_method gre
> wccp2_return_method gre
> wccp2_rebuild_wait off
> wccp2_assignment_method hash
> wccp2_service standard 0
> wccp2_service dynamic 70
> wccp2_service_info 70 protocol=tcp
flags=dst_ip_hash,src_ip_alt_hash,src_port_alt_hash priority=240
ports=443,80
> always_direct allow all
> thanks
> ________________________________________
> From: squid-users <squid-users-bounces at lists.squid-cache.org> on
behalf of Yuri Voinov <yvoinov at gmail.com>
> Sent: Wednesday, April 27, 2016 10:57 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] help for my intercept proxy setup
>
> Show WCCP section of yout squid.conf please.
>
>
> 27.04.16 3:05, maileh ?????:
> > Hi
> > Here is my router wccp config
> > In global config i enable ip wccp
> > #ip wccp web-cache redirect-list WCCP_HTTP
> > #ip wccp 70 redirect-list WCCP_HTTPS
> > Interface facing my Clients and also Squid is in the same subnet
>
> > int g0/0.904
> > ip wccp web-cache redirect out
> > ip wccp 70 redirect out.
>
> > Verification
>
> > #sh ip wccp sum
> > WCCP version 2 enabled, 2 services
>
> > Service     Clients   Routers   Assign      Redirect   Bypass
> > -------     -------   -------   ------      --------   ------
> > Default routing table (Router Id: x.x.x.x):
> > web-cache   1         1         HASH        GRE        GRE
> > 70                  1         1         HASH        GRE        GRE
>
> > #sh tunnel groups wccp
> >  WCCP : service group 0 in "Default", ver v2, assgnmnt: hash-table
> >    intf: Tunnel2, locally sourced
> >  WCCP : service group 326 in "Default", ver v2, assgnmnt: hash-table
> >    intf: Tunnel0, locally sourced
>
> > #sh adjacency tunnel 0 detail
> > Protocol Interface                 Address
> > IP       Tunnel0                   10.240.0.30(3)
> >                                    connectionid 1
> >                                    0 packets, 0 bytes
> >                                    epoch 0
> >                                    sourced in sev-epoch 31
> >                                    Encap length 28
> >                                    4500000000000000FF2FC732CA861F08
> >                                    0AF0001E0000883E01460000
> >                                    Tun endpt
> >                                    Next chain element:
> >                                     IP adj out of
GigabitEthernet0/0.904,
> > addr 10.240.0.30
> > #sh adjacency tunnel 2 detail
> >     Protocol Interface                 Address
> > IP       Tunnel2                   10.240.0.30(3)
> >                                    connectionid 1
> >                                    0 packets, 0 bytes
> >                                    epoch 0
> >                                    sourced in sev-epoch 32
> >                                    Encap length 28
> >                                    4500000000000000FF2FC732CA861F08
> >                                    0AF0001E0000883E00000000
> >                                    Tun endpt
> >                                    Next chain element:
> >                                     IP adj out of
GigabitEthernet0/0.904,
> > addr 10.240.0.30
> > #sh ip wccp web-cache detail
> > WCCP Client information:
> >         WCCP Client ID:          10.240.0.30
> >         Protocol Version:        2.0
> >         State:                   Usable
> >         Redirection:             GRE
> >         Packet Return:           GRE
> >         Assignment:              HASH
> >         Initial Hash Info:       00000000000000000000000000000000
> >                                  00000000000000000000000000000000
> >         Assigned Hash Info:      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
> >                                  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
> >         Hash Allotment:          256 (100.00%)
> >         Packets s/w Redirected:  0
> >         Connect Time:            00:08:42
> >         GRE Bypassed Packets
> >           Process:               0
> >           CEF:                   0
> >           Errors:                0
> > If you can see all seems to be established between the router and
> squid box
> > but no PACKET has been redirected.
> > For my IOS
> > ROM: System Bootstrap, Version 15.0(1r)M15, RELEASE SOFTWARE (fc1)
>
> > It's been over two weeks now and i seems to looking everywhere but no
> luck.
> > Also here is my iptables rules for you info whch run on ubuntu 14.04
with
> > squid
>
> > # squid -v
> > Squid Cache: Version 3.5.16
> > Service Name: squid
> > Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC Production
> > configure options:  '--prefix=/usr/local' '--enable-translation'
> > '--enable-external-acl-helpers=none'
> '--enable-storeio=ufs,aufs,diskd,rock'
> > '--enable-removal-policies=lru,heap' '--enable-wccp2'
> > '--enable-follow-x-forwarded-for' '--enable-cache-digests'
> > '--enable-auth-negotiate=none' '--disable-auth-digest'
> '--disable-auth-ntlm'
> > '--disable-url-rewrite-helpers' '--enable-storeid-rewrite-helpers=file'
> > '--enable-log-daemon-helpers=file' '--with-openssl=/usr/local'
> > '--enable-ssl' '--enable-ssl-crtd' '--enable-zph-qos' '--enable-snmp'
> > '--enable-inline' '--with-dl'
> '--with-build-environment=POSIX_V6_LP64_OFF64'
> > 'CFLAGS=-O3 -m64 -pipe' 'CXXFLAGS=-O3 -m64 -pipe'
> > 'LIBOPENSSL_CFLAGS=-I/usr/local/include'
> > 'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig'
> '--disable-strict-error-checking'
>
>
'--enable-build-info=Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC
> > Production'
> > IPtables Rules for redirection to squid ports
> > -A PREROUTING -i wccp0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports
> 3127
> > -A PREROUTING -i wccp0 -p tcp -m tcp --dport 443 -j REDIRECT
> --to-ports 3129
> > -A POSTROUTING -j MASQUERADE
>
>
> > Appreciate you kind asistance ....
> > hanks in advance
> > Maile
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXH+aSAAoJENNXIZxhPexGKQMH/j/cG/jTnbol7r83SbVMUs7t
FO8S98Hx+Sq79Hbfs8EJUxpNPG0k7y7HnvgJEbGSbU/Rn31neJ1/vzU/a+zmVdEs
5JiLkDXYueBvwvf9kapY24tXcspeEDKi1UkHIDDwyR79yA9il5CCxb1sTNWNKWVp
IkBkkmbsVpD1FO1pPB6hF8U8zZe6E9WI2drCguNvqJSsMY/a9ByrhcEbODDMxQBR
D3UyxzwVgm+QnKIFuyc+Adxf0fTAakqzk1KIreCAfmethBZ7TYtA/8TSHo+gzmri
JWXjrquqd7pxfLHdOzWjfIJm6vXUMsi7RcHPwP2SWbsx15dGyoEkVxz2U1rwArE=
=3K52
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/6fafcb38/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/6fafcb38/attachment.key>

From yvoinov at gmail.com  Tue Apr 26 22:08:06 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 04:08:06 +0600
Subject: [squid-users] help for my intercept proxy setup
In-Reply-To: <3271d495b9094e20bbea8d35e4031c62@mail.tcc.to>
References: <1461704700055-4677279.post@n4.nabble.com>
 <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>
 <3271d495b9094e20bbea8d35e4031c62@mail.tcc.to>
Message-ID: <8781660a-3f53-eb48-fb16-f48db31e1315@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
The only problem I see is this:

Your proxy box can't interconnect with WCCP on transport/configuration
level.

27.04.16 4:01, Maile Halatuituia ?????:
> wccp2_router 10.240.0.254
> wccp_version 4
> wccp2_forwarding_method gre
> wccp2_return_method gre
> wccp2_rebuild_wait off
> wccp2_assignment_method hash
> wccp2_service standard 0
> wccp2_service dynamic 70
> wccp2_service_info 70 protocol=tcp
flags=dst_ip_hash,src_ip_alt_hash,src_port_alt_hash priority=240
ports=443,80
> always_direct allow all
> thanks
> ________________________________________
> From: squid-users <squid-users-bounces at lists.squid-cache.org> on
behalf of Yuri Voinov <yvoinov at gmail.com>
> Sent: Wednesday, April 27, 2016 10:57 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] help for my intercept proxy setup
>
> Show WCCP section of yout squid.conf please.
>
>
> 27.04.16 3:05, maileh ?????:
> > Hi
> > Here is my router wccp config
> > In global config i enable ip wccp
> > #ip wccp web-cache redirect-list WCCP_HTTP
> > #ip wccp 70 redirect-list WCCP_HTTPS
> > Interface facing my Clients and also Squid is in the same subnet
>
> > int g0/0.904
> > ip wccp web-cache redirect out
> > ip wccp 70 redirect out.
>
> > Verification
>
> > #sh ip wccp sum
> > WCCP version 2 enabled, 2 services
>
> > Service     Clients   Routers   Assign      Redirect   Bypass
> > -------     -------   -------   ------      --------   ------
> > Default routing table (Router Id: x.x.x.x):
> > web-cache   1         1         HASH        GRE        GRE
> > 70                  1         1         HASH        GRE        GRE
>
> > #sh tunnel groups wccp
> >  WCCP : service group 0 in "Default", ver v2, assgnmnt: hash-table
> >    intf: Tunnel2, locally sourced
> >  WCCP : service group 326 in "Default", ver v2, assgnmnt: hash-table
> >    intf: Tunnel0, locally sourced
>
> > #sh adjacency tunnel 0 detail
> > Protocol Interface                 Address
> > IP       Tunnel0                   10.240.0.30(3)
> >                                    connectionid 1
> >                                    0 packets, 0 bytes
> >                                    epoch 0
> >                                    sourced in sev-epoch 31
> >                                    Encap length 28
> >                                    4500000000000000FF2FC732CA861F08
> >                                    0AF0001E0000883E01460000
> >                                    Tun endpt
> >                                    Next chain element:
> >                                     IP adj out of
GigabitEthernet0/0.904,
> > addr 10.240.0.30
> > #sh adjacency tunnel 2 detail
> >     Protocol Interface                 Address
> > IP       Tunnel2                   10.240.0.30(3)
> >                                    connectionid 1
> >                                    0 packets, 0 bytes
> >                                    epoch 0
> >                                    sourced in sev-epoch 32
> >                                    Encap length 28
> >                                    4500000000000000FF2FC732CA861F08
> >                                    0AF0001E0000883E00000000
> >                                    Tun endpt
> >                                    Next chain element:
> >                                     IP adj out of
GigabitEthernet0/0.904,
> > addr 10.240.0.30
> > #sh ip wccp web-cache detail
> > WCCP Client information:
> >         WCCP Client ID:          10.240.0.30
> >         Protocol Version:        2.0
> >         State:                   Usable
> >         Redirection:             GRE
> >         Packet Return:           GRE
> >         Assignment:              HASH
> >         Initial Hash Info:       00000000000000000000000000000000
> >                                  00000000000000000000000000000000
> >         Assigned Hash Info:      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
> >                                  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
> >         Hash Allotment:          256 (100.00%)
> >         Packets s/w Redirected:  0
> >         Connect Time:            00:08:42
> >         GRE Bypassed Packets
> >           Process:               0
> >           CEF:                   0
> >           Errors:                0
> > If you can see all seems to be established between the router and
> squid box
> > but no PACKET has been redirected.
> > For my IOS
> > ROM: System Bootstrap, Version 15.0(1r)M15, RELEASE SOFTWARE (fc1)
>
> > It's been over two weeks now and i seems to looking everywhere but no
> luck.
> > Also here is my iptables rules for you info whch run on ubuntu 14.04
with
> > squid
>
> > # squid -v
> > Squid Cache: Version 3.5.16
> > Service Name: squid
> > Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC Production
> > configure options:  '--prefix=/usr/local' '--enable-translation'
> > '--enable-external-acl-helpers=none'
> '--enable-storeio=ufs,aufs,diskd,rock'
> > '--enable-removal-policies=lru,heap' '--enable-wccp2'
> > '--enable-follow-x-forwarded-for' '--enable-cache-digests'
> > '--enable-auth-negotiate=none' '--disable-auth-digest'
> '--disable-auth-ntlm'
> > '--disable-url-rewrite-helpers' '--enable-storeid-rewrite-helpers=file'
> > '--enable-log-daemon-helpers=file' '--with-openssl=/usr/local'
> > '--enable-ssl' '--enable-ssl-crtd' '--enable-zph-qos' '--enable-snmp'
> > '--enable-inline' '--with-dl'
> '--with-build-environment=POSIX_V6_LP64_OFF64'
> > 'CFLAGS=-O3 -m64 -pipe' 'CXXFLAGS=-O3 -m64 -pipe'
> > 'LIBOPENSSL_CFLAGS=-I/usr/local/include'
> > 'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig'
> '--disable-strict-error-checking'
>
>
'--enable-build-info=Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC
> > Production'
> > IPtables Rules for redirection to squid ports
> > -A PREROUTING -i wccp0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports
> 3127
> > -A PREROUTING -i wccp0 -p tcp -m tcp --dport 443 -j REDIRECT
> --to-ports 3129
> > -A POSTROUTING -j MASQUERADE
>
>
> > Appreciate you kind asistance ....
> > hanks in advance
> > Maile
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXH+bGAAoJENNXIZxhPexGs38IAK2ZRk2qXFIERPJgIudlhifu
BBY1CHHTQA7PQVctlPC/ed7HIYc33uNocWjWAwVXcVr0ER8UGqAw75ERfA+yfYkL
B/WU8+PIPX+Jm476Mh9y4Vd0GnK0jkANbuY5Fr6iWZJdIT6VXKWkIGKGjyZmERVc
1K9D60QNT5ndGxv7yJG55e0jaksP1+l71cLkSBvxhSwKYLKyV4QWSKvoGbrvwgSA
y5De3wiQIDJA7JLsox6HC3hfKCF3CqFGa/ccl6uvkK7vFl9BM5NXUg0TuGF1hrEQ
MJPIgvk3WFSBB3hPN33l+17oOhUsTnemLN2SykNwNmHYBsJUy2P1qy/8b50TMUE=
=9kyx
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/4b830665/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/4b830665/attachment.key>

From maile.halatuituia at tcc.to  Tue Apr 26 21:40:00 2016
From: maile.halatuituia at tcc.to (maileh)
Date: Tue, 26 Apr 2016 14:40:00 -0700 (PDT)
Subject: [squid-users] help for my intercept proxy setup
In-Reply-To: <8781660a-3f53-eb48-fb16-f48db31e1315@gmail.com>
References: <1461704700055-4677279.post@n4.nabble.com>
 <57d2c343-9a9d-a833-4ebc-9a99a4ee83d4@gmail.com>
 <3271d495b9094e20bbea8d35e4031c62@mail.tcc.to>
 <8781660a-3f53-eb48-fb16-f48db31e1315@gmail.com>
Message-ID: <ef740dc1539847de90f356821a20eb1a@mail.tcc.to>

?Thanks Yuri

..any suggestion .... thanks

________________________________
From: Yuri Voinov [via Squid Web Proxy Cache] <ml-node+s1019090n4677285h55 at n4.nabble.com>
Sent: Wednesday, April 27, 2016 10:34 AM
To: Maile Halatuituia
Subject: Re: help for my intercept proxy setup


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

The only problem I see is this:

Your proxy box can't interconnect with WCCP on transport/configuration level.

27.04.16 4:01, Maile Halatuituia ?????:
> wccp2_router 10.240.0.254
> wccp_version 4
> wccp2_forwarding_method gre
> wccp2_return_method gre
> wccp2_rebuild_wait off
> wccp2_assignment_method hash
> wccp2_service standard 0
> wccp2_service dynamic 70
> wccp2_service_info 70 protocol=tcp flags=dst_ip_hash,src_ip_alt_hash,src_port_alt_hash priority=240 ports=443,80
> always_direct allow all
> thanks
> ________________________________________
> From: squid-users [hidden email]</user/SendEmail.jtp?type=node&node=4677285&i=0> on behalf of Yuri Voinov [hidden email]</user/SendEmail.jtp?type=node&node=4677285&i=1>
> Sent: Wednesday, April 27, 2016 10:57 AM
> To: [hidden email]</user/SendEmail.jtp?type=node&node=4677285&i=2>
> Subject: Re: [squid-users] help for my intercept proxy setup
>
> Show WCCP section of yout squid.conf please.
>
>
> 27.04.16 3:05, maileh ?????:
> > Hi
> > Here is my router wccp config
> > In global config i enable ip wccp
> > #ip wccp web-cache redirect-list WCCP_HTTP
> > #ip wccp 70 redirect-list WCCP_HTTPS
> > Interface facing my Clients and also Squid is in the same subnet
>
> > int g0/0.904
> > ip wccp web-cache redirect out
> > ip wccp 70 redirect out.
>
> > Verification
>
> > #sh ip wccp sum
> > WCCP version 2 enabled, 2 services
>
> > Service     Clients   Routers   Assign      Redirect   Bypass
> > -------     -------   -------   ------      --------   ------
> > Default routing table (Router Id: x.x.x.x):
> > web-cache   1         1         HASH        GRE        GRE
> > 70                  1         1         HASH        GRE        GRE
>
> > #sh tunnel groups wccp
> >  WCCP : service group 0 in "Default", ver v2, assgnmnt: hash-table
> >    intf: Tunnel2, locally sourced
> >  WCCP : service group 326 in "Default", ver v2, assgnmnt: hash-table
> >    intf: Tunnel0, locally sourced
>
> > #sh adjacency tunnel 0 detail
> > Protocol Interface                 Address
> > IP       Tunnel0                   10.240.0.30(3)
> >                                    connectionid 1
> >                                    0 packets, 0 bytes
> >                                    epoch 0
> >                                    sourced in sev-epoch 31
> >                                    Encap length 28
> >                                    4500000000000000FF2FC732CA861F08
> >                                    0AF0001E0000883E01460000
> >                                    Tun endpt
> >                                    Next chain element:
> >                                     IP adj out of GigabitEthernet0/0.904,
> > addr 10.240.0.30
> > #sh adjacency tunnel 2 detail
> >     Protocol Interface                 Address
> > IP       Tunnel2                   10.240.0.30(3)
> >                                    connectionid 1
> >                                    0 packets, 0 bytes
> >                                    epoch 0
> >                                    sourced in sev-epoch 32
> >                                    Encap length 28
> >                                    4500000000000000FF2FC732CA861F08
> >                                    0AF0001E0000883E00000000
> >                                    Tun endpt
> >                                    Next chain element:
> >                                     IP adj out of GigabitEthernet0/0.904,
> > addr 10.240.0.30
> > #sh ip wccp web-cache detail
> > WCCP Client information:
> >         WCCP Client ID:          10.240.0.30
> >         Protocol Version:        2.0
> >         State:                   Usable
> >         Redirection:             GRE
> >         Packet Return:           GRE
> >         Assignment:              HASH
> >         Initial Hash Info:       00000000000000000000000000000000
> >                                  00000000000000000000000000000000
> >         Assigned Hash Info:      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
> >                                  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
> >         Hash Allotment:          256 (100.00%)
> >         Packets s/w Redirected:  0
> >         Connect Time:            00:08:42
> >         GRE Bypassed Packets
> >           Process:               0
> >           CEF:                   0
> >           Errors:                0
> > If you can see all seems to be established between the router and
> squid box
> > but no PACKET has been redirected.
> > For my IOS
> > ROM: System Bootstrap, Version 15.0(1r)M15, RELEASE SOFTWARE (fc1)
>
> > It's been over two weeks now and i seems to looking everywhere but no
> luck.
> > Also here is my iptables rules for you info whch run on ubuntu 14.04 with
> > squid
>
> > # squid -v
> > Squid Cache: Version 3.5.16
> > Service Name: squid
> > Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC Production
> > configure options:  '--prefix=/usr/local' '--enable-translation'
> > '--enable-external-acl-helpers=none'
> '--enable-storeio=ufs,aufs,diskd,rock'
> > '--enable-removal-policies=lru,heap' '--enable-wccp2'
> > '--enable-follow-x-forwarded-for' '--enable-cache-digests'
> > '--enable-auth-negotiate=none' '--disable-auth-digest'
> '--disable-auth-ntlm'
> > '--disable-url-rewrite-helpers' '--enable-storeid-rewrite-helpers=file'
> > '--enable-log-daemon-helpers=file' '--with-openssl=/usr/local'
> > '--enable-ssl' '--enable-ssl-crtd' '--enable-zph-qos' '--enable-snmp'
> > '--enable-inline' '--with-dl'
> '--with-build-environment=POSIX_V6_LP64_OFF64'
> > 'CFLAGS=-O3 -m64 -pipe' 'CXXFLAGS=-O3 -m64 -pipe'
> > 'LIBOPENSSL_CFLAGS=-I/usr/local/include'
> > 'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig'
> '--disable-strict-error-checking'
>
> '--enable-build-info=Intercept/WCCPv2/LibreSSL/CRTD/(A)UFS/DISKD/ROCK/eCAP/64/GCC
> > Production'
> > IPtables Rules for redirection to squid ports
> > -A PREROUTING -i wccp0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports
> 3127
> > -A PREROUTING -i wccp0 -p tcp -m tcp --dport 443 -j REDIRECT
> --to-ports 3129
> > -A POSTROUTING -j MASQUERADE
>
>
> > Appreciate you kind asistance ....
> > hanks in advance
> > Maile
>
>
>
> > --
> > View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > [hidden email]</user/SendEmail.jtp?type=node&node=4677285&i=3>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
> Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.
> Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJXH+bGAAoJENNXIZxhPexGs38IAK2ZRk2qXFIERPJgIudlhifu
BBY1CHHTQA7PQVctlPC/ed7HIYc33uNocWjWAwVXcVr0ER8UGqAw75ERfA+yfYkL
B/WU8+PIPX+Jm476Mh9y4Vd0GnK0jkANbuY5Fr6iWZJdIT6VXKWkIGKGjyZmERVc
1K9D60QNT5ndGxv7yJG55e0jaksP1+l71cLkSBvxhSwKYLKyV4QWSKvoGbrvwgSA
y5De3wiQIDJA7JLsox6HC3hfKCF3CqFGa/ccl6uvkK7vFl9BM5NXUg0TuGF1hrEQ
MJPIgvk3WFSBB3hPN33l+17oOhUsTnemLN2SykNwNmHYBsJUy2P1qy/8b50TMUE=
=9kyx
-----END PGP SIGNATURE-----


_______________________________________________
squid-users mailing list
[hidden email]</user/SendEmail.jtp?type=node&node=4677285&i=4>
http://lists.squid-cache.org/listinfo/squid-users

[http://squid-web-proxy-cache.1019090.n4.nabble.com/images/icon_attachment.gif] 0x613DEC46.asc (2K) Download Attachment<http://squid-web-proxy-cache.1019090.n4.nabble.com/attachment/4677285/0/0x613DEC46.asc>


________________________________
If you reply to this email, your message will be added to the discussion below:
http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279p4677285.html
To unsubscribe from help for my intercept proxy setup, click here<http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4677279&code=bWFpbGUuaGFsYXR1aXR1aWFAdGNjLnRvfDQ2NzcyNzl8LTEwMTI1NzgwODY=>.
NAML<http://squid-web-proxy-cache.1019090.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.
Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/help-for-my-intercept-proxy-setup-tp4677279p4677286.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From alfrenovsky at gmail.com  Wed Apr 27 11:32:38 2016
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Wed, 27 Apr 2016 08:32:38 -0300
Subject: [squid-users] Regex optimization
Message-ID: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>

I saw in debug log that when an ACL has many regexes each one is compared
sequentially.

If I have

www.facebook.com
facebook.com
www.google.com
google.com

If will be faster to check just ONE optimized regex like
(www\.)?(facebook|google).com than the previous three?

I'm really talking about optimizing about 3000 url regexes in one huge
regex because comparing each and every url to 3000 regexes is too slow.

I know using
(www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com) with
PCRE will produce the same optimized result as
(www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
optimizes this as well ?


-- 
Alfrenovsky
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/634b325a/attachment.htm>

From yvoinov at gmail.com  Wed Apr 27 12:09:34 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 18:09:34 +0600
Subject: [squid-users] Regex optimization
In-Reply-To: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
Message-ID: <3f452f7f-4c76-f71a-719a-6eb9c317cd17@gmail.com>

https://regex101.com is your best friend.


27.04.16 17:32, Alfredo Rezinovsky ?????:
> I saw in debug log that when an ACL has many regexes each one is 
> compared sequentially.
>
> If I have
>
> www.facebook.com <http://www.facebook.com>
> facebook.com <http://facebook.com>
> www.google.com <http://www.google.com>
> google.com <http://google.com>
>
> If will be faster to check just ONE optimized regex like 
> (www\.)?(facebook|google).com than the previous three?
>
> I'm really talking about optimizing about 3000 url regexes in one huge 
> regex because comparing each and every url to 3000 regexes is too slow.
>
> I know using 
> (www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com) 
> with PCRE will produce the same optimized result as 
> (www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib 
> optimizes this as well ?
>
>
> -- 
> Alfrenovsky
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/cd96906a/attachment.htm>

From alfrenovsky at gmail.com  Wed Apr 27 13:11:26 2016
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Wed, 27 Apr 2016 10:11:26 -0300
Subject: [squid-users] Regex optimization
In-Reply-To: <3f452f7f-4c76-f71a-719a-6eb9c317cd17@gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <3f452f7f-4c76-f71a-719a-6eb9c317cd17@gmail.com>
Message-ID: <CAMXC=WvSDv4YyOeNU0VnTMfORuvRrCD+3G-88XKf7FFZZcz7cQ@mail.gmail.com>

Not my question. I'm asking about performance

2016-04-27 9:09 GMT-03:00 Yuri Voinov <yvoinov at gmail.com>:

> https://regex101.com is your best friend.
>
> 27.04.16 17:32, Alfredo Rezinovsky ?????:
>
> I saw in debug log that when an ACL has many regexes each one is compared
> sequentially.
>
> If I have
>
> www.facebook.com
> facebook.com
> www.google.com
> google.com
>
> If will be faster to check just ONE optimized regex like
> (www\.)?(facebook|google).com than the previous three?
>
> I'm really talking about optimizing about 3000 url regexes in one huge
> regex because comparing each and every url to 3000 regexes is too slow.
>
> I know using
> (www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com) with
> PCRE will produce the same optimized result as
> (www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
> optimizes this as well ?
>
>
>


-- 
Alfrenovsky
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/dced54d8/attachment.htm>

From uhlar at fantomas.sk  Wed Apr 27 13:12:16 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 27 Apr 2016 15:12:16 +0200
Subject: [squid-users] Logging in squid
In-Reply-To: <CAO4ouAZndvtRh6pGc3GzUHCVnVJ=kAExw7EgVadU2jvpknhm3A@mail.gmail.com>
References: <CAO4ouAZndvtRh6pGc3GzUHCVnVJ=kAExw7EgVadU2jvpknhm3A@mail.gmail.com>
Message-ID: <20160427131216.GA3734@fantomas.sk>

On 26.04.16 15:20, Aashima Madaan wrote:
>I have kept squid between a proxy and a server. Requests and response pass
>from proxy to squid to server and back.

between? Squid is a proxy, do you connect one proxy through another proxy?
Why?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
I intend to live forever - so far so good. 


From yvoinov at gmail.com  Wed Apr 27 13:28:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 19:28:07 +0600
Subject: [squid-users] Regex optimization
In-Reply-To: <CAMXC=WvSDv4YyOeNU0VnTMfORuvRrCD+3G-88XKf7FFZZcz7cQ@mail.gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <3f452f7f-4c76-f71a-719a-6eb9c317cd17@gmail.com>
 <CAMXC=WvSDv4YyOeNU0VnTMfORuvRrCD+3G-88XKf7FFZZcz7cQ@mail.gmail.com>
Message-ID: <CACKH78q8gij38Nj9VO4Z4-r285H4NYDXF6efWsTStkMFZLBVRg@mail.gmail.com>

Wrong.

When you test regex, you can see this:

https://i1.someimage.com/Ae6P3is.png

this:

https://i1.someimage.com/70Y4kl9.png

and this:

https://i1.someimage.com/rNjCjVX.png

As you can see, green bar in upper right corner shows you steps count when
parse and _execute_ regex.

This is performance info you required. This is obvious.

More steps - slower exec. So odd you can't see obvious.
Otherwise only regex gurus/creator can tell you how fast/slow is any regex.
Regex is magic.

Also, just for minute, you asking in wrong place. This is squid, not regex.

Best rgrds, Yuri


2016-04-27 19:11 GMT+06:00 Alfredo Rezinovsky <alfrenovsky at gmail.com>:

> Not my question. I'm asking about performance
>
> 2016-04-27 9:09 GMT-03:00 Yuri Voinov <yvoinov at gmail.com>:
>
>> https://regex101.com is your best friend.
>>
>> 27.04.16 17:32, Alfredo Rezinovsky ?????:
>>
>> I saw in debug log that when an ACL has many regexes each one is compared
>> sequentially.
>>
>> If I have
>>
>> www.facebook.com
>> facebook.com
>> www.google.com
>> google.com
>>
>> If will be faster to check just ONE optimized regex like
>> (www\.)?(facebook|google).com than the previous three?
>>
>> I'm really talking about optimizing about 3000 url regexes in one huge
>> regex because comparing each and every url to 3000 regexes is too slow.
>>
>> I know using
>> (www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com) with
>> PCRE will produce the same optimized result as
>> (www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
>> optimizes this as well ?
>>
>>
>>
>
>
> --
> Alfrenovsky
>



-- 
-= WBR, Yuri.
                    Powered by Google =-
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/d55330a9/attachment.htm>

From squid3 at treenet.co.nz  Wed Apr 27 14:01:31 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Apr 2016 02:01:31 +1200
Subject: [squid-users] Regex optimization
In-Reply-To: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
Message-ID: <5720C63B.2040601@treenet.co.nz>

On 27/04/2016 11:32 p.m., Alfredo Rezinovsky wrote:
> I saw in debug log that when an ACL has many regexes each one is compared
> sequentially.
> 
> If I have
> 
> www.facebook.com
> facebook.com
> www.google.com
> google.com
> 
> If will be faster to check just ONE optimized regex like
> (www\.)?(facebook|google).com than the previous three?
> 
> I'm really talking about optimizing about 3000 url regexes in one huge
> regex because comparing each and every url to 3000 regexes is too slow.

As Yuri was trying to point out (I think) simply using one bigger regex
pattern is not always meaning faster.


> 
> I know using
> (www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com) with
> PCRE will produce the same optimized result as
> (www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
> optimizes this as well ?

If you actually pass GNURegex that *single* pattern. Yes, it will do
some optimization. Though I'm not sure how much exactly in comparison to
PCRE.

 * Also, while GNURegex is the built-in backup regex engine bundled with
Squid. It really is only a backup engine for systems like Windows which
dont provide a regex engine. The stdlib regex library is always used if
available. On some OS that stdlib engine is GNU, on others PCRE or
something even better.


What you see in the log is the fact that Squid is actually *not*
configured with a single compound "optimized" pattern. You are actually
using a file with ~3000 patterns in it ... so 3000 regex patterns to be
checked against the URL.

Whether Squid checks 3000 tests or some smaller number depends on what
Squid version you are using. The recent versions do some trivial pattern
aggregation and stripping away prefix/suffix ".*" garbage to help the
library optimize better. But as Yuri showed, bigger pattern is not
necessarily better *steps* for per-test speed. The gains are mostly in
reduced Squid code CPU time and RAM overheads.
Regex is still the slowest of the ACLs in terms of raw CPU consumed.


The biggest problem with using regex for domain name lists is that regex
is optimized for left-to-right comparisons. Domain name labels are built
right-to-left. dstdomain is optimized for right-to-left comparison with
an early-abort on mismatch and sub-domain wildcards - which gives it a
huge advantage in CPU cycles over regex.

Amos



From yvoinov at gmail.com  Wed Apr 27 14:22:24 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 20:22:24 +0600
Subject: [squid-users] Regex optimization
In-Reply-To: <5720C63B.2040601@treenet.co.nz>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <5720C63B.2040601@treenet.co.nz>
Message-ID: <4bc4ef7f-6046-b518-b2dc-9f8e6d7176ff@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


27.04.16 20:01, Amos Jeffries ?????:
> On 27/04/2016 11:32 p.m., Alfredo Rezinovsky wrote:
>> I saw in debug log that when an ACL has many regexes each one is compared
>> sequentially.
>>
>> If I have
>>
>> www.facebook.com
>> facebook.com
>> www.google.com
>> google.com
>>
>> If will be faster to check just ONE optimized regex like
>> (www\.)?(facebook|google).com than the previous three?
>>
>> I'm really talking about optimizing about 3000 url regexes in one huge
>> regex because comparing each and every url to 3000 regexes is too slow.
>
> As Yuri was trying to point out (I think) simply using one bigger regex
> pattern is not always meaning faster.
Absolutely yes.

For example: By my experience, expression (.*) for group selecting uses
much more steps than (.*?) or (.+?). Yes, often last expressions has
another meaning, but as part of optimization this method - as partial
solution - is useful.

Also, the site I point contains "explanation" section, which is good
starting point in performance tuning of regexps.

In two words: You can think that regex "steps" is equivalent of "CPU
cycles". Just to simplify. And yes, this is direct dependency - more
steps - more cycles - slower execution.
>
>
>
>>
>> I know using
>> (www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com)
with
>> PCRE will produce the same optimized result as
>> (www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
>> optimizes this as well ?
>
> If you actually pass GNURegex that *single* pattern. Yes, it will do
> some optimization. Though I'm not sure how much exactly in comparison to
> PCRE.
>
>  * Also, while GNURegex is the built-in backup regex engine bundled with
> Squid. It really is only a backup engine for systems like Windows which
> dont provide a regex engine. The stdlib regex library is always used if
> available. On some OS that stdlib engine is GNU, on others PCRE or
> something even better.
>
>
> What you see in the log is the fact that Squid is actually *not*
> configured with a single compound "optimized" pattern. You are actually
> using a file with ~3000 patterns in it ... so 3000 regex patterns to be
> checked against the URL.
>
> Whether Squid checks 3000 tests or some smaller number depends on what
> Squid version you are using. The recent versions do some trivial pattern
> aggregation and stripping away prefix/suffix ".*" garbage to help the
> library optimize better. But as Yuri showed, bigger pattern is not
> necessarily better *steps* for per-test speed. The gains are mostly in
> reduced Squid code CPU time and RAM overheads.
> Regex is still the slowest of the ACLs in terms of raw CPU consumed.
>
>
> The biggest problem with using regex for domain name lists is that regex
> is optimized for left-to-right comparisons. Domain name labels are built
> right-to-left. dstdomain is optimized for right-to-left comparison with
> an early-abort on mismatch and sub-domain wildcards - which gives it a
> huge advantage in CPU cycles over regex.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXIMsfAAoJENNXIZxhPexGuZ8H/2DNMNKp3u/3kmOsUczWH4KG
mP09zPzbPu7veniLOR30RGFZEbAFr0UxPGnaASyzzRMbJZ2ChAqUEtwsJvT2+lCL
g0lNZ5GPdnBh8DECrR0Cu5cV67Y8fXeQRdxYJlnjQdD4UH5thg6iZbOYNqOZLkOr
FiCpK6m6J32QH9EgI5x8GwhZBxpEJLyilqeAaku3kxTY4yqeguiSh6L4srfYhc+U
EPCR7q+dYrQ1UuroenHlCYnXLX/KmDD5AUA5AdxML1bNpTo1z7tVrdDVXbbBofIb
CZ+Y9duuBtJ5zaYi2qVbROolx7GDDwT2zdhniA+UNaMhx6k2RMnKZHTcFScfsE8=
=2fLk
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/8d950e29/attachment.key>

From yvoinov at gmail.com  Wed Apr 27 14:25:04 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 27 Apr 2016 20:25:04 +0600
Subject: [squid-users] Regex optimization
In-Reply-To: <5720C63B.2040601@treenet.co.nz>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <5720C63B.2040601@treenet.co.nz>
Message-ID: <288040af-b902-052a-cd8b-adb9e9a45b0f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Furthermore. The more specifically a regular expression, so it usually
faster.


27.04.16 20:01, Amos Jeffries ?????:
> On 27/04/2016 11:32 p.m., Alfredo Rezinovsky wrote:
>> I saw in debug log that when an ACL has many regexes each one is compared
>> sequentially.
>>
>> If I have
>>
>> www.facebook.com
>> facebook.com
>> www.google.com
>> google.com
>>
>> If will be faster to check just ONE optimized regex like
>> (www\.)?(facebook|google).com than the previous three?
>>
>> I'm really talking about optimizing about 3000 url regexes in one huge
>> regex because comparing each and every url to 3000 regexes is too slow.
>
> As Yuri was trying to point out (I think) simply using one bigger regex
> pattern is not always meaning faster.
>
>
>>
>> I know using
>> (www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com)
with
>> PCRE will produce the same optimized result as
>> (www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
>> optimizes this as well ?
>
> If you actually pass GNURegex that *single* pattern. Yes, it will do
> some optimization. Though I'm not sure how much exactly in comparison to
> PCRE.
>
>  * Also, while GNURegex is the built-in backup regex engine bundled with
> Squid. It really is only a backup engine for systems like Windows which
> dont provide a regex engine. The stdlib regex library is always used if
> available. On some OS that stdlib engine is GNU, on others PCRE or
> something even better.
>
>
> What you see in the log is the fact that Squid is actually *not*
> configured with a single compound "optimized" pattern. You are actually
> using a file with ~3000 patterns in it ... so 3000 regex patterns to be
> checked against the URL.
>
> Whether Squid checks 3000 tests or some smaller number depends on what
> Squid version you are using. The recent versions do some trivial pattern
> aggregation and stripping away prefix/suffix ".*" garbage to help the
> library optimize better. But as Yuri showed, bigger pattern is not
> necessarily better *steps* for per-test speed. The gains are mostly in
> reduced Squid code CPU time and RAM overheads.
> Regex is still the slowest of the ACLs in terms of raw CPU consumed.
>
>
> The biggest problem with using regex for domain name lists is that regex
> is optimized for left-to-right comparisons. Domain name labels are built
> right-to-left. dstdomain is optimized for right-to-left comparison with
> an early-abort on mismatch and sub-domain wildcards - which gives it a
> huge advantage in CPU cycles over regex.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXIMvAAAoJENNXIZxhPexGY6UIAJdAACrNLs2MdfAdnUHoqtrD
/5oiUdd1kBMnAyOvpJfXZOK8glSui3wnTJpsw6sq7YOgU4PzIH7rCRw9uAsTyIxQ
3lyWh5u2GJDObz9DSUZVUDs7WtEHyclNxSO4OkoA7zNliFe4uvdZ4mujrWk2mHxB
AjHEWmOEFzVlq0AbCnrbDJ6HX1KMURbCpkP/3G8zPauJEyCMiYVAIVigaT1H4yko
JV0AgSII0zns+hKPUWywZ1vlCeOaIvEqGZu1/Z1q/L1oWNZ4HqgFg1jYIBYlA3oY
34727VzE0LSLQX673nIkAn4uF/lkqmAgzAbOQ9Q+7N5bj+q0a6ELUEFMxq1m8FA=
=p9LL
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/76d52f9b/attachment.key>

From Sebastien.Boulianne at cpu.ca  Wed Apr 27 17:42:46 2016
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Wed, 27 Apr 2016 13:42:46 -0400
Subject: [squid-users] Squid with a FTPD... glFTPD or ioFTPD
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5837FD1682@CPUMAIL2.cpu.qc.ca>

Hi all,

I would like to know if someone use Squid with a FTPD like glFTPD or ioFTPD or something like that.

Thanks you very much for your answer.

S?bastien

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160427/d544afe8/attachment.htm>

From uhlar at fantomas.sk  Wed Apr 27 18:02:54 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 27 Apr 2016 20:02:54 +0200
Subject: [squid-users] Squid with a FTPD... glFTPD or ioFTPD
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5837FD1682@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD1682@CPUMAIL2.cpu.qc.ca>
Message-ID: <20160427180254.GA10593@fantomas.sk>

On 27.04.16 13:42, Sebastien.Boulianne at cpu.ca wrote:
>I would like to know if someone use Squid with a FTPD like glFTPD or ioFTPD
> or something like that.

why? squid and tpd are two different things...

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Quantum mechanics: The dreams stuff is made of. 


From yvoinov at gmail.com  Wed Apr 27 18:51:51 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 28 Apr 2016 00:51:51 +0600
Subject: [squid-users] Squid with a FTPD... glFTPD or ioFTPD
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5837FD1682@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD1682@CPUMAIL2.cpu.qc.ca>
Message-ID: <f5da0c71-c842-cad4-b09f-e5a4adc2117e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hmmmmmmmmm...... for what?


27.04.16 23:42, Sebastien.Boulianne at cpu.ca ?????:
>
> Hi all,
>
> 
>
> I would like to know if someone use Squid with a FTPD like glFTPD or
ioFTPD or something like that.
>
> 
>
> Thanks you very much for your answer.
>
> 
>
> S?bastien
>
> 
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXIQpHAAoJENNXIZxhPexGfKIH/im6RmGSK9DiYJjVjv2opRMf
IWu1ON9/L9zxkO85Zi0GqBawp/k8hf/0vpDG+Tb3MzM4EirYLM3KLDpf07nGGFeX
QlTANBtJ6N6Su/bECngCUG6O6NUFymb3mdw6sfzAo76+WA7MOWY9ZFhW4xlvsYzT
hD2bdiV+gFL/sBCH/TvVhqZ11vEbpD7QxUVpPgkfN9NCEkFs2FvpVS0knTdHKpdC
ASciiI8odw/1Vr/toydTad46xX846CnzRLTskYq7mS3ThFGV2DJQLml6ObURpnav
zn8q3Phkk4cwnBTGU6RZkSywn9tEoU+YepxZsoRC1CmQRU0uMZ4r89cRnTqi3G8=
=y2+f
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160428/3598138b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160428/3598138b/attachment.key>

From rousskov at measurement-factory.com  Wed Apr 27 21:11:37 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 27 Apr 2016 15:11:37 -0600
Subject: [squid-users] Squid with a FTPD... glFTPD or ioFTPD
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5837FD1682@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD1682@CPUMAIL2.cpu.qc.ca>
Message-ID: <57212B09.2010804@measurement-factory.com>

On 04/27/2016 11:42 AM, Sebastien.Boulianne at cpu.ca wrote:

> I would like to know if someone use Squid with a FTPD like glFTPD or
> ioFTPD or something like that.

Folks can and do access various FTP servers through Squid (either via
native FTP commands sent/redirected to Squid's ftp_port or via HTTP
requests for ftp:// URLs). If that usage is not what you are asking
about, then please clarify what you mean by "use with FTPD".

Alex.



From bmarkey at steinmancommunications.com  Thu Apr 28 20:32:53 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Thu, 28 Apr 2016 20:32:53 +0000
Subject: [squid-users] Using dont_verify_peer
Message-ID: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>

I didn't really get an answer previously so I did some research and now I'm not quite sure what to do.

Problem is I'm getting a lot of these:


The following error was encountered while trying to retrieve the URL: https://*.agentimediaservices.com/*<https://%2A.agentimediaservices.com/*>

Failed to establish a secure connection to 63.240.52.151

The system returned:

(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)

SSL Certficate error: certificate issuer (CA) not known: /C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA

This proxy and the remote host failed to negotiate a mutually acceptable security settings for handling your request. It is possible that the remote host does not support secure connections, or the proxy is not satisfied with the host security credentials.

Your cache administrator is webmaster<mailto:webmaster?subject=CacheErrorInfo%20-%20ERR_SECURE_CONNECT_FAIL&body=CacheHost%3A%20LNP-Proxy%0D%0AErrPage%3A%20ERR_SECURE_CONNECT_FAIL%0D%0AErr%3A%20(71)%20Protocol%20error%0D%0ATimeStamp%3A%20Thu,%2028%20Apr%202016%2016%3A37%3A14%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.203.24%0D%0AServerIP%3A%2063.240.52.151%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%2063.240.52.151%3A443%0D%0A%0D%0A%0D%0A>.


As I had stated some are "fixable" by adding the url to my broken acl and then not peeking at it. That sometimes works, most of the time not and then I have to add the ip listed to an acl of allowed ips.   This usually works but not in all cases.

That leaves me sort of stuck. I've been having to actually remove folks from the proxy so they could work.  I work for a newspaper and most of the issues lie with the myriad of SEO/Marketing sites/tools these people use. They're horrible.

That leads me to my question of will using that flag make this issue go away?   Granted Im aware it's not the safest I can't deny users access to the sites they need.


I'm running 3.5.16 compiled from source on debian Jessie.  Fully updated.  I'm also confused as to why this is happening.  My ca store is up to date.   I'm confused as to why this is happening.  If I can access all these sites fine without the proxy I'd have to think it's not the cert itself. So it's either debians cert store or something else.  I'm sort of at the end of my knowledge here as to what to troubleshoot.

The other option, though it would be last resort would be to just stop doing anything with https, though all I really wanted was to keep stats on sites visited.

Here is some openssl info.  This leads me to believe its not a squid issue persay, its an openssl issue and or debian issue with certs. But I'm not 100% on that.

bruce at LNP-Proxy:/etc/squid3$ sudo openssl s_client -connect www.agentimediaservices.com:443 -showcerts
CONNECTED(00000003)
depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street = 195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU = PlatinumSSL Wildcard, CN = *.agentimediaservices.com
verify error:num=20:unable to get local issuer certificate
verify return:1
depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street = 195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU = PlatinumSSL Wildcard, CN = *.agentimediaservices.com
verify error:num=27:certificate not trusted
verify return:1
depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street = 195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU = PlatinumSSL Wildcard, CN = *.agentimediaservices.com
verify error:num=21:unable to verify the first certificate
verify return:1
---
Certificate chain
0 s:/C=US/postalCode=10007/ST=NY/L=New York/street=195 Broadway/O=OMD USA LLC/OU=IT/OU=Hosted by OMD USA INC/OU=PlatinumSSL Wildcard/CN=*.agentimediaservices.com
   i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA
-----BEGIN CERTIFICATE-----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=
-----END CERTIFICATE-----
---
Server certificate
subject=/C=US/postalCode=10007/ST=NY/L=New York/street=195 Broadway/O=OMD USA LLC/OU=IT/OU=Hosted by OMD USA INC/OU=PlatinumSSL Wildcard/CN=*.agentimediaservices.com
issuer=/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA
---
No client certificate CA names sent
---
SSL handshake has read 1678 bytes and written 599 bytes
---
New, TLSv1/SSLv3, Cipher is RC4-MD5
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : RC4-MD5
    Session-ID: 4F9EE34EFA2F6305BBD46D6F367BFDC9F95580A7889D9E1FE91F0F79BA86701F
    Session-ID-ctx:
    Master-Key: F741F597EFC3C837CE52546CC455FFFEBC0F18CCBC74CFB4BE7F1AE3C85EEB9065C39AE50CC525A33C5BD6CCF3D2483A
    Key-Arg   : None
    PSK identity: None
   PSK identity hint: None
    SRP username: None
    Start Time: 1461875411
    Timeout   : 300 (sec)
    Verify return code: 21 (unable to verify the first certificate)
---

Squid.conf:

#Access Lists
acl internal src 192.168.200.0/21
acl wireless src 192.168.100.0/23

#Ports allowed through Squid
acl Safe_ports port 80
acl Safe_ports port 443
acl SSL_ports port 443
acl CONNECT method CONNECT

#acls from blacklist
acl allowed dstdomain -i "/etc/squid3/acls/http_allowed.acl"
acl prime dstdomain -i "/etc/squid3/acls/squid-prime.acl"
acl china dst -n "/etc/squid3/acls/ccd-china.acl"
acl india dst -n "/etc/squid3/acls/ccd-india.acl"
acl iran dst -n "/etc/squid3/acls/ccd-iran.acl"
acl nigeria dst -n "/etc/squid3/acls/ccd-nigeria.acl"
acl pakistan dst -n "/etc/squid3/acls/ccd-nigeria.acl"
acl romania dst -n "/etc/squid3/acls/ccd-romania.acl"
acl russia dst -n "/etc/squid3/acls/ccd-russia.acl"
acl syria dst -n "/etc/squid3/acls/ccd-syria.acl"
acl ukraine dst -n "/etc/squid3/acls/ccd-ukraine.acl"
acl uzbekistan dst -n "/etc/squid3/acls/ccd-uzbekistan.acl"
acl ips dst -n "/etc/squid3/acls/broken_ips.acl"
acl blocked dstdomain -i "/etc/squid3/acls/http_blocked.acl"

#allow/deny
http_access allow allowed
http_access allow ips
http_access deny blocked
http_access deny prime
http_access deny china
http_access deny india
http_access deny iran
http_access deny nigeria
http_access deny pakistan
http_access deny romania
http_access deny russia
http_access deny syria
http_access deny ukraine
http_access deny uzbekistan

http_access allow internal
http_access allow wireless
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all

#Bumping
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"

#ssl_bump peek all
ssl_bump peek !broken_sites
ssl_bump splice all
#ssl_bump splice !broken_sites

sslproxy_capath /etc/ssl/certs

sslcrtd_program /lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
sslcrtd_children 32 startup=5 idle=1


#logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni %ssl::>cert_subject %>Hs %<st %Ss:%Sh

#access_log syslog:daemon.info mine
#access_log daemon:/var/log/squid3/test.log mine

#intercept
http_port 3128 intercept
https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB sslflags=NO_SESSION_REUSE

#nameservers
dns_nameservers 192.168.201.1 8.8.8.8

#WCCPv2 items
wccp_version 2
wccp2_router 192.168.200.73
wccp2_forwarding_method gre
wccp2_return_method gre
wccp2_service standard 0 password=LNP1
wccp2_service dynamic 70 password=LNP1
wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 ports=443

Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758 (o) | bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160428/e57abd51/attachment.htm>

From rafael.akchurin at diladele.com  Thu Apr 28 20:56:29 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 28 Apr 2016 20:56:29 +0000
Subject: [squid-users] Using dont_verify_peer
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>
Message-ID: <VI1PR04MB1359E191B57DDC980709E9218F650@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Bruce,

According to https://www.ssllabs.com/ssltest/analyze.html?d=agentimediaservices.com the server does not send the whole chain of certificates and imho squid cannot automatically download the intermediate certificates like browsers do.

You need to manually add them to the store. Currently we do it like http://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html

I hope Yuri knows everything about adding certificates to the store and will reply shortly :)

If you were using explicit proxy usually making agentimediaservices.com non bumpable would be enough as squid would simply pump bytes from browser to site after allowed CONNECT; but as you have intercepting squid - I suspect it needs to establish a new connection to the remote site and thus openssl code that is used when establishing connections gets a change to fail the connection to a site with incomplete certificate chain. IMHO :)

I am also interested how to bypass it in intercepted scenario.

Best regards,
Rafael Akchurin
Diladele B.V.

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Markey, Bruce
Sent: Thursday, April 28, 2016 10:33 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Using dont_verify_peer

I didn't really get an answer previously so I did some research and now I'm not quite sure what to do.

Problem is I'm getting a lot of these:


The following error was encountered while trying to retrieve the URL: https://*.agentimediaservices.com/*<https://%2A.agentimediaservices.com/*>

Failed to establish a secure connection to 63.240.52.151

The system returned:

(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)

SSL Certficate error: certificate issuer (CA) not known: /C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA

This proxy and the remote host failed to negotiate a mutually acceptable security settings for handling your request. It is possible that the remote host does not support secure connections, or the proxy is not satisfied with the host security credentials.

Your cache administrator is webmaster<mailto:webmaster?subject=CacheErrorInfo%20-%20ERR_SECURE_CONNECT_FAIL&body=CacheHost%3A%20LNP-Proxy%0D%0AErrPage%3A%20ERR_SECURE_CONNECT_FAIL%0D%0AErr%3A%20(71)%20Protocol%20error%0D%0ATimeStamp%3A%20Thu,%2028%20Apr%202016%2016%3A37%3A14%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.203.24%0D%0AServerIP%3A%2063.240.52.151%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%2063.240.52.151%3A443%0D%0A%0D%0A%0D%0A>.


As I had stated some are "fixable" by adding the url to my broken acl and then not peeking at it. That sometimes works, most of the time not and then I have to add the ip listed to an acl of allowed ips.   This usually works but not in all cases.

That leaves me sort of stuck. I've been having to actually remove folks from the proxy so they could work.  I work for a newspaper and most of the issues lie with the myriad of SEO/Marketing sites/tools these people use. They're horrible.

That leads me to my question of will using that flag make this issue go away?   Granted Im aware it's not the safest I can't deny users access to the sites they need.



I'm running 3.5.16 compiled from source on debian Jessie.  Fully updated.  I'm also confused as to why this is happening.  My ca store is up to date.   I'm confused as to why this is happening.  If I can access all these sites fine without the proxy I'd have to think it's not the cert itself. So it's either debians cert store or something else.  I'm sort of at the end of my knowledge here as to what to troubleshoot.

The other option, though it would be last resort would be to just stop doing anything with https, though all I really wanted was to keep stats on sites visited.

Here is some openssl info.  This leads me to believe its not a squid issue persay, its an openssl issue and or debian issue with certs. But I'm not 100% on that.

bruce at LNP-Proxy:/etc/squid3$ sudo openssl s_client -connect www.agentimediaservices.com:443<http://www.agentimediaservices.com:443> -showcerts
CONNECTED(00000003)
depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street = 195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU = PlatinumSSL Wildcard, CN = *.agentimediaservices.com
verify error:num=20:unable to get local issuer certificate
verify return:1
depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street = 195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU = PlatinumSSL Wildcard, CN = *.agentimediaservices.com
verify error:num=27:certificate not trusted
verify return:1
depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street = 195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU = PlatinumSSL Wildcard, CN = *.agentimediaservices.com
verify error:num=21:unable to verify the first certificate
verify return:1
---
Certificate chain
0 s:/C=US/postalCode=10007/ST=NY/L=New York/street=195 Broadway/O=OMD USA LLC/OU=IT/OU=Hosted by OMD USA INC/OU=PlatinumSSL Wildcard/CN=*.agentimediaservices.com
   i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA
-----BEGIN CERTIFICATE-----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=
-----END CERTIFICATE-----
---
Server certificate
subject=/C=US/postalCode=10007/ST=NY/L=New York/street=195 Broadway/O=OMD USA LLC/OU=IT/OU=Hosted by OMD USA INC/OU=PlatinumSSL Wildcard/CN=*.agentimediaservices.com
issuer=/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA
---
No client certificate CA names sent
---
SSL handshake has read 1678 bytes and written 599 bytes
---
New, TLSv1/SSLv3, Cipher is RC4-MD5
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : RC4-MD5
    Session-ID: 4F9EE34EFA2F6305BBD46D6F367BFDC9F95580A7889D9E1FE91F0F79BA86701F
    Session-ID-ctx:
    Master-Key: F741F597EFC3C837CE52546CC455FFFEBC0F18CCBC74CFB4BE7F1AE3C85EEB9065C39AE50CC525A33C5BD6CCF3D2483A
    Key-Arg   : None
    PSK identity: None
   PSK identity hint: None
    SRP username: None
    Start Time: 1461875411
    Timeout   : 300 (sec)
    Verify return code: 21 (unable to verify the first certificate)
---

Squid.conf:

#Access Lists
acl internal src 192.168.200.0/21
acl wireless src 192.168.100.0/23

#Ports allowed through Squid
acl Safe_ports port 80
acl Safe_ports port 443
acl SSL_ports port 443
acl CONNECT method CONNECT

#acls from blacklist
acl allowed dstdomain -i "/etc/squid3/acls/http_allowed.acl"
acl prime dstdomain -i "/etc/squid3/acls/squid-prime.acl"
acl china dst -n "/etc/squid3/acls/ccd-china.acl"
acl india dst -n "/etc/squid3/acls/ccd-india.acl"
acl iran dst -n "/etc/squid3/acls/ccd-iran.acl"
acl nigeria dst -n "/etc/squid3/acls/ccd-nigeria.acl"
acl pakistan dst -n "/etc/squid3/acls/ccd-nigeria.acl"
acl romania dst -n "/etc/squid3/acls/ccd-romania.acl"
acl russia dst -n "/etc/squid3/acls/ccd-russia.acl"
acl syria dst -n "/etc/squid3/acls/ccd-syria.acl"
acl ukraine dst -n "/etc/squid3/acls/ccd-ukraine.acl"
acl uzbekistan dst -n "/etc/squid3/acls/ccd-uzbekistan.acl"
acl ips dst -n "/etc/squid3/acls/broken_ips.acl"
acl blocked dstdomain -i "/etc/squid3/acls/http_blocked.acl"

#allow/deny
http_access allow allowed
http_access allow ips
http_access deny blocked
http_access deny prime
http_access deny china
http_access deny india
http_access deny iran
http_access deny nigeria
http_access deny pakistan
http_access deny romania
http_access deny russia
http_access deny syria
http_access deny ukraine
http_access deny uzbekistan

http_access allow internal
http_access allow wireless
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all

#Bumping
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"

#ssl_bump peek all
ssl_bump peek !broken_sites
ssl_bump splice all
#ssl_bump splice !broken_sites

sslproxy_capath /etc/ssl/certs

sslcrtd_program /lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
sslcrtd_children 32 startup=5 idle=1


#logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni %ssl::>cert_subject %>Hs %<st %Ss:%Sh

#access_log syslog:daemon.info mine
#access_log daemon:/var/log/squid3/test.log mine

#intercept
http_port 3128 intercept
https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB sslflags=NO_SESSION_REUSE

#nameservers
dns_nameservers 192.168.201.1 8.8.8.8

#WCCPv2 items
wccp_version 2
wccp2_router 192.168.200.73
wccp2_forwarding_method gre
wccp2_return_method gre
wccp2_service standard 0 password=LNP1
wccp2_service dynamic 70 password=LNP1
wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 ports=443

Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758 (o) | bmarkey at steinmancommunications.com<mailto:bmarkey at steinmancommunications.com>
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160428/41d10760/attachment.htm>

From yvoinov at gmail.com  Thu Apr 28 21:42:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 29 Apr 2016 03:42:08 +0600
Subject: [squid-users] Using dont_verify_peer
In-Reply-To: <VI1PR04MB1359E191B57DDC980709E9218F650@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>
 <VI1PR04MB1359E191B57DDC980709E9218F650@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <2f0deaa4-cfa5-2abc-c478-a5dd477bbff4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
With intermediate certificates better to use
sslproxy_foreign_intermediate_certs for many reasons:

1. sslproxy_foreign_intermediate_certs not treated as trusted root CA's.
They only uses for complete certificate chain.

2. Intermediate CA's most often has relatively short expiration, so
better do not mix it with root's.

3. IMHO separate intermediate bundle has less maintenance overhead.

# sslproxy_foreign_intermediate_certs backported from 4.x starting 3.5.13
sslproxy_foreign_intermediate_certs /usr/local/squid/etc/intermediate_ca.pem

I've published here download link to my intermediate_ca.pem I'm using in
my setups. I'm not pretend this bundle is full, but I'm updating it when
meet UNABLE_TO_GET_ISSUER_CERT_LOCALLY.

Note: You need to check intermediate CA's expiration/revocation youself.
So, to do this you need all source intermediates separately. This time
there is no tool to build this bundle automatically, like Mozilla's CA
bundle.

Note 2: Don't - I repeat - DONT USE dont_verify_peer in production
setups. Never. This is dangerous.

29.04.16 2:56, Rafael Akchurin ?????:
>
> Hello Bruce,
>
> 
>
> According to
https://www.ssllabs.com/ssltest/analyze.html?d=agentimediaservices.com
the server does not send the whole chain of certificates and imho squid
cannot automatically download the intermediate certificates like
browsers do.
>
> 
>
> You need to manually add them to the store. Currently we do it like
http://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html
>
> 
>
> I hope Yuri knows everything about adding certificates to the store
and will reply shortly :)
>
> 
>
> If you were using explicit proxy usually making
agentimediaservices.com non bumpable would be enough as squid would
simply pump bytes from browser to site after allowed CONNECT; but as you
have intercepting squid ? I suspect it needs to establish a new
connection to the remote site and thus openssl code that is used when
establishing connections gets a change to fail the connection to a site
with incomplete certificate chain. IMHO :)
>
> 
>
> I am also interested how to bypass it in intercepted scenario.
>
> 
>
> Best regards,
>
> Rafael Akchurin
>
> Diladele B.V.
>
> 
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
*On Behalf Of *Markey, Bruce
> *Sent:* Thursday, April 28, 2016 10:33 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* [squid-users] Using dont_verify_peer
>
> 
>
> I didn?t really get an answer previously so I did some research and
now I?m not quite sure what to do.
>
> 
>
> Problem is I?m getting a lot of these:
>
> 
>
> The following error was encountered while trying to retrieve the URL:
https://*.agentimediaservices.com/* <https://%2A.agentimediaservices.com/*>
>
> *Failed to establish a secure connection to 63.240.52.151*
>
> The system returned:
>
> (71) Protocol error (TLS code:
X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
>
> SSL Certficate error: certificate issuer (CA) not known:
/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA
Organization Validation Secure Server CA
>
> This proxy and the remote host failed to negotiate a mutually
acceptable security settings for handling your request. It is possible
that the remote host does not support secure connections, or the proxy
is not satisfied with the host security credentials.
>
> Your cache administrator is webmaster
<mailto:webmaster?subject=CacheErrorInfo%20-%20ERR_SECURE_CONNECT_FAIL&body=CacheHost%3A%20LNP-Proxy%0D%0AErrPage%3A%20ERR_SECURE_CONNECT_FAIL%0D%0AErr%3A%20(71)%20Protocol%20error%0D%0ATimeStamp%3A%20Thu,%2028%20Apr%202016%2016%3A37%3A14%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.203.24%0D%0AServerIP%3A%2063.240.52.151%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%2063.240.52.151%3A443%0D%0A%0D%0A%0D%0A>.
>
> 
>
> 
>
> As I had stated some are ?fixable? by adding the url to my broken acl
and then not peeking at it. That sometimes works, most of the time not
and then I have to add the ip listed to an acl of allowed ips.   This
usually works but not in all cases.
>
> 
>
> That leaves me sort of stuck. I?ve been having to actually remove
folks from the proxy so they could work.  I work for a newspaper and
most of the issues lie with the myriad of SEO/Marketing sites/tools
these people use. They?re horrible.
>
> 
>
> That leads me to my question of will using that flag make this issue
go away?   Granted Im aware it?s not the safest I can?t deny users
access to the sites they need.
>
> 
>
> 
>
> 
>
> I?m running 3.5.16 compiled from source on debian Jessie.  Fully
updated.  I?m also confused as to why this is happening.  My ca store is
up to date.   I?m confused as to why this is happening.  If I can access
all these sites fine without the proxy I?d have to think it?s not the
cert itself. So it?s either debians cert store or something else.  I?m
sort of at the end of my knowledge here as to what to troubleshoot.
>
> 
>
> The other option, though it would be last resort would be to just stop
doing anything with https, though all I really wanted was to keep stats
on sites visited.
>
> 
>
> Here is some openssl info.  This leads me to believe its not a squid
issue persay, its an openssl issue and or debian issue with certs. But
I?m not 100% on that.
>
> 
>
> bruce at LNP-Proxy:/etc/squid3$ sudo openssl s_client -connect
www.agentimediaservices.com:443 <http://www.agentimediaservices.com:443>
-showcerts
>
> CONNECTED(00000003)
>
> depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street =
195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU =
PlatinumSSL Wildcard, CN = *.agentimediaservices.com
>
> verify error:num=20:unable to get local issuer certificate
>
> verify return:1
>
> depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street =
195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU =
PlatinumSSL Wildcard, CN = *.agentimediaservices.com
>
> verify error:num=27:certificate not trusted
>
> verify return:1
>
> depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street =
195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU =
PlatinumSSL Wildcard, CN = *.agentimediaservices.com
>
> verify error:num=21:unable to verify the first certificate
>
> verify return:1
>
> ---
>
> Certificate chain
>
> 0 s:/C=US/postalCode=10007/ST=NY/L=New York/street=195 Broadway/O=OMD
USA LLC/OU=IT/OU=Hosted by OMD USA INC/OU=PlatinumSSL
Wildcard/CN=*.agentimediaservices.com
>
>    i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA
Limited/CN=COMODO RSA Organization Validation Secure Server CA
>
> -----BEGIN CERTIFICATE-----
>
> MIIF+zCCBOOgAwIBAgIRAMmCjqA+AnLRGj9AxsuZpfMwDQYJKoZIhvcNAQELBQAw
>
> gZYxCzAJBgNVBAYTAkdCMRswGQYDVQQIExJHcmVhdGVyIE1hbmNoZXN0ZXIxEDAO
>
> BgNVBAcTB1NhbGZvcmQxGjAYBgNVBAoTEUNPTU9ETyBDQSBMaW1pdGVkMTwwOgYD
>
> VQQDEzNDT01PRE8gUlNBIE9yZ2FuaXphdGlvbiBWYWxpZGF0aW9uIFNlY3VyZSBT
>
> ZXJ2ZXIgQ0EwHhcNMTUwMTE2MDAwMDAwWhcNMTgwMTE1MjM1OTU5WjCB2jELMAkG
>
> A1UEBhMCVVMxDjAMBgNVBBETBTEwMDA3MQswCQYDVQQIEwJOWTERMA8GA1UEBxMI
>
> TmV3IFlvcmsxFTATBgNVBAkTDDE5NSBCcm9hZHdheTEUMBIGA1UEChMLT01EIFVT
>
> QSBMTEMxCzAJBgNVBAsTAklUMR4wHAYDVQQLExVIb3N0ZWQgYnkgT01EIFVTQSBJ
>
> TkMxHTAbBgNVBAsTFFBsYXRpbnVtU1NMIFdpbGRjYXJkMSIwIAYDVQQDFBkqLmFn
>
> ZW50aW1lZGlhc2VydmljZXMuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB
>
> CgKCAQEA26hgIL5HPDSLX6fySB8fUzbWFHFwEFzPIqt47wdqyNR2moDHrtEJ+ybZ
>
> v+byrRm4b34Zjfvt7n6caV6pcogiazE1ByIEWdEPN7M6jTU4ZiwMfaIfs0T4uNlc
>
> 9I8PKws8u093JRP5DV1AEm2t8JI69msPaK14x4pE6sDRqRuNaXVtLiMBR5B/jurK
>
> xOpv365wb3ckoebFNbOo/AHC8abi3PCaVTVFMu1b1QFI9SVrmHVYAsqVwPiyi2YJ
>
> zkdaHyu51uOmk6kXuVyZT2sfrNyTt9e7UuwqmgqvolncoMyV5MEzR5LZvephPIpM
>
> bV9HNPcDY0KXOKfeDWPpfeFJxosVzQIDAQABo4IB/DCCAfgwHwYDVR0jBBgwFoAU
>
> mvMr2s+tT7YvuypISCoStxtCwSQwHQYDVR0OBBYEFIu+BPXh1FoDihdd/D/iMDMv
>
> bNRhMA4GA1UdDwEB/wQEAwIFoDAMBgNVHRMBAf8EAjAAMB0GA1UdJQQWMBQGCCsG
>
> AQUFBwMBBggrBgEFBQcDAjBQBgNVHSAESTBHMDsGDCsGAQQBsjEBAgEDBDArMCkG
>
> CCsGAQUFBwIBFh1odHRwczovL3NlY3VyZS5jb21vZG8uY29tL0NQUzAIBgZngQwB
>
> AgIwWgYDVR0fBFMwUTBPoE2gS4ZJaHR0cDovL2NybC5jb21vZG9jYS5jb20vQ09N
>
> T0RPUlNBT3JnYW5pemF0aW9uVmFsaWRhdGlvblNlY3VyZVNlcnZlckNBLmNybDCB
>
> iwYIKwYBBQUHAQEEfzB9MFUGCCsGAQUFBzAChklodHRwOi8vY3J0LmNvbW9kb2Nh
>
> LmNvbS9DT01PRE9SU0FPcmdhbml6YXRpb25WYWxpZGF0aW9uU2VjdXJlU2VydmVy
>
> Q0EuY3J0MCQGCCsGAQUFBzABhhhodHRwOi8vb2NzcC5jb21vZG9jYS5jb20wPQYD
>
> VR0RBDYwNIIZKi5hZ2VudGltZWRpYXNlcnZpY2VzLmNvbYIXYWdlbnRpbWVkaWFz
>
> ZXJ2aWNlcy5jb20wDQYJKoZIhvcNAQELBQADggEBACDzmWMa2LpUbcDEh1Quz+ak
>
> 4irQoi97D3iD7HHtZRuLSzR5AT11le56GJR9e/0IlFFlxiA+dwn60OmAAi6EX0zb
>
> 7qAJ5Lemm8PtLcdqAydreaK9uYxhF3J1O4/bJHmCJ6P/n6U5MDTNRHYKx4Vo0Dfy
>
> CepRebqV79BCzRDEBTTL2MOnoFJB5NZciYRcypm4JuKHCDO0XCjkONHIlLLDquKV
>
> cNDI7Q00Ctlw8MriPpT8MPY1pdfIYkEVNp2AXOPQ/gXMHJ7EwFPGk3pnct3a9Nk1
>
> XsLTUSSRN5ggOIVk+qDU+PhgKA5U1V6TJEfEt7WA47DY5DtJqVpV/qMoNaGlU8Y=
>
> -----END CERTIFICATE-----
>
> ---
>
> Server certificate
>
> subject=/C=US/postalCode=10007/ST=NY/L=New York/street=195
Broadway/O=OMD USA LLC/OU=IT/OU=Hosted by OMD USA INC/OU=PlatinumSSL
Wildcard/CN=*.agentimediaservices.com
>
> issuer=/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA
Limited/CN=COMODO RSA Organization Validation Secure Server CA
>
> ---
>
> No client certificate CA names sent
>
> ---
>
> SSL handshake has read 1678 bytes and written 599 bytes
>
> ---
>
> New, TLSv1/SSLv3, Cipher is RC4-MD5
>
> Server public key is 2048 bit
>
> Secure Renegotiation IS supported
>
> Compression: NONE
>
> Expansion: NONE
>
> SSL-Session:
>
>     Protocol  : TLSv1.2
>
>     Cipher    : RC4-MD5
>
>     Session-ID:
4F9EE34EFA2F6305BBD46D6F367BFDC9F95580A7889D9E1FE91F0F79BA86701F
>
>     Session-ID-ctx:
>
>     Master-Key:
F741F597EFC3C837CE52546CC455FFFEBC0F18CCBC74CFB4BE7F1AE3C85EEB9065C39AE50CC525A33C5BD6CCF3D2483A
>
>     Key-Arg   : None
>
>     PSK identity: None
>
>    PSK identity hint: None
>
>     SRP username: None
>
>     Start Time: 1461875411
>
>     Timeout   : 300 (sec)
>
>     Verify return code: 21 (unable to verify the first certificate)
>
> ---
>
> 
>
> Squid.conf:
>
> 
>
> #Access Lists
>
> acl internal src 192.168.200.0/21
>
> acl wireless src 192.168.100.0/23
>
> 
>
> #Ports allowed through Squid
>
> acl Safe_ports port 80
>
> acl Safe_ports port 443
>
> acl SSL_ports port 443
>
> acl CONNECT method CONNECT
>
> 
>
> #acls from blacklist
>
> acl allowed dstdomain -i "/etc/squid3/acls/http_allowed.acl"
>
> acl prime dstdomain -i "/etc/squid3/acls/squid-prime.acl"
>
> acl china dst -n "/etc/squid3/acls/ccd-china.acl"
>
> acl india dst -n "/etc/squid3/acls/ccd-india.acl"
>
> acl iran dst -n "/etc/squid3/acls/ccd-iran.acl"
>
> acl nigeria dst -n "/etc/squid3/acls/ccd-nigeria.acl"
>
> acl pakistan dst -n "/etc/squid3/acls/ccd-nigeria.acl"
>
> acl romania dst -n "/etc/squid3/acls/ccd-romania.acl"
>
> acl russia dst -n "/etc/squid3/acls/ccd-russia.acl"
>
> acl syria dst -n "/etc/squid3/acls/ccd-syria.acl"
>
> acl ukraine dst -n "/etc/squid3/acls/ccd-ukraine.acl"
>
> acl uzbekistan dst -n "/etc/squid3/acls/ccd-uzbekistan.acl"
>
> acl ips dst -n "/etc/squid3/acls/broken_ips.acl"
>
> acl blocked dstdomain -i "/etc/squid3/acls/http_blocked.acl"
>
> 
>
> #allow/deny
>
> http_access allow allowed
>
> http_access allow ips
>
> http_access deny blocked
>
> http_access deny prime
>
> http_access deny china
>
> http_access deny india
>
> http_access deny iran
>
> http_access deny nigeria
>
> http_access deny pakistan
>
> http_access deny romania
>
> http_access deny russia
>
> http_access deny syria
>
> http_access deny ukraine
>
> http_access deny uzbekistan
>
> 
>
> http_access allow internal
>
> http_access allow wireless
>
> http_access deny !Safe_ports
>
> http_access deny CONNECT !SSL_ports
>
> http_access deny all
>
> 
>
> #Bumping
>
> acl step1 at_step SslBump1
>
> acl step2 at_step SslBump2
>
> acl step3 at_step SslBump3
>
> 
>
> acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"
>
> 
>
> #ssl_bump peek all
>
> ssl_bump peek !broken_sites
>
> ssl_bump splice all
>
> #ssl_bump splice !broken_sites
>
> 
>
> sslproxy_capath /etc/ssl/certs
>
> 
>
> sslcrtd_program /lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
>
> sslcrtd_children 32 startup=5 idle=1
>
> 
>
> 
>
> #logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni
%ssl::>cert_subject %>Hs %<st %Ss:%Sh
>
> 
>
> #access_log syslog:daemon.info mine
>
> #access_log daemon:/var/log/squid3/test.log mine
>
> 
>
> #intercept
>
> http_port 3128 intercept
>
> https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem
cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem 
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslflags=NO_SESSION_REUSE
>
> 
>
> #nameservers
>
> dns_nameservers 192.168.201.1 8.8.8.8
>
> 
>
> #WCCPv2 items
>
> wccp_version 2
>
> wccp2_router 192.168.200.73
>
> wccp2_forwarding_method gre
>
> wccp2_return_method gre
>
> wccp2_service standard 0 password=LNP1
>
> wccp2_service dynamic 70 password=LNP1
>
> wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240
ports=443
>
> 
>
> *Bruce Markey*| Network Security Analyst
>
> STEINMANCOMMUNICATIONS
>
> 717.291.8758 (o) | _bmarkey at steinmancommunications.com
<mailto:bmarkey at steinmancommunications.com>_
>
> 8 West King St| PO Box 1328,Lancaster, PA 17608-1328
>
> 
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXIoOwAAoJENNXIZxhPexGyhwH/iys6RATQ+spnune1egNhMal
OcYXbZoC+mtIF5axYxLALNe+codKZlEEEcbdqQIRVx9EtM3q6ilwVhw0tJ6r2N4G
87h0sfRvTzdWVrHXjdmZhgDzj1TjIfb74W2nRWBMrSEbPrEinEJHaMqtO2/5iXBX
/k4GqAsq8LZi8fKEwKdiENYp82ywe5fsVleG6RxIlP4ek7dyAFj21XHWCvc0+Fwc
wzbC06H/3Uik797IlXB3opeWQfemxXqs9OzK/u+P8SNUgoQTLcz4DFpillg/8u9T
IJMSSxIbOqxIzKLT9+SFIno9GBgkjJ6MvorUVd24aMqbUr0jWp6a+vjN2X9HFk8=
=JLmW
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/1d355b36/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/1d355b36/attachment.key>

From yvoinov at gmail.com  Thu Apr 28 21:52:11 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 29 Apr 2016 03:52:11 +0600
Subject: [squid-users] Using dont_verify_peer
In-Reply-To: <VI1PR04MB1359E191B57DDC980709E9218F650@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>
 <VI1PR04MB1359E191B57DDC980709E9218F650@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <88360dd6-6c52-331b-49cb-11c547febff9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
For the future: using SSL Bump dangerous enough itself, so the less it
will be all kinds of exceptions - the better.

29.04.16 2:56, Rafael Akchurin ?????:
>
> Hello Bruce,
>
> 
>
> According to
https://www.ssllabs.com/ssltest/analyze.html?d=agentimediaservices.com
the server does not send the whole chain of certificates and imho squid
cannot automatically download the intermediate certificates like
browsers do.
>
> 
>
> You need to manually add them to the store. Currently we do it like
http://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html
>
> 
>
> I hope Yuri knows everything about adding certificates to the store
and will reply shortly :)
>
> 
>
> If you were using explicit proxy usually making
agentimediaservices.com non bumpable would be enough as squid would
simply pump bytes from browser to site after allowed CONNECT; but as you
have intercepting squid ? I suspect it needs to establish a new
connection to the remote site and thus openssl code that is used when
establishing connections gets a change to fail the connection to a site
with incomplete certificate chain. IMHO :)
>
> 
>
> I am also interested how to bypass it in intercepted scenario.
>
> 
>
> Best regards,
>
> Rafael Akchurin
>
> Diladele B.V.
>
> 
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
*On Behalf Of *Markey, Bruce
> *Sent:* Thursday, April 28, 2016 10:33 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* [squid-users] Using dont_verify_peer
>
> 
>
> I didn?t really get an answer previously so I did some research and
now I?m not quite sure what to do.
>
> 
>
> Problem is I?m getting a lot of these:
>
> 
>
> The following error was encountered while trying to retrieve the URL:
https://*.agentimediaservices.com/* <https://%2A.agentimediaservices.com/*>
>
> *Failed to establish a secure connection to 63.240.52.151*
>
> The system returned:
>
> (71) Protocol error (TLS code:
X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
>
> SSL Certficate error: certificate issuer (CA) not known:
/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA
Organization Validation Secure Server CA
>
> This proxy and the remote host failed to negotiate a mutually
acceptable security settings for handling your request. It is possible
that the remote host does not support secure connections, or the proxy
is not satisfied with the host security credentials.
>
> Your cache administrator is webmaster
<mailto:webmaster?subject=CacheErrorInfo%20-%20ERR_SECURE_CONNECT_FAIL&body=CacheHost%3A%20LNP-Proxy%0D%0AErrPage%3A%20ERR_SECURE_CONNECT_FAIL%0D%0AErr%3A%20(71)%20Protocol%20error%0D%0ATimeStamp%3A%20Thu,%2028%20Apr%202016%2016%3A37%3A14%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.203.24%0D%0AServerIP%3A%2063.240.52.151%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%2063.240.52.151%3A443%0D%0A%0D%0A%0D%0A>.
>
> 
>
> 
>
> As I had stated some are ?fixable? by adding the url to my broken acl
and then not peeking at it. That sometimes works, most of the time not
and then I have to add the ip listed to an acl of allowed ips.   This
usually works but not in all cases.
>
> 
>
> That leaves me sort of stuck. I?ve been having to actually remove
folks from the proxy so they could work.  I work for a newspaper and
most of the issues lie with the myriad of SEO/Marketing sites/tools
these people use. They?re horrible.
>
> 
>
> That leads me to my question of will using that flag make this issue
go away?   Granted Im aware it?s not the safest I can?t deny users
access to the sites they need.
>
> 
>
> 
>
> 
>
> I?m running 3.5.16 compiled from source on debian Jessie.  Fully
updated.  I?m also confused as to why this is happening.  My ca store is
up to date.   I?m confused as to why this is happening.  If I can access
all these sites fine without the proxy I?d have to think it?s not the
cert itself. So it?s either debians cert store or something else.  I?m
sort of at the end of my knowledge here as to what to troubleshoot.
>
> 
>
> The other option, though it would be last resort would be to just stop
doing anything with https, though all I really wanted was to keep stats
on sites visited.
>
> 
>
> Here is some openssl info.  This leads me to believe its not a squid
issue persay, its an openssl issue and or debian issue with certs. But
I?m not 100% on that.
>
> 
>
> bruce at LNP-Proxy:/etc/squid3$ sudo openssl s_client -connect
www.agentimediaservices.com:443 <http://www.agentimediaservices.com:443>
-showcerts
>
> CONNECTED(00000003)
>
> depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street =
195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU =
PlatinumSSL Wildcard, CN = *.agentimediaservices.com
>
> verify error:num=20:unable to get local issuer certificate
>
> verify return:1
>
> depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street =
195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU =
PlatinumSSL Wildcard, CN = *.agentimediaservices.com
>
> verify error:num=27:certificate not trusted
>
> verify return:1
>
> depth=0 C = US, postalCode = 10007, ST = NY, L = New York, street =
195 Broadway, O = OMD USA LLC, OU = IT, OU = Hosted by OMD USA INC, OU =
PlatinumSSL Wildcard, CN = *.agentimediaservices.com
>
> verify error:num=21:unable to verify the first certificate
>
> verify return:1
>
> ---
>
> Certificate chain
>
> 0 s:/C=US/postalCode=10007/ST=NY/L=New York/street=195 Broadway/O=OMD
USA LLC/OU=IT/OU=Hosted by OMD USA INC/OU=PlatinumSSL
Wildcard/CN=*.agentimediaservices.com
>
>    i:/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA
Limited/CN=COMODO RSA Organization Validation Secure Server CA
>
> -----BEGIN CERTIFICATE-----
>
> MIIF+zCCBOOgAwIBAgIRAMmCjqA+AnLRGj9AxsuZpfMwDQYJKoZIhvcNAQELBQAw
>
> gZYxCzAJBgNVBAYTAkdCMRswGQYDVQQIExJHcmVhdGVyIE1hbmNoZXN0ZXIxEDAO
>
> BgNVBAcTB1NhbGZvcmQxGjAYBgNVBAoTEUNPTU9ETyBDQSBMaW1pdGVkMTwwOgYD
>
> VQQDEzNDT01PRE8gUlNBIE9yZ2FuaXphdGlvbiBWYWxpZGF0aW9uIFNlY3VyZSBT
>
> ZXJ2ZXIgQ0EwHhcNMTUwMTE2MDAwMDAwWhcNMTgwMTE1MjM1OTU5WjCB2jELMAkG
>
> A1UEBhMCVVMxDjAMBgNVBBETBTEwMDA3MQswCQYDVQQIEwJOWTERMA8GA1UEBxMI
>
> TmV3IFlvcmsxFTATBgNVBAkTDDE5NSBCcm9hZHdheTEUMBIGA1UEChMLT01EIFVT
>
> QSBMTEMxCzAJBgNVBAsTAklUMR4wHAYDVQQLExVIb3N0ZWQgYnkgT01EIFVTQSBJ
>
> TkMxHTAbBgNVBAsTFFBsYXRpbnVtU1NMIFdpbGRjYXJkMSIwIAYDVQQDFBkqLmFn
>
> ZW50aW1lZGlhc2VydmljZXMuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB
>
> CgKCAQEA26hgIL5HPDSLX6fySB8fUzbWFHFwEFzPIqt47wdqyNR2moDHrtEJ+ybZ
>
> v+byrRm4b34Zjfvt7n6caV6pcogiazE1ByIEWdEPN7M6jTU4ZiwMfaIfs0T4uNlc
>
> 9I8PKws8u093JRP5DV1AEm2t8JI69msPaK14x4pE6sDRqRuNaXVtLiMBR5B/jurK
>
> xOpv365wb3ckoebFNbOo/AHC8abi3PCaVTVFMu1b1QFI9SVrmHVYAsqVwPiyi2YJ
>
> zkdaHyu51uOmk6kXuVyZT2sfrNyTt9e7UuwqmgqvolncoMyV5MEzR5LZvephPIpM
>
> bV9HNPcDY0KXOKfeDWPpfeFJxosVzQIDAQABo4IB/DCCAfgwHwYDVR0jBBgwFoAU
>
> mvMr2s+tT7YvuypISCoStxtCwSQwHQYDVR0OBBYEFIu+BPXh1FoDihdd/D/iMDMv
>
> bNRhMA4GA1UdDwEB/wQEAwIFoDAMBgNVHRMBAf8EAjAAMB0GA1UdJQQWMBQGCCsG
>
> AQUFBwMBBggrBgEFBQcDAjBQBgNVHSAESTBHMDsGDCsGAQQBsjEBAgEDBDArMCkG
>
> CCsGAQUFBwIBFh1odHRwczovL3NlY3VyZS5jb21vZG8uY29tL0NQUzAIBgZngQwB
>
> AgIwWgYDVR0fBFMwUTBPoE2gS4ZJaHR0cDovL2NybC5jb21vZG9jYS5jb20vQ09N
>
> T0RPUlNBT3JnYW5pemF0aW9uVmFsaWRhdGlvblNlY3VyZVNlcnZlckNBLmNybDCB
>
> iwYIKwYBBQUHAQEEfzB9MFUGCCsGAQUFBzAChklodHRwOi8vY3J0LmNvbW9kb2Nh
>
> LmNvbS9DT01PRE9SU0FPcmdhbml6YXRpb25WYWxpZGF0aW9uU2VjdXJlU2VydmVy
>
> Q0EuY3J0MCQGCCsGAQUFBzABhhhodHRwOi8vb2NzcC5jb21vZG9jYS5jb20wPQYD
>
> VR0RBDYwNIIZKi5hZ2VudGltZWRpYXNlcnZpY2VzLmNvbYIXYWdlbnRpbWVkaWFz
>
> ZXJ2aWNlcy5jb20wDQYJKoZIhvcNAQELBQADggEBACDzmWMa2LpUbcDEh1Quz+ak
>
> 4irQoi97D3iD7HHtZRuLSzR5AT11le56GJR9e/0IlFFlxiA+dwn60OmAAi6EX0zb
>
> 7qAJ5Lemm8PtLcdqAydreaK9uYxhF3J1O4/bJHmCJ6P/n6U5MDTNRHYKx4Vo0Dfy
>
> CepRebqV79BCzRDEBTTL2MOnoFJB5NZciYRcypm4JuKHCDO0XCjkONHIlLLDquKV
>
> cNDI7Q00Ctlw8MriPpT8MPY1pdfIYkEVNp2AXOPQ/gXMHJ7EwFPGk3pnct3a9Nk1
>
> XsLTUSSRN5ggOIVk+qDU+PhgKA5U1V6TJEfEt7WA47DY5DtJqVpV/qMoNaGlU8Y=
>
> -----END CERTIFICATE-----
>
> ---
>
> Server certificate
>
> subject=/C=US/postalCode=10007/ST=NY/L=New York/street=195
Broadway/O=OMD USA LLC/OU=IT/OU=Hosted by OMD USA INC/OU=PlatinumSSL
Wildcard/CN=*.agentimediaservices.com
>
> issuer=/C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA
Limited/CN=COMODO RSA Organization Validation Secure Server CA
>
> ---
>
> No client certificate CA names sent
>
> ---
>
> SSL handshake has read 1678 bytes and written 599 bytes
>
> ---
>
> New, TLSv1/SSLv3, Cipher is RC4-MD5
>
> Server public key is 2048 bit
>
> Secure Renegotiation IS supported
>
> Compression: NONE
>
> Expansion: NONE
>
> SSL-Session:
>
>     Protocol  : TLSv1.2
>
>     Cipher    : RC4-MD5
>
>     Session-ID:
4F9EE34EFA2F6305BBD46D6F367BFDC9F95580A7889D9E1FE91F0F79BA86701F
>
>     Session-ID-ctx:
>
>     Master-Key:
F741F597EFC3C837CE52546CC455FFFEBC0F18CCBC74CFB4BE7F1AE3C85EEB9065C39AE50CC525A33C5BD6CCF3D2483A
>
>     Key-Arg   : None
>
>     PSK identity: None
>
>    PSK identity hint: None
>
>     SRP username: None
>
>     Start Time: 1461875411
>
>     Timeout   : 300 (sec)
>
>     Verify return code: 21 (unable to verify the first certificate)
>
> ---
>
> 
>
> Squid.conf:
>
> 
>
> #Access Lists
>
> acl internal src 192.168.200.0/21
>
> acl wireless src 192.168.100.0/23
>
> 
>
> #Ports allowed through Squid
>
> acl Safe_ports port 80
>
> acl Safe_ports port 443
>
> acl SSL_ports port 443
>
> acl CONNECT method CONNECT
>
> 
>
> #acls from blacklist
>
> acl allowed dstdomain -i "/etc/squid3/acls/http_allowed.acl"
>
> acl prime dstdomain -i "/etc/squid3/acls/squid-prime.acl"
>
> acl china dst -n "/etc/squid3/acls/ccd-china.acl"
>
> acl india dst -n "/etc/squid3/acls/ccd-india.acl"
>
> acl iran dst -n "/etc/squid3/acls/ccd-iran.acl"
>
> acl nigeria dst -n "/etc/squid3/acls/ccd-nigeria.acl"
>
> acl pakistan dst -n "/etc/squid3/acls/ccd-nigeria.acl"
>
> acl romania dst -n "/etc/squid3/acls/ccd-romania.acl"
>
> acl russia dst -n "/etc/squid3/acls/ccd-russia.acl"
>
> acl syria dst -n "/etc/squid3/acls/ccd-syria.acl"
>
> acl ukraine dst -n "/etc/squid3/acls/ccd-ukraine.acl"
>
> acl uzbekistan dst -n "/etc/squid3/acls/ccd-uzbekistan.acl"
>
> acl ips dst -n "/etc/squid3/acls/broken_ips.acl"
>
> acl blocked dstdomain -i "/etc/squid3/acls/http_blocked.acl"
>
> 
>
> #allow/deny
>
> http_access allow allowed
>
> http_access allow ips
>
> http_access deny blocked
>
> http_access deny prime
>
> http_access deny china
>
> http_access deny india
>
> http_access deny iran
>
> http_access deny nigeria
>
> http_access deny pakistan
>
> http_access deny romania
>
> http_access deny russia
>
> http_access deny syria
>
> http_access deny ukraine
>
> http_access deny uzbekistan
>
> 
>
> http_access allow internal
>
> http_access allow wireless
>
> http_access deny !Safe_ports
>
> http_access deny CONNECT !SSL_ports
>
> http_access deny all
>
> 
>
> #Bumping
>
> acl step1 at_step SslBump1
>
> acl step2 at_step SslBump2
>
> acl step3 at_step SslBump3
>
> 
>
> acl broken_sites ssl::server_name_regex "/etc/squid3/acls/http_broken.txt"
>
> 
>
> #ssl_bump peek all
>
> ssl_bump peek !broken_sites
>
> ssl_bump splice all
>
> #ssl_bump splice !broken_sites
>
> 
>
> sslproxy_capath /etc/ssl/certs
>
> 
>
> sslcrtd_program /lib/squid3/ssl_crtd -s /etc/squid3/ssl_db -M 4MB
>
> sslcrtd_children 32 startup=5 idle=1
>
> 
>
> 
>
> #logformat mine %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %ssl::>sni
%ssl::>cert_subject %>Hs %<st %Ss:%Sh
>
> 
>
> #access_log syslog:daemon.info mine
>
> #access_log daemon:/var/log/squid3/test.log mine
>
> 
>
> #intercept
>
> http_port 3128 intercept
>
> https_port 3129 intercept ssl-bump cert=/etc/squid3/certs/squid.pem
cafile=/etc/squid3/certs/squid.pem key=/etc/squid3/certs/squid.pem 
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslflags=NO_SESSION_REUSE
>
> 
>
> #nameservers
>
> dns_nameservers 192.168.201.1 8.8.8.8
>
> 
>
> #WCCPv2 items
>
> wccp_version 2
>
> wccp2_router 192.168.200.73
>
> wccp2_forwarding_method gre
>
> wccp2_return_method gre
>
> wccp2_service standard 0 password=LNP1
>
> wccp2_service dynamic 70 password=LNP1
>
> wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240
ports=443
>
> 
>
> *Bruce Markey*| Network Security Analyst
>
> STEINMANCOMMUNICATIONS
>
> 717.291.8758 (o) | _bmarkey at steinmancommunications.com
<mailto:bmarkey at steinmancommunications.com>_
>
> 8 West King St| PO Box 1328,Lancaster, PA 17608-1328
>
> 
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXIoYKAAoJENNXIZxhPexG2KQH/0xu7wFziLMCa/GTRJ477Ndc
RVq4uWq+omb7E9wHIXjvPMiDPhahVEDymO28l5naTgfbqqQmowDg4BoWYulJmsRj
V3HSQr7IY47vHp04PlCjNr/Td+AxDNsx7Mb24OzkiG4R6muFTefbfKbnkufIuVAG
/gbqtHYJ/oOVfdeAVy9apADiX13WCUXE++8K0yYZ5aSm0FptjLXyBJ8/3oyczJWh
jPUYzWQrfjob9EYQbGcYEWe+0ctCKvAje1ZBy9DZaK6WtrDYZIQT2pVK2SHoui7s
YtNqo3mQZgSvgIQwxSkRkkzAB2lQoE9esUp9yhcUo9TBa5wYqqCL7n3N+Dxp/os=
=Z635
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/f9081e75/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/f9081e75/attachment.key>

From reet.vyas28 at gmail.com  Fri Apr 29 10:33:58 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Fri, 29 Apr 2016 16:03:58 +0530
Subject: [squid-users] Block VPN access like hola.org ,ultrasurf
Message-ID: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>

Hi,

I have working trasparent squid , Some users are using proxy vpn in
moziilla as addon and bypassing my squid, Please tell me how to block all
hola.org vpn and ulrta surf, I have already blocked websites,but seems not
working.

Please let me know how to block these vpn access.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/d6a6f845/attachment.htm>

From yvoinov at gmail.com  Fri Apr 29 10:49:01 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 29 Apr 2016 16:49:01 +0600
Subject: [squid-users] Block VPN access like hola.org ,ultrasurf
In-Reply-To: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>
References: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>
Message-ID: <1ec90c04-477c-031e-7223-e7f9be71dcf8@gmail.com>

Not with squid, man.

Only on Cisco/another router by IP.

ip access-list extended TO_INET
  remark Hamachi
  deny   ip 25.0.0.0 0.255.255.255 any
  deny   ip 64.34.106.0 0.0.0.255 any
  deny   ip any host 69.25.21.195
  deny   ip any host 74.201.75.195
  deny   ip any host 146.255.195.92
  remark ZenMate servers
  deny   ip any 162.159.244.0 0.0.0.255
  deny   ip any 78.137.96.0 0.0.7.255
  deny   ip any 46.165.192.0 0.0.63.255
  deny   ip any 207.244.64.0 0.0.63.255
  deny   ip any 178.162.128.0 0.0.127.255
  deny   ip any 179.43.128.0 0.0.31.255
  deny   ip any 88.150.192.0 0.0.31.255
  deny   ip any 31.7.56.0 0.0.7.255
  deny   ip any 185.12.44.0 0.0.3.255
  deny   ip any 103.10.197.0 0.0.0.255
  deny   ip any 37.58.48.0 0.0.15.255
  deny   ip any 5.152.192.0 0.0.31.255
  deny   ip any 81.17.16.0 0.0.15.255
  deny   ip any 199.115.112.0 0.0.7.255
  deny   ip any 103.10.199.0 0.0.0.255
  remark Opera Turbo servers
  deny   ip any 37.228.104.0 0.0.7.255
  deny   ip any 141.0.8.0 0.0.7.255
  deny   ip any 82.145.208.0 0.0.15.255
  deny   ip any 195.189.142.0 0.0.1.255
  deny   ip any 185.26.180.0 0.0.3.255
  remark Ultrasurf port
  deny   tcp any any eq 9666
  remark Hola
  deny   ip any host 107.22.193.119
  deny   ip any host 54.225.121.9
  deny   ip any host 54.225.227.202
  deny   ip any host 54.243.128.120
  deny   tcp any any eq 6851
  deny   tcp any any eq 6861
  deny   ip any 107.155.75.0 0.0.0.255
  deny   ip any 103.18.42.0 0.0.0.255
  deny   ip any 103.27.232.0 0.0.0.255
  deny   ip any 103.4.16.0 0.0.0.255
  deny   ip any 103.6.87.0 0.0.0.255
  deny   ip any 104.131.128.0 0.0.15.255
  deny   ip any 106.185.0.0 0.0.127.255
  deny   ip any 106.186.64.0 0.0.63.255
  deny   ip any 106.187.0.0 0.0.63.255
  deny   ip any 107.155.85.0 0.0.0.255
  deny   ip any 107.161.144.0 0.0.7.255
  deny   ip any 107.170.0.0 0.0.127.255
  deny   ip any 107.181.166.0 0.0.0.255
  deny   ip any 107.190.128.0 0.0.15.255
  deny   ip any 107.191.100.0 0.0.3.255
  deny   ip any 108.61.208.0 0.0.1.255
  deny   ip any 109.74.192.0 0.0.15.255
  deny   ip any 128.199.128.0 0.0.63.255
  deny   ip any 14.136.236.0 0.0.0.255
  deny   ip any 149.154.157.0 0.0.0.255
  deny   ip any 149.62.168.0 0.0.3.255
  deny   ip any 151.236.18.0 0.0.0.255
  deny   ip any 158.255.208.0 0.0.0.255
  deny   ip any 162.213.197.0 0.0.0.255
  deny   ip any 162.217.132.0 0.0.3.255
  deny   ip any 162.218.92.0 0.0.1.255
  deny   ip any 162.221.180.0 0.0.1.255
  deny   ip any 162.243.0.0 0.0.127.255
  deny   ip any 167.88.112.0 0.0.3.255
  deny   ip any 168.235.64.0 0.0.3.255
  deny   ip any 173.255.192.0 0.0.15.255
  deny   ip any 176.58.96.0 0.0.31.255
  deny   ip any 176.9.0.0 0.0.255.255
  deny   ip any 177.67.81.0 0.0.0.255
  deny   ip any 178.209.32.0 0.0.31.255
  deny   ip any 178.79.128.0 0.0.63.255
  deny   ip any 192.110.160.0 0.0.0.255
  deny   ip any 192.121.112.0 0.0.0.255
  deny   ip any 192.184.80.0 0.0.7.255
  deny   ip any 192.211.49.0 0.0.0.255
  deny   ip any 192.241.160.0 0.0.31.255
  deny   ip any 192.30.32.0 0.0.3.255
  deny   ip any 192.34.56.0 0.0.7.255
  deny   ip any 192.40.56.0 0.0.0.255
  deny   ip any 192.73.232.0 0.0.7.255
  deny   ip any 192.81.208.0 0.0.7.255
  deny   ip any 192.99.0.0 0.0.255.255
  deny   ip any 198.147.20.0 0.0.0.255
  deny   ip any 198.211.96.0 0.0.15.255
  deny   ip any 198.58.96.0 0.0.31.255
  deny   ip any 199.241.28.0 0.0.3.255
  deny   ip any 208.68.36.0 0.0.3.255
  deny   ip any 209.222.30.0 0.0.0.255
  deny   ip any 213.229.64.0 0.0.63.255
  deny   ip any 217.170.192.0 0.0.15.255
  deny   ip any 217.78.0.0 0.0.15.255
  deny   ip any 23.227.160.0 0.0.0.255
  deny   ip any 23.249.168.0 0.0.1.255
  deny   ip any 23.29.124.0 0.0.0.255
  deny   ip any 31.193.128.0 0.0.15.255
  deny   ip any 31.220.24.0 0.0.3.255
  deny   ip any 37.139.0.0 0.0.31.255
  deny   ip any 37.235.52.0 0.0.0.255
  deny   ip any 41.215.240.0 0.0.0.255
  deny   ip any 41.223.52.0 0.0.0.255
  deny   ip any 46.17.56.0 0.0.7.255
  deny   ip any 46.19.136.0 0.0.7.255
  deny   ip any 46.246.0.0 0.0.127.255
  deny   ip any 46.38.48.0 0.0.7.255
  deny   ip any 46.4.0.0 0.0.255.255
  deny   ip any 5.9.0.0 0.0.255.255
  deny   ip any 50.116.32.0 0.0.15.255
  deny   ip any 66.85.128.0 0.0.63.255
  deny   ip any 74.82.192.0 0.0.31.255
  deny   ip any 77.237.248.0 0.0.1.255
  deny   ip any 81.4.108.0 0.0.3.255
  deny   ip any 85.234.128.0 0.0.31.255
  deny   ip any 88.150.156.0 0.0.3.255
  deny   ip any 91.186.0.0 0.0.31.255
  deny   ip any 92.222.0.0 0.0.255.255
  deny   ip any 92.48.64.0 0.0.63.255
  deny   ip any 94.76.192.0 0.0.63.255
  deny   ip any 95.215.44.0 0.0.3.255
  deny   ip any 96.126.96.0 0.0.7.255
  remark Browsec
  deny   ip any 178.62.64.0 0.0.63.255
  deny   ip any 178.62.0.0 0.0.63.255
  deny   ip any 46.101.0.0 0.0.63.255
  deny   ip any 5.101.111.0 0.0.0.255
  deny   ip any 45.55.96.0 0.0.31.255
  deny   ip any 45.55.192.0 0.0.63.255
  deny   ip any 45.55.128.0 0.0.63.255
  deny   ip any 162.243.188.0 0.0.1.255
  deny   ip any 162.243.176.0 0.0.7.255
  deny   ip any 104.236.64.0 0.0.63.255
  deny   ip any 104.236.192.0 0.0.63.255
  deny   ip any 104.236.0.0 0.0.63.255
  deny   ip any 104.131.64.0 0.0.63.255
  deny   ip any 104.131.176.0 0.0.15.255
  deny   ip any 104.131.160.0 0.0.15.255
  deny   ip any 104.131.0.0 0.0.63.255
  deny   ip any 198.199.96.0 0.0.15.255
  deny   ip any 198.199.92.0 0.0.3.255
  deny   ip any 198.199.112.0 0.0.7.255
  deny   ip any 192.241.224.0 0.0.15.255
  deny   ip any 192.241.192.0 0.0.31.255
  deny   ip any 162.243.128.0 0.0.31.255
  deny   ip any 107.170.192.0 0.0.63.255
  deny   ip any 104.236.128.0 0.0.63.255
  deny   ip any 104.131.144.0 0.0.15.255
  deny   ip any 95.85.0.0 0.0.63.255
  deny   ip any 80.240.128.0 0.0.15.255
  deny   ip any 5.101.96.0 0.0.7.255
  deny   ip any 5.101.104.0 0.0.3.255
  deny   ip any 188.226.128.0 0.0.127.255
  deny   ip any 178.62.128.0 0.0.63.255
  deny   ip any 146.185.184.0 0.0.7.255
  deny   ip any 5.101.110.0 0.0.0.255
  deny   ip any 188.166.64.0 0.0.63.255
  deny   ip any 188.166.0.0 0.0.63.255
  deny   ip any 178.62.192.0 0.0.63.255
  deny   ip any 128.199.32.0 0.0.31.255
  deny   ip any 192.241.240.0 0.0.15.255
  deny   ip any 162.243.192.0 0.0.63.255
  deny   ip any 162.243.191.0 0.0.0.255
  deny   ip any 107.170.160.0 0.0.31.255
  deny   ip any 107.170.128.0 0.0.31.255
  deny   ip any 104.131.224.0 0.0.31.255
  deny   ip any 104.131.192.0 0.0.31.255
  deny   ip any 128.199.64.0 0.0.63.255
  deny   ip any 128.199.192.0 0.0.63.255
  deny   ip any 103.253.144.0 0.0.3.255
  remark Stealthy
  deny   ip any 118.97.128.0 0.0.15.255
  deny   ip any 41.231.0.0 0.0.255.255
  deny   ip any 195.154.0.0 0.0.255.255
  remark Finally pass internal LAN to NAT
  permit ip 192.168.0.0 0.0.255.255 any

Hope this helps.

29.04.16 16:33, Reet Vyas ?????:
> Hi,
>
> I have working trasparent squid , Some users are using proxy vpn in 
> moziilla as addon and bypassing my squid, Please tell me how to block 
> all hola.org <http://hola.org> vpn and ulrta surf, I have already 
> blocked websites,but seems not working.
>
> Please let me know how to block these vpn access.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/7ee3cc66/attachment.htm>

From yvoinov at gmail.com  Fri Apr 29 10:52:25 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 29 Apr 2016 16:52:25 +0600
Subject: [squid-users] Block VPN access like hola.org ,ultrasurf
In-Reply-To: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>
References: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>
Message-ID: <8cc8dd00-feb9-0e76-e4a7-81da87b7f871@gmail.com>

Not with squid, man.

Only on Cisco/another router by IP.

ip access-list extended TO_INET
  remark Hamachi
  deny   ip 25.0.0.0 0.255.255.255 any
  deny   ip 64.34.106.0 0.0.0.255 any
  deny   ip any host 69.25.21.195
  deny   ip any host 74.201.75.195
  deny   ip any host 146.255.195.92
  remark ZenMate servers
  deny   ip any 162.159.244.0 0.0.0.255
  deny   ip any 78.137.96.0 0.0.7.255
  deny   ip any 46.165.192.0 0.0.63.255
  deny   ip any 207.244.64.0 0.0.63.255
  deny   ip any 178.162.128.0 0.0.127.255
  deny   ip any 179.43.128.0 0.0.31.255
  deny   ip any 88.150.192.0 0.0.31.255
  deny   ip any 31.7.56.0 0.0.7.255
  deny   ip any 185.12.44.0 0.0.3.255
  deny   ip any 103.10.197.0 0.0.0.255
  deny   ip any 37.58.48.0 0.0.15.255
  deny   ip any 5.152.192.0 0.0.31.255
  deny   ip any 81.17.16.0 0.0.15.255
  deny   ip any 199.115.112.0 0.0.7.255
  deny   ip any 103.10.199.0 0.0.0.255
  remark Opera Turbo servers
  deny   ip any 37.228.104.0 0.0.7.255
  deny   ip any 141.0.8.0 0.0.7.255
  deny   ip any 82.145.208.0 0.0.15.255
  deny   ip any 195.189.142.0 0.0.1.255
  deny   ip any 185.26.180.0 0.0.3.255
  remark Ultrasurf port
  deny   tcp any any eq 9666
  remark Hola
  deny   ip any host 107.22.193.119
  deny   ip any host 54.225.121.9
  deny   ip any host 54.225.227.202
  deny   ip any host 54.243.128.120
  deny   tcp any any eq 6851
  deny   tcp any any eq 6861
  deny   ip any 107.155.75.0 0.0.0.255
  deny   ip any 103.18.42.0 0.0.0.255
  deny   ip any 103.27.232.0 0.0.0.255
  deny   ip any 103.4.16.0 0.0.0.255
  deny   ip any 103.6.87.0 0.0.0.255
  deny   ip any 104.131.128.0 0.0.15.255
  deny   ip any 106.185.0.0 0.0.127.255
  deny   ip any 106.186.64.0 0.0.63.255
  deny   ip any 106.187.0.0 0.0.63.255
  deny   ip any 107.155.85.0 0.0.0.255
  deny   ip any 107.161.144.0 0.0.7.255
  deny   ip any 107.170.0.0 0.0.127.255
  deny   ip any 107.181.166.0 0.0.0.255
  deny   ip any 107.190.128.0 0.0.15.255
  deny   ip any 107.191.100.0 0.0.3.255
  deny   ip any 108.61.208.0 0.0.1.255
  deny   ip any 109.74.192.0 0.0.15.255
  deny   ip any 128.199.128.0 0.0.63.255
  deny   ip any 14.136.236.0 0.0.0.255
  deny   ip any 149.154.157.0 0.0.0.255
  deny   ip any 149.62.168.0 0.0.3.255
  deny   ip any 151.236.18.0 0.0.0.255
  deny   ip any 158.255.208.0 0.0.0.255
  deny   ip any 162.213.197.0 0.0.0.255
  deny   ip any 162.217.132.0 0.0.3.255
  deny   ip any 162.218.92.0 0.0.1.255
  deny   ip any 162.221.180.0 0.0.1.255
  deny   ip any 162.243.0.0 0.0.127.255
  deny   ip any 167.88.112.0 0.0.3.255
  deny   ip any 168.235.64.0 0.0.3.255
  deny   ip any 173.255.192.0 0.0.15.255
  deny   ip any 176.58.96.0 0.0.31.255
  deny   ip any 176.9.0.0 0.0.255.255
  deny   ip any 177.67.81.0 0.0.0.255
  deny   ip any 178.209.32.0 0.0.31.255
  deny   ip any 178.79.128.0 0.0.63.255
  deny   ip any 192.110.160.0 0.0.0.255
  deny   ip any 192.121.112.0 0.0.0.255
  deny   ip any 192.184.80.0 0.0.7.255
  deny   ip any 192.211.49.0 0.0.0.255
  deny   ip any 192.241.160.0 0.0.31.255
  deny   ip any 192.30.32.0 0.0.3.255
  deny   ip any 192.34.56.0 0.0.7.255
  deny   ip any 192.40.56.0 0.0.0.255
  deny   ip any 192.73.232.0 0.0.7.255
  deny   ip any 192.81.208.0 0.0.7.255
  deny   ip any 192.99.0.0 0.0.255.255
  deny   ip any 198.147.20.0 0.0.0.255
  deny   ip any 198.211.96.0 0.0.15.255
  deny   ip any 198.58.96.0 0.0.31.255
  deny   ip any 199.241.28.0 0.0.3.255
  deny   ip any 208.68.36.0 0.0.3.255
  deny   ip any 209.222.30.0 0.0.0.255
  deny   ip any 213.229.64.0 0.0.63.255
  deny   ip any 217.170.192.0 0.0.15.255
  deny   ip any 217.78.0.0 0.0.15.255
  deny   ip any 23.227.160.0 0.0.0.255
  deny   ip any 23.249.168.0 0.0.1.255
  deny   ip any 23.29.124.0 0.0.0.255
  deny   ip any 31.193.128.0 0.0.15.255
  deny   ip any 31.220.24.0 0.0.3.255
  deny   ip any 37.139.0.0 0.0.31.255
  deny   ip any 37.235.52.0 0.0.0.255
  deny   ip any 41.215.240.0 0.0.0.255
  deny   ip any 41.223.52.0 0.0.0.255
  deny   ip any 46.17.56.0 0.0.7.255
  deny   ip any 46.19.136.0 0.0.7.255
  deny   ip any 46.246.0.0 0.0.127.255
  deny   ip any 46.38.48.0 0.0.7.255
  deny   ip any 46.4.0.0 0.0.255.255
  deny   ip any 5.9.0.0 0.0.255.255
  deny   ip any 50.116.32.0 0.0.15.255
  deny   ip any 66.85.128.0 0.0.63.255
  deny   ip any 74.82.192.0 0.0.31.255
  deny   ip any 77.237.248.0 0.0.1.255
  deny   ip any 81.4.108.0 0.0.3.255
  deny   ip any 85.234.128.0 0.0.31.255
  deny   ip any 88.150.156.0 0.0.3.255
  deny   ip any 91.186.0.0 0.0.31.255
  deny   ip any 92.222.0.0 0.0.255.255
  deny   ip any 92.48.64.0 0.0.63.255
  deny   ip any 94.76.192.0 0.0.63.255
  deny   ip any 95.215.44.0 0.0.3.255
  deny   ip any 96.126.96.0 0.0.7.255
  remark Browsec
  deny   ip any 178.62.64.0 0.0.63.255
  deny   ip any 178.62.0.0 0.0.63.255
  deny   ip any 46.101.0.0 0.0.63.255
  deny   ip any 5.101.111.0 0.0.0.255
  deny   ip any 45.55.96.0 0.0.31.255
  deny   ip any 45.55.192.0 0.0.63.255
  deny   ip any 45.55.128.0 0.0.63.255
  deny   ip any 162.243.188.0 0.0.1.255
  deny   ip any 162.243.176.0 0.0.7.255
  deny   ip any 104.236.64.0 0.0.63.255
  deny   ip any 104.236.192.0 0.0.63.255
  deny   ip any 104.236.0.0 0.0.63.255
  deny   ip any 104.131.64.0 0.0.63.255
  deny   ip any 104.131.176.0 0.0.15.255
  deny   ip any 104.131.160.0 0.0.15.255
  deny   ip any 104.131.0.0 0.0.63.255
  deny   ip any 198.199.96.0 0.0.15.255
  deny   ip any 198.199.92.0 0.0.3.255
  deny   ip any 198.199.112.0 0.0.7.255
  deny   ip any 192.241.224.0 0.0.15.255
  deny   ip any 192.241.192.0 0.0.31.255
  deny   ip any 162.243.128.0 0.0.31.255
  deny   ip any 107.170.192.0 0.0.63.255
  deny   ip any 104.236.128.0 0.0.63.255
  deny   ip any 104.131.144.0 0.0.15.255
  deny   ip any 95.85.0.0 0.0.63.255
  deny   ip any 80.240.128.0 0.0.15.255
  deny   ip any 5.101.96.0 0.0.7.255
  deny   ip any 5.101.104.0 0.0.3.255
  deny   ip any 188.226.128.0 0.0.127.255
  deny   ip any 178.62.128.0 0.0.63.255
  deny   ip any 146.185.184.0 0.0.7.255
  deny   ip any 5.101.110.0 0.0.0.255
  deny   ip any 188.166.64.0 0.0.63.255
  deny   ip any 188.166.0.0 0.0.63.255
  deny   ip any 178.62.192.0 0.0.63.255
  deny   ip any 128.199.32.0 0.0.31.255
  deny   ip any 192.241.240.0 0.0.15.255
  deny   ip any 162.243.192.0 0.0.63.255
  deny   ip any 162.243.191.0 0.0.0.255
  deny   ip any 107.170.160.0 0.0.31.255
  deny   ip any 107.170.128.0 0.0.31.255
  deny   ip any 104.131.224.0 0.0.31.255
  deny   ip any 104.131.192.0 0.0.31.255
  deny   ip any 128.199.64.0 0.0.63.255
  deny   ip any 128.199.192.0 0.0.63.255
  deny   ip any 103.253.144.0 0.0.3.255
  remark Stealthy
  deny   ip any 118.97.128.0 0.0.15.255
  deny   ip any 41.231.0.0 0.0.255.255
  deny   ip any 195.154.0.0 0.0.255.255
  remark Finally pass internal LAN to NAT
  permit ip 192.168.0.0 0.0.255.255 any

Hope this helps.
29.04.16 16:33, Reet Vyas ?????:
> Hi,
>
> I have working trasparent squid , Some users are using proxy vpn in 
> moziilla as addon and bypassing my squid, Please tell me how to block 
> all hola.org <http://hola.org> vpn and ulrta surf, I have already 
> blocked websites,but seems not working.
>
> Please let me know how to block these vpn access.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/2c527ce7/attachment.htm>

From robertocarna36 at gmail.com  Fri Apr 29 13:16:44 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Fri, 29 Apr 2016 10:16:44 -0300
Subject: [squid-users] Squid reverse proxy: www.site1.com to
	www.site2.com/foo/
Message-ID: <CAG2Qp6taeWi1oxGBwKnQVLTngc2xDBwk7Y25EU+=nNSUhPpa1g@mail.gmail.com>

Dear, I'm using Squid in reverse proxy mode.

Everything is OK, but now I have to do this:

If a user put in the browser:

http://www.site1.com

Squid reverse has to redirect to:

http://www.site2.com/foo/

How can I do this???

Special thanks,

Roberto


From rousskov at measurement-factory.com  Fri Apr 29 14:57:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 29 Apr 2016 08:57:52 -0600
Subject: [squid-users] Using dont_verify_peer
In-Reply-To: <VI1PR04MB1359E191B57DDC980709E9218F650@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>
 <VI1PR04MB1359E191B57DDC980709E9218F650@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <57237670.1040803@measurement-factory.com>

On 04/28/2016 02:56 PM, Rafael Akchurin wrote:

> According to
> https://www.ssllabs.com/ssltest/analyze.html?d=agentimediaservices.com
> the server does not send the whole chain of certificates and imho squid
> cannot automatically download the intermediate certificates like
> browsers do.


Yes, this is a feature request or bug #4305:
http://bugs.squid-cache.org/show_bug.cgi?id=4305

Factory actually implemented that feature but the code is currently
stuck due to some surprising changes in Squid trunk that we now have to
review and accommodate first... I hope to be done with that in a few
weeks, but a constant drum of CVEs and other emergencies delays that work.

Alex.



From rousskov at measurement-factory.com  Fri Apr 29 15:12:34 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 29 Apr 2016 09:12:34 -0600
Subject: [squid-users] Using dont_verify_peer
In-Reply-To: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>
References: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>
Message-ID: <572379E2.5090301@measurement-factory.com>

On 04/28/2016 02:32 PM, Markey, Bruce wrote:

> I?ve been having to actually remove folks from the proxy so they could work.
> I can?t deny users access to the sites they need.
> all I really wanted was to keep stats on sites visited.

Yours and many other passive monitoring use cases call for a
non-intrusive or "stealth" splice. No TLS version enforcement, no
[fatal] certificate validation errors, no errors returned to the user,
just domain name logging and splicing. Supporting this stealthy mode
requires a lot of work, and there is currently no sponsor to get us all
the way to that goal, but I am optimistic that we will eventually get there.

The automated certificate fetching (bug #4305) still needs to be
supported, of course. It is a separate issue.

Meanwhile, besides manually adding untrusted certificates as have been
recommended by others, consider limiting peeking to step1 [in some
cases]. This way, Squid will not see and validate the server
certificate. If most of your traffic has SNI, and users are not trying
to defeat your monitoring, then the logs may still contain enough info
to produce the stats you want, even without seeing certificates.


HTH,

Alex.



From yvoinov at gmail.com  Fri Apr 29 16:07:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 29 Apr 2016 22:07:08 +0600
Subject: [squid-users] Block VPN access like hola.org ,ultrasurf
In-Reply-To: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>
References: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>
Message-ID: <bcd5bd78-6bd6-0cf9-6e73-c3c7be7b6c85@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
The another option is using advanced DPI with database. Like China
government uses.

Squid itself can't.

29.04.16 16:33, Reet Vyas ?????:
> Hi,
>
> I have working trasparent squid , Some users are using proxy vpn in
moziilla as addon and bypassing my squid, Please tell me how to block
all hola.org <http://hola.org> vpn and ulrta surf, I have already
blocked websites,but seems not working.
>
> Please let me know how to block these vpn access.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXI4asAAoJENNXIZxhPexGNfAIALiyG5lIwMpH198p6JJOjp+9
g2TvYj17NTsiMePao1omhf+yYvIYQNrQ1YRyPFQ5ax5eJX7yd5YwhvwewobGZjwR
xhhJIo3DS6XGKijHwKlVekhZ6lCP/eoph3r02zTKv1dpF4nuAVRRImLL//XKjyir
h4yyrK65TCzJsbKL7qe9n7/k0BLNUm5eXiER2KJbfXDzFnjaN62VKxVN1Apw11EQ
xpKa1TrH+rjyzyrd2la/S8On0G771rIRj80bl1q6IHA4+74qSmRm/gVyibDosGA3
JFmeG4DU1wt280zoTZJFv7GSAGl7PqL8Shp2LDUVt499ylxua+jhF3ahzWLetjg=
=r/mv
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/d38f55ec/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160429/d38f55ec/attachment.key>

From bmarkey at steinmancommunications.com  Fri Apr 29 17:47:38 2016
From: bmarkey at steinmancommunications.com (Markey, Bruce)
Date: Fri, 29 Apr 2016 17:47:38 +0000
Subject: [squid-users] Using dont_verify_peer
In-Reply-To: <572379E2.5090301@measurement-factory.com>
References: <2B77BF184EAC2F43BB9FC908954D8B12670B2E77@ex4.lnpnews.com>
 <572379E2.5090301@measurement-factory.com>
Message-ID: <2B77BF184EAC2F43BB9FC908954D8B12670BCBCB@ex4.lnpnews.com>

Ok that makes more sense now. Thanks to everyone for the tips.  I'm going to work on this over the next few days and see where I end up. 



Bruce Markey | Network Security Analyst
STEINMAN COMMUNICATIONS
717.291.8758?(o) |?bmarkey at steinmancommunications.com
8 West King St | PO Box 1328, Lancaster, PA 17608-1328

-----Original Message-----
From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
Sent: Friday, April 29, 2016 11:13 AM
To: squid-users at lists.squid-cache.org
Cc: Markey, Bruce <bmarkey at steinmancommunications.com>
Subject: Re: [squid-users] Using dont_verify_peer

On 04/28/2016 02:32 PM, Markey, Bruce wrote:

> I?ve been having to actually remove folks from the proxy so they could work.
> I can?t deny users access to the sites they need.
> all I really wanted was to keep stats on sites visited.

Yours and many other passive monitoring use cases call for a non-intrusive or "stealth" splice. No TLS version enforcement, no [fatal] certificate validation errors, no errors returned to the user, just domain name logging and splicing. Supporting this stealthy mode requires a lot of work, and there is currently no sponsor to get us all the way to that goal, but I am optimistic that we will eventually get there.

The automated certificate fetching (bug #4305) still needs to be supported, of course. It is a separate issue.

Meanwhile, besides manually adding untrusted certificates as have been recommended by others, consider limiting peeking to step1 [in some cases]. This way, Squid will not see and validate the server certificate. If most of your traffic has SNI, and users are not trying to defeat your monitoring, then the logs may still contain enough info to produce the stats you want, even without seeing certificates.


HTH,

Alex.


From yvoinov at gmail.com  Fri Apr 29 22:04:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 30 Apr 2016 04:04:57 +0600
Subject: [squid-users] Block VPN access like hola.org ,ultrasurf
In-Reply-To: <bcd5bd78-6bd6-0cf9-6e73-c3c7be7b6c85@gmail.com>
References: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>
 <bcd5bd78-6bd6-0cf9-6e73-c3c7be7b6c85@gmail.com>
Message-ID: <cf6dc2fd-a185-c609-8459-c6a239694360@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
AFAIK,

every proxy admin faced with excessively smart users who want to bypass
a proxy. If you think that this is not true in your case - it means you
not know yet. While you suffer prince Hamlet's ethical dilemma - "To
bump or not to bump - that is a serious matter", your smart-ass users
will shamelessly use every possible tools and methods to step over you
and wipe they feet on the your proxy.

I am deeply sorry for you, but to solve this problem by means of a Squid
is not possible. It is necessary to take into account the existence of
Tor, VPN, URL shorteners, Google Translate (Yea, it also uses for
bypassing proxy!), SOCKS, http/https anonymizers etc. This is not easy
and not simple. This battle occurs every day.

I deliberately do not mention really advanced techniques of hiding one
type of traffic inside the other and another hacker's tools. VPN is a
strong, but not the last tool to ignore the proxy server if it does not
exist at all. And you can be sure your users will not miss them.

And in the fight against shield and sword sword usually wins.

Only a proxy in this issue is not worth little or nothing. Only trained
administrator with experienced network administrator and two pairs
bodied brain can more or less hinder the  life of these smart-ass users.

This day-by-day battle is significant part of IT security, which is not
product, but process.

Hard luck,
                 Yuri

29.04.16 22:07, Yuri Voinov ?????:
>
> The another option is using advanced DPI with database. Like China
government uses.
>
> Squid itself can't.
>
> 29.04.16 16:33, Reet Vyas ?????:
> > Hi,
>
>
>
>       > I have working trasparent squid , Some users are using proxy
>       vpn in moziilla as addon and bypassing my squid, Please tell me
>       how to block all hola.org <http://hola.org> vpn and ulrta
>       surf, I have already blocked websites,but seems not working.
>
>
>
>       > Please let me know how to block these vpn access.
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXI9qIAAoJENNXIZxhPexGISAH/ivV0JV6zUhN5C85GubgI3or
EZJgL706JL+Q6CasmYF/88gau/j7EwYW+mtJ9EzdMGVo5lGkQW3Y/y6SjAmCdtI3
J4eJMGIqi8mQRzfx55HGEv2cXHsYh3hxcBcBay4YHM9NFcXW/xMqsnwrkICULI6b
mu91LERDiH5iBn9cT1qquKoTV8rg5E1eb6ZATA8r6VYRoZutzHN5/v4eww1ogxmc
cE+DVzEcK5VJYFtfUHEyOCO785Xu1TSCctmmvzjrv2SpBQcgxJJ6pSrDrk+Qw614
g50IJz26t0zqlrC/Z+LU0SeAgW7iboPID5yA/3bxWLSnupex3W93lwlPSJu48Pg=
=V6pf
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160430/3ad2362e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160430/3ad2362e/attachment.key>

From chip_pop at hotmail.com  Fri Apr 29 22:17:56 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 29 Apr 2016 15:17:56 -0700 (PDT)
Subject: [squid-users] runing squid on second processor
Message-ID: <1461968276793-4677313.post@n4.nabble.com>

hi i have 2 cpu 4 core each
 i need to leave alone first processor and use the second one for squid and
its helper
is that will do ???   taskset 0x000000f0 squid -YC -f /etc/squid/squid.conf
or other way around ??
so i can keep the kernel and other program running on first cpu not
interfere  with squid
cause wen i run Calamaris Log Analysis on cpl large log it take cpu % very
hi and it slow delay squid performance until it finish :(

tks 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/runing-squid-on-second-processor-tp4677313.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From uhlar at fantomas.sk  Sat Apr 30 14:08:10 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sat, 30 Apr 2016 16:08:10 +0200
Subject: [squid-users] runing squid on second processor
In-Reply-To: <1461968276793-4677313.post@n4.nabble.com>
References: <1461968276793-4677313.post@n4.nabble.com>
Message-ID: <20160430140810.GB18421@fantomas.sk>

On 29.04.16 15:17, joe wrote:
>hi i have 2 cpu 4 core each
> i need to leave alone first processor and use the second one for squid and
>its helper
>is that will do ???   taskset 0x000000f0 squid -YC -f /etc/squid/squid.conf
>or other way around ??
>so i can keep the kernel and other program running on first cpu not
>interfere  with squid
>cause wen i run Calamaris Log Analysis on cpl large log it take cpu % very
>hi and it slow delay squid performance until it finish :(

why do you think it's better to tune this manually and not leave it for the
OS?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Emacs is a complicated operating system without good text editor.


From chip_pop at hotmail.com  Sat Apr 30 14:05:21 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 30 Apr 2016 07:05:21 -0700 (PDT)
Subject: [squid-users] runing squid on second processor
In-Reply-To: <20160430140810.GB18421@fantomas.sk>
References: <1461968276793-4677313.post@n4.nabble.com>
 <20160430140810.GB18421@fantomas.sk>
Message-ID: <1462025121146-4677315.post@n4.nabble.com>

i have it running  tks
cause every time i run Calamaris Log first cpu get hi 100% and squid work
slow until the calamaris finish
so i moved squid to use second processor now its OK not affected by that or
anything else  
running nice now



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/runing-squid-on-second-processor-tp4677313p4677315.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sat Apr 30 23:33:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 1 May 2016 11:33:02 +1200
Subject: [squid-users] Squid reverse proxy: www.site1.com to
 www.site2.com/foo/
In-Reply-To: <CAG2Qp6taeWi1oxGBwKnQVLTngc2xDBwk7Y25EU+=nNSUhPpa1g@mail.gmail.com>
References: <CAG2Qp6taeWi1oxGBwKnQVLTngc2xDBwk7Y25EU+=nNSUhPpa1g@mail.gmail.com>
Message-ID: <e00e7f78-b617-97b7-4093-53386aac6a81@treenet.co.nz>

On 30/04/2016 1:16 a.m., Roberto Carna wrote:
> Dear, I'm using Squid in reverse proxy mode.
> 
> Everything is OK, but now I have to do this:
> 
> If a user put in the browser:
> 
> http://www.site1.com
> 
> Squid reverse has to redirect to:
> 
> http://www.site2.com/foo/
> 
> How can I do this???
> 

acl site1 dstdomain www.site1.com
deny_info 302:http://www.site2.com/foo%R site1
http_access deny site1

Amos



