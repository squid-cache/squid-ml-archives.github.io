From squid3 at treenet.co.nz  Mon Aug  1 12:05:18 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 2 Aug 2016 00:05:18 +1200
Subject: [squid-users] cachemgr.cgi on embedded system
In-Reply-To: <1469543113687-4678682.post@n4.nabble.com>
References: <1469364864274-4678665.post@n4.nabble.com>
 <b396301d1e5df$d7350960$859f1c20$@ngtech.co.il>
 <da81d95a-1651-ce23-9b9a-597e440477c3@treenet.co.nz>
 <1469436926898-4678668.post@n4.nabble.com>
 <dcc13563-9828-d275-1cd8-b19fbe818b8b@treenet.co.nz>
 <1469450968676-4678677.post@n4.nabble.com>
 <177800de-8add-58da-d0d2-cc6afe086aab@treenet.co.nz>
 <1469543113687-4678682.post@n4.nabble.com>
Message-ID: <fba280b4-44ac-3eb2-5f53-66510e69d3de@treenet.co.nz>

On 27/07/2016 2:25 a.m., reinerotto wrote:
> No progress. 
> I rebuilt squid (3.5.20), incl. basic-auth, but still get
> 
> The following error was encountered while trying to retrieve the URL:
> http://my_local_domain.lan:3128/squid-internal-mgr/info
> Access Denied.
> 
> although I have in squid.conf (just for testing):
> 
> ...
> http_access deny connect !ssl_ports
> http_access allow all manager
> cachemgr_passwd my_passwd all
> ...
> 
> This should allow everybody to use the cachemgr, correct ?

Provided there are no http_access rules above that snippet of config
that are denying access. It should let anyone using the password
represented there by "my_passwd" to see the proxy manager reports.



> 
> When running the cachemgr.cgi, the page to enter the password shows up, but
> then also "Access denied".
> 
> One more speciality of my environment:
> The client, running
> "http://my_local_domain.lan:3128/squid-internal-mgr/info" 
> sits on the other side of a captive portal (opposite side of squid). Captive
> portal has its _private_ IP-Pool. 
> 
> So, the IP trying to access squid, does _not_ show up when running simple
> "arp" command on the squid-machine. squid and captive portal run on same
> box.
> In case there is some hidden access control within squid, based on the IP of
> the client, this_might_ fail.

There is nothing implicit like that. Though you could have an explicitly
configured one somehow.


> 
> Any hint, which debug options to set in squid.conf, for more detailed info ?
> 

Adding this to your squid.conf will show the manager, access control,
and authentication activity.
 debug_options ALL,1 16,4 28,4 29,4

Amos



From johnpearson555 at gmail.com  Mon Aug  1 17:59:14 2016
From: johnpearson555 at gmail.com (John Pearson)
Date: Mon, 1 Aug 2016 10:59:14 -0700
Subject: [squid-users] Squid not caching some files
In-Reply-To: <814930be-803f-f4a5-3d0b-07cb85f883b8@treenet.co.nz>
References: <CAKNtY_xoAJwJsVwO0QpkON7i-XrteNBtbJJ5DsFKqpDkn5_xDQ@mail.gmail.com>
 <814930be-803f-f4a5-3d0b-07cb85f883b8@treenet.co.nz>
Message-ID: <CAKNtY_yFO+LVUwZ38AC5=K=si=6Cr7V=WTEi2UWXHXgipzzEaA@mail.gmail.com>

Thanks Amos! Learned a lot. I changed .conf file and it works as expected.


On Thu, Jul 28, 2016 at 3:30 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 28/07/2016 1:33 p.m., John Pearson wrote:
> > Hi,
> >
> > main problem: different squid configurations are not caching certain
> files.
> >
> > These are my conf files `1_squid.conf` and `2_squid.conf` both can be
> found
> > here:
> >
> > https://gist.github.com/ironpillow/e6b86354f4ac3941f74db86d893008f1
> >
> > I am using http://www.thinkbroadband.com/download/ to download the 5MB
> zip
> > file but it's always a tcp_miss UNLESS I uncomment (use) lines 57 and 58
> in
> > 1_squid.conf. dmg files are being cached.
> >
> > But when using 2_squid.conf, the above zip file is cached (tcp_hit) but
> dmg
> > files (https://support.apple.com/kb/dl1870?locale=en_US) are not being
> > cached.
> >
> > Any advice?
>
> Quite a lot.
>
> Firstly, the design of those two configs is quite different about what
> they do when caching. Some of the below details about #1 config should
> explain why #2 config does them differently, the rest of the changes
> apply to both configs.
>
> Specifics:
>
> 1) there are no such things as "files" in HTTP. "file" is a disk storage
> concept. Network transfer protocols are about resources and where they
> are located (URL). Any relationship between URL and a filename is a
> coincidence of that domains designer having made it so, and certainly
> not reliable in the general case. That effects the (3) behaviour below.
>
> 2) in HTTP the relationship between "site" and URL is tenuous at best.
> Just because one URL is displayed as being where to fetch an object does
> not mean thats where the object resides. Redirects can happen in between
> initial fetch, and your Store-ID helper will also be having effects on
> what URL the refresh_pattern see as representing the object.
>
> 3) the regex patterns you have for URLs *ending* with specific 4-letter
> sequences between lines 54-70 are;
>  a) specifically bound to individual domain names (thats good because of
> #1 above), and
>  b) do not include the domains you mention having trouble with (which
> explains why they do not do what you expect to those domains).
>
> 4) due to the way you have configured the "cache" directives. Only
> domain names listed in /etc/squid/updatesites.txt will ever be stored by
> Squid. This effects the behaviours created by (2) and (3) -
> refresh_pattern is only relevant for stored content.
>
> 5) Squid *will not* store responses for intercepted traffic unless it
> can verify the server being contacted is actually the authoritative
> origin server for that URL domain.
>  * The DNS servers behind "8.8.8.8" are expicitly configured to rotate
> teh IP addresses on every single lookup. Which makes it almost
> guaranteed that Squid and the client being intercepted will be seeing
> different sets of origin servers when they lookup the domain.
>
> 6) configuring "dns_defnames" to pass *single label* domain names out to
> the global 8.8.8.8 service is plain wrong. Remove that line.
>
> 7) "logformat squid" - do not redefine Squid's built-in log formats. It
> will *not* record the values you think it records.
>
> 8) remove the comment from line 84 of 1_squid.conf. That line defines
> the proper way to deal with URLs when they have query strings.
>
> 9) remove the "regex_pattern -i cgi-bin" lines at 86-87. Its an old and
> wrong config setting.
>
> 10) you can remove the "always_direct allow all" it is about whether to
> use cache_peer's and is pointless in your configuration that doesn't use
> any peers.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160801/c29a5632/attachment.htm>

From jr at jrssite.com  Tue Aug  2 01:30:11 2016
From: jr at jrssite.com (JR Dalrymple)
Date: Tue, 02 Aug 2016 01:30:11 +0000
Subject: [squid-users] SSLBump just not working
Message-ID: <CABs_asnhvDtviza-Ew-Fuj2==dezjjq-FLphFWesOASHFeF=FA@mail.gmail.com>

I have a freshly installed Squid from source on a likewise freshly
installed OpenBSD system. Attempting to replace an aging stub Squid on
Linux with transparent with SSLBump. I think I have everything set up
pretty skookup, the symptom is it just isn't working. When I browse to an
https website I get presented my root cert, but not a dynamically created
cert underneath. It doesn't look like they're being created as the folder
hierarchy that's supposed to contain the dynamic certs remains empty. Note
that as of yet this is not in a transparent configuration - choosing to
crawl before I walk. Here is some perhaps useful info from the system:

# uname -a
OpenBSD router.example.local 5.9 GENERIC#1761 amd64
# /usr/local/squid/sbin/squid -v
Squid Cache: Version 3.5.20
Service Name: squid
configure options:  '--enable-icmp' '--enable-delay-pools'
'--enable-pf-transparent' '--enable-ssl-crtd' '--enable-auth'
'--with-openssl' --enable-ltdl-convenience

# ps -waux | grep squid
squid     2604 10.9  1.4 17060 14840 ??  R      5:16PM    0:03.11 (squid-1)
(squid)
root     28389  0.0  0.2 10608  2548 ??  Ss     5:16PM    0:00.06
/usr/local/squid/sbin/squid
squid    17905  0.0  0.3   688  3496 ??  S      5:16PM    0:00.10
(ssl_crtd) -s /usr/local/squid/var/lib/ssl_db -M 4MB (ssl_crtd)
squid    21985  0.0  0.3   680  3460 ??  S      5:16PM    0:00.05
(ssl_crtd) -s /usr/local/squid/var/lib/ssl_db -M 4MB (ssl_crtd)
squid    20149  0.1  0.3   676  3468 ??  S      5:16PM    0:00.04
(ssl_crtd) -s /usr/local/squid/var/lib/ssl_db -M 4MB (ssl_crtd)
squid     8313  0.0  0.3   688  3488 ??  S      5:16PM    0:00.03
(ssl_crtd) -s /usr/local/squid/var/lib/ssl_db -M 4MB (ssl_crtd)
squid    11338  0.0  0.3   688  3488 ??  S      5:16PM    0:00.04
(ssl_crtd) -s /usr/local/squid/var/lib/ssl_db -M 4MB (ssl_crtd)
squid    23712  0.0  0.2   448  1580 ??  S      5:16PM    0:00.06
(logfile-daemon) /var/log/squid/access.log (log_file_daemon)
squid    20208  0.0  0.1   324  1448 ??  S      5:16PM    0:00.02 (unlinkd)
(unlinkd)

# grep -i ssl /var/log/squid/cache.log
...
2016/08/01 16:54:54.370 kid1| 83,7| bio.cc(168) stateChanged: FD 12 now:
0x20 SSLOK  (SSL negotiation finished successfully)
2016/08/01 16:54:54.370 kid1| 83,7| bio.cc(168) stateChanged: FD 12 now:
0x2002 SSLOK  (SSL negotiation finished successfully)
-----BEGIN SSL SESSION PARAMETERS-----
-----END SSL SESSION PARAMETERS-----
2016/08/01 16:54:54.370 kid1| 83,2| client_side.cc(3809)
clientNegotiateSSL: clientNegotiateSSL: New session 0x38985389200 on FD 12 (
172.22.19.48:65433)
2016/08/01 16:54:54.370 kid1| 83,3| client_side.cc(3813)
clientNegotiateSSL: clientNegotiateSSL: FD 12 negotiated cipher AES128-SHA
2016/08/01 16:54:54.371 kid1| 83,5| client_side.cc(3829)
clientNegotiateSSL: clientNegotiateSSL: FD 12 has no certificate.
2016/08/01 16:54:54.426 kid1| 85,5| client_side_request.cc(1438)
sslBumpAccessCheck: cannot SslBump this request
...

# grep -v ^# /usr/local/squid/etc/squid.conf | grep -v ^[\s]*$
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
ssl_bump bump all
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/ssl/CA.pem
cache_dir ufs /var/cache/squid 4000 16 256
coredump_dir /var/cache/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
cache_effective_user squid
cache_effective_group squid
access_log daemon:/var/log/squid/access.log squid
cache_log /var/log/squid/cache.log
sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s
/usr/local/squid/var/lib/ssl_db -M 4MB
sslcrtd_children 10
debug_options ALL,9

# ls -lR /usr/local/squid/var/lib/
total 4
drwxr-xr-x  3 squid  wheel  512 Jul 23 18:38 ssl_db

/usr/local/squid/var/lib/ssl_db:
total 8
drwxr-xr-x  2 squid  wheel  512 Jul 23 18:38 certs
-rw-r--r--  1 squid  wheel    0 Jul 23 18:38 index.txt
-rw-r--r--  1 squid  wheel    1 Jul 23 18:38 size




Any advice would be much appreciated.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160802/d84d641c/attachment.htm>

From samm.abcd at gmail.com  Tue Aug  2 05:43:08 2016
From: samm.abcd at gmail.com (Sam M)
Date: Tue, 2 Aug 2016 01:43:08 -0400
Subject: [squid-users] different results every time
Message-ID: <CALBG=MFOwdQyRmOL5P_S06DDx-oJWzzdNoom0_4VLUAryFuEmA@mail.gmail.com>

Hi,

I'm querying lots of files through 4 cache servers connected through parent
hierarchy. I clean all the caches before I start and then I query the files
again in the same exact order. Weirdly, every time I check the logs, I see
a different cache served a file compared with the previous test. The query
process is done through a python script that uses wget through a proxy to
the cache, hence the query process is really fast.

Interestingly, if I put a delay of 1 second between each query, the result
will be stable and same every time I run the script.

Following a snippet from the config file after changing it too many times
to make it re-produce the same results yet, that didn't help:
cache_dir ufs /var/spool/squid 9 16 256
cache_mem 0 MB
memory_pools off
cache_swap_low 100
cache_swap_high 100
maximum_object_size_in_memory 0 KB
cache_replacement_policy lru
range_offset_limit 0
quick_abort_min 0 KB
quick_abort_max 0 KB

Can someone shed some light on the issue and how to fix it please?

Thanks,
Sam
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160802/633d3164/attachment.htm>

From eliezer at ngtech.co.il  Tue Aug  2 06:03:45 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 2 Aug 2016 09:03:45 +0300
Subject: [squid-users] different results every time
In-Reply-To: <CALBG=MFOwdQyRmOL5P_S06DDx-oJWzzdNoom0_4VLUAryFuEmA@mail.gmail.com>
References: <CALBG=MFOwdQyRmOL5P_S06DDx-oJWzzdNoom0_4VLUAryFuEmA@mail.gmail.com>
Message-ID: <01c501d1ec83$a1011a50$e3034ef0$@ngtech.co.il>

Hey Sam,

 

>From what I understand it seems that your expectation doesn't meet the reality but I am unsure yet.

It seems that the goal is to fetch and save everything to disk and from disk, right?

 

During the time that your clients and proxy are fetching the object using squid, you cannot serve this "in-transit" content to other clients.

Collapsed Forwarding feature of squid should satisfy your use case but depends on the size of the object it might not be the right choice for you.

What objects size are we talking about?

 

Eliezer

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sam M
Sent: Tuesday, August 2, 2016 8:43 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] different results every time

 

Hi, 

I'm querying lots of files through 4 cache servers connected through parent hierarchy. I clean all the caches before I start and then I query the files again in the same exact order. Weirdly, every time I check the logs, I see a different cache served a file compared with the previous test. The query process is done through a python script that uses wget through a proxy to the cache, hence the query process is really fast. 

Interestingly, if I put a delay of 1 second between each query, the result will be stable and same every time I run the script. 

Following a snippet from the config file after changing it too many times to make it re-produce the same results yet, that didn't help: 
cache_dir ufs /var/spool/squid 9 16 256
cache_mem 0 MB
memory_pools off
cache_swap_low 100
cache_swap_high 100
maximum_object_size_in_memory 0 KB
cache_replacement_policy lru
range_offset_limit 0
quick_abort_min 0 KB
quick_abort_max 0 KB

 

Can someone shed some light on the issue and how to fix it please?

Thanks, 

Sam 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160802/3a267301/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160802/3a267301/attachment.png>

From marcus.kool at urlfilterdb.com  Wed Aug  3 01:50:06 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 2 Aug 2016 22:50:06 -0300
Subject: [squid-users] Recommended Multi-CPU Configuration
In-Reply-To: <CAEnCSG4EQ9_4qHoBnJmS3TKG8fURhzQk7t3K+UmorTuJN=bJWA@mail.gmail.com>
References: <CAEnCSG54TNcRKt4hdAUOHVJVJ=VCKPkZusjq_wJTqP48hv3vWg@mail.gmail.com>
 <55821F81.70809@treenet.co.nz>
 <CAEnCSG4EQ9_4qHoBnJmS3TKG8fURhzQk7t3K+UmorTuJN=bJWA@mail.gmail.com>
Message-ID: <1fb5f720-f2fe-e80e-e447-e742e756778d@urlfilterdb.com>

Hi Michael,

Can you share with us what you ended up with?

Thanks
Marcus

On 06/18/2015 12:28 AM, Michael Pelletier wrote:
> Which one would be good for capacity\load? I have a very, very large environment. I have 220,000 users on 8 Gig to the INTERNET. I am running a load balancer, ipvsadm (Direct Routing) with 20 proxies
> behind it. I am interested in handling load.
>
> Michael
>
> On Wed, Jun 17, 2015 at 9:31 PM, Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>> wrote:
>
>     On 18/06/2015 8:53 a.m., Michael Pelletier wrote:
>     > Hello,
>     >
>     > I am looking to had some more power to squid. I have seen two different
>     > types of configurations to do this:
>     >
>     > 1. Adding workers directive equal to the number of cpus. Then adding a
>     > special wrapper around the AUFS disk cache so that the correct worker can
>     > only access the correct cache. Yes, I know rock is multi cpu capable.
>     >
>     > 2. Using the split configuration from the Squid Web page. This involved a
>     > front end and multiple backend squid servers on the same server.
>     > http://wiki.squid-cache.org/ConfigExamples/MultiCpuSystem
>     >
>     > My question is, which one is recommended? What are the pros and cons of
>     > each?
>     >
>
>     Both and neither. #1 improves bandwidth savings. #2 improves raw speed.
>     Pick your poison.
>
>     These are example configurations only. For real high performance mutiple
>     machines in a mix of the two setups is even better.
>
>     Amos
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> *Disclaimer: *Under Florida law, e-mail addresses are public records. If you do not want your e-mail address released in response to a public records request, do not send electronic mail to this
> entity. Instead, contact this office by phone or in writing.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From samm.abcd at gmail.com  Wed Aug  3 01:51:46 2016
From: samm.abcd at gmail.com (Sam M)
Date: Tue, 2 Aug 2016 21:51:46 -0400
Subject: [squid-users] different results every time
In-Reply-To: <01c501d1ec83$a1011a50$e3034ef0$@ngtech.co.il>
References: <CALBG=MFOwdQyRmOL5P_S06DDx-oJWzzdNoom0_4VLUAryFuEmA@mail.gmail.com>
 <01c501d1ec83$a1011a50$e3034ef0$@ngtech.co.il>
Message-ID: <CALBG=MFe4GmiQoK5nGDCfuPj1dE38xTkMwXz4jtr_FSMAfsQVA@mail.gmail.com>

Hi Eliezer,

Thanks for your prompt reply. We are testing our squid configuration before
we use it. That said, all objects are 1 MB in size and in order to test
squid we queried a sequence of files multiple times in a manner that
theoretically at the end of the querying process we should get the same
number of hits from cache1, cache2, cache3, and cache4.

Structure of test network is: User (using a script) -> cache1 -> cache2 ->
cache3 -> cache4 -> web server (stores the queried files).

I'm gonna try the Collapsed Forwarding feature and will post back if this
fixes the issue.

Thank you,
Sam

On Tue, Aug 2, 2016 at 2:03 AM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> Hey Sam,
>
>
>
> From what I understand it seems that your expectation doesn't meet the
> reality but I am unsure yet.
>
> It seems that the goal is to fetch and save everything to disk and from
> disk, right?
>
>
>
> During the time that your clients and proxy are fetching the object using
> squid, you cannot serve this "in-transit" content to other clients.
>
> Collapsed Forwarding feature of squid should satisfy your use case but
> depends on the size of the object it might not be the right choice for you.
>
> What objects size are we talking about?
>
>
>
> Eliezer
>
>
>
> ----
>
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org] *On
> Behalf Of *Sam M
> *Sent:* Tuesday, August 2, 2016 8:43 AM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* [squid-users] different results every time
>
>
>
> Hi,
>
> I'm querying lots of files through 4 cache servers connected through
> parent hierarchy. I clean all the caches before I start and then I query
> the files again in the same exact order. Weirdly, every time I check the
> logs, I see a different cache served a file compared with the previous
> test. The query process is done through a python script that uses wget
> through a proxy to the cache, hence the query process is really fast.
>
> Interestingly, if I put a delay of 1 second between each query, the result
> will be stable and same every time I run the script.
>
> Following a snippet from the config file after changing it too many times
> to make it re-produce the same results yet, that didn't help:
> cache_dir ufs /var/spool/squid 9 16 256
> cache_mem 0 MB
> memory_pools off
> cache_swap_low 100
> cache_swap_high 100
> maximum_object_size_in_memory 0 KB
> cache_replacement_policy lru
> range_offset_limit 0
> quick_abort_min 0 KB
> quick_abort_max 0 KB
>
>
>
> Can someone shed some light on the issue and how to fix it please?
>
> Thanks,
>
> Sam
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160802/2050e07b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160802/2050e07b/attachment.png>

From samm.abcd at gmail.com  Wed Aug  3 02:06:37 2016
From: samm.abcd at gmail.com (Sam M)
Date: Tue, 2 Aug 2016 22:06:37 -0400
Subject: [squid-users] different results every time
In-Reply-To: <CALBG=MFe4GmiQoK5nGDCfuPj1dE38xTkMwXz4jtr_FSMAfsQVA@mail.gmail.com>
References: <CALBG=MFOwdQyRmOL5P_S06DDx-oJWzzdNoom0_4VLUAryFuEmA@mail.gmail.com>
 <01c501d1ec83$a1011a50$e3034ef0$@ngtech.co.il>
 <CALBG=MFe4GmiQoK5nGDCfuPj1dE38xTkMwXz4jtr_FSMAfsQVA@mail.gmail.com>
Message-ID: <CALBG=MEoJH9XO8PpimnVgSKtoupXoAP1pvUXU0_8Q-LxH-KCGw@mail.gmail.com>

Reading through the documentation of Collapsed Forwarding feature I don't
know if this feature would help as the problem to what I'm feeling is the
squid eviction process and decision. It looks like squid is storing more
what is being set in the cache_dir and not evicting the least recently used
files at the right time because of the heavy request load.

Does that make sense, or is there other explanation to the issue I'm having?

Sam

On Tue, Aug 2, 2016 at 9:51 PM, Sam M <samm.abcd at gmail.com> wrote:

> Hi Eliezer,
>
> Thanks for your prompt reply. We are testing our squid configuration
> before we use it. That said, all objects are 1 MB in size and in order to
> test squid we queried a sequence of files multiple times in a manner that
> theoretically at the end of the querying process we should get the same
> number of hits from cache1, cache2, cache3, and cache4.
>
> Structure of test network is: User (using a script) -> cache1 -> cache2 ->
> cache3 -> cache4 -> web server (stores the queried files).
>
> I'm gonna try the Collapsed Forwarding feature and will post back if this
> fixes the issue.
>
> Thank you,
> Sam
>
> On Tue, Aug 2, 2016 at 2:03 AM, Eliezer Croitoru <eliezer at ngtech.co.il>
> wrote:
>
>> Hey Sam,
>>
>>
>>
>> From what I understand it seems that your expectation doesn't meet the
>> reality but I am unsure yet.
>>
>> It seems that the goal is to fetch and save everything to disk and from
>> disk, right?
>>
>>
>>
>> During the time that your clients and proxy are fetching the object using
>> squid, you cannot serve this "in-transit" content to other clients.
>>
>> Collapsed Forwarding feature of squid should satisfy your use case but
>> depends on the size of the object it might not be the right choice for you.
>>
>> What objects size are we talking about?
>>
>>
>>
>> Eliezer
>>
>>
>>
>> ----
>>
>> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>>
>> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org] *On
>> Behalf Of *Sam M
>> *Sent:* Tuesday, August 2, 2016 8:43 AM
>> *To:* squid-users at lists.squid-cache.org
>> *Subject:* [squid-users] different results every time
>>
>>
>>
>> Hi,
>>
>> I'm querying lots of files through 4 cache servers connected through
>> parent hierarchy. I clean all the caches before I start and then I query
>> the files again in the same exact order. Weirdly, every time I check the
>> logs, I see a different cache served a file compared with the previous
>> test. The query process is done through a python script that uses wget
>> through a proxy to the cache, hence the query process is really fast.
>>
>> Interestingly, if I put a delay of 1 second between each query, the
>> result will be stable and same every time I run the script.
>>
>> Following a snippet from the config file after changing it too many times
>> to make it re-produce the same results yet, that didn't help:
>> cache_dir ufs /var/spool/squid 9 16 256
>> cache_mem 0 MB
>> memory_pools off
>> cache_swap_low 100
>> cache_swap_high 100
>> maximum_object_size_in_memory 0 KB
>> cache_replacement_policy lru
>> range_offset_limit 0
>> quick_abort_min 0 KB
>> quick_abort_max 0 KB
>>
>>
>>
>> Can someone shed some light on the issue and how to fix it please?
>>
>> Thanks,
>>
>> Sam
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160802/ac59de77/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160802/ac59de77/attachment.png>

From paul at it.alliedpress.co.nz  Wed Aug  3 02:37:37 2016
From: paul at it.alliedpress.co.nz (Paul van Tuel)
Date: Wed, 03 Aug 2016 14:37:37 +1200
Subject: [squid-users] Squid performance not able to drive a 1Gbps internet
	link
Message-ID: <57A158F1.6070909@it.alliedpress.co.nz>

Hi All,
We've been running Squid for many years. Recently we upgraded our 
internet link to a 1Gbps link, but we are finding that squid is not able 
to drive this link to its full potential (previous links have been 
30Mbps or 100Mbps).
Currently running squid 3.5.1, but have tried 3.4, 3.3, 3.2 versions too.

Upload speeds from the server (without using the local proxy) to the 
internet are 200-300Mbps
Download speeds from the server (without using the local proxy) to the 
internet are 300-600Mbps (the link is not guaranteed).

If we use squid (or tinyproxy) to upload a file the upload speed is 
varies from 15-50Mbps.
If we use squid (or tinyproxy) to download a file from the internet, the 
speeds varies from 80-115Mbps.

We have used various combinations of hardware:
* Dell Power Edge T300, 2950 with SSD or SAS disks. Both using 
bare-metal or VMWare ESXi. Quad-core 2.6GHz Xeon processors with 8G or 
16G RAM
* We have used windows 7 Pro, Ubuntu, Centos 6, Centos 7 each as 
bare-metal and as VM under ESXi.
* We have used a white box (Asus motherboard with 1Gbps NIC, i7, 16G 
RAM) with each of the above OSes in bare-metal installations.

Squid configuration has basically been the out-of-the-box sample file 
with no authentication enabled. Only one user testing the performance of 
the squid proxy. The server is pretty much idle.

Each time the result is the same - if we go direct to the internet 
without using the local proxy the speed is as we would expect. If we use 
the local proxy, the speed drops significantly.
Is this expected behaviour? Or is there something we can do to speed 
up/tune squid's performance? I would be expecting squid to utilise the 
full bandwidth available (similar to what the server can download if you 
do not use a proxy).


Thank you
Paul.





From heiler.bemerguy at cinbesa.com.br  Wed Aug  3 02:42:36 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 2 Aug 2016 23:42:36 -0300
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <57A158F1.6070909@it.alliedpress.co.nz>
References: <57A158F1.6070909@it.alliedpress.co.nz>
Message-ID: <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>


in /etc/sysctl.conf, add:

net.core.rmem_max = 8388608
net.core.wmem_max = 8388608
net.core.wmem_default = 32768
net.core.rmem_default = 32768
net.ipv4.tcp_wmem = 1024 32768 8388608
net.ipv4.tcp_rmem = 1024 32768 8388608


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 02/08/2016 23:37, Paul van Tuel escreveu:
> Hi All,
> We've been running Squid for many years. Recently we upgraded our 
> internet link to a 1Gbps link, but we are finding that squid is not 
> able to drive this link to its full potential (previous links have 
> been 30Mbps or 100Mbps).
> Currently running squid 3.5.1, but have tried 3.4, 3.3, 3.2 versions too.
>
> Upload speeds from the server (without using the local proxy) to the 
> internet are 200-300Mbps
> Download speeds from the server (without using the local proxy) to the 
> internet are 300-600Mbps (the link is not guaranteed).
>
> If we use squid (or tinyproxy) to upload a file the upload speed is 
> varies from 15-50Mbps.
> If we use squid (or tinyproxy) to download a file from the internet, 
> the speeds varies from 80-115Mbps.
>
> We have used various combinations of hardware:
> * Dell Power Edge T300, 2950 with SSD or SAS disks. Both using 
> bare-metal or VMWare ESXi. Quad-core 2.6GHz Xeon processors with 8G or 
> 16G RAM
> * We have used windows 7 Pro, Ubuntu, Centos 6, Centos 7 each as 
> bare-metal and as VM under ESXi.
> * We have used a white box (Asus motherboard with 1Gbps NIC, i7, 16G 
> RAM) with each of the above OSes in bare-metal installations.
>
> Squid configuration has basically been the out-of-the-box sample file 
> with no authentication enabled. Only one user testing the performance 
> of the squid proxy. The server is pretty much idle.
>
> Each time the result is the same - if we go direct to the internet 
> without using the local proxy the speed is as we would expect. If we 
> use the local proxy, the speed drops significantly.
> Is this expected behaviour? Or is there something we can do to speed 
> up/tune squid's performance? I would be expecting squid to utilise the 
> full bandwidth available (similar to what the server can download if 
> you do not use a proxy).
>
>
> Thank you
> Paul.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Aug  3 03:30:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 3 Aug 2016 15:30:37 +1200
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
Message-ID: <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>

On 3/08/2016 2:42 p.m., Heiler Bemerguy wrote:
> 
> in /etc/sysctl.conf, add:
> 
> net.core.rmem_max = 8388608
> net.core.wmem_max = 8388608
> net.core.wmem_default = 32768
> net.core.rmem_default = 32768
> net.ipv4.tcp_wmem = 1024 32768 8388608
> net.ipv4.tcp_rmem = 1024 32768 8388608
> 


PLease aso bump up your version to 3.5.20, there have been more than a
few performance bug fixes since 3.5.1.

For near-Gbps speeds you will need one of the 'Extreme CARP'
configurations for spreading the workload between Squid processes. That
has achieved 800-900 Mbps a while back.
<http://wiki.squid-cache.org/ConfigExamples/ExtremeCarpFrontend>

If thats not fast enough, you may also wish to patch in a larger value
for HTTP_REQBUF_SZ in src/defines.h to 64KB with a matching incease to
read_ahead_gap in squid.conf. That has had some mixed results though,
faster traffic, but also some assertions being hit.

You may find that memory becomes your bottleneck at higher speeds.
8-16GB sounds like a lot for most uses, but when you have enough
connections active to drive Gbps (with 4-6x 64KB I/O buffers) there are
is lot of parallel pressures on the RAM.

Amos



From squid3 at treenet.co.nz  Wed Aug  3 03:53:15 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 3 Aug 2016 15:53:15 +1200
Subject: [squid-users] SSLBump just not working
In-Reply-To: <CABs_asnhvDtviza-Ew-Fuj2==dezjjq-FLphFWesOASHFeF=FA@mail.gmail.com>
References: <CABs_asnhvDtviza-Ew-Fuj2==dezjjq-FLphFWesOASHFeF=FA@mail.gmail.com>
Message-ID: <c9467f58-6dda-edc1-1698-8534a3c9b053@treenet.co.nz>

On 2/08/2016 1:30 p.m., JR Dalrymple wrote:
> I have a freshly installed Squid from source on a likewise freshly
> installed OpenBSD system. Attempting to replace an aging stub Squid on
> Linux with transparent with SSLBump. I think I have everything set up
> pretty skookup, the symptom is it just isn't working. When I browse to an
> https website I get presented my root cert, but not a dynamically created
> cert underneath. It doesn't look like they're being created as the folder
> hierarchy that's supposed to contain the dynamic certs remains empty. Note
> that as of yet this is not in a transparent configuration - choosing to
> crawl before I walk. Here is some perhaps useful info from the system:
> 
<snip>

> ...
> 2016/08/01 16:54:54.370 kid1| 83,7| bio.cc(168) stateChanged: FD 12 now:
> 0x20 SSLOK  (SSL negotiation finished successfully)
> 2016/08/01 16:54:54.370 kid1| 83,7| bio.cc(168) stateChanged: FD 12 now:
> 0x2002 SSLOK  (SSL negotiation finished successfully)
> -----BEGIN SSL SESSION PARAMETERS-----
> -----END SSL SESSION PARAMETERS-----
> 2016/08/01 16:54:54.370 kid1| 83,2| client_side.cc(3809)
> clientNegotiateSSL: clientNegotiateSSL: New session 0x38985389200 on FD 12 (
> 172.22.19.48:65433)
> 2016/08/01 16:54:54.370 kid1| 83,3| client_side.cc(3813)
> clientNegotiateSSL: clientNegotiateSSL: FD 12 negotiated cipher AES128-SHA
> 2016/08/01 16:54:54.371 kid1| 83,5| client_side.cc(3829)
> clientNegotiateSSL: clientNegotiateSSL: FD 12 has no certificate.
> 2016/08/01 16:54:54.426 kid1| 85,5| client_side_request.cc(1438)
> sslBumpAccessCheck: cannot SslBump this request
> ...
> 
> # grep -v ^# /usr/local/squid/etc/squid.conf | grep -v ^[\s]*$

...
> ssl_bump bump all

ssl_bump gets processed in three stages.
#1 on client TCP connection,
#2 after TLS clientHello is received (using the config cert)
#3 after TLS serverHello is received (using a mimic cert)

As the cache.log indicates. The above casues 'bump' action to begin at
#1. The bump handshake is getting the clientHello details, so it can do
something but the Squid configured cert is used since there is no server
details available to generate anything from.

To do bumping with server certificate mimic you need the 'bump' action
to occur at #3.

Like:
 acl step1 at_step SslBump1
 acl step2 at_step SslBump2
 ssl_bump peek step1
 ssl_bump stare step2
 ssl_bump bump all

(or maybe stare and both non-3 steps. I'm not 100% certain there.).

...
> debug_options ALL,9
> 


ALL,9 is only needed if you have to trace exact I/O bytes for debugging.
Almost all useful info about transaction processing is logged at levels
1-6 if you are just interested in what its doing.


> # ls -lR /usr/local/squid/var/lib/
> total 4
> drwxr-xr-x  3 squid  wheel  512 Jul 23 18:38 ssl_db
> 
> /usr/local/squid/var/lib/ssl_db:
> total 8
> drwxr-xr-x  2 squid  wheel  512 Jul 23 18:38 certs
> -rw-r--r--  1 squid  wheel    0 Jul 23 18:38 index.txt
> -rw-r--r--  1 squid  wheel    1 Jul 23 18:38 size
> 

'r' permission for 'other' is usually not good, 640 permissions are
recommended even though these are fake certs in here. But YMMV.

Amos


From michael.pelletier at palmbeachschools.org  Wed Aug  3 04:14:54 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Wed, 3 Aug 2016 00:14:54 -0400
Subject: [squid-users] Recommended Multi-CPU Configuration
In-Reply-To: <1fb5f720-f2fe-e80e-e447-e742e756778d@urlfilterdb.com>
References: <CAEnCSG54TNcRKt4hdAUOHVJVJ=VCKPkZusjq_wJTqP48hv3vWg@mail.gmail.com>
 <55821F81.70809@treenet.co.nz>
 <CAEnCSG4EQ9_4qHoBnJmS3TKG8fURhzQk7t3K+UmorTuJN=bJWA@mail.gmail.com>
 <1fb5f720-f2fe-e80e-e447-e742e756778d@urlfilterdb.com>
Message-ID: <CAEnCSG5378xvOA3n8f334orY-OOq7PD7EsDuwHfd78HPezrY3A@mail.gmail.com>

I filter 7 Gbps of Internet with AD integration.

To do this I have 28 CentOS VMs running in VMWare which are load balanced
(explicit and implicit traffic) The load balancer is also CentOS ipvs.

Michael


On Tue, Aug 2, 2016 at 9:50 PM, Marcus Kool <marcus.kool at urlfilterdb.com>
wrote:

> Hi Michael,
>
> Can you share with us what you ended up with?
>
> Thanks
> Marcus
>
> On 06/18/2015 12:28 AM, Michael Pelletier wrote:
>
>> Which one would be good for capacity\load? I have a very, very large
>> environment. I have 220,000 users on 8 Gig to the INTERNET. I am running a
>> load balancer, ipvsadm (Direct Routing) with 20 proxies
>> behind it. I am interested in handling load.
>>
>> Michael
>>
>> On Wed, Jun 17, 2015 at 9:31 PM, Amos Jeffries <squid3 at treenet.co.nz
>> <mailto:squid3 at treenet.co.nz>> wrote:
>>
>>     On 18/06/2015 8:53 a.m., Michael Pelletier wrote:
>>     > Hello,
>>     >
>>     > I am looking to had some more power to squid. I have seen two
>> different
>>     > types of configurations to do this:
>>     >
>>     > 1. Adding workers directive equal to the number of cpus. Then
>> adding a
>>     > special wrapper around the AUFS disk cache so that the correct
>> worker can
>>     > only access the correct cache. Yes, I know rock is multi cpu
>> capable.
>>     >
>>     > 2. Using the split configuration from the Squid Web page. This
>> involved a
>>     > front end and multiple backend squid servers on the same server.
>>     > http://wiki.squid-cache.org/ConfigExamples/MultiCpuSystem
>>     >
>>     > My question is, which one is recommended? What are the pros and
>> cons of
>>     > each?
>>     >
>>
>>     Both and neither. #1 improves bandwidth savings. #2 improves raw
>> speed.
>>     Pick your poison.
>>
>>     These are example configurations only. For real high performance
>> mutiple
>>     machines in a mix of the two setups is even better.
>>
>>     Amos
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org <mailto:
>> squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> *Disclaimer: *Under Florida law, e-mail addresses are public records. If
>> you do not want your e-mail address released in response to a public
>> records request, do not send electronic mail to this
>> entity. Instead, contact this office by phone or in writing.
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160803/f3350fa0/attachment.htm>

From squid3 at treenet.co.nz  Wed Aug  3 04:37:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 3 Aug 2016 16:37:43 +1200
Subject: [squid-users] different results every time
In-Reply-To: <CALBG=MEoJH9XO8PpimnVgSKtoupXoAP1pvUXU0_8Q-LxH-KCGw@mail.gmail.com>
References: <CALBG=MFOwdQyRmOL5P_S06DDx-oJWzzdNoom0_4VLUAryFuEmA@mail.gmail.com>
 <01c501d1ec83$a1011a50$e3034ef0$@ngtech.co.il>
 <CALBG=MFe4GmiQoK5nGDCfuPj1dE38xTkMwXz4jtr_FSMAfsQVA@mail.gmail.com>
 <CALBG=MEoJH9XO8PpimnVgSKtoupXoAP1pvUXU0_8Q-LxH-KCGw@mail.gmail.com>
Message-ID: <80528f60-813e-b6c6-8042-cb86eb03a911@treenet.co.nz>

On 3/08/2016 2:06 p.m., Sam M wrote:
> Reading through the documentation of Collapsed Forwarding feature I don't
> know if this feature would help as the problem to what I'm feeling is the
> squid eviction process and decision. It looks like squid is storing more
> what is being set in the cache_dir and not evicting the least recently used
> files at the right time because of the heavy request load.

A lot is going on. More on that below.

Also, there is no mistakes possible about the too-early eviction.
Because the "right time" is exactly when something else needs to use
that piece of cache space.  Under heavy traffic the time-based eviction
of data almost never happens, everything cycles out due to load pressure
far earlier thanit would naturalliy expire.  The rare pieces of data
that manage to reach their stale timeout are evicted *later* than that
staleness point.

> 
> Does that make sense, or is there other explanation to the issue I'm having?

Yes. CF is for overlapping requests from the client. It is one of the
things that may be going on. But not by default.


> On Tue, Aug 2, 2016 at 9:51 PM, Sam M wrote:
> 
>> Hi Eliezer,
>>
>> Thanks for your prompt reply. We are testing our squid configuration
>> before we use it. That said, all objects are 1 MB in size and in order to
>> test squid we queried a sequence of files multiple times in a manner that
>> theoretically at the end of the querying process we should get the same
>> number of hits from cache1, cache2, cache3, and cache4.
>>
>> Structure of test network is: User (using a script) -> cache1 -> cache2 ->
>> cache3 -> cache4 -> web server (stores the queried files).
>>
>> I'm gonna try the Collapsed Forwarding feature and will post back if this
>> fixes the issue.
>>

>>>
>>> *From:* Sam M
>>> *Sent:* Tuesday, August 2, 2016 8:43 AM
>>>
>>> Hi,
>>>
>>> I'm querying lots of files through 4 cache servers connected through
>>> parent hierarchy. I clean all the caches before I start and then I query
>>> the files again in the same exact order. Weirdly, every time I check the
>>> logs, I see a different cache served a file compared with the previous
>>> test. The query process is done through a python script that uses wget
>>> through a proxy to the cache, hence the query process is really fast.
>>>
>>> Interestingly, if I put a delay of 1 second between each query, the
>>> result will be stable and same every time I run the script.
>>>
>>> Following a snippet from the config file after changing it too many times
>>> to make it re-produce the same results yet, that didn't help:
>>> cache_dir ufs /var/spool/squid 9 16 256
>>> cache_mem 0 MB
>>> memory_pools off
>>> cache_swap_low 100
>>> cache_swap_high 100
>>> maximum_object_size_in_memory 0 KB
>>> cache_replacement_policy lru
>>> range_offset_limit 0
>>> quick_abort_min 0 KB
>>> quick_abort_max 0 KB
>>>
>>>
>>>
>>> Can someone shed some light on the issue and how to fix it please?
>>>

TL;DR: Does not sound like a problem to me. That behaviour is how HTTP
works.


HTTP is stateless by design. Each request is evaluated at each proxy
independently.

The network itself is dynamic, in timing and known-state. When you are
dealing with things on the nanosecond scale details as low down as ARP
cache and maybe lower, affect the RTT and thus the timing data Squid
stores about its peers and reachable servers. The HTTP object cache is
just one amongst many type of caches having effects - both inside and
outside Squid.

At longer timescales. DNS results can be differently ordered, or
rotating per-lookup, or plain different (but 'static') content per
lookup source.

Even the server memory access speed plays a part. By delaying traffic
(or not) by some nanoseconds during the cache index lookup.

There is also the absolute UTC timestamp of the request reaching the
origin server versus the Expires/Cache-Control/Age/Date headers it
produces. Which are also affected by all sorts of things internal to the
origin itself. The delta values of these timestamps relative to the
cache abolute UTC timestamp on recieving the response - is dynamic and
the amount of that dynamic increases the smaller the timescale one looks
at (ie faster he traffic).

[probably more there I've missed].


All those little details affect in some ways the choice to determine any
given request destination or whether it is served from cache. And that
determination is made independently by each of the proxies in the
traffic chain at the timepoint where each separate request passes
through it.

So with 4x caches in your chain all these tiny details are compounded 4x
times on each request. Of course its going to fluctuate. Even in
isolated test traffic.


HTTP has a 1sec resolution on caching calculations for good reason. And
even that is not enough to average out the entire affect when you
compount the clock variance with multiple layers of proxy.

Unless you wait multiples of whole seconds between each test request you
will be guaranteed to see at least some variance in the HIT vs MISS
behaviour. Even waiting you might see variation between which particular
cache was a HIT.


PS. Squid is only about 90% compliant with the HTTP/1.1 requirements. So
there are some known bugs in the caching logics that your testing may
encounter as well. Though at least bugs are "stable" in their behaviour
for a given proxy build.

HTH
Amos



From squid3 at treenet.co.nz  Wed Aug  3 04:54:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 3 Aug 2016 16:54:17 +1200
Subject: [squid-users] Recommended Multi-CPU Configuration
In-Reply-To: <CAEnCSG5378xvOA3n8f334orY-OOq7PD7EsDuwHfd78HPezrY3A@mail.gmail.com>
References: <CAEnCSG54TNcRKt4hdAUOHVJVJ=VCKPkZusjq_wJTqP48hv3vWg@mail.gmail.com>
 <55821F81.70809@treenet.co.nz>
 <CAEnCSG4EQ9_4qHoBnJmS3TKG8fURhzQk7t3K+UmorTuJN=bJWA@mail.gmail.com>
 <1fb5f720-f2fe-e80e-e447-e742e756778d@urlfilterdb.com>
 <CAEnCSG5378xvOA3n8f334orY-OOq7PD7EsDuwHfd78HPezrY3A@mail.gmail.com>
Message-ID: <bdac3047-d683-6080-43d5-a5220e42ae57@treenet.co.nz>

On 3/08/2016 4:14 p.m., Michael Pelletier wrote:
> I filter 7 Gbps of Internet with AD integration.
> 
> To do this I have 28 CentOS VMs running in VMWare which are load balanced
> (explicit and implicit traffic) The load balancer is also CentOS ipvs.
> 

There are some 'rule of thumb' details that affect this type of
installation;

 * ensuring that UFS based cache_dir (if any) do not share physical disk
spindles. When using VM and other virtualised layers this can be very
tricky to enforce.
 - if you can enforce is Squid will use that spindle to the hardware limits.
 - if you can't enforce it and any two Squid instances end up sharing
their load capacity more than halves, and the disk lifetime is greatly
reduced as disk I/O contention causes controller issues.

* ensuring that heavily loaded Squid do not share their CPU core with
other services. And core "threads" being (near) useless for Squid itself.
 - VM overheads themselves are to be avoided as much as possible. You
may find the container approach better for Squid performance.

* avoiding NTLM. It doubles the traffic load on the frontend compared to
any other auth type.


With special regards to VMs - some versions of VM tools have been shown
that cloning the VM does something to greatly reduce its I/O capacities.
If you have to use them at all a "clean install" type setup (eg. with
ansible) is better to use than cloning an image. YMMV.

HTH
Amos



From marcus.kool at urlfilterdb.com  Wed Aug  3 09:45:18 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 3 Aug 2016 06:45:18 -0300
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
Message-ID: <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>



On 08/03/2016 12:30 AM, Amos Jeffries wrote:


> If thats not fast enough, you may also wish to patch in a larger value
> for HTTP_REQBUF_SZ in src/defines.h to 64KB with a matching incease to
> read_ahead_gap in squid.conf. That has had some mixed results though,
> faster traffic, but also some assertions being hit.

I remember the thread about increasing the request buffer to 64K and it
looked so promising.
Is there any evidence of setting HTTP_REQBUF_SZ to 16K is stable in 3.5.x?

Marcus

> You may find that memory becomes your bottleneck at higher speeds.
> 8-16GB sounds like a lot for most uses, but when you have enough
> connections active to drive Gbps (with 4-6x 64KB I/O buffers) there are
> is lot of parallel pressures on the RAM.
>
> Amos


From chip_pop at hotmail.com  Wed Aug  3 12:34:35 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 3 Aug 2016 05:34:35 -0700 (PDT)
Subject: [squid-users] Spdy header and related
Message-ID: <1470227675660-4678728.post@n4.nabble.com>

is it ok to drop X-Firefox-Spdy
reply_header_access X-Firefox-Spdy deny all
just alow http/1
and if yes how chrome use Spdy in header to drop it 
dose it heart the clients app or browsig ??
im droping those as well so fare so good no complain

reply_header_access Strict-Transport-Security deny all
reply_header_replace Strict-Transport-Security max-age=0; includeSubDomains
reply_header_access Alternate-Protocol deny all 
reply_header_access alternate-protocol deny all 
reply_header_access Alt-Svc deny all
reply_header_access alt-svc deny all
if there is any other headers to drop pls help tks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Spdy-header-and-related-tp4678728.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Aug  3 13:27:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 Aug 2016 01:27:12 +1200
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
 <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
Message-ID: <e49795c6-26a5-c7b9-1167-3eb26713dd56@treenet.co.nz>

On 3/08/2016 9:45 p.m., Marcus Kool wrote:
> 
> 
> On 08/03/2016 12:30 AM, Amos Jeffries wrote:
> 
> 
>> If thats not fast enough, you may also wish to patch in a larger value
>> for HTTP_REQBUF_SZ in src/defines.h to 64KB with a matching incease to
>> read_ahead_gap in squid.conf. That has had some mixed results though,
>> faster traffic, but also some assertions being hit.
> 
> I remember the thread about increasing the request buffer to 64K and it
> looked so promising.
> Is there any evidence of setting HTTP_REQBUF_SZ to 16K is stable in 3.5.x?
> 

It has not had much testing other than Nathan's use, so I'm a bit
hesitant to call it stable. But just raising the 4KB limit a bit to 64K
or less should not have much effect negative effect other than extra RAM
per transaction for buffering (bumped x8 from 256KB per client
connection to 2MB).

We got a bit ambitious and made the main buffers dynamic and effectively
unlimited for Squid-4. But that hit an issue, so has been pulled out
while Nathan figures out how to avoid it.

Amos



From squid3 at treenet.co.nz  Wed Aug  3 13:57:11 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 Aug 2016 01:57:11 +1200
Subject: [squid-users] Spdy header and related
In-Reply-To: <1470227675660-4678728.post@n4.nabble.com>
References: <1470227675660-4678728.post@n4.nabble.com>
Message-ID: <5cdf82bf-28d0-84a2-44e4-b5028fc3734f@treenet.co.nz>

On 4/08/2016 12:34 a.m., joe wrote:
> is it ok to drop X-Firefox-Spdy
> reply_header_access X-Firefox-Spdy deny all
> just alow http/1

"just allow http/1" is not what the above does. It simply denies the
client being informed about that header existing.

> and if yes how chrome use Spdy in header to drop it 
> dose it heart the clients app or browsig ??

Yes it is okay to drop that and any other X-* header. They are by
definition experimental and already deprecated. That includes the ones
generated by Squid itself.

SPDY itself as a protocol is destined to be killed off rather soon.
IIRC, by the end of this year. It has been superceeded by HTTP/2 which
Squid does not yet support (but I'm working on it).


> im droping those as well so fare so good no complain
> 
> reply_header_access Strict-Transport-Security deny all
> reply_header_replace Strict-Transport-Security max-age=0; includeSubDomains
> reply_header_access Alternate-Protocol deny all 
> reply_header_access alternate-protocol deny all 
> reply_header_access Alt-Svc deny all
> reply_header_access alt-svc deny all
> if there is any other headers to drop pls help tks


What is your goal?

If it is to encourage use of protocols that Squid supports, then AFAIK
those are the headers to alter. However, there are details ...

* replacing (or removing) Strict-Transport-Security is only good for
people performing transparent interception of port 443. And is only
useful for domains which have "pinned" certificates. Other domains can
be bumped despite HSTS being used.

* Alternate-Protocol is a header with behaviour that should have been
defined as hop-by-hop. Recent Squid versions strip it by default. You
don't have to do anything.

* Alt-Svc is a tricky situation. The information in it can be useful to
Squid to let the client know, even when intercepting traffic. It is an
OPTIONAL header though, so stripping it away is harmless and has some gain.

Amos



From chip_pop at hotmail.com  Wed Aug  3 13:22:33 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 3 Aug 2016 06:22:33 -0700 (PDT)
Subject: [squid-users] Spdy header and related
In-Reply-To: <5cdf82bf-28d0-84a2-44e4-b5028fc3734f@treenet.co.nz>
References: <1470227675660-4678728.post@n4.nabble.com>
 <5cdf82bf-28d0-84a2-44e4-b5028fc3734f@treenet.co.nz>
Message-ID: <1470230553479-4678731.post@n4.nabble.com>

tks amos yes its just to have some gain of caching 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Spdy-header-and-related-tp4678728p4678731.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Wed Aug  3 14:13:43 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 3 Aug 2016 08:13:43 -0600
Subject: [squid-users] SSLBump just not working
In-Reply-To: <c9467f58-6dda-edc1-1698-8534a3c9b053@treenet.co.nz>
References: <CABs_asnhvDtviza-Ew-Fuj2==dezjjq-FLphFWesOASHFeF=FA@mail.gmail.com>
 <c9467f58-6dda-edc1-1698-8534a3c9b053@treenet.co.nz>
Message-ID: <57A1FC17.2050700@measurement-factory.com>

On 08/02/2016 09:53 PM, Amos Jeffries wrote:

> To do bumping with server certificate mimic you need the 'bump' action
> to occur at #3.
> 
> Like:
>  acl step1 at_step SslBump1
>  acl step2 at_step SslBump2
>  ssl_bump peek step1
>  ssl_bump stare step2
>  ssl_bump bump all
> 
> (or maybe stare and both non-3 steps. I'm not 100% certain there.).


Yes, all of the above can be polished and simplified to become just two
lines:

  ssl_bump stare all
  ssl_bump bump all

Alex.



From heiler.bemerguy at cinbesa.com.br  Wed Aug  3 14:32:40 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Wed, 3 Aug 2016 11:32:40 -0300
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
 <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
Message-ID: <3f248c59-67d4-2a84-359a-004de81b4d67@cinbesa.com.br>


I think it doesn't really matter how much squid sets its default buffer. 
The linux kernel will upscale to the maximum set by the third option. 
(and the TCP Window Size will follow that)

net.ipv4.tcp_wmem = 1024 32768 8388608
net.ipv4.tcp_rmem = 1024 32768 8388608


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 03/08/2016 06:45, Marcus Kool escreveu:
>
>
> On 08/03/2016 12:30 AM, Amos Jeffries wrote:
>
>
>> If thats not fast enough, you may also wish to patch in a larger value
>> for HTTP_REQBUF_SZ in src/defines.h to 64KB with a matching incease to
>> read_ahead_gap in squid.conf. That has had some mixed results though,
>> faster traffic, but also some assertions being hit.
>
> I remember the thread about increasing the request buffer to 64K and it
> looked so promising.
> Is there any evidence of setting HTTP_REQBUF_SZ to 16K is stable in 
> 3.5.x?
>
> Marcus
>
>> You may find that memory becomes your bottleneck at higher speeds.
>> 8-16GB sounds like a lot for most uses, but when you have enough
>> connections active to drive Gbps (with 4-6x 64KB I/O buffers) there are
>> is lot of parallel pressures on the RAM.
>>
>> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From ht at inf.ed.ac.uk  Wed Aug  3 14:36:45 2016
From: ht at inf.ed.ac.uk (Henry S. Thompson)
Date: Wed, 03 Aug 2016 15:36:45 +0100
Subject: [squid-users] Seeking insight into zeros,
	negative values in log: 2.6.STABLE18
Message-ID: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>

I'm trying to do some summary statistics based on log files from our
2.6.STABLE18 setup.

A range of issues with interpreting 0 and negative values have arisen:

 1) Roughly 6 in every 1000 log lines show an HTTP status code of 000,
    about 90% with TCP_MISS, the rest mostly TCP_HIT, e.g.

    1402700792.606 54 ... TCP_MISS/000 0 GET http://... DIRECT/... -
    1402700780.177 1 ... TCP_HIT/000 0 GET http://... NONE/- -

    Web search suggests the most likely interpretation of this is client
    disconnect, can anyone confirm/elaborate?  Note this seems
    consistent with the fact that as in the examples above almost all
    show a 0 for the size, but doesn't explain the lack of media type...

 2) Leaving aside those cases, I see a modest handful (1 in 7000) of 0
    values in the size field, e.g.

    1402741879.726 114 ... TCP_MISS/200 0 GET http://... DIRECT/... image/gif
    1402771557.693 176 ... TCP_HIT/200 0 GET http://... NONE/- image/gif

    How should these be understood?

 3) I'm seeing very small numbers (1 in 100000) of negative durations, e.g.

    1402744620.389 -70 ... TCP_MISS/200 1882 GET http://... DIRECT/... text/xml
    
    How should these be understood?

Sorry for these queries of mostly historical interest for most people,
but I've looked fairly hard for earlier discussion of these oddities w/o
success.

Thanks,

ht
-- 
       Henry S. Thompson, School of Informatics, University of Edinburgh
      10 Crichton Street, Edinburgh EH8 9AB, SCOTLAND -- (44) 131 650-4440
                Fax: (44) 131 650-4587, e-mail: ht at inf.ed.ac.uk
                       URL: http://www.ltg.ed.ac.uk/~ht/
 [mail from me _always_ has a .sig like this -- mail without it is forged spam]


From stan.prescott at gmail.com  Wed Aug  3 14:45:03 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Wed, 3 Aug 2016 09:45:03 -0500
Subject: [squid-users] sslproxyflags DONT_VERIFY_PEER
Message-ID: <CANLNtGRVZ-J=ZNGP_QeipFD0cvwupNV3mAZTo2vx-OkmFaFqRA@mail.gmail.com>

I have had my squid implementation for sslbump set up and working for some
time now. I have had several people point out that my use of "sslproxyflags
DONT_VERIFY_PEER" is dangerous from a security standpoint. When I was first
trying to get sslbump working it would not work until I saw a suggestion
somewhere that that sslproxyflag could be used. When I tried it, sslbump
started working.

After several configurations adding the new peek+splice and peek+bump
features, I still am not able to remove "sslproxyflags DONT_VERIFY_PEER".
Whenever I try removing it, I get the error message that my browser is
trying to connect to an unsecured site or "Untrusted connection" whenever
it tries to connect to an https site.

Here is my squid.conf:

*visible_hostname smoothwall*

*# Uncomment the following to send debug info to /var/log/squid/cache.log*
*#debug_options ALL,1 33,2 28,9*

*# ACCESS CONTROLS*
*# ----------------------------------------------------------------*
*acl localhostgreen src 10.40.40.1*
*acl localnetgreen src 10.40.40.0/24 <http://10.40.40.0/24>*
*acl SWE_subnets          src
"/var/smoothwall/mods/proxy/acls/src_subnets.acl"*

*acl SSL_ports port 445 443 441 563*
*acl Safe_ports port 80     # http*
*acl Safe_ports port 81     # smoothwall http*
*acl Safe_ports port 21     # ftp *
*acl Safe_ports port 445 443 441 563 # https, snews*
*acl Safe_ports port 70     # gopher*
*acl Safe_ports port 210       # wais  *
*acl Safe_ports port 1025-65535 # unregistered ports*
*acl Safe_ports port 280       # http-mgmt*
*acl Safe_ports port 488       # gss-http *
*acl Safe_ports port 591       # filemaker*
*acl Safe_ports port 777       # multiling http*

*acl CONNECT method CONNECT*

*# TAG: http_access*
*# ----------------------------------------------------------------*

*http_access allow SWE_subnets*


*http_access allow localhost*
*http_access deny !Safe_ports*
*http_access deny CONNECT !SSL_ports*

*http_access allow localnetgreen*
*http_access allow CONNECT localnetgreen*

*http_access allow localhostgreen*
*http_access allow CONNECT localhostgreen*

*# http_port and https_port*
*#----------------------------------------------------------------------------*

*# For forward-proxy port. Squid uses this port to serve error pages, ftp
icons and communication with other proxies.*
*#----------------------------------------------------------------------------*
*http_port 3127*

*http_port 10.40.40.1:800 <http://10.40.40.1:800> intercept*
*https_port 10.40.40.1:808 <http://10.40.40.1:808> intercept ssl-bump
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
cert=/var/smoothwall/mods/proxy/ssl_cert/squidCA.pem
sslflags=VERIFY_CRL_ALL options=NO_SSLv2,NO_SSLv3,No_Compression
dhparams=/var/smoothwall/mods/proxy/ssl_cert/dhparam.pem*


*http_port 127.0.0.1:800 <http://127.0.0.1:800> intercept*

*sslproxy_session_cache_size 4 MB*

*ssl_bump none localhostgreen*

*sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression*
*sslproxy_cipher
ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL*

*acl tls_s1_connect at_step SslBump1*
*acl tls_s2_client_hello at_step SslBump2*
*acl tls_s3_server_hello at_step SslBump3*

*acl tls_allowed_hsts ssl::server_name .akamaihd.net <http://akamaihd.net>*
*acl tls_server_is_bank ssl::server_name .wellsfargo.com
<http://wellsfargo.com>*
*acl tls_to_splice any-of tls_allowed_hsts tls_server_is_bank*

*ssl_bump peek tls_s1_connect all*
*ssl_bump splice tls_s2_client_hello tls_to_splice*
*ssl_bump stare tls_s2_client_hello all*
*ssl_bump bump tls_s3_server_hello all*

*sslproxy_cert_error deny all*
*sslproxy_flags DONT_VERIFY_PEER*

*sslcrtd_program /var/smoothwall/mods/proxy/libexec/ssl_crtd -s
/var/smoothwall/mods/proxy/lib/ssl_db -M 4MB*
*sslcrtd_children 5*

*http_access deny all*

*cache_replacement_policy heap GDSF*
*memory_replacement_policy heap GDSF*

*# CACHE OPTIONS*
*#
----------------------------------------------------------------------------*
*cache_effective_user squid*
*cache_effective_group squid*

*cache_swap_high 92*
*cache_swap_low 90*

*cache_access_log stdio:/var/log/squid/access.log*
*cache_log /var/log/squid/cache.log*
*cache_mem 64 MB*

*cache_dir aufs /var/spool/squid/cache 1024 16 256*

*maximum_object_size 33 MB*

*minimum_object_size 0 KB*


*request_body_max_size 0 KB*

*# OTHER OPTIONS*
*#
----------------------------------------------------------------------------*
*#via off*
*forwarded_for off*

*pid_filename /var/run/squid.pid*

*shutdown_lifetime 10 seconds*
*#icp_port 3130*

*half_closed_clients off*
*icap_enable on*
*icap_send_client_ip on*
*icap_send_client_username on*
*icap_client_username_encode off*
*icap_client_username_header X-Authenticated-User*
*icap_preview_enable on*
*icap_preview_size 1024*
*icap_service service_avi_req reqmod_precache
icap://localhost:1344/squidclamav bypass=off*
*adaptation_access service_avi_req allow all*
*icap_service service_avi_resp respmod_precache
icap://localhost:1344/squidclamav bypass=on*
*adaptation_access service_avi_resp allow all*

*umask 022*

*logfile_rotate 0*

*strip_query_terms off*


*url_rewrite_program /var/smoothwall/mods/ufdbguard/bin/ufdbgclient ?l
/var/log/squid*
*url_rewrite_children 64 startup=16 idle=4 concurrency=0*
*url_rewrite_extras "%>a/%>A %un %>rm bump_mode=%ssl::bump_mode
sni='%ssl::>sni' referer='%{Referer}>h'"*


Does anyone have any suggestions how I can remove that proxy flag and still
keep sslbump working?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160803/ae497a56/attachment.htm>

From harsha.s.aryan at gmail.com  Wed Aug  3 16:53:42 2016
From: harsha.s.aryan at gmail.com (Harsha S Aryan)
Date: Wed, 3 Aug 2016 22:23:42 +0530
Subject: [squid-users] Fwd: All website getting Blocked
In-Reply-To: <CAAqh_uH_oeMc6ksiDcOx-t+CGOsyJrepAgt1YzHAv0WezkSUyg@mail.gmail.com>
References: <CAAqh_uH_oeMc6ksiDcOx-t+CGOsyJrepAgt1YzHAv0WezkSUyg@mail.gmail.com>
Message-ID: <CAAqh_uF9X5KVK2bs_MvRNinvmBXRTR0AhP8o=kdQ5fTAzX2BBA@mail.gmail.com>

---------- Forwarded message ----------
From: Harsha S Aryan <harsha.s.aryan at gmail.com>
Date: Wed, Aug 3, 2016 at 10:22 PM
Subject: All website getting Blocked
To: squid-users at lists.squid-cache.org


Hi,

All website getting Blocked
using squid3
ubuntu 14.04
Squid Cache: Version 3.3.8


conf file


auth_param basic children 5
auth_param basic realm Squid proxy-caching web server
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off
acl allowed_sites dstdomain "/etc/squid3/Allowed_Sites.txt"
acl blocked_ip src "/etc/squid3/Blocked_Ip.txt"
acl allowed_ip dst "/etc/squid3/Allowed_Ip.txt"
acl allcomputers src 192.168.1.0/255.255.255.0
acl allcomputers src 192.168.2.0/255.255.255.0
acl all_others dst 0.0.0.0/0.0.0.0
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl all src all
acl localhost src 127.0.0.1/32
acl to_localhost dst 127.0.0.0/8
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_access deny all
http_port 3128
http_port 80 vhost
hierarchy_stoplist cgi-bin ?
access_log /var/log/squid3/access.log squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern (Release|Package(.gz)*)$        0       20%     2880
refresh_pattern \.js$ 1440 0% 4320
refresh_pattern \.(PNG|png)$ 1440 0% 4320
refresh_pattern .               0       20%     4320
acl shoutcast rep_header X-HTTP09-First-Line ^ICY\s[0-9]
upgrade_http0.9 deny shoutcast
acl apache rep_header Server ^Apache
broken_vary_encoding allow apache
extension_methods REPORT MERGE MKACTIVITY CHECKOUT
hosts_file /etc/hosts
coredump_dir /var/spool/squid3

Please let me know if anything is missing

-- 
Rehards,
Harsha



-- 
Rehards,
Harsha
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160803/c39b1ccd/attachment.htm>

From yvoinov at gmail.com  Wed Aug  3 17:16:54 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 3 Aug 2016 23:16:54 +0600
Subject: [squid-users] Fwd: All website getting Blocked
In-Reply-To: <CAAqh_uF9X5KVK2bs_MvRNinvmBXRTR0AhP8o=kdQ5fTAzX2BBA@mail.gmail.com>
References: <CAAqh_uH_oeMc6ksiDcOx-t+CGOsyJrepAgt1YzHAv0WezkSUyg@mail.gmail.com>
 <CAAqh_uF9X5KVK2bs_MvRNinvmBXRTR0AhP8o=kdQ5fTAzX2BBA@mail.gmail.com>
Message-ID: <6bb18ffb-1dbf-5360-ff86-08a58bcc67c5@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You haven't permissive rule for localnet.


03.08.2016 22:53, Harsha S Aryan ?????:
>
> ---------- Forwarded message ----------
> From: *Harsha S Aryan* <harsha.s.aryan at gmail.com
<mailto:harsha.s.aryan at gmail.com>>
> Date: Wed, Aug 3, 2016 at 10:22 PM
> Subject: All website getting Blocked
> To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>
> Hi,
>
> All website getting Blocked
> using squid3
> ubuntu 14.04
> Squid Cache: Version 3.3.8
>
>
> conf file
>
>
> auth_param basic children 5
> auth_param basic realm Squid proxy-caching web server
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off
> acl allowed_sites dstdomain "/etc/squid3/Allowed_Sites.txt"
> acl blocked_ip src "/etc/squid3/Blocked_Ip.txt"
> acl allowed_ip dst "/etc/squid3/Allowed_Ip.txt"
> acl allcomputers src 192.168.1.0/255.255.255.0
<http://192.168.1.0/255.255.255.0>
> acl allcomputers src 192.168.2.0/255.255.255.0
<http://192.168.2.0/255.255.255.0>
> acl all_others dst 0.0.0.0/0.0.0.0 <http://0.0.0.0/0.0.0.0>
> acl localnet src 10.0.0.0/8 <http://10.0.0.0/8>     # RFC1918 possible
internal network
> acl localnet src 172.16.0.0/12 <http://172.16.0.0/12>  # RFC1918
possible internal network
> acl localnet src 192.168.0.0/16 <http://192.168.0.0/16> # RFC1918
possible internal network
> acl all src all
> acl localhost src 127.0.0.1/32 <http://127.0.0.1/32>
> acl to_localhost dst 127.0.0.0/8 <http://127.0.0.0/8>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localhost
Add this here:
http_access allow localnet
and reconfigure. That's all.
> http_access deny all
> http_port 3128
> http_port 80 vhost
> hierarchy_stoplist cgi-bin ?
> access_log /var/log/squid3/access.log squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern (Release|Package(.gz)*)$        0       20%     2880
> refresh_pattern \.js$ 1440 0% 4320
> refresh_pattern \.(PNG|png)$ 1440 0% 4320
> refresh_pattern .               0       20%     4320
> acl shoutcast rep_header X-HTTP09-First-Line ^ICY\s[0-9]
> upgrade_http0.9 deny shoutcast
> acl apache rep_header Server ^Apache
> broken_vary_encoding allow apache
> extension_methods REPORT MERGE MKACTIVITY CHECKOUT
> hosts_file /etc/hosts
> coredump_dir /var/spool/squid3
>
> Please let me know if anything is missing
>
> --
> Rehards,
> Harsha
>
>
>
> --
> Rehards,
> Harsha
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXoicGAAoJENNXIZxhPexGCbIIAJt8ndstXmvXchMIuR0YgEuO
1B/lA3DY/fR14udGm8BvNtTn2V103Ch8WH97NZ0Rxm11cYZvauQ8OnkHE53aZ9Uk
J4qVVYBbidLERwRIZQQr559qyYPTZV8khNhSRNJXD1r2Vdl0vJsybIe1IW8D6v33
aVPQN2tScT4bdDFCDOYN++6Cm+uT+eU8eSR5N56qJg+t4CmQxcEPFGgqHFVP/59c
i2lVDF7vTcmsMif/HbqUx3fxHa6H6dYliaycmRVHEbApjtwT/TqFGuJsC+PTtjPH
FHApEXDfZycJh69iVVfJstfTj8yrHpe96EYOCxVdOKc6+tN1XMH2wqflkjALMeM=
=K5gg
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160803/0666e917/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160803/0666e917/attachment.key>

From marcus.kool at urlfilterdb.com  Wed Aug  3 19:54:45 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 3 Aug 2016 16:54:45 -0300
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <e49795c6-26a5-c7b9-1167-3eb26713dd56@treenet.co.nz>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
 <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
 <e49795c6-26a5-c7b9-1167-3eb26713dd56@treenet.co.nz>
Message-ID: <92f8720e-85f7-90ae-cb68-4f131e2f8938@urlfilterdb.com>



On 08/03/2016 10:27 AM, Amos Jeffries wrote:
> On 3/08/2016 9:45 p.m., Marcus Kool wrote:
>>
>>
>> On 08/03/2016 12:30 AM, Amos Jeffries wrote:
>>
>>
>>> If thats not fast enough, you may also wish to patch in a larger value
>>> for HTTP_REQBUF_SZ in src/defines.h to 64KB with a matching incease to
>>> read_ahead_gap in squid.conf. That has had some mixed results though,
>>> faster traffic, but also some assertions being hit.
>>
>> I remember the thread about increasing the request buffer to 64K and it
>> looked so promising.
>> Is there any evidence of setting HTTP_REQBUF_SZ to 16K is stable in 3.5.x?
>>
>
> It has not had much testing other than Nathan's use, so I'm a bit
> hesitant to call it stable. But just raising the 4KB limit a bit to 64K
> or less should not have much effect negative effect other than extra RAM
> per transaction for buffering (bumped x8 from 256KB per client
> connection to 2MB).

I am about to configure an array of squid servers to process 50 gbit of traffic
and the performance increase that Nathan originally reported is significant...
So if I understand it correctly, raising it to 16K in 3.5.20
will most likely have no issues.  I will give it a try.

Thanks
Marcus

> We got a bit ambitious and made the main buffers dynamic and effectively
> unlimited for Squid-4. But that hit an issue, so has been pulled out
> while Nathan figures out how to avoid it.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From rousskov at measurement-factory.com  Wed Aug  3 20:01:40 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 3 Aug 2016 14:01:40 -0600
Subject: [squid-users] sslproxyflags DONT_VERIFY_PEER
In-Reply-To: <CANLNtGRVZ-J=ZNGP_QeipFD0cvwupNV3mAZTo2vx-OkmFaFqRA@mail.gmail.com>
References: <CANLNtGRVZ-J=ZNGP_QeipFD0cvwupNV3mAZTo2vx-OkmFaFqRA@mail.gmail.com>
Message-ID: <57A24DA4.5020901@measurement-factory.com>

On 08/03/2016 08:45 AM, Stanford Prescott wrote:

> ssl_bump none localhostgreen
> ssl_bump peek tls_s1_connect all
> ssl_bump splice tls_s2_client_hello tls_to_splice
> ssl_bump stare tls_s2_client_hello all
> ssl_bump bump tls_s3_server_hello all

AFAICT, the above is too complex. You can simplify it with:

  ssl_bump splice localhostgreen
  ssl_bump peek tls_s1_connect
  ssl_bump splice tls_to_splice
  ssl_bump stare all
  ssl_bump bump all

and, after polishing your ACLs a little, possibly even with:

  ssl_bump splice transactions_to_splice
  ssl_bump peek tls_s1_connect
  ssl_bump stare all
  ssl_bump bump all

where transactions_to_splice is "localhostgreen or (tls_s2_client_hello
and tls_to_splice)".


As for your original question, I recommend figuring out why Squid cannot
verify the peer. For example, your setup might be missing fresh
certificates for some well-known Root CAs. I do not know a good way to
figure out why peer verification does not work, but analyzing cache.log
with high-enough debugging level should be doable, especially if you can
reproduce the problem using a single transaction:

http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction


HTH,

Alex.



From stan.prescott at gmail.com  Wed Aug  3 21:12:45 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Wed, 3 Aug 2016 16:12:45 -0500
Subject: [squid-users] sslproxyflags DONT_VERIFY_PEER
In-Reply-To: <57A24DA4.5020901@measurement-factory.com>
References: <CANLNtGRVZ-J=ZNGP_QeipFD0cvwupNV3mAZTo2vx-OkmFaFqRA@mail.gmail.com>
 <57A24DA4.5020901@measurement-factory.com>
Message-ID: <CANLNtGTMwGReDXU9oWMx5aPDOH5RBKvMbMsH2dj3O5rN1OTuog@mail.gmail.com>

Thanks for the info, Alex. That's very helpful about cleaning up my ACLs.
Those ACLs are a collection of ACLs that others have suggested I use, but
it would be nice to make them less confusing for me.

With my limited understanding of how sslbump works, the idea for squid to
play MITM is that a self-signed cert like squidCA.der is imported to a
browser's root CAs. I have left a copy of the self-signed cert named
squidCA.pem in the squid's cert directory which only works if squid is told
to not verify the peer. When following the instructions how to generate the
self-signed cert with openssl, the .pem file must be converted to a .der
file for the browser to accept it. It just dawned on me that, could this be
related to the fact that the squid self-signed certs are not named the same?

On Wed, Aug 3, 2016 at 3:01 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 08/03/2016 08:45 AM, Stanford Prescott wrote:
>
> > ssl_bump none localhostgreen
> > ssl_bump peek tls_s1_connect all
> > ssl_bump splice tls_s2_client_hello tls_to_splice
> > ssl_bump stare tls_s2_client_hello all
> > ssl_bump bump tls_s3_server_hello all
>
> AFAICT, the above is too complex. You can simplify it with:
>
>   ssl_bump splice localhostgreen
>   ssl_bump peek tls_s1_connect
>   ssl_bump splice tls_to_splice
>   ssl_bump stare all
>   ssl_bump bump all
>
> and, after polishing your ACLs a little, possibly even with:
>
>   ssl_bump splice transactions_to_splice
>   ssl_bump peek tls_s1_connect
>   ssl_bump stare all
>   ssl_bump bump all
>
> where transactions_to_splice is "localhostgreen or (tls_s2_client_hello
> and tls_to_splice)".
>
>
> As for your original question, I recommend figuring out why Squid cannot
> verify the peer. For example, your setup might be missing fresh
> certificates for some well-known Root CAs. I do not know a good way to
> figure out why peer verification does not work, but analyzing cache.log
> with high-enough debugging level should be doable, especially if you can
> reproduce the problem using a single transaction:
>
>
> http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction
>
>
> HTH,
>
> Alex.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160803/6380c63e/attachment.htm>

From stan.prescott at gmail.com  Wed Aug  3 23:51:41 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Wed, 3 Aug 2016 18:51:41 -0500
Subject: [squid-users] sslproxyflags DONT_VERIFY_PEER
In-Reply-To: <CANLNtGTMwGReDXU9oWMx5aPDOH5RBKvMbMsH2dj3O5rN1OTuog@mail.gmail.com>
References: <CANLNtGRVZ-J=ZNGP_QeipFD0cvwupNV3mAZTo2vx-OkmFaFqRA@mail.gmail.com>
 <57A24DA4.5020901@measurement-factory.com>
 <CANLNtGTMwGReDXU9oWMx5aPDOH5RBKvMbMsH2dj3O5rN1OTuog@mail.gmail.com>
Message-ID: <CANLNtGSqpbeTvr7bdQC15vcUwrCYe26USqxUpLQCEMAR3v7VJg@mail.gmail.com>

Okay, it's not a name of the cert problem.

I turned on extra debug info to see what I get when I remove the
DONT_VERIFY_PEER flag and tried accessing https://www.yahoo.com. This is
what I got in the cache.log. I only see a couple of lines about a
certificate error. Sorry this is long but I didn't know what to include so
I just included everything for that one access attempt.

*2016/08/03 18:12:16.701 kid1| 28,4| Eui48.cc(178) lookup: id=0xa2064b0
query ARP table*
*2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(222) lookup: id=0xa2064b0
query ARP on each interface (128 found)*
*2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
found interface lo*
*2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
found interface eth2*
*2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
looking up ARP address for 10.40.40.110 on eth2*
*2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
found interface eth1*
*2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
looking up ARP address for 10.40.40.110 on eth1*
*2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(280) lookup: id=0xa2064b0 got
address 08:00:27:29:24:4a on eth1*
*2016/08/03 18:12:16.702 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
*2016/08/03 18:12:16.702 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
*2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
checking slow rules*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rules)*
*2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/0is not banned*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
localhostgreen*
*2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare:
10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
<http://10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]>
(10.40.40.110:49732 <http://10.40.40.110:49732>)  vs
10.40.40.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]*
*2016/08/03 18:12:16.702 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:49732 <http://10.40.40.110:49732>' NOT found*
*2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
localhostgreen = 0*
*2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 0*
*2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/3is not banned*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
tls_s1_connect*
*2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
tls_s1_connect = 1*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking all*
*2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
<http://10.40.40.110:49732/[:>:] ([::]:49732)  vs [::]-[::]/[::]*
*2016/08/03 18:12:16.702 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:49732 <http://10.40.40.110:49732>' found*
*2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
*2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 1*
*2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rules) = 1*
*2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(63) markFinished:
0xa210ad8 answer ALLOWED for match*
*2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
*2016/08/03 18:12:16.702 kid1| 33,2| client_side.cc(3909)
httpsSslBumpAccessCheckDone: sslBump needed for local=52.34.245.108:443
<http://52.34.245.108:443> remote=10.40.40.110:49732
<http://10.40.40.110:49732> FD 14 flags=33 method 3*
*2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(70) preCheck: 0xa214d28
checking slow rules*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
http_access*
*2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/0is not banned*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
http_access#1*
*2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
SWE_subnets*
*2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare:
10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
<http://10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]>
(10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
192.168.192.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
*2016/08/03 18:12:16.703 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare:
10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
<http://10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]>
(10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
*2016/08/03 18:12:16.703 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare:
10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
<http://10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]>
(10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
*2016/08/03 18:12:16.703 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:49732 <http://10.40.40.110:49732>' found*
*2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
SWE_subnets = 1*
*2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
http_access#1 = 1*
*2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
http_access = 1*
*2016/08/03 18:12:16.703 kid1| 28,3| Checklist.cc(63) markFinished:
0xa214d28 answer ALLOWED for match*
*2016/08/03 18:12:16.703 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0xa214d28 answer=ALLOWED*
*2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fc08*
*2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf94fc08*
*2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fd3c*
*2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf94fd3c*
*2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa214d28*
*2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa214d28*
*2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
*2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
*2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
checking slow rules*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rules)*
*2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/0 is  banned*
*2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/3is not banned*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
tls_s1_connect*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
tls_s1_connect = 0*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 0*
*2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/6is not banned*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
tls_s2_client_hello*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
tls_s2_client_hello = 1*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
tls_to_splice*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
tls_allowed_hsts*
*2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
'tiles.services.mozilla.com <http://tiles.services.mozilla.com>'*
*2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
aclHostDomainCompare: Match:tiles.services.mozilla.com
<http://tiles.services.mozilla.com> <>  .akamaihd.net <http://akamaihd.net>*
*2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match:
'tiles.services.mozilla.com <http://tiles.services.mozilla.com>' NOT found*
*2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
'none'*
*2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
aclHostDomainCompare: Match:none <>  .akamaihd.net <http://akamaihd.net>*
*2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
found*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
tls_allowed_hsts = 0*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
tls_server_is_bank*
*2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
'tiles.services.mozilla.com <http://tiles.services.mozilla.com>'*
*2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
aclHostDomainCompare: Match:tiles.services.mozilla.com
<http://tiles.services.mozilla.com> <>  .wellsfargo.com
<http://wellsfargo.com>*
*2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match:
'tiles.services.mozilla.com <http://tiles.services.mozilla.com>' NOT found*
*2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
'none'*
*2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
aclHostDomainCompare: Match:none <>  .wellsfargo.com
<http://wellsfargo.com>*
*2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
found*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
tls_server_is_bank = 0*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
tls_to_splice = 0*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 0*
*2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/4is not banned*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
tls_s2_client_hello*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
tls_s2_client_hello = 1*
*2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking all*
*2016/08/03 18:12:16.704 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
<http://10.40.40.110:49732/[:>:] ([::]:49732)  vs [::]-[::]/[::]*
*2016/08/03 18:12:16.704 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:49732 <http://10.40.40.110:49732>' found*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 1*
*2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rules) = 1*
*2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(63) markFinished:
0xa210ad8 answer ALLOWED for match*
*2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
*2016/08/03 18:12:16.704 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf95080c*
*2016/08/03 18:12:16.704 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf95080c*
*2016/08/03 18:12:16.704 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
*2016/08/03 18:12:16.704 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
*2016/08/03 18:12:16.869 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
checking fast rules*
*2016/08/03 18:12:16.870 kid1| 28,5| Checklist.cc(346) fastCheck:
aclCheckFast: list: 0x9de0a80*
*2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking
sslproxy_cert_error*
*2016/08/03 18:12:16.870 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'DENIED/0is not banned*
*2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking
sslproxy_cert_error#1*
*2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking all*
*2016/08/03 18:12:16.870 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
<http://10.40.40.110:49732/[:>:] ([::]:49732)  vs [::]-[::]/[::]*
*2016/08/03 18:12:16.870 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:49732 <http://10.40.40.110:49732>' found*
*2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
*2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked:
sslproxy_cert_error#1 = 1*
*2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked:
sslproxy_cert_error = 1*
*2016/08/03 18:12:16.870 kid1| 28,3| Checklist.cc(63) markFinished:
0xa210ad8 answer DENIED for match*
*2016/08/03 18:12:16.870 kid1| Error negotiating SSL on FD 16:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)*
*2016/08/03 18:12:16.871 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950b68
checking fast ACLs*
*2016/08/03 18:12:16.871 kid1| 28,5| Acl.cc(138) matches: checking
cache_access_log stdio:/var/log/squid/access.log*
*2016/08/03 18:12:16.871 kid1| 28,5| Acl.cc(138) matches: checking
(cache_access_log stdio:/var/log/squid/access.log line)*
*2016/08/03 18:12:16.871 kid1| 28,3| Acl.cc(158) matches: checked:
(cache_access_log stdio:/var/log/squid/access.log line) = 1*
*2016/08/03 18:12:16.871 kid1| 28,3| Acl.cc(158) matches: checked:
cache_access_log stdio:/var/log/squid/access.log = 1*
*2016/08/03 18:12:16.871 kid1| 28,3| Checklist.cc(63) markFinished:
0xbf950b68 answer ALLOWED for match*
*2016/08/03 18:12:16.871 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950b68*
*2016/08/03 18:12:16.871 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950b68*
*2016/08/03 18:12:16.998 kid1| 33,2| client_side.cc(816) swanSong:
local=52.34.245.108:443 <http://52.34.245.108:443>
remote=10.40.40.110:49732 <http://10.40.40.110:49732> flags=33*
*2016/08/03 18:12:16.998 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950c28
checking fast ACLs*
*2016/08/03 18:12:16.998 kid1| 28,5| Acl.cc(138) matches: checking
cache_access_log stdio:/var/log/squid/access.log*
*2016/08/03 18:12:16.998 kid1| 28,5| Acl.cc(138) matches: checking
(cache_access_log stdio:/var/log/squid/access.log line)*
*2016/08/03 18:12:16.998 kid1| 28,3| Acl.cc(158) matches: checked:
(cache_access_log stdio:/var/log/squid/access.log line) = 1*
*2016/08/03 18:12:16.998 kid1| 28,3| Acl.cc(158) matches: checked:
cache_access_log stdio:/var/log/squid/access.log = 1*
*2016/08/03 18:12:16.998 kid1| 28,3| Checklist.cc(63) markFinished:
0xbf950c28 answer ALLOWED for match*
*2016/08/03 18:12:16.998 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950c28*
*2016/08/03 18:12:16.998 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950c28*
*2016/08/03 18:12:16.998 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
*2016/08/03 18:12:16.998 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
*2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(178) lookup: id=0xa2064b0
query ARP table*
*2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(222) lookup: id=0xa2064b0
query ARP on each interface (128 found)*
*2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
found interface lo*
*2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
found interface eth2*
*2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
looking up ARP address for 10.40.40.110 on eth2*
*2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
found interface eth1*
*2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
looking up ARP address for 10.40.40.110 on eth1*
*2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(280) lookup: id=0xa2064b0 got
address 08:00:27:29:24:4a on eth1*
*2016/08/03 18:12:21.032 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
*2016/08/03 18:12:21.032 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
*2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
checking slow rules*
*2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
http_access*
*2016/08/03 18:12:21.054 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/0is not banned*
*2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
http_access#1*
*2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
SWE_subnets*
*2016/08/03 18:12:21.054 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare:
10.40.40.110:40595/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
<http://10.40.40.110:40595/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]>
(10.40.40.0:40595 <http://10.40.40.0:40595>)  vs
10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
*2016/08/03 18:12:21.054 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:40595 <http://10.40.40.110:40595>' found*
*2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
SWE_subnets = 1*
*2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
http_access#1 = 1*
*2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
http_access = 1*
*2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(63) markFinished:
0xa210ad8 answer ALLOWED for match*
*2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
*2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950198*
*2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950198*
*2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf9502cc*
*2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf9502cc*
*2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94f87c*
*2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf94f87c*
*2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
*2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
*2016/08/03 18:12:21.101 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf9509dc*
*2016/08/03 18:12:21.102 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf9509dc*
*2016/08/03 18:12:21.150 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950ae8
checking fast ACLs*
*2016/08/03 18:12:21.150 kid1| 28,5| Acl.cc(138) matches: checking
cache_access_log stdio:/var/log/squid/access.log*
*2016/08/03 18:12:21.150 kid1| 28,5| Acl.cc(138) matches: checking
(cache_access_log stdio:/var/log/squid/access.log line)*
*2016/08/03 18:12:21.150 kid1| 28,3| Acl.cc(158) matches: checked:
(cache_access_log stdio:/var/log/squid/access.log line) = 1*
*2016/08/03 18:12:21.150 kid1| 28,3| Acl.cc(158) matches: checked:
cache_access_log stdio:/var/log/squid/access.log = 1*
*2016/08/03 18:12:21.150 kid1| 28,3| Checklist.cc(63) markFinished:
0xbf950ae8 answer ALLOWED for match*
*2016/08/03 18:12:21.150 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950ae8*
*2016/08/03 18:12:21.150 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950ae8*
*2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(178) lookup: id=0xa224638
query ARP table*
*2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(222) lookup: id=0xa224638
query ARP on each interface (128 found)*
*2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
found interface lo*
*2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
found interface eth2*
*2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(237) lookup: id=0xa224638
looking up ARP address for 10.40.40.110 on eth2*
*2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
found interface eth1*
*2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(237) lookup: id=0xa224638
looking up ARP address for 10.40.40.110 on eth1*
*2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(280) lookup: id=0xa224638 got
address 08:00:27:29:24:4a on eth1*
*2016/08/03 18:12:21.171 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
*2016/08/03 18:12:21.171 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
*2016/08/03 18:12:21.171 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
checking slow rules*
*2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rules)*
*2016/08/03 18:12:21.171 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/0is not banned*
*2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
localhostgreen*
*2016/08/03 18:12:21.171 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare:
10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
<http://10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]>
(10.40.40.110:35474 <http://10.40.40.110:35474>)  vs
10.40.40.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]*
*2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:35474 <http://10.40.40.110:35474>' NOT found*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
localhostgreen = 0*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 0*
*2016/08/03 18:12:21.172 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/3is not banned*
*2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
tls_s1_connect*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
tls_s1_connect = 1*
*2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking all*
*2016/08/03 18:12:21.172 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
<http://10.40.40.110:35474/[:>:] ([::]:35474)  vs [::]-[::]/[::]*
*2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:35474 <http://10.40.40.110:35474>' found*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 1*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rules) = 1*
*2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(63) markFinished:
0xa210ad8 answer ALLOWED for match*
*2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
*2016/08/03 18:12:21.172 kid1| 33,2| client_side.cc(3909)
httpsSslBumpAccessCheckDone: sslBump needed for local=98.138.253.109:443
<http://98.138.253.109:443> remote=10.40.40.110:35474
<http://10.40.40.110:35474> FD 18 flags=33 method 3*
*2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(70) preCheck: 0xa214d28
checking slow rules*
*2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
http_access*
*2016/08/03 18:12:21.172 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/0is not banned*
*2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
http_access#1*
*2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
SWE_subnets*
*2016/08/03 18:12:21.172 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare:
10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
<http://10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]>
(10.40.40.0:35474 <http://10.40.40.0:35474>)  vs
10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
*2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:35474 <http://10.40.40.110:35474>' found*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
SWE_subnets = 1*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
http_access#1 = 1*
*2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
http_access = 1*
*2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(63) markFinished:
0xa214d28 answer ALLOWED for match*
*2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0xa214d28 answer=ALLOWED*
*2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fc08*
*2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf94fc08*
*2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fd3c*
*2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf94fd3c*
*2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa214d28*
*2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa214d28*
*2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
*2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
*2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
checking slow rules*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rules)*
*2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/0 is  banned*
*2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/3is not banned*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
tls_s1_connect*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
tls_s1_connect = 0*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 0*
*2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/6is not banned*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
tls_s2_client_hello*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
tls_s2_client_hello = 1*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
tls_to_splice*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
tls_allowed_hsts*
*2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
'www.yahoo.com <http://www.yahoo.com>'*
*2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
aclHostDomainCompare: Match:www.yahoo.com <http://www.yahoo.com> <>
 .akamaihd.net <http://akamaihd.net>*
*2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match:
'www.yahoo.com <http://www.yahoo.com>' NOT found*
*2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
'none'*
*2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
aclHostDomainCompare: Match:none <>  .akamaihd.net <http://akamaihd.net>*
*2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
found*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
tls_allowed_hsts = 0*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
tls_server_is_bank*
*2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
'www.yahoo.com <http://www.yahoo.com>'*
*2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
aclHostDomainCompare: Match:www.yahoo.com <http://www.yahoo.com> <>
 .wellsfargo.com <http://wellsfargo.com>*
*2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match:
'www.yahoo.com <http://www.yahoo.com>' NOT found*
*2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
'none'*
*2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
aclHostDomainCompare: Match:none <>  .wellsfargo.com
<http://wellsfargo.com>*
*2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
found*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
tls_server_is_bank = 0*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
tls_to_splice = 0*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 0*
*2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'ALLOWED/4is not banned*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
(ssl_bump rule)*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
tls_s2_client_hello*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
tls_s2_client_hello = 1*
*2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking all*
*2016/08/03 18:12:21.173 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
<http://10.40.40.110:35474/[:>:] ([::]:35474)  vs [::]-[::]/[::]*
*2016/08/03 18:12:21.173 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:35474 <http://10.40.40.110:35474>' found*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rule) = 1*
*2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
(ssl_bump rules) = 1*
*2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(63) markFinished:
0xa210ad8 answer ALLOWED for match*
*2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
*2016/08/03 18:12:21.173 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf95080c*
*2016/08/03 18:12:21.173 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf95080c*
*2016/08/03 18:12:21.173 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
*2016/08/03 18:12:21.173 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
*2016/08/03 18:12:21.278 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
checking fast rules*
*2016/08/03 18:12:21.278 kid1| 28,5| Checklist.cc(346) fastCheck:
aclCheckFast: list: 0x9de0a80*
*2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking
sslproxy_cert_error*
*2016/08/03 18:12:21.278 kid1| 28,5| Checklist.cc(400) bannedAction: Action
'DENIED/0is not banned*
*2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking
sslproxy_cert_error#1*
*2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking all*
*2016/08/03 18:12:21.278 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
<http://10.40.40.110:35474/[:>:] ([::]:35474)  vs [::]-[::]/[::]*
*2016/08/03 18:12:21.278 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
'10.40.40.110:35474 <http://10.40.40.110:35474>' found*
*2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
*2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked:
sslproxy_cert_error#1 = 1*
*2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked:
sslproxy_cert_error = 1*
*2016/08/03 18:12:21.278 kid1| 28,3| Checklist.cc(63) markFinished:
0xa210ad8 answer DENIED for match*
*2016/08/03 18:12:21.278 kid1| Error negotiating SSL on FD 20:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)*
*2016/08/03 18:12:21.279 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950b68
checking fast ACLs*
*2016/08/03 18:12:21.279 kid1| 28,5| Acl.cc(138) matches: checking
cache_access_log stdio:/var/log/squid/access.log*
*2016/08/03 18:12:21.279 kid1| 28,5| Acl.cc(138) matches: checking
(cache_access_log stdio:/var/log/squid/access.log line)*
*2016/08/03 18:12:21.279 kid1| 28,3| Acl.cc(158) matches: checked:
(cache_access_log stdio:/var/log/squid/access.log line) = 1*
*2016/08/03 18:12:21.279 kid1| 28,3| Acl.cc(158) matches: checked:
cache_access_log stdio:/var/log/squid/access.log = 1*
*2016/08/03 18:12:21.279 kid1| 28,3| Checklist.cc(63) markFinished:
0xbf950b68 answer ALLOWED for match*
*2016/08/03 18:12:21.279 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950b68*
*2016/08/03 18:12:21.279 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950b68*
*2016/08/03 18:12:21.331 kid1| 33,2| client_side.cc(816) swanSong:
local=98.138.253.109:443 <http://98.138.253.109:443>
remote=10.40.40.110:35474 <http://10.40.40.110:35474> flags=33*
*2016/08/03 18:12:21.331 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950c28
checking fast ACLs*
*2016/08/03 18:12:21.331 kid1| 28,5| Acl.cc(138) matches: checking
cache_access_log stdio:/var/log/squid/access.log*
*2016/08/03 18:12:21.331 kid1| 28,5| Acl.cc(138) matches: checking
(cache_access_log stdio:/var/log/squid/access.log line)*
*2016/08/03 18:12:21.331 kid1| 28,3| Acl.cc(158) matches: checked:
(cache_access_log stdio:/var/log/squid/access.log line) = 1*
*2016/08/03 18:12:21.331 kid1| 28,3| Acl.cc(158) matches: checked:
cache_access_log stdio:/var/log/squid/access.log = 1*
*2016/08/03 18:12:21.331 kid1| 28,3| Checklist.cc(63) markFinished:
0xbf950c28 answer ALLOWED for match*
*2016/08/03 18:12:21.331 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950c28*
*2016/08/03 18:12:21.331 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xbf950c28*
*2016/08/03 18:12:21.331 kid1| 28,4| FilledChecklist.cc(66)
~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
*2016/08/03 18:12:21.331 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*


The web browser error says:
"Failed to establish a secure connection to (a yahoo.com IP address was
here)"
and another message of "(71) Protocol error (TLS code:
X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)"
and "Certificate issuer (CA) not known".

On Wed, Aug 3, 2016 at 4:12 PM, Stanford Prescott <stan.prescott at gmail.com>
wrote:

> Thanks for the info, Alex. That's very helpful about cleaning up my ACLs.
> Those ACLs are a collection of ACLs that others have suggested I use, but
> it would be nice to make them less confusing for me.
>
> With my limited understanding of how sslbump works, the idea for squid to
> play MITM is that a self-signed cert like squidCA.der is imported to a
> browser's root CAs. I have left a copy of the self-signed cert named
> squidCA.pem in the squid's cert directory which only works if squid is told
> to not verify the peer. When following the instructions how to generate the
> self-signed cert with openssl, the .pem file must be converted to a .der
> file for the browser to accept it. It just dawned on me that, could this be
> related to the fact that the squid self-signed certs are not named the same?
>
> On Wed, Aug 3, 2016 at 3:01 PM, Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
>
>> On 08/03/2016 08:45 AM, Stanford Prescott wrote:
>>
>> > ssl_bump none localhostgreen
>> > ssl_bump peek tls_s1_connect all
>> > ssl_bump splice tls_s2_client_hello tls_to_splice
>> > ssl_bump stare tls_s2_client_hello all
>> > ssl_bump bump tls_s3_server_hello all
>>
>> AFAICT, the above is too complex. You can simplify it with:
>>
>>   ssl_bump splice localhostgreen
>>   ssl_bump peek tls_s1_connect
>>   ssl_bump splice tls_to_splice
>>   ssl_bump stare all
>>   ssl_bump bump all
>>
>> and, after polishing your ACLs a little, possibly even with:
>>
>>   ssl_bump splice transactions_to_splice
>>   ssl_bump peek tls_s1_connect
>>   ssl_bump stare all
>>   ssl_bump bump all
>>
>> where transactions_to_splice is "localhostgreen or (tls_s2_client_hello
>> and tls_to_splice)".
>>
>>
>> As for your original question, I recommend figuring out why Squid cannot
>> verify the peer. For example, your setup might be missing fresh
>> certificates for some well-known Root CAs. I do not know a good way to
>> figure out why peer verification does not work, but analyzing cache.log
>> with high-enough debugging level should be doable, especially if you can
>> reproduce the problem using a single transaction:
>>
>>
>> http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160803/5875f69a/attachment.htm>

From bruce.rosenberg.au at gmail.com  Thu Aug  4 01:05:08 2016
From: bruce.rosenberg.au at gmail.com (Bruce Rosenberg)
Date: Thu, 4 Aug 2016 11:05:08 +1000
Subject: [squid-users] sslproxyflags DONT_VERIFY_PEER
In-Reply-To: <CANLNtGSqpbeTvr7bdQC15vcUwrCYe26USqxUpLQCEMAR3v7VJg@mail.gmail.com>
References: <CANLNtGRVZ-J=ZNGP_QeipFD0cvwupNV3mAZTo2vx-OkmFaFqRA@mail.gmail.com>
 <57A24DA4.5020901@measurement-factory.com>
 <CANLNtGTMwGReDXU9oWMx5aPDOH5RBKvMbMsH2dj3O5rN1OTuog@mail.gmail.com>
 <CANLNtGSqpbeTvr7bdQC15vcUwrCYe26USqxUpLQCEMAR3v7VJg@mail.gmail.com>
Message-ID: <CAHaxnUJAs7savtS-E-y907pvRxDfXB_r3qSTQ2zv87jGQ9i9Xg@mail.gmail.com>

It looks like you are missing the Verisign Class 3 Public Primary Root cert.
Notice the certificate chain list below.
Yahoo correctly send back all intermediate certificates in the TLS
handshake so the only certificate you need to make sure squid trusts (via
openssl) is the Verisign root.

You should be able to determine if the openssl client on the squid proxy
can verify the complete chain by running the following command on the proxy.
The important part is that at each step it outputs "verify return: 1"
meaning that the certificate at that depth in the chain was successfully
verified by it's issuing certificate i.e. the certificate at the previous
higher level depth that we have already established we trust.
The root certificate is automagically verified by virtue of being
explicitly trusted by your openssl.


$ openssl s_client -connect www.yahoo.com:443 </dev/null

                                    ?
CONNECTED(00000003)
depth=3 C = US, O = "VeriSign, Inc.", OU = Class 3 Public Primary
Certification Authority
verify return:1
depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU =
"(c) 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3
Public Primary Certification Authority - G5
verify return:1
depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, CN =
Symantec Class 3 Secure Server CA - G4
verify return:1
depth=0 C = US, ST = California, L = Sunnyvale, O = Yahoo Inc., OU =
Information Technology, CN = www.yahoo.com
verify return:1
---
Certificate chain
 0 s:/C=US/ST=California/L=Sunnyvale/O=Yahoo Inc./OU=Information
Technology/CN=www.yahoo.com
   i:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
Class 3 Secure Server CA - G4
 1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
Class 3 Secure Server CA - G4
   i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 VeriSign,
Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
Certification Authority - G5
 2 s:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 VeriSign,
Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
Certification Authority - G5
   i:/C=US/O=VeriSign, Inc./OU=Class 3 Public Primary Certification
Authority


On Thu, Aug 4, 2016 at 9:51 AM, Stanford Prescott <stan.prescott at gmail.com>
wrote:

> Okay, it's not a name of the cert problem.
>
> I turned on extra debug info to see what I get when I remove the
> DONT_VERIFY_PEER flag and tried accessing https://www.yahoo.com. This is
> what I got in the cache.log. I only see a couple of lines about a
> certificate error. Sorry this is long but I didn't know what to include so
> I just included everything for that one access attempt.
>
> *2016/08/03 18:12:16.701 kid1| 28,4| Eui48.cc(178) lookup: id=0xa2064b0
> query ARP table*
> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(222) lookup: id=0xa2064b0
> query ARP on each interface (128 found)*
> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
> found interface lo*
> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
> found interface eth2*
> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
> looking up ARP address for 10.40.40.110 on eth2*
> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
> found interface eth1*
> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
> looking up ARP address for 10.40.40.110 on eth1*
> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(280) lookup: id=0xa2064b0
> got address 08:00:27:29:24:4a on eth1*
> *2016/08/03 18:12:16.702 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
> *2016/08/03 18:12:16.702 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
> checking slow rules*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rules)*
> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/0is not banned*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
> localhostgreen*
> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare:
> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff%5D>
> (10.40.40.110:49732 <http://10.40.40.110:49732>)  vs
> 10.40.40.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]*
> *2016/08/03 18:12:16.702 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:49732 <http://10.40.40.110:49732>' NOT found*
> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
> localhostgreen = 0*
> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 0*
> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/3is not banned*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
> tls_s1_connect*
> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_s1_connect = 1*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking all*
> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
> *2016/08/03 18:12:16.702 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 1*
> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rules) = 1*
> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa210ad8 answer ALLOWED for match*
> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(163) checkCallback:
> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
> *2016/08/03 18:12:16.702 kid1| 33,2| client_side.cc(3909)
> httpsSslBumpAccessCheckDone: sslBump needed for local=52.34.245.108:443
> <http://52.34.245.108:443> remote=10.40.40.110:49732
> <http://10.40.40.110:49732> FD 14 flags=33 method 3*
> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(70) preCheck: 0xa214d28
> checking slow rules*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
> http_access*
> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/0is not banned*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
> http_access#1*
> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
> SWE_subnets*
> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare:
> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
> 192.168.192.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
> *2016/08/03 18:12:16.703 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare:
> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
> *2016/08/03 18:12:16.703 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare:
> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
> *2016/08/03 18:12:16.703 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
> SWE_subnets = 1*
> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
> http_access#1 = 1*
> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
> http_access = 1*
> *2016/08/03 18:12:16.703 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa214d28 answer ALLOWED for match*
> *2016/08/03 18:12:16.703 kid1| 28,3| Checklist.cc(163) checkCallback:
> ACLChecklist::checkCallback: 0xa214d28 answer=ALLOWED*
> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fc08*
> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf94fc08*
> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fd3c*
> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf94fd3c*
> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa214d28*
> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa214d28*
> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
> checking slow rules*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rules)*
> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/0 is  banned*
> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/3is not banned*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> tls_s1_connect*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_s1_connect = 0*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 0*
> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/6is not banned*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> tls_s2_client_hello*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_s2_client_hello = 1*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> tls_to_splice*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> tls_allowed_hsts*
> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>'*
> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
> aclHostDomainCompare: Match:tiles.services.mozilla.com
> <http://tiles.services.mozilla.com> <>  .akamaihd.net <http://akamaihd.net>*
> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match:
> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>' NOT found*
> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
> 'none'*
> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
> aclHostDomainCompare: Match:none <>  .akamaihd.net <http://akamaihd.net>*
> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
> found*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_allowed_hsts = 0*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> tls_server_is_bank*
> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>'*
> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
> aclHostDomainCompare: Match:tiles.services.mozilla.com
> <http://tiles.services.mozilla.com> <>  .wellsfargo.com
> <http://wellsfargo.com>*
> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match:
> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>' NOT found*
> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
> 'none'*
> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
> aclHostDomainCompare: Match:none <>  .wellsfargo.com
> <http://wellsfargo.com>*
> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
> found*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_server_is_bank = 0*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_to_splice = 0*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 0*
> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/4is not banned*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
> tls_s2_client_hello*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_s2_client_hello = 1*
> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking all*
> *2016/08/03 18:12:16.704 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
> *2016/08/03 18:12:16.704 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 1*
> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rules) = 1*
> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa210ad8 answer ALLOWED for match*
> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(163) checkCallback:
> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
> *2016/08/03 18:12:16.704 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf95080c*
> *2016/08/03 18:12:16.704 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf95080c*
> *2016/08/03 18:12:16.704 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
> *2016/08/03 18:12:16.704 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
> *2016/08/03 18:12:16.869 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
> checking fast rules*
> *2016/08/03 18:12:16.870 kid1| 28,5| Checklist.cc(346) fastCheck:
> aclCheckFast: list: 0x9de0a80*
> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking
> sslproxy_cert_error*
> *2016/08/03 18:12:16.870 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'DENIED/0is not banned*
> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking
> sslproxy_cert_error#1*
> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking all*
> *2016/08/03 18:12:16.870 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
> *2016/08/03 18:12:16.870 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked:
> sslproxy_cert_error#1 = 1*
> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked:
> sslproxy_cert_error = 1*
> *2016/08/03 18:12:16.870 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa210ad8 answer DENIED for match*
> *2016/08/03 18:12:16.870 kid1| Error negotiating SSL on FD 16:
> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
> failed (1/-1/0)*
> *2016/08/03 18:12:16.871 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950b68
> checking fast ACLs*
> *2016/08/03 18:12:16.871 kid1| 28,5| Acl.cc(138) matches: checking
> cache_access_log stdio:/var/log/squid/access.log*
> *2016/08/03 18:12:16.871 kid1| 28,5| Acl.cc(138) matches: checking
> (cache_access_log stdio:/var/log/squid/access.log line)*
> *2016/08/03 18:12:16.871 kid1| 28,3| Acl.cc(158) matches: checked:
> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
> *2016/08/03 18:12:16.871 kid1| 28,3| Acl.cc(158) matches: checked:
> cache_access_log stdio:/var/log/squid/access.log = 1*
> *2016/08/03 18:12:16.871 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xbf950b68 answer ALLOWED for match*
> *2016/08/03 18:12:16.871 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950b68*
> *2016/08/03 18:12:16.871 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950b68*
> *2016/08/03 18:12:16.998 kid1| 33,2| client_side.cc(816) swanSong:
> local=52.34.245.108:443 <http://52.34.245.108:443>
> remote=10.40.40.110:49732 <http://10.40.40.110:49732> flags=33*
> *2016/08/03 18:12:16.998 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950c28
> checking fast ACLs*
> *2016/08/03 18:12:16.998 kid1| 28,5| Acl.cc(138) matches: checking
> cache_access_log stdio:/var/log/squid/access.log*
> *2016/08/03 18:12:16.998 kid1| 28,5| Acl.cc(138) matches: checking
> (cache_access_log stdio:/var/log/squid/access.log line)*
> *2016/08/03 18:12:16.998 kid1| 28,3| Acl.cc(158) matches: checked:
> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
> *2016/08/03 18:12:16.998 kid1| 28,3| Acl.cc(158) matches: checked:
> cache_access_log stdio:/var/log/squid/access.log = 1*
> *2016/08/03 18:12:16.998 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xbf950c28 answer ALLOWED for match*
> *2016/08/03 18:12:16.998 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950c28*
> *2016/08/03 18:12:16.998 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950c28*
> *2016/08/03 18:12:16.998 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
> *2016/08/03 18:12:16.998 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(178) lookup: id=0xa2064b0
> query ARP table*
> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(222) lookup: id=0xa2064b0
> query ARP on each interface (128 found)*
> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
> found interface lo*
> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
> found interface eth2*
> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
> looking up ARP address for 10.40.40.110 on eth2*
> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
> found interface eth1*
> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
> looking up ARP address for 10.40.40.110 on eth1*
> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(280) lookup: id=0xa2064b0
> got address 08:00:27:29:24:4a on eth1*
> *2016/08/03 18:12:21.032 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
> *2016/08/03 18:12:21.032 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
> checking slow rules*
> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
> http_access*
> *2016/08/03 18:12:21.054 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/0is not banned*
> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
> http_access#1*
> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
> SWE_subnets*
> *2016/08/03 18:12:21.054 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare:
> 10.40.40.110:40595/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
> <http://10.40.40.110:40595/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
> (10.40.40.0:40595 <http://10.40.40.0:40595>)  vs
> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
> *2016/08/03 18:12:21.054 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:40595 <http://10.40.40.110:40595>' found*
> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
> SWE_subnets = 1*
> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
> http_access#1 = 1*
> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
> http_access = 1*
> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa210ad8 answer ALLOWED for match*
> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(163) checkCallback:
> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950198*
> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950198*
> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf9502cc*
> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf9502cc*
> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94f87c*
> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf94f87c*
> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
> *2016/08/03 18:12:21.101 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf9509dc*
> *2016/08/03 18:12:21.102 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf9509dc*
> *2016/08/03 18:12:21.150 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950ae8
> checking fast ACLs*
> *2016/08/03 18:12:21.150 kid1| 28,5| Acl.cc(138) matches: checking
> cache_access_log stdio:/var/log/squid/access.log*
> *2016/08/03 18:12:21.150 kid1| 28,5| Acl.cc(138) matches: checking
> (cache_access_log stdio:/var/log/squid/access.log line)*
> *2016/08/03 18:12:21.150 kid1| 28,3| Acl.cc(158) matches: checked:
> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
> *2016/08/03 18:12:21.150 kid1| 28,3| Acl.cc(158) matches: checked:
> cache_access_log stdio:/var/log/squid/access.log = 1*
> *2016/08/03 18:12:21.150 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xbf950ae8 answer ALLOWED for match*
> *2016/08/03 18:12:21.150 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950ae8*
> *2016/08/03 18:12:21.150 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950ae8*
> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(178) lookup: id=0xa224638
> query ARP table*
> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(222) lookup: id=0xa224638
> query ARP on each interface (128 found)*
> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
> found interface lo*
> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
> found interface eth2*
> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(237) lookup: id=0xa224638
> looking up ARP address for 10.40.40.110 on eth2*
> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
> found interface eth1*
> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(237) lookup: id=0xa224638
> looking up ARP address for 10.40.40.110 on eth1*
> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(280) lookup: id=0xa224638
> got address 08:00:27:29:24:4a on eth1*
> *2016/08/03 18:12:21.171 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
> *2016/08/03 18:12:21.171 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
> *2016/08/03 18:12:21.171 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
> checking slow rules*
> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rules)*
> *2016/08/03 18:12:21.171 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/0is not banned*
> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
> localhostgreen*
> *2016/08/03 18:12:21.171 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare:
> 10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
> <http://10.40.40.110:35474/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff%5D>
> (10.40.40.110:35474 <http://10.40.40.110:35474>)  vs
> 10.40.40.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]*
> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:35474 <http://10.40.40.110:35474>' NOT found*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
> localhostgreen = 0*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 0*
> *2016/08/03 18:12:21.172 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/3is not banned*
> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
> tls_s1_connect*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_s1_connect = 1*
> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking all*
> *2016/08/03 18:12:21.172 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 1*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rules) = 1*
> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa210ad8 answer ALLOWED for match*
> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(163) checkCallback:
> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
> *2016/08/03 18:12:21.172 kid1| 33,2| client_side.cc(3909)
> httpsSslBumpAccessCheckDone: sslBump needed for local=98.138.253.109:443
> <http://98.138.253.109:443> remote=10.40.40.110:35474
> <http://10.40.40.110:35474> FD 18 flags=33 method 3*
> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(70) preCheck: 0xa214d28
> checking slow rules*
> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
> http_access*
> *2016/08/03 18:12:21.172 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/0is not banned*
> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
> http_access#1*
> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
> SWE_subnets*
> *2016/08/03 18:12:21.172 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare:
> 10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
> <http://10.40.40.110:35474/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
> (10.40.40.0:35474 <http://10.40.40.0:35474>)  vs
> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
> SWE_subnets = 1*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
> http_access#1 = 1*
> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
> http_access = 1*
> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa214d28 answer ALLOWED for match*
> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(163) checkCallback:
> ACLChecklist::checkCallback: 0xa214d28 answer=ALLOWED*
> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fc08*
> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf94fc08*
> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fd3c*
> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf94fd3c*
> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa214d28*
> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa214d28*
> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
> checking slow rules*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rules)*
> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/0 is  banned*
> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/3is not banned*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> tls_s1_connect*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_s1_connect = 0*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 0*
> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/6is not banned*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> tls_s2_client_hello*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_s2_client_hello = 1*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> tls_to_splice*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> tls_allowed_hsts*
> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
> 'www.yahoo.com <http://www.yahoo.com>'*
> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
> aclHostDomainCompare: Match:www.yahoo.com <http://www.yahoo.com> <>
>  .akamaihd.net <http://akamaihd.net>*
> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match:
> 'www.yahoo.com <http://www.yahoo.com>' NOT found*
> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
> 'none'*
> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
> aclHostDomainCompare: Match:none <>  .akamaihd.net <http://akamaihd.net>*
> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
> found*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_allowed_hsts = 0*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> tls_server_is_bank*
> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
> 'www.yahoo.com <http://www.yahoo.com>'*
> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
> aclHostDomainCompare: Match:www.yahoo.com <http://www.yahoo.com> <>
>  .wellsfargo.com <http://wellsfargo.com>*
> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match:
> 'www.yahoo.com <http://www.yahoo.com>' NOT found*
> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
> 'none'*
> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
> aclHostDomainCompare: Match:none <>  .wellsfargo.com
> <http://wellsfargo.com>*
> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
> found*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_server_is_bank = 0*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_to_splice = 0*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 0*
> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'ALLOWED/4is not banned*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> (ssl_bump rule)*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
> tls_s2_client_hello*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> tls_s2_client_hello = 1*
> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking all*
> *2016/08/03 18:12:21.173 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
> *2016/08/03 18:12:21.173 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rule) = 1*
> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
> (ssl_bump rules) = 1*
> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa210ad8 answer ALLOWED for match*
> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(163) checkCallback:
> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
> *2016/08/03 18:12:21.173 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf95080c*
> *2016/08/03 18:12:21.173 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf95080c*
> *2016/08/03 18:12:21.173 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
> *2016/08/03 18:12:21.173 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
> *2016/08/03 18:12:21.278 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
> checking fast rules*
> *2016/08/03 18:12:21.278 kid1| 28,5| Checklist.cc(346) fastCheck:
> aclCheckFast: list: 0x9de0a80*
> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking
> sslproxy_cert_error*
> *2016/08/03 18:12:21.278 kid1| 28,5| Checklist.cc(400) bannedAction:
> Action 'DENIED/0is not banned*
> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking
> sslproxy_cert_error#1*
> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking all*
> *2016/08/03 18:12:21.278 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
> *2016/08/03 18:12:21.278 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked: all = 1*
> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked:
> sslproxy_cert_error#1 = 1*
> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked:
> sslproxy_cert_error = 1*
> *2016/08/03 18:12:21.278 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xa210ad8 answer DENIED for match*
> *2016/08/03 18:12:21.278 kid1| Error negotiating SSL on FD 20:
> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
> failed (1/-1/0)*
> *2016/08/03 18:12:21.279 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950b68
> checking fast ACLs*
> *2016/08/03 18:12:21.279 kid1| 28,5| Acl.cc(138) matches: checking
> cache_access_log stdio:/var/log/squid/access.log*
> *2016/08/03 18:12:21.279 kid1| 28,5| Acl.cc(138) matches: checking
> (cache_access_log stdio:/var/log/squid/access.log line)*
> *2016/08/03 18:12:21.279 kid1| 28,3| Acl.cc(158) matches: checked:
> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
> *2016/08/03 18:12:21.279 kid1| 28,3| Acl.cc(158) matches: checked:
> cache_access_log stdio:/var/log/squid/access.log = 1*
> *2016/08/03 18:12:21.279 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xbf950b68 answer ALLOWED for match*
> *2016/08/03 18:12:21.279 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950b68*
> *2016/08/03 18:12:21.279 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950b68*
> *2016/08/03 18:12:21.331 kid1| 33,2| client_side.cc(816) swanSong:
> local=98.138.253.109:443 <http://98.138.253.109:443>
> remote=10.40.40.110:35474 <http://10.40.40.110:35474> flags=33*
> *2016/08/03 18:12:21.331 kid1| 28,3| Checklist.cc(70) preCheck: 0xbf950c28
> checking fast ACLs*
> *2016/08/03 18:12:21.331 kid1| 28,5| Acl.cc(138) matches: checking
> cache_access_log stdio:/var/log/squid/access.log*
> *2016/08/03 18:12:21.331 kid1| 28,5| Acl.cc(138) matches: checking
> (cache_access_log stdio:/var/log/squid/access.log line)*
> *2016/08/03 18:12:21.331 kid1| 28,3| Acl.cc(158) matches: checked:
> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
> *2016/08/03 18:12:21.331 kid1| 28,3| Acl.cc(158) matches: checked:
> cache_access_log stdio:/var/log/squid/access.log = 1*
> *2016/08/03 18:12:21.331 kid1| 28,3| Checklist.cc(63) markFinished:
> 0xbf950c28 answer ALLOWED for match*
> *2016/08/03 18:12:21.331 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950c28*
> *2016/08/03 18:12:21.331 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xbf950c28*
> *2016/08/03 18:12:21.331 kid1| 28,4| FilledChecklist.cc(66)
> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
> *2016/08/03 18:12:21.331 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>
>
> The web browser error says:
> "Failed to establish a secure connection to (a yahoo.com IP address was
> here)"
> and another message of "(71) Protocol error (TLS code:
> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)"
> and "Certificate issuer (CA) not known".
>
> On Wed, Aug 3, 2016 at 4:12 PM, Stanford Prescott <stan.prescott at gmail.com
> > wrote:
>
>> Thanks for the info, Alex. That's very helpful about cleaning up my ACLs.
>> Those ACLs are a collection of ACLs that others have suggested I use, but
>> it would be nice to make them less confusing for me.
>>
>> With my limited understanding of how sslbump works, the idea for squid to
>> play MITM is that a self-signed cert like squidCA.der is imported to a
>> browser's root CAs. I have left a copy of the self-signed cert named
>> squidCA.pem in the squid's cert directory which only works if squid is told
>> to not verify the peer. When following the instructions how to generate the
>> self-signed cert with openssl, the .pem file must be converted to a .der
>> file for the browser to accept it. It just dawned on me that, could this be
>> related to the fact that the squid self-signed certs are not named the same?
>>
>> On Wed, Aug 3, 2016 at 3:01 PM, Alex Rousskov <
>> rousskov at measurement-factory.com> wrote:
>>
>>> On 08/03/2016 08:45 AM, Stanford Prescott wrote:
>>>
>>> > ssl_bump none localhostgreen
>>> > ssl_bump peek tls_s1_connect all
>>> > ssl_bump splice tls_s2_client_hello tls_to_splice
>>> > ssl_bump stare tls_s2_client_hello all
>>> > ssl_bump bump tls_s3_server_hello all
>>>
>>> AFAICT, the above is too complex. You can simplify it with:
>>>
>>>   ssl_bump splice localhostgreen
>>>   ssl_bump peek tls_s1_connect
>>>   ssl_bump splice tls_to_splice
>>>   ssl_bump stare all
>>>   ssl_bump bump all
>>>
>>> and, after polishing your ACLs a little, possibly even with:
>>>
>>>   ssl_bump splice transactions_to_splice
>>>   ssl_bump peek tls_s1_connect
>>>   ssl_bump stare all
>>>   ssl_bump bump all
>>>
>>> where transactions_to_splice is "localhostgreen or (tls_s2_client_hello
>>> and tls_to_splice)".
>>>
>>>
>>> As for your original question, I recommend figuring out why Squid cannot
>>> verify the peer. For example, your setup might be missing fresh
>>> certificates for some well-known Root CAs. I do not know a good way to
>>> figure out why peer verification does not work, but analyzing cache.log
>>> with high-enough debugging level should be doable, especially if you can
>>> reproduce the problem using a single transaction:
>>>
>>>
>>> http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>>>
>>>
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160804/a6bc1991/attachment.htm>

From stan.prescott at gmail.com  Thu Aug  4 02:29:54 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Wed, 3 Aug 2016 21:29:54 -0500
Subject: [squid-users] sslproxyflags DONT_VERIFY_PEER
In-Reply-To: <CAHaxnUJAs7savtS-E-y907pvRxDfXB_r3qSTQ2zv87jGQ9i9Xg@mail.gmail.com>
References: <CANLNtGRVZ-J=ZNGP_QeipFD0cvwupNV3mAZTo2vx-OkmFaFqRA@mail.gmail.com>
 <57A24DA4.5020901@measurement-factory.com>
 <CANLNtGTMwGReDXU9oWMx5aPDOH5RBKvMbMsH2dj3O5rN1OTuog@mail.gmail.com>
 <CANLNtGSqpbeTvr7bdQC15vcUwrCYe26USqxUpLQCEMAR3v7VJg@mail.gmail.com>
 <CAHaxnUJAs7savtS-E-y907pvRxDfXB_r3qSTQ2zv87jGQ9i9Xg@mail.gmail.com>
Message-ID: <CANLNtGQmArkGrWLtyFR9rgw1yqNbWJ4jJRw29VYueQj3J+80Zg@mail.gmail.com>

That would explain the error if the Verisign Class 3 public root CA were
missing. However, our Smoothwall Express OS has all the standard root CAs
package found in /usr/ssl/certs. Do I need to tell squid where to find
those certs? If so, what config directive would I use for that?

Thanks!

On Wed, Aug 3, 2016 at 8:05 PM, Bruce Rosenberg <
bruce.rosenberg.au at gmail.com> wrote:

> It looks like you are missing the Verisign Class 3 Public Primary Root
> cert.
> Notice the certificate chain list below.
> Yahoo correctly send back all intermediate certificates in the TLS
> handshake so the only certificate you need to make sure squid trusts (via
> openssl) is the Verisign root.
>
> You should be able to determine if the openssl client on the squid proxy
> can verify the complete chain by running the following command on the proxy.
> The important part is that at each step it outputs "verify return: 1"
> meaning that the certificate at that depth in the chain was successfully
> verified by it's issuing certificate i.e. the certificate at the previous
> higher level depth that we have already established we trust.
> The root certificate is automagically verified by virtue of being
> explicitly trusted by your openssl.
>
>
> $ openssl s_client -connect www.yahoo.com:443 </dev/null
>
>                                       ?
> CONNECTED(00000003)
> depth=3 C = US, O = "VeriSign, Inc.", OU = Class 3 Public Primary
> Certification Authority
> verify return:1
> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU =
> "(c) 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3
> Public Primary Certification Authority - G5
> verify return:1
> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, CN
> = Symantec Class 3 Secure Server CA - G4
> verify return:1
> depth=0 C = US, ST = California, L = Sunnyvale, O = Yahoo Inc., OU =
> Information Technology, CN = www.yahoo.com
> verify return:1
> ---
> Certificate chain
>  0 s:/C=US/ST=California/L=Sunnyvale/O=Yahoo Inc./OU=Information
> Technology/CN=www.yahoo.com
>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
> Class 3 Secure Server CA - G4
>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
> Class 3 Secure Server CA - G4
>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006
> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
> Certification Authority - G5
>  2 s:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006
> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
> Certification Authority - G5
>    i:/C=US/O=VeriSign, Inc./OU=Class 3 Public Primary Certification
> Authority
>
>
> On Thu, Aug 4, 2016 at 9:51 AM, Stanford Prescott <stan.prescott at gmail.com
> > wrote:
>
>> Okay, it's not a name of the cert problem.
>>
>> I turned on extra debug info to see what I get when I remove the
>> DONT_VERIFY_PEER flag and tried accessing https://www.yahoo.com. This is
>> what I got in the cache.log. I only see a couple of lines about a
>> certificate error. Sorry this is long but I didn't know what to include so
>> I just included everything for that one access attempt.
>>
>> *2016/08/03 18:12:16.701 kid1| 28,4| Eui48.cc(178) lookup: id=0xa2064b0
>> query ARP table*
>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(222) lookup: id=0xa2064b0
>> query ARP on each interface (128 found)*
>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>> found interface lo*
>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>> found interface eth2*
>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
>> looking up ARP address for 10.40.40.110 on eth2*
>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>> found interface eth1*
>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
>> looking up ARP address for 10.40.40.110 on eth1*
>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(280) lookup: id=0xa2064b0
>> got address 08:00:27:29:24:4a on eth1*
>> *2016/08/03 18:12:16.702 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
>> *2016/08/03 18:12:16.702 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
>> checking slow rules*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rules)*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/0is not banned*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>> localhostgreen*
>> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare:
>> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
>> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff%5D>
>> (10.40.40.110:49732 <http://10.40.40.110:49732>)  vs
>> 10.40.40.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:49732 <http://10.40.40.110:49732>' NOT found*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>> localhostgreen = 0*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 0*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/3is not banned*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_s1_connect*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_s1_connect = 1*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking all*
>> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
>> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked: all =
>> 1*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 1*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rules) = 1*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa210ad8 answer ALLOWED for match*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(163) checkCallback:
>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>> *2016/08/03 18:12:16.702 kid1| 33,2| client_side.cc(3909)
>> httpsSslBumpAccessCheckDone: sslBump needed for local=52.34.245.108:443
>> <http://52.34.245.108:443> remote=10.40.40.110:49732
>> <http://10.40.40.110:49732> FD 14 flags=33 method 3*
>> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(70) preCheck: 0xa214d28
>> checking slow rules*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>> http_access*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/0is not banned*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>> http_access#1*
>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>> SWE_subnets*
>> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare:
>> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
>> 192.168.192.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>> *2016/08/03 18:12:16.703 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare:
>> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
>> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>> *2016/08/03 18:12:16.703 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare:
>> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
>> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>> *2016/08/03 18:12:16.703 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
>> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
>> SWE_subnets = 1*
>> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
>> http_access#1 = 1*
>> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
>> http_access = 1*
>> *2016/08/03 18:12:16.703 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa214d28 answer ALLOWED for match*
>> *2016/08/03 18:12:16.703 kid1| 28,3| Checklist.cc(163) checkCallback:
>> ACLChecklist::checkCallback: 0xa214d28 answer=ALLOWED*
>> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fc08*
>> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf94fc08*
>> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fd3c*
>> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf94fd3c*
>> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa214d28*
>> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa214d28*
>> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
>> checking slow rules*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rules)*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/0 is  banned*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/3is not banned*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_s1_connect*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_s1_connect = 0*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 0*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/6is not banned*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_s2_client_hello*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_s2_client_hello = 1*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_to_splice*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_allowed_hsts*
>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
>> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>'*
>> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
>> aclHostDomainCompare: Match:tiles.services.mozilla.com
>> <http://tiles.services.mozilla.com> <>  .akamaihd.net <http://akamaihd.net>*
>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match:
>> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>' NOT found*
>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
>> 'none'*
>> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
>> aclHostDomainCompare: Match:none <>  .akamaihd.net <http://akamaihd.net>*
>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
>> found*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_allowed_hsts = 0*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_server_is_bank*
>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
>> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>'*
>> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
>> aclHostDomainCompare: Match:tiles.services.mozilla.com
>> <http://tiles.services.mozilla.com> <>  .wellsfargo.com
>> <http://wellsfargo.com>*
>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match:
>> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>' NOT found*
>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
>> 'none'*
>> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
>> aclHostDomainCompare: Match:none <>  .wellsfargo.com
>> <http://wellsfargo.com>*
>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
>> found*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_server_is_bank = 0*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_to_splice = 0*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 0*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/4is not banned*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_s2_client_hello*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_s2_client_hello = 1*
>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking all*
>> *2016/08/03 18:12:16.704 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
>> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked: all =
>> 1*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 1*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rules) = 1*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa210ad8 answer ALLOWED for match*
>> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(163) checkCallback:
>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>> *2016/08/03 18:12:16.704 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf95080c*
>> *2016/08/03 18:12:16.704 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf95080c*
>> *2016/08/03 18:12:16.704 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>> *2016/08/03 18:12:16.704 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>> *2016/08/03 18:12:16.869 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
>> checking fast rules*
>> *2016/08/03 18:12:16.870 kid1| 28,5| Checklist.cc(346) fastCheck:
>> aclCheckFast: list: 0x9de0a80*
>> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking
>> sslproxy_cert_error*
>> *2016/08/03 18:12:16.870 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'DENIED/0is not banned*
>> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking
>> sslproxy_cert_error#1*
>> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking all*
>> *2016/08/03 18:12:16.870 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
>> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
>> *2016/08/03 18:12:16.870 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
>> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked: all =
>> 1*
>> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked:
>> sslproxy_cert_error#1 = 1*
>> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked:
>> sslproxy_cert_error = 1*
>> *2016/08/03 18:12:16.870 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa210ad8 answer DENIED for match*
>> *2016/08/03 18:12:16.870 kid1| Error negotiating SSL on FD 16:
>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
>> failed (1/-1/0)*
>> *2016/08/03 18:12:16.871 kid1| 28,3| Checklist.cc(70) preCheck:
>> 0xbf950b68 checking fast ACLs*
>> *2016/08/03 18:12:16.871 kid1| 28,5| Acl.cc(138) matches: checking
>> cache_access_log stdio:/var/log/squid/access.log*
>> *2016/08/03 18:12:16.871 kid1| 28,5| Acl.cc(138) matches: checking
>> (cache_access_log stdio:/var/log/squid/access.log line)*
>> *2016/08/03 18:12:16.871 kid1| 28,3| Acl.cc(158) matches: checked:
>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>> *2016/08/03 18:12:16.871 kid1| 28,3| Acl.cc(158) matches: checked:
>> cache_access_log stdio:/var/log/squid/access.log = 1*
>> *2016/08/03 18:12:16.871 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xbf950b68 answer ALLOWED for match*
>> *2016/08/03 18:12:16.871 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950b68*
>> *2016/08/03 18:12:16.871 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950b68*
>> *2016/08/03 18:12:16.998 kid1| 33,2| client_side.cc(816) swanSong:
>> local=52.34.245.108:443 <http://52.34.245.108:443>
>> remote=10.40.40.110:49732 <http://10.40.40.110:49732> flags=33*
>> *2016/08/03 18:12:16.998 kid1| 28,3| Checklist.cc(70) preCheck:
>> 0xbf950c28 checking fast ACLs*
>> *2016/08/03 18:12:16.998 kid1| 28,5| Acl.cc(138) matches: checking
>> cache_access_log stdio:/var/log/squid/access.log*
>> *2016/08/03 18:12:16.998 kid1| 28,5| Acl.cc(138) matches: checking
>> (cache_access_log stdio:/var/log/squid/access.log line)*
>> *2016/08/03 18:12:16.998 kid1| 28,3| Acl.cc(158) matches: checked:
>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>> *2016/08/03 18:12:16.998 kid1| 28,3| Acl.cc(158) matches: checked:
>> cache_access_log stdio:/var/log/squid/access.log = 1*
>> *2016/08/03 18:12:16.998 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xbf950c28 answer ALLOWED for match*
>> *2016/08/03 18:12:16.998 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950c28*
>> *2016/08/03 18:12:16.998 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950c28*
>> *2016/08/03 18:12:16.998 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>> *2016/08/03 18:12:16.998 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(178) lookup: id=0xa2064b0
>> query ARP table*
>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(222) lookup: id=0xa2064b0
>> query ARP on each interface (128 found)*
>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>> found interface lo*
>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>> found interface eth2*
>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
>> looking up ARP address for 10.40.40.110 on eth2*
>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>> found interface eth1*
>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
>> looking up ARP address for 10.40.40.110 on eth1*
>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(280) lookup: id=0xa2064b0
>> got address 08:00:27:29:24:4a on eth1*
>> *2016/08/03 18:12:21.032 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
>> *2016/08/03 18:12:21.032 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
>> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
>> checking slow rules*
>> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
>> http_access*
>> *2016/08/03 18:12:21.054 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/0is not banned*
>> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
>> http_access#1*
>> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
>> SWE_subnets*
>> *2016/08/03 18:12:21.054 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare:
>> 10.40.40.110:40595/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>> <http://10.40.40.110:40595/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>> (10.40.40.0:40595 <http://10.40.40.0:40595>)  vs
>> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>> *2016/08/03 18:12:21.054 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:40595 <http://10.40.40.110:40595>' found*
>> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
>> SWE_subnets = 1*
>> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
>> http_access#1 = 1*
>> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
>> http_access = 1*
>> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa210ad8 answer ALLOWED for match*
>> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(163) checkCallback:
>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950198*
>> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950198*
>> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf9502cc*
>> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf9502cc*
>> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94f87c*
>> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf94f87c*
>> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>> *2016/08/03 18:12:21.101 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf9509dc*
>> *2016/08/03 18:12:21.102 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf9509dc*
>> *2016/08/03 18:12:21.150 kid1| 28,3| Checklist.cc(70) preCheck:
>> 0xbf950ae8 checking fast ACLs*
>> *2016/08/03 18:12:21.150 kid1| 28,5| Acl.cc(138) matches: checking
>> cache_access_log stdio:/var/log/squid/access.log*
>> *2016/08/03 18:12:21.150 kid1| 28,5| Acl.cc(138) matches: checking
>> (cache_access_log stdio:/var/log/squid/access.log line)*
>> *2016/08/03 18:12:21.150 kid1| 28,3| Acl.cc(158) matches: checked:
>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>> *2016/08/03 18:12:21.150 kid1| 28,3| Acl.cc(158) matches: checked:
>> cache_access_log stdio:/var/log/squid/access.log = 1*
>> *2016/08/03 18:12:21.150 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xbf950ae8 answer ALLOWED for match*
>> *2016/08/03 18:12:21.150 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950ae8*
>> *2016/08/03 18:12:21.150 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950ae8*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(178) lookup: id=0xa224638
>> query ARP table*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(222) lookup: id=0xa224638
>> query ARP on each interface (128 found)*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
>> found interface lo*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
>> found interface eth2*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(237) lookup: id=0xa224638
>> looking up ARP address for 10.40.40.110 on eth2*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
>> found interface eth1*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(237) lookup: id=0xa224638
>> looking up ARP address for 10.40.40.110 on eth1*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(280) lookup: id=0xa224638
>> got address 08:00:27:29:24:4a on eth1*
>> *2016/08/03 18:12:21.171 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
>> *2016/08/03 18:12:21.171 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
>> *2016/08/03 18:12:21.171 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
>> checking slow rules*
>> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rules)*
>> *2016/08/03 18:12:21.171 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/0is not banned*
>> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
>> localhostgreen*
>> *2016/08/03 18:12:21.171 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare:
>> 10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
>> <http://10.40.40.110:35474/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff%5D>
>> (10.40.40.110:35474 <http://10.40.40.110:35474>)  vs
>> 10.40.40.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:35474 <http://10.40.40.110:35474>' NOT found*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>> localhostgreen = 0*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 0*
>> *2016/08/03 18:12:21.172 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/3is not banned*
>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_s1_connect*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_s1_connect = 1*
>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking all*
>> *2016/08/03 18:12:21.172 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
>> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked: all =
>> 1*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 1*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rules) = 1*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa210ad8 answer ALLOWED for match*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(163) checkCallback:
>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>> *2016/08/03 18:12:21.172 kid1| 33,2| client_side.cc(3909)
>> httpsSslBumpAccessCheckDone: sslBump needed for local=98.138.253.109:443
>> <http://98.138.253.109:443> remote=10.40.40.110:35474
>> <http://10.40.40.110:35474> FD 18 flags=33 method 3*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(70) preCheck: 0xa214d28
>> checking slow rules*
>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>> http_access*
>> *2016/08/03 18:12:21.172 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/0is not banned*
>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>> http_access#1*
>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>> SWE_subnets*
>> *2016/08/03 18:12:21.172 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare:
>> 10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>> <http://10.40.40.110:35474/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>> (10.40.40.0:35474 <http://10.40.40.0:35474>)  vs
>> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>> SWE_subnets = 1*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>> http_access#1 = 1*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>> http_access = 1*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa214d28 answer ALLOWED for match*
>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(163) checkCallback:
>> ACLChecklist::checkCallback: 0xa214d28 answer=ALLOWED*
>> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fc08*
>> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf94fc08*
>> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fd3c*
>> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf94fd3c*
>> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa214d28*
>> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa214d28*
>> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
>> checking slow rules*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rules)*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/0 is  banned*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/3is not banned*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_s1_connect*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_s1_connect = 0*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 0*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/6is not banned*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_s2_client_hello*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_s2_client_hello = 1*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_to_splice*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_allowed_hsts*
>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
>> 'www.yahoo.com <http://www.yahoo.com>'*
>> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
>> aclHostDomainCompare: Match:www.yahoo.com <http://www.yahoo.com> <>
>>  .akamaihd.net <http://akamaihd.net>*
>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match:
>> 'www.yahoo.com <http://www.yahoo.com>' NOT found*
>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
>> 'none'*
>> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
>> aclHostDomainCompare: Match:none <>  .akamaihd.net <http://akamaihd.net>*
>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
>> found*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_allowed_hsts = 0*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_server_is_bank*
>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
>> 'www.yahoo.com <http://www.yahoo.com>'*
>> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
>> aclHostDomainCompare: Match:www.yahoo.com <http://www.yahoo.com> <>
>>  .wellsfargo.com <http://wellsfargo.com>*
>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match:
>> 'www.yahoo.com <http://www.yahoo.com>' NOT found*
>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
>> 'none'*
>> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
>> aclHostDomainCompare: Match:none <>  .wellsfargo.com
>> <http://wellsfargo.com>*
>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
>> found*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_server_is_bank = 0*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_to_splice = 0*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 0*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'ALLOWED/4is not banned*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> (ssl_bump rule)*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>> tls_s2_client_hello*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> tls_s2_client_hello = 1*
>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking all*
>> *2016/08/03 18:12:21.173 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
>> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked: all =
>> 1*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rule) = 1*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>> (ssl_bump rules) = 1*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa210ad8 answer ALLOWED for match*
>> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(163) checkCallback:
>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>> *2016/08/03 18:12:21.173 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf95080c*
>> *2016/08/03 18:12:21.173 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf95080c*
>> *2016/08/03 18:12:21.173 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>> *2016/08/03 18:12:21.173 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>> *2016/08/03 18:12:21.278 kid1| 28,3| Checklist.cc(70) preCheck: 0xa210ad8
>> checking fast rules*
>> *2016/08/03 18:12:21.278 kid1| 28,5| Checklist.cc(346) fastCheck:
>> aclCheckFast: list: 0x9de0a80*
>> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking
>> sslproxy_cert_error*
>> *2016/08/03 18:12:21.278 kid1| 28,5| Checklist.cc(400) bannedAction:
>> Action 'DENIED/0is not banned*
>> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking
>> sslproxy_cert_error#1*
>> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking all*
>> *2016/08/03 18:12:21.278 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
>> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
>> *2016/08/03 18:12:21.278 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
>> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked: all =
>> 1*
>> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked:
>> sslproxy_cert_error#1 = 1*
>> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked:
>> sslproxy_cert_error = 1*
>> *2016/08/03 18:12:21.278 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xa210ad8 answer DENIED for match*
>> *2016/08/03 18:12:21.278 kid1| Error negotiating SSL on FD 20:
>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
>> failed (1/-1/0)*
>> *2016/08/03 18:12:21.279 kid1| 28,3| Checklist.cc(70) preCheck:
>> 0xbf950b68 checking fast ACLs*
>> *2016/08/03 18:12:21.279 kid1| 28,5| Acl.cc(138) matches: checking
>> cache_access_log stdio:/var/log/squid/access.log*
>> *2016/08/03 18:12:21.279 kid1| 28,5| Acl.cc(138) matches: checking
>> (cache_access_log stdio:/var/log/squid/access.log line)*
>> *2016/08/03 18:12:21.279 kid1| 28,3| Acl.cc(158) matches: checked:
>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>> *2016/08/03 18:12:21.279 kid1| 28,3| Acl.cc(158) matches: checked:
>> cache_access_log stdio:/var/log/squid/access.log = 1*
>> *2016/08/03 18:12:21.279 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xbf950b68 answer ALLOWED for match*
>> *2016/08/03 18:12:21.279 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950b68*
>> *2016/08/03 18:12:21.279 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950b68*
>> *2016/08/03 18:12:21.331 kid1| 33,2| client_side.cc(816) swanSong:
>> local=98.138.253.109:443 <http://98.138.253.109:443>
>> remote=10.40.40.110:35474 <http://10.40.40.110:35474> flags=33*
>> *2016/08/03 18:12:21.331 kid1| 28,3| Checklist.cc(70) preCheck:
>> 0xbf950c28 checking fast ACLs*
>> *2016/08/03 18:12:21.331 kid1| 28,5| Acl.cc(138) matches: checking
>> cache_access_log stdio:/var/log/squid/access.log*
>> *2016/08/03 18:12:21.331 kid1| 28,5| Acl.cc(138) matches: checking
>> (cache_access_log stdio:/var/log/squid/access.log line)*
>> *2016/08/03 18:12:21.331 kid1| 28,3| Acl.cc(158) matches: checked:
>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>> *2016/08/03 18:12:21.331 kid1| 28,3| Acl.cc(158) matches: checked:
>> cache_access_log stdio:/var/log/squid/access.log = 1*
>> *2016/08/03 18:12:21.331 kid1| 28,3| Checklist.cc(63) markFinished:
>> 0xbf950c28 answer ALLOWED for match*
>> *2016/08/03 18:12:21.331 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950c28*
>> *2016/08/03 18:12:21.331 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xbf950c28*
>> *2016/08/03 18:12:21.331 kid1| 28,4| FilledChecklist.cc(66)
>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>> *2016/08/03 18:12:21.331 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>>
>>
>> The web browser error says:
>> "Failed to establish a secure connection to (a yahoo.com IP address was
>> here)"
>> and another message of "(71) Protocol error (TLS code:
>> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)"
>> and "Certificate issuer (CA) not known".
>>
>> On Wed, Aug 3, 2016 at 4:12 PM, Stanford Prescott <
>> stan.prescott at gmail.com> wrote:
>>
>>> Thanks for the info, Alex. That's very helpful about cleaning up my
>>> ACLs. Those ACLs are a collection of ACLs that others have suggested I use,
>>> but it would be nice to make them less confusing for me.
>>>
>>> With my limited understanding of how sslbump works, the idea for squid
>>> to play MITM is that a self-signed cert like squidCA.der is imported to a
>>> browser's root CAs. I have left a copy of the self-signed cert named
>>> squidCA.pem in the squid's cert directory which only works if squid is told
>>> to not verify the peer. When following the instructions how to generate the
>>> self-signed cert with openssl, the .pem file must be converted to a .der
>>> file for the browser to accept it. It just dawned on me that, could this be
>>> related to the fact that the squid self-signed certs are not named the same?
>>>
>>> On Wed, Aug 3, 2016 at 3:01 PM, Alex Rousskov <
>>> rousskov at measurement-factory.com> wrote:
>>>
>>>> On 08/03/2016 08:45 AM, Stanford Prescott wrote:
>>>>
>>>> > ssl_bump none localhostgreen
>>>> > ssl_bump peek tls_s1_connect all
>>>> > ssl_bump splice tls_s2_client_hello tls_to_splice
>>>> > ssl_bump stare tls_s2_client_hello all
>>>> > ssl_bump bump tls_s3_server_hello all
>>>>
>>>> AFAICT, the above is too complex. You can simplify it with:
>>>>
>>>>   ssl_bump splice localhostgreen
>>>>   ssl_bump peek tls_s1_connect
>>>>   ssl_bump splice tls_to_splice
>>>>   ssl_bump stare all
>>>>   ssl_bump bump all
>>>>
>>>> and, after polishing your ACLs a little, possibly even with:
>>>>
>>>>   ssl_bump splice transactions_to_splice
>>>>   ssl_bump peek tls_s1_connect
>>>>   ssl_bump stare all
>>>>   ssl_bump bump all
>>>>
>>>> where transactions_to_splice is "localhostgreen or (tls_s2_client_hello
>>>> and tls_to_splice)".
>>>>
>>>>
>>>> As for your original question, I recommend figuring out why Squid cannot
>>>> verify the peer. For example, your setup might be missing fresh
>>>> certificates for some well-known Root CAs. I do not know a good way to
>>>> figure out why peer verification does not work, but analyzing cache.log
>>>> with high-enough debugging level should be doable, especially if you can
>>>> reproduce the problem using a single transaction:
>>>>
>>>>
>>>> http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>>>
>>>>
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160803/5bd2ba17/attachment.htm>

From jr at jrssite.com  Thu Aug  4 02:45:56 2016
From: jr at jrssite.com (JR Dalrymple)
Date: Thu, 04 Aug 2016 02:45:56 +0000
Subject: [squid-users] SSLBump just not working
In-Reply-To: <57A1FC17.2050700@measurement-factory.com>
References: <CABs_asnhvDtviza-Ew-Fuj2==dezjjq-FLphFWesOASHFeF=FA@mail.gmail.com>
 <c9467f58-6dda-edc1-1698-8534a3c9b053@treenet.co.nz>
 <57A1FC17.2050700@measurement-factory.com>
Message-ID: <CABs_asmxA5cbCH6gYbXxn=nqRG3PzxNKMe7rHdTovgdU0pgfPw@mail.gmail.com>

On Wed, Aug 3, 2016 at 9:14 AM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 08/02/2016 09:53 PM, Amos Jeffries wrote:
>
> > To do bumping with server certificate mimic you need the 'bump' action
> > to occur at #3.
>

Thanks for the clarification. I probably read that 100 times in the
documentation but it didn't really sink in until today how that all works.
To be brutally honest the whole concept is still a bit lost on me, but I
can make sense that you have to perform the SNI CONNECT bits before you can
actually bump. My apologies for the earlier misunderstanding...


> >
> > Like:
> >  acl step1 at_step SslBump1
> >  acl step2 at_step SslBump2
> >  ssl_bump peek step1
> >  ssl_bump stare step2
> >  ssl_bump bump all
> >
> > (or maybe stare and both non-3 steps. I'm not 100% certain there.).
>
>
> Yes, all of the above can be polished and simplified to become just two
> lines:
>
>   ssl_bump stare all
>   ssl_bump bump all
>

I'm still having issues I'm afraid - albeit different issues. My problem
now reads a lot like this guys issue:

https://www.mail-archive.com/misc at openbsd.org/msg144692.html

I did however perform the step he did to rectify his issue and it's not
having any effect for me I'm afraid. My browser just times out and no
auto-generated certificate is ever generated. I've combed through a number
of configurations on the Internet at this point and I'm not seeing how mine
is terribly different from anyone else's who is having success. For the
sake of completeness I'll post my configuration as it stands today:

 # grep -v ^[\s]*$ /usr/local/squid/etc/squid.conf | grep -v ^#
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
ssl_bump stare all
ssl_bump bump all
http_access deny all
http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/ssl/gzgtgCA.pem
cache_dir ufs /var/cache/squid 4000 16 256
coredump_dir /var/cache/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_sign signTrusted
cache_effective_user squid
cache_effective_group squid
access_log daemon:/var/log/squid/access.log squid
cache_log /var/log/squid/cache.log
sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s
/usr/local/squid/var/lib/ssl_db -M 4MB
sslcrtd_children 10


I've tried various different combinations of ssl_bump directives including
adding the step_1 and step_2 ACLs as suggested by Amos (verbatim), and
additionally (again verbatim) the configuration outlined on the
squid-cache.org site, but at this point the only behavior I'm getting out
of the system is that which I've described. I have also tried both peeking
and staring, as I understand the use case for my environment stare would be
most appropriate, however neither seem to be working for me at this point
so it's moot. I've turned off the debugging as I wasn't getting anything
terribly useful out of it. I could see CONNECTs to the https sites, and
mentions that they qualified for stare or bump, but never did it seem to
actually happen. If anyone has anything that I should grep for in debug
logs to maybe help I'd be happy to oblige. Perhaps I should just abandon
OpenBSD and move to a more common flavor of *nix - although I will miss PF.

Thanks for the help.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160804/a2577649/attachment.htm>

From bruce.rosenberg.au at gmail.com  Thu Aug  4 02:51:27 2016
From: bruce.rosenberg.au at gmail.com (Bruce Rosenberg)
Date: Thu, 4 Aug 2016 12:51:27 +1000
Subject: [squid-users] sslproxyflags DONT_VERIFY_PEER
In-Reply-To: <CANLNtGQmArkGrWLtyFR9rgw1yqNbWJ4jJRw29VYueQj3J+80Zg@mail.gmail.com>
References: <CANLNtGRVZ-J=ZNGP_QeipFD0cvwupNV3mAZTo2vx-OkmFaFqRA@mail.gmail.com>
 <57A24DA4.5020901@measurement-factory.com>
 <CANLNtGTMwGReDXU9oWMx5aPDOH5RBKvMbMsH2dj3O5rN1OTuog@mail.gmail.com>
 <CANLNtGSqpbeTvr7bdQC15vcUwrCYe26USqxUpLQCEMAR3v7VJg@mail.gmail.com>
 <CAHaxnUJAs7savtS-E-y907pvRxDfXB_r3qSTQ2zv87jGQ9i9Xg@mail.gmail.com>
 <CANLNtGQmArkGrWLtyFR9rgw1yqNbWJ4jJRw29VYueQj3J+80Zg@mail.gmail.com>
Message-ID: <CAHaxnUKF6xJyFkpZjNgwn2G3MZ4krMdZ-gEAP6ydF5_9n13rwQ@mail.gmail.com>

First run the command I mentioned to ensure openssl can verify the full
chain for Yahoo.

$ openssl s_client -connect www.yahoo.com:443 </dev/null

If that fails at any depth then check the default certificate directory
compiled into openssl

$ openssl version -d


If the directory is not /usr/ssl or /usr/ssl/certs then you need to tell
openssl to use that directory.

$ openssl s_client -connect www.yahoo.com:443  -CApath
/usr/ssl/certs </dev/null

If this verifies OK then you have to tell squid to pass the same parameter
to openssl with the following config option.

sslproxy_capath /usr/ssl/certs


You also may need to rehash your ssl cert directory.

This command should spit out the subject hash of the root cert.
$ openssl x509 -in
/usr/ssl/certs/Verisign_Class_3_Public_Primary_Certification_Authority.pem
-noout -subject_hash
415660c1

You should have a corresponding symlink in the /usr/ssl/certs directory
that looks something like this.

$ ls -la 415660c1.*
lrwxrwxrwx 1 root root 97 Jul  5 20:27 415660c1.0 ->
../../ca-certificates/extracted/cadir/Verisign_Class_3_Public_Primary_Certification_Authority.pem

If you don't have a symlink that matches the subject hash then rehash the
directory like so as root
# c_rehash /usr/ssl/certs.

If the hash symlink doesn't exist then openssl's verify functions will fail.




On Thu, Aug 4, 2016 at 12:29 PM, Stanford Prescott <stan.prescott at gmail.com>
wrote:

> That would explain the error if the Verisign Class 3 public root CA were
> missing. However, our Smoothwall Express OS has all the standard root CAs
> package found in /usr/ssl/certs. Do I need to tell squid where to find
> those certs? If so, what config directive would I use for that?
>
> Thanks!
>
> On Wed, Aug 3, 2016 at 8:05 PM, Bruce Rosenberg <
> bruce.rosenberg.au at gmail.com> wrote:
>
>> It looks like you are missing the Verisign Class 3 Public Primary Root
>> cert.
>> Notice the certificate chain list below.
>> Yahoo correctly send back all intermediate certificates in the TLS
>> handshake so the only certificate you need to make sure squid trusts (via
>> openssl) is the Verisign root.
>>
>> You should be able to determine if the openssl client on the squid proxy
>> can verify the complete chain by running the following command on the proxy.
>> The important part is that at each step it outputs "verify return: 1"
>> meaning that the certificate at that depth in the chain was successfully
>> verified by it's issuing certificate i.e. the certificate at the previous
>> higher level depth that we have already established we trust.
>> The root certificate is automagically verified by virtue of being
>> explicitly trusted by your openssl.
>>
>>
>> $ openssl s_client -connect www.yahoo.com:443 </dev/null
>>
>>                                       ?
>> CONNECTED(00000003)
>> depth=3 C = US, O = "VeriSign, Inc.", OU = Class 3 Public Primary
>> Certification Authority
>> verify return:1
>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU =
>> "(c) 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3
>> Public Primary Certification Authority - G5
>> verify return:1
>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, CN
>> = Symantec Class 3 Secure Server CA - G4
>> verify return:1
>> depth=0 C = US, ST = California, L = Sunnyvale, O = Yahoo Inc., OU =
>> Information Technology, CN = www.yahoo.com
>> verify return:1
>> ---
>> Certificate chain
>>  0 s:/C=US/ST=California/L=Sunnyvale/O=Yahoo Inc./OU=Information
>> Technology/CN=www.yahoo.com
>>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
>> Class 3 Secure Server CA - G4
>>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
>> Class 3 Secure Server CA - G4
>>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006
>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
>> Certification Authority - G5
>>  2 s:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006
>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
>> Certification Authority - G5
>>    i:/C=US/O=VeriSign, Inc./OU=Class 3 Public Primary Certification
>> Authority
>>
>>
>> On Thu, Aug 4, 2016 at 9:51 AM, Stanford Prescott <
>> stan.prescott at gmail.com> wrote:
>>
>>> Okay, it's not a name of the cert problem.
>>>
>>> I turned on extra debug info to see what I get when I remove the
>>> DONT_VERIFY_PEER flag and tried accessing https://www.yahoo.com. This
>>> is what I got in the cache.log. I only see a couple of lines about a
>>> certificate error. Sorry this is long but I didn't know what to include so
>>> I just included everything for that one access attempt.
>>>
>>> *2016/08/03 18:12:16.701 kid1| 28,4| Eui48.cc(178) lookup: id=0xa2064b0
>>> query ARP table*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(222) lookup: id=0xa2064b0
>>> query ARP on each interface (128 found)*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>>> found interface lo*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>>> found interface eth2*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
>>> looking up ARP address for 10.40.40.110 on eth2*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>>> found interface eth1*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
>>> looking up ARP address for 10.40.40.110 on eth1*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| Eui48.cc(280) lookup: id=0xa2064b0
>>> got address 08:00:27:29:24:4a on eth1*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
>>> *2016/08/03 18:12:16.702 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa210ad8 checking slow rules*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rules)*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/0is not banned*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>>> localhostgreen*
>>> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare:
>>> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
>>> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff%5D>
>>> (10.40.40.110:49732 <http://10.40.40.110:49732>)  vs
>>> 10.40.40.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:49732 <http://10.40.40.110:49732>' NOT found*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>>> localhostgreen = 0*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 0*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/3is not banned*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_s1_connect*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_s1_connect = 1*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking all*
>>> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
>>> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked: all =
>>> 1*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 1*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rules) = 1*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa210ad8 answer ALLOWED for match*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(163) checkCallback:
>>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>>> *2016/08/03 18:12:16.702 kid1| 33,2| client_side.cc(3909)
>>> httpsSslBumpAccessCheckDone: sslBump needed for local=52.34.245.108:443
>>> <http://52.34.245.108:443> remote=10.40.40.110:49732
>>> <http://10.40.40.110:49732> FD 14 flags=33 method 3*
>>> *2016/08/03 18:12:16.702 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa214d28 checking slow rules*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>>> http_access*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/0is not banned*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>>> http_access#1*
>>> *2016/08/03 18:12:16.702 kid1| 28,5| Acl.cc(138) matches: checking
>>> SWE_subnets*
>>> *2016/08/03 18:12:16.702 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare:
>>> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>>> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>>> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
>>> 192.168.192.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>>> *2016/08/03 18:12:16.703 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare:
>>> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>>> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>>> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
>>> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>>> *2016/08/03 18:12:16.703 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare:
>>> 10.40.40.110:49732/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>>> <http://10.40.40.110:49732/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>>> (10.40.40.0:49732 <http://10.40.40.0:49732>)  vs
>>> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>>> *2016/08/03 18:12:16.703 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
>>> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
>>> SWE_subnets = 1*
>>> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
>>> http_access#1 = 1*
>>> *2016/08/03 18:12:16.703 kid1| 28,3| Acl.cc(158) matches: checked:
>>> http_access = 1*
>>> *2016/08/03 18:12:16.703 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa214d28 answer ALLOWED for match*
>>> *2016/08/03 18:12:16.703 kid1| 28,3| Checklist.cc(163) checkCallback:
>>> ACLChecklist::checkCallback: 0xa214d28 answer=ALLOWED*
>>> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fc08*
>>> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf94fc08*
>>> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fd3c*
>>> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf94fd3c*
>>> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa214d28*
>>> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa214d28*
>>> *2016/08/03 18:12:16.703 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>>> *2016/08/03 18:12:16.703 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa210ad8 checking slow rules*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rules)*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/0 is  banned*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/3is not banned*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_s1_connect*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_s1_connect = 0*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 0*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/6is not banned*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_s2_client_hello*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_s2_client_hello = 1*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_to_splice*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_allowed_hsts*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
>>> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>'*
>>> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
>>> aclHostDomainCompare: Match:tiles.services.mozilla.com
>>> <http://tiles.services.mozilla.com> <>  .akamaihd.net <http://akamaihd.net>*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match:
>>> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>' NOT found*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
>>> 'none'*
>>> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
>>> aclHostDomainCompare: Match:none <>  .akamaihd.net <http://akamaihd.net>*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
>>> found*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_allowed_hsts = 0*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_server_is_bank*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
>>> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>'*
>>> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
>>> aclHostDomainCompare: Match:tiles.services.mozilla.com
>>> <http://tiles.services.mozilla.com> <>  .wellsfargo.com
>>> <http://wellsfargo.com>*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match:
>>> 'tiles.services.mozilla.com <http://tiles.services.mozilla.com>' NOT found*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(42) match: checking
>>> 'none'*
>>> *2016/08/03 18:12:16.704 kid1| 28,7| ServerName.cc(32)
>>> aclHostDomainCompare: Match:none <>  .wellsfargo.com
>>> <http://wellsfargo.com>*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
>>> found*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_server_is_bank = 0*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_to_splice = 0*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 0*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/4is not banned*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_s2_client_hello*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_s2_client_hello = 1*
>>> *2016/08/03 18:12:16.704 kid1| 28,5| Acl.cc(138) matches: checking all*
>>> *2016/08/03 18:12:16.704 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
>>> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked: all =
>>> 1*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 1*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rules) = 1*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa210ad8 answer ALLOWED for match*
>>> *2016/08/03 18:12:16.704 kid1| 28,3| Checklist.cc(163) checkCallback:
>>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>>> *2016/08/03 18:12:16.704 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf95080c*
>>> *2016/08/03 18:12:16.704 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf95080c*
>>> *2016/08/03 18:12:16.704 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>>> *2016/08/03 18:12:16.704 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>>> *2016/08/03 18:12:16.869 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa210ad8 checking fast rules*
>>> *2016/08/03 18:12:16.870 kid1| 28,5| Checklist.cc(346) fastCheck:
>>> aclCheckFast: list: 0x9de0a80*
>>> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking
>>> sslproxy_cert_error*
>>> *2016/08/03 18:12:16.870 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'DENIED/0is not banned*
>>> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking
>>> sslproxy_cert_error#1*
>>> *2016/08/03 18:12:16.870 kid1| 28,5| Acl.cc(138) matches: checking all*
>>> *2016/08/03 18:12:16.870 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare: 10.40.40.110:49732/[:
>>> <http://10.40.40.110:49732/%5B:>:] ([::]:49732)  vs [::]-[::]/[::]*
>>> *2016/08/03 18:12:16.870 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:49732 <http://10.40.40.110:49732>' found*
>>> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked: all =
>>> 1*
>>> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked:
>>> sslproxy_cert_error#1 = 1*
>>> *2016/08/03 18:12:16.870 kid1| 28,3| Acl.cc(158) matches: checked:
>>> sslproxy_cert_error = 1*
>>> *2016/08/03 18:12:16.870 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa210ad8 answer DENIED for match*
>>> *2016/08/03 18:12:16.870 kid1| Error negotiating SSL on FD 16:
>>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
>>> failed (1/-1/0)*
>>> *2016/08/03 18:12:16.871 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xbf950b68 checking fast ACLs*
>>> *2016/08/03 18:12:16.871 kid1| 28,5| Acl.cc(138) matches: checking
>>> cache_access_log stdio:/var/log/squid/access.log*
>>> *2016/08/03 18:12:16.871 kid1| 28,5| Acl.cc(138) matches: checking
>>> (cache_access_log stdio:/var/log/squid/access.log line)*
>>> *2016/08/03 18:12:16.871 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>>> *2016/08/03 18:12:16.871 kid1| 28,3| Acl.cc(158) matches: checked:
>>> cache_access_log stdio:/var/log/squid/access.log = 1*
>>> *2016/08/03 18:12:16.871 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xbf950b68 answer ALLOWED for match*
>>> *2016/08/03 18:12:16.871 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950b68*
>>> *2016/08/03 18:12:16.871 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950b68*
>>> *2016/08/03 18:12:16.998 kid1| 33,2| client_side.cc(816) swanSong:
>>> local=52.34.245.108:443 <http://52.34.245.108:443>
>>> remote=10.40.40.110:49732 <http://10.40.40.110:49732> flags=33*
>>> *2016/08/03 18:12:16.998 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xbf950c28 checking fast ACLs*
>>> *2016/08/03 18:12:16.998 kid1| 28,5| Acl.cc(138) matches: checking
>>> cache_access_log stdio:/var/log/squid/access.log*
>>> *2016/08/03 18:12:16.998 kid1| 28,5| Acl.cc(138) matches: checking
>>> (cache_access_log stdio:/var/log/squid/access.log line)*
>>> *2016/08/03 18:12:16.998 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>>> *2016/08/03 18:12:16.998 kid1| 28,3| Acl.cc(158) matches: checked:
>>> cache_access_log stdio:/var/log/squid/access.log = 1*
>>> *2016/08/03 18:12:16.998 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xbf950c28 answer ALLOWED for match*
>>> *2016/08/03 18:12:16.998 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950c28*
>>> *2016/08/03 18:12:16.998 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950c28*
>>> *2016/08/03 18:12:16.998 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>>> *2016/08/03 18:12:16.998 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(178) lookup: id=0xa2064b0
>>> query ARP table*
>>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(222) lookup: id=0xa2064b0
>>> query ARP on each interface (128 found)*
>>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>>> found interface lo*
>>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>>> found interface eth2*
>>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
>>> looking up ARP address for 10.40.40.110 on eth2*
>>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(228) lookup: id=0xa2064b0
>>> found interface eth1*
>>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(237) lookup: id=0xa2064b0
>>> looking up ARP address for 10.40.40.110 on eth1*
>>> *2016/08/03 18:12:21.031 kid1| 28,4| Eui48.cc(280) lookup: id=0xa2064b0
>>> got address 08:00:27:29:24:4a on eth1*
>>> *2016/08/03 18:12:21.032 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
>>> *2016/08/03 18:12:21.032 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
>>> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa210ad8 checking slow rules*
>>> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
>>> http_access*
>>> *2016/08/03 18:12:21.054 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/0is not banned*
>>> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
>>> http_access#1*
>>> *2016/08/03 18:12:21.054 kid1| 28,5| Acl.cc(138) matches: checking
>>> SWE_subnets*
>>> *2016/08/03 18:12:21.054 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare:
>>> 10.40.40.110:40595/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>>> <http://10.40.40.110:40595/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>>> (10.40.40.0:40595 <http://10.40.40.0:40595>)  vs
>>> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>>> *2016/08/03 18:12:21.054 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:40595 <http://10.40.40.110:40595>' found*
>>> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
>>> SWE_subnets = 1*
>>> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
>>> http_access#1 = 1*
>>> *2016/08/03 18:12:21.054 kid1| 28,3| Acl.cc(158) matches: checked:
>>> http_access = 1*
>>> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa210ad8 answer ALLOWED for match*
>>> *2016/08/03 18:12:21.054 kid1| 28,3| Checklist.cc(163) checkCallback:
>>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>>> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950198*
>>> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950198*
>>> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf9502cc*
>>> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf9502cc*
>>> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94f87c*
>>> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf94f87c*
>>> *2016/08/03 18:12:21.054 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>>> *2016/08/03 18:12:21.054 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>>> *2016/08/03 18:12:21.101 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf9509dc*
>>> *2016/08/03 18:12:21.102 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf9509dc*
>>> *2016/08/03 18:12:21.150 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xbf950ae8 checking fast ACLs*
>>> *2016/08/03 18:12:21.150 kid1| 28,5| Acl.cc(138) matches: checking
>>> cache_access_log stdio:/var/log/squid/access.log*
>>> *2016/08/03 18:12:21.150 kid1| 28,5| Acl.cc(138) matches: checking
>>> (cache_access_log stdio:/var/log/squid/access.log line)*
>>> *2016/08/03 18:12:21.150 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>>> *2016/08/03 18:12:21.150 kid1| 28,3| Acl.cc(158) matches: checked:
>>> cache_access_log stdio:/var/log/squid/access.log = 1*
>>> *2016/08/03 18:12:21.150 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xbf950ae8 answer ALLOWED for match*
>>> *2016/08/03 18:12:21.150 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950ae8*
>>> *2016/08/03 18:12:21.150 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950ae8*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(178) lookup: id=0xa224638
>>> query ARP table*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(222) lookup: id=0xa224638
>>> query ARP on each interface (128 found)*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
>>> found interface lo*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
>>> found interface eth2*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(237) lookup: id=0xa224638
>>> looking up ARP address for 10.40.40.110 on eth2*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(228) lookup: id=0xa224638
>>> found interface eth1*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(237) lookup: id=0xa224638
>>> looking up ARP address for 10.40.40.110 on eth1*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Eui48.cc(280) lookup: id=0xa224638
>>> got address 08:00:27:29:24:4a on eth1*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950dec*
>>> *2016/08/03 18:12:21.171 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950dec*
>>> *2016/08/03 18:12:21.171 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa210ad8 checking slow rules*
>>> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rules)*
>>> *2016/08/03 18:12:21.171 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/0is not banned*
>>> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:21.171 kid1| 28,5| Acl.cc(138) matches: checking
>>> localhostgreen*
>>> *2016/08/03 18:12:21.171 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare:
>>> 10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]
>>> <http://10.40.40.110:35474/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff%5D>
>>> (10.40.40.110:35474 <http://10.40.40.110:35474>)  vs
>>> 10.40.40.1-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff]*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:35474 <http://10.40.40.110:35474>' NOT found*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>>> localhostgreen = 0*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 0*
>>> *2016/08/03 18:12:21.172 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/3is not banned*
>>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_s1_connect*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_s1_connect = 1*
>>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking all*
>>> *2016/08/03 18:12:21.172 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
>>> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked: all =
>>> 1*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 1*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rules) = 1*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa210ad8 answer ALLOWED for match*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(163) checkCallback:
>>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>>> *2016/08/03 18:12:21.172 kid1| 33,2| client_side.cc(3909)
>>> httpsSslBumpAccessCheckDone: sslBump needed for local=98.138.253.109:443
>>> <http://98.138.253.109:443> remote=10.40.40.110:35474
>>> <http://10.40.40.110:35474> FD 18 flags=33 method 3*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa214d28 checking slow rules*
>>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>>> http_access*
>>> *2016/08/03 18:12:21.172 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/0is not banned*
>>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>>> http_access#1*
>>> *2016/08/03 18:12:21.172 kid1| 28,5| Acl.cc(138) matches: checking
>>> SWE_subnets*
>>> *2016/08/03 18:12:21.172 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare:
>>> 10.40.40.110:35474/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]
>>> <http://10.40.40.110:35474/%5Bffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00%5D>
>>> (10.40.40.0:35474 <http://10.40.40.0:35474>)  vs
>>> 10.40.40.0-[::]/[ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00]*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>>> SWE_subnets = 1*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>>> http_access#1 = 1*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Acl.cc(158) matches: checked:
>>> http_access = 1*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa214d28 answer ALLOWED for match*
>>> *2016/08/03 18:12:21.172 kid1| 28,3| Checklist.cc(163) checkCallback:
>>> ACLChecklist::checkCallback: 0xa214d28 answer=ALLOWED*
>>> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fc08*
>>> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf94fc08*
>>> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf94fd3c*
>>> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf94fd3c*
>>> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa214d28*
>>> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa214d28*
>>> *2016/08/03 18:12:21.172 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>>> *2016/08/03 18:12:21.172 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa210ad8 checking slow rules*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rules)*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/0 is  banned*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/3is not banned*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_s1_connect*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_s1_connect = 0*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 0*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/6is not banned*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_s2_client_hello*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_s2_client_hello = 1*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_to_splice*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_allowed_hsts*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
>>> 'www.yahoo.com <http://www.yahoo.com>'*
>>> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
>>> aclHostDomainCompare: Match:www.yahoo.com <http://www.yahoo.com> <>
>>>  .akamaihd.net <http://akamaihd.net>*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match:
>>> 'www.yahoo.com <http://www.yahoo.com>' NOT found*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
>>> 'none'*
>>> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
>>> aclHostDomainCompare: Match:none <>  .akamaihd.net <http://akamaihd.net>*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
>>> found*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_allowed_hsts = 0*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_server_is_bank*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
>>> 'www.yahoo.com <http://www.yahoo.com>'*
>>> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
>>> aclHostDomainCompare: Match:www.yahoo.com <http://www.yahoo.com> <>
>>>  .wellsfargo.com <http://wellsfargo.com>*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match:
>>> 'www.yahoo.com <http://www.yahoo.com>' NOT found*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(42) match: checking
>>> 'none'*
>>> *2016/08/03 18:12:21.173 kid1| 28,7| ServerName.cc(32)
>>> aclHostDomainCompare: Match:none <>  .wellsfargo.com
>>> <http://wellsfargo.com>*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| ServerName.cc(47) match: 'none' NOT
>>> found*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_server_is_bank = 0*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_to_splice = 0*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 0*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'ALLOWED/4is not banned*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> (ssl_bump rule)*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking
>>> tls_s2_client_hello*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> tls_s2_client_hello = 1*
>>> *2016/08/03 18:12:21.173 kid1| 28,5| Acl.cc(138) matches: checking all*
>>> *2016/08/03 18:12:21.173 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
>>> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked: all =
>>> 1*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rule) = 1*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (ssl_bump rules) = 1*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa210ad8 answer ALLOWED for match*
>>> *2016/08/03 18:12:21.173 kid1| 28,3| Checklist.cc(163) checkCallback:
>>> ACLChecklist::checkCallback: 0xa210ad8 answer=ALLOWED*
>>> *2016/08/03 18:12:21.173 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf95080c*
>>> *2016/08/03 18:12:21.173 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf95080c*
>>> *2016/08/03 18:12:21.173 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>>> *2016/08/03 18:12:21.173 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>>> *2016/08/03 18:12:21.278 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xa210ad8 checking fast rules*
>>> *2016/08/03 18:12:21.278 kid1| 28,5| Checklist.cc(346) fastCheck:
>>> aclCheckFast: list: 0x9de0a80*
>>> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking
>>> sslproxy_cert_error*
>>> *2016/08/03 18:12:21.278 kid1| 28,5| Checklist.cc(400) bannedAction:
>>> Action 'DENIED/0is not banned*
>>> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking
>>> sslproxy_cert_error#1*
>>> *2016/08/03 18:12:21.278 kid1| 28,5| Acl.cc(138) matches: checking all*
>>> *2016/08/03 18:12:21.278 kid1| 28,9| Ip.cc(95) aclIpAddrNetworkCompare:
>>> aclIpAddrNetworkCompare: compare: 10.40.40.110:35474/[:
>>> <http://10.40.40.110:35474/%5B:>:] ([::]:35474)  vs [::]-[::]/[::]*
>>> *2016/08/03 18:12:21.278 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp:
>>> '10.40.40.110:35474 <http://10.40.40.110:35474>' found*
>>> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked: all =
>>> 1*
>>> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked:
>>> sslproxy_cert_error#1 = 1*
>>> *2016/08/03 18:12:21.278 kid1| 28,3| Acl.cc(158) matches: checked:
>>> sslproxy_cert_error = 1*
>>> *2016/08/03 18:12:21.278 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xa210ad8 answer DENIED for match*
>>> *2016/08/03 18:12:21.278 kid1| Error negotiating SSL on FD 20:
>>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
>>> failed (1/-1/0)*
>>> *2016/08/03 18:12:21.279 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xbf950b68 checking fast ACLs*
>>> *2016/08/03 18:12:21.279 kid1| 28,5| Acl.cc(138) matches: checking
>>> cache_access_log stdio:/var/log/squid/access.log*
>>> *2016/08/03 18:12:21.279 kid1| 28,5| Acl.cc(138) matches: checking
>>> (cache_access_log stdio:/var/log/squid/access.log line)*
>>> *2016/08/03 18:12:21.279 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>>> *2016/08/03 18:12:21.279 kid1| 28,3| Acl.cc(158) matches: checked:
>>> cache_access_log stdio:/var/log/squid/access.log = 1*
>>> *2016/08/03 18:12:21.279 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xbf950b68 answer ALLOWED for match*
>>> *2016/08/03 18:12:21.279 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950b68*
>>> *2016/08/03 18:12:21.279 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950b68*
>>> *2016/08/03 18:12:21.331 kid1| 33,2| client_side.cc(816) swanSong:
>>> local=98.138.253.109:443 <http://98.138.253.109:443>
>>> remote=10.40.40.110:35474 <http://10.40.40.110:35474> flags=33*
>>> *2016/08/03 18:12:21.331 kid1| 28,3| Checklist.cc(70) preCheck:
>>> 0xbf950c28 checking fast ACLs*
>>> *2016/08/03 18:12:21.331 kid1| 28,5| Acl.cc(138) matches: checking
>>> cache_access_log stdio:/var/log/squid/access.log*
>>> *2016/08/03 18:12:21.331 kid1| 28,5| Acl.cc(138) matches: checking
>>> (cache_access_log stdio:/var/log/squid/access.log line)*
>>> *2016/08/03 18:12:21.331 kid1| 28,3| Acl.cc(158) matches: checked:
>>> (cache_access_log stdio:/var/log/squid/access.log line) = 1*
>>> *2016/08/03 18:12:21.331 kid1| 28,3| Acl.cc(158) matches: checked:
>>> cache_access_log stdio:/var/log/squid/access.log = 1*
>>> *2016/08/03 18:12:21.331 kid1| 28,3| Checklist.cc(63) markFinished:
>>> 0xbf950c28 answer ALLOWED for match*
>>> *2016/08/03 18:12:21.331 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbf950c28*
>>> *2016/08/03 18:12:21.331 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xbf950c28*
>>> *2016/08/03 18:12:21.331 kid1| 28,4| FilledChecklist.cc(66)
>>> ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xa210ad8*
>>> *2016/08/03 18:12:21.331 kid1| 28,4| Checklist.cc(197) ~ACLChecklist:
>>> ACLChecklist::~ACLChecklist: destroyed 0xa210ad8*
>>>
>>>
>>> The web browser error says:
>>> "Failed to establish a secure connection to (a yahoo.com IP address was
>>> here)"
>>> and another message of "(71) Protocol error (TLS code:
>>> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)"
>>> and "Certificate issuer (CA) not known".
>>>
>>> On Wed, Aug 3, 2016 at 4:12 PM, Stanford Prescott <
>>> stan.prescott at gmail.com> wrote:
>>>
>>>> Thanks for the info, Alex. That's very helpful about cleaning up my
>>>> ACLs. Those ACLs are a collection of ACLs that others have suggested I use,
>>>> but it would be nice to make them less confusing for me.
>>>>
>>>> With my limited understanding of how sslbump works, the idea for squid
>>>> to play MITM is that a self-signed cert like squidCA.der is imported to a
>>>> browser's root CAs. I have left a copy of the self-signed cert named
>>>> squidCA.pem in the squid's cert directory which only works if squid is told
>>>> to not verify the peer. When following the instructions how to generate the
>>>> self-signed cert with openssl, the .pem file must be converted to a .der
>>>> file for the browser to accept it. It just dawned on me that, could this be
>>>> related to the fact that the squid self-signed certs are not named the same?
>>>>
>>>> On Wed, Aug 3, 2016 at 3:01 PM, Alex Rousskov <
>>>> rousskov at measurement-factory.com> wrote:
>>>>
>>>>> On 08/03/2016 08:45 AM, Stanford Prescott wrote:
>>>>>
>>>>> > ssl_bump none localhostgreen
>>>>> > ssl_bump peek tls_s1_connect all
>>>>> > ssl_bump splice tls_s2_client_hello tls_to_splice
>>>>> > ssl_bump stare tls_s2_client_hello all
>>>>> > ssl_bump bump tls_s3_server_hello all
>>>>>
>>>>> AFAICT, the above is too complex. You can simplify it with:
>>>>>
>>>>>   ssl_bump splice localhostgreen
>>>>>   ssl_bump peek tls_s1_connect
>>>>>   ssl_bump splice tls_to_splice
>>>>>   ssl_bump stare all
>>>>>   ssl_bump bump all
>>>>>
>>>>> and, after polishing your ACLs a little, possibly even with:
>>>>>
>>>>>   ssl_bump splice transactions_to_splice
>>>>>   ssl_bump peek tls_s1_connect
>>>>>   ssl_bump stare all
>>>>>   ssl_bump bump all
>>>>>
>>>>> where transactions_to_splice is "localhostgreen or (tls_s2_client_hello
>>>>> and tls_to_splice)".
>>>>>
>>>>>
>>>>> As for your original question, I recommend figuring out why Squid
>>>>> cannot
>>>>> verify the peer. For example, your setup might be missing fresh
>>>>> certificates for some well-known Root CAs. I do not know a good way to
>>>>> figure out why peer verification does not work, but analyzing cache.log
>>>>> with high-enough debugging level should be doable, especially if you
>>>>> can
>>>>> reproduce the problem using a single transaction:
>>>>>
>>>>>
>>>>> http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction
>>>>>
>>>>>
>>>>> HTH,
>>>>>
>>>>> Alex.
>>>>>
>>>>>
>>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160804/2b5f335d/attachment.htm>

From squid3 at treenet.co.nz  Thu Aug  4 06:16:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 Aug 2016 18:16:39 +1200
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <3f248c59-67d4-2a84-359a-004de81b4d67@cinbesa.com.br>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
 <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
 <3f248c59-67d4-2a84-359a-004de81b4d67@cinbesa.com.br>
Message-ID: <e181c5d0-4969-706f-d8bc-9a1d52e69ead@treenet.co.nz>

On 4/08/2016 2:32 a.m., Heiler Bemerguy wrote:
> 
> I think it doesn't really matter how much squid sets its default buffer.
> The linux kernel will upscale to the maximum set by the third option.
> (and the TCP Window Size will follow that)
> 
> net.ipv4.tcp_wmem = 1024 32768 8388608
> net.ipv4.tcp_rmem = 1024 32768 8388608
> 

Having large system buffers like that just leads to buffer bloat
problems. Squid is still the bottleneck if it is sending only 4KB each
I/O cycle to the client - no matter how much is already received by
Squid, or stuck in kernel queues waiting to arrive to Squid. The more
heavily loaded the proxy is the longer each I/O cycle gets as all
clients get one slice of the cycle to do whatever processing they need done.

The buffers limited by HTTP_REQBUF_SZ are not dynamic so its not just a
minimum. Nathan found a 300% speed increase from a 3x buffer size
increase. Which is barely noticable (but still present) on small
responses, but very noticable with large transactions.

Amos



From harsha.s.aryan at gmail.com  Thu Aug  4 08:04:18 2016
From: harsha.s.aryan at gmail.com (Harsha S Aryan)
Date: Thu, 4 Aug 2016 13:34:18 +0530
Subject: [squid-users] All website getting Blocked
In-Reply-To: <CAAqh_uF9X5KVK2bs_MvRNinvmBXRTR0AhP8o=kdQ5fTAzX2BBA@mail.gmail.com>
References: <CAAqh_uH_oeMc6ksiDcOx-t+CGOsyJrepAgt1YzHAv0WezkSUyg@mail.gmail.com>
 <CAAqh_uF9X5KVK2bs_MvRNinvmBXRTR0AhP8o=kdQ5fTAzX2BBA@mail.gmail.com>
Message-ID: <CAAqh_uFbK=P4nXWuM_2h+P=4gFn-3AL2PmBFLzoYO5NzVu5TGQ@mail.gmail.com>

this is my squid conf file.

#############################################

auth_param basic children 5
auth_param basic realm Squid proxy-caching web server
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off
acl allowed_sites dstdomain "/etc/squid3/Allowed_Sites.txt"
acl blocked_ip src "/etc/squid3/Blocked_Ip.txt"
acl allowed_ip dst "/etc/squid3/Allowed_Ip.txt"
acl allcomputers src 192.168.1.0/255.255.255.0
acl allcomputers src 192.168.2.0/255.255.255.0
acl all_others dst 0.0.0.0/0.0.0.0
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl all src all
acl localhost src 127.0.0.1/32
acl to_localhost dst 127.0.0.0/8
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_access deny all
http_port 3128
http_port 80 vhost
hierarchy_stoplist cgi-bin ?
access_log /var/log/squid3/access.log squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern (Release|Package(.gz)*)$        0       20%     2880
refresh_pattern \.js$ 1440 0% 4320
refresh_pattern \.(PNG|png)$ 1440 0% 4320
refresh_pattern .               0       20%     4320
acl shoutcast rep_header X-HTTP09-First-Line ^ICY\s[0-9]
upgrade_http0.9 deny shoutcast
acl apache rep_header Server ^Apache
broken_vary_encoding allow apache
extension_methods REPORT MERGE MKACTIVITY CHECKOUT
hosts_file /etc/hosts
coredump_dir /var/spool/squid3

###################################################

On Wed, Aug 3, 2016 at 10:23 PM, Harsha S Aryan <harsha.s.aryan at gmail.com>
wrote:

>
> ---------- Forwarded message ----------
> From: Harsha S Aryan <harsha.s.aryan at gmail.com>
> Date: Wed, Aug 3, 2016 at 10:22 PM
> Subject: All website getting Blocked
> To: squid-users at lists.squid-cache.org
>
>
> Hi,
>
> All website getting Blocked
> using squid3
> ubuntu 14.04
> Squid Cache: Version 3.3.8
>
>
> conf file
>
>
> auth_param basic children 5
> auth_param basic realm Squid proxy-caching web server
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off
> acl allowed_sites dstdomain "/etc/squid3/Allowed_Sites.txt"
> acl blocked_ip src "/etc/squid3/Blocked_Ip.txt"
> acl allowed_ip dst "/etc/squid3/Allowed_Ip.txt"
> acl allcomputers src 192.168.1.0/255.255.255.0
> acl allcomputers src 192.168.2.0/255.255.255.0
> acl all_others dst 0.0.0.0/0.0.0.0
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl all src all
> acl localhost src 127.0.0.1/32
> acl to_localhost dst 127.0.0.0/8
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localhost
> http_access deny all
> http_port 3128
> http_port 80 vhost
> hierarchy_stoplist cgi-bin ?
> access_log /var/log/squid3/access.log squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern (Release|Package(.gz)*)$        0       20%     2880
> refresh_pattern \.js$ 1440 0% 4320
> refresh_pattern \.(PNG|png)$ 1440 0% 4320
> refresh_pattern .               0       20%     4320
> acl shoutcast rep_header X-HTTP09-First-Line ^ICY\s[0-9]
> upgrade_http0.9 deny shoutcast
> acl apache rep_header Server ^Apache
> broken_vary_encoding allow apache
> extension_methods REPORT MERGE MKACTIVITY CHECKOUT
> hosts_file /etc/hosts
> coredump_dir /var/spool/squid3
>
> Please let me know if anything is missing
>
> --
> Rehards,
> Harsha
>
>
>
> --
> Rehards,
> Harsha
>



-- 
Rehards,
Harsha
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160804/70836926/attachment.htm>

From augustus_meyer at gmx.net  Thu Aug  4 08:15:35 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Thu, 4 Aug 2016 01:15:35 -0700 (PDT)
Subject: [squid-users] cachemgr.cgi on embedded system
In-Reply-To: <fba280b4-44ac-3eb2-5f53-66510e69d3de@treenet.co.nz>
References: <1469364864274-4678665.post@n4.nabble.com>
 <b396301d1e5df$d7350960$859f1c20$@ngtech.co.il>
 <da81d95a-1651-ce23-9b9a-597e440477c3@treenet.co.nz>
 <1469436926898-4678668.post@n4.nabble.com>
 <dcc13563-9828-d275-1cd8-b19fbe818b8b@treenet.co.nz>
 <1469450968676-4678677.post@n4.nabble.com>
 <177800de-8add-58da-d0d2-cc6afe086aab@treenet.co.nz>
 <1469543113687-4678682.post@n4.nabble.com>
 <fba280b4-44ac-3eb2-5f53-66510e69d3de@treenet.co.nz>
Message-ID: <1470298535365-4678748.post@n4.nabble.com>

Thanx a lot, I got it now. 
The magic line in squid.conf, I had to add:

acl safe_ports port 3128

Now 
http://my.local.ip.onsquidbox:3128/squid-internal-mgr/info 
succeeds. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/cachemgr-cgi-on-embedded-system-tp4678665p4678748.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Thu Aug  4 09:09:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 Aug 2016 21:09:29 +1200
Subject: [squid-users] All website getting Blocked
In-Reply-To: <CAAqh_uFbK=P4nXWuM_2h+P=4gFn-3AL2PmBFLzoYO5NzVu5TGQ@mail.gmail.com>
References: <CAAqh_uH_oeMc6ksiDcOx-t+CGOsyJrepAgt1YzHAv0WezkSUyg@mail.gmail.com>
 <CAAqh_uF9X5KVK2bs_MvRNinvmBXRTR0AhP8o=kdQ5fTAzX2BBA@mail.gmail.com>
 <CAAqh_uFbK=P4nXWuM_2h+P=4gFn-3AL2PmBFLzoYO5NzVu5TGQ@mail.gmail.com>
Message-ID: <d27179be-d84e-2055-e18d-767664dc8008@treenet.co.nz>

On 4/08/2016 8:04 p.m., Harsha S Aryan wrote:
> this is my squid conf file.
> 
> #############################################
> 
> auth_param basic children 5
> auth_param basic realm Squid proxy-caching web server
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off
> acl allowed_sites dstdomain "/etc/squid3/Allowed_Sites.txt"
> acl blocked_ip src "/etc/squid3/Blocked_Ip.txt"
> acl allowed_ip dst "/etc/squid3/Allowed_Ip.txt"
> acl allcomputers src 192.168.1.0/255.255.255.0
> acl allcomputers src 192.168.2.0/255.255.255.0
> acl all_others dst 0.0.0.0/0.0.0.0
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl all src all
> acl localhost src 127.0.0.1/32
> acl to_localhost dst 127.0.0.0/8
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localhost
> http_access deny all
> http_port 3128
> http_port 80 vhost
> hierarchy_stoplist cgi-bin ?
> access_log /var/log/squid3/access.log squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern (Release|Package(.gz)*)$        0       20%     2880
> refresh_pattern \.js$ 1440 0% 4320
> refresh_pattern \.(PNG|png)$ 1440 0% 4320
> refresh_pattern .               0       20%     4320
> acl shoutcast rep_header X-HTTP09-First-Line ^ICY\s[0-9]
> upgrade_http0.9 deny shoutcast
> acl apache rep_header Server ^Apache
> broken_vary_encoding allow apache
> extension_methods REPORT MERGE MKACTIVITY CHECKOUT
> hosts_file /etc/hosts
> coredump_dir /var/spool/squid3
> 
> ###################################################
> 
> On Wed, Aug 3, 2016 at 10:23 PM, Harsha S Aryan <harsha.s.aryan at gmail.com>
> wrote:
> 
>>
>> ---------- Forwarded message ----------
>> From: Harsha S Aryan <harsha.s.aryan at gmail.com>
>> Date: Wed, Aug 3, 2016 at 10:22 PM
>> Subject: All website getting Blocked
>> To: squid-users at lists.squid-cache.org
>>
>>
>> Hi,
>>
>> All website getting Blocked
>> using squid3
>> ubuntu 14.04
>> Squid Cache: Version 3.3.8
>>
>>
>> conf file
>>
>>
>> auth_param basic children 5
>> auth_param basic realm Squid proxy-caching web server
>> auth_param basic credentialsttl 2 hours
>> auth_param basic casesensitive off

No auth helper is configurred, making the above useless. You can remove.

>> acl allowed_sites dstdomain "/etc/squid3/Allowed_Sites.txt"
>> acl blocked_ip src "/etc/squid3/Blocked_Ip.txt"
>> acl allowed_ip dst "/etc/squid3/Allowed_Ip.txt"
>> acl allcomputers src 192.168.1.0/255.255.255.0
>> acl allcomputers src 192.168.2.0/255.255.255.0
>> acl all_others dst 0.0.0.0/0.0.0.0

Thats all quite odd. Not used anyhow, so you can erase all of the above.

>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

>> acl all src all

"all" is now a built-in directive. You can remove the above line.

>> acl localhost src 127.0.0.1/32
>> acl to_localhost dst 127.0.0.0/8

"localhost" in modern systems includes the IP address ::1 from IPv6.

The to_localhost should also be including the 0.0.0.0/32 address which
some networking systems treat as localhost. This is a security
protection so needs to be configured right to work. You have not used it
anywhere though, so you can remove the definition entirely if you like.

>> acl SSL_ports port 443
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>> acl CONNECT method CONNECT
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>> http_access allow localhost
>> http_access deny all

In other words, this proxy will only accept requests coming from
locahost (127.0.0.1). No other clients are permitted to use the proxy
for HTTP.


>> http_port 3128
>> http_port 80 vhost
>> hierarchy_stoplist cgi-bin ?

Above is an obsolete directive. Remove.

>> access_log /var/log/squid3/access.log squid
>> refresh_pattern ^ftp:           1440    20%     10080
>> refresh_pattern ^gopher:        1440    0%      1440
>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>> refresh_pattern (Release|Package(.gz)*)$        0       20%     2880
>> refresh_pattern \.js$ 1440 0% 4320
>> refresh_pattern \.(PNG|png)$ 1440 0% 4320
>> refresh_pattern .               0       20%     4320
>> acl shoutcast rep_header X-HTTP09-First-Line ^ICY\s[0-9]
>> upgrade_http0.9 deny shoutcast

The shoutcast stuff is obsolete old Squid-2.7 config. Squid-3 has native
ICY / SHOUTcast / ICEcast support. There is no config required.

>> acl apache rep_header Server ^Apache
>> broken_vary_encoding allow apache
>> extension_methods REPORT MERGE MKACTIVITY CHECKOUT

extension_methods are also obsolete in Squid-3. All methods, including
unknown ones are treated properly.

>> hosts_file /etc/hosts

That is the default location for Limux systems. No need to configure
hosts_file like this.

>> coredump_dir /var/spool/squid3
>>
>> Please let me know if anything is missing
>>

What are you intending this proxies purpose to be?


Amos



From squid3 at treenet.co.nz  Thu Aug  4 09:17:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 Aug 2016 21:17:05 +1200
Subject: [squid-users] cachemgr.cgi on embedded system
In-Reply-To: <1470298535365-4678748.post@n4.nabble.com>
References: <1469364864274-4678665.post@n4.nabble.com>
 <b396301d1e5df$d7350960$859f1c20$@ngtech.co.il>
 <da81d95a-1651-ce23-9b9a-597e440477c3@treenet.co.nz>
 <1469436926898-4678668.post@n4.nabble.com>
 <dcc13563-9828-d275-1cd8-b19fbe818b8b@treenet.co.nz>
 <1469450968676-4678677.post@n4.nabble.com>
 <177800de-8add-58da-d0d2-cc6afe086aab@treenet.co.nz>
 <1469543113687-4678682.post@n4.nabble.com>
 <fba280b4-44ac-3eb2-5f53-66510e69d3de@treenet.co.nz>
 <1470298535365-4678748.post@n4.nabble.com>
Message-ID: <2a33a710-1cf1-0e61-247b-e0da9ea2007d@treenet.co.nz>

On 4/08/2016 8:15 p.m., reinerotto wrote:
> Thanx a lot, I got it now. 
> The magic line in squid.conf, I had to add:
> 
> acl safe_ports port 3128
> 

Hmm. Which means you have altered the settings for Safe_ports in the
first place to be far too restrictive.

Safe_ports purpose and use in the basic config is carefully defined to
prevent the proxy being used as an Open-proxy/open-relay by traffic
attacking servers whose other ASCII based protocols exist that can
easily be confused with (and abused by) HTTP/1 messages.

Amos



From squid3 at treenet.co.nz  Thu Aug  4 09:33:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 Aug 2016 21:33:14 +1200
Subject: [squid-users] Seeking insight into zeros,
 negative values in log: 2.6.STABLE18
In-Reply-To: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
Message-ID: <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>

On 4/08/2016 2:36 a.m., Henry S. Thompson wrote:
> I'm trying to do some summary statistics based on log files from our
> 2.6.STABLE18 setup.

Please upgrade. The current 3.5.20 release can do everything that
Squid-2.6 could do, and a lot more useful stuff besides.

> 
> A range of issues with interpreting 0 and negative values have arisen:
> 
>  1) Roughly 6 in every 1000 log lines show an HTTP status code of 000,
>     about 90% with TCP_MISS, the rest mostly TCP_HIT, e.g.
> 
>     1402700792.606 54 ... TCP_MISS/000 0 GET http://... DIRECT/... -
>     1402700780.177 1 ... TCP_HIT/000 0 GET http://... NONE/- -
> 
>     Web search suggests the most likely interpretation of this is client
>     disconnect, can anyone confirm/elaborate?  Note this seems
>     consistent with the fact that as in the examples above almost all
>     show a 0 for the size, but doesn't explain the lack of media type...
> 

Yes, for both the client disconnected before any response was sent by
Squid. The first Squid was still in the process of talking to a server
to get a response.


>  2) Leaving aside those cases, I see a modest handful (1 in 7000) of 0
>     values in the size field, e.g.
> 
>     1402741879.726 114 ... TCP_MISS/200 0 GET http://... DIRECT/... image/gif
>     1402771557.693 176 ... TCP_HIT/200 0 GET http://... NONE/- image/gif
> 
>     How should these be understood?

A response with no body payload. It happens. Usually with "web bug" type
images used for tracking.
Or maybe the image was something like a captcha and the script producing
it crashed with no data sent.

> 
>  3) I'm seeing very small numbers (1 in 100000) of negative durations, e.g.
> 
>     1402744620.389 -70 ... TCP_MISS/200 1882 GET http://... DIRECT/... text/xml
>     
>     How should these be understood?

The system clock on your machine went backwards between the request
arriving and the response being completely sent. Check for issues in
your NTP setup.

Amos



From ht at inf.ed.ac.uk  Thu Aug  4 09:52:09 2016
From: ht at inf.ed.ac.uk (Henry S. Thompson)
Date: Thu, 04 Aug 2016 10:52:09 +0100
Subject: [squid-users] Seeking insight into zeros,
	negative values in log: 2.6.STABLE18
In-Reply-To: <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz> (Amos
 Jeffries's message of "Thu\, 4 Aug 2016 21\:33\:14 +1200")
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
Message-ID: <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>

Amos Jeffries writes:

> On 4/08/2016 2:36 a.m., Henry S. Thompson wrote:
>> I'm trying to do some summary statistics based on log files from our
>> 2.6.STABLE18 setup.
>
> Please upgrade. The current 3.5.20 release can do everything that
> Squid-2.6 could do, and a lot more useful stuff besides.

I'd love to, but it's out of my hands, much higher up :-(.

Thanks for your help below.

>>  2) Leaving aside those cases, I see a modest handful (1 in 7000) of 0
>>     values in the size field, e.g.
>> 
>>     1402741879.726 114 ... TCP_MISS/200 0 GET http://... DIRECT/... image/gif
>>     1402771557.693 176 ... TCP_HIT/200 0 GET http://... NONE/- image/gif
>> 
>>     How should these be understood?
>
> A response with no body payload. It happens. Usually with "web bug" type
> images used for tracking.
> Or maybe the image was something like a captcha and the script producing
> it crashed with no data sent.

But documentation claims size field includes headers, and clearly
(image/gif) at least a Content-type header was sent...

>>  3) I'm seeing very small numbers (1 in 100000) of negative durations, e.g.
>> 
>>     1402744620.389 -70 ... TCP_MISS/200 1882 GET http://... DIRECT/... text/xml
>>     
>>     How should these be understood?
>
> The system clock on your machine went backwards between the request
> arriving and the response being completely sent. Check for issues in
> your NTP setup.

1000s of times a day?  Seems . . . unlikely.  But I'll try to get the
sys admin people responsible to investigate.

Thanks again,

ht
-- 
       Henry S. Thompson, School of Informatics, University of Edinburgh
      10 Crichton Street, Edinburgh EH8 9AB, SCOTLAND -- (44) 131 650-4440
                Fax: (44) 131 650-4587, e-mail: ht at inf.ed.ac.uk
                       URL: http://www.ltg.ed.ac.uk/~ht/
 [mail from me _always_ has a .sig like this -- mail without it is forged spam]


From garth1985 at gmail.com  Thu Aug  4 10:16:04 2016
From: garth1985 at gmail.com (Garth)
Date: Thu, 4 Aug 2016 12:16:04 +0200
Subject: [squid-users] Squid NTLM AD Group Delay Pools
Message-ID: <43af660a-58d3-1736-3761-674a760ef5a3@gmail.com>

Hi All

I am struggling with delay pools and Group AD. I have managed to narrow 
down the problem to the AD Groups. If I do user auth, the delay pool 
works perfectly. I have tried multiple groups from old to new just 
incase. The AD Groups work for normal site access in the http_access 
rules etc.

Is there a known issue with this? Is there a way to confirm the group 
lookup is correct by the squid/winbind?

Squid Cache: Version 3.1.23

Centos 6.8

external_acl_type ldap_group %LOGIN /usr/lib64/squid/squid_ldap_group -R 
-b "dc=example,dc=example" -f 
"(&(sAMAccountName=%v)(memberOf=cn=%a,ou=Security,ou=groups,dc=example,dc=example))" 
-D test at EXAMPLE.EXAMPLE -w testing -h 192.168.1.254

auth_param ntlm program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 50
auth_param basic program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-basic
auth_param basic children 50

acl proxyusers-delaypool external ldap_group proxyusers-delaypool
acl proxyusers-nondelaypool external ldap_group proxyusers-nondelaypool
acl ftp.is url_regex ftp.is.co.za

acl socialsites url_regex "/etc/squid/socialsites.txt"

In the socialsites is the following:

.facebook.com
.facebook.co.za
.facebook.com:443
.youtube.com:443
.googlevideo.
.fbcdn.net
.akamaihd.net
.vimeocdn.com:443

delay_pools 4
delay_class 1 1
delay_class 2 2
delay_class 3 2
delay_class 4 1
delay_parameters 1 244000/552000
delay_parameters 2 524000/525000 524000/525000
delay_parameters 3 244000/254000 244000/254000
delay_parameters 4 244000/552000
delay_access 1 allow socialsites proxyusers-delaypool
delay_access 2 allow proxyusers-nondelaypool
delay_access 3 allow proxyusers-delaypool
delay_access 4 allow ftp.is proxyusers-delaypool

I am testing via wget and proxy input details into the bash profile. I 
can confirm the username appears in the squid logs.

Any ideas?

Thanks

Garth



From augustus_meyer at gmx.net  Thu Aug  4 09:37:27 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Thu, 4 Aug 2016 02:37:27 -0700 (PDT)
Subject: [squid-users] squid 3.5.x/4.x on embedded system. Anybody ?
Message-ID: <1470303447931-4678754.post@n4.nabble.com>

I have the impression, that these squid versions are much more
memory/CPU-hungry compared to good old 2.7
Any users out there, to share some experience ?

I am running 3.5.20 on a 580MHz MIPS CPU, with 128MB RAM.
So my system is limited in many aspects, and I try some tuning.
For example, recent firefox has a limit of 900 server conns. Which might be
some stress to intercepting squid on my small machine. Especially, as now
persistent conns are default. So I set persistent client conns to off, which
seems to speed up browsing.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-3-5-x-4-x-on-embedded-system-Anybody-tp4678754.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Thu Aug  4 11:34:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 Aug 2016 23:34:47 +1200
Subject: [squid-users] Seeking insight into zeros,
 negative values in log: 2.6.STABLE18
In-Reply-To: <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
Message-ID: <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>

On 4/08/2016 9:52 p.m., Henry S. Thompson wrote:
> Amos Jeffries writes:
> 
>> On 4/08/2016 2:36 a.m., Henry S. Thompson wrote:
>>> I'm trying to do some summary statistics based on log files from our
>>> 2.6.STABLE18 setup.
>>
>> Please upgrade. The current 3.5.20 release can do everything that
>> Squid-2.6 could do, and a lot more useful stuff besides.
> 
> I'd love to, but it's out of my hands, much higher up :-(.
> 
> Thanks for your help below.
> 
>>>  2) Leaving aside those cases, I see a modest handful (1 in 7000) of 0
>>>     values in the size field, e.g.
>>>
>>>     1402741879.726 114 ... TCP_MISS/200 0 GET http://... DIRECT/... image/gif
>>>     1402771557.693 176 ... TCP_HIT/200 0 GET http://... NONE/- image/gif
>>>
>>>     How should these be understood?
>>
>> A response with no body payload. It happens. Usually with "web bug" type
>> images used for tracking.
>> Or maybe the image was something like a captcha and the script producing
>> it crashed with no data sent.
> 
> But documentation claims size field includes headers, and clearly
> (image/gif) at least a Content-type header was sent...

Nope. The reply message header (maybe more, or not) was received from
the server but not sent to the client. The second case it only got as
far as loading from disk and not yet sending.

At the lowest level it was likely the attempt to write(2) those reply
details to the client that detected the connection was closed/aborted
already by the other end.

> 
>>>  3) I'm seeing very small numbers (1 in 100000) of negative durations, e.g.
>>>
>>>     1402744620.389 -70 ... TCP_MISS/200 1882 GET http://... DIRECT/... text/xml
>>>     
>>>     How should these be understood?
>>
>> The system clock on your machine went backwards between the request
>> arriving and the response being completely sent. Check for issues in
>> your NTP setup.
> 
> 1000s of times a day?  Seems . . . unlikely.  But I'll try to get the
> sys admin people responsible to investigate.

Squid's simply doing a time fetch from the kernel and subtracting
Start-time from End-time to get a negative.
Note that its on the scale of ~100 milliseconds.

Amos


From squid3 at treenet.co.nz  Thu Aug  4 11:46:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 Aug 2016 23:46:34 +1200
Subject: [squid-users] squid 3.5.x/4.x on embedded system. Anybody ?
In-Reply-To: <1470303447931-4678754.post@n4.nabble.com>
References: <1470303447931-4678754.post@n4.nabble.com>
Message-ID: <597edcb1-5579-00a9-2216-c63070749ae3@treenet.co.nz>

On 4/08/2016 9:37 p.m., reinerotto wrote:
> I have the impression, that these squid versions are much more
> memory/CPU-hungry compared to good old 2.7
> Any users out there, to share some experience ?

Perhapse on CPU a little. The memory defaults have been raised since
even most embeded systems have more than a few MB available now. The
buffering memory usage is about the same in Squid-2 and Squid-3 though,
maybe smaller even. Unless you are using ICAP in which case it doubles
the buffer memory requirements.

For embeded systems you will want to tune cache_mem downwards quite a
bit. The default is 256MB with no disk cache. Compared to Squid-2 with
32MB of memory cache and 100MB of disk.

> 
> I am running 3.5.20 on a 580MHz MIPS CPU, with 128MB RAM.
> So my system is limited in many aspects, and I try some tuning.
> For example, recent firefox has a limit of 900 server conns. Which might be
> some stress to intercepting squid on my small machine. Especially, as now
> persistent conns are default. So I set persistent client conns to off, which
> seems to speed up browsing.

"seems to" being the operative words. I think you will find that leaving
them active, but tweaking the timeouts will have better results than
fully disabling.
The browser guys (and we) are actively pushing for persistence since it
does measurably reduce latency/delay overheads.

Amos



From bpk678 at gmail.com  Thu Aug  4 11:55:46 2016
From: bpk678 at gmail.com (brendan kearney)
Date: Thu, 4 Aug 2016 07:55:46 -0400
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <e181c5d0-4969-706f-d8bc-9a1d52e69ead@treenet.co.nz>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
 <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
 <3f248c59-67d4-2a84-359a-004de81b4d67@cinbesa.com.br>
 <e181c5d0-4969-706f-d8bc-9a1d52e69ead@treenet.co.nz>
Message-ID: <CAARxGtjOe5-bp=D2Tpb-BU5KVq0fPuuY=hE5YRn_jK2Q6MQtnw@mail.gmail.com>

At what point does buffer bloat set in?  I have a linux router with the
below sysctl tweaks load balancing with haproxy to 2 squid instances.  I
have 4 x 1Gb interfaces bonded and have bumped the ring buffers on RX and
TX to 1024 on all interfaces.

The squid servers run with almost the same hardware and tweaks, except the
ring buffers have only been bumped to 512.

DSL Reports has a speed test page that supposedly finds and quantifies
buffer bloat and my setup does not introduce it, per their tests.

I am only running a home internet connection (50 down x 15 up) but have a
wonderful browsing experience.  I imagine scale of bandwidth might be a
factor, but have no idea where buffer bloat begins to set in.

# Favor low latency over high bandwidth
net.ipv4.tcp_low_latency = 1

# Use the full range of ports.
net.ipv4.ip_local_port_range = 1025 65535

# Maximum number of open files per process; default 1048576
#fs.nr_open = 10000000

# Increase system file descriptor limit; default 402289
fs.file-max = 100000

# Maximum number of requests queued to a listen socket; default 128
net.core.somaxconn = 1024

# Maximum number of packets backlogged in the kernel; default 1000
#net.core.netdev_max_backlog = 2000
net.core.netdev_max_backlog = 4096

# Maximum number of outstanding syn requests allowed; default 128
#net.ipv4.tcp_max_syn_backlog = 2048
net.ipv4.tcp_max_syn_backlog = 16284

# Discourage Linux from swapping idle processes to disk (default = 60)
#vm.swappiness = 10

# Increase Linux autotuning TCP buffer limits
# Set max to 16MB for 1GE and 32M (33554432) or 54M (56623104) for 10GE
# Don't set tcp_mem itself! Let the kernel scale it based on RAM.
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.core.rmem_default = 16777216
net.core.wmem_default = 16777216
net.core.optmem_max = 40960
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216

# Increase Linux autotuning UDP buffer limits
net.ipv4.udp_mem = 4096 87380 16777216

# Make room for more TIME_WAIT sockets due to more clients,
# and allow them to be reused if we run out of sockets
# Also increase the max packet backlog
net.core.netdev_max_backlog = 50000
net.ipv4.tcp_max_syn_backlog = 30000
net.ipv4.tcp_max_tw_buckets = 2000000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 10

# Disable TCP slow start on idle connections
net.ipv4.tcp_slow_start_after_idle = 0

On Aug 4, 2016 2:17 AM, "Amos Jeffries" <squid3 at treenet.co.nz> wrote:

> On 4/08/2016 2:32 a.m., Heiler Bemerguy wrote:
> >
> > I think it doesn't really matter how much squid sets its default buffer.
> > The linux kernel will upscale to the maximum set by the third option.
> > (and the TCP Window Size will follow that)
> >
> > net.ipv4.tcp_wmem = 1024 32768 8388608
> > net.ipv4.tcp_rmem = 1024 32768 8388608
> >
>
> Having large system buffers like that just leads to buffer bloat
> problems. Squid is still the bottleneck if it is sending only 4KB each
> I/O cycle to the client - no matter how much is already received by
> Squid, or stuck in kernel queues waiting to arrive to Squid. The more
> heavily loaded the proxy is the longer each I/O cycle gets as all
> clients get one slice of the cycle to do whatever processing they need
> done.
>
> The buffers limited by HTTP_REQBUF_SZ are not dynamic so its not just a
> minimum. Nathan found a 300% speed increase from a 3x buffer size
> increase. Which is barely noticable (but still present) on small
> responses, but very noticable with large transactions.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160804/b7e0c140/attachment.htm>

From squid3 at treenet.co.nz  Thu Aug  4 12:07:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 5 Aug 2016 00:07:36 +1200
Subject: [squid-users] Squid NTLM AD Group Delay Pools
In-Reply-To: <43af660a-58d3-1736-3761-674a760ef5a3@gmail.com>
References: <43af660a-58d3-1736-3761-674a760ef5a3@gmail.com>
Message-ID: <216a60fc-3ab3-61bd-5056-fbe0d5d8b103@treenet.co.nz>

On 4/08/2016 10:16 p.m., Garth wrote:
> Hi All
> 
> I am struggling with delay pools and Group AD. I have managed to narrow
> down the problem to the AD Groups. If I do user auth, the delay pool
> works perfectly. I have tried multiple groups from old to new just
> incase. The AD Groups work for normal site access in the http_access
> rules etc.
> 
> Is there a known issue with this?

Yes. See the FAQ:
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Fast_and_Slow_ACLs>

> Is there a way to confirm the group
> lookup is correct by the squid/winbind?
> 

By running your group helper manually from the command line. Entering
the username (in NTLM format) and group nam, separated by a space.


> Squid Cache: Version 3.1.23
> 
> Centos 6.8
> 

There is one other catch with older Squid RHEL/CentOS packages. RHEL
used to patch Squid so the cache_effective_group directive had a default
value. This actively prevents Squid being setup as a member of the
winbind_priv group in addition to its normal 'proxy' or 'nobody' group.
You have to build your own proxy without that patch to use Winbind on
RHEL and CentOS.

I see that you are using the LDAP helper (not Winbinid helper you said
you were). So this may not be an issue, but YMMV.

> external_acl_type ldap_group %LOGIN /usr/lib64/squid/squid_ldap_group -R
> -b "dc=example,dc=example" -f
> "(&(sAMAccountName=%v)(memberOf=cn=%a,ou=Security,ou=groups,dc=example,dc=example))"
> -D test at EXAMPLE.EXAMPLE -w testing -h 192.168.1.254
> 
> auth_param ntlm program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 50

:-( this month is the 10-year anniversary since MiS announced NTLM was
being deprecated and removed from their software. And the 5-year
anniversary since that process was apparently completed. It is very sad
to see such a broken protocol still being used.


> auth_param basic program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-basic
> auth_param basic children 50
> 
> acl proxyusers-delaypool external ldap_group proxyusers-delaypool
> acl proxyusers-nondelaypool external ldap_group proxyusers-nondelaypool
> acl ftp.is url_regex ftp.is.co.za
> 
> acl socialsites url_regex "/etc/squid/socialsites.txt"
> 
> In the socialsites is the following:
> 
> .facebook.com
> .facebook.co.za
> .facebook.com:443
> .youtube.com:443
> .googlevideo.
> .fbcdn.net
> .akamaihd.net
> .vimeocdn.com:443
> 
> delay_pools 4
> delay_class 1 1
> delay_class 2 2
> delay_class 3 2
> delay_class 4 1
> delay_parameters 1 244000/552000
> delay_parameters 2 524000/525000 524000/525000
> delay_parameters 3 244000/254000 244000/254000
> delay_parameters 4 244000/552000
> delay_access 1 allow socialsites proxyusers-delaypool
> delay_access 2 allow proxyusers-nondelaypool
> delay_access 3 allow proxyusers-delaypool
> delay_access 4 allow ftp.is proxyusers-delaypool
> 
> I am testing via wget and proxy input details into the bash profile. I
> can confirm the username appears in the squid logs.
> 
> Any ideas?\

With Squid-3.1 you are limited to running the group lookup ACL in one of
the slow access control. Usually http_access. Then hoping that it stays
in memory long enough for the delay_access lookup to find it there and
not "fail" because no lookup is possible.

With the recent Squid versions you can make a wrapper script** that
returns the group names to Squid-3.5 as annotations like ' group="Foo"
', and you have a 'note' type ACL checking the groups in delay_access.

** if you (or anyone) want to try patching the helper to do it without a
wrapper that would be very welcome for merging to Squid-4.

Amos



From ht at inf.ed.ac.uk  Thu Aug  4 12:37:59 2016
From: ht at inf.ed.ac.uk (Henry S. Thompson)
Date: Thu, 04 Aug 2016 13:37:59 +0100
Subject: [squid-users] Seeking insight into zeros,
	negative values in log: 2.6.STABLE18
In-Reply-To: <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz> (Amos
 Jeffries's message of "Thu\, 4 Aug 2016 23\:34\:47 +1200")
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
 <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>
Message-ID: <f5blh0cpv4o.fsf@troutbeck.inf.ed.ac.uk>

Thanks for your patience with this, but still not quite getting it.

I thought there were two cases:

  1) Client drops the connection before the interaction is complete ==
     log shows HTTP result code 000, almost always size 0 as well;

  2) Interaction completed successfully == HTTP result code as from
     cache or remote, size as sent to client.

See below how I can't make that fit with your reply

Amos Jeffries writes:

>>>>  2) Leaving aside those cases, I see a modest handful (1 in 7000) of 0
>>>>     values in the size field, e.g.
>>>>
>>>>     1402741879.726 114 ... TCP_MISS/200 0 GET http://... DIRECT/... image/gif
>>>>     1402771557.693 176 ... TCP_HIT/200 0 GET http://... NONE/- image/gif
>>>>
>>>>     How should these be understood?
>>>
>>> A response with no body payload. It happens. Usually with "web bug" type
>>> images used for tracking.
>>> Or maybe the image was something like a captcha and the script producing
>>> it crashed with no data sent.
>> 
>> But documentation claims size field includes headers, and clearly
>> (image/gif) at least a Content-type header was sent...
>
> Nope. The reply message header (maybe more, or not) was received from
> the server but not sent to the client. The second case it only got as
> far as loading from disk and not yet sending.
>
> At the lowest level it was likely the attempt to write(2) those reply
> details to the client that detected the connection was closed/aborted
> already by the other end.

So the simple story I added at the top is wrong, and I should instead
understand that

  1') Log shows size 0 means client dropped the connection before the
      interaction was complete (HTTP result code 000 vs. something else is
      just a question of when the drop was detected);

  2) Interaction completed successfully == HTTP result code as from
     cache or remote, size as sent to client.  0 size can _never_ mean
     all is well, server result was empty, because if all is well at
     least some header info will have been sent.

>>>>  3) I'm seeing very small numbers (1 in 100000) of negative durations, e.g.
>>>>
>>>>     1402744620.389 -70 ... TCP_MISS/200 1882 GET http://... DIRECT/... text/xml
>>>>     
>>>>     How should these be understood?
>>>
>>> The system clock on your machine went backwards between the request
>>> arriving and the response being completely sent. Check for issues in
>>> your NTP setup.
>> 
>> 1000s of times a day?  Seems . . . unlikely.  But I'll try to get the
>> sys admin people responsible to investigate.
>
> Squid's simply doing a time fetch from the kernel and subtracting
> Start-time from End-time to get a negative.
> Note that its on the scale of ~100 milliseconds.

Sorry but I still don't see how two successive fetchs could result in a
decrement (w/o an NTP intervention).  

The negative numbers I'm seeing range up into the low 1000s (of msec,
right?  That's what the squid documentation says, IIRC).

Did you really mean "~100 _milliseconds_"?  My understanding was that
kernel time differences were typically accurate to ~100 _nanoseconds_.

If you can easily tell me where to look in the source, obviously that's
what I should do....

ht
-- 
       Henry S. Thompson, School of Informatics, University of Edinburgh
      10 Crichton Street, Edinburgh EH8 9AB, SCOTLAND -- (44) 131 650-4440
                Fax: (44) 131 650-4587, e-mail: ht at inf.ed.ac.uk
                       URL: http://www.ltg.ed.ac.uk/~ht/
 [mail from me _always_ has a .sig like this -- mail without it is forged spam]


From heiler.bemerguy at cinbesa.com.br  Thu Aug  4 13:08:06 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Thu, 4 Aug 2016 10:08:06 -0300
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <e181c5d0-4969-706f-d8bc-9a1d52e69ead@treenet.co.nz>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
 <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
 <3f248c59-67d4-2a84-359a-004de81b4d67@cinbesa.com.br>
 <e181c5d0-4969-706f-d8bc-9a1d52e69ead@treenet.co.nz>
Message-ID: <2a2ea76d-ef4c-7335-8c1c-1700a0c0ec73@cinbesa.com.br>


Sorry Amos, but I've tested with modifying JUST these two sysctl 
parameters and the difference is huge.

Without maximum tcp buffers set to 8MB, I got a 110KB/s download speed, 
and with a 8MB kernel buffer I got a 9.5MB/s download speed (via squid, 
of course).

I think it has to do with the TCP maximum Window Size, the kernel can 
set on a connection.


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 04/08/2016 03:16, Amos Jeffries escreveu:
> On 4/08/2016 2:32 a.m., Heiler Bemerguy wrote:
>> I think it doesn't really matter how much squid sets its default buffer.
>> The linux kernel will upscale to the maximum set by the third option.
>> (and the TCP Window Size will follow that)
>>
>> net.ipv4.tcp_wmem = 1024 32768 8388608
>> net.ipv4.tcp_rmem = 1024 32768 8388608
>>
> Having large system buffers like that just leads to buffer bloat
> problems. Squid is still the bottleneck if it is sending only 4KB each
> I/O cycle to the client - no matter how much is already received by
> Squid, or stuck in kernel queues waiting to arrive to Squid. The more
> heavily loaded the proxy is the longer each I/O cycle gets as all
> clients get one slice of the cycle to do whatever processing they need done.
>
> The buffers limited by HTTP_REQBUF_SZ are not dynamic so its not just a
> minimum. Nathan found a 300% speed increase from a 3x buffer size
> increase. Which is barely noticable (but still present) on small
> responses, but very noticable with large transactions.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From marcus.kool at urlfilterdb.com  Thu Aug  4 13:38:24 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 4 Aug 2016 10:38:24 -0300
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <2a2ea76d-ef4c-7335-8c1c-1700a0c0ec73@cinbesa.com.br>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
 <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
 <3f248c59-67d4-2a84-359a-004de81b4d67@cinbesa.com.br>
 <e181c5d0-4969-706f-d8bc-9a1d52e69ead@treenet.co.nz>
 <2a2ea76d-ef4c-7335-8c1c-1700a0c0ec73@cinbesa.com.br>
Message-ID: <7891042f-cf94-08b8-61bc-542bea58946d@urlfilterdb.com>



On 08/04/2016 10:08 AM, Heiler Bemerguy wrote:
>
> Sorry Amos, but I've tested with modifying JUST these two sysctl parameters and the difference is huge.
>
> Without maximum tcp buffers set to 8MB, I got a 110KB/s download speed, and with a 8MB kernel buffer I got a 9.5MB/s download speed (via squid, of course).
>
> I think it has to do with the TCP maximum Window Size, the kernel can set on a connection.

With these tuning parameters it is always important to look at the bandwidth*latency product.
I see that you are from Brasil and I know from experience that latencies to Europe are 230+ ms and latencies to USA vary between 80 and 200 ms.
I believe that the large variation in latency is due to the limited international capacity of Brasil (the Level3 link from the SP-IX to USA is most of the day 90+% utilized).

Marcus



From rousskov at measurement-factory.com  Thu Aug  4 15:20:29 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 Aug 2016 09:20:29 -0600
Subject: [squid-users] SSLBump just not working
In-Reply-To: <CABs_asmxA5cbCH6gYbXxn=nqRG3PzxNKMe7rHdTovgdU0pgfPw@mail.gmail.com>
References: <CABs_asnhvDtviza-Ew-Fuj2==dezjjq-FLphFWesOASHFeF=FA@mail.gmail.com>
 <c9467f58-6dda-edc1-1698-8534a3c9b053@treenet.co.nz>
 <57A1FC17.2050700@measurement-factory.com>
 <CABs_asmxA5cbCH6gYbXxn=nqRG3PzxNKMe7rHdTovgdU0pgfPw@mail.gmail.com>
Message-ID: <57A35D3D.1020709@measurement-factory.com>

On 08/03/2016 08:45 PM, JR Dalrymple wrote:

> To be brutally honest the whole concept is still a bit lost on me

[rant]Admitting one's limitations is often the most difficult first
step, but please do not stop here! Suggestions for where to go next: Ask
good questions, do not accept answers you do not fully understand,
provide excellent debugging info, and carefully update Squid wiki as you
master the concept. Repeat as needed.

IMHO, without solid SslBump understanding and providing good debugging,
you confine yourself to the endless copy-pasting of random config
snippets that usually do something you do not want and do not do
something you do want. Your ability to troubleshoot problems (and there
will be problems!) approaches zero in this case.

Most Squid-related concepts are easy and can be brute-forced by
trial-and-error. SslBump is different.[/rant]


> I'm still having issues I'm afraid - albeit different issues. My problem
> now reads a lot like this guys issue:
> https://www.mail-archive.com/misc at openbsd.org/msg144692.html

That email thread does not have enough info to know what the problem
really is and contains a seemingly bogus (or at least very poorly
detailed) solution. In other words, this is one of the many SslBump
threads you may be better off ignoring for now.


> My browser just times out and no
> auto-generated certificate is ever generated. 

> ssl_bump stare all
> ssl_bump bump all

Sounds like a good start to me, provided you _understand_ what these
rules do and why this simple configuration is equivalent to the more
complex one!


> I've
> turned off the debugging as I wasn't getting anything terribly useful
> out of it.

That's fine if you want folks to keep guessing what your problem is. If
you want more efficient help, use the latest Squid, isolate the problem
to a single HTTPS transaction, and share the corresponding ALL,9 log:

http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction


HTH,

Alex.



From jr at jrssite.com  Fri Aug  5 02:13:21 2016
From: jr at jrssite.com (JR Dalrymple)
Date: Fri, 05 Aug 2016 02:13:21 +0000
Subject: [squid-users] SSLBump just not working
In-Reply-To: <57A35D3D.1020709@measurement-factory.com>
References: <CABs_asnhvDtviza-Ew-Fuj2==dezjjq-FLphFWesOASHFeF=FA@mail.gmail.com>
 <c9467f58-6dda-edc1-1698-8534a3c9b053@treenet.co.nz>
 <57A1FC17.2050700@measurement-factory.com>
 <CABs_asmxA5cbCH6gYbXxn=nqRG3PzxNKMe7rHdTovgdU0pgfPw@mail.gmail.com>
 <57A35D3D.1020709@measurement-factory.com>
Message-ID: <CABs_asmta43FptHuC4coxTPvus+kpFKbdxcvAinOD1qwCZyLbg@mail.gmail.com>

On Thu, Aug 4, 2016 at 10:20 AM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 08/03/2016 08:45 PM, JR Dalrymple wrote:
>
> > To be brutally honest the whole concept is still a bit lost on me
>
> [rant]Admitting one's limitations is often the most difficult first
> step, but please do not stop here! Suggestions for where to go next: Ask
> good questions, do not accept answers you do not fully understand,
> provide excellent debugging info, and carefully update Squid wiki as you
> master the concept. Repeat as needed.
>
> IMHO, without solid SslBump understanding and providing good debugging,
> you confine yourself to the endless copy-pasting of random config
> snippets that usually do something you do not want and do not do
> something you do want. Your ability to troubleshoot problems (and there
> will be problems!) approaches zero in this case.
>
> Most Squid-related concepts are easy and can be brute-forced by
> trial-and-error. SslBump is different.[/rant]
>
>
> > I'm still having issues I'm afraid - albeit different issues. My problem
> > now reads a lot like this guys issue:
> > https://www.mail-archive.com/misc at openbsd.org/msg144692.html
>
> That email thread does not have enough info to know what the problem
> really is and contains a seemingly bogus (or at least very poorly
> detailed) solution. In other words, this is one of the many SslBump
> threads you may be better off ignoring for now.
>
>
> > My browser just times out and no
> > auto-generated certificate is ever generated.
>
> > ssl_bump stare all
> > ssl_bump bump all
>
> Sounds like a good start to me, provided you _understand_ what these
> rules do and why this simple configuration is equivalent to the more
> complex one!
>
>
> > I've
> > turned off the debugging as I wasn't getting anything terribly useful
> > out of it.
>
> That's fine if you want folks to keep guessing what your problem is. If
> you want more efficient help, use the latest Squid, isolate the problem
> to a single HTTPS transaction, and share the corresponding ALL,9 log:
>
>
> http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction
>
>
> HTH,
>
> Alex.
>
>
Thanks for the encouragement Alex,

I was doing single transaction debugging all along as this is currently
configured in a lab with a single client.

I've gotten it working at this point, but not due to diligent debugging I'm
afraid - more just a lucky shot in the dark. I reconfigured my system and
lab network to perform the bump on intercepted traffic. It *just works*. I
honestly don't care to backtrack and debug direct proxy requests as it
wasn't part of my planned end-state anyway.

For posterity's sake, here are the relevant parts of my working
configuration:

/etc/pf.conf:
pass in proto tcp to any port 80 divert-to 127.0.0.1 port 3128
pass in proto tcp to any port 443 divert-to 127.0.0.1 port 3129

squid.conf:
http_port 127.0.0.1:3128 intercept
https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/ssl/CA.pem

# /usr/local/squid/sbin/squid -v
Squid Cache: Version 3.5.20
Service Name: squid
configure options:  '--enable-icmp' '--enable-delay-pools'
'--enable-pf-transparent' '--enable-ssl-crtd' '--enable-auth'
'--with-openssl' --enable-ltdl-convenience

# uname -a
OpenBSD router.example.local 5.9 GENERIC#1761 amd64

Thanks again for all your help.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160805/b0227f36/attachment.htm>

From ano31415926535 at gmail.com  Fri Aug  5 02:25:42 2016
From: ano31415926535 at gmail.com (Do John)
Date: Fri, 5 Aug 2016 11:25:42 +0900
Subject: [squid-users] Squid automatically deleted the Proxy-Authenticate
	header
Message-ID: <CANBbT7AT9-sGZrW1i1m9X3H5EoRztUP-5=t88AUOxGJUYYDKeg@mail.gmail.com>

Hi All,

I'm Akhaice.
# And now, thanks for developers and maintainers at all times.

I'm using squid-3.5.16.
Recently I upgraded from squid-3.1 to squid-3.5.

And I've been using ICAP Server that has authentication function.

I configured that users needed authentication when they access web site.
The authentication function were provided by ICAP Server.

When ICAP Server return response code 407 with "Proxy-Authenticate" header,
Client browser was not able to receive this header and display
authentication dialog.

I captured packets in two places.
One is between squid and ICAP server. The other is between squid and Client
browser.

The header information is as follows.
==================================================
+ From ICAP Server to Squid

ICAP/1.0 200 OK
Server: TEST-ICAP
ISTag: "TEST-ICAP"
Date: Thu, 04 Aug 2016 03:05:34 GMT
Cache-Control: no-cache
Connection: close
Encapsulated: res-hdr=0, res-body=232

HTTP/1.1 407 Proxy Authentication Required
Proxy-Connection: close
Content-Type: text/html; charset=utf-8
Proxy-Authenticate: Basic realm="TESTAUTH"
Pragma: no-cache
Expires: Tue, 2 2001 20:00:00 GMT
Content-Length: 2349

==================================================
+ From Squid to Client browser

HTTP/1.1 407 Proxy Authentication Required
Date: Thu, 04 Aug 2016 03:05:34 GMT
Content-Type: text/html; charset=utf-8
Pragma: no-cache
Expires: Tue, 2 2001 20:00:00 GMT
Content-Length: 2349
X-Cache: MISS from proxyserver.local
Connection: keep-alive
==================================================

I found that Squid-3.5 automatically deleted the Proxy-Authenticate header.

Is it the correct behavior on squid-3.5 ?
How can I make client browser get Proxy-Authenticate header?

Thank you.

John Akhaice
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160805/808abf5c/attachment.htm>

From squid3 at treenet.co.nz  Fri Aug  5 10:54:48 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 5 Aug 2016 22:54:48 +1200
Subject: [squid-users] SSLBump just not working
In-Reply-To: <CABs_asmta43FptHuC4coxTPvus+kpFKbdxcvAinOD1qwCZyLbg@mail.gmail.com>
References: <CABs_asnhvDtviza-Ew-Fuj2==dezjjq-FLphFWesOASHFeF=FA@mail.gmail.com>
 <c9467f58-6dda-edc1-1698-8534a3c9b053@treenet.co.nz>
 <57A1FC17.2050700@measurement-factory.com>
 <CABs_asmxA5cbCH6gYbXxn=nqRG3PzxNKMe7rHdTovgdU0pgfPw@mail.gmail.com>
 <57A35D3D.1020709@measurement-factory.com>
 <CABs_asmta43FptHuC4coxTPvus+kpFKbdxcvAinOD1qwCZyLbg@mail.gmail.com>
Message-ID: <9ae277aa-b036-23b2-3d51-bfdb19ff93e1@treenet.co.nz>

On 5/08/2016 2:13 p.m., JR Dalrymple wrote:
> 
> For posterity's sake, here are the relevant parts of my working
> configuration:
> 
> /etc/pf.conf:
> pass in proto tcp to any port 80 divert-to 127.0.0.1 port 3128
> pass in proto tcp to any port 443 divert-to 127.0.0.1 port 3129
> 
> squid.conf:
> http_port 127.0.0.1:3128 intercept
> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/ssl/CA.pem
> 

FYI: Since OpenBSD 4.4+ the PF divert-to rule performs their
implementation of TPROXY. So technically it is more correct to configure
"tproxy" option on the listening ports. But the "intercept" will also
work - it just makes Squid behave like a NAT instead of fully transparent.

Also, both styles can handle IPv6 as well as IPv4. That is currently
limited only by your explicit use of 127.0.0.1 in the rules and port
declarations.

Amos



From squid3 at treenet.co.nz  Fri Aug  5 11:23:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 5 Aug 2016 23:23:27 +1200
Subject: [squid-users] Seeking insight into zeros,
 negative values in log: 2.6.STABLE18
In-Reply-To: <f5blh0cpv4o.fsf@troutbeck.inf.ed.ac.uk>
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
 <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>
 <f5blh0cpv4o.fsf@troutbeck.inf.ed.ac.uk>
Message-ID: <ec9d7dd1-99f6-91b4-ff6d-7b2f4ed95bd8@treenet.co.nz>

On 5/08/2016 12:37 a.m., Henry S. Thompson wrote:
> Thanks for your patience with this, but still not quite getting it.
> 
> I thought there were two cases:
> 
>   1) Client drops the connection before the interaction is complete ==
>      log shows HTTP result code 000, almost always size 0 as well;
> 
>   2) Interaction completed successfully == HTTP result code as from
>      cache or remote, size as sent to client.
> 
> See below how I can't make that fit with your reply


#1 is correct but incomplete. The 000 status means dropped any time
before the status to be delivered became known. So while "incomplete" is
true, there are very short times in the transaction where "incomplete"
is still true but are logged with non-000 status and size 0.

NP: There are also later times during payload delivery where drop can
happen so incomplete is still true and both status and size have values.
Those are impossible to detect in HTTP/1.0, so another reason to upgrade
to HTTP/1.1 software (Squid-3.2+).

The difference in timing between all these state changes should be a
very, very small number of milliseconds. Enough to see differently in
logs sometimes but should not be something to worry about.


The duration column is more important on these error entries as it shows
the user-visible latency. If that has big values (relative to your
usually expected network latency to the server) then its probably a sign
of network congestion slowing the TCP handshake or DNS lag. Not Squid
problems directly, but something to fix nevertheless.

Amos



From squid3 at treenet.co.nz  Fri Aug  5 11:59:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 5 Aug 2016 23:59:49 +1200
Subject: [squid-users] Squid performance not able to drive a 1Gbps
 internet link
In-Reply-To: <CAARxGtjOe5-bp=D2Tpb-BU5KVq0fPuuY=hE5YRn_jK2Q6MQtnw@mail.gmail.com>
References: <57A158F1.6070909@it.alliedpress.co.nz>
 <3386879c-1a22-cfea-28b7-be44f3196f8c@cinbesa.com.br>
 <c8eda1e4-deea-55bf-07b7-04ed28353881@treenet.co.nz>
 <2f4d96ba-e5e2-80c8-1065-f360ef6bad04@urlfilterdb.com>
 <3f248c59-67d4-2a84-359a-004de81b4d67@cinbesa.com.br>
 <e181c5d0-4969-706f-d8bc-9a1d52e69ead@treenet.co.nz>
 <CAARxGtjOe5-bp=D2Tpb-BU5KVq0fPuuY=hE5YRn_jK2Q6MQtnw@mail.gmail.com>
Message-ID: <9d6004ee-4feb-f43e-092a-f3aa27eb300d@treenet.co.nz>

On 4/08/2016 11:55 p.m., brendan kearney wrote:
> At what point does buffer bloat set in?  I have a linux router with the
> below sysctl tweaks load balancing with haproxy to 2 squid instances.  I
> have 4 x 1Gb interfaces bonded and have bumped the ring buffers on RX and
> TX to 1024 on all interfaces.

Exact timing will depend on your systems. AFAIU, it is the point where
control signals about congestion spend longer time in the traffic buffer
than needed for one endpoing to start re-sending packets and cause
congestino to get worse - a meltdown sort of behaviour.

If Squid takes say 1ms to process a I/O cycle, and reads 4KB per cycle.
Any server that send more than 4KB/ms will fill the buffer somewhat.
 (real I/O cycles are dynamic in timing, so theres no easily pointed at
time when bloat effects start to happen).

What I would expect to see with buffer limits set to 8MB. Is that on
transfer of objects greater than 8MB (ie 1GB) the first ~12MB happen
really fast, then speed drops off a cliff down to the slower rate Squid
is processing it out of the buffer.

With my fake numbers from above 1ms x 4KB ==> 4MB/sec. So in theory you
would get up to 64Mbps for the first chunk of large objects, then drop
down to 32Mbps. Then the Squid->client buffers start filling, and there
is a second drop down to whatever speed the client is emptying its side.

The issue is not visible on any object smaller than those cliff
boundaries. And may not be user visible at all unless total network load
reaches rates where the processing speed drops - which makes the speed
drop occur much sooner.
 In particular as I said earlier as Squid gets more processing load its
I/O cycle slow down, effectively shifting the speed 'cliff' to lower
thresholds.

 If there is any problem in the traffic, it will take 2 seconds for
Squid to become aware and even begin to start failure recovery.
Signals like end-of-object might arrive faster if the TCP stack is
optimized for control signals and cause up to 8MB of data at the end of
the object to be truncated. Other weird things like that start to happen
depending on the TCP stack implementation.

> 
> The squid servers run with almost the same hardware and tweaks, except the
> ring buffers have only been bumped to 512.
> 
> DSL Reports has a speed test page that supposedly finds and quantifies
> buffer bloat and my setup does not introduce it, per their tests.

The result there will depend on the size of object they test with. And
as Marcus mentioned the bandwidth product to the test server has an
impact on what data sizes will be required to find any problems.

> 
> I am only running a home internet connection (50 down x 15 up) but have a
> wonderful browsing experience.  I imagine scale of bandwidth might be a
> factor, but have no idea where buffer bloat begins to set in.

At values higher than your "50 down" by the sounds of it. I assume that
means 50 Mbps, which is well under the 64Mbps cliff your 8MB buffer causes.

It is rare to see a home connection that needs industrial scale
performance optimizations tuned with Squid. The bottlneck is that
Internet modem. Anything you configure internally greater than its
limits is effectively "infinity".

The bloat effects (if any) will be happening in your ISP's network.
Bloating is particularly nasty as it effects *others* sharing the
network worse than the individual causing it.


> # Maximum number of outstanding syn requests allowed; default 128
> #net.ipv4.tcp_max_syn_backlog = 2048
> net.ipv4.tcp_max_syn_backlog = 16284
> 

For each of these entries thare will be ~256 bytes of RAM used by Squid
to remember that it occured. Plus whatever your TCP stack uses.
Not big, but the latency effect of waiting for FD to become available in
Squid might be noticed in highly loaded network conditions.


> # Discourage Linux from swapping idle processes to disk (default = 60)
> #vm.swappiness = 10
> 
> # Increase Linux autotuning TCP buffer limits

AFAIK these are the limits. Not what is actually used. The latest Linux
versions contain algorithms designed by the buffer bloat research team
that prevent insane buffers being created even if the limits are set large.


Amos



From ht at inf.ed.ac.uk  Fri Aug  5 13:01:01 2016
From: ht at inf.ed.ac.uk (Henry S. Thompson)
Date: Fri, 05 Aug 2016 14:01:01 +0100
Subject: [squid-users] Seeking insight into zeros,
	negative values in log: 2.6.STABLE18
In-Reply-To: <ec9d7dd1-99f6-91b4-ff6d-7b2f4ed95bd8@treenet.co.nz> (Amos
 Jeffries's message of "Fri\, 5 Aug 2016 23\:23\:27 +1200")
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
 <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>
 <f5blh0cpv4o.fsf@troutbeck.inf.ed.ac.uk>
 <ec9d7dd1-99f6-91b4-ff6d-7b2f4ed95bd8@treenet.co.nz>
Message-ID: <f5bmvkrnzea.fsf@troutbeck.inf.ed.ac.uk>

Amos Jeffries writes:

> On 5/08/2016 12:37 a.m., Henry S. Thompson wrote:
>> Thanks for your patience with this, but still not quite getting it.
>> 
>> I thought there were two cases:
>> 
>>   1) Client drops the connection before the interaction is complete ==
>>      log shows HTTP result code 000, almost always size 0 as well;
>> 
>>   2) Interaction completed successfully == HTTP result code as from
>>      cache or remote, size as sent to client.
>> 
>> See below how I can't make that fit with your reply
>
> #1 is correct but incomplete. The 000 status means dropped any time
> before the status to be delivered became known. So while "incomplete" is
> true, there are very short times in the transaction where "incomplete"
> is still true but are logged with non-000 status and size 0.

Right, that's helpful, thanks.

> NP: There are also later times during payload delivery where drop can
> happen so incomplete is still true and both status and size have values.
> Those are impossible to detect in HTTP/1.0, so another reason to upgrade
> to HTTP/1.1 software (Squid-3.2+).

Understood.

> The difference in timing between all these state changes should be a
> very, very small number of milliseconds. Enough to see differently in
> logs sometimes but should not be something to worry about.

Right.

ht
-- 
       Henry S. Thompson, School of Informatics, University of Edinburgh
      10 Crichton Street, Edinburgh EH8 9AB, SCOTLAND -- (44) 131 650-4440
                Fax: (44) 131 650-4587, e-mail: ht at inf.ed.ac.uk
                       URL: http://www.ltg.ed.ac.uk/~ht/
 [mail from me _always_ has a .sig like this -- mail without it is forged spam]


From ht at inf.ed.ac.uk  Fri Aug  5 13:03:49 2016
From: ht at inf.ed.ac.uk (Henry S. Thompson)
Date: Fri, 05 Aug 2016 14:03:49 +0100
Subject: [squid-users] Seeking insight into zeros,
	negative values in log: 2.6.STABLE18
In-Reply-To: <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz> (Amos
 Jeffries's message of "Thu\, 4 Aug 2016 23\:34\:47 +1200")
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
 <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>
Message-ID: <f5binvfnz9m.fsf@troutbeck.inf.ed.ac.uk>

Amos wrote:
> HST wrote:
...
>> Amos wrote:
...
>>> HST wrote:
>>>>  3) I'm seeing very small numbers (1 in 100000) of negative durations, e.g.
>>>>
>>>>     1402744620.389 -70 ... TCP_MISS/200 1882 GET http://... DIRECT/... text/xml
>>>>     
>>>>     How should these be understood?
>>>
>>> The system clock on your machine went backwards between the request
>>> arriving and the response being completely sent. Check for issues in
>>> your NTP setup.
>> 
>> 1000s of times a day?  Seems . . . unlikely.  But I'll try to get the
>> sys admin people responsible to investigate.
>
> Squid's simply doing a time fetch from the kernel and subtracting
> Start-time from End-time to get a negative.
> Note that its on the scale of ~100 milliseconds.

Sorry but I still don't see how two successive fetchs could result in a
decrement (w/o an NTP intervention).  

The negative numbers I'm seeing range up into the low 1000s (of msec,
right?  That's what the squid documentation says, IIRC).

Did you really mean "~100 _milliseconds_"?  My understanding was that
kernel time differences were typically accurate to ~100 _nanoseconds_.

If you can easily tell me where to look in the source, obviously that's
what I should do....

ht
-- 
       Henry S. Thompson, School of Informatics, University of Edinburgh
      10 Crichton Street, Edinburgh EH8 9AB, SCOTLAND -- (44) 131 650-4440
                Fax: (44) 131 650-4587, e-mail: ht at inf.ed.ac.uk
                       URL: http://www.ltg.ed.ac.uk/~ht/
 [mail from me _always_ has a .sig like this -- mail without it is forged spam]


From ht at inf.ed.ac.uk  Fri Aug  5 13:09:02 2016
From: ht at inf.ed.ac.uk (Henry S. Thompson)
Date: Fri, 05 Aug 2016 14:09:02 +0100
Subject: [squid-users] Seeking insight into zeros,
	negative values in log: 2.6.STABLE18
In-Reply-To: <ec9d7dd1-99f6-91b4-ff6d-7b2f4ed95bd8@treenet.co.nz> (Amos
 Jeffries's message of "Fri\, 5 Aug 2016 23\:23\:27 +1200")
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
 <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>
 <f5blh0cpv4o.fsf@troutbeck.inf.ed.ac.uk>
 <ec9d7dd1-99f6-91b4-ff6d-7b2f4ed95bd8@treenet.co.nz>
Message-ID: <f5beg63nz0x.fsf@troutbeck.inf.ed.ac.uk>

Amos Jeffries writes:

> On 5/08/2016 12:37 a.m., Henry S. Thompson wrote:
>> Thanks for your patience with this, but still not quite getting it.
>> 
>> I thought there were two cases:
>> 
>>   1) Client drops the connection before the interaction is complete ==
>>      log shows HTTP result code 000, almost always size 0 as well;
>> 
>>   2) Interaction completed successfully == HTTP result code as from
>>      cache or remote, size as sent to client.
>> 
>> See below how I can't make that fit with your reply
>
> #1 is correct but incomplete. The 000 status means dropped any time
> before the status to be delivered became known. So while "incomplete" is
> true, there are very short times in the transaction where "incomplete"
> is still true but are logged with non-000 status and size 0.
>
> NP: There are also later times during payload delivery where drop can
> happen so incomplete is still true and both status and size have values.
> Those are impossible to detect in HTTP/1.0, so another reason to upgrade
> to HTTP/1.1 software (Squid-3.2+).

So is this a correct summary:

  Log shows size 0 iff client dropped the connection before the
  interaction was complete (HTTP result code 000 vs. something else is
  just a question of when the drop was detected);

  In other words, 0 size in the log can _never_ mean all is well, server
  result was empty, because if all is well at least some header info
  will have been sent.

ht
-- 
       Henry S. Thompson, School of Informatics, University of Edinburgh
      10 Crichton Street, Edinburgh EH8 9AB, SCOTLAND -- (44) 131 650-4440
                Fax: (44) 131 650-4587, e-mail: ht at inf.ed.ac.uk
                       URL: http://www.ltg.ed.ac.uk/~ht/
 [mail from me _always_ has a .sig like this -- mail without it is forged spam]


From squid3 at treenet.co.nz  Fri Aug  5 14:03:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 6 Aug 2016 02:03:24 +1200
Subject: [squid-users] Seeking insight into zeros,
 negative values in log: 2.6.STABLE18
In-Reply-To: <f5binvfnz9m.fsf@troutbeck.inf.ed.ac.uk>
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
 <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>
 <f5binvfnz9m.fsf@troutbeck.inf.ed.ac.uk>
Message-ID: <8b6f5ca7-eb06-981b-573d-045154ff420b@treenet.co.nz>

On 6/08/2016 1:03 a.m., Henry S. Thompson wrote:
> Amos wrote:
>> HST wrote:
> ...
>>> Amos wrote:
> ...
>>>> HST wrote:
>>>>>  3) I'm seeing very small numbers (1 in 100000) of negative durations, e.g.
>>>>>
>>>>>     1402744620.389 -70 ... TCP_MISS/200 1882 GET http://... DIRECT/... text/xml
>>>>>     
>>>>>     How should these be understood?
>>>>
>>>> The system clock on your machine went backwards between the request
>>>> arriving and the response being completely sent. Check for issues in
>>>> your NTP setup.
>>>
>>> 1000s of times a day?  Seems . . . unlikely.  But I'll try to get the
>>> sys admin people responsible to investigate.
>>
>> Squid's simply doing a time fetch from the kernel and subtracting
>> Start-time from End-time to get a negative.
>> Note that its on the scale of ~100 milliseconds.
> 
> Sorry but I still don't see how two successive fetchs could result in a
> decrement (w/o an NTP intervention).  

Yes. I could have been clearer by saying the value is likely to be some
few hundred milliseconds off what really happened.

> 
> The negative numbers I'm seeing range up into the low 1000s (of msec,
> right?  That's what the squid documentation says, IIRC).

Yes Squid logs show milliseconds. But...

> 
> Did you really mean "~100 _milliseconds_"?  My understanding was that
> kernel time differences were typically accurate to ~100 _nanoseconds_.
> 

Kernels at nanoseconds. Squid is working in milliseconds. Average
transactions are usually around 100ms and NTP jumps which are probably
behind this are in seconds or milliseconds.

So with NTP jumping around I' give it a rough estimate of the accuracy
being likely to be some 100's of ms different from reality.

> If you can easily tell me where to look in the source, obviously that's
> what I should do....

Sorry. With 2.6 I'm not sure where anything is. 3.x has a lot of change
since then, even 2.7 is significantly different.

In Squid-3 it is src/time.cc getCurrentTime() to fetch when the request
is done parsing, and again when log line is formatted - the value of
current_time stored at those points (not squid_time). With
tvSubMsec(T1(parsed time), T2(logged time)) output used as the duration
column.

So the Squid logs can contain negative duration under exactly four
conditions:
 1) server boot when (and only when) the BIOS clock is innacurate and
jumps around a bit.

 2) daylight savings changes. Only when the server is running in local
timezone clocks instead of proper UTC.

 3) UTC leap seconds/minutes that go backward. (once every six months
that might happen).

 4) NTP service adjusting the kernel clock backwards.

Since you say this is happening noticably often then its #4 and there is
something funky going on with NTP. The others are all at rare and
predictable times.

Amos



From squid3 at treenet.co.nz  Fri Aug  5 14:11:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 6 Aug 2016 02:11:02 +1200
Subject: [squid-users] Squid automatically deleted the
 Proxy-Authenticate header
In-Reply-To: <CANBbT7AT9-sGZrW1i1m9X3H5EoRztUP-5=t88AUOxGJUYYDKeg@mail.gmail.com>
References: <CANBbT7AT9-sGZrW1i1m9X3H5EoRztUP-5=t88AUOxGJUYYDKeg@mail.gmail.com>
Message-ID: <fd9f5bb5-7b83-dceb-dd59-085cff9fd7d6@treenet.co.nz>

On 5/08/2016 2:25 p.m., Do John wrote:
> Hi All,
> 
> I'm Akhaice.
> # And now, thanks for developers and maintainers at all times.
> 
> I'm using squid-3.5.16.
> Recently I upgraded from squid-3.1 to squid-3.5.
> 

Please upgrade to 3.5.20, or at least 3.5.19 if you can. There are quite
a few major bugs and security issues fixed in the latest releases.
 Though I don't expect the problem you are mentioning here to be one of
them.

> And I've been using ICAP Server that has authentication function.
> 
> I configured that users needed authentication when they access web site.
> The authentication function were provided by ICAP Server.
> 
> When ICAP Server return response code 407 with "Proxy-Authenticate" header,
> Client browser was not able to receive this header and display
> authentication dialog.
> 
> I captured packets in two places.
> One is between squid and ICAP server. The other is between squid and Client
> browser.
> 
> The header information is as follows.
> ==================================================
> + From ICAP Server to Squid
> 
> ICAP/1.0 200 OK
> Server: TEST-ICAP
> ISTag: "TEST-ICAP"
> Date: Thu, 04 Aug 2016 03:05:34 GMT
> Cache-Control: no-cache
> Connection: close
> Encapsulated: res-hdr=0, res-body=232
> 
> HTTP/1.1 407 Proxy Authentication Required
> Proxy-Connection: close
> Content-Type: text/html; charset=utf-8
> Proxy-Authenticate: Basic realm="TESTAUTH"
> Pragma: no-cache
> Expires: Tue, 2 2001 20:00:00 GMT
> Content-Length: 2349
> 
> ==================================================
> + From Squid to Client browser
> 
> HTTP/1.1 407 Proxy Authentication Required
> Date: Thu, 04 Aug 2016 03:05:34 GMT
> Content-Type: text/html; charset=utf-8
> Pragma: no-cache
> Expires: Tue, 2 2001 20:00:00 GMT
> Content-Length: 2349
> X-Cache: MISS from proxyserver.local
> Connection: keep-alive
> ==================================================
> 
> I found that Squid-3.5 automatically deleted the Proxy-Authenticate header.
> 
> Is it the correct behavior on squid-3.5 ?
> How can I make client browser get Proxy-Authenticate header?

Is this an explicit/forward proxy or reverse proxy or interceptor?

How did you have it working in 3.1? It should not have worked any
differently then either.

Amos



From ht at inf.ed.ac.uk  Fri Aug  5 15:20:30 2016
From: ht at inf.ed.ac.uk (Henry S. Thompson)
Date: Fri, 05 Aug 2016 16:20:30 +0100
Subject: [squid-users] Seeking insight into zeros,
	negative values in log: 2.6.STABLE18 -- SOLVED
In-Reply-To: <8b6f5ca7-eb06-981b-573d-045154ff420b@treenet.co.nz> (Amos
 Jeffries's message of "Sat\, 6 Aug 2016 02\:03\:24 +1200")
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
 <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>
 <f5binvfnz9m.fsf@troutbeck.inf.ed.ac.uk>
 <8b6f5ca7-eb06-981b-573d-045154ff420b@treenet.co.nz>
Message-ID: <f5b1t23nsxt.fsf_-_@troutbeck.inf.ed.ac.uk>

Amos Jeffries writes:

> On 6/08/2016 1:03 a.m., Henry S. Thompson wrote:
>> Amos wrote:
>>> HST wrote:
>> ...
>>>> Amos wrote:
>> ...
>>>>> HST wrote:
>>>>>>  3) I'm seeing very small numbers (1 in 100000) of negative durations, e.g.
...
>>>> 1000s of times a day?  Seems . . . unlikely.

Oops, my mistake -- that should have been (at most) 100s, not 1000s, per
day.

> ...
> So the Squid logs can contain negative duration under exactly four
> conditions:
> ...
>  4) NTP service adjusting the kernel clock backwards.
>
> Since you say this is happening noticably often then its #4 and there is
> something funky going on with NTP. The others are all at rare and
> predictable times.

On closer investigation, you are exactly right.  Here are the first two
columns (with the timestamp converted to human-readable form) for the
negative duration log lines starting at 0900 on the worst day on record,
3 years ago:

Tue 25 Jun 09:17:00 BST 2013 -281
Tue 25 Jun 09:17:00 BST 2013 -200
Tue 25 Jun 10:17:00 BST 2013 -644
Tue 25 Jun 10:17:00 BST 2013 -237
Tue 25 Jun 10:17:00 BST 2013 -388
Tue 25 Jun 10:17:00 BST 2013 -297
Tue 25 Jun 10:17:00 BST 2013 -259
Tue 25 Jun 11:16:59 BST 2013 -634
Tue 25 Jun 11:16:59 BST 2013 -644
Tue 25 Jun 11:16:59 BST 2013 -644
Tue 25 Jun 11:16:59 BST 2013 -871
Tue 25 Jun 11:16:59 BST 2013 -548
Tue 25 Jun 11:16:59 BST 2013 -901
Tue 25 Jun 11:16:59 BST 2013 -900
Tue 25 Jun 11:16:59 BST 2013 -905
Tue 25 Jun 11:16:59 BST 2013 -850
Tue 25 Jun 11:16:59 BST 2013 -865
Tue 25 Jun 11:16:59 BST 2013 -783
Tue 25 Jun 11:16:59 BST 2013 -858
Tue 25 Jun 11:16:59 BST 2013 -502
Tue 25 Jun 11:16:59 BST 2013 -378
Tue 25 Jun 11:16:59 BST 2013 -556
Tue 25 Jun 11:16:59 BST 2013 -61
Tue 25 Jun 11:17:00 BST 2013 -164
Tue 25 Jun 11:17:00 BST 2013 -179
Tue 25 Jun 11:17:00 BST 2013 -138
and so it goes on.

There's a cron job on the 4 cache machines that runs every hour, and we
now know at exactly what time :-).

Thanks again for your careful and detailed help,

ht
-- 
       Henry S. Thompson, School of Informatics, University of Edinburgh
      10 Crichton Street, Edinburgh EH8 9AB, SCOTLAND -- (44) 131 650-4440
                Fax (44) 131 650-4587, e-mail ht at inf.ed.ac.uk
                       URL http://www.ltg.ed.ac.uk/~ht/
 [mail from me _always_ has a .sig like this -- mail without it is forged spam]


From chio1990 at gmail.com  Sat Aug  6 09:56:29 2016
From: chio1990 at gmail.com (k simon)
Date: Sat, 6 Aug 2016 17:56:29 +0800
Subject: [squid-users] Range header is a hit ratio killer
Message-ID: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>

Hi,list,
   Code 206 is the most pain for our forwed proxy. Squid use 
?range_offset_limit? to process byte-range request. when set it "none", 
it has 2 wellknown issue:
1.  boost the traffic on the server side, we observed it's amplified 
500% compared to clients side on our box.
2.  it's always failed on a lossy link, and squid refetched it again and 
again.
   I've noticed that nginx have supported "byte-range cacheing" since 
1.9.8  by Module ngx_http_slice_module officially.
(1. 
http://nginx.org/en/docs/http/ngx_http_slice_module.html?_ga=1.140845234.106894549.1470474534
2. https://www.nginx.com/resources/admin-guide/content-caching/  ).
   The solution is not perfect, but it's really more usable than 
"range_offset_limit". The secret it's use a fixed size object replaced 
the whole file, and we can alter the request range offset and passed it 
to server; perhaps forward the origin range offset and cache a part of 
the object with a range key is a better idea. And squid should know how 
to make up those object and process the request with range header.
   And with a fixed size object to cache it may benefits to disk IO. 
Sounds it's similar like big-rock db concept, though I've not got 
successed with rock on FreeBSD nor ubuntu box.
   Does squid has some plan to support this method or have another solution?



Regards
Simon


From uhlar at fantomas.sk  Sun Aug  7 12:24:38 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 7 Aug 2016 14:24:38 +0200
Subject: [squid-users] Seeking insight into zeros,
 negative values in log: 2.6.STABLE18 -- SOLVED
In-Reply-To: <f5b1t23nsxt.fsf_-_@troutbeck.inf.ed.ac.uk>
References: <f5bk2fxrkaq.fsf@troutbeck.inf.ed.ac.uk>
 <1bae4dc6-5693-ea06-62ed-76eb494c3722@treenet.co.nz>
 <f5b7fbwrhdi.fsf@troutbeck.inf.ed.ac.uk>
 <978e7df7-6c34-0577-973c-129badb82d84@treenet.co.nz>
 <f5binvfnz9m.fsf@troutbeck.inf.ed.ac.uk>
 <8b6f5ca7-eb06-981b-573d-045154ff420b@treenet.co.nz>
 <f5b1t23nsxt.fsf_-_@troutbeck.inf.ed.ac.uk>
Message-ID: <20160807122438.GA2734@fantomas.sk>

>Amos Jeffries writes:
>> So the Squid logs can contain negative duration under exactly four
>> conditions:
>> ...
>>  4) NTP service adjusting the kernel clock backwards.
>>
>> Since you say this is happening noticably often then its #4 and there is
>> something funky going on with NTP. The others are all at rare and
>> predictable times.

On 05.08.16 16:20, Henry S. Thompson wrote:
>On closer investigation, you are exactly right.  Here are the first two
>columns (with the timestamp converted to human-readable form) for the
>negative duration log lines starting at 0900 on the worst day on record,
>3 years ago:

>Tue 25 Jun 09:17:00 BST 2013 -281
[...]
>Tue 25 Jun 11:16:59 BST 2013 -634
[...]
>Tue 25 Jun 11:17:00 BST 2013 -164
>and so it goes on.
>
>There's a cron job on the 4 cache machines that runs every hour, and we
>now know at exactly what time :-).

what cron job, ntpdate? if so, you should run ntpd instead. That one should
be able to manage time more precisely.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
My mind is like a steel trap - rusty and illegal in 37 states. 


From squid3 at treenet.co.nz  Sun Aug  7 14:12:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 8 Aug 2016 02:12:49 +1200
Subject: [squid-users] Range header is a hit ratio killer
In-Reply-To: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
References: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
Message-ID: <5bf69bb8-8864-a4bf-abf1-003c5f3d7c3b@treenet.co.nz>

On 6/08/2016 9:56 p.m., k simon wrote:
> Hi,list,
>   Code 206 is the most pain for our forwed proxy. Squid use
> ?range_offset_limit? to process byte-range request. when set it "none",
> it has 2 wellknown issue:
> 1.  boost the traffic on the server side, we observed it's amplified
> 500% compared to clients side on our box.

To which the answer currently is to see if enabling collapsed_forwarding
works okay for your needs.

> 2.  it's always failed on a lossy link, and squid refetched it again and
> again.
>   I've noticed that nginx have supported "byte-range cacheing" since
> 1.9.8  by Module ngx_http_slice_module officially.
> (1.
> http://nginx.org/en/docs/http/ngx_http_slice_module.html?_ga=1.140845234.106894549.1470474534
> 

So? what relevance does other software features have to Squid behaviour?

 <http://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F>

... to be fair the storage code in Squid is a bit hairy in places. So
paying for it to be done is unlikely to be cheap. But still, waiting
wont fix the problem. We nearly go there in Squid-2.7, but the
experiment there is not able to completely port across to Squid-3 and
had some important problems anyway.


> 2. https://www.nginx.com/resources/admin-guide/content-caching/  ).
>   The solution is not perfect, but it's really more usable than
> "range_offset_limit". The secret it's use a fixed size object replaced
> the whole file, and we can alter the request range offset and passed it
> to server;

Ah, thats what range_offset_limit does today. Updates the server request
to say "deliver all of it" and stores the response in a file the size of
the whole expected response the server informs will be arriving.

The reason you are seeing that 500% increase in bandwidth is that
multiple Range requests arrive while the initial part of the first
response is still arriving back to Squid, so 5 of them get sent through
to the server. When that first one finishes, its object becomes
available for use as a HIT and followup Range requests get bits of it
(so you dont see 600% -> millions of % bandwidth increase).

collapsed_fowarding alters this by letting the first response be used by
other requests while it is still incomplete. But YMMV regarding the
savings and CF affects all traffic, so it may cause behaviours you dont
want on other types of request. Worth a try though.


> perhaps forward the origin range offset and cache a part of
> the object with a range key is a better idea.
> And squid should know how
> to make up those object and process the request with range header.
>   And with a fixed size object to cache it may benefits to disk IO.
> Sounds it's similar like big-rock db concept, though I've not got
> successed with rock on FreeBSD nor ubuntu box.
>   Does squid has some plan to support this method or have another solution?
> 

squid is software. It doesn't have its own plans (at least I hope not).

I'm not aware of any plans specifically to add Range caching any time
soon. Ideas for how to do it get thrown around in squid-dev a couple of
times a year, so lots of ideas but so far nothing concrete has come out
of it. Yes rock and/or memory caches are looking like the most easily
adapted cache types to enable storing partial objects in, someone still
has to do the actual coding work though.

Amos



From eliezer at ngtech.co.il  Sun Aug  7 13:20:41 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 7 Aug 2016 16:20:41 +0300
Subject: [squid-users] Range header is a hit ratio killer
In-Reply-To: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
References: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
Message-ID: <01e101d1f0ae$7f193830$7d4ba890$@ngtech.co.il>

Hey Simon,

I do not know the plans but it will depend on couple things which can fit to one case but not the other.
The assumption that we can fetch any part of the object is the first step for any solution what so ever.
However it is not guaranteed that each request will be public.

The idea of static chunks exists for many years in many applications and in many forms and YouTube videos player uses a similar idea. Google video clients and servers uses a bytes "range" request in the url rather then in the request header.
Technically it would be possible to implement such an idea but it has it's own cost.
Eventually if the file is indeed public(what squid was designed to cache) then it might not be of a big problem.
Depends on the target sites a the solution will be different.
Before deciding on a specific solution my preferred path is to analyze the requests.

By observing amplified traffic of 500% to  clients side you mean that the incoming traffic to the server is 500% compared to the output towards the clients?
If so I think that there might be a "smarter" solution then 206 range offset limit.
The old method of prefetching works pretty good in many cases. From what you describe it might have better luck then the plain "fetch everything on the wire in real time".

I cannot guarantee that prefetching is the right solution for you but I think that a case like this deserves couple eyes to understand if there is a right way to handle the situation.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of k simon
Sent: Saturday, August 6, 2016 12:56 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Range header is a hit ratio killer

Hi,list,
   Code 206 is the most pain for our forwed proxy. Squid use ?range_offset_limit? to process byte-range request. when set it "none", it has 2 wellknown issue:
1.  boost the traffic on the server side, we observed it's amplified 500% compared to clients side on our box.
2.  it's always failed on a lossy link, and squid refetched it again and again.
   I've noticed that nginx have supported "byte-range cacheing" since
1.9.8  by Module ngx_http_slice_module officially.
(1. 
http://nginx.org/en/docs/http/ngx_http_slice_module.html?_ga=1.140845234.106894549.1470474534
2. https://www.nginx.com/resources/admin-guide/content-caching/  ).
   The solution is not perfect, but it's really more usable than "range_offset_limit". The secret it's use a fixed size object replaced the whole file, and we can alter the request range offset and passed it to server; perhaps forward the origin range offset and cache a part of the object with a range key is a better idea. And squid should know how to make up those object and process the request with range header.
   And with a fixed size object to cache it may benefits to disk IO. 
Sounds it's similar like big-rock db concept, though I've not got successed with rock on FreeBSD nor ubuntu box.
   Does squid has some plan to support this method or have another solution?



Regards
Simon
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Sun Aug  7 18:22:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 8 Aug 2016 00:22:57 +0600
Subject: [squid-users] Range header is a hit ratio killer
In-Reply-To: <5bf69bb8-8864-a4bf-abf1-003c5f3d7c3b@treenet.co.nz>
References: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
 <5bf69bb8-8864-a4bf-abf1-003c5f3d7c3b@treenet.co.nz>
Message-ID: <d2f19104-3fb1-85a4-9076-21461c953533@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
So,

the overall answer is "NO".

You can use Store-ID + collapsed forwarding functionality to achieve
something your want. May be together, may be separate. Hard luck :)

But this is your own problem. No one will solve the problem without the
infusion of large amounts of money to make it interesting.

:)


07.08.2016 20:12, Amos Jeffries ?????:
> On 6/08/2016 9:56 p.m., k simon wrote:
>> Hi,list,
>>   Code 206 is the most pain for our forwed proxy. Squid use
>> ?range_offset_limit? to process byte-range request. when set it "none",
>> it has 2 wellknown issue:
>> 1.  boost the traffic on the server side, we observed it's amplified
>> 500% compared to clients side on our box.
>
> To which the answer currently is to see if enabling collapsed_forwarding
> works okay for your needs.
>
>> 2.  it's always failed on a lossy link, and squid refetched it again and
>> again.
>>   I've noticed that nginx have supported "byte-range cacheing" since
>> 1.9.8  by Module ngx_http_slice_module officially.
>> (1.
>>
http://nginx.org/en/docs/http/ngx_http_slice_module.html?_ga=1.140845234.106894549.1470474534
>>
>
> So? what relevance does other software features have to Squid behaviour?
>
> 
<http://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F>
>
> ... to be fair the storage code in Squid is a bit hairy in places. So
> paying for it to be done is unlikely to be cheap. But still, waiting
> wont fix the problem. We nearly go there in Squid-2.7, but the
> experiment there is not able to completely port across to Squid-3 and
> had some important problems anyway.
>
>
>> 2. https://www.nginx.com/resources/admin-guide/content-caching/  ).
>>   The solution is not perfect, but it's really more usable than
>> "range_offset_limit". The secret it's use a fixed size object replaced
>> the whole file, and we can alter the request range offset and passed it
>> to server;
>
> Ah, thats what range_offset_limit does today. Updates the server request
> to say "deliver all of it" and stores the response in a file the size of
> the whole expected response the server informs will be arriving.
>
> The reason you are seeing that 500% increase in bandwidth is that
> multiple Range requests arrive while the initial part of the first
> response is still arriving back to Squid, so 5 of them get sent through
> to the server. When that first one finishes, its object becomes
> available for use as a HIT and followup Range requests get bits of it
> (so you dont see 600% -> millions of % bandwidth increase).
>
> collapsed_fowarding alters this by letting the first response be used by
> other requests while it is still incomplete. But YMMV regarding the
> savings and CF affects all traffic, so it may cause behaviours you dont
> want on other types of request. Worth a try though.
>
>
>> perhaps forward the origin range offset and cache a part of
>> the object with a range key is a better idea.
>> And squid should know how
>> to make up those object and process the request with range header.
>>   And with a fixed size object to cache it may benefits to disk IO.
>> Sounds it's similar like big-rock db concept, though I've not got
>> successed with rock on FreeBSD nor ubuntu box.
>>   Does squid has some plan to support this method or have another
solution?
>>
>
> squid is software. It doesn't have its own plans (at least I hope not).
>
> I'm not aware of any plans specifically to add Range caching any time
> soon. Ideas for how to do it get thrown around in squid-dev a couple of
> times a year, so lots of ideas but so far nothing concrete has come out
> of it. Yes rock and/or memory caches are looking like the most easily
> adapted cache types to enable storing partial objects in, someone still
> has to do the actual coding work though.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXp3yAAAoJENNXIZxhPexGDEYH/AjM5hD4ahsF9IXsMo5PrWLE
nlKCloampXBur7o1PD2uOynU35ayV2wjJlBU9P9uQrux5lus0FCHt0yD/X9rEJ4J
E1AcShLUfK6ezMdSKnn5tylfTg1+4U08/hJz3+E9PGxA//peoPVovgHu/WuFXM4X
2NtSaVeib1O7QI2Dr0yRGZKKuJ9C2/YZqTAgjUa8rT2JZAsi5bzVU4WoaXwxklZD
OolueguA63dKo3n86oAR1W0jmPoXQeHvPuleYbGLUwWVBBlRJdCHpKfVnh/D+ni4
w0hR0MRBZzS8dVNQTrTCCzuFoIH1VjHhYKKZaIQEgPpo7AsvtABNTxLM7MJmqRY=
=UX3s
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160808/9bbb2d26/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160808/9bbb2d26/attachment.key>

From eliezer at ngtech.co.il  Mon Aug  8 01:17:44 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 8 Aug 2016 04:17:44 +0300
Subject: [squid-users] Range header is a hit ratio killer
In-Reply-To: <d2f19104-3fb1-85a4-9076-21461c953533@gmail.com>
References: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
 <5bf69bb8-8864-a4bf-abf1-003c5f3d7c3b@treenet.co.nz>
 <d2f19104-3fb1-85a4-9076-21461c953533@gmail.com>
Message-ID: <02d401d1f112$aab5c6c0$00215440$@ngtech.co.il>

Hey Yuri,

 

The issue is not money alone?

To my understanding Squid is written in C++ and is very complex, due to this it requires more then basic level knowledge.

However I can clearly say that it's not a big issue to use current squid APIs\Interfaces(ICAP\ECAP) to implement a solution which will act like the nginx  "module".

I do not know how long it would take or how much it will cost since it requires time?

This time is required for:

- Learning\Relearning

- Identifying and predicting the different cases

- Basic testing for the different cases

- Implementing a basic structure

- Testing

- (In a loop and\or couple trees?)

 

>From my point of view compared to "ransom" or any similar idea, anyone that will write any piece of software to implement this specific idea should be able to take on his shoulders more then only this but more then just this.

And just to illustrate, imagine that some nice guy pops into Boing or RedHat offices and will leave a DiskOnKey at the front desk with a note "This flash drive contains an idea that will bring you lots of money"(not saying the current idea itself is bad or wrong..).

What would these companies do? Will they put a team of engineers in a second?

I do believe that they are not "hot headed" enough to act in a second.

 

I received a link couple years ago from Amos for an e-cap module:

https://github.com/creamy/ecap-mongo

Which does couple very interesting things but, despite to the fact that I learned to program in C and C++ I couldn't understand and\or implement a Store API which could be used for\by squid.

However I implemented this:

Windows Updates a Caching Stub zone[ http://www1.ngtech.co.il/wpe/?page_id=301 ]

And while implementing the idea one of the main things I noticed is that trying to "catch" all traffic into disk is the wrong way to define a goal.

Indeed it can be written to be done "automatically" but I will ask:
What is it worth to write everything into disk if you never read from disk more then 1% of the files content?

 

If you have a specific targeted site it's one thing but trying to catch them all is kind of like tying your feet with a rope to a door and then shove\slam the door to the other direction.
Imagine yourself how far and fast you will fly?

 

Thanks,

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Sunday, August 7, 2016 9:23 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Range header is a hit ratio killer

 


-----BEGIN PGP SIGNED MESSAGE----- 
Hash: SHA256 
 
So,

the overall answer is "NO".

You can use Store-ID + collapsed forwarding functionality to achieve something your want. May be together, may be separate. Hard luck :)

But this is your own problem. No one will solve the problem without the infusion of large amounts of money to make it interesting.

:)


07.08.2016 20:12, Amos Jeffries ?????:
> On 6/08/2016 9:56 p.m., k simon

      wrote:



      >> Hi,list,



      >>   Code 206 is the most pain for our forwed proxy. Squid

      use



      >> ?range_offset_limit? to process byte-range request. when

      set it "none",



      >> it has 2 wellknown issue:



      >> 1.  boost the traffic on the server side, we observed

      it's amplified



      >> 500% compared to clients side on our box.



      >



      > To which the answer currently is to see if enabling

      collapsed_forwarding



      > works okay for your needs.



      >



      >> 2.  it's always failed on a lossy link, and squid

      refetched it again and



      >> again.



      >>   I've noticed that nginx have supported "byte-range

      cacheing" since



      >> 1.9.8  by Module ngx_http_slice_module officially.



      >> (1.



      >>

http://nginx.org/en/docs/http/ngx_http_slice_module.html?_ga=1.140845234.106894549.1470474534



      >>



      >



      > So? what relevance does other software features have to Squid

      behaviour?



      >



      > 

 <http://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F> <http://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F>



      >



      > ... to be fair the storage code in Squid is a bit hairy in

      places. So



      > paying for it to be done is unlikely to be cheap. But still,

      waiting



      > wont fix the problem. We nearly go there in Squid-2.7, but

      the



      > experiment there is not able to completely port across to

      Squid-3 and



      > had some important problems anyway.



      >



      >



      >> 2.

      https://www.nginx.com/resources/admin-guide/content-caching/  ).



      >>   The solution is not perfect, but it's really more

      usable than



      >> "range_offset_limit". The secret it's use a fixed size

      object replaced



      >> the whole file, and we can alter the request range offset

      and passed it



      >> to server;



      >



      > Ah, thats what range_offset_limit does today. Updates the

      server request



      > to say "deliver all of it" and stores the response in a file

      the size of



      > the whole expected response the server informs will be

      arriving.



      >



      > The reason you are seeing that 500% increase in bandwidth is

      that



      > multiple Range requests arrive while the initial part of the

      first



      > response is still arriving back to Squid, so 5 of them get

      sent through



      > to the server. When that first one finishes, its object

      becomes



      > available for use as a HIT and followup Range requests get

      bits of it



      > (so you dont see 600% -> millions of % bandwidth

      increase).



      >



      > collapsed_fowarding alters this by letting the first response

      be used by



      > other requests while it is still incomplete. But YMMV

      regarding the



      > savings and CF affects all traffic, so it may cause

      behaviours you dont



      > want on other types of request. Worth a try though.



      >



      >



      >> perhaps forward the origin range offset and cache a part

      of



      >> the object with a range key is a better idea.



      >> And squid should know how



      >> to make up those object and process the request with

      range header.



      >>   And with a fixed size object to cache it may benefits

      to disk IO.



      >> Sounds it's similar like big-rock db concept, though I've

      not got



      >> successed with rock on FreeBSD nor ubuntu box.



      >>   Does squid has some plan to support this method or have

      another solution?



      >>



      >



      > squid is software. It doesn't have its own plans (at least I

      hope not).



      >



      > I'm not aware of any plans specifically to add Range caching

      any time



      > soon. Ideas for how to do it get thrown around in squid-dev a

      couple of



      > times a year, so lots of ideas but so far nothing concrete

      has come out



      > of it. Yes rock and/or memory caches are looking like the

      most easily



      > adapted cache types to enable storing partial objects in,

      someone still



      > has to do the actual coding work though.



      >



      > Amos



      >



      > _______________________________________________



      > squid-users mailing list



      > squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 



      > http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE----- 
Version: GnuPG v2 
 
iQEcBAEBCAAGBQJXp3yAAAoJENNXIZxhPexGDEYH/AjM5hD4ahsF9IXsMo5PrWLE 
nlKCloampXBur7o1PD2uOynU35ayV2wjJlBU9P9uQrux5lus0FCHt0yD/X9rEJ4J 
E1AcShLUfK6ezMdSKnn5tylfTg1+4U08/hJz3+E9PGxA//peoPVovgHu/WuFXM4X 
2NtSaVeib1O7QI2Dr0yRGZKKuJ9C2/YZqTAgjUa8rT2JZAsi5bzVU4WoaXwxklZD 
OolueguA63dKo3n86oAR1W0jmPoXQeHvPuleYbGLUwWVBBlRJdCHpKfVnh/D+ni4 
w0hR0MRBZzS8dVNQTrTCCzuFoIH1VjHhYKKZaIQEgPpo7AsvtABNTxLM7MJmqRY= 
=UX3s 
-----END PGP SIGNATURE----- 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160808/31bc9354/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 11317 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160808/31bc9354/attachment.png>

From fastestsuperman at gmail.com  Mon Aug  8 05:36:03 2016
From: fastestsuperman at gmail.com (james82)
Date: Sun, 7 Aug 2016 22:36:03 -0700 (PDT)
Subject: [squid-users] how to fix this problem when start squid in terminal ?
Message-ID: <1470634563895-4678780.post@n4.nabble.com>

I start my squid proxy in terminal, then i meet problem like this:
http://imgur.com/a/YPI1X . how can i fdix this?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/how-to-fix-this-problem-when-start-squid-in-terminal-tp4678780.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon Aug  8 12:43:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 Aug 2016 00:43:13 +1200
Subject: [squid-users] how to fix this problem when start squid in
 terminal ?
In-Reply-To: <1470634563895-4678780.post@n4.nabble.com>
References: <1470634563895-4678780.post@n4.nabble.com>
Message-ID: <8d055bd6-6cee-bd39-21d2-0a77b6ac6e63@treenet.co.nz>

On 8/08/2016 5:36 p.m., james82 wrote:
> I start my squid proxy in terminal, then i meet problem like this:
> http://imgur.com/a/YPI1X . how can i fdix this?

Read the terminal text. It tells you what to do.

Also, the purpose of this mailing list is to provide a public archive
recrd of problems and how they are solved.

Hiding all the details of your problem inside an image hosted on a
shortened URL which at some point not too far in the future will point
at a piece of malware is a terrible way to seek help.

Amos



From erdosain9 at gmail.com  Mon Aug  8 20:39:12 2016
From: erdosain9 at gmail.com (Erdosain9)
Date: Mon, 8 Aug 2016 17:39:12 -0300
Subject: [squid-users] squid 3.3.8 https
Message-ID: <CA+EQfqHg=nmmV=RpKtCjG1788Kp9hCn1WUasP_eoThD1ww4cvQ@mail.gmail.com>

I want to limit the bandwidth for youtube, so I want to intercept https
connections. I followed several tutorials and can not. Could someone give
me a hand ?? Thanks to all.
this is my squid.conf

# Squid listen Port
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB key=/etc/squid/example.com.private
cert=/etc/squid/example.com.cert
# SSL Bump Config
always_direct allow all
ssl_bump server-first all
sslproxy_cert_error deny all
sslproxy_flags DONT_VERIFY_PEER
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1

I import the example.com.cert to the webbrowser and then any web https i go
i get "The proxy server is refusing connections". if not https go well.

this is access.log:

192.168.1.172 TCP_HIT/200 52543 GET
http://www.silencio.com.ar/wp-content/uploads/2016/07/AHJ8239-540x386.jpg
- HIER_NONE/- image/jpeg
192.168.1.172 TCP_HIT/200 49912 GET
http://www.silencio.com.ar/wp-content/uploads/2016/07/strokes-2001-adentro-540x386.jpg
- HIER_NONE/- image/jpeg
192.168.1.172 TCP_HIT/200 43804 GET
http://www.silencio.com.ar/wp-content/uploads/2016/07/ArcticMonkeys012-540x386.jpg
- HIER_NONE/- image/jpeg
192.168.1.172 TCP_DENIED/200 0 CONNECT www.google-analytics.com:443 -
HIER_NONE/- -
192.168.1.172 TCP_MISS/301 807 GET http://www.youtube.com/ -
HIER_DIRECT/64.233.186.91 text/html
192.168.1.172 NONE/200 0 CONNECT www.youtube.com:443 -
HIER_DIRECT/64.233.186.91 -
192.168.1.172 NONE/200 0 CONNECT blocklist.addons.mozilla.org:443 -
HIER_DIRECT/52.35.149.230 -
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160808/c24d5b80/attachment.htm>

From yvoinov at gmail.com  Mon Aug  8 20:41:34 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 9 Aug 2016 02:41:34 +0600
Subject: [squid-users] squid 3.3.8 https
In-Reply-To: <CA+EQfqHg=nmmV=RpKtCjG1788Kp9hCn1WUasP_eoThD1ww4cvQ@mail.gmail.com>
References: <CA+EQfqHg=nmmV=RpKtCjG1788Kp9hCn1WUasP_eoThD1ww4cvQ@mail.gmail.com>
Message-ID: <13cba164-5f08-c805-5e94-5bf83980394e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
3.3.8 is antique at 2016.

Upgrade at least to 3.5.20.


09.08.2016 2:39, Erdosain9 ?????:
>
> I want to limit the bandwidth for youtube, so I want to intercept
https connections. I followed several tutorials and can not. Could
someone give me a hand ?? Thanks to all.
>
> this is my squid.conf
>
> |# Squid listen Port
> http_port 192.168.1.215:3128 <http://192.168.1.215:3128> ssl-bump
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
key=/etc/squid/example.com.private cert=/etc/squid/example.com.cert
> # SSL Bump Config
> always_direct allow all
> ssl_bump server-first all
> sslproxy_cert_error deny all
> sslproxy_flags DONT_VERIFY_PEER
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1|
> I import the example.com.cert to the webbrowser and then any web https
i go i get "The proxy server is refusing connections". if not https go well.
>
> this is access.log:
> |
> |192.168.1.172 TCP_HIT/200 52543 GET
http://www.silencio.com.ar/wp-content/uploads/2016/07/AHJ8239-540x386.jpg
- HIER_NONE/- image/jpeg
> 192.168.1.172 TCP_HIT/200 49912 GET
http://www.silencio.com.ar/wp-content/uploads/2016/07/strokes-2001-adentro-540x386.jpg
- HIER_NONE/- image/jpeg
> 192.168.1.172 TCP_HIT/200 43804 GET
http://www.silencio.com.ar/wp-content/uploads/2016/07/ArcticMonkeys012-540x386.jpg
- HIER_NONE/- image/jpeg
> 192.168.1.172 TCP_DENIED/200 0 CONNECT www.google-analytics.com:443
<http://www.google-analytics.com:443> - HIER_NONE/- -
> 192.168.1.172 TCP_MISS/301 807 GET http://www.youtube.com/ -
HIER_DIRECT/64.233.186.91 <http://64.233.186.91> text/html
> 192.168.1.172 NONE/200 0 CONNECT www.youtube.com:443
<http://www.youtube.com:443> - HIER_DIRECT/64.233.186.91
<http://64.233.186.91> -
> 192.168.1.172 NONE/200 0 CONNECT blocklist.addons.mozilla.org:443
<http://blocklist.addons.mozilla.org:443> - HIER_DIRECT/52.35.149.230
<http://52.35.149.230> -||
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXqO5+AAoJENNXIZxhPexGUT4H/iFwAOK4xf2QIQf/b21H0vfZ
j9+ldNZpMaWlsn12tw96ip6o8iQ9h+j5GuTlpbo8BTQolEsHWMG8YvI0HCdPsXZB
nRLteQ/3ZDysNgbrnNuBXv6cmWdwd1S8rNamHVdxzDGpw/Guc2D1X7+rk+rwLndw
rMw9N2iO1eW4/q8BZbFyMaRkHRO4LR/Dyz2cvSRTCn3BTeEyt/yJFK5s4IuU7YjY
igUYC4fysRweUoVJxCGOOP/q90pT5CYJkdp+wgL3dG6Bx9AuUPVFaj8kv6atyMNZ
EE5Ttbnp3+mnE2MF61WIu/fsls+7n7UEUnjm4jphWR1ch1Q78V1e3hzYTuzjmjg=
=ZphP
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160809/bac145a1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160809/bac145a1/attachment.key>

From marciobacci at gmail.com  Mon Aug  8 21:22:23 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Mon, 8 Aug 2016 18:22:23 -0300
Subject: [squid-users] Problem with the Squid 3
Message-ID: <CA+0TdyqJ+vqNLP8XC6K0bmCmvry3j8fsXo-BqQYJHYX8-81f4A@mail.gmail.com>

I have a problem with Squid 3 on Debian 8.2

When the users open your browsers, the squid asks the name and password.
Until this moment is OK, but if the users inform only the password (field
"name" not filled - in blank), the navigation is permitted.

The following is my squid.conf file:

http_port 3128
cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90
maximum_object_size 512 MB
minimum_object_size 0 KB
maximum_object_size_in_memory 4096 KB
cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA
quick_abort_min -1 KB
detect_broken_pconn on
fqdncache_size 1024

### CACHE
refresh_pattern ^ftp:    1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%     0
refresh_pattern .        0    20%    4320

### LOGS
access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log

cache_dir aufs /var/spool/squid3 600 16 256

#Allow Acces
acl caixa dstdomain .caixa.gov.br
cache deny caixa

# NTLM
auth_param ntlm program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp --domain=EMPRESA
auth_param ntlm children 20
auth_param ntlm keep_alive off


# BASIC
auth_param basic program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-basic
auth_param basic children 5
auth_param basic realm Autenticacao B?sica - Acesso Monitorado
auth_param basic credentialsttl 8 hours

/usr/lib/squid3/ext_wbinfo_group_acl
external_acl_type ad_group %LOGIN /usr/lib/squid3/ext_wbinfo_group_acl -d

visible_hostname proxy.empresa.com

### ACLs
acl localhost src 192.168.200.35/32
acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, bacula
acl Safe_ports port 21         # ftp
acl Safe_ports port 70         # gopher
acl Safe_ports port 80          # http
acl Safe_ports port 88         # kerberos
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 389          # ldap
acl Safe_ports port 443          # https
acl Safe_ports port 464          # kerberos password
acl Safe_ports port 488         # gss-http
acl Safe_ports port 563         # snews
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 1025-65535     # unregistered ports

acl purge method PURGE
acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow manager localhost
http_access deny manager
http_access allow purge localhost
http_access deny purge

acl group_admins external ad_group gg_webadmins
acl group_managers external ad_group gg_webliberados
acl grupo_commons external ad_group domain%20users

### ALLOW UPDATE
acl updates url_regex -i "/etc/squid3/acls/updates"
http_access allow updates


### DENY EXTENSIONS
acl extensions_deny url_regex -i "/etc/squid3/acls/extensions-denied"

### ALLOW SITES
acl sites_allows url_regex -i "/etc/squid3/acls/sites-allow"
acl sites_denied url_regex -i "/etc/squid3/acls/sites-denied"

acl users proxy_auth REQUIRED

http_access allow group_admins

http_access deny extensions-denied
http_access allow sites_allows
http_access deny sites_denied

http_access allow group_manager

# SquidGuard Rules
redirect_program /usr/bin/squidGuard
redirect_children 20
redirector_bypass on

http_access allow group_common

http_access allow users

### LAN #####
acl lan-net src 192.168.200.0/22
acl wireless-net src 192.168.210.0/22


http_access allow lan-net
http_access allow wireless-net

#negando o acesso para todos que nao estiverem nas regras anteriores
http_access deny all

### Errors
error_directory /usr/share/squid3/errors/en
coredump_dir /var/spool/squid3

Regards,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160808/fe5eff2a/attachment.htm>

From squid3 at treenet.co.nz  Mon Aug  8 21:29:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 Aug 2016 09:29:50 +1200
Subject: [squid-users] Problem with the Squid 3
In-Reply-To: <CA+0TdyqJ+vqNLP8XC6K0bmCmvry3j8fsXo-BqQYJHYX8-81f4A@mail.gmail.com>
References: <CA+0TdyqJ+vqNLP8XC6K0bmCmvry3j8fsXo-BqQYJHYX8-81f4A@mail.gmail.com>
Message-ID: <dd572050-cfed-c7df-706e-ba482a0881a4@treenet.co.nz>

On 9/08/2016 9:22 a.m., Marcio Demetrio Bacci wrote:
> I have a problem with Squid 3 on Debian 8.2
> 
> When the users open your browsers, the squid asks the name and password.
> Until this moment is OK, but if the users inform only the password (field
> "name" not filled - in blank), the navigation is permitted.
> 

Your config uses credentails to *allow* things, but there is no denial
for invalid auth credentials so unless one of the other non-auth ACL
tests denies the request there is no reason to prevent access.

Amos



From erdosain9 at gmail.com  Mon Aug  8 21:54:00 2016
From: erdosain9 at gmail.com (Erdosain9)
Date: Mon, 8 Aug 2016 18:54:00 -0300
Subject: [squid-users] squid 3.3.8 https (Yuri Voinov)
Message-ID: <CAKqfNrkrzXP=Bry9-ijy_hdpfmxER05szDGLRvMiX+WsohkBZA@mail.gmail.com>

but, its possible to do with this version?? (3.3.8).... i have CentOs 7 and
thats the official packet.
thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160808/1cb0d473/attachment.htm>

From marciobacci at gmail.com  Mon Aug  8 22:29:59 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Mon, 8 Aug 2016 19:29:59 -0300
Subject: [squid-users] Problem with the Squid 3
In-Reply-To: <CA+0TdyqJ+vqNLP8XC6K0bmCmvry3j8fsXo-BqQYJHYX8-81f4A@mail.gmail.com>
References: <CA+0TdyqJ+vqNLP8XC6K0bmCmvry3j8fsXo-BqQYJHYX8-81f4A@mail.gmail.com>
Message-ID: <CA+0Tdype-QuP81OR1TYyFEJaOF-JemCq8CcpRjoE8E7kmb__=g@mail.gmail.com>

I changed http_access allow users TO http_access deny !users in my
squid.conf file, but dosen't solved my problem

http_port 3128

cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90
maximum_object_size 512 MB
minimum_object_size 0 KB
maximum_object_size_in_memory 4096 KB
cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA
quick_abort_min -1 KB
detect_broken_pconn on
fqdncache_size 1024

### CACHE
refresh_pattern ^ftp:    1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%     0
refresh_pattern .        0    20%    4320

### LOGS
access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log

cache_dir aufs /var/spool/squid3 600 16 256

#Allow Acces
acl caixa dstdomain .caixa.gov.br
cache deny caixa

# NTLM
auth_param ntlm program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp --domain=EMPRESA
auth_param ntlm children 20
auth_param ntlm keep_alive off


# BASIC
auth_param basic program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-basic
auth_param basic children 5
auth_param basic realm Autenticacao B?sica - Acesso Monitorado
auth_param basic credentialsttl 8 hours

/usr/lib/squid3/ext_wbinfo_group_acl
external_acl_type ad_group %LOGIN /usr/lib/squid3/ext_wbinfo_group_acl -d

visible_hostname proxy.empresa.com

### ACLs
acl localhost src 192.168.200.35/32
acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, bacula
acl Safe_ports port 21         # ftp
acl Safe_ports port 70         # gopher
acl Safe_ports port 80          # http
acl Safe_ports port 88         # kerberos
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 389          # ldap
acl Safe_ports port 443          # https
acl Safe_ports port 464          # kerberos password
acl Safe_ports port 488         # gss-http
acl Safe_ports port 563         # snews
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 1025-65535     # unregistered ports

acl purge method PURGE
acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow manager localhost
http_access deny manager
http_access allow purge localhost
http_access deny purge

acl group_admins external ad_group gg_webadmins
acl group_managers external ad_group gg_webliberados
acl grupo_commons external ad_group domain%20users

### ALLOW UPDATE
acl updates url_regex -i "/etc/squid3/acls/updates"
http_access allow updates


### DENY EXTENSIONS
acl extensions_deny url_regex -i "/etc/squid3/acls/extensions-denied"

### ALLOW SITES
acl sites_allows url_regex -i "/etc/squid3/acls/sites-allow"
acl sites_denied url_regex -i "/etc/squid3/acls/sites-denied"

acl users proxy_auth REQUIRED
http_access deny !users

http_access allow group_admins
http_access deny extensions_denied
http_access allow sites_allows
http_access deny sites_denied

http_access allow group_manager

# SquidGuard Rules
redirect_program /usr/bin/squidGuard
redirect_children 20
redirector_bypass on

http_access allow group_common

### LAN #####
acl lan-net src 192.168.200.0/22
acl wireless-net src 192.168.210.0/22


http_access allow lan-net
http_access allow wireless-net

#negando o acesso para todos que nao estiverem nas regras anteriores
http_access deny all

### Errors
error_directory /usr/share/squid3/errors/en
coredump_dir /var/spool/squid3

 Regards,

M?rcio

2016-08-08 18:22 GMT-03:00 Marcio Demetrio Bacci <marciobacci at gmail.com>:

> I have a problem with Squid 3 on Debian 8.2
>
> When the users open your browsers, the squid asks the name and password.
> Until this moment is OK, but if the users inform only the password (field
> "name" not filled - in blank), the navigation is permitted.
>
> The following is my squid.conf file:
>
> http_port 3128
> cache_mem 512 MB
> cache_swap_low 80
> cache_swap_high 90
> maximum_object_size 512 MB
> minimum_object_size 0 KB
> maximum_object_size_in_memory 4096 KB
> cache_replacement_policy heap LFUDA
> memory_replacement_policy heap LFUDA
> quick_abort_min -1 KB
> detect_broken_pconn on
> fqdncache_size 1024
>
> ### CACHE
> refresh_pattern ^ftp:    1440    20%    10080
> refresh_pattern ^gopher:    1440    0%    1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0%     0
> refresh_pattern .        0    20%    4320
>
> ### LOGS
> access_log /var/log/squid3/access.log
> cache_log /var/log/squid3/cache.log
>
> cache_dir aufs /var/spool/squid3 600 16 256
>
> #Allow Acces
> acl caixa dstdomain .caixa.gov.br
> cache deny caixa
>
> # NTLM
> auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp
> --domain=EMPRESA
> auth_param ntlm children 20
> auth_param ntlm keep_alive off
>
>
> # BASIC
> auth_param basic program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-
> basic
> auth_param basic children 5
> auth_param basic realm Autenticacao B?sica - Acesso Monitorado
> auth_param basic credentialsttl 8 hours
>
> /usr/lib/squid3/ext_wbinfo_group_acl
> external_acl_type ad_group %LOGIN /usr/lib/squid3/ext_wbinfo_group_acl -d
>
> visible_hostname proxy.empresa.com
>
> ### ACLs
> acl localhost src 192.168.200.35/32
> acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, bacula
> acl Safe_ports port 21         # ftp
> acl Safe_ports port 70         # gopher
> acl Safe_ports port 80          # http
> acl Safe_ports port 88         # kerberos
> acl Safe_ports port 210         # wais
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 389          # ldap
> acl Safe_ports port 443          # https
> acl Safe_ports port 464          # kerberos password
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 563         # snews
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 1025-65535     # unregistered ports
>
> acl purge method PURGE
> acl CONNECT method CONNECT
>
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow manager localhost
> http_access deny manager
> http_access allow purge localhost
> http_access deny purge
>
> acl group_admins external ad_group gg_webadmins
> acl group_managers external ad_group gg_webliberados
> acl grupo_commons external ad_group domain%20users
>
> ### ALLOW UPDATE
> acl updates url_regex -i "/etc/squid3/acls/updates"
> http_access allow updates
>
>
> ### DENY EXTENSIONS
> acl extensions_deny url_regex -i "/etc/squid3/acls/extensions-denied"
>
> ### ALLOW SITES
> acl sites_allows url_regex -i "/etc/squid3/acls/sites-allow"
> acl sites_denied url_regex -i "/etc/squid3/acls/sites-denied"
>
> acl users proxy_auth REQUIRED
>
> http_access allow group_admins
>
> http_access deny extensions-denied
> http_access allow sites_allows
> http_access deny sites_denied
>
> http_access allow group_manager
>
> # SquidGuard Rules
> redirect_program /usr/bin/squidGuard
> redirect_children 20
> redirector_bypass on
>
> http_access allow group_common
>
> http_access allow users
>
> ### LAN #####
> acl lan-net src 192.168.200.0/22
> acl wireless-net src 192.168.210.0/22
>
>
> http_access allow lan-net
> http_access allow wireless-net
>
> #negando o acesso para todos que nao estiverem nas regras anteriores
> http_access deny all
>
> ### Errors
> error_directory /usr/share/squid3/errors/en
> coredump_dir /var/spool/squid3
>
> Regards,
>
> M?rcio
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160808/f5e6259a/attachment.htm>

From squid3 at treenet.co.nz  Mon Aug  8 23:05:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 Aug 2016 11:05:35 +1200
Subject: [squid-users] squid 3.3.8 https (Yuri Voinov)
In-Reply-To: <CAKqfNrkrzXP=Bry9-ijy_hdpfmxER05szDGLRvMiX+WsohkBZA@mail.gmail.com>
References: <CAKqfNrkrzXP=Bry9-ijy_hdpfmxER05szDGLRvMiX+WsohkBZA@mail.gmail.com>
Message-ID: <0ef16c8f-f46f-56c6-7ef2-86abc05a0512@treenet.co.nz>

On 9/08/2016 9:54 a.m., Erdosain9 wrote:
> but, its possible to do with this version?? (3.3.8).... i have CentOs 7 and
> thats the official packet.

With difficulty. HTTPS was designed to prevent MITM being possible. So
the Squid SSL-Bump feature(s) have been in an arms race situation with
the whole security community since before it was even designed. It is
still quote volatile with changes to how bumping works right up to the
very latest releases.

If you want to SSL-Bump traffic you really need to be following the
latest changes. Old packages will have an increasing number of sites
where it suddenly stops working because they fixed the security hole
that old version as using. Or added some new TLS extension the old
version is not aware of.


The <http://wiki.squid-cache.org/KnowledgeBase/CentOS> page lists where
you can get more up-to-date packages for CentOS.

Amos



From squid3 at treenet.co.nz  Mon Aug  8 23:10:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 Aug 2016 11:10:28 +1200
Subject: [squid-users] Problem with the Squid 3
In-Reply-To: <CA+0Tdype-QuP81OR1TYyFEJaOF-JemCq8CcpRjoE8E7kmb__=g@mail.gmail.com>
References: <CA+0TdyqJ+vqNLP8XC6K0bmCmvry3j8fsXo-BqQYJHYX8-81f4A@mail.gmail.com>
 <CA+0Tdype-QuP81OR1TYyFEJaOF-JemCq8CcpRjoE8E7kmb__=g@mail.gmail.com>
Message-ID: <6d7d6f9e-3d4b-bd8d-41cf-53363801053f@treenet.co.nz>

On 9/08/2016 10:29 a.m., Marcio Demetrio Bacci wrote:
> I changed http_access allow users TO http_access deny !users in my
> squid.conf file, but dosen't solved my problem
> 

Then what the browser is sending to Squid must either include some form
of username, or be accepted by the backend auth system.

Squid is not handling the credentials itself. They get passed to the
auth helper for processing. Which just tells Squid whether or not they
are good and what the username in them is.

Amos



From chio1990 at gmail.com  Tue Aug  9 03:36:14 2016
From: chio1990 at gmail.com (k simon)
Date: Tue, 9 Aug 2016 11:36:14 +0800
Subject: [squid-users] Range header is a hit ratio killer
In-Reply-To: <01e101d1f0ae$7f193830$7d4ba890$@ngtech.co.il>
References: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
 <01e101d1f0ae$7f193830$7d4ba890$@ngtech.co.il>
Message-ID: <170cdcb0-c784-e822-5510-a0565a48adf3@gmail.com>



? 16/8/7 21:20, Eliezer Croitoru ??:
> Hey Simon,
>
> I do not know the plans but it will depend on couple things which can fit to one case but not the other.
> The assumption that we can fetch any part of the object is the first step for any solution what so ever.
> However it is not guaranteed that each request will be public.
>
> The idea of static chunks exists for many years in many applications and in many forms and YouTube videos player uses a similar idea. Google video clients and servers uses a bytes "range" request in the url rather then in the request header.
> Technically it would be possible to implement such an idea but it has it's own cost.
> Eventually if the file is indeed public(what squid was designed to cache) then it might not be of a big problem.
> Depends on the target sites a the solution will be different.
> Before deciding on a specific solution my preferred path is to analyze the requests.
>
> By observing amplified traffic of 500% to  clients side you mean that the incoming traffic to the server is 500% compared to the output towards the clients?
> If so I think that there might be a "smarter" solution then 206 range offset limit.
> The old method of prefetching works pretty good in many cases. From what you describe it might have better luck then the plain "fetch everything on the wire in real time".
>
> I cannot guarantee that prefetching is the right solution for you but I think that a case like this deserves couple eyes to understand if there is a right way to handle the situation.
>
  I think prefetch may not be fit for forward proxy, as we do not know 
what's "hot" request exactly. LRU should do more efficient.

Simon


From chio1990 at gmail.com  Tue Aug  9 03:50:07 2016
From: chio1990 at gmail.com (k simon)
Date: Tue, 9 Aug 2016 11:50:07 +0800
Subject: [squid-users] Range header is a hit ratio killer
In-Reply-To: <5bf69bb8-8864-a4bf-abf1-003c5f3d7c3b@treenet.co.nz>
References: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
 <5bf69bb8-8864-a4bf-abf1-003c5f3d7c3b@treenet.co.nz>
Message-ID: <c73e37e5-ddb1-5ec6-7aeb-c022f8c86c8a@gmail.com>


Hi,
   As a workaround, I placed a nginx in the front of my bigfiles squid 
box. then I tcpdump on the squid's server side, byte-range are convertd 
to a fixed size, and it's cached as expected. :)

Simon
20160809


From admin at tisiz72.ru  Tue Aug  9 03:54:46 2016
From: admin at tisiz72.ru (Andrey Ivnitsky)
Date: Tue, 09 Aug 2016 08:54:46 +0500
Subject: [squid-users] Forum
Message-ID: <73f21e0114074c51d6fb84bbee5da791@tisiz72.ru>

Hi guys! I do not want to offend anyone, but the email lists was not
terribly comfortable. Probably, this issue has been debated, but it can
be to have a Forum?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160809/da0f9864/attachment.htm>

From dan at getbusi.com  Tue Aug  9 05:39:02 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Tue, 9 Aug 2016 15:39:02 +1000
Subject: [squid-users] Rate limiting bad clients?
Message-ID: <858F001E-FA29-4319-975A-4BF21811A584@getbusi.com>

Hi all,

This is more of a squid-adjacent query. Hopefully relevant enough for someone here to help?

I?m sick of all these web apps that take it upon themselves to hammer proxies when they don?t get the response they want, like if they have to authenticate for example. On big networks, behind a forward proxy, there?s always a few computers with some software doing dozens of identical, failing, requests per second.

- What?s a good approach for rate limiting the clients computers which are doing this?
- Can anyone point to a good tutorial for this using, say, iptables if that?s appropriate?

Any advice welcome.

Thanks!
Dan

From johnzeng2013 at yahoo.com  Tue Aug  9 07:31:57 2016
From: johnzeng2013 at yahoo.com (johnzeng)
Date: Tue, 09 Aug 2016 15:31:57 +0800
Subject: [squid-users] I redirect some http traffic to squid ( 90Mbps) and i
 found TIME_WAIT is 20840 and one of squid process is 57% ,
 whether it will be fine ?
Message-ID: <57A986ED.4060009@yahoo.com>



Hello Dear Sir

I redirect some http traffic to squid ( 90Mbps) and i found TIME_WAIT is
20840 and one of squid process is 57%

whether it will be normal condition ??

Whether we can balance cpu processing capacity
<http://www.baidu.com/link?url=Rnht_DzfJLQPi_VnmfPjUfWfUdE4kaP1H7Vol-rTTZqKvF8npmGrx8-h947AFhU6-kqlwyWBW7W4ghqHWMs1iN1APnbkLMjrB7YI1PzephOCELHTqemcUEY1JH0mmw68>
for full squid process !

Because we use squid 3.5.2 and use cache_dir rock part . Maybe squid
3.5.2 require to do automatic scheduling at full cpu core

i don't know whether i can use taskset for squid 3.5.3 as squid 2.7 ??


if possible , please give me some advisement


___________________________________________________________
accerater
TIME_WAIT DETAIL
___________________________________________________________

TIME_WAIT 20840
CLOSE_WAIT 59
SYN_SENT 7
FIN_WAIT1 23
FIN_WAIT2 294
ESTABLISHED 5902
SYN_RECV 13
LAST_ACK 11


____________________________________________________________________

CPU STATUS
____________________________________________________________________


Tasks: 381 total, 1 running, 380 sleeping, 0 stopped, 0 zombie
Cpu(s): 4.1%us, 0.6%sy, 0.0%ni, 92.6%id, 0.2%wa, 0.0%hi, 2.5%si, 0.0%st
Mem: 65889452k total, 65038396k used, 851056k free, 790788k buffers
Swap: 976892k total, 0k used, 976892k free, 56220968k cached

PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND
1904 sqiduser 20 0 33.5g 710m 271m S 57 1.1 978:34.74 squid
1903 sqiduser 20 0 33.4g 609m 271m S 32 0.9 497:59.29 squid
1906 sqiduser 20 0 33.3g 555m 271m S 22 0.9 266:41.47 squid
1902 sqiduser 20 0 33.4g 651m 271m S 20 1.0 710:04.17 squid
1901 sqiduser 20 0 33.5g 694m 271m S 15 1.1 616:40.25 squid
2028 sqiduser 20 0 2406m 75m 1888 S 7 0.1 297:56.70 named
1907 sqiduser 20 0 33.4g 589m 270m S 7 0.9 167:37.24 squid
1908 sqiduser 20 0 33.3g 545m 270m S 5 0.8 155:50.67 squid
1905 sqiduser 20 0 33.3g 553m 270m S 1 0.9 121:05.67 squid


___________________________________________________________________________

PART SQUID CONFIG
___________________________________________________________________________

cache_mem 32172 MB
workers 8
cpu_affinity_map process_numbers=1,2,3,4,5,6,7,8 cores=1,3,5,7,9,11,13,15
cache_dir rock /acapp/webcache3/storage/cossbig1/squid1 17280
min-size=4097 max-size=262144 max-swap-rate=250 swap-timeout=350
cache_dir rock /acapp/webcache3/storage/cosssmall1/squid1 1152
max-size=4096 max-swap-rate=250 swap-timeout=350
if ${process_number} = 1
unique_hostname fast_squid${process_number}
access_log stdio:/acapp/logs/webcache3/squid${process_number}/access.log
squid
cache_log /acapp/logs/webcache3/squid${process_number}/cache.log
snmp_port 3401
cache_dir aufs /acapp/webcache3/storage/aufs1/squid${process_number}
192000 16 64 min-size=262145
cache_dir aufs /acapp/webcache3/storage/aufs2/squid${process_number}
192000 16 64 min-size=262145
cache_dir aufs /acapp/webcache3/storage/aufs3/squid${process_number}
288096 16 64 min-size=262145
cache_dir aufs /acapp/webcache3/storage/aufs4/squid${process_number}
288096 16 64 min-size=262145
endif
if ${process_number} = 2
unique_hostname fast_squid${process_number}
access_log stdio:/acapp/logs/webcache3/squid${process_number}/access.log
squid
cache_log /acapp/logs/webcache3/squid${process_number}/cache.log
snmp_port 3402
cache_dir aufs /acapp/webcache3/storage/aufs1/squid${process_number}
192000 16 64 min-size=262145
cache_dir aufs /acapp/webcache3/storage/aufs2/squid${process_number}
192000 16 64 min-size=262145
cache_dir aufs /acapp/webcache3/storage/aufs3/squid${process_number}
288096 16 64 min-size=262145
cache_dir aufs /acapp/webcache3/storage/aufs4/squid${process_number}
288096 16 64 min-size=262145
endif
................
..............................





From llancelot7 at gmail.com  Tue Aug  9 08:12:18 2016
From: llancelot7 at gmail.com (Zidane Sama)
Date: Tue, 9 Aug 2016 15:12:18 +0700
Subject: [squid-users] [Feature request] possibility to mark some keys(in
	kv-pairs) as singular
Message-ID: <CAAbRcnOkQhKxt0uEzUieUgWL2TFi_jTVZVbON2O62Qxp96SJsw@mail.gmail.com>

In my situation external auth script returns "access_level" as kv_pair.
If this value was changed then two values appeared at once in
annotation and acl for high access level will be matched.
It's possible to add functionality for marking keys as singular?


From amajer at suse.de  Tue Aug  9 08:54:53 2016
From: amajer at suse.de (Adam Majer)
Date: Tue, 9 Aug 2016 10:54:53 +0200
Subject: [squid-users] Squid distribution keyring
Message-ID: <60e020db-d612-81c2-f1f4-00f8f4d6b6d0@suse.de>

Hello,

Squid-cache.org download page has all the tarballs and detached 
signatures. Thank you!

But is there an official keyring for validating these signatures? Is it 
only Amos Jeffries (Primary key fingerprint: EA31 CC5E 9488 E516 8D2D 
CC5E B268 E706 FF5C F463) that is doing releases?

Thanks,
Adam


From squid3 at treenet.co.nz  Mon Aug  8 13:22:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 Aug 2016 01:22:30 +1200
Subject: [squid-users] [squid-announce] Squid 4.0.13 beta is available
Message-ID: <1a50b5a1-7ddd-32ab-894c-b9da4176007b@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.13 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:


* HTTP/1.1: Update all stored headers on 304 revalidation.

Previous specifications for HTTP outlined a limited number of headers
that could be updated by 304 responses to a small set related to
revalidation. The latest RFC 7234 specification removes those limits and
permits custom headers, or content headers to be altered by a 304 response.


* TLS Authority Key Identifier certificate extension

The Server TLS certificate mimic feature now supports mimicking this TLS
extension in Squid generated TLS certificates if possible.


* Collapse internal revalidation requests (SMP-unaware caches).

Prior to these changes, multiple concurrent HTTP requests for the same
stale cached object always resulted in multiple internal revalidation
requests sent by Squid to the origin server. Those internal requests
were likely to result in multiple competing Squid cache updates, causing
cache misses and/or more internal revalidation requests, negating
collapsed forwarding savings.


* kerberos_ldap_group: support SSL/TLS used to connect to an LDAP server

This release of the helper extends and updates the use of TLS/SSL to
support connecting to an LDAP server.


* General portability and stability changes

This release also includes a large number of code polishing and cleanup
changes too small to mention individually, but which resolve a lot of
portability and build issues.



 All users of Squid-4.0.x are encouraged to upgrade to this release.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Tue Aug  9 15:12:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Aug 2016 03:12:24 +1200
Subject: [squid-users] Squid distribution keyring
In-Reply-To: <60e020db-d612-81c2-f1f4-00f8f4d6b6d0@suse.de>
References: <60e020db-d612-81c2-f1f4-00f8f4d6b6d0@suse.de>
Message-ID: <6bdb5db0-36ed-27bc-0073-e17232d050e9@treenet.co.nz>

On 9/08/2016 8:54 p.m., Adam Majer wrote:
> Hello,
> 
> Squid-cache.org download page has all the tarballs and detached
> signatures. Thank you!
> 
> But is there an official keyring for validating these signatures?

The .asc files containing detatched signature should also be referencing
several ways to find the keyring data:

      keyring = http://www.squid-cache.org/pgp.asc
      keyserver = subkeys.pgp.net

The keyserver report the key is outdated and I've not been able to
change that. Probably because they no longer accept short bit-lengths on
keys.

> Is it
> only Amos Jeffries (Primary key fingerprint: EA31 CC5E 9488 E516 8D2D
> CC5E B268 E706 FF5C F463) that is doing releases?

For now yes. I'm planning to do a key rollover soon-ish for Squid-4
stable releases. The new key will be signed by that previous one.

Amos



From squid3 at treenet.co.nz  Tue Aug  9 15:14:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Aug 2016 03:14:04 +1200
Subject: [squid-users] [Feature request] possibility to mark some
 keys(in kv-pairs) as singular
In-Reply-To: <CAAbRcnOkQhKxt0uEzUieUgWL2TFi_jTVZVbON2O62Qxp96SJsw@mail.gmail.com>
References: <CAAbRcnOkQhKxt0uEzUieUgWL2TFi_jTVZVbON2O62Qxp96SJsw@mail.gmail.com>
Message-ID: <444e48dc-e354-b1e8-4534-fbc5d5d069fa@treenet.co.nz>

On 9/08/2016 8:12 p.m., Zidane Sama wrote:
> In my situation external auth script returns "access_level" as kv_pair.
> If this value was changed then two values appeared at once in
> annotation and acl for high access level will be matched.
> It's possible to add functionality for marking keys as singular?

Please open a 'feature request' bug reoprt for this.
<http://bugs.squid-cache.org/>

Amos



From squid3 at treenet.co.nz  Tue Aug  9 15:24:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Aug 2016 03:24:03 +1200
Subject: [squid-users] Forum
In-Reply-To: <73f21e0114074c51d6fb84bbee5da791@tisiz72.ru>
References: <73f21e0114074c51d6fb84bbee5da791@tisiz72.ru>
Message-ID: <f04556f7-f2b3-2332-2b0a-0ad9b02f6479@treenet.co.nz>

On 9/08/2016 3:54 p.m., Andrey Ivnitsky wrote:
> Hi guys! I do not want to offend anyone, but the email lists was not
> terribly comfortable. Probably, this issue has been debated, but it can
> be to have a Forum?
> 

<http://squid-web-proxy-cache.1019090.n4.nabble.com/>

Please note that your Nabble registered email still has to be subscribed
to the mailing list to post to the forum.

Amos



From fastestsuperman at gmail.com  Tue Aug  9 14:51:27 2016
From: fastestsuperman at gmail.com (james82)
Date: Tue, 9 Aug 2016 07:51:27 -0700 (PDT)
Subject: [squid-users] how to install squid proxy with source package
 downloaded, not use apt?
Message-ID: <1470754287785-4678813.post@n4.nabble.com>

I use kali linux. I want to install squid proxy in my kali "cute"linux, not
by use apt-get install, because i'm not sure they have lastest version. I
want to install with source file download from official squid website.
Please tell me how to do this? Is it work perfect with this method.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/how-to-install-squid-proxy-with-source-package-downloaded-not-use-apt-tp4678813.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue Aug  9 15:56:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Aug 2016 03:56:08 +1200
Subject: [squid-users] I redirect some http traffic to squid ( 90Mbps)
 and i found TIME_WAIT is 20840 and one of squid process is 57% ,
 whether it will be fine ?
In-Reply-To: <57A986ED.4060009@yahoo.com>
References: <57A986ED.4060009@yahoo.com>
Message-ID: <4c61fe6a-56d5-4a03-a76b-a832d995cda6@treenet.co.nz>

On 9/08/2016 7:31 p.m., johnzeng wrote:
> 
> 
> Hello Dear Sir
> 
> I redirect some http traffic to squid ( 90Mbps) and i found TIME_WAIT is
> 20840 and one of squid process is 57%
> 
> whether it will be normal condition ??
> 

For 3.5.2 it can be 'normal'. But normal is not necessarily good.
Several bugs that have that type of effect have been fixed since 3.5.2
was released.

If you can please upgrade to 3.5.20 ASAP, all releases before 3.5.19
have major security vulnerabilities.


> Whether we can balance cpu processing capacity
> <http://www.baidu.com/link?url=Rnht_DzfJLQPi_VnmfPjUfWfUdE4kaP1H7Vol-rTTZqKvF8npmGrx8-h947AFhU6-kqlwyWBW7W4ghqHWMs1iN1APnbkLMjrB7YI1PzephOCELHTqemcUEY1JH0mmw68>
> for full squid process !

This focussing on balanced CPUs is counter-productive. With processes
like Squid it is actually more efficient to use fewer CPUs at higher
load than more CPUs at lower load.

When one CPU core is doing a lot more of the work it means there is less
contention between cores for access to RAM resoures, less delays
incurred by UDP messaging between the Squid worker processes or waiting
for atomic locks, and the unused core(s) can possibly be put into
power-saving modes. All of which reduces latency or monetary costs.

> 
> Because we use squid 3.5.2 and use cache_dir rock part . Maybe squid
> 3.5.2 require to do automatic scheduling at full cpu core
> 
> i don't know whether i can use taskset for squid 3.5.3 as squid 2.7 ??
> 

I'm not certain but it should be possible. You have used cpu_affinity
explicitly in squid.conf, so that may alter what can be done with
taskset. Give it a try.

> ___________________________________________________________________________
> 
> PART SQUID CONFIG
> ___________________________________________________________________________
> 
> cache_mem 32172 MB
> workers 8
> cpu_affinity_map process_numbers=1,2,3,4,5,6,7,8 cores=1,3,5,7,9,11,13,15
> cache_dir rock /acapp/webcache3/storage/cossbig1/squid1 17280
> min-size=4097 max-size=262144 max-swap-rate=250 swap-timeout=350
> cache_dir rock /acapp/webcache3/storage/cosssmall1/squid1 1152
> max-size=4096 max-swap-rate=250 swap-timeout=350
> if ${process_number} = 1
> unique_hostname fast_squid${process_number}
> access_log stdio:/acapp/logs/webcache3/squid${process_number}/access.log
> squid
> cache_log /acapp/logs/webcache3/squid${process_number}/cache.log


FYI the idea behind using ${process_number} within config lines is to
avoid the need to wrap them inside the if ${process_number} config block
conditions.

Amos



From squid3 at treenet.co.nz  Tue Aug  9 16:12:22 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Aug 2016 04:12:22 +1200
Subject: [squid-users] how to install squid proxy with source package
 downloaded, not use apt?
In-Reply-To: <1470754287785-4678813.post@n4.nabble.com>
References: <1470754287785-4678813.post@n4.nabble.com>
Message-ID: <4db1a229-a4de-c82f-963c-b8263410e306@treenet.co.nz>

On 10/08/2016 2:51 a.m., james82 wrote:
> I use kali linux. I want to install squid proxy in my kali "cute"linux, not
> by use apt-get install, because i'm not sure they have lastest version. I
> want to install with source file download from official squid website.
> Please tell me how to do this? Is it work perfect with this method.
> 

Kali is based on Debian Testing. So you can use the Debian Testing or
Sid repositories to get the latest packages. It has 3.5.19 at present.
Which should be current enough, there were no critical changes in the .20.

The best way to do custom installs is to start with an install of the
distro package with apt. That gives you all the integration scripts,
paths and permissions etc.

Then do your custom compile over the top. Details specific for Debian
are at <http://wiki.squid-cache.org/KnowledgeBase/Debian>. They should
work just as well for Kali.

Amos



From squid3 at treenet.co.nz  Tue Aug  9 16:23:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Aug 2016 04:23:34 +1200
Subject: [squid-users] Rate limiting bad clients?
In-Reply-To: <858F001E-FA29-4319-975A-4BF21811A584@getbusi.com>
References: <858F001E-FA29-4319-975A-4BF21811A584@getbusi.com>
Message-ID: <f5e1392a-5d46-6b5a-0bd4-89dd744812c4@treenet.co.nz>

On 9/08/2016 5:39 p.m., Dan Charlesworth wrote:
> Hi all,
> 
> This is more of a squid-adjacent query. Hopefully relevant enough for someone here to help?
> 
> I?m sick of all these web apps that take it upon themselves to hammer proxies when they don?t get the response they want, like if they have to authenticate for example. On big networks, behind a forward proxy, there?s always a few computers with some software doing dozens of identical, failing, requests per second.
> 
> - What?s a good approach for rate limiting the clients computers which are doing this?
> - Can anyone point to a good tutorial for this using, say, iptables if that?s appropriate?
> 
> Any advice welcome.

HTTP being stateless Squid does not track correlations enough to do
anything like that.

I've been suggesting people add an external ACL helper that tracks
requests per client IP and tells Squid whether to accept or reject any
given request based on its history.
Recent Squid releases bundle ext_delayer_acl which is a Perl script that
can be adjusted for this type of thing.

Amos



From erdosain9 at gmail.com  Tue Aug  9 21:07:56 2016
From: erdosain9 at gmail.com (Erdosain9)
Date: Tue, 9 Aug 2016 18:07:56 -0300
Subject: [squid-users] HSTS and MOZILLA_PKIX_ERROR_V1_CERT_USED_AS_CA
Message-ID: <CA+EQfqEHOKOcQ9HTLEhD+XZinZT6A7OzE5oe_iFh8s9njfgU6A@mail.gmail.com>

Hi to all.
I keep trying to achieve inspect https. I think I'm close to doing. This is
my current configuration relative to ssl-bump.

   -

   # Squid listen Port
   http_port 192.168.1.215:3128
   https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem

   #always_direct allow all
   ssl_bump server-first all
   #sslproxy_cert_error deny all
   #sslproxy_flags DONT_VERIFY_PEER

   sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
   sslcrtd_children 8 startup=1 idle=1

   -
-
- *Im having this error in firefox.*

*when try google.com <http://google.com>*
The owner of www.google.com has configured their website improperly. To
protect your information from being stolen, Firefox has not connected to
this website.

This site uses HTTP Strict Transport Security (HSTS) to specify that
Firefox only connect to it securely. As a result, it is not possible to add
an exception for this certificate.

*or yahoo.com <http://yahoo.com>*

https://search.yahoo.com/yhs/search?p=X.509+version+1+
certificates+are+deprecated&ei=UTF-8&hspart=mozilla&hsimp=yhs-005
 An X.509 version 1 certificate that is not a trust anchor was used to
issue the server's certificate. X.509 version 1 certificates are deprecated
and should not be used to sign other certificates.
HTTP Strict Transport Security: true
HTTP Public Key Pinning: false



*MOZILLA_PKIX_ERROR_V1_CERT_USED_AS_CA*

When i create self-signed certificate, i do like this:

   -

   openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes *-x509
*-keyout myCA.pem  -out myCA.pem


so what can i change to avoid the problem???
Thanks to all!!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160809/45ab4304/attachment.htm>

From David.J.Berkes at pjc.com  Tue Aug  9 22:43:58 2016
From: David.J.Berkes at pjc.com (Berkes, David)
Date: Tue, 9 Aug 2016 22:43:58 +0000
Subject: [squid-users] squid refresh_pattern / cache question
Message-ID: <916606669CFF224AB6997E9DB783F6EACCCBF48C@ESCML200.corp.pjc.com>


I have a question about the caching mechanism and "refresh_pattern" specifically.  I had the following configured for my company.  Lateley there have been complaints that people are seeing old pages and not the recent content...specifically when going to www.bbc.com<http://www.bbc.com>.

Im not actually sure what is not allowing the bbc.com pages to not get updated, but at this point, I just want to let squid do normal caching without any refresh_pattern or "fancy" settings.

My question is will I still get caching features/benefits of squid after I remove the "refresh_pattern" entries?

Thank you.




##############################################
# disk caching settings
##############################################
#
refresh_pattern -i \.(3gp|7z|ace|asx|avi|bin|cab|dat|deb|rpm|divx|dvr-ms)      20160 80% 20160 ignore-no-cache ignore-no-store ignore-private override-expire override-lastmod reload-into-ims ignore-reload
refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv) 20160 80% 20160 ignore-no-cache ignore-no-store ignore-private override-expire override-lastmod reload-into-ims ignore-reload
refresh_pattern -i \.(jp(e?g|e|2)|gif|pn[pg]|bm?|tiff?|ico|swf|css|js)         20160 80% 20160 ignore-no-cache ignore-no-store ignore-private override-expire override-lastmod reload-into-ims ignore-reload
refresh_pattern -i \.(mp(e?g|a|e|1|2|3|4)|mk(a|v)|ms(i|u|p))                   20160 80% 20160 ignore-no-cache ignore-no-store ignore-private override-expire override-lastmod reload-into-ims ignore-reload
refresh_pattern -i \.(og(x|v|a|g)|rar|rm|r(a|p)m|snd|vob|wav)                  20160 80% 20160 ignore-no-cache ignore-no-store ignore-private override-expire override-lastmod reload-into-ims ignore-reload
refresh_pattern -i \.(pp(s|t)|wax|wm(a|v)|wmx|wpl|zip|cb(r|z|t))               20160 80% 20160 ignore-no-cache ignore-no-store ignore-private override-expire override-lastmod reload-into-ims ignore-reload

refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern ^ftp:    10080 95% 43200 override-lastmod reload-into-ims

refresh_pattern -i \.(doc|pdf)$           20160 90% 20160 override-expire ignore-no-cache ignore-no-store ignore-private reload-into-ims
refresh_pattern -i \.(html|htm)$          1440   40% 20160 ignore-no-cache ignore-no-store ignore-private override-expire reload-into-ims
refresh_pattern . 0 40% 20160
________________________________

Piper Jaffray & Co. Since 1895. Member SIPC and NYSE. Learn more at www.piperjaffray.com. Piper Jaffray corporate headquarters is located at 800 Nicollet Mall, Minneapolis, MN 55402.

Piper Jaffray outgoing and incoming e-mail is electronically archived and recorded and is subject to review, monitoring and/or disclosure to someone other than the recipient. This e-mail may be considered an advertisement or solicitation for purposes of regulation of commercial electronic mail messages. If you do not wish to receive commercial e-mail communications from Piper Jaffray, go to: www.piperjaffray.com/do_not_email to review the details and submit your request to be added to the Piper Jaffray "Do Not E-mail Registry." For additional disclosure information see www.piperjaffray.com/disclosures
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160809/5e6e475b/attachment.htm>

From squid3 at treenet.co.nz  Tue Aug  9 22:48:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Aug 2016 10:48:42 +1200
Subject: [squid-users] HSTS and MOZILLA_PKIX_ERROR_V1_CERT_USED_AS_CA
In-Reply-To: <CA+EQfqEHOKOcQ9HTLEhD+XZinZT6A7OzE5oe_iFh8s9njfgU6A@mail.gmail.com>
References: <CA+EQfqEHOKOcQ9HTLEhD+XZinZT6A7OzE5oe_iFh8s9njfgU6A@mail.gmail.com>
Message-ID: <8364f849-acd2-b973-91fd-c6767e4ab7ac@treenet.co.nz>

On 10/08/2016 9:07 a.m., Erdosain9 wrote:
> 
> *MOZILLA_PKIX_ERROR_V1_CERT_USED_AS_CA*
> 
> When i create self-signed certificate, i do like this:
> 
>    -
> 
>    openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes *-x509
> *-keyout myCA.pem  -out myCA.pem
> 
> 
> so what can i change to avoid the problem???

A quick search brings up other people with the same problem who solved
it by adding the "-extensions v3_ca" option to the command for creating
the CA certificate.

Amos



From squid3 at treenet.co.nz  Tue Aug  9 23:11:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Aug 2016 11:11:39 +1200
Subject: [squid-users] squid refresh_pattern / cache question
In-Reply-To: <916606669CFF224AB6997E9DB783F6EACCCBF48C@ESCML200.corp.pjc.com>
References: <916606669CFF224AB6997E9DB783F6EACCCBF48C@ESCML200.corp.pjc.com>
Message-ID: <5cb2932e-cb71-d983-bb9f-cb96c2060c8f@treenet.co.nz>

On 10/08/2016 10:43 a.m., Berkes, David wrote:
> 
> I have a question about the caching mechanism and "refresh_pattern" specifically.  I had the following configured for my company.  Lateley there have been complaints that people are seeing old pages and not the recent content...specifically when going to www.bbc.com<http://www.bbc.com>.
> 
> Im not actually sure what is not allowing the bbc.com pages to not get updated, but at this point, I just want to let squid do normal caching without any refresh_pattern or "fancy" settings.
> 
> My question is will I still get caching features/benefits of squid after I remove the "refresh_pattern" entries?

Yes you will get caching. Just on a slightly different set of objects
than are being cached now.

The HTTP protocol defines an algorithm for heuristic caching. Which is
based on the headers sent by the server (or not) for each object. All
that refresh_pattern does is provide default values for the headers if
the server did not send one or other. The ignore/override options make
Squid calculate that algorithm as if certain header values were not sent
even if they were.


I suggest you try the following changes first though:

* remove the ignore-no-cache ignore-no-store ignore-private options.

* add the refresh_pattern for correctly handling dynamic content. This
should be placed as second to last pattern, just above the '.' one.

  refresh_pattern -i (/cgi-bin/|\?) 0 0% 0


That should make your Squid obey the HTTP protocol more accurately. If
the problem remains after those changes, then you need to take a closer
look at what exactly is going on with those problem URLs.


Amos



From fastestsuperman at gmail.com  Wed Aug 10 05:59:48 2016
From: fastestsuperman at gmail.com (james82)
Date: Tue, 9 Aug 2016 22:59:48 -0700 (PDT)
Subject: [squid-users] how can I coplete this squid tutorial?
Message-ID: <1470808788551-4678821.post@n4.nabble.com>

I find a tutorial on this website:
http://www.deckle.co.uk/squid-users-guide/squid-configuration-basics.html
. I want to complete it. I don't know where is those line: 

acl localnet src 192.168.1.0/255.255.255.0
..
http_access allow  localnet 
icp_access  allow  localnet

Can somebody help me? 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/how-can-I-coplete-this-squid-tutorial-tp4678821.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Martin.Frosch at x-tention.at  Wed Aug 10 06:49:57 2016
From: Martin.Frosch at x-tention.at (Frosch Martin)
Date: Wed, 10 Aug 2016 06:49:57 +0000
Subject: [squid-users] Problem with SSL client setting in case of erverse
	proxy
Message-ID: <39d791ea766d45abae3f87684c10031d@XTDCMXMB11.ks.local>

Hello,

I hope I am right here.

I use Squid Version 3.5.20 as reverse Proxy for Outlook (2010) Anywhere and OWA.
The problem is that I cannot transfer Files bigger than 2MB since the Microsoft Update https://technet.microsoft.com/de-de/library/security/3042058. This Update brings new Cipher Versions to IIS. Now I want to use older Cipher Sites but the following line of Squid config is not working 100%.

cache_peer X.X.X.X parent 443 0 ssl no-query originserver sslflags=DONT_VERIFY_PEER ssloptions=NO_SSLv2:NO_SSLv3:ALL:SINGLE_DH_USE:SINGLE_ECDH_USE:NO_TICKET sslcipher=AES256-SHA login=PASS name=exchangeServer standby=5

Squid as Client uses always 38 Cipher Suites, no matter what I define as ssloptions or sslcipher.

Can You help me with that Problem?

Best regards and thanks in advance!

Martin


________________________________

[ Disclaimer for x-tention.at ]

This message and any attachment are confidential and may be privileged or otherwise protected from disclosure.
If you are not the intended recipient, please return the email to the sender and delete this message and
any attachment from your system. If you are not the intended recipient you must not copy this message or
attachment or disclose the contents to any other person.

Email messages may be monitored and/or
recorded by x-tention Informationstechnologie GmbH.

Thank you for your co-operation.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160810/d477a6c7/attachment.htm>

From eliezer at ngtech.co.il  Wed Aug 10 11:19:38 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 10 Aug 2016 14:19:38 +0300
Subject: [squid-users] Range header is a hit ratio killer
In-Reply-To: <170cdcb0-c784-e822-5510-a0565a48adf3@gmail.com>
References: <80e05c94-a690-0571-4743-388d298c4f42@gmail.com>
 <01e101d1f0ae$7f193830$7d4ba890$@ngtech.co.il>
 <170cdcb0-c784-e822-5510-a0565a48adf3@gmail.com>
Message-ID: <091b01d1f2f9$1579d720$406d8560$@ngtech.co.il>

Well it will be different from system to system but one of the main things was not about prefetching.
Indeed sometimes prefetching is not possible, but, when you have a situation which parallel requests are causing amplified download by your proxy it means the proxy or the clients have some conflict of "interest".
The client and you will blame the proxy while you will probably blame the software or the code.

Prefetching in the caching world and from my perspective and understanding of how proxies work is only compared to repeated download.
Means that since a proxy can never fetch something without the client requesting anything, then we can separate couple things in the proxy.
The request, the prefetching and the cache policy are couple different "things".
When you are using a rule\config which forces the proxy to utilize 500% of the bandwidth then you have an "issue".
This specific issue can be converted from one to another with enough admin logic leaving the cache policy to the internal parts of the cache.

The simplest way to understand the issue is to understand what Amos described.. It is possible that the proxy is trying to download the full object 5 times if 5 clients(or the  same but couple connections) are asking the same object.
The solution to such an issue would be to consolidate these requests into one.
And since code changes in Squid takes time you could convert the issue into another form.
The simplest way to do so is inspect each request in a level that will identify a 206 request and will send it into one "prefetch" queue.
This prefetch external queue software\script\code will be able to resolve the "500% amplification" which some would describe as an attack.
This way the clients requests will be served live and without causing amplification attacks while the cache will be filled externally\artificially with objects.
Depends on the cache purpose you would be able to make it work.
I have implemented couple times this idea in the past using a set of ruby scripts and I must admit that some objects do not worth the code invested in them.

Hope it clears the picture\words and meanings,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: k simon [mailto:chio1990 at gmail.com] 
Sent: Tuesday, August 9, 2016 6:36 AM
To: Eliezer Croitoru; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Range header is a hit ratio killer



? 16/8/7 21:20, Eliezer Croitoru ??:
> Hey Simon,
>
> I do not know the plans but it will depend on couple things which can fit to one case but not the other.
> The assumption that we can fetch any part of the object is the first step for any solution what so ever.
> However it is not guaranteed that each request will be public.
>
> The idea of static chunks exists for many years in many applications and in many forms and YouTube videos player uses a similar idea. Google video clients and servers uses a bytes "range" request in the url rather then in the request header.
> Technically it would be possible to implement such an idea but it has it's own cost.
> Eventually if the file is indeed public(what squid was designed to cache) then it might not be of a big problem.
> Depends on the target sites a the solution will be different.
> Before deciding on a specific solution my preferred path is to analyze the requests.
>
> By observing amplified traffic of 500% to  clients side you mean that the incoming traffic to the server is 500% compared to the output towards the clients?
> If so I think that there might be a "smarter" solution then 206 range offset limit.
> The old method of prefetching works pretty good in many cases. From what you describe it might have better luck then the plain "fetch everything on the wire in real time".
>
> I cannot guarantee that prefetching is the right solution for you but I think that a case like this deserves couple eyes to understand if there is a right way to handle the situation.
>
  I think prefetch may not be fit for forward proxy, as we do not know what's "hot" request exactly. LRU should do more efficient.

Simon



From David.J.Berkes at pjc.com  Wed Aug 10 14:24:14 2016
From: David.J.Berkes at pjc.com (Berkes, David)
Date: Wed, 10 Aug 2016 14:24:14 +0000
Subject: [squid-users] squid refresh_pattern / cache question
In-Reply-To: <5cb2932e-cb71-d983-bb9f-cb96c2060c8f@treenet.co.nz>
References: <916606669CFF224AB6997E9DB783F6EACCCBF48C@ESCML200.corp.pjc.com>
 <5cb2932e-cb71-d983-bb9f-cb96c2060c8f@treenet.co.nz>
Message-ID: <916606669CFF224AB6997E9DB783F6EACCCBF7DF@ESCML200.corp.pjc.com>

Thank you very much Amos.  Your support and the Squid product works very good for us.  It is handling all of our traffic very well and have not had any issues since the change.

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, August 09, 2016 6:12 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid refresh_pattern / cache question

On 10/08/2016 10:43 a.m., Berkes, David wrote:
>
> I have a question about the caching mechanism and "refresh_pattern" specifically.  I had the following configured for my company.  Lateley there have been complaints that people are seeing old pages and not the recent content...specifically when going to www.bbc.com<https://urldefense.proofpoint.com/v2/url?u=http-3A__www.bbc.com&d=CwIGaQ&c=y6v6TkqbF5T5q8gzoA5_qyxfBe6wpRCKPt3qOZXx4sE&r=cEqld2WF5YXp35LOdsMCPdSMKFHyVQBUWZMc0D_9qzI&m=XTlkALphJqTeTc9DfX4Rm5TaIO-jZtR0yZQ0tNYNHOE&s=5GPJPKVFqHYAv0pEZYSGQSDS8GijxSR7NaGDZIjtvdM&e= >.
>
> Im not actually sure what is not allowing the bbc.com pages to not get updated, but at this point, I just want to let squid do normal caching without any refresh_pattern or "fancy" settings.
>
> My question is will I still get caching features/benefits of squid after I remove the "refresh_pattern" entries?

Yes you will get caching. Just on a slightly different set of objects than are being cached now.

The HTTP protocol defines an algorithm for heuristic caching. Which is based on the headers sent by the server (or not) for each object. All that refresh_pattern does is provide default values for the headers if the server did not send one or other. The ignore/override options make Squid calculate that algorithm as if certain header values were not sent even if they were.


I suggest you try the following changes first though:

* remove the ignore-no-cache ignore-no-store ignore-private options.

* add the refresh_pattern for correctly handling dynamic content. This should be placed as second to last pattern, just above the '.' one.

  refresh_pattern -i (/cgi-bin/|\?) 0 0% 0


That should make your Squid obey the HTTP protocol more accurately. If the problem remains after those changes, then you need to take a closer look at what exactly is going on with those problem URLs.


Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://urldefense.proofpoint.com/v2/url?u=http-3A__lists.squid-2Dcache.org_listinfo_squid-2Dusers&d=CwIGaQ&c=y6v6TkqbF5T5q8gzoA5_qyxfBe6wpRCKPt3qOZXx4sE&r=cEqld2WF5YXp35LOdsMCPdSMKFHyVQBUWZMc0D_9qzI&m=XTlkALphJqTeTc9DfX4Rm5TaIO-jZtR0yZQ0tNYNHOE&s=dcU9dnoc_YN_qUGX_4NE01SGVn7A52SB_O3E2dm7BIA&e=
________________________________


Piper Jaffray & Co. Since 1895. Member SIPC and NYSE. Learn more at www.piperjaffray.com. Piper Jaffray corporate headquarters is located at 800 Nicollet Mall, Minneapolis, MN 55402.

Piper Jaffray outgoing and incoming e-mail is electronically archived and recorded and is subject to review, monitoring and/or disclosure to someone other than the recipient. This e-mail may be considered an advertisement or solicitation for purposes of regulation of commercial electronic mail messages. If you do not wish to receive commercial e-mail communications from Piper Jaffray, go to: www.piperjaffray.com/do_not_email to review the details and submit your request to be added to the Piper Jaffray "Do Not E-mail Registry." For additional disclosure information see www.piperjaffray.com/disclosures

From eliezer at ngtech.co.il  Wed Aug 10 23:02:17 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 11 Aug 2016 02:02:17 +0300
Subject: [squid-users] squid 3.3.8 https (Yuri Voinov)
In-Reply-To: <CAKqfNrkrzXP=Bry9-ijy_hdpfmxER05szDGLRvMiX+WsohkBZA@mail.gmail.com>
References: <CAKqfNrkrzXP=Bry9-ijy_hdpfmxER05szDGLRvMiX+WsohkBZA@mail.gmail.com>
Message-ID: <007e01d1f35b$3dd1fb00$b975f100$@ngtech.co.il>

To do what?

If you want to implement QOS you can do that pretty easily on the OS level.

Since you are using a regular forward proxy you can monitor youtube traffic using some external acl or a logging helper and add new domains IP addresses to an iptables IPSET which will mark these connections.

There is a risk that some of these are IP will be shared with other google services but most of the problematic content is on the subdomains of .googlevideo.com and it will be pretty simple to mark then.

 

It would be better if you could upgrade to a more recent version of squid but I think you should consider the options first since maybe even with newer versions of squid you would need a combination to get a full match for your needs.

 

Eliezer

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Erdosain9
Sent: Tuesday, August 9, 2016 12:54 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid 3.3.8 https (Yuri Voinov)

 

but, its possible to do with this version?? (3.3.8).... i have CentOs 7 and thats the official packet.

thanks

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160811/035b1d99/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160811/035b1d99/attachment.png>

From erdosain9 at gmail.com  Wed Aug 10 23:37:51 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 10 Aug 2016 16:37:51 -0700 (PDT)
Subject: [squid-users] squid 3.3.8 https (Yuri Voinov)
In-Reply-To: <007e01d1f35b$3dd1fb00$b975f100$@ngtech.co.il>
References: <CAKqfNrkrzXP=Bry9-ijy_hdpfmxER05szDGLRvMiX+WsohkBZA@mail.gmail.com>
 <007e01d1f35b$3dd1fb00$b975f100$@ngtech.co.il>
Message-ID: <1470872271669-4678826.post@n4.nabble.com>

Yes, sorry, i break the "thread"... i was talking about this
http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-3-3-8-https-td4678795.html

i just want to limit youtube, not block youtube... just limit the bandwith.
i can do that without https?? i try with dealy pools, but not working with
https....... there's other way??
Thanks!!!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Re-squid-3-3-8-https-Yuri-Voinov-tp4678799p4678826.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Wed Aug 10 23:44:56 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 10 Aug 2016 16:44:56 -0700 (PDT)
Subject: [squid-users] HSTS and MOZILLA_PKIX_ERROR_V1_CERT_USED_AS_CA
In-Reply-To: <8364f849-acd2-b973-91fd-c6767e4ab7ac@treenet.co.nz>
References: <CA+EQfqEHOKOcQ9HTLEhD+XZinZT6A7OzE5oe_iFh8s9njfgU6A@mail.gmail.com>
 <8364f849-acd2-b973-91fd-c6767e4ab7ac@treenet.co.nz>
Message-ID: <1470872696660-4678827.post@n4.nabble.com>

Thanks!it works!!!but...........  have this strange behavior in
access.log1470835274.046    896 192.168.1.172 NONE/200 0 CONNECT
mail.google.com:443 - HIER_DIRECT/172.217.28.229 -1470835274.569    521
192.168.1.172 TCP_MISS/204 406 GET https://mail.google.com/mail/gxlu? -
PINNED/2800:3f0:4002:800::2005 -1470835339.166    797 192.168.1.172 NONE/200
0 CONNECT www.facebook.com:443 - HIER_DIRECT/31.13.73.36 -1470835339.398   
228 192.168.1.172 TCP_MISS/200 1995 POST https://www.facebook.com/ajax/bz -
PINNED/2a03:2880:f100:83:face:b00c:0:25de
application/x-javascript1470835490.537   2164 192.168.1.172 NONE/200 0
CONNECT www.facebook.com:443 - HIER_DIRECT/31.13.85.36 -1470835491.041   
504 192.168.1.172 TCP_MISS/200 1800 POST https://www.facebook.com/ajax/bz -
PINNED/2a03:2880:f100:83:face:b00c:0:25de application/x-jfirst a *NONE/200
*when i go to a https web... it works, but what can be that
"none/200"???*this is now my squid.conf:*# Squid listen Porthttp_port
192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pemalways_direct allow allssl_bump server-first
all#sslproxy_cert_error deny all#sslproxy_flags
DONT_VERIFY_PEERsslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db
-M 4MBsslcrtd_children 8 startup=1 idle=1Thanks!!!!!!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HSTS-and-MOZILLA-PKIX-ERROR-V1-CERT-USED-AS-CA-tp4678817p4678827.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Thu Aug 11 01:50:16 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 11 Aug 2016 04:50:16 +0300
Subject: [squid-users] squid 3.3.8 https (Yuri Voinov)
In-Reply-To: <1470872271669-4678826.post@n4.nabble.com>
References: <CAKqfNrkrzXP=Bry9-ijy_hdpfmxER05szDGLRvMiX+WsohkBZA@mail.gmail.com>
 <007e01d1f35b$3dd1fb00$b975f100$@ngtech.co.il>
 <1470872271669-4678826.post@n4.nabble.com>
Message-ID: <00bd01d1f372$b591fd40$20b5f7c0$@ngtech.co.il>

There are couple ways to do so but your speed issues are probably not from access to the domains in the logs:
www.youtube.com

You will need to "slow" down domains such as:
r7---sn-nhpax-ua8s.googlevideo.com

You don't need squid for that but you would be able to track the relevant IP addresses to limit access towards.
I can write a log "follower" script that will update an IPTSET iptables target.
Do you have any experience with CentOS QOS or rate limiting?

I will be able to write the script only next week if it will help you.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, August 11, 2016 2:38 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid 3.3.8 https (Yuri Voinov)

Yes, sorry, i break the "thread"... i was talking about this http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-3-3-8-https-td4678795.html

i just want to limit youtube, not block youtube... just limit the bandwith.
i can do that without https?? i try with dealy pools, but not working with https....... there's other way??
Thanks!!!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Re-squid-3-3-8-https-Yuri-Voinov-tp4678799p4678826.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Thu Aug 11 01:55:19 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 11 Aug 2016 04:55:19 +0300
Subject: [squid-users] how can I coplete this squid tutorial?
In-Reply-To: <1470808788551-4678821.post@n4.nabble.com>
References: <1470808788551-4678821.post@n4.nabble.com>
Message-ID: <00bf01d1f373$6a1e8a30$3e5b9e90$@ngtech.co.il>

Hey james,

We can try to help you but I couldn't understand your question.
The squid.conf file by default contains a limited set of configuration lines since others are bound to the default.
You can see the full list of options in the squid.conf.documented.
Depends on your OS version you will be able to access the file on different locations in the file system.
The configuration that are mentioned in the document\tutorial are specific and some of then will not appear in the default squid.conf directly but can be added manually.
What OS are you using?
What are you trying to achieve? Basic caching or filtering or just access control?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of james82
Sent: Wednesday, August 10, 2016 9:00 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] how can I coplete this squid tutorial?

I find a tutorial on this website:
http://www.deckle.co.uk/squid-users-guide/squid-configuration-basics.html
. I want to complete it. I don't know where is those line: 

acl localnet src 192.168.1.0/255.255.255.0
..
http_access allow  localnet 
icp_access  allow  localnet

Can somebody help me? 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/how-can-I-coplete-this-squid-tutorial-tp4678821.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Aug 11 03:34:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 11 Aug 2016 15:34:26 +1200
Subject: [squid-users] HSTS and MOZILLA_PKIX_ERROR_V1_CERT_USED_AS_CA
In-Reply-To: <1470872696660-4678827.post@n4.nabble.com>
References: <CA+EQfqEHOKOcQ9HTLEhD+XZinZT6A7OzE5oe_iFh8s9njfgU6A@mail.gmail.com>
 <8364f849-acd2-b973-91fd-c6767e4ab7ac@treenet.co.nz>
 <1470872696660-4678827.post@n4.nabble.com>
Message-ID: <41c92ef9-dd7e-edf0-fb13-b2fa77904b01@treenet.co.nz>

On 11/08/2016 11:44 a.m., erdosain9 wrote:
> Thanks!it works!!!but...........  have this strange behavior in
> access.log1470835274.046    896 192.168.1.172 NONE/200 0 CONNECT
> mail.google.com:443 - HIER_DIRECT/172.217.28.229 -1470835274.569    521
> 192.168.1.172 TCP_MISS/204 406 GET https://mail.google.com/mail/gxlu? -
> PINNED/2800:3f0:4002:800::2005 -1470835339.166    797 192.168.1.172 NONE/200
> 0 CONNECT www.facebook.com:443 - HIER_DIRECT/31.13.73.36 -1470835339.398   
> 228 192.168.1.172 TCP_MISS/200 1995 POST https://www.facebook.com/ajax/bz -
> PINNED/2a03:2880:f100:83:face:b00c:0:25de
> application/x-javascript1470835490.537   2164 192.168.1.172 NONE/200 0
> CONNECT www.facebook.com:443 - HIER_DIRECT/31.13.85.36 -1470835491.041   
> 504 192.168.1.172 TCP_MISS/200 1800 POST https://www.facebook.com/ajax/bz -
> PINNED/2a03:2880:f100:83:face:b00c:0:25de application/x-jfirst a *NONE/200

> *when i go to a https web... it works, but what can be that
> "none/200"???

Squid represents port-443 interception as a CONNECT request during the
time bumping is going on. So that if it fails is can fallback to
treating it as an opaque CONNECT tunnel whch can be relayed through
peers etc.

That also lets you have the chance to perform http_access controls on
the CONNECT based on the client presented TCP or TLS details before the
TLS server is contacted during bumping. In the same sort of way you
would get a chance to block early for port-80 intercepted requests.

Amos



From carlopmart at gmail.com  Thu Aug 11 07:04:16 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Thu, 11 Aug 2016 07:04:16 +0000
Subject: [squid-users] A problem with a refresh pattern rule
Message-ID: <20160811070416.GA3411@beagle.bcn.sia.es>

Hi all,

 I am doing some modifications in refresh_patterns rules in a squid host (release 3.5.20) and it seems they are working, with the exception of this one:

refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)  129600  80%  129600  override-expire override-lastmod reload-into-ims ignore-reload

 When I run 'squid -k parse' returns me the following error:

2016/08/11 06:57:33| /etc/squid/squid.conf line 173: refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)     129600  80%  129600  override-expire override-lastmod reload-into-ims ignore-reload
2016/08/11 06:57:33| refreshAddToList: Invalid regular expression '\.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)': empty (sub)expression

 Searching where I am doing the mistake, I don't find any problem with "\.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)". Where am I doing the mistake??

 On the other side, I see the following warnings also:

2016/08/11 06:57:33| WARNING: use of 'override-expire' in 'refresh_pattern' violates HTTP
2016/08/11 06:57:33| WARNING: use of 'override-lastmod' in 'refresh_pattern' violates HTTP
2016/08/11 06:57:33| WARNING: use of 'reload-into-ims' in 'refresh_pattern' violates HTTP
2016/08/11 06:57:33| WARNING: use of 'ignore-reload' in 'refresh_pattern' violates HTTP

 I have enabled these options "override-expire override-lastmod reload-into-ims ignore-reload" on some other patterns. Is this wrong??

Thanks.

-- 
Greetings,
C. L. Martinez


From squid3 at treenet.co.nz  Thu Aug 11 10:38:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 11 Aug 2016 22:38:13 +1200
Subject: [squid-users] A problem with a refresh pattern rule
In-Reply-To: <20160811070416.GA3411@beagle.bcn.sia.es>
References: <20160811070416.GA3411@beagle.bcn.sia.es>
Message-ID: <c8f5e0c1-ecbe-5413-1b4f-7d9513a69dcc@treenet.co.nz>

On 11/08/2016 7:04 p.m., C. L. Martinez wrote:
> Hi all,
> 
>  I am doing some modifications in refresh_patterns rules in a squid host (release 3.5.20) and it seems they are working, with the exception of this one:
> 
> refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)  129600  80%  129600  override-expire override-lastmod reload-into-ims ignore-reload
> 
>  When I run 'squid -k parse' returns me the following error:
> 
> 2016/08/11 06:57:33| /etc/squid/squid.conf line 173: refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)     129600  80%  129600  override-expire override-lastmod reload-into-ims ignore-reload
> 2016/08/11 06:57:33| refreshAddToList: Invalid regular expression '\.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)': empty (sub)expression
> 
>  Searching where I am doing the mistake, I don't find any problem with "\.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)". Where am I doing the mistake??
> 

That pattern works fine for me. Must be something to do with the regex
library on your system.

I think the error message is about the (x-|)flv piece. The absence of
anything between | and ) is the only bit that coudl be called an 'empty
sub-expression' there. You might have to change that to x-flv|flv.


>  On the other side, I see the following warnings also:
> 
> 2016/08/11 06:57:33| WARNING: use of 'override-expire' in 'refresh_pattern' violates HTTP
> 2016/08/11 06:57:33| WARNING: use of 'override-lastmod' in 'refresh_pattern' violates HTTP
> 2016/08/11 06:57:33| WARNING: use of 'reload-into-ims' in 'refresh_pattern' violates HTTP
> 2016/08/11 06:57:33| WARNING: use of 'ignore-reload' in 'refresh_pattern' violates HTTP
> 
>  I have enabled these options "override-expire override-lastmod reload-into-ims ignore-reload" on some other patterns. Is this wrong??

Those are WARNINGs. Not an error. They instruct Squid to do things which
are outside the HTTP specification. You may encounter trouble with some
traffic because of that changed behaviour.

The warnings are there to make sure you awre aware something risky is
being done, and when you run into trouble with those options it is
probably not Squid bugs but your choice to violate the standard HTTP
behaviour which caused it.

Amos



From squid3 at treenet.co.nz  Thu Aug 11 11:09:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 11 Aug 2016 23:09:14 +1200
Subject: [squid-users] Problem with SSL client setting in case of
 erverse proxy
In-Reply-To: <39d791ea766d45abae3f87684c10031d@XTDCMXMB11.ks.local>
References: <39d791ea766d45abae3f87684c10031d@XTDCMXMB11.ks.local>
Message-ID: <0d6f7f62-6afc-c261-4f74-e95076883113@treenet.co.nz>

On 10/08/2016 6:49 p.m., Frosch Martin wrote:
> Hello,
> 
> I hope I am right here.
> 
> I use Squid Version 3.5.20 as reverse Proxy for Outlook (2010)
> Anywhere and OWA. The problem is that I cannot transfer Files bigger
> than 2MB since the Microsoft Update
> https://technet.microsoft.com/de-de/library/security/3042058. This
> Update brings new Cipher Versions to IIS. Now I want to use older
> Cipher Sites but the following line of Squid config is not working
> 100%.

Why do you want to force bad security when better is available?

> 
> cache_peer X.X.X.X parent 443 0 ssl no-query originserver
> sslflags=DONT_VERIFY_PEER
> ssloptions=NO_SSLv2:NO_SSLv3:ALL:SINGLE_DH_USE:SINGLE_ECDH_USE:NO_TICKET

Process those options (instructions) from left-to-right in your head.
You should see that all things *enabled* at the end of it. That includes
SSLv2 and SSLv3 being enabled.

Hint: "ALL" force-enables everything the library is capable of.
Restrictions can only follow after it in the options list.

> sslcipher=AES256-SHA login=PASS name=exchangeServer standby=5
> 
> Squid as Client uses always 38 Cipher Suites, no matter what I define
> as ssloptions or sslcipher.
> 

cipher= is very rarely needed to be explicitly set. The library already
enables good ciphers, and options can enable others manually if needed.


Use of ALL in the options is often recommended by people without
understanding what it does. It enables *everything* the library is
capable of doing. Basically using it means the admin (or whoever wrote
the tutorial) thinks they know security better than the experts who
wrote the library. Then the admin/author goes and lists removal of the
(often few) things they know are bad (at that point in time) - often
missing out lots of custom hacks they dont know the library just enabled
as instructed, or crypto things which are broken but long forgotten.

The best thing to do is to start with neither cipher nor options
configured at all and test what the library tries to offer. Use that
test to add specific disable/enable options to the options= list. Repeat
as necessary until what the library does meets your need.

HTH
Amos


From emz at norma.perm.ru  Thu Aug 11 11:17:52 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Thu, 11 Aug 2016 16:17:52 +0500
Subject: [squid-users] large downloads got interrupted
In-Reply-To: <bad52c96-20d6-c538-4fde-8f7c5e9326e8@treenet.co.nz>
References: <57723949.1060504@norma.perm.ru>
 <16f57ceb-f22e-25e8-ee5c-dfc3e9eeb7fa@treenet.co.nz>
 <5773DA3B.60409@norma.perm.ru>
 <bad52c96-20d6-c538-4fde-8f7c5e9326e8@treenet.co.nz>
Message-ID: <57AC5EE0.9070904@norma.perm.ru>

Hi.

On 30.06.16 17:19, Amos Jeffries wrote:
>
> Okay, I wasn't suggesting you post it here. Its likely to be too big for
> that.
>
> I would look for the messages about the large object, and its FD. Then,
> for anthing about why it was closed by Squid. Not sure what tha would be
> at this point though.
> There are some scripts in the Squid sources scripts/ directory that
> might help wade through the log. Or the grep tool.
>
>
I enabled logLevel 2 for all squid facilities, but so far I didn't
fugura out any pattern from log. The only thing I noticed - is that for
large download the Recv-Q value reported by the netstat for a particular
squid-to-server connection is extremely high, so is the Send-Q value for
a connection from squid to client. I don't know if it's a cause or a
consequence, but from my point of view this may indicate that buffers
are overflown for some reason, I think this may cause, in turn, RSTs and
connection closing - am I right ?. I still don't know whether it's a
squid fault of may be it's local OS misconfiguration.

Eugene.


From carlopmart at gmail.com  Thu Aug 11 11:22:12 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Thu, 11 Aug 2016 11:22:12 +0000
Subject: [squid-users] A problem with a refresh pattern rule
In-Reply-To: <c8f5e0c1-ecbe-5413-1b4f-7d9513a69dcc@treenet.co.nz>
References: <20160811070416.GA3411@beagle.bcn.sia.es>
 <c8f5e0c1-ecbe-5413-1b4f-7d9513a69dcc@treenet.co.nz>
Message-ID: <20160811112211.GB3411@beagle.bcn.sia.es>

On Thu 11.Aug'16 at 22:38:13 +1200, Amos Jeffries wrote:
> On 11/08/2016 7:04 p.m., C. L. Martinez wrote:
> > Hi all,
> > 
> >  I am doing some modifications in refresh_patterns rules in a squid host (release 3.5.20) and it seems they are working, with the exception of this one:
> > 
> > refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)  129600  80%  129600  override-expire override-lastmod reload-into-ims ignore-reload
> > 
> >  When I run 'squid -k parse' returns me the following error:
> > 
> > 2016/08/11 06:57:33| /etc/squid/squid.conf line 173: refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)     129600  80%  129600  override-expire override-lastmod reload-into-ims ignore-reload
> > 2016/08/11 06:57:33| refreshAddToList: Invalid regular expression '\.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)': empty (sub)expression
> > 
> >  Searching where I am doing the mistake, I don't find any problem with "\.(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv)". Where am I doing the mistake??
> > 
> 
> That pattern works fine for me. Must be something to do with the regex
> library on your system.
> 
> I think the error message is about the (x-|)flv piece. The absence of
> anything between | and ) is the only bit that coudl be called an 'empty
> sub-expression' there. You might have to change that to x-flv|flv.

Perfect!!! .. That was, thanks Amos.
> 
> 
> >  On the other side, I see the following warnings also:
> > 
> > 2016/08/11 06:57:33| WARNING: use of 'override-expire' in 'refresh_pattern' violates HTTP
> > 2016/08/11 06:57:33| WARNING: use of 'override-lastmod' in 'refresh_pattern' violates HTTP
> > 2016/08/11 06:57:33| WARNING: use of 'reload-into-ims' in 'refresh_pattern' violates HTTP
> > 2016/08/11 06:57:33| WARNING: use of 'ignore-reload' in 'refresh_pattern' violates HTTP
> > 
> >  I have enabled these options "override-expire override-lastmod reload-into-ims ignore-reload" on some other patterns. Is this wrong??
> 
> Those are WARNINGs. Not an error. They instruct Squid to do things which
> are outside the HTTP specification. You may encounter trouble with some
> traffic because of that changed behaviour.
> 
> The warnings are there to make sure you awre aware something risky is
> being done, and when you run into trouble with those options it is
> probably not Squid bugs but your choice to violate the standard HTTP
> behaviour which caused it.
> 
> Amos

 Understood. I will remove those options, then.

Many thanks.

-- 
Greetings,
C. L. Martinez


From steve at opendium.com  Thu Aug 11 16:56:23 2016
From: steve at opendium.com (Steve Hill)
Date: Thu, 11 Aug 2016 17:56:23 +0100
Subject: [squid-users] Large memory leak with ssl_peek (now partly
	understood)
Message-ID: <6ebc07c2-c8e7-13f1-8c9f-cd00ab812339@opendium.com>


I've been suffering from a significant memory leak on multiple servers 
running Squid 3.5 for months, but was unable to reproduce it in a test 
environment.  I've now figured out how to reproduce it and have done 
some investigation:

When using TPROXY, Squid generates fake "CONNECT 192.0.2.1:443" 
requests, using the IP address that the client connected to.  At 
ssl_bump step 1, we peek and Squid generates another fake "CONNECT 
example.com:443" request containing the SNI from the client's SSL handshake.

At ssl_bump step 2 we splice the connection and Squid does verification 
to make sure that example.com does actually resolve to 192.0.2.1.  If it 
doesn't, Squid is supposed to reject the connection in 
ClientRequestContext::hostHeaderVerifyFailed() to prevent clients from 
manipulating the SNI to bypass ACLs.

Unfortunately, when verification fails, rather than actually dropping 
the client's connection, Squid just leaves the client hanging. 
Eventually the client (hopefully) times out and drops the connection 
itself, but the associated ClientRequestContext is never destroyed.

This is testable by repeatedly executing:
openssl s_client -connect 17.252.76.30:443 -servername 
courier.push.apple.com

That is a traffic pattern that we see in the real world and is now 
clearly what is triggering the leak: Apple devices make connections to 
addresses within the 17.0.0.0/8 network with an SNI of 
"courier.push.apple.com".  courier.push.apple.com resolves to a CNAME 
pointing to courier-push-apple.com.akadns.net, but 
courier-push-apple.com.akadns.net doesn't exist.  Since Squid can't 
verify the connection, it won't allow it and after 30 seconds the client 
times out.  Each Apple device keeps retrying the connection, leaking a 
ClientRequestContext each time, and before long we've leaked several 
gigabytes of memory (on some networks I'm seeing 16GB or more of leaked 
RAM over 24 hours!).

Unfortunately I'm a bit lost in the Squid code and can't quite figure 
out how to gracefully terminate the connection and destroy the context.

-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Sales / enquiries:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From fastestsuperman at gmail.com  Thu Aug 11 17:15:08 2016
From: fastestsuperman at gmail.com (james82)
Date: Thu, 11 Aug 2016 10:15:08 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
Message-ID: <1470935708530-4678837.post@n4.nabble.com>

I want to do this tutorial :
https://www.linode.com/docs/networking/squid/squid-http-proxy-ubuntu-12-04,
but these are something I don't understand so much, please help me. Here is
my squid.conf file: https://ghostbin/paste/kw7pp. I can't find line
http_access like in tutorial, because have so much line 'example' have name
'http_access'. Can you edit file for me and tell me how to start squid with
it?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Tommy.Craddock at bicgraphic.com  Thu Aug 11 17:20:04 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Thu, 11 Aug 2016 17:20:04 +0000
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1470935708530-4678837.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE73C9D5F@CLWSEXCMBX02.na.bicworld.com>

Hello, 

That line is not in the default squid.conf.  That tutorial is telling you to add that line to your squid.conf.   

For ex:

  acl client src 12.34.56.78 # Home IP 
  http_access allow client


becomes:

  acl homepc src 1.2.3.4
  http_access allow homepc
 

Replace 1.2.3.4 with the IP of your PC.

?
Tommy E CRADDOCK JR

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

From fastestsuperman at gmail.com  Thu Aug 11 17:46:53 2016
From: fastestsuperman at gmail.com (james82)
Date: Thu, 11 Aug 2016 10:46:53 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE73C9D5F@CLWSEXCMBX02.na.bicworld.com>
References: <1470935708530-4678837.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73C9D5F@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <1470937613361-4678839.post@n4.nabble.com>

Are you sure about this?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678839.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fastestsuperman at gmail.com  Thu Aug 11 17:48:33 2016
From: fastestsuperman at gmail.com (james82)
Date: Thu, 11 Aug 2016 10:48:33 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1470937613361-4678839.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73C9D5F@CLWSEXCMBX02.na.bicworld.com>
 <1470937613361-4678839.post@n4.nabble.com>
Message-ID: <1470937713493-4678840.post@n4.nabble.com>

where I gonna add http_access? Can you edit the squid.conf file in ghostbin
for me and paste a new once. Please, I need your help. Hug thanks a lot.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678840.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marko.cupac at mimar.rs  Thu Aug 11 18:09:00 2016
From: marko.cupac at mimar.rs (Marko =?UTF-8?B?Q3VwYcSH?=)
Date: Thu, 11 Aug 2016 20:09:00 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1470935708530-4678837.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
Message-ID: <20160811200900.796bb108@efreet.mimar.rs>

On Thu, 11 Aug 2016 10:15:08 -0700 (PDT)
james82 <fastestsuperman at gmail.com> wrote:

> I want to do this tutorial :
> https://www.linode.com/docs/networking/squid/squid-http-proxy-ubuntu-12-04,
> but these are something I don't understand so much, please help me.

Do you want to do the tutorial, or do you want to set up squid? You
won't be able to do neither until you get familiar with http_access
directive. With all the directives in your squid.conf, actually.
http://www.squid-cache.org/Doc/config/

And while I'm in poetic mood:

The Pledge of the Network Admin
-------------------------------

This is my network. 

It is mine 
or technically my employer's, 
it is my responsibility 
and I care for it with all my heart

there are many other networks a lot like mine,

but none are just like it.

I solemnly swear 

that I will not mindlessly paste from HOWTOs.
-- 
Before enlightenment - chop wood, draw water.
After  enlightenment - chop wood, draw water.

Marko Cupa?
https://www.mimar.rs/


From Antony.Stone at squid.open.source.it  Thu Aug 11 18:23:48 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 11 Aug 2016 20:23:48 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1470935708530-4678837.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
Message-ID: <201608112023.48916.Antony.Stone@squid.open.source.it>

On Thursday 11 August 2016 at 19:15:08, james82 wrote:

> I want to do this tutorial :
> https://www.linode.com/docs/networking/squid/squid-http-proxy-ubuntu-12-04,
> but these are something I don't understand so much, please help me.

If you find this tutorial difficult to follow, I would suggest your best option 
is to try a different one, which may have been written more clearly for 
beginners to understand.

> Here is my squid.conf file: https://ghostbin/paste/kw7pp.

That URL does not work for me.

In any case, if you have questions for the list, it would be *far* better if 
you were to put your squid.conf file, without comments or blank lines (I assume 
you do know how to use grep to remove these, if you are trying to set up 
something like Squid), into the body of your emails, so that we can reply to 
specific parts of your setup, and the results can easily be seen in the list 
archives for anyone in future who has the same problems as you do.

My best guidance for you at the moment, though, is to look for the following 
line in your squid.conf file:

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

and insert the lines your tutorial tells you add immediately after that.

Once you have done that, if you continue to encounter problems, please post 
your resulting squid.conf file (without comments or blank lines) here and tell 
us exactly what the problem was.  We may then be able to help further.


Regards,


Antony.

-- 
This space intentionally has nothing but text explaining why this space has 
nothing but text explaining that this space would otherwise have been left 
blank, and would otherwise have been left blank.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From adam at endpoint.com  Thu Aug 11 18:25:04 2016
From: adam at endpoint.com (Adam Vollrath)
Date: Thu, 11 Aug 2016 13:25:04 -0500
Subject: [squid-users] Inconsistent Cache Peer Selection in Accelerator mode
	- Squid 3.3.8
Message-ID: <46d669f7-9c47-f2a7-e48b-a096c465162f@endpoint.com>

Good afternoon! I'm configuring Squid 3.3.8 on Ubuntu 14.04.5 LTS.  It's
in reverse proxy mode and has some explicit peers specified.  My issue
is that sometimes requests get forwarded to that specified peer, but
sometimes squid just forwards directly itself.

`squid.conf` has these lines:

http_port 127.0.1.2:80 accel ignore-cc act-as-origin allow-direct

cache_peer localhost parent 9900 0 no-query no-digest no-netdb-exchange
originserver name=example

cache_peer_domain example foo.example.com

Just after squid restarts, this all works as desired: Requests for
`foo.example.com` are forwarded to `localhost:9900`.  But after some
idle time, squid routes requests directly to `foo.example.com`,
bypassing `localhost:9900`.  I don't see any changes in the cache log.

How exactly does squid select upstream peers while in Accelerator mode?

Can I prevent it from forwarding requests directly?

Thank y'all for your time,
Adam Vollrath
End Point
http://www.endpoint.com


From Antony.Stone at squid.open.source.it  Thu Aug 11 18:31:27 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 11 Aug 2016 20:31:27 +0200
Subject: [squid-users] Inconsistent Cache Peer Selection in Accelerator
	mode - Squid 3.3.8
In-Reply-To: <46d669f7-9c47-f2a7-e48b-a096c465162f@endpoint.com>
References: <46d669f7-9c47-f2a7-e48b-a096c465162f@endpoint.com>
Message-ID: <201608112031.27867.Antony.Stone@squid.open.source.it>

On Thursday 11 August 2016 at 20:25:04, Adam Vollrath wrote:

> Good afternoon! I'm configuring Squid 3.3.8 on Ubuntu 14.04.5 LTS.  It's
> in reverse proxy mode and has some explicit peers specified.  My issue
> is that sometimes requests get forwarded to that specified peer, but
> sometimes squid just forwards directly itself.
> 
> `squid.conf` has these lines:
> 
> http_port 127.0.1.2:80 accel ignore-cc act-as-origin allow-direct

> Can I prevent it from forwarding requests directly?

I'm not an expert on reverse proxy mode, but do you think "allow-direct" might 
be your problem?

That sounds to me as though you are telling Squid it is allowed to forward 
requests directly, instead of having to rely on peers...


Antony.

-- 
Tinned food was developed for the British Navy in 1813.

The tin opener was not invented until 1858.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From danielwreif at gmail.com  Thu Aug 11 20:15:12 2016
From: danielwreif at gmail.com (Daniel Reif)
Date: Thu, 11 Aug 2016 17:15:12 -0300
Subject: [squid-users] Transparent proxy and non-transparent proxy on the
	same squid.
Message-ID: <CAA0zFtyEAC+xcAQWmvnkt6uFV=_AGk=JOYtMCWZ0uYzTq0UJCQ@mail.gmail.com>

There is any way to run squid in transparent mode and non-transparent
mode in the same squid?

I searched the internet and not found anything about it

The transparent proxy is necessary because there are some applications
that run on my network
that do not have proxy configuration.

But the non-transparent proxy is used with ntlm authentication for
other services.

Att

Daniel William Reif


From rousskov at measurement-factory.com  Thu Aug 11 20:22:59 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Aug 2016 14:22:59 -0600
Subject: [squid-users] Large memory leak with ssl_peek (now partly
 understood)
In-Reply-To: <6ebc07c2-c8e7-13f1-8c9f-cd00ab812339@opendium.com>
References: <6ebc07c2-c8e7-13f1-8c9f-cd00ab812339@opendium.com>
Message-ID: <19bf0746-0f96-106a-bb43-72b1f69f434f@measurement-factory.com>

On 08/11/2016 10:56 AM, Steve Hill wrote:

> At ssl_bump step 2 we splice the connection and Squid does verification
...
> Unfortunately, when verification fails, rather than actually dropping
> the client's connection, Squid just leaves the client hanging.

Hi Steve,

    This sounds very similar to Squid bug 4508. Factory proposed a fix
for that bug, but the patch is for Squid v4. You may be able to adapt it
to v3. Testing (with any version) is very welcomed, of course:

  http://bugs.squid-cache.org/show_bug.cgi?id=4508

Alex.



From Antony.Stone at squid.open.source.it  Thu Aug 11 20:30:55 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 11 Aug 2016 22:30:55 +0200
Subject: [squid-users] Transparent proxy and non-transparent proxy on
	the same squid.
In-Reply-To: <CAA0zFtyEAC+xcAQWmvnkt6uFV=_AGk=JOYtMCWZ0uYzTq0UJCQ@mail.gmail.com>
References: <CAA0zFtyEAC+xcAQWmvnkt6uFV=_AGk=JOYtMCWZ0uYzTq0UJCQ@mail.gmail.com>
Message-ID: <201608112230.55323.Antony.Stone@squid.open.source.it>

On Thursday 11 August 2016 at 22:15:12, Daniel Reif wrote:

> There is any way to run squid in transparent mode and non-transparent
> mode in the same squid?

Yes - you define one listener on port 80 for the intercept traffic (which *must* 
be redirected on the Squid box, so it must either be in the routing path from 
your clients to the Interet, or else it must get policy-routed traffic from some 
point in the default routing path), and another listener on port 3128 (or 
whatever else you prefer) for the non-transparent traffic.

If you haven't found a suitable guide to let you combine the two, I suggest 
you follow two guides, one for transparent procying, and one for direct 
proxying, combine the two sets of directives, and then come back to us with 
your squid.conf if you have any problems.

But yes, Squid can certainly do it.


Regards,


Antony.

-- 
If you were ploughing a field, which would you rather use - two strong oxen or 
1024 chickens?

 - Seymour Cray, pioneer of supercomputing

                                                   Please reply to the list;
                                                         please *don't* CC me.


From chip_pop at hotmail.com  Thu Aug 11 21:10:57 2016
From: chip_pop at hotmail.com (joe)
Date: Thu, 11 Aug 2016 14:10:57 -0700 (PDT)
Subject: [squid-users] X-Squid-Error
Message-ID: <1470949857868-4678848.post@n4.nabble.com>

only on latest squid 4 happen
Squid Cache: Version 4.0.13-20160809-r14785
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Thu, 11 Aug 2016 21:02:46 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/X-Squid-Error-tp4678848.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Aug 12 03:17:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Aug 2016 15:17:46 +1200
Subject: [squid-users] Inconsistent Cache Peer Selection in Accelerator
 mode - Squid 3.3.8
In-Reply-To: <201608112031.27867.Antony.Stone@squid.open.source.it>
References: <46d669f7-9c47-f2a7-e48b-a096c465162f@endpoint.com>
 <201608112031.27867.Antony.Stone@squid.open.source.it>
Message-ID: <fb328fe3-d001-fa0f-da40-908b891340fb@treenet.co.nz>

On 12/08/2016 6:31 a.m., Antony Stone wrote:
> On Thursday 11 August 2016 at 20:25:04, Adam Vollrath wrote:
> 
>> Good afternoon! I'm configuring Squid 3.3.8 on Ubuntu 14.04.5 LTS.  It's
>> in reverse proxy mode and has some explicit peers specified.  My issue
>> is that sometimes requests get forwarded to that specified peer, but
>> sometimes squid just forwards directly itself.
>>
>> `squid.conf` has these lines:
>>
>> http_port 127.0.1.2:80 accel ignore-cc act-as-origin allow-direct
> 
>> Can I prevent it from forwarding requests directly?
> 
> I'm not an expert on reverse proxy mode, but do you think "allow-direct" might 
> be your problem?
> 
> That sounds to me as though you are telling Squid it is allowed to forward 
> requests directly, instead of having to rely on peers...

Exactlys so.

Amos



From squid3 at treenet.co.nz  Fri Aug 12 03:20:22 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Aug 2016 15:20:22 +1200
Subject: [squid-users] X-Squid-Error
In-Reply-To: <1470949857868-4678848.post@n4.nabble.com>
References: <1470949857868-4678848.post@n4.nabble.com>
Message-ID: <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>

On 12/08/2016 9:10 a.m., joe wrote:
> only on latest squid 4 happen
> Squid Cache: Version 4.0.13-20160809-r14785
> ---------
> HTTP/1.1 400 Bad Request
> Server: squid
> Mime-Version: 1.0
> Date: Thu, 11 Aug 2016 21:02:46 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3367
> X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
> X-Cache: MISS from proxy.netgatesss.com
> Connection: close
> 

In response to what?

Amos



From dan at getbusi.com  Fri Aug 12 03:30:00 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Fri, 12 Aug 2016 13:30:00 +1000
Subject: [squid-users] Large memory leak with ssl_peek (now partly
	understood)
In-Reply-To: <19bf0746-0f96-106a-bb43-72b1f69f434f@measurement-factory.com>
References: <6ebc07c2-c8e7-13f1-8c9f-cd00ab812339@opendium.com>
 <19bf0746-0f96-106a-bb43-72b1f69f434f@measurement-factory.com>
Message-ID: <CAN8nrKB3KQHsOC-_uaOxS__L-S-WZm_8d0GgOBC_U-_106O=ng@mail.gmail.com>

Pretty sure this is affecting our 3.5.x systems as well ? we use a very
similar splicing implementation.

I'll keep an eye out in hope someone adapts that patch!

Dan

On 12 August 2016 at 06:22, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 08/11/2016 10:56 AM, Steve Hill wrote:
>
> > At ssl_bump step 2 we splice the connection and Squid does verification
> ...
> > Unfortunately, when verification fails, rather than actually dropping
> > the client's connection, Squid just leaves the client hanging.
>
> Hi Steve,
>
>     This sounds very similar to Squid bug 4508. Factory proposed a fix
> for that bug, but the patch is for Squid v4. You may be able to adapt it
> to v3. Testing (with any version) is very welcomed, of course:
>
>   http://bugs.squid-cache.org/show_bug.cgi?id=4508
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/d817e5eb/attachment.htm>

From fastestsuperman at gmail.com  Fri Aug 12 03:48:35 2016
From: fastestsuperman at gmail.com (james82)
Date: Thu, 11 Aug 2016 20:48:35 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608112023.48916.Antony.Stone@squid.open.source.it>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608112023.48916.Antony.Stone@squid.open.source.it>
Message-ID: <1470973715555-4678852.post@n4.nabble.com>

i'm really sorry. can you check the link in my post again. I can't find that
line,really. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678852.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Aug 12 06:51:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Aug 2016 18:51:03 +1200
Subject: [squid-users] large downloads got interrupted
In-Reply-To: <57AC5EE0.9070904@norma.perm.ru>
References: <57723949.1060504@norma.perm.ru>
 <16f57ceb-f22e-25e8-ee5c-dfc3e9eeb7fa@treenet.co.nz>
 <5773DA3B.60409@norma.perm.ru>
 <bad52c96-20d6-c538-4fde-8f7c5e9326e8@treenet.co.nz>
 <57AC5EE0.9070904@norma.perm.ru>
Message-ID: <b76a57b1-39f9-8db2-01d8-bda4a936bbe7@treenet.co.nz>

On 11/08/2016 11:17 p.m., Eugene M. Zheganin wrote:
> Hi.
> 
> On 30.06.16 17:19, Amos Jeffries wrote:
>>
>> Okay, I wasn't suggesting you post it here. Its likely to be too big for
>> that.
>>
>> I would look for the messages about the large object, and its FD. Then,
>> for anthing about why it was closed by Squid. Not sure what tha would be
>> at this point though.
>> There are some scripts in the Squid sources scripts/ directory that
>> might help wade through the log. Or the grep tool.
>>
>>
> I enabled logLevel 2 for all squid facilities, but so far I didn't
> fugura out any pattern from log. The only thing I noticed - is that for
> large download the Recv-Q value reported by the netstat for a particular
> squid-to-server connection is extremely high, so is the Send-Q value for
> a connection from squid to client. I don't know if it's a cause or a
> consequence, but from my point of view this may indicate that buffers
> are overflown for some reason, I think this may cause, in turn, RSTs and
> connection closing - am I right ?. I still don't know whether it's a
> squid fault of may be it's local OS misconfiguration.

Er. That indicates buffers are probably full, but not necessarily overflown.

If the Send-Q is high that means the client is not reading what Squid
has sent. If the client stays hung like that for too long (15min IIRC)
Squid will give up on it and close the connections so it can move on to
handle other more responsive clients. TCP has a much shorter timeout
than Squid, so it may not be Squid aborting, but the TCP stack. Either
way its for the same reason - client is not read(2)'ing the traffic.

Amos



From carlopmart at gmail.com  Fri Aug 12 07:45:16 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Fri, 12 Aug 2016 07:45:16 +0000
Subject: [squid-users] Trying to compile Squid-4 under OpenBSD 5.9
Message-ID: <20160812074516.GB3401@beagle.bcn.sia.es>

Hi all

 I would like to some tests with squid-4 under my OpenBSD 5.9 hosts. But when I launch configure:

checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... cfgaux/install-sh -c -d
checking for gawk... no
checking for mawk... no
checking for nawk... no
checking for awk... awk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking whether UID '0' is supported by ustar format... yes
checking whether GID '0' is supported by ustar format... yes
checking how to create a ustar tar archive... plaintar
checking whether to enable maintainer-specific portions of Makefiles... no
checking for gcc... cc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether cc accepts -g... yes
checking for cc option to accept ISO C89... none needed
checking whether cc understands -c and -o together... yes
checking for style of include used by make... GNU
checking dependency style of cc... gcc3
checking whether we are using the GNU C++ compiler... yes
checking whether c++ accepts -g... yes
checking dependency style of c++... gcc3
checking build system type... x86_64-unknown-openbsd5.9
checking host system type... x86_64-unknown-openbsd5.9
configure: CPU arch native optimization enabled: no
checking simplified host os... openbsd (version 5.9)
checking whether c++ supports C++11 features by default... no
checking whether c++ supports C++11 features with -std=c++11... no
checking whether c++ supports C++11 features with -std=c++0x... no
configure: error: *** A compiler with support for C++11 language features is required.

 My configure options are:

 ./configure --prefix=/opt/squid --disable-strict-error-checking --disable-arch-native --enable-ssl-crtd --disable-loadable-modules --enable-arp-acl --enable-auth --enable-delay-pools --enable-follow-x-forwarded-for --enable-forw-via-db --enable-http-violations --enable-icap-client --enable-ipv6 --enable-referer-log --enable-removal-policies="lru heap" --enable-ssl --with-openssl --enable-storeio="aufs ufs" --with-default-user="_squid" --with-filedescriptors=8192 --with-krb5-config=no --with-pidfile="/var/run/squid.pid" --with-pthreads --with-swapdir=/var/squid/cache --sysconfdir=/etc/squid --localstatedir=/var/squid --disable-pf-transparent --enable-ipfw-transparent

 Do I need to pass another option?

Thanks.
-- 
Greetings,
C. L. Martinez


From Antony.Stone at squid.open.source.it  Fri Aug 12 08:02:41 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 12 Aug 2016 10:02:41 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1470973715555-4678852.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608112023.48916.Antony.Stone@squid.open.source.it>
 <1470973715555-4678852.post@n4.nabble.com>
Message-ID: <201608121002.41509.Antony.Stone@squid.open.source.it>

On Friday 12 August 2016 at 05:48:35, james82 wrote:

> i'm really sorry. can you check the link in my post again. I can't find
> that line,really.

If you mean the link https://ghostbin/paste/kw7pp in your original question, 
it does not work - it has no valid domain.

If the line:

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

does not appear anywhere in your squid.conf, then please check that you are 
starting from a plain installation of Squid - tell us:

1. how did you install squid
2. where are you looking for squid.conf
3. have you installed any other software which might be trying to "manage" 
Squid on your system?


Antony.

-- 
Why is "dylexia" so difficult to spell, and why can I never remember "aphasia" 
when I want to?

                                                   Please reply to the list;
                                                         please *don't* CC me.


From chip_pop at hotmail.com  Fri Aug 12 09:05:03 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 12 Aug 2016 02:05:03 -0700 (PDT)
Subject: [squid-users] X-Squid-Error
In-Reply-To: <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
Message-ID: <1470992703140-4678856.post@n4.nabble.com>

it was on debug all 2 if you want i re install it and do dump on all 9
i did not try the relise r14785
r14782 	was good

2016/08/12 00:02:46.254 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 21
2016/08/12 00:02:46.254 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
2016/08/12 00:02:46.254 kid1| 33,2| client_side.cc(586) swanSong:
local=149.202.92.139:80 remote=10.4.4.61:24710 flags=33
2016/08/12 00:02:46.307 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 21
2016/08/12 00:02:46.307 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
2016/08/12 00:02:46.307 kid1| 33,2| client_side.cc(586) swanSong:
local=149.202.92.139:80 remote=10.4.4.61:24711 flags=33
2016/08/12 00:02:46.360 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 21
2016/08/12 00:02:46.360 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
2016/08/12 00:02:46.361 kid1| 33,2| client_side.cc(586) swanSong:
local=149.202.92.139:80 remote=10.4.4.61:24712 flags=33
2016/08/12 00:02:46.413 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 21
2016/08/12 00:02:46.413 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
2016/08/12 00:02:46.418 kid1| 33,2| Http1Server.cc(101) buildHttpRequest:
Invalid Request
2016/08/12 00:02:46.418 kid1| 4,2| errorpage.cc(1260) BuildContent: No
existing error page language negotiated for ERR_PROTOCOL_UNKNOWN. Using
default error file.
2016/08/12 00:02:46.418 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 00:02:46.418 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 00:02:46.418 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 00:02:46.418 kid1| 33,2| QosConfig.cc(163) doTosLocalMiss: QOS:
Preserving TOS on miss, TOS=0
2016/08/12 00:02:46.418 kid1| 88,2| client_side_reply.cc(2054)
processReplyAccessResult: The reply for NONE error:invalid-request is
ALLOWED, because it matched (access_log daemon:/var/log/squid/access.log
line)
2016/08/12 00:02:46.418 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=149.202.92.139:80 remote=10.4.4.61:24713 FD 11 flags=33
2016/08/12 00:02:46.419 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Thu, 11 Aug 2016 21:02:46 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close


----------
2016/08/12 00:02:46.419 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 00:02:46.419 kid1| 33,2| client_side.cc(893) kick:
local=149.202.92.139:80 remote=10.4.4.61:24713 flags=33 Connection was
closed
2016/08/12 00:02:46.419 kid1| 33,2| client_side.cc(586) swanSong:
local=149.202.92.139:80 remote=10.4.4.61:24713 flags=33
2016/08/12 00:02:46.469 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 21
2016/08/12 00:02:46.469 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
2016/08/12 00:02:46.470 kid1| 33,2| client_side.cc(586) swanSong:
local=149.202.92.139:80 remote=10.4.4.61:24714 flags=33
2016/08/12 00:02:46.523 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 21
2016/08/12 00:02:46.523 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
2016/08/12 00:02:46.523 kid1| 33,2| Http1Server.cc(101) buildHttpRequest:
Invalid Request
2016/08/12 00:02:46.523 kid1| 4,2| errorpage.cc(1260) BuildContent: No
existing error page language negotiated for ERR_PROTOCOL_UNKNOWN. Using
default error file.
2016/08/12 00:02:46.523 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 00:02:46.523 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 00:02:46.524 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 00:02:46.524 kid1| 33,2| QosConfig.cc(163) doTosLocalMiss: QOS:
Preserving TOS on miss, TOS=0
2016/08/12 00:02:46.524 kid1| 88,2| client_side_reply.cc(2054)
processReplyAccessResult: The reply for NONE error:invalid-request is
ALLOWED, because it matched (access_log daemon:/var/log/squid/access.log
line)
2016/08/12 00:02:46.524 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=149.202.92.139:80 remote=10.4.4.61:24715 FD 11 flags=33
2016/08/12 00:02:46.524 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Thu, 11 Aug 2016 21:02:46 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/X-Squid-Error-tp4678848p4678856.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From steve at opendium.com  Fri Aug 12 09:05:15 2016
From: steve at opendium.com (Steve Hill)
Date: Fri, 12 Aug 2016 10:05:15 +0100
Subject: [squid-users] Large memory leak with ssl_peek (now partly
 understood)
In-Reply-To: <CAN8nrKB3KQHsOC-_uaOxS__L-S-WZm_8d0GgOBC_U-_106O=ng@mail.gmail.com>
References: <6ebc07c2-c8e7-13f1-8c9f-cd00ab812339@opendium.com>
 <19bf0746-0f96-106a-bb43-72b1f69f434f@measurement-factory.com>
 <CAN8nrKB3KQHsOC-_uaOxS__L-S-WZm_8d0GgOBC_U-_106O=ng@mail.gmail.com>
Message-ID: <c372fb8b-d013-0605-9692-59a954be13cc@opendium.com>


>         This sounds very similar to Squid bug 4508. Factory proposed a fix
>     for that bug, but the patch is for Squid v4. You may be able to adapt it
>     to v3. Testing (with any version) is very welcomed, of course:

Thanks for that - I'll look into adapting and testing it.

(been chasing this bug off and on for months - hadn't spotted that there 
was a bug report open for it :)


-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Sales / enquiries:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From fastestsuperman at gmail.com  Fri Aug 12 09:42:23 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 02:42:23 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608121002.41509.Antony.Stone@squid.open.source.it>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608112023.48916.Antony.Stone@squid.open.source.it>
 <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
Message-ID: <1470994943213-4678858.post@n4.nabble.com>

I'm sorry. I just fix my link squid.conf file. PLease check. And I install
squid by type" apt-get install squid". I use kali linux.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678858.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Fri Aug 12 09:50:03 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 12 Aug 2016 11:50:03 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1470994943213-4678858.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
Message-ID: <201608121150.03866.Antony.Stone@squid.open.source.it>

On Friday 12 August 2016 at 11:42:23, james82 wrote:

> I'm sorry. I just fix my link squid.conf file. PLease check. And I install
> squid by type" apt-get install squid". I use kali linux.

I also asked "where are you looking for the file squid.conf?"

I remember in some of your previous postings, you showed us a file which was 
the *documentation* for squid.conf, not squid.conf itself - and it said 
clearly at the top of the file:

#        This is the documentation for the Squid configuration file.

I just want to make sure you are not still trying to use that instead of the 
correct squid.conf file.

So, please confirm:

1. Where on your system is the squid.conf file which you are using?

2. Does that file contain the line above ("This is the documentation for the 
Squid configuration file.") at the top?

3. Does the file contain the line "# INSERT YOUR OWN RULE(S) HERE TO ALLOW 
ACCESS FROM YOUR CLIENTS"?

4. Have you tried adding the lines containined in the tutorial you are trying 
to follow, immediately after the line in question 3?


Please make sure you answer all four questions when you reply.


Regards,


Antony.

-- 
Police have found a cartoonist dead in his house.  They say that details are 
currently sketchy.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Fri Aug 12 10:41:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 12 Aug 2016 16:41:57 +0600
Subject: [squid-users] X-Squid-Error
In-Reply-To: <1470992703140-4678856.post@n4.nabble.com>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
Message-ID: <ff7d61c7-c44f-0017-3d46-ec8efaab4710@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I'm regulary got the same error.

By my observations, it's produces by GTalk.


12.08.2016 15:05, joe ?????:
> it was on debug all 2 if you want i re install it and do dump on all 9
> i did not try the relise r14785
> r14782     was good
>
> 2016/08/12 00:02:46.254 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
> connection on FD 21
> 2016/08/12 00:02:46.254 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
> connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
> 2016/08/12 00:02:46.254 kid1| 33,2| client_side.cc(586) swanSong:
> local=149.202.92.139:80 remote=10.4.4.61:24710 flags=33
> 2016/08/12 00:02:46.307 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
> connection on FD 21
> 2016/08/12 00:02:46.307 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
> connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
> 2016/08/12 00:02:46.307 kid1| 33,2| client_side.cc(586) swanSong:
> local=149.202.92.139:80 remote=10.4.4.61:24711 flags=33
> 2016/08/12 00:02:46.360 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
> connection on FD 21
> 2016/08/12 00:02:46.360 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
> connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
> 2016/08/12 00:02:46.361 kid1| 33,2| client_side.cc(586) swanSong:
> local=149.202.92.139:80 remote=10.4.4.61:24712 flags=33
> 2016/08/12 00:02:46.413 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
> connection on FD 21
> 2016/08/12 00:02:46.413 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
> connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
> 2016/08/12 00:02:46.418 kid1| 33,2| Http1Server.cc(101) buildHttpRequest:
> Invalid Request
> 2016/08/12 00:02:46.418 kid1| 4,2| errorpage.cc(1260) BuildContent: No
> existing error page language negotiated for ERR_PROTOCOL_UNKNOWN. Using
> default error file.
> 2016/08/12 00:02:46.418 kid1| 20,2| store.cc(990) checkCachable:
> StoreEntry::checkCachable: NO: not cachable
> 2016/08/12 00:02:46.418 kid1| 20,2| store.cc(990) checkCachable:
> StoreEntry::checkCachable: NO: not cachable
> 2016/08/12 00:02:46.418 kid1| 20,2| store.cc(990) checkCachable:
> StoreEntry::checkCachable: NO: not cachable
> 2016/08/12 00:02:46.418 kid1| 33,2| QosConfig.cc(163) doTosLocalMiss: QOS:
> Preserving TOS on miss, TOS=0
> 2016/08/12 00:02:46.418 kid1| 88,2| client_side_reply.cc(2054)
> processReplyAccessResult: The reply for NONE error:invalid-request is
> ALLOWED, because it matched (access_log daemon:/var/log/squid/access.log
> line)
> 2016/08/12 00:02:46.418 kid1| 11,2| Stream.cc(266) sendStartOfMessage:
HTTP
> Client local=149.202.92.139:80 remote=10.4.4.61:24713 FD 11 flags=33
> 2016/08/12 00:02:46.419 kid1| 11,2| Stream.cc(267) sendStartOfMessage:
HTTP
> Client REPLY:
> ---------
> HTTP/1.1 400 Bad Request
> Server: squid
> Mime-Version: 1.0
> Date: Thu, 11 Aug 2016 21:02:46 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3367
> X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
> X-Cache: MISS from proxy.netgatesss.com
> Connection: close
>
>
> ----------
> 2016/08/12 00:02:46.419 kid1| 20,2| store.cc(990) checkCachable:
> StoreEntry::checkCachable: NO: not cachable
> 2016/08/12 00:02:46.419 kid1| 33,2| client_side.cc(893) kick:
> local=149.202.92.139:80 remote=10.4.4.61:24713 flags=33 Connection was
> closed
> 2016/08/12 00:02:46.419 kid1| 33,2| client_side.cc(586) swanSong:
> local=149.202.92.139:80 remote=10.4.4.61:24713 flags=33
> 2016/08/12 00:02:46.469 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
> connection on FD 21
> 2016/08/12 00:02:46.469 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
> connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
> 2016/08/12 00:02:46.470 kid1| 33,2| client_side.cc(586) swanSong:
> local=149.202.92.139:80 remote=10.4.4.61:24714 flags=33
> 2016/08/12 00:02:46.523 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
> connection on FD 21
> 2016/08/12 00:02:46.523 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
> connection on local=0.0.0.0:3128 remote=[::] FD 21 flags=41
> 2016/08/12 00:02:46.523 kid1| 33,2| Http1Server.cc(101) buildHttpRequest:
> Invalid Request
> 2016/08/12 00:02:46.523 kid1| 4,2| errorpage.cc(1260) BuildContent: No
> existing error page language negotiated for ERR_PROTOCOL_UNKNOWN. Using
> default error file.
> 2016/08/12 00:02:46.523 kid1| 20,2| store.cc(990) checkCachable:
> StoreEntry::checkCachable: NO: not cachable
> 2016/08/12 00:02:46.523 kid1| 20,2| store.cc(990) checkCachable:
> StoreEntry::checkCachable: NO: not cachable
> 2016/08/12 00:02:46.524 kid1| 20,2| store.cc(990) checkCachable:
> StoreEntry::checkCachable: NO: not cachable
> 2016/08/12 00:02:46.524 kid1| 33,2| QosConfig.cc(163) doTosLocalMiss: QOS:
> Preserving TOS on miss, TOS=0
> 2016/08/12 00:02:46.524 kid1| 88,2| client_side_reply.cc(2054)
> processReplyAccessResult: The reply for NONE error:invalid-request is
> ALLOWED, because it matched (access_log daemon:/var/log/squid/access.log
> line)
> 2016/08/12 00:02:46.524 kid1| 11,2| Stream.cc(266) sendStartOfMessage:
HTTP
> Client local=149.202.92.139:80 remote=10.4.4.61:24715 FD 11 flags=33
> 2016/08/12 00:02:46.524 kid1| 11,2| Stream.cc(267) sendStartOfMessage:
HTTP
> Client REPLY:
> ---------
> HTTP/1.1 400 Bad Request
> Server: squid
> Mime-Version: 1.0
> Date: Thu, 11 Aug 2016 21:02:46 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3367
> X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
> X-Cache: MISS from proxy.netgatesss.com
> Connection: close
>
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/X-Squid-Error-tp4678848p4678856.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXraf0AAoJENNXIZxhPexGvnQIAMzeScsSpOEc+M2m4ir0mI+y
5suTgjWQWpCssLVRNYki8wzsIzHpkatKzWRYw57wBgskMa+bkWuDfv3uXM8vYLKR
tiYmRc8tKHswNU/EuVktacmk6tLmi1pQkgeH1IZBOh3dXRUnAI3gEqFGn98bQ5UE
77LjbwrRofUWIc6to9cs8yBfCYJ3o4H+EeTDA8dg27qT0+4jPeAa5ScCMZIENP8y
J62nM2+Nh2vwtVrcONimYa/rMlcH53dTo1BfdPd0hs1KQYrwlBdnMkt+ayJa4GDM
Yj8rcYWtlHzKXCoVlKAEpG1ScrnbLZVG+E+4CK021Xz+6972IlBi3ODSmrvE+3s=
=GvKW
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/4e64159d/attachment.key>

From fastestsuperman at gmail.com  Fri Aug 12 11:16:01 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 04:16:01 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608121150.03866.Antony.Stone@squid.open.source.it>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608112023.48916.Antony.Stone@squid.open.source.it>
 <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
Message-ID: <1471000561217-4678861.post@n4.nabble.com>

where? these have a example and I don't know where truly it.  here is it:
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

#  TAG: adapted_http_access
#	Allowing or Denying access based on defined access lists
#
#	Essentially identical to http_access, but runs after redirectors
#	and ICAP/eCAP adaptation. Allowing access control based on their
#	output.
#
#	If not set then only http_access is used.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678861.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Fri Aug 12 11:20:28 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 12 Aug 2016 13:20:28 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471000561217-4678861.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
Message-ID: <201608121320.28858.Antony.Stone@squid.open.source.it>

On Friday 12 August 2016 at 13:16:01, james82 wrote:

> where? these have a example and I don't know where truly it.  here is it:
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

<snip>

Please answer all four questions from my previous email as requested.

You ask questions and expect to get answers - so do I.

If you do not give us the information we need to be able to help you, we 
cannot give you the help you clearly need.


Antony.

-- 
"The future is already here.   It's just not evenly distributed yet."

 - William Gibson

                                                   Please reply to the list;
                                                         please *don't* CC me.


From fastestsuperman at gmail.com  Fri Aug 12 11:53:10 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 04:53:10 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608121320.28858.Antony.Stone@squid.open.source.it>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608112023.48916.Antony.Stone@squid.open.source.it>
 <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
Message-ID: <1471002790969-4678863.post@n4.nabble.com>

Yes, if you see in my post. It have the line: This is the documentation for
the
Squid configuration file. and it also have line:  INSERT YOUR OWN RULE(S)
HERE TO ALLOW
ACCESS FROM YOUR CLIENTS"? . No, i not still not tried adding the lines
containined in the tutorial you are trying
to follow yet, because i don't know where should i add right. and it also
have step 3 in tutorial, anonymizing traffic, i don't know how to do this.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678863.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Aug 12 11:57:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 12 Aug 2016 17:57:17 +0600
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471002790969-4678863.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608112023.48916.Antony.Stone@squid.open.source.it>
 <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
Message-ID: <2fdd2049-ca55-a5bf-7cc5-0477ccdbc3ae@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Man, if you do not know what to add - we do the more we can not know.
You asked - what do you want to do? Formulate the problem, it makes it
clear that it is necessary to add. If you do not know yourself, you have
to do - we can know where it came from?


12.08.2016 17:53, james82 ?????:
> Yes, if you see in my post. It have the line: This is the documentation for
> the
> Squid configuration file. and it also have line:  INSERT YOUR OWN RULE(S)
> HERE TO ALLOW
> ACCESS FROM YOUR CLIENTS"? . No, i not still not tried adding the lines
> containined in the tutorial you are trying
> to follow yet, because i don't know where should i add right. and it also
> have step 3 in tutorial, anonymizing traffic, i don't know how to do this.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678863.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXrbmcAAoJENNXIZxhPexGZ+AH/1DXXSx8+JgIntd1ADDPgwnN
Fyx+T/4M6krSoch5RggJv2DDmr110hRFJGCf3ZWMdrl3mu6IEEils/IAHZbhareu
UDSoNH++AYI/WAGSmfIPDqoUD950Ae+qAPCkwGuPzfSdn3X47mBE0IgfA85EsW08
C8oh/FXj05B3R5kAn1o08vFwU4BmIX8iwJyBxYo+5Lbhxy7PdXH4B353ZJJsw5M+
JjgjbFFv6+ZMxeB+3GYQAcuHFt66oXJedJKBAZ7/N5/WObwO3R3OpyD0stozu9tf
cC+jAMiGQoZGYqzd/EmbmBcBwWl0XhcNOMXbn0Yq1NPr4lgJSSAQR4y7yd/f3Tw=
=InM3
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/0b860990/attachment.key>

From Antony.Stone at squid.open.source.it  Fri Aug 12 12:06:17 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 12 Aug 2016 14:06:17 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471002790969-4678863.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
Message-ID: <201608121406.17631.Antony.Stone@squid.open.source.it>

On Friday 12 August 2016 at 13:53:10, james82 wrote:

> Yes, if you see in my post. It have the line: This is the documentation for
> the Squid configuration file

In that case you are editing the wrong file.

Please answer my question "Where on your system is the squid.conf file which 
you are using?"

> and it also have line:  INSERT YOUR OWN RULE(S) HERE TO ALLOW
> ACCESS FROM YOUR CLIENTS".

> No, i not still not tried adding the lines containined in the tutorial you
> are trying to follow yet, because i don't know where should i add right.

Add the lines immediately after the line "INSERT YOUR OWN..." (as I said in a 
previous reply).

However, please answer my question "Where on your system is the squid.conf file 
which you are using?"

> and it also have step 3 in tutorial, anonymizing traffic, i don't know how to
> do this.

Don't worry about step three until you have steps 1 and 2 correctly working.


Incidentally, I cannot help feeling that you are not going to achieve what you 
appear to want.  You keep on talking of anonymizing your traffic, and you 
previously asked how to change your IP address...

I am assuming that your Squid server is either:

1. on your own network, on an Internet connection registered to you

or

2. hosted by a provider on a machine registered to you

or

3. hosted on some cloud service running under an account registered to you

Therefore in all three cases, requests sent to remote websites by your Squid 
server will be traceable in the remote server logs to your account and 
therefore you.

The "anonymizing" steps in the tutorial you are trying to follow will hide the 
IP address of your client machine, but not that of your Squid server.


Best wishes,

Antony.

-- 
"640 kilobytes (of RAM) should be enough for anybody."

 - Bill Gates

                                                   Please reply to the list;
                                                         please *don't* CC me.


From michel at ltu.fcbc.cu  Fri Aug 12 13:29:04 2016
From: michel at ltu.fcbc.cu (Michel)
Date: Fri, 12 Aug 2016 09:29:04 -0400
Subject: [squid-users] Helppppp
Message-ID: <86BE18FCA5FC48319D949B8B2AF70309@ltu.fcbc.cu>

Hello everyone. I have the following problem. The squid server has the
system time correctly however messages
squid out with 5 hours ahead. For example, when you do not have access to a restricted website through squid that's where you put Generated Thu, 22 Jan 2015 18:45:05 GMT and are 1:45 pm
Anyone know the solution? 


Regards,
Michel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/7bc387ea/attachment.htm>

From fastestsuperman at gmail.com  Fri Aug 12 13:32:27 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 06:32:27 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608121406.17631.Antony.Stone@squid.open.source.it>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608112023.48916.Antony.Stone@squid.open.source.it>
 <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
 <201608121406.17631.Antony.Stone@squid.open.source.it>
Message-ID: <1471008747015-4678867.post@n4.nabble.com>

Can you fix it for me, this problem: http://imgur.com/a/AiSSQ



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678867.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fastestsuperman at gmail.com  Fri Aug 12 13:34:55 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 06:34:55 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471008747015-4678867.post@n4.nabble.com>
References: <201608112023.48916.Antony.Stone@squid.open.source.it>
 <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
 <201608121406.17631.Antony.Stone@squid.open.source.it>
 <1471008747015-4678867.post@n4.nabble.com>
Message-ID: <1471008895856-4678868.post@n4.nabble.com>

is i add this right: 
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost
http_access allow homepc

# And finally deny all other access to this proxy
http_access deny all

#  TAG: adapted_http_access
# Allowing or Denying access based on defined access lists
#
# Essentially identical to http_access, but runs after redirectors
# and ICAP/eCAP adaptation. Allowing access control based on their
# output.
#
# If not set then only http_access is used. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678868.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Aug 12 14:03:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 12 Aug 2016 20:03:08 +0600
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471008747015-4678867.post@n4.nabble.com>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608112023.48916.Antony.Stone@squid.open.source.it>
 <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
 <201608121406.17631.Antony.Stone@squid.open.source.it>
 <1471008747015-4678867.post@n4.nabble.com>
Message-ID: <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
It is not sesessary to make screenshots every time, man.

Just enough copy-n-paste relevant cache.log entries.

You are freaking annoying. Can you clearly explain what you want to
achieve and clearly formulate the problem? Do we have to guess your
wishes telepathically? You no one is able to help as long as you clearly
can not be said, what the hell do you want to achieve.


12.08.2016 19:32, james82 ?????:
> Can you fix it for me, this problem: http://imgur.com/a/AiSSQ
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678867.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXrdccAAoJENNXIZxhPexG4asH/REmLkHIaX/SBFs0zJF15/cv
V9rERX0dRlXMuKj5zMM/++I+a5Cun2E4EwUbvrg6hlgbvudqSyA0AGDsI80HtE/f
dYBamat+TsSYd5c1RHSYfVUrzYcl7rXAPuJ7S7JlaxzR2T6BOVkiKanmQ0K6eKOM
fyAhL1hIzcwKR5BCnIlU/EFNIU4ZU7GgsZNx+V2DSCYJSEAZ9fT18XgWaslsJbO8
jmE5631o3NrdjsOTtD08sI+mXjfsxNqd9E/ArjpQ/CHX6YF1352zBMpJayjkP9db
aNj5ZRMGGi061l3rzyNGxZ6qY5RPnh/20Bzok0nj9R17zyXCJEStDW9MNrvcrYU=
=wKl+
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/261d0378/attachment.key>

From yvoinov at gmail.com  Fri Aug 12 14:04:02 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 12 Aug 2016 20:04:02 +0600
Subject: [squid-users] Helppppp
In-Reply-To: <86BE18FCA5FC48319D949B8B2AF70309@ltu.fcbc.cu>
References: <86BE18FCA5FC48319D949B8B2AF70309@ltu.fcbc.cu>
Message-ID: <956fdfdd-63d8-8af3-1e51-bca9bb61ee0c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Wait a minute, man. Can you describe in more detail what's wrong with you?


12.08.2016 19:29, Michel ?????:
> Hello everyone. I have the following problem. The squid server has the
> system time correctly however messages
> squid out with 5 hours ahead. For example, when you do not have access
to a restricted website through squid that's where you put Generated
Thu, 22 Jan 2015 18:45:05 GMT and are 1:45 pm
> Anyone know the solution?
> 
> 
> Regards,
> Michel
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXrddSAAoJENNXIZxhPexGuToIALy9YSpXPD38fed2ZYJWLBot
kuxVNS2b6SfJll6Lxy3O4jGtcqbHnXtW9oNOKcJcJRG17Sh/3HsbhMHMRkwmFXIi
XbMy3JHDzPT7F57M6WbDkZjGr+34tKXMm2pmm+LOCcJeO9XoW78KR5xqUKiq7syI
NQDYEb0FqflTie3vzZlSz/WEp5YG7V7vD6FQ+HVX+L4Mp8EOlNeF+MhOh267yUEU
AiRTni7siQufoY4OYJ4rbK9siksX3roIJdYGYixC2BDmqed1jwPciSkH7i7M3Clc
B7MqPVCFE+vus3pWwhFat7JTVILgPNoSoH5QzvakJ7iYx7VHZVQ7BU/HNZkDUvU=
=OOCV
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/cab75909/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/cab75909/attachment.key>

From yvoinov at gmail.com  Fri Aug 12 14:06:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 12 Aug 2016 20:06:43 +0600
Subject: [squid-users] Helppppp
In-Reply-To: <956fdfdd-63d8-8af3-1e51-bca9bb61ee0c@gmail.com>
References: <86BE18FCA5FC48319D949B8B2AF70309@ltu.fcbc.cu>
 <956fdfdd-63d8-8af3-1e51-bca9bb61ee0c@gmail.com>
Message-ID: <b3e37cf4-4116-4b34-8118-6458a44dbfff@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Also - most obvious question: which TZ is setted up on your box
globally, and per-user ? Seems you squid's user TZ is different than global.

12.08.2016 20:04, Yuri Voinov ?????:
>
> Wait a minute, man. Can you describe in more detail what's wrong with you?
>
>
> 12.08.2016 19:29, Michel ?????:
> > Hello everyone. I have the
>       following problem. The squid server has the
>
>       > system time correctly however messages
>
>       > squid out with 5 hours ahead. For example, when you do not
>       have access to a restricted website through squid that's where you
>       put Generated Thu, 22 Jan 2015 18:45:05 GMT and are 1:45 pm
>
>       > Anyone know the solution?
>
>
>
>
>
>       > Regards,
>
>       > Michel
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXrdfyAAoJENNXIZxhPexGVMwH/3x+ED47Yz4REtGLENZ5xEJf
XuOrCNSLju9+MqEgRGdwSR3xwe6ERTl3vvQD7+GLcypwg+L/D3qyFpiSxKglIqQD
8lMb1d4+vpS8K3X13o8fGkXIJ7/X7yZxVsRW9VcFlLm7t+HPeKCSGd5RIpuwKl/K
LExa0UeprAuDKZt7VjixRlsaJmPhl3N0hPLHkfa92vguDuFc7OSsmzCVJ/gn0aQf
7Qxlt1S2XRVxatvP6SzQeQbvNPBH9xnLXDEe1o5yUK1oGLvtvSBAhImnl36wSGzU
+TJeUXnwSZ1d2/MZAMYvsf1X0tJ2wMakzGk/bfJdxYIWItM5PF0VAB7egLfFujI=
=bdzW
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/2feb4692/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/2feb4692/attachment.key>

From squid3 at treenet.co.nz  Fri Aug 12 14:16:01 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Aug 2016 02:16:01 +1200
Subject: [squid-users] X-Squid-Error
In-Reply-To: <1470992703140-4678856.post@n4.nabble.com>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
Message-ID: <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>

On 12/08/2016 9:05 p.m., joe wrote:
> it was on debug all 2 if you want i re install it and do dump on all 9
> i did not try the relise r14785
> r14782 	was good


Just "debug_option ALL,1 11,2 74,9" please. That will show you the
buffer contents the HTTP parser is receiving and what it thinks is
wrong. With none of the other high level stuff that is irrelevant.

Amos



From squid3 at treenet.co.nz  Fri Aug 12 14:18:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Aug 2016 02:18:50 +1200
Subject: [squid-users] Trying to compile Squid-4 under OpenBSD 5.9
In-Reply-To: <20160812074516.GB3401@beagle.bcn.sia.es>
References: <20160812074516.GB3401@beagle.bcn.sia.es>
Message-ID: <2efe28c4-9af8-14bf-6d7b-83773b94449d@treenet.co.nz>

On 12/08/2016 7:45 p.m., C. L. Martinez wrote:
> Hi all
> 
>  I would like to some tests with squid-4 under my OpenBSD 5.9 hosts. But when I launch configure:
> 
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... cfgaux/install-sh -c -d
> checking for gawk... no
> checking for mawk... no
> checking for nawk... no
> checking for awk... awk
> checking whether make sets $(MAKE)... yes
> checking whether make supports nested variables... yes
> checking whether UID '0' is supported by ustar format... yes
> checking whether GID '0' is supported by ustar format... yes
> checking how to create a ustar tar archive... plaintar
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking for gcc... cc
> checking whether the C compiler works... yes

You have a C compiler ...

> checking simplified host os... openbsd (version 5.9)
> checking whether c++ supports C++11 features by default... no
> checking whether c++ supports C++11 features with -std=c++11... no
> checking whether c++ supports C++11 features with -std=c++0x... no
> configure: error: *** A compiler with support for C++11 language features is required.
> 

... but no C++ compiler it seems.

Amos



From squid3 at treenet.co.nz  Fri Aug 12 14:24:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Aug 2016 02:24:03 +1200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608121150.03866.Antony.Stone@squid.open.source.it>
References: <1470935708530-4678837.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
Message-ID: <7db7028b-dd76-bde9-3892-a39cd9fc29ed@treenet.co.nz>

On 12/08/2016 9:50 p.m., Antony Stone wrote:
> On Friday 12 August 2016 at 11:42:23, james82 wrote:
> 
>> I'm sorry. I just fix my link squid.conf file. PLease check. And I install
>> squid by type" apt-get install squid". I use kali linux.
> 
> I also asked "where are you looking for the file squid.conf?"
> 
> I remember in some of your previous postings, you showed us a file which was 
> the *documentation* for squid.conf, not squid.conf itself - and it said 
> clearly at the top of the file:
> 
> #        This is the documentation for the Squid configuration file.
> 
> I just want to make sure you are not still trying to use that instead of the 
> correct squid.conf file.


FYI: since this is Kali its suffering the problem of the package
maintainer having installed that docs file over the squid.conf.
 So likely he *is* using the provided squid.conf, but its filled with
750KB of confusing extra text.

Amos


From fastestsuperman at gmail.com  Fri Aug 12 14:25:26 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 07:25:26 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
References: <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
 <201608121406.17631.Antony.Stone@squid.open.source.it>
 <1471008747015-4678867.post@n4.nabble.com>
 <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
Message-ID: <1471011926463-4678875.post@n4.nabble.com>

SORRY. I want to start squid service success. but it show a failed problem. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678875.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From carlopmart at gmail.com  Fri Aug 12 14:28:46 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Fri, 12 Aug 2016 14:28:46 +0000
Subject: [squid-users] Trying to compile Squid-4 under OpenBSD 5.9
In-Reply-To: <2efe28c4-9af8-14bf-6d7b-83773b94449d@treenet.co.nz>
References: <20160812074516.GB3401@beagle.bcn.sia.es>
 <2efe28c4-9af8-14bf-6d7b-83773b94449d@treenet.co.nz>
Message-ID: <20160812142846.GC3401@beagle.bcn.sia.es>

On Sat 13.Aug'16 at  2:18:50 +1200, Amos Jeffries wrote:
> On 12/08/2016 7:45 p.m., C. L. Martinez wrote:
> > Hi all
> > 
> >  I would like to some tests with squid-4 under my OpenBSD 5.9 hosts. But when I launch configure:
> > 
> > checking for a BSD-compatible install... /usr/bin/install -c
> > checking whether build environment is sane... yes
> > checking for a thread-safe mkdir -p... cfgaux/install-sh -c -d
> > checking for gawk... no
> > checking for mawk... no
> > checking for nawk... no
> > checking for awk... awk
> > checking whether make sets $(MAKE)... yes
> > checking whether make supports nested variables... yes
> > checking whether UID '0' is supported by ustar format... yes
> > checking whether GID '0' is supported by ustar format... yes
> > checking how to create a ustar tar archive... plaintar
> > checking whether to enable maintainer-specific portions of Makefiles... no
> > checking for gcc... cc
> > checking whether the C compiler works... yes
> 
> You have a C compiler ...
> 
> > checking simplified host os... openbsd (version 5.9)
> > checking whether c++ supports C++11 features by default... no
> > checking whether c++ supports C++11 features with -std=c++11... no
> > checking whether c++ supports C++11 features with -std=c++0x... no
> > configure: error: *** A compiler with support for C++11 language features is required.
> > 
> 
> ... but no C++ compiler it seems.
> 
> Amos
> 

Nop, that is not right. I have a C++ compiler:

root at obsdprxy01:~# whereis g++                                                                                                                                           
/usr/bin/g++
root at obsdprxy01:~#

 I think the problem is with gcc version:

Reading specs from /usr/lib/gcc-lib/amd64-unknown-openbsd5.9/4.2.1/specs
Target: amd64-unknown-openbsd5.9
Configured with: OpenBSD/amd64 system compiler
Thread model: posix
gcc version 4.2.1 20070719

 .. could it be the problem?

-- 
Greetings,
C. L. Martinez


From Antony.Stone at squid.open.source.it  Fri Aug 12 14:31:37 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 12 Aug 2016 16:31:37 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471011926463-4678875.post@n4.nabble.com>
References: <1470973715555-4678852.post@n4.nabble.com>
 <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
Message-ID: <201608121631.37310.Antony.Stone@squid.open.source.it>

On Friday 12 August 2016 at 16:25:26, james82 wrote:

> SORRY. I want to start squid service success. but it show a failed problem.

Yes - it tells you that the problem is on line 1193 of squid.conf

If you cannot work out for yourself what is wrong with that line, please post 
it here (do NOT send another screenshot link, please) so that we may be able 
to help you with it.

Until we see that line, we cannot possibly tell you what the error is.


Antony.

-- 
"Life is just a lot better if you feel you're having 10 [small] wins a day 
rather than a [big] win every 10 years or so."

 - Chris Hadfield, former skiing (and ski racing) instructor

                                                   Please reply to the list;
                                                         please *don't* CC me.


From fastestsuperman at gmail.com  Fri Aug 12 14:32:25 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 07:32:25 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471011926463-4678875.post@n4.nabble.com>
References: <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
 <201608121406.17631.Antony.Stone@squid.open.source.it>
 <1471008747015-4678867.post@n4.nabble.com>
 <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
Message-ID: <1471012345768-4678878.post@n4.nabble.com>

my squid.conf file come from /etc/squid/squid.conf, is that right?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678878.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Aug 12 14:39:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Aug 2016 02:39:36 +1200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471011926463-4678875.post@n4.nabble.com>
References: <1470973715555-4678852.post@n4.nabble.com>
 <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1470994943213-4678858.post@n4.nabble.com>
 <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
 <201608121406.17631.Antony.Stone@squid.open.source.it>
 <1471008747015-4678867.post@n4.nabble.com>
 <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
Message-ID: <ad32ca33-a083-057f-e6a9-efb13de9807b@treenet.co.nz>

On 13/08/2016 2:25 a.m., james82 wrote:
> SORRY. I want to start squid service success. but it show a failed problem. 
> 

The image you posted earlier is missing at least half of the error
message line. Specifically it is missing the part where it tells you
what config line contains the problem.
 SO we cannot see what the problems is (only that one exists). Guessing
how to solve an unknown problem would get nowhere.


If you are using a fresh install on Kali Linux. Then do this:


1) Go to this URL <http://wiki.squid-cache.org/Squid-3.5>

2) find /etc/squid/squid.conf

3) erase the contents of your /etc/squid/squid.conf

4) copy-n-paste the default config file from that wiki page into the now
empty squid.conf file.

** the default config is all lines in the yellow box at the end of the
page under the title "Squid-3.5 default config". From http_port down to
the last refresh_pattern line.


5) restart/start Squid

You should now be able to use the proxy. The config file will also be
empty enough to hopefully not confuse you when you do changes to make
Squid do something which you still haven't clearly told us.

HTH
Amos



From Antony.Stone at squid.open.source.it  Fri Aug 12 14:41:52 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 12 Aug 2016 16:41:52 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471012345768-4678878.post@n4.nabble.com>
References: <201608121002.41509.Antony.Stone@squid.open.source.it>
 <1471011926463-4678875.post@n4.nabble.com>
 <1471012345768-4678878.post@n4.nabble.com>
Message-ID: <201608121641.52803.Antony.Stone@squid.open.source.it>

On Friday 12 August 2016 at 16:32:25, james82 wrote:

> my squid.conf file come from /etc/squid/squid.conf, is that right?

Yes, that is correct, however Amos has pointed out that the package maintainer 
for Kali Linux appears to have put the wrong file in that location.

It will work, but that file has far more comments than usual / necessary, and 
it makes it more difficult for us to help you, because it is not the standard 
squid.conf we are used to dealing with.

However, if you were to follow the request that several people including 
myself have made, and post here, in the body of an email, the contents of your 
squid.conf without any comments or blank lines, then that would be a 
manageable-sized file which we can discuss and assist you with (once, that is, 
you have told us what it is you are trying to get Squid to do).

So, please take note of Yuri's comment that we do not need (or want) 
screenshots of your computer every time you get an error message - copy and 
paste the actual text itself into an email instead - and when we ask for 
further information in order to be able to help you, tell us what we need.

For the time being, let us know what line 1193 of your squid.conf says.


Antony.

-- 
I want to build a machine that will be proud of me.

 - Danny Hillis, creator of The Connection Machine

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Fri Aug 12 14:42:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Aug 2016 02:42:42 +1200
Subject: [squid-users] Trying to compile Squid-4 under OpenBSD 5.9
In-Reply-To: <20160812142846.GC3401@beagle.bcn.sia.es>
References: <20160812074516.GB3401@beagle.bcn.sia.es>
 <2efe28c4-9af8-14bf-6d7b-83773b94449d@treenet.co.nz>
 <20160812142846.GC3401@beagle.bcn.sia.es>
Message-ID: <d520e78f-4a4c-d3c3-f929-4b7b553b49d0@treenet.co.nz>

On 13/08/2016 2:28 a.m., C. L. Martinez wrote:
> On Sat 13.Aug'16 at  2:18:50 +1200, Amos Jeffries wrote:
>> On 12/08/2016 7:45 p.m., C. L. Martinez wrote:
>>> Hi all
>>>
>>>  I would like to some tests with squid-4 under my OpenBSD 5.9 hosts. But when I launch configure:
>>>
>>> checking for a BSD-compatible install... /usr/bin/install -c
>>> checking whether build environment is sane... yes
>>> checking for a thread-safe mkdir -p... cfgaux/install-sh -c -d
>>> checking for gawk... no
>>> checking for mawk... no
>>> checking for nawk... no
>>> checking for awk... awk
>>> checking whether make sets $(MAKE)... yes
>>> checking whether make supports nested variables... yes
>>> checking whether UID '0' is supported by ustar format... yes
>>> checking whether GID '0' is supported by ustar format... yes
>>> checking how to create a ustar tar archive... plaintar
>>> checking whether to enable maintainer-specific portions of Makefiles... no
>>> checking for gcc... cc
>>> checking whether the C compiler works... yes
>>
>> You have a C compiler ...
>>
>>> checking simplified host os... openbsd (version 5.9)
>>> checking whether c++ supports C++11 features by default... no
>>> checking whether c++ supports C++11 features with -std=c++11... no
>>> checking whether c++ supports C++11 features with -std=c++0x... no
>>> configure: error: *** A compiler with support for C++11 language features is required.
>>>
>>
>> ... but no C++ compiler it seems.
>>
>> Amos
>>
> 
> Nop, that is not right. I have a C++ compiler:
> 
> root at obsdprxy01:~# whereis g++                                                                                                                                           
> /usr/bin/g++
> root at obsdprxy01:~#
> 
>  I think the problem is with gcc version:
> 
> Reading specs from /usr/lib/gcc-lib/amd64-unknown-openbsd5.9/4.2.1/specs
> Target: amd64-unknown-openbsd5.9
> Configured with: OpenBSD/amd64 system compiler
> Thread model: posix
> gcc version 4.2.1 20070719
> 
>  .. could it be the problem?
> 

Yes GCC 4.9 is the minimum g++ version required to build Squid-4.
Preferrably GCC 5+ if you can though.

Amos


From fastestsuperman at gmail.com  Fri Aug 12 15:14:43 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 08:14:43 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608121641.52803.Antony.Stone@squid.open.source.it>
References: <201608121150.03866.Antony.Stone@squid.open.source.it>
 <1471000561217-4678861.post@n4.nabble.com>
 <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
 <201608121406.17631.Antony.Stone@squid.open.source.it>
 <1471008747015-4678867.post@n4.nabble.com>
 <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
 <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
Message-ID: <1471014883949-4678882.post@n4.nabble.com>

i try to do this tutorial:
https://www.linode.com/docs/networking/squid/squid-http-proxy-ubuntu-12-04. 
And here is my squid.conf file: pastebin.com/MnhK0ewx . can you tell me what
line number for i add : acl client src 12.34.56.78, and what line number
for: http_access allow client. please, i need this help. Please help me like
this, just tell me the line number in my squid.conf that i will add that two
thing. hug thank very much.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678882.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Fri Aug 12 15:17:15 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 12 Aug 2016 08:17:15 -0700 (PDT)
Subject: [squid-users] X-Squid-Error
In-Reply-To: <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
 <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>
Message-ID: <1471015035516-4678883.post@n4.nabble.com>

2016/08/12 18:14:51.855 kid1| 74,9| RequestParser.cc(316) parse: Parse
buf={length=135, data='??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???
.Rw???
.Sw???
/3W|???3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??'}
2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(263)
parseRequestFirstLine: parsing possible request: buf.length=135
2016/08/12 18:14:51.856 kid1| 74,9| RequestParser.cc(264)
parseRequestFirstLine: ??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???
.Rw???
.Sw???
/3W|???3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??
2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(339) parse:
request-line: retval -1: line={135,
data='??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???	.Rw???
.Sw???
/3W|???3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??'}
2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(340) parse:
request-line: method: NONE
2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(341) parse:
request-line: url: 
2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(342) parse:
request-line: proto: NONE/0.0
2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(343) parse: Parser:
bytes processed=0
2016/08/12 18:14:51.856 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=173.236.187.17:80 remote=10.4.4.61:7937 FD 11 flags=33
2016/08/12 18:14:51.856 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Fri, 12 Aug 2016 15:14:51 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close


----------
2016/08/12 18:14:51.907 kid1| 74,9| RequestParser.cc(316) parse: Parse
buf={length=267, data='??c?????d????@d????
@e????
Ae????
Af????
Bf????
Ch????Dh???? Di???? Ei????!Ej????!Fj????"Fk????"Gk????#Gl????#Hl????$Hm???
2016/08/12 18:14:51.907 kid1| 74,5| RequestParser.cc(263)
parseRequestFirstLine: parsing possible request: buf.length=267
2016/08/12 18:14:51.907 kid1| 74,9| RequestParser.cc(264)
parseRequestFirstLine: ??c?????d????@d????
@e????
Ae????
Af????
Bf????
Ch????Dh???? Di???? Ei????!Ej????!Fj????"Fk????"Gk????#Gl????#Hl????$Hm???
2016/08/12 18:14:51.907 kid1| 74,5| RequestParser.cc(339) parse:
request-line: retval -1: line={267, data='??c?????d????@d????
@e????
Ae????
Af????
Bf????Ch????Dh???? Di????
Ei????!Ej????!Fj????"Fk????"Gk????#Gl????#Hl????$Hm???
2016/08/12 18:14:51.907 kid1| 74,5| RequestParser.cc(340) parse:
request-line: method: NONE
2016/08/12 18:14:51.907 kid1| 74,5| RequestParser.cc(341) parse:
request-line: url: 
2016/08/12 18:14:51.907 kid1| 74,5| RequestParser.cc(342) parse:
request-line: proto: NONE/0.0
2016/08/12 18:14:51.907 kid1| 74,5| RequestParser.cc(343) parse: Parser:
bytes processed=0
2016/08/12 18:14:51.907 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=173.236.187.17:80 remote=10.4.4.61:7938 FD 11 flags=33
2016/08/12 18:14:51.907 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Fri, 12 Aug 2016 15:14:51 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close


----------
2016/08/12 18:14:51.980 kid1| 74,9| RequestParser.cc(316) parse: Parse
buf={length=82, data='Jq???+Pt???,Pu???,Qu???-Qv???	-Rv???	.Rw???
.Tx???
0Ty???
0Uy???
1Uz???
1Vz???'}
2016/08/12 18:14:51.980 kid1| 74,5| RequestParser.cc(263)
parseRequestFirstLine: parsing possible request: buf.length=82
2016/08/12 18:14:51.980 kid1| 74,9| RequestParser.cc(264)
parseRequestFirstLine: Jq???+Pt???,Pu???,Qu???-Qv???	-Rv???	.Rw???
.Tx???
0Ty???
0Uy???
1Uz???
1Vz???
2016/08/12 18:14:51.980 kid1| 74,5| RequestParser.cc(339) parse:
request-line: retval -1: line={82, data='Jq???+Pt???,Pu???,Qu???-Qv???
-Rv???	.Rw???
.Tx???
0Ty???
0Uy???
1Uz???
1Vz???'}
2016/08/12 18:14:51.980 kid1| 74,5| RequestParser.cc(340) parse:
request-line: method: Jq
2016/08/12 18:14:51.980 kid1| 74,5| RequestParser.cc(341) parse:
request-line: url: 
2016/08/12 18:14:51.980 kid1| 74,5| RequestParser.cc(342) parse:
request-line: proto: NONE/0.0
2016/08/12 18:14:51.981 kid1| 74,5| RequestParser.cc(343) parse: Parser:
bytes processed=0
2016/08/12 18:14:51.981 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=173.236.187.17:80 remote=10.4.4.61:7939 FD 11 flags=33
2016/08/12 18:14:51.981 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Fri, 12 Aug 2016 15:14:51 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close


----------
2016/08/12 18:14:52.038 kid1| 74,9| RequestParser.cc(316) parse: Parse
buf={length=505, data='
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???6[???7[????7\????8\????8]????9]????9^????:^????:_????;_????;`????<`????<a????=a????=b????>b????>c?????c?????d????@d????
@e????
Ae????
Af????
Bf????
Bg????
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????"Fk????"Gk????#Gl????#'Lp???(Lq???(Mq???)Mr???)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???-Qv???
-Rv???	.Rw???
.Sw???
/Sx???
/Tx???
0Ty???
0Uy???
1Uz???
1Vz???
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???5Z~???6Z???'}
2016/08/12 18:14:52.038 kid1| 74,5| RequestParser.cc(263)
parseRequestFirstLine: parsing possible request: buf.length=505
2016/08/12 18:14:52.038 kid1| 74,9| RequestParser.cc(264)
parseRequestFirstLine: 
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???6[???7[????7\????8\????8]????9]????9^????:^????:_????;_????;`????<`????<a????=a????=b????>b????>c?????c?????d????@d????
@e????
Ae????
Af????
Bf????
Bg????
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????"Fk????"Gk????#Gl????#'Lp???(Lq???(Mq???)Mr???)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???-Qv???
-Rv???	.Rw???
.Sw???
/Sx???
/Tx???
0Ty???
0Uy???
1Uz???
1Vz???
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???5Z~???6Z???
2016/08/12 18:14:52.038 kid1| 74,5| RequestParser.cc(339) parse:
request-line: retval -1: line={505, data='
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???6[???7[????7\????8\????8]????9]????9^????:^????:_????;_????;`????<`????<a????=a????=b????>b????>c?????c?????d????@d????
@e????
Ae????
Af????
Bf????
Bg????
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????"Fk????"Gk????#Gl????#'Lp???(Lq???(Mq???)Mr???)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???-Qv???
-Rv???	.Rw???
.Sw???
/Sx???
/Tx???
0Ty???
0Uy???
1Uz???
1Vz???
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???5Z~???6Z???'}
2016/08/12 18:14:52.038 kid1| 74,5| RequestParser.cc(340) parse:
request-line: method: NONE
2016/08/12 18:14:52.038 kid1| 74,5| RequestParser.cc(341) parse:
request-line: url: 
2016/08/12 18:14:52.038 kid1| 74,5| RequestParser.cc(342) parse:
request-line: proto: NONE/0.0
2016/08/12 18:14:52.038 kid1| 74,5| RequestParser.cc(343) parse: Parser:
bytes processed=0
2016/08/12 18:14:52.038 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=173.236.187.17:80 remote=10.4.4.61:7940 FD 11 flags=33
2016/08/12 18:14:52.038 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Fri, 12 Aug 2016 15:14:52 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close


----------
2016/08/12 18:14:52.097 kid1| 74,9| RequestParser.cc(316) parse: Parse
buf={length=207,
data='??7\????8\????8]????9]????9^????:^????:_????<`????<a????=a????=b????>b????>c?????c?????d????@d????
@e????
Ae????
Af????
Bf????
Bg????
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????"Fk????"G'}
2016/08/12 18:14:52.097 kid1| 74,5| RequestParser.cc(263)
parseRequestFirstLine: parsing possible request: buf.length=207
2016/08/12 18:14:52.097 kid1| 74,9| RequestParser.cc(264)
parseRequestFirstLine:
??7\????8\????8]????9]????9^????:^????:_????<`????<a????=a????=b????>b????>c?????c?????d????@d????
@e????
Ae????
Af????
Bf????
Bg????
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????"Fk????"G
2016/08/12 18:14:52.097 kid1| 74,5| RequestParser.cc(273)
parseRequestFirstLine: Parser needs more data
2016/08/12 18:14:52.097 kid1| 74,5| RequestParser.cc(339) parse:
request-line: retval 0: line={207,
data='??7\????8\????8]????9]????9^????:^????:_????<`????<a????=a????=b????>b????>c?????c?????d????@d????
@e????
Ae????
Af????
Bf????
Bg????
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????"Fk????"G'}
2016/08/12 18:14:52.097 kid1| 74,5| RequestParser.cc(340) parse:
request-line: method: NONE
2016/08/12 18:14:52.097 kid1| 74,5| RequestParser.cc(341) parse:
request-line: url: 
2016/08/12 18:14:52.097 kid1| 74,5| RequestParser.cc(342) parse:
request-line: proto: NONE/0.0
2016/08/12 18:14:52.097 kid1| 74,5| RequestParser.cc(343) parse: Parser:
bytes processed=0
2016/08/12 18:14:52.152 kid1| 74,9| RequestParser.cc(316) parse: Parse
buf={length=78, data='
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???6[???7[????7\????8\????'}
2016/08/12 18:14:52.152 kid1| 74,5| RequestParser.cc(263)
parseRequestFirstLine: parsing possible request: buf.length=78
2016/08/12 18:14:52.152 kid1| 74,9| RequestParser.cc(264)
parseRequestFirstLine: 
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???6[???7[????7\????8\????
2016/08/12 18:14:52.152 kid1| 74,5| RequestParser.cc(273)
parseRequestFirstLine: Parser needs more data
2016/08/12 18:14:52.152 kid1| 74,5| RequestParser.cc(339) parse:
request-line: retval 0: line={78, data='
2V{???2W{???3W|???3X|???4X}???4Y}???5Y~???6[???7[????7\????8\????'}
2016/08/12 18:14:52.152 kid1| 74,5| RequestParser.cc(340) parse:
request-line: method: NONE
2016/08/12 18:14:52.152 kid1| 74,5| RequestParser.cc(341) parse:
request-line: url: 
2016/08/12 18:14:52.152 kid1| 74,5| RequestParser.cc(342) parse:
request-line: proto: NONE/0.0
2016/08/12 18:14:52.152 kid1| 74,5| RequestParser.cc(343) parse: Parser:
bytes processed=0
2016/08/12 18:14:52.203 kid1| 74,9| RequestParser.cc(316) parse: Parse
buf={length=393, data='???
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????#Gl????#Hl????$Hm???
2016/08/12 18:14:52.203 kid1| 74,5| RequestParser.cc(263)
parseRequestFirstLine: parsing possible request: buf.length=393
2016/08/12 18:14:52.203 kid1| 74,9| RequestParser.cc(264)
parseRequestFirstLine: ???
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????#Gl????#Hl????$Hm???
2016/08/12 18:14:52.203 kid1| 74,5| RequestParser.cc(339) parse:
request-line: retval -1: line={393, data='???
Cg????Ch????Dh???? Di????
Ei????!Ej????!Fj????#Gl????#Hl????$Hm???
2016/08/12 18:14:52.203 kid1| 74,5| RequestParser.cc(340) parse:
request-line: method: NONE
2016/08/12 18:14:52.203 kid1| 74,5| RequestParser.cc(341) parse:
request-line: url: 
2016/08/12 18:14:52.203 kid1| 74,5| RequestParser.cc(342) parse:
request-line: proto: NONE/0.0
2016/08/12 18:14:52.203 kid1| 74,5| RequestParser.cc(343) parse: Parser:
bytes processed=0
2016/08/12 18:14:52.203 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=173.236.187.17:80 remote=10.4.4.61:7943 FD 11 flags=33
2016/08/12 18:14:52.203 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Fri, 12 Aug 2016 15:14:52 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/X-Squid-Error-tp4678848p4678883.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ht at inf.ed.ac.uk  Fri Aug 12 15:30:17 2016
From: ht at inf.ed.ac.uk (Henry S. Thompson)
Date: Fri, 12 Aug 2016 16:30:17 +0100
Subject: [squid-users] Another squid log question (still from 2.6.STABLE18):
	TCP_HIT + DIRECT
Message-ID: <f5by44280om.fsf@troutbeck.inf.ed.ac.uk>

In e.g. yesterday's log file, for 950K valid http requests, I find about
with 822K peer status DIRECT/...
Of these, those with squid status some variant of _HIT break down as
follows:

    115 TCP_HIT/200
     49 TCP_IMS_HIT/304
      8 TCP_MEM_HIT/200
  12880 TCP_REFRESH_HIT/200
     15 TCP_REFRESH_HIT/206
  14566 TCP_REFRESH_HIT/304

I understand the REFRESH cases, but what about the first three?  Under
what circumstances does a (non-REFRESH) cache hit none-the-less cause a
fetch to an origin server?

Thanks,

ht
-- 
       Henry S. Thompson, School of Informatics, University of Edinburgh
      10 Crichton Street, Edinburgh EH8 9AB, SCOTLAND -- (44) 131 650-4440
                Fax: (44) 131 650-4587, e-mail: ht at inf.ed.ac.uk
                       URL: http://www.ltg.ed.ac.uk/~ht/
 [mail from me _always_ has a .sig like this -- mail without it is forged spam]


From Antony.Stone at squid.open.source.it  Fri Aug 12 15:32:49 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 12 Aug 2016 17:32:49 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471014883949-4678882.post@n4.nabble.com>
References: <201608121150.03866.Antony.Stone@squid.open.source.it>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
Message-ID: <201608121732.50042.Antony.Stone@squid.open.source.it>

On Friday 12 August 2016 at 17:14:43, james82 wrote:

> i try to do this tutorial:
> https://www.linode.com/docs/networking/squid/squid-http-proxy-ubuntu-12-04.
> And here is my squid.conf file: pastebin.com/MnhK0ewx . can you tell me
> what line number for i add : acl client src 12.34.56.78, and what line
> number for: http_access allow client. please, i need this help. Please
> help me like this, just tell me the line number in my squid.conf that i
> will add that two thing. hug thank very much.

You are getting really annoying.

We ask you to post your squid.conf file here - you keep on putting it onto 
pastebin.

We ask you to copy error messages into the body of your emails - you keep 
sending us incomplete screenshots.

We suggest that you put the configuration lines you are trying to add to your 
squid.conf immediately after the line which says "INSERT YOUR OWN RULE(S) HERE 
TO ALLOW ACCESS FROM YOUR CLIENTS" (which, to be honest, I think should be 
self-explanatory in itself that that is where you should be putting them), and 
you come back and ask multiple times "where do I put them?"

And by the way, I hope that the IP address 12.34.56.78 was just an example, 
and isn't the real IP address of your client machine (or do you in fact work 
for the Northwestern Mutual Life Insurance Company of Milwaukee, Wisconsin, 
which is who that IP address belongs to?).


Please show us any indication that you have attempted to do something for 
yourself, rather than just asking us to create your squid.conf file for you.


If you are unable to follow guidance such as I wrote to you yesterday:

-----
My best guidance for you at the moment, though, is to look for the following 
line in your squid.conf file:

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

and insert the lines your tutorial tells you add immediately after that.

Once you have done that, if you continue to encounter problems, please post 
your resulting squid.conf file (without comments or blank lines) here and tell 
us exactly what the problem was.  We may then be able to help further.
-----

then I'm not sure we are able to help you in any way at all.


Regards,


Antony.

-- 
I just got a new mobile phone, and I called it Titanic.  It's already syncing.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Fri Aug 12 16:00:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Aug 2016 04:00:12 +1200
Subject: [squid-users] X-Squid-Error
In-Reply-To: <1471015035516-4678883.post@n4.nabble.com>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
 <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>
 <1471015035516-4678883.post@n4.nabble.com>
Message-ID: <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>

On 13/08/2016 3:17 a.m., joe wrote:
> 2016/08/12 18:14:51.855 kid1| 74,9| RequestParser.cc(316) parse: Parse
> buf={length=135, data='??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???
> .Rw???
> .Sw???
> /3W| ??3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??'}
> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(263)
> parseRequestFirstLine: parsing possible request: buf.length=135
> 2016/08/12 18:14:51.856 kid1| 74,9| RequestParser.cc(264)
> parseRequestFirstLine: ??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???
> .Rw???
> .Sw???
> /3W| ??3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??
> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(339) parse:
> request-line: retval -1: line={135,
> data='??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???	.Rw???
> .Sw???
> /3W| ??3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??'}
> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(340) parse:
> request-line: method: NONE
> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(341) parse:
> request-line: url: 
> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(342) parse:
> request-line: proto: NONE/0.0
> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(343) parse: Parser:
> bytes processed=0
> 2016/08/12 18:14:51.856 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
> Client local=173.236.187.17:80 remote=10.4.4.61:7937 FD 11 flags=33
> 2016/08/12 18:14:51.856 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
> Client REPLY:
> ---------
> HTTP/1.1 400 Bad Request
> Server: squid
> Mime-Version: 1.0
> Date: Fri, 12 Aug 2016 15:14:51 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3367
> X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
> X-Cache: MISS from proxy.netgatesss.com
> Connection: close
> 
> 

That 400 statuss output is correct. This stream of binary octets does
not make an HTTP request message, not even close.

The "problem" (if you can call it that) it that some application is
attempting to pass non-HTTP garbage over the registered HTTP port 80.
The solution is to stop that application. Squids output is the polite
way of telling it that it has to use HTTP over that port.

Amos



From yvoinov at gmail.com  Fri Aug 12 16:40:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 12 Aug 2016 22:40:40 +0600
Subject: [squid-users] X-Squid-Error
In-Reply-To: <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
 <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>
 <1471015035516-4678883.post@n4.nabble.com>
 <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
Message-ID: <f0ce7e7c-46ff-3df3-8df3-d5ecbb151bb0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Something like self-made bullshit proto,

something like bittorrent-over-http or something. Heh.

Webmasters still respect us!


12.08.2016 22:00, Amos Jeffries ?????:
> On 13/08/2016 3:17 a.m., joe wrote:
>> 2016/08/12 18:14:51.855 kid1| 74,9| RequestParser.cc(316) parse: Parse
>> buf={length=135,
data='??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???
>> .Rw???
>> .Sw???
>> /3W| ??3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??'}
>> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(263)
>> parseRequestFirstLine: parsing possible request: buf.length=135
>> 2016/08/12 18:14:51.856 kid1| 74,9| RequestParser.cc(264)
>> parseRequestFirstLine:
??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???
>> .Rw???
>> .Sw???
>> /3W| ??3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??
>> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(339) parse:
>> request-line: retval -1: line={135,
>> data='??)Nr???*Ns???*Os???+Ot???+Pt???,Pu???,Qu???    .Rw???
>> .Sw???
>> /3W| ??3X|???4X}???4Y}???5Y~???5Z~???6Z???6[???7[????7\??'}
>> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(340) parse:
>> request-line: method: NONE
>> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(341) parse:
>> request-line: url:
>> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(342) parse:
>> request-line: proto: NONE/0.0
>> 2016/08/12 18:14:51.856 kid1| 74,5| RequestParser.cc(343) parse: Parser:
>> bytes processed=0
>> 2016/08/12 18:14:51.856 kid1| 11,2| Stream.cc(266)
sendStartOfMessage: HTTP
>> Client local=173.236.187.17:80 remote=10.4.4.61:7937 FD 11 flags=33
>> 2016/08/12 18:14:51.856 kid1| 11,2| Stream.cc(267)
sendStartOfMessage: HTTP
>> Client REPLY:
>> ---------
>> HTTP/1.1 400 Bad Request
>> Server: squid
>> Mime-Version: 1.0
>> Date: Fri, 12 Aug 2016 15:14:51 GMT
>> Content-Type: text/html;charset=utf-8
>> Content-Length: 3367
>> X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
>> X-Cache: MISS from proxy.netgatesss.com
>> Connection: close
>>
>>
>
> That 400 statuss output is correct. This stream of binary octets does
> not make an HTTP request message, not even close.
>
> The "problem" (if you can call it that) it that some application is
> attempting to pass non-HTTP garbage over the registered HTTP port 80.
> The solution is to stop that application. Squids output is the polite
> way of telling it that it has to use HTTP over that port.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXrfwHAAoJENNXIZxhPexGTXgH/0ox4ESdUd2Nph3M988WrahP
nRQARZvEfGHXD80eQOseLqSYiTTsC0D2XxDN2qthYqLBd6B19EJ8A+z4+pmHUeYq
NSubVjPC4tEtX0n1F0v4BWxw++vljwCRP8eRvsX7Quccb86LtVtHIJRVkuwe0c78
YEg/TucNmb2UGMawlSpeP4Tejo9LTVysIyl1zCAI21IYiBIl4RUHTo1Fp6GBDhTN
zn1Pf7EwJPjoZYBsgB2jufuHbjRzXs4MyXaagH4tTNwllTkyALdRw8KY4JXgLEUG
7Reh2zoTgA+FCIgCQumgqbe0lfOIirxnhU7owNVOnntLqIzS0uYHT1VzFLyfPT4=
=m+4M
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160812/48d6679e/attachment.key>

From chip_pop at hotmail.com  Fri Aug 12 17:31:05 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 12 Aug 2016 10:31:05 -0700 (PDT)
Subject: [squid-users] X-Squid-Error
In-Reply-To: <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
 <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>
 <1471015035516-4678883.post@n4.nabble.com>
 <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
Message-ID: <1471023065161-4678888.post@n4.nabble.com>

its just me and my self  and i only test on cnn.com  no other app ar runing
in my computer
wen i click on cnn.com it happen
config file and the compile configur ar identical
r14782 trunk ar ok and lower trunk all ok



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/X-Squid-Error-tp4678848p4678888.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Fri Aug 12 18:22:44 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 12 Aug 2016 11:22:44 -0700 (PDT)
Subject: [squid-users] X-Squid-Error
In-Reply-To: <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
 <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>
 <1471015035516-4678883.post@n4.nabble.com>
 <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
Message-ID: <1471026164054-4678889.post@n4.nabble.com>

hmmm  if i try to vue the same page cnn.com no more error
wen i clean my cache and try again it happen it look like only on clean
cache can triger it
debug_options ALL,3


2016/08/12 21:05:45.904 kid1| 36,3| ufs/UFSSwapDir.cc(1334) DirClean:
Cleaning directory /mnt/cache/02/7C
2016/08/12 21:06:00.905 kid1| 36,3| ufs/UFSSwapDir.cc(1334) DirClean:
Cleaning directory /mnt/cache/03/7C
2016/08/12 21:06:15.906 kid1| 36,3| ufs/UFSSwapDir.cc(1334) DirClean:
Cleaning directory /mnt/cache/04/7C
2016/08/12 21:06:18.660 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 20
2016/08/12 21:06:18.660 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 20 flags=41
2016/08/12 21:06:18.660 kid1| 51,3| fd.cc(199) fd_open: fd_open() FD 11 HTTP
Request
2016/08/12 21:06:18.660 kid1| 28,3| Eui48.cc(516) lookup: id=0x181b404
10.4.4.60 NOT found
2016/08/12 21:06:18.660 kid1| 78,3| dns_internal.cc(1823) idnsPTRLookup:
idnsPTRLookup: buf is 40 bytes for 10.4.4.60, id = 0x28ae
2016/08/12 21:06:18.660 kid1| 50,3| comm.cc(960) comm_udp_sendto:
comm_udp_sendto: Attempt to send UDP packet to 4.2.2.3:53 using FD 6 using
Port 10982
2016/08/12 21:06:18.660 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=54.192.217.48:80 remote=10.4.4.60:3318 FD 11 flags=33 timeout 300
2016/08/12 21:06:18.778 kid1| 78,3| dns_internal.cc(1330) idnsRead:
idnsRead: starting with FD 6
2016/08/12 21:06:18.778 kid1| 78,3| dns_internal.cc(1376) idnsRead:
idnsRead: FD 6: received 99 bytes from 4.2.2.3:53
2016/08/12 21:06:18.778 kid1| 78,3| dns_internal.cc(1183) idnsGrokReply:
idnsGrokReply: QID 0x28ae, -3 answers
2016/08/12 21:06:18.778 kid1| 78,3| dns_internal.cc(1248) idnsGrokReply:
idnsGrokReply: error Name Error: The domain name does not exist. (3)
2016/08/12 21:06:18.778 kid1| 35,3| fqdncache.cc(327) fqdncacheParse:
fqdncacheParse: Lookup of '10.4.4.60' failed (Name Error: The domain name
does not exist.)
2016/08/12 21:06:20.969 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 20
2016/08/12 21:06:20.969 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 20 flags=41
2016/08/12 21:06:20.969 kid1| 51,3| fd.cc(199) fd_open: fd_open() FD 13 HTTP
Request
2016/08/12 21:06:20.969 kid1| 28,3| Eui48.cc(516) lookup: id=0x1409634
10.4.4.61 NOT found
2016/08/12 21:06:20.969 kid1| 78,3| dns_internal.cc(1823) idnsPTRLookup:
idnsPTRLookup: buf is 40 bytes for 10.4.4.61, id = 0x75b7
2016/08/12 21:06:20.969 kid1| 50,3| comm.cc(960) comm_udp_sendto:
comm_udp_sendto: Attempt to send UDP packet to 4.2.2.3:53 using FD 6 using
Port 10982
2016/08/12 21:06:20.969 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=173.236.187.17:80 remote=10.4.4.61:12441 FD 13 flags=33 timeout 300
2016/08/12 21:06:20.969 kid1| 5,3| IoCallback.cc(116) finish: called for
local=173.236.187.17:80 remote=10.4.4.61:12441 FD 13 flags=33 (0, 0)
2016/08/12 21:06:20.969 kid1| 5,3| Read.cc(92) ReadNow:
local=173.236.187.17:80 remote=10.4.4.61:12441 FD 13 flags=33, size 4096,
retval 363, errno 0
2016/08/12 21:06:20.969 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=173.236.187.17:80 remote=10.4.4.61:12441 FD 13 flags=33 timeout 120
2016/08/12 21:06:20.970 kid1| 5,3| IoCallback.cc(116) finish: called for
local=173.236.187.17:80 remote=10.4.4.61:12441 FD 13 flags=33 (0, 0)
2016/08/12 21:06:20.970 kid1| 5,3| Read.cc(92) ReadNow:
local=173.236.187.17:80 remote=10.4.4.61:12441 FD 13 flags=33, size 3733,
retval 0, errno 0
2016/08/12 21:06:20.970 kid1| 33,3| client_side.cc(1429)
connFinishedWithConn: local=173.236.187.17:80 remote=10.4.4.61:12441 FD 13
flags=33 aborted (half_closed_clients disabled)
2016/08/12 21:06:20.970 kid1| 5,3| comm.cc(871) _comm_close: comm_close:
start closing FD 13
2016/08/12 21:06:20.970 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 13
2016/08/12 21:06:20.970 kid1| 33,2| client_side.cc(586) swanSong:
local=173.236.187.17:80 remote=10.4.4.61:12441 flags=33
2016/08/12 21:06:20.970 kid1| 33,3| client_side_request.cc(270)
~ClientHttpRequest: httpRequestFree: error:transaction-end-before-headers
2016/08/12 21:06:20.970 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffc80a911a0 checking fast ACLs
2016/08/12 21:06:20.970 kid1| 28,3| Acl.cc(290) matches: checked:
(access_log daemon:/var/log/squid/access.log line) = 1
2016/08/12 21:06:20.970 kid1| 28,3| Acl.cc(290) matches: checked: access_log
daemon:/var/log/squid/access.log = 1
2016/08/12 21:06:20.970 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffc80a911a0 answer ALLOWED for match
2016/08/12 21:06:20.970 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 1 bytes
2016/08/12 21:06:20.970 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 0
of 32768 bytes before append
2016/08/12 21:06:20.970 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 100 bytes
2016/08/12 21:06:20.970 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 1
of 32768 bytes before append
2016/08/12 21:06:20.970 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 7 bytes
2016/08/12 21:06:20.970 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 101
of 32768 bytes before append
2016/08/12 21:06:20.970 kid1| 33,3| client_side.cc(4004) unpinConnection: 
2016/08/12 21:06:20.970 kid1| 33,3| client_side.cc(616) ~ConnStateData:
local=173.236.187.17:80 remote=10.4.4.61:12441 flags=33
2016/08/12 21:06:20.970 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 13
Reading next request
2016/08/12 21:06:21.057 kid1| 78,3| dns_internal.cc(1330) idnsRead:
idnsRead: starting with FD 6
2016/08/12 21:06:21.057 kid1| 78,3| dns_internal.cc(1376) idnsRead:
idnsRead: FD 6: received 99 bytes from 4.2.2.3:53
2016/08/12 21:06:21.057 kid1| 78,3| dns_internal.cc(1183) idnsGrokReply:
idnsGrokReply: QID 0x75b7, -3 answers
2016/08/12 21:06:21.057 kid1| 78,3| dns_internal.cc(1248) idnsGrokReply:
idnsGrokReply: error Name Error: The domain name does not exist. (3)
2016/08/12 21:06:21.057 kid1| 35,3| fqdncache.cc(327) fqdncacheParse:
fqdncacheParse: Lookup of '10.4.4.61' failed (Name Error: The domain name
does not exist.)
2016/08/12 21:06:21.081 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 20
2016/08/12 21:06:21.081 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 20 flags=41
2016/08/12 21:06:21.081 kid1| 51,3| fd.cc(199) fd_open: fd_open() FD 13 HTTP
Request
2016/08/12 21:06:21.081 kid1| 28,3| Eui48.cc(516) lookup: id=0x1409634
10.4.4.61 NOT found
2016/08/12 21:06:21.082 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=173.236.187.17:80 remote=10.4.4.61:12442 FD 13 flags=33 timeout 300
2016/08/12 21:06:21.082 kid1| 5,3| IoCallback.cc(116) finish: called for
local=173.236.187.17:80 remote=10.4.4.61:12442 FD 13 flags=33 (0, 0)
2016/08/12 21:06:21.082 kid1| 5,3| Read.cc(92) ReadNow:
local=173.236.187.17:80 remote=10.4.4.61:12442 FD 13 flags=33, size 4096,
retval 373, errno 0
2016/08/12 21:06:21.082 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=173.236.187.17:80 remote=10.4.4.61:12442 FD 13 flags=33 timeout 120
2016/08/12 21:06:21.082 kid1| 87,3| clientStream.cc(140)
clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x140afc8 with
data 0x140ce78 after head
2016/08/12 21:06:21.082 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=173.236.187.17:80 remote=10.4.4.61:12442 FD 13 flags=33 timeout 86400
2016/08/12 21:06:21.082 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x14096e0
add request 1 0x140be10*3
2016/08/12 21:06:21.082 kid1| 33,2| Http1Server.cc(101) buildHttpRequest:
Invalid Request
2016/08/12 21:06:21.082 kid1| 20,3| store.cc(777) storeCreatePureEntry:
storeCreateEntry: 'error:invalid-request'
2016/08/12 21:06:21.082 kid1| 20,3| MemObject.cc(110) MemObject: new
MemObject 0x1824f10
2016/08/12 21:06:21.082 kid1| 20,3| store.cc(472) setReleaseFlag:
StoreEntry::setReleaseFlag: '[null_store_key]'
2016/08/12 21:06:21.082 kid1| 20,3| store.cc(421) hashInsert:
StoreEntry::hashInsert: Inserting Entry e:=XI/0x140e330*0 key
'34000000000000009A53000001000000'
2016/08/12 21:06:21.082 kid1| 20,3| store.cc(457) lock: storeCreateEntry
locked key 34000000000000009A53000001000000 e:=XIV/0x140e330*1
2016/08/12 21:06:21.082 kid1| 4,2| errorpage.cc(1260) BuildContent: No
existing error page language negotiated for ERR_PROTOCOL_UNKNOWN. Using
default error file.
2016/08/12 21:06:21.082 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%l --> '/*
 * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.
 */

/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates
 http://www.freecsstemplates.org
 Released for free under a Creative Commons Attribution 2.5 License
*/

/* Page basics */
* {
	font-family: verdana, sans-serif;
}

html body {
	margin: 0;
	padding: 0;
	background: #efefef;
	font-size: 12px;
	color: #1e1e1e;
}

/* Page displayed title area */
#titles {
	margin-left: 15px;
	padding: 10px;
	padding-left: 100px;
	background: url('http://www.squid-cache.org/Artwork/SN.png') no-repeat
left;
}

/* initial title */
#titles h1 {
	color: #000000;
}
#titles h2 {
	color: #000000;
}

/* special event: FTP success page titles */
#titles ftpsuccess {
	background-color:#00ff00;
	width:100%;
}

/* Page displayed body content area */
#content {
	padding: 10px;
	background: #ffffff;
}

/* General text */
p {
}

/* error brief description */
#error p {
}

/* some data which may have caused the problem */
#data {
}

/* the error message received from the system or other software */
#sysmsg {
}

pre {
    font-family:sans-serif;
}

/* special event: FTP / Gopher directory listing */
#dirmsg {
    font-family: courier;
    color: black;
    font-size: 10pt;
}
#dirlisting {
    margin-left: 2%;
    margin-right: 2%;
}
#dirlisting tr.entry td.icon,td.filename,td.size,td.date {
    border-bottom: groove;
}
#dirlisting td.size {
    width: 50px;
    text-align: right;
    padding-right: 5px;
}

/* horizontal lines */
hr {
	margin: 0;
}

/* page displayed footer area */
#footer {
	font-size: 9px;
	padding-left: 10px;
}
'
2016/08/12 21:06:21.082 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%; --> '%;'
2016/08/12 21:06:21.082 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%c --> 'ERR_PROTOCOL_UNKNOWN'
2016/08/12 21:06:21.082 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%U --> 'error:invalid-request'
2016/08/12 21:06:21.082 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%U --> 'error:invalid-request'
2016/08/12 21:06:21.082 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%w --> 'webmaster'
2016/08/12 21:06:21.082 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%W -->
'?subject=CacheErrorInfo%20-%20ERR_PROTOCOL_UNKNOWN&body=CacheHost%3A%20proxy.netgatesss.com%0D%0AErrPage%3A%20ERR_PROTOCOL_UNKNOWN%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Fri,%2012%20Aug%202016%2018%3A06%3A21%20GMT%0D%0A%0D%0AClientIP%3A%2010.4.4.61%0D%0A%0D%0AHTTP%20Request%3A%0D%0A%0D%0A%0D%0A'
2016/08/12 21:06:21.083 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%w --> 'webmaster'
2016/08/12 21:06:21.083 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%T --> 'Fri, 12 Aug 2016 18:06:21 GMT'
2016/08/12 21:06:21.083 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%h --> 'proxy.netgatesss.com'
2016/08/12 21:06:21.083 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%s --> 'squid'
2016/08/12 21:06:21.083 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%c --> 'ERR_PROTOCOL_UNKNOWN'
2016/08/12 21:06:21.083 kid1| 20,3| store.cc(457) lock:
StoreEntry::storeErrorResponse locked key 34000000000000009A53000001000000
e:=XIV/0x140e330*2
2016/08/12 21:06:21.083 kid1| 20,3| store.cc(1848) replaceHttpReply:
StoreEntry::replaceHttpReply: error:invalid-request
2016/08/12 21:06:21.083 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 21:06:21.083 kid1| 20,3| store_swapout.cc(382) mayStartSwapOut:
not cachable
2016/08/12 21:06:21.083 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 21:06:21.083 kid1| 90,3| store_client.cc(729) invokeHandlers:
InvokeHandlers: 34000000000000009A53000001000000
2016/08/12 21:06:21.083 kid1| 90,3| store_client.cc(735) invokeHandlers:
StoreEntry::InvokeHandlers: checking client #0
2016/08/12 21:06:21.083 kid1| 20,3| store.cc(1089) complete: storeComplete:
'34000000000000009A53000001000000'
2016/08/12 21:06:21.083 kid1| 20,3| store.cc(1342) validLength:
storeEntryValidLength: Checking '34000000000000009A53000001000000'
2016/08/12 21:06:21.083 kid1| 20,3| store_swapout.cc(357) mayStartSwapOut: 
already rejected
2016/08/12 21:06:21.083 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 21:06:21.083 kid1| 90,3| store_client.cc(729) invokeHandlers:
InvokeHandlers: 34000000000000009A53000001000000
2016/08/12 21:06:21.083 kid1| 90,3| store_client.cc(735) invokeHandlers:
StoreEntry::InvokeHandlers: checking client #0
2016/08/12 21:06:21.083 kid1| 20,3| store.cc(494) unlock:
StoreEntry::storeErrorResponse unlocking key
34000000000000009A53000001000000 e:=sXINV/0x140e330*2
2016/08/12 21:06:21.083 kid1| 87,3| clientStream.cc(180) clientStreamRead:
clientStreamRead: Calling 1 with cbdata 0x140e298 from node 0x140afc8
2016/08/12 21:06:21.083 kid1| 90,3| store_client.cc(198) copy:
store_client::copy: 34000000000000009A53000001000000, from 0, for length
4096, cb 1, cbdata 0x140d1e8
2016/08/12 21:06:21.083 kid1| 20,3| store.cc(457) lock: store_client::copy
locked key 34000000000000009A53000001000000 e:=sXINV/0x140e330*2
2016/08/12 21:06:21.083 kid1| 90,3| store_client.cc(295) storeClientCopy2:
storeClientCopy2: 34000000000000009A53000001000000
2016/08/12 21:06:21.083 kid1| 90,3| store_client.cc(429) scheduleMemRead:
store_client::doCopy: Copying normal from memory
2016/08/12 21:06:21.083 kid1| 33,2| QosConfig.cc(163) doTosLocalMiss: QOS:
Preserving TOS on miss, TOS=0
2016/08/12 21:06:21.083 kid1| 50,3| ../../src/ip/Qos.cci(22) setSockTos: for
FD 13 to 0
2016/08/12 21:06:21.083 kid1| 88,2| client_side_reply.cc(2054)
processReplyAccessResult: The reply for NONE error:invalid-request is
ALLOWED, because it matched (access_log daemon:/var/log/squid/access.log
line)
2016/08/12 21:06:21.083 kid1| 20,3| store.cc(457) lock:
ClientHttpRequest::loggingEntry locked key 34000000000000009A53000001000000
e:=sXINV/0x140e330*3
2016/08/12 21:06:21.083 kid1| 88,3| client_side_reply.cc(2092)
processReplyAccessResult: clientReplyContext::sendMoreData: Appending 3367
bytes after 199 bytes of headers
2016/08/12 21:06:21.083 kid1| 87,3| clientStream.cc(158)
clientStreamCallback: clientStreamCallback: Calling 1 with cbdata 0x140ce78
from node 0x1409a68
2016/08/12 21:06:21.083 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x14096e0 front 0x140be10*3
2016/08/12 21:06:21.083 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x14096e0 front 0x140be10*3
2016/08/12 21:06:21.083 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=173.236.187.17:80 remote=10.4.4.61:12442 FD 13 flags=33
2016/08/12 21:06:21.083 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Fri, 12 Aug 2016 18:06:21 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close


----------
2016/08/12 21:06:21.083 kid1| 20,3| store.cc(494) unlock: store_client::copy
unlocking key 34000000000000009A53000001000000 e:=sXINV/0x140e330*3
2016/08/12 21:06:21.084 kid1| 5,3| IoCallback.cc(116) finish: called for
local=173.236.187.17:80 remote=10.4.4.61:12442 FD 13 flags=33 (0, 0)
2016/08/12 21:06:21.084 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x14096e0 front 0x140be10*2
2016/08/12 21:06:21.084 kid1| 88,3| client_side_reply.cc(1150)
storeOKTransferDone: storeOKTransferDone  out.offset=3367 objectLen()=3566
headers_sz=199
2016/08/12 21:06:21.084 kid1| 5,3| comm.cc(871) _comm_close: comm_close:
start closing FD 13
2016/08/12 21:06:21.084 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 13
2016/08/12 21:06:21.084 kid1| 87,3| clientStream.cc(198) clientStreamDetach:
clientStreamDetach: Detaching node 0x140afc8
2016/08/12 21:06:21.084 kid1| 87,3| clientStream.cc(97) ~clientStreamNode:
Freeing clientStreamNode 0x140afc8
2016/08/12 21:06:21.084 kid1| 87,3| clientStream.cc(219) clientStreamDetach:
clientStreamDetach: Calling 1 with cbdata 0x140e298
2016/08/12 21:06:21.084 kid1| 87,3| clientStream.cc(198) clientStreamDetach:
clientStreamDetach: Detaching node 0x1409a68
2016/08/12 21:06:21.084 kid1| 87,3| clientStream.cc(97) ~clientStreamNode:
Freeing clientStreamNode 0x1409a68
2016/08/12 21:06:21.084 kid1| 90,3| store_client.cc(661) storeUnregister:
storeUnregister: called for '34000000000000009A53000001000000'
2016/08/12 21:06:21.084 kid1| 20,3| store_swapout.cc(357) mayStartSwapOut: 
already rejected
2016/08/12 21:06:21.084 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 21:06:21.084 kid1| 20,3| store.cc(457) lock: storeUnregister
locked key 34000000000000009A53000001000000 e:=sXINV/0x140e330*3
2016/08/12 21:06:21.084 kid1| 90,3| store_client.cc(755)
storePendingNClients: storePendingNClients: returning 0
2016/08/12 21:06:21.084 kid1| 20,3| store.cc(494) unlock: storeUnregister
unlocking key 34000000000000009A53000001000000 e:=sXINV/0x140e330*3
2016/08/12 21:06:21.084 kid1| 20,3| store.cc(494) unlock:
clientReplyContext::removeStoreReference unlocking key
34000000000000009A53000001000000 e:=sXINV/0x140e330*2
2016/08/12 21:06:21.084 kid1| 33,3| Pipeline.cc(69) popMe: Pipeline
0x14096e0 drop 0x140be10*3
2016/08/12 21:06:21.084 kid1| 33,2| client_side.cc(893) kick:
local=173.236.187.17:80 remote=10.4.4.61:12442 flags=33 Connection was
closed
2016/08/12 21:06:21.084 kid1| 33,3| client_side_request.cc(270)
~ClientHttpRequest: httpRequestFree: error:invalid-request
2016/08/12 21:06:21.084 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffc80a91290 checking fast ACLs
2016/08/12 21:06:21.084 kid1| 28,3| Acl.cc(290) matches: checked:
(access_log daemon:/var/log/squid/access.log line) = 1
2016/08/12 21:06:21.084 kid1| 28,3| Acl.cc(290) matches: checked: access_log
daemon:/var/log/squid/access.log = 1
2016/08/12 21:06:21.084 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffc80a91290 answer ALLOWED for match
2016/08/12 21:06:21.084 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 1 bytes
2016/08/12 21:06:21.084 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 108
of 32768 bytes before append
2016/08/12 21:06:21.084 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 96 bytes
2016/08/12 21:06:21.084 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 109
of 32768 bytes before append
2016/08/12 21:06:21.084 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 220 bytes
2016/08/12 21:06:21.084 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 205
of 32768 bytes before append
2016/08/12 21:06:21.084 kid1| 20,3| store.cc(494) unlock:
ClientHttpRequest::loggingEntry unlocking key
34000000000000009A53000001000000 e:=sXINV/0x140e330*1
2016/08/12 21:06:21.084 kid1| 90,3| store_client.cc(755)
storePendingNClients: storePendingNClients: returning 0
2016/08/12 21:06:21.084 kid1| 20,3| store.cc(1252) release: releasing
e:=sXINV/0x140e330*0 34000000000000009A53000001000000
2016/08/12 21:06:21.084 kid1| 20,3| store.cc(378) destroyMemObject:
destroyMemObject 0x1824f10
2016/08/12 21:06:21.084 kid1| 20,3| MemObject.cc(119) ~MemObject: del
MemObject 0x1824f10
2016/08/12 21:06:21.084 kid1| 20,3| store.cc(396) destroyStoreEntry:
destroyStoreEntry: destroying 0x140e338
2016/08/12 21:06:21.084 kid1| 20,3| store.cc(378) destroyMemObject:
destroyMemObject 0
2016/08/12 21:06:21.085 kid1| 33,2| client_side.cc(586) swanSong:
local=173.236.187.17:80 remote=10.4.4.61:12442 flags=33
2016/08/12 21:06:21.085 kid1| 33,3| client_side_request.cc(270)
~ClientHttpRequest: httpRequestFree: error:transaction-end-before-headers
2016/08/12 21:06:21.085 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffc80a911a0 checking fast ACLs
2016/08/12 21:06:21.085 kid1| 28,3| Acl.cc(290) matches: checked:
(access_log daemon:/var/log/squid/access.log line) = 1
2016/08/12 21:06:21.085 kid1| 28,3| Acl.cc(290) matches: checked: access_log
daemon:/var/log/squid/access.log = 1
2016/08/12 21:06:21.085 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffc80a911a0 answer ALLOWED for match
2016/08/12 21:06:21.085 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 1 bytes
2016/08/12 21:06:21.085 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 425
of 32768 bytes before append
2016/08/12 21:06:21.085 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 100 bytes
2016/08/12 21:06:21.085 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 426
of 32768 bytes before append
2016/08/12 21:06:21.085 kid1| 50,3| ModDaemon.cc(174)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 7 bytes
2016/08/12 21:06:21.085 kid1| 50,3| ModDaemon.cc(178)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 526
of 32768 bytes before append
2016/08/12 21:06:21.085 kid1| 33,3| client_side.cc(4004) unpinConnection: 
2016/08/12 21:06:21.085 kid1| 33,3| client_side.cc(616) ~ConnStateData:
local=173.236.187.17:80 remote=10.4.4.61:12442 flags=33
2016/08/12 21:06:21.085 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 13
Reading next request
2016/08/12 21:06:21.168 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New
connection on FD 20
2016/08/12 21:06:21.168 kid1| 5,2| TcpAcceptor.cc(315) acceptNext:
connection on local=0.0.0.0:3128 remote=[::] FD 20 flags=41
2016/08/12 21:06:21.168 kid1| 51,3| fd.cc(199) fd_open: fd_open() FD 13 HTTP
Request
2016/08/12 21:06:21.168 kid1| 28,3| Eui48.cc(516) lookup: id=0x1409634
10.4.4.61 NOT found
2016/08/12 21:06:21.168 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=173.236.187.17:80 remote=10.4.4.61:12443 FD 13 flags=33 timeout 300
2016/08/12 21:06:21.169 kid1| 5,3| IoCallback.cc(116) finish: called for
local=173.236.187.17:80 remote=10.4.4.61:12443 FD 13 flags=33 (0, 0)
2016/08/12 21:06:21.169 kid1| 5,3| Read.cc(92) ReadNow:
local=173.236.187.17:80 remote=10.4.4.61:12443 FD 13 flags=33, size 4096,
retval 216, errno 0
2016/08/12 21:06:21.169 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=173.236.187.17:80 remote=10.4.4.61:12443 FD 13 flags=33 timeout 120
2016/08/12 21:06:21.169 kid1| 87,3| clientStream.cc(140)
clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x140afc8 with
data 0x140ce78 after head
2016/08/12 21:06:21.169 kid1| 5,3| comm.cc(559) commSetConnTimeout:
local=173.236.187.17:80 remote=10.4.4.61:12443 FD 13 flags=33 timeout 86400
2016/08/12 21:06:21.169 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x14096e0
add request 1 0x140be10*3
2016/08/12 21:06:21.169 kid1| 33,2| Http1Server.cc(101) buildHttpRequest:
Invalid Request
2016/08/12 21:06:21.169 kid1| 20,3| store.cc(777) storeCreatePureEntry:
storeCreateEntry: 'error:invalid-request'
2016/08/12 21:06:21.169 kid1| 20,3| MemObject.cc(110) MemObject: new
MemObject 0x1824f10
2016/08/12 21:06:21.169 kid1| 20,3| store.cc(472) setReleaseFlag:
StoreEntry::setReleaseFlag: '[null_store_key]'
2016/08/12 21:06:21.169 kid1| 20,3| store.cc(421) hashInsert:
StoreEntry::hashInsert: Inserting Entry e:=XI/0x140e330*0 key
'35000000000000009A53000001000000'
2016/08/12 21:06:21.169 kid1| 20,3| store.cc(457) lock: storeCreateEntry
locked key 35000000000000009A53000001000000 e:=XIV/0x140e330*1
2016/08/12 21:06:21.169 kid1| 4,2| errorpage.cc(1260) BuildContent: No
existing error page language negotiated for ERR_PROTOCOL_UNKNOWN. Using
default error file.
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%l --> '/*
 * Copyright (C) 1996-2015 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.
 */

/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates
 http://www.freecsstemplates.org
 Released for free under a Creative Commons Attribution 2.5 License
*/

/* Page basics */
* {
	font-family: verdana, sans-serif;
}

html body {
	margin: 0;
	padding: 0;
	background: #efefef;
	font-size: 12px;
	color: #1e1e1e;
}

/* Page displayed title area */
#titles {
	margin-left: 15px;
	padding: 10px;
	padding-left: 100px;
	background: url('http://www.squid-cache.org/Artwork/SN.png') no-repeat
left;
}

/* initial title */
#titles h1 {
	color: #000000;
}
#titles h2 {
	color: #000000;
}

/* special event: FTP success page titles */
#titles ftpsuccess {
	background-color:#00ff00;
	width:100%;
}

/* Page displayed body content area */
#content {
	padding: 10px;
	background: #ffffff;
}

/* General text */
p {
}

/* error brief description */
#error p {
}

/* some data which may have caused the problem */
#data {
}

/* the error message received from the system or other software */
#sysmsg {
}

pre {
    font-family:sans-serif;
}

/* special event: FTP / Gopher directory listing */
#dirmsg {
    font-family: courier;
    color: black;
    font-size: 10pt;
}
#dirlisting {
    margin-left: 2%;
    margin-right: 2%;
}
#dirlisting tr.entry td.icon,td.filename,td.size,td.date {
    border-bottom: groove;
}
#dirlisting td.size {
    width: 50px;
    text-align: right;
    padding-right: 5px;
}

/* horizontal lines */
hr {
	margin: 0;
}

/* page displayed footer area */
#footer {
	font-size: 9px;
	padding-left: 10px;
}
'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%; --> '%;'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%c --> 'ERR_PROTOCOL_UNKNOWN'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%U --> 'error:invalid-request'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%U --> 'error:invalid-request'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%w --> 'webmaster'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%W -->
'?subject=CacheErrorInfo%20-%20ERR_PROTOCOL_UNKNOWN&body=CacheHost%3A%20proxy.netgatesss.com%0D%0AErrPage%3A%20ERR_PROTOCOL_UNKNOWN%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Fri,%2012%20Aug%202016%2018%3A06%3A21%20GMT%0D%0A%0D%0AClientIP%3A%2010.4.4.61%0D%0A%0D%0AHTTP%20Request%3A%0D%0A%0D%0A%0D%0A'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%w --> 'webmaster'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%T --> 'Fri, 12 Aug 2016 18:06:21 GMT'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%h --> 'proxy.netgatesss.com'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%s --> 'squid'
2016/08/12 21:06:21.169 kid1| 4,3| errorpage.cc(1099) Convert: errorConvert:
%%c --> 'ERR_PROTOCOL_UNKNOWN'
2016/08/12 21:06:21.169 kid1| 20,3| store.cc(457) lock:
StoreEntry::storeErrorResponse locked key 35000000000000009A53000001000000
e:=XIV/0x140e330*2
2016/08/12 21:06:21.169 kid1| 20,3| store.cc(1848) replaceHttpReply:
StoreEntry::replaceHttpReply: error:invalid-request
2016/08/12 21:06:21.170 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 21:06:21.170 kid1| 20,3| store_swapout.cc(382) mayStartSwapOut:
not cachable
2016/08/12 21:06:21.170 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 21:06:21.170 kid1| 90,3| store_client.cc(729) invokeHandlers:
InvokeHandlers: 35000000000000009A53000001000000
2016/08/12 21:06:21.170 kid1| 90,3| store_client.cc(735) invokeHandlers:
StoreEntry::InvokeHandlers: checking client #0
2016/08/12 21:06:21.170 kid1| 20,3| store.cc(1089) complete: storeComplete:
'35000000000000009A53000001000000'
2016/08/12 21:06:21.170 kid1| 20,3| store.cc(1342) validLength:
storeEntryValidLength: Checking '35000000000000009A53000001000000'
2016/08/12 21:06:21.170 kid1| 20,3| store_swapout.cc(357) mayStartSwapOut: 
already rejected
2016/08/12 21:06:21.170 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/08/12 21:06:21.170 kid1| 90,3| store_client.cc(729) invokeHandlers:
InvokeHandlers: 35000000000000009A53000001000000
2016/08/12 21:06:21.170 kid1| 90,3| store_client.cc(735) invokeHandlers:
StoreEntry::InvokeHandlers: checking client #0
2016/08/12 21:06:21.170 kid1| 20,3| store.cc(494) unlock:
StoreEntry::storeErrorResponse unlocking key
35000000000000009A53000001000000 e:=sXINV/0x140e330*2
2016/08/12 21:06:21.170 kid1| 87,3| clientStream.cc(180) clientStreamRead:
clientStreamRead: Calling 1 with cbdata 0x140e298 from node 0x140afc8
2016/08/12 21:06:21.170 kid1| 90,3| store_client.cc(198) copy:
store_client::copy: 35000000000000009A53000001000000, from 0, for length
4096, cb 1, cbdata 0x140d1e8
2016/08/12 21:06:21.170 kid1| 20,3| store.cc(457) lock: store_client::copy
locked key 35000000000000009A53000001000000 e:=sXINV/0x140e330*2
2016/08/12 21:06:21.170 kid1| 90,3| store_client.cc(295) storeClientCopy2:
storeClientCopy2: 35000000000000009A53000001000000
2016/08/12 21:06:21.170 kid1| 90,3| store_client.cc(429) scheduleMemRead:
store_client::doCopy: Copying normal from memory
2016/08/12 21:06:21.170 kid1| 33,2| QosConfig.cc(163) doTosLocalMiss: QOS:
Preserving TOS on miss, TOS=0
2016/08/12 21:06:21.170 kid1| 50,3| ../../src/ip/Qos.cci(22) setSockTos: for
FD 13 to 0
2016/08/12 21:06:21.170 kid1| 88,2| client_side_reply.cc(2054)
processReplyAccessResult: The reply for NONE error:invalid-request is
ALLOWED, because it matched (access_log daemon:/var/log/squid/access.log
line)
2016/08/12 21:06:21.170 kid1| 20,3| store.cc(457) lock:
ClientHttpRequest::loggingEntry locked key 35000000000000009A53000001000000
e:=sXINV/0x140e330*3
2016/08/12 21:06:21.170 kid1| 88,3| client_side_reply.cc(2092)
processReplyAccessResult: clientReplyContext::sendMoreData: Appending 3367
bytes after 199 bytes of headers
2016/08/12 21:06:21.170 kid1| 87,3| clientStream.cc(158)
clientStreamCallback: clientStreamCallback: Calling 1 with cbdata 0x140ce78
from node 0x1409a68
2016/08/12 21:06:21.170 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x14096e0 front 0x140be10*3
2016/08/12 21:06:21.170 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x14096e0 front 0x140be10*3
2016/08/12 21:06:21.170 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=173.236.187.17:80 remote=10.4.4.61:12443 FD 13 flags=33
2016/08/12 21:06:21.170 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Fri, 12 Aug 2016 18:06:21 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3367
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
X-Cache: MISS from proxy.netgatesss.com
Connection: close


----------



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/X-Squid-Error-tp4678848p4678889.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Fri Aug 12 23:00:18 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 12 Aug 2016 16:00:18 -0700 (PDT)
Subject: [squid-users] X-Squid-Error
In-Reply-To: <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
 <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>
 <1471015035516-4678883.post@n4.nabble.com>
 <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
Message-ID: <1471042818421-4678890.post@n4.nabble.com>

lol guys its fixt just by removing Trunk r14783 
that patch did a lot :(



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/X-Squid-Error-tp4678848p4678890.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sat Aug 13 01:01:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Aug 2016 13:01:30 +1200
Subject: [squid-users] X-Squid-Error
In-Reply-To: <1471042818421-4678890.post@n4.nabble.com>
References: <1470949857868-4678848.post@n4.nabble.com>
 <28d16a14-6136-1e60-5b15-ad67bda228b7@treenet.co.nz>
 <1470992703140-4678856.post@n4.nabble.com>
 <fa17cbe0-6c0e-72fc-cfbb-47ae757347a5@treenet.co.nz>
 <1471015035516-4678883.post@n4.nabble.com>
 <dc1af827-301a-ca62-2b74-2be31958eeb1@treenet.co.nz>
 <1471042818421-4678890.post@n4.nabble.com>
Message-ID: <25b8aa38-860d-4eae-24dd-fc53e67b9f5f@treenet.co.nz>

On 13/08/2016 11:00 a.m., joe wrote:
> lol guys its fixt just by removing Trunk r14783 
> that patch did a lot :(
> 

Great. Was just about to suggest trying the snapshot after we reverted that.

Amos



From squid3 at treenet.co.nz  Sat Aug 13 01:12:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Aug 2016 13:12:41 +1200
Subject: [squid-users] Another squid log question (still from
 2.6.STABLE18): TCP_HIT + DIRECT
In-Reply-To: <f5by44280om.fsf@troutbeck.inf.ed.ac.uk>
References: <f5by44280om.fsf@troutbeck.inf.ed.ac.uk>
Message-ID: <10990322-a3fc-552a-f9c8-5a1fa9f68e50@treenet.co.nz>

On 13/08/2016 3:30 a.m., Henry S. Thompson wrote:
> In e.g. yesterday's log file, for 950K valid http requests, I find about
> with 822K peer status DIRECT/...
> Of these, those with squid status some variant of _HIT break down as
> follows:
> 
>     115 TCP_HIT/200
>      49 TCP_IMS_HIT/304
>       8 TCP_MEM_HIT/200
>   12880 TCP_REFRESH_HIT/200
>      15 TCP_REFRESH_HIT/206
>   14566 TCP_REFRESH_HIT/304
> 
> I understand the REFRESH cases, but what about the first three?  Under
> what circumstances does a (non-REFRESH) cache hit none-the-less cause a
> fetch to an origin server?
> 

IIRC Squid-2 used DIRECT as a catch-all value when it didn't have a
better one to use.

My old memories could be wrong though. You will likely have to check the
code or an ALL,9 cache.log to find out why. None of the dev guys who
worked on Squid-2 hang out here anymore. It has been 8 years since that
version was deprecated.


PS. If this version is being forced on you by any particular vendors
product I suggest you send queries their way. Squid versions are
officially supported here for only a few years (1-3) with a bit of
'wiggle room' for things that haven't changed in the supported releases,
then any vendors who want to provide LTE releases of old Squid take up
the support burden for their particular release.

Amos



From fastestsuperman at gmail.com  Sat Aug 13 06:37:15 2016
From: fastestsuperman at gmail.com (james82)
Date: Fri, 12 Aug 2016 23:37:15 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608121732.50042.Antony.Stone@squid.open.source.it>
References: <201608121320.28858.Antony.Stone@squid.open.source.it>
 <1471002790969-4678863.post@n4.nabble.com>
 <201608121406.17631.Antony.Stone@squid.open.source.it>
 <1471008747015-4678867.post@n4.nabble.com>
 <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
 <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
Message-ID: <1471070235127-4678893.post@n4.nabble.com>

ok, this is last. Is i add this right: 

Default:
# ACLs all, manager, localhost, and to_localhost are predefined.
#
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
#acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
#acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
#acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
#acl localnet src fc00::/7       # RFC 4193 local private network range
#acl localnet src fe80::/10     # RFC 4291 link-local (directly plugged)
machines
#acl homepc src 12.34.56.78

acl SSL_ports port 443 80 
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl CONNECT method CONNECT


and:
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost
http_access allow homepc

# And finally deny all other access to this proxy
http_access deny all


i just edit only like this. is anything out that i should do. what about
make a password for this. and in the linode website tutorial, what about
anonymizing traffic?




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678893.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Sat Aug 13 07:18:24 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 13 Aug 2016 00:18:24 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
Message-ID: <1471072704202-4678894.post@n4.nabble.com>

Hello,

Recently 2 different squid boxes grows from ~40% cpu usage to 100% without
any changes to config/banwidth/number of clients/etc

The problems forced me to bypass squid until the problem found . 
Right now even 10% of users can make squid 100% .

Info 

Squid is in tproxy mode with routing

Ubuntu Linux 16.04 , 4.4.0-34-generic on x86_64
Squid Cache: Version 3.5.19 from debian repository


samples  %        image name               symbol name
1532894  42.8190  libc-2.23.so             _IO_strn_overflow
1028537  28.7306  libc-2.23.so             _IO_default_xsputn
662802   18.5143  libc-2.23.so             vfprintf
77019     2.1514  squid                    /usr/sbin/squid
28861     0.8062  libc-2.23.so             __memset_sse2
26948     0.7528  r8169                    /r8169
25320     0.7073  libc-2.23.so             __memcpy_sse2_unaligned
21712     0.6065  libc-2.23.so             __GI___mempcpy
14918     0.4167  libc-2.23.so             _int_malloc
8889      0.2483  nf_conntrack             /nf_conntrack
8130      0.2271  libc-2.23.so             __GI_strchr
6357      0.1776  libc-2.23.so             _int_free
4152      0.1160  libc-2.23.so             re_search_internal
4043      0.1129  libc-2.23.so             strlen
2754      0.0769  libstdc++.so.6.0.21     
/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
2753      0.0769  libc-2.23.so             free
2704      0.0755  ip_tables                /ip_tables
2560      0.0715  reiserfs                 /reiserfs
2332      0.0651  kallsyms                 ___slab_alloc
2284      0.0638  libc-2.23.so             malloc_consolidate
2204      0.0616  libc-2.23.so             malloc
2175      0.0608  kallsyms                 sys_epoll_ctl
2035      0.0568  kallsyms                 csum_partial_copy_generic
1614      0.0451  libc-2.23.so             calloc
1552      0.0434  kallsyms                 _raw_spin_lock
1208      0.0337  kallsyms                 memcpy
1203      0.0336  kallsyms                 nf_iterate
1177      0.0329  kallsyms                 irq_entries_start
1165      0.0325  kallsyms                 __fget
1072      0.0299  kallsyms                 copy_user_generic_string
1037      0.0290  kallsyms                 __alloc_skb
1002      0.0280  kallsyms                 tcp_sendmsg
945       0.0264  libc-2.23.so             build_upper_buffer
875       0.0244  kallsyms                 kmem_cache_free
873       0.0244  kallsyms                 tcp_rack_mark_lost
868       0.0242  nf_nat_ipv4              /nf_nat_ipv4
861       0.0241  kallsyms                 kfree
837       0.0234  kallsyms                 __inet_lookup_established
834       0.0233  kallsyms                 get_partial_node.isra.61
825       0.0230  kallsyms                 __slab_free
815       0.0228  kallsyms                 sock_poll
810       0.0226  kallsyms                 skb_release_data
802       0.0224  nf_conntrack_ipv4        /nf_conntrack_ipv4
792       0.0221  kallsyms                 tcp_transmit_skb
771       0.0215  kallsyms                 kmem_cache_alloc
719       0.0201  kallsyms                 fib_table_lookup
704       0.0197  kallsyms                 _raw_spin_lock_irqsave
701       0.0196  kallsyms                 tcp_v4_rcv
699       0.0195  libm-2.23.so             __ieee754_log_avx
686       0.0192  nf_nat                   /nf_nat
684       0.0191  kallsyms                 tcp_write_xmit
674       0.0188  kallsyms                 __cmpxchg_double_slab.isra.44
626       0.0175  kallsyms                 __netif_receive_skb_core
621       0.0173  libnettle.so.6.2        
/usr/lib/x86_64-linux-gnu/libnettle.so.6.2
608       0.0170  kallsyms                 delay_tsc
600       0.0168  kallsyms                 ksize
595       0.0166  kallsyms                 tcp_ack
592       0.0165  kallsyms                 __local_bh_enable_ip




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Sat Aug 13 08:22:21 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 10:22:21 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471070235127-4678893.post@n4.nabble.com>
References: <201608121320.28858.Antony.Stone@squid.open.source.it>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
Message-ID: <201608131022.21575.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 08:37:15, james82 wrote:

> ok, this is last. Is i add this right:

> #acl homepc src 12.34.56.78

The # symbol at the start of a line means it is a comment, and therefore 
ignored by squid.

The tutorial you are trying to follow does not have a # at the start of that 
line, therefore please do not add one.

Also, you do need to READ and FOLLOW the instructions in the tutorial.  If you 
will read what it says immediately after telling you to add that line:

-----
Be sure to replace client with a name identifying the connecting computer and 
12.34.56.78 with your local IP address. The comment # Home IP isn?t required, 
but comments can be used to help identify clients.
-----

Therefore you must CHANGE 12.34.56.78 to be the real IP address of YOUR 
computer (and no, we cannot tell you what that is - it's YOUR computer, not 
ours).

> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> http_access allow homepc

That line looks fine.  Well done.

> i just edit only like this. is anything out that i should do. what about
> make a password for this.

Keep things simple to start with.  Test them.  When they work, start on the 
complicated stuff.

> and in the linode website tutorial, what about anonymizing traffic?

As I said before, don't worry about step three until you have steps 1 and 2 
correctly working.


So, what you need to do now is:

1. Remove the # from the "acl homepc" line

2. Change the IP address in the "acl homepc" line to be that of your client 
computer (the one your browser is running on).

3. Restart the squid service, look out for any reported errors, and correct 
the lines it complains about if it does.

4. Test the system by configuring your browser to use the proxy, trying to 
access a website, and looking at squid.s log file (which is probably in 
/var/log/squid3/access.log on your system).


Antony.

-- 
"Linux is going to be part of the future. It's going to be like Unix was."

 - Peter Moore, Asia-Pacific general manager, Microsoft

                                                   Please reply to the list;
                                                         please *don't* CC me.


From fastestsuperman at gmail.com  Sat Aug 13 08:56:12 2016
From: fastestsuperman at gmail.com (james82)
Date: Sat, 13 Aug 2016 01:56:12 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608131022.21575.Antony.Stone@squid.open.source.it>
References: <201608121406.17631.Antony.Stone@squid.open.source.it>
 <1471008747015-4678867.post@n4.nabble.com>
 <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
 <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
Message-ID: <1471078572964-4678896.post@n4.nabble.com>

is i have to do anything out like iptables? i have start squid with service
squid start, but how to gonna use it? 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678896.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Sat Aug 13 09:24:02 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 11:24:02 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471078572964-4678896.post@n4.nabble.com>
References: <201608121406.17631.Antony.Stone@squid.open.source.it>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
Message-ID: <201608131124.02833.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 10:56:12, james82 wrote:

> is i have to do anything out like iptables?

No.

> i have start squid with service squid start,

Good.  I trust that no errors were reported this time.

> but how to gonna use it?

1. Configure your browser to use the proxy - that means telling your browser 
the IP address of your Squid machine, and to connect on port 3128.

2. Try to access some URL in your browser (preferably one you haven't visited 
before, to avoid any possibility of getting a locally-cached copy).

3. Look at Squid's access log (which is probably at /var/log/squid3/access.log 
on your system) and make sure it has entries for the URL you just visited.


If you run into problems at any stage, please give us as much information as 
you can to tell us what you have done, and what went wrong, so that we know 
what you did and can advise on what to do differently.

Please remember that if you do not tell us what you tried, or how you found 
out there was a problem, we can only guess, and that is unlikely to be 
helpful.


Regards,


Antony.

-- 
The first fifty percent of an engineering project takes ninety percent of the 
time, and the remaining fifty percent takes another ninety percent of the time.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Sat Aug 13 09:31:23 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 11:31:23 +0200
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471072704202-4678894.post@n4.nabble.com>
References: <1471072704202-4678894.post@n4.nabble.com>
Message-ID: <201608131131.23744.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 09:18:24, Omid Kosari wrote:

> Hello,
> 
> Recently 2 different squid boxes grows from ~40% cpu usage to 100% without
> any changes to config/banwidth/number of clients/etc

What are your bandwidth and number of clients?

> The problems forced me to bypass squid until the problem found .
> Right now even 10% of users can make squid 100% .

How many users is 10%, and how many accesses per second/minute are they making 
through Squid?

> Info
> 
> Squid is in tproxy mode with routing
> 
> Ubuntu Linux 16.04 , 4.4.0-34-generic on x86_64

How much RAM do you have, how many CPU cores, what speed CPU?

> Squid Cache: Version 3.5.19 from debian repository
> 
> 
> samples  %        image name               symbol name
> 1532894  42.8190  libc-2.23.so             _IO_strn_overflow
> 1028537  28.7306  libc-2.23.so             _IO_default_xsputn
> 662802   18.5143  libc-2.23.so             vfprintf
> 77019     2.1514  squid                    /usr/sbin/squid
> 28861     0.8062  libc-2.23.so             __memset_sse2
> 26948     0.7528  r8169                    /r8169
> 25320     0.7073  libc-2.23.so             __memcpy_sse2_unaligned
> 21712     0.6065  libc-2.23.so             __GI___mempcpy
> 14918     0.4167  libc-2.23.so             _int_malloc
> 8889      0.2483  nf_conntrack             /nf_conntrack
> 8130      0.2271  libc-2.23.so             __GI_strchr
> 6357      0.1776  libc-2.23.so             _int_free
> 4152      0.1160  libc-2.23.so             re_search_internal
> 4043      0.1129  libc-2.23.so             strlen
> 2754      0.0769  libstdc++.so.6.0.21
> /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
> 2753      0.0769  libc-2.23.so             free
> 2704      0.0755  ip_tables                /ip_tables
> 2560      0.0715  reiserfs                 /reiserfs
> 2332      0.0651  kallsyms                 ___slab_alloc
> 2284      0.0638  libc-2.23.so             malloc_consolidate
> 2204      0.0616  libc-2.23.so             malloc
> 2175      0.0608  kallsyms                 sys_epoll_ctl
> 2035      0.0568  kallsyms                 csum_partial_copy_generic
> 1614      0.0451  libc-2.23.so             calloc
> 1552      0.0434  kallsyms                 _raw_spin_lock
> 1208      0.0337  kallsyms                 memcpy
> 1203      0.0336  kallsyms                 nf_iterate
> 1177      0.0329  kallsyms                 irq_entries_start
> 1165      0.0325  kallsyms                 __fget
> 1072      0.0299  kallsyms                 copy_user_generic_string
> 1037      0.0290  kallsyms                 __alloc_skb
> 1002      0.0280  kallsyms                 tcp_sendmsg
> 945       0.0264  libc-2.23.so             build_upper_buffer
> 875       0.0244  kallsyms                 kmem_cache_free
> 873       0.0244  kallsyms                 tcp_rack_mark_lost
> 868       0.0242  nf_nat_ipv4              /nf_nat_ipv4
> 861       0.0241  kallsyms                 kfree
> 837       0.0234  kallsyms                 __inet_lookup_established
> 834       0.0233  kallsyms                 get_partial_node.isra.61
> 825       0.0230  kallsyms                 __slab_free
> 815       0.0228  kallsyms                 sock_poll
> 810       0.0226  kallsyms                 skb_release_data
> 802       0.0224  nf_conntrack_ipv4        /nf_conntrack_ipv4
> 792       0.0221  kallsyms                 tcp_transmit_skb
> 771       0.0215  kallsyms                 kmem_cache_alloc
> 719       0.0201  kallsyms                 fib_table_lookup
> 704       0.0197  kallsyms                 _raw_spin_lock_irqsave
> 701       0.0196  kallsyms                 tcp_v4_rcv
> 699       0.0195  libm-2.23.so             __ieee754_log_avx
> 686       0.0192  nf_nat                   /nf_nat
> 684       0.0191  kallsyms                 tcp_write_xmit
> 674       0.0188  kallsyms                 __cmpxchg_double_slab.isra.44
> 626       0.0175  kallsyms                 __netif_receive_skb_core
> 621       0.0173  libnettle.so.6.2
> /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
> 608       0.0170  kallsyms                 delay_tsc
> 600       0.0168  kallsyms                 ksize
> 595       0.0166  kallsyms                 tcp_ack
> 592       0.0165  kallsyms                 __local_bh_enable_ip

Regards,


Antony.

-- 
Anyone that's normal doesn't really achieve much.

 - Mark Blair, Australian rocket engineer

                                                   Please reply to the list;
                                                         please *don't* CC me.


From omidkosari at yahoo.com  Sat Aug 13 10:11:38 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 13 Aug 2016 03:11:38 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <201608131131.23744.Antony.Stone@squid.open.source.it>
References: <1471072704202-4678894.post@n4.nabble.com>
 <201608131131.23744.Antony.Stone@squid.open.source.it>
Message-ID: <1471083098789-4678899.post@n4.nabble.com>

The bandwidth was about 120Mbps to each squid box but now even 10Mbps makes
100% cpu usage

With 10% of users
Average HTTP requests per minute since start:	2355.3


16GB of ram and i3-2100 CPU @ 3.10GHz, 4 cores and NO SMP like before .

It seems like an attack to/from our clients to/from internet which makes
squid crazy .

Also the profiling result attached to end of my first post .




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678899.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marcus.kool at urlfilterdb.com  Sat Aug 13 11:02:11 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sat, 13 Aug 2016 08:02:11 -0300
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471072704202-4678894.post@n4.nabble.com>
References: <1471072704202-4678894.post@n4.nabble.com>
Message-ID: <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>

It seems that squid is doing a lot of calls to vfprintf.
The first thing that comes to mind is that you have debugging on.
What is the setting for debug_options ?

Marcus

On 08/13/2016 04:18 AM, Omid Kosari wrote:
> Hello,
>
> Recently 2 different squid boxes grows from ~40% cpu usage to 100% without
> any changes to config/banwidth/number of clients/etc
>
> The problems forced me to bypass squid until the problem found .
> Right now even 10% of users can make squid 100% .
>
> Info
>
> Squid is in tproxy mode with routing
>
> Ubuntu Linux 16.04 , 4.4.0-34-generic on x86_64
> Squid Cache: Version 3.5.19 from debian repository
>
>
> samples  %        image name               symbol name
> 1532894  42.8190  libc-2.23.so             _IO_strn_overflow
> 1028537  28.7306  libc-2.23.so             _IO_default_xsputn
> 662802   18.5143  libc-2.23.so             vfprintf
> 77019     2.1514  squid                    /usr/sbin/squid
> 28861     0.8062  libc-2.23.so             __memset_sse2
> 26948     0.7528  r8169                    /r8169
> 25320     0.7073  libc-2.23.so             __memcpy_sse2_unaligned
> 21712     0.6065  libc-2.23.so             __GI___mempcpy
> 14918     0.4167  libc-2.23.so             _int_malloc
> 8889      0.2483  nf_conntrack             /nf_conntrack
> 8130      0.2271  libc-2.23.so             __GI_strchr
> 6357      0.1776  libc-2.23.so             _int_free
> 4152      0.1160  libc-2.23.so             re_search_internal
> 4043      0.1129  libc-2.23.so             strlen
> 2754      0.0769  libstdc++.so.6.0.21
> /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
> 2753      0.0769  libc-2.23.so             free
> 2704      0.0755  ip_tables                /ip_tables
> 2560      0.0715  reiserfs                 /reiserfs
> 2332      0.0651  kallsyms                 ___slab_alloc
> 2284      0.0638  libc-2.23.so             malloc_consolidate
> 2204      0.0616  libc-2.23.so             malloc
> 2175      0.0608  kallsyms                 sys_epoll_ctl
> 2035      0.0568  kallsyms                 csum_partial_copy_generic
> 1614      0.0451  libc-2.23.so             calloc
> 1552      0.0434  kallsyms                 _raw_spin_lock
> 1208      0.0337  kallsyms                 memcpy
> 1203      0.0336  kallsyms                 nf_iterate
> 1177      0.0329  kallsyms                 irq_entries_start
> 1165      0.0325  kallsyms                 __fget
> 1072      0.0299  kallsyms                 copy_user_generic_string
> 1037      0.0290  kallsyms                 __alloc_skb
> 1002      0.0280  kallsyms                 tcp_sendmsg
> 945       0.0264  libc-2.23.so             build_upper_buffer
> 875       0.0244  kallsyms                 kmem_cache_free
> 873       0.0244  kallsyms                 tcp_rack_mark_lost
> 868       0.0242  nf_nat_ipv4              /nf_nat_ipv4
> 861       0.0241  kallsyms                 kfree
> 837       0.0234  kallsyms                 __inet_lookup_established
> 834       0.0233  kallsyms                 get_partial_node.isra.61
> 825       0.0230  kallsyms                 __slab_free
> 815       0.0228  kallsyms                 sock_poll
> 810       0.0226  kallsyms                 skb_release_data
> 802       0.0224  nf_conntrack_ipv4        /nf_conntrack_ipv4
> 792       0.0221  kallsyms                 tcp_transmit_skb
> 771       0.0215  kallsyms                 kmem_cache_alloc
> 719       0.0201  kallsyms                 fib_table_lookup
> 704       0.0197  kallsyms                 _raw_spin_lock_irqsave
> 701       0.0196  kallsyms                 tcp_v4_rcv
> 699       0.0195  libm-2.23.so             __ieee754_log_avx
> 686       0.0192  nf_nat                   /nf_nat
> 684       0.0191  kallsyms                 tcp_write_xmit
> 674       0.0188  kallsyms                 __cmpxchg_double_slab.isra.44
> 626       0.0175  kallsyms                 __netif_receive_skb_core
> 621       0.0173  libnettle.so.6.2
> /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
> 608       0.0170  kallsyms                 delay_tsc
> 600       0.0168  kallsyms                 ksize
> 595       0.0166  kallsyms                 tcp_ack
> 592       0.0165  kallsyms                 __local_bh_enable_ip
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From omidkosari at yahoo.com  Sat Aug 13 11:40:18 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 13 Aug 2016 04:40:18 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
Message-ID: <1471088418734-4678901.post@n4.nabble.com>

debug_options ALL,1



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678901.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Sat Aug 13 12:09:22 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 14:09:22 +0200
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471088418734-4678901.post@n4.nabble.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471088418734-4678901.post@n4.nabble.com>
Message-ID: <201608131409.22668.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 13:40:18, Omid Kosari wrote:

> debug_options ALL,1

I would not recommend having debugging turned on for a production server.

In the first instance, to check whether this is what is causing your problems, 
turn this option off and see whether your CPU load comes back to normal.


Antony.

-- 
The Magic Words are Squeamish Ossifrage.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From fastestsuperman at gmail.com  Sat Aug 13 12:33:58 2016
From: fastestsuperman at gmail.com (james82)
Date: Sat, 13 Aug 2016 05:33:58 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608131124.02833.Antony.Stone@squid.open.source.it>
References: <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
 <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
Message-ID: <1471091638369-4678903.post@n4.nabble.com>

where is the line that for use port in squid.conf? where is port 3128 come
from? Is ip-address that i will configure in browser is ip in : acl homepc
src 12.34.56.78?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678903.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Sat Aug 13 12:43:22 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 13 Aug 2016 05:43:22 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <201608131409.22668.Antony.Stone@squid.open.source.it>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471088418734-4678901.post@n4.nabble.com>
 <201608131409.22668.Antony.Stone@squid.open.source.it>
Message-ID: <1471092202103-4678904.post@n4.nabble.com>

Turned off , still high cpu usage .



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678904.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Aug 13 12:56:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 13 Aug 2016 18:56:32 +0600
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471091638369-4678903.post@n4.nabble.com>
References: <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
 <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
 <1471091638369-4678903.post@n4.nabble.com>
Message-ID: <44fb3a57-259a-3a46-b060-18fe8e9fc4d6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
# NETWORK OPTIONS
#
-----------------------------------------------------------------------------

#  TAG: http_port
#    Usage:    port [mode] [options]
#        hostname:port [mode] [options]
#        1.2.3.4:port [mode] [options]
#
#    The socket addresses where Squid will listen for HTTP client
#    requests.  You may specify multiple socket addresses.
#    There are three forms: port alone, hostname with port, and
#    IP address with port.  If you specify a hostname or IP
#    address, Squid binds the socket to that specific
#    address. Most likely, you do not need to bind to a specific
#    address, so you can use the port number alone.
#
#    If you are running Squid in accelerator mode, you
#    probably want to listen on port 80 also, or instead.
#
#    The -a command line option may be used to specify additional
#    port(s) where Squid listens for proxy request. Such ports will
#    be plain proxy ports with no options.
#
#    You may specify multiple socket addresses on multiple lines.

Finally, read squid.conf.documented


13.08.2016 18:33, james82 ?????:
> where is the line that for use port in squid.conf? where is port 3128 come
> from? Is ip-address that i will configure in browser is ip in : acl homepc
> src 12.34.56.78?
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678903.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXrxj/AAoJENNXIZxhPexG7FoH/1gMrCV6nEHBgSnYOURWqKBS
nkQtHRd5+zPVqh9MsZVj1Nimq0B0xCr/Oyzoh9pLgNzEG97f5kBuupdw20ejSJLx
RpSvs+0sCUTq98M4NHJqyFArcLrxL8IiKBphfssSpCF9Ne4YfzIlh27+yVQawMQh
/MiiE42jYo5lo3naSgxs6/zCG5GXinCILIXsCbVjy2lvZfOTAkRTx9YYbME11X+b
IGBCD8JCsHcdHyk0A2HIRdXOMOO/UAEPP/KMfop2OJErvSSeKUOlfWkBpXjVHuVM
wFPAFsdFRi+ULgBPPorg9RHvupIZK2oKjnc7ExIfV5MZz98vVeLl0kVqkqF4HNI=
=fUQ3
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160813/26993dd2/attachment.key>

From fastestsuperman at gmail.com  Sat Aug 13 13:36:39 2016
From: fastestsuperman at gmail.com (james82)
Date: Sat, 13 Aug 2016 06:36:39 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <44fb3a57-259a-3a46-b060-18fe8e9fc4d6@gmail.com>
References: <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
 <1471091638369-4678903.post@n4.nabble.com>
 <44fb3a57-259a-3a46-b060-18fe8e9fc4d6@gmail.com>
Message-ID: <1471095399554-4678906.post@n4.nabble.com>

Is I edit this right:
# Squid normally listens to port 3128
http_port 3128 80 443 

#  TAG: https_port
# Note: This option is only available if Squid is rebuilt with the
#       --with-openssl
#
#	Usage:  [ip:]port cert=certificate.pem [key=key.pem] [mode] [options...]
#
#	The socket address where Squid will listen for client requests made
#	over TLS or SSL connections. Commonly referred to as HTTPS.
#
#	This is most useful for situations where you are running squid in
#	accelerator mode and you want to do the SSL work at the accelerator level.
#
#	You may specify multiple socket addresses on multiple lines,
#	each with their own SSL certificate and/or options.

when I configure IP and port 3128 in browser for proxy network, it say
connecting but it like actually not connect, the load circle not blue, may
be it not work. Do you know this problem?
#



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678906.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Aug 13 13:39:36 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 13 Aug 2016 19:39:36 +0600
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471095399554-4678906.post@n4.nabble.com>
References: <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
 <1471091638369-4678903.post@n4.nabble.com>
 <44fb3a57-259a-3a46-b060-18fe8e9fc4d6@gmail.com>
 <1471095399554-4678906.post@n4.nabble.com>
Message-ID: <9d01ee82-1c23-2737-6197-efefa080b024@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
For forwarding HTTP-proxy it is enough

http_port 3128

13.08.2016 19:36, james82 ?????:
> Is I edit this right:
> # Squid normally listens to port 3128
> http_port 3128 80 443
>
> #  TAG: https_port
> # Note: This option is only available if Squid is rebuilt with the
> #       --with-openssl
> #
> #    Usage:  [ip:]port cert=certificate.pem [key=key.pem] [mode]
[options...]
> #
> #    The socket address where Squid will listen for client requests made
> #    over TLS or SSL connections. Commonly referred to as HTTPS.
> #
> #    This is most useful for situations where you are running squid in
> #    accelerator mode and you want to do the SSL work at the
accelerator level.
> #
> #    You may specify multiple socket addresses on multiple lines,
> #    each with their own SSL certificate and/or options.
>
> when I configure IP and port 3128 in browser for proxy network, it say
> connecting but it like actually not connect, the load circle not blue, may
> be it not work. Do you know this problem?
No. My DNA is ok and I'm able to think and read fine manuals.
>
> #
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678906.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXryMVAAoJENNXIZxhPexGDnIIAJhCn6HFWFo9XdG972pd5a2b
+yrhyzSPavKFm5SlUwsYWZONkPFn5xRqIR6XfusO5+PAJ1vdDLMBu/sL4RkvbSEy
QI5YSECjkCa9cD2+O2qQlnKe5IGJe5g2inBp2kjPj0iqteJTUKe46L6WaCvf7PkU
oe0u/M0ue7H+8mQ3fJ//nThZ9H98EI9TzG1O3oKyOigQJlSQa64rGxNS65QBcpZ+
mx3xl0vLbP5XfP9Z1Z7MTnq8IrDCzF78ceJz734fsWKw/alcH3UHQd523DJgARBH
mcb/4vkIkPXeYmxeJEpGIjOwR0e+QM0DEaAS7jkzHFFMexHVWcduQ4jFmmbMjhc=
=G2Gh
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160813/5ef295d6/attachment.key>

From Antony.Stone at squid.open.source.it  Sat Aug 13 13:49:10 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 15:49:10 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471091638369-4678903.post@n4.nabble.com>
References: <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
 <1471091638369-4678903.post@n4.nabble.com>
Message-ID: <201608131549.10373.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 14:33:58, james82 wrote:

> where is the line that for use port in squid.conf?

The following two lines exit in your squid.conf:

# Squid normally listens to port 3128
http_port 3128

> where is port 3128 come from?

That is the standard port number which squid uses for client (ie: browser) 
connections.

> Is ip-address that i will configure in browser is ip in : acl homepc
> src 12.34.56.78?

No.

Firstly, you must tell the browser to connect to the IP address of your squid 
proxy.

You can probably find out what this is by typing "/sbin/ifconfig" at a shell 
prompt on your squid server.


Secondly, you must tell the squid proxy to allow connections from the IP 
address of your client machine (ie: the one the browser is running on).


I have told you at least twice already that 12.34.56.78 is an EXAMPLE - it 
WILL NOT WORK until you change it to the actual IP address of YOUR client 
machine.

Nobody here can tell you what the IP address of YOUR squid proxy and YOUR 
client machine are, because we did not set up your network.  You need to know 
how your own network is organised before you can get something like squid 
working.

We do not even know what sort of machine you are using for your client (is it 
Linux? Mac OS? Windows? Android?) so we cannot even give you clues about 
finding out this information about your own network if you do not yet know.


Antony.

-- 
Perfection in design is achieved not when there is nothing left to add, but 
rather when there is nothing left to take away.

 - Antoine de Saint-Exupery

                                                   Please reply to the list;
                                                         please *don't* CC me.


From fastestsuperman at gmail.com  Sat Aug 13 14:29:55 2016
From: fastestsuperman at gmail.com (james82)
Date: Sat, 13 Aug 2016 07:29:55 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608131124.02833.Antony.Stone@squid.open.source.it>
References: <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
 <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
Message-ID: <1471098595906-4678909.post@n4.nabble.com>

what about i want to add more port, not only 3128? how to do this?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678909.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Aug 13 14:34:02 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 13 Aug 2016 20:34:02 +0600
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471098595906-4678909.post@n4.nabble.com>
References: <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <1471011926463-4678875.post@n4.nabble.com>
 <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
 <1471098595906-4678909.post@n4.nabble.com>
Message-ID: <36a7ea9b-43d1-a3dc-9ff0-49775e4cc346@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
#    You may specify multiple socket addresses on multiple lines,
#    each with their own SSL certificate and/or options.

Man, really, read squid.conf.documented! All you questions are answered
there!


13.08.2016 20:29, james82 ?????:
> what about i want to add more port, not only 3128? how to do this?
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678909.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXry/aAAoJENNXIZxhPexGDGoH/3qJNMxKIKgN48ilIeYTDH0v
Ym8nhpWhsEYkoiRyZuAJI/IUKrSalOnQOsR3zr0aH1z2idqPomno1Y6qmmU++2aM
ImXqgc1Ovo6nAGD9kgcfsShOzYvaRCw0r9LZ7dmI9Oj+9mjMGrzjm8LwIdHxsKF1
FJ7W7hd3+U5uNXglOOGqb3vMrdfrXQfFIcfHwiXlMjoYGPxgivFUXc4J6UpR6m48
Ozh69lsI5dyZmMjtpRlPi2fbp+TLBf7M/z66Rhw5o2DYpQT9lSWqUimhEIyBwedP
WdqqkZz6ka7I+0GkrUuSn3Py5Ts1MBp/R/9ygWyVdDHe7DSakpH7/fMAD1N9u6g=
=OFXU
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160813/8eee059d/attachment.key>

From Antony.Stone at squid.open.source.it  Sat Aug 13 14:34:24 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 16:34:24 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471098595906-4678909.post@n4.nabble.com>
References: <b96b4b26-1a05-a6b5-05ed-a2409e2b0383@gmail.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
 <1471098595906-4678909.post@n4.nabble.com>
Message-ID: <201608131634.24581.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 16:29:55, james82 wrote:

> what about i want to add more port, not only 3128? how to do this?

Why do you think you need to do that?

Antony.

-- 
This email was created using 100% recycled electrons.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From fastestsuperman at gmail.com  Sat Aug 13 14:41:14 2016
From: fastestsuperman at gmail.com (james82)
Date: Sat, 13 Aug 2016 07:41:14 -0700 (PDT)
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <201608131634.24581.Antony.Stone@squid.open.source.it>
References: <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
 <1471098595906-4678909.post@n4.nabble.com>
 <201608131634.24581.Antony.Stone@squid.open.source.it>
Message-ID: <1471099274103-4678912.post@n4.nabble.com>

like port 80, 443? how to add this to http_port? i try configure my ip
address and port 3128 in browser, but  seem like not work? say
"connecting..." but seem like never connect. how to fix this?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678912.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Aug 13 14:46:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 13 Aug 2016 20:46:15 +0600
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471099274103-4678912.post@n4.nabble.com>
References: <1471012345768-4678878.post@n4.nabble.com>
 <201608121641.52803.Antony.Stone@squid.open.source.it>
 <1471014883949-4678882.post@n4.nabble.com>
 <201608121732.50042.Antony.Stone@squid.open.source.it>
 <1471070235127-4678893.post@n4.nabble.com>
 <201608131022.21575.Antony.Stone@squid.open.source.it>
 <1471078572964-4678896.post@n4.nabble.com>
 <201608131124.02833.Antony.Stone@squid.open.source.it>
 <1471098595906-4678909.post@n4.nabble.com>
 <201608131634.24581.Antony.Stone@squid.open.source.it>
 <1471099274103-4678912.post@n4.nabble.com>
Message-ID: <a0c87696-cf4b-4a2b-ddbc-8fd9a366b3ec@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
This not helps you.

Once more. Again and again.

1. Specify you task. What do you want to achieve with squid. Exactly. Do
your understand this phrase? You task.

2. Read fine squid manuals. Including squid.conf.documented. Did you
understand, which file I means?

3. Write you own squid.conf based on pos.1 and pos.2.

4. If you still not understand nothing, go here and ask your questions.
Without screenshots. Only log files.


13.08.2016 20:41, james82 ?????:
> like port 80, 443? how to add this to http_port? i try configure my ip
> address and port 3128 in browser, but  seem like not work? say
> "connecting..." but seem like never connect. how to fix this?
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/How-can-I-complete-this-tutorial-tp4678837p4678912.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXrzK2AAoJENNXIZxhPexGiQUH+wZoXatc2q0ZpzsT0JBrynVR
+h1ZDhKOQsnVWASgjinUqE3wEr+4ZCI4JJrNr18T/OsJ1GNZI+tEsAbbNvLYeUvv
drX7ci+Of/yNDICwIVQ4njFaI4FvNe+aRdFl02KyocTk9g4x/gJCeRt+a3VPs651
TEgeu/gwqHkNHPvTAIRxtCdPlIXjv696Usgab5YWWs6idwzSVwDJkXZqU+4HL1SE
s575dFSU4tlOxE8E1c15Y3Xc5QOsfdnUmhlSimxknyoq5vVbGmVRhxAvCjzElUhw
xBUGOp4TjkR3GRBA/9Ko4ANgxSjkK8iuiJ8ylN4/OcNGSG7phMzibGLJz3HqgFk=
=FdwC
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160813/ed3de8f5/attachment.key>

From Antony.Stone at squid.open.source.it  Sat Aug 13 14:46:50 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 16:46:50 +0200
Subject: [squid-users] How can I complete this tutorial?
In-Reply-To: <1471099274103-4678912.post@n4.nabble.com>
References: <1471012345768-4678878.post@n4.nabble.com>
 <201608131634.24581.Antony.Stone@squid.open.source.it>
 <1471099274103-4678912.post@n4.nabble.com>
Message-ID: <201608131646.50252.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 16:41:14, james82 wrote:

> like port 80, 443? how to add this to http_port? i try configure my ip
> address and port 3128 in browser, but  seem like not work? say
> "connecting..." but seem like never connect. how to fix this?

Firstly tell us what IP address you have changed 12.34.56.78 in your 
squid.conf file to.

If you have not changed 12.34.56.78 and that address is still in your 
squid.conf, then go back and read my earlier emails to you from today, and 
understand that I have told you this MUST be changed for squid to work 
properly.


Secondly, tell us what proxy IP address you told your browser to connect to 
(we know you've configured it to connect to port 3128, but on what IP 
address?).


Thirdly tell us what URL you tried to access in your browser, and show us what 
appears in /var/log/squid3/access.log when you tried to do this.


Antony.

-- 
"I find the whole business of religion profoundly interesting.  But it does 
mystify me that otherwise intelligent people take it seriously."

 - Douglas Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From fastestsuperman at gmail.com  Sat Aug 13 16:54:14 2016
From: fastestsuperman at gmail.com (james82)
Date: Sat, 13 Aug 2016 09:54:14 -0700 (PDT)
Subject: [squid-users] Is I can change my public ip-address by use squid
	proxy?
Message-ID: <1471107254838-4678915.post@n4.nabble.com>

I want change my public ip-address to access some website by use squid proxy.
Is I actually can do that? How to do that?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Is-I-can-change-my-public-ip-address-by-use-squid-proxy-tp4678915.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Aug 13 16:56:38 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 13 Aug 2016 22:56:38 +0600
Subject: [squid-users] Is I can change my public ip-address by use squid
 proxy?
In-Reply-To: <1471107254838-4678915.post@n4.nabble.com>
References: <1471107254838-4678915.post@n4.nabble.com>
Message-ID: <95c9d6b3-bd22-9577-c43a-ab5f55d249b5@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
https://torproject.org

Not by squid.


13.08.2016 22:54, james82 ?????:
> I want change my public ip-address to access some website by use squid proxy.
> Is I actually can do that? How to do that?
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Is-I-can-change-my-public-ip-address-by-use-squid-proxy-tp4678915.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXr1FGAAoJENNXIZxhPexGEv0IAM0BOJlnZNEdJwYhuW577WTo
dzdJNx9IISZXuRwbF3cufrima999IW1oGc+qcFZzKiqKo+cBXHg+rVFazgsqWlC9
EojeT06LngOCwzxA5svvJf43Zg0AWorqiOTwRqoJQdTFfXBaybU2rxLBlLDgJ4rb
MiuerA+hloVAHJI2GbuZsZQmmJhKB6Q1jJr+baRW4j/nJYH9yiXBNrjkujGqte3b
gn2q52dzp43phFUq9pKOYW4hjtadWDMF0ajsm1oHnzduoclWEoGXoBLmUxDpKO1y
hwia75B251NNdm34Vl5Pr9fmHDzWlUEv/1t6Jz7q7Q4oGLr2xvlGfYXkxBgCYRE=
=pBrn
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160813/6b1aaffd/attachment.key>

From Antony.Stone at squid.open.source.it  Sat Aug 13 18:04:08 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 20:04:08 +0200
Subject: [squid-users] Is I can change my public ip-address by use squid
	proxy?
In-Reply-To: <1471107254838-4678915.post@n4.nabble.com>
References: <1471107254838-4678915.post@n4.nabble.com>
Message-ID: <201608132004.08427.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 18:54:14, james82 wrote:

> I want change my public ip-address to access some website by use squid
> proxy.

I won't even begin to ask why.

> Is I actually can do that?

You cannot.  Your public IP address is assigned to you by your Internet 
Connectivity Provider, and there is no way for you to change it (or, if you 
do, it will still be the current address assigned to you, and therefore 
whoever is running the websites you want to hide yourself from can still find 
out who you are).

> How to do that?

Yuri has just answered this, but I also just wanted to point out:

On Wednesday 20 July 2016 at 17:32:43, Antony Stone wrote:

> On Wednesday 20 July 2016 at 16:06:22, james82 wrote:
> > i'm sorry. using for what is my secret. .i just want to know, can i use
> > squid as a proxy server to connect to internet? normal i search whatmyip
> > and my ip appear on that website. i want to change that ip. is it
> > possible? how to do it.
> 
> It sounds to me like you want something like https://www.torproject.org/
> rather than Squid.
> 
> However, based on the almost-zero information you've given us about what
> you're actually trying to do, it's hard to be sure what to advise.
> 
> 
> Regards,
> 
> 
> Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Sat Aug 13 18:51:40 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 13 Aug 2016 12:51:40 -0600
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <201608131409.22668.Antony.Stone@squid.open.source.it>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471088418734-4678901.post@n4.nabble.com>
 <201608131409.22668.Antony.Stone@squid.open.source.it>
Message-ID: <cbd2a761-86b2-aa1f-4ce7-9d565e1e84ca@measurement-factory.com>

On 08/13/2016 06:09 AM, Antony Stone wrote:
> On Saturday 13 August 2016 at 13:40:18, Omid Kosari wrote:
> 
>> debug_options ALL,1
> 
> I would not recommend having debugging turned on for a production server.

"ALL,1" is the default and recommended verbosity level. The word
"debugging" is somewhat misleading in this context.

Alex.



From Antony.Stone at squid.open.source.it  Sat Aug 13 19:02:05 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 13 Aug 2016 21:02:05 +0200
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <cbd2a761-86b2-aa1f-4ce7-9d565e1e84ca@measurement-factory.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <201608131409.22668.Antony.Stone@squid.open.source.it>
 <cbd2a761-86b2-aa1f-4ce7-9d565e1e84ca@measurement-factory.com>
Message-ID: <201608132102.06091.Antony.Stone@squid.open.source.it>

On Saturday 13 August 2016 at 20:51:40, Alex Rousskov wrote:

> On 08/13/2016 06:09 AM, Antony Stone wrote:
> > On Saturday 13 August 2016 at 13:40:18, Omid Kosari wrote:
> >> debug_options ALL,1
> > 
> > I would not recommend having debugging turned on for a production server.
> 
> "ALL,1" is the default and recommended verbosity level. The word
> "debugging" is somewhat misleading in this context.

I apologise for making assumptions about one of the options I am clearly not 
sufficiently familiar with.


Antony.

-- 
You can tell that the day just isn't going right when you find yourself using 
the telephone before the toilet.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From vitoantonio.smaldino at istruzione.it  Sat Aug 13 21:11:55 2016
From: vitoantonio.smaldino at istruzione.it (Vito A. Smaldino)
Date: Sat, 13 Aug 2016 23:11:55 +0200
Subject: [squid-users] Is I can change my public ip-address by use squid
	proxy?
In-Reply-To: <1471107254838-4678915.post@n4.nabble.com>
References: <1471107254838-4678915.post@n4.nabble.com>
Message-ID: <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>

Here
https://itechnology.wordpress.com/2008/05/26/setup-squid-proxy-server-to-use-multiple-outgoing-ip-addresses/
you can find a good example of using multiple WAN IPs (you got more than 1
IP, right?) based on the client subnet. STarting from this tutorial, i
implemented something similar in my school.
If you own a pool of public IPs and you need to play with *few* and *well
defined* destination websites, i'm quite sure that it can be easily adapted.

V

2016-08-13 18:54 GMT+02:00 james82 <fastestsuperman at gmail.com>:

> I want change my public ip-address to access some website by use squid
> proxy.
> Is I actually can do that? How to do that?
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Is-I-can-change-my-public-ip-
> address-by-use-squid-proxy-tp4678915.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> Vito A. Smaldino
>
> <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160813/73db9fa0/attachment.htm>

From yvoinov at gmail.com  Sat Aug 13 21:24:42 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 14 Aug 2016 03:24:42 +0600
Subject: [squid-users] Is I can change my public ip-address by use squid
 proxy?
In-Reply-To: <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
Message-ID: <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
2008?

This is antique tutorial. 8 years in IT is eternity.


14.08.2016 3:11, Vito A. Smaldino ?????:
> Here https://itechnology.wordpress.com/2008/05/26/setup-squid-proxy-server-to-use-multiple-outgoing-ip-addresses/ you can find a good example of using multiple WAN IPs (you got more than 1 IP, right?) based on the client subnet. STarting from this tutorial, i implemented something similar in my school.
> If you own a pool of public IPs and you need to play with *few* and
*well defined* destination websites, i'm quite sure that it can be
easily adapted.
>
> V
>
> 2016-08-13 18:54 GMT+02:00 james82 <fastestsuperman at gmail.com
<mailto:fastestsuperman at gmail.com>>:
>
>     I want change my public ip-address to access some website by use
squid proxy.
>     Is I actually can do that? How to do that?
>
>
>
>     --
>     View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Is-I-can-change-my-public-ip-address-by-use-squid-proxy-tp4678915.html
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Is-I-can-change-my-public-ip-address-by-use-squid-proxy-tp4678915.html>
>     Sent from the Squid - Users mailing list archive at Nabble.com.
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>     --
>     Vito A. Smaldino
>
>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXr5AZAAoJENNXIZxhPexGaEMIAI+8n+H4ks3GENjbTaQMRtDh
wzsoHeYa82zmwcnY2lNEhWLYzt1lSqDiVqWQj0dSbesNmUXCGxUQ9RRgx+U/Usun
lDJLiczemScv+JXeYBWmhqCARAxjfXT5Iy/ErxwP0HVz6rXLZ1WCf+sdGoVxMuW4
XCb3ChkciJxusarguhwCyXLcySZAfYZ9l5SLqwK3ZCXJ343NdrIz4I98dSdhHDLd
b086dod6LmmXbSqA6S+VdE+DCIB3SZ+65pK48QIbQOmFBfIxeI/Z32ubjLwZpZwi
+hvU2MRxfEZorwjHXEijFUwyAAjTFfgmA9WCpAhVYRizl+ZTg7eJ2RnDP1/UhME=
=ADUy
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/a926faf1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/a926faf1/attachment.key>

From yvoinov at gmail.com  Sat Aug 13 21:31:09 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 14 Aug 2016 03:31:09 +0600
Subject: [squid-users] Is I can change my public ip-address by use squid
 proxy?
In-Reply-To: <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
 <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
Message-ID: <b80a905f-1a29-8c59-026e-ea35dfe16050@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I suggests you lost of op point. He is talking about anonimity, not
about rotating outgoing IP's.

14.08.2016 3:24, Yuri Voinov ?????:
>
> 2008?
>
> This is antique tutorial. 8 years in IT is eternity.
>
>
> 14.08.2016 3:11, Vito A. Smaldino ?????:
> > Here
>
https://itechnology.wordpress.com/2008/05/26/setup-squid-proxy-server-to-use-multiple-outgoing-ip-addresses/
>       you can find a good example of using multiple WAN IPs (you got
>       more than 1 IP, right?) based on the client subnet. STarting from
>       this tutorial, i implemented something similar in my school.
>
>       > If you own a pool of public IPs and you need to play with
>       *few* and *well defined* destination websites, i'm quite sure that
>       it can be easily adapted.
>
>
>
>       > V
>
>
>
>       > 2016-08-13 18:54 GMT+02:00 james82
>       <fastestsuperman at gmail.com
>       <mailto:fastestsuperman at gmail.com>>:
>
>
>
>       >     I want change my public ip-address to access some website
>       by use squid proxy.
>
>       >     Is I actually can do that? How to do that?
>
>
>
>
>
>
>
>       >     --
>
>       >     View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Is-I-can-change-my-public-ip-address-by-use-squid-proxy-tp4678915.html
>
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Is-I-can-change-my-public-ip-address-by-use-squid-proxy-tp4678915.html>
>
>       >     Sent from the Squid - Users mailing list archive at
>       Nabble.com.
>
>       >     _______________________________________________
>
>       >     squid-users mailing list
>
>       >     squid-users at lists.squid-cache.org
>       <mailto:squid-users at lists.squid-cache.org>
>
>       >     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>       >     --
>
>       >     Vito A. Smaldino
>
>
>
>       >     <http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXr5GcAAoJENNXIZxhPexGtAgIAJ1TUzSaGex0rKu2glVIuxxG
6l/3Z9u8SJ4x+r/U2evqJKLq2XTtpKi0U+VpfXU+1EMlbo8+m++mlrK76edyx2Eo
EDClqkIXvK+nNgtvRjDPl6rtDblPZ3tNyGPIBtFE7JpUnCwFPi5l3O6J5MHPJ2ge
X9PLG0DSD1rgLB7LyAdwyqXYm0nVtSyFJluWX/YbMYrL4JQTomqjhtUZ1TU4Te2F
AHns/VJBLADCzTpnNM5h9MNbSQefxEk++ml1yu6QOj7r1Ul4dXB5eiIt8sZ1C6DF
1c5rUo+05+fZWIwqTPgkRnatPKSYJULXTI7pSRNsAPYN5Z0UCCIyfB90vlV5Bj8=
=NQ+v
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/70223a6e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/70223a6e/attachment.key>

From vitoantonio.smaldino at istruzione.it  Sat Aug 13 21:40:11 2016
From: vitoantonio.smaldino at istruzione.it (Vito A. Smaldino)
Date: Sat, 13 Aug 2016 23:40:11 +0200
Subject: [squid-users] Is I can change my public ip-address by use squid
	proxy?
In-Reply-To: <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
 <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
Message-ID: <CAHZaXGx6F7LSBu_ccAKN+edvfZbreQQ=SLPSxG0UYRwzZH=urg@mail.gmail.com>

2016-08-13 23:24 GMT+02:00 Yuri Voinov <yvoinov at gmail.com>:

>
> 2008?
>
> This is antique tutorial. 8 years in IT is eternity.
>
>
Yes, usually you're right, but usually good ideas remains good for the
eternity :-)

I adapted it to my network few weeks ago and it works like a charme; if you
known something better, you are welcome, i'm very interested to the matter.

V
<http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160813/82eb07b2/attachment.htm>

From yvoinov at gmail.com  Sat Aug 13 21:44:27 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 14 Aug 2016 03:44:27 +0600
Subject: [squid-users] Is I can change my public ip-address by use squid
 proxy?
In-Reply-To: <CAHZaXGx6F7LSBu_ccAKN+edvfZbreQQ=SLPSxG0UYRwzZH=urg@mail.gmail.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
 <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
 <CAHZaXGx6F7LSBu_ccAKN+edvfZbreQQ=SLPSxG0UYRwzZH=urg@mail.gmail.com>
Message-ID: <0a75ed5e-4b73-1900-1b5d-b3afdbe844c0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I see no point to do this with squid.

10 GBps NIC is invented already. So, bandwith is no problem.

Load balancing task is also better to do with active network equipement,
like Cisco.

I consider it appropriate to use things for non-core functions.

In fact, I just did not hear the problem statement, which could be
required for this functionality.
14.08.2016 3:40, Vito A. Smaldino ?????:
>
>
> 2016-08-13 23:24 GMT+02:00 Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>>:
>
>     
>     2008?
>
>     This is antique tutorial. 8 years in IT is eternity.
>
>
> Yes, usually you're right, but usually good ideas remains good for the
eternity :-)
>
> I adapted it to my network few weeks ago and it works like a charme;
if you known something better, you are welcome, i'm very interested to
the matter.
>
> V
> <http://lists.squid-cache.org/listinfo/squid-users>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXr5S6AAoJENNXIZxhPexG2SwH/2d5TBLDa3ybwViU2FNFVPeG
MJ40fJcc32ME7s7BG1BUGhacfgDpCzlTWRyzlxEnuWmf75Lm5RDyjszkvrSZ2PUb
CFAK65Nph8W/8z4YColV0y6IacEVceLm1EpcvzXB2NoSO3BF8jbI1sZ71BfvqjHy
rRcYI/BRx5HCEVZGBux58FNQ0GtZRk+kgXn2xecuZd/Ef2t6a6hj4jNspb3DpYri
H1WWVby3U7C6+rx6W98enYq2fNsubPoKnsqR8yijZRnlxfRIaexiqy/iSa33F2AZ
hyTjSfAD4PtNAVOTC8cPPPSj9DuIrr8xAuq0ayEy9EOfGGCqh529km7i8IEXs/E=
=YXf/
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/ef2fbab0/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/ef2fbab0/attachment.key>

From yvoinov at gmail.com  Sat Aug 13 22:06:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 14 Aug 2016 04:06:21 +0600
Subject: [squid-users] Is I can change my public ip-address by use squid
 proxy?
In-Reply-To: <CAHZaXGyR8RK9TnQr_ppqzH4uj46w02pqY_fX-1-ySVjVgMGTkw@mail.gmail.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
 <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
 <b80a905f-1a29-8c59-026e-ea35dfe16050@gmail.com>
 <CAHZaXGyR8RK9TnQr_ppqzH4uj46w02pqY_fX-1-ySVjVgMGTkw@mail.gmail.com>
Message-ID: <317ca78a-49c4-7819-c888-191a5f54eaf1@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


14.08.2016 3:59, Vito A. Smaldino ?????:
>
>
> 2016-08-13 23:31 GMT+02:00 Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>>:
>
>
>     -----BEGIN PGP SIGNED MESSAGE-----
>     Hash: SHA256
>     
>     I suggests you lost of op point. He is talking about anonimity,
not about rotating outgoing IP's.
>
>
> I found only 1 mex from james82 (i'm missing something?) and he didn't
wrote about anonimity.
>
> The tutorial doesn't deal with rotating IPs or load balancing (not
only), it deals with routing the http requests through different ISPs
(or IPs) based on the net of the client generating the request. In my
case, the goal is to make sure that administration net and dida net
route using 2 different public IP, using a unique squid proxy.
This task definitely can be solved on border router level. This is
relatively trivial task. But if in the hands of a hammer, the whole
world looks like a nail around, is not it? :)
Note: Cisco on eBay stands as shovel shit. Switched 1843 cost is only
100-160$. It completely solves you and much more tasks, including WCCP,
firewall, etc.etc.
>
> A similar approach could be used for a route based on the destination
website.
Routes must be done by routers. You can quote me. You should never use
the thingsfor non-core functions.
I have met on the Internet, and more wild tutorials. For example, as
used in the NAT routing purposes.
>
> V

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXr5ncAAoJENNXIZxhPexG/RIH/RVlONKjr0Z6YZz6ILui5o9+
HJ3WAMv6udta02Mj73+H8mDMlRMOHvXlor4ExcQ5EA6mScenZ6XJ+3lxTRh5tPY8
cZeHvsH6kjRkSaQcjgTedlcg4R9tXtLgs7HsD+a/Wu+d6EvWlISttEB2zPORnGDj
fLDrQrJRcELgFP0gIMOQYYf6kq37iZ0kv4OE8QdOYH/CMcvTJhiy1CuJXUvfFwSH
eUaRGj3qF4CY2GmJDrScbKpYCnRit2EBDAM4/FO20imcWUrStHpq/ltSlDpj4UrW
zZiDLKMmMqg+ciMUFFQwE5biJF//B0VHFgbFtrOW1DFIN103I2D5axuY+7iCzxs=
=ftJj
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/26132877/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/26132877/attachment.key>

From yvoinov at gmail.com  Sat Aug 13 22:07:46 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 14 Aug 2016 04:07:46 +0600
Subject: [squid-users] Is I can change my public ip-address by use squid
 proxy?
In-Reply-To: <CAHZaXGyR8RK9TnQr_ppqzH4uj46w02pqY_fX-1-ySVjVgMGTkw@mail.gmail.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
 <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
 <b80a905f-1a29-8c59-026e-ea35dfe16050@gmail.com>
 <CAHZaXGyR8RK9TnQr_ppqzH4uj46w02pqY_fX-1-ySVjVgMGTkw@mail.gmail.com>
Message-ID: <d027daf8-237f-0a6b-a82e-4576726cddeb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


14.08.2016 3:59, Vito A. Smaldino ?????:
>
>
> 2016-08-13 23:31 GMT+02:00 Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>>:
>
>
>     -----BEGIN PGP SIGNED MESSAGE-----
>     Hash: SHA256
>     
>     I suggests you lost of op point. He is talking about anonimity,
not about rotating outgoing IP's.
>
>
> I found only 1 mex from james82 (i'm missing something?) and he didn't
wrote about anonimity.
By the way, we do not know what the devil wants op. He gives us a whole
month for a ride, without disclosing what the heck wants to achieve.
>
> The tutorial doesn't deal with rotating IPs or load balancing (not
only), it deals with routing the http requests through different ISPs
(or IPs) based on the net of the client generating the request. In my
case, the goal is to make sure that administration net and dida net
route using 2 different public IP, using a unique squid proxy.
>
> A similar approach could be used for a route based on the destination
website.
>
> V

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXr5oyAAoJENNXIZxhPexGZVEIAMXtNhucRzhdwiDMtRKsQN3c
9CVF//6JDNAtmXcEnUHRlpZw6mFweqMLm1bxkFo9H2EgpbVmqSaMEPMRZDzAmjMS
eSW0KwKkFuOs7inw3fG0QO1IzGCGVfL+1P1T8QPXhHVhVsi9P/1HnDm7aNB3g2ID
k3IdOEiWyxA97r2hNqMDWSJ8N2Kr/897NCf3Qk17Y8IsNjDT+GUmDZ3UmhE8CNSp
BtRYXbPar1dOX3NNT3ePZVkIPP5eJO6eXFLbPAsrQ79yH6FG+4dFcpRrSDvxn/lw
lHRhywIlM17D1vJhBhSCMsHPq7/KSN8pCMLpJDAeSdY23g6VKut9MIRrfwNCUSs=
=4Y5Y
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/a4f3bd19/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/a4f3bd19/attachment.key>

From fastestsuperman at gmail.com  Sun Aug 14 02:32:48 2016
From: fastestsuperman at gmail.com (james82)
Date: Sat, 13 Aug 2016 19:32:48 -0700 (PDT)
Subject: [squid-users] Is I can change my public ip-address by use squid
	proxy?
In-Reply-To: <d027daf8-237f-0a6b-a82e-4576726cddeb@gmail.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
 <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
 <b80a905f-1a29-8c59-026e-ea35dfe16050@gmail.com>
 <d027daf8-237f-0a6b-a82e-4576726cddeb@gmail.com>
Message-ID: <1471141968817-4678927.post@n4.nabble.com>

Dear Athony, in that tutorial multi ip addess, just all only local ip , not
public ip, what is this mean? Can ou explain for me? i want to use squid
proxy to change my public ip addess, like create a proxy ip in my computer.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Is-I-can-change-my-public-ip-address-by-use-squid-proxy-tp4678915p4678927.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Sun Aug 14 08:23:48 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 14 Aug 2016 10:23:48 +0200
Subject: [squid-users] Is I can change my public ip-address by use squid
	proxy?
In-Reply-To: <1471141968817-4678927.post@n4.nabble.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <d027daf8-237f-0a6b-a82e-4576726cddeb@gmail.com>
 <1471141968817-4678927.post@n4.nabble.com>
Message-ID: <201608141023.48933.Antony.Stone@squid.open.source.it>

On Sunday 14 August 2016 at 04:32:48, james82 wrote:

> Dear Athony,

I assume you mean me (my name is Antony)?

> in that tutorial multi ip addess, just all only local ip , not
> public ip, what is this mean?

It means the private IPs which are purely local to your network (and, frankly, 
of no interest or use to anyone else) will be hidden from remote websites, but 
that your public IP address assigned to you by your Internet Connectivity 
Provider, will not be hidden.

> Can ou explain for me?

I doubt it.

> i want to use squid proxy to change my public ip addess,

Squid cannot do that.  You are trying to use the wrong tool for the job.

> like create a proxy ip in my computer.

That statement makes no sense to me.

Yuri and I have already pointed you at a project which we think will do what 
you want: https://www.torproject.org/

Squid cannot hide your public IP address from remote websites.


Antony.

-- 
Archaeologists have found a previously-unknown dinosaur which seems to have 
had a very large vocabulary.  They've named it Thesaurus.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Sun Aug 14 08:41:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 14 Aug 2016 20:41:41 +1200
Subject: [squid-users] Is I can change my public ip-address by use squid
 proxy?
In-Reply-To: <0a75ed5e-4b73-1900-1b5d-b3afdbe844c0@gmail.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
 <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
 <CAHZaXGx6F7LSBu_ccAKN+edvfZbreQQ=SLPSxG0UYRwzZH=urg@mail.gmail.com>
 <0a75ed5e-4b73-1900-1b5d-b3afdbe844c0@gmail.com>
Message-ID: <8b81284b-d3c9-946b-ee37-bfdc5849a15d@treenet.co.nz>

On 14/08/2016 9:44 a.m., Yuri Voinov wrote:
> In fact, I just did not hear the problem statement, which could be
> required for this functionality.

Problem statement is in the first post of this thread:
"I want change my public ip-address to access some website by use squid
proxy."

Nothing to do with routing. Not very clear yet, but better than nothing
at all for several days of email exchanges.

Amos


From vitoantonio.smaldino at istruzione.it  Sun Aug 14 08:46:40 2016
From: vitoantonio.smaldino at istruzione.it (Vito A. Smaldino)
Date: Sun, 14 Aug 2016 10:46:40 +0200
Subject: [squid-users] Is I can change my public ip-address by use squid
	proxy?
In-Reply-To: <1471141968817-4678927.post@n4.nabble.com>
References: <1471107254838-4678915.post@n4.nabble.com>
 <CAHZaXGwLpTQ3ree0V7kqr7kzMnHgLpr3Ui6y7pRxfuQwkiX7Lw@mail.gmail.com>
 <7e73960a-47d5-fe24-b683-7f9f0d8d0117@gmail.com>
 <b80a905f-1a29-8c59-026e-ea35dfe16050@gmail.com>
 <d027daf8-237f-0a6b-a82e-4576726cddeb@gmail.com>
 <1471141968817-4678927.post@n4.nabble.com>
Message-ID: <CAHZaXGx4MKqp3JKWgoPLV_Gryqy1YO9=_zsR1aRGZTcnjGzRKQ@mail.gmail.com>

james82, I think you should explain better what are your needs, what your
goals and what resources you got for this.

V

2016-08-14 4:32 GMT+02:00 james82 <fastestsuperman at gmail.com>:

> Dear Athony, in that tutorial multi ip addess, just all only local ip , not
> public ip, what is this mean? Can ou explain for me? i want to use squid
> proxy to change my public ip addess, like create a proxy ip in my computer.
>
> <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/d403c174/attachment.htm>

From omidkosari at yahoo.com  Sun Aug 14 12:03:44 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sun, 14 Aug 2016 05:03:44 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
Message-ID: <1471176224321-4678931.post@n4.nabble.com>

My investigation shows even 1 random chosen ip address makes squid cpu usage
about 30% . 
I have chosen that ip address based on users with TAG_NONE/400 errors .

I've found that a kind of request makes a loop in squid . Wireshark shows
infinite loop of

X-Squid-Error: ERR_INVALID_REQ 0

and

X-Squid-Error: ERR_INVALID_URL 0

which makes high cpu usage .

Please find the attachements . The last files edited and personal info
removed from it

squid-access-log.JPG
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4678931/squid-access-log.JPG>  
squid-access-log2.JPG
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4678931/squid-access-log2.JPG>  
squid-problem.squid-problem
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4678931/squid-problem.squid-problem>  



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678931.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Sun Aug 14 12:11:56 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 14 Aug 2016 14:11:56 +0200
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471176224321-4678931.post@n4.nabble.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
Message-ID: <201608141411.56671.Antony.Stone@squid.open.source.it>

On Sunday 14 August 2016 at 14:03:44, Omid Kosari wrote:

> I've found that a kind of request makes a loop in squid . Wireshark shows
> infinite loop of
> 
> X-Squid-Error: ERR_INVALID_REQ 0
> 
> and
> 
> X-Squid-Error: ERR_INVALID_URL 0
> 
> which makes high cpu usage.

What is the URL / request which results in this effect?

What application is generating this request?


Antony.

-- 
Douglas was one of those writers who honourably failed to get anywhere with 
'weekending'.  It put a premium on people who could write things that lasted 
thirty seconds, and Douglas was incapable of writing a single sentence that 
lasted less than thirty seconds.

 - Geoffrey Perkins, about Douglas Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From omidkosari at yahoo.com  Sun Aug 14 12:25:38 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sun, 14 Aug 2016 05:25:38 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <201608141411.56671.Antony.Stone@squid.open.source.it>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
Message-ID: <1471177538989-4678933.post@n4.nabble.com>

Still could not find the app or url but the 2 server ip addresses are
149.202.92.139 and 173.236.187.17 .

As i said this is a sample random user . The only thing common between these
kind of users are 

TAG_NONE/400 24728 NONE error:invalid-request

or 

TAG_NONE/400 24728 "Strange binary characters here"

in logs



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678933.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Sun Aug 14 12:35:45 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 14 Aug 2016 14:35:45 +0200
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471177538989-4678933.post@n4.nabble.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
Message-ID: <201608141435.45901.Antony.Stone@squid.open.source.it>

On Sunday 14 August 2016 at 14:25:38, Omid Kosari wrote:

> Still could not find the app or url but the 2 server ip addresses are
> 149.202.92.139 and 173.236.187.17 .

The first does not respond on port 80 for me, and the second simply tells me 
that it doesn't know which Dreamhost website I'm trying to access.

> TAG_NONE/400 24728 "Strange binary characters here"

I would agree with that description.

My guess is that something is sending non-HTTP data over connections to port 
80 on the servers, therefore Squid can't handle it (because it's an HTTP 
proxy).

I think you should be able to identify what the target URL / request being 
made by the client application is, provided you can get at the earliest 
entries in your log files for such a connection.


Regards,


Antony.

-- 
"Black holes are where God divided by zero."

 - Steven Wright

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Sun Aug 14 14:36:04 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 14 Aug 2016 20:36:04 +0600
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <201608141435.45901.Antony.Stone@squid.open.source.it>
References: <1471072704202-4678894.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
Message-ID: <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


14.08.2016 18:35, Antony Stone ?????:
> On Sunday 14 August 2016 at 14:25:38, Omid Kosari wrote:
>
>> Still could not find the app or url but the 2 server ip addresses are
>> 149.202.92.139 and 173.236.187.17 .
>
> The first does not respond on port 80 for me, and the second simply
tells me
> that it doesn't know which Dreamhost website I'm trying to access.
>
>> TAG_NONE/400 24728 "Strange binary characters here"
>
> I would agree with that description.
>
> My guess is that something is sending non-HTTP data over connections
to port
> 80 on the servers, therefore Squid can't handle it (because it's an HTTP
> proxy).
Bittorrent often use HTTP port, also some IM - like ICQ.
>
> I think you should be able to identify what the target URL / request
being
> made by the client application is, provided you can get at the earliest
> entries in your log files for such a connection.
Identify client application and block it ;) Or bypass proxy for it :)
>
>
>
> Regards,
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXsIHUAAoJENNXIZxhPexGx+kH/RiqhZgiP9KudxTcrpaZJOgm
dPC/5zRoQRt09uQnyGRcaY7xXfAdpSzRU+BI6OIaiOnOZwbo0/rWkaPvpe+FUwHo
D4PSVzzfCd9SyVkuPpIbA6B/gYqpqNZR8FuGkxMBN/860t1yfkXlBjP/fEU5daiL
BfarfyGSl8qc5iA73SgvhK8r+jVJd9wKcT/TdFvlrgxXFD/Z1OPAQs1Gztj00mk6
qVRoj60s8yP0thialLln43Z+kw/Z3H/es6ZFw43HXvT4jeCwZxK1LCXnAwHlPRi/
tzUOTEwAnWoOTOMunF7K5wnKvLdUCY8eWp5LhWDBoZI7TvJ/XnR4wlTZ6E53q3s=
=Qyu3
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/d22ef52d/attachment.key>

From squid3 at treenet.co.nz  Sun Aug 14 09:23:08 2016
From: squid3 at treenet.co.nz (Ben Hutchings)
Date: Sun, 14 Aug 2016 12:23:08 +0300
Subject: [squid-users] admirable!
Message-ID: <000081743dd5$890608e6$3c903fd3$@treenet.co.nz>

Hi, 

That stuff I just found on the  web is admirable, you have to take  a look <http://numultixe.miscwonderings.org/e4vvmm>


Kind regards, Ben Hutchings


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160814/0e8d64ac/attachment.htm>

From omidkosari at yahoo.com  Mon Aug 15 08:58:54 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Mon, 15 Aug 2016 01:58:54 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
Message-ID: <1471251534915-4678937.post@n4.nabble.com>

One of server's ip addresses that i've found belongs to cloudflare .
Cloudflare does not accept anything other than HTTP on port 80 . So it seems
an attack to some servers .
Maybe our clients are infected and they are zombies .

Anyone knows some good ways to defend squid . I mean when squid forwards
these requests it becomes crazy .

I manage to create some iptables rules on squid box to only accept http
protocol . But i know it will have at least 2 problems .
1. Performance will be degraded
2. Some sites/apps may have problems

Any suggestion ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678937.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marciobacci at gmail.com  Mon Aug 15 10:19:08 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Mon, 15 Aug 2016 07:19:08 -0300
Subject: [squid-users] Squid Authentication
Message-ID: <CA+0TdyoH9_LVYfCT7_nD569AN2FY-jRJ5wbwmbwXLneizQ-7Dw@mail.gmail.com>

In my network I have Windows and Linux computers.
I tried the NTLM authentication method, but is experiencing many problems.
So I wonder if the authentication method "squid_ldap_auth" is designed for
Windows and Linux stations?

Regards,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160815/8f899565/attachment.htm>

From squid3 at treenet.co.nz  Mon Aug 15 10:28:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 15 Aug 2016 22:28:14 +1200
Subject: [squid-users] Helppppp
In-Reply-To: <86BE18FCA5FC48319D949B8B2AF70309@ltu.fcbc.cu>
References: <86BE18FCA5FC48319D949B8B2AF70309@ltu.fcbc.cu>
Message-ID: <65d9781e-cbe0-f7e6-0081-81fc0462b285@treenet.co.nz>

On 13/08/2016 1:29 a.m., Michel wrote:
> Hello everyone. I have the following problem. The squid server has
> the system time correctly however messages squid out with 5 hours
> ahead. For example, when you do not have access to a restricted
> website through squid that's where you put Generated Thu, 22 Jan 2015
> 18:45:05 GMT and are 1:45 pm Anyone know the solution?

The Internet runs in timezone UTC, and in HTTP that is labeled "GMT" for
historic reasons. There is no AM/PM in UTC 24hr time.

The reason for that is at any given second of the day it will be 1:45 pm
somewhere on the planet. You never can be completely certain what
timezone your clients are coming from. Particularly when they are ones
not allowed to use the proxy or something - those rejected visitors are
the ones most likely *not* to be in your known local/acceptible network.

Amos



From squid3 at treenet.co.nz  Mon Aug 15 10:40:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 15 Aug 2016 22:40:13 +1200
Subject: [squid-users] Squid Authentication
In-Reply-To: <CA+0TdyoH9_LVYfCT7_nD569AN2FY-jRJ5wbwmbwXLneizQ-7Dw@mail.gmail.com>
References: <CA+0TdyoH9_LVYfCT7_nD569AN2FY-jRJ5wbwmbwXLneizQ-7Dw@mail.gmail.com>
Message-ID: <e21e7d2a-b02f-0b7b-ec8d-8ba3f45e3ffa@treenet.co.nz>

On 15/08/2016 10:19 p.m., Marcio Demetrio Bacci wrote:
> In my network I have Windows and Linux computers.
> I tried the NTLM authentication method, but is experiencing many problems.

FYI, Microsoft deprecated NTLM in 2006 and all software produced by them
since has been migrating towards Kerberos-only support. Since that is a
decade ago you can expect a lot of trouble with recent Windows machines
doing NTLM-only auth.

Try Negotiate/Kerberos authentication instead. It does all the things
NTLM claimed to provide, faster and in a more secure way.


> So I wonder if the authentication method "squid_ldap_auth" is designed for
> Windows and Linux stations?
> 

The auth helper is just a way of connecting Squid to the auth backend
system. In your case probably AD, right?

Any of the helpers that run on the Squid machine OS and connect to AD
will "work" as they are designed to - but that says nothing about
whether they do suits your setup needs.

The LDAP helper you mention runs on Linux or BSD and connects to AD
using the LDAP database protocol. That is all. AFAIK, unless things have
changed recently AD itself restricts the LDAP interface to only
servicing Basic authentication credentials or group checks.


PS. if that is the helper installed with your Squid then you need to
upgrade. That has not been the official helper name since Squid-3.1
which is long ago deprecated.

Amos



From ano31415926535 at gmail.com  Mon Aug 15 11:33:22 2016
From: ano31415926535 at gmail.com (John Akhaice)
Date: Mon, 15 Aug 2016 20:33:22 +0900
Subject: [squid-users] Squid automatically deleted the
	Proxy-Authenticate header
In-Reply-To: <CANBbT7AT9-sGZrW1i1m9X3H5EoRztUP-5=t88AUOxGJUYYDKeg@mail.gmail.com>
References: <CANBbT7AT9-sGZrW1i1m9X3H5EoRztUP-5=t88AUOxGJUYYDKeg@mail.gmail.com>
Message-ID: <CANBbT7CAZgobsG=RoM+gb11mrcKeucOe794u_0WBP=C+gnkKHw@mail.gmail.com>

Hi Amos.

Thank you for your reply.

I upgraded to 3.5.20.
However, as you thought, the result is not changed.

I'm using squid for an explicit proxy.

> How did you have it working in 3.1? It should not have worked any
> differently then either.

I'm sorry but I realized that my colleague had applied a patch long time
ago.

The patch he found was located in the following.
  http://bugs.squid-cache.org/show_bug.cgi?id=3025
Maybe, the patch was not committed, I think.

I have to make and apply a same effect patch on squid-3.5.20.
If you could make the patch, that would be great.

Thank you.

John
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160815/5bf02b97/attachment.htm>

From squid3 at treenet.co.nz  Mon Aug 15 12:11:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 Aug 2016 00:11:29 +1200
Subject: [squid-users] Squid automatically deleted the
 Proxy-Authenticate header
In-Reply-To: <CANBbT7CAZgobsG=RoM+gb11mrcKeucOe794u_0WBP=C+gnkKHw@mail.gmail.com>
References: <CANBbT7AT9-sGZrW1i1m9X3H5EoRztUP-5=t88AUOxGJUYYDKeg@mail.gmail.com>
 <CANBbT7CAZgobsG=RoM+gb11mrcKeucOe794u_0WBP=C+gnkKHw@mail.gmail.com>
Message-ID: <e8ef5d9a-8691-bfe9-694b-06efecabcc81@treenet.co.nz>

On 15/08/2016 11:33 p.m., John Akhaice wrote:
> Hi Amos.
> 
> Thank you for your reply.
> 
> I upgraded to 3.5.20.
> However, as you thought, the result is not changed.
> 
> I'm using squid for an explicit proxy.
> 
>> How did you have it working in 3.1? It should not have worked any
>> differently then either.
> 
> I'm sorry but I realized that my colleague had applied a patch long time
> ago.
> 
> The patch he found was located in the following.
>   http://bugs.squid-cache.org/show_bug.cgi?id=3025
> Maybe, the patch was not committed, I think.
> 
> I have to make and apply a same effect patch on squid-3.5.20.
> If you could make the patch, that would be great.

Sure. Not sure how that one slipped through the cracks. It should have
been merged years ago.

Amos



From yvoinov at gmail.com  Mon Aug 15 12:27:35 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 15 Aug 2016 18:27:35 +0600
Subject: [squid-users] 2016/08/15 18:20:53 kid1| WARNING: HTTP: Invalid
 Response: No object data received for
Message-ID: <36338c43-55af-2960-a49c-8b2b06d5471d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hi gents.

Sometimes I'm observing this warning in cache.log:

2016/08/15 18:20:53 kid1| WARNING: HTTP: Invalid Response: No object
data received for
http://cdn.lastpass.com.squidinternal/ws/be91a9c2b5ce789cb72eb0262551eff0fbbcc00f2c44ad01c1e89e3671d20369
AKA
lp-push-server-164.lastpass.com/ws/be91a9c2b5ce789cb72eb0262551eff0fbbcc00f2c44ad01c1e89e3671d20369

Most often for sites with AKA names.

As you can see in entrie above, this is store-ID rewrited URL.

What does it mean and how to suppress this warnings?

WBR, Yuri

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXsbU2AAoJENNXIZxhPexG+XMIAMfEB39gT3GR44SNbfiM6iyk
wpjaYbDV0lWwdEcwOxrYMoJW6HTr2OW/s+F7iNiahGcLoaH814QswMQXBW67P0jC
aisfoZcp7oG+LZ70tbJ43WyThmaM9bVKR44qhaQ29kkt054I+2FXKBJlb4kKCvwH
k7ESaQCmLEzbzFW3fErZ3Vp0wxFKH2oeyGSJPrEBNSxweOa1T9TzV7RJ+akCAQ/T
SfptQE24BSHhvHJsGAXqTvh4fgy08+Zb9daDj8AfdOYWNfOPDjktVrMOmjT14DJQ
NAVr/rQFcqTbSE2y6lovX9l1b4bUSaLudaVBscf3yNPeAYWPeO/pc8pve2NT8t4=
=RoN4
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160815/701c954b/attachment.key>

From yvoinov at gmail.com  Mon Aug 15 12:27:48 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 15 Aug 2016 18:27:48 +0600
Subject: [squid-users] kid1| WARNING: HTTP: Invalid Response: No object data
	received for
Message-ID: <12f19495-8701-bc5a-f2ee-68956405cff4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hi gents.

Sometimes I'm observing this warning in cache.log:

2016/08/15 18:20:53 kid1| WARNING: HTTP: Invalid Response: No object
data received for
http://cdn.lastpass.com.squidinternal/ws/be91a9c2b5ce789cb72eb0262551eff0fbbcc00f2c44ad01c1e89e3671d20369
AKA
lp-push-server-164.lastpass.com/ws/be91a9c2b5ce789cb72eb0262551eff0fbbcc00f2c44ad01c1e89e3671d20369

Most often for sites with AKA names.

As you can see in entrie above, this is store-ID rewrited URL.

What does it mean and how to suppress this warnings?

WBR, Yuri

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXsbVDAAoJENNXIZxhPexGmiwIAKa+S0n3dWrqhfCIiyF9eh2t
pJmxFNJtu1+U9eTMOk2rLNUHgYF7TE32QmbNG+wRLRIwQ7Ce17tYbCgHSL+Dve5C
3Aw26XkEO4UxVmfz5mRA70v14X2t4vGXwMOUn/oH/B2fECTw9/8vUwivetRFR8ZJ
YU2P8SJBY6Dyx4kByk5REZOux5BhOZYGhlshEA9o85HO/OqNad9ooxmYRsgjCWKT
OY65z0Tv5FIoXCqtiqu/qonjm1lhjKIy+xGjC8TboncCaKgPBgzdEx2BT3fS88pm
bYxemup4ddnePeYnxPEpXgtsEKEvQBiXentSGrVpXQ8Vlyyk9H4HpH5fxoA4B7o=
=mxI+
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160815/b4820980/attachment.key>

From yvoinov at gmail.com  Mon Aug 15 12:31:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 15 Aug 2016 18:31:18 +0600
Subject: [squid-users] kid1| WARNING: HTTP: Invalid Response: No object
 data received for
In-Reply-To: <12f19495-8701-bc5a-f2ee-68956405cff4@gmail.com>
References: <12f19495-8701-bc5a-f2ee-68956405cff4@gmail.com>
Message-ID: <fe6d87cb-c82f-22c1-1dbb-1fdda7d5c04a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Maybe I'm not very well put. As I understand it, the AKA is the original
name, which does not work out quite correctly Store ID.

Anyway, what caused this warning?

15.08.2016 18:27, Yuri Voinov ?????:
>
> Hi gents.
>
> Sometimes I'm observing this warning in cache.log:
>
> 2016/08/15 18:20:53 kid1| WARNING: HTTP: Invalid Response: No object
> data received for
>
http://cdn.lastpass.com.squidinternal/ws/be91a9c2b5ce789cb72eb0262551eff0fbbcc00f2c44ad01c1e89e3671d20369
> AKA
>
lp-push-server-164.lastpass.com/ws/be91a9c2b5ce789cb72eb0262551eff0fbbcc00f2c44ad01c1e89e3671d20369
>
> Most often for sites with AKA names.
>
> As you can see in entrie above, this is store-ID rewrited URL.
>
> What does it mean and how to suppress this warnings?
>
> WBR, Yuri
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXsbYWAAoJENNXIZxhPexGbQIIAInylgVH05wUQb4N3dkmsLFj
pCM7Pf4kmxYmn2Q3oZMsnE3thdFPSHJBvROtK41n1lIJEhq3121MWm6A05tkF95F
cEzYV+fS8O6K9xPdqHfYn5uhNX5oLiexGhLRzGo03s8v/y6gN2PrVZ0Rf72myELH
9HddYNhbdqxPDYiaH2GqZRl7XXwdTW0biLbatNXWkxQj6Txzben06DnVGLe4ukm/
G45PCXbJHTh3Bcs6Kx919HIoPDVwYNyM1gf5be7zsZarWFi8wFEMvxqzbo15XXVN
7sxh1JR6HUMkoIGuE8OMcGnqij1j/Wuo5VI9b0BsbJoiSIvldqlAJvf0a8iMvoU=
=Q01a
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160815/4a2abc48/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160815/4a2abc48/attachment.key>

From squid3 at treenet.co.nz  Mon Aug 15 12:46:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 Aug 2016 00:46:44 +1200
Subject: [squid-users] kid1| WARNING: HTTP: Invalid Response: No object
 data received for
In-Reply-To: <fe6d87cb-c82f-22c1-1dbb-1fdda7d5c04a@gmail.com>
References: <12f19495-8701-bc5a-f2ee-68956405cff4@gmail.com>
 <fe6d87cb-c82f-22c1-1dbb-1fdda7d5c04a@gmail.com>
Message-ID: <79ab7d3b-5f01-1886-0996-66c3a2898b43@treenet.co.nz>

On 16/08/2016 12:31 a.m., Yuri Voinov wrote:
> 
> Maybe I'm not very well put. As I understand it, the AKA is the original
> name, which does not work out quite correctly Store ID.
> 
> Anyway, what caused this warning?

That particular mesage means the server responded with no response
object data. Even the HTTTP reply headers (if any were sent) were not
complete.

The AKA means the on-wire URL Squid is requesting from the server (sans
the scheme name).

Amos


From yvoinov at gmail.com  Mon Aug 15 13:46:04 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 15 Aug 2016 19:46:04 +0600
Subject: [squid-users] kid1| WARNING: HTTP: Invalid Response: No object
 data received for
In-Reply-To: <79ab7d3b-5f01-1886-0996-66c3a2898b43@treenet.co.nz>
References: <12f19495-8701-bc5a-f2ee-68956405cff4@gmail.com>
 <fe6d87cb-c82f-22c1-1dbb-1fdda7d5c04a@gmail.com>
 <79ab7d3b-5f01-1886-0996-66c3a2898b43@treenet.co.nz>
Message-ID: <5708651b-ccb5-75db-8ba6-f581b54b8341@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


15.08.2016 18:46, Amos Jeffries ?????:
> On 16/08/2016 12:31 a.m., Yuri Voinov wrote:
>>
>> Maybe I'm not very well put. As I understand it, the AKA is the original
>> name, which does not work out quite correctly Store ID.
>>
>> Anyway, what caused this warning?
>
> That particular mesage means the server responded with no response
> object data. Even the HTTTP reply headers (if any were sent) were not
> complete.
Aha, i.e. this is server and/or internet problem, right?
>
>
> The AKA means the on-wire URL Squid is requesting from the server (sans
> the scheme name).
Yup, understand.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXscecAAoJENNXIZxhPexGmbUH/1ZpbTz9ZXjk8s2YLWXHaPDh
8IaqXNrHxD/Mr5XJoPeaXT7dTMU5mv1suWCJgnIvhhlxWTw5COwnNawwqQOec4SV
7M8WyAbOMQTcmnuQpXcs/IIbE/mmK++XTYTKGSjEpJWgPhhKbheK2Rsy2KLNyxO9
hAGz1mmFnBUu7Sr8qXU4LI+Twc1Z6ifoemLmWC9LVzAJ5BipwffskbsgqUD7nGeo
p0Nr/+vSvAUQUS9Qouzbirpq4Uhu423t4GrCa8tPqHZC0DVn/bxBMs/cCksQHVbZ
FNcKzFLMRpX4quDlbFgPd4QEjfvKe2u7NHHE7D1oKrHbUOGSsFL6MGgtxpNZtLk=
=Vo66
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160815/180f3355/attachment.key>

From kpeng at freenet.de  Tue Aug 16 03:12:37 2016
From: kpeng at freenet.de (kpeng at freenet.de)
Date: Tue, 16 Aug 2016 11:12:37 +0800
Subject: [squid-users] squid for live stream
Message-ID: <430f100b-1c24-5126-7ed0-68edd3eec109@freenet.de>

hello,

is there any guide for squid acceleration of live stream?

thanks.


From squid3 at treenet.co.nz  Tue Aug 16 05:59:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 Aug 2016 17:59:37 +1200
Subject: [squid-users] squid for live stream
In-Reply-To: <430f100b-1c24-5126-7ed0-68edd3eec109@freenet.de>
References: <430f100b-1c24-5126-7ed0-68edd3eec109@freenet.de>
Message-ID: <d4b9995c-6ed1-2793-ece7-d18e5368dd6c@treenet.co.nz>

On 16/08/2016 3:12 p.m., kpeng wrote:
> hello,
> 
> is there any guide for squid acceleration of live stream?
> 

What do you mean by "acceleration" ?

Streaming via HTTP just works, other protocols just don't. Nothing
special to do with Squid in either case.

Amos



From omidkosari at yahoo.com  Tue Aug 16 10:23:02 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 16 Aug 2016 03:23:02 -0700 (PDT)
Subject: [squid-users] Malformed HTTP on tproxy squid
Message-ID: <1471342982214-4678951.post@n4.nabble.com>

According to my other post
http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-td4678894.html


Squid cpu usage becomes 100% when it forwatds some kind of malformed http
traffic .
Even one ip address with less than 5 requests per second can grow squid cpu
usage up to 30% 

We have found that this request belongs to a cheap popular satellite
receiver www.starmax.co . Maybe it has been infected and becomes zombie of a
btnet .

Apart from the client type , my question is 

Shouldn't squid have a mechanism to defend this types of problems ? Isn't
possible for squid to simply ignore malformed http requests ?

Is there any workaround to prevent this problem ?




Squid is in tproxy mode with routing

Ubuntu Linux 16.04 , 4.4.0-34-generic on x86_64
Squid Cache: Version 3.5.19 from debian repository


samples  %        image name               symbol name
1532894  42.8190  libc-2.23.so             _IO_strn_overflow
1028537  28.7306  libc-2.23.so             _IO_default_xsputn
662802   18.5143  libc-2.23.so             vfprintf
77019     2.1514  squid                    /usr/sbin/squid
28861     0.8062  libc-2.23.so             __memset_sse2
26948     0.7528  r8169                    /r8169
25320     0.7073  libc-2.23.so             __memcpy_sse2_unaligned
21712     0.6065  libc-2.23.so             __GI___mempcpy
14918     0.4167  libc-2.23.so             _int_malloc
8889      0.2483  nf_conntrack             /nf_conntrack
8130      0.2271  libc-2.23.so             __GI_strchr
6357      0.1776  libc-2.23.so             _int_free
4152      0.1160  libc-2.23.so             re_search_internal
4043      0.1129  libc-2.23.so             strlen
2754      0.0769  libstdc++.so.6.0.21     
/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
2753      0.0769  libc-2.23.so             free
2704      0.0755  ip_tables                /ip_tables
2560      0.0715  reiserfs                 /reiserfs
2332      0.0651  kallsyms                 ___slab_alloc
2284      0.0638  libc-2.23.so             malloc_consolidate
2204      0.0616  libc-2.23.so             malloc
2175      0.0608  kallsyms                 sys_epoll_ctl
2035      0.0568  kallsyms                 csum_partial_copy_generic
1614      0.0451  libc-2.23.so             calloc
1552      0.0434  kallsyms                 _raw_spin_lock
1208      0.0337  kallsyms                 memcpy
1203      0.0336  kallsyms                 nf_iterate
1177      0.0329  kallsyms                 irq_entries_start
1165      0.0325  kallsyms                 __fget
1072      0.0299  kallsyms                 copy_user_generic_string
1037      0.0290  kallsyms                 __alloc_skb
1002      0.0280  kallsyms                 tcp_sendmsg
945       0.0264  libc-2.23.so             build_upper_buffer
875       0.0244  kallsyms                 kmem_cache_free
873       0.0244  kallsyms                 tcp_rack_mark_lost
868       0.0242  nf_nat_ipv4              /nf_nat_ipv4
861       0.0241  kallsyms                 kfree
837       0.0234  kallsyms                 __inet_lookup_established
834       0.0233  kallsyms                 get_partial_node.isra.61
825       0.0230  kallsyms                 __slab_free
815       0.0228  kallsyms                 sock_poll
810       0.0226  kallsyms                 skb_release_data
802       0.0224  nf_conntrack_ipv4        /nf_conntrack_ipv4
792       0.0221  kallsyms                 tcp_transmit_skb
771       0.0215  kallsyms                 kmem_cache_alloc
719       0.0201  kallsyms                 fib_table_lookup
704       0.0197  kallsyms                 _raw_spin_lock_irqsave
701       0.0196  kallsyms                 tcp_v4_rcv
699       0.0195  libm-2.23.so             __ieee754_log_avx
686       0.0192  nf_nat                   /nf_nat
684       0.0191  kallsyms                 tcp_write_xmit
674       0.0188  kallsyms                 __cmpxchg_double_slab.isra.44
626       0.0175  kallsyms                 __netif_receive_skb_core
621       0.0173  libnettle.so.6.2        
/usr/lib/x86_64-linux-gnu/libnettle.so.6.2
608       0.0170  kallsyms                 delay_tsc
600       0.0168  kallsyms                 ksize
595       0.0166  kallsyms                 tcp_ack
592       0.0165  kallsyms                 __local_bh_enable_i



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Malformed-HTTP-on-tproxy-squid-tp4678951.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Tue Aug 16 10:37:52 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 16 Aug 2016 03:37:52 -0700 (PDT)
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <1471342982214-4678951.post@n4.nabble.com>
References: <1471342982214-4678951.post@n4.nabble.com>
Message-ID: <1471343872149-4678952.post@n4.nabble.com>

Squid access.log and wireshark PCAP attached
access_(1).log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4678952/access_%281%29.log>  
dump2.pcap
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4678952/dump2.pcap>  



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Malformed-HTTP-on-tproxy-squid-tp4678951p4678952.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Tue Aug 16 12:14:52 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 16 Aug 2016 15:14:52 +0300
Subject: [squid-users] Linux Youtube video Rate limiting script
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAAq7gWCEchlAqiSJXck7RegBANlTnCJhprtFudq2LHCBs8EBACQA//8AABAAAACdgvZ67XPwR4X1K+2N+a1gAQAAAAA=@ngtech.co.il>

I don't remember who have asked me and where is the email so I am posting
it, if it's you who asked me about the subject send a private message.

The next are a set of scripts to help and "slow down" youtube ie
.googlevideo.com domains\servers.
https://github.com/elico/squid-yt-log-analyzer

Only use it if googlevideo is an environmental hazard!!

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 62969 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160816/279c3d72/attachment.bin>

From eliezer at ngtech.co.il  Tue Aug 16 13:08:57 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 16 Aug 2016 16:08:57 +0300
Subject: [squid-users] Squid in Air Planes WiFi system,
	how should it be used?
In-Reply-To: <3596f7a2-6340-2259-7a13-a42455aac403@riosoft.com.br>
References: <!&!AAAAAAAAAAAuAAAAAAAAANIlB21wPQZLlj2Y4QUZ/uABAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABGVPTOZa5tQ4+OMqt2IZvXAQAAAAA=@ngtech.co.il>
 <3596f7a2-6340-2259-7a13-a42455aac403@riosoft.com.br>
Message-ID: <007f01d1f7bf$5952fc40$0bf8f4c0$@ngtech.co.il>

Hey Bruno,

Sorry it took me so long to respond.
How high am I? Depends when on the day you catch me.
If I installed couple CentOS and Ubuntu servers I am probably on 1000%++ High.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Bruno de Paula Larini
Sent: Thursday, June 23, 2016 8:17 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid in Air Planes WiFi system, how should it be used?

Em 23/06/2016 10:22, Eliezer Croitoru escreveu:
> Since Internet is starting to flow into the "Flying ships" industry I 
> started to wonder what are the limits?
> In the air the network connections are very low quality despite to the 
> fact that they can transfer lots of data.
> So the OS will probably handle all the lower network issues and will 
> leave to the proxy software all the fun stuff.
> The basic services on a Flying WiFi network would be:
> -	FW + NAT
> -	DNS proxy + local
> -	DHCP
> -	Authorization and Authentication services(Radius, token based\OTP),
> I don't expect any form of AD or LDAP based.
> -	Internet Service Payments portal (maybe can be used as an
> alternative or extension to pre-paid tickets)
> -	VOD
> -	Digital Book Shelf
> -	VOIP services
> -	And probably couple other services which many require
>
> Then I asked myself: What squid can offer for this system? Where squid 
> can be plugged inside this list of services?
> >From where is see it, the proxy can take over the application stack 
> >from the
> client to the server.
> Since the OS will be designed to handle the network level issue(both 
> fabric and protocol) it will simplify for the clients the need to 
> overcome network level issues.
> The clients will need to just be clients using  WiFi(leaving aside the 
> 700KMPH radio\physics layer).
> The flight will be much nicer from the technology perspective of it.
> I do however think that one of the main issues with so many 
> technological "comforts" would be the human to human in-flight relationship.
>
> Two examples to special scenarios I know from the Anime world are:
> -	Accel World
> -	Ghost In The Shell
> Which gives an image of a world which humans are bypassing the real 
> world for the favor of a Virtual world.
> What do you think?
>
> Eliezer
>
> Links:
> -	http://myanimelist.net/anime/11759/Accel_World
> -	http://myanimelist.net/anime/43/Ghost_in_the_Shell
I'm sorry to post unrelated comments on the list but... How high are you? Pun intended.
It is something I'm missing?
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From steve at opendium.com  Tue Aug 16 14:22:15 2016
From: steve at opendium.com (Steve Hill)
Date: Tue, 16 Aug 2016 15:22:15 +0100
Subject: [squid-users] Checking SSL bump status in http_access
Message-ID: <d0b96af9-b14c-54b3-4ffa-d4e072e5b03d@opendium.com>


Is there a way of figuring out if the current request is a bumped 
request when the http_access ACL is being checked?  i.e. can we tell the 
difference between a GET request that is inside a bumped tunnel, and an 
unencrypted GET request?

-- 
  - Steve Hill
    Technical Director
    Opendium Limited     http://www.opendium.com

Sales / enquiries:
    Email:            sales at opendium.com
    Phone:            +44-1792-824568 / sip:sales at opendium.com

Support:
    Email:            support at opendium.com
    Phone:            +44-1792-825748 / sip:support at opendium.com


From rousskov at measurement-factory.com  Tue Aug 16 16:57:32 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 16 Aug 2016 10:57:32 -0600
Subject: [squid-users] kid1| WARNING: HTTP: Invalid Response: No object
 data received for
In-Reply-To: <79ab7d3b-5f01-1886-0996-66c3a2898b43@treenet.co.nz>
References: <12f19495-8701-bc5a-f2ee-68956405cff4@gmail.com>
 <fe6d87cb-c82f-22c1-1dbb-1fdda7d5c04a@gmail.com>
 <79ab7d3b-5f01-1886-0996-66c3a2898b43@treenet.co.nz>
Message-ID: <63fd1a68-d350-ce0a-e73d-30d8f4f9ce35@measurement-factory.com>

On 08/15/2016 06:46 AM, Amos Jeffries wrote:
> On 16/08/2016 12:31 a.m., Yuri Voinov wrote:
>>
>> Maybe I'm not very well put. As I understand it, the AKA is the original
>> name, which does not work out quite correctly Store ID.
>>
>> Anyway, what caused this warning?
> 
> That particular mesage means the server responded with no response
> object data. Even the HTTTP reply headers (if any were sent) were not
> complete.
> 
> The AKA means the on-wire URL Squid is requesting from the server (sans
> the scheme name).

I suspect the letters "AKA" in this context mean "also known as". To
minimize confusion, the letters should not have been capitalized (the
canonical spelling is "a.k.a."), and Squid should not have printed two
identical URLs, but nobody bothered to polish the corresponding code yet.

The URL printed after the letters AKA may or may not be "on the wire"
HTTP request target URI actually sent to the server. There are several
transformations that may be applied to the printed URI before it is sent
to the server. In most cases, the differences do not matter though.

Alex.



From rousskov at measurement-factory.com  Tue Aug 16 17:06:23 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 16 Aug 2016 11:06:23 -0600
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471251534915-4678937.post@n4.nabble.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
Message-ID: <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>

On 08/15/2016 02:58 AM, Omid Kosari wrote:

> Maybe our clients are infected and they are zombies .
> 
> Anyone knows some good ways to defend squid . I mean when squid forwards
> these requests it becomes crazy .

If Squid becomes crazy, it is a Squid bug that you should report and
help fix. Even when Squid deals with zombie clients, it should remain sane.

Alex.



From yvoinov at gmail.com  Tue Aug 16 17:30:16 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 16 Aug 2016 23:30:16 +0600
Subject: [squid-users] kid1| WARNING: HTTP: Invalid Response: No object
 data received for
In-Reply-To: <63fd1a68-d350-ce0a-e73d-30d8f4f9ce35@measurement-factory.com>
References: <12f19495-8701-bc5a-f2ee-68956405cff4@gmail.com>
 <fe6d87cb-c82f-22c1-1dbb-1fdda7d5c04a@gmail.com>
 <79ab7d3b-5f01-1886-0996-66c3a2898b43@treenet.co.nz>
 <63fd1a68-d350-ce0a-e73d-30d8f4f9ce35@measurement-factory.com>
Message-ID: <262138da-e9bb-d77c-5bc0-4e7c7649dbcc@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


16.08.2016 22:57, Alex Rousskov ?????:
> On 08/15/2016 06:46 AM, Amos Jeffries wrote:
>> On 16/08/2016 12:31 a.m., Yuri Voinov wrote:
>>>
>>> Maybe I'm not very well put. As I understand it, the AKA is the original
>>> name, which does not work out quite correctly Store ID.
>>>
>>> Anyway, what caused this warning?
>>
>> That particular mesage means the server responded with no response
>> object data. Even the HTTTP reply headers (if any were sent) were not
>> complete.
>>
>> The AKA means the on-wire URL Squid is requesting from the server (sans
>> the scheme name).
>
> I suspect the letters "AKA" in this context mean "also known as". To
> minimize confusion, the letters should not have been capitalized (the
> canonical spelling is "a.k.a."), and Squid should not have printed two
> identical URLs, but nobody bothered to polish the corresponding code yet.
>
> The URL printed after the letters AKA may or may not be "on the wire"
> HTTP request target URI actually sent to the server. There are several
> transformations that may be applied to the printed URI before it is sent
> to the server. In most cases, the differences do not matter though.
Aha, thank you for explanation, Alex.
By my observation, this warning occurs when network packets accidentally
dropped during transmission. So, may be it occurs due to freshness
content validation?
>
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXs02oAAoJENNXIZxhPexGR/wH+wWKkt1qU+wa6ZoNPiRdufuz
D3lzt2Cu0eOoULlwD0vrbrOQ75Xz0sdzOzVdK30JnFs0e0MSwH7asuGfEObs5Jq4
p0TKjOq9ybbBsvW4JrB3ymLqt0e2VSpirDg6vjwe3oBosFT71Ij+6/fUvipBtoQ3
bSQ7/YAw+eNdrenlOC9WAeTZLd0rg/TfRQVH22pvBLyaU3Ioz/xlNgxBb2fdcQqt
qRo2+K1M/oQ8UZng4vw6JHjmy4K0L6J0PznTLz6sbHLqVrnCYRcOl2Fp6JQxIWMB
EO3E4f0OsDV9PqjwRlC9xJLYzMBRTrMdKvTcb/DtcwcyBfPaUFPj4d7haRr1MPU=
=FBya
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160816/a46fcb0f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160816/a46fcb0f/attachment.key>

From squid3 at treenet.co.nz  Tue Aug 16 23:12:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 Aug 2016 11:12:03 +1200
Subject: [squid-users] Checking SSL bump status in http_access
In-Reply-To: <d0b96af9-b14c-54b3-4ffa-d4e072e5b03d@opendium.com>
References: <d0b96af9-b14c-54b3-4ffa-d4e072e5b03d@opendium.com>
Message-ID: <3cc7a49f-c6cc-0f18-31cd-4b2c3cc6d5d5@treenet.co.nz>

On 17/08/2016 2:22 a.m., Steve Hill wrote:
> 
> Is there a way of figuring out if the current request is a bumped
> request when the http_access ACL is being checked?  i.e. can we tell the
> difference between a GET request that is inside a bumped tunnel, and an
> unencrypted GET request?
> 

In Squid-3 a combo of the myportname and proto ACLs should do that.

In Squid-4 the above, or the connections_encrypted ACL type.

Amos



From squid3 at treenet.co.nz  Tue Aug 16 23:15:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 Aug 2016 11:15:24 +1200
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
Message-ID: <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>

On 17/08/2016 5:06 a.m., Alex Rousskov wrote:
> On 08/15/2016 02:58 AM, Omid Kosari wrote:
> 
>> Maybe our clients are infected and they are zombies .
>>
>> Anyone knows some good ways to defend squid . I mean when squid forwards
>> these requests it becomes crazy .
> 
> If Squid becomes crazy, it is a Squid bug that you should report and
> help fix. Even when Squid deals with zombie clients, it should remain sane.

FYI: Omid is using "crazy" to mean 100% CPU is used under DoS type
conditions. Which is not crazy at all.

Amos



From omidkosari at yahoo.com  Wed Aug 17 05:03:49 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 16 Aug 2016 22:03:49 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
 <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
Message-ID: <1471410229820-4678961.post@n4.nabble.com>

Even one ip address with less than 5 requests per second can grow squid cpu
usage up to 30% . And 10 requests per second made 100% cpu usage . While
there is nothing other than that client goes through squid . The client
bandwidth is less than 10Kbps .

Isn't it crazy also ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678961.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dan at getbusi.com  Wed Aug 17 05:22:32 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Wed, 17 Aug 2016 15:22:32 +1000
Subject: [squid-users] Large memory leak with ssl_peek (now partly
	understood)
In-Reply-To: <c372fb8b-d013-0605-9692-59a954be13cc@opendium.com>
References: <6ebc07c2-c8e7-13f1-8c9f-cd00ab812339@opendium.com>
 <19bf0746-0f96-106a-bb43-72b1f69f434f@measurement-factory.com>
 <CAN8nrKB3KQHsOC-_uaOxS__L-S-WZm_8d0GgOBC_U-_106O=ng@mail.gmail.com>
 <c372fb8b-d013-0605-9692-59a954be13cc@opendium.com>
Message-ID: <CE0D84FD-1E2C-42D5-868A-D3B9EFE98572@getbusi.com>

Hey Steve,

Deployed a 3.5.20 build with both of those patches and have noticed a big improvement in memory consumption of squid processes at a couple of splice-heavy sites.

Thank you, sir!

Dan

> On 12 Aug 2016, at 7:05 PM, Steve Hill <steve at opendium.com> wrote:
> 
> 
>>        This sounds very similar to Squid bug 4508. Factory proposed a fix
>>    for that bug, but the patch is for Squid v4. You may be able to adapt it
>>    to v3. Testing (with any version) is very welcomed, of course:
> 
> Thanks for that - I'll look into adapting and testing it.
> 
> (been chasing this bug off and on for months - hadn't spotted that there was a bug report open for it :)
> 
> 
> -- 
> - Steve Hill
>   Technical Director
>   Opendium Limited     http://www.opendium.com
> 
> Sales / enquiries:
>   Email:            sales at opendium.com
>   Phone:            +44-1792-824568 / sip:sales at opendium.com
> 
> Support:
>   Email:            support at opendium.com
>   Phone:            +44-1792-825748 / sip:support at opendium.com
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Aug 17 09:01:40 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 17 Aug 2016 12:01:40 +0300
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471410229820-4678961.post@n4.nabble.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
 <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
 <1471410229820-4678961.post@n4.nabble.com>
Message-ID: <013f01d1f865$f83010e0$e89032a0$@ngtech.co.il>

Hey Omid,

Just to understand, are you intercepting traffic?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Wednesday, August 17, 2016 8:04 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid cpu usage 100% from few days ago !!

Even one ip address with less than 5 requests per second can grow squid cpu usage up to 30% . And 10 requests per second made 100% cpu usage . While there is nothing other than that client goes through squid . The client bandwidth is less than 10Kbps .

Isn't it crazy also ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678961.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From Antony.Stone at squid.open.source.it  Wed Aug 17 09:03:39 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 17 Aug 2016 11:03:39 +0200
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <013f01d1f865$f83010e0$e89032a0$@ngtech.co.il>
References: <1471072704202-4678894.post@n4.nabble.com>
 <1471410229820-4678961.post@n4.nabble.com>
 <013f01d1f865$f83010e0$e89032a0$@ngtech.co.il>
Message-ID: <201608171103.39448.Antony.Stone@squid.open.source.it>

On Wednesday 17 August 2016 at 11:01:40, Eliezer Croitoru wrote:

> Hey Omid,
> 
> Just to understand, are you intercepting traffic?

From the original report: "Squid is in tproxy mode with routing"


Antony.

> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Omid Kosari Sent: Wednesday, August 17, 2016 8:04 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid cpu usage 100% from few days ago !!
> 
> Even one ip address with less than 5 requests per second can grow squid cpu
> usage up to 30% . And 10 requests per second made 100% cpu usage . While
> there is nothing other than that client goes through squid . The client
> bandwidth is less than 10Kbps .
> 
> Isn't it crazy also ?

-- 
Salad is what food eats.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From eliezer at ngtech.co.il  Wed Aug 17 09:06:47 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 17 Aug 2016 12:06:47 +0300
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <1471342982214-4678951.post@n4.nabble.com>
References: <1471342982214-4678951.post@n4.nabble.com>
Message-ID: <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>

Hey Omid,

If you know what domain or ip address causes and issue the first thing I can think about is bypassing the malicious traffic to allow other clients\users to reach the Internet.
Depends on the client and the destination you can choose the right approach.
And since squid is also being used as a http ACL enforcement tool malformed requests basically should be dropped and not bypassed automatically.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Tuesday, August 16, 2016 1:23 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Malformed HTTP on tproxy squid

According to my other post
http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-td4678894.html


Squid cpu usage becomes 100% when it forwatds some kind of malformed http traffic .
Even one ip address with less than 5 requests per second can grow squid cpu usage up to 30% 

We have found that this request belongs to a cheap popular satellite receiver www.starmax.co . Maybe it has been infected and becomes zombie of a btnet .

Apart from the client type , my question is 

Shouldn't squid have a mechanism to defend this types of problems ? Isn't possible for squid to simply ignore malformed http requests ?

Is there any workaround to prevent this problem ?




Squid is in tproxy mode with routing

Ubuntu Linux 16.04 , 4.4.0-34-generic on x86_64 Squid Cache: Version 3.5.19 from debian repository


samples  %        image name               symbol name
1532894  42.8190  libc-2.23.so             _IO_strn_overflow
1028537  28.7306  libc-2.23.so             _IO_default_xsputn
662802   18.5143  libc-2.23.so             vfprintf
77019     2.1514  squid                    /usr/sbin/squid
28861     0.8062  libc-2.23.so             __memset_sse2
26948     0.7528  r8169                    /r8169
25320     0.7073  libc-2.23.so             __memcpy_sse2_unaligned
21712     0.6065  libc-2.23.so             __GI___mempcpy
14918     0.4167  libc-2.23.so             _int_malloc
8889      0.2483  nf_conntrack             /nf_conntrack
8130      0.2271  libc-2.23.so             __GI_strchr
6357      0.1776  libc-2.23.so             _int_free
4152      0.1160  libc-2.23.so             re_search_internal
4043      0.1129  libc-2.23.so             strlen
2754      0.0769  libstdc++.so.6.0.21     
/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
2753      0.0769  libc-2.23.so             free
2704      0.0755  ip_tables                /ip_tables
2560      0.0715  reiserfs                 /reiserfs
2332      0.0651  kallsyms                 ___slab_alloc
2284      0.0638  libc-2.23.so             malloc_consolidate
2204      0.0616  libc-2.23.so             malloc
2175      0.0608  kallsyms                 sys_epoll_ctl
2035      0.0568  kallsyms                 csum_partial_copy_generic
1614      0.0451  libc-2.23.so             calloc
1552      0.0434  kallsyms                 _raw_spin_lock
1208      0.0337  kallsyms                 memcpy
1203      0.0336  kallsyms                 nf_iterate
1177      0.0329  kallsyms                 irq_entries_start
1165      0.0325  kallsyms                 __fget
1072      0.0299  kallsyms                 copy_user_generic_string
1037      0.0290  kallsyms                 __alloc_skb
1002      0.0280  kallsyms                 tcp_sendmsg
945       0.0264  libc-2.23.so             build_upper_buffer
875       0.0244  kallsyms                 kmem_cache_free
873       0.0244  kallsyms                 tcp_rack_mark_lost
868       0.0242  nf_nat_ipv4              /nf_nat_ipv4
861       0.0241  kallsyms                 kfree
837       0.0234  kallsyms                 __inet_lookup_established
834       0.0233  kallsyms                 get_partial_node.isra.61
825       0.0230  kallsyms                 __slab_free
815       0.0228  kallsyms                 sock_poll
810       0.0226  kallsyms                 skb_release_data
802       0.0224  nf_conntrack_ipv4        /nf_conntrack_ipv4
792       0.0221  kallsyms                 tcp_transmit_skb
771       0.0215  kallsyms                 kmem_cache_alloc
719       0.0201  kallsyms                 fib_table_lookup
704       0.0197  kallsyms                 _raw_spin_lock_irqsave
701       0.0196  kallsyms                 tcp_v4_rcv
699       0.0195  libm-2.23.so             __ieee754_log_avx
686       0.0192  nf_nat                   /nf_nat
684       0.0191  kallsyms                 tcp_write_xmit
674       0.0188  kallsyms                 __cmpxchg_double_slab.isra.44
626       0.0175  kallsyms                 __netif_receive_skb_core
621       0.0173  libnettle.so.6.2        
/usr/lib/x86_64-linux-gnu/libnettle.so.6.2
608       0.0170  kallsyms                 delay_tsc
600       0.0168  kallsyms                 ksize
595       0.0166  kallsyms                 tcp_ack
592       0.0165  kallsyms                 __local_bh_enable_i



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Malformed-HTTP-on-tproxy-squid-tp4678951.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From omidkosari at yahoo.com  Wed Aug 17 09:26:29 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 17 Aug 2016 02:26:29 -0700 (PDT)
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>
References: <1471342982214-4678951.post@n4.nabble.com>
 <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>
Message-ID: <1471425989455-4678966.post@n4.nabble.com>

Hi Eliezer,


Eliezer Croitoru-2 wrote
> If you know what domain or ip address causes and issue the first thing I
> can think about is bypassing the malicious traffic to allow other
> clients\users to reach the Internet.

Source ip may be 70% of our customers because it is a popular device so it
is not an option . Destination ip or domains are too much . 

Unfortunately because the requests are not normal http , so squid log does
not have the dst url/domain/ip so it is hard job to find them .
1- First i should keep looking the squid access.log to find client which has
such request . 
2-Then try to sniff that client from router. 
3-Separate normal requests from malformed . 
4-Find the destination from malformed requests.
5-Put that ip in router acl to exclude from tproxy routing to squid .

Nobody knows how many times this loop should be repeated because nobody
knows count of destinations .



Eliezer Croitoru-2 wrote
> And since squid is also being used as a http ACL enforcement tool
> malformed requests basically should be dropped and not bypassed
> automatically.

So then squid should be able to simply drop them.
Even it would be fine to have some patterns in iptables or something like
mod_security for apache etc which introduce by squid gurus to prevent these
kinds of problems .




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Malformed-HTTP-on-tproxy-squid-tp4678951p4678966.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From uhlar at fantomas.sk  Wed Aug 17 10:37:18 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 17 Aug 2016 12:37:18 +0200
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471410229820-4678961.post@n4.nabble.com>
References: <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
 <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
 <1471410229820-4678961.post@n4.nabble.com>
Message-ID: <20160817103718.GA31240@fantomas.sk>

On 16.08.16 22:03, Omid Kosari wrote:
>Even one ip address with less than 5 requests per second can grow squid cpu
>usage up to 30% . And 10 requests per second made 100% cpu usage . While
>there is nothing other than that client goes through squid . The client
>bandwidth is less than 10Kbps .
>
>Isn't it crazy also ?

are you intercepting traffic for port 80 only?


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
- Have you got anything without Spam in it?
- Well, there's Spam egg sausage and Spam, that's not got much Spam in it.


From omidkosari at yahoo.com  Wed Aug 17 10:48:34 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 17 Aug 2016 03:48:34 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <20160817103718.GA31240@fantomas.sk>
References: <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
 <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
 <1471410229820-4678961.post@n4.nabble.com>
 <20160817103718.GA31240@fantomas.sk>
Message-ID: <1471430914306-4678968.post@n4.nabble.com>

Matus UHLAR - fantomas wrote
> are you intercepting traffic for port 80 only?

yes



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678968.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Wed Aug 17 10:50:10 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 17 Aug 2016 12:50:10 +0200 (CEST)
Subject: [squid-users] Rock store status
In-Reply-To: <1022191120.678356711.1471429725615.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1366914360.678396724.1471431010434.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello All,

I tried rock store and smp long time ago (squid 3.2 I guess), Unfortunately I definitely drop smp because there are some limitations (In my case), and I fall-back to diskd because there were many bugs with rock store. FI I also switched to aufs without big differences.

But now with the latest 3.5.20 ? Sadly SMP still not for me but rock store ?

There is someone who are using rock store with a high load, more than 800 r/s, without any problem ? There is a real difference in this situation, cpu, speed, memory ?

My configuration is 

Debian 8
Squid 3.5.20
16 cores Xeon E5-2637 3.50Ghz
64 Go ram
2 drives sata - 15k - dedicated to caches (+ one for OS) 150 Go each
Delay pool -> BP limitation by ldap account
Authentication digest + basic 

Any advice welcome.

Fred



From marciobacci at gmail.com  Wed Aug 17 11:05:58 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Wed, 17 Aug 2016 08:05:58 -0300
Subject: [squid-users] Questions about Kerberos authentication on squid3
Message-ID: <CA+0Tdyq37-=Ue8pHZ8+1dNrP4=RcLndQ99M6zRw3dkzwGGqKjg@mail.gmail.com>

I have the following questions to use Kerberos authentication in squid3:

You must create the krb5.keytab file when using Samba 4 as DC? If positive,
how to create it?

Kerberos authentication (squid_kerb_auth) works for both Windows and Linux?

In this type of authentication the user will not need to enter your
username / password when you open the browser?

On the workstations I install ntp or ntpdate package?

Regards,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160817/877fd685/attachment.htm>

From eliezer at ngtech.co.il  Wed Aug 17 13:37:34 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 17 Aug 2016 16:37:34 +0300
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <201608171103.39448.Antony.Stone@squid.open.source.it>
References: <1471072704202-4678894.post@n4.nabble.com>
 <1471410229820-4678961.post@n4.nabble.com>
 <013f01d1f865$f83010e0$e89032a0$@ngtech.co.il>
 <201608171103.39448.Antony.Stone@squid.open.source.it>
Message-ID: <024101d1f88c$82aed1e0$880c75a0$@ngtech.co.il>

Thanks Antony!
It kind of disappeared from my mind\eyes despite to the fact that it's there.

Omid,
You are right about the expectation from a software to be polished.
I am with you on this but naturally port 80 should be used for http in a world which everybody obeys the holy RFC's.
There are couple options on how to resolve the issue but non of them are easy to put in production.

Amos can say what is to be expected from squid-4.
However I have it on my todo list to test the on_unsupported_protocol [http://www.squid-cache.org/Versions/v4/cfgman/on_unsupported_protocol.html] with hope it will give you and many others the right solution to weird scenarios.
Currently I do not have enough options\sites to test the issue also I am not sure about the expected result in a case of websockets.
I have compiled squid-4 but it will take me a bit more time to test over and over again.
If you have any suggestion on how to actually test this issue I would be happy to test the subject.
Currently my test lab is composed of:
- CentOS\Fedora\Ubuntu Intercept router
- Windows 7\8\10 Client
- Debian\Ubuntu\Fedora\CentOS\OpenSuse client
- Customized tcp service on port 80 which can serve both http and couple other protocols

Let me know about how I can verify the issue.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antony Stone
Sent: Wednesday, August 17, 2016 12:04 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid cpu usage 100% from few days ago !!

On Wednesday 17 August 2016 at 11:01:40, Eliezer Croitoru wrote:

> Hey Omid,
> 
> Just to understand, are you intercepting traffic?

>From the original report: "Squid is in tproxy mode with routing"


Antony.

> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of Omid Kosari Sent: Wednesday, August 17, 2016 8:04 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid cpu usage 100% from few days ago !!
> 
> Even one ip address with less than 5 requests per second can grow 
> squid cpu usage up to 30% . And 10 requests per second made 100% cpu 
> usage . While there is nothing other than that client goes through 
> squid . The client bandwidth is less than 10Kbps .
> 
> Isn't it crazy also ?

--
Salad is what food eats.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From omidkosari at yahoo.com  Wed Aug 17 13:43:49 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 17 Aug 2016 06:43:49 -0700 (PDT)
Subject: [squid-users] Yet another store_id question HIT MISS
Message-ID: <1471441429858-4678972.post@n4.nabble.com>

Why following link is HIT

X-Cache:"HIT from cache1"
X-Cache-Lookup:"HIT from cache1:3128"


http://igcdn-photos-c-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg

but this one is MISS

http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg



store_id_program "/usr/lib/squid/storeid_file_rewrite"
"/etc/squid/storeid_db"
store_id_children 50 startup=10 idle=5 concurrency=50
acl storeiddomainregex dstdom_regex
^igcdn(\-photos|\-videos)[a-z0-9\-]{0,9}\.akamaihd\.net$
store_id_access allow storeiddomainregex
store_id_access deny all
refresh_pattern -i ^http:\/\/[a-zA-Z0-9\-\_\.]+\.squid\.internal\/.* 10080
95% 86400  override-lastmod override-expire reload-into-ims ignore-reload
ignore-must-revalidate ignore-no-store ignore-private  

storeid_db content

^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$)
http://instagramcdn.squid.internal/$1


root at cache:~# echo
'http://igcdn-photos-c-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg'
| /usr/lib/squid/storeid_file_rewrite /etc/squid/storeid_db
OK
store-id=http://instagramcdn.squid.internal/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg
root at cache:~# echo
'http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg'
| /usr/lib/squid/storeid_file_rewrite /etc/squid/storeid_db
OK
store-id=http://instagramcdn.squid.internal/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg



StoreId helper Statistics:
program: /usr/lib/squid/storeid_file_rewrite
number active: 10 of 50 (0 shutting down)
requests sent: 1755734
replies received: 1755734
queue length: 0
avg service time: 0 msec

Number of requests bypassed because all StoreId helpers were busy: 0





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From belle at bazuin.nl  Wed Aug 17 13:56:07 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 17 Aug 2016 15:56:07 +0200
Subject: [squid-users] Questions about Kerberos authentication on squid3
In-Reply-To: <CA+0Tdyq37-=Ue8pHZ8+1dNrP4=RcLndQ99M6zRw3dkzwGGqKjg@mail.gmail.com>
References: <CA+0Tdyq37-=Ue8pHZ8+1dNrP4=RcLndQ99M6zRw3dkzwGGqKjg@mail.gmail.com>
Message-ID: <vmime.57b46cf7.4477.787ef0c155f00ee7@ms249-lin-003.rotterdam.bazuin.nl>

Hi Marcio, 

?

Have a look here a good guide. 

https://dev.tranquil.it/wiki/SAMBA_-_Configuration_Squid_Kerberos 

?

Most important, make sure your DNS setup is correct and the proxy server has an A and PTR (RR) record. 

Can be done without but that can result in problems. 

?

?

You must create the krb5.keytab file when using Samba 4 as DC? If positive, how to create it?

On the proxy itself as member server.? 

?

Make sure you then have also those 2. 

??? # enable offline logins

??? winbind offline logon = yes

??? # renew the kerberos ticket

??? winbind refresh tickets = yes

?

net ads join -U administrator

net ads keytab add HTTP -U administrator

?


or ?with samba tool on the DC. which i did since i use 2 proxys and 1 user for SPNs 

?

samba-tool user create squid-proxy --description="Unprivileged user for SQUID-Proxy Services" --random-password

samba-tool user setexpiry squid-proxy ?noexpiry 

samba-tool spn add HTTP/proxy1.internal.domain.tld squid-proxy

samba-tool spn add HTTP/proxy1.internal.domain.tld at REALM squid-proxy

?

and export it. 

samba-tool domain exportkeytab --principal=HTTP/proxy1. internal.domain.tld proxy1.keytab

and put the proxy1.keytab file in place on the proxy server, see link above. 

?

?


Kerberos authentication (squid_kerb_auth) works for both Windows and Linux?

Yes


?


In this type of authentication the user will not need to enter your username / password when you open the browser?

Correct, but you also need to setup your webbrowser for it. 


?


On the workstations I install ntp or ntpdate package?

No, but the make sure time is in sync with the DC?s. 




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160817/64ae1e16/attachment.htm>

From omidkosari at yahoo.com  Wed Aug 17 13:55:52 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 17 Aug 2016 06:55:52 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <024101d1f88c$82aed1e0$880c75a0$@ngtech.co.il>
References: <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
 <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
 <1471410229820-4678961.post@n4.nabble.com>
 <013f01d1f865$f83010e0$e89032a0$@ngtech.co.il>
 <201608171103.39448.Antony.Stone@squid.open.source.it>
 <024101d1f88c$82aed1e0$880c75a0$@ngtech.co.il>
Message-ID: <1471442152777-4678973.post@n4.nabble.com>

Thanks for reply

I have provided a sample wireshark pcap and squid access.log  here
http://squid-web-proxy-cache.1019090.n4.nabble.com/Malformed-HTTP-on-tproxy-squid-tp4678951p4678952.html

Maybe you can reproduce and resend those requests with the help of something
like fiddler or any other tool . Also i am volunteer to provide unlimited
number of such pcap files.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678973.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Aug 17 13:58:31 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 17 Aug 2016 16:58:31 +0300
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <1471441429858-4678972.post@n4.nabble.com>
References: <1471441429858-4678972.post@n4.nabble.com>
Message-ID: <024901d1f88f$701dd4b0$50597e10$@ngtech.co.il>

Hey Omid,

StoreID is not the only thing which can affect a HIT or a MISS.
A nice tool which was written to understand the subject is RedBot at:
https://redbot.org/

>From a simple inspection of the file it seems that it should get  hit but, why are you using StoreID for this object?
Also why are you using:
refresh_pattern -i ^http:\/\/[a-zA-Z0-9\-\_\.]+\.squid\.internal\/.* 10080 95% 86400   override-lastmod override-expire reload-into-ims ignore-reload ignore-must-revalidate ignore-no-store ignore-private 

??
You would only need this for the specific case which the hostname is "dynamic".
This url seems by default cache friendly and only if you have enough details on their cdn network you should try to use StoreID.
Something that may help you is the next log format settings:
logformat cache_headers %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt Q-CC: "%{Cache-Control}>h" "%{Cache-Control}>ha" Q-P: "%{Pragma}>h" "%{Pragma}>ha" REP-CC: "%{Cache-Control}<h" REP-EXP: "%{Expires}<h" VARY: "%{Vary}<h" %>eui
access_log daemon:/var/log/squid/access.log cache_headers

Try to see how the requests for these looks like in the logs.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Wednesday, August 17, 2016 4:44 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Yet another store_id question HIT MISS

Why following link is HIT

X-Cache:"HIT from cache1"
X-Cache-Lookup:"HIT from cache1:3128"


http://igcdn-photos-c-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg

but this one is MISS

http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg



store_id_program "/usr/lib/squid/storeid_file_rewrite"
"/etc/squid/storeid_db"
store_id_children 50 startup=10 idle=5 concurrency=50
acl storeiddomainregex dstdom_regex
^igcdn(\-photos|\-videos)[a-z0-9\-]{0,9}\.akamaihd\.net$
store_id_access allow storeiddomainregex
store_id_access deny all
refresh_pattern -i ^http:\/\/[a-zA-Z0-9\-\_\.]+\.squid\.internal\/.* 10080
95% 86400  override-lastmod override-expire reload-into-ims ignore-reload
ignore-must-revalidate ignore-no-store ignore-private  

storeid_db content

^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$)
http://instagramcdn.squid.internal/$1


root at cache:~# echo
'http://igcdn-photos-c-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg'
| /usr/lib/squid/storeid_file_rewrite /etc/squid/storeid_db
OK
store-id=http://instagramcdn.squid.internal/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg
root at cache:~# echo
'http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg'
| /usr/lib/squid/storeid_file_rewrite /etc/squid/storeid_db
OK
store-id=http://instagramcdn.squid.internal/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg



StoreId helper Statistics:
program: /usr/lib/squid/storeid_file_rewrite
number active: 10 of 50 (0 shutting down)
requests sent: 1755734
replies received: 1755734
queue length: 0
avg service time: 0 msec

Number of requests bypassed because all StoreId helpers were busy: 0





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Aug 17 14:01:15 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 17 Aug 2016 17:01:15 +0300
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471442152777-4678973.post@n4.nabble.com>
References: <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
 <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
 <1471410229820-4678961.post@n4.nabble.com>
 <013f01d1f865$f83010e0$e89032a0$@ngtech.co.il>
 <201608171103.39448.Antony.Stone@squid.open.source.it>
 <024101d1f88c$82aed1e0$880c75a0$@ngtech.co.il>
 <1471442152777-4678973.post@n4.nabble.com>
Message-ID: <026301d1f88f$d1a4df30$74ee9d90$@ngtech.co.il>

Hey Omid,

I can try to use the PCAP files but I am trying to stick in the upper level of operation when testing.
What I mean by that is that I am trying to find real world software which encounter an issue when squid is in the middle.
I can write scripts but as long there is something I can reproduce as a user and not as a programmer I prefer to stick with it.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Wednesday, August 17, 2016 4:56 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid cpu usage 100% from few days ago !!

Thanks for reply

I have provided a sample wireshark pcap and squid access.log  here http://squid-web-proxy-cache.1019090.n4.nabble.com/Malformed-HTTP-on-tproxy-squid-tp4678951p4678952.html

Maybe you can reproduce and resend those requests with the help of something like fiddler or any other tool . Also i am volunteer to provide unlimited number of such pcap files.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678973.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From steve at opendium.com  Wed Aug 17 14:08:37 2016
From: steve at opendium.com (Steve Hill)
Date: Wed, 17 Aug 2016 15:08:37 +0100
Subject: [squid-users] Large memory leak with ssl_peek (now partly
 understood)
In-Reply-To: <CE0D84FD-1E2C-42D5-868A-D3B9EFE98572@getbusi.com>
References: <6ebc07c2-c8e7-13f1-8c9f-cd00ab812339@opendium.com>
 <19bf0746-0f96-106a-bb43-72b1f69f434f@measurement-factory.com>
 <CAN8nrKB3KQHsOC-_uaOxS__L-S-WZm_8d0GgOBC_U-_106O=ng@mail.gmail.com>
 <c372fb8b-d013-0605-9692-59a954be13cc@opendium.com>
 <CE0D84FD-1E2C-42D5-868A-D3B9EFE98572@getbusi.com>
Message-ID: <d14f6350-c9ec-a2b4-cd7d-80242f8a4d76@opendium.com>

On 17/08/16 06:22, Dan Charlesworth wrote:

> Deployed a 3.5.20 build with both of those patches and have noticed a big improvement in memory consumption of squid processes at a couple of splice-heavy sites.
>
> Thank you, sir!

We've now started tentatively rolling this out to a few production sites 
too and are seeing good results so far.


-- 
  - Steve Hill
    Technical Director
    Opendium    Online Safety / Web Filtering    http://www.opendium.com

    Enquiries                 Support
    ---------                 -------
    sales at opendium.com        support at opendium.com
    +44-1792-824568           +44-1792-825748


From omidkosari at yahoo.com  Wed Aug 17 14:17:24 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 17 Aug 2016 07:17:24 -0700 (PDT)
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <026301d1f88f$d1a4df30$74ee9d90$@ngtech.co.il>
References: <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
 <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
 <1471410229820-4678961.post@n4.nabble.com>
 <013f01d1f865$f83010e0$e89032a0$@ngtech.co.il>
 <201608171103.39448.Antony.Stone@squid.open.source.it>
 <024101d1f88c$82aed1e0$880c75a0$@ngtech.co.il>
 <1471442152777-4678973.post@n4.nabble.com>
 <026301d1f88f$d1a4df30$74ee9d90$@ngtech.co.il>
Message-ID: <1471443444185-4678978.post@n4.nabble.com>

Aha . We have found that this request belongs to a cheap popular satellite
receiver www.starmax.co . Maybe it has been infected and becomes zombie of a
btnet . Maybe you should buy one device from them 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-cpu-usage-100-from-few-days-ago-tp4678894p4678978.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Wed Aug 17 14:26:44 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 17 Aug 2016 07:26:44 -0700 (PDT)
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <024901d1f88f$701dd4b0$50597e10$@ngtech.co.il>
References: <1471441429858-4678972.post@n4.nabble.com>
 <024901d1f88f$701dd4b0$50597e10$@ngtech.co.il>
Message-ID: <1471444004543-4678979.post@n4.nabble.com>

Eliezer Croitoru-2 wrote
> StoreID is not the only thing which can affect a HIT or a MISS.
> A nice tool which was written to understand the subject is RedBot at:
> https://redbot.org/
> 
> From a simple inspection of the file it seems that it should get  hit but,
> why are you using StoreID for this object?

Already tested with redbot and then asked here .
This url belongs to instagram and it uses a lot of such urls for same file .


Eliezer Croitoru-2 wrote
> Also why are you using:
> refresh_pattern -i ^http:\/\/[a-zA-Z0-9\-\_\.]+\.squid\.internal\/.* 10080
> 95% 86400   override-lastmod override-expire reload-into-ims ignore-reload
> ignore-must-revalidate ignore-no-store ignore-private 
> 
> ??
> You would only need this for the specific case which the hostname is
> "dynamic".

Thanks removed it .


Eliezer Croitoru-2 wrote
> This url seems by default cache friendly and only if you have enough
> details on their cdn network you should try to use StoreID.
> Something that may help you is the next log format settings:
> logformat cache_headers %ts.%03tu %6tr %>a %Ss/%03>Hs %
> <st %rm %ru %[un %Sh/%<a %mt Q-CC: "%{Cache-Control}>
> h" "%{Cache-Control}>ha" Q-P: "%{Pragma}>h" "%{Pragma}>ha" REP-CC:
> "%{Cache-Control}&lt;h&quot; REP-EXP: &quot;%{Expires}&lt;h&quot; VARY:
> &quot;%{Vary}&lt;h&quot; %&gt;eui
> access_log daemon:/var/log/squid/access.log cache_headers
> 
> Try to see how the requests for these looks like in the logs.

Yes we have enough details. Now i am investigating on hit miss problem with
logformat you provided .I will inform you the result .

Thanks






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4678979.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Wed Aug 17 14:27:27 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 17 Aug 2016 08:27:27 -0600
Subject: [squid-users] Squid cpu usage 100% from few days ago !!
In-Reply-To: <1471410229820-4678961.post@n4.nabble.com>
References: <1471072704202-4678894.post@n4.nabble.com>
 <43d47103-542c-0fdd-9a56-ba45a360123c@urlfilterdb.com>
 <1471176224321-4678931.post@n4.nabble.com>
 <201608141411.56671.Antony.Stone@squid.open.source.it>
 <1471177538989-4678933.post@n4.nabble.com>
 <201608141435.45901.Antony.Stone@squid.open.source.it>
 <2fa19f24-bd54-3acf-b1ad-1e505c0e6092@gmail.com>
 <1471251534915-4678937.post@n4.nabble.com>
 <f951c350-5a1c-ac8d-655e-4df8ae26b2e6@measurement-factory.com>
 <5634b719-e8d1-574b-df42-e44b2ed88487@treenet.co.nz>
 <1471410229820-4678961.post@n4.nabble.com>
Message-ID: <0cf31ac1-172d-73ad-0385-30b95a7557af@measurement-factory.com>

On 08/16/2016 11:03 PM, Omid Kosari wrote:
> Even one ip address with less than 5 requests per second can grow squid cpu
> usage up to 30% . And 10 requests per second made 100% cpu usage . While
> there is nothing other than that client goes through squid . The client
> bandwidth is less than 10Kbps .
> 
> Isn't it crazy also ?

It is.

Alex.



From squid3 at treenet.co.nz  Wed Aug 17 14:28:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 02:28:58 +1200
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <1471441429858-4678972.post@n4.nabble.com>
References: <1471441429858-4678972.post@n4.nabble.com>
Message-ID: <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>

On 18/08/2016 1:43 a.m., Omid Kosari wrote:
> Why following link is HIT
> 
> X-Cache:"HIT from cache1"
> X-Cache-Lookup:"HIT from cache1:3128"
> 
> 
> http://igcdn-photos-c-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg
> 
> but this one is MISS
> 
> http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg
> 

Because your override-expire tells Squid to ignore the
Cache-Control:max-age expiry details - instead to treat anything 10080
seconds old as expired.

Then the override-last-mod tells Squid to ignore the Last-Modified
header, instead to treat everything arriving as being 10080 seconds old.

When combined they mean that objects are only cacheable for the
remainder of the first second after arrival. When that 0-1 second is
over they are identified as being stale and require revalidation to be used.

Your options also tell Squid to ignore revalidation ...
 You see where this is going?


It is most often a bad idea to override cache controls coming from the
server. refresh_pattern is a way to work around broken services or those
which do not send sufficient cache-controls to cache properly. Use with
great care and caution.

Amos



From yvoinov at gmail.com  Wed Aug 17 14:34:10 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 17 Aug 2016 20:34:10 +0600
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
Message-ID: <392aad5f-3559-15ed-74d3-7d272fac59dd@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


17.08.2016 20:28, Amos Jeffries ?????:
> On 18/08/2016 1:43 a.m., Omid Kosari wrote:
>> Why following link is HIT
>>
>> X-Cache:"HIT from cache1"
>> X-Cache-Lookup:"HIT from cache1:3128"
>>
>>
>>
http://igcdn-photos-c-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg
>>
>> but this one is MISS
>>
>>
http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg
>>
>
> Because your override-expire tells Squid to ignore the
> Cache-Control:max-age expiry details - instead to treat anything 10080
> seconds old as expired.
>
> Then the override-last-mod tells Squid to ignore the Last-Modified
> header, instead to treat everything arriving as being 10080 seconds old.
>
> When combined they mean that objects are only cacheable for the
> remainder of the first second after arrival. When that 0-1 second is
> over they are identified as being stale and require revalidation to be
used.
>
> Your options also tell Squid to ignore revalidation ...
>  You see where this is going?
>
>
> It is most often a bad idea to override cache controls coming from the
> server. refresh_pattern is a way to work around broken services or those
> which do not send sufficient cache-controls to cache properly. Use with
> great care and caution.
I do not agree. Many webmasters intentionally set the value in the "no
cache" in their own selfish interests. For example, when displaying
advertising. Or, even worse, when watching videos - like Youtube. Which
leads to the monstrous traffic overspending. Why should we respect them?
While they actively oppose us?
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXtHXiAAoJENNXIZxhPexGueMIAIWGnKWYsEkMPKmCqotCAcxo
N+raeePYsVaur/PZFsZgm2I9Dh+K0x2E8s5cYo5kcAcJl+q2Kfe9M1PvTJdvc6AG
zOSHzYtZ6e3n/w0f/WkUunSXOX0gWOlqHXvZZTjfm6R1zH8Qw+yx3jWIKQG8TuFP
EwSk1fPHfk77sfBXeYcgHPOYHrpGr8ubLsUmfQmrLWTWd5LP6rpFtGvm/pnreX9j
ZTOoNjYcqRdC+90Hwg6p6KDCyxSJOkd00fOoCclp4toAiNEwq2mUOOVwlvuL6pTZ
Vz97vrus0c2ntcojYPlHmX9/ywzs4vlR1y8J2QAg5HeITvnlv64ZI0Mmt3Enjmc=
=l7rO
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160817/6e522e84/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160817/6e522e84/attachment.key>

From omidkosari at yahoo.com  Wed Aug 17 14:36:18 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 17 Aug 2016 07:36:18 -0700 (PDT)
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
Message-ID: <1471444578446-4678983.post@n4.nabble.com>

Amos Jeffries wrote
> On 18/08/2016 1:43 a.m., Omid Kosari wrote:
>> Why following link is HIT
>> 
>> X-Cache:"HIT from cache1"
>> X-Cache-Lookup:"HIT from cache1:3128"
>> 
>> 
>> http://igcdn-photos-c-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg
>> 
>> but this one is MISS
>> 
>> http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150x150/e35/13649137_1547514802224163_950421795_n.jpg
>> 
> 
> Because your override-expire tells Squid to ignore the
> Cache-Control:max-age expiry details - instead to treat anything 10080
> seconds old as expired.
> 
> Then the override-last-mod tells Squid to ignore the Last-Modified
> header, instead to treat everything arriving as being 10080 seconds old.
> 
> When combined they mean that objects are only cacheable for the
> remainder of the first second after arrival. When that 0-1 second is
> over they are identified as being stale and require revalidation to be
> used.
> 
> Your options also tell Squid to ignore revalidation ...
>  You see where this is going?
> 
> 
> It is most often a bad idea to override cache controls coming from the
> server. refresh_pattern is a way to work around broken services or those
> which do not send sufficient cache-controls to cache properly. Use with
> great care and caution.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

Thanks . i have completely removed that refresh_pattern line but still same
result .



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4678983.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Aug 17 14:38:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 02:38:55 +1200
Subject: [squid-users] Questions about Kerberos authentication on squid3
In-Reply-To: <vmime.57b46cf7.4477.787ef0c155f00ee7@ms249-lin-003.rotterdam.bazuin.nl>
References: <CA+0Tdyq37-=Ue8pHZ8+1dNrP4=RcLndQ99M6zRw3dkzwGGqKjg@mail.gmail.com>
 <vmime.57b46cf7.4477.787ef0c155f00ee7@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <ffd51019-91a8-f469-4344-715150d88575@treenet.co.nz>

On 18/08/2016 1:56 a.m., L.P.H. van Belle wrote:
> 
> In this type of authentication the user will not need to enter your username / password when you open the browser?
> 
> Correct, but you also need to setup your webbrowser for it. 
> 

Actually; *no* authentication scheme needs the user to enter username
and password manually. The browsers auth popup happens only when it
cannot find working credentials via any other way. It is entirely
possible to setup any of the HTTP authentication schemes so no popup
happens (just varying degrees of difficulty).
 Kerberos is nothing special in that regard.

Amos



From squid3 at treenet.co.nz  Wed Aug 17 15:02:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 03:02:04 +1200
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <1471425989455-4678966.post@n4.nabble.com>
References: <1471342982214-4678951.post@n4.nabble.com>
 <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>
 <1471425989455-4678966.post@n4.nabble.com>
Message-ID: <47d89333-8d24-ae94-66dd-d04bc9dfcd63@treenet.co.nz>

On 17/08/2016 9:26 p.m., Omid Kosari wrote:
> Hi Eliezer,
> 
> 
> Eliezer Croitoru-2 wrote
>> If you know what domain or ip address causes and issue the first thing I
>> can think about is bypassing the malicious traffic to allow other
>> clients\users to reach the Internet.
> 
> Source ip may be 70% of our customers because it is a popular device so it
> is not an option . Destination ip or domains are too much . 
> 
> Unfortunately because the requests are not normal http , so squid log does
> not have the dst url/domain/ip so it is hard job to find them .
> 1- First i should keep looking the squid access.log to find client which has
> such request . 
> 2-Then try to sniff that client from router. 
> 3-Separate normal requests from malformed . 
> 4-Find the destination from malformed requests.
> 5-Put that ip in router acl to exclude from tproxy routing to squid .
> 
> Nobody knows how many times this loop should be repeated because nobody
> knows count of destinations .
> 

Easier way:

 logformat Xips %ts.%03tu %6tr %>a %>la %>ru
 access_log stdio:/var/log/squid/xact.log Xips

Then just grep the xact.log file for the "error:invalid-request" URLs,
and see what the '>la' column IP address is.

If you want to automate it make a logging daemon script.

> 
> Eliezer Croitoru-2 wrote
>> And since squid is also being used as a http ACL enforcement tool
>> malformed requests basically should be dropped and not bypassed
>> automatically.
> 
> So then squid should be able to simply drop them.
> Even it would be fine to have some patterns in iptables or something like
> mod_security for apache etc which introduce by squid gurus to prevent these
> kinds of problems .


Your Squid is not even getting far enough to apply security rules to the
garbage traffic. It is basically just doing: accept() connection,
unmangle the NAT/TPROXY details, read(2) some bytes, try to parse - bam
generate and send error page, close the TCP connection and log the event.


About the only thing you could do to speed it up is locate the error
page templates (file paths: en/ERR_INVALID_REQ and
templates/ERR_INVALID_REQ) and remove their contents. Then restart Squid.
That should remove at least a few of the vprintf() syscalls that your
earlier trace showed as being a significant source of CPU load.

Amos



From tekuehn at web.de  Wed Aug 17 15:23:52 2016
From: tekuehn at web.de (Torsten =?ISO-8859-15?Q?K=FChn?=)
Date: Wed, 17 Aug 2016 17:23:52 +0200
Subject: [squid-users] Squid 2.7.s9 HTTPS-proxying - hint welcome
Message-ID: <20160817172352.3f19dc8f@BS2>

Dear Mailing List,

older Squid versions have been obsoleted by 3.X and 4.X, I (barely)
dare to ask a 2.X-related question ... For particular reasons, I am
forced to stuck with 2.X: my cache contains objects since 2010, of
personal value. Due to small bandwith (ISDN speed), I use Squid
as a "buffer" for offline browsing, objects are reloaded on request
only (Ctrl-R/ F5).

I managed to build a debianized Version of 2.7.STABLE9-20110824
'--enable-ssl' (OpenSSL 1.0.1t) on Raspbian Jessie in June (an OS/2
build using VAC++ failed in 2013). Duane Wessels' Squid Guide is an
invaluable source - I did not find comparably clear explanations
on SSL/ HTTPS-features on squid-cache.org. In the mail archive,
2.X SSL-related topics are rare.

In brief, I failed to set up SSL-options properly, i.e. the proxy
is still unable to cache HTTPS-URLs by means of Man-in-the-middle-
(MITM-) decryption, i.e. no HTTPS objects never get stored in the
cache. The more and more web pages become secured, bigger and bigger
as well - it is hard to lose information on each reboot.

Configuration (extract from cachmgr.cgi's current configuration):
 acl SSL_ports port 443
 acl Safe_ports port 443
 http_access Deny !Safe_ports
 http_access Deny CONNECT !SSL_ports
 ...
 ssl_unclean_shutdown on
 sslproxy_client_certificate /etc/squid/proxyCert.proxyCertInfo
 sslproxy_client_key /etc/squid/proxyKey.pem
 sslproxy_version 1
 sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
 sslproxy_cafile /etc/ssl/certs/ca-certificates.crt
 sslproxy_capath /etc/ssl/certs
 http_port 0.0.0.0:8080 protocol=http
--- End of current Squid configuration's extract ----
   (Complete configuration available if required.)

The client_certificate "proxyKey.pem" is a 2048 bit RSA key without
pass phrase, signed by a self-created Root CA-certificate. (Appropriate
entries for the sslpassword_program TAG are unknown - Squid stalls when
opening password-protected keys). The extension of client_certificate,
"proxyCert.proxyCertInfo" is inspired by OpenSSL's proxy certificates
HOWTO. The sslproxy_cafile & _capath TAGs point to OpenSSL's CA certs.

I don't understand how clients gain access to Squid's HTTPS-capabilities;
I tried to exclude port 443 from the CONNECTable acl hoping the client
might connect to Squid itself (it didn't). Entries such as
 https_port 443 cert=/etc/squid/proxyCert.proxyCertInfo
      key=/etc/squid/proxyKey.pem dhparams=/etc/squid/proxyDHparam.pem
were unsuccessful as well. If I got things right, the global sslproxy_*
TAGs control how Squid handles DIRECT traffic towards https:// URLs,
whilst https_port defines the proxy as an end point of SSL-connections,
and cache_peer sets up (encryptable) links to other Squids or servers.

Despite sslproxy_* entries, Squid still tunnels HTTPS requests and
DIRECTs them to origin servers. V2.7.s9 lacks features introduced in
newer versions (like SSL Bump), I hope it is at all capable to cache
encrypted data. I'd be glad about feedback pointing out misunderstandings.

OR, is it possible - by contrast to the step from Squid 1.X to 2.X - that
the cache objects' file format did not change since 2.X, which would allow
to use my (precious) objects with, e.g. Squid 3.5? There is a 3.5.19 build
on http://archive.raspbian.org/raspbian/pool/main/s/squid3/, but the
respective dependencies cannot be resolved yet.

Sincerely  Torsten


From squid3 at treenet.co.nz  Wed Aug 17 16:01:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 04:01:05 +1200
Subject: [squid-users] Squid 2.7.s9 HTTPS-proxying - hint welcome
In-Reply-To: <20160817172352.3f19dc8f@BS2>
References: <20160817172352.3f19dc8f@BS2>
Message-ID: <2162fa4d-41e1-81c1-12a2-7b99d2bd04aa@treenet.co.nz>

On 18/08/2016 3:23 a.m., Torsten K?hn wrote:
> Dear Mailing List,
> 
> older Squid versions have been obsoleted by 3.X and 4.X, I (barely)
> dare to ask a 2.X-related question ... For particular reasons, I am
> forced to stuck with 2.X

Then you cannot decrypt the HTTPS in order to cache it. Squid older than
3.2 simply do not have any of the functionality to do so.

> my cache contains objects since 2010, of
> personal value.

Cache is not an archive. Everything in a cache is by definition *not*
valuable and subject to be erased at any time. That is why it is called
caching and not archiving.

FYI, your "of personal value" data is at high risk of being erased with
every request sent through that proxy, even though it is in an old Squid.


> Due to small bandwith (ISDN speed), I use Squid
> as a "buffer" for offline browsing, objects are reloaded on request
> only (Ctrl-R/ F5).

NO version of Squid provides that guarantee.

...
> 
> OR, is it possible - by contrast to the step from Squid 1.X to 2.X - that
> the cache objects' file format did not change since 2.X, which would allow
> to use my (precious) objects with, e.g. Squid 3.5? There is a 3.5.19 build
> on http://archive.raspbian.org/raspbian/pool/main/s/squid3/, but the
> respective dependencies cannot be resolved yet.

We have done some fundamental data-integrity changes to the swap.state
journal format since 2.7. But that alone is nothing serious - after
upgrade Squid should discard the old swap.state file and do a "DIRTY"
cache scan to rebuild the journal in the new format.

I don't recall the format of the objects themselves being changed. It is
just a simple TLV chain followed by the HTTP response object/payload.
Though it might have, so testing is recommended just to be sure.

Amos



From rousskov at measurement-factory.com  Wed Aug 17 16:07:20 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 17 Aug 2016 10:07:20 -0600
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <47d89333-8d24-ae94-66dd-d04bc9dfcd63@treenet.co.nz>
References: <1471342982214-4678951.post@n4.nabble.com>
 <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>
 <1471425989455-4678966.post@n4.nabble.com>
 <47d89333-8d24-ae94-66dd-d04bc9dfcd63@treenet.co.nz>
Message-ID: <34b9a680-f2cb-8709-e141-4041af19b39b@measurement-factory.com>

On 08/17/2016 09:02 AM, Amos Jeffries wrote:

> Your Squid is not even getting far enough to apply security rules to the
> garbage traffic. It is basically just doing: accept() connection,
> unmangle the NAT/TPROXY details, read(2) some bytes, try to parse - bam
> generate and send error page, close the TCP connection and log the event.

*If* just a few clients doing the above can have a serious effect on
overall performance of a Squid instance running on decent hardware, then
we need to fix or optimize something. There is little Squid can do
against a powerful DDoS, but a few broken clients rarely mimic that.


> About the only thing you could do to speed it up is locate the error
> page templates and remove their contents.

Also, *if* the clients do not open new connections until their old
connections are closed, then you may be able to slow them down
considerably by delaying those error responses. It may be possible to do
that with an external ACL helper (that delays responses) and
http_reply_access rules that target those specific error pages.


Disclaimer: I am not implying that the two conditions marked with "*If*"
above are true. I have not checked them.

Alex.



From rousskov at measurement-factory.com  Wed Aug 17 16:18:23 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 17 Aug 2016 10:18:23 -0600
Subject: [squid-users] Checking SSL bump status in http_access
In-Reply-To: <3cc7a49f-c6cc-0f18-31cd-4b2c3cc6d5d5@treenet.co.nz>
References: <d0b96af9-b14c-54b3-4ffa-d4e072e5b03d@opendium.com>
 <3cc7a49f-c6cc-0f18-31cd-4b2c3cc6d5d5@treenet.co.nz>
Message-ID: <8f934c8a-5dcf-7039-fe76-199840254616@measurement-factory.com>

On 08/16/2016 05:12 PM, Amos Jeffries wrote:
> On 17/08/2016 2:22 a.m., Steve Hill wrote:
>> Is there a way of figuring out if the current request is a bumped
>> request when the http_access ACL is being checked?  i.e. can we tell the
>> difference between a GET request that is inside a bumped tunnel, and an
>> unencrypted GET request?


> In Squid-3 a combo of the myportname and proto ACLs should do that.
> 
> In Squid-4 the above, or the connections_encrypted ACL type.


In both cases, please be extra careful with CONNECT requests (real or
fake) that precede bumped traffic but also go through http_access rules
and with unencrypted https:// requests that some Squids may receive.

Since bumping is not a instantaneous decision but a long process,
possibly involving several CONNECT requests, and since other traffic,
especially in complicated deployments can have properties similar to
bumped requests, it is often difficult to write correct "this HTTP
request was bumped" ACLs.

This configuration problem should be at least partially addressed by the
upcoming annotate_transaction ACLs inserted into ssl_bump rules:
http://lists.squid-cache.org/pipermail/squid-dev/2016-July/006146.html


HTH,

Alex.



From squid3 at treenet.co.nz  Wed Aug 17 16:25:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 04:25:46 +1200
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <34b9a680-f2cb-8709-e141-4041af19b39b@measurement-factory.com>
References: <1471342982214-4678951.post@n4.nabble.com>
 <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>
 <1471425989455-4678966.post@n4.nabble.com>
 <47d89333-8d24-ae94-66dd-d04bc9dfcd63@treenet.co.nz>
 <34b9a680-f2cb-8709-e141-4041af19b39b@measurement-factory.com>
Message-ID: <a9912a8c-d8de-ff6f-3af2-584988eaf7e5@treenet.co.nz>

On 18/08/2016 4:07 a.m., Alex Rousskov wrote:
> On 08/17/2016 09:02 AM, Amos Jeffries wrote:
> 
>> Your Squid is not even getting far enough to apply security rules to the
>> garbage traffic. It is basically just doing: accept() connection,
>> unmangle the NAT/TPROXY details, read(2) some bytes, try to parse - bam
>> generate and send error page, close the TCP connection and log the event.
> 
> *If* just a few clients doing the above can have a serious effect on
> overall performance of a Squid instance running on decent hardware, then
> we need to fix or optimize something. There is little Squid can do
> against a powerful DDoS, but a few broken clients rarely mimic that.
> 

I'm not convinced that the few req/sec is really that small. It could be
5 proper HTTP req/sec plus some hundreds of attempts to connect with the
non-HTTP transactions.
The latter wont show up in the mg:info report or SNMP req/sec stats (for
HTTP requests/sec), but will only appear in the mgr:utilization report
syscalls.sock.accepts counters and (maybe) the access.log.

Omar: can you clarify how you are identifying the req/sec rates?

> 
>> About the only thing you could do to speed it up is locate the error
>> page templates and remove their contents.
> 
> Also, *if* the clients do not open new connections until their old
> connections are closed, then you may be able to slow them down
> considerably by delaying those error responses. It may be possible to do
> that with an external ACL helper (that delays responses) and
> http_reply_access rules that target those specific error pages.
> 
> 
> Disclaimer: I am not implying that the two conditions marked with "*If*"
> above are true. I have not checked them.

I don't think the delayer approach will work because these are parse
error/abort responses that don't go near any ACL system.

Amos



From rousskov at measurement-factory.com  Wed Aug 17 16:47:26 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 17 Aug 2016 10:47:26 -0600
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <a9912a8c-d8de-ff6f-3af2-584988eaf7e5@treenet.co.nz>
References: <1471342982214-4678951.post@n4.nabble.com>
 <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>
 <1471425989455-4678966.post@n4.nabble.com>
 <47d89333-8d24-ae94-66dd-d04bc9dfcd63@treenet.co.nz>
 <34b9a680-f2cb-8709-e141-4041af19b39b@measurement-factory.com>
 <a9912a8c-d8de-ff6f-3af2-584988eaf7e5@treenet.co.nz>
Message-ID: <988adebc-9743-c429-6dfd-bca93fb54f77@measurement-factory.com>

On 08/17/2016 10:25 AM, Amos Jeffries wrote:

> I don't think the delayer approach will work because these are parse
> error/abort responses that don't go near any ACL system.

If an error response does not go through http_reply_access, then this is
a Squid bug IMO.

Alex.



From ahmed.zaeem at netstream.ps  Wed Aug 17 19:05:20 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 17 Aug 2016 22:05:20 +0300
Subject: [squid-users] stop caching completely on squid 3.5.2
Message-ID: <E065046A-83CF-4A30-8E08-31AC1C0A09A2@netstream.ps>

Hi 
I?m  willing to stop caching on squid 3.5.2 on both memory & disk caching 

is the directive :
cache deny all

sufficient for that ?

again i don?t want any type of caching 


cheers

From eliezer at ngtech.co.il  Wed Aug 17 19:25:29 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 17 Aug 2016 22:25:29 +0300
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <1471444578446-4678983.post@n4.nabble.com>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
Message-ID: <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>

Hey Omid,

I will try to test here on my local squid to see if there is a well understood reason for the MISS.
What have you tried until now to test the issue?
Did you tried to reproduce from your PC?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Wednesday, August 17, 2016 5:36 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Yet another store_id question HIT MISS

Amos Jeffries wrote
> On 18/08/2016 1:43 a.m., Omid Kosari wrote:
>> Why following link is HIT
>> 
>> X-Cache:"HIT from cache1"
>> X-Cache-Lookup:"HIT from cache1:3128"
>> 
>> 
>> http://igcdn-photos-c-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150
>> x150/e35/13649137_1547514802224163_950421795_n.jpg
>> 
>> but this one is MISS
>> 
>> http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xaf1/t51.2885-15/s150
>> x150/e35/13649137_1547514802224163_950421795_n.jpg
>> 
> 
> Because your override-expire tells Squid to ignore the 
> Cache-Control:max-age expiry details - instead to treat anything 10080 
> seconds old as expired.
> 
> Then the override-last-mod tells Squid to ignore the Last-Modified 
> header, instead to treat everything arriving as being 10080 seconds old.
> 
> When combined they mean that objects are only cacheable for the 
> remainder of the first second after arrival. When that 0-1 second is 
> over they are identified as being stale and require revalidation to be 
> used.
> 
> Your options also tell Squid to ignore revalidation ...
>  You see where this is going?
> 
> 
> It is most often a bad idea to override cache controls coming from the 
> server. refresh_pattern is a way to work around broken services or 
> those which do not send sufficient cache-controls to cache properly. 
> Use with great care and caution.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

Thanks . i have completely removed that refresh_pattern line but still same result .



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4678983.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From erdosain9 at gmail.com  Wed Aug 17 20:58:25 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 17 Aug 2016 13:58:25 -0700 (PDT)
Subject: [squid-users] AD Ldap (automatically take the user that is logging
	on PC)
Message-ID: <1471467505128-4678994.post@n4.nabble.com>

Hi
Squid configured to authenticate with AD with LDAP. this is the relevant
configuration.


# Active Directory
auth_param basic program /usr/lib64/squid/basic_ldap_auth -R -b
"cn=Users,dc=example,dc=lan" -D squid at example.lan -w pass  -f
sAMAccountName=%s -v 3 -s sub -h 192.168.1.60
auth_param basic children 10
auth_param basic realm Proxy
auth_param basic credentialsttl 2 hour

external_acl_type ldap_group ttl=360 %LOGIN
/usr/lib64/squid/ext_ldap_group_acl -d -R -b "dc=example,dc=lan" -D
squid at example.lan -w pass -f
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%a,ou=group,dc=example,dc=lan))"
-h 192.168.1.60

acl vip  external ldap_group vip
acl control external ldap_group control


It works well. Except I do not want to ask for username and password in the
webbrowser. I want squid automatically take the user that is logging on PC.
What I can do?
greetings and thanks.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Aug 17 21:28:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 18 Aug 2016 03:28:08 +0600
Subject: [squid-users] AD Ldap (automatically take the user that is
 logging on PC)
In-Reply-To: <1471467505128-4678994.post@n4.nabble.com>
References: <1471467505128-4678994.post@n4.nabble.com>
Message-ID: <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Vips do not want enter username and password? :)


18.08.2016 2:58, erdosain9 ?????:
> Hi
> Squid configured to authenticate with AD with LDAP. this is the relevant
> configuration.
>
>
> # Active Directory
> auth_param basic program /usr/lib64/squid/basic_ldap_auth -R -b
> "cn=Users,dc=example,dc=lan" -D squid at example.lan -w pass  -f
> sAMAccountName=%s -v 3 -s sub -h 192.168.1.60
> auth_param basic children 10
> auth_param basic realm Proxy
> auth_param basic credentialsttl 2 hour
>
> external_acl_type ldap_group ttl=360 %LOGIN
> /usr/lib64/squid/ext_ldap_group_acl -d -R -b "dc=example,dc=lan" -D
> squid at example.lan -w pass -f
>
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%a,ou=group,dc=example,dc=lan))"
> -h 192.168.1.60
>
> acl vip  external ldap_group vip
> acl control external ldap_group control
>
>
> It works well. Except I do not want to ask for username and password
in the
> webbrowser. I want squid automatically take the user that is logging
on PC.
> What I can do?
> greetings and thanks.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXtNbmAAoJENNXIZxhPexGRV8H/ifU+Q6Wu4pYc59rzH+7kTu4
BxfiVm+DvZK31dGBNPrA71mAD15d3YiI//rZjtaPpy0M0Zn1M6sF6exH4RMqcWps
ChLrxrwymtc4SGFhHPzjHhOhoiaIvP21U9VRVi+svJ1AjtuWCg3Q2vrhnac4473o
10HyDPKudDMa8I1ktvuQgxxwECE2ELKuO1NMDOmLaUiLUTi8o5qIbSHPdVA85c9V
klUw6ViQmoLpV+Wp35LF7M//x+IxOuyfNPhlDeE6daBofDg6weJse2G5t/GXogJp
1dWXci8a+yedR2ay3k8MjiehvAKQa979oy83FVsMO0Vj54TXEoK3MRiQkNGstKQ=
=xFmV
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/435bdfb4/attachment.key>

From erdosain9 at gmail.com  Wed Aug 17 22:29:18 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 17 Aug 2016 15:29:18 -0700 (PDT)
Subject: [squid-users] AD Ldap (automatically take the user that is
	logging on PC)
In-Reply-To: <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
Message-ID: <1471472958047-4678996.post@n4.nabble.com>

lol
no, for all the ACL.
vip and control.......
that no users need to enter username and password ... (only to log on to the
PC, but do not have to put username and password in the browser)..........
for all.

(i dont speak english.........)



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994p4678996.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From tekuehn at web.de  Wed Aug 17 23:00:41 2016
From: tekuehn at web.de (Torsten Kuehn)
Date: Wed, 17 Aug 2016 16:00:41 -0700 (PDT)
Subject: [squid-users] Squid 2.7.s9 HTTPS-proxying - hint welcome
In-Reply-To: <2162fa4d-41e1-81c1-12a2-7b99d2bd04aa@treenet.co.nz>
References: <20160817172352.3f19dc8f@BS2>
 <2162fa4d-41e1-81c1-12a2-7b99d2bd04aa@treenet.co.nz>
Message-ID: <1471474841533-4678997.post@n4.nabble.com>

Thank you for your quick reply!

On 17/08/2016 6:01 p.m., Amos Jeffries wrote:

>> I am forced to stuck with 2.X
> Then you cannot decrypt the HTTPS in order to cache it. Squid older than
> 3.2 simply do not have any of the functionality to do so.

I.e. not cacheable at all? May sound stupid but I imagine layouts where the
encrypted traffic itself gets stored and a client could re-use it later.
But, most probably, session identifiers are unique, and the REQ-/ ACK-chains
during SSL/ TLS-negotiation are hardly reproducable. As Yuri Voinov
explained
earlier, new protocols were explicitly re-designed to suppress
MITM-handling.

At the beginning, I was so impressed by this new SSL & certificates stuff
that I did not notice significant differences between Squid releases.

> Cache is not an archive. Everything in a cache is by definition *not*
> valuable and subject to be erased at any time.
> [...] "of personal value" data is at high risk of being erased with
> every request sent through that proxy

Archiving is a different matter, no question. But I prefer not to erase
objects from my cache, unless requested. My refresh_patterns etc. may look
horrible for administrators who try to provide most recent content:
    authenticate_ttl 359996400 seconds
    hierarchy_stoplist cgi-bin
    maximum_object_size 1073741824 bytes
    refresh_pattern -i /cgi-bin/ 5258880 100% 5258880
    refresh_pattern (Release|Packages(.gz)*)$ 0 20% 2880
    refresh_pattern . 5258880 100% 5258880
        override-expire override-lastmod ignore-no-cache ignore-private
    positive_dns_ttl 359996400 seconds
    negative_dns_ttl 60 seconds
    vary_ignore_expire on
    reload_into_ims on

This setup is that robust that both force-reload and PURGE fail unless
objects are deleted manually (resulting in "truncate: Warning: DosOpen
Error 110, OPEN_FAILED, file ...") or the ugly "reload_into_ims on" option
is set which violates standards.

>> is it possible that the cache objects' file format [unchanged] since 2.X
> some fundamental [...] changes to the swap.state journal format since 2.7.
> nothing serious - after upgrade Squid should discard the old swap.state
> file and do a "DIRTY" cache scan to rebuild the journal in the new format.

Sounds promising, thanks!

> objects themselves [...] just a simple TLV chain followed by the HTTP
> response object/payload. [...] testing is recommended

I'll try 3.5.19 as soon as GCC 5.2 libstdc++.so.6 for Raspbian is out.

Regards,  Torsten



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-s9-HTTPS-proxying-hint-welcome-tp4678986p4678997.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bpk678 at gmail.com  Thu Aug 18 00:11:34 2016
From: bpk678 at gmail.com (brendan kearney)
Date: Wed, 17 Aug 2016 20:11:34 -0400
Subject: [squid-users] AD Ldap (automatically take the user that is
 logging on PC)
In-Reply-To: <1471472958047-4678996.post@n4.nabble.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
Message-ID: <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>

You want Kerberos and/or NTLM authentication for Single Sign On.  These
authentication methods automatically provide credentials when browser are
configured and the necessary network services are running.

On Aug 17, 2016 6:30 PM, "erdosain9" <erdosain9 at gmail.com> wrote:

> lol
> no, for all the ACL.
> vip and control.......
> that no users need to enter username and password ... (only to log on to
> the
> PC, but do not have to put username and password in the browser)..........
> for all.
>
> (i dont speak english.........)
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-
> that-is-logging-on-PC-tp4678994p4678996.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160817/e1dd8ae7/attachment.htm>

From jford1968 at hotmail.com  Thu Aug 18 00:29:45 2016
From: jford1968 at hotmail.com (Jim Ford)
Date: Thu, 18 Aug 2016 00:29:45 +0000
Subject: [squid-users] making 204s cachable again
Message-ID: <BAY173-W3CAA0130D6471B1EECD71BC150@phx.gbl>

I recently upgraded to Version 3.5.10.  I'm using it as a regular as well as a reverse proxy.  In both cases I've noticed that what were formerly cachable requests that resulted in a 204 response, are now always resulting in a MISS.  The only hits I'm getting are negative when the requests are close together.  Is there a configuration option I can use to force normal caching and have it obey the expiration?  I don't want to just increase the negative caching time.   		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/4c20d5dc/attachment.htm>

From webmaster at squidblacklist.org  Thu Aug 18 01:12:17 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Wed, 17 Aug 2016 20:12:17 -0500
Subject: [squid-users] New Domain Blacklist Options...
Message-ID: <943fbc90-4a13-65e6-d091-98b5e39b157a@squidblacklist.org>

We heard you loud and clear, you wanted our enhanced blacklists in a 
similar archive/file structure as shallalist and urlblacklist for your 
web filtering platform, so we finally did it. Available now to all 
squidblacklist.org members is the new ?Universal Archive Structure 
Format? for any platform coded for shallalist or urlblacklist file 
structured archives, just copy and paste the link ( registration required ).

http://www.squidblacklist.org/downloads/squidblacklists/squidblacklist.tar.gz 



-- 
--

Signed,

Benjamin E. Nichols

http://www.squidblacklist.org



From erdosain9 at gmail.com  Thu Aug 18 02:06:37 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 17 Aug 2016 19:06:37 -0700 (PDT)
Subject: [squid-users] AD Ldap (automatically take the user that is
	logging on PC)
In-Reply-To: <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
Message-ID: <1471485997133-4679001.post@n4.nabble.com>

so.......... there is no way to do that with ldap?........................
:-(



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994p4679001.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rafael.akchurin at diladele.com  Thu Aug 18 03:36:12 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 18 Aug 2016 03:36:12 +0000
Subject: [squid-users] AD Ldap (automatically take the user that is
 logging on PC)
In-Reply-To: <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
Message-ID: <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Erdosain,

Here is how to configure it reusing your squid at example.lan<mailto:squid at example.lan> user (no samba).
http://docs.diladele.com/administrator_guide_4_6/active_directory/install_prerequisites_for_kerberos_authentication.html
Best regards,
Rafael


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of brendan kearney
Sent: Thursday, August 18, 2016 2:12 AM
To: erdosain9
Cc: Squid Users
Subject: Re: [squid-users] AD Ldap (automatically take the user that is logging on PC)


You want Kerberos and/or NTLM authentication for Single Sign On.  These authentication methods automatically provide credentials when browser are configured and the necessary network services are running.

On Aug 17, 2016 6:30 PM, "erdosain9" <erdosain9 at gmail.com<mailto:erdosain9 at gmail.com>> wrote:
lol
no, for all the ACL.
vip and control.......
that no users need to enter username and password ... (only to log on to the
PC, but do not have to put username and password in the browser)..........
for all.

(i dont speak english.........)



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994p4678996.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/447f2c2b/attachment.htm>

From squid3 at treenet.co.nz  Thu Aug 18 04:32:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 16:32:37 +1200
Subject: [squid-users] Squid 2.7.s9 HTTPS-proxying - hint welcome
In-Reply-To: <1471474841533-4678997.post@n4.nabble.com>
References: <20160817172352.3f19dc8f@BS2>
 <2162fa4d-41e1-81c1-12a2-7b99d2bd04aa@treenet.co.nz>
 <1471474841533-4678997.post@n4.nabble.com>
Message-ID: <b000d16b-ae3f-4a91-9cc9-1a2fb4fb018e@treenet.co.nz>

On 18/08/2016 11:00 a.m., Torsten Kuehn wrote:
> Thank you for your quick reply!
> 
> On 17/08/2016 6:01 p.m., Amos Jeffries wrote:
> 
>>> I am forced to stuck with 2.X
>> Then you cannot decrypt the HTTPS in order to cache it. Squid older than
>> 3.2 simply do not have any of the functionality to do so.
> 
> I.e. not cacheable at all?

Correct.

> May sound stupid but I imagine layouts where the
> encrypted traffic itself gets stored and a client could re-use it later.

There is no way for Squid to know what is contained inside the
encryption. Therefore no way to know if a previous encrypted stream is
reusable. To squid it is just a random stream of opaque bytes.


> 
>> Cache is not an archive. Everything in a cache is by definition *not*
>> valuable and subject to be erased at any time.
>> [...] "of personal value" data is at high risk of being erased with
>> every request sent through that proxy
> 
> Archiving is a different matter, no question. But I prefer not to erase
> objects from my cache, unless requested. My refresh_patterns etc. may look
> horrible for administrators who try to provide most recent content:
>     authenticate_ttl 359996400 seconds

Lookup "credentials replay attack". Thats what this enables. There is no
other use for this directive than attacking your clients. We have
dropped it in Squid-3.

Use the "auth_param ... credentialsttl" to extend credentials lifespan.
It is still not good to have large values there, but way better than the
global TTL feature.


>     hierarchy_stoplist cgi-bin
>     maximum_object_size 1073741824 bytes
>     refresh_pattern -i /cgi-bin/ 5258880 100% 5258880

Please use the pattern settings:  "-i (/cgi-bin/|\?) 0 0% 0"

This pattern is designed to work around an issue with truly ancient CGI
scripts that are so old or broken that they do not produce any
cache-control headers. Such scripts are guaranteed to be dynamically
changing but being so old /broken they are incapable of telling the
proxy what their outputs expiry should be. Thus we need to use 0's to be
sure its accurate.

NP: this does not affect ASP or PHP type dynamic CGI scripts used in
modern sites. These languages are new enough that the scripting engines
automatically add appropriate cache-controls and the 0 values do not get
used on their outputs.


>     refresh_pattern (Release|Packages(.gz)*)$ 0 20% 2880
>     refresh_pattern . 5258880 100% 5258880
>         override-expire override-lastmod ignore-no-cache ignore-private
>     positive_dns_ttl 359996400 seconds

Meaning whenever any domain name moves hosting service you get cutoff
from it completely for ~11 years or until you fully restart Squid.

When you go to Squid-3, removing both these DNS settings entirely would
be best. But if you really insist on caching the DNS positive results
for a long time ~48hrs should work just as well and be much safer as well.


>     negative_dns_ttl 60 seconds
>     vary_ignore_expire on
>     reload_into_ims on
> 
> This setup is that robust that both force-reload

This is done solely by "override-expire". The rest of your config is
unrelated. Even the "reload_into_ims" does nothing because Squid is
explicitly ignoring the max-age=0 value, aka. 'force reload'.


> and PURGE fail unless

In Squid-2 this is more efficiently done by:
 acl PURGE method PURGE
 http_access deny PURGE

Squid-3 does that automatically by default and even disables all the
PURGE functionality *unless* you have "PURGE" method in an ACL like
above. It is a good idea for performance reasons to remove all mention
of "PURGE" when upgrading to Squid-3.


> objects are deleted manually (resulting in "truncate: Warning: DosOpen
> Error 110, OPEN_FAILED, file ...") or the ugly "reload_into_ims on" option
> is set which violates standards.

reload_into_ims is not a violation of current HTTP/1.1 standards. It is
simply undefined behaviour - therefore a bit risky.

The big(est) problem with it is that Squid-2 is HTTP/1.0 software and
both reload and IMS revalidation are not defined in that version of the
protocol. Adding two risky undefined things together multiplies the
dangers. The risk being that the server or client is not properly doing
the revalidate actions in HTTP/1.0 messaging.



Overall the approach to caching *at any cost* is doing more harm than
good, both to yourself and to many others. I have seen far worse
configurations though.

The only really terrible things you are doing is the authenticate_ttl
and positive_dns_ttl values. They are not relevant to the HTTP caching
behaviour and are doing a huge amount of harm to you.


Amos



From squid3 at treenet.co.nz  Thu Aug 18 04:36:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 16:36:54 +1200
Subject: [squid-users] making 204s cachable again
In-Reply-To: <BAY173-W3CAA0130D6471B1EECD71BC150@phx.gbl>
References: <BAY173-W3CAA0130D6471B1EECD71BC150@phx.gbl>
Message-ID: <facd28a1-a088-43fd-5bd4-6dec6b7b086c@treenet.co.nz>

On 18/08/2016 12:29 p.m., Jim Ford wrote:
> I recently upgraded to Version 3.5.10.  I'm using it as a regular as

Please keep going. 3.5.20 is current and all releases older than 3.5.19
have security issues.

> well as a reverse proxy.  In both cases I've noticed that what were
> formerly cachable requests that resulted in a 204 response, are now
> always resulting in a MISS.  The only hits I'm getting are negative
> when the requests are close together.  Is there a configuration
> option I can use to force normal caching and have it obey the
> expiration?  I don't want to just increase the negative caching time.
> 
> 

What are the HTTP headers on those responses?

Amos



From squid3 at treenet.co.nz  Thu Aug 18 04:45:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 16:45:54 +1200
Subject: [squid-users] AD Ldap (automatically take the user that is
 logging on PC)
In-Reply-To: <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
Message-ID: <9fe12a37-5776-ec54-c21b-5b3263fcbf74@treenet.co.nz>

On 18/08/2016 12:11 p.m., brendan kearney wrote:
> You want Kerberos and/or NTLM authentication for Single Sign On.

That is a myth. SSO is simply a way of building the system so that the
credentials used for machine login work when sent to the proxy and other
services. If you don't build the system right even NTLM wont work as SSO.

It is up to the browser to send the credentials it can find using the
appropriate authentication scheme for any receiving services (ie the proxy).

NTLM and Kerberos take the Windows login credentials without translating
them. So "work" without fancy browser translation being needed is all.


IIRC, there is a setting somewhere called "Use Windows Integrated
Authentication" that sometimes has to be enabled for SSO to work with
non-Microsoft designed authentication schemes.

Amos



From squid3 at treenet.co.nz  Thu Aug 18 04:56:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 Aug 2016 16:56:26 +1200
Subject: [squid-users] stop caching completely on squid 3.5.2
In-Reply-To: <E065046A-83CF-4A30-8E08-31AC1C0A09A2@netstream.ps>
References: <E065046A-83CF-4A30-8E08-31AC1C0A09A2@netstream.ps>
Message-ID: <8ef88ea8-22a7-009a-5f71-2d6dc1dc2d92@treenet.co.nz>

On 18/08/2016 7:05 a.m., --Ahmad-- wrote:
> Hi 
> I?m  willing to stop caching on squid 3.5.2 on both memory & disk caching 
> 
> is the directive :
> cache deny all
> 
> sufficient for that ?

Almost. Squid will still allocate the memory cache RAM.

You will want to accompany it with "cache_mem 0" or maybe just a small
value for memory used if tat auses trouble.


PS. Please do upgrade to 3.5.20 or at least 3.5.19. A huge amount of
problems have been found and fixed during the 3.5 lifetime. We all would
prefer to avoid having to help re-solve difficult problems fixed a year
or more ago.

Amos



From brett.lymn at baesystems.com  Thu Aug 18 05:03:08 2016
From: brett.lymn at baesystems.com (LYMN)
Date: Thu, 18 Aug 2016 14:33:08 +0930
Subject: [squid-users] AD Ldap (automatically take the user that is
	logging on PC)
In-Reply-To: <9fe12a37-5776-ec54-c21b-5b3263fcbf74@treenet.co.nz>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
 <9fe12a37-5776-ec54-c21b-5b3263fcbf74@treenet.co.nz>
Message-ID: <20160818050308.GC23360@baea.com.au>

On Thu, Aug 18, 2016 at 04:45:54PM +1200, Amos Jeffries wrote:
> 
> IIRC, there is a setting somewhere called "Use Windows Integrated
> Authentication" that sometimes has to be enabled for SSO to work with
> non-Microsoft designed authentication schemes.
> 

Not in my experience - if you have "Use Windows Integrated
Authentication" (it is in the Advanced tab of the IE configuration,
under the security section) ticked then IE will just try Kerberos and
NTLM.  If your proxy supports neither (or the client isn't in the
kerberos realm) then IE will continually prompt for authentication and
not get anywhere.  If you untick that option then IE will try Basic
authentication.

-- 
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

    BAE Systems Australia Limited - Australian Company Number 008 423 005
    BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846
    BAE Systems Australia Logistics Pty Limited - Australian Company Number 086 228 864

Our registered office is Evans Building, Taranaki Road, Edinburgh Parks,
Edinburgh, South Australia, 5111. If the identity of the sending company is
not clear from the content of this email please contact the sender.

This email and any attachments may contain confidential and legally
privileged information.  If you are not the intended recipient, do not copy or
disclose its content, but please reply to this email immediately and highlight
the error to the sender and then immediately delete the message.



From steve at opendium.com  Thu Aug 18 09:18:35 2016
From: steve at opendium.com (Steve Hill)
Date: Thu, 18 Aug 2016 10:18:35 +0100
Subject: [squid-users] Checking SSL bump status in http_access
In-Reply-To: <8f934c8a-5dcf-7039-fe76-199840254616@measurement-factory.com>
References: <d0b96af9-b14c-54b3-4ffa-d4e072e5b03d@opendium.com>
 <3cc7a49f-c6cc-0f18-31cd-4b2c3cc6d5d5@treenet.co.nz>
 <8f934c8a-5dcf-7039-fe76-199840254616@measurement-factory.com>
Message-ID: <542c8640-b0ba-c86a-99c3-e2b982502343@opendium.com>

On 17/08/16 17:18, Alex Rousskov wrote:

> This configuration problem should be at least partially addressed by the
> upcoming annotate_transaction ACLs inserted into ssl_bump rules:
> http://lists.squid-cache.org/pipermail/squid-dev/2016-July/006146.html

That looks good.  When implementing this, beware the note in comment 3 
of bug 4340: http://bugs.squid-cache.org/show_bug.cgi?id=4340#c3
"for transparent connections, the NotePairs instance used during the 
step-1 ssl_bump ACL is not the same as the instance used during the 
http_access ACL, but for non-transparent connections they are the same 
instance.  The upshot is that any notes set by an external ACL when 
processing the ssl_bump ACL during step 1 are discarded when handling 
transparent connections."  - It would greatly reduce the functionality 
of your proposed ACLs if the annotations were sometimes discarded part 
way through a connection or request.

Something I've been wanting to do for a while is attach a unique 
"connection ID" and "request ID" to requests so that:
1. An ICAP server can make decisions about the connection (e.g. how to 
authenticate, whether to bump, etc.) and then refer back to the data it 
knows/generated about the connection when it processes the requests 
contained within that connection.
2. When multiple ICAP requests will be generated, they can be linked 
together by the ICAP server - e.g. where a single request will generate 
a REQMOD followed by a RESPMOD it would be good for the ICAP server to 
know which REQMOD and RESPMOD relate to the same request.

It sounds like your annotations plan may address this to some extent. 
(We can probably already do some of this by having the ICAP server 
generate unique IDs and store them in ICAP headers to be passed along 
with the request, but I think the bug mentioned above would cause those 
headers to be discarded mid-request in some cases)

-- 
  - Steve Hill
    Technical Director
    Opendium    Online Safety / Web Filtering    http://www.opendium.com

    Enquiries                 Support
    ---------                 -------
    sales at opendium.com        support at opendium.com
    +44-1792-824568           +44-1792-825748


From omidkosari at yahoo.com  Thu Aug 18 11:19:12 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Thu, 18 Aug 2016 04:19:12 -0700 (PDT)
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <47d89333-8d24-ae94-66dd-d04bc9dfcd63@treenet.co.nz>
References: <1471342982214-4678951.post@n4.nabble.com>
 <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>
 <1471425989455-4678966.post@n4.nabble.com>
 <47d89333-8d24-ae94-66dd-d04bc9dfcd63@treenet.co.nz>
Message-ID: <1471519152724-4679009.post@n4.nabble.com>

Amos Jeffries wrote
> About the only thing you could do to speed it up is locate the error
> page templates (file paths: en/ERR_INVALID_REQ and
> templates/ERR_INVALID_REQ) and remove their contents. Then restart Squid.
> That should remove at least a few of the vprintf() syscalls that your
> earlier trace showed as being a significant source of CPU load.

Fine. This resolved the problem .
Thanks


samples  %        image name               symbol name
190728   34.3901  squid                    /usr/sbin/squid
26003     4.6886  r8169                    /r8169
22958     4.1396  libc-2.23.so             _int_malloc
13812     2.4904  nf_conntrack             /nf_conntrack
11146     2.0097  libc-2.23.so             re_search_internal
11044     1.9913  libc-2.23.so             _int_free
8748      1.5774  libstdc++.so.6.0.21     
/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7240      1.3054  reiserfs                 /reiserfs
6087      1.0975  libc-2.23.so             malloc_consolidate
5850      1.0548  libc-2.23.so             malloc
4840      0.8727  libc-2.23.so             vfprintf
4468      0.8056  ip_tables                /ip_tables
4423      0.7975  libm-2.23.so             __ieee754_log_avx
4364      0.7869  libc-2.23.so             __memcpy_sse2_unaligned
3935      0.7095  kallsyms                 sys_epoll_ctl
3929      0.7084  libc-2.23.so             free
3829      0.6904  libc-2.23.so             build_upper_buffer
3562      0.6423  kallsyms                 __fget
3413      0.6154  kallsyms                 copy_user_generic_string
3169      0.5714  libc-2.23.so             calloc
2815      0.5076  kallsyms                 delay_tsc
2767      0.4989  kallsyms                 csum_partial_copy_generic
2739      0.4939  kallsyms                 tcp_sendmsg
2454      0.4425  kallsyms                 memcpy
2192      0.3952  libc-2.23.so             _wordcopy_fwd_dest_aligned
2139      0.3857  kallsyms                 _raw_spin_lock_irqsave
2108      0.3801  kallsyms                 _raw_spin_lock
2075      0.3741  kallsyms                 nf_iterate
1916      0.3455  libc-2.23.so             __memset_sse2
1900      0.3426  [vdso] (tgid:12101 range:0x7fff9fbca000-0x7fff9fbcbfff)
[vdso] (tgid:12101 range:0x7fff9fbca000-0x7fff9fbcbfff
)
1842      0.3321  libc-2.23.so             __strcmp_sse2_unaligned
1794      0.3235  kallsyms                 sock_poll
1753      0.3161  libc-2.23.so             strlen
1702      0.3069  kallsyms                 entry_SYSCALL_64_after_swapgs
1618      0.2917  kallsyms                 tcp_poll
1611      0.2905  kallsyms                 irq_entries_start
1593      0.2872  kallsyms                 ep_send_events_proc
1567      0.2825  kallsyms                 ___slab_alloc
1539      0.2775  kallsyms                 __local_bh_enable_ip
1523      0.2746  nf_conntrack_ipv4        /nf_conntrack_ipv4
1467      0.2645  libc-2.23.so             re_string_reconstruct
1455      0.2624  kallsyms                 tcp_transmit_skb
1425      0.2569  nf_nat_ipv4              /nf_nat_ipv4
1366      0.2463  kallsyms                 _raw_spin_lock_bh
1333      0.2404  kallsyms                 __alloc_skb
1319      0.2378  kallsyms                 mutex_spin_on_owner.isra.3
1313      0.2367  kallsyms                 tcp_recvmsg
1307      0.2357  kallsyms                 tcp_write_xmit
1279      0.2306  kallsyms                 __fget_light
1266      0.2283  libc-2.23.so             __memmove_sse2
1234      0.2225  libnettle.so.6.2        
/usr/lib/x86_64-linux-gnu/libnettle.so.6.2
1202      0.2167  kallsyms                 __inet_lookup_established
1177      0.2122  kallsyms                 __lock_text_start
1116      0.2012  kallsyms                 common_file_perm
1080      0.1947  kallsyms                 tcp_ack
1075      0.1938  kallsyms                 tcp_clean_rtx_queue
1046      0.1886  kallsyms                 tcp_v4_rcv





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Malformed-HTTP-on-tproxy-squid-tp4678951p4679009.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Thu Aug 18 12:53:41 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Thu, 18 Aug 2016 05:53:41 -0700 (PDT)
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
Message-ID: <1471524821802-4679021.post@n4.nabble.com>

Simply open following url in firefox
http://igcdn-photos-h-a.akamaihd.net/hphotos-ak-xap1/t51.2885-15/s640x640/sh0.08/e35/13702999_1008425479275495_76276919_n.jpg

then rename h to a,b,c,d,e,f for example

http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xap1/t51.2885-15/s640x640/sh0.08/e35/13702999_1008425479275495_76276919_n.jpg

According to my store_id rules it should be hit but it is not .

Even i am uncertain about if we open same exact url 2 times , is it hit in
second time ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679021.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From cbninin at gmail.com  Thu Aug 18 13:27:32 2016
From: cbninin at gmail.com (Claudio Ninin)
Date: Thu, 18 Aug 2016 10:27:32 -0300
Subject: [squid-users] FTP access with proxy_auth
Message-ID: <CAGOdWOjowaNmV3VBz=3+sVf0ntoLPCDfHMQ8_jeABM1Y7m_haA@mail.gmail.com>

Hi,

I need a help.
I'm trying configure to allow ftp acces across squid with the proxy_auth,
but when try access some ftp the squid doesn't get authentication.
This is my ACL:
#--------------------------------------------------------------------------------
### ACLs de liberacao do ftp
#--------------------------------------------------------------------------------
#acl usu-ftp src "/etc/squid/ips-ftp.cfg"
acl usu-ftp proxy_auth -i "/etc/squid/usu_ftp.cfg"
ftp_passive on
http_access allow ftp usu-ftp all
http_access allow CONNECT ftp_port usu-ftp all
http_access deny ftp

[image: Imagem inline 1]

[image: Imagem inline 2]

Can you help me?

Best regards,

Cl?udio Benelli Ninin
Analista de TI
Telefone: +55 16 3942-2106
Celular: +55 16 98824-2706
E-mail: cbninin at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/916b51b7/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5033 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/916b51b7/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 5504 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/916b51b7/attachment-0001.png>

From adego70 at gmail.com  Thu Aug 18 13:56:11 2016
From: adego70 at gmail.com (adego70 at gmail.com)
Date: Thu, 18 Aug 2016 15:56:11 +0200
Subject: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING CONNECTIONS
Message-ID: <011701d1f958$478dab00$d6a90100$@gmail.com>

Hello,

My request concerns SQUID v.3.4.8
I'm using :
 - DEBIAN Jessie
 - Firefox 48.0
 - simple home network

Actually, I whitelist some http(s) domains with SQUID.

My problem is :
when I want to go with firefox to any httpS domain which is not whitelisted,
I obtain this error message : "THE PROXY SERVER IS REFUSING CONNECTIONS"
(example :
"https://www.pntbrother.com/wp-content/uploads/2014/11/proxy_server_refusing
_connection.jpg ")
And I have to find a solution for showing the usual HTML error page from
SQUID (the page I can custom, example : "
http://cdn.krizna.com/wp-content/uploads/2012/08/squid_proxy_server_block.jp
g ")


Here is my "squid.conf" :
acl whitelist_prim dstdomain "/etc/squid3/whitelist_primaire"

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager

http_access allow whitelist_prim

http_access allow localhost
http_access deny all
http_port 3128
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320



Here is my " whitelist_primaire" file :
.google.com
.google.fr
.bing.com
.ubuntuforums.org
.squid-cache.org
.facebook.com

Here is the result of " sudo tail -f /var/log/squid3/access.log " for this
url https://www.waze.com :
1471512108.462      1 192.168.0.14 TCP_DENIED/403 3628 CONNECT
www.waze.com:443 - HIER_NONE/- text/html


I already try "deny_info" ( there
:http://digitizor.com/how-to-change-the-default-error-document-pages-in-squi
d/ ), but without success.

Is it possible to have a solution (with simple solution : ACLs...) for httpS
domains ?

Any advice will be appreciated.




From marciobacci at gmail.com  Thu Aug 18 14:08:35 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Thu, 18 Aug 2016 11:08:35 -0300
Subject: [squid-users] Kerberos Autenthication doesn't work
Message-ID: <CA+0TdyrtO_LATVRNKc4yRtOOxDtZeSPM6iwK9O-Rf4vto=sucQ@mail.gmail.com>

I have problems with Kerberos Autenthication in Squid3 on Debian 8 and
Samba4 DC
My Squid version is: 3.4.8

My Kerberos Autenthication doesn't work.

PROCEDURES PERFORMED

INSTALL OF SAMBA4 AND WINBIND OF DEBIAN BACKPORTS
apt-get -t jessie-backports install samba samba-doc winbind

KERBEROS TEST: kinit administrator at EMPRESA.COM.BR
klist -l
Principal Name                   Cache name
--------------                   ----------
administrator at EMPRESA.COM.BR     FILE:/tmp/krb5cc_0

JOIN IN THE DOMAIN: net ads join -U administrator
net ads testjoin: JOIN OK

kdestroy
KERBEROS TEST:kinit administrator at EMPRESA.COM.BR
klist -l
Principal Name                   Cache name
--------------                   ----------
administrator at EMPRESA.COM.BR     FILE:/tmp/krb5cc_0

STOP SERVICES
/etc/init.d/winbind stop
/etc/init.d/samba stop
update-rc.d winbind remove
update-rc.d samba remove

export KRB5_KTNAME=FILE:/etc/squid3/HTTP.keytab

INSTALL OF SQUID3: apt-get install squid3

export KRB5_KTNAME=FILE:/etc/squid3/HTTP.keytab
net ads keytab CREATE
net ads keytab ADD HTTP
unset KRB5_KTNAME

chgrp proxy /etc/squid3/HTTP.keytab
chmod g+r /etc/squid3/HTTP.keytab

/etc/init.d/squid3 restart

KRB5_KTNAME=/etc/squid3/HTTP.keytab
export KRB5_KTNAME
KRB5RCACHETYPE=none
export KRB5RCACHETYPE

/etc/init.d/squid3 restart


Below are my configuration files:

1) /etc/krb5.conf
[libdefaults]
default_realm = EMPRESA.COM.BR
dns_lookup_kdc = no
       dns_lookup_realm = no
       default_keytab_name = /etc/krb5.keytab

[realms]
EMPRESA.COM.BR = {
kdc = dc1.EMPRESA.COM.BR:88
admin_server = dc1.EMPRESA.COM.BR
default_domain = EMPRESA.COM.BR
}


[domain_realm]
.EMPRESA.COM.BR = EMPRESA.COM.BR
EMPRESA.COM.BR = EMPRESA.COM.BR

[logging]
  kdc = FILE:/var/log/kdc.log
  admin_server = FILE:/var/log/kadmin.log
  default = FILE:/var/log/krb5lib.log

2/etc/samba/smb.conf
[global]
  netbios name = proxy
  workgroup = EMPRESA
  security = ads
  realm = EMPRESA.COM.BR
  encrypt passwords = yes
  dedicated keytab file = /etc/krb5.keytab
  kerberos method = secrets and keytab
# password server = dc1.empresa.com.br
  preferred master = no
  idmap config *:backend = tdb
  idmap config *:range = 1000-3000
  idmap config EMPRESA:backend = ad
  idmap config EMPRESA:schema_mode = rfc2307
  idmap config EMPRESA:range = 10000-9999999

  winbind nss info = rfc2307
  winbind trusted domains only = no
  winbind use default domain = yes
  winbind enum users = yes
  winbind enum groups = yes
  winbind offline logon = yes
  winbind refresh tickets = yes

  vfs objects = acl_xattr
  map acl inherit = Yes
  store dos attributes = Yes
  username map = /etc/samba/user.map


3) /etc/squid3/squid.conf

### Configuracoes Basicas
http_port 3128

#debug_options ALL,111,2 29,9 84,6

cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90

maximum_object_size 512 MB
minimum_object_size 0 KB

maximum_object_size_in_memory 4096 KB

cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA

#Para n?o bloquear downloads
quick_abort_min -1 KB


#Resolve um problema com conexoes persistentes
detect_broken_pconn on

fqdncache_size 1024

### Parametros de atualizacao da memoria cache
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

### Localizacao dos logs
access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log


### define a localizacao do cache de disco, tamanho, qtd de diretorios pai
e subdiretorios
cache_dir aufs /var/spool/squid3 600 16 256

#auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth
auth_param negotiate children 10
auth_param negotiate keep_alive on

visible_hostname proxy.empresa.com.br

### acls
#acl manager proto cache_object
acl localhost src 192.168.200.7/32
acl to_localhost dst 192.168.200.7/32
acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, zimbra, webmin
acl Safe_ports port 21 # ftp
acl Safe_ports port 70 # gopher
acl Safe_ports port 80 # http
acl Safe_ports port 88 # kerberos
acl Safe_ports port 210 # wais
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 389 # ldap
acl Safe_ports port 443 # https
acl Safe_ports port 488 # gss-http
acl Safe_ports port 563 # snews
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl Safe_ports port 3001            # imprenssa nacional
acl Safe_ports port 8080 # http
acl Safe_ports port 1025-65535 # unregistered ports

acl purge method PURGE
acl CONNECT method CONNECT

### Regras iniciais do Squid
http_access allow localhost
http_access allow purge localhost
http_access deny purge
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

### Exige autenticacao
acl autenticados proxy_auth REQUIRED
http_access deny !autenticados

# acl ligada a autenticacao
acl grupo_admins proxy_auth "/etc/squid3/acls/usr-admins"

acl grupo_liberado proxy_auth "/etc/squid3/acls/usr-liberados"

#libera o grupo de administradores
http_access allow grupo_admins

### Bloqueia extensoes de arquivos
acl extensoes_bloqueadas url_regex -i "/etc/squid3/acls/extensoes-proibidas"

### Liberar alguns sites
acl sites_liberados url_regex -i "/etc/squid3/acls/sites-permitidos"

### Bloqueia sites por URL
acl sites_bloqueados url_regex -i "/etc/squid3/acls/sites-proibidos"

#bloqueios basicos
http_access allow sites_liberados
http_access deny extensoes_bloqueadas
http_access deny sites_bloqueados

# Libera acesso ao grupo de chefes e professores
http_access allow grupo_liberado

# Incorpora as regras do SquidGuard
redirect_program /usr/bin/squidGuard
redirect_children 20
redirector_bypass on

#libera o grupo de usuarios comuns apos passar por todos os bloqueios
http_access allow autenticados

### Rede do CMB #####
acl lannet src 192.168.200.0/22


### Nega acesso de quem nao esta na rede local
http_access allow lannet

#negando o acesso para todos que nao estiverem nas regras anteriores
http_access deny all

### Erros em portugues
error_directory /usr/share/squid3/errors/pt-br

#cache_effective_user proxy
coredump_dir /var/spool/squid3


Regards,

M?rcio Bacci
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/3ee1ce5a/attachment.htm>

From omidkosari at yahoo.com  Thu Aug 18 14:15:12 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Thu, 18 Aug 2016 07:15:12 -0700 (PDT)
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <1471524821802-4679021.post@n4.nabble.com>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
 <1471524821802-4679021.post@n4.nabble.com>
Message-ID: <1471529712673-4679025.post@n4.nabble.com>

I was correct .

If one of following conditions happens then the mentioned urls will not
cache .

1-in squid.conf have this line
acl storeiddomainregex dstdom_regex
^igcdn(\-photos|\-videos)[a-z0-9\-]{0,9}\.akamaihd\.net$ 

2-in storeid_db have this line
^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$)
http://instagramcdn.squid.internal/$1

IF 1 OR 2 THEN 
http://igcdn-photos-h-a.akamaihd.net/hphotos-ak-xap1/t51.2885-15/s640x640/sh0.08/e35/13702999_1008425479275495_76276919_n.jpg
will not cache at all even if we open that url for many times .

But if i remove 1 and 2 then the url will be cached .

My first email was incorrect because i realized that first url is hit but
second miss . The hit was from before store_id rules added .

Now the problem is with my mentioned squid.conf and store_id rules , the
mentioned urls will not cache at all.Even if same url reopens many times .

Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679025.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From steve at opendium.com  Thu Aug 18 14:45:32 2016
From: steve at opendium.com (Steve Hill)
Date: Thu, 18 Aug 2016 15:45:32 +0100
Subject: [squid-users] Checking SSL bump status in http_access
In-Reply-To: <3cc7a49f-c6cc-0f18-31cd-4b2c3cc6d5d5@treenet.co.nz>
References: <d0b96af9-b14c-54b3-4ffa-d4e072e5b03d@opendium.com>
 <3cc7a49f-c6cc-0f18-31cd-4b2c3cc6d5d5@treenet.co.nz>
Message-ID: <fc0c3ec7-a18d-411c-d513-e1b4b72380ee@opendium.com>

On 17/08/16 00:12, Amos Jeffries wrote:

>> Is there a way of figuring out if the current request is a bumped
>> request when the http_access ACL is being checked?  i.e. can we tell the
>> difference between a GET request that is inside a bumped tunnel, and an
>> unencrypted GET request?
>
> In Squid-3 a combo of the myportname and proto ACLs should do that.

I think when using a nontransparent proxy you can't tell the difference 
between:

1. HTTPS requests inside a bumped CONNECT tunnel, and
2. unencrypted "GET https://example.com/ HTTP/1.1" requests made 
directly to the proxy.


-- 
  - Steve Hill
    Technical Director
    Opendium    Online Safety / Web Filtering    http://www.opendium.com

    Enquiries                 Support
    ---------                 -------
    sales at opendium.com        support at opendium.com
    +44-1792-824568           +44-1792-825748


From steve at opendium.com  Thu Aug 18 14:48:41 2016
From: steve at opendium.com (Steve Hill)
Date: Thu, 18 Aug 2016 15:48:41 +0100
Subject: [squid-users] Rock store status
In-Reply-To: <1366914360.678396724.1471431010434.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1366914360.678396724.1471431010434.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <58f8bba2-c6e8-4f67-317e-6cdb4be89671@opendium.com>

On 17/08/16 11:50, FredB wrote:

> I tried rock store and smp long time ago (squid 3.2 I guess), Unfortunately I definitely drop smp because there are some limitations (In my case), and I fall-back to diskd because there were many bugs with rock store. FI I also switched to aufs without big differences.
>
> But now with the latest 3.5.20 ? Sadly SMP still not for me but rock store ?
>
> There is someone who are using rock store with a high load, more than 800 r/s, without any problem ? There is a real difference in this situation, cpu, speed, memory ?

We use SMP and Rock under the 3.5 series without problems.  But I don't 
think any of our sites have as high req/sec load as you.

-- 
  - Steve Hill
    Technical Director
    Opendium    Online Safety / Web Filtering    http://www.opendium.com

    Enquiries                 Support
    ---------                 -------
    sales at opendium.com        support at opendium.com
    +44-1792-824568           +44-1792-825748


From belle at bazuin.nl  Thu Aug 18 14:52:34 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 18 Aug 2016 16:52:34 +0200
Subject: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING CONNECTIONS
In-Reply-To: <011701d1f958$478dab00$d6a90100$@gmail.com>
References: <011701d1f958$478dab00$d6a90100$@gmail.com>
Message-ID: <vmime.57b5cbb2.16e9.65ee5de404551d2@ms249-lin-003.rotterdam.bazuin.nl>

That you proxy refused you connections is correct. 

You forgot to define an acl and allow it.  

Something like : 
acl internal-net 192.168.x.0/.24 

and 
> http_access allow localhost
http_access allow internal-net
> http_access deny all

Greetz, 

Louis


> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> adego70 at gmail.com
> Verzonden: donderdag 18 augustus 2016 15:56
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING CONNECTIONS
> Urgentie: Hoog
> 
> Hello,
> 
> My request concerns SQUID v.3.4.8
> I'm using :
>  - DEBIAN Jessie
>  - Firefox 48.0
>  - simple home network
> 
> Actually, I whitelist some http(s) domains with SQUID.
> 
> My problem is :
> when I want to go with firefox to any httpS domain which is not
> whitelisted,
> I obtain this error message : "THE PROXY SERVER IS REFUSING CONNECTIONS"
> (example :
> "https://www.pntbrother.com/wp-
> content/uploads/2014/11/proxy_server_refusing
> _connection.jpg ")
> And I have to find a solution for showing the usual HTML error page from
> SQUID (the page I can custom, example : "
> http://cdn.krizna.com/wp-
> content/uploads/2012/08/squid_proxy_server_block.jp
> g ")
> 
> 
> Here is my "squid.conf" :
> acl whitelist_prim dstdomain "/etc/squid3/whitelist_primaire"
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> 
> http_access allow whitelist_prim
> 
> http_access allow localhost

> http_access deny all
> http_port 3128
> coredump_dir /var/spool/squid3
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> 
> 
> 
> Here is my " whitelist_primaire" file :
> .google.com
> .google.fr
> .bing.com
> .ubuntuforums.org
> .squid-cache.org
> .facebook.com
> 
> Here is the result of " sudo tail -f /var/log/squid3/access.log " for this
> url https://www.waze.com :
> 1471512108.462      1 192.168.0.14 TCP_DENIED/403 3628 CONNECT
> www.waze.com:443 - HIER_NONE/- text/html
> 
> 
> I already try "deny_info" ( there
> :http://digitizor.com/how-to-change-the-default-error-document-pages-in-
> squi
> d/ ), but without success.
> 
> Is it possible to have a solution (with simple solution : ACLs...) for
> httpS
> domains ?
> 
> Any advice will be appreciated.
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Thu Aug 18 14:54:36 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 Aug 2016 08:54:36 -0600
Subject: [squid-users] Checking SSL bump status in http_access
In-Reply-To: <542c8640-b0ba-c86a-99c3-e2b982502343@opendium.com>
References: <d0b96af9-b14c-54b3-4ffa-d4e072e5b03d@opendium.com>
 <3cc7a49f-c6cc-0f18-31cd-4b2c3cc6d5d5@treenet.co.nz>
 <8f934c8a-5dcf-7039-fe76-199840254616@measurement-factory.com>
 <542c8640-b0ba-c86a-99c3-e2b982502343@opendium.com>
Message-ID: <1b7cea2f-203c-6390-b50d-d8a52c0bcefc@measurement-factory.com>

On 08/18/2016 03:18 AM, Steve Hill wrote:
> On 17/08/16 17:18, Alex Rousskov wrote:
>> This configuration problem should be at least partially addressed by the
>> upcoming annotate_transaction ACLs inserted into ssl_bump rules:
>> http://lists.squid-cache.org/pipermail/squid-dev/2016-July/006146.html

> http://bugs.squid-cache.org/show_bug.cgi?id=4340#c3
> any notes set by an external ACL when
> processing the ssl_bump ACL during step 1 are discarded when handling
> transparent connections.

Annotations lifetime is a different problem IMO. If somebody needs
[more] connection annotations, they should extend existing clt_conn_tag
support to arbitrary key=value pairs, probably by adding a configuration
option that names connection-scope keys.

If somebody needs a third annotation lifetime scope, they should propose
to add support for it. For example:

1. Supported: HTTP request (including fake CONNECTs);
2. Supported: Client connection;
3. Proposed:  Compound transaction (e.g., all authenticatING requests
plus the first authenticatED request that follows them; all fake
CONNECTs plus the first bumped HTTP request that follows them).

Needless to say, compelling use cases must be presented to justify this
addition/complication along with a firm definition of which individual
transactions belong to the new scope, keeping the "HTTP is stateless"
mantra in mind.


> It would greatly reduce the functionality
> of your proposed ACLs if the annotations were sometimes discarded part
> way through a connection or request.

This is a separate issue, but annotations set by annotate_client ACL
will persist for the client connection lifetime and annotations set by
annotate_transaction ACL will persist for the transaction lifetime
(e.g., a single fake CONNECT request). See above if you need a
different/new lifetime scope. I recommend avoiding the term "request"
for labeling that new scope even if it is convenient for you to think of
all fake CONNECT requests as a single request.


> Something I've been wanting to do for a while is attach a unique
> "connection ID" and "request ID" to requests

Yes, we already do that (in clients and servers) for testing purposes.
And some adaptation services do that to match responses with requests,
as you have mentioned. Adding that support to Squid would be a useful
feature. Official support must account for SMP needs and restarts, but
it is certainly doable.


Cheers,

Alex.



From rousskov at measurement-factory.com  Thu Aug 18 14:56:53 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 Aug 2016 08:56:53 -0600
Subject: [squid-users] Checking SSL bump status in http_access
In-Reply-To: <1b7cea2f-203c-6390-b50d-d8a52c0bcefc@measurement-factory.com>
References: <d0b96af9-b14c-54b3-4ffa-d4e072e5b03d@opendium.com>
 <3cc7a49f-c6cc-0f18-31cd-4b2c3cc6d5d5@treenet.co.nz>
 <8f934c8a-5dcf-7039-fe76-199840254616@measurement-factory.com>
 <542c8640-b0ba-c86a-99c3-e2b982502343@opendium.com>
 <1b7cea2f-203c-6390-b50d-d8a52c0bcefc@measurement-factory.com>
Message-ID: <1b65f359-0859-ec04-5e49-d16548c59c83@measurement-factory.com>

On 08/18/2016 08:54 AM, Alex Rousskov wrote:
> 1. Supported: HTTP request (including fake CONNECTs);

To clarify, s/fake CONNECTs/a single fake CONNECT/

> 2. Supported: Client connection;

> 3. Proposed:  Compound transaction (e.g., all authenticatING requests
> plus the first authenticatED request that follows them; all fake
> CONNECTs plus the first bumped HTTP request that follows them).

Alex.



From eliezer at ngtech.co.il  Thu Aug 18 14:59:53 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 18 Aug 2016 17:59:53 +0300
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <1471529712673-4679025.post@n4.nabble.com>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
 <1471524821802-4679021.post@n4.nabble.com>
 <1471529712673-4679025.post@n4.nabble.com>
Message-ID: <00c001d1f961$2d31fe10$8795fa30$@ngtech.co.il>

Well it works for me locally:
1471532262.544      3 192.168.10.131 TCP_MEM_HIT/200 72214 GET http://igcdn-photos-a-a.akamaihd.net/hphotos-ak-xap1/t51.2885-15/s640x640/sh0.08/e35/13702999_1008425479275495_76276919_n.jpg - HIER_NONE/- image/jpeg
1471532274.903      9 192.168.10.131 TCP_MEM_HIT/200 72215 GET http://igcdn-photos-h-a.akamaihd.net/hphotos-ak-xap1/t51.2885-15/s640x640/sh0.08/e35/13702999_1008425479275495_76276919_n.jpg - HIER_NONE/- image/jpeg

Try to open a "private" or incognito window and see what happens.
Also try to download the file using wget or curl via the proxy.
See what happens..
I am using the default refresh_pattern rules of squid ie :
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Thursday, August 18, 2016 5:15 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Yet another store_id question HIT MISS

I was correct .

If one of following conditions happens then the mentioned urls will not
cache .

1-in squid.conf have this line
acl storeiddomainregex dstdom_regex
^igcdn(\-photos|\-videos)[a-z0-9\-]{0,9}\.akamaihd\.net$ 

2-in storeid_db have this line
^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$)
http://instagramcdn.squid.internal/$1

IF 1 OR 2 THEN 
http://igcdn-photos-h-a.akamaihd.net/hphotos-ak-xap1/t51.2885-15/s640x640/sh0.08/e35/13702999_1008425479275495_76276919_n.jpg
will not cache at all even if we open that url for many times .

But if i remove 1 and 2 then the url will be cached .

My first email was incorrect because i realized that first url is hit but
second miss . The hit was from before store_id rules added .

Now the problem is with my mentioned squid.conf and store_id rules , the
mentioned urls will not cache at all.Even if same url reopens many times .

Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679025.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From belle at bazuin.nl  Thu Aug 18 15:26:44 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 18 Aug 2016 17:26:44 +0200
Subject: [squid-users] Kerberos Autenthication doesn't work
In-Reply-To: <CA+0TdyrtO_LATVRNKc4yRtOOxDtZeSPM6iwK9O-Rf4vto=sucQ@mail.gmail.com>
References: <CA+0TdyrtO_LATVRNKc4yRtOOxDtZeSPM6iwK9O-Rf4vto=sucQ@mail.gmail.com>
Message-ID: <vmime.57b5d3b4.2467.126f91ec5ad51cf4@ms249-lin-003.rotterdam.bazuin.nl>

Ok, samba isnt yet in jessie backports.. so you now use the 4.2.10 version. 

?

Look here, these work good. 

I build them and i use them in my office for some time now. ?

I?ll try the next version samba ( 4.4.5-3 ) in debian stretch to get in BPO. 

That one has the file overwrite fixed. (just read the readme.txt it explains all) 

?

Here you find a signed by me samba 4.4.5 ( amd64 and i386 packages for jessie )

http://downloads.van-belle.nl/samba4/ 

Again, please do read the readme.txt? 

?

?

This part. 

STOP SERVICES

/etc/init.d/winbind stop

/etc/init.d/samba stop

update-rc.d winbind remove

update-rc.d samba remove

?

Dont remove winbind/samba inits. you need that to refresh the keytabs.

only winbind for keytab refresh is sufficient. 

?

?

KRB5_KTNAME=/etc/squid3/HTTP.keytab

export KRB5_KTNAME

KRB5RCACHETYPE=none

export KRB5RCACHETYPE

Add that in /etc/default/squid3 ?and try not to change default init.d debian files. 

The /etc/default/squid3 is included in the init script. 

?

?

Enable the kerberos auth line in you squid conf.

auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s HTTP/proxy.empresa.com.br at EMPRESA.COM.BR

?

check both you keytabs, since Im not sure about your keytab files. 

Check where the HTTP SPN is defined. 

klist -k /etc/krb5.keytab 

klist -k /etc/squid3/HTTP.keytab

?

Try with these settings. 

1) /etc/krb5.conf

[libdefaults]

?? default_realm = EMPRESA.COM.BR

?? dns_lookup_kdc = yes

? ?dns_lookup_realm = no

?

then if that works, change it back to your needs. 

?

?

You can check if you get users out of winbind

wbinfo ?u 

if that works, set these lines to no, not needed for squid. 

? winbind enum users = yes

? winbind enum groups = yes

?

Try with these changes first. 

?

And last you did configure samba AD DC with ssl support? If not. 

Enable the old behavior. 

More info about that here : 

https://www.samba.org/samba/history/samba-4.4.2.html 

?

?

Greetz, 

?

Louis

?

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Marcio Demetrio Bacci
Verzonden: donderdag 18 augustus 2016 16:09
Aan: Squid Users
Onderwerp: [squid-users] Kerberos Autenthication doesn't work


?

I have problems with Kerberos Autenthication in Squid3 on Debian 8 and Samba4 DC


My Squid version is: 3.4.8


?


My Kerberos Autenthication doesn't work.


?


PROCEDURES PERFORMED


?


INSTALL OF SAMBA4 AND WINBIND OF DEBIAN BACKPORTS


apt-get -t jessie-backports install samba samba-doc winbind


?


KERBEROS TEST: kinit administrator at EMPRESA.COM.BR


klist -l


Principal Name ? ? ? ? ? ? ? ? ? Cache name


-------------- ? ? ? ? ? ? ? ? ? ----------


administrator at EMPRESA.COM.BR ? ? FILE:/tmp/krb5cc_0


?


JOIN IN THE DOMAIN: net ads join -U administrator?


net ads testjoin: JOIN OK


?


kdestroy


KERBEROS TEST:kinit administrator at EMPRESA.COM.BR


klist -l


Principal Name ? ? ? ? ? ? ? ? ? Cache name


-------------- ? ? ? ? ? ? ? ? ? ----------


administrator at EMPRESA.COM.BR ? ? FILE:/tmp/krb5cc_0


?


STOP SERVICES


/etc/init.d/winbind stop


/etc/init.d/samba stop


update-rc.d winbind remove


update-rc.d samba remove


?


export KRB5_KTNAME=FILE:/etc/squid3/HTTP.keytab


?


INSTALL OF SQUID3: apt-get install squid3


?


export KRB5_KTNAME=FILE:/etc/squid3/HTTP.keytab


net ads keytab CREATE


net ads keytab ADD HTTP


unset KRB5_KTNAME


?


chgrp proxy /etc/squid3/HTTP.keytab?


chmod g+r /etc/squid3/HTTP.keytab?


?


/etc/init.d/squid3 restart


?


KRB5_KTNAME=/etc/squid3/HTTP.keytab


export KRB5_KTNAME


KRB5RCACHETYPE=none


export KRB5RCACHETYPE


?


/etc/init.d/squid3 restart


?


?


Below are my configuration files:


?


1) /etc/krb5.conf


[libdefaults]


?? default_realm = EMPRESA.COM.BR


?? dns_lookup_kdc = no


? ? ? ?dns_lookup_realm = no


? ? ? ?default_keytab_name = /etc/krb5.keytab


?


[realms]


?? EMPRESA.COM.BR = {


?? kdc = dc1.EMPRESA.COM.BR:88


?? admin_server = dc1.EMPRESA.COM.BR


?? default_domain = EMPRESA.COM.BR?


?? }


?


?


[domain_realm]


?? .EMPRESA.COM.BR = EMPRESA.COM.BR


?? EMPRESA.COM.BR = EMPRESA.COM.BR


?


[logging]


? kdc = FILE:/var/log/kdc.log


? admin_server = FILE:/var/log/kadmin.log


? default = FILE:/var/log/krb5lib.log


?


2/etc/samba/smb.conf


[global]


? netbios name = proxy?


? workgroup = EMPRESA


? security = ads?


? realm = EMPRESA.COM.BR?


? encrypt passwords = yes


? dedicated keytab file = /etc/krb5.keytab


? kerberos method = secrets and keytab


# password server = dc1.empresa.com.br


? preferred master = no


? idmap config *:backend = tdb


? idmap config *:range = 1000-3000


? idmap config EMPRESA:backend = ad


? idmap config EMPRESA:schema_mode = rfc2307


? idmap config EMPRESA:range = 10000-9999999


?


? winbind nss info = rfc2307


? winbind trusted domains only = no


? winbind use default domain = yes


? winbind enum users = yes


? winbind enum groups = yes


? winbind offline logon = yes


? winbind refresh tickets = yes


?


? vfs objects = acl_xattr


? map acl inherit = Yes


? store dos attributes = Yes


? username map = /etc/samba/user.map?


?


?


3) /etc/squid3/squid.conf


?


### Configuracoes Basicas


http_port 3128


?


#debug_options ALL,111,2 29,9 84,6


?


cache_mem 512 MB


cache_swap_low 80


cache_swap_high 90


?


maximum_object_size 512 MB


minimum_object_size 0 KB


?


maximum_object_size_in_memory 4096 KB


?


cache_replacement_policy heap LFUDA


memory_replacement_policy heap LFUDA


?


#Para n?o bloquear downloads


quick_abort_min -1 KB


?


?


#Resolve um problema com conexoes persistentes


detect_broken_pconn on


?


fqdncache_size 1024


?


### Parametros de atualizacao da memoria cache


refresh_pattern ^ftp:?? 1440?? 20%?? 10080


refresh_pattern ^gopher:?? 1440?? 0%?? 1440


refresh_pattern -i (/cgi-bin/|\?) 0 0%??? 0


refresh_pattern .????? 0?? 20%?? 4320


?


### Localizacao dos logs


access_log /var/log/squid3/access.log


cache_log /var/log/squid3/cache.log


?


?


### define a localizacao do cache de disco, tamanho, qtd de diretorios pai e subdiretorios


cache_dir aufs /var/spool/squid3 600 16 256


?


#auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth


auth_param negotiate children 10


auth_param negotiate keep_alive on


?


visible_hostname proxy.empresa.com.br


?


### acls


#acl manager proto cache_object


acl localhost src MailScanner warning: numerical links are often malicious: 192.168.200.7/32


acl to_localhost dst MailScanner warning: numerical links are often malicious: 192.168.200.7/32


acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, zimbra, webmin


acl Safe_ports port 21?????? # ftp


acl Safe_ports port 70?????? # gopher


acl Safe_ports port 80?????? # http


acl Safe_ports port 88?????? # kerberos


acl Safe_ports port 210 ??????# wais


acl Safe_ports port 280?????? # http-mgmt


acl Safe_ports port 389?????? # ldap


acl Safe_ports port 443?????? # https


acl Safe_ports port 488?????? # gss-http


acl Safe_ports port 563?????? # snews


acl Safe_ports port 591?????? # filemaker


acl Safe_ports port 777?????? # multiling http


acl Safe_ports port 3001 ? ? ? ? ? ?# imprenssa nacional


acl Safe_ports port 8080?????? # http


acl Safe_ports port 1025-65535??? # unregistered ports


?


acl purge method PURGE


acl CONNECT method CONNECT


?


### Regras iniciais do Squid


http_access allow localhost


http_access allow purge localhost


http_access deny purge


http_access deny !Safe_ports


http_access deny CONNECT !SSL_ports


?


### Exige autenticacao


acl autenticados proxy_auth REQUIRED


http_access deny !autenticados


?


# acl ligada a autenticacao


acl grupo_admins proxy_auth "/etc/squid3/acls/usr-admins"


?


acl grupo_liberado proxy_auth "/etc/squid3/acls/usr-liberados"


?


#libera o grupo de administradores


http_access allow grupo_admins


?


### Bloqueia extensoes de arquivos


acl extensoes_bloqueadas url_regex -i "/etc/squid3/acls/extensoes-proibidas"


?


### Liberar alguns sites


acl sites_liberados url_regex -i "/etc/squid3/acls/sites-permitidos"


?


### Bloqueia sites por URL


acl sites_bloqueados url_regex -i "/etc/squid3/acls/sites-proibidos"


?


#bloqueios basicos


http_access allow sites_liberados


http_access deny extensoes_bloqueadas


http_access deny sites_bloqueados?


?


# Libera acesso ao grupo de chefes e professores


http_access allow grupo_liberado


?


# Incorpora as regras do SquidGuard


redirect_program /usr/bin/squidGuard


redirect_children 20


redirector_bypass on


?


#libera o grupo de usuarios comuns apos passar por todos os bloqueios


http_access allow autenticados


?


### Rede do CMB #####


acl lannet src MailScanner warning: numerical links are often malicious: 192.168.200.0/22?


?


?


### Nega acesso de quem nao esta na rede local?


http_access allow lannet?


?


#negando o acesso para todos que nao estiverem nas regras anteriores


http_access deny all


?


### Erros em portugues


error_directory /usr/share/squid3/errors/pt-br


?


#cache_effective_user proxy


coredump_dir /var/spool/squid3


?


?


Regards,


?


M?rcio Bacci




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/b80baccd/attachment.htm>

From rousskov at measurement-factory.com  Thu Aug 18 23:39:43 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 Aug 2016 17:39:43 -0600
Subject: [squid-users] Malformed HTTP on tproxy squid
In-Reply-To: <988adebc-9743-c429-6dfd-bca93fb54f77@measurement-factory.com>
References: <1471342982214-4678951.post@n4.nabble.com>
 <014101d1f866$af3a9620$0dafc260$@ngtech.co.il>
 <1471425989455-4678966.post@n4.nabble.com>
 <47d89333-8d24-ae94-66dd-d04bc9dfcd63@treenet.co.nz>
 <34b9a680-f2cb-8709-e141-4041af19b39b@measurement-factory.com>
 <a9912a8c-d8de-ff6f-3af2-584988eaf7e5@treenet.co.nz>
 <988adebc-9743-c429-6dfd-bca93fb54f77@measurement-factory.com>
Message-ID: <62d1fd7d-24ee-ccc8-39b7-f0aeffc67973@measurement-factory.com>

On 08/17/2016 10:47 AM, Alex Rousskov wrote:
> On 08/17/2016 10:25 AM, Amos Jeffries wrote:
> 
>> I don't think the delayer approach will work because these are parse
>> error/abort responses that don't go near any ACL system.
> 
> If an error response does not go through http_reply_access, then this is
> a Squid bug IMO.

In my primitive test, an error:invalid-request response does go through
the http_reply_access rules, as expected:

2016/08/17 16:10:11.206| 88,2| client_side_reply.cc(2049)
processReplyAccessResult: The reply for NONE error:invalid-request is
ALLOWED

Alex.



From squid3 at treenet.co.nz  Fri Aug 19 01:05:15 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Aug 2016 13:05:15 +1200
Subject: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING CONNECTIONS
In-Reply-To: <vmime.57b5cbb2.16e9.65ee5de404551d2@ms249-lin-003.rotterdam.bazuin.nl>
References: <011701d1f958$478dab00$d6a90100$@gmail.com>
 <vmime.57b5cbb2.16e9.65ee5de404551d2@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <53cd6c2d-e8aa-0f0c-2af7-6038bd862abb@treenet.co.nz>

On 19/08/2016 2:52 a.m., L.P.H. van Belle wrote:
> That you proxy refused you connections is correct. 
> 
> You forgot to define an acl and allow it.  
> 

Aye. Compare the default config file with yours:

  <http://wiki.squid-cache.org/Squid-3.5>

(the 3.5 one still applies to 3.4)

Amos



From squid3 at treenet.co.nz  Fri Aug 19 01:37:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Aug 2016 13:37:13 +1200
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <1471529712673-4679025.post@n4.nabble.com>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
 <1471524821802-4679021.post@n4.nabble.com>
 <1471529712673-4679025.post@n4.nabble.com>
Message-ID: <4879fbd5-f12c-5127-3363-aad590e87ba5@treenet.co.nz>

On 19/08/2016 2:15 a.m., Omid Kosari wrote:
> I was correct .
> 
> If one of following conditions happens then the mentioned urls will not
> cache .
> 
> 1-in squid.conf have this line
> acl storeiddomainregex dstdom_regex
> ^igcdn(\-photos|\-videos)[a-z0-9\-]{0,9}\.akamaihd\.net$ 
> 

How you use that ACL in your access rule logics is just as important as
what it contains / matches.


> 2-in storeid_db have this line
> ^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$)
> http://instagramcdn.squid.internal/$1


The pattern is malformed. Several parts of it are impossible to match,
and just make it look complicated when its not.

It is better written as:

^http:\/\/igcdn-[a-z0-9\-\.]+\.akamaihd\.net/hphotos-ak-[a-z0-9]+/(t5.*)
  http://instagramcdn.squid.internal/$2


> 
> Now the problem is with my mentioned squid.conf and store_id rules , the
> mentioned urls will not cache at all.Even if same url reopens many times .
> 

Store-ID does not force caching. All it does is provide Squid with a
different ID under which the item would be stored *IF* (and only if) it
would be stored normally.

I suggest removing the "ignore-no-store ignore-private" from your
.squid.internal refresh_pattern. They trigger actions that break the
image objects you actually want to store at that Store-ID location.

Amos



From marciobacci at gmail.com  Fri Aug 19 01:50:23 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Thu, 18 Aug 2016 22:50:23 -0300
Subject: [squid-users] Problems with Squid Authentication
Message-ID: <CA+0TdyoUrAQ_nnG4+EoUwRABfXseOCSF_d80W1wqohxNy1a_WA@mail.gmail.com>

My Kerberos Authentication doesn't work. This is very hard!

My Squid3 is join in the Domain
kinit and klist are ok
wbinfo -g and wbinfo -u are ok too.

I have created the squid3 file in /etc/default with the following content:
KRB5_KTNAME=/etc/squid3/HTTP.keytab
export KRB5_KTNAME

I have two keytab files:
/etc/krb5.keytab and /etc/squid3/HTTP.keytab (both are identical)

I have installed libsasl2-modules-gssapi-mit libsasl2-modules packages
because my Squid server is Debian 8. But I didn't use msktutil tool. I have
only joined Squid server in the Domain (net ads join -U administrator)

How can I debbug the problem?
How can I test kerberos authentication in terminal (command line)?

Below is my squid.conf file:

### Configuracoes Basicas

cache_mgr administrator at empresa.com.br

http_port 3128

#debug_options ALL,111,2 29,9 84,6

cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90

maximum_object_size 512 MB
minimum_object_size 0 KB

maximum_object_size_in_memory 4096 KB

cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA

#Para n?o bloquear downloads
quick_abort_min -1 KB


#Resolve um problema com conexoes persistentes
detect_broken_pconn on

fqdncache_size 1024

### Parametros de atualizacao da memoria cache
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

### Localizacao dos logs
access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log


### define a localizacao do cache de disco, tamanho, qtd de diretorios pai
e subdiretorios
cache_dir aufs /var/spool/squid3 600 16 256

auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -s
HTTP/proxy.empresa.com.br at EMPRESA.COM.BR
auth_param negotiate children 20
auth_param negotiate keep_alive on

visible_hostname proxy.empresa.com.br

### acls
#acl manager proto cache_object
acl localhost src 192.168.200.7/32
acl to_localhost dst 192.168.200.7/32
acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, zimbra, webmin
acl Safe_ports port 21 # ftp
acl Safe_ports port 70 # gopher
acl Safe_ports port 80 # http
acl Safe_ports port 88 # kerberos
acl Safe_ports port 210 # wais
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 389 # ldap
acl Safe_ports port 443 # https
acl Safe_ports port 488 # gss-http
acl Safe_ports port 563 # snews
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl Safe_ports port 3001         # imprenssa nacional
acl Safe_ports port 8080 # http
acl Safe_ports port 1025-65535 # unregistered ports

acl purge method PURGE
acl CONNECT method CONNECT


### Regras iniciais do Squid
http_access allow localhost
http_access allow purge localhost
http_access deny purge
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

### Exige autenticacao
acl autenticados proxy_auth REQUIRED
http_access allow autenticados



### Rede do Local #####
acl rede_local src 192.168.200.0/22


### Nega acesso de quem nao esta na rede local
http_access allow rede_local

#negando o acesso para todos que nao estiverem nas regras anteriores
http_access deny all

### Erros em portugues
error_directory /usr/share/squid3/errors/pt-br

#cache_effective_user proxy
coredump_dir /var/spool/squid3


Regards,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/6646775b/attachment.htm>

From harisrind284 at gmail.com  Fri Aug 19 07:28:07 2016
From: harisrind284 at gmail.com (sallo baloch)
Date: Fri, 19 Aug 2016 12:28:07 +0500
Subject: [squid-users] training
Message-ID: <CAKikXHqu=f2FtEuP5AdSTqstf7VBcwAcokXkSEYc-UGs+rh1iA@mail.gmail.com>

dear

sir how to learn squid proxy from scratch
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/a25cd2a4/attachment.htm>

From fredbmail at free.fr  Fri Aug 19 07:45:01 2016
From: fredbmail at free.fr (FredB)
Date: Fri, 19 Aug 2016 09:45:01 +0200 (CEST)
Subject: [squid-users] Rock store status
In-Reply-To: <58f8bba2-c6e8-4f67-317e-6cdb4be89671@opendium.com>
Message-ID: <1004492469.685148441.1471592701223.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> We use SMP and Rock under the 3.5 series without problems.  But I
> don't
> think any of our sites have as high req/sec load as you.

Thanks for your answer

Please can you describe your load and configurations ?
No crash ?

Fred


From ano31415926535 at gmail.com  Fri Aug 19 09:06:07 2016
From: ano31415926535 at gmail.com (John Akhaice)
Date: Fri, 19 Aug 2016 18:06:07 +0900
Subject: [squid-users] Squid automatically deleted the
	Proxy-Authenticate header
In-Reply-To: <e8ef5d9a-8691-bfe9-694b-06efecabcc81@treenet.co.nz>
References: <CANBbT7AT9-sGZrW1i1m9X3H5EoRztUP-5=t88AUOxGJUYYDKeg@mail.gmail.com>
 <CANBbT7CAZgobsG=RoM+gb11mrcKeucOe794u_0WBP=C+gnkKHw@mail.gmail.com>
 <e8ef5d9a-8691-bfe9-694b-06efecabcc81@treenet.co.nz>
Message-ID: <CANBbT7DUr5g5=x+k-D5Edn8dOO7_XEZqtPwU3+FNruvXwvfPvQ@mail.gmail.com>

Thank you for appling the patch to squid-4.
I look forward to new version of the squid-3.5.

And thank you very much for your prompt response.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/0b45f236/attachment.htm>

From belle at bazuin.nl  Fri Aug 19 10:02:42 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 19 Aug 2016 12:02:42 +0200
Subject: [squid-users] Problems with Squid Authentication
In-Reply-To: <CA+0TdyoUrAQ_nnG4+EoUwRABfXseOCSF_d80W1wqohxNy1a_WA@mail.gmail.com>
References: <CA+0TdyoUrAQ_nnG4+EoUwRABfXseOCSF_d80W1wqohxNy1a_WA@mail.gmail.com>
Message-ID: <vmime.57b6d942.77ba.4578e4ce3f59062@ms249-lin-003.rotterdam.bazuin.nl>

Hai,

?

Yes, all new things are hard..

I need some extra info because there are lots of things that can be wrong. 

?

post what you see here : 

/usr/lib/squid/negotiate_kerberos_auth -s HTTP/proxy.empresa.com.br at EMPRESA.COM.BR ?d ?i 

?

?

>> kinit and klist are ok

>> /etc/krb5.keytab and /etc/squid3/HTTP.keytab (both are identical)

These are normaly not identical. In the HTTPkeytab i have ONLY the HTTP spn. 

And in the krb5.keytab i? have the host SPN and netbios_name($)? 

?

How to test the kerberos auth.. hmm, thats a difficult one for me. 

I know lot but not all..? :-(? .

?

But what i do iknow, you can test with

/usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME 

If that works its probely an SPN or dns problem.

If that isnt working, then do check the time on the ad server and proxy server.

?

I can only say. 

The proxy servername must exist in dns and must have A and PTR record. ?( add this in the samba AD ) 

The reverse zone is ( maybe ) created, if not, create it yourself and add the ptr records. 

?

Cat /etc/hosts file may NOT contain any. 

127.0.1.1??????? yourhostname.. ..? 

if its in there, you installed with dhcp ip. 

?

It should contain 

127.0.0.1????????? ??? localhost 

IP_OF_SERVER?? hostname.domain.tld hostname

The is there if you install with a static ip. 

?

Time must be in sync with the AD server ( max difference i allow is 1 min. ) 

If needed install ntp on the proxy and point the server ?to the ad dc. 

?

And post what you now have in krb5.conf 

?

These are the most common pitfalls, i?ll see what i can do to help out. 

?

?

Greetz, 

?

Louis

?

?

?

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Marcio Demetrio Bacci
Verzonden: vrijdag 19 augustus 2016 3:50
Aan: Squid Users
Onderwerp: [squid-users] Problems with Squid Authentication


?

My Kerberos Authentication doesn't work. This is very hard!


?


My Squid3 is join in the Domain


kinit and klist are ok


wbinfo -g and wbinfo -u are ok too.


?


I have created the squid3 file in /etc/default with the following content:?


KRB5_KTNAME=/etc/squid3/HTTP.keytab


export KRB5_KTNAME


?


I have two keytab files:


/etc/krb5.keytab and /etc/squid3/HTTP.keytab (both are identical)


?


I have installed libsasl2-modules-gssapi-mit libsasl2-modules packages because my Squid server is Debian 8. But I didn't use msktutil tool. I have only joined Squid server in the Domain (net ads join -U administrator)


?


How can I debbug the problem?


How can I test kerberos authentication in terminal (command line)?


?


Below is my squid.conf file:


?


### Configuracoes Basicas


?


cache_mgr administrator at empresa.com.br


?


http_port 3128


?


#debug_options ALL,111,2 29,9 84,6


?


cache_mem 512 MB


cache_swap_low 80


cache_swap_high 90


?


maximum_object_size 512 MB


minimum_object_size 0 KB


?


maximum_object_size_in_memory 4096 KB


?


cache_replacement_policy heap LFUDA


memory_replacement_policy heap LFUDA


?


#Para n?o bloquear downloads


quick_abort_min -1 KB


?


?


#Resolve um problema com conexoes persistentes


detect_broken_pconn on


?


fqdncache_size 1024


?


### Parametros de atualizacao da memoria cache


refresh_pattern ^ftp:?? 1440?? 20%?? 10080


refresh_pattern ^gopher:?? 1440?? 0%?? 1440


refresh_pattern -i (/cgi-bin/|\?) 0 0%??? 0


refresh_pattern .????? 0?? 20%?? 4320


?


### Localizacao dos logs


access_log /var/log/squid3/access.log


cache_log /var/log/squid3/cache.log


?


?


### define a localizacao do cache de disco, tamanho, qtd de diretorios pai e subdiretorios


cache_dir aufs /var/spool/squid3 600 16 256


?


auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -s HTTP/proxy.empresa.com.br at EMPRESA.COM.BR


auth_param negotiate children 20


auth_param negotiate keep_alive on


?


visible_hostname proxy.empresa.com.br


?


### acls


#acl manager proto cache_object


acl localhost src MailScanner warning: numerical links are often malicious: 192.168.200.7/32


acl to_localhost dst MailScanner warning: numerical links are often malicious: 192.168.200.7/32


acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, zimbra, webmin


acl Safe_ports port 21?????? # ftp


acl Safe_ports port 70?????? # gopher


acl Safe_ports port 80?????? # http


acl Safe_ports port 88?????? # kerberos


acl Safe_ports port 210?????? # wais


acl Safe_ports port 280?????? # http-mgmt


acl Safe_ports port 389?????? # ldap


acl Safe_ports port 443??? # https


acl Safe_ports port 488?????? # gss-http


acl Safe_ports port 563?????? # snews


acl Safe_ports port 591?????? # filemaker


acl Safe_ports port 777?????? # multiling http


acl Safe_ports port 3001 ? ? ? ? # imprenssa nacional


acl Safe_ports port 8080??? # http


acl Safe_ports port 1025-65535??? # unregistered ports


?


acl purge method PURGE


acl CONNECT method CONNECT


?


?


### Regras iniciais do Squid


http_access allow localhost


http_access allow purge localhost


http_access deny purge


http_access deny !Safe_ports


http_access deny CONNECT !SSL_ports


?


### Exige autenticacao


acl autenticados proxy_auth REQUIRED


http_access allow autenticados


?


?


?


### Rede do Local #####


acl rede_local src MailScanner warning: numerical links are often malicious: 192.168.200.0/22?


?


?


### Nega acesso de quem nao esta na rede local


http_access allow rede_local?


?


#negando o acesso para todos que nao estiverem nas regras anteriores


http_access deny all


?


### Erros em portugues


error_directory /usr/share/squid3/errors/pt-br


?


#cache_effective_user proxy


coredump_dir /var/spool/squid3


?


?


Regards,


?


M?rcio




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/381d99e8/attachment.htm>

From tekuehn at web.de  Fri Aug 19 10:42:56 2016
From: tekuehn at web.de (Torsten Kuehn)
Date: Fri, 19 Aug 2016 03:42:56 -0700 (PDT)
Subject: [squid-users] Squid 2.7.s9 HTTPS-proxying - hint welcome
In-Reply-To: <b000d16b-ae3f-4a91-9cc9-1a2fb4fb018e@treenet.co.nz>
References: <20160817172352.3f19dc8f@BS2>
 <2162fa4d-41e1-81c1-12a2-7b99d2bd04aa@treenet.co.nz>
 <1471474841533-4678997.post@n4.nabble.com>
 <b000d16b-ae3f-4a91-9cc9-1a2fb4fb018e@treenet.co.nz>
Message-ID: <1471603376992-4679041.post@n4.nabble.com>

Hi,

On 18/08/2016 6:32 a.m., Amos Jeffries wrote:

>> I imagine layouts where the encrypted traffic itself gets stored
> no way for Squid to know if a previous encrypted stream is reusable.
> To squid it is just a random stream of opaque bytes.

Enlightening! The idea was that omitting decryption but instead providing
measures to do so from the client's side had less concerns wrt privacy.
As I see, with a mere "stream of opaque bytes", any "handle" to provide
such measures is missing. Thus, if caching of SSL-encrypted data is wished,
decryption is mandatory.

>> I.e. [HTTPS] not cacheable at all [in 2.7.s9]?
> Correct.

Asking months earlier here would have saved me painful failures ...

>> I prefer not to erase objects [...] My [TAGs] may look horrible
>>     authenticate_ttl 359996400 seconds
> Lookup "credentials replay attack". [...] There is no other use for
> this directive than attacking your clients.

Uugh! Was set in april 2012, by error (without effect in 2.5.s8_OS2_VAC,
thus
it didn't harm): the idea was to turn off Squid's garbage collection, in
order
to avoid wearing out flash memory. Wrong place, and I ignored credentials
...

>>     hierarchy_stoplist cgi-bin
>>     refresh_pattern -i /cgi-bin/ 5258880 100% 5258880
> Please use the pattern settings:  "-i (/cgi-bin/|\?) 0 0% 0"
> This pattern is designed to work around an issue with truly ancient CGI
> scripts [...] Such scripts are guaranteed to be dynamically changing [...]

The idea comes from http://twiki.cern.ch/twiki/bin/view/CMS/MyOwnSquid ,
to get dynamic web pages cached. I am glad that Squid finally does so!
Conflicting concepts, as it seems. Or, is there any RegEx which does the
old CGI script-workaround but still caches content with "?" in URLs?

>>     refresh_pattern . 5258880 100% 5258880
>>         override-expire override-lastmod ignore-no-cache ignore-private
>>     positive_dns_ttl 359996400 seconds
> Meaning whenever any domain name moves hosting service you get cutoff
> from it completely for ~11 years or until you fully restart Squid.

Yes, I noticed this :-) (Used to reconfigure Squid from CacheMgr in these
cases). Came from Sjoerd Visser's dutch page on Squid 1.1, to work around
it's missing offline_mode TAG (just kept positive_dns_ttl afterwards):
http://vissesh.home.xs4all.nl/multiboot/firewall/squid.html

> When you go to Squid-3, removing both these DNS settings entirely would
> be best. [...] if you really insist [...] ~48hrs should work just as well

Truely. When I set up 2.5.s8_OS2_VAC six years ago, I just added a few new
TAGs to my old 1.1 config. Only this summer, I spent a couple of days to
migrate previous settings into the new order of a fresh 2.7.s9's config (for
better comparison), now comprising a history of all available OS/2 builds
(introduction/ disappearance of features etc.). To be re-done with 3.5.

>> setup is that robust that force-reload [fails unless objects deleted]
> This is done solely by "override-expire".

Perfect. I'm far from knowing config TAGs by heart and thus don't see how
things play together. Enabling "overide-expire" in 2012 was a bad thing.

>> [setup that robust that] PURGE fails unless [objects deleted manually]
> In Squid-2 this is more efficiently done by:
>   acl PURGE method PURGE
>   http_access deny PURGE

Recently enabled (as well as CacheMgr-access) by setting
    acl localnet src 192.168.0.160/27
    [...]
    acl purge method PURGE
    http_access allow purge localnet
    http_access allow purge localhost
    http_access deny purge

> Squid-3 [...] disables all the PURGE functionality *unless* you have
> "PURGE" method in an ACL like above. It is a good idea for performance
> reasons to remove all mention of "PURGE" when upgrading to Squid-3.

Permitting PURGE has a performance impact? I enabled it recently, but
since reload works now, it could be suppressed.

>> [force-reload fails unless] the ugly "reload_into_ims on" option
>> is set which violates standards.
> reload_into_ims is not a violation of current HTTP/1.1 standards. [...]
> The big(est) problem with it is that Squid-2 is HTTP/1.0 software and
> both reload and IMS revalidation are not defined in that version of the
> protocol. Adding two risky undefined things together multiplies dangers.
> [...] Overall the approach to caching *at any cost* is doing more harm
> than good, both to yourself and to many others.

Disquieting. In fact, I tried to change Squid's default caching behaviour
to "accumulating" content ("once here, why to reload redundant stuff?").
The second, important intention behind this is not to wear out the flash
memory where Squid runs on. Data is backed up regularily, but I'm afraid
of, e.g., the regular revalidation processes's write accesses. (A friend
lost a solid state disk with a Squid cache after only six months.)

Suggestions for a proper compromise welcome.

Regards  Torsten Kuehn, Weil am Rhein/ Basle



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-s9-HTTPS-proxying-hint-welcome-tp4678986p4679041.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From steve at opendium.com  Fri Aug 19 10:48:39 2016
From: steve at opendium.com (Steve Hill)
Date: Fri, 19 Aug 2016 11:48:39 +0100
Subject: [squid-users] Rock store status
In-Reply-To: <1004492469.685148441.1471592701223.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1004492469.685148441.1471592701223.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <5d227f1b-e1e9-b8cb-c70a-9aeed3b90691@opendium.com>

On 19/08/16 08:45, FredB wrote:

> Please can you describe your load and configurations ?

We supply Squid based online safety systems to schools across the UK, 
utilising Rock store for caching and peek/splice, external ACLs and ICAP 
for access control/filtering/auditing.  Typically I think our biggest 
schools probably top out at around 400,000 requests/hour, but I don't 
have any hard data to hand to back that up at the moment.

The only serious Squid issue we've been tracking recently is the memory 
leak associated with spliced connections, which we've now fixed (and 
submitted patches).  That said, with the schools currently on holiday 
those fixes haven't yet been well tested on real-world servers - we'll 
find out if there are any issues with them when term starts again :)

-- 
  - Steve Hill
    Technical Director
    Opendium    Online Safety / Web Filtering    http://www.opendium.com

    Enquiries                 Support
    ---------                 -------
    sales at opendium.com        support at opendium.com
    +44-1792-824568           +44-1792-825748


From adego70 at gmail.com  Fri Aug 19 11:37:42 2016
From: adego70 at gmail.com (adego70 at gmail.com)
Date: Fri, 19 Aug 2016 13:37:42 +0200
Subject: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING
Message-ID: <03b101d1fa0e$19de72f0$4d9b58d0$@gmail.com>

Thank you for your help (both L.P.H. van Belle & Amos Jeffries).

I changed my squid.conf but now, I don't obtain any url deny...
In fact, any http & https url are allowed even if they not in whitelist_primaire.
I made many tests but I can't find the good way...
Please find enclosed the conf for Firefox.

My new conf :
http_port 3128
acl localnet src 192.168.0.0/24 # RFC 1918 local private network (LAN)

acl SSL_ports port 443

acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 1025-65535  # unregistered ports

acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager


acl whitelist_prim dstdomain "/etc/squid3/whitelist_primaire"
http_access deny !whitelist_prim

http_access allow localnet
http_access allow localhost
http_access deny all

coredump_dir /var/spool/squid3

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320








-------------- next part --------------
A non-text attachment was scrubbed...
Name: 45852.png
Type: image/png
Size: 22990 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/dc6209e5/attachment.png>

From belle at bazuin.nl  Fri Aug 19 13:26:40 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 19 Aug 2016 15:26:40 +0200
Subject: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING
In-Reply-To: <03b101d1fa0e$19de72f0$4d9b58d0$@gmail.com>
References: <03b101d1fa0e$19de72f0$4d9b58d0$@gmail.com>
Message-ID: <vmime.57b70910.6a64.500edf706f3210@ms249-lin-003.rotterdam.bazuin.nl>

Hm, beside the order, it looks good. 

?

So if i understand correct, you want to deny everything except whats in your whitelist_primaire file.? 

?

Than ?take this copy of my home config, and i adjusted to your settings already. 

so you should be able to copy past this. ;-) ?

it mostly a default file 

?

for the learning process. Look where i put your rules and look at the order. 

?

?

#--------------FROM HERE ---------------------------

acl SSL_ports port 443

?

acl Safe_ports port 80????????? # http

acl Safe_ports port 21????????? # ftp

acl Safe_ports port 443???????? # https

acl Safe_ports port 70????????? # gopher

acl Safe_ports port 210???????? # wais

acl Safe_ports port 280???????? # http-mgmt

acl Safe_ports port 488???????? # gss-http

acl Safe_ports port 591???????? # filemaker

acl Safe_ports port 777???????? # multiling http

acl Safe_ports port 1025-65535? # unregistered ports

acl CONNECT method CONNECT

?

# own ACL rules

acl localnet src 192.168.0.0/24 # RFC 1918 local private network (LAN)

?

# and maybe also add : acl localnet src 192.168.1.0/24 # RFC 1918 local private network (LAN)

#

# OR acl localnet src 192.168.0.0/23 # RFC 1918 local private network (LAN)

# since i see 192.168.0.0 and 192.168.1.x in you mails. 

?

# acl to explicit allowed sites.

acl whitelist_prim dstdomain "/etc/squid3/whitelist_primaire"

?

## To always block ads, put them above all other rules. 

## optional block advertising site rules here. ?

## https://calomel.org/squid_adservers.html 

?

#

# Recommended minimum Access Permission configuration:

#

# Deny requests to certain unsafe ports

http_access deny !Safe_ports

?

# Deny CONNECT to other than secure SSL ports

http_access deny CONNECT !SSL_ports

?

# Only allow cachemgr access from localhost

http_access allow localhost manager

http_access deny manager

?

# We strongly recommend the following be uncommented to protect innocent

# web applications running on the proxy server who think the only

# one who can access services on "localhost" is a local user

http_access deny to_localhost

?

#

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

?

# ?Allow sites in whitelist_primaire 

http_access allow whitelist_prim

?

# Deny sites not in whitelist_primaire 

http_access deny !whitelist_prim

?

# Example rule allowing access from your local networks.

# Adapt localnet in the ACL section to list your (internal) IP networks

# from where browsing should be allowed

http_access allow localnet

http_access allow localhost

?

# And finally deny all other access to this proxy

http_access deny all

?

# other rules

?

http_port 192.168.0.28:3128

?

cache_mem 512 MB

maximum_object_size_in_memory 1024 KB

?

cache_dir ufs /var/spool/squid3 5000 16 256

?

###################################

## If /dev/null is specified to any of the above log files,

## logfile rotate MUST also be set to 0 or else risk Squid

## rotating away /dev/null making it a plain log file

######################################

access_log daemon:/var/log/squid3/access.log squid

#access_log none

cache_log /var/log/squid3/cache.log

#cache_log /dev/null

cache_store_log /var/log/squid3/cache.log

#cache_store_log none

#######################################

?

coredump_dir /var/spool/squid3

# change this to you country code the "nl" to .. 

error_directory /usr/share/squid-langpack/nl

?

pinger_enable off

?

?

#

# Add any of your own refresh_pattern entries above these.

#

refresh_pattern ^ftp:?????????? 1440??? 20%???? 10080

refresh_pattern ^gopher:??????? 1440??? 0%????? 1440

refresh_pattern -i (/cgi-bin/|\?) 0???? 0%????? 0

refresh_pattern .?????????????? 0?????? 20%???? 4320

?

httpd_suppress_version_string on

?

?

#--------------TO ?HERE ---------------------------

?

Greetz, 

?

Louis

?

?

> -----Oorspronkelijk bericht-----

> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens

> adego70 at gmail.com

> Verzonden: vrijdag 19 augustus 2016 13:38

> Aan: squid-users at lists.squid-cache.org

> Onderwerp: Re: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING

> 

> Thank you for your help (both L.P.H. van Belle & Amos Jeffries).

> 

> I changed my squid.conf but now, I don't obtain any url deny...

> In fact, any http & https url are allowed even if they not in

> whitelist_primaire.

> I made many tests but I can't find the good way...

> Please find enclosed the conf for Firefox.

> 

> My new conf :

> http_port 3128

> acl localnet src 192.168.0.0/24 # RFC 1918 local private network (LAN)

> 

> acl SSL_ports port 443

> 

> acl Safe_ports port 80????????? # http

> acl Safe_ports port 21????????? # ftp

> acl Safe_ports port 443???????? # https

> acl Safe_ports port 70????????? # gopher

> acl Safe_ports port 210???????? # wais

> acl Safe_ports port 280???????? # http-mgmt

> acl Safe_ports port 488???????? # gss-http

> acl Safe_ports port 591???????? # filemaker

> acl Safe_ports port 777???????? # multiling http

> acl Safe_ports port 1025-65535? # unregistered ports

> 

> acl CONNECT method CONNECT

> 

> http_access deny !Safe_ports

> http_access deny CONNECT !SSL_ports

> http_access allow localhost manager

> http_access deny manager

> 

> 

> acl whitelist_prim dstdomain "/etc/squid3/whitelist_primaire"

> http_access deny !whitelist_prim

> 

> http_access allow localnet

> http_access allow localhost

> http_access deny all

> 

> coredump_dir /var/spool/squid3

> 

> refresh_pattern ^ftp:?????????? 1440??? 20%???? 10080

> refresh_pattern ^gopher:??????? 1440??? 0%????? 1440

> refresh_pattern -i (/cgi-bin/|\?) 0???? 0%????? 0

> refresh_pattern .?????????????? 0?????? 20%???? 4320

> 

?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/11dceed9/attachment.htm>

From erdosain9 at gmail.com  Fri Aug 19 15:20:11 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 19 Aug 2016 08:20:11 -0700 (PDT)
Subject: [squid-users] AD Ldap (automatically take the user that is
	logging on PC)
In-Reply-To: <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
 <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <1471620011751-4679045.post@n4.nabble.com>

Hi.
Could give me a link for configuring Kerberos (Heimdal) ???.
I can not find tutorials about it.

Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994p4679045.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Aug 19 15:43:16 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 19 Aug 2016 21:43:16 +0600
Subject: [squid-users] AD Ldap (automatically take the user that is
 logging on PC)
In-Reply-To: <1471620011751-4679045.post@n4.nabble.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
 <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <1471620011751-4679045.post@n4.nabble.com>
Message-ID: <78607b31-cdb0-3c02-d76b-f247fdd02dc7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
https://www.google.com/search?q=Kerberos+%28Heimdal%29+configuring


19.08.2016 21:20, erdosain9 ?????:
> Kerberos (Heimdal)

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXtykTAAoJENNXIZxhPexG3yUH/3wOl8nd6OAtfWVcCKYvDqFS
A2aAiVLmSQRxAkr1LB5+FEaCk1ogoDUGgnB8J9+QKW/PIRLEZZvGmjF8azFBE5EA
68uqCfU5X1IA1jUIJKb5QZTjTx1ChQ7Q9R9ncWhksbiKfiVh1jLD9Xjkk/YjmHT3
B87UJ9eMWBdUXPo3GdMWlGfX9imcr+/cSXDH8f4xAb4Cwg+tS7hvVPfKRpfl147I
3+OJhrPkQVmFQXIanxn23KGPntDO8qZD8nIFDJpW+m2wqi7BY5aUi49lksiV6DhB
L0olut+MoxqrDMlTBaMV7lfE/sCk+VAp3h9JUxr7vkbi0FwWke4wSe3S7cDZ3zo=
=BqEK
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/d3bc2908/attachment.key>

From adego70 at gmail.com  Fri Aug 19 16:07:28 2016
From: adego70 at gmail.com (adego70 at gmail.com)
Date: Fri, 19 Aug 2016 18:07:28 +0200
Subject: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING CONNECTIONS
Message-ID: <03ef01d1fa33$c941e4f0$5bc5aed0$@gmail.com>

Thank you VERY MUCH L.P.H. van Belle !

 

I tried with or without changes but I don't have good result :

I still have " THE PROXY SERVER IS REFUSING CONNECTIONS" for https
websites...

I can't understand why it doesn't work.

Is it working on your side ?

 

Another information, maybe it's important : my squid is installed on a
dedicated computer. Then the IP of SQUID is different than the IP of my
firefox. 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/95274e98/attachment.htm>

From sebelk at gmail.com  Fri Aug 19 16:33:36 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Fri, 19 Aug 2016 13:33:36 -0300
Subject: [squid-users] DENIED and ALLOWED at once?
Message-ID: <CABZC=5zu1F_-garY7XiKQeoCDNAheiQcDNcEsp0UQ-XQhoidig@mail.gmail.com>

Hi,

I've configured squid 3.5.19 to allow only AD authenticated users, the
strange thing I've found is that the same domain is both denied and
allowed.

In some browsers I had problem with yahoo.com that won't load correctly the
pages. Besides that, I used squidanalyzer, and it's a problem that count
some urls as denied when most of cases is allowed:

## Log files

/var/log/squid/access.log
192.168.50.41 - - [19/Aug/2016:12:19:45 -0300] "CONNECT
beap-bc.yahoo.com:443 HTTP/1.1" 407 4634 "-" "Mozilla/5.0 (Windows NT 6.1;
WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TCP_DENIED:HIER_NONE
192.168.50.41 - juan.perez [19/Aug/2016:12:19:45 -0300] "CONNECT
beap-bc.yahoo.com:443 HTTP/1.1" 200 0 "-" "Mozilla/5.0 (Windows NT 6.1;
WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TAG_NONE:HIER_DIRECT

## /var/log/squid/cache.log

It's long so you can take a look at
http://pastebin.com/P2Ey6XcH

Please could you explain me?

## Configuration:

etc/squid/squid.conf:

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl nobumpSites ssl::server_name "/etc/squid/acls/nobumpSites.txt"
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
acl social_ips dst "/etc/squid/acls/social_ips"
acl social_dom dstdomain "/etc/squid/acls/social_dom"
acl whitelist_ips src "/etc/squid/acls/whitelist_ips"
auth_param negotiate program /usr/lib64/squid/negotiate_wrapper_auth -d
--ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp
--domain=EXAMPLE --kerberos /usr/lib64/squid/negotiate_kerberos_auth -d -s
GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive on
acl kerb_auth proxy_auth REQUIRED
ssl_bump peek step1 all               # at step 1 we're peeking at client
TLS-request in order to find the "SNI"
ssl_bump peek step2 nobumpSites       # here we're peeking at server
certificate
ssl_bump splice step3 nobumpSites     # here we're splicing connections
which match the whitelist
ssl_bump stare step2                  # here we're staring at server
certificate
ssl_bump bump step3                   # finally we're bumping all other SSL
connections at step 3
http_access allow localhost
http_access deny  !kerb_auth
http_access allow kerb_auth whitelist_ips
http_access deny social_ips
http_access deny social_dom
acl numeric_IPs urlpath_regex ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+
acl connect method CONNECT
http_access deny connect numeric_IPs all
http_access allow localnet
http_access deny all
always_direct allow all
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB
visible_hostname kanban.example.local
http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=6MB cert=/etc/squid/ssl_cert/myCA.pem
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
url_rewrite_program /usr/sbin/ufdbgclient ?l /var/ufdbguard/logs
url_rewrite_children 64
access_log daemon:/var/log/squid/access.log combined
logformat combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
"%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh %mt
debug_options ALL,1 33,2 28,9

EOF

Thanks in advance!

-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/da71b27e/attachment.htm>

From erdosain9 at gmail.com  Fri Aug 19 18:16:21 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 19 Aug 2016 11:16:21 -0700 (PDT)
Subject: [squid-users] AD Ldap (automatically take the user that is
	logging on PC)
In-Reply-To: <78607b31-cdb0-3c02-d76b-f247fdd02dc7@gmail.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
 <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <1471620011751-4679045.post@n4.nabble.com>
 <78607b31-cdb0-3c02-d76b-f247fdd02dc7@gmail.com>
Message-ID: <1471630581076-4679049.post@n4.nabble.com>

:-)
lol

This is the krb5.conf in the AD. 
[libdefaults]
        default_realm = EPRUEBA.LAN
        dns_lookup_realm = false
        dns_lookup_kdc = true
~                                

just that.
the admin of the AD, tell me that squid need to authenticate with Kerberos
to have all other config setting.... what do you think about it?? as if the
info was in the database AD... 

Thanks!





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994p4679049.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From je at ktf.rtu.lv  Fri Aug 19 18:23:17 2016
From: je at ktf.rtu.lv (=?utf-8?b?SsSBbmlz?=)
Date: Fri, 19 Aug 2016 21:23:17 +0300
Subject: [squid-users] communication with parent proxy using ssl
Message-ID: <20160819212317.Horde.Oy646hpz8x6jh4-w1Li8Eg1@inbox.dv.lv>

Hi!

may someone suggest some solution for traffic encryption between the  
parent and "child" proxy based on squid's own functionality?

Solution involving stunnel is clear.

Janis


From jok at spikes.com  Fri Aug 19 18:41:11 2016
From: jok at spikes.com (Jok Thuau)
Date: Fri, 19 Aug 2016 11:41:11 -0700
Subject: [squid-users] DENIED and ALLOWED at once?
In-Reply-To: <CABZC=5zu1F_-garY7XiKQeoCDNAheiQcDNcEsp0UQ-XQhoidig@mail.gmail.com>
References: <CABZC=5zu1F_-garY7XiKQeoCDNAheiQcDNcEsp0UQ-XQhoidig@mail.gmail.com>
Message-ID: <CADSSinNTVG4_diOHMKpp+1wp=Q5D6X5nz8E_2cEfupachczidA@mail.gmail.com>

On Fri, Aug 19, 2016 at 9:33 AM, Sergio Belkin <sebelk at gmail.com> wrote:

> /var/log/squid/access.log
> 192.168.50.41 - - [19/Aug/2016:12:19:45 -0300] "CONNECT
> beap-bc.yahoo.com:443 HTTP/1.1" 407 4634 "-" "Mozilla/5.0 (Windows NT
> 6.1; WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TCP_DENIED:HIER_NONE
>

This is "unauthenticated (notice the "- -" after the IP)


> 192.168.50.41 - juan.perez [19/Aug/2016:12:19:45 -0300] "CONNECT
> beap-bc.yahoo.com:443 HTTP/1.1" 200 0 "-" "Mozilla/5.0 (Windows NT 6.1;
> WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TAG_NONE:HIER_DIRECT
>
>
This one is authenticated (juan.perez). The code 407 in the first request
means "proxy request authentication". So what happened here is that the
user browsed, was asked for credentials (and maybe those were provided
automatically), and then the request was resent with the creds included.


http_access deny  !kerb_auth
> http_access allow kerb_auth whitelist_ips
>

And here is the config that causes that -- it's totally normal...

Thanks,
Jok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160819/5587e203/attachment.htm>

From yvoinov at gmail.com  Fri Aug 19 18:54:59 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 20 Aug 2016 00:54:59 +0600
Subject: [squid-users] AD Ldap (automatically take the user that is
 logging on PC)
In-Reply-To: <1471630581076-4679049.post@n4.nabble.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
 <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <1471620011751-4679045.post@n4.nabble.com>
 <78607b31-cdb0-3c02-d76b-f247fdd02dc7@gmail.com>
 <1471630581076-4679049.post@n4.nabble.com>
Message-ID: <bfed0fbc-084b-2fb1-d35f-5342e13678ec@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Sorry, this is not to me.

My setups works without any authentication, just transparent
interception. :)


20.08.2016 0:16, erdosain9 ?????:
> :-)
> lol
>
> This is the krb5.conf in the AD.
> [libdefaults]
>         default_realm = EPRUEBA.LAN
>         dns_lookup_realm = false
>         dns_lookup_kdc = true
> ~                               
>
> just that.
> the admin of the AD, tell me that squid need to authenticate with Kerberos
> to have all other config setting.... what do you think about it?? as
if the
> info was in the database AD...
>
> Thanks!
>
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994p4679049.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXt1YBAAoJENNXIZxhPexGm0MIAJMcEr7V9/b21jFgKO0xZsQC
IlxaCXlgCN53yd0OTymXDNr5YIkRUMDRr50e3s7fiWGxvIKcS/8VXGOyNA7pqSMH
wg28gbQ51UWiTmG19bW0yBusRs2W7WX4WxjCxM4BzNfGSsjfwWX/sdRSWy7nIHvI
jB630x5UP0NZ/X1231ENhh74HLkoBhcwK2WU4LzqRJTVE5aOpVskLGKeng50JWkk
XvUBVQlpHhv7QADTZXJZoiva675oin1XWKxutib25y8WL05sif1qChwBtQOp+w2c
/F74akFCnjdMy3zpUiwrCxIvXlIbzrJJpwic9SJIG1DRK3QOM9GhXYZDdDC7uhc=
=S9V3
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160820/7d16eae2/attachment.key>

From erdosain9 at gmail.com  Fri Aug 19 19:13:58 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 19 Aug 2016 12:13:58 -0700 (PDT)
Subject: [squid-users] AD Ldap (automatically take the user that is
	logging on PC)
In-Reply-To: <bfed0fbc-084b-2fb1-d35f-5342e13678ec@gmail.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
 <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <1471620011751-4679045.post@n4.nabble.com>
 <78607b31-cdb0-3c02-d76b-f247fdd02dc7@gmail.com>
 <1471630581076-4679049.post@n4.nabble.com>
 <bfed0fbc-084b-2fb1-d35f-5342e13678ec@gmail.com>
Message-ID: <1471634038246-4679053.post@n4.nabble.com>

For eg., in all the config that i read is necessary a file call something
like squid.keytab...
its possible just make a user in AD like "squid", and then just log the
squid in the Ad??? or is mandatory generating this file???
thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994p4679053.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Fri Aug 19 20:22:20 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 19 Aug 2016 22:22:20 +0200
Subject: [squid-users] DENIED and ALLOWED at once?
In-Reply-To: <CADSSinNTVG4_diOHMKpp+1wp=Q5D6X5nz8E_2cEfupachczidA@mail.gmail.com>
References: <CABZC=5zu1F_-garY7XiKQeoCDNAheiQcDNcEsp0UQ-XQhoidig@mail.gmail.com>
 <CADSSinNTVG4_diOHMKpp+1wp=Q5D6X5nz8E_2cEfupachczidA@mail.gmail.com>
Message-ID: <201608192222.20884.Antony.Stone@squid.open.source.it>

On Friday 19 August 2016 at 20:41:11, Jok Thuau wrote:

> On Fri, Aug 19, 2016 at 9:33 AM, Sergio Belkin <sebelk at gmail.com> wrote:
> > /var/log/squid/access.log
> > 192.168.50.41 - - [19/Aug/2016:12:19:45 -0300] "CONNECT
> > beap-bc.yahoo.com:443 HTTP/1.1" 407 4634 "-" "Mozilla/5.0 (Windows NT
> > 6.1; WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TCP_DENIED:HIER_NONE
> 
> This is unauthenticated (notice the "- -" after the IP)
> 
> > 192.168.50.41 - juan.perez [19/Aug/2016:12:19:45 -0300] "CONNECT
> > beap-bc.yahoo.com:443 HTTP/1.1" 200 0 "-" "Mozilla/5.0 (Windows NT 6.1;
> > WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TAG_NONE:HIER_DIRECT
> 
> This one is authenticated (juan.perez). The code 407 in the first request
> means "proxy request authentication". So what happened here is that the
> user browsed, was asked for credentials (and maybe those were provided
> automatically), and then the request was resent with the creds included.

Given the timestamps (both 12:19:45; no time for a human to enter credentials 
at a prompt) the browser did this automatically, and invisibly to the user.

> http_access deny  !kerb_auth
> 
> > http_access allow kerb_auth whitelist_ips
> 
> And here is the config that causes that -- it's totally normal...
> 
> Thanks,

Antony.

-- 
"In fact I wanted to be John Cleese and it took me some time to realise that 
the job was already taken."

 - Douglas Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ahmed.zaeem at netstream.ps  Fri Aug 19 23:48:48 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 20 Aug 2016 02:48:48 +0300
Subject: [squid-users] squid shutdown or reconfigure in Multi-instance
	environment 3.5.2
Message-ID: <801BA207-C533-49A9-AD1F-0A49A88BEBEC@netstream.ps>

Hi Squid-users
==========
I?m using squid 3.5.2 as multi instances .

i have it great 

i have many instances like

squid -n s1
squid -n s2
squid -n s3
squid -n s4
.
.
.
etc


but the problem that i have is sometimes i need to reconfigure only 1 instance or reload 1 instance alone 

if i try to do :

[root at s93898 ~]# squid -n s1 -k rec
squid: ERROR: No running copy
[root at s93898 ~]# 




the question here :

how can i do rec or shutdown specific instance ??

my kind regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160820/33b29d27/attachment.htm>

From ahmed.zaeem at netstream.ps  Fri Aug 19 23:56:30 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 20 Aug 2016 02:56:30 +0300
Subject: [squid-users] squid shutdown or reconfigure in Multi-instance
	environment 3.5.2
In-Reply-To: <8686k1ier11v2u5fqneesvjj.1471650686086@email.lge.com>
References: <8686k1ier11v2u5fqneesvjj.1471650686086@email.lge.com>
Message-ID: <C551F153-96C2-4338-9F91-A5AB3E40396F@netstream.ps>

Ohhhh man , me too i miss you .


> On Aug 20, 2016, at 2:51 AM, Benjamin E. Nichols <webmaster at squidblacklist.org> wrote:
> 
> We miss you!
> 
>  Benjamin  E. Nichols
> http://www.squidblacklist.org <http://www.squidblacklist.org/>
> 
> 1-405-397-1360 <tel:1-405-397-1360>
> 
> ------ Original message------
> From: --Ahmad--
> Date: Fri, Aug 19, 2016 6:48 PM
> To: Squid Users;
> Cc:
> Subject:[squid-users] squid shutdown or reconfigure in Multi-instance	environment 3.5.2
> 
> Hi Squid-users
> ==========
> I?m using squid 3.5.2 as multi instances .
> 
> i have it great 
> 
> i have many instances like
> 
> squid -n s1
> squid -n s2
> squid -n s3
> squid -n s4
> .
> .
> .
> etc
> 
> 
> but the problem that i have is sometimes i need to reconfigure only 1 instance or reload 1 instance alone 
> 
> if i try to do :
> 
> [root at s93898 ~]# squid -n s1 -k rec
> squid: ERROR: No running copy
> [root at s93898 ~]# 
> 
> 
> 
> 
> the question here :
> 
> how can i do rec or shutdown specific instance ??
> 
> my kind regards

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160820/8cb8d8b0/attachment.htm>

From jr at jrssite.com  Sat Aug 20 02:56:42 2016
From: jr at jrssite.com (JR Dalrymple)
Date: Sat, 20 Aug 2016 02:56:42 +0000
Subject: [squid-users] ssl-bump / https traffic not cacheing
Message-ID: <CABs_askfq-CY-TEWw1qatwf8qySpzmVhjAcMf-sfeiRRgScdZQ@mail.gmail.com>

I'm sure I'm missing something stupid, but https traffic just isn't
caching. I really want to cache https alongside http as this project is for
a customer who lives in the sticks and pays dearly for every byte.

1471660884.894  11402 172.22.19.48 TCP_MISS/200 746898 GET
https://www.jrssite.com/newfi/fullsizes/081916214031.jpg - ORIGINAL_DST/
23.30.254.3 image/jpeg
1471660967.389  14392 172.22.22.68 TCP_MISS/200 746898 GET
https://www.jrssite.com/newfi/fullsizes/081916214031.jpg - ORIGINAL_DST/
23.30.254.3 image/jpeg
1471661329.884  33506 172.22.22.68 TCP_MISS/200 746898 GET
http://www.jrssite.com/newfi/fullsizes/081916214031.jpg - ORIGINAL_DST/
23.30.254.3 image/jpeg
1471661385.282    402 172.22.19.48 TCP_HIT/200 746906 GET
http://www.jrssite.com/newfi/fullsizes/081916214031.jpg - HIER_NONE/-
image/jpeg

# grep -i ssl /usr/local/squid/etc/squid.conf
acl SSL_ports port 443
# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports
ssl_bump stare all
ssl_bump bump all
https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/ssl/CACert.pem
sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s
/usr/local/squid/var/lib/ssl_db -M 4MB
sslcrtd_children 10

Happy to provide any other information someone else might find useful. I'm
sure that there is just some point of ignorance on my part. This is indeed
all very new to me.

Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160820/1468db86/attachment.htm>

From marciobacci at gmail.com  Sat Aug 20 03:50:26 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Sat, 20 Aug 2016 00:50:26 -0300
Subject: [squid-users] Problems with Squid Authentication
In-Reply-To: <vmime.57b6d942.77ba.4578e4ce3f59062@ms249-lin-003.rotterdam.bazuin.nl>
References: <CA+0TdyoUrAQ_nnG4+EoUwRABfXseOCSF_d80W1wqohxNy1a_WA@mail.gmail.com>
 <vmime.57b6d942.77ba.4578e4ce3f59062@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <CA+0TdyqmK9eMNqgWuJSW0ktGHL=znLP-JVuX6a6fn-xOTE13mQ@mail.gmail.com>

Hi,

1) Here is the result of the command-line:
/usr/lib/squid/negotiate_kerberos_auth -s HTTP/
proxy.empresa.com.br at EMPRESA.COM.BR ?d ?i
mary abc at 12345
negotiate_kerberos_auth.cc(258): pid=1421 :2016/08/19 23:44:33|
negotiate_kerberos_auth: DEBUG: Got 'mary abc at 12345' from squid (length:
14).
negotiate_kerberos_auth.cc(295): pid=1421 :2016/08/19 23:44:33|
negotiate_kerberos_auth: ERROR: Invalid request [mary abc at 12345]
BH invalid request

2) Bellow are my keytabs:
Keytab name: FILE:/etc/krb5.keytab
KVNO Principal
----
--------------------------------------------------------------------------
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy at EMPRESA.COM.BR
   1 host/proxy at EMPRESA.COM.BR
   1 host/proxy at EMPRESA.COM.BR
   1 host/proxy at EMPRESA.COM.BR
   1 host/proxy at EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR


Keytab name: FILE:/etc/squid3/HTTP.keytab
KVNO Principal
----
--------------------------------------------------------------------------
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy.empresa.com.br at EMPRESA.COM.BR
   1 host/proxy$EMPRESA.COM.BR
   1 host/proxy$EMPRESA.COM.BR
   1 host/proxy$EMPRESA.COM.BR
   1 host/proxy$EMPRESA.COM.BR
   1 host/proxy$EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 proxy$@EMPRESA.COM.BR
   1 HTTP/proxy.empresa.com.br at EMPRESA.COM.BR
   1 HTTP/proxy.empresa.com.br at EMPRESA.COM.BR
   1 HTTP/proxy.empresa.com.br at EMPRESA.COM.BR
   1 HTTP/proxy.empresa.com.br at EMPRESA.COM.BR
   1 HTTP/proxy.empresa.com.br at EMPRESA.COM.BR
   1 HTTP/proxy$EMPRESA.COM.BR
   1 HTTP/proxy$EMPRESA.COM.BR
   1 HTTP/proxy$EMPRESA.COM.BR
   1 HTTP/proxy$EMPRESA.COM.BR
   1 HTTP/proxy$EMPRESA.COM.BR

OBS: I left and joined in the domain again

3) Here is the result:
/usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME
mary abc at 12345
BH invalid request



4) DNS Recors are OK.
The proxy servername exist in dns and have A (proxy IN A 192.168.200.7) and
PTR record (7 IN PTR proxy.empresa.com.br.)


5) cat /etc/hosts
127.0.0.1              localhost
192.168.200.7     proxy.empresa.com.br   proxy



6) Time is sync with the AD server (The time is identical)


7) My /etc/krb5.conf file:
[libdefaults]
       default_realm = EMPRESA.COM.BR
       dns_lookup_kdc = yes
       dns_lookup_realm = yes
       default_keytab_name = /etc/krb5.keytab

[realms]
EMPRESA.COM.BR = {
kdc = dc1.empresa.com.br:88
admin_server = dc1.empresa.com.br
default_domain = EMPRESA.COM.BR
}


[domain_realm]
.empresa.com.br = EMPRESA.COM.BR
empresa.com.br = EMPRESA.COM.BR

[logging]
  kdc = FILE:/var/log/kdc.log
  admin_server = FILE:/var/log/kadmin.log
  default = FILE:/var/log/krb5lib.log


8) Bellow is my /etc/nsswitch.conf file:
passwd:         compat winbind
group:          compat winbind
shadow:         compat
gshadow:        files
hosts:          files dns
networks:       files
protocols:      db files
services:       db files
ethers:         db files
rpc:            db files
netgroup:       nis


9) Bellow is my /etc/pam.d/common-session file:
session [default=1] pam_permit.so
session requisite pam_deny.so
session required pam_permit.so
session required pam_unix.so
session    optional pam_winbind.so


10) Following my /etc/samba/smb.conf file:
[global]
  netbios name = proxy
  workgroup = EMPRESA
  security = ads
  realm = EMPRESA.COM.BR
  encrypt passwords = yes
  dedicated keytab file = /etc/krb5.keytab
  kerberos method = secrets and keytab
  password server = dc1.empresa.com.br
  preferred master = no
  idmap config *:backend = tdb
  idmap config *:range = 1000-3000
  idmap config EMPRESA:backend = ad
  idmap config EMPRESA:schema_mode = rfc2307
  idmap config EMPRESA:range = 10000-9999999
  winbind nss info = rfc2307
  winbind trusted domains only = no
  winbind use default domain = yes
  winbind enum users = yes
  winbind enum groups = yes
  winbind offline logon = yes
  winbind refresh tickets = yes
  vfs objects = acl_xattr
  map acl inherit = Yes
  store dos attributes = Yes
  username map = /etc/samba/user.map


11) Other Informations:
>> Samba4 and Winbind services are enable
>> In my DC there is a Squid account (call "proxy")
>> wbinfo -g, wbinfo -u, wbinfo -t, getent passwd are OK
>> kinit <user> is OK
>> klist -l is OK

Do you have any other idea?

Regards,

M?rcio

2016-08-19 7:02 GMT-03:00 L.P.H. van Belle <belle at bazuin.nl>:

> Hai,
>
>
>
> Yes, all new things are hard..
>
> I need some extra info because there are lots of things that can be wrong.
>
>
>
> post what you see here :
>
> /usr/lib/squid/negotiate_kerberos_auth -s HTTP/proxy.empresa.com.br@
> EMPRESA.COM.BR ?d ?i
>
>
>
>
>
> >> kinit and klist are ok
>
> >> /etc/krb5.keytab and /etc/squid3/HTTP.keytab (both are identical)
>
> These are normaly not identical. In the HTTPkeytab i have ONLY the HTTP
> spn.
>
> And in the krb5.keytab i  have the host SPN and netbios_name($)
>
>
>
> How to test the kerberos auth.. hmm, thats a difficult one for me.
>
> I know lot but not all..  :-(  .
>
>
>
> But what i do iknow, you can test with
>
> /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME
>
> If that works its probely an SPN or dns problem.
>
> If that isnt working, then do check the time on the ad server and proxy
> server.
>
>
>
> I can only say.
>
> The proxy servername must exist in dns and must have A and PTR record.  (
> add this in the samba AD )
>
> The reverse zone is ( maybe ) created, if not, create it yourself and add
> the ptr records.
>
>
>
> Cat /etc/hosts file may NOT contain any.
>
> 127.0.1.1        yourhostname.. ..
>
> if its in there, you installed with dhcp ip.
>
>
>
> It should contain
>
> 127.0.0.1              localhost
>
> IP_OF_SERVER   hostname.domain.tld hostname
>
> The is there if you install with a static ip.
>
>
>
> Time must be in sync with the AD server ( max difference i allow is 1 min.
> )
>
> If needed install ntp on the proxy and point the server  to the ad dc.
>
>
>
> And post what you now have in krb5.conf
>
>
>
> These are the most common pitfalls, i?ll see what i can do to help out.
>
>
>
>
>
> Greetz,
>
>
>
> Louis
>
>
>
>
>
>
>
>
>
>
> ------------------------------
>
> *Van:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org] *Namens
> *Marcio Demetrio Bacci
> *Verzonden:* vrijdag 19 augustus 2016 3:50
> *Aan:* Squid Users
> *Onderwerp:* [squid-users] Problems with Squid Authentication
>
>
>
> My Kerberos Authentication doesn't work. This is very hard!
>
>
>
> My Squid3 is join in the Domain
>
> kinit and klist are ok
>
> wbinfo -g and wbinfo -u are ok too.
>
>
>
> I have created the squid3 file in /etc/default with the following content:
>
> KRB5_KTNAME=/etc/squid3/HTTP.keytab
>
> export KRB5_KTNAME
>
>
>
> I have two keytab files:
>
> /etc/krb5.keytab and /etc/squid3/HTTP.keytab (both are identical)
>
>
>
> I have installed libsasl2-modules-gssapi-mit libsasl2-modules packages
> because my Squid server is Debian 8. But I didn't use msktutil tool. I have
> only joined Squid server in the Domain (net ads join -U administrator)
>
>
>
> How can I debbug the problem?
>
> How can I test kerberos authentication in terminal (command line)?
>
>
>
> Below is my squid.conf file:
>
>
>
> ### Configuracoes Basicas
>
>
>
> cache_mgr administrator at empresa.com.br
>
>
>
> http_port 3128
>
>
>
> #debug_options ALL,111,2 29,9 84,6
>
>
>
> cache_mem 512 MB
>
> cache_swap_low 80
>
> cache_swap_high 90
>
>
>
> maximum_object_size 512 MB
>
> minimum_object_size 0 KB
>
>
>
> maximum_object_size_in_memory 4096 KB
>
>
>
> cache_replacement_policy heap LFUDA
>
> memory_replacement_policy heap LFUDA
>
>
>
> #Para n?o bloquear downloads
>
> quick_abort_min -1 KB
>
>
>
>
>
> #Resolve um problema com conexoes persistentes
>
> detect_broken_pconn on
>
>
>
> fqdncache_size 1024
>
>
>
> ### Parametros de atualizacao da memoria cache
>
> refresh_pattern ^ftp:   1440   20%   10080
>
> refresh_pattern ^gopher:   1440   0%   1440
>
> refresh_pattern -i (/cgi-bin/|\?) 0 0%    0
>
> refresh_pattern .      0   20%   4320
>
>
>
> ### Localizacao dos logs
>
> access_log /var/log/squid3/access.log
>
> cache_log /var/log/squid3/cache.log
>
>
>
>
>
> ### define a localizacao do cache de disco, tamanho, qtd de diretorios pai
> e subdiretorios
>
> cache_dir aufs /var/spool/squid3 600 16 256
>
>
>
> auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -s
> HTTP/proxy.empresa.com.br at EMPRESA.COM.BR
>
> auth_param negotiate children 20
>
> auth_param negotiate keep_alive on
>
>
>
> visible_hostname proxy.empresa.com.br
>
>
>
> ### acls
>
> #acl manager proto cache_object
>
> acl localhost src * MailScanner heeft een e-mail met mogelijk een poging
> tot fraude gevonden van "192.168.200.7" * *MailScanner warning: numerical
> links are often malicious:* 192.168.200.7/32 <http://192.168.200.7/32>
>
> acl to_localhost dst * MailScanner heeft een e-mail met mogelijk een
> poging tot fraude gevonden van "192.168.200.7" * *MailScanner warning:
> numerical links are often malicious:* 192.168.200.7/32
> <http://192.168.200.7/32>
>
> acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, zimbra,
> webmin
>
> acl Safe_ports port 21       # ftp
>
> acl Safe_ports port 70       # gopher
>
> acl Safe_ports port 80       # http
>
> acl Safe_ports port 88       # kerberos
>
> acl Safe_ports port 210       # wais
>
> acl Safe_ports port 280       # http-mgmt
>
> acl Safe_ports port 389       # ldap
>
> acl Safe_ports port 443    # https
>
> acl Safe_ports port 488       # gss-http
>
> acl Safe_ports port 563       # snews
>
> acl Safe_ports port 591       # filemaker
>
> acl Safe_ports port 777       # multiling http
>
> acl Safe_ports port 3001         # imprenssa nacional
>
> acl Safe_ports port 8080    # http
>
> acl Safe_ports port 1025-65535    # unregistered ports
>
>
>
> acl purge method PURGE
>
> acl CONNECT method CONNECT
>
>
>
>
>
> ### Regras iniciais do Squid
>
> http_access allow localhost
>
> http_access allow purge localhost
>
> http_access deny purge
>
> http_access deny !Safe_ports
>
> http_access deny CONNECT !SSL_ports
>
>
>
> ### Exige autenticacao
>
> acl autenticados proxy_auth REQUIRED
>
> http_access allow autenticados
>
>
>
>
>
>
>
> ### Rede do Local #####
>
> acl rede_local src * MailScanner heeft een e-mail met mogelijk een poging
> tot fraude gevonden van "192.168.200.0" * *MailScanner warning: numerical
> links are often malicious:* 192.168.200.0/22 <http://192.168.200.0/22>
>
>
>
>
>
> ### Nega acesso de quem nao esta na rede local
>
> http_access allow rede_local
>
>
>
> #negando o acesso para todos que nao estiverem nas regras anteriores
>
> http_access deny all
>
>
>
> ### Erros em portugues
>
> error_directory /usr/share/squid3/errors/pt-br
>
>
>
> #cache_effective_user proxy
>
> coredump_dir /var/spool/squid3
>
>
>
>
>
> Regards,
>
>
>
> M?rcio
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160820/a9dc2db6/attachment.htm>

From squid3 at treenet.co.nz  Sat Aug 20 09:43:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Aug 2016 21:43:55 +1200
Subject: [squid-users] communication with parent proxy using ssl
In-Reply-To: <20160819212317.Horde.Oy646hpz8x6jh4-w1Li8Eg1@inbox.dv.lv>
References: <20160819212317.Horde.Oy646hpz8x6jh4-w1Li8Eg1@inbox.dv.lv>
Message-ID: <e323f6f6-7acf-0558-3a6f-6fd45fbe77c0@treenet.co.nz>

On 20/08/2016 6:23 a.m., J?nis wrote:
> Hi!
> 
> may someone suggest some solution for traffic encryption between the
> parent and "child" proxy based on squid's own functionality?

Assumgin both are Squid;
* child proxy simply has cache_peer ... parent ... ssl"
  <http://www.squid-cache.org/Doc/config/cache_peer/>
* parent proxy has "https_port ..."
  <http://www.squid-cache.org/Doc/config/https_port/>


Both proxies have to be built with TLS/SSL support for encrypted
connections to work of course.

Amos



From squid3 at treenet.co.nz  Sat Aug 20 09:50:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Aug 2016 21:50:49 +1200
Subject: [squid-users] HTTPS - THE PROXY SERVER IS REFUSING CONNECTIONS
In-Reply-To: <03ef01d1fa33$c941e4f0$5bc5aed0$@gmail.com>
References: <03ef01d1fa33$c941e4f0$5bc5aed0$@gmail.com>
Message-ID: <0dafffd5-da13-d63a-f478-58b1d0ef575e@treenet.co.nz>

On 20/08/2016 4:07 a.m., adego70 at gmail.com wrote:
> Thank you VERY MUCH L.P.H. van Belle !
> 
>  
> 
> I tried with or without changes but I don't have good result :
> 
> I still have " THE PROXY SERVER IS REFUSING CONNECTIONS" for https
> websites...
> 
> I can't understand why it doesn't work.
> 
> Is it working on your side ?
> 

Your original config should have worked.

Have you configured the clients (manually or via WPAD/PAC auto-config)
to connect to your Squid as an *HTTP* proxy and send their HTTPS
requests via that ?

>  
> 
> Another information, maybe it's important : my squid is installed on a
> dedicated computer. Then the IP of SQUID is different than the IP of my
> firefox. 

As long as the localnet ACL lists the IP ranges your Firefox can be part
of that is fine.

Exactly what HTTP request message is the proxy refusing when you attempt
an HTTPS connection?
 --> access.log should give you that info.


Amos



From squid3 at treenet.co.nz  Sat Aug 20 10:12:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Aug 2016 22:12:21 +1200
Subject: [squid-users] Squid 2.7.s9 HTTPS-proxying - hint welcome
In-Reply-To: <1471603376992-4679041.post@n4.nabble.com>
References: <20160817172352.3f19dc8f@BS2>
 <2162fa4d-41e1-81c1-12a2-7b99d2bd04aa@treenet.co.nz>
 <1471474841533-4678997.post@n4.nabble.com>
 <b000d16b-ae3f-4a91-9cc9-1a2fb4fb018e@treenet.co.nz>
 <1471603376992-4679041.post@n4.nabble.com>
Message-ID: <cc5f8760-989f-0dd9-460d-58f179a34d32@treenet.co.nz>

On 19/08/2016 10:42 p.m., Torsten Kuehn wrote:
> Hi,
> 
> On 18/08/2016 6:32 a.m., Amos Jeffries wrote:
> 
>>> I imagine layouts where the encrypted traffic itself gets stored
>> no way for Squid to know if a previous encrypted stream is reusable.
>> To squid it is just a random stream of opaque bytes.
> 
> Enlightening! The idea was that omitting decryption but instead providing
> measures to do so from the client's side had less concerns wrt privacy.
> As I see, with a mere "stream of opaque bytes", any "handle" to provide
> such measures is missing. Thus, if caching of SSL-encrypted data is wished,
> decryption is mandatory.
> 
>>> I.e. [HTTPS] not cacheable at all [in 2.7.s9]?
>> Correct.
> 
> Asking months earlier here would have saved me painful failures ...
> 
>>> I prefer not to erase objects [...] My [TAGs] may look horrible
>>>     authenticate_ttl 359996400 seconds
>> Lookup "credentials replay attack". [...] There is no other use for
>> this directive than attacking your clients.
> 
> Uugh! Was set in april 2012, by error (without effect in 2.5.s8_OS2_VAC,
> thus
> it didn't harm): the idea was to turn off Squid's garbage collection, in
> order
> to avoid wearing out flash memory. Wrong place, and I ignored credentials
> ...
> 
>>>     hierarchy_stoplist cgi-bin
>>>     refresh_pattern -i /cgi-bin/ 5258880 100% 5258880
>> Please use the pattern settings:  "-i (/cgi-bin/|\?) 0 0% 0"
>> This pattern is designed to work around an issue with truly ancient CGI
>> scripts [...] Such scripts are guaranteed to be dynamically changing [...]
> 
> The idea comes from http://twiki.cern.ch/twiki/bin/view/CMS/MyOwnSquid ,
> to get dynamic web pages cached. I am glad that Squid finally does so!
> Conflicting concepts, as it seems. Or, is there any RegEx which does the
> old CGI script-workaround but still caches content with "?" in URLs?
> 
>>>     refresh_pattern . 5258880 100% 5258880
>>>         override-expire override-lastmod ignore-no-cache ignore-private
>>>     positive_dns_ttl 359996400 seconds
>> Meaning whenever any domain name moves hosting service you get cutoff
>> from it completely for ~11 years or until you fully restart Squid.
> 
> Yes, I noticed this :-) (Used to reconfigure Squid from CacheMgr in these
> cases). Came from Sjoerd Visser's dutch page on Squid 1.1, to work around
> it's missing offline_mode TAG (just kept positive_dns_ttl afterwards):
> http://vissesh.home.xs4all.nl/multiboot/firewall/squid.html
> 

Well, that tags available now. :-). Though it does not do much now since
HTTP/1.1 caching brings most of what it used to do but in a standardised
way.

>> When you go to Squid-3, removing both these DNS settings entirely would
>> be best. [...] if you really insist [...] ~48hrs should work just as well
> 
> Truely. When I set up 2.5.s8_OS2_VAC six years ago, I just added a few new
> TAGs to my old 1.1 config. Only this summer, I spent a couple of days to
> migrate previous settings into the new order of a fresh 2.7.s9's config (for
> better comparison), now comprising a history of all available OS/2 builds
> (introduction/ disappearance of features etc.). To be re-done with 3.5.

Hmm. Run "squid -k parse" and you should get notices about chnaged or
removed config options. You should do so before/during any big version
jump anyway.

> 
>>> setup is that robust that force-reload [fails unless objects deleted]
>> This is done solely by "override-expire".
> 
> Perfect. I'm far from knowing config TAGs by heart and thus don't see how
> things play together. Enabling "overide-expire" in 2012 was a bad thing.
> 

Yeah. Times change. The new RFCs now tell us Expires header is to be
followed unless other (max-age) values are available, so its sort of
optional in todays traffic. Ignoring it is still a violation, but not
much risk.


>>> [setup that robust that] PURGE fails unless [objects deleted manually]
>> In Squid-2 this is more efficiently done by:
>>   acl PURGE method PURGE
>>   http_access deny PURGE
> 
> Recently enabled (as well as CacheMgr-access) by setting
>     acl localnet src 192.168.0.160/27
>     [...]
>     acl purge method PURGE
>     http_access allow purge localnet
>     http_access allow purge localhost
>     http_access deny purge
> 
>> Squid-3 [...] disables all the PURGE functionality *unless* you have
>> "PURGE" method in an ACL like above. It is a good idea for performance
>> reasons to remove all mention of "PURGE" when upgrading to Squid-3.
> 
> Permitting PURGE has a performance impact? I enabled it recently, but
> since reload works now, it could be suppressed.

A little bit. Squid has to track cached objects with an index ID that
PURGE can use (normal one is tied to GET), so wastes a bit of memory and
CPU time calculating it.

 HTCP protocol CLR messages work better than PURGE, especially when
using a group/hierarchy of caches.

> 
>>> [force-reload fails unless] the ugly "reload_into_ims on" option
>>> is set which violates standards.
>> reload_into_ims is not a violation of current HTTP/1.1 standards. [...]
>> The big(est) problem with it is that Squid-2 is HTTP/1.0 software and
>> both reload and IMS revalidation are not defined in that version of the
>> protocol. Adding two risky undefined things together multiplies dangers.
>> [...] Overall the approach to caching *at any cost* is doing more harm
>> than good, both to yourself and to many others.
> 
> Disquieting. In fact, I tried to change Squid's default caching behaviour
> to "accumulating" content ("once here, why to reload redundant stuff?").
> The second, important intention behind this is not to wear out the flash
> memory where Squid runs on. Data is backed up regularily, but I'm afraid
> of, e.g., the regular revalidation processes's write accesses. (A friend
> lost a solid state disk with a Squid cache after only six months.)
> 

Nod. My customers experiences with SSD, and talk with other list members
here, has been similar. The older Squid pass all objects through the
cache_dir so the disk gets a lot more write activity than you would
expect. That has been improved with recent releases, but is not yet
fully solved.

You need to go for SSD with very high advertised write/rewrite counts,
and you can expect/budget for the operating lifetime under Squid to be
1/2 or even 1/3 what the manufacturer advertise. Not due to any fault of
theirs, Squid just thrashes hardware in ways SSD are not designed for.

FYI; ufs/aufs/diskd cache_dir do not update the on-disk copy of objects
when revalidating - just the in-memory objects or rock cache types do
that. For most that is a bug (#7 if interested) for you it may be a
bonus :-)

Cheers
Amos



From squid3 at treenet.co.nz  Sat Aug 20 10:31:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Aug 2016 22:31:02 +1200
Subject: [squid-users] ssl-bump / https traffic not cacheing
In-Reply-To: <CABs_askfq-CY-TEWw1qatwf8qySpzmVhjAcMf-sfeiRRgScdZQ@mail.gmail.com>
References: <CABs_askfq-CY-TEWw1qatwf8qySpzmVhjAcMf-sfeiRRgScdZQ@mail.gmail.com>
Message-ID: <8f255f2a-331a-8615-d05e-73d4e26832c0@treenet.co.nz>

On 20/08/2016 2:56 p.m., JR Dalrymple wrote:
> I'm sure I'm missing something stupid, but https traffic just isn't
> caching. I really want to cache https alongside http as this project is for
> a customer who lives in the sticks and pays dearly for every byte.
> 
> 1471660884.894  11402 172.22.19.48 TCP_MISS/200 746898 GET
> https://www.jrssite.com/newfi/fullsizes/081916214031.jpg - ORIGINAL_DST/
> 23.30.254.3 image/jpeg
> 1471660967.389  14392 172.22.22.68 TCP_MISS/200 746898 GET
> https://www.jrssite.com/newfi/fullsizes/081916214031.jpg - ORIGINAL_DST/
> 23.30.254.3 image/jpeg
> 1471661329.884  33506 172.22.22.68 TCP_MISS/200 746898 GET
> http://www.jrssite.com/newfi/fullsizes/081916214031.jpg - ORIGINAL_DST/
> 23.30.254.3 image/jpeg
> 1471661385.282    402 172.22.19.48 TCP_HIT/200 746906 GET
> http://www.jrssite.com/newfi/fullsizes/081916214031.jpg - HIER_NONE/-
> image/jpeg
> 
> # grep -i ssl /usr/local/squid/etc/squid.conf
> acl SSL_ports port 443
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> ssl_bump stare all
> ssl_bump bump all
> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/etc/ssl/CACert.pem
> sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s
> /usr/local/squid/var/lib/ssl_db -M 4MB
> sslcrtd_children 10
> 
> Happy to provide any other information someone else might find useful. I'm
> sure that there is just some point of ignorance on my part. This is indeed
> all very new to me.


ORIGINAL_DST is a hint that these requests may have failed to pass
Squid's Host verfication tests. If Squid is unable to verify that the
server providing the data is actually the correct origin/authority for
that data then we relay to the client expicitly requesting that server
be used - but do not cache to avoid corrupting/infecting other clients.

Alternatively, there could be some cache controls or Vary header
involved that cause the particular reponses.
 (I went to check that myself, but it says login is required. You can
use the redbot.org tool to see the caching status if you have a working
login).

Amos



From squid3 at treenet.co.nz  Sat Aug 20 10:34:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Aug 2016 22:34:41 +1200
Subject: [squid-users] AD Ldap (automatically take the user that is
 logging on PC)
In-Reply-To: <1471634038246-4679053.post@n4.nabble.com>
References: <1471467505128-4678994.post@n4.nabble.com>
 <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
 <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <1471620011751-4679045.post@n4.nabble.com>
 <78607b31-cdb0-3c02-d76b-f247fdd02dc7@gmail.com>
 <1471630581076-4679049.post@n4.nabble.com>
 <bfed0fbc-084b-2fb1-d35f-5342e13678ec@gmail.com>
 <1471634038246-4679053.post@n4.nabble.com>
Message-ID: <ebd59d41-544f-a60e-cfe5-0d6308cc1dc8@treenet.co.nz>

On 20/08/2016 7:13 a.m., erdosain9 wrote:
> For eg., in all the config that i read is necessary a file call something
> like squid.keytab...
> its possible just make a user in AD like "squid", and then just log the
> squid in the Ad??? or is mandatory generating this file???
> thanks


Perhapse you should check out the wiki configuration examples:
<http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos>
or
<http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory>

If those don't work, or need updates it would be good to know.

Amos



From squid3 at treenet.co.nz  Sat Aug 20 11:59:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 Aug 2016 23:59:50 +1200
Subject: [squid-users] squid shutdown or reconfigure in Multi-instance
 environment 3.5.2
In-Reply-To: <801BA207-C533-49A9-AD1F-0A49A88BEBEC@netstream.ps>
References: <801BA207-C533-49A9-AD1F-0A49A88BEBEC@netstream.ps>
Message-ID: <33a60130-b907-059e-5225-435449116a45@treenet.co.nz>

On 20/08/2016 11:48 a.m., --Ahmad-- wrote:
> Hi Squid-users
> ==========
> I?m using squid 3.5.2 as multi instances .
> 

There were problems with -n up to 3.5.9. Though please upgrade right to
3.5.19 or 3.5.20 to avoid the major security issues that have been fixed
this past year.

NP: if you have pid_filename configured, you need to ensure it is unique
for each named service so they dont overrite other services PID vaues.
So use the ${service_name} macro in Squid-3 configs. Squid-4 takes care
of that by default.

Amos



From squid3 at treenet.co.nz  Sat Aug 20 12:15:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 Aug 2016 00:15:56 +1200
Subject: [squid-users] training
In-Reply-To: <CAKikXHqu=f2FtEuP5AdSTqstf7VBcwAcokXkSEYc-UGs+rh1iA@mail.gmail.com>
References: <CAKikXHqu=f2FtEuP5AdSTqstf7VBcwAcokXkSEYc-UGs+rh1iA@mail.gmail.com>
Message-ID: <2fbc3982-74b4-df79-607b-9a51c45d9952@treenet.co.nz>

On 19/08/2016 7:28 p.m., sallo baloch wrote:
> dear
> 
> sir how to learn squid proxy from scratch
> 

<http://www.squid-cache.org/Doc/>

You can find there links to lots of documentation from a Beginners
Manual to Squid-3 (3.1, but most of it it still very relevant). The
Squid FAQ, wiki, etc. Those three will also introduce you to the
terminology needed to help searching for additional things of interest.

Once you know the basis of what can be done and want to try things out
install the package for your OS (look in the wiki for those if you dont
already know the packaging system your OS provides).
<http://www.squid-cache.org/Doc/config/> provides the very latest
documentation on squid.conf directives and settings for all available
Squid versions.

So basically; a bit of reading into what Squid does, install the package
for your OS and start using it :-)

We are here to answer questions if things are not very clear (or to
correct wrong tutorials info). Some minor effort on your part to look
for the answers first is appreciated of course. Most things that can be
asked by beginners already have been and answers exist online somewhere.

Amos



From d.webb at mdx.ac.uk  Sat Aug 20 13:34:12 2016
From: d.webb at mdx.ac.uk (David Webb)
Date: Sat, 20 Aug 2016 14:34:12 +0100
Subject: [squid-users] Squid Samba 4 and ntlm_auth concurrency question
Message-ID: <7611006e-ff51-5f4c-f789-2f250e3bdb52@mdx.ac.uk>


I'm currently using the binary version of squid provided by yum with 
RHEL 7.2  (3.3.8) with Samba 4's  winbind ntlm_auth to authenticate 
against AD which is working fine

auth_param negotiate program /usr/bin/ntlm_auth --helper-protocol=gss-spnego
auth_param negotiate children 250  startup=2 idle=1
auth_param negotiate keep_alive off
#
auth_param ntlm program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 250  startup=2 idle=1
auth_param ntlm keep_alive off
#

However I'm wondering if I can reduce the number of  ntlm_auth processes 
created by introducing some concurrency.

I've seen mention of helper-mux.pl but from what I've seen on the web 
I'm not sure if this will work with negotiate and ntlm.
Also it  looks like in the future with Squid 4  helper-mux.pl is being 
retired.
I've also seen some mention of Samba 4 building in some concurrency 
itself into ntlm_auth but I'm not sure that this is fully supported.

So my question is what is the current state of play for squid 3.x (and 
upcoming squid 4) with respect to negotiate and ntlm concurrency with 
samba4 ?


-- 

David Webb  (CISSP-ISSAP)
Information Systems Security Architecture Professional
IT Security team leader
CCSS
Middlesex University




---------------------------------------------------------------------------


Please note that all incoming post to Middlesex University is opened and scanned by our digital document handler and then emailed to the recipient. If you do not want your correspondence to processed in this way please email the recipient directly. Parcels, couriered items and recorded delivery items will not be opened or scanned.  



From omidkosari at yahoo.com  Sat Aug 20 13:41:24 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 20 Aug 2016 06:41:24 -0700 (PDT)
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <00c001d1f961$2d31fe10$8795fa30$@ngtech.co.il>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
 <1471524821802-4679021.post@n4.nabble.com>
 <1471529712673-4679025.post@n4.nabble.com>
 <00c001d1f961$2d31fe10$8795fa30$@ngtech.co.il>
Message-ID: <1471700484064-4679067.post@n4.nabble.com>

I have also tested with several browsers, PCs etc . Also i have disabled
every refresh pattern except default squid rules as like as yours . Same
result . 

The only way to get hits are the way i mentioned in
http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679025.html


Do you tested when enabled my storeid config (mentioned in my first email )
was there ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679067.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Sat Aug 20 14:10:16 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 20 Aug 2016 07:10:16 -0700 (PDT)
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <4879fbd5-f12c-5127-3363-aad590e87ba5@treenet.co.nz>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
 <1471524821802-4679021.post@n4.nabble.com>
 <1471529712673-4679025.post@n4.nabble.com>
 <4879fbd5-f12c-5127-3363-aad590e87ba5@treenet.co.nz>
Message-ID: <1471702216186-4679068.post@n4.nabble.com>

Amos Jeffries wrote
> On 19/08/2016 2:15 a.m., Omid Kosari wrote:
>> I was correct .
>> 
>> If one of following conditions happens then the mentioned urls will not
>> cache .
>> 
>> 1-in squid.conf have this line
>> acl storeiddomainregex dstdom_regex
>> ^igcdn(\-photos|\-videos)[a-z0-9\-]{0,9}\.akamaihd\.net$ 
>> 
> 
> How you use that ACL in your access rule logics is just as important as
> what it contains / matches.

In my first email i have pasted other parts of config .



Amos Jeffries wrote
>> 2-in storeid_db have this line
>> ^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$)
>> http://instagramcdn.squid.internal/$1
> 
> 
> The pattern is malformed. Several parts of it are impossible to match,
> and just make it look complicated when its not.
> 
> It is better written as:
> 
> ^http:\/\/igcdn-[a-z0-9\-\.]+\.akamaihd\.net/hphotos-ak-[a-z0-9]+/(t5.*)
>   http://instagramcdn.squid.internal/$2

Thanks for suggest but this one seems incorrect . At least i think the $2
should be $1 . Apart from that i will use yours .




Amos Jeffries wrote
>> 
>> Now the problem is with my mentioned squid.conf and store_id rules , the
>> mentioned urls will not cache at all.Even if same url reopens many times
>> .
>> 
> 
> Store-ID does not force caching. All it does is provide Squid with a
> different ID under which the item would be stored *IF* (and only if) it
> would be stored normally.
> 
> I suggest removing the "ignore-no-store ignore-private" from your
> .squid.internal refresh_pattern. They trigger actions that break the
> image objects you actually want to store at that Store-ID location.
> 
> Amos

I have completely deleted that refresh_pattern line . But still same results
.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679068.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marciobacci at gmail.com  Sat Aug 20 21:29:08 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Sat, 20 Aug 2016 18:29:08 -0300
Subject: [squid-users] dubt about kerberos authentication in the Squid 3
Message-ID: <CA+0Tdyo--BM1d+o0nhxp_EoY980pc8vUGCbjz5awR+=yUWc4bA@mail.gmail.com>

Hi

I have many dubt about kerberos authentication in the Squid 3 (3.4.8) on
Debian 8. I'm using Samba 4 (4.2.1) as DC.

If I to join Squid Server in the Domain (net ads join) I don't need to
execute the command-line msktutil as bellow ?

msktutil -c -b "CN=COMPUTERS" -s HTTP/squidproxy.example.local -k
/etc/squid3/PROXY.keytab \
--computer-name SQUIDPROXY-K --upn HTTP/squidproxy.example.local --server
dc1.example.local --verbose

Is SQUIDPROXY-K an alias for squidproxy.example.local or is another server?

What is the correct value for default_keytab_name in /etc/krb5.conf file:
 = /etc/squid3/HTTP.keytab  or /etc/krb5.keytab?

Have to enable Samba4 and Winbind services or disable ?


Is join the Squid server on Domain better use than msktutil command?

Does Kerberos uses enctypes by default? My DC is Samba4. Do I need to
configure the following directives in /etc/krb5.conf ?

;for Windows 2008 with AES
    default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
   default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
   permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5

Regards,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160820/0ca8d54d/attachment.htm>

From marcus.kool at urlfilterdb.com  Sun Aug 21 12:46:50 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sun, 21 Aug 2016 09:46:50 -0300
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki + fake
	CONNECT
Message-ID: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>

The ssl-bump peek/splice/bump feature is now maturing and many are using it but
there are still some issues with the wiki page that I like to clarify.
wiki: http://wiki.squid-cache.org/Features/SslPeekAndSplice

section "processing steps"

Can action "none" be removed from step 1?

Step 1.  what is "CONNECT info" ?  In the introduction one speaks
of "HTTP CONNECT" which has a FQDN.  But the fake CONNECT sent to
a URL rewriter has only an IP address.

Why is the fake CONNECT that is sent to the URL rewriter done
at step 1 where only the IP and not the FQDN is available?
It seems to make more sense to do this in step 2 when the SNI/FQDN is available
and a proper fake HTTP CONNECT can be sent to helpers.  The helpers need to get
the FQDN in the same way they get the FQDN in non-interception mode.
And as a bonus the value of the parameter %ssl::>sni in url_rewrite_extras
will become useful (i.e. not the '-').

In section "Peek at SNI and Bump" it is stated that SNI is obtained in step 1.
This contradicts the text at step 1 and 2.

squid.conf.documented has this:
#       acl aclname at_step step
#         # match against the current step during ssl_bump evaluation [fast]
#         # Never matches and should not be used outside the ssl_bump context.
#         #
#         # At each SslBump step, Squid evaluates ssl_bump directives to find
#         # the *next* bumping action (e.g., peek or splice). Valid SslBump step
#         # values and the corresponding ssl_bump evaluation moments are:
#         #   SslBump1: After getting TCP-level and HTTP CONNECT info.
#         #   SslBump2: After getting SSL Client Hello info.
#         #   SslBump3: After getting SSL Server Hello info.
Emphasis on "*next* bumping action".
Should the wiki be reworded and use "next bumping action"?

Section "Actions"

item peek: Receive client SNI (step1), or server certificate (step2)  ...
This contradicts the explanation of the processing steps.
item stare: likewise.

I suggest to remove the "Deprecated actions" or use a BOLD warning not to use them.

Section "Mimicking SSL client Hello properties when staring"
The section has "The information in this section is incomplete and somewhat stale."
Is there any information to update this section ?

section "Examples"

I usually write explicit rules like this:
# TLS/SSL bumping definitions
acl tls_s1_ip_connect   at_step SslBump1
acl tls_s2_client_hello at_step SslBump2
acl tls_s3_server_hello at_step SslBump3
# do not touch servers where ssl-bump breaks HSTS
acl tls_allowed_hsts ssl::server_name .akamaihd.net
# prevent bumping some allowed servers with self-signed certificates
acl tls_allowed_selfsigned ssl::server_name .nic.es .example.local
# prevent bumping of sites where client software fails when bumped
acl tls_allowed_software ssl::server_name .dropbox.com .googledrive.com drive.google.com
# do not bump internal servers
acl tls_server_is_ours ssl::server_name foo.example.com
# do not touch servers of a bank
acl tls_server_is_bank ssl::server_name .santander.com.br
acl tls_server_is_bank ssl::server_name .santander.com
acl tls_server_is_bank ssl::server_name .santandernet.com.br
acl tls_to_splice any-of tls_allowed_hsts tls_allowed_selfsigned tls_server_is_bank tls_server_is_ours tls_allowed_software
# TLS/SSL bumping steps
ssl_bump peek   tls_s1_ip_connect   all                 # peek a client connecting at IP level
ssl_bump splice tls_s2_client_hello tls_to_splice       # splice some: do not bump/interfere
ssl_bump stare  tls_s2_client_hello all                 # connect to the server and stare(peek) at its TLS/SSL properties
ssl_bump bump   tls_s3_server_hello all                 # bump if we can (tls_s2_client_hello/stare succeeded)

The above rules follow the steps of the wiki page but
the examples on the wiki have optimised rules and sometimes
there are messages on the mailing list that rules can be optimized
to save CPU cycles.

The last 4 lines of the example can be optimized into
ssl_bump peek   tls_s1_ip_connect   all
ssl_bump splice tls_s2_client_hello tls_to_splice
ssl_bump stare  all
ssl_bump bump   all

I prefer not to optimize since reading the rules is
easier and one understands better what happens at each step.
However, if a significant number of CPU cycles are saved, I suggest to
include an example like above and rules of thumb on how to optimize and the
final optimized results so that a less experienced reader understands
the optimizations.

The examples in "Avoid bumping banking traffic" :
I can image what used (but not defined) serverIsBank acl looks like:
    acl serverIsBank  ssl::server_name .santander.com
but have no idea what the acl haveServerName looks like.
What is intended here?

Marcus


From squid3 at treenet.co.nz  Sun Aug 21 13:15:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 22 Aug 2016 01:15:42 +1200
Subject: [squid-users] Squid Samba 4 and ntlm_auth concurrency question
In-Reply-To: <7611006e-ff51-5f4c-f789-2f250e3bdb52@mdx.ac.uk>
References: <7611006e-ff51-5f4c-f789-2f250e3bdb52@mdx.ac.uk>
Message-ID: <71dcc4cd-f245-8a00-c1e8-14e1972d37f3@treenet.co.nz>

On 21/08/2016 1:34 a.m., David Webb wrote:
> 
> I'm currently using the binary version of squid provided by yum with
> RHEL 7.2  (3.3.8) with Samba 4's  winbind ntlm_auth to authenticate
> against AD which is working fine
> 
> auth_param negotiate program /usr/bin/ntlm_auth
> --helper-protocol=gss-spnego
> auth_param negotiate children 250  startup=2 idle=1
> auth_param negotiate keep_alive off
> #
> auth_param ntlm program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 250  startup=2 idle=1
> auth_param ntlm keep_alive off
> #
> 
> However I'm wondering if I can reduce the number of  ntlm_auth processes
> created by introducing some concurrency.
> 
> I've seen mention of helper-mux.pl but from what I've seen on the web
> I'm not sure if this will work with negotiate and ntlm.
> Also it  looks like in the future with Squid 4  helper-mux.pl is being
> retired.

Should not be. The use cases and need for it still exists. The way it
works needs to be completely different for the new ID numbering scheme
is all. So the Squid-3 version of the helper is not forward-compatible.

The Squid-4 helper should work** in any Squid version still. If its not
working that is a bug in Squid-4 we want to hear about.

** except on Logging, pinger, NTLM and Negotiate helper interfaces.


> I've also seen some mention of Samba 4 building in some concurrency
> itself into ntlm_auth but I'm not sure that this is fully supported.
> 
> So my question is what is the current state of play for squid 3.x (and
> upcoming squid 4) with respect to negotiate and ntlm concurrency with
> samba4 ?

Squid does not support concurrency in the NTLM and Negotiate helper API
lookups. The helpers apparently do, but Squid wont do it. Not even
enough to experiment with yet.

NTLM has been deprecated for 10 years now (as of this month IIRC). You
should really not have many (or any) Windows 95/98/2k clients needing to
use it. Yes, even XP supports Kerberos.

The only way to reduce load with NTLM is to enable persistent HTTP
connections to clients (and servers where possible) - unrelated to that
"keep_alive off" setting. The more requests your clients can make on a
single connection without having to re-authenticate from scratch the
better. This also helps with Kerberos auth load as they upgrade.

Amos



From squid3 at treenet.co.nz  Sun Aug 21 13:17:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 22 Aug 2016 01:17:50 +1200
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <1471702216186-4679068.post@n4.nabble.com>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
 <1471524821802-4679021.post@n4.nabble.com>
 <1471529712673-4679025.post@n4.nabble.com>
 <4879fbd5-f12c-5127-3363-aad590e87ba5@treenet.co.nz>
 <1471702216186-4679068.post@n4.nabble.com>
Message-ID: <b0fb3f2e-546b-3afe-6c13-5f1763de66c4@treenet.co.nz>

On 21/08/2016 2:10 a.m., Omid Kosari wrote:
> Amos Jeffries wrote
>> On 19/08/2016 2:15 a.m., Omid Kosari wrote:
>>> I was correct .
>>>
>>> If one of following conditions happens then the mentioned urls will not
>>> cache .
>>>
>>> 1-in squid.conf have this line
>>> acl storeiddomainregex dstdom_regex
>>> ^igcdn(\-photos|\-videos)[a-z0-9\-]{0,9}\.akamaihd\.net$ 
>>>
>>
>> How you use that ACL in your access rule logics is just as important as
>> what it contains / matches.
> 
> In my first email i have pasted other parts of config .
> 
> 
> 
> Amos Jeffries wrote
>>> 2-in storeid_db have this line
>>> ^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$)
>>> http://instagramcdn.squid.internal/$1
>>
>>
>> The pattern is malformed. Several parts of it are impossible to match,
>> and just make it look complicated when its not.
>>
>> It is better written as:
>>
>> ^http:\/\/igcdn-[a-z0-9\-\.]+\.akamaihd\.net/hphotos-ak-[a-z0-9]+/(t5.*)
>>   http://instagramcdn.squid.internal/$2
> 
> Thanks for suggest but this one seems incorrect . At least i think the $2
> should be $1 . Apart from that i will use yours .
> 

Right - should be $1. Sorry, thats leftover from my own first attempt to
clean it up quickly.

Amos



From eliezer at ngtech.co.il  Sun Aug 21 13:23:04 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 21 Aug 2016 16:23:04 +0300
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <1471700484064-4679067.post@n4.nabble.com>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
 <1471524821802-4679021.post@n4.nabble.com>
 <1471529712673-4679025.post@n4.nabble.com>
 <00c001d1f961$2d31fe10$8795fa30$@ngtech.co.il>
 <1471700484064-4679067.post@n4.nabble.com>
Message-ID: <011801d1fbaf$25e1ab10$71a50130$@ngtech.co.il>

Well it's pretty simple, I have used squd 4.0.13 with default settings and the rules you provided ie:
squid.conf:
store_id_program /usr/lib64/squid/storeid_file_rewrite /etc/squid/storeid-rules
store_id_children 40 startup=10 idle=5 concurrency=0
store_id_access allow GET
store_id_access deny all

/etc/squid/storeid-rules:
^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$) http://instagramcdn.squid.internal/$1

But I am not sure how you decided on the StoreID structure. I am pretty sure you can replace the ".*" with a much more accurate rule such as in:
^http:\/\/igcdn-(photos|videos)-([a-z]+)-a\.akamaihd\.net/hphotos-ak-([a-z0-9]+)/(t5[\.\-\_\/a-z0-9]+?)(?:\?|$) http://instagramcdn.squid.internal/$4

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Saturday, August 20, 2016 4:41 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Yet another store_id question HIT MISS

I have also tested with several browsers, PCs etc . Also i have disabled
every refresh pattern except default squid rules as like as yours . Same
result . 

The only way to get hits are the way i mentioned in
http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679025.html


Do you tested when enabled my storeid config (mentioned in my first email )
was there ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679067.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Sun Aug 21 16:50:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 21 Aug 2016 22:50:14 +0600
Subject: [squid-users] Yet another store_id question HIT MISS
In-Reply-To: <011801d1fbaf$25e1ab10$71a50130$@ngtech.co.il>
References: <1471441429858-4678972.post@n4.nabble.com>
 <7572f612-a999-27a2-7366-03c467029980@treenet.co.nz>
 <1471444578446-4678983.post@n4.nabble.com>
 <034f01d1f8bd$1d3476e0$579d64a0$@ngtech.co.il>
 <1471524821802-4679021.post@n4.nabble.com>
 <1471529712673-4679025.post@n4.nabble.com>
 <00c001d1f961$2d31fe10$8795fa30$@ngtech.co.il>
 <1471700484064-4679067.post@n4.nabble.com>
 <011801d1fbaf$25e1ab10$71a50130$@ngtech.co.il>
Message-ID: <aef5e002-38b0-70ab-7f8d-985c6dba2817@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


21.08.2016 19:23, Eliezer Croitoru ?????:
> Well it's pretty simple, I have used squd 4.0.13 with default settings and the rules you provided ie:
> squid.conf:
> store_id_program /usr/lib64/squid/storeid_file_rewrite
/etc/squid/storeid-rules
> store_id_children 40 startup=10 idle=5 concurrency=0
> store_id_access allow GET
> store_id_access deny all
>
> /etc/squid/storeid-rules:
> ^http:\/\/igcdn-.*\.akamaihd\.net/hphotos-ak-.*/(t5.*?)(?:\?|$)
http://instagramcdn.squid.internal/$1
>
> But I am not sure how you decided on the StoreID structure. I am
pretty sure you can replace the ".*" with a much more accurate rule such
as in:
>
^http:\/\/igcdn-(photos|videos)-([a-z]+)-a\.akamaihd\.net/hphotos-ak-([a-z0-9]+)/(t5[\.\-\_\/a-z0-9]+?)(?:\?|$)
http://instagramcdn.squid.internal/$4
I suggests here is required efficiency agains accuracy. ".*" in some
cases requires less steps.
>
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of Omid Kosari
> Sent: Saturday, August 20, 2016 4:41 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Yet another store_id question HIT MISS
>
> I have also tested with several browsers, PCs etc . Also i have disabled
> every refresh pattern except default squid rules as like as yours . Same
> result .
>
> The only way to get hits are the way i mentioned in
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679025.html
>
>
> Do you tested when enabled my storeid config (mentioned in my first
email )
> was there ?
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Yet-another-store-id-question-HIT-MISS-tp4678972p4679067.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXudvGAAoJENNXIZxhPexGO8EH/2aZEapcMeO3q4MOeP2/hVz4
/8hc3xwjai72Uk0hQ2LWt/jB34GEs7FUPYi3i51nKpI6+qYHcvDbGwTGn6DXdTdV
8VSR/NIyrDTNSBKoZDNvkyWDm45H4W0HYwRRrG0XMVagyZpDFj8JzNwt6iXvlJdY
mSHkxP5wslbhpXG/+cD4nqKEjLGBvSjr+7Jp4/py4D1KXd8BFsg1wh78wwCiAUUp
WnCVsdvsHIW3TDUNYQuQE8d4ONktklm6aRo62McYr3VGnb4w0dI5IpnXKnDOzfUP
7rIq0kfykWkQSn/MN5ibz/AInrxyCe7Tp7TFiufbr+aFPFbltmA6obBW+qRxU24=
=dxxA
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160821/9b5ff296/attachment.key>

From yan at seiner.com  Sun Aug 21 17:31:22 2016
From: yan at seiner.com (Yan Seiner)
Date: Sun, 21 Aug 2016 10:31:22 -0700
Subject: [squid-users] Viber + squid = no images
Message-ID: <E1bbWaq-0007Sq-1d@mail.seiner.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160821/cf0d3492/attachment.htm>

From yvoinov at gmail.com  Sun Aug 21 17:32:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 21 Aug 2016 23:32:49 +0600
Subject: [squid-users] Viber + squid = no images
In-Reply-To: <E1bbWaq-0007Sq-1d@mail.seiner.com>
References: <E1bbWaq-0007Sq-1d@mail.seiner.com>
Message-ID: <7babc922-bd1a-1a70-0dd9-44117bba2df4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Show your logs and config.


21.08.2016 23:31, Yan Seiner ?????:
>
> I'm struggling with a strange problem. I have squid 2.4 set up as a
transparent proxy.  Everything works fine, except that Viber will not
download images.
>
> Has anyone run across this?  I don't even know where to start, as
nothing else seems broken and viber, alas, does not provide any diagnostics.
>
> More info on Viber: viber.com
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXueXBAAoJENNXIZxhPexGTXMIAJ7dslHfQQTaeh/96r710SUQ
Zs+TkHagSlP2sMzJgzq3C4HvdotT7fiVoLrEcygs0ox96fFateiF1BXP2XttOtwo
tcbvrTsgZ4XikHCcNiJHyOtQps5T1+2JfHZ71zOyE3M/HSzMv+cPL4JmUabCO76x
6c8c1MhJqrENqTc+mZlwkDRoc/1rzlD/5L6iEUM9S1WOKPXpnb4i3UP4tAZNtXQh
ZJ2Bh4F4K9E5iwLnIdGnv+cdy5Ve1gvAe3VtrdgRNzqP0BM/eFcGSStpxdofKYi7
lkfXR4fLzWKJv9jBm6OoIRdWLHDwbrHCW9ltTOse6iDXTo0MirJDei0AwHxTYOw=
=98Kg
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160821/7c21ac4c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160821/7c21ac4c/attachment.key>

From splash at gmail.com  Sun Aug 21 22:54:36 2016
From: splash at gmail.com (Diogenes S. Jesus)
Date: Mon, 22 Aug 2016 00:54:36 +0200
Subject: [squid-users] dynamic group using URI as group name on external acl
	with ext_ldap_group_acl
Message-ID: <CAD8MJvAEM-zmVAntSGqeJhqXECZjv=W=qhASS=f77w4DAx+ttA@mail.gmail.com>

Hi everyone.

I've the following use case to be accomplished using ACL:

- Allow any authenticated user who is member of a group named after the URI

To construct this I've built the following squid.conf (snippet):

---------
auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -d -r
auth_param negotiate children 10
auth_param negotiate keep_alive on

external_acl_type ldap_HTTP %LOGIN %URI
/usr/lib/squid/ext_ldap_group_acl -D "cn=admin,dc=example,dc=com" -w
test -R -b "ou=authorization,dc=example,dc=com" -B
"ou=people,dc=example,dc=com" -f
'(&(objectclass=groupOfNames)(cn=%g)(member=uid=%u,ou=people,dc=example,dc=com))'
-h ldap01.example.com -d

acl allow_HTTP_ACL external ldap_HTTP ""

http_access deny !allow_HTTP_ACL all
http_access allow allow_HTTP_ACL
http_access deny all
---------

I call it a "dynamic" acl, because the value of the group is the
actual URI (the search filter will expand like:
cn=<URI>,ou=authorization,dc=example,dc=com). For that
"allow_HTTP_ACL" passes "" to ldap_HTTP.

This is working, however that's not documented. I was wondering how
this works, so I debugged.

I found out the %<template filter var> expands as following for the
following search filter:
-f '(&(objectclass=groupOfNames)(<template_filter_reference>=%<template_filter>)(member=uid=%u,ou=people,dc=example,dc=com))'

1) '(&(objectclass=groupOfNames)(a=%a)(member=uid=%u,ou=people,dc=example,dc=com))':
ext_ldap_group_acl.cc(718): pid=25913 :group filter
'(&(objectclass=groupOfNames)(a=http://web.example.com/)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=ou=authorization,dc=example,dc=com'
ext_ldap_group_acl.cc(718): pid=25913 :group filter
'(&(objectclass=groupOfNames)(a=GET)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=authorization,dc=example,dc=com'
ext_ldap_group_acl.cc(718): pid=25913 :group filter
'(&(objectclass=groupOfNames)(a=80)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=authorization,dc=example,dc=com'

2) '(&(objectclass=groupOfNames)(b=%b)(member=uid=%u,ou=people,dc=example,dc=com))':
ext_ldap_group_acl.cc(579): pid=26068 :Connected OK
ERROR: Unknown filter template string %b
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(b=L?II??U", user="john_doe",
group="http://web.example.com/"
ERROR: Unknown filter template string %b
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(b=L?II??U", user="john_doe",
group="GET"
ERROR: Unknown filter template string %b
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(b=L?II??U", user="john_doe",
group="80"

3) '(&(objectclass=groupOfNames)(c=%c)(member=uid=%u,ou=people,dc=example,dc=com))':
ERROR: Unknown filter template string %c
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(c=??>?U", user="john_doe",
group="http://web.example.com/"
ERROR: Unknown filter template string %c
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(c=??>?U", user="john_doe",
group="GET"
ERROR: Unknown filter template string %c
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(c=??>?U", user="john_doe",
group="80"

4) '(&(objectclass=groupOfNames)(test=%test)(member=uid=%u,ou=people,dc=example,dc=com))':
ERROR: Unknown filter template string %t
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(test=?,?U", user="john_doe",
group="http://web.example.com/"
ERROR: Unknown filter template string %t
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(test=?,?U", user="john_doe",
group="GET"
ERROR: Unknown filter template string %t
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(test=?,?U", user="john_doe",
group="80"

5) '(&(objectclass=groupOfNames)(v=%v)(member=uid=%u,ou=people,dc=example,dc=com))':
ext_ldap_group_acl.cc(718): pid=26314 :group filter
'(&(objectclass=groupOfNames)(v=john_doe)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=authorization,dc=example,dc=com'
ext_ldap_group_acl.cc(718): pid=26314 :group filter
'(&(objectclass=groupOfNames)(v=john_doe)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=authorization,dc=example,dc=com'
ext_ldap_group_acl.cc(718): pid=26314 :group filter
'(&(objectclass=groupOfNames)(v=john_doe)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=authorization,dc=example,dc=com'


6) '(&(objectclass=groupOfNames)(g=%g)(member=uid=%u,ou=people,dc=example,dc=com))':
ext_ldap_group_acl.cc(718): pid=26408 :group filter
'(&(objectclass=groupOfNames)(g=http://web.example.com/)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=authorization,dc=example,dc=com'
ext_ldap_group_acl.cc(718): pid=26408 :group filter
'(&(objectclass=groupOfNames)(g=GET)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=authorization,dc=example,dc=com'
ext_ldap_group_acl.cc(718): pid=26408 :group filter
'(&(objectclass=groupOfNames)(g=80)(member=uid=john_doe,ou=people,dc=example,dc=com))',
searchbase 'ou=authorization,dc=example,dc=com'

This is all pretty much happening here
[https://github.com/squid-cache/squid/blob/master/helpers/external_acl/LDAP_group/ext_ldap_group_acl.cc#L638]

So conclusions:
- %v and %u both map to "user", which is expected (historical reasons
& compatibility)
- %g and %a both map to "group", which is expected (historical reasons
& compatibility)
- any other template filter (%b, %c, %test, etc) is trash (only %a,
%u, %g, %v won't yield error)
- when "" is passed to the acl ("acl <ACL_name> external ldap_HTTP
""), the helper will attempt all FORMAT values, mapping then to
"group" (%a or %g)


Although I can move on with this for now, I would be actually more
relieved if I could use:
acl allow_HTTP_ACL external ldap_HTTP
<a_var_which_is_available_here_representing_URI>
 instead of
acl allow_HTTP_ACL external ldap_HTTP ""  + non-documented behavior of
ext_ldap_group_acl

However I don't know that <acl> directive has access to the URI
variable. Tips anyone?

Best regards


From timp87 at gmail.com  Mon Aug 22 09:00:29 2016
From: timp87 at gmail.com (Pavel Timofeev)
Date: Mon, 22 Aug 2016 12:00:29 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <CAAvSkVEZD4K3nCKDEvsuQ-Gv9o-CEapC_0F=X3Huctb8WJjNgA@mail.gmail.com>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <5761327F.5010400@urlfilterdb.com>
 <CAAvSkVEZD4K3nCKDEvsuQ-Gv9o-CEapC_0F=X3Huctb8WJjNgA@mail.gmail.com>
Message-ID: <CAAoTqfs_Y3bef6Ji_5wz-Teg3zn9sfKWqNN7vvLCDK7wwuKp9A@mail.gmail.com>

2016-06-15 14:24 GMT+03:00 reqman <reqman at freemail.gr>:
> 2016-06-15 13:48 GMT+03:00 Marcus Kool <marcus.kool at urlfilterdb.com>:
>>
>>
>> On 06/15/2016 04:22 AM, reqman wrote:
>>>
>>> Hello all,
>>>
>>> I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD
>>> 8.x box for years. Started out some 10 years ago, with a much older
>>> squid/squidguard/FreeBSD combination.
>>>
>>> Having to upgrade to FreeBSD 10.3, I examined my option regarding
>>> squid. 3.5.19 was available which I assumed would behave the same as
>>> 2.7, regarding compatibility. Squidguard 1.4 was also installed.
>>
>>
>> A great decision to go to Squid 3.5.19, but it is a large leap so
>> you might expect some compatibility issues.
>>
>> Squidguard has no support nor maintenance for many years and the patch
>> for squidguard to become compatible with squid 3.4+ was written by a Squid
>> developer.
>> Hence I recommend to install ufdbGuard, which is a fork of squidGuard and
>> does have support and updates.  ufdbGuard is also 3x faster and uses less
>> memory, so plenty of reasons to say goodbye to squidGuard.
>
> I have been using squidGuard for 10+ years. Not the best one could
> have, but I am accustomed to its use and idiosyncrasies. Furthermore,
> it is package well supported on FreeBSD.
>
> You are mentioning ufdbGuard. Are its lists free for government use?
> If not, then I can not use it, since we have very strict purchasing
> requirements, even if it costs $1. And of course, I would have to go
> through evaluation, the usual learning curve etc.
>
> Don't get me wrong here, I'm not saying no. I'm just saying that even
> though it seems to be easy to say "yes", reality is much different.
>
> M.-
>

Hi!

I've made a freebsd port for ufdbGuard.
https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=212044
I'd appreciate any kind of feedback.

>>
>> Marcus
>>
>>
>>> - Squid was configured to behave along the lines of what I had on 2.7.
>>> - For squidguard I used the exact same blocklists and configurations.
>>> Note that I do not employ an URL rewriting in squidguard, only
>>> redirection.
>>> - no SSL-bump or other SSL interception takes place
>>> - the squidguard-related lines on squid are the following:
>>>
>>> url_rewrite_program /usr/local/bin/squidGuard
>>> url_rewrite_children 8 startup=4 idle=4 concurrency=0
>>> url_rewrite_access allow all
>>>
>>> - In squidGuard.conf, the typical redirect section is like:
>>>
>>>   default {
>>>                  pass local-ok !block1 !block2 !blockN all
>>>                  redirect
>>>
>>> 301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+srcclass=%s+targetclass=%t+url=%u
>>>          }
>>>
>>> I am now experiencing problems that I did not have. Specifically,
>>> access to certain but *not* all HTTPS sites seems to timeout.
>>> Furthermore, I see entries similar to the following in cache.log:
>>>
>>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>>> remote=192.168.2.239:3446 FD 591 flags=1
>>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>>> remote=192.168.2.239:3448 FD 592 flags=1
>>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>>> remote=192.168.2.239:3452 FD 594 flags=1
>>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>>> remote=192.168.2.239:3456 FD 596 flags=1
>>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>>> remote=192.168.2.239:3454 FD 595 flags=1
>>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>>> remote=192.168.2.239:3458 FD 597 flags=1
>>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>>> remote=192.168.2.239:3462 FD 599 flags=1
>>>
>>> Searching around, the closest I have come to an answer is the
>>> following:
>>> http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html
>>> I am not sure though whether I am plagued by the same issue,
>>> considering that the thread refers to a squid version dated 4 years
>>> ago. And I definitely do not understand what the is meant by the
>>> poster's proposal:
>>>
>>> "If you can't alter the re-writer to perform redirection you can work
>>> around that by using:
>>>
>>>    acl foo ... some test to match the re-written URL ...
>>>    deny_info 302:%s foo
>>>    adapted_http_access deny foo "
>>>
>>> Can someone help resolve this? Is the 2.7 series supported at all? As
>>> is if everything fails, I'll have to go back to it if there's some
>>> support.
>>>
>>> BR,
>>>
>>>
>>> Michael.-
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From garryd at comnet.uz  Mon Aug 22 11:46:47 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Mon, 22 Aug 2016 16:46:47 +0500
Subject: [squid-users] Objects with values below 60 second for Cache-Control
 max-age are not cached
Message-ID: <1471866407.18669.13.camel@comnet.uz>

Hello Squid users,

Can anyone explain, why Squid doesn't cache the objects with max-age
values below 60 seconds? For example:

$ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.local/
cgi-bin/hello.cgi" && date
HTTP/1.1 200 OK
Date: Mon, 22 Aug 2016 11:31:16 GMT
Server: Apache
Cache-Control: max-age=60
Content-Type: text/plain
X-Cache: MISS from gentoo.comnet.uz
Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
Connection: keep-alive

Mon Aug 22 16:31:19 UZT 2016

---

$ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.local/
cgi-bin/hello.cgi" && date
HTTP/1.1 200 OK
Date: Mon, 22 Aug 2016 11:31:23 GMT
Server: Apache
Cache-Control: max-age=60
Content-Type: text/plain
X-Cache: MISS from gentoo.comnet.uz
Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
Connection: keep-alive

Mon Aug 22 16:31:26 UZT 2016


No problems with values above 60 seconds. For example:

$ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.local/
cgi-bin/hello.cgi" && date
HTTP/1.1 200 OK
Date: Mon, 22 Aug 2016 11:36:06 GMT
Server: Apache
Cache-Control: max-age=70
Content-Type: text/plain
X-Cache: MISS from gentoo.comnet.uz
Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
Connection: keep-alive

Mon Aug 22 16:36:09 UZT 2016

---

$ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.local/
cgi-bin/hello.cgi" && date
HTTP/1.1 200 OK
Date: Mon, 22 Aug 2016 11:36:06 GMT
Server: Apache
Cache-Control: max-age=70
Content-Type: text/plain
Age: 5
X-Cache: HIT from gentoo.comnet.uz
Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
Connection: keep-alive

Mon Aug 22 16:36:11 UZT 2016


As you can see, time difference between origin server and localhost is
3 seconds (UZT is +5 offset).

Configuration is minimal:

# diff -u etc/squid.conf.default etc/squid.conf
--- etc/squid.conf.default	2016-08-12 17:21:48.877474780 +0500
+++ etc/squid.conf	2016-08-22 16:41:47.759766991 +0500
@@ -71,3 +71,5 @@
?refresh_pattern ^gopher:	1440	0%	1440
?refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
?refresh_pattern .		0	20%	4320
+
+cache_mem 64 MB


Thanks in advance!
Garri


From squid3 at treenet.co.nz  Mon Aug 22 14:49:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 Aug 2016 02:49:26 +1200
Subject: [squid-users] dynamic group using URI as group name on external
 acl with ext_ldap_group_acl
In-Reply-To: <CAD8MJvAEM-zmVAntSGqeJhqXECZjv=W=qhASS=f77w4DAx+ttA@mail.gmail.com>
References: <CAD8MJvAEM-zmVAntSGqeJhqXECZjv=W=qhASS=f77w4DAx+ttA@mail.gmail.com>
Message-ID: <458f56ba-1312-73f7-0951-d62d74090a67@treenet.co.nz>

On 22/08/2016 10:54 a.m., Diogenes S. Jesus wrote:
> Hi everyone.
> 
> I've the following use case to be accomplished using ACL:
> 
> - Allow any authenticated user who is member of a group named after the URI
> 
> To construct this I've built the following squid.conf (snippet):
> 
> ---------
> auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -d -r
> auth_param negotiate children 10
> auth_param negotiate keep_alive on
> 
> external_acl_type ldap_HTTP %LOGIN %URI
> /usr/lib/squid/ext_ldap_group_acl -D "cn=admin,dc=example,dc=com" -w
> test -R -b "ou=authorization,dc=example,dc=com" -B
> "ou=people,dc=example,dc=com" -f
> '(&(objectclass=groupOfNames)(cn=%g)(member=uid=%u,ou=people,dc=example,dc=com))'
> -h ldap01.example.com -d


Please be aware that the %URI format does not perform any type of shell
or LDAP escaping to protect this helper lookup against shell-injection
attacks.

It is possible that a remote client can end a URL with ')' followed by
any LDAP commands they like and have that executed by your helper.

If you want to do things like this safely please upgrade to Squid-4
where the logformat codes are available. Those codes provide
customizable escaping and quoting styles so you can set one that
protects LDAP against these attacks to be ued on the URI field value
sent by Squid.


> 
> acl allow_HTTP_ACL external ldap_HTTP ""
> 
> http_access deny !allow_HTTP_ACL all
> http_access allow allow_HTTP_ACL
> http_access deny all
> ---------
> 
> I call it a "dynamic" acl, because the value of the group is the
> actual URI

Whereas everyone else calls it dynamic because the ACL test is highly
variable (aka dynamic) based on whatever the custom helper logic is.


> (the search filter will expand like:
> cn=<URI>,ou=authorization,dc=example,dc=com). For that
> "allow_HTTP_ACL" passes "" to ldap_HTTP.
> 
> This is working, however that's not documented. I was wondering how
> this works, so I debugged.
> 
> I found out the %<template filter var> expands as following for the
> following search filter:
> -f '(&(objectclass=groupOfNames)(<template_filter_reference>=%<template_filter>)(member=uid=%u,ou=people,dc=example,dc=com))'
> 
...
> 
> 4) '(&(objectclass=groupOfNames)(test=%test)(member=uid=%u,ou=people,dc=example,dc=com))':
> ERROR: Unknown filter template string %t
> ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
> filter="(&(objectclass=groupOfNames)(test=?,?U", user="john_doe",
> group="http://web.example.com/"
> ERROR: Unknown filter template string %t
> ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
> filter="(&(objectclass=groupOfNames)(test=?,?U", user="john_doe",
> group="GET"
> ERROR: Unknown filter template string %t
> ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
> filter="(&(objectclass=groupOfNames)(test=?,?U", user="john_doe",
> group="80"
> 
> 5) '(&(objectclass=groupOfNames)(v=%v)(member=uid=%u,ou=people,dc=example,dc=com))':
> ext_ldap_group_acl.cc(718): pid=26314 :group filter
> '(&(objectclass=groupOfNames)(v=john_doe)(member=uid=john_doe,ou=people,dc=example,dc=com))',
> searchbase 'ou=authorization,dc=example,dc=com'
> ext_ldap_group_acl.cc(718): pid=26314 :group filter
> '(&(objectclass=groupOfNames)(v=john_doe)(member=uid=john_doe,ou=people,dc=example,dc=com))',
> searchbase 'ou=authorization,dc=example,dc=com'
> ext_ldap_group_acl.cc(718): pid=26314 :group filter
> '(&(objectclass=groupOfNames)(v=john_doe)(member=uid=john_doe,ou=people,dc=example,dc=com))',
> searchbase 'ou=authorization,dc=example,dc=com'
> 


I dont think you quite grok which part of these outputs is the garbage
(uninitialized memory dump), and which part is the incomplete prefix of
the filter string.

Notice the above 'garbage' outputs start with:
 filter="(&(objectclass=groupOfNames)(test=

then obvious garbage:
 ?,?U", user="john_doe", group="GET"

Its not always obvious. As in case #6:


> 
> 6) '(&(objectclass=groupOfNames)(g=%g)(member=uid=%u,ou=people,dc=example,dc=com))':
> ext_ldap_group_acl.cc(718): pid=26408 :group filter
> '(&(objectclass=groupOfNames)(g=http://web.example.com/)(member=uid=john_doe,ou=people,dc=example,dc=com))',
> searchbase 'ou=authorization,dc=example,dc=com'
> ext_ldap_group_acl.cc(718): pid=26408 :group filter
> '(&(objectclass=groupOfNames)(g=GET)(member=uid=john_doe,ou=people,dc=example,dc=com))',
> searchbase 'ou=authorization,dc=example,dc=com'
> ext_ldap_group_acl.cc(718): pid=26408 :group filter
> '(&(objectclass=groupOfNames)(g=80)(member=uid=john_doe,ou=people,dc=example,dc=com))',
> searchbase 'ou=authorization,dc=example,dc=com'

What is happening is that the helper expects the %LOGIN field to be
followed by a list of space-separated 'words'. Each 'word' is a group
name to be checked against the users account memberships. So the list of
words is looked up individually until one matches or none left to check.

So somehow the HTTP request URL/URI is the whole string:
 "GET http://web.example.com/ 80"

-> very odd. It is not even a valid HTTP request-line. Looks more like
some outdated Squid-1.1 URL re-write helper is mangling the URL. But the
order is slightly wrong even for that (GET would be after the actual URL).


Anyhow, that resuls in the ACL group helper receiving:
 john_does GET http://web.example.com/ 80

Meaning,
 username: "john_doe"
 group #1: "GET"
 group #2: "http://web.example.com/"
 group #3: "80"


> 
> This is all pretty much happening here
> [https://github.com/squid-cache/squid/blob/master/helpers/external_acl/LDAP_group/ext_ldap_group_acl.cc#L638]
> 
> So conclusions:
> - %v and %u both map to "user", which is expected (historical reasons
> & compatibility)

As documented.

> - %g and %a both map to "group", which is expected (historical reasons
> & compatibility)

As documented.

> - any other template filter (%b, %c, %test, etc) is trash (only %a,
> %u, %g, %v won't yield error)

Nod. The helper autor(s) reserve other %-code to be defined with any
arbitrary meaning at any time. So there is simply no documented
behaviour for them.
 A you found v and a have old meanings that are still supported, though
deprecated so removed from the documentation intentionally to prevent
future use.


> - when "" is passed to the acl ("acl <ACL_name> external ldap_HTTP
> ""), the helper will attempt all FORMAT values, mapping then to
> "group" (%a or %g)

It should mean Squid loads a file with undefined name (\0) and sends
that files content as the list of group names. Each line in the file
being a group name.


> 
> Although I can move on with this for now, I would be actually more
> relieved if I could use:
> acl allow_HTTP_ACL external ldap_HTTP
> <a_var_which_is_available_here_representing_URI>
>  instead of
> acl allow_HTTP_ACL external ldap_HTTP ""  + non-documented behavior of
> ext_ldap_group_acl

Dont specify anything at all in that position. The %URI field you
defined to be sent to the helper should be formatted in the place it
expects to find a group name "word" as mentioned above.

Just use:
 acl allow_HTTP_ACL external ldap_HTTP


Amos



From erdosain9 at gmail.com  Mon Aug 22 16:24:22 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 22 Aug 2016 09:24:22 -0700 (PDT)
Subject: [squid-users] AD Ldap (automatically take the user that is
	logging on PC)
In-Reply-To: <ebd59d41-544f-a60e-cfe5-0d6308cc1dc8@treenet.co.nz>
References: <6e111284-02d4-0b3c-a62d-36436cfea421@gmail.com>
 <1471472958047-4678996.post@n4.nabble.com>
 <CAARxGtgVGopg=YQPz73pE_DbjSvQEq46x2pzSjL69CwKmuKy1g@mail.gmail.com>
 <VI1PR04MB1359AAF2907AC708D5F47A938F150@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <1471620011751-4679045.post@n4.nabble.com>
 <78607b31-cdb0-3c02-d76b-f247fdd02dc7@gmail.com>
 <1471630581076-4679049.post@n4.nabble.com>
 <bfed0fbc-084b-2fb1-d35f-5342e13678ec@gmail.com>
 <1471634038246-4679053.post@n4.nabble.com>
 <ebd59d41-544f-a60e-cfe5-0d6308cc1dc8@treenet.co.nz>
Message-ID: <1471883062872-4679081.post@n4.nabble.com>

Hi. Im having problems with Kerberos.
I cannot do the keytab...

kinit squid (all good)
-----------------------------------------------------------------------------------------------------
klist
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: squid at xxxxxxx.LAN

Valid starting     Expires            Service principal
22/08/16 13:17:55  22/08/16 23:17:55  krbtgt/xxxxxx.LAN at xxxxx.LAN (THIS IS
NOT STRANGE???!--- I mean krbtgt/*EXAMPLE.LAN at EXAMPLE.LAN*)
	renew until 23/08/16 13:17:51
-------------------------------------------------------------------------------------------------------
msktutil -c -b "CN=Computers" -s HTTP/squid.xxxxx.lan -k
/etc/squid/PROXY.keytab --computer-name SQUIDPROXY-K --upn
HTTP/squid.xxxxxx.lan --server d02.xxxxxx.lan --verbose --enctypes 28

 -- init_password: Wiping the computer password structure
 -- generate_new_password: Generating a new, random password for the
computer account
 -- generate_new_password:  Characters read from /dev/udandom = 84
 -- create_fake_krb5_conf: Created a fake krb5.conf file:
/tmp/.msktkrb5.conf-cfazrB
 -- reload: Reloading Kerberos Context
 -- finalize_exec: SAM Account Name is: SQUIDPROXY-K$
 -- try_machine_keytab_princ: Trying to authenticate for SQUIDPROXY-K$ from
local keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Client not found in Kerberos database)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_keytab_princ: Trying to authenticate for host/localhost from
local keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Client not found in Kerberos database)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_password: Trying to authenticate for SQUIDPROXY-K$ with
password.
 -- create_default_machine_password: Default machine password for
SQUIDPROXY-K$ is squidproxy-k
 -- try_machine_password: Error: krb5_get_init_creds_keytab failed (Client
not found in Kerberos database)
 -- try_machine_password: Authentication with password failed
 -- try_user_creds: Checking if default ticket cache has tickets...
 -- finalize_exec: Authenticated using method 4

 -- ldap_connect: Connecting to LDAP server: d02.xxxxxx.lan try_tls=YES
 -- ldap_connect: Connecting to LDAP server: d02.xxxxxx.lan try_tls=NO
SASL/GSSAPI authentication started
SASL username: squid at xxxxxx.LAN
SASL SSF: 56
SASL data security layer installed.
 -- ldap_connect: LDAP_OPT_X_SASL_SSF=56

 -- ldap_get_base_dn: Determining default LDAP base: dc=xxxxxxx,dc=LAN
 -- ldap_check_account: Checking that a computer account for SQUIDPROXY-K$
exists
 -- ldap_check_account: Computer account not found, create the account

No computer account for SQUIDPROXY-K found, creating a new one.
dn: cn=SQUIDPROXY-K,CN=Computers,dc=xxxxx,dc=LAN
Error: ldap_add_ext_s failed (Insufficient access)
 -- ~KRB5Context: Destroying Kerberos Context


-------------------------------------------------------------------------------------

*/etc/krb5.conf
*

[libdefaults]
    default_realm = XXXXXXX.LAN
    dns_lookup_kdc = no
    dns_lookup_realm = no
    ticket_lifetime = 24h
    default_keytab_name = /etc/squid/PROXY.keytab

; for Windows 2003
;    default_tgs_enctypes = rc4-hmac des-cbc-crc des-cbc-md5
;    default_tkt_enctypes = rc4-hmac des-cbc-crc des-cbc-md5
;    permitted_enctypes = rc4-hmac des-cbc-crc des-cbc-md5

; for Windows 2008 with AES
    default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
    default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
    permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5

[realms]
    EMPDHPR.LAN = {
        kdc = d02.xxxxxx.lan
        admin_server = d02.xxxxxxx.lan
        default_domain = xxxxxxxx.lan
    }



What i can do??
Is necessary another info???




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Ldap-automatically-take-the-user-that-is-logging-on-PC-tp4678994p4679081.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Mon Aug 22 17:00:05 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 22 Aug 2016 20:00:05 +0300
Subject: [squid-users] squid shutdown or reconfigure in Multi-instance
	environment 3.5.2
In-Reply-To: <999378EF-24FA-4612-872D-4442AA0C68B2@gmail.com>
References: <801BA207-C533-49A9-AD1F-0A49A88BEBEC@netstream.ps>
 <33a60130-b907-059e-5225-435449116a45@treenet.co.nz>
 <999378EF-24FA-4612-872D-4442AA0C68B2@gmail.com>
Message-ID: <1E956086-3081-4C51-9357-20E77B4934CB@netstream.ps>

> yes amos i have each instance its own PID
> 
> ok thanks i will upgrade to the newer version 
> 
> thank you 




> 
> 
> 
>> On Aug 20, 2016, at 2:59 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> 
>> On 20/08/2016 11:48 a.m., --Ahmad-- wrote:
>>> Hi Squid-users
>>> ==========
>>> I?m using squid 3.5.2 as multi instances .
>>> 
>> 
>> There were problems with -n up to 3.5.9. Though please upgrade right to
>> 3.5.19 or 3.5.20 to avoid the major security issues that have been fixed
>> this past year.
>> 
>> NP: if you have pid_filename configured, you need to ensure it is unique
>> for each named service so they dont overrite other services PID vaues.
>> So use the ${service_name} macro in Squid-3 configs. Squid-4 takes care
>> of that by default.
>> 
>> Amos
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 



From ahmed.zaeem at netstream.ps  Mon Aug 22 18:01:14 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 22 Aug 2016 21:01:14 +0300
Subject: [squid-users] best way to have randomized outgoing per each new
	connection
Message-ID: <14BD3F10-BA3C-495C-9992-CE375CD10F25@netstream.ps>

Hi Guys . (squid users) :)

I?m wondering here ? what is the best method so that i give randomized tcp outgoing address per new session.

let me explain well .

say that i have 100 ips  on squid .

i want each new connection to squid comes to have a specified outgoing address from the 100 pool

say i connected to port xxx on squid  i want to have outgoing ip like ip1

say i closed my browser or disconnected the session and connected again to have ip2 and keep on ip2 until session is closed or dead or timeout .


again i don?t want to have trouble with the current connection or instability with the current connection .

say that the main ip of squid/server was 1.2.3.4
i want to access the server 1.2.3.4:port 3128

and in each connection or new connection it go outside one of the 100 ips i have in the pool .


im not sure what is the best :
iptables , redsocks or squid or even combination between them 

i will be using squid 3.5.lastver





my kind regards





From ahmed.zaeem at netstream.ps  Mon Aug 22 18:03:17 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 22 Aug 2016 21:03:17 +0300
Subject: [squid-users] squid shutdown or reconfigure in Multi-instance
	environment 3.5.2
In-Reply-To: <CAKikXHpsWYU9y8GYtWuCCXh+hhyEG21XcDrqpRZGuMuNhq01PA@mail.gmail.com>
References: <801BA207-C533-49A9-AD1F-0A49A88BEBEC@netstream.ps>
 <33a60130-b907-059e-5225-435449116a45@treenet.co.nz>
 <999378EF-24FA-4612-872D-4442AA0C68B2@gmail.com>
 <1E956086-3081-4C51-9357-20E77B4934CB@netstream.ps>
 <CAKikXHpsWYU9y8GYtWuCCXh+hhyEG21XcDrqpRZGuMuNhq01PA@mail.gmail.com>
Message-ID: <404141FD-2EBD-4AE7-926B-12A46BD7C5BC@netstream.ps>

most squid mailing list is  an advanced topics  and very hard to be understood for a newbie .


i would advise you to read and understand squid from blogger websites .

try to read squid book 


cheers

> On Aug 22, 2016, at 8:45 PM, sallo baloch <harisrind284 at gmail.com> wrote:
> 
>  plz tell me how to learn squid proxy from screcth
> 
> On Mon, Aug 22, 2016 at 10:00 PM, --Ahmad-- <ahmed.zaeem at netstream.ps <mailto:ahmed.zaeem at netstream.ps>> wrote:
> > yes amos i have each instance its own PID
> >
> > ok thanks i will upgrade to the newer version
> >
> > thank you
> 
> 
> 
> 
> >
> >
> >
> >> On Aug 20, 2016, at 2:59 PM, Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>> wrote:
> >>
> >> On 20/08/2016 11:48 a.m., --Ahmad-- wrote:
> >>> Hi Squid-users
> >>> ==========
> >>> I?m using squid 3.5.2 as multi instances .
> >>>
> >>
> >> There were problems with -n up to 3.5.9. Though please upgrade right to
> >> 3.5.19 or 3.5.20 to avoid the major security issues that have been fixed
> >> this past year.
> >>
> >> NP: if you have pid_filename configured, you need to ensure it is unique
> >> for each named service so they dont overrite other services PID vaues.
> >> So use the ${service_name} macro in Squid-3 configs. Squid-4 takes care
> >> of that by default.
> >>
> >> Amos
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> >> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
> >
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160822/396aae6f/attachment.htm>

From rousskov at measurement-factory.com  Mon Aug 22 19:20:51 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 22 Aug 2016 13:20:51 -0600
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
Message-ID: <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>

On 08/21/2016 06:46 AM, Marcus Kool wrote:
> there are still some issues with the wiki page that I like to clarify.

Thanks a lot for working on this!


> wiki: http://wiki.squid-cache.org/Features/SslPeekAndSplice
> 
> section "processing steps"
> 
> Can action "none" be removed from step 1?

Done.


> Step 1.  what is "CONNECT info"?  In the introduction one speaks
> of "HTTP CONNECT" which has a FQDN.  But the fake CONNECT sent to
> a URL rewriter has only an IP address.

CONNECT info is the info associated with a CONNECT request, real or fake
(depending on the http*_port being used for the transaction). Real
CONNECT requests often have FQDNs. Fake CONNECT requests have IP
addresses during step1.


> Why is the fake CONNECT that is sent to the URL rewriter done
> at step 1 where only the IP and not the FQDN is available?

... because some rewriters want/need those CONNECTs, for various
reasons. The overall design here is simple and logical in my biased
opinion: Send everything by default but let admin control what should be
sent. If _your_ rewriter does not need some CONNECTs, configure Squid
not to send those unwanted CONNECTS to the rewriter. If Squid lacks ACLs
to detect unwanted CONNECTs, add support for those missing ACLs.

The url_rewrite_access directive controls what transactions are sent to
the redirector.

Note that CONNECTs should be sent both during step1 and during step2 by
default.


> In section "Peek at SNI and Bump" it is stated that SNI is obtained in
> step 1. This contradicts the text at step 1 and 2.

In section "Peek at SNI and Bump" it is NOT stated that SNI is obtained
in step 1. It is stated that SNI is obtained by peeking during step 1.
"obtaining SNI" and "peeking" are not the same! If, during step 1, you
tell Squid to peek, then, during step 2, Squid peeks and obtains SNI.

There is no contradiction, but we are definitely struggling with how to
describe what is going on. Specific improvement suggestions are very
welcomed.


> squid.conf.documented has this:
> #  At each SslBump step, Squid evaluates ssl_bump directives to find
> #  the *next* bumping action (e.g., peek or splice).
> Emphasis on "*next* bumping action".
> Should the wiki be reworded and use "next bumping action"?

Please suggest complete specific fixes. We know that the current wiki
text is difficult to follow for many so the attempts to rework it are
welcomed.


> Section "Actions"
> 
> item peek: Receive client SNI (step1), or server certificate (step2)  ...
> This contradicts the explanation of the processing steps.
> item stare: likewise.

I do not think it does (see the "peeking during step1 tells Squid to get
SNI during step2" discussion above), but please suggest a better way to
phrase those descriptions. We know they are confusing. SNI (and
certificate parsing) happens at the beginning of stepN+1 but whether
that step happens at all depends on the stepN action.


> I suggest to remove the "Deprecated actions" or use a BOLD warning not
> to use them.

I do not think we should remove them because comparing their description
with the currently supported actions may be very useful for upgrading
admins. Does not Squid already emit a deprecation WARNING when those
actions are used?

If you know how to gray-out the rows with deprecated actions, please do
that. Otherwise (or in addition to that), please feel free to add a
"Avoid this deprecated, poorly supported, and soon to be deleted
action." or similar text to each deprecated action description.


> Section "Mimicking SSL client Hello properties when staring"
> The section has "The information in this section is incomplete and
> somewhat stale."
> Is there any information to update this section ?

Yes, but it is only Squid sources and possibly commit log :-(.


> section "Examples"
> 
> I usually write explicit rules like this:

> # do not touch servers where ssl-bump breaks HSTS
> acl tls_allowed_hsts ...
> # prevent bumping some allowed servers with self-signed certificates
> acl tls_allowed_selfsigned ...
...

I recommend against documenting ACLs as actions. Your tls_allowed_hsts
does not prevent touching anything. Your tls_allowed_selfsigned does not
prevent bumping of any connections. Etc. ACLs are conditions. They only
identify certain transactions. They do not touch/prevent/allow/block
anything. The rules that use those ACLs do all that.


> # TLS/SSL bumping steps
> ssl_bump peek   tls_s1_ip_connect   all                 # peek a client connecting at IP level
> ssl_bump splice tls_s2_client_hello tls_to_splice       # splice some: do not bump/interfere
> ssl_bump stare  tls_s2_client_hello all                 # connect to the server and stare(peek) at its TLS/SSL properties
> ssl_bump bump   tls_s3_server_hello all                 # bump if we can (tls_s2_client_hello/stare succeeded)


> The above rules follow the steps of the wiki page but
> the examples on the wiki have optimised rules and sometimes
> there are messages on the mailing list that rules can be optimized
> to save CPU cycles.


It is not primarily about CPU optimization. It is about readability.

> The last 4 lines of the example can be optimized into

> ssl_bump peek   tls_s1_ip_connect   all
> ssl_bump splice tls_s2_client_hello tls_to_splice
> ssl_bump stare  all
> ssl_bump bump   all

Actually, they should be written as:

  ssl_bump peek   tls_s1_ip_connect
  ssl_bump splice tls_to_splice
  ssl_bump stare  all
  ssl_bump bump   all


And, most likely (possibly after some ACL adjustments) can be further
clarified as:

  ssl_bump splice tls_to_splice
  ssl_bump stare  all
  ssl_bump bump   all

Which is a lot clearer for some, but not for others.


> I prefer not to optimize since reading the rules is
> easier and one understands better what happens at each step.

It is a matter of taste.


> However, if a significant number of CPU cycles are saved, I suggest to
> include an example like above and rules of thumb on how to optimize and the
> final optimized results so that a less experienced reader understands
> the optimizations.

Please do, but this is not about optimization. It is about describing
desired outcome in two different ways:

* If you want to be verbose and prefix every rule with the step it
applies to, then you can do that (at the elevated risk of forgetting to
tell Squid what to do in some cases among all the noise).

* If you want to express the essence of your configuration, you can do
that instead (at the risk of misinterpreting which step a rule will be
applied at, due to increased complexity).


There are only two "noise reduction" or "condensing" rules AFAICT:

1. Do not say "large green all". Just say "large green".
2. Splice and peek rules are ignored during step 3.



> The examples in "Avoid bumping banking traffic" :
> I can image what used (but not defined) serverIsBank acl looks like:
>    acl serverIsBank  ssl::server_name .santander.com
> but have no idea what the acl haveServerName looks like.
> What is intended here?

IIRC, that example was originally written before ssl::server_name
existed. haveServerName would have to detect a request where the server
name is known (e.g., step2 with SNI or step3). The difficulties with
writing such ACLs is what prompted us to add ssl::server_name. The
example should probably be rewritten as:

  acl serverIsBank ssl::server_name ...
  ssl_bump peek step1
  ssl_bump splice serverIsBank
  ssl_bump bump all

or even

  acl serverIsBank ssl::server_name ...
  ssl_bump splice serverIsBank
  ssl_bump stare all
  ssl_bump bump all

if you do not want Squid to silently bump bank transactions that lack
SNI. I am not sure whether Squid will log level-1 warning when it cannot
splice after staring during step2, but it would be appropriate to teach
Squid to do so IMO (with a rate/count limit of course).

The example description would need to be adjusted accordingly.


Thank you,

Alex.



From splash at gmail.com  Mon Aug 22 19:56:11 2016
From: splash at gmail.com (Diogenes S. Jesus)
Date: Mon, 22 Aug 2016 21:56:11 +0200
Subject: [squid-users] dynamic group using URI as group name on external
 acl with ext_ldap_group_acl
In-Reply-To: <458f56ba-1312-73f7-0951-d62d74090a67@treenet.co.nz>
References: <CAD8MJvAEM-zmVAntSGqeJhqXECZjv=W=qhASS=f77w4DAx+ttA@mail.gmail.com>
 <458f56ba-1312-73f7-0951-d62d74090a67@treenet.co.nz>
Message-ID: <CAD8MJvAutiwk_TTq9_p+FUaAcmE3YdVQUO8584YyH0TR=nmpew@mail.gmail.com>

Hi there. First thanks for taking the time to thoroughly reply to it.

>> external_acl_type ldap_HTTP %LOGIN %URI
>> /usr/lib/squid/ext_ldap_group_acl -D "cn=admin,dc=example,dc=com" -w
>> test -R -b "ou=authorization,dc=example,dc=com" -B
>> "ou=people,dc=example,dc=com" -f
>> '(&(objectclass=groupOfNames)(cn=%g)(member=uid=%u,ou=
people,dc=example,dc=com))'
>> -h ldap01.example.com -d
>
>
> Please be aware that the %URI format does not perform any type of shell
> or LDAP escaping to protect this helper lookup against shell-injection
> attacks.
>
> It is possible that a remote client can end a URL with ')' followed by
> any LDAP commands they like and have that executed by your helper.

I was also concerned about shell injection and LDAP injection but:
- group value is not really passed as shell argument but read from stdin
AFAIU
- I could not see ")" reflected in the LDAP filter. When performing the
following request, for example:

$ curl --proxy-negotiate --negotiate -u : http://web.example")".com/

I see the following lines in the debug log:

ext_ldap_group_acl.cc(579): pid=31325 :Connected OK

ext_ldap_group_acl.cc(718): pid=31325 :group filter
'(&(objectclass=groupOfNames)(cn=web.example\29.com)(member=uid= john_doe
,ou=people,dc=example,dc=com))', searchbase 'ou=authorization,dc=example,
dc=com'

That's because "group" is ldap-escaped when building the LDAP search filter
(https://github.com/squid-cache/squid/tree/master/helpers/external_acl/LDAP_
group#L654) AFAIU.

I have since the message was sent to the mailing list stopped using "%URI
and changed to "%DST" - only because %URI will also add scheme and for SSL,
port number.

Regardless, your point may still be valid for those passing argument to the
binary. Minor pentests I did didn't show much of a security risk here.

> If you want to do things like this safely please upgrade to Squid-4
> where the logformat codes are available. Those codes provide
> customizable escaping and quoting styles so you can set one that
> protects LDAP against these attacks to be ued on the URI field value
> sent by Squid.

You mean these <http://www.squid-cache.org/Doc/config/logformat/>
logformats are available to be used in acl / external acls @ squid.conf? Or?

.....

>
> What is happening is that the helper expects the %LOGIN field to be
> followed by a list of space-separated 'words'. Each 'word' is a group
> name to be checked against the users account memberships. So the list of
> words is looked up individually until one matches or none left to check.

I forgot to mention that for the debugging I used the following:

external_acl_type ldap_HTTP %LOGIN %URI %METHOD %PORT


So it's perfectly in line with what you mentioned.


So in:


4) '(&(objectclass=groupOfNames)(test=%test)(member=uid=%u,ou=p
eople,dc=example,dc=com))':
ERROR: Unknown filter template string %t
ext_ldap_group_acl: ERROR: Failed to construct LDAP search filter.
filter="(&(objectclass=groupOfNames)(test=?,?U", user="john_doe",

group="http://web.example.com/"


The garbage is here: ?,?U",


>
> So somehow the HTTP request URL/URI is the whole string:
>  "GET http://web.example.com/ 80"
>
> -> very odd. It is not even a valid HTTP request-line. Looks more like
> some outdated Squid-1.1 URL re-write helper is mangling the URL. But the
> order is slightly wrong even for that (GET would be after the actual URL).
>

Sorry - that's because the "%URI %METHOD %PORT" was added as FORMAT, as I
mentioned above.

>
> Anyhow, that resuls in the ACL group helper receiving:
>  john_does GET http://web.example.com/ 80
>
> Meaning,
>  username: "john_doe"
>  group #1: "GET"
>  group #2: "http://web.example.com/"
>  group #3: "80"
>
>
>>
>> This is all pretty much happening here
>> [https://github.com/squid-cache/squid/blob/master/
helpers/external_acl/LDAP_group/ext_ldap_group_acl.cc#L638]
>>
>> So conclusions:
>> - %v and %u both map to "user", which is expected (historical reasons
>> & compatibility)
>
> As documented.
>
>> - %g and %a both map to "group", which is expected (historical reasons
>> & compatibility)
>
> As documented.
>
>> - any other template filter (%b, %c, %test, etc) is trash (only %a,
>> %u, %g, %v won't yield error)
>
> Nod. The helper autor(s) reserve other %-code to be defined with any
> arbitrary meaning at any time. So there is simply no documented
> behaviour for them.
>  A you found v and a have old meanings that are still supported, though
> deprecated so removed from the documentation intentionally to prevent
> future use.
>
>
>> - when "" is passed to the acl ("acl <ACL_name> external ldap_HTTP
>> ""), the helper will attempt all FORMAT values, mapping then to
>> "group" (%a or %g)
>
> It should mean Squid loads a file with undefined name (\0) and sends
> that files content as the list of group names. Each line in the file
> being a group name.

Oh, ok. Got that now.

>
>
>>
>> Although I can move on with this for now, I would be actually more
>> relieved if I could use:
>> acl allow_HTTP_ACL external ldap_HTTP
>> <a_var_which_is_available_here_representing_URI>
>>  instead of
>> acl allow_HTTP_ACL external ldap_HTTP ""  + non-documented behavior of
>> ext_ldap_group_acl
>
> Dont specify anything at all in that position. The %URI field you
> defined to be sent to the helper should be formatted in the place it
> expects to find a group name "word" as mentioned above.
>
> Just use:
>  acl allow_HTTP_ACL external ldap_HTTP
>

I had tried that early on without success - clearly the problem was
somewhere else as this indeed proves to work now. Thanks.

>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 

--------

Diogenes S. de Jesus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160822/3cf5406a/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Aug 22 21:20:46 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 22 Aug 2016 23:20:46 +0200
Subject: [squid-users] best way to have randomized outgoing per each new
	connection
In-Reply-To: <14BD3F10-BA3C-495C-9992-CE375CD10F25@netstream.ps>
References: <14BD3F10-BA3C-495C-9992-CE375CD10F25@netstream.ps>
Message-ID: <201608222320.47279.Antony.Stone@squid.open.source.it>

On Monday 22 August 2016 at 20:01:14, --Ahmad-- wrote:

> I?m wondering here ? what is the best method so that i give randomized tcp
> outgoing address per new session.

How do you define a "session" (in terms that mean something to Squid)?

> say that i have 100 ips  on squid .
> 
> i want each new connection to squid comes to have a specified outgoing
> address from the 100 pool
> 
> say i connected to port xxx on squid  i want to have outgoing ip like ip1
> 
> say i closed my browser or disconnected the session and connected again to
> have ip2 and keep on ip2 until session is closed or dead or timeout .

Please define "session" :)


Antony.

-- 
Python is executable pseudocode.
Perl is executable line noise.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Mon Aug 22 21:31:09 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 23 Aug 2016 03:31:09 +0600
Subject: [squid-users] best way to have randomized outgoing per each new
 connection
In-Reply-To: <201608222320.47279.Antony.Stone@squid.open.source.it>
References: <14BD3F10-BA3C-495C-9992-CE375CD10F25@netstream.ps>
 <201608222320.47279.Antony.Stone@squid.open.source.it>
Message-ID: <dd1e1bc8-3d91-5379-8309-29de0ce57612@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Aha :-)

HTTP is stateless protocol :-)


23.08.2016 3:20, Antony Stone ?????:
> On Monday 22 August 2016 at 20:01:14, --Ahmad-- wrote:
>
>> I?m wondering here ? what is the best method so that i give
randomized tcp
>> outgoing address per new session.
>
> How do you define a "session" (in terms that mean something to Squid)?
>
>> say that i have 100 ips  on squid .
>>
>> i want each new connection to squid comes to have a specified outgoing
>> address from the 100 pool
>>
>> say i connected to port xxx on squid  i want to have outgoing ip like ip1
>>
>> say i closed my browser or disconnected the session and connected
again to
>> have ip2 and keep on ip2 until session is closed or dead or timeout .
>
> Please define "session" :)
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXu28bAAoJENNXIZxhPexGR6MIAKU9M8pCaJfILUG+R0jTvkEZ
714aJYrPsy1sTXdev6VUv+YVHKS8UWtUSgCYEk41jKvpBvuF9aZBPSEX/OWNjW3m
V2mOSc1Ske3iHD/tS26LSvt6wjGT4N4peTAd7RtHO4/8FRzlBF5O0LF1xhMyufDs
qnnhvhHyrKVxUonvhZLuiqleaGbonMHXwe6sgpEsCoQq0Sp/GmsmtJ3HxrvsuPkm
aaRQyIkLe2r/MQkEOeuG/DxTlvnG+VlrRZ8j+oyV8XRpepaSHx6XGRbmjOeRvy7P
pBwXVnKpB1V+bQ2WvKtH8VHW7VlsB8Cdxx6ivraN0gE4P630Mzn5jlOXSZPmUQ0=
=vYcP
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160823/de2b34b5/attachment.key>

From marcus.kool at urlfilterdb.com  Tue Aug 23 02:14:56 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 22 Aug 2016 23:14:56 -0300
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
Message-ID: <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>

Thanks for your reply.
I will start changing the wiki page.
When I think I am done, I will let you know for a review.

What is left is my desire to get a fake CONNECT with FQDN (see below).

Marcus

On 08/22/2016 04:20 PM, Alex Rousskov wrote:
> On 08/21/2016 06:46 AM, Marcus Kool wrote:
>> there are still some issues with the wiki page that I like to clarify.
>
> Thanks a lot for working on this!
>
>
>> wiki: http://wiki.squid-cache.org/Features/SslPeekAndSplice
>>
>> section "processing steps"
>>
>> Can action "none" be removed from step 1?
>
> Done.
>
>
>> Step 1.  what is "CONNECT info"?  In the introduction one speaks
>> of "HTTP CONNECT" which has a FQDN.  But the fake CONNECT sent to
>> a URL rewriter has only an IP address.
>
> CONNECT info is the info associated with a CONNECT request, real or fake
> (depending on the http*_port being used for the transaction). Real
> CONNECT requests often have FQDNs. Fake CONNECT requests have IP
> addresses during step1.
>
>
>> Why is the fake CONNECT that is sent to the URL rewriter done
>> at step 1 where only the IP and not the FQDN is available?
>
> ... because some rewriters want/need those CONNECTs, for various
> reasons. The overall design here is simple and logical in my biased
> opinion: Send everything by default but let admin control what should be
> sent. If _your_ rewriter does not need some CONNECTs, configure Squid
> not to send those unwanted CONNECTS to the rewriter. If Squid lacks ACLs
> to detect unwanted CONNECTs, add support for those missing ACLs.

The fake CONNECT _is_ desired, but with FQDN, to
1) have no differences in the CONNECT information sent to
    the URL rewriter in normal proxy mode and in transparent
    intercept mode.
2) be able to filter.  The url rewriter cannot filter based
    on the IP address, it needs a FQDN/SNI.  The parameter
    %ssl::>sni in url_rewrite_extras is always '-' which is
    not only fatal for _my_ url rewriter.

squid.conf.documented adds to the confusion with
    acl aclname at_step step
    ...
    SslBump1: After getting TCP-level and HTTP CONNECT info.
The forward proxy has a FQDN and the intercept proxy has an IP.
Without this information the confusion is created.

> The url_rewrite_access directive controls what transactions are sent to
> the redirector.
>
> Note that CONNECTs should be sent both during step1 and during step2 by
> default.

I think I missed something.  The URL rewriter on my systems only get IP
addresses, never SNI/FQDN.  And never receives two CONNECTS (i.e. one
at step1 and one at step2).
Can I configure Squid to send a fake CONNECT during step2 ?
What is "during"?  Is the CONNECT sent at the end of step2 so it can
send the SNI?

>> In section "Peek at SNI and Bump" it is stated that SNI is obtained in
>> step 1. This contradicts the text at step 1 and 2.
>
> In section "Peek at SNI and Bump" it is NOT stated that SNI is obtained
> in step 1. It is stated that SNI is obtained by peeking during step 1.
> "obtaining SNI" and "peeking" are not the same! If, during step 1, you
> tell Squid to peek, then, during step 2, Squid peeks and obtains SNI.
>
> There is no contradiction, but we are definitely struggling with how to
> describe what is going on. Specific improvement suggestions are very
> welcomed.
>
>
>> squid.conf.documented has this:
>> #  At each SslBump step, Squid evaluates ssl_bump directives to find
>> #  the *next* bumping action (e.g., peek or splice).
>> Emphasis on "*next* bumping action".
>> Should the wiki be reworded and use "next bumping action"?
>
> Please suggest complete specific fixes. We know that the current wiki
> text is difficult to follow for many so the attempts to rework it are
> welcomed.
>
>
>> Section "Actions"
>>
>> item peek: Receive client SNI (step1), or server certificate (step2)  ...
>> This contradicts the explanation of the processing steps.
>> item stare: likewise.
>
> I do not think it does (see the "peeking during step1 tells Squid to get
> SNI during step2" discussion above), but please suggest a better way to
> phrase those descriptions. We know they are confusing. SNI (and
> certificate parsing) happens at the beginning of stepN+1 but whether
> that step happens at all depends on the stepN action.
>
>
>> I suggest to remove the "Deprecated actions" or use a BOLD warning not
>> to use them.
>
> I do not think we should remove them because comparing their description
> with the currently supported actions may be very useful for upgrading
> admins. Does not Squid already emit a deprecation WARNING when those
> actions are used?
>
> If you know how to gray-out the rows with deprecated actions, please do
> that. Otherwise (or in addition to that), please feel free to add a
> "Avoid this deprecated, poorly supported, and soon to be deleted
> action." or similar text to each deprecated action description.
>
>
>> Section "Mimicking SSL client Hello properties when staring"
>> The section has "The information in this section is incomplete and
>> somewhat stale."
>> Is there any information to update this section ?
>
> Yes, but it is only Squid sources and possibly commit log :-(.
>
>
>> section "Examples"
>>
>> I usually write explicit rules like this:
>
>> # do not touch servers where ssl-bump breaks HSTS
>> acl tls_allowed_hsts ...
>> # prevent bumping some allowed servers with self-signed certificates
>> acl tls_allowed_selfsigned ...
> ...
>
> I recommend against documenting ACLs as actions. Your tls_allowed_hsts
> does not prevent touching anything. Your tls_allowed_selfsigned does not
> prevent bumping of any connections. Etc. ACLs are conditions. They only
> identify certain transactions. They do not touch/prevent/allow/block
> anything. The rules that use those ACLs do all that.
>
>
>> # TLS/SSL bumping steps
>> ssl_bump peek   tls_s1_ip_connect   all                 # peek a client connecting at IP level
>> ssl_bump splice tls_s2_client_hello tls_to_splice       # splice some: do not bump/interfere
>> ssl_bump stare  tls_s2_client_hello all                 # connect to the server and stare(peek) at its TLS/SSL properties
>> ssl_bump bump   tls_s3_server_hello all                 # bump if we can (tls_s2_client_hello/stare succeeded)
>
>
>> The above rules follow the steps of the wiki page but
>> the examples on the wiki have optimised rules and sometimes
>> there are messages on the mailing list that rules can be optimized
>> to save CPU cycles.
>
>
> It is not primarily about CPU optimization. It is about readability.
>
>> The last 4 lines of the example can be optimized into
>
>> ssl_bump peek   tls_s1_ip_connect   all
>> ssl_bump splice tls_s2_client_hello tls_to_splice
>> ssl_bump stare  all
>> ssl_bump bump   all
>
> Actually, they should be written as:
>
>   ssl_bump peek   tls_s1_ip_connect
>   ssl_bump splice tls_to_splice
>   ssl_bump stare  all
>   ssl_bump bump   all
>
>
> And, most likely (possibly after some ACL adjustments) can be further
> clarified as:
>
>   ssl_bump splice tls_to_splice
>   ssl_bump stare  all
>   ssl_bump bump   all
>
> Which is a lot clearer for some, but not for others.
>
>
>> I prefer not to optimize since reading the rules is
>> easier and one understands better what happens at each step.
>
> It is a matter of taste.
>
>
>> However, if a significant number of CPU cycles are saved, I suggest to
>> include an example like above and rules of thumb on how to optimize and the
>> final optimized results so that a less experienced reader understands
>> the optimizations.
>
> Please do, but this is not about optimization. It is about describing
> desired outcome in two different ways:
>
> * If you want to be verbose and prefix every rule with the step it
> applies to, then you can do that (at the elevated risk of forgetting to
> tell Squid what to do in some cases among all the noise).
>
> * If you want to express the essence of your configuration, you can do
> that instead (at the risk of misinterpreting which step a rule will be
> applied at, due to increased complexity).
>
>
> There are only two "noise reduction" or "condensing" rules AFAICT:
>
> 1. Do not say "large green all". Just say "large green".
> 2. Splice and peek rules are ignored during step 3.
>
>
>
>> The examples in "Avoid bumping banking traffic" :
>> I can image what used (but not defined) serverIsBank acl looks like:
>>    acl serverIsBank  ssl::server_name .santander.com
>> but have no idea what the acl haveServerName looks like.
>> What is intended here?
>
> IIRC, that example was originally written before ssl::server_name
> existed. haveServerName would have to detect a request where the server
> name is known (e.g., step2 with SNI or step3). The difficulties with
> writing such ACLs is what prompted us to add ssl::server_name. The
> example should probably be rewritten as:
>
>   acl serverIsBank ssl::server_name ...
>   ssl_bump peek step1
>   ssl_bump splice serverIsBank
>   ssl_bump bump all
>
> or even
>
>   acl serverIsBank ssl::server_name ...
>   ssl_bump splice serverIsBank
>   ssl_bump stare all
>   ssl_bump bump all
>
> if you do not want Squid to silently bump bank transactions that lack
> SNI. I am not sure whether Squid will log level-1 warning when it cannot
> splice after staring during step2, but it would be appropriate to teach
> Squid to do so IMO (with a rate/count limit of course).
>
> The example description would need to be adjusted accordingly.
>
>
> Thank you,
>
> Alex.
>
>
>


From rousskov at measurement-factory.com  Tue Aug 23 03:44:15 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 22 Aug 2016 21:44:15 -0600
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
Message-ID: <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>

On 08/22/2016 08:14 PM, Marcus Kool wrote:
> Thanks for your reply.
> I will start changing the wiki page.
> When I think I am done, I will let you know for a review.

It is best to commit all your intended changes at once (if at all)
rather than to use the public page as a scratch pad -- folks read what
you commit.


> The fake CONNECT _is_ desired, but with FQDN, to

I am not sure whether you are making a general/universal claim (as in
"nobody needs CONNECTs without FQDN") or just documenting your
particular use case. I assume it is the latter. Please note that the
wiki page should focus on the general case (but may document specific
use cases as well, of course).


> 1) have no differences in the CONNECT information sent to
>    the URL rewriter in normal proxy mode and in transparent
>    intercept mode.

You do not control what is being sent to the rewriter in a forward proxy
mode. Some HTTPS clients use FQDNs, some use IP addresses.


> 2) be able to filter.  The url rewriter cannot filter based
>    on the IP address, it needs a FQDN/SNI.

Some rewriters can.


>> Note that CONNECTs should be sent both during step1 and during step2 by
>> default.

> I think I missed something.  The URL rewriter on my systems only get IP
> addresses, never SNI/FQDN.  And never receives two CONNECTS (i.e. one
> at step1 and one at step2).

This is a bug or a missing feature [in your Squid?] IMHO.


> Can I configure Squid to send a fake CONNECT during step2 ?

It should be done automatically IIRC.


> What is "during"?

Each step starts with obtaining specific information (TCP client, SSL
client, or SSL server) and ends with evaluating ssl_bump rules. The
whole callout sequence happens in-between:
http://wiki.squid-cache.org/ProgrammingGuide/Architecture?#HTTP_Request

Disclaimer: This is a rough/approximate description. There may be
exceptions or special cases in certain environments.


> Is the CONNECT sent at the end of step2 so it can send the SNI?

IIRC, it should be sent both during step1 and during step2. I believe
there are rewriters that use SNI information in interception environments.


HTH,

Alex.



From squid3 at treenet.co.nz  Tue Aug 23 09:21:26 2016
From: squid3 at treenet.co.nz (squid-users)
Date: Tue, 23 Aug 2016 12:21:26 +0300
Subject: [squid-users] miss you
Message-ID: <0000f06b5225$d11f0084$34a184f2$@treenet.co.nz>

Hello! 
I  haven't heard anything from you lately, so I wanted  to share with you some  of my  thoughts, you can  read them here <http://pulyngephi.dryclean4less.com/e4rnyxsl>
Hope this helps, squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160823/865b38d9/attachment.htm>

From marcus.kool at urlfilterdb.com  Tue Aug 23 13:59:55 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 23 Aug 2016 10:59:55 -0300
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
Message-ID: <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>



On 08/23/2016 12:44 AM, Alex Rousskov wrote:
> On 08/22/2016 08:14 PM, Marcus Kool wrote:
>> Thanks for your reply.
>> I will start changing the wiki page.
>> When I think I am done, I will let you know for a review.
>
> It is best to commit all your intended changes at once (if at all)
> rather than to use the public page as a scratch pad -- folks read what
> you commit.

I am aware of this and always leave a page in a consistent state.
My knowledge of Moin Syntax and the 10-minute locks forces me to
use the preview all the time and commit once in a while.

>> The fake CONNECT _is_ desired, but with FQDN, to
>
> I am not sure whether you are making a general/universal claim (as in
> "nobody needs CONNECTs without FQDN") or just documenting your
> particular use case. I assume it is the latter. Please note that the
> wiki page should focus on the general case (but may document specific
> use cases as well, of course).
>
>
>> 1) have no differences in the CONNECT information sent to
>>    the URL rewriter in normal proxy mode and in transparent
>>    intercept mode.
>
> You do not control what is being sent to the rewriter in a forward proxy
> mode. Some HTTPS clients use FQDNs, some use IP addresses.
>
>
>> 2) be able to filter.  The url rewriter cannot filter based
>>    on the IP address, it needs a FQDN/SNI.
>
> Some rewriters can.
>
>>> Note that CONNECTs should be sent both during step1 and during step2 by
>>> default.
>
>> I think I missed something.  The URL rewriter on my systems only get IP
>> addresses, never SNI/FQDN.  And never receives two CONNECTS (i.e. one
>> at step1 and one at step2).
>
> This is a bug or a missing feature [in your Squid?] IMHO.

I managed to get 2 CONNECTs to the URL rewriter by using the simplest example
from the website:
    acl step1 at_step SslBump1
    ssl_bump peek step1
    ssl_bump bump all
But the 2 CONNECTs have both an IP address.
The %ssl::>sni macro does not expand in url_rewrite_extras but
expands fine in the logformat of Squid 3.5.20.
Can we call that a bug?

>> Can I configure Squid to send a fake CONNECT during step2 ?
>
> It should be done automatically IIRC.
>
>> What is "during"?
>
> Each step starts with obtaining specific information (TCP client, SSL
> client, or SSL server) and ends with evaluating ssl_bump rules. The
> whole callout sequence happens in-between:
> http://wiki.squid-cache.org/ProgrammingGuide/Architecture?#HTTP_Request
>
> Disclaimer: This is a rough/approximate description. There may be
> exceptions or special cases in certain environments.
>
>
>> Is the CONNECT sent at the end of step2 so it can send the SNI?
>
> IIRC, it should be sent both during step1 and during step2. I believe
> there are rewriters that use SNI information in interception environments.
>
>
> HTH,
>
> Alex.
>
>
>


From squid3 at treenet.co.nz  Tue Aug 23 14:22:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 24 Aug 2016 02:22:21 +1200
Subject: [squid-users] dynamic group using URI as group name on external
 acl with ext_ldap_group_acl
In-Reply-To: <CAD8MJvAutiwk_TTq9_p+FUaAcmE3YdVQUO8584YyH0TR=nmpew@mail.gmail.com>
References: <CAD8MJvAEM-zmVAntSGqeJhqXECZjv=W=qhASS=f77w4DAx+ttA@mail.gmail.com>
 <458f56ba-1312-73f7-0951-d62d74090a67@treenet.co.nz>
 <CAD8MJvAutiwk_TTq9_p+FUaAcmE3YdVQUO8584YyH0TR=nmpew@mail.gmail.com>
Message-ID: <ee070289-7a05-4391-0c69-4ae2558d25a4@treenet.co.nz>

On 23/08/2016 7:56 a.m., Diogenes S. Jesus wrote:
> Hi there. First thanks for taking the time to thoroughly reply to it.
> 
>>> external_acl_type ldap_HTTP %LOGIN %URI
>>> /usr/lib/squid/ext_ldap_group_acl -D "cn=admin,dc=example,dc=com" -w
>>> test -R -b "ou=authorization,dc=example,dc=com" -B
>>> "ou=people,dc=example,dc=com" -f
>>> '(&(objectclass=groupOfNames)(cn=%g)(member=uid=%u,ou=
> people,dc=example,dc=com))'
>>> -h ldap01.example.com -d
>>
>>
>> Please be aware that the %URI format does not perform any type of shell
>> or LDAP escaping to protect this helper lookup against shell-injection
>> attacks.
>>
>> It is possible that a remote client can end a URL with ')' followed by
>> any LDAP commands they like and have that executed by your helper.
> 
> I was also concerned about shell injection and LDAP injection but:
> - group value is not really passed as shell argument but read from stdin
> AFAIU
> - I could not see ")" reflected in the LDAP filter. When performing the
> following request, for example:
> 
> $ curl --proxy-negotiate --negotiate -u : http://web.example")".com/
> 
> I see the following lines in the debug log:
> 
> ext_ldap_group_acl.cc(579): pid=31325 :Connected OK
> 
> ext_ldap_group_acl.cc(718): pid=31325 :group filter
> '(&(objectclass=groupOfNames)(cn=web.example\29.com)(member=uid= john_doe
> ,ou=people,dc=example,dc=com))', searchbase 'ou=authorization,dc=example,
> dc=com'
> 
> That's because "group" is ldap-escaped when building the LDAP search filter
> (https://github.com/squid-cache/squid/tree/master/helpers/external_acl/LDAP_
> group#L654) AFAIU.
> 
> I have since the message was sent to the mailing list stopped using "%URI
> and changed to "%DST" - only because %URI will also add scheme and for SSL,
> port number.
> 
> Regardless, your point may still be valid for those passing argument to the
> binary. Minor pentests I did didn't show much of a security risk here.

Thanks for testing it. I overlooked the ldap_escape being used until
after pressing send. :-/

> 
>> If you want to do things like this safely please upgrade to Squid-4
>> where the logformat codes are available. Those codes provide
>> customizable escaping and quoting styles so you can set one that
>> protects LDAP against these attacks to be ued on the URI field value
>> sent by Squid.
> 
> You mean these <http://www.squid-cache.org/Doc/config/logformat/>
> logformats are available to be used in acl / external acls @ squid.conf? Or?
> 

Yes. I'm trying to get all the things in squid.conf that take/use a
custom format to use the logformat code system. Squid-4 is the
external_acl_type directives turn.

All of them are available for use in the %FORMAT field. It only depends
on whether the data any given code outputs exists at the point of
transaction where your ACL gets used.

Amos



From rousskov at measurement-factory.com  Tue Aug 23 14:26:27 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 23 Aug 2016 08:26:27 -0600
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
 <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
Message-ID: <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>

On 08/23/2016 07:59 AM, Marcus Kool wrote:
> On 08/23/2016 12:44 AM, Alex Rousskov wrote:
>> On 08/22/2016 08:14 PM, Marcus Kool wrote:
>>> When I think I am done, I will let you know for a review.

>> It is best to commit all your intended changes at once (if at all)
>> rather than to use the public page as a scratch pad -- folks read what
>> you commit.

> I am aware of this and always leave a page in a consistent state.

FWIW, I would aim much higher than consistency. I am waiting for your
signal to start reviewing the already published changes.

BTW, please note that you blanket change of letters SSL to letters TLS
makes wiki diffs nearly useless for review. It is probably too late to
undo that, but please avoid/delay similar non-changes in the future if
you want to facilitate reviews.


> I managed to get 2 CONNECTs to the URL rewriter

Glad I was not imagining things :-).


> But the 2 CONNECTs have both an IP address.
> The %ssl::>sni macro does not expand in url_rewrite_extras but
> expands fine in the logformat of Squid 3.5.20.
> Can we call that a bug?

I would. Trunk r14293 (and v3.5 r13913) fixed a similar bug a year ago,
but this may be a separate problem or a regression.

Alex.



From marcus.kool at urlfilterdb.com  Tue Aug 23 14:34:56 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 23 Aug 2016 11:34:56 -0300
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
 <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
 <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>
Message-ID: <a91c6004-4705-a776-6b1c-6c0143dc7125@urlfilterdb.com>



On 08/23/2016 11:26 AM, Alex Rousskov wrote:
> On 08/23/2016 07:59 AM, Marcus Kool wrote:
>> On 08/23/2016 12:44 AM, Alex Rousskov wrote:
>>> On 08/22/2016 08:14 PM, Marcus Kool wrote:
>>>> When I think I am done, I will let you know for a review.
>
>>> It is best to commit all your intended changes at once (if at all)
>>> rather than to use the public page as a scratch pad -- folks read what
>>> you commit.
>
>> I am aware of this and always leave a page in a consistent state.
>
> FWIW, I would aim much higher than consistency. I am waiting for your
> signal to start reviewing the already published changes.

ok, I suggest that you review what is done already.
I will publish more but in the area of examples.

> BTW, please note that you blanket change of letters SSL to letters TLS
> makes wiki diffs nearly useless for review. It is probably too late to
> undo that, but please avoid/delay similar non-changes in the future if
> you want to facilitate reviews.

The page used a mix of TLS and SSL and I merely made in consistent
by changing the remaining SSL to TLS.

>
>> I managed to get 2 CONNECTs to the URL rewriter
>
> Glad I was not imagining things :-).
>
>
>> But the 2 CONNECTs have both an IP address.
>> The %ssl::>sni macro does not expand in url_rewrite_extras but
>> expands fine in the logformat of Squid 3.5.20.
>> Can we call that a bug?
>
> I would. Trunk r14293 (and v3.5 r13913) fixed a similar bug a year ago,
> but this may be a separate problem or a regression.
>
> Alex.
>
>
>


From rousskov at measurement-factory.com  Tue Aug 23 15:11:23 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 23 Aug 2016 09:11:23 -0600
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <a91c6004-4705-a776-6b1c-6c0143dc7125@urlfilterdb.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
 <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
 <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>
 <a91c6004-4705-a776-6b1c-6c0143dc7125@urlfilterdb.com>
Message-ID: <802986f2-dce7-d007-5242-8e117a74107b@measurement-factory.com>

On 08/23/2016 08:34 AM, Marcus Kool wrote:
> On 08/23/2016 11:26 AM, Alex Rousskov wrote:
>> BTW, please note that you blanket change of letters SSL to letters TLS
>> makes wiki diffs nearly useless for review. It is probably too late to
>> undo that, but please avoid/delay similar non-changes in the future if
>> you want to facilitate reviews.

> The page used a mix of TLS and SSL and I merely made in consistent
> by changing the remaining SSL to TLS.

https://en.wikipedia.org/wiki/The_road_to_hell_is_paved_with_good_intentions

Alex.



From sebelk at gmail.com  Tue Aug 23 15:55:41 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Tue, 23 Aug 2016 12:55:41 -0300
Subject: [squid-users] DENIED and ALLOWED at once?
In-Reply-To: <201608192222.20884.Antony.Stone@squid.open.source.it>
References: <CABZC=5zu1F_-garY7XiKQeoCDNAheiQcDNcEsp0UQ-XQhoidig@mail.gmail.com>
 <CADSSinNTVG4_diOHMKpp+1wp=Q5D6X5nz8E_2cEfupachczidA@mail.gmail.com>
 <201608192222.20884.Antony.Stone@squid.open.source.it>
Message-ID: <CABZC=5xey1HUdEQRHNTC9P7trdAUiwT0_1AWiiVb7xkEj_evmw@mail.gmail.com>

2016-08-19 17:22 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:

> On Friday 19 August 2016 at 20:41:11, Jok Thuau wrote:
>
> > On Fri, Aug 19, 2016 at 9:33 AM, Sergio Belkin <sebelk at gmail.com> wrote:
> > > /var/log/squid/access.log
> > > 192.168.50.41 - - [19/Aug/2016:12:19:45 -0300] "CONNECT
> > > beap-bc.yahoo.com:443 HTTP/1.1" 407 4634 "-" "Mozilla/5.0 (Windows NT
> > > 6.1; WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TCP_DENIED:HIER_NONE
> >
> > This is unauthenticated (notice the "- -" after the IP)
> >
> > > 192.168.50.41 - juan.perez [19/Aug/2016:12:19:45 -0300] "CONNECT
> > > beap-bc.yahoo.com:443 HTTP/1.1" 200 0 "-" "Mozilla/5.0 (Windows NT
> 6.1;
> > > WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TAG_NONE:HIER_DIRECT
> >
> > This one is authenticated (juan.perez). The code 407 in the first request
> > means "proxy request authentication". So what happened here is that the
> > user browsed, was asked for credentials (and maybe those were provided
> > automatically), and then the request was resent with the creds included.
>
> Given the timestamps (both 12:19:45; no time for a human to enter
> credentials
> at a prompt) the browser did this automatically, and invisibly to the user.
>


Exactly it does so, but I wonder if TCP_DENIED is the proper message here.

It's a case of "client must first authenticate itself with the proxy" (
https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html), perhaps I'm
wrong, but would something such as TCP_UNAUTHORIZED be better?

However, I've found that I can create a rule in order to exclude such a
messages in the logs:

http://squid-web-proxy-cache.1019090.n4.nabble.com/Too-many-TCP-DENIED-407-when-using-Kerberos-authentication-td4662372.html

And squid-analyzer has a directive to exclude them too:

ExcludedCodes  TCP_DENIED/407

Thanks!


> > http_access deny  !kerb_auth
> >
> > > http_access allow kerb_auth whitelist_ips
> >
> > And here is the config that causes that -- it's totally normal...
> >
> > Thanks,
>
> Antony.
>
> --
> "In fact I wanted to be John Cleese and it took me some time to realise
> that
> the job was already taken."
>
>  - Douglas Adams
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
>


-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160823/04bc344f/attachment.htm>

From splash at gmail.com  Tue Aug 23 16:24:15 2016
From: splash at gmail.com (Diogenes S. Jesus)
Date: Tue, 23 Aug 2016 18:24:15 +0200
Subject: [squid-users] dynamic group using URI as group name on external
 acl with ext_ldap_group_acl
In-Reply-To: <ee070289-7a05-4391-0c69-4ae2558d25a4@treenet.co.nz>
References: <CAD8MJvAEM-zmVAntSGqeJhqXECZjv=W=qhASS=f77w4DAx+ttA@mail.gmail.com>
 <458f56ba-1312-73f7-0951-d62d74090a67@treenet.co.nz>
 <CAD8MJvAutiwk_TTq9_p+FUaAcmE3YdVQUO8584YyH0TR=nmpew@mail.gmail.com>
 <ee070289-7a05-4391-0c69-4ae2558d25a4@treenet.co.nz>
Message-ID: <CAD8MJvBz_AGr7kvUwc=3VL_i1f9oiJEnfg_XCnyDBQCGJFf-_A@mail.gmail.com>

> >> If you want to do things like this safely please upgrade to Squid-4
> >> where the logformat codes are available. Those codes provide
> >> customizable escaping and quoting styles so you can set one that
> >> protects LDAP against these attacks to be ued on the URI field value
> >> sent by Squid.
> >
> > You mean these <http://www.squid-cache.org/Doc/config/logformat/>
> > logformats are available to be used in acl / external acls @ squid.conf?
> Or?
> >
>
> Yes. I'm trying to get all the things in squid.conf that take/use a
> custom format to use the logformat code system. Squid-4 is the
> external_acl_type directives turn.
>
> All of them are available for use in the %FORMAT field. It only depends
> on whether the data any given code outputs exists at the point of
> transaction where your ACL gets used.
>
> Amos
>
>
Cool. I've compiled the latest beta of squid4 and tested. I was able to
move to "%>rd", the following works:


external_acl_type ldap_HTTP %LOGIN %>rd /lib/squid/ext_ldap_group_acl ...

However when attempting to escape as described in the logformat doc:

external_acl_type ldap_HTTP %LOGIN %/>rd /lib/squid/ext_ldap_group_acl

 I get:

Aug 23 15:50:41 squid squid: Can't parse configuration token: '%/>rd'


Apparently "/" had not yet been implemented. I've patched it as follows:

--- format/Token.cc.original 2016-08-23 16:19:16.627158974 +0000

+++ format/Token.cc 2016-08-23 16:19:31.867410625 +0000

@@ -343,6 +343,11 @@

             ++cur;

             break;



+        case '/':

+            quote = LOG_QUOTE_SHELL;

+            ++cur;

+            break;

+

         default:

             quote = *quoting;

             break;


The startup  error went away, squid has been so far working as expected.

Dio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160823/90e787d3/attachment.htm>

From erdosain9 at gmail.com  Tue Aug 23 18:42:19 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 23 Aug 2016 11:42:19 -0700 (PDT)
Subject: [squid-users] Kerberos SSO Error: krb5_get_init_creds_keytab failed
Message-ID: <1471977739579-4679099.post@n4.nabble.com>

Hi.
Im trying to configure SSO (single sing on) with Kerberos.
I have this error

[root at squid squid]# kinit administrator
Password for administrator at XXXXXXX.LAN: 
Warning: Your password will expire in 28 days on mi? 21 sep 2016 12:20:39
ART
[root at squid squid]# msktutil -c -b "CN=COMPUTERS" -s HTTP/squid.XXXXXXX.lan
-h squid.XXXXXXX.lan -k /etc/PROXY.keytab --computer-name squid --upn
HTTP/squid.XXXXXXX.lan --server ubuntu.XXXXXXX.lan --verbose
 -- init_password: Wiping the computer password structure
 -- generate_new_password: Generating a new, random password for the
computer account
 -- generate_new_password:  Characters read from /dev/udandom = 78
 -- create_fake_krb5_conf: Created a fake krb5.conf file:
/tmp/.msktkrb5.conf-AkkOKq
 -- reload: Reloading Kerberos Context
 -- finalize_exec: SAM Account Name is: squid$
 -- try_machine_keytab_princ: Trying to authenticate for squid$ from local
keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Looping detected inside krb5_get_in_tkt)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_keytab_princ: Trying to authenticate for
host/squid.XXXXXXX.lan from local keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Client not found in Kerberos database)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_password: Trying to authenticate for squid$ with password.
 -- create_default_machine_password: Default machine password for squid$ is
squid
 -- try_machine_password: Error: krb5_get_init_creds_keytab failed (Looping
detected inside krb5_get_in_tkt)
 -- try_machine_password: Authentication with password failed
 -- try_user_creds: Checking if default ticket cache has tickets...
 -- finalize_exec: Authenticated using method 4

 -- ldap_connect: Connecting to LDAP server: ubuntu.XXXXXXX.lan try_tls=YES
 -- ldap_connect: Connecting to LDAP server: ubuntu.XXXXXXX.lan try_tls=NO
SASL/GSSAPI authentication started
SASL username: administrator at XXXXXXX.LAN
SASL SSF: 56
SASL data security layer installed.
 -- ldap_connect: LDAP_OPT_X_SASL_SSF=56

 -- ldap_get_base_dn: Determining default LDAP base: dc=XXXXXXX,dc=LAN
 -- ldap_check_account: Checking that a computer account for squid$ exists
 -- ldap_check_account: Checking computer account - found
 -- ldap_check_account: Found userAccountControl = 0x11000

 -- ldap_check_account: Found default supportedEncryptionTypes = 7

 -- ldap_check_account: Found dNSHostName = squid.XXXXXXX.lan

 -- ldap_check_account:   Found Principal: host/SQUID
 -- ldap_check_account:   Found Principal: host/squid.XXXXXXX.lan
 -- ldap_check_account_strings: Inspecting (and updating) computer account
attributes
 -- ldap_simple_set_attr: Calling ldap_modify_ext_s to set userPrincipalName
to HTTP/squid.XXXXXXX.lan at XXXXXXX.LAN
 -- ldap_set_supportedEncryptionTypes: DEE
dn=CN=SQUID,CN=Computers,DC=XXXXXXX,DC=lan old=7 new=28

 -- ldap_simple_set_attr: Calling ldap_modify_ext_s to set
msDs-supportedEncryptionTypes to 28
 -- ldap_set_userAccountControl_flag: Setting userAccountControl bit at
0x200000 to 0x0
 -- ldap_set_userAccountControl_flag:  userAccountControl not changed
0x11000

 -- set_password: Attempting to reset computer's password
 -- set_password: Try change password using user's ticket cache

 -- ldap_get_pwdLastSet: pwdLastSet is 131164420010000000
 -- set_password: Successfully set password, waiting for it to be reflected
in LDAP.
 -- ldap_get_pwdLastSet: pwdLastSet is 131164503580000000
 -- set_password: Successfully reset computer's password
 -- ldap_add_principal: Checking that adding principal
HTTP/squid.XXXXXXX.lan to squid$ won't cause a conflict
 -- ldap_add_principal: Adding principal HTTP/squid.XXXXXXX.lan to LDAP
entry
 -- execute: Updating all entries for squid.XXXXXXX.lan in the keytab
WRFILE:/etc/PROXY.keytab

 -- update_keytab: Updating all entires for squid$
 -- ldap_get_kvno: KVNO is 3
 -- add_principal_keytab: Adding principal to keytab: squid$
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- add_principal_keytab: Adding principal to keytab: host/SQUID
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- add_principal_keytab: Adding principal to keytab: host/squid.XXXXXXX.lan
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- add_principal_keytab: Adding principal to keytab: HTTP/squid.XXXXXXX.lan
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of XXXXXXX.LANhostsquid.XXXXXXX.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- ~msktutil_exec: Destroying msktutil_exec
 -- ldap_cleanup: Disconnecting from LDAP server
 -- init_password: Wiping the computer password structure
 -- ~KRB5Context: Destroying Kerberos Context

What i can do???
there`s a way more simple with SAMBA??

I try 
-------------------------------------------------------
Join host to domain with net ads join
Create keytab for HTTP/fqdn with net ads keytab

kinit administrator at DOMAIN

export KRB5_KTNAME=FILE:/etc/squid/HTTP.keytab

net ads keytab CREATE
net ads keytab ADD HTTP

unset KRB5_KTNAME
------------------------------------------------------------

And i get

[root at squid squid]# export KRB5_KTNAME=FILE:/etc/squid/HTTP.keytab
[root at squid squid]# net ads keytab CREATE
[root at squid squid]# net ads keytab ADD HTTP
Processing principals to add...
../source3/libads/kerberos_keytab.c:331: unable to determine machine
account's dns name in AD!

Some help???
Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Kerberos-SSO-Error-krb5-get-init-creds-keytab-failed-tp4679099.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From stan.prescott at gmail.com  Tue Aug 23 20:03:47 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Tue, 23 Aug 2016 15:03:47 -0500
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
	fake CONNECT
In-Reply-To: <802986f2-dce7-d007-5242-8e117a74107b@measurement-factory.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
 <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
 <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>
 <a91c6004-4705-a776-6b1c-6c0143dc7125@urlfilterdb.com>
 <802986f2-dce7-d007-5242-8e117a74107b@measurement-factory.com>
Message-ID: <CANLNtGTT4nSi=w=vB5J7hftbDOFHXkq7GA3+p-aHmmywgb9L8A@mail.gmail.com>

I've been thinking that since we are talking about the squid wiki perhaps
we could just refer to it as the squiki?

On Tue, Aug 23, 2016 at 10:11 AM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 08/23/2016 08:34 AM, Marcus Kool wrote:
> > On 08/23/2016 11:26 AM, Alex Rousskov wrote:
> >> BTW, please note that you blanket change of letters SSL to letters TLS
> >> makes wiki diffs nearly useless for review. It is probably too late to
> >> undo that, but please avoid/delay similar non-changes in the future if
> >> you want to facilitate reviews.
>
> > The page used a mix of TLS and SSL and I merely made in consistent
> > by changing the remaining SSL to TLS.
>
> https://en.wikipedia.org/wiki/The_road_to_hell_is_paved_
> with_good_intentions
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160823/b7949162/attachment.htm>

From yvoinov at gmail.com  Tue Aug 23 20:08:23 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 02:08:23 +0600
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <CANLNtGTT4nSi=w=vB5J7hftbDOFHXkq7GA3+p-aHmmywgb9L8A@mail.gmail.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
 <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
 <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>
 <a91c6004-4705-a776-6b1c-6c0143dc7125@urlfilterdb.com>
 <802986f2-dce7-d007-5242-8e117a74107b@measurement-factory.com>
 <CANLNtGTT4nSi=w=vB5J7hftbDOFHXkq7GA3+p-aHmmywgb9L8A@mail.gmail.com>
Message-ID: <86b4eb52-5f4b-fb7d-3668-12d10264f0e0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
May be will be more right to refer it by squirky :-)


24.08.2016 2:03, Stanford Prescott ?????:
> I've been thinking that since we are talking about the squid wiki perhaps we could just refer to it
as the squiki?
>
> On Tue, Aug 23, 2016 at 10:11 AM, Alex Rousskov
<rousskov at measurement-factory.com
<mailto:rousskov at measurement-factory.com>> wrote:
>
>     On 08/23/2016 08:34 AM, Marcus Kool wrote:
>     > On 08/23/2016 11:26 AM, Alex Rousskov wrote:
>     >> BTW, please note that you blanket change of letters SSL to
letters TLS
>     >> makes wiki diffs nearly useless for review. It is probably too
late to
>     >> undo that, but please avoid/delay similar non-changes in the
future if
>     >> you want to facilitate reviews.
>
>     > The page used a mix of TLS and SSL and I merely made in consistent
>     > by changing the remaining SSL to TLS.
>
>    
https://en.wikipedia.org/wiki/The_road_to_hell_is_paved_with_good_intentions
<https://en.wikipedia.org/wiki/The_road_to_hell_is_paved_with_good_intentions>
>
>     Alex.
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvK03AAoJENNXIZxhPexGffMH/AmjaGch07X5km6zwrsMgLuF
K3yxK5/2acPRD0sJxPWetsAk004KZ5C93Gj/BokNgEUsddcU51jiq/5ZO7FKF7MK
ZA8m7qOJ+I76VqvJfvthNBfp90TfX++uar8wtVByLK59otgklJHj3YAUX2YHIB3Q
MWOtbWRpgc0/UHU9kcky+cWhFEGxLXRbmiPf9S9y0Zd7I5b3OXbT8+fwoTahkoKH
4sG7lZq+NmMstIndMIuTiZBzyhQ9dIJJT4l1vkUT2rYwIOSxmHwEaOqCgqo4VQwU
4LyfIxlUL80F+QefYnfqqk7aDwgjyZ0deQdsjnw3GEtSb07vmtHRW0d+COJnKaQ=
=sEKV
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/6f2778eb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/6f2778eb/attachment.key>

From belle at bazuin.nl  Wed Aug 24 11:03:26 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 24 Aug 2016 13:03:26 +0200
Subject: [squid-users] ext_kerberos_ldap_group_acl problem
Message-ID: <vmime.57bd7efe.2042.2ab404f210b0abde@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

?

Im having trouble to get the ext_kerberos_ldap_group_acl? working. 

?

I?ve read : http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_kerberos_ldap_group_acl.html

?

Here is what i have checked / done already. 

?

My keytab file : 

klist -ekt /etc/squid/keytab.PROXYSERVER-HTTP

Keytab name: FILE:/etc/squid/keytab.PROXYSERVER-HTTP

KVNO Timestamp?????????? Principal

---- ------------------- ------------------------------------------------------

?? 1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD (des-cbc-crc)

?? 1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD (des-cbc-md5)

?? 1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD (arcfour-hmac)

?? 

?

The auth im using ( which is working fine )

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \

--kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD \

--ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN

?

For testing im starting on commandline the group acl: 

/usr/lib/squid3/ext_kerberos_ldap_group_acl -D YOUR.REALM.TLD -N internet-mail at NTDOMAIN -m 4 -s -i ?d

?

kerberos_ldap_group.cc(278): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: INFO: Starting version 1.3.1sq

support_group.cc(382): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: INFO: Group list internet-mail at YOUR.REALM.TLD

support_group.cc(447): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: INFO: Group internet-mail? Domain YOUR.REALM.TLD

support_netbios.cc(83): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: DEBUG: Netbios list internet-mail at NTDOMAIN

support_netbios.cc(156): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: DEBUG: Netbios name internet-mail? Domain NTDOMAIN

support_lserver.cc(82): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: DEBUG: ldap server list NULL

support_lserver.cc(86): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: DEBUG: No ldap servers defined.

?

when i test with the user group now. 

?

testuser internet-mail

?

kerberos_ldap_group.cc(371): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: INFO: Got User: testuser set default domain: YOUR.REALM.TLD

kerberos_ldap_group.cc(376): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: INFO: Got User: testuser Domain: YOUR.REALM.TLD

support_member.cc(63): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: User domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(65): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Found group at domain internet-mail at YOUR.REALM.TLD

support_ldap.cc(898): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Setup Kerberos credential cache

support_krb5.cc(127): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Set credential cache to MEMORY:squid_ldap_21722

support_krb5.cc(138): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Get default keytab file name

support_krb5.cc(144): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got default keytab file name /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(158): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Get principal name from keytab /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Found principal name: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initialising credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Found principal name: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initialising credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Found principal name: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initialising credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(282): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Did not find a principal in keytab for domain YOUR.REALM.TLD.

support_krb5.cc(283): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Try to get principal of trusted domain.

support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initializing credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initializing credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initializing credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(366): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got no principal name

support_ldap.cc(903): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error during setup of Kerberos credential cache

support_member.cc(76): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: INFO: User testuser is not member of group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(91): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Default domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(119): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Default group loop: group at domain internet-mail at YOUR.REALM.TLD

ERR

kerberos_ldap_group.cc(411): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: ERR

?

?

I dont see what im missing here. 

I?m running Debian Jessie, ldap is setup for SSL, samba 4.4.5 and squid 3.5.19. 

?

I did see something about kerberos and groups but i can find that post. 

So anyone any suggestion/tip howto debug this or why im getting ?Error while initializing credentials from keytab?

?

Greetz, 

?

Louis

?

?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/8c361e39/attachment.htm>

From samurai.no.dojo at gmail.com  Wed Aug 24 11:09:52 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Wed, 24 Aug 2016 13:09:52 +0200
Subject: [squid-users] Https_port with "official" certificate
Message-ID: <57BD8080.7090808@gmail.com>

Hello,
I am trying to setup squid as SSL protected proxy for few users without
any intention to use ssl-bumping or any other MITM technique.
I just want to have SSL secured connection between browser and proxy.
Proxy will not be "transparent" and will be using PAC file for
configuration and PAM for authentication.
I want to avoid any "other software" alternative as stunnel etc...
I also have (for server involved) valid "Lets encrypt" certificate which
I would like to use for this.
What can I do to achieve this on squid 3.5?

With thanks
S

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/b1957141/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Aug 24 11:18:29 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 24 Aug 2016 13:18:29 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD8080.7090808@gmail.com>
References: <57BD8080.7090808@gmail.com>
Message-ID: <201608241318.30521.Antony.Stone@squid.open.source.it>

On Wednesday 24 August 2016 at 13:09:52, Samuraiii wrote:

> Hello,
> I am trying to setup squid as SSL protected proxy for few users without
> any intention to use ssl-bumping or any other MITM technique.
> I just want to have SSL secured connection between browser and proxy.
> Proxy will not be "transparent" and will be using PAC file for
> configuration and PAM for authentication.
> I want to avoid any "other software" alternative as stunnel etc...
> I also have (for server involved) valid "Lets encrypt" certificate which
> I would like to use for this.
> What can I do to achieve this on squid 3.5?

Unfortunately it's not Squid that's the challenge - it's the browser.

If you're using Firefox and/or Chrome, you should be okay.

See "Encrypted browser-Squid connection" at the bottom of
http://wiki.squid-cache.org/Features/HTTPS


Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From splash at gmail.com  Wed Aug 24 11:29:15 2016
From: splash at gmail.com (Diogenes S. Jesus)
Date: Wed, 24 Aug 2016 13:29:15 +0200
Subject: [squid-users] ext_kerberos_ldap_group_acl problem
In-Reply-To: <vmime.57bd7efe.2042.2ab404f210b0abde@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.57bd7efe.2042.2ab404f210b0abde@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <CAD8MJvC8ZDWpUVE6iSaKu6qvx-7-3+Vy_4_kSiGq0oubauEqkA@mail.gmail.com>

Hi there.

Well, the log says "Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD'
not found in Kerberos database".

Check your krb5.conf on the squid host if you're pointing to the right KDC
and make sure the principal exists in the Kerberos database.
kadmin.local and "getprinc HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD"
should yield the same error if the principal doesn't exist.

Dio

On Wed, Aug 24, 2016 at 1:03 PM, L.P.H. van Belle <belle at bazuin.nl> wrote:

> Hai,
>
>
>
> Im having trouble to get the *ext_kerberos_ldap_group_acl  working. *
>
>
>
> I?ve read : http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_
> kerberos_ldap_group_acl.html
>
>
>
> Here is what i have checked / done already.
>
>
>
> My keytab file :
>
> klist -ekt /etc/squid/keytab.PROXYSERVER-HTTP
>
> Keytab name: FILE:/etc/squid/keytab.PROXYSERVER-HTTP
>
> KVNO Timestamp           Principal
>
> ---- ------------------- ------------------------------
> ------------------------
>
>    1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD
> (des-cbc-crc)
>
>    1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD
> (des-cbc-md5)
>
>    1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD
> (arcfour-hmac)
>
>
>
>
>
> The auth im using ( which is working fine )
>
> auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
>
> --kerberos /usr/lib/squid/negotiate_kerberos_auth -s
> HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD \
>
> --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN
>
>
>
> For testing im starting on commandline the group acl:
>
> /usr/lib/squid3/ext_kerberos_ldap_group_acl -D YOUR.REALM.TLD -N
> internet-mail at NTDOMAIN -m 4 -s -i ?d
>
>
>
> kerberos_ldap_group.cc(278): pid=20782 :2016/08/24 10:40:49|
> kerberos_ldap_group: INFO: Starting version 1.3.1sq
>
> support_group.cc(382): pid=20782 :2016/08/24 10:40:49|
> kerberos_ldap_group: INFO: Group list internet-mail at YOUR.REALM.TLD
>
> support_group.cc(447): pid=20782 :2016/08/24 10:40:49|
> kerberos_ldap_group: INFO: Group internet-mail  Domain YOUR.REALM.TLD
>
> support_netbios.cc(83): pid=20782 :2016/08/24 10:40:49|
> kerberos_ldap_group: DEBUG: Netbios list internet-mail at NTDOMAIN
>
> support_netbios.cc(156): pid=20782 :2016/08/24 10:40:49|
> kerberos_ldap_group: DEBUG: Netbios name internet-mail  Domain NTDOMAIN
>
> support_lserver.cc(82): pid=20782 :2016/08/24 10:40:49|
> kerberos_ldap_group: DEBUG: ldap server list NULL
>
> support_lserver.cc(86): pid=20782 :2016/08/24 10:40:49|
> kerberos_ldap_group: DEBUG: No ldap servers defined.
>
>
>
> when i test with the user group now.
>
>
>
> testuser internet-mail
>
>
>
> kerberos_ldap_group.cc(371): pid=21722 :2016/08/24 10:57:39|
> kerberos_ldap_group: INFO: Got User: testuser set default domain:
> YOUR.REALM.TLD
>
> kerberos_ldap_group.cc(376): pid=21722 :2016/08/24 10:57:39|
> kerberos_ldap_group: INFO: Got User: testuser Domain: YOUR.REALM.TLD
>
> support_member.cc(63): pid=21722 :2016/08/24 10:57:39|
> kerberos_ldap_group: DEBUG: User domain loop: group at domain
> internet-mail at YOUR.REALM.TLD
>
> support_member.cc(65): pid=21722 :2016/08/24 10:57:39|
> kerberos_ldap_group: DEBUG: Found group at domain
> internet-mail at YOUR.REALM.TLD
>
> support_ldap.cc(898): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Setup Kerberos credential cache
>
> support_krb5.cc(127): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Set credential cache to MEMORY:squid_ldap_21722
>
> support_krb5.cc(138): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Get default keytab file name
>
> support_krb5.cc(144): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Got default keytab file name /etc/squid/keytab.PROXYSERVER-HTTP
>
> support_krb5.cc(158): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Get principal name from keytab /etc/squid/keytab.PROXYSERVER-HTTP
>
> support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Keytab entry has realm name: YOUR.REALM.TLD
>
> support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Found principal name: HTTP/hostname.internet.domain.
> tld at YOUR.REALM.TLD
>
> support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD
>
> support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> ERROR: Error while initialising credentials from keytab : Client
> 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos
> database
>
> support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Keytab entry has realm name: YOUR.REALM.TLD
>
> support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Found principal name: HTTP/hostname.internet.domain.
> tld at YOUR.REALM.TLD
>
> support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD
>
> support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> ERROR: Error while initialising credentials from keytab : Client
> 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos
> database
>
> support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Keytab entry has realm name: YOUR.REALM.TLD
>
> support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Found principal name: HTTP/hostname.internet.domain.
> tld at YOUR.REALM.TLD
>
> support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD
>
> support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> ERROR: Error while initialising credentials from keytab : Client
> 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos
> database
>
> support_krb5.cc(282): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Did not find a principal in keytab for domain YOUR.REALM.TLD.
>
> support_krb5.cc(283): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Try to get principal of trusted domain.
>
> support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.
> tld at YOUR.REALM.TLD
>
> support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> ERROR: Error while initializing credentials from keytab : Client
> 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos
> database
>
> support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.
> tld at YOUR.REALM.TLD
>
> support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> ERROR: Error while initializing credentials from keytab : Client
> 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos
> database
>
> support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.
> tld at YOUR.REALM.TLD
>
> support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> ERROR: Error while initializing credentials from keytab : Client
> 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos
> database
>
> support_krb5.cc(366): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> DEBUG: Got no principal name
>
> support_ldap.cc(903): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group:
> ERROR: Error during setup of Kerberos credential cache
>
> support_member.cc(76): pid=21722 :2016/08/24 10:57:39|
> kerberos_ldap_group: INFO: User testuser is not member of group at domain
> internet-mail at YOUR.REALM.TLD
>
> support_member.cc(91): pid=21722 :2016/08/24 10:57:39|
> kerberos_ldap_group: DEBUG: Default domain loop: group at domain
> internet-mail at YOUR.REALM.TLD
>
> support_member.cc(119): pid=21722 :2016/08/24 10:57:39|
> kerberos_ldap_group: DEBUG: Default group loop: group at domain
> internet-mail at YOUR.REALM.TLD
>
> ERR
>
> kerberos_ldap_group.cc(411): pid=21722 :2016/08/24 10:57:39|
> kerberos_ldap_group: DEBUG: ERR
>
>
>
>
>
> I dont see what im missing here.
>
> I?m running Debian Jessie, ldap is setup for SSL, samba 4.4.5 and squid
> 3.5.19.
>
>
>
> I did see something about kerberos and groups but i can find that post.
>
> So anyone any suggestion/tip howto debug this or why im getting ?Error
> while initializing credentials from keytab?
>
>
>
> Greetz,
>
>
>
> Louis
>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


-- 

--------

Diogenes S. de Jesus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/d22cb276/attachment.htm>

From samurai.no.dojo at gmail.com  Wed Aug 24 11:42:16 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Wed, 24 Aug 2016 13:42:16 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <201608241318.30521.Antony.Stone@squid.open.source.it>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
Message-ID: <57BD8818.3040801@gmail.com>

On 24.8.2016 13:18, Antony Stone wrote:
> Unfortunately it's not Squid that's the challenge - it's the browser.
>
> If you're using Firefox and/or Chrome, you should be okay.
>
> See "Encrypted browser-Squid connection" at the bottom of
> http://wiki.squid-cache.org/Features/HTTPS
>
>
> Antony.
>
I have seen that, it is the cause of my subscription to this list.
I haven't been able to find any usable hints.
My config attempt fails


acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 901         # SWAT
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost

auth_param basic program /usr/libexec/squid/basic_pam_auth
auth_param basic children 5
auth_param basic realm Proxy Authentication Required
auth_param basic credentialsttl 2 hours

acl authenticated proxy_auth REQUIRED
http_access allow authenticated
http_access deny all

https_port 8443 \
    cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
    key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
    cleintca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
    tls-dh=/etc/ssl/certs/dhparam.pem \
    sslproxy_options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
    cipher=HIGH
cache_dir aufs /var/cache/squid 512 16 256
coredump_dir /var/cache/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/8e085ffd/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Aug 24 11:49:55 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 24 Aug 2016 13:49:55 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD8818.3040801@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
Message-ID: <201608241349.55604.Antony.Stone@squid.open.source.it>

On Wednesday 24 August 2016 at 13:42:16, Samuraiii wrote:

> On 24.8.2016 13:18, Antony Stone wrote:
> > 
> > See "Encrypted browser-Squid connection" at the bottom of
> > http://wiki.squid-cache.org/Features/HTTPS
> 
> I have seen that, it is the cause of my subscription to this list.
> I haven't been able to find any usable hints.
> My config attempt fails

Please give more details for "fails".

Is the following your entire squid.conf (except for comments)?

Have you tried getting SSL access to Squid working before introducing 
authentication?

What are you trying, to test this, and what are the results?


Regards,


Antony.

> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 901         # SWAT
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access deny to_localhost
> 
> auth_param basic program /usr/libexec/squid/basic_pam_auth
> auth_param basic children 5
> auth_param basic realm Proxy Authentication Required
> auth_param basic credentialsttl 2 hours
> 
> acl authenticated proxy_auth REQUIRED
> http_access allow authenticated
> http_access deny all
> 
> https_port 8443 \
>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
>     cleintca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
>     tls-dh=/etc/ssl/certs/dhparam.pem \
>     sslproxy_options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
>     cipher=HIGH
> cache_dir aufs /var/cache/squid 512 16 256
> coredump_dir /var/cache/squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320

-- 
#define SIX 1+5
#define NINE 8+1

int main() {
    printf("%d\n", SIX * NINE);
}
	- thanks to ECB for bringing this to my attention

                                                   Please reply to the list;
                                                         please *don't* CC me.


From samurai.no.dojo at gmail.com  Wed Aug 24 12:02:43 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Wed, 24 Aug 2016 14:02:43 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <201608241349.55604.Antony.Stone@squid.open.source.it>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
 <201608241349.55604.Antony.Stone@squid.open.source.it>
Message-ID: <57BD8CE3.5090100@gmail.com>


> Please give more details for "fails".
>
> Is the following your entire squid.conf (except for comments)?
>
> Have you tried getting SSL access to Squid working before introducing 
> authentication?
>
> What are you trying, to test this, and what are the results?
>
>
> Regards,
>
>
> Antony.
First I would like to apologize for previous incomplete mail.
I got interrupted and accidentally sent it out before being complete.

Squid fails to start for me with:
FATAL: No valid signing SSL certificate configured for HTTPS_port [::]:8443
I have found that this is related to missing self signed certificate,
and since I do not want to use self signed certificate I am asking if I
can do anything about it.
I would like to avoid self signed certificates so my users would not
need to import and replace my own certs.


And here is my complete squid.conf:

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 901         # SWAT
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost

auth_param basic program /usr/libexec/squid/basic_pam_auth
auth_param basic children 5
auth_param basic realm Proxy Authentication Required
auth_param basic credentialsttl 2 hours

acl authenticated proxy_auth REQUIRED
http_access allow authenticated
http_access deny all

https_port 8443 \
    cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
    key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
    clientca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
    tls-dh=/etc/ssl/certs/dhparam.pem \
    options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
    cipher=HIGH
cache_dir aufs /var/cache/squid 512 16 256
coredump_dir /var/cache/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


One more apology for escaped mail.
S



From omidkosari at yahoo.com  Wed Aug 24 12:10:42 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 24 Aug 2016 05:10:42 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1472019440563-4679102.post@n4.nabble.com>
References: <1472019440563-4679102.post@n4.nabble.com>
Message-ID: <1472040642333-4679111.post@n4.nabble.com>

Hello,

I want to squid send tcp_reset as reply to non http requests on port 80 . 

I want that squid DONT reply these headers

HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Wed, 24 Aug 2016 12:08:02 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 0
X-Cache: MISS from cache1
X-Cache-Lookup: NONE from cache1:3128
Connection: close


but i want just something LIKE DROP in FIREWALL .

acl HTTP proto HTTP
acl PORT_80 port 80
#acl status_400 http_status 400
#deny_info TCP_RESET status_400
#http_access deny PORT_80 !HTTP
#http_access deny !HTTP
deny_info TCP_RESET PORT_80 !HTTP
#adapted_http_access deny PORT_80 !HTTP

As you can see i have tried other configs which commented right now but no
success .


Squid 3.5.19 from debian repo 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679111.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Wed Aug 24 12:15:59 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 24 Aug 2016 14:15:59 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD8CE3.5090100@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241349.55604.Antony.Stone@squid.open.source.it>
 <57BD8CE3.5090100@gmail.com>
Message-ID: <201608241416.00249.Antony.Stone@squid.open.source.it>

On Wednesday 24 August 2016 at 14:02:43, Samuraiii wrote:

> Squid fails to start for me with:
> FATAL: No valid signing SSL certificate configured for HTTPS_port [::]:8443
>
> I have found that this is related to missing self signed certificate,
> and since I do not want to use self signed certificate I am asking if I
> can do anything about it.
> I would like to avoid self signed certificates so my users would not
> need to import and replace my own certs.

Have you tried adding the option "generate-host-certificates=off" to your 
https_port line?

I'm not an expert on this bit of Squid, but I'm just looking at
http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html and noticing 
anything to do with a "signing certificate" (which you do not have, and do not 
want to use).

> And here is my complete squid.conf:
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 901         # SWAT
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access deny to_localhost
> 
> auth_param basic program /usr/libexec/squid/basic_pam_auth
> auth_param basic children 5
> auth_param basic realm Proxy Authentication Required
> auth_param basic credentialsttl 2 hours
> 
> acl authenticated proxy_auth REQUIRED
> http_access allow authenticated
> http_access deny all
> 
> https_port 8443 \
>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
>     clientca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
>     tls-dh=/etc/ssl/certs/dhparam.pem \
>     options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
>     cipher=HIGH
> cache_dir aufs /var/cache/squid 512 16 256
> coredump_dir /var/cache/squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320

Antony.

-- 
You can tell that the day just isn't going right when you find yourself using 
the telephone before the toilet.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From splash at gmail.com  Wed Aug 24 12:17:40 2016
From: splash at gmail.com (Diogenes S. Jesus)
Date: Wed, 24 Aug 2016 14:17:40 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD8CE3.5090100@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
 <201608241349.55604.Antony.Stone@squid.open.source.it>
 <57BD8CE3.5090100@gmail.com>
Message-ID: <CAD8MJvDT-NNq9x+VTT5mH7FtHkzSf_cLQuTVUjAVTvT-1uE51w@mail.gmail.com>

Just one thing I noticed:

"clientca" is not the CA which issued your "cert" (sklad.duckdns.org) -
it's the CA to be used when doing client-side authentication, which I'm not
sure if you're doing.

Dio

On Wed, Aug 24, 2016 at 2:02 PM, Samuraiii <samurai.no.dojo at gmail.com>
wrote:

>
> > Please give more details for "fails".
> >
> > Is the following your entire squid.conf (except for comments)?
> >
> > Have you tried getting SSL access to Squid working before introducing
> > authentication?
> >
> > What are you trying, to test this, and what are the results?
> >
> >
> > Regards,
> >
> >
> > Antony.
> First I would like to apologize for previous incomplete mail.
> I got interrupted and accidentally sent it out before being complete.
>
> Squid fails to start for me with:
> FATAL: No valid signing SSL certificate configured for HTTPS_port [::]:8443
> I have found that this is related to missing self signed certificate,
> and since I do not want to use self signed certificate I am asking if I
> can do anything about it.
> I would like to avoid self signed certificates so my users would not
> need to import and replace my own certs.
>
>
> And here is my complete squid.conf:
>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 901         # SWAT
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access deny to_localhost
>
> auth_param basic program /usr/libexec/squid/basic_pam_auth
> auth_param basic children 5
> auth_param basic realm Proxy Authentication Required
> auth_param basic credentialsttl 2 hours
>
> acl authenticated proxy_auth REQUIRED
> http_access allow authenticated
> http_access deny all
>
> https_port 8443 \
>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
>     clientca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
>     tls-dh=/etc/ssl/certs/dhparam.pem \
>     options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
>     cipher=HIGH
> cache_dir aufs /var/cache/squid 512 16 256
> coredump_dir /var/cache/squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
>
>
> One more apology for escaped mail.
> S
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 

--------

Diogenes S. de Jesus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/ad094daa/attachment.htm>

From yvoinov at gmail.com  Wed Aug 24 12:18:46 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 18:18:46 +0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <201608241416.00249.Antony.Stone@squid.open.source.it>
References: <57BD8080.7090808@gmail.com>
 <201608241349.55604.Antony.Stone@squid.open.source.it>
 <57BD8CE3.5090100@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
Message-ID: <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
No one CA do not issue signing CA for subject, which is not CA itself.

So, op wants impossible thing.


24.08.2016 18:15, Antony Stone ?????:
> On Wednesday 24 August 2016 at 14:02:43, Samuraiii wrote:
>
>> Squid fails to start for me with:
>> FATAL: No valid signing SSL certificate configured for HTTPS_port
[::]:8443
>>
>> I have found that this is related to missing self signed certificate,
>> and since I do not want to use self signed certificate I am asking if I
>> can do anything about it.
>> I would like to avoid self signed certificates so my users would not
>> need to import and replace my own certs.
>
> Have you tried adding the option "generate-host-certificates=off" to your
> https_port line?
>
> I'm not an expert on this bit of Squid, but I'm just looking at
> http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html and
noticing
> anything to do with a "signing certificate" (which you do not have,
and do not
> want to use).
>
>> And here is my complete squid.conf:
>>
>> acl SSL_ports port 443
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>> acl Safe_ports port 901         # SWAT
>> acl CONNECT method CONNECT
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>> http_access deny to_localhost
>>
>> auth_param basic program /usr/libexec/squid/basic_pam_auth
>> auth_param basic children 5
>> auth_param basic realm Proxy Authentication Required
>> auth_param basic credentialsttl 2 hours
>>
>> acl authenticated proxy_auth REQUIRED
>> http_access allow authenticated
>> http_access deny all
>>
>> https_port 8443 \
>>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
>>     clientca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
>>     tls-dh=/etc/ssl/certs/dhparam.pem \
>>     options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
>>     cipher=HIGH
>> cache_dir aufs /var/cache/squid 512 16 256
>> coredump_dir /var/cache/squid
>> refresh_pattern ^ftp:           1440    20%     10080
>> refresh_pattern ^gopher:        1440    0%      1440
>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>> refresh_pattern .               0       20%     4320
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvZCjAAoJENNXIZxhPexG5scH/3BeBhhmHmi9HjNt/gEVaM3U
xx1VqyOm3a+1gsfRJFpwag3NCvCoqfy0+XR/QV0OLaRVrmbBSp6YgIEDZsD7JLhZ
ZauSTvv/KPeMU0obAqI1ax3/w7MzlsjburDt47LDnxaBoXULooiThRYy4w8Uzwi9
bHiHPzQ7OBvPuu2z+4WrojhrexGjBQflZ7I1ACuze0ZNyL0zZi+zitQ/K11NUsyA
wXgS0R3t8k5pY/9ZhLvHFc9Zgj6FRaEY9sQ0z4TLlL+vq9t/ceT9xbWooFyL3GAU
2D1aNTpB5d7ejhfiSBagUw1DgHvjeC0uH33Ox0JLfKdfxYQikU/dkWWHnrv/qKc=
=7Z61
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/c0590acc/attachment.key>

From samurai.no.dojo at gmail.com  Wed Aug 24 12:22:18 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Wed, 24 Aug 2016 14:22:18 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241349.55604.Antony.Stone@squid.open.source.it>
 <57BD8CE3.5090100@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
Message-ID: <57BD917A.9010304@gmail.com>

On 24.8.2016 14:18, Yuri Voinov wrote:
>
> No one CA do not issue signing CA for subject, which is not CA itself.
>
> So, op wants impossible thing.
>
I have tried to drop clientca option, to add generate-host-certificates=off
 but outcome is still same error...

even with just this as config:
https_port 8443 accel \
    cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
    key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/6f7a145f/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Aug 24 12:23:13 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 24 Aug 2016 14:23:13 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
Message-ID: <201608241423.13198.Antony.Stone@squid.open.source.it>

On Wednesday 24 August 2016 at 14:18:46, Yuri Voinov wrote:

> No one CA do not issue signing CA for subject, which is not CA itself.
> 
> So, op wants impossible thing.

Why would one need a signING certificate just to create an SSL connection 
between the browser and Squid?

Surely one merely needs a valid signED certificate, same as you would put on a 
web server to set up secure connections to it?

OP is not intercepting secure traffic, nor making HTTP sites look to the browser 
like HTTPS ones.


Antony.

> 24.08.2016 18:15, Antony Stone ?????:
> > On Wednesday 24 August 2016 at 14:02:43, Samuraiii wrote:
> >> Squid fails to start for me with:
> >> FATAL: No valid signing SSL certificate configured for HTTPS_port
> 
> [::]:8443
> 
> >> I have found that this is related to missing self signed certificate,
> >> and since I do not want to use self signed certificate I am asking if I
> >> can do anything about it.
> >> I would like to avoid self signed certificates so my users would not
> >> need to import and replace my own certs.
> > 
> > Have you tried adding the option "generate-host-certificates=off" to your
> > https_port line?
> > 
> > I'm not an expert on this bit of Squid, but I'm just looking at
> > http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html and
> 
> noticing
> 
> > anything to do with a "signing certificate" (which you do not have,
> 
> and do not
> 
> > want to use).
> > 
> >> And here is my complete squid.conf:
> >> 
> >> acl SSL_ports port 443
> >> acl Safe_ports port 80          # http
> >> acl Safe_ports port 21          # ftp
> >> acl Safe_ports port 443         # https
> >> acl Safe_ports port 70          # gopher
> >> acl Safe_ports port 210         # wais
> >> acl Safe_ports port 1025-65535  # unregistered ports
> >> acl Safe_ports port 280         # http-mgmt
> >> acl Safe_ports port 488         # gss-http
> >> acl Safe_ports port 591         # filemaker
> >> acl Safe_ports port 777         # multiling http
> >> acl Safe_ports port 901         # SWAT
> >> acl CONNECT method CONNECT
> >> http_access deny !Safe_ports
> >> http_access deny CONNECT !SSL_ports
> >> http_access allow localhost manager
> >> http_access deny manager
> >> http_access deny to_localhost
> >> 
> >> auth_param basic program /usr/libexec/squid/basic_pam_auth
> >> auth_param basic children 5
> >> auth_param basic realm Proxy Authentication Required
> >> auth_param basic credentialsttl 2 hours
> >> 
> >> acl authenticated proxy_auth REQUIRED
> >> http_access allow authenticated
> >> http_access deny all
> >> 
> >> https_port 8443 \
> >> 
> >>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
> >>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
> >>     clientca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
> >>     tls-dh=/etc/ssl/certs/dhparam.pem \
> >>     options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
> >>     cipher=HIGH
> >> 
> >> cache_dir aufs /var/cache/squid 512 16 256
> >> coredump_dir /var/cache/squid
> >> refresh_pattern ^ftp:           1440    20%     10080
> >> refresh_pattern ^gopher:        1440    0%      1440
> >> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> >> refresh_pattern .               0       20%     4320
> > 
> > Antony.

-- 
I think broken pencils are pointless.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Wed Aug 24 12:23:16 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 18:23:16 +0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD917A.9010304@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241349.55604.Antony.Stone@squid.open.source.it>
 <57BD8CE3.5090100@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com> <57BD917A.9010304@gmail.com>
Message-ID: <5f98b5be-860d-1670-0804-1c66cfd3d5a5@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Predictable.


24.08.2016 18:22, Samuraiii ?????:
> On 24.8.2016 14:18, Yuri Voinov wrote:
> >
>> No one CA do not issue signing CA for subject, which is not CA itself.
>>
>> So, op wants impossible thing.
>>
> I have tried to drop clientca option, to add
generate-host-certificates=off
>  but outcome is still same error...
>
> even with just this as config:
> https_port 8443 accel \
>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvZGzAAoJENNXIZxhPexG8DMH/RSvPBJGW2cyA9RFWQU9bwnl
9mPyiFB8nGOFh5EK5m9+BTaE3vItK6wOslS+jwMHD7J/o9NcaVVXQl4duaANG9oA
gA6K3f3pfUEcIl3eBDU534DM+GZfgKaH8vkUoM9kbKomzp42Co8KXscMzwLv0m8S
fbytyQG51ksg1J5UbZph7dKjTUWDbvdY+ILCw0OqwwOcEC/32oaIHexURZN3htbB
qVqeyrtD+xLoBzvSRTyCo9yTp7hmjtz3cFMMVM4W8nvuH7yuAL3Y4hOch3OmEAJO
m9Cgo3SLQNEs64FMuYXefql7GTbKzs+2XHf2C1p4khZguTAZIgUDq0mnYYUE3nE=
=e9Gg
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/91251ca6/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/91251ca6/attachment.key>

From Antony.Stone at squid.open.source.it  Wed Aug 24 12:24:05 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 24 Aug 2016 14:24:05 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD917A.9010304@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com> <57BD917A.9010304@gmail.com>
Message-ID: <201608241424.05936.Antony.Stone@squid.open.source.it>

On Wednesday 24 August 2016 at 14:22:18, Samuraiii wrote:

> On 24.8.2016 14:18, Yuri Voinov wrote:
> > No one CA do not issue signing CA for subject, which is not CA itself.
> > 
> > So, op wants impossible thing.
> 
> I have tried to drop clientca option, to add generate-host-certificates=off
>  but outcome is still same error...
> 
> even with just this as config:
> https_port 8443 accel \

Why are you using accelerator mode?  Surely this is just a normal forwarding 
proxy?

>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem


Antony.

-- 
"Reports that say that something hasn't happened are always interesting to me, 
because as we know, there are known knowns; there are things we know we know. 
We also know there are known unknowns; that is to say we know there are some 
things we do not know. But there are also unknown unknowns - the ones we don't 
know we don't know."

 - Donald Rumsfeld, US Secretary of Defence

                                                   Please reply to the list;
                                                         please *don't* CC me.


From samurai.no.dojo at gmail.com  Wed Aug 24 12:26:10 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Wed, 24 Aug 2016 14:26:10 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <201608241424.05936.Antony.Stone@squid.open.source.it>
References: <57BD8080.7090808@gmail.com>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com> <57BD917A.9010304@gmail.com>
 <201608241424.05936.Antony.Stone@squid.open.source.it>
Message-ID: <57BD9262.8040209@gmail.com>

On 24.8.2016 14:24, Antony Stone wrote:
> On Wednesday 24 August 2016 at 14:22:18, Samuraiii wrote:
>
>> On 24.8.2016 14:18, Yuri Voinov wrote:
>>> No one CA do not issue signing CA for subject, which is not CA itself.
>>>
>>> So, op wants impossible thing.
>> I have tried to drop clientca option, to add generate-host-certificates=off
>>  but outcome is still same error...
>>
>> even with just this as config:
>> https_port 8443 accel \
> Why are you using accelerator mode?  Surely this is just a normal forwarding 
> proxy?
It was just kind of random try.
Error is still same.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/ac948e42/attachment.htm>

From yvoinov at gmail.com  Wed Aug 24 12:26:48 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 18:26:48 +0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <201608241423.13198.Antony.Stone@squid.open.source.it>
References: <57BD8080.7090808@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
Message-ID: <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.08.2016 18:23, Antony Stone ?????:
> On Wednesday 24 August 2016 at 14:18:46, Yuri Voinov wrote:
>
>> No one CA do not issue signing CA for subject, which is not CA itself.
>>
>> So, op wants impossible thing.
>
> Why would one need a signING certificate just to create an SSL connection
> between the browser and Squid?
>
> Surely one merely needs a valid signED certificate, same as you would
put on a
> web server to set up secure connections to it?
>
> OP is not intercepting secure traffic, nor making HTTP sites look to
the browser
> like HTTPS ones.
Then I do not understand what he wants op.
>
>
>
> Antony.
>
>> 24.08.2016 18:15, Antony Stone ?????:
>>> On Wednesday 24 August 2016 at 14:02:43, Samuraiii wrote:
>>>> Squid fails to start for me with:
>>>> FATAL: No valid signing SSL certificate configured for HTTPS_port
>>
>> [::]:8443
>>
>>>> I have found that this is related to missing self signed certificate,
>>>> and since I do not want to use self signed certificate I am asking if I
>>>> can do anything about it.
>>>> I would like to avoid self signed certificates so my users would not
>>>> need to import and replace my own certs.
>>>
>>> Have you tried adding the option "generate-host-certificates=off" to
your
>>> https_port line?
>>>
>>> I'm not an expert on this bit of Squid, but I'm just looking at
>>> http://www.squid-cache.org/Versions/v3/3.5/cfgman/https_port.html and
>>
>> noticing
>>
>>> anything to do with a "signing certificate" (which you do not have,
>>
>> and do not
>>
>>> want to use).
>>>
>>>> And here is my complete squid.conf:
>>>>
>>>> acl SSL_ports port 443
>>>> acl Safe_ports port 80          # http
>>>> acl Safe_ports port 21          # ftp
>>>> acl Safe_ports port 443         # https
>>>> acl Safe_ports port 70          # gopher
>>>> acl Safe_ports port 210         # wais
>>>> acl Safe_ports port 1025-65535  # unregistered ports
>>>> acl Safe_ports port 280         # http-mgmt
>>>> acl Safe_ports port 488         # gss-http
>>>> acl Safe_ports port 591         # filemaker
>>>> acl Safe_ports port 777         # multiling http
>>>> acl Safe_ports port 901         # SWAT
>>>> acl CONNECT method CONNECT
>>>> http_access deny !Safe_ports
>>>> http_access deny CONNECT !SSL_ports
>>>> http_access allow localhost manager
>>>> http_access deny manager
>>>> http_access deny to_localhost
>>>>
>>>> auth_param basic program /usr/libexec/squid/basic_pam_auth
>>>> auth_param basic children 5
>>>> auth_param basic realm Proxy Authentication Required
>>>> auth_param basic credentialsttl 2 hours
>>>>
>>>> acl authenticated proxy_auth REQUIRED
>>>> http_access allow authenticated
>>>> http_access deny all
>>>>
>>>> https_port 8443 \
>>>>
>>>>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>>>>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
>>>>     clientca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
>>>>     tls-dh=/etc/ssl/certs/dhparam.pem \
>>>>     options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
>>>>     cipher=HIGH
>>>>
>>>> cache_dir aufs /var/cache/squid 512 16 256
>>>> coredump_dir /var/cache/squid
>>>> refresh_pattern ^ftp:           1440    20%     10080
>>>> refresh_pattern ^gopher:        1440    0%      1440
>>>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>>>> refresh_pattern .               0       20%     4320
>>>
>>> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvZKIAAoJENNXIZxhPexG5iIIAJTZAbpMkYDqdVWG5thlBxG0
cJBXI/MmYN7Al6GiGGD1ttqXHv6AAIeg5NXue0qVM/hGcJuE5eTI4+10zzQImeTU
OFRHz/C4EqBCDb06lfM+spR/5xFxW4l8vXYxr9Q61YYE2JyCvmMEoABntiWrE0/+
pwoUiNK2lIVURAGMBjMzMYwAC/t0D8JRg79gsh+o/h3TtOtAiKFbZRU3Dy2EqP9E
0pNssmSvUSR4Du0mY4fZJisAnUNUzYz1qkX0GyS0zdj6LZ4r7VlTX+fjyfPGd/fg
va1nQFgA5IqQ+VKoD02GSNBkNCw56j8aOwoo3RXO6bLKPell5NFzWVC3Wrn0AXY=
=9vnU
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/2584f1bf/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/2584f1bf/attachment.key>

From samurai.no.dojo at gmail.com  Wed Aug 24 12:31:30 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Wed, 24 Aug 2016 14:31:30 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com>
Message-ID: <57BD93A2.8080103@gmail.com>


>       look to the browser
>
>       > like HTTPS ones.
> Then I do not understand what he wants op.
>
>
>

http://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connection

Secure connection to squid proxy without need for anything else (on
client side) than configuring proxy in browser.
Using provided signed certificates.
No SSL-bumping or whatever just forwarding.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/7892748c/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Aug 24 12:32:52 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 24 Aug 2016 14:32:52 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com>
Message-ID: <201608241432.53118.Antony.Stone@squid.open.source.it>

On Wednesday 24 August 2016 at 14:26:48, Yuri Voinov wrote:

> 24.08.2016 18:23, Antony Stone ?????:
> > On Wednesday 24 August 2016 at 14:18:46, Yuri Voinov wrote:
> >> No one CA do not issue signing CA for subject, which is not CA itself.
> >> 
> >> So, op wants impossible thing.
> > 
> > Why would one need a signING certificate just to create an SSL connection
> > between the browser and Squid?
> > 
> > Surely one merely needs a valid signED certificate, same as you would
> > put on a web server to set up secure connections to it?
> > 
> > OP is not intercepting secure traffic, nor making HTTP sites look to
> > the browser like HTTPS ones.
> 
> Then I do not understand what he wants op.

He wants to configure his browser to connect to the proxy over an SSL 
connection, and then inside this secure connection send standard HTTP and 
HTTPS requests, just as a browser would do over an unsecured connection to the 
proxy on Squid's standard port 3128.

It's nothing to do with whether either the client or the destination server 
believe the web content itself to be secured with SSL/TLS.

See "Encrypted browser-Squid connection" at the bottom of
http://wiki.squid-cache.org/Features/HTTPS


Antony.

-- 
Archaeologists have found a previously-unknown dinosaur which seems to have 
had a very large vocabulary.  They've named it Thesaurus.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Wed Aug 24 12:35:03 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 18:35:03 +0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD93A2.8080103@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com> <57BD93A2.8080103@gmail.com>
Message-ID: <087c3a5a-7db6-79bc-27b4-246e64aca519@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.08.2016 18:31, Samuraiii ?????:
>
>>       look to the browser
>>
>>       > like HTTPS ones.
>> Then I do not understand what he wants op.
>>
>>
>>
>
>
http://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connection
>
> Secure connection to squid proxy without need for anything else (on
client side) than configuring proxy in browser.
> Using provided signed certificates.
> No SSL-bumping or whatever just forwarding.
Firstly, the concept is not safe. Users will have a secure connection to
the proxy - as well as the next? HTTP? User misled green padlock,
believes all secure connection - as external traffic is not encrypted
after the fact. Second. You seriously think that the world will sit
under HTTPS? What, for example, you want to protect on news sites?
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvZR2AAoJENNXIZxhPexGuysH/isUCXkB+snA0NlEimmF9Z2k
wC7jugsj7Fu5hzmx2JFI/Q6X+uuJ/bxzjqwkMQGA3358EZI3PtYfuvJmRoF5g4eE
X4zoy9anB+Phvo1T4/EhT5v8utLBndRgeD0j2btAQmQSYimB6HGoxxrW4XM6EZj3
s/WCPXmfdIdbu/hOvnrPE0a7y7RRbvLx5tvem0jdBpOcLyK4jq40p4f8J57dF5Qk
w0wSKgLe9R+FBjRhj+MxBbjFNDsU1/nP/Nb4wmTgCQ0OPMUprlVIpyz3TDv4qRhY
fxb2nkKZuf1ouKJy/ewtNpZZqX52Pqao1wGWr1U/I/bZtdHVpI87hrKHgj4o3pA=
=0NS/
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/33c508f4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/33c508f4/attachment.key>

From yvoinov at gmail.com  Wed Aug 24 12:36:35 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 18:36:35 +0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <201608241432.53118.Antony.Stone@squid.open.source.it>
References: <57BD8080.7090808@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com>
 <201608241432.53118.Antony.Stone@squid.open.source.it>
Message-ID: <48301d22-f105-99f9-752b-14d673234c01@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.08.2016 18:32, Antony Stone ?????:
> On Wednesday 24 August 2016 at 14:26:48, Yuri Voinov wrote:
>
>> 24.08.2016 18:23, Antony Stone ?????:
>>> On Wednesday 24 August 2016 at 14:18:46, Yuri Voinov wrote:
>>>> No one CA do not issue signing CA for subject, which is not CA itself.
>>>>
>>>> So, op wants impossible thing.
>>>
>>> Why would one need a signING certificate just to create an SSL
connection
>>> between the browser and Squid?
>>>
>>> Surely one merely needs a valid signED certificate, same as you would
>>> put on a web server to set up secure connections to it?
>>>
>>> OP is not intercepting secure traffic, nor making HTTP sites look to
>>> the browser like HTTPS ones.
>>
>> Then I do not understand what he wants op.
>
> He wants to configure his browser to connect to the proxy over an SSL
> connection, and then inside this secure connection send standard HTTP and
> HTTPS requests, just as a browser would do over an unsecured
connection to the
> proxy on Squid's standard port 3128.
Yeah, I get it. It seems to me, is absolutely crazy and insecure idea.
>
>
> It's nothing to do with whether either the client or the destination
server
> believe the web content itself to be secured with SSL/TLS.
>
> See "Encrypted browser-Squid connection" at the bottom of
> http://wiki.squid-cache.org/Features/HTTPS
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvZTTAAoJENNXIZxhPexG3n4H/0O+OLxWoxAIoVq4B2g33Ep0
Iz4JkLx542E4gQjCzhtO3Ikjxoh2VLwwkF/S6PZqNvmQg6dJ6sbZVSsUBtJa6h+6
dWCM6gEeH/xnO3B5krKw9t721fyMpQEmb2uKCLyDxpJHiJLGShifliFykfcZwJ+m
Vt7+bp1R4KWtYGfh/2QUyRwzReMqlEkuNIJ2/KHucuuEfMauOB/Gn42MsPQDxZKZ
I0eJmi4Eo8jzYKyC1ZLsZVPVqVSuMz152QYdhBuUb5AJo/DaWVuyEwmhP0MYmEbU
bSYzQh8FiKuTsrHKYoqqo6m7fLtbz2o5ouGP8kbq6l93E9JBsmBwSsR28Urzwyg=
=C3LP
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/3e00c8f5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/3e00c8f5/attachment.key>

From yvoinov at gmail.com  Wed Aug 24 12:37:19 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 18:37:19 +0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <201608241432.53118.Antony.Stone@squid.open.source.it>
References: <57BD8080.7090808@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com>
 <201608241432.53118.Antony.Stone@squid.open.source.it>
Message-ID: <6dbcfb36-0c8c-a806-2f55-45468ac0a660@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Against this backdrop, even a bump SSL security seems a masterpiece.


24.08.2016 18:32, Antony Stone ?????:
> On Wednesday 24 August 2016 at 14:26:48, Yuri Voinov wrote:
>
>> 24.08.2016 18:23, Antony Stone ?????:
>>> On Wednesday 24 August 2016 at 14:18:46, Yuri Voinov wrote:
>>>> No one CA do not issue signing CA for subject, which is not CA itself.
>>>>
>>>> So, op wants impossible thing.
>>>
>>> Why would one need a signING certificate just to create an SSL
connection
>>> between the browser and Squid?
>>>
>>> Surely one merely needs a valid signED certificate, same as you would
>>> put on a web server to set up secure connections to it?
>>>
>>> OP is not intercepting secure traffic, nor making HTTP sites look to
>>> the browser like HTTPS ones.
>>
>> Then I do not understand what he wants op.
>
> He wants to configure his browser to connect to the proxy over an SSL
> connection, and then inside this secure connection send standard HTTP and
> HTTPS requests, just as a browser would do over an unsecured
connection to the
> proxy on Squid's standard port 3128.
>
> It's nothing to do with whether either the client or the destination
server
> believe the web content itself to be secured with SSL/TLS.
>
> See "Encrypted browser-Squid connection" at the bottom of
> http://wiki.squid-cache.org/Features/HTTPS
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvZT/AAoJENNXIZxhPexG2NQH/3zgESU+lH6DAOGxvB/9IPUa
P9OUKg4Ss9sRj8l1zUhAxy1Gf5A9vbX0qxUKF7KhhwsmUU1BSG+F2ocbouG4YGwJ
VNeyPSLhsQ9AF83OZEaaov4cra9YuYSk7pGxm4SdafTYDyPU96UCcj5MwEQfRzjq
TgB7GVrhGQ7TalEjGKGW8qP6nI1apriEkKXNCbEvm6Q3tpIjp72cx/LuQv/pu03x
BOFpZoUxzn61a2JUV4+lUcz6lmeji3kcTSWhuMBgE+W8klqxRYGOtVTGwNLv08N2
v1HYYI05BrCtqVYaPXAfKNxgqzBIS8X7fFSf14JrnpsF0W6d994g5La3EnOpZ/4=
=kNOJ
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/3df6d4c8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/3df6d4c8/attachment.key>

From omidkosari at yahoo.com  Wed Aug 24 12:39:07 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 24 Aug 2016 05:39:07 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1472040642333-4679111.post@n4.nabble.com>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
Message-ID: <1472042347026-4679126.post@n4.nabble.com>

This config works for dstdomain acl type

acl test dstdomain 123.com
deny_info TCP_RESET test
adapted_http_access deny test


but it is not what i want . I want

acl status_400 http_status 400
deny_info TCP_RESET status_400 
adapted_http_access deny status_400 

OR

acl HTTP proto HTTP
acl PORT_80 port 80 
deny_info TCP_RESET PORT_80 !HTTP
adapted_http_access deny PORT_80 !HTTP 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679126.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From samurai.no.dojo at gmail.com  Wed Aug 24 12:44:35 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Wed, 24 Aug 2016 14:44:35 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <087c3a5a-7db6-79bc-27b4-246e64aca519@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com> <57BD93A2.8080103@gmail.com>
 <087c3a5a-7db6-79bc-27b4-246e64aca519@gmail.com>
Message-ID: <57BD96B3.9050203@gmail.com>


>
>       > No SSL-bumping or whatever just forwarding.
> Firstly, the concept is not safe. Users will have a secure connection
> to the proxy - as well as the next? HTTP? User misled green padlock,
> believes all secure connection - as external traffic is not encrypted
> after the fact. Second. You seriously think that the world will sit
> under HTTPS? What, for example, you want to protect on news sites?
>
>
Since I would like to set up proxy for few people I am comfortable in
telling them what to want from it and what not.
Second what about of security on proxy login info?
Last I asked this because I stumbled on this on official squid wiki.
It wouldn't cross my mind that it existed.
It should be corrected, if it is impossible to set it up.
I really do not like your quick judgement.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/2e82a1bb/attachment.htm>

From yvoinov at gmail.com  Wed Aug 24 12:48:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 18:48:40 +0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD96B3.9050203@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com> <57BD93A2.8080103@gmail.com>
 <087c3a5a-7db6-79bc-27b4-246e64aca519@gmail.com> <57BD96B3.9050203@gmail.com>
Message-ID: <a32f4aee-891a-d38d-5a53-3a3a44636514@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.08.2016 18:44, Samuraiii ?????:
>
>>
>>       > No SSL-bumping or whatever just forwarding.
>> Firstly, the concept is not safe. Users will have a secure connection
to the proxy - as well as the next? HTTP? User misled green padlock,
believes all secure connection - as external traffic is not encrypted
after the fact. Second. You seriously think that the world will sit
under HTTPS? What, for example, you want to protect on news sites?
>>
>>
> Since I would like to set up proxy for few people I am comfortable in
telling them what to want from it and what not.
> Second what about of security on proxy login info?
> Last I asked this because I stumbled on this on official squid wiki.
> It wouldn't cross my mind that it existed.
> It should be corrected, if it is impossible to set it up.
> I really do not like your quick judgement.
What is the question - is the answer. Telepaths vacation.

I also do not like a lot of things in the modern sense of security.
However, I did not create this world in this. In addition, as far as I
know, the functionality that you want to see - do not exist in nature.
Either fully encrypted connections - or not at all. Proxy is not a Web
server that can encrypt only the login and then leave unprotected
connection or let the tunnel.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvZeoAAoJENNXIZxhPexGR8oH/2qrV0Hqc2A8OnmO/m5Xd+2/
Rhlmabr5yofll/aqg3qwmYwY76QcONt2+Ur4kmbf99chwALV/68qVyahPTbyB/8w
NY9/lYffQYeff63bWj/VbbdjYtH1vjp2NmD47nfv5fJFaVOTtGlvVhJ55VLtY2eC
IfT/WflvA6aGnG7IyyvTa0EDN7unhgvBJEwUXvmhnCDJVF0NWWp9NcWZytufF3g9
9V02KYIaw49TFmUOMn0R3f42HHpCrlYLNNG8yy3yBs2t5o4dhQ+dMvTE6MWQrzgR
kPLoJcLKzrlFN8aY1MzKo7MjiAY8WGkkayZnaS65c//sZFa63CI4/q17Iu++qJM=
=6+l5
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/29018063/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/29018063/attachment.key>

From samurai.no.dojo at gmail.com  Wed Aug 24 13:01:50 2016
From: samurai.no.dojo at gmail.com (Samurai)
Date: Wed, 24 Aug 2016 13:01:50 +0000
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <a32f4aee-891a-d38d-5a53-3a3a44636514@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241416.00249.Antony.Stone@squid.open.source.it>
 <899513e9-73c7-c158-83e6-d05634c07011@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com> <57BD93A2.8080103@gmail.com>
 <087c3a5a-7db6-79bc-27b4-246e64aca519@gmail.com> <57BD96B3.9050203@gmail.com>
 <a32f4aee-891a-d38d-5a53-3a3a44636514@gmail.com>
Message-ID: <9C06C28C-B263-4333-B6CE-061AD49B665F@gmail.com>

Ok
This is answer (not) I was looking for. 
Thank you 
S

On 24 August 2016 14:48:40 CEST, Yuri Voinov <yvoinov at gmail.com> wrote:
>
>-----BEGIN PGP SIGNED MESSAGE-----
>Hash: SHA256
> 
>
>
>24.08.2016 18:44, Samuraiii ?????:
>>
>>>
>>>       > No SSL-bumping or whatever just forwarding.
>>> Firstly, the concept is not safe. Users will have a secure
>connection
>to the proxy - as well as the next? HTTP? User misled green padlock,
>believes all secure connection - as external traffic is not encrypted
>after the fact. Second. You seriously think that the world will sit
>under HTTPS? What, for example, you want to protect on news sites?
>>>
>>>
>> Since I would like to set up proxy for few people I am comfortable in
>telling them what to want from it and what not.
>> Second what about of security on proxy login info?
>> Last I asked this because I stumbled on this on official squid wiki.
>> It wouldn't cross my mind that it existed.
>> It should be corrected, if it is impossible to set it up.
>> I really do not like your quick judgement.
>What is the question - is the answer. Telepaths vacation.
>
>I also do not like a lot of things in the modern sense of security.
>However, I did not create this world in this. In addition, as far as I
>know, the functionality that you want to see - do not exist in nature.
>Either fully encrypted connections - or not at all. Proxy is not a Web
>server that can encrypt only the login and then leave unprotected
>connection or let the tunnel.
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>-----BEGIN PGP SIGNATURE-----
>Version: GnuPG v2
> 
>iQEcBAEBCAAGBQJXvZeoAAoJENNXIZxhPexGR8oH/2qrV0Hqc2A8OnmO/m5Xd+2/
>Rhlmabr5yofll/aqg3qwmYwY76QcONt2+Ur4kmbf99chwALV/68qVyahPTbyB/8w
>NY9/lYffQYeff63bWj/VbbdjYtH1vjp2NmD47nfv5fJFaVOTtGlvVhJ55VLtY2eC
>IfT/WflvA6aGnG7IyyvTa0EDN7unhgvBJEwUXvmhnCDJVF0NWWp9NcWZytufF3g9
>9V02KYIaw49TFmUOMn0R3f42HHpCrlYLNNG8yy3yBs2t5o4dhQ+dMvTE6MWQrzgR
>kPLoJcLKzrlFN8aY1MzKo7MjiAY8WGkkayZnaS65c//sZFa63CI4/q17Iu++qJM=
>=6+l5
>-----END PGP SIGNATURE-----
>
>
>
>------------------------------------------------------------------------
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/3204aeee/attachment.htm>

From belle at bazuin.nl  Wed Aug 24 13:02:35 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 24 Aug 2016 15:02:35 +0200
Subject: [squid-users] ext_kerberos_ldap_group_acl problem
In-Reply-To: <CAD8MJvC8ZDWpUVE6iSaKu6qvx-7-3+Vy_4_kSiGq0oubauEqkA@mail.gmail.com>
References: <vmime.57bd7efe.2042.2ab404f210b0abde@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57bd9aeb.72ce.fa87a6d7dfd8a1b@ms249-lin-003.rotterdam.bazuin.nl>

Hello Dia, 

?

Thank you for the reply,? 

?

So, can this be a ?MIT? kerberos of HEIMDAL thing. 

Im use Samba4 for ADDC and that uses heimdal. 

?

Even that the logs says : 

"Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database".?

?

Im using NFSv4 over kerberos, ssh over kerberos, squid user auth already and that is working fine. ( on the same server ) 

I dont have/use kadmin, since samba is my KDC. 

?

The only thing i can think of besides MIT or HEIMDAL is that i use a dedicated user, which is having the SPN for my proxy server. 

?

A snip from my krb5.conf 

[libdefaults]

??? default_realm = YOUR.REALM.TLD

??? dns_lookup_kdc = true

??? dns_lookup_realm = false

?

?

Best regards, 

?

Louis

?

?

?

?


Van: Diogenes S. Jesus [mailto:splash at gmail.com] 
Verzonden: woensdag 24 augustus 2016 13:29
Aan: L.P.H. van Belle
CC: squid-users at squid-cache.org
Onderwerp: Re: [squid-users] ext_kerberos_ldap_group_acl problem


?

Hi there.

?


Well, the log says "Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database".?

?


Check your krb5.conf on the squid host if you're pointing to the right KDC and make sure the principal exists in the Kerberos database.


kadmin.local and "getprinc?HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD" should yield the same error if the principal doesn't exist.


?


Dio




?

On Wed, Aug 24, 2016 at 1:03 PM, L.P.H. van Belle <belle at bazuin.nl> wrote:

Hai, 

?

Im having trouble to get the ext_kerberos_ldap_group_acl? working. 

?

I?ve read : http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_kerberos_ldap_group_acl.html

?

Here is what i have checked / done already. 

?

My keytab file : 

klist -ekt /etc/squid/keytab.PROXYSERVER-HTTP

Keytab name: FILE:/etc/squid/keytab.PROXYSERVER-HTTP

KVNO Timestamp?????????? Principal

---- ------------------- ------------------------------------------------------

?? 1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD (des-cbc-crc)

?? 1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD (des-cbc-md5)

?? 1 06/08/2015 15:28:03 HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD (arcfour-hmac)

?? 

?

The auth im using ( which is working fine )

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \

--kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD \

--ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOMAIN

?

For testing im starting on commandline the group acl: 

/usr/lib/squid3/ext_kerberos_ldap_group_acl -D YOUR.REALM.TLD -N internet-mail at NTDOMAIN -m 4 -s -i ?d

?

kerberos_ldap_group.cc(278): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: INFO: Starting version 1.3.1sq

support_group.cc(382): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: INFO: Group list internet-mail at YOUR.REALM.TLD

support_group.cc(447): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: INFO: Group internet-mail? Domain YOUR.REALM.TLD

support_netbios.cc(83): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: DEBUG: Netbios list internet-mail at NTDOMAIN

support_netbios.cc(156): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: DEBUG: Netbios name internet-mail? Domain NTDOMAIN

support_lserver.cc(82): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: DEBUG: ldap server list NULL

support_lserver.cc(86): pid=20782 :2016/08/24 10:40:49| kerberos_ldap_group: DEBUG: No ldap servers defined.

?

when i test with the user group now. 

?

testuser internet-mail

?

kerberos_ldap_group.cc(371): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: INFO: Got User: testuser set default domain: YOUR.REALM.TLD

kerberos_ldap_group.cc(376): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: INFO: Got User: testuser Domain: YOUR.REALM.TLD

support_member.cc(63): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: User domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(65): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Found group at domain internet-mail at YOUR.REALM.TLD

support_ldap.cc(898): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Setup Kerberos credential cache

support_krb5.cc(127): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Set credential cache to MEMORY:squid_ldap_21722

support_krb5.cc(138): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Get default keytab file name

support_krb5.cc(144): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got default keytab file name /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(158): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Get principal name from keytab /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Found principal name: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initialising credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Found principal name: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initialising credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(169): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Found principal name: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got principal name HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initialising credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(282): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Did not find a principal in keytab for domain YOUR.REALM.TLD.

support_krb5.cc(283): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Try to get principal of trusted domain.

support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initializing credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initializing credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(297): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Keytab entry has principal: HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD

support_krb5.cc(64): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error while initializing credentials from keytab : Client 'HTTP/hostname.internet.domain.tld at YOUR.REALM.TLD' not found in Kerberos database

support_krb5.cc(366): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Got no principal name

support_ldap.cc(903): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: ERROR: Error during setup of Kerberos credential cache

support_member.cc(76): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: INFO: User testuser is not member of group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(91): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Default domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(119): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: Default group loop: group at domain internet-mail at YOUR.REALM.TLD

ERR

kerberos_ldap_group.cc(411): pid=21722 :2016/08/24 10:57:39| kerberos_ldap_group: DEBUG: ERR

?

?

I dont see what im missing here. 

I?m running Debian Jessie, ldap is setup for SSL, samba 4.4.5 and squid 3.5.19. 

?

I did see something about kerberos and groups but i can find that post. 

So anyone any suggestion/tip howto debug this or why im getting ?Error while initializing credentials from keytab?

?

Greetz, 

?

Louis

?

?




_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users






?


-- 


--------

Diogenes S. de Jesus






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/490795fc/attachment.htm>

From marcus.kool at urlfilterdb.com  Wed Aug 24 13:23:03 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 24 Aug 2016 10:23:03 -0300
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <cc4e3527-6cd4-a8c1-9f2f-928ff38a0a9d@measurement-factory.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
 <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
 <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>
 <a91c6004-4705-a776-6b1c-6c0143dc7125@urlfilterdb.com>
 <cc4e3527-6cd4-a8c1-9f2f-928ff38a0a9d@measurement-factory.com>
Message-ID: <3fc016b9-dd62-ef2c-da3f-56d54ecbb23a@urlfilterdb.com>



On 08/24/2016 02:43 AM, Alex Rousskov wrote:
> On 08/23/2016 08:34 AM, Marcus Kool wrote:
>
>> ok, I suggest that you review what is done already.
>
> I have made a few corrections and improvements, trying to document every
> change (and some suggestions for future work) in the commit messages.
>
> The page still needs a lot of work IMO, but perhaps it is now better
> than it was before you started polishing it.
>
>
> Thank you,
>
> Alex.

Ok, it is improving.
I added an image in PNG format with data flow and events.
If you are interested I can send you the ODG file that was
used to generate the image.

Marcus



From squid3 at treenet.co.nz  Wed Aug 24 13:23:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 Aug 2016 01:23:07 +1200
Subject: [squid-users] DENIED and ALLOWED at once?
In-Reply-To: <CABZC=5xey1HUdEQRHNTC9P7trdAUiwT0_1AWiiVb7xkEj_evmw@mail.gmail.com>
References: <CABZC=5zu1F_-garY7XiKQeoCDNAheiQcDNcEsp0UQ-XQhoidig@mail.gmail.com>
 <CADSSinNTVG4_diOHMKpp+1wp=Q5D6X5nz8E_2cEfupachczidA@mail.gmail.com>
 <201608192222.20884.Antony.Stone@squid.open.source.it>
 <CABZC=5xey1HUdEQRHNTC9P7trdAUiwT0_1AWiiVb7xkEj_evmw@mail.gmail.com>
Message-ID: <47a367a0-faa3-a5b5-99eb-122942d61f06@treenet.co.nz>

On 24/08/2016 3:55 a.m., Sergio Belkin wrote:
> 2016-08-19 17:22 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:
> 
>> On Friday 19 August 2016 at 20:41:11, Jok Thuau wrote:
>>
>>> On Fri, Aug 19, 2016 at 9:33 AM, Sergio Belkin <sebelk at gmail.com> wrote:
>>>> /var/log/squid/access.log
>>>> 192.168.50.41 - - [19/Aug/2016:12:19:45 -0300] "CONNECT
>>>> beap-bc.yahoo.com:443 HTTP/1.1" 407 4634 "-" "Mozilla/5.0 (Windows NT
>>>> 6.1; WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TCP_DENIED:HIER_NONE
>>>
>>> This is unauthenticated (notice the "- -" after the IP)
>>>
>>>> 192.168.50.41 - juan.perez [19/Aug/2016:12:19:45 -0300] "CONNECT
>>>> beap-bc.yahoo.com:443 HTTP/1.1" 200 0 "-" "Mozilla/5.0 (Windows NT
>> 6.1;
>>>> WOW64; rv:41.0) Gecko/20100101 Firefox/41.0" TAG_NONE:HIER_DIRECT
>>>
>>> This one is authenticated (juan.perez). The code 407 in the first request
>>> means "proxy request authentication". So what happened here is that the
>>> user browsed, was asked for credentials (and maybe those were provided
>>> automatically), and then the request was resent with the creds included.
>>
>> Given the timestamps (both 12:19:45; no time for a human to enter
>> credentials
>> at a prompt) the browser did this automatically, and invisibly to the user.
>>
> 
> 
> Exactly it does so, but I wonder if TCP_DENIED is the proper message here.
> 
> It's a case of "client must first authenticate itself with the proxy" (
> https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html), perhaps I'm
> wrong, but would something such as TCP_UNAUTHORIZED be better?
> 

'Unauthorized' is what DENIED means. That is not related to the 407
(*Authenticate* required).

The textual part is indicating what actions Squid has taken. DENIED
means a denial/error page was generated. In this case referring to the
payload it sent on the 407 response.


The 407 means "Authentication Required". Repeating that in the textual
tag would be redundant and also no cover the subtle event cases properly ...

Specifically, in uncommon cases a 407 can also be logged with other tags
like HIT (the response was stored in cache for some reason - not
produced due to authenticator activity), and MISS (upstream proxy
generated the 407), or even REFRESH etc.

Amos



From Antony.Stone at squid.open.source.it  Wed Aug 24 13:24:57 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 24 Aug 2016 15:24:57 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <087c3a5a-7db6-79bc-27b4-246e64aca519@gmail.com>
References: <57BD8080.7090808@gmail.com> <57BD93A2.8080103@gmail.com>
 <087c3a5a-7db6-79bc-27b4-246e64aca519@gmail.com>
Message-ID: <201608241524.57514.Antony.Stone@squid.open.source.it>

On Wednesday 24 August 2016 at 14:35:03, Yuri Voinov wrote:

> >> Then I do not understand what he wants op.
> 
> http://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connecti
> on
> 
> > Secure connection to squid proxy without need for anything else (on
> > client side) than configuring proxy in browser.
> 
> > Using provided signed certificates.
> > No SSL-bumping or whatever just forwarding.
> 
> Firstly, the concept is not safe. Users will have a secure connection to
> the proxy

Yes, that is all the OP is looking for.

> as well as the next?

Once it leaves the OP's network I suspect the risk (of eavesdropping etc) is 
reduced.

> HTTP? User misled green padlock,

I do not think the browser will show an SSL/TLS padlock for a secured proxy 
connection - it only shows this for a secured connection to the destination 
server.  Therefore no misled users.

> believes all secure connection - as external traffic is not encrypted
> after the fact. Second. You seriously think that the world will sit
> under HTTPS? What, for example, you want to protect on news sites?

I don't understand what you are saying here.

The connection across the local network between browser and proxy is secured.

Beyond that everything works across the Internet just as normal - HTTP sites 
are not secured, HTTPS sites are secured.  The user sees SSL padlock and 
certificate chain for HTTPS sites, nothing for HTTP sites.

So, the design is more secure over the local network than the standard 
arrangement, and exactly the same beyond the local network.

No security is being compromised or downgraded.


Antony.

-- 
Douglas was one of those writers who honourably failed to get anywhere with 
'weekending'.  It put a premium on people who could write things that lasted 
thirty seconds, and Douglas was incapable of writing a single sentence that 
lasted less than thirty seconds.

 - Geoffrey Perkins, about Douglas Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Wed Aug 24 13:30:33 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 24 Aug 2016 19:30:33 +0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <201608241524.57514.Antony.Stone@squid.open.source.it>
References: <57BD8080.7090808@gmail.com> <57BD93A2.8080103@gmail.com>
 <087c3a5a-7db6-79bc-27b4-246e64aca519@gmail.com>
 <201608241524.57514.Antony.Stone@squid.open.source.it>
Message-ID: <18eb0c6b-8644-bc18-459b-38e89ece58be@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.08.2016 19:24, Antony Stone ?????:
> On Wednesday 24 August 2016 at 14:35:03, Yuri Voinov wrote:
>
>>>> Then I do not understand what he wants op.
>>
>>
http://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connecti
>> on
>>
>>> Secure connection to squid proxy without need for anything else (on
>>> client side) than configuring proxy in browser.
>>
>>> Using provided signed certificates.
>>> No SSL-bumping or whatever just forwarding.
>>
>> Firstly, the concept is not safe. Users will have a secure connection to
>> the proxy
>
> Yes, that is all the OP is looking for.
>
>> as well as the next?
>
> Once it leaves the OP's network I suspect the risk (of eavesdropping
etc) is
> reduced.
>
>> HTTP? User misled green padlock,
>
> I do not think the browser will show an SSL/TLS padlock for a secured
proxy
> connection - it only shows this for a secured connection to the
destination
> server.  Therefore no misled users.
>
>> believes all secure connection - as external traffic is not encrypted
>> after the fact. Second. You seriously think that the world will sit
>> under HTTPS? What, for example, you want to protect on news sites?
>
> I don't understand what you are saying here.
May be some misunderstanding here.

If we are talking about encryption, just authentication proxy - is one
thing. If encryption of all client traffic at all only to the proxy, not
caring about what happens to it next - is another.

>
> The connection across the local network between browser and proxy is
secured.
>
> Beyond that everything works across the Internet just as normal - HTTP
sites
> are not secured, HTTPS sites are secured.  The user sees SSL padlock and
> certificate chain for HTTPS sites, nothing for HTTP sites.
>
> So, the design is more secure over the local network than the standard
> arrangement, and exactly the same beyond the local network.
Correct LAN design solves most of these problems.
>
>
> No security is being compromised or downgraded.
Not sure.
>
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvaF5AAoJENNXIZxhPexG7MMH/RYfzKl3PMQFBtbjZ8jg6Jra
4dtgJifJTLjSsF0NSqRtT/iZ8KpW3SrSJ+10Ht9IoVbjGiAL8p8/FMLh8/ImTmqJ
QxqI0ovLgj/YuHoxlm4U25L7NG0amzUTINhNXRw79Yvp5RxNEyAmfFpy0mAfD34h
ClXQQeWsCalS8Wz7yGqpgp28T9m86l3BNe+SoP+Q1/tfIkopcGD4Hz32N32J/Bsm
Wen8JMW2f6BAa0mIbb+tV9q1dI5stommTtprCzi8kAtzqX2bbBt3Nnz+xXQWZmwZ
tEO9CsLN4fTSUGILLQG2Bv5ZyT0tAFvhxzCBoz8hpBO+NcIPkm5OgkzpGe32/NA=
=A9CF
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/8df31cb7/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/8df31cb7/attachment.key>

From squid3 at treenet.co.nz  Wed Aug 24 13:32:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 Aug 2016 01:32:13 +1200
Subject: [squid-users] dynamic group using URI as group name on external
 acl with ext_ldap_group_acl
In-Reply-To: <CAD8MJvBz_AGr7kvUwc=3VL_i1f9oiJEnfg_XCnyDBQCGJFf-_A@mail.gmail.com>
References: <CAD8MJvAEM-zmVAntSGqeJhqXECZjv=W=qhASS=f77w4DAx+ttA@mail.gmail.com>
 <458f56ba-1312-73f7-0951-d62d74090a67@treenet.co.nz>
 <CAD8MJvAutiwk_TTq9_p+FUaAcmE3YdVQUO8584YyH0TR=nmpew@mail.gmail.com>
 <ee070289-7a05-4391-0c69-4ae2558d25a4@treenet.co.nz>
 <CAD8MJvBz_AGr7kvUwc=3VL_i1f9oiJEnfg_XCnyDBQCGJFf-_A@mail.gmail.com>
Message-ID: <a9597c6a-3aee-e92b-7c97-4ba3d9520849@treenet.co.nz>

On 24/08/2016 4:24 a.m., Diogenes S. Jesus wrote:
>>>> If you want to do things like this safely please upgrade to Squid-4
>>>> where the logformat codes are available. Those codes provide
>>>> customizable escaping and quoting styles so you can set one that
>>>> protects LDAP against these attacks to be ued on the URI field value
>>>> sent by Squid.
>>>
>>> You mean these <http://www.squid-cache.org/Doc/config/logformat/>
>>> logformats are available to be used in acl / external acls @ squid.conf?
>> Or?
>>>
>>
>> Yes. I'm trying to get all the things in squid.conf that take/use a
>> custom format to use the logformat code system. Squid-4 is the
>> external_acl_type directives turn.
>>
>> All of them are available for use in the %FORMAT field. It only depends
>> on whether the data any given code outputs exists at the point of
>> transaction where your ACL gets used.
>>
>> Amos
>>
>>
> Cool. I've compiled the latest beta of squid4 and tested. I was able to
> move to "%>rd", the following works:
> 

Doh!. Thanks for the patch it has now been applied to Squid-4.

Amos



From squid3 at treenet.co.nz  Wed Aug 24 13:46:22 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 Aug 2016 01:46:22 +1200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BD8818.3040801@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
Message-ID: <4c3d3b78-a866-e096-9ddf-0211d2c67cb6@treenet.co.nz>

Just to rewind this conversation to the actual problem ...

On 24/08/2016 11:42 p.m., Samuraiii wrote:
> On 24.8.2016 13:18, Antony Stone wrote:
>> Unfortunately it's not Squid that's the challenge - it's the browser.
>>
>> If you're using Firefox and/or Chrome, you should be okay.
>>
>> See "Encrypted browser-Squid connection" at the bottom of
>> http://wiki.squid-cache.org/Features/HTTPS
>>
>>
>> Antony.
>>
> I have seen that, it is the cause of my subscription to this list.
> I haven't been able to find any usable hints.
> My config attempt fails
> 

<snip>
> 
> https_port 8443 \
>     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
>     cleintca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
>     tls-dh=/etc/ssl/certs/dhparam.pem \
>     sslproxy_options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
>     cipher=HIGH


As Dio mentioned the cleintca= (or rather clientca=) is for
authenticating clients ceritficates. Don't use that unless you are
requiring client certs in TLS.

The rest of your config looks reasonable to me. I suspect you have found
a bug introduced during all the SSL-Bump code changes. Please make a
bugzilla report and include your exact Squid version (found with the
'squid -v' command), the https_port line(s) and the exact error message
produced on startup.

Amos



From squid3 at treenet.co.nz  Wed Aug 24 13:54:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 Aug 2016 01:54:28 +1200
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1472042347026-4679126.post@n4.nabble.com>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
Message-ID: <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>

On 25/08/2016 12:39 a.m., Omid Kosari wrote:
> This config works for dstdomain acl type
> 
> acl test dstdomain 123.com
> deny_info TCP_RESET test
> adapted_http_access deny test
> 
> 
> but it is not what i want . I want
> 
> acl status_400 http_status 400
> deny_info TCP_RESET status_400 
> adapted_http_access deny status_400 
> 
> OR
> 
> acl HTTP proto HTTP
> acl PORT_80 port 80 
> deny_info TCP_RESET PORT_80 !HTTP
> adapted_http_access deny PORT_80 !HTTP 
> 

Status code is only available in the response processing pathways.
So use "http_reply_access deny test". As Alex showed the generated
errors do go through that access control.


For better control Squid-4 will be needed, and also the
on_unsupported_protocol will need patching to be applied when HTTP
parser detects unsupported protocol on port 80 (or 3128). AFAIK it is
currently only done by SSL-Bump'ing code detecting non-TLS protocols on
port 443.

Amos



From garryd at comnet.uz  Wed Aug 24 14:09:53 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Wed, 24 Aug 2016 19:09:53 +0500
Subject: [squid-users] Objects with values below 60 second for
 Cache-Control max-age are not cached
In-Reply-To: <1471866407.18669.13.camel@comnet.uz>
References: <1471866407.18669.13.camel@comnet.uz>
Message-ID: <1472047793.650.5.camel@comnet.uz>

On Mon, 2016-08-22 at 16:46 +0500, Garri Djavadyan wrote:
> Hello Squid users,
> 
> Can anyone explain, why Squid doesn't cache the objects with max-age
> values below 60 seconds? For example:
> 
> $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.loca
> l/
> cgi-bin/hello.cgi" && date
> HTTP/1.1 200 OK
> Date: Mon, 22 Aug 2016 11:31:16 GMT
> Server: Apache
> Cache-Control: max-age=60
> Content-Type: text/plain
> X-Cache: MISS from gentoo.comnet.uz
> Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> Connection: keep-alive
> 
> Mon Aug 22 16:31:19 UZT 2016
> 
> ---
> 
> $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.loca
> l/
> cgi-bin/hello.cgi" && date
> HTTP/1.1 200 OK
> Date: Mon, 22 Aug 2016 11:31:23 GMT
> Server: Apache
> Cache-Control: max-age=60
> Content-Type: text/plain
> X-Cache: MISS from gentoo.comnet.uz
> Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> Connection: keep-alive
> 
> Mon Aug 22 16:31:26 UZT 2016
> 
> 
> No problems with values above 60 seconds. For example:
> 
> $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.loca
> l/
> cgi-bin/hello.cgi" && date
> HTTP/1.1 200 OK
> Date: Mon, 22 Aug 2016 11:36:06 GMT
> Server: Apache
> Cache-Control: max-age=70
> Content-Type: text/plain
> X-Cache: MISS from gentoo.comnet.uz
> Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> Connection: keep-alive
> 
> Mon Aug 22 16:36:09 UZT 2016
> 
> ---
> 
> $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.loca
> l/
> cgi-bin/hello.cgi" && date
> HTTP/1.1 200 OK
> Date: Mon, 22 Aug 2016 11:36:06 GMT
> Server: Apache
> Cache-Control: max-age=70
> Content-Type: text/plain
> Age: 5
> X-Cache: HIT from gentoo.comnet.uz
> Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> Connection: keep-alive
> 
> Mon Aug 22 16:36:11 UZT 2016
> 
> 
> As you can see, time difference between origin server and localhost
> is
> 3 seconds (UZT is +5 offset).
> 
> Configuration is minimal:
> 
> # diff -u etc/squid.conf.default etc/squid.conf
> --- etc/squid.conf.default	2016-08-12 17:21:48.877474780 +0500
> +++ etc/squid.conf	2016-08-22 16:41:47.759766991 +0500
> @@ -71,3 +71,5 @@
> ?refresh_pattern ^gopher:	1440	0%	1440
> ?refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
> ?refresh_pattern .		0	20%	4320
> +
> +cache_mem 64 MB
> 
> 
> Thanks in advance!
> Garri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Dear Squid developers,

Is the situation described above intended behaviour, or a bug which
should be reported? Thanks.

Garri


From omidkosari at yahoo.com  Wed Aug 24 14:17:52 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 24 Aug 2016 07:17:52 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
Message-ID: <1472048272300-4679139.post@n4.nabble.com>

acl status_400 http_status 400
deny_info TCP_RESET status_400
http_reply_access deny status_400


still send headers . just the 400 changed to 403


HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Wed, 24 Aug 2016 14:11:35 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 5
X-Cache: MISS from cache1
X-Cache-Lookup: NONE from cache1:3128
Connection: close

reset



Isn't a way that squid does not send these headers and just send reset ?




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679139.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Wed Aug 24 14:28:15 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 24 Aug 2016 08:28:15 -0600
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
 fake CONNECT
In-Reply-To: <3fc016b9-dd62-ef2c-da3f-56d54ecbb23a@urlfilterdb.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
 <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
 <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>
 <a91c6004-4705-a776-6b1c-6c0143dc7125@urlfilterdb.com>
 <cc4e3527-6cd4-a8c1-9f2f-928ff38a0a9d@measurement-factory.com>
 <3fc016b9-dd62-ef2c-da3f-56d54ecbb23a@urlfilterdb.com>
Message-ID: <293d7a76-cdcc-39d2-8481-f59d707454d5@measurement-factory.com>

On 08/24/2016 07:23 AM, Marcus Kool wrote:
> I added an image in PNG format with data flow and events.

And I added an XXX why that image might do more harm than good.


> If you are interested I can send you the ODG file that was
> used to generate the image.

Please attach those image sources to the wiki page itself. I do not
think I will have the time to fix it, but somebody else might.


Thank you,

Alex.



From splash at gmail.com  Wed Aug 24 14:37:31 2016
From: splash at gmail.com (Diogenes S. Jesus)
Date: Wed, 24 Aug 2016 16:37:31 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <4c3d3b78-a866-e096-9ddf-0211d2c67cb6@treenet.co.nz>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
 <4c3d3b78-a866-e096-9ddf-0211d2c67cb6@treenet.co.nz>
Message-ID: <CAD8MJvAKuZL3g5YiWfgOpKgPEyVOb9sO6r=MFoUNGwdoxBqN_A@mail.gmail.com>

This configuration here covers the use case described by the OP:
https://gist.githubusercontent.com/splashx/758ff0c59ea291f32edafc516fdaad73/raw/8050fa054821657812961050332b38a56e7e3e68/

If everything works well, you'll notice you won't support HTTP proxy at
all, but users can reach  both HTTP and HTTPS target websites via your
HTTPS proxy.

# netstat -nltp

Active Internet connections (only servers)

Proto Recv-Q Send-Q Local Address           Foreign Address         State
    PID/Program name

tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
    32109/sshd

tcp6       0      0 :::80                   :::*                    LISTEN
    26627/apache2

tcp6       0      0 :::3443                 :::*                    LISTEN
    7303/(squid-1)

tcp6       0      0 :::22                   :::*                    LISTEN
    32109/sshd


The user connects to the proxy ONLY via HTTPS Proxy on port 3443

All traffic between the OP and the proxy is encrypted using TLS.
A) If the user enters http://target.example.com, between the proxy and the
target you'll see HTTP.
B) If the user enters https://target.example.com, between the proxy and the
target you'll see HTTPS.

If you sniff the traffic between the client and the proxy, you'll see TLS.

Tested with:

$ /Applications/Firefox\ 2.app/Contents/MacOS/firefox -v

Mozilla Firefox 48.0

Firefox set up to use PAC: Preferences > Advanced > Network > Settings:
"Automatic Proxy Configuration": http://squid.example.com/proxy.pac

The downside here of course is the limited amount of clients supporting
HTTPS Proxy settings.

Dio


On Wed, Aug 24, 2016 at 3:46 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> Just to rewind this conversation to the actual problem ...
>
> On 24/08/2016 11:42 p.m., Samuraiii wrote:
> > On 24.8.2016 13:18, Antony Stone wrote:
> >> Unfortunately it's not Squid that's the challenge - it's the browser.
> >>
> >> If you're using Firefox and/or Chrome, you should be okay.
> >>
> >> See "Encrypted browser-Squid connection" at the bottom of
> >> http://wiki.squid-cache.org/Features/HTTPS
> >>
> >>
> >> Antony.
> >>
> > I have seen that, it is the cause of my subscription to this list.
> > I haven't been able to find any usable hints.
> > My config attempt fails
> >
>
> <snip>
> >
> > https_port 8443 \
> >     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
> >     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
> >     cleintca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
> >     tls-dh=/etc/ssl/certs/dhparam.pem \
> >     sslproxy_options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
> >     cipher=HIGH
>
>
> As Dio mentioned the cleintca= (or rather clientca=) is for
> authenticating clients ceritficates. Don't use that unless you are
> requiring client certs in TLS.
>
> The rest of your config looks reasonable to me. I suspect you have found
> a bug introduced during all the SSL-Bump code changes. Please make a
> bugzilla report and include your exact Squid version (found with the
> 'squid -v' command), the https_port line(s) and the exact error message
> produced on startup.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 

--------

Diogenes S. de Jesus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/bce4c338/attachment.htm>

From splash at gmail.com  Wed Aug 24 14:39:51 2016
From: splash at gmail.com (Diogenes S. Jesus)
Date: Wed, 24 Aug 2016 16:39:51 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <CAD8MJvAKuZL3g5YiWfgOpKgPEyVOb9sO6r=MFoUNGwdoxBqN_A@mail.gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
 <4c3d3b78-a866-e096-9ddf-0211d2c67cb6@treenet.co.nz>
 <CAD8MJvAKuZL3g5YiWfgOpKgPEyVOb9sO6r=MFoUNGwdoxBqN_A@mail.gmail.com>
Message-ID: <CAD8MJvB3_0K-0bJET++8-kW=YGHCCHHc1YEHK+nobVehRe0d9Q@mail.gmail.com>

Oh, an a tiny little detail :)

# squid -v

Squid Cache: Version 4.0.13

Service Name: squid

configure options:  '--with-openssl' '--prefix=/usr' '--localstatedir=/var'
'--libexecdir=/lib/squid' '--datadir=/share/squid'
'--sysconfdir=/etc/squid' '--with-default-user=proxy'
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'


On Wed, Aug 24, 2016 at 4:37 PM, Diogenes S. Jesus <splash at gmail.com> wrote:

> This configuration here covers the use case described by the OP:
> https://gist.githubusercontent.com/splashx/758ff0c59ea291f32edafc516fdaad
> 73/raw/8050fa054821657812961050332b38a56e7e3e68/
>
> If everything works well, you'll notice you won't support HTTP proxy at
> all, but users can reach  both HTTP and HTTPS target websites via your
> HTTPS proxy.
>
> # netstat -nltp
>
> Active Internet connections (only servers)
>
> Proto Recv-Q Send-Q Local Address           Foreign Address         State
>       PID/Program name
>
> tcp        0      0 0.0.0.0:22              0.0.0.0:*
> LISTEN      32109/sshd
>
> tcp6       0      0 :::80                   :::*
> LISTEN      26627/apache2
>
> tcp6       0      0 :::3443                 :::*
> LISTEN      7303/(squid-1)
>
> tcp6       0      0 :::22                   :::*
> LISTEN      32109/sshd
>
>
> The user connects to the proxy ONLY via HTTPS Proxy on port 3443
>
> All traffic between the OP and the proxy is encrypted using TLS.
> A) If the user enters http://target.example.com, between the proxy and
> the target you'll see HTTP.
> B) If the user enters https://target.example.com, between the proxy and
> the target you'll see HTTPS.
>
> If you sniff the traffic between the client and the proxy, you'll see TLS.
>
> Tested with:
>
> $ /Applications/Firefox\ 2.app/Contents/MacOS/firefox -v
>
> Mozilla Firefox 48.0
>
> Firefox set up to use PAC: Preferences > Advanced > Network > Settings:
> "Automatic Proxy Configuration": http://squid.example.com/proxy.pac
>
> The downside here of course is the limited amount of clients supporting
> HTTPS Proxy settings.
>
> Dio
>
>
> On Wed, Aug 24, 2016 at 3:46 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> Just to rewind this conversation to the actual problem ...
>>
>> On 24/08/2016 11:42 p.m., Samuraiii wrote:
>> > On 24.8.2016 13:18, Antony Stone wrote:
>> >> Unfortunately it's not Squid that's the challenge - it's the browser.
>> >>
>> >> If you're using Firefox and/or Chrome, you should be okay.
>> >>
>> >> See "Encrypted browser-Squid connection" at the bottom of
>> >> http://wiki.squid-cache.org/Features/HTTPS
>> >>
>> >>
>> >> Antony.
>> >>
>> > I have seen that, it is the cause of my subscription to this list.
>> > I haven't been able to find any usable hints.
>> > My config attempt fails
>> >
>>
>> <snip>
>> >
>> > https_port 8443 \
>> >     cert=/etc/letsencrypt/live/sklad.duckdns.org/cert.pem \
>> >     key=/etc/letsencrypt/live/sklad.duckdns.org/key.pem \
>> >     cleintca=/etc/letsencrypt/live/sklad.duckdns.org/fullchain.pem \
>> >     tls-dh=/etc/ssl/certs/dhparam.pem \
>> >     sslproxy_options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE \
>> >     cipher=HIGH
>>
>>
>> As Dio mentioned the cleintca= (or rather clientca=) is for
>> authenticating clients ceritficates. Don't use that unless you are
>> requiring client certs in TLS.
>>
>> The rest of your config looks reasonable to me. I suspect you have found
>> a bug introduced during all the SSL-Bump code changes. Please make a
>> bugzilla report and include your exact Squid version (found with the
>> 'squid -v' command), the https_port line(s) and the exact error message
>> produced on startup.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
>
> --
>
> --------
>
> Diogenes S. de Jesus
>



-- 

--------

Diogenes S. de Jesus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/a98c0fb5/attachment.htm>

From rousskov at measurement-factory.com  Wed Aug 24 14:47:09 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 24 Aug 2016 08:47:09 -0600
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
Message-ID: <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>

On 08/24/2016 07:54 AM, Amos Jeffries wrote:
> on_unsupported_protocol will need patching to be applied when HTTP
> parser detects unsupported protocol on port 80 (or 3128).

on_unsupported_protocol determines (among other things) Squid behavior
when encountering a strange (i.e., probably non-HTTP) request at the
beginning of an accepted TCP connection (where Squid expects to see an
HTTP request). Thus, the existing implementation should cover non-HTTP
requests on port 80 (or 3128). If it does not, it is a bug. We should
polish the documentation to make this clear.


> AFAIK it is
> currently only done by SSL-Bump'ing code detecting non-TLS protocols on
> port 443.

Yes, the above use case is also covered by the existing implementation.

You might also be thinking about non-HTTP inside a bumped TLS tunnel.
IIRC, that is indeed not supported, but Factory is working on that.


HTH,

Alex.



From belle at bazuin.nl  Wed Aug 24 14:58:31 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 24 Aug 2016 16:58:31 +0200
Subject: [squid-users] ext_kerberos_ldap_group_acl problem ( 2 minor
	bugsmaybe )
In-Reply-To: <vmime.57bd9aeb.72ce.fa87a6d7dfd8a1b@ms249-lin-003.rotterdam.bazuin.nl>
References: <CAD8MJvC8ZDWpUVE6iSaKu6qvx-7-3+Vy_4_kSiGq0oubauEqkA@mail.gmail.com>
Message-ID: <vmime.57bdb617.37c8.575130a1134f9a07@ms249-lin-003.rotterdam.bazuin.nl>

Ok reply to myself so other users know this also.

?

if you create a user for the HTTP services and you dont use msktutil but like me samba-tool or something else. 

?

Read : 

http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos carefully. 

and the clue was this line for me.? 

?

Squid "login" to Windows Active Directory or Unix kdc as user <HTTP/<fqdn-squid>@DOMAIN.COM>. 

This requires Active Directory to have an attribute userPrincipalname set to <HTTP/<fqdn-squid>@DOMAIN.COM>

?for the associated acount. This is usaully done by using msktutil. 

?

But this is not done by samba-tools? 

?

samba-tool setup fro squid i used, was as followed. 

samba-tool user create squid1-service --description="Unprivileged user for SQUID1-Proxy Services" --random-password 

samba-tool user setexpiry squid1-service ?noexpiry

samba-tool spn add HTTP/proxy.internal.domain.tld squid1-service

?

?

Now this results in : 

My UPN was set to the username at internal.domain.tld ?( as it should ). 

My SPN was set to HTTP/proxyserver.internal.domain.tld at REALM ( as is should )? 

?

samba-tool spn list squid1-service 

squid1-service

User CN=squid1-service,OU=Service-Accounts,OU=XXXX,DC=XXXXX,DC=XXXX,DC=XX has the following servicePrincipalName:

???????? HTTP/proxy.internal.domain.tld

???????? HTTP/proxy.internal.domain.tld at YOUR.REALM.T

?

?

Now i changed my UPN from username at internal.domain.tld ?to the (SPN name)? ?HTTP/proxyserver.internal.domain.tld at REALM 

Solved my initial problem. 

This should be in my optionion be changed to search for the SPN in ext_kerberos_ldap_group.

?

Now i have LDAPS messages, see below, im adding the _ldaps SRV records now ,but i dont get why im getting : 

Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

?

Im already having : TLS_CACERT????? /etc/ssl/certs/ca-certificates.crt 

Which contains the needed certs.

?

Did i find 2 small bugs here? ?

Or is this a ?Debian? related thing? 

?

?

Debug output. 

/usr/lib/squid3/ext_kerberos_ldap_group_acl -g internet-mail at YOUR.REALM.TLD -D YOUR.REALM.TLD -N internet-mail at NTDOMAIN -s -i -d

kerberos_ldap_group.cc(278): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Starting version 1.3.1sq

support_group.cc(382): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Group list internet-mail at YOUR.REALM.TLD

support_group.cc(447): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Group internet-mail? Domain YOUR.REALM.TLD

support_netbios.cc(83): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: Netbios list internet-mail at NTDOMAIN

support_netbios.cc(156): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: Netbios name internet-mail? Domain NTDOMAIN

support_lserver.cc(82): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: ldap server list NULL

support_lserver.cc(86): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: No ldap servers defined.

testuser internet-mail

kerberos_ldap_group.cc(371): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: Got User: testuser set default domain: YOUR.REALM.TLD

kerberos_ldap_group.cc(376): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: Got User: testuser Domain: YOUR.REALM.TLD

support_member.cc(63): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: User domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(65): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Found group at domain internet-mail at YOUR.REALM.TLD

support_ldap.cc(898): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setup Kerberos credential cache

support_krb5.cc(127): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set credential cache to MEMORY:squid_ldap_6902

support_krb5.cc(138): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Get default keytab file name

support_krb5.cc(144): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Got default keytab file name /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(158): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Get principal name from keytab /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(169): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Found principal name: HTTP/proxy.internal.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Got principal name HTTP/proxy.internal.domain.tld at YOUR.REALM.TLD

support_krb5.cc(260): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Stored credentials

support_ldap.cc(927): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Initialise ldap connection

support_ldap.cc(931): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable SSL to ldap servers

support_ldap.cc(933): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Canonicalise ldap server name for domain YOUR.REALM.TLD

support_resolv.cc(289): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while resolving service record _ldaps._tcp.YOUR.REALM.TLD with res_search

support_resolv.cc(71): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: res_search: Unknown service record: _ldaps._tcp.YOUR.REALM.TLD

support_resolv.cc(379): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved SRV _ldap._tcp.YOUR.REALM.TLD record to samba-dc2.internal.domain.tld

support_resolv.cc(379): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved SRV _ldap._tcp.YOUR.REALM.TLD record to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 1 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 2 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 3 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 4 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 5 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 6 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(407): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Adding YOUR.REALM.TLD to list

support_resolv.cc(443): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Sorted ldap server names for domain YOUR.REALM.TLD:

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: samba-dc1.internal.domain.tld Port: 389 Priority: 0 Weight: 100

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: samba-dc2.internal.domain.tld Port: 389 Priority: 0 Weight: 100

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: YOUR.REALM.TLD Port: -1 Priority: -2 Weight: -2

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc1.internal.domain.tld:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc2.internal.domain.tld:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server YOUR.REALM.TLD:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(979): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Error during initialisation of ldap connection: No such file or directory

support_ldap.cc(1048): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Error during initialisation of ldap connection: No such file or directory

support_member.cc(76): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: User testuser is not member of group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(91): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Default domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(119): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Default group loop: group at domain internet-mail at YOUR.REALM.TLD

?

?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/1ceddf1c/attachment.htm>

From rousskov at measurement-factory.com  Wed Aug 24 15:02:27 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 24 Aug 2016 09:02:27 -0600
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <48301d22-f105-99f9-752b-14d673234c01@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241423.13198.Antony.Stone@squid.open.source.it>
 <853504cc-479e-6a4b-583c-b4a9d3dd0ff5@gmail.com>
 <201608241432.53118.Antony.Stone@squid.open.source.it>
 <48301d22-f105-99f9-752b-14d673234c01@gmail.com>
Message-ID: <b06473e2-adc0-3b5e-cefa-40f4f18d8306@measurement-factory.com>

On 08/24/2016 06:36 AM, Yuri Voinov wrote:
> 24.08.2016 18:32, Antony Stone ?????:
>> He wants to configure his browser to connect to the proxy over an SSL
>> connection, and then inside this secure connection send standard HTTP and
>> HTTPS requests

> Yeah, I get it. It seems to me, is absolutely crazy and insecure idea.

No, you do not get it. If you were getting it, you would not call it
"crazy" or "insecure". Please do not scare folks away from the
configuration that makes a lot of sense and is actually used in highly
secure environments.

If you would like to understand why this configuration makes sense,
please carefully study available documentation, resist the urge to post
one-sentence knee-jerk responses, and think about what gets encrypted
between the client and Squid (hint: There are two layers of encryption
in case of HTTPS) and between Squid and the server. If, after all that
effort, you still think that this is "crazy" or "insecure", then
consider carefully itemizing a few specific reasons behind that
[incorrect] conclusion so that others can correct your mistake.


Thank you,

Alex.

>> See "Encrypted browser-Squid connection" at the bottom of
>> http://wiki.squid-cache.org/Features/HTTPS


From stan.prescott at gmail.com  Wed Aug 24 16:35:03 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Wed, 24 Aug 2016 11:35:03 -0500
Subject: [squid-users] clarifying Features/SslPeekAndSplice on wiki +
	fake CONNECT
In-Reply-To: <293d7a76-cdcc-39d2-8481-f59d707454d5@measurement-factory.com>
References: <47ccce43-c8cd-38b5-7c66-02bb205e0c38@urlfilterdb.com>
 <ecafc136-b76f-48ed-d5e1-c7feb3a7ef69@measurement-factory.com>
 <5b4c46a0-ef29-fcdd-f21c-189dade5bf80@urlfilterdb.com>
 <edec5e99-7624-8380-f7f7-ef19ca02a37f@measurement-factory.com>
 <2f810dbd-a289-65ea-7793-7c17df49a66b@urlfilterdb.com>
 <b7ee6ff1-579d-dc3a-635a-b9ca582601ae@measurement-factory.com>
 <a91c6004-4705-a776-6b1c-6c0143dc7125@urlfilterdb.com>
 <cc4e3527-6cd4-a8c1-9f2f-928ff38a0a9d@measurement-factory.com>
 <3fc016b9-dd62-ef2c-da3f-56d54ecbb23a@urlfilterdb.com>
 <293d7a76-cdcc-39d2-8481-f59d707454d5@measurement-factory.com>
Message-ID: <CANLNtGTmyLRvbv6Dm_uLwim5g9dMXWK+RyNc-GC0Mec6FQ4kyg@mail.gmail.com>

I just read through the wiki being discussed. For the first time, I think I
finally understand, for the most part, what peek, splice and stare do. The
last time I read the wiki a few months ago, I gave up understanding those
because it was too confusing to me.

Thanks!

On Wed, Aug 24, 2016 at 9:28 AM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 08/24/2016 07:23 AM, Marcus Kool wrote:
> > I added an image in PNG format with data flow and events.
>
> And I added an XXX why that image might do more harm than good.
>
>
> > If you are interested I can send you the ODG file that was
> > used to generate the image.
>
> Please attach those image sources to the wiki page itself. I do not
> think I will have the time to fix it, but somebody else might.
>
>
> Thank you,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160824/39cedbe3/attachment.htm>

From omidkosari at yahoo.com  Wed Aug 24 18:24:08 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 24 Aug 2016 11:24:08 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
Message-ID: <1472063048224-4679147.post@n4.nabble.com>

Alex Rousskov wrote
> Thus, the existing implementation should cover non-HTTP
> requests on port 80 (or 3128). If it does not, it is a bug. We should
> polish the documentation to make this clear.

The problem is not squid itself . The problem is in some situations for
example DOS(with malformed requests) , infected clients sends lots of
requests to target server . The requests goes through squid tproxy so squid
will send back about 250 byte in reply to each request .

So i am looking for a way to just send tcp reset and not that 250 bytes .

HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Wed, 24 Aug 2016 14:11:35 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 5
X-Cache: MISS from cache1
X-Cache-Lookup: NONE from cache1:3128
Connection: close 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679147.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Wed Aug 24 19:43:18 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 24 Aug 2016 13:43:18 -0600
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1472063048224-4679147.post@n4.nabble.com>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
Message-ID: <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>

On 08/24/2016 12:24 PM, Omid Kosari wrote:
> Alex Rousskov wrote
>> Thus, the existing implementation should cover non-HTTP
>> requests on port 80 (or 3128). If it does not, it is a bug. We should
>> polish the documentation to make this clear.


> The problem is not squid itself . The problem is in some situations for
> example DOS(with malformed requests) , infected clients sends lots of
> requests to target server . The requests goes through squid tproxy so squid
> will send back about 250 byte in reply to each request .
> 
> So i am looking for a way to just send tcp reset and not that 250 bytes .


What you said is orthogonal to what I said. There are two parts of the
problem you are trying to solve:

1. Detect a non-HTTP request on port 80.
2. Reset the client connection when #1 happens.

The existing on_unsupported_protocol directive already supports #1 --
bugs notwithstanding, it can be used to generate an error response when
you want. It is also the default behavior.

Once that error response is generated, you want to convert it into a TCP
reset by denying that response _and_ using a matching "deny_info
TCP_RESET". That is part #2. I do not know why deny_info does not work
in your tests.


N.B. Since resetting non-HTTP connections is a common need, it may be
tempting to add a "terminate" action to the on_unsupported_protocol list
of supported actions. However, I am not sure that is a good idea because
resetting a connection is a common need in many contexts. Deny_info may
be a better (more general) solution.


HTH,

Alex.



From erdosain9 at gmail.com  Wed Aug 24 20:24:34 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 24 Aug 2016 13:24:34 -0700 (PDT)
Subject: [squid-users] Some delay pools questions
Message-ID: <1472070274479-4679149.post@n4.nabble.com>

Hi.
I have thought to have several delay pools but I doubt whether this is the
right way.
Eg.
I want to give to the "administration" 512kb in total, to be distributed
among 8 users.
Give the "video editing area" a total of 1000KB to divide among 8 users.
I want to limit the bandwidth dedicated to youtube for "administration" to
125kb and 512kb for "video editing area".
And this bandwidth dedicated to youtube, are taken from the respective
totals.
It's possible??

Another doubt. If I want to provide, for example. 512kb to three different
areas.

How would the syntax? Not to be shared, but each area has 512kb available.

It would be like this??

delay_pools 1
delay_class February 1
delay_parameters 1 512000/512000 64000/256000
delay_access 1 area1
delay_access 1 area2
delay_access 1 area3

In this way each area would 512kb ?? or they would be sharing ??

Thank you very much!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Some-delay-pools-questions-tp4679149.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From caoshichao at powercdn.com  Thu Aug 25 05:56:00 2016
From: caoshichao at powercdn.com (=?UTF-8?B?5pu55aOr6LaF?=)
Date: Thu, 25 Aug 2016 13:56:00 +0800 (GMT+08:00)
Subject: [squid-users] =?utf-8?q?smp_purge?=
Message-ID: <AO6AMwCoAZURdui4TBXuTqr9.1.1472104560540.Hmail.caoshichao@powercdn.com>

Hi How are you
        I don`t know squid use smp , multi cpu process purge cache, each process define cache_dir ,when purge cache Choose a different worker,Lead to clear the cache fails






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/c9df1859/attachment.htm>

From belle at bazuin.nl  Thu Aug 25 08:27:13 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 25 Aug 2016 10:27:13 +0200
Subject: [squid-users] ext_kerberos_ldap_group_acl problem
In-Reply-To: <vmime.57bdb617.37c8.575130a1134f9a07@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.57bd9aeb.72ce.fa87a6d7dfd8a1b@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57beabe1.6a01.3a47ad2737b8db71@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

?

I?ve added the needed upn, setup the _ldaps in the dns zones, thats ok now. 



The last part, here i need some help.

support_ldap.cc(942): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc1.internal.domain.tld:636

support_ldap.cc(786): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc2.internal.domain.tld:636

support_ldap.cc(786): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

?

I tried to set 

TLS_CACERTFILE in ldap.conf, didnt work, so dont know how to fix this or there to put these variables. 

?

I need a user to connect to the ldap. ?Hi have that one in place. 

I just can find how to put this in this line so i can test this out, but i can only authenticate if the TLS_CACERTFILE is set correctly. 

?

Any suggestions here? 

?

?

Greetz, 

?

Louis

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/14746114/attachment.htm>

From samurai.no.dojo at gmail.com  Thu Aug 25 09:17:41 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Thu, 25 Aug 2016 11:17:41 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <CAD8MJvB3_0K-0bJET++8-kW=YGHCCHHc1YEHK+nobVehRe0d9Q@mail.gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
 <4c3d3b78-a866-e096-9ddf-0211d2c67cb6@treenet.co.nz>
 <CAD8MJvAKuZL3g5YiWfgOpKgPEyVOb9sO6r=MFoUNGwdoxBqN_A@mail.gmail.com>
 <CAD8MJvB3_0K-0bJET++8-kW=YGHCCHHc1YEHK+nobVehRe0d9Q@mail.gmail.com>
Message-ID: <57BEB7B5.5080203@gmail.com>

On 24.8.2016 16:39, Diogenes S. Jesus wrote:
> Oh, an a tiny little detail :) 
>
> # squid -v
>
> Squid Cache: Version 4.0.13
>
> Service Name: squid
>
> configure options:  '--with-openssl' '--prefix=/usr'
> '--localstatedir=/var' '--libexecdir=/lib/squid'
> '--datadir=/share/squid' '--sysconfdir=/etc/squid'
> '--with-default-user=proxy' '--with-logdir=/var/log/squid'
> '--with-pidfile=/var/run/squid.pid'
>
>
Hi,
Thank you for your nice reply.
Is is possible to bend this config for squid 3.5.19?
My distro (Gentoo) doesn't offer v4 squid... Latest "testing" is 3.5.20.
I have no problem with compiling code,
the thing I am concerned of is maintaining system in as much effortless
way as possible,
that is why I want to avoid non-distro sw.

squid -v output is on the end of mail.
with thanks
S

squid -v
Squid Cache: Version 3.5.19
Service Name: squid
configure options:  '--prefix=/usr' '--build=x86_64-pc-linux-gnu'
'--host=x86_64-pc-linux-gnu' '--mandir=/usr/share/man'
'--infodir=/usr/share/info' '--datadir=/usr/share' '--sysconfdir=/etc'
'--localstatedir=/var/lib' '--disable-dependency-tracking'
'--disable-silent-rules' '--docdir=/usr/share/doc/squid-3.5.19'
'--htmldir=/usr/share/doc/squid-3.5.19/html' '--libdir=/usr/lib64'
'--sysconfdir=/etc/squid' '--libexecdir=/usr/libexec/squid'
'--localstatedir=/var' '--with-pidfile=/run/squid.pid'
'--datadir=/usr/share/squid' '--with-logdir=/var/log/squid'
'--with-default-user=squid' '--enable-removal-policies=lru,heap'
'--enable-storeio=aufs,diskd,rock,ufs' '--enable-disk-io'
'--enable-auth-basic=MSNT-multi-domain,NCSA,POP3,getpwnam,SMB,PAM'
'--enable-auth-digest=file' '--enable-auth-ntlm=smb_lm'
'--enable-auth-negotiate=none'
'--enable-external-acl-helpers=file_userip,session,unix_group,wbinfo_group'
'--enable-log-daemon-helpers' '--enable-url-rewrite-helpers'
'--enable-cache-digests' '--enable-delay-pools' '--enable-eui'
'--enable-icmp' '--enable-follow-x-forwarded-for' '--with-large-files'
'--disable-strict-error-checking' '--disable-arch-native'
'--with-ltdl-includedir=/usr/include' '--with-ltdl-libdir=/usr/lib64'
'--without-libcap' '--enable-ipv6' '--disable-snmp' '--with-openssl'
'--with-nettle' '--with-gnutls' '--disable-ssl-crtd' '--disable-ecap'
'--disable-esi' '--enable-htcp' '--enable-wccp' '--enable-wccpv2'
'--enable-linux-netfilter' '--without-mit-krb5' '--without-heimdal-krb5'
'build_alias=x86_64-pc-linux-gnu' 'host_alias=x86_64-pc-linux-gnu'
'CC=x86_64-pc-linux-gnu-gcc' 'CFLAGS=[too long...redacted]''
'LDFLAGS=-Wl,-O1 -Wl,--as-needed' 'CXXFLAGS=[too long...redacted]'
'PKG_CONFIG_PATH=/usr/lib64/pkgconfig'
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/41cbbff7/attachment.htm>

From splash at gmail.com  Thu Aug 25 11:24:43 2016
From: splash at gmail.com (Diogenes Jesus)
Date: Thu, 25 Aug 2016 13:24:43 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BEB7B5.5080203@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
 <4c3d3b78-a866-e096-9ddf-0211d2c67cb6@treenet.co.nz>
 <CAD8MJvAKuZL3g5YiWfgOpKgPEyVOb9sO6r=MFoUNGwdoxBqN_A@mail.gmail.com>
 <CAD8MJvB3_0K-0bJET++8-kW=YGHCCHHc1YEHK+nobVehRe0d9Q@mail.gmail.com>
 <57BEB7B5.5080203@gmail.com>
Message-ID: <65F82B28-F716-4BB7-9D47-B169AB983698@gmail.com>

Hi there.

The config should work - I noticed only that you're using "--with-gnutls", but that shouldn't be an issue. Try it out and let us know how that worked for you. 

Dio

Sent from my iPhone

> On Aug 25, 2016, at 11:17 AM, Samuraiii <samurai.no.dojo at gmail.com> wrote:
> 
>> On 24.8.2016 16:39, Diogenes S. Jesus wrote:
>> Oh, an a tiny little detail :) 
>> 
>> # squid -v
>> Squid Cache: Version 4.0.13
>> Service Name: squid
>> configure options:  '--with-openssl' '--prefix=/usr' '--localstatedir=/var' '--libexecdir=/lib/squid' '--datadir=/share/squid' '--sysconfdir=/etc/squid' '--with-default-user=proxy' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'
>> 
> Hi,
> Thank you for your nice reply.
> Is is possible to bend this config for squid 3.5.19?
> My distro (Gentoo) doesn't offer v4 squid... Latest "testing" is 3.5.20.
> I have no problem with compiling code, 
> the thing I am concerned of is maintaining system in as much effortless way as possible, 
> that is why I want to avoid non-distro sw.
> 
> squid -v output is on the end of mail.
> with thanks 
> S
> 
> squid -v
> Squid Cache: Version 3.5.19
> Service Name: squid
> configure options:  '--prefix=/usr' '--build=x86_64-pc-linux-gnu' '--host=x86_64-pc-linux-gnu' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--datadir=/usr/share' '--sysconfdir=/etc' '--localstatedir=/var/lib' '--disable-dependency-tracking' '--disable-silent-rules' '--docdir=/usr/share/doc/squid-3.5.19' '--htmldir=/usr/share/doc/squid-3.5.19/html' '--libdir=/usr/lib64' '--sysconfdir=/etc/squid' '--libexecdir=/usr/libexec/squid' '--localstatedir=/var' '--with-pidfile=/run/squid.pid' '--datadir=/usr/share/squid' '--with-logdir=/var/log/squid' '--with-default-user=squid' '--enable-removal-policies=lru,heap' '--enable-storeio=aufs,diskd,rock,ufs' '--enable-disk-io'       '--enable-auth-basic=MSNT-multi-domain,NCSA,POP3,getpwnam,SMB,PAM' '--enable-auth-digest=file' '--enable-auth-ntlm=smb_lm' '--enable-auth-negotiate=none' '--enable-external-acl-helpers=file_userip,session,unix_group,wbinfo_group' '--enable-log-daemon-helpers' '--enable-url-rewrite-helpers' '--enable-cache-digests' '--enable-delay-pools' '--enable-eui' '--enable-icmp' '--enable-follow-x-forwarded-for' '--with-large-files' '--disable-strict-error-checking' '--disable-arch-native' '--with-ltdl-includedir=/usr/include' '--with-ltdl-libdir=/usr/lib64' '--without-libcap' '--enable-ipv6' '--disable-snmp' '--with-openssl' '--with-nettle' '--with-gnutls' '--disable-ssl-crtd' '--disable-ecap' '--disable-esi' '--enable-htcp' '--enable-wccp' '--enable-wccpv2' '--enable-linux-netfilter' '--without-mit-krb5' '--without-heimdal-krb5' 'build_alias=x86_64-pc-linux-gnu' 'host_alias=x86_64-pc-linux-gnu' 'CC=x86_64-pc-linux-gnu-gcc' 'CFLAGS=[too long...redacted]'' 'LDFLAGS=-Wl,-O1 -Wl,--as-needed' 'CXXFLAGS=[too long...redacted]' 'PKG_CONFIG_PATH=/usr/lib64/pkgconfig'
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/a57f83db/attachment.htm>

From belle at bazuin.nl  Thu Aug 25 12:07:29 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 25 Aug 2016 14:07:29 +0200
Subject: [squid-users] few small typos on the manual 3.5
Message-ID: <vmime.57bedf81.7bf1.59fb56873edb911@ms249-lin-003.rotterdam.bazuin.nl>

http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_kerberos_ldap_group_acl.html

shows the following. 
-u Ldap-User
Username for LDAP server.

-u Ldap-Password
Password for LDAP server.

-u Ldap-URL
LDAP server URL in form ldap[s]://server:port

3 x -u  


While shows something different.  

/usr/lib/squid3/ext_kerberos_ldap_group_acl -h
Usage:
squid_kerb_ldap [-d] [-i] -g group list [-D domain] [-N netbios domain map] [-s] [-u ldap user] [-p ldap user password] [-l ldap url] [-b ldap bind path] [-a] [-m max depth] [-h]

-u ldap user
-p ldap user password
-l ldap url
-b ldap bind path


Greetz, 

Louis
 



From samurai.no.dojo at gmail.com  Thu Aug 25 13:24:18 2016
From: samurai.no.dojo at gmail.com (Samuraiii)
Date: Thu, 25 Aug 2016 15:24:18 +0200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <65F82B28-F716-4BB7-9D47-B169AB983698@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
 <4c3d3b78-a866-e096-9ddf-0211d2c67cb6@treenet.co.nz>
 <CAD8MJvAKuZL3g5YiWfgOpKgPEyVOb9sO6r=MFoUNGwdoxBqN_A@mail.gmail.com>
 <CAD8MJvB3_0K-0bJET++8-kW=YGHCCHHc1YEHK+nobVehRe0d9Q@mail.gmail.com>
 <57BEB7B5.5080203@gmail.com> <65F82B28-F716-4BB7-9D47-B169AB983698@gmail.com>
Message-ID: <57BEF182.7060202@gmail.com>

On 25.8.2016 13:24, Diogenes Jesus wrote:
> Hi there.
>
> The config should work - I noticed only that you're using
> "--with-gnutls", but that shouldn't be an issue. Try it out and let us
> know how that worked for you. 
>
> Dio
>
> Sent from my iPhone
>
Hello again,
still same error...
Comlete debug output of "squid -X" is here:
https://gist.github.com/samuraiii/839151ae083872d3fd2be650df004e0c

These flagsare from my distro, I cant influence it directly, only
through few "use flags", which represent some functionality I can trigger:

htcp ipv6 pam samba ssl wccp wccpv2 -caps -ecap -esi -ipf-transparent
-kerberos -kqueue -ldap -logrotate -mysql -nis -pf-transparent -postgres
-qos -radius -sasl -selinux -snmp -sqlite -ssl-crtd -test -tproxy

That which is prepended withc dash is diabled.
I append this just for reference, I do not see much of use in this for
non-gentooists.
S
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/46b6c67e/attachment.htm>

From belle at bazuin.nl  Thu Aug 25 13:38:06 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 25 Aug 2016 15:38:06 +0200
Subject: [squid-users] ext_kerberos_ldap_group_acl problem (Solved for
 me for now)
In-Reply-To: <vmime.57beabe1.6a01.3a47ad2737b8db71@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.57bdb617.37c8.575130a1134f9a07@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57bef4be.3047.776bbd3242521d9e@ms249-lin-003.rotterdam.bazuin.nl>

Ok, found it. 

?

So a resume for a squid 3.5.19 + samba 4.4.5, kerberos auth and kerberos groups on debian jessie. 

?

By default the package libsasl2-modules-gssapi-mit? was not installed. ?

So i installed it:? apt-get install libsasl2-modules-gssapi-mit

I always install with, --no-install-recommends, here i missed this package. 

?

After installing it works fine, at least, ..? 

?

This works : (SASL/GSSAPI over port 389) ?

/usr/lib/squid3/ext_kerberos_ldap_group_acl -g group-mail at REALM? -D REALM? -N group-mail at REALM 

?

But with ssl enabled.. 

SASL/GSSAPI over port 636 (ldaps)

/usr/lib/squid3/ext_kerberos_ldap_group_acl -g group-mail at REALM? -D REALM? -N group-mail at REALM ?s 

Or .. 

SASL/GSSAPI over port 636 (ldaps) without cert checks. ?

/usr/lib/squid3/ext_kerberos_ldap_group_acl -g group-mail at REALM? -D REALM? -N group-mail at REALM ?s ?a

?

And with also tried adding this to the /etc/default/squid 

TLS_CACERTFILE=/etc/ssl/certs/ca-certificates.crt

export TLS_CACERTFILE

?

And adding the _ldaps_._tcp records the samba4/bind_dlz dns didnt help. 

(samba-tool dns add ADDC.FQDN REALM _ldaps._tcp SRV ?'host.internal.domain.tld 636 0 100') 

?

The log part of the remaining errors. ?

But no need to fix this for me, im putting this here so people can find it as reference. 

?

DEBUG: Set SSL defaults

DEBUG: Disable server certificate check for ldap server.

ERROR: Error while setting start_tls for ldap server: Operations error

DEBUG: Bind to ldap server with SASL/GSSAPI

ERROR: ldap_sasl_interactive_bind_s error: Strong(er) authentication required

ERROR: Error while binding to ldap server with SASL/GSSAPI: Strong(er) authentication required

DEBUG: Setting up connection to ldap server hostname.internal.domain.tld:636

DEBUG: Set SSL defaults

DEBUG: Disable server certificate check for ldap server.

ERROR: Error while setting start_tls for ldap server: Operations error

DEBUG: Bind to ldap server with SASL/GSSAPI

ERROR: ldap_sasl_interactive_bind_s error: Strong(er) authentication required

?

And if someone find the solution for this above, that would be nice to report here. 

?

?

Greetz, 

?

Louis

?

?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/4e60fa0b/attachment.htm>

From rousskov at measurement-factory.com  Thu Aug 25 14:42:44 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 25 Aug 2016 08:42:44 -0600
Subject: [squid-users] smp purge
In-Reply-To: <AO6AMwCoAZURdui4TBXuTqr9.1.1472104560540.Hmail.caoshichao@powercdn.com>
References: <AO6AMwCoAZURdui4TBXuTqr9.1.1472104560540.Hmail.caoshichao@powercdn.com>
Message-ID: <158757ff-5039-0ebf-7f04-b4f97c58bbe9@measurement-factory.com>

On 08/24/2016 11:56 PM, ??? wrote:

>         I don`t know squid use smp , multi cpu process purge cache, each
> process define cache_dir ,when purge cache Choose a different
> worker,Lead to clear the cache fails

Hello,

    Due to the language barrier, I am not sure what question you are
asking,  but I hope that the following facts give you enough information
to find the right answer:

The two SMP-aware caches are rock cache_dir and shared memory cache. All
ufs-based cache_dirs and local memory cache are SMP-unaware. Shared
memory caching is enabled by default when you use multiple workers.

SMP caching is supported only when all your caches are SMP-aware. With
SMP-aware caches all Squid workers should share the same set of caches.

If you do not use SMP-aware caches, use a mixture of SMP-aware and
SMP-unaware caches, or give different workers a different set of
SMP-aware caches, then many caching-related things will fail to work in
SMP mode (often without warnings or error messages). I am ignoring all
those problematic cases in the text below!

When receiving a DELETE transaction or otherwise purging a cached
response, Squid must delete all copies of that response from all caches.
This protocol requirement applies to SMP and non-SMP Squid alike, of course.

There is a known Squid bug that leads to some copies of a being-purged
response not deleted in SMP Squids. Factory is working on a patch to fix
that protocol violation (with the exception of one corner case that goes
beyond purging itself). Our fix is almost ready, and I hope to see the
corresponding patch posted to squid-dev soon.


HTH,

Alex.



From skupko.sk at gmail.com  Thu Aug 25 14:58:19 2016
From: skupko.sk at gmail.com (Peter Viskup)
Date: Thu, 25 Aug 2016 16:58:19 +0200
Subject: [squid-users] Meaning of "HTTP I/O number of reads"
Message-ID: <CAPa6PsELX-R_vsR2NLTbQkMSsDHPz-CX5_5mqHFrRFFKtzNDjg@mail.gmail.com>

Hello all,
we do experience some connection issues with SFTP and clear HTTP
clients on Squid 3.4 version built with SSL split.
We occasionally see ERR_CONNECT_FAIL with SYSERR=110.

Just discovered higher value of "HTTP I/O number of reads" at the time
the issue occur.
I am not able to understand this value - what it points to. Sometimes
the value of HTTP I/O number of reads jump from tenths to 6000 or even
higher.

Peter


From michael.pelletier at palmbeachschools.org  Thu Aug 25 15:27:15 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Thu, 25 Aug 2016 11:27:15 -0400
Subject: [squid-users] How to log ACL to custom log
Message-ID: <CAEnCSG6y2cZ7t7xmPpO5QGn0Y=eKi0w+1_WWPhUBUD4=xQMYPQ@mail.gmail.com>

Hello,
I would like to log ACLs Pass \ Blocks in the access.log. I am using
Logstash for a monitoring system and being able to pass this information
allows me to do some nice graphing.

Does any know how this can be done?

Michael

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/2682e1fd/attachment.htm>

From squid3 at treenet.co.nz  Thu Aug 25 15:43:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 26 Aug 2016 03:43:49 +1200
Subject: [squid-users] Https_port with "official" certificate
In-Reply-To: <57BEF182.7060202@gmail.com>
References: <57BD8080.7090808@gmail.com>
 <201608241318.30521.Antony.Stone@squid.open.source.it>
 <57BD8818.3040801@gmail.com>
 <4c3d3b78-a866-e096-9ddf-0211d2c67cb6@treenet.co.nz>
 <CAD8MJvAKuZL3g5YiWfgOpKgPEyVOb9sO6r=MFoUNGwdoxBqN_A@mail.gmail.com>
 <CAD8MJvB3_0K-0bJET++8-kW=YGHCCHHc1YEHK+nobVehRe0d9Q@mail.gmail.com>
 <57BEB7B5.5080203@gmail.com> <65F82B28-F716-4BB7-9D47-B169AB983698@gmail.com>
 <57BEF182.7060202@gmail.com>
Message-ID: <fc4ff01a-6ea6-a35e-416e-a94f1fb7dcce@treenet.co.nz>

On 26/08/2016 1:24 a.m., Samuraiii wrote:
> On 25.8.2016 13:24, Diogenes Jesus wrote:
>> Hi there.
>>
>> The config should work - I noticed only that you're using
>> "--with-gnutls", but that shouldn't be an issue. Try it out and let us
>> know how that worked for you. 
>>
>> Dio
>>
>> Sent from my iPhone
>>
> Hello again,
> still same error...
> Comlete debug output of "squid -X" is here:
> https://gist.github.com/samuraiii/839151ae083872d3fd2be650df004e0c
> 
> These flagsare from my distro, I cant influence it directly, only
> through few "use flags", which represent some functionality I can trigger:
> 
> htcp ipv6 pam samba ssl wccp wccpv2 -caps -ecap -esi -ipf-transparent
> -kerberos -kqueue -ldap -logrotate -mysql -nis -pf-transparent -postgres
> -qos -radius -sasl -selinux -snmp -sqlite -ssl-crtd -test -tproxy
> 
> That which is prepended withc dash is diabled.
> I append this just for reference, I do not see much of use in this for
> non-gentooists.

Like I said the other day, please open a bug report with the details. I
don't have the time to look into it and the dev who might be interested
don't follow this list closely.

Amos



From squid3 at treenet.co.nz  Thu Aug 25 16:06:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 26 Aug 2016 04:06:00 +1200
Subject: [squid-users] Meaning of "HTTP I/O number of reads"
In-Reply-To: <CAPa6PsELX-R_vsR2NLTbQkMSsDHPz-CX5_5mqHFrRFFKtzNDjg@mail.gmail.com>
References: <CAPa6PsELX-R_vsR2NLTbQkMSsDHPz-CX5_5mqHFrRFFKtzNDjg@mail.gmail.com>
Message-ID: <1da1f206-1fa6-9104-c376-524458554507@treenet.co.nz>

On 26/08/2016 2:58 a.m., Peter Viskup wrote:
> Hello all,
> we do experience some connection issues with SFTP and clear HTTP
> clients on Squid 3.4 version built with SSL split.

What is this "SSL split" you speak of?

Squid does not support SFTP as far as I am aware except by CONNECT
tunnelling done by the client. Which is difficult since (S)FTP has
several TCP connections going in different directions at once.

> We occasionally see ERR_CONNECT_FAIL with SYSERR=110.

TCP connection setup failed. Whatever your operating system means by the
"110" message is the reason why.

> 
> Just discovered higher value of "HTTP I/O number of reads" at the time
> the issue occur.

If you mean the SNMP  OID *.1.3.1.2.0 (aka cacheSysNumReads). Which is
described as "HTTP I/O number of reads".

It is the counter of how many system read(2) I/O operations that have
been done for HTTP traffic. Being a counter, it will only ever go up.

> I am not able to understand this value - what it points to. Sometimes
> the value of HTTP I/O number of reads jump from tenths to 6000 or even
> higher.
> 


Since you imply that you are proxying CONNECT tunnels containing entire
SFTP transactions. It would be reasonable to expect a lot of read
operations to happen for them. Both the 'S' and the 'FTP' layers each
have a lot of small messages going back and forth through the tunnel.


You might also be having bug 2907. Which is fixed in Squid-3.5. Please
try an upgrade.

Amos



From rousskov at measurement-factory.com  Thu Aug 25 16:06:11 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 25 Aug 2016 10:06:11 -0600
Subject: [squid-users] How to log ACL to custom log
In-Reply-To: <CAEnCSG6y2cZ7t7xmPpO5QGn0Y=eKi0w+1_WWPhUBUD4=xQMYPQ@mail.gmail.com>
References: <CAEnCSG6y2cZ7t7xmPpO5QGn0Y=eKi0w+1_WWPhUBUD4=xQMYPQ@mail.gmail.com>
Message-ID: <5c17c0e0-6e8f-9e6b-7630-7a6e077ae79c@measurement-factory.com>

On 08/25/2016 09:27 AM, Michael Pelletier wrote:

> I would like to log ACLs Pass \ Blocks in the access.log. 

If you want to log the name of the ACL that resulted in an http_access
allow or deny decision, then there is only poor/indirect support for
that right now AFAIK: You can kind of do that via an annotation-setting
external ACL at the end of each http_access rule, but that is not a good
solution for many reasons.

The upcoming annotate_transaction ACLs will help with that, but even
they are not a good solution if you have many http_access rules.

Squid already has a concept of a "blocking ACL name" because deny_info
needs that. The underlying implementation is extremely kludgey and not
reliable. We should support this better and make the blocking ACL name
available via a new logformat code, at least. I do not think this would
be very difficult to implement, but decent knowledge of ACL code may be
required to replace the kludge mentioned above.


HTH,

Alex.



From squid3 at treenet.co.nz  Thu Aug 25 16:12:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 26 Aug 2016 04:12:23 +1200
Subject: [squid-users] How to log ACL to custom log
In-Reply-To: <CAEnCSG6y2cZ7t7xmPpO5QGn0Y=eKi0w+1_WWPhUBUD4=xQMYPQ@mail.gmail.com>
References: <CAEnCSG6y2cZ7t7xmPpO5QGn0Y=eKi0w+1_WWPhUBUD4=xQMYPQ@mail.gmail.com>
Message-ID: <b2629a4d-d740-8384-5c5f-502f1e58eeb6@treenet.co.nz>

On 26/08/2016 3:27 a.m., Michael Pelletier wrote:
> Hello,
> I would like to log ACLs Pass \ Blocks in the access.log. I am using
> Logstash for a monitoring system and being able to pass this information
> allows me to do some nice graphing.
> 
> Does any know how this can be done?

Besides what Alex has already said. Consider this: The decision of which
access.log to write to is ACL driven. Deciding it alters the ACLs which
have been checked and passed/failed.

Also;
 access.log logs *network transactions*.

 cache.log logs *squid activity*.

ACL logic processing is a Squid activity, not a network transaction.
Thus logged in cache.log - with the appropriate debug section and
verbosity level you can find ACL processing decisions in that log.

Amos



From steve at opendium.com  Thu Aug 25 16:17:46 2016
From: steve at opendium.com (Steve Hill)
Date: Thu, 25 Aug 2016 17:17:46 +0100
Subject: [squid-users] More host header forgery pain with peek/splice
Message-ID: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>


This one just seems to keep coming up and I'm wondering how other people 
are dealing with it:

When you peek and splice a transparently proxied connection, the SNI 
goes through the host validation phase.  Squid does a DNS lookup for the 
SNI, and if it doesn't resolve to the IP address that the client is 
connecting to, Squid drops the connection.

When accessing one of the increasingly common websites that use DNS load 
balancing, since the DNS results change on each lookup, Squid and the 
client may not get the same DNS results, so Squid drops perfectly good 
connections.

Most of this problem goes away if you ensure all the clients use the 
same DNS server as squid, but not quite.  Because the TTL on DNS records 
only has a resolution of 1 second, there is a period of up to 1 second 
when the DNS records Squid knows about doesn't match the ones that the 
client knows about.  The client and squid may expire the records up to 1 
second apart.

So what's the solution?  (Notably the validation check can't be disabled 
without hacking the code).

-- 
  - Steve Hill
    Technical Director
    Opendium    Online Safety / Web Filtering    http://www.opendium.com

    Enquiries                 Support
    ---------                 -------
    sales at opendium.com        support at opendium.com
    +44-1792-824568           +44-1792-825748


From erdosain9 at gmail.com  Thu Aug 25 18:31:45 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 25 Aug 2016 11:31:45 -0700 (PDT)
Subject: [squid-users] Strange log https problem??
Message-ID: <1472149905612-4679179.post@n4.nabble.com>

Hi im doing bump.
all is working fine except that i have this error in log

49484.020      0 192.168.1.17 NONE/200 0 CONNECT www.facebook.com:443 -
HIER_NONE/- -
1472149484.225   1644 192.168.1.2 TCP_MISS/200 1493 POST
https://outlook.live.com/owa/ev.owa2? - HIER_DIRECT/132.245.61.50
application/json
1472149484.485   4407 192.168.1.17 TCP_MISS/200 392 POST
https://0-edge-chat.facebook.com/sub? - HIER_DIRECT/157.240.0.17
application/json
1472149485.489   1465 192.168.1.17 TCP_MISS/200 31281 GET
https://www.facebook.com/ajax/pagelet/generic.php/LitestandTailLoadPagelet?
- HIER_DIRECT/157.240.0.35 text/html
1472149486.360      0 192.168.1.17 NONE/200 0 CONNECT
fb-s-d-a.akamaihd.net:443 - HIER_NONE/- -
1472149486.403      0 192.168.1.17 NONE/200 0 CONNECT
fbcdn-photos-a-a.akamaihd.net:443 - HIER_NONE/- -
1472149486.511   2012 192.168.1.17 TCP_MISS/200 392 POST
https://0-edge-chat.facebook.com/sub? - HIER_DIRECT/157.240.0.17
application/json
1472149486.512    193 192.168.1.17 TCP_MISS/200 1470 GET
https://fbcdn-profile-a.akamaihd.net/hprofile-ak-xta1/v/t1.0-1/p32x32/13331122_632799513554063_5285269617903617538_n.jpg?
- HIER_DIRECT/204.2.179.19 image/jpeg
1472149486.558      0 192.168.1.17 NONE/200 0 CONNECT
fbcdn-photos-b-a.akamaihd.net:443 - HIER_NONE/- -

This is my config

# Squid listen Port
http_port 192.168.1.97:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem

acl excluidosSSL dstdomain "/etc/squid/listas/excluidosSSL.lst"
ssl_bump none excluidosSSL
ssl_bump client-first all

#always_direct allow all
ssl_bump server-first all
sslproxy_cert_error  allow all
sslproxy_flags DONT_VERIFY_PEER

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1

#############################################




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Strange-log-https-problem-tp4679179.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Aug 25 18:35:25 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 00:35:25 +0600
Subject: [squid-users] Strange log https problem??
In-Reply-To: <1472149905612-4679179.post@n4.nabble.com>
References: <1472149905612-4679179.post@n4.nabble.com>
Message-ID: <93612d4d-da1b-8685-6516-ca61af371c39@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
What is you threat as error?


26.08.2016 0:31, erdosain9 ?????:
> Hi im doing bump.
> all is working fine except that i have this error in log
>
> 49484.020      0 192.168.1.17 NONE/200 0 CONNECT www.facebook.com:443 -
> HIER_NONE/- -
> 1472149484.225   1644 192.168.1.2 TCP_MISS/200 1493 POST
> https://outlook.live.com/owa/ev.owa2? - HIER_DIRECT/132.245.61.50
> application/json
> 1472149484.485   4407 192.168.1.17 TCP_MISS/200 392 POST
> https://0-edge-chat.facebook.com/sub? - HIER_DIRECT/157.240.0.17
> application/json
> 1472149485.489   1465 192.168.1.17 TCP_MISS/200 31281 GET
>
https://www.facebook.com/ajax/pagelet/generic.php/LitestandTailLoadPagelet?
> - HIER_DIRECT/157.240.0.35 text/html
> 1472149486.360      0 192.168.1.17 NONE/200 0 CONNECT
> fb-s-d-a.akamaihd.net:443 - HIER_NONE/- -
> 1472149486.403      0 192.168.1.17 NONE/200 0 CONNECT
> fbcdn-photos-a-a.akamaihd.net:443 - HIER_NONE/- -
> 1472149486.511   2012 192.168.1.17 TCP_MISS/200 392 POST
> https://0-edge-chat.facebook.com/sub? - HIER_DIRECT/157.240.0.17
> application/json
> 1472149486.512    193 192.168.1.17 TCP_MISS/200 1470 GET
>
https://fbcdn-profile-a.akamaihd.net/hprofile-ak-xta1/v/t1.0-1/p32x32/13331122_632799513554063_5285269617903617538_n.jpg?
> - HIER_DIRECT/204.2.179.19 image/jpeg
> 1472149486.558      0 192.168.1.17 NONE/200 0 CONNECT
> fbcdn-photos-b-a.akamaihd.net:443 - HIER_NONE/- -
>
> This is my config
>
> # Squid listen Port
> http_port 192.168.1.97:3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
> key=/etc/squid/ssl_cert/myca.pem
>
> acl excluidosSSL dstdomain "/etc/squid/listas/excluidosSSL.lst"
> ssl_bump none excluidosSSL
> ssl_bump client-first all
>
> #always_direct allow all
> ssl_bump server-first all
> sslproxy_cert_error  allow all
> sslproxy_flags DONT_VERIFY_PEER
>
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
>
> #############################################
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Strange-log-https-problem-tp4679179.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvzptAAoJENNXIZxhPexGBLIH/i4WoYkoiBoKT474AkcluDxi
fIq7J2Ik/CW3zFKHOEYvbwkIlQKJ5N5LXkApYTwNZe25RKvPSPPHX4cB7cPGHNgp
az2fcmnIz53NFFJHewJtQL57NCxRSNXC9L3p5XabDcr83+slB7kAn3CVE9vCBSv1
JLEoRqZFvPj2DPZtVy1HnWGLUWWVUyiuRL9VUIekwvOXCYROby6btcCbFYNadEuf
tYwb4/uUMqJVlA/QzBaUOFiW4zK+bmCoiGFChMWy6mw3Gww4kkV7PTgu6z1pAYZj
NrBpmXe8INaIue0siwXMDt1OjDRlLFADJXpm7g3ooRCl/tUgJyU4SDDZcDSn/kk=
=n0FO
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/3706a59e/attachment.key>

From augustus_meyer at gmx.net  Thu Aug 25 18:34:35 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Thu, 25 Aug 2016 11:34:35 -0700 (PDT)
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
Message-ID: <1472150075016-4679181.post@n4.nabble.com>

Hack the code. Because it is even worse, as firefox for example does not obey
to the TTL. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/More-host-header-forgery-pain-with-peek-splice-tp4679178p4679181.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu Aug 25 18:39:09 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 25 Aug 2016 11:39:09 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
Message-ID: <1472150349506-4679182.post@n4.nabble.com>

Hi.
i have ssl-bump enable...

#############################################
# Squid listen Port
http_port 192.168.1.97:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem

acl excluidosSSL dstdomain "/etc/squid/listas/excluidosSSL.lst"
ssl_bump none excluidosSSL
ssl_bump client-first all

#always_direct allow all
ssl_bump server-first all
sslproxy_cert_error  allow all
sslproxy_flags DONT_VERIFY_PEER

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1

#############################################

What kind of acl i should do...?? pointing to...??
Thanks!!!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Aug 25 18:42:10 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 00:42:10 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472150349506-4679182.post@n4.nabble.com>
References: <1472150349506-4679182.post@n4.nabble.com>
Message-ID: <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


26.08.2016 0:39, erdosain9 ?????:
> Hi.
> i have ssl-bump enable...
>
> #############################################
> # Squid listen Port
> http_port 192.168.1.97:3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
> key=/etc/squid/ssl_cert/myca.pem
>
> acl excluidosSSL dstdomain "/etc/squid/listas/excluidosSSL.lst"
> ssl_bump none excluidosSSL
> ssl_bump client-first all
>
> #always_direct allow all
> ssl_bump server-first all
> sslproxy_cert_error  allow all
> sslproxy_flags DONT_VERIFY_PEER
>
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
>
> #############################################
>
> What kind of acl i should do...?? pointing to...??
Delay pool pointing to googlevideo.com.
>
> Thanks!!!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXvzwCAAoJENNXIZxhPexGLBgH/iNu8RK6TvqMNjbuhlFH+XEb
4CVdUo86jwv2SZ+uOP2e+75RbIxbCvPKETLKYy20kemtFPhf9VYrnXdbUPcA6mCB
sSHZFLC8sSelvWVDxvUhbhQRNydlPFGuVEU/IT92rJQPJ5oFzkjBwGfV8kbG4wr2
abhdpXHFdpysFq8T9i2FyB6eR0skbh00DbZMa2QF3Xztu3Fdb9tYoznEjQHdV44x
2HQrnBy2v8N+dGWRscnTxXXqdJHIZLc1OT+Ay7VfFZr3vfpey8YPQJhi0XXdprau
LkziXr7dWWXTzkB5qsvP/5PM4v8D7rVouOE/FSX//6JNRZVCXwSldmbbIncF30U=
=/l0O
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/e70b9e4c/attachment.key>

From erdosain9 at gmail.com  Thu Aug 25 18:58:56 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 25 Aug 2016 11:58:56 -0700 (PDT)
Subject: [squid-users] Block access to a ip (external)
Message-ID: <1472151536705-4679184.post@n4.nabble.com>

Hi.
I have too much traffic to this ip 190.61.17.9.... i really dont know what
it is... so i want to block that ip. 
How i can do this?
Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Block-access-to-a-ip-external-tp4679184.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Aug 25 19:03:52 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 01:03:52 +0600
Subject: [squid-users] Block access to a ip (external)
In-Reply-To: <1472151536705-4679184.post@n4.nabble.com>
References: <1472151536705-4679184.post@n4.nabble.com>
Message-ID: <90ebfa12-8e7d-6e26-1c8f-ecad2642604f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
With router or L3 switch.


26.08.2016 0:58, erdosain9 ?????:
> Hi.
> I have too much traffic to this ip 190.61.17.9.... i really dont know what
> it is... so i want to block that ip.
> How i can do this?
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Block-access-to-a-ip-external-tp4679184.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXv0EYAAoJENNXIZxhPexG83QIAJEIdIk0ckn1CgxSXoR8CnIN
KI3XIiKBdnvhKaxTDomDhLB9M93od0tiOye/vyZ/rgAeiWuY2OXkk97LOCKcDRNW
IXf6znaDO3DMJZAsQIAk96u3RhyKfAyl0PKaMq33jd6uKViV5MGjHRLtiyWUpriN
k2SG9bEvI4miqUzMZjI7c5LcvgYKrs8db83kTU0rbIdjt4PJx8WD2HmW7wFaVS0N
+WD6Xa64ZFnmf98KTXVBJ257h6u8NO3SjFjtxEzaOGtHxvVUYxoAeISaMQtl0JcG
XmOVptoIMIRacwIbVNDa06sr8MR98dKFNZelNCWZw2p8LLaeGLWERwEX9Pc5N4Q=
=ffOL
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/d9305228/attachment.key>

From ahmed.zaeem at netstream.ps  Thu Aug 25 19:05:46 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Thu, 25 Aug 2016 22:05:46 +0300
Subject: [squid-users] squid  user session/connections  control
Message-ID: <C375DBF1-3D2B-467F-AA80-56C9C799CE96@netstream.ps>

Hi dear ?squid users ?

i have a question in mind on how can i limit connections for a user that is connected using AUTH_NTLM method 
i already added the directives below :

as example  , user will connect to squid and have only 50 max connections .



my config are below :

##########################################
acl vvv maxconn 100

http_access deny vvv all

auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
acl ncsa_users proxy_auth REQUIRED
http_access allow ncsa_users
#################################

im not sure how can i limit the connections per user connection not per ip 




hope to help 

I?m using squid 3.5.2


kind regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/a285522b/attachment.htm>

From yvoinov at gmail.com  Thu Aug 25 19:09:12 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 01:09:12 +0600
Subject: [squid-users] Block access to a ip (external)
In-Reply-To: <1472151536705-4679184.post@n4.nabble.com>
References: <1472151536705-4679184.post@n4.nabble.com>
Message-ID: <49ddfd82-8b3b-81f2-e0b2-35d01b9384ea@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Feel free to check yoursuspicious IP:

http://www.tcpiputils.com/browse/ip-address/190.61.17.9

As you can see, this is Akamai. So, this can be (most probably)
perfectly legitimate traffic.

So, don't panic.


26.08.2016 0:58, erdosain9 ?????:
> Hi.
> I have too much traffic to this ip 190.61.17.9.... i really dont know what
> it is... so i want to block that ip.
> How i can do this?
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Block-access-to-a-ip-external-tp4679184.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXv0JYAAoJENNXIZxhPexGy0IH/imZSDl7SFHJteygzk0Od1b2
c4UeW5AsifHGwVTB73UOGLSGWcD0zSNA9n98orbNizPXaAwzPJZkQ8jrZeMNhfRP
AbaYF9mQpL++tNjz/5tk3EBEFRsCB3JpUAiz3wPT44Sq/AJChgxTez56pCBj9/i2
4DLI/Orn5S39Dimc8yR7EhK59Pb6Cg+jtK1KBrVhx2ChssThWTOVDD5EvLeXAmAf
+M9fimvlIwAjWDNeZaCHbPISj8Y7TW23Wc+FN0EyMatDQTAzI0LhydfYYOHAREpC
Ta+6Grw+wXilGjrxbhGP9JrCUBloEEYuui8JQyD6elnxUIInqzMXe40FwNkisIA=
=9khl
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/c1ad28e8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/c1ad28e8/attachment.key>

From yvoinov at gmail.com  Thu Aug 25 19:09:23 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 01:09:23 +0600
Subject: [squid-users] Block access to a ip (external)
In-Reply-To: <1472151536705-4679184.post@n4.nabble.com>
References: <1472151536705-4679184.post@n4.nabble.com>
Message-ID: <9fd67911-0a71-f88d-8780-ee4c020e1a46@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Feel free to check yoursuspicious IP:

http://www.tcpiputils.com/browse/ip-address/190.61.17.9

As you can see, this is Akamai. So, this can be (most probably)
perfectly legitimate traffic.

So, don't panic.


26.08.2016 0:58, erdosain9 ?????:
> Hi.
> I have too much traffic to this ip 190.61.17.9.... i really dont know what
> it is... so i want to block that ip.
> How i can do this?
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Block-access-to-a-ip-external-tp4679184.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXv0JjAAoJENNXIZxhPexGcWEH/39zcJqyZmZ/frU80oWY3DPc
wrvSlVcv5JVTK7LPZsmSGdnF+2kM5ChntITY/Qm9DB+ElqjmwO73JF/VgotrmBnH
DbvB7Fzg567g6bXbyo/WvofMdzSPizjdCx15xPbFC7zJ3IfzZ333d0I69MyRFDxF
1TF5iR97QqNa1X0UixvqwZpPALvE01WWhTmdcnbAmX+gdzOkBLped9LTc2lpvOyo
Rq+ssOKRQp24MRbkFRFuxOYEFB7h43/1QOJbjkPCtNf0cNYQzhpGf0ELF2nij15m
M3VEIwtRHcWinaij7RR/wJUFm0LDbKWJYu2VeXwkFVApuvfbya+rxxalngfL34I=
=C6On
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/0afb5e28/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/0afb5e28/attachment.key>

From yvoinov at gmail.com  Thu Aug 25 19:09:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 01:09:32 +0600
Subject: [squid-users] Block access to a ip (external)
In-Reply-To: <1472151536705-4679184.post@n4.nabble.com>
References: <1472151536705-4679184.post@n4.nabble.com>
Message-ID: <ae199a31-8b85-19b5-7533-64b69c85846d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Feel free to check your    suspicious IP:

http://www.tcpiputils.com/browse/ip-address/190.61.17.9

As you can see, this is Akamai. So, this can be (most probably)
perfectly legitimate traffic.

So, don't panic.


26.08.2016 0:58, erdosain9 ?????:
> Hi.
> I have too much traffic to this ip 190.61.17.9.... i really dont know what
> it is... so i want to block that ip.
> How i can do this?
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Block-access-to-a-ip-external-tp4679184.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXv0JrAAoJENNXIZxhPexGlrIH/ix4Mn5zzvlG51J/gIQnNB0h
JZrdN/iDE1a5+rKlYHLUIIEM9wo3JeOFowZLZu1nlrqf+z7uShGgTvBOoeG6EzVE
l8LgQr+SGehyKGa23VB4H3fPbwezhtlnH48I9N/j64fHX/4jTs8x5UYDkM2u89Lu
IsV1ZGqH/6wyT3riq/p7u5RPtLLaaRtDNENhs+prAmf1YIJytVj5xQ3grtDUz/0J
/BHhCmzwC2ld+r+dLY9jNdb9oMHg0POqoUhHtIRQZtlGktIQmsTWkoDI1AWNfimn
uId8WjzfGEBzhkdDpFJVPfV7+qYmlCVAy+rHFnkGyqzcwVmdH9S5nN6gSPClW6U=
=e6SO
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/d06b3845/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/d06b3845/attachment.key>

From yvoinov at gmail.com  Thu Aug 25 19:11:46 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 01:11:46 +0600
Subject: [squid-users] Block access to a ip (external)
In-Reply-To: <1472151536705-4679184.post@n4.nabble.com>
References: <1472151536705-4679184.post@n4.nabble.com>
Message-ID: <06ab5772-4774-ced2-ceab-5c6a4d062bdc@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Traceroute confirm this:

root @ khorne / # traceroute 190.61.17.9
traceroute to 190.61.17.9 (190.61.17.9), 30 hops max, 40 byte packets
 1  192.168.201.1 (192.168.201.1)  0.978 ms  0.798 ms  0.755 ms
 2  178.88.163.97 (178.88.163.97)  24.230 ms  22.326 ms  23.565 ms
 3  10.244.3.163 (10.244.3.163)  19.175 ms  20.637 ms  21.153 ms
 4  82.200.244.254 (82.200.244.254)  20.186 ms  21.437 ms  20.149 ms
 5  95.59.170.132 (95.59.170.132)  36.467 ms  34.081 ms 92.47.145.100
(92.47.145.100)  36.128 ms
 6  95.59.172.9 (95.59.172.9)  58.821 ms 95.59.172.46 (95.59.172.46) 
34.089 ms 95.59.172.9 (95.59.172.9)  34.488 ms
 7  95.59.172.35 (95.59.172.35)  33.117 ms  72.374 ms  34.162 ms
 8  217.150.44.146 (217.150.44.146)  49.700 ms  49.871 ms  54.814 ms
 9  149.6.168.202 (149.6.168.202)  92.711 ms  88.549 ms  90.769 ms
10  be4027.ccr21.sto01.atlas.cogentco.com (149.6.168.201)  93.142 ms 
99.441 ms  94.862 ms
11  be2397.ccr22.sto03.atlas.cogentco.com (130.117.50.129)  88.284 ms
be2396.ccr21.sto03.atlas.cogentco.com (130.117.50.121)  88.485 ms
be2397.ccr22.sto03.atlas.cogentco.com (130.117.50.129)  88.171 ms
12  be2281.ccr41.ham01.atlas.cogentco.com (154.54.63.1)  122.398 ms 
124.122 ms be2282.ccr42.ham01.atlas.cogentco.com (154.54.72.105)  113.810 ms
13  be2815.ccr41.ams03.atlas.cogentco.com (154.54.38.205)  117.810 ms
be2816.ccr42.ams03.atlas.cogentco.com (154.54.38.209)  117.928 ms 
118.170 ms
14  be12194.ccr41.lon13.atlas.cogentco.com (154.54.56.93)  198.772 ms
be12488.ccr42.lon13.atlas.cogentco.com (130.117.51.41)  197.821 ms
be12194.ccr41.lon13.atlas.cogentco.com (154.54.56.93)  197.405 ms
15  be2317.ccr41.jfk02.atlas.cogentco.com (154.54.30.185)  197.616 ms
be2983.ccr22.bos01.atlas.cogentco.com (154.54.1.178)  198.366 ms
be2982.ccr21.bos01.atlas.cogentco.com (154.54.1.117)  191.831 ms
16  be2096.ccr42.jfk02.atlas.cogentco.com (154.54.30.41)  199.380 ms
be2324.ccr21.jfk04.atlas.cogentco.com (154.54.47.18)  191.371 ms
be2096.ccr42.jfk02.atlas.cogentco.com (154.54.30.41)  199.611 ms
17  * be2325.ccr21.jfk04.atlas.cogentco.com (154.54.47.30)  195.955 ms 
192.230 ms
18  * * *
19  * * *
20  * a190-61-17-9.deploy.akamaitechnologies.com (190.61.17.9)  346.728
ms  346.381 ms



26.08.2016 0:58, erdosain9 ?????:
> Hi.
> I have too much traffic to this ip 190.61.17.9.... i really dont know what
> it is... so i want to block that ip.
> How i can do this?
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Block-access-to-a-ip-external-tp4679184.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXv0LxAAoJENNXIZxhPexGiqoIAL4hS9uoLAFJ2b0CDUs6eu1F
mxARV5vlrKHwi5wb7BlJZyVvxPQihFGkwq+mvecujEj8/o33I3QEitxw2HVpYQAW
b3xYH0n9Xfdi0R9N3vBBCwsYxFXgZ+SBL1KsnkT1FVufkIdsbWsNUjXlyvRJPlse
PZTWuUKFseCm6CxGsDWQXzOu2wXuEyPjDqNof+c0abflRHJZqCEs4+KygRqjuAtl
ENThPhMWb8LHha52zV8ng/V0elPvQA5pGUFyZFbrHhk1SnedRd4anBJ6XXnlL/qZ
ja5SE5S5mUoYprOmaSFOv5DLCsePJ7ab2usy0V1yiKh0/c9Qltn2YTQVnNHWuDc=
=TLPw
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/63fd4415/attachment.key>

From erdosain9 at gmail.com  Thu Aug 25 19:56:24 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 25 Aug 2016 12:56:24 -0700 (PDT)
Subject: [squid-users] Strange log https problem??
In-Reply-To: <93612d4d-da1b-8685-6516-ca61af371c39@gmail.com>
References: <1472149905612-4679179.post@n4.nabble.com>
 <93612d4d-da1b-8685-6516-ca61af371c39@gmail.com>
Message-ID: <1472154984225-4679192.post@n4.nabble.com>

I have a lot of

"NONE/200".......... that's an error i guess.
or not??
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Strange-log-https-problem-tp4679179p4679192.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Aug 25 19:59:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 01:59:18 +0600
Subject: [squid-users] Strange log https problem??
In-Reply-To: <1472154984225-4679192.post@n4.nabble.com>
References: <1472149905612-4679179.post@n4.nabble.com>
 <93612d4d-da1b-8685-6516-ca61af371c39@gmail.com>
 <1472154984225-4679192.post@n4.nabble.com>
Message-ID: <50e467fa-1d5b-fef1-6869-264b8d921314@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Nod. This is informational tag AFAIK.


26.08.2016 1:56, erdosain9 ?????:
> I have a lot of
>
> "NONE/200".......... that's an error i guess.
> or not??
> Thanks
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Strange-log-https-problem-tp4679179p4679192.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXv04VAAoJENNXIZxhPexGgaoH/jbYwudu+xWRP9q6aqfHlvDm
3qPWhUC4WQ5HIIM+EUyaCz31jLGahdiO2xKIawY9VjR4QvIT0Ed5MnUOHKh2/3+v
myfJcPXQbgH+4ysLL+xjRuhoKpxtytGSaROn4jzuZyDoLJEXjleqNWph1yvWvjPA
660zQUc3Pw/ybNHwnUVnfAigTZKHRu3i0U8PEHUmOmFs0P1NVJZsEQ7IAyQ5JTxW
RzaoNH7c3sgOv6Ql97n9aEz6gj+EDZ7T8NfDURD3EQz3rUzdsRXn0n6vNrCAivvW
9PAWxC6W/c9uVbZ4IqGgoE54CT5OJN72T+7zQZRntaFu3wCSrILHpT6IXZiYwBs=
=1mSI
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/f0e00c3d/attachment.key>

From erdosain9 at gmail.com  Thu Aug 25 20:35:12 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 25 Aug 2016 13:35:12 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
Message-ID: <1472157312575-4679194.post@n4.nabble.com>

Hi.Thanks
Yes i have a delay pool pointing to googlevideo.com and its working... but,
it's strange because... look this.
The proxy for now is being tested. And I have very few users (ip) in the
proxy.
So i have this delay pool and acl.

http_access allow localhost
http_access allow administration
http_access allow videoandediting
http_access allow logistic


acl administration src "/etc/squid/ips/administration.lst"
acl videoandediting src "/etc/squid/ips/videoandediting.lst"
acl logistic src "/etc/squid/ips/logistic.lst"


delay_pools 4

# Limiting YOUTUBE 
delay_class 1 1
delay_parameters 1 30000/125000
acl YOUTUBE dstdomain .googlevideo.com
delay_access 1 allow administration YOUTUBE
delay_access 1 allow videoandeditting YOUTUBE
delay_access 1 allow logistic YOUTUBE

#Limting Administration
delay_class 2 2
delay_parameters 2 256000/256000 30000/128000
delay_access 2 allow administration

#Limiting Video And Editting Area
delay_class 3 2
delay_parameters 3 512000/512000 60000/256000
delay_access 3 allow videoandeditting

#Limiting Logistic
delay_class 4 2
delay_parameters 4 300000/300000 100000/256000
delay_access 4 allow logistic


The strange is that if i look the Download avg in Mikrotik i see too much
download in the proxy ip.  as if the proxy was downloading a lot of data.
(but like i say i just have a few users) and if my delay pools are
working... the proxy should not exceed 1200kb... and sometimes reaches much
higher values.

On the other hand, if I see the ip (in the mikrotik) dialoguing with the
proxy, many are from google .... and reach much higher speeds than allowed.
But if I see a video ... yes, really slow connection, ie the delay pool
seems to work.
What can be what is happening ??

Thanks for your answer.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679194.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jok at spikes.com  Thu Aug 25 20:41:17 2016
From: jok at spikes.com (Jok Thuau)
Date: Thu, 25 Aug 2016 13:41:17 -0700
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472157312575-4679194.post@n4.nabble.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
Message-ID: <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>

Be aware that youtube uses the QUIC protocol (
https://en.wikipedia.org/wiki/QUIC) with browsers that support it.
Unless you block and/or manage that specific condition with your firewall,
the actual downloading of the videos will not go through Squid...

Thanks,
Jok

On Thu, Aug 25, 2016 at 1:35 PM, erdosain9 <erdosain9 at gmail.com> wrote:

> Hi.Thanks
> Yes i have a delay pool pointing to googlevideo.com and its working...
> but,
> it's strange because... look this.
> The proxy for now is being tested. And I have very few users (ip) in the
> proxy.
> So i have this delay pool and acl.
>
> http_access allow localhost
> http_access allow administration
> http_access allow videoandediting
> http_access allow logistic
>
>
> acl administration src "/etc/squid/ips/administration.lst"
> acl videoandediting src "/etc/squid/ips/videoandediting.lst"
> acl logistic src "/etc/squid/ips/logistic.lst"
>
>
> delay_pools 4
>
> # Limiting YOUTUBE
> delay_class 1 1
> delay_parameters 1 30000/125000
> acl YOUTUBE dstdomain .googlevideo.com
> delay_access 1 allow administration YOUTUBE
> delay_access 1 allow videoandeditting YOUTUBE
> delay_access 1 allow logistic YOUTUBE
>
> #Limting Administration
> delay_class 2 2
> delay_parameters 2 256000/256000 30000/128000
> delay_access 2 allow administration
>
> #Limiting Video And Editting Area
> delay_class 3 2
> delay_parameters 3 512000/512000 60000/256000
> delay_access 3 allow videoandeditting
>
> #Limiting Logistic
> delay_class 4 2
> delay_parameters 4 300000/300000 100000/256000
> delay_access 4 allow logistic
>
>
> The strange is that if i look the Download avg in Mikrotik i see too much
> download in the proxy ip.  as if the proxy was downloading a lot of data.
> (but like i say i just have a few users) and if my delay pools are
> working... the proxy should not exceed 1200kb... and sometimes reaches much
> higher values.
>
> On the other hand, if I see the ip (in the mikrotik) dialoguing with the
> proxy, many are from google .... and reach much higher speeds than allowed.
> But if I see a video ... yes, really slow connection, ie the delay pool
> seems to work.
> What can be what is happening ??
>
> Thanks for your answer.
>
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679194.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/25ae0ca3/attachment.htm>

From erdosain9 at gmail.com  Thu Aug 25 20:40:52 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 25 Aug 2016 13:40:52 -0700 (PDT)
Subject: [squid-users] Block access to a ip (external)
In-Reply-To: <06ab5772-4774-ced2-ceab-5c6a4d062bdc@gmail.com>
References: <1472151536705-4679184.post@n4.nabble.com>
 <06ab5772-4774-ced2-ceab-5c6a4d062bdc@gmail.com>
Message-ID: <1472157652529-4679196.post@n4.nabble.com>

Is there any way to know which service (web, or whatever) provides this ip ??
Because it consumes a lot of bandwidth.
How do I know which machine asks for it ?? From the proxy.

It also appears the ip  190.61.17.10

Greetings and thanks.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Block-access-to-a-ip-external-tp4679185p4679196.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Thu Aug 25 20:46:23 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 25 Aug 2016 14:46:23 -0600
Subject: [squid-users] Strange log https problem??
In-Reply-To: <1472154984225-4679192.post@n4.nabble.com>
References: <1472149905612-4679179.post@n4.nabble.com>
 <93612d4d-da1b-8685-6516-ca61af371c39@gmail.com>
 <1472154984225-4679192.post@n4.nabble.com>
Message-ID: <e7a712ae-d530-8ac8-073f-c3faaec5e3e3@measurement-factory.com>

On 08/25/2016 01:56 PM, erdosain9 wrote:

> "NONE/200".......... that's an error i guess.

Those lines are often "normal" when you use SslBump. If you want to know
a little more about what gets logged during SslBump processing, then
search for "logged" at

  http://wiki.squid-cache.org/Features/SslPeekAndSplice

Alex.



From yvoinov at gmail.com  Thu Aug 25 21:04:11 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 03:04:11 +0600
Subject: [squid-users] Block access to a ip (external)
In-Reply-To: <1472157652529-4679196.post@n4.nabble.com>
References: <1472151536705-4679184.post@n4.nabble.com>
 <06ab5772-4774-ced2-ceab-5c6a4d062bdc@gmail.com>
 <1472157652529-4679196.post@n4.nabble.com>
Message-ID: <cade1e63-5b87-9c21-2a4f-27c599befdf3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Akamai works with many companies. Antivirus providers, MS updates,
Social networks (FB, Instagram, etc.etc.etc.).


26.08.2016 2:40, erdosain9 ?????:
> Is there any way to know which service (web, or whatever) provides this ip ??
Only squid's access.log can help. Sometimes. I
>
> Because it consumes a lot of bandwidth.
> How do I know which machine asks for it ?? From the proxy.
>
> It also appears the ip  190.61.17.10
>
> Greetings and thanks.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Block-access-to-a-ip-external-tp4679185p4679196.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXv11LAAoJENNXIZxhPexG8MkIAIbu7MMJMQksvSaDqgjykOmK
Np9WMTEW7pf6B+ag1V4nH6TipdiDN3mI8rGW3HerzUd4uf0/xV8VWn/Q28xEK/xF
bMO33/tYzXDwAPitTs4vG20PefZkkX9UjCKfHhWVed30TXIJb+w8HRzX/lUaWfnh
jw0Se1snR5zr5Avq97KI1M0OxnRhf+vcvZ6d9V/pJW22ItYfF0hXqRqK5sFbhArV
Vl5iZGJjwvcE+se3Q+ekXGgXHokZPZKKGO0eFutpkF+P1rDNNTPENZoUkdsavqH9
0/7Femjx3smRWEosu/PPH0ttF/49A9fks/iB1s8sBZWES9dpVHNBEiiI1atYTiY=
=N700
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/61558c9b/attachment.key>

From erdosain9 at gmail.com  Thu Aug 25 21:10:15 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 25 Aug 2016 14:10:15 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
Message-ID: <1472159415603-4679199.post@n4.nabble.com>

I have ssl-bump enable... I guess "quic" is not the problem.

In fact, in the pc, yes, the video slows down ... however, bandwidth,
showing the Proxy in the mikrotik is excessive ......

(sorry I do not speak English)

My delay pools are fine?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679199.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Aug 25 21:16:55 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 26 Aug 2016 03:16:55 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472159415603-4679199.post@n4.nabble.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
Message-ID: <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Everything can be much easier. Google Streaming video is not cacheable.
Absolutely.  If users are watching the same video, each time it is
downloaded from the outside. Slowly and sadly.


26.08.2016 3:10, erdosain9 ?????:
> I have ssl-bump enable... I guess "quic" is not the problem.
>
> In fact, in the pc, yes, the video slows down ... however, bandwidth,
> showing the Proxy in the mikrotik is excessive ......
>
> (sorry I do not speak English)
>
> My delay pools are fine?????
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679199.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXv2BGAAoJENNXIZxhPexGZgMH/RHoRe4bHzUrvRzi+hHc1Zpg
GfOlhE4rwZa58ktX8LLx41mFSYxWe3bWknC2h/NIF2gRDHzG5uURQmOTgpwgNNHt
m3+0mHzXB4z96sZs+qkR1gdwN4JlzSyqc+En0cfh8lkJAgZ1kR0bemR9TCp7K0El
y5FoFrSjqRxboioKikzBk2VHd75r4YbTJ6A3cOHfD8cU0Ltb4DE9oAnVW2shnTOj
S01BzUfXRvYb8TuJUWsWfX78BKhkem9a74mScU6kHejubz5TyFCx6QfiZqjjGauf
soVYOOJntS8kZqXSCRq1cq16MXQSktNGzoetO63J9JjOdvES08SeixGtGQAuWwA=
=Im38
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/0803f04c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/0803f04c/attachment.key>

From erdosain9 at gmail.com  Thu Aug 25 21:53:38 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 25 Aug 2016 14:53:38 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
Message-ID: <1472162018951-4679201.post@n4.nabble.com>

Thats ok i dont want to give more Bandwith, and im not interest in caching
video.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679201.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chicocvenancio at gmail.com  Thu Aug 25 22:01:08 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Thu, 25 Aug 2016 19:01:08 -0300
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472162018951-4679201.post@n4.nabble.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <1472162018951-4679201.post@n4.nabble.com>
Message-ID: <CAEpx-0W6zF93qdstiiGt62WArA5w5QQNJPTYwy8jEBcqH2kieA@mail.gmail.com>

What is the squid version?

Chico Venancio
(98) 9 8800 2743
CEO - VM TECH

2016-08-25 18:53 GMT-03:00 erdosain9 <erdosain9 at gmail.com>:

> Thats ok i dont want to give more Bandwith, and im not interest in caching
> video.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679201.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160825/fffae709/attachment.htm>

From squid3 at treenet.co.nz  Fri Aug 26 01:40:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 26 Aug 2016 13:40:30 +1200
Subject: [squid-users] squid user session/connections control
In-Reply-To: <C375DBF1-3D2B-467F-AA80-56C9C799CE96@netstream.ps>
References: <C375DBF1-3D2B-467F-AA80-56C9C799CE96@netstream.ps>
Message-ID: <74a91a5d-a535-080d-e6bd-bacf6ecb5b7a@treenet.co.nz>

On 26/08/2016 7:05 a.m., --Ahmad-- wrote:
> Hi dear ?squid users ?
> 
> i have a question in mind on how can i limit connections for a user that is connected using AUTH_NTLM method 

Why?


> i already added the directives below :
> 
> as example  , user will connect to squid and have only 50 max connections .

The config you presented will allow 100 connections, and uses Basic
authentication.

> 
> im not sure how can i limit the connections per user connection not per ip 
> 

You can't. The user has to already have an accepted open connection for
authentication to be performed. Particularly with NTLM that requires +2
connections before you ever find out what the username is. Once you have
authentication it is too late to undo.


> 
> 
> 
> hope to help 
> 
> I?m using squid 3.5.2
> 

Please upgrade. That is a very old and insecure version. Several attacks
are now widely available.

Amos



From squid3 at treenet.co.nz  Fri Aug 26 01:50:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 26 Aug 2016 13:50:09 +1200
Subject: [squid-users] Block access to a ip (external)
In-Reply-To: <1472157652529-4679196.post@n4.nabble.com>
References: <1472151536705-4679184.post@n4.nabble.com>
 <06ab5772-4774-ced2-ceab-5c6a4d062bdc@gmail.com>
 <1472157652529-4679196.post@n4.nabble.com>
Message-ID: <a5d4238f-76a5-dd29-117c-7c8a0155128b@treenet.co.nz>

On 26/08/2016 8:40 a.m., erdosain9 wrote:
> Is there any way to know which service (web, or whatever) provides this ip ??
> Because it consumes a lot of bandwidth.
> How do I know which machine asks for it ?? From the proxy.
> 
> It also appears the ip  190.61.17.10
> 
> Greetings and thanks.

Please read the FAQs about logging.

<http://wiki.squid-cache.org/SquidFaq/SquidLogs#access.log>

<http://wiki.squid-cache.org/Features/LogFormat#Squid_native_access.log_format_in_detail>

Amos



From squid3 at treenet.co.nz  Fri Aug 26 02:03:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 26 Aug 2016 14:03:13 +1200
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472157312575-4679194.post@n4.nabble.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
Message-ID: <144fe7c6-b110-4cce-365e-e885564e3d99@treenet.co.nz>

On 26/08/2016 8:35 a.m., erdosain9 wrote:
> Hi.Thanks
> Yes i have a delay pool pointing to googlevideo.com and its working... but,
> it's strange because... look this.
> The proxy for now is being tested. And I have very few users (ip) in the
> proxy.
> So i have this delay pool and acl.
> 
...
> 
> The strange is that if i look the Download avg in Mikrotik i see too much
> download in the proxy ip.  as if the proxy was downloading a lot of data.
> (but like i say i just have a few users) and if my delay pools are
> working... the proxy should not exceed 1200kb... and sometimes reaches much
> higher values.
> 
> On the other hand, if I see the ip (in the mikrotik) dialoguing with the
> proxy, many are from google .... and reach much higher speeds than allowed.
> But if I see a video ... yes, really slow connection, ie the delay pool
> seems to work.
> What can be what is happening ??

YouTube is not only using googlevideo domain. That domain is for the
video itself, but many other parts of the visible page and pieces of the
vidoe layer and TLS dependencies use other Google owned or hosted
domains. All of that can use hundreds of objects not in *.googlevideo.com.

There are other things too. But I dont have time right now to write that
up. You can use debug_options 11,2 to see the HTTP message headers and
figure it out.

Amos



From bestlijo at yahoo.com  Fri Aug 26 12:10:53 2016
From: bestlijo at yahoo.com (LIJO C J)
Date: Fri, 26 Aug 2016 12:10:53 +0000 (UTC)
Subject: [squid-users] Shared Caching with Authorization
References: <1385494105.149002.1472213453775.ref@mail.yahoo.com>
Message-ID: <1385494105.149002.1472213453775@mail.yahoo.com>

Hi,
I have a resource representation in a REST service. ?The response content ?is same for allusers. But the response should be accessed only by authorizedInventoryAuditors.


?
1.??????How should be the response headers set to leveragecaching in Squid (as a forward proxy)?

2.??????How Squid will validate that the requested useris an authorized InventoryAuditor, while serving the response from cache?


?

?

?
[RoutePrefix("api/users")]

public classUsersController : ApiController

{

???[Authorize(Roles="InventoryAuditor")]

???[Route("")]

???[HttpGet]

??? publicList<User> GetAllUsers()

??? {

???????//Return list of users

??? }


?
}


?
public class User

{

??? publicint UserID { get; set; }

??? publicstring FirstName { get; set; }

}

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160826/dc63fcf9/attachment.htm>

From omidkosari at yahoo.com  Fri Aug 26 14:42:14 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Fri, 26 Aug 2016 07:42:14 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
Message-ID: <1472222534649-4679207.post@n4.nabble.com>

Alex Rousskov wrote
> I do not know why deny_info does not work
> in your tests.

Should i give up ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679207.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Fri Aug 26 15:10:06 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 Aug 2016 09:10:06 -0600
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1472222534649-4679207.post@n4.nabble.com>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
Message-ID: <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>

On 08/26/2016 08:42 AM, Omid Kosari wrote:
> Alex Rousskov wrote
>> I do not know why deny_info does not work in your tests.

> Should i give up ?

I cannot answer that question, but if you decide to keep going, then I
am sure that somebody can figure out why deny_info does not work for
you. You may have to try various configurations, supply good debugging
information, and/or pay somebody to make that happen.

I recommend starting with something like this:

  http_reply_access deny all
  deny_info TCP_RESET all

Does that reset all connections to Squid (after Squid fetches the reply)?

Alex.



From uhlar at fantomas.sk  Fri Aug 26 17:54:35 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 26 Aug 2016 19:54:35 +0200
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
Message-ID: <20160826175435.GB32085@fantomas.sk>

On 26.08.16 03:16, Yuri Voinov wrote:
>Everything can be much easier. Google Streaming video is not cacheable.
>Absolutely.  If users are watching the same video, each time it is
>downloaded from the outside. Slowly and sadly.

could something like collapsed forwarding solve this problem?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Microsoft dick is soft to do no harm


From yvoinov at gmail.com  Fri Aug 26 19:10:41 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 27 Aug 2016 01:10:41 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <20160826175435.GB32085@fantomas.sk>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
Message-ID: <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Dont' sure.

http://wiki.squid-cache.org/ConfigExamples/DynamicContent/YouTube/Discussion?highlight=%28Youtube%29


26.08.2016 23:54, Matus UHLAR - fantomas ?????:
> On 26.08.16 03:16, Yuri Voinov wrote:
>> Everything can be much easier. Google Streaming video is not cacheable.
>> Absolutely.  If users are watching the same video, each time it is
>> downloaded from the outside. Slowly and sadly.
>
> could something like collapsed forwarding solve this problem?
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXwJQxAAoJENNXIZxhPexGLBYH/ApOKtpBO/gt+u5aj9AJuHUP
cXczUTYRHwgD/Q5vDbLXOzEuVVoyTMxWW6Shl6wC6LHStznOE/gwQig9CPsg7JcK
rh34hn6uttyi0Q7/BQuszGBW4WMOJCYDAEt+T6PK4R784iMu/WJRQMebgPch1h6L
dSquzNy2q0D8eDflpNiAkIW8ZJgeiyTTPbVbOPUMwPnl9QxYACwDRSegl3KBNrQz
zoBHDVO/svoJqp9howoq+sFQnrlitpfgdIqchtE2sUGEAeh0eScAdJGzbed6eNT2
RO1/T39RhUCaqjDax0kiHlaZSTSorj69XfwuJYp9pMxNi9XWSZYsDu80FmQ+e8I=
=C6gy
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160827/688939d8/attachment.key>

From rousskov at measurement-factory.com  Fri Aug 26 22:57:47 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 Aug 2016 16:57:47 -0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <20160826175435.GB32085@fantomas.sk>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
Message-ID: <edc69b5b-debe-9c53-620e-1b9ee4c70b43@measurement-factory.com>

On 08/26/2016 11:54 AM, Matus UHLAR - fantomas wrote:
> On 26.08.16 03:16, Yuri Voinov wrote:
>> Google Streaming video is not cacheable.
>> Absolutely.  If users are watching the same video, each time it is
>> downloaded from the outside. Slowly and sadly.

> could something like collapsed forwarding solve this problem?

Collapsed forwarding does not make uncachable responses cachable. If
your problem is caused by uncachable responses, then collapsed
forwarding is not a solution.

Alex.



From omidkosari at yahoo.com  Sat Aug 27 11:44:48 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 27 Aug 2016 04:44:48 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
Message-ID: <1472298288404-4679212.post@n4.nabble.com>

Alex Rousskov wrote
> I recommend starting with something like this:
> 
>   http_reply_access deny all
>   deny_info TCP_RESET all
> 
> Does that reset all connections to Squid (after Squid fetches the reply)?

Thanks for reply .

As i mention before the deny_info works in other configs for example 

acl test dstdomain 123.com
deny_info TCP_RESET test
http_reply_access deny test 

works fine and it only reset the connection without any additional headers .

But if you looking for special purpose i will schedule a maintenance time
and do following config as you said .

  http_reply_access deny all
  deny_info TCP_RESET all






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679212.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From huaraz at moeller.plus.com  Sat Aug 27 14:37:44 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sat, 27 Aug 2016 15:37:44 +0100
Subject: [squid-users] ext_kerberos_ldap_group_acl problem
In-Reply-To: <vmime.57beabe1.6a01.3a47ad2737b8db71@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.57bd9aeb.72ce.fa87a6d7dfd8a1b@ms249-lin-003.rotterdam.bazuin.nl>
 <vmime.57beabe1.6a01.3a47ad2737b8db71@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <nps8jp$45t$1@blaine.gmane.org>

Hi  Louis,

    I made lately a change in how the SSL certifcate verification is done.  Did you use the latest version from trunk ?  Also set the variable TLS_CACERTFILE in your startup script (e.g. export TLS_CACERTFILE=/etc/mydir/cas.pem ). I do not read any ldap.conf file for this yet.

Markus



"L.P.H. van Belle" <belle at bazuin.nl> wrote in message news:vmime.57beabe1.6a01.3a47ad2737b8db71 at ms249-lin-003.rotterdam.bazuin.nl...
Hai, 

 

I?ve added the needed upn, setup the _ldaps in the dns zones, thats ok now. 



The last part, here i need some help.

support_ldap.cc(942): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc1.internal.domain.tld:636

support_ldap.cc(786): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc2.internal.domain.tld:636

support_ldap.cc(786): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

 

I tried to set 

TLS_CACERTFILE in ldap.conf, didnt work, so dont know how to fix this or there to put these variables. 

 

I need a user to connect to the ldap.  Hi have that one in place. 

I just can find how to put this in this line so i can test this out, but i can only authenticate if the TLS_CACERTFILE is set correctly. 

 

Any suggestions here? 

 

 

Greetz, 

 

Louis



--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160827/0be4e126/attachment.htm>

From huaraz at moeller.plus.com  Sat Aug 27 14:52:07 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sat, 27 Aug 2016 15:52:07 +0100
Subject: [squid-users] ext_kerberos_ldap_group_acl problem ( 2
	minorbugsmaybe )
In-Reply-To: <vmime.57bdb617.37c8.575130a1134f9a07@ms249-lin-003.rotterdam.bazuin.nl>
References: <CAD8MJvC8ZDWpUVE6iSaKu6qvx-7-3+Vy_4_kSiGq0oubauEqkA@mail.gmail.com>
 <vmime.57bdb617.37c8.575130a1134f9a07@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <nps9en$dm0$1@blaine.gmane.org>

Hi,

   I would say they are bugs. The first ?issue? is as you say more about understanding the difference between UPN and SPN and how the tools use them.  The helper tries to ?authenticate? squid to AD as a user with the found SPN name, so the UPN must be the same as the SPN.  There is no easy way to query what the UPN for the SPN is. 

  Also msktutil (my preferred tool) creates a machine account not a user account in AD. The reason I prefer this is that often user accounts have a global password policy e.g. change every 60 days otherwise it will be locked. machine accounts do not have that limitation. But as I said it is just my preference. 

   Regarding the certifcate check I do not use any ldap.conf settings. I require an export TLS_CACERTFILE=/mydir/myfile.pem   in the squid startup file.  Maybe in the next version I see how I can determine the right ldap.conf file and check if the CACERTFILE variable is already set.


Kind regards
Markus


"L.P.H. van Belle" <belle at bazuin.nl> wrote in message news:vmime.57bdb617.37c8.575130a1134f9a07 at ms249-lin-003.rotterdam.bazuin.nl...
Ok reply to myself so other users know this also.

 

if you create a user for the HTTP services and you dont use msktutil but like me samba-tool or something else. 

 

Read : 

http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos carefully. 

and the clue was this line for me.  

 

Squid "login" to Windows Active Directory or Unix kdc as user <HTTP/<fqdn-squid>@DOMAIN.COM>. 

This requires Active Directory to have an attribute userPrincipalname set to <HTTP/<fqdn-squid>@DOMAIN.COM>

for the associated acount. This is usaully done by using msktutil. 

 

But this is not done by samba-tools  

 

samba-tool setup fro squid i used, was as followed. 

samba-tool user create squid1-service --description="Unprivileged user for SQUID1-Proxy Services" --random-password 

samba-tool user setexpiry squid1-service ?noexpiry

samba-tool spn add HTTP/proxy.internal.domain.tld squid1-service

 

 

Now this results in : 

My UPN was set to the username at internal.domain.tld  ( as it should ). 

My SPN was set to HTTP/proxyserver.internal.domain.tld at REALM ( as is should )  

 

samba-tool spn list squid1-service 

squid1-service

User CN=squid1-service,OU=Service-Accounts,OU=XXXX,DC=XXXXX,DC=XXXX,DC=XX has the following servicePrincipalName:

         HTTP/proxy.internal.domain.tld

         HTTP/proxy.internal.domain.tld at YOUR.REALM.T

 

 

Now i changed my UPN from username at internal.domain.tld  to the (SPN name)   HTTP/proxyserver.internal.domain.tld at REALM 

Solved my initial problem. 

This should be in my optionion be changed to search for the SPN in ext_kerberos_ldap_group.

 

Now i have LDAPS messages, see below, im adding the _ldaps SRV records now ,but i dont get why im getting : 

Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

 

Im already having : TLS_CACERT      /etc/ssl/certs/ca-certificates.crt 

Which contains the needed certs.

 

Did i find 2 small bugs here?  

Or is this a ?Debian? related thing? 

 

 

Debug output. 

/usr/lib/squid3/ext_kerberos_ldap_group_acl -g internet-mail at YOUR.REALM.TLD -D YOUR.REALM.TLD -N internet-mail at NTDOMAIN -s -i -d

kerberos_ldap_group.cc(278): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Starting version 1.3.1sq

support_group.cc(382): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Group list internet-mail at YOUR.REALM.TLD

support_group.cc(447): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Group internet-mail  Domain YOUR.REALM.TLD

support_netbios.cc(83): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: Netbios list internet-mail at NTDOMAIN

support_netbios.cc(156): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: Netbios name internet-mail  Domain NTDOMAIN

support_lserver.cc(82): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: ldap server list NULL

support_lserver.cc(86): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: No ldap servers defined.

testuser internet-mail

kerberos_ldap_group.cc(371): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: Got User: testuser set default domain: YOUR.REALM.TLD

kerberos_ldap_group.cc(376): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: Got User: testuser Domain: YOUR.REALM.TLD

support_member.cc(63): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: User domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(65): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Found group at domain internet-mail at YOUR.REALM.TLD

support_ldap.cc(898): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setup Kerberos credential cache

support_krb5.cc(127): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set credential cache to MEMORY:squid_ldap_6902

support_krb5.cc(138): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Get default keytab file name

support_krb5.cc(144): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Got default keytab file name /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(158): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Get principal name from keytab /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(169): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Found principal name: HTTP/proxy.internal.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Got principal name HTTP/proxy.internal.domain.tld at YOUR.REALM.TLD

support_krb5.cc(260): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Stored credentials

support_ldap.cc(927): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Initialise ldap connection

support_ldap.cc(931): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable SSL to ldap servers

support_ldap.cc(933): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Canonicalise ldap server name for domain YOUR.REALM.TLD

support_resolv.cc(289): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while resolving service record _ldaps._tcp.YOUR.REALM.TLD with res_search

support_resolv.cc(71): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: res_search: Unknown service record: _ldaps._tcp.YOUR.REALM.TLD

support_resolv.cc(379): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved SRV _ldap._tcp.YOUR.REALM.TLD record to samba-dc2.internal.domain.tld

support_resolv.cc(379): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved SRV _ldap._tcp.YOUR.REALM.TLD record to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 1 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 2 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 3 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 4 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 5 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 6 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(407): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Adding YOUR.REALM.TLD to list

support_resolv.cc(443): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Sorted ldap server names for domain YOUR.REALM.TLD:

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: samba-dc1.internal.domain.tld Port: 389 Priority: 0 Weight: 100

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: samba-dc2.internal.domain.tld Port: 389 Priority: 0 Weight: 100

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: YOUR.REALM.TLD Port: -1 Priority: -2 Weight: -2

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc1.internal.domain.tld:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc2.internal.domain.tld:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server YOUR.REALM.TLD:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(979): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Error during initialisation of ldap connection: No such file or directory

support_ldap.cc(1048): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Error during initialisation of ldap connection: No such file or directory

support_member.cc(76): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: User testuser is not member of group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(91): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Default domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(119): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Default group loop: group at domain internet-mail at YOUR.REALM.TLD

 

 



--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160827/a49f7eac/attachment.htm>

From marciobacci at gmail.com  Sat Aug 27 16:32:20 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Sat, 27 Aug 2016 13:32:20 -0300
Subject: [squid-users] Trouble negotiate_kerberos_auth
Message-ID: <CA+0TdyqEAt4L5KO4zrJNJ1aUe64mY2Re7z95KFdqW7Y8SV_qbg@mail.gmail.com>

I have trouble to authenticate Squid3 with kerberos in Samba4 domain. I'm
using CentOS 7 and Squid 3.3.8 (yum install squid)

When I type the bellow command in terminal:
/usr/lib64/squid/negotiate_kerberos_auth -d -i -s HTTP/
proxy.cms.ensino.br at CMS.ENSINO.BR
john xyz at 12345

I have the following error:
negotiate_kerberos_auth.cc(315): pid=6364 :2016/08/27 10:44:33|
negotiate_kerberos_auth: DEBUG: Got 'john xyz at 12345' from squid (length:
14).
negotiate_kerberos_auth.cc(362): pid=6364 :2016/08/27 10:44:33|
negotiate_kerberos_auth: ERROR: Invalid request [john xyz at 12345]
BH invalid request


Here are my files configuration:

/etc/krb5.conf
[libdefaults]
    default_realm = CMS.ENSINO.BR
[realms]
    CMS.ENSINO.BR = {
    kdc = dc1.cms.ensino.br:88
    admin_server = dc1.cms.ensino.br
    default_domain = CMS.ENSINO.BR
    }
[domain_realm]
    .cms.ensino.br = CMS.ENSINO.BR
    cms.ensino.br = CMS.ENSINO.BR



Keytab name: FILE:/etc/krb5.keytab
KVNO Principal
----
--------------------------------------------------------------------------
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR


Keytab name: FILE:/etc/squid/PROXY.keytab
KVNO Principal
----
--------------------------------------------------------------------------
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR


/etc/sysconfig/squid
# default squid options
SQUID_OPTS=""
# Time to wait for Squid to shut down when asked. Should not be necessary
# most of the time.
SQUID_SHUTDOWN_TIMEOUT=100
# default squid conf file
SQUID_CONF="/etc/squid/squid.conf"

KRB5_KTNAME=/etc/squid/PROXY.keytab
export KRB5_KTNAME


kinit and klist commands are OK.

Best Regards,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160827/eff9813a/attachment.htm>

From marcus.kool at urlfilterdb.com  Sat Aug 27 17:20:48 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sat, 27 Aug 2016 14:20:48 -0300
Subject: [squid-users] Skype+intercept+ssl_bump
In-Reply-To: <579CFE32.4040400@measurement-factory.com>
References: <1468579083.987752759@f362.i.mail.ru>
 <8db650ae-f784-2fd4-365f-ac4ae7b59323@treenet.co.nz>
 <578D603C.4050009@measurement-factory.com>
 <579CFE32.4040400@measurement-factory.com>
Message-ID: <972e69a0-2d21-f73a-df32-d547f3c531f3@urlfilterdb.com>



On 07/30/2016 04:21 PM, Alex Rousskov wrote:
*snip*

> Update: The question still stands, but we now know more about what
> happens if the on_unsupported_protocol bug (in code and/or
> documentation, depending on how you look at it) discussed above is
> fixed: Squid then starts tunneling traffic as it is told by the
> on_unsupported_protocol directive, but forgets to use the existing
> encrypted connection to the server and opens/uses a new Squid-to-server
> unencrypted connection instead.
>
> Thus, the patch I posted previously does not solve the known Skype
> groups/MSNP problem -- it only exposes the next (and bigger!) obstacle
> on the way to that solution.
>
> We are working on supporting/fixing tunneling of bumped connections, but
> feedback regarding request counting check question above is still welcomed.
>
>
> Thank you,
>
> Alex.

I am using squid-4.0.13-20160819-r14813 and have observed the following
with transparent intercept:
1) skype (on windows10) login fails, access.log contains
    "CNT error:invalid-request HTTP/1.1" 400 3705 NONE:HIER_NONE -
2) whatsapp (on Android) fails, access.log contains
    "NONE error:transaction-end-before-headers HTTP/0.0" 0 0 NONE:HIER_NONE -
    "' error:invalid-request HTTP/1.1" 400 3705 NONE:HIER_NONE -
3) Samsung (monitoring?) app on my Samsung smartphone:
    "CONNECT 54.76.6.24:80 HTTP/1.1" 403 3775 TCP_DENIED:HIER_NONE Host:%2054.76.6.24:80%0D%0A
    "NONE error:invalid-request HTTP/1.1" 400 3705 NONE:HIER_NONE -

TCP_DENIED in 3) is OK since the app connects on port 80 and this port is
not in SSL_ports, but the error message "invalid-request" on the next line
is misleading.

If you need a cache.log with debug ALL,9 I can provide one.

The ssl-bump rules on my server are:
acl tls_s1_connect at_step SslBump1
acl tls_to_splice complex-acl-but-does-not-matter-what-it-has
ssl_bump peek   tls_s1_connect
ssl_bump splice tls_to_splice
ssl_bump stare  all
ssl_bump bump   all

With best regards,

Marcus


From rousskov at measurement-factory.com  Sat Aug 27 21:41:26 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 27 Aug 2016 15:41:26 -0600
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1472298288404-4679212.post@n4.nabble.com>
References: <1472019440563-4679102.post@n4.nabble.com>
 <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
Message-ID: <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>

On 08/27/2016 05:44 AM, Omid Kosari wrote:
> Alex Rousskov wrote
>> I recommend starting with something like this:
>>
>>   http_reply_access deny all
>>   deny_info TCP_RESET all
>>
>> Does that reset all connections to Squid (after Squid fetches the reply)?
> 
> Thanks for reply .
> 
> As i mention before the deny_info works in other configs 

AFAICT, the examples you mentioned before were all wrong, for one reason
or another.


> for example 
> 
> acl test dstdomain 123.com
> deny_info TCP_RESET test
> http_reply_access deny test 
> 
> works fine and it only reset the connection without any additional headers .

You have not mentioned the above example before AFAICT. I understand
that it works for regular requests. Does it also work (i.e., does Squid
reset the connection) when handling a non-HTTP request on port 80?


> But if you looking for special purpose i will schedule a maintenance time
> and do following config as you said .
> 
>   http_reply_access deny all
>   deny_info TCP_RESET all

We can start with dstdomain if that is easier for you. I am surprised
you are testing this on a live Squid though. It would be much easier to
get it working in a lab first...

Alex.



From ahmed.zaeem at netstream.ps  Sat Aug 27 22:34:04 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sun, 28 Aug 2016 01:34:04 +0300
Subject: [squid-users] squid with random outgoing ip from pool of 1000 ips
Message-ID: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>

hi folks 
i have like 1000 ips on a sever and ips inserted on the ip of the server .

i want to do like random outgoing address per request .

say i opened website http://whatismyipaddress.com/ <http://whatismyipaddress.com/> it should  have randomized ip address form the 1000 pools on my server .
so i guess i need to create probability 1/1000 for each ip.

the question is being asked here is :

how can i create the randomized acls ???

is my settings below is correct ??


==========
acl half10000 random 1/1000
acl half10001 random 1/1000
acl half10002 random 1/1000
acl half10003 random 1/1000
acl half10004 random 1/1000
acl half10005 random 1/1000
acl half10006 random 1/1000
acl half10007 random 1/1000
acl half10008 random 1/1000
.
.
.
.
until reach 10000 random 1/1000
==============================

tcp_outgoing_address 2002:4300:a:14e:f9fc:748b:1b9a:b147 half10000
tcp_outgoing_address 2002:4300:a:14e:a68a:2d3b:889:767d half10001
tcp_outgoing_address 2002:4300:a:14e:6304:4fc2:37a4:2c2d half10002
tcp_outgoing_address 2002:4300:a:14e:2aa6:743b:2d0d:d3d2 half10003
tcp_outgoing_address 2002:4300:a:14e:f6f9:86da:1ff:3159 half10004
tcp_outgoing_address 2002:4300:a:14e:7ba1:5cf5:b477:422c half10005
tcp_outgoing_address 2202:4300:a:14e:14c4:ab57:6521:5f39 half10006
tcp_outgoing_address 2002:4300:a:14e:32ea:e262:6efb:ebda half1007
tcp_outgoing_address 2002:4300:a:14e:29b2:2ff2:573a:5c9c half11008
.
.
.
.

tcp_outgoing_address 2002:4300:a:14e:b221:a1a0:60ee:323f half10000




is the settings above will random the request  per 1000 ips as outgoing ips ???????????



cheers
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/a6d7a4e0/attachment.htm>

From rousskov at measurement-factory.com  Sat Aug 27 23:38:09 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 27 Aug 2016 17:38:09 -0600
Subject: [squid-users] squid with random outgoing ip from pool of 1000
	ips
In-Reply-To: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>
References: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>
Message-ID: <579f8215-35f7-57ef-0f4d-be68f0a22da1@measurement-factory.com>

On 08/27/2016 04:34 PM, --Ahmad-- wrote:

> i guess i need to create probability 1/1000 for each ip.

Yes, but that is _not_ the same as 1/1000 probability for each
tcp_outgoing_address rule, unfortunately. tcp_outgoing_address rules are
evaluated top to bottom until the first matches. If you have N rules and
each rule has a 1/N probability of a match in isolation, then you will
get the following probabilities of a match when the rules are combined:

  rule #0: 1/N   -- good!
  rule #1: (1-1/N) * 1/N  -- which is not 1/N
  rule #2: (1-1/N) * (1-1/N) * 1/N  -- even less 1/N than rule #2 was
  rule #3: (1-1/N) * (1-1/N) * (1-1/N) * 1/N  -- and getting worse!
  ...

To simplify equations, let me denote 1/N as p and (1-1/N) as q. With
your incorrect 1/N ACLs, you get the following probabilities (I am just
rewriting the above using p and q):

  rule #0: p
  rule #1: q * p
  rule #2: q*q * p
  rule #3: q*q*q * p
  ...

If you are still unsure, consider the simple case of just 2 rules
(instead of 1000). You want the second rule to match 50% of the time. If
you give the second rule ACL the same 1/2 probability of a match, then
the second rule will only match 1/4 of the time because it will match
only when the previous rule did _not_ match (1/2) _and_ when its own ACL
matched (1/2): 1/2*1/2 = 1/4.


To compensate for the cumulative effect of rules evaluation, you need
rule i to have p/(q^i) probability of a match (where "q^i" is "q to the
power of i"). With that, you will always get the same probability of a
match (p) for each rule when that rule is evaluated:

  rule #0: p
  rule #1: q * p/q = p
  rule #2: q*q * p/(q*q) = p
  rule #3: q*q*q * p/(q*q*q) = p
  ...
  rule #998: q^998 * p/(q^998) = p

To avoid uncertainty, the last rule (rule #999 in the above notation)
should use the "all" ACL (i.e., it will always match).


> how can i create the randomized acls ???

I suggest writing a script that generates 999 ACLs with correct p/(q^i)
probability and the corresponding tcp_outgoing_address lines to match them.

Please note that computing ~500 random ACL matches for each outgoing
Squid connection (or is it each request?) is not going to be
instantaneous! If you are worried about Squid performance, then you may
want to add custom Squid code to select a random or round-robin IP
address out of a pool of 1000 addresses instead.

[ It is not going to be easy, but if you do it right, the same new
configuration interface and underlying code can then be applied to other
similar tasks in Squid (e.g., selecting one of several load-balanced
ICAP services). In that case, it would be a welcomed feature that may be
officially accepted. If you decide to make this generally useful, then I
recommend getting your configuration design pre-approved on squid-dev
before you implement anything (or before you pay somebody else to
implement it)! ]


> is my settings below is correct ??

No. Your ACL(s) and rule probabilities are wrong. See above.


HTH,

Alex.



From chip_pop at hotmail.com  Sun Aug 28 00:56:25 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 27 Aug 2016 17:56:25 -0700 (PDT)
Subject: [squid-users] cache object with vary
Message-ID: <1472345785055-4679220.post@n4.nabble.com>

is this bug or its made to work like that
lets say we have object in cache name 000000A5
url.com/some.js
vary=accept-encoding="gzip"

if some browser get the same object
url.com/some.js
vary=accept-encoding="deflate"

the md5 key wont match and it delete the old cached object with
accept-encoding="gzip" and replace with
new one with vary=accept-encoding="deflate" and prosess as TCP_MISS

that will result in "varyEvaluateMatch: Oops. Not a Vary match on second
attempt
no match and the code in client_side.cc
return VARY_CANCEL

and in client_side_reply.cc

    case VARY_CANCEL:
        /* varyEvaluateMatch found a object loop. Process as miss */
        debugs(88, DBG_IMPORTANT, "clientProcessHit: Vary object loop!");
        http->logType = LOG_TCP_MISS; // we lack a more precise LOG_*_MISS
code
        processMiss();
        return;

the way it should be instead of replacing the existing obj  should be
another object with the 
new vary
shuld be 2 file 000000A5
and    000000A6     example each one has different vary to match the correct
obj if its gzip or ident or deflate or with useragent
wen vary not matching shuld be new obj file to be saved as diferent cache
name 000000A7
so it match the correct object name with its vary





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/cache-object-with-vary-tp4679220.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Sun Aug 28 08:04:27 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sun, 28 Aug 2016 11:04:27 +0300
Subject: [squid-users] squid with random outgoing ip from pool of 1000
	ips
In-Reply-To: <579f8215-35f7-57ef-0f4d-be68f0a22da1@measurement-factory.com>
References: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>
 <579f8215-35f7-57ef-0f4d-be68f0a22da1@measurement-factory.com>
Message-ID: <D61E7137-EA75-4142-A2FC-25E10C5417BF@netstream.ps>

thanks for reply 

how about the length of the number?

1/1000 to which digits should i round ??

4 or 5 6 digits ?



AS AN EXAMPLE the 1/1000 probabilities will have the acls as below :


0.001 0.000999 0.000998001 0.000997002999 0.000996005996001


the question is how many digits should i round ?

will squid understand the long digits ?


cheers


> On Aug 28, 2016, at 2:38 AM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 08/27/2016 04:34 PM, --Ahmad-- wrote:
> 
>> i guess i need to create probability 1/1000 for each ip.
> 
> Yes, but that is _not_ the same as 1/1000 probability for each
> tcp_outgoing_address rule, unfortunately. tcp_outgoing_address rules are
> evaluated top to bottom until the first matches. If you have N rules and
> each rule has a 1/N probability of a match in isolation, then you will
> get the following probabilities of a match when the rules are combined:
> 
>  rule #0: 1/N   -- good!
>  rule #1: (1-1/N) * 1/N  -- which is not 1/N
>  rule #2: (1-1/N) * (1-1/N) * 1/N  -- even less 1/N than rule #2 was
>  rule #3: (1-1/N) * (1-1/N) * (1-1/N) * 1/N  -- and getting worse!
>  ...
> 
> To simplify equations, let me denote 1/N as p and (1-1/N) as q. With
> your incorrect 1/N ACLs, you get the following probabilities (I am just
> rewriting the above using p and q):
> 
>  rule #0: p
>  rule #1: q * p
>  rule #2: q*q * p
>  rule #3: q*q*q * p
>  ...
> 
> If you are still unsure, consider the simple case of just 2 rules
> (instead of 1000). You want the second rule to match 50% of the time. If
> you give the second rule ACL the same 1/2 probability of a match, then
> the second rule will only match 1/4 of the time because it will match
> only when the previous rule did _not_ match (1/2) _and_ when its own ACL
> matched (1/2): 1/2*1/2 = 1/4.
> 
> 
> To compensate for the cumulative effect of rules evaluation, you need
> rule i to have p/(q^i) probability of a match (where "q^i" is "q to the
> power of i"). With that, you will always get the same probability of a
> match (p) for each rule when that rule is evaluated:
> 
>  rule #0: p
>  rule #1: q * p/q = p
>  rule #2: q*q * p/(q*q) = p
>  rule #3: q*q*q * p/(q*q*q) = p
>  ...
>  rule #998: q^998 * p/(q^998) = p
> 
> To avoid uncertainty, the last rule (rule #999 in the above notation)
> should use the "all" ACL (i.e., it will always match).
> 
> 
>> how can i create the randomized acls ???
> 
> I suggest writing a script that generates 999 ACLs with correct p/(q^i)
> probability and the corresponding tcp_outgoing_address lines to match them.
> 
> Please note that computing ~500 random ACL matches for each outgoing
> Squid connection (or is it each request?) is not going to be
> instantaneous! If you are worried about Squid performance, then you may
> want to add custom Squid code to select a random or round-robin IP
> address out of a pool of 1000 addresses instead.
> 
> [ It is not going to be easy, but if you do it right, the same new
> configuration interface and underlying code can then be applied to other
> similar tasks in Squid (e.g., selecting one of several load-balanced
> ICAP services). In that case, it would be a welcomed feature that may be
> officially accepted. If you decide to make this generally useful, then I
> recommend getting your configuration design pre-approved on squid-dev
> before you implement anything (or before you pay somebody else to
> implement it)! ]
> 
> 
>> is my settings below is correct ??
> 
> No. Your ACL(s) and rule probabilities are wrong. See above.
> 
> 
> HTH,
> 
> Alex.
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/3598e14d/attachment.htm>

From omidkosari at yahoo.com  Sun Aug 28 09:10:29 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sun, 28 Aug 2016 02:10:29 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
References: <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
Message-ID: <1472375429698-4679222.post@n4.nabble.com>

Alex Rousskov wrote
> I understand that it works for regular requests. Does it also work (i.e.,
> does Squid
> reset the connection) when handling a non-HTTP request on port 80?

No , when the request is non-HTTP it does not reset the connection .



Here is my test results . i would test with 123.com ip address which is
69.58.188.49 .






config:
acl test dst 69.58.188.49
deny_info TCP_RESET test
http_reply_access deny test 


=====
test type:
telnet 123.com 80
GET / HTTP/1.1
host: 123.com


RESULT:
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Sun, 28 Aug 2016 08:45:23 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 5
X-Cache: MISS from cache1
X-Cache-Lookup: MISS from cache1:3128
Connection: keep-alive

reset

note:telnet will not disconnect until i hit few Enter

=====
test type:
telnet 123.com 80
sgsdgsdgsdgsdg

RESULT:
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Sun, 28 Aug 2016 09:00:12 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 0
X-Cache: MISS from cache1
X-Cache-Lookup: NONE from cache1:3128
Connection: close



Connection to host lost.


====================================================================

config:
acl test dst 69.58.188.49
deny_info TCP_RESET test
adapted_http_access deny test


=====
test type:
telnet 123.com 80
GET / HTTP/1.1
host: 123.com



RESULT:
note:empty, just disconnects the telnet

=====
test type:
telnet 123.com 80
sgsdgsdgsdgsdg

RESULT:
HTTP/1.1 400 Bad Request
Server: squid
Mime-Version: 1.0
Date: Sun, 28 Aug 2016 08:56:14 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 0
X-Cache: MISS from cache1
X-Cache-Lookup: NONE from cache1:3128
Connection: close



Connection to host lost.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679222.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Sun Aug 28 09:56:39 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sun, 28 Aug 2016 12:56:39 +0300
Subject: [squid-users] squid with random outgoing ip from pool of 1000
	ips
In-Reply-To: <D61E7137-EA75-4142-A2FC-25E10C5417BF@netstream.ps>
References: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>
 <579f8215-35f7-57ef-0f4d-be68f0a22da1@measurement-factory.com>
 <D61E7137-EA75-4142-A2FC-25E10C5417BF@netstream.ps>
Message-ID: <8FBBE5B3-4C18-47C2-A8BE-59ACD625E133@netstream.ps>

just to tell you 
i updated the acl as below :
acl half10001 random 0.0009980010000000
acl half10006 random 0.0009930209650350
acl half10011 random 0.0009880657804942
acl half10020 random 0.0009792086759647
acl half10037 random 0.0009626946373158
acl half10043 random 0.0009569328906720
acl half10059 random 0.0009417362622232
acl half10079 random 0.0009230793978373
acl half10082 random 0.0009203129279589
acl half10084 random 0.0009184732224159
acl half10094 random 0.0009093297114627
acl half10098 random 0.0009056978449587
acl half10109 random 0.0008957848329039
acl half10113 random 0.0008922070646991
acl half10114 random 0.0008913148576344
acl half10122 random 0.0008842092457380
acl half10137 random 0.0008710385479118
acl half10154 random 0.0008563487636013
acl half10168 random 0.0008444374977929
acl half10171 random 0.0008419067177676
acl half10173 random 0.0008402237462388
acl half10218 random 0.0008032337005613
acl half10221 random 0.0008008264083574
acl half10222 random 0.0008000255819491
acl half10223 random 0.0007992255563671
acl half10227 random 0.0007960334462989
acl half10247 random 0.0007802631200941
acl half10248 random 0.0007794828569740
.
.
.
.
.


but the rotation is very bad and the outgoing ip now is the ip that is on my eth0 ipv6 address  only .
i mean the lists above not working at all and all request go with  1 ipv6 which is the ip that is on my eth0 address .


what wrong did i do ?



> On Aug 28, 2016, at 11:04 AM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:
> 
> thanks for reply 
> 
> how about the length of the number?
> 
> 1/1000 to which digits should i round ??
> 
> 4 or 5 6 digits ?
> 
> 
> 
> AS AN EXAMPLE the 1/1000 probabilities will have the acls as below :
> 
> 
> 0.001 0.000999 0.000998001 0.000997002999 0.000996005996001
> 
> 
> the question is how many digits should i round ?
> 
> will squid understand the long digits ?
> 
> 
> cheers
> 
> 
>> On Aug 28, 2016, at 2:38 AM, Alex Rousskov <rousskov at measurement-factory.com <mailto:rousskov at measurement-factory.com>> wrote:
>> 
>> On 08/27/2016 04:34 PM, --Ahmad-- wrote:
>> 
>>> i guess i need to create probability 1/1000 for each ip.
>> 
>> Yes, but that is _not_ the same as 1/1000 probability for each
>> tcp_outgoing_address rule, unfortunately. tcp_outgoing_address rules are
>> evaluated top to bottom until the first matches. If you have N rules and
>> each rule has a 1/N probability of a match in isolation, then you will
>> get the following probabilities of a match when the rules are combined:
>> 
>>  rule #0: 1/N   -- good!
>>  rule #1: (1-1/N) * 1/N  -- which is not 1/N
>>  rule #2: (1-1/N) * (1-1/N) * 1/N  -- even less 1/N than rule #2 was
>>  rule #3: (1-1/N) * (1-1/N) * (1-1/N) * 1/N  -- and getting worse!
>>  ...
>> 
>> To simplify equations, let me denote 1/N as p and (1-1/N) as q. With
>> your incorrect 1/N ACLs, you get the following probabilities (I am just
>> rewriting the above using p and q):
>> 
>>  rule #0: p
>>  rule #1: q * p
>>  rule #2: q*q * p
>>  rule #3: q*q*q * p
>>  ...
>> 
>> If you are still unsure, consider the simple case of just 2 rules
>> (instead of 1000). You want the second rule to match 50% of the time. If
>> you give the second rule ACL the same 1/2 probability of a match, then
>> the second rule will only match 1/4 of the time because it will match
>> only when the previous rule did _not_ match (1/2) _and_ when its own ACL
>> matched (1/2): 1/2*1/2 = 1/4.
>> 
>> 
>> To compensate for the cumulative effect of rules evaluation, you need
>> rule i to have p/(q^i) probability of a match (where "q^i" is "q to the
>> power of i"). With that, you will always get the same probability of a
>> match (p) for each rule when that rule is evaluated:
>> 
>>  rule #0: p
>>  rule #1: q * p/q = p
>>  rule #2: q*q * p/(q*q) = p
>>  rule #3: q*q*q * p/(q*q*q) = p
>>  ...
>>  rule #998: q^998 * p/(q^998) = p
>> 
>> To avoid uncertainty, the last rule (rule #999 in the above notation)
>> should use the "all" ACL (i.e., it will always match).
>> 
>> 
>>> how can i create the randomized acls ???
>> 
>> I suggest writing a script that generates 999 ACLs with correct p/(q^i)
>> probability and the corresponding tcp_outgoing_address lines to match them.
>> 
>> Please note that computing ~500 random ACL matches for each outgoing
>> Squid connection (or is it each request?) is not going to be
>> instantaneous! If you are worried about Squid performance, then you may
>> want to add custom Squid code to select a random or round-robin IP
>> address out of a pool of 1000 addresses instead.
>> 
>> [ It is not going to be easy, but if you do it right, the same new
>> configuration interface and underlying code can then be applied to other
>> similar tasks in Squid (e.g., selecting one of several load-balanced
>> ICAP services). In that case, it would be a welcomed feature that may be
>> officially accepted. If you decide to make this generally useful, then I
>> recommend getting your configuration design pre-approved on squid-dev
>> before you implement anything (or before you pay somebody else to
>> implement it)! ]
>> 
>> 
>>> is my settings below is correct ??
>> 
>> No. Your ACL(s) and rule probabilities are wrong. See above.
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/448d80c1/attachment.htm>

From uhlar at fantomas.sk  Sun Aug 28 11:34:31 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 28 Aug 2016 13:34:31 +0200
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
Message-ID: <20160828113431.GA8946@fantomas.sk>

On 27.08.16 01:10, Yuri Voinov wrote:
>http://wiki.squid-cache.org/ConfigExamples/DynamicContent/YouTube/Discussion?highlight=%28Youtube%29
>
>
>26.08.2016 23:54, Matus UHLAR - fantomas ?????:
>> On 26.08.16 03:16, Yuri Voinov wrote:
>>> Everything can be much easier. Google Streaming video is not cacheable.
>>> Absolutely.  If users are watching the same video, each time it is
>>> downloaded from the outside. Slowly and sadly.
>>
>> could something like collapsed forwarding solve this problem?

not videos, streaming. Streamed content should be (at least hypotetically)
possible to receive once, send many times.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
10 GOTO 10 : REM (C) Bill Gates 1998, All Rights Reserved!


From yvoinov at gmail.com  Sun Aug 28 15:59:53 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 28 Aug 2016 21:59:53 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <20160828113431.GA8946@fantomas.sk>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
Message-ID: <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


28.08.2016 17:34, Matus UHLAR - fantomas ?????:
> On 27.08.16 01:10, Yuri Voinov wrote:
>>
http://wiki.squid-cache.org/ConfigExamples/DynamicContent/YouTube/Discussion?highlight=%28Youtube%29
>>
>>
>> 26.08.2016 23:54, Matus UHLAR - fantomas ?????:
>>> On 26.08.16 03:16, Yuri Voinov wrote:
>>>> Everything can be much easier. Google Streaming video is not cacheable.
>>>> Absolutely.  If users are watching the same video, each time it is
>>>> downloaded from the outside. Slowly and sadly.
>>>
>>> could something like collapsed forwarding solve this problem?
>
> not videos, streaming. Streamed content should be (at least hypotetically)
> possible to receive once, send many times.
So?

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXwwp4AAoJENNXIZxhPexGZSUIAITHcsi3CltBKxizehM8EQ5D
RBZ7NnBI88dF1ATfn5x9sW0/4m96G/iXjUOrpa8sNLDbnXaRDb+53RtNR1rs4dSb
pKGa5YvxI218t5LPAGfSMuDpjIkmgnE3/4cDiubasqgIt0yBva40tdWoGjkfxdZJ
ADbmO23EUQ328XNWR+pr+64CegpxeBHtIav1YR1oMJVDRmhVoVZWBc6e+hzEJYfV
jAUbDxZp9Viw/05XInhadcR+l+tCBAjY8uGR1JsVk3FU2EpOxj4RLsnCU27Xng4q
aTwcd3daT+dgEMjYnoOnwFd42oWQT2EA6us7reH8y8f0lMCm8i+Iiwx1J4Rj7Lg=
=9iXx
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/f395dae4/attachment.key>

From yvoinov at gmail.com  Sun Aug 28 16:39:04 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 28 Aug 2016 22:39:04 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
Message-ID: <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


28.08.2016 21:59, Yuri Voinov ?????:
>
>
>
> 28.08.2016 17:34, Matus UHLAR - fantomas ?????:
> > On 27.08.16 01:10, Yuri Voinov wrote:
> >>
>
http://wiki.squid-cache.org/ConfigExamples/DynamicContent/YouTube/Discussion?highlight=%28Youtube%29
> >>
> >>
> >> 26.08.2016 23:54, Matus UHLAR - fantomas ?????:
> >>> On 26.08.16 03:16, Yuri Voinov wrote:
> >>>> Everything can be much easier. Google Streaming video is not
cacheable.
> >>>> Absolutely.  If users are watching the same video, each time it is
> >>>> downloaded from the outside. Slowly and sadly.
> >>>
> >>> could something like collapsed forwarding solve this problem?
>
> > not videos, streaming. Streamed content should be (at least
hypotetically)
> > possible to receive once, send many times.
> So?
Streamed content is always files. Generally with the same chunk size.
With fixed length.
Only YT encrypt every chunk, so it can't be cached in any way. Another
streamed content can be cached with store-ID.

Where is collapsed forwarding here?
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXwxOnAAoJENNXIZxhPexGbR0H/1lFeUXDAjbY3jeXKDfyeP8o
FBUE5nAhYHCKbdZU+VYLMcm+p0C/t4x59XwjI455gEZZ5vTdNhx/JT+/kQR/AcDc
klwKnkXIvDoxHuxvTrBzoMtlTjnZ4ZLHaEHvv7FoBp4dkY3Sptbzxt6Q2LM9/h9K
ssGSbvPYxuUrNDqc35B9pACxyxhRWWZfl6k/OKPA++Kj8smLiPnd7Hbc84wOm3gA
Y7/3W0N/Qo1p2E/KcxVnkFrd2Nhbe7Jt0yLTRew/5046hSxKEDf37ykP8gFrdUcH
9gbM/gakXRjfrdhLUJnKBDQPnlVqKroAOtN6aKgvhraCbIj9z0CgmkbG9r8X/lE=
=RuBT
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/20c304e5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/20c304e5/attachment.key>

From yvoinov at gmail.com  Sun Aug 28 16:39:53 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 28 Aug 2016 22:39:53 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
Message-ID: <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


28.08.2016 22:39, Yuri Voinov ?????:
>
>
>
> 28.08.2016 21:59, Yuri Voinov ?????:
>
>
>
>
>
>
>       > 28.08.2016 17:34, Matus UHLAR - fantomas ?????:
>
>       > > On 27.08.16 01:10, Yuri Voinov wrote:
>
>       > >>
>
>
>
http://wiki.squid-cache.org/ConfigExamples/DynamicContent/YouTube/Discussion?highlight=%28Youtube%29
>
>       > >>
>
>       > >>
>
>       > >> 26.08.2016 23:54, Matus UHLAR - fantomas ?????:
>
>       > >>> On 26.08.16 03:16, Yuri Voinov wrote:
>
>       > >>>> Everything can be much easier. Google
>       Streaming video is not cacheable.
>
>       > >>>> Absolutely.  If users are watching the same
>       video, each time it is
>
>       > >>>> downloaded from the outside. Slowly and
>       sadly.
>
>       > >>>
>
>       > >>> could something like collapsed forwarding solve
>       this problem?
>
>
>
>       > > not videos, streaming. Streamed content should be (at
>       least hypotetically)
>
>       > > possible to receive once, send many times.
>
>       > So?
> Streamed content is always files. Generally with the same chunk size.
With fixed length.
> Only YT encrypt every chunk, so it can't be cached in any way. Another
streamed content can be cached with store-ID.
Sorry - Only YT encrypt every chunk *URL*, so it can't be cached in any way.
>
> Where is collapsed forwarding here?
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXwxPZAAoJENNXIZxhPexGS30H/jKSWUd/X0fdJ7RxYHF1PtA4
D4cW9mqIQJUxKCA8YZkTN0PioWPpwWB6x/ZbSRUnrtcAp/350hG6N8O3hm3k4WlT
XXvPPSfwvAdyuWNA9QHROmfP6z1RMvnnf6avjA3HDdNqmFM2CFYWaZDphWsEEHVa
256etwQAd6Ck7e5jOLqtLcpBZZ4Nol0c9L8x4Ids2xfVMO3FvBP6QAO9uBeEKt/o
cgCgoPCWSFSDlgiQFb0Dk8Js5VfBY4dVau+CsgN+w7L4RJUBT4pT1DTWnxzTOhO0
Z4jvH3MDEtBRm9b3ewWEmN/ZWUVE/fP3BgNevD9fSrDvQyuTLbY7hx2xosHBcGY=
=WNI8
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/0e392b8d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/0e392b8d/attachment.key>

From squid3 at treenet.co.nz  Sun Aug 28 16:48:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 Aug 2016 04:48:16 +1200
Subject: [squid-users] cache object with vary
In-Reply-To: <1472345785055-4679220.post@n4.nabble.com>
References: <1472345785055-4679220.post@n4.nabble.com>
Message-ID: <dfa9a967-d6a6-b874-e1d2-4725dd1e70e7@treenet.co.nz>

On 28/08/2016 12:56 p.m., joe wrote:
> is this bug or its made to work like that
> lets say we have object in cache name 000000A5
> url.com/some.js
> vary=accept-encoding="gzip"
> 
> if some browser get the same object
> url.com/some.js
> vary=accept-encoding="deflate"
> 
> the md5 key wont match 

Correct.

> and it delete the old cached object with
> accept-encoding="gzip" and replace with
> new one with vary=accept-encoding="deflate" and prosess as TCP_MISS

Incorrect.

The first thing Squid does is lookup the URL (only). That finda a 'vark
marker' object which tels Squid the Vary header pattern to append to the
hash key and do another lookup for that.

The amended hash key for the second query finds no object ==> a MISS.
Period.

The "gzip" object existence or absence is not related nor touched.

> 
> that will result in "varyEvaluateMatch: Oops. Not a Vary match on second
> attempt
> no match and the code in client_side.cc
> return VARY_CANCEL

IF:
 * the second lookup with the amended hash key *did* find an object, and
 * it was for the same URL, and
 * it has no Vary header;
then a warning message (the above?) is output and the found object will
be replaced with whatever comes back from the MISS resolving actions.


I think you can get yourself into this type of situation when using
Store-ID in ways prohibited by the Store-ID design.

 Requirement #1 for Store-ID is that all objects found by the custom ID
key are identical.

 Variants are non-identical by definition. So at least one variant of
objects that Vary is not going to be identical to objects that lack Vary!


You can also encounter it with SMP workers at times. Since the workers
are processing more traffic than ever before the churn and key hash
collisions rate is potentially greater.


> 
> and in client_side_reply.cc
> 
>     case VARY_CANCEL:
>         /* varyEvaluateMatch found a object loop. Process as miss */
>         debugs(88, DBG_IMPORTANT, "clientProcessHit: Vary object loop!");

NP: the above statements may or may not be true. The code was written a
long time ago and things around it have changed a lot in the meantime.

>         http->logType = LOG_TCP_MISS; // we lack a more precise LOG_*_MISS
> code
>         processMiss();
>         return;
> 
> the way it should be instead of replacing the existing obj  should be
> another object with the 
> new vary
> shuld be 2 file 000000A5
> and    000000A6     example each one has different vary to match the correct
> obj if its gzip or ident or deflate or with useragent
> wen vary not matching shuld be new obj file to be saved as diferent cache
> name 000000A7
> so it match the correct object name with its vary
> 

If the above wasn't clear enough. This is how squid does it:

 key: MD5("http://url.com/some.js")
 data: vary-marker object ("Vary:Accept-Encoding", ...)

 key: MD5("http://url.com/some.js" + "accept-encoding=")
 data: no- Accept-Encoding variant response

 key: MD5("http://url.com/some.js" + "accept-encoding=identity")
 data: "identity" variant response

 key: MD5("http://url.com/some.js" + "accept-encoding=gzip")
 data: "gzip" variant response

 key: MD5("http://url.com/some.js" + "accept-encoding=deflate")
 data: "deflate" variant response

 key: MD5("http://url.com/some.js" + "accept-encoding=deflate,gzip")
 data: "deflate,gzip" variant response

 key: MD5("http://url.com/some.js" + "accept-encoding=gzip,deflate")
 data: "gzip,deflate" variant response

 ... and so on for all possible unique strings that could be sent in
Accept-Encoding.


If one of those 'data' objects contains a 'wrong' response object. The
transaction encountering it MISS'es  / VARY_CANCEL and that store
location gets updated with correct content resulting from the server fetch.

Amos



From chip_pop at hotmail.com  Sun Aug 28 17:36:11 2016
From: chip_pop at hotmail.com (joe)
Date: Sun, 28 Aug 2016 10:36:11 -0700 (PDT)
Subject: [squid-users] cache object with vary
In-Reply-To: <dfa9a967-d6a6-b874-e1d2-4725dd1e70e7@treenet.co.nz>
References: <1472345785055-4679220.post@n4.nabble.com>
 <dfa9a967-d6a6-b874-e1d2-4725dd1e70e7@treenet.co.nz>
Message-ID: <1472405771378-4679229.post@n4.nabble.com>

>If the above wasn't clear enough. This is how squid does it: 

> key: MD5("http://url.com/some.js") 
>data: vary-marker object ("Vary:Accept-Encoding", ...) 

 >key: MD5("http://url.com/some.js" + "accept-encoding=") 
 >data: no- Accept-Encoding variant response 

 >key: MD5("http://url.com/some.js" + "accept-encoding=identity") 
 >data: "identity" variant response 

 >key: MD5("http://url.com/some.js" + "accept-encoding=gzip") 
 >data: "gzip" variant response 

 >key: MD5("http://url.com/some.js" + "accept-encoding=deflate") 
 >data: "deflate" variant response 

 >key: MD5("http://url.com/some.js" + "accept-encoding=deflate,gzip") 
 >data: "deflate,gzip" variant response 

> key: MD5("http://url.com/some.js" + "accept-encoding=gzip,deflate") 
 >data: "gzip,deflate" variant response 
right so those example they shuld be separet file right depend on vary key
match
mmmmmmmmmmmmmmmm is that right ??
must be as you sayd the store-id then doing some funy things
im going to disable store id and test



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/cache-object-with-vary-tp4679220p4679229.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From huaraz at moeller.plus.com  Sun Aug 28 18:24:14 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sun, 28 Aug 2016 19:24:14 +0100
Subject: [squid-users] Trouble negotiate_kerberos_auth
In-Reply-To: <CA+0TdyqEAt4L5KO4zrJNJ1aUe64mY2Re7z95KFdqW7Y8SV_qbg@mail.gmail.com>
References: <CA+0TdyqEAt4L5KO4zrJNJ1aUe64mY2Re7z95KFdqW7Y8SV_qbg@mail.gmail.com>
Message-ID: <npva8g$nni$1@blaine.gmane.org>


HI Marcio,

  The helper need a Kerberos token as input.  Please have a look at test_negotiate_auth.sh  which is in src/auth/negotiate/kerberos of the trunk version. The squid hostname must match the entry in your keytab and you must have done kinit to authenticate against a Kerberos server (e.g. AD) as user first.

Regards
Markus 


"Marcio Demetrio Bacci" <marciobacci at gmail.com> wrote in message news:CA+0TdyqEAt4L5KO4zrJNJ1aUe64mY2Re7z95KFdqW7Y8SV_qbg at mail.gmail.com...
I have trouble to authenticate Squid3 with kerberos in Samba4 domain. I'm using CentOS 7 and Squid 3.3.8 (yum install squid)


When I type the bellow command in terminal: 
/usr/lib64/squid/negotiate_kerberos_auth -d -i -s HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
john xyz at 12345

I have the following error:
negotiate_kerberos_auth.cc(315): pid=6364 :2016/08/27 10:44:33| negotiate_kerberos_auth: DEBUG: Got 'john xyz at 12345' from squid (length: 14).
negotiate_kerberos_auth.cc(362): pid=6364 :2016/08/27 10:44:33| negotiate_kerberos_auth: ERROR: Invalid request [john xyz at 12345]
BH invalid request 


Here are my files configuration:

/etc/krb5.conf
[libdefaults]
    default_realm = CMS.ENSINO.BR
[realms]
    CMS.ENSINO.BR = {
    kdc = dc1.cms.ensino.br:88
    admin_server = dc1.cms.ensino.br
    default_domain = CMS.ENSINO.BR 
    }
[domain_realm]
    .cms.ensino.br = CMS.ENSINO.BR
    cms.ensino.br = CMS.ENSINO.BR



Keytab name: FILE:/etc/krb5.keytab
KVNO Principal
---- --------------------------------------------------------------------------
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 host/PROXY at CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 PROXY$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR
   1 HTTP/PROXY at CMS.ENSINO.BR


Keytab name: FILE:/etc/squid/PROXY.keytab
KVNO Principal
---- --------------------------------------------------------------------------
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 proxy-k$@CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
   1 host/proxy.cms.ensino.br at CMS.ENSINO.BR


/etc/sysconfig/squid
# default squid options
SQUID_OPTS=""
# Time to wait for Squid to shut down when asked. Should not be necessary
# most of the time.
SQUID_SHUTDOWN_TIMEOUT=100
# default squid conf file
SQUID_CONF="/etc/squid/squid.conf"

KRB5_KTNAME=/etc/squid/PROXY.keytab
export KRB5_KTNAME



kinit and klist commands are OK.


Best Regards,


M?rcio




--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/0010a025/attachment.htm>

From rousskov at measurement-factory.com  Sun Aug 28 23:28:05 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 28 Aug 2016 17:28:05 -0600
Subject: [squid-users] squid with random outgoing ip from pool of 1000
	ips
In-Reply-To: <D61E7137-EA75-4142-A2FC-25E10C5417BF@netstream.ps>
References: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>
 <579f8215-35f7-57ef-0f4d-be68f0a22da1@measurement-factory.com>
 <D61E7137-EA75-4142-A2FC-25E10C5417BF@netstream.ps>
Message-ID: <865eeb7d-ee06-749b-a45c-650f54435145@measurement-factory.com>

On 08/28/2016 02:04 AM, --Ahmad-- wrote:

> how about the length of the number?
> 
> 1/1000 to which digits should i round ??
> 
> 4 or 5 6 digits ?

I would start with 10 digits or the maximum precision that your
ACL-calculation program allows and decrease the number of digits if
Squid cannot parse the generated probability.

> will squid understand the long digits ?

Yes, but probably up to an [unknown to me] point.

HTH,

Alex.



>> To compensate for the cumulative effect of rules evaluation, you need
>> rule i to have p/(q^i) probability of a match



From rousskov at measurement-factory.com  Sun Aug 28 23:38:10 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 28 Aug 2016 17:38:10 -0600
Subject: [squid-users] squid with random outgoing ip from pool of 1000
	ips
In-Reply-To: <8FBBE5B3-4C18-47C2-A8BE-59ACD625E133@netstream.ps>
References: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>
 <579f8215-35f7-57ef-0f4d-be68f0a22da1@measurement-factory.com>
 <D61E7137-EA75-4142-A2FC-25E10C5417BF@netstream.ps>
 <8FBBE5B3-4C18-47C2-A8BE-59ACD625E133@netstream.ps>
Message-ID: <8814f0a6-fae9-0483-d1fc-014b3d533dea@measurement-factory.com>

On 08/28/2016 03:56 AM, --Ahmad-- wrote:

> the rotation is very bad and the outgoing ip now is the ip that is
> on my eth0 ipv6 address  only .
> i mean the lists above not working at all and all request go with  1
> ipv6 which is the ip that is on my eth0 address .
> 
> 
> what wrong did i do ?

I do not know. I recommend the following procedure:

1. Start with just one outgoing IP address (that is not the default!)
and make that work well first. Does all from-Squid traffic originate at
that alternative IP address?

2. Move to two outgoing IP addresses (none of which is the default!) and
make that work well. Do you get a nice 50/50 distribution?

3. Use three IP addresses. This step will allow you to test your script.
Again, make sure everything works very well before you proceed any
further. Do measure the actual IP probabilities for a large number of
transactions to verify that your configuration is correct. You should
see ~33% of transactions using each alternative IP.

4. Move on to 1000 IP addresses. Check again.

Alex.



From rousskov at measurement-factory.com  Sun Aug 28 23:53:26 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 28 Aug 2016 17:53:26 -0600
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1472375429698-4679222.post@n4.nabble.com>
References: <1472040642333-4679111.post@n4.nabble.com>
 <1472042347026-4679126.post@n4.nabble.com>
 <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
 <1472375429698-4679222.post@n4.nabble.com>
Message-ID: <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>

On 08/28/2016 03:10 AM, Omid Kosari wrote:
> Alex Rousskov wrote
>> I understand that it works for regular requests. Does it also work (i.e.,
>> does Squid reset the connection) when handling a non-HTTP request on port 80?

> No , when the request is non-HTTP it does not reset the connection .

Great. Now please go back to the simpler configuration I asked you to
test some time ago:

  http_reply_access deny all
  deny_info TCP_RESET all

Does that work for non-HTTP request on port 80?



> config:
> acl test dst 69.58.188.49
> deny_info TCP_RESET test
> http_reply_access deny test 
> 
> 
> =====
> test type:
> telnet 123.com 80
> GET / HTTP/1.1
> host: 123.com
> 
> 
> RESULT:
> HTTP/1.1 403 Forbidden

I am confused. Earlier you said "As i mention before the deny_info works
in other configs" and gave a very similar configuration example with
dstdomain ACL. Now you are showing that this example does _not_ work
even with regular requests (you are getting HTTP headers from Squid
instead of a TCP connection reset). Am I missing something?



> config:
> acl test dst 69.58.188.49
> deny_info TCP_RESET test
> adapted_http_access deny test
> 
> 
> =====
> test type:
> telnet 123.com 80
> GET / HTTP/1.1
> host: 123.com
> 
> 
> 
> RESULT:
> note:empty, just disconnects the telnet

OK, this works as expected, but we need to get it working for the
http_reply_access IMO.


> =====
> test type:
> telnet 123.com 80
> sgsdgsdgsdgsdg
> 
> RESULT:
> HTTP/1.1 400 Bad Request
> Server: squid
> Mime-Version: 1.0
> Date: Sun, 28 Aug 2016 08:56:14 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 0
> X-Cache: MISS from cache1
> X-Cache-Lookup: NONE from cache1:3128
> Connection: close

OK, this does not work, as expected (there is no matching request and/or
adapted_http_access is not evaluated at all in this case). You need
http_reply_access.

Alex.



From marciobacci at gmail.com  Mon Aug 29 01:58:25 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Sun, 28 Aug 2016 22:58:25 -0300
Subject: [squid-users] Trouble negotiate_kerberos_auth
In-Reply-To: <npva8g$nni$1@blaine.gmane.org>
References: <CA+0TdyqEAt4L5KO4zrJNJ1aUe64mY2Re7z95KFdqW7Y8SV_qbg@mail.gmail.com>
 <npva8g$nni$1@blaine.gmane.org>
Message-ID: <CA+0Tdyr+2jEL7p09yrtJQ516M-2uE-q=Zayd3F5J0A=25zcacQ@mail.gmail.com>

Hi Markus, thank you for help me.

When I type the klist command, the result is:

Ticket cache: FILE:/tmp/krb5cc_0
Default principal: robert at CMS.ENSINO.BR
Valid starting       Expires              Service principal
28-08-2016 22:40:53  29-08-2016 08:40:53  krbtgt/CMS.ENSINO.BR at CMS.ENSINO.BR
    renew until 29-08-2016 22:40:41

But, I have the following result to command bellow:
/usr/lib64/squid/negotiate_kerberos_auth_test proxy.cms.ensino.br| awk
'{sub(/Token:/,"YR"); print $0}END{print "QQ"}' |
/usr/lib64/squid/negotiate_kerberos_auth -r -s HTTP/proxy.cms.ensino.br

Result:
TT
oYGbMIGYoAMKAQGhCAYGKwYBBQIFooGGBIGDBQEwFKESBBBDTUIuRU5TSU5PLkVCLkJSfmkwZ6ADAgEFoQMCAR6iERgPMjAxNjA4MjkwMTM2MDVaowUCAwK7P6QRGA8yMDE2MDgyOTAxMzYwNVqlBQIDBhpppgMCAQepFRsTPHVuc3BlY2lmaWVkIHJlYWxtPqoLMAmgAwIBAKECMAA=
BH quit command


The HTTP/proxy.cms.ensino.br is in keytab files

I don't have the "test_negotiate_auth.sh" file in
src/auth/negotiate/kerberos, but I have
/usr/lib64/squid/negotiate_kerberos_auth_test, thus I'm using it.

My Linux distribution is CentOS 7

Regards,

M?rcio




2016-08-28 15:24 GMT-03:00 Markus Moeller <huaraz at moeller.plus.com>:

>
> HI Marcio,
>
>   The helper need a Kerberos token as input.  Please have a look at
> test_negotiate_auth.sh  which is in src/auth/negotiate/kerberos of the
> trunk version. The squid hostname must match the entry in your keytab and
> you must have done kinit to authenticate against a Kerberos server (e.g.
> AD) as user first.
>
> Regards
> Markus
>
>
> "Marcio Demetrio Bacci" <marciobacci at gmail.com> wrote in message news:CA+
> 0TdyqEAt4L5KO4zrJNJ1aUe64mY2Re7z95KFdqW7Y8SV_qbg at mail.gmail.com...
> I have trouble to authenticate Squid3 with kerberos in Samba4 domain. I'm
> using CentOS 7 and Squid 3.3.8 (yum install squid)
>
> When I type the bellow command in terminal:
> /usr/lib64/squid/negotiate_kerberos_auth -d -i -s HTTP/
> proxy.cms.ensino.br at CMS.ENSINO.BR
> john xyz at 12345
>
> I have the following error:
> negotiate_kerberos_auth.cc(315): pid=6364 :2016/08/27 10:44:33|
> negotiate_kerberos_auth: DEBUG: Got 'john xyz at 12345' from squid (length:
> 14).
> negotiate_kerberos_auth.cc(362): pid=6364 :2016/08/27 10:44:33|
> negotiate_kerberos_auth: ERROR: Invalid request [john xyz at 12345]
> BH invalid request
>
>
> Here are my files configuration:
>
> /etc/krb5.conf
> [libdefaults]
>     default_realm = CMS.ENSINO.BR
> [realms]
>     CMS.ENSINO.BR = {
>     kdc = dc1.cms.ensino.br:88
>     admin_server = dc1.cms.ensino.br
>     default_domain = CMS.ENSINO.BR
>     }
> [domain_realm]
>     .cms.ensino.br = CMS.ENSINO.BR
>     cms.ensino.br = CMS.ENSINO.BR
>
>
>
> Keytab name: FILE:/etc/krb5.keytab
> KVNO Principal
> ---- ------------------------------------------------------------
> --------------
>    1 proxy-k$@CMS.ENSINO.BR
>    1 proxy-k$@CMS.ENSINO.BR
>    1 proxy-k$@CMS.ENSINO.BR
>    1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/PROXY at CMS.ENSINO.BR
>    1 host/PROXY at CMS.ENSINO.BR
>    1 host/PROXY at CMS.ENSINO.BR
>    1 host/PROXY at CMS.ENSINO.BR
>    1 host/PROXY at CMS.ENSINO.BR
>    1 PROXY$@CMS.ENSINO.BR
>    1 PROXY$@CMS.ENSINO.BR
>    1 PROXY$@CMS.ENSINO.BR
>    1 PROXY$@CMS.ENSINO.BR
>    1 PROXY$@CMS.ENSINO.BR
>    1 proxy-k$@CMS.ENSINO.BR
>    1 proxy-k$@CMS.ENSINO.BR
>    1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 HTTP/PROXY at CMS.ENSINO.BR
>    1 HTTP/PROXY at CMS.ENSINO.BR
>    1 HTTP/PROXY at CMS.ENSINO.BR
>    1 HTTP/PROXY at CMS.ENSINO.BR
>    1 HTTP/PROXY at CMS.ENSINO.BR
>
>
> Keytab name: FILE:/etc/squid/PROXY.keytab
> KVNO Principal
> ---- ------------------------------------------------------------
> --------------
>    1 proxy-k$@CMS.ENSINO.BR
>    1 proxy-k$@CMS.ENSINO.BR
>    1 proxy-k$@CMS.ENSINO.BR
>    1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
>    1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
>
>
> /etc/sysconfig/squid
> # default squid options
> SQUID_OPTS=""
> # Time to wait for Squid to shut down when asked. Should not be necessary
> # most of the time.
> SQUID_SHUTDOWN_TIMEOUT=100
> # default squid conf file
> SQUID_CONF="/etc/squid/squid.conf"
>
> KRB5_KTNAME=/etc/squid/PROXY.keytab
> export KRB5_KTNAME
>
>
> kinit and klist commands are OK.
>
> Best Regards,
>
> M?rcio
>
>
> ------------------------------
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160828/2c7658a1/attachment.htm>

From chip_pop at hotmail.com  Mon Aug 29 02:33:40 2016
From: chip_pop at hotmail.com (joe)
Date: Sun, 28 Aug 2016 19:33:40 -0700 (PDT)
Subject: [squid-users] cache object with vary
In-Reply-To: <dfa9a967-d6a6-b874-e1d2-4725dd1e70e7@treenet.co.nz>
References: <1472345785055-4679220.post@n4.nabble.com>
 <dfa9a967-d6a6-b874-e1d2-4725dd1e70e7@treenet.co.nz>
Message-ID: <1472438020846-4679235.post@n4.nabble.com>

amos just by switching refresh from chrome to firefox and vice versa
2016/08/29 05:27:46 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.annahar.com/'
'accept-encoding="gzip,%20deflate,%20sdch",
user-agent="Mozilla%2F5.0%20(Windows%20NT%205.1)%20AppleWebKit%2F537.36%20(KHTML,%20like%20Gecko)%20Chrome%2F49.0.2623.112%20Safari%2F537.36"'
2016/08/29 05:27:46 kid1| clientProcessHit: Vary object loop!
2016/08/29 05:27:56 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.annahar.com/'
'accept-encoding="gzip,%20deflate",
user-agent="Mozilla%2F5.0%20(Windows%20NT%205.1%3B%20rv%3A47.0)%20Gecko%2F20100101%20Firefox%2F47.0"'
2016/08/29 05:27:56 kid1| clientProcessHit: Vary object loop!
2016/08/29 05:28:14 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.annahar.com/'
'accept-encoding="gzip,%20deflate,%20sdch",
user-agent="Mozilla%2F5.0%20(Windows%20NT%205.1)%20AppleWebKit%2F537.36%20(KHTML,%20like%20Gecko)%20Chrome%2F49.0.2623.112%20Safari%2F537.36"'
2016/08/29 05:28:14 kid1| clientProcessHit: Vary object loop!
2016/08/29 05:28:26 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.annahar.com/'
'accept-encoding="gzip,%20deflate",
user-agent="Mozilla%2F5.0%20(Windows%20NT%205.1%3B%20rv%3A47.0)%20Gecko%2F20100101%20Firefox%2F47.0"'
2016/08/29 05:28:26 kid1| clientProcessHit: Vary object loop!

without store-id 
squid detect the obj and replace by new one if i switch back to another
browser it dose the same
it should keep the obj in cache for chrome and have new obj save for firefox
if you ar saying they ar 2 diff md5 key but it dose not do that



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/cache-object-with-vary-tp4679220p4679235.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Mon Aug 29 06:14:18 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 29 Aug 2016 09:14:18 +0300
Subject: [squid-users] squid with random outgoing ip from pool of 1000
	ips
In-Reply-To: <8FBBE5B3-4C18-47C2-A8BE-59ACD625E133@netstream.ps>
References: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>
 <579f8215-35f7-57ef-0f4d-be68f0a22da1@measurement-factory.com>
 <D61E7137-EA75-4142-A2FC-25E10C5417BF@netstream.ps>
 <8FBBE5B3-4C18-47C2-A8BE-59ACD625E133@netstream.ps>
Message-ID: <15C8A029-3A81-490F-9295-439406FCA152@netstream.ps>

Ok


but can you confirm me about the list below if its correct ???



should it be like 1/9987 or .088787  formatting ?




acl half10001 random 0.0009980010000000
acl half10006 random 0.0009930209650350
acl half10011 random 0.0009880657804942
acl half10020 random 0.0009792086759647
acl half10037 random 0.0009626946373158
acl half10043 random 0.0009569328906720
acl half10059 random 0.0009417362622232
acl half10079 random 0.0009230793978373
acl half10082 random 0.0009203129279589
acl half10084 random 0.0009184732224159
acl half10094 random 0.0009093297114627
acl half10098 random 0.0009056978449587
acl half10109 random 0.0008957848329039
acl half10113 random 0.0008922070646991
acl half10114 random 0.0008913148576344
acl half10122 random 0.0008842092457380
acl half10137 random 0.0008710385479118
acl half10154 random 0.0008563487636013
acl half10168 random 0.0008444374977929
acl half10171 random 0.0008419067177676
acl half10173 random 0.0008402237462388
acl half10218 random 0.0008032337005613
acl half10221 random 0.0008008264083574
acl half10222 random 0.0008000255819491
acl half10223 random 0.0007992255563671
acl half10227 random 0.0007960334462989
acl half10247 random 0.0007802631200941
acl half10248 random 0.0007794828569740
.
.
.
.
.

> On Aug 28, 2016, at 12:56 PM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:
> 
> just to tell you 
> i updated the acl as below :
> acl half10001 random 0.0009980010000000
> acl half10006 random 0.0009930209650350
> acl half10011 random 0.0009880657804942
> acl half10020 random 0.0009792086759647
> acl half10037 random 0.0009626946373158
> acl half10043 random 0.0009569328906720
> acl half10059 random 0.0009417362622232
> acl half10079 random 0.0009230793978373
> acl half10082 random 0.0009203129279589
> acl half10084 random 0.0009184732224159
> acl half10094 random 0.0009093297114627
> acl half10098 random 0.0009056978449587
> acl half10109 random 0.0008957848329039
> acl half10113 random 0.0008922070646991
> acl half10114 random 0.0008913148576344
> acl half10122 random 0.0008842092457380
> acl half10137 random 0.0008710385479118
> acl half10154 random 0.0008563487636013
> acl half10168 random 0.0008444374977929
> acl half10171 random 0.0008419067177676
> acl half10173 random 0.0008402237462388
> acl half10218 random 0.0008032337005613
> acl half10221 random 0.0008008264083574
> acl half10222 random 0.0008000255819491
> acl half10223 random 0.0007992255563671
> acl half10227 random 0.0007960334462989
> acl half10247 random 0.0007802631200941
> acl half10248 random 0.0007794828569740
> .
> .
> .
> .
> .
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/f5436c3a/attachment.htm>

From belle at bazuin.nl  Mon Aug 29 07:35:38 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Mon, 29 Aug 2016 09:35:38 +0200
Subject: [squid-users] ext_kerberos_ldap_group_acl problem ( 2
 minorbugsmaybe )
In-Reply-To: <nps9en$dm0$1@blaine.gmane.org>
References: <vmime.57bdb617.37c8.575130a1134f9a07@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57c3e5ca.28ab.73ab0c8662c3316a@ms249-lin-003.rotterdam.bazuin.nl>

Hello Markus, 

?

Thank you for the explanation, that helped a lot. 

?

I use the TLS_CACERTFILE in the init script now and that works for me . 

( in debian the /etc/default/squid ?)

?

>>The helper tries to ?authenticate? squid to AD as a user with the found SPN name, so the UPN must be the same as the SPN.? There is no easy way to query what the UPN for the SPN is. 

Ah, this helped identify-ing so other small things to. 

?

>>msktutil (my preferred tool)

Since i try to use only debian packages the msktutil is not available for me. 

?

>>Also msktutil (my preferred tool) creates a machine account not a user account in AD. 

>>The reason I prefer this is that often user accounts have a global password policy e.g. change every 60 days otherwise it will be locked. 

>>machine accounts do not have that limitation. But as I said it is just my preference.

?

Thats not correct in my optionion. A the computer account, works the (almost) same an user account. 

Like a computer account = a user account. 

?

?some pointers :

https://technet.microsoft.com/en-us/library/cc731641(v=ws.11).aspx

https://adsecurity.org/?p=280 

?

I used a seperated user since i wanted to have 2 proxy on 1 service account, but due to the UPS/SPN thing,

thats not options anymore, not thats a problem, I?ll change to add the computer to the samba domain and 

add the UPN/SPN on the computer account where needed.

Which maybe even a better option.

?

Thanks again for you replies. 

?

?

Best regards, 

?

Louis

?

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Markus Moeller
Verzonden: zaterdag 27 augustus 2016 16:52
Aan: squid-users at lists.squid-cache.org
Onderwerp: Re: [squid-users] ext_kerberos_ldap_group_acl problem ( 2 minorbugsmaybe )


?

Hi,


?


?? I would say they are bugs. The first ?issue? is as you say more about understanding the difference between UPN and SPN and how the tools use them.? The helper tries to ?authenticate? squid to AD as a user with the found SPN name, so the UPN must be the same as the SPN.? There is no easy way to query what the UPN for the SPN is. 


?


? Also msktutil (my preferred tool) creates a machine account not a user account in AD. The reason I prefer this is that often user accounts have a global password policy e.g. change every 60 days otherwise it will be locked. machine accounts do not have that limitation. But as I said it is just my preference. 


?


?? Regarding the certifcate check I do not use any ldap.conf settings. I require an export TLS_CACERTFILE=/mydir/myfile.pem?? in the squid startup file.? Maybe in the next version I see how I can determine the right ldap.conf file and check if the CACERTFILE variable is already set.


?


?


Kind regards


Markus


?


?


"L.P.H. van Belle" <belle at bazuin.nl> wrote in message news:vmime.57bdb617.37c8.575130a1134f9a07 at ms249-lin-003.rotterdam.bazuin.nl...




Ok reply to myself so other users know this also.

?

if you create a user for the HTTP services and you dont use msktutil but like me samba-tool or something else. 

?

Read : 

http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos carefully. 

and the clue was this line for me.? 

?

Squid "login" to Windows Active Directory or Unix kdc as user <HTTP/<fqdn-squid>@DOMAIN.COM>. 

This requires Active Directory to have an attribute userPrincipalname set to <HTTP/<fqdn-squid>@DOMAIN.COM>

for the associated acount. This is usaully done by using msktutil. 

?

But this is not done by samba-tools? 

?

samba-tool setup fro squid i used, was as followed. 

samba-tool user create squid1-service --description="Unprivileged user for SQUID1-Proxy Services" --random-password 

samba-tool user setexpiry squid1-service ?noexpiry

samba-tool spn add HTTP/proxy.internal.domain.tld squid1-service

?

?

Now this results in : 

My UPN was set to the username at internal.domain.tld? ( as it should ). 

My SPN was set to HTTP/proxyserver.internal.domain.tld at REALM ( as is should )? 

?

samba-tool spn list squid1-service 

squid1-service

User CN=squid1-service,OU=Service-Accounts,OU=XXXX,DC=XXXXX,DC=XXXX,DC=XX has the following servicePrincipalName:

???????? HTTP/proxy.internal.domain.tld

???????? HTTP/proxy.internal.domain.tld at YOUR.REALM.T

?

?

Now i changed my UPN from username at internal.domain.tld? to the (SPN name)?? HTTP/proxyserver.internal.domain.tld at REALM 

Solved my initial problem. 

This should be in my optionion be changed to search for the SPN in ext_kerberos_ldap_group.

?

Now i have LDAPS messages, see below, im adding the _ldaps SRV records now ,but i dont get why im getting : 

Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

?

Im already having : TLS_CACERT????? /etc/ssl/certs/ca-certificates.crt 

Which contains the needed certs.

?

Did i find 2 small bugs here?? 

Or is this a ?Debian? related thing? 

?

?

Debug output. 

/usr/lib/squid3/ext_kerberos_ldap_group_acl -g internet-mail at YOUR.REALM.TLD -D YOUR.REALM.TLD -N internet-mail at NTDOMAIN -s -i -d

kerberos_ldap_group.cc(278): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Starting version 1.3.1sq

support_group.cc(382): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Group list internet-mail at YOUR.REALM.TLD

support_group.cc(447): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Group internet-mail? Domain YOUR.REALM.TLD

support_netbios.cc(83): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: Netbios list internet-mail at NTDOMAIN

support_netbios.cc(156): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: Netbios name internet-mail? Domain NTDOMAIN

support_lserver.cc(82): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: ldap server list NULL

support_lserver.cc(86): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: No ldap servers defined.

testuser internet-mail

kerberos_ldap_group.cc(371): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: Got User: testuser set default domain: YOUR.REALM.TLD

kerberos_ldap_group.cc(376): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: Got User: testuser Domain: YOUR.REALM.TLD

support_member.cc(63): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: User domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(65): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Found group at domain internet-mail at YOUR.REALM.TLD

support_ldap.cc(898): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setup Kerberos credential cache

support_krb5.cc(127): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set credential cache to MEMORY:squid_ldap_6902

support_krb5.cc(138): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Get default keytab file name

support_krb5.cc(144): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Got default keytab file name /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(158): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Get principal name from keytab /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(169): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Found principal name: HTTP/proxy.internal.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Got principal name HTTP/proxy.internal.domain.tld at YOUR.REALM.TLD

support_krb5.cc(260): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Stored credentials

support_ldap.cc(927): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Initialise ldap connection

support_ldap.cc(931): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable SSL to ldap servers

support_ldap.cc(933): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Canonicalise ldap server name for domain YOUR.REALM.TLD

support_resolv.cc(289): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while resolving service record _ldaps._tcp.YOUR.REALM.TLD with res_search

support_resolv.cc(71): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: res_search: Unknown service record: _ldaps._tcp.YOUR.REALM.TLD

support_resolv.cc(379): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved SRV _ldap._tcp.YOUR.REALM.TLD record to samba-dc2.internal.domain.tld

support_resolv.cc(379): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved SRV _ldap._tcp.YOUR.REALM.TLD record to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 1 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 2 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 3 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 4 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 5 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 6 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(407): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Adding YOUR.REALM.TLD to list

support_resolv.cc(443): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Sorted ldap server names for domain YOUR.REALM.TLD:

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: samba-dc1.internal.domain.tld Port: 389 Priority: 0 Weight: 100

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: samba-dc2.internal.domain.tld Port: 389 Priority: 0 Weight: 100

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: YOUR.REALM.TLD Port: -1 Priority: -2 Weight: -2

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc1.internal.domain.tld:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc2.internal.domain.tld:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server YOUR.REALM.TLD:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(979): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Error during initialisation of ldap connection: No such file or directory

support_ldap.cc(1048): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Error during initialisation of ldap connection: No such file or directory

support_member.cc(76): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: User testuser is not member of group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(91): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Default domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(119): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Default group loop: group at domain internet-mail at YOUR.REALM.TLD

?

?


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/329ecaa2/attachment.htm>

From belle at bazuin.nl  Mon Aug 29 08:11:12 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Mon, 29 Aug 2016 10:11:12 +0200
Subject: [squid-users] ext_kerberos_ldap_group_acl problem
In-Reply-To: <nps8jp$45t$1@blaine.gmane.org>
References: <vmime.57beabe1.6a01.3a47ad2737b8db71@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57c3ee20.3f51.2e4ec2e034dc0020@ms249-lin-003.rotterdam.bazuin.nl>

Hello Markus, 

?

No, im not useing the latest from trunk Atm i use the ( by debian testing ) supplied 3.5.19.

If you want me test test something, im happy to do that for you. 

?

Best regards, 

?

Louis

?

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Markus Moeller
Verzonden: zaterdag 27 augustus 2016 16:38
Aan: squid-users at lists.squid-cache.org
Onderwerp: Re: [squid-users] ext_kerberos_ldap_group_acl problem


?

Hi? Louis,


?


??? I made lately a change in how the SSL certifcate verification is done.? Did you use the latest version from trunk ?? Also set the variable TLS_CACERTFILE in your startup script (e.g. export TLS_CACERTFILE=/etc/mydir/cas.pem ). I do not read any ldap.conf file for this yet.


?


Markus


?


?


?


"L.P.H. van Belle" <belle at bazuin.nl> wrote in message news:vmime.57beabe1.6a01.3a47ad2737b8db71 at ms249-lin-003.rotterdam.bazuin.nl...




Hai, 

?

I?ve added the needed upn, setup the _ldaps in the dns zones, thats ok now. 

The last part, here i need some help.

support_ldap.cc(942): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc1.internal.domain.tld:636

support_ldap.cc(786): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc2.internal.domain.tld:636

support_ldap.cc(786): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=26693 :2016/08/25 08:52:33| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

?

I tried to set 

TLS_CACERTFILE in ldap.conf, didnt work, so dont know how to fix this or there to put these variables. 

?

I need a user to connect to the ldap.? Hi have that one in place. 

I just can find how to put this in this line so i can test this out, but i can only authenticate if the TLS_CACERTFILE is set correctly. 

?

Any suggestions here? 

?

?

Greetz, 

?

Louis


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/06d53cde/attachment.htm>

From omidkosari at yahoo.com  Mon Aug 29 13:40:56 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Mon, 29 Aug 2016 06:40:56 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>
References: <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
 <1472375429698-4679222.post@n4.nabble.com>
 <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>
Message-ID: <1472478056062-4679239.post@n4.nabble.com>

Alex Rousskov wrote
> On 08/28/2016 03:10 AM, Omid Kosari wrote:
>> Alex Rousskov wrote
>>> I understand that it works for regular requests. Does it also work
>>> (i.e.,
>>> does Squid reset the connection) when handling a non-HTTP request on
>>> port 80?
> 
>> No , when the request is non-HTTP it does not reset the connection .
> 
> Great. Now please go back to the simpler configuration I asked you to
> test some time ago:
> 
>   http_reply_access deny all
>   deny_info TCP_RESET all
> 
> Does that work for non-HTTP request on port 80?

config:
http_reply_access deny all
deny_info TCP_RESET all 

=====
test type:
telnet 123.com 80
sgsdgsdgsdgsdg 

RESULT: 
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Mon, 29 Aug 2016 13:30:47 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 5
X-Cache: MISS from cache1
X-Cache-Lookup: NONE from cache1:3128
Connection: close

reset

Connection to host lost.
==========================================




Alex Rousskov wrote
> I am confused. Earlier you said "As i mention before the deny_info works
> in other configs" and gave a very similar configuration example with
> dstdomain ACL. Now you are showing that this example does _not_ work
> even with regular requests (you are getting HTTP headers from Squid
> instead of a TCP connection reset). Am I missing something?

Sorry i mean with adapted_http_access . Maybe my typo 





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679239.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Mon Aug 29 14:14:20 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 29 Aug 2016 08:14:20 -0600
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1472478056062-4679239.post@n4.nabble.com>
References: <9e92825c-20fa-4bb7-0c11-681a6528cc0d@treenet.co.nz>
 <700c771d-45b9-796e-fbca-e2690b96e171@measurement-factory.com>
 <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
 <1472375429698-4679222.post@n4.nabble.com>
 <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>
 <1472478056062-4679239.post@n4.nabble.com>
Message-ID: <14b920b2-67b5-31c8-b85e-96eea33768f0@measurement-factory.com>

On 08/29/2016 07:40 AM, Omid Kosari wrote:
> config:
> http_reply_access deny all
> deny_info TCP_RESET all 
> 
> =====
> test type:
> telnet 123.com 80
> sgsdgsdgsdgsdg 
> 
> RESULT: 
> HTTP/1.1 403 Forbidden
> Server: squid
> Mime-Version: 1.0
> Date: Mon, 29 Aug 2016 13:30:47 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 5
> X-Cache: MISS from cache1
> X-Cache-Lookup: NONE from cache1:3128
> Connection: close
> 
> reset

and

> config:
> acl test dst 69.58.188.49
> deny_info TCP_RESET test
> http_reply_access deny test 
> 
> 
> =====
> test type:
> telnet 123.com 80
> GET / HTTP/1.1
> host: 123.com
> 
> 
> RESULT:
> HTTP/1.1 403 Forbidden
> Server: squid
> Mime-Version: 1.0
> Date: Sun, 28 Aug 2016 08:45:23 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 5
> X-Cache: MISS from cache1
> X-Cache-Lookup: MISS from cache1:3128
> Connection: keep-alive
> 
> reset


Based on v3.5.19 test results you have posted, your Squid does not honor
deny_info when processing http_reply_access. This problem definitely
affects error messages generated by non-HTTP requests and probably
affects regular responses as well. Most likely, Squid modifications
would be required to fix/improve this. The next steps are outlined at

http://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F

Alex.



From rousskov at measurement-factory.com  Mon Aug 29 14:53:40 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 29 Aug 2016 08:53:40 -0600
Subject: [squid-users] squid with random outgoing ip from pool of 1000
	ips
In-Reply-To: <15C8A029-3A81-490F-9295-439406FCA152@netstream.ps>
References: <E3CC5311-14A2-46AD-BD79-0E98BFA9B1BE@netstream.ps>
 <579f8215-35f7-57ef-0f4d-be68f0a22da1@measurement-factory.com>
 <D61E7137-EA75-4142-A2FC-25E10C5417BF@netstream.ps>
 <8FBBE5B3-4C18-47C2-A8BE-59ACD625E133@netstream.ps>
 <15C8A029-3A81-490F-9295-439406FCA152@netstream.ps>
Message-ID: <ae062546-b7ff-fb51-303c-5a5412588ecf@measurement-factory.com>

On 08/29/2016 12:14 AM, --Ahmad-- wrote:

> but can you confirm me about the list below if its correct ???

Sorry, I do not have the time to validate your math.


> should it be like 1/9987 or .088787  formatting ?

According to squid.conf.documented, both should work. However, I
recommend the latter because I am not sure you can express p/(q^i) using
a proper fraction with nominator and denominator small enough for an
integer (assuming Squid uses integers when parsing those -- I have not
checked).

Alex.



From erdosain9 at gmail.com  Mon Aug 29 15:08:18 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 29 Aug 2016 08:08:18 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
References: <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
Message-ID: <1472483298687-4679242.post@n4.nabble.com>

mmmm....... and a last thing with this theme of limit video..... for
facebook????? 
what would be the sysntax???


(i get this on log 


https://video-yyz1-1.xx.fbcdn.net/v/t42.1790-2/14194700_1292914777409287_1273911953_n.mp4?
- HIER_DIRECT/31.13.80.9 video/mp4

)

Thanks!!!!




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679242.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From vibhorsaraswat at gmail.com  Mon Aug 29 15:25:26 2016
From: vibhorsaraswat at gmail.com (Vibhor Saraswat)
Date: Mon, 29 Aug 2016 20:55:26 +0530
Subject: [squid-users] Wget https://www.google.com not download
In-Reply-To: <CAKtg4ZigARiV43CYYwDvHOtL=kFp=xOnvY=oXYrrrzweoRpL4Q@mail.gmail.com>
References: <CAKtg4ZgvjC88tA10+0fy7wwoNTL8ndP3K7WoCXQp6aZSu76_bA@mail.gmail.com>
 <CAKtg4ZiKyPKz1DXO-wiZtCwcR5Tdwu7KsZya9CuFODzVpLGr-g@mail.gmail.com>
 <CAKtg4ZjSbDx49b5-9-e-OLfOENtpG_hX13S2TPK6qhAVjxH__w@mail.gmail.com>
 <CAKtg4ZhgWjz=0LDh4+iM4srXuuXsVGNgTwR_=HfPFE8rop9BrQ@mail.gmail.com>
 <CAKtg4ZiTQNbw7eRrAWZ5wqTKrmpZ0Vy+1MkM4vA3J-6yNY0RdA@mail.gmail.com>
 <CAKtg4Zj7qyVVbtumGshZjrcJvPPrFeBJVY6StmppUtr992sHUQ@mail.gmail.com>
 <CAKtg4ZiXBEqe8q2XRUuyU2sZ0tdR0hODeOPJxqLmfn6nDgoJhw@mail.gmail.com>
 <CAKtg4ZgemYk2UTaA51PvuaSOQQmwfczpsWXv1SvNqMJrWh96eQ@mail.gmail.com>
 <CAKtg4Zh__HWo_gMAUoEHxHFBtts4W9fgGdO+hmPUV3RO2LHZNw@mail.gmail.com>
 <CAKtg4ZhkSxgkzjv90JqRn70RiWU8Zy+6zUXXpCT4wq3_32p8_g@mail.gmail.com>
 <CAKtg4ZigARiV43CYYwDvHOtL=kFp=xOnvY=oXYrrrzweoRpL4Q@mail.gmail.com>
Message-ID: <CAKtg4ZhXLo-_Jgc0qME0wvJewHKZKB4JHqPSBVvW9WvRB-p-HQ@mail.gmail.com>

Hello Team,

We have one centos 7 client machine and configure the proxy manually
through command.
Proxy ip 192.168.1.2
Proxy port 8080

Set the environment with below command
Export http_ proxy="192.168.1.2:8080"

But when I download the website through http it is download.
Wget http://google.com

Index.html page download

2. Wget https://google.com
Index.html not download and it is showing the connection problem.

Note: on browser it is working with https too. But on cli terminal it is
not working.

Please help me asap
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/20cedd8b/attachment.htm>

From fredbmail at free.fr  Mon Aug 29 15:45:44 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 29 Aug 2016 17:45:44 +0200 (CEST)
Subject: [squid-users] Wget https://www.google.com not download
In-Reply-To: <CAKtg4ZhXLo-_Jgc0qME0wvJewHKZKB4JHqPSBVvW9WvRB-p-HQ@mail.gmail.com>
Message-ID: <1678293257.767606962.1472485544170.JavaMail.root@zimbra4-e1.priv.proxad.net>


> Set the environment with below command
> Export http_ proxy=" 192.168.1.2:8080 "
> 
HTTP

> But when I download the website through http it is download.
> Wget http://google.com
> 

HTTPS
export https_ proxy="192.168.1.2:8080"

Fred


From vibhorsaraswat at gmail.com  Mon Aug 29 16:05:45 2016
From: vibhorsaraswat at gmail.com (Vibhor Saraswat)
Date: Mon, 29 Aug 2016 21:35:45 +0530
Subject: [squid-users] Wget https://www.google.com not download
In-Reply-To: <1678293257.767606962.1472485544170.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <CAKtg4ZhXLo-_Jgc0qME0wvJewHKZKB4JHqPSBVvW9WvRB-p-HQ@mail.gmail.com>
 <1678293257.767606962.1472485544170.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CAKtg4ZgUBddMXw-Szy3hpH+XYR4W4Q8NLEko9vRYWYwYhwy52Q@mail.gmail.com>

Are you sure it is working, some times
when i try wget https:// <https://www.google.com/>www.google.com

it is not download

""wget proxy tunneling failed bad request unable to establish ssl
connection""

this message is appears when i  try wget https:// URL's

On 29-Aug-2016 9:15 pm, "FredB" <fredbmail at free.fr> wrote:

>
> > Set the environment with below command
> > Export http_ proxy=" 192.168.1.2:8080 "
> >
> HTTP
>
> > But when I download the website through http it is download.
> > Wget http://google.com
> >
>
> HTTPS
> export https_ proxy="192.168.1.2:8080"
>
> Fred
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/c35b4d0c/attachment.htm>

From squid3 at treenet.co.nz  Mon Aug 29 16:09:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 30 Aug 2016 04:09:27 +1200
Subject: [squid-users] squid user session/connections control
In-Reply-To: <0F7C0299-E486-4849-AF5A-A1E1370E2DED@gmail.com>
References: <C375DBF1-3D2B-467F-AA80-56C9C799CE96@netstream.ps>
 <74a91a5d-a535-080d-e6bd-bacf6ecb5b7a@treenet.co.nz>
 <0F7C0299-E486-4849-AF5A-A1E1370E2DED@gmail.com>
Message-ID: <1f51d0c0-7008-729d-1797-5b2dab5eaf7c@treenet.co.nz>

On 27/08/2016 4:57 a.m., Ahmed Alzaeem wrote:
> hi amos 
> sorry i didn?t understand you 
> 
> did you mean that the settings below will limit connections per user to 100 connection ?
> 
> or per ip
> 
> 
> can you clarify please ??
> 

On 26/08/2016 7:05 a.m., --Ahmad-- wrote:
>
> user will connect to squid and have only 50 max connections .
>
> my config are below :
>
> ##########################################
> acl vvv maxconn 100
>

"maxconn 100" is not "50 max". It is 100 == 100.


On 26/08/2016 7:05 a.m., --Ahmad-- wrote:
>
> i have a question in mind on how can i limit connections for a user
that is connected using AUTH_NTLM method
...
>
> my config are below :
>
> ##########################################
...
>
> auth_param basic program ...

"auth_param basic" is not NTLM.


Amos




From yvoinov at gmail.com  Mon Aug 29 16:36:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 29 Aug 2016 22:36:05 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472483298687-4679242.post@n4.nabble.com>
References: <1472157312575-4679194.post@n4.nabble.com>
 <CADSSinNRcSKYdujtsA9bDnJJGdWaZ2EnAVUTV64qc-DwpYiKCA@mail.gmail.com>
 <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
Message-ID: <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Regex for fb video:

fbcdn\.net\/v\/(.*\.mp4)\?

Written with help of https://regex101.com.


29.08.2016 21:08, erdosain9 ?????:
> mmmm....... and a last thing with this theme of limit video..... for
> facebook?????
> what would be the sysntax???
>
>
> (i get this on log
>
>
>
https://video-yyz1-1.xx.fbcdn.net/v/t42.1790-2/14194700_1292914777409287_1273911953_n.mp4?
> - HIER_DIRECT/31.13.80.9 video/mp4
>
> )
>
> Thanks!!!!
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679242.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXxGR0AAoJENNXIZxhPexG2DwIALwaO7hRJ5gjWjge+3XTiQWc
sNPfm3lgaEWL1mTlbhUY1ThG17dbZaCDGF0Rz0HbfsfAGeCodovcj7Pr3p+Mbzq1
e26Z0XjxBHG7wY2cJDEACmOubtBjJYVMV3hdl+PJbXzMfcJ5aDPU17yCrRclDZps
qafxbhudtwOC/ayefpV3RuUMhH0a9sUTV3fvdOGsKDlDRVMCKK0jKUa9Pcx7mcnI
J+J7tjkf2IEzenCDiBUcUixm/RaQEL7q7MpwPs/TmXGjeb05MQls703xt2KhHkJE
DwQFUNFTJfVYpd1AI50xIjwOOq2GW40eqimJsFTHvMKbDTFDxao9+Nzi2dDlxdk=
=uCfT
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/95544771/attachment.key>

From stan.prescott at gmail.com  Mon Aug 29 16:43:03 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Mon, 29 Aug 2016 11:43:03 -0500
Subject: [squid-users] Transparent intercept Squid 3.5.20: where VPNs go to
	die.
Message-ID: <CANLNtGR2MCY_3M3k5tP_6ij5nCG1SppfsbkUhj=+aDfE9LV96g@mail.gmail.com>

I have successfully gotten Squid 3.5.20 to filter both HTTP and HTTPS in
transparent intercept mode. With intercept mode, iptables rules redirect
port 80 to squid's http_port 800 and HTTPS port 443 is redirected to
Squid's https_port 801. It all seems to work exactly as it should.

I have recently been trying to integrate a urlfilter using
url_redirect_program with my Squid implementation, and that works very
well, also.

The problem:

One of the useful features of the urlfilter is that it detects proxy
tunnels and blocks them. Not being very proficient in the use of proxy
tunnels and VPNs I wanted to test it out. I setup a VPN client (CyberGhost
VPN) on my Linux client connected to my firewall with the Squid
implementation and could successfully establish a VPN connection *via port
443* when Squid and the URL Filter were disabled. After disconnecting the
VPN and enabling Squid and the urlfilter, attempting to connect using the
VPN over 443 failed to connect.

Now that actually might be a good thing because I am trying to block it
anyway. But the block is an error and not in the manner that is expected.
It is blocked, it seems, because the redirection of port 443 to Squid
causes Squid to barf on the VPN because the VPN, while using port 443 is
not a TLS/SSL encrypted connection and Squid doesn't seem to know what to
do with the connection.

Is there a way to tell Squid that there may be port 443 connections that
don't use TLS/SSL so that a useful message could be generated other than
the "connection failed" message the VPN client gives? There are error
messages in the Squid cache.log about connection attempts failed because of
problems with TLS/SSL and certs.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/ca3ebcd8/attachment.htm>

From jorgeley at gmail.com  Mon Aug 29 16:50:52 2016
From: jorgeley at gmail.com (Jorgeley Junior)
Date: Mon, 29 Aug 2016 13:50:52 -0300
Subject: [squid-users] Wget https://www.google.com not download
In-Reply-To: <CAKtg4ZgUBddMXw-Szy3hpH+XYR4W4Q8NLEko9vRYWYwYhwy52Q@mail.gmail.com>
References: <CAKtg4ZhXLo-_Jgc0qME0wvJewHKZKB4JHqPSBVvW9WvRB-p-HQ@mail.gmail.com>
 <1678293257.767606962.1472485544170.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <CAKtg4ZgUBddMXw-Szy3hpH+XYR4W4Q8NLEko9vRYWYwYhwy52Q@mail.gmail.com>
Message-ID: <CAMeoTHkGObw-A5OFqJt52XqPmYhq8Pe1bah+Wi2r9Dw3rNB=JA@mail.gmail.com>

I think you have to set all these environment variables, see my example:

ftp_proxy=ftp://192.168.1.254:8213/
http_proxy=http://192.168.1.254:8213/
https_proxy=https://192.168.1.254:8213/
socks_proxy=socks://192.168.1.254:8213/

Also, I setted the proxy into the file:   /etc/wgetrc

Hope it helps

2016-08-29 13:05 GMT-03:00 Vibhor Saraswat <vibhorsaraswat at gmail.com>:

> Are you sure it is working, some times
> when i try wget https:// <https://www.google.com/>www.google.com
>
> it is not download
>
> ""wget proxy tunneling failed bad request unable to establish ssl
> connection""
>
> this message is appears when i  try wget https:// URL's
>
> On 29-Aug-2016 9:15 pm, "FredB" <fredbmail at free.fr> wrote:
>
>>
>> > Set the environment with below command
>> > Export http_ proxy=" 192.168.1.2:8080 "
>> >
>> HTTP
>>
>> > But when I download the website through http it is download.
>> > Wget http://google.com
>> >
>>
>> HTTPS
>> export https_ proxy="192.168.1.2:8080"
>>
>> Fred
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


--
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/90a9633b/attachment.htm>

From huaraz at moeller.plus.com  Mon Aug 29 13:54:42 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Mon, 29 Aug 2016 14:54:42 +0100
Subject: [squid-users] Trouble negotiate_kerberos_auth
In-Reply-To: <CA+0Tdyr+2jEL7p09yrtJQ516M-2uE-q=Zayd3F5J0A=25zcacQ@mail.gmail.com>
References: <CA+0TdyqEAt4L5KO4zrJNJ1aUe64mY2Re7z95KFdqW7Y8SV_qbg@mail.gmail.com>
 <npva8g$nni$1@blaine.gmane.org>
 <CA+0Tdyr+2jEL7p09yrtJQ516M-2uE-q=Zayd3F5J0A=25zcacQ@mail.gmail.com>
Message-ID: <nq22bk$vga$1@blaine.gmane.org>

Hi Marcio,

That looks OK.  TT means the helper requires additional data from the client which I did not prepare a test for. In my case I get the AF response.

#  /opt/squid-trunk/sbin/negotiate_kerberos_auth_test opensuse42.suse.home | awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}'  | /opt/squid-trunk/sbin/negotiate_kerberos_auth -r -k squid.keytab -s HTTP/opensuse42.suse.home
AF oRQwEqADCgEAoQsGCSqGSIb3EgECAg== markus group=
BH quit command

  Anyway the basic check looks good. You now just need to run the helper with squid.  I will see if I can create a test which deals with the TT response too.

Regards
Markus

"Marcio Demetrio Bacci" <marciobacci at gmail.com> wrote in message news:CA+0Tdyr+2jEL7p09yrtJQ516M-2uE-q=Zayd3F5J0A=25zcacQ at mail.gmail.com...
Hi Markus, thank you for help me.

When I type the klist command, the result is:

Ticket cache: FILE:/tmp/krb5cc_0
Default principal: robert at CMS.ENSINO.BR
Valid starting       Expires              Service principal
28-08-2016 22:40:53  29-08-2016 08:40:53  krbtgt/CMS.ENSINO.BR at CMS.ENSINO.BR
    renew until 29-08-2016 22:40:41

But, I have the following result to command bellow:
/usr/lib64/squid/negotiate_kerberos_auth_test proxy.cms.ensino.br| awk '{sub(/Token:/,"YR"); print $0}END{print "QQ"}' | /usr/lib64/squid/negotiate_kerberos_auth -r -s HTTP/proxy.cms.ensino.br 

Result:
TT oYGbMIGYoAMKAQGhCAYGKwYBBQIFooGGBIGDBQEwFKESBBBDTUIuRU5TSU5PLkVCLkJSfmkwZ6ADAgEFoQMCAR6iERgPMjAxNjA4MjkwMTM2MDVaowUCAwK7P6QRGA8yMDE2MDgyOTAxMzYwNVqlBQIDBhpppgMCAQepFRsTPHVuc3BlY2lmaWVkIHJlYWxtPqoLMAmgAwIBAKECMAA=
BH quit command


The HTTP/proxy.cms.ensino.br is in keytab files

I don't have the "test_negotiate_auth.sh" file in src/auth/negotiate/kerberos, but I have /usr/lib64/squid/negotiate_kerberos_auth_test, thus I'm using it.

My Linux distribution is CentOS 7


Regards,


M?rcio






2016-08-28 15:24 GMT-03:00 Markus Moeller <huaraz at moeller.plus.com>:


  HI Marcio,

    The helper need a Kerberos token as input.  Please have a look at test_negotiate_auth.sh  which is in src/auth/negotiate/kerberos of the trunk version. The squid hostname must match the entry in your keytab and you must have done kinit to authenticate against a Kerberos server (e.g. AD) as user first.

  Regards
  Markus 


  "Marcio Demetrio Bacci" <marciobacci at gmail.com> wrote in message news:CA+0TdyqEAt4L5KO4zrJNJ1aUe64mY2Re7z95KFdqW7Y8SV_qbg at mail.gmail.com...
  I have trouble to authenticate Squid3 with kerberos in Samba4 domain. I'm using CentOS 7 and Squid 3.3.8 (yum install squid)


  When I type the bellow command in terminal: 
  /usr/lib64/squid/negotiate_kerberos_auth -d -i -s HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
  john xyz at 12345

  I have the following error:
  negotiate_kerberos_auth.cc(315): pid=6364 :2016/08/27 10:44:33| negotiate_kerberos_auth: DEBUG: Got 'john xyz at 12345' from squid (length: 14).
  negotiate_kerberos_auth.cc(362): pid=6364 :2016/08/27 10:44:33| negotiate_kerberos_auth: ERROR: Invalid request [john xyz at 12345]
  BH invalid request 


  Here are my files configuration:

  /etc/krb5.conf
  [libdefaults]
      default_realm = CMS.ENSINO.BR
  [realms]
      CMS.ENSINO.BR = {
      kdc = dc1.cms.ensino.br:88
      admin_server = dc1.cms.ensino.br
      default_domain = CMS.ENSINO.BR 
      }
  [domain_realm]
      .cms.ensino.br = CMS.ENSINO.BR
      cms.ensino.br = CMS.ENSINO.BR



  Keytab name: FILE:/etc/krb5.keytab
  KVNO Principal
  ---- --------------------------------------------------------------------------
     1 proxy-k$@CMS.ENSINO.BR
     1 proxy-k$@CMS.ENSINO.BR
     1 proxy-k$@CMS.ENSINO.BR
     1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/PROXY at CMS.ENSINO.BR
     1 host/PROXY at CMS.ENSINO.BR
     1 host/PROXY at CMS.ENSINO.BR
     1 host/PROXY at CMS.ENSINO.BR
     1 host/PROXY at CMS.ENSINO.BR
     1 PROXY$@CMS.ENSINO.BR
     1 PROXY$@CMS.ENSINO.BR
     1 PROXY$@CMS.ENSINO.BR
     1 PROXY$@CMS.ENSINO.BR
     1 PROXY$@CMS.ENSINO.BR
     1 proxy-k$@CMS.ENSINO.BR
     1 proxy-k$@CMS.ENSINO.BR
     1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 HTTP/PROXY at CMS.ENSINO.BR
     1 HTTP/PROXY at CMS.ENSINO.BR
     1 HTTP/PROXY at CMS.ENSINO.BR
     1 HTTP/PROXY at CMS.ENSINO.BR
     1 HTTP/PROXY at CMS.ENSINO.BR


  Keytab name: FILE:/etc/squid/PROXY.keytab
  KVNO Principal
  ---- --------------------------------------------------------------------------
     1 proxy-k$@CMS.ENSINO.BR
     1 proxy-k$@CMS.ENSINO.BR
     1 proxy-k$@CMS.ENSINO.BR
     1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/proxy.cms.ensino.br at CMS.ENSINO.BR
     1 host/proxy.cms.ensino.br at CMS.ENSINO.BR


  /etc/sysconfig/squid
  # default squid options
  SQUID_OPTS=""
  # Time to wait for Squid to shut down when asked. Should not be necessary
  # most of the time.
  SQUID_SHUTDOWN_TIMEOUT=100
  # default squid conf file
  SQUID_CONF="/etc/squid/squid.conf"

  KRB5_KTNAME=/etc/squid/PROXY.keytab
  export KRB5_KTNAME



  kinit and klist commands are OK.


  Best Regards,


  M?rcio



------------------------------------------------------------------------------
  _______________________________________________
  squid-users mailing list
  squid-users at lists.squid-cache.org
  http://lists.squid-cache.org/listinfo/squid-users


  _______________________________________________
  squid-users mailing list
  squid-users at lists.squid-cache.org
  http://lists.squid-cache.org/listinfo/squid-users





--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/bd5d9d7f/attachment.htm>

From huaraz at moeller.plus.com  Mon Aug 29 13:59:02 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Mon, 29 Aug 2016 14:59:02 +0100
Subject: [squid-users] ext_kerberos_ldap_group_acl problem ( 2
	minorbugsmaybe )
In-Reply-To: <vmime.57c3e5ca.28ab.73ab0c8662c3316a@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.57bdb617.37c8.575130a1134f9a07@ms249-lin-003.rotterdam.bazuin.nl>
 <vmime.57c3e5ca.28ab.73ab0c8662c3316a@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <nq22bl$vga$2@blaine.gmane.org>

Hi Louis,

    I know a user and machine account can be used and they work the same. What my concern is, is that many companies deploy password policies for users in AD.  You would need to create exceptions for user accounts which have SPNs with associated keytabs as a password change will make the keytab invalid.

Markus 


"L.P.H. van Belle" <belle at bazuin.nl> wrote in message news:vmime.57c3e5ca.28ab.73ab0c8662c3316a at ms249-lin-003.rotterdam.bazuin.nl...
Hello Markus, 

 

Thank you for the explanation, that helped a lot. 

 

I use the TLS_CACERTFILE in the init script now and that works for me . 

( in debian the /etc/default/squid  )

 

>>The helper tries to ?authenticate? squid to AD as a user with the found SPN name, so the UPN must be the same as the SPN.  There is no easy way to query what the UPN for the SPN is. 

Ah, this helped identify-ing so other small things to. 

 

>>msktutil (my preferred tool)

Since i try to use only debian packages the msktutil is not available for me. 

 

>>Also msktutil (my preferred tool) creates a machine account not a user account in AD. 

>>The reason I prefer this is that often user accounts have a global password policy e.g. change every 60 days otherwise it will be locked. 

>>machine accounts do not have that limitation. But as I said it is just my preference.

 

Thats not correct in my optionion. A the computer account, works the (almost) same an user account. 

Like a computer account = a user account. 

 

some pointers :

https://technet.microsoft.com/en-us/library/cc731641(v=ws.11).aspx

https://adsecurity.org/?p=280 

 

I used a seperated user since i wanted to have 2 proxy on 1 service account, but due to the UPS/SPN thing,

thats not options anymore, not thats a problem, I?ll change to add the computer to the samba domain and 

add the UPN/SPN on the computer account where needed.

Which maybe even a better option.

 

Thanks again for you replies. 

 

 

Best regards, 

 

Louis

 

 

 


--------------------------------------------------------------------------------

Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Markus Moeller
Verzonden: zaterdag 27 augustus 2016 16:52
Aan: squid-users at lists.squid-cache.org
Onderwerp: Re: [squid-users] ext_kerberos_ldap_group_acl problem ( 2 minorbugsmaybe )

 

Hi,

 

   I would say they are bugs. The first ?issue? is as you say more about understanding the difference between UPN and SPN and how the tools use them.  The helper tries to ?authenticate? squid to AD as a user with the found SPN name, so the UPN must be the same as the SPN.  There is no easy way to query what the UPN for the SPN is. 

 

  Also msktutil (my preferred tool) creates a machine account not a user account in AD. The reason I prefer this is that often user accounts have a global password policy e.g. change every 60 days otherwise it will be locked. machine accounts do not have that limitation. But as I said it is just my preference. 

 

   Regarding the certifcate check I do not use any ldap.conf settings. I require an export TLS_CACERTFILE=/mydir/myfile.pem   in the squid startup file.  Maybe in the next version I see how I can determine the right ldap.conf file and check if the CACERTFILE variable is already set.

 

 

Kind regards

Markus

 

 

"L.P.H. van Belle" <belle at bazuin.nl> wrote in message news:vmime.57bdb617.37c8.575130a1134f9a07 at ms249-lin-003.rotterdam.bazuin.nl...

Ok reply to myself so other users know this also.

 

if you create a user for the HTTP services and you dont use msktutil but like me samba-tool or something else. 

 

Read : 

http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos carefully. 

and the clue was this line for me.  

 

Squid "login" to Windows Active Directory or Unix kdc as user <HTTP/<fqdn-squid>@DOMAIN.COM>. 

This requires Active Directory to have an attribute userPrincipalname set to <HTTP/<fqdn-squid>@DOMAIN.COM>

for the associated acount. This is usaully done by using msktutil. 

 

But this is not done by samba-tools  

 

samba-tool setup fro squid i used, was as followed. 

samba-tool user create squid1-service --description="Unprivileged user for SQUID1-Proxy Services" --random-password 

samba-tool user setexpiry squid1-service ?noexpiry

samba-tool spn add HTTP/proxy.internal.domain.tld squid1-service

 

 

Now this results in : 

My UPN was set to the username at internal.domain.tld  ( as it should ). 

My SPN was set to HTTP/proxyserver.internal.domain.tld at REALM ( as is should )  

 

samba-tool spn list squid1-service 

squid1-service

User CN=squid1-service,OU=Service-Accounts,OU=XXXX,DC=XXXXX,DC=XXXX,DC=XX has the following servicePrincipalName:

         HTTP/proxy.internal.domain.tld

         HTTP/proxy.internal.domain.tld at YOUR.REALM.T

 

 

Now i changed my UPN from username at internal.domain.tld  to the (SPN name)   HTTP/proxyserver.internal.domain.tld at REALM 

Solved my initial problem. 

This should be in my optionion be changed to search for the SPN in ext_kerberos_ldap_group.

 

Now i have LDAPS messages, see below, im adding the _ldaps SRV records now ,but i dont get why im getting : 

Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

 

Im already having : TLS_CACERT      /etc/ssl/certs/ca-certificates.crt 

Which contains the needed certs.

 

Did i find 2 small bugs here?  

Or is this a ?Debian? related thing? 

 

 

Debug output. 

/usr/lib/squid3/ext_kerberos_ldap_group_acl -g internet-mail at YOUR.REALM.TLD -D YOUR.REALM.TLD -N internet-mail at NTDOMAIN -s -i -d

kerberos_ldap_group.cc(278): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Starting version 1.3.1sq

support_group.cc(382): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Group list internet-mail at YOUR.REALM.TLD

support_group.cc(447): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: INFO: Group internet-mail  Domain YOUR.REALM.TLD

support_netbios.cc(83): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: Netbios list internet-mail at NTDOMAIN

support_netbios.cc(156): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: Netbios name internet-mail  Domain NTDOMAIN

support_lserver.cc(82): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: ldap server list NULL

support_lserver.cc(86): pid=6902 :2016/08/24 16:10:07| kerberos_ldap_group: DEBUG: No ldap servers defined.

testuser internet-mail

kerberos_ldap_group.cc(371): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: Got User: testuser set default domain: YOUR.REALM.TLD

kerberos_ldap_group.cc(376): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: Got User: testuser Domain: YOUR.REALM.TLD

support_member.cc(63): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: User domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(65): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Found group at domain internet-mail at YOUR.REALM.TLD

support_ldap.cc(898): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setup Kerberos credential cache

support_krb5.cc(127): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set credential cache to MEMORY:squid_ldap_6902

support_krb5.cc(138): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Get default keytab file name

support_krb5.cc(144): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Got default keytab file name /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(158): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Get principal name from keytab /etc/squid/keytab.PROXYSERVER-HTTP

support_krb5.cc(169): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Keytab entry has realm name: YOUR.REALM.TLD

support_krb5.cc(181): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Found principal name: HTTP/proxy.internal.domain.tld at YOUR.REALM.TLD

support_krb5.cc(196): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Got principal name HTTP/proxy.internal.domain.tld at YOUR.REALM.TLD

support_krb5.cc(260): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Stored credentials

support_ldap.cc(927): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Initialise ldap connection

support_ldap.cc(931): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable SSL to ldap servers

support_ldap.cc(933): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Canonicalise ldap server name for domain YOUR.REALM.TLD

support_resolv.cc(289): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while resolving service record _ldaps._tcp.YOUR.REALM.TLD with res_search

support_resolv.cc(71): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: res_search: Unknown service record: _ldaps._tcp.YOUR.REALM.TLD

support_resolv.cc(379): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved SRV _ldap._tcp.YOUR.REALM.TLD record to samba-dc2.internal.domain.tld

support_resolv.cc(379): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved SRV _ldap._tcp.YOUR.REALM.TLD record to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 1 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 2 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 3 of YOUR.REALM.TLD to samba-dc1.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 4 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 5 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(207): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Resolved address 6 of YOUR.REALM.TLD to samba-dc2.internal.domain.tld

support_resolv.cc(407): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Adding YOUR.REALM.TLD to list

support_resolv.cc(443): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Sorted ldap server names for domain YOUR.REALM.TLD:

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: samba-dc1.internal.domain.tld Port: 389 Priority: 0 Weight: 100

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: samba-dc2.internal.domain.tld Port: 389 Priority: 0 Weight: 100

support_resolv.cc(445): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Host: YOUR.REALM.TLD Port: -1 Priority: -2 Weight: -2

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc1.internal.domain.tld:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server samba-dc2.internal.domain.tld:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(942): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Setting up connection to ldap server YOUR.REALM.TLD:389

support_ldap.cc(786): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set SSL defaults

support_ldap.cc(531): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Enable server certificate check for ldap server.

support_ldap.cc(544): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Set certificate file for ldap server to /etc/ssl/certs/cert.pem.(Changeable through setting environment variable TLS_CACERTFILE)

support_ldap.cc(800): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while setting start_tls for ldap server: Can't contact LDAP server

support_ldap.cc(953): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Bind to ldap server with SASL/GSSAPI

support_sasl.cc(276): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Can't contact LDAP server

support_ldap.cc(957): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: ERROR: Error while binding to ldap server with SASL/GSSAPI: Can't contact LDAP server

support_ldap.cc(979): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Error during initialisation of ldap connection: No such file or directory

support_ldap.cc(1048): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Error during initialisation of ldap connection: No such file or directory

support_member.cc(76): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: INFO: User testuser is not member of group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(91): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Default domain loop: group at domain internet-mail at YOUR.REALM.TLD

support_member.cc(119): pid=6902 :2016/08/24 16:10:12| kerberos_ldap_group: DEBUG: Default group loop: group at domain internet-mail at YOUR.REALM.TLD

 

 


--------------------------------------------------------------------------------

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160829/1e22a04c/attachment.htm>

From rousskov at measurement-factory.com  Mon Aug 29 20:07:20 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 29 Aug 2016 14:07:20 -0600
Subject: [squid-users] Transparent intercept Squid 3.5.20: where VPNs go
 to die.
In-Reply-To: <CANLNtGR2MCY_3M3k5tP_6ij5nCG1SppfsbkUhj=+aDfE9LV96g@mail.gmail.com>
References: <CANLNtGR2MCY_3M3k5tP_6ij5nCG1SppfsbkUhj=+aDfE9LV96g@mail.gmail.com>
Message-ID: <ff632291-39e5-6aca-2354-96ab270f8ecb@measurement-factory.com>

On 08/29/2016 10:43 AM, Stanford Prescott wrote:

> Is there a way to tell Squid that there may be port 443 connections that
> don't use TLS/SSL so that a useful message could be generated other than
> the "connection failed" message the VPN client gives?

Not quite, but we are slowly getting there:

Recent Squids have on_unsupported_protocol feature that is usually
triggered when Squid receives a request using the wrong protocol,
including receiving non-SSL bytes instead of SSL Hello. You can
configure Squid to respond with an error response in that case (in fact,
that is the default behavior).

In theory, you can also configure Squid to customize that error response
using deny_info, but see
http://lists.squid-cache.org/pipermail/squid-users/2016-August/012124.html
 (Ideally, we should support a better way of customize error responses
than denying them and using deny_info to customize denied responses!)

Even if deny_info works, there is currently no way to customize an error
response so that it becomes a non-HTTP response, but that (together with
ACLs/code to detect common non-HTTP protocols) would be a welcomed
feature IMO. Ideally, the admin should be able to tell Squid exactly
what bytes to send to the client (as opaque or opaque with placeholders
data) if needed.


HTH,

Alex.



From erdosain9 at gmail.com  Mon Aug 29 20:13:09 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 29 Aug 2016 13:13:09 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
References: <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
Message-ID: <1472501589650-4679253.post@n4.nabble.com>

Ok,thanks!
But something is wrong with my config............
I dont have almost no users... (because is proxy testing) and i have too
many download avg.

Look , this is Torch to the ip of proxy, to see whats going on...


<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679253/Captura_de_pantalla_de_2016-08-29_15-48-41.png> 

<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679253/Captura_de_pantalla_de_2016-08-29_16-03-14.png> 

This is my config 

#Pools para ancho de Banda
delay_pools 5 

###VELOCIDAD PARA REDES SOCIALES
delay_class 1 1
delay_parameters 1 10000/100000
delay_access 1 allow redes_sociales limitado
delay_access 1 allow redes_sociales full
delay_access 1 allow redes_sociales adminis

#Limitar YOUTUBE
delay_class 2 1
delay_parameters 2 10000/100000
delay_access 2 allow youtube adminis
delay_access 2 allow youtube full
delay_access 2 allow youtube limitado

#Ancho de Banda Administracion
delay_class 3 2
delay_parameters 3 512000/512000 60000/256000
delay_access 3 allow adminis

#Ancho de Banda Sistemas
delay_class 4 2
delay_parameters 4 512000/512000 64000/256000
delay_access 4 allow sistemas

#Ancho de Banda Logistica
delay_class 5 2
delay_parameters 5 256000/256000 30000/125000
delay_access 5 allow limitado


if I have delay pools with low bandwidth . How can it be that "long period
of time " the squid has a bandwidth so high ??

Thanks!!!!!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679253.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Aug 29 21:27:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 30 Aug 2016 03:27:15 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472501589650-4679253.post@n4.nabble.com>
References: <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
 <1472501589650-4679253.post@n4.nabble.com>
Message-ID: <94d17876-7a64-44b7-6471-71c65df04e69@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I'm a little differently solve the problem of the speed limit streaming
video. I limit the speed of the video on the router to the proxy, the
proxy itself gives cached video streaming to the local network at full
speed, because the speed of the local network I is not limited. My main
task is to prevent the exhaustion of uplink bandwidth.


30.08.2016 2:13, erdosain9 ?????:
> Ok,thanks!
> But something is wrong with my config............
> I dont have almost no users... (because is proxy testing) and i have too
> many download avg.
>
> Look , this is Torch to the ip of proxy, to see whats going on...
>
>
>
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679253/Captura_de_pantalla_de_2016-08-29_15-48-41.png>

>
>
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679253/Captura_de_pantalla_de_2016-08-29_16-03-14.png>

>
> This is my config
>
> #Pools para ancho de Banda
> delay_pools 5
>
> ###VELOCIDAD PARA REDES SOCIALES
> delay_class 1 1
> delay_parameters 1 10000/100000
> delay_access 1 allow redes_sociales limitado
> delay_access 1 allow redes_sociales full
> delay_access 1 allow redes_sociales adminis
>
> #Limitar YOUTUBE
> delay_class 2 1
> delay_parameters 2 10000/100000
> delay_access 2 allow youtube adminis
> delay_access 2 allow youtube full
> delay_access 2 allow youtube limitado
>
> #Ancho de Banda Administracion
> delay_class 3 2
> delay_parameters 3 512000/512000 60000/256000
> delay_access 3 allow adminis
>
> #Ancho de Banda Sistemas
> delay_class 4 2
> delay_parameters 4 512000/512000 64000/256000
> delay_access 4 allow sistemas
>
> #Ancho de Banda Logistica
> delay_class 5 2
> delay_parameters 5 256000/256000 30000/125000
> delay_access 5 allow limitado
>
>
> if I have delay pools with low bandwidth . How can it be that "long period
> of time " the squid has a bandwidth so high ??
>
> Thanks!!!!!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679253.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXxKizAAoJENNXIZxhPexGVRsH/1z+Z35AFdhTP1n/hMelYo4/
4padot4Aw5XBzP8igI3MhF7U5sTmH8Z8lvKD8W5G0wikqeIfS0uPcW/qpyXJyibw
iuJkHxWAFpolDN5bxUsmDUJ8I5OMzXnJduUha6BkK498/iBgmJDzJx6DyLyKjZs6
pd4KkoyFAFnGeY7pgUJrIXpkTeYejdcO+3kjnK1qQeJhHCGuQl1Oo8ARbE5iIZUP
apuZnPz8Xt0iG6X/um0Se5opvvNaxKs+st+hElpw4rGQBUqMBpqGVPLOryEUdbyN
pa+bhjH70djKxyGNDC1meEKRL5yjH2u1teKN4DasG+Q6A+THblqHuA6DvQyUOZo=
=qIfq
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160830/ee76ae84/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160830/ee76ae84/attachment.key>

From alberto.furia at gmail.com  Tue Aug 30 11:05:48 2016
From: alberto.furia at gmail.com (alberto)
Date: Tue, 30 Aug 2016 13:05:48 +0200
Subject: [squid-users] Too many AD group and squid kerberos auth problem
Message-ID: <CANEbR8ke2t9wDMwtT6V11i7run4B=OEgo7Ppfb46rPCF9Wv7pg@mail.gmail.com>

Hi all,
I have a squid3 installation with kerberos ldap groups authentication.
Everything works like a charm except for one of my user that belongs to too
many groups (more than 50): this user can not browse any site because of
authentication problem.
I always see TCP_DENIED/407 in the squid log file for that user.

Is there a parameter that I can change in the squid.conf file to increase
the number of groups allowed during authentication?
FYI I'm on Debian Jessie and using this kerberos configuration

====squid.conf snippet=======

################## Kerberos Auth ###################
auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth  -s
GSS_C_NO_NAME -i
auth_param negotiate children 10
auth_param negotiate keep_alive off

################# External_acl_type ########################
#internet ALL
external_acl_type kgrp_all ttl=60 negative_ttl=60 %LOGIN
 /usr/lib/squid3/ext_kerberos_ldap_group_acl -i -g "DL Internet
ALL at EXAMPLE.LCL" -D EXAMPLE.LCL -S example.lcl at EXAMPLE.LCL -m 10 -b
"OU=InternetAccess,OU=Groups,OU=Users &
Groups,OU=Inet,OU=Root,DC=EXAMPLE,DC=LCL"  -D EXAMPLE.LCL -N
EXAMPLE at EXAMPLE.LCL

################# Basic Auth ########################
auth_param basic program /usr/lib/squid3/basic_ldap_auth -D
srvc_squid at example.lcl -W /etc/squid3/ldappwd.txt -h "example.lcl" -b
"OU=root,DC=EXAMPLE,DC=LCL" -s sub -f
(&(objectClass=Person)(sAMAccountName=%s))
auth_param basic children 10
auth_param basic realm Internet Proxy
auth_param basic credentialsttl 1 minute


Thank you for your help,
Alberto
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160830/3d2d28fd/attachment.htm>

From squid3 at treenet.co.nz  Tue Aug 30 15:02:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Aug 2016 03:02:57 +1200
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472501589650-4679253.post@n4.nabble.com>
References: <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
 <1472501589650-4679253.post@n4.nabble.com>
Message-ID: <32111747-1177-6735-ca32-b289378c3ec1@treenet.co.nz>

On 30/08/2016 8:13 a.m., erdosain9 wrote:
> Ok,thanks!
> But something is wrong with my config............
> I dont have almost no users... (because is proxy testing) and i have too
> many download avg.
> 
> Look , this is Torch to the ip of proxy, to see whats going on...
> 
> 
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679253/Captura_de_pantalla_de_2016-08-29_15-48-41.png> 
> 

Image does not exist.

> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679253/Captura_de_pantalla_de_2016-08-29_16-03-14.png> 

This appears to be showing several clients who are using only several
KB/sec *download* which approximately match some of the delay pools
download rates configured (~10-30 KBps). Also they are *uploading* very
fast to the server.

Delay pools controls download rates, not uploads. So that is as
expected. Although not much upload data is expected when streaming
_downloads_, so even if it did the 'burst' rates could account for most
of the higher upload speeds.


> 
> This is my config 
> 
> #Pools para ancho de Banda
> delay_pools 5 
> 
> ###VELOCIDAD PARA REDES SOCIALES
> delay_class 1 1
> delay_parameters 1 10000/100000
> delay_access 1 allow redes_sociales limitado
> delay_access 1 allow redes_sociales full
> delay_access 1 allow redes_sociales adminis
> 
> #Limitar YOUTUBE
> delay_class 2 1
> delay_parameters 2 10000/100000
> delay_access 2 allow youtube adminis
> delay_access 2 allow youtube full
> delay_access 2 allow youtube limitado
> 
> #Ancho de Banda Administracion
> delay_class 3 2
> delay_parameters 3 512000/512000 60000/256000
> delay_access 3 allow adminis
> 
> #Ancho de Banda Sistemas
> delay_class 4 2
> delay_parameters 4 512000/512000 64000/256000
> delay_access 4 allow sistemas
> 
> #Ancho de Banda Logistica
> delay_class 5 2
> delay_parameters 5 256000/256000 30000/125000
> delay_access 5 allow limitado
> 
> 
> if I have delay pools with low bandwidth . How can it be that "long period
> of time " the squid has a bandwidth so high ??

1) see above about download vs upload differences.

2) there are non-HTTP things involves with connections that use up
bandwidth and being non-HTTP are not accounted by Squid - which can only
account the HTTP message bytes.

3) you have both small and large bandwidth pools. Delay pools do not
operate on connection or port basis. They operate on HTTP message bytes
basis. So any given TCP connection may be rate limited one second (for
one message) and then rate limited differently the next second (for its
next message).

Delay pools are a very old design from the days before QoS was properly
standardized. It has many flaws. If you can do rate limiting with TOS /
QoS controls it is recommended to use that instead. I hope to remove
Delay Pools functionality from Squid as soon as the alternatives are
able to meet all use-cases.

Amos



From squid3 at treenet.co.nz  Tue Aug 30 15:15:25 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Aug 2016 03:15:25 +1200
Subject: [squid-users] Too many AD group and squid kerberos auth problem
In-Reply-To: <CANEbR8ke2t9wDMwtT6V11i7run4B=OEgo7Ppfb46rPCF9Wv7pg@mail.gmail.com>
References: <CANEbR8ke2t9wDMwtT6V11i7run4B=OEgo7Ppfb46rPCF9Wv7pg@mail.gmail.com>
Message-ID: <804a52fa-56cb-b2ba-0337-b23594056ab7@treenet.co.nz>

On 30/08/2016 11:05 p.m., alberto wrote:
> Hi all,
> I have a squid3 installation with kerberos ldap groups authentication.
> Everything works like a charm except for one of my user that belongs to too
> many groups (more than 50): this user can not browse any site because of
> authentication problem.
> I always see TCP_DENIED/407 in the squid log file for that user.

The Squid<->helper protocol in Squid-3 is not able to handle very long
lists of groups being returned by the helper. We have a fix in Squid-4,
but it is too large and destabilizing to backport.

You may want to try the latest 4.0 daily snapshot, or 4.0.14 release
which will be coming out as soon as I can find the time to package it.

If Squid-4 does not resolve the issue then the problem is likely to be
the large size of the Negotiate token in HTTP headers. There is no
guarantee that any HTTP header longer than 8000 bytes will be able to be
transmitted. Squid also has a 64KB header length limit at present which
may be applicable.

Amos



From squid3 at treenet.co.nz  Tue Aug 30 15:32:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Aug 2016 03:32:30 +1200
Subject: [squid-users] Shared Caching with Authorization
In-Reply-To: <1385494105.149002.1472213453775@mail.yahoo.com>
References: <1385494105.149002.1472213453775.ref@mail.yahoo.com>
 <1385494105.149002.1472213453775@mail.yahoo.com>
Message-ID: <5101ab08-4658-f9a9-2b4e-06b37ef0c889@treenet.co.nz>

On 27/08/2016 12:10 a.m., LIJO C J wrote:
> Hi, I have a resource representation in a REST service.  The response
> content  is same for allusers. But the response should be accessed
> only by authorizedInventoryAuditors.
> 
> 
> 
> 1.      How should be the response headers set to leveragecaching in
> Squid (as a forward proxy)?
> 

Squid obeys (modulo bugs) the rules set forth in:
 <https://tools.ietf.org/html/rfc7234#section-3>

Responses are cached by Squid unless prohibited, or the caching
freshness is impossible to calculate.

If you want to guarantee cacheability of your responses send
Last-Modified plus either Expires or Cache-Control:max-age=N.

If those are not possible to send, then dont bother - just let Squid
sort out what is possible to cache with the data you can provide about
the response object.



> 2.      How Squid will validate that the requested useris an
> authorized InventoryAuditor, while serving the response from cache?
> 

Authorization and Authentication are orthoganal concepts to Caching.

Squid uses HTTP authentication as specified in
<https://tools.ietf.org/html/rfc7235> *if* you configure Squid to
perform authentication *and* make use of it for authorization checks (ACL).

To provide a cached response the client must be authorized to send HTTP
requests to the proxy. The squid.conf http_access directive does HTTP
request authorization checks.


PS. I'm not sure what that code you finished up your questions with was
supposed to mean. HTTP is a protool, Squid is a proxy - neither is a
coding language.

Amos



From squid3 at treenet.co.nz  Tue Aug 30 16:01:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Aug 2016 04:01:47 +1200
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <1472150075016-4679181.post@n4.nabble.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
Message-ID: <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>

On 26/08/2016 6:34 a.m., reinerotto wrote:
> Hack the code. Because it is even worse, as firefox for example does not obey
> to the TTL. 
> 

It is not that simple. The checks are there for very good reason(s)
related to security of the network using the proxy.

The Host forgery issue being checked for allows network firewall rule
bypass, browser same-origin bypass, and browser sandbox bypass - in a
way which places the attacker in control of what logs you see [aha!
invisible access to the network]. With all the related nasty
side-effects those allow. There is both malware and services for sale
around the 'net that take advantage of the attack to do those bypasses.
=> Simply disabling the check code is a *very* risky thing to do.


The cases where Squid still gets it wrong are where the popular CDN
service(s) in question are performing DNS actions indistinguishable to
those malware attacks. If Squid can't tell the difference between an
attack and normal DNS behaviour the only code change possible is to
disable the check (see above about the risk level).


FYI: I have a plan to reduce the false-positive rate from DNS rotation
effects. But that requires some deep redesign of the DNS code, which I'm
intending to do as part of the Squid-5 roadmap to avoid further
destabilizing 4.x while its in beta.

For now the workarounds are:

* obey the requirement that destination NAT (if any) is performed only
on the Squid machine.

* to tune the lifetime for persistent client connections. That reduces
(but not fully) connections outliving DNS rotation times and thus
causing requests to have different ORIGINAL_DST from what DNS says.

* if wanting Google 8.8.8.8 service as your resolver. Use a local DNS
recursive resolver shared by Squid and client which points to that
service as its parent/forwarded resolver. That removes the issue with
every 8.8.8.8 response having different reply IP values (so client and
Squid doing near simultaneous lookups get different IPs).

Amos



From squid3 at treenet.co.nz  Tue Aug 30 16:14:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Aug 2016 04:14:09 +1200
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
Message-ID: <9ab7100a-228e-a96a-35ad-afbcf840e896@treenet.co.nz>

On 26/08/2016 4:17 a.m., Steve Hill wrote:
> 
> This one just seems to keep coming up and I'm wondering how other people
> are dealing with it:
> 
> When you peek and splice a transparently proxied connection, the SNI
> goes through the host validation phase.  Squid does a DNS lookup for the
> SNI, and if it doesn't resolve to the IP address that the client is
> connecting to, Squid drops the connection.
> 
> When accessing one of the increasingly common websites that use DNS load
> balancing, since the DNS results change on each lookup, Squid and the
> client may not get the same DNS results, so Squid drops perfectly good
> connections.
> 
> Most of this problem goes away if you ensure all the clients use the
> same DNS server as squid, but not quite.  Because the TTL on DNS records
> only has a resolution of 1 second, there is a period of up to 1 second
> when the DNS records Squid knows about doesn't match the ones that the
> client knows about.  The client and squid may expire the records up to 1
> second apart.

FYI: Services sending TTL of just 1 or even a few seconds are abusing
the DNS system. Rotating the order of IPs in the RR record is a
standardized feature and works just fine with how Squid does its checks.

NP: using "8.8.8.8" in both Squid and client does not count as using the
same resolver. Because that service is an entire farm of resolvers that
can and do respond differently to any two requests - even if they are
made simultaneously. Not a single machine using a single cache of DNS data.

> 
> So what's the solution?  (Notably the validation check can't be disabled
> without hacking the code).
> 

Well, hacking the code. But not necessarily in the obvious way of
disabling checks. Redesign in Squid DNS component is needed. If you want
to sponsor and/or test that work mail me privately. Though its unlikely
to be available for use in the short term .

Amos



From jok at spikes.com  Tue Aug 30 17:08:27 2016
From: jok at spikes.com (Jok Thuau)
Date: Tue, 30 Aug 2016 10:08:27 -0700
Subject: [squid-users] Too many AD group and squid kerberos auth problem
In-Reply-To: <CANEbR8ke2t9wDMwtT6V11i7run4B=OEgo7Ppfb46rPCF9Wv7pg@mail.gmail.com>
References: <CANEbR8ke2t9wDMwtT6V11i7run4B=OEgo7Ppfb46rPCF9Wv7pg@mail.gmail.com>
Message-ID: <CADSSinOqM-v8dAEg=LiHMgejimsJAv336j2hdkQx98uch+3tzA@mail.gmail.com>

On Tue, Aug 30, 2016 at 4:05 AM, alberto <alberto.furia at gmail.com> wrote:

> Hi all,
> I have a squid3 installation with kerberos ldap groups authentication.
> Everything works like a charm except for one of my user that belongs to
> too many groups (more than 50): this user can not browse any site because
> of authentication problem.
> I always see TCP_DENIED/407 in the squid log file for that user.
>
> Is there a parameter that I can change in the squid.conf file to increase
> the number of groups allowed during authentication?
> FYI I'm on Debian Jessie and using this kerberos configuration
>
>
if you are using group membership authorization purely to allow/deny access
globally (rather than for specific sites), you can tweak your filter to
accomplish that...


> ====squid.conf snippet=======
>

 [snip]


> ################# Basic Auth ########################
> auth_param basic program /usr/lib/squid3/basic_ldap_auth -D
> srvc_squid at example.lcl -W /etc/squid3/ldappwd.txt -h "example.lcl" -b
> "OU=root,DC=EXAMPLE,DC=LCL" -s sub -f (&(objectClass=Person)(
> sAMAccountName=%s))
>

this filter (after "-f") could be tweaked like this:
(&(objectClass=Person)(sAMAccountName=%s)(|(memberOf=CN=group1,OU=somewhere,dc=EXAMPLE,dc=LCL)(memberOf=CN=group2,OU=somewhere,dc=EXAMPLE,dc=LCL))

That would allow the user to login if they are member of either group.
(that syntax/schema is for AD, feel free to adjust as needed)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160830/8ede5620/attachment.htm>

From marcus.kool at urlfilterdb.com  Tue Aug 30 17:25:45 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 30 Aug 2016 14:25:45 -0300
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
 <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
Message-ID: <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>

Do I understand it correctly that Squid in normal proxy mode
allows malware to do a CONNECT to any destination, while in
transparent proxy mode does extra security checks which causes
some regular (non-malware) clients to fail?

And philosophical questions: is Squid the right tool
to stop malware?  If yes, is it acceptable that connections
of regular (non-malware) clients are wrongly dropped?

IMO Squid should do all it can to be a secure proxy.
Doing security checks on connections in an attempt
to stop malware sounds like a job for an antivirus / IDS tool.

Marcus


On 08/30/2016 01:01 PM, Amos Jeffries wrote:
> On 26/08/2016 6:34 a.m., reinerotto wrote:
>> Hack the code. Because it is even worse, as firefox for example does not obey
>> to the TTL.
>>
>
> It is not that simple. The checks are there for very good reason(s)
> related to security of the network using the proxy.
>
> The Host forgery issue being checked for allows network firewall rule
> bypass, browser same-origin bypass, and browser sandbox bypass - in a
> way which places the attacker in control of what logs you see [aha!
> invisible access to the network]. With all the related nasty
> side-effects those allow. There is both malware and services for sale
> around the 'net that take advantage of the attack to do those bypasses.
> => Simply disabling the check code is a *very* risky thing to do.
>
>
> The cases where Squid still gets it wrong are where the popular CDN
> service(s) in question are performing DNS actions indistinguishable to
> those malware attacks. If Squid can't tell the difference between an
> attack and normal DNS behaviour the only code change possible is to
> disable the check (see above about the risk level).
>
>
> FYI: I have a plan to reduce the false-positive rate from DNS rotation
> effects. But that requires some deep redesign of the DNS code, which I'm
> intending to do as part of the Squid-5 roadmap to avoid further
> destabilizing 4.x while its in beta.
>
> For now the workarounds are:
>
> * obey the requirement that destination NAT (if any) is performed only
> on the Squid machine.
>
> * to tune the lifetime for persistent client connections. That reduces
> (but not fully) connections outliving DNS rotation times and thus
> causing requests to have different ORIGINAL_DST from what DNS says.
>
> * if wanting Google 8.8.8.8 service as your resolver. Use a local DNS
> recursive resolver shared by Squid and client which points to that
> service as its parent/forwarded resolver. That removes the issue with
> every 8.8.8.8 response having different reply IP values (so client and
> Squid doing near simultaneous lookups get different IPs).
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From yvoinov at gmail.com  Tue Aug 30 19:24:38 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Aug 2016 01:24:38 +0600
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
 <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
 <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
Message-ID: <1002f7f8-b16a-889d-564d-e5325edef4e6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


30.08.2016 23:25, Marcus Kool ?????:
> Do I understand it correctly that Squid in normal proxy mode
> allows malware to do a CONNECT to any destination, while in
> transparent proxy mode does extra security checks which causes
> some regular (non-malware) clients to fail?
http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
>
> And philosophical questions: is Squid the right tool
> to stop malware?  If yes, is it acceptable that connections
> of regular (non-malware) clients are wrongly dropped?
http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP

>
> IMO Squid should do all it can to be a secure proxy.
> Doing security checks on connections in an attempt
> to stop malware sounds like a job for an antivirus / IDS tool.
http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
http://wiki.squid-cache.org/Features/SslPeekAndSplice


>
> Marcus
>
>
> On 08/30/2016 01:01 PM, Amos Jeffries wrote:
>> On 26/08/2016 6:34 a.m., reinerotto wrote:
>>> Hack the code. Because it is even worse, as firefox for example does
not obey
>>> to the TTL.
>>>
>>
>> It is not that simple. The checks are there for very good reason(s)
>> related to security of the network using the proxy.
>>
>> The Host forgery issue being checked for allows network firewall rule
>> bypass, browser same-origin bypass, and browser sandbox bypass - in a
>> way which places the attacker in control of what logs you see [aha!
>> invisible access to the network]. With all the related nasty
>> side-effects those allow. There is both malware and services for sale
>> around the 'net that take advantage of the attack to do those bypasses.
>> => Simply disabling the check code is a *very* risky thing to do.
>>
>>
>> The cases where Squid still gets it wrong are where the popular CDN
>> service(s) in question are performing DNS actions indistinguishable to
>> those malware attacks. If Squid can't tell the difference between an
>> attack and normal DNS behaviour the only code change possible is to
>> disable the check (see above about the risk level).
>>
>>
>> FYI: I have a plan to reduce the false-positive rate from DNS rotation
>> effects. But that requires some deep redesign of the DNS code, which I'm
>> intending to do as part of the Squid-5 roadmap to avoid further
>> destabilizing 4.x while its in beta.
>>
>> For now the workarounds are:
>>
>> * obey the requirement that destination NAT (if any) is performed only
>> on the Squid machine.
>>
>> * to tune the lifetime for persistent client connections. That reduces
>> (but not fully) connections outliving DNS rotation times and thus
>> causing requests to have different ORIGINAL_DST from what DNS says.
>>
>> * if wanting Google 8.8.8.8 service as your resolver. Use a local DNS
>> recursive resolver shared by Squid and client which points to that
>> service as its parent/forwarded resolver. That removes the issue with
>> every 8.8.8.8 response having different reply IP values (so client and
>> Squid doing near simultaneous lookups get different IPs).
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXxd12AAoJENNXIZxhPexGatAIAMvXwPnEHw5PR+fg+8KdxCQ3
h0fYEFKZHOI2P0b+kk7DRd/RG1mBdM23Hlr6EflqXGSigkuYF8fLGfx4iyo6BaXt
gOO4Z/CEoUCtjF8PPG8WWNaRz5kz4eZcMJM10gGJ0wke8ojDUJ11Z0TXorj7n9Ou
JRG2XuyP4RF2fHxOPsCvQRD1I7yiynMVXa8vsc6PHvlOru56rs/VTd86NX2jBFJf
TpM6UWrJzmZbUAIlrzhgllEPpgfUPzTdJX8eIFKQeVnOyq0i6o5pjc8wdg4CZUkw
naaYNTp/xsx/zfhW75xjKV4UuxCGiZy9zroiKpyu/EjnSUvtnQHVFrWyhvxCJrM=
=mPgV
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/ee89839a/attachment.key>

From yvoinov at gmail.com  Tue Aug 30 19:26:19 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Aug 2016 01:26:19 +0600
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <1002f7f8-b16a-889d-564d-e5325edef4e6@gmail.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
 <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
 <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
 <1002f7f8-b16a-889d-564d-e5325edef4e6@gmail.com>
Message-ID: <2fd6c5dd-9e8a-1d21-e697-7bd31ead7f5a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


31.08.2016 1:24, Yuri Voinov ?????:
>
>
>
> 30.08.2016 23:25, Marcus Kool ?????:
> > Do I understand it correctly that Squid in normal proxy mode
> > allows malware to do a CONNECT to any destination, while in
> > transparent proxy mode does extra security checks which causes
> > some regular (non-malware) clients to fail?
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
>
> > And philosophical questions: is Squid the right tool
> > to stop malware?  If yes, is it acceptable that connections
> > of regular (non-malware) clients are wrongly dropped?
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
Not stop all. But reduce.
>
>
> > IMO Squid should do all it can to be a secure proxy.
> > Doing security checks on connections in an attempt
> > to stop malware sounds like a job for an antivirus / IDS tool.
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
> http://wiki.squid-cache.org/Features/SslPeekAndSplice
>
>
>
> > Marcus
>
>
> > On 08/30/2016 01:01 PM, Amos Jeffries wrote:
> >> On 26/08/2016 6:34 a.m., reinerotto wrote:
> >>> Hack the code. Because it is even worse, as firefox for example does
> not obey
> >>> to the TTL.
> >>>
> >>
> >> It is not that simple. The checks are there for very good reason(s)
> >> related to security of the network using the proxy.
> >>
> >> The Host forgery issue being checked for allows network firewall rule
> >> bypass, browser same-origin bypass, and browser sandbox bypass - in a
> >> way which places the attacker in control of what logs you see [aha!
> >> invisible access to the network]. With all the related nasty
> >> side-effects those allow. There is both malware and services for sale
> >> around the 'net that take advantage of the attack to do those bypasses.
> >> => Simply disabling the check code is a *very* risky thing to do.
> >>
> >>
> >> The cases where Squid still gets it wrong are where the popular CDN
> >> service(s) in question are performing DNS actions indistinguishable to
> >> those malware attacks. If Squid can't tell the difference between an
> >> attack and normal DNS behaviour the only code change possible is to
> >> disable the check (see above about the risk level).
> >>
> >>
> >> FYI: I have a plan to reduce the false-positive rate from DNS rotation
> >> effects. But that requires some deep redesign of the DNS code,
which I'm
> >> intending to do as part of the Squid-5 roadmap to avoid further
> >> destabilizing 4.x while its in beta.
> >>
> >> For now the workarounds are:
> >>
> >> * obey the requirement that destination NAT (if any) is performed only
> >> on the Squid machine.
> >>
> >> * to tune the lifetime for persistent client connections. That reduces
> >> (but not fully) connections outliving DNS rotation times and thus
> >> causing requests to have different ORIGINAL_DST from what DNS says.
> >>
> >> * if wanting Google 8.8.8.8 service as your resolver. Use a local DNS
> >> recursive resolver shared by Squid and client which points to that
> >> service as its parent/forwarded resolver. That removes the issue with
> >> every 8.8.8.8 response having different reply IP values (so client and
> >> Squid doing near simultaneous lookups get different IPs).
> >>
> >> Amos
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users
> >>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXxd3bAAoJENNXIZxhPexGUbgH/j4qcbQW7u/zktJpJLlqhed3
+J7Qsr6eXyeC3ryG8q8w5CGAdP/ESoeJO/aA02uW/DEf517oH5kHxMtKdtyl9VNw
suqNAcFsk6F8fYG+9h2+0Zip2IN3IC8u2ArtZcVcd5QO/rruEEFLK6HX3K9cvOBn
guRq9LNa5DvX83cYhxdQIdDJ8eeGGOxcwteyajkeMfwskfx4dLeoDO2B4F56VKLA
ugVA7NBskVe2TiuhgfpZ4fOWslWaiZATma1beM4sa0KOvRUqxKuf0BJlnX+Llyzp
YsD1cPRXs4YftF6t4d/iV4BT+oUYKq4UugHNHgy3PqgKu9VFWoeX/dBmHRMYHQY=
=Siw+
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/0b1241a8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/0b1241a8/attachment.key>

From yvoinov at gmail.com  Tue Aug 30 19:27:59 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Aug 2016 01:27:59 +0600
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
 <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
 <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
Message-ID: <7dfc4d1b-9e7a-1506-6912-aa7a8c000b2f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
And this one:

http://wiki.squid-cache.org/ConfigExamples/Intercept/CiscoIOSv15Wccp2

of course.


30.08.2016 23:25, Marcus Kool ?????:
> Do I understand it correctly that Squid in normal proxy mode
> allows malware to do a CONNECT to any destination, while in
> transparent proxy mode does extra security checks which causes
> some regular (non-malware) clients to fail?
>
> And philosophical questions: is Squid the right tool
> to stop malware?  If yes, is it acceptable that connections
> of regular (non-malware) clients are wrongly dropped?
>
> IMO Squid should do all it can to be a secure proxy.
> Doing security checks on connections in an attempt
> to stop malware sounds like a job for an antivirus / IDS tool.
>
> Marcus
>
>
> On 08/30/2016 01:01 PM, Amos Jeffries wrote:
>> On 26/08/2016 6:34 a.m., reinerotto wrote:
>>> Hack the code. Because it is even worse, as firefox for example does
not obey
>>> to the TTL.
>>>
>>
>> It is not that simple. The checks are there for very good reason(s)
>> related to security of the network using the proxy.
>>
>> The Host forgery issue being checked for allows network firewall rule
>> bypass, browser same-origin bypass, and browser sandbox bypass - in a
>> way which places the attacker in control of what logs you see [aha!
>> invisible access to the network]. With all the related nasty
>> side-effects those allow. There is both malware and services for sale
>> around the 'net that take advantage of the attack to do those bypasses.
>> => Simply disabling the check code is a *very* risky thing to do.
>>
>>
>> The cases where Squid still gets it wrong are where the popular CDN
>> service(s) in question are performing DNS actions indistinguishable to
>> those malware attacks. If Squid can't tell the difference between an
>> attack and normal DNS behaviour the only code change possible is to
>> disable the check (see above about the risk level).
>>
>>
>> FYI: I have a plan to reduce the false-positive rate from DNS rotation
>> effects. But that requires some deep redesign of the DNS code, which I'm
>> intending to do as part of the Squid-5 roadmap to avoid further
>> destabilizing 4.x while its in beta.
>>
>> For now the workarounds are:
>>
>> * obey the requirement that destination NAT (if any) is performed only
>> on the Squid machine.
>>
>> * to tune the lifetime for persistent client connections. That reduces
>> (but not fully) connections outliving DNS rotation times and thus
>> causing requests to have different ORIGINAL_DST from what DNS says.
>>
>> * if wanting Google 8.8.8.8 service as your resolver. Use a local DNS
>> recursive resolver shared by Squid and client which points to that
>> service as its parent/forwarded resolver. That removes the issue with
>> every 8.8.8.8 response having different reply IP values (so client and
>> Squid doing near simultaneous lookups get different IPs).
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXxd4/AAoJENNXIZxhPexGwjwH+QHrd7xRMHLr1kTxd7cMoVtS
bMXLslGgtdno0T8hueLY68pCybfFSU/aO3HDg3V8SNvH8cx84ZSndqvUtbro3/Ze
Uzt+JQtvp8R7vyTgrfJFy02UJvxk6jtd88H/FSO0bp4vLNOxDg3H/OvxjyXuHU5C
fACXayHvZbf/IZzpEjyVWt2pKH9TBNK2eB2omqIQupFCGboIk70S2kpeA8L8+YKx
1hWq0QWY9esyi7b8OZwX2QnEU2M+eBYCn+KZHp6BorLfxOTcctpxM37Up3ieOON5
asyOC4MMmOAvqs4NSHgqfGB2Pybd6I0+wZ0yz576rZqscE/zfRxkbaZ3MqKT53s=
=ernf
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/6aec6f83/attachment.key>

From janis.heller at outlook.de  Tue Aug 30 20:10:16 2016
From: janis.heller at outlook.de (Janis Heller)
Date: Tue, 30 Aug 2016 20:10:16 +0000
Subject: [squid-users] SQUID3 FreeRADIUS
Message-ID: <VI1PR0101MB2192E276F22016EEEFA282B4F7E00@VI1PR0101MB2192.eurprd01.prod.exchangelabs.com>

How to use freeradius in squid3?
The wiki information I found is very outdated:

http://wiki.squid-cache.org/ConfigExamples/Authenticate/Radius

The path: "/usr/local/squid/libexec/squid_radius_auth -f /etc/radius_config? doesn?t exist anymore on SQUID3.

All the best;
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160830/4c2aa79b/attachment.htm>

From erdosain9 at gmail.com  Tue Aug 30 20:13:00 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 30 Aug 2016 13:13:00 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <32111747-1177-6735-ca32-b289378c3ec1@treenet.co.nz>
References: <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
 <1472501589650-4679253.post@n4.nabble.com>
 <32111747-1177-6735-ca32-b289378c3ec1@treenet.co.nz>
Message-ID: <1472587980055-4679268.post@n4.nabble.com>

Thanks.
But... 
I'm misunderstanding ?
Tx , is not the download?


I think it works this way in the mikrotik . That is, the transmission would
be the " download "



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679268.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Tue Aug 30 20:16:14 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 30 Aug 2016 13:16:14 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
References: <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
Message-ID: <1472588174138-4679269.post@n4.nabble.com>

By the way... 
I have this on log

https://fbcdn-video-k-a.akamaihd.net/hvideo-ak-xat1/v/t42.1790-2/12094265_992502374146158_1776024195_n.mp4?
- HIER_DIRECT/204.2.178.146 -

i do not know how to use https://regex101.com/

it will be like 

akamaihd\.net\/v\/(.*\.mp4)\? 

Thanks.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679269.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Tommy.Craddock at bicgraphic.com  Tue Aug 30 20:35:44 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Tue, 30 Aug 2016 20:35:44 +0000
Subject: [squid-users] SQUID3 FreeRADIUS
In-Reply-To: <VI1PR0101MB2192E276F22016EEEFA282B4F7E00@VI1PR0101MB2192.eurprd01.prod.exchangelabs.com>
References: <VI1PR0101MB2192E276F22016EEEFA282B4F7E00@VI1PR0101MB2192.eurprd01.prod.exchangelabs.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE73E1BFA@CLWSEXCMBX02.na.bicworld.com>

Hello,

The name of the helper was changed some time ago:

2.5 Helper Name Changes

To improve the understanding of what each helper does and where it should be used the helper binaries which are bundled with Squid have undergone a naming change in this release.

Below is a list of the old helper names and what their names have changed to. For several helpers the directory name used in --enable-X-helpers configure option has also changed.

Basic Authentication protocol helpers:


  *   squid_radius_auth - basic_radius_auth - Authenticate with RADIUS.

Source:
ftp://ftp.fu-berlin.de/unix/www/squid/archive/3.2/squid-3.2.0.12-RELEASENOTES.html

On RH and its derivatives, it will be at:

[root at clwslprox01p ~]# locate basic_radius_auth
/usr/lib64/squid/basic_radius_auth

May be different on other flavors, do a locate on it to find it.

Tommy Craddock Jr.


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Janis Heller
Sent: Tuesday, August 30, 2016 4:10 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] SQUID3 FreeRADIUS

How to use freeradius in squid3?
The wiki information I found is very outdated:

http://wiki.squid-cache.org/ConfigExamples/Authenticate/Radius

The path: "/usr/local/squid/libexec/squid_radius_auth -f /etc/radius_config? doesn?t exist anymore on SQUID3.

All the best;



______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160830/d99ecf13/attachment.htm>

From yvoinov at gmail.com  Tue Aug 30 20:48:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Aug 2016 02:48:05 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472588174138-4679269.post@n4.nabble.com>
References: <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
 <1472588174138-4679269.post@n4.nabble.com>
Message-ID: <1c954c25-3b7f-7968-ac43-faa34524d6bb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
To cache streaming video, you require to utilize Store-ID feature:

http://wiki.squid-cache.org/Features/StoreID


31.08.2016 2:16, erdosain9 ?????:
> By the way... 
> I have this on log
>
>
https://fbcdn-video-k-a.akamaihd.net/hvideo-ak-xat1/v/t42.1790-2/12094265_992502374146158_1776024195_n.mp4?
> - HIER_DIRECT/204.2.178.146 -
>
> i do not know how to use https://regex101.com/
>
> it will be like
>
> akamaihd\.net\/v\/(.*\.mp4)\?
>
> Thanks.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679269.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXxfEFAAoJENNXIZxhPexGPNAIAIuFAn/eijxhISMJity1Nu4i
TJOmsqM2RR9mCKwbbJSm+8M9fML7SNn/SH7V7nMgI01+WusgjBIgSpaIrT4ZNoP4
FinnYscibOC2oJPPmYBMp2dqdilIq+8MCMTjFzVwgJuYzxAeCtz5sgjlDpq8fNAp
nje6/q3TgfYYLuQwaQYseJO7ig3kvcDHa7vGrqdQzxPzk2epXnkx3EE5kmrU48hp
EWeAYh4yBa1wF5njtBJ57PhXtL0nTSXfm4ZJVsn87fBQQGqeqz+Smgw1HbX7qtLH
0zCXf3jZyud3wcA+nGM0xxDSEEKVw3j6KUKtFXC99iqredrVIsFyHnzhFODKEIc=
=933O
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/15588433/attachment.key>

From yvoinov at gmail.com  Tue Aug 30 20:51:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Aug 2016 02:51:57 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1c954c25-3b7f-7968-ac43-faa34524d6bb@gmail.com>
References: <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
 <1472588174138-4679269.post@n4.nabble.com>
 <1c954c25-3b7f-7968-ac43-faa34524d6bb@gmail.com>
Message-ID: <a9a0d7bc-3d6f-3635-c829-9a6f72a47ad0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
And, to limit faceboot video,
 you require to utilize akamaihd\.net\/v\/(.*\.mp4)\? regex in
conjunction with delay-pool + SSL bump. :)

31.08.2016 2:48, Yuri Voinov ?????:
>
> To cache streaming video, you require to utilize Store-ID feature:
>
> http://wiki.squid-cache.org/Features/StoreID
>
>
> 31.08.2016 2:16, erdosain9 ?????:
> > By the way...
> > I have this on log
>
>
>
https://fbcdn-video-k-a.akamaihd.net/hvideo-ak-xat1/v/t42.1790-2/12094265_992502374146158_1776024195_n.mp4?
> > - HIER_DIRECT/204.2.178.146 -
>
> > i do not know how to use https://regex101.com/
>
> > it will be like
>
> > akamaihd\.net\/v\/(.*\.mp4)\?
>
> > Thanks.
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679269.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXxfHrAAoJENNXIZxhPexGanwH+wXVGdAz0hdbK6Pof0vZlXHz
poxITiDr/hS3IUU5hiFNIsXS4fHRHZBkAH5m9jxnwgo2kOIu4KQ8MJh7eUmV3gAi
Qu+r0A/S3U3CWpbPpRMvbhyK9X+7434vWE6Qeuywc7WjtEnf+Pjwo5/yVwf+p2IN
ntdZwJaYc8loQcTgofYw+ARYBeRP6f9H9BUIrmTwm91HaPP1XYo4/XxL+wfmbjtI
CiAtW0bu4xi479cG7HaWkwSs3MnXz2lZGD/usBqpvZi+L3N4Kjh3cE5ZDDM8P2/h
lJqIZiIJAjkV6z6ychdZgp8KYZcvpbVPAodZZ4NTRe/NGRwx/MyHIFoaSO2TjZ4=
=TIqC
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/8a353483/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/8a353483/attachment.key>

From yvoinov at gmail.com  Tue Aug 30 21:08:25 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 31 Aug 2016 03:08:25 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <a9a0d7bc-3d6f-3635-c829-9a6f72a47ad0@gmail.com>
References: <1472159415603-4679199.post@n4.nabble.com>
 <8bc269c9-c352-e616-5e7a-f3c9548bd7b2@gmail.com>
 <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
 <1472588174138-4679269.post@n4.nabble.com>
 <1c954c25-3b7f-7968-ac43-faa34524d6bb@gmail.com>
 <a9a0d7bc-3d6f-3635-c829-9a6f72a47ad0@gmail.com>
Message-ID: <4143f16f-4e0e-e582-051b-9d9667e6aa61@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I did not say it would be easy, right? :)

31.08.2016 2:51, Yuri Voinov ?????:
>
> And, to limit faceboot video,
>  you require to utilize akamaihd\.net\/v\/(.*\.mp4)\? regex in
conjunction with delay-pool + SSL bump. :)
>
> 31.08.2016 2:48, Yuri Voinov ?????:
>
>
>       > To cache streaming video, you require to utilize Store-ID
>       feature:
>
>
>
>       > http://wiki.squid-cache.org/Features/StoreID
>
>
>
>
>
>       > 31.08.2016 2:16, erdosain9 ?????:
>
>       > > By the way...
>
>       > > I have this on log
>
>
>
>
>
>
>
https://fbcdn-video-k-a.akamaihd.net/hvideo-ak-xat1/v/t42.1790-2/12094265_992502374146158_1776024195_n.mp4?
>
>       > > - HIER_DIRECT/204.2.178.146 -
>
>
>
>       > > i do not know how to use https://regex101.com/
>
>
>
>       > > it will be like
>
>
>
>       > > akamaihd\.net\/v\/(.*\.mp4)\?
>
>
>
>       > > Thanks.
>
>
>
>
>
>
>
>       > > --
>
>       > > View this message in context:
>
>
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679269.html
>
>       > > Sent from the Squid - Users mailing list archive at
>       Nabble.com.
>
>       > > _______________________________________________
>
>       > > squid-users mailing list
>
>       > > squid-users at lists.squid-cache.org
>
>       > > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXxfXJAAoJENNXIZxhPexGpLkIAL8qff5Ky6ZEYXgBnc3MVxIx
elo//UatXQHcELnPdSpFpC+5W+bSF5KMyBtzZy3zThsy7ipcT2iKwUP/9e00uCWY
fVQcbFUIiu9bR9M3LGhJuG7mUVtER2MBkX/wPUuRUpAabKRRZ05TlpIaYyUteU7A
GDuA74l/X3j26/XOeY0zPishz1V8enPLmgyO5ZvL3t16YjXKF2QWLkoe4gkSHLHr
+HWqXn1yYGa+XoJetZAgTbLp4eNhoBNC6ZOIs1ThRzkUFfuDjexCVinJX1E3JLYC
CBBQ+PBQIiirML0u3WwA02ad0pIeyeUEZ4eV6ZnHuXX8wZyuaD2H/DiSwW/90vI=
=bQ0e
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/baae8b80/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/baae8b80/attachment.key>

From gregory_shively at fanniemae.com  Tue Aug 30 23:19:10 2016
From: gregory_shively at fanniemae.com (Shively, Gregory)
Date: Tue, 30 Aug 2016 19:19:10 -0400
Subject: [squid-users] Transparent Proxy on OSX Yosemite
Message-ID: <F25802A5228F1345B9BD8093E210C3B90257AAB7BE@EXWCMS01.fanniemae.com>

I'm attempting to get a squid working as a transparent proxy on OSX Yosemite. Every attempt ended with a "Forward loop detected". I initially started with the version from homebrew and moved to just compiling myself to see if I could figure out what was going on. Being new to both pf network and squid, it might be something that I have configured wrong. I configured pf similar to:

              nat on $ext_if proto {udp, tcp} from $int_if:network to any port domain -> ($ext_if)
              rdr pass on $int_if proto tcp from $int_if:network to any port {http, https} -> 127.0.0.1 port 3129

And my squid.conf for my testing is basically:

http_port 3128
http_port 3129 intercept
http_access allow all

I'm not sure if this is more appropriate on this mailing list or the developer mailing list (hoping it is just something I'm doing wrong). The squid that I'm using doesn't have -with-nat-devpf enabled; it fails to compile with that option. I'm wondering if the getsockname() as per comment for PFIntercept (of the !_USE_NAT_DEVPF) in src/ip/Intercept.cc, on OSX is not returning the pre-rdr address and causing the forward loop.

As mentioned, the -with-nat-devpf fails to compile on OSX due to a missing header file. And from looking it sounds like the header is for the ioctl() on /dev/pf, which doesn't seem to be public API on OSX. So I'm trying to determine if my issue is due to a misconfiguration - or is this portion of the code not working with OSX. I looked at the code for mitmproxy, and it seems like they require a sudoers entry to run "pfctl -s state" and parse the state. Would something like that need to be added to squid to support transparent proxy on OSX. I had started to put some code together like mitmproxy, but thought better check if I didn't get something configured correctly.

Greg
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160830/231fc8ad/attachment.htm>

From hibandx at gmail.com  Wed Aug 31 01:55:47 2016
From: hibandx at gmail.com (hibandx)
Date: Tue, 30 Aug 2016 18:55:47 -0700 (PDT)
Subject: [squid-users] Acl to deny all sites, and allow some sites
Message-ID: <1472608547291-4679275.post@n4.nabble.com>

So, i have an squid configured and ok with ad 2012, but the acl
Proxy_restrito is not working...

This acl is for 

any solution?

This is my conf is for deny all sites, and allow just some sites on file
proxy_restrito_whitelist...

follow:

#Porta padr?o do proxy
http_port 3128
 
#Endereco de E-mail do administrador do proxy
cache_mgr suporte at dominio.local
 
#Nao faz cache de dados de formularios html,em de resultados de programas
cgi                      
#hierarchy_stoplist cgi-bin ?
 
#Cria uma access control list, baseando-se na url e utilizando exp.
regulares nesta situacao   
#foi criado uma exp. regular para cgi e ?.        
acl QUERY urlpath_regex cgi-bin \?
 
#Nao faz cache da acl QUERY                        
cache deny QUERY
 
#Define o tamonho maximo de um objeto para seu armazenamento no cache local                 
maximum_object_size 4096 KB
 
#Define o tamanho minimo de um objeto para seu armazenamento no cache local                 
minimum_object_size 0 KB
 
#Define o tamanho maximo de um objeto para seu armazenamento no cache de
memoria            
maximum_object_size_in_memory 64 KB
 
#Definicao da quantidade de memoria ram a ser alocada para cache                                
cache_mem 60 MB
 
#Para nao bloquear downloads                       
quick_abort_min -1 KB
 
# Resolve um problema com conex?es persistentes que ocorre com certos
servidores,
# e que provoca delays em nosso cache.
detect_broken_pconn on
 
# Provoca um ganho de performance ao usar conex?es Pipeline (requisi??es em
paralelo)
pipeline_prefetch on
 
 
#Para cache de fqdn
fqdncache_size 1024

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:   1440  20% 10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
refresh_pattern .   0 20% 4320

#Definicao da porcentagem do uso do cache que fara o squid descartar os
arquivos mais antigos                                    
cache_swap_low 90
cache_swap_high 95
 
#Logs   
access_log /var/log/squid/access.log squid
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log
 
#Define a localizacao do cache de disco, tamanho, qtd de diretorios pai, e
por fim a qtd de dir filhos                   
cache_dir aufs /var/spool/squid 100 16 256
 
#Controle do arquivo de Log
logfile_rotate 10
 
#Arquivo que contem os nomes de maquinas           
hosts_file /etc/hosts
 
#Maquinas que nao precisaram de autenticacao   
acl liberados dstdomain "/etc/squid/regras/liberados"
http_access allow liberados
 
#liberar o acesso ao site da caixa que est? com problemas 
#acl caixa dstdomain caixa.gov.br
#always_direct allow caixa
#cache deny caixa
 
#MACS que est?o liberados.
acl macliberado   arp "/etc/squid/regras/mac_liberado"
http_access allow macliberado
 
 
### ACL Padroes
acl SSL_ports port 443 # https
acl SSL_ports port 563 # snews
acl SSL_ports port 873 # rsync
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 563 # https, snews
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl Safe_ports port 631 # cups
acl Safe_ports port 873 # rsync
acl Safe_ports port 901 # SWAT
acl Safe_ports port 1080
acl Safe_ports port 1863
acl Safe_ports port 8443 # https
acl Safe_ports port 5222 # gTalk
acl Safe_ports port 5223 # gTalk
acl Safe_ports port 47057 # torrent

acl purge method PURGE
acl CONNECT method CONNECT

http_access allow manager localhost
http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

#Limita conexeos HTTP
#acl connect_abertas maxconn 8

#sites que n?o ser?o feito cache geralmente bancos
acl NOCACHE dstdomain "/etc/squid/regras/direto" \?
no_cache deny NOCACHE

 
#### Autenticao no Windows 2008/2012/Samba 4 via WINBIND
auth_param ntlm program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 30
auth_param basic program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-basic
auth_param basic children 5
auth_param basic realm Squid proxy server
auth_param basic credentialsttl 2 hours
#Note que abaixo o meu sistema ? 64 ent?o as minhas libs est?o em /usr/lib64
caso esteja utilizando sistema 32 troque para /usr/lib
external_acl_type ad_group ttl=1800 children=200 %LOGIN
/usr/lib64/squid/ext_wbinfo_group_acl

#-----------------------------------------------------------------------------------#
#       Nome ACL                TIPO                    Nome Grupo AD              
#
#-----------------------------------------------------------------------------------#

acl    proxy_livre        external ad_group          proxy_livre
acl    proxy_geral           external ad_group          proxy_geral
acl    proxy_restrito      external ad_group         proxy_restrito


# Whitelists / Blacklists
acl downloads         urlpath_regex -i "/etc/squid/regras/downloads"
acl proxy_restrito_whitelist url_regex -i
"/etc/squid/regras/proxy_restrito_whitelist"
acl proxy_geral_bracklist   url_regex  -i
"/etc/squid/regras/proxy_geral_blacklist"
acl proxy_livre_proibidos	url_regex	 -i
"/etc/squid/regras/proxy_livre_proibidos"

#Bloquear determinados usu?rios autenticados
acl usuarios_bloqueados proxy_auth "/etc/squid/regras/usuarios_bloqueados"
 
#Controle de acesso por hor?rio aqui, vamos liberar o acesso no hor?rio do
almo?o
#aqui os usu?rio v?o poder acessar alguns sites diferenciados entre as 12:00
at? as 13:00
#acl almoco time MTWHFAS 12:30-13:30

#Agora vamos criar uma regra para garantir que os usu?rios que v?o acessar
no almo?o est?o autenticados
acl autenticados proxy_auth REQUIRED

#Agora vamos criar uma lista de sites que eles v?o poder acessar no hor?rio
do almo?o
acl sites-almoco   url_regex     -i "/etc/squid/regras/sites_almoco"

# Permissoes de Acesso
http_access allow proxy_livre !proxy_livre_proibidos
#Aqui vamos cruzar as acls para garantir que os usu?rios que v?o acessar os
sites no almo?o estejam autenticados
#http_access allow almoco autenticados sites-almoco
http_access deny  downloads
http_access deny  usu_bloqueados
http_access allow proxy_geral !proxy_geral_bracklist
http_access deny proxy_restrito 	!proxy_restrito_whitelist
############################################################
http_access deny all
http_reply_access allow all
icp_access allow all
miss_access allow all
visible_hostname proxy
error_directory /usr/share/squid/errors/pt-br
#cache_effective_group squid
cache_effective_user squid
coredump_dir /var/spool/squid



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Acl-to-deny-all-sites-and-allow-some-sites-tp4679275.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Ralf.Hildebrandt at charite.de  Wed Aug 31 08:20:10 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Wed, 31 Aug 2016 10:20:10 +0200
Subject: [squid-users] TCP_TUNNEL_ABORTED/200?
Message-ID: <20160831082010.rcsl4fvw3b776e4u@charite.de>

One of our users is trying to connect to somw windows remoteapps via
out squid proxy.

Logging in does seem to work, but somewhere along the line, the user
is getting error messages. In our logs we're seeing the encrypted
traffic (TCP_TUNNEL/200 CONNECT remoteapps.eortc.be:443), but then
we're getting "TCP_TUNNEL_ABORTED/200" messages

I can't find anything on what exactly would cause a
"TCP_TUNNEL_ABORTED/200"

Wed Aug 31 09:33:15 2016 000330 10.39.80.171 TCP_TUNNEL/200 3177 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18724
Wed Aug 31 09:35:15 2016 120329 10.39.80.171 TCP_TUNNEL_ABORTED/200 730 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18728
Wed Aug 31 09:35:15 2016 120330 10.39.80.171 TCP_TUNNEL_ABORTED/200 778 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18726
Wed Aug 31 09:35:15 2016 120531 10.39.80.171 TCP_TUNNEL_ABORTED/200 97549 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18704
Wed Aug 31 09:35:15 2016 120520 10.39.80.171 TCP_TUNNEL_ABORTED/200 35620 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18716
Wed Aug 31 09:35:15 2016 120530 10.39.80.171 TCP_TUNNEL_ABORTED/200 21295 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18706
Wed Aug 31 09:35:15 2016 120530 10.39.80.171 TCP_TUNNEL_ABORTED/200 4607 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18708
Wed Aug 31 09:35:15 2016 121397 10.39.80.171 TCP_TUNNEL_ABORTED/200 63224 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18622
Wed Aug 31 09:35:15 2016 120531 10.39.80.171 TCP_TUNNEL_ABORTED/200 8175 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18710
Wed Aug 31 09:35:15 2016 120530 10.39.80.171 TCP_TUNNEL_ABORTED/200 5663 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18712
Wed Aug 31 09:35:15 2016 120529 10.39.80.171 TCP_TUNNEL_ABORTED/200 4575 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 18714
Wed Aug 31 09:40:17 2016 000623 10.39.80.171 TCP_TUNNEL/200 5737 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40220
Wed Aug 31 09:40:25 2016 008522 10.39.80.171 TCP_TUNNEL_ABORTED/200 12575 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40222
Wed Aug 31 09:41:35 2016 079147 10.39.80.171 TCP_TUNNEL/200 13785 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40216
Wed Aug 31 09:41:35 2016 079143 10.39.80.171 TCP_TUNNEL/200 1050 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40224
Wed Aug 31 09:41:35 2016 079137 10.39.80.171 TCP_TUNNEL/200 1050 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40226
Wed Aug 31 09:41:35 2016 079148 10.39.80.171 TCP_TUNNEL/200 3359 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40218
Wed Aug 31 09:41:35 2016 079443 10.39.80.171 TCP_TUNNEL/200 6190 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40120
Wed Aug 31 09:41:35 2016 081507 10.39.80.171 TCP_TUNNEL/200 108336 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 39584
Wed Aug 31 09:41:35 2016 079441 10.39.80.171 TCP_TUNNEL/200 6222 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40122
Wed Aug 31 09:41:35 2016 079440 10.39.80.171 TCP_TUNNEL/200 5214 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40126
Wed Aug 31 09:41:35 2016 079440 10.39.80.171 TCP_TUNNEL/200 5956 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40128
Wed Aug 31 09:41:35 2016 079442 10.39.80.171 TCP_TUNNEL/200 3508 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40124
Wed Aug 31 09:42:39 2016 064005 10.39.80.171 TCP_TUNNEL/200 10591 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 54632
Wed Aug 31 09:43:51 2016 071666 10.39.80.171 TCP_TUNNEL/200 101799 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 10486
Wed Aug 31 09:44:41 2016 000429 10.39.80.171 TCP_TUNNEL/200 5621 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 32494
Wed Aug 31 09:45:29 2016 000406 10.39.80.171 TCP_TUNNEL/200 5621 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 40374
Wed Aug 31 09:46:10 2016 138175 10.39.80.171 TCP_TUNNEL_ABORTED/200 121039 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24594
Wed Aug 31 09:46:10 2016 138416 10.39.80.171 TCP_TUNNEL_ABORTED/200 13286 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24538
Wed Aug 31 09:46:10 2016 138415 10.39.80.171 TCP_TUNNEL_ABORTED/200 8791 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24544
Wed Aug 31 09:46:10 2016 139221 10.39.80.171 TCP_TUNNEL_ABORTED/200 118413 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24388
Wed Aug 31 09:46:10 2016 138178 10.39.80.171 TCP_TUNNEL_ABORTED/200 10392 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24590
Wed Aug 31 09:46:10 2016 138177 10.39.80.171 TCP_TUNNEL_ABORTED/200 10764 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24592
Wed Aug 31 09:46:10 2016 138414 10.39.80.171 TCP_TUNNEL_ABORTED/200 11425 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24546
Wed Aug 31 09:46:10 2016 138416 10.39.80.171 TCP_TUNNEL_ABORTED/200 9879 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24542
Wed Aug 31 09:46:10 2016 138181 10.39.80.171 TCP_TUNNEL_ABORTED/200 26016 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24588
Wed Aug 31 09:46:10 2016 138185 10.39.80.171 TCP_TUNNEL_ABORTED/200 114372 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24586
Wed Aug 31 09:46:10 2016 138187 10.39.80.171 TCP_TUNNEL_ABORTED/200 10455 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24584
Wed Aug 31 09:46:10 2016 138419 10.39.80.171 TCP_TUNNEL_ABORTED/200 13697 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 24540
Wed Aug 31 09:59:48 2016 000465 10.39.80.171 TCP_TUNNEL/200 54536 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41176
Wed Aug 31 09:59:54 2016 006016 10.39.80.171 TCP_TUNNEL/200 112172 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41230
Wed Aug 31 10:00:25 2016 030812 10.39.80.171 TCP_TUNNEL/200 18483 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41696
Wed Aug 31 10:02:22 2016 147993 10.39.80.171 TCP_TUNNEL/200 1540 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41694
Wed Aug 31 10:02:22 2016 154295 10.39.80.171 TCP_TUNNEL/200 5192 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41198
Wed Aug 31 10:02:22 2016 154301 10.39.80.171 TCP_TUNNEL/200 11304 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41190
Wed Aug 31 10:02:22 2016 154079 10.39.80.171 TCP_TUNNEL/200 7592 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41224
Wed Aug 31 10:02:22 2016 154078 10.39.80.171 TCP_TUNNEL/200 3491 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41226
Wed Aug 31 10:02:22 2016 154297 10.39.80.171 TCP_TUNNEL/200 5096 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41194
Wed Aug 31 10:02:22 2016 154303 10.39.80.171 TCP_TUNNEL/200 25293 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41188
Wed Aug 31 10:02:22 2016 154297 10.39.80.171 TCP_TUNNEL/200 6317 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41196
Wed Aug 31 10:02:22 2016 154300 10.39.80.171 TCP_TUNNEL/200 3491 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41192
Wed Aug 31 10:02:22 2016 154079 10.39.80.171 TCP_TUNNEL/200 9875 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41228
Wed Aug 31 10:02:22 2016 154296 10.39.80.171 TCP_TUNNEL/200 4963 CONNECT remoteapps.eortc.be:443 - HIER_DIRECT/193.9.9.153 - 41200


-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From fredbmail at free.fr  Wed Aug 31 08:46:19 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 31 Aug 2016 10:46:19 +0200 (CEST)
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <620312882.781429350.1472633092073.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1535002212.781434297.1472633179254.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello,

I saw this in rock store documentation

        If possible, Squid using Rock Store creates a dedicated kid
        process called "disker" to avoid blocking Squid worker(s) on disk
        I/O. One disker kid is created for each rock cache_dir.  Diskers
        are created only when Squid, running in daemon mode, has support
        for the IpcIo disk I/O module.

So I tried

--enable-disk-io=AIO,Blocking,DiskThreads,IpcIo,Mmapped

But there is a segfault at start, FI same result with diskd ...

OK so I'm trying now --enable-disk-io=yes and there no more disker process, I'm doing something wrong ?
Perhaps this process is only created in smp mode ?

Fred


From fredbmail at free.fr  Wed Aug 31 09:45:36 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 31 Aug 2016 11:45:36 +0200 (CEST)
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <1535002212.781434297.1472633179254.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <2128452263.781794292.1472636736761.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> --enable-disk-io=AIO,Blocking,DiskThreads,IpcIo,Mmapped

Wrong sorry, crash with diskd only because DiskDaemon is missing 

> 
> But there is a segfault at start, FI same result with diskd ...
> 
> OK so I'm trying now --enable-disk-io=yes and there no more disker
> process, I'm doing something wrong ?
> Perhaps this process is only created in smp mode ?

Still present 


> 
> Fred
> _______________________________________________


From drcimino at mail.com  Wed Aug 31 12:37:47 2016
From: drcimino at mail.com (akn ab)
Date: Wed, 31 Aug 2016 14:37:47 +0200
Subject: [squid-users] Debugging NTLM problem
Message-ID: <trinity-8fd3ad57-d083-4981-8f17-58fc5cd8c047-1472647067151@3capp-mailcom-lxa15>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/9211d451/attachment.htm>

From squid3 at treenet.co.nz  Wed Aug 31 14:25:51 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Sep 2016 02:25:51 +1200
Subject: [squid-users] TCP_TUNNEL_ABORTED/200?
In-Reply-To: <20160831082010.rcsl4fvw3b776e4u@charite.de>
References: <20160831082010.rcsl4fvw3b776e4u@charite.de>
Message-ID: <165d94cb-6bf8-f749-0c17-32e03a9bb659@treenet.co.nz>

On 31/08/2016 8:20 p.m., Ralf Hildebrandt wrote:
> One of our users is trying to connect to somw windows remoteapps via
> out squid proxy.
> 
> Logging in does seem to work, but somewhere along the line, the user
> is getting error messages. In our logs we're seeing the encrypted
> traffic (TCP_TUNNEL/200 CONNECT remoteapps.eortc.be:443), but then
> we're getting "TCP_TUNNEL_ABORTED/200" messages
> 
> I can't find anything on what exactly would cause a
> "TCP_TUNNEL_ABORTED/200"

A client that disconnects before the server has finished sending data,
or before Squid has relayed the data it sent to the server.

The TUNNEL and 200 parts means Squid connected to the requested server.
The ABORTED that the client disconnected while tunnel data was still in
transit.

What that 'in transit' stuff might be depends on the application and how
it works.

Amos



From erdosain9 at gmail.com  Wed Aug 31 14:26:11 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 31 Aug 2016 07:26:11 -0700 (PDT)
Subject: [squid-users] HTTPS chrome  - SHA1 this page is insecure
Message-ID: <1472653571328-4679281.post@n4.nabble.com>

Hi.
Im using ssl-bump.. all ir working fine, but i want to know if it is
possible that which is not seen crossed out and red "https".
This happen just in Chrome
This page is insecure (broken HTTPS)
SHA-1 Certificate
The certificate for this site expires in 2017 or later, and the certificate
chain contains a certificate signed using SHA-1.

Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HTTPS-chrome-SHA1-this-page-is-insecure-tp4679281.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Aug 31 14:40:38 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Sep 2016 02:40:38 +1200
Subject: [squid-users] Transparent Proxy on OSX Yosemite
In-Reply-To: <F25802A5228F1345B9BD8093E210C3B90257AAB7BE@EXWCMS01.fanniemae.com>
References: <F25802A5228F1345B9BD8093E210C3B90257AAB7BE@EXWCMS01.fanniemae.com>
Message-ID: <abfba7dd-984a-36ba-6504-b734156e2b19@treenet.co.nz>

On 31/08/2016 11:19 a.m., Shively, Gregory wrote:
> I'm attempting to get a squid working as a transparent proxy on OSX
> Yosemite. Every attempt ended with a "Forward loop detected". I
> initially started with the version from homebrew and moved to just
> compiling myself to see if I could figure out what was going on.
> Being new to both pf network and squid, it might be something that I
> have configured wrong. I configured pf similar to:
> 
>    nat on $ext_if proto {udp, tcp} from $int_if:network to any port domain -> ($ext_if)
>    rdr pass on $int_if proto tcp from $int_if:network to any port {http, https} -> 127.0.0.1 port 3129
> 
> And my squid.conf for my testing is basically:
> 
> http_port 3128
> http_port 3129 intercept
> http_access allow all
> 

> I'm not sure if this is more appropriate on this mailing list or the
> developer mailing list (hoping it is just something I'm doing wrong).
> The squid that I'm using doesn't have -with-nat-devpf enabled; it
> fails to compile with that option. I'm wondering if the getsockname()
> as per comment for PFIntercept (of the !_USE_NAT_DEVPF) in
> src/ip/Intercept.cc, on OSX is not returning the pre-rdr address and
> causing the forward loop.

Your access.log can show that. It shows up as the server the transaction
is being sent to being port 3128/3129 on 127.0.0.1 or another IP
assigned to the Squid machine.

> 
> As mentioned, the -with-nat-devpf fails to compile on OSX due to a
> missing header file. And from looking it sounds like the header is
> for the ioctl() on /dev/pf, which doesn't seem to be public API on
> OSX. So I'm trying to determine if my issue is due to a
> misconfiguration - or is this portion of the code not working with
> OSX.

It has been a long time since anyone using MacOS has provided any
particular feedback about Squid behaviour on MacOS. So it could be just
bugs when running on MacOS.


> I looked at the code for mitmproxy, and it seems like they
> require a sudoers entry to run "pfctl -s state" and parse the state.
> Would something like that need to be added to squid to support
> transparent proxy on OSX. I had started to put some code together
> like mitmproxy, but thought better check if I didn't get something
> configured correctly.

Squid (when built with the /dev/pf support) master process which is run
as root [you are running Squid from the root account right?] should be
preserving its permission to access the device before it drops down to
low privilege levels for handling the network traffic.

Some other troubleshooting things to try:

* using the machines public IP addres instead of 127.0.0.1. There are
hardware or driver level restrictions on locahost addresses that often
prohibit that type of NAT.

* using a divert-to rule instead of rdr. If your PF firewall accepts
that and the 'tproxy' option in squid.conf works then the /dev/pf is not
relevant. rdr sometimes does not work when divert-to is fine.

* check the PF version in your MacOS. If it derives from OpenBSD 4.8 or
later then the .dev.pf is not relevant - rdr/divert-to failure is then a
bug somewhere AFAIK.


Amos



From rousskov at measurement-factory.com  Wed Aug 31 14:47:44 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 31 Aug 2016 08:47:44 -0600
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <1535002212.781434297.1472633179254.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1535002212.781434297.1472633179254.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <8d554ef6-6c7a-4b1b-16a5-d5abc52ed19a@measurement-factory.com>

On 08/31/2016 02:46 AM, FredB wrote:

> I saw this in rock store documentation
> 
>         If possible, Squid using Rock Store creates a dedicated kid
>         process called "disker" to avoid blocking Squid worker(s) on disk
>         I/O. One disker kid is created for each rock cache_dir.  Diskers
>         are created only when Squid, running in daemon mode, has support
>         for the IpcIo disk I/O module.

The above sounds correct to me.


> OK so I'm trying now --enable-disk-io=yes and there no more disker
> process, I'm doing something wrong ?

Normally, you do not need any ./configure options to enable Rock
support, including support for a stand-alone disker process. If you want
to enable IpcIo explicitly, you may, but I would first check whether it
was enabled without any --enable-disk-io options:

> $ fgrep IpcIo config.log 
> configure:21195: Enabling IpcIo DiskIO module
> configure:21227: IO Modules built:  AIO Blocking DiskDaemon DiskThreads IpcIo Mmapped

IpcIo requires shared memory support bust most modern build environments
provide that.


> Perhaps this process is only created in smp mode ?

As the documentation tries to imply, the disker process is used when all
of the statements below are true:

* there are rock cache_dir(s) in squid.conf
* IpcIo disk I/O module is enabled (it usually is by default)
* Squid was started without the -N command line option.


HTH,

Alex.



From squid3 at treenet.co.nz  Wed Aug 31 15:10:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Sep 2016 03:10:58 +1200
Subject: [squid-users] Debugging NTLM problem
In-Reply-To: <trinity-8fd3ad57-d083-4981-8f17-58fc5cd8c047-1472647067151@3capp-mailcom-lxa15>
References: <trinity-8fd3ad57-d083-4981-8f17-58fc5cd8c047-1472647067151@3capp-mailcom-lxa15>
Message-ID: <f1165df6-eb78-529e-9068-0106b45f0d1e@treenet.co.nz>

On 1/09/2016 12:37 a.m., akn ab wrote:
> Dear all,
> i'm facing a strange problem using squid 3.5.20 with ntlm transparent 
> authentication.
> I cannot use kerberos auth because i need to pass DOMAIN\user to my parent proxy 
> with x-authenticated-user header, and the form USERNAME at DOMAIN is not supported.
> Users can surf the web without problems but, sometimes, they receive request 
> credential popup from browser (explorer, edge, mozilla and chrome it does not 
> matter).
> auth_param ntlm program /usr/local/samba/bin/ntlm_auth 
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 300 startup=200 idle=10 concurrency=0
> auth_param ntlm keep_alive on
> auth_param basic program /usr/local/samba/bin/ntlm_auth 
> --helper-protocol=squid-2.5-basic
> auth_param basic children 25 startup=15 idle=5 concurrency=0
> auth_param basic realm PROXY AUTHORIZATION REQUIRED
> auth_param basic credentialsttl 30 minutes
> authenticate_cache_garbage_interval 1 hours
> authenticate_ttl 30 minutes
> authenticate_ip_ttl 30 minutes
>
> I migrated from squid 2.6.x and, with similar configuration, the required 
> credentials was displayed only when the password was expired.
> In this situation,  users must click on abort button many times to restore a 
> good situation, but i cannot understand why the request popup suddenly.
> Is this a credentials cache timeout problm (authenticate_ttl 30 minutes)?

Maybe. If so its not an NTLM problem since NTLM credentials are "cached"
by being tied to the TCP connection state, not stored in a regular cache
like Basic auth credentials.

I suggest trying:
  auth_param ntlm keep_alive off

Squid-3 is now HTTP/1.1 which behaves a bit differently with persistent
connectiosn than HTTP/1.0 did. Which affects the pile of nasty hacks
needed to make NTLM work over HTTP.

> Is this a problem in the browser?

Yes, at least partially. The popup only occurs when the browser thinks
none of its credentials are valid to send to the proxy. Why it thinks
that might be a browser bug or a Squid bug. Or just the way NTLM behaves
in some HTTP message circumstances.

> Is this a comunication problem with squind and Active Directory?

Unlikely. It's more probably between Squid and browser. Squid only
interacts with AD at the start of a new TCP connection, or when NTLM is
started on an existing connection.

It could be browser sending unacceptible credentials (eg. the users
machine's account instead of the users own account) then deciding NTLM
is unusable.

It could be the browser failing to send the right NTLM token for Squid
to check against the existing known credentials tied to the connection.


> I would like to undestrand why, so i need advices to start debug and find a 
> solution.

<http://wiki.squid-cache.org/KnowledgeBase/DebugSections>

Section 29 is the various authenticators. You will also need the ACL
processing section and results.

Amos



From squid3 at treenet.co.nz  Wed Aug 31 15:15:51 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Sep 2016 03:15:51 +1200
Subject: [squid-users] HTTPS chrome - SHA1 this page is insecure
In-Reply-To: <1472653571328-4679281.post@n4.nabble.com>
References: <1472653571328-4679281.post@n4.nabble.com>
Message-ID: <132fa841-bddd-630a-85c1-a0475e9480a8@treenet.co.nz>

On 1/09/2016 2:26 a.m., erdosain9 wrote:
> Hi.
> Im using ssl-bump.. all ir working fine, but i want to know if it is
> possible that which is not seen crossed out and red "https".
> This happen just in Chrome
> This page is insecure (broken HTTPS)
> SHA-1 Certificate
> The certificate for this site expires in 2017 or later, and the certificate
> chain contains a certificate signed using SHA-1.

This requires changes to the certificate generator used by SSL-Bump.
IIRC there were some patches, but I can't find them right now in the
changesets. If the issue exists in current releases then please ask on
squid-dev.

Of course, its possible the site realy does have a SHA1 certificate and
Squid is just passing on the real details. The mimic feature is designed
to ensure TLS is actually transparent as best we can manage.

Amos



From squid3 at treenet.co.nz  Wed Aug 31 15:23:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Sep 2016 03:23:39 +1200
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472587980055-4679268.post@n4.nabble.com>
References: <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
 <1472501589650-4679253.post@n4.nabble.com>
 <32111747-1177-6735-ca32-b289378c3ec1@treenet.co.nz>
 <1472587980055-4679268.post@n4.nabble.com>
Message-ID: <defe52fd-6193-9fed-8a05-2bb76afaa744@treenet.co.nz>

On 31/08/2016 8:13 a.m., erdosain9 wrote:
> Thanks.
> But... 
> I'm misunderstanding ?
> Tx , is not the download?

TX is sent bytes. It depends on what your interfaces mean, but it looks
to me like it is uploads. There are known bugs in delay pools but they
cause very specific low number of multiples or fractions of the
configured pool size - not hundreds of KB faster rates.

> 
> I think it works this way in the mikrotik . That is, the transmission would
> be the " download "

So the report you are looking at is measuring the Squid<->client interface?

Squid delay pools are operating on the Squid<->Server interface traffic.
So they can rate limit your (probably costly) *upstream* bandwidth, not
your internal LAN bandwidth between Squid and clients.

Amos



From rousskov at measurement-factory.com  Wed Aug 31 15:24:29 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 31 Aug 2016 09:24:29 -0600
Subject: [squid-users] HTTPS chrome - SHA1 this page is insecure
In-Reply-To: <132fa841-bddd-630a-85c1-a0475e9480a8@treenet.co.nz>
References: <1472653571328-4679281.post@n4.nabble.com>
 <132fa841-bddd-630a-85c1-a0475e9480a8@treenet.co.nz>
Message-ID: <a8e64dad-e101-430f-5c90-b895c01e8714@measurement-factory.com>

On 08/31/2016 09:15 AM, Amos Jeffries wrote:
> On 1/09/2016 2:26 a.m., erdosain9 wrote:
>> Hi.
>> Im using ssl-bump.. all ir working fine, but i want to know if it is
>> possible that which is not seen crossed out and red "https".
>> This happen just in Chrome
>> This page is insecure (broken HTTPS)
>> SHA-1 Certificate
>> The certificate for this site expires in 2017 or later, and the certificate
>> chain contains a certificate signed using SHA-1.

Sounds like you are running an old Squid version.


> This requires changes to the certificate generator used by SSL-Bump.
> IIRC there were some patches, but I can't find them right now in the
> changesets. If the issue exists in current releases then please ask on
> squid-dev.

See http://www.squid-cache.org/Doc/config/sslproxy_cert_sign_hash/


> Of course, its possible the site realy does have a SHA1 certificate and
> Squid is just passing on the real details. The mimic feature is designed
> to ensure TLS is actually transparent as best we can manage.

I have not checked, but I doubt we mimic the signing algorithm (because
it would make client-Squid communication less secure?). If we do, we
should update the wiki page that lists what is being mimicked.


HTH,

Alex.



From rousskov at measurement-factory.com  Wed Aug 31 15:38:17 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 31 Aug 2016 09:38:17 -0600
Subject: [squid-users] TCP_TUNNEL_ABORTED/200?
In-Reply-To: <20160831082010.rcsl4fvw3b776e4u@charite.de>
References: <20160831082010.rcsl4fvw3b776e4u@charite.de>
Message-ID: <97014100-7662-3c4f-f479-3787a969fa8a@measurement-factory.com>

On 08/31/2016 02:20 AM, Ralf Hildebrandt wrote:
> One of our users is trying to connect to somw windows remoteapps via
> out squid proxy.
> 
> Logging in does seem to work, but somewhere along the line, the user
> is getting error messages. In our logs we're seeing the encrypted
> traffic (TCP_TUNNEL/200 CONNECT remoteapps.eortc.be:443), but then
> we're getting "TCP_TUNNEL_ABORTED/200" messages
> 
> I can't find anything on what exactly would cause a
> "TCP_TUNNEL_ABORTED/200"

In addition to what Amos has said, Squid bugs cause extra _ABORTED
suffixes in recent (but not recent enough) code. Two of such bugs were
fixed in trunk:

> revno: 14806
> branch nick: trunk
> timestamp: Wed 2016-08-17 17:11:56 -0600
> message:
>   Do not access-log chunked non-persistent responses with _ABORTED suffix.

> revno: 14805
> branch nick: trunk
> timestamp: Wed 2016-08-17 16:46:38 -0600
> message:
>   Do not access-log SslBump-faked CONNECTs with _ABORTED suffixes.


Our second fix might be related to your problems.

Alex.



From rousskov at measurement-factory.com  Wed Aug 31 15:53:22 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 31 Aug 2016 09:53:22 -0600
Subject: [squid-users] TCP_TUNNEL_ABORTED/200?
In-Reply-To: <165d94cb-6bf8-f749-0c17-32e03a9bb659@treenet.co.nz>
References: <20160831082010.rcsl4fvw3b776e4u@charite.de>
 <165d94cb-6bf8-f749-0c17-32e03a9bb659@treenet.co.nz>
Message-ID: <a2986a53-3256-0ae0-ca82-5963c43d4d43@measurement-factory.com>

On 08/31/2016 08:25 AM, Amos Jeffries wrote:
> On 31/08/2016 8:20 p.m., Ralf Hildebrandt wrote:
>> I can't find anything on what exactly would cause a
>> "TCP_TUNNEL_ABORTED/200"

> A client that disconnects before the server has finished sending data,

If "has finished sending" means "closed connection", then I do not think
that should trigger the _ABORTED suffix. If it does, it is a Squid bug
IMO. When tunneling, Squid should not assume that the server must close
the connection first.


> or before Squid has relayed the data it sent to the server.

That too should not trigger an _ABORTED suffix IMO, for similar reasons.
In general, nothing prevents Squid from relayed client data to the
server after the client has disconnected (or vice versa).


AFAICT, the tunnel code should add an _ABORTED suffix only if Squid has
data destined for an already closed connection. I did not check whether
the code actually obeys that, and the answer may be version-specific.

To make matters more complex, there are also so called half-closed TCP
connections. IIRC (and that is a big IF!), the tunneling code is one of
the areas where Squid does not handle them correctly. If my recollection
is correct, and the tunneled applications half-close, then Squid may
break those applications.


> The TUNNEL and 200 parts means Squid connected to the requested server.
> The ABORTED that the client disconnected while tunnel data was still in
> transit.

Agreed, provided "data in transit" means "Squid-buffered bytes not yet
sent to that already-disconnected client".


Cheers,

Alex.



From gregory_shively at fanniemae.com  Wed Aug 31 17:59:15 2016
From: gregory_shively at fanniemae.com (Shively, Gregory)
Date: Wed, 31 Aug 2016 13:59:15 -0400
Subject: [squid-users] Transparent Proxy on OSX Yosemite
Message-ID: <F25802A5228F1345B9BD8093E210C3B90257C35106@EXWCMS01.fanniemae.com>

> On 31/08/2016 11:19 a.m., Shively, Gregory wrote:

> > I'm attempting to get a squid working as a transparent proxy on OSX

> > Yosemite. Every attempt ended with a "Forward loop detected". I

> > initially started with the version from homebrew and moved to just

> > compiling myself to see if I could figure out what was going on.

> > Being new to both pf network and squid, it might be something that I

> > have configured wrong. I configured pf similar to:

> >

> >    nat on $ext_if proto {udp, tcp} from $int_if:network to any port domain -> ($ext_if)

> >    rdr pass on $int_if proto tcp from $int_if:network to any port

> > {http, https} -> 127.0.0.1 port 3129

> >

> > And my squid.conf for my testing is basically:

> >

> > http_port 3128

> > http_port 3129 intercept

> > http_access allow all

> >



> > I'm not sure if this is more appropriate on this mailing list or the

> > developer mailing list (hoping it is just something I'm doing wrong).

> > The squid that I'm using doesn't have -with-nat-devpf enabled; it

> > fails to compile with that option. I'm wondering if the getsockname()

> > as per comment for PFIntercept (of the !_USE_NAT_DEVPF) in

> > src/ip/Intercept.cc, on OSX is not returning the pre-rdr address and

> > causing the forward loop.



> Your access.log can show that. It shows up as the server the transaction is being sent to being port 3128/3129 on 127.0.0.1 or another IP assigned to the Squid machine.



It looks like I get 2 associated TCP_MISS entries in the access.log, followed by entries that looks like they are associated with the access denied error screen. All generate the forwarding loop warning when running squid in debug.  I also had the pf logging and see the rdr getting redirected, plus had started netcat listening on 3129 prior to starting squid and saw the HTTP request come in.



> >

> > As mentioned, the -with-nat-devpf fails to compile on OSX due to a

> > missing header file. And from looking it sounds like the header is for

> > the ioctl() on /dev/pf, which doesn't seem to be public API on OSX. So

> > I'm trying to determine if my issue is due to a misconfiguration - or

> > is this portion of the code not working with OSX.



> It has been a long time since anyone using MacOS has provided any particular feedback about Squid behaviour on MacOS. So it could be just bugs when running on MacOS.





> > I looked at the code for mitmproxy, and it seems like they require a

> > sudoers entry to run "pfctl -s state" and parse the state.

> > Would something like that need to be added to squid to support

> > transparent proxy on OSX. I had started to put some code together like

> > mitmproxy, but thought better check if I didn't get something

> > configured correctly.



> Squid (when built with the /dev/pf support) master process which is run as root [you are running Squid from the root account right?] should be preserving its permission to access the device before it drops down to low privilege levels for handling the network traffic.



Yeah - I'm running the squid process as root; that is partially what headed me down the road with the /dev/pf - the permissions had changed after a reboot of the Mac and I started getting curious on why squid didn't give me a permission warning in the same way that mitmproxy was. And from the code, at least in the portion of the code I was looking, since I didn't have the -use-devpf it doesn't seem to open the dev file.



> Some other troubleshooting things to try:



> * using the machines public IP addres instead of 127.0.0.1. There are hardware or driver level restrictions on locahost addresses that often prohibit that type of NAT.



> * using a divert-to rule instead of rdr. If your PF firewall accepts that and the 'tproxy' option in squid.conf works then the /dev/pf is not relevant. rdr sometimes does not work when divert-to is fine.



> * check the PF version in your MacOS. If it derives from OpenBSD 4.8 or later then the .dev.pf is not relevant - rdr/divert-to failure is then a bug somewhere AFAIK.



I tried using both the internal and external interface IP addresses on the rdr rule. Both ended in the same forward loop. And it doesn't look like, at least Yosemite, has the option to use the divert-to in the firewall rules. I can't seem to find the reference, but I think that the pf in OSX is based around OpenBSD 4.4 or 4.5, but don't hold me to it. I'm guessing that is the reason that the divert-to is not available. I can look at an El Capt machine, but don't currently have access.



Thanks for the help on getting this setup. I had put some code in the PfInterception method to replace the "local" address that I pulled from running the pfctl -s state command and it did change the results. But I'm thinking that I might have gotten the host or port in the "address" object incorrectly - it didn't seem to work and further connections just errored out. When I get a change will take a more detailed look and verify I'm getting the addresses in the correct form.



> Amos

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160831/e8a6c07a/attachment.htm>

From rejaine at bhz.jamef.com.br  Wed Aug 31 20:44:18 2016
From: rejaine at bhz.jamef.com.br (Rejaine Monteiro)
Date: Wed, 31 Aug 2016 17:44:18 -0300
Subject: [squid-users] TCP_MISS_ABORTED only for one site
Message-ID: <57C741A2.9030106@bhz.jamef.com.br>


hi,

we are having trouble accessing (only) that site below.  all other sites 
are accessing normally.

TCP_MISS_ABORTED/000 0 GET http://www.ipiranga.com.br/ - H
(the site in question works with direct access to internet - without proxy)

  discarded problems with cpu, firewall rules, memory, acls, link, etc.

I set up another squid (in another machine and direct internet access) 
with basic settings and the same problem. Any idea?

squid version 3.3.13. my basic squid.conf bellow:

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
dns_v4_first on
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128
coredump_dir /var/cache/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
http_access allow localnet
http_access deny all



From yvoinov at gmail.com  Wed Aug 31 20:48:37 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 1 Sep 2016 02:48:37 +0600
Subject: [squid-users] TCP_MISS_ABORTED only for one site
In-Reply-To: <57C741A2.9030106@bhz.jamef.com.br>
References: <57C741A2.9030106@bhz.jamef.com.br>
Message-ID: <c9df86d8-fed5-483b-287f-5be55f7826b0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
1472676457.210   5829 127.0.0.1 TCP_MISS/302 512 GET
http://www.ipiranga.com.br/ - HIER_DIRECT/177.67.60.32 text/html
1472676457.633    366 127.0.0.1 TCP_MISS/302 739 GET
http://www.ipiranga.com.br/wps/portal/ipiranga - HIER_DIRECT/177.67.60.32 -
1472676458.600    934 127.0.0.1 TCP_MISS/200 16145 GET
http://www.ipiranga.com.br/wps/portal/ipiranga/inicio/!ut/p/a1/04_Sj9CPykssy0xPLMnMz0vMAfGjzOK9PUxMPJxMDLz8ncKMDByN_I2N3YJDnMzMzYAKIoEKDHAARwNC-sP1o_AqCTKHKsBjRUFuhEGmo6IiAIN0ChE!/dl5/d5/L2dBISEvZ0FBIS9nQSEh/
- HIER_DIRECT/177.67.60.32 text/html
1472676458.935    697 127.0.0.1 TCP_MISS/302 686 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/css/apps-style-responsive.css
- HIER_DIRECT/177.67.60.32 -
1472676458.980    384 127.0.0.1 TCP_MISS/200 11929 GET
http://www.ipiranga.com.br/wps/wcm/connect/67615a58-86cf-413e-b8db-9447641ebefe/inicio.css?MOD=AJPERES&CACHEID=67615a58-86cf-413e-b8db-9447641ebefe
- HIER_DIRECT/177.67.60.32 text/css
1472676459.043    769 127.0.0.1 TCP_MISS/302 696 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/jquery.fancybox.css?v=2.1.4
- HIER_DIRECT/177.67.60.32 -
1472676459.043    767 127.0.0.1 TCP_MISS/302 711 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7
- HIER_DIRECT/177.67.60.32 -
1472676459.043    771 127.0.0.1 TCP_MISS/302 680 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/css/ipiranga-portal.css
- HIER_DIRECT/177.67.60.32 -
1472676459.065    748 127.0.0.1 TCP_MISS/302 676 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery-ui.min.js
- HIER_DIRECT/177.67.60.32 -
1472676459.065    746 127.0.0.1 TCP_MISS/302 667 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/load.js
- HIER_DIRECT/177.67.60.32 -
1472676459.075    760 127.0.0.1 TCP_MISS/302 673 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery.min.js
- HIER_DIRECT/177.67.60.32 -
1472676459.075    753 127.0.0.1 TCP_MISS/302 700 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/jquery.fancybox.pack.js?v=2.1.4
- HIER_DIRECT/177.67.60.32 -
1472676459.075    751 127.0.0.1 TCP_MISS/302 677 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery.blockUI.js
- HIER_DIRECT/177.67.60.32 -
1472676459.292    795 127.0.0.1 TCP_MISS/302 674 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/icons/favicon.ico
- HIER_DIRECT/177.67.60.32 -
1472676459.372   1060 127.0.0.1 TCP_MISS/302 1780 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!chKmIlFLdAjIrqV18BJUlQ/mashup/ra:collection?themeID=ZJ_KH44HB40J8I540AS3JCRS43811&locale=pt-BR&locale=pt&locale=en&mime-type=text%2Fplain&entry=dojo_17__0.0%3Ahead_js&entry=dojo_fx_17__0.0%3Ahead_js&entry=dojo_fmt_17__0.0%3Ahead_js&entry=dojo_dom_17__0.0%3Ahead_js&entry=dojo_app_17__0.0%3Ahead_js&entry=dijit_17__0.0%3Ahead_js&entry=dojo_dnd_basic_17__0.0%3Ahead_js&entry=dojo_dnd_ext_17__0.0%3Ahead_js&entry=dijit_layout_basic_17__0.0%3Ahead_js&entry=dijit_menu_17__0.0%3Ahead_js&entry=dojo_data_17__0.0%3Ahead_js&entry=dijit_form_17__0.0%3Ahead_js&entry=dijit_layout_ext_17__0.0%3Ahead_js&entry=dojox_xml_17__0.0%3Ahead_js&entry=dojox_io_17__0.0%3Ahead_js&entry=wp_client_main__0.0%3Ahead_js&entry=wp_client_ext__0.0%3Ahead_js&entry=dojox_fx_17__0.0%3Ahead_js&entry=dojox_gfx_17__0.0%3Ahead_js&entry=dojox_charting_17__0.0%3Ahead_js&entry=dojox_layout_basic_17__0.0%3Ahead_js&entry=dojox_collections_17__0.0%3Ahead_js&entry=dojox_uuid_17__0.0%3Ahead_js&entry=dojox_data_basic_17__0.0%3Ahead_js&entry=dojox_aspect_17__0.0%3Ahead_js&entry=wp_analytics_aggregator__0.0%3Ahead_js&entry=wp_portal_client_utils__0.0%3Ahead_js&entry=dijit_tree_17__0.0%3Ahead_js&entry=wp_theme_portal_80__0.0%3Ahead_js&entry=wp_portlet_client_model__0.0%3Ahead_js&entry=mm_open_ajax_hub__0.0%3Ahead_js
- HIER_DIRECT/177.67.60.32 -
1472676459.446    726 127.0.0.1 TCP_MISS/302 667 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/lang/pt.js
- HIER_DIRECT/177.67.60.32 -
1472676459.446    723 127.0.0.1 TCP_MISS/302 667 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/lang/en.js
- HIER_DIRECT/177.67.60.32 -
1472676459.520    794 127.0.0.1 TCP_MISS/302 678 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/ipiranga-portal.js
- HIER_DIRECT/177.67.60.32 -
1472676459.730    405 127.0.0.1 TCP_MISS/200 1213 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/icons/favicon.ico
- HIER_DIRECT/177.67.60.32 image/x-icon
1472676459.781    387 127.0.0.1 TCP_MISS/302 605 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/logo_ipiranga.png
- HIER_DIRECT/177.67.60.32 -
1472676459.831    453 127.0.0.1 TCP_MISS/200 3566 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/css/apps-style-responsive.css
- HIER_DIRECT/177.67.60.32 text/css
1472676459.831    453 127.0.0.1 TCP_MISS/200 2269 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/jquery.fancybox.css?v=2.1.4
- HIER_DIRECT/177.67.60.32 text/css
1472676459.831    453 127.0.0.1 TCP_MISS/200 1180 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7
- HIER_DIRECT/177.67.60.32 text/css
1472676459.831    436 127.0.0.1 TCP_MISS/302 596 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-km.jpg
- HIER_DIRECT/177.67.60.32 -
1472676459.831    388 127.0.0.1 TCP_MISS/302 602 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-produtos.jpg
- HIER_DIRECT/177.67.60.32 -
1472676459.862    485 127.0.0.1 TCP_MISS/200 976 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/load.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
1472676459.862    415 127.0.0.1 TCP_MISS/302 602 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-servicos.jpg
- HIER_DIRECT/177.67.60.32 -
1472676460.120    744 127.0.0.1 TCP_MISS/200 7479 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery.blockUI.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
1472676460.132    734 127.0.0.1 TCP_MISS/302 601 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-comprar.jpg
- HIER_DIRECT/177.67.60.32 -
1472676460.218    765 127.0.0.1 TCP_MISS/302 601 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-cartoes.jpg
- HIER_DIRECT/177.67.60.32 -
1472676460.218    765 127.0.0.1 TCP_MISS/302 599 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destque-postos.jpg
- HIER_DIRECT/177.67.60.32 -
1472676460.351    728 127.0.0.1 TCP_MISS/302 514 GET
http://www.ipiranga.com.br/wps/portal/ipiranga/inicio/!ut/p/a1/04_Sj9CPykssy0xPLMnMz0vMAfGjzOK9PUxMPJxMDLz8ncKMDByN_I2N3YJDnMzMzYAKIoEKDHAARwNC-sP1o_AqCTKHKsBjRUFuhEGmo6IiAIN0ChE!/dl5/d5/L2dBISEvZ0FBIS9nQSEh/img/bg_postoipiranganaweb.jpg
- HIER_DIRECT/177.67.60.32 -
1472676460.422   1044 127.0.0.1 TCP_MISS/200 17782 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery-ui.min.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
1472676460.464   1086 127.0.0.1 TCP_MISS/200 26743 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/css/ipiranga-portal.css
- HIER_DIRECT/177.67.60.32 text/css
1472676460.635    751 127.0.0.1 TCP_MISS/200 3670 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/lang/pt.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
1472676460.720    829 127.0.0.1 TCP_MISS/200 3349 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/lang/en.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
1472676460.720   1041 127.0.0.1 TCP_MISS/200 8068 GET
http://www.ipiranga.com.br/wps/wcm/connect/2af8cefd-d885-4f66-b447-51e2fae1bf66/bomba3_laranjaescuro.png?MOD=AJPERES&CACHEID=2af8cefd-d885-4f66-b447-51e2fae1bf66
- HIER_DIRECT/177.67.60.32 image/png
1472676460.737   1106 127.0.0.1 TCP_MISS/200 8061 GET
http://www.ipiranga.com.br/wps/wcm/connect/0fad93be-b726-4cdd-b68f-29111b51386f/bomba2_laranjaclaro.png?MOD=AJPERES&CACHEID=0fad93be-b726-4cdd-b68f-29111b51386f
- HIER_DIRECT/177.67.60.32 image/png
1472676460.746   1117 127.0.0.1 TCP_MISS/200 12462 GET
http://www.ipiranga.com.br/wps/wcm/connect/e26ea9fb-7698-4198-ab67-1fbb2914637a/bomba1_amarelo.png?MOD=AJPERES&CACHEID=e26ea9fb-7698-4198-ab67-1fbb2914637a
- HIER_DIRECT/177.67.60.32 image/png
1472676460.769   1391 127.0.0.1 TCP_MISS/200 33607 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery.min.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
1472676460.803   1022 127.0.0.1 TCP_MISS/200 8052 GET
http://www.ipiranga.com.br/wps/wcm/connect/0673995b-ac7e-4d54-b388-0c45a248dd7e/bomba4_vermelho.png?MOD=AJPERES&CACHEID=0673995b-ac7e-4d54-b388-0c45a248dd7e
- HIER_DIRECT/177.67.60.32 image/png
1472676460.994   1466 127.0.0.1 TCP_MISS/200 23383 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/ipiranga-portal.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
1472676461.015    763 127.0.0.1 TCP_MISS/302 612 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/logo_ipiranga_rodape.png
- HIER_DIRECT/177.67.60.32 -
1472676461.071    803 127.0.0.1 TCP_MISS/302 605 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!52aFj7K51d0egnrpwPUtYQ/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/icon_spanchat.jpg
- HIER_DIRECT/177.67.60.32 -
1472676461.093   1717 127.0.0.1 TCP_MISS/200 9350 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/jquery.fancybox.pack.js?v=2.1.4
- HIER_DIRECT/177.67.60.32 application/x-javascript
1472676461.100   1475 127.0.0.1 TCP_MISS/200 25088 GET
http://www.ipiranga.com.br/wps/wcm/connect/35a5a339-18e6-44bc-8dcd-6bf9b60bfe37/logo_postoipiranganaweb.png?MOD=AJPERES&CACHEID=35a5a339-18e6-44bc-8dcd-6bf9b60bfe37
- HIER_DIRECT/177.67.60.32 image/png
1472676461.219   1086 127.0.0.1 TCP_MISS/200 23334 GET
http://www.ipiranga.com.br/wps/wcm/connect/289ef530-558d-4a26-9351-798d16ce74cb/Frotas.PNG?MOD=AJPERES&CACHEID=289ef530-558d-4a26-9351-798d16ce74cb
- HIER_DIRECT/177.67.60.32 image/png
1472676461.219    864 127.0.0.1 TCP_MISS/200 2497 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/logo_ipiranga.png
- HIER_DIRECT/177.67.60.32 image/png
1472676461.252   1391 127.0.0.1 TAG_NONE/200 0 CONNECT
security.trustsign.com.br:443 - HIER_NONE/- -
1472676461.341   1778 127.0.0.1 TCP_MISS/200 45232 GET
http://www.ipiranga.com.br/wps/wcm/connect/32260164-5ca9-456f-91ca-2f51fd73d520/circle-dt-clean.png?MOD=AJPERES&CACHEID=32260164-5ca9-456f-91ca-2f51fd73d520
- HIER_DIRECT/177.67.60.32 image/png
1472676461.345   1818 127.0.0.1 TCP_MISS/200 50629 GET
http://www.ipiranga.com.br/wps/wcm/connect/921d21b0-a6ab-498a-9ad2-716f613865aa/03_ampm.png?MOD=AJPERES&CACHEID=921d21b0-a6ab-498a-9ad2-716f613865aa
- HIER_DIRECT/177.67.60.32 image/png
1472676461.380   1812 127.0.0.1 TCP_MISS/200 46261 GET
http://www.ipiranga.com.br/wps/wcm/connect/ef686a97-527e-4b2c-b7e0-baa31a8db8c9/01_conectcar.png?MOD=AJPERES&CACHEID=ef686a97-527e-4b2c-b7e0-baa31a8db8c9
- HIER_DIRECT/177.67.60.32 image/png
1472676461.382   1807 127.0.0.1 TCP_MISS/200 43985 GET
http://www.ipiranga.com.br/wps/wcm/connect/36c0aa7f-632a-4961-a4b3-7e500f8d84b0/circle-jetoil.png?MOD=AJPERES&CACHEID=36c0aa7f-632a-4961-a4b3-7e500f8d84b0
- HIER_DIRECT/177.67.60.32 image/png
1472676461.423   1529 127.0.0.1 TCP_MISS/200 15410 GET
http://www.ipiranga.com.br/wps/wcm/connect/b941561d-e114-4d2d-a5ff-e67988f33dda/servicos_conectcar.png?MOD=AJPERES&CACHEID=b941561d-e114-4d2d-a5ff-e67988f33dda
- HIER_DIRECT/177.67.60.32 image/png
1472676461.427   1519 127.0.0.1 TCP_MISS/200 19505 GET
http://www.ipiranga.com.br/wps/wcm/connect/0da3e60f-1623-4b8e-ac2c-28012d0779b8/servicos_recargacelular.png?MOD=AJPERES&CACHEID=0da3e60f-1623-4b8e-ac2c-28012d0779b8
- HIER_DIRECT/177.67.60.32 image/png
1472676461.472      2 127.0.0.1 TAG_NONE/503 4082 GET
https://security.trustsign.com.br/static/seals/selo-pro-57984cf8c13fa073dbb14cbe21e9368c-pt.png
- HIER_NONE/- text/html
1472676461.503   1931 127.0.0.1 TCP_MISS/200 30931 GET
http://www.ipiranga.com.br/wps/wcm/connect/d0b422c1-2b90-4698-bc5a-93de2b8f55f2/02_kmdevantagens.png?MOD=AJPERES&CACHEID=d0b422c1-2b90-4698-bc5a-93de2b8f55f2
- HIER_DIRECT/177.67.60.32 image/png
1472676461.602   1166 127.0.0.1 TCP_MISS/200 48024 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-km.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676461.607    846 127.0.0.1 TCP_MISS/301 623 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!FOjivSMSGOmrYOwhPEyrNw/spa/Z6_KH44HB40JOBV20A2O33FSTB676/html/img/bg_postoipiranganaweb.jpg
- HIER_DIRECT/177.67.60.32 -
1472676461.789   1917 127.0.0.1 TCP_MISS/200 56642 GET
http://www.ipiranga.com.br/wps/wcm/connect/c5fdf79b-6da3-42c3-b787-1c36c2afd1ec/08-revista-km-ago.jpg?MOD=AJPERES&CACHEID=c5fdf79b-6da3-42c3-b787-1c36c2afd1ec
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676461.841   1938 127.0.0.1 TCP_MISS/200 44908 GET
http://www.ipiranga.com.br/wps/wcm/connect/94782b7e-ffd3-484f-9572-bac60810ec3c/thumb_hotelurb.png?MOD=AJPERES&CACHEID=94782b7e-ffd3-484f-9572-bac60810ec3c
- HIER_DIRECT/177.67.60.32 image/png
1472676461.932    909 127.0.0.1 TCP_MISS/200 6015 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/logo_ipiranga_rodape.png
- HIER_DIRECT/177.67.60.32 image/png
1472676461.960    879 127.0.0.1 TCP_MISS/200 2899 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/icon_spanchat.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.029   1543 127.0.0.1 TCP_MISS/200 40138 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-produtos.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.090   2617 127.0.0.1 TCP_MISS/200 139799 GET
http://www.ipiranga.com.br/wps/wcm/connect/994d21ed-9dab-40f6-8ce4-afbd97c1b52a/SAMSUNG_WEBBANNER.JPG?MOD=AJPERES&CACHEID=994d21ed-9dab-40f6-8ce4-afbd97c1b52a
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.238   1597 127.0.0.1 TCP_MISS/200 36145 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-servicos.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.346   1592 127.0.0.1 TCP_MISS/200 49965 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destque-postos.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.389   1653 127.0.0.1 TCP_MISS/200 41858 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-comprar.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.422   1676 127.0.0.1 TCP_MISS/200 46619 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-cartoes.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.440   2921 127.0.0.1 TCP_MISS/200 225780 GET
http://www.ipiranga.com.br/wps/wcm/connect/586f2192-e220-4e95-bc55-665347e1e573/Abastece%2BAi.jpg?MOD=AJPERES&CACHEID=586f2192-e220-4e95-bc55-665347e1e573
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.633   2489 127.0.0.1 TCP_MISS/200 53637 GET
http://www.ipiranga.com.br/wps/wcm/connect/f1500e66-546e-426f-ae64-cca3bf417f30/movida_thumb.png?MOD=AJPERES&CACHEID=f1500e66-546e-426f-ae64-cca3bf417f30
- HIER_DIRECT/177.67.60.32 image/png
1472676462.856   1241 127.0.0.1 TCP_MISS/200 82356 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/bg_postoipiranganaweb.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676462.907   3007 127.0.0.1 TCP_MISS/200 242344 GET
http://www.ipiranga.com.br/wps/wcm/connect/420fffd8-f8b1-430d-b147-d595d8272483/Cartoes.png?MOD=AJPERES&CACHEID=420fffd8-f8b1-430d-b147-d595d8272483
- HIER_DIRECT/177.67.60.32 image/png
1472676463.442   3926 127.0.0.1 TCP_MISS/200 439204 GET
http://www.ipiranga.com.br/wps/wcm/connect/b8a8c8b0-7af2-40cb-9309-62a57bde67f5/banner_dtclean-v5-laranja.jpg?MOD=AJPERES&CACHEID=b8a8c8b0-7af2-40cb-9309-62a57bde67f5
- HIER_DIRECT/177.67.60.32 image/jpeg
1472676464.201   4322 127.0.0.1 TCP_MISS/200 363207 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/mashup/ra:collection?themeID=ZJ_KH44HB40J8I540AS3JCRS43811&locale=pt-BR&locale=pt&locale=en&mime-type=text/plain&entry=dojo_17__0.0%3ahead_js&entry=dojo_fx_17__0.0%3ahead_js&entry=dojo_fmt_17__0.0%3ahead_js&entry=dojo_dom_17__0.0%3ahead_js&entry=dojo_app_17__0.0%3ahead_js&entry=dijit_17__0.0%3ahead_js&entry=dojo_dnd_basic_17__0.0%3ahead_js&entry=dojo_dnd_ext_17__0.0%3ahead_js&entry=dijit_layout_basic_17__0.0%3ahead_js&entry=dijit_menu_17__0.0%3ahead_js&entry=dojo_data_17__0.0%3ahead_js&entry=dijit_form_17__0.0%3ahead_js&entry=dijit_layout_ext_17__0.0%3ahead_js&entry=dojox_xml_17__0.0%3ahead_js&entry=dojox_io_17__0.0%3ahead_js&entry=wp_client_main__0.0%3ahead_js&entry=wp_client_ext__0.0%3ahead_js&entry=dojox_fx_17__0.0%3ahead_js&entry=dojox_gfx_17__0.0%3ahead_js&entry=dojox_charting_17__0.0%3ahead_js&entry=dojox_layout_basic_17__0.0%3ahead_js&entry=dojox_collections_17__0.0%3ahead_js&entry=dojox_uuid_17__0.0%3ahead_js&entry=dojox_data_basic_17__0.0%3ahead_js&entry=dojox_aspect_17__0.0%3ahead_js&entry=wp_analytics_aggregator__0.0%3ahead_js&entry=wp_portal_client_utils__0.0%3ahead_js&entry=dijit_tree_17__0.0%3ahead_js&entry=wp_theme_portal_80__0.0%3ahead_js&entry=wp_portlet_client_model__0.0%3ahead_js&entry=mm_open_ajax_hub__0.0%3ahead_js
- HIER_DIRECT/177.67.60.32 text/plain

Squid 3.5.20.

01.09.2016 2:44, Rejaine Monteiro ?????:
>
> hi,
>
> we are having trouble accessing (only) that site below.  all other
sites are accessing normally.
>
> TCP_MISS_ABORTED/000 0 GET http://www.ipiranga.com.br/ - H
> (the site in question works with direct access to internet - without
proxy)
>
>  discarded problems with cpu, firewall rules, memory, acls, link, etc.
>
> I set up another squid (in another machine and direct internet access)
with basic settings and the same problem. Any idea?
>
> squid version 3.3.13. my basic squid.conf bellow:
>
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly
plugged) machines
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> dns_v4_first on
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localnet
> http_access allow localhost
> http_access deny all
> http_port 3128
> coredump_dir /var/cache/squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> http_access allow localnet
> http_access deny all
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXx0KlAAoJENNXIZxhPexGRi0H/2oDn1o7fz3KYXedCujuN39+
kYqc4JBPUr1ZZLMTjtb3O00kcHdiH757oG/JceIn4Re/2OBy3sy8VsAMJF4gr9Zc
ZD5dmysajH8N7Yf4NP5rW2YY/U4E05f0vcG7SPYjbbwu+c3azL12RAqf2NfHbnsc
gsw1ktnAAAt4mIRGn28AFwwj3YMVjsQfVZgCxXCMezUoJ5cDKSKSMnMFeWqOnW/8
Uw31o9ZFqEIrIoEctp6uGWzfG23RWboJgJwLCe927BwhICIr+15daS2aWMe/gDFa
ObogWEhkJK6eeE62nf/vfF/8StE7hf2Kk4DUZJN9Q24RUBfZRi2NwJt1R+ypKp0=
=QtvP
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/820f1e7a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/820f1e7a/attachment.key>

From yvoinov at gmail.com  Wed Aug 31 20:49:44 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 1 Sep 2016 02:49:44 +0600
Subject: [squid-users] TCP_MISS_ABORTED only for one site
In-Reply-To: <c9df86d8-fed5-483b-287f-5be55f7826b0@gmail.com>
References: <57C741A2.9030106@bhz.jamef.com.br>
 <c9df86d8-fed5-483b-287f-5be55f7826b0@gmail.com>
Message-ID: <eb0a36c0-1ee7-c595-6d1c-ec8ba693238b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
May be upgrade? 3.3.x is antique.

01.09.2016 2:48, Yuri Voinov ?????:
>
> 1472676457.210   5829 127.0.0.1 TCP_MISS/302 512 GET
http://www.ipiranga.com.br/ - HIER_DIRECT/177.67.60.32 text/html
> 1472676457.633    366 127.0.0.1 TCP_MISS/302 739 GET
http://www.ipiranga.com.br/wps/portal/ipiranga - HIER_DIRECT/177.67.60.32 -
> 1472676458.600    934 127.0.0.1 TCP_MISS/200 16145 GET
http://www.ipiranga.com.br/wps/portal/ipiranga/inicio/!ut/p/a1/04_Sj9CPykssy0xPLMnMz0vMAfGjzOK9PUxMPJxMDLz8ncKMDByN_I2N3YJDnMzMzYAKIoEKDHAARwNC-sP1o_AqCTKHKsBjRUFuhEGmo6IiAIN0ChE!/dl5/d5/L2dBISEvZ0FBIS9nQSEh/
- HIER_DIRECT/177.67.60.32 text/html
> 1472676458.935    697 127.0.0.1 TCP_MISS/302 686 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/css/apps-style-responsive.css
- HIER_DIRECT/177.67.60.32 -
> 1472676458.980    384 127.0.0.1 TCP_MISS/200 11929 GET
http://www.ipiranga.com.br/wps/wcm/connect/67615a58-86cf-413e-b8db-9447641ebefe/inicio.css?MOD=AJPERES&CACHEID=67615a58-86cf-413e-b8db-9447641ebefe
- HIER_DIRECT/177.67.60.32 text/css
> 1472676459.043    769 127.0.0.1 TCP_MISS/302 696 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/jquery.fancybox.css?v=2.1.4
- HIER_DIRECT/177.67.60.32 -
> 1472676459.043    767 127.0.0.1 TCP_MISS/302 711 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7
- HIER_DIRECT/177.67.60.32 -
> 1472676459.043    771 127.0.0.1 TCP_MISS/302 680 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/css/ipiranga-portal.css
- HIER_DIRECT/177.67.60.32 -
> 1472676459.065    748 127.0.0.1 TCP_MISS/302 676 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery-ui.min.js
- HIER_DIRECT/177.67.60.32 -
> 1472676459.065    746 127.0.0.1 TCP_MISS/302 667 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/load.js
- HIER_DIRECT/177.67.60.32 -
> 1472676459.075    760 127.0.0.1 TCP_MISS/302 673 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery.min.js
- HIER_DIRECT/177.67.60.32 -
> 1472676459.075    753 127.0.0.1 TCP_MISS/302 700 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/jquery.fancybox.pack.js?v=2.1.4
- HIER_DIRECT/177.67.60.32 -
> 1472676459.075    751 127.0.0.1 TCP_MISS/302 677 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery.blockUI.js
- HIER_DIRECT/177.67.60.32 -
> 1472676459.292    795 127.0.0.1 TCP_MISS/302 674 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/icons/favicon.ico
- HIER_DIRECT/177.67.60.32 -
> 1472676459.372   1060 127.0.0.1 TCP_MISS/302 1780 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!chKmIlFLdAjIrqV18BJUlQ/mashup/ra:collection?themeID=ZJ_KH44HB40J8I540AS3JCRS43811&locale=pt-BR&locale=pt&locale=en&mime-type=text%2Fplain&entry=dojo_17__0.0%3Ahead_js&entry=dojo_fx_17__0.0%3Ahead_js&entry=dojo_fmt_17__0.0%3Ahead_js&entry=dojo_dom_17__0.0%3Ahead_js&entry=dojo_app_17__0.0%3Ahead_js&entry=dijit_17__0.0%3Ahead_js&entry=dojo_dnd_basic_17__0.0%3Ahead_js&entry=dojo_dnd_ext_17__0.0%3Ahead_js&entry=dijit_layout_basic_17__0.0%3Ahead_js&entry=dijit_menu_17__0.0%3Ahead_js&entry=dojo_data_17__0.0%3Ahead_js&entry=dijit_form_17__0.0%3Ahead_js&entry=dijit_layout_ext_17__0.0%3Ahead_js&entry=dojox_xml_17__0.0%3Ahead_js&entry=dojox_io_17__0.0%3Ahead_js&entry=wp_client_main__0.0%3Ahead_js&entry=wp_client_ext__0.0%3Ahead_js&entry=dojox_fx_17__0.0%3Ahead_js&entry=dojox_gfx_17__0.0%3Ahead_js&entry=dojox_charting_17__0.0%3Ahead_js&entry=dojox_layout_basic_17__0.0%3Ahead_js&entry=dojox_collections_17__0.0%3Ahead_js&entry=dojox_uuid_17__0.0%3Ahead_js&entry=dojox_data_basic_17__0.0%3Ahead_js&entry=dojox_aspect_17__0.0%3Ahead_js&entry=wp_analytics_aggregator__0.0%3Ahead_js&entry=wp_portal_client_utils__0.0%3Ahead_js&entry=dijit_tree_17__0.0%3Ahead_js&entry=wp_theme_portal_80__0.0%3Ahead_js&entry=wp_portlet_client_model__0.0%3Ahead_js&entry=mm_open_ajax_hub__0.0%3Ahead_js
- HIER_DIRECT/177.67.60.32 -
> 1472676459.446    726 127.0.0.1 TCP_MISS/302 667 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/lang/pt.js
- HIER_DIRECT/177.67.60.32 -
> 1472676459.446    723 127.0.0.1 TCP_MISS/302 667 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/lang/en.js
- HIER_DIRECT/177.67.60.32 -
> 1472676459.520    794 127.0.0.1 TCP_MISS/302 678 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/ipiranga-portal.js
- HIER_DIRECT/177.67.60.32 -
> 1472676459.730    405 127.0.0.1 TCP_MISS/200 1213 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/icons/favicon.ico
- HIER_DIRECT/177.67.60.32 image/x-icon
> 1472676459.781    387 127.0.0.1 TCP_MISS/302 605 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/logo_ipiranga.png
- HIER_DIRECT/177.67.60.32 -
> 1472676459.831    453 127.0.0.1 TCP_MISS/200 3566 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/css/apps-style-responsive.css
- HIER_DIRECT/177.67.60.32 text/css
> 1472676459.831    453 127.0.0.1 TCP_MISS/200 2269 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/jquery.fancybox.css?v=2.1.4
- HIER_DIRECT/177.67.60.32 text/css
> 1472676459.831    453 127.0.0.1 TCP_MISS/200 1180 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7
- HIER_DIRECT/177.67.60.32 text/css
> 1472676459.831    436 127.0.0.1 TCP_MISS/302 596 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-km.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676459.831    388 127.0.0.1 TCP_MISS/302 602 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-produtos.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676459.862    485 127.0.0.1 TCP_MISS/200 976 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/load.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
> 1472676459.862    415 127.0.0.1 TCP_MISS/302 602 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-servicos.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676460.120    744 127.0.0.1 TCP_MISS/200 7479 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery.blockUI.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
> 1472676460.132    734 127.0.0.1 TCP_MISS/302 601 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-comprar.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676460.218    765 127.0.0.1 TCP_MISS/302 601 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-cartoes.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676460.218    765 127.0.0.1 TCP_MISS/302 599 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destque-postos.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676460.351    728 127.0.0.1 TCP_MISS/302 514 GET
http://www.ipiranga.com.br/wps/portal/ipiranga/inicio/!ut/p/a1/04_Sj9CPykssy0xPLMnMz0vMAfGjzOK9PUxMPJxMDLz8ncKMDByN_I2N3YJDnMzMzYAKIoEKDHAARwNC-sP1o_AqCTKHKsBjRUFuhEGmo6IiAIN0ChE!/dl5/d5/L2dBISEvZ0FBIS9nQSEh/img/bg_postoipiranganaweb.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676460.422   1044 127.0.0.1 TCP_MISS/200 17782 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery-ui.min.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
> 1472676460.464   1086 127.0.0.1 TCP_MISS/200 26743 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/css/ipiranga-portal.css
- HIER_DIRECT/177.67.60.32 text/css
> 1472676460.635    751 127.0.0.1 TCP_MISS/200 3670 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/lang/pt.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
> 1472676460.720    829 127.0.0.1 TCP_MISS/200 3349 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/lang/en.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
> 1472676460.720   1041 127.0.0.1 TCP_MISS/200 8068 GET
http://www.ipiranga.com.br/wps/wcm/connect/2af8cefd-d885-4f66-b447-51e2fae1bf66/bomba3_laranjaescuro.png?MOD=AJPERES&CACHEID=2af8cefd-d885-4f66-b447-51e2fae1bf66
- HIER_DIRECT/177.67.60.32 image/png
> 1472676460.737   1106 127.0.0.1 TCP_MISS/200 8061 GET
http://www.ipiranga.com.br/wps/wcm/connect/0fad93be-b726-4cdd-b68f-29111b51386f/bomba2_laranjaclaro.png?MOD=AJPERES&CACHEID=0fad93be-b726-4cdd-b68f-29111b51386f
- HIER_DIRECT/177.67.60.32 image/png
> 1472676460.746   1117 127.0.0.1 TCP_MISS/200 12462 GET
http://www.ipiranga.com.br/wps/wcm/connect/e26ea9fb-7698-4198-ab67-1fbb2914637a/bomba1_amarelo.png?MOD=AJPERES&CACHEID=e26ea9fb-7698-4198-ab67-1fbb2914637a
- HIER_DIRECT/177.67.60.32 image/png
> 1472676460.769   1391 127.0.0.1 TCP_MISS/200 33607 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/jquery.min.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
> 1472676460.803   1022 127.0.0.1 TCP_MISS/200 8052 GET
http://www.ipiranga.com.br/wps/wcm/connect/0673995b-ac7e-4d54-b388-0c45a248dd7e/bomba4_vermelho.png?MOD=AJPERES&CACHEID=0673995b-ac7e-4d54-b388-0c45a248dd7e
- HIER_DIRECT/177.67.60.32 image/png
> 1472676460.994   1466 127.0.0.1 TCP_MISS/200 23383 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/ipiranga-portal.js
- HIER_DIRECT/177.67.60.32 application/x-javascript
> 1472676461.015    763 127.0.0.1 TCP_MISS/302 612 GET
http://www.ipiranga.com.br/wps/contenthandler/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/logo_ipiranga_rodape.png
- HIER_DIRECT/177.67.60.32 -
> 1472676461.071    803 127.0.0.1 TCP_MISS/302 605 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!52aFj7K51d0egnrpwPUtYQ/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/icon_spanchat.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676461.093   1717 127.0.0.1 TCP_MISS/200 9350 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/js/fancybox/jquery.fancybox.pack.js?v=2.1.4
- HIER_DIRECT/177.67.60.32 application/x-javascript
> 1472676461.100   1475 127.0.0.1 TCP_MISS/200 25088 GET
http://www.ipiranga.com.br/wps/wcm/connect/35a5a339-18e6-44bc-8dcd-6bf9b60bfe37/logo_postoipiranganaweb.png?MOD=AJPERES&CACHEID=35a5a339-18e6-44bc-8dcd-6bf9b60bfe37
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.219   1086 127.0.0.1 TCP_MISS/200 23334 GET
http://www.ipiranga.com.br/wps/wcm/connect/289ef530-558d-4a26-9351-798d16ce74cb/Frotas.PNG?MOD=AJPERES&CACHEID=289ef530-558d-4a26-9351-798d16ce74cb
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.219    864 127.0.0.1 TCP_MISS/200 2497 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/logo_ipiranga.png
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.252   1391 127.0.0.1 TAG_NONE/200 0 CONNECT
security.trustsign.com.br:443 - HIER_NONE/- -
> 1472676461.341   1778 127.0.0.1 TCP_MISS/200 45232 GET
http://www.ipiranga.com.br/wps/wcm/connect/32260164-5ca9-456f-91ca-2f51fd73d520/circle-dt-clean.png?MOD=AJPERES&CACHEID=32260164-5ca9-456f-91ca-2f51fd73d520
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.345   1818 127.0.0.1 TCP_MISS/200 50629 GET
http://www.ipiranga.com.br/wps/wcm/connect/921d21b0-a6ab-498a-9ad2-716f613865aa/03_ampm.png?MOD=AJPERES&CACHEID=921d21b0-a6ab-498a-9ad2-716f613865aa
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.380   1812 127.0.0.1 TCP_MISS/200 46261 GET
http://www.ipiranga.com.br/wps/wcm/connect/ef686a97-527e-4b2c-b7e0-baa31a8db8c9/01_conectcar.png?MOD=AJPERES&CACHEID=ef686a97-527e-4b2c-b7e0-baa31a8db8c9
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.382   1807 127.0.0.1 TCP_MISS/200 43985 GET
http://www.ipiranga.com.br/wps/wcm/connect/36c0aa7f-632a-4961-a4b3-7e500f8d84b0/circle-jetoil.png?MOD=AJPERES&CACHEID=36c0aa7f-632a-4961-a4b3-7e500f8d84b0
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.423   1529 127.0.0.1 TCP_MISS/200 15410 GET
http://www.ipiranga.com.br/wps/wcm/connect/b941561d-e114-4d2d-a5ff-e67988f33dda/servicos_conectcar.png?MOD=AJPERES&CACHEID=b941561d-e114-4d2d-a5ff-e67988f33dda
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.427   1519 127.0.0.1 TCP_MISS/200 19505 GET
http://www.ipiranga.com.br/wps/wcm/connect/0da3e60f-1623-4b8e-ac2c-28012d0779b8/servicos_recargacelular.png?MOD=AJPERES&CACHEID=0da3e60f-1623-4b8e-ac2c-28012d0779b8
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.472      2 127.0.0.1 TAG_NONE/503 4082 GET
https://security.trustsign.com.br/static/seals/selo-pro-57984cf8c13fa073dbb14cbe21e9368c-pt.png
- HIER_NONE/- text/html
> 1472676461.503   1931 127.0.0.1 TCP_MISS/200 30931 GET
http://www.ipiranga.com.br/wps/wcm/connect/d0b422c1-2b90-4698-bc5a-93de2b8f55f2/02_kmdevantagens.png?MOD=AJPERES&CACHEID=d0b422c1-2b90-4698-bc5a-93de2b8f55f2
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.602   1166 127.0.0.1 TCP_MISS/200 48024 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-km.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676461.607    846 127.0.0.1 TCP_MISS/301 623 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!FOjivSMSGOmrYOwhPEyrNw/spa/Z6_KH44HB40JOBV20A2O33FSTB676/html/img/bg_postoipiranganaweb.jpg
- HIER_DIRECT/177.67.60.32 -
> 1472676461.789   1917 127.0.0.1 TCP_MISS/200 56642 GET
http://www.ipiranga.com.br/wps/wcm/connect/c5fdf79b-6da3-42c3-b787-1c36c2afd1ec/08-revista-km-ago.jpg?MOD=AJPERES&CACHEID=c5fdf79b-6da3-42c3-b787-1c36c2afd1ec
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676461.841   1938 127.0.0.1 TCP_MISS/200 44908 GET
http://www.ipiranga.com.br/wps/wcm/connect/94782b7e-ffd3-484f-9572-bac60810ec3c/thumb_hotelurb.png?MOD=AJPERES&CACHEID=94782b7e-ffd3-484f-9572-bac60810ec3c
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.932    909 127.0.0.1 TCP_MISS/200 6015 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/logo_ipiranga_rodape.png
- HIER_DIRECT/177.67.60.32 image/png
> 1472676461.960    879 127.0.0.1 TCP_MISS/200 2899 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/assets/img/icon_spanchat.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.029   1543 127.0.0.1 TCP_MISS/200 40138 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-produtos.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.090   2617 127.0.0.1 TCP_MISS/200 139799 GET
http://www.ipiranga.com.br/wps/wcm/connect/994d21ed-9dab-40f6-8ce4-afbd97c1b52a/SAMSUNG_WEBBANNER.JPG?MOD=AJPERES&CACHEID=994d21ed-9dab-40f6-8ce4-afbd97c1b52a
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.238   1597 127.0.0.1 TCP_MISS/200 36145 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-servicos.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.346   1592 127.0.0.1 TCP_MISS/200 49965 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destque-postos.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.389   1653 127.0.0.1 TCP_MISS/200 41858 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-comprar.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.422   1676 127.0.0.1 TCP_MISS/200 46619 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/destaque-cartoes.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.440   2921 127.0.0.1 TCP_MISS/200 225780 GET
http://www.ipiranga.com.br/wps/wcm/connect/586f2192-e220-4e95-bc55-665347e1e573/Abastece%2BAi.jpg?MOD=AJPERES&CACHEID=586f2192-e220-4e95-bc55-665347e1e573
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.633   2489 127.0.0.1 TCP_MISS/200 53637 GET
http://www.ipiranga.com.br/wps/wcm/connect/f1500e66-546e-426f-ae64-cca3bf417f30/movida_thumb.png?MOD=AJPERES&CACHEID=f1500e66-546e-426f-ae64-cca3bf417f30
- HIER_DIRECT/177.67.60.32 image/png
> 1472676462.856   1241 127.0.0.1 TCP_MISS/200 82356 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/dav/fs-type1/themes/ipiranga.ipirangaV3.1.theme/img/bg_postoipiranganaweb.jpg
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676462.907   3007 127.0.0.1 TCP_MISS/200 242344 GET
http://www.ipiranga.com.br/wps/wcm/connect/420fffd8-f8b1-430d-b147-d595d8272483/Cartoes.png?MOD=AJPERES&CACHEID=420fffd8-f8b1-430d-b147-d595d8272483
- HIER_DIRECT/177.67.60.32 image/png
> 1472676463.442   3926 127.0.0.1 TCP_MISS/200 439204 GET
http://www.ipiranga.com.br/wps/wcm/connect/b8a8c8b0-7af2-40cb-9309-62a57bde67f5/banner_dtclean-v5-laranja.jpg?MOD=AJPERES&CACHEID=b8a8c8b0-7af2-40cb-9309-62a57bde67f5
- HIER_DIRECT/177.67.60.32 image/jpeg
> 1472676464.201   4322 127.0.0.1 TCP_MISS/200 363207 GET
http://www.ipiranga.com.br/wps/contenthandler/!ut/p/digest!YpQPND6BbndKuc2LDrehnA/mashup/ra:collection?themeID=ZJ_KH44HB40J8I540AS3JCRS43811&locale=pt-BR&locale=pt&locale=en&mime-type=text/plain&entry=dojo_17__0.0%3ahead_js&entry=dojo_fx_17__0.0%3ahead_js&entry=dojo_fmt_17__0.0%3ahead_js&entry=dojo_dom_17__0.0%3ahead_js&entry=dojo_app_17__0.0%3ahead_js&entry=dijit_17__0.0%3ahead_js&entry=dojo_dnd_basic_17__0.0%3ahead_js&entry=dojo_dnd_ext_17__0.0%3ahead_js&entry=dijit_layout_basic_17__0.0%3ahead_js&entry=dijit_menu_17__0.0%3ahead_js&entry=dojo_data_17__0.0%3ahead_js&entry=dijit_form_17__0.0%3ahead_js&entry=dijit_layout_ext_17__0.0%3ahead_js&entry=dojox_xml_17__0.0%3ahead_js&entry=dojox_io_17__0.0%3ahead_js&entry=wp_client_main__0.0%3ahead_js&entry=wp_client_ext__0.0%3ahead_js&entry=dojox_fx_17__0.0%3ahead_js&entry=dojox_gfx_17__0.0%3ahead_js&entry=dojox_charting_17__0.0%3ahead_js&entry=dojox_layout_basic_17__0.0%3ahead_js&entry=dojox_collections_17__0.0%3ahead_js&entry=dojox_uuid_17__0.0%3ahead_js&entry=dojox_data_basic_17__0.0%3ahead_js&entry=dojox_aspect_17__0.0%3ahead_js&entry=wp_analytics_aggregator__0.0%3ahead_js&entry=wp_portal_client_utils__0.0%3ahead_js&entry=dijit_tree_17__0.0%3ahead_js&entry=wp_theme_portal_80__0.0%3ahead_js&entry=wp_portlet_client_model__0.0%3ahead_js&entry=mm_open_ajax_hub__0.0%3ahead_js
- HIER_DIRECT/177.67.60.32 text/plain
>
> Squid 3.5.20.
>
> 01.09.2016 2:44, Rejaine Monteiro ?????:
>
>
>       > hi,
>
>
>
>       > we are having trouble accessing (only) that site below.  all
>       other sites are accessing normally.
>
>
>
>       > TCP_MISS_ABORTED/000 0 GET http://www.ipiranga.com.br/ - H
>
>       > (the site in question works with direct access to internet -
>       without proxy)
>
>
>
>       >  discarded problems with cpu, firewall rules, memory, acls,
>       link, etc.
>
>
>
>       > I set up another squid (in another machine and direct
>       internet access) with basic settings and the same problem. Any
>       idea?
>
>
>
>       > squid version 3.3.13. my basic squid.conf bellow:
>
>
>
>       > acl localnet src 10.0.0.0/8     # RFC1918 possible internal
>       network
>
>       > acl localnet src fc00::/7       # RFC 4193 local private
>       network range
>
>       > acl localnet src fe80::/10      # RFC 4291 link-local
>       (directly plugged) machines
>
>       > acl SSL_ports port 443
>
>       > acl Safe_ports port 80          # http
>
>       > acl Safe_ports port 21          # ftp
>
>       > acl Safe_ports port 443         # https
>
>       > acl Safe_ports port 70          # gopher
>
>       > acl Safe_ports port 210         # wais
>
>       > acl Safe_ports port 1025-65535  # unregistered ports
>
>       > acl Safe_ports port 280         # http-mgmt
>
>       > acl Safe_ports port 488         # gss-http
>
>       > acl Safe_ports port 591         # filemaker
>
>       > acl Safe_ports port 777         # multiling http
>
>       > acl CONNECT method CONNECT
>
>       > dns_v4_first on
>
>       > http_access deny !Safe_ports
>
>       > http_access deny CONNECT !SSL_ports
>
>       > http_access allow localhost manager
>
>       > http_access deny manager
>
>       > http_access allow localnet
>
>       > http_access allow localhost
>
>       > http_access deny all
>
>       > http_port 3128
>
>       > coredump_dir /var/cache/squid
>
>       > refresh_pattern ^ftp:           1440    20%     10080
>
>       > refresh_pattern ^gopher:        1440    0%      1440
>
>       > refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>
>       > refresh_pattern .               0       20%     4320
>
>       > http_access allow localnet
>
>       > http_access deny all
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXx0LoAAoJENNXIZxhPexGmkcH/0aQBrUZtoEAGkBVhLPuP26l
N+niTb4NXYkmkYAuoX/t+7qp78ZXAUp/6mJvehZnjLj9ta7saBAHhI04hbxSolde
/FPNrE/g1jM2Y04yFf/ia6lPGiGSoYcXm8C9kbsnrHvTC120lGjksGKM0bCqh7iH
Vx27A+Fm8IQ7+M5kLRh/2W2e21C/FGBkFteO80EZJy6+a/NFTBa4v2lYpEX4lTci
c0dWy644SptpBrhRm2VAr8c7IQpWdXj/ZP5C3lTVgHM/pmfOP+V7wvrRsJemdjJ6
+ohK6l1DziV3/2Tvhf3i0NYJFiokznt3P9Syit8kMiLdDsHSC9Yqor4ADVg8Lk8=
=oU3N
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/cefce139/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/cefce139/attachment.key>

