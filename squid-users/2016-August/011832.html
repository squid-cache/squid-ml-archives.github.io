<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] Rate limiting bad clients?
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Rate%20limiting%20bad%20clients%3F&In-Reply-To=%3C858F001E-FA29-4319-975A-4BF21811A584%40getbusi.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="011839.html">
   <LINK REL="Next"  HREF="011843.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] Rate limiting bad clients?</H1>
    <B>Dan Charlesworth</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Rate%20limiting%20bad%20clients%3F&In-Reply-To=%3C858F001E-FA29-4319-975A-4BF21811A584%40getbusi.com%3E"
       TITLE="[squid-users] Rate limiting bad clients?">dan at getbusi.com
       </A><BR>
    <I>Tue Aug  9 05:39:02 UTC 2016</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="011839.html">[squid-users] Forum
</A></li>
        <LI>Next message (by thread): <A HREF="011843.html">[squid-users] Rate limiting bad clients?
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#11832">[ date ]</a>
              <a href="thread.html#11832">[ thread ]</a>
              <a href="subject.html#11832">[ subject ]</a>
              <a href="author.html#11832">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi all,

This is more of a squid-adjacent query. Hopefully relevant enough for someone here to help&#8230;

I&#8217;m sick of all these web apps that take it upon themselves to hammer proxies when they don&#8217;t get the response they want, like if they have to authenticate for example. On big networks, behind a forward proxy, there&#8217;s always a few computers with some software doing dozens of identical, failing, requests per second.

- What&#8217;s a good approach for rate limiting the clients computers which are doing this?
- Can anyone point to a good tutorial for this using, say, iptables if that&#8217;s appropriate?

Any advice welcome.

Thanks!
Dan
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="011839.html">[squid-users] Forum
</A></li>
	<LI>Next message (by thread): <A HREF="011843.html">[squid-users] Rate limiting bad clients?
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#11832">[ date ]</a>
              <a href="thread.html#11832">[ thread ]</a>
              <a href="subject.html#11832">[ subject ]</a>
              <a href="author.html#11832">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
