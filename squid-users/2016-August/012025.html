<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] making 204s cachable again
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20making%20204s%20cachable%20again&In-Reply-To=%3CBAY173-W3CAA0130D6471B1EECD71BC150%40phx.gbl%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="012033.html">
   <LINK REL="Next"  HREF="012030.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] making 204s cachable again</H1>
    <B>Jim Ford</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20making%20204s%20cachable%20again&In-Reply-To=%3CBAY173-W3CAA0130D6471B1EECD71BC150%40phx.gbl%3E"
       TITLE="[squid-users] making 204s cachable again">jford1968 at hotmail.com
       </A><BR>
    <I>Thu Aug 18 00:29:45 UTC 2016</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="012033.html">[squid-users] AD Ldap (automatically take the user that is	logging on PC)
</A></li>
        <LI>Next message (by thread): <A HREF="012030.html">[squid-users] making 204s cachable again
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#12025">[ date ]</a>
              <a href="thread.html#12025">[ thread ]</a>
              <a href="subject.html#12025">[ subject ]</a>
              <a href="author.html#12025">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>I recently upgraded to Version 3.5.10.  I'm using it as a regular as well as a reverse proxy.  In both cases I've noticed that what were formerly cachable requests that resulted in a 204 response, are now always resulting in a MISS.  The only hits I'm getting are negative when the requests are close together.  Is there a configuration option I can use to force normal caching and have it obey the expiration?  I don't want to just increase the negative caching time.   		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/4c20d5dc/attachment.htm">http://lists.squid-cache.org/pipermail/squid-users/attachments/20160818/4c20d5dc/attachment.htm</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="012033.html">[squid-users] AD Ldap (automatically take the user that is	logging on PC)
</A></li>
	<LI>Next message (by thread): <A HREF="012030.html">[squid-users] making 204s cachable again
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#12025">[ date ]</a>
              <a href="thread.html#12025">[ thread ]</a>
              <a href="subject.html#12025">[ subject ]</a>
              <a href="author.html#12025">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
