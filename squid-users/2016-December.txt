From frio_cervesa at hotmail.com  Thu Dec  1 06:10:30 2016
From: frio_cervesa at hotmail.com (senor)
Date: Thu, 1 Dec 2016 06:10:30 +0000
Subject: [squid-users] squid SMP notes
Message-ID: <BN6PR17MB114082F5EAE8097B81D0DCABF78F0@BN6PR17MB1140.namprd17.prod.outlook.com>

It is unclear to me how the more recent 'multiple instance' configuration compares with that of 'SMP Scaling'.


Is there a short and sweet description of pros and cons or is the multiple instance simply the new way? The wiki pages vary in detail of implementation but don't directly state any advantage of one over the other. Further confusing me is my need to consider SSL Interception, ssl_crtd helpers and ecap. To be clear, I'm not looking for configuration help. Just some advice on which to pursue so I'm not rethinking the whole thing 6 months down the road.

Thank you for any help.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161201/a1b1a8fd/attachment.htm>

From rousskov at measurement-factory.com  Thu Dec  1 07:15:03 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 1 Dec 2016 00:15:03 -0700
Subject: [squid-users] squid SMP notes
In-Reply-To: <BN6PR17MB114082F5EAE8097B81D0DCABF78F0@BN6PR17MB1140.namprd17.prod.outlook.com>
References: <BN6PR17MB114082F5EAE8097B81D0DCABF78F0@BN6PR17MB1140.namprd17.prod.outlook.com>
Message-ID: <eeb14807-3402-49b3-a5a7-e1b7056bdc56@measurement-factory.com>

On 11/30/2016 11:10 PM, senor wrote:
> It is unclear to me how the more recent 'multiple instance'
> configuration compares with that of 'SMP Scaling'. 
> 
> Is there a short and sweet description of pros and cons or is the
> multiple instance simply the new way? The wiki pages vary in detail of
> implementation but don't directly state any advantage of one over the
> other. Further confusing me is my need to consider SSL Interception,
> ssl_crtd helpers and ecap. To be clear, I'm not looking for
> configuration help. Just some advice on which to pursue so I'm not
> rethinking the whole thing 6 months down the road.


SMP Squid is usually the correct way to deploy a single Squid on a
single beefy machine. "Multiple instances" is the correct way to host
multiple/different/independent Squids on a single machine. In some
cases, multiple Squid instances include SMP Squid instances! The two
features are essentially orthogonal.

Multiple Squid instances are also used (and abused) as a workaround for
various current SMP Squid limitations, which is where the confusion is
often coming from. If you think of a high-level description of what you
want to do, treating Squid as a black box "proxy", then you should be
able to classify your particular use case as a "ideally, a single Squid"
or "multiple/different/independent Squids" and go from there.

[ If you know Apache web server (httpd), then temporary consider
thinking of Squid as an Apache web server configured to proxy traffic.
Does your environment require multiple Apache servers or a single one?
Similar to Squid, Apache supports SMP scale, but that is a _secondary_
question. ]

Some of the current SMP Squid limitations are important and do require
either workarounds or development, but "multiple instance" propaganda
often comes from folks who do not understand SMP or have non-technical
phobias/biases against it. Often, those folks are far more vocal than
those who understand what is going on, so it is easy to get the wrong
impression that "multiple instances" is "more recent" or "the future".

SMP Squid is gradually getting better, with fewer exceptions that
require workarounds, including workarounds that involve multiple
instances. Multiple instances support is also getting better. Again,
each orthogonal feature targets a completely different problem area.

The above summary was true for several years, and I expect it to remain
accurate for the foreseeable future.


Sorry, I cannot provide detailed answers to your other good questions
right now.


HTH,

Alex.



From domshyra at gmail.com  Thu Dec  1 15:35:40 2016
From: domshyra at gmail.com (domshyra)
Date: Thu, 1 Dec 2016 07:35:40 -0800 (PST)
Subject: [squid-users] TCP_DENIED/403 on raspberrypi
In-Reply-To: <1480468113203-4680706.post@n4.nabble.com>
References: <1480468113203-4680706.post@n4.nabble.com>
Message-ID: <1480606540060-4680710.post@n4.nabble.com>

Bump for the mailing list... 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-DENIED-403-on-raspberrypi-tp4680706p4680710.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From domshyra at gmail.com  Thu Dec  1 15:36:26 2016
From: domshyra at gmail.com (domshyra)
Date: Thu, 1 Dec 2016 07:36:26 -0800 (PST)
Subject: [squid-users] TCP_DENIED/403 on raspberrypi
Message-ID: <1480606586696-4680711.post@n4.nabble.com>

Hello. I have looked for countless hours to solve this problem. 
I have tried reordering the config file so that 
 are all in different orders 

I've messed with http_access deny !Safe_ports

None of the regular trouble shooting issues helped. 
I am on wifi on the pi with a static ip address, and I have tried explicitly
adding that as well




I've parsed it too, no errors or warnings. 
Here is the full output...



It's weird to me cause 192.168.1.25 is what my wifi ip is on my macbook
which I am using to ssh into the pi, but even when I run it on the pi its
the same error. Idk if that effects anything but I am lost for a solution on
this. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-DENIED-403-on-raspberrypi-tp4680711.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From lo.kenneth at gmail.com  Thu Dec  1 17:27:13 2016
From: lo.kenneth at gmail.com (klops)
Date: Thu, 1 Dec 2016 09:27:13 -0800 (PST)
Subject: [squid-users] Transparent Proxy in AWS
In-Reply-To: <583CF4B7.3030107@treenet.co.nz>
References: <1480368783954-4680691.post@n4.nabble.com>
 <583CF4B7.3030107@treenet.co.nz>
Message-ID: <1480613233935-4680712.post@n4.nabble.com>

Does this mean the squid box has to be the overall gateway for the internal
network for transparrancy to work?

The reason the proposed setup the way it is is because AWS VPC  service has
a service based NAT gateway which we have not low level control over and it
is the default gateway. We want to only route http/https traffic over to
squid and the rest via their NAT gateway

Thanks in advance for the followup 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-Proxy-in-AWS-tp4680691p4680712.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Thu Dec  1 23:46:51 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 2 Dec 2016 12:46:51 +1300
Subject: [squid-users] TCP_DENIED/403 on raspberrypi
In-Reply-To: <1480606586696-4680711.post@n4.nabble.com>
References: <1480606586696-4680711.post@n4.nabble.com>
Message-ID: <eff7ead9-66cc-a672-0d1b-44440eb766a0@treenet.co.nz>

On 2/12/2016 4:36 a.m., domshyra wrote:
> Hello. I have looked for countless hours to solve this problem. 
> I have tried reordering the config file so that 
>  are all in different orders 
> 
> I've messed with http_access deny !Safe_ports
> 
> None of the regular trouble shooting issues helped. 
> I am on wifi on the pi with a static ip address, and I have tried explicitly
> adding that as well
> 

Try:
<http://wiki.squid-cache.org/SquidFaq/OrderIsImportant>

You have mentioned quite a few things being tried, but the config you
put the changes matters a lot to determine whether an attempt works or not.


<snip>
> acl localnet src 192.168.0.0/16        # RFC1918 possible internal network
> #acl localnet src 192.168.1.39/24 #home wifi

You removed the default "http_access allow localnet" line that uses this
ACL check to let traffic through.

<snip>
> 
> # SAFE PORTS
> acl SSL_ports  port 443 494 2598
<snip>
> acl Safe_ports port 1025-65535  # unregistered ports
> acl CONNECT method CONNECT
> never_direct allow all
> 

So Squid is never allowed to connect to any server ... Um.


> acl authenticated_ips src "/etc/squid3/ip_auth"
> 
> # HTTP ACCESS
> http_access allow manager localhost
> http_access deny manager
> http_access deny !Safe_ports
> http_access allow authenticated_ips
> http_access deny CONNECT !SSL_ports
> http_access allow localhost
> http_access deny all
> icp_access deny all
> htcp_access deny all

<snip>

> pi at raspberrypi:~ $ sudo tail -F /var/log/squid3/access.log 
> 1480315313.153      1 192.168.1.25 TCP_DENIED/403 3637 CONNECT 127.0.0.1:19536 - HIER_NONE/- text/html

Read through the http_access ACL checks top-down left-to-right ...

> http_access allow manager localhost
> http_access deny manager
> http_access deny !Safe_ports
> http_access allow authenticated_ips
> http_access deny CONNECT !SSL_ports
> http_access allow localhost

These 403 transactions are;
 *not* cache manager requests, next
 *not* cache manager requests, next
 *are* to a port listed in Safe_ports, next


Is 192.168.1.25 or a subnet containing it listed in the file
/etc/squid3/ip_auth ?
 Was it listed there when you started or last reconfigured Squid?


Starting from the default config file you should only have to add the
19536 port to SSL_ports and replace localnet ACL with your
authenticated_ips thing.

Just be extra paranoid about adding ports to SSL_Ports. Be sure you know
that the protocol(s!) being used over that port are safe. Squid does not
have any control or insight into whats happening over a CONNECT tunnel
once its permitted.

Amos



From squid3 at treenet.co.nz  Fri Dec  2 00:00:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 2 Dec 2016 13:00:21 +1300
Subject: [squid-users] Transparent Proxy in AWS
In-Reply-To: <1480613233935-4680712.post@n4.nabble.com>
References: <1480368783954-4680691.post@n4.nabble.com>
 <583CF4B7.3030107@treenet.co.nz> <1480613233935-4680712.post@n4.nabble.com>
Message-ID: <fb7baf0d-51aa-36e2-3f82-6647f5cd1cdb@treenet.co.nz>

On 2/12/2016 6:27 a.m., klops wrote:
> Does this mean the squid box has to be the overall gateway for the internal
> network for transparrancy to work?

That is just one option. The other two are routing or tunnel, as I
mentioned in the second sentence.

> 
> The reason the proposed setup the way it is is because AWS VPC  service has
> a service based NAT gateway which we have not low level control over and it
> is the default gateway. We want to only route http/https traffic over to
> squid and the rest via their NAT gateway

NAT is a destructive process. DNAT erases the clients original
destination-IP and the only way around that requires that DNAT to happen
on the same machine as Squid.

If you cannot do that, then you cannot use intercept or tproxy modes on
this Squid.

Amos



From gibson at telmate.com  Fri Dec  2 00:18:51 2016
From: gibson at telmate.com (Michael Gibson)
Date: Thu, 1 Dec 2016 16:18:51 -0800
Subject: [squid-users] 100% cpu after about an hour
Message-ID: <CA+uU-7VP=dDQOpXbkRNdhtJdZuMRLvpF3WPp5TFWg6=UbYK--w@mail.gmail.com>

Hello,

Having about 100% CPU usage after about an hour running. We operate Squid v
3.5 on multiple nodes. We range from 10 users, up through 200 on various
nodes. We recently updated from 3.3 to 3.5 and I've been unable to contain
the core usage of Squid. I attempted to get multiple Squid workers resulted
in both cores getting pegged on our small servers.

Dual core Intel(R) Celeron(R) M processor         1.50GHz
4GB RAM

Here's the config we're currently running:

# Managed by Chef
# Changes will be overwritten

# Crazy debug
#debug_options ALL,0 11,5 20,5 17,5 23,5 26,5 28,5 44,5 55,5 61,5 78,5 83,5

# Debug ACL issues
#debug_options ALL,1 28,4

# Debug ACL issues full access
#debug_options ALL,1 28,2 28,9

# Setup our local networks ACLs
acl VPN_Net src 10.1.2.0/24
acl No_Auth_Net src 10.10.1.0/24
acl Android_Server src 10.10.1.1/32

acl SSL_ports port 443
acl Safe_ports port 80    # http
acl Safe_ports port 443   # https
acl CONNECT method CONNECT

# Custom acl for Telmate-controlled sites
acl telmate_domains dstdomain .telmate.com .telmate.cc
request_header_add ****************************
request_header_add **********************

#
# Content filtering
#
icap_enable on

# unlimited icap failure
icap_service_failure_limit -1
icap_retry allow all
icap_send_client_ip on
icap_retry_limit -1

icap_service service_req reqmod_precache bypass=0 icap://
127.0.0.1:1344/request
adaptation_access service_req allow VPN_Net !CONNECT

icap_service service_resp respmod_precache bypass=0 icap://
127.0.0.1:1344/response
adaptation_access service_resp allow VPN_Net

# Only allow cachemgr access from Android Server
http_access allow Android_Server manager
http_access deny manager

# Deny requests to ports we don't allow
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# URL Filtering

# acl No_Auth_Whitelist dstdomain "/etc/squid3/approved-sites.squid"
acl No_Auth_Whitelist dstdomain "/etc/squid3/no-auth-approved-sites.squid"

# dedicated, no exception URL blacklist managed by chef only
acl blacklist-urls url_regex "/etc/squid3/blacklist-urls.squid"
http_access deny blacklist-urls

# Allow localhost access in case of misconfigured application
http_access allow localhost

# Allow No_Auth_Net access to only the No auth whitelist
http_access allow No_Auth_Whitelist No_Auth_Net

# CONNECT method requests only have an IP address, allow all SSL CONNECT
handshakes
http_access allow No_Auth_Net CONNECT

# Allow VPN_Net to anything as ICAP will be consulted for approval
http_access allow VPN_Net

# Default catch all to deny access not specifically granted
http_access deny all


# Squid proxy interception config
http_port 10.10.1.1:3128
http_port 10.10.1.1:3126 intercept
https_port 10.10.1.1:3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/telmate-gk-CA.pem

# Proxy public hiding, don't tell site we are using a proxy
via off
forwarded_for off

# ssl-bump goodies
always_direct allow all
ssl_bump server-first all

# the following two options are unsafe and not always necessary:
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

# Prepare ssl_db: Done in Chef
# /usr/lib/squid3/ssl_crtd3 -c -s /var/spool/squid3/ssl_db -M 4MB
# chown -R proxy:proxy /var/spool/squid3/ssl_db
sslcrtd_program /usr/lib/squid3/ssl_crtd3 -s /var/spool/squid3/ssl_db -M 4MB
sslcrtd_children 32 startup=5 idle=1

# Shutdown Squid after 2 seconds to flush current connections, default is 10
shutdown_lifetime 2 seconds

# Leave coredumps in the cache dir
coredump_dir /var/spool/squid3

# Object size and lifetime settings
cache_mem 256 MB
maximum_object_size 1024 MB
range_offset_limit 200 MB
quick_abort_min -1
read_ahead_gap 50 MB

# cache the health_check to give poor snap a break :(
refresh_pattern ^https://*************/health_check 10 80% 30
override-expire override-lastmod ignore-reload ignore-no-store
ignore-must-revalidate ignore-private ignore-auth store-stale

refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|
swf|flv|x-flv|mpg|wma|ogg|wmv|asx|asf)$ 260000 90% 260009 override-expire
refresh_pattern -i zip$ 432000 100% 864000 override-expire
refresh_pattern .   0 20% 4320

# Logging
# Following logformat WITH request headers, VERY chatty, debug only
# logformat squid %tl %5trms %>a %Ss/%03>Hs %<st %rm %>ru %mt %>ha
logformat squid-full %tl %5trms %>a %Ss/%03>Hs %<st %rm %>ru %mt
logformat squid %tl %5trms %>a %Ss/%03>Hs %<st %rm %ru %mt
# Log query params for telmate traffic only
access_log daemon:/var/log/squid3/telmate.log squid-full telmate_domains
access_log daemon:/var/log/squid3/access.log squid

# Cache_dir must be after maximum_object_size
cache_dir rock /var/spool/squid3 51200

-- 
*Michael Gibson*
*Linux Systems Administrator*
655 Montgomery Street, 18th Floor
San Francisco, CA 94111
Email gibson at telmate.com
Office (415) 300-4015 www.Telmate.com <http://www.telmate.com/> |
www.GettingOut.com <http://www.gettingout.com/> | GettingOut Facebook
<https://www.facebook.com/pages/Gettingout/494201843984720>

[image: Telmate] <http://www.telmate.com/>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161201/29fa1b8d/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec  2 01:27:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 2 Dec 2016 14:27:23 +1300
Subject: [squid-users] 100% cpu after about an hour
In-Reply-To: <CA+uU-7VP=dDQOpXbkRNdhtJdZuMRLvpF3WPp5TFWg6=UbYK--w@mail.gmail.com>
References: <CA+uU-7VP=dDQOpXbkRNdhtJdZuMRLvpF3WPp5TFWg6=UbYK--w@mail.gmail.com>
Message-ID: <a6874296-0065-4845-52cf-0a3b3fd2fa38@treenet.co.nz>

On 2/12/2016 1:18 p.m., Michael Gibson wrote:
> Hello,
> 
> Having about 100% CPU usage after about an hour running. We operate Squid v
> 3.5 on multiple nodes. We range from 10 users, up through 200 on various
> nodes. We recently updated from 3.3 to 3.5 and I've been unable to contain
> the core usage of Squid. I attempted to get multiple Squid workers resulted
> in both cores getting pegged on our small servers.

Which 3.5 release exactly?


Any hint about what its doing with all those cycles?
 cache.log might have something.

> 
> Dual core Intel(R) Celeron(R) M processor         1.50GHz
> 4GB RAM
> 
> Here's the config we're currently running:
> 
> # Managed by Chef
> # Changes will be overwritten
> 
> # Crazy debug
> #debug_options ALL,0 11,5 20,5 17,5 23,5 26,5 28,5 44,5 55,5 61,5 78,5 83,5
> 
> # Debug ACL issues
> #debug_options ALL,1 28,4
> 
> # Debug ACL issues full access
> #debug_options ALL,1 28,2 28,9
> 
> # Setup our local networks ACLs
> acl VPN_Net src 10.1.2.0/24
> acl No_Auth_Net src 10.10.1.0/24
> acl Android_Server src 10.10.1.1/32
> 
> acl SSL_ports port 443
> acl Safe_ports port 80    # http
> acl Safe_ports port 443   # https
> acl CONNECT method CONNECT
> 
> # Custom acl for Telmate-controlled sites
> acl telmate_domains dstdomain .telmate.com .telmate.cc
> request_header_add ****************************
> request_header_add **********************
> 
> #
> # Content filtering
> #
> icap_enable on
> 
> # unlimited icap failure
> icap_service_failure_limit -1
> icap_retry allow all
> icap_send_client_ip on
> icap_retry_limit -1
> 
> icap_service service_req reqmod_precache bypass=0 icap://
> 127.0.0.1:1344/request
> adaptation_access service_req allow VPN_Net !CONNECT
> 
> icap_service service_resp respmod_precache bypass=0 icap://
> 127.0.0.1:1344/response
> adaptation_access service_resp allow VPN_Net
> 
> # Only allow cachemgr access from Android Server
> http_access allow Android_Server manager
> http_access deny manager
> 

In 3.5 move the manager stuff down below the CONNECT line...

> # Deny requests to ports we don't allow
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 

... here. It is a small bit faster that way.

> # URL Filtering
> 
> # acl No_Auth_Whitelist dstdomain "/etc/squid3/approved-sites.squid"
> acl No_Auth_Whitelist dstdomain "/etc/squid3/no-auth-approved-sites.squid"
> 
> # dedicated, no exception URL blacklist managed by chef only
> acl blacklist-urls url_regex "/etc/squid3/blacklist-urls.squid"
> http_access deny blacklist-urls
> 
> # Allow localhost access in case of misconfigured application
> http_access allow localhost
> 
> # Allow No_Auth_Net access to only the No auth whitelist
> http_access allow No_Auth_Whitelist No_Auth_Net
> 
> # CONNECT method requests only have an IP address, allow all SSL CONNECT
> handshakes
> http_access allow No_Auth_Net CONNECT
> 
> # Allow VPN_Net to anything as ICAP will be consulted for approval
> http_access allow VPN_Net
> 
> # Default catch all to deny access not specifically granted
> http_access deny all
> 
> 
> # Squid proxy interception config
> http_port 10.10.1.1:3128
> http_port 10.10.1.1:3126 intercept
> https_port 10.10.1.1:3127 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/telmate-gk-CA.pem
> 
> # Proxy public hiding, don't tell site we are using a proxy
> via off
> forwarded_for off
> 
> # ssl-bump goodies
> always_direct allow all

Obsolete 3.1 hack for client-first SSL-Bump. Remove.

> ssl_bump server-first all

Deprecated bumping rules. Please update this to the 3.5 feature syntax.

IIRC, the 3.5 equivalent of the above line is:
 ssl_bump stare all
 ssl_bump bump all


> 
> # the following two options are unsafe and not always necessary:
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> 
> # Prepare ssl_db: Done in Chef
> # /usr/lib/squid3/ssl_crtd3 -c -s /var/spool/squid3/ssl_db -M 4MB
> # chown -R proxy:proxy /var/spool/squid3/ssl_db
> sslcrtd_program /usr/lib/squid3/ssl_crtd3 -s /var/spool/squid3/ssl_db -M 4MB
> sslcrtd_children 32 startup=5 idle=1
> 
> # Shutdown Squid after 2 seconds to flush current connections, default is 10
> shutdown_lifetime 2 seconds
> 
> # Leave coredumps in the cache dir
> coredump_dir /var/spool/squid3
> 
> # Object size and lifetime settings
> cache_mem 256 MB
> maximum_object_size 1024 MB
> range_offset_limit 200 MB


Since rock cache also breaks objects down into chunks of ~32KB it is
inefficient for large MB (or GB) sized objects. That is not going to do
much good for CPU performance.


> quick_abort_min -1
> read_ahead_gap 50 MB
> 

So 50+ MB of buffer per client connection.

 How many connections per second does your proxy service?
 How many of those are concurrent after this "1 hour" ?

  200 clients x 50 MB buffer => up to 10 GB of buffered data.
 Easily more than the ~3 GB RAM this machine might have spare.
 And thats assuming just one connection per client, usually browser
clients have 8-100 connections open at a time.
 There is a good reason the default 'gap' is set to 64KB :-)


If Squid starts to use swap memory performance does down the drain,
really, really badly.


> # cache the health_check to give poor snap a break :(
> refresh_pattern ^https://*************/health_check 10 80% 30
> override-expire override-lastmod ignore-reload ignore-no-store
> ignore-must-revalidate ignore-private ignore-auth store-stale

Ah, you know that 30 means *minutes* right?

So the health checker will have a 30min delay between identifying
problems. Or counterwise, a 30min delay before identiying problems resolved.


> 
> refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
> refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|
> swf|flv|x-flv|mpg|wma|ogg|wmv|asx|asf)$ 260000 90% 260009 override-expire
> refresh_pattern -i zip$ 432000 100% 864000 override-expire

You seem to be trying to cache video and multimedia objects in a
default/small RAM cache and a rock cache.

rock cache type is optimized for use caching very small objects in the
order of KB at most. While it can store larger ones now, that is quite
inefficient use of the rock cache design.

UFS/AUFS/diskd are the cache types to use for large MB/GB sized objects.


> refresh_pattern .   0 20% 4320
> 
> # Logging
> # Following logformat WITH request headers, VERY chatty, debug only
> # logformat squid %tl %5trms %>a %Ss/%03>Hs %<st %rm %>ru %mt %>ha
> logformat squid-full %tl %5trms %>a %Ss/%03>Hs %<st %rm %>ru %mt
> logformat squid %tl %5trms %>a %Ss/%03>Hs %<st %rm %ru %mt

Re-defining the built-in "squid" format does not do what you expect, and
is yet another drain on the CPU.

> # Log query params for telmate traffic only
> access_log daemon:/var/log/squid3/telmate.log squid-full telmate_domains
> access_log daemon:/var/log/squid3/access.log squid
> 
> # Cache_dir must be after maximum_object_size
> cache_dir rock /var/spool/squid3 51200
> 

HTH
Amos



From squid3 at treenet.co.nz  Fri Dec  2 18:33:32 2016
From: squid3 at treenet.co.nz (squid-users)
Date: Fri, 2 Dec 2016 19:33:32 +0100
Subject: [squid-users] this is definitely the coolest stuff ever
Message-ID: <0000f7e482c4$4054f402$0045de12$@treenet.co.nz>

Dear! 


Have you already seen  that  awesome stuff?  I've never  seen something that cool before, take a look <http://nine.rockandsouljewels.com/e4gfs/0>

Warmest regards, squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161202/2ed59751/attachment.htm>

From domshyra at gmail.com  Fri Dec  2 20:30:57 2016
From: domshyra at gmail.com (domshyra)
Date: Fri, 2 Dec 2016 12:30:57 -0800 (PST)
Subject: [squid-users] TCP_DENIED/403 on raspberrypi
In-Reply-To: <eff7ead9-66cc-a672-0d1b-44440eb766a0@treenet.co.nz>
References: <1480606586696-4680711.post@n4.nabble.com>
 <eff7ead9-66cc-a672-0d1b-44440eb766a0@treenet.co.nz>
Message-ID: <1480710657434-4680721.post@n4.nabble.com>

So I have changed the file to a sample conf file. Here is what it looks like
now




authenticated_ips is a list of ip addresses that are going to be outgoing
ips and 192.168.1.25 isn't part of it. I have received a new 403 error which
is this below


192.168.1.25 is my macbook which is SSH'd into the raspberry pi 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-DENIED-403-on-raspberrypi-tp4680711p4680721.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Fri Dec  2 21:07:21 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 2 Dec 2016 22:07:21 +0100
Subject: [squid-users] TCP_DENIED/403 on raspberrypi
In-Reply-To: <1480710657434-4680721.post@n4.nabble.com>
References: <1480606586696-4680711.post@n4.nabble.com>
 <eff7ead9-66cc-a672-0d1b-44440eb766a0@treenet.co.nz>
 <1480710657434-4680721.post@n4.nabble.com>
Message-ID: <201612022207.21310.Antony.Stone@squid.open.source.it>

On Friday 02 December 2016 at 21:30:57, domshyra wrote:

> So I have changed the file to a sample conf file. Here is what it looks
> like now

	http_access allow all

Looks to me to be your biggest problem.

Standard security practice is "allow what you specifically know you want to 
allow, and deny by default everything else".

So, create your ACLs to allow what you want to allow, and then "deny all" at 
the end.


Antony.

-- 
I wasn't sure about having a beard at first, but then it grew on me.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From domshyra at gmail.com  Fri Dec  2 21:02:21 2016
From: domshyra at gmail.com (domshyra)
Date: Fri, 2 Dec 2016 13:02:21 -0800 (PST)
Subject: [squid-users] TCP_DENIED/403 on raspberrypi
In-Reply-To: <201612022207.21310.Antony.Stone@squid.open.source.it>
References: <1480606586696-4680711.post@n4.nabble.com>
 <eff7ead9-66cc-a672-0d1b-44440eb766a0@treenet.co.nz>
 <1480710657434-4680721.post@n4.nabble.com>
 <201612022207.21310.Antony.Stone@squid.open.source.it>
Message-ID: <1480712541147-4680723.post@n4.nabble.com>

I tried that but still 403 :/. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-DENIED-403-on-raspberrypi-tp4680711p4680723.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From creditu at eml.cc  Sat Dec  3 22:08:51 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Sat, 03 Dec 2016 15:08:51 -0700
Subject: [squid-users] Secrecy and TCP Reset and Allow Direct
Message-ID: <1480802931.2948804.807424569.2F043E95@webmail.messagingengine.com>

I am trying to finalize an accelerator configuration  in 3.1.  The
accelerator has cache disabled (we use an external service) with cache
deny all. We have several public IPs that send requests to back end
Apache servers using http.  The accelerator will provide both http and
https for a while.  A few questions:

Trying to get a A rating in Qualys site and the best I can get is A- due
to forward secrecy not supported for a few browsers.  I think this is
due to Squid not being able to support ECDHE (which some of those
browsers need).  Just wanted to confirm that we're not missing
something.  Is there any alternate configuration that we may be able to
do? 

I have an ACL that I want to send a TCP reset if the url being requested
matches a regx.  It seems to work, but in testing the first time a
browser request the url, the upper left corner of the browser has the
word "reset" in it.  Subsequent requests seem to work as expected and
the client/browser gets the reset.  In the cache log I see:   
 errorpage.cc(293) errorTryLoadText:
 '/usr/share/squid/errors/en-us/TCP_RESET': (2) No such file or
 directory
WARNING: Error Pages Missing Language: en-us
errorpage.cc(293) errorTryLoadText:
'/usr/share/squid/errors/en/TCP_RESET': (2) No such file or directory"
"WARNING: Error Pages Missing Language: en
I touched an empty file in the directories and the errors went away. 
Now after a squid restart I get "max-age=86400" in the upper left corner
once then it goes away and works as expected (client gets reset).  Just
curious if  this is expected?  Here is the ACL:

acl www_url url_regex -i [^:]+://www.example.com.*
deny_info TCP_RESET www_url

Trying to understand if we should use the always direct directive with
this configuration.   As stated, we just want to send public requests to
the backend servers. The current ACL for this is:

acl apache dst 10.10.10.0/24
always_direct allow apache
always_direct deny all



From squid3 at treenet.co.nz  Sat Dec  3 23:13:01 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 4 Dec 2016 12:13:01 +1300
Subject: [squid-users] Secrecy and TCP Reset and Allow Direct
In-Reply-To: <1480802931.2948804.807424569.2F043E95@webmail.messagingengine.com>
References: <1480802931.2948804.807424569.2F043E95@webmail.messagingengine.com>
Message-ID: <c396f4ee-c84b-b960-7204-9b24b9b8c0e2@treenet.co.nz>

On 4/12/2016 11:08 a.m., creditu wrote:
> I am trying to finalize an accelerator configuration  in 3.1.  The
> accelerator has cache disabled (we use an external service) with cache
> deny all. We have several public IPs that send requests to back end
> Apache servers using http.  The accelerator will provide both http and
> https for a while.  A few questions:
> 
> Trying to get a A rating in Qualys site and the best I can get is A- due
> to forward secrecy not supported for a few browsers.  I think this is
> due to Squid not being able to support ECDHE (which some of those
> browsers need).  Just wanted to confirm that we're not missing
> something.  Is there any alternate configuration that we may be able to
> do? 

ECDHE is enabled when the https_port tls-dh= option is given a curve
name. This is supported in 3.5.13+.

> 
> I have an ACL that I want to send a TCP reset if the url being requested
> matches a regx.  It seems to work, but in testing the first time a
> browser request the url, the upper left corner of the browser has the
> word "reset" in it.  Subsequent requests seem to work as expected and
> the client/browser gets the reset.  In the cache log I see:   
>  errorpage.cc(293) errorTryLoadText:
>  '/usr/share/squid/errors/en-us/TCP_RESET': (2) No such file or
>  directory
> WARNING: Error Pages Missing Language: en-us
> errorpage.cc(293) errorTryLoadText:
> '/usr/share/squid/errors/en/TCP_RESET': (2) No such file or directory"
> "WARNING: Error Pages Missing Language: en
> I touched an empty file in the directories and the errors went away. 
> Now after a squid restart I get "max-age=86400" in the upper left corner
> once then it goes away and works as expected (client gets reset).  Just
> curious if  this is expected?  Here is the ACL:
> 
> acl www_url url_regex -i [^:]+://www.example.com.*
> deny_info TCP_RESET www_url

You can omit the trailing ".*" , but yes that is correct.

The browser showing some text is odd. You can use "debug_options 11,2"
to get a cache.log trace of the HTTP message headers and see what is
going on there.

> 
> Trying to understand if we should use the always direct directive with
> this configuration.   As stated, we just want to send public requests to
> the backend servers. The current ACL for this is:
> 
> acl apache dst 10.10.10.0/24
> always_direct allow apache
> always_direct deny all

This directives only purpose is to prevent cache_peer links being used
for the traffic which has an "allow" action.

Amos


From creditu at eml.cc  Sat Dec  3 23:38:33 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Sat, 03 Dec 2016 16:38:33 -0700
Subject: [squid-users] Secrecy and TCP Reset and Allow Direct
In-Reply-To: <c396f4ee-c84b-b960-7204-9b24b9b8c0e2@treenet.co.nz>
References: <1480802931.2948804.807424569.2F043E95@webmail.messagingengine.com>
 <c396f4ee-c84b-b960-7204-9b24b9b8c0e2@treenet.co.nz>
Message-ID: <1480808313.2964586.807462281.69AEFE3C@webmail.messagingengine.com>



On Sat, Dec 3, 2016, at 04:13 PM, Amos Jeffries wrote:
> On 4/12/2016 11:08 a.m., creditu wrote:
> > I am trying to finalize an accelerator configuration  in 3.1.  The
> > accelerator has cache disabled (we use an external service) with cache
> > deny all. We have several public IPs that send requests to back end
> > Apache servers using http.  The accelerator will provide both http and
> > https for a while.  A few questions:
> > 
> > Trying to get a A rating in Qualys site and the best I can get is A- due
> > to forward secrecy not supported for a few browsers.  I think this is
> > due to Squid not being able to support ECDHE (which some of those
> > browsers need).  Just wanted to confirm that we're not missing
> > something.  Is there any alternate configuration that we may be able to
> > do? 
> 
> ECDHE is enabled when the https_port tls-dh= option is given a curve
> name. This is supported in 3.5.13+.

Thanks and good to know.  We'll work on the upgrade once we can get the
3.1 online.

> 
> > 
> > I have an ACL that I want to send a TCP reset if the url being requested
> > matches a regx.  It seems to work, but in testing the first time a
> > browser request the url, the upper left corner of the browser has the
> > word "reset" in it.  Subsequent requests seem to work as expected and
> > the client/browser gets the reset.  In the cache log I see:   
> >  errorpage.cc(293) errorTryLoadText:
> >  '/usr/share/squid/errors/en-us/TCP_RESET': (2) No such file or
> >  directory
> > WARNING: Error Pages Missing Language: en-us
> > errorpage.cc(293) errorTryLoadText:
> > '/usr/share/squid/errors/en/TCP_RESET': (2) No such file or directory"
> > "WARNING: Error Pages Missing Language: en
> > I touched an empty file in the directories and the errors went away. 
> > Now after a squid restart I get "max-age=86400" in the upper left corner
> > once then it goes away and works as expected (client gets reset).  Just
> > curious if  this is expected?  Here is the ACL:
> > 
> > acl www_url url_regex -i [^:]+://www.example.com.*
> > deny_info TCP_RESET www_url
> 
> You can omit the trailing ".*" , but yes that is correct.
> 
> The browser showing some text is odd. You can use "debug_options 11,2"
> to get a cache.log trace of the HTTP message headers and see what is
> going on there.
> 

Okay, will give it a try.

> > 
> > Trying to understand if we should use the always direct directive with
> > this configuration.   As stated, we just want to send public requests to
> > the backend servers. The current ACL for this is:
> > 
> > acl apache dst 10.10.10.0/24
> > always_direct allow apache
> > always_direct deny all
> 
> This directives only purpose is to prevent cache_peer links being used
> for the traffic which has an "allow" action.
> 

Still a little confused if I need it.  Based on what you said I think I
don't, but it doesn't seem to hurt anything that I can tell.  My
cache_peer statements send to backend apache servers and we have
disabled all caching, for example:

acl www_site dstdomain www.example.com
cache_peer 10.10.10.1 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.1 allow www_site
cache_peer_access 10.10.10.1 deny all

cache_peer 10.10.10.2 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10..10.2 allow www_site
cache_peer_access 10.10.10.2 deny all

Thanks Again.  Appreciate the help.

> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Sat Dec  3 23:47:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 4 Dec 2016 12:47:49 +1300
Subject: [squid-users] TCP_DENIED/403 on raspberrypi
In-Reply-To: <1480710657434-4680721.post@n4.nabble.com>
References: <1480606586696-4680711.post@n4.nabble.com>
 <eff7ead9-66cc-a672-0d1b-44440eb766a0@treenet.co.nz>
 <1480710657434-4680721.post@n4.nabble.com>
Message-ID: <e991a41d-fef5-d6b7-1f01-20da7b62dfe5@treenet.co.nz>

NOTE: please dont use fancy quoting when posting through the Nabble
interface. It erases the critical information about your problem from
any other copy of the list:

On 3/12/2016 9:30 a.m., domshyra wrote:
> So I have changed the file to a sample conf file. Here is what it looks like
> now
> 
> 
> 
> 
> authenticated_ips is a list of ip addresses that are going to be outgoing
> ips and 192.168.1.25 isn't part of it. I have received a new 403 error which
> is this below
> 
> 
> 192.168.1.25 is my macbook which is SSH'd into the raspberry pi 
> 
> 


There is the root cause of your problem. http_access matches the Squid
*incoming* traffic. The requests arriving into Squid from clients.

Outgoing traffic of a Squid (and thus its outgoing IP(s)) should never
be sent back into that Squid. That would be a loop in the traffic.

Your access.log says:

The client (src) of the requests is 192.168.1.25.

The destination is the server 127.0.0.1 port 19536.

(PS. why are you logging proxy traffic in web-server format anyway? web
servers do not have two TCP connections to deal with like proxies)


So like I said earlier:
> 
> Starting from the default config file you should only have to add the
> 19536 port to SSL_ports and replace localnet ACL with your
> authenticated_ips thing.
> 
> Just be extra paranoid about adding ports to SSL_Ports. Be sure you know
> that the protocol(s!) being used over that port are safe. Squid does not
> have any control or insight into whats happening over a CONNECT tunnel
> once its permitted.


1) Set your http_access lines to be this (notice that it is the default
config):

 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_ports
 http_access allow localhost manager
 http_access deny manager

 # INSERT YOUR OWN RULE(S) HERE ...

 http_access allow localnet
 http_access allow localhost
 http_access deny all


2) Since your client is using 192.168.* the localnet ACL should be reset
to the below:

 #acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
 #acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
 acl localnet src 192.168.0.0/16        # RFC1918 possible internal network
 acl localnet src fc00::/7       # RFC 4193 local private network range
 acl localnet src fe80::/10      # RFC 4291 link-local (directly
plugged) machines


3) Figure out what the strange port 19536 is about. If you actually want
that to happen then add the below to your squid.conf:

 # your reason for adding this port goes here.
 acl SSL_ports port 19536



Amos


From squid3 at treenet.co.nz  Sun Dec  4 00:03:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 4 Dec 2016 13:03:29 +1300
Subject: [squid-users] Secrecy and TCP Reset and Allow Direct
In-Reply-To: <1480808313.2964586.807462281.69AEFE3C@webmail.messagingengine.com>
References: <1480802931.2948804.807424569.2F043E95@webmail.messagingengine.com>
 <c396f4ee-c84b-b960-7204-9b24b9b8c0e2@treenet.co.nz>
 <1480808313.2964586.807462281.69AEFE3C@webmail.messagingengine.com>
Message-ID: <aaed9452-390e-792b-4338-3d822341007a@treenet.co.nz>

On 4/12/2016 12:38 p.m., creditu wrote:
> 
> 
> On Sat, Dec 3, 2016, at 04:13 PM, Amos Jeffries wrote:
>> On 4/12/2016 11:08 a.m., creditu wrote:
>>> I am trying to finalize an accelerator configuration  in 3.1.  The
>>> accelerator has cache disabled (we use an external service) with cache
>>> deny all. We have several public IPs that send requests to back end
>>> Apache servers using http.  The accelerator will provide both http and
>>> https for a while.  A few questions:
>>>
>>> Trying to get a A rating in Qualys site and the best I can get is A- due
>>> to forward secrecy not supported for a few browsers.  I think this is
>>> due to Squid not being able to support ECDHE (which some of those
>>> browsers need).  Just wanted to confirm that we're not missing
>>> something.  Is there any alternate configuration that we may be able to
>>> do? 
>>
>> ECDHE is enabled when the https_port tls-dh= option is given a curve
>> name. This is supported in 3.5.13+.
> 
> Thanks and good to know.  We'll work on the upgrade once we can get the
> 3.1 online.
> 
>>
>>>
>>> I have an ACL that I want to send a TCP reset if the url being requested
>>> matches a regx.  It seems to work, but in testing the first time a
>>> browser request the url, the upper left corner of the browser has the
>>> word "reset" in it.  Subsequent requests seem to work as expected and
>>> the client/browser gets the reset.  In the cache log I see:   
>>>  errorpage.cc(293) errorTryLoadText:
>>>  '/usr/share/squid/errors/en-us/TCP_RESET': (2) No such file or
>>>  directory
>>> WARNING: Error Pages Missing Language: en-us
>>> errorpage.cc(293) errorTryLoadText:
>>> '/usr/share/squid/errors/en/TCP_RESET': (2) No such file or directory"
>>> "WARNING: Error Pages Missing Language: en
>>> I touched an empty file in the directories and the errors went away. 
>>> Now after a squid restart I get "max-age=86400" in the upper left corner
>>> once then it goes away and works as expected (client gets reset).  Just
>>> curious if  this is expected?  Here is the ACL:
>>>
>>> acl www_url url_regex -i [^:]+://www.example.com.*
>>> deny_info TCP_RESET www_url
>>
>> You can omit the trailing ".*" , but yes that is correct.
>>
>> The browser showing some text is odd. You can use "debug_options 11,2"
>> to get a cache.log trace of the HTTP message headers and see what is
>> going on there.
>>
> 
> Okay, will give it a try.

Sorry. I overlooked your version number when writing that. The 11,2 wont
work in 3.1. You need a tcpdump trace to see what is going on for that
old version.

> 
>>>
>>> Trying to understand if we should use the always direct directive with
>>> this configuration.   As stated, we just want to send public requests to
>>> the backend servers. The current ACL for this is:
>>>
>>> acl apache dst 10.10.10.0/24
>>> always_direct allow apache
>>> always_direct deny all
>>
>> This directives only purpose is to prevent cache_peer links being used
>> for the traffic which has an "allow" action.
>>
> 
> Still a little confused if I need it.  Based on what you said I think I
> don't, but it doesn't seem to hurt anything that I can tell.  My

If you dont know of a need for it, you dont need it.

Given the below config then it will prevent any future cache_peer
settings working when you extend them to things beyond basic
originserver' option.

It is already stopping the round-robin being used properly (since no
traffic over those PARENT links). If you see any balancing at all with
that always_direct set then its being done solely via the DNS response
rotation in the DIRECT traffic.


> cache_peer statements send to backend apache servers and we have
> disabled all caching, for example:
> 
> acl www_site dstdomain www.example.com
> cache_peer 10.10.10.1 parent 80 0 no-query no-digest originserver
> round-robin
> cache_peer_access 10.10.10.1 allow www_site
> cache_peer_access 10.10.10.1 deny all
> 
> cache_peer 10.10.10.2 parent 80 0 no-query no-digest originserver
> round-robin
> cache_peer_access 10.10..10.2 allow www_site
> cache_peer_access 10.10.10.2 deny all
> 
> Thanks Again.  Appreciate the help.
> 


Cheers
Amos



From Mohammed.AlJakri at iq.ey.com  Sun Dec  4 08:40:31 2016
From: Mohammed.AlJakri at iq.ey.com (Mohammed M AlJakri)
Date: Sun, 4 Dec 2016 08:40:31 +0000
Subject: [squid-users] Squid Configuration - IP Gateway Issue
Message-ID: <452f46a279df43eba74e2741f3912efd@AM3PR31MB0066.061d.mgd.msft.net>

Dears,

My name is Mohammed M AlJakri, from IT Advisory Department in Ernst and Young Company at Iraq.
I am newbie to Squid and I need your assistant to implement the Basic settings. The Squid server and the my laptop is connected to the home router. (Squid Config file is attached) The DHCP is the local router, the details are below:
172.16.10.1/16 (router and Gateway)
172.16.10.100-199 Range
172.16.10.3 (Squid server IP) is squid server should be the gateway?
after setting the proxy server in the browser-Proxy settings- (IP:172.16.10.3 , port 8888) I cant access internet but I still can ping 8.8.8.8 . also in tracert command, the first hop is the gateway/router (172.16.10.1)
sorry for delay, and hope you can assist me on this problem. However, I know that this problem is not simple for you but I am trying to make this works then I will go deeper in squid implementations.

Best Regards,

-
[cid:image001.gif at 01D24E22.7701B1A0]

Mohammed AlJakri | Advisory Services

EY
Al-Mansour, Al-Amirat St., Baghdad/Erbil, Iraq
Mobile: +964 7704772882 | mohammed.aljakri at iq.ey.com<mailto:mohammed.aljakri at iq.ey.com>
EY/Comm: 964 600
Website: http://www.ey.com
Read our points of view while on the go via the EY Insights mobile app<http://www.ey.com/GL/en/Home/EYInsightsapp>.





___________________________________
The information contained in this communication is intended solely for the use of the individual or entity to whom it is addressed and others authorized to receive it. It may contain confidential or legally privileged information. If you are not the intended recipient you are hereby notified that any disclosure, copying, distribution or taking any action in reliance on the contents of this information is strictly prohibited and may be unlawful. If you have received this communication in error, please notify us immediately by responding to this email and then delete it from your system. EY is neither liable for the proper and complete transmission of the information contained in this communication nor for any delay in its receipt.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161204/322dc165/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.gif
Type: image/gif
Size: 7924 bytes
Desc: image001.gif
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161204/322dc165/attachment.gif>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Squid.conf.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161204/322dc165/attachment.txt>

From squid3 at treenet.co.nz  Sun Dec  4 09:26:18 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 4 Dec 2016 22:26:18 +1300
Subject: [squid-users] Squid Configuration - IP Gateway Issue
In-Reply-To: <452f46a279df43eba74e2741f3912efd@AM3PR31MB0066.061d.mgd.msft.net>
References: <452f46a279df43eba74e2741f3912efd@AM3PR31MB0066.061d.mgd.msft.net>
Message-ID: <44d87198-51fc-3616-f183-5a0a04e4fd6d@treenet.co.nz>

On 4/12/2016 9:40 p.m., Mohammed M AlJakri wrote:
> Dears,
> 
> My name is Mohammed M AlJakri, from IT Advisory Department in Ernst and Young Company at Iraq.
> I am newbie to Squid and I need your assistant to implement the Basic settings. The Squid server and the my laptop is connected to the home router. (Squid Config file is attached) The DHCP is the local router, the details are below:
> 172.16.10.1/16 (router and Gateway)
> 172.16.10.100-199 Range
> 172.16.10.3 (Squid server IP) is squid server should be the gateway?

That depends on what you want to do with it. For now it does not have to
be, but may change later as you change what you are doing with the proxy.

What OS and Squid version are you using on the Squid machine?

(Hint: "uname -a ; squid -v" should tell you that)

> after setting the proxy server in the browser-Proxy settings-
> (IP:172.16.10.3 , port 8888) I cant access internet but I still can
> ping 8.8.8.8 . also in tracert command, the first hop is the
> gateway/router (172.16.10.1)

The ping and tracert tools do not use the browser config settings. So
are not going to produce meaningful results at this point.

Check the /etc/resolv.conf settings of the Squid machine have been setup
correctly by DHCP.

If that looks correct to you. Then please provide details of what "cant
access internet" looks like. What error message is showing up, where it
is showing up, etc.

Amos



From alfrenovsky at gmail.com  Sun Dec  4 22:05:05 2016
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Sun, 4 Dec 2016 19:05:05 -0300
Subject: [squid-users] mangle ranges using ICAP
Message-ID: <CAMXC=WtzBDZATdVLmjOXOnr7TM_txOTrmS19Ttvc4C91bd2nVQ@mail.gmail.com>

Let say a client asks for a URL using a range: 0-256000.

I want squid to ask just for 10.000 bytes and answer as if the request was
server side aborted.

I can change the request Range: "bytes=0-256000" to "bytes=0-10000" with
and icap server


In the answer I'm trying to change the Content-Range from "0-10000/total"
to "0-256000/total" and Content-Length from "10001" to "256001" squid won't
hung up and the client will stay waiting after the first 10001 bytes.

There's a way to make squid send what it gets from the icap and then drop
the TCP connection as in a server side aborted connection?




-- 
Alfrenovsky
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161204/21108460/attachment.htm>

From creditu at eml.cc  Mon Dec  5 00:44:36 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Sun, 04 Dec 2016 17:44:36 -0700
Subject: [squid-users] Config Recommendations
Message-ID: <1480898676.1904222.808186633.011C372F@webmail.messagingengine.com>

For a 3.1 accelerator we have put the followinconfig together.  This
accelerator will not be doing any caching since we use an external
service.  Initially both http and https will be provided.   Some
questions:   I think the ordering of statements and acls is correct, but
was hoping to get some feedback if possible.  Also, since we  want to
turn caching off completely  I was wondering if some of the statements
are unnecessary.  Any feedback or recommendations on the overall config
would be appreciated.     

-----------------------------------
visible_hostname squid.example.com

http_port 192.168.100.1:80 accel defaultsite=www.example.com vhost
http_port 192.168.100.2:80 accel defaultsite=dev.example.com vhost
http_port 192.168.100.4:80 accel defaultsite=test1.example.com vhost

https_port 192.168.100.1:443 accel defaultsite=www.example.com vhost
cert=/path/cert.pem key=/path/key.pem
options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,CIPHER_SERVER_PREFERENCE
cipher=[cipher-list] dhparams=/path/dhparams.pem
https_port 192.168.100.2:443 accel defaultsite=dev.example.com vhost
cert=/path/cert.pem key=/path/key.pem
options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,CIPHER_SERVER_PREFERENCE
cipher=[cipher-list] dhparams=/path/dhparams.pem
https_port 192.168.100.4:443 accel defaultsite=test1.example.com vhost
cert=/path/cert.pem key=/path/key.pem
options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,CIPHER_SERVER_PREFERENCE
cipher=[cipher-list] dhparams=/path/dhparams.pem

# Backend servers for www
acl www dstdomain www.example.com
cache_peer 10.10.10.1 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.1 allow www
cache_peer_access 10.10.10.1 deny all

cache_peer 10.10.10.2 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.2 allow www
cache_peer_access 10.10.10.2 deny all

# Backend server for dev
acl dev dstdomain dev.example.com
cache_peer 10.10.10.3 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.3 allow dev
cache_peer_access 10.10.10.3 deny all

# Debug
#debug_options All,1

cache_effective_user squid
cache_effective_group squid

cache deny all

cache_log /var/log/squid/cache.log
buffered_logs on
cache_store_log none
strip_query_terms off
emulate_httpd_log on
logformat custom %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
"%{Referer}>h" "%{User-Agent}>h" "%{Host}>h" "%tr" %Ss:%Sh
access_log /var/log/squid/access.log custom

acl manager proto cache_object
acl localhost src 127.0.0.1/32
acl to_localhost dst 127.0.0.0/8
acl Safe_ports port 80
acl Safe_ports port 443
acl SSL_ports port 443
acl internal src 10.10.10.0/24
acl CONNECT method CONNECT

acl test1_dst dstdomain test1.example.com
acl test1-refer referer_regex -i [^:]+://[^/]+/test1/
acl test1 url_regex -i [^:]+://test1.example.com

deny_info TCP_RESET test1

http_access deny !Safe_ports
#http_access deny CONNECT !SSL_ports
http_access deny CONNECT
http_access allow manager localhost
http_access deny manager
http_access deny internal
http_access deny to_localhost
http_access allow localhost
http_access allow www
http_access allow dev
http_access allow test-refer
#http_access deny test1

http_access deny all

url_rewrite_program /usr/local/bin/red_http
url_rewrite_children 5

cachemgr_passwd none info
cachemgr_passwd disable all
cache_mgr user at exampe.com

allow_underscore off
httpd_suppress_version_string on
log_mime_hdrs on

client_db off
log_icp_queries off
cache_replacement_policy heap GDSF
memory_replacement_policy heap GDSF
##cache_mem 1000 MB
##cache_dir diskd /var/spool/squid 5000 16 256



From squid3 at treenet.co.nz  Mon Dec  5 02:33:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Dec 2016 15:33:29 +1300
Subject: [squid-users] mangle ranges using ICAP
In-Reply-To: <CAMXC=WtzBDZATdVLmjOXOnr7TM_txOTrmS19Ttvc4C91bd2nVQ@mail.gmail.com>
References: <CAMXC=WtzBDZATdVLmjOXOnr7TM_txOTrmS19Ttvc4C91bd2nVQ@mail.gmail.com>
Message-ID: <54bed6ec-032c-7f73-7c87-592efd98126b@treenet.co.nz>

On 5/12/2016 11:05 a.m., Alfredo Rezinovsky wrote:
> Let say a client asks for a URL using a range: 0-256000.
> 
> I want squid to ask just for 10.000 bytes and answer as if the request was
> server side aborted.
> 
> I can change the request Range: "bytes=0-256000" to "bytes=0-10000" with
> and icap server
> 
> 
> In the answer I'm trying to change the Content-Range from "0-10000/total"
> to "0-256000/total" and Content-Length from "10001" to "256001" squid won't
> hung up and the client will stay waiting after the first 10001 bytes.
> 
> There's a way to make squid send what it gets from the icap and then drop
> the TCP connection as in a server side aborted connection?


Squid is a network proxy for production use, not a piece of testing
software. To see what happens when a server disconnects early ... make
the server disconnect early.


There is also no relationship between client and server TCP connections
in HTTP proxying. And there is no server abort happening in your setup.
So the server abort handling is not going to happen. Period.


ICAP has told Squid there are 256000 bytes comming *from ICAP*, not from
any server. How those bytes are found/generated is not up to Squid.
Since ICAP only requested 10000 bytes from the server the rest is up to
the ICAP service to generate somehow. Squid is simply waiting for that
_ICAP_ transaction to complete.
 --> What you are emulating is the handling of an ICAP service hanging.


Amos



From squid3 at treenet.co.nz  Mon Dec  5 03:19:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Dec 2016 16:19:34 +1300
Subject: [squid-users] Config Recommendations
In-Reply-To: <1480898676.1904222.808186633.011C372F@webmail.messagingengine.com>
References: <1480898676.1904222.808186633.011C372F@webmail.messagingengine.com>
Message-ID: <44308a53-93ef-5c0f-9b5b-778ca9c03c46@treenet.co.nz>

On 5/12/2016 1:44 p.m., creditu at eml.cc wrote:
> For a 3.1 accelerator we have put the followinconfig together.  This
> accelerator will not be doing any caching since we use an external
> service.  Initially both http and https will be provided.   Some
> questions:   I think the ordering of statements and acls is correct, but
> was hoping to get some feedback if possible.  Also, since we  want to
> turn caching off completely  I was wondering if some of the statements
> are unnecessary.  Any feedback or recommendations on the overall config
> would be appreciated.     

You can remove any options which are setting things to their default values.

Add "cache_mem 0" to prevent the memory cache being allocated.
And remove the *_replacement_policy lines, they are pointless without
caching.

The "cachemgr_passwd none info" line is useless, since the next thing
done is disabled.
That also means the "http_access allow manager localhost" line is not
useful either unless you re-open the info report.


Amo


From rousskov at measurement-factory.com  Mon Dec  5 03:29:17 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 4 Dec 2016 20:29:17 -0700
Subject: [squid-users] mangle ranges using ICAP
In-Reply-To: <CAMXC=WtzBDZATdVLmjOXOnr7TM_txOTrmS19Ttvc4C91bd2nVQ@mail.gmail.com>
References: <CAMXC=WtzBDZATdVLmjOXOnr7TM_txOTrmS19Ttvc4C91bd2nVQ@mail.gmail.com>
Message-ID: <a8885ab2-6d1d-fec4-37ca-cbe69d77d757@measurement-factory.com>

On 12/04/2016 03:05 PM, Alfredo Rezinovsky wrote:
> Let say a client asks for a URL using a range: 0-256000.
> 
> I want squid to ask just for 10.000 bytes and answer as if the request
> was server side aborted.
> 
> I can change the request Range: "bytes=0-256000" to "bytes=0-10000" with
> and icap server
> 
> 
> In the answer I'm trying to change the Content-Range from
> "0-10000/total" to "0-256000/total" and Content-Length from "10001" to
> "256001" squid won't hung up and the client will stay waiting after the
> first 10001 bytes.
> 
> There's a way to make squid send what it gets from the icap and then
> drop the TCP connection as in a server side aborted connection?

I have not tested it, but I would expect Squid to close the TCP
connection to the HTTP client if the ICAP service aborts the
corresponding RESPMOD transaction (i.e., closes the ICAP connection
before serving the entire ICAP response).

In theory, Squid should read the embedded HTTP response headers and
expect 256001 HTTP body bytes. Your ICAP service can close the
connection after sending fewer HTTP body bytes to simulate the abort.
Such premature aborts do happen in virus filtering with data trickling
environments, so I would expect the corresponding Squid code to work in
principle.

In practice, Squid might get confused with ICAP service manipulations of
the overall transaction state. You would need to test this to know
whether your specific plan works without any Squid modifications.

For example, there is a bug report about Squid getting confused when an
ICAP REQMOD service rewrites a CONNECT request to a GET request (or vice
versa, I do not recall). You might hit somewhat similar limitations with
range manipulations.


HTH,

Alex.



From Silamael at coronamundi.de  Mon Dec  5 10:17:28 2016
From: Silamael at coronamundi.de (Silamael)
Date: Mon, 5 Dec 2016 11:17:28 +0100
Subject: [squid-users] Bad HTTP requests trigger ICAP suspension
Message-ID: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>

Hi,

We are using the ICAP services of Squid for filtering HTTP-Requests. Now
we encountered the problem that a buggy? web application creates
requests with an URL with the hostname set to '.'.
These bad requests than cause the suspension of the whole ICAP service
which then causes the bypass of the URL filtering as the ICAP service
has bypass=yes configured.
This sounds somehow wrong to me, the ICAP service doesn't have a
problem, just the HTTP request being forwarded is borken. Therefor is no
need to suspend the ICAP service at a whole for 30 seconds.
Am I wrong or is this behavior intended?

This are the log messages:
2016/11/28 13:30:00 kid1| SECURITY ALERT: Missing hostname in URL
'http:///?_task=mail&_id=xxxxxxxxxxx&_action=display-attachment&_file=rcmfilexxxxxxxxxxxxxxxxxxxxx'.
see access.log for details.
2016/11/28 13:30:00.740 kid1| 0,3| src/base/TextException.cc(87) Throw:
src/adaptation/icap/ModXact.cc:970:exception:
adapted.header->parse(&httpBuf, true, &error)
2016/11/28 13:30:00.740 kid1| suspending ICAP service for too many failures
2016/11/28 13:30:00.740 kid1| optional ICAP service is suspended:
icap://XXX.XXX.XXX.XXX:1344/reqmod [down,susp,fail11]

Cheers,
Matthias


From alfrenovsky at gmail.com  Mon Dec  5 11:31:56 2016
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Mon, 5 Dec 2016 08:31:56 -0300
Subject: [squid-users] mangle ranges using ICAP
In-Reply-To: <a8885ab2-6d1d-fec4-37ca-cbe69d77d757@measurement-factory.com>
References: <CAMXC=WtzBDZATdVLmjOXOnr7TM_txOTrmS19Ttvc4C91bd2nVQ@mail.gmail.com>
 <a8885ab2-6d1d-fec4-37ca-cbe69d77d757@measurement-factory.com>
Message-ID: <ac2e10fc-e9f4-e211-7132-e0d9c3df7702@gmail.com>


On 05/12/16 00:29, Alex Rousskov wrote:
> On 12/04/2016 03:05 PM, Alfredo Rezinovsky wrote:
>> Let say a client asks for a URL using a range: 0-256000.
>>
>> I want squid to ask just for 10.000 bytes and answer as if the request
>> was server side aborted.
>>
>> I can change the request Range: "bytes=0-256000" to "bytes=0-10000" with
>> and icap server
>>
>>
>> In the answer I'm trying to change the Content-Range from
>> "0-10000/total" to "0-256000/total" and Content-Length from "10001" to
>> "256001" squid won't hung up and the client will stay waiting after the
>> first 10001 bytes.
>>
>> There's a way to make squid send what it gets from the icap and then
>> drop the TCP connection as in a server side aborted connection?
> I have not tested it, but I would expect Squid to close the TCP
> connection to the HTTP client if the ICAP service aborts the
> corresponding RESPMOD transaction (i.e., closes the ICAP connection
> before serving the entire ICAP response).
I noticed that after sending the mail.
I tried to icap encapsule an aborted http connection and squid (and the 
client) stays waiting.
I will try to encapsule icap as if the http connection is complete and 
then abort the icap conection to see what happens.

Thanks.

> In theory, Squid should read the embedded HTTP response headers and
> expect 256001 HTTP body bytes. Your ICAP service can close the
> connection after sending fewer HTTP body bytes to simulate the abort.
> Such premature aborts do happen in virus filtering with data trickling
> environments, so I would expect the corresponding Squid code to work in
> principle.
>
> In practice, Squid might get confused with ICAP service manipulations of
> the overall transaction state. You would need to test this to know
> whether your specific plan works without any Squid modifications.
>
> For example, there is a bug report about Squid getting confused when an
> ICAP REQMOD service rewrites a CONNECT request to a GET request (or vice
> versa, I do not recall). You might hit somewhat similar limitations with
> range manipulations.
>
>
> HTH,
>
> Alex.
>



From squid3 at treenet.co.nz  Mon Dec  5 12:58:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Dec 2016 01:58:35 +1300
Subject: [squid-users] Bad HTTP requests trigger ICAP suspension
In-Reply-To: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>
References: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>
Message-ID: <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>

On 5/12/2016 11:17 p.m., Silamael wrote:
> Hi,
> 
> We are using the ICAP services of Squid for filtering HTTP-Requests. Now
> we encountered the problem that a buggy? web application creates
> requests with an URL with the hostname set to '.'.

Ok.

> These bad requests than cause the suspension of the whole ICAP service
> which then causes the bypass of the URL filtering as the ICAP service
> has bypass=yes configured.

These are not exactly bad requests. '.' is a valid URL host segment.
Very much not likely to succeed in todays Internet, but still valid.

In DNS terms it means the root zone server is the origin host. However,
there is no requirement that hostnames resolve using DNS. So it may have
another meaning if passed to a service that resolves it differently (eg.
the /etc/hosts mapping, or your ICAP service).

There may or may not be bugs in the ICAP service itself handling that
weird input. I can't speak for that software.


> This sounds somehow wrong to me, the ICAP service doesn't have a
> problem, just the HTTP request being forwarded is borken. Therefor is no

The ICAP service appears to be producing URLs without any host segment
at all ("") instead of using the input "." or some other value of its
choosing.

Strictly speaking Squid should accept that as a URL with no hostname,
just like it accepted the odd '.' hostname. That is one of the issues
bug 1961 seeks to fix.


> need to suspend the ICAP service at a whole for 30 seconds.
> Am I wrong or is this behavior intended?
> 

AIUI, for installations using bypass=yes the behaviour is expected. That
setting is not tied to particular types of error, it simply means the
service is optional. *any* HTTP request (even good ones) can bypass.


There is an interoperability issue between Squid and the ICAP service
causing the transaction to break down. The proper handling seems to
happen after that.


> This are the log messages:
> 2016/11/28 13:30:00 kid1| SECURITY ALERT: Missing hostname in URL
> 'http:///?_task=mail&_id=xxxxxxxxxxx&_action=display-attachment&_file=rcmfilexxxxxxxxxxxxxxxxxxxxx'.
> see access.log for details.
> 2016/11/28 13:30:00.740 kid1| 0,3| src/base/TextException.cc(87) Throw:
> src/adaptation/icap/ModXact.cc:970:exception:
> adapted.header->parse(&httpBuf, true, &error)
> 2016/11/28 13:30:00.740 kid1| suspending ICAP service for too many failures
> 2016/11/28 13:30:00.740 kid1| optional ICAP service is suspended:
> icap://XXX.XXX.XXX.XXX:1344/reqmod [down,susp,fail11]
> 

IIRC that "fail11" means the service repeatedly failed (11 times) before
it got suspended for 30sec. Presumably those were 10 bypasses and one
final 'I give up -> suspend' from Squid.

Amos



From eliezer at ngtech.co.il  Mon Dec  5 15:06:24 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 5 Dec 2016 17:06:24 +0200
Subject: [squid-users] Bad HTTP requests trigger ICAP suspension
In-Reply-To: <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>
References: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>
 <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>
Message-ID: <031d01d24f09$25299db0$6f7cd910$@ngtech.co.il>

To resolve this issue quickly I would use a simple squid dstdom regex that reject the request in the first place before passing it to the ICAP service.
The simples is:
acl buggyroot dstdom_regex ^.$

http_access deny buggyroot

Hope it helps to protect the ICAP service.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, December 5, 2016 2:59 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Bad HTTP requests trigger ICAP suspension

On 5/12/2016 11:17 p.m., Silamael wrote:
> Hi,
> 
> We are using the ICAP services of Squid for filtering HTTP-Requests. 
> Now we encountered the problem that a buggy? web application creates 
> requests with an URL with the hostname set to '.'.

Ok.

> These bad requests than cause the suspension of the whole ICAP service 
> which then causes the bypass of the URL filtering as the ICAP service 
> has bypass=yes configured.

These are not exactly bad requests. '.' is a valid URL host segment.
Very much not likely to succeed in todays Internet, but still valid.

In DNS terms it means the root zone server is the origin host. However, there is no requirement that hostnames resolve using DNS. So it may have another meaning if passed to a service that resolves it differently (eg.
the /etc/hosts mapping, or your ICAP service).

There may or may not be bugs in the ICAP service itself handling that weird input. I can't speak for that software.


> This sounds somehow wrong to me, the ICAP service doesn't have a 
> problem, just the HTTP request being forwarded is borken. Therefor is 
> no

The ICAP service appears to be producing URLs without any host segment at all ("") instead of using the input "." or some other value of its choosing.

Strictly speaking Squid should accept that as a URL with no hostname, just like it accepted the odd '.' hostname. That is one of the issues bug 1961 seeks to fix.


> need to suspend the ICAP service at a whole for 30 seconds.
> Am I wrong or is this behavior intended?
> 

AIUI, for installations using bypass=yes the behaviour is expected. That setting is not tied to particular types of error, it simply means the service is optional. *any* HTTP request (even good ones) can bypass.


There is an interoperability issue between Squid and the ICAP service causing the transaction to break down. The proper handling seems to happen after that.


> This are the log messages:
> 2016/11/28 13:30:00 kid1| SECURITY ALERT: Missing hostname in URL 
> 'http:///?_task=mail&_id=xxxxxxxxxxx&_action=display-attachment&_file=rcmfilexxxxxxxxxxxxxxxxxxxxx'.
> see access.log for details.
> 2016/11/28 13:30:00.740 kid1| 0,3| src/base/TextException.cc(87) Throw:
> src/adaptation/icap/ModXact.cc:970:exception:
> adapted.header->parse(&httpBuf, true, &error)
> 2016/11/28 13:30:00.740 kid1| suspending ICAP service for too many 
> failures
> 2016/11/28 13:30:00.740 kid1| optional ICAP service is suspended:
> icap://XXX.XXX.XXX.XXX:1344/reqmod [down,susp,fail11]
> 

IIRC that "fail11" means the service repeatedly failed (11 times) before it got suspended for 30sec. Presumably those were 10 bypasses and one final 'I give up -> suspend' from Squid.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Mon Dec  5 16:28:01 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 5 Dec 2016 18:28:01 +0200
Subject: [squid-users] Bad HTTP requests trigger ICAP suspension
In-Reply-To: <031d01d24f09$25299db0$6f7cd910$@ngtech.co.il>
References: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>
 <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>
 <031d01d24f09$25299db0$6f7cd910$@ngtech.co.il>
Message-ID: <034801d24f14$8c3d3f10$a4b7bd30$@ngtech.co.il>

Sorry a typo.. the dot needs to be escaped..
acl buggyroot dstdom_regex ^\.$
http_access deny buggyroot

Eliezer


----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Monday, December 5, 2016 5:06 PM
To: 'Silamael' <Silamael at coronamundi.de>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Bad HTTP requests trigger ICAP suspension

To resolve this issue quickly I would use a simple squid dstdom regex that reject the request in the first place before passing it to the ICAP service.
The simples is:
acl buggyroot dstdom_regex ^.$

http_access deny buggyroot

Hope it helps to protect the ICAP service.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, December 5, 2016 2:59 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Bad HTTP requests trigger ICAP suspension

On 5/12/2016 11:17 p.m., Silamael wrote:
> Hi,
> 
> We are using the ICAP services of Squid for filtering HTTP-Requests. 
> Now we encountered the problem that a buggy? web application creates 
> requests with an URL with the hostname set to '.'.

Ok.

> These bad requests than cause the suspension of the whole ICAP service 
> which then causes the bypass of the URL filtering as the ICAP service 
> has bypass=yes configured.

These are not exactly bad requests. '.' is a valid URL host segment.
Very much not likely to succeed in todays Internet, but still valid.

In DNS terms it means the root zone server is the origin host. However, there is no requirement that hostnames resolve using DNS. So it may have another meaning if passed to a service that resolves it differently (eg.
the /etc/hosts mapping, or your ICAP service).

There may or may not be bugs in the ICAP service itself handling that weird input. I can't speak for that software.


> This sounds somehow wrong to me, the ICAP service doesn't have a 
> problem, just the HTTP request being forwarded is borken. Therefor is 
> no

The ICAP service appears to be producing URLs without any host segment at all ("") instead of using the input "." or some other value of its choosing.

Strictly speaking Squid should accept that as a URL with no hostname, just like it accepted the odd '.' hostname. That is one of the issues bug 1961 seeks to fix.


> need to suspend the ICAP service at a whole for 30 seconds.
> Am I wrong or is this behavior intended?
> 

AIUI, for installations using bypass=yes the behaviour is expected. That setting is not tied to particular types of error, it simply means the service is optional. *any* HTTP request (even good ones) can bypass.


There is an interoperability issue between Squid and the ICAP service causing the transaction to break down. The proper handling seems to happen after that.


> This are the log messages:
> 2016/11/28 13:30:00 kid1| SECURITY ALERT: Missing hostname in URL 
> 'http:///?_task=mail&_id=xxxxxxxxxxx&_action=display-attachment&_file=rcmfilexxxxxxxxxxxxxxxxxxxxx'.
> see access.log for details.
> 2016/11/28 13:30:00.740 kid1| 0,3| src/base/TextException.cc(87) Throw:
> src/adaptation/icap/ModXact.cc:970:exception:
> adapted.header->parse(&httpBuf, true, &error)
> 2016/11/28 13:30:00.740 kid1| suspending ICAP service for too many 
> failures
> 2016/11/28 13:30:00.740 kid1| optional ICAP service is suspended:
> icap://XXX.XXX.XXX.XXX:1344/reqmod [down,susp,fail11]
> 

IIRC that "fail11" means the service repeatedly failed (11 times) before it got suspended for 30sec. Presumably those were 10 bypasses and one final 'I give up -> suspend' from Squid.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From blaxxton at yahoo.com  Mon Dec  5 17:40:01 2016
From: blaxxton at yahoo.com (Blaxton)
Date: Mon, 5 Dec 2016 17:40:01 +0000 (UTC)
Subject: [squid-users] HTTPS through http proxy
References: <1806958423.6896315.1480959601580.ref@mail.yahoo.com>
Message-ID: <1806958423.6896315.1480959601580@mail.yahoo.com>

Hi?
So I understand that using connect method https connection can pass through http proxybut I am seeing strange behavior and thought some one here might help me to findthe problem we are facing.
I am using simple java app to test https connectivity through http proxy:http://alvinalexander.com/blog/post/java/simple-https-example

If we run below command agains squid running on RedHat:
java -Dhttp.proxyHost=webcache.example.com -Dhttp.proxyPort=808 JavaHttpsExample
connection fails , and Squid log file won't even log any thing in log file.but if we run:java -Dhttps.proxyHost=webcache.example.com -Dhttps.proxyPort=8080 JavaHttpsExampleI get response and a line being recorded in log file.And now running the same app against different squid running on Centos,I get response from both but nothing being logged with -Dhttp.proxyHost.
Please help.If any one has any tips or any simple app to test different aspect of https connectivity through squid please let me know.Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161205/84e6f58c/attachment.htm>

From ricardo.claus at yahoo.com.br  Mon Dec  5 18:28:19 2016
From: ricardo.claus at yahoo.com.br (Ricardo Pardim Claus)
Date: Mon, 5 Dec 2016 18:28:19 +0000 (UTC)
Subject: [squid-users] TCP_MISS/419
References: <1102856376.6186307.1480962499615.ref@mail.yahoo.com>
Message-ID: <1102856376.6186307.1480962499615@mail.yahoo.com>

Dear, 
I ask for help to resolve a connection failure with a particular site. 
See the logs below. Even the log showing DENIED, I do not get denied access message. 
One of the codes below that I did not find in the Squid FAQ is TCP_MISS / 419. Can anyone tell me what this error means? 

What happens: 
When we log in to the site, when accessing features, it simply goes back to the login screen. 
I did a test passing outside the proxy, the problem does not happen. 
I tested on 2 different proxy (Pfsense and Endian). 
Can anybody help me ?


site:  centauroseg.com.br


Squid Cache: Version 3.5.19 


1480959765.502     10 172.16.16.158 TCP_MISS/403 2928 GET http://www3.centauroseg.com.br/centauroonline/ iuser HIER_DIRECT/172.16.16.7 text/html
1480959765.589      3 172.16.16.158 TCP_MISS/403 2920 GET http://www3.centauroseg.com.br/favicon.ico iuser HIER_DIRECT/172.16.16.7 text/html

1480960157.830     30 172.16.16.158 TCP_MISS/403 2888 GET http://centauroseg.com.br/ iuser HIER_DIRECT/172.16.16.7 text/html 
1480960157.848      3 172.16.16.158 TCP_MISS/403 2910 GET http://centauroseg.com.br/favicon.ico iuser HIER_DIRECT/172.16.16.7 text/html 

1480960157.793      0 172.16.16.158 TCP_DENIED/407 4464 GET http://centauroseg.com.br/ - HIER_NONE/- text/html 
1480960157.798      1 172.16.16.158 TCP_DENIED/407 4731 GET http://centauroseg.com.br/ - HIER_NONE/- text/html 



Squid Cache: Version 2.6.STABLE22 


1480958042.688     57 172.16.16.158 TCP_MISS/419 414 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/1B310BA2CF00D106634425C37707A4BD/segurancaRecurso?NomeServico=extratoDetalhado - DIRECT/201.16.246.41 text/html 


1480958427.064      4 172.16.16.158 TCP_OFFLINE_HIT/200 1017 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/login?UsrNome=05011810438502&UsrSenha=Vm1wQmVGRXdNVlZWV0djOQ== - NONE/- application/json 

1480958042.870      0 172.16.16.158 TCP_IMS_HIT/304 351 GET http://www3.centauroseg.com.br/centauroonline/images/favicon.ico - NONE/- image/x-icon 

1480958181.455      0 172.16.16.158 TCP_OFFLINE_HIT/200 1017 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/login?UsrNome=05011810438502&UsrSenha=Vm1wQmVGRXdNVlZWV0djOQ== - NONE/- application/json 


From gergely at egervary.hu  Mon Dec  5 18:34:16 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Mon, 5 Dec 2016 19:34:16 +0100
Subject: [squid-users] IPv6 support for PF interception
Message-ID: <4ef91bbc-bcd0-fd0b-022c-7c2a8bf5dec6@egervary.hu>

Hi,

So, do you want IPv4/IPv6 dual-stacked transparent interception on your
NetBSD box? Unfortunately, you are out of luck.

On NetBSD, we have three choices for packet filtering:

- Darren Reed's "IPFilter". It has known bugs for years, and looks
abandoned.

- OpenBSD's "PF". It's NetBSD port is very outdated, and porting newer
version of PF is abandoned by NetBSD developers. Squid has support for
PF interception for IPv4 only. (Newer OpenBSD PF supports IPv6 with
TPROXY, but TPROXY is not supported by NetBSD version of PF)

- NetBSD's "NPF". It's quite new, and missing features like TPROXY /
divert sockets support, and Squid does not have interception code for
it.

We start working on NPF intercept support, but there's no working code
yet. Until then, I have prepared a very simple patch for Squid -
enabling IPv6 for PF interception. It works for me on my NetBSD 7-STABLE
box.

Please review and test it, especially on OpenBSD and newer PF versions.
If it's approiate, please commit it.

Thank you.

--- Intercept.cc.orig   2016-10-09 21:58:01.000000000 +0200
+++ Intercept.cc        2016-12-02 22:57:24.000000000 +0100
@@ -336,13 +336,20 @@
      }

      memset(&nl, 0, sizeof(struct pfioc_natlook));
-    newConn->remote.getInAddr(nl.saddr.v4);
-    nl.sport = htons(newConn->remote.port());

-    newConn->local.getInAddr(nl.daddr.v4);
+    if (newConn->remote.isIPv6()) {
+        newConn->remote.getInAddr(nl.saddr.v6);
+        newConn->local.getInAddr(nl.daddr.v6);
+        nl.af = AF_INET6;
+    } else {
+        newConn->remote.getInAddr(nl.saddr.v4);
+        newConn->local.getInAddr(nl.daddr.v4);
+        nl.af = AF_INET;
+    }
+
+    nl.sport = htons(newConn->remote.port());
      nl.dport = htons(newConn->local.port());

-    nl.af = AF_INET;
      nl.proto = IPPROTO_TCP;
      nl.direction = PF_OUT;

@@ -358,7 +365,11 @@
          debugs(89, 9, HERE << "address: " << newConn);
          return false;
      } else {
-        newConn->local = nl.rdaddr.v4;
+        if (newConn->remote.isIPv6()) {
+            newConn->local = nl.rdaddr.v6;
+        } else {
+            newConn->local = nl.rdaddr.v4;
+        }
          newConn->local.port(ntohs(nl.rdport));
          debugs(89, 5, HERE << "address NAT: " << newConn);
          return true;


-- 
Gergely EGERVARY


From rousskov at measurement-factory.com  Mon Dec  5 20:11:38 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 5 Dec 2016 13:11:38 -0700
Subject: [squid-users] HTTPS through http proxy
In-Reply-To: <1806958423.6896315.1480959601580@mail.yahoo.com>
References: <1806958423.6896315.1480959601580.ref@mail.yahoo.com>
 <1806958423.6896315.1480959601580@mail.yahoo.com>
Message-ID: <07f1fa27-abc1-53db-e819-75c1addcb62d@measurement-factory.com>

On 12/05/2016 10:40 AM, Blaxton wrote:

> I am using simple java app to test https connectivity through http proxy:
> http://alvinalexander.com/blog/post/java/simple-https-example
> 
> If we run below command agains squid running on RedHat:
> java -Dhttp.proxyHost=webcache.example.com -Dhttp.proxyPort=808
> JavaHttpsExample
> 
> connection fails , and Squid log file won't even log any thing in log file.

If Squid does not listen on port 808 and the IP address(es) that
webcache.example.com resolves to, then what you observe is expected.


> but if we run:
> 
> java -Dhttps.proxyHost=webcache.example.com -Dhttps.proxyPort=8080
> JavaHttpsExample
> 
> I get response and a line being recorded in log file.

If Squid listens on port 8080 and the IP address(es) that
webcache.example.com resolves to, then what you observe is expected.



> And now running the same app against different squid running on Centos,
> I get response from both but nothing being logged with -Dhttp.proxyHost.

If you get a response from Squid and then terminate the connection to
Squid, then Squid should log something to its access.log file. There are
rare exceptions to that rule, but you are very unlikely to hit them with
a modern Squid version in such a simple test.


> If any one has any tips or any simple app to test different aspect of
> https connectivity through squid please let me know.

I recommend the following initial tests:

1. ping the Squid listening IP address from the client box
2. telnet to the Squid listening port from the client box
3. use curl or wget on the client box to pass through Squid
4. Now it is time to test with a browser or some obscure Java app!

The step #2 (telnet) verifies TCP-level connectivity to the Squid
listening port. Typos like 808 instead of 8080 can be caught at this
stage. You should be able to connect to Squid, send some garbage input
in lieu of an encrypted HTTP request, and receive an error response (or
at least a connection termination) from Squid. However, some may
consider this telnet test to be too extreme for the 21st century.

In all these tests, in complex networking setups, you may have to tell
the test app to use the source IP address that the final/intended
application will use. It is usually not necessary though. Similarly,
some low-level tests cannot work in complex setups (e.g., something
between the client and Squid blocks non-SSL traffic), but they usually do.


If you cannot get curl or wget to work, then fiddling with some obscure
Java app is unlikely to speed up the triage. And if you can get them to
work, then you would have a working example to compare the app behavior
with.


If you continue to have problems, please do not forget to specify what
exactly you perceive the problem to be and exactly which logs you have
checked. Attaching Squid access.log entries and packet captures
(captured on the Squid box) often helps as well.


HTH,

Alex.



From sameh.onaissi at solcv.com  Mon Dec  5 22:46:44 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Mon, 5 Dec 2016 22:46:44 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
Message-ID: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>

I have a Ubuntu 16.04 server with Squid 3.5.22 installed. It acts as a gateway in a LAN.

It is configured to intercept HTTP and HTTPS traffic (Transparent). So iptables redirects were used for ports 80 and 443.

The server runs two scripts:
nat.sh to bridge the two network cards, allowing LAN computers access to the internet through the servers Internet interface card.
iptables.sh which defines the ip rules and port forwarding: http://pastebin.com/SqpbmYQQ


BEFORE RUNNING iptables.sh...

When I connect a LAN computer to it, everything works as expected. Complete Internet access with some HTTP and HTTPS domains blocked/redirected to another page. Skype for Business logs in successfully.

AFTER RUNNING iptables.sh
Skype for Business disconnects, and fails to re-connect, normal skype works just fine.


I revised: https://support.office.com/en-us/article/Create-DNS-records-at-eNomCentral-for-Office-365-a6626053-a9c8-445b-81ee-eeb6672fae77?ui=en-US&rs=en-US&ad=US#bkmk_verify And added all DNS configurations on enom.

That got rid of the DNS error I was getting to another error saying service is temporarily unavailable.

Any suggestions to why this is happening? Any solutions?

Note: both router and Ubuntu's WAN interface use Google's 8.8.8.8 DNS

Any help is really appreciated as I have been trying to fix this for days!





[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161205/8d0075c0/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161205/8d0075c0/attachment.jpg>

From sameh.onaissi at solcv.com  Mon Dec  5 23:28:18 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Mon, 5 Dec 2016 23:28:18 +0000
Subject: [squid-users] Skype for Business behind a transparent
	squid	(TProxy) HTTP/S
In-Reply-To: <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
Message-ID: <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>

Hello Eliezer, thank you for the reply.

Honestly, to get things working after several failed attempts to intercept HTTPS, I followed this guide: http://www.cyberscie.com/2015/08/installing-squid-357-as-transparent.html?showComment=1463513043421

My squid.conf is simple: http://pastebin.com/9uZ4kxW6

I have collected a few IPs that skype for business uses, I tried allowing them through IP-tables but it did not work.



[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 5, 2016, at 6:16 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

Hey,

The first suggestion is to find out what servers needs to be in the exceptions from squid interception.
It should be a bunch of IP addresses.
The possibility of skype hosting services to hold unwanted sites or content is slight but not impossible.
You don?t need tproxy on this machine since it is masquerading in any case(just a pointer that will ease your life).

We can try to recognize together what IP addresses are required to be ?bypassed? from squid interception.
And we are missing the squid.conf so we are limited to even know if your setup should work to begin with.

Eliezer

----
Eliezer Croitoru<http://ngtech.co.il/lmgtfy/>
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>
<Picture (Device Independent Bitmap) 1.jpg>

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
Sent: Tuesday, December 6, 2016 12:47 AM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

I have a Ubuntu 16.04 server with Squid 3.5.22 installed. It acts as a gateway in a LAN.
It is configured to intercept HTTP and HTTPS traffic (Transparent). So iptables redirects were used for ports 80 and 443.
The server runs two scripts:
nat.sh to bridge the two network cards, allowing LAN computers access to the internet through the servers Internet interface card.
iptables.sh which defines the ip rules and port forwarding: http://pastebin.com/SqpbmYQQ


BEFORE RUNNING iptables.sh...
When I connect a LAN computer to it, everything works as expected. Complete Internet access with some HTTP and HTTPS domains blocked/redirected to another page. Skype for Business logs in successfully.

AFTER RUNNING iptables.sh
Skype for Business disconnects, and fails to re-connect, normal skype works just fine.

I revised: https://support.office.com/en-us/article/Create-DNS-records-at-eNomCentral-for-Office-365-a6626053-a9c8-445b-81ee-eeb6672fae77?ui=en-US&rs=en-US&ad=US#bkmk_verify<https://support.office.com/en-us/article/Create-DNS-records-at-eNomCentral-for-Office-365-a6626053-a9c8-445b-81ee-eeb6672fae77?ui=en-US&rs=en-US&ad=US> And added all DNS configurations on enom.
That got rid of the DNS error I was getting to another error saying service is temporarily unavailable.
Any suggestions to why this is happening? Any solutions?
Note: both router and Ubuntu's WAN interface use Google's 8.8.8.8 DNS

Any help is really appreciated as I have been trying to fix this for days!




<Picture (Device Independent Bitmap) 2.jpg> Piensa en el medio ambiente antes de imprimir este email.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161205/50e12468/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161205/50e12468/attachment.jpg>

From squid3 at treenet.co.nz  Mon Dec  5 23:35:18 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Dec 2016 12:35:18 +1300
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
Message-ID: <98160ea5-dadb-72fb-6e69-abc3ec0bd69b@treenet.co.nz>

On 6/12/2016 11:46 a.m., Sameh Onaissi wrote:
>
> I have a Ubuntu 16.04 server with Squid 3.5.22 installed. It acts as a 
> gateway in a LAN.
>
> It is configured to intercept HTTP and HTTPS traffic (Transparent). So 
> iptables redirects were used for ports 80 and 443.
> The server runs two scripts:
> _*nat.sh*_ to bridge the two network cards, allowing LAN computers 
> access to the internet through the servers Internet interface card.
> *_iptables.sh_* which defines the ip rules and port forwarding: 
> http://pastebin.com/SqpbmYQQ
>
> BEFORE RUNNING iptables.sh...
>
> When I connect a LAN computer to it, everything works as expected. 
> Complete Internet access with some HTTP and HTTPS domains 
> blocked/redirected to another page. Skype for Business logs in 
> successfully.
>
> AFTER RUNNING iptables.sh
> Skype for Business disconnects, and fails to re-connect, normal skype 
> works just fine.
>
>
> I revised: 
> https://support.office.com/en-us/article/Create-DNS-records-at-eNomCentral-for-Office-365-a6626053-a9c8-445b-81ee-eeb6672fae77?ui=en-US&rs=en-US&ad=US#bkmk_verify And 
> added all DNS configurations on enom.
>
> That got rid of the DNS error I was getting to another error saying 
> service is temporarily unavailable.
>
> Any suggestions to why this is happening? Any solutions?

Skype is sending something that is not HTTPS over port 443. The 
on_unsupported_protocol feature in Squid-4 is needed to tunnel Skype 
traffic when intercepting port 443.

>
> *Note:* both router and Ubuntu's WAN interface use Google's 8.8.8.8 DNS
>

I hope that means the border router is providing DNS recursive lookup 
with 8.8.8.8 as the parent, with LAN devices using that border router as 
their DNS server. That will minimize the damage Google is causing, but 
not avoid it completely. If not you should make it so, or at least place 
another shared resolver somewhere to do the necessary DNS caching.


*Amos

*


From squid3 at treenet.co.nz  Tue Dec  6 00:04:33 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Dec 2016 13:04:33 +1300
Subject: [squid-users] HTTPS through http proxy
In-Reply-To: <1806958423.6896315.1480959601580@mail.yahoo.com>
References: <1806958423.6896315.1480959601580.ref@mail.yahoo.com>
 <1806958423.6896315.1480959601580@mail.yahoo.com>
Message-ID: <28dec4e7-4d3c-6508-889e-189a44471028@treenet.co.nz>



On 6/12/2016 6:40 a.m., Blaxton wrote:
> Hi
>
> So I understand that using connect method https connection can pass 
> through http proxy
> but I am seeing strange behavior and thought some one here might help 
> me to find
> the problem we are facing.
>
> I am using simple java app to test https connectivity through http proxy:
> http://alvinalexander.com/blog/post/java/simple-https-example
>
> If we run below command agains squid running on RedHat:
> java -Dhttp.proxyHost=webcache.example.com -Dhttp.proxyPort=808 
> JavaHttpsExample
> connection fails , and Squid log file won't even log any thing in log 
> file.

That means you either have a very old Squid, or the transaction is not 
completed yet as far as Squid is aware. Transactions only get logged on 
completion, in this case when the CONNECT tunnel connection is closed by 
one of the remove endpoints (client or server). It is not uncommon to 
have tunnels stay open all day with HTTPS traffic going back and forward 
unseen.

The recent Squid releases log failed client connections that did not 
have any HTTP message received. So you can see if the failure happened 
before HTTP happened.

> but if we run:
> java -Dhttps.proxyHost=webcache.example.com -Dhttps.proxyPort=8080 
> JavaHttpsExample
> I get response and a line being recorded in log file.
> And now running the same app against different squid running on Centos,
> I get response from both but nothing being logged with -Dhttp.proxyHost.

see above about logging time.

> Please help.
> If any one has any tips or any simple app to test different aspect of 
> https connectivity through squid please let me know.


You can also use recent squidclient tool if it has been built with 
GnuTLS support. Or curl with debug tracing. Or wireshark with packet 
captures if you know how.

Amos



From sameh.onaissi at solcv.com  Tue Dec  6 00:11:13 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Tue, 6 Dec 2016 00:11:13 +0000
Subject: [squid-users] Skype for Business behind a transparent
	squid	(TProxy) HTTP/S
In-Reply-To: <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
Message-ID: <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>

Hey,


Let me see if I understood that right.

I can change TPROXY to REDIRECT in my iptables.sh and in the ssl-bump replace proxy with intercept.
Then, I can run your bash script after creating domains-to-bypass.txt and putting skype domains in there.
Is that right? or am I missing something?

P.S: Skype for Business uses Lync servers, I do not think skype.com<http://skype.com> is its domain at all.


[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 5, 2016, at 6:54 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

Hey,

Well it?s nice to have such a tutorial but I didn?t followed all of it.
You will want to use REDIRECT in the nat table rather then trroxy.
But if it works now and the only issue is skype then you can try my script at:
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

And maybe you will need to monitor your logs for incoming requests with new ip addresses.
I started working on an external_acl helper that can help in such scenarios which identifies if the destination server might be of skype but I think that most of the information exists at:
https://github.com/vel21ripn/nDPI/blob/netfilter/src/lib/protocols/skype.c
https://github.com/ntop/nDPI/blob/dev/src/lib/protocols/skype.c
And also:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/src/lib/ndpi_content_match.c.inc#L286

Try to see if when you add these ip addresses to bypass it works fine.

Eliezer

----
Eliezer Croitoru<http://ngtech.co.il/lmgtfy/>
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 1:28 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>>
Cc: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Hello Eliezer, thank you for the reply.

Honestly, to get things working after several failed attempts to intercept HTTPS, I followed this guide: http://www.cyberscie.com/2015/08/installing-squid-357-as-transparent.html?showComment=1463513043421

My squid.conf is simple: http://pastebin.com/9uZ4kxW6

I have collected a few IPs that skype for business uses, I tried allowing them through IP-tables but it did not work.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir este email.

On Dec 5, 2016, at 6:16 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

Hey,

The first suggestion is to find out what servers needs to be in the exceptions from squid interception.
It should be a bunch of IP addresses.
The possibility of skype hosting services to hold unwanted sites or content is slight but not impossible.
You don?t need tproxy on this machine since it is masquerading in any case(just a pointer that will ease your life).

We can try to recognize together what IP addresses are required to be ?bypassed? from squid interception.
And we are missing the squid.conf so we are limited to even know if your setup should work to begin with.

Eliezer

----
Eliezer Croitoru<http://ngtech.co.il/lmgtfy/>
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>
<Picture (Device Independent Bitmap) 1.jpg>

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
Sent: Tuesday, December 6, 2016 12:47 AM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

I have a Ubuntu 16.04 server with Squid 3.5.22 installed. It acts as a gateway in a LAN.
It is configured to intercept HTTP and HTTPS traffic (Transparent). So iptables redirects were used for ports 80 and 443.
The server runs two scripts:
nat.sh to bridge the two network cards, allowing LAN computers access to the internet through the servers Internet interface card.
iptables.sh which defines the ip rules and port forwarding: http://pastebin.com/SqpbmYQQ


BEFORE RUNNING iptables.sh...
When I connect a LAN computer to it, everything works as expected. Complete Internet access with some HTTP and HTTPS domains blocked/redirected to another page. Skype for Business logs in successfully.

AFTER RUNNING iptables.sh
Skype for Business disconnects, and fails to re-connect, normal skype works just fine.

I revised: https://support.office.com/en-us/article/Create-DNS-records-at-eNomCentral-for-Office-365-a6626053-a9c8-445b-81ee-eeb6672fae77?ui=en-US&rs=en-US&ad=US#bkmk_verify<https://support.office.com/en-us/article/Create-DNS-records-at-eNomCentral-for-Office-365-a6626053-a9c8-445b-81ee-eeb6672fae77?ui=en-US&rs=en-US&ad=US> And added all DNS configurations on enom.
That got rid of the DNS error I was getting to another error saying service is temporarily unavailable.
Any suggestions to why this is happening? Any solutions?
Note: both router and Ubuntu's WAN interface use Google's 8.8.8.8 DNS

Any help is really appreciated as I have been trying to fix this for days!




<Picture (Device Independent Bitmap) 2.jpg> Piensa en el medio ambiente antes de imprimir este email.





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/cd92df83/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/cd92df83/attachment.jpg>

From squid3 at treenet.co.nz  Tue Dec  6 01:33:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Dec 2016 14:33:13 +1300
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
Message-ID: <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>

On 6/12/2016 1:11 p.m., Sameh Onaissi wrote:
> Hey,
>
>
> Let me see if I understood that right.
>
> I can change TPROXY to REDIRECT in my iptables.sh and in the ssl-bump 
> replace proxy with intercept.

You _can_ but dont have to. It is just an optimization made possible by 
what that machine is doing to TCP traffic.


> Then, I can run your bash script after creating domains-to-bypass.txt 
> and putting skype domains in there.
> Is that right? or am I missing something?
>
> P.S: Skype for Business uses Lync servers, I do not think skype.com 
> <http://skype.com> is its domain at all.

That is likely to be part of the problem. The common tutorials and 
how-tos are based on home Skype versions that are easy for random people 
to get hold of and write about.

Good luck.
Amos



From squid3 at treenet.co.nz  Tue Dec  6 02:25:11 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Dec 2016 15:25:11 +1300
Subject: [squid-users] TCP_MISS/419
In-Reply-To: <1102856376.6186307.1480962499615@mail.yahoo.com>
References: <1102856376.6186307.1480962499615.ref@mail.yahoo.com>
 <1102856376.6186307.1480962499615@mail.yahoo.com>
Message-ID: <aba65398-e9d3-9c51-aaa4-43c89842b3f9@treenet.co.nz>



On 6/12/2016 7:28 a.m., Ricardo Pardim Claus wrote:
> Dear, I ask for help to resolve a connection failure with a particular 
> site. See the logs below. Even the log showing DENIED, I do not get 
> denied access message. One of the codes below that I did not find in 
> the Squid FAQ is TCP_MISS / 419. Can anyone tell me what this error 
> means? 

It is officially an undefined status code. Which means the server 
sending it is doing some custom or experimental thing.

A quick search of the Interwebs shows several meanings, the most common 
being that it is (ab)used by non-HTTP auth mechanisms.

> What happens: When we log in to the site, when accessing features, it 
> simply goes back to the login screen. I did a test passing outside the 
> proxy, the problem does not happen. I tested on 2 different proxy 
> (Pfsense and Endian). 

You used different URLs to test those proxies. So the results are bogus.

Testing properly reveals identical (and correct) handling and log 
entries. And that the origin server is generating the 419. It has 
nothing to do with the proxy.

Amos



From blaxxton at yahoo.com  Tue Dec  6 06:30:09 2016
From: blaxxton at yahoo.com (Blaxton)
Date: Tue, 6 Dec 2016 06:30:09 +0000 (UTC)
Subject: [squid-users] HTTPS through http proxy
In-Reply-To: <28dec4e7-4d3c-6508-889e-189a44471028@treenet.co.nz>
References: <1806958423.6896315.1480959601580.ref@mail.yahoo.com>
 <1806958423.6896315.1480959601580@mail.yahoo.com>
 <28dec4e7-4d3c-6508-889e-189a44471028@treenet.co.nz>
Message-ID: <1940580971.371543.1481005809367@mail.yahoo.com>

Thank you Amos,
version of squid is :?squid-3.3.8-26.el7_2.4.x86_64
Is this statement true:squid is not aware or traffic that is made with connect command ?since connect command make a tunnel within squid ?
passing below argument to JVM:-Dhttps.proxyHost=webcache.example.com -Dhttps.proxyPort=8080cause application connect to https://webcache.exammple.comhowever I have not created any certificate.May I assume squid is built with ssl enabled and both https and http proxybeing provided on one port ?
either above statement is true, or maybe Java has a bug.
Thanks for help, I will check on squidtool.
Thanks

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Monday, December 5, 2016 6:04 PM
 Subject: Re: [squid-users] HTTPS through http proxy
   


On 6/12/2016 6:40 a.m., Blaxton wrote:
> Hi
>
> So I understand that using connect method https connection can pass 
> through http proxy
> but I am seeing strange behavior and thought some one here might help 
> me to find
> the problem we are facing.
>
> I am using simple java app to test https connectivity through http proxy:
> http://alvinalexander.com/blog/post/java/simple-https-example
>
> If we run below command agains squid running on RedHat:
> java -Dhttp.proxyHost=webcache.example.com -Dhttp.proxyPort=808 
> JavaHttpsExample
> connection fails , and Squid log file won't even log any thing in log 
> file.

That means you either have a very old Squid, or the transaction is not 
completed yet as far as Squid is aware. Transactions only get logged on 
completion, in this case when the CONNECT tunnel connection is closed by 
one of the remove endpoints (client or server). It is not uncommon to 
have tunnels stay open all day with HTTPS traffic going back and forward 
unseen.

The recent Squid releases log failed client connections that did not 
have any HTTP message received. So you can see if the failure happened 
before HTTP happened.

> but if we run:
> java -Dhttps.proxyHost=webcache.example.com -Dhttps.proxyPort=8080 
> JavaHttpsExample
> I get response and a line being recorded in log file.
> And now running the same app against different squid running on Centos,
> I get response from both but nothing being logged with -Dhttp.proxyHost.

see above about logging time.

> Please help.
> If any one has any tips or any simple app to test different aspect of 
> https connectivity through squid please let me know.


You can also use recent squidclient tool if it has been built with 
GnuTLS support. Or curl with debug tracing. Or wireshark with packet 
captures if you know how.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/43404099/attachment.htm>

From Silamael at coronamundi.de  Tue Dec  6 08:03:46 2016
From: Silamael at coronamundi.de (Silamael)
Date: Tue, 6 Dec 2016 09:03:46 +0100
Subject: [squid-users] Bad HTTP requests trigger ICAP suspension
In-Reply-To: <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>
References: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>
 <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>
Message-ID: <0aab183e-ca94-59a1-033f-11995d5c2240@coronamundi.de>

On 05.12.2016 13:58, Amos Jeffries wrote:
> On 5/12/2016 11:17 p.m., Silamael wrote:
>> This sounds somehow wrong to me, the ICAP service doesn't have a
>> problem, just the HTTP request being forwarded is borken. Therefor is no
> 
> The ICAP service appears to be producing URLs without any host segment
> at all ("") instead of using the input "." or some other value of its
> choosing.
> 
> Strictly speaking Squid should accept that as a URL with no hostname,
> just like it accepted the odd '.' hostname. That is one of the issues
> bug 1961 seeks to fix.

Hi Amos,

So, you think the URL Squid complains about is returned by our ICAP service?
As far as I understood the log messages, the URL was not sent to the
ICAP service at all.
Or am I wrong here?

>> need to suspend the ICAP service at a whole for 30 seconds.
>> Am I wrong or is this behavior intended?
>>
> 
> AIUI, for installations using bypass=yes the behaviour is expected. That
> setting is not tied to particular types of error, it simply means the
> service is optional. *any* HTTP request (even good ones) can bypass.

Yeah, that's clear. My problem is, that the service is suspended.
If there are real problems within the communication with the ICAP
service, it should be bypassed.

-- Matthias


From Silamael at coronamundi.de  Tue Dec  6 08:05:04 2016
From: Silamael at coronamundi.de (Silamael)
Date: Tue, 6 Dec 2016 09:05:04 +0100
Subject: [squid-users] Bad HTTP requests trigger ICAP suspension
In-Reply-To: <034801d24f14$8c3d3f10$a4b7bd30$@ngtech.co.il>
References: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>
 <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>
 <031d01d24f09$25299db0$6f7cd910$@ngtech.co.il>
 <034801d24f14$8c3d3f10$a4b7bd30$@ngtech.co.il>
Message-ID: <f84390f5-5ed4-d9aa-5dec-8503ea9333b3@coronamundi.de>

On 05.12.2016 17:28, Eliezer Croitoru wrote:
> Sorry a typo.. the dot needs to be escaped..
> acl buggyroot dstdom_regex ^\.$
> http_access deny buggyroot
> 
> Eliezer

Hi Eliezer,

Thanks for the hint. We will block these URLs now before the reach Squid
at all.

-- Matthias


From ricardo.claus at yahoo.com.br  Tue Dec  6 11:01:27 2016
From: ricardo.claus at yahoo.com.br (Ricardo Pardim Claus)
Date: Tue, 6 Dec 2016 11:01:27 +0000 (UTC)
Subject: [squid-users] TCP_MISS/419
In-Reply-To: <1102856376.6186307.1480962499615@mail.yahoo.com>
References: <1102856376.6186307.1480962499615.ref@mail.yahoo.com>
 <1102856376.6186307.1480962499615@mail.yahoo.com>
Message-ID: <37640340.395737.1481022087682@mail.yahoo.com>

Dear Amos, 
Thanks for the initial contact. 

Now I'm getting an error message. 
I placed the domain in the allowed domain list. I still get the access denied message. 
Can you tell me why I'm getting this status code "TCP_MISS / 403", which actually refers to "Forbidden"?

In "Squid Version 3.5.19", I have Squidguard running as well. In the logs I do not see anything that references the site in question. 
In Version 2.6.STABLE22, I have the Dansguardian running.


The following are performed only in Squid Version 3.5.19:

1481019362.202      5 172.16.16.158 TCP_MISS/403 2836 GET http://www3.centauroseg.com.br/centauroonline/ - HIER_DIRECT/172.16.16.7 text/html 
1481019362.221      4 172.16.16.158 TCP_MISS/403 2828 GET http://www3.centauroseg.com.br/favicon.ico - HIER_DIRECT/172.16.16.7 text/html 
1481019364.147      3 172.16.16.158 TCP_MISS/403 2836 GET http://www3.centauroseg.com.br/centauroonline/ - HIER_DIRECT/172.16.16.7 text/html 
1481019364.170      4 172.16.16.158 TCP_MISS/403 2828 GET http://www3.centauroseg.com.br/favicon.ico - HIER_DIRECT/172.16.16.7 text/html 
1481019385.724      4 172.16.16.158 TCP_MISS/403 2836 GET http://www3.centauroseg.com.br/centauroonline/ - HIER_DIRECT/172.16.16.7 text/html 
1481019385.851      3 172.16.16.158 TCP_MISS/403 2828 GET http://www3.centauroseg.com.br/favicon.ico - HIER_DIRECT/172.16.16.7 text/html 
1481019385.857      4 172.16.16.158 TCP_MISS/403 2828 GET http://www3.centauroseg.com.br/favicon.ico - HIER_DIRECT/172.16.16.7 text/html 
1481019394.955      4 172.16.16.158 TCP_MISS/403 2836 GET http://www3.centauroseg.com.br/centauroonline/ - HIER_DIRECT/172.16.16.7 text/html 
1481019394.986      3 172.16.16.158 TCP_MISS/403 2828 GET http://www3.centauroseg.com.br/favicon.ico - HIER_DIRECT/172.16.16.7 text/html 



Squid Cache: Version 2.6.STABLE22 


1481020252.226      0 172.16.16.158 TCP_OFFLINE_HIT/200 1017 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/login?UsrNome=05011810438502&UsrSenha=Vm1wQmVGRXdNVlZWV0djOQ== - NONE/- application/json 
Dec  6 08:30:52 srv05 squid[17957]: 1481020252.226      0 172.16.16.158 TCP_OFFLINE_HIT/200 1017 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/login?UsrNome=05011810438502&UsrSenha=Vm1wQmVGRXdNVlZWV0djOQ== - NONE/- application/json 
1481020252.253     16 172.16.16.158 TCP_OFFLINE_HIT/200 768 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/relacao/permissoes?wUsrCodigo=113 - NONE/- application/json 
Dec  6 08:30:52 srv05 squid[17957]: 1481020252.253     16 172.16.16.158 TCP_OFFLINE_HIT/200 768 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/relacao/permissoes?wUsrCodigo=113 - NONE/- application/json 
1481020252.274     20 172.16.16.158 TCP_OFFLINE_HIT/200 612 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/relacao/nomeUsuarioLogado?TabelaMaster=CADCOMISSIONADOS&CodigoUsuario=45 - NONE/- application/json 
Dec  6 08:30:52 srv05 squid[17957]: 1481020252.274     20 172.16.16.158 TCP_OFFLINE_HIT/200 612 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/relacao/nomeUsuarioLogado?TabelaMaster=CADCOMISSIONADOS&CodigoUsuario=45 - NONE/- application/json 
1481020252.350     19 172.16.16.158 TCP_IMS_HIT/304 351 GET http://www3.centauroseg.com.br/centauroonline/images/linhaAcesso.png - NONE/- image/png 
Dec  6 08:30:52 srv05 squid[17957]: 1481020252.350     19 172.16.16.158 TCP_IMS_HIT/304 351 GET http://www3.centauroseg.com.br/centauroonline/images/linhaAcesso.png - NONE/- image/png 
1481020252.357      6 172.16.16.158 TCP_IMS_HIT/304 352 GET http://www3.centauroseg.com.br/centauroonline/images/acessoCorretor.jpg - NONE/- image/jpeg 
Dec  6 08:30:52 srv05 squid[17957]: 1481020252.357      6 172.16.16.158 TCP_IMS_HIT/304 352 GET http://www3.centauroseg.com.br/centauroonline/images/acessoCorretor.jpg - NONE/- image/jpeg 
1481020252.377     19 172.16.16.158 TCP_IMS_HIT/304 363 GET http://www3.centauroseg.com.br/centauroonline/fonts/Gotham/GothamBlack.woff - NONE/- application/font-woff 
Dec  6 08:30:52 srv05 squid[17957]: 1481020252.377     19 172.16.16.158 TCP_IMS_HIT/304 363 GET http://www3.centauroseg.com.br/centauroonline/fonts/Gotham/GothamBlack.woff - NONE/- application/font-woff 



See the logs when the failure occurs (when accessing the resource within the site, I'm redirected to the login page). 
These logs are version 2.6.STABLE22:


1481020304.245      1 172.16.16.158 TCP_OFFLINE_HIT/200 2901 GET http://www3.centauroseg.com.br/centauroonline/conf/extratosDetalhados.json - NONE/- application/json 
Dec  6 08:31:44 srv05 squid[17957]: 1481020304.245      1 172.16.16.158 TCP_OFFLINE_HIT/200 2901 GET http://www3.centauroseg.com.br/centauroonline/conf/extratosDetalhados.json - NONE/- application/json 
1481020304.352     56 172.16.16.158 TCP_MISS/419 414 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/1B310BA2CF00D106634425C37707A4BD/segurancaRecurso?NomeServico=extratoDetalhado - DIRECT/201.16.246.41 text/html 
Dec  6 08:31:44 srv05 squid[17957]: 1481020304.352     56 172.16.16.158 TCP_MISS/419 414 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/1B310BA2CF00D106634425C37707A4BD/segurancaRecurso?NomeServico=extratoDetalhado - DIRECT/201.16.246.41 text/html 


From squid3 at treenet.co.nz  Tue Dec  6 13:54:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Dec 2016 02:54:24 +1300
Subject: [squid-users] Bad HTTP requests trigger ICAP suspension
In-Reply-To: <0aab183e-ca94-59a1-033f-11995d5c2240@coronamundi.de>
References: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>
 <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>
 <0aab183e-ca94-59a1-033f-11995d5c2240@coronamundi.de>
Message-ID: <1421fdfd-99e5-5a1f-d336-cd054f5919ce@treenet.co.nz>

On 6/12/2016 9:03 p.m., Silamael wrote:
> On 05.12.2016 13:58, Amos Jeffries wrote:
>> On 5/12/2016 11:17 p.m., Silamael wrote:
>>> This sounds somehow wrong to me, the ICAP service doesn't have a
>>> problem, just the HTTP request being forwarded is borken. Therefor is no
>>
>> The ICAP service appears to be producing URLs without any host segment
>> at all ("") instead of using the input "." or some other value of its
>> choosing.
>>
>> Strictly speaking Squid should accept that as a URL with no hostname,
>> just like it accepted the odd '.' hostname. That is one of the issues
>> bug 1961 seeks to fix.
> 
> Hi Amos,
> 
> So, you think the URL Squid complains about is returned by our ICAP service?
> As far as I understood the log messages, the URL was not sent to the
> ICAP service at all.
> Or am I wrong here?

The exception was thrown from the HTTP request parser when handling the
ICAP service response - which was delivering a new HTTP request message
to use instead of the client-provided request message.

Assuming your statement was correct about the input having '.' hostname.
That means the ICAP changed the URL to 'scheme:///path'.


> 
>>> need to suspend the ICAP service at a whole for 30 seconds.
>>> Am I wrong or is this behavior intended?
>>>
>>
>> AIUI, for installations using bypass=yes the behaviour is expected. That
>> setting is not tied to particular types of error, it simply means the
>> service is optional. *any* HTTP request (even good ones) can bypass.
> 
> Yeah, that's clear. My problem is, that the service is suspended.
> If there are real problems within the communication with the ICAP
> service, it should be bypassed.

Nod. I think Eliezers solution with the ACL is the best thing to do
while waiting on the Squid fix to handle that URL type. Maybe even keep
it after that if the ICAP service is not liking the input request either.

Amos



From squid3 at treenet.co.nz  Tue Dec  6 14:05:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Dec 2016 03:05:26 +1300
Subject: [squid-users] HTTPS through http proxy
In-Reply-To: <1940580971.371543.1481005809367@mail.yahoo.com>
References: <1806958423.6896315.1480959601580.ref@mail.yahoo.com>
 <1806958423.6896315.1480959601580@mail.yahoo.com>
 <28dec4e7-4d3c-6508-889e-189a44471028@treenet.co.nz>
 <1940580971.371543.1481005809367@mail.yahoo.com>
Message-ID: <1d5ba5ab-009c-8fdf-0a83-fea5450d849f@treenet.co.nz>

On 6/12/2016 7:30 p.m., Blaxton wrote:
> Thank you Amos,
> version of squid is : squid-3.3.8-26.el7_2.4.x86_64
> Is this statement true:squid is not aware or traffic that is made with connect command ?

"aware of the traffic" is too vague to answer yes or no. Squid is
"aware" that there are bytes going through (ie how many). But it does
not normally look at them to see what they are made of.


> since connect command make a tunnel within squid ?

That assumes that the CONNECT message arrived into Squid. Unless you can
see some things happening in some logs or tracers (ie. system ones) then
you dont know if that stage of the transaction even got reached.

The only thing that is sure is that no tunnel has ended.


> passing below argument to JVM:-Dhttps.proxyHost=webcache.example.com -Dhttps.proxyPort=8080cause application connect to https://webcache.exammple.comhowever I have not created any certificate.

Do not understand what you said.

clients usually dont need certificates to do HTTPS these days (thats
bad, but what we have to work with for now). So that should not matter.


Also, "connect to https://webcache.exammple.com" could mean

1) connecting to webcache.exammple.com with TCP, then
  negotiating TLS

OR it could mean

2) connecting to the proxy, and
  initiating a "CONNECT webcache.exammple.com:443" tunnel, then
  negotiating TLS through that

.. then there is the matter of whats going on inside the TLS:

 i) HTTP/1 (aka "HTTPS")
 ii) WebSockets
 iii) SPDY
 iv) HTTP/2 (aka, "h2", aka "HTTPS")
 v) something unknown.

I don't know what that java tool is or what its doing.


Alex already advised; Use a tool with well known capabilities and
behaviour to do initial testing.

That will save you the time of providing a complete documentation and
behavioural lesson about the java tool you are using. Just so we can say
what its doing right or wrong.


> May I assume squid is built with ssl enabled and both https and http proxybeing provided on one port ?

No, you cant assume.

There are two Transports (TCP or TLS) and two Transfer message syntaxes
(origin or proxy). Squid listening ports can only listen on one
Transport protocol + Transfer syntax pair at a time.

* Port 80 has TCP transport and origin syntax.
* Port 443 has TLS transport and origin syntax.
* Port 3128 has TCP transport + proxy syntax.
* There is no port commonly associated with TLS transport + proxy syntax.


The TCP receiver is called http_port.
The TLS receiver is called https_port. Notice the 's' difference.


CONNECT messages are part of the proxy syntax.

The origin syntax is split into "modes" (accel, intercept, tproxy)
depending on how traffic managed to reach the proxy - which determines
how it can be handled.

So whether the assumption is true or not depends on what you mean by
'https' and by 'proxy being provided'.


Does that clarify enough for you to answer the question yourself?


> either above statement is true, or maybe Java has a bug.
> Thanks for help, I will check on squidtool.
> Thanks
> 

see also Alex response, he listed some others you might be familiar
enough with to use for testing. Along with what you need to test.

[ sorry for the long mail, I'm a bit bored waiting for compiles to
finish :-) ]

Amos



From squid3 at treenet.co.nz  Tue Dec  6 14:22:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Dec 2016 03:22:19 +1300
Subject: [squid-users] TCP_MISS/419
In-Reply-To: <37640340.395737.1481022087682@mail.yahoo.com>
References: <1102856376.6186307.1480962499615.ref@mail.yahoo.com>
 <1102856376.6186307.1480962499615@mail.yahoo.com>
 <37640340.395737.1481022087682@mail.yahoo.com>
Message-ID: <58ee1d77-7cc6-4ead-2a9e-625b136ffd39@treenet.co.nz>

On 7/12/2016 12:01 a.m., Ricardo Pardim Claus wrote:
> Dear Amos, 
> Thanks for the initial contact. 
> 
> Now I'm getting an error message. 
> I placed the domain in the allowed domain list. I still get the access denied message. 
> Can you tell me why I'm getting this status code "TCP_MISS / 403", which actually refers to "Forbidden"?
> 

Because the client was forbidden to access those URLs at that time, in
that way, with the information in the request sent.


> In "Squid Version 3.5.19", I have Squidguard running as well. In the logs I do not see anything that references the site in question. 
> In Version 2.6.STABLE22, I have the Dansguardian running.


So you have a modern proxy with an obsolete traffic filtering plugin,
being compared with an obsolete Squid version chained end-to-end with an
unspecified version of another proxy software product.

What is the point?


> 
> The following are performed only in Squid Version 3.5.19:
> 
> 1481019362.202      5 172.16.16.158 TCP_MISS/403 2836 GET http://www3.centauroseg.com.br/centauroonline/ - HIER_DIRECT/172.16.16.7 text/html 
> 1481019362.221      4 172.16.16.158 TCP_MISS/403 2828 GET http://www3.centauroseg.com.br/favicon.ico - HIER_DIRECT/172.16.16.7 text/html 


The "MISS" part and the HEIR_DIRECT means almost certainly the response
was generated by the server. Though you could have configured that not
to be true.

Lacking any info about your software config (both Squid and everything
else plugged into it [squidguard]) that is the best anyone can say right
now.

The tool at redbot.org tells me there are 200 and 404 responses coming
out of the server now for those URLs.


> 
> Squid Cache: Version 2.6.STABLE22 
> 
> 
> 1481020252.226      0 172.16.16.158 TCP_OFFLINE_HIT/200 1017 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/login?UsrNome=05011810438502&UsrSenha=Vm1wQmVGRXdNVlZWV0djOQ== - NONE/- application/json 
> Dec  6 08:30:52 srv05 squid[17957]: 1481020252.226      0 172.16.16.158 TCP_OFFLINE_HIT/200 1017 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/login?UsrNome=05011810438502&UsrSenha=Vm1wQmVGRXdNVlZWV0djOQ== - NONE/- application/json 
> 1481020252.253     16 172.16.16.158 TCP_OFFLINE_HIT/200 768 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/relacao/permissoes?wUsrCodigo=113 - NONE/- application/json 
> Dec  6 08:30:52 srv05 squid[17957]: 1481020252.253     16 172.16.16.158 TCP_OFFLINE_HIT/200 768 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/relacao/permissoes?wUsrCodigo=113 - NONE/- application/json 
> 1481020252.274     20 172.16.16.158 TCP_OFFLINE_HIT/200 612 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/relacao/nomeUsuarioLogado?TabelaMaster=CADCOMISSIONADOS&CodigoUsuario=45 - NONE/- application/json 
> Dec  6 08:30:52 srv05 squid[17957]: 1481020252.274     20 172.16.16.158 TCP_OFFLINE_HIT/200 612 GET http://www3.centauroseg.com.br/centauroonline/servico/recurso/relacao/nomeUsuarioLogado?TabelaMaster=CADCOMISSIONADOS&CodigoUsuario=45 - NONE/- application/json 
> 1481020252.350     19 172.16.16.158 TCP_IMS_HIT/304 351 GET http://www3.centauroseg.com.br/centauroonline/images/linhaAcesso.png - NONE/- image/png 
> Dec  6 08:30:52 srv05 squid[17957]: 1481020252.350     19 172.16.16.158 TCP_IMS_HIT/304 351 GET http://www3.centauroseg.com.br/centauroonline/images/linhaAcesso.png - NONE/- image/png 
> 1481020252.357      6 172.16.16.158 TCP_IMS_HIT/304 352 GET http://www3.centauroseg.com.br/centauroonline/images/acessoCorretor.jpg - NONE/- image/jpeg 
> Dec  6 08:30:52 srv05 squid[17957]: 1481020252.357      6 172.16.16.158 TCP_IMS_HIT/304 352 GET http://www3.centauroseg.com.br/centauroonline/images/acessoCorretor.jpg - NONE/- image/jpeg 
> 1481020252.377     19 172.16.16.158 TCP_IMS_HIT/304 363 GET http://www3.centauroseg.com.br/centauroonline/fonts/Gotham/GothamBlack.woff - NONE/- application/font-woff 
> Dec  6 08:30:52 srv05 squid[17957]: 1481020252.377     19 172.16.16.158 TCP_IMS_HIT/304 363 GET http://www3.centauroseg.com.br/centauroonline/fonts/Gotham/GothamBlack.woff - NONE/- application/font-woff 
> 

Which if those lines is accessing the favicon.ico file ...

Consider:
"
Grass in springtime is green if you go outside and look at it, but the
sky when looked at through a window is blue.

Do you believe there must be some problem with the window not making the
sky the same color as grass? just because the window exists?
"

The log lines you are posting are all about different things, with no
overlap. Like sky compared to grass - they are simply different things
going on.


The proxy access.log is simply a statement of what happened. It does not
tell anyone the *why*. And nobody can do better than guesswork given
only log entries.


> 
> See the logs when the failure occurs (when accessing the resource within the site, I'm redirected to the login page). 

4xx do not necessarily mean failure. They mean that the server needs the
client to send something different to get the resource at the URL being
requested. The value of the 4xx code and other details in the reply
indicate what needs to change (or may not).
 What you are calling a "redirect" seems to be in fact the payload of
the 419 message.

What you see in the logs appears to be how the website is designed to
operate. *Especially* since there are custom codes involved  The site
server is intentionally sending them. Both the 4xx code and the action
that happens because of that response are being forced by the server.



Squid-2.x is HTTP/1.0 software. It follows the RFC 1945 protocol. 2.6
follows some features of RFC 2616, but mostly not.

Squid-3.x is HTTP/1.1 software. It follows most of RFC 2616 and a few
bits of the new RFC 723x specifications.

Some things of the proxy behaviour is the same. But when the client and
server are both HTTP/1.1 as well the behaviour of 3.x can be very
different to Squid-2.x.


Amos



From creditu at eml.cc  Tue Dec  6 15:05:03 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Tue, 06 Dec 2016 08:05:03 -0700
Subject: [squid-users] Config Recommendations
In-Reply-To: <44308a53-93ef-5c0f-9b5b-778ca9c03c46@treenet.co.nz>
References: <1480898676.1904222.808186633.011C372F@webmail.messagingengine.com>
 <44308a53-93ef-5c0f-9b5b-778ca9c03c46@treenet.co.nz>
Message-ID: <1481036703.3832126.810156545.79014CB9@webmail.messagingengine.com>


On Sun, Dec 4, 2016, at 08:19 PM, Amos Jeffries wrote:
> On 5/12/2016 1:44 p.m., creditu at eml.cc wrote:
> > For a 3.1 accelerator we have put the followinconfig together.  This
> > accelerator will not be doing any caching since we use an external
> > service.  Initially both http and https will be provided.   Some
> > questions:   I think the ordering of statements and acls is correct, but
> > was hoping to get some feedback if possible.  Also, since we  want to
> > turn caching off completely  I was wondering if some of the statements
> > are unnecessary.  Any feedback or recommendations on the overall config
> > would be appreciated.     
> 
> You can remove any options which are setting things to their default
> values.
> 
> Add "cache_mem 0" to prevent the memory cache being allocated.
> And remove the *_replacement_policy lines, they are pointless without
> caching.
> 
> The "cachemgr_passwd none info" line is useless, since the next thing
> done is disabled.
> That also means the "http_access allow manager localhost" line is not
> useful either unless you re-open the info report.
> 
> 
> Amo
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Quick follow up.  When using debug 28,3 does this record
cache_peer_access and deny_info acls in the cache log?  Since I'm using
the same ACL declaration  for both the cache_peer_access and http_access
statements,  in a lot of cases, I just want to make sure I'm
interpreting  the ACL debug information correctly.  

For example:
acl www dstdomain www.example.com
cache_peer 10.10.10.1 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.1 allow www
cache_peer_access 10.10.10.1 deny all

cache_peer 10.10.10.2 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.2 allow www
cache_peer_access 10.10.10.2 deny all
. . . 
http_access allow www

As always, thanks for the help.


From heiler.bemerguy at cinbesa.com.br  Tue Dec  6 15:08:11 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 6 Dec 2016 12:08:11 -0300
Subject: [squid-users] "store-stale" sending original "expires" header may
 be breaking windows update?
Message-ID: <f5cc6534-55b3-a6ef-8b8d-9566c922a9ad@cinbesa.com.br>


Hi folks, what do you think about it?

refresh_pattern -i 
(microsoft|windowsupdate)\.com.*\.(cab|exe|ms[iup]|dat|zip|[ap]sf|appx(bundle)?|esd|crl)$ 
483840 100% 483840 override-expire ignore-reload ignore-no-store store-stale


A request sent to squid:

GET 
http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab 
HTTP/1.1
Accept: */*
User-Agent: Windows-Update-Agent
Proxy-Connection: Keep-Alive
Host: download.windowsupdate.com


squid reply to the user:

HTTP/1.1 200 OK
*Expires: Thu, 17 Nov 2016 18:00:01 GMT*
MSRegion: Latam
Cache-Control: public,max-age=172800
Content-Length: 0
Content-Type: application/vnd.ms-cab-compressed
Last-Modified: Mon, 14 Nov 2016 16:57:44 GMT
Accept-Ranges: bytes
ETag: "0b4d737983ed21:0"
Server: Microsoft-IIS/8.5
X-Powered-By: ASP.NET
X-CID: 7
X-CCC: US
X-MSEdge-Ref: Ref A: A41379B47DAB430595652F948ADA374C Ref B: 
A3C4FE3E5EFF7E01F424A3DC08B40AF5 Ref C: Tue Dec  6 06:44:10 2016 PST
*Date: Tue, 06 Dec 2016 14:44:10 GMT*
X-Cache: MISS from proxycache2
Age: 60080
X-Cache: HIT from proxy
Via: 1.1 proxycache2 (squid), 1.1 proxy (squid)
Connection: keep-alive

So.. it's sending a stale object, but it's saying to the user that the 
object is expired...  is it right? I think windows update is aborting 
this download everytime:
1481035881.814     78 10.11.0.111 TCP_REFRESH_UNMODIFIED_ABORTED/200 
4113 GET 
http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab 
- FIRSTUP_PARENT/127.0.0.1 application/vnd.ms-cab-compressed
1481035885.924    100 10.11.0.111 TCP_REFRESH_UNMODIFIED_ABORTED/200 
4113 GET 
http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab 
- FIRSTUP_PARENT/127.0.0.1 application/vnd.ms-cab-compressed
1481035890.658     86 10.11.0.111 TCP_REFRESH_UNMODIFIED_ABORTED/200 
4113 GET 
http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab 
- FIRSTUP_PARENT/127.0.0.1 application/vnd.ms-cab-compressed
1481035894.940     78 10.11.0.111 TCP_REFRESH_UNMODIFIED_ABORTED/200 
4113 GET 
http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab 
- FIRSTUP_PARENT/127.0.0.1 application/vnd.ms-cab-compressed
1481035899.252    119 10.11.0.111 TCP_REFRESH_UNMODIFIED_ABORTED/200 
12305 GET 
http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab 
- FIRSTUP_PARENT/127.0.0.1 application/vnd.ms-cab-compressed
1481035903.547    132 10.11.0.111 TCP_REFRESH_UNMODIFIED_ABORTED/200 
4113 GET 
http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab 
- FIRSTUP_PARENT/127.0.0.1 application/vnd.ms-cab-compressed


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/4a4fcf51/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec  6 15:30:18 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Dec 2016 04:30:18 +1300
Subject: [squid-users] "store-stale" sending original "expires" header
 may be breaking windows update?
In-Reply-To: <f5cc6534-55b3-a6ef-8b8d-9566c922a9ad@cinbesa.com.br>
References: <f5cc6534-55b3-a6ef-8b8d-9566c922a9ad@cinbesa.com.br>
Message-ID: <c2709d44-f29f-92ea-053e-5ffd9914bcd9@treenet.co.nz>

On 7/12/2016 4:08 a.m., Heiler Bemerguy wrote:
> 
> Hi folks, what do you think about it?
> 
> refresh_pattern -i
> (microsoft|windowsupdate)\.com.*\.(cab|exe|ms[iup]|dat|zip|[ap]sf|appx(bundle)?|esd|crl)$
> 483840 100% 483840 override-expire ignore-reload ignore-no-store
> store-stale
> 
> 
> A request sent to squid:
> 
> GET
> http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab
> HTTP/1.1
> Accept: */*
> User-Agent: Windows-Update-Agent
> Proxy-Connection: Keep-Alive
> Host: download.windowsupdate.com
> 
> 
> squid reply to the user:
> 
> HTTP/1.1 200 OK
> *Expires: Thu, 17 Nov 2016 18:00:01 GMT*
> MSRegion: Latam
> Cache-Control: public,max-age=172800
> Content-Length: 0
> Content-Type: application/vnd.ms-cab-compressed
> Last-Modified: Mon, 14 Nov 2016 16:57:44 GMT
> Accept-Ranges: bytes
> ETag: "0b4d737983ed21:0"
> Server: Microsoft-IIS/8.5
> X-Powered-By: ASP.NET
> X-CID: 7
> X-CCC: US
> X-MSEdge-Ref: Ref A: A41379B47DAB430595652F948ADA374C Ref B:
> A3C4FE3E5EFF7E01F424A3DC08B40AF5 Ref C: Tue Dec  6 06:44:10 2016 PST
> *Date: Tue, 06 Dec 2016 14:44:10 GMT*
> X-Cache: MISS from proxycache2
> Age: 60080
> X-Cache: HIT from proxy
> Via: 1.1 proxycache2 (squid), 1.1 proxy (squid)
> Connection: keep-alive
> 
> So.. it's sending a stale object, but it's saying to the user that the
> object is expired...  is it right? I think windows update is aborting

Worse than that.

-> Last-Modified + Age is not even close to the Date value.

-> The CC:max-age=172800 says it expires at 16 Nov 2016 16:57:44 GMT.

-> Content-Length says it is 0 bytes of data. Yet there are non-zero
amount of object being transferred in your log records.

Something is getting very screwed up in those headers.

What versions of Squid are those two proxies?

Amos



From heiler.bemerguy at cinbesa.com.br  Tue Dec  6 16:03:52 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 6 Dec 2016 13:03:52 -0300
Subject: [squid-users] "store-stale" sending original "expires" header
 may be breaking windows update?
In-Reply-To: <c2709d44-f29f-92ea-053e-5ffd9914bcd9@treenet.co.nz>
References: <f5cc6534-55b3-a6ef-8b8d-9566c922a9ad@cinbesa.com.br>
 <c2709d44-f29f-92ea-053e-5ffd9914bcd9@treenet.co.nz>
Message-ID: <fbc80297-c8ec-f55e-8ca7-00025f733f56@cinbesa.com.br>


Squid Cache: Version 3.5.22-20161115-r14113

it seems removing "ignore-reload" fixed that loop.. but anyway something 
seems to be broken +_+


Em 06/12/2016 12:30, Amos Jeffries escreveu:
> On 7/12/2016 4:08 a.m., Heiler Bemerguy wrote:
>> Hi folks, what do you think about it?
>>
>> refresh_pattern -i
>> (microsoft|windowsupdate)\.com.*\.(cab|exe|ms[iup]|dat|zip|[ap]sf|appx(bundle)?|esd|crl)$
>> 483840 100% 483840 override-expire ignore-reload ignore-no-store
>> store-stale
>>
>>
>> A request sent to squid:
>>
>> GET
>> http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab
>> HTTP/1.1
>> Accept: */*
>> User-Agent: Windows-Update-Agent
>> Proxy-Connection: Keep-Alive
>> Host: download.windowsupdate.com
>>
>>
>> squid reply to the user:
>>
>> HTTP/1.1 200 OK
>> *Expires: Thu, 17 Nov 2016 18:00:01 GMT*
>> MSRegion: Latam
>> Cache-Control: public,max-age=172800
>> Content-Length: 0
>> Content-Type: application/vnd.ms-cab-compressed
>> Last-Modified: Mon, 14 Nov 2016 16:57:44 GMT
>> Accept-Ranges: bytes
>> ETag: "0b4d737983ed21:0"
>> Server: Microsoft-IIS/8.5
>> X-Powered-By: ASP.NET
>> X-CID: 7
>> X-CCC: US
>> X-MSEdge-Ref: Ref A: A41379B47DAB430595652F948ADA374C Ref B:
>> A3C4FE3E5EFF7E01F424A3DC08B40AF5 Ref C: Tue Dec  6 06:44:10 2016 PST
>> *Date: Tue, 06 Dec 2016 14:44:10 GMT*
>> X-Cache: MISS from proxycache2
>> Age: 60080
>> X-Cache: HIT from proxy
>> Via: 1.1 proxycache2 (squid), 1.1 proxy (squid)
>> Connection: keep-alive
>>
>> So.. it's sending a stale object, but it's saying to the user that the
>> object is expired...  is it right? I think windows update is aborting
> Worse than that.
>
> -> Last-Modified + Age is not even close to the Date value.
>
> -> The CC:max-age=172800 says it expires at 16 Nov 2016 16:57:44 GMT.
>
> -> Content-Length says it is 0 bytes of data. Yet there are non-zero
> amount of object being transferred in your log records.
>
> Something is getting very screwed up in those headers.
>
> What versions of Squid are those two proxies?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



From rousskov at measurement-factory.com  Tue Dec  6 16:08:40 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 6 Dec 2016 09:08:40 -0700
Subject: [squid-users] HTTPS through http proxy
In-Reply-To: <1861420251.318740.1481006056444@mail.yahoo.com>
References: <1806958423.6896315.1480959601580.ref@mail.yahoo.com>
 <1806958423.6896315.1480959601580@mail.yahoo.com>
 <07f1fa27-abc1-53db-e819-75c1addcb62d@measurement-factory.com>
 <1861420251.318740.1481006056444@mail.yahoo.com>
Message-ID: <95680214-760e-e9a0-ed89-7d6b69ab3814@measurement-factory.com>

On 12/05/2016 11:34 PM, Blaxton wrote:

> most of our applications are written in Java and I have to test it with
> this small java application to understand our users.

That is step #4. You are missing steps #1-3.

Imagine you are a semi-unconscious emergency room patient complaining of
severe headaches. Do you want the doctors to immediately open up your
skull to see if there is anything wrong with your brain (because your
head is what you are complaining about)? That would be step #4.

Or do you want them to start with taking your temperature and blood
pressure? That would be steps #1-3.


HTH,

Alex.


> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *To:* "squid-users at lists.squid-cache.org"
> <squid-users at lists.squid-cache.org>
> *Cc:* Blaxton <blaxxton at yahoo.com>
> *Sent:* Monday, December 5, 2016 2:11 PM
> *Subject:* Re: [squid-users] HTTPS through http proxy
> 
> I recommend the following initial tests:
> 
> 1. ping the Squid listening IP address from the client box
> 2. telnet to the Squid listening port from the client box
> 3. use curl or wget on the client box to pass through Squid
> 4. Now it is time to test with a browser or some obscure Java app!
> 
> The step #2 (telnet) verifies TCP-level connectivity to the Squid
> listening port. Typos like 808 instead of 8080 can be caught at this
> stage. You should be able to connect to Squid, send some garbage input
> in lieu of an encrypted HTTP request, and receive an error response (or
> at least a connection termination) from Squid. However, some may
> consider this telnet test to be too extreme for the 21st century.
> 
> In all these tests, in complex networking setups, you may have to tell
> the test app to use the source IP address that the final/intended
> application will use. It is usually not necessary though. Similarly,
> some low-level tests cannot work in complex setups (e.g., something
> between the client and Squid blocks non-SSL traffic), but they usually do.
> 
> 
> If you cannot get curl or wget to work, then fiddling with some obscure
> Java app is unlikely to speed up the triage. And if you can get them to
> work, then you would have a working example to compare the app behavior 
> with.
> 
> 
> 
> If you continue to have problems, please do not forget to specify what
> exactly you perceive the problem to be and exactly which logs you have
> checked. Attaching Squid access.log entries and packet captures
> (captured on the Squid box) often helps as well.
> 
> 
> HTH,
> 
> Alex.



From sameh.onaissi at solcv.com  Tue Dec  6 17:29:10 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Tue, 6 Dec 2016 17:29:10 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
Message-ID: <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>

Hello,

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 - ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although solve.com<http://solve.com> is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?



[cid:DA9A1E3F-3876-4EF2-BBA2-D3942A06ACE1 at routerb408e2.com]

Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: sameh.onaissi at solcv.com<mailto:sameh.onaissi at solcv.com>



[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run ?apt-get install ipset?.
And then run the script.

Eliezer

----
Eliezer Croitoru<http://ngtech.co.il/lmgtfy/>
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz>>
Cc: Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>>
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Amos, thanks for the reply.


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh bypass.sh<http://bypass.sh/> + iptables -t mangle -L PREROUTING + grep bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set --match-set bypasspool dst,src -j DIVERT iptables v1.6.0:<http://v1.6.0/> Set bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more information. + ipset create bypasspool hash:ip bypass.sh:<http://bypass.sh/> 10: bypass.sh:<http://bypass.sh/> ipset: not found + read item + echolyncdiscover.solcv.com<http://lyncdiscover.solcv.com/> lyncdiscover.solcv.com<http://lyncdiscover.solcv.com/> + host -4 lyncdiscover.solcv.com<http://lyncdiscover.solcv.com/> + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory + read item + echo webdir0a.online.lync.com<http://webdir0a.online.lync.com/>webdir0a.online.lync.com<http://webdir0a.online.lync.com/> + host -4 webdir0a.online.lync.com<http://webdir0a.online.lync.com/> + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

? this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like:

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz>> wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have messed up somewhere, so I am sticking with mangle/tproxy for now since squid is working with them.

How can I change Eliezer?s script to mangle/tproxy? https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

 iptables -t mangle -L PREROUTING |grep bypasspool
 if [ "$?" -ne "0" ];then

   iptables -t mangle -I 2 PREROUTING \
     -m set --match-set bypasspool dst,src \
     -j DIVERT

 fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.


I am looking at access.log to collect all domains I see heading to skype for business, as well as IPs. My question is, can I add the domains AND IPs into the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/0f24624c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 58.png
Type: image/png
Size: 7419 bytes
Desc: 58.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/0f24624c/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/0f24624c/attachment.jpg>

From pieter at insync.za.net  Tue Dec  6 17:32:03 2016
From: pieter at insync.za.net (Pieter De Wit)
Date: Wed, 7 Dec 2016 06:32:03 +1300
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <98160ea5-dadb-72fb-6e69-abc3ec0bd69b@treenet.co.nz>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <98160ea5-dadb-72fb-6e69-abc3ec0bd69b@treenet.co.nz>
Message-ID: <14FD8AC2-756C-4B39-9CA3-757E95BE4B96@insync.za.net>

If that is the edge server then it will be the audio/video

Sent from my iPhone

> On 6/12/2016, at 12:35, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 6/12/2016 11:46 a.m., Sameh Onaissi wrote:
>> 
>> I have a Ubuntu 16.04 server with Squid 3.5.22 installed. It acts as a gateway in a LAN.
>> 
>> It is configured to intercept HTTP and HTTPS traffic (Transparent). So iptables redirects were used for ports 80 and 443.
>> The server runs two scripts:
>> _*nat.sh*_ to bridge the two network cards, allowing LAN computers access to the internet through the servers Internet interface card.
>> *_iptables.sh_* which defines the ip rules and port forwarding: http://pastebin.com/SqpbmYQQ
>> 
>> BEFORE RUNNING iptables.sh...
>> 
>> When I connect a LAN computer to it, everything works as expected. Complete Internet access with some HTTP and HTTPS domains blocked/redirected to another page. Skype for Business logs in successfully.
>> 
>> AFTER RUNNING iptables.sh
>> Skype for Business disconnects, and fails to re-connect, normal skype works just fine.
>> 
>> 
>> I revised: https://support.office.com/en-us/article/Create-DNS-records-at-eNomCentral-for-Office-365-a6626053-a9c8-445b-81ee-eeb6672fae77?ui=en-US&rs=en-US&ad=US#bkmk_verify And added all DNS configurations on enom.
>> 
>> That got rid of the DNS error I was getting to another error saying service is temporarily unavailable.
>> 
>> Any suggestions to why this is happening? Any solutions?
> 
> Skype is sending something that is not HTTPS over port 443. The on_unsupported_protocol feature in Squid-4 is needed to tunnel Skype traffic when intercepting port 443.
> 
>> 
>> *Note:* both router and Ubuntu's WAN interface use Google's 8.8.8.8 DNS
>> 
> 
> I hope that means the border router is providing DNS recursive lookup with 8.8.8.8 as the parent, with LAN devices using that border router as their DNS server. That will minimize the damage Google is causing, but not avoid it completely. If not you should make it so, or at least place another shared resolver somewhere to do the necessary DNS caching.
> 
> 
> *Amos
> 
> *
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From eliezer at ngtech.co.il  Tue Dec  6 18:27:13 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 6 Dec 2016 20:27:13 +0200
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
Message-ID: <041a01d24fee$5db66150$192323f0$@ngtech.co.il>

Now you can enhance the script by adding manually the ntop skype related networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/src/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15 
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Hello, 

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 - ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:

Hey,
 
Depends on your OS you will need to installthe  ipset package.
Try to run ?apt-get install ipset?.
And then run the script.
 
Eliezer
 
----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>
 
From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S
 
Amos, thanks for the reply. 
 
 
This is getting more confusing.
 
I changed the script to: http://pastebin.com/jLgywstg
 
And I ran it, but I am getting errors:
 
sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set --match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more information. + ipset create bypasspool hash:ip http://bypass.sh/ 10: http://bypass.sh/ ipset: not found + read item + echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4 http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory + read item + echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ + host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory
 
? this goes on the same for all the domains in the text file
 
My iptables is still <http://pastebin.com/SqpbmYQQ>
 
I did not quite understand what you meant by 
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>
 
should I incorporate the bypass script into my iptables.sh script? run iptables first then bypass?
 
 
 
On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like: 
 
acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all
 
 
 
Again, thanks again for your help.
 
 

<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir este email.
 
On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz> wrote:
 
On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have messed up somewhere, so I am sticking with mangle/tproxy for now since squid is working with them.

How can I change Eliezer?s script to mangle/tproxy? https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

 iptables -t mangle -L PREROUTING |grep bypasspool
 if [ "$?" -ne "0" ];then

   iptables -t mangle -I 2 PREROUTING \
     -m set --match-set bypasspool dst,src \
     -j DIVERT

 fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for business, as well as IPs. My question is, can I add the domains AND IPs into the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos
 
 




From sameh.onaissi at solcv.com  Tue Dec  6 19:24:07 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Tue, 6 Dec 2016 19:24:07 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
Message-ID: <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>

Yes please, I would appreciate help with that script.

As I aforementioned, totally new to all this



[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

Now you can enhance the script by adding manually the ntop skype related networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/src/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Hello,

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 - ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run ?apt-get install ipset?.
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Amos, thanks for the reply.


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set --match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more information. + ipset create bypasspool hash:ip http://bypass.sh/ 10: http://bypass.sh/ ipset: not found + read item + echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4 http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory + read item + echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ + host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

? this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like:

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz> wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have messed up somewhere, so I am sticking with mangle/tproxy for now since squid is working with them.

How can I change Eliezer?s script to mangle/tproxy? https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for business, as well as IPs. My question is, can I add the domains AND IPs into the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/49498bd1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/49498bd1/attachment.jpg>

From Silamael at coronamundi.de  Tue Dec  6 19:30:51 2016
From: Silamael at coronamundi.de (Silamael)
Date: Tue, 6 Dec 2016 20:30:51 +0100
Subject: [squid-users] Bad HTTP requests trigger ICAP suspension
In-Reply-To: <1421fdfd-99e5-5a1f-d336-cd054f5919ce@treenet.co.nz>
References: <87c2d95e-87e3-ecd1-cd1e-1058d47d4965@coronamundi.de>
 <036c916d-57d7-58ae-f9cb-b28c7a8e7f4b@treenet.co.nz>
 <0aab183e-ca94-59a1-033f-11995d5c2240@coronamundi.de>
 <1421fdfd-99e5-5a1f-d336-cd054f5919ce@treenet.co.nz>
Message-ID: <c5f21041-bf95-c423-0e36-3ab868bdec4c@coronamundi.de>

On 06.12.2016 14:54, Amos Jeffries wrote:
> 
> The exception was thrown from the HTTP request parser when handling the
> ICAP service response - which was delivering a new HTTP request message
> to use instead of the client-provided request message.
> 
> Assuming your statement was correct about the input having '.' hostname.
> That means the ICAP changed the URL to 'scheme:///path'.

Hi Amos,

Now I got it. And Squid behaves exactly as I expected it.

> Nod. I think Eliezers solution with the ACL is the best thing to do
> while waiting on the Squid fix to handle that URL type. Maybe even keep
> it after that if the ICAP service is not liking the input request either.

That's what we are doing now.

Thanks a lot!

-- Matthias


From peter.goffa at openmailbox.org  Tue Dec  6 20:33:50 2016
From: peter.goffa at openmailbox.org (Peter Goffa)
Date: Tue, 06 Dec 2016 21:33:50 +0100
Subject: [squid-users] SSL Offloading using Squid
Message-ID: <584720AE.1050501@openmailbox.org>

Hello,

I would like to kindly ask you for your help. I need to configure Squid 
for *SSL **O**ffloading* and I am not able to find any comprehensive 
explanation on the web.


Many thanks in advance.

Best regards,

Peter Goffa


From eliezer at ngtech.co.il  Tue Dec  6 21:07:14 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 6 Dec 2016 23:07:14 +0200
Subject: [squid-users] SSL Offloading using Squid
In-Reply-To: <584720AE.1050501@openmailbox.org>
References: <584720AE.1050501@openmailbox.org>
Message-ID: <043001d25004$b82772d0$28765870$@ngtech.co.il>

Hey Peter,

Squid is using standard Libraries such as OpenSSL and GnuTLS.
These are the main tools that squid is using in order to handle SSL.
If these support AES or any other level of SSL offloading(in the session level) then squid would by nature use it.
This is what I know but maybe Alex or other team member can shed more light on the subject then I may anticipate.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Peter Goffa
Sent: Tuesday, December 6, 2016 10:34 PM
To: squid-users at lists.squid-cache.org
Cc: noc at lists.squid-cache.org
Subject: [squid-users] SSL Offloading using Squid

Hello,

I would like to kindly ask you for your help. I need to configure Squid for *SSL **O**ffloading* and I am not able to find any comprehensive explanation on the web.


Many thanks in advance.

Best regards,

Peter Goffa
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Tue Dec  6 21:36:56 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 6 Dec 2016 23:36:56 +0200
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>

Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b

It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Yes please, I would appreciate help with that script.  

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:

Now you can enhance the script by adding manually the ntop skype related networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/src/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15 
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>; mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Hello, 

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 - ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run ?apt-get install ipset?.
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Amos, thanks for the reply. 


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set --match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more information. + ipset create bypasspool hash:ip http://bypass.sh/ 10: http://bypass.sh/ ipset: not found + read item + echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4 http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory + read item + echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ + host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

? this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by 
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like: 

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz> wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have messed up somewhere, so I am sticking with mangle/tproxy for now since squid is working with them.

How can I change Eliezer?s script to mangle/tproxy? https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for business, as well as IPs. My question is, can I add the domains AND IPs into the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos







From ahmed.zaeem at netstream.ps  Tue Dec  6 21:43:36 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 6 Dec 2016 23:43:36 +0200
Subject: [squid-users] for people who suffer from https ssl pump and not
	interested with caching it
Message-ID: <F55065D3-E1BC-4D60-B990-09DF88116608@netstream.ps>

hey squid users .

i want just to share  a small stuff  .

i always see many people suffer from problems of https pump with some websites .

and in the same time i see that they are not interested with caching of https .

so all what they need is they just let HTTP & HTTPS as transparent .

so i just want to share about ?redsocks? tool and using it to catch up https and forward it to other squid  server using ?TCP_connect ? METHOD .

so yes .. u already pump the http without problems.

but if u feel u have headache with ssl pump ?? ? u can use redsocks  and from redsocks forward it to squid again using ?tcp_connect ?


i hope this  is helpful for some .


Kind regards 

Ahmad Alzaeem



From rousskov at measurement-factory.com  Tue Dec  6 21:58:44 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 6 Dec 2016 14:58:44 -0700
Subject: [squid-users] for people who suffer from https ssl pump and not
 interested with caching it
In-Reply-To: <F55065D3-E1BC-4D60-B990-09DF88116608@netstream.ps>
References: <F55065D3-E1BC-4D60-B990-09DF88116608@netstream.ps>
Message-ID: <456fef62-aeb1-3471-2ec4-c4ae48f79d5c@measurement-factory.com>

On 12/06/2016 02:43 PM, --Ahmad-- wrote:

> i always see many people suffer from problems of https pump with some websites .
> and in the same time i see that they are not interested with caching of https .
> so all what they need is they just let HTTP & HTTPS as transparent .
> 
> so i just want to share about ?redsocks? tool and using it to catch up https and forward it to other squid  server using ?TCP_connect ? METHOD .
> 
> u can use redsocks  and from redsocks forward it to squid again using ?tcp_connect ?

If using an external TCP CONNECT wrapper is better than using "ssl_bump
splice all" Squid configuration, then there is some Squid bug that we
need to fix because "ssl_bump splice all" is supposed to generate the
same TCP CONNECT internally, without any wrappers.

AFAIK, most SslBump problems in modern Squids are related to cases where
folks want [a lot] more than just blindly tunnel (and log) all
intercepted HTTPS connections. Many do not care about caching indeed,
but most care about the details of what is being proxied.


Alex.



From sameh.onaissi at solcv.com  Tue Dec  6 22:35:49 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Tue, 6 Dec 2016 22:35:49 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>,
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
Message-ID: <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>


Hello Eliezer and thanks again.


I ran the script with the tproxy argument.


Tried to reconnect skype for business...


After about a 3 min wait, a pop up saying "Skype for Business couldn?t find a skype for business server"  and access log shows:


1481061269.006    400 10.0.0.38 TCP_MISS/200 1068 GET http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28 application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270    667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 - HIER_NONE/- -
1481061269.270    665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770    596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 - HIER_NONE/- -
1481061269.770    594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679    897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 - HIER_NONE/- -
1481061270.679    895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178    841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 - HIER_NONE/- -
1481061272.178    840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713    641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 - HIER_NONE/- -
1481061273.713    640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 - HIER_NONE/- -
1481061273.751   3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 - HIER_NONE/- -
1481061273.751   1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370    371 10.0.0.38 TCP_MISS/200 1068 GET http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210 application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271  74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 - HIER_NONE/- -
1481063278.271  74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143  60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 - HIER_NONE/- -
1481063344.143  60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks


[https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcQfU2bXCBPGhd5da40t2NysagP5_TdzOv6NOC14r3PXrn5b8k8cog]  Piensa en el medio ambiente antes de imprimir este email.
________________________________
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
[https://avatars1.githubusercontent.com/u/1786800?v=3&s=400]<https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b>

bypass squid interception for skype<https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b>
gist.github.com
bypass squid interception for skype




It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Yes please, I would appreciate help with that script.

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:

Now you can enhance the script by adding manually the ntop skype related networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/src/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>; mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Hello,

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 - ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 - ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run ?apt-get install ipset?.
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Amos, thanks for the reply.


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set --match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more information. + ipset create bypasspool hash:ip http://bypass.sh/ 10: http://bypass.sh/ ipset: not found + read item + echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4 http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory + read item + echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ + host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4} + xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

? this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like:

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz> wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have messed up somewhere, so I am sticking with mangle/tproxy for now since squid is working with them.

How can I change Eliezer?s script to mangle/tproxy? https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for business, as well as IPs. My question is, can I add the domains AND IPs into the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161206/f61cf22c/attachment.htm>

From eliezer at ngtech.co.il  Tue Dec  6 23:31:52 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 7 Dec 2016 01:31:52 +0200
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>,
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
Message-ID: <043a01d25018$ec62c9a0$c5285ce0$@ngtech.co.il>

You should try to think about adding more ip addresses\cirds and domains
such as that are in the logs.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>;
squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...?

After about a 3 min wait, a pop up saying "Skype for Business couldn?t find
a skype for business server"??and?access log shows:?

1481061269.006 ? ?400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270 ? ?667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270 ? ?665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770 ? ?596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770 ? ?594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679 ? ?897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679 ? ?895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178 ? ?841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178 ? ?840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713 ? ?641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713 ? ?640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370 ? ?371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271 ?74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271 ?74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143 ?60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143 ?60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

??Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
?
Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b 
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.? 

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15 
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello, 

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398?? 3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296??? 372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685?? 4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:?????? 132.245.0.0 - 132.245.255.255
CIDR:?????????? 132.245.0.0/16
NetName:??????? MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe? ipset package.
Try to run ?apt-get install ipset?.
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply. 


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory


 this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by 
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like: 

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer?s script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

? iptables -t mangle -I 2 PREROUTING \
??? -m set --match-set bypasspool dst,src \
??? -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos







From squid3 at treenet.co.nz  Wed Dec  7 00:25:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Dec 2016 13:25:24 +1300
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
Message-ID: <fa55ff45-4dee-e520-911e-8014e512bd54@treenet.co.nz>

On 7/12/2016 11:35 a.m., Sameh Onaissi wrote:
> 
> a new set showed up...
> 
> what more can we do?
> 
> keep adding ip ranges?

Yes, this choice of approach means constatly keeping an eye out for and
adding ranges as needed.

Amos



From squid3 at treenet.co.nz  Wed Dec  7 00:38:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Dec 2016 13:38:12 +1300
Subject: [squid-users] Config Recommendations
In-Reply-To: <1481036703.3832126.810156545.79014CB9@webmail.messagingengine.com>
References: <1480898676.1904222.808186633.011C372F@webmail.messagingengine.com>
 <44308a53-93ef-5c0f-9b5b-778ca9c03c46@treenet.co.nz>
 <1481036703.3832126.810156545.79014CB9@webmail.messagingengine.com>
Message-ID: <3b7f5b04-0b6f-4b4e-ce40-b6ecc1b27bff@treenet.co.nz>

On 7/12/2016 4:05 a.m., creditu at eml.cc wrote:
> 
> Quick follow up.  When using debug 28,3 does this record
> cache_peer_access and deny_info acls in the cache log?  Since I'm using
> the same ACL declaration  for both the cache_peer_access and http_access
> statements,  in a lot of cases, I just want to make sure I'm
> interpreting  the ACL debug information correctly.
> 

In 3.1 that debug level logs details of ACL tests, regardless of where
that test is used.

Current Squid log the config line being checked at one of those levels.
But IIRC that is not available in 3.1.


> For example:
> acl www dstdomain www.example.com
> cache_peer 10.10.10.1 parent 80 0 no-query no-digest originserver
> round-robin
> cache_peer_access 10.10.10.1 allow www
> cache_peer_access 10.10.10.1 deny all
> 
> cache_peer 10.10.10.2 parent 80 0 no-query no-digest originserver
> round-robin
> cache_peer_access 10.10.10.2 allow www
> cache_peer_access 10.10.10.2 deny all
> . . . 
> http_access allow www
> 

For any given request http_access is checked long before cache_peer_access.

see <http://wiki.squid-cache.org/SquidFaq/OrderIsImportant> about
callout sequence.

Amos



From sameh.onaissi at solcv.com  Wed Dec  7 13:23:43 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 7 Dec 2016 13:23:43 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <043a01d25018$ec62c9a0$c5285ce0$@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <043a01d25018$ec62c9a0$c5285ce0$@ngtech.co.il>
Message-ID: <A1BE1CBC-18FC-43E3-BEC2-561E62A3D73E@solcv.com>

I kept on adding, now the log is showing an ip and domain that are already in the bypass pool.

when I manually define internal and external servers to sipdir.online.lync.com<http://sipdir.online.lync.com>:443
1481069419.028<http://1481069419.028/> 338 10.0.0.38<http://10.0.0.38/> TCP_CLIENT_REFRESH_MISS/200 1067 GET http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28<http://132.245.1.28/> application/vnd.microsoft.rtc.autodiscover+xml<http://vnd.microsoft.rtc.autodiscover+xml/> 1481069419.276<http://1481069419.276/> 588 10.0.0.38<http://10.0.0.38/> TAG_NONE/200 0 CONNECT 132.245.1.28:443<http://132.245.1.28:443/> - HIER_NONE/- - 1481069419.276<http://1481069419.276/> 587 10.0.0.38<http://10.0.0.38/> TCP_TUNNEL/200 5568 CONNECT lyncdiscover.solcv.com:443<http://lyncdiscover.solcv.com:443/> - ORIGINAL_DST/132.245.1.28<http://132.245.1.28/> - 1481069434.817<http://1481069434.817/> 428 10.0.0.38<http://10.0.0.38/> TAG_NONE/200 0 CONNECT 131.253.61.100:443<http://131.253.61.100:443/> - ORIGINAL_DST/131.253.61.100<http://131.253.61.100/> - 1481069435.779<http://1481069435.779/> 665 10.0.0.38<http://10.0.0.38/> TAG_NONE/200 0 CONNECT 65.55.44.108:443<http://65.55.44.108:443/> - ORIGINAL_DST/65.55.44.108<http://65.55.44.108/> - 1481069436.062<http://1481069436.062/> 258 10.0.0.38<http://10.0.0.38/> TAG_NONE/200 0 CONNECT 65.55.44.108:443<http://65.55.44.108:443/> - ORIGINAL_DST/65.55.44.108<http://65.55.44.108/> -


ANOTHER attempt:

1481069703.652<http://1481069703.652/> 450 10.0.0.38<http://10.0.0.38/> TAG_NONE/200 0 CONNECT 143.127.102.40:443<http://143.127.102.40:443/> - ORIGINAL_DST/143.127.102.40<http://143.127.102.40/> - 1481069704.115<http://1481069704.115/> 443 10.0.0.38<http://10.0.0.38/> TAG_NONE/200 0 CONNECT 143.127.102.40:443<http://143.127.102.40:443/> - ORIGINAL_DST/143.127.102.40<http://143.127.102.40/> - 1481069704.581<http://1481069704.581/> 447 10.0.0.38<http://10.0.0.38/> TAG_NONE/200 0 CONNECT 143.127.102.40:443<http://143.127.102.40:443/> - ORIGINAL_DST/143.127.102.40<http://143.127.102.40/> -

Then, when it is automatic:

1481069176.180<http://1481069176.180/> 365 10.0.0.38<http://10.0.0.38/> TCP_MISS/200 1068 GET http://lyncdiscover.solcv.com/? - ORIGINAL_DST/52.112.65.206<http://52.112.65.206/> application/vnd.microsoft.rtc.autodiscover+xml<http://vnd.microsoft.rtc.autodiscover+xml/> 1481069176.792<http://1481069176.792/> 976 10.0.0.38<http://10.0.0.38/> TAG_NONE/200 0 CONNECT 52.112.65.206:443<http://52.112.65.206:443/> - HIER_NONE/- - 1481069176.792<http://1481069176.792/> 975 10.0.0.38<http://10.0.0.38/> TCP_TUNNEL/200 7060 CONNECT lyncdiscover.solcv.com:443<http://lyncdiscover.solcv.com:443/> - ORIGINAL_DST/52.112.65.206<http://52.112.65.206/>




This is surely harder than it should be.

Amos mentioned something about squid 4 handling this better? should I try squid 4? how would the ssl_bumping be any different?

Again, thank you for your help!

[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 6:31 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

You should try to think about adding more ip addresses\cirds and domains
such as that are in the logs.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>;
squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"  and access log shows:

1481061269.006    400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270    667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270    665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770    596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770    594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679    897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679    895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178    841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178    840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713    641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713    640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370    371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271  74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271  74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143  60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143  60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello,

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply.


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like:

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/4c1c5766/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/4c1c5766/attachment.jpg>

From eliezer at ngtech.co.il  Wed Dec  7 14:50:59 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 7 Dec 2016 16:50:59 +0200
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>,
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>;
squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...?

After about a 3 min wait, a pop up saying "Skype for Business couldn?t find
a skype for business server"??and?access log shows:?

1481061269.006 ? ?400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270 ? ?667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270 ? ?665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770 ? ?596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770 ? ?594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679 ? ?897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679 ? ?895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178 ? ?841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178 ? ?840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713 ? ?641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713 ? ?640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370 ? ?371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271 ?74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271 ?74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143 ?60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143 ?60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

??Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
?
Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b 
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.? 

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15 
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello, 

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398?? 3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296??? 372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685?? 4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:?????? 132.245.0.0 - 132.245.255.255
CIDR:?????????? 132.245.0.0/16
NetName:??????? MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe? ipset package.
Try to run ?apt-get install ipset?.
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply. 


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory


 this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by 
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like: 

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer?s script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

? iptables -t mangle -I 2 PREROUTING \
??? -m set --match-set bypasspool dst,src \
??? -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos







From ahmed.zaeem at netstream.ps  Wed Dec  7 14:53:20 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 7 Dec 2016 16:53:20 +0200
Subject: [squid-users] for people who suffer from https ssl pump and not
	interested with caching it
In-Reply-To: <456fef62-aeb1-3471-2ec4-c4ae48f79d5c@measurement-factory.com>
References: <F55065D3-E1BC-4D60-B990-09DF88116608@netstream.ps>
 <456fef62-aeb1-3471-2ec4-c4ae48f79d5c@measurement-factory.com>
Message-ID: <0664EB53-D2A8-4E67-A08B-D4CACD109523@netstream.ps>

yes thats why i posted that and hope that it can help guys .

thanks 
> On Dec 6, 2016, at 11:58 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 12/06/2016 02:43 PM, --Ahmad-- wrote:
> 
>> i always see many people suffer from problems of https pump with some websites .
>> and in the same time i see that they are not interested with caching of https .
>> so all what they need is they just let HTTP & HTTPS as transparent .
>> 
>> so i just want to share about ?redsocks? tool and using it to catch up https and forward it to other squid  server using ?TCP_connect ? METHOD .
>> 
>> u can use redsocks  and from redsocks forward it to squid again using ?tcp_connect ?
> 
> If using an external TCP CONNECT wrapper is better than using "ssl_bump
> splice all" Squid configuration, then there is some Squid bug that we
> need to fix because "ssl_bump splice all" is supposed to generate the
> same TCP CONNECT internally, without any wrappers.
> 
> AFAIK, most SslBump problems in modern Squids are related to cases where
> folks want [a lot] more than just blindly tunnel (and log) all
> intercepted HTTPS connections. Many do not care about caching indeed,
> but most care about the details of what is being proxied.
> 
> 
> Alex.
> 



From sameh.onaissi at solcv.com  Wed Dec  7 15:22:40 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 7 Dec 2016 15:22:40 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
Message-ID: <2DF89710-B0F5-41B7-98CD-D7B6BDD32659@solcv.com>

Still not working and I do not know what to do next.

access.log shows IPs and domains that are supposed to be bypassed already.

Any further instructions are hugely appreciated.



[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 7, 2016, at 9:50 AM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>;
squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"  and access log shows:

1481061269.006    400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270    667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270    665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770    596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770    594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679    897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679    895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178    841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178    840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713    641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713    640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370    371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271  74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271  74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143  60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143  60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello,

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply.


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like:

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/42271fb1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/42271fb1/attachment.jpg>

From rousskov at measurement-factory.com  Wed Dec  7 15:35:36 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 7 Dec 2016 08:35:36 -0700
Subject: [squid-users] for people who suffer from https ssl pump and not
 interested with caching it
In-Reply-To: <0664EB53-D2A8-4E67-A08B-D4CACD109523@netstream.ps>
References: <F55065D3-E1BC-4D60-B990-09DF88116608@netstream.ps>
 <456fef62-aeb1-3471-2ec4-c4ae48f79d5c@measurement-factory.com>
 <0664EB53-D2A8-4E67-A08B-D4CACD109523@netstream.ps>
Message-ID: <08d129fb-5b24-a319-4cce-e54f587e33d2@measurement-factory.com>

On 12/07/2016 07:53 AM, --Ahmad-- wrote:
> yes thats why i posted that and hope that it can help guys .

IMHO, replacing what is supposed to be a working feature with a whole
other product is unlikely to be helpful long-term.

* If "ssl_bump splice all" does not work for an intercepting https_port,
then file or update a bug report (at least).

* If "ssl_bump splice all" works, then your message is more likely to
misdirect and spread FUD than to help those struggling with SslBump.

Alex.



>> On Dec 6, 2016, at 11:58 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>
>> On 12/06/2016 02:43 PM, --Ahmad-- wrote:
>>
>>> i always see many people suffer from problems of https pump with some websites .
>>> and in the same time i see that they are not interested with caching of https .
>>> so all what they need is they just let HTTP & HTTPS as transparent .
>>>
>>> so i just want to share about ?redsocks? tool and using it to catch up https and forward it to other squid  server using ?TCP_connect ? METHOD .
>>>
>>> u can use redsocks  and from redsocks forward it to squid again using ?tcp_connect ?
>>
>> If using an external TCP CONNECT wrapper is better than using "ssl_bump
>> splice all" Squid configuration, then there is some Squid bug that we
>> need to fix because "ssl_bump splice all" is supposed to generate the
>> same TCP CONNECT internally, without any wrappers.
>>
>> AFAIK, most SslBump problems in modern Squids are related to cases where
>> folks want [a lot] more than just blindly tunnel (and log) all
>> intercepted HTTPS connections. Many do not care about caching indeed,
>> but most care about the details of what is being proxied.
>>
>>
>> Alex.



From eliezer at ngtech.co.il  Wed Dec  7 15:58:18 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 7 Dec 2016 17:58:18 +0200
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <2DF89710-B0F5-41B7-98CD-D7B6BDD32659@solcv.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
 <2DF89 710-B0F5-41B7- 98CD-D7B6BDD32659@solcv.com>
Message-ID: <04a601d250a2$b9fa5340$2deef9c0$@ngtech.co.il>

Give us the ?iptables-save? output and also ?ipset list?.
(or what ever was the command of ipset to dump the content of the list).
After this we can understand what is causing this issue.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 5:23 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Still not working and I do not know what to do next. 

access.log shows IPs and domains that are supposed to be bypassed already.

Any further instructions are hugely appreciated.



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 7, 2016, at 9:50 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...?

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"??and?access log shows:?

1481061269.006 ? ?400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270 ? ?667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270 ? ?665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770 ? ?596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770 ? ?594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679 ? ?897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679 ? ?895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178 ? ?841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178 ? ?840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713 ? ?641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713 ? ?640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370 ? ?371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271 ?74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271 ?74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143 ?60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143 ?60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

??Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
?
Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b 
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.? 

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15 
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello, 

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398?? 3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296??? 372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685?? 4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:?????? 132.245.0.0 - 132.245.255.255
CIDR:?????????? 132.245.0.0/16
NetName:??????? MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe? ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply. 


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by 
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like: 

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

? iptables -t mangle -I 2 PREROUTING \
??? -m set --match-set bypasspool dst,src \
??? -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos








From sameh.onaissi at solcv.com  Wed Dec  7 16:08:30 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 7 Dec 2016 16:08:30 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <04a601d250a2$b9fa5340$2deef9c0$@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
 <"2DF89 710-B0F5-41B7-
 98CD-D7B6BDD32659"@solcv.com>,<04a601d250a2$b9fa5340$2deef9c0$@ngtech.co.il>
Message-ID: <DM5PR05MB287511D04A202361B0BE3C88EC850@DM5PR05MB2875.namprd05.prod.outlook.com>

iptables-save:  http://pastebin.com/9JrVANtt


ipset list : http://pastebin.com/wtMtzaQe

[http://pastebin.com/i/facebook.png]<http://pastebin.com/wtMtzaQe>

Name: bypascidrspool Type: hash:net Revision: 6 Header: family inet hashsiz - Pastebin.com<http://pastebin.com/wtMtzaQe>
pastebin.com


[http://pastebin.com/i/facebook.png]<http://pastebin.com/9JrVANtt>

# Generated by iptables-save v1.6.0 on Wed Dec 7 11:03:51 2016 *mangle :PRERO - Pastebin.com<http://pastebin.com/9JrVANtt>
pastebin.com




[https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcQfU2bXCBPGhd5da40t2NysagP5_TdzOv6NOC14r3PXrn5b8k8cog]  Piensa en el medio ambiente antes de imprimir este email.
________________________________
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Wednesday, December 7, 2016 10:58:18 AM
To: Sameh Onaissi
Cc: squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Give us the ?iptables-save? output and also ?ipset list?.
(or what ever was the command of ipset to dump the content of the list).
After this we can understand what is causing this issue.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 5:23 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Still not working and I do not know what to do next.

access.log shows IPs and domains that are supposed to be bypassed already.

Any further instructions are hugely appreciated.



Piensa en el medio ambiente antes de imprimir este email.

On Dec 7, 2016, at 9:50 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"  and access log shows:

1481061269.006    400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270    667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270    665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770    596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770    594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679    897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679    895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178    841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178    840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713    641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713    640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370    371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271  74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271  74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143  60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143  60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello,

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply.


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like:

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/3c36b5dd/attachment.htm>

From eliezer at ngtech.co.il  Wed Dec  7 17:12:19 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 7 Dec 2016 19:12:19 +0200
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <DM5PR05MB287511D04A202361B0BE3C88EC850@DM5PR05MB2875.namprd05.prod.outlook.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
 <"2DF8 9 710-B0F5-41B 7- 98CD-D7B6BDD32659"@solcv.com>,
 <04a601d250a2$b9fa5340$2deef9c0$@ngtech.co.il>
 <DM5PR05MB287511D04A202361B0BE3C88EC850@DM5PR05MB2875.namprd05.prod.outlook.com>
Message-ID: <04aa01d250ad$10fe20e0$32fa62a0$@ngtech.co.il>

Are you sure this setup works?
You have both REDIRECT and TPROXY on the same machine so you need to bypass
for both of these.
Is this iptables-save snapshot after you ran the script?
Also for this to work you will need to use the updated version of the script
at:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b

And run it twice... once with tproxy and the other without tproxy.
After you run the script share the snapshot of "iptables-save" and "ipset
list".
If it can be reproducible here when I will be using SKYPE I would be able to
test it but I believe it should work good enough to minimize the issue.
The above depends only on one thing: NTOP Skype networks identification.
Maybe I have mentioned but there is another script which I wrote that is
more simplified at:
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

But can be adapted to be used against skype known domains.
The next level would be to use some kind of splice rules with an
external_acl helper.
The external_acl helper can receive information from squid about the request
SNI and to verify if the server only serves skype domains or others.
The above is a much more deeper level and I think that the first scripts
should be enough to resolve most of the issues.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 6:09 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

iptables-save: ?http://pastebin.com/9JrVANtt

ipset list :?http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
pastebin.com

http://pastebin.com/9JrVANtt
http://pastebin.com/9JrVANtt
pastebin.com


??Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Wednesday, December 7, 2016 10:58:18 AM
To: Sameh Onaissi
Cc: mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
?
Give us the ?iptables-save? output and also ?ipset list?.
(or what ever was the command of ipset to dump the content of the list).
After this we can understand what is causing this issue.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 5:23 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Still not working and I do not know what to do next. 

access.log shows IPs and domains that are supposed to be bypassed already.

Any further instructions are hugely appreciated.



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 7, 2016, at 9:50 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...?

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"??and?access log shows:?

1481061269.006 ? ?400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270 ? ?667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270 ? ?665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770 ? ?596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770 ? ?594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679 ? ?897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679 ? ?895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178 ? ?841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178 ? ?840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713 ? ?641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713 ? ?640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370 ? ?371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271 ?74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271 ?74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143 ?60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143 ?60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

??Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
?
Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b 
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.? 

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15 
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello, 

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398?? 3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296??? 372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685?? 4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:?????? 132.245.0.0 - 132.245.255.255
CIDR:?????????? 132.245.0.0/16
NetName:??????? MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe? ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply. 


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by 
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like: 

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

? iptables -t mangle -I 2 PREROUTING \
??? -m set --match-set bypasspool dst,src \
??? -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos








From ahmed.zaeem at netstream.ps  Wed Dec  7 18:55:23 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 7 Dec 2016 20:55:23 +0200
Subject: [squid-users] for people who suffer from https ssl pump and not
	interested with caching it
In-Reply-To: <08d129fb-5b24-a319-4cce-e54f587e33d2@measurement-factory.com>
References: <F55065D3-E1BC-4D60-B990-09DF88116608@netstream.ps>
 <456fef62-aeb1-3471-2ec4-c4ae48f79d5c@measurement-factory.com>
 <0664EB53-D2A8-4E67-A08B-D4CACD109523@netstream.ps>
 <08d129fb-5b24-a319-4cce-e54f587e33d2@measurement-factory.com>
Message-ID: <E617837E-8051-43B5-AA27-CA0EDD3080F9@netstream.ps>

bro this is just an option .not an alternative .

thanks 
> On Dec 7, 2016, at 5:35 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> IMHO

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/6b937f96/attachment.htm>

From sameh.onaissi at solcv.com  Wed Dec  7 20:11:06 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 7 Dec 2016 20:11:06 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <04aa01d250ad$10fe20e0$32fa62a0$@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
 <"2DF8 9 710-B0F5-41B	7- 98CD-D7B6BDD32659"@solcv.com>
 <04a601d250a2$b9fa5340$2deef9c0$@ngtech.co.il>
 <DM5PR05MB287511D04A202361B0BE3C88EC850@DM5PR05MB2875.namprd05.prod.outlook.com>
 <04aa01d250ad$10fe20e0$32fa62a0$@ngtech.co.il>
Message-ID: <818EC61B-122E-46DE-86C7-B11CC4D1325D@solcv.com>

iptables is the same.. here is after I ran the script twice (with and without proxy)
http://pastebin.com/YFtbG6St


I have a script that bridges the two network cards, that uses nat, hence having both

I can send you all the scripts I run to set up squid and the bypasses so you can reproduce the situation.

thanks again!



[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 7, 2016, at 12:12 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

Are you sure this setup works?
You have both REDIRECT and TPROXY on the same machine so you need to bypass
for both of these.
Is this iptables-save snapshot after you ran the script?
Also for this to work you will need to use the updated version of the script
at:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b

And run it twice... once with tproxy and the other without tproxy.
After you run the script share the snapshot of "iptables-save" and "ipset
list".
If it can be reproducible here when I will be using SKYPE I would be able to
test it but I believe it should work good enough to minimize the issue.
The above depends only on one thing: NTOP Skype networks identification.
Maybe I have mentioned but there is another script which I wrote that is
more simplified at:
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

But can be adapted to be used against skype known domains.
The next level would be to use some kind of splice rules with an
external_acl helper.
The external_acl helper can receive information from squid about the request
SNI and to verify if the server only serves skype domains or others.
The above is a much more deeper level and I think that the first scripts
should be enough to resolve most of the issues.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 6:09 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

iptables-save:  http://pastebin.com/9JrVANtt

ipset list : http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
pastebin.com

http://pastebin.com/9JrVANtt
http://pastebin.com/9JrVANtt
pastebin.com


  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Wednesday, December 7, 2016 10:58:18 AM
To: Sameh Onaissi
Cc: mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Give us the "iptables-save" output and also "ipset list".
(or what ever was the command of ipset to dump the content of the list).
After this we can understand what is causing this issue.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 5:23 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Still not working and I do not know what to do next.

access.log shows IPs and domains that are supposed to be bypassed already.

Any further instructions are hugely appreciated.



Piensa en el medio ambiente antes de imprimir este email.

On Dec 7, 2016, at 9:50 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"  and access log shows:

1481061269.006    400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270    667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270    665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770    596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770    594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679    897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679    895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178    841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178    840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713    641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713    640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370    371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271  74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271  74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143  60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143  60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello,

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply.


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like:

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/b2468f9e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/b2468f9e/attachment.jpg>

From eliezer at ngtech.co.il  Wed Dec  7 21:18:20 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 7 Dec 2016 23:18:20 +0200
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <818EC61B-122E-46DE-86C7-B11CC4D1325D@solcv.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
 <"2DF8 9 710-B0F5-41 B	7- 98CD-D7B6BDD32659"@solcv.com>
 <04a601d250a2$b9fa5340$2deef9c0$@ngtech.co.il>
 <DM5PR05MB287511D04A202361B0BE3C88EC850@DM5PR05MB2875.namprd05.prod.outlook.com>
 <04aa01d250ad$10fe20e0$32fa62a0$@ngtech.co.il>
 <818EC61B-122E-46DE-86C7-B11CC4D1325D@solcv.com>
Message-ID: <04b301d250cf$6f3089b0$4d919d10$@ngtech.co.il>

Try to load these iptables rues using "iptables-restore < file.txt"
http://pastebin.com/mYsqu8D7

You are either running the script wrongly or my script is wrong.
Is this a trial or a production system?
It seems to me that you need to first test and resolve the iptables and
squid setup and then add my script to it.
What OS are you using?(sorry if I don't remember).

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 10:11 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

iptables is the same.. here is after I ran the script twice (with and
without proxy) 
http://pastebin.com/YFtbG6St


I have a script that bridges the two network cards, that uses nat, hence
having both

I can send you all the scripts I run to set up squid and the bypasses so you
can reproduce the situation.

thanks again!



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 7, 2016, at 12:12 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Are you sure this setup works?
You have both REDIRECT and TPROXY on the same machine so you need to bypass
for both of these.
Is this iptables-save snapshot after you ran the script?
Also for this to work you will need to use the updated version of the script
at:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b

And run it twice... once with tproxy and the other without tproxy.
After you run the script share the snapshot of "iptables-save" and "ipset
list".
If it can be reproducible here when I will be using SKYPE I would be able to
test it but I believe it should work good enough to minimize the issue.
The above depends only on one thing: NTOP Skype networks identification.
Maybe I have mentioned but there is another script which I wrote that is
more simplified at:
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

But can be adapted to be used against skype known domains.
The next level would be to use some kind of splice rules with an
external_acl helper.
The external_acl helper can receive information from squid about the request
SNI and to verify if the server only serves skype domains or others.
The above is a much more deeper level and I think that the first scripts
should be enough to resolve most of the issues.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 6:09 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

iptables-save: ?http://pastebin.com/9JrVANtt

ipset list :?http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
pastebin.com

http://pastebin.com/9JrVANtt
http://pastebin.com/9JrVANtt
pastebin.com


??Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Wednesday, December 7, 2016 10:58:18 AM
To: Sameh Onaissi
Cc: mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
?
Give us the "iptables-save" output and also "ipset list".
(or what ever was the command of ipset to dump the content of the list).
After this we can understand what is causing this issue.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 5:23 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Still not working and I do not know what to do next. 

access.log shows IPs and domains that are supposed to be bypassed already.

Any further instructions are hugely appreciated.



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 7, 2016, at 9:50 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...?

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"??and?access log shows:?

1481061269.006 ? ?400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270 ? ?667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270 ? ?665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770 ? ?596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770 ? ?594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679 ? ?897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679 ? ?895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178 ? ?841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178 ? ?840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713 ? ?641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713 ? ?640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751 ? 1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751 ? 1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370 ? ?371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271 ?74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271 ?74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143 ?60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143 ?60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

??Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
?
Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b 
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.? 

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15 
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello, 

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398?? 3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296??? 372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685?? 4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726????? 0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:?????? 132.245.0.0 - 132.245.255.255
CIDR:?????????? 132.245.0.0/16
NetName:??????? MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe? ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply. 


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by 
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like: 

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

? iptables -t mangle -I 2 PREROUTING \
??? -m set --match-set bypasspool dst,src \
??? -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos









From eliezer at ngtech.co.il  Wed Dec  7 21:43:47 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 7 Dec 2016 23:43:47 +0200
Subject: [squid-users] squid SMP notes
In-Reply-To: <BN6PR17MB114082F5EAE8097B81D0DCABF78F0@BN6PR17MB1140.namprd17.prod.outlook.com>
References: <BN6PR17MB114082F5EAE8097B81D0DCABF78F0@BN6PR17MB1140.namprd17.prod.outlook.com>
Message-ID: <04bb01d250d2$fd62cab0$f8286010$@ngtech.co.il>

May I ask about the purpose of the proxy? Caching or ACL?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of senor
Sent: Thursday, December 1, 2016 8:11 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid SMP notes

It is unclear to me how the more recent 'multiple instance' configuration
compares with that of 'SMP Scaling'. 

Is there a short and sweet description of pros and cons or is the multiple
instance simply the new way? The wiki pages vary in detail of implementation
but don't directly state any advantage of one over the other. Further
confusing me is my need to consider SSL Interception, ssl_crtd helpers and
ecap. To be clear, I'm not looking for configuration help.?Just some advice
on which to pursue so I'm not rethinking the whole thing 6 months down the
road.
Thank you for any help.




From sameh.onaissi at solcv.com  Wed Dec  7 22:50:49 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 7 Dec 2016 22:50:49 +0000
Subject: [squid-users] Skype for Business behind a transparent squid
 (TProxy) HTTP/S
In-Reply-To: <04b301d250cf$6f3089b0$4d919d10$@ngtech.co.il>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
 <"2DF8  9 710-B0F5-41	B	7- 98CD-D7B6BDD32659"@solcv.com>
 <04a601d250a2$b9fa5340$2deef9c0$@ngtech.co.il>
 <DM5PR05MB287511D04A202361B0BE3C88EC850@DM5PR05MB2875.namprd05.prod.outlook.com>
 <04aa01d250ad$10fe20e0$32fa62a0$@ngtech.co.il>
 <818EC61B-122E-46DE-86C7-B11CC4D1325D@solcv.com>
 <04b301d250cf$6f3089b0$4d919d10$@ngtech.co.il>
Message-ID: <09B23917-8A5F-4A50-8A92-88F23BA797B7@solcv.com>

Hello, thank you Eliezer!

We managed to fix the issue, but we created another.

Restoring those iptables gives an error at first: Set bypasidrpool doesn?t exist.
So I ran the scripts (bypass domains and bypass-skye-cird) then restored the iptables you sent me and now I can access Skype for Business.

The new issues now is that no websites load. I do have squidguard installed with some lists of blocked sites that get redirected to an ?access denied? page on a web server. However, after applying those iptables, I can not open any site besides (youtube or a google search) but clicking a search result or going to any site will just give a ERR_CONNECTION_TIMED_OUT


This is a Ubuntu 16.04 server by the way. Squid is not in production, I am testing it.

The server has a functional iRedmail installed on it too.

[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 7, 2016, at 4:18 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

Try to load these iptables rues using "iptables-restore < file.txt"
http://pastebin.com/mYsqu8D7

You are either running the script wrongly or my script is wrong.
Is this a trial or a production system?
It seems to me that you need to first test and resolve the iptables and
squid setup and then add my script to it.
What OS are you using?(sorry if I don't remember).

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 10:11 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

iptables is the same.. here is after I ran the script twice (with and
without proxy)
http://pastebin.com/YFtbG6St


I have a script that bridges the two network cards, that uses nat, hence
having both

I can send you all the scripts I run to set up squid and the bypasses so you
can reproduce the situation.

thanks again!



Piensa en el medio ambiente antes de imprimir este email.

On Dec 7, 2016, at 12:12 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Are you sure this setup works?
You have both REDIRECT and TPROXY on the same machine so you need to bypass
for both of these.
Is this iptables-save snapshot after you ran the script?
Also for this to work you will need to use the updated version of the script
at:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b

And run it twice... once with tproxy and the other without tproxy.
After you run the script share the snapshot of "iptables-save" and "ipset
list".
If it can be reproducible here when I will be using SKYPE I would be able to
test it but I believe it should work good enough to minimize the issue.
The above depends only on one thing: NTOP Skype networks identification.
Maybe I have mentioned but there is another script which I wrote that is
more simplified at:
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

But can be adapted to be used against skype known domains.
The next level would be to use some kind of splice rules with an
external_acl helper.
The external_acl helper can receive information from squid about the request
SNI and to verify if the server only serves skype domains or others.
The above is a much more deeper level and I think that the first scripts
should be enough to resolve most of the issues.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 6:09 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

iptables-save:  http://pastebin.com/9JrVANtt

ipset list : http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
pastebin.com

http://pastebin.com/9JrVANtt
http://pastebin.com/9JrVANtt
pastebin.com


  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Wednesday, December 7, 2016 10:58:18 AM
To: Sameh Onaissi
Cc: mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Give us the "iptables-save" output and also "ipset list".
(or what ever was the command of ipset to dump the content of the list).
After this we can understand what is causing this issue.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 5:23 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Still not working and I do not know what to do next.

access.log shows IPs and domains that are supposed to be bypassed already.

Any further instructions are hugely appreciated.



Piensa en el medio ambiente antes de imprimir este email.

On Dec 7, 2016, at 9:50 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business...

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"  and access log shows:

1481061269.006    400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270    667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270    665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770    596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770    594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679    897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679    895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178    841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178    840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713    641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713    640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370    371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271  74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271  74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143  60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143  60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello,

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email.

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com]
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply.


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like:

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos








-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/c040d18a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161207/c040d18a/attachment.jpg>

From eliezer at ngtech.co.il  Wed Dec  7 23:19:01 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 8 Dec 2016 01:19:01 +0200
Subject: [squid-users] Skype for Business behind a transparent squid
	(TProxy) HTTP/S
In-Reply-To: <09B23917-8A5F-4A50-8A92-88F23BA797B7@solcv.com>
References: <FBFE34BE-67DE-463B-8225-0F1764CFE432@solcv.com>
 <039801d24f4d$9d6e18c0$d84a4a40$@ngtech.co.il>
 <EC5700CF-24AE-4D7A-A4F2-87EFAF512ACD@solcv.com>
 <03b001d24f52$e531bb80$af953280$@ngtech.co.il>
 <556C6486-CCC9-41A5-8C9C-26D6CD18C2D0@solcv.com>
 <f660a931-a8ab-4eee-9b4d-37a8acb45d2b@treenet.co.nz>
 <429471E6-928B-4468-AAAA-3DE33A412FA3@solcv.com>
 <9889fa45-8136-4558-1316-75ea3761be05@treenet.co.nz>
 <026893CF-0C9C-4BAB-B93B-70CDFFB7330D@solcv.com>
 <040c01d24fe3$d1a97580$74fc6080$@ngtech.co.il>
 <9D566DB5-1019-407C-9BFF-D3208BD9A7B9@solcv.com>
 <041a01d24fee$5db66150$192323f0$@ngtech.co.il>
 <22196CEF-B90C-4ADA-AA4B-58A7BAC417C9@solcv.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACCSPtqPUBkRZnM+GT64aynAQAAAAA=@ngtech.co.il>
 <DM5PR05MB2875AB1E07FA28765D7ACAEEEC820@DM5PR05MB2875.namprd05.prod.outlook.com>
 <!&!AAAAAAAAAAAuAAAAAAAAABe2OZkJks5BoPCdPyKEhdMBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAEWIl4bLZeTa6ShV/Ya6BjAQAAAAA=@ngtech.co.il>
 <"2DF8 9 710-B0F5-4 1	B	7- 98CD-D7B6BDD32659"@solcv.com>
 <04a601d250a2$b9fa5340$2deef9c0$@ngtech.co.il>
 <DM5PR05MB287511D04A202361B0BE3C88EC850@DM5PR05MB2875.namprd05.prod.outlook.com>
 <04aa01d250ad$10fe20e0$32fa62a0$@ngtech.co.il>
 <818EC61B-122E-46DE-86C7-B11CC4D1325D@solcv.com>
 <04b301d250cf$6f3089b0$4d919d10$@ngtech.co.il>
 <09B23917-8A5F-4A50-8A92-88F23BA797B7@solcv.com>
Message-ID: <04c901d250e0$4b6c2280$e2446780$@ngtech.co.il>

Now you need to go one step back and reorganize your rules to work in a non tproxy setup but a REDIRECT one.
I can turn on a lab tomorrow to simulate your network but I can only work with regular skype and not for business.

If you want to start configuring squid and iptables from 0 with understanding of what happens I am here for it.
Tomorrow would be a good day to talk to me and see from noon(IST) via irc or SKYPE or phone what can be done in order to help you resolve the issue quick and then allow you to have a learning curve of the subject.
(The above is only if it's a production maintained system and not a hack...)

Eliezer

* Feel free to contact me via the mobile number and if you are not able to reach me once try couple times.

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Thursday, December 8, 2016 12:51 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid (TProxy) HTTP/S

Hello, thank you Eliezer! 

We managed to fix the issue, but we created another.

Restoring those iptables gives an error at first: Set bypasidrpool doesn?t exist.
So I ran the scripts (bypass domains and bypass-skye-cird) then restored the iptables you sent me and now I can access Skype for Business.

The new issues now is that no websites load. I do have squidguard installed with some lists of blocked sites that get redirected to an ?access denied? page on a web server. However, after applying those iptables, I can not open any site besides (youtube or a google search) but clicking a search result or going to any site will just give a ERR_CONNECTION_TIMED_OUT 


This is a Ubuntu 16.04 server by the way. Squid is not in production, I am testing it.


The server has a functional iRedmail installed on it too.

Piensa en el medio ambiente antes de imprimir este email. 

On Dec 7, 2016, at 4:18 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:

Try to load these iptables rues using "iptables-restore < file.txt"
http://pastebin.com/mYsqu8D7

You are either running the script wrongly or my script is wrong.
Is this a trial or a production system?
It seems to me that you need to first test and resolve the iptables and
squid setup and then add my script to it.
What OS are you using?(sorry if I don't remember).

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 10:11 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

iptables is the same.. here is after I ran the script twice (with and
without proxy) 
http://pastebin.com/YFtbG6St


I have a script that bridges the two network cards, that uses nat, hence
having both

I can send you all the scripts I run to set up squid and the bypasses so you
can reproduce the situation.

thanks again!



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 7, 2016, at 12:12 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Are you sure this setup works?
You have both REDIRECT and TPROXY on the same machine so you need to bypass
for both of these.
Is this iptables-save snapshot after you ran the script?
Also for this to work you will need to use the updated version of the script
at:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b

And run it twice... once with tproxy and the other without tproxy.
After you run the script share the snapshot of "iptables-save" and "ipset
list".
If it can be reproducible here when I will be using SKYPE I would be able to
test it but I believe it should work good enough to minimize the issue.
The above depends only on one thing: NTOP Skype networks identification.
Maybe I have mentioned but there is another script which I wrote that is
more simplified at:
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

But can be adapted to be used against skype known domains.
The next level would be to use some kind of splice rules with an
external_acl helper.
The external_acl helper can receive information from squid about the request
SNI and to verify if the server only serves skype domains or others.
The above is a much more deeper level and I think that the first scripts
should be enough to resolve most of the issues.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 6:09 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

iptables-save:  http://pastebin.com/9JrVANtt

ipset list : http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
http://pastebin.com/wtMtzaQe
pastebin.com

http://pastebin.com/9JrVANtt
http://pastebin.com/9JrVANtt
pastebin.com


  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Wednesday, December 7, 2016 10:58:18 AM
To: Sameh Onaissi
Cc: mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
 
Give us the "iptables-save" output and also "ipset list".
(or what ever was the command of ipset to dump the content of the list).
After this we can understand what is causing this issue.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 5:23 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Still not working and I do not know what to do next. 

access.log shows IPs and domains that are supposed to be bypassed already.

Any further instructions are hugely appreciated.



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 7, 2016, at 9:50 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Was there any progress with the script and the issues?

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Wednesday, December 7, 2016 12:36 AM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: 'Amos Jeffries' <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S


Hello Eliezer and thanks again.

I ran the script with the tproxy argument.

Tried to reconnect skype for business... 

After about a 3 min wait, a pop up saying "Skype for Business couldn't find
a skype for business server"  and access log shows: 

1481061269.006    400 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/132.245.1.28
application/vnd.microsoft.rtc.autodiscover+xml
1481061269.270    667 10.0.0.38 TAG_NONE/200 0 CONNECT 132.245.1.28:443 -
HIER_NONE/- -
1481061269.270    665 10.0.0.38 TCP_TUNNEL/200 5568 CONNECT
lyncdiscover.solcv.com:443 - ORIGINAL_DST/132.245.1.28 -
1481061269.770    596 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061269.770    594 10.0.0.38 TCP_TUNNEL/200 6981 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061270.679    897 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061270.679    895 10.0.0.38 TCP_TUNNEL/200 7733 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061272.178    841 10.0.0.38 TAG_NONE/200 0 CONNECT 23.100.120.65:443 -
HIER_NONE/- -
1481061272.178    840 10.0.0.38 TCP_TUNNEL/200 20539 CONNECT
login.microsoftonline.com:443 - ORIGINAL_DST/23.100.120.65 -
1481061273.713    641 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.713    640 10.0.0.38 TCP_TUNNEL/200 8037 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   3054 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   3052 10.0.0.38 TCP_TUNNEL/200 24458 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -
1481061273.751   1544 10.0.0.38 TAG_NONE/200 0 CONNECT 52.112.64.14:443 -
HIER_NONE/- -
1481061273.751   1543 10.0.0.38 TCP_TUNNEL/200 11653 CONNECT
webdir0a.online.lync.com:443 - ORIGINAL_DST/52.112.64.14 -


so I added more ip ranges to the cidr-to-bypass.txt and ran the script again


1481063243.370    371 10.0.0.38 TCP_MISS/200 1068 GET
http://lyncdiscover.solcv.com/? - ORIGINAL_DST/134.170.113.210
application/vnd.microsoft.rtc.autodiscover+xml
1481063278.271  74233 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063278.271  74231 10.0.0.38 TCP_TUNNEL/200 6746 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -
1481063344.143  60720 10.0.0.38 TAG_NONE/200 0 CONNECT 104.208.31.113:443 -
HIER_NONE/- -
1481063344.143  60719 10.0.0.38 TCP_TUNNEL/200 6389 CONNECT
pipe.skype.com:443 - ORIGINAL_DST/104.208.31.113 -

a new set showed up...

what more can we do?

keep adding ip ranges?

thanks

  Piensa en el medio ambiente antes de imprimir este email.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Sent: Tuesday, December 6, 2016 4:36:56 PM
To: Sameh Onaissi
Cc: 'Amos Jeffries'; mailto:squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S 
 
Try the next script:
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b 
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b
gist.github.com
bypass squid interception for skype



It has two modes: regular and tproxy.
In your case you should run the script with:
$ bypass-skype-cidr.sh tproxy

The tproxy flag should do the trick for you.

Let me know if it works for you.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 9:24 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Yes please, I would appreciate help with that script.  

As I aforementioned, totally new to all this



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 1:27 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Now you can enhance the script by adding manually the ntop skype related
networks based on:
https://github.com/ntop/nDPI/blob/d9a2d9a6bd4d476d666d26cb713952760a975d92/s
rc/lib/ndpi_content_match.c.inc#L286

/*
Skype (Microsoft CDN)
157.56.135.64/26, 157.56.185.0/26, 157.56.52.0/26,
157.56.53.128/25, 157.56.198.0/26
157.60.0.0/16, 157.54.0.0/15 
13.107.3.128/32
13.107.3.129/32
111.221.64.0 - 111.221.127.255
91.190.216.0/21 (AS198015 Skype Communications Sarl)
91.190.218.0/24
40.126.129.109/32
65.55.223.0/26
*/

If you need help scripting this let me know.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 7:29 PM
To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Cc: Amos Jeffries <mailto:squid3 at treenet.co.nz>;
mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Hello, 

OK, I added the ssl_bump slice on the skype domains text file
I installed ipset and ran the script.

Now access.log has much less skype related logs:

What is left is:
1481044996.398   3412 10.0.0.11 TAG_NONE/200 0 CONNECT 132.245.1.32:443 -
ORIGINAL_DST/132.245.1.32 -
1481044996.423      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045000.296    372 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045000.325      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html
1481045008.685   4259 10.0.0.11 TAG_NONE/200 0 CONNECT 134.170.113.207:443 -
ORIGINAL_DST/134.170.113.207 -
1481045008.726      0 10.0.0.11 TAG_NONE/400 3998 REGISTER
sip:solcv.comSIP/2.0 - HIER_NONE/- text/html


although http://solve.com is in the text file.

I ran whois on the first IP and got:

NetRange:       132.245.0.0 - 132.245.255.255
CIDR:           132.245.0.0/16
NetName:        MICROSOFT


Same with the 134.170. address. Can we slice that range?





Sameh Onaissi
Ingeniero de Soporte
Sol Cable Visi?n
Cel: 316-3023424
Email: mailto:sameh.onaissi at solcv.com



Piensa en el medio ambiente antes de imprimir este email. 

On Dec 6, 2016, at 12:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

Hey,

Depends on your OS you will need to installthe  ipset package.
Try to run "apt-get install ipset".
And then run the script.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il
<Untitled Attachment 1.jpg>

From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 6, 2016 5:23 PM
To: Amos Jeffries <mailto:squid3 at treenet.co.nz>
Cc: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
Subject: Re: [squid-users] Skype for Business behind a transparent squid
(TProxy) HTTP/S

Amos, thanks for the reply. 


This is getting more confusing.

I changed the script to: http://pastebin.com/jLgywstg

And I ran it, but I am getting errors:

sudo sh http://bypass.sh/ + iptables -t mangle -L PREROUTING + grep
bypasspool + [ 1 -ne 0 ] + iptables -t mangle -I PREROUTING -m set
--match-set bypasspool dst,src -j DIVERT iptables http://v1.6.0/ Set
bypasspool doesn't exist. Try `iptables -h' or 'iptables --help' for more
information. + ipset create bypasspool hash:ip http://bypass.sh/ 10:
http://bypass.sh/ ipset: not found + read item +
echohttp://lyncdiscover.solcv.com/ http://lyncdiscover.solcv.com/ + host -4
http://lyncdiscover.solcv.com/ + grep has address + awk {print $4} + xargs
-l1 ipset add bypasspool xargs: ipset: No such file or directory + read item
+ echo http://webdir0a.online.lync.com/http://webdir0a.online.lync.com/ +
host -4 http://webdir0a.online.lync.com/ + grep has address + awk {print $4}
+ xargs -l1 ipset add bypasspool xargs: ipset: No such file or directory

. this goes on the same for all the domains in the text file

My iptables is still <http://pastebin.com/SqpbmYQQ>

I did not quite understand what you meant by 
You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

should I incorporate the bypass script into my iptables.sh script? run
iptables first then bypass?



On a side note, would adding ssl_bump exceptions to squid.conf do it?
Something like: 

acl skype_domains <path to file>
ssl_bump splice skype_domains
ssl_bump bump all



Again, thanks again for your help.



<Untitled Attachment 2.jpg> Piensa en el medio ambiente antes de imprimir
este email.

On Dec 6, 2016, at 9:50 AM, Amos Jeffries <mailto:squid3 at treenet.co.nz>
wrote:

On 7/12/2016 3:19 a.m., Sameh Onaissi wrote:
Hello,

I tried doing the changes to nat/REDIRECT in iptables.sh and I must have
messed up somewhere, so I am sticking with mangle/tproxy for now since squid
is working with them.

How can I change Eliezer's script to mangle/tproxy?
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Excuse my novice knowledge in iptables.

No worries.

You need to change where iptables attaches the 'bypasspool'. Both the
table/location (-t) and the jump/action (-j).

iptables -t mangle -L PREROUTING |grep bypasspool
if [ "$?" -ne "0" ];then

  iptables -t mangle -I 2 PREROUTING \
    -m set --match-set bypasspool dst,src \
    -j DIVERT

fi

You should test whether -m set or -m socket work faster and put that one
first. My change above places it at line 2 (after -m socket) assuming
your iptables script is still <http://pastebin.com/SqpbmYQQ>

(Your script should do that line adding, not Eliezers - so that you can
be sure the order is always correct).


BTW: you should use iptables-save / iptables-restore instead of a slow
script calling iptables "manually". Those other tools will ensure there
are no gaps in the firewall initialization for nasty traffic to sneak
through.

I am looking at access.log to collect all domains I see heading to skype for
business, as well as IPs. My question is, can I add the domains AND IPs into
the domains-to-bypass.txt that the above script uses?

IIRC you should be able to use domain as the parameter to ipset. But it
will resolve the domain immediately and only add those IPs that it finds
at that time into the pool. Any future changes, or a hidden set of IPs
that rotate in/out will not be listed.

Amos










From frio_cervesa at hotmail.com  Thu Dec  8 08:07:26 2016
From: frio_cervesa at hotmail.com (senor)
Date: Thu, 8 Dec 2016 08:07:26 +0000
Subject: [squid-users] squid SMP notes
In-Reply-To: <04bb01d250d2$fd62cab0$f8286010$@ngtech.co.il>
References: <BN6PR17MB114082F5EAE8097B81D0DCABF78F0@BN6PR17MB1140.namprd17.prod.outlook.com>
 <04bb01d250d2$fd62cab0$f8286010$@ngtech.co.il>
Message-ID: <BN6PR17MB1140F6B35E84C64EB1765FA1F7840@BN6PR17MB1140.namprd17.prod.outlook.com>

On 12/7/2016 13:43, Eliezer Croitoru wrote:
> May I ask about the purpose of the proxy? Caching or ACL?
> 
> Eliezer
> 
> ----
> http://ngtech.co.il/lmgtfy/
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of senor
> Sent: Thursday, December 1, 2016 8:11 AM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] squid SMP notes
> 
> It is unclear to me how the more recent 'multiple instance' configuration
> compares with that of 'SMP Scaling'. 
> 
> Is there a short and sweet description of pros and cons or is the multiple
> instance simply the new way? The wiki pages vary in detail of implementation
> but don't directly state any advantage of one over the other. Further
> confusing me is my need to consider SSL Interception, ssl_crtd helpers and
> ecap. To be clear, I'm not looking for configuration help. Just some advice
> on which to pursue so I'm not rethinking the whole thing 6 months down the
> road.
> Thank you for any help.
> 
> 
A combination of ACL, eCAP and caching is my goal. At the moment I'm
trying to make sense out of the statistics so I have metrics to guide
me. So now it's just a matter of comparing the various possible
configurations.

Is there a tool or option to log statistics in machine readable format?
SNMP doesn't expose as much as I'd like and cachemgr output needs to be
gawked down to something like a csv file but still account for kids?

Also, is ssl_crtd disk DB ok to share among workers or do they each need
their own? I just realized I forgot to give the workers their own DB but
it seems to be working. Although not under load.

I really appreciate the help.


From rousskov at measurement-factory.com  Thu Dec  8 15:26:10 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Dec 2016 08:26:10 -0700
Subject: [squid-users] squid SMP notes
In-Reply-To: <BN6PR17MB1140F6B35E84C64EB1765FA1F7840@BN6PR17MB1140.namprd17.prod.outlook.com>
References: <BN6PR17MB114082F5EAE8097B81D0DCABF78F0@BN6PR17MB1140.namprd17.prod.outlook.com>
 <04bb01d250d2$fd62cab0$f8286010$@ngtech.co.il>
 <BN6PR17MB1140F6B35E84C64EB1765FA1F7840@BN6PR17MB1140.namprd17.prod.outlook.com>
Message-ID: <2608104c-9cc5-6b91-818f-7c669d51a552@measurement-factory.com>

On 12/08/2016 01:07 AM, senor wrote:
> is ssl_crtd disk DB ok to share among workers

Yes, certificate generators support database sharing.

Alex.



From gregs at net-virtual.com  Thu Dec  8 16:15:41 2016
From: gregs at net-virtual.com (Greg Saylor)
Date: Thu, 8 Dec 2016 10:15:41 -0600
Subject: [squid-users] SSL bump config or possible code issue
Message-ID: <6348944B-9964-49FD-8FB5-F744842C3275@net-virtual.com>

Hello,

This is my first time looking at the squid code. I'm trying to debug a situation where squid 3.4 would return a ERR_ACCESS_DENIED and version 3.5 does not. I believe its somehow related to ssl peek/slice/bump, but being new to Squid I can't really understand that too well.

So squid is configured with:

configure options:  '--prefix=/usr' '--includedir=/usr/include' '--datadir=/usr/share' '--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid' '--localstatedir=/var' '--sysconfdir=/etc/squid' '--with-logdir=/var/log/squid' '--with-openssl' '--enable-linux-netfilter' '--enable-ssl' '--enable-icap-client?

Here?s the http_access rules which exhibit this behavior:


acl socialnetworks dstdomain .facebook.com

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

acl SSL_ports port 443 8443
acl Safe_ports port 80          # http
acl Safe_ports port 443         # https
acl Safe_ports port 8443         # https
acl Safe_ports port 3128        # squid
acl CONNECT method CONNECT

http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

http_access allow socialnetworks

icp_access deny all
icp_port 4130


Now in socat setup a proxy like so:

socat TCP-LISTEN:8080,fork "SSL,verify=0 | PROXY-CONNECT:www.facebook.com:443 | TCP:{squid host}:4130"


Then make a request to port 8080 which sets (which is some https service on localnet):

Host: 172.16.0.10:443

Then try one that is not running https:

Host: 172.16.0.11:443

You will see that in 3.5 172.16.0.10 responds with the response, 172.16.0.11 times out.  The 3.4 behavior was that both of these hosts would result in a ERR_ACCESS_DENIED.


So, I started looking at the source code between 3.4 and 3.5. In 3.5 there is this code in src/client_side_request.cc.

    if (calloutContext->error) {
        const char *storeUri = request->storeId();
        StoreEntry *e= storeCreateEntry(storeUri, storeUri, request->flags, request->method);
#if USE_OPENSSL
        if (sslBumpNeeded()) { 
            // We have to serve an error, so bump the client first.
            sslBumpNeed(Ssl::bumpClientFirst);
            // set final error but delay sending until we bump 
            Ssl::ServerBump *srvBump = new Ssl::ServerBump(request, e);
            errorAppendEntry(e, calloutContext->error);
            calloutContext->error = NULL; 
            getConn()->setServerBump(srvBump);
            e->unlock("ClientHttpRequest::doCallouts+sslBumpNeeded");
        } else  
#endif
        {       
            // send the error to the client now
            clientStreamNode *node = (clientStreamNode *)client_stream.tail->prev->data;
            clientReplyContext *repContext = dynamic_cast<clientReplyContext *>(node->data.getRaw());
            assert (repContext);
            repContext->setReplyToStoreEntry(e, "immediate SslBump error");
            errorAppendEntry(e, calloutContext->error);
            calloutContext->error = NULL; 
            if (calloutContext->readNextRequest && getConn())
                getConn()->flags.readMore = true; // resume any pipeline reads.
            node = (clientStreamNode *)client_stream.tail->data;
            clientStreamRead(node, this, node->readBuffer);
            e->unlock("ClientHttpRequest::doCallouts-sslBumpNeeded");
            return; 
        }       
    }


If I change:

if (sslBumpNeeded()) {

to:

if (sslBumpNeeded() && 0) {

Then it correctly responds with ERR_ACCESS_DENIED. Otherwise it seems to proceed along and actually process and return the request.

I sincerely apologize for not, yet, being able to get my head around this new feature. But, it does seem like somehow calloutContext->error is getting lost or overridden by something else later in the processing chain.

It looks to me as if something is taking precedence over calloutContext->error.  But even if it was not, because the request is actually being processed it would allow a security hole where an attacker could map a private internal network of https services based on the time it takes them to respond - even if it allowed the connection.

Again, my apologies for the lack of detail.  This is my first time working with squid since late 1990?s, its obviously come a very long way since then.


Any ideas?

Regards,

Greg Saylor



From rousskov at measurement-factory.com  Thu Dec  8 16:41:31 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Dec 2016 09:41:31 -0700
Subject: [squid-users] SSL bump config or possible code issue
In-Reply-To: <6348944B-9964-49FD-8FB5-F744842C3275@net-virtual.com>
References: <6348944B-9964-49FD-8FB5-F744842C3275@net-virtual.com>
Message-ID: <7ec470d6-49fb-b08f-55e4-0002c73be1ab@measurement-factory.com>

On 12/08/2016 09:15 AM, Greg Saylor wrote:

> I'm trying to debug a situation where squid 3.4 would return a ERR_ACCESS_DENIED and version 3.5 does not.

I trust you use Squid v3.5.22 or later. Some v3.5 releases have serious
SslBump bugs so the minor version is important.


> I started looking at the source code between 3.4 and 3.5. In 3.5 there is this code in src/client_side_request.cc.
> 
>         if (sslBumpNeeded()) { 
>             // We have to serve an error, so bump the client first.
>             sslBumpNeed(Ssl::bumpClientFirst);
>             // set final error but delay sending until we bump 
...
>         } else  
>             // send the error to the client now


> If I change:
> 
> if (sslBumpNeeded()) {
> 
> to:
> 
> if (sslBumpNeeded() && 0) {
> 
> Then it correctly responds with ERR_ACCESS_DENIED.


Do you enable SslBump features in your Squid?

* If you did not enable SslBump and sslBumpNeeded() returns true, then
this is a Squid bug. If you can reproduce with the latest Squid v3.5 (or
later), please file a bug report.

* If you enabled SslBump, then Squid tries to bump the client connection
to serve the error message to the HTTPS client (because popular browsers
ignore errors delivered as CONNECT responses). I do not recall whether
Squid v3.4 did that, but that is pretty much irrelevant because v3.5
behavior is deliberate (that behavior may need more configuration
options, but that is unrelated to v3.4 anyway). There may be bugs with
that code path, but they are not related to the sslBumpNeeded() result
as such.


> It looks to me as if something is taking precedence over
> calloutContext->error.  But even if it was not, because the request
> is actually being processed it would allow a security hole where an
> attacker could map a private internal network of https services based
> on the time it takes them to respond - even if it allowed the
> connection.

Agreed. If you are using SslBump, then, as the next step, I recommend
ignoring Squid code and clearly demonstrating that Squid forwards a
request that should be denied. A packet trace or Squid's HTTP request
printouts would be helpful for those of us who do not know what exactly
that "socat" command does in your environment, and what Squid does when
processing that traffic.

Alex.



From eliezer at ngtech.co.il  Thu Dec  8 20:26:00 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 8 Dec 2016 22:26:00 +0200
Subject: [squid-users] "store-stale" sending original "expires" header
	may be breaking windows update?
In-Reply-To: <fbc80297-c8ec-f55e-8ca7-00025f733f56@cinbesa.com.br>
References: <f5cc6534-55b3-a6ef-8b8d-9566c922a9ad@cinbesa.com.br>
 <c2709d44-f29f-92ea-053e-5ffd9914bcd9@treenet.co.nz>
 <fbc80297-c8ec-f55e-8ca7-00025f733f56@cinbesa.com.br>
Message-ID: <006601d25191$4a49bd20$dedd3760$@ngtech.co.il>

Is it a TPROXY or INTERCEPT proxy or a simple proxy defined in the OS?
If it's not such a big network and not in TPROXY mode(can be used in this case also but not recommended) you can try to peek at:
http://www1.ngtech.co.il/wpe/?page_id=301

But if plain squid works for you then simply use squid.

Hope it Helps,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Heiler Bemerguy
Sent: Tuesday, December 6, 2016 6:04 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] "store-stale" sending original "expires" header may be breaking windows update?


Squid Cache: Version 3.5.22-20161115-r14113

it seems removing "ignore-reload" fixed that loop.. but anyway something seems to be broken +_+


Em 06/12/2016 12:30, Amos Jeffries escreveu:
> On 7/12/2016 4:08 a.m., Heiler Bemerguy wrote:
>> Hi folks, what do you think about it?
>>
>> refresh_pattern -i
>> (microsoft|windowsupdate)\.com.*\.(cab|exe|ms[iup]|dat|zip|[ap]sf|appx(bundle)?|esd|crl)$
>> 483840 100% 483840 override-expire ignore-reload ignore-no-store
>> store-stale
>>
>>
>> A request sent to squid:
>>
>> GET
>> http://download.windowsupdate.com/d/msdownload/update/others/2016/11/23135907_62c440827e79f4ebcb1babac054468802f1be1cd.cab
>> HTTP/1.1
>> Accept: */*
>> User-Agent: Windows-Update-Agent
>> Proxy-Connection: Keep-Alive
>> Host: download.windowsupdate.com
>>
>>
>> squid reply to the user:
>>
>> HTTP/1.1 200 OK
>> *Expires: Thu, 17 Nov 2016 18:00:01 GMT*
>> MSRegion: Latam
>> Cache-Control: public,max-age=172800
>> Content-Length: 0
>> Content-Type: application/vnd.ms-cab-compressed
>> Last-Modified: Mon, 14 Nov 2016 16:57:44 GMT
>> Accept-Ranges: bytes
>> ETag: "0b4d737983ed21:0"
>> Server: Microsoft-IIS/8.5
>> X-Powered-By: ASP.NET
>> X-CID: 7
>> X-CCC: US
>> X-MSEdge-Ref: Ref A: A41379B47DAB430595652F948ADA374C Ref B:
>> A3C4FE3E5EFF7E01F424A3DC08B40AF5 Ref C: Tue Dec  6 06:44:10 2016 PST
>> *Date: Tue, 06 Dec 2016 14:44:10 GMT*
>> X-Cache: MISS from proxycache2
>> Age: 60080
>> X-Cache: HIT from proxy
>> Via: 1.1 proxycache2 (squid), 1.1 proxy (squid)
>> Connection: keep-alive
>>
>> So.. it's sending a stale object, but it's saying to the user that the
>> object is expired...  is it right? I think windows update is aborting
> Worse than that.
>
> -> Last-Modified + Age is not even close to the Date value.
>
> -> The CC:max-age=172800 says it expires at 16 Nov 2016 16:57:44 GMT.
>
> -> Content-Length says it is 0 bytes of data. Yet there are non-zero
> amount of object being transferred in your log records.
>
> Something is getting very screwed up in those headers.
>
> What versions of Squid are those two proxies?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From javibarroso at gmail.com  Fri Dec  9 11:55:53 2016
From: javibarroso at gmail.com (Javier Barroso)
Date: Fri, 9 Dec 2016 12:55:53 +0100
Subject: [squid-users] 10 seconds delay squdclient delay
Message-ID: <CAL5yMZRB78tNieUCD+oWFgtiByODPJxy+pnRgZTypX5wOVccCw@mail.gmail.com>

Hello,

We are having trouble with cachemgr performance. Do you know why
squidclient could delay 10 seconds on mgr:xxx queries ?

I have looked about any timeout, or network error, or something, but I
did not find nothing

See info and storedir outputs :

11:16:24 O: HTTP/1.1 200 OK
11:16:24 O: Server: squid/3.5.1
11:16:24 O: Mime-Version: 1.0
11:16:24 O: Date: Fri, 09 Dec 2016 10:16:24 GMT
11:16:24 O: Content-Type: text/plain
11:16:24 O: Expires: Fri, 09 Dec 2016 10:16:24 GMT
11:16:24 O: Last-Modified: Fri, 09 Dec 2016 10:16:24 GMT
11:16:24 O: Connection: close
11:16:24 O: < ===================== STALE 10 seconds ====
11:16:34 O: Squid Object Cache: Version 3.5.1
11:16:34 E: Shared connection to proxyweb02 closed.
11:16:34 O: Build Info:
11:16:34 O: Service Name: squid
11:16:34 O: Start Time:    Fri, 09 Dec 2016 08:30:20 GMT
11:16:34 O: Current Time:    Fri, 09 Dec 2016 10:16:24 GMT
11:16:34 O: Connection information for squid:
11:16:34 O:     Number of clients accessing cache:    1630
11:16:34 O:     Number of HTTP requests received:    541924
11:16:34 O:     Number of ICP messages received:    0
11:16:34 O:     Number of ICP messages sent:    0
11:16:34 O:     Number of queued ICP replies:    0
11:16:34 O:     Number of HTCP messages received:    0
11:16:34 O:     Number of HTCP messages sent:    0
11:16:34 O:     Request failure ratio:     0.00
11:16:34 O:     Average HTTP requests per minute since start:    5109.1
11:16:34 O:     Average ICP messages per minute since start:    0.0
11:16:34 O:     Select loop called: 13075819 times, 1.967 ms avg
11:16:34 O: Cache information for squid:
11:16:34 O:     Hits as % of all requests:    5min: 7.7%, 60min: 6.6%
11:16:34 O:     Hits as % of bytes sent:    5min: 6.7%, 60min: 9.2%
11:16:34 O:     Memory hits as % of hit requests:    5min: 0.0%, 60min: 0.0%
11:16:34 O:     Disk hits as % of hit requests:    5min: 73.9%, 60min: 74.1%
11:16:34 O:     Storage Swap size:    11325052 KB
11:16:34 O:     Storage Swap capacity:    90.0% used, 10.0% free
11:16:34 O:     Storage Mem size:    736 KB
11:16:34 O:     Storage Mem capacity:     0.1% used, 99.9% free
11:16:34 O:     Mean Object Size:    29.44 KB
11:16:34 O:     Requests given to unlinkd:    0
11:16:34 O: Median Service Times (seconds)  5 min    60 min:
11:16:34 O:     HTTP Requests (All):   0.03698  0.03437
11:16:34 O:     Cache Misses:          0.04456  0.04870
11:16:34 O:     Cache Hits:            0.00091  0.00179
11:16:34 O:     Near Hits:             0.00683  0.00707
11:16:34 O:     Not-Modified Replies:  0.00000  0.00065
11:16:34 O:     DNS Lookups:           0.00126  0.00126
11:16:34 O:     ICP Queries:           0.00000  0.00000
11:16:34 O: Resource usage for squid:
11:16:34 O:     UP Time:    6364.214 seconds
11:16:34 O:     CPU Time:    2481.987 seconds
11:16:34 O:     CPU Usage:    39.00%
11:16:34 O:     CPU Usage, 5 minute avg:    37.19%
11:16:34 O:     CPU Usage, 60 minute avg:    38.61%
11:16:34 O:     Maximum Resident Size: 2347456 KB
11:16:34 O:     Page faults with physical i/o: 0
11:16:34 O: Memory accounted for:
11:16:34 O:     Total accounted:       199928 KB
11:16:34 O:     memPoolAlloc calls: 295256640
11:16:34 O:     memPoolFree calls:  301578438
11:16:34 O: File descriptor usage for squid:
11:16:34 O:     Maximum number of file descriptors:   98304
11:16:34 O:     Largest file desc currently in use:   2566
11:16:34 O:     Number of file desc currently in use: 4030
11:16:34 O:     Files queued for open:                   0
11:16:34 O:     Available number of file descriptors: 94274
11:16:34 O:     Reserved number of file descriptors:   300
11:16:34 O:     Store Disk files open:                   3
11:16:34 O: Internal Data Structures:
11:16:34 O:     384892 StoreEntries
11:16:34 O:        208 StoreEntries with MemObjects
11:16:34 O:         14 Hot Object Cache Items
11:16:34 O:     384687 on-disk objects
11:16:34 O:
11:16:34 O: real    0m10.019s
11:16:34 O: user    0m0.006s
11:16:34 O: sys    0m0.006s


11:14:53 O: HTTP/1.1 200 OK
11:14:53 O: Server: squid/3.5.1
11:14:53 O: Mime-Version: 1.0
11:14:53 O: Date: Fri, 09 Dec 2016 10:14:53 GMT
11:14:53 O: Content-Type: text/plain
11:14:53 O: Expires: Fri, 09 Dec 2016 10:14:53 GMT
11:14:53 O: Last-Modified: Fri, 09 Dec 2016 10:14:53 GMT
11:14:53 O: Connection: close
11:14:53 O:
11:14:53 O: by kid1 {
11:14:53 O: Store Directory Statistics:
11:14:53 O: Store Entries          : 126418
11:14:53 O: Maximum Swap Size      : 4194304 KB
11:14:53 O: Current Store Swap Size: 3774836.00 KB
11:14:53 O: Current Capacity       : 90.00% used, 10.00% free
11:14:53 O:
11:14:53 O:
11:14:53 O: Shared Memory Cache
11:14:53 O: Maximum Size: 1048576 KB
11:14:53 O: Current Size: 736.00 KB 0.07%
11:14:53 O: Maximum entries:     32768
11:14:53 O: Current entries: 14 0.04%
11:14:53 O: Maximum slots:       32768
11:14:53 O: Used slots:             23 0.07%
11:14:53 O:
11:14:53 O: Store Directory #0 (aufs): /var/log/squid/cache/cache1
11:14:53 O: FS Block Size 4096 Bytes
11:14:53 O: First level subdirectories: 128
11:14:53 O: Second level subdirectories: 128
11:14:53 O: Maximum Size: 4194304 KB
11:14:53 O: Current Size: 3774836.00 KB
11:14:53 O: Percent Used: 90.00%
11:14:53 O: Filemap bits in use: 126340 of 262144 (48%)
11:14:53 O: Filesystem Space in use: 15704112/22008352 KB (71%)
11:14:53 O: Filesystem Inodes in use: 575168/29360128 (2%)
11:14:53 O: Flags: SELECTED
11:14:53 O: Removal policy: lru
11:14:53 O: LRU reference age: 2.00 days
11:14:53 O: } by kid1
11:14:53 O:
11:14:53 O: by kid2 {
11:14:53 O: Store Directory Statistics:
11:14:53 O: Store Entries          : 131817
11:14:53 O: Maximum Swap Size      : 4194304 KB
11:14:53 O: Current Store Swap Size: 3774848.00 KB
11:14:53 O: Current Capacity       : 90.00% used, 10.00% free
11:14:53 O:
11:14:53 O:
11:14:53 O: Shared Memory Cache
11:14:53 O: Maximum Size: 1048576 KB
11:14:53 O: Current Size: 736.00 KB 0.07%
11:14:53 O: Maximum entries:     32768
11:14:53 O: Current entries: 14 0.04%
11:14:53 O: Maximum slots:       32768
11:14:53 O: Used slots:             23 0.07%
11:14:53 O:
11:14:53 O: Store Directory #0 (aufs): /var/log/squid/cache/cache2
11:14:53 O: FS Block Size 4096 Bytes
11:14:53 O: First level subdirectories: 128
11:14:53 O: Second level subdirectories: 128
11:14:53 O: Maximum Size: 4194304 KB
11:14:53 O: Current Size: 3774848.00 KB
11:14:53 O: Percent Used: 90.00%
11:14:53 O: Filemap bits in use: 131752 of 262144 (50%)
11:14:53 O: Filesystem Space in use: 15704112/22008352 KB (71%)
11:14:53 O: Filesystem Inodes in use: 575168/29360128 (2%)
11:14:53 O: Flags: SELECTED
11:14:53 O: Removal policy: lru
11:14:53 O: LRU reference age: 2.14 days
11:14:53 O: } by kid2
11:14:53 O:
11:14:53 O: by kid3 {
11:14:53 O: Store Directory Statistics:
11:14:53 O: Store Entries          : 126609
11:14:53 O: Maximum Swap Size      : 4194304 KB
11:14:53 O: Current Store Swap Size: 3774872.00 KB
11:14:53 O: Current Capacity       : 90.00% used, 10.00% free
11:14:53 O:
11:14:53 O:
11:14:53 O: Shared Memory Cache
11:14:53 O: Maximum Size: 1048576 KB
11:14:53 O: Current Size: 736.00 KB 0.07%
11:14:53 O: Maximum entries:     32768
11:14:53 O: Current entries: 14 0.04%
11:14:53 O: Maximum slots:       32768
11:14:53 O: Used slots:             23 0.07%
11:14:53 O:
11:14:53 O: Store Directory #0 (aufs): /var/log/squid/cache/cache3
11:14:53 O: FS Block Size 4096 Bytes
11:14:53 O: First level subdirectories: 128
11:14:53 O: Second level subdirectories: 128
11:14:53 O: Maximum Size: 4194304 KB
11:14:53 O: Current Size: 3774872.00 KB
11:14:53 O: Percent Used: 90.00%
11:14:53 O: Filemap bits in use: 126552 of 262144 (48%)
11:14:53 O: Filesystem Space in use: 15704112/22008352 KB (71%)
11:14:53 O: Filesystem Inodes in use: 575168/29360128 (2%)
11:14:53 O: Flags: SELECTED
11:14:53 O: Removal policy: lru
11:14:53 O: LRU reference age: 3.91 days
11:14:53 O: } by kid3
11:15:03 O: < ===================== STALE 10 seconds ====
11:15:03 O: real    0m10.017s
11:15:03 O: user    0m0.006s
11:15:03 O: sys    0m0.006s

We have 3 balanced squid proxy,  at another squid I have seen the same
behaviour but with 20 seconds delay. When we restarted that squid,
mgr:info / mgr:storedir become inmediate.

Thank you very much


From gregs at net-virtual.com  Thu Dec  8 18:42:21 2016
From: gregs at net-virtual.com (Greg Saylor)
Date: Thu, 8 Dec 2016 12:42:21 -0600
Subject: [squid-users] SSL bump config or possible code issue
In-Reply-To: <7ec470d6-49fb-b08f-55e4-0002c73be1ab@measurement-factory.com>
References: <6348944B-9964-49FD-8FB5-F744842C3275@net-virtual.com>
 <7ec470d6-49fb-b08f-55e4-0002c73be1ab@measurement-factory.com>
Message-ID: <D4068264-0B70-4896-A429-E61551C35E98@net-virtual.com>


> On Dec 8, 2016, at 10:41 AM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 12/08/2016 09:15 AM, Greg Saylor wrote:
> 
>> I'm trying to debug a situation where squid 3.4 would return a ERR_ACCESS_DENIED and version 3.5 does not.
> 
> I trust you use Squid v3.5.22 or later. Some v3.5 releases have serious
> SslBump bugs so the minor version is important.


yes I tested this with 3.5.22.  The original issue was noticed in 3.5.19 - but with something like this I?ll always pull down the latest version.  To clarify the prior version was 3,4.6 - I can?t believe that I forgot to mention specific version numbers in the original post - apologies.

>> I started looking at the source code between 3.4 and 3.5. In 3.5 there is this code in src/client_side_request.cc.
>> 
>>        if (sslBumpNeeded()) { 
>>            // We have to serve an error, so bump the client first.
>>            sslBumpNeed(Ssl::bumpClientFirst);
>>            // set final error but delay sending until we bump 
> ...
>>        } else  
>>            // send the error to the client now
> 
> 
>> If I change:
>> 
>> if (sslBumpNeeded()) {
>> 
>> to:
>> 
>> if (sslBumpNeeded() && 0) {
>> 
>> Then it correctly responds with ERR_ACCESS_DENIED.
> 
> 
> Do you enable SslBump features in your Squid?

Yes.  I should clarify: the purpose of this ?hack? was to bypass that block of code and have it fall down to the ?else? statement which returned immediately with an error.

> * If you enabled SslBump, then Squid tries to bump the client connection
> to serve the error message to the HTTPS client (because popular browsers
> ignore errors delivered as CONNECT responses). I do not recall whether
> Squid v3.4 did that, but that is pretty much irrelevant because v3.5
> behavior is deliberate (that behavior may need more configuration
> options, but that is unrelated to v3.4 anyway). There may be bugs with
> that code path, but they are not related to the sslBumpNeeded() result
> as such.

Regretfully, I have not been able to figure this out.  But I agree this is not related to sslBumpNeeded().  I think its more around how the http_access rule result is being squirreled away and not being checked before proceeding with the SSL Bump.  Or perhaps in more 3.5.22 terms: its not being consulted when deciding how to respond to the client request?  Maybe its just not taking precedence?


> 
>> It looks to me as if something is taking precedence over
>> calloutContext->error.  But even if it was not, because the request
>> is actually being processed it would allow a security hole where an
>> attacker could map a private internal network of https services based
>> on the time it takes them to respond - even if it allowed the
>> connection.
> 
> Agreed. If you are using SslBump, then, as the next step, I recommend
> ignoring Squid code and clearly demonstrating that Squid forwards a
> request that should be denied. A packet trace or Squid's HTTP request
> printouts would be helpful for those of us who do not know what exactly
> that "socat" command does in your environment, and what Squid does when
> processing that traffic.
> 


It this what you mean?

2016/12/08 18:07:36.796 kid1| 5,2| src/comm/TcpAcceptor.cc(220) doAccept: New connection on FD 27
2016/12/08 18:07:36.796 kid1| 5,2| src/comm/TcpAcceptor.cc(295) acceptNext: connection on local=[::]:3130 remote=[::] FD 27 flags=1
2016/12/08 18:07:36.796 kid1| 50,5| src/comm/TcpAcceptor.cc(348) oldAccept:  FD 27, [::] [ job21]: (11) Resource temporarily unavailable
2016/12/08 18:07:36.796 kid1| 5,5| src/comm/TcpAcceptor.cc(273) acceptOne: try later: local=[::]:3130 remote=[::] FD 27 flags=1 handler Subscription: 0x24b4210*1
2016/12/08 18:07:36.796 kid1| 5,5| src/comm/ModEpoll.cc(116) SetSelect: FD 27, type=1, handler=1, client_data=0x24bc3c8, timeout=0
2016/12/08 18:07:36.796 kid1| 5,5| src/comm/ModEpoll.cc(116) SetSelect: FD 27, type=1, handler=1, client_data=0x24bc3c8, timeout=0
2016/12/08 18:07:37.471 kid1| 41,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall MaintainSwapSpace constructed, this=0x2098170 [call14588]
2016/12/08 18:07:37.471 kid1| 41,5| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/event.cc(237) will call MaintainSwapSpace() [call14588]
2016/12/08 18:07:37.471 kid1| 41,5| src/base/AsyncCallQueue.cc(55) fireNext: entering MaintainSwapSpace()
2016/12/08 18:07:37.471 kid1| 41,5| src/base/AsyncCall.cc(38) make: make call MaintainSwapSpace [call14588]
2016/12/08 18:07:37.471 kid1| 41,7| src/event.cc(322) schedule: schedule: Adding 'MaintainSwapSpace', in 1.00 seconds
2016/12/08 18:07:37.471 kid1| 41,5| src/base/AsyncCallQueue.cc(57) fireNext: leaving MaintainSwapSpace()
2016/12/08 18:07:37.569 kid1| 41,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::ServiceRep::noteTimeToUpdate constructed, this=0x2098170 [call14589]
2016/12/08 18:07:37.569 kid1| 41,5| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/event.cc(237) will call Adaptation::Icap::ServiceRep::noteTimeToUpdate(0x24b7a68*?) [call14589]
2016/12/08 18:07:37.569 kid1| 41,5| src/base/AsyncCallQueue.cc(55) fireNext: entering Adaptation::Icap::ServiceRep::noteTimeToUpdate(0x24b7a68*?)
2016/12/08 18:07:37.569 kid1| 41,5| src/base/AsyncCall.cc(38) make: make call Adaptation::Icap::ServiceRep::noteTimeToUpdate [call14589]
2016/12/08 18:07:37.569 kid1| 93,5| src/adaptation/icap/ServiceRep.cc(358) noteTimeToUpdate: performs a regular options update [up]
2016/12/08 18:07:37.569 kid1| 93,6| src/adaptation/icap/ServiceRep.cc(591) startGettingOptions: will get new options [up]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncJob.cc(34) AsyncJob: AsyncJob constructed, this=0x21db6c8 type=Adaptation::Icap::OptXactLauncher [job789]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0x2529e10 [call14590]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/base/AsyncJob.cc(26) will call AsyncJob::start() [call14590]
2016/12/08 18:07:37.569 kid1| 41,5| src/base/AsyncCallQueue.cc(57) fireNext: leaving Adaptation::Icap::ServiceRep::noteTimeToUpdate(0x24b7a68*?)
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCallQueue.cc(55) fireNext: entering AsyncJob::start()
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(38) make: make call AsyncJob::start [call14590]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncJob.cc(123) callStart: Adaptation::Icap::OptXactLauncher status in: [ job789]
2016/12/08 18:07:37.569 kid1| 93,4| src/adaptation/icap/Launcher.cc(49) launchXaction: launching first xaction #1
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncJob.cc(34) AsyncJob: AsyncJob constructed, this=0x24d29b8 type=Adaptation::Icap::OptXact [job790]
2016/12/08 18:07:37.569 kid1| 93,3| src/adaptation/icap/Xaction.cc(60) Xaction: Adaptation::Icap::OptXact constructed, this=0x24d28b8 [icapxjob790]
2016/12/08 18:07:37.569 kid1| 55,7| src/HttpHeader.cc(446) HttpHeader: init-ing hdr: 0x2458c98 owner: 2
2016/12/08 18:07:37.569 kid1| 24,7| src/SBuf.cc(139) assign: assigning SBuf4091 from SBuf4092
2016/12/08 18:07:37.569 kid1| 93,5| src/adaptation/icap/Xaction.cc(92) disableRepeats: Adaptation::Icap::OptXact from now on cannot be repeated because over icap_retry_limit [/ job790]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0x21bb480 [call14591]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/base/AsyncJob.cc(26) will call AsyncJob::start() [call14591]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncJob.cc(152) callEnd: Adaptation::Icap::OptXactLauncher status out: [ job789]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCallQueue.cc(57) fireNext: leaving AsyncJob::start()
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCallQueue.cc(55) fireNext: entering AsyncJob::start()
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(38) make: make call AsyncJob::start [call14591]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncJob.cc(123) callStart: Adaptation::Icap::OptXact status in: [/ job790]
2016/12/08 18:07:37.569 kid1| 48,3| src/pconn.cc(156) clearHandlers: removing close handler for local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1
2016/12/08 18:07:37.569 kid1| 5,4| src/base/AsyncCall.cc(56) cancel: will not call IdleConnList::Read [call14540] because old comm_read_cancel
2016/12/08 18:07:37.569 kid1| 5,4| src/base/AsyncCall.cc(56) cancel: will not call IdleConnList::Read [call14540] also because old comm_read_cancel
2016/12/08 18:07:37.569 kid1| 5,5| src/comm/ModEpoll.cc(116) SetSelect: FD 35, type=1, handler=0, client_data=0, timeout=0
2016/12/08 18:07:37.569 kid1| 5,3| src/comm.cc(579) commUnsetConnTimeout: Remove timeout for local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1
2016/12/08 18:07:37.569 kid1| 5,3| src/comm.cc(553) commSetConnTimeout: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 timeout -1
2016/12/08 18:07:37.569 kid1| 93,3| src/adaptation/icap/ServiceRep.cc(122) getConnection: got connection: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1
2016/12/08 18:07:37.569 kid1| 93,3| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommConnected constructed, this=0x252d4e0 [call14592]
2016/12/08 18:07:37.569 kid1| 93,3| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/adaptation/icap/Xaction.cc(138) will call Adaptation::Icap::Xaction::noteCommConnected(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8) [call14592]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncJob.cc(152) callEnd: Adaptation::Icap::OptXact status out: [FD 35;/ job790]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCallQueue.cc(57) fireNext: leaving AsyncJob::start()
2016/12/08 18:07:37.569 kid1| 93,3| src/base/AsyncCallQueue.cc(55) fireNext: entering Adaptation::Icap::Xaction::noteCommConnected(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8)
2016/12/08 18:07:37.569 kid1| 93,3| src/base/AsyncCall.cc(38) make: make call Adaptation::Icap::Xaction::noteCommConnected [call14592]
2016/12/08 18:07:37.569 kid1| 93,3| src/base/AsyncJob.cc(123) callStart: Adaptation::Icap::OptXact status in: [FD 35;/ job790]
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommTimedout constructed, this=0x25273d0 [call14593]
2016/12/08 18:07:37.569 kid1| 5,3| src/comm.cc(553) commSetConnTimeout: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 timeout 60
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommClosed constructed, this=0x25409d0 [call14594]
2016/12/08 18:07:37.569 kid1| 5,5| src/comm.cc(994) comm_add_close_handler: comm_add_close_handler: FD 35, AsyncCall=0x25409d0*1
2016/12/08 18:07:37.569 kid1| 93,3| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommRead constructed, this=0x21d0a00 [call14595]
2016/12/08 18:07:37.569 kid1| 5,5| src/comm/Read.cc(58) comm_read_base: comm_read, queueing read for local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1; asynCall 0x21d0a00*1
2016/12/08 18:07:37.569 kid1| 5,5| src/comm/ModEpoll.cc(116) SetSelect: FD 35, type=1, handler=1, client_data=0x7f1a3515a080, timeout=0
2016/12/08 18:07:37.569 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommTimedout constructed, this=0x20c54a0 [call14596]
2016/12/08 18:07:37.569 kid1| 5,3| src/comm.cc(553) commSetConnTimeout: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 timeout 900
2016/12/08 18:07:37.569 kid1| 24,7| src/SBuf.cc(139) assign: assigning SBuf4090 from SBuf4094
2016/12/08 18:07:37.569 kid1| 23,3| src/url.cc(359) urlParse: urlParse: Split URL 'icap://127.0.0.1:1344/foo_reqmod ICAP/1.0
' into proto='icap', host='127.0.0.1', port='1344', path='/foo_reqmod ICAP/1.0'
2016/12/08 18:07:37.569 kid1| 23,2| src/url.cc(395) urlParse: urlParse: URI has whitespace: {icap://127.0.0.1:1344/foo_reqmod ICAP/1.0
}
2016/12/08 18:07:37.569 kid1| 24,7| src/SBuf.cc(139) assign: assigning SBuf4090 from SBuf4090
2016/12/08 18:07:37.569 kid1| 23,3| src/HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 127.0.0.1
2016/12/08 18:07:37.569 kid1| 55,7| src/HttpHeader.cc(597) parse: parsing hdr: (0x2458c98)
Host: 127.0.0.1:1344
Allow: 206

2016/12/08 18:07:37.570 kid1| 55,7| src/HttpHeader.cc(981) addEntry: 0x2458c98 adding entry: 29 at 0
2016/12/08 18:07:37.570 kid1| 55,7| src/HttpHeader.cc(981) addEntry: 0x2458c98 adding entry: 6 at 1
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommWrote constructed, this=0x2540e50 [call14597]
2016/12/08 18:07:37.570 kid1| 5,5| src/comm/Write.cc(35) Write: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1: sz 94: asynCall 0x2540e50*1
2016/12/08 18:07:37.570 kid1| 5,5| src/comm/ModEpoll.cc(116) SetSelect: FD 35, type=2, handler=1, client_data=0x7f1a3515a0b8, timeout=0
2016/12/08 18:07:37.570 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommTimedout constructed, this=0x2540ef0 [call14598]
2016/12/08 18:07:37.570 kid1| 5,3| src/comm.cc(553) commSetConnTimeout: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 timeout 900
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncJob.cc(152) callEnd: Adaptation::Icap::OptXact status out: [FD 35wr;/ job790]
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCallQueue.cc(57) fireNext: leaving Adaptation::Icap::Xaction::noteCommConnected(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8)
2016/12/08 18:07:37.570 kid1| 5,5| src/comm/Write.cc(66) HandleWrite: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1: off 0, sz 94.
2016/12/08 18:07:37.570 kid1| 5,5| src/comm/Write.cc(108) HandleWrite: write() returns 94
2016/12/08 18:07:37.570 kid1| 5,3| src/comm/IoCallback.cc(116) finish: called for local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 (0, 0)
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(135) will call Adaptation::Icap::Xaction::noteCommWrote(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8) [call14597]
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCallQueue.cc(55) fireNext: entering Adaptation::Icap::Xaction::noteCommWrote(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8)
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCall.cc(38) make: make call Adaptation::Icap::Xaction::noteCommWrote [call14597]
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncJob.cc(123) callStart: Adaptation::Icap::OptXact status in: [FD 35wr;/ job790]
2016/12/08 18:07:37.570 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommTimedout constructed, this=0x25273d0 [call14599]
2016/12/08 18:07:37.570 kid1| 5,3| src/comm.cc(553) commSetConnTimeout: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 timeout 900
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncJob.cc(152) callEnd: Adaptation::Icap::OptXact status out: [FD 35r;/ job790]
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCallQueue.cc(57) fireNext: leaving Adaptation::Icap::Xaction::noteCommWrote(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8)
2016/12/08 18:07:37.570 kid1| 5,5| src/comm/ModEpoll.cc(116) SetSelect: FD 35, type=2, handler=0, client_data=0, timeout=0
2016/12/08 18:07:37.570 kid1| 5,3| src/comm/Read.cc(144) HandleRead: FD 35, size 65535, retval 210, errno 0
2016/12/08 18:07:37.570 kid1| 5,3| src/comm/IoCallback.cc(116) finish: called for local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 (0, 0)
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(135) will call Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8, size=210, buf=0x24e0b90) [call14595]
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCallQueue.cc(55) fireNext: entering Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8, size=210, buf=0x24e0b90)
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncCall.cc(38) make: make call Adaptation::Icap::Xaction::noteCommRead [call14595]
2016/12/08 18:07:37.570 kid1| 93,3| src/base/AsyncJob.cc(123) callStart: Adaptation::Icap::OptXact status in: [FD 35r;/ job790]
2016/12/08 18:07:37.570 kid1| 5,3| src/comm.cc(579) commUnsetConnTimeout: Remove timeout for local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1
2016/12/08 18:07:37.570 kid1| 5,3| src/comm.cc(553) commSetConnTimeout: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 timeout -1
2016/12/08 18:07:37.570 kid1| 93,3| src/adaptation/icap/Xaction.cc(425) noteCommRead: read 210 bytes
2016/12/08 18:07:37.570 kid1| 93,5| src/adaptation/icap/Xaction.cc(85) disableRetries: Adaptation::Icap::OptXact from now on cannot be retried  [FD 35;/ job790]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/OptXact.cc(103) parseResponse: have 210 bytes to parse [FD 35;/ job790]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/OptXact.cc(104) parseResponse: 
ICAP/1.0 200 OK
Date: Thu, 8 Dec 2016 18:07:37 UTC
ISTag: Socialware TAG Thu, 8 Dec 2016 18:07:37 UTC
Max-Connections: 1000
Methods: REQMOD
Server: Socialware ICAP Server/1.0
Encapsulated: null-body=0


2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(446) HttpHeader: init-ing hdr: 0x24583e8 owner: 3
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Xaction.cc(450) parseHttpMsg: have 210 head bytes to parse
2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(597) parse: parsing hdr: (0x24583e8)
Date: Thu, 8 Dec 2016 18:07:37 UTC
ISTag: Socialware TAG Thu, 8 Dec 2016 18:07:37 UTC
Max-Connections: 1000
Methods: REQMOD
Server: Socialware ICAP Server/1.0
Encapsulated: null-body=0

2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(981) addEntry: 0x24583e8 adding entry: 23 at 0
2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(981) addEntry: 0x24583e8 adding entry: 85 at 1
2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(981) addEntry: 0x24583e8 adding entry: 85 at 2
2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(981) addEntry: 0x24583e8 adding entry: 85 at 3
2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(981) addEntry: 0x24583e8 adding entry: 56 at 4
2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(981) addEntry: 0x24583e8 adding entry: 85 at 5
2016/12/08 18:07:37.571 kid1| 55,2| src/HttpHeader.cc(1754) httpHeaderNoteParsedEntry: cannot parse hdr field: 'Date: Thu, 8 Dec 2016 18:07:37 UTC'
2016/12/08 18:07:37.571 kid1| 93,7| src/adaptation/icap/OptXact.cc(89) handleCommRead: readAll=1
2016/12/08 18:07:37.571 kid1| 93,4| src/adaptation/icap/Xaction.cc(514) setOutcome: ICAP_OPT
2016/12/08 18:07:37.571 kid1| 93,4| src/adaptation/Answer.cc(29) Forward: forwarding: 0x24583d0
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Initiator::noteAdaptationAnswer constructed, this=0x20c54a0 [call14600]
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/adaptation/Initiate.cc(83) will call Initiator::noteAdaptationAnswer(0) [call14600]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Xaction.cc(354) callEnd: Adaptation::Icap::OptXact done with I/O [FD 35;/ job790]
2016/12/08 18:07:37.571 kid1| 5,5| src/comm.cc(1039) comm_remove_close_handler: comm_remove_close_handler: FD 35, AsyncCall=0x25409d0*2
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(56) cancel: will not call Adaptation::Icap::Xaction::noteCommClosed [call14594] because comm_remove_close_handler
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Xaction.cc(85) disableRetries: Adaptation::Icap::OptXact still cannot be retried  [FD 35;/ job790]
2016/12/08 18:07:37.571 kid1| 93,3| src/adaptation/icap/ServiceRep.cc(132) putConnection: pushing pconn [FD 35;/ job790]
2016/12/08 18:07:37.571 kid1| 5,3| src/comm.cc(579) commUnsetConnTimeout: Remove timeout for local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1
2016/12/08 18:07:37.571 kid1| 5,3| src/comm.cc(553) commSetConnTimeout: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 timeout -1
2016/12/08 18:07:37.571 kid1| 5,4| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall IdleConnList::Read constructed, this=0x252d4e0 [call14601]
2016/12/08 18:07:37.571 kid1| 5,5| src/comm/Read.cc(58) comm_read_base: comm_read, queueing read for local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1; asynCall 0x252d4e0*1
2016/12/08 18:07:37.571 kid1| 5,5| src/comm/ModEpoll.cc(116) SetSelect: FD 35, type=1, handler=1, client_data=0x7f1a3515a080, timeout=0
2016/12/08 18:07:37.571 kid1| 5,4| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall IdleConnList::Timeout constructed, this=0x24dcb50 [call14602]
2016/12/08 18:07:37.571 kid1| 5,3| src/comm.cc(553) commSetConnTimeout: local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1 timeout 60
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncJob.cc(137) callEnd: Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8, size=210, buf=0x24e0b90) ends job [/ job790]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/Initiate.cc(64) swanSong: swan sings [/ job790]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/Initiate.cc(71) swanSong: swan sang [/ job790]
2016/12/08 18:07:37.571 kid1| 93,3| src/adaptation/icap/Xaction.cc(71) ~Xaction: Adaptation::Icap::OptXact destructed, this=0x24d28b8 [icapxjob790]
2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(480) clean: cleaning hdr: 0x2458c98 owner: 2
2016/12/08 18:07:37.571 kid1| 93,7| src/HttpRequest.cc(55) ~HttpRequest: destructed, this=0x2458c80
2016/12/08 18:07:37.571 kid1| 55,7| src/HttpHeader.cc(480) clean: cleaning hdr: 0x2458c98 owner: 2
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncJob.cc(40) ~AsyncJob: AsyncJob destructed, this=0x24d29b8 type=Adaptation::Icap::OptXact [job790]
2016/12/08 18:07:37.571 kid1| 93,6| src/base/AsyncJob.cc(147) callEnd: Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8, size=210, buf=0x24e0b90) ended 0x24d29b8
2016/12/08 18:07:37.571 kid1| 93,3| src/base/AsyncCallQueue.cc(57) fireNext: leaving Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:35366 remote=127.0.0.1:1344 FD 35 flags=1, data=0x24d28b8, size=210, buf=0x24e0b90)
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCallQueue.cc(55) fireNext: entering Initiator::noteAdaptationAnswer(0)
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(38) make: make call Initiator::noteAdaptationAnswer [call14600]
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncJob.cc(123) callStart: Adaptation::Icap::OptXactLauncher status in: [ job789]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Launcher.cc(64) noteAdaptationAnswer: launches: 1 answer: 0
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Initiator::noteAdaptationAnswer constructed, this=0x25409d0 [call14603]
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/adaptation/Initiate.cc(83) will call Initiator::noteAdaptationAnswer(0) [call14603]
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncJob.cc(137) callEnd: Initiator::noteAdaptationAnswer(0) ends job [ job789]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/Initiate.cc(64) swanSong: swan sings [ job789]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/Initiate.cc(71) swanSong: swan sang [ job789]
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncJob.cc(40) ~AsyncJob: AsyncJob destructed, this=0x21db6c8 type=Adaptation::Icap::OptXactLauncher [job789]
2016/12/08 18:07:37.571 kid1| 93,6| src/base/AsyncJob.cc(147) callEnd: Initiator::noteAdaptationAnswer(0) ended 0x21db6c8
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCallQueue.cc(57) fireNext: leaving Initiator::noteAdaptationAnswer(0)
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCallQueue.cc(55) fireNext: entering Initiator::noteAdaptationAnswer(0)
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(38) make: make call Initiator::noteAdaptationAnswer [call14603]
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncJob.cc(123) callStart: Adaptation::Icap::ServiceRep status in:[up,fetch]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/ServiceRep.cc(543) noteAdaptationAnswer: is interpreting new options [up]
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Options.cc(153) cfgIntHeader: int header: Max-Connections: 1000
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Options.cc(153) cfgIntHeader: int header: Options-TTL: -1
2016/12/08 18:07:37.571 kid1| 55,2| src/HttpHeader.cc(1754) httpHeaderNoteParsedEntry: cannot parse hdr field: 'Date: Thu, 8 Dec 2016 18:07:37 UTC'
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Options.cc(153) cfgIntHeader: int header: Preview: -1
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Options.cc(234) report: Adaptation::Icap::Options::cfgTransferList: no Transfer-Preview extensions
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Options.cc(234) report: Adaptation::Icap::Options::cfgTransferList: no Transfer-Ignore extensions
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/Options.cc(234) report: Adaptation::Icap::Options::cfgTransferList: no Transfer-Complete extensions
2016/12/08 18:07:37.571 kid1| 93,3| src/adaptation/icap/ServiceRep.cc(571) handleNewOptions: got new options and is now [up]
2016/12/08 18:07:37.571 kid1| 93,7| src/adaptation/icap/ServiceRep.cc(642) optionsFetchTime: options expire on 1481220517 >= 1481220457
2016/12/08 18:07:37.571 kid1| 93,7| src/adaptation/icap/ServiceRep.cc(614) scheduleUpdate: raw OPTIONS fetch at 1481220497 or in 40 sec
2016/12/08 18:07:37.571 kid1| 93,5| src/adaptation/icap/ServiceRep.cc(629) scheduleUpdate: will fetch OPTIONS in 40 sec
2016/12/08 18:07:37.571 kid1| 41,7| src/event.cc(322) schedule: schedule: Adding 'Adaptation::Icap::ServiceRep::noteTimeToUpdate', in 40.00 seconds
2016/12/08 18:07:37.571 kid1| 93,7| src/adaptation/icap/ServiceRep.cc(436) scheduleNotification: will notify 0 clients
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Icap::ServiceRep::noteTimeToNotify constructed, this=0x21bb480 [call14604]
2016/12/08 18:07:37.571 kid1| 93,5| src/base/AsyncCall.cc(93) ScheduleCall: /tmp/squid_source/src/adaptation/icap/ServiceRep.cc(437) will call Adaptation::Icap::ServiceRep::noteTimeToNotify() [call14604]


That is from 3.5.22

Here?s the same from 3.4.6, I tried to clean this up a bit there were substantially more log messages:

2016/12/08 18:14:35.927 kid2| src/comm/TcpAcceptor.cc(220) doAccept: New connection on FD 19
2016/12/08 18:14:35.927 kid2| src/comm/TcpAcceptor.cc(295) acceptNext: connection on local=[::]:3130 remote=[::] FD 19 flags=1
2016/12/08 18:14:35.927 kid2| src/fd.cc(221) fd_open: fd_open() FD 27 HTTP Request
2016/12/08 18:14:35.927 kid2| src/eui/Eui48.cc(203) lookup: id=0x2512c64 query ARP table
2016/12/08 18:14:35.927 kid2| src/eui/Eui48.cc(246) lookup: id=0x2512c64 query ARP on each interface (80 found)
2016/12/08 18:14:35.927 kid2| src/eui/Eui48.cc(252) lookup: id=0x2512c64 found interface lo
2016/12/08 18:14:35.927 kid2| src/eui/Eui48.cc(252) lookup: id=0x2512c64 found interface eth0
2016/12/08 18:14:35.927 kid2| src/eui/Eui48.cc(261) lookup: id=0x2512c64 looking up ARP address for 172.16.0.43 on eth0
2016/12/08 18:14:35.927 kid2| src/eui/Eui48.cc(540) lookup: id=0x2512c64 172.16.0.43 NOT found
2016/12/08 18:14:35.927 kid2| src/comm/TcpAcceptor.cc(287) acceptOne: Listener: local=[::]:3130 remote=[::] FD 19 flags=1 accepted new connection local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 handler Subscription: 0x2501b30*1
2016/12/08 18:14:35.927 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall httpAccept constructed, this=0x2574f90 [call15371]
2016/12/08 18:14:35.927 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm/TcpAcceptor.cc(317) will call httpAccept(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x131d668, MXID_46) [call15371]
2016/12/08 18:14:35.927 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 19, type=1, handler=1, client_data=0x2501c08, timeout=0
2016/12/08 18:14:35.927 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering httpAccept(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x131d668, MXID_46)
2016/12/08 18:14:35.927 kid2| src/base/AsyncCall.cc(30) make: make call httpAccept [call15371]
2016/12/08 18:14:35.927 kid2| src/client_side.cc(3412) httpAccept: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: accepted
2016/12/08 18:14:35.927 kid2| src/base/AsyncJob.cc(28) AsyncJob: AsyncJob constructed, this=0x2513100 type=ConnStateData [job820]
2016/12/08 18:14:35.927 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall ConnStateData::connStateClosed constructed, this=0x2574aa0 [call15372]
2016/12/08 18:14:35.927 kid2| src/comm.cc(1208) comm_add_close_handler: comm_add_close_handler: FD 27, AsyncCall=0x2574aa0*1
2016/12/08 18:14:35.927 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall ConnStateData::requestTimeout constructed, this=0x2575470 [call15373]
2016/12/08 18:14:35.927 kid2| src/comm.cc(768) commSetConnTimeout: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 timeout 300
2016/12/08 18:14:35.927 kid2| src/client_side.cc(258) readSomeData: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: reading request...
2016/12/08 18:14:35.927 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall ConnStateData::clientReadRequest constructed, this=0x210d9c0 [call15374]
2016/12/08 18:14:35.927 kid2| src/comm.cc(167) comm_read: comm_read, queueing read for local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1; asynCall 0x210d9c0*1
2016/12/08 18:14:35.927 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=1, handler=1, client_data=0x7ff2cba7bcc0, timeout=0
2016/12/08 18:14:35.927 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving httpAccept(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x131d668, MXID_46)
2016/12/08 18:14:35.971 kid2| src/comm.cc(138) commHandleRead: comm_read_try: FD 27, size 4095, retval 41, errno 0
2016/12/08 18:14:35.971 kid2| src/comm/IoCallback.cc(108) finish: called for local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 (0, 0)
2016/12/08 18:14:35.971 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(127) will call ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2512f88, size=41, buf=0x24a20d0) [call15374]
2016/12/08 18:14:35.971 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2512f88, size=41, buf=0x24a20d0)
2016/12/08 18:14:35.971 kid2| src/base/AsyncCall.cc(30) make: make call ConnStateData::clientReadRequest [call15374]
2016/12/08 18:14:35.971 kid2| src/base/AsyncJob.cc(117) callStart: ConnStateData status in: [ job820]
2016/12/08 18:14:35.971 kid2| src/client_side.cc(3042) clientReadRequest: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 size 41
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2981) clientParseRequests: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: attempting to parse
2016/12/08 18:14:35.971 kid2| src/HttpParser.cc(29) reset: Request buffer is CONNECT www.facebook.com:443 HTTP/1.0


2016/12/08 18:14:35.971 kid2| src/HttpParser.cc(39) parseRequestFirstLine: parsing possible request: CONNECT www.facebook.com:443 HTTP/1.0


2016/12/08 18:14:35.971 kid2| src/HttpParser.cc(249) HttpParserParseReqLine: Parser: retval 1: from 0->38: method 0->6; url 8->27; version 29->36 (1/0)
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2322) parseHttpRequest: parseHttpRequest: req_hdr = {
}
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2326) parseHttpRequest: parseHttpRequest: end = {
}
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2330) parseHttpRequest: parseHttpRequest: prefix_sz = 41, req_line_sz = 39
2016/12/08 18:14:35.971 kid2| src/base/AsyncJob.cc(28) AsyncJob: AsyncJob constructed, this=0x2513570 type=ClientHttpRequest [job821]
2016/12/08 18:14:35.971 kid2| src/clientStream.cc(167) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x25106f8 with data 0x2514c40 after head
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2346) parseHttpRequest: parseHttpRequest: Request Header is


2016/12/08 18:14:35.971 kid2| src/client_side.cc(2367) parseHttpRequest: repare absolute URL from 
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2404) parseHttpRequest: parseHttpRequest: Complete request received
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2407) parseHttpRequest: HTTP Client local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2408) parseHttpRequest: HTTP Client REQUEST:
---------
CONNECT www.facebook.com:443 HTTP/1.0


----------
2016/12/08 18:14:35.971 kid2| src/client_side.cc(3019) clientParseRequests: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: parsed a request
2016/12/08 18:14:35.971 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall clientLifetimeTimeout constructed, this=0x2574f90 [call15375]
2016/12/08 18:14:35.971 kid2| src/comm.cc(768) commSetConnTimeout: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 timeout 86400
2016/12/08 18:14:35.971 kid2| src/url.cc(386) urlParse: urlParse: Split URL 'www.facebook.com:443' into proto='', host='www.facebook.com', port='443', path=''
2016/12/08 18:14:35.971 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x249f858 owner: 2
2016/12/08 18:14:35.971 kid2| src/HttpRequest.cc(70) HttpRequest: constructed, this=0x249f840 id=8
2016/12/08 18:14:35.971 kid2| src/ip/Address.cc(378) lookupHostIP: Given Non-IP 'www.facebook.com': Name or service not known
2016/12/08 18:14:35.971 kid2| src/HttpHeader.cc(557) parse: parsing hdr: (0x249f858)

2016/12/08 18:14:35.971 kid2| src/client_side.cc(925) clientSetKeepaliveFlag: clientSetKeepaliveFlag: http_ver = 1.0
2016/12/08 18:14:35.971 kid2| src/client_side.cc(927) clientSetKeepaliveFlag: clientSetKeepaliveFlag: method = CONNECT
2016/12/08 18:14:35.971 kid2| src/client_side.h(108) mayUseConnection: This 0x2513bc8 marked 1
2016/12/08 18:14:35.971 kid2| src/client_side.cc(2510) connNoteUseOfBuffer: conn->in.notYetUsed = 0
2016/12/08 18:14:35.971 kid2| src/client_side_request.cc(152) ClientRequestContext: 0x250fb88 ClientRequestContext constructed
2016/12/08 18:14:35.971 kid2| src/client_side_request.cc(1691) doCallouts: Doing calloutContext->hostHeaderVerify()
2016/12/08 18:14:35.971 kid2| src/client_side_request.cc(605) hostHeaderVerify: validate skipped with no Host: header present.
2016/12/08 18:14:35.971 kid2| src/client_side_request.cc(1698) doCallouts: Doing calloutContext->clientAccessCheck()
2016/12/08 18:14:35.971 kid2| src/acl/Checklist.cc(62) preCheck: 0x2516068 checking slow rules
2016/12/08 18:14:35.971 kid2| src/acl/Acl.cc(157) matches: checking http_access
2016/12/08 18:14:35.971 kid2| src/acl/Acl.cc(157) matches: checking http_access#1
2016/12/08 18:14:35.971 kid2| src/acl/Acl.cc(157) matches: checking manager
2016/12/08 18:14:35.971 kid2| src/acl/RegexData.cc(71) match: aclRegexData::match: checking 'www.facebook.com:443'
2016/12/08 18:14:35.971 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(^cache_object://)'
2016/12/08 18:14:35.971 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(^https?://[^/]+/squid-internal-mgr/)'
2016/12/08 18:14:35.971 kid2| src/acl/Acl.cc(177) matches: checked: manager = 0
2016/12/08 18:14:35.971 kid2| src/acl/Acl.cc(177) matches: checked: http_access#1 = 0
2016/12/08 18:14:35.971 kid2| src/acl/Acl.cc(157) matches: checking http_access#2
2016/12/08 18:14:35.971 kid2| src/acl/Acl.cc(157) matches: checking manager
2016/12/08 18:14:35.972 kid2| src/acl/RegexData.cc(71) match: aclRegexData::match: checking 'www.facebook.com:443'
2016/12/08 18:14:35.972 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(^cache_object://)'
2016/12/08 18:14:35.972 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(^https?://[^/]+/squid-internal-mgr/)'
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: manager = 0
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: http_access#2 = 0
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking http_access#3
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking healthcheck
2016/12/08 18:14:35.972 kid2| src/acl/RegexData.cc(71) match: aclRegexData::match: checking 'www.facebook.com:443'
2016/12/08 18:14:35.972 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(sw_proxy_health_check$)'
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: healthcheck = 0
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: http_access#3 = 0
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking http_access#4
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking !Safe_ports
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking Safe_ports
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: Safe_ports = 1
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: !Safe_ports = 0
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: http_access#4 = 0
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking http_access#5
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking CONNECT
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: CONNECT = 1
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking !SSL_ports
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking SSL_ports
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: SSL_ports = 1
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: !SSL_ports = 0
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: http_access#5 = 0
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking http_access#6
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking socialnetworks
2016/12/08 18:14:35.972 kid2| src/acl/DomainData.cc(131) match: aclMatchDomainList: checking 'www.facebook.com'
2016/12/08 18:14:35.972 kid2| src/acl/DomainData.cc(135) match: aclMatchDomainList: 'www.facebook.com' found
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: socialnetworks = 1
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: http_access#6 = 1
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: http_access = 1
2016/12/08 18:14:35.972 kid2| src/acl/Checklist.cc(55) markFinished: 0x2516068 answer ALLOWED for match
2016/12/08 18:14:35.972 kid2| src/acl/Checklist.cc(155) checkCallback: ACLChecklist::checkCallback: 0x2516068 answer=ALLOWED
2016/12/08 18:14:35.972 kid2| src/client_side_request.cc(759) clientAccessCheckDone: The request CONNECT www.facebook.com:443 is ALLOWED; last ACL checked: socialnetworks
2016/12/08 18:14:35.972 kid2| src/base/AsyncJob.cc(28) AsyncJob: AsyncJob constructed, this=0x2511548 type=AccessCheck [job822]
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(49) AccessCheck: AccessCheck constructed for REQMOD PRECACHE
2016/12/08 18:14:35.972 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0x2560bd0 [call15376]
2016/12/08 18:14:35.972 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/base/AsyncJob.cc(20) will call AsyncJob::start() [call15376]
2016/12/08 18:14:35.972 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x2516068
2016/12/08 18:14:35.972 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x2516068
2016/12/08 18:14:35.972 kid2| src/client_side.cc(3029) clientParseRequests: Not parsing new requests, as this request may need the connection
2016/12/08 18:14:35.972 kid2| src/base/AsyncJob.cc(146) callEnd: ConnStateData status out: [ job820]
2016/12/08 18:14:35.972 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2512f88, size=41, buf=0x24a20d0)
2016/12/08 18:14:35.972 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering AsyncJob::start()
2016/12/08 18:14:35.972 kid2| src/base/AsyncCall.cc(30) make: make call AsyncJob::start [call15376]
2016/12/08 18:14:35.972 kid2| src/base/AsyncJob.cc(117) callStart: AccessCheck status in: [ job822]
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(96) check: start checking
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(215) isCandidate: checking candidacy of 1, group service_test_resp
2016/12/08 18:14:35.972 kid2| src/adaptation/ServiceGroups.cc(136) findService: service_test_resp serves another location
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(225) isCandidate: service_test_resp ignores
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(215) isCandidate: checking candidacy of 2, group service_test_req
2016/12/08 18:14:35.972 kid2| src/adaptation/icap/Options.cc(46) transferKind: url  matches no extensions; using default: Transfer-Complete
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(225) isCandidate: service_test_req wants
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(102) check: check: rule '2' is a candidate
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(118) checkCandidates: has 1 rules
2016/12/08 18:14:35.972 kid2| src/acl/Checklist.cc(62) preCheck: 0x2516068 checking slow rules
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking adaptation_access
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking adaptation_access#1
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(157) matches: checking socialnetworks
2016/12/08 18:14:35.972 kid2| src/acl/DomainData.cc(131) match: aclMatchDomainList: checking 'www.facebook.com'
2016/12/08 18:14:35.972 kid2| src/acl/DomainData.cc(135) match: aclMatchDomainList: 'www.facebook.com' found
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: socialnetworks = 1
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_access#1 = 1
2016/12/08 18:14:35.972 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_access = 1
2016/12/08 18:14:35.972 kid2| src/acl/Checklist.cc(55) markFinished: 0x2516068 answer ALLOWED for match
2016/12/08 18:14:35.972 kid2| src/acl/Checklist.cc(155) checkCallback: ACLChecklist::checkCallback: 0x2516068 answer=ALLOWED
2016/12/08 18:14:35.972 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::AccessCheck::noteAnswer constructed, this=0x23aa110 [call15377]
2016/12/08 18:14:35.972 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/adaptation/AccessCheck.cc(155) will call Adaptation::AccessCheck::noteAnswer(ALLOWED) [call15377]
2016/12/08 18:14:35.972 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x2516068
2016/12/08 18:14:35.972 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x2516068
2016/12/08 18:14:35.972 kid2| src/base/AsyncJob.cc(146) callEnd: AccessCheck status out: [ job822]
2016/12/08 18:14:35.972 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving AsyncJob::start()
2016/12/08 18:14:35.972 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Adaptation::AccessCheck::noteAnswer(ALLOWED)
2016/12/08 18:14:35.972 kid2| src/base/AsyncCall.cc(30) make: make call Adaptation::AccessCheck::noteAnswer [call15377]
2016/12/08 18:14:35.972 kid2| src/base/AsyncJob.cc(117) callStart: AccessCheck status in: [ job822]
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(164) noteAnswer: 2 answer=ALLOWED
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(198) topGroup: top group for 2 is 0x250e440*2
2016/12/08 18:14:35.972 kid2| src/adaptation/AccessCheck.cc(185) callBack: 0x250e440*2
2016/12/08 18:14:35.972 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Initiator::noteAdaptationAclCheckDone constructed, this=0x22189f0 [call15378]
2016/12/08 18:14:35.972 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/adaptation/AccessCheck.cc(187) will call Adaptation::Initiator::noteAdaptationAclCheckDone(0x250e440*5) [call15378]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(78) mustStop: AccessCheck will stop, reason: done
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(131) callEnd: Adaptation::AccessCheck::noteAnswer(ALLOWED) ends job [Stopped, reason:done job822]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(34) ~AsyncJob: AsyncJob destructed, this=0x2511548 type=AccessCheck [job822]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(141) callEnd: Adaptation::AccessCheck::noteAnswer(ALLOWED) ended 0x2511548
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Adaptation::AccessCheck::noteAnswer(ALLOWED)
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Adaptation::Initiator::noteAdaptationAclCheckDone(0x250e440*2)
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(30) make: make call Adaptation::Initiator::noteAdaptationAclCheckDone [call15378]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(117) callStart: ClientHttpRequest status in: [ job821]
2016/12/08 18:14:35.973 kid2| src/client_side_request.cc(846) noteAdaptationAclCheckDone: 0x2513418 adaptationAclCheckDone called
2016/12/08 18:14:35.973 kid2| src/client_side_request.cc(1854) startAdaptation: adaptation needed for 0x2513418
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(28) AsyncJob: AsyncJob constructed, this=0x2513328 type=Iterator [job823]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0x2560bd0 [call15379]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/base/AsyncJob.cc(20) will call AsyncJob::start() [call15379]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(146) callEnd: ClientHttpRequest status out: [ job821]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Adaptation::Initiator::noteAdaptationAclCheckDone(0x250e440*3)
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering AsyncJob::start()
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(30) make: make call AsyncJob::start [call15379]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(117) callStart: Iterator status in: [ job823]
2016/12/08 18:14:35.973 kid2| src/adaptation/icap/Options.cc(46) transferKind: url  matches no extensions; using default: Transfer-Complete
2016/12/08 18:14:35.973 kid2| src/adaptation/Iterator.cc(54) step: #1 plan: service_test_req[0..1]
2016/12/08 18:14:35.973 kid2| src/HttpRequest.cc(508) clearError: old error details: 0/0
2016/12/08 18:14:35.973 kid2| src/adaptation/Iterator.cc(80) step: using adaptation service: service_test_req
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(28) AsyncJob: AsyncJob constructed, this=0x25105e0 type=Adaptation::Icap::ModXactLauncher [job824]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0x2574ed0 [call15380]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/base/AsyncJob.cc(20) will call AsyncJob::start() [call15380]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(146) callEnd: Iterator status out: [ job823]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving AsyncJob::start()
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering AsyncJob::start()
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(30) make: make call AsyncJob::start [call15380]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(117) callStart: Adaptation::Icap::ModXactLauncher status in: [ job824]
2016/12/08 18:14:35.973 kid2| src/adaptation/icap/Launcher.cc(43) launchXaction: launching first xaction #1
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(28) AsyncJob: AsyncJob constructed, this=0x25163d8 type=Adaptation::Icap::ModXact [job825]
2016/12/08 18:14:35.973 kid2| src/adaptation/icap/Xaction.cc(50) Xaction: Adaptation::Icap::ModXact constructed, this=0x2516228 [icapxjob825]
2016/12/08 18:14:35.973 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x25389e8 owner: 2
2016/12/08 18:14:35.973 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:35.973 kid2| src/adaptation/icap/ModXact.cc(74) ModXact: initialized. [G/R job825]
2016/12/08 18:14:35.973 kid2| src/adaptation/icap/Xaction.cc(80) disableRepeats: Adaptation::Icap::ModXact from now on cannot be repeated because over icap_retry_limit [G/R job825]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0x2560bd0 [call15381]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/base/AsyncJob.cc(20) will call AsyncJob::start() [call15381]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(146) callEnd: Adaptation::Icap::ModXactLauncher status out: [ job824]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving AsyncJob::start()
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering AsyncJob::start()
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(30) make: make call AsyncJob::start [call15381]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(117) callStart: Adaptation::Icap::ModXact status in: [G/R job825]
2016/12/08 18:14:35.973 kid2| src/adaptation/icap/ModXact.cc(1783) estimateVirginBody: does not expect virgin body
2016/12/08 18:14:35.973 kid2| src/adaptation/icap/ModXact.cc(1567) decideOnPreview: preview disabled by squid.conf
2016/12/08 18:14:35.973 kid2| src/pconn.cc(169) clearHandlers: removing close handler for local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(48) cancel: will not call IdleConnList::Read [call15344] because old comm_read_cancel
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(48) cancel: will not call IdleConnList::Read [call15344] also because old comm_read_cancel
2016/12/08 18:14:35.973 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 28, type=1, handler=0, client_data=0, timeout=0
2016/12/08 18:14:35.973 kid2| src/comm.cc(794) commUnsetConnTimeout: Remove timeout for local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1
2016/12/08 18:14:35.973 kid2| src/comm.cc(768) commSetConnTimeout: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 timeout -1
2016/12/08 18:14:35.973 kid2| src/adaptation/icap/ServiceRep.cc(116) getConnection: got connection: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommConnected constructed, this=0x2223ab0 [call15382]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/adaptation/icap/Xaction.cc(126) will call Adaptation::Icap::Xaction::noteCommConnected(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228) [call15382]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(146) callEnd: Adaptation::Icap::ModXact status out: [FD 28;rw(1)G/R job825]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving AsyncJob::start()
2016/12/08 18:14:35.973 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Adaptation::Icap::Xaction::noteCommConnected(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228)
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(30) make: make call Adaptation::Icap::Xaction::noteCommConnected [call15382]
2016/12/08 18:14:35.973 kid2| src/base/AsyncJob.cc(117) callStart: Adaptation::Icap::ModXact status in: [FD 28;rw(1)G/R job825]
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommTimedout constructed, this=0x210d9c0 [call15383]
2016/12/08 18:14:35.973 kid2| src/comm.cc(768) commSetConnTimeout: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 timeout 60
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommClosed constructed, this=0x221e470 [call15384]
2016/12/08 18:14:35.973 kid2| src/comm.cc(1208) comm_add_close_handler: comm_add_close_handler: FD 28, AsyncCall=0x221e470*1
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommRead constructed, this=0x2575290 [call15385]
2016/12/08 18:14:35.973 kid2| src/comm.cc(167) comm_read: comm_read, queueing read for local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1; asynCall 0x2575290*1
2016/12/08 18:14:35.973 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 28, type=1, handler=1, client_data=0x7ff2cba7bd38, timeout=0
2016/12/08 18:14:35.973 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommTimedout constructed, this=0x20f8350 [call15386]
2016/12/08 18:14:35.973 kid2| src/comm.cc(768) commSetConnTimeout: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 timeout 900
2016/12/08 18:14:35.973 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x2517ae8 owner: 2
2016/12/08 18:14:35.974 kid2| src/url.cc(386) urlParse: urlParse: Split URL 'www.facebook.com:443' into proto='', host='www.facebook.com', port='443', path=''
2016/12/08 18:14:35.974 kid2| src/ip/Address.cc(378) lookupHostIP: Given Non-IP 'www.facebook.com': Name or service not known
2016/12/08 18:14:35.974 kid2| src/HttpHeader.cc(713) packInto: packing hdr: (0x2517ae8)
2016/12/08 18:14:35.974 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x2517ae8 owner: 2
2016/12/08 18:14:35.974 kid2| src/HttpRequest.cc(78) ~HttpRequest: destructed, this=0x2517ad0
2016/12/08 18:14:35.974 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x2517ae8 owner: 2
2016/12/08 18:14:35.974 kid2| src/adaptation/icap/ModXact.cc(1496) makeAllowHeader: Will write Allow: 204

2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f440 checking fast ACLs
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking adaptation_meta X-Proxy-Port=13135
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking (adaptation_meta X-Proxy-Port=13135 line)
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking lp13135
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: lp13135 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: (adaptation_meta X-Proxy-Port=13135 line) = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_meta X-Proxy-Port=13135 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f440 answer DENIED for ACLs failed to match
2016/12/08 18:14:35.974 kid2| src/Notes.cc(71) match: Check for header name: X-Proxy-Port: 13135, HttpRequest: 0x249f840 HttpReply: 0 matched: 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f440 checking fast ACLs
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking adaptation_meta X-Proxy-Port=13148
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking (adaptation_meta X-Proxy-Port=13148 line)
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking lp13148
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: lp13148 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: (adaptation_meta X-Proxy-Port=13148 line) = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_meta X-Proxy-Port=13148 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f440 answer DENIED for ACLs failed to match
2016/12/08 18:14:35.974 kid2| src/Notes.cc(71) match: Check for header name: X-Proxy-Port: 13148, HttpRequest: 0x249f840 HttpReply: 0 matched: 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f440 checking fast ACLs
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking adaptation_meta X-Proxy-Port=13138
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking (adaptation_meta X-Proxy-Port=13138 line)
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking lp13138
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: lp13138 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: (adaptation_meta X-Proxy-Port=13138 line) = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_meta X-Proxy-Port=13138 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f440 answer DENIED for ACLs failed to match
2016/12/08 18:14:35.974 kid2| src/Notes.cc(71) match: Check for header name: X-Proxy-Port: 13138, HttpRequest: 0x249f840 HttpReply: 0 matched: 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f440 checking fast ACLs
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking adaptation_meta X-Proxy-Port=13146
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking (adaptation_meta X-Proxy-Port=13146 line)
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking lp13146
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: lp13146 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: (adaptation_meta X-Proxy-Port=13146 line) = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_meta X-Proxy-Port=13146 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f440 answer DENIED for ACLs failed to match
2016/12/08 18:14:35.974 kid2| src/Notes.cc(71) match: Check for header name: X-Proxy-Port: 13146, HttpRequest: 0x249f840 HttpReply: 0 matched: 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f440 checking fast ACLs
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking adaptation_meta X-Proxy-Port=13145
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking (adaptation_meta X-Proxy-Port=13145 line)
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking lp13145
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: lp13145 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: (adaptation_meta X-Proxy-Port=13145 line) = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_meta X-Proxy-Port=13145 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f440 answer DENIED for ACLs failed to match
2016/12/08 18:14:35.974 kid2| src/Notes.cc(71) match: Check for header name: X-Proxy-Port: 13145, HttpRequest: 0x249f840 HttpReply: 0 matched: 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f440 checking fast ACLs
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking adaptation_meta X-Proxy-Port=3128
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking (adaptation_meta X-Proxy-Port=3128 line)
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking lp3128
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: lp3128 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: (adaptation_meta X-Proxy-Port=3128 line) = 0
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_meta X-Proxy-Port=3128 = 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f440 answer DENIED for ACLs failed to match
2016/12/08 18:14:35.974 kid2| src/Notes.cc(71) match: Check for header name: X-Proxy-Port: 3128, HttpRequest: 0x249f840 HttpReply: 0 matched: 0
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f440 checking fast ACLs
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking adaptation_meta X-Proxy-Port=3130
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking (adaptation_meta X-Proxy-Port=3130 line)
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(157) matches: checking lp3130
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: lp3130 = 1
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: (adaptation_meta X-Proxy-Port=3130 line) = 1
2016/12/08 18:14:35.974 kid2| src/acl/Acl.cc(177) matches: checked: adaptation_meta X-Proxy-Port=3130 = 1
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f440 answer ALLOWED for match
2016/12/08 18:14:35.974 kid2| src/Notes.cc(71) match: Check for header name: X-Proxy-Port: 3130, HttpRequest: 0x249f840 HttpReply: 0 matched: 1
2016/12/08 18:14:35.974 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffdea97f440
2016/12/08 18:14:35.974 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffdea97f440
2016/12/08 18:14:35.974 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x25389e8 owner: 2
2016/12/08 18:14:35.974 kid2| src/url.cc(386) urlParse: urlParse: Split URL 'icap://127.0.0.1:1344/foo_reqmod ICAP/1.0
' into proto='icap', host='127.0.0.1', port='1344', path='/foo_reqmod ICAP/1.0'
2016/12/08 18:14:35.974 kid2| src/url.cc(422) urlParse: urlParse: URI has whitespace: {icap://127.0.0.1:1344/foo_reqmod ICAP/1.0
}
2016/12/08 18:14:35.974 kid2| src/HttpRequest.h(103) SetHost: HttpRequest::SetHost() given IP: 127.0.0.1
2016/12/08 18:14:35.974 kid2| src/HttpHeader.cc(557) parse: parsing hdr: (0x25389e8)
Host: 127.0.0.1:1344
Date: Thu, 08 Dec 2016 18:14:35 GMT
Encapsulated: req-hdr=0, null-body=41
Allow: 204
X-Client-IP: 172.16.0.43
X-Proxy-Port: 3130

2016/12/08 18:14:35.975 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommWrote constructed, this=0x2574d60 [call15387]
2016/12/08 18:14:35.975 kid2| src/comm/Write.cc(29) Write: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1: sz 256: asynCall 0x2574d60*1
2016/12/08 18:14:35.975 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 28, type=2, handler=1, client_data=0x7ff2cba7bd70, timeout=0
2016/12/08 18:14:35.975 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommTimedout constructed, this=0x2574e00 [call15388]
2016/12/08 18:14:35.975 kid2| src/comm.cc(768) commSetConnTimeout: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 timeout 900
2016/12/08 18:14:35.975 kid2| src/base/AsyncJob.cc(146) callEnd: Adaptation::Icap::ModXact status out: [FD 28wr;rw(2)G/R job825]
2016/12/08 18:14:35.975 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Adaptation::Icap::Xaction::noteCommConnected(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228)
2016/12/08 18:14:35.975 kid2| src/comm/Write.cc(60) HandleWrite: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1: off 0, sz 256.
2016/12/08 18:14:35.975 kid2| src/comm/Write.cc(100) HandleWrite: write() returns 256
2016/12/08 18:14:35.975 kid2| src/comm/IoCallback.cc(108) finish: called for local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 (0, 0)
2016/12/08 18:14:35.975 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(127) will call Adaptation::Icap::Xaction::noteCommWrote(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228) [call15387]
2016/12/08 18:14:35.975 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Adaptation::Icap::Xaction::noteCommWrote(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228)
2016/12/08 18:14:35.975 kid2| src/base/AsyncCall.cc(30) make: make call Adaptation::Icap::Xaction::noteCommWrote [call15387]
2016/12/08 18:14:35.975 kid2| src/base/AsyncJob.cc(117) callStart: Adaptation::Icap::ModXact status in: [FD 28wr;rw(2)G/R job825]
2016/12/08 18:14:35.975 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Adaptation::Icap::Xaction::noteCommTimedout constructed, this=0x20f8350 [call15389]
2016/12/08 18:14:35.975 kid2| src/comm.cc(768) commSetConnTimeout: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 timeout 900
2016/12/08 18:14:35.975 kid2| src/adaptation/icap/ModXact.cc(201) handleCommWrote: Wrote 256 bytes
2016/12/08 18:14:35.975 kid2| src/adaptation/icap/ModXact.cc(502) stopWriting: will no longer write [FD 28r;rw(2)G/R job825]
2016/12/08 18:14:35.975 kid2| src/base/AsyncJob.cc(146) callEnd: Adaptation::Icap::ModXact status out: [FD 28r;rG/Rw job825]
2016/12/08 18:14:35.975 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Adaptation::Icap::Xaction::noteCommWrote(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228)
2016/12/08 18:14:35.975 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 28, type=2, handler=0, client_data=0, timeout=0
2016/12/08 18:14:35.975 kid2| src/comm.cc(138) commHandleRead: comm_read_try: FD 28, size 65535, retval 99, errno 0
2016/12/08 18:14:35.975 kid2| src/comm/IoCallback.cc(108) finish: called for local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 (0, 0)
2016/12/08 18:14:35.975 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(127) will call Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228, size=99, buf=0x25281d0) [call15385]
2016/12/08 18:14:35.975 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228, size=99, buf=0x25281d0)
2016/12/08 18:14:35.975 kid2| src/base/AsyncCall.cc(30) make: make call Adaptation::Icap::Xaction::noteCommRead [call15385]
2016/12/08 18:14:35.975 kid2| src/base/AsyncJob.cc(117) callStart: Adaptation::Icap::ModXact status in: [FD 28r;rG/Rw job825]
2016/12/08 18:14:35.975 kid2| src/comm.cc(794) commUnsetConnTimeout: Remove timeout for local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1
2016/12/08 18:14:35.975 kid2| src/comm.cc(768) commSetConnTimeout: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 timeout -1
2016/12/08 18:14:35.975 kid2| src/adaptation/icap/Xaction.cc(413) noteCommRead: read 99 bytes
2016/12/08 18:14:35.975 kid2| src/adaptation/icap/Xaction.cc(73) disableRetries: Adaptation::Icap::ModXact from now on cannot be retried  [FD 28;rG/Rw job825]
2016/12/08 18:14:35.975 kid2| src/adaptation/icap/ModXact.cc(646) parseMore: have 99 bytes to parse [FD 28;rG/Rw job825]
2016/12/08 18:14:35.975 kid2| src/adaptation/icap/ModXact.cc(647) parseMore: 
ICAP/1.0 200 OK
Encapsulated: req-hdr=0, null-body=41

CONNECT www.facebook.com:443 HTTP/1.0


2016/12/08 18:14:35.975 kid2| src/adaptation/icap/ModXact.cc(742) parseHeaders: parse ICAP headers
2016/12/08 18:14:35.975 kid2| src/adaptation/icap/ModXact.cc(1072) parseHead: have 99 head bytes to parse; state: 0
2016/12/08 18:14:35.975 kid2| src/HttpHeader.cc(557) parse: parsing hdr: (0x249f3a8)
Encapsulated: req-hdr=0, null-body=41

2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(1087) parseHead: parse success, consume 58 bytes, return true
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(747) parseHeaders: parse HTTP headers
2016/12/08 18:14:35.976 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x2517ae8 owner: 2
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/Xaction.cc(502) setOutcome: ICAP_MOD
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(1072) parseHead: have 41 head bytes to parse; state: 1
2016/12/08 18:14:35.976 kid2| src/url.cc(386) urlParse: urlParse: Split URL 'www.facebook.com:443' into proto='', host='www.facebook.com', port='443', path=''
2016/12/08 18:14:35.976 kid2| src/ip/Address.cc(378) lookupHostIP: Given Non-IP 'www.facebook.com': Name or service not known
2016/12/08 18:14:35.976 kid2| src/HttpHeader.cc(557) parse: parsing hdr: (0x2517ae8)

2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(1087) parseHead: parse success, consume 41 bytes, return true
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(1102) decideOnParsingBody: not expecting a body
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(1165) stopParsing: will no longer parse [FD 28;rp(1)S(2)G/Rw job825]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(609) stopSending: Enter stop sending 
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(612) stopSending: Proceed with stop sending 
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(615) stopSending: will no longer send [FD 28;S(2)G/Rwrp job825]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/Xaction.cc(80) disableRepeats: Adaptation::Icap::ModXact still cannot be repeated because sent headers [FD 28;G/RwrpS job825]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(715) disableBypass: not protecting group bypass because sent headers
2016/12/08 18:14:35.976 kid2| src/adaptation/Answer.cc(23) Forward: forwarding: 0x2517ad0
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Initiator::noteAdaptationAnswer constructed, this=0x2223ab0 [call15390]
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/adaptation/Initiate.cc(77) will call Initiator::noteAdaptationAnswer(0) [call15390]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(542) readMore: returning from readMore because reader or doneReading()
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/Xaction.cc(342) callEnd: Adaptation::Icap::ModXact done with I/O [FD 28;/RwrpS job825]
2016/12/08 18:14:35.976 kid2| src/comm.cc(1253) comm_remove_close_handler: comm_remove_close_handler: FD 28, AsyncCall=0x221e470*2
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(48) cancel: will not call Adaptation::Icap::Xaction::noteCommClosed [call15384] because comm_remove_close_handler
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/Xaction.cc(73) disableRetries: Adaptation::Icap::ModXact still cannot be retried  [FD 28;/RwrpS job825]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ServiceRep.cc(126) putConnection: pushing pconn [FD 28;/RwrpS job825]
2016/12/08 18:14:35.976 kid2| src/comm.cc(794) commUnsetConnTimeout: Remove timeout for local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1
2016/12/08 18:14:35.976 kid2| src/comm.cc(768) commSetConnTimeout: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 timeout -1
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall IdleConnList::Read constructed, this=0x210d9c0 [call15391]
2016/12/08 18:14:35.976 kid2| src/comm.cc(167) comm_read: comm_read, queueing read for local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1; asynCall 0x210d9c0*1
2016/12/08 18:14:35.976 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 28, type=1, handler=1, client_data=0x7ff2cba7bd38, timeout=0
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall IdleConnList::Timeout constructed, this=0x2569cd0 [call15392]
2016/12/08 18:14:35.976 kid2| src/comm.cc(768) commSetConnTimeout: local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1 timeout 60
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(131) callEnd: Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228, size=99, buf=0x25281d0) ends job [/RwrpS job825]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(1235) swanSong: swan sings [/RwrpS job825]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(609) stopSending: Enter stop sending 
2016/12/08 18:14:35.976 kid2| src/adaptation/Initiate.cc(58) swanSong: swan sings [/RwrpS job825]
2016/12/08 18:14:35.976 kid2| src/adaptation/Initiate.cc(65) swanSong: swan sang [/RwrpS job825]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/Xaction.cc(59) ~Xaction: Adaptation::Icap::ModXact destructed, this=0x2516228 [icapxjob825]
2016/12/08 18:14:35.976 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x25389e8 owner: 2
2016/12/08 18:14:35.976 kid2| src/HttpRequest.cc(78) ~HttpRequest: destructed, this=0x25389d0
2016/12/08 18:14:35.976 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x25389e8 owner: 2
2016/12/08 18:14:35.976 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:35.976 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(34) ~AsyncJob: AsyncJob destructed, this=0x25163d8 type=Adaptation::Icap::ModXact [job825]
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(141) callEnd: Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228, size=99, buf=0x25281d0) ended 0x25163d8
2016/12/08 18:14:35.976 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:53018 remote=127.0.0.1:1344 FD 28 flags=1, data=0x2516228, size=99, buf=0x25281d0)
2016/12/08 18:14:35.976 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Initiator::noteAdaptationAnswer(0)
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(30) make: make call Initiator::noteAdaptationAnswer [call15390]
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(117) callStart: Adaptation::Icap::ModXactLauncher status in: [ job824]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/Launcher.cc(58) noteAdaptationAnswer: launches: 1 answer: 0
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Initiator::noteAdaptationAnswer constructed, this=0x2575290 [call15393]
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/adaptation/Initiate.cc(77) will call Initiator::noteAdaptationAnswer(0) [call15393]
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(131) callEnd: Initiator::noteAdaptationAnswer(0) ends job [ job824]
2016/12/08 18:14:35.976 kid2| src/adaptation/icap/ModXact.cc(1966) swanSong: swan sings
2016/12/08 18:14:35.976 kid2| src/adaptation/Initiate.cc(58) swanSong: swan sings [ job824]
2016/12/08 18:14:35.976 kid2| src/adaptation/Initiate.cc(65) swanSong: swan sang [ job824]
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(34) ~AsyncJob: AsyncJob destructed, this=0x25105e0 type=Adaptation::Icap::ModXactLauncher [job824]
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(141) callEnd: Initiator::noteAdaptationAnswer(0) ended 0x25105e0
2016/12/08 18:14:35.976 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Initiator::noteAdaptationAnswer(0)
2016/12/08 18:14:35.976 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Initiator::noteAdaptationAnswer(0)
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(30) make: make call Initiator::noteAdaptationAnswer [call15393]
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(117) callStart: Iterator status in: [ job823]
2016/12/08 18:14:35.976 kid2| src/adaptation/ServiceGroups.cc(181) findService: service_test_req has no matching services
2016/12/08 18:14:35.976 kid2| src/adaptation/Iterator.cc(54) step: #2 plan: service_test_req[1..1.]
2016/12/08 18:14:35.976 kid2| src/adaptation/Answer.cc(23) Forward: forwarding: 0x2517ad0
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Initiator::noteAdaptationAnswer constructed, this=0x2223ab0 [call15394]
2016/12/08 18:14:35.976 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/adaptation/Initiate.cc(77) will call Initiator::noteAdaptationAnswer(0) [call15394]
2016/12/08 18:14:35.976 kid2| src/base/AsyncJob.cc(131) callEnd: Initiator::noteAdaptationAnswer(0) ends job [ job823]
2016/12/08 18:14:35.977 kid2| src/adaptation/Initiate.cc(58) swanSong: swan sings [ job823]
2016/12/08 18:14:35.977 kid2| src/adaptation/Initiate.cc(65) swanSong: swan sang [ job823]
2016/12/08 18:14:35.977 kid2| src/base/AsyncJob.cc(34) ~AsyncJob: AsyncJob destructed, this=0x2513328 type=Iterator [job823]
2016/12/08 18:14:35.977 kid2| src/base/AsyncJob.cc(141) callEnd: Initiator::noteAdaptationAnswer(0) ended 0x2513328
2016/12/08 18:14:35.977 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Initiator::noteAdaptationAnswer(0)
2016/12/08 18:14:35.977 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Initiator::noteAdaptationAnswer(0)
2016/12/08 18:14:35.977 kid2| src/base/AsyncCall.cc(30) make: make call Initiator::noteAdaptationAnswer [call15394]
2016/12/08 18:14:35.977 kid2| src/base/AsyncJob.cc(117) callStart: ClientHttpRequest status in: [ job821]
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1727) doCallouts: Doing calloutContext->clientAccessCheck2()
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(734) clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(759) clientAccessCheckDone: The request CONNECT www.facebook.com:443 is ALLOWED; last ACL checked: lp3130
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1746) doCallouts: Doing clientInterpretRequestHeaders()
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1197) clientInterpretRequestHeaders: clientInterpretRequestHeaders: REQ_NOCACHE = NOT SET
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1199) clientInterpretRequestHeaders: clientInterpretRequestHeaders: REQ_CACHABLE = SET
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1201) clientInterpretRequestHeaders: clientInterpretRequestHeaders: REQ_HIERARCHICAL = NOT SET
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1755) doCallouts: Doing calloutContext->checkNoCache()
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(62) preCheck: 0x2516068 checking slow rules
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(157) matches: checking cache
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(157) matches: checking cache#1
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(157) matches: checking all
2016/12/08 18:14:35.977 kid2| src/acl/Ip.cc(560) match: aclIpMatchIp: '172.16.0.43:35114' found
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(177) matches: checked: all = 1
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(177) matches: checked: cache#1 = 1
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(177) matches: checked: cache = 1
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(55) markFinished: 0x2516068 answer DENIED for match
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(155) checkCallback: ACLChecklist::checkCallback: 0x2516068 answer=DENIED
2016/12/08 18:14:35.977 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffdea97f0c0
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffdea97f0c0
2016/12/08 18:14:35.977 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffdea97f0c0
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffdea97f0c0
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1469) sslBumpAccessCheck: SslBump possible, checking ACL
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(62) preCheck: 0x2517878 checking slow rules
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(157) matches: checking (ssl_bump rules)
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(157) matches: checking (ssl_bump rule)
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(157) matches: checking socialnetworksssl
2016/12/08 18:14:35.977 kid2| src/acl/DomainData.cc(131) match: aclMatchDomainList: checking 'www.facebook.com'
2016/12/08 18:14:35.977 kid2| src/acl/DomainData.cc(135) match: aclMatchDomainList: 'www.facebook.com' found
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(177) matches: checked: socialnetworksssl = 1
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(177) matches: checked: (ssl_bump rule) = 1
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(177) matches: checked: (ssl_bump rules) = 1
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(55) markFinished: 0x2517878 answer ALLOWED for match
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(155) checkCallback: ACLChecklist::checkCallback: 0x2517878 answer=ALLOWED
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1551) sslBumpNeed: sslBump required: client-first
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(137) ~ClientRequestContext: 0x250fb88 ClientRequestContext destructed
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1835) doCallouts: calling processRequest()
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1513) processRequest: clientProcessRequest: CONNECT 'www.facebook.com:443'
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1597) sslBumpStart: Confirming client-first-bumped CONNECT tunnel on FD local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1
2016/12/08 18:14:35.977 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall ClientSocketContext::sslBumpEstablish constructed, this=0x2575290 [call15395]
2016/12/08 18:14:35.977 kid2| src/comm/Write.cc(29) Write: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: sz 39: asynCall 0x2575290*1
2016/12/08 18:14:35.977 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=2, handler=1, client_data=0x7ff2cba7bcf8, timeout=0
2016/12/08 18:14:35.977 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x2517878
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x2517878
2016/12/08 18:14:35.977 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x2516068
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x2516068
2016/12/08 18:14:35.977 kid2| src/base/AsyncJob.cc(146) callEnd: ClientHttpRequest status out: [ job821]
2016/12/08 18:14:35.977 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Initiator::noteAdaptationAnswer(0)
2016/12/08 18:14:35.977 kid2| src/comm/Write.cc(60) HandleWrite: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: off 0, sz 39.
2016/12/08 18:14:35.977 kid2| src/comm/Write.cc(100) HandleWrite: write() returns 39
2016/12/08 18:14:35.977 kid2| src/comm/IoCallback.cc(108) finish: called for local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 (0, 0)
2016/12/08 18:14:35.977 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(127) will call ClientSocketContext::sslBumpEstablish(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2513418, size=39, buf=0x797dd0) [call15395]
2016/12/08 18:14:35.977 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering ClientSocketContext::sslBumpEstablish(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2513418, size=39, buf=0x797dd0)
2016/12/08 18:14:35.977 kid2| src/base/AsyncCall.cc(30) make: make call ClientSocketContext::sslBumpEstablish [call15395]
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(1560) SslBumpEstablish: responded to CONNECT: 0x2513418 ? 0
2016/12/08 18:14:35.977 kid2| src/client_side.cc(4015) switchToHttps: converting local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 to SSL
2016/12/08 18:14:35.977 kid2| src/clientStream.cc(225) clientStreamDetach: clientStreamDetach: Detaching node 0x25106f8
2016/12/08 18:14:35.977 kid2| src/clientStream.cc(310) clientStreamFree: Freeing clientStreamNode 0x25106f8
2016/12/08 18:14:35.977 kid2| src/clientStream.cc(246) clientStreamDetach: clientStreamDetach: Calling 1 with cbdata 0x2515e98
2016/12/08 18:14:35.977 kid2| src/clientStream.cc(225) clientStreamDetach: clientStreamDetach: Detaching node 0x250bb78
2016/12/08 18:14:35.977 kid2| src/clientStream.cc(310) clientStreamFree: Freeing clientStreamNode 0x250bb78
2016/12/08 18:14:35.977 kid2| src/client_side_request.cc(265) ~ClientHttpRequest: httpRequestFree: www.facebook.com:443
2016/12/08 18:14:35.977 kid2| src/client_side.cc(617) logRequest: logging half-baked transaction: www.facebook.com:443
2016/12/08 18:14:35.977 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f4e0 checking fast ACLs
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(157) matches: checking access_log stdio:/var/log/squid/access.log
2016/12/08 18:14:35.977 kid2| src/acl/Acl.cc(157) matches: checking (access_log stdio:/var/log/squid/access.log line)
2016/12/08 18:14:35.978 kid2| src/acl/Acl.cc(177) matches: checked: (access_log stdio:/var/log/squid/access.log line) = 1
2016/12/08 18:14:35.978 kid2| src/acl/Acl.cc(177) matches: checked: access_log stdio:/var/log/squid/access.log = 1
2016/12/08 18:14:35.978 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f4e0 answer ALLOWED for match
2016/12/08 18:14:35.978 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffdea97f4e0
2016/12/08 18:14:35.978 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffdea97f4e0
2016/12/08 18:14:35.978 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Initiate::noteInitiatorAborted constructed, this=0x2560bd0 [call15396]
2016/12/08 18:14:35.978 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/adaptation/Initiator.cc(34) will call Initiate::noteInitiatorAborted() [call15396]
2016/12/08 18:14:35.978 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x2517ae8 owner: 2
2016/12/08 18:14:35.978 kid2| src/HttpRequest.cc(78) ~HttpRequest: destructed, this=0x2517ad0
2016/12/08 18:14:35.978 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x2517ae8 owner: 2
2016/12/08 18:14:35.978 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f858 owner: 2
2016/12/08 18:14:35.978 kid2| src/HttpRequest.cc(78) ~HttpRequest: destructed, this=0x249f840
2016/12/08 18:14:35.978 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f858 owner: 2
2016/12/08 18:14:35.978 kid2| src/base/AsyncJob.cc(34) ~AsyncJob: AsyncJob destructed, this=0x2513570 type=ClientHttpRequest [job821]
2016/12/08 18:14:35.978 kid2| src/client_side.cc(3983) getSslContextDone: Using static ssl context.
2016/12/08 18:14:35.978 kid2| src/client_side.cc(3496) httpsCreate: httpsCreate: will negotate SSL on local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1
2016/12/08 18:14:35.978 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall ConnStateData::requestTimeout constructed, this=0x23aa110 [call15397]
2016/12/08 18:14:35.978 kid2| src/comm.cc(768) commSetConnTimeout: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 timeout 300
2016/12/08 18:14:35.978 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=1, handler=0, client_data=0, timeout=0
2016/12/08 18:14:35.978 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=1, handler=1, client_data=0x2512f88, timeout=0
2016/12/08 18:14:35.978 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving ClientSocketContext::sslBumpEstablish(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2513418, size=39, buf=0x797dd0)
2016/12/08 18:14:35.978 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Initiate::noteInitiatorAborted()
2016/12/08 18:14:35.978 kid2| src/base/AsyncCall.cc(30) make: make call Initiate::noteInitiatorAborted [call15396]
2016/12/08 18:14:35.978 kid2| src/base/AsyncCall.cc(48) cancel: will not call Initiate::noteInitiatorAborted [call15396] because job gone
2016/12/08 18:14:35.978 kid2| src/base/AsyncCall.cc(40) make: will not call Initiate::noteInitiatorAborted [call15396] because of job gone
2016/12/08 18:14:35.978 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Initiate::noteInitiatorAborted()
2016/12/08 18:14:35.978 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=2, handler=0, client_data=0, timeout=0
2016/12/08 18:14:36.035 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=1, handler=1, client_data=0x2512f88, timeout=0
-----BEGIN SSL SESSION PARAMETERS-----
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX=
-----END SSL SESSION PARAMETERS-----
2016/12/08 18:14:36.085 kid2| src/client_side.cc(3594) clientNegotiateSSL: clientNegotiateSSL: New session 0x2574d60 on FD 27 (172.16.0.43:35114)
2016/12/08 18:14:36.085 kid2| src/client_side.cc(3598) clientNegotiateSSL: clientNegotiateSSL: FD 27 negotiated cipher AES256-GCM-SHA384
2016/12/08 18:14:36.086 kid2| src/client_side.cc(3614) clientNegotiateSSL: clientNegotiateSSL: FD 27 has no certificate.
2016/12/08 18:14:36.086 kid2| src/client_side.cc(258) readSomeData: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: reading request...
2016/12/08 18:14:36.086 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall ConnStateData::clientReadRequest constructed, this=0x221e480 [call15398]
2016/12/08 18:14:36.086 kid2| src/comm.cc(167) comm_read: comm_read, queueing read for local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1; asynCall 0x221e480*1
2016/12/08 18:14:36.086 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=1, handler=1, client_data=0x7ff2cba7bcc0, timeout=0
2016/12/08 18:14:36.131 kid2| src/comm.cc(138) commHandleRead: comm_read_try: FD 27, size 4095, retval 40, errno 0
2016/12/08 18:14:36.131 kid2| src/comm/IoCallback.cc(108) finish: called for local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 (0, 0)
2016/12/08 18:14:36.131 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(127) will call ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2512f88, size=40, buf=0x24a20d0) [call15398]
2016/12/08 18:14:36.131 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2512f88, size=40, buf=0x24a20d0)
2016/12/08 18:14:36.131 kid2| src/base/AsyncCall.cc(30) make: make call ConnStateData::clientReadRequest [call15398]
2016/12/08 18:14:36.131 kid2| src/base/AsyncJob.cc(117) callStart: ConnStateData status in: [ job820]
2016/12/08 18:14:36.131 kid2| src/client_side.cc(3042) clientReadRequest: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 size 40
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2981) clientParseRequests: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: attempting to parse
2016/12/08 18:14:36.131 kid2| src/HttpParser.cc(29) reset: Request buffer is GET / HTTP/1.0
Host: 172.16.32.219:443


2016/12/08 18:14:36.131 kid2| src/HttpParser.cc(39) parseRequestFirstLine: parsing possible request: GET / HTTP/1.0
Host: 172.16.32.219:443


2016/12/08 18:14:36.131 kid2| src/HttpParser.cc(249) HttpParserParseReqLine: Parser: retval 1: from 0->14: method 0->2; url 4->4; version 6->13 (1/0)
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2322) parseHttpRequest: parseHttpRequest: req_hdr = {Host: 172.16.32.219:443

}
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2326) parseHttpRequest: parseHttpRequest: end = {
}
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2330) parseHttpRequest: parseHttpRequest: prefix_sz = 40, req_line_sz = 15
2016/12/08 18:14:36.131 kid2| src/base/AsyncJob.cc(28) AsyncJob: AsyncJob constructed, this=0x2513570 type=ClientHttpRequest [job826]
2016/12/08 18:14:36.131 kid2| src/clientStream.cc(167) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x25106f8 with data 0x2514c40 after head
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2346) parseHttpRequest: parseHttpRequest: Request Header is
Host: 172.16.32.219:443


2016/12/08 18:14:36.131 kid2| src/client_side.cc(2367) parseHttpRequest: repare absolute URL from 
2016/12/08 18:14:36.131 kid2| src/mime_header.cc(59) mime_get_header_field: mime_get_header: looking for 'Host'
2016/12/08 18:14:36.131 kid2| src/mime_header.cc(81) mime_get_header_field: mime_get_header: checking 'Host: 172.16.32.219:443'
2016/12/08 18:14:36.131 kid2| src/mime_header.cc(104) mime_get_header_field: mime_get_header: returning '172.16.32.219:443'
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2137) prepareAcceleratedURL: ACCEL VHOST REWRITE: vhost=172.16.32.219:443 + vport=0
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2157) prepareAcceleratedURL: ACCEL VHOST REWRITE: 'https://172.16.32.219:443/'
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2404) parseHttpRequest: parseHttpRequest: Complete request received
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2407) parseHttpRequest: HTTP Client local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1
2016/12/08 18:14:36.131 kid2| src/client_side.cc(2408) parseHttpRequest: HTTP Client REQUEST:
---------
GET / HTTP/1.0
Host: 172.16.32.219:443


----------
2016/12/08 18:14:36.131 kid2| src/client_side.cc(3019) clientParseRequests: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: parsed a request
2016/12/08 18:14:36.131 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall clientLifetimeTimeout constructed, this=0x2223ab0 [call15399]
2016/12/08 18:14:36.131 kid2| src/comm.cc(768) commSetConnTimeout: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 timeout 86400
2016/12/08 18:14:36.131 kid2| src/url.cc(386) urlParse: urlParse: Split URL 'https://172.16.32.219:443/' into proto='https', host='172.16.32.219', port='443', path='/'
2016/12/08 18:14:36.131 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x249f858 owner: 2
2016/12/08 18:14:36.131 kid2| src/HttpRequest.cc(70) HttpRequest: constructed, this=0x249f840 id=9
2016/12/08 18:14:36.131 kid2| src/HttpRequest.h(103) SetHost: HttpRequest::SetHost() given IP: 172.16.32.219
2016/12/08 18:14:36.131 kid2| src/HttpHeader.cc(557) parse: parsing hdr: (0x249f858)
Host: 172.16.32.219:443

2016/12/08 18:14:36.131 kid2| src/client_side.cc(925) clientSetKeepaliveFlag: clientSetKeepaliveFlag: http_ver = 1.0
2016/12/08 18:14:36.131 kid2| src/client_side.cc(927) clientSetKeepaliveFlag: clientSetKeepaliveFlag: method = GET
2016/12/08 18:14:36.131 kid2| src/client_side_request.cc(152) ClientRequestContext: 0x250fb88 ClientRequestContext constructed
2016/12/08 18:14:36.131 kid2| src/client_side_request.cc(1691) doCallouts: Doing calloutContext->hostHeaderVerify()
2016/12/08 18:14:36.131 kid2| src/client_side_request.cc(648) hostHeaderVerify: validate host=172.16.32.219, port=443, portStr=443
2016/12/08 18:14:36.131 kid2| src/client_side_request.cc(662) hostHeaderVerify: validate skipped.
2016/12/08 18:14:36.131 kid2| src/client_side_request.cc(1698) doCallouts: Doing calloutContext->clientAccessCheck()
2016/12/08 18:14:36.131 kid2| src/acl/Checklist.cc(62) preCheck: 0x2516068 checking slow rules
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(157) matches: checking http_access
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(157) matches: checking http_access#1
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(157) matches: checking manager
2016/12/08 18:14:36.131 kid2| src/acl/RegexData.cc(71) match: aclRegexData::match: checking 'https://172.16.32.219/'
2016/12/08 18:14:36.131 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(^cache_object://)'
2016/12/08 18:14:36.131 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(^https?://[^/]+/squid-internal-mgr/)'
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(177) matches: checked: manager = 0
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(177) matches: checked: http_access#1 = 0
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(157) matches: checking http_access#2
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(157) matches: checking manager
2016/12/08 18:14:36.131 kid2| src/acl/RegexData.cc(71) match: aclRegexData::match: checking 'https://172.16.32.219/'
2016/12/08 18:14:36.131 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(^cache_object://)'
2016/12/08 18:14:36.131 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(^https?://[^/]+/squid-internal-mgr/)'
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(177) matches: checked: manager = 0
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(177) matches: checked: http_access#2 = 0
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(157) matches: checking http_access#3
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(157) matches: checking healthcheck
2016/12/08 18:14:36.131 kid2| src/acl/RegexData.cc(71) match: aclRegexData::match: checking 'https://172.16.32.219/'
2016/12/08 18:14:36.131 kid2| src/acl/RegexData.cc(82) match: aclRegexData::match: looking for '(sw_proxy_health_check$)'
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(177) matches: checked: healthcheck = 0
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(177) matches: checked: http_access#3 = 0
2016/12/08 18:14:36.131 kid2| src/acl/Acl.cc(157) matches: checking http_access#4
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(157) matches: checking !Safe_ports
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(157) matches: checking Safe_ports
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: Safe_ports = 1
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: !Safe_ports = 0
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: http_access#4 = 0
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(157) matches: checking http_access#5
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(157) matches: checking CONNECT
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: CONNECT = 0
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: http_access#5 = 0
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(157) matches: checking http_access#6
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(157) matches: checking socialnetworks
2016/12/08 18:14:36.132 kid2| src/acl/DomainData.cc(131) match: aclMatchDomainList: checking '172.16.32.219'
2016/12/08 18:14:36.132 kid2| src/acl/DomainData.cc(135) match: aclMatchDomainList: '172.16.32.219' NOT found
2016/12/08 18:14:36.132 kid2| src/ipcache.cc(961) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '172.16.32.219' == 172.16.32.219
2016/12/08 18:14:36.132 kid2| src/acl/DestinationDomain.cc(109) match: aclMatchAcl: Can't yet compare 'socialnetworks' ACL for '172.16.32.219'
2016/12/08 18:14:36.132 kid2| src/fqdncache.cc(542) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: Name '172.16.32.219'.
2016/12/08 18:14:36.132 kid2| src/fqdncache.cc(564) fqdncache_nbgethostbyaddr: fqdncache_nbgethostbyaddr: HIT for '172.16.32.219'
2016/12/08 18:14:36.132 kid2| src/acl/DomainData.cc(131) match: aclMatchDomainList: checking 'none'
2016/12/08 18:14:36.132 kid2| src/acl/DomainData.cc(135) match: aclMatchDomainList: 'none' NOT found
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: socialnetworks = 0
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: http_access#6 = 0
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(157) matches: checking http_access#7
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(157) matches: checking passthrough
2016/12/08 18:14:36.132 kid2| src/acl/DomainData.cc(131) match: aclMatchDomainList: checking '172.16.32.219'
2016/12/08 18:14:36.132 kid2| src/acl/DomainData.cc(135) match: aclMatchDomainList: '172.16.32.219' NOT found
2016/12/08 18:14:36.132 kid2| src/ipcache.cc(961) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '172.16.32.219' == 172.16.32.219
2016/12/08 18:14:36.132 kid2| src/acl/DomainData.cc(131) match: aclMatchDomainList: checking 'none'
2016/12/08 18:14:36.132 kid2| src/acl/DomainData.cc(135) match: aclMatchDomainList: 'none' NOT found
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: passthrough = 0
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: http_access#7 = 0
2016/12/08 18:14:36.132 kid2| src/acl/Acl.cc(177) matches: checked: http_access = 0
2016/12/08 18:14:36.132 kid2| src/acl/Checklist.cc(378) calcImplicitAnswer: 0x2516068 NO match found, last action ALLOWED so returning DENIED
2016/12/08 18:14:36.132 kid2| src/acl/Checklist.cc(55) markFinished: 0x2516068 answer DENIED for implicit rule won
2016/12/08 18:14:36.132 kid2| src/acl/Checklist.cc(155) checkCallback: ACLChecklist::checkCallback: 0x2516068 answer=DENIED
2016/12/08 18:14:36.132 kid2| src/client_side_request.cc(759) clientAccessCheckDone: The request GET https://172.16.32.219:443/ is DENIED; last ACL checked: passthrough
2016/12/08 18:14:36.132 kid2| src/acl/Gadgets.cc(103) aclIsProxyAuth: aclIsProxyAuth: called for passthrough
2016/12/08 18:14:36.132 kid2| src/acl/Gadgets.cc(108) aclIsProxyAuth: aclIsProxyAuth: returning 0
2016/12/08 18:14:36.132 kid2| src/client_side_request.cc(775) clientAccessCheckDone: Access Denied: https://172.16.32.219:443/
2016/12/08 18:14:36.132 kid2| src/client_side_request.cc(776) clientAccessCheckDone: AclMatchedName = passthrough
2016/12/08 18:14:36.132 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffdea97ebe0
2016/12/08 18:14:36.132 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffdea97ebe0
2016/12/08 18:14:36.132 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffdea97ebe0
2016/12/08 18:14:36.132 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffdea97ebe0
2016/12/08 18:14:36.132 kid2| src/client_side_request.cc(1443) sslBumpAccessCheck: SslBump already decided (1), ignoring ssl_bump for 0x2512f88
2016/12/08 18:14:36.132 kid2| src/HttpRequest.cc(711) storeId: sent back canonicalUrl:https://172.16.32.219/
2016/12/08 18:14:36.132 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:36.132 kid2| src/store_key_md5.cc(109) storeKeyPrivate: storeKeyPrivate: GET https://172.16.32.219/
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(615) errorAppendEntry: Creating an error page for entry 0x255f7f0 with errorstate 0x255f698 page id 1
2016/12/08 18:14:36.132 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x2559a68 owner: 3
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1278) BuildContent: No existing error page language negotiated for ERR_ACCESS_DENIED. Using default error file.
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%l --> '/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates
 http://www.freecsstemplates.org
 Released for free under a Creative Commons Attribution 2.5 License
*/

/* Page basics */
* {
	font-family: verdana, sans-serif;
}

html body {
	margin: 0;
	padding: 0;
	background: #efefef;
	font-size: 12px;
	color: #1e1e1e;
}

/* Page displayed title area */
#titles {
	margin-left: 15px;
	padding: 10px;
	padding-left: 100px;
	background: url('http://www.squid-cache.org/Artwork/SN.png') no-repeat left;
}

/* initial title */
#titles h1 {
	color: #000000;
}
#titles h2 {
	color: #000000;
}

/* special event: FTP success page titles */
#titles ftpsuccess {
	background-color:#00ff00;
	width:100%;
}

/* Page displayed body content area */
#content {
	padding: 10px;
	background: #ffffff;
}

/* General text */
p {
}

/* error brief description */
#error p {
}

/* some data which may have caused the problem */
#data {
}

/* the error message received from the system or other software */
#sysmsg {
}

pre {
    font-family:sans-serif;
}

/* special event: FTP / Gopher directory listing */
#dirmsg {
    font-family: courier;
    color: black;
    font-size: 10pt;
}
#dirlisting {
    margin-left: 2%;
    margin-right: 2%;
}
#dirlisting tr.entry td.icon,td.filename,td.size,td.date {
    border-bottom: groove;
}
#dirlisting td.size {
    width: 50px;
    text-align: right;
    padding-right: 5px;
}

/* horizontal lines */
hr {
	margin: 0;
}

/* page displayed footer area */
#footer {
	font-size: 9px;
	padding-left: 10px;
}
'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%; --> '%;'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%c --> 'ERR_ACCESS_DENIED'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%U --> 'https://172.16.32.219/'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%U --> 'https://172.16.32.219/'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%w --> 'webmaster'
2016/12/08 18:14:36.132 kid2| src/HttpHeader.cc(713) packInto: packing hdr: (0x249f858)
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%W --> '?subject=CacheErrorInfo%20-%20ERR_ACCESS_DENIED&body=CacheHost%3A%20localhost%0D%0AErrPage%3A%20ERR_ACCESS_DENIED%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Thu,%2008%20Dec%202016%2018%3A14%3A36%20GMT%0D%0A%0D%0AClientIP%3A%20172.16.0.43%0D%0A%0D%0AHTTP%20Request%3A%0D%0AGET%20%2F%20HTTP%2F1.0%0AHost%3A%20172.16.32.219%3A443%0D%0A%0D%0A%0D%0A'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%w --> 'webmaster'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%T --> 'Thu, 08 Dec 2016 18:14:36 GMT'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%h --> 'localhost'
2016/12/08 18:14:36.132 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%s --> 'squid'
2016/12/08 18:14:36.133 kid2| src/errorpage.cc(1117) Convert: errorConvert: %%c --> 'ERR_ACCESS_DENIED'
2016/12/08 18:14:36.133 kid2| src/HttpRequest.cc(496) detailError: current error details: 1/0
2016/12/08 18:14:36.133 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:36.133 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:36.133 kid2| src/HttpHeader.cc(713) packInto: packing hdr: (0x2559a68)
2016/12/08 18:14:36.134 kid2| src/store_dir.cc(824) maybeTrimMemory: keepInLocalMemory: 1
2016/12/08 18:14:36.134 kid2| src/store_client.cc(761) invokeHandlers: InvokeHandlers: FB0F4AC67B901ACF463CE31BE1D89D3C
2016/12/08 18:14:36.134 kid2| src/store_client.cc(767) invokeHandlers: StoreEntry::InvokeHandlers: checking client #0
2016/12/08 18:14:36.134 kid2| src/store_dir.cc(824) maybeTrimMemory: keepInLocalMemory: 1
2016/12/08 18:14:36.134 kid2| src/store_client.cc(761) invokeHandlers: InvokeHandlers: FB0F4AC67B901ACF463CE31BE1D89D3C
2016/12/08 18:14:36.134 kid2| src/store_client.cc(767) invokeHandlers: StoreEntry::InvokeHandlers: checking client #0
2016/12/08 18:14:36.134 kid2| src/clientStream.cc(207) clientStreamRead: clientStreamRead: Calling 1 with cbdata 0x2515e98 from node 0x25106f8
2016/12/08 18:14:36.134 kid2| src/store_client.cc(222) copy: store_client::copy: FB0F4AC67B901ACF463CE31BE1D89D3C, from 0, for length 4096, cb 1, cbdata 0x2514de8
2016/12/08 18:14:36.134 kid2| src/store_client.cc(317) storeClientCopy2: storeClientCopy2: FB0F4AC67B901ACF463CE31BE1D89D3C
2016/12/08 18:14:36.134 kid2| src/store_client.cc(349) doCopy: store_client::doCopy: co: 0, hi: 3282
2016/12/08 18:14:36.134 kid2| src/store_client.cc(450) scheduleMemRead: store_client::doCopy: Copying normal from memory
2016/12/08 18:14:36.134 kid2| src/client_side_reply.cc(2122) sendMoreData: clientReplyContext::sendMoreData: https://172.16.32.219/, 3282 bytes (3282 new bytes)
2016/12/08 18:14:36.134 kid2| src/client_side_reply.cc(2126) sendMoreData: clientReplyContext::sendMoreData:local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 'https://172.16.32.219/' out.offset=0
2016/12/08 18:14:36.134 kid2| src/HttpHeader.cc(407) HttpHeader: init-ing hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:36.134 kid2| src/HttpHeader.cc(491) append: appending hdr: 0x249f3a8 += 0x2559a68
2016/12/08 18:14:36.135 kid2| src/client_side_reply.cc(1474) buildReplyHeader: clientBuildReplyHeader: bumped reply forces close
2016/12/08 18:14:36.135 kid2| src/client_side_reply.cc(1969) processReplyAccessResult: The reply for GET https://172.16.32.219/ is ALLOWED, because it matched 'passthrough'
2016/12/08 18:14:36.135 kid2| src/client_side_reply.cc(2007) processReplyAccessResult: clientReplyContext::sendMoreData: Appending 3057 bytes after 225 bytes of headers
2016/12/08 18:14:36.135 kid2| src/clientStream.cc(185) clientStreamCallback: clientStreamCallback: Calling 1 with cbdata 0x2514c40 from node 0x250bb78
2016/12/08 18:14:36.135 kid2| src/HttpHeader.cc(713) packInto: packing hdr: (0x249f3a8)
2016/12/08 18:14:36.135 kid2| src/client_side.cc(1459) sendStartOfMessage: HTTP Client local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1
2016/12/08 18:14:36.135 kid2| src/client_side.cc(1460) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Thu, 08 Dec 2016 18:14:36 GMT
Content-Type: text/html
Content-Length: 3057
X-Squid-Error: ERR_ACCESS_DENIED 0
Vary: Accept-Language
Content-Language: en
X-Cache: MISS from localhost
Via: 1.1 localhost (squid)
Connection: close


----------
2016/12/08 18:14:36.135 kid2| src/client_side.cc(1483) sendStartOfMessage: sendStartOfMessage schedules clientWriteComplete
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall clientWriteComplete constructed, this=0x25135a0 [call15400]
2016/12/08 18:14:36.135 kid2| src/comm/Write.cc(29) Write: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: sz 3359: asynCall 0x25135a0*1
2016/12/08 18:14:36.135 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=2, handler=1, client_data=0x7ff2cba7bcf8, timeout=0
2016/12/08 18:14:36.135 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x2516068
2016/12/08 18:14:36.135 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x2516068
2016/12/08 18:14:36.135 kid2| src/client_side.cc(2510) connNoteUseOfBuffer: conn->in.notYetUsed = 0
2016/12/08 18:14:36.135 kid2| src/client_side.cc(258) readSomeData: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: reading request...
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall ConnStateData::clientReadRequest constructed, this=0x2513630 [call15401]
2016/12/08 18:14:36.135 kid2| src/comm.cc(167) comm_read: comm_read, queueing read for local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1; asynCall 0x2513630*1
2016/12/08 18:14:36.135 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=1, handler=1, client_data=0x7ff2cba7bcc0, timeout=0
2016/12/08 18:14:36.135 kid2| src/base/AsyncJob.cc(146) callEnd: ConnStateData status out: [ job820]
2016/12/08 18:14:36.135 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2512f88, size=40, buf=0x24a20d0)
2016/12/08 18:14:36.135 kid2| src/comm/Write.cc(60) HandleWrite: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1: off 0, sz 3359.
2016/12/08 18:14:36.135 kid2| src/comm/Write.cc(100) HandleWrite: write() returns 3359
2016/12/08 18:14:36.135 kid2| src/comm/IoCallback.cc(108) finish: called for local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 (0, 0)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(127) will call clientWriteComplete(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2513bc8) [call15400]
2016/12/08 18:14:36.135 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering clientWriteComplete(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, data=0x2513bc8)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(30) make: make call clientWriteComplete [call15400]
2016/12/08 18:14:36.135 kid2| src/client_side.cc(1943) writeComplete: local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, sz 3359, err 0, off 3359, len 3282
2016/12/08 18:14:36.135 kid2| src/client_side_reply.cc(1073) storeOKTransferDone: storeOKTransferDone  out.offset=3057 objectLen()=3282 headers_sz=225
2016/12/08 18:14:36.135 kid2| src/client_side_reply.cc(1185) replyStatus: clientReplyStatus: transfer is DONE
2016/12/08 18:14:36.135 kid2| src/client_side_reply.cc(1210) replyStatus: clientReplyStatus: stream was not expected to complete!
2016/12/08 18:14:36.135 kid2| src/client_side.cc(1917) stopSending: sending error (local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1): STREAM_UNPLANNED_COMPLETE; old receiving error: none
2016/12/08 18:14:36.135 kid2| src/comm.cc(1080) _comm_close: comm_close: start closing FD 27
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall commStartSslClose constructed, this=0x25776a0 [call15402]
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm.cc(1114) will call commStartSslClose(FD 27) [call15402]
2016/12/08 18:14:36.135 kid2| src/comm.cc(755) commUnsetFdTimeout: Remove timeout for FD 27
2016/12/08 18:14:36.135 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=1, handler=0, client_data=0, timeout=0
2016/12/08 18:14:36.135 kid2| src/comm/IoCallback.cc(108) finish: called for local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1 (-10, 0)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm/IoCallback.cc(127) will call ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 FD 27 flags=1, flag=-10, data=0x2512f88, size=0, buf=0x24a20d0) [call15401]
2016/12/08 18:14:36.135 kid2| src/comm.cc(933) commCallCloseHandlers: commCallCloseHandlers: FD 27
2016/12/08 18:14:36.135 kid2| src/comm.cc(941) commCallCloseHandlers: commCallCloseHandlers: ch->handler=0x2574aa0*1
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm.cc(942) will call ConnStateData::connStateClosed(FD -1, data=0x2512f88) [call15372]
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x2223ab0 [call15403]
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/comm.cc(1156) will call comm_close_complete(FD 27) [call15403]
2016/12/08 18:14:36.135 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving clientWriteComplete(local=172.16.32.96:3130 remote=172.16.0.43:35114 flags=1, data=0x2513bc8)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering commStartSslClose(FD 27)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(30) make: make call commStartSslClose [call15402]
2016/12/08 18:14:36.135 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving commStartSslClose(FD 27)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 flags=1, flag=-10, data=0x2512f88, size=0, buf=0x24a20d0)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(30) make: make call ConnStateData::clientReadRequest [call15401]
2016/12/08 18:14:36.135 kid2| src/base/AsyncJob.cc(117) callStart: ConnStateData status in: [ job820]
2016/12/08 18:14:36.135 kid2| src/client_side.cc(3042) clientReadRequest: local=172.16.32.96:3130 remote=172.16.0.43:35114 flags=1 size 0
2016/12/08 18:14:36.135 kid2| src/client_side.cc(3049) clientReadRequest: local=172.16.32.96:3130 remote=172.16.0.43:35114 flags=1 closing Bailout.
2016/12/08 18:14:36.135 kid2| src/base/AsyncJob.cc(146) callEnd: ConnStateData status out: [ job820]
2016/12/08 18:14:36.135 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving ConnStateData::clientReadRequest(local=172.16.32.96:3130 remote=172.16.0.43:35114 flags=1, flag=-10, data=0x2512f88, size=0, buf=0x24a20d0)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering ConnStateData::connStateClosed(FD -1, data=0x2512f88)
2016/12/08 18:14:36.135 kid2| src/base/AsyncCall.cc(30) make: make call ConnStateData::connStateClosed [call15372]
2016/12/08 18:14:36.136 kid2| src/base/AsyncJob.cc(117) callStart: ConnStateData status in: [ job820]
2016/12/08 18:14:36.136 kid2| src/base/AsyncJob.cc(49) deleteThis: ConnStateData will NOT delete in-call job, reason: ConnStateData::connStateClosed
2016/12/08 18:14:36.136 kid2| src/base/AsyncJob.cc(131) callEnd: ConnStateData::connStateClosed(FD -1, data=0x2512f88) ends job [Stopped, reason:ConnStateData::connStateClosed job820]
2016/12/08 18:14:36.136 kid2| src/client_side.cc(864) swanSong: local=172.16.32.96:3130 remote=172.16.0.43:35114 flags=1
2016/12/08 18:14:36.136 kid2| src/clientStream.cc(225) clientStreamDetach: clientStreamDetach: Detaching node 0x25106f8
2016/12/08 18:14:36.136 kid2| src/clientStream.cc(310) clientStreamFree: Freeing clientStreamNode 0x25106f8
2016/12/08 18:14:36.136 kid2| src/clientStream.cc(246) clientStreamDetach: clientStreamDetach: Calling 1 with cbdata 0x2515e98
2016/12/08 18:14:36.136 kid2| src/clientStream.cc(225) clientStreamDetach: clientStreamDetach: Detaching node 0x250bb78
2016/12/08 18:14:36.136 kid2| src/clientStream.cc(310) clientStreamFree: Freeing clientStreamNode 0x250bb78
2016/12/08 18:14:36.136 kid2| src/store_client.cc(689) storeUnregister: storeUnregister: called for 'FB0F4AC67B901ACF463CE31BE1D89D3C'
2016/12/08 18:14:36.136 kid2| src/store_dir.cc(824) maybeTrimMemory: keepInLocalMemory: 1
2016/12/08 18:14:36.136 kid2| src/store_client.cc(786) storePendingNClients: storePendingNClients: returning 0
2016/12/08 18:14:36.136 kid2| src/client_side_request.cc(265) ~ClientHttpRequest: httpRequestFree: https://172.16.32.219/
2016/12/08 18:14:36.136 kid2| src/acl/Checklist.cc(62) preCheck: 0x7ffdea97f4e0 checking fast ACLs
2016/12/08 18:14:36.136 kid2| src/acl/Acl.cc(157) matches: checking access_log stdio:/var/log/squid/access.log
2016/12/08 18:14:36.136 kid2| src/acl/Acl.cc(157) matches: checking (access_log stdio:/var/log/squid/access.log line)
2016/12/08 18:14:36.136 kid2| src/acl/Acl.cc(177) matches: checked: (access_log stdio:/var/log/squid/access.log line) = 1
2016/12/08 18:14:36.136 kid2| src/acl/Acl.cc(177) matches: checked: access_log stdio:/var/log/squid/access.log = 1
2016/12/08 18:14:36.136 kid2| src/acl/Checklist.cc(55) markFinished: 0x7ffdea97f4e0 answer ALLOWED for match
2016/12/08 18:14:36.136 kid2| src/acl/FilledChecklist.cc(61) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffdea97f4e0
2016/12/08 18:14:36.136 kid2| src/acl/Checklist.cc(189) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffdea97f4e0
2016/12/08 18:14:36.136 kid2| src/store_client.cc(786) storePendingNClients: storePendingNClients: returning 0
2016/12/08 18:14:36.136 kid2| ctx: enter level  0: 'https://172.16.32.219/'
2016/12/08 18:14:36.136 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x2559a68 owner: 3
2016/12/08 18:14:36.136 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x2559a68 owner: 3
2016/12/08 18:14:36.136 kid2| ctx: exit level  0
2016/12/08 18:14:36.136 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall Initiate::noteInitiatorAborted constructed, this=0x2560bd0 [call15404]
2016/12/08 18:14:36.136 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/adaptation/Initiator.cc(34) will call Initiate::noteInitiatorAborted() [call15404]
2016/12/08 18:14:36.136 kid2| src/client_side_request.cc(137) ~ClientRequestContext: 0x250fb88 ClientRequestContext destructed
2016/12/08 18:14:36.136 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:36.136 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f3a8 owner: 3
2016/12/08 18:14:36.136 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f858 owner: 2
2016/12/08 18:14:36.136 kid2| src/HttpRequest.cc(78) ~HttpRequest: destructed, this=0x249f840
2016/12/08 18:14:36.136 kid2| src/HttpHeader.cc(442) clean: cleaning hdr: 0x249f858 owner: 2
2016/12/08 18:14:36.136 kid2| src/base/AsyncJob.cc(34) ~AsyncJob: AsyncJob destructed, this=0x2513570 type=ClientHttpRequest [job826]
2016/12/08 18:14:36.136 kid2| src/client_side.cc(4644) unpinConnection: 
2016/12/08 18:14:36.136 kid2| src/client_side.cc(895) ~ConnStateData: local=172.16.32.96:3130 remote=172.16.0.43:35114 flags=1
2016/12/08 18:14:36.136 kid2| src/base/AsyncJob.cc(34) ~AsyncJob: AsyncJob destructed, this=0x2513100 type=ConnStateData [job820]
2016/12/08 18:14:36.136 kid2| src/base/AsyncJob.cc(141) callEnd: ConnStateData::connStateClosed(FD -1, data=0x2512f88) ended 0x2513100
2016/12/08 18:14:36.136 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving ConnStateData::connStateClosed(FD -1, data=0x2512f88)
2016/12/08 18:14:36.136 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering comm_close_complete(FD 27)
2016/12/08 18:14:36.136 kid2| src/base/AsyncCall.cc(30) make: make call comm_close_complete [call15403]
2016/12/08 18:14:36.136 kid2| src/fd.cc(116) fd_close: fd_close FD 27 Reading next request
2016/12/08 18:14:36.136 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=1, handler=0, client_data=0, timeout=0
2016/12/08 18:14:36.136 kid2| src/comm/ModEpoll.cc(139) SetSelect: FD 27, type=2, handler=0, client_data=0, timeout=0
2016/12/08 18:14:36.136 kid2| src/comm/AcceptLimiter.cc(47) kick: size=0
2016/12/08 18:14:36.136 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving comm_close_complete(FD 27)
2016/12/08 18:14:36.136 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering Initiate::noteInitiatorAborted()
2016/12/08 18:14:36.136 kid2| src/base/AsyncCall.cc(30) make: make call Initiate::noteInitiatorAborted [call15404]
2016/12/08 18:14:36.136 kid2| src/base/AsyncCall.cc(48) cancel: will not call Initiate::noteInitiatorAborted [call15404] because job gone
2016/12/08 18:14:36.136 kid2| src/base/AsyncCall.cc(40) make: will not call Initiate::noteInitiatorAborted [call15404] because of job gone
2016/12/08 18:14:36.136 kid2| src/base/AsyncCallQueue.cc(53) fireNext: leaving Initiate::noteInitiatorAborted()
2016/12/08 18:14:36.725 kid2| src/base/AsyncCall.cc(18) AsyncCall: The AsyncCall MaintainSwapSpace constructed, this=0x2560bd0 [call15405]
2016/12/08 18:14:36.725 kid2| src/base/AsyncCall.cc(85) ScheduleCall: /tmp/squid_source/src/event.cc(261) will call MaintainSwapSpace() [call15405]
2016/12/08 18:14:36.725 kid2| src/base/AsyncCallQueue.cc(51) fireNext: entering MaintainSwapSpace()


- Greg




From bjoern.wahl at hospital-borken.de  Mon Dec 12 13:52:36 2016
From: bjoern.wahl at hospital-borken.de (bjoern wahl)
Date: Mon, 12 Dec 2016 14:52:36 +0100
Subject: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell eDirectory
 with /usr/lib64/squid/digest_edirectory_auth
Message-ID: <584EB9B402000009000242C9@mail01.hospital-borken.de>

Hello!

I would like to install a squid-3.3.8-26.el7_2.4.x86_64 (CentOS7) using
LDAP auth with digest_edirectory_auth,
but i can not get it working.

Does anybody user this ?

I tried:


/usr/lib64/squid/digest_edirectory_auth -A password -l : -e -v 3 -D
"cn=xxxx,o=xxxxx" -b "o=xxxxx" -w xxxx -b o=xxxx -s sub -F
"(&(objectclass=User)(cn=%s))" -Z -h ldaps://xxxxxx -n

but i only get:


user1 pw1
ERR 
user2 pw2
ERR 
user3 pw3
ERR 

Any ideas ?

Thanks, Bj?rn !

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.





From eliezer at ngtech.co.il  Mon Dec 12 14:13:24 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 12 Dec 2016 16:13:24 +0200
Subject: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell
	eDirectory with /usr/lib64/squid/digest_edirectory_auth
In-Reply-To: <584EB9B402000009000242C9@mail01.hospital-borken.de>
References: <584EB9B402000009000242C9@mail01.hospital-borken.de>
Message-ID: <000101d25481$e6890720$b39b1560$@ngtech.co.il>

Hey,

digest_edirectory_auth is not for LDAP but for edirectory but I a not too familiar with this to tell you how to test.
Basically you need a  "basic" ldap authentication helper  
Which the source is: http://bazaar.launchpad.net/~squid/squid/3.5/files/head:/helpers/basic_auth/LDAP/
And we are also missing the squid.conf.
Try find out if there some helper in the /usr/lib64/squid/ directory which contains ldap.

Let me know if we are on the right direction.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of bjoern wahl
Sent: Monday, December 12, 2016 3:53 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth

Hello!

I would like to install a squid-3.3.8-26.el7_2.4.x86_64 (CentOS7) using LDAP auth with digest_edirectory_auth, but i can not get it working.

Does anybody user this ?

I tried:


/usr/lib64/squid/digest_edirectory_auth -A password -l : -e -v 3 -D "cn=xxxx,o=xxxxx" -b "o=xxxxx" -w xxxx -b o=xxxx -s sub -F "(&(objectclass=User)(cn=%s))" -Z -h ldaps://xxxxxx -n

but i only get:


user1 pw1
ERR
user2 pw2
ERR
user3 pw3
ERR 

Any ideas ?

Thanks, Bj?rn !

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind, informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der enthaltenen Informationen ist nicht gestattet.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From fomodong at gmail.com  Mon Dec 12 16:11:03 2016
From: fomodong at gmail.com (Fomo Dong)
Date: Mon, 12 Dec 2016 08:11:03 -0800
Subject: [squid-users] Transparent HTTPs proxy with Squid 3.5
Message-ID: <CABEkGyZRkP_j2s3PGjgdQBNb=Z6x7QjmjmUNVWKk+2k4Y8v7tg@mail.gmail.com>

Hi all,

For couple of days I'm trying to figure out how to get a transparent HTTPs
proxy to work with Squid. What I'm trying to achieve is a proxy that
accepts internet traffic from ports 80 & 443, routes them through Squid to
Privoxy and finally through Tor and returns back the data. So essentially I
want to "automatically" revert some traffic through Tor without the user
needing to add a proxy to their connection.

I know how to setup the Privoxy and Tor part, but I'm struggling with the
Squid & IP tables configuration.
Here is my setup

Download latest version

curl -O http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.22.tar.gz
&& tar zxvf squid-3.5.22.tar.gz && cd squid-3.5.22

Install all needed packages

apt install devscripts build-essential openssl libssl-dev fakeroot
libcppunit-dev libsasl2-dev cdbs ccze libfile-readbackwards-perl
libcap2 libcap-dev libcap2-dev libnetfilter-conntrack-dev htop ccze
sysv-rc-conf -y

Configure the build and make and install

./configure \
CHOST="x86_64-pc-linux-gnu" \
CFLAGS="-march=core2 -O2 -pipe" \
CXXFLAGS="${CFLAGS}" \
--build=x86_64-linux-gnu \
--prefix=/usr \
--exec-prefix=/usr \
--bindir=/usr/bin \
--sbindir=/usr/sbin \
--libdir=/usr/lib \
--sharedstatedir=/usr/com \
--includedir=/usr/include \
--localstatedir=/var \
--libexecdir=/usr/lib/squid \
--srcdir=. \
--datadir=/usr/share/squid \
--sysconfdir=/etc/squid \
--infodir=/usr/share/info \
--mandir=/usr/share/man \
--x-includes=/usr/include \
--x-libraries=/usr/lib \
--with-default-user=proxy \
--with-logdir=/var/log/squid \
--with-pidfile=/var/run/squid.pid \
--enable-err-languages=English \
--enable-default-err-language=English \
--enable-storeio=ufs,aufs,diskd \
--enable-linux-netfilter \
--enable-removal-policies=lru,heap \
--enable-gnuregex \
--enable-follow-x-forwarded-for \
--enable-x-accelerator-vary \
--enable-zph-qos \
--enable-delay-pools \
--enable-snmp \
--enable-underscores \
--with-openssl \
--enable-ssl-crtd \
--enable-http-violations \
--enable-async-io=24 \
--enable-storeid-rewrite-helpers \
--with-large-files \
--with-libcap \
--with-netfilter-conntrack \
--with-included-ltdl \
--with-maxfd=65536 \
--with-filedescriptors=65536 \
--with-pthreads \
--without-gnutls \
--without-mit-krb5 \
--without-heimdal-krb5 \
--without-gnugss \
--disable-icap-client \
--disable-wccp \
--disable-wccpv2 \
--disable-dependency-tracking \
--disable-auth --disable-epoll \
--disable-ident-lookups \
--disable-icmp

Allow ip4 forwarding

echo -e "net.ipv4.ip_forward = 1\nnet.ipv4.conf.default.rp_filter =
0\nnet.ipv4.conf.all.rp_filter = 0\nnet.ipv4.conf.eth0.rp_filter =
0\n" >> /etc/sysctl.conf

Generate certificates

mkdir /etc/squid/ssl_certs && cd /etc/squid/ssl_certs
openssl genrsa -out squid.key 2048
openssl req -new -key squid.key -out squid.csr -nodes
openssl x509 -req -days 3652 -in squid.csr -signkey squid.key -out squid.crt
cat squid.crt squid.key > squid.pem

Generate certificate cache

mkdir /var/lib/squid && chown -R proxy:proxy /var/lib/squid/
/usr/lib/squid/ssl_crtd -c -s /var/lib/squid/ssl_db

Change ownership and rights to folders

mkdir -p /var/spool/squid

chown -R proxy:proxy /etc/squid/squid.conf | chown -R proxy:proxy
/usr/lib/squid | chown -R proxy:proxy /var/lib/squid/ssl_db/ | chown
-R proxy:proxy /var/spool/squid | chown -R proxy:proxy /var/log/squid
| chmod 777 /var/spool/squid | chmod 777 /var/log/squid  | chmod 755
/var/lib/squid/ssl_db/certs | chown proxy:proxy /var/log/squid/

Change configuration (bellow) and initialize the cache

squid -f /etc/squid/squid.conf -z

Redirect ports 80 and 443

iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 3128
iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-ports 3129

My actual squid configuration

acl localnet src all

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

never_direct allow all
always_direct allow all

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

http_access allow localnet
http_access allow localhost

debug_options ALL,2

visible_hostname squid

# stop squid taking forever to restart.
shutdown_lifetime 3
# for clients with a configured proxy.
http_port 3127
# for clients who are sent here via iptables ... REDIRECT.
http_port 3128 tproxy
# for https clients who are sent here via iptables ... REDIRECT
https_port 3129 tproxy ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.pem

sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M
4MB sslcrtd_children 8 startup=1 idle=1

# acl step1 at_step SslBump1
# ssl_bump peek step1
# ssl_bump bump all

ssl_bump server-first all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

via off
forwarded_for off

request_header_access From deny all
request_header_access Server deny all
request_header_access WWW-Authenticate deny all
request_header_access Link deny all
request_header_access Cache-Control deny all
request_header_access Proxy-Connection deny all
request_header_access X-Cache deny all
request_header_access X-Cache-Lookup deny all
request_header_access Via deny all
request_header_access X-Forwarded-For deny all
request_header_access Pragma deny all
request_header_access Keep-Alive deny all

cache_dir ufs /var/spool/squid 1024 16 256
coredump_dir /var/cache/squid

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

------------------------------

You can notice how benevolent I'm with the settings for Squid. It's only
for testing.

So where I got now is that nor intercept nor tproxy works. If I use accel
for the non-HTTPS traffic it works, but nothing else. If I use it as it is,
the result is that it will end up hanging for the client's timeout period
and then timeout.

Here is an example. I changed in /etc/hosts the IP for httpbin.org and
redirected it through the squid box.

? curl -vk https://httpbin.org/ip
*   Trying *******...
* Connected to httpbin.org (*******) port 443 (#0)
* TLS 1.2 connection using TLS_RSA_WITH_AES_256_GCM_SHA384
* Server certificate: ******
* Server certificate: Universe
> GET /ip HTTP/1.1
> Host: httpbin.org
> User-Agent: curl/7.49.1
> Accept: */*
>
< HTTP/1.1 503 Service Unavailable
< Server: squid/3.5.22
< Mime-Version: 1.0
< Date: Mon, 05 Dec 2016 05:43:50 GMT
< Content-Type: text/html;charset=utf-8
< Content-Length: 3498
< X-Squid-Error: ERR_CONNECT_FAIL 110
< Vary: Accept-Language
< Content-Language: en
< X-Cache: MISS from pipik
< Connection: close

On the squid side

2016/12/05 05:42:50.362 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New
connection on FD 28
2016/12/05 05:42:50.362 kid1| 5,2| TcpAcceptor.cc(295) acceptNext:
connection on local=[::]:3129 remote=[::] FD 28 flags=25
2016/12/05 05:42:50.363 kid1| 33,2| client_side.cc(3911)
httpsSslBumpAccessCheckDone: sslBump needed for local=*******:3129
remote=############# FD 11 flags=17 method 3
2016/12/05 05:42:50.363 kid1| 11,2| client_side.cc(2347)
parseHttpRequest: HTTP Client local=*******:3129 remote=#############
FD 11 flags=17
2016/12/05 05:42:50.363 kid1| 11,2| client_side.cc(2348)
parseHttpRequest: HTTP Client REQUEST:
---------
CONNECT *******:3129 HTTP/1.1
Host: *******:3129


----------
2016/12/05 05:42:50.363 kid1| 85,2| client_side_request.cc(744)
clientAccessCheckDone: The request CONNECT *******:3129 is ALLOWED;
last ACL checked: localnet
2016/12/05 05:42:50.363 kid1| 85,2| client_side_request.cc(720)
clientAccessCheck2: No adapted_http_access configuration. default:
ALLOW
2016/12/05 05:42:50.363 kid1| 85,2| client_side_request.cc(744)
clientAccessCheckDone: The request CONNECT *******:3129 is ALLOWED;
last ACL checked: localnet
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.378 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.379 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.379 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.379 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.379 kid1| 83,2| client_side.cc(4284)
clientPeekAndSpliceSSL: SSL_accept failed.
2016/12/05 05:42:50.379 kid1| 17,2| FwdState.cc(133) FwdState:
Forwarding client request local=*******:3129 remote=############# FD
11 flags=17, url=*******:3129
2016/12/05 05:42:50.379 kid1| 44,2| peer_select.cc(280)
peerSelectDnsPaths: Found sources for '*******:3129'
2016/12/05 05:42:50.379 kid1| 44,2| peer_select.cc(281)
peerSelectDnsPaths:   always_direct = ALLOWED
2016/12/05 05:42:50.379 kid1| 44,2| peer_select.cc(282)
peerSelectDnsPaths:    never_direct = DUNNO
2016/12/05 05:42:50.379 kid1| 44,2| peer_select.cc(288)
peerSelectDnsPaths:    ORIGINAL_DST = local=#############
remote=*******:3129 flags=25
2016/12/05 05:42:50.379 kid1| 44,2| peer_select.cc(295)
peerSelectDnsPaths:        timedout = 0
2016/12/05 05:43:50.645 kid1| 4,2| errorpage.cc(1261) BuildContent: No
existing error page language negotiated for ERR_CONNECT_FAIL. Using
default error file.
2016/12/05 05:43:50.645 kid1| 20,2| store.cc(980) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/12/05 05:43:50.645 kid1| 20,2| store.cc(980) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/12/05 05:43:50.845 kid1| 83,2| client_side.cc(3811)
clientNegotiateSSL: clientNegotiateSSL: New session 0x29dda60 on FD 11
(#############:59117)
2016/12/05 05:43:50.943 kid1| 11,2| client_side.cc(2347)
parseHttpRequest: HTTP Client local=*******:3129 remote=#############
FD 11 flags=17
2016/12/05 05:43:50.944 kid1| 11,2| client_side.cc(2348)
parseHttpRequest: HTTP Client REQUEST:
---------
GET /ip HTTP/1.1
Host: httpbin.org
User-Agent: curl/7.49.1
Accept: */*


----------
2016/12/05 05:43:50.944 kid1| 33,2| QosConfig.cc(145) doTosLocalMiss:
QOS: Preserving TOS on miss, TOS=0
2016/12/05 05:43:50.944 kid1| 33,2| client_side_reply.cc(1534)
buildReplyHeader: clientBuildReplyHeader: Connection Keep-Alive not
requested by admin or client
2016/12/05 05:43:50.944 kid1| 88,2| client_side_reply.cc(2051)
processReplyAccessResult: The reply for GET https://httpbin.org/ip is
ALLOWED, because it matched (access_log
daemon:/var/log/squid/access.log line)
2016/12/05 05:43:50.944 kid1| 11,2| client_side.cc(1393)
sendStartOfMessage: HTTP Client local=*******:3129
remote=############# FD 11 flags=17
2016/12/05 05:43:50.944 kid1| 11,2| client_side.cc(1394)
sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 503 Service Unavailable
Server: squid/3.5.22
Mime-Version: 1.0
Date: Mon, 05 Dec 2016 05:43:50 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3498
X-Squid-Error: ERR_CONNECT_FAIL 110
Vary: Accept-Language
Content-Language: en
X-Cache: MISS from squid
Connection: close


----------
2016/12/05 05:43:50.944 kid1| 33,2| client_side.cc(817) swanSong:
local=*******:3129 remote=############# flags=17
2016/12/05 05:43:50.944 kid1| 20,2| store.cc(980) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/12/05 05:43:50.944 kid1| 20,2| store.cc(980) checkCachable:
StoreEntry::checkCachable: NO: not cachable

I tried so many different configurations that I'm already lost in what does
work and what doesn't. I'm probably not understanding the connection
between iptables and squid properly, but no matter what I read I always end
up here.

I appreciate any suggestions.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161212/5eff0caf/attachment.htm>

From rousskov at measurement-factory.com  Tue Dec 13 00:46:53 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 12 Dec 2016 17:46:53 -0700
Subject: [squid-users] SSL bump config or possible code issue
In-Reply-To: <D4068264-0B70-4896-A429-E61551C35E98@net-virtual.com>
References: <6348944B-9964-49FD-8FB5-F744842C3275@net-virtual.com>
 <7ec470d6-49fb-b08f-55e4-0002c73be1ab@measurement-factory.com>
 <D4068264-0B70-4896-A429-E61551C35E98@net-virtual.com>
Message-ID: <27b45d69-0e84-1069-c37c-04732ff27971@measurement-factory.com>

On 12/08/2016 11:42 AM, Greg Saylor wrote:
>> On Dec 8, 2016, at 10:41 AM, Alex Rousskov wrote:
>> On 12/08/2016 09:15 AM, Greg Saylor wrote:
>>> I'm trying to debug a situation where squid 3.4 would return a ERR_ACCESS_DENIED and version 3.5 does not.

>> Squid [v3.5] tries to bump the client connection
>> to serve the error message to the HTTPS client.

> Regretfully, I have not been able to figure this out. I think its
> more around how the http_access rule result is being squirreled away
> and not being checked before proceeding with the SSL Bump.  Or
> perhaps in more 3.5.22 terms: its not being consulted when deciding
> how to respond to the client request?  Maybe its just not taking
> precedence?

Such a bug is somewhat unlikely but any bug is possible. More
information is needed to confirm or deny the bug itself (and one of your
explanations why it exists).


>> I recommend
>> ignoring Squid code and clearly demonstrating that Squid forwards a
>> request that should be denied. A packet trace or Squid's HTTP request
>> printouts would be helpful.

> It this what you mean?

Sorry, that was not it. That quoted v3.5 debugging log does not appear
to have [enough] HTTP information. It is mostly about your Squid talking
to your ICAP service. The v3.4 log was better, but I do not really care
much about v3.4.

Here is what I meant:

* Packet trace is a binary file in libpcap format. Usually produced by
tools like tcpdump or Wireshark. We need traffic from/to Squid (two TCP
connections, four directions). Some of that traffic may be encrypted.
This option works well, at least as a starting point, if Squid forwards
the CONNECT request (or an intercepted SSL connection) that it should
deny because those parts are not usually encrypted.

* Squid's HTTP request printouts can be collected by setting
debug_options to ALL,2 and repeating your test. Please limit the
collection to one failing transaction if possible and attach your logs
(or post a link to them).

Whichever approach you use, please do not forget to identify which
packets/requests were incorrectly forwarded and which "http_access deny"
rules they [should have] matched. In other words, you are essentially
claiming that there is a bug. You may be right! Please provide enough
information to support/illustrate your claim so that we can reproduce
and fix the bug if needed.


HTH,

Alex.



From squid3 at treenet.co.nz  Tue Dec 13 01:17:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 13 Dec 2016 14:17:47 +1300
Subject: [squid-users] Transparent HTTPs proxy with Squid 3.5
In-Reply-To: <CABEkGyZRkP_j2s3PGjgdQBNb=Z6x7QjmjmUNVWKk+2k4Y8v7tg@mail.gmail.com>
References: <CABEkGyZRkP_j2s3PGjgdQBNb=Z6x7QjmjmUNVWKk+2k4Y8v7tg@mail.gmail.com>
Message-ID: <e9a871a6-d1cc-3dec-7c24-583abeabf9d1@treenet.co.nz>

On 13/12/2016 5:11 a.m., Fomo Dong wrote:
> Hi all,
> 
> For couple of days I'm trying to figure out how to get a transparent HTTPs
> proxy to work with Squid. What I'm trying to achieve is a proxy that
> accepts internet traffic from ports 80 & 443, routes them through Squid to
> Privoxy and finally through Tor and returns back the data. So essentially I
> want to "automatically" revert some traffic through Tor without the user
> needing to add a proxy to their connection.
> 
> I know how to setup the Privoxy and Tor part, but I'm struggling with the
> Squid & IP tables configuration.

The first thing to be aware of is that Squid obeys the HTTPS requirement
that traffic received on TLS connection also goes out one. So your
Privoxy must be capable of receiving TLS connections from Squid.

If Privoxy cannot do TLS like that you could have Squid do the privacy
filtering. But then Tor would face the same requirement.


Second thing I want to make clear is that a *transparent* proxy is the
opposite of anonyizing proxy. A transparent proxy hides *itself* while
_revealing_ the client.  An anonymous proxy reveals itself, while hiding
the client(s). They are almost direct opposites in behaviour.

Anyhow, what you meant by the word "transparent" turns out to actually
be "intercepting". I hope that clarifies why 'tproxy' is definitely not
what you want to do here.



> Here is my setup
> 
> Download latest version
> 
> curl -O http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.22.tar.gz
> && tar zxvf squid-3.5.22.tar.gz && cd squid-3.5.22
> 
> Install all needed packages
> 
> apt install devscripts build-essential openssl libssl-dev fakeroot
> libcppunit-dev libsasl2-dev cdbs ccze libfile-readbackwards-perl
> libcap2 libcap-dev libcap2-dev libnetfilter-conntrack-dev htop ccze
> sysv-rc-conf -y
> 
> Configure the build and make and install
> 
> ./configure \
<snip>
> --enable-err-languages=English \
> --enable-default-err-language=English \
<snip>

Those two saying "English" are not right. Squid uses ISO codes for
languages now. You can remove the above without affecting the build.

> 
> Allow ip4 forwarding
> 
> echo -e "net.ipv4.ip_forward = 1\nnet.ipv4.conf.default.rp_filter =
> 0\nnet.ipv4.conf.all.rp_filter = 0\nnet.ipv4.conf.eth0.rp_filter =
> 0\n" >> /etc/sysctl.conf
> 
> Generate certificates
> 
> mkdir /etc/squid/ssl_certs && cd /etc/squid/ssl_certs
> openssl genrsa -out squid.key 2048
> openssl req -new -key squid.key -out squid.csr -nodes
> openssl x509 -req -days 3652 -in squid.csr -signkey squid.key -out squid.crt
> cat squid.crt squid.key > squid.pem
> 
> Generate certificate cache
> 
> mkdir /var/lib/squid && chown -R proxy:proxy /var/lib/squid/
> /usr/lib/squid/ssl_crtd -c -s /var/lib/squid/ssl_db
> 
> Change ownership and rights to folders
> 
> mkdir -p /var/spool/squid
> 
> chown -R proxy:proxy /etc/squid/squid.conf | chown -R proxy:proxy
> /usr/lib/squid | chown -R proxy:proxy /var/lib/squid/ssl_db/ | chown
> -R proxy:proxy /var/spool/squid | chown -R proxy:proxy /var/log/squid
> | chmod 777 /var/spool/squid | chmod 777 /var/log/squid  | chmod 755
> /var/lib/squid/ssl_db/certs | chown proxy:proxy /var/log/squid/
> 

Er, I suggest you use '&&' or ';' between those instead of '|'.
chmod/chown do not take each others output as input.


Squid will be reading its config files as 'root', not as 'proxy'.

And you might want to rethink allowing world-writeable and
world-readable privileges on those directories. Particularly the TLS
certs one. 640 should be enough access for most logs, and 600 for the
certs area.

NP: if this is on a Debian/Ubuntu machine you should install the
squid/squid3 package to setup all the permissions and directories
properly. Then build your custom Squid so that the binary replaces the
default package one.


> Change configuration (bellow) and initialize the cache
> 
> squid -f /etc/squid/squid.conf -z
> 
> Redirect ports 80 and 443
> 
> iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 3128
> iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-ports 3129
> 

Good start, there are a few more rules to add though. This config
example covers it all:
 <http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>


> My actual squid configuration
> 
> acl localnet src all

No. localnet should only have your LAN subnets. There is a built-in ACL
'all' for use when you want the entire Internet to match.

> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 

You should at this position in your config add back in the default
security protection lines:

 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_ports


> never_direct allow all
> always_direct allow all
> 

Remove the always_direct line. The never_direct should not be necessary,
but could help later.


You need to setup a cache_peer line pointing Squid at the Privoxy
listening address and port.
 * that line will also need at least the 'ssl' option for the HTTPS
traffic to be sent there.
 * Privoxy will need to be configured to receive TLS traffic. If it can
receive proxy<->proxy connections over TLS that would be great,
otherwise the cache_peer line might need the 'originserver' option to
send it port-443 / HTTPS formatted data.

More on cache_peer can be found at:
 <http://www.squid-cache.org/Versions/v3/3.5/cfgman/cache_peer.html>


> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> http_access allow localnet
> http_access allow localhost
> 

You are missing this line:

  http_access deny all

> debug_options ALL,2
> 
> visible_hostname squid

This is supposed to be a FQDN. It gets used in URLs for icons and such
things that Squid serves up from its port 3128 ... er 3127 below.

With this config file the clients will be told to fetch things from URLs
starting "http://squid:3127/squid-internal-static/" ...

> 
> # stop squid taking forever to restart.
> shutdown_lifetime 3
> # for clients with a configured proxy.
> http_port 3127
> # for clients who are sent here via iptables ... REDIRECT.
> http_port 3128 tproxy
> # for https clients who are sent here via iptables ... REDIRECT
> https_port 3129 tproxy ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.pem

Replace 'tproxy' with 'intercept'. NAT is just an intercept of the
traffic, no transparency.

> 
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M
> 4MB sslcrtd_children 8 startup=1 idle=1
> 
> # acl step1 at_step SslBump1
> # ssl_bump peek step1
> # ssl_bump bump all
> 
> ssl_bump server-first all

Two things wrong here:

1) server-first mode requires that Squid upstream be the origin server
for the HTTPS website. That is because Squid mimics the server
connection certificate. If that connection is not the origin server the
cert Squid presents to the client is almost guaranteed to be invalid and
breaks HTTPS.

The configuration you are planning will only work with the very unsafe
client-first bumping style. Where Squid generates a completely false
certificate, but has some chance of working if the client doesn't
validate it too thoroughly.

2) The server-first/client-first config actions are deprecated. For
Squid-3.5 use the peek/splice/bump/terminate actions.

You want to start with the below rules and build any special handing
from there:

 acl step1 at_step BumpStep1
 ssl_bump stare step1
 ssl_bump bump all


> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> 

Those can go. never_direct prevents Squid -> origin connections existing
so the above dont work. Which is lucky, that could be nasty.

> via off
> forwarded_for off

'forwarded_for transparent' would be better for your requirements. Maybe
'delete' if you want to also prevent clients using the header.

> 
> request_header_access From deny all
> request_header_access Server deny all
> request_header_access WWW-Authenticate deny all

Server and WWW-Authenticate are not a request headers. You should be
able to remove those lines.


> request_header_access Link deny all
> request_header_access Cache-Control deny all

That Cache-Control line will seriously break HTTP for the clients.


> request_header_access Proxy-Connection deny all

Squid is already erasing the obsolete Proxy-Connection headers. You can
remove the above line.

> request_header_access X-Cache deny all
> request_header_access X-Cache-Lookup deny all
> request_header_access Via deny all

The via off line is already doing that. You can remove.

> request_header_access X-Forwarded-For deny all

The forwarded_for line should already do that. You can remove.


> request_header_access Pragma deny all

FYI: Like Cache-Control, doing this to Pragma will cause breakage in
HTTP. But since it is not an HTTP/1.1 header that will be minimal.

> request_header_access Keep-Alive deny all

I suggest adding this to remove all custom headers from the request:

 request_header_access Other deny all


Squid also has a reply_header_access directive for anonymizing response
headers. Though hiding server details from the client is less important.

 reply_header_access Set-Cookie deny all
 reply_header_access Set-Cookie2 deny all
 reply_header_access Other deny all


You may find that you dont actually need Privoxy after doing all this
request filtering in squid.conf.

> 
> cache_dir ufs /var/spool/squid 1024 16 256
> coredump_dir /var/cache/squid
> 
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> 
> ------------------------------
> 
> You can notice how benevolent I'm with the settings for Squid. It's only
> for testing.

If you are referring to the missing security rules and the disabled TLS
validation. That is bad for testing as well as production use.

You need to test the real config that will be used in production and fix
the problems encountered with that. Disabling things for testing hides
problems they cause when enabled, and even introduces false problems
that wont occur in production.


Amos


From squid3 at treenet.co.nz  Tue Dec 13 03:24:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 13 Dec 2016 16:24:44 +1300
Subject: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell
 eDirectory with /usr/lib64/squid/digest_edirectory_auth
In-Reply-To: <000101d25481$e6890720$b39b1560$@ngtech.co.il>
References: <584EB9B402000009000242C9@mail01.hospital-borken.de>
 <000101d25481$e6890720$b39b1560$@ngtech.co.il>
Message-ID: <aa106a0e-6b4e-82a5-681b-13efd9d68466@treenet.co.nz>

On 13/12/2016 3:13 a.m., Eliezer Croitoru wrote:
> Hey,
> 
> digest_edirectory_auth is not for LDAP but for edirectory but I a not too familiar with this to tell you how to test.

Uhm, wrong there. But a common mistake.
 LDAP is a *protocol* (like HTTP is a protocol).
 eDirectory is software (like Squid is software).

That helper is for performing Digest authentication with an eDirectory
backend. It uses LDAP to communicate to that eDirectory software.


> Basically you need a  "basic" ldap authentication helper  
> Which the source is: http://bazaar.launchpad.net/~squid/squid/3.5/files/head:/helpers/basic_auth/LDAP/

That helper is for performing Basic authentication with *any* backend
that speaks LDAP protocol.


> -----Original Message-----
> From: squid-users On Behalf Of bjoern wahl
> 
> Hello!
> 
> I would like to install a squid-3.3.8-26.el7_2.4.x86_64 (CentOS7) using LDAP auth with digest_edirectory_auth, but i can not get it working.
> 
> Does anybody user this ?
> 
> I tried:
> 
> 
> /usr/lib64/squid/digest_edirectory_auth -A password -l : -e -v 3 -D "cn=xxxx,o=xxxxx" -b "o=xxxxx" -w xxxx -b o=xxxx -s sub -F "(&(objectclass=User)(cn=%s))" -Z -h ldaps://xxxxxx -n
> 

-h parameter takes a hostname,  "ldaps://" is a URI.

> but i only get:
> 
> 
> user1 pw1
> ERR
> user2 pw2
> ERR
> user3 pw3
> ERR 
> 
> Any ideas ?

Those test lines are Basic auth inputs.

Use Digest auth inputs for testing Digest helpers.
<http://wiki.squid-cache.org/Features/AddonHelpers#Digest_Scheme>


Amos



From bjoern.wahl at hospital-borken.de  Tue Dec 13 07:14:49 2016
From: bjoern.wahl at hospital-borken.de (bjoern wahl)
Date: Tue, 13 Dec 2016 08:14:49 +0100
Subject: [squid-users] Antw: RE: squid-3.3.8-26.el7_2.4.x86_64 using Novell
 eDirectory with /usr/lib64/squid/digest_edirectory_auth
In-Reply-To: <000101d25481$e6890720$b39b1560$@ngtech.co.il>
References: <584EB9B402000009000242C9@mail01.hospital-borken.de>
 <000101d25481$e6890720$b39b1560$@ngtech.co.il>
Message-ID: <584FADF902000009000242F7@mail01.hospital-borken.de>


Hello!

Thanks for the fast response.

I got the Ldap-Auth working with

SLES11.4 / squid3-3.1.23-8.16.33.2
=========================================================================================================
auth_param basic program /usr/sbin/squid_ldap_auth -d -D "cn=xxx,o=xxxx"
-w xx -b o=x -s sub -f "(&(objectclass=User)(cn=%s))" -h ldaps://xxxx -p
636

external_acl_type ldap_group %LOGIN /usr/sbin/squid_ldap_group -d -D
"cn=xx,o=x" -w ldap -b o=x -s sub -f
"(&(objectclass=User)(cn=%u)(groupMembership=%g))" -h ldaps://x -p 636
=========================================================================================================

but now i would like to do it with

CentOS Linux release 7.2.1511 / squid-3.3.8-26.el7_2.4.x86_64

and it turned out the I have no more "squid_ldap_auth" but i found
"basic_ldap_auth".
So it tried switching "squid_ldap_auth" to "basic_ldap_auth" but that
did not work....

I get the login window, but even if i enter a vaild user, i can not
access a website.

squid.conf looks like this:

=========================================================================================================
auth_param basic program /usr/lib64/squid/basic_ldap_auth -d -D
"cn=xxx,o=xxx" -w xxx -b o=xxx -s sub -f "(&(objectclass=User)(cn=%s))"
-h ldaps://xxxx -p 636

auth_param basic children 5
auth_param basic credentialsttl 2 hours
acl ediruser proxy_auth REQUIRE
http_access allow ediruser
http_access deny all

=========================================================================================================


>>> Eliezer Croitoru <eliezer at ngtech.co.il> 12.12.16 15.28 Uhr >>>
Hey,

digest_edirectory_auth is not for LDAP but for edirectory but I a not
too familiar with this to tell you how to test.
Basically you need a "basic" ldap authentication helper
Which the source is:
http://bazaar.launchpad.net/~squid/squid/3.5/files/head:/helpers/basic_auth/LDAP/
And we are also missing the squid.conf.
Try find out if there some helper in the /usr/lib64/squid/ directory
which contains ldap.

Let me know if we are on the right direction.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of bjoern wahl
Sent: Monday, December 12, 2016 3:53 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell
eDirectory with /usr/lib64/squid/digest_edirectory_auth

Hello!

I would like to install a squid-3.3.8-26.el7_2.4.x86_64 (CentOS7) using
LDAP auth with digest_edirectory_auth, but i can not get it working.

Does anybody user this ?

I tried:


/usr/lib64/squid/digest_edirectory_auth -A password -l : -e -v 3 -D
"cn=xxxx,o=xxxxx" -b "o=xxxxx" -w xxxx -b o=xxxx -s sub -F
"(&(objectclass=User)(cn=%s))" -Z -h ldaps://xxxxxx -n

but i only get:


user1 pw1
ERR
user2 pw2
ERR
user3 pw3
ERR

Any ideas ?

Thanks, Bj?rn !

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken Registergericht
Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (SprechDiese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.





From odhiambo at gmail.com  Tue Dec 13 09:07:01 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Tue, 13 Dec 2016 12:07:01 +0300
Subject: [squid-users] URL too large??
Message-ID: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>

Hi,

Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):

2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not
permitted
2016/12/13 11:47:55| HTCP Disabled.
2016/12/13 11:47:55| Finished loading MIME types and icons.
2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket connections at
local=[::]:13128 remote=[::] FD 39 flags=41
2016/12/13 11:47:55| Accepting HTTP Socket connections at local=[::]:13130
remote=[::] FD 40 flags=9
2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS Socket
connections at local=[::]:13129 remote=[::] FD 41 flags=41
2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
2016/12/13 11:47:55| Sending ICP messages from [::]:3130
*2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)*


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161213/c2bd34d8/attachment.htm>

From per at computer.org  Tue Dec 13 09:15:14 2016
From: per at computer.org (Per Jessen)
Date: Tue, 13 Dec 2016 10:15:14 +0100
Subject: [squid-users] Transparent HTTPs proxy with Squid 3.5
References: <CABEkGyZRkP_j2s3PGjgdQBNb=Z6x7QjmjmUNVWKk+2k4Y8v7tg@mail.gmail.com>
 <e9a871a6-d1cc-3dec-7c24-583abeabf9d1@treenet.co.nz>
Message-ID: <o2oe72$tpv$1@saturn.local.net>

Amos Jeffries wrote:

> On 13/12/2016 5:11 a.m., Fomo Dong wrote:
>> Hi all,
>> 
>> For couple of days I'm trying to figure out how to get a transparent
>> HTTPs proxy to work with Squid. What I'm trying to achieve is a proxy
>> that accepts internet traffic from ports 80 & 443, routes them
>> through Squid to Privoxy and finally through Tor and returns back the
>> data. So essentially I want to "automatically" revert some traffic
>> through Tor without the user needing to add a proxy to their
>> connection.
>> 
>> I know how to setup the Privoxy and Tor part, but I'm struggling with
>> the Squid & IP tables configuration.
> 
> The first thing to be aware of is that Squid obeys the HTTPS
> requirement that traffic received on TLS connection also goes out one.
> So your Privoxy must be capable of receiving TLS connections from
> Squid.
> 
> If Privoxy cannot do TLS like that you could have Squid do the privacy
> filtering. But then Tor would face the same requirement.
> 
> 
> Second thing I want to make clear is that a *transparent* proxy is the
> opposite of anonyizing proxy. A transparent proxy hides *itself* while
> _revealing_ the client.  An anonymous proxy reveals itself, while
> hiding the client(s). They are almost direct opposites in behaviour.
> 
> Anyhow, what you meant by the word "transparent" turns out to actually
> be "intercepting". 

We also run a "transparent" proxy, but it is transparent for the
_client_.  The main office router simply sends an ICMP redirect to
point clients to the proxy. 


-- 
Per Jessen, Z?rich (0.1?C)
http://www.cloudsuisse.com/ - your owncloud, hosted in Switzerland.



From ahmed.zaeem at netstream.ps  Tue Dec 13 13:14:30 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 13 Dec 2016 15:14:30 +0200
Subject: [squid-users] FATAL: The userIp helpers are crashing too rapidly,
	need help!
Message-ID: <A805AF84-6B38-4837-A39C-E260BB5DA8CD@netstream.ps>


hello squid users & hello Amos

amos I?m trying to do like 1000 ipv6 binding outgoing usernames but i have the error like helpers are crashed .. I?m not sure  if i need to tune some settings before completion to take out the error .

here is the config i used for that i needed :

auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
auth_param basic children 100
external_acl_type userIp %SRC %LOGIN /lib/squid/ext_file_userip_acl -f /root/soso/userIP.conf
acl ncsa_users proxy_auth REQUIRED
acl userIp external userIp
http_access deny !ncsa_users
http_access allow userIp
http_access deny all


and here is /root/soso/userIP.conf

2001:19f0:5001:a:1748:abc0:b85b:eaec user17991
2001:19f0:5001:a:b4f:cd29:4962:5d3c user17992
2001:19f0:5001:a:9ef4:478c:f8d1:a1e2 user17993
2001:19f0:5001:a:1307:1614:63c1:260a user17994
2001:19f0:5001:a:ad0b:59aa:9a1c:52f0 user17995
2001:19f0:5001:a:10d2:841f:bea0:d87 user17996



here is case.log

[root at netherlands soso]# tailf /var/log/squid/cache.log 
2016/12/13 13:11:03 kid1| Closing HTTP port 45.76.37.139:17999
2016/12/13 13:11:03 kid1| storeDirWriteCleanLogs: Starting...
2016/12/13 13:11:03 kid1|   Finished.  Wrote 0 entries.
2016/12/13 13:11:03 kid1|   Took 0.00 seconds (  0.00 entries/sec).
FATAL: The userIp helpers are crashing too rapidly, need help!

Squid Cache (Version 3.5.22): Terminated abnormally.
CPU Usage: 0.677 seconds = 0.589 user + 0.087 sys
Maximum Resident Size: 161056 KB
Page faults with physical i/o: 0



can you help me to fix the crashing ?

thank you so much 

From fredbmail at free.fr  Tue Dec 13 13:21:42 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 13 Dec 2016 14:21:42 +0100 (CET)
Subject: [squid-users] FATAL: The userIp helpers are crashing too
 rapidly, need help!
In-Reply-To: <A805AF84-6B38-4837-A39C-E260BB5DA8CD@netstream.ps>
Message-ID: <447788432.131067552.1481635302945.JavaMail.root@zimbra4-e1.priv.proxad.net>


/root/soso/userIP.conf

Make a try with /tmp 

/tmp/userIP.conf

Fred


From eliezer at ngtech.co.il  Tue Dec 13 13:37:49 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 13 Dec 2016 15:37:49 +0200
Subject: [squid-users] Antw: RE: squid-3.3.8-26.el7_2.4.x86_64 using
	Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth
In-Reply-To: <584FADF902000009000242F7@mail01.hospital-borken.de>
References: <584EB9B402000009000242C9@mail01.hospital-borken.de>
 <000101d25481$e6890720$b39b1560$@ngtech.co.il>
 <584FADF902000009000242F7@mail01.hospital-borken.de>
Message-ID: <09a801d25546$186c5430$4944fc90$@ngtech.co.il>

Which of the helpers are you having issues with?
The Group or the user one?
I did some experiment with ldap groups which can be found at:
http://lists.squid-cache.org/pipermail/squid-users/2015-July/004874.html

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: bjoern wahl [mailto:bjoern.wahl at hospital-borken.de] 
Sent: Tuesday, December 13, 2016 9:15 AM
To: squid-users at lists.squid-cache.org; eliezer at ngtech.co.il
Subject: Antw: RE: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth


Hello!

Thanks for the fast response.

I got the Ldap-Auth working with

SLES11.4 / squid3-3.1.23-8.16.33.2
=========================================================================================================
auth_param basic program /usr/sbin/squid_ldap_auth -d -D "cn=xxx,o=xxxx"
-w xx -b o=x -s sub -f "(&(objectclass=User)(cn=%s))" -h ldaps://xxxx -p
636

external_acl_type ldap_group %LOGIN /usr/sbin/squid_ldap_group -d -D "cn=xx,o=x" -w ldap -b o=x -s sub -f "(&(objectclass=User)(cn=%u)(groupMembership=%g))" -h ldaps://x -p 636 =========================================================================================================

but now i would like to do it with

CentOS Linux release 7.2.1511 / squid-3.3.8-26.el7_2.4.x86_64

and it turned out the I have no more "squid_ldap_auth" but i found "basic_ldap_auth".
So it tried switching "squid_ldap_auth" to "basic_ldap_auth" but that did not work....

I get the login window, but even if i enter a vaild user, i can not access a website.

squid.conf looks like this:

=========================================================================================================
auth_param basic program /usr/lib64/squid/basic_ldap_auth -d -D "cn=xxx,o=xxx" -w xxx -b o=xxx -s sub -f "(&(objectclass=User)(cn=%s))"
-h ldaps://xxxx -p 636

auth_param basic children 5
auth_param basic credentialsttl 2 hours
acl ediruser proxy_auth REQUIRE
http_access allow ediruser
http_access deny all

=========================================================================================================


>>> Eliezer Croitoru <eliezer at ngtech.co.il> 12.12.16 15.28 Uhr >>>
Hey,

digest_edirectory_auth is not for LDAP but for edirectory but I a not too familiar with this to tell you how to test.
Basically you need a "basic" ldap authentication helper Which the source is:
http://bazaar.launchpad.net/~squid/squid/3.5/files/head:/helpers/basic_auth/LDAP/
And we are also missing the squid.conf.
Try find out if there some helper in the /usr/lib64/squid/ directory which contains ldap.

Let me know if we are on the right direction.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of bjoern wahl
Sent: Monday, December 12, 2016 3:53 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth

Hello!

I would like to install a squid-3.3.8-26.el7_2.4.x86_64 (CentOS7) using LDAP auth with digest_edirectory_auth, but i can not get it working.

Does anybody user this ?

I tried:


/usr/lib64/squid/digest_edirectory_auth -A password -l : -e -v 3 -D "cn=xxxx,o=xxxxx" -b "o=xxxxx" -w xxxx -b o=xxxx -s sub -F "(&(objectclass=User)(cn=%s))" -Z -h ldaps://xxxxxx -n

but i only get:


user1 pw1
ERR
user2 pw2
ERR
user3 pw3
ERR

Any ideas ?

Thanks, Bj?rn !

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind, informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der enthaltenen Informationen ist nicht gestattet.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (SprechDiese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind, informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der enthaltenen Informationen ist nicht gestattet.






From ahmed.zaeem at netstream.ps  Tue Dec 13 14:14:56 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 13 Dec 2016 16:14:56 +0200
Subject: [squid-users] FATAL: The userIp helpers are crashing too
	rapidly, need help!
In-Reply-To: <447788432.131067552.1481635302945.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <447788432.131067552.1481635302945.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <4DD6DBCC-52A8-48BA-ACE7-8A5E88AE0820@netstream.ps>

thank you brother , you have  been rock !
> On Dec 13, 2016, at 3:21 PM, FredB <fredbmail at free.fr> wrote:
> 
> 
> /root/soso/userIP.conf
> 
> Make a try with /tmp 
> 
> /tmp/userIP.conf
> 
> Fred
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From ahmed.zaeem at netstream.ps  Tue Dec 13 14:18:18 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 13 Dec 2016 16:18:18 +0200
Subject: [squid-users] squid bind username to  same ip but different port
Message-ID: <4C22FF79-D4C6-4368-8B33-4A6143587C34@netstream.ps>

hey squid users .
i  have a question .

say i have 1 ipv4 and with 100 ports opened  with http directive .

say i have 100 user/pwd for squid.

the question is how can i bind each user to ip:port

i mean i don?t want each user to be available on each port .. i just want to bind each port with usr/pwd


as example , the result will be like 

ip:port1:user1:pwd1
ip:port2:user2:pwd2


ip will be same .
so i don?t want the result  of

ip:port1:user2:pwd2 work ? i only want ip:port:user1:pwd1


im not sure if the directive :

external_acl_type type-name %SRC %LOGIN /path/to/ext_file_userip_acl -f /path/to/config.file

will help becuase its description on ip/mask , not ip:port



kind regards 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161213/856e01db/attachment.htm>

From fredbmail at free.fr  Tue Dec 13 14:18:35 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 13 Dec 2016 15:18:35 +0100 (CET)
Subject: [squid-users] FATAL: The userIp helpers are crashing too
 rapidly, need help!
In-Reply-To: <4DD6DBCC-52A8-48BA-ACE7-8A5E88AE0820@netstream.ps>
Message-ID: <1829313114.131279125.1481638715670.JavaMail.root@zimbra4-e1.priv.proxad.net>


Now, You should use another directory, less insecure I mean
/tmp is r/w for all ...


From eliezer at ngtech.co.il  Tue Dec 13 16:51:25 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 13 Dec 2016 16:51:25 +0000
Subject: [squid-users] URL too large??
In-Reply-To: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
Message-ID: <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>

I think that the maximum size was 64k and it's way above this.
It should not be an issue if this is some weird application creating some random url which doesn't have meaning.
But if you know what is creating such a url it's a whole another story.
Can you reproducerecreate this url?
Eliezer
----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il
On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington  wrote: Hi,
Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):
2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/13 11:47:55| HTCP Disabled.
2016/12/13 11:47:55| Finished loading MIME types and icons.
2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket connections at local=[::]:13128 remote=[::] FD 39 flags=41
2016/12/13 11:47:55| Accepting HTTP Socket connections at local=[::]:13130 remote=[::] FD 40 flags=9
2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS Socket connections at local=[::]:13129 remote=[::] FD 41 flags=41
2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
2016/12/13 11:47:55| Sending ICP messages from [::]:3130
2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)
-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161213/e1b19333/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 29577 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161213/e1b19333/attachment.png>

From rousskov at measurement-factory.com  Tue Dec 13 17:03:31 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 13 Dec 2016 10:03:31 -0700
Subject: [squid-users] URL too large??
In-Reply-To: <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
 <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
Message-ID: <66e7a55e-c734-c5c1-d7e9-de761c37537d@measurement-factory.com>

On 12/13/2016 09:51 AM, Eliezer Croitoru wrote:
> I think that the maximum size was 64k 

The maximum appears to be 8KB:

  v3.5/src/defines.h:#define MAX_URL  8192
  v4/src/defines.h:#define MAX_URL  8192
  v5/src/defines.h:#define MAX_URL  8192

IIRC, there are many emails discussing this limit and what to do about it.

Alex.


> On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington wrote:
> 
>     Hi,
> 
>     Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):
> 
>     2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not
>     permitted
>     2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not
>     permitted
>     2016/12/13 11:47:55| HTCP Disabled.
>     2016/12/13 11:47:55| Finished loading MIME types and icons.
>     2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket
>     connections at local=[::]:13128 remote=[::] FD 39 flags=41
>     2016/12/13 11:47:55| Accepting HTTP Socket connections at
>     local=[::]:13130 remote=[::] FD 40 flags=9
>     2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS
>     Socket connections at local=[::]:13129 remote=[::] FD 41 flags=41
>     2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
>     2016/12/13 11:47:55| Sending ICP messages from [::]:3130
>     *2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)*
> 
> 
>     -- 
>     Best regards,
>     Odhiambo WASHINGTON,
>     Nairobi,KE
>     +254 7 3200 0004/+254 7 2274 3223
>     "Oh, the cruft."
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From garryd at comnet.uz  Tue Dec 13 17:22:21 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Tue, 13 Dec 2016 22:22:21 +0500
Subject: [squid-users] URL too large??
In-Reply-To: <66e7a55e-c734-c5c1-d7e9-de761c37537d@measurement-factory.com>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
 <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
 <66e7a55e-c734-c5c1-d7e9-de761c37537d@measurement-factory.com>
Message-ID: <d468f8ea084ccefbe426bc71e74f75e1@comnet.uz>

On 2016-12-13 22:03, Alex Rousskov wrote:
> On 12/13/2016 09:51 AM, Eliezer Croitoru wrote:
>> I think that the maximum size was 64k
> 
> The maximum appears to be 8KB:
> 
>   v3.5/src/defines.h:#define MAX_URL  8192
>   v4/src/defines.h:#define MAX_URL  8192
>   v5/src/defines.h:#define MAX_URL  8192
> 
> IIRC, there are many emails discussing this limit and what to do about 
> it.
> 
> Alex.
> 
>> On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington wrote:
>> 
>>     Hi,
>> 
>>     Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):
>> 
>>     2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation 
>> not
>>     permitted
>>     2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation 
>> not
>>     permitted
>>     2016/12/13 11:47:55| HTCP Disabled.
>>     2016/12/13 11:47:55| Finished loading MIME types and icons.
>>     2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket
>>     connections at local=[::]:13128 remote=[::] FD 39 flags=41
>>     2016/12/13 11:47:55| Accepting HTTP Socket connections at
>>     local=[::]:13130 remote=[::] FD 40 flags=9
>>     2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS
>>     Socket connections at local=[::]:13129 remote=[::] FD 41 flags=41
>>     2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
>>     2016/12/13 11:47:55| Sending ICP messages from [::]:3130
>>     *2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)*
>> 
>> 
>>     --
>>     Best regards,
>>     Odhiambo WASHINGTON,
>>     Nairobi,KE
>>     +254 7 3200 0004/+254 7 2274 3223
>>     "Oh, the cruft."


Details could be found in the following bug report:
http://bugs.squid-cache.org/show_bug.cgi?id=4422#c1

Garri


From odhiambo at gmail.com  Tue Dec 13 19:05:27 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Tue, 13 Dec 2016 22:05:27 +0300
Subject: [squid-users] URL too large??
In-Reply-To: <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
 <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
Message-ID: <CAAdA2WPYFLTUWpGgv6JoFBuYb08zmBefoWBnZmYjucvpuoDkQA@mail.gmail.com>

I did not dig deep into it I couldn't scan the access log for it because I
had no idea what 'too long' meant.
I will ignore it until someone says they're unable to access a website, and
they can give me details of what it is.


On 13 December 2016 at 19:51, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:

> I think that the maximum size was 64k and it's way above this.
> It should not be an issue if this is some weird application creating some
> random url which doesn't have meaning.
> But if you know what is creating such a url it's a whole another story.
> Can you reproduce\recreate this url?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile+WhatsApp: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
>
> On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington <odhiambo at gmail.com>
> wrote:
>
> Hi,
>
> Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):
>
> 2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/13 11:47:55| HTCP Disabled.
> 2016/12/13 11:47:55| Finished loading MIME types and icons.
> 2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket connections at
> local=[::]:13128 remote=[::] FD 39 flags=41
> 2016/12/13 11:47:55| Accepting HTTP Socket connections at local=[::]:13130
> remote=[::] FD 40 flags=9
> 2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS Socket
> connections at local=[::]:13129 remote=[::] FD 41 flags=41
> 2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
> 2016/12/13 11:47:55| Sending ICP messages from [::]:3130
> *2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)*
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161213/4556460d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 29577 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161213/4556460d/attachment.png>

From yvoinov at gmail.com  Tue Dec 13 19:46:09 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Dec 2016 01:46:09 +0600
Subject: [squid-users] URL too large??
In-Reply-To: <CAAdA2WPYFLTUWpGgv6JoFBuYb08zmBefoWBnZmYjucvpuoDkQA@mail.gmail.com>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
 <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
 <CAAdA2WPYFLTUWpGgv6JoFBuYb08zmBefoWBnZmYjucvpuoDkQA@mail.gmail.com>
Message-ID: <1c1d1fa3-771b-3ea0-4cfb-77ae4e0448d5@gmail.com>

It means exactly what it said: URL too long.

In Squid's defaults set 8k for URL size. This was reasonable maximum 10
years ago.

Now it seems too small (at least 4 times) because of now Internet full
of adware bullshit (referrals/trackers/counters etc.) which is often
more 8k.

You can easy fix it (if you worry about it. It seems for end-user like
hang/broken links) if you build squid from source. Just change vaule
MAX_URL in src/defines.h and recompile.

But if you do this, beware - some things become slower, and danger of
deinal of service exists.

That's it.

WBR, Yuri


14.12.2016 1:05, Odhiambo Washington ?????:
> I did not dig deep into it I couldn't scan the access log for it
> because I had no idea what 'too long' meant.
> I will ignore it until someone says they're unable to access a
> website, and they can give me details of what it is.
>
>
> On 13 December 2016 at 19:51, Eliezer Croitoru <eliezer at ngtech.co.il
> <mailto:eliezer at ngtech.co.il>> wrote:
>
>     I think that the maximum size was 64k and it's way above this.
>     It should not be an issue if this is some weird application
>     creating some random url which doesn't have meaning.
>     But if you know what is creating such a url it's a whole another
>     story.
>     Can you reproduce\recreate this url?
>
>     Eliezer
>
>     ----
>     Eliezer Croitoru
>     Linux System Administrator
>     Mobile+WhatsApp: +972-5-28704261
>     Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>
>
>
>
>     On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington
>     <odhiambo at gmail.com <mailto:odhiambo at gmail.com>> wrote:
>
>         Hi,
>
>         Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):
>
>         2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1)
>         Operation not permitted
>         2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1)
>         Operation not permitted
>         2016/12/13 11:47:55| HTCP Disabled.
>         2016/12/13 11:47:55| Finished loading MIME types and icons.
>         2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket
>         connections at local=[::]:13128 remote=[::] FD 39 flags=41
>         2016/12/13 11:47:55| Accepting HTTP Socket connections at
>         local=[::]:13130 remote=[::] FD 40 flags=9
>         2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped
>         HTTPS Socket connections at local=[::]:13129 remote=[::] FD 41
>         flags=41
>         2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
>         2016/12/13 11:47:55| Sending ICP messages from [::]:3130
>         *2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)*
>
>
>         -- 
>         Best regards,
>         Odhiambo WASHINGTON,
>         Nairobi,KE
>         +254 7 3200 0004/+254 7 2274 3223
>         "Oh, the cruft."
>
>
>
>
> -- 
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/1060f1d7/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 29577 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/1060f1d7/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/1060f1d7/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/1060f1d7/attachment.sig>

From eliezer at ngtech.co.il  Tue Dec 13 20:05:38 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 13 Dec 2016 22:05:38 +0200
Subject: [squid-users] URL too large??
In-Reply-To: <1c1d1fa3-771b-3ea0-4cfb-77ae4e0448d5@gmail.com>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
 <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
 <CAAdA2WPYFLTUWpGgv6JoFBuYb08zmBefoWBnZmYjucvpuoDkQA@mail.gmail.com>
 <1c1d1fa3-771b-3ea0-4cfb-77ae4e0448d5@gmail.com>
Message-ID: <0a5d01d2557c$464a8440$d2df8cc0$@ngtech.co.il>

Hey Yuri,

It's not right that the Internet is 4*8K in the urls.
It's just that it happens that some of the Internet users abuse their options to enter something in the browser.
Most browsers doesn't support more then 16k and the number which was mentioned was 100K++ so it's either not HTTP or something else.

If you are managing a network like a soho this is a very nice restriction to have 8k or 16k and in some cases 24k limit for a url maximum size.
The defaults are defaults but depends on the applications which are being used the choice of the defaults or special compiled version would change.

Eliezer
----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Tuesday, December 13, 2016 9:46 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] URL too large??

It means exactly what it said: URL too long.
In Squid's defaults set 8k for URL size. This was reasonable maximum 10 years ago.
Now it seems too small (at least 4 times) because of now Internet full of adware bullshit (referrals/trackers/counters etc.) which is often more 8k.
You can easy fix it (if you worry about it. It seems for end-user like hang/broken links) if you build squid from source. Just change vaule MAX_URL in src/defines.h and recompile.
But if you do this, beware - some things become slower, and danger of deinal of service exists.
That's it.
WBR, Yuri

14.12.2016 1:05, Odhiambo Washington ?????:
I did not dig deep into it I couldn't scan the access log for it because I had no idea what 'too long' meant. 
I will ignore it until someone says they're unable to access a website, and they can give me details of what it is.


On 13 December 2016 at 19:51, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
I think that the maximum size was 64k and it's way above this. 
It should not be an issue if this is some weird application creating some random url which doesn't have meaning.
But if you know what is creating such a url it's a whole another story.
Can you reproduce\recreate this url?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington <mailto:odhiambo at gmail.com> wrote:
Hi, 

Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):

2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/13 11:47:55| HTCP Disabled.
2016/12/13 11:47:55| Finished loading MIME types and icons.
2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket connections at local=[::]:13128 remote=[::] FD 39 flags=41
2016/12/13 11:47:55| Accepting HTTP Socket connections at local=[::]:13130 remote=[::] FD 40 flags=9
2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS Socket connections at local=[::]:13129 remote=[::] FD 41 flags=41
2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
2016/12/13 11:47:55| Sending ICP messages from [::]:3130
2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."




-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."



_______________________________________________
squid-users mailing list
mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

-- 
Cats - delicious. You just do not know how to cook them.



From yvoinov at gmail.com  Tue Dec 13 20:09:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Dec 2016 02:09:08 +0600
Subject: [squid-users] URL too large??
In-Reply-To: <0a5d01d2557c$464a8440$d2df8cc0$@ngtech.co.il>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
 <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
 <CAAdA2WPYFLTUWpGgv6JoFBuYb08zmBefoWBnZmYjucvpuoDkQA@mail.gmail.com>
 <1c1d1fa3-771b-3ea0-4cfb-77ae4e0448d5@gmail.com>
 <0a5d01d2557c$464a8440$d2df8cc0$@ngtech.co.il>
Message-ID: <1ff13c83-5dcc-4d15-9913-f4918220bc1b@gmail.com>

14.12.2016 2:05, Eliezer Croitoru ?????:
> Hey Yuri,
>
> It's not right that the Internet is 4*8K in the urls.
> It's just that it happens that some of the Internet users abuse their options to enter something in the browser.
> Most browsers doesn't support more then 16k and the number which was mentioned was 100K++ so it's either not HTTP or something else.
I don't care. I know all about this problem and solve it years ago.
>
> If you are managing a network like a soho this is a very nice restriction to have 8k or 16k and in some cases 24k limit for a url maximum size.
> The defaults are defaults but depends on the applications which are being used the choice of the defaults or special compiled version would change.
Please, stop lecture me. I have big enough networks, I'm solve this
problem years ago, I know exactly which URL_MAX satisfied my
requirements, I'm builds all critical software from sources, I know how
to change defaults and what are they means.

Thank you.
>
> Eliezer
> ----
> http://ngtech.co.il/lmgtfy/
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
> Sent: Tuesday, December 13, 2016 9:46 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] URL too large??
>
> It means exactly what it said: URL too long.
> In Squid's defaults set 8k for URL size. This was reasonable maximum 10 years ago.
> Now it seems too small (at least 4 times) because of now Internet full of adware bullshit (referrals/trackers/counters etc.) which is often more 8k.
> You can easy fix it (if you worry about it. It seems for end-user like hang/broken links) if you build squid from source. Just change vaule MAX_URL in src/defines.h and recompile.
> But if you do this, beware - some things become slower, and danger of deinal of service exists.
> That's it.
> WBR, Yuri
>
> 14.12.2016 1:05, Odhiambo Washington ?????:
> I did not dig deep into it I couldn't scan the access log for it because I had no idea what 'too long' meant. 
> I will ignore it until someone says they're unable to access a website, and they can give me details of what it is.
>
>
> On 13 December 2016 at 19:51, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
> I think that the maximum size was 64k and it's way above this. 
> It should not be an issue if this is some weird application creating some random url which doesn't have meaning.
> But if you know what is creating such a url it's a whole another story.
> Can you reproduce\recreate this url?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile+WhatsApp: +972-5-28704261
> Email: mailto:eliezer at ngtech.co.il
>
>
> On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington <mailto:odhiambo at gmail.com> wrote:
> Hi, 
>
> Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):
>
> 2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/13 11:47:55| HTCP Disabled.
> 2016/12/13 11:47:55| Finished loading MIME types and icons.
> 2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket connections at local=[::]:13128 remote=[::] FD 39 flags=41
> 2016/12/13 11:47:55| Accepting HTTP Socket connections at local=[::]:13130 remote=[::] FD 40 flags=9
> 2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS Socket connections at local=[::]:13129 remote=[::] FD 41 flags=41
> 2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
> 2016/12/13 11:47:55| Sending ICP messages from [::]:3130
> 2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)
>
>

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/2bb285b5/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/2bb285b5/attachment.sig>

From eliezer at ngtech.co.il  Tue Dec 13 20:28:31 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 13 Dec 2016 22:28:31 +0200
Subject: [squid-users] URL too large??
In-Reply-To: <1ff13c83-5dcc-4d15-9913-f4918220bc1b@gmail.com>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
 <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
 <CAAdA2WPYFLTUWpGgv6JoFBuYb08zmBefoWBnZmYjucvpuoDkQA@mail.gmail.com>
 <1c1d1fa3-771b-3ea0-4cfb-77ae4e0448d5@gmail.com>
 <0a5d01d2557c$464a8440$d2df8cc0$@ngtech.co.il>
 <1ff13c83-5dcc-4d15-9913-f4918220bc1b@gmail.com>
Message-ID: <0a6801d2557f$7869c190$693d44b0$@ngtech.co.il>

And you are still using squid?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Yuri Voinov [mailto:yvoinov at gmail.com] 
Sent: Tuesday, December 13, 2016 10:09 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] URL too large??

14.12.2016 2:05, Eliezer Croitoru ?????:
> Hey Yuri,
>
> It's not right that the Internet is 4*8K in the urls.
> It's just that it happens that some of the Internet users abuse their options to enter something in the browser.
> Most browsers doesn't support more then 16k and the number which was mentioned was 100K++ so it's either not HTTP or something else.
I don't care. I know all about this problem and solve it years ago.
>
> If you are managing a network like a soho this is a very nice restriction to have 8k or 16k and in some cases 24k limit for a url maximum size.
> The defaults are defaults but depends on the applications which are being used the choice of the defaults or special compiled version would change.
Please, stop lecture me. I have big enough networks, I'm solve this problem years ago, I know exactly which URL_MAX satisfied my requirements, I'm builds all critical software from sources, I know how to change defaults and what are they means.

Thank you.
>
> Eliezer
> ----
> http://ngtech.co.il/lmgtfy/
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of Yuri Voinov
> Sent: Tuesday, December 13, 2016 9:46 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] URL too large??
>
> It means exactly what it said: URL too long.
> In Squid's defaults set 8k for URL size. This was reasonable maximum 10 years ago.
> Now it seems too small (at least 4 times) because of now Internet full of adware bullshit (referrals/trackers/counters etc.) which is often more 8k.
> You can easy fix it (if you worry about it. It seems for end-user like hang/broken links) if you build squid from source. Just change vaule MAX_URL in src/defines.h and recompile.
> But if you do this, beware - some things become slower, and danger of deinal of service exists.
> That's it.
> WBR, Yuri
>
> 14.12.2016 1:05, Odhiambo Washington ?????:
> I did not dig deep into it I couldn't scan the access log for it because I had no idea what 'too long' meant. 
> I will ignore it until someone says they're unable to access a website, and they can give me details of what it is.
>
>
> On 13 December 2016 at 19:51, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
> I think that the maximum size was 64k and it's way above this. 
> It should not be an issue if this is some weird application creating some random url which doesn't have meaning.
> But if you know what is creating such a url it's a whole another story.
> Can you reproduce\recreate this url?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile+WhatsApp: +972-5-28704261
> Email: mailto:eliezer at ngtech.co.il
>
>
> On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington <mailto:odhiambo at gmail.com> wrote:
> Hi,
>
> Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):
>
> 2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not 
> permitted
> 2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not 
> permitted
> 2016/12/13 11:47:55| HTCP Disabled.
> 2016/12/13 11:47:55| Finished loading MIME types and icons.
> 2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket connections 
> at local=[::]:13128 remote=[::] FD 39 flags=41
> 2016/12/13 11:47:55| Accepting HTTP Socket connections at 
> local=[::]:13130 remote=[::] FD 40 flags=9
> 2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS Socket 
> connections at local=[::]:13129 remote=[::] FD 41 flags=41
> 2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
> 2016/12/13 11:47:55| Sending ICP messages from [::]:3130
> 2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)
>
>

--
Cats - delicious. You just do not know how to cook them.



From yvoinov at gmail.com  Tue Dec 13 20:38:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Dec 2016 02:38:14 +0600
Subject: [squid-users] URL too large??
In-Reply-To: <0a6801d2557f$7869c190$693d44b0$@ngtech.co.il>
References: <CAAdA2WOGMf2mg2T1Gcy6Q+i0r1=uqp7S6DyW7ao2M_Vr1AbAhQ@mail.gmail.com>
 <cb0f514cabc8d2466aeeb19be0f77990@ngtech.co.il>
 <CAAdA2WPYFLTUWpGgv6JoFBuYb08zmBefoWBnZmYjucvpuoDkQA@mail.gmail.com>
 <1c1d1fa3-771b-3ea0-4cfb-77ae4e0448d5@gmail.com>
 <0a5d01d2557c$464a8440$d2df8cc0$@ngtech.co.il>
 <1ff13c83-5dcc-4d15-9913-f4918220bc1b@gmail.com>
 <0a6801d2557f$7869c190$693d44b0$@ngtech.co.il>
Message-ID: <6e0257f5-9ddc-6298-5b10-4b3933f78cb1@gmail.com>

Yes.

Let's cut discussion. Answer to op, not for me. If you have to tell some.


14.12.2016 2:28, Eliezer Croitoru ?????:
> And you are still using squid?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: Yuri Voinov [mailto:yvoinov at gmail.com] 
> Sent: Tuesday, December 13, 2016 10:09 PM
> To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] URL too large??
>
> 14.12.2016 2:05, Eliezer Croitoru ?????:
>> Hey Yuri,
>>
>> It's not right that the Internet is 4*8K in the urls.
>> It's just that it happens that some of the Internet users abuse their options to enter something in the browser.
>> Most browsers doesn't support more then 16k and the number which was mentioned was 100K++ so it's either not HTTP or something else.
> I don't care. I know all about this problem and solve it years ago.
>> If you are managing a network like a soho this is a very nice restriction to have 8k or 16k and in some cases 24k limit for a url maximum size.
>> The defaults are defaults but depends on the applications which are being used the choice of the defaults or special compiled version would change.
> Please, stop lecture me. I have big enough networks, I'm solve this problem years ago, I know exactly which URL_MAX satisfied my requirements, I'm builds all critical software from sources, I know how to change defaults and what are they means.
>
> Thank you.
>> Eliezer
>> ----
>> http://ngtech.co.il/lmgtfy/
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
>> On Behalf Of Yuri Voinov
>> Sent: Tuesday, December 13, 2016 9:46 PM
>> To: squid-users at lists.squid-cache.org
>> Subject: Re: [squid-users] URL too large??
>>
>> It means exactly what it said: URL too long.
>> In Squid's defaults set 8k for URL size. This was reasonable maximum 10 years ago.
>> Now it seems too small (at least 4 times) because of now Internet full of adware bullshit (referrals/trackers/counters etc.) which is often more 8k.
>> You can easy fix it (if you worry about it. It seems for end-user like hang/broken links) if you build squid from source. Just change vaule MAX_URL in src/defines.h and recompile.
>> But if you do this, beware - some things become slower, and danger of deinal of service exists.
>> That's it.
>> WBR, Yuri
>>
>> 14.12.2016 1:05, Odhiambo Washington ?????:
>> I did not dig deep into it I couldn't scan the access log for it because I had no idea what 'too long' meant. 
>> I will ignore it until someone says they're unable to access a website, and they can give me details of what it is.
>>
>>
>> On 13 December 2016 at 19:51, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
>> I think that the maximum size was 64k and it's way above this. 
>> It should not be an issue if this is some weird application creating some random url which doesn't have meaning.
>> But if you know what is creating such a url it's a whole another story.
>> Can you reproduce\recreate this url?
>>
>> Eliezer
>>
>> ----
>> Eliezer Croitoru
>> Linux System Administrator
>> Mobile+WhatsApp: +972-5-28704261
>> Email: mailto:eliezer at ngtech.co.il
>>
>>
>> On Tue, Dec 13, 2016 at 11:08 AM, Odhiambo Washington <mailto:odhiambo at gmail.com> wrote:
>> Hi,
>>
>> Saw this on my cache.log (squid-3.5.22, FreeBSD-9.3,):
>>
>> 2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not 
>> permitted
>> 2016/12/13 11:47:55| WARNING: no_suid: setuid(0): (1) Operation not 
>> permitted
>> 2016/12/13 11:47:55| HTCP Disabled.
>> 2016/12/13 11:47:55| Finished loading MIME types and icons.
>> 2016/12/13 11:47:55| Accepting NAT intercepted HTTP Socket connections 
>> at local=[::]:13128 remote=[::] FD 39 flags=41
>> 2016/12/13 11:47:55| Accepting HTTP Socket connections at 
>> local=[::]:13130 remote=[::] FD 40 flags=9
>> 2016/12/13 11:47:55| Accepting NAT intercepted SSL bumped HTTPS Socket 
>> connections at local=[::]:13129 remote=[::] FD 41 flags=41
>> 2016/12/13 11:47:55| Accepting ICP messages on [::]:3130
>> 2016/12/13 11:47:55| Sending ICP messages from [::]:3130
>> 2016/12/13 11:53:25| urlParse: URL too large (11654 bytes)
>>
>>
> --
> Cats - delicious. You just do not know how to cook them.
>

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/990c4b02/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/990c4b02/attachment.sig>

From sb33781 at gmail.com  Tue Dec 13 22:44:12 2016
From: sb33781 at gmail.com (Steve Becker)
Date: Tue, 13 Dec 2016 17:44:12 -0500
Subject: [squid-users] Looking for additional information about securing
	squid
Message-ID: <032e01d25592$6dc15a60$49440f20$@com>

Hi all,

 

My background's in networking, I'm very new to unix/linux and server
administration, I don't know a whole lot about security beyond ACLs and
setting up crypto for VPNs. I'm setting up a box at home with CentOS and
squid, among other features (I want this box to be a syslog server, etc).
At the moment I have no plan to run a web server, but I'm still concerned.
I know web servers are vulnerable to certain kinds of attacks, some of which
could escalate user privileges or dump data people shouldn't have access to.
Is squid, as a proxy server, I'm vulnerable to some of these kinds of
attacks?  I'll be limiting squid to only accept traffic from my LAN but you
still never know.  A guest might use my network with an infected device,
etc.

 

I've looked at the security FAQ on the squid wiki, and I tried to search the
mailing list archive using the link at
http://www.squid-cache.org/Support/mailing-lists.html, however I get a 404
error.  I downloaded the last 6 months worth of archives and searched for
the word security, and I see references to SSL, TLS, bumping, etc.  I'm sure
these conversations follow the requirements of people using squid at work
but aside from one thread I don't see anything addressing my concerns, hence
my post.

 

I suspect there's no more additional securing of squid I need to do - if
there were I would've expected something to mention it in the FAQ - but I'd
rather ask just in case.  Any thoughts/suggestions?

 

TIA

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161213/5f7329f2/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec 13 22:50:48 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Dec 2016 11:50:48 +1300
Subject: [squid-users] Transparent HTTPs proxy with Squid 3.5
In-Reply-To: <o2oe72$tpv$1@saturn.local.net>
References: <CABEkGyZRkP_j2s3PGjgdQBNb=Z6x7QjmjmUNVWKk+2k4Y8v7tg@mail.gmail.com>
 <e9a871a6-d1cc-3dec-7c24-583abeabf9d1@treenet.co.nz>
 <o2oe72$tpv$1@saturn.local.net>
Message-ID: <e5c447b3-8b54-c8b8-053d-6cd74236dc73@treenet.co.nz>

On 13/12/2016 10:15 p.m., Per Jessen wrote:
> Amos Jeffries wrote:
> 
>> On 13/12/2016 5:11 a.m., Fomo Dong wrote:
>>> Hi all,
>>>
>>> For couple of days I'm trying to figure out how to get a transparent
>>> HTTPs proxy to work with Squid. What I'm trying to achieve is a proxy
>>> that accepts internet traffic from ports 80 & 443, routes them
>>> through Squid to Privoxy and finally through Tor and returns back the
>>> data. So essentially I want to "automatically" revert some traffic
>>> through Tor without the user needing to add a proxy to their
>>> connection.
>>>
>>> I know how to setup the Privoxy and Tor part, but I'm struggling with
>>> the Squid & IP tables configuration.
>>
>> The first thing to be aware of is that Squid obeys the HTTPS
>> requirement that traffic received on TLS connection also goes out one.
>> So your Privoxy must be capable of receiving TLS connections from
>> Squid.
>>
>> If Privoxy cannot do TLS like that you could have Squid do the privacy
>> filtering. But then Tor would face the same requirement.
>>
>>
>> Second thing I want to make clear is that a *transparent* proxy is the
>> opposite of anonyizing proxy. A transparent proxy hides *itself* while
>> _revealing_ the client.  An anonymous proxy reveals itself, while
>> hiding the client(s). They are almost direct opposites in behaviour.
>>
>> Anyhow, what you meant by the word "transparent" turns out to actually
>> be "intercepting". 
> 
> We also run a "transparent" proxy, but it is transparent for the
> _client_.  The main office router simply sends an ICMP redirect to
> point clients to the proxy. 
> 

Uh, ICMP redirect informs the client that its not contacting the
original server. It also implies there are no NAT records for the proxy
to lookup to resolve the ORIGINAL_DST address.

How does that work with the 'transparent' mode flag on your http_port
line(s)? Not well I suspect.


It is people calling non-transparent things like that "transparent"
which has led to Fomo's problem of the configuration being half *actual*
Transparent Proxy (TPROXY, 'tproxy' mode) and half NAT interception
(REDIRECT, 'intercept' mode).

Amos



From Antony.Stone at squid.open.source.it  Wed Dec 14 00:38:18 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 14 Dec 2016 01:38:18 +0100
Subject: [squid-users] Looking for additional information about securing
	squid
In-Reply-To: <032e01d25592$6dc15a60$49440f20$@com>
References: <032e01d25592$6dc15a60$49440f20$@com>
Message-ID: <201612140138.18317.Antony.Stone@squid.open.source.it>

On Tuesday 13 December 2016 at 23:44:12, Steve Becker wrote:

> Hi all,

Hi.

> My background's in networking, I'm very new to unix/linux and server
> administration, I don't know a whole lot about security beyond ACLs and
> setting up crypto for VPNs.
>
> I'm setting up a box at home with CentOS and squid,

> I know web servers are vulnerable to certain kinds of attacks, some of
> which could escalate user privileges or dump data people shouldn't have
> access to. Is squid, as a proxy server, I'm vulnerable to some of these
> kinds of attacks?  I'll be limiting squid to only accept traffic from my
> LAN but you still never know.  A guest might use my network with an
> infected device, etc.

First question - what are you aiming / hoping to achieve by implementing 
Squid?

Second question - do you really give guests full access to your home network, 
rather than just "a gateway to the Internet with no visibility of my private 
machines"?


Antony.

-- 
I wasn't sure about having a beard at first, but then it grew on me.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Wed Dec 14 00:39:20 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Dec 2016 13:39:20 +1300
Subject: [squid-users] Looking for additional information about securing
 squid
In-Reply-To: <032e01d25592$6dc15a60$49440f20$@com>
References: <032e01d25592$6dc15a60$49440f20$@com>
Message-ID: <4c12d35e-2117-f60e-3e77-53f334253f22@treenet.co.nz>

On 14/12/2016 11:44 a.m., Steve Becker wrote:
> Hi all,
> 
>  
> 
> My background's in networking, I'm very new to unix/linux and server
> administration, I don't know a whole lot about security beyond ACLs and
> setting up crypto for VPNs. I'm setting up a box at home with CentOS and
> squid, among other features (I want this box to be a syslog server, etc).
> At the moment I have no plan to run a web server, but I'm still concerned.
> I know web servers are vulnerable to certain kinds of attacks, some of which
> could escalate user privileges or dump data people shouldn't have access to.
> Is squid, as a proxy server, I'm vulnerable to some of these kinds of
> attacks?

Generally no. Those types of attack require operations that Squid does
not do (executing something attacker-controlled). Though sometimes the
helpers and plugins people use might have such problems. Especially
badly written custom ones.

Squid (and other HTTP proxies) vulnerabilities tend to be along the
lines of; data leaks, DoS, cache poisoning, or message smuggling. The
result of those types is typically privacy abuses, or network hijacking
by allowing attack malwares to reach target servers or other clients.


>  I'll be limiting squid to only accept traffic from my LAN but you
> still never know.  A guest might use my network with an infected device,
> etc.
> 
> 
> I've looked at the security FAQ on the squid wiki, and I tried to search the
> mailing list archive using the link at
> http://www.squid-cache.org/Support/mailing-lists.html, however I get a 404
> error.  I downloaded the last 6 months worth of archives and searched for
> the word security, and I see references to SSL, TLS, bumping, etc.  I'm sure
> these conversations follow the requirements of people using squid at work
> but aside from one thread I don't see anything addressing my concerns, hence
> my post.
> 

It may not be easy to see at times, but most of the traffic on this list
includes a security aspect. The posters either have a specific
transaction problem, or some f'up in their config settings letting
traffic do unwanted things.
 To resolve that type of thing we not only have to provide a solution
but try to ensure the admin in question (and future readers) understands
why it solves the problem, and whether there are any risks associated
(ie security considerations).

(Thanks for the mention of that 404. Looking into it now.)

> 
> I suspect there's no more additional securing of squid I need to do - if
> there were I would've expected something to mention it in the FAQ - but I'd
> rather ask just in case.  Any thoughts/suggestions?
> 

Yes. The default installation of Squid is very secure so far as CVE type
vulnerability issues go. We do aim to be completely secure (if only it
were possible!). But that naturally varies by version and what is known
about.


As for an attacker in your LAN; they can use the proxy default config to
do some limited HTTP things, but they would be able to do even more
nasties if they didn't go through Squids protocol sanitizing/validation
logics. The risk is relative to your overall network security design,
and that should of course be considered before starting a proxy in any
network more secure than what the default squid.conf allows.


The wiki in general has a lot of info, most of it is under specific
config examples or feature documentations rather than the FAQ. The
squid.conf documentation also has 'WARNING' and mentions of issues
related to using the relevant directives.

If you want advice about specific features that is not mentioned in the
relevant squid.conf directive docs or the wiki, feel free to ask. But
security is a rather big topic so pardon if I dont try to brain-dump
everything right here :-)

Amos



From squid3 at treenet.co.nz  Wed Dec 14 01:10:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Dec 2016 14:10:02 +1300
Subject: [squid-users] squid bind username to same ip but different port
In-Reply-To: <4C22FF79-D4C6-4368-8B33-4A6143587C34@netstream.ps>
References: <4C22FF79-D4C6-4368-8B33-4A6143587C34@netstream.ps>
Message-ID: <0be7be03-3849-21e7-c2a7-d83879372fb8@treenet.co.nz>

On 14/12/2016 3:18 a.m., --Ahmad-- wrote:
> 
> im not sure if the directive :
> 
> external_acl_type type-name %SRC %LOGIN /path/to/ext_file_userip_acl -f /path/to/config.file
> 
> will help becuase its description on ip/mask , not ip:port
> 

If you want to write your own helper you could base it on that ones code
easily enough. But as you see it does not consider port numbers, since
HTTP is multiplexed it is rare for ports to matter beyond the 80, 443,
3128 triplet which have different syntaxes.

You could use the ext_sql_session_acl helper. Just pass it the port and
username as the session key. It has the extra benefit of not
auto-creating sessions but relying on you filling the database via some
other registration system.

Amos



From creditu at eml.cc  Wed Dec 14 01:10:40 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Tue, 13 Dec 2016 18:10:40 -0700
Subject: [squid-users] Proper Cache Peer Access
Message-ID: <1481677840.246532.818227873.09759741@webmail.messagingengine.com>

Looking for the best way to provide cache peer access for two urls on a
3.1 accelerator.  For example if a set of backend servers fullfill
requests for both www.example.com and www-legacy.example.com is the
following the correct way to handle them in regards to the cach peer
access? 


http_port 192.168.100.1:80 accel defaultsite=www.example.com vhost
http_port 192.168.100.2:80 accel defaultsite=dev.example.com vhost

https_port 192.168.100.1:443 accel defaultsite=www.example.com vhost
cert=/path/cert.pem key=/path/key.pem
https_port 192.168.100.2:443 accel defaultsite=dev.example.com vhost
cert=/path/cert.pem key=/path/key.pem

# Backend servers for www and www-legacy
acl www dstdomain www.example.com
acl www-legacy dstdomain www-legacy.example.com
cache_peer 10.10.10.1 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.1 allow www
cache_peer_access 10.10.10.1 allow www-legacy
cache_peer_access 10.10.10.1 deny all

cache_peer 10.10.10.2 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.2 allow www
cache_peer_access 10.10.10.2 allow www-legacy
cache_peer_access 10.10.10.2 deny all

# Backend server for dev
acl dev dstdomain dev.example.com
cache_peer 10.10.10.3 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.3 allow dev
cache_peer_access 10.10.10.3 deny all


From squid3 at treenet.co.nz  Wed Dec 14 01:33:45 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Dec 2016 14:33:45 +1300
Subject: [squid-users] Proper Cache Peer Access
In-Reply-To: <1481677840.246532.818227873.09759741@webmail.messagingengine.com>
References: <1481677840.246532.818227873.09759741@webmail.messagingengine.com>
Message-ID: <6ac90a52-3089-2d21-417d-98ed4a159200@treenet.co.nz>

On 14/12/2016 2:10 p.m., creditu wrote:
> Looking for the best way to provide cache peer access for two urls on a
> 3.1 accelerator.  For example if a set of backend servers fullfill
> requests for both www.example.com and www-legacy.example.com is the
> following the correct way to handle them in regards to the cach peer
> access? 
> 

What you have works and is fine for simple setups like yours.

However, since you ask for "proper" ...

<snip>
> 
> # Backend servers for www and www-legacy
> acl www dstdomain www.example.com
> acl www-legacy dstdomain www-legacy.example.com

Recommended practice when you have same-type data and ACLs used in
identical ways like these ones. Is to place both those domain values in
the one ACL named 'www'. That will simplify your access lines.

There are some tiny memory and (cumulative) speed gains. But the biggest
reason is easier understanding and maintenance of the config if/when it
gets more complex.

Amos



From creditu at eml.cc  Wed Dec 14 01:56:30 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Tue, 13 Dec 2016 18:56:30 -0700
Subject: [squid-users] Proper Cache Peer Access
In-Reply-To: <6ac90a52-3089-2d21-417d-98ed4a159200@treenet.co.nz>
References: <1481677840.246532.818227873.09759741@webmail.messagingengine.com>
 <6ac90a52-3089-2d21-417d-98ed4a159200@treenet.co.nz>
Message-ID: <1481680590.257524.818258457.53390C0E@webmail.messagingengine.com>

On Tue, Dec 13, 2016, at 06:33 PM, Amos Jeffries wrote:
> On 14/12/2016 2:10 p.m., creditu wrote:
> > Looking for the best way to provide cache peer access for two urls on a
> > 3.1 accelerator.  For example if a set of backend servers fullfill
> > requests for both www.example.com and www-legacy.example.com is the
> > following the correct way to handle them in regards to the cach peer
> > access? 
> > 
> 
> What you have works and is fine for simple setups like yours.
> 
> However, since you ask for "proper" ...
> 
> <snip>
> > 
> > # Backend servers for www and www-legacy
> > acl www dstdomain www.example.com
> > acl www-legacy dstdomain www-legacy.example.com
> 
> Recommended practice when you have same-type data and ACLs used in
> identical ways like these ones. Is to place both those domain values in
> the one ACL named 'www'. That will simplify your access lines.
> 
> There are some tiny memory and (cumulative) speed gains. But the biggest
> reason is easier understanding and maintenance of the config if/when it
> gets more complex.
> 
> Amos
> 
> _______________

Ah, so you would do something like this:

acl www dstdomain www.example.com www-legacy.example.com
cache_peer 10.10.10.1 parent 80 0 no-query no-digest originserver
round-robin
cache_peer_access 10.10.10.1 allow www
cache_peer_access 10.10.10.1 deny all
. . .

I was worried about a situation that was detailed in
http://wiki.squid-cache.org/SquidFaq/SquidAcl#And.2FOr_logic (the src
address example).  Thanks


From sb33781 at gmail.com  Wed Dec 14 02:55:51 2016
From: sb33781 at gmail.com (Steve Becker)
Date: Tue, 13 Dec 2016 21:55:51 -0500
Subject: [squid-users] Looking for additional information about securing
	squid
In-Reply-To: <mailman.3616.1481677846.20516.squid-users@lists.squid-cache.org>
References: <mailman.3616.1481677846.20516.squid-users@lists.squid-cache.org>
Message-ID: <033601d255b5$94d4eef0$be7eccd0$@com>

> First question - what are you aiming / hoping to achieve by implementing
> Squid?

1. Some ad blocking via an MVPS hosts file. I'm not trying for a perfect solution, some ad blocking is better than none.

2. Parental control abilities. I like that squid can serve a local webpage that can say, "Facebook is only allowed between X hours on X days" instead of giving an unreachable response.

3. Possible small improvements in page response times due to web caching and ad blocking.

> Second question - do you really give guests full access to your home
> network, rather than just "a gateway to the Internet with no visibility
> of my private machines"?

At the moment, yes.  It's a work in progress.  I can count on one hand the number of people I've allowed access to in the last year and my wifi is secured as best it can be.  That said, I recognize that - as the saying goes - locks only keep good people out.

> data leaks
> cache poisoning
> message smuggling

I need to read up on cache poisoning, haven't heard of that one. Not sure what you mean by message smuggling.  And yes, the data leaks was what I knew enough to be asking about.  Specifically my concern is that someone could gain control of my server and install malware/trojan/work/whatever.  I'm not that good with Linux yet so I probably wouldn't even know where to begin looking for something like that, much less clean it off.  And I would expect the malware/antivirus safeguards I have on my PCs would be less effective if there's a server on the same LAN possibly attacking them 24/7.

> The risk is relative to your overall network security design, and that
> should of course be considered before starting a proxy in any network
> more secure than what the default squid.conf allows.

<joke>
Well I'm sure my network is *less* secure than what the default squid.conf allows so no worries, eh?
</joke>

> If you want advice about specific features that is not mentioned in the
> relevant squid.conf directive docs or the wiki, feel free to ask. But
> security is a rather big topic so pardon if I dont try to brain-dump
> everything right here :-)

Understood. Antony was on the right track with asking about my objectives.

As far as non-standard squid config ... I really wish I could link you to the website I used as a template to add onto the default squid install. Normally I save the web link in the txt file with the notes I've made but I seem to have forgotten to save the link in this one.  I've spent about the last 20 minutes searching but I can't find the page.  There were a few things I added for rate limiting Windows update and allowing Youtube and cgi-bin pages to be cached, but the modifications shouldn't have affect permissions, etc.  I don't think they would, but would've liked to have linked you to that page.



From fredbmail at free.fr  Wed Dec 14 09:46:35 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 14 Dec 2016 10:46:35 +0100 (CET)
Subject: [squid-users] Squid 3.5.21 ssl bump and x-forward
In-Reply-To: <1207850530.86747654.1480498480274.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1347513797.133685986.1481708795627.JavaMail.root@zimbra4-e1.priv.proxad.net>

If really needed, there is a patch here http://bugs.squid-cache.org/show_bug.cgi?id=3792
But as Amos said this patch is incomplete the CONNECT XFF header contents should also be added to the bumped request

Fred


From noc at forceline.net  Wed Dec 14 11:40:10 2016
From: noc at forceline.net (noc at forceline.net)
Date: Wed, 14 Dec 2016 14:40:10 +0300
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory: Kill
	process (squid)
Message-ID: <039901d255fe$d80cfe30$8826fa90$@net>


Hello. I wrote earlier in wrong location:
http://bugs.squid-cache.org/show_bug.cgi?id=4647

> Squid eats all RAM, then eats all swap in a hour and killed by kernel.
>I was try to turn off cache, change squid version, change some
configuration parameters by this guide
http://wiki.squid-cache.org/SquidFaq/SquidMemory except malloc, but nothing
helps.

I made some config changes in accordance with the advice of Amos Jeffries
(via on). But it does not help.
This trouble somehow linked with https.
If wccp redirects only 80 port - works fine.
  wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority = 231
ports = 80
If wccp redirects 443 too - then squid overflows and killed by kernel
  wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority = 231
ports = 80,443

---Before it died (HTTPS on):
Mem:  16291720k total, 16125288k used,   166432k free,      540k buffers
Swap:  8216568k total,  8112628k used,   103940k free,    27112k cached
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
30858 squid     20   0 22.7g  14g 3612 S  8.0 94.6  14:50.82 squid


# free -m
             total       used       free     shared    buffers     cached
Mem:         15909      15750        158          0          0         26
-/+ buffers/cache:      15723        186
Swap:         8023       7936         87


Start Time:	Sat, 10 Dec 2016 07:52:50 GMT
Current Time:	Sat, 10 Dec 2016 09:39:45 GMT

Connection information for squid:
	Number of clients accessing cache:	1305
	Number of HTTP requests received:	193434
	Number of ICP messages received:	0
	Number of ICP messages sent:	0
	Number of queued ICP replies:	0
	Number of HTCP messages received:	0
	Number of HTCP messages sent:	0
	Request failure ratio:	 0.00
	Average HTTP requests per minute since start:	1809.2
	Average ICP messages per minute since start:	0.0
	Select loop called: 4529796 times, 1.416 ms avg
Cache information for squid:
	Hits as % of all requests:	5min: 0.0%, 60min: 0.0%
	Hits as % of bytes sent:	5min: 0.1%, 60min: -0.0%
	Memory hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
	Disk hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
	Storage Swap size:	82044 KB
	Storage Swap capacity:	80.1% used, 19.9% free
	Storage Mem size:	107876 KB
	Storage Mem capacity:	20.6% used, 79.4% free
	Mean Object Size:	29.54 KB
	Requests given to unlinkd:	9258
Median Service Times (seconds)  5 min    60 min:
	HTTP Requests (All):   0.10857  0.04519
	Cache Misses:          0.01648  0.00678
	Cache Hits:            0.00000  0.00000
	Near Hits:             0.00000  0.00000
	Not-Modified Replies:  0.00000  0.00000
	DNS Lookups:           0.00860  0.00779
	ICP Queries:           0.00000  0.00000
Resource usage for squid:
	UP Time:	6415.101 seconds
	CPU Time:	902.767 seconds
	CPU Usage:	14.07%
	CPU Usage, 5 minute avg:	15.97%
	CPU Usage, 60 minute avg:	13.96%
	Maximum Resident Size: 62241760 KB
	Page faults with physical i/o: 32647
Memory accounted for:
	Total accounted:       1073388 KB
	memPoolAlloc calls:     12969
	memPoolFree calls:   35802441
File descriptor usage for squid:
	Maximum number of file descriptors:   100000
	Largest file desc currently in use:   28744
	Number of file desc currently in use: 28738
	Files queued for open:                   0
	Available number of file descriptors: 71262
	Reserved number of file descriptors:   100
	Store Disk files open:                   0
Internal Data Structures:
	 57337 StoreEntries
	 54560 StoreEntries with MemObjects
	    52 Hot Object Cache Items
	  2777 on-disk objects

---after:
/var/log/messages
kernel: 11733 total pagecache pages
kernel: 8957 pages in swap cache
kernel: Swap cache stats: add 21118384, delete 21109427, find
12110273/12422740
kernel: Free swap  = 0kB
kernel: Total swap = 8216568kB
kernel: 4194303 pages RAM
kernel: 121373 pages reserved
kernel: 11781 pages shared
kernel: 4023631 pages non-shared
...omitted...
kernel: Out of memory: Kill process 30858 (squid) score 954 or sacrifice
child
kernel: Killed process 30868, UID 23, (log_file_daemon) total-vm:26640kB,
anon-rss:48kB, file-rss:512kB
(squid-1): I don't handle this error well!
Dec 10 12:44:27 localhost squid[30855]: Squid Parent: (squid-1) process
30858 exited due to signal 9 with status 0


In attach all /var/log/messages output.
Main task for the server is to block bad sites and bypass others on same
IPs.
Any ideas?

--
Sergey

-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 2470 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/f39b395f/attachment.obj>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mgr-info_only-http.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/f39b395f/attachment.txt>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: messages_when_died
Type: application/octet-stream
Size: 11847 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/f39b395f/attachment-0001.obj>

From bjoern.wahl at hospital-borken.de  Wed Dec 14 12:06:15 2016
From: bjoern.wahl at hospital-borken.de (bjoern wahl)
Date: Wed, 14 Dec 2016 13:06:15 +0100
Subject: [squid-users] Antw: RE: Antw: RE: squid-3.3.8-26.el7_2.4.x86_64
 using Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth
In-Reply-To: <09a801d25546$186c5430$4944fc90$@ngtech.co.il>
References: <584EB9B402000009000242C9@mail01.hospital-borken.de>
 <000101d25481$e6890720$b39b1560$@ngtech.co.il>
 <584FADF902000009000242F7@mail01.hospital-borken.de>
 <09a801d25546$186c5430$4944fc90$@ngtech.co.il>
Message-ID: <585143C7020000090002434F@mail01.hospital-borken.de>

I would like to use a group, but i would be happy if anything with ldap
would be working.

Just in case, i did a tcpdump an i can see that the server communicates
with the ldap-server, and that the squid gets an answer.



>>> Eliezer Croitoru <eliezer at ngtech.co.il> 13.12.16 14.37 Uhr >>>
Which of the helpers are you having issues with?
The Group or the user one?
I did some experiment with ldap groups which can be found at:
http://lists.squid-cache.org/pipermail/squid-users/2015-July/004874.html

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: bjoern wahl [mailto:bjoern.wahl at hospital-borken.de] 
Sent: Tuesday, December 13, 2016 9:15 AM
To: squid-users at lists.squid-cache.org; eliezer at ngtech.co.il
Subject: Antw: RE: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using
Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth


Hello!

Thanks for the fast response.

I got the Ldap-Auth working with

SLES11.4 / squid3-3.1.23-8.16.33.2
=========================================================================================================
auth_param basic program /usr/sbin/squid_ldap_auth -d -D "cn=xxx,o=xxxx"
-w xx -b o=x -s sub -f "(&(objectclass=User)(cn=%s))" -h ldaps://xxxx -p
636

external_acl_type ldap_group %LOGIN /usr/sbin/squid_ldap_group -d -D
"cn=xx,o=x" -w ldap -b o=x -s sub -f
"(&(objectclass=User)(cn=%u)(groupMembership=%g))" -h ldaps://x -p 636
=========================================================================================================

but now i would like to do it with

CentOS Linux release 7.2.1511 / squid-3.3.8-26.el7_2.4.x86_64

and it turned out the I have no more "squid_ldap_auth" but i found
"basic_ldap_auth".
So it tried switching "squid_ldap_auth" to "basic_ldap_auth" but that
did not work....

I get the login window, but even if i enter a vaild user, i can not
access a website.

squid.conf looks like this:

=========================================================================================================
auth_param basic program /usr/lib64/squid/basic_ldap_auth -d -D
"cn=xxx,o=xxx" -w xxx -b o=xxx -s sub -f "(&(objectclass=User)(cn=%s))"
-h ldaps://xxxx -p 636

auth_param basic children 5
auth_param basic credentialsttl 2 hours
acl ediruser proxy_auth REQUIRE
http_access allow ediruser
http_access deny all

=========================================================================================================


>>> Eliezer Croitoru <eliezer at ngtech.co.il> 12.12.16 15.28 Uhr >>>
Hey,

digest_edirectory_auth is not for LDAP but for edirectory but I a not
too familiar with this to tell you how to test.
Basically you need a "basic" ldap authentication helper Which the source
is:
http://bazaar.launchpad.net/~squid/squid/3.5/files/head:/helpers/basic_auth/LDAP/
And we are also missing the squid.conf.
Try find out if there some helper in the /usr/lib64/squid/ directory
which contains ldap.

Let me know if we are on the right direction.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of bjoern wahl
Sent: Monday, December 12, 2016 3:53 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell
eDirectory with /usr/lib64/squid/digest_edirectory_auth

Hello!

I would like to install a squid-3.3.8-26.el7_2.4.x86_64 (CentOS7) using
LDAP auth with digest_edirectory_auth, but i can not get it working.

Does anybody user this ?

I tried:


/usr/lib64/squid/digest_edirectory_auth -A password -l : -e -v 3 -D
"cn=xxxx,o=xxxxx" -b "o=xxxxx" -w xxxx -b o=xxxx -s sub -F
"(&(objectclass=User)(cn=%s))" -Z -h ldaps://xxxxxx -n

but i only get:


user1 pw1
ERR
user2 pw2
ERR
user3 pw3
ERR

Any ideas ?


Thanks, Bj?rn !

Tr?ger: Klinikum Westm?nsterland GmbHGesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken Registergericht
Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (SprechDiese E-Mail
enth?lt vertrauliche oder rechtlich gesch?tzte Informationen. Wenn Sie
nicht der beabsichtigte Empf?nger sind, informieren Sie bitte sofort den
Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.






Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.





From eliezer at ngtech.co.il  Wed Dec 14 14:02:15 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 14 Dec 2016 16:02:15 +0200
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
	Kill	process (squid)
In-Reply-To: <039901d255fe$d80cfe30$8826fa90$@net>
References: <039901d255fe$d80cfe30$8826fa90$@net>
Message-ID: <0a9501d25612$ad0483c0$070d8b40$@ngtech.co.il>

First goes first change this:
https_port 192.168.253.10:3130 intercept ssl-bump
options=ALL:NO_SSLv3:NO_SSLv2 connection-auth=off
cert=/etc/squid/squidCA.pem

into:
http_port 192.168.253.10:13130 intercept ssl-bump
options=ALL:NO_SSLv3:NO_SSLv2 connection-auth=off
cert=/etc/squid/squidCA.pem

and iptables accordingly.
Are you working based on some tutorial?
If so please attach the link to it.
Notice that port 3130 is officially a port which should not be used for
interception but for other purposes.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of noc at forceline.net
Sent: Wednesday, December 14, 2016 1:40 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory: Kill
process (squid)


Hello. I wrote earlier in wrong location:
http://bugs.squid-cache.org/show_bug.cgi?id=4647

> Squid eats all RAM, then eats all swap in a hour and killed by kernel.
>I was try to turn off cache, change squid version, change some
configuration parameters by this guide
http://wiki.squid-cache.org/SquidFaq/SquidMemory except malloc, but nothing
helps.

I made some config changes in accordance with the advice of Amos Jeffries
(via on). But it does not help.
This trouble somehow linked with https.
If wccp redirects only 80 port - works fine.
  wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority = 231
ports = 80 If wccp redirects 443 too - then squid overflows and killed by
kernel
  wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority = 231
ports = 80,443

---Before it died (HTTPS on):
Mem:  16291720k total, 16125288k used,   166432k free,      540k buffers
Swap:  8216568k total,  8112628k used,   103940k free,    27112k cached
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
30858 squid     20   0 22.7g  14g 3612 S  8.0 94.6  14:50.82 squid


# free -m
             total       used       free     shared    buffers     cached
Mem:         15909      15750        158          0          0         26
-/+ buffers/cache:      15723        186
Swap:         8023       7936         87


Start Time:	Sat, 10 Dec 2016 07:52:50 GMT
Current Time:	Sat, 10 Dec 2016 09:39:45 GMT

Connection information for squid:
	Number of clients accessing cache:	1305
	Number of HTTP requests received:	193434
	Number of ICP messages received:	0
	Number of ICP messages sent:	0
	Number of queued ICP replies:	0
	Number of HTCP messages received:	0
	Number of HTCP messages sent:	0
	Request failure ratio:	 0.00
	Average HTTP requests per minute since start:	1809.2
	Average ICP messages per minute since start:	0.0
	Select loop called: 4529796 times, 1.416 ms avg Cache information
for squid:
	Hits as % of all requests:	5min: 0.0%, 60min: 0.0%
	Hits as % of bytes sent:	5min: 0.1%, 60min: -0.0%
	Memory hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
	Disk hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
	Storage Swap size:	82044 KB
	Storage Swap capacity:	80.1% used, 19.9% free
	Storage Mem size:	107876 KB
	Storage Mem capacity:	20.6% used, 79.4% free
	Mean Object Size:	29.54 KB
	Requests given to unlinkd:	9258
Median Service Times (seconds)  5 min    60 min:
	HTTP Requests (All):   0.10857  0.04519
	Cache Misses:          0.01648  0.00678
	Cache Hits:            0.00000  0.00000
	Near Hits:             0.00000  0.00000
	Not-Modified Replies:  0.00000  0.00000
	DNS Lookups:           0.00860  0.00779
	ICP Queries:           0.00000  0.00000
Resource usage for squid:
	UP Time:	6415.101 seconds
	CPU Time:	902.767 seconds
	CPU Usage:	14.07%
	CPU Usage, 5 minute avg:	15.97%
	CPU Usage, 60 minute avg:	13.96%
	Maximum Resident Size: 62241760 KB
	Page faults with physical i/o: 32647
Memory accounted for:
	Total accounted:       1073388 KB
	memPoolAlloc calls:     12969
	memPoolFree calls:   35802441
File descriptor usage for squid:
	Maximum number of file descriptors:   100000
	Largest file desc currently in use:   28744
	Number of file desc currently in use: 28738
	Files queued for open:                   0
	Available number of file descriptors: 71262
	Reserved number of file descriptors:   100
	Store Disk files open:                   0
Internal Data Structures:
	 57337 StoreEntries
	 54560 StoreEntries with MemObjects
	    52 Hot Object Cache Items
	  2777 on-disk objects

---after:
/var/log/messages
kernel: 11733 total pagecache pages
kernel: 8957 pages in swap cache
kernel: Swap cache stats: add 21118384, delete 21109427, find
12110273/12422740
kernel: Free swap  = 0kB
kernel: Total swap = 8216568kB
kernel: 4194303 pages RAM
kernel: 121373 pages reserved
kernel: 11781 pages shared
kernel: 4023631 pages non-shared
...omitted...
kernel: Out of memory: Kill process 30858 (squid) score 954 or sacrifice
child
kernel: Killed process 30868, UID 23, (log_file_daemon) total-vm:26640kB,
anon-rss:48kB, file-rss:512kB
(squid-1): I don't handle this error well!
Dec 10 12:44:27 localhost squid[30855]: Squid Parent: (squid-1) process
30858 exited due to signal 9 with status 0


In attach all /var/log/messages output.
Main task for the server is to block bad sites and bypass others on same
IPs.
Any ideas?

--
Sergey




From eliezer at ngtech.co.il  Wed Dec 14 14:05:44 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 14 Dec 2016 16:05:44 +0200
Subject: [squid-users] Antw: RE: Antw: RE: squid-3.3.8-26.el7_2.4.x86_64
	using Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth
In-Reply-To: <585143C7020000090002434F@mail01.hospital-borken.de>
References: <584EB9B402000009000242C9@mail01.hospital-borken.de>
 <000101d25481$e6890720$b39b1560$@ngtech.co.il>
 <584FADF902000009000242F7@mail01.hospital-borken.de>
 <09a801d25546$186c5430$4944fc90$@ngtech.co.il>
 <585143C7020000090002434F@mail01.hospital-borken.de>
Message-ID: <0a9701d25613$29664020$7c32c060$@ngtech.co.il>

What have  you tried to test the helpers by themselves?
Let say you run from the command line the command which squid runs and like in the example in the mailing list which I attached,
What happens?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: bjoern wahl [mailto:bjoern.wahl at hospital-borken.de] 
Sent: Wednesday, December 14, 2016 2:06 PM
To: squid-users at lists.squid-cache.org; eliezer at ngtech.co.il
Subject: Antw: RE: Antw: RE: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth

I would like to use a group, but i would be happy if anything with ldap would be working.

Just in case, i did a tcpdump an i can see that the server communicates with the ldap-server, and that the squid gets an answer.



>>> Eliezer Croitoru <eliezer at ngtech.co.il> 13.12.16 14.37 Uhr >>>
Which of the helpers are you having issues with?
The Group or the user one?
I did some experiment with ldap groups which can be found at:
http://lists.squid-cache.org/pipermail/squid-users/2015-July/004874.html

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: bjoern wahl [mailto:bjoern.wahl at hospital-borken.de]
Sent: Tuesday, December 13, 2016 9:15 AM
To: squid-users at lists.squid-cache.org; eliezer at ngtech.co.il
Subject: Antw: RE: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell eDirectory with /usr/lib64/squid/digest_edirectory_auth


Hello!

Thanks for the fast response.

I got the Ldap-Auth working with

SLES11.4 / squid3-3.1.23-8.16.33.2
=========================================================================================================
auth_param basic program /usr/sbin/squid_ldap_auth -d -D "cn=xxx,o=xxxx"
-w xx -b o=x -s sub -f "(&(objectclass=User)(cn=%s))" -h ldaps://xxxx -p
636

external_acl_type ldap_group %LOGIN /usr/sbin/squid_ldap_group -d -D
"cn=xx,o=x" -w ldap -b o=x -s sub -f
"(&(objectclass=User)(cn=%u)(groupMembership=%g))" -h ldaps://x -p 636
=========================================================================================================

but now i would like to do it with

CentOS Linux release 7.2.1511 / squid-3.3.8-26.el7_2.4.x86_64

and it turned out the I have no more "squid_ldap_auth" but i found
"basic_ldap_auth".
So it tried switching "squid_ldap_auth" to "basic_ldap_auth" but that
did not work....

I get the login window, but even if i enter a vaild user, i can not
access a website.

squid.conf looks like this:

=========================================================================================================
auth_param basic program /usr/lib64/squid/basic_ldap_auth -d -D
"cn=xxx,o=xxx" -w xxx -b o=xxx -s sub -f "(&(objectclass=User)(cn=%s))"
-h ldaps://xxxx -p 636

auth_param basic children 5
auth_param basic credentialsttl 2 hours
acl ediruser proxy_auth REQUIRE
http_access allow ediruser
http_access deny all

=========================================================================================================


>>> Eliezer Croitoru <eliezer at ngtech.co.il> 12.12.16 15.28 Uhr >>>
Hey,

digest_edirectory_auth is not for LDAP but for edirectory but I a not
too familiar with this to tell you how to test.
Basically you need a "basic" ldap authentication helper Which the source
is:
http://bazaar.launchpad.net/~squid/squid/3.5/files/head:/helpers/basic_auth/LDAP/
And we are also missing the squid.conf.
Try find out if there some helper in the /usr/lib64/squid/ directory
which contains ldap.

Let me know if we are on the right direction.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of bjoern wahl
Sent: Monday, December 12, 2016 3:53 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid-3.3.8-26.el7_2.4.x86_64 using Novell
eDirectory with /usr/lib64/squid/digest_edirectory_auth

Hello!

I would like to install a squid-3.3.8-26.el7_2.4.x86_64 (CentOS7) using
LDAP auth with digest_edirectory_auth, but i can not get it working.

Does anybody user this ?

I tried:


/usr/lib64/squid/digest_edirectory_auth -A password -l : -e -v 3 -D
"cn=xxxx,o=xxxxx" -b "o=xxxxx" -w xxxx -b o=xxxx -s sub -F
"(&(objectclass=User)(cn=%s))" -Z -h ldaps://xxxxxx -n

but i only get:


user1 pw1
ERR
user2 pw2
ERR
user3 pw3
ERR

Any ideas ?


Thanks, Bj?rn !

Tr?ger: Klinikum Westm?nsterland GmbHGesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken Registergericht
Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (SprechDiese E-Mail
enth?lt vertrauliche oder rechtlich gesch?tzte Informationen. Wenn Sie
nicht der beabsichtigte Empf?nger sind, informieren Sie bitte sofort den
Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.






Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.






From rafael.akchurin at diladele.com  Wed Dec 14 15:08:24 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 14 Dec 2016 15:08:24 +0000
Subject: [squid-users] Cisco ASA with transparent Squid with HTTP/HTTPS
	filtering
Message-ID: <DB6PR0401MB268040C64F44D6D67280ECF48F9A0@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello everyone,

After pulling all my hair out and reading every possible howto on the Internet for Cisco ASA integration with Squid using WCCP I have decided to write my own. The how to is at https://docs.diladele.com/tutorials/web_filter_https_squid_cisco_wccp/index.html. Please note it is aimed at those with minimal admin skills and contains every single step thoroughly described (mostly for myself not to forget anything).

May I get your opinions/ideas if what is written is good enough for the novice admin?

Moreover several question remain:


1.      Does Squid perform fake CONNECT requests with SNI info instead of raw IP like I am seeing now?

2.      Why HTTPS redirection only works with "wccp2_service_info 70 protocol=tcp flags=dst_ip_hash priority=240 ports=443" (all other flags from wccp configuration section in squid.conf do not work).

3.      How to bypass connections from workstations to specific remote sites by FQDN on Cisco ASA?

4.      Or maybe it is better to exclude them (3) from SSL bump on Squid using ssl::server_name by splicing?

Thanks in advance for everyone who responds.

Best regards,
Rafael Akchurin
Diladele B.V.


--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at https://www.diladele.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/08247ebb/attachment.htm>

From sameh.onaissi at solcv.com  Wed Dec 14 15:16:17 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 14 Dec 2016 15:16:17 +0000
Subject: [squid-users] unknown source IP in access.log
Message-ID: <C5EE8EBF-9BE1-4B91-BD76-B32FA7DD27BB@solcv.com>

Hello,


I have a functional transparent squid with ssl-bump on Ubuntu 16.04

With Eliezer?s great help, I added a bypass pool to bypass Skype for Business IPs and allow the Skype for Business client to log in successfully. I notices that personal Skype is not logging in however, so I wanted to add its IPs to the pool.

Currently, the squid server has only 1 client (my laptop). I closed all my browsers, in an effort to isolate only Skype log in attempts. Mail client is also closed.

Looking at access.log, to find the Skype IPs, I noticed a LOT of unknown source IPs. All those IPs seem to be originated from China.
In my config file I deny all but local net IPs 10.0.0.0/24.

Here is a sample of the log:

1481728035.855      0 199.233.237.186 TAG_NONE/400 4534 NONE error:invalid-request - HIER_NONE/- text/html
1481728035.952   1556 118.89.21.244 TCP_MISS/200 445 POST http://online.huya.com/ - HIER_DIRECT/183.61.6.181 application/multipart-formdata
1481728036.461    595 123.207.123.80 TCP_MISS/200 419 POST http://online.huya.com/ - HIER_DIRECT/183.61.6.181 application/multipart-formdata
1481728036.993    749 123.207.123.80 TCP_MISS/200 819 POST http://wup.huya.com/ - HIER_DIRECT/180.208.65.100 application/multipart-formdata
1481728037.538   2307 122.227.189.214 TCP_MISS/200 764 POST http://webim.ganji.com/message/ImSendMsg? - HIER_DIRECT/124.251.6.233 text/html
1481728038.572   9372 74.222.20.124 TCP_MISS/502 3922 GET http://116.31.99.233:9636/ - HIER_DIRECT/116.31.99.233 text/html
1481728038.573      0 74.222.20.124 TAG_NONE/400 4532 NONE error:invalid-request - HIER_NONE/- text/html
1481728038.773   2528 118.89.21.244 TCP_MISS/200 419 POST http://online.huya.com/ - HIER_DIRECT/183.61.6.181 application/multipart-formdata
1481728039.162   1575 139.199.60.36 TCP_MISS/200 419 POST http://online.huya.com/ - HIER_DIRECT/183.61.6.181 application/multipart-formdata
1481728039.203    612 122.227.189.214 TCP_MISS/200 1182 POST http://mobapi.ganji.com/datashare/ - HIER_DIRECT/115.159.231.182 text/html
1481728039.615  51681 172.82.184.19 TCP_MISS/502 3806 GET http://115.231.17.12:9636/ - HIER_DIRECT/115.231.17.12 text/html
1481728039.615      0 172.82.184.19 TAG_NONE/400 4532 NONE error:invalid-request - HIER_NONE/- text/html
1481728040.311  36606 74.222.20.124 TCP_MISS/502 3806 GET http://116.31.99.233:9636/ - HIER_DIRECT/116.31.99.233 text/html
1481728040.312      0 74.222.20.124 TAG_NONE/400 4532 NONE error:invalid-request - HIER_NONE/- text/html
1481728041.477  67001 74.222.19.19 TCP_MISS/502 3802 GET http://61.155.5.197:9636/ - HIER_DIRECT/61.155.5.197 text/html
1481728041.478      0 74.222.19.19 TAG_NONE/400 4531 NONE error:invalid-request - HIER_NONE/- text/html
1481728041.856  13613 172.82.190.245 TCP_MISS/502 3926 GET http://122.226.191.17:9636/ - HIER_DIRECT/122.226.191.17 text/html
1481728041.857      0 172.82.190.245 TAG_NONE/400 4533 NONE error:invalid-request - HIER_NONE/- text/html

I am worried about spam? is this normal? if not, how can I know what is accessing squid and stop it.

NOTE: this server has a small iRedMail server installed on it.



Sam


[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/7f73c778/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/7f73c778/attachment.jpg>

From Antony.Stone at squid.open.source.it  Wed Dec 14 15:25:32 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 14 Dec 2016 16:25:32 +0100
Subject: [squid-users] unknown source IP in access.log
In-Reply-To: <C5EE8EBF-9BE1-4B91-BD76-B32FA7DD27BB@solcv.com>
References: <C5EE8EBF-9BE1-4B91-BD76-B32FA7DD27BB@solcv.com>
Message-ID: <201612141625.32701.Antony.Stone@squid.open.source.it>

On Wednesday 14 December 2016 at 16:16:17, Sameh Onaissi wrote:

> Looking at access.log, to find the Skype IPs, I noticed a LOT of unknown
> source IPs. All those IPs seem to be originated from China. In my config
> file I deny all but local net IPs 10.0.0.0/24.

I suggest you show us your squid.conf (wiithout comments or blank lines) 
because you do not seem to have achieved restricting source IPs as intended.

> Here is a sample of the log:
> 
> 1481728035.855      0 199.233.237.186 TAG_NONE/400 4534 NONE
> error:invalid-request - HIER_NONE/- text/html 1481728035.952   1556
>
> 118.89.21.244 TCP_MISS/200 445 POST http://online.huya.com/ -
> HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728036.461   
> 595
>
> 123.207.123.80 TCP_MISS/200 419 POST http://online.huya.com/ -
> HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728036.993   
> 749
>
> 123.207.123.80 TCP_MISS/200 819 POST http://wup.huya.com/ -
> HIER_DIRECT/180.208.65.100 application/multipart-formdata 1481728037.538  
> 2307
>
> 122.227.189.214 TCP_MISS/200 764 POST
> http://webim.ganji.com/message/ImSendMsg? - HIER_DIRECT/124.251.6.233
> text/html 1481728038.572   9372
>
> 74.222.20.124 TCP_MISS/502 3922 GET http://116.31.99.233:9636/ -
> HIER_DIRECT/116.31.99.233 text/html 1481728038.573      0
>
> 74.222.20.124 TAG_NONE/400 4532 NONE error:invalid-request - HIER_NONE/-
> text/html 1481728038.773   2528
>
> 118.89.21.244 TCP_MISS/200 419 POST http://online.huya.com/ -
> HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728039.162  
> 1575
>
> 139.199.60.36 TCP_MISS/200 419 POST http://online.huya.com/ -
> HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728039.203   
> 612
>
> 122.227.189.214 TCP_MISS/200 1182 POST http://mobapi.ganji.com/datashare/ -
> HIER_DIRECT/115.159.231.182 text/html 1481728039.615  51681
>
> 172.82.184.19 TCP_MISS/502 3806 GET http://115.231.17.12:9636/ -
> HIER_DIRECT/115.231.17.12 text/html 1481728039.615      0
>
> 172.82.184.19 TAG_NONE/400 4532 NONE
> error:invalid-request - HIER_NONE/- text/html 1481728040.311  36606
>
> 74.222.20.124 TCP_MISS/502 3806 GET http://116.31.99.233:9636/ -
> HIER_DIRECT/116.31.99.233 text/html 1481728040.312      0
>
> 74.222.20.124 TAG_NONE/400 4532 NONE error:invalid-request - HIER_NONE/-
> text/html 1481728041.477  67001
>
> 74.222.19.19 TCP_MISS/502 3802 GET http://61.155.5.197:9636/ -
> HIER_DIRECT/61.155.5.197 text/html 1481728041.478      0
>
> 74.222.19.19 TAG_NONE/400 4531 NONE error:invalid-request - HIER_NONE/-
> text/html 1481728041.856  13613
>
> 172.82.190.245 TCP_MISS/502 3926 GET http://122.226.191.17:9636/ -
> HIER_DIRECT/122.226.191.17 text/html 1481728041.857      0
>
> 172.82.190.245 TAG_NONE/400 4533 NONE error:invalid-request - HIER_NONE/-
> text/html
> 
> I am worried about spam?

I would not call this spam - I would call it "people trying to abuse your 
proxy".

> is this normal?

It is normal that they try.  It is not normal that your access control rules 
allow them to get this far.

> if not, how can I know what is accessing squid and stop it.

You don't care what is accessing it - you only care that it's coming from the 
outside, and that should not be allowed.  Either or both of your Squid ACLs 
and your firewall rules need to be reviewed.

> NOTE: this server has a small iRedMail server installed on it.

What port/s does that listen on?  It is intended to be externally accessible?


Regards,


Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From andre.bolinhas at articatech.com  Wed Dec 14 15:46:01 2016
From: andre.bolinhas at articatech.com (=?iso-8859-1?Q?Andr=E9_Bolinhas?=)
Date: Wed, 14 Dec 2016 15:46:01 -0000
Subject: [squid-users] Setup wccp2 with squid3 and cisco switch 4507
Message-ID: <007201d25621$2bcfe4c0$836fae40$@articatech.com>

Hi,

I need to setup wccp2 between my Squid3 box and my cisco switch 4507

Since my 4507 don't support GRE on forward methoding I need to configure the
the wccp with L2.

 

My squid.conf

http_port 3129 intercept

wccp2_router $IP-OF-ROUTER

wccp2_forwarding_method l2

wccp2_return_method l2

 

My question is, in GRE method I need to create a GRE tunnel like this

modprobe ip_gre

ip tunnel add wccp0 mode gre remote $ASA-EXT-IP local $SQUID-IP dev eth0

 

ifconfig wccp0 $SQUID-IP netmask 255.255.255.255 up

echo 0 >/proc/sys/net/ipv4/conf/wccp0/rp_filter

echo 0 >/proc/sys/net/ipv4/conf/eth0/rp_filter

echo 1 >/proc/sys/net/ipv4/ip_forward

iptables -t nat -A PREROUTING -i wccp0 -p tcp --dport 80 -j REDIRECT
--to-port 3129

iptables -t nat -A POSTROUTING -j MASQUERADE

 

In L2 method the configuration is the same (tunnel, sysctl, iptables..) ? if
not can you help me to configure it (tunnel, sysctl, iptables..).

 

Also in switch what's ACL I need to create? 

 

Best regard

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/08f950eb/attachment.htm>

From yvoinov at gmail.com  Wed Dec 14 15:59:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Dec 2016 21:59:56 +0600
Subject: [squid-users] Cisco ASA with transparent Squid with HTTP/HTTPS
 filtering
In-Reply-To: <DB6PR0401MB268040C64F44D6D67280ECF48F9A0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <DB6PR0401MB268040C64F44D6D67280ECF48F9A0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <9ea0b311-c2c6-e894-1555-7ff501b1f335@gmail.com>



14.12.2016 21:08, Rafael Akchurin ?????:
>
> Hello everyone,
>
>  
>
> After pulling all my hair out and reading every possible howto on the
> Internet for Cisco ASA integration with Squid using WCCP I have
> decided to write my own. The how to is at
> https://docs.diladele.com/tutorials/web_filter_https_squid_cisco_wccp/index.html.
> Please note it is aimed at those with minimal admin skills and
> contains every single step thoroughly described (mostly for myself not
> to forget anything).
>
>  
>
> May I get your opinions/ideas if what is written is good enough for
> the novice admin?
>
>  
>
> Moreover several question remain:
>
>  
>
> 1.      Does Squid perform fake CONNECT requests with SNI info instead
> of raw IP like I am seeing now?
>
> 2.      Why HTTPS redirection only works with ?wccp2_service_info 70
> protocol=tcp flags=*dst_ip_hash* priority=240 ports=443? (all other
> flags from wccp configuration section in squid.conf do not work).
>
Because of ASA is router. Cisco routers uses HASH as assignment method.
>
> 3.      How to bypass connections from workstations to specific remote
> sites by FQDN on Cisco ASA?
>
In fact this will occurs by IP anyway. Cisco devices do DNS lookup and
saves IP's in config instead of FQDN.
>
> 4.      Or maybe it is better to exclude them (3) from SSL bump on
> Squid using ssl::server_name by splicing?
>
Depending your requirements.
>
>  
>
> Thanks in advance for everyone who responds.
>
>  
>
> Best regards,
>
> Rafael Akchurin
>
> Diladele B.V.
>
>  
>
> --
>
> Please take a look at Web Safety - our ICAP based web filter server
> for Squid proxy at https://www.diladele.com
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/e2fc3135/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/e2fc3135/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/e2fc3135/attachment.sig>

From yvoinov at gmail.com  Wed Dec 14 16:01:39 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Dec 2016 22:01:39 +0600
Subject: [squid-users] Setup wccp2 with squid3 and cisco switch 4507
In-Reply-To: <007201d25621$2bcfe4c0$836fae40$@articatech.com>
References: <007201d25621$2bcfe4c0$836fae40$@articatech.com>
Message-ID: <f4c69ab1-6539-69df-0bf7-604e2ee543f1@gmail.com>

May be, this could help you:

http://wiki.squid-cache.org/ConfigExamples/Intercept/CiscoIOSv15Wccp2


14.12.2016 21:46, Andr? Bolinhas ?????:
>
> Hi,
>
> I need to setup wccp2 between my Squid3 box and my cisco switch 4507
>
> Since my 4507 don't support GRE on forward methoding I need to
> configure the the wccp with L2.
>
>  
>
> My squid.conf
>
> http_port 3129 intercept
>
> wccp2_router $IP-OF-ROUTER
>
> wccp2_forwarding_method l2
>
> wccp2_return_method l2
>
>  
>
> My question is, in GRE method I need to create a GRE tunnel like this
>
> modprobe ip_gre
>
> ip tunnel add wccp0 mode gre remote $ASA-EXT-IP local $SQUID-IP dev eth0
>
>  
>
> ifconfig wccp0 $SQUID-IP netmask 255.255.255.255 up
>
> echo 0 >/proc/sys/net/ipv4/conf/wccp0/rp_filter
>
> echo 0 >/proc/sys/net/ipv4/conf/eth0/rp_filter
>
> echo 1 >/proc/sys/net/ipv4/ip_forward
>
> iptables -t nat -A PREROUTING -i wccp0 -p tcp --dport 80 -j REDIRECT
> --to-port 3129
>
> iptables -t nat -A POSTROUTING -j MASQUERADE
>
>  
>
> In L2 method the configuration is the same (tunnel, sysctl,
> iptables..) ? if not can you help me to configure it (tunnel, sysctl,
> iptables..).
>
>  
>
> Also in switch what's ACL I need to create?
>
>  
>
> Best regard
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/b244966e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/b244966e/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/b244966e/attachment.sig>

From yvoinov at gmail.com  Wed Dec 14 16:03:44 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Dec 2016 22:03:44 +0600
Subject: [squid-users] Cisco ASA with transparent Squid with HTTP/HTTPS
 filtering
In-Reply-To: <9ea0b311-c2c6-e894-1555-7ff501b1f335@gmail.com>
References: <DB6PR0401MB268040C64F44D6D67280ECF48F9A0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <9ea0b311-c2c6-e894-1555-7ff501b1f335@gmail.com>
Message-ID: <a28c42ce-ed35-5758-4f7a-3e2349162566@gmail.com>



14.12.2016 21:59, Yuri Voinov ?????:
>
>
>
> 14.12.2016 21:08, Rafael Akchurin ?????:
>>
>> Hello everyone,
>>
>>  
>>
>> After pulling all my hair out and reading every possible howto on the
>> Internet for Cisco ASA integration with Squid using WCCP I have
>> decided to write my own. The how to is at
>> https://docs.diladele.com/tutorials/web_filter_https_squid_cisco_wccp/index.html.
>> Please note it is aimed at those with minimal admin skills and
>> contains every single step thoroughly described (mostly for myself
>> not to forget anything).
>>
>>  
>>
>> May I get your opinions/ideas if what is written is good enough for
>> the novice admin?
>>
>>  
>>
>> Moreover several question remain:
>>
>>  
>>
>> 1.      Does Squid perform fake CONNECT requests with SNI info
>> instead of raw IP like I am seeing now?
>>
>> 2.      Why HTTPS redirection only works with ?wccp2_service_info 70
>> protocol=tcp flags=*dst_ip_hash* priority=240 ports=443? (all other
>> flags from wccp configuration section in squid.conf do not work).
>>
> Because of ASA is router. Cisco routers uses HASH as assignment method.
http://wiki.squid-cache.org/ConfigExamples/Intercept/CiscoIOSv15Wccp2

Here is described differences in configs for switches/routers.
>>
>> 3.      How to bypass connections from workstations to specific
>> remote sites by FQDN on Cisco ASA?
>>
> In fact this will occurs by IP anyway. Cisco devices do DNS lookup and
> saves IP's in config instead of FQDN.
>>
>> 4.      Or maybe it is better to exclude them (3) from SSL bump on
>> Squid using ssl::server_name by splicing?
>>
> Depending your requirements.
>>
>>  
>>
>> Thanks in advance for everyone who responds.
>>
>>  
>>
>> Best regards,
>>
>> Rafael Akchurin
>>
>> Diladele B.V.
>>
>>  
>>
>> --
>>
>> Please take a look at Web Safety - our ICAP based web filter server
>> for Squid proxy at https://www.diladele.com
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> Cats - delicious. You just do not know how to cook them.

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/5f7ba2b8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/5f7ba2b8/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/5f7ba2b8/attachment.sig>

From yvoinov at gmail.com  Wed Dec 14 16:10:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Dec 2016 22:10:43 +0600
Subject: [squid-users] Cisco ASA with transparent Squid with HTTP/HTTPS
 filtering
In-Reply-To: <9ea0b311-c2c6-e894-1555-7ff501b1f335@gmail.com>
References: <DB6PR0401MB268040C64F44D6D67280ECF48F9A0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <9ea0b311-c2c6-e894-1555-7ff501b1f335@gmail.com>
Message-ID: <7f845b74-7dc9-db78-854c-6bb060a4c887@gmail.com>



14.12.2016 21:59, Yuri Voinov ?????:
>
>
>
> 14.12.2016 21:08, Rafael Akchurin ?????:
>>
>> Hello everyone,
>>
>>  
>>
>> After pulling all my hair out and reading every possible howto on the
>> Internet for Cisco ASA integration with Squid using WCCP I have
>> decided to write my own. The how to is at
>> https://docs.diladele.com/tutorials/web_filter_https_squid_cisco_wccp/index.html.
>> Please note it is aimed at those with minimal admin skills and
>> contains every single step thoroughly described (mostly for myself
>> not to forget anything).
>>
Raf, one more note. WCCP is never be easy for junior admins. Especially
with minimal admin skills. As by ASA ;) And (by my own opinion) Squid +
WCCP for any infrastructure never been simple task and will never be
simple task. ;) Warn you readers, not mislead them, though it is a very
simple task.
>>
>>  
>>
>> May I get your opinions/ideas if what is written is good enough for
>> the novice admin?
>>
>>  
>>
>> Moreover several question remain:
>>
>>  
>>
>> 1.      Does Squid perform fake CONNECT requests with SNI info
>> instead of raw IP like I am seeing now?
>>
>> 2.      Why HTTPS redirection only works with ?wccp2_service_info 70
>> protocol=tcp flags=*dst_ip_hash* priority=240 ports=443? (all other
>> flags from wccp configuration section in squid.conf do not work).
>>
> Because of ASA is router. Cisco routers uses HASH as assignment method.
>>
>> 3.      How to bypass connections from workstations to specific
>> remote sites by FQDN on Cisco ASA?
>>
> In fact this will occurs by IP anyway. Cisco devices do DNS lookup and
> saves IP's in config instead of FQDN.
>>
>> 4.      Or maybe it is better to exclude them (3) from SSL bump on
>> Squid using ssl::server_name by splicing?
>>
> Depending your requirements.
>>
>>  
>>
>> Thanks in advance for everyone who responds.
>>
>>  
>>
>> Best regards,
>>
>> Rafael Akchurin
>>
>> Diladele B.V.
>>
>>  
>>
>> --
>>
>> Please take a look at Web Safety - our ICAP based web filter server
>> for Squid proxy at https://www.diladele.com
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> Cats - delicious. You just do not know how to cook them.

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/5f8add4c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/5f8add4c/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/5f8add4c/attachment.sig>

From sameh.onaissi at solcv.com  Wed Dec 14 16:26:34 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 14 Dec 2016 16:26:34 +0000
Subject: [squid-users] unknown source IP in access.log
In-Reply-To: <201612141625.32701.Antony.Stone@squid.open.source.it>
References: <C5EE8EBF-9BE1-4B91-BD76-B32FA7DD27BB@solcv.com>
 <201612141625.32701.Antony.Stone@squid.open.source.it>
Message-ID: <92FCB4D3-86C5-46EF-8384-96949387D54E@solcv.com>

Thanks for your reply.

Here?s the config file:

http://pastebin.com/DNDacy6M


Dovecot used its default ports:
110: pop
143: imap
995: pop3s
993: maps

Postfix SMTP 587

Kind regards,
Sam



[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 14, 2016, at 10:25 AM, Antony Stone <Antony.Stone at squid.open.source.it<mailto:Antony.Stone at squid.open.source.it>> wrote:

On Wednesday 14 December 2016 at 16:16:17, Sameh Onaissi wrote:

Looking at access.log, to find the Skype IPs, I noticed a LOT of unknown
source IPs. All those IPs seem to be originated from China. In my config
file I deny all but local net IPs 10.0.0.0/24.

I suggest you show us your squid.conf (wiithout comments or blank lines)
because you do not seem to have achieved restricting source IPs as intended.

Here is a sample of the log:

1481728035.855      0 199.233.237.186 TAG_NONE/400 4534 NONE
error:invalid-request - HIER_NONE/- text/html 1481728035.952   1556

118.89.21.244 TCP_MISS/200 445 POST http://online.huya.com/ -
HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728036.461
595

123.207.123.80 TCP_MISS/200 419 POST http://online.huya.com/ -
HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728036.993
749

123.207.123.80 TCP_MISS/200 819 POST http://wup.huya.com/ -
HIER_DIRECT/180.208.65.100 application/multipart-formdata 1481728037.538
2307

122.227.189.214 TCP_MISS/200 764 POST
http://webim.ganji.com/message/ImSendMsg? - HIER_DIRECT/124.251.6.233
text/html 1481728038.572   9372

74.222.20.124 TCP_MISS/502 3922 GET http://116.31.99.233:9636/ -
HIER_DIRECT/116.31.99.233 text/html 1481728038.573      0

74.222.20.124 TAG_NONE/400 4532 NONE error:invalid-request - HIER_NONE/-
text/html 1481728038.773   2528

118.89.21.244 TCP_MISS/200 419 POST http://online.huya.com/ -
HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728039.162
1575

139.199.60.36 TCP_MISS/200 419 POST http://online.huya.com/ -
HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728039.203
612

122.227.189.214 TCP_MISS/200 1182 POST http://mobapi.ganji.com/datashare/ -
HIER_DIRECT/115.159.231.182 text/html 1481728039.615  51681

172.82.184.19 TCP_MISS/502 3806 GET http://115.231.17.12:9636/ -
HIER_DIRECT/115.231.17.12 text/html 1481728039.615      0

172.82.184.19 TAG_NONE/400 4532 NONE
error:invalid-request - HIER_NONE/- text/html 1481728040.311  36606

74.222.20.124 TCP_MISS/502 3806 GET http://116.31.99.233:9636/ -
HIER_DIRECT/116.31.99.233 text/html 1481728040.312      0

74.222.20.124 TAG_NONE/400 4532 NONE error:invalid-request - HIER_NONE/-
text/html 1481728041.477  67001

74.222.19.19 TCP_MISS/502 3802 GET http://61.155.5.197:9636/ -
HIER_DIRECT/61.155.5.197 text/html 1481728041.478      0

74.222.19.19 TAG_NONE/400 4531 NONE error:invalid-request - HIER_NONE/-
text/html 1481728041.856  13613

172.82.190.245 TCP_MISS/502 3926 GET http://122.226.191.17:9636/ -
HIER_DIRECT/122.226.191.17 text/html 1481728041.857      0

172.82.190.245 TAG_NONE/400 4533 NONE error:invalid-request - HIER_NONE/-
text/html

I am worried about spam?

I would not call this spam - I would call it "people trying to abuse your
proxy".

is this normal?

It is normal that they try.  It is not normal that your access control rules
allow them to get this far.

if not, how can I know what is accessing squid and stop it.

You don't care what is accessing it - you only care that it's coming from the
outside, and that should not be allowed.  Either or both of your Squid ACLs
and your firewall rules need to be reviewed.

NOTE: this server has a small iRedMail server installed on it.

What port/s does that listen on?  It is intended to be externally accessible?


Regards,


Antony.

--
Wanted: telepath.   You know where to apply.

                                                  Please reply to the list;
                                                        please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/5d59d3d1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/5d59d3d1/attachment.jpg>

From noc at forceline.net  Wed Dec 14 17:24:15 2016
From: noc at forceline.net (noc at forceline.net)
Date: Wed, 14 Dec 2016 20:24:15 +0300
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
	Kill	process (squid)
In-Reply-To: <0a9501d25612$ad0483c0$070d8b40$@ngtech.co.il>
References: <039901d255fe$d80cfe30$8826fa90$@net>
 <0a9501d25612$ad0483c0$070d8b40$@ngtech.co.il>
Message-ID: <04d501d2562e$e56d5e00$b0481a00$@net>

Eliezer, thanks for your reply. Guides:
http://wiki.squid-cache.org/Features/SslBump
http://wiki.squid-cache.org/Features/SslPeekAndSplice
https://habrahabr.ru/post/267851/  <-- Russian lang
https://habrahabr.ru/post/272733/  <-- Russian lang

>First goes first change this: 13130:
Done, nothing changed. Squid died.

Maby it will be work fine whith lower load even with https. But I don't
understand, why it killed by a kernel rather than just update memory by new
one.

http://wiki.squid-cache.org/Features/SslBump
>Memory usage
>
>    /!\ Warning: Unlike the rest of this page at the time of writing, this
section applies to Squid-3.3 and possibly later code capable of dynamic SSL
certificate generation and origin server certificate mimicking. The current
section text is intended primarily for developers and early adopters facing
excessive memory consumption in certain SslBump environments. These notes
may be relocated elsewhere if a better location is found. 
>
>Current documentation is specific to bump-server-first configurations.

In attach server statistic.

--
Sergey

> -----Original Message-----
> From: Eliezer Croitoru [mailto:eliezer at ngtech.co.il]
> Sent: Wednesday, December 14, 2016 5:02 PM
> To: noc at forceline.net; squid-users at lists.squid-cache.org
> Subject: RE: [squid-users] Crash: every 1-2 hour: kernel: Out of
> memory: Kill process (squid)
> 
> First goes first change this:
> https_port 192.168.253.10:3130 intercept ssl-bump
> options=ALL:NO_SSLv3:NO_SSLv2 connection-auth=off
> cert=/etc/squid/squidCA.pem
> 
> into:
> http_port 192.168.253.10:13130 intercept ssl-bump
> options=ALL:NO_SSLv3:NO_SSLv2 connection-auth=off
> cert=/etc/squid/squidCA.pem
> 
> and iptables accordingly.
> Are you working based on some tutorial?
> If so please attach the link to it.
> Notice that port 3130 is officially a port which should not be used for
> interception but for other purposes.
> 
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of noc at forceline.net
> Sent: Wednesday, December 14, 2016 1:40 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
> Kill
> process (squid)
> 
> 
> Hello. I wrote earlier in wrong location:
> http://bugs.squid-cache.org/show_bug.cgi?id=4647
> 
> > Squid eats all RAM, then eats all swap in a hour and killed by
> kernel.
> >I was try to turn off cache, change squid version, change some
> configuration parameters by this guide
> http://wiki.squid-cache.org/SquidFaq/SquidMemory except malloc, but
> nothing
> helps.
> 
> I made some config changes in accordance with the advice of Amos
> Jeffries
> (via on). But it does not help.
> This trouble somehow linked with https.
> If wccp redirects only 80 port - works fine.
>   wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority =
> 231
> ports = 80 If wccp redirects 443 too - then squid overflows and killed
> by
> kernel
>   wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority =
> 231
> ports = 80,443
> 
> ---Before it died (HTTPS on):
> Mem:  16291720k total, 16125288k used,   166432k free,      540k
> buffers
> Swap:  8216568k total,  8112628k used,   103940k free,    27112k cached
>   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
> 30858 squid     20   0 22.7g  14g 3612 S  8.0 94.6  14:50.82 squid
> 
> 
> # free -m
>              total       used       free     shared    buffers
> cached
> Mem:         15909      15750        158          0          0
> 26
> -/+ buffers/cache:      15723        186
> Swap:         8023       7936         87
> 
> 
> Start Time:	Sat, 10 Dec 2016 07:52:50 GMT
> Current Time:	Sat, 10 Dec 2016 09:39:45 GMT
> 
> Connection information for squid:
> 	Number of clients accessing cache:	1305
> 	Number of HTTP requests received:	193434
> 	Number of ICP messages received:	0
> 	Number of ICP messages sent:	0
> 	Number of queued ICP replies:	0
> 	Number of HTCP messages received:	0
> 	Number of HTCP messages sent:	0
> 	Request failure ratio:	 0.00
> 	Average HTTP requests per minute since start:	1809.2
> 	Average ICP messages per minute since start:	0.0
> 	Select loop called: 4529796 times, 1.416 ms avg Cache information
> for squid:
> 	Hits as % of all requests:	5min: 0.0%, 60min: 0.0%
> 	Hits as % of bytes sent:	5min: 0.1%, 60min: -0.0%
> 	Memory hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
> 	Disk hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
> 	Storage Swap size:	82044 KB
> 	Storage Swap capacity:	80.1% used, 19.9% free
> 	Storage Mem size:	107876 KB
> 	Storage Mem capacity:	20.6% used, 79.4% free
> 	Mean Object Size:	29.54 KB
> 	Requests given to unlinkd:	9258
> Median Service Times (seconds)  5 min    60 min:
> 	HTTP Requests (All):   0.10857  0.04519
> 	Cache Misses:          0.01648  0.00678
> 	Cache Hits:            0.00000  0.00000
> 	Near Hits:             0.00000  0.00000
> 	Not-Modified Replies:  0.00000  0.00000
> 	DNS Lookups:           0.00860  0.00779
> 	ICP Queries:           0.00000  0.00000
> Resource usage for squid:
> 	UP Time:	6415.101 seconds
> 	CPU Time:	902.767 seconds
> 	CPU Usage:	14.07%
> 	CPU Usage, 5 minute avg:	15.97%
> 	CPU Usage, 60 minute avg:	13.96%
> 	Maximum Resident Size: 62241760 KB
> 	Page faults with physical i/o: 32647
> Memory accounted for:
> 	Total accounted:       1073388 KB
> 	memPoolAlloc calls:     12969
> 	memPoolFree calls:   35802441
> File descriptor usage for squid:
> 	Maximum number of file descriptors:   100000
> 	Largest file desc currently in use:   28744
> 	Number of file desc currently in use: 28738
> 	Files queued for open:                   0
> 	Available number of file descriptors: 71262
> 	Reserved number of file descriptors:   100
> 	Store Disk files open:                   0
> Internal Data Structures:
> 	 57337 StoreEntries
> 	 54560 StoreEntries with MemObjects
> 	    52 Hot Object Cache Items
> 	  2777 on-disk objects
> 
> ---after:
> /var/log/messages
> kernel: 11733 total pagecache pages
> kernel: 8957 pages in swap cache
> kernel: Swap cache stats: add 21118384, delete 21109427, find
> 12110273/12422740
> kernel: Free swap  = 0kB
> kernel: Total swap = 8216568kB
> kernel: 4194303 pages RAM
> kernel: 121373 pages reserved
> kernel: 11781 pages shared
> kernel: 4023631 pages non-shared
> ...omitted...
> kernel: Out of memory: Kill process 30858 (squid) score 954 or
> sacrifice
> child
> kernel: Killed process 30868, UID 23, (log_file_daemon) total-
> vm:26640kB,
> anon-rss:48kB, file-rss:512kB
> (squid-1): I don't handle this error well!
> Dec 10 12:44:27 localhost squid[30855]: Squid Parent: (squid-1) process
> 30858 exited due to signal 9 with status 0
> 
> 
> In attach all /var/log/messages output.
> Main task for the server is to block bad sites and bypass others on
> same
> IPs.
> Any ideas?
> 
> --
> Sergey
-------------- next part --------------
A non-text attachment was scrubbed...
Name: load.png
Type: image/png
Size: 59431 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/385060ce/attachment.png>

From Antony.Stone at squid.open.source.it  Wed Dec 14 19:11:46 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 14 Dec 2016 20:11:46 +0100
Subject: [squid-users] unknown source IP in access.log
In-Reply-To: <92FCB4D3-86C5-46EF-8384-96949387D54E@solcv.com>
References: <C5EE8EBF-9BE1-4B91-BD76-B32FA7DD27BB@solcv.com>
 <201612141625.32701.Antony.Stone@squid.open.source.it>
 <92FCB4D3-86C5-46EF-8384-96949387D54E@solcv.com>
Message-ID: <201612142011.47200.Antony.Stone@squid.open.source.it>

On Wednesday 14 December 2016 at 17:26:34, Sameh Onaissi wrote:

> Thanks for your reply.
> 
> Here?s the config file: http://pastebin.com/DNDacy6M

Where is this file located on your system?  The answer to this question is 
needed further down my reply.

I've skipped some bits to make my reply clearer...

> acl localnet src 10.0.0.0/24 # RFC1918 possible internal network
>
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localnet
> http_access allow localhost
> http_access deny all
> http_access allow CONNECT localnet numeric_IPs Skype_UA

Maybe someone more knowledgeable can say if I'm wrong here, but I find it hard 
to accept that this really is the squid.conf file you're using:

a) if it allows connections from IPs such as 118.89.21.244

b) if it allows *anything* to CONNECT.


Please do one of the following:

1. Run "squid -k parse" and make sure it returns no errors, then introduce a 
deliberate error to your squid.conf file (such as mis-spelling "deny" or 
similar) and run "squid -k parse" again to make sure it reads the file you 
think it is using, and reports the error (then undo the mistake again).

2. Run "squid -f /path/to/your/squid.conf -k parse" substituting in the 
location on your system where your config file lives (as asked above).  Assuming 
this returns no errors, again (as in suggestion 1) instroduce a deliberate 
error, re-run "squid -f /path/to/you/squid.conf -k parse" and make sure it 
picks up on the error.

I find it hard to believe that the squid.conf you showed can produce the 
results you report.

Please also post the output of "find / -name squid.conf" on your machine.

> Dovecot used its default ports:
> 110: pop
> 143: imap
> 995: pop3s
> 993: maps
> 
> Postfix SMTP 587

Okay, so nothing to do with Squid, then.  I just wondered whether it might 
have a web interface.


Regards,


Antony.

> On Dec 14, 2016, at 10:25 AM, Antony Stone wrote:
> 
> On Wednesday 14 December 2016 at 16:16:17, Sameh Onaissi wrote:
> 
> Looking at access.log, to find the Skype IPs, I noticed a LOT of unknown
> source IPs. All those IPs seem to be originated from China. In my config
> file I deny all but local net IPs 10.0.0.0/24.
> 
> I suggest you show us your squid.conf (wiithout comments or blank lines)
> because you do not seem to have achieved restricting source IPs as
> intended.
> 
> Here is a sample of the log:
> 
> 118.89.21.244 TCP_MISS/200 445 POST http://online.huya.com/ -
> HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728036.461
> 595
> 
> 123.207.123.80 TCP_MISS/200 419 POST http://online.huya.com/ -
> HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728036.993
> 749
> 
> 74.222.20.124 TCP_MISS/502 3806 GET http://116.31.99.233:9636/ -
> HIER_DIRECT/116.31.99.233 text/html 1481728040.312      0
> 
> I am worried about spam?
> 
> I would not call this spam - I would call it "people trying to abuse your
> proxy".
> 
> is this normal?
> 
> It is normal that they try.  It is not normal that your access control
> rules allow them to get this far.
> 
> if not, how can I know what is accessing squid and stop it.
> 
> You don't care what is accessing it - you only care that it's coming from
> the outside, and that should not be allowed.  Either or both of your Squid
> ACLs and your firewall rules need to be reviewed.
> 
> NOTE: this server has a small iRedMail server installed on it.
> 
> What port/s does that listen on?  It is intended to be externally
> accessible?

-- 
"The tofu battle I saw last weekend was quite brutal."

 - Marija Danute Brigita Kuncaitis

                                                   Please reply to the list;
                                                         please *don't* CC me.


From sameh.onaissi at solcv.com  Wed Dec 14 19:58:18 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 14 Dec 2016 19:58:18 +0000
Subject: [squid-users] unknown source IP in access.log
In-Reply-To: <201612142011.47200.Antony.Stone@squid.open.source.it>
References: <C5EE8EBF-9BE1-4B91-BD76-B32FA7DD27BB@solcv.com>
 <201612141625.32701.Antony.Stone@squid.open.source.it>
 <92FCB4D3-86C5-46EF-8384-96949387D54E@solcv.com>
 <201612142011.47200.Antony.Stone@squid.open.source.it>
Message-ID: <7EC9D65B-924F-4D7F-954C-CF2CB83770A2@solcv.com>

Hey Antony, all?

The file is where is should be: /etc/squid/squid.conf


squid -k parse returns nothing strange.
To make sure, I followed your instructions of writing deny wrong (in /etc/squid/squid.conf) and ran "squid -k parse? again, and it complained:

2016/12/14 14:45:15| Processing: http_access denyl !Safe_ports
2016/12/14 14:45:15| aclParseAccessLine: /etc/squid/squid.conf line 35: http_access denyl !Safe_ports
2016/12/14 14:45:15| aclParseAccessLine: expecting 'allow' or 'deny', got 'denyl'.
2016/12/14 14:45:15| Processing: http_access deny CONNECT !SSL_ports


I also commented out the line allowing skype IPs and the access log continued showing said results.

I should mention that this behavior started today, when it was not happening before.

additionally:

find / -name squid.conf
/etc/fail2ban/filter.d/squid.conf
/etc/squid.bk/squid.conf
/etc/squid/squid.conf
find: ?/run/user/118/gvfs?: Permission denied


I am sure it is not the squid.bk/squid.conf because that has no acls defined nor configured to use squid guard to redirect pages (which currently is functioning)




Any other ideas?

Thank you again!
Sam


[cid:2FD1C3AB-E45C-49F0-84AB-0F8AC658BD11 at routerb408e2.com]Piensa en el medio ambiente antes de imprimir este email.

On Dec 14, 2016, at 2:11 PM, Antony Stone <Antony.Stone at squid.open.source.it<mailto:Antony.Stone at squid.open.source.it>> wrote:

On Wednesday 14 December 2016 at 17:26:34, Sameh Onaissi wrote:

Thanks for your reply.

Here?s the config file: http://pastebin.com/DNDacy6M
eaWhere is this file located on your system?  The answer to this question is
needed further down my reply.

I've skipped some bits to make my reply clearer...

acl localnet src 10.0.0.0/24 # RFC1918 possible internal network

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny all
http_access allow CONNECT localnet numeric_IPs Skype_UA

Maybe someone more knowledgeable can say if I'm wrong here, but I find it hard
to accept that this really is the squid.conf file you're using:

a) if it allows connections from IPs such as 118.89.21.244

b) if it allows *anything* to CONNECT.


Please do one of the following:

1. Run "squid -k parse" and make sure it returns no errors, then introduce a
deliberate error to your squid.conf file (such as mis-spelling "deny" or
similar) and run "squid -k parse" again to make sure it reads the file you
think it is using, and reports the error (then undo the mistake again).

2. Run "squid -f /path/to/your/squid.conf -k parse" substituting in the
location on your system where your config file lives (as asked above).  Assuming
this returns no errors, again (as in suggestion 1) instroduce a deliberate
error, re-run "squid -f /path/to/you/squid.conf -k parse" and make sure it
picks up on the error.

I find it hard to believe that the squid.conf you showed can produce the
results you report.

Please also post the output of "find / -name squid.conf" on your machine.

Dovecot used its default ports:
110: pop
143: imap
995: pop3s
993: maps

Postfix SMTP 587

Okay, so nothing to do with Squid, then.  I just wondered whether it might
have a web interface.


Regards,


Antony.

On Dec 14, 2016, at 10:25 AM, Antony Stone wrote:

On Wednesday 14 December 2016 at 16:16:17, Sameh Onaissi wrote:

Looking at access.log, to find the Skype IPs, I noticed a LOT of unknown
source IPs. All those IPs seem to be originated from China. In my config
file I deny all but local net IPs 10.0.0.0/24.

I suggest you show us your squid.conf (wiithout comments or blank lines)
because you do not seem to have achieved restricting source IPs as
intended.

Here is a sample of the log:

118.89.21.244 TCP_MISS/200 445 POST http://online.huya.com/ -
HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728036.461
595

123.207.123.80 TCP_MISS/200 419 POST http://online.huya.com/ -
HIER_DIRECT/183.61.6.181 application/multipart-formdata 1481728036.993
749

74.222.20.124 TCP_MISS/502 3806 GET http://116.31.99.233:9636/ -
HIER_DIRECT/116.31.99.233 text/html 1481728040.312      0

I am worried about spam?

I would not call this spam - I would call it "people trying to abuse your
proxy".

is this normal?

It is normal that they try.  It is not normal that your access control
rules allow them to get this far.

if not, how can I know what is accessing squid and stop it.

You don't care what is accessing it - you only care that it's coming from
the outside, and that should not be allowed.  Either or both of your Squid
ACLs and your firewall rules need to be reviewed.

NOTE: this server has a small iRedMail server installed on it.

What port/s does that listen on?  It is intended to be externally
accessible?

--
"The tofu battle I saw last weekend was quite brutal."

- Marija Danute Brigita Kuncaitis

                                                  Please reply to the list;
                                                        please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/f093aad5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Image 5-5-16 at 11.48 AM.jpg
Type: image/jpeg
Size: 4083 bytes
Desc: Image 5-5-16 at 11.48 AM.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/f093aad5/attachment.jpg>

From andre.bolinhas at articatech.com  Wed Dec 14 22:23:57 2016
From: andre.bolinhas at articatech.com (=?utf-8?Q?Andr=C3=A9_Bolinhas?=)
Date: Wed, 14 Dec 2016 22:23:57 -0000
Subject: [squid-users] Setup wccp2 with squid3 and cisco switch 4507
In-Reply-To: <f4c69ab1-6539-69df-0bf7-604e2ee543f1@gmail.com>
References: <007201d25621$2bcfe4c0$836fae40$@articatech.com>
 <f4c69ab1-6539-69df-0bf7-604e2ee543f1@gmail.com>
Message-ID: <017401d25658$c365b8a0$4a3129e0$@articatech.com>

Hi,

In this case, using L2 I don?t need to create a GRE tunnel?

Also need to use HTTP_PORT 3128 intercept ?

Wish iptables I need to create?

Best regards

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: quarta-feira, 14 de dezembro de 2016 16:02
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Setup wccp2 with squid3 and cisco switch 4507

 

May be, this could help you:

http://wiki.squid-cache.org/ConfigExamples/Intercept/CiscoIOSv15Wccp2

 

14.12.2016 21:46, Andr? Bolinhas ?????:

Hi,

I need to setup wccp2 between my Squid3 box and my cisco switch 4507

Since my 4507 don't support GRE on forward methoding I need to configure the the wccp with L2.

 

My squid.conf

http_port 3129 intercept

wccp2_router $IP-OF-ROUTER

wccp2_forwarding_method l2

wccp2_return_method l2

 

My question is, in GRE method I need to create a GRE tunnel like this

modprobe ip_gre

ip tunnel add wccp0 mode gre remote $ASA-EXT-IP local $SQUID-IP dev eth0

 

ifconfig wccp0 $SQUID-IP netmask 255.255.255.255 up

echo 0 >/proc/sys/net/ipv4/conf/wccp0/rp_filter

echo 0 >/proc/sys/net/ipv4/conf/eth0/rp_filter

echo 1 >/proc/sys/net/ipv4/ip_forward

iptables -t nat -A PREROUTING -i wccp0 -p tcp --dport 80 -j REDIRECT --to-port 3129

iptables -t nat -A POSTROUTING -j MASQUERADE

 

In L2 method the configuration is the same (tunnel, sysctl, iptables..) ? if not can you help me to configure it (tunnel, sysctl, iptables..).

 

Also in switch what's ACL I need to create? 

 

Best regard






_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

 

-- 
Cats - delicious. You just do not know how to cook them.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/1cbffe6d/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 15 04:16:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Dec 2016 17:16:44 +1300
Subject: [squid-users] unknown source IP in access.log
In-Reply-To: <7EC9D65B-924F-4D7F-954C-CF2CB83770A2@solcv.com>
References: <C5EE8EBF-9BE1-4B91-BD76-B32FA7DD27BB@solcv.com>
 <201612141625.32701.Antony.Stone@squid.open.source.it>
 <92FCB4D3-86C5-46EF-8384-96949387D54E@solcv.com>
 <201612142011.47200.Antony.Stone@squid.open.source.it>
 <7EC9D65B-924F-4D7F-954C-CF2CB83770A2@solcv.com>
Message-ID: <6230fc27-3ac9-9276-de7e-92a58fb203c9@treenet.co.nz>

On 15/12/2016 8:58 a.m., Sameh Onaissi wrote:
> Hey Antony, all?
> 
> The file is where is should be: /etc/squid/squid.conf
> 
> 
> squid -k parse returns nothing strange.
> To make sure, I followed your instructions of writing deny wrong (in /etc/squid/squid.conf) and ran "squid -k parse? again, and it complained:
> 
> 2016/12/14 14:45:15| Processing: http_access denyl !Safe_ports
> 2016/12/14 14:45:15| aclParseAccessLine: /etc/squid/squid.conf line 35: http_access denyl !Safe_ports
> 2016/12/14 14:45:15| aclParseAccessLine: expecting 'allow' or 'deny', got 'denyl'.
> 2016/12/14 14:45:15| Processing: http_access deny CONNECT !SSL_ports
> 
> 
> I also commented out the line allowing skype IPs and the access log continued showing said results.
> 
> I should mention that this behavior started today, when it was not happening before.
> 
> additionally:
> 
> find / -name squid.conf
> /etc/fail2ban/filter.d/squid.conf
> /etc/squid.bk/squid.conf
> /etc/squid/squid.conf
> find: ?/run/user/118/gvfs?: Permission denied
> 
> 
> I am sure it is not the squid.bk/squid.conf because that has no acls defined nor configured to use squid guard to redirect pages (which currently is functioning)
> 
> 
> Any other ideas?

>> acl Safe_ports port 587 #SMTP

SMTP is the #1 worst protocol to let anywhere near an HTTP proxy.
Preventing what you have allowed to happen is one of the primary reasons
Safe_ports exists in the first place!

Some (but not all) of the log lines you displayed show signs of email
being delivered through the HTTP proxy to external mailservers.

The protocols look nearly identical in syntax. But the semantic meaning
of the message is different and gets interpreted by HTTP and SMTP relays
in ways the make the results quite nasty (for you) and practically a
haven for spammers.

> 
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localnet
> http_access allow localhost
> http_access deny all

'deny all' is final. No following http_access will ever be used. Which
is lucky given your problem.

> http_access allow CONNECT localnet numeric_IPs Skype_UA
> 
> Maybe someone more knowledgeable can say if I'm wrong here, but I find it hard
> to accept that this really is the squid.conf file you're using:
> 
> a) if it allows connections from IPs such as 118.89.21.244
> 
> b) if it allows *anything* to CONNECT.
> 

With some simple mistake(s) in the iptables rules the port 587 being
allowed could lead to this behaviour. Though the external IP showing up
in the log and not being denied is odd.

Sameh Onaissi: what are your iptables rules? (all of them. For nat,
mangle and filter tables).


One other thing to try is to take the access.log and subtract the
duration times from the timestamp and see what turns out to be starting
at about the same times. The durations on these requests is very long,
so important bits will be happening long before they get logged.

Amos



From squid3 at treenet.co.nz  Thu Dec 15 04:52:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Dec 2016 17:52:21 +1300
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
 Kill process (squid)
In-Reply-To: <04d501d2562e$e56d5e00$b0481a00$@net>
References: <039901d255fe$d80cfe30$8826fa90$@net>
 <0a9501d25612$ad0483c0$070d8b40$@ngtech.co.il>
 <04d501d2562e$e56d5e00$b0481a00$@net>
Message-ID: <78d8e7d3-c361-f610-59fd-85f3657cd326@treenet.co.nz>

On 15/12/2016 6:24 a.m., noc at forceline.net wrote:
> Eliezer, thanks for your reply. Guides:
> http://wiki.squid-cache.org/Features/SslBump
> http://wiki.squid-cache.org/Features/SslPeekAndSplice
> https://habrahabr.ru/post/267851/  <-- Russian lang
> https://habrahabr.ru/post/272733/  <-- Russian lang
> 
>> First goes first change this: 13130:
> Done, nothing changed. Squid died.
> 
> Maby it will be work fine whith lower load even with https. But I don't
> understand, why it killed by a kernel rather than just update memory by new
> one.
> 
> http://wiki.squid-cache.org/Features/SslBump
>> Memory usage
>>
>>    /!\ Warning: Unlike the rest of this page at the time of writing, this
> section applies to Squid-3.3 and possibly later code capable of dynamic SSL
> certificate generation and origin server certificate mimicking. The current
> section text is intended primarily for developers and early adopters facing
> excessive memory consumption in certain SslBump environments. These notes
> may be relocated elsewhere if a better location is found. 
>>
>> Current documentation is specific to bump-server-first configurations.
> 
> In attach server statistic.
> 


I think you still have a forwarding loop. Does the cisco WCCP send port
443 connections from Squid to reach the Internet instead of sending them
back into Squid.

The Via header will protect against HTTP messages looping, but the TLS
handshake traffic has no such protection.

Amos



From bcook at poughkeepsieschools.org  Thu Dec 15 04:56:50 2016
From: bcook at poughkeepsieschools.org (B. Cook)
Date: Wed, 14 Dec 2016 23:56:50 -0500
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
 Kill process (squid)
In-Reply-To: <CAOyb_EyaNh_mdH3Hkztrri-78GOZnK7KSnLD5r9xKdCTN0Nq2w@mail.gmail.com>
References: <039901d255fe$d80cfe30$8826fa90$@net>
 <0a9501d25612$ad0483c0$070d8b40$@ngtech.co.il>
 <04d501d2562e$e56d5e00$b0481a00$@net>
 <78d8e7d3-c361-f610-59fd-85f3657cd326@treenet.co.nz>
 <CAOyb_Ew_ROoNfznFh85vbPsdqRQkuCKO5rprZE3ypaCGWnu3Cw@mail.gmail.com>
 <CAOyb_EyaNh_mdH3Hkztrri-78GOZnK7KSnLD5r9xKdCTN0Nq2w@mail.gmail.com>
Message-ID: <CAOyb_EzLJKVJNRZmDKMOUN+bksch4-nRdQb-m8QrEEz1g2_t0Q@mail.gmail.com>

What does squidclient show?

Get a trace going..

On Dec 14, 2016 11:52 PM, "Amos Jeffries" <squid3 at treenet.co.nz> wrote:

On 15/12/2016 6:24 a.m., noc at forceline.net wrote:
> Eliezer, thanks for your reply. Guides:
> http://wiki.squid-cache.org/Features/SslBump
> http://wiki.squid-cache.org/Features/SslPeekAndSplice
> https://habrahabr.ru/post/267851/  <-- Russian lang
> https://habrahabr.ru/post/272733/  <-- Russian lang
>
>> First goes first change this: 13130:
> Done, nothing changed. Squid died.
>
> Maby it will be work fine whith lower load even with https. But I don't
> understand, why it killed by a kernel rather than just update memory by
new
> one.
>
> http://wiki.squid-cache.org/Features/SslBump
>> Memory usage
>>
>>    /!\ Warning: Unlike the rest of this page at the time of writing, this
> section applies to Squid-3.3 and possibly later code capable of dynamic
SSL
> certificate generation and origin server certificate mimicking. The
current
> section text is intended primarily for developers and early adopters
facing
> excessive memory consumption in certain SslBump environments. These notes
> may be relocated elsewhere if a better location is found.
>>
>> Current documentation is specific to bump-server-first configurations.
>
> In attach server statistic.
>


I think you still have a forwarding loop. Does the cisco WCCP send port
443 connections from Squid to reach the Internet instead of sending them
back into Squid.

The Via header will protect against HTTP messages looping, but the TLS
handshake traffic has no such protection.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

-- 

This message may contain confidential information and is intended only for 
the individual(s) named. If you are not an intended recipient you are not 
authorized to disseminate, distribute or copy this e-mail. Please notify 
the sender immediately if you have received this e-mail by mistake and 
delete this e-mail from your system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161214/1e618a64/attachment.htm>

From yvoinov at gmail.com  Thu Dec 15 11:16:12 2016
From: yvoinov at gmail.com (Yuri)
Date: Thu, 15 Dec 2016 17:16:12 +0600
Subject: [squid-users] Setup wccp2 with squid3 and cisco switch 4507
In-Reply-To: <017401d25658$c365b8a0$4a3129e0$@articatech.com>
References: <007201d25621$2bcfe4c0$836fae40$@articatech.com>
 <f4c69ab1-6539-69df-0bf7-604e2ee543f1@gmail.com>
 <017401d25658$c365b8a0$4a3129e0$@articatech.com>
Message-ID: <3c3cae65-a072-8a4e-ac51-a2281aa777c0@gmail.com>



15.12.2016 4:23, Andr? Bolinhas ?????:
>
> Hi,
>
> In this case, using L2 I don?t need to create a GRE tunnel?
>
Exactly.
>
> Also need to use HTTP_PORT 3128 intercept ?
>
As documented in wiki's article.
>
> Wish iptables I need to create?
>
I know nothing about iptables. I'm not Linux-fanboy.
>
> Best regards
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> *On Behalf Of *Yuri Voinov
> *Sent:* quarta-feira, 14 de dezembro de 2016 16:02
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Setup wccp2 with squid3 and cisco switch 4507
>
> May be, this could help you:
>
> http://wiki.squid-cache.org/ConfigExamples/Intercept/CiscoIOSv15Wccp2
>
> 14.12.2016 21:46, Andr? Bolinhas ?????:
>
>     Hi,
>
>     I need to setup wccp2 between my Squid3 box and my cisco switch 4507
>
>     Since my 4507 don't support GRE on forward methoding I need to
>     configure the the wccp with L2.
>
>     My squid.conf
>
>     http_port 3129 intercept
>
>     wccp2_router $IP-OF-ROUTER
>
>     wccp2_forwarding_method l2
>
>     wccp2_return_method l2
>
>     My question is, in GRE method I need to create a GRE tunnel like this
>
>     modprobe ip_gre
>
>     ip tunnel add wccp0 mode gre remote $ASA-EXT-IP local $SQUID-IP
>     dev eth0
>
>     ifconfig wccp0 $SQUID-IP netmask 255.255.255.255 up
>
>     echo 0 >/proc/sys/net/ipv4/conf/wccp0/rp_filter
>
>     echo 0 >/proc/sys/net/ipv4/conf/eth0/rp_filter
>
>     echo 1 >/proc/sys/net/ipv4/ip_forward
>
>     iptables -t nat -A PREROUTING -i wccp0 -p tcp --dport 80 -j
>     REDIRECT --to-port 3129
>
>     iptables -t nat -A POSTROUTING -j MASQUERADE
>
>     In L2 method the configuration is the same (tunnel, sysctl,
>     iptables..) ? if not can you help me to configure it (tunnel,
>     sysctl, iptables..).
>
>     Also in switch what's ACL I need to create?
>
>     Best regard
>
>
>
>
>     _______________________________________________
>
>     squid-users mailing list
>
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>
>     http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> Cats - delicious. You just do not know how to cook them.
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161215/d0569e57/attachment.htm>

From eliezer at ngtech.co.il  Thu Dec 15 13:13:17 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 15 Dec 2016 15:13:17 +0200
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
	Kill process (squid)
In-Reply-To: <78d8e7d3-c361-f610-59fd-85f3657cd326@treenet.co.nz>
References: <039901d255fe$d80cfe30$8826fa90$@net>
 <0a9501d25612$ad0483c0$070d8b40$@ngtech.co.il>
 <04d501d2562e$e56d5e00$b0481a00$@net>
 <78d8e7d3-c361-f610-59fd-85f3657cd326@treenet.co.nz>
Message-ID: <0bc001d256d4$ffcc24b0$ff646e10$@ngtech.co.il>

+1 for what Amos suggesting.
It's too weird to be caused by a special and unknown issue.
Can you minimize the test to intercept only 1 SINGLE client?
Also about the Russian tutorials, these are for building and running squid which might work.
But for the interception part on the cisco you didn't referred to any tutorial.
I can only refer a tutorial which I wrote for a cisco router:
http://wiki.squid-cache.org/ConfigExamples/UbuntuTproxy4Wccp2
Also squid cannot identify in any way if there is a routing or switching loop.

To illustrate:
Squid has mac address 99:99:99:99:99:91 and the switch has 99:99:99:99:99:92, 
Squid will always see packets flowing from one of the switch mac address for both legit and non legit(loops).
So you first need to verify the setup with one single client and use tcdump on the squid machine to identify by the src port if the connection is looped or not.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Thursday, December 15, 2016 6:52 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Crash: every 1-2 hour: kernel: Out of memory: Kill process (squid)

On 15/12/2016 6:24 a.m., noc at forceline.net wrote:
> Eliezer, thanks for your reply. Guides:
> http://wiki.squid-cache.org/Features/SslBump
> http://wiki.squid-cache.org/Features/SslPeekAndSplice
> https://habrahabr.ru/post/267851/  <-- Russian lang 
> https://habrahabr.ru/post/272733/  <-- Russian lang
> 
>> First goes first change this: 13130:
> Done, nothing changed. Squid died.
> 
> Maby it will be work fine whith lower load even with https. But I 
> don't understand, why it killed by a kernel rather than just update 
> memory by new one.
> 
> http://wiki.squid-cache.org/Features/SslBump
>> Memory usage
>>
>>    /!\ Warning: Unlike the rest of this page at the time of writing, 
>> this
> section applies to Squid-3.3 and possibly later code capable of 
> dynamic SSL certificate generation and origin server certificate 
> mimicking. The current section text is intended primarily for 
> developers and early adopters facing excessive memory consumption in 
> certain SslBump environments. These notes may be relocated elsewhere if a better location is found.
>>
>> Current documentation is specific to bump-server-first configurations.
> 
> In attach server statistic.
> 


I think you still have a forwarding loop. Does the cisco WCCP send port
443 connections from Squid to reach the Internet instead of sending them back into Squid.

The Via header will protect against HTTP messages looping, but the TLS handshake traffic has no such protection.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From bryan at softchalk.com  Thu Dec 15 14:29:19 2016
From: bryan at softchalk.com (Bryan Peters)
Date: Thu, 15 Dec 2016 09:29:19 -0500
Subject: [squid-users] Squid Forward Proxy for LDAP
Message-ID: <CAL0tzXMmsb0gn+KiOOVUOa-EUJ9VjYyNvttf+7KGWX_eC4LCpg@mail.gmail.com>

My Google-fu seems to be coming up short.

We have an application that ties into our users SSO/LDAP servers.  We,
don't run an LDAP server of our own, we're just making outbound calls to
their LDAP servers.

I would like to proxy all outbound LDAP calls through Squid to get around
some limitations of AWS and our customers need to whitelist an IP. (AWS
load balancers don't have static IPs, some of our customers won't whitelist
FQDNs in their firewall).

Getting the traffic from our app server(s) to the Squid box hasn't been
much of a problem.  I'm using Iptables/NAT to accomplish this.   TCPdump on
the Squid machine sees  traffic coming in on 3128.

I've added 389 as a 'safe port' in the squid config, created ACLs that
allow the network the traffic is coming in on.  Yet squid never grabs the
traffic and does anything with it.  The logs don't get updated at all.

Am I incorrect about Squid being able to proxy LDAP traffic?

Googling for this is sort of maddening as all forums, mailing lists, FAQs
and documentation continues to come up for doing LDAP auth on a Squid
machine, which isn't what I'm looking for at all.

Any help you can give would be appreciated.

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161215/28c8a468/attachment.htm>

From yvoinov at gmail.com  Thu Dec 15 21:20:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 16 Dec 2016 03:20:56 +0600
Subject: [squid-users] Squid Forward Proxy for LDAP
In-Reply-To: <CAL0tzXMmsb0gn+KiOOVUOa-EUJ9VjYyNvttf+7KGWX_eC4LCpg@mail.gmail.com>
References: <CAL0tzXMmsb0gn+KiOOVUOa-EUJ9VjYyNvttf+7KGWX_eC4LCpg@mail.gmail.com>
Message-ID: <16ee3c45-cf95-51be-d4db-4ab180e6c170@gmail.com>



15.12.2016 20:29, Bryan Peters ?????:
> My Google-fu seems to be coming up short.
>
> We have an application that ties into our users SSO/LDAP servers.  We,
> don't run an LDAP server of our own, we're just making outbound calls
> to their LDAP servers.
>
> I would like to proxy all outbound LDAP calls through Squid to get
> around some limitations of AWS and our customers need to whitelist an
> IP. (AWS load balancers don't have static IPs, some of our customers
> won't whitelist FQDNs in their firewall).
>
> Getting the traffic from our app server(s) to the Squid box hasn't
> been much of a problem.  I'm using Iptables/NAT to accomplish this.  
> TCPdump on the Squid machine sees  traffic coming in on 3128.
>
> I've added 389 as a 'safe port' in the squid config, created ACLs that
> allow the network the traffic is coming in on.  Yet squid never grabs
> the traffic and does anything with it.  The logs don't get updated at all.
>
> Am I incorrect about Squid being able to proxy LDAP traffic?  
Exactly. By definition, squid is only HTTP proxy. Initially.
Modern versions supports also HTTPS (with restrictions) and FTP (with
restrictions).
>
> Googling for this is sort of maddening as all forums, mailing lists,
> FAQs and documentation continues to come up for doing LDAP auth on a
> Squid machine, which isn't what I'm looking for at all.
Condolences. Thing you want is not possible by Squid.
>
> Any help you can give would be appreciated.
It can not help the fact that the product is not as a class. Squid - no
proxy all protocols in the world. Although it would not prevent the
availability of support for some of them - and it is certainly not FTP
(FTP - in 2016 the year indeed! :))
>
> Thanks
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161216/320e3cd3/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161216/320e3cd3/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161216/320e3cd3/attachment.sig>

From bpk678 at gmail.com  Thu Dec 15 23:36:40 2016
From: bpk678 at gmail.com (Brendan Kearney)
Date: Thu, 15 Dec 2016 18:36:40 -0500
Subject: [squid-users] Squid Forward Proxy for LDAP
In-Reply-To: <16ee3c45-cf95-51be-d4db-4ab180e6c170@gmail.com>
References: <CAL0tzXMmsb0gn+KiOOVUOa-EUJ9VjYyNvttf+7KGWX_eC4LCpg@mail.gmail.com>
 <16ee3c45-cf95-51be-d4db-4ab180e6c170@gmail.com>
Message-ID: <289a578a-4512-3ada-6924-afc2fd3831d7@gmail.com>

On 12/15/2016 04:20 PM, Yuri Voinov wrote:
>
>
>
> 15.12.2016 20:29, Bryan Peters ?????:
>> My Google-fu seems to be coming up short.
>>
>> We have an application that ties into our users SSO/LDAP servers.  
>> We, don't run an LDAP server of our own, we're just making outbound 
>> calls to their LDAP servers.
>>
>> I would like to proxy all outbound LDAP calls through Squid to get 
>> around some limitations of AWS and our customers need to whitelist an 
>> IP. (AWS load balancers don't have static IPs, some of our customers 
>> won't whitelist FQDNs in their firewall).
>>
>> Getting the traffic from our app server(s) to the Squid box hasn't 
>> been much of a problem.  I'm using Iptables/NAT to accomplish this.   
>> TCPdump on the Squid machine sees  traffic coming in on 3128.
>>
>> I've added 389 as a 'safe port' in the squid config, created ACLs 
>> that allow the network the traffic is coming in on.  Yet squid never 
>> grabs the traffic and does anything with it.  The logs don't get 
>> updated at all.
>>
>> Am I incorrect about Squid being able to proxy LDAP traffic?
> Exactly. By definition, squid is only HTTP proxy. Initially.
> Modern versions supports also HTTPS (with restrictions) and FTP (with 
> restrictions).
>>
>> Googling for this is sort of maddening as all forums, mailing lists, 
>> FAQs and documentation continues to come up for doing LDAP auth on a 
>> Squid machine, which isn't what I'm looking for at all.
> Condolences. Thing you want is not possible by Squid.
>>
>> Any help you can give would be appreciated.
> It can not help the fact that the product is not as a class. Squid - 
> no proxy all protocols in the world. Although it would not prevent the 
> availability of support for some of them - and it is certainly not FTP 
> (FTP - in 2016 the year indeed! :))
>>
>> Thanks
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> Cats - delicious. You just do not know how to cook them.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

if you want to proxy LDAP, why not use LDAP to do it?

http://www.openldap.org/doc/admin23/proxycache.html


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161215/7a7fa1b0/attachment.htm>

From moremore2 at outlook.com  Fri Dec 16 06:34:12 2016
From: moremore2 at outlook.com (k simon)
Date: Fri, 16 Dec 2016 06:34:12 +0000
Subject: [squid-users] r14088 crash on FreeBSD 11
Message-ID: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>

Hi,lists,
   r14087 is quite stable on FB 11. But r14088 crashed frequently with 
"2016/12/16 09:00:59 kid1| assertion failed: MemBuf.cc:216: "0 <= 
tailSize && tailSize <= cSize" ". The config file is almost the default 
except listening port and http_access modification.


Simon
20161216





P.S.
# uname -a
FreeBSD unkn-j9 11.0-STABLE FreeBSD 11.0-STABLE #0 r309724: Fri Dec  9 
11:01:51 CST 2016 
root at cache-farm-n1:/usr/obj/usr/src/sys/11-ule-r309209  amd64

# squid -vv
Squid Cache: Version 3.5.21
Service Name: squid
configure options:  '--with-default-user=squid' 
'--bindir=/usr/local/sbin' '--sbindir=/usr/local/sbin' 
'--datadir=/usr/local/etc/squid' '--libexecdir=/usr/local/libexec/squid' 
'--localstatedir=/var' '--sysconfdir=/usr/local/etc/squid' 
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid/squid.pid' 
'--with-swapdir=/var/squid/cache' '--without-gnutls' '--enable-auth' 
'--enable-build-info' '--enable-loadable-modules' 
'--enable-removal-policies=lru heap' '--disable-epoll' 
'--disable-linux-netfilter' '--disable-linux-tproxy' 
'--disable-translation' '--disable-arch-native' '--disable-eui' 
'--disable-cache-digests' '--disable-delay-pools' '--disable-ecap' 
'--disable-esi' '--enable-follow-x-forwarded-for' '--disable-htcp' 
'--disable-icap-client' '--disable-icmp' '--disable-ident-lookups' 
'--enable-ipv6' '--enable-kqueue' '--with-large-files' 
'--enable-http-violations' '--without-nettle' '--enable-snmp' 
'--disable-ssl' '--disable-ssl-crtd' '--disable-stacktraces' 
'--disable-forw-via-db' '--disable-wccp' '--disable-wccpv2' 
'--without-heimdal-krb5' '--without-mit-krb5' '--without-gss' 
'--disable-ipf-transparent' '--enable-ipfw-transparent' 
'--disable-pf-transparent' '--without-nat-devpf' '--enable-auth-basic=DB 
SMB_LM MSNT-multi-domain NCSA PAM POP3 RADIUS fake getpwnam' 
'--enable-auth-digest=file' '--enable-external-acl-helpers=file_userip 
time_quota unix_group' '--enable-auth-negotiate=none' 
'--enable-auth-ntlm=fake smb_lm' '--enable-storeio=aufs diskd rock ufs' 
'--enable-disk-io=DiskThreads DiskDaemon AIO Blocking IpcIo Mmapped' 
'--enable-log-daemon-helpers=file' '--enable-url-rewrite-helpers=fake' 
'--enable-storeid-rewrite-helpers=file' '--prefix=/usr/local' 
'--mandir=/usr/local/man' '--disable-silent-rules' 
'--infodir=/usr/local/info/' '--build=amd64-portbld-freebsd11.0' 
'build_alias=amd64-portbld-freebsd11.0' 'CC=cc' 'CFLAGS=-O2 -pipe -m64 
-fno-strict-aliasing -fno-omit-frame-pointer -march=penryn 
-fstack-protector' 'LDFLAGS=-L/usr/local/lib -Wl,--eh-frame-hdr' 
'LIBS=-lthr -lpcreposix -lpcre -ltcmalloc_minimal' 'CPPFLAGS=' 'CXX=c++' 
'CXXFLAGS=-std=c++11 -fPIC -DPIC -I/usr/local/include' 'CPP=cpp'

From garryd at comnet.uz  Fri Dec 16 09:38:33 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Fri, 16 Dec 2016 14:38:33 +0500
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
Message-ID: <1481881113.13325.1.camel@comnet.uz>

On Fri, 2016-12-16 at 06:34 +0000, k simon wrote:
> Hi,lists,
> ???r14087 is quite stable on FB 11. But r14088 crashed frequently
> with?
> "2016/12/16 09:00:59 kid1| assertion failed: MemBuf.cc:216: "0 <=?
> tailSize && tailSize <= cSize" ". The config file is almost the
> default?
> except listening port and http_access modification.

Hi,

I believe you faced bug 4606 [1]. Do you use 'collapsed_forwarding'
option? If you have any new details please add a comment to the bug
report.

[1]?http://bugs.squid-cache.org/show_bug.cgi?id=4606


Garri


From garryd at comnet.uz  Fri Dec 16 09:47:30 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Fri, 16 Dec 2016 14:47:30 +0500
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <1481881113.13325.1.camel@comnet.uz>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
 <1481881113.13325.1.camel@comnet.uz>
Message-ID: <1481881650.13325.3.camel@comnet.uz>

On Fri, 2016-12-16 at 14:38 +0500, Garri Djavadyan wrote:
> On Fri, 2016-12-16 at 06:34 +0000, k simon wrote:
> > Hi,lists,
> > ???r14087 is quite stable on FB 11. But r14088 crashed frequently
> > with?
> > "2016/12/16 09:00:59 kid1| assertion failed: MemBuf.cc:216: "0 <=?
> > tailSize && tailSize <= cSize" ". The config file is almost the
> > default?
> > except listening port and http_access modification.
> 
> Hi,
> 
> I believe you faced bug 4606 [1]. Do you use 'collapsed_forwarding'
> option? If you have any new details please add a comment to the bug
> report.
> 
> [1]?http://bugs.squid-cache.org/show_bug.cgi?id=4606

Sorry, actually, 'collapsed_forwarding' should not be enabled to facethe bug. 

Garri


From moremore2 at outlook.com  Fri Dec 16 10:31:32 2016
From: moremore2 at outlook.com (k simon)
Date: Fri, 16 Dec 2016 10:31:32 +0000
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <1481881650.13325.3.camel@comnet.uz>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
 <1481881113.13325.1.camel@comnet.uz> <1481881650.13325.3.camel@comnet.uz>
Message-ID: <MWHPR13MB1262DFF6EF015950634108D1EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>

Hi,
   Thank you ,Garri. It's it, but I have no new detail.

Simon

? 2016/12/16 17:47, Garri Djavadyan ??:
> On Fri, 2016-12-16 at 14:38 +0500, Garri Djavadyan wrote:
>> On Fri, 2016-12-16 at 06:34 +0000, k simon wrote:
>>> Hi,lists,
>>>    r14087 is quite stable on FB 11. But r14088 crashed frequently
>>> with
>>> "2016/12/16 09:00:59 kid1| assertion failed: MemBuf.cc:216: "0 <=
>>> tailSize && tailSize <= cSize" ". The config file is almost the
>>> default
>>> except listening port and http_access modification.
>>
>> Hi,
>>
>> I believe you faced bug 4606 [1]. Do you use 'collapsed_forwarding'
>> option? If you have any new details please add a comment to the bug
>> report.
>>
>> [1] http://bugs.squid-cache.org/show_bug.cgi?id=4606
>
> Sorry, actually, 'collapsed_forwarding' should not be enabled to facethe bug.
>
> Garri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

From squid3 at treenet.co.nz  Fri Dec 16 11:41:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 17 Dec 2016 00:41:34 +1300
Subject: [squid-users] Proper Cache Peer Access
In-Reply-To: <1481680590.257524.818258457.53390C0E@webmail.messagingengine.com>
References: <1481677840.246532.818227873.09759741@webmail.messagingengine.com>
 <6ac90a52-3089-2d21-417d-98ed4a159200@treenet.co.nz>
 <1481680590.257524.818258457.53390C0E@webmail.messagingengine.com>
Message-ID: <8c061728-1aa3-db19-b9a3-92c4952535ea@treenet.co.nz>

On 14/12/2016 2:56 p.m., creditu at eml.cc wrote:
> On Tue, Dec 13, 2016, at 06:33 PM, Amos Jeffries wrote:
>> On 14/12/2016 2:10 p.m., creditu wrote:
>>> Looking for the best way to provide cache peer access for two urls on a
>>> 3.1 accelerator.  For example if a set of backend servers fullfill
>>> requests for both www.example.com and www-legacy.example.com is the
>>> following the correct way to handle them in regards to the cach peer
>>> access? 
>>>
>>
>> What you have works and is fine for simple setups like yours.
>>
>> However, since you ask for "proper" ...
>>
>> <snip>
>>>
>>> # Backend servers for www and www-legacy
>>> acl www dstdomain www.example.com
>>> acl www-legacy dstdomain www-legacy.example.com
>>
>> Recommended practice when you have same-type data and ACLs used in
>> identical ways like these ones. Is to place both those domain values in
>> the one ACL named 'www'. That will simplify your access lines.
>>
>> There are some tiny memory and (cumulative) speed gains. But the biggest
>> reason is easier understanding and maintenance of the config if/when it
>> gets more complex.
>>
>> Amos
>>
>> _______________
> 
> Ah, so you would do something like this:
> 
> acl www dstdomain www.example.com www-legacy.example.com
> cache_peer 10.10.10.1 parent 80 0 no-query no-digest originserver
> round-robin
> cache_peer_access 10.10.10.1 allow www
> cache_peer_access 10.10.10.1 deny all
> . . .

I would, yes.

> 
> I was worried about a situation that was detailed in
> http://wiki.squid-cache.org/SquidFaq/SquidAcl#And.2FOr_logic (the src
> address example).  Thanks

You are more likely to make that mistake with the differently named ACLs
config. That's part of the simplicity==good reasoning.

Using them as the only condition on different but sequential lines is an
OR condition. Putting two values in one named ACL is also an OR
condition. So for simple types like dstdomain the two ways of writing
'OR' are equivalent and the simpler way is better for reasons other than
than technical ones (harder for us humans to make mistakes with).

For some ACL types which have side effects (like helper or remote data
lookups) the use of multiple allow/deny lines can behave differently
than one ACL check. Which can be useful if you want that, but not what
you have going on here.

Amos



From squid3 at treenet.co.nz  Fri Dec 16 13:20:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 17 Dec 2016 02:20:59 +1300
Subject: [squid-users] 10 seconds delay squdclient delay
In-Reply-To: <CAL5yMZRB78tNieUCD+oWFgtiByODPJxy+pnRgZTypX5wOVccCw@mail.gmail.com>
References: <CAL5yMZRB78tNieUCD+oWFgtiByODPJxy+pnRgZTypX5wOVccCw@mail.gmail.com>
Message-ID: <605e298c-e16b-9764-3b50-acf3c5014d2d@treenet.co.nz>

On 10/12/2016 12:55 a.m., Javier Barroso wrote:
> Hello,
> 
> We are having trouble with cachemgr performance. Do you know why
> squidclient could delay 10 seconds on mgr:xxx queries ?
> 
> I have looked about any timeout, or network error, or something, but I
> did not find nothing

The idea that comes to mind (for me) is that it may be a queue delay in
the UDS kernel I/O subsystem if your Squid is processing much traffic
shared between workers. The SMP coordinator process that arbitrates all
that plus generates these reports may be heavily loaded with work.

If it is a bug, whoever looks into it will likely need a ALL,9 cache.log
trace to have a chance figuring out what the problem might be.

Amos



From rousskov at measurement-factory.com  Fri Dec 16 16:06:56 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 16 Dec 2016 09:06:56 -0700
Subject: [squid-users] 10 seconds delay squdclient delay
In-Reply-To: <605e298c-e16b-9764-3b50-acf3c5014d2d@treenet.co.nz>
References: <CAL5yMZRB78tNieUCD+oWFgtiByODPJxy+pnRgZTypX5wOVccCw@mail.gmail.com>
 <605e298c-e16b-9764-3b50-acf3c5014d2d@treenet.co.nz>
Message-ID: <4875c2e4-157e-b686-aa3a-c2d7345ce285@measurement-factory.com>

On 12/16/2016 06:20 AM, Amos Jeffries wrote:
> On 10/12/2016 12:55 a.m., Javier Barroso wrote:
>> We are having trouble with cachemgr performance. Do you know why
>> squidclient could delay 10 seconds on mgr:xxx queries ?
>>
>> I have looked about any timeout, or network error, or something, but I
>> did not find nothing
> 
> The idea that comes to mind (for me) is that it may be a queue delay in
> the UDS kernel I/O subsystem if your Squid is processing much traffic
> shared between workers. The SMP coordinator process that arbitrates all
> that plus generates these reports may be heavily loaded with work.

To test that theory, you can use mgr:xxx queries that target:

* Coordinator itself (without forwarding to any other kids)
* an idle kid (which can be created for the test if needed)
* N idle kids (which can be created for the test if needed)
* a busy kid
* etc.

I suspect that with enough variety of such queries, one can confirm or
rule out UDS communication delays, separating them from load-induced
processing delays at each kid.

Another investigation vector is studying the timing of individual kid
response blobs inside a single multi-kid mgr:xxx response. Does the
delay accumulate with each blob or occurs before all blobs? You may be
able to measure the delay using packet traces.

Sorry, I cannot provide detailed instructions at this time, but perhaps
others on this list can.

Alex.



From robert at gillecaluim.com  Sat Dec 17 05:00:26 2016
From: robert at gillecaluim.com (Robert Watson)
Date: Fri, 16 Dec 2016 21:00:26 -0800
Subject: [squid-users] squid.conf blocking live video stream
Message-ID: <CADoG9xmtUhG38Wy5bYsE54oQsrttCiX=XOHWQYXiDHj2ORiSGw@mail.gmail.com>

Sorry if this shows up twice on the mailing list...
I've setup a transparent proxy squid v3.5.22 on a x86_64 Arch Linux
server.  The transparent proxy is working fine for web page caching but
live video isn't getting through.  I thought it was a netfilter issue but
bypassing the proxy fixes this issue.

acl localnet src 10.20.0.0/16 # RFC1918 possible internal network
acl SSL_ports port 443 # https
acl Safe_ports port 80 # http
acl Safe_ports port 554 # rtsp
acl Safe_ports port 1935 # rtmp
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 1025-65535  # unregistered ports
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
http_access allow localnet
http_access allow localhost
http_access deny all
visible_hostname server.ourhome.net
http_port 10.20.30.1:3128 intercept disable-pmtu-discovery=transparent
http_port 127.0.0.0:8181
coredump_dir /var/cache/squid
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320
#
# Anonymous Proxy settings
include /etc/squid/extra/anonymous.conf
#
# Virus scanning via C-ICAP
#
include /etc/squid/extra/c-icap.conf
#

By the process of elimination I've narrowed it down to the anonymous proxy
settings...
anonymous.conf

forwarded_for off
request_header_access Allow allow all
request_header_access Authorization allow all
request_header_access WWW-Authenticate allow all
request_header_access Proxy-Authorization allow all
request_header_access Proxy-Authenticate allow all
request_header_access Cache-Control allow all
request_header_access Content-Encoding allow all
request_header_access Content-Length allow all
request_header_access Content-Type allow all
request_header_access Date allow all
request_header_access Expires allow all
request_header_access Host allow all
request_header_access If-Modified-Since allow all
request_header_access Last-Modified allow all
request_header_access Location allow all
request_header_access Pragma allow all
request_header_access Accept allow all
request_header_access Accept-Charset allow all
request_header_access Accept-Encoding allow all
request_header_access Accept-Language allow all
request_header_access Content-Language allow all
request_header_access Mime-Version allow all
request_header_access Retry-After allow all
request_header_access Title allow all
request_header_access Connection allow all
request_header_access Proxy-Connection allow all
request_header_access User-Agent allow all
request_header_access Cookie allow all
request_header_access All deny all

could someone please tell me what request_header_access I need to all, or
how to further trouble shoot this configuration?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161216/4c5a593a/attachment.htm>

From squid3 at treenet.co.nz  Sat Dec 17 05:43:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 17 Dec 2016 18:43:32 +1300
Subject: [squid-users] squid.conf blocking live video stream
In-Reply-To: <CADoG9xmtUhG38Wy5bYsE54oQsrttCiX=XOHWQYXiDHj2ORiSGw@mail.gmail.com>
References: <CADoG9xmtUhG38Wy5bYsE54oQsrttCiX=XOHWQYXiDHj2ORiSGw@mail.gmail.com>
Message-ID: <9f6760ea-6d4c-25e8-b5d1-c86019e09d03@treenet.co.nz>

On 17/12/2016 6:00 p.m., Robert Watson wrote:
> Sorry if this shows up twice on the mailing list...
> I've setup a transparent proxy squid v3.5.22 on a x86_64 Arch Linux
> server.  The transparent proxy is working fine for web page caching but
> live video isn't getting through.  I thought it was a netfilter issue but
> bypassing the proxy fixes this issue.
> 
<snip>
> 
> could someone please tell me what request_header_access I need to all, or
> how to further trouble shoot this configuration?
> 

Via.

I expect that will then reveal that you have configured a forwarding
loop in your iptables rules.
Please check that you are using *all* of the iptables rules mentioned in
<http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>
(when that wiki is fixed, it seems to be down right now).


To allow the HTTP standard headers, but not application specific
extensions it is simpler to use just this one line:
  request_header_access Other deny all

Then you only need to add "deny" lines for any of the standard headers
you want to block above that one.

Amos



From javibarroso at gmail.com  Sat Dec 17 08:18:11 2016
From: javibarroso at gmail.com (Javier Barroso)
Date: Sat, 17 Dec 2016 09:18:11 +0100
Subject: [squid-users] 10 seconds delay squdclient delay
In-Reply-To: <605e298c-e16b-9764-3b50-acf3c5014d2d@treenet.co.nz>
References: <CAL5yMZRB78tNieUCD+oWFgtiByODPJxy+pnRgZTypX5wOVccCw@mail.gmail.com>
 <605e298c-e16b-9764-3b50-acf3c5014d2d@treenet.co.nz>
Message-ID: <CAL5yMZSx5YNpw5jcBJMWc9symLoZMXLoD8tCjpCa5eETdsXzPg@mail.gmail.com>

Hello,

On Fri, Dec 16, 2016 at 2:20 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 10/12/2016 12:55 a.m., Javier Barroso wrote:
>> Hello,
>>
>> We are having trouble with cachemgr performance. Do you know why
>> squidclient could delay 10 seconds on mgr:xxx queries ?
>>
>> I have looked about any timeout, or network error, or something, but I
>> did not find nothing
>
> The idea that comes to mind (for me) is that it may be a queue delay in
> the UDS kernel I/O subsystem if your Squid is processing much traffic
> shared between workers. The SMP coordinator process that arbitrates all
> that plus generates these reports may be heavily loaded with work.
>
> If it is a bug, whoever looks into it will likely need a ALL,9 cache.log
> trace to have a chance figuring out what the problem might be.
As it is a production environment I should try to replicate on another
environment, I am not sure if we can do it in a short space of time.

i think ALL,9 is not suitable for production. We are using squid
3.5.1, so the first step is to upgrade to the latest 3.5 release.

Thank you very much


From javibarroso at gmail.com  Sat Dec 17 08:20:45 2016
From: javibarroso at gmail.com (Javier Barroso)
Date: Sat, 17 Dec 2016 09:20:45 +0100
Subject: [squid-users] 10 seconds delay squdclient delay
In-Reply-To: <4875c2e4-157e-b686-aa3a-c2d7345ce285@measurement-factory.com>
References: <CAL5yMZRB78tNieUCD+oWFgtiByODPJxy+pnRgZTypX5wOVccCw@mail.gmail.com>
 <605e298c-e16b-9764-3b50-acf3c5014d2d@treenet.co.nz>
 <4875c2e4-157e-b686-aa3a-c2d7345ce285@measurement-factory.com>
Message-ID: <CAL5yMZTFYEGsFmMxYkjt99B+DjTqDj99MKbb5W6K_=tQkeF5BA@mail.gmail.com>

Hello,

On Fri, Dec 16, 2016 at 5:06 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 12/16/2016 06:20 AM, Amos Jeffries wrote:
>> On 10/12/2016 12:55 a.m., Javier Barroso wrote:
>>> We are having trouble with cachemgr performance. Do you know why
>>> squidclient could delay 10 seconds on mgr:xxx queries ?
>>>
>>> I have looked about any timeout, or network error, or something, but I
>>> did not find nothing
>>
>> The idea that comes to mind (for me) is that it may be a queue delay in
>> the UDS kernel I/O subsystem if your Squid is processing much traffic
>> shared between workers. The SMP coordinator process that arbitrates all
>> that plus generates these reports may be heavily loaded with work.
>
> To test that theory, you can use mgr:xxx queries that target:
>
> * Coordinator itself (without forwarding to any other kids)
> * an idle kid (which can be created for the test if needed)
> * N idle kids (which can be created for the test if needed)
> * a busy kid
> * etc.

I had a case where squid (with the same configuration) hangs 20
seconds, and it have configured 4 workers, so may be this is what is
happening.
Unfortunaly I couldn't get the trace before that such instance was restarted.

Thank you very much


From hardikdangar+squid at gmail.com  Sat Dec 17 09:16:55 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Sat, 17 Dec 2016 14:46:55 +0530
Subject: [squid-users] Squid Websocket Issue
Message-ID: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>

Here is some information about my squid version,

Squid Cache: Version 3.5.22-20161115-r14113
Service Name: squid
configure options:  '--prefix=/usr' '--localstatedir=/var/squid'
'--libexecdir=/lib/squid' '--srcdir=.' '--datadir=/share/squid'
'--sysconfdir=/etc/squid' '--with-default-user=proxy'
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'
'--with-openssl' '--enable-ssl-crtd' '--enable-inline'
'--disable-arch-native' '--enable-async-io=8'
'--enable-storeio=ufs,aufs,diskd,rock'
'--enable-removal-policies=lru,heap' '--enable-delay-pools'
'--enable-follow-x-forwarded-for' '--enable-url-rewrite-helpers=fake'
'--enable-ecap'

My squid config file is located at, http://pastebin.com/raw/LvDxEF4x

Now the issue is whenever someone requests a page which contains web socket
requests response is always bad request.
Here is an example,

Request URL:wss://w4.web.whatsapp.com/ws
Request Method:GET
Status Code:400 Bad Request

Response Headers
#################
Connection:keep-alive
Date:Sat, 17 Dec 2016 09:05:36 GMT
Transfer-Encoding:chunked
X-Cache:MISS from Proxy

Request Headers
#################
Accept-Encoding:gzip, deflate, sdch, br
Accept-Language:en-US,en;q=0.8
Cache-Control:no-cache
Connection:Upgrade
Host:w4.web.whatsapp.com
Origin:https://web.whatsapp.com
Pragma:no-cache
Sec-WebSocket-Extensions:permessage-deflate; client_max_window_bits
Sec-WebSocket-Key:kzrB2ZcMHDAqvjDNXnjL/w==
Sec-WebSocket-Version:13
Upgrade:websocket
User-Agent:Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like
Gecko) Chrome/55.0.2883.75 Safari/537.36


My question is how we can work with web socket requests in squid or if not
by pass them squid. My squid instance is in interception mode and requests
are intercepted at instance via iptables and forwarded to squid using below
rules,

SQUIDIP=192.168.1.1

# your proxy listening port
SQUIDHTTPPORT=3128
SQUIDHTTPSPORT=3129


iptables -t nat -A PREROUTING -s $SQUIDIP -p tcp --dport 80 -j ACCEPT
iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port
$SQUIDHTTPPORT

iptables -t nat -A PREROUTING -s $SQUIDIP -p tcp --dport 443 -j ACCEPT
iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port
$SQUIDHTTPSPORT

iptables -t nat -A POSTROUTING -j MASQUERADE
iptables -t mangle -A PREROUTING -p tcp --dport $SQUIDHTTPPORT -j DROP
iptables -t mangle -A PREROUTING -p tcp --dport $SQUIDHTTPSPORT -j DROP


If anyone can help me with this it would be really awesome. Thanks for your
support.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161217/90a68891/attachment.htm>

From odhiambo at gmail.com  Sat Dec 17 10:41:20 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Sat, 17 Dec 2016 13:41:20 +0300
Subject: [squid-users] Missing cache files
Message-ID: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>

Hi,

I keep seeing something that I think is odd. Squid has been exiting on
signal 6, and I keep seeing this:

root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1

So, what could be making the files disappear?


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161217/9c3dd5b3/attachment.htm>

From yvoinov at gmail.com  Sat Dec 17 12:06:36 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 17 Dec 2016 18:06:36 +0600
Subject: [squid-users] Missing cache files
In-Reply-To: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
Message-ID: <39653388-5581-657c-7c44-9b961e8f39b7@gmail.com>

Man, this question has been answered a million times. Use the search.


17.12.2016 16:41, Odhiambo Washington ?????:
> Hi,
>
> I keep seeing something that I think is odd. Squid has been exiting on
> signal 6, and I keep seeing this:
>
> root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
> 2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
> 2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
> 2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
> 2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
> 2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1
>
> So, what could be making the files disappear?
>
>
> -- 
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Cats - delicious. You just do not know how to cook them.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161217/1a118202/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161217/1a118202/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161217/1a118202/attachment.sig>

From garryd at comnet.uz  Sat Dec 17 12:17:02 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Sat, 17 Dec 2016 17:17:02 +0500
Subject: [squid-users] Missing cache files
In-Reply-To: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
Message-ID: <0a9b80f91fa7363c0addc0ae3f5d231a@comnet.uz>

On 2016-12-17 15:41, Odhiambo Washington wrote:
> Hi,
> 
> I keep seeing something that I think is odd. Squid has been exiting on
> signal 6, and I keep seeing this:
> 
> root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
> 2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
> 2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
> 2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
> 2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
> 2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file
> or directory
> 2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1
> 
> So, what could be making the files disappear?


Hi,

(Reply from Amos Jeffries from 
http://bugs.squid-cache.org/show_bug.cgi?id=4367#c2)
> This is Squid *detecting* complete absence of disk files. Not causing
> corruption.
> 
> Please check if you have multiple Squid instances running and accessing 
> the
> same cache_dir. That includes multiple workers using the same 
> ufs/aufs/diskd
> cache_dir configuration line.
> 
> Also whether swap.state for that cache_dir is being correctly and 
> completely
> written out to disk on shutdown or restart. Using an outdated 
> swap.state
> file can also lead to these warnings.

The last paragraph explains your issue. The signal 6 (abort) forces 
Squid worker to terminate immediately (to avoid all required shutdown 
procedures) and leave core dump. You can find a reason for abort in 
cache.log.


Garri


From piequiex at nym.mixmin.net  Sat Dec 17 13:29:10 2016
From: piequiex at nym.mixmin.net (piequiex)
Date: Sat, 17 Dec 2016 13:29:10 +0000 (GMT)
Subject: [squid-users] cipher log
Message-ID: <20161217132911.065DD1200B8@fleegle.mixmin.net>

ssl-bump enabled, I would like to log ciphers. Is it possible?
-- 
0x16E684E1A170D8A3



From odhiambo at gmail.com  Sat Dec 17 13:39:37 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Sat, 17 Dec 2016 16:39:37 +0300
Subject: [squid-users] Missing cache files
In-Reply-To: <0a9b80f91fa7363c0addc0ae3f5d231a@comnet.uz>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <0a9b80f91fa7363c0addc0ae3f5d231a@comnet.uz>
Message-ID: <CAAdA2WPhCUusnqFN=mheAenCsuxj5TfU-ssWBjwip1Fmsts6vw@mail.gmail.com>

On 17 December 2016 at 15:17, Garri Djavadyan <garryd at comnet.uz> wrote:

> On 2016-12-17 15:41, Odhiambo Washington wrote:
>
>> Hi,
>>
>> I keep seeing something that I think is odd. Squid has been exiting on
>> signal 6, and I keep seeing this:
>>
>> root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
>> 2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file
>> or directory
>> 2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
>> 2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file
>> or directory
>> 2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
>> 2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file
>> or directory
>> 2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
>> 2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file
>> or directory
>> 2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
>> 2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file
>> or directory
>> 2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1
>>
>> So, what could be making the files disappear?
>>
>
>
> Hi,
>
> (Reply from Amos Jeffries from http://bugs.squid-cache.org/sh
> ow_bug.cgi?id=4367#c2)
>
>> This is Squid *detecting* complete absence of disk files. Not causing
>> corruption.
>>
>> Please check if you have multiple Squid instances running and accessing
>> the
>> same cache_dir. That includes multiple workers using the same
>> ufs/aufs/diskd
>> cache_dir configuration line.
>>
>> Also whether swap.state for that cache_dir is being correctly and
>> completely
>> written out to disk on shutdown or restart. Using an outdated swap.state
>> file can also lead to these warnings.
>>
>
> The last paragraph explains your issue. The signal 6 (abort) forces Squid
> worker to terminate immediately (to avoid all required shutdown procedures)
> and leave core dump. You can find a reason for abort in cache.log.
>
>
> Garri
>

Hi Garri,

So, checking, I don't see swap.state being written to disk and there is no
core dump either.
There is no directive in my squid.conf to suppress the two.


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161217/86e4ea5b/attachment.htm>

From odhiambo at gmail.com  Sat Dec 17 13:40:23 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Sat, 17 Dec 2016 16:40:23 +0300
Subject: [squid-users] Missing cache files
In-Reply-To: <39653388-5581-657c-7c44-9b961e8f39b7@gmail.com>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <39653388-5581-657c-7c44-9b961e8f39b7@gmail.com>
Message-ID: <CAAdA2WNSTQBo=JAE1hWTcq+rGp7REMx8YaLRxTe0Drbg4xrdjg@mail.gmail.com>

True. Sometimes you search, but the clue isn't obvious :-)


On 17 December 2016 at 15:06, Yuri Voinov <yvoinov at gmail.com> wrote:

> Man, this question has been answered a million times. Use the search.
>
> 17.12.2016 16:41, Odhiambo Washington ?????:
>
> Hi,
>
> I keep seeing something that I think is odd. Squid has been exiting on
> signal 6, and I keep seeing this:
>
> root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
> 2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
> 2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
> 2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
> 2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
> 2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1
>
> So, what could be making the files disappear?
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
> --
> Cats - delicious. You just do not know how to cook them.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161217/ade9a48d/attachment.htm>

From garryd at comnet.uz  Sat Dec 17 14:31:02 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Sat, 17 Dec 2016 19:31:02 +0500
Subject: [squid-users] Missing cache files
In-Reply-To: <CAAdA2WPhCUusnqFN=mheAenCsuxj5TfU-ssWBjwip1Fmsts6vw@mail.gmail.com>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <0a9b80f91fa7363c0addc0ae3f5d231a@comnet.uz>
 <CAAdA2WPhCUusnqFN=mheAenCsuxj5TfU-ssWBjwip1Fmsts6vw@mail.gmail.com>
Message-ID: <d9309fc75a32b6e1a623e6dddde45e77@comnet.uz>

On 2016-12-17 18:39, Odhiambo Washington wrote:
>>> Also whether swap.state for that cache_dir is being correctly and
>>> completely
>>> written out to disk on shutdown or restart. Using an outdated
>>> swap.state
>>> file can also lead to these warnings.
>> 
>> The last paragraph explains your issue. The signal 6 (abort) forces
>> Squid worker to terminate immediately (to avoid all required
>> shutdown procedures) and leave core dump. You can find a reason for
>> abort in cache.log.
>> 
>> Garri
> 
> Hi Garri,
> 
> So, checking, I don't see swap.state being written to disk and there
> is no core dump either.

swap.state description [1]:
         This index file holds
	the metadata of objects saved on disk.  It is used to rebuild
	the cache during startup.  Normally this file resides in each
	'cache_dir' directory, but you may specify an alternate
	pathname here.

You can learn how to get core dump on wiki [2].


> There is no directive in my squid.conf to suppress the two.

What do you mean?

AIUI, your Squid instance faced unexpected event and initiated abort. 
Abort produces core dump which could be useful for developers to 
investigate unexpected event. As a side effect of abort, swap.state file 
was not updated correctly. The errors you see in cache.log are harmless 
and just confirm that swap.state and cache_dir objects are not 
synchronized due to abort.

You should concentrate on an event which led to abort. Usually, Squid 
inform about unexpected event in cache.log. Find the lines before 
'Starting Squid Cache version'.


[1] http://www.squid-cache.org/Doc/config/cache_swap_state/
[2] 
http://wiki.squid-cache.org/SquidFaq/BugReporting#crashes_and_core_dumps


Garri


From squid3 at treenet.co.nz  Sat Dec 17 14:37:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Dec 2016 03:37:32 +1300
Subject: [squid-users] cipher log
In-Reply-To: <20161217132911.065DD1200B8@fleegle.mixmin.net>
References: <20161217132911.065DD1200B8@fleegle.mixmin.net>
Message-ID: <bd6eecb8-ed99-5a3e-3131-59b6c5d16596@treenet.co.nz>

On 18/12/2016 2:29 a.m., piequiex wrote:
> ssl-bump enabled, I would like to log ciphers. Is it possible?
> 

Only with Squid-4. See the log documentation:
 <http://www.squid-cache.org/Doc/config/logformat/>

Amos


From squid3 at treenet.co.nz  Sat Dec 17 14:51:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Dec 2016 03:51:54 +1300
Subject: [squid-users] Squid Websocket Issue
In-Reply-To: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
References: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
Message-ID: <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>

On 17/12/2016 10:16 p.m., Hardik Dangar wrote:
> Here is some information about my squid version,
> 
> Squid Cache: Version 3.5.22-20161115-r14113
<snip>
> Now the issue is whenever someone requests a page which contains web socket
> requests response is always bad request.
> Here is an example,
> 
> Request URL:wss://w4.web.whatsapp.com/ws
> Request Method:GET
> Status Code:400 Bad Request
> 

Squid does not yet support using Upgrade for "websocket" protocol,


> Request Headers
> #################
> Connection:Upgrade
...
> Upgrade:websocket
...
> 
> My question is how we can work with web socket requests in squid or if not
> by pass them squid. My squid instance is in interception mode and requests
> are intercepted at instance via iptables and forwarded to squid using below
> rules,

You need to prevent these transactions from being bump'ed. If you want
that protocol to work they need to be splice'd by your ssl_bump rules.
How you determine which ones is a bit of a problem.

Amos



From squid3 at treenet.co.nz  Sat Dec 17 16:04:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Dec 2016 05:04:13 +1300
Subject: [squid-users] [squid-announce] Squid 4.0.17 beta is available
Message-ID: <836ad21b-4249-dc71-a6ef-bc775f06551d@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.17 release!


This release is a security and bug fix release resolving several issues
found in the prior Squid releases.


The major changes to be aware of:

* SQUID-2016:10 Information disclosure in Collapsed Forwarding
 <http://www.squid-cache.org/Advisories/SQUID-2016_10.txt>

This problem allows a remote attacker to discover private and sensitive
information about another clients browsing session. Potentially
including credentials which allow access to further sensitive resources.

This problem only affects Squid configured to use the Collapsed
Forwarding feature. It is of particular importance for HTTPS
reverse-proxy sites with Collapsed Forwarding.

This problem is present on all 3.5 releases, though 3.5.22 is hit worst
due to the collapsed revalidation extension increasing the scope of
traffic which can be collapsed.


* SQUID-2016:11 Information disclosure in HTTP Request processing
 <http://www.squid-cache.org/Advisories/SQUID-2016_11.txt>

This problem allows a remote attacker to discover private and sensitive
information about another clients browsing session. Potentially
including credentials which allow access to further sensitive resources.

This vulnerability is present in all Squid-3.1 and later versions. The
only known workaround is to prevent caching entirely, which is far from
ideal.


* TLS: Support tunneling of bumped non-HTTP traffic

Previously, the use of "on_unsupported_protocol tunnel" resulted in
encrypted HTTP 400 (Bad Request) messages sent to clients that do not
speak HTTP(S). Such as Skype groups, which appear to use TLS-encrypted
MSNP protocol instead of HTTPS.

This Squid allows admins using SslBump to tunnel Skype groups and
similar non-HTTP traffic bytes via "on_unsupported_protocol tunnel all".



 All users of Squid-4.x are urged to upgrade to this release as
soon as possible.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Sat Dec 17 16:04:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Dec 2016 05:04:19 +1300
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2016:10 -
 Information disclosure in Collapsed Forwarding
Message-ID: <81d5db94-2b35-c178-4d3c-b8413a2e1999@treenet.co.nz>

__________________________________________________________________

    Squid Proxy Cache Security Update Advisory SQUID-2016:10
__________________________________________________________________

Advisory ID:        SQUID-2016:10
Date:               Dec 16, 2016
Summary:            Information disclosure
                    in Collapsed Forwarding.
Affected versions:  Squid 3.5 -> 3.5.22
                    Squid 4.0 -> 4.0.16
Fixed in version:   Squid 4.0.17, 3.5.23
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_10.txt
__________________________________________________________________

Problem Description:

 Due to incorrect comparsion of request headers Squid can deliver
 responses containing private data to clients it should not have
 reached.

__________________________________________________________________

Severity:

 This problem allows a remote attacker to discover private and
 sensitive information about another clients browsing session.
 Potentially including credentials which allow access to further
 sensitive resources.

 This problem only affects Squid configured to use the Collapsed
 Forwarding feature.

 It is of particular importance for HTTPS reverse-proxy sites
 with Collapsed Forwarding.

__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid version 3.5.23 and 4.0.17.

 In addition, patches addressing this problem can be found in our
 patch archives:

Squid 3.5 (excluding 3.5.22):
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/SQUID-2016_10_a.patch>

Squid 3.5.22:
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14127.patch>

Squid 4.0:
 <http://www.squid-cache.org/Versions/v4/changesets/squid-4-14956.patch>

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

 Squid-2.x have not been tested.


 The following command can be used to determine if Squid-3 or
 later have collapsed_forwarding in squid.conf:

  (squid -k parse 2>&1) | grep collapsed_forwarding


 All Squid-3.x versions without collapsed_forwarding configured
 are not vulnerable.

 All Squid-3.5 versions with 'collapsed_forwarding off'
 configured are not vulnerable.

 All Squid-3.5 versions up to and including Squid-3.5.22 with
 'collapsed_forwarding on' configured are vulnerable.

 All Squid-4.0 versions without collapsed_forwarding configured
 are not vulnerable.

 All Squid-4.0 versions with 'collapsed_forwarding off'
 configured are not vulnerable.

 All Squid-4.0 versions up to and including Squid-4.0.16 with
 'collapsed_forwarding on' configured are vulnerable.

__________________________________________________________________

Workaround:

 Remove all uses of 'collapsed_forwarding' from squid.conf and
 included sub-files.

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If your install and build Squid from the original Squid sources
 then the squid-users at lists.squid-cache.org mailing list is your
 primary support point. For subscription details see
 <http://www.squid-cache.org/Support/mailing-lists.html>.

 For reporting of non-security bugs in the latest STABLE release
 the squid bugzilla database should be used
 <http://bugs.squid-cache.org/>.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at lists.squid-cache.org mailing list. It's a closed
 list (though anyone can post) and security related bug reports
 are treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 This issue was reported by Felix Hassert from Sevenval
 Technologies GmbH.

 Fixed by Eduard Bagdasaryan from Measurement Factory.

__________________________________________________________________

Revision history:

 2016-11-28 17:28:43 UTC Initial Report
 2016-12-16 18:37:00 UTC Packages Released
__________________________________________________________________
END

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Sat Dec 17 16:04:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Dec 2016 05:04:58 +1300
Subject: [squid-users] [squid-announce] Squid 3.5.23 is available
Message-ID: <6d7c243b-a7dc-0f21-f1c8-7a23300c9b75@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.5.23 release!


This release is a security and bug fix release resolving several issues
found in the prior Squid releases.


The major changes to be aware of:

* SQUID-2016:10 Information disclosure in Collapsed Forwarding
 <http://www.squid-cache.org/Advisories/SQUID-2016_10.txt>

This problem allows a remote attacker to discover private and sensitive
information about another clients browsing session. Potentially
including credentials which allow access to further sensitive resources.

This problem only affects Squid configured to use the Collapsed
Forwarding feature. It is of particular importance for HTTPS
reverse-proxy sites with Collapsed Forwarding.

This problem is present on all 3.5 releases, though 3.5.22 is hit worst
due to the collapsed revalidation extension increasing the scope of
traffic which can be collapsed.


* SQUID-2016:11 Information disclosure in HTTP Request processing
 <http://www.squid-cache.org/Advisories/SQUID-2016_11.txt>

This problem allows a remote attacker to discover private and sensitive
information about another clients browsing session. Potentially
including credentials which allow access to further sensitive resources.

This vulnerability is present in all Squid-3.1 and later versions. The
only known workaround is to prevent caching entirely, which is far from
ideal.


* Bug #4169: HIT marked as MISS when If-None-Match does not match
* Bug #3940: Host verify failures MISS when they should be HIT
* Bug #3533: Cache still valid after HTTP/1.1 303 See Other
* Bug #2258: bypassing cache but not destroying cache entry

These bugs all share a common thread of reducing cache efficiency. This
Squid will now leave existing cache content in place for use unless the
new client response is able to be shared with other clients. Some of
these bugs are only partially fixed so further improvements may be possible.


* HTTP/1.1: make Vary:* objects cacheable

Under RFC 2616 responses containing "Vary: *" header were not cachable.
That requirement has been loosened by RFC 7231 and Squid is now able to
cache these responses.


* ssl::server_name ACL badly broken since inception

The original server_name code mishandled all SNI checks and some rare
host checks. This was most visible with the reports that the
ssl::server_name ACL tests would fail where the equivalent regex ACL
test would behave differently, usually by matching. Or in situations
where neither would match despite the value appearing to be available.


* TLS: Make key= before cert= an error instead of quietly hiding the issue

Previous versions of Squid would accept the TLS/SSL key= parameter being
configured first before cert= parameter. But would then silently discard
the key settings when loading the cert file. This would lead to
unexpected behaviour or obscure 'permission' errors.

This release will now produce a FATAL error and halt if configured with
a key= parameter before its matched cert= parameter.



 All users of Squid-3 are urged to upgrade to this release as
soon as possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Sat Dec 17 16:05:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Dec 2016 05:05:09 +1300
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2016:11 -
 Information disclosure in HTTP Request processing
Message-ID: <b7ad193e-b769-432d-bf47-2dfc35c8c133@treenet.co.nz>

__________________________________________________________________

    Squid Proxy Cache Security Update Advisory SQUID-2016:11
__________________________________________________________________

Advisory ID:        SQUID-2016:11
Date:               Dec 16, 2016
Summary:            Information disclosure
                    in HTTP Request processing.
Affected versions:  Squid 2.6 -> 2.7.STABLE9
                    Squid 3.1 -> 3.5.22
                    Squid 4.0 -> 4.0.16
Fixed in version:   Squid 4.0.17, 3.5.23
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_11.txt
__________________________________________________________________

Problem Description:

 Due to incorrect HTTP conditional request handling Squid can
 deliver responses containing private data to clients it should
 not have reached.

__________________________________________________________________

Severity:

 This problem allows a remote attacker to discover private and
 sensitive information about another clients browsing session.
 Potentially including credentials which allow access to further
 sensitive resources.

__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid version 3.5.23 and 4.0.17.

 In addition, patches addressing this problem can be found in our
 patch archives:

Squid 3.1:
 <http://www.squid-cache.org/Versions/v3/3.1/changesets/SQUID-2016_11.patch>

Squid 3.2:
 <http://www.squid-cache.org/Versions/v3/3.2/changesets/SQUID-2016_11.patch>

Squid 3.3:
 <http://www.squid-cache.org/Versions/v3/3.3/changesets/SQUID-2016_11.patch>

Squid 3.4:
 <http://www.squid-cache.org/Versions/v3/3.4/changesets/SQUID-2016_11.patch>

Squid 3.5:
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/SQUID-2016_11.patch>

Squid 4.0:
 <http://www.squid-cache.org/Versions/v4/changesets/SQUID-2016_11.patch>

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

 All Squid-2.x versions are not vulnerable.

 All Squid-3.0 are not vulnerable.

 All Squid-3.1 versions up to and including 3.1.9 are not
 vulnerable.

 All Squid-3.1 versions 3.1.10 and later are vulnerable.

 Squid-3.2.0.1 and 3.2.0.2 are not vulnerable.

 All Squid-3.2 versions 3.2.0.3 and later are vulnerable.

 All Squid-3.3 versions are vulnerable.

 All Squid-3.4 versions are vulnerable.

 All Squid-3.5 versions up to and including Squid-3.5.22 are
 vulnerable.

 All Squid-4.0 versions up to and including Squid-4.0.16 are
 vulnerable.

__________________________________________________________________

Workaround:

 The only workaround known is to disable caching, including
 memory cache. In squid.conf set:

   cache deny all
   cache_mem 0

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If your install and build Squid from the original Squid sources
 then the squid-users at lists.squid-cache.org mailing list is your
 primary support point. For subscription details see
 <http://www.squid-cache.org/Support/mailing-lists.html>.

 For reporting of non-security bugs in the latest STABLE release
 the squid bugzilla database should be used
 <http://bugs.squid-cache.org/>.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at lists.squid-cache.org mailing list. It's a closed
 list (though anyone can post) and security related bug reports
 are treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 This issue was reported by Saulius Lapinskas from Lithuanian
 State Social Insurance Fund Board.

 Fixed by Garri Djavadyan from iPlus LLC (Comnet ISP).

__________________________________________________________________

Revision history:

 2014-12-30 12:44:32 UTC Initial Report
 2016-12-16 18:37:00 UTC Packages Released
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From creditu at eml.cc  Sun Dec 18 19:13:35 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Sun, 18 Dec 2016 12:13:35 -0700
Subject: [squid-users] sslpassword_program
Message-ID: <1482088415.4018167.822848113.09A453E0@webmail.messagingengine.com>

I'm having trouble getting the sslpassword_program working for an
encrypted key.  Config looks like this:
 
sslpassword_program /usr/local/bin/pass.sh 
https_port 10.10.10.1:443 accel vhost cert=/etc/squid/www.crt
key=/etc/squid/private.key

On start, cache log states "Ignoring https_port 10.10.10.1:443 due to
SSL initialization failure."
On stop, console states "Failed to acquire SSL private key
'/etc/squid/private.key': error:0200100D:system library:fopen:Permission
denied"

Removing the passphrase from the private key, squid starts normally. 
Permissions on the encrypted and non-encrypted keys are the same.  I
also tried putting the pass.sh program in /bin.  The pass.sh program
looks like this:
#!/bin/sh
echo "testing"

The hash of the private key modulus and the certificate modulus match as
well.

Am I missing something? This is on squid 3.1.


From michael.pelletier at palmbeachschools.org  Sun Dec 18 20:21:07 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Sun, 18 Dec 2016 15:21:07 -0500
Subject: [squid-users] sslpassword_program
In-Reply-To: <1482088415.4018167.822848113.09A453E0@webmail.messagingengine.com>
References: <1482088415.4018167.822848113.09A453E0@webmail.messagingengine.com>
Message-ID: <CAEnCSG5N7fXNjwSHq7GKvcCtJGpM8Bv0kUOfeFEFcEvacNUGVQ@mail.gmail.com>

Check your file permissions on the key.

On Dec 18, 2016 2:13 PM, <creditu at eml.cc> wrote:

> I'm having trouble getting the sslpassword_program working for an
> encrypted key.  Config looks like this:
>
> sslpassword_program /usr/local/bin/pass.sh
> https_port 10.10.10.1:443 accel vhost cert=/etc/squid/www.crt
> key=/etc/squid/private.key
>
> On start, cache log states "Ignoring https_port 10.10.10.1:443 due to
> SSL initialization failure."
> On stop, console states "Failed to acquire SSL private key
> '/etc/squid/private.key': error:0200100D:system library:fopen:Permission
> denied"
>
> Removing the passphrase from the private key, squid starts normally.
> Permissions on the encrypted and non-encrypted keys are the same.  I
> also tried putting the pass.sh program in /bin.  The pass.sh program
> looks like this:
> #!/bin/sh
> echo "testing"
>
> The hash of the private key modulus and the certificate modulus match as
> well.
>
> Am I missing something? This is on squid 3.1.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161218/9477f361/attachment.htm>

From eliezer at ngtech.co.il  Sun Dec 18 22:25:47 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 19 Dec 2016 00:25:47 +0200
Subject: [squid-users] squid.conf blocking live video stream
In-Reply-To: <CADoG9xmtUhG38Wy5bYsE54oQsrttCiX=XOHWQYXiDHj2ORiSGw@mail.gmail.com>
References: <CADoG9xmtUhG38Wy5bYsE54oQsrttCiX=XOHWQYXiDHj2ORiSGw@mail.gmail.com>
Message-ID: <008e01d2597d$ae7409b0$0b5c1d10$@ngtech.co.il>

Hey Robert,

Can you be more specific?
?Not working? can depend on couple things and on the nature of the
streaming system.
I know that many streaming sites do work under transparent squid so it?s
not really well understood what is not working from the spectrum of options.
Can you give examples for streaming sites that do work and others that do
not?
The first that pops in my mind to test it would be:
https://www.youtube.com/
https://www.crunchyroll.com/
https://rutube.ru/
And many others that are mentioned at:
http://www.unveiltech.com/indexsquidvideobooster.php (under Smart Cache)

And take Amos suggestion about restricting the headers more selectively.
Depends on your system policy you would be able to find that for most sites
you won?t have any issues letting any headers pass but for selective sites
you would want to take another policy that would be to block in general and
leaving aside the specific headers ?allowed? approach.

Also, have you tried to disable the virus scan to verify if it?s the
culprit for the streaming issue?

Please give one example so I and maybe others would be able to grasp the
issue in some way.

Thanks,
Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Robert Watson
Sent: Saturday, December 17, 2016 7:00 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid.conf blocking live video stream

Sorry if this shows up twice on the mailing list...
I've setup a transparent proxy squid v3.5.22 on a x86_64 Arch Linux server.
The transparent proxy is working fine for web page caching but live video
isn't getting through.  I thought it was a netfilter issue but bypassing the
proxy fixes this issue.

acl localnet src 10.20.0.0/16 <http://10.20.0.0/16> 	# RFC1918 possible
internal network
acl SSL_ports port 443		# https
acl Safe_ports port 80		# http
acl Safe_ports port 554	# rtsp
acl Safe_ports port 1935	# rtmp
acl Safe_ports port 21		# ftp
acl Safe_ports port 443	# https
acl Safe_ports port 1025-65535  # unregistered ports 
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
http_access allow localnet
http_access allow localhost
http_access deny all
visible_hostname server.ourhome.net <http://server.ourhome.net> 
http_port 10.20.30.1:3128 <http://10.20.30.1:3128>  intercept
disable-pmtu-discovery=transparent
http_port 127.0.0.0:8181 <http://127.0.0.0:8181> 
coredump_dir /var/cache/squid
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320
#
# Anonymous Proxy settings
include /etc/squid/extra/anonymous.conf
#
# Virus scanning via C-ICAP
#
include /etc/squid/extra/c-icap.conf
#

By the process of elimination I've narrowed it down to the anonymous proxy
settings...
anonymous.conf

forwarded_for off
request_header_access Allow allow all
request_header_access Authorization allow all
request_header_access WWW-Authenticate allow all
request_header_access Proxy-Authorization allow all
request_header_access Proxy-Authenticate allow all
request_header_access Cache-Control allow all
request_header_access Content-Encoding allow all
request_header_access Content-Length allow all
request_header_access Content-Type allow all
request_header_access Date allow all
request_header_access Expires allow all
request_header_access Host allow all
request_header_access If-Modified-Since allow all
request_header_access Last-Modified allow all
request_header_access Location allow all
request_header_access Pragma allow all
request_header_access Accept allow all
request_header_access Accept-Charset allow all
request_header_access Accept-Encoding allow all
request_header_access Accept-Language allow all
request_header_access Content-Language allow all
request_header_access Mime-Version allow all
request_header_access Retry-After allow all
request_header_access Title allow all
request_header_access Connection allow all
request_header_access Proxy-Connection allow all
request_header_access User-Agent allow all
request_header_access Cookie allow all
request_header_access All deny all

could someone please tell me what request_header_access I need to all, or
how to further trouble shoot this configuration?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 68721 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/b27b303d/attachment.bin>

From eliezer at ngtech.co.il  Sun Dec 18 22:38:38 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 19 Dec 2016 00:38:38 +0200
Subject: [squid-users] Missing cache files
In-Reply-To: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
Message-ID: <009d01d2597f$79da3d30$6d8eb790$@ngtech.co.il>

Can you give more details on the setup?.. squid.conf.
And cache.log dumps.
Files are not usually disappearing but it?s not clear who erased them.
If you do not have a swap file at /opt/squid-3.5/var/cache/ then you should
ask yourself how squid has started at all.

Please fill up the missing pieces,
Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Odhiambo Washington
Sent: Saturday, December 17, 2016 12:41 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Missing cache files

Hi,

I keep seeing something that I think is odd. Squid has been exiting on
signal 6, and I keep seeing this:

root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1

So, what could be making the files disappear?


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 64345 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/ad3bf7c3/attachment.bin>

From hardikdangar+squid at gmail.com  Sun Dec 18 23:14:39 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Mon, 19 Dec 2016 04:44:39 +0530
Subject: [squid-users] Squid Websocket Issue
In-Reply-To: <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>
References: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
 <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>
Message-ID: <CA+sSnVZYcQkvA=-bBVSuQtoXeYxomL5Ca51cw4ax0dP3EUKF7g@mail.gmail.com>

can you give me one example please ?
like in the above example.
w4.web.whatsapp.com domain is fixed
are you suggesting i can create acl and by pass it to squid ?



On Sat, Dec 17, 2016 at 8:21 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 17/12/2016 10:16 p.m., Hardik Dangar wrote:
> > Here is some information about my squid version,
> >
> > Squid Cache: Version 3.5.22-20161115-r14113
> <snip>
> > Now the issue is whenever someone requests a page which contains web
> socket
> > requests response is always bad request.
> > Here is an example,
> >
> > Request URL:wss://w4.web.whatsapp.com/ws
> > Request Method:GET
> > Status Code:400 Bad Request
> >
>
> Squid does not yet support using Upgrade for "websocket" protocol,
>
>
> > Request Headers
> > #################
> > Connection:Upgrade
> ...
> > Upgrade:websocket
> ...
> >
> > My question is how we can work with web socket requests in squid or if
> not
> > by pass them squid. My squid instance is in interception mode and
> requests
> > are intercepted at instance via iptables and forwarded to squid using
> below
> > rules,
>
> You need to prevent these transactions from being bump'ed. If you want
> that protocol to work they need to be splice'd by your ssl_bump rules.
> How you determine which ones is a bit of a problem.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/17704a7e/attachment.htm>

From creditu at eml.cc  Mon Dec 19 04:59:37 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Sun, 18 Dec 2016 21:59:37 -0700
Subject: [squid-users] sslpassword_program
In-Reply-To: <CAEnCSG5N7fXNjwSHq7GKvcCtJGpM8Bv0kUOfeFEFcEvacNUGVQ@mail.gmail.com>
References: <1482088415.4018167.822848113.09A453E0@webmail.messagingengine.com>
 <CAEnCSG5N7fXNjwSHq7GKvcCtJGpM8Bv0kUOfeFEFcEvacNUGVQ@mail.gmail.com>
Message-ID: <1482123577.4142040.823185569.4201259E@webmail.messagingengine.com>


On Sun, Dec 18, 2016, at 01:21 PM, Michael Pelletier wrote:
> Check your file permissions on the key.
> 
> On Dec 18, 2016 2:13 PM, <creditu at eml.cc> wrote:
> 
> > I'm having trouble getting the sslpassword_program working for an
> > encrypted key.  Config looks like this:
> >
> > sslpassword_program /usr/local/bin/pass.sh
> > https_port 10.10.10.1:443 accel vhost cert=/etc/squid/www.crt
> > key=/etc/squid/private.key
> >
> > On start, cache log states "Ignoring https_port 10.10.10.1:443 due to
> > SSL initialization failure."
> > On stop, console states "Failed to acquire SSL private key
> > '/etc/squid/private.key': error:0200100D:system library:fopen:Permission
> > denied"
> >
> > Removing the passphrase from the private key, squid starts normally.
> > Permissions on the encrypted and non-encrypted keys are the same.  I
> > also tried putting the pass.sh program in /bin.  The pass.sh program
> > looks like this:
> > #!/bin/sh
> > echo "testing"
> >
> > The hash of the private key modulus and the certificate modulus match as
> > well.
> >
> > Am I missing something? This is on squid 3.1.
> > _______________________________________________

Checked the perms and they are identical as the private key that I
stripped the password out of.  They are also in the same directory.  The
one without a password works fine.  Also tried encrypting with des3
versus aes128 and that didn't make a difference either.   Gotta be
missing something.  The error points to a perms problem, but not seeing
how since everything is the same.  Also, added a line in the
sslpassword_program to touch a file to see if it got executed and it
didn't create the file. Additionally, ran the stat command on the 
/usr/local/bin/pass.sh after squid started up and the access time never
changes.  It seems like the shell script may not being executed for some
reason.  I'm able to launch the shell script from the command line and
it echos out the pass fine. 


From squid3 at treenet.co.nz  Mon Dec 19 06:24:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 19 Dec 2016 19:24:54 +1300
Subject: [squid-users] sslpassword_program
In-Reply-To: <1482123577.4142040.823185569.4201259E@webmail.messagingengine.com>
References: <1482088415.4018167.822848113.09A453E0@webmail.messagingengine.com>
 <CAEnCSG5N7fXNjwSHq7GKvcCtJGpM8Bv0kUOfeFEFcEvacNUGVQ@mail.gmail.com>
 <1482123577.4142040.823185569.4201259E@webmail.messagingengine.com>
Message-ID: <20921bd3-cbcd-e6f0-1788-abb7907f53ab@treenet.co.nz>

On 19/12/2016 5:59 p.m., creditu wrote:
> 
> On Sun, Dec 18, 2016, at 01:21 PM, Michael Pelletier wrote:
>> Check your file permissions on the key.
>>
>> On Dec 18, 2016 2:13 PM, creditu wrote:
>>
>>> I'm having trouble getting the sslpassword_program working for an
>>> encrypted key.  Config looks like this:
>>>
>>> sslpassword_program /usr/local/bin/pass.sh
>>> https_port 10.10.10.1:443 accel vhost cert=/etc/squid/www.crt
>>> key=/etc/squid/private.key
>>>
>>> On start, cache log states "Ignoring https_port 10.10.10.1:443 due to
>>> SSL initialization failure."
>>> On stop, console states "Failed to acquire SSL private key
>>> '/etc/squid/private.key': error:0200100D:system library:fopen:Permission
>>> denied"
>>>
>>> Removing the passphrase from the private key, squid starts normally.
>>> Permissions on the encrypted and non-encrypted keys are the same.  I
>>> also tried putting the pass.sh program in /bin.  The pass.sh program
>>> looks like this:
>>> #!/bin/sh
>>> echo "testing"
>>>
>>> The hash of the private key modulus and the certificate modulus match as
>>> well.
>>>
>>> Am I missing something? This is on squid 3.1.

If the ideas below don't help can you try an upgrade? there are a few
fixes in 3.2 and 3.3 related to that directive.

>>> _______________________________________________
> 
> Checked the perms and they are identical as the private key that I
> stripped the password out of.  They are also in the same directory.  The
> one without a password works fine.

The one without a password is being opened by OpenSSL directly.

The one with pssword is being opened in Squid oeprating context, which
should be root, but may also be the low-privilege proxy user at the time
the script is run.

So you need the key file to be readable by whichever of those privilege
contexts Squid is using at the time. (Sorry I can't be more precise, I'm
not sure myself which is used in 3.1).

If you have SELinux or AppArmour they may also be interferring with the
priviledged access.

The script itself needs either executable permissions set, or squid.conf
containing the full shell interpreter path as well as the script path.
 ie. "sslpassword_program /bin/sh /usr/local/bin/pass.sh"


>  Also tried encrypting with des3
> versus aes128 and that didn't make a difference either.   Gotta be
> missing something.

>  The error points to a perms problem, but not seeing
> how since everything is the same.

The error message says fopen() command is not permitted for whichever
user account is trying to access the .key file.
 It's not clear if that is fopen() of the .key file, or fopen() of the
pass.sh file before running it.

The way you describe the issues below hint to me that it is the
permission to access the script which is breaking things.


Also, those old Squid had some issues with processing errno at the wrong
times. So there is a small but non-zero chance that the error is
actually something else. :-(


>  Also, added a line in the
> sslpassword_program to touch a file to see if it got executed and it
> didn't create the file. Additionally, ran the stat command on the 
> /usr/local/bin/pass.sh after squid started up

FYI: That test only works if your filesystem has been configured to
record access times. Using such a setup with Squid will cause major
slowdown as cache related files and logs get accessed *a lot*. So is
typically disabled via fstab "noatime" settings if anyone with expertise
has tuned the proxy machine before you.


> and the access time never
> changes.  It seems like the shell script may not being executed for some
> reason.  I'm able to launch the shell script from the command line and
> it echos out the pass fine.

This kind of implies the file permission problem is for Squid to open
the script "file" before running whats inside.

Check /usr/local/bin/pass.sh ownership, executable rights, and
SELinux/AppArmour permissions (whichever is present on that achine).

Amos


From squid3 at treenet.co.nz  Mon Dec 19 06:51:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 19 Dec 2016 19:51:10 +1300
Subject: [squid-users] Squid Websocket Issue
In-Reply-To: <CA+sSnVZYcQkvA=-bBVSuQtoXeYxomL5Ca51cw4ax0dP3EUKF7g@mail.gmail.com>
References: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
 <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>
 <CA+sSnVZYcQkvA=-bBVSuQtoXeYxomL5Ca51cw4ax0dP3EUKF7g@mail.gmail.com>
Message-ID: <5990ba78-39ea-569a-29dd-409e4912f1a6@treenet.co.nz>

On 19/12/2016 12:14 p.m., Hardik Dangar wrote:
> can you give me one example please ?
> like in the above example.
> w4.web.whatsapp.com domain is fixed
> are you suggesting i can create acl and by pass it to squid ?
> 

You are the first person to ask about WhatsApp traffic.

These might be a useful starting point
<http://wiki.squid-cache.org/Features/SslPeekAndSplice#Configuration_Examples>

What the examples are doing for banks is what you want to do for WhatsApp.

The trick though will be figuring out how to splice *before* seeing what
type of HTTP request exists inside the tunnel. If you are lucky the app
will be using SNI.

Amos



From odhiambo at gmail.com  Mon Dec 19 08:11:06 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Mon, 19 Dec 2016 11:11:06 +0300
Subject: [squid-users] Missing cache files
In-Reply-To: <009d01d2597f$79da3d30$6d8eb790$@ngtech.co.il>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <009d01d2597f$79da3d30$6d8eb790$@ngtech.co.il>
Message-ID: <CAAdA2WMtAx-sOVQEyCyEshO+tZh4bRyJQtyXrGk_Bzrhxff--g@mail.gmail.com>

Hi Eliezer,

I have put the files on this link: http://bit.ly/2h1bzqp


On 19 December 2016 at 01:38, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:

> Can you give more details on the setup?.. squid.conf.
> And cache.log dumps.
> Files are not usually disappearing but it?s not clear who erased them.
> If you do not have a swap file at /opt/squid-3.5/var/cache/ then you should
> ask yourself how squid has started at all.
>
> Please fill up the missing pieces,
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Odhiambo Washington
> Sent: Saturday, December 17, 2016 12:41 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Missing cache files
>
> Hi,
>
> I keep seeing something that I think is odd. Squid has been exiting on
> signal 6, and I keep seeing this:
>
> root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
> 2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
> 2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
> 2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
> 2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
> 2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1
>
> So, what could be making the files disappear?
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/6ccc9045/attachment.htm>

From eliezer at ngtech.co.il  Mon Dec 19 11:10:16 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 19 Dec 2016 13:10:16 +0200
Subject: [squid-users] Missing cache files
In-Reply-To: <CAAdA2WMtAx-sOVQEyCyEshO+tZh4bRyJQtyXrGk_Bzrhxff--g@mail.gmail.com>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <009d01d2597f$79da3d30$6d8eb790$@ngtech.co.il>
 <CAAdA2WMtAx-sOVQEyCyEshO+tZh4bRyJQtyXrGk_Bzrhxff--g@mail.gmail.com>
Message-ID: <00e801d259e8$7a41e7f0$6ec5b7d0$@ngtech.co.il>

The file:
http://gw.crownkenya.com/~wash/3.5.22/cache.log.txt

isn't accessible.
Also missing details like OS version and other things.
It seems like a very simple setup and the first thing to check is permissions to the whole directory tree:
/opt/squid-3.5/var/cache

Please add the output of:
# ls -la /opt/squid-3.5/var/cache/

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Odhiambo Washington
Sent: Monday, December 19, 2016 10:11 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Missing cache files

Hi Eliezer,

I have put the files on this link: http://bit.ly/2h1bzqp


On 19 December 2016 at 01:38, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
Can you give more details on the setup?.. squid.conf.
And cache.log dumps.
Files are not usually disappearing but it?s not clear who erased them.
If you do not have a swap file at /opt/squid-3.5/var/cache/ then you should
ask yourself how squid has started at all.

Please fill up the missing pieces,
Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Odhiambo Washington
Sent: Saturday, December 17, 2016 12:41 PM
To: mailto:squid-users at lists.squid-cache.org
Subject: [squid-users] Missing cache files

Hi,

I keep seeing something that I think is odd. Squid has been exiting on
signal 6, and I keep seeing this:

root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1

So, what could be making the files disappear?


--
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."




-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."



From noc at forceline.net  Mon Dec 19 11:34:19 2016
From: noc at forceline.net (noc at forceline.net)
Date: Mon, 19 Dec 2016 14:34:19 +0300
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
	Kill process (squid)
Message-ID: <024e01d259eb$d6ee3e10$84caba30$@net>


Anybody can help?
Maby I need to change mailing list?

--
Sergey

> -----Original Message-----
> From: noc at forceline.net [mailto:noc at forceline.net]
> Sent: Wednesday, December 14, 2016 2:40 PM
> To: 'squid-users at lists.squid-cache.org'
> Subject: Crash: every 1-2 hour: kernel: Out of memory: Kill process
> (squid)
> 
> 
> Hello. I wrote earlier in wrong location:
> http://bugs.squid-cache.org/show_bug.cgi?id=4647
> 
> > Squid eats all RAM, then eats all swap in a hour and killed by
> kernel.
> >I was try to turn off cache, change squid version, change some
> configuration parameters by this guide http://wiki.squid-
> cache.org/SquidFaq/SquidMemory except malloc, but nothing helps.
> 
> I made some config changes in accordance with the advice of Amos
> Jeffries (via on). But it does not help.
> This trouble somehow linked with https.
> If wccp redirects only 80 port - works fine.
>   wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority =
> 231 ports = 80
> If wccp redirects 443 too - then squid overflows and killed by kernel
>   wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority =
> 231 ports = 80,443
> 
> ---Before it died (HTTPS on):
> Mem:  16291720k total, 16125288k used,   166432k free,      540k
> buffers
> Swap:  8216568k total,  8112628k used,   103940k free,    27112k cached
>   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
> 30858 squid     20   0 22.7g  14g 3612 S  8.0 94.6  14:50.82 squid
> 
> 
> # free -m
>              total       used       free     shared    buffers
> cached
> Mem:         15909      15750        158          0          0
> 26
> -/+ buffers/cache:      15723        186
> Swap:         8023       7936         87
> 
> 
> Start Time:	Sat, 10 Dec 2016 07:52:50 GMT
> Current Time:	Sat, 10 Dec 2016 09:39:45 GMT
> 
> Connection information for squid:
> 	Number of clients accessing cache:	1305
> 	Number of HTTP requests received:	193434
> 	Number of ICP messages received:	0
> 	Number of ICP messages sent:	0
> 	Number of queued ICP replies:	0
> 	Number of HTCP messages received:	0
> 	Number of HTCP messages sent:	0
> 	Request failure ratio:	 0.00
> 	Average HTTP requests per minute since start:	1809.2
> 	Average ICP messages per minute since start:	0.0
> 	Select loop called: 4529796 times, 1.416 ms avg
> Cache information for squid:
> 	Hits as % of all requests:	5min: 0.0%, 60min: 0.0%
> 	Hits as % of bytes sent:	5min: 0.1%, 60min: -0.0%
> 	Memory hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
> 	Disk hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
> 	Storage Swap size:	82044 KB
> 	Storage Swap capacity:	80.1% used, 19.9% free
> 	Storage Mem size:	107876 KB
> 	Storage Mem capacity:	20.6% used, 79.4% free
> 	Mean Object Size:	29.54 KB
> 	Requests given to unlinkd:	9258
> Median Service Times (seconds)  5 min    60 min:
> 	HTTP Requests (All):   0.10857  0.04519
> 	Cache Misses:          0.01648  0.00678
> 	Cache Hits:            0.00000  0.00000
> 	Near Hits:             0.00000  0.00000
> 	Not-Modified Replies:  0.00000  0.00000
> 	DNS Lookups:           0.00860  0.00779
> 	ICP Queries:           0.00000  0.00000
> Resource usage for squid:
> 	UP Time:	6415.101 seconds
> 	CPU Time:	902.767 seconds
> 	CPU Usage:	14.07%
> 	CPU Usage, 5 minute avg:	15.97%
> 	CPU Usage, 60 minute avg:	13.96%
> 	Maximum Resident Size: 62241760 KB
> 	Page faults with physical i/o: 32647
> Memory accounted for:
> 	Total accounted:       1073388 KB
> 	memPoolAlloc calls:     12969
> 	memPoolFree calls:   35802441
> File descriptor usage for squid:
> 	Maximum number of file descriptors:   100000
> 	Largest file desc currently in use:   28744
> 	Number of file desc currently in use: 28738
> 	Files queued for open:                   0
> 	Available number of file descriptors: 71262
> 	Reserved number of file descriptors:   100
> 	Store Disk files open:                   0
> Internal Data Structures:
> 	 57337 StoreEntries
> 	 54560 StoreEntries with MemObjects
> 	    52 Hot Object Cache Items
> 	  2777 on-disk objects
> 
> ---after:
> /var/log/messages
> kernel: 11733 total pagecache pages
> kernel: 8957 pages in swap cache
> kernel: Swap cache stats: add 21118384, delete 21109427, find
> 12110273/12422740
> kernel: Free swap  = 0kB
> kernel: Total swap = 8216568kB
> kernel: 4194303 pages RAM
> kernel: 121373 pages reserved
> kernel: 11781 pages shared
> kernel: 4023631 pages non-shared
> ...omitted...
> kernel: Out of memory: Kill process 30858 (squid) score 954 or
> sacrifice child
> kernel: Killed process 30868, UID 23, (log_file_daemon) total-
> vm:26640kB, anon-rss:48kB, file-rss:512kB
> (squid-1): I don't handle this error well!
> Dec 10 12:44:27 localhost squid[30855]: Squid Parent: (squid-1) process
> 30858 exited due to signal 9 with status 0
> 
> 
> In attach all /var/log/messages output.
> Main task for the server is to block bad sites and bypass others on
> same IPs.
> Any ideas?
> 
> --
> Sergey


From odhiambo at gmail.com  Mon Dec 19 11:37:24 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Mon, 19 Dec 2016 14:37:24 +0300
Subject: [squid-users] Missing cache files
In-Reply-To: <00e801d259e8$7a41e7f0$6ec5b7d0$@ngtech.co.il>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <009d01d2597f$79da3d30$6d8eb790$@ngtech.co.il>
 <CAAdA2WMtAx-sOVQEyCyEshO+tZh4bRyJQtyXrGk_Bzrhxff--g@mail.gmail.com>
 <00e801d259e8$7a41e7f0$6ec5b7d0$@ngtech.co.il>
Message-ID: <CAAdA2WP3j6MY5QyJa9foR-EeJ-Bp6=oob3cc5ks+NFn3CSkoEg@mail.gmail.com>

Hi,

I have added details.txt and also fixed perms on cache.log

On 19 December 2016 at 14:10, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:

> The file:
> http://gw.crownkenya.com/~wash/3.5.22/cache.log.txt
>
> isn't accessible.
> Also missing details like OS version and other things.
> It seems like a very simple setup and the first thing to check is
> permissions to the whole directory tree:
> /opt/squid-3.5/var/cache
>
> Please add the output of:
> # ls -la /opt/squid-3.5/var/cache/
>
> Eliezer
>
> ----
> http://ngtech.co.il/lmgtfy/
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Odhiambo Washington
> Sent: Monday, December 19, 2016 10:11 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Missing cache files
>
> Hi Eliezer,
>
> I have put the files on this link: http://bit.ly/2h1bzqp
>
>
> On 19 December 2016 at 01:38, Eliezer Croitoru <mailto:
> eliezer at ngtech.co.il> wrote:
> Can you give more details on the setup?.. squid.conf.
> And cache.log dumps.
> Files are not usually disappearing but it?s not clear who erased them.
> If you do not have a swap file at /opt/squid-3.5/var/cache/ then you should
> ask yourself how squid has started at all.
>
> Please fill up the missing pieces,
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: mailto:eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org]
> On
> Behalf Of Odhiambo Washington
> Sent: Saturday, December 17, 2016 12:41 PM
> To: mailto:squid-users at lists.squid-cache.org
> Subject: [squid-users] Missing cache files
>
> Hi,
>
> I keep seeing something that I think is odd. Squid has been exiting on
> signal 6, and I keep seeing this:
>
> root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
> 2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
> 2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
> 2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
> 2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
> 2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file or
> directory
> 2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1
>
> So, what could be making the files disappear?
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
>
>
>
> --
> Best regards,
> Odhiambo WASHINGTON,
> Nairobi,KE
> +254 7 3200 0004/+254 7 2274 3223
> "Oh, the cruft."
>
>


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/11913b76/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Dec 19 11:39:50 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 19 Dec 2016 12:39:50 +0100
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
	Kill process (squid)
In-Reply-To: <024e01d259eb$d6ee3e10$84caba30$@net>
References: <024e01d259eb$d6ee3e10$84caba30$@net>
Message-ID: <201612191239.51098.Antony.Stone@squid.open.source.it>

On Monday 19 December 2016 at 12:34:19, noc at forceline.net wrote:

> Anybody can help?
> Maby I need to change mailing list?

Did you try the suggestions already made?

http://lists.squid-cache.org/pipermail/squid-users/2016-December/013777.html
http://lists.squid-cache.org/pipermail/squid-users/2016-December/013778.html
http://lists.squid-cache.org/pipermail/squid-users/2016-December/013780.html

Antony.

> > -----Original Message-----
> > From: noc at forceline.net [mailto:noc at forceline.net]
> > Sent: Wednesday, December 14, 2016 2:40 PM
> > To: 'squid-users at lists.squid-cache.org'
> > Subject: Crash: every 1-2 hour: kernel: Out of memory: Kill process
> > (squid)
> > 
> > 
> > Hello. I wrote earlier in wrong location:
> > http://bugs.squid-cache.org/show_bug.cgi?id=4647
> > 
> > > Squid eats all RAM, then eats all swap in a hour and killed by
> > 
> > kernel.
> > 
> > >I was try to turn off cache, change squid version, change some
> > 
> > configuration parameters by this guide http://wiki.squid-
> > cache.org/SquidFaq/SquidMemory except malloc, but nothing helps.
> > 
> > I made some config changes in accordance with the advice of Amos
> > Jeffries (via on). But it does not help.
> > This trouble somehow linked with https.
> > If wccp redirects only 80 port - works fine.
> > 
> >   wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority =
> > 
> > 231 ports = 80
> > If wccp redirects 443 too - then squid overflows and killed by kernel
> > 
> >   wccp2_service_info 70 protocol = tcp flags = dst_ip_hash priority =
> > 
> > 231 ports = 80,443
> > 
> > ---Before it died (HTTPS on):
> > Mem:  16291720k total, 16125288k used,   166432k free,      540k
> > buffers
> > Swap:  8216568k total,  8112628k used,   103940k free,    27112k cached
> > 
> >   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
> > 
> > 30858 squid     20   0 22.7g  14g 3612 S  8.0 94.6  14:50.82 squid
> > 
> > 
> > # free -m
> > 
> >              total       used       free     shared    buffers
> > 
> > cached
> > Mem:         15909      15750        158          0          0
> > 26
> > -/+ buffers/cache:      15723        186
> > Swap:         8023       7936         87
> > 
> > 
> > Start Time:	Sat, 10 Dec 2016 07:52:50 GMT
> > Current Time:	Sat, 10 Dec 2016 09:39:45 GMT
> > 
> > Connection information for squid:
> > 	Number of clients accessing cache:	1305
> > 	Number of HTTP requests received:	193434
> > 	Number of ICP messages received:	0
> > 	Number of ICP messages sent:	0
> > 	Number of queued ICP replies:	0
> > 	Number of HTCP messages received:	0
> > 	Number of HTCP messages sent:	0
> > 	Request failure ratio:	 0.00
> > 	Average HTTP requests per minute since start:	1809.2
> > 	Average ICP messages per minute since start:	0.0
> > 	Select loop called: 4529796 times, 1.416 ms avg
> > 
> > Cache information for squid:
> > 	Hits as % of all requests:	5min: 0.0%, 60min: 0.0%
> > 	Hits as % of bytes sent:	5min: 0.1%, 60min: -0.0%
> > 	Memory hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
> > 	Disk hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
> > 	Storage Swap size:	82044 KB
> > 	Storage Swap capacity:	80.1% used, 19.9% free
> > 	Storage Mem size:	107876 KB
> > 	Storage Mem capacity:	20.6% used, 79.4% free
> > 	Mean Object Size:	29.54 KB
> > 	Requests given to unlinkd:	9258
> > 
> > Median Service Times (seconds)  5 min    60 min:
> > 	HTTP Requests (All):   0.10857  0.04519
> > 	Cache Misses:          0.01648  0.00678
> > 	Cache Hits:            0.00000  0.00000
> > 	Near Hits:             0.00000  0.00000
> > 	Not-Modified Replies:  0.00000  0.00000
> > 	DNS Lookups:           0.00860  0.00779
> > 	ICP Queries:           0.00000  0.00000
> > 
> > Resource usage for squid:
> > 	UP Time:	6415.101 seconds
> > 	CPU Time:	902.767 seconds
> > 	CPU Usage:	14.07%
> > 	CPU Usage, 5 minute avg:	15.97%
> > 	CPU Usage, 60 minute avg:	13.96%
> > 	Maximum Resident Size: 62241760 KB
> > 	Page faults with physical i/o: 32647
> > 
> > Memory accounted for:
> > 	Total accounted:       1073388 KB
> > 	memPoolAlloc calls:     12969
> > 	memPoolFree calls:   35802441
> > 
> > File descriptor usage for squid:
> > 	Maximum number of file descriptors:   100000
> > 	Largest file desc currently in use:   28744
> > 	Number of file desc currently in use: 28738
> > 	Files queued for open:                   0
> > 	Available number of file descriptors: 71262
> > 	Reserved number of file descriptors:   100
> > 	Store Disk files open:                   0
> > 
> > Internal Data Structures:
> > 	 57337 StoreEntries
> > 	 54560 StoreEntries with MemObjects
> > 	 
> > 	    52 Hot Object Cache Items
> > 	  
> > 	  2777 on-disk objects
> > 
> > ---after:
> > /var/log/messages
> > kernel: 11733 total pagecache pages
> > kernel: 8957 pages in swap cache
> > kernel: Swap cache stats: add 21118384, delete 21109427, find
> > 12110273/12422740
> > kernel: Free swap  = 0kB
> > kernel: Total swap = 8216568kB
> > kernel: 4194303 pages RAM
> > kernel: 121373 pages reserved
> > kernel: 11781 pages shared
> > kernel: 4023631 pages non-shared
> > ...omitted...
> > kernel: Out of memory: Kill process 30858 (squid) score 954 or
> > sacrifice child
> > kernel: Killed process 30868, UID 23, (log_file_daemon) total-
> > vm:26640kB, anon-rss:48kB, file-rss:512kB
> > (squid-1): I don't handle this error well!
> > Dec 10 12:44:27 localhost squid[30855]: Squid Parent: (squid-1) process
> > 30858 exited due to signal 9 with status 0
> > 
> > 
> > In attach all /var/log/messages output.
> > Main task for the server is to block bad sites and bypass others on
> > same IPs.
> > Any ideas?
> > 
> > --
> > Sergey

-- 
What makes you think I know what I'm talking about?
I just have more O'Reilly books than most people.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From david at articatech.com  Mon Dec 19 11:44:35 2016
From: david at articatech.com (David Touzeau)
Date: Mon, 19 Dec 2016 12:44:35 +0100
Subject: [squid-users] cache_peer and PROXY protocol
Message-ID: <003701d259ed$45bc1140$d13433c0$@articatech.com>


Hi

Squid accept "Proxy protocol" in http_port, is there a chance to see  "PROXY
Protocol" supported in cache_peer if you need to link 2 squid ?

Best regards.





From noc at forceline.net  Mon Dec 19 11:57:18 2016
From: noc at forceline.net (noc at forceline.net)
Date: Mon, 19 Dec 2016 14:57:18 +0300
Subject: [squid-users] Crash: every 1-2 hour: kernel: Out of memory:
	Kill process (squid)
In-Reply-To: <78d8e7d3-c361-f610-59fd-85f3657cd326@treenet.co.nz>
References: <039901d255fe$d80cfe30$8826fa90$@net>
 <0a9501d25612$ad0483c0$070d8b40$@ngtech.co.il>
 <04d501d2562e$e56d5e00$b0481a00$@net>
 <78d8e7d3-c361-f610-59fd-85f3657cd326@treenet.co.nz>
Message-ID: <029601d259ef$1cfa0990$56ee1cb0$@net>

Oh sorry, I miss some replys.

>I think you still have a forwarding loop. Does the cisco WCCP send port
>443 connections from Squid to reach the Internet instead of sending them
>back into Squid.

interface TenGigabitEthernet0/2/0.501
 description for WCCP
 encapsulation dot1Q 501
 ip address 192.168.253.1 255.255.255.0
 no ip redirects
 no ip unreachables
 no ip proxy-arp
 ip nat inside
 ip wccp redirect exclude in

interface TenGigabitEthernet0/2/0.600
 description SQUID external IP
 encapsulation dot1Q 600
 ip address 1.1.1.65 255.255.255.192
 no ip redirects
 no ip proxy-arp
 ip wccp 70 redirect in

I'd change:
(config)# interface TenGigabitEthernet0/2/0.600
(config-subif)# no ip wccp 70 redirect in

Then restrat squid and wait for results.
I'll report.

--
Sergey


> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Amos Jeffries
> Sent: Thursday, December 15, 2016 7:52 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Crash: every 1-2 hour: kernel: Out of
> memory: Kill process (squid)
> 
> On 15/12/2016 6:24 a.m., noc at forceline.net wrote:
> > Eliezer, thanks for your reply. Guides:
> > http://wiki.squid-cache.org/Features/SslBump
> > http://wiki.squid-cache.org/Features/SslPeekAndSplice
> > https://habrahabr.ru/post/267851/  <-- Russian lang
> > https://habrahabr.ru/post/272733/  <-- Russian lang
> >
> >> First goes first change this: 13130:
> > Done, nothing changed. Squid died.
> >
> > Maby it will be work fine whith lower load even with https. But I
> don't
> > understand, why it killed by a kernel rather than just update memory
> by new
> > one.
> >
> > http://wiki.squid-cache.org/Features/SslBump
> >> Memory usage
> >>
> >>    /!\ Warning: Unlike the rest of this page at the time of writing,
> this
> > section applies to Squid-3.3 and possibly later code capable of
> dynamic SSL
> > certificate generation and origin server certificate mimicking. The
> current
> > section text is intended primarily for developers and early adopters
> facing
> > excessive memory consumption in certain SslBump environments. These
> notes
> > may be relocated elsewhere if a better location is found.
> >>
> >> Current documentation is specific to bump-server-first
> configurations.
> >
> > In attach server statistic.
> >
> 
> 
> I think you still have a forwarding loop. Does the cisco WCCP send port
> 443 connections from Squid to reach the Internet instead of sending
> them
> back into Squid.
> 
> The Via header will protect against HTTP messages looping, but the TLS
> handshake traffic has no such protection.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Mon Dec 19 12:20:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 20 Dec 2016 01:20:10 +1300
Subject: [squid-users] cache_peer and PROXY protocol
In-Reply-To: <003701d259ed$45bc1140$d13433c0$@articatech.com>
References: <003701d259ed$45bc1140$d13433c0$@articatech.com>
Message-ID: <efbe8143-c354-0924-4518-13d122cacaeb@treenet.co.nz>

On 20/12/2016 12:44 a.m., David Touzeau wrote:
> 
> Hi
> 
> Squid accept "Proxy protocol" in http_port, is there a chance to see  "PROXY
> Protocol" supported in cache_peer if you need to link 2 squid ?
> 

'a chance' only at this point unless somebody (you?) wants to sponsor
it. It is on my TODO list, way down under TLS improvements and HTTP/2
support - both big projects.

What is your use-case ?

Amos



From eliezer at ngtech.co.il  Mon Dec 19 13:06:25 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 19 Dec 2016 15:06:25 +0200
Subject: [squid-users] Missing cache files
In-Reply-To: <CAAdA2WP3j6MY5QyJa9foR-EeJ-Bp6=oob3cc5ks+NFn3CSkoEg@mail.gmail.com>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <009d01d2597f$79da3d30$6d8eb790$@ngtech.co.il>
 <CAAdA2WMtAx-sOVQEyCyEshO+tZh4bRyJQtyXrGk_Bzrhxff--g@mail.gmail.com>
 <00e801d259e8$7a41e7f0$6ec5b7d0$@ngtech.co.il>
 <CAAdA2WP3j6MY5QyJa9foR-EeJ-Bp6=oob3cc5ks+NFn3CSkoEg@mail.gmail.com>
Message-ID: <010201d259f8$b45422e0$1cfc68a0$@ngtech.co.il>

Did you noticed these errors:
FATAL: The ssl_crtd helpers are crashing too rapidly, need help!

Squid Cache (Version 3.5.23): Terminated abnormally.
CPU Usage: 63.837 seconds = 28.308 user + 35.529 sys
Maximum Resident Size: 171488 KB
Page faults with physical i/o: 154
2016/12/18 17:25:05| Set Current Directory to /opt/squid-3.5/var/logs/
2016/12/18 17:25:06| Starting Squid Cache version 3.5.23 for i386-unknown-freebsd9.3...
2016/12/18 17:25:06| Service Name: squid
2016/12/18 17:25:06| Process ID 2943
2016/12/18 17:25:06| Process Roles: master worker
2016/12/18 17:25:06| NOTICE: Could not increase the number of filedescriptors
2016/12/18 17:25:06| With 32768 file descriptors available
2016/12/18 17:25:06| Initializing IP Cache...
2016/12/18 17:25:06| DNS Socket created at [::], FD 10
2016/12/18 17:25:06| DNS Socket created at 0.0.0.0, FD 11
2016/12/18 17:25:06| Adding domain crownkenya.com from /etc/resolv.conf
2016/12/18 17:25:06| Adding nameserver 192.168.55.254 from /etc/resolv.conf
2016/12/18 17:25:06| helperOpenServers: Starting 5/15 'ssl_crtd' processes
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| helperOpenServers: Starting 5/10 'perl' processes
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
2016/12/18 17:25:11| Logfile: opening log stdio:/opt/squid-3.5/var/logs/access.log

????
And it's good to know you are running FreeBSD 9.3...(32 bit..)

You need to fix the issues with the helpers before anything else since these are blockers for squid to operate right.
The missing file is a side effect which happens at almost the same time.
I would have started with looking at the lines:
sslcrtd_program /opt/squid-3.5/libexec/ssl_crtd -s /opt/squid-3.5/ssl_db -M 4MB
store_id_program /usr/local/bin/perl /opt/squid-3.5/scripts/store-id.pl

And see what is causing this operation is not permitted.
It can be rights or another issue but you must resolve it.
And before diving hard into StoreID make sure your squid just runs fine with ssl bump.
Then jump into StoreID and feel free to share your wishes for this service..(caching youtube, Microsoft updates etc..)

Let me know if you need anything.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Odhiambo Washington [mailto:odhiambo at gmail.com] 
Sent: Monday, December 19, 2016 1:37 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Missing cache files

Hi,

I have added details.txt and also fixed perms on cache.log

On 19 December 2016 at 14:10, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
The file:
http://gw.crownkenya.com/~wash/3.5.22/cache.log.txt

isn't accessible.
Also missing details like OS version and other things.
It seems like a very simple setup and the first thing to check is permissions to the whole directory tree:
/opt/squid-3.5/var/cache

Please add the output of:
# ls -la /opt/squid-3.5/var/cache/

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Odhiambo Washington
Sent: Monday, December 19, 2016 10:11 AM
To: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Missing cache files

Hi Eliezer,

I have put the files on this link: http://bit.ly/2h1bzqp


On 19 December 2016 at 01:38, Eliezer Croitoru <mailto:mailto:eliezer at ngtech.co.il> wrote:
Can you give more details on the setup?.. squid.conf.
And cache.log dumps.
Files are not usually disappearing but it?s not clear who erased them.
If you do not have a swap file at /opt/squid-3.5/var/cache/ then you should
ask yourself how squid has started at all.

Please fill up the missing pieces,
Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:mailto:eliezer at ngtech.co.il


From: squid-users [mailto:mailto:mailto:mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Odhiambo Washington
Sent: Saturday, December 17, 2016 12:41 PM
To: mailto:mailto:squid-users at lists.squid-cache.org
Subject: [squid-users] Missing cache files

Hi,

I keep seeing something that I think is odd. Squid has been exiting on
signal 6, and I keep seeing this:

root at gw:/usr/local/openssl # tail -f /opt/squid-3.5/var/logs/cache.log
2016/12/17 13:38:32| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:38:32|    /opt/squid-3.5/var/cache/00/26/0000264D
2016/12/17 13:40:24| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:40:24|    /opt/squid-3.5/var/cache/00/3B/00003B56
2016/12/17 13:42:34| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:42:34|    /opt/squid-3.5/var/cache/00/6B/00006B0D
2016/12/17 13:43:36| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:43:36|    /opt/squid-3.5/var/cache/00/00/00000050
2016/12/17 13:44:25| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/12/17 13:44:25|    /opt/squid-3.5/var/cache/00/AF/0000AFF1

So, what could be making the files disappear?


--
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."




--
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."




-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."



From eliezer at ngtech.co.il  Mon Dec 19 13:10:43 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 19 Dec 2016 15:10:43 +0200
Subject: [squid-users] Squid Websocket Issue
In-Reply-To: <5990ba78-39ea-569a-29dd-409e4912f1a6@treenet.co.nz>
References: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
 <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>
 <CA+sSnVZYcQkvA=-bBVSuQtoXeYxomL5Ca51cw4ax0dP3EUKF7g@mail.gmail.com>
 <5990ba78-39ea-569a-29dd-409e4912f1a6@treenet.co.nz>
Message-ID: <010401d259f9$4dfcd630$e9f68290$@ngtech.co.il>

I can give a hint that once you see the request you can identify using an ICAP\ECAP services couple details about the request.
Basically I had a regex which allowed any what's app traffic to be spliced by the SNI domain name.
It should be something like "w[0-9]+\.web\.whatsapp\.com$" to match the required domains for whatsapp to be spliced.
If nobody will try it before me it's on my todo list for this release (3.5.23, 4.0.17).

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, December 19, 2016 8:51 AM
To: Hardik Dangar <hardikdangar+squid at gmail.com>
Cc: Squid Users <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid Websocket Issue

On 19/12/2016 12:14 p.m., Hardik Dangar wrote:
> can you give me one example please ?
> like in the above example.
> w4.web.whatsapp.com domain is fixed
> are you suggesting i can create acl and by pass it to squid ?
> 

You are the first person to ask about WhatsApp traffic.

These might be a useful starting point
<http://wiki.squid-cache.org/Features/SslPeekAndSplice#Configuration_Examples>

What the examples are doing for banks is what you want to do for WhatsApp.

The trick though will be figuring out how to splice *before* seeing what type of HTTP request exists inside the tunnel. If you are lucky the app will be using SNI.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From hardikdangar+squid at gmail.com  Mon Dec 19 13:16:59 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Mon, 19 Dec 2016 18:46:59 +0530
Subject: [squid-users] Squid Websocket Issue
In-Reply-To: <010401d259f9$4dfcd630$e9f68290$@ngtech.co.il>
References: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
 <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>
 <CA+sSnVZYcQkvA=-bBVSuQtoXeYxomL5Ca51cw4ax0dP3EUKF7g@mail.gmail.com>
 <5990ba78-39ea-569a-29dd-409e4912f1a6@treenet.co.nz>
 <010401d259f9$4dfcd630$e9f68290$@ngtech.co.il>
Message-ID: <CA+sSnVavKQR80XNvykdecMeB1feLwBMEP29Vm+Lxp3=U8-S1dg@mail.gmail.com>

Based on Amos's Answer,

acl serverIsws ssl::server_name .w0.whatsapp.com
acl serverIsws ssl::server_name .w1.whatsapp.com

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump !serverIsws all
ssl_bump splice all

will above work ?

Or should i splice first and bump all others later?

This is very interesting. I will definitely try this when i will reach
office.

On Mon, Dec 19, 2016 at 6:40 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> I can give a hint that once you see the request you can identify using an
> ICAP\ECAP services couple details about the request.
> Basically I had a regex which allowed any what's app traffic to be spliced
> by the SNI domain name.
> It should be something like "w[0-9]+\.web\.whatsapp\.com$" to match the
> required domains for whatsapp to be spliced.
> If nobody will try it before me it's on my todo list for this release
> (3.5.23, 4.0.17).
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Amos Jeffries
> Sent: Monday, December 19, 2016 8:51 AM
> To: Hardik Dangar <hardikdangar+squid at gmail.com>
> Cc: Squid Users <squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Squid Websocket Issue
>
> On 19/12/2016 12:14 p.m., Hardik Dangar wrote:
> > can you give me one example please ?
> > like in the above example.
> > w4.web.whatsapp.com domain is fixed
> > are you suggesting i can create acl and by pass it to squid ?
> >
>
> You are the first person to ask about WhatsApp traffic.
>
> These might be a useful starting point
> <http://wiki.squid-cache.org/Features/SslPeekAndSplice#
> Configuration_Examples>
>
> What the examples are doing for banks is what you want to do for WhatsApp.
>
> The trick though will be figuring out how to splice *before* seeing what
> type of HTTP request exists inside the tunnel. If you are lucky the app
> will be using SNI.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/db5c03e0/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Mon Dec 19 13:21:40 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Mon, 19 Dec 2016 10:21:40 -0300
Subject: [squid-users] 4.0.17 assert http->storeEntry()->objectLen() >=
	headers_sz
Message-ID: <ead1526a-70f0-2545-742e-e5c76a69c02a@cinbesa.com.br>


Hi guys, have been getting crashes with this message..

2016/12/19 10:00:06 kid1| assertion failed: client_side_reply.cc:1167: 
"http->storeEntry()->objectLen() >= headers_sz"


clean rockstore databases from 3 days ago
cache_dir rock /cache  135000 min-size=0 max-size=12288 slot-size=12288
cache_dir rock /cache2 135000 min-size=12289 max-size=65536
cache_dir rock /cache3 135000 min-size=65537 max-size=262144
cache_dir rock /cache4 135000 min-size=262145

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



From squid3 at treenet.co.nz  Mon Dec 19 13:30:38 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 20 Dec 2016 02:30:38 +1300
Subject: [squid-users] Missing cache files
In-Reply-To: <010201d259f8$b45422e0$1cfc68a0$@ngtech.co.il>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <009d01d2597f$79da3d30$6d8eb790$@ngtech.co.il>
 <CAAdA2WMtAx-sOVQEyCyEshO+tZh4bRyJQtyXrGk_Bzrhxff--g@mail.gmail.com>
 <00e801d259e8$7a41e7f0$6ec5b7d0$@ngtech.co.il>
 <CAAdA2WP3j6MY5QyJa9foR-EeJ-Bp6=oob3cc5ks+NFn3CSkoEg@mail.gmail.com>
 <010201d259f8$b45422e0$1cfc68a0$@ngtech.co.il>
Message-ID: <73eb4145-a443-ddb9-cb31-1eb8b1fde107@treenet.co.nz>

On 20/12/2016 2:06 a.m., Eliezer Croitoru wrote:
> Did you noticed these errors:
> FATAL: The ssl_crtd helpers are crashing too rapidly, need help!
> 

Unfortunately that helper does not have much debug to figure out why its
crashing. There are a couple of bug reports open about this crashing,
but only after its been running a while in some past execution.

The current workaround seems to be erasing the cert DB it uses and
re-generating it. Any help debugging that would be very welcome.


> Squid Cache (Version 3.5.23): Terminated abnormally.
> CPU Usage: 63.837 seconds = 28.308 user + 35.529 sys
> Maximum Resident Size: 171488 KB
> Page faults with physical i/o: 154
> 2016/12/18 17:25:05| Set Current Directory to /opt/squid-3.5/var/logs/
> 2016/12/18 17:25:06| Starting Squid Cache version 3.5.23 for i386-unknown-freebsd9.3...
> 2016/12/18 17:25:06| Service Name: squid
> 2016/12/18 17:25:06| Process ID 2943
> 2016/12/18 17:25:06| Process Roles: master worker
> 2016/12/18 17:25:06| NOTICE: Could not increase the number of filedescriptors
> 2016/12/18 17:25:06| With 32768 file descriptors available
> 2016/12/18 17:25:06| Initializing IP Cache...
> 2016/12/18 17:25:06| DNS Socket created at [::], FD 10
> 2016/12/18 17:25:06| DNS Socket created at 0.0.0.0, FD 11
> 2016/12/18 17:25:06| Adding domain crownkenya.com from /etc/resolv.conf
> 2016/12/18 17:25:06| Adding nameserver 192.168.55.254 from /etc/resolv.conf
> 2016/12/18 17:25:06| helperOpenServers: Starting 5/15 'ssl_crtd' processes
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| helperOpenServers: Starting 5/10 'perl' processes
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not permitted
> 2016/12/18 17:25:11| Logfile: opening log stdio:/opt/squid-3.5/var/logs/access.log
> 
> ????
> And it's good to know you are running FreeBSD 9.3...(32 bit..)
> 
> You need to fix the issues with the helpers before anything else since these are blockers for squid to operate right.
> The missing file is a side effect which happens at almost the same time.
> I would have started with looking at the lines:
> sslcrtd_program /opt/squid-3.5/libexec/ssl_crtd -s /opt/squid-3.5/ssl_db -M 4MB
> store_id_program /usr/local/bin/perl /opt/squid-3.5/scripts/store-id.pl
> 
> And see what is causing this operation is not permitted.

That is a known bug on BSD. The child process fork()'d to run the helper
already has been down-privileged by Squid. On BSD systems that means the
test to see if it is still root fails - unfortunately loudly.

Amos



From odhiambo at gmail.com  Mon Dec 19 14:01:24 2016
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Mon, 19 Dec 2016 17:01:24 +0300
Subject: [squid-users] Missing cache files
In-Reply-To: <010201d259f8$b45422e0$1cfc68a0$@ngtech.co.il>
References: <CAAdA2WO+5+vdioEH_8xZ7p7K3a+1+6NYNob5GNpwkZKgYBFgNA@mail.gmail.com>
 <009d01d2597f$79da3d30$6d8eb790$@ngtech.co.il>
 <CAAdA2WMtAx-sOVQEyCyEshO+tZh4bRyJQtyXrGk_Bzrhxff--g@mail.gmail.com>
 <00e801d259e8$7a41e7f0$6ec5b7d0$@ngtech.co.il>
 <CAAdA2WP3j6MY5QyJa9foR-EeJ-Bp6=oob3cc5ks+NFn3CSkoEg@mail.gmail.com>
 <010201d259f8$b45422e0$1cfc68a0$@ngtech.co.il>
Message-ID: <CAAdA2WM8qO=cYHUiCL-Uu1EFvbrSru-2NFTDjUs-L1MT=y=Xqg@mail.gmail.com>

On 19 December 2016 at 16:06, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:

> Did you noticed these errors:
> FATAL: The ssl_crtd helpers are crashing too rapidly, need help!
>
> Squid Cache (Version 3.5.23): Terminated abnormally.
> CPU Usage: 63.837 seconds = 28.308 user + 35.529 sys
> Maximum Resident Size: 171488 KB
> Page faults with physical i/o: 154
> 2016/12/18 17:25:05| Set Current Directory to /opt/squid-3.5/var/logs/
> 2016/12/18 17:25:06| Starting Squid Cache version 3.5.23 for
> i386-unknown-freebsd9.3...
> 2016/12/18 17:25:06| Service Name: squid
> 2016/12/18 17:25:06| Process ID 2943
> 2016/12/18 17:25:06| Process Roles: master worker
> 2016/12/18 17:25:06| NOTICE: Could not increase the number of
> filedescriptors
> 2016/12/18 17:25:06| With 32768 file descriptors available
> 2016/12/18 17:25:06| Initializing IP Cache...
> 2016/12/18 17:25:06| DNS Socket created at [::], FD 10
> 2016/12/18 17:25:06| DNS Socket created at 0.0.0.0, FD 11
> 2016/12/18 17:25:06| Adding domain crownkenya.com from /etc/resolv.conf
> 2016/12/18 17:25:06| Adding nameserver 192.168.55.254 from /etc/resolv.conf
> 2016/12/18 17:25:06| helperOpenServers: Starting 5/15 'ssl_crtd' processes
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| helperOpenServers: Starting 5/10 'perl' processes
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:06| WARNING: no_suid: setuid(0): (1) Operation not
> permitted
> 2016/12/18 17:25:11| Logfile: opening log stdio:/opt/squid-3.5/var/logs/
> access.log
>
> ????
>

I did not see those, funnily.



> And it's good to know you are running FreeBSD 9.3...(32 bit..)
>

Yes, might soon become 10.3 or even 11.


>
> You need to fix the issues with the helpers before anything else since
> these are blockers for squid to operate right.
> The missing file is a side effect which happens at almost the same time.
> I would have started with looking at the lines:
> sslcrtd_program /opt/squid-3.5/libexec/ssl_crtd -s /opt/squid-3.5/ssl_db
> -M 4MB
> store_id_program /usr/local/bin/perl /opt/squid-3.5/scripts/store-id.pl


I have started with disabling the stuff to do with ssl_bump, etc because
it's not practical using it in the environment.



> And see what is causing this operation is not permitted.
> It can be rights or another issue but you must resolve it.
>

I doubt it is rights at all. I checked my /etc/devfs.conf, which is the
only other place I thought could have an issue but it looks fine.



> And before diving hard into StoreID make sure your squid just runs fine
> with ssl bump.
>

I abandoned ssl bump because it wasn't practical in the environment.



> Then jump into StoreID and feel free to share your wishes for this
> service..(caching youtube, Microsoft updates etc..)
>
> Let me know if you need anything.
>
>
Sure. I will.




-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/829e4990/attachment.htm>

From sameh.onaissi at solcv.com  Mon Dec 19 16:42:42 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Mon, 19 Dec 2016 16:42:42 +0000
Subject: [squid-users] squidcliente stopped working!
Message-ID: <5115B4D4-67F4-4CD4-BA02-993DE85B7889@solcv.com>

Hello,

I was using squid client to get cache stats, however this morning it completely stopped working.


When I run squidclient mgr:info I get the following

HTTP/1.1 200 OK
Date: Mon, 19 Dec 2016 16:33:44 GMT
Server: Apache/2.4.7 (Ubuntu)
Last-Modified: Fri, 25 Nov 2016 16:55:22 GMT
ETag: "bd-54222fce80317"
Accept-Ranges: bytes
Content-Length: 189
Vary: Accept-Encoding
Content-Type: text/html
Age: 539
X-Cache: HIT from hostname
X-Cache-Lookup: HIT from hostname:3128
Via: 1.1 hostname (squid/3.5.22)
Connection: close

<!DOCTYPE html>
<html>
<body>


<center><img src="http://mydomainname.com/squid/access_denied.jpg" alt="Acceso Denegado" style="width:704px;height:428px;"></center>

</body>
</html>


the html code is the code of my redirect page whenever a client tries to access a blacklisted website.

squid.conf:
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/0c451975/attachment.htm>

From sameh.onaissi at solcv.com  Mon Dec 19 16:44:11 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Mon, 19 Dec 2016 16:44:11 +0000
Subject: [squid-users] squidcliente stopped working!
Message-ID: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>

Hello,

I was using squid client to get cache stats, however this morning it completely stopped working.


When I run squidclient mgr:info I get the following

HTTP/1.1 200 OK
Date: Mon, 19 Dec 2016 16:33:44 GMT
Server: Apache/2.4.7 (Ubuntu)
Last-Modified: Fri, 25 Nov 2016 16:55:22 GMT
ETag: "bd-54222fce80317"
Accept-Ranges: bytes
Content-Length: 189
Vary: Accept-Encoding
Content-Type: text/html
Age: 539
X-Cache: HIT from hostname
X-Cache-Lookup: HIT from hostname:3128
Via: 1.1 hostname (squid/3.5.22)
Connection: close

<!DOCTYPE html>
<html>
<body>


<center><img src="http://mydomainname.com/squid/access_denied.jpg" alt="Acceso Denegado" style="width:704px;height:428px;"></center>

</body>
</html>


the html code is the code of my redirect page whenever a client tries to access a blacklisted website.

squid.conf: http://pastebin.com/TQ8H6bRp

Any idea how to fix this?


ON SIDE NOTE:
squid client returns numbers based on traffic on 3128 by default right? but in my intercept, I have https traffic going through 3127 and ssl-bump on port 3129. How can I account for all traffic being cached?

Thanks you!
Sam
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/af9a5be7/attachment.htm>

From rousskov at measurement-factory.com  Mon Dec 19 17:09:58 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 19 Dec 2016 10:09:58 -0700
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
Message-ID: <cda129dd-5db4-c62e-3ae4-fa6447d6c07d@measurement-factory.com>

On 12/19/2016 09:44 AM, Sameh Onaissi wrote:
> squid client returns numbers based on traffic on 3128 by default right?

No, the above statement is incorrect. The cache manager interface
reports whole-Squid statistics by default, including all listening ports.

Alex.



From robert at gillecaluim.com  Mon Dec 19 17:43:20 2016
From: robert at gillecaluim.com (Robert Watson)
Date: Mon, 19 Dec 2016 09:43:20 -0800
Subject: [squid-users] squid.conf blocking live video stream
In-Reply-To: <CADoG9xntAFcpd8RWieXKhyOMct6tzo_jo_u+vhh14xH6Jws98g@mail.gmail.com>
References: <CADoG9xmtUhG38Wy5bYsE54oQsrttCiX=XOHWQYXiDHj2ORiSGw@mail.gmail.com>
 <008e01d2597d$ae7409b0$0b5c1d10$@ngtech.co.il>
 <CADoG9xntAFcpd8RWieXKhyOMct6tzo_jo_u+vhh14xH6Jws98g@mail.gmail.com>
Message-ID: <CADoG9xn_9eyLYGAh1une0Mk0B1Jamoz_CttswwW8WXsMvou_hQ@mail.gmail.com>

The site I was having trouble with was video.foxnews.com.  The page loads
but the actual video hangs with "spinning wheel of death".  I took Amos
suggestion and added deny via, request-x-forward and that fixed the issue
but I was trying to create the anonymous proxy paranoid setup initially,
and Amos suggestion won't achieve that.

On Mon, Dec 19, 2016 at 9:28 AM, Robert Watson <robert at gillecaluim.com>
wrote:

> The site I was having trouble with was video.foxnews.com.  I took Amos
> suggestion and added deny via, request-x-forward and that fixed the issue
> but I was trying to create the anonymous proxy paranoid setup initially,
> and Amos suggestion won't achieve that.
>
> On Sun, Dec 18, 2016 at 2:25 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
> wrote:
>
>> Hey Robert,
>>
>> Can you be more specific?
>> ?Not working? can depend on couple things and on the nature of the
>> streaming system.
>> I know that many streaming sites do work under transparent squid so it?s
>> not really well understood what is not working from the spectrum of
>> options.
>> Can you give examples for streaming sites that do work and others that do
>> not?
>> The first that pops in my mind to test it would be:
>> https://www.youtube.com/
>> https://www.crunchyroll.com/
>> https://rutube.ru/
>> And many others that are mentioned at:
>> http://www.unveiltech.com/indexsquidvideobooster.php (under Smart Cache)
>>
>> And take Amos suggestion about restricting the headers more selectively.
>> Depends on your system policy you would be able to find that for most
>> sites
>> you won?t have any issues letting any headers pass but for selective sites
>> you would want to take another policy that would be to block in general
>> and
>> leaving aside the specific headers ?allowed? approach.
>>
>> Also, have you tried to disable the virus scan to verify if it?s the
>> culprit for the streaming issue?
>>
>> Please give one example so I and maybe others would be able to grasp the
>> issue in some way.
>>
>> Thanks,
>> Eliezer
>>
>> ----
>> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
>> Behalf Of Robert Watson
>> Sent: Saturday, December 17, 2016 7:00 AM
>> To: squid-users at lists.squid-cache.org
>> Subject: [squid-users] squid.conf blocking live video stream
>>
>> Sorry if this shows up twice on the mailing list...
>> I've setup a transparent proxy squid v3.5.22 on a x86_64 Arch Linux
>> server.
>> The transparent proxy is working fine for web page caching but live video
>> isn't getting through.  I thought it was a netfilter issue but bypassing
>> the
>> proxy fixes this issue.
>>
>> acl localnet src 10.20.0.0/16 <http://10.20.0.0/16>     # RFC1918
>> possible
>> internal network
>> acl SSL_ports port 443          # https
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 554 # rtsp
>> acl Safe_ports port 1935        # rtmp
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443 # https
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl CONNECT method CONNECT
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>> http_access deny to_localhost
>> http_access allow localnet
>> http_access allow localhost
>> http_access deny all
>> visible_hostname server.ourhome.net <http://server.ourhome.net>
>> http_port 10.20.30.1:3128 <http://10.20.30.1:3128>  intercept
>> disable-pmtu-discovery=transparent
>> http_port 127.0.0.0:8181 <http://127.0.0.0:8181>
>> coredump_dir /var/cache/squid
>> refresh_pattern ^ftp:           1440    20%     10080
>> refresh_pattern ^gopher:        1440    0%      1440
>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>> refresh_pattern .               0       20%     4320
>> #
>> # Anonymous Proxy settings
>> include /etc/squid/extra/anonymous.conf
>> #
>> # Virus scanning via C-ICAP
>> #
>> include /etc/squid/extra/c-icap.conf
>> #
>>
>> By the process of elimination I've narrowed it down to the anonymous proxy
>> settings...
>> anonymous.conf
>>
>> forwarded_for off
>> request_header_access Allow allow all
>> request_header_access Authorization allow all
>> request_header_access WWW-Authenticate allow all
>> request_header_access Proxy-Authorization allow all
>> request_header_access Proxy-Authenticate allow all
>> request_header_access Cache-Control allow all
>> request_header_access Content-Encoding allow all
>> request_header_access Content-Length allow all
>> request_header_access Content-Type allow all
>> request_header_access Date allow all
>> request_header_access Expires allow all
>> request_header_access Host allow all
>> request_header_access If-Modified-Since allow all
>> request_header_access Last-Modified allow all
>> request_header_access Location allow all
>> request_header_access Pragma allow all
>> request_header_access Accept allow all
>> request_header_access Accept-Charset allow all
>> request_header_access Accept-Encoding allow all
>> request_header_access Accept-Language allow all
>> request_header_access Content-Language allow all
>> request_header_access Mime-Version allow all
>> request_header_access Retry-After allow all
>> request_header_access Title allow all
>> request_header_access Connection allow all
>> request_header_access Proxy-Connection allow all
>> request_header_access User-Agent allow all
>> request_header_access Cookie allow all
>> request_header_access All deny all
>>
>> could someone please tell me what request_header_access I need to all, or
>> how to further trouble shoot this configuration?
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161219/14252b4b/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Dec 19 18:31:59 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 19 Dec 2016 19:31:59 +0100
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
Message-ID: <201612191931.59746.Antony.Stone@squid.open.source.it>

On Monday 19 December 2016 at 17:44:11, Sameh Onaissi wrote:

> Hello,
> 
> I was using squid client to get cache stats, however this morning it
> completely stopped working.

> <center><img src="http://mydomainname.com/squid/access_denied.jpg"
> alt="Acceso Denegado" style="width:704px;height:428px;"></center>

> the html code is the code of my redirect page whenever a client tries to
> access a blacklisted website.

How big is your blacklist?  Could you show us what's in it?

Have you added the proxy itself to the whitelist?

> squid.conf: http://pastebin.com/TQ8H6bRp

Quote from your config:

	acl Safe_ports port 587 #SMTP

Did you read Amos' reply "SMTP is the #1 worst protocol to let anywhere near 
an HTTP proxy.  Preventing what you have allowed to happen is one of the 
primary reasons Safe_ports exists in the first place!"

http://lists.squid-cache.org/pipermail/squid-users/2016-December/013776.html

By the way, what did you have to fix to prevent those public IP addresses being 
able to access your Squid proxy?

http://lists.squid-cache.org/pipermail/squid-users/2016-December/013764.html


Antony.

-- 
Pavlov is in the pub enjoying a pint.
The barman rings for last orders, and Pavlov jumps up exclaiming "Damn!  I 
forgot to feed the dog!"

                                                   Please reply to the list;
                                                         please *don't* CC me.


From sameh.onaissi at solcv.com  Mon Dec 19 20:52:02 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Mon, 19 Dec 2016 20:52:02 +0000
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <201612191931.59746.Antony.Stone@squid.open.source.it>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <201612191931.59746.Antony.Stone@squid.open.source.it>
Message-ID: <DE2F9B11-32A1-44CE-A362-5D3A055D8E39@solcv.com>


> On Dec 19, 2016, at 1:31 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Monday 19 December 2016 at 17:44:11, Sameh Onaissi wrote:
> 
>> Hello,
>> 
>> I was using squid client to get cache stats, however this morning it
>> completely stopped working.
> 
>> <center><img src="http://mydomainname.com/squid/access_denied.jpg"
>> alt="Acceso Denegado" style="width:704px;height:428px;"></center>
> 
>> the html code is the code of my redirect page whenever a client tries to
>> access a blacklisted website.
> 
> How big is your blacklist?  Could you show us what's in it?
> 
> Have you added the proxy itself to the whitelist?

The blacklist consistes of the ads, porn, socialnet and spyware lists of the BL list. 

I added both LAN and WAN IPs of the server to the whitelist but didn?t help.

So, I changed my default acl setting in squid guard config file to pass all for now (I know it is not ideal), just to monitor the cache as I am trying to get the HIT ratio up. (currently only at 7.8%)
	
squid guard config: pastebin.com/bbe8CWLE



> 
>> squid.conf: http://pastebin.com/TQ8H6bRp
> 
> Quote from your config:
> 
> 	acl Safe_ports port 587 #SMTP
> 
> Did you read Amos' reply "SMTP is the #1 worst protocol to let anywhere near 
> an HTTP proxy.  Preventing what you have allowed to happen is one of the 
> primary reasons Safe_ports exists in the first place!?

The reason I allow 587 is because the Squid Proxy lives on the same server as a mail server which needs this port, and several clients have their mail clientes (Outlook..etc) already configured to use this port.

> 
> http://lists.squid-cache.org/pipermail/squid-users/2016-December/013776.html
> 
> By the way, what did you have to fix to prevent those public IP addresses being 
> able to access your Squid proxy?

I basically let them get blocked by squid for a day or two and they stopped. I just allowed LAN source IPs.

> 
> http://lists.squid-cache.org/pipermail/squid-users/2016-December/013764.html
> 
> 
> Antony.
> 
> -- 
> Pavlov is in the pub enjoying a pint.
> The barman rings for last orders, and Pavlov jumps up exclaiming "Damn!  I 
> forgot to feed the dog!"
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From creditu at eml.cc  Tue Dec 20 01:58:56 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Mon, 19 Dec 2016 18:58:56 -0700
Subject: [squid-users] sslpassword_program
In-Reply-To: <20921bd3-cbcd-e6f0-1788-abb7907f53ab@treenet.co.nz>
References: <1482088415.4018167.822848113.09A453E0@webmail.messagingengine.com>
 <CAEnCSG5N7fXNjwSHq7GKvcCtJGpM8Bv0kUOfeFEFcEvacNUGVQ@mail.gmail.com>
 <1482123577.4142040.823185569.4201259E@webmail.messagingengine.com>
 <20921bd3-cbcd-e6f0-1788-abb7907f53ab@treenet.co.nz>
Message-ID: <1482199136.1103037.824314009.69C9556B@webmail.messagingengine.com>


On Sun, Dec 18, 2016, at 11:24 PM, Amos Jeffries wrote:
> On 19/12/2016 5:59 p.m., creditu wrote:
> > 
> > On Sun, Dec 18, 2016, at 01:21 PM, Michael Pelletier wrote:
> >> Check your file permissions on the key.
> >>
> >> On Dec 18, 2016 2:13 PM, creditu wrote:
> >>
> >>> I'm having trouble getting the sslpassword_program working for an
> >>> encrypted key.  Config looks like this:
> >>>
> >>> sslpassword_program /usr/local/bin/pass.sh
> >>> https_port 10.10.10.1:443 accel vhost cert=/etc/squid/www.crt
> >>> key=/etc/squid/private.key
> >>>
> >>> On start, cache log states "Ignoring https_port 10.10.10.1:443 due to
> >>> SSL initialization failure."
> >>> On stop, console states "Failed to acquire SSL private key
> >>> '/etc/squid/private.key': error:0200100D:system library:fopen:Permission
> >>> denied"
> >>>
> >>> Removing the passphrase from the private key, squid starts normally.
> >>> Permissions on the encrypted and non-encrypted keys are the same.  I
> >>> also tried putting the pass.sh program in /bin.  The pass.sh program
> >>> looks like this:
> >>> #!/bin/sh
> >>> echo "testing"
> >>>
> >>> The hash of the private key modulus and the certificate modulus match as
> >>> well.
> >>>
> >>> Am I missing something? This is on squid 3.1.
> 
> If the ideas below don't help can you try an upgrade? there are a few
> fixes in 3.2 and 3.3 related to that directive.
> 
> >>> _______________________________________________
> > 
> > Checked the perms and they are identical as the private key that I
> > stripped the password out of.  They are also in the same directory.  The
> > one without a password works fine.
> 
> The one without a password is being opened by OpenSSL directly.
> 
> The one with pssword is being opened in Squid oeprating context, which
> should be root, but may also be the low-privilege proxy user at the time
> the script is run.
> 
> So you need the key file to be readable by whichever of those privilege
> contexts Squid is using at the time. (Sorry I can't be more precise, I'm
> not sure myself which is used in 3.1).
> 
> If you have SELinux or AppArmour they may also be interferring with the
> priviledged access.
> 
> The script itself needs either executable permissions set, or squid.conf
> containing the full shell interpreter path as well as the script path.
>  ie. "sslpassword_program /bin/sh /usr/local/bin/pass.sh"
> 
> 
> >  Also tried encrypting with des3
> > versus aes128 and that didn't make a difference either.   Gotta be
> > missing something.
> 
> >  The error points to a perms problem, but not seeing
> > how since everything is the same.
> 
> The error message says fopen() command is not permitted for whichever
> user account is trying to access the .key file.
>  It's not clear if that is fopen() of the .key file, or fopen() of the
> pass.sh file before running it.
> 
> The way you describe the issues below hint to me that it is the
> permission to access the script which is breaking things.
> 
> 
> Also, those old Squid had some issues with processing errno at the wrong
> times. So there is a small but non-zero chance that the error is
> actually something else. :-(
> 
> 
> >  Also, added a line in the
> > sslpassword_program to touch a file to see if it got executed and it
> > didn't create the file. Additionally, ran the stat command on the 
> > /usr/local/bin/pass.sh after squid started up
> 
> FYI: That test only works if your filesystem has been configured to
> record access times. Using such a setup with Squid will cause major
> slowdown as cache related files and logs get accessed *a lot*. So is
> typically disabled via fstab "noatime" settings if anyone with expertise
> has tuned the proxy machine before you.
> 
> 
> > and the access time never
> > changes.  It seems like the shell script may not being executed for some
> > reason.  I'm able to launch the shell script from the command line and
> > it echos out the pass fine.
> 
> This kind of implies the file permission problem is for Squid to open
> the script "file" before running whats inside.
> 
> Check /usr/local/bin/pass.sh ownership, executable rights, and
> SELinux/AppArmour permissions (whichever is present on that achine).
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Thanks.  Worked down the list and the problem ended up being SELinux. 
Of course I would have sworn that it was not in enforcing mode.


From squid3 at treenet.co.nz  Tue Dec 20 04:55:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 20 Dec 2016 17:55:54 +1300
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <DE2F9B11-32A1-44CE-A362-5D3A055D8E39@solcv.com>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <201612191931.59746.Antony.Stone@squid.open.source.it>
 <DE2F9B11-32A1-44CE-A362-5D3A055D8E39@solcv.com>
Message-ID: <6fd126f4-858f-1839-32d7-26a96d92b7f4@treenet.co.nz>

On 20/12/2016 9:52 a.m., Sameh Onaissi wrote:
> 
>> On Dec 19, 2016, at 1:31 PM, Antony Stone wrote:
>>
>> On Monday 19 December 2016 at 17:44:11, Sameh Onaissi wrote:
>>
>>> Hello,
>>>
>>> I was using squid client to get cache stats, however this morning it
>>> completely stopped working.
>>
>>> <center><img src="http://mydomainname.com/squid/access_denied.jpg"
>>> alt="Acceso Denegado" style="width:704px;height:428px;"></center>
>>
>>> the html code is the code of my redirect page whenever a client tries to
>>> access a blacklisted website.
>>
>> How big is your blacklist?  Could you show us what's in it?
>>
>> Have you added the proxy itself to the whitelist?
> 
> The blacklist consistes of the ads, porn, socialnet and spyware lists of the BL list. 
> 
> I added both LAN and WAN IPs of the server to the whitelist but didn?t help.
> 

What URL was being requested that got the above access denied response?

Use -vv parameter to squidclient and "debug_options 11,2" in squid.conf
to have the requests header logged and find that out.


> So, I changed my default acl setting in squid guard config file to pass all for now (I know it is not ideal), just to monitor the cache as I am trying to get the HIT ratio up. (currently only at 7.8%)
> 	
> squid guard config: pastebin.com/bbe8CWLE
> 

So your SG config just does basic IP, URL and time based allow or
redirect decisions.

I suggest you drop SG entirely and move that config into your squid.conf:


# Time rules
# abbrev for weekdays:
# s = sun, m = mon, t =tue, w = wed, h = thu, f = fri, a = sat
acl non-working-hours time MTWHF 18:00-24:00 00:00-08:00
acl non-working-hours time MTWHF 18:00-24:00 00:00-08:00
acl non-working-hours time SA 00:00-24:00

# Source addresses
acl exempt src 10.0.0.90 10.0.0.167
acl youtubers src 10.0.0.1-10.0.0.4
acl localnet src 10.0.0.0/24

# Destination classes
acl blah_domains dstdomain "adv/domains"
acl blah_domains dstdomain "deny/domains"
acl blah_domains dstdomain "porn/domains"
acl blah_domains dstdomain "spyware/domains"
acl blah_domains dstdomain "socialnet/domains"

acl blah_urls dstdom_regex "adv/urls"
acl blah_urls dstdom_regex "deny/urls"
acl blah_urls dstdom_regex "porn/urls"
acl blah_urls dstdom_regex "spyware/urls"
acl blah_urls dstdom_regex "socialnet/urls"

acl stuff_always_blocked anyof blah_domains blah_urls

acl whitelist_domains dstdomain "whitelist/domains"
acl whitelist_urls dstdom_regex "whitelist/urls"
acl whitelist anyof whitelist_domains whitelist_urls
deny_info 302:http://example.com/squid/denegado.html whitelist

acl youtubers_domains dstdomain "socialnet/domains"
acl youtubers_urls dstdom_regex "adv/urls"
acl youtubers anyof youtubers_domains youtubers_urls
deny_info 302:http://example.com/squid/denegado.html youtubers

# Policies
http_access deny !localnet
deny_info 302:http://example.com/squid/denegado.html localnet

http_access allow exempt
http_access allow youtubers !stuff_always_blocked
http_access deny youtubers
http_access allow non-working-hours
http_access allow whitelist !stuff_always_blocked
http_access deny whitelist
http_access allow localnet

deny_info 302:http://example.com/squid/denegado.html all
http_access deny all


> 
>>
>>> squid.conf: http://pastebin.com/TQ8H6bRp
>>
>> Quote from your config:
>>
>> 	acl Safe_ports port 587 #SMTP
>>
>> Did you read Amos' reply "SMTP is the #1 worst protocol to let anywhere near 
>> an HTTP proxy.  Preventing what you have allowed to happen is one of the 
>> primary reasons Safe_ports exists in the first place!?
> 

> The reason I allow 587 is because the Squid Proxy lives on the same
server as a mail server which needs this port, and several clients have
their mail clientes (Outlook..etc) already configured to use this port.

Bogus. You should know it is possible that two pieces of software can
run on one machine without interferring with each other.

Whether or not a mailserver exists on the same machine has nothing to do
with Squid.

Your mailserver itself should be using that port and controlling what
traffic can use it. *HTTP* traffic should never be allowed to flow from
the proxy software through to the mailserver software.

Amos



From bjoern.wahl at hospital-borken.de  Tue Dec 20 07:18:40 2016
From: bjoern.wahl at hospital-borken.de (bjoern wahl)
Date: Tue, 20 Dec 2016 08:18:40 +0100
Subject: [squid-users] CentOS Linux 7 / Squid Cache: Version 3.5.20 / ecap
	clamav
Message-ID: <5858E96002000009000243CF@mail01.hospital-borken.de>

Hello!

I would like to switch from SLES to CentOS Squid proxy server and just
learned that icap is no longer up-to-date.

Better use eCap, but i am not able to find a good howto telling me how
to get it to work in my environment.

Can anybody help me out ?

Thanks, Bj?rn.

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.





From bjoern.wahl at hospital-borken.de  Tue Dec 20 08:33:14 2016
From: bjoern.wahl at hospital-borken.de (bjoern wahl)
Date: Tue, 20 Dec 2016 09:33:14 +0100
Subject: [squid-users] Antw: CentOS Linux 7 / Squid Cache: Version 3.5.20 /
 ecap clamav
In-Reply-To: <5858E96002000009000243CF@mail01.hospital-borken.de>
References: <5858E96002000009000243CF@mail01.hospital-borken.de>
Message-ID: <5858FADA02000009000243DF@mail01.hospital-borken.de>

Hello!

Just a short update.

Got it working.

So now we have CentOS/Squid/ecap camav and ldap auth. Just the redirect
is missing if a virus was fond...working on that.

Thanks for all the help.

bj?rn


>>> "bjoern wahl" <bjoern.wahl at hospital-borken.de> 20.12.16 8.19 Uhr >>>
Hello!

I would like to switch from SLES to CentOS Squid proxy server and just
learned that icap is no longer up-to-date.

Better use eCap, but i am not able to find a good howto telling me how
to get it to work in my environment.

Can anybody help me out ?

Thanks, Bj?rn.

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.





From moremore2 at outlook.com  Tue Dec 20 08:34:56 2016
From: moremore2 at outlook.com (k simon)
Date: Tue, 20 Dec 2016 08:34:56 +0000
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <1481881650.13325.3.camel@comnet.uz>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
 <1481881113.13325.1.camel@comnet.uz> <1481881650.13325.3.camel@comnet.uz>
Message-ID: <MWHPR13MB126290BF1C86AFDD8968C562EE900@MWHPR13MB1262.namprd13.prod.outlook.com>

Hi, Garri,
   I've tested 3.5-r14128, it crashed again with the same error.

2016/12/20 16:23:22 kid1| assertion failed: MemBuf.cc:216: "0 <= 
tailSize && tailSize <= cSize"

Simon
20161220

? 2016/12/16 17:47, Garri Djavadyan ??:
> On Fri, 2016-12-16 at 14:38 +0500, Garri Djavadyan wrote:
>> On Fri, 2016-12-16 at 06:34 +0000, k simon wrote:
>>> Hi,lists,
>>>    r14087 is quite stable on FB 11. But r14088 crashed frequently
>>> with
>>> "2016/12/16 09:00:59 kid1| assertion failed: MemBuf.cc:216: "0 <=
>>> tailSize && tailSize <= cSize" ". The config file is almost the
>>> default
>>> except listening port and http_access modification.
>>
>> Hi,
>>
>> I believe you faced bug 4606 [1]. Do you use 'collapsed_forwarding'
>> option? If you have any new details please add a comment to the bug
>> report.
>>
>> [1] http://bugs.squid-cache.org/show_bug.cgi?id=4606
>
> Sorry, actually, 'collapsed_forwarding' should not be enabled to facethe bug.
>
> Garri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

From hardikdangar+squid at gmail.com  Tue Dec 20 09:42:48 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Tue, 20 Dec 2016 15:12:48 +0530
Subject: [squid-users] Squid Websocket Issue
In-Reply-To: <CA+sSnVavKQR80XNvykdecMeB1feLwBMEP29Vm+Lxp3=U8-S1dg@mail.gmail.com>
References: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
 <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>
 <CA+sSnVZYcQkvA=-bBVSuQtoXeYxomL5Ca51cw4ax0dP3EUKF7g@mail.gmail.com>
 <5990ba78-39ea-569a-29dd-409e4912f1a6@treenet.co.nz>
 <010401d259f9$4dfcd630$e9f68290$@ngtech.co.il>
 <CA+sSnVavKQR80XNvykdecMeB1feLwBMEP29Vm+Lxp3=U8-S1dg@mail.gmail.com>
Message-ID: <CA+sSnVbob7T03YvK8RCHmd4o=9Ej8NZ6vhmgKj+h75hnB1EXdQ@mail.gmail.com>

@Eliezer, @Amos

Following changes in config works and whatsapp starts working,

acl serverIsws ssl::server_name_regex ^w[0-9]+\.web\.whatsapp\.com$

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice serverIsws
ssl_bump bump !serverIsws all

[ above is a feature of whatsapp which allows you to connect to
web.whatsapp.com from browser]


now what happens at request level is following,

Request URL:wss://w8.web.whatsapp.com/ws
Request Method:GET
Status Code:101 Switching Protocols

----------------------------------

Response Headers

Connection:Upgrade
Sec-WebSocket-Accept:Z6CC+QVdvB0cCHPbJAQMaHKL2uQ=
Upgrade:websocket

----------------------------------
Request Headers

Accept-Encoding:gzip, deflate, sdch, br
Accept-Language:en-US,en;q=0.8
Cache-Control:no-cache
Connection:Upgrade
Host:w8.web.whatsapp.com
Origin:https://web.whatsapp.com
Pragma:no-cache
Sec-WebSocket-Extensions:permessage-deflate; client_max_window_bits
Sec-WebSocket-Key:mbCFLN/Q1KMt58t6DoQI9Q==
Sec-WebSocket-Version:13
Upgrade:websocket
User-Agent:Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like
Gecko) Chrome/55.0.2883.75 Safari/537.36

After this no other web sockets open it seems whatsapp switches to normal
communication from websockets.

Above solution could help lot of people who is trying to configure
websockets to run. I have few more websocket applications which i need to
work on and i will let you know if it works soon.

Thank you very much for your help. Really appreciate the help.

On Mon, Dec 19, 2016 at 6:46 PM, Hardik Dangar <hardikdangar+squid at gmail.com
> wrote:

> Based on Amos's Answer,
>
> acl serverIsws ssl::server_name .w0.whatsapp.com
> acl serverIsws ssl::server_name .w1.whatsapp.com
>
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump !serverIsws all
> ssl_bump splice all
>
> will above work ?
>
> Or should i splice first and bump all others later?
>
> This is very interesting. I will definitely try this when i will reach
> office.
>
> On Mon, Dec 19, 2016 at 6:40 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
> wrote:
>
>> I can give a hint that once you see the request you can identify using an
>> ICAP\ECAP services couple details about the request.
>> Basically I had a regex which allowed any what's app traffic to be
>> spliced by the SNI domain name.
>> It should be something like "w[0-9]+\.web\.whatsapp\.com$" to match the
>> required domains for whatsapp to be spliced.
>> If nobody will try it before me it's on my todo list for this release
>> (3.5.23, 4.0.17).
>>
>> Eliezer
>>
>> ----
>> Eliezer Croitoru
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>> -----Original Message-----
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
>> Behalf Of Amos Jeffries
>> Sent: Monday, December 19, 2016 8:51 AM
>> To: Hardik Dangar <hardikdangar+squid at gmail.com>
>> Cc: Squid Users <squid-users at lists.squid-cache.org>
>> Subject: Re: [squid-users] Squid Websocket Issue
>>
>> On 19/12/2016 12:14 p.m., Hardik Dangar wrote:
>> > can you give me one example please ?
>> > like in the above example.
>> > w4.web.whatsapp.com domain is fixed
>> > are you suggesting i can create acl and by pass it to squid ?
>> >
>>
>> You are the first person to ask about WhatsApp traffic.
>>
>> These might be a useful starting point
>> <http://wiki.squid-cache.org/Features/SslPeekAndSplice#Confi
>> guration_Examples>
>>
>> What the examples are doing for banks is what you want to do for WhatsApp.
>>
>> The trick though will be figuring out how to splice *before* seeing what
>> type of HTTP request exists inside the tunnel. If you are lucky the app
>> will be using SNI.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161220/4b4d795d/attachment.htm>

From edwin.zhou at hotmail.com  Tue Dec 20 10:56:30 2016
From: edwin.zhou at hotmail.com (wei)
Date: Tue, 20 Dec 2016 10:56:30 +0000
Subject: [squid-users] Help: How to calculate all bytes when communicate
 with client for a request
In-Reply-To: <PS1PR01MB130674C70AA4CEC08590F0F898900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
References: <PS1PR01MB130674C70AA4CEC08590F0F898900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
Message-ID: <PS1PR01MB13062EF0025C299B8F4ECCC498900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>

Hi Guys,


I want to calculate all bytes when a request is sent to squid, including:

  1.  the header length that client will send to squid
  2.  the post content length that send to squid
  3.  the response length squid will reply to client

logformat squid %ts.%03tu %6tr %>a %Ss/%03Hs %<st %rm %ru %un %Sh/%<A:%<a %mt %st

In the squid config file, I can only set %st which only include 1 and 3, seems squid ignore the point 2(the post content length is not included in the total size), it also happens when a post request occurs in squid https connection.

I don't need to know the request content, just want to know how many bytes the client totally send including the post and https bytes, is it possible to do this?

Is it possible to modify the squid source code if there is no parameter to control this? Is it just a counting logic that won't be complex? Any help would be much appreciated. Thanks.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161220/04adb279/attachment.htm>

From rafael.akchurin at diladele.com  Tue Dec 20 11:17:17 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 20 Dec 2016 11:17:17 +0000
Subject: [squid-users] Squid 3.5.23 for Microsoft Windows 64-bit is available
Message-ID: <DB6PR0401MB26803969591E7DE3AD2E41028F900@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Greetings everyone,



The CygWin based build of Squid proxy for Microsoft Windows version 3.5.23 is now available (amd64 only!).



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.23-RELEASENOTES.html.

* Ready to use MSI package can be downloaded from http://squid.diladele.com.

* List of open issues for the installer - https://github.com/diladele/squid-windows/issues



Thanks a lot for Squid developers for making this great software!



Please join our humble efforts to provide ready to run MSI installer for Squid on Microsoft Windows with all required dependencies at GitHub -

https://github.com/diladele/squid-windows. Please report all issues/bugs/feature requests at GitHub project. Issues about the *MSI installer only* can also be reported to support at diladele.com<mailto:support at diladele.com>.



Best regards,

Rafael Akchurin

Diladele B.V.

https://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161220/3e872776/attachment.htm>

From david at articatech.com  Tue Dec 20 11:50:00 2016
From: david at articatech.com (David Touzeau)
Date: Tue, 20 Dec 2016 12:50:00 +0100
Subject: [squid-users] cache_peer and PROXY protocol
In-Reply-To: <efbe8143-c354-0924-4518-13d122cacaeb@treenet.co.nz>
References: <003701d259ed$45bc1140$d13433c0$@articatech.com>
 <efbe8143-c354-0924-4518-13d122cacaeb@treenet.co.nz>
Message-ID: <02bd01d25ab7$31ba8cb0$952fa610$@articatech.com>

Thanks Amos.


It is to create a kind of WAN Proxy that accepts only PROXY Protocol and to
get Proxy Protocol benefits (without losing the client information - IP 
addresses and Authentications )
Forwarding SSL can be useful too.

<< You can send to me your ways to be a sponsor on it... >>

-----Message d'origine-----
De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la
part de Amos Jeffries
Envoy? : lundi 19 d?cembre 2016 13:20
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] cache_peer and PROXY protocol

On 20/12/2016 12:44 a.m., David Touzeau wrote:
>
> Hi
>
> Squid accept "Proxy protocol" in http_port, is there a chance to see
> "PROXY Protocol" supported in cache_peer if you need to link 2 squid ?
>

'a chance' only at this point unless somebody (you?) wants to sponsor it. It
is on my TODO list, way down under TLS improvements and HTTP/2 support -
both big projects.

What is your use-case ?

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From david at articatech.com  Tue Dec 20 11:53:28 2016
From: david at articatech.com (David Touzeau)
Date: Tue, 20 Dec 2016 12:53:28 +0100
Subject: [squid-users] Squid freeze each hour.
Message-ID: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>

Hi

I'm using the 3.5.23, each hour, the proxy port did not respond for 3 to 10
minutes.
During the freeze have made a -k debug to see whats happening.
Here a piece of log of the log during the freeze:

Is there something relevant ?:

2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 877FE61D1641BCA926338890AF1478D2
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
1024129
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Thu, 08 Dec 2016 15:40:20 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(168) refreshStaleness: FRESH:
expires 1486393228 >= check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= -1
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(461) refreshCheck: Object
isn't stale..
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(463) refreshCheck: returning
FRESH_EXPIRES
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(288) storeDigestAdd:
storeDigestAdd: added entry, key: 877FE61D1641BCA926338890AF1478D2
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87BF2568F0A7D71F1E567579CCC216F7
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
1019863
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Thu, 08 Dec 2016 16:51:26 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481215886 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= 1019863
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must
revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 873F5089579B6B7E351555B77F98259A
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
956460
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Fri, 09 Dec 2016 10:28:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481279289 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= 956460
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must
revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87FFFEA8EBEFAE0DBC21EBC97D405839
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
948473
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Fri, 09 Dec 2016 12:41:16 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(179) refreshStaleness: No
explicit expiry given, using heuristics to determine freshness
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(198) refreshStaleness: Last
modified 19509132 sec before we cached it, L-M factor 75.00% = 14631849 sec
freshness lifetime
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(205) refreshStaleness: FRESH:
age 948473 <= stale_age 14631849
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= -1
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(461) refreshCheck: Object
isn't stale..
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(470) refreshCheck: returning
FRESH_LMFACTOR_RULE
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(288) storeDigestAdd:
storeDigestAdd: added entry, key: 87FFFEA8EBEFAE0DBC21EBC97D405839
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 873F5CB8872FFC57B8D32027D4DC8174
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
520259
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Wed, 14 Dec 2016 11:38:10 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 631151999 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= 851083750
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must
revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87FF2043810CAE2CE015C43DBC3E1004
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
594643
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Tue, 13 Dec 2016 14:58:26 GMT
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481727507 < check_time 1482235749
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= 508242
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring



From eliezer at ngtech.co.il  Tue Dec 20 13:29:57 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 20 Dec 2016 15:29:57 +0200
Subject: [squid-users] Squid freeze each hour.
In-Reply-To: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
References: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
Message-ID: <003d01d25ac5$285f5840$791e08c0$@ngtech.co.il>

Hey David,

Some things are missing and we need you to fill the picture for us.
What OS are you running squid ontop?
Are you running it in intercept or tproxy mode?
Are you using ssl-bump?
Are you using it with multiple cores?
Can you attach the squid.conf( removing the confidential details) to this email?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of David Touzeau
Sent: Tuesday, December 20, 2016 1:53 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid freeze each hour.

Hi

I'm using the 3.5.23, each hour, the proxy port did not respond for 3 to 10 minutes.
During the freeze have made a -k debug to see whats happening.
Here a piece of log of the log during the freeze:

Is there something relevant ?:

2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 877FE61D1641BCA926338890AF1478D2
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
1024129
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Thu, 08 Dec 2016 15:40:20 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(168) refreshStaleness: FRESH:
expires 1486393228 >= check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = -1
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(461) refreshCheck: Object isn't stale..
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(463) refreshCheck: returning FRESH_EXPIRES
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(288) storeDigestAdd:
storeDigestAdd: added entry, key: 877FE61D1641BCA926338890AF1478D2
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87BF2568F0A7D71F1E567579CCC216F7
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
1019863
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Thu, 08 Dec 2016 16:51:26 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481215886 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 1019863
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 873F5089579B6B7E351555B77F98259A
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
956460
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Fri, 09 Dec 2016 10:28:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481279289 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 956460
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87FFFEA8EBEFAE0DBC21EBC97D405839
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
948473
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Fri, 09 Dec 2016 12:41:16 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(179) refreshStaleness: No explicit expiry given, using heuristics to determine freshness
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(198) refreshStaleness: Last modified 19509132 sec before we cached it, L-M factor 75.00% = 14631849 sec freshness lifetime
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(205) refreshStaleness: FRESH:
age 948473 <= stale_age 14631849
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = -1
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(461) refreshCheck: Object isn't stale..
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(470) refreshCheck: returning FRESH_LMFACTOR_RULE
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(288) storeDigestAdd:
storeDigestAdd: added entry, key: 87FFFEA8EBEFAE0DBC21EBC97D405839
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 873F5CB8872FFC57B8D32027D4DC8174
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
520259
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Wed, 14 Dec 2016 11:38:10 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 631151999 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 851083750
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87FF2043810CAE2CE015C43DBC3E1004
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
594643
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Tue, 13 Dec 2016 14:58:26 GMT
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481727507 < check_time 1482235749
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 508242
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Tue Dec 20 13:33:43 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 20 Dec 2016 15:33:43 +0200
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
Message-ID: <004001d25ac5$af542470$0dfc6d50$@ngtech.co.il>

Hey Simon,

Just to clear out things for me since the bug report is a bit confusing in the Bugzilla.
What should I do to replicate the bug in my lab?
1. install FreeBSD 11 stable
2. Compile squid latest
And what then?
Just use the proxy?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of k simon
Sent: Friday, December 16, 2016 8:34 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] r14088 crash on FreeBSD 11

Hi,lists,
   r14087 is quite stable on FB 11. But r14088 crashed frequently with
"2016/12/16 09:00:59 kid1| assertion failed: MemBuf.cc:216: "0 <= tailSize && tailSize <= cSize" ". The config file is almost the default except listening port and http_access modification.


Simon
20161216





P.S.
# uname -a
FreeBSD unkn-j9 11.0-STABLE FreeBSD 11.0-STABLE #0 r309724: Fri Dec  9
11:01:51 CST 2016
root at cache-farm-n1:/usr/obj/usr/src/sys/11-ule-r309209  amd64

# squid -vv
Squid Cache: Version 3.5.21
Service Name: squid
configure options:  '--with-default-user=squid' 
'--bindir=/usr/local/sbin' '--sbindir=/usr/local/sbin' 
'--datadir=/usr/local/etc/squid' '--libexecdir=/usr/local/libexec/squid' 
'--localstatedir=/var' '--sysconfdir=/usr/local/etc/squid' 
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid/squid.pid' 
'--with-swapdir=/var/squid/cache' '--without-gnutls' '--enable-auth' 
'--enable-build-info' '--enable-loadable-modules' 
'--enable-removal-policies=lru heap' '--disable-epoll' 
'--disable-linux-netfilter' '--disable-linux-tproxy' 
'--disable-translation' '--disable-arch-native' '--disable-eui' 
'--disable-cache-digests' '--disable-delay-pools' '--disable-ecap' 
'--disable-esi' '--enable-follow-x-forwarded-for' '--disable-htcp' 
'--disable-icap-client' '--disable-icmp' '--disable-ident-lookups' 
'--enable-ipv6' '--enable-kqueue' '--with-large-files' 
'--enable-http-violations' '--without-nettle' '--enable-snmp' 
'--disable-ssl' '--disable-ssl-crtd' '--disable-stacktraces' 
'--disable-forw-via-db' '--disable-wccp' '--disable-wccpv2' 
'--without-heimdal-krb5' '--without-mit-krb5' '--without-gss' 
'--disable-ipf-transparent' '--enable-ipfw-transparent' 
'--disable-pf-transparent' '--without-nat-devpf' '--enable-auth-basic=DB SMB_LM MSNT-multi-domain NCSA PAM POP3 RADIUS fake getpwnam' 
'--enable-auth-digest=file' '--enable-external-acl-helpers=file_userip
time_quota unix_group' '--enable-auth-negotiate=none' 
'--enable-auth-ntlm=fake smb_lm' '--enable-storeio=aufs diskd rock ufs' 
'--enable-disk-io=DiskThreads DiskDaemon AIO Blocking IpcIo Mmapped' 
'--enable-log-daemon-helpers=file' '--enable-url-rewrite-helpers=fake' 
'--enable-storeid-rewrite-helpers=file' '--prefix=/usr/local' 
'--mandir=/usr/local/man' '--disable-silent-rules' 
'--infodir=/usr/local/info/' '--build=amd64-portbld-freebsd11.0' 
'build_alias=amd64-portbld-freebsd11.0' 'CC=cc' 'CFLAGS=-O2 -pipe -m64 -fno-strict-aliasing -fno-omit-frame-pointer -march=penryn -fstack-protector' 'LDFLAGS=-L/usr/local/lib -Wl,--eh-frame-hdr' 
'LIBS=-lthr -lpcreposix -lpcre -ltcmalloc_minimal' 'CPPFLAGS=' 'CXX=c++' 
'CXXFLAGS=-std=c++11 -fPIC -DPIC -I/usr/local/include' 'CPP=cpp'
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From fredbmail at free.fr  Tue Dec 20 13:33:36 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 20 Dec 2016 14:33:36 +0100 (CET)
Subject: [squid-users] Squid freeze each hour.
In-Reply-To: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
Message-ID: <544116519.156783906.1482240816777.JavaMail.root@zimbra4-e1.priv.proxad.net>

I do not see this, do you have something particular ? SSLBump maybe ? SMP ?


From eliezer at ngtech.co.il  Tue Dec 20 13:34:36 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 20 Dec 2016 15:34:36 +0200
Subject: [squid-users] Antw: CentOS Linux 7 / Squid Cache: Version
	3.5.20 / ecap clamav
In-Reply-To: <5858FADA02000009000243DF@mail01.hospital-borken.de>
References: <5858E96002000009000243CF@mail01.hospital-borken.de>
 <5858FADA02000009000243DF@mail01.hospital-borken.de>
Message-ID: <004201d25ac5$ce39b030$6aad1090$@ngtech.co.il>

Can you share what was the issue and how did you managed to resolve it?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of bjoern wahl
Sent: Tuesday, December 20, 2016 10:33 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Antw: CentOS Linux 7 / Squid Cache: Version 3.5.20 / ecap clamav

Hello!

Just a short update.

Got it working.

So now we have CentOS/Squid/ecap camav and ldap auth. Just the redirect is missing if a virus was fond...working on that.

Thanks for all the help.

bj?rn


>>> "bjoern wahl" <bjoern.wahl at hospital-borken.de> 20.12.16 8.19 Uhr >>>
Hello!

I would like to switch from SLES to CentOS Squid proxy server and just learned that icap is no longer up-to-date.

Better use eCap, but i am not able to find a good howto telling me how to get it to work in my environment.

Can anybody help me out ?

Thanks, Bj?rn.

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind, informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der enthaltenen Informationen ist nicht gestattet.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind, informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der enthaltenen Informationen ist nicht gestattet.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From sameh.onaissi at solcv.com  Tue Dec 20 14:03:55 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Tue, 20 Dec 2016 14:03:55 +0000
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <6fd126f4-858f-1839-32d7-26a96d92b7f4@treenet.co.nz>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <201612191931.59746.Antony.Stone@squid.open.source.it>
 <DE2F9B11-32A1-44CE-A362-5D3A055D8E39@solcv.com>
 <6fd126f4-858f-1839-32d7-26a96d92b7f4@treenet.co.nz>
Message-ID: <E11BF72C-0400-435F-BFDE-B94F73538303@solcv.com>


On Dec 19, 2016, at 11:55 PM, Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz>> wrote:

On 20/12/2016 9:52 a.m., Sameh Onaissi wrote:

On Dec 19, 2016, at 1:31 PM, Antony Stone wrote:

On Monday 19 December 2016 at 17:44:11, Sameh Onaissi wrote:

Hello,

I was using squid client to get cache stats, however this morning it
completely stopped working.

<center><img src="http://mydomainname.com/squid/access_denied.jpg"
alt="Acceso Denegado" style="width:704px;height:428px;"></center>

the html code is the code of my redirect page whenever a client tries to
access a blacklisted website.

How big is your blacklist?  Could you show us what's in it?

Have you added the proxy itself to the whitelist?

The blacklist consistes of the ads, porn, socialnet and spyware lists of the BL list.

I added both LAN and WAN IPs of the server to the whitelist but didn?t help.


What URL was being requested that got the above access denied response?

Use -vv parameter to squidclient and "debug_options 11,2" in squid.conf
to have the requests header logged and find that out.

This is what shows now:

verbosity level set to 2
Request:
GET cache_object://localhost/info HTTP/1.0
Host: localhost
User-Agent: squidclient/3.5.22
Accept: */*
Connection: close


.
Transport detected: IPv4-mapped  and IPv6
Resolving localhost ...
Connecting... localhost ([::1]:3128)
Connected to: localhost ([::1]:3128)
Sending HTTP request ...
done.
HTTP/1.1 200 OK
Date: Tue, 20 Dec 2016 14:03:46 GMT
Server: Apache/2.4.7 (Ubuntu)
Last-Modified: Fri, 25 Nov 2016 16:55:22 GMT
ETag: "bd-54222fce80317"
Accept-Ranges: bytes
Content-Length: 189
Vary: Accept-Encoding
Content-Type: text/html
Age: 103
X-Cache: HIT from squidpxy.domain.com<http://squidpxy.domain.com>
X-Cache-Lookup: HIT from squidpxy.domain.com<http://squidpxy.domain.com>:3128
Via: 1.1 squidpxy.domain.com<http://squidpxy.domain.com> (squid/3.5.22)
Connection: close

<!DOCTYPE html>
<html>
<body>


<center><img src="http://www.domain.com/squid/access_denied.jpg" alt="Acceso Denegado" style="width:704px;height:428px;"></center>

</body>
</html>

And in the access log:

1482242596.513      0 ::1 TCP_MEM_HIT/200 598 GET cache_object://localhost/info - HIER_NONE/- text/html






So, I changed my default acl setting in squid guard config file to pass all for now (I know it is not ideal), just to monitor the cache as I am trying to get the HIT ratio up. (currently only at 7.8%)

squid guard config: pastebin.com/bbe8CWLE<http://pastebin.com/bbe8CWLE>


So your SG config just does basic IP, URL and time based allow or
redirect decisions.

I suggest you drop SG entirely and move that config into your squid.conf:


# Time rules
# abbrev for weekdays:
# s = sun, m = mon, t =tue, w = wed, h = thu, f = fri, a = sat
acl non-working-hours time MTWHF 18:00-24:00 00:00-08:00
acl non-working-hours time MTWHF 18:00-24:00 00:00-08:00
acl non-working-hours time SA 00:00-24:00

# Source addresses
acl exempt src 10.0.0.90 10.0.0.167
acl youtubers src 10.0.0.1-10.0.0.4
acl localnet src 10.0.0.0/24

# Destination classes
acl blah_domains dstdomain "adv/domains"
acl blah_domains dstdomain "deny/domains"
acl blah_domains dstdomain "porn/domains"
acl blah_domains dstdomain "spyware/domains"
acl blah_domains dstdomain "socialnet/domains"

acl blah_urls dstdom_regex "adv/urls"
acl blah_urls dstdom_regex "deny/urls"
acl blah_urls dstdom_regex "porn/urls"
acl blah_urls dstdom_regex "spyware/urls"
acl blah_urls dstdom_regex "socialnet/urls"

acl stuff_always_blocked anyof blah_domains blah_urls

acl whitelist_domains dstdomain "whitelist/domains"
acl whitelist_urls dstdom_regex "whitelist/urls"
acl whitelist anyof whitelist_domains whitelist_urls
deny_info 302:http://example.com/squid/denegado.html whitelist

acl youtubers_domains dstdomain "socialnet/domains"
acl youtubers_urls dstdom_regex "adv/urls"
acl youtubers anyof youtubers_domains youtubers_urls
deny_info 302:http://example.com/squid/denegado.html youtubers

# Policies
http_access deny !localnet
deny_info 302:http://example.com/squid/denegado.html localnet

http_access allow exempt
http_access allow youtubers !stuff_always_blocked
http_access deny youtubers
http_access allow non-working-hours
http_access allow whitelist !stuff_always_blocked
http_access deny whitelist
http_access allow localnet

deny_info 302:http://example.com/squid/denegado.html all
http_access deny all




squid.conf: http://pastebin.com/TQ8H6bRp

Quote from your config:

acl Safe_ports port 587 #SMTP

Did you read Amos' reply "SMTP is the #1 worst protocol to let anywhere near
an HTTP proxy.  Preventing what you have allowed to happen is one of the
primary reasons Safe_ports exists in the first place!?


The reason I allow 587 is because the Squid Proxy lives on the same
server as a mail server which needs this port, and several clients have
their mail clientes (Outlook..etc) already configured to use this port.

Bogus. You should know it is possible that two pieces of software can
run on one machine without interferring with each other.

Whether or not a mailserver exists on the same machine has nothing to do
with Squid.

Your mailserver itself should be using that port and controlling what
traffic can use it. *HTTP* traffic should never be allowed to flow from
the proxy software through to the mailserver software.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161220/87aa6333/attachment.htm>

From creditu at eml.cc  Tue Dec 20 14:21:40 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Tue, 20 Dec 2016 07:21:40 -0700
Subject: [squid-users] sslpassword_program
In-Reply-To: <1482199136.1103037.824314009.69C9556B@webmail.messagingengine.com>
References: <1482088415.4018167.822848113.09A453E0@webmail.messagingengine.com>
 <CAEnCSG5N7fXNjwSHq7GKvcCtJGpM8Bv0kUOfeFEFcEvacNUGVQ@mail.gmail.com>
 <1482123577.4142040.823185569.4201259E@webmail.messagingengine.com>
 <20921bd3-cbcd-e6f0-1788-abb7907f53ab@treenet.co.nz>
 <1482199136.1103037.824314009.69C9556B@webmail.messagingengine.com>
Message-ID: <1482243700.1266664.824823329.0D9E02B7@webmail.messagingengine.com>



On Mon, Dec 19, 2016, at 06:58 PM, creditu at eml.cc wrote:
> 
> On Sun, Dec 18, 2016, at 11:24 PM, Amos Jeffries wrote:
> > On 19/12/2016 5:59 p.m., creditu wrote:
> > > 
> > > On Sun, Dec 18, 2016, at 01:21 PM, Michael Pelletier wrote:
> > >> Check your file permissions on the key.
> > >>
> > >> On Dec 18, 2016 2:13 PM, creditu wrote:
> > >>
> > >>> I'm having trouble getting the sslpassword_program working for an
> > >>> encrypted key.  Config looks like this:
> > >>>
> > >>> sslpassword_program /usr/local/bin/pass.sh
> > >>> https_port 10.10.10.1:443 accel vhost cert=/etc/squid/www.crt
> > >>> key=/etc/squid/private.key
> > >>>
> > >>> On start, cache log states "Ignoring https_port 10.10.10.1:443 due to
> > >>> SSL initialization failure."
> > >>> On stop, console states "Failed to acquire SSL private key
> > >>> '/etc/squid/private.key': error:0200100D:system library:fopen:Permission
> > >>> denied"
> > >>>
> > >>> Removing the passphrase from the private key, squid starts normally.
> > >>> Permissions on the encrypted and non-encrypted keys are the same.  I
> > >>> also tried putting the pass.sh program in /bin.  The pass.sh program
> > >>> looks like this:
> > >>> #!/bin/sh
> > >>> echo "testing"
> > >>>
> > >>> The hash of the private key modulus and the certificate modulus match as
> > >>> well.
> > >>>
> > >>> Am I missing something? This is on squid 3.1.
> > 
> > If the ideas below don't help can you try an upgrade? there are a few
> > fixes in 3.2 and 3.3 related to that directive.
> > 
> > >>> _______________________________________________
> > > 
> > > Checked the perms and they are identical as the private key that I
> > > stripped the password out of.  They are also in the same directory.  The
> > > one without a password works fine.
> > 
> > The one without a password is being opened by OpenSSL directly.
> > 
> > The one with pssword is being opened in Squid oeprating context, which
> > should be root, but may also be the low-privilege proxy user at the time
> > the script is run.
> > 
> > So you need the key file to be readable by whichever of those privilege
> > contexts Squid is using at the time. (Sorry I can't be more precise, I'm
> > not sure myself which is used in 3.1).
> > 
> > If you have SELinux or AppArmour they may also be interferring with the
> > priviledged access.
> > 
> > The script itself needs either executable permissions set, or squid.conf
> > containing the full shell interpreter path as well as the script path.
> >  ie. "sslpassword_program /bin/sh /usr/local/bin/pass.sh"
> > 
> > 
> > >  Also tried encrypting with des3
> > > versus aes128 and that didn't make a difference either.   Gotta be
> > > missing something.
> > 
> > >  The error points to a perms problem, but not seeing
> > > how since everything is the same.
> > 
> > The error message says fopen() command is not permitted for whichever
> > user account is trying to access the .key file.
> >  It's not clear if that is fopen() of the .key file, or fopen() of the
> > pass.sh file before running it.
> > 
> > The way you describe the issues below hint to me that it is the
> > permission to access the script which is breaking things.
> > 
> > 
> > Also, those old Squid had some issues with processing errno at the wrong
> > times. So there is a small but non-zero chance that the error is
> > actually something else. :-(
> > 
> > 
> > >  Also, added a line in the
> > > sslpassword_program to touch a file to see if it got executed and it
> > > didn't create the file. Additionally, ran the stat command on the 
> > > /usr/local/bin/pass.sh after squid started up
> > 
> > FYI: That test only works if your filesystem has been configured to
> > record access times. Using such a setup with Squid will cause major
> > slowdown as cache related files and logs get accessed *a lot*. So is
> > typically disabled via fstab "noatime" settings if anyone with expertise
> > has tuned the proxy machine before you.
> > 
> > 
> > > and the access time never
> > > changes.  It seems like the shell script may not being executed for some
> > > reason.  I'm able to launch the shell script from the command line and
> > > it echos out the pass fine.
> > 
> > This kind of implies the file permission problem is for Squid to open
> > the script "file" before running whats inside.
> > 
> > Check /usr/local/bin/pass.sh ownership, executable rights, and
> > SELinux/AppArmour permissions (whichever is present on that achine).
> > 
> > Amos
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> 
> Thanks.  Worked down the list and the problem ended up being SELinux. 
> Of course I would have sworn that it was not in enforcing mode.

After getting the SELinux straightened out, I tightened up the perms on
the key file and the pass program.  In my case, the tightest I could set
the perms and still have it work was the key file readable only by root
and the pass program owned by root and the group set to squid.  Both
having execute perms (750). 


From david at articatech.com  Tue Dec 20 14:56:14 2016
From: david at articatech.com (David Touzeau)
Date: Tue, 20 Dec 2016 15:56:14 +0100
Subject: [squid-users] Squid freeze each hour.
In-Reply-To: <003d01d25ac5$285f5840$791e08c0$@ngtech.co.il>
References: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
 <003d01d25ac5$285f5840$791e08c0$@ngtech.co.il>
Message-ID: <02e401d25ad1$36606f40$a3214dc0$@articatech.com>


Thanks Elizer, i will send you squid configuration and cache.log in a separate message

Some things are missing and we need you to fill the picture for us.

What OS are you running squid ontop? --> Debian 7 64 bits
Are you running it in intercept or tproxy mode? --> connected mode.
Are you using ssl-bump? --> No
Are you using it with multiple cores? --> Only one core
Can you attach the squid.conf( removing the confidential details) to this
email?

-----Message d'origine-----
De : Eliezer Croitoru [mailto:eliezer at ngtech.co.il]
Envoy? : mardi 20 d?cembre 2016 14:30
? : 'David Touzeau' <david at articatech.com>;
squid-users at lists.squid-cache.org
Objet : RE: [squid-users] Squid freeze each hour.

Hey David,

Some things are missing and we need you to fill the picture for us.
What OS are you running squid ontop?
Are you running it in intercept or tproxy mode?
Are you using ssl-bump?
Are you using it with multiple cores?
Can you attach the squid.conf( removing the confidential details) to this
email?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of David Touzeau
Sent: Tuesday, December 20, 2016 1:53 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid freeze each hour.

Hi

I'm using the 3.5.23, each hour, the proxy port did not respond for 3 to 10
minutes.
During the freeze have made a -k debug to see whats happening.
Here a piece of log of the log during the freeze:

Is there something relevant ?:

2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 877FE61D1641BCA926338890AF1478D2
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
1024129
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Thu, 08 Dec 2016 15:40:20 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(168) refreshStaleness: FRESH:
expires 1486393228 >= check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= -1
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(461) refreshCheck: Object
isn't stale..
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(463) refreshCheck: returning
FRESH_EXPIRES
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(288) storeDigestAdd:
storeDigestAdd: added entry, key: 877FE61D1641BCA926338890AF1478D2
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87BF2568F0A7D71F1E567579CCC216F7
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
1019863
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Thu, 08 Dec 2016 16:51:26 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481215886 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= 1019863
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must
revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 873F5089579B6B7E351555B77F98259A
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
956460
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Fri, 09 Dec 2016 10:28:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481279289 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= 956460
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must
revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87FFFEA8EBEFAE0DBC21EBC97D405839
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
948473
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Fri, 09 Dec 2016 12:41:16 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(179) refreshStaleness: No
explicit expiry given, using heuristics to determine freshness
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(198) refreshStaleness: Last
modified 19509132 sec before we cached it, L-M factor 75.00% = 14631849 sec
freshness lifetime
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(205) refreshStaleness: FRESH:
age 948473 <= stale_age 14631849
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= -1
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(461) refreshCheck: Object
isn't stale..
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(470) refreshCheck: returning
FRESH_LMFACTOR_RULE
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(288) storeDigestAdd:
storeDigestAdd: added entry, key: 87FFFEA8EBEFAE0DBC21EBC97D405839
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 873F5CB8872FFC57B8D32027D4DC8174
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
520259
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Wed, 14 Dec 2016 11:38:10 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 631151999 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= 851083750
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must
revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87FF2043810CAE2CE015C43DBC3E1004
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(291) refreshCheck: checking
freshness of '<none>'
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
594643
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Tue, 13 Dec 2016 14:58:26 GMT
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481727507 < check_time 1482235749
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness
= 508242
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From david at articatech.com  Tue Dec 20 15:04:42 2016
From: david at articatech.com (David Touzeau)
Date: Tue, 20 Dec 2016 16:04:42 +0100
Subject: [squid-users] Squid freeze each hour.
In-Reply-To: <003d01d25ac5$285f5840$791e08c0$@ngtech.co.il>
References: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
 <003d01d25ac5$285f5840$791e08c0$@ngtech.co.il>
Message-ID: <02f401d25ad2$64ac4850$2e04d8f0$@articatech.com>


Proxy has freezed again and when doing squid -k debug

Many refresh.cc, store_digest.cc, store_dir.cc

After finishing these tasks, proxy will return to be responsive 

2016/12/20 15:27:41.470 kid1| 71,6| store_digest.cc(288) storeDigestAdd: storeDigestAdd: added entry, key: A035B81FB42C32A106E4384A2F17F4B4
2016/12/20 15:27:41.470 kid1| 71,6| store_digest.cc(226) storeDigestAddable: storeDigestAddable: checking entry, key: A07598353220500410873ECDA474BE05
2016/12/20 15:27:41.470 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of 'http://pagead2.googlesyndication.com/activeview?avi=Bddpfgi1ZWMuzC9OS3gOp9KzwCAAAAAAQATgByAEJwAIC4AIA4AQBoAYg&cid=CAASFeRoE1xZjx5ogoC0cxxshgMXQzuIPQ&id=osdim&ti=1&adk=2863166925&p=0,0,0,0&tos=0,0,0,0,0&mtos=0,0,0,0,0&rs=3&ht=0&mc=0&lte=-1&bas=1&bac=1&fp=correlator%3D3261868290981518%26eid%3D108809080%26iu%3D%252F128139881%252FLM_lemonde%252Fa_la_une%252Fa_la_une%252Fhp%252Fbanniere_haute%26oid%3D3%26url%3Dhttp%253A%252F%252Fwww.lemonde.fr%252F&afp=%26output%3Djson_html%26impl%3Dfif%26dt%3D1482239361000%26adx%3D0%26ady%3D216%26ifi%3D4%26flash%3D24.0.0.186&r=u&bs=904,618&bos=160,27&ps=1000,18109&ss=1920,1200&tt=16433&pt=1166&deb=1-7-7-3-8-9&tvt=0&ms=geo&uc=1&tgt=nf&cl=0'
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '. 0 75%% 2592000'
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(314) refreshCheck: 	age:	8280
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(316) refreshCheck: 	check_time:	Tue, 20 Dec 2016 15:27:41 GMT
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(318) refreshCheck: 	entry->timestamp:	Tue, 20 Dec 2016 13:09:41 GMT
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE: expires 631152000 < check_time 1482247661 
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 851095661
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must revalidate stale object (origin set no-cache or private)
2016/12/20 15:27:41.531 kid1| 71,6| store_digest.cc(259) storeDigestAddable: storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 15:27:41.531 kid1| 71,6| store_digest.cc(226) storeDigestAddable: storeDigestAddable: checking entry, key: A035C0F65A81E715DA653BDE6632A99E
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of 'http://img.2ememain.be/f/listthumb/323814646.jpg'
2016/12/20 15:27:41.531 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '\.(jpeg|jpg|jpe|jp2|gif|tiff?|pcx|png|bmp|pic|ico|bif|ver|pict)(\?.*|$) 36000 80%% 604800'
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(314) refreshCheck: 	age:	18430
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(316) refreshCheck: 	check_time:	Tue, 20 Dec 2016 15:27:41 GMT
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(318) refreshCheck: 	entry->timestamp:	Tue, 20 Dec 2016 10:20:31 GMT
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(168) refreshStaleness: FRESH: expires 1643826450 >= check_time 1482247661 
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = -1
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(461) refreshCheck: Object isn't stale..
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(463) refreshCheck: returning FRESH_EXPIRES
2016/12/20 15:27:41.532 kid1| 71,6| store_digest.cc(288) storeDigestAdd: storeDigestAdd: added entry, key: A035C0F65A81E715DA653BDE6632A99E
2016/12/20 15:27:41.532 kid1| 47,3| store_dir.cc(1352) copyBucket: StoreSearchHashIndex::copyBucket #13729
2016/12/20 15:27:41.532 kid1| 47,3| store_dir.cc(1366) copyBucket: got entries: 4
2016/12/20 15:27:41.532 kid1| 71,6| store_digest.cc(226) storeDigestAddable: storeDigestAddable: checking entry, key: A1F528E3C02DAB25C5FB18C8D2EDACEE
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of 'http://static1.hln.be/images/logos/hln_logo.png?6.16.0.20161219'
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '\.(jpeg|jpg|jpe|jp2|gif|tiff?|pcx|png|bmp|pic|ico|bif|ver|pict)(\?.*|$) 36000 80%% 604800'
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(314) refreshCheck: 	age:	13612
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(316) refreshCheck: 	check_time:	Tue, 20 Dec 2016 15:27:41 GMT
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(318) refreshCheck: 	entry->timestamp:	Tue, 20 Dec 2016 11:40:49 GMT
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(168) refreshStaleness: FRESH: expires 1487346358 >= check_time 1482247661 
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = -1
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(461) refreshCheck: Object isn't stale..
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(463) refreshCheck: returning FRESH_EXPIRES
2016/12/20 15:27:41.532 kid1| 71,6| store_digest.cc(288) storeDigestAdd: storeDigestAdd: added entry, key: A1F528E3C02DAB25C5FB18C8D2EDACEE
2016/12/20 15:27:41.532 kid1| 71,6| store_digest.cc(226) storeDigestAddable: storeDigestAddable: checking entry, key: A1F5E4243AA2BD14C147D180CBD5022F
2016/12/20 15:27:41.532 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of 'http://cdn.embedly.com/js/all.c353026a.js'
2016/12/20 15:27:41.533 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '\.js$ 84000 80%% 604800'
2016/12/20 15:27:41.533 kid1| 22,3| refresh.cc(314) refreshCheck: 	age:	11727
2016/12/20 15:27:41.533 kid1| 22,3| refresh.cc(316) refreshCheck: 	check_time:	Tue, 20 Dec 2016 15:27:41 GMT
2016/12/20 15:27:41.533 kid1| 22,3| refresh.cc(318) refreshCheck: 	entry->timestamp:	Tue, 20 Dec 2016 12:12:14 GMT
2016/12/20 15:27:41.533 kid1| 22,3| refresh.cc(168) refreshStaleness: FRESH: expires 1545307934 >= check_time 1482247661 
2016/12/20 15:27:41.533 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = -1
2016/12/20 15:27:41.533 kid1| 22,3| refresh.cc(461) refreshCheck: Object isn't stale..
2016/12/20 15:27:41.533 kid1| 22,3| refresh.cc(463) refreshCheck: returning FRESH_EXPIRES
2016/12/20 15:27:41.533 kid1| 71,6| store_digest.cc(288) storeDigestAdd: storeDigestAdd: added entry, key: A1F5E4243AA2BD14C147D180CBD5022F


-----Message d'origine-----
De : Eliezer Croitoru [mailto:eliezer at ngtech.co.il] 
Envoy? : mardi 20 d?cembre 2016 14:30
? : 'David Touzeau' <david at articatech.com>; squid-users at lists.squid-cache.org
Objet : RE: [squid-users] Squid freeze each hour.

Hey David,

Some things are missing and we need you to fill the picture for us.
What OS are you running squid ontop?
Are you running it in intercept or tproxy mode?
Are you using ssl-bump?
Are you using it with multiple cores?
Can you attach the squid.conf( removing the confidential details) to this email?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of David Touzeau
Sent: Tuesday, December 20, 2016 1:53 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid freeze each hour.

Hi

I'm using the 3.5.23, each hour, the proxy port did not respond for 3 to 10 minutes.
During the freeze have made a -k debug to see whats happening.
Here a piece of log of the log during the freeze:

Is there something relevant ?:

2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 877FE61D1641BCA926338890AF1478D2
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
1024129
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Thu, 08 Dec 2016 15:40:20 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(168) refreshStaleness: FRESH:
expires 1486393228 >= check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = -1
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(461) refreshCheck: Object isn't stale..
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(463) refreshCheck: returning FRESH_EXPIRES
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(288) storeDigestAdd:
storeDigestAdd: added entry, key: 877FE61D1641BCA926338890AF1478D2
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87BF2568F0A7D71F1E567579CCC216F7
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
1019863
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Thu, 08 Dec 2016 16:51:26 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481215886 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 1019863
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 873F5089579B6B7E351555B77F98259A
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
956460
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Fri, 09 Dec 2016 10:28:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481279289 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 956460
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87FFFEA8EBEFAE0DBC21EBC97D405839
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
948473
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Fri, 09 Dec 2016 12:41:16 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(179) refreshStaleness: No explicit expiry given, using heuristics to determine freshness
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(198) refreshStaleness: Last modified 19509132 sec before we cached it, L-M factor 75.00% = 14631849 sec freshness lifetime
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(205) refreshStaleness: FRESH:
age 948473 <= stale_age 14631849
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = -1
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(461) refreshCheck: Object isn't stale..
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(470) refreshCheck: returning FRESH_LMFACTOR_RULE
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(288) storeDigestAdd:
storeDigestAdd: added entry, key: 87FFFEA8EBEFAE0DBC21EBC97D405839
2016/12/20 12:09:09.072 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 873F5CB8872FFC57B8D32027D4DC8174
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
520259
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Wed, 14 Dec 2016 11:38:10 GMT
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 631151999 < check_time 1482235749
2016/12/20 12:09:09.072 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 851083750
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(362) refreshCheck: YES: Must revalidate stale object (origin set no-cache or private)
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(226) storeDigestAddable:
storeDigestAddable: checking entry, key: 87FF2043810CAE2CE015C43DBC3E1004
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(291) refreshCheck: checking freshness of '<none>'
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(312) refreshCheck: Matched '.
0 75%% 2592000'
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(314) refreshCheck:       age:
594643
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(316) refreshCheck:
check_time:     Tue, 20 Dec 2016 12:09:09 GMT
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(318) refreshCheck:
entry->timestamp:       Tue, 13 Dec 2016 14:58:26 GMT
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(173) refreshStaleness: STALE:
expires 1481727507 < check_time 1482235749
2016/12/20 12:09:09.073 kid1| 22,3| refresh.cc(338) refreshCheck: Staleness = 508242
2016/12/20 12:09:09.073 kid1| 71,6| store_digest.cc(259) storeDigestAddable:
storeDigestAdd: entry expires within 3600 secs, ignoring

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From eliezer at ngtech.co.il  Tue Dec 20 15:26:28 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 20 Dec 2016 17:26:28 +0200
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <E11BF72C-0400-435F-BFDE-B94F73538303@solcv.com>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <201612191931.59746.Antony.Stone@squid.open.source.it>
 <DE2F9B11-32A1-44CE-A362-5D3A055D8E39@solcv.com>
 <6fd126f4-858f-1839-32d7-26a96d92b7f4@treenet.co.nz>
 <E11BF72C-0400-435F-BFDE-B94F73538303@solcv.com>
Message-ID: <24fd01d25ad5$6f685c90$4e3915b0$@ngtech.co.il>

It looks like your acls are denying access to the localhost because it's trying to access the proxy using ipv6.
Try to comment the "::1 localhost" line from /etc/hosts and try to see if it's the same.
If it's still not working you will need to write couple rules at the top of the squid.conf files to allow manager interface access from localhost.
Also since squid 3.2 you have the option to use curl or any other tool to access the info pages without squid client which can help you.
Try the next:
# curl http://localhost:3128/squid-internal-mgr/info

And see what happens.
Also if you have some filtering solution in this squid setup you will need to make an exception from this inspection on connections for localhost(both ipv4 and ipv6) since the admin doesn't need these restrictions.

Let me know about the results.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
Sent: Tuesday, December 20, 2016 4:04 PM
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squidcliente stopped working!


On Dec 19, 2016, at 11:55 PM, Amos Jeffries <mailto:squid3 at treenet.co.nz> wrote:

On 20/12/2016 9:52 a.m., Sameh Onaissi wrote:



On Dec 19, 2016, at 1:31 PM, Antony Stone wrote:

On Monday 19 December 2016 at 17:44:11, Sameh Onaissi wrote:


Hello,

I was using squid client to get cache stats, however this morning it
completely stopped working.


<center><img src="http://mydomainname.com/squid/access_denied.jpg"
alt="Acceso Denegado" style="width:704px;height:428px;"></center>


the html code is the code of my redirect page whenever a client tries to
access a blacklisted website.

How big is your blacklist?  Could you show us what's in it?

Have you added the proxy itself to the whitelist?

The blacklist consistes of the ads, porn, socialnet and spyware lists of the BL list. 

I added both LAN and WAN IPs of the server to the whitelist but didn?t help.

What URL was being requested that got the above access denied response?

Use -vv parameter to squidclient and "debug_options 11,2" in squid.conf
to have the requests header logged and find that out.

This is what shows now:

verbosity level set to 2
Request:
GET cache_object://localhost/info HTTP/1.0
Host: localhost
User-Agent: squidclient/3.5.22
Accept: */*
Connection: close


.
Transport detected: IPv4-mapped  and IPv6
Resolving localhost ...
Connecting... localhost ([::1]:3128)
Connected to: localhost ([::1]:3128)
Sending HTTP request ... 
done.
HTTP/1.1 200 OK
Date: Tue, 20 Dec 2016 14:03:46 GMT
Server: Apache/2.4.7 (Ubuntu)
Last-Modified: Fri, 25 Nov 2016 16:55:22 GMT
ETag: "bd-54222fce80317"
Accept-Ranges: bytes
Content-Length: 189
Vary: Accept-Encoding
Content-Type: text/html
Age: 103
X-Cache: HIT from http://squidpxy.domain.com
X-Cache-Lookup: HIT from http://squidpxy.domain.com:3128
Via: 1.1 http://squidpxy.domain.com (squid/3.5.22)
Connection: close

<!DOCTYPE html>
<html>
<body>


<center><img src="http://www.domain.com/squid/access_denied.jpg" alt="Acceso Denegado" style="width:704px;height:428px;"></center>

</body>
</html>


And in the access log:

1482242596.513      0 ::1 TCP_MEM_HIT/200 598 GET cache_object://localhost/info - HIER_NONE/- text/html








So, I changed my default acl setting in squid guard config file to pass all for now (I know it is not ideal), just to monitor the cache as I am trying to get the HIT ratio up. (currently only at 7.8%)

squid guard config: http://pastebin.com/bbe8CWLE

So your SG config just does basic IP, URL and time based allow or
redirect decisions.

I suggest you drop SG entirely and move that config into your squid.conf:


# Time rules
# abbrev for weekdays:
# s = sun, m = mon, t =tue, w = wed, h = thu, f = fri, a = sat
acl non-working-hours time MTWHF 18:00-24:00 00:00-08:00
acl non-working-hours time MTWHF 18:00-24:00 00:00-08:00
acl non-working-hours time SA 00:00-24:00

# Source addresses
acl exempt src 10.0.0.90 10.0.0.167
acl youtubers src 10.0.0.1-10.0.0.4
acl localnet src 10.0.0.0/24

# Destination classes
acl blah_domains dstdomain "adv/domains"
acl blah_domains dstdomain "deny/domains"
acl blah_domains dstdomain "porn/domains"
acl blah_domains dstdomain "spyware/domains"
acl blah_domains dstdomain "socialnet/domains"

acl blah_urls dstdom_regex "adv/urls"
acl blah_urls dstdom_regex "deny/urls"
acl blah_urls dstdom_regex "porn/urls"
acl blah_urls dstdom_regex "spyware/urls"
acl blah_urls dstdom_regex "socialnet/urls"

acl stuff_always_blocked anyof blah_domains blah_urls

acl whitelist_domains dstdomain "whitelist/domains"
acl whitelist_urls dstdom_regex "whitelist/urls"
acl whitelist anyof whitelist_domains whitelist_urls
deny_info 302:http://example.com/squid/denegado.html whitelist

acl youtubers_domains dstdomain "socialnet/domains"
acl youtubers_urls dstdom_regex "adv/urls"
acl youtubers anyof youtubers_domains youtubers_urls
deny_info 302:http://example.com/squid/denegado.html youtubers

# Policies
http_access deny !localnet
deny_info 302:http://example.com/squid/denegado.html localnet

http_access allow exempt
http_access allow youtubers !stuff_always_blocked
http_access deny youtubers
http_access allow non-working-hours
http_access allow whitelist !stuff_always_blocked
http_access deny whitelist
http_access allow localnet

deny_info 302:http://example.com/squid/denegado.html all
http_access deny all







squid.conf: http://pastebin.com/TQ8H6bRp

Quote from your config:

acl Safe_ports port 587 #SMTP

Did you read Amos' reply "SMTP is the #1 worst protocol to let anywhere near 
an HTTP proxy.  Preventing what you have allowed to happen is one of the 
primary reasons Safe_ports exists in the first place!?



The reason I allow 587 is because the Squid Proxy lives on the same
server as a mail server which needs this port, and several clients have
their mail clientes (Outlook..etc) already configured to use this port.

Bogus. You should know it is possible that two pieces of software can
run on one machine without interferring with each other.

Whether or not a mailserver exists on the same machine has nothing to do
with Squid.

Your mailserver itself should be using that port and controlling what
traffic can use it. *HTTP* traffic should never be allowed to flow from
the proxy software through to the mailserver software.

Amos

_______________________________________________
squid-users mailing list
mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From sameh.onaissi at solcv.com  Tue Dec 20 15:39:32 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Tue, 20 Dec 2016 15:39:32 +0000
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <24fd01d25ad5$6f685c90$4e3915b0$@ngtech.co.il>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <201612191931.59746.Antony.Stone@squid.open.source.it>
 <DE2F9B11-32A1-44CE-A362-5D3A055D8E39@solcv.com>
 <6fd126f4-858f-1839-32d7-26a96d92b7f4@treenet.co.nz>
 <E11BF72C-0400-435F-BFDE-B94F73538303@solcv.com>
 <24fd01d25ad5$6f685c90$4e3915b0$@ngtech.co.il>
Message-ID: <0600F3CA-1F9D-48CC-B8F7-F7E4D3E3047F@solcv.com>

Hi Eliezer,
Thanks for the reply.

changing /etc/hosts made no difference, the new log just showed the ipv4 localhost:

verbosity level set to 2
Request:
GET cache_object://localhost/info HTTP/1.0
Host: localhost
User-Agent: squidclient/3.5.22
Accept: */*
Connection: close


.
Transport detected: IPv4-mapped  and IPv6
Resolving localhost ...
Connecting... localhost (127.0.0.1:3128)
Connected to: localhost (127.0.0.1:3128)
Sending HTTP request ...
done.
HTTP/1.1 200 OK
Date: Tue, 20 Dec 2016 15:42:07 GMT
Server: Apache/2.4.7 (Ubuntu)
Last-Modified: Fri, 25 Nov 2016 16:55:22 GMT
ETag: "bd-54222fce80317"
Accept-Ranges: bytes
Content-Length: 189
Vary: Accept-Encoding
Content-Type: text/html
Age: 225
X-Cache: HIT from squidpxy.domain.com<http://squidpxy.domain.com>
X-Cache-Lookup: HIT from squidpxy.domain.com<http://squidpxy.domain.com>:3128
Via: 1.1 squidpxy.domain.com<http://squidpxy.domain.com> (squid/3.5.22)
Connection: close

<!DOCTYPE html>
<html>
<body>


<center><img src="http://www.domain.com/squid/access_denied.jpg" alt="Acceso Denegado" style="width:704px;height:428px;"></center>

</body>
</html>



curl just returns the html code of the access denied page.


On Dec 20, 2016, at 10:26 AM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

curl http://localhost:3128/squid-internal-mgr/info

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161220/e5b1ce9c/attachment.htm>

From eliezer at ngtech.co.il  Tue Dec 20 15:59:11 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 20 Dec 2016 17:59:11 +0200
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <0600F3CA-1F9D-48CC-B8F7-F7E4D3E3047F@solcv.com>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <201612191931.59746.Antony.Stone@squid.open.source.it>
 <DE2F9B11-32A1-44CE-A362-5D3A055D8E39@solcv.com>
 <6fd126f4-858f-1839-32d7-26a96d92b7f4@treenet.co.nz>
 <E11BF72C-0400-435F-BFDE-B94F73538303@solcv.com>
 <24fd01d25ad5$6f685c90$4e3915b0$@ngtech.co.il>
 <0600F3CA-1F9D-48CC-B8F7-F7E4D3E3047F@solcv.com>
Message-ID: <250501d25ada$00f285b0$02d79110$@ngtech.co.il>

The issue is with acls and probably squidguard.
You should add to the configuration something like:
http_access allow localhost manager

and also another line that will deny localhost traffic from being inspected.
If the above as the first line doesn't sort it out I will need squid.conf to
understand what is causing it.
If you want to send the squid.conf privately feel free to do so.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Tuesday, December 20, 2016 5:40 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squidcliente stopped working!

Hi Eliezer, 
Thanks for the reply.

changing /etc/hosts made no difference, the new log just showed the ipv4
localhost:

verbosity level set to 2
Request:
GET cache_object://localhost/info HTTP/1.0
Host: localhost
User-Agent: squidclient/3.5.22
Accept: */*
Connection: close


.
Transport detected: IPv4-mapped? and IPv6
Resolving localhost ...
Connecting... localhost (127.0.0.1:3128)
Connected to: localhost (127.0.0.1:3128)
Sending HTTP request ...?
done.
HTTP/1.1 200 OK
Date: Tue, 20 Dec 2016 15:42:07 GMT
Server: Apache/2.4.7 (Ubuntu)
Last-Modified: Fri, 25 Nov 2016 16:55:22 GMT
ETag: "bd-54222fce80317"
Accept-Ranges: bytes
Content-Length: 189
Vary: Accept-Encoding
Content-Type: text/html
Age: 225
X-Cache: HIT from http://squidpxy.domain.com
X-Cache-Lookup: HIT from http://squidpxy.domain.com:3128
Via: 1.1 http://squidpxy.domain.com (squid/3.5.22)
Connection: close

<!DOCTYPE html>
<html>
<body>


<center><img src="http://www.domain.com/squid/access_denied.jpg" alt="Acceso
Denegado" style="width:704px;height:428px;"></center>

</body>
</html>



curl just returns the html code of the access denied page.


On Dec 20, 2016, at 10:26 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
wrote:

curl?http://localhost:3128/squid-internal-mgr/info




From Antony.Stone at squid.open.source.it  Tue Dec 20 16:11:08 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 20 Dec 2016 17:11:08 +0100
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <250501d25ada$00f285b0$02d79110$@ngtech.co.il>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <0600F3CA-1F9D-48CC-B8F7-F7E4D3E3047F@solcv.com>
 <250501d25ada$00f285b0$02d79110$@ngtech.co.il>
Message-ID: <201612201711.09173.Antony.Stone@squid.open.source.it>

On Tuesday 20 December 2016 at 16:59:11, Eliezer Croitoru wrote:

> The issue is with acls and probably squidguard.
> You should add to the configuration something like:
> http_access allow localhost manager

Er, that line is already in his squid.conf

> and also another line that will deny localhost traffic from being
> inspected. If the above as the first line doesn't sort it out I will need
> squid.conf to understand what is causing it.

I think http://pastebin.com/TQ8H6bRp is what he is working with?


Antony.

-- 
The truth is rarely pure, and never simple.

 - Oscar Wilde

                                                   Please reply to the list;
                                                         please *don't* CC me.


From sameh.onaissi at solcv.com  Tue Dec 20 16:16:17 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Tue, 20 Dec 2016 16:16:17 +0000
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <201612201711.09173.Antony.Stone@squid.open.source.it>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <0600F3CA-1F9D-48CC-B8F7-F7E4D3E3047F@solcv.com>
 <250501d25ada$00f285b0$02d79110$@ngtech.co.il>
 <201612201711.09173.Antony.Stone@squid.open.source.it>
Message-ID: <9FF33F71-4485-44F7-B288-854D6EC72AC9@solcv.com>

Antony is right?.

I have that line in my config file. That is my config that Antony posted (http://pastebin.com/TQ8H6bRp), except I excluded the SMTP port as Amos recommended.

> On Dec 20, 2016, at 11:11 AM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Tuesday 20 December 2016 at 16:59:11, Eliezer Croitoru wrote:
> 
>> The issue is with acls and probably squidguard.
>> You should add to the configuration something like:
>> http_access allow localhost manager
> 
> Er, that line is already in his squid.conf
> 
>> and also another line that will deny localhost traffic from being
>> inspected. If the above as the first line doesn't sort it out I will need
>> squid.conf to understand what is causing it.
> 
> I think http://pastebin.com/TQ8H6bRp is what he is working with?
> 
> 
> Antony.
> 
> -- 
> The truth is rarely pure, and never simple.
> 
> - Oscar Wilde
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From eliezer at ngtech.co.il  Tue Dec 20 16:20:00 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 20 Dec 2016 18:20:00 +0200
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <9FF33F71-4485-44F7-B288-854D6EC72AC9@solcv.com>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <0600F3CA-1F9D-48CC-B8F7-F7E4D3E3047F@solcv.com>
 <250501d25ada$00f285b0$02d79110$@ngtech.co.il>
 <201612201711.09173.Antony.Stone@squid.open.source.it>
 <9FF33F71-4485-44F7-B288-854D6EC72AC9@solcv.com>
Message-ID: <250701d25adc$e9afc040$bd0f40c0$@ngtech.co.il>

What I wrote is that you will need to put it as the first line in the squid.conf file...
But in your case you are using squidguard so you will need to add the next lines in this order:
url_rewrite_access deny localhost
url_rewrite_access allow all

Eliezer

* Anthony thanks for pointing me to the squid.conf paste.

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
Sent: Tuesday, December 20, 2016 6:16 PM
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squidcliente stopped working!

Antony is right?.

I have that line in my config file. That is my config that Antony posted (http://pastebin.com/TQ8H6bRp), except I excluded the SMTP port as Amos recommended.

> On Dec 20, 2016, at 11:11 AM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Tuesday 20 December 2016 at 16:59:11, Eliezer Croitoru wrote:
> 
>> The issue is with acls and probably squidguard.
>> You should add to the configuration something like:
>> http_access allow localhost manager
> 
> Er, that line is already in his squid.conf
> 
>> and also another line that will deny localhost traffic from being 
>> inspected. If the above as the first line doesn't sort it out I will 
>> need squid.conf to understand what is causing it.
> 
> I think http://pastebin.com/TQ8H6bRp is what he is working with?
> 
> 
> Antony.
> 
> --
> The truth is rarely pure, and never simple.
> 
> - Oscar Wilde
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Tue Dec 20 16:20:49 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Dec 2016 09:20:49 -0700
Subject: [squid-users] Squid freeze each hour.
In-Reply-To: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
References: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
Message-ID: <9fe14868-3682-5ef1-943c-498fe690e77a@measurement-factory.com>

On 12/20/2016 04:53 AM, David Touzeau wrote:

> I'm using the 3.5.23, each hour, the proxy port did not respond for 3 to 10
> minutes.

Do you have Cache Digests enabled (either implicitly or explicitly)? If
yes, try disabling them. Others on the list can help you with that if
you cannot figure it out.

If disabling Cache Digests solves the problem, keep them disabled unless
your Squids actually need/use them.


HTH,

Alex.



From sameh.onaissi at solcv.com  Tue Dec 20 16:28:01 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Tue, 20 Dec 2016 16:28:01 +0000
Subject: [squid-users] squidcliente stopped working!
In-Reply-To: <250701d25adc$e9afc040$bd0f40c0$@ngtech.co.il>
References: <16CF6530-41BE-4025-92B2-BE49A8FEEF88@solcv.com>
 <0600F3CA-1F9D-48CC-B8F7-F7E4D3E3047F@solcv.com>
 <250501d25ada$00f285b0$02d79110$@ngtech.co.il>
 <201612201711.09173.Antony.Stone@squid.open.source.it>
 <9FF33F71-4485-44F7-B288-854D6EC72AC9@solcv.com>
 <250701d25adc$e9afc040$bd0f40c0$@ngtech.co.il>
Message-ID: <2C45F0EA-4D18-4443-8034-34AA5D76BD63@solcv.com>

That did it.

Again, Thanks Eliezer! I really appreciate it. 




> On Dec 20, 2016, at 11:20 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> What I wrote is that you will need to put it as the first line in the squid.conf file...
> But in your case you are using squidguard so you will need to add the next lines in this order:
> url_rewrite_access deny localhost
> url_rewrite_access allow all
> 
> Eliezer
> 
> * Anthony thanks for pointing me to the squid.conf paste.
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
> Sent: Tuesday, December 20, 2016 6:16 PM
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] squidcliente stopped working!
> 
> Antony is right?.
> 
> I have that line in my config file. That is my config that Antony posted (http://pastebin.com/TQ8H6bRp), except I excluded the SMTP port as Amos recommended.
> 
>> On Dec 20, 2016, at 11:11 AM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
>> 
>> On Tuesday 20 December 2016 at 16:59:11, Eliezer Croitoru wrote:
>> 
>>> The issue is with acls and probably squidguard.
>>> You should add to the configuration something like:
>>> http_access allow localhost manager
>> 
>> Er, that line is already in his squid.conf
>> 
>>> and also another line that will deny localhost traffic from being 
>>> inspected. If the above as the first line doesn't sort it out I will 
>>> need squid.conf to understand what is causing it.
>> 
>> I think http://pastebin.com/TQ8H6bRp is what he is working with?
>> 
>> 
>> Antony.
>> 
>> --
>> The truth is rarely pure, and never simple.
>> 
>> - Oscar Wilde
>> 
>>                                                  Please reply to the list;
>>                                                        please *don't* CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From rousskov at measurement-factory.com  Tue Dec 20 16:38:46 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Dec 2016 09:38:46 -0700
Subject: [squid-users] Help: How to calculate all bytes when communicate
 with client for a request
In-Reply-To: <PS1PR01MB13062EF0025C299B8F4ECCC498900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
References: <PS1PR01MB130674C70AA4CEC08590F0F898900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
 <PS1PR01MB13062EF0025C299B8F4ECCC498900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
Message-ID: <e2c334d8-4501-2005-ccac-6a19bc6024bc@measurement-factory.com>

On 12/20/2016 03:56 AM, wei wrote:

> I want to calculate all bytes when a request is sent to squid,

According to squid.conf.documented, you can use the following logformat
%codes to get unencrypted HTTP request sizes:


> including:

>  1. the header length that client will send to squid

[http::]>sh     Size of request headers received from client


>  2. the post content length that send to squid

[http::]>st     Total size of request received from client.

minus

[http::]>sh     Size of request headers received from client


>  3. the response length squid will reply to client


[http::]<st     Total size of reply sent to client (after adaptation)

minus

[http::]<sh     Size of reply headers sent to client (after adaptation)


Please note that you need Squid v3.5.22 or later for many size-related
logformat %codes to work reasonably well in some environments. There
were many size logging bugs in earlier versions!

If some of these %codes do not work in your tests with the latest Squid,
please consider filing a but report with an isolated test case
illustrating the problem.


> I don't need to know the request content, just want to know how many
> bytes the client totally send including the post and https bytes, is it
> possible to do this?

The only way to measure the size of encrypted HTTP message parts is to
decrypt that message. Thus, if you want to log HTTPS POST body sizes (as
opposed to just the number of encrypted bytes received from the HTTPS
client), then you have to tell Squid to decrypt that traffic. In most
cases, decryption is not worth the associated headaches if you just want
to log sizes.


HTH,

Alex.



From david at articatech.com  Tue Dec 20 16:42:49 2016
From: david at articatech.com (David Touzeau)
Date: Tue, 20 Dec 2016 17:42:49 +0100
Subject: [squid-users] Squid freeze each hour.
In-Reply-To: <9fe14868-3682-5ef1-943c-498fe690e77a@measurement-factory.com>
References: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
 <9fe14868-3682-5ef1-943c-498fe690e77a@measurement-factory.com>
Message-ID: <036301d25ae0$1a08e390$4e1aaab0$@articatech.com>

Hi Alex,

Is there any way to disabling Cache digest without need to recompile squid ?

-----Message d'origine-----
De : Alex Rousskov [mailto:rousskov at measurement-factory.com] 
Envoy? : mardi 20 d?cembre 2016 17:21
? : squid-users at lists.squid-cache.org
Cc : David Touzeau <david at articatech.com>
Objet : Re: [squid-users] Squid freeze each hour.

On 12/20/2016 04:53 AM, David Touzeau wrote:

> I'm using the 3.5.23, each hour, the proxy port did not respond for 3 
> to 10 minutes.

Do you have Cache Digests enabled (either implicitly or explicitly)? If yes, try disabling them. Others on the list can help you with that if you cannot figure it out.

If disabling Cache Digests solves the problem, keep them disabled unless your Squids actually need/use them.


HTH,

Alex.




From rousskov at measurement-factory.com  Tue Dec 20 16:57:17 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Dec 2016 09:57:17 -0700
Subject: [squid-users] Squid Websocket Issue
In-Reply-To: <CA+sSnVbob7T03YvK8RCHmd4o=9Ej8NZ6vhmgKj+h75hnB1EXdQ@mail.gmail.com>
References: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
 <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>
 <CA+sSnVZYcQkvA=-bBVSuQtoXeYxomL5Ca51cw4ax0dP3EUKF7g@mail.gmail.com>
 <5990ba78-39ea-569a-29dd-409e4912f1a6@treenet.co.nz>
 <010401d259f9$4dfcd630$e9f68290$@ngtech.co.il>
 <CA+sSnVavKQR80XNvykdecMeB1feLwBMEP29Vm+Lxp3=U8-S1dg@mail.gmail.com>
 <CA+sSnVbob7T03YvK8RCHmd4o=9Ej8NZ6vhmgKj+h75hnB1EXdQ@mail.gmail.com>
Message-ID: <b858d071-bc6c-1789-c72b-d1b9343b32e5@measurement-factory.com>

On 12/20/2016 02:42 AM, Hardik Dangar wrote:
> Following changes in config works and whatsapp starts working,
> 
> acl serverIsws ssl::server_name_regex ^w[0-9]+\.web\.whatsapp\.com$
> 
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump splice serverIsws
> ssl_bump bump !serverIsws all

You do not need the "!serverIsws" part because if serverIsws matches,
then the splice rule wins, and Squid does not reach the bump rule. This
configuration is sufficient:

  ssl_bump peek step1
  ssl_bump splice serverIsws
  ssl_bump bump all

In theory, adding "!serverIsws" does not hurt. However, negating complex
ACLs is tricky/dangerous and should be avoided when possible.

Alex.



From garryd at comnet.uz  Tue Dec 20 17:57:54 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Tue, 20 Dec 2016 22:57:54 +0500
Subject: [squid-users] Squid freeze each hour.
In-Reply-To: <036301d25ae0$1a08e390$4e1aaab0$@articatech.com>
References: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
 <9fe14868-3682-5ef1-943c-498fe690e77a@measurement-factory.com>
 <036301d25ae0$1a08e390$4e1aaab0$@articatech.com>
Message-ID: <0dffbcdae6cbb7f56ecefd9495ddaf25@comnet.uz>

On 2016-12-20 21:42, David Touzeau wrote:
> Is there any way to disabling Cache digest without need to recompile 
> squid ?

Hi,

Use "digest_generation off".

http://www.squid-cache.org/Doc/config/digest_generation/


Garri


From david at articatech.com  Tue Dec 20 20:39:42 2016
From: david at articatech.com (David Touzeau)
Date: Tue, 20 Dec 2016 21:39:42 +0100
Subject: [squid-users] Squid freeze each hour.
In-Reply-To: <0dffbcdae6cbb7f56ecefd9495ddaf25@comnet.uz>
References: <02be01d25ab7$adfc16e0$09f444a0$@articatech.com>
 <9fe14868-3682-5ef1-943c-498fe690e77a@measurement-factory.com>
 <036301d25ae0$1a08e390$4e1aaab0$@articatech.com>
 <0dffbcdae6cbb7f56ecefd9495ddaf25@comnet.uz>
Message-ID: <03c701d25b01$3666b000$a3341000$@articatech.com>

Thanks, 

I'm test it now

-----Message d'origine-----
De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Garri Djavadyan
Envoy? : mardi 20 d?cembre 2016 18:58
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] Squid freeze each hour.

On 2016-12-20 21:42, David Touzeau wrote:
> Is there any way to disabling Cache digest without need to recompile 
> squid ?

Hi,

Use "digest_generation off".

http://www.squid-cache.org/Doc/config/digest_generation/


Garri
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From edwin.zhou at hotmail.com  Wed Dec 21 04:09:37 2016
From: edwin.zhou at hotmail.com (wei)
Date: Wed, 21 Dec 2016 04:09:37 +0000
Subject: [squid-users] Help: How to calculate all bytes when communicate
 with client for a request
In-Reply-To: <e2c334d8-4501-2005-ccac-6a19bc6024bc@measurement-factory.com>
References: <PS1PR01MB130674C70AA4CEC08590F0F898900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
 <PS1PR01MB13062EF0025C299B8F4ECCC498900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>,
 <e2c334d8-4501-2005-ccac-6a19bc6024bc@measurement-factory.com>
Message-ID: <PS1PR01MB130668D47038EA8944175F6598930@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>

Hi Alex,


Many thanks for your reply and sorry for the misleading. In fact I just want to log the number of encrypted bytes received from the HTTPS client, not the decrypted HTTPS body sizes. Do you know how to do this?


I also build squid 3.5.23 with default parameter, and seems squid log still ignore the encrypted bytes(except "CONNECT" header) that the client send to squid server.


Below is two Get and Post commands and you can see there is no difference with their total size(%st 3520) in the logs:

curl --proxy 48.96.17.25:3128  https://showip.net
curl --proxy 48.96.17.25:3128 -d'test' https://showip.net

1482292236.816   1700 48.96.17.25 TCP_TUNNEL/200 3408 112 3520 0 112 CONNECT showip.net:443 - HIER_DIRECT/showip.net:23.253.100.206 -
1482292258.735   1234 48.96.17.25 TCP_TUNNEL/200 3408 112 3520 0 112 CONNECT showip.net:443 - HIER_DIRECT/showip.net:23.253.100.206 -

logformat in squid.conf is:
logformat squid %ts.%03tu %6tr %>a %Ss/%03Hs %<st %>st %st %<sh %>sh %rm %ru %un %Sh/%<A:%<a %mt

For Https, %>st is supposed to be "Total bytes received from client" and %st is supposed to be "Total bytes received from client and sent to client", right? But why they have no change while the client send more data to squid server? Is this a bug?

Thanks for all your help!

Regards,
Edwin

________________________________
On 20 December 2016 at 16:38, Alex Rousskov <rousskov at measurement-factory.com> wrote:

> I want to calculate all bytes when a request is sent to squid,

According to squid.conf.documented, you can use the following logformat
%codes to get unencrypted HTTP request sizes:


> including:

>  1. the header length that client will send to squid

[http::]>sh     Size of request headers received from client


>  2. the post content length that send to squid

[http::]>st     Total size of request received from client.

minus

[http::]>sh     Size of request headers received from client


>  3. the response length squid will reply to client


[http::]<st     Total size of reply sent to client (after adaptation)

minus

[http::]<sh     Size of reply headers sent to client (after adaptation)


Please note that you need Squid v3.5.22 or later for many size-related
logformat %codes to work reasonably well in some environments. There
were many size logging bugs in earlier versions!

If some of these %codes do not work in your tests with the latest Squid,
please consider filing a but report with an isolated test case
illustrating the problem.


> I don't need to know the request content, just want to know how many
> bytes the client totally send including the post and https bytes, is it
> possible to do this?

The only way to measure the size of encrypted HTTP message parts is to
decrypt that message. Thus, if you want to log HTTPS POST body sizes (as
opposed to just the number of encrypted bytes received from the HTTPS
client), then you have to tell Squid to decrypt that traffic. In most
cases, decryption is not worth the associated headaches if you just want
to log sizes.


HTH,

Alex.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161221/266d9413/attachment.htm>

From rafael.akchurin at diladele.com  Wed Dec 21 08:51:53 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 21 Dec 2016 08:51:53 +0000
Subject: [squid-users] Squid 3.5.23-1 is available for Ubuntu 16.04 LTS
 (online repo ubuntu16.diladele.com)
Message-ID: <DB6PR0401MB26808172DDFE4A59040671378F930@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Greetings everyone,



The Squid 3.5.23-1 package for Ubuntu 16.04 LTS is now available. This version is recompiled using Squid DEB source from Debian Testing with some changes required to support SSL bump / libecap3 on Ubuntu 16.04 LTS.



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.23-RELEASENOTES.html

* The online repo is at http://ubuntu16.diladele.com/

* Tutorial showing how we rebuilt Squid 3.5.23 on Ubuntu 16.04 LTS http://docs.diladele.com/tutorials/build_squid_ubuntu16/index.html

* Scripts we used to build it are at https://github.com/diladele/squid-ubuntu



If you have installed previous version from this repo then please run "sudo apt-get update && sudo apt-get upgrade".  Please also check that your current squid.conf file from previous version is not overwritten.

If you are installing this version for the first time run the following commands:



    # add diladele apt key

    wget -qO - http://packages.diladele.com/diladele_pub.asc | apt-key add -



    # add repo

    echo "deb http://ubuntu16.diladele.com/ubuntu/ xenial main" > /etc/apt/sources.list.d/ubuntu16.diladele.com.list



    # update the apt cache

    apt-get update



    # install

    apt-get install libecap3

    apt-get install squid-common

    apt-get install squid

    apt-get install squidclient



All questions/comments and suggestions are welcome at support at diladele.com<mailto:support at diladele.com> or here in the mailing list.



Best regards,

Rafael Akchurin

Diladele B.V.

https://www.diladele.com/



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at https://www.diladele.com/.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161221/362c4c48/attachment.htm>

From bjoern.wahl at hospital-borken.de  Wed Dec 21 10:24:16 2016
From: bjoern.wahl at hospital-borken.de (bjoern wahl)
Date: Wed, 21 Dec 2016 11:24:16 +0100
Subject: [squid-users] CentOS Linux 7 / squid-3.5.20-2.el7.x86_64 / LDAP /
 ECAP / squidGuard blacklisting
Message-ID: <585A66600200000900024428@mail01.hospital-borken.de>

Hello!

Just for those who would like to have a:

Squid with Ldap user auth on an eDirectory with an ecap (watch out ! It
is not i-cap!) virus check and squidGuard for blacklisting.

One think not working for me so far is the redirect to a virus info site
if ecap/clamd did find a virus. By now the user is informed that the
access was "denied" but not why. A thing i do not like with this setup
right now. (still working on this!)

The working squid.conf looks like this:

=================================================================
cache_mgr xxx at mail.de
http_port IPADDRESSOFSERVER:3128
acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines
acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT
auth_param basic program /usr/lib64/squid/basic_ldap_auth -b o=XXXX -h
IPOFEDIRSERVER -D cn=XXX,o=XXX -w PASSWORDOFUSER -f
"(&(objectclass=User)(cn=%s))"
auth_param basic children 5
auth_param basic realm WHATEVER-YOU-LIKE-TO-TELL-THE-USER
auth_param basic credentialsttl 2 hours
ecap_enable on
loadable_modules /usr/local/lib/ecap_clamav_adapter.so
ecap_service clamav_service_req reqmod_precache
uri=ecap://e-cap.org/ecap/services/clamav?mode=REQMOD bypass=off
ecap_service clamav_service_resp respmod_precache
uri=ecap://e-cap.org/ecap/services/clamav?mode=RESPMOD bypass=on
adaptation_access clamav_service_req allow all
adaptation_access clamav_service_resp allow all
acl ediruser proxy_auth REQUIRED
http_access allow ediruser
http_access deny all
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny all
http_port 3128
coredump_dir /var/spool/squid
refresh_pattern ^ftp:        1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
refresh_pattern .        0    20%    4320
url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidGuard.conf
url_rewrite_children 15
url_rewrite_access allow all
======================================================================================================================

Thanks for all the help!

Bj?rn

Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.





From rousskov at measurement-factory.com  Wed Dec 21 15:13:43 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 21 Dec 2016 08:13:43 -0700
Subject: [squid-users] Help: How to calculate all bytes when communicate
 with client for a request
In-Reply-To: <PS1PR01MB130668D47038EA8944175F6598930@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
References: <PS1PR01MB130674C70AA4CEC08590F0F898900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
 <PS1PR01MB13062EF0025C299B8F4ECCC498900@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
 <e2c334d8-4501-2005-ccac-6a19bc6024bc@measurement-factory.com>
 <PS1PR01MB130668D47038EA8944175F6598930@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
Message-ID: <70a54957-c33e-b0d6-77c8-1ac142b2fe7e@measurement-factory.com>

On 12/20/2016 09:09 PM, wei wrote:
> Below is two Get and Post commands and you can see there is no
> difference with their total size(%st 3520) in the logs:
> 
> curl --proxy 48.96.17.25:3128  https://showip.net
> curl --proxy 48.96.17.25:3128 -d'test' https://showip.net
> 
> 1482292236.816   1700 48.96.17.25 TCP_TUNNEL/200 3408*112 3520 *0 112
> CONNECT showip.net:443 - HIER_DIRECT/showip.net:23.253.100.206 -
> 1482292258.735   1234 48.96.17.25 TCP_TUNNEL/200 3408*112 3520 *0 112
> CONNECT showip.net:443 - HIER_DIRECT/showip.net:23.253.100.206 -
> 
> logformat in squid.conf is:
> logformat squid %ts.%03tu %6tr %>a %Ss/%03Hs %<st*%>st %st *%<sh %>sh
> %rm %ru %un %Sh/%<A:%<a %mt**
> 
> For Https, %>st is supposed to be "Total bytes received from client" and
> %st is supposed to be "Total bytes received from client and sent to
> client", right? 

Correct.

> But why they have no change while the client send more
> data to squid server? Is this a bug?

If your Squid does not use SslBump features, then most likely this is a
tunneling code bug in Squid.

Alex.



From sameh.onaissi at solcv.com  Wed Dec 21 17:14:16 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 21 Dec 2016 17:14:16 +0000
Subject: [squid-users] Bypassed Proxy
Message-ID: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>

Hello all,

I got a transparent squid installed on Ubuntu 16.04

Using squid guard, I am blocking certain websites, including youtube.

Anytime a user tries accessing it, he/she is redirected to an access denied page.

Except for ONE user!

One user is somehow, able to access you tube through squid!
That IP is not on the exempt list, and has no special configurations.

access.log:

1482339083.228      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443 - HIER_NONE/- text/html
1482339083.324      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443 - HIER_NONE/- text/html
1482339083.331      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443 - HIER_NONE/- text/html
1482339083.422      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443 - HIER_NONE/- text/html
1482339083.436      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443 - HIER_NONE/- text/html
1482339083.517      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443 - HIER_NONE/- text/html
1482339086.251      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443 - HIER_NONE/- text/html

Any other user tries and gets:

1482339588.002    350 10.0.0.40 TCP_MISS/200 611 GET https://www.youtube.com/ - HIER_DIRECT/190.xxx.xxx.xxx text/html

That is the redirect html page.

My deny list where youtube is:

var/lib/squidguard/db/deny/urls has www.youtube.com<http://www.youtube.com>
var/lib/squidguard/db/deny/domains has youtube.com<http://youtube.com>


Any idea to how he is doing it?

I can add a rule to specifically deny 10.0.0.162, but I want to know how he is doing it to prevent it for others. Also this is a dynamic IP.

Thank you,
Sam



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161221/e8e4b869/attachment.htm>

From eliezer at ngtech.co.il  Wed Dec 21 18:43:50 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 21 Dec 2016 20:43:50 +0200
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
Message-ID: <267a01d25bba$2c34ace0$849e06a0$@ngtech.co.il>

How does squid.conf looks now?
It?s probably a typo or some settings exception.
You need to debug and check first if squidguard receives the request details
and what it does with it.
To see the relevant details you will need to use squid debug_options:
http://wiki.squid-cache.org/KnowledgeBase/DebugSections

Specifically section 61.
You should add to squid.conf the line
debug_options ALL,1 61,6

And your cache.log will be flooded with details about any request that is
being passed to squidguard.
I believe that this should be a start point that will show you if squid is
sending the request to squidguard and how squidguard answers.
If you want more help share with a paste the current squid.conf and
squidguard.conf.
This way even if it?s not related directly to squid we can see if there is a
hole in the setup you don?t see yet.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Sameh Onaissi
Sent: Wednesday, December 21, 2016 7:14 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Bypassed Proxy

Hello all, 

I got a transparent squid installed on Ubuntu 16.04

Using squid guard, I am blocking certain websites, including youtube.

Anytime a user tries accessing it, he/she is redirected to an access denied
page.

Except for ONE user!

One user is somehow, able to access you tube through squid!
That IP is not on the exempt list, and has no special configurations.

access.log:

1482339083.228? ? ? 0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.324? ? ? 0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.331? ? ? 0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.422? ? ? 0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.436? ? ? 0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.517? ? ? 0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339086.251? ? ? 0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html


Any other user tries and gets:

1482339588.002? ? 350 10.0.0.40 TCP_MISS/200 611 GET
https://www.youtube.com/ - HIER_DIRECT/190.xxx.xxx.xxx text/html

That is the redirect html page.

My deny list where youtube is:

var/lib/squidguard/db/deny/urls has http://www.youtube.com
var/lib/squidguard/db/deny/domains has http://youtube.com


Any idea to how he is doing it?

I can add a rule to specifically deny 10.0.0.162, but I want to know how he
is doing it to prevent it for others. Also this is a dynamic IP.

Thank you,
Sam






From pheriko.support at gmail.com  Wed Dec 21 20:49:26 2016
From: pheriko.support at gmail.com (Periko Support)
Date: Wed, 21 Dec 2016 12:49:26 -0800
Subject: [squid-users] Pre-Built Binary Packages: squid_ldap_auth: (2) No
	such file or directory
Message-ID: <CAK2yrTbK0Ve5yKCsaGg9rNzpD4CW6ZauBm9L35PH+Rq4K=F_TQ@mail.gmail.com>

Hi.

We are testing squid 3.5 from:

http://wiki.squid-cache.org/KnowledgeBase/CentOS#Squid-3.5

But we got some issue, our server requieres auth to a local LDAP server.

But looks like it was build without this module.

Can some one confirm this?

squid -z
2016/12/21 12:40:00| ERROR: Authentication helper program
/usr/lib64/squid/squid_ldap_auth: (2) No such file or directory
FATAL: Authentication helper program /usr/lib64/squid/squid_ldap_auth:
(2) No such file or directory
Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.006 seconds = 0.005 user + 0.001 sys
Maximum Resident Size: 30512 KB
Page faults with physical i/o: 0

Centos 6.x x64, thanks.


From eliezer at ngtech.co.il  Wed Dec 21 21:40:35 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 21 Dec 2016 23:40:35 +0200
Subject: [squid-users] Pre-Built Binary Packages: squid_ldap_auth: (2)
	No	such file or directory
In-Reply-To: <CAK2yrTbK0Ve5yKCsaGg9rNzpD4CW6ZauBm9L35PH+Rq4K=F_TQ@mail.gmail.com>
References: <CAK2yrTbK0Ve5yKCsaGg9rNzpD4CW6ZauBm9L35PH+Rq4K=F_TQ@mail.gmail.com>
Message-ID: <26a601d25bd2$dd3b8190$97b284b0$@ngtech.co.il>

Hey,

These were built with support for ldap auth but the name of the binary was kept as it was by squid.
The package of squid from my repository was split into the "main" binary and "helpers".
This allows whoever that want's to install squid without resulting or being required to install all sort of other un-needed dependencies that is being caused by external helpers.
So first if you haven't installed the "squid-helpers" package install it from the repo.
Then if you are still missing the file then it might be because of it has another name then expected by the admin.
Maybe in the past the name was specific but it should be something else.
Here is the list of helpers in the squid-helpers latest rpm:
eliezer at www: /tmp/helpers$  rpm2cpio /mnt/squid-repos/centos/7/x86_64/squid-helpers-3.5.23-1.el7.centos.x86_64.rpm |cpio -idmv
./usr/lib64/squid/basic_db_auth
./usr/lib64/squid/basic_fake_auth
./usr/lib64/squid/basic_getpwnam_auth
./usr/lib64/squid/basic_ldap_auth
./usr/lib64/squid/basic_ncsa_auth
./usr/lib64/squid/basic_nis_auth
./usr/lib64/squid/basic_pam_auth
./usr/lib64/squid/basic_pop3_auth
./usr/lib64/squid/basic_radius_auth
./usr/lib64/squid/basic_sasl_auth
./usr/lib64/squid/basic_smb_auth
./usr/lib64/squid/basic_smb_auth.sh
./usr/lib64/squid/cachemgr.cgi
./usr/lib64/squid/cert_tool
./usr/lib64/squid/cert_valid.pl
./usr/lib64/squid/digest_edirectory_auth
./usr/lib64/squid/digest_file_auth
./usr/lib64/squid/digest_ldap_auth
./usr/lib64/squid/ext_delayer_acl
./usr/lib64/squid/ext_file_userip_acl
./usr/lib64/squid/ext_kerberos_ldap_group_acl
./usr/lib64/squid/ext_ldap_group_acl
./usr/lib64/squid/ext_session_acl
./usr/lib64/squid/ext_sql_session_acl
./usr/lib64/squid/ext_time_quota_acl
./usr/lib64/squid/ext_unix_group_acl
./usr/lib64/squid/ext_wbinfo_group_acl
./usr/lib64/squid/helper-mux.pl
./usr/lib64/squid/log_db_daemon
./usr/lib64/squid/negotiate_kerberos_auth
./usr/lib64/squid/negotiate_kerberos_auth_test
./usr/lib64/squid/negotiate_wrapper_auth
./usr/lib64/squid/ntlm_fake_auth
./usr/lib64/squid/ntlm_smb_lm_auth
./usr/lib64/squid/ssl_crtd
./usr/lib64/squid/storeid_file_rewrite
./usr/lib64/squid/url_fake_rewrite
./usr/lib64/squid/url_fake_rewrite.sh
1553 blocks

And from that I assume that the file you seek is:
/usr/lib64/squid/basic_ldap_auth
And if you want you can use a tiny symbolic link to keep the same name and location in your squid.conf using:
# ln -s /usr/lib64/squid/basic_ldap_auth /usr/lib64/squid/squid_ldap_auth

Let me know if something is missing( I have yet to force the repository version update but will do so in the next hours),
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Periko Support
Sent: Wednesday, December 21, 2016 10:49 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Pre-Built Binary Packages: squid_ldap_auth: (2) No such file or directory

Hi.

We are testing squid 3.5 from:

http://wiki.squid-cache.org/KnowledgeBase/CentOS#Squid-3.5

But we got some issue, our server requieres auth to a local LDAP server.

But looks like it was build without this module.

Can some one confirm this?

squid -z
2016/12/21 12:40:00| ERROR: Authentication helper program
/usr/lib64/squid/squid_ldap_auth: (2) No such file or directory
FATAL: Authentication helper program /usr/lib64/squid/squid_ldap_auth:
(2) No such file or directory
Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.006 seconds = 0.005 user + 0.001 sys Maximum Resident Size: 30512 KB Page faults with physical i/o: 0

Centos 6.x x64, thanks.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From sameh.onaissi at solcv.com  Wed Dec 21 22:19:41 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Wed, 21 Dec 2016 22:19:41 +0000
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <267a01d25bba$2c34ace0$849e06a0$@ngtech.co.il>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <267a01d25bba$2c34ace0$849e06a0$@ngtech.co.il>
Message-ID: <1EC2EFE5-FDC0-4537-8E42-7601BE494CC6@solcv.com>

HI Eliezer,


squid.conf: http://pastebin.com/7Nusciiu

sqiudguard.conf: http://pastebin.com/DiRgD23c


I think the client is using a Google chrome extension: https://chrome.google.com/webstore/detail/hotspot-shield-free-vpn-p/nlbejmccbhkncgokjcmghpfloaajcffj?hl=en

(can?t get cache logs now as client is disconnected)




On Dec 21, 2016, at 1:43 PM, Eliezer Croitoru <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>> wrote:

How does squid.conf looks now?
It?s probably a typo or some settings exception.
You need to debug and check first if squidguard receives the request details
and what it does with it.
To see the relevant details you will need to use squid debug_options:
http://wiki.squid-cache.org/KnowledgeBase/DebugSections

Specifically section 61.
You should add to squid.conf the line
debug_options ALL,1 61,6

And your cache.log will be flooded with details about any request that is
being passed to squidguard.
I believe that this should be a start point that will show you if squid is
sending the request to squidguard and how squidguard answers.
If you want more help share with a paste the current squid.conf and
squidguard.conf.
This way even if it?s not related directly to squid we can see if there is a
hole in the setup you don?t see yet.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Sameh Onaissi
Sent: Wednesday, December 21, 2016 7:14 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Bypassed Proxy

Hello all,

I got a transparent squid installed on Ubuntu 16.04

Using squid guard, I am blocking certain websites, including youtube.

Anytime a user tries accessing it, he/she is redirected to an access denied
page.

Except for ONE user!

One user is somehow, able to access you tube through squid!
That IP is not on the exempt list, and has no special configurations.

access.log:

1482339083.228      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.324      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.331      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.422      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.436      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.517      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339086.251      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html


Any other user tries and gets:

1482339588.002    350 10.0.0.40 TCP_MISS/200 611 GET
https://www.youtube.com/ - HIER_DIRECT/190.xxx.xxx.xxx text/html

That is the redirect html page.

My deny list where youtube is:

var/lib/squidguard/db/deny/urls has http://www.youtube.com
var/lib/squidguard/db/deny/domains has http://youtube.com


Any idea to how he is doing it?

I can add a rule to specifically deny 10.0.0.162, but I want to know how he
is doing it to prevent it for others. Also this is a dynamic IP.

Thank you,
Sam





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161221/b242926b/attachment.htm>

From eliezer at ngtech.co.il  Wed Dec 21 23:09:46 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 22 Dec 2016 01:09:46 +0200
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <1EC2EFE5-FDC0-4537-8E42-7601BE494CC6@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <267a01d25bba$2c34ace0$849e06a0$@ngtech.co.il>
 <1EC2EFE5-FDC0-4537-8E42-7601BE494CC6@solcv.com>
Message-ID: <26e901d25bdf$527f8850$f77e98f0$@ngtech.co.il>

Try to see what happens when you change and simplify squidguard conf(after a backup) to a one default which blocks youtube.
This way you would be able to minimize the options from squidguard to squid or backwards.
Try to follow the cache.log and see if you see anything about anything which mentions "youtube".

The options for the issue are one of two:
Squidguard is configured wrong or has a bug
Squid is configured wrong or has a bug

I cannot say that squid is 100% bullet proof but first analyze the logs to see what happens and if you need to block youtube specifically I would do it in the squid level rather then in squidguard level since it's a very simple and tiny and static rule.
And leaving the beauty of the splash page and just block add the next lines to the beginning of squid.conf:
#YT DOMS
acl ytdoms dstdomain .youtube.com .ytimg.com .googlevideo.com
acl ytallowedusers src 10.0.0.1/32 10.0.0.2/32
http_access deny ytdoms !ytallowedusers
##END OF ADDITION

If you wish to allow a specific user to access these domains just add them to the ytallowedusers acl.
Use squidguard only for things which needs more frequent updates.

All The Bests,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sameh Onaissi [mailto:sameh.onaissi at solcv.com] 
Sent: Thursday, December 22, 2016 12:20 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Bypassed Proxy

HI Eliezer, 


squid.conf: http://pastebin.com/7Nusciiu

sqiudguard.conf: http://pastebin.com/DiRgD23c


I think the client is using a Google chrome extension: https://chrome.google.com/webstore/detail/hotspot-shield-free-vpn-p/nlbejmccbhkncgokjcmghpfloaajcffj?hl=en

(can?t get cache logs now as client is disconnected)




On Dec 21, 2016, at 1:43 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:

How does squid.conf looks now?
It?s probably a typo or some settings exception.
You need to debug and check first if squidguard receives the request details
and what it does with it.
To see the relevant details you will need to use squid debug_options:
http://wiki.squid-cache.org/KnowledgeBase/DebugSections

Specifically section 61.
You should add to squid.conf the line
debug_options ALL,1 61,6

And your cache.log will be flooded with details about any request that is
being passed to squidguard.
I believe that this should be a start point that will show you if squid is
sending the request to squidguard and how squidguard answers.
If you want more help share with a paste the current squid.conf and
squidguard.conf.
This way even if it?s not related directly to squid we can see if there is a
hole in the setup you don?t see yet.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Sameh Onaissi
Sent: Wednesday, December 21, 2016 7:14 PM
To: mailto:squid-users at lists.squid-cache.org
Subject: [squid-users] Bypassed Proxy

Hello all, 

I got a transparent squid installed on Ubuntu 16.04

Using squid guard, I am blocking certain websites, including youtube.

Anytime a user tries accessing it, he/she is redirected to an access denied
page.

Except for ONE user!

One user is somehow, able to access you tube through squid!
That IP is not on the exempt list, and has no special configurations.

access.log:

1482339083.228      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.324      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.331      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.422      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.436      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339083.517      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443
- HIER_NONE/- text/html
1482339086.251      0 10.0.0.162 TAG_NONE/503 4450 CONNECT s.youtube.com:443
- HIER_NONE/- text/html


Any other user tries and gets:

1482339588.002    350 10.0.0.40 TCP_MISS/200 611 GET
https://www.youtube.com/ - HIER_DIRECT/190.xxx.xxx.xxx text/html

That is the redirect html page.

My deny list where youtube is:

var/lib/squidguard/db/deny/urls has http://www.youtube.com
var/lib/squidguard/db/deny/domains has http://youtube.com


Any idea to how he is doing it?

I can add a rule to specifically deny 10.0.0.162, but I want to know how he
is doing it to prevent it for others. Also this is a dynamic IP.

Thank you,
Sam







From rousskov at measurement-factory.com  Wed Dec 21 23:51:29 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 21 Dec 2016 16:51:29 -0700
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
Message-ID: <abee932e-c03b-0f67-c311-1b2b20d61ce6@measurement-factory.com>

On 12/21/2016 10:14 AM, Sameh Onaissi wrote:

> One user is somehow, able to access you tube through squid!

> 1482339083.228      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com:443 - HIER_NONE/- text/html

What makes you think this user was able to access youtube? AFAICT, Squid
responded with an error (TAG_NONE/503) and did not contact the origin
server (HIER_NONE/-).

I understand that you want Squid to redirect users instead of responding
with an error. This 503 response could be due to Squid being unable to
bump the user connection for some reason. Successful bumping is required
to redirect users.

You may see more details inside that error response itself. Others on
the list may be able to help you to get to that response in Squid logs
or packet captures.


HTH,

Alex.



From squid3 at treenet.co.nz  Thu Dec 22 03:31:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 22 Dec 2016 16:31:16 +1300
Subject: [squid-users] CentOS Linux 7 / squid-3.5.20-2.el7.x86_64 / LDAP
 / ECAP / squidGuard blacklisting
In-Reply-To: <585A66600200000900024428@mail01.hospital-borken.de>
References: <585A66600200000900024428@mail01.hospital-borken.de>
Message-ID: <00ddea66-3f9d-4cbb-4110-53978cceaa2b@treenet.co.nz>

On 21/12/2016 11:24 p.m., bjoern wahl wrote:
> Hello!
> 
> Just for those who would like to have a:
> 
> Squid with Ldap user auth on an eDirectory with an ecap (watch out ! It
> is not i-cap!) virus check and squidGuard for blacklisting.
> 
> One think not working for me so far is the redirect to a virus info site
> if ecap/clamd did find a virus. By now the user is informed that the
> access was "denied" but not why. A thing i do not like with this setup
> right now. (still working on this!)

You have missed out the most important part of this tutorial...
   Where to get the eCAP adapter.


> 
> The working squid.conf looks like this:
> 
> =================================================================
> cache_mgr xxx at mail.de
> http_port IPADDRESSOFSERVER:3128

Or just use the default "http_port 3128" config line provided. If you
hard-code IP addresses unnecessarily into configs you just make yourself
do extra work maintaining them.

> acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
> machines
> acl SSL_ports port 443
> acl Safe_ports port 80        # http
> acl Safe_ports port 21        # ftp
> acl Safe_ports port 443        # https
> acl Safe_ports port 70        # gopher
> acl Safe_ports port 210        # wais
> acl Safe_ports port 1025-65535    # unregistered ports
> acl Safe_ports port 280        # http-mgmt
> acl Safe_ports port 488        # gss-http
> acl Safe_ports port 591        # filemaker
> acl Safe_ports port 777        # multiling http
> acl CONNECT method CONNECT
> auth_param basic program /usr/lib64/squid/basic_ldap_auth -b o=XXXX -h
> IPOFEDIRSERVER -D cn=XXX,o=XXX -w PASSWORDOFUSER -f
> "(&(objectclass=User)(cn=%s))"
> auth_param basic children 5
> auth_param basic realm WHATEVER-YOU-LIKE-TO-TELL-THE-USER
> auth_param basic credentialsttl 2 hours
> ecap_enable on
> loadable_modules /usr/local/lib/ecap_clamav_adapter.so
> ecap_service clamav_service_req reqmod_precache
> uri=ecap://e-cap.org/ecap/services/clamav?mode=REQMOD bypass=off
> ecap_service clamav_service_resp respmod_precache
> uri=ecap://e-cap.org/ecap/services/clamav?mode=RESPMOD bypass=on

Since bypass=on if the eCAP service has any error. (Such as finding a
virus perhapse?) The eCAP adapter will stop being used for some minutes.

If you want scanners like this to filter all traffic you need to set
bypass=off and fix any/every-thing that causes service outages.


> adaptation_access clamav_service_req allow all
> adaptation_access clamav_service_resp allow all
> acl ediruser proxy_auth REQUIRED
> http_access allow ediruser
> http_access deny all

Sigh. Whats the point of the below security rules if you are going to
bypass them completely for all traffic?

The http_access lines above this should all be down ...

> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager

 ... here.

At which point you will find yourself looking at two "deny all" rules in
a row. Do the obvious to fix that.

> http_access deny all
> http_port 3128
> coredump_dir /var/spool/squid
> refresh_pattern ^ftp:        1440    20%    10080
> refresh_pattern ^gopher:    1440    0%    1440
> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
> refresh_pattern .        0    20%    4320
> url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidGuard.conf
> url_rewrite_children 15
> url_rewrite_access allow all

Which is the default setting for "url_rewrite_access" directive.

And BTW, SquidGuard cannot cope with many HTTP extension request methods
in modern traffic. You will at the very least have to prevent it seeing
the CONNECT messages.

You should then realize that any users doing HTTPS can easily bypass
your SG URL mangling "control". If you are lucky right now SG will be
"blocking" HTTPS by breaking the Squid transaction on each attempt to
use it.

Otherwise what this config actually does is cause clients to send their
user credentials in clear-text across the network, while possibly
letting any client that can see and re-use anothers users credentials
create tunnels through the proxy. Hackers paradise.

Amos



From moremore2 at outlook.com  Thu Dec 22 07:13:12 2016
From: moremore2 at outlook.com (k simon)
Date: Thu, 22 Dec 2016 07:13:12 +0000
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <004001d25ac5$af542470$0dfc6d50$@ngtech.co.il>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
 <004001d25ac5$af542470$0dfc6d50$@ngtech.co.il>
Message-ID: <MWHPR13MB1262139B89D70AC1A350874FEE920@MWHPR13MB1262.namprd13.prod.outlook.com>

Hi,lists,
   Here's the debug_options 11,5 output.



2016/12/22 14:12:48.556 kid1| ctx: exit level  0
2016/12/22 14:12:48.556 kid1| 11,2| client_side.cc(1408) 
sendStartOfMessage: HTTP Client local=192.168.130.1:3128 
remote=192.168.130.54:25625 FD 668 flags=1
2016/12/22 14:12:48.556 kid1| 11,2| client_side.cc(1409) 
sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Content-Type: image/jpeg
X-Delay: 5275 us
X-Info: real data
X-BCheck: 0_1
X-Cpt: filename=0
User-ReturnCode: 0
Size: 71819
chid: 0
fid: 0
Date: Thu, 22 Dec 2016 05:50:17 GMT
Server: ImgHttp3.0.0
Cache-Control: max-age=15
Last-Modified: Mon, 28 Mar 2016 13:22:29 GMT
Content-Length: 0
X-RtFlag: 1
X-Cache: MISS from sqd-l2-dx2-j4-b
Age: 1351
X-Cache: HIT from backend-j1
Via: 1.1 sqd-l2-dx2-j4-b (squid), 1.1 backend-j1 (squid)
Connection: keep-alive


----------
2016/12/22 14:12:48.556 kid1| 11,5| http.cc(2428) abortAll: aborting 
transaction for store entry aborted while storing reply; 
local=192.168.133.13:38878 remote=192.168.133.31:1800 FD 585 flags=1, 
this 0x83cf47b18
2016/12/22 14:12:48.556 kid1| 11,5| http.cc(1586) closeServer: closing 
HTTP server local=192.168.133.13:38878 remote=192.168.133.31:1800 FD 585 
flags=1 this 0x83cf47b18
2016/12/22 14:12:48.556 kid1| 11,5| http.cc(143) ~HttpStateData: 
HttpStateData 0x83cf47b18 destroyed; local=192.168.133.13:38878 
remote=192.168.133.31:1800 flags=1
2016/12/22 14:12:48.556 kid1| 11,5| AsyncCallQueue.cc(57) fireNext: 
leaving HttpStateData::readReply(local=192.168.133.13:38878 
remote=192.168.133.31:1800 flags=1, data=0x83cf47b18, size=263, 
buf=0x8529b2000)
2016/12/22 14:12:48.556 kid1| 11,5| AsyncCallQueue.cc(55) fireNext: 
entering HttpStateData::readReply(local=192.168.133.13:38882 
remote=192.168.133.31:1800 FD 298 flags=1, data=0x851677e18, size=1876, 
buf=0x857ff2800)
2016/12/22 14:12:48.556 kid1| 11,5| AsyncCall.cc(38) make: make call 
HttpStateData::readReply [call103139655]
2016/12/22 14:12:48.557 kid1| 11,5| AsyncJob.cc(123) callStart: 
HttpStateData status in: [ job7708653]
2016/12/22 14:12:48.557 kid1| 11,5| http.cc(1138) readReply: 
local=192.168.133.13:38882 remote=192.168.133.31:1800 FD 298 flags=1: 
len 1876.
2016/12/22 14:12:48.557 kid1| 11,3| http.cc(1061) persistentConnStatus: 
local=192.168.133.13:38882 remote=192.168.133.31:1800 FD 298 flags=1 eof=0
2016/12/22 14:12:48.557 kid1| 11,5| http.cc(1081) persistentConnStatus: 
persistentConnStatus: content_length=13705
2016/12/22 14:12:48.557 kid1| 11,5| http.cc(1085) persistentConnStatus: 
persistentConnStatus: clen=13705
2016/12/22 14:12:48.557 kid1| 11,5| http.cc(1098) persistentConnStatus: 
persistentConnStatus: body_bytes_read=13705 content_length=13705
2016/12/22 14:12:48.557 kid1| 11,5| http.cc(1451) processReplyBody: 
processReplyBody: COMPLETE_PERSISTENT_MSG from 
local=192.168.133.13:38882 remote=192.168.133.31:1800 FD 298 flags=1
2016/12/22 14:12:48.557 kid1| 11,5| Client.cc(174) serverComplete: 
serverComplete 0x851677e18
2016/12/22 14:12:48.557 kid1| 11,5| Client.cc(198) serverComplete2: 
serverComplete2 0x851677e18
2016/12/22 14:12:48.557 kid1| 11,5| Client.cc(226) completeForwarding: 
completing forwarding for 0x850346718*2
2016/12/22 14:12:48.557 kid1| 11,5| http.cc(143) ~HttpStateData: 
HttpStateData 0x851677e18 destroyed;
2016/12/22 14:12:48.557 kid1| 11,5| AsyncCallQueue.cc(57) fireNext: 
leaving HttpStateData::readReply(local=192.168.133.13:38882 
remote=192.168.133.31:1800 FD 298 flags=1, data=0x851677e18, size=1876, 
buf=0x857ff2800)
2016/12/22 14:12:48.557 kid1| 11,5| AsyncCallQueue.cc(55) fireNext: 
entering HttpStateData::readReply(local=192.168.133.13:38891 
remote=192.168.133.31:1800 FD 56 flags=1, data=0x83ed5eb18, size=49, 
buf=0x85a1ac0c0)
2016/12/22 14:12:48.557 kid1| 11,5| AsyncCall.cc(38) make: make call 
HttpStateData::readReply [call103139387]
2016/12/22 14:12:48.557 kid1| 11,5| AsyncJob.cc(123) callStart: 
HttpStateData status in: [ job7708690]
2016/12/22 14:12:48.557 kid1| 11,5| http.cc(1138) readReply: 
local=192.168.133.13:38891 remote=192.168.133.31:1800 FD 56 flags=1: len 49.
2016/12/22 14:12:48.557 kid1| ctx: enter level  0: 'http://a.x.baidu.com/'
2016/12/22 14:12:48.557 kid1| 11,3| http.cc(694) processReplyHeader: 
processReplyHeader: key '2195D900F0B02BE163B3750D3D800FF1'
2016/12/22 14:12:48.557 kid1| 11,2| http.cc(735) processReplyHeader: 
HTTP Server local=192.168.133.13:38891 remote=192.168.133.31:1800 FD 56 
flags=1
2016/12/22 14:12:48.557 kid1| 11,2| http.cc(736) processReplyHeader: 
HTTP Server REPLY:
---------
HTTP/1.1 100 Continue
Connection: keep-alive


----------
2016/12/22 14:12:48.558 kid1| 11,2| http.cc(803) handle1xx: forwarding 
1xx to client
2016/12/22 14:12:48.558 kid1| 11,3| AsyncCall.cc(26) AsyncCall: The 
AsyncCall HttpStateData::proceedAfter1xx constructed, this=0x817b996b0 
[call103139775]
2016/12/22 14:12:48.558 kid1| 11,4| AsyncCall.cc(26) AsyncCall: The 
AsyncCall ConnStateData::ConnStateData::sendControlMsg constructed, 
this=0x84ae4ad00 [call103139776]
2016/12/22 14:12:48.558 kid1| 11,4| AsyncCall.cc(93) ScheduleCall: 
http.cc(810) will call 
ConnStateData::ConnStateData::sendControlMsg(0x851677e00*4, 
0x817b996b0*4) [call103139776]
2016/12/22 14:12:48.558 kid1| ctx: exit level  0
2016/12/22 14:12:48.558 kid1| 11,5| http.cc(1262) 
continueAfterParsingHeader: wait for 1xx handling
2016/12/22 14:12:48.558 kid1| 11,5| AsyncJob.cc(152) callEnd: 
HttpStateData status out: [ job7708690]
2016/12/22 14:12:48.558 kid1| 11,5| AsyncCallQueue.cc(57) fireNext: 
leaving HttpStateData::readReply(local=192.168.133.13:38891 
remote=192.168.133.31:1800 FD 56 flags=1, data=0x83ed5eb18, size=49, 
buf=0x85a1ac0c0)
2016/12/22 14:12:48.558 kid1| 11,5| AsyncCallQueue.cc(55) fireNext: 
entering HttpStateData::readReply(local=192.168.133.13:36592 
remote=192.168.133.31:1800 FD 109 flags=1, data=0x84a64c358, size=2817, 
buf=0x84ffecf00)
2016/12/22 14:12:48.558 kid1| 11,5| AsyncCall.cc(38) make: make call 
HttpStateData::readReply [call103139712]
2016/12/22 14:12:48.558 kid1| 11,5| AsyncJob.cc(123) callStart: 
HttpStateData status in: [ job7708643]
2016/12/22 14:12:48.558 kid1| 11,5| http.cc(1138) readReply: 
local=192.168.133.13:36592 remote=192.168.133.31:1800 FD 109 flags=1: 
len 2817.
2016/12/22 14:12:48.558 kid1| 11,3| http.cc(1061) persistentConnStatus: 
local=192.168.133.13:36592 remote=192.168.133.31:1800 FD 109 flags=1 eof=0
2016/12/22 14:12:48.558 kid1| 11,5| http.cc(1081) persistentConnStatus: 
persistentConnStatus: content_length=94450
2016/12/22 14:12:48.558 kid1| 11,5| http.cc(1085) persistentConnStatus: 
persistentConnStatus: clen=94450
2016/12/22 14:12:48.558 kid1| 11,5| http.cc(1098) persistentConnStatus: 
persistentConnStatus: body_bytes_read=45377 content_length=94450
2016/12/22 14:12:48.558 kid1| 11,5| http.cc(1437) processReplyBody: 
processReplyBody: INCOMPLETE_MSG from local=192.168.133.13:36592 
remote=192.168.133.31:1800 FD 109 flags=1
2016/12/22 14:12:48.558 kid1| 11,5| AsyncCall.cc(26) AsyncCall: The 
AsyncCall HttpStateData::readReply constructed, this=0x817903fe0 
[call103139780]
2016/12/22 14:12:48.558 kid1| 11,5| AsyncJob.cc(152) callEnd: 
HttpStateData status out: [ job7708643]
2016/12/22 14:12:48.558 kid1| 11,5| AsyncCallQueue.cc(57) fireNext: 
leaving HttpStateData::readReply(local=192.168.133.13:36592 
remote=192.168.133.31:1800 FD 109 flags=1, data=0x84a64c358, size=2817, 
buf=0x84ffecf00)
2016/12/22 14:12:48.558 kid1| 11,5| AsyncCallQueue.cc(55) fireNext: 
entering HttpStateData::readReply(local=192.168.133.13:38877 
remote=192.168.133.31:1800 FD 1087 flags=1, data=0x836989898, 
size=16383, buf=0x858d7d340)
2016/12/22 14:12:48.558 kid1| 11,5| AsyncCall.cc(38) make: make call 
HttpStateData::readReply [call103139713]
2016/12/22 14:12:48.558 kid1| 11,5| AsyncJob.cc(123) callStart: 
HttpStateData status in: [ job7708663]
2016/12/22 14:12:48.558 kid1| 11,5| http.cc(1138) readReply: 
local=192.168.133.13:38877 remote=192.168.133.31:1800 FD 1087 flags=1: 
len 16383.
2016/12/22 14:12:48.559 kid1| 11,5| http.cc(1344) truncateVirginBody: 
body_bytes_read=64845 clen=0/0 body_bytes_truncated=0+64845
2016/12/22 14:12:48.559 kid1| assertion failed: MemBuf.cc:216: "0 <= 
tailSize && tailSize <= cSize"
2016/12/22 14:12:52 kid1| Starting Squid Cache version 3.5.23 for 
amd64-portbld-freebsd11.0...
2016/12/22 14:12:52 kid1| Service Name: squid



Simon
20161222

From bjoern.wahl at hospital-borken.de  Thu Dec 22 07:44:00 2016
From: bjoern.wahl at hospital-borken.de (bjoern wahl)
Date: Thu, 22 Dec 2016 08:44:00 +0100
Subject: [squid-users] Antw: Re: CentOS Linux 7 / squid-3.5.20-2.el7.x86_64
 / LDAP / ECAP / squidGuard blacklisting
In-Reply-To: <00ddea66-3f9d-4cbb-4110-53978cceaa2b@treenet.co.nz>
References: <585A66600200000900024428@mail01.hospital-borken.de>
 <00ddea66-3f9d-4cbb-4110-53978cceaa2b@treenet.co.nz>
Message-ID: <585B9250020000090002447E@mail01.hospital-borken.de>

Hello!

Thanks for your input.

Remember: This is still a test environment.

Never the less i very much appreciate your answer.

Lets do it one by one.

-> this was never meant to be a tutorial. I just send this because such
an info would have saved me some time and as i didn`t find any
information on eDir/Ldap/Squid auth i just thought it would be nice to
post some infos, never meant to be a perfect solution to copy.

Skipping 1-2 things you mentioned, the next thing to answer would be the
"bypass=off" info you gave.

-> Thanks for this, i also found that, and did a correction on this.

The securityrules  in the config, that are ignored...

-> This is because of the whole testing i did here. These are leftovers
from the standard config comming with the installation.

Your comment an SquidGuard an HTTPS.

-> It is right, that SquidGuard is blocking HTTPS by this config. So the
questions are two:

1.) What other to user than SquidGuard ?
2.) or how to deal with HTTPS  ?

Because of the clear-text credatials:

-> what would be your alternative in this environment ?

Thanks for your time !

Bj?rn

On 21/12/2016 11:24 p.m., bjoern wahl wrote:
> Hello!
>
> Just for those who would like to have a:
>
> Squid with Ldap user auth on an eDirectory with an ecap (watch out !
It
> is not i-cap!) virus check and squidGuard for blacklisting.
>
> One think not working for me so far is the redirect to a virus info
site
> if ecap/clamd did find a virus. By now the user is informed that the
> access was "denied" but not why. A thing i do not like with this setup
> right now. (still working on this!)

You have missed out the most important part of this tutorial...
  Where to get the eCAP adapter.


>
> The working squid.conf looks like this:
>
> =================================================================
> cache_mgr xxx at mail.de
> http_port IPADDRESSOFSERVER:3128

Or just use the default "http_port 3128" config line provided. If you
hard-code IP addresses unnecessarily into configs you just make yourself
do extra work maintaining them.

> acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly
plugged)
> machines
> acl SSL_ports port 443
> acl Safe_ports port 80        # http
> acl Safe_ports port 21        # ftp
> acl Safe_ports port 443        # https
> acl Safe_ports port 70        # gopher
> acl Safe_ports port 210        # wais
> acl Safe_ports port 1025-65535    # unregistered ports
> acl Safe_ports port 280        # http-mgmt
> acl Safe_ports port 488        # gss-http
> acl Safe_ports port 591        # filemaker
> acl Safe_ports port 777        # multiling http
> acl CONNECT method CONNECT
> auth_param basic program /usr/lib64/squid/basic_ldap_auth -b o=XXXX -h
> IPOFEDIRSERVER -D cn=XXX,o=XXX -w PASSWORDOFUSER -f
> "(&(objectclass=User)(cn=%s))"
> auth_param basic children 5
> auth_param basic realm WHATEVER-YOU-LIKE-TO-TELL-THE-USER
> auth_param basic credentialsttl 2 hours
> ecap_enable on
> loadable_modules /usr/local/lib/ecap_clamav_adapter.so
> ecap_service clamav_service_req reqmod_precache
> uri=ecap://e-cap.org/ecap/services/clamav?mode=REQMOD bypass=off
> ecap_service clamav_service_resp respmod_precache
> uri=ecap://e-cap.org/ecap/services/clamav?mode=RESPMOD bypass=on

Since bypass=on if the eCAP service has any error. (Such as finding a
virus perhapse?) The eCAP adapter will stop being used for some minutes.

If you want scanners like this to filter all traffic you need to set
bypass=off and fix any/every-thing that causes service outages.


> adaptation_access clamav_service_req allow all
> adaptation_access clamav_service_resp allow all
> acl ediruse
r proxy_auth REQUIRED
> http_access allow ediruser
> http_acbypass them completely for all traffic?

The http_access lines above this should all be down ...

> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager

... here.

At which point you will find yourself looking at two "deny all" rules in
a row. Do the obvious to fix that.

> http_access deny all
> http_port 3128
> coredump_dir /var/spool/squid
> refresh_pattern ^ftp:        1440    20%    10080
> refresh_pattern ^gopher:    1440    0%    1440
> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
> refresh_pattern .        0    20%    4320
> url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidGuard.conf
> url_rewrite_children 15
> url_rewrite_access allow all

Which is the default setting for "url_rewrite_access" directive.

And BTW, SquidGuard cannot cope with many HTTP extension request methods
in modern traffic. You will at the very least have to prevent it seeing
the CONNECT messages.

You should then realize that any users doing HTTPS can easily bypass
your SG URL mangling "control". If you are lucky right now SG will be
"blocking" HTTPS by breaking the Squid transaction on each attempt to
use it.

Otherwise what this config actually does is cause clients to send their
user credentials in clear-text across the network, while possibly
letting any client that can see and re-use anothers users credentials
create tunnels through the proxy. Hackers paradise.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
Tr?ger: Klinikum Westm?nsterland GmbH
Jur. Sitz der Gesellschaft: Am Boltenhof 7, 46325 Borken
Registergericht Coesfeld, HRB Nr. 4184 I Ust.-Id.Nr.: DE123762133
Gesch?ftsf?hrer: Christoph Br?cker, Ludger Hellmann (Sprecher)
Aufsichtsratsvorsitzender: J?rgen B?ngeler

Diese E-Mail enth?lt vertrauliche oder rechtlich gesch?tzte
Informationen. Wenn Sie nicht der beabsichtigte Empf?nger sind,
informieren Sie bitte sofort den Absender und l?schen Sie diese E-Mail.
Das unbefugte Kopieren dieser E-Mail oder die unbefugte Weitergabe der
enthaltenen Informationen ist nicht gestattet.





From rousskov at measurement-factory.com  Thu Dec 22 15:59:12 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 22 Dec 2016 08:59:12 -0700
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <MWHPR13MB1262139B89D70AC1A350874FEE920@MWHPR13MB1262.namprd13.prod.outlook.com>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
 <004001d25ac5$af542470$0dfc6d50$@ngtech.co.il>
 <MWHPR13MB1262139B89D70AC1A350874FEE920@MWHPR13MB1262.namprd13.prod.outlook.com>
Message-ID: <1fd8873e-9f61-216e-17eb-e14b6c515724@measurement-factory.com>

On 12/22/2016 12:13 AM, k simon wrote:
>    Here's the debug_options 11,5 output.

Please post that to bugzilla. It is less likely to be lost there.
http://bugs.squid-cache.org/show_bug.cgi?id=4606

Alex.



From sameh.onaissi at solcv.com  Thu Dec 22 21:02:56 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Thu, 22 Dec 2016 21:02:56 +0000
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <761434DB-66CD-4FBE-851D-2E3928D870F2@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <abee932e-c03b-0f67-c311-1b2b20d61ce6@measurement-factory.com>
 <761434DB-66CD-4FBE-851D-2E3928D870F2@solcv.com>
Message-ID: <11A1F1B6-1047-473A-AF1C-974BCB0777AF@solcv.com>

Hello,


Eliezer?s recommended fix did not work.

The user was on YouTube watching UFC all day today.

Here?s a copy of the log at the time.
1482436450.285    353 10.0.0.105 TAG_NONE/200 0 CONNECT 167.114.159.186:443 - ORIGINAL_DST/167.114.159.186 -
1482436450.303      0 10.0.0.105 TAG_NONE/503 4462 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436450.318   4756 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
1482436450.340      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436450.567    839 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.70.138:443 - ORIGINAL_DST/188.166.70.138 -
1482436450.585      0 10.0.0.105 TAG_NONE/503 4459 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436450.650    373 10.0.0.105 TAG_NONE/200 0 CONNECT 85.203.7.35:443 - ORIGINAL_DST/85.203.7.35 -
1482436450.669      0 10.0.0.105 TAG_NONE/503 4450 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436450.682   1969 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
1482436450.706    386 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.73.9:443 - ORIGINAL_DST/188.166.73.9 -
1482436450.740   6540 10.0.0.105 TAG_NONE/200 0 CONNECT 85.203.18.254:443 - ORIGINAL_DST/85.203.18.254 -
1482436450.784      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436450.784      0 10.0.0.105 TAG_NONE/503 4453 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436450.784      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436450.909    469 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.93.229:443 - ORIGINAL_DST/138.68.93.229 -
1482436450.927   1882 10.0.0.105 TAG_NONE/200 0 CONNECT 208.123.223.254:443 - ORIGINAL_DST/208.123.223.254 -
1482436450.940      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436450.955      0 10.0.0.105 TAG_NONE/503 4462 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436451.063    197 10.0.0.105 TAG_NONE/200 0 CONNECT 208.123.223.254:443 - ORIGINAL_DST/208.123.223.254 -
1482436451.080      0 10.0.0.105 TAG_NONE/503 4462 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436451.217    434 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.97.9:443 - ORIGINAL_DST/138.68.97.9 -
1482436451.236      0 10.0.0.105 TAG_NONE/503 4450 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436451.322    271 10.0.0.105 TAG_NONE/200 0 CONNECT 65.52.108.76:443 - ORIGINAL_DST/65.52.108.76 -
1482436451.345    479 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.93.229:443 - ORIGINAL_DST/138.68.93.229 -
1482436451.361      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436451.498   4240 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
1482436451.530      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
1482436451.909    817 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.70.138:443 - ORIGINAL_DST/188.166.70.138 -



I know 503 is an error, but the user was using youtube without any hassles.
Those IPs are for Digital Ocean and Alentus Corporation.

Squid is being ?fooled? somehow.
 I did notice the 503, which made it more confusing to me.
The reason I investigated the issue was because I saw youtube working on the client?s PC with a blue shield-like icon along with some words on top of the youtube page (was not close enough to see the exact logo/words). The video was working fine, but that blue shield extension seems to be the reason behind ?fooling? squid.

Both the chrome extension and the Desktop client are installed on the machine.

I tried replicating that, but I couldn?t even connect the client.

What should I be looking for in cache.log?


Thanks again!

Sam

On Dec 21, 2016, at 6:59 PM, Sameh Onaissi <sameh.onaissi at solcv.com<mailto:sameh.onaissi at solcv.com>> wrote:





On Dec 21, 2016, at 6:51 PM, Alex Rousskov <rousskov at measurement-factory.com<mailto:rousskov at measurement-factory.com>> wrote:

On 12/21/2016 10:14 AM, Sameh Onaissi wrote:

One user is somehow, able to access you tube through squid!

1482339083.228      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html

What makes you think this user was able to access youtube? AFAICT, Squid
responded with an error (TAG_NONE/503) and did not contact the origin
server (HIER_NONE/-).

I did notice the 503, which made it more confusing to me.
The reason I investigated the issue was because I saw youtube working on the client?s PC with a blue shield-like icon along with some words on top of the youtube page (was not close enough to see the exact logo/words). The video was working fine, but that blue shield extension seems to be the reason behind ?fooling? squid.

In any case, I applied the ACL?s to the squid.conf as Eliezer recommended, now I?ll wait till the user comes back in tomorrow to see if it worked.


I understand that you want Squid to redirect users instead of responding
with an error. This 503 response could be due to Squid being unable to
bump the user connection for some reason. Successful bumping is required
to redirect users.

You may see more details inside that error response itself. Others on
the list may be able to help you to get to that response in Squid logs
or packet captures.


HTH,

Alex.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161222/ff8c7596/attachment.htm>

From sameh.onaissi at solcv.com  Thu Dec 22 21:50:33 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Thu, 22 Dec 2016 21:50:33 +0000
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <1F13F4C925B73F48A73307A32424FB8702C117E125@chemsur-ex-01.emlchem.local>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <abee932e-c03b-0f67-c311-1b2b20d61ce6@measurement-factory.com>
 <761434DB-66CD-4FBE-851D-2E3928D870F2@solcv.com>
 <11A1F1B6-1047-473A-AF1C-974BCB0777AF@solcv.com>
 <1F13F4C925B73F48A73307A32424FB8702C117E125@chemsur-ex-01.emlchem.local>
Message-ID: <AB3EF6B0-AE87-45A5-906C-9285F4AC9411@solcv.com>

Hi Paul and thank you for your reply.

I did try the extension and Squid blocked it right away.

The user has hotspot shield installed on his PC, which I believe is a similar extension to the one you mentioned.
My squid.conf blocks domains, I have a bypass list of IPs for local company servers and Skype For Business.

The user has hotspot shield installed, both the chrome extension and the desktop software, although the chrome extension is always Off from what I have seen (red icon when off, green when on).

He is getting by squid with some sort of VPN, I thought squid can be configured against such things?




On Dec 22, 2016, at 4:34 PM, Paul Freeman <paul.freeman at emlchem.com.au<mailto:paul.freeman at emlchem.com.au>> wrote:

Sam,
I haven?t followed your thread closely so what I am about to mentio may already have been discussed.  Apologies if this is the case.

As Alex says, the connections to youtube receive a 503 but then there are successful connects on port 443 to numerous site by IP address rather than hostname.

Doing a reverse lookup on the IP addresses shows some are in the northghost.com<http://northghost.com/> dns domain name.

I looked up northghost.com<http://northghost.com/> and they offer an app for mobiles or an add-on for Chrome called Touch VPN.  Perhaps this might be being used by your user although I don?t really know how it works and whether it really is how the user appears to be pypassing the proxy.

In your squid.conf or other access control systems, do you allow urls specified by IP as well as hostnames?

Paul

NOTE: This email contains my personal opinions and comments which do not necessarily represent those of my employer.


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
Sent: Friday, 23 December 2016 8:03 AM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Bypassed Proxy

Hello,


Eliezer?s recommended fix did not work.

The user was on YouTube watching UFC all day today.

Here?s a copy of the log at the time.
1482436450.285    353 10.0.0.105 TAG_NONE/200 0 CONNECT 167.114.159.186:443 - ORIGINAL_DST/167.114.159.186 -
1482436450.303      0 10.0.0.105 TAG_NONE/503 4462 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436450.318   4756 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
1482436450.340      0 10.0.0.105 TAG_NONE/503 4456 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436450.567    839 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.70.138:443 - ORIGINAL_DST/188.166.70.138 -
1482436450.585      0 10.0.0.105 TAG_NONE/503 4459 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436450.650    373 10.0.0.105 TAG_NONE/200 0 CONNECT 85.203.7.35:443 - ORIGINAL_DST/85.203.7.35 -
1482436450.669      0 10.0.0.105 TAG_NONE/503 4450 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436450.682   1969 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
1482436450.706    386 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.73.9:443 - ORIGINAL_DST/188.166.73.9 -
1482436450.740   6540 10.0.0.105 TAG_NONE/200 0 CONNECT 85.203.18.254:443 - ORIGINAL_DST/85.203.18.254 -
1482436450.784      0 10.0.0.105 TAG_NONE/503 4456 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436450.784      0 10.0.0.105 TAG_NONE/503 4453 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436450.784      0 10.0.0.105 TAG_NONE/503 4456 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436450.909    469 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.93.229:443 - ORIGINAL_DST/138.68.93.229 -
1482436450.927   1882 10.0.0.105 TAG_NONE/200 0 CONNECT 208.123.223.254:443 - ORIGINAL_DST/208.123.223.254 -
1482436450.940      0 10.0.0.105 TAG_NONE/503 4456 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436450.955      0 10.0.0.105 TAG_NONE/503 4462 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436451.063    197 10.0.0.105 TAG_NONE/200 0 CONNECT 208.123.223.254:443 - ORIGINAL_DST/208.123.223.254 -
1482436451.080      0 10.0.0.105 TAG_NONE/503 4462 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436451.217    434 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.97.9:443 - ORIGINAL_DST/138.68.97.9 -
1482436451.236      0 10.0.0.105 TAG_NONE/503 4450 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436451.322    271 10.0.0.105 TAG_NONE/200 0 CONNECT 65.52.108.76:443 - ORIGINAL_DST/65.52.108.76 -
1482436451.345    479 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.93.229:443 - ORIGINAL_DST/138.68.93.229 -
1482436451.361      0 10.0.0.105 TAG_NONE/503 4456 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436451.498   4240 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
1482436451.530      0 10.0.0.105 TAG_NONE/503 4456 CONNECTs.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html
1482436451.909    817 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.70.138:443 - ORIGINAL_DST/188.166.70.138 -



I know 503 is an error, but the user was using youtube without any hassles.
Those IPs are for Digital Ocean and Alentus Corporation.

Squid is being ?fooled? somehow.
 I did notice the 503, which made it more confusing to me.
The reason I investigated the issue was because I saw youtube working on the client?s PC with a blue shield-like icon along with some words on top of the youtube page (was not close enough to see the exact logo/words). The video was working fine, but that blue shield extension seems to be the reason behind ?fooling? squid.

Both the chrome extension and the Desktop client are installed on the machine.

I tried replicating that, but I couldn?t even connect the client.

What should I be looking for in cache.log?


Thanks again!

Sam

On Dec 21, 2016, at 6:59 PM, Sameh Onaissi <sameh.onaissi at solcv.com<mailto:sameh.onaissi at solcv.com>> wrote:






On Dec 21, 2016, at 6:51 PM, Alex Rousskov <rousskov at measurement-factory.com<mailto:rousskov at measurement-factory.com>> wrote:

On 12/21/2016 10:14 AM, Sameh Onaissi wrote:


One user is somehow, able to access you tube through squid!


1482339083.228      0 10.0.0.162 TAG_NONE/503 4459 CONNECT s.youtube.com<http://s.youtube.com/>:443 - HIER_NONE/- text/html

What makes you think this user was able to access youtube? AFAICT, Squid
responded with an error (TAG_NONE/503) and did not contact the origin
server (HIER_NONE/-).

I did notice the 503, which made it more confusing to me.
The reason I investigated the issue was because I saw youtube working on the client?s PC with a blue shield-like icon along with some words on top of the youtube page (was not close enough to see the exact logo/words). The video was working fine, but that blue shield extension seems to be the reason behind ?fooling? squid.

In any case, I applied the ACL?s to the squid.conf as Eliezer recommended, now I?ll wait till the user comes back in tomorrow to see if it worked.



I understand that you want Squid to redirect users instead of responding
with an error. This 503 response could be due to Squid being unable to
bump the user connection for some reason. Successful bumping is required
to redirect users.

You may see more details inside that error response itself. Others on
the list may be able to help you to get to that response in Squid logs
or packet captures.


HTH,

Alex.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161222/b0f38216/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Dec 22 22:14:03 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 22 Dec 2016 23:14:03 +0100
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <AB3EF6B0-AE87-45A5-906C-9285F4AC9411@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <1F13F4C925B73F48A73307A32424FB8702C117E125@chemsur-ex-01.emlchem.local>
 <AB3EF6B0-AE87-45A5-906C-9285F4AC9411@solcv.com>
Message-ID: <201612222314.03801.Antony.Stone@squid.open.source.it>

On Thursday 22 December 2016 at 22:50:33, Sameh Onaissi wrote:

> The user has hotspot shield installed on his PC, which I believe is a
> similar extension to the one you mentioned.

> He is getting by squid with some sort of VPN, I thought squid can be
> configured against such things?

It sounds as though you need to review your firewall (routing) policies.

Anyone who is allowed to use a VPN can effectively bypass all security policies 
on your network.


Antony.

-- 
Schr?dinger's rule of data integrity: the condition of any backup is unknown 
until a restore is attempted.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From sameh.onaissi at solcv.com  Fri Dec 23 00:02:35 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Fri, 23 Dec 2016 00:02:35 +0000
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <201612222314.03801.Antony.Stone@squid.open.source.it>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <1F13F4C925B73F48A73307A32424FB8702C117E125@chemsur-ex-01.emlchem.local>
 <AB3EF6B0-AE87-45A5-906C-9285F4AC9411@solcv.com>
 <201612222314.03801.Antony.Stone@squid.open.source.it>
Message-ID: <B48FB51B-1D9D-4773-BFF4-F89A26CD0039@solcv.com>

I have been trying to replicate what he is doing.

I have tried 4 or 5 VPN software and none connects, including Hotspot Shield. My iptables seem to be doing the job in that regard (Eliezer helped me set them up)



> On Dec 22, 2016, at 5:14 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Thursday 22 December 2016 at 22:50:33, Sameh Onaissi wrote:
> 
>> The user has hotspot shield installed on his PC, which I believe is a
>> similar extension to the one you mentioned.
> 
>> He is getting by squid with some sort of VPN, I thought squid can be
>> configured against such things?
> 
> It sounds as though you need to review your firewall (routing) policies.
> 
> Anyone who is allowed to use a VPN can effectively bypass all security policies 
> on your network.
> 
> 
> Antony.
> 
> -- 
> Schr?dinger's rule of data integrity: the condition of any backup is unknown 
> until a restore is attempted.
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Fri Dec 23 02:42:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 23 Dec 2016 15:42:56 +1300
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <1fd8873e-9f61-216e-17eb-e14b6c515724@measurement-factory.com>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
 <004001d25ac5$af542470$0dfc6d50$@ngtech.co.il>
 <MWHPR13MB1262139B89D70AC1A350874FEE920@MWHPR13MB1262.namprd13.prod.outlook.com>
 <1fd8873e-9f61-216e-17eb-e14b6c515724@measurement-factory.com>
Message-ID: <61ca6bcc-1eaf-e062-1821-9ea83927a680@treenet.co.nz>

On 23/12/2016 4:59 a.m., Alex Rousskov wrote:
> On 12/22/2016 12:13 AM, k simon wrote:
>>    Here's the debug_options 11,5 output.
> 
> Please post that to bugzilla. It is less likely to be lost there.
> http://bugs.squid-cache.org/show_bug.cgi?id=4606
> 

Most of those lines appear to be not useful.

The relevant call sequence is for "FD 1087", so please include in that
bug update the output of:

  grep --context=20 "FD 1087" /var/log/squid/cache.log

Amos



From squid3 at treenet.co.nz  Fri Dec 23 03:06:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 23 Dec 2016 16:06:49 +1300
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <B48FB51B-1D9D-4773-BFF4-F89A26CD0039@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <1F13F4C925B73F48A73307A32424FB8702C117E125@chemsur-ex-01.emlchem.local>
 <AB3EF6B0-AE87-45A5-906C-9285F4AC9411@solcv.com>
 <201612222314.03801.Antony.Stone@squid.open.source.it>
 <B48FB51B-1D9D-4773-BFF4-F89A26CD0039@solcv.com>
Message-ID: <647e3dae-7937-3335-5dbc-96c4af034844@treenet.co.nz>

On 23/12/2016 1:02 p.m., Sameh Onaissi wrote:
> I have been trying to replicate what he is doing.
> 
> I have tried 4 or 5 VPN software and none connects, including Hotspot
> Shield. My iptables seem to be doing the job in that regard (Eliezer
> helped me set them up)
> 

Do you have matching ip6tables rules to prevent IPv6 networking being
used for the prohibited things?

>> On Dec 22, 2016, at 5:14 PM, Antony Stone wrote:
>>
>> On Thursday 22 December 2016 at 22:50:33, Sameh Onaissi wrote:
>>
>>> The user has hotspot shield installed on his PC, which I believe is a
>>> similar extension to the one you mentioned.
>>
>>> He is getting by squid with some sort of VPN, I thought squid can be
>>> configured against such things?

Squid can only prevent things going through itself.

Unless the VPN software is using HTTP(S) protocol messaging as a
transport layer, AND that messaging goes through the proxy, the answer
is no. That kind of control is what firewalls are for.


>>
>> It sounds as though you need to review your firewall (routing) policies.
>>
>> Anyone who is allowed to use a VPN can effectively bypass all security policies 
>> on your network.
>>

I second that.

Keep in mind that "iptables" command only sets up rules for IPv4
connections. They could be using IPv6. 'VPN' also has a number of
sub-types: 6to4, SOCKS, IP-IP, or remote NPT relay.

Amos



From moremore2 at outlook.com  Fri Dec 23 03:26:20 2016
From: moremore2 at outlook.com (k simon)
Date: Fri, 23 Dec 2016 03:26:20 +0000
Subject: [squid-users] r14088 crash on FreeBSD 11
In-Reply-To: <61ca6bcc-1eaf-e062-1821-9ea83927a680@treenet.co.nz>
References: <MWHPR13MB126268F5E5C296912ED27974EE9C0@MWHPR13MB1262.namprd13.prod.outlook.com>
 <004001d25ac5$af542470$0dfc6d50$@ngtech.co.il>
 <MWHPR13MB1262139B89D70AC1A350874FEE920@MWHPR13MB1262.namprd13.prod.outlook.com>
 <1fd8873e-9f61-216e-17eb-e14b6c515724@measurement-factory.com>
 <61ca6bcc-1eaf-e062-1821-9ea83927a680@treenet.co.nz>
Message-ID: <MWHPR13MB1262F809839EDBF79197C354EE950@MWHPR13MB1262.namprd13.prod.outlook.com>

Hi,Amos,
   It's 54M file big after "grep" command. How can I continue truncate 
it for useful info?

Simon
20161223

From squid3 at treenet.co.nz  Fri Dec 23 03:56:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 23 Dec 2016 16:56:27 +1300
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <11A1F1B6-1047-473A-AF1C-974BCB0777AF@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <abee932e-c03b-0f67-c311-1b2b20d61ce6@measurement-factory.com>
 <761434DB-66CD-4FBE-851D-2E3928D870F2@solcv.com>
 <11A1F1B6-1047-473A-AF1C-974BCB0777AF@solcv.com>
Message-ID: <bcc3ec05-53e2-b0f3-10bc-f3e98c6ca7c2@treenet.co.nz>

On 23/12/2016 10:02 a.m., Sameh Onaissi wrote:
> Hello,
> 
> 
> Eliezer?s recommended fix did not work.
> 
> The user was on YouTube watching UFC all day today.
> 
> Here?s a copy of the log at the time.
> 1482436450.285    353 10.0.0.105 TAG_NONE/200 0 CONNECT 167.114.159.186:443 - ORIGINAL_DST/167.114.159.186 -
> 1482436450.303      0 10.0.0.105 TAG_NONE/503 4462 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436450.318   4756 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
> 1482436450.340      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436450.567    839 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.70.138:443 - ORIGINAL_DST/188.166.70.138 -
> 1482436450.585      0 10.0.0.105 TAG_NONE/503 4459 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436450.650    373 10.0.0.105 TAG_NONE/200 0 CONNECT 85.203.7.35:443 - ORIGINAL_DST/85.203.7.35 -
> 1482436450.669      0 10.0.0.105 TAG_NONE/503 4450 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436450.682   1969 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
> 1482436450.706    386 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.73.9:443 - ORIGINAL_DST/188.166.73.9 -
> 1482436450.740   6540 10.0.0.105 TAG_NONE/200 0 CONNECT 85.203.18.254:443 - ORIGINAL_DST/85.203.18.254 -
> 1482436450.784      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436450.784      0 10.0.0.105 TAG_NONE/503 4453 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436450.784      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436450.909    469 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.93.229:443 - ORIGINAL_DST/138.68.93.229 -
> 1482436450.927   1882 10.0.0.105 TAG_NONE/200 0 CONNECT 208.123.223.254:443 - ORIGINAL_DST/208.123.223.254 -
> 1482436450.940      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436450.955      0 10.0.0.105 TAG_NONE/503 4462 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436451.063    197 10.0.0.105 TAG_NONE/200 0 CONNECT 208.123.223.254:443 - ORIGINAL_DST/208.123.223.254 -
> 1482436451.080      0 10.0.0.105 TAG_NONE/503 4462 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436451.217    434 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.97.9:443 - ORIGINAL_DST/138.68.97.9 -
> 1482436451.236      0 10.0.0.105 TAG_NONE/503 4450 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436451.322    271 10.0.0.105 TAG_NONE/200 0 CONNECT 65.52.108.76:443 - ORIGINAL_DST/65.52.108.76 -
> 1482436451.345    479 10.0.0.105 TAG_NONE/200 0 CONNECT 138.68.93.229:443 - ORIGINAL_DST/138.68.93.229 -
> 1482436451.361      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436451.498   4240 10.0.0.105 TAG_NONE/200 0 CONNECT 139.59.225.84:443 - ORIGINAL_DST/139.59.225.84 -
> 1482436451.530      0 10.0.0.105 TAG_NONE/503 4456 CONNECT s.youtube.com<http://s.youtube.com>:443 - HIER_NONE/- text/html
> 1482436451.909    817 10.0.0.105 TAG_NONE/200 0 CONNECT 188.166.70.138:443 - ORIGINAL_DST/188.166.70.138 -
> 
> 
> 
> I know 503 is an error, but the user was using youtube without any hassles.
> Those IPs are for Digital Ocean and Alentus Corporation.

rDNS says they are being used by the northghost "Touch VPN" network.

> 
> Squid is being ?fooled? somehow.
>  I did notice the 503, which made it more confusing to me.

Squid is rejecting the YT traffic attempts asked of it. Maybe not in the
way you intended, but to the same effect.

The above log implies they are visiting northghost. Nothing is
prohibiting that. Then Squid during the bumping process sees the YT
domain in SNI or somesuch, and tries to reject it but cant at that late
stage so 503 occurs.

There are very likely other attempts being made in other ways since
these did not succeed. If any of those do succeed the user gets their YT
access.

Amos



From eliezer at ngtech.co.il  Fri Dec 23 09:31:41 2016
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Fri, 23 Dec 2016 11:31:41 +0200
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <B48FB51B-1D9D-4773-BFF4-F89A26CD0039@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <1F13F4C925B73F48A73307A32424FB8702C117E125@chemsur-ex-01.emlchem.local>
 <AB3EF6B0-AE87-45A5-906C-9285F4AC9411@solcv.com>
 <201612222314.03801.Antony.Stone@squid.open.source.it>
 <B48FB51B-1D9D-4773-BFF4-F89A26CD0039@solcv.com>
Message-ID: <018801d25cff$5e84c0e0$1b8e42a0$@ngtech.co.il>

My suggestion would be to find the holes in the system.
There are couple good networking tools ie:
Iptstate
Iptraf-ng
netstat-nat
conntrackd-tools

The above tools have the options to see what parts of the IP is not ports such as:
53
80
443

Which you can control easily.
You can easily add a DROP or REJECT rule in iptables for all new connections on other then these ports as a starter.
It's very simple to write and I think you should dig a bit on iptables so you would be able to understand how it works better to give you a glimpse into the networking security world.
This amazing site and page:
http://www.linuxhomenetworking.com/wiki/index.php/Quick_HOWTO_:_Ch14_:_Linux_Firewalls_Using_iptables

Gives a better understanding to iptables and also on networking.
If you need more guidance let me know.

Eliezer 

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
Sent: Friday, December 23, 2016 2:03 AM
To: Antony Stone <Antony.Stone at squid.open.source.it>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Bypassed Proxy

I have been trying to replicate what he is doing.

I have tried 4 or 5 VPN software and none connects, including Hotspot Shield. My iptables seem to be doing the job in that regard (Eliezer helped me set them up)



> On Dec 22, 2016, at 5:14 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Thursday 22 December 2016 at 22:50:33, Sameh Onaissi wrote:
> 
>> The user has hotspot shield installed on his PC, which I believe is a 
>> similar extension to the one you mentioned.
> 
>> He is getting by squid with some sort of VPN, I thought squid can be 
>> configured against such things?
> 
> It sounds as though you need to review your firewall (routing) policies.
> 
> Anyone who is allowed to use a VPN can effectively bypass all security 
> policies on your network.
> 
> 
> Antony.
> 
> --
> Schr?dinger's rule of data integrity: the condition of any backup is 
> unknown until a restore is attempted.
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From sameh.onaissi at solcv.com  Fri Dec 23 17:30:37 2016
From: sameh.onaissi at solcv.com (Sameh Onaissi)
Date: Fri, 23 Dec 2016 17:30:37 +0000
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <018801d25cff$5e84c0e0$1b8e42a0$@ngtech.co.il>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <1F13F4C925B73F48A73307A32424FB8702C117E125@chemsur-ex-01.emlchem.local>
 <AB3EF6B0-AE87-45A5-906C-9285F4AC9411@solcv.com>
 <201612222314.03801.Antony.Stone@squid.open.source.it>
 <B48FB51B-1D9D-4773-BFF4-F89A26CD0039@solcv.com>
 <018801d25cff$5e84c0e0$1b8e42a0$@ngtech.co.il>
Message-ID: <971350DB-9959-4275-9856-1245355DCE7E@solcv.com>

Thank you all for the suggestions.

I will try to read up on iptables and add the necessary rules, as well as try to add norhtghost IPs to the blacklist.

On another note, I noticed Tor Browser bypasses squid completely. The only search results I found on how to block it with squid date back to 2011. (Amos has a script for that?)
Any idea how to block Tor? I downloaded it and ran it and none of its traffic is detected by Squid.





> On Dec 23, 2016, at 4:31 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> My suggestion would be to find the holes in the system.
> There are couple good networking tools ie:
> Iptstate
> Iptraf-ng
> netstat-nat
> conntrackd-tools
> 
> The above tools have the options to see what parts of the IP is not ports such as:
> 53
> 80
> 443
> 
> Which you can control easily.
> You can easily add a DROP or REJECT rule in iptables for all new connections on other then these ports as a starter.
> It's very simple to write and I think you should dig a bit on iptables so you would be able to understand how it works better to give you a glimpse into the networking security world.
> This amazing site and page:
> http://www.linuxhomenetworking.com/wiki/index.php/Quick_HOWTO_:_Ch14_:_Linux_Firewalls_Using_iptables
> 
> Gives a better understanding to iptables and also on networking.
> If you need more guidance let me know.
> 
> Eliezer 
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
> Sent: Friday, December 23, 2016 2:03 AM
> To: Antony Stone <Antony.Stone at squid.open.source.it>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Bypassed Proxy
> 
> I have been trying to replicate what he is doing.
> 
> I have tried 4 or 5 VPN software and none connects, including Hotspot Shield. My iptables seem to be doing the job in that regard (Eliezer helped me set them up)
> 
> 
> 
>> On Dec 22, 2016, at 5:14 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
>> 
>> On Thursday 22 December 2016 at 22:50:33, Sameh Onaissi wrote:
>> 
>>> The user has hotspot shield installed on his PC, which I believe is a 
>>> similar extension to the one you mentioned.
>> 
>>> He is getting by squid with some sort of VPN, I thought squid can be 
>>> configured against such things?
>> 
>> It sounds as though you need to review your firewall (routing) policies.
>> 
>> Anyone who is allowed to use a VPN can effectively bypass all security 
>> policies on your network.
>> 
>> 
>> Antony.
>> 
>> --
>> Schr?dinger's rule of data integrity: the condition of any backup is 
>> unknown until a restore is attempted.
>> 
>>                                                  Please reply to the list;
>>                                                        please *don't* CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From yvoinov at gmail.com  Fri Dec 23 17:43:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 23 Dec 2016 23:43:43 +0600
Subject: [squid-users] Bypassed Proxy
In-Reply-To: <971350DB-9959-4275-9856-1245355DCE7E@solcv.com>
References: <FA424FAA-0013-49C4-A79A-8CEDAA1996B4@solcv.com>
 <1F13F4C925B73F48A73307A32424FB8702C117E125@chemsur-ex-01.emlchem.local>
 <AB3EF6B0-AE87-45A5-906C-9285F4AC9411@solcv.com>
 <201612222314.03801.Antony.Stone@squid.open.source.it>
 <B48FB51B-1D9D-4773-BFF4-F89A26CD0039@solcv.com>
 <018801d25cff$5e84c0e0$1b8e42a0$@ngtech.co.il>
 <971350DB-9959-4275-9856-1245355DCE7E@solcv.com>
Message-ID: <e8296830-8af9-a8d2-8a99-30cbf4d1e60d@gmail.com>



23.12.2016 23:30, Sameh Onaissi ?????:
> Thank you all for the suggestions.
>
> I will try to read up on iptables and add the necessary rules, as well as try to add norhtghost IPs to the blacklist.
AFAIK not IPs, but network ranges. And you require to regullarry update
it, to keep up-to-date, and made enough exceptions - to work innocent sites.
>
> On another note, I noticed Tor Browser bypasses squid completely. The only search results I found on how to block it with squid date back to 2011. (Amos has a script for that?)
> Any idea how to block Tor? I downloaded it and ran it and none of its traffic is detected by Squid.
Bridged Tor?! Cool story, bro. Ever China government, with Great China
Firewall, can't block Tor.

PS. Personal advice. Forget about blocking Tor. Forever. It desined to
prevent any blocking. And good designed.
>
>
>
>
>
>> On Dec 23, 2016, at 4:31 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
>>
>> My suggestion would be to find the holes in the system.
>> There are couple good networking tools ie:
>> Iptstate
>> Iptraf-ng
>> netstat-nat
>> conntrackd-tools
>>
>> The above tools have the options to see what parts of the IP is not ports such as:
>> 53
>> 80
>> 443
>>
>> Which you can control easily.
>> You can easily add a DROP or REJECT rule in iptables for all new connections on other then these ports as a starter.
>> It's very simple to write and I think you should dig a bit on iptables so you would be able to understand how it works better to give you a glimpse into the networking security world.
>> This amazing site and page:
>> http://www.linuxhomenetworking.com/wiki/index.php/Quick_HOWTO_:_Ch14_:_Linux_Firewalls_Using_iptables
>>
>> Gives a better understanding to iptables and also on networking.
>> If you need more guidance let me know.
>>
>> Eliezer 
>>
>> ----
>> Eliezer Croitoru
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>> -----Original Message-----
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sameh Onaissi
>> Sent: Friday, December 23, 2016 2:03 AM
>> To: Antony Stone <Antony.Stone at squid.open.source.it>
>> Cc: squid-users at lists.squid-cache.org
>> Subject: Re: [squid-users] Bypassed Proxy
>>
>> I have been trying to replicate what he is doing.
>>
>> I have tried 4 or 5 VPN software and none connects, including Hotspot Shield. My iptables seem to be doing the job in that regard (Eliezer helped me set them up)
>>
>>
>>
>>> On Dec 22, 2016, at 5:14 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
>>>
>>> On Thursday 22 December 2016 at 22:50:33, Sameh Onaissi wrote:
>>>
>>>> The user has hotspot shield installed on his PC, which I believe is a 
>>>> similar extension to the one you mentioned.
>>>> He is getting by squid with some sort of VPN, I thought squid can be 
>>>> configured against such things?
>>> It sounds as though you need to review your firewall (routing) policies.
>>>
>>> Anyone who is allowed to use a VPN can effectively bypass all security 
>>> policies on your network.
>>>
>>>
>>> Antony.
>>>
>>> --
>>> Schr?dinger's rule of data integrity: the condition of any backup is 
>>> unknown until a restore is attempted.
>>>
>>>                                                  Please reply to the list;
>>>                                                        please *don't* CC me.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
What is the fundamental difference between the programmer and by a fag?
Fag never become five times to free the memory of one object. Fag will
not use two almost identical string libraries in the same project. Fag
will never write to a mixture of C and C ++. Fag will never pass objects
by pointer. Now you know why these two categories so often mentioned
together, and one of them is worse :)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161223/4e4f5f59/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161223/4e4f5f59/attachment.sig>

From edwin.zhou at hotmail.com  Sat Dec 24 02:43:55 2016
From: edwin.zhou at hotmail.com (wei)
Date: Sat, 24 Dec 2016 02:43:55 +0000
Subject: [squid-users] Squid keep using one parent proxy while I have
 multiple parent proxies
Message-ID: <PS1PR01MB1306295EADB281CFAD17252E98940@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>

I have the following cache_peer settings in squid.conf, it works fine but I found when the interval of every request is more than 55 seconds or so, the request will only be forwarded to the last parent(p3), I think this is because the counter being reset by squid if there is no new request for about 55 seconds, anyone know how to increase this value? Many thanks.

cache_peer 192.168.1.100 parent 3128 weight=5 no-query name=p1 round-robin
cache_peer 192.168.1.101 parent 3128 weight=5 no-query name=p2 round-robin
cache_peer 192.168.1.102 parent 3128 weight=5 no-query name=p3 round-robin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161224/be2d1049/attachment.htm>

From squid3 at treenet.co.nz  Sun Dec 25 10:25:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Dec 2016 23:25:34 +1300
Subject: [squid-users] Squid keep using one parent proxy while I have
	multiple parent proxies
In-Reply-To: <PS1PR01MB1306295EADB281CFAD17252E98940@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
References: <PS1PR01MB1306295EADB281CFAD17252E98940@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
Message-ID: <6ace087dad7238ba88b6d89c84dfd373@treenet.co.nz>

On 2016-12-24 15:43, wei wrote:
> I have the following cache_peer settings in squid.conf, it works fine
> but I found when the interval of every request is more than 55 seconds
> or so, the request will only be forwarded to the last parent(p3), I
> think this is because the counter being reset by squid if there is no
> new request for about 55 seconds, anyone know how to increase this
> value? Many thanks.
> 
> cache_peer 192.168.1.100 parent 3128 weight=5 no-query name=p1
> round-robin
> cache_peer 192.168.1.101 parent 3128 weight=5 no-query name=p2
> round-robin
> cache_peer 192.168.1.102 parent 3128 weight=5 no-query name=p3
> round-robin


What version of Squid?

Amos


From edwin.zhou at hotmail.com  Mon Dec 26 01:34:25 2016
From: edwin.zhou at hotmail.com (wei)
Date: Mon, 26 Dec 2016 01:34:25 +0000
Subject: [squid-users] Squid keep using one parent proxy while I have
 multiple parent proxies
In-Reply-To: <PS1PR01MB1306295EADB281CFAD17252E98940@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
References: <PS1PR01MB1306295EADB281CFAD17252E98940@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
Message-ID: <PS1PR01MB1306A3D4710242C670132D2C98960@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>

Hi Amos,

The Squid version I tested is 3.4.14(installed by yum on Centos 6.8) and 3.4.8(installed by apt on Debian 7), both have the problem of use same parent proxy after about 55 seconds. I also test 3.5.23(compiled by default parameter) and found the time increased from 55 to 85 seconds or so. Thanks.

Regards,
Edwin





Message: 1
Date: Sun, 25 Dec 2016 23:25:34 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid keep using one parent proxy while I
        have    multiple parent proxies
Message-ID: <6ace087dad7238ba88b6d89c84dfd373 at treenet.co.nz>
Content-Type: text/plain; charset=US-ASCII; format=flowed

On 2016-12-24 15:43, wei wrote:
> I have the following cache_peer settings in squid.conf, it works fine
> but I found when the interval of every request is more than 55 seconds
> or so, the request will only be forwarded to the last parent(p3), I
> think this is because the counter being reset by squid if there is no
> new request for about 55 seconds, anyone know how to increase this
> value? Many thanks.
>
> cache_peer 192.168.1.100 parent 3128 weight=5 no-query name=p1
> round-robin
> cache_peer 192.168.1.101 parent 3128 weight=5 no-query name=p2
> round-robin
> cache_peer 192.168.1.102 parent 3128 weight=5 no-query name=p3
> round-robin


What version of Squid?

Amos


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161226/18ca157e/attachment.htm>

From edwin.zhou at hotmail.com  Mon Dec 26 01:47:25 2016
From: edwin.zhou at hotmail.com (wei)
Date: Mon, 26 Dec 2016 01:47:25 +0000
Subject: [squid-users] Squid keep using one parent proxy while I have
 multiple parent proxies
In-Reply-To: <PS1PR01MB1306A3D4710242C670132D2C98960@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
References: <PS1PR01MB1306295EADB281CFAD17252E98940@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>,
 <PS1PR01MB1306A3D4710242C670132D2C98960@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
Message-ID: <PS1PR01MB13060DABD12EA640CC6A719B98960@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>

Hi Amos,

The Squid version I tested is 3.4.14(installed by yum on Centos 6.8) and 3.4.8(installed by apt on Debian 7), both have the problem of use same parent proxy after about 55 seconds. I also test 3.5.23(compiled by default parameter) and found the time increased from 55 to 85 seconds or so. Thanks.

Regards,
Edwin





Message: 1
Date: Sun, 25 Dec 2016 23:25:34 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid keep using one parent proxy while I
        have    multiple parent proxies
Message-ID: <6ace087dad7238ba88b6d89c84dfd373 at treenet.co.nz>
Content-Type: text/plain; charset=US-ASCII; format=flowed

On 2016-12-24 15:43, wei wrote:
> I have the following cache_peer settings in squid.conf, it works fine
> but I found when the interval of every request is more than 55 seconds
> or so, the request will only be forwarded to the last parent(p3), I
> think this is because the counter being reset by squid if there is no
> new request for about 55 seconds, anyone know how to increase this
> value? Many thanks.
>
> cache_peer 192.168.1.100 parent 3128 weight=5 no-query name=p1
> round-robin
> cache_peer 192.168.1.101 parent 3128 weight=5 no-query name=p2
> round-robin
> cache_peer 192.168.1.102 parent 3128 weight=5 no-query name=p3
> round-robin


What version of Squid?

Amos


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161226/7cbd1514/attachment.htm>

From eliezer at ngtech.co.il  Mon Dec 26 15:32:21 2016
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Mon, 26 Dec 2016 17:32:21 +0200
Subject: [squid-users] Squid keep using one parent proxy while I have
	multiple parent proxies
In-Reply-To: <PS1PR01MB1306A3D4710242C670132D2C98960@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
References: <PS1PR01MB1306295EADB281CFAD17252E98940@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
 <PS1PR01MB1306A3D4710242C670132D2C98960@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
Message-ID: <39cd01d25f8d$401f8280$c05e8780$@ngtech.co.il>

Can you give a bash example with curl to replicate this issue?

Thanks,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of wei
Sent: Monday, December 26, 2016 3:34 AM
To: squid3 at treenet.co.nz; squid-users at squid-cache.org
Subject: Re: [squid-users] Squid keep using one parent proxy while I have
multiple parent proxies

Hi Amos,

The Squid version I tested is 3.4.14(installed by yum on Centos 6.8) and
3.4.8(installed by apt on Debian 7), both have the problem of use same
parent proxy after about 55 seconds. I also test 3.5.23(compiled by default
parameter) and found the time increased from 55 to 85 seconds or so. Thanks.

Regards,
Edwin




Message: 1
Date: Sun, 25 Dec 2016 23:25:34 +1300
From: Amos Jeffries <mailto:squid3 at treenet.co.nz>
To: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid keep using one parent proxy while I
? ? ? ? have ? ?multiple parent proxies
Message-ID: <mailto:6ace087dad7238ba88b6d89c84dfd373 at treenet.co.nz>
Content-Type: text/plain; charset=US-ASCII; format=flowed

On 2016-12-24 15:43, wei wrote:
> I have the following cache_peer settings in squid.conf, it works fine
> but I found when the interval of every request is more than 55 seconds
> or so, the request will only be forwarded to the last parent(p3), I
> think this is because the counter being reset by squid if there is no
> new request for about 55 seconds, anyone know how to increase this
> value? Many thanks.
>?
> cache_peer 192.168.1.100 parent 3128 weight=5 no-query name=p1
> round-robin
> cache_peer 192.168.1.101 parent 3128 weight=5 no-query name=p2
> round-robin
> cache_peer 192.168.1.102 parent 3128 weight=5 no-query name=p3
> round-robin


What version of Squid?

Amos


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From heiler.bemerguy at cinbesa.com.br  Mon Dec 26 17:11:42 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Mon, 26 Dec 2016 14:11:42 -0300
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
Message-ID: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>


Hi list,

This is my box trying to GET a CSS file via squid 4.0.17:

GET 
http://agendamento.inss.gov.br/saginternet/resources/bootstrap/css/bootstrap.min.css 
HTTP/1.1
Host: agendamento.inss.gov.br
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 
Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3
*Accept-Encoding: none*
Cookie: ACE-STICKY=R1291873686; 
JSESSIONID=nhL8YhJSPnJNvjx6GpQ6LrmckqV0jVkj7p1NxHBktbn47SG2tLrc!-162452808; 
SAG_ROUTEID=.2; ROUTEID=.2
Connection: keep-alive
Upgrade-Insecure-Requests: 1
Pragma: no-cache
Cache-Control: no-cache

This is squid answer:

HTTP/1.1 200 OK
Accept-Ranges: bytes
Last-Modified: Tue, 14 Jun 2016 14:15:36 GMT
Content-Language: en
*Content-Encoding: gzip*
Content-Type: text/html
Server: Oracle-Web-Cache-11g/11.1.1.6.0 (N;ecid=83589858340691620,0:1)
Date: Mon, 26 Dec 2016 17:07:27 GMT
X-Powered-By: Servlet/3.0 JSP/2.2
Cache-Control: max-age=0, no-cache, no-store, must-revalidate
Pragma: no-cache
Content-Length: 0
Age: 0
X-Cache: HIT from proxy
Via: 1.1 proxy (squid)
Connection: keep-alive

I don't know the refresh pattern matters in this case:

refresh_pattern -i 
\.(jp[eg]{1,2}|pdf|gif|pn[pg]|bmp|tiff|ico|swf|css|js|ad|png)$ 10080 80% 
120960 ignore-no-store ignore-reload ignore-private override-expire 
store-stale reload-into-ims

The effect of this "bug" is that the page in question is totally screwed 
up because the CSS file won't be readable by the browser.. (it shows 
nothing if I try to view the source of it)


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161226/675a8307/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Mon Dec 26 18:08:31 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Mon, 26 Dec 2016 15:08:31 -0300
Subject: [squid-users]  squid 4.0.17 accept-encoding.. sending gzip?!!!
Message-ID: <f190cd3e-e25b-8d8d-8f25-36c499ea7c3d@cinbesa.com.br>

Continuing the weirdeness.

It was like this:
1482773242.442     96 10.1.4.22 TCP_REFRESH_UNMODIFIED/200 *31152 *GET 
http://agendamento.inss.gov.br/saginternet/resources/bootstrap/css/bootstrap.min.css 
- HIER_DIRECT/200.152.32.99*text/html*

Then after a full cache wipe:
1482773914.752    344 10.1.4.22 TCP_MISS/200 *31174 *GET 
http://agendamento.inss.gov.br/saginternet/resources/bootstrap/css/bootstrap.min.css 
- HIER_DIRECT/200.152.32.99*text/css*

Then again, but now with correct mime type
1482773937.676    166 10.1.4.22 TCP_REFRESH_UNMODIFIED/200 *31094 *GET 
http://agendamento.inss.gov.br/saginternet/resources/bootstrap/css/bootstrap.min.css 
- HIER_DIRECT/200.152.32.99*text/css*

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161226/474dc812/attachment.htm>

From mabi at protonmail.ch  Mon Dec 26 19:07:03 2016
From: mabi at protonmail.ch (mabi)
Date: Mon, 26 Dec 2016 14:07:03 -0500
Subject: [squid-users] How to bypass Squid proxy in intercept mode using
	acl/always_direct
Message-ID: <OmNaPoqHutswXnyWd2BFgg157nCoXJ1KThGCGrCEGqU_yi9bZhQIokRSJnVev0t6Bppjwh8qVHdRttWypwOoo5MzjBAol_0-J9hyYy5VDDg=@protonmail.ch>

Hello,

I am using Squid 3.5.20 in intercept mode for HTTP and HTTPS traffic with my OpenBSD 6.0 firewall. For some internal servers located on two different subdomains I would like to access these directly and as such bypass the Squid proxy. Is this possible to achieve that using the an acl and always_direct parameters of Squid? I tried it out but checking the squid access.log file I still see the accesses going through the proxy. You will find below my squid.conf file, you will find the acl/always_direct in the last 3 lines of my config.

Thanks for your help.

Regards,
Mabi

acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7 # RFC 4193 local private network range
acl localnet src fe80::/10 # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access deny manager

http_access allow localnet
http_access allow localhost
http_access deny all

coredump_dir /var/squid/cache

refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

url_rewrite_program /usr/local/bin/squidGuard -c /etc/squidguard/squidguard.conf
url_rewrite_children 19 startup=15 idle=10 concurrency=0

http_port 127.0.0.1:3129 intercept

cache_mem 1024 MB
maximum_object_size_in_memory 8 MB
cache_dir ufs /var/squid/cache 800 16 64
minimum_object_size 3 KB
maximum_object_size 6 MB

ipcache_size 10240
fqdncache_size 10240
max_filedescriptors 4096

https_port 127.0.0.1:3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/proxy-ca.pem key=/etc/squid/proxy-ca.pem
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all
sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_program /usr/local/libexec/squid/ssl_crtd -s /var/squid/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1

acl local-servers dstdomain .internal.domain.net
acl local-servers dstdomain .dmz.domain.net
always_direct allow local-servers
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161226/560af1ea/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Dec 26 19:30:21 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 26 Dec 2016 20:30:21 +0100
Subject: [squid-users] How to bypass Squid proxy in intercept mode using
	acl/always_direct
Message-ID: <201612262030.22125.Antony.Stone@squid.open.source.it>

On Monday 26 December 2016 at 20:07:03, mabi wrote:

> Hello,
> 
> I am using Squid 3.5.20 in intercept mode for HTTP and HTTPS traffic with
> my OpenBSD 6.0 firewall. For some internal servers located on two
> different subdomains I would like to access these directly and as such
> bypass the Squid proxy. Is this possible to achieve that using the an acl
> and always_direct parameters of Squid?

I would recommend doing the bypass in the firewall rule which redirects all 
port 80 traffic to Squid - just allow those internal servers to get to the 
Internet without the redirect.


Antony.

-- 
"Black holes are where God divided by zero."

 - Steven Wright

                                                   Please reply to the list;
                                                         please *don't* CC me.


From heiler.bemerguy at cinbesa.com.br  Mon Dec 26 20:12:23 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Mon, 26 Dec 2016 17:12:23 -0300
Subject: [squid-users] squid 4.0.17 gziped and with another headers? (clean
 cache)
Message-ID: <810751a1-da57-65be-e592-3cd8a80e21ce@cinbesa.com.br>


This is the pure get, without proxy.. tcpdumped:
GET /saginternet/resources/bootstrap/css/bootstrap.min.css HTTP/1.1
Host: agendamento.inss.gov.br
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 
Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: none
Connection: keep-alive
Upgrade-Insecure-Requests: 1

The pure reply:
HTTP/1.1 200 OK
Set-Cookie: ACE-STICKY=R1291873686; path=/; expires=Mon, 26-Dec-2016 
23:51:26 GMT
Date: Mon, 26 Dec 2016 19:36:06 GMT
Accept-Ranges: bytes
Content-Length: 152264
Content-Type: text/css; charset=UTF-8
X-Powered-By: Servlet/3.0 JSP/2.2
Cache-Control: max-age=0, no-cache, no-store, must-revalidate
Pragma: no-cache
Content-Language: en
Set-Cookie: 
JSESSIONID=DCLCYhxGPHvpfnPNsPv51cGkS55GPqB4b3xJsybLgLJpyqPZZhNW!-162452808; 
path=/; HttpOnly


Now this is the reply the squid is sending to me while asking the same 
exact file (full url):
HTTP/1.1 200 OK
Accept-Ranges: bytes
Last-Modified: Tue, 14 Jun 2016 14:15:36 GMT
Content-Language: en
*Content-Encoding: gzip*
Content-Type: text/html
*Server: Oracle-Web-Cache-11g/11.1.1.6.0 (N;ecid=85114765013486139,0:1)*
Date: Mon, 26 Dec 2016 19:36:52 GMT
X-Powered-By: Servlet/3.0 JSP/2.2
Cache-Control: max-age=0, no-cache, no-store, must-revalidate
Pragma: no-cache
*Content-Length: 0*
Age: 0
X-Cache: HIT from proxy
Via: 1.1 proxy (squid)
Connection: keep-alive

Where did it get this SERVER name and this ZERO content-length ?!?!

Squid Cache: Version 4.0.17-20161226-r14960

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161226/7bd54115/attachment.htm>

From rousskov at measurement-factory.com  Tue Dec 27 00:07:47 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Dec 2016 17:07:47 -0700
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
In-Reply-To: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
References: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
Message-ID: <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>

On December 26, 2016 10:11:55 AM Heiler Bemerguy wrote:

> *Accept-Encoding: none*

> *Content-Encoding: gzip*

These are end-to-end headers. Squid does not modify or add them (unless you 
tell it to do that).

The origin server does not honor the bogus "none" content coding requested 
by the client.

HTH,

Alex.




From rousskov at measurement-factory.com  Tue Dec 27 00:16:59 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Dec 2016 17:16:59 -0700
Subject: [squid-users] squid 4.0.17 gziped and with another headers?
	(clean cache)
In-Reply-To: <810751a1-da57-65be-e592-3cd8a80e21ce@cinbesa.com.br>
References: <810751a1-da57-65be-e592-3cd8a80e21ce@cinbesa.com.br>
Message-ID: <1593da32478.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>

On December 26, 2016 1:12:36 PM Heiler Bemerguy 
<heiler.bemerguy at cinbesa.com.br> wrote:

> This is the pure get, without proxy.. tcpdumped:
> GET /saginternet/resources/bootstrap/css/bootstrap.min.css HTTP/1.1
> Host: agendamento.inss.gov.br
> User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101
> Firefox/50.0
> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
> Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3
> Accept-Encoding: none
> Connection: keep-alive
> Upgrade-Insecure-Requests: 1
>
> The pure reply:
> HTTP/1.1 200 OK
> Set-Cookie: ACE-STICKY=R1291873686; path=/; expires=Mon, 26-Dec-2016
> 23:51:26 GMT
> Date: Mon, 26 Dec 2016 19:36:06 GMT
> Accept-Ranges: bytes
> Content-Length: 152264
> Content-Type: text/css; charset=UTF-8
> X-Powered-By: Servlet/3.0 JSP/2.2
> Cache-Control: max-age=0, no-cache, no-store, must-revalidate
> Pragma: no-cache
> Content-Language: en
> Set-Cookie:
> JSESSIONID=DCLCYhxGPHvpfnPNsPv51cGkS55GPqB4b3xJsybLgLJpyqPZZhNW!-162452808;
> path=/; HttpOnly
>
>
> Now this is the reply the squid is sending to me while asking the same
> exact file (full url):
> HTTP/1.1 200 OK
> Accept-Ranges: bytes
> Last-Modified: Tue, 14 Jun 2016 14:15:36 GMT
> Content-Language: en
> *Content-Encoding: gzip*
> Content-Type: text/html
> *Server: Oracle-Web-Cache-11g/11.1.1.6.0 (N;ecid=85114765013486139,0:1)*
> Date: Mon, 26 Dec 2016 19:36:52 GMT
> X-Powered-By: Servlet/3.0 JSP/2.2
> Cache-Control: max-age=0, no-cache, no-store, must-revalidate
> Pragma: no-cache
> *Content-Length: 0*
> Age: 0
> X-Cache: HIT from proxy
> Via: 1.1 proxy (squid)
> Connection: keep-alive
>
> Where did it get this SERVER name and this ZERO content-length ?!?!

>From the origin server via the Squid cache, probably because you configured 
Squid to violate HTTP Cache-Control rules.

Alex.





From edwin.zhou at hotmail.com  Tue Dec 27 03:37:49 2016
From: edwin.zhou at hotmail.com (wei)
Date: Tue, 27 Dec 2016 03:37:49 +0000
Subject: [squid-users] Squid keep using one parent proxy while I have
 multiple parent proxies
In-Reply-To: <39cd01d25f8d$401f8280$c05e8780$@ngtech.co.il>
References: <PS1PR01MB1306295EADB281CFAD17252E98940@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>
 <PS1PR01MB1306A3D4710242C670132D2C98960@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>,
 <39cd01d25f8d$401f8280$c05e8780$@ngtech.co.il>
Message-ID: <PS1PR01MB1306DADBBDCFE0E5D82244E698690@PS1PR01MB1306.apcprd01.prod.exchangelabs.com>

The curl command is:


curl -s -i http://showip.net


The configuration in squid.conf is:


cache_peer 192.168.1.100 parent 3128 weight=5 no-query name=p1 round-robin
cache_peer 192.168.1.101 parent 3128 weight=5 no-query name=p2 round-robin
cache_peer 192.168.1.102 parent 3128 weight=5 no-query name=p3 round-robin


cache_peer_domain p1 .com

cache_peer_domain p1 .net
cache_peer_domain p2 .com
cache_peer_domain p2 .net
cache_peer_domain p3 .com
cache_peer_domain p3 .net

Thanks

________________________________
On 26 December 2016 at 15:32, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:

Can you give a bash example with curl to replicate this issue?

Thanks,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of wei
Sent: Monday, December 26, 2016 3:34 AM
To: squid3 at treenet.co.nz; squid-users at squid-cache.org
Subject: Re: [squid-users] Squid keep using one parent proxy while I have
multiple parent proxies

Hi Amos,

The Squid version I tested is 3.4.14(installed by yum on Centos 6.8) and
3.4.8(installed by apt on Debian 7), both have the problem of use same
parent proxy after about 55 seconds. I also test 3.5.23(compiled by default
parameter) and found the time increased from 55 to 85 seconds or so. Thanks.

Regards,
Edwin




Message: 1
Date: Sun, 25 Dec 2016 23:25:34 +1300
From: Amos Jeffries <mailto:squid3 at treenet.co.nz>
To: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid keep using one parent proxy while I
        have    multiple parent proxies
Message-ID: <mailto:6ace087dad7238ba88b6d89c84dfd373 at treenet.co.nz>
Content-Type: text/plain; charset=US-ASCII; format=flowed

On 2016-12-24 15:43, wei wrote:
> I have the following cache_peer settings in squid.conf, it works fine
> but I found when the interval of every request is more than 55 seconds
> or so, the request will only be forwarded to the last parent(p3), I
> think this is because the counter being reset by squid if there is no
> new request for about 55 seconds, anyone know how to increase this
> value? Many thanks.
>
> cache_peer 192.168.1.100 parent 3128 weight=5 no-query name=p1
> round-robin
> cache_peer 192.168.1.101 parent 3128 weight=5 no-query name=p2
> round-robin
> cache_peer 192.168.1.102 parent 3128 weight=5 no-query name=p3
> round-robin


What version of Squid?

Amos


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161227/46825f0c/attachment.htm>

From hardikdangar+squid at gmail.com  Tue Dec 27 11:50:08 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Tue, 27 Dec 2016 17:20:08 +0530
Subject: [squid-users] Squid Websocket Issue
In-Reply-To: <b858d071-bc6c-1789-c72b-d1b9343b32e5@measurement-factory.com>
References: <CA+sSnVZo1250omWkLDzPpknEa-qqLNisA6YJeROx5BxL6pqv9Q@mail.gmail.com>
 <0577240a-6b02-0bd7-2e0d-2e58b5bb7b77@treenet.co.nz>
 <CA+sSnVZYcQkvA=-bBVSuQtoXeYxomL5Ca51cw4ax0dP3EUKF7g@mail.gmail.com>
 <5990ba78-39ea-569a-29dd-409e4912f1a6@treenet.co.nz>
 <010401d259f9$4dfcd630$e9f68290$@ngtech.co.il>
 <CA+sSnVavKQR80XNvykdecMeB1feLwBMEP29Vm+Lxp3=U8-S1dg@mail.gmail.com>
 <CA+sSnVbob7T03YvK8RCHmd4o=9Ej8NZ6vhmgKj+h75hnB1EXdQ@mail.gmail.com>
 <b858d071-bc6c-1789-c72b-d1b9343b32e5@measurement-factory.com>
Message-ID: <CA+sSnVYOZXznoDpAR4pA_-=xNVCQaqPxLbHPs3FdfXa4oduEcA@mail.gmail.com>

Hey Alex,

actually its reverse. If i remove !serverIsws somehow websockets will not
work. conversion does not happen and i get 400 bad request. whereas if i
put !serverIsws then request is converted and status code is 101

acl serverIsws ssl::server_name_regex ^w[0-9]+\.web\.whatsapp\.com$
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice serverIsws
ssl_bump bump !serverIsws all

So above works but if i remove serverIsws then it will not work at all i.e.

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice serverIsws
ssl_bump bump all

above does not work

This is actually surprising for me too :) I did lot of tests with other
websocket apps used by my network and when i remove rules from bump it will
not work. May be amos could tell us something that we don't understand
about acls.


On Tue, Dec 20, 2016 at 10:27 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 12/20/2016 02:42 AM, Hardik Dangar wrote:
> > Following changes in config works and whatsapp starts working,
> >
> > acl serverIsws ssl::server_name_regex ^w[0-9]+\.web\.whatsapp\.com$
> >
> > acl step1 at_step SslBump1
> > ssl_bump peek step1
> > ssl_bump splice serverIsws
> > ssl_bump bump !serverIsws all
>
> You do not need the "!serverIsws" part because if serverIsws matches,
> then the splice rule wins, and Squid does not reach the bump rule. This
> configuration is sufficient:
>
>   ssl_bump peek step1
>   ssl_bump splice serverIsws
>   ssl_bump bump all
>
> In theory, adding "!serverIsws" does not hurt. However, negating complex
> ACLs is tricky/dangerous and should be avoided when possible.
>
> Alex.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161227/07d902eb/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec 27 12:00:31 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 28 Dec 2016 01:00:31 +1300
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
In-Reply-To: <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
References: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
 <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
Message-ID: <88c47e33f72d7917844ac09abca5df36@treenet.co.nz>

On 2016-12-27 13:07, Alex Rousskov wrote:
> On December 26, 2016 10:11:55 AM Heiler Bemerguy wrote:
> 
>> *Accept-Encoding: none*
> 
>> *Content-Encoding: gzip*
> 
> These are end-to-end headers. Squid does not modify or add them
> (unless you tell it to do that).
> 
> The origin server does not honor the bogus "none" content coding
> requested by the client.
> 

More importantly there is no Vary header. The origin server is claiming 
to produce *only* the one response object. That happens to be in gzip 
encoded format.

Since there are no other variants, the client Accept-* headers do not 
matter. Simple as that.

Amos



From heiler.bemerguy at cinbesa.com.br  Tue Dec 27 13:13:50 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 27 Dec 2016 10:13:50 -0300
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
In-Reply-To: <88c47e33f72d7917844ac09abca5df36@treenet.co.nz>
References: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
 <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
 <88c47e33f72d7917844ac09abca5df36@treenet.co.nz>
Message-ID: <318e1cd0-5245-17cf-2d19-0c34da443866@cinbesa.com.br>


Hey dudes, thanks for the replies..

Client GET say it won't accept any encoding format. Why is squid 
compressing it and sending as compressed to a client that explicity says 
it doesn't accept encoding?

Is this really correct? Because no browser is liking it here. Even more, 
I think no data is sent back to the browser, as "Content-Length = 0"


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 27/12/2016 09:00, Amos Jeffries escreveu:
> On 2016-12-27 13:07, Alex Rousskov wrote:
>> On December 26, 2016 10:11:55 AM Heiler Bemerguy wrote:
>>
>>> *Accept-Encoding: none*
>>
>>> *Content-Encoding: gzip*
>>
>> These are end-to-end headers. Squid does not modify or add them
>> (unless you tell it to do that).
>>
>> The origin server does not honor the bogus "none" content coding
>> requested by the client.
>>
>
> More importantly there is no Vary header. The origin server is 
> claiming to produce *only* the one response object. That happens to be 
> in gzip encoded format.
>
> Since there are no other variants, the client Accept-* headers do not 
> matter. Simple as that.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From heiler.bemerguy at cinbesa.com.br  Tue Dec 27 14:02:53 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 27 Dec 2016 11:02:53 -0300
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
In-Reply-To: <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
References: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
 <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
Message-ID: <97c3616c-1eec-f036-9150-efa0b1c96f7a@cinbesa.com.br>


The server doesn't define any "content-encoding". This is the *original 
**server *reply, tcpdumped:

    HTTP/1.1 200 OK
    Set-Cookie: ACE-STICKY=R1291873686; path=/; expires=Mon, 26-Dec-2016
    23:51:26 GMT
    Date: Mon, 26 Dec 2016 19:36:06 GMT
    Accept-Ranges: bytes
    Content-Length: 152264
    Content-Type: text/css; charset=UTF-8
    X-Powered-By: Servlet/3.0 JSP/2.2
    Cache-Control: max-age=0, no-cache, no-store, must-revalidate
    Pragma: no-cache
    Content-Language: en
    Set-Cookie:
    JSESSIONID=DCLCYhxGPHvpfnPNsPv51cGkS55GPqB4b3xJsybLgLJpyqPZZhNW!-162452808;

    path=/; HttpOnly


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



Em 26/12/2016 21:07, Alex Rousskov escreveu:
> On December 26, 2016 10:11:55 AM Heiler Bemerguy wrote:
>
>> *Accept-Encoding: none*
>
>> *Content-Encoding: gzip*
>
> These are end-to-end headers. Squid does not modify or add them 
> (unless you tell it to do that).
>
> The origin server does not honor the bogus "none" content coding 
> requested by the client.
>
> HTH,
>
> Alex.
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161227/0914ee6e/attachment.htm>

From q.dutheil at montpellier3m.fr  Tue Dec 27 16:03:52 2016
From: q.dutheil at montpellier3m.fr (qdmetro)
Date: Tue, 27 Dec 2016 08:03:52 -0800 (PST)
Subject: [squid-users] ACL and outgoing IP
Message-ID: <1482854632538-4680990.post@n4.nabble.com>

Hello,
I have an issue with acl and outgoing ip address.

I have a squid connected behind a firewall. On the firewall, only the Ip of
the squid (192.168.1.1) is allowed to go on Internet.

Usually, when a user authenticate itself on the proxy, all the requests use
the outgoing IP of the squid (192.168.1.1) so the can access to the website.
I want to allow some websites to be reachable without authentication
(especially for the activation of windows licences). I've tried this :

/acl Microsoft dstdomain .microsoft.com
http_access allow Microsoft/

With this configuration, the requests don't use the outgoing Ip of the proxy
anymore, so they come to my firewall with the source IP of the client (which
is not allowed to go on the Internet).
I've tried this to force the outgoing IP for this acl :

/tcp_outgoing_address 192.168.1.1 Microsoft/

but the request still don't use the IP of the proxy.

Maybe this kind of configuration isn't possible, or I miss something...
Any idea to help me ? 

Thanks !



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/ACL-and-outgoing-IP-tp4680990.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Tue Dec 27 16:30:05 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 27 Dec 2016 17:30:05 +0100
Subject: [squid-users] ACL and outgoing IP
In-Reply-To: <1482854632538-4680990.post@n4.nabble.com>
References: <1482854632538-4680990.post@n4.nabble.com>
Message-ID: <201612271730.05883.Antony.Stone@squid.open.source.it>

On Tuesday 27 December 2016 at 17:03:52, qdmetro wrote:

> I have a squid connected behind a firewall. On the firewall, only the Ip of
> the squid (192.168.1.1) is allowed to go on Internet.
> 
> Usually, when a user authenticate itself on the proxy, all the requests use
> the outgoing IP of the squid (192.168.1.1) so the can access to the
> website. I want to allow some websites to be reachable without
> authentication (especially for the activation of windows licences). I've
> tried this :
> 
> /acl Microsoft dstdomain .microsoft.com
> http_access allow Microsoft/
> 
> With this configuration, the requests don't use the outgoing Ip of the
> proxy anymore, so they come to my firewall with the source IP of the
> client (which is not allowed to go on the Internet).
> I've tried this to force the outgoing IP for this acl :
> 
> /tcp_outgoing_address 192.168.1.1 Microsoft/
> 
> but the request still don't use the IP of the proxy.
> 
> Maybe this kind of configuration isn't possible, or I miss something...

Show us your full squid.conf (just post it here in a reply, omitting comments 
and blank lines).

That should give us more useful information to go on.


Antony.

-- 
I don't know, maybe if we all waited then cosmic rays would write all our 
software for us. Of course it might take a while.

 - Ron Minnich, Los Alamos National Laboratory

                                                   Please reply to the list;
                                                         please *don't* CC me.


From eliezer at ngtech.co.il  Tue Dec 27 17:26:49 2016
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 27 Dec 2016 19:26:49 +0200
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
In-Reply-To: <97c3616c-1eec-f036-9150-efa0b1c96f7a@cinbesa.com.br>
References: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
 <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
 <97c3616c-1eec-f036-9150-efa0b1c96f7a@cinbesa.com.br>
Message-ID: <3a4301d26066$67d4b690$377e23b0$@ngtech.co.il>

May I ask how did you manager to tell squid to cache a no-cache object?

>From the dump it states:

Cache-Control: max-age=0, no-cache, no-store, must-revalidate


Which means it should not be cached..

 

Eliezer

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Heiler Bemerguy
Sent: Tuesday, December 27, 2016 4:03 PM
To: squid-users at squid-cache.org
Subject: Re: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!

 

 

The server doesn't define any "content-encoding". This is the original
server reply, tcpdumped:

HTTP/1.1 200 OK 
Set-Cookie: ACE-STICKY=R1291873686; path=/; expires=Mon, 26-Dec-2016 
23:51:26 GMT 
Date: Mon, 26 Dec 2016 19:36:06 GMT 
Accept-Ranges: bytes 
Content-Length: 152264 
Content-Type: text/css; charset=UTF-8 
X-Powered-By: Servlet/3.0 JSP/2.2 
Cache-Control: max-age=0, no-cache, no-store, must-revalidate 
Pragma: no-cache 
Content-Language: en 
Set-Cookie: 
JSESSIONID=DCLCYhxGPHvpfnPNsPv51cGkS55GPqB4b3xJsybLgLJpyqPZZhNW!-162452808; 
path=/; HttpOnly 





-- 
Best Regards,
 
Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

 

Em 26/12/2016 21:07, Alex Rousskov escreveu:

On December 26, 2016 10:11:55 AM Heiler Bemerguy wrote: 




*Accept-Encoding: none* 





*Content-Encoding: gzip* 


These are end-to-end headers. Squid does not modify or add them (unless you
tell it to do that). 

The origin server does not honor the bogus "none" content coding requested
by the client. 

HTH, 

Alex. 



 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161227/9b008247/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 11297 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161227/9b008247/attachment.png>

From heiler.bemerguy at cinbesa.com.br  Tue Dec 27 17:31:14 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 27 Dec 2016 14:31:14 -0300
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
In-Reply-To: <3a4301d26066$67d4b690$377e23b0$@ngtech.co.il>
References: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
 <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
 <97c3616c-1eec-f036-9150-efa0b1c96f7a@cinbesa.com.br>
 <3a4301d26066$67d4b690$377e23b0$@ngtech.co.il>
Message-ID: <0a898562-314f-1038-e5ba-f790e9b355d6@cinbesa.com.br>

Hi,

refresh_pattern -i 
\.(jp[eg]{1,2}|pdf|gif|pn[pg]|bmp|tiff|ico|swf|css|js|ad|png)$ 10080 80% 
120960 ignore-no-store ignore-reload ignore-must-revalidate 
ignore-private override-expire store-stale

But it shouldn't change the length of the object, the encoding type of 
the object, the "Server" header of the object..... or am I wrong?


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 27/12/2016 14:26, Eliezer Croitoru escreveu:
>
> May I ask how did you manager to tell squid to cache a no-cache object?
>
> From the dump it states:
>
> Cache-Control: max-age=0, no-cache, no-store, must-revalidate
>
>
> Which means it should not be cached?.
>
> Eliezer
>
> ----
>
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> *On Behalf Of *Heiler Bemerguy
> *Sent:* Tuesday, December 27, 2016 4:03 PM
> *To:* squid-users at squid-cache.org
> *Subject:* Re: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
>
> The server doesn't define any "content-encoding". This is the 
> *original **server *reply, tcpdumped:
>
>     HTTP/1.1 200 OK
>     Set-Cookie: ACE-STICKY=R1291873686; path=/; expires=Mon, 26-Dec-2016
>     23:51:26 GMT
>     Date: Mon, 26 Dec 2016 19:36:06 GMT
>     Accept-Ranges: bytes
>     Content-Length: 152264
>     Content-Type: text/css; charset=UTF-8
>     X-Powered-By: Servlet/3.0 JSP/2.2
>     Cache-Control: max-age=0, no-cache, no-store, must-revalidate
>     Pragma: no-cache
>     Content-Language: en
>     Set-Cookie:
>     JSESSIONID=DCLCYhxGPHvpfnPNsPv51cGkS55GPqB4b3xJsybLgLJpyqPZZhNW!-162452808;
>
>     path=/; HttpOnly
>
>
>
> -- 
> Best Regards,
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
> Em 26/12/2016 21:07, Alex Rousskov escreveu:
>
>     On December 26, 2016 10:11:55 AM Heiler Bemerguy wrote:
>
>
>         *Accept-Encoding: none*
>
>
>
>         *Content-Encoding: gzip*
>
>
>     These are end-to-end headers. Squid does not modify or add them
>     (unless you tell it to do that).
>
>     The origin server does not honor the bogus "none" content coding
>     requested by the client.
>
>     HTH,
>
>     Alex.
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161227/95ac09e3/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 11297 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161227/95ac09e3/attachment.png>

From eliezer at ngtech.co.il  Tue Dec 27 18:26:35 2016
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 27 Dec 2016 20:26:35 +0200
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
In-Reply-To: <0a898562-314f-1038-e5ba-f790e9b355d6@cinbesa.com.br>
References: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
 <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
 <97c3616c-1eec-f036-9150-efa0b1c96f7a@cinbesa.com.br>
 <3a4301d26066$67d4b690$377e23b0$@ngtech.co.il>
 <0a898562-314f-1038-e5ba-f790e9b355d6@cinbesa.com.br>
Message-ID: <3a5f01d2606e$c1a99070$44fcb150$@ngtech.co.il>

And what shows in the access.log when you fetch this object?
The response headers are missing couple things.
Also you are using a heuristic refresh_pattern that should not work and it's
wrong to use such.
The first thing is to change the refresh pattern to something more connected
to reality rather then science fiction.
refresh_pattern -i
\.(jp[eg]{1,2}|pdf|gif|pn[pg]|bmp|tiff|ico|swf|css|js|ad|png)$ 1800 80% 7200

Try It and see if it changes something.
And a refence for the available options that can be used with enough details
to start to understand what you are doing:
http://www.squid-cache.org/Versions/v4/cfgman/refresh_pattern.html

In this specific case there is a cache server.. Oracle at the other side and
the logs are the only one which will give us a glimpse into what is going on
for real.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Heiler Bemerguy
Sent: Tuesday, December 27, 2016 7:31 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!

Hi,
refresh_pattern -i
\.(jp[eg]{1,2}|pdf|gif|pn[pg]|bmp|tiff|ico|swf|css|js|ad|png)$ 10080 80%
120960 ignore-no-store ignore-reload ignore-must-revalidate ignore-private
override-expire store-stale
But it shouldn't change the length of the object, the encoding type of the
object, the "Server" header of the object..... or am I wrong?


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

Em 27/12/2016 14:26, Eliezer Croitoru escreveu:
May I ask how did you manager to tell squid to cache a no-cache object?
>From the dump it states:
Cache-Control: max-age=0, no-cache, no-store, must-revalidate

Which means it should not be cached?.
?
Eliezer
?
----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il

?
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Heiler Bemerguy
Sent: Tuesday, December 27, 2016 4:03 PM
To: mailto:squid-users at squid-cache.org
Subject: Re: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
?
?
The server doesn't define any "content-encoding". This is the original
server reply, tcpdumped:
HTTP/1.1 200 OK 
Set-Cookie: ACE-STICKY=R1291873686; path=/; expires=Mon, 26-Dec-2016 
23:51:26 GMT 
Date: Mon, 26 Dec 2016 19:36:06 GMT 
Accept-Ranges: bytes 
Content-Length: 152264 
Content-Type: text/css; charset=UTF-8 
X-Powered-By: Servlet/3.0 JSP/2.2 
Cache-Control: max-age=0, no-cache, no-store, must-revalidate 
Pragma: no-cache 
Content-Language: en 
Set-Cookie: 
JSESSIONID=DCLCYhxGPHvpfnPNsPv51cGkS55GPqB4b3xJsybLgLJpyqPZZhNW!-162452808; 
path=/; HttpOnly 



-- 
Best Regards,
?
Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751
?
Em 26/12/2016 21:07, Alex Rousskov escreveu:
On December 26, 2016 10:11:55 AM Heiler Bemerguy wrote: 



*Accept-Encoding: none* 



*Content-Encoding: gzip* 

These are end-to-end headers. Squid does not modify or add them (unless you
tell it to do that). 

The origin server does not honor the bogus "none" content coding requested
by the client. 

HTH, 

Alex. 


?




From uhlar at fantomas.sk  Tue Dec 27 19:03:51 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 27 Dec 2016 20:03:51 +0100
Subject: [squid-users] How to bypass Squid proxy in intercept mode using
 acl/always_direct
In-Reply-To: <OmNaPoqHutswXnyWd2BFgg157nCoXJ1KThGCGrCEGqU_yi9bZhQIokRSJnVev0t6Bppjwh8qVHdRttWypwOoo5MzjBAol_0-J9hyYy5VDDg=@protonmail.ch>
References: <OmNaPoqHutswXnyWd2BFgg157nCoXJ1KThGCGrCEGqU_yi9bZhQIokRSJnVev0t6Bppjwh8qVHdRttWypwOoo5MzjBAol_0-J9hyYy5VDDg=@protonmail.ch>
Message-ID: <20161227190351.GA32734@fantomas.sk>

On 26.12.16 14:07, mabi wrote:
>I am using Squid 3.5.20 in intercept mode for HTTP and HTTPS traffic with
> my OpenBSD 6.0 firewall.  For some internal servers located on two
> different subdomains I would like to access these directly and as such
> bypass the Squid proxy.  Is this possible to achieve that using the an acl
> and always_direct parameters of Squid? 

No. It is NOT possible to configure bypassing on the squid proxy.
Proxy can only handle connections that did NOT bypass it.
Bypassing means that connections will NOT be done to squid.

That means, when a connection reaches squid, it's already too late to bypass
it.

The only way to bypass squid is to configure router not to send connections
to it.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Christian Science Programming: "Let God Debug It!".


From q.dutheil at montpellier3m.fr  Wed Dec 28 08:22:47 2016
From: q.dutheil at montpellier3m.fr (qdmetro)
Date: Wed, 28 Dec 2016 00:22:47 -0800 (PST)
Subject: [squid-users] ACL and outgoing IP
In-Reply-To: <201612271730.05883.Antony.Stone@squid.open.source.it>
References: <1482854632538-4680990.post@n4.nabble.com>
 <201612271730.05883.Antony.Stone@squid.open.source.it>
Message-ID: <1482913367413-4680996.post@n4.nabble.com>

Here the squid.conf :

auth_param negotiate program /usr/lib/squid3/squid_kerb_auth -s
GSS_C_NO_NAME HTTP/hostname.domain.com
auth_param negotiate children 200
auth_param negotiate keep_alive on
auth_param basic program /usr/lib/squid3/squid_ldap_auth -b
"ou=users,dc=ref,dc=local" -u uid ref.domain.com
url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
url_rewrite_children 80
acl SSL_ports port 443 4443
acl SSL_ports port 563 4431
acl SSL_ports port 873
acl SSL_ports port 7071
acl SSL_ports port 33333 33334
acl SSL_ports port 83
acl Safe_ports port 21
acl Safe_ports port 22
acl Safe_ports port 80 81
acl Safe_ports port 443
acl CONNECT method CONNECT
acl domain_auth proxy_auth REQUIRED
acl localhost src 127.0.0.1/32
acl password proxy_auth REQUIRED
visible_hostname name
snmp_port 3401
acl acl_snmp snmp_community com_name
snmp_access allow acl_snmp
acl localnet src 10.0.0.0/8
acl Microsoft dstdomain .microsoft.com
delay_pools 2
delay_class 2 2
delay_access 2 allow localnet
delay_parameters 2 12233386/12233386 12233386/12233386
forwarded_for on
follow_x_forwarded_for allow localnet
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow Microsoft
tcp_outgoing_address 192.168.1.1 Microsoft
http_access allow localnet password
http_access allow localnet domain_auth
http_access deny all
http_reply_access allow localnet
icp_access deny all
htcp_access deny all
http_port 3128
icp_port 3130
dns_v4_first on
cache_mem 4096 MB
cache_swap_low 75
cache_swap_high 90
cache_replacement_policy heap GDSF
cache_dir ufs /var/spool/squid3 5000 16 256
maximum_object_size_in_memory 128 KB
maximum_object_size 2 MB
access_log /var/log/squid3/access.log squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern (cgi-bin|\?)    0       0%      0
refresh_pattern .               0       20%     4320


Thanks for your help.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/ACL-and-outgoing-IP-tp4680990p4680996.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Dec 28 11:58:27 2016
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 28 Dec 2016 13:58:27 +0200
Subject: [squid-users] SNAT BASED on tos. Anyone tried it?
Message-ID: <3ac001d26101$b37226f0$1a5674d0$@ngtech.co.il>

I was wondering if someone tried to do something like this:
Mark the outgoing traffic with a TOS and create a SNAT rule in iptables to
change the source ip address?
Something like:
# iptables?-t?nat?-A?POSTROUTING?-m tos --tos 0x02 -o eth0?-j?SNAT
--to?192.168.1.1

## squid.conf
tcp_outgoing_tos 0x02 !some_users

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il





From eduardoocarneiro at gmail.com  Wed Dec 28 17:16:26 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Wed, 28 Dec 2016 09:16:26 -0800 (PST)
Subject: [squid-users] Problem with ssl_crtd
Message-ID: <1482945386684-4680998.post@n4.nabble.com>

Hi everyone.

I have a strange issue with my squid 3.5.19. When I enable ssl-bump and
url_rewrite in order to make dynamic content cache, I've got, sporadically,
this error in my cache.log:

/assertion failed: Read.cc:69: "fd_table[conn->fd].halfClosedReader !=
NULL"/

When the error occur, my squid simply stops.

Here is a part of my cache.log:

---
2016/12/28 12:29:17 kid1| assertion failed: Read.cc:69:
"fd_table[conn->fd].halfClosedReader != NULL"
2016/12/28 12:36:21 kid1| Set Current Directory to /proxycache
2016/12/28 12:36:21 kid1| Starting Squid Cache version 3.5.19 for
x86_64-pc-linux-gnu...
2016/12/28 12:36:21 kid1| Service Name: squid
2016/12/28 12:36:21 kid1| Process ID 15359
2016/12/28 12:36:21 kid1| Process Roles: worker
2016/12/28 12:36:21 kid1| With 40960 file descriptors available
2016/12/28 12:36:21 kid1| Initializing IP Cache...
2016/12/28 12:36:21 kid1| DNS Socket created at [::], FD 7
2016/12/28 12:36:21 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/12/28 12:36:21 kid1| Adding nameserver 172.31.32.12 from
/etc/resolv.conf
2016/12/28 12:36:21 kid1| Adding nameserver 172.31.32.31 from
/etc/resolv.conf
2016/12/28 12:36:21 kid1| Adding domain domain.com from /etc/resolv.conf
2016/12/28 12:36:21 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.19): Terminated abnormally.
CPU Usage: 0.252 seconds = 0.056 user + 0.196 sys
Maximum Resident Size: 81088 KB
Page faults with physical i/o: 13
2016/12/28 12:36:24 kid1| Set Current Directory to /proxycache
2016/12/28 12:36:24 kid1| Starting Squid Cache version 3.5.19 for
x86_64-pc-linux-gnu...
2016/12/28 12:36:24 kid1| Service Name: squid
2016/12/28 12:36:24 kid1| Process ID 15368
2016/12/28 12:36:24 kid1| Process Roles: worker
2016/12/28 12:36:24 kid1| With 40960 file descriptors available
2016/12/28 12:36:24 kid1| Initializing IP Cache...
2016/12/28 12:36:24 kid1| DNS Socket created at [::], FD 7
2016/12/28 12:36:24 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/12/28 12:36:24 kid1| Adding nameserver 172.31.32.12 from
/etc/resolv.conf
2016/12/28 12:36:24 kid1| Adding nameserver 172.31.32.31 from
/etc/resolv.conf
2016/12/28 12:36:24 kid1| Adding domain domain.com from /etc/resolv.conf
2016/12/28 12:36:24 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.19): Terminated abnormally.
CPU Usage: 0.032 seconds = 0.032 user + 0.000 sys
Maximum Resident Size: 80624 KB
Page faults with physical i/o: 0
2016/12/28 12:36:27 kid1| Set Current Directory to /proxycache
2016/12/28 12:36:27 kid1| Starting Squid Cache version 3.5.19 for
x86_64-pc-linux-gnu...
2016/12/28 12:36:27 kid1| Service Name: squid
2016/12/28 12:36:27 kid1| Process ID 15375
2016/12/28 12:36:27 kid1| Process Roles: worker
2016/12/28 12:36:27 kid1| With 40960 file descriptors available
2016/12/28 12:36:27 kid1| Initializing IP Cache...
2016/12/28 12:36:27 kid1| DNS Socket created at [::], FD 7
2016/12/28 12:36:27 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/12/28 12:36:27 kid1| Adding nameserver 172.31.32.12 from
/etc/resolv.conf
2016/12/28 12:36:27 kid1| Adding nameserver 172.31.32.31 from
/etc/resolv.conf
2016/12/28 12:36:27 kid1| Adding domain domain.com from /etc/resolv.conf
2016/12/28 12:36:27 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.19): Terminated abnormally.
CPU Usage: 0.032 seconds = 0.028 user + 0.004 sys
Maximum Resident Size: 79904 KB
Page faults with physical i/o: 0
2016/12/28 12:36:30 kid1| Set Current Directory to /proxycache
2016/12/28 12:36:30 kid1| Starting Squid Cache version 3.5.19 for
x86_64-pc-linux-gnu...
2016/12/28 12:36:30 kid1| Service Name: squid
2016/12/28 12:36:30 kid1| Process ID 15382
2016/12/28 12:36:30 kid1| Process Roles: worker
2016/12/28 12:36:30 kid1| With 40960 file descriptors available
2016/12/28 12:36:30 kid1| Initializing IP Cache...
2016/12/28 12:36:30 kid1| DNS Socket created at [::], FD 7
2016/12/28 12:36:30 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/12/28 12:36:30 kid1| Adding nameserver 172.31.32.12 from
/etc/resolv.conf
2016/12/28 12:36:30 kid1| Adding nameserver 172.31.32.31 from
/etc/resolv.conf
2016/12/28 12:36:30 kid1| Adding domain domain.com from /etc/resolv.conf
2016/12/28 12:36:30 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
---

If I disable ssl-bump and url_rewrite, the error does not occur. I saw here
in the list that this were a bug on squid 3.4, but I'm using squid 3.5.19.

Someone knows how to fix this?

Thanks in advance.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Problem-with-ssl-crtd-tp4680998.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Dec 28 19:57:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 29 Dec 2016 01:57:49 +0600
Subject: [squid-users] Problem with ssl_crtd
In-Reply-To: <1482945386684-4680998.post@n4.nabble.com>
References: <1482945386684-4680998.post@n4.nabble.com>
Message-ID: <1572281d-bbce-18a3-4684-032e1ebb78cf@gmail.com>

Try to upgrade to 3.5.23. It seems like partially fixed bug.


28.12.2016 23:16, Eduardo Carneiro ?????:
> Hi everyone.
>
> I have a strange issue with my squid 3.5.19. When I enable ssl-bump and
> url_rewrite in order to make dynamic content cache, I've got, sporadically,
> this error in my cache.log:
>
> /assertion failed: Read.cc:69: "fd_table[conn->fd].halfClosedReader !=
> NULL"/
>
> When the error occur, my squid simply stops.
>
> Here is a part of my cache.log:
>
> ---
> 2016/12/28 12:29:17 kid1| assertion failed: Read.cc:69:
> "fd_table[conn->fd].halfClosedReader != NULL"
> 2016/12/28 12:36:21 kid1| Set Current Directory to /proxycache
> 2016/12/28 12:36:21 kid1| Starting Squid Cache version 3.5.19 for
> x86_64-pc-linux-gnu...
> 2016/12/28 12:36:21 kid1| Service Name: squid
> 2016/12/28 12:36:21 kid1| Process ID 15359
> 2016/12/28 12:36:21 kid1| Process Roles: worker
> 2016/12/28 12:36:21 kid1| With 40960 file descriptors available
> 2016/12/28 12:36:21 kid1| Initializing IP Cache...
> 2016/12/28 12:36:21 kid1| DNS Socket created at [::], FD 7
> 2016/12/28 12:36:21 kid1| DNS Socket created at 0.0.0.0, FD 9
> 2016/12/28 12:36:21 kid1| Adding nameserver 172.31.32.12 from
> /etc/resolv.conf
> 2016/12/28 12:36:21 kid1| Adding nameserver 172.31.32.31 from
> /etc/resolv.conf
> 2016/12/28 12:36:21 kid1| Adding domain domain.com from /etc/resolv.conf
> 2016/12/28 12:36:21 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
> processes
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
>
> Squid Cache (Version 3.5.19): Terminated abnormally.
> CPU Usage: 0.252 seconds = 0.056 user + 0.196 sys
> Maximum Resident Size: 81088 KB
> Page faults with physical i/o: 13
> 2016/12/28 12:36:24 kid1| Set Current Directory to /proxycache
> 2016/12/28 12:36:24 kid1| Starting Squid Cache version 3.5.19 for
> x86_64-pc-linux-gnu...
> 2016/12/28 12:36:24 kid1| Service Name: squid
> 2016/12/28 12:36:24 kid1| Process ID 15368
> 2016/12/28 12:36:24 kid1| Process Roles: worker
> 2016/12/28 12:36:24 kid1| With 40960 file descriptors available
> 2016/12/28 12:36:24 kid1| Initializing IP Cache...
> 2016/12/28 12:36:24 kid1| DNS Socket created at [::], FD 7
> 2016/12/28 12:36:24 kid1| DNS Socket created at 0.0.0.0, FD 9
> 2016/12/28 12:36:24 kid1| Adding nameserver 172.31.32.12 from
> /etc/resolv.conf
> 2016/12/28 12:36:24 kid1| Adding nameserver 172.31.32.31 from
> /etc/resolv.conf
> 2016/12/28 12:36:24 kid1| Adding domain domain.com from /etc/resolv.conf
> 2016/12/28 12:36:24 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
> processes
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
>
> Squid Cache (Version 3.5.19): Terminated abnormally.
> CPU Usage: 0.032 seconds = 0.032 user + 0.000 sys
> Maximum Resident Size: 80624 KB
> Page faults with physical i/o: 0
> 2016/12/28 12:36:27 kid1| Set Current Directory to /proxycache
> 2016/12/28 12:36:27 kid1| Starting Squid Cache version 3.5.19 for
> x86_64-pc-linux-gnu...
> 2016/12/28 12:36:27 kid1| Service Name: squid
> 2016/12/28 12:36:27 kid1| Process ID 15375
> 2016/12/28 12:36:27 kid1| Process Roles: worker
> 2016/12/28 12:36:27 kid1| With 40960 file descriptors available
> 2016/12/28 12:36:27 kid1| Initializing IP Cache...
> 2016/12/28 12:36:27 kid1| DNS Socket created at [::], FD 7
> 2016/12/28 12:36:27 kid1| DNS Socket created at 0.0.0.0, FD 9
> 2016/12/28 12:36:27 kid1| Adding nameserver 172.31.32.12 from
> /etc/resolv.conf
> 2016/12/28 12:36:27 kid1| Adding nameserver 172.31.32.31 from
> /etc/resolv.conf
> 2016/12/28 12:36:27 kid1| Adding domain domain.com from /etc/resolv.conf
> 2016/12/28 12:36:27 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
> processes
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
>
> Squid Cache (Version 3.5.19): Terminated abnormally.
> CPU Usage: 0.032 seconds = 0.028 user + 0.004 sys
> Maximum Resident Size: 79904 KB
> Page faults with physical i/o: 0
> 2016/12/28 12:36:30 kid1| Set Current Directory to /proxycache
> 2016/12/28 12:36:30 kid1| Starting Squid Cache version 3.5.19 for
> x86_64-pc-linux-gnu...
> 2016/12/28 12:36:30 kid1| Service Name: squid
> 2016/12/28 12:36:30 kid1| Process ID 15382
> 2016/12/28 12:36:30 kid1| Process Roles: worker
> 2016/12/28 12:36:30 kid1| With 40960 file descriptors available
> 2016/12/28 12:36:30 kid1| Initializing IP Cache...
> 2016/12/28 12:36:30 kid1| DNS Socket created at [::], FD 7
> 2016/12/28 12:36:30 kid1| DNS Socket created at 0.0.0.0, FD 9
> 2016/12/28 12:36:30 kid1| Adding nameserver 172.31.32.12 from
> /etc/resolv.conf
> 2016/12/28 12:36:30 kid1| Adding nameserver 172.31.32.31 from
> /etc/resolv.conf
> 2016/12/28 12:36:30 kid1| Adding domain domain.com from /etc/resolv.conf
> 2016/12/28 12:36:30 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
> processes
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
> ---
>
> If I disable ssl-bump and url_rewrite, the error does not occur. I saw here
> in the list that this were a bug on squid 3.4, but I'm using squid 3.5.19.
>
> Someone knows how to fix this?
>
> Thanks in advance.
>
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Problem-with-ssl-crtd-tp4680998.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
What is the fundamental difference between the programmer and by a fag?
Fag never become five times to free the memory of one object. Fag will
not use two almost identical string libraries in the same project. Fag
will never write to a mixture of C and C ++. Fag will never pass objects
by pointer. Now you know why these two categories so often mentioned
together, and one of them is worse :)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161229/728f93c6/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161229/728f93c6/attachment.sig>

From eliezer at ngtech.co.il  Thu Dec 29 00:07:43 2016
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Thu, 29 Dec 2016 02:07:43 +0200
Subject: [squid-users] Problem with ssl_crtd
In-Reply-To: <1482945386684-4680998.post@n4.nabble.com>
References: <1482945386684-4680998.post@n4.nabble.com>
Message-ID: <001301d26167$93eb41c0$bbc1c540$@ngtech.co.il>

Depends on what is causing the issue.
What bug report are you writing about? Do you have a specific one that you have seen?

Also if you can disable CONNECT requests from url_rewrite it might solve an issue or two.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eduardo Carneiro
Sent: Wednesday, December 28, 2016 7:16 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Problem with ssl_crtd

Hi everyone.

I have a strange issue with my squid 3.5.19. When I enable ssl-bump and url_rewrite in order to make dynamic content cache, I've got, sporadically, this error in my cache.log:

/assertion failed: Read.cc:69: "fd_table[conn->fd].halfClosedReader != NULL"/

When the error occur, my squid simply stops.

Here is a part of my cache.log:

---
2016/12/28 12:29:17 kid1| assertion failed: Read.cc:69:
"fd_table[conn->fd].halfClosedReader != NULL"
2016/12/28 12:36:21 kid1| Set Current Directory to /proxycache
2016/12/28 12:36:21 kid1| Starting Squid Cache version 3.5.19 for x86_64-pc-linux-gnu...
2016/12/28 12:36:21 kid1| Service Name: squid
2016/12/28 12:36:21 kid1| Process ID 15359
2016/12/28 12:36:21 kid1| Process Roles: worker
2016/12/28 12:36:21 kid1| With 40960 file descriptors available
2016/12/28 12:36:21 kid1| Initializing IP Cache...
2016/12/28 12:36:21 kid1| DNS Socket created at [::], FD 7
2016/12/28 12:36:21 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/12/28 12:36:21 kid1| Adding nameserver 172.31.32.12 from /etc/resolv.conf
2016/12/28 12:36:21 kid1| Adding nameserver 172.31.32.31 from /etc/resolv.conf
2016/12/28 12:36:21 kid1| Adding domain domain.com from /etc/resolv.conf
2016/12/28 12:36:21 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.19): Terminated abnormally.
CPU Usage: 0.252 seconds = 0.056 user + 0.196 sys Maximum Resident Size: 81088 KB Page faults with physical i/o: 13
2016/12/28 12:36:24 kid1| Set Current Directory to /proxycache
2016/12/28 12:36:24 kid1| Starting Squid Cache version 3.5.19 for x86_64-pc-linux-gnu...
2016/12/28 12:36:24 kid1| Service Name: squid
2016/12/28 12:36:24 kid1| Process ID 15368
2016/12/28 12:36:24 kid1| Process Roles: worker
2016/12/28 12:36:24 kid1| With 40960 file descriptors available
2016/12/28 12:36:24 kid1| Initializing IP Cache...
2016/12/28 12:36:24 kid1| DNS Socket created at [::], FD 7
2016/12/28 12:36:24 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/12/28 12:36:24 kid1| Adding nameserver 172.31.32.12 from /etc/resolv.conf
2016/12/28 12:36:24 kid1| Adding nameserver 172.31.32.31 from /etc/resolv.conf
2016/12/28 12:36:24 kid1| Adding domain domain.com from /etc/resolv.conf
2016/12/28 12:36:24 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.19): Terminated abnormally.
CPU Usage: 0.032 seconds = 0.032 user + 0.000 sys Maximum Resident Size: 80624 KB Page faults with physical i/o: 0
2016/12/28 12:36:27 kid1| Set Current Directory to /proxycache
2016/12/28 12:36:27 kid1| Starting Squid Cache version 3.5.19 for x86_64-pc-linux-gnu...
2016/12/28 12:36:27 kid1| Service Name: squid
2016/12/28 12:36:27 kid1| Process ID 15375
2016/12/28 12:36:27 kid1| Process Roles: worker
2016/12/28 12:36:27 kid1| With 40960 file descriptors available
2016/12/28 12:36:27 kid1| Initializing IP Cache...
2016/12/28 12:36:27 kid1| DNS Socket created at [::], FD 7
2016/12/28 12:36:27 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/12/28 12:36:27 kid1| Adding nameserver 172.31.32.12 from /etc/resolv.conf
2016/12/28 12:36:27 kid1| Adding nameserver 172.31.32.31 from /etc/resolv.conf
2016/12/28 12:36:27 kid1| Adding domain domain.com from /etc/resolv.conf
2016/12/28 12:36:27 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.19): Terminated abnormally.
CPU Usage: 0.032 seconds = 0.028 user + 0.004 sys Maximum Resident Size: 79904 KB Page faults with physical i/o: 0
2016/12/28 12:36:30 kid1| Set Current Directory to /proxycache
2016/12/28 12:36:30 kid1| Starting Squid Cache version 3.5.19 for x86_64-pc-linux-gnu...
2016/12/28 12:36:30 kid1| Service Name: squid
2016/12/28 12:36:30 kid1| Process ID 15382
2016/12/28 12:36:30 kid1| Process Roles: worker
2016/12/28 12:36:30 kid1| With 40960 file descriptors available
2016/12/28 12:36:30 kid1| Initializing IP Cache...
2016/12/28 12:36:30 kid1| DNS Socket created at [::], FD 7
2016/12/28 12:36:30 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/12/28 12:36:30 kid1| Adding nameserver 172.31.32.12 from /etc/resolv.conf
2016/12/28 12:36:30 kid1| Adding nameserver 172.31.32.31 from /etc/resolv.conf
2016/12/28 12:36:30 kid1| Adding domain domain.com from /etc/resolv.conf
2016/12/28 12:36:30 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
---

If I disable ssl-bump and url_rewrite, the error does not occur. I saw here in the list that this were a bug on squid 3.4, but I'm using squid 3.5.19.

Someone knows how to fix this?

Thanks in advance.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Problem-with-ssl-crtd-tp4680998.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From xeron.oskom at gmail.com  Thu Dec 29 03:03:41 2016
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Wed, 28 Dec 2016 19:03:41 -0800
Subject: [squid-users] squid sibling peers and digest requests
Message-ID: <CAHvB88yTUbw-kYtjZ=T-Na+EQMBxhkDPZnJ+WXtapWhqniuzyg@mail.gmail.com>

Hello!

I'm trying to setup multiple squids as siblings with a parent which is not
even a squid.

But I'm getting following message in logs:

temporary disabling (Bad Gateway) digest from 172.22.15.88
temporary disabling (Bad Gateway) digest from ?

Squid 3.5.23, compiled with "--enable-cache-digests".

For parent I'm setting no-digest, but I'd like to get digests between
siblings. However, it doesn't work and I probably found a reason after
reading debug logs:

This is how squid does store_digest request from a sibling peer:

GET http://172.22.15.88:3128/squid-internal-periodic/store_digest HTTP/1.1
Accept: application/cache-digest
Accept: text/html
X-Forwarded-For: unknown
Host: 172.22.15.88:3128
Cache-Control: max-age=259200
Connection: keep-alive

Response (if I execute this request manually from telnet):

HTTP/1.1 502 Bad Gateway
?

This request has been forwarded to a parent and parent returned 502!

Now if I manually do the same request with a relative URL:

GET /squid-internal-periodic/store_digest HTTP/1.1
?

Response:

HTTP/1.1 200 Cache Digest OK
?

My setup:

Multiple squids as siblings, one parent (not a squid).

Peers configuration:

# Other squids
cache_peer 172.22.15.88 sibling 3128 4827 htcp
cache_peer ? sibling 3128 4827 htcp
acl siblings src 172.22.15.88/32
acl siblings src ?/32
miss_access deny siblings

# Parent
cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=NAME
cache_peer_access NAME deny some_acl

Anyone else seen similar issue? Do you have an example of working
configuration with multiple siblings and enabled digests?

-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161228/985c6e35/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 29 06:02:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Dec 2016 19:02:56 +1300
Subject: [squid-users] squid 4.0.17 accept-encoding.. sending gzip?!
In-Reply-To: <0a898562-314f-1038-e5ba-f790e9b355d6@cinbesa.com.br>
References: <59a77f42-2ccf-54d5-0e3b-7578e8213b8c@cinbesa.com.br>
 <1593d9ab838.277f.0fa0e86c8d2ee43f749db760f8bca319@measurement-factory.com>
 <97c3616c-1eec-f036-9150-efa0b1c96f7a@cinbesa.com.br>
 <3a4301d26066$67d4b690$377e23b0$@ngtech.co.il>
 <0a898562-314f-1038-e5ba-f790e9b355d6@cinbesa.com.br>
Message-ID: <1e0ec9200298518d55d46948635751f5@treenet.co.nz>

On 2016-12-28 06:31, Heiler Bemerguy wrote:
> Hi,
> 
> refresh_pattern -i
> \.(jp[eg]{1,2}|pdf|gif|pn[pg]|bmp|tiff|ico|swf|css|js|ad|png)$ 10080
> 80% 120960 ignore-no-store ignore-reload ignore-must-revalidate
> ignore-private override-expire store-stale
> 
> But it shouldn't change the length of the object, the encoding type of
> the object, the "Server" header of the object..... or am I wrong?
> 

You are misunderstanding what is going on. Squid is simply delivering a 
cached response.

Either the exact original response, or with some updated headers 
supplied *by the server* during revalidation.

The log entry on your earlier post indicates there was _no_ server 
contact. So nothing was changed. Period.

That means what came out of cache was the previously cached response 
with original headers and formatting.


BTW: you should remove the ignore-must-revalidate. Squid current 
releases can only cache private responses IF revalidation is enabled.

>> 
>> FROM: Heiler Bemerguy
>> 
>> The server doesn't define any "content-encoding". This is the
>> ORIGINAL SERVER reply, tcpdumped:

The squid logs you presented earlier showed that the reply was a HIT, 
with *no* server connection made. So you cannot have got a packet 
capture when no TCP packets existed.

What you are seeing below could be another transactions response, or the 
response to some other request which did not get a gzip encoded 
response.


>> 
>>> HTTP/1.1 200 OK
>>> Set-Cookie: ACE-STICKY=R1291873686; path=/; expires=Mon,
>>> 26-Dec-2016
>>> 23:51:26 GMT
>>> Date: Mon, 26 Dec 2016 19:36:06 GMT
>>> Accept-Ranges: bytes
>>> Content-Length: 152264
>>> Content-Type: text/css; charset=UTF-8
>>> X-Powered-By: Servlet/3.0 JSP/2.2
>>> Cache-Control: max-age=0, no-cache, no-store, must-revalidate
>>> Pragma: no-cache
>>> Content-Language: en
>>> Set-Cookie:
>>> 
>> 
> JSESSIONID=DCLCYhxGPHvpfnPNsPv51cGkS55GPqB4b3xJsybLgLJpyqPZZhNW!-162452808;
>>> 
>>> path=/; HttpOnly
>> 

Amos



From squid3 at treenet.co.nz  Thu Dec 29 06:35:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Dec 2016 19:35:00 +1300
Subject: [squid-users] ACL and outgoing IP
In-Reply-To: <1482913367413-4680996.post@n4.nabble.com>
References: <1482854632538-4680990.post@n4.nabble.com>
 <201612271730.05883.Antony.Stone@squid.open.source.it>
 <1482913367413-4680996.post@n4.nabble.com>
Message-ID: <b423a315c53ac771f5e746e761fa1a97@treenet.co.nz>

On 2016-12-28 05:03, qdmetro wrote:
> Hello,
> I have an issue with acl and outgoing ip address.
> 
> I have a squid connected behind a firewall. On the firewall, only the 
> Ip of
> the squid (192.168.1.1) is allowed to go on Internet.
> 
> Usually, when a user authenticate itself on the proxy, all the requests 
> use
> the outgoing IP of the squid (192.168.1.1) so the can access to the 
> website.
> I want to allow some websites to be reachable without authentication
> (especially for the activation of windows licences). I've tried this :
> 
> /acl Microsoft dstdomain .microsoft.com
> http_access allow Microsoft/
> 
> With this configuration, the requests don't use the outgoing Ip of the 
> proxy
> anymore, so they come to my firewall with the source IP of the client 
> (which
> is not allowed to go on the Internet).
> I've tried this to force the outgoing IP for this acl :
> 
> /tcp_outgoing_address 192.168.1.1 Microsoft/
> 
> but the request still don't use the IP of the proxy.
> 
> Maybe this kind of configuration isn't possible, or I miss something...
> Any idea to help me ?
> 

Something other than Squid is causing that. Connections outgoing Squid 
have their IPs selected by the OS. Usually there is one main/primary IP 
on the machine and that gets selected. But things like routing rules or 
NAT can alter that.

Setting tcp_outgoing_address Squid tells the OS it should select that IP 
unless there is a specific admin config forcing something else (like a 
NAT on outgoing traffic).


I've added some comments about changes to improve your config below, but 
nothing that will fix the address issue.


On 2016-12-28 21:22, qdmetro wrote:
> Here the squid.conf :
> 
> auth_param negotiate program /usr/lib/squid3/squid_kerb_auth -s
> GSS_C_NO_NAME HTTP/hostname.domain.com
> auth_param negotiate children 200
> auth_param negotiate keep_alive on
> auth_param basic program /usr/lib/squid3/squid_ldap_auth -b
> "ou=users,dc=ref,dc=local" -u uid ref.domain.com
> url_rewrite_program /usr/bin/squidGuard -c 
> /etc/squidguard/squidGuard.conf
> url_rewrite_children 80
> acl SSL_ports port 443 4443
> acl SSL_ports port 563 4431
> acl SSL_ports port 873
> acl SSL_ports port 7071
> acl SSL_ports port 33333 33334
> acl SSL_ports port 83
> acl Safe_ports port 21
> acl Safe_ports port 22
> acl Safe_ports port 80 81
> acl Safe_ports port 443
> acl CONNECT method CONNECT
> acl domain_auth proxy_auth REQUIRED
> acl localhost src 127.0.0.1/32
> acl password proxy_auth REQUIRED

Since "password" and "domain_auth" ACLs are defined identically and 
neither is tied to anything fancy like deny_inf. You can pick one of 
them and remove it.

> visible_hostname name
> snmp_port 3401
> acl acl_snmp snmp_community com_name
> snmp_access allow acl_snmp
> acl localnet src 10.0.0.0/8
> acl Microsoft dstdomain .microsoft.com
> delay_pools 2
> delay_class 2 2
> delay_access 2 allow localnet
> delay_parameters 2 12233386/12233386 12233386/12233386
> forwarded_for on
> follow_x_forwarded_for allow localnet

That tells Squid that all clients within the localnet (LAN) are allowed 
to forge XFF headers.

Proper use of this directive is to "allow" only the client proxies you 
are confident will not send your proxy fake values in that header. 
Usually you are managing the downstream proxy yourself, or at least have 
contact with its admin if not.

NP: The follow_* directive has nothing to do with your Squid producing 
or updating the XFF headers. "forwarded_for on" does that.

The forwarded_for directive is set to its default. So unless there is 
any reason you need follow-* to be set for some clients you should just 
remove those XFF related lines and let Squid do the default action.


> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports

I advise placing this rule here:
   http_access deny !localnet

After that you can then remove the 'localnet' ACL from the below lines.

> http_access allow Microsoft
> tcp_outgoing_address 192.168.1.1 Microsoft
> http_access allow localnet password
> http_access allow localnet domain_auth
> http_access deny all
> http_reply_access allow localnet

After the http_access change above, you can also remove this 
http_reply_access line.

> icp_access deny all
> htcp_access deny all

Since you are just denying ICP and HTCP usage it would be better to 
remove all icp_* and htcp_* lines from your config. The default in 
current Squid versions is to no even open those ports.

> http_port 3128
> icp_port 3130
> dns_v4_first on


Amos



From squid3 at treenet.co.nz  Thu Dec 29 06:48:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Dec 2016 19:48:44 +1300
Subject: [squid-users] Problem with ssl_crtd
In-Reply-To: <1482945386684-4680998.post@n4.nabble.com>
References: <1482945386684-4680998.post@n4.nabble.com>
Message-ID: <58a6b9fcba54f11bfa7e21ed4256e252@treenet.co.nz>

On 2016-12-29 06:16, Eduardo Carneiro wrote:
> Hi everyone.
> 
> I have a strange issue with my squid 3.5.19. When I enable ssl-bump and
> url_rewrite in order to make dynamic content cache,


URL has nothing to do with cachability of dynamic content.
If that content is not cachign by default then you probably still have 
some very outdated rules in your squid.conf prohibiting that content 
from being stored.



> I've got, sporadically,
> this error in my cache.log:
> 
> /assertion failed: Read.cc:69: "fd_table[conn->fd].halfClosedReader !=
> NULL"/
> 
> When the error occur, my squid simply stops.
> 
> Here is a part of my cache.log:
> 
> ---
> 2016/12/28 12:29:17 kid1| assertion failed: Read.cc:69:
> "fd_table[conn->fd].halfClosedReader != NULL"


<http://bugs.squid-cache.org/show_bug.cgi?id=4270>


> 2016/12/28 12:36:21 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
> processes
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
> 
> Squid Cache (Version 3.5.19): Terminated abnormally.
> 

Hmm, seems there is a part of bug 3805 still present
  <http://bugs.squid-cache.org/show_bug.cgi?id=3805>

> ---
> 
> If I disable ssl-bump and url_rewrite, the error does not occur. I saw 
> here
> in the list that this were a bug on squid 3.4, but I'm using squid 
> 3.5.19.
> 
> Someone knows how to fix this?

The bug about it is still open. That usually means no.

However, I think we should look at why you have resorted to screwing 
around with URLs to "make dynamic content cache". Squid-3.2 and later 
are quite good at caching dynamic content. Current 3.5 have even reached 
the point where private content can be cached safely.

  What is your squid.conf?
  and what do you have the re-writer doing?

Amos



From squid3 at treenet.co.nz  Thu Dec 29 07:15:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Dec 2016 20:15:13 +1300
Subject: [squid-users] squid sibling peers and digest requests
In-Reply-To: <CAHvB88yTUbw-kYtjZ=T-Na+EQMBxhkDPZnJ+WXtapWhqniuzyg@mail.gmail.com>
References: <CAHvB88yTUbw-kYtjZ=T-Na+EQMBxhkDPZnJ+WXtapWhqniuzyg@mail.gmail.com>
Message-ID: <c771c78ab2e007e3c633ba423db1a927@treenet.co.nz>

On 2016-12-29 16:03, Ivan Larionov wrote:
> Hello!
> 
> I'm trying to setup multiple squids as siblings with a parent which is
> not even a squid.
> 
> But I'm getting following message in logs:
> 
> temporary disabling (Bad Gateway) digest from 172.22.15.88
> 
> temporary disabling (Bad Gateway) digest from ?
> 
> Squid 3.5.23, compiled with "--enable-cache-digests".
> 
> For parent I'm setting no-digest, but I'd like to get digests between
> siblings. However, it doesn't work and I probably found a reason after
> reading debug logs:
> 
> This is how squid does store_digest request from a sibling peer:
> 
> GET http://172.22.15.88:3128/squid-internal-periodic/store_digest [1]
> HTTP/1.1
> Accept: application/cache-digest
> Accept: text/html
> X-Forwarded-For: unknown
> Host: 172.22.15.88:3128 [2]
> Cache-Control: max-age=259200
> Connection: keep-alive
> 
> Response (if I execute this request manually from telnet):
> 
> HTTP/1.1 502 Bad Gateway
> ?
> 
> This request has been forwarded to a parent and parent returned 502!
> 

Are you sure about that forwarding?
  Its not being generated by the sibling?


> Now if I manually do the same request with a relative URL:
> 
> GET /squid-internal-periodic/store_digest HTTP/1.1
> ?
> 
> Response:
> 
> HTTP/1.1 200 Cache Digest OK
> ?
> 
> My setup:
> 
> Multiple squids as siblings, one parent (not a squid).
> 
> Peers configuration:
> 
> # Other squids
> cache_peer 172.22.15.88 sibling 3128 4827 htcp
> cache_peer ? sibling 3128 4827 htcp
> acl siblings src 172.22.15.88/32 [3]
> acl siblings src ?/32
> miss_access deny siblings
> 
> # Parent
> cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=NAME
> cache_peer_access NAME deny some_acl
> 
> Anyone else seen similar issue? Do you have an example of working
> configuration with multiple siblings and enabled digests?

The default config usually just works.

Do you have "global_internal_static off" in your squid.conf?

Amos



From squid3 at treenet.co.nz  Thu Dec 29 07:47:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Dec 2016 20:47:46 +1300
Subject: [squid-users] Squid keep using one parent proxy while I have
	multiple parent proxies
Message-ID: <54d1d59a53739622233651f862187e1f@treenet.co.nz>

On 2016-12-27 16:37, wei wrote:
> The curl command is:
> 
> curl -s -i http://showip.net [1]
> 
> The configuration in squid.conf is:
> 
> cache_peer 192.168.1.100 parent 3128 weight=5 no-query name=p1
> round-robin
> cache_peer 192.168.1.101 parent 3128 weight=5 no-query name=p2
> round-robin
> cache_peer 192.168.1.102 parent 3128 weight=5 no-query name=p3
> round-robin

Since you have equal weightings on each peer they are irrelevant. Remove 
the weight=5 for better performance.


> 
> cache_peer_domain p1 .com
> cache_peer_domain p1 .net
> cache_peer_domain p2 .com
> cache_peer_domain p2 .net
> cache_peer_domain p3 .com
> cache_peer_domain p3 .net

Please use the cache_peer_access directive instead. cache_peer_domain is 
deprecated.


> From: wei
> 
> Hi Amos,
> 
> The Squid version I tested is 3.4.14(installed by yum on Centos 6.8)
> and
> 3.4.8(installed by apt on Debian 7), both have the problem of use same
> parent proxy after about 55 seconds. I also test 3.5.23(compiled by
> default
> parameter) and found the time increased from 55 to 85 seconds or so.
> Thanks.

I have just checked the code. The round-robin counters are 'cleared' on 
a 5min cycle, on startup, on reconfigure, or when peers change from DEAD 
to ALIVE state "to prevent the revived CachePeer being flooded with 
requests which it has 'missed' during the down period."

So if your peers are being reset every minute, then either you are 
reconfiguring Squid that often, or they are constantly being detected as 
DEAD. Neither of which is good.

Amos



From xeron.oskom at gmail.com  Thu Dec 29 07:51:27 2016
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Wed, 28 Dec 2016 23:51:27 -0800
Subject: [squid-users] squid sibling peers and digest requests
In-Reply-To: <c771c78ab2e007e3c633ba423db1a927@treenet.co.nz>
References: <CAHvB88yTUbw-kYtjZ=T-Na+EQMBxhkDPZnJ+WXtapWhqniuzyg@mail.gmail.com>
 <c771c78ab2e007e3c633ba423db1a927@treenet.co.nz>
Message-ID: <CAHvB88ycK3RbM9UG2pyjDxeO_3KJoLk3auqLZRnR9TNg3tsO=A@mail.gmail.com>

I'm sure about forwarding because I see requests to
http://172.22.15.88:3128/squid-internal-periodic/store_digest in parent
logs and my parent returns 502 because we do not allow requests to internal
IPs. Logs from the parent:

Got request: GET
http://172.22.15.88:3128/squid-internal-periodic/store_digest
Not allowing blacklisted IP 172.22.15.88
GET http://172.22.15.88:3128/squid-internal-periodic/store_digest 502 0ms

I do not have "global_internal_static off" in my config and also I'm able
to get http://172.22.15.88:3128/squid-internal-periodic/store_digest using
curl or telnet (with telnet I do "GET /squid-internal-periodic/store_digest"
? note relative URL).

However according to debug logs squid does this request using absolute URL
which probably works if target sibling can do direct requests (so it will
request itself for digest and return response to original squid). But I do
have "never_direct allow all" which probably makes sibling to forward such
request to a parent.

If my theory about absolute vs relative URL is correct then I believe
original squid should make store_digest request using relative URL (like I
can do with telnet) so sibling squid will return response right away w/o
asking itself for result.

This is more complete config (only stripped default things like localnet acls
/ http_access), note that I have 2 parents actually which I select based on
header (but all requests w/o header will go to the first parent), and also
have:

via off
never_direct allow all
forwarded_for off

# START CONFIG ====================

# Allow HTCP queries from local networks only
htcp_access allow localnet
htcp_access allow localhost
htcp_access deny all

# Other squids
cache_peer 172.22.15.88 sibling 3128 4827 htcp
cache_peer ? sibling 3128 4827 htcp
acl siblings src 172.22.15.88/32
acl siblings src ?/32
miss_access deny siblings

acl header_a req_header header_a -i true
acl header_b req_header header_b -i true

# name1 parent
cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=name1
cache_peer_access name1 deny header_a
cache_peer_access name1 deny header_b

# name2 parent
cache_peer 127.0.0.1 parent 18079 0 no-query no-digest name=name2
cache_peer_access name2 allow header_a
cache_peer_access name2 allow header_b
cache_peer_access name2 deny all

cache_mem ?
maximum_object_size_in_memory ?
memory_replacement_policy ?
cache_replacement_policy ?

cache_dir aufs ? ? 16 256

minimum_object_size ? bytes # none-zero so we dont cache mistakes
maximum_object_size ? KB

client_db off

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
# refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

# don't cache errors
negative_ttl 0 minutes
# always fetch object from the beginning regardless of Range requests
range_offset_limit none
via off
cache_effective_user squid
cache_effective_group squid
# disable icp
icp_port 0
never_direct allow all
forwarded_for off

# END CONFIG ====================

On Wed, Dec 28, 2016 at 11:15 PM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 2016-12-29 16:03, Ivan Larionov wrote:
>
>> Hello!
>>
>> I'm trying to setup multiple squids as siblings with a parent which is
>> not even a squid.
>>
>> But I'm getting following message in logs:
>>
>> temporary disabling (Bad Gateway) digest from 172.22.15.88
>>
>> temporary disabling (Bad Gateway) digest from ?
>>
>> Squid 3.5.23, compiled with "--enable-cache-digests".
>>
>> For parent I'm setting no-digest, but I'd like to get digests between
>> siblings. However, it doesn't work and I probably found a reason after
>> reading debug logs:
>>
>> This is how squid does store_digest request from a sibling peer:
>>
>> GET http://172.22.15.88:3128/squid-internal-periodic/store_digest [1]
>> HTTP/1.1
>> Accept: application/cache-digest
>> Accept: text/html
>> X-Forwarded-For: unknown
>> Host: 172.22.15.88:3128 [2]
>> Cache-Control: max-age=259200
>> Connection: keep-alive
>>
>> Response (if I execute this request manually from telnet):
>>
>> HTTP/1.1 502 Bad Gateway
>> ?
>>
>> This request has been forwarded to a parent and parent returned 502!
>>
>>
> Are you sure about that forwarding?
>  Its not being generated by the sibling?
>
>
> Now if I manually do the same request with a relative URL:
>>
>> GET /squid-internal-periodic/store_digest HTTP/1.1
>> ?
>>
>> Response:
>>
>> HTTP/1.1 200 Cache Digest OK
>> ?
>>
>> My setup:
>>
>> Multiple squids as siblings, one parent (not a squid).
>>
>> Peers configuration:
>>
>> # Other squids
>> cache_peer 172.22.15.88 sibling 3128 4827 htcp
>> cache_peer ? sibling 3128 4827 htcp
>> acl siblings src 172.22.15.88/32 [3]
>> acl siblings src ?/32
>> miss_access deny siblings
>>
>> # Parent
>> cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=NAME
>> cache_peer_access NAME deny some_acl
>>
>> Anyone else seen similar issue? Do you have an example of working
>> configuration with multiple siblings and enabled digests?
>>
>
> The default config usually just works.
>
> Do you have "global_internal_static off" in your squid.conf?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161228/678804a0/attachment.htm>

From xeron.oskom at gmail.com  Thu Dec 29 08:01:56 2016
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Thu, 29 Dec 2016 00:01:56 -0800
Subject: [squid-users] acls with the same name, last wins
Message-ID: <CAHvB88z33YGF8jveNmOu-Q6RuV7yNUsaAczWb3KikA4eW+tNoQ@mail.gmail.com>

I see behavior change after update from squid 2.7 to 3.5:

I have following ACLs which I later use for cache_peer_access:

acl header req_header header_a -i true
acl header req_header header_b -i true

# name1 parent
cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=name1
cache_peer_access name1 deny header

# name2 parent
cache_peer 127.0.0.1 parent 18079 0 no-query no-digest name=name2
cache_peer_access name2 allow header
cache_peer_access name2 deny all

With squid 2.7 it was working as expected (requests with header_a OR
header_b were going to the second parent, all other requests to the first
one).

However with squid 3.5 the same config doesn't work as expected. ONLY
requests with header_b are going to the second parent and debug logs show
that squid only does verification of header_b.

My current workaround is to use 2 different ACL names:

acl header_a req_header header_a -i true
acl header_b req_header header_b -i true

# name1 parent
cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=name1
cache_peer_access name1 deny header_a
cache_peer_access name1 deny header_b

# name2 parent
cache_peer 127.0.0.1 parent 18079 0 no-query no-digest name=name2
cache_peer_access name2 allow header_a
cache_peer_access name2 allow header_b
cache_peer_access name2 deny all

But I think it could be a bug. Multiple ACLs with the same name should work
as OR, right? Do I understand it correctly? And it was working as expected
in 2.7.

Has anyone saw similar behavior? Should I report a bug?

-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161229/d41fdff1/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 29 09:00:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Dec 2016 22:00:59 +1300
Subject: [squid-users] squid sibling peers and digest requests
In-Reply-To: <CAHvB88ycK3RbM9UG2pyjDxeO_3KJoLk3auqLZRnR9TNg3tsO=A@mail.gmail.com>
References: <CAHvB88yTUbw-kYtjZ=T-Na+EQMBxhkDPZnJ+WXtapWhqniuzyg@mail.gmail.com>
 <c771c78ab2e007e3c633ba423db1a927@treenet.co.nz>
 <CAHvB88ycK3RbM9UG2pyjDxeO_3KJoLk3auqLZRnR9TNg3tsO=A@mail.gmail.com>
Message-ID: <fbac4b898433c81b46a362dd3869c0f6@treenet.co.nz>

On 2016-12-29 20:51, Ivan Larionov wrote:
> I'm sure about forwarding because I see requests to
> http://172.22.15.88:3128/squid-internal-periodic/store_digest [1] in
> parent logs and my parent returns 502 because we do not allow requests
> to internal IPs. Logs from the parent:
> 
> Got request: GET
> http://172.22.15.88:3128/squid-internal-periodic/store_digest
> Not allowing blacklisted IP 172.22.15.88
> GET http://172.22.15.88:3128/squid-internal-periodic/store_digest 502
> 0ms
> 
> I do not have "global_internal_static off" in my config and also I'm
> able to get
> http://172.22.15.88:3128/squid-internal-periodic/store_digest [1]
> using curl or telnet (with telnet I do "GET
> /squid-internal-periodic/store_digest" ? note relative URL).

Okay, thats good.

> 
> However according to debug logs squid does this request using absolute
> URL which probably works if target sibling can do direct requests (so
> it will request itself for digest and return response to original
> squid). But I do have "never_direct allow all" which probably makes
> sibling to forward such request to a parent.

Hmm, I think you might be right about that.
You can test it by adding:

  acl foo urlpath_regex +i /squid.internal.digest/
  never_direct deny foo


> 
> If my theory about absolute vs relative URL is correct then I believe
> original squid should make store_digest request using relative URL
> (like I can do with telnet) so sibling squid will return response
> right away w/o asking itself for result.

Whats happening with the URL is that the sending peer generates it from 
the cache_peer IP/host name and port.

The receiving peer checks the pathstarts with "/squid-internal-" and 
that the hostname portion matches its own visible_hostname or 
unique_hostname. If those match its marked for special handling as an 
internal request, otherwise global_internal_static is used to determine 
if the hostname not matching is ignored and it gets marked anyway.

Since the digest needs to be targeted at the specific peer and not 
anything which may inject itself in between them the hostname does need 
to be sent. The relative URLs are for things that don't vary between 
proxies, like the Squid icons.

If you configure cache_peer with the hostname of the receiving peer 
instead of its raw-IP the requests should be sent with that hostname 
instead of raw-IP.



The config looks okay. Thanks for that.

Amos



From eduardoocarneiro at gmail.com  Thu Dec 29 11:10:01 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Thu, 29 Dec 2016 03:10:01 -0800 (PST)
Subject: [squid-users] Problem with ssl_crtd
In-Reply-To: <58a6b9fcba54f11bfa7e21ed4256e252@treenet.co.nz>
References: <1482945386684-4680998.post@n4.nabble.com>
 <58a6b9fcba54f11bfa7e21ed4256e252@treenet.co.nz>
Message-ID: <1483009801311-4681010.post@n4.nabble.com>

I admit that I am sad because it is a bug and has not been solved yet. In
this way, I will not be able to use this feature while this bug has not been
solved because, if I enable ssl-bump on my port, the squid sporadically
stops.

Here is the important part to us, of my squid.conf. I use url rewrite, store
id and some regular expressions to make dynamic cache content like Youtube,
per example.

---
url_rewrite_program /usr/local/bin/simplerewrite

acl rewritedoms dstdomain .ubuntu.com .fbcdn.net .akamaihd.net
acl yt url_regex -i googlevideo.*videoplayback
acl globo url_regex -i ^https?:\/\/voddownload[0-9]+\.video\.globo\.com.*
acl ubuntu url_regex -i ^https?:\/\/.*ubuntu.*.iso$
acl getmethod method GET

range_offset_limit none
quick_abort_min -1 KB

store_id_program /usr/local/bin/dynamic-cache -file
/usr/local/etc/dynamic-cache-db.txt
store_id_extras "%>a/%>A %un %>rm myip=%la myport=%lp referer=%{Referer}>h"
store_id_children 40 startup=10 idle=5 concurrency=0
store_id_access deny !getmethod
store_id_access allow rewritedoms
store_id_access allow yt
store_id_access allow globo
store_id_access allow ubuntu
store_id_access deny all

refresh_pattern -i squid\.internal 10080 90% 79900 override-lastmod
override-expire ignore-reload ignore-no-store ignore-must-revalidate
ignore-private ignore-auth ignore-no-cache
refresh_pattern -i \.(3gp|7z|ace|asx|avi|bin|cab|dat|deb|divx|dvr-ms\.*).*$     
10800 80% 10800 ignore-no-cache override-expire override-lastmod
reload-into-ims
refresh_pattern -i \.(rar|jar|gz|tgz|bz2|iso|m1v|m2(v|p)|mo(d|v)\.*).*$         
10800 80% 10800 ignore-no-cache override-expire override-lastmod
reload-into-ims
refresh_pattern -i
\.(mp(e?g|a|e|1|2|3|4)|mk(a|v)|ms(i|u|p)|og(x|v|a|g)|rar|rm|r(a|p)m|snd|vob|wav\.*).*$
10800 80% 10800 ignore-no-cache override-expire override-lastmod
reload-into-ims
refresh_pattern -i \.(pp(s|t)|wax|wm(a|v)|wmx|wpl|zip|cb(r|z|t)\.*).*$    
10800 80% 10800 ignore-no-cache override-expire override-lastmod
reload-into-ims

acl text-plain rep_mime_type text/plain
acl youtube_dom dstdomain .googlevideo.com
store_miss deny text-plain youtube_dom
send_hit deny text-plain youtube_dom

http_port 8080 ssl-bump cert=/etc/squid/ssl_cert/ProxyCert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

strip_query_terms off
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
ssl_bump none localhost
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
sslproxy_session_cache_size 128 MB
snmp_port 3401
max_filedescriptors 40960
detect_broken_pconn on
pipeline_prefetch off
half_closed_clients off
shutdown_lifetime 1 second
cache_mgr user at domain.com
cache_store_log /var/log/squid/store.log
cache_log /var/log/squid/cache.log
balance_on_multiple_ip off

acl PURGE method PURGE
http_access deny PURGE !localhost

cache_mem 2097152 KB
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA
maximum_object_size_in_memory 2048 KB
maximum_object_size 2 GB
minimum_object_size 0 KB
cache_swap_low 90
cache_swap_high 95
cache_dir ufs /proxycache 307200 16 256
cache_access_log /var/log/squid/access.log
memory_pools off
log_icp_queries off
buffered_logs on
half_closed_clients off

auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s
GSS_C_NO_NAME
auth_param negotiate children 20 startup=0 idle=1
auth_param negotiate keep_alive off

auth_param basic program /usr/lib/squid/basic_ldap_auth -R -b
"dc=domain,dc=com" -D user at domain.com -w password -f
(|(userPrincipalName=%s)(sAMAccountName=%s)) -h dcserver.domain.com
auth_param basic children 10
auth_param basic realm Enter you password
auth_param basic credentialsttl 1 minute
---

If you find something wrong please report me.

Thanks.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Problem-with-ssl-crtd-tp4680998p4681010.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From xeron.oskom at gmail.com  Thu Dec 29 22:21:49 2016
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Thu, 29 Dec 2016 14:21:49 -0800
Subject: [squid-users] squid sibling peers and digest requests
In-Reply-To: <fbac4b898433c81b46a362dd3869c0f6@treenet.co.nz>
References: <CAHvB88yTUbw-kYtjZ=T-Na+EQMBxhkDPZnJ+WXtapWhqniuzyg@mail.gmail.com>
 <c771c78ab2e007e3c633ba423db1a927@treenet.co.nz>
 <CAHvB88ycK3RbM9UG2pyjDxeO_3KJoLk3auqLZRnR9TNg3tsO=A@mail.gmail.com>
 <fbac4b898433c81b46a362dd3869c0f6@treenet.co.nz>
Message-ID: <CAHvB88xBBL5TxaxuQ+47d2OvkhGHpK7oToBJC6AbW-i2nZ2h=w@mail.gmail.com>

Thank you for helping.

After some experiments and tcpdumping it looks like it's not sibling
sending request to the parent, but original squid!

So instead of asking sibling about his digests squid asks parent.

And your trick with urlpath_regex didn't help. I even tried:

acl internal_digest urlpath_regex +i /.*store_digest.*/
always_direct allow internal_digest
never_direct deny internal_digest

but no luck. It still asks parent.


On Thu, Dec 29, 2016 at 1:00 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 2016-12-29 20:51, Ivan Larionov wrote:
>
>> I'm sure about forwarding because I see requests to
>> http://172.22.15.88:3128/squid-internal-periodic/store_digest [1] in
>> parent logs and my parent returns 502 because we do not allow requests
>> to internal IPs. Logs from the parent:
>>
>> Got request: GET
>> http://172.22.15.88:3128/squid-internal-periodic/store_digest
>> Not allowing blacklisted IP 172.22.15.88
>> GET http://172.22.15.88:3128/squid-internal-periodic/store_digest 502
>> 0ms
>>
>> I do not have "global_internal_static off" in my config and also I'm
>> able to get
>> http://172.22.15.88:3128/squid-internal-periodic/store_digest [1]
>> using curl or telnet (with telnet I do "GET
>> /squid-internal-periodic/store_digest" ? note relative URL).
>>
>
> Okay, thats good.
>
>
>> However according to debug logs squid does this request using absolute
>> URL which probably works if target sibling can do direct requests (so
>> it will request itself for digest and return response to original
>> squid). But I do have "never_direct allow all" which probably makes
>> sibling to forward such request to a parent.
>>
>
> Hmm, I think you might be right about that.
> You can test it by adding:
>
>  acl foo urlpath_regex +i /squid.internal.digest/
>  never_direct deny foo
>
>
>
>> If my theory about absolute vs relative URL is correct then I believe
>> original squid should make store_digest request using relative URL
>> (like I can do with telnet) so sibling squid will return response
>> right away w/o asking itself for result.
>>
>
> Whats happening with the URL is that the sending peer generates it from
> the cache_peer IP/host name and port.
>
> The receiving peer checks the pathstarts with "/squid-internal-" and that
> the hostname portion matches its own visible_hostname or unique_hostname.
> If those match its marked for special handling as an internal request,
> otherwise global_internal_static is used to determine if the hostname not
> matching is ignored and it gets marked anyway.
>
> Since the digest needs to be targeted at the specific peer and not
> anything which may inject itself in between them the hostname does need to
> be sent. The relative URLs are for things that don't vary between proxies,
> like the Squid icons.
>
> If you configure cache_peer with the hostname of the receiving peer
> instead of its raw-IP the requests should be sent with that hostname
> instead of raw-IP.
>
>
>
> The config looks okay. Thanks for that.
>
> Amos
>
>


-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161229/a9cd1ff1/attachment.htm>

From xeron.oskom at gmail.com  Fri Dec 30 00:15:00 2016
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Thu, 29 Dec 2016 16:15:00 -0800
Subject: [squid-users] squid sibling peers and digest requests
In-Reply-To: <CAHvB88xBBL5TxaxuQ+47d2OvkhGHpK7oToBJC6AbW-i2nZ2h=w@mail.gmail.com>
References: <CAHvB88yTUbw-kYtjZ=T-Na+EQMBxhkDPZnJ+WXtapWhqniuzyg@mail.gmail.com>
 <c771c78ab2e007e3c633ba423db1a927@treenet.co.nz>
 <CAHvB88ycK3RbM9UG2pyjDxeO_3KJoLk3auqLZRnR9TNg3tsO=A@mail.gmail.com>
 <fbac4b898433c81b46a362dd3869c0f6@treenet.co.nz>
 <CAHvB88xBBL5TxaxuQ+47d2OvkhGHpK7oToBJC6AbW-i2nZ2h=w@mail.gmail.com>
Message-ID: <CAHvB88xr0nRmh68JogRgSWMGoYtV9LtBvEUWJ-uL-RhneBiBNQ@mail.gmail.com>

Here are some debug logs from FwdState which handles digest request.

172.22.13.210 ? original squid
172.22.8.145 ? sibling squid
127.0.0.1:18070 ? parent

As you can see it uses connection to parent for this request (reusing pconn
local=127.0.0.1:44120 remote=127.0.0.1:18070 FD 16 flags=1) which is
probably a bug.

2016/12/29 15:57:41.121| 17,3| FwdState.cc(332) Start: '
http://172.22.8.145:3128/squid-internal-periodic/store_digest'
2016/12/29 15:57:41.121| 17,2| FwdState.cc(133) FwdState: Forwarding client
request , url=http://172.22.8.145:3128/squid-internal-periodic/store_digest
2016/12/29 15:57:41.121| 17,3| FwdState.cc(387) startConnectionOrFail:
http://172.22.8.145:3128/squid-internal-periodic/store_digest
2016/12/29 15:57:41.121| 17,3| FwdState.cc(806) connectStart:
fwdConnectStart:
http://172.22.8.145:3128/squid-internal-periodic/store_digest
2016/12/29 15:57:41.121| 17,3| FwdState.cc(875) connectStart: reusing pconn
local=127.0.0.1:44120 remote=127.0.0.1:18070 FD 16 flags=1
2016/12/29 15:57:41.121| 17,3| FwdState.cc(908) dispatch: : Fetching GET
http://172.22.8.145:3128/squid-internal-periodic/store_digest
2016/12/29 15:57:41.124| 17,3| FwdState.cc(447) unregister:
http://172.22.8.145:3128/squid-internal-periodic/store_digest
2016/12/29 15:57:41.124| 17,2| FwdState.cc(655)
handleUnregisteredServerEnd: self=0x1450738*2 err=0
http://172.22.8.145:3128/squid-internal-periodic/store_digest

And peer_select logs:

2016/12/29 16:12:41.843| 44,3| peer_select.cc(137) peerSelect:
e:=IWV/0x148bae0*2
http://172.22.8.145:3128/squid-internal-periodic/store_digest
2016/12/29 16:12:41.843| 44,3| peer_select.cc(441) peerSelectFoo: GET
172.22.8.145
2016/12/29 16:12:41.843| 44,3| peer_select.cc(446) peerSelectFoo:
peerSelectFoo: direct = DIRECT_UNKNOWN (always_direct to be checked)
2016/12/29 16:12:41.844| 44,3| peer_select.cc(194)
peerCheckAlwaysDirectDone: peerCheckAlwaysDirectDone: DENIED
2016/12/29 16:12:41.844| 44,3| peer_select.cc(441) peerSelectFoo: GET
172.22.8.145
2016/12/29 16:12:41.844| 44,3| peer_select.cc(454) peerSelectFoo:
peerSelectFoo: direct = DIRECT_UNKNOWN (never_direct to be checked)
2016/12/29 16:12:41.844| 44,3| peer_select.cc(171)
peerCheckNeverDirectDone: peerCheckNeverDirectDone: ALLOWED
2016/12/29 16:12:41.844| 44,3| peer_select.cc(177)
peerCheckNeverDirectDone: direct = DIRECT_NO (never_direct allow)
2016/12/29 16:12:41.844| 44,3| peer_select.cc(441) peerSelectFoo: GET
172.22.8.145
2016/12/29 16:12:41.844| 44,3| peer_select.cc(110) peerSelectIcpPing:
peerSelectIcpPing:
http://172.22.8.145:3128/squid-internal-periodic/store_digest
2016/12/29 16:12:41.844| 44,3| peer_select.cc(121) peerSelectIcpPing:
peerSelectIcpPing: counted 0 neighbors
2016/12/29 16:12:41.844| 44,3| peer_select.cc(685) peerGetSomeParent: GET
172.22.8.145
2016/12/29 16:12:41.844| 44,3| peer_select.cc(709) peerGetSomeParent:
peerSelect: FIRSTUP_PARENT/127.0.0.1
2016/12/29 16:12:41.844| 44,5| peer_select.cc(938) peerAddFwdServer:
peerAddFwdServer: adding 127.0.0.1 FIRSTUP_PARENT
2016/12/29 16:12:41.844| 44,5| peer_select.cc(938) peerAddFwdServer:
peerAddFwdServer: adding 127.0.0.1 ANY_OLD_PARENT
2016/12/29 16:12:41.844| 44,2| peer_select.cc(258) peerSelectDnsPaths: Find
IP destination for:
http://172.22.8.145:3128/squid-internal-periodic/store_digest' via 127.0.0.1
2016/12/29 16:12:41.844| 44,2| peer_select.cc(258) peerSelectDnsPaths: Find
IP destination for:
http://172.22.8.145:3128/squid-internal-periodic/store_digest' via 127.0.0.1
2016/12/29 16:12:41.844| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for '
http://172.22.8.145:3128/squid-internal-periodic/store_digest'
2016/12/29 16:12:41.844| 44,2| peer_select.cc(281) peerSelectDnsPaths:
always_direct = DENIED
2016/12/29 16:12:41.844| 44,2| peer_select.cc(282) peerSelectDnsPaths:
 never_direct = ALLOWED
2016/12/29 16:12:41.844| 44,2| peer_select.cc(292) peerSelectDnsPaths:
 cache_peer = local=0.0.0.0 remote=127.0.0.1:18070 flags=1
2016/12/29 16:12:41.844| 44,2| peer_select.cc(292) peerSelectDnsPaths:
 cache_peer = local=0.0.0.0 remote=127.0.0.1:18070 flags=1
2016/12/29 16:12:41.844| 44,2| peer_select.cc(295) peerSelectDnsPaths:
   timedout = 0
2016/12/29 16:12:41.844| 44,3| peer_select.cc(79) ~ps_state:
http://172.22.8.145:3128/squid-internal-periodic/store_digest


On Thu, Dec 29, 2016 at 2:21 PM, Ivan Larionov <xeron.oskom at gmail.com>
wrote:

> Thank you for helping.
>
> After some experiments and tcpdumping it looks like it's not sibling
> sending request to the parent, but original squid!
>
> So instead of asking sibling about his digests squid asks parent.
>
> And your trick with urlpath_regex didn't help. I even tried:
>
> acl internal_digest urlpath_regex +i /.*store_digest.*/
> always_direct allow internal_digest
> never_direct deny internal_digest
>
> but no luck. It still asks parent.
>
>
> On Thu, Dec 29, 2016 at 1:00 AM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> On 2016-12-29 20:51, Ivan Larionov wrote:
>>
>>> I'm sure about forwarding because I see requests to
>>> http://172.22.15.88:3128/squid-internal-periodic/store_digest [1] in
>>> parent logs and my parent returns 502 because we do not allow requests
>>> to internal IPs. Logs from the parent:
>>>
>>> Got request: GET
>>> http://172.22.15.88:3128/squid-internal-periodic/store_digest
>>> Not allowing blacklisted IP 172.22.15.88
>>> GET http://172.22.15.88:3128/squid-internal-periodic/store_digest 502
>>> 0ms
>>>
>>> I do not have "global_internal_static off" in my config and also I'm
>>> able to get
>>> http://172.22.15.88:3128/squid-internal-periodic/store_digest [1]
>>> using curl or telnet (with telnet I do "GET
>>> /squid-internal-periodic/store_digest" ? note relative URL).
>>>
>>
>> Okay, thats good.
>>
>>
>>> However according to debug logs squid does this request using absolute
>>> URL which probably works if target sibling can do direct requests (so
>>> it will request itself for digest and return response to original
>>> squid). But I do have "never_direct allow all" which probably makes
>>> sibling to forward such request to a parent.
>>>
>>
>> Hmm, I think you might be right about that.
>> You can test it by adding:
>>
>>  acl foo urlpath_regex +i /squid.internal.digest/
>>  never_direct deny foo
>>
>>
>>
>>> If my theory about absolute vs relative URL is correct then I believe
>>> original squid should make store_digest request using relative URL
>>> (like I can do with telnet) so sibling squid will return response
>>> right away w/o asking itself for result.
>>>
>>
>> Whats happening with the URL is that the sending peer generates it from
>> the cache_peer IP/host name and port.
>>
>> The receiving peer checks the pathstarts with "/squid-internal-" and that
>> the hostname portion matches its own visible_hostname or unique_hostname.
>> If those match its marked for special handling as an internal request,
>> otherwise global_internal_static is used to determine if the hostname not
>> matching is ignored and it gets marked anyway.
>>
>> Since the digest needs to be targeted at the specific peer and not
>> anything which may inject itself in between them the hostname does need to
>> be sent. The relative URLs are for things that don't vary between proxies,
>> like the Squid icons.
>>
>> If you configure cache_peer with the hostname of the receiving peer
>> instead of its raw-IP the requests should be sent with that hostname
>> instead of raw-IP.
>>
>>
>>
>> The config looks okay. Thanks for that.
>>
>> Amos
>>
>>
>
>
> --
> With best regards, Ivan Larionov.
>



-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161229/a2d6b76a/attachment.htm>

From xeron.oskom at gmail.com  Fri Dec 30 00:40:50 2016
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Thu, 29 Dec 2016 16:40:50 -0800
Subject: [squid-users] squid sibling peers and digest requests
In-Reply-To: <CAHvB88xr0nRmh68JogRgSWMGoYtV9LtBvEUWJ-uL-RhneBiBNQ@mail.gmail.com>
References: <CAHvB88yTUbw-kYtjZ=T-Na+EQMBxhkDPZnJ+WXtapWhqniuzyg@mail.gmail.com>
 <c771c78ab2e007e3c633ba423db1a927@treenet.co.nz>
 <CAHvB88ycK3RbM9UG2pyjDxeO_3KJoLk3auqLZRnR9TNg3tsO=A@mail.gmail.com>
 <fbac4b898433c81b46a362dd3869c0f6@treenet.co.nz>
 <CAHvB88xBBL5TxaxuQ+47d2OvkhGHpK7oToBJC6AbW-i2nZ2h=w@mail.gmail.com>
 <CAHvB88xr0nRmh68JogRgSWMGoYtV9LtBvEUWJ-uL-RhneBiBNQ@mail.gmail.com>
Message-ID: <CAHvB88zZzR8tJbmTiN2NXCLEVJkdeSStyRz12FQfP+L_ibdbXg@mail.gmail.com>

Ok, sorry for so many messages. This is the last one :)

In the end what helped was this:

acl internal_digest urlpath_regex +i ^/squid-internal-periodic/store_digest$
always_direct allow internal_digest
never_direct deny internal_digest

So Amos' original idea with ACL was correct, I just had to adjust it a bit.

Looks like "never_direct allow all" which I have later in config affects
store_digest requests. Not sure if it's a bug or feature.

Thank you for helping again.

On Thu, Dec 29, 2016 at 4:15 PM, Ivan Larionov <xeron.oskom at gmail.com>
wrote:

> Here are some debug logs from FwdState which handles digest request.
>
> 172.22.13.210 ? original squid
> 172.22.8.145 ? sibling squid
> 127.0.0.1:18070 ? parent
>
> As you can see it uses connection to parent for this request (reusing
> pconn local=127.0.0.1:44120 remote=127.0.0.1:18070 FD 16 flags=1) which
> is probably a bug.
>
> 2016/12/29 15:57:41.121| 17,3| FwdState.cc(332) Start: '
> http://172.22.8.145:3128/squid-internal-periodic/store_digest'
> 2016/12/29 15:57:41.121| 17,2| FwdState.cc(133) FwdState: Forwarding
> client request , url=http://172.22.8.145:3128/
> squid-internal-periodic/store_digest
> 2016/12/29 15:57:41.121| 17,3| FwdState.cc(387) startConnectionOrFail:
> http://172.22.8.145:3128/squid-internal-periodic/store_digest
> 2016/12/29 15:57:41.121| 17,3| FwdState.cc(806) connectStart:
> fwdConnectStart: http://172.22.8.145:3128/squid-internal-periodic/store_
> digest
> 2016/12/29 15:57:41.121| 17,3| FwdState.cc(875) connectStart: reusing
> pconn local=127.0.0.1:44120 remote=127.0.0.1:18070 FD 16 flags=1
> 2016/12/29 15:57:41.121| 17,3| FwdState.cc(908) dispatch: : Fetching GET
> http://172.22.8.145:3128/squid-internal-periodic/store_digest
> 2016/12/29 15:57:41.124| 17,3| FwdState.cc(447) unregister:
> http://172.22.8.145:3128/squid-internal-periodic/store_digest
> 2016/12/29 15:57:41.124| 17,2| FwdState.cc(655)
> handleUnregisteredServerEnd: self=0x1450738*2 err=0
> http://172.22.8.145:3128/squid-internal-periodic/store_digest
>
> And peer_select logs:
>
> 2016/12/29 16:12:41.843| 44,3| peer_select.cc(137) peerSelect:
> e:=IWV/0x148bae0*2 http://172.22.8.145:3128/squid-internal-periodic/store_
> digest
> 2016/12/29 16:12:41.843| 44,3| peer_select.cc(441) peerSelectFoo: GET
> 172.22.8.145
> 2016/12/29 16:12:41.843| 44,3| peer_select.cc(446) peerSelectFoo:
> peerSelectFoo: direct = DIRECT_UNKNOWN (always_direct to be checked)
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(194)
> peerCheckAlwaysDirectDone: peerCheckAlwaysDirectDone: DENIED
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(441) peerSelectFoo: GET
> 172.22.8.145
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(454) peerSelectFoo:
> peerSelectFoo: direct = DIRECT_UNKNOWN (never_direct to be checked)
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(171)
> peerCheckNeverDirectDone: peerCheckNeverDirectDone: ALLOWED
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(177)
> peerCheckNeverDirectDone: direct = DIRECT_NO (never_direct allow)
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(441) peerSelectFoo: GET
> 172.22.8.145
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(110) peerSelectIcpPing:
> peerSelectIcpPing: http://172.22.8.145:3128/squid-internal-periodic/store_
> digest
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(121) peerSelectIcpPing:
> peerSelectIcpPing: counted 0 neighbors
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(685) peerGetSomeParent: GET
> 172.22.8.145
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(709) peerGetSomeParent:
> peerSelect: FIRSTUP_PARENT/127.0.0.1
> 2016/12/29 16:12:41.844| 44,5| peer_select.cc(938) peerAddFwdServer:
> peerAddFwdServer: adding 127.0.0.1 FIRSTUP_PARENT
> 2016/12/29 16:12:41.844| 44,5| peer_select.cc(938) peerAddFwdServer:
> peerAddFwdServer: adding 127.0.0.1 ANY_OLD_PARENT
> 2016/12/29 16:12:41.844| 44,2| peer_select.cc(258) peerSelectDnsPaths:
> Find IP destination for: http://172.22.8.145:3128/
> squid-internal-periodic/store_digest' via 127.0.0.1
> 2016/12/29 16:12:41.844| 44,2| peer_select.cc(258) peerSelectDnsPaths:
> Find IP destination for: http://172.22.8.145:3128/
> squid-internal-periodic/store_digest' via 127.0.0.1
> 2016/12/29 16:12:41.844| 44,2| peer_select.cc(280) peerSelectDnsPaths:
> Found sources for 'http://172.22.8.145:3128/squid-internal-periodic/store_
> digest'
> 2016/12/29 16:12:41.844| 44,2| peer_select.cc(281) peerSelectDnsPaths:
> always_direct = DENIED
> 2016/12/29 16:12:41.844| 44,2| peer_select.cc(282) peerSelectDnsPaths:
>  never_direct = ALLOWED
> 2016/12/29 16:12:41.844| 44,2| peer_select.cc(292) peerSelectDnsPaths:
>  cache_peer = local=0.0.0.0 remote=127.0.0.1:18070 flags=1
> 2016/12/29 16:12:41.844| 44,2| peer_select.cc(292) peerSelectDnsPaths:
>  cache_peer = local=0.0.0.0 remote=127.0.0.1:18070 flags=1
> 2016/12/29 16:12:41.844| 44,2| peer_select.cc(295) peerSelectDnsPaths:
>    timedout = 0
> 2016/12/29 16:12:41.844| 44,3| peer_select.cc(79) ~ps_state:
> http://172.22.8.145:3128/squid-internal-periodic/store_digest
>
>
> On Thu, Dec 29, 2016 at 2:21 PM, Ivan Larionov <xeron.oskom at gmail.com>
> wrote:
>
>> Thank you for helping.
>>
>> After some experiments and tcpdumping it looks like it's not sibling
>> sending request to the parent, but original squid!
>>
>> So instead of asking sibling about his digests squid asks parent.
>>
>> And your trick with urlpath_regex didn't help. I even tried:
>>
>> acl internal_digest urlpath_regex +i /.*store_digest.*/
>> always_direct allow internal_digest
>> never_direct deny internal_digest
>>
>> but no luck. It still asks parent.
>>
>>
>> On Thu, Dec 29, 2016 at 1:00 AM, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>
>>> On 2016-12-29 20:51, Ivan Larionov wrote:
>>>
>>>> I'm sure about forwarding because I see requests to
>>>> http://172.22.15.88:3128/squid-internal-periodic/store_digest [1] in
>>>> parent logs and my parent returns 502 because we do not allow requests
>>>> to internal IPs. Logs from the parent:
>>>>
>>>> Got request: GET
>>>> http://172.22.15.88:3128/squid-internal-periodic/store_digest
>>>> Not allowing blacklisted IP 172.22.15.88
>>>> GET http://172.22.15.88:3128/squid-internal-periodic/store_digest 502
>>>> 0ms
>>>>
>>>> I do not have "global_internal_static off" in my config and also I'm
>>>> able to get
>>>> http://172.22.15.88:3128/squid-internal-periodic/store_digest [1]
>>>> using curl or telnet (with telnet I do "GET
>>>> /squid-internal-periodic/store_digest" ? note relative URL).
>>>>
>>>
>>> Okay, thats good.
>>>
>>>
>>>> However according to debug logs squid does this request using absolute
>>>> URL which probably works if target sibling can do direct requests (so
>>>> it will request itself for digest and return response to original
>>>> squid). But I do have "never_direct allow all" which probably makes
>>>> sibling to forward such request to a parent.
>>>>
>>>
>>> Hmm, I think you might be right about that.
>>> You can test it by adding:
>>>
>>>  acl foo urlpath_regex +i /squid.internal.digest/
>>>  never_direct deny foo
>>>
>>>
>>>
>>>> If my theory about absolute vs relative URL is correct then I believe
>>>> original squid should make store_digest request using relative URL
>>>> (like I can do with telnet) so sibling squid will return response
>>>> right away w/o asking itself for result.
>>>>
>>>
>>> Whats happening with the URL is that the sending peer generates it from
>>> the cache_peer IP/host name and port.
>>>
>>> The receiving peer checks the pathstarts with "/squid-internal-" and
>>> that the hostname portion matches its own visible_hostname or
>>> unique_hostname. If those match its marked for special handling as an
>>> internal request, otherwise global_internal_static is used to determine if
>>> the hostname not matching is ignored and it gets marked anyway.
>>>
>>> Since the digest needs to be targeted at the specific peer and not
>>> anything which may inject itself in between them the hostname does need to
>>> be sent. The relative URLs are for things that don't vary between proxies,
>>> like the Squid icons.
>>>
>>> If you configure cache_peer with the hostname of the receiving peer
>>> instead of its raw-IP the requests should be sent with that hostname
>>> instead of raw-IP.
>>>
>>>
>>>
>>> The config looks okay. Thanks for that.
>>>
>>> Amos
>>>
>>>
>>
>>
>> --
>> With best regards, Ivan Larionov.
>>
>
>
>
> --
> With best regards, Ivan Larionov.
>



-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161229/326d9c46/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec 30 05:44:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Dec 2016 18:44:02 +1300
Subject: [squid-users] acls with the same name, last wins
In-Reply-To: <CAHvB88z33YGF8jveNmOu-Q6RuV7yNUsaAczWb3KikA4eW+tNoQ@mail.gmail.com>
References: <CAHvB88z33YGF8jveNmOu-Q6RuV7yNUsaAczWb3KikA4eW+tNoQ@mail.gmail.com>
Message-ID: <c08c592a043673588b2e7d907bc142f3@treenet.co.nz>

On 2016-12-29 21:01, Ivan Larionov wrote:
> I see behavior change after update from squid 2.7 to 3.5:
> 
> I have following ACLs which I later use for cache_peer_access:
> 
> acl header req_header header_a -i true
> acl header req_header header_b -i true
> 
> # name1 parent
> cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=name1
> cache_peer_access name1 deny header
> 
> # name2 parent
> cache_peer 127.0.0.1 parent 18079 0 no-query no-digest name=name2
> cache_peer_access name2 allow header
> cache_peer_access name2 deny all
> 
> With squid 2.7 it was working as expected (requests with header_a OR
> header_b were going to the second parent, all other requests to the
> first one).
> 
> However with squid 3.5 the same config doesn't work as expected. ONLY
> requests with header_b are going to the second parent and debug logs
> show that squid only does verification of header_b.
> 
> My current workaround is to use 2 different ACL names:
> 
> acl header_a req_header header_a -i true
> acl header_b req_header header_b -i true
> 
> # name1 parent
> cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=name1
> cache_peer_access name1 deny header_a
> cache_peer_access name1 deny header_b
> 
> # name2 parent
> cache_peer 127.0.0.1 parent 18079 0 no-query no-digest name=name2
> cache_peer_access name2 allow header_a
> cache_peer_access name2 allow header_b
> cache_peer_access name2 deny all
> 
> But I think it could be a bug. Multiple ACLs with the same name should
> work as OR, right? Do I understand it correctly? And it was working as
> expected in 2.7.
> 
> Has anyone saw similar behavior? Should I report a bug?

Good find. You are the first to mention it.

I have had a look back into the code history and don't see this as ever 
being an intended behaviour for Squid-2. Just a side effect of how the 
Squid-2 ACL lists happened to be stored internally.

The intended design for ACLs is that basic/primitive tests check one 
piece of state data and get chained explicitly in the access lines for 
AND/OR conditions. That way it is clear what is being processed and 
matched (or not matched).

So for now I am making Squid produce a config ERROR when this config 
situation is found. The 'anyof' or 'allof' ACL types in 3.4+ can be used 
to assemble a more complex test set checking different ACL primitives.

Amos



From xeron.oskom at gmail.com  Fri Dec 30 21:58:52 2016
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Fri, 30 Dec 2016 13:58:52 -0800
Subject: [squid-users] acls with the same name, last wins
In-Reply-To: <c08c592a043673588b2e7d907bc142f3@treenet.co.nz>
References: <CAHvB88z33YGF8jveNmOu-Q6RuV7yNUsaAczWb3KikA4eW+tNoQ@mail.gmail.com>
 <c08c592a043673588b2e7d907bc142f3@treenet.co.nz>
Message-ID: <CAHvB88yANBRHnUZtPMB_B9Pqu=-QO+uBh4pDKmMVwR63xcmq0Q@mail.gmail.com>

I'm a bit confused now. Examples from default config:

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 1025-65535  # unregistered ports

All these ACL work as OR, right?

Why is req_header different?

On Thu, Dec 29, 2016 at 9:44 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 2016-12-29 21:01, Ivan Larionov wrote:
>
>> I see behavior change after update from squid 2.7 to 3.5:
>>
>> I have following ACLs which I later use for cache_peer_access:
>>
>> acl header req_header header_a -i true
>> acl header req_header header_b -i true
>>
>> # name1 parent
>> cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=name1
>> cache_peer_access name1 deny header
>>
>> # name2 parent
>> cache_peer 127.0.0.1 parent 18079 0 no-query no-digest name=name2
>> cache_peer_access name2 allow header
>> cache_peer_access name2 deny all
>>
>> With squid 2.7 it was working as expected (requests with header_a OR
>> header_b were going to the second parent, all other requests to the
>> first one).
>>
>> However with squid 3.5 the same config doesn't work as expected. ONLY
>> requests with header_b are going to the second parent and debug logs
>> show that squid only does verification of header_b.
>>
>> My current workaround is to use 2 different ACL names:
>>
>> acl header_a req_header header_a -i true
>> acl header_b req_header header_b -i true
>>
>> # name1 parent
>> cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=name1
>> cache_peer_access name1 deny header_a
>> cache_peer_access name1 deny header_b
>>
>> # name2 parent
>> cache_peer 127.0.0.1 parent 18079 0 no-query no-digest name=name2
>> cache_peer_access name2 allow header_a
>> cache_peer_access name2 allow header_b
>> cache_peer_access name2 deny all
>>
>> But I think it could be a bug. Multiple ACLs with the same name should
>> work as OR, right? Do I understand it correctly? And it was working as
>> expected in 2.7.
>>
>> Has anyone saw similar behavior? Should I report a bug?
>>
>
> Good find. You are the first to mention it.
>
> I have had a look back into the code history and don't see this as ever
> being an intended behaviour for Squid-2. Just a side effect of how the
> Squid-2 ACL lists happened to be stored internally.
>
> The intended design for ACLs is that basic/primitive tests check one piece
> of state data and get chained explicitly in the access lines for AND/OR
> conditions. That way it is clear what is being processed and matched (or
> not matched).
>
> So for now I am making Squid produce a config ERROR when this config
> situation is found. The 'anyof' or 'allof' ACL types in 3.4+ can be used to
> assemble a more complex test set checking different ACL primitives.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161230/8df21a16/attachment.htm>

From squid3 at treenet.co.nz  Sat Dec 31 02:04:25 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 31 Dec 2016 15:04:25 +1300
Subject: [squid-users] acls with the same name, last wins
In-Reply-To: <CAHvB88yANBRHnUZtPMB_B9Pqu=-QO+uBh4pDKmMVwR63xcmq0Q@mail.gmail.com>
References: <CAHvB88z33YGF8jveNmOu-Q6RuV7yNUsaAczWb3KikA4eW+tNoQ@mail.gmail.com>
 <c08c592a043673588b2e7d907bc142f3@treenet.co.nz>
 <CAHvB88yANBRHnUZtPMB_B9Pqu=-QO+uBh4pDKmMVwR63xcmq0Q@mail.gmail.com>
Message-ID: <42b71fe3fb040dc3962e2f94331974da@treenet.co.nz>

On 2016-12-31 10:58, Ivan Larionov wrote:
> I'm a bit confused now. Examples from default config:
> 
> acl localnet src 10.0.0.0/8 [2]     # RFC1918 possible internal
> network
> acl localnet src 172.16.0.0/12 [3]  # RFC1918 possible internal
> network
> acl localnet src 192.168.0.0/16 [4] # RFC1918 possible internal
> network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly
> plugged) machines
> 
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 1025-65535  # unregistered ports
> 
> All these ACL work as OR, right?

Yes. They put the port or IP values into a bucket/set of values that are 
matched in OR style.


You can list the port/IP ACls values all on one line if you want and it 
works identically to listing them on separate lines.

> 
> Why is req_header different?

With the req_header (and rep_header) in Squid-3 only the regex portion 
provides that "line and list being identical" property, the header name 
changing requires a new line.

Squid-2 appears to have implemented the ACL as a set of header names 
with the regex being a secondary lookup. So if any of the headers 
existed the set of regex were then tested and that was the overall 
result.


It can probably be made to work the Squid-2 way (if its really needed 
make a feature enhancement bug), but Squid-3 has the allof and anyof 
ACLs now to make an explicit logic tree where this type of OR 
requirement is clearly visible in the config file. These new ACL tests 
walk their tree of AND/OR ACL conditions and the overall match/non-match 
is whatever the leaf ACL test says. Thats a lot more flexible.

Amos



From mark_squid at finito.me.uk  Sat Dec 31 14:37:43 2016
From: mark_squid at finito.me.uk (Mark Hoare)
Date: Sat, 31 Dec 2016 14:37:43 +0000
Subject: [squid-users] ssl_bump - peek & splice logging IP rather than
	server name
Message-ID: <9A9925E4-014F-4C64-B830-1644C809084F@finito.me.uk>

Hi,

I?m trying to setup policy based routing on a gateway device pointing at a remote squid server to do transparent HTTP & HTTPS proxying with ssl_bump (peek & splice)

After quite a bit of pain getting policy based routing working on the gateway and local port redirection on the squid server, everything appears to be working except the access log still refers to the destination IP address in the TCP_TUNNEL rather than the SNI/TLS server name.

By increasing the debug level I can see that the SNI/TLS details are definitely being obtained during the request processing but for some reason they are not ending up in the access log.

Extract from cache log:
> 2016/12/31 14:18:01.966 kid1| 83,7| bio.cc(1110) parseV3Hello: Found server name: www.ssllabs.com
> 2016/12/31 14:18:02.351 kid1| 83,5| support.cc(259) ssl_verify_cb: SSL Certificate signature OK: /C=US/ST=California/L=Redwood City/O=Qualys, Inc./CN=ssllabs.com
> 2016/12/31 14:18:02.351 kid1| 83,4| support.cc(213) check_domain: Verifying server domain www.ssllabs.com to certificate name/subjectAltName ssllabs.com
> 2016/12/31 14:18:02.351 kid1| 83,4| support.cc(213) check_domain: Verifying server domain www.ssllabs.com to certificate name/subjectAltName *.ssllabs.com
> 2016/12/31 14:18:02.383 kid1| 83,5| PeerConnector.cc(307) serverCertificateVerified: HTTPS server CN: ssllabs.com bumped: local=<squid IP removed>:57790 remote=64.41.200.100:443 FD 14 flags=1

Extract from access log:
> 1483193882.790    870 <local ip removed> TCP_TUNNEL/200 5620 CONNECT 64.41.200.100:443 - ORIGINAL_DST/64.41.200.100 -

From the output above I would have expected some of the server name info to get into the access log.

Squid config below:
> debug_options ALL,7
> 
> http_port 3128
> 
> https_port 3130 intercept ssl-bump cert=/etc/squid/ssl_cert/squidCA.pem generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> http_port 3131 intercept ssl-bump cert=/etc/squid/ssl_cert/squidCA.pem generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> cache_dir ufs /var/spool/squid 200 16 256
> coredump_dir /var/spool/squid
> 
> acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
> acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
> acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
> 
> acl Safe_ports port 80		# http
> acl Safe_ports port 21		# ftp
> acl Safe_ports port 443		# https
> acl Safe_ports port 70		# gopher
> acl Safe_ports port 210		# wais
> acl Safe_ports port 1025-65535	# unregistered ports
> acl Safe_ports port 280		# http-mgmt
> acl Safe_ports port 488		# gss-http
> acl Safe_ports port 591		# filemaker
> acl Safe_ports port 777		# multiling http
> 
> acl SSL_ports port 443
> acl CONNECT method CONNECT
> 
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> 
> http_access allow localhost manager
> http_access deny manager
> 
> refresh_pattern ^ftp:		1440	20%	10080
> refresh_pattern ^gopher:	1440	0%	1440
> refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
> refresh_pattern .		0	20%	4320
> 
> ssl_bump peek all
> ssl_bump splice all
> 
> always_direct allow all
> 
> http_access allow localnet
> http_access allow localhost
> 
> http_access deny all


Any suggestions gratefully received.

Thanks

Mark

