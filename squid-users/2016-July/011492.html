<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] url_rewrite_program shows IP addresses instead of domain name when rewriting SSL/HTTPS
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20url_rewrite_program%20shows%20IP%20addresses%20instead%20of%0A%20domain%20name%20when%20rewriting%20SSL/HTTPS&In-Reply-To=%3CCAJ_yQB%3DSphX9doO%2B%3D3Liy52oci_pCQhFsyFjY-rZS%3DiYw_0-Hw%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="011491.html">
   <LINK REL="Next"  HREF="011493.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] url_rewrite_program shows IP addresses instead of domain name when rewriting SSL/HTTPS</H1>
    <B>Moataz Elmasry</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20url_rewrite_program%20shows%20IP%20addresses%20instead%20of%0A%20domain%20name%20when%20rewriting%20SSL/HTTPS&In-Reply-To=%3CCAJ_yQB%3DSphX9doO%2B%3D3Liy52oci_pCQhFsyFjY-rZS%3DiYw_0-Hw%40mail.gmail.com%3E"
       TITLE="[squid-users] url_rewrite_program shows IP addresses instead of domain name when rewriting SSL/HTTPS">zaza1851983ml at googlemail.com
       </A><BR>
    <I>Sun Jul 10 08:13:12 UTC 2016</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="011491.html">[squid-users] url_rewrite_program shows IP addresses instead of domain name when rewriting SSL/HTTPS
</A></li>
        <LI>Next message (by thread): <A HREF="011493.html">[squid-users] url_rewrite_program shows IP addresses instead of domain name when rewriting SSL/HTTPS
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#11492">[ date ]</a>
              <a href="thread.html#11492">[ thread ]</a>
              <a href="subject.html#11492">[ subject ]</a>
              <a href="author.html#11492">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi Amos,

Thanks I really learnt alot from your previous email.

going on..

On Fri, Jul 8, 2016 at 1:18 PM, Amos Jeffries &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid3 at treenet.co.nz</A>&gt; wrote:

&gt;<i> On 8/07/2016 10:20 p.m., Moataz Elmasry wrote:
</I>&gt;<i> &gt; Hi Amos,
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Do you know any of those 'exceptional' redirectors that can handle https?
</I>&gt;<i> &gt;
</I>&gt;<i>
</I>&gt;<i> I know they exist, some of my clients wrote and use some. But I can't
</I>&gt;<i> point you to any if thats what you are asking.
</I>&gt;<i>
</I>&gt;<i> I can say though there r two things that can reliably be done with a
</I>&gt;<i> CONNECT request by a URL-rewriter;
</I>&gt;<i>
</I>&gt;<i> 1) return ERR, explicitly telling Squid not to re-write those tunnels.
</I>&gt;<i>
</I>&gt;<i> This trades helper complexity for simpler squid.conf ACLs. Both simply
</I>&gt;<i> telling Squid not to re-write.
</I>&gt;<i>
</I>&gt;<i> 2) re-write the URI from domain:port to be IP:port.
</I>&gt;<i>
</I>Funny thing is when I'm getting the URL in the redirect.bash, I'm not
getting an IP. I probed and logged in many fields as described in the
logformat page, and I usually get either the IP or the DNS inside
redirect.bash but not both

&gt;<i>
</I>&gt;<i> If the IP it gets re-written to is the one the client was going to, this
</I>&gt;<i> is in effect telling Squid not to do DNS lookup when figuring out where
</I>&gt;<i> to send it. That can be useful when you don't want Squid to use
</I>&gt;<i> alternative IPs it might find via DNS.
</I>&gt;<i>  (NP: This wont affect the host verify checking as it happens too late.
</I>&gt;<i> This is actually just a fancy way to enforce the ORIGINAL_DST pass-thru
</I>&gt;<i> behaviour based on more complex things than host-verify detects)
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; Ok. So let's ignore the redirection for now and just try to whitelist
</I>&gt;<i> some
</I>&gt;<i> &gt; https urls and deny anything else.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Now I'm trying to peek and bump the connection, just to obtain the
</I>&gt;<i> &gt; servername without causing much harm, but the https sites are now either
</I>&gt;<i> &gt; loading infinitely, or loading successfully, where they should have been
</I>&gt;<i> &gt; blacklisted, assuming the https unwrapping happened successfully. Could
</I>&gt;<i> you
</I>&gt;<i> &gt; please have a look and tell me what's wrong with the following
</I>&gt;<i> &gt; configuration? BTW after playing with ssl_bump I realized that I didn't
</I>&gt;<i> &gt; really understand the steps(1,2,3) as well as when to peek/bump/stare
</I>&gt;<i> &gt; etc... . The squid.conf contains some comments and questions
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; squid.conf
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; &quot;
</I>&gt;<i> &gt; acl http_sites dstdomain play.google.com mydomain.com
</I>&gt;<i> &gt; acl https_sites ssl::server_name play.google.com mydomain.com
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; #match any url where the servername in the SNI is not empty
</I>&gt;<i> &gt; acl haveServerName ssl::server_name_regex .
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; http_access allow http_sites
</I>&gt;<i> &gt; http_access allow https_sites #My expectation is that this rule is
</I>&gt;<i> matched
</I>&gt;<i> &gt; when the https connection has been unwrapped
</I>&gt;<i>
</I>&gt;<i> On HTTP traffic the &quot;http_sites&quot; ACL will match the URL domain.
</I>&gt;<i>
</I>&gt;<i> On HTTPS traffic without (or before finding) the SNI neither ACL will
</I>&gt;<i> match. Because URL is a raw-IP at that stage.
</I>&gt;<i>
</I>&gt;<i> On HTTPS traffic with SNI the &quot;http_sites&quot; ACL will match. Because the
</I>&gt;<i> SNI got copied to the request URI.
</I>&gt;<i>
</I>&gt;<i> The &quot;https_sites&quot; ACL will only be reached on traffic where the SNI does
</I>&gt;<i> *not* contain the values its looking for. This test will always be a
</I>&gt;<i> non-match / false.
</I>&gt;<i>
</I>Ouch, I now see in the docs that ssl::server_name is suitable for usage
within ssl_bump. So this is the only use case I suppose.

&gt;<i>
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; sslcrtd_program /lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; http_access deny all
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; http_port 3127
</I>&gt;<i> &gt; http_port 3128 intercept
</I>&gt;<i> &gt; https_port 3129 cert=/etc/squid/ssl/example.com.cert
</I>&gt;<i> &gt; key=/etc/squid/ssl/example.com.private ssl-bump intercept
</I>&gt;<i> &gt; generate-host-certificates=on  version=1
</I>&gt;<i> &gt; options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE capath=/etc/ssl/certs/
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; sslproxy_cert_error allow all
</I>&gt;<i> &gt; sslproxy_flags DONT_VERIFY_PEER
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; acl step1 at_step SslBump1
</I>&gt;<i> &gt; acl step2 at_step SslBump2
</I>&gt;<i> &gt; acl step3 at_step SslBump3
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; ssl_bump peek step1  #Is this equivelant to &quot;ssl_bump peek step1 all ???&quot;
</I>&gt;<i> &gt;
</I>&gt;<i>
</I>&gt;<i> Yes. &quot;all&quot; is a test that always produces match / true.
</I>&gt;<i>
</I>&gt;<i> The &quot;ssl_bump peek step1 all&quot; means:
</I>&gt;<i>  If (at_step == SslBump1 and true == true) then do peeking.
</I>&gt;<i>  else ...
</I>&gt;<i>
</I>&gt;<i> &gt; ssl_bump bump haveServerName !https_sites
</I>&gt;<i> &gt; #What about connections that didn't provide sni yet? Do they get to have
</I>&gt;<i> &gt; own definition for step2?
</I>&gt;<i>
</I>&gt;<i> For those:
</I>&gt;<i>
</I>&gt;<i>  &quot;haveServerName&quot; being a regex &quot;.&quot; pattern will match the raw-IP in the
</I>&gt;<i> CONNECT request, the SNI value, or any subjectAltName in the server
</I>&gt;<i> certificate. One of those three will always exist and have a value that
</I>&gt;<i> '.' is matched against. Basically it can't fail - therefore you can
</I>&gt;<i> consider it just a complicated (and slow / CPU draining) way of checking
</I>&gt;<i> &quot;all&quot;.
</I>&gt;<i>
</I>&gt;<i> AND
</I>&gt;<i>
</I>&gt;<i>  &quot;https_sites&quot; produces false. The &quot;!&quot; turns that false into true.
</I>&gt;<i>
</I>&gt;<i> So that line matches and &quot;bump&quot; action is done at step 2.
</I>&gt;<i>
</I>&gt;<i> Bump being a final action means there is no step 3 for those requests.
</I>&gt;<i>
</I>&gt;<i> NOTE:  Side effects of bump at step 2 (aka client-first bumping) is that
</I>&gt;<i> certificate Squid generates will be generated ONLY from squid.conf
</I>&gt;<i> settings and clientHello details.
</I>&gt;<i>  No server involvement, thus a very high chance that the server TLS
</I>&gt;<i> connection requirements and what Squid offers the client to use will
</I>&gt;<i> conflict or introduce downgrade attack vulnerabilities into these
</I>&gt;<i> connections.
</I>&gt;<i>
</I>&gt;<i>  Whether that is okay is a grey area with disagreement possibilities on
</I>&gt;<i> all sides.
</I>&gt;<i>  * On the one hand you are probably configuring good security for the
</I>&gt;<i> client connection even when the server connection has worse TLS.
</I>&gt;<i>  * On the two hand you are potentially configuring something worse than
</I>&gt;<i> some servers.
</I>&gt;<i>  * On the third hand you are definitely fooling the client into thinking
</I>&gt;<i> it has different security level than the server connection can provide,
</I>&gt;<i> or vice-versa for the server knowledge about the client connection. Its
</I>&gt;<i> risky, and you can expect problems.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; #Is this equivelant to &quot;ssl_bump  bump step2 haveServerName
</I>&gt;<i> !https_sites&quot; ??
</I>&gt;<i>
</I>&gt;<i> Yes it is.
</I>&gt;<i>
</I>&gt;<i> &gt; #Can I use step2 with some other acl?
</I>&gt;<i>
</I>&gt;<i> Er. You can use any ACL that has available data for the time and
</I>&gt;<i> position at which it is tested.
</I>&gt;<i>  In other words I would not suggest using ACLs that check HTTP response
</I>&gt;<i> headers at the ssl_bump checking time.
</I>&gt;<i>
</I>&gt;<i> At step 2 of SSL-Bumping process you have client TCP connection details,
</I>&gt;<i> TLS clientHello details and initial extensions like SNI (well the ones
</I>&gt;<i> that have been implemented - SNI being the only useful one AFAIK).
</I>&gt;<i>
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; ssl_bump splice all
</I>&gt;<i> &gt; #Is this now step3 for all?what about those urls who didn't have a match
</I>&gt;<i> in
</I>&gt;<i> &gt; step2. Is this step2 for some and step3 for others?
</I>&gt;<i>
</I>&gt;<i> Any step2 traffic which fails the &quot;!https_sites&quot; test will match this.
</I>&gt;<i> Which means there is no step3 for those requests.
</I>&gt;<i>
</I>&gt;<i> If you have been paying attention you will have noticed that all traffic
</I>&gt;<i> passing the &quot;!https_sites&quot; has been bumped, and all traffic failing that
</I>&gt;<i> same test has been spliced.
</I>&gt;<i>
</I>&gt;<i> ==&gt; Therefore, zero traffic reaches step 3.
</I>&gt;<i>
</I>&gt;<i> Many thanks for the detailed clarification, this really helps ALOT!!!!
</I>

&gt;<i>
</I>&gt;<i> My advice on this as a general rule-of-thumb is to splice at step 1 or 2
</I>&gt;<i> if you can. That solves a lot of possible problems with the splicing.
</I>&gt;<i> And to bump only at step 3 where the mimic feature can avoid a lot of
</I>&gt;<i> other problems with the bumping.
</I>&gt;<i>
</I>&gt;<i> You will still encounter some problems though (guaranteed). Don't forget
</I>&gt;<i> that TLS is specifically designed to prevent 'bumping' from being done
</I>&gt;<i> on its connections. The fact that we can offer the feature at all for
</I>&gt;<i> generic use is a terrible statement about the Internets bad lack of
</I>&gt;<i> security.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Cheers.
</I>&gt;<i> Amos
</I>&gt;<i>
</I>&gt;<i>
</I>Ok. new try.  The following are common configurations:
&quot;

acl http_sites dstdomain play.google.com mydomain.com
acl https_sites ssl::server_name play.google.com mydomain.com

http_access allow http_sites

sslcrtd_program /lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
http_access deny all

http_port 3127
http_port 3128 intercept
https_port 3129 cert=/etc/squid/ssl/example.com.cert
key=/etc/squid/ssl/example.com.private ssl-bump intercept
generate-host-certificates=on  version=1
options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE capath=/etc/ssl/certs/

sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

url_rewrite_program /bin/bash -c -l /etc/squid/redirect.bash
url_rewrite_extras &quot;%&gt;a/%&gt;A %&lt;A la=%la:%lp la2=%&lt;a/%&lt;a  la3=%&lt;la:%&lt;lp %un
%&gt;rm myip=%la myport=%lp  ru=%ru ru2=%&gt;ru ru3=%&lt;ru rd=%&gt;rd rd2=%&lt;rd h=%&gt;h
ssl1=%ssl::bump_mode ssl2=%ssl::&gt;sni ssl3=%ssl::&gt;cert_subject
ssl4=%ssl::&gt;cert_issuer  rp1=%rp rp2=%&gt;rp rp3=%&lt;rp h1=%&gt;h h2=%&gt;ha&quot;
logformat squid &quot;%&gt;a/%&gt;A %&lt;A la=%la:%lp la2=%&lt;a/%&lt;a  la3=%&lt;la:%&lt;lp  %un
%&gt;rm myip=%la myport=%lp  ru=%ru ru2=%&gt;ru ru3=%&lt;ru rd=%&gt;rd rd2=%&lt;rd h=%&gt;h
ssl1=%ssl::bump_mode ssl2=%ssl::&gt;sni ssl3=%ssl::&gt;cert_subject
ssl4=%ssl::&gt;cert_issuer  rp1=%rp rp2=%&gt;rp rp3=%&lt;rp h1=%&gt;h h2=%&gt;ha&quot;
url_rewrite_access allow all
&quot;

Using

&quot;ssl_bump splice step1 all
ssl_bump bump step3 all&quot;

Nothing is blocked. And I don't see any urls, nor sni info neither in
access.log nor in my redirect.log.Only IPs.  I'm trying many https sites.

Using
&quot;ssl_bump splice step2 all
ssl_bump bump step3 all&quot;

Same result.

Using
&quot;
ssl_bump peek step1 all
ssl_bump splice step2  all
ssl_bump bump step3 all
&quot;

I can see URLs in the access.log and redirect.log but no IP's. Further I'm
getting the header forgery warning in the logs, and all pages start
loading, but never finish. Maybe this is something related to the nat rules
in the iptables?

For info, I'm using the simplest bash redirector for now. Here's the code
while true;
do
    read input;
    echo &quot;input=${input}&quot;  &gt;&gt;/var/log/squid/redirects.log 2&gt;&amp;1
    old_url=$(echo ${input} | awk '{print $1}')
    echo &quot;${old_url}&quot;
    [[ $? != 0 ]] &amp;&amp; exit -1
    continue
done


I'll try squid4 next week, maybe the result will be better

Many thanks and cheers,
Moataz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.squid-cache.org/pipermail/squid-users/attachments/20160710/3dc4baf1/attachment.htm">http://lists.squid-cache.org/pipermail/squid-users/attachments/20160710/3dc4baf1/attachment.htm</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="011491.html">[squid-users] url_rewrite_program shows IP addresses instead of domain name when rewriting SSL/HTTPS
</A></li>
	<LI>Next message (by thread): <A HREF="011493.html">[squid-users] url_rewrite_program shows IP addresses instead of domain name when rewriting SSL/HTTPS
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#11492">[ date ]</a>
              <a href="thread.html#11492">[ thread ]</a>
              <a href="subject.html#11492">[ subject ]</a>
              <a href="author.html#11492">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
